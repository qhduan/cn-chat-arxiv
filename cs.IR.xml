<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;RetPO&#26694;&#26550;&#65292;&#36890;&#36807;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#23545;&#25628;&#32034;&#26597;&#35810;&#36827;&#34892;&#37325;&#26500;&#65292;&#20197;&#31526;&#21512;&#30446;&#26631;&#26816;&#32034;&#31995;&#32479;&#30340;&#20559;&#22909;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;RF Collection&#65292;&#29992;&#20110;&#25910;&#38598;&#26816;&#32034;&#32467;&#26524;&#20316;&#20026;&#26816;&#32034;&#22120;&#30340;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.11827</link><description>&lt;p&gt;
&#35810;&#38382;&#26368;&#20339;&#38382;&#39064;&#65306;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#26816;&#32034;&#22120;&#20559;&#22909;&#22312;&#20250;&#35805;&#25628;&#32034;&#20013;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Ask Optimal Questions: Aligning Large Language Models with Retriever's Preference in Conversational Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11827
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;RetPO&#26694;&#26550;&#65292;&#36890;&#36807;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#23545;&#25628;&#32034;&#26597;&#35810;&#36827;&#34892;&#37325;&#26500;&#65292;&#20197;&#31526;&#21512;&#30446;&#26631;&#26816;&#32034;&#31995;&#32479;&#30340;&#20559;&#22909;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;RF Collection&#65292;&#29992;&#20110;&#25910;&#38598;&#26816;&#32034;&#32467;&#26524;&#20316;&#20026;&#26816;&#32034;&#22120;&#30340;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#24335;&#25628;&#32034;&#19982;&#21333;&#36718;&#26816;&#32034;&#20219;&#21153;&#19981;&#21516;&#65292;&#38656;&#35201;&#29702;&#35299;&#23545;&#35805;&#19978;&#19979;&#25991;&#20013;&#30340;&#24403;&#21069;&#38382;&#39064;&#12290;&#24120;&#35265;&#30340;&#8220;&#37325;&#20889;-&#28982;&#21518;&#26816;&#32034;&#8221;&#30340;&#26041;&#27861;&#26088;&#22312;&#23558;&#38382;&#39064;&#21435;&#19978;&#19979;&#25991;&#21270;&#65292;&#20351;&#20854;&#23545;&#29616;&#25104;&#30340;&#26816;&#32034;&#22120;&#33258;&#32473;&#33258;&#36275;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#30001;&#20110;&#33021;&#21147;&#26377;&#38480;&#32780;&#20135;&#29983;&#27425;&#20248;&#30340;&#26597;&#35810;&#37325;&#20889;&#65292;&#26080;&#27861;&#20805;&#20998;&#21033;&#29992;&#26469;&#33258;&#26816;&#32034;&#32467;&#26524;&#30340;&#20449;&#21495;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;RetPO&#65288;&#26816;&#32034;&#22120;&#20559;&#22909;&#20248;&#21270;&#65289;&#65292;&#26088;&#22312;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#20197;&#31526;&#21512;&#30446;&#26631;&#26816;&#32034;&#31995;&#32479;&#30340;&#37325;&#20889;&#25628;&#32034;&#26597;&#35810;&#30340;&#20559;&#22909;&#12290;&#35813;&#36807;&#31243;&#22987;&#20110;&#25552;&#31034;&#22823;&#22411;LM&#29983;&#25104;&#21508;&#31181;&#28508;&#22312;&#37325;&#20889;&#65292;&#28982;&#21518;&#25910;&#38598;&#36825;&#20123;&#37325;&#20889;&#30340;&#26816;&#32034;&#24615;&#33021;&#20316;&#20026;&#26816;&#32034;&#22120;&#30340;&#20559;&#22909;&#12290;&#36890;&#36807;&#35813;&#36807;&#31243;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;RF&#22609;&#38598;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#23545;&#36229;&#36807;410K&#20010;&#26597;&#35810;&#30340;&#26816;&#32034;&#22120;&#21453;&#39304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11827v1 Announce Type: cross  Abstract: Conversational search, unlike single-turn retrieval tasks, requires understanding the current question within a dialogue context. The common approach of rewrite-then-retrieve aims to decontextualize questions to be self-sufficient for off-the-shelf retrievers, but most existing methods produce sub-optimal query rewrites due to the limited ability to incorporate signals from the retrieval results. To overcome this limitation, we present a novel framework RetPO (Retriever's Preference Optimization), which is designed to optimize a language model (LM) for reformulating search queries in line with the preferences of the target retrieval systems. The process begins by prompting a large LM to produce various potential rewrites and then collects retrieval performance for these rewrites as the retrievers' preferences. Through the process, we construct a large-scale dataset called RF collection, containing Retrievers' Feedback on over 410K quer
&lt;/p&gt;</description></item></channel></rss>