<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#65292;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2302.09051</link><description>&lt;p&gt;
&#22797;&#26434;&#38382;&#31572;&#21644;&#35821;&#35328;&#27169;&#22411;&#28151;&#21512;&#26550;&#26500;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Complex QA and language models hybrid architectures, Survey. (arXiv:2302.09051v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#65292;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#26631;&#20934;&#38382;&#39064;&#19978;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#65292;&#20294;&#22312;&#35299;&#20915;&#26356;&#20855;&#20307;&#30340;&#22797;&#26434;&#38382;&#39064;&#26102;&#65288;&#22914;&#22312;&#19981;&#21516;&#25991;&#21270;&#20013;&#20010;&#20154;&#33258;&#30001;&#27010;&#24565;&#30340;&#21464;&#21270;&#22914;&#20309;&#65311;&#20160;&#20040;&#26159;&#20026;&#20943;&#23569;&#27668;&#20505;&#21464;&#21270;&#32780;&#23454;&#29616;&#30340;&#26368;&#20339;&#21457;&#30005;&#26041;&#27861;&#32452;&#21512;&#65311;&#65289;&#65292;&#38656;&#35201;&#29305;&#23450;&#30340;&#26550;&#26500;&#12289;&#30693;&#35782;&#12289;&#25216;&#33021;&#12289;&#26041;&#27861;&#12289;&#25935;&#24863;&#25968;&#25454;&#20445;&#25252;&#12289;&#21487;&#35299;&#37322;&#24615;&#12289;&#20154;&#31867;&#23457;&#25209;&#21644;&#22810;&#21151;&#33021;&#21453;&#39304;&#12290;&#26368;&#36817;&#30340;&#39033;&#30446;&#22914;ChatGPT&#21644;GALACTICA&#20801;&#35768;&#38750;&#19987;&#19994;&#20154;&#21592;&#20102;&#35299;LLM&#22312;&#22797;&#26434;QA&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#20197;&#21450;&#21516;&#31561;&#24378;&#22823;&#30340;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23457;&#26597;&#25152;&#38656;&#30340;&#25216;&#33021;&#21644;&#35780;&#20272;&#25216;&#26415;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32508;&#36848;&#20102;&#29616;&#26377;&#30340;&#28151;&#21512;&#26550;&#26500;&#65292;&#23558;LLM&#19982;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#12289;&#20449;&#24687;&#26816;&#32034;&#12289;&#30693;&#35782;&#22270;&#35889;&#21644;&#20854;&#20182;AI/ML&#25216;&#26415;&#30456;&#32467;&#21512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;&#36825;&#20123;CQA&#31995;&#32479;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#26410;&#26469;&#30740;&#31350;&#30340;&#21487;&#33021;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper reviews the state-of-the-art of language models architectures and strategies for "complex" question-answering (QA, CQA, CPS) with a focus on hybridization. Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems (e.g. How does the concept of personal freedom vary between different cultures ? What is the best mix of power generation methods to reduce climate change ?) you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of LLM in complex QA. In this paper, we start by reviewing required skills and evaluation techniques. We integrate findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and an
&lt;/p&gt;</description></item></channel></rss>