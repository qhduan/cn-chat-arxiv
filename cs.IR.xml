<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>EASRec&#26159;&#19968;&#20010;&#38024;&#23545;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#24377;&#24615;&#26550;&#26500;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#21098;&#26525;&#25216;&#26415;&#21644;&#20808;&#36827;&#27169;&#22411;&#26550;&#26500;&#32467;&#21512;&#65292;&#20197;&#21450;&#36164;&#28304;&#21463;&#38480;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#21644;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#20445;&#25345;&#25110;&#22686;&#24378;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.00390</link><description>&lt;p&gt;
EASRec&#65306;&#29992;&#20110;&#39640;&#25928;&#38271;&#26399;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#24377;&#24615;&#26550;&#26500;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
EASRec: Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00390
&lt;/p&gt;
&lt;p&gt;
EASRec&#26159;&#19968;&#20010;&#38024;&#23545;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#30340;&#24377;&#24615;&#26550;&#26500;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#21098;&#26525;&#25216;&#26415;&#21644;&#20808;&#36827;&#27169;&#22411;&#26550;&#26500;&#32467;&#21512;&#65292;&#20197;&#21450;&#36164;&#28304;&#21463;&#38480;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#21644;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#20445;&#25345;&#25110;&#22686;&#24378;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#20016;&#23500;&#30340;&#26102;&#20195;&#65292;&#20174;&#28023;&#37327;&#20449;&#24687;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#35265;&#35299;&#30340;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#35299;&#20915;&#20102;&#24403;&#21069;&#39034;&#24207;&#25512;&#33616;&#31995;&#32479;&#65288;SRSs&#65289;&#22312;&#35745;&#31639;&#21644;&#36164;&#28304;&#25928;&#29575;&#26041;&#38754;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#37319;&#29992;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#27169;&#22411;&#65288;&#22914;SASRec&#65289;&#30340;&#31995;&#32479;&#12290;&#36825;&#20123;&#31995;&#32479;&#26088;&#22312;&#20026;&#21508;&#31181;&#24212;&#29992;&#25552;&#20379;&#19979;&#19968;&#20010;&#39033;&#30446;&#30340;&#25512;&#33616;&#65292;&#20174;&#30005;&#23376;&#21830;&#21153;&#21040;&#31038;&#20132;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#22312;&#25512;&#29702;&#38454;&#27573;&#20250;&#20135;&#29983;&#30456;&#24403;&#22823;&#30340;&#35745;&#31639;&#25104;&#26412;&#21644;&#36164;&#28304;&#28040;&#32791;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#33258;&#21160;&#21098;&#26525;&#25216;&#26415;&#21644;&#20808;&#36827;&#27169;&#22411;&#26550;&#26500;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#20013;&#27969;&#34892;&#30340;&#36164;&#28304;&#21463;&#38480;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#25216;&#26415;&#30340;&#28508;&#21147;&#65292;&#20197;&#35843;&#25972;&#27169;&#22411;&#20197;&#20943;&#23569;FLOPs&#12289;&#24310;&#36831;&#21644;&#33021;&#37327;&#20351;&#29992;&#65292;&#21516;&#26102;&#20445;&#25345;&#25110;&#22686;&#24378;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24320;&#21457;&#20102;&#19968;&#31181;
&lt;/p&gt;
&lt;p&gt;
In this age where data is abundant, the ability to distill meaningful insights from the sea of information is essential. Our research addresses the computational and resource inefficiencies that current Sequential Recommender Systems (SRSs) suffer from. especially those employing attention-based models like SASRec, These systems are designed for next-item recommendations in various applications, from e-commerce to social networks. However, such systems suffer from substantial computational costs and resource consumption during the inference stage. To tackle these issues, our research proposes a novel method that combines automatic pruning techniques with advanced model architectures. We also explore the potential of resource-constrained Neural Architecture Search (NAS), a technique prevalent in the realm of recommendation systems, to fine-tune models for reduced FLOPs, latency, and energy usage while retaining or even enhancing accuracy. The main contribution of our work is developing 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;Agent-OM&#65292;&#21033;&#29992;LLM&#20195;&#29702;&#20026;&#26412;&#20307;&#21305;&#37197;&#31995;&#32479;&#24341;&#20837;&#20102;&#26032;&#30340;&#35774;&#35745;&#33539;&#24335;&#12290;</title><link>https://arxiv.org/abs/2312.00326</link><description>&lt;p&gt;
Agent-OM&#65306;&#21033;&#29992;LLM&#20195;&#29702;&#36827;&#34892;&#26412;&#20307;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Agent-OM: Leveraging LLM Agents for Ontology Matching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.00326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;Agent-OM&#65292;&#21033;&#29992;LLM&#20195;&#29702;&#20026;&#26412;&#20307;&#21305;&#37197;&#31995;&#32479;&#24341;&#20837;&#20102;&#26032;&#30340;&#35774;&#35745;&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20307;&#21305;&#37197;&#65288;OM&#65289;&#33021;&#22815;&#23454;&#29616;&#19981;&#21516;&#26412;&#20307;&#20043;&#38388;&#30340;&#35821;&#20041;&#20114;&#25805;&#20316;&#24615;&#65292;&#36890;&#36807;&#23545;&#40784;&#30456;&#20851;&#23454;&#20307;&#26469;&#35299;&#20915;&#20854;&#27010;&#24565;&#24322;&#26500;&#24615;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20195;&#29702;&#30340;LLM&#35774;&#35745;&#33539;&#24335;&#65292;&#21629;&#21517;&#20026;Agent-OM&#65292;&#21253;&#25324;&#20004;&#20010;&#29992;&#20110;&#26816;&#32034;&#21644;&#21305;&#37197;&#30340;&#21516;&#20307;&#20195;&#29702;&#20197;&#21450;&#19968;&#32452;&#22522;&#20110;&#25552;&#31034;&#30340;&#31616;&#21333;OM&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.00326v2 Announce Type: replace  Abstract: Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM, consisting of two Siamese agents for retrieval and matching, with a set of simple prompt-based OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAE
&lt;/p&gt;</description></item></channel></rss>