<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#24341;&#20837;&#20102;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;MA4DIV&#26041;&#27861;&#65292;&#23558;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#24314;&#27169;&#20026;&#22810;&#20010;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21512;&#20316;&#20219;&#21153;&#65292;&#30452;&#25509;&#20248;&#21270;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#22914;$\alpha$-NDCG&#65292;&#20197;&#23454;&#29616;&#39640;&#35757;&#32451;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.17421</link><description>&lt;p&gt;
MA4DIV&#65306;&#29992;&#20110;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MA4DIV: Multi-Agent Reinforcement Learning for Search Result Diversification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17421
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;MA4DIV&#26041;&#27861;&#65292;&#23558;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#24314;&#27169;&#20026;&#22810;&#20010;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21512;&#20316;&#20219;&#21153;&#65292;&#30452;&#25509;&#20248;&#21270;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#22914;$\alpha$-NDCG&#65292;&#20197;&#23454;&#29616;&#39640;&#35757;&#32451;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#65288;SRD&#65289;&#30340;&#30446;&#26631;&#26159;&#30830;&#20445;&#25152;&#36873;&#25991;&#26723;&#28085;&#30422;&#23613;&#21487;&#33021;&#22810;&#30340;&#19981;&#21516;&#23376;&#20027;&#39064;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#21033;&#29992;&#8220;&#36138;&#23146;&#36873;&#25321;&#8221;&#33539;&#24335;&#65292;&#21363;&#19968;&#27425;&#36873;&#25321;&#19968;&#20010;&#20855;&#26377;&#26368;&#39640;&#22810;&#26679;&#24615;&#20998;&#25968;&#30340;&#25991;&#26723;&#12290;&#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#25928;&#29575;&#20302;&#19979;&#65292;&#23481;&#26131;&#38519;&#20837;&#27425;&#20248;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;&#19968;&#20123;&#20854;&#20182;&#26041;&#27861;&#26088;&#22312;&#36817;&#20284;&#20248;&#21270;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#22914;$\alpha$-NDCG&#65292;&#20294;&#32467;&#26524;&#20173;&#28982;&#19981;&#23613;&#22914;&#20154;&#24847;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#29992;&#20110;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#24615;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#26041;&#27861;&#65292;&#31216;&#20026;MA4DIV&#12290;&#22312;&#36825;&#31181;&#26041;&#27861;&#20013;&#65292;&#27599;&#20010;&#25991;&#26723;&#37117;&#26159;&#19968;&#20010;&#26234;&#33021;&#20307;&#65292;&#25628;&#32034;&#32467;&#26524;&#22810;&#26679;&#21270;&#34987;&#24314;&#27169;&#20026;&#22810;&#20010;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21512;&#20316;&#20219;&#21153;&#12290;&#35813;&#26041;&#27861;&#20801;&#35768;&#30452;&#25509;&#20248;&#21270;&#22810;&#26679;&#24615;&#25351;&#26631;&#65292;&#22914;$\alpha$-NDCG&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#35757;&#32451;&#25928;&#29575;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#21021;&#27493;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17421v1 Announce Type: cross  Abstract: The objective of search result diversification (SRD) is to ensure that selected documents cover as many different subtopics as possible. Existing methods primarily utilize a paradigm of "greedy selection", i.e., selecting one document with the highest diversity score at a time. These approaches tend to be inefficient and are easily trapped in a suboptimal state. In addition, some other methods aim to approximately optimize the diversity metric, such as $\alpha$-NDCG, but the results still remain suboptimal. To address these challenges, we introduce Multi-Agent reinforcement learning (MARL) for search result DIVersity, which called MA4DIV. In this approach, each document is an agent and the search result diversification is modeled as a cooperative task among multiple agents. This approach allows for directly optimizing the diversity metrics, such as $\alpha$-NDCG, while achieving high training efficiency. We conducted preliminary experi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23450;&#37327;&#30693;&#35782;&#26816;&#32034;&#30340;&#21487;&#34892;&#24615;&#65292;&#20197;&#36741;&#21161;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#24037;&#31243;&#26694;&#26550;&#65292;&#23558;LLMs&#20316;&#20026;&#31185;&#23398;&#25991;&#29486;&#28508;&#22312;&#31354;&#38388;&#30340;&#25509;&#21475;&#12290;&#35752;&#35770;&#20102;&#20351;&#29992;LLMs&#20316;&#20026;&#8220;&#19987;&#23478;&#8221;&#30340;&#24433;&#21709;&#21644;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.07770</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#23450;&#37327;&#30693;&#35782;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Quantitative knowledge retrieval from large language models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23450;&#37327;&#30693;&#35782;&#26816;&#32034;&#30340;&#21487;&#34892;&#24615;&#65292;&#20197;&#36741;&#21161;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#24037;&#31243;&#26694;&#26550;&#65292;&#23558;LLMs&#20316;&#20026;&#31185;&#23398;&#25991;&#29486;&#28508;&#22312;&#31354;&#38388;&#30340;&#25509;&#21475;&#12290;&#35752;&#35770;&#20102;&#20351;&#29992;LLMs&#20316;&#20026;&#8220;&#19987;&#23478;&#8221;&#30340;&#24433;&#21709;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22240;&#20854;&#29983;&#25104;&#20855;&#26377;&#35828;&#26381;&#21147;&#30340;&#33258;&#28982;&#35821;&#35328;&#24207;&#21015;&#30340;&#33021;&#21147;&#32780;&#34987;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#20854;&#20316;&#20026;&#23450;&#37327;&#20449;&#24687;&#26816;&#32034;&#30340;&#23454;&#29992;&#24615;&#23578;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;LLMs&#20316;&#20026;&#23450;&#37327;&#30693;&#35782;&#26816;&#32034;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#65292;&#20197;&#24110;&#21161;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#65292;&#22914;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#20808;&#39564;&#20998;&#24067;&#24341;&#23548;&#21644;&#32570;&#22833;&#25968;&#25454;&#30340;&#22635;&#34917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#24037;&#31243;&#26694;&#26550;&#65292;&#23558;LLMs&#35270;&#20026;&#31185;&#23398;&#25991;&#29486;&#28508;&#22312;&#31354;&#38388;&#30340;&#25509;&#21475;&#65292;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#21644;&#39046;&#22495;&#20013;&#27604;&#36739;&#21709;&#24212;&#19982;&#26356;&#25104;&#29087;&#30340;&#26041;&#27861;&#12290;&#35752;&#35770;&#20102;&#20351;&#29992;LLMs&#20316;&#20026;&#8220;&#19987;&#23478;&#8221;&#30340;&#24433;&#21709;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have been extensively studied for their abilities to generate convincing natural language sequences, however their utility for quantitative information retrieval is less well understood. In this paper we explore the feasibility of LLMs as a mechanism for quantitative knowledge retrieval to aid data analysis tasks such as elicitation of prior distributions for Bayesian models and imputation of missing data. We present a prompt engineering framework, treating an LLM as an interface to a latent space of scientific literature, comparing responses in different contexts and domains against more established approaches. Implications and challenges of using LLMs as 'experts' are discussed.
&lt;/p&gt;</description></item></channel></rss>