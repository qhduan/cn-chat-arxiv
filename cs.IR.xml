<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#65292;&#29992;&#20110;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#38754;&#20020;&#30340;&#25361;&#25112;&#26159;&#23458;&#25143;&#31471;&#24615;&#33021;&#19981;&#24179;&#34913;&#21644;&#23545;&#35745;&#31639;&#36164;&#28304;&#30340;&#39640;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.09959</link><description>&lt;p&gt;
&#22522;&#20110;LLM&#30340;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
LLM-based Federated Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09959
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#32852;&#37030;&#25512;&#33616;&#31995;&#32479;&#65292;&#29992;&#20110;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#38754;&#20020;&#30340;&#25361;&#25112;&#26159;&#23458;&#25143;&#31471;&#24615;&#33021;&#19981;&#24179;&#34913;&#21644;&#23545;&#35745;&#31639;&#36164;&#28304;&#30340;&#39640;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36890;&#36807;&#24494;&#35843;&#26041;&#27861;&#23637;&#31034;&#20102;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#20855;&#22791;&#20808;&#36827;&#30340;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#24494;&#35843;&#38656;&#35201;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#65292;&#36825;&#20250;&#24102;&#26469;&#38544;&#31169;&#39118;&#38505;&#65292;&#22240;&#20026;&#21253;&#21547;&#20102;&#25935;&#24863;&#29992;&#25143;&#20449;&#24687;&#12290;&#36825;&#20123;&#25968;&#25454;&#30340;&#24847;&#22806;&#27844;&#38706;&#21487;&#33021;&#20405;&#29359;&#25968;&#25454;&#20445;&#25252;&#27861;&#65292;&#24182;&#24341;&#21457;&#20262;&#29702;&#38382;&#39064;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#20123;&#38544;&#31169;&#38382;&#39064;&#65292;&#32852;&#37030;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#65288;Fed4Rec&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23558;Fed4Rec&#24212;&#29992;&#20110;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#39318;&#20808;&#65292;&#23458;&#25143;&#31471;&#24615;&#33021;&#19981;&#24179;&#34913;&#21152;&#21095;&#65292;&#24433;&#21709;&#31995;&#32479;&#30340;&#25928;&#29575;&#65307;&#20854;&#27425;&#65292;&#23545;&#20110;&#26412;&#22320;&#35757;&#32451;&#21644;&#25512;&#29702;LLM&#65292;&#23545;&#23458;&#25143;&#31471;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#36164;&#28304;&#38656;&#27714;&#24456;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09959v1 Announce Type: new  Abstract: Large Language Models (LLMs), with their advanced contextual understanding abilities, have demonstrated considerable potential in enhancing recommendation systems via fine-tuning methods. However, fine-tuning requires users' behavior data, which poses considerable privacy risks due to the incorporation of sensitive user information. The unintended disclosure of such data could infringe upon data protection laws and give rise to ethical issues. To mitigate these privacy issues, Federated Learning for Recommendation (Fed4Rec) has emerged as a promising approach. Nevertheless, applying Fed4Rec to LLM-based recommendation presents two main challenges: first, an increase in the imbalance of performance across clients, affecting the system's efficiency over time, and second, a high demand on clients' computational and storage resources for local training and inference of LLMs.   To address these challenges, we introduce a Privacy-Preserving LL
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#26041;&#27861;&#65292;&#19968;&#31181;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65292;&#21478;&#19968;&#31181;&#20351;&#29992;XGBoost&#31639;&#27861;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#25991;&#31456;&#25512;&#33616;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#30693;&#35782;&#22270;&#35889;&#65292;&#24182;&#22312;&#19968;&#20010;&#22823;&#22411;&#36328;&#22269;&#37329;&#34701;&#26381;&#21153;&#20844;&#21496;&#30340;&#23458;&#25143;&#20013;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.04996</link><description>&lt;p&gt;
&#21033;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#30693;&#35782;&#22270;&#35889;&#21644;&#24378;&#21270;&#23398;&#20064;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Empowering recommender systems using automatically generated Knowledge Graphs and Reinforcement Learning. (arXiv:2307.04996v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04996
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#26041;&#27861;&#65292;&#19968;&#31181;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65292;&#21478;&#19968;&#31181;&#20351;&#29992;XGBoost&#31639;&#27861;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#25991;&#31456;&#25512;&#33616;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#30693;&#35782;&#22270;&#35889;&#65292;&#24182;&#22312;&#19968;&#20010;&#22823;&#22411;&#36328;&#22269;&#37329;&#34701;&#26381;&#21153;&#20844;&#21496;&#30340;&#23458;&#25143;&#20013;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#25512;&#33616;&#22312;&#30452;&#25509;&#33829;&#38144;&#20013;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#28608;&#21457;&#20102;&#36890;&#36807;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#24212;&#29992;&#26469;&#25552;&#21319;&#23458;&#25143;&#20307;&#39564;&#30340;&#30740;&#31350;&#21160;&#26426;&#12290;&#20363;&#22914;&#65292;&#22312;&#37329;&#34701;&#26381;&#21153;&#39046;&#22495;&#65292;&#20844;&#21496;&#21487;&#20197;&#36890;&#36807;&#21521;&#23458;&#25143;&#25552;&#20379;&#30456;&#20851;&#37329;&#34701;&#25991;&#31456;&#26469;&#22521;&#20859;&#20851;&#31995;&#65292;&#20419;&#36827;&#23458;&#25143;&#21442;&#19982;&#21644;&#20419;&#36827;&#30693;&#24773;&#30340;&#37329;&#34701;&#20915;&#31574;&#12290;&#23613;&#31649;&#19968;&#20123;&#26041;&#27861;&#19987;&#27880;&#20110;&#22522;&#20110;KG&#30340;&#25512;&#33616;&#31995;&#32479;&#20197;&#25913;&#36827;&#20869;&#23481;&#65292;&#20294;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;KG&#30340;&#25512;&#33616;&#31995;&#32479;&#26469;&#36827;&#34892;&#20915;&#31574;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#20010;&#24615;&#21270;&#25991;&#31456;&#25512;&#33616;&#26041;&#27861;&#65292;&#29992;&#20110;&#19968;&#23478;&#22823;&#22411;&#36328;&#22269;&#37329;&#34701;&#26381;&#21153;&#20844;&#21496;&#30340;&#19968;&#32452;&#23458;&#25143;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65292;&#31532;&#20108;&#31181;&#26041;&#27861;&#20351;&#29992;XGBoost&#31639;&#27861;&#26469;&#21521;&#23458;&#25143;&#25512;&#33616;&#25991;&#31456;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#21033;&#29992;&#20174;&#32467;&#26500;&#21270;&#65288;&#34920;&#26684;&#25968;&#25454;&#65289;&#21644;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#22823;&#37327;&#25991;&#26412;&#25968;&#25454;&#65289;&#29983;&#25104;&#30340;KG&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized recommendations have a growing importance in direct marketing, which motivates research to enhance customer experiences by knowledge graph (KG) applications. For example, in financial services, companies may benefit from providing relevant financial articles to their customers to cultivate relationships, foster client engagement and promote informed financial decisions. While several approaches center on KG-based recommender systems for improved content, in this study we focus on interpretable KG-based recommender systems for decision making.To this end, we present two knowledge graph-based approaches for personalized article recommendations for a set of customers of a large multinational financial services company. The first approach employs Reinforcement Learning and the second approach uses the XGBoost algorithm for recommending articles to the customers. Both approaches make use of a KG generated from both structured (tabular data) and unstructured data (a large body o
&lt;/p&gt;</description></item></channel></rss>