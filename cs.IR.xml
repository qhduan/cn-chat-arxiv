<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;</title><link>https://arxiv.org/abs/2403.15740</link><description>&lt;p&gt;
Ghost Sentence&#65306;&#19968;&#31181;&#20379;&#26222;&#36890;&#29992;&#25143;&#20351;&#29992;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#36827;&#34892;&#29256;&#26435;&#20445;&#25252;
&lt;/p&gt;
&lt;p&gt;
Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15740
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Web&#29992;&#25143;&#25968;&#25454;&#22312;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21450;&#20854;&#24494;&#35843;&#21464;&#31181;&#30340;&#29983;&#24577;&#31995;&#32479;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#24314;&#35758;&#29992;&#25143;&#22312;&#20854;&#25991;&#26723;&#20013;&#21453;&#22797;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#65292;&#20351;LLMs&#33021;&#22815;&#35760;&#24518;&#36825;&#20123;&#23494;&#30721;&#12290;&#36825;&#20123;&#29992;&#25143;&#25991;&#26723;&#20013;&#38544;&#34255;&#30340;&#23494;&#30721;&#65292;&#34987;&#31216;&#20026;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#19968;&#26086;&#23427;&#20204;&#20986;&#29616;&#22312;LLMs&#29983;&#25104;&#30340;&#20869;&#23481;&#20013;&#65292;&#29992;&#25143;&#23601;&#21487;&#20197;&#30830;&#20449;&#20182;&#20204;&#30340;&#25968;&#25454;&#34987;&#29992;&#20110;&#35757;&#32451;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#31181;&#29256;&#26435;&#24037;&#20855;&#30340;&#26377;&#25928;&#24615;&#21644;&#29992;&#27861;&#65292;&#25105;&#20204;&#21033;&#29992;&#24189;&#28789;&#21477;&#23376;&#23450;&#20041;&#20102;&#8220;&#29992;&#25143;&#35757;&#32451;&#25968;&#25454;&#35782;&#21035;&#8221;&#20219;&#21153;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#26469;&#33258;&#19981;&#21516;&#26469;&#28304;&#12289;&#19981;&#21516;&#35268;&#27169;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#19981;&#21516;&#35268;&#27169;&#30340;LLMs&#36827;&#34892;&#27979;&#35797;&#12290;&#20026;&#20102;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26368;&#21518;$k$&#20010;&#21333;&#35789;&#39564;&#35777;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15740v1 Announce Type: new  Abstract: Web user data plays a central role in the ecosystem of pre-trained large language models (LLMs) and their fine-tuned variants. Billions of data are crawled from the web and fed to LLMs. How can \textit{\textbf{everyday web users}} confirm if LLMs misuse their data without permission? In this work, we suggest that users repeatedly insert personal passphrases into their documents, enabling LLMs to memorize them. These concealed passphrases in user documents, referred to as \textit{ghost sentences}, once they are identified in the generated content of LLMs, users can be sure that their data is used for training. To explore the effectiveness and usage of this copyrighting tool, we define the \textit{user training data identification} task with ghost sentences. Multiple datasets from various sources at different scales are created and tested with LLMs of different sizes. For evaluation, we introduce a last $k$ words verification manner along 
&lt;/p&gt;</description></item></channel></rss>