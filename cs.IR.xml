<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22914;&#20309;&#20351;&#29992;LLMs&#26469;&#25913;&#36827;&#24207;&#21015;&#25512;&#33616;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19977;&#31181;&#27491;&#20132;&#26041;&#27861;&#21644;&#23427;&#20204;&#30340;&#28151;&#21512;&#24418;&#24335;&#26469;&#21033;&#29992;LLMs&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#22823;&#37327;&#23454;&#39564;&#21644;&#19981;&#21516;&#37197;&#32622;&#19978;&#30340;&#25506;&#32034;&#65292;&#25105;&#20204;&#21457;&#29616;&#36890;&#36807;&#21021;&#22987;&#21270;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#21487;&#20197;&#23454;&#29616;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01339</link><description>&lt;p&gt;
&#20351;&#29992;LLMs&#25913;&#36827;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Improving Sequential Recommendations with LLMs
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22914;&#20309;&#20351;&#29992;LLMs&#26469;&#25913;&#36827;&#24207;&#21015;&#25512;&#33616;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19977;&#31181;&#27491;&#20132;&#26041;&#27861;&#21644;&#23427;&#20204;&#30340;&#28151;&#21512;&#24418;&#24335;&#26469;&#21033;&#29992;LLMs&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#22823;&#37327;&#23454;&#39564;&#21644;&#19981;&#21516;&#37197;&#32622;&#19978;&#30340;&#25506;&#32034;&#65292;&#25105;&#20204;&#21457;&#29616;&#36890;&#36807;&#21021;&#22987;&#21270;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#21487;&#20197;&#23454;&#29616;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#65292;&#24207;&#21015;&#25512;&#33616;&#38382;&#39064;&#24341;&#36215;&#20102;&#30456;&#24403;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#65292;&#23548;&#33268;&#20102;&#35768;&#22810;&#25512;&#33616;&#27169;&#22411;&#30340;&#20986;&#29616;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#29616;&#20170;&#22312;&#35768;&#22810;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#24212;&#29992;&#20013;&#24341;&#20837;&#20102;&#39072;&#35206;&#24615;&#24433;&#21709;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#26500;&#24314;&#25110;&#25913;&#36827;&#24207;&#21015;&#25512;&#33616;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19977;&#31181;&#27491;&#20132;&#26041;&#27861;&#21644;&#23427;&#20204;&#30340;&#28151;&#21512;&#24418;&#24335;&#65292;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#21033;&#29992;LLMs&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#20851;&#27880;&#32452;&#25104;&#25216;&#26415;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#24182;&#23545;&#27599;&#20010;&#26041;&#27861;&#30830;&#23450;&#19968;&#31995;&#21015;&#21487;&#34892;&#30340;&#26367;&#20195;&#36873;&#25321;&#65292;&#26469;&#30740;&#31350;&#27599;&#20010;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#24182;&#25506;&#32034;&#20102;&#21508;&#31181;&#37197;&#32622;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#35821;&#35328;&#27169;&#22411;&#21644;&#22522;&#20934;&#25512;&#33616;&#27169;&#22411;&#65292;&#20197;&#33719;&#24471;&#27599;&#20010;&#26041;&#27861;&#30340;&#24615;&#33021;&#30340;&#32508;&#21512;&#22270;&#29255;&#12290;&#22312;&#20854;&#20182;&#35266;&#23519;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#36890;&#36807;&#21021;&#22987;&#21270;&#26368;&#20808;&#36827;&#30340;&#24207;&#21015;&#25512;&#33616;&#27169;&#22411;&#21487;&#20197;&#23454;&#29616;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
The sequential recommendation problem has attracted considerable research attention in the past few years, leading to the rise of numerous recommendation models. In this work, we explore how Large Language Models (LLMs), which are nowadays introducing disruptive effects in many AI-based applications, can be used to build or improve sequential recommendation approaches. Specifically, we design three orthogonal approaches and hybrids of those to leverage the power of LLMs in different ways. In addition, we investigate the potential of each approach by focusing on its comprising technical aspects and determining an array of alternative choices for each one. We conduct extensive experiments on three datasets and explore a large variety of configurations, including different language models and baseline recommendation models, to obtain a comprehensive picture of the performance of each approach. Among other observations, we highlight that initializing state-of-the-art sequential recommendat
&lt;/p&gt;</description></item></channel></rss>