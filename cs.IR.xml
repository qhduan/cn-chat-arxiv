<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34701;&#20837;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20114;&#34917;&#22686;&#24378;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;&#65292;&#20805;&#20998;&#21457;&#25381;&#23427;&#20204;&#21508;&#33258;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#21319;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.13870</link><description>&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34701;&#20837;&#25512;&#33616;&#31995;&#32479;&#30340;&#20114;&#34917;&#22686;&#24378;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Integrating Large Language Models into Recommendation via Mutual Augmentation and Adaptive Aggregation. (arXiv:2401.13870v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34701;&#20837;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20114;&#34917;&#22686;&#24378;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;&#65292;&#20805;&#20998;&#21457;&#25381;&#23427;&#20204;&#21508;&#33258;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#21319;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25512;&#33616;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#34892;&#20026;&#20013;&#30340;&#21327;&#21516;&#25110;&#36830;&#32493;&#20449;&#24687;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#26368;&#36817;&#65292;&#30001;&#20110;&#20854;&#22312;&#29702;&#35299;&#21644;&#25512;&#29702;&#25991;&#26412;&#35821;&#20041;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#24471;&#21040;&#20102;&#37325;&#35270;&#65292;&#24182;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#21457;&#29616;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;&#20256;&#32479;&#30340;&#25512;&#33616;&#26041;&#27861;&#21644;LLMs&#21508;&#33258;&#20855;&#26377;&#21508;&#33258;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#12290;&#20256;&#32479;&#26041;&#27861;&#25797;&#38271;&#25366;&#25496;&#21327;&#21516;&#20449;&#24687;&#21644;&#24314;&#27169;&#36830;&#32493;&#34892;&#20026;&#65292;&#20294;&#22312;&#25968;&#25454;&#31232;&#30095;&#21644;&#38271;&#23614;&#38382;&#39064;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#32780;LLMs&#21017;&#25797;&#38271;&#21033;&#29992;&#20016;&#23500;&#30340;&#25991;&#26412;&#19978;&#19979;&#25991;&#65292;&#20294;&#22312;&#25366;&#25496;&#21327;&#21516;&#25110;&#36830;&#32493;&#20449;&#24687;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#23613;&#31649;&#23427;&#20204;&#21508;&#33258;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22312;&#21033;&#29992;&#23427;&#20204;&#30340;&#32852;&#21512;&#28508;&#21147;&#26469;&#25552;&#21319;&#25512;&#33616;&#24615;&#33021;&#26041;&#38754;&#23384;&#22312;&#30528;&#26174;&#33879;&#24046;&#36317;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20114;&#34917;&#22686;&#24378;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conventional recommendation methods have achieved notable advancements by harnessing collaborative or sequential information from user behavior. Recently, large language models (LLMs) have gained prominence for their capabilities in understanding and reasoning over textual semantics, and have found utility in various domains, including recommendation. Conventional recommendation methods and LLMs each have their strengths and weaknesses. While conventional methods excel at mining collaborative information and modeling sequential behavior, they struggle with data sparsity and the long-tail problem. LLMs, on the other hand, are proficient at utilizing rich textual contexts but face challenges in mining collaborative or sequential information. Despite their individual successes, there is a significant gap in leveraging their combined potential to enhance recommendation performance.  In this paper, we introduce a general and model-agnostic framework known as \textbf{L}arge \textbf{la}nguage
&lt;/p&gt;</description></item></channel></rss>