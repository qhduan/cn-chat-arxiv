<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#38024;&#23545;&#25490;&#21517;&#27169;&#22411;&#30340;&#29305;&#24449;&#24402;&#22240;&#36827;&#34892;&#20102;&#20005;&#26684;&#23450;&#20041;&#65292;&#24182;&#25552;&#20986;&#20102;RankingSHAP&#20316;&#20026;&#19968;&#31181;&#36880;&#39033;&#25490;&#21517;&#24402;&#22240;&#26041;&#27861;&#65292;&#31361;&#30772;&#20102;&#24403;&#21069;&#35299;&#37322;&#35780;&#20272;&#26041;&#26696;&#30340;&#23616;&#38480;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#35780;&#20272;&#33539;&#24335;&#12290;</title><link>https://arxiv.org/abs/2403.16085</link><description>&lt;p&gt;
RankingSHAP -- &#38024;&#23545;&#25490;&#21517;&#27169;&#22411;&#30340;&#36880;&#39033;&#29305;&#24449;&#24402;&#22240;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
RankingSHAP -- Listwise Feature Attribution Explanations for Ranking Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16085
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#25490;&#21517;&#27169;&#22411;&#30340;&#29305;&#24449;&#24402;&#22240;&#36827;&#34892;&#20102;&#20005;&#26684;&#23450;&#20041;&#65292;&#24182;&#25552;&#20986;&#20102;RankingSHAP&#20316;&#20026;&#19968;&#31181;&#36880;&#39033;&#25490;&#21517;&#24402;&#22240;&#26041;&#27861;&#65292;&#31361;&#30772;&#20102;&#24403;&#21069;&#35299;&#37322;&#35780;&#20272;&#26041;&#26696;&#30340;&#23616;&#38480;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#35780;&#20272;&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#24402;&#22240;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#35299;&#37322;&#31867;&#22411;&#65292;&#29992;&#20110;&#22312;&#35757;&#32451;&#27169;&#22411;&#21518;&#20107;&#21518;&#35299;&#37322;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#22312;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#27809;&#26377;&#24471;&#21040;&#24456;&#22909;&#30340;&#30740;&#31350;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#29305;&#24449;&#24402;&#22240;&#24456;&#23569;&#34987;&#20005;&#26684;&#23450;&#20041;&#65292;&#38500;&#20102;&#23558;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#24402;&#22240;&#20026;&#26368;&#39640;&#20540;&#20043;&#22806;&#12290;&#20160;&#20040;&#26159;&#27604;&#20854;&#20182;&#29305;&#24449;&#26356;&#37325;&#35201;&#30340;&#29305;&#24449;&#24448;&#24448;&#34987;&#27169;&#31946;&#22320;&#25551;&#36848;&#12290;&#22240;&#27492;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#21482;&#20851;&#27880;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#65292;&#19981;&#20805;&#20998;&#21033;&#29992;&#29978;&#33267;&#24573;&#35270;&#29305;&#24449;&#20869;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20005;&#26684;&#23450;&#20041;&#20102;&#25490;&#21517;&#27169;&#22411;&#29305;&#24449;&#24402;&#22240;&#30340;&#27010;&#24565;&#65292;&#24182;&#21015;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#24402;&#22240;&#24212;&#20855;&#22791;&#30340;&#22522;&#26412;&#23646;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;RankingSHAP&#20316;&#20026;&#36880;&#39033;&#25490;&#21517;&#24402;&#22240;&#26041;&#27861;&#30340;&#20855;&#20307;&#23454;&#20363;&#12290;&#19982;&#30446;&#21069;&#20851;&#27880;&#36873;&#25321;&#30340;&#35299;&#37322;&#35780;&#20272;&#26041;&#26696;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#35780;&#20272;&#24402;&#22240;&#30340;&#26032;&#39062;&#35780;&#20272;&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16085v1 Announce Type: new  Abstract: Feature attributions are a commonly used explanation type, when we want to posthoc explain the prediction of a trained model. Yet, they are not very well explored in IR. Importantly, feature attribution has rarely been rigorously defined, beyond attributing the most important feature the highest value. What it means for a feature to be more important than others is often left vague. Consequently, most approaches focus on just selecting the most important features and under utilize or even ignore the relative importance within features. In this work, we rigorously define the notion of feature attribution for ranking models, and list essential properties that a valid attribution should have. We then propose RankingSHAP as a concrete instantiation of a list-wise ranking attribution method. Contrary to current explanation evaluation schemes that focus on selections, we propose two novel evaluation paradigms for evaluating attributions over l
&lt;/p&gt;</description></item></channel></rss>