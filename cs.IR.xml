<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;LLM4SBR&#26694;&#26550;&#65292;&#26159;&#31532;&#19968;&#20010;&#36866;&#21512;&#22312;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36731;&#37327;&#19988;&#26377;&#25928;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2402.13840</link><description>&lt;p&gt;
LLM4SBR: &#19968;&#20010;&#36731;&#37327;&#19988;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13840
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;LLM4SBR&#26694;&#26550;&#65292;&#26159;&#31532;&#19968;&#20010;&#36866;&#21512;&#22312;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36731;&#37327;&#19988;&#26377;&#25928;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;(SBR)&#21033;&#29992;&#26469;&#33258;&#21311;&#21517;&#29992;&#25143;&#30340;&#20250;&#35805;&#34892;&#20026;&#24207;&#21015;&#36827;&#34892;&#25512;&#33616;&#12290;&#34429;&#28982;&#36825;&#31181;&#31574;&#30053;&#38750;&#24120;&#39640;&#25928;&#65292;&#20294;&#29306;&#29298;&#20102;&#21830;&#21697;&#30340;&#22266;&#26377;&#35821;&#20041;&#20449;&#24687;&#65292;&#20351;&#27169;&#22411;&#38590;&#20197;&#29702;&#35299;&#20250;&#35805;&#30340;&#30495;&#27491;&#24847;&#22270;&#65292;&#23548;&#33268;&#25512;&#33616;&#32467;&#26524;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#12290;&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#20010;&#39046;&#22495;&#34028;&#21187;&#21457;&#23637;&#65292;&#20026;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#24102;&#26469;&#20102;&#19968;&#32447;&#24076;&#26395;&#12290;&#21463;LLMs&#24433;&#21709;&#65292;&#25506;&#35752;LLMs&#19982;&#25512;&#33616;&#31995;&#32479;(RS)&#38598;&#25104;&#30340;&#30740;&#31350;&#22914;&#38632;&#21518;&#26149;&#31499;&#33324;&#28044;&#29616;&#12290;&#28982;&#32780;&#65292;&#21463;&#38480;&#20110;&#39640;&#26102;&#38388;&#21644;&#31354;&#38388;&#25104;&#26412;&#65292;&#20197;&#21450;&#20250;&#35805;&#25968;&#25454;&#30701;&#26242;&#19988;&#21311;&#21517;&#30340;&#29305;&#24615;&#65292;&#31532;&#19968;&#20010;&#36866;&#21512;&#24037;&#19994;&#37096;&#32626;&#30340;LLM&#25512;&#33616;&#26694;&#26550;&#22312;SBR&#39046;&#22495;&#23578;&#26410;&#20986;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#65292;&#25105;&#20204;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13840v1 Announce Type: cross  Abstract: Traditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation. Although this strategy is highly efficient, it sacrifices the inherent semantic information of the items, making it difficult for the model to understand the true intent of the session and resulting in a lack of interpretability in the recommended results. Recently, large language models (LLMs) have flourished across various domains, offering a glimpse of hope in addressing the aforementioned challenges. Inspired by the impact of LLMs, research exploring the integration of LLMs with the Recommender system (RS) has surged like mushrooms after rain. However, constrained by high time and space costs, as well as the brief and anonymous nature of session data, the first LLM recommendation framework suitable for industrial deployment has yet to emerge in the field of SBR. To address the aforementioned challenges, we hav
&lt;/p&gt;</description></item><item><title>LD4MRec&#26159;&#19968;&#31181;&#31616;&#21270;&#21644;&#21152;&#24378;&#22810;&#23186;&#20307;&#25512;&#33616;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#34892;&#20026;&#25968;&#25454;&#22122;&#22768;&#23545;&#25512;&#33616;&#24615;&#33021;&#30340;&#36127;&#38754;&#24433;&#21709;&#12289;&#32463;&#20856;&#25193;&#25955;&#27169;&#22411;&#35745;&#31639;&#37327;&#36807;&#22823;&#20197;&#21450;&#29616;&#26377;&#21453;&#21521;&#36807;&#31243;&#19981;&#36866;&#29992;&#20110;&#31163;&#25955;&#34892;&#20026;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.15363</link><description>&lt;p&gt;
LD4MRec:&#31616;&#21270;&#21644;&#21152;&#24378;&#22810;&#23186;&#20307;&#25512;&#33616;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LD4MRec: Simplifying and Powering Diffusion Model for Multimedia Recommendation. (arXiv:2309.15363v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15363
&lt;/p&gt;
&lt;p&gt;
LD4MRec&#26159;&#19968;&#31181;&#31616;&#21270;&#21644;&#21152;&#24378;&#22810;&#23186;&#20307;&#25512;&#33616;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#34892;&#20026;&#25968;&#25454;&#22122;&#22768;&#23545;&#25512;&#33616;&#24615;&#33021;&#30340;&#36127;&#38754;&#24433;&#21709;&#12289;&#32463;&#20856;&#25193;&#25955;&#27169;&#22411;&#35745;&#31639;&#37327;&#36807;&#22823;&#20197;&#21450;&#29616;&#26377;&#21453;&#21521;&#36807;&#31243;&#19981;&#36866;&#29992;&#20110;&#31163;&#25955;&#34892;&#20026;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23186;&#20307;&#25512;&#33616;&#26088;&#22312;&#26681;&#25454;&#21382;&#21490;&#34892;&#20026;&#25968;&#25454;&#21644;&#39033;&#30446;&#30340;&#22810;&#27169;&#24577;&#20449;&#24687;&#39044;&#27979;&#29992;&#25143;&#30340;&#26410;&#26469;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#34892;&#20026;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#65292;&#20135;&#29983;&#20110;&#19982;&#19981;&#24863;&#20852;&#36259;&#30340;&#39033;&#30446;&#30340;&#38750;&#39044;&#26399;&#29992;&#25143;&#20132;&#20114;&#65292;&#23545;&#25512;&#33616;&#24615;&#33021;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#26368;&#36817;&#65292;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#20102;&#39640;&#36136;&#37327;&#30340;&#20449;&#24687;&#29983;&#25104;&#65292;&#20854;&#20013;&#21453;&#21521;&#36807;&#31243;&#26681;&#25454;&#21463;&#25439;&#29366;&#24577;&#36845;&#20195;&#22320;&#25512;&#26029;&#26410;&#26469;&#20449;&#24687;&#12290;&#23427;&#28385;&#36275;&#20102;&#22312;&#22024;&#26434;&#26465;&#20214;&#19979;&#30340;&#39044;&#27979;&#20219;&#21153;&#38656;&#27714;&#65292;&#24182;&#28608;&#21457;&#20102;&#23545;&#20854;&#22312;&#39044;&#27979;&#29992;&#25143;&#34892;&#20026;&#26041;&#38754;&#30340;&#24212;&#29992;&#30340;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#36824;&#38656;&#35201;&#35299;&#20915;&#20960;&#20010;&#25361;&#25112;&#65306;1&#65289;&#32463;&#20856;&#25193;&#25955;&#27169;&#22411;&#38656;&#35201;&#36807;&#22810;&#30340;&#35745;&#31639;&#65292;&#36825;&#19981;&#31526;&#21512;&#25512;&#33616;&#31995;&#32479;&#30340;&#25928;&#29575;&#35201;&#27714;&#12290;2&#65289;&#29616;&#26377;&#30340;&#21453;&#21521;&#36807;&#31243;&#20027;&#35201;&#35774;&#35745;&#29992;&#20110;&#36830;&#32493;&#22411;&#25968;&#25454;&#65292;&#32780;&#34892;&#20026;&#20449;&#24687;&#26159;&#31163;&#25955;&#22411;&#30340;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#31163;&#25955;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimedia recommendation aims to predict users' future behaviors based on historical behavioral data and item's multimodal information. However, noise inherent in behavioral data, arising from unintended user interactions with uninteresting items, detrimentally impacts recommendation performance. Recently, diffusion models have achieved high-quality information generation, in which the reverse process iteratively infers future information based on the corrupted state. It meets the need of predictive tasks under noisy conditions, and inspires exploring their application to predicting user behaviors. Nonetheless, several challenges must be addressed: 1) Classical diffusion models require excessive computation, which does not meet the efficiency requirements of recommendation systems. 2) Existing reverse processes are mainly designed for continuous data, whereas behavioral information is discrete in nature. Therefore, an effective method is needed for the generation of discrete behaviora
&lt;/p&gt;</description></item></channel></rss>