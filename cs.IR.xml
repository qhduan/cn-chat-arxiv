<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20132;&#20114;&#27169;&#25311;&#22120; (LLM-InS)&#65292;&#29992;&#20110;&#35299;&#20915;&#20919;&#21551;&#21160;&#29289;&#21697;&#25512;&#33616;&#30340;&#38382;&#39064;&#12290;&#35813;&#27169;&#25311;&#22120;&#33021;&#22815;&#27169;&#25311;&#20986;&#36924;&#30495;&#30340;&#20132;&#20114;&#65292;&#24182;&#23558;&#20919;&#21551;&#21160;&#29289;&#21697;&#36716;&#21270;&#20026;&#28909;&#38376;&#29289;&#21697;&#65292;&#20174;&#32780;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09176</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20132;&#20114;&#27169;&#25311;&#22120;&#29992;&#20110;&#20919;&#21551;&#21160;&#29289;&#21697;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Large Language Model Interaction Simulator for Cold-Start Item Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09176
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20132;&#20114;&#27169;&#25311;&#22120; (LLM-InS)&#65292;&#29992;&#20110;&#35299;&#20915;&#20919;&#21551;&#21160;&#29289;&#21697;&#25512;&#33616;&#30340;&#38382;&#39064;&#12290;&#35813;&#27169;&#25311;&#22120;&#33021;&#22815;&#27169;&#25311;&#20986;&#36924;&#30495;&#30340;&#20132;&#20114;&#65292;&#24182;&#23558;&#20919;&#21551;&#21160;&#29289;&#21697;&#36716;&#21270;&#20026;&#28909;&#38376;&#29289;&#21697;&#65292;&#20174;&#32780;&#25552;&#39640;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#20919;&#21551;&#21160;&#29289;&#21697;&#23545;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#26469;&#35828;&#26159;&#20010;&#38271;&#26399;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#36825;&#20123;&#29289;&#21697;&#32570;&#20047;&#21382;&#21490;&#29992;&#25143;&#20132;&#20114;&#20197;&#24314;&#27169;&#20182;&#20204;&#30340;&#21327;&#21516;&#29305;&#24615;&#12290;&#20919;&#21551;&#21160;&#29289;&#21697;&#30340;&#20869;&#23481;&#19982;&#34892;&#20026;&#27169;&#24335;&#20043;&#38388;&#30340;&#24046;&#36317;&#20351;&#24471;&#24456;&#38590;&#20026;&#20854;&#29983;&#25104;&#20934;&#30830;&#30340;&#34892;&#20026;&#23884;&#20837;&#12290;&#29616;&#26377;&#30340;&#20919;&#21551;&#21160;&#27169;&#22411;&#20351;&#29992;&#26144;&#23556;&#20989;&#25968;&#22522;&#20110;&#20919;&#21551;&#21160;&#29289;&#21697;&#30340;&#20869;&#23481;&#29305;&#24449;&#29983;&#25104;&#34394;&#20551;&#30340;&#34892;&#20026;&#23884;&#20837;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#29983;&#25104;&#30340;&#23884;&#20837;&#19982;&#30495;&#23454;&#30340;&#34892;&#20026;&#23884;&#20837;&#23384;&#22312;&#26174;&#33879;&#30340;&#24046;&#24322;&#65292;&#23545;&#20919;&#21551;&#21160;&#25512;&#33616;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20869;&#23481;&#26041;&#38754;&#26469;&#27169;&#25311;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#30340;LLM&#20132;&#20114;&#27169;&#25311;&#22120; (LLM-InS)&#12290;&#35813;&#27169;&#25311;&#22120;&#20801;&#35768;&#25512;&#33616;&#31995;&#32479;&#20026;&#27599;&#20010;&#20919;&#21551;&#21160;&#29289;&#21697;&#27169;&#25311;&#29983;&#21160;&#30340;&#20132;&#20114;&#65292;&#24182;&#23558;&#20854;&#30452;&#25509;&#20174;&#20919;&#21551;&#21160;&#29289;&#21697;&#36716;&#21270;&#20026;&#28909;&#38376;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09176v1 Announce Type: new Abstract: Recommending cold items is a long-standing challenge for collaborative filtering models because these cold items lack historical user interactions to model their collaborative features. The gap between the content of cold items and their behavior patterns makes it difficult to generate accurate behavioral embeddings for cold items. Existing cold-start models use mapping functions to generate fake behavioral embeddings based on the content feature of cold items. However, these generated embeddings have significant differences from the real behavioral embeddings, leading to a negative impact on cold recommendation performance. To address this challenge, we propose an LLM Interaction Simulator (LLM-InS) to model users' behavior patterns based on the content aspect. This simulator allows recommender systems to simulate vivid interactions for each cold item and transform them from cold to warm items directly. Specifically, we outline the desig
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20840;&#38754;&#35780;&#20272;&#20102;LLMs&#22312;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#21644;&#25512;&#29702;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;GPT-4&#26356;&#36866;&#21512;&#20316;&#20026;&#25512;&#29702;&#21161;&#25163;&#65292;&#24182;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#20102;&#31934;&#35843;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2305.13168</link><description>&lt;p&gt;
LLMs&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#21644;&#25512;&#29702;&#65306;&#26368;&#26032;&#21151;&#33021;&#19982;&#26410;&#26469;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2305.13168
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20840;&#38754;&#35780;&#20272;&#20102;LLMs&#22312;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#21644;&#25512;&#29702;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;GPT-4&#26356;&#36866;&#21512;&#20316;&#20026;&#25512;&#29702;&#21161;&#25163;&#65292;&#24182;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#20102;&#31934;&#35843;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#26500;&#24314;&#21644;&#25512;&#29702;&#20013;&#30340;&#25968;&#37327;&#21270;&#21644;&#36136;&#21270;&#35780;&#20272;&#36827;&#34892;&#20102;&#35814;&#23613;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#22312;&#20843;&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#37325;&#28857;&#20851;&#27880;&#28085;&#30422;&#23454;&#20307;&#21644;&#20851;&#31995;&#25552;&#21462;&#12289;&#20107;&#20214;&#25552;&#21462;&#12289;&#38142;&#25509;&#39044;&#27979;&#21644;&#38382;&#31572;&#22235;&#20010;&#20856;&#22411;&#20219;&#21153;&#65292;&#20174;&#32780;&#20840;&#38754;&#25506;&#32034;&#20102;LLMs&#22312;&#26500;&#24314;&#21644;&#25512;&#29702;&#39046;&#22495;&#30340;&#34920;&#29616;&#12290;&#32463;&#39564;&#24615;&#30740;&#31350;&#21457;&#29616;&#65292;&#20197;GPT-4&#20026;&#20195;&#34920;&#30340;LLMs&#26356;&#36866;&#21512;&#20316;&#20026;&#25512;&#29702;&#21161;&#25163;&#65292;&#32780;&#19981;&#26159;&#23569;&#26679;&#26412;&#20449;&#24687;&#25552;&#21462;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#34429;&#28982;GPT-4&#22312;&#19982;KG&#26500;&#24314;&#30456;&#20851;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#25512;&#29702;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#20986;&#33394;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#20102;&#31934;&#35843;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#35843;&#26597;&#36824;&#25193;&#23637;&#21040;LLMs&#22312;&#20449;&#24687;&#25552;&#21462;&#26041;&#38754;&#30340;&#28508;&#22312;&#27867;&#21270;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#34394;&#25311;&#30693;&#35782;&#25552;&#21462;&#30340;&#26500;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2305.13168v2 Announce Type: replace-cross  Abstract: This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We engage in experiments across eight diverse datasets, focusing on four representative tasks encompassing entity and relation extraction, event extraction, link prediction, and question-answering, thereby thoroughly exploring LLMs' performance in the domain of construction and inference. Empirically, our findings suggest that LLMs, represented by GPT-4, are more suited as inference assistants rather than few-shot information extractors. Specifically, while GPT-4 exhibits good performance in tasks related to KG construction, it excels further in reasoning tasks, surpassing fine-tuned models in certain cases. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, leading to the proposition of a Virtual Knowledge Extr
&lt;/p&gt;</description></item></channel></rss>