<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#27169;&#22411;-&#19981;&#21487;&#30693;&#30340;&#26694;&#26550;RLMRec&#65292;&#36890;&#36807;&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#22686;&#24378;&#20256;&#32479;&#30340;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#24182;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12289;&#20165;&#20381;&#36182;&#25991;&#26412;&#30340;&#38480;&#21046;&#20197;&#21450;&#25552;&#31034;&#36755;&#20837;&#38480;&#21046;&#31561;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.15950</link><description>&lt;p&gt;
&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25512;&#33616;&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Representation Learning with Large Language Models for Recommendation. (arXiv:2310.15950v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15950
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#27169;&#22411;-&#19981;&#21487;&#30693;&#30340;&#26694;&#26550;RLMRec&#65292;&#36890;&#36807;&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#22686;&#24378;&#20256;&#32479;&#30340;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#31995;&#32479;&#65292;&#24182;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12289;&#20165;&#20381;&#36182;&#25991;&#26412;&#30340;&#38480;&#21046;&#20197;&#21450;&#25552;&#31034;&#36755;&#20837;&#38480;&#21046;&#31561;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#22312;&#28145;&#24230;&#23398;&#20064;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#19979;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#29305;&#21035;&#26159;&#22312;&#25429;&#25417;&#22797;&#26434;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20851;&#31995;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22522;&#20110;&#22270;&#30340;&#25512;&#33616;&#31995;&#32479;&#20005;&#37325;&#20381;&#36182;&#20110;&#22522;&#20110;ID&#30340;&#25968;&#25454;&#65292;&#21487;&#33021;&#24573;&#30053;&#20102;&#19982;&#29992;&#25143;&#21644;&#29289;&#21697;&#30456;&#20851;&#30340;&#26377;&#20215;&#20540;&#30340;&#25991;&#26412;&#20449;&#24687;&#65292;&#23548;&#33268;&#23398;&#21040;&#30340;&#34920;&#31034;&#19981;&#22815;&#23500;&#26377;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#38544;&#24335;&#21453;&#39304;&#25968;&#25454;&#30340;&#21033;&#29992;&#24341;&#20837;&#20102;&#28508;&#22312;&#30340;&#22122;&#22768;&#21644;&#20559;&#24046;&#65292;&#32473;&#29992;&#25143;&#20559;&#22909;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#23613;&#31649;&#23558;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;ID&#30340;&#25512;&#33616;&#31995;&#32479;&#30456;&#32467;&#21512;&#24050;&#32463;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#20294;&#22312;&#23454;&#38469;&#25512;&#33616;&#31995;&#32479;&#20013;&#26377;&#25928;&#23454;&#26045;&#36824;&#38656;&#35201;&#35299;&#20915;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12289;&#20165;&#20381;&#36182;&#25991;&#26412;&#30340;&#38480;&#21046;&#20197;&#21450;&#25552;&#31034;&#36755;&#20837;&#38480;&#21046;&#31561;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26694;&#26550;RLMRec&#65292;&#26088;&#22312;&#36890;&#36807;LLM&#24378;&#21270;&#34920;&#31034;&#26469;&#22686;&#24378;&#29616;&#26377;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representati
&lt;/p&gt;</description></item></channel></rss>