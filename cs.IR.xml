<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#25968;&#25454;&#38598;CODE-ACCORD&#65292;&#26088;&#22312;&#35299;&#20915;&#33258;&#21160;&#21512;&#35268;&#26816;&#26597;&#20013;&#35299;&#37322;&#24314;&#31569;&#27861;&#35268;&#30340;&#25361;&#25112;&#65292;&#25104;&#20026;&#26426;&#22120;&#21487;&#35835;&#35268;&#21017;&#29983;&#25104;&#30340;&#22522;&#30784;&#12290;</title><link>https://arxiv.org/abs/2403.02231</link><description>&lt;p&gt;
CODE-ACCORD&#65306;&#29992;&#20110;&#35268;&#21017;&#29983;&#25104;&#30340;&#24314;&#31569;&#27861;&#35268;&#25968;&#25454;&#35821;&#26009;&#24211;
&lt;/p&gt;
&lt;p&gt;
CODE-ACCORD: A Corpus of Building Regulatory Data for Rule Generation towards Automatic Compliance Checking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02231
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#25968;&#25454;&#38598;CODE-ACCORD&#65292;&#26088;&#22312;&#35299;&#20915;&#33258;&#21160;&#21512;&#35268;&#26816;&#26597;&#20013;&#35299;&#37322;&#24314;&#31569;&#27861;&#35268;&#30340;&#25361;&#25112;&#65292;&#25104;&#20026;&#26426;&#22120;&#21487;&#35835;&#35268;&#21017;&#29983;&#25104;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21512;&#35268;&#26816;&#26597;&#65288;ACC&#65289;&#22312;&#24314;&#31569;&#12289;&#24037;&#31243;&#21644;&#26045;&#24037;&#65288;AEC&#65289;&#39046;&#22495;&#20869;&#30340;&#33258;&#21160;&#21512;&#35268;&#26816;&#26597;&#38656;&#35201;&#33258;&#21160;&#35299;&#37322;&#24314;&#31569;&#27861;&#35268;&#65292;&#20197;&#21457;&#25381;&#20854;&#20840;&#37096;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#20174;&#25991;&#26412;&#35268;&#21017;&#20013;&#25552;&#21462;&#20449;&#24687;&#20197;&#23558;&#20854;&#36716;&#25442;&#20026;&#26426;&#22120;&#21487;&#35835;&#26684;&#24335;&#30001;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#22797;&#26434;&#24615;&#20197;&#21450;&#20165;&#33021;&#25903;&#25345;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#26377;&#38480;&#36164;&#28304;&#32780;&#25104;&#20026;&#19968;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#25968;&#25454;&#38598;CODE-ACCORD&#65292;&#36825;&#26159;&#22312;&#27431;&#30431;Horizon ACCORD&#39033;&#30446;&#19979;&#32534;&#21046;&#30340;&#12290;CODE-ACCORD&#21253;&#21547;862&#20010;&#26469;&#33258;&#33521;&#26684;&#20848;&#21644;&#33452;&#20848;&#24314;&#31569;&#27861;&#35268;&#30340;&#33258;&#21253;&#21547;&#21477;&#23376;&#12290;&#19982;&#25105;&#20204;&#30340;&#26680;&#24515;&#30446;&#26631;&#19968;&#33268;&#65292;&#21363;&#20419;&#36827;&#20174;&#25991;&#26412;&#20013;&#25552;&#21462;&#20449;&#24687;&#20197;&#29983;&#25104;&#26426;&#22120;&#21487;&#35835;&#35268;&#21017;&#65292;&#27599;&#20010;&#21477;&#23376;&#37117;&#27880;&#37322;&#20102;&#23454;&#20307;&#21644;&#20851;&#31995;&#12290;&#23454;&#20307;&#20195;&#34920;&#29305;&#23450;&#32452;&#20214;&#65292;&#22914;&#8220;&#31383;&#25143;&#8221;&#21644;&#8220;&#28895;&#38654;&#25506;&#27979;&#22120;&#8221;&#65292;&#32780;re
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02231v1 Announce Type: new  Abstract: Automatic Compliance Checking (ACC) within the Architecture, Engineering, and Construction (AEC) sector necessitates automating the interpretation of building regulations to achieve its full potential. However, extracting information from textual rules to convert them to a machine-readable format has been a challenge due to the complexities associated with natural language and the limited resources that can support advanced machine-learning techniques. To address this challenge, we introduce CODE-ACCORD, a unique dataset compiled under the EU Horizon ACCORD project. CODE-ACCORD comprises 862 self-contained sentences extracted from the building regulations of England and Finland. Aligned with our core objective of facilitating information extraction from text for machine-readable rule generation, each sentence was annotated with entities and relations. Entities represent specific components such as "window" and "smoke detectors", while re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#36848;&#20102;&#20174;&#22240;&#26524;&#23398;&#20064;&#30340;&#35282;&#24230;&#23545;&#21487;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#35843;&#26597;&#12290;&#22240;&#26524;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;TRS&#20013;&#28508;&#22312;&#20559;&#35265;&#21644;&#22122;&#22768;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#39046;&#22495;&#20013;&#65292;&#32570;&#20047;&#19968;&#20010;&#21450;&#26102;&#30340;&#35843;&#26597;&#12290;</title><link>https://arxiv.org/abs/2402.08241</link><description>&lt;p&gt;
&#21487;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#22240;&#26524;&#25512;&#29702;&#25216;&#26415;&#65306;&#19968;&#39033;&#35843;&#26597;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Causal Learning for Trustworthy Recommender Systems: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;&#20174;&#22240;&#26524;&#23398;&#20064;&#30340;&#35282;&#24230;&#23545;&#21487;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#36827;&#34892;&#35843;&#26597;&#12290;&#22240;&#26524;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;TRS&#20013;&#28508;&#22312;&#20559;&#35265;&#21644;&#22122;&#22768;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#39046;&#22495;&#20013;&#65292;&#32570;&#20047;&#19968;&#20010;&#21450;&#26102;&#30340;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#22312;&#22312;&#32447;&#20869;&#23481;&#21457;&#29616;&#21644;&#20010;&#24615;&#21270;&#20915;&#31574;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;RS&#20013;&#20986;&#29616;&#30340;&#28431;&#27934;&#20419;&#20351;&#20102;&#21521;&#21487;&#20449;&#36182;&#30340;&#25512;&#33616;&#31995;&#32479;&#65288;TRS&#65289;&#30340;&#33539;&#24335;&#36716;&#21464;&#12290;&#23613;&#31649;TRS&#21462;&#24471;&#20102;&#35768;&#22810;&#36827;&#23637;&#65292;&#20294;&#22823;&#37096;&#20998;&#37117;&#38598;&#20013;&#22312;&#25968;&#25454;&#30456;&#20851;&#24615;&#19978;&#65292;&#32780;&#24573;&#35270;&#20102;&#25512;&#33616;&#20013;&#30340;&#22522;&#26412;&#22240;&#26524;&#20851;&#31995;&#12290;&#36825;&#20010;&#32570;&#28857;&#38459;&#30861;&#20102;TRS&#22312;&#35299;&#20915;&#21487;&#20449;&#36182;&#24615;&#38382;&#39064;&#26102;&#35782;&#21035;&#21407;&#22240;&#65292;&#23548;&#33268;&#20844;&#24179;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#21463;&#21040;&#38480;&#21046;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#22240;&#26524;&#23398;&#20064;&#20316;&#20026;&#19968;&#31867;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#20986;&#29616;&#65292;&#20197;&#22686;&#24378;TRS&#12290;&#36825;&#20123;&#26041;&#27861;&#20197;&#21487;&#38752;&#30340;&#22240;&#26524;&#20851;&#31995;&#20026;&#22522;&#30784;&#65292;&#22312;&#20943;&#36731;&#21508;&#31181;&#20559;&#35265;&#21644;&#22122;&#22768;&#30340;&#21516;&#26102;&#65292;&#20026;TRS&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#39046;&#22495;&#20013;&#65292;&#32570;&#20047;&#19968;&#20010;&#21450;&#26102;&#30340;&#35843;&#26597;&#12290;&#26412;&#25991;&#20174;&#22240;&#26524;&#23398;&#20064;&#30340;&#35282;&#24230;&#23545;TRS&#36827;&#34892;&#20102;&#27010;&#36848;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#22240;&#26524;&#23548;&#21521;TRS&#65288;CTRS&#65289;&#30340;&#20248;&#21183;&#21644;&#24120;&#35265;&#31243;&#24207;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#28508;&#22312;&#30340;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;&#22312;TRS&#20013;&#30340;&#24212;&#29992;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender Systems (RS) have significantly advanced online content discovery and personalized decision-making. However, emerging vulnerabilities in RS have catalyzed a paradigm shift towards Trustworthy RS (TRS). Despite numerous progress on TRS, most of them focus on data correlations while overlooking the fundamental causal nature in recommendation. This drawback hinders TRS from identifying the cause in addressing trustworthiness issues, leading to limited fairness, robustness, and explainability. To bridge this gap, causal learning emerges as a class of promising methods to augment TRS. These methods, grounded in reliable causality, excel in mitigating various biases and noises while offering insightful explanations for TRS. However, there lacks a timely survey in this vibrant area. This paper creates an overview of TRS from the perspective of causal learning. We begin by presenting the advantages and common procedures of Causality-oriented TRS (CTRS). Then, we identify potential 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#30340;&#20027;&#39064;&#21457;&#29616;&#26041;&#27861;&#65292;&#23558;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#26469;&#33258;&#36755;&#20837;&#35821;&#26009;&#24211;&#30340;&#23616;&#37096;&#35821;&#20041;&#30456;&#32467;&#21512;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#20027;&#39064;&#36830;&#36143;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.01845</link><description>&lt;p&gt;
&#24102;&#26377;&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#30340;&#20027;&#39064;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds. (arXiv:2205.01845v1 [cs.CL] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.01845
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#30340;&#20027;&#39064;&#21457;&#29616;&#26041;&#27861;&#65292;&#23558;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#26469;&#33258;&#36755;&#20837;&#35821;&#26009;&#24211;&#30340;&#23616;&#37096;&#35821;&#20041;&#30456;&#32467;&#21512;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#20027;&#39064;&#36830;&#36143;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#24180;&#26469;&#65292;&#20174;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#21457;&#29616;&#28508;&#22312;&#20027;&#39064;&#19968;&#30452;&#26159;&#30740;&#31350;&#30340;&#35838;&#39064;&#12290;&#35768;&#22810;&#29616;&#26377;&#30340;&#20027;&#39064;&#27169;&#22411;&#37319;&#29992;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#35774;&#32622;&#65292;&#30001;&#20110;&#23427;&#20204;&#26080;&#27861;&#21033;&#29992;&#29992;&#25143;&#25351;&#23548;&#65292;&#25152;&#20197;&#23427;&#20204;&#21457;&#29616;&#30340;&#20027;&#39064;&#21487;&#33021;&#19981;&#31526;&#21512;&#29992;&#25143;&#30340;&#29305;&#23450;&#20852;&#36259;&#12290;&#34429;&#28982;&#23384;&#22312;&#21033;&#29992;&#29992;&#25143;&#25552;&#20379;&#30340;&#31181;&#23376;&#35789;&#26469;&#21457;&#29616;&#20027;&#39064;&#20195;&#34920;&#35789;&#30340;&#31181;&#23376;&#24341;&#23548;&#20027;&#39064;&#21457;&#29616;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#36739;&#23569;&#20851;&#27880;&#20004;&#20010;&#22240;&#32032;&#65306;(1)&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#30340;&#23384;&#22312;&#21644;(2)&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#31181;&#23376;&#24341;&#23548;&#20027;&#39064;&#21457;&#29616;&#30340;&#20219;&#21153;&#25512;&#24191;&#21040;&#20801;&#35768;&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;SeeTopic&#65292;&#22312;&#20854;&#20013;PLM&#30340;&#36890;&#29992;&#30693;&#35782;&#21644;&#20174;&#36755;&#20837;&#35821;&#26009;&#24211;&#20013;&#23398;&#20064;&#30340;&#23616;&#37096;&#35821;&#20041;&#21487;&#20197;&#30456;&#20114;&#21463;&#30410;&#12290;&#22312;&#26469;&#33258;&#19981;&#21516;&#39046;&#22495;&#30340;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;SeeTopic&#22312;&#20027;&#39064;&#36830;&#36143;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering latent topics from text corpora has been studied for decades. Many existing topic models adopt a fully unsupervised setting, and their discovered topics may not cater to users' particular interests due to their inability of leveraging user guidance. Although there exist seed-guided topic discovery approaches that leverage user-provided seeds to discover topic-representative terms, they are less concerned with two factors: (1) the existence of out-of-vocabulary seeds and (2) the power of pre-trained language models (PLMs). In this paper, we generalize the task of seed-guided topic discovery to allow out-of-vocabulary seeds. We propose a novel framework, named SeeTopic, wherein the general knowledge of PLMs and the local semantics learned from the input corpus can mutually benefit each other. Experiments on three real datasets from different domains demonstrate the effectiveness of SeeTopic in terms of topic coherence, accuracy, and diversity.
&lt;/p&gt;</description></item></channel></rss>