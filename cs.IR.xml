<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36890;&#36807;&#28151;&#21512;&#32467;&#26500;&#21270;&#25688;&#35201;&#21644;&#22522;&#20110;LLM&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#20027;&#39064;&#30456;&#20851;&#24615;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#26356;&#22909;&#22320;&#23398;&#20064;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24230;&#12290;</title><link>https://arxiv.org/abs/2404.02616</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#32467;&#26500;&#21270;&#25688;&#35201;&#21644;&#22522;&#20110;LLM&#30340;&#25968;&#25454;&#22686;&#24378;&#26469;&#25913;&#36827;&#20027;&#39064;&#30456;&#20851;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Improving Topic Relevance Model by Mix-structured Summarization and LLM-based Data Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02616
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#32467;&#26500;&#21270;&#25688;&#35201;&#21644;&#22522;&#20110;LLM&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#20027;&#39064;&#30456;&#20851;&#24615;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#26356;&#22909;&#22320;&#23398;&#20064;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#21644;&#25991;&#26723;&#20043;&#38388;&#30340;&#20027;&#39064;&#30456;&#20851;&#24615;&#26159;&#31038;&#20132;&#25628;&#32034;&#30340;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#37096;&#20998;&#65292;&#21487;&#20197;&#35780;&#20272;&#25991;&#26723;&#19982;&#29992;&#25143;&#38656;&#27714;&#20043;&#38388;&#30340;&#21305;&#37197;&#31243;&#24230;&#12290;&#22312;&#22823;&#22810;&#25968;&#31038;&#20132;&#25628;&#32034;&#22330;&#26223;&#20013;&#65292;&#22914;&#22823;&#20247;&#28857;&#35780;&#65292;&#24314;&#27169;&#25628;&#32034;&#30456;&#20851;&#24615;&#24635;&#26159;&#38754;&#20020;&#20004;&#20010;&#25361;&#25112;&#12290;&#19968;&#20010;&#26159;&#35768;&#22810;&#31038;&#20132;&#25628;&#32034;&#20013;&#30340;&#25991;&#26723;&#38750;&#24120;&#38271;&#19988;&#21253;&#21547;&#22823;&#37327;&#20887;&#20313;&#20449;&#24687;&#12290;&#21478;&#19968;&#20010;&#38382;&#39064;&#26159;&#25628;&#32034;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#24456;&#38590;&#33719;&#24471;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#22810;&#20998;&#31867;&#30456;&#20851;&#24615;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#20197;&#19978;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#26597;&#35810;&#19982;&#22522;&#20110;&#26597;&#35810;&#30340;&#25688;&#35201;&#20197;&#21450;&#19981;&#24102;&#26597;&#35810;&#30340;&#25991;&#26723;&#25688;&#35201;&#21512;&#24182;&#65292;&#20316;&#20026;&#20027;&#39064;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#36755;&#20837;&#65292;&#36825;&#26377;&#21161;&#20110;&#27169;&#22411;&#23398;&#20064;&#26597;&#35810;&#21644;&#25991;&#26723;&#26680;&#24515;&#20027;&#39064;&#20043;&#38388;&#30340;&#30456;&#20851;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#20174;&#29616;&#26377;&#35757;&#32451;&#25968;&#25454;&#20013;&#37325;&#26032;&#32534;&#20889;&#21644;&#29983;&#25104;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02616v1 Announce Type: cross  Abstract: Topic relevance between query and document is a very important part of social search, which can evaluate the degree of matching between document and user's requirement. In most social search scenarios such as Dianping, modeling search relevance always faces two challenges. One is that many documents in social search are very long and have much redundant information. The other is that the training data for search relevance model is difficult to get, especially for multi-classification relevance model. To tackle above two problems, we first take query concatenated with the query-based summary and the document summary without query as the input of topic relevance model, which can help model learn the relevance degree between query and the core topic of document. Then, we utilize the language understanding and generation abilities of large language model (LLM) to rewrite and generate query from queries and documents in existing training da
&lt;/p&gt;</description></item></channel></rss>