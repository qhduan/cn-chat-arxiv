<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#31038;&#21306;&#24212;&#35813;&#37325;&#26032;&#23558;&#30740;&#31350;&#35758;&#31243;&#32858;&#28966;&#20110;&#31038;&#20250;&#38656;&#27714;&#65292;&#28040;&#38500;&#20844;&#24179;&#24615;&#12289;&#38382;&#36131;&#21046;&#12289;&#36879;&#26126;&#24230;&#21644;&#36947;&#24503;&#30740;&#31350;&#19982;&#20449;&#24687;&#26816;&#32034;&#20854;&#20182;&#39046;&#22495;&#20043;&#38388;&#30340;&#20154;&#20026;&#38548;&#31163;&#65292;&#31215;&#26497;&#35774;&#23450;&#30740;&#31350;&#35758;&#31243;&#65292;&#28608;&#21169;&#26500;&#24314;&#26126;&#30830;&#38472;&#36848;&#30340;&#31038;&#20250;&#25216;&#26415;&#24819;&#35937;&#21147;&#25152;&#21551;&#21457;&#30340;&#31995;&#32479;&#31867;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.17901</link><description>&lt;p&gt;
&#25628;&#32034;&#19982;&#31038;&#20250;&#65306;&#37325;&#26032;&#26500;&#24819;&#28608;&#36827;&#26410;&#26469;&#30340;&#20449;&#24687;&#33719;&#21462;
&lt;/p&gt;
&lt;p&gt;
Search and Society: Reimagining Information Access for Radical Futures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17901
&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#24212;&#35813;&#37325;&#26032;&#23558;&#30740;&#31350;&#35758;&#31243;&#32858;&#28966;&#20110;&#31038;&#20250;&#38656;&#27714;&#65292;&#28040;&#38500;&#20844;&#24179;&#24615;&#12289;&#38382;&#36131;&#21046;&#12289;&#36879;&#26126;&#24230;&#21644;&#36947;&#24503;&#30740;&#31350;&#19982;&#20449;&#24687;&#26816;&#32034;&#20854;&#20182;&#39046;&#22495;&#20043;&#38388;&#30340;&#20154;&#20026;&#38548;&#31163;&#65292;&#31215;&#26497;&#35774;&#23450;&#30740;&#31350;&#35758;&#31243;&#65292;&#28608;&#21169;&#26500;&#24314;&#26126;&#30830;&#38472;&#36848;&#30340;&#31038;&#20250;&#25216;&#26415;&#24819;&#35937;&#21147;&#25152;&#21551;&#21457;&#30340;&#31995;&#32479;&#31867;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv: 2403.17901v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#25216;&#26415;&#21644;&#30740;&#31350;&#27491;&#22312;&#32463;&#21382;&#21464;&#38761;&#12290;&#25105;&#20204;&#35748;&#20026;&#31038;&#21306;&#24212;&#35813;&#25235;&#20303;&#36825;&#20010;&#26426;&#20250;&#65292;&#37325;&#26032;&#23558;&#30740;&#31350;&#35758;&#31243;&#32858;&#28966;&#20110;&#31038;&#20250;&#38656;&#27714;&#65292;&#21516;&#26102;&#28040;&#38500;IR&#30340;&#20844;&#24179;&#24615;&#12289;&#38382;&#36131;&#21046;&#12289;&#36879;&#26126;&#24230;&#21644;&#36947;&#24503;&#30740;&#31350;&#19982;IR&#20854;&#20182;&#39046;&#22495;&#20043;&#38388;&#30340;&#20154;&#20026;&#38548;&#31163;&#12290;&#31038;&#21306;&#19981;&#24212;&#37319;&#21462;&#35797;&#22270;&#20943;&#36731;&#26032;&#20852;&#25216;&#26415;&#21487;&#33021;&#24102;&#26469;&#31038;&#20250;&#23475;&#22788;&#30340;&#21453;&#24212;&#24615;&#31574;&#30053;&#65292;&#32780;&#24212;&#35813;&#31215;&#26497;&#35774;&#23450;&#30740;&#31350;&#35758;&#31243;&#65292;&#28608;&#21169;&#25105;&#20204;&#26500;&#24314;&#21508;&#31181;&#26126;&#30830;&#38472;&#36848;&#30340;&#31038;&#20250;&#25216;&#26415;&#24819;&#35937;&#21147;&#25152;&#21551;&#21457;&#30340;&#31995;&#32479;&#31867;&#22411;&#12290;&#25903;&#25745;&#20449;&#24687;&#33719;&#21462;&#25216;&#26415;&#35774;&#35745;&#21644;&#24320;&#21457;&#30340;&#31038;&#20250;&#25216;&#26415;&#24819;&#35937;&#21147;&#38656;&#35201;&#26126;&#30830;&#34920;&#36798;&#65292;&#25105;&#20204;&#38656;&#35201;&#22312;&#36825;&#20123;&#19981;&#21516;&#35270;&#35282;&#30340;&#32972;&#26223;&#19979;&#21457;&#23637;&#21464;&#38761;&#29702;&#35770;&#12290;&#25105;&#20204;&#30340;&#25351;&#23548;&#26410;&#26469;&#24819;&#35937;&#21147;&#24517;&#39035;&#21463;&#21040;&#20854;&#20182;&#23398;&#26415;&#39046;&#22495;&#30340;&#21551;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17901v1 Announce Type: new  Abstract: Information retrieval (IR) technologies and research are undergoing transformative changes. It is our perspective that the community should accept this opportunity to re-center our research agendas on societal needs while dismantling the artificial separation between the work on fairness, accountability, transparency, and ethics in IR and the rest of IR research. Instead of adopting a reactionary strategy of trying to mitigate potential social harms from emerging technologies, the community should aim to proactively set the research agenda for the kinds of systems we should build inspired by diverse explicitly stated sociotechnical imaginaries. The sociotechnical imaginaries that underpin the design and development of information access technologies needs to be explicitly articulated, and we need to develop theories of change in context of these diverse perspectives. Our guiding future imaginaries must be informed by other academic field
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#22312;&#22823;&#35268;&#27169;&#30005;&#21830;&#25968;&#25454;&#38598;&#19978;&#36890;&#36807;&#38598;&#25104;&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.14906</link><description>&lt;p&gt;
&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions. (arXiv:2307.14906v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#22312;&#22823;&#35268;&#27169;&#30005;&#21830;&#25968;&#25454;&#38598;&#19978;&#36890;&#36807;&#38598;&#25104;&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;TRON&#65292;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#30340;&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#12290;&#21463;&#21040;SASRec&#21644;GRU4Rec+&#31561;&#29616;&#26377;&#27169;&#22411;&#22312;&#21487;&#25193;&#23637;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#38480;&#21046;&#65292;TRON&#38598;&#25104;&#20102;top-k&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#25552;&#39640;&#20854;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#22312;&#30456;&#20851;&#30340;&#22823;&#35268;&#27169;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;TRON&#22312;&#20445;&#25345;&#19982;SASRec&#31867;&#20284;&#30340;&#35757;&#32451;&#36895;&#24230;&#30340;&#21516;&#26102;&#65292;&#25913;&#36827;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#25512;&#33616;&#36136;&#37327;&#12290;&#19968;&#39033;&#23454;&#26102;&#30340;A/B&#27979;&#35797;&#26174;&#31034;&#65292;&#30456;&#23545;&#20110;SASRec&#65292;TRON&#30340;&#28857;&#20987;&#29575;&#22686;&#21152;&#20102;18.14%&#65292;&#31361;&#26174;&#20102;&#20854;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces TRON, a scalable session-based Transformer Recommender using Optimized Negative-sampling. Motivated by the scalability and performance limitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates top-k negative sampling and listwise loss functions to enhance its recommendation accuracy. Evaluations on relevant large-scale e-commerce datasets show that TRON improves upon the recommendation quality of current methods while maintaining training speeds similar to SASRec. A live A/B test yielded an 18.14% increase in click-through rate over SASRec, highlighting the potential of TRON in practical settings. For further research, we provide access to our source code at https://github.com/otto-de/TRON and an anonymized dataset at https://github.com/otto-de/recsys-dataset.
&lt;/p&gt;</description></item></channel></rss>