<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#20171;&#32461;&#20102;IR2&#65292;&#19968;&#31181;&#29992;&#20110;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#20943;&#23569;&#36807;&#25311;&#21512;&#30340;&#20449;&#24687;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#22312;&#22797;&#26434;&#26597;&#35810;&#30340;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#21516;&#26102;&#23558;&#25104;&#26412;&#38477;&#20302;&#39640;&#36798;50%&#12290;</title><link>https://arxiv.org/abs/2402.16200</link><description>&lt;p&gt;
IR2&#65306;&#20449;&#24687;&#27491;&#21017;&#21270;&#29992;&#20110;&#20449;&#24687;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
IR2: Information Regularization for Information Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16200
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;IR2&#65292;&#19968;&#31181;&#29992;&#20110;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#20943;&#23569;&#36807;&#25311;&#21512;&#30340;&#20449;&#24687;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#22312;&#22797;&#26434;&#26597;&#35810;&#30340;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#21516;&#26102;&#23558;&#25104;&#26412;&#38477;&#20302;&#39640;&#36798;50%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#22320;&#22312;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#22797;&#26434;&#26597;&#35810;&#65292;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;IR2&#65292;&#21363;&#20449;&#24687;&#26816;&#32034;&#30340;&#20449;&#24687;&#27491;&#21017;&#21270;&#65292;&#19968;&#31181;&#29992;&#20110;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#20943;&#23569;&#36807;&#25311;&#21512;&#30340;&#25216;&#26415;&#12290;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#22797;&#26434;&#26597;&#35810;&#29305;&#24449;&#30340;&#19977;&#20010;&#26368;&#36817;&#30340;IR&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65306;DORIS-MAE&#12289;ArguAna&#21644;WhatsThatBook&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#19981;&#20165;&#22312;&#25152;&#32771;&#34385;&#30340;&#20219;&#21153;&#19978;&#20248;&#20110;&#20808;&#21069;&#30340;&#21512;&#25104;&#26597;&#35810;&#29983;&#25104;&#26041;&#27861;&#65292;&#32780;&#19988;&#36824;&#33021;&#23558;&#25104;&#26412;&#38477;&#20302;&#39640;&#36798;50&#65285;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#23558;&#19981;&#21516;&#38454;&#27573;&#30340;&#19977;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#8212;&#8212;&#36755;&#20837;&#12289;&#25552;&#31034;&#21644;&#36755;&#20986;&#36827;&#34892;&#20102;&#20998;&#31867;&#21644;&#25506;&#32034;&#65292;&#27599;&#31181;&#26041;&#27861;&#30456;&#23545;&#20110;&#27809;&#26377;&#27491;&#21017;&#21270;&#30340;&#27169;&#22411;&#22343;&#25552;&#20379;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16200v1 Announce Type: cross  Abstract: Effective information retrieval (IR) in settings with limited training data, particularly for complex queries, remains a challenging task. This paper introduces IR2, Information Regularization for Information Retrieval, a technique for reducing overfitting during synthetic data generation. This approach, representing a novel application of regularization techniques in synthetic data creation for IR, is tested on three recent IR tasks characterized by complex queries: DORIS-MAE, ArguAna, and WhatsThatBook. Experimental results indicate that our regularization techniques not only outperform previous synthetic query generation methods on the tasks considered but also reduce cost by up to 50%. Furthermore, this paper categorizes and explores three regularization methods at different stages of the query synthesis pipeline-input, prompt, and output-each offering varying degrees of performance improvement compared to models where no regulariz
&lt;/p&gt;</description></item></channel></rss>