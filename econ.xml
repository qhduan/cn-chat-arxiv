<rss version="2.0"><channel><title>Chat Arxiv econ</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for econ</description><item><title>&#22312;&#22810;&#20803;&#22238;&#24402;&#19981;&#36830;&#32493;&#35774;&#35745;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20803;&#23616;&#37096;&#22810;&#39033;&#24335;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#20803;&#35774;&#35745;&#24182;&#25429;&#25417;&#36793;&#30028;&#22788;&#30340;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#12290;</title><link>https://arxiv.org/abs/2402.08941</link><description>&lt;p&gt;
&#22810;&#20803;&#22238;&#24402;&#19981;&#36830;&#32493;&#35774;&#35745;&#30340;&#23616;&#37096;&#22810;&#39033;&#24335;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Local-Polynomial Estimation for Multivariate Regression Discontinuity Designs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08941
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#20803;&#22238;&#24402;&#19981;&#36830;&#32493;&#35774;&#35745;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20803;&#23616;&#37096;&#22810;&#39033;&#24335;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#20803;&#35774;&#35745;&#24182;&#25429;&#25417;&#36793;&#30028;&#22788;&#30340;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22810;&#20803;&#23616;&#37096;&#32447;&#24615;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#20803;&#22238;&#24402;&#19981;&#36830;&#32493;&#35774;&#35745;&#20013;&#30340;&#27835;&#30103;&#20998;&#37197;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20351;&#29992;&#20174;&#36793;&#30028;&#28857;&#21040;&#27431;&#27663;&#36317;&#31163;&#20316;&#20026;&#26631;&#37327;&#36816;&#34892;&#21464;&#37327;&#65292;&#22240;&#27492;&#22810;&#20803;&#35774;&#35745;&#34987;&#22788;&#29702;&#20026;&#21333;&#21464;&#37327;&#35774;&#35745;&#12290;&#28982;&#32780;&#65292;&#36317;&#31163;&#36816;&#34892;&#21464;&#37327;&#19982;&#28176;&#36817;&#26377;&#25928;&#24615;&#30340;&#20551;&#35774;&#19981;&#30456;&#23481;&#12290;&#25105;&#20204;&#23558;&#22810;&#20803;&#35774;&#35745;&#20316;&#20026;&#22810;&#20803;&#22788;&#29702;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#38024;&#23545;&#22810;&#20803;&#23616;&#37096;&#22810;&#39033;&#24335;&#20272;&#35745;&#22120;&#30340;&#26032;&#22411;&#28176;&#36817;&#27491;&#24120;&#24615;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#26159;&#28176;&#36817;&#26377;&#25928;&#30340;&#65292;&#24182;&#33021;&#25429;&#25417;&#36793;&#30028;&#22788;&#30340;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#22312;&#21733;&#20262;&#27604;&#20122;&#22870;&#23398;&#37329;&#30740;&#31350;&#20013;&#30340;&#23454;&#35777;&#35828;&#26126;&#25581;&#31034;&#20102;&#27835;&#30103;&#25928;&#24212;&#30340;&#26356;&#20016;&#23500;&#30340;&#24322;&#36136;&#24615;&#65288;&#21253;&#25324;&#20854;&#19981;&#23384;&#22312;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08941v1 Announce Type: new Abstract: We introduce a multivariate local-linear estimator for multivariate regression discontinuity designs in which treatment is assigned by crossing a boundary in the space of running variables. The dominant approach uses the Euclidean distance from a boundary point as the scalar running variable; hence, multivariate designs are handled as uni-variate designs. However, the distance running variable is incompatible with the assumption for asymptotic validity. We handle multivariate designs as multivariate. In this study, we develop a novel asymptotic normality for multivariate local-polynomial estimators. Our estimator is asymptotically valid and can capture heterogeneous treatment effects over the boundary. We demonstrate the effectiveness of our estimator through numerical simulations. Our empirical illustration of a Colombian scholarship study reveals a richer heterogeneity (including its absence) of the treatment effect that is hidden in th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#26410;&#26469;&#22870;&#21169;&#30340;&#20449;&#24687;&#26469;&#28608;&#21169;&#21162;&#21147;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#22312;&#27809;&#26377;&#36716;&#35753;&#30340;&#22996;&#25176;-&#20195;&#29702;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#20449;&#24687;&#31574;&#30053;&#65292;&#24182;&#30830;&#23450;&#20102;&#20004;&#20010;&#26465;&#20214;&#19979;&#30340;&#24310;&#36831;&#25259;&#38706;&#30340;&#20215;&#20540;&#12290;&#36825;&#20010;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#22996;&#25176;&#20154;&#23545;&#27604;&#20195;&#29702;&#20154;&#26356;&#19981;&#32784;&#24515;&#65292;&#25110;&#32773;&#22312;&#27809;&#26377;&#20449;&#24687;&#25259;&#38706;&#30340;&#24773;&#20917;&#19979;&#20195;&#29702;&#20154;&#30340;&#20449;&#24565;&#21576;&#29616;&#19979;&#38477;&#36235;&#21183;&#65292;&#24310;&#36831;&#25259;&#38706;&#26159;&#26377;&#30410;&#30340;&#12290;</title><link>http://arxiv.org/abs/2110.05643</link><description>&lt;p&gt;
&#29992;&#20851;&#20110;&#26410;&#26469;&#22870;&#21169;&#30340;&#20449;&#24687;&#28608;&#21169;&#21162;&#21147;
&lt;/p&gt;
&lt;p&gt;
Motivating Effort with Information about Future Rewards. (arXiv:2110.05643v3 [econ.TH] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.05643
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#26410;&#26469;&#22870;&#21169;&#30340;&#20449;&#24687;&#26469;&#28608;&#21169;&#21162;&#21147;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#22312;&#27809;&#26377;&#36716;&#35753;&#30340;&#22996;&#25176;-&#20195;&#29702;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#20449;&#24687;&#31574;&#30053;&#65292;&#24182;&#30830;&#23450;&#20102;&#20004;&#20010;&#26465;&#20214;&#19979;&#30340;&#24310;&#36831;&#25259;&#38706;&#30340;&#20215;&#20540;&#12290;&#36825;&#20010;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#22996;&#25176;&#20154;&#23545;&#27604;&#20195;&#29702;&#20154;&#26356;&#19981;&#32784;&#24515;&#65292;&#25110;&#32773;&#22312;&#27809;&#26377;&#20449;&#24687;&#25259;&#38706;&#30340;&#24773;&#20917;&#19979;&#20195;&#29702;&#20154;&#30340;&#20449;&#24565;&#21576;&#29616;&#19979;&#38477;&#36235;&#21183;&#65292;&#24310;&#36831;&#25259;&#38706;&#26159;&#26377;&#30410;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#36716;&#35753;&#30340;&#21160;&#24577;&#22996;&#25176;-&#20195;&#29702;&#27169;&#22411;&#20013;&#28608;&#21169;&#21162;&#21147;&#30340;&#26368;&#20339;&#26426;&#21046;&#12290;&#20195;&#29702;&#20154;&#21442;&#19982;&#19968;&#20010;&#26377;&#19981;&#30830;&#23450;&#26410;&#26469;&#22870;&#21169;&#30340;&#20219;&#21153;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#20219;&#20309;&#26102;&#20505;&#36827;&#34892;&#19981;&#21487;&#36870;&#30340;&#25512;&#21368;&#36131;&#20219;&#12290;&#22996;&#25176;&#20154;&#20102;&#35299;&#20219;&#21153;&#30340;&#22870;&#21169;&#65292;&#24182;&#26681;&#25454;&#26102;&#38388;&#21521;&#20195;&#29702;&#20154;&#25552;&#20379;&#20449;&#24687;&#20197;&#28608;&#21169;&#21162;&#21147;&#12290;&#25105;&#20204;&#20174;&#38381;&#24335;&#24418;&#24335;&#20013;&#25512;&#23548;&#20986;&#26368;&#20248;&#20449;&#24687;&#31574;&#30053;&#65292;&#24182;&#22240;&#27492;&#30830;&#23450;&#20102;&#20004;&#20010;&#26465;&#20214;&#65292;&#27599;&#20010;&#26465;&#20214;&#37117;&#20445;&#35777;&#20102;&#24310;&#36831;&#25259;&#38706;&#30340;&#20215;&#20540;&#12290;&#39318;&#20808;&#65292;&#22914;&#26524;&#22996;&#25176;&#20154;&#23545;&#27604;&#20195;&#29702;&#20154;&#26356;&#19981;&#32784;&#24515;&#65292;&#22905;&#26356;&#21916;&#27426;&#30001;&#24310;&#36831;&#25259;&#38706;&#24341;&#36215;&#30340;&#25552;&#21069;&#25237;&#20837;&#30340;&#21162;&#21147;&#35745;&#21010;&#12290;&#22312;&#31283;&#24577;&#29615;&#22659;&#19979;&#65292;&#21482;&#26377;&#24403;&#22996;&#25176;&#20154;&#27604;&#20195;&#29702;&#20154;&#26356;&#19981;&#32784;&#24515;&#26102;&#65292;&#24310;&#36831;&#25259;&#38706;&#25165;&#26159;&#26377;&#30410;&#30340;&#12290;&#20854;&#27425;&#65292;&#22914;&#26524;&#22312;&#27809;&#26377;&#20219;&#20309;&#20449;&#24687;&#25259;&#38706;&#30340;&#24773;&#20917;&#19979;&#29615;&#22659;&#20351;&#20195;&#29702;&#20154;&#36880;&#28176;&#21464;&#24471;&#24754;&#35266;&#65292;&#37027;&#20040;&#25552;&#20379;&#24310;&#36831;&#30340;&#28040;&#24687;&#21487;&#20197;&#25269;&#28040;&#20195;&#29702;&#20154;&#20449;&#24565;&#19979;&#38477;&#36235;&#21183;&#65292;&#24182;&#40723;&#21169;&#20195;&#29702;&#20154;&#24037;&#20316;&#26356;&#38271;&#26102;&#38388;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#32467;&#35770;&#26159;&#22312;&#19968;&#20010;&#38745;&#24577;&#29615;&#22659;&#19979;&#24471;&#20986;&#30340;&#65292;&#19988;&#20165;&#36866;&#29992;&#20110;&#29305;&#23450;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the optimal mechanism to motivate effort in a dynamic principal-agent model without transfers. An agent is engaged in a task with uncertain future rewards and can shirk irreversibly at any time. The principal knows the reward of the task and provides information to the agent over time in order to motivate effort. We derive the optimal information policy in closed form and thus identify two conditions, each of which guarantees that delayed disclosure is valuable. First, if the principal is impatient compared to the agent, she prefers the front-loaded effort schedule induced by delayed disclosure. In a stationary environment, delayed disclosure is beneficial if and only if the principal is less patient than the agent. Second, if the environment makes the agent become pessimistic over time in absence of any information disclosure, then providing delayed news can counteract this downward trend in the agent's belief and encourage the agent to work longer. Notably, the lev
&lt;/p&gt;</description></item></channel></rss>