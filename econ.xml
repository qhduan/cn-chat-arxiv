<rss version="2.0"><channel><title>Chat Arxiv econ</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for econ</description><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22996;&#25176;&#20154;&#36890;&#36807;&#38599;&#20323;&#20195;&#29702;&#20154;&#20197;&#21160;&#24577;&#26041;&#24335;&#33719;&#21462;&#20449;&#24687;&#30340;&#38382;&#39064;&#65292;&#22312;&#26465;&#20214;&#20801;&#35768;&#30340;&#24773;&#20917;&#19979;&#65292;&#22996;&#25176;&#20154;&#26080;&#27861;&#36890;&#36807;&#19968;&#27425;&#24615;&#25910;&#38598;&#25152;&#26377;&#20449;&#24687;&#20043;&#21518;&#20877;&#20174;&#20195;&#29702;&#20154;&#37027;&#37324;&#33719;&#21462;&#21333;&#20010;&#25253;&#21578;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#22312;&#36739;&#24378;&#30340;&#26465;&#20214;&#36829;&#21453;&#19979;&#65292;&#38745;&#24577;&#21512;&#21516;&#26159;&#27425;&#20248;&#30340;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#36824;&#23637;&#31034;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#65292;&#21363;&#20351;&#20195;&#29702;&#20154;&#23545;&#29366;&#24577;&#39044;&#27979;&#38169;&#35823;&#65292;&#26368;&#20248;&#21512;&#21516;&#20063;&#21487;&#33021;&#20250;&#32473;&#20104;&#20195;&#29702;&#20154;&#20005;&#26684;&#27491;&#30340;&#22522;&#26412;&#22870;&#21169;&#12290;</title><link>http://arxiv.org/abs/2310.19147</link><description>&lt;p&gt;
&#21160;&#24577;&#20449;&#24687;&#33719;&#21462;&#30340;&#26368;&#20339;&#35780;&#20998;
&lt;/p&gt;
&lt;p&gt;
Optimal Scoring for Dynamic Information Acquisition. (arXiv:2310.19147v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19147
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22996;&#25176;&#20154;&#36890;&#36807;&#38599;&#20323;&#20195;&#29702;&#20154;&#20197;&#21160;&#24577;&#26041;&#24335;&#33719;&#21462;&#20449;&#24687;&#30340;&#38382;&#39064;&#65292;&#22312;&#26465;&#20214;&#20801;&#35768;&#30340;&#24773;&#20917;&#19979;&#65292;&#22996;&#25176;&#20154;&#26080;&#27861;&#36890;&#36807;&#19968;&#27425;&#24615;&#25910;&#38598;&#25152;&#26377;&#20449;&#24687;&#20043;&#21518;&#20877;&#20174;&#20195;&#29702;&#20154;&#37027;&#37324;&#33719;&#21462;&#21333;&#20010;&#25253;&#21578;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#22312;&#36739;&#24378;&#30340;&#26465;&#20214;&#36829;&#21453;&#19979;&#65292;&#38745;&#24577;&#21512;&#21516;&#26159;&#27425;&#20248;&#30340;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#36824;&#23637;&#31034;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#65292;&#21363;&#20351;&#20195;&#29702;&#20154;&#23545;&#29366;&#24577;&#39044;&#27979;&#38169;&#35823;&#65292;&#26368;&#20248;&#21512;&#21516;&#20063;&#21487;&#33021;&#20250;&#32473;&#20104;&#20195;&#29702;&#20154;&#20005;&#26684;&#27491;&#30340;&#22522;&#26412;&#22870;&#21169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#22996;&#25176;&#20154;&#35797;&#22270;&#36890;&#36807;&#38599;&#20323;&#19968;&#20010;&#20195;&#29702;&#20154;&#26469;&#20351;&#29992;&#27850;&#26494;&#20449;&#24687;&#21040;&#36798;&#25216;&#26415;&#38543;&#30528;&#26102;&#38388;&#26469;&#33719;&#21462;&#20851;&#20110;&#20108;&#36827;&#21046;&#29366;&#24577;&#30340;&#20449;&#24687;&#12290;&#20195;&#29702;&#20154;&#20250;&#31169;&#19979;&#20102;&#35299;&#36825;&#20010;&#29366;&#24577;&#65292;&#32780;&#22996;&#25176;&#20154;&#26080;&#27861;&#35266;&#23519;&#21040;&#20195;&#29702;&#20154;&#30340;&#21162;&#21147;&#36873;&#25321;&#12290;&#22996;&#25176;&#20154;&#21487;&#20197;&#26681;&#25454;&#20195;&#29702;&#20154;&#30340;&#25253;&#21578;&#24207;&#21015;&#21644;&#23454;&#29616;&#30340;&#29366;&#24577;&#65292;&#20197;&#19968;&#20010;&#22266;&#23450;&#20215;&#20540;&#30340;&#22870;&#21697;&#26469;&#22870;&#21169;&#20195;&#29702;&#20154;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20123;&#26465;&#20214;&#65292;&#27599;&#20010;&#26465;&#20214;&#37117;&#30830;&#20445;&#22996;&#25176;&#20154;&#26080;&#27861;&#27604;&#22312;&#33719;&#21462;&#20102;&#25152;&#26377;&#20449;&#24687;&#21518;&#20174;&#20195;&#29702;&#20154;&#37027;&#37324;&#25552;&#21462;&#21333;&#20010;&#25253;&#21578;&#26356;&#22909;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#36825;&#20123;&#26465;&#20214;&#36275;&#22815;&#24378;&#28872;&#30340;&#36829;&#21453;&#19979;&#65292;&#36825;&#26679;&#30340;&#38745;&#24577;&#21512;&#21516;&#26159;&#27425;&#20248;&#30340;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#19982;&#20195;&#29702;&#20154;&#19968;&#27425;&#24615;&#33719;&#21462;&#25152;&#26377;&#20449;&#24687;&#30340;&#24773;&#20917;&#36827;&#34892;&#23545;&#27604;&#65307;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#65292;&#21363;&#20351;&#20195;&#29702;&#20154;&#23545;&#29366;&#24577;&#30340;&#39044;&#27979;&#26159;&#38169;&#35823;&#30340;&#65292;&#26368;&#20248;&#21512;&#21516;&#21487;&#33021;&#20250;&#21521;&#20195;&#29702;&#20154;&#25552;&#20379;&#20005;&#26684;&#27491;&#30340;&#22522;&#26412;&#22870;&#21169;&#12290;
&lt;/p&gt;
&lt;p&gt;
A principal seeks to learn about a binary state and can do so by enlisting an agent to acquire information over time using a Poisson information arrival technology. The agent learns about this state privately, and his effort choices are unobserved by the principal. The principal can reward the agent with a prize of fixed value as a function of the agent's sequence of reports and the realized state. We identify conditions that each individually ensure that the principal cannot do better than by eliciting a single report from the agent after all information has been acquired. We also show that such a static contract is suboptimal under sufficiently strong violations of these conditions. We contrast our solution to the case where the agent acquires information "all at once;" notably, the optimal contract in the dynamic environment may provide strictly positive base rewards to the agent even if his prediction about the state is incorrect.
&lt;/p&gt;</description></item></channel></rss>