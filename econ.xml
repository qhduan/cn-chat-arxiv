<rss version="2.0"><channel><title>Chat Arxiv econ</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for econ</description><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#23398;&#26657;&#29677;&#32423;&#20998;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#21451;&#35850;&#39044;&#27979;&#12289;&#21516;&#20394;&#24433;&#21709;&#20272;&#35745;&#21644;&#29677;&#32423;&#20998;&#37197;&#20248;&#21270;&#65292;&#21457;&#29616;&#23558;&#23398;&#29983;&#20998;&#25104;&#26377;&#24615;&#21035;&#29305;&#24449;&#30340;&#29677;&#32423;&#33021;&#22815;&#25552;&#39640;&#24179;&#22343;&#21516;&#20394;&#24433;&#21709;&#65292;&#24182;&#19988;&#26497;&#31471;&#28151;&#21512;&#30340;&#29677;&#32423;&#20998;&#37197;&#26041;&#27861;&#21487;&#20197;&#25913;&#21892;&#24213;&#37096;&#22235;&#20998;&#20043;&#19968;&#23398;&#29983;&#30340;&#21516;&#20394;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2404.02497</link><description>&lt;p&gt;
&#29992;&#26426;&#22120;&#23398;&#20064;&#25552;&#21319;&#25945;&#32946;&#25104;&#26524;&#65306;&#24314;&#27169;&#21451;&#35850;&#24418;&#25104;&#65292;&#34913;&#37327;&#21516;&#20394;&#24433;&#21709;&#21644;&#20248;&#21270;&#29677;&#32423;&#20998;&#37197;
&lt;/p&gt;
&lt;p&gt;
Enhancing Educational Outcome with Machine Learning: Modeling Friendship Formation, Measuring Peer Effect and Optimizing Class Assignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02497
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#23398;&#26657;&#29677;&#32423;&#20998;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#21451;&#35850;&#39044;&#27979;&#12289;&#21516;&#20394;&#24433;&#21709;&#20272;&#35745;&#21644;&#29677;&#32423;&#20998;&#37197;&#20248;&#21270;&#65292;&#21457;&#29616;&#23558;&#23398;&#29983;&#20998;&#25104;&#26377;&#24615;&#21035;&#29305;&#24449;&#30340;&#29677;&#32423;&#33021;&#22815;&#25552;&#39640;&#24179;&#22343;&#21516;&#20394;&#24433;&#21709;&#65292;&#24182;&#19988;&#26497;&#31471;&#28151;&#21512;&#30340;&#29677;&#32423;&#20998;&#37197;&#26041;&#27861;&#21487;&#20197;&#25913;&#21892;&#24213;&#37096;&#22235;&#20998;&#20043;&#19968;&#23398;&#29983;&#30340;&#21516;&#20394;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23398;&#26657;&#26657;&#38271;&#30340;&#29677;&#32423;&#20998;&#37197;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#20998;&#20026;&#19977;&#20010;&#38454;&#27573;&#65306;&#21451;&#35850;&#39044;&#27979;&#12289;&#21516;&#20394;&#24433;&#21709;&#35780;&#20272;&#21644;&#29677;&#32423;&#20998;&#37197;&#20248;&#21270;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#24494;&#35266;&#22522;&#30784;&#27169;&#22411;&#26469;&#27169;&#25311;&#21451;&#35850;&#24418;&#25104;&#65292;&#24182;&#23558;&#35813;&#27169;&#22411;&#36924;&#36817;&#20026;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#21033;&#29992;&#39044;&#27979;&#30340;&#21451;&#35850;&#27010;&#29575;&#37051;&#25509;&#30697;&#38453;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#20256;&#32479;&#30340;&#32447;&#24615;&#22343;&#20540;&#27169;&#22411;&#24182;&#20272;&#35745;&#20102;&#21516;&#20394;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#20197;&#35299;&#20915;&#21451;&#35850;&#36873;&#25321;&#30340;&#20869;&#29983;&#24615;&#38382;&#39064;&#12290;&#20272;&#35745;&#30340;&#21516;&#20394;&#24433;&#21709;&#30053;&#22823;&#20110;&#32447;&#24615;&#22343;&#20540;&#27169;&#22411;&#30340;&#20272;&#35745;&#12290;&#21033;&#29992;&#21451;&#35850;&#39044;&#27979;&#21644;&#21516;&#20394;&#24433;&#21709;&#20272;&#35745;&#32467;&#26524;&#65292;&#25105;&#20204;&#27169;&#25311;&#20102;&#25152;&#26377;&#23398;&#29983;&#30340;&#21453;&#20107;&#23454;&#21516;&#20394;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#23558;&#23398;&#29983;&#20998;&#25104;&#26377;&#24615;&#21035;&#29305;&#24449;&#30340;&#29677;&#32423;&#21487;&#20197;&#23558;&#24179;&#22343;&#21516;&#20394;&#24433;&#21709;&#25552;&#39640;0.02&#20998;&#65288;&#22312;5&#20998;&#21046;&#20013;&#65289;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#26497;&#31471;&#28151;&#21512;&#30340;&#29677;&#32423;&#20998;&#37197;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#24213;&#37096;&#22235;&#20998;&#20043;&#19968;&#23398;&#29983;&#30340;&#21516;&#20394;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02497v1 Announce Type: new  Abstract: In this paper, we look at a school principal's class assignment problem. We break the problem into three stages (1) friendship prediction (2) peer effect estimation (3) class assignment optimization. We build a micro-founded model for friendship formation and approximate the model as a neural network. Leveraging on the predicted friendship probability adjacent matrix, we improve the traditional linear-in-means model and estimate peer effect. We propose a new instrument to address the friendship selection endogeneity. The estimated peer effect is slightly larger than the linear-in-means model estimate. Using the friendship prediction and peer effect estimation results, we simulate counterfactual peer effects for all students. We find that dividing students into gendered classrooms increases average peer effect by 0.02 point on a scale of 5. We also find that extreme mixing class assignment method improves bottom quartile students' peer ef
&lt;/p&gt;</description></item><item><title>&#20449;&#24687;&#25552;&#20379;&#23454;&#39564;&#29992;&#20110;&#30830;&#23450;&#20449;&#24565;&#22914;&#20309;&#22240;&#26524;&#22320;&#24433;&#21709;&#20915;&#31574;&#21644;&#34892;&#20026;&#12290;&#36890;&#36807;&#24212;&#29992;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#20934;&#30830;&#35782;&#21035;&#20986;&#65288;&#38750;&#21152;&#26435;&#30340;&#65289;&#24179;&#22343;&#37096;&#20998;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2309.11387</link><description>&lt;p&gt;
&#20449;&#24687;&#25552;&#20379;&#23454;&#39564;&#20013;&#30340;&#22240;&#26524;&#25928;&#24212;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Identifying Causal Effects in Information Provision Experiments. (arXiv:2309.11387v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11387
&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#25552;&#20379;&#23454;&#39564;&#29992;&#20110;&#30830;&#23450;&#20449;&#24565;&#22914;&#20309;&#22240;&#26524;&#22320;&#24433;&#21709;&#20915;&#31574;&#21644;&#34892;&#20026;&#12290;&#36890;&#36807;&#24212;&#29992;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#20934;&#30830;&#35782;&#21035;&#20986;&#65288;&#38750;&#21152;&#26435;&#30340;&#65289;&#24179;&#22343;&#37096;&#20998;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#25552;&#20379;&#23454;&#39564;&#26159;&#19968;&#31181;&#36234;&#26469;&#36234;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#30830;&#23450;&#20449;&#24565;&#22914;&#20309;&#22240;&#26524;&#22320;&#24433;&#21709;&#20915;&#31574;&#21644;&#34892;&#20026;&#12290;&#22312;&#22522;&#20110;&#36127;&#25285;&#20449;&#24687;&#33719;&#21462;&#30340;&#31616;&#21333;&#36125;&#21494;&#26031;&#20449;&#24565;&#24418;&#25104;&#27169;&#22411;&#20013;&#65292;&#24403;&#36825;&#20123;&#20449;&#24565;&#23545;&#20182;&#20204;&#30340;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#26102;&#65292;&#20154;&#20204;&#24418;&#25104;&#31934;&#30830;&#30340;&#20449;&#24565;&#12290;&#20808;&#21069;&#20449;&#24565;&#30340;&#31934;&#30830;&#24230;&#25511;&#21046;&#30528;&#24403;&#20182;&#20204;&#25509;&#21463;&#26032;&#20449;&#24687;&#26102;&#20182;&#20204;&#30340;&#20449;&#24565;&#21464;&#21270;&#31243;&#24230;&#65288;&#21363;&#31532;&#19968;&#38454;&#27573;&#30340;&#24378;&#24230;&#65289;&#12290;&#30001;&#20110;&#20004;&#38454;&#27573;&#26368;&#23567;&#20108;&#20056;&#27861;&#65288;TSLS&#65289;&#20197;&#26435;&#37325;&#19982;&#31532;&#19968;&#38454;&#27573;&#30340;&#24378;&#24230;&#25104;&#27604;&#20363;&#30340;&#21152;&#26435;&#24179;&#22343;&#20026;&#30446;&#26631;&#65292;TSLS&#20250;&#36807;&#24230;&#21152;&#26435;&#20855;&#26377;&#36739;&#23567;&#22240;&#26524;&#25928;&#24212;&#30340;&#20010;&#20307;&#65292;&#24182;&#20302;&#20272;&#20855;&#26377;&#36739;&#22823;&#25928;&#24212;&#30340;&#20010;&#20307;&#65292;&#20174;&#32780;&#20302;&#20272;&#20102;&#20449;&#24565;&#23545;&#34892;&#20026;&#30340;&#24179;&#22343;&#37096;&#20998;&#25928;&#24212;&#12290;&#22312;&#25152;&#26377;&#21442;&#19982;&#32773;&#37117;&#25509;&#21463;&#26032;&#20449;&#24687;&#30340;&#23454;&#39564;&#35774;&#35745;&#20013;&#65292;&#36125;&#21494;&#26031;&#26356;&#26032;&#24847;&#21619;&#30528;&#21487;&#20197;&#20351;&#29992;&#25511;&#21046;&#20989;&#25968;&#26469;&#30830;&#23450;&#65288;&#38750;&#21152;&#26435;&#30340;&#65289;&#24179;&#22343;&#37096;&#20998;&#25928;&#24212;&#12290;&#25105;&#23558;&#36825;&#20010;&#20272;&#35745;&#22120;&#24212;&#29992;&#20110;&#26368;&#36817;&#19968;&#39033;&#20851;&#20110;&#25928;&#24212;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information provision experiments are an increasingly popular tool to identify how beliefs causally affect decision-making and behavior. In a simple Bayesian model of belief formation via costly information acquisition, people form precise beliefs when these beliefs are important for their decision-making. The precision of prior beliefs controls how much their beliefs shift when they are shown new information (i.e., the strength of the first stage). Since two-stage least squares (TSLS) targets a weighted average with weights proportional to the strength of the first stage, TSLS will overweight individuals with smaller causal effects and underweight those with larger effects, thus understating the average partial effect of beliefs on behavior. In experimental designs where all participants are exposed to new information, Bayesian updating implies that a control function can be used to identify the (unweighted) average partial effect. I apply this estimator to a recent study of the effec
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#27454;&#21517;&#20026; Torch-Choice &#30340; PyTorch &#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#31649;&#29702;&#25968;&#25454;&#24211;&#12289;&#26500;&#24314;&#22810;&#39033;&#24335;Logit&#21644;&#23884;&#22871;Logit&#27169;&#22411;&#65292;&#24182;&#25903;&#25345;GPU&#21152;&#36895;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.01906</link><description>&lt;p&gt;
Torch-Choice: &#29992;Python&#23454;&#29616;&#22823;&#35268;&#27169;&#36873;&#25321;&#24314;&#27169;&#30340;PyTorch&#21253;
&lt;/p&gt;
&lt;p&gt;
Torch-Choice: A PyTorch Package for Large-Scale Choice Modelling with Python. (arXiv:2304.01906v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#27454;&#21517;&#20026; Torch-Choice &#30340; PyTorch &#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#31649;&#29702;&#25968;&#25454;&#24211;&#12289;&#26500;&#24314;&#22810;&#39033;&#24335;Logit&#21644;&#23884;&#22871;Logit&#27169;&#22411;&#65292;&#24182;&#25903;&#25345;GPU&#21152;&#36895;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
$\texttt{torch-choice}$ &#26159;&#19968;&#27454;&#24320;&#28304;&#36719;&#20214;&#21253;&#65292;&#20351;&#29992;Python&#21644;PyTorch&#23454;&#29616;&#28789;&#27963;&#12289;&#24555;&#36895;&#30340;&#36873;&#25321;&#24314;&#27169;&#12290;&#23427;&#25552;&#20379;&#20102; $\texttt{ChoiceDataset}$ &#25968;&#25454;&#32467;&#26500;&#65292;&#20197;&#20415;&#28789;&#27963;&#32780;&#39640;&#25928;&#22320;&#31649;&#29702;&#25968;&#25454;&#24211;&#12290;&#26412;&#25991;&#28436;&#31034;&#20102;&#22914;&#20309;&#20174;&#21508;&#31181;&#26684;&#24335;&#30340;&#25968;&#25454;&#24211;&#20013;&#26500;&#24314; $\texttt{ChoiceDataset}$&#65292;&#24182;&#23637;&#31034;&#20102; $\texttt{ChoiceDataset}$ &#30340;&#21508;&#31181;&#21151;&#33021;&#12290;&#35813;&#36719;&#20214;&#21253;&#23454;&#29616;&#20102;&#20004;&#31181;&#24120;&#29992;&#30340;&#27169;&#22411;: &#22810;&#39033;&#24335;Logit&#21644;&#23884;&#22871;Logit&#27169;&#22411;&#65292;&#24182;&#25903;&#25345;&#27169;&#22411;&#20272;&#35745;&#26399;&#38388;&#30340;&#27491;&#21017;&#21270;&#12290;&#35813;&#36719;&#20214;&#21253;&#36824;&#25903;&#25345;&#20351;&#29992;GPU&#36827;&#34892;&#20272;&#35745;&#65292;&#20351;&#20854;&#21487;&#20197;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#32780;&#19988;&#22312;&#35745;&#31639;&#19978;&#26356;&#39640;&#25928;&#12290;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;R&#39118;&#26684;&#30340;&#20844;&#24335;&#23383;&#31526;&#20018;&#25110;Python&#23383;&#20856;&#36827;&#34892;&#21021;&#22987;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102; $\texttt{torch-choice}$ &#21644; R&#20013;&#30340; $\texttt{mlogit}$ &#22312;&#20197;&#19979;&#20960;&#20010;&#26041;&#38754;&#30340;&#35745;&#31639;&#25928;&#29575;: (1) &#35266;&#27979;&#25968;&#22686;&#21152;&#26102;&#65292;(2) &#21327;&#21464;&#37327;&#20010;&#25968;&#22686;&#21152;&#26102;&#65292; (3) &#27979;&#35797;&#25968;&#21319;&#39640;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
The $\texttt{torch-choice}$ is an open-source library for flexible, fast choice modeling with Python and PyTorch. $\texttt{torch-choice}$ provides a $\texttt{ChoiceDataset}$ data structure to manage databases flexibly and memory-efficiently. The paper demonstrates constructing a $\texttt{ChoiceDataset}$ from databases of various formats and functionalities of $\texttt{ChoiceDataset}$. The package implements two widely used models, namely the multinomial logit and nested logit models, and supports regularization during model estimation. The package incorporates the option to take advantage of GPUs for estimation, allowing it to scale to massive datasets while being computationally efficient. Models can be initialized using either R-style formula strings or Python dictionaries. We conclude with a comparison of the computational efficiencies of $\texttt{torch-choice}$ and $\texttt{mlogit}$ in R as (1) the number of observations increases, (2) the number of covariates increases, and (3) th
&lt;/p&gt;</description></item></channel></rss>