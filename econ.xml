<rss version="2.0"><channel><title>Chat Arxiv econ</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for econ</description><item><title>&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#21152;&#26435;Lasso&#20272;&#35745;&#22120;&#65292;&#35299;&#20915;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#35843;&#21442;&#36873;&#25321;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.06657</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#35843;&#21442;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Data-Driven Tuning Parameter Selection for High-Dimensional Vector Autoregressions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06657
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#21152;&#26435;Lasso&#20272;&#35745;&#22120;&#65292;&#35299;&#20915;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#35843;&#21442;&#36873;&#25321;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lasso&#31867;&#22411;&#30340;&#20272;&#35745;&#22120;&#36890;&#24120;&#29992;&#20110;&#20272;&#35745;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#12290;Lasso&#30340;&#29702;&#35770;&#20445;&#35777;&#36890;&#24120;&#35201;&#27714;&#36873;&#25321;&#21512;&#36866;&#30340;&#24809;&#32602;&#27700;&#24179;&#65292;&#36825;&#36890;&#24120;&#21462;&#20915;&#20110;&#26410;&#30693;&#30340;&#24635;&#20307;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#24471;&#21040;&#30340;&#20272;&#35745;&#20540;&#21644;&#27169;&#22411;&#20013;&#20445;&#30041;&#30340;&#21464;&#37327;&#25968;&#37327;&#20851;&#38190;&#21462;&#20915;&#20110;&#25152;&#36873;&#25321;&#30340;&#24809;&#32602;&#27700;&#24179;&#12290;&#30446;&#21069;&#65292;&#22312;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#30340;&#24773;&#20917;&#19979;&#27809;&#26377;&#29702;&#35770;&#19978;&#30340;&#25351;&#23548;&#26469;&#20570;&#36825;&#20010;&#36873;&#25321;&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#20063;&#35768;&#26159;&#26368;&#24120;&#29992;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20043;&#19968;&#65292;&#32447;&#24615;&#21521;&#37327;&#33258;&#22238;&#24402;&#65288;VAR&#65289;&#27169;&#22411;&#30340;&#20272;&#35745;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#26041;&#24335;&#36873;&#25321;&#24809;&#32602;&#30340;&#21152;&#26435;Lasso&#20272;&#35745;&#37327;&#12290;&#25105;&#20204;&#20026;&#36825;&#19968;&#26041;&#27861;&#24314;&#31435;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06657v1 Announce Type: new  Abstract: Lasso-type estimators are routinely used to estimate high-dimensional time series models. The theoretical guarantees established for Lasso typically require the penalty level to be chosen in a suitable fashion often depending on unknown population quantities. Furthermore, the resulting estimates and the number of variables retained in the model depend crucially on the chosen penalty level. However, there is currently no theoretically founded guidance for this choice in the context of high-dimensional time series. Instead one resorts to selecting the penalty level in an ad hoc manner using, e.g., information criteria or cross-validation. We resolve this problem by considering estimation of the perhaps most commonly employed multivariate time series model, the linear vector autoregressive (VAR) model, and propose a weighted Lasso estimator with penalization chosen in a fully data-driven way. The theoretical guarantees that we establish for
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#22312;&#26377;&#38480;&#20449;&#24687;&#26465;&#20214;&#19979;&#23398;&#20064;&#22914;&#20309;&#21033;&#29992;&#19981;&#21516;&#25237;&#31080;&#26041;&#27861;&#36827;&#34892;&#25805;&#32437;&#65292;&#21457;&#29616;&#26576;&#20123;&#25237;&#31080;&#26041;&#27861;&#22312;&#26377;&#38480;&#20449;&#24687;&#19979;&#23481;&#26131;&#34987;&#25805;&#32437;&#65292;&#32780;&#20854;&#20182;&#26041;&#27861;&#19981;&#23481;&#26131;&#34987;&#25805;&#32437;&#12290;</title><link>http://arxiv.org/abs/2401.16412</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#26377;&#38480;&#20449;&#24687;&#19979;&#36827;&#34892;&#25805;&#32437;
&lt;/p&gt;
&lt;p&gt;
Learning to Manipulate under Limited Information. (arXiv:2401.16412v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#22312;&#26377;&#38480;&#20449;&#24687;&#26465;&#20214;&#19979;&#23398;&#20064;&#22914;&#20309;&#21033;&#29992;&#19981;&#21516;&#25237;&#31080;&#26041;&#27861;&#36827;&#34892;&#25805;&#32437;&#65292;&#21457;&#29616;&#26576;&#20123;&#25237;&#31080;&#26041;&#27861;&#22312;&#26377;&#38480;&#20449;&#24687;&#19979;&#23481;&#26131;&#34987;&#25805;&#32437;&#65292;&#32780;&#20854;&#20182;&#26041;&#27861;&#19981;&#23481;&#26131;&#34987;&#25805;&#32437;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26681;&#25454;&#31038;&#20250;&#36873;&#25321;&#29702;&#35770;&#30340;&#32463;&#20856;&#32467;&#26524;&#65292;&#20219;&#20309;&#21512;&#29702;&#30340;&#20559;&#22909;&#25237;&#31080;&#26041;&#27861;&#26377;&#26102;&#20250;&#32473;&#20010;&#20307;&#25552;&#20379;&#25253;&#21578;&#19981;&#30495;&#23454;&#20559;&#22909;&#30340;&#28608;&#21169;&#12290;&#23545;&#20110;&#27604;&#36739;&#25237;&#31080;&#26041;&#27861;&#26469;&#35828;&#65292;&#19981;&#21516;&#25237;&#31080;&#26041;&#27861;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#26356;&#25110;&#32773;&#26356;&#23569;&#25269;&#25239;&#36825;&#31181;&#31574;&#30053;&#24615;&#25805;&#32437;&#24050;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#32771;&#34385;&#22240;&#32032;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#21516;&#35268;&#27169;&#19979;&#23545;&#38480;&#21046;&#20449;&#24687;&#19979;&#23398;&#20064;&#22914;&#20309;&#21033;&#29992;&#32473;&#23450;&#25237;&#31080;&#26041;&#27861;&#36827;&#34892;&#25805;&#32437;&#30340;&#25104;&#21151;&#31243;&#24230;&#26469;&#34913;&#37327;&#25805;&#32437;&#30340;&#25269;&#25239;&#21147;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;&#23558;&#36817;40,000&#20010;&#19981;&#21516;&#35268;&#27169;&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#23545;&#25239;8&#31181;&#19981;&#21516;&#30340;&#25237;&#31080;&#26041;&#27861;&#65292;&#22312;6&#31181;&#38480;&#21046;&#20449;&#24687;&#24773;&#20917;&#19979;&#65292;&#36827;&#34892;&#21253;&#21547;5-21&#21517;&#36873;&#27665;&#21644;3-6&#21517;&#20505;&#36873;&#20154;&#30340;&#22996;&#21592;&#20250;&#35268;&#27169;&#36873;&#20030;&#30340;&#25805;&#32437;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#19968;&#20123;&#25237;&#31080;&#26041;&#27861;&#65292;&#22914;Borda&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#20449;&#24687;&#19979;&#21487;&#20197;&#34987;&#31070;&#32463;&#32593;&#32476;&#39640;&#24230;&#25805;&#32437;&#65292;&#32780;&#20854;&#20182;&#26041;&#27861;&#65292;&#22914;Instant Runoff&#26041;&#27861;&#65292;&#34429;&#28982;&#34987;&#19968;&#20010;&#29702;&#24819;&#30340;&#25805;&#32437;&#32773;&#21033;&#28070;&#21270;&#25805;&#32437;&#65292;&#20294;&#22312;&#26377;&#38480;&#20449;&#24687;&#19979;&#19981;&#20250;&#21463;&#21040;&#25805;&#32437;&#12290;
&lt;/p&gt;
&lt;p&gt;
By classic results in social choice theory, any reasonable preferential voting method sometimes gives individuals an incentive to report an insincere preference. The extent to which different voting methods are more or less resistant to such strategic manipulation has become a key consideration for comparing voting methods. Here we measure resistance to manipulation by whether neural networks of varying sizes can learn to profitably manipulate a given voting method in expectation, given different types of limited information about how other voters will vote. We trained nearly 40,000 neural networks of 26 sizes to manipulate against 8 different voting methods, under 6 types of limited information, in committee-sized elections with 5-21 voters and 3-6 candidates. We find that some voting methods, such as Borda, are highly manipulable by networks with limited information, while others, such as Instant Runoff, are not, despite being quite profitably manipulated by an ideal manipulator with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26041;&#27861;&#26469;&#20998;&#26512;&#20108;&#12289;&#19977;&#24230;&#20215;&#26684;&#27495;&#35270;&#30340;&#31119;&#21033;&#24433;&#21709;&#12290;&#36890;&#36807;&#36873;&#25321;&#29305;&#23450;&#30340;&#20998;&#21106;&#26041;&#24335;&#65292;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#30340;&#31119;&#21033;&#32467;&#26524;&#65292;&#24182;&#19988;&#20998;&#26512;&#20102;&#20998;&#21106;&#23545;&#28040;&#36153;&#32773;&#21097;&#20313;&#21644;&#20215;&#26684;&#30340;&#24433;&#21709;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#31639;&#27861;&#26469;&#35745;&#31639;&#20998;&#21106;&#12290;</title><link>http://arxiv.org/abs/2401.12366</link><description>&lt;p&gt;
&#20108;&#12289;&#19977;&#24230;&#20215;&#26684;&#27495;&#35270;&#30340;&#32479;&#19968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Unified Approach to Second and Third Degree Price Discrimination. (arXiv:2401.12366v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26041;&#27861;&#26469;&#20998;&#26512;&#20108;&#12289;&#19977;&#24230;&#20215;&#26684;&#27495;&#35270;&#30340;&#31119;&#21033;&#24433;&#21709;&#12290;&#36890;&#36807;&#36873;&#25321;&#29305;&#23450;&#30340;&#20998;&#21106;&#26041;&#24335;&#65292;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#30340;&#31119;&#21033;&#32467;&#26524;&#65292;&#24182;&#19988;&#20998;&#26512;&#20102;&#20998;&#21106;&#23545;&#28040;&#36153;&#32773;&#21097;&#20313;&#21644;&#20215;&#26684;&#30340;&#24433;&#21709;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#31639;&#27861;&#26469;&#35745;&#31639;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#20010;&#33021;&#22815;&#23545;&#22810;&#20135;&#21697;&#24066;&#22330;&#36827;&#34892;&#20998;&#21106;&#24182;&#22312;&#27599;&#20010;&#20998;&#21106;&#20013;&#25552;&#20379;&#24046;&#24322;&#21270;&#20215;&#26684;&#33756;&#21333;&#30340;&#22404;&#26029;&#32773;&#30340;&#31119;&#21033;&#24433;&#21709;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#32452;&#26497;&#31471;&#20998;&#24067;&#65292;&#36890;&#36807;&#20174;&#36825;&#20123;&#20998;&#24067;&#20869;&#36873;&#25321;&#20998;&#21106;&#65292;&#21487;&#20197;&#36798;&#21040;&#25152;&#26377;&#21487;&#34892;&#30340;&#31119;&#21033;&#32467;&#26524;&#12290;&#36825;&#20010;&#20998;&#24067;&#26063;&#26159;&#23545;&#22810;&#21830;&#21697;&#24066;&#22330;&#20013;&#28040;&#36153;&#32773;&#26368;&#22823;&#21270;&#20215;&#20540;&#20998;&#24067;&#30340;&#35299;&#20915;&#26041;&#26696;&#20135;&#29983;&#30340;&#12290;&#26681;&#25454;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20998;&#21106;&#23545;&#28040;&#36153;&#32773;&#21097;&#20313;&#21644;&#20215;&#26684;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#23384;&#22312;&#20351;&#25152;&#26377;&#28040;&#36153;&#32773;&#21463;&#30410;&#30340;&#20998;&#21106;&#30340;&#26465;&#20214;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the welfare impact of a monopolist able to segment a multiproduct market and offer differentiated price menus within each segment. We characterize a family of extremal distributions such that all achievable welfare outcomes can be reached by selecting segments from within these distributions. This family of distributions arises as the solution to the consumer maximizing distribution of values for multigood markets. With these results, we analyze the effect of segmentation on consumer surplus and prices in both interior and extremal markets, including conditions under which there exists a segmentation benefiting all consumers. Finally, we present an efficient algorithm for computing segmentations.
&lt;/p&gt;</description></item></channel></rss>