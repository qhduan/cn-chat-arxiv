<rss version="2.0"><channel><title>Chat Arxiv q-fin</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-fin</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#23545;&#39057;&#29575;-&#20005;&#37325;&#24615;&#20445;&#38505;&#23450;&#20215;&#36827;&#34892;&#20102;&#22522;&#20934;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#19981;&#21516;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;(CANN)&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.12671</link><description>&lt;p&gt;
&#21033;&#29992;&#39057;&#29575;&#21644;&#20005;&#37325;&#24615;&#25968;&#25454;&#36827;&#34892;&#20445;&#38505;&#23450;&#20215;&#30340;&#31070;&#32463;&#32593;&#32476;&#65306;&#20174;&#25968;&#25454;&#39044;&#22788;&#29702;&#21040;&#25216;&#26415;&#23450;&#20215;&#30340;&#22522;&#20934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Neural networks for insurance pricing with frequency and severity data: a benchmark study from data preprocessing to technical tariff. (arXiv:2310.12671v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#23545;&#39057;&#29575;-&#20005;&#37325;&#24615;&#20445;&#38505;&#23450;&#20215;&#36827;&#34892;&#20102;&#22522;&#20934;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#19981;&#21516;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;(CANN)&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20445;&#38505;&#20844;&#21496;&#36890;&#24120;&#20351;&#29992;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#26469;&#24314;&#27169;&#32034;&#36180;&#30340;&#39057;&#29575;&#21644;&#20005;&#37325;&#24615;&#25968;&#25454;&#12290;&#30001;&#20110;&#20854;&#22312;&#20854;&#20182;&#39046;&#22495;&#30340;&#25104;&#21151;&#65292;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#31934;&#31639;&#24037;&#20855;&#31665;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#26412;&#25991;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#20026;&#39057;&#29575;-&#20005;&#37325;&#24615;&#20445;&#38505;&#23450;&#20215;&#19982;&#26426;&#22120;&#23398;&#20064;&#30456;&#20851;&#30340;&#25991;&#29486;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#20445;&#38505;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22522;&#20934;&#30740;&#31350;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#21253;&#21547;&#26377;&#22810;&#31181;&#31867;&#22411;&#30340;&#36755;&#20837;&#29305;&#24449;&#21644;&#39057;&#29575;-&#20005;&#37325;&#24615;&#30446;&#26631;&#12290;&#25105;&#20204;&#35814;&#32454;&#27604;&#36739;&#20102;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#22312;&#20998;&#31665;&#36755;&#20837;&#25968;&#25454;&#12289;&#26799;&#24230;&#25552;&#21319;&#26641;&#27169;&#22411;&#12289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFNN&#65289;&#21644;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;&#65288;CANN&#65289;&#19978;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;CANN&#23558;&#36890;&#36807;GLM&#21644;GBM&#20998;&#21035;&#24314;&#31435;&#30340;&#22522;&#32447;&#39044;&#27979;&#19982;&#31070;&#32463;&#32593;&#32476;&#26657;&#27491;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#25968;&#25454;&#39044;&#22788;&#29702;&#27493;&#39588;&#65292;&#29305;&#21035;&#20851;&#27880;&#36890;&#24120;&#23384;&#22312;&#20110;&#34920;&#26684;&#20445;&#38505;&#25968;&#25454;&#38598;&#20013;&#30340;&#22810;&#31181;&#31867;&#22411;&#30340;&#36755;&#20837;&#29305;&#24449;&#65292;&#27604;&#22914;&#37038;&#32534;&#21644;&#25968;&#23383;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Insurers usually turn to generalized linear models for modelling claim frequency and severity data. Due to their success in other fields, machine learning techniques are gaining popularity within the actuarial toolbox. Our paper contributes to the literature on frequency-severity insurance pricing with machine learning via deep learning structures. We present a benchmark study on four insurance data sets with frequency and severity targets in the presence of multiple types of input features. We compare in detail the performance of: a generalized linear model on binned input data, a gradient-boosted tree model, a feed-forward neural network (FFNN), and the combined actuarial neural network (CANN). Our CANNs combine a baseline prediction established with a GLM and GBM, respectively, with a neural network correction. We explain the data preprocessing steps with specific focus on the multiple types of input features typically present in tabular insurance data sets, such as postal codes, nu
&lt;/p&gt;</description></item></channel></rss>