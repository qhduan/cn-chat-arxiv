<rss version="2.0"><channel><title>Chat Arxiv q-fin</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-fin</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31639;&#27861;&#23450;&#20215;&#20195;&#29702;&#22312;&#23521;&#22836;&#24066;&#22330;&#29615;&#22659;&#20013;&#33258;&#20027;&#21246;&#32467;&#65292;&#23545;&#28040;&#36153;&#32773;&#21033;&#30410;&#26377;&#23475;&#65292;&#20854;&#35828;&#26126;&#20070;&#20013;&#30340;&#30701;&#35821;&#21464;&#21270;&#21487;&#33021;&#22686;&#21152;&#21246;&#32467;&#12290;</title><link>https://arxiv.org/abs/2404.00806</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31639;&#27861;&#21246;&#32467;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Collusion by Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00806
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31639;&#27861;&#23450;&#20215;&#20195;&#29702;&#22312;&#23521;&#22836;&#24066;&#22330;&#29615;&#22659;&#20013;&#33258;&#20027;&#21246;&#32467;&#65292;&#23545;&#28040;&#36153;&#32773;&#21033;&#30410;&#26377;&#23475;&#65292;&#20854;&#35828;&#26126;&#20070;&#20013;&#30340;&#30701;&#35821;&#21464;&#21270;&#21487;&#33021;&#22686;&#21152;&#21246;&#32467;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00806v1 &#20844;&#21578;&#31867;&#22411;:&#20132;&#21449;&#25688;&#35201;:&#31639;&#27861;&#23450;&#20215;&#30340;&#20852;&#36215;&#24341;&#36215;&#20102;&#23545;&#31639;&#27861;&#21246;&#32467;&#30340;&#25285;&#24551;&#12290;&#25105;&#20204;&#23545;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29305;&#21035;&#26159;GPT-4&#30340;&#31639;&#27861;&#23450;&#20215;&#20195;&#29702;&#36827;&#34892;&#23454;&#39564;&#12290;&#25105;&#20204;&#21457;&#29616;&#65306;&#65288;1&#65289;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#22312;&#23450;&#20215;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#65288;2&#65289;&#22522;&#20110;LLM&#30340;&#23450;&#20215;&#20195;&#29702;&#22312;&#23521;&#22836;&#24066;&#22330;&#29615;&#22659;&#20013;&#33258;&#20027;&#21246;&#32467;&#65292;&#25439;&#23475;&#28040;&#36153;&#32773;&#21033;&#30410;&#65292;&#65288;3&#65289;LLM&#35828;&#26126;&#20070;&#20013;&#30475;&#20284;&#26080;&#23475;&#30701;&#35821;("&#25552;&#31034;")&#30340;&#21464;&#21270;&#21487;&#33021;&#20250;&#22686;&#21152;&#21246;&#32467;&#12290;&#36825;&#20123;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#25293;&#21334;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24378;&#35843;&#20102;&#26377;&#20851;&#31639;&#27861;&#23450;&#20215;&#30340;&#21453;&#22404;&#26029;&#30417;&#31649;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#21457;&#29616;&#20102;&#22522;&#20110;LLM&#30340;&#23450;&#20215;&#20195;&#29702;&#25152;&#38754;&#20020;&#30340;&#30417;&#31649;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00806v1 Announce Type: cross  Abstract: The rise of algorithmic pricing raises concerns of algorithmic collusion. We conduct experiments with algorithmic pricing agents based on Large Language Models (LLMs), and specifically GPT-4. We find that (1) LLM-based agents are adept at pricing tasks, (2) LLM-based pricing agents autonomously collude in oligopoly settings to the detriment of consumers, and (3) variation in seemingly innocuous phrases in LLM instructions ("prompts") may increase collusion. These results extend to auction settings. Our findings underscore the need for antitrust regulation regarding algorithmic pricing, and uncover regulatory challenges unique to LLM-based pricing agents.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CaT-GNN&#30340;&#26032;&#22411;&#20449;&#29992;&#21345;&#27450;&#35784;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#22240;&#26524;&#19981;&#21464;&#24615;&#23398;&#20064;&#25581;&#31034;&#20132;&#26131;&#25968;&#25454;&#20013;&#30340;&#22266;&#26377;&#30456;&#20851;&#24615;&#65292;&#24182;&#24341;&#20837;&#22240;&#26524;&#28151;&#21512;&#31574;&#30053;&#26469;&#22686;&#24378;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14708</link><description>&lt;p&gt;
&#36890;&#36807;&#22240;&#26524;&#26102;&#38388;&#22270;&#31070;&#32463;&#32593;&#32476;&#22686;&#24378;&#20449;&#29992;&#21345;&#27450;&#35784;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14708
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CaT-GNN&#30340;&#26032;&#22411;&#20449;&#29992;&#21345;&#27450;&#35784;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#22240;&#26524;&#19981;&#21464;&#24615;&#23398;&#20064;&#25581;&#31034;&#20132;&#26131;&#25968;&#25454;&#20013;&#30340;&#22266;&#26377;&#30456;&#20851;&#24615;&#65292;&#24182;&#24341;&#20837;&#22240;&#26524;&#28151;&#21512;&#31574;&#30053;&#26469;&#22686;&#24378;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#29992;&#21345;&#27450;&#35784;&#23545;&#32463;&#27982;&#26500;&#25104;&#37325;&#22823;&#23041;&#32961;&#12290;&#23613;&#31649;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#27450;&#35784;&#26816;&#27979;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#24573;&#35270;&#33410;&#28857;&#30340;&#26412;&#22320;&#32467;&#26500;&#23545;&#39044;&#27979;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#29992;&#21345;&#27450;&#35784;&#26816;&#27979;&#26041;&#27861;&#8212;&#8212;CaT-GNN&#65288;Causal Temporal Graph Neural Networks&#65289;&#65292;&#21033;&#29992;&#22240;&#26524;&#19981;&#21464;&#24615;&#23398;&#20064;&#26469;&#25581;&#31034;&#20132;&#26131;&#25968;&#25454;&#20013;&#30340;&#22266;&#26377;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#21457;&#29616;&#21644;&#24178;&#39044;&#38454;&#27573;&#65292;CaT-GNN&#30830;&#23450;&#20132;&#26131;&#22270;&#20013;&#30340;&#22240;&#26524;&#33410;&#28857;&#65292;&#24182;&#24212;&#29992;&#22240;&#26524;&#28151;&#21512;&#31574;&#30053;&#26469;&#22686;&#24378;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;CaT-GNN&#30001;&#20004;&#20010;&#20851;&#38190;&#32452;&#20214;&#32452;&#25104;&#65306;Causal-Inspector&#21644;Causal-Intervener&#12290;Causal-Inspector&#21033;&#29992;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#30340;&#27880;&#24847;&#21147;&#26435;&#37325;&#26469;&#35782;&#21035;&#22240;&#26524;&#21644;&#29615;&#22659;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14708v1 Announce Type: cross  Abstract: Credit card fraud poses a significant threat to the economy. While Graph Neural Network (GNN)-based fraud detection methods perform well, they often overlook the causal effect of a node's local structure on predictions. This paper introduces a novel method for credit card fraud detection, the \textbf{\underline{Ca}}usal \textbf{\underline{T}}emporal \textbf{\underline{G}}raph \textbf{\underline{N}}eural \textbf{N}etwork (CaT-GNN), which leverages causal invariant learning to reveal inherent correlations within transaction data. By decomposing the problem into discovery and intervention phases, CaT-GNN identifies causal nodes within the transaction graph and applies a causal mixup strategy to enhance the model's robustness and interpretability. CaT-GNN consists of two key components: Causal-Inspector and Causal-Intervener. The Causal-Inspector utilizes attention weights in the temporal attention mechanism to identify causal and environm
&lt;/p&gt;</description></item></channel></rss>