<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#20044;&#20811;&#20848;&#25991;&#26412;&#20998;&#31867;&#39046;&#22495;&#25506;&#32034;&#36328;&#35821;&#35328;&#30693;&#35782;&#20256;&#36882;&#26041;&#27861;&#65292;&#21033;&#29992;&#26368;&#26032;&#30340;NLP&#25216;&#26415;&#65292;&#27979;&#35797;&#20102;&#22312;&#27602;&#24615;&#20998;&#31867;&#12289;&#25991;&#20307;&#20998;&#31867;&#21644;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#26368;&#20339;&#35774;&#32622;&#12290;</title><link>https://arxiv.org/abs/2404.02043</link><description>&lt;p&gt;
&#20044;&#20811;&#20848;&#25991;&#26412;&#20998;&#31867;&#65306;&#36328;&#35821;&#35328;&#30693;&#35782;&#20256;&#36882;&#26041;&#27861;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Ukrainian Texts Classification: Exploration of Cross-lingual Knowledge Transfer Approaches
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02043
&lt;/p&gt;
&lt;p&gt;
&#20044;&#20811;&#20848;&#25991;&#26412;&#20998;&#31867;&#39046;&#22495;&#25506;&#32034;&#36328;&#35821;&#35328;&#30693;&#35782;&#20256;&#36882;&#26041;&#27861;&#65292;&#21033;&#29992;&#26368;&#26032;&#30340;NLP&#25216;&#26415;&#65292;&#27979;&#35797;&#20102;&#22312;&#27602;&#24615;&#20998;&#31867;&#12289;&#25991;&#20307;&#20998;&#31867;&#21644;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#26368;&#20339;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25991;&#26412;&#20998;&#31867;&#39046;&#22495;&#23384;&#22312;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#20294;&#21508;&#31181;&#35821;&#35328;&#21487;&#29992;&#25968;&#25454;&#30340;&#19981;&#24179;&#34913;&#38382;&#39064;&#20381;&#28982;&#26174;&#32780;&#26131;&#35265;&#12290;&#20044;&#20811;&#20848;&#35821;&#20316;&#20026;&#19968;&#31181;&#20173;&#21487;&#20174;&#36328;&#35821;&#35328;&#26041;&#27861;&#30340;&#25345;&#32493;&#23436;&#21892;&#20013;&#21463;&#30410;&#30340;&#35821;&#35328;&#12290;&#37492;&#20110;&#25105;&#20204;&#25152;&#20102;&#35299;&#65292;&#38024;&#23545;&#20856;&#22411;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#65292;&#20044;&#20811;&#20848;&#35821;&#35821;&#26009;&#24211;&#26497;&#24230;&#21294;&#20047;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25506;&#32034;&#36328;&#35821;&#35328;&#30693;&#35782;&#20256;&#36882;&#26041;&#27861;&#65292;&#36991;&#20813;&#25163;&#21160;&#25968;&#25454;&#25972;&#29702;&#65306;&#22823;&#22411;&#22810;&#35821;&#35328;&#32534;&#30721;&#22120;&#21644;&#32763;&#35793;&#31995;&#32479;&#12289;LLMs&#65292;&#20197;&#21450;&#35821;&#35328;&#36866;&#37197;&#22120;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#19978;&#27979;&#35797;&#36825;&#20123;&#26041;&#27861;--&#27602;&#24615;&#20998;&#31867;&#12289;&#25991;&#20307;&#20998;&#31867;&#21644;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;--&#25552;&#20379;&#20102;&#26368;&#20339;&#35774;&#32622;&#30340;"&#37197;&#26041;"&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02043v1 Announce Type: cross  Abstract: Despite the extensive amount of labeled datasets in the NLP text classification field, the persistent imbalance in data availability across various languages remains evident. Ukrainian, in particular, stands as a language that still can benefit from the continued refinement of cross-lingual methodologies. Due to our knowledge, there is a tremendous lack of Ukrainian corpora for typical text classification tasks. In this work, we leverage the state-of-the-art advances in NLP, exploring cross-lingual knowledge transfer methods avoiding manual data curation: large multilingual encoders and translation systems, LLMs, and language adapters. We test the approaches on three text classification tasks -- toxicity classification, formality classification, and natural language inference -- providing the "recipe" for the optimal setups.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;DiMA&#27169;&#22411;&#65292;&#22312;&#34507;&#30333;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#36827;&#34892;&#25193;&#25955;&#26469;&#29983;&#25104;&#27688;&#22522;&#37240;&#24207;&#21015;&#65292;&#27604;&#20256;&#32479;&#35299;&#20915;&#26041;&#26696;&#34920;&#29616;&#26356;&#22909;&#65292;&#24182;&#36890;&#36807;&#35774;&#35745;&#36873;&#25321;&#30340;&#24433;&#21709;&#26469;&#37327;&#21270;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.03726</link><description>&lt;p&gt;
&#34507;&#30333;&#36136;&#24207;&#21015;&#29983;&#25104;&#30340;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#25193;&#25955;
&lt;/p&gt;
&lt;p&gt;
Diffusion on language model embeddings for protein sequence generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03726
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;DiMA&#27169;&#22411;&#65292;&#22312;&#34507;&#30333;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#36827;&#34892;&#25193;&#25955;&#26469;&#29983;&#25104;&#27688;&#22522;&#37240;&#24207;&#21015;&#65292;&#27604;&#20256;&#32479;&#35299;&#20915;&#26041;&#26696;&#34920;&#29616;&#26356;&#22909;&#65292;&#24182;&#36890;&#36807;&#35774;&#35745;&#36873;&#25321;&#30340;&#24433;&#21709;&#26469;&#37327;&#21270;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34507;&#30333;&#35774;&#35745;&#38656;&#35201;&#23545;&#34507;&#30333;&#36136;&#23431;&#23449;&#22266;&#26377;&#22797;&#26434;&#24615;&#30340;&#28145;&#20837;&#20102;&#35299;&#12290;&#23613;&#31649;&#35768;&#22810;&#24037;&#20316;&#20542;&#21521;&#20110;&#26377;&#26465;&#20214;&#30340;&#29983;&#25104;&#25110;&#19987;&#27880;&#20110;&#29305;&#23450;&#34507;&#30333;&#36136;&#23478;&#26063;&#65292;&#20294;&#26080;&#26465;&#20214;&#29983;&#25104;&#30340;&#22522;&#30784;&#20219;&#21153;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#21644;&#37325;&#35270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25506;&#32034;&#36825;&#20010;&#20851;&#38190;&#39046;&#22495;&#65292;&#24341;&#20837;&#20102;DiMA&#65292;&#36825;&#26159;&#19968;&#20010;&#21033;&#29992;&#20174;&#34507;&#30333;&#35821;&#35328;&#27169;&#22411;ESM-2&#34893;&#29983;&#30340;&#23884;&#20837;&#36827;&#34892;&#36830;&#32493;&#25193;&#25955;&#20197;&#29983;&#25104;&#27688;&#22522;&#37240;&#24207;&#21015;&#30340;&#27169;&#22411;&#12290;DiMA&#36229;&#36234;&#20102;&#21253;&#25324;&#33258;&#22238;&#24402;&#21464;&#25442;&#22120;&#21644;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#22312;&#20869;&#30340;&#20027;&#35201;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#23450;&#37327;&#22320;&#35828;&#26126;&#20102;&#23548;&#33268;&#20854;&#21331;&#36234;&#24615;&#33021;&#30340;&#35774;&#35745;&#36873;&#25321;&#25152;&#24102;&#26469;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#25351;&#26631;&#36328;&#22810;&#31181;&#24418;&#24335;&#24191;&#27867;&#35780;&#20272;&#29983;&#25104;&#24207;&#21015;&#30340;&#36136;&#37327;&#12289;&#22810;&#26679;&#24615;&#12289;&#20998;&#24067;&#30456;&#20284;&#24615;&#21644;&#29983;&#29289;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22987;&#32456;&#20135;&#29983;&#26032;&#39062;&#12289;&#22810;&#26679;&#21270;&#30340;&#34507;&#30333;&#36136;&#24207;&#21015;&#65292;&#31934;&#20934;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03726v1 Announce Type: cross  Abstract: Protein design requires a deep understanding of the inherent complexities of the protein universe. While many efforts lean towards conditional generation or focus on specific families of proteins, the foundational task of unconditional generation remains underexplored and undervalued. Here, we explore this pivotal domain, introducing DiMA, a model that leverages continuous diffusion on embeddings derived from the protein language model, ESM-2, to generate amino acid sequences. DiMA surpasses leading solutions, including autoregressive transformer-based and discrete diffusion models, and we quantitatively illustrate the impact of the design choices that lead to its superior performance. We extensively evaluate the quality, diversity, distribution similarity, and biological relevance of the generated sequences using multiple metrics across various modalities. Our approach consistently produces novel, diverse protein sequences that accura
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#22411;&#36234;&#29425;&#25915;&#20987;&#65292;&#36890;&#36807;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#25554;&#20837;&#24694;&#24847;&#25991;&#26412;&#25552;&#31034;&#65292;&#25104;&#21151;&#23454;&#26045;&#36234;&#29425;&#25915;&#20987;&#65292;&#24182;&#20998;&#26512;&#20102;&#26377;&#27602;&#25968;&#25454;&#27604;&#29575;&#21644;&#21487;&#35757;&#32451;&#21442;&#25968;&#20301;&#32622;&#23545;&#25915;&#20987;&#25104;&#21151;&#29575;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.02910</link><description>&lt;p&gt;
ImgTrojan: &#29992;&#19968;&#24352;&#22270;&#29255;&#23545;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#36234;&#29425;
&lt;/p&gt;
&lt;p&gt;
ImgTrojan: Jailbreaking Vision-Language Models with ONE Image
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02910
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#22411;&#36234;&#29425;&#25915;&#20987;&#65292;&#36890;&#36807;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#25554;&#20837;&#24694;&#24847;&#25991;&#26412;&#25552;&#31034;&#65292;&#25104;&#21151;&#23454;&#26045;&#36234;&#29425;&#25915;&#20987;&#65292;&#24182;&#20998;&#26512;&#20102;&#26377;&#27602;&#25968;&#25454;&#27604;&#29575;&#21644;&#21487;&#35757;&#32451;&#21442;&#25968;&#20301;&#32622;&#23545;&#25915;&#20987;&#25104;&#21151;&#29575;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#30340;&#23545;&#40784;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#19982;&#35270;&#35273;&#27169;&#22359;&#38598;&#25104;&#30340;&#23433;&#20840;&#38382;&#39064;&#65292;&#21363;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#65292;&#20173;&#28982;&#30456;&#23545;&#26410;&#34987;&#20805;&#20998;&#25506;&#35752;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;VLMs&#30340;&#26032;&#22411;&#36234;&#29425;&#25915;&#20987;&#65292;&#26088;&#22312;&#24403;&#29992;&#25143;&#36755;&#20837;&#26377;&#23475;&#25351;&#20196;&#26102;&#32469;&#36807;&#20854;&#23433;&#20840;&#38459;&#30861;&#12290;&#20551;&#35774;&#25105;&#20204;&#30340;&#26377;&#27602;&#65288;&#22270;&#20687;&#65292;&#25991;&#26412;&#65289;&#25968;&#25454;&#23545;&#21253;&#21547;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#12290;&#36890;&#36807;&#29992;&#24694;&#24847;&#36234;&#29425;&#25552;&#31034;&#26367;&#25442;&#21407;&#22987;&#25991;&#26412;&#26631;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#21033;&#29992;&#26377;&#27602;&#22270;&#20687;&#25191;&#34892;&#36234;&#29425;&#25915;&#20987;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#26377;&#27602;&#27604;&#29575;&#21644;&#21487;&#35757;&#32451;&#21442;&#25968;&#20301;&#32622;&#23545;&#25915;&#20987;&#25104;&#21151;&#29575;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35780;&#20272;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#24230;&#37327;&#26631;&#20934;&#26469;&#37327;&#21270;&#25105;&#20204;&#25915;&#20987;&#30340;&#25104;&#21151;&#29575;&#21644;&#38544;&#34109;&#24615;&#12290;&#32467;&#21512;&#19968;&#31995;&#21015;&#31574;&#21010;&#30340;&#26377;&#23475;&#25351;&#20196;&#65292;&#21487;&#20197;&#34913;&#37327;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02910v1 Announce Type: cross  Abstract: There has been an increasing interest in the alignment of large language models (LLMs) with human values. However, the safety issues of their integration with a vision module, or vision language models (VLMs), remain relatively underexplored. In this paper, we propose a novel jailbreaking attack against VLMs, aiming to bypass their safety barrier when a user inputs harmful instructions. A scenario where our poisoned (image, text) data pairs are included in the training data is assumed. By replacing the original textual captions with malicious jailbreak prompts, our method can perform jailbreak attacks with the poisoned images. Moreover, we analyze the effect of poison ratios and positions of trainable parameters on our attack's success rate. For evaluation, we design two metrics to quantify the success rate and the stealthiness of our attack. Together with a list of curated harmful instructions, a benchmark for measuring attack efficac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#20844;&#24179;&#24615;&#21407;&#21017;&#8212;&#8212;&#24179;&#31561;&#20445;&#25252;&#65292;&#20854;&#20851;&#38190;&#22312;&#20110;&#23558;&#38169;&#35823;&#20998;&#31867;&#30340;&#39118;&#38505;&#22343;&#31561;&#21270;&#65292;&#36991;&#20813;&#20102;&#35768;&#22810;&#23545;&#20256;&#32479;&#20998;&#31867;&#24179;&#31561;&#21407;&#21017;&#30340;&#21453;&#20363;&#12290;</title><link>https://arxiv.org/abs/2402.12062</link><description>&lt;p&gt;
&#22240;&#26524;&#24179;&#31561;&#20445;&#25252;&#19982;&#31639;&#27861;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Causal Equal Protection as Algorithmic Fairness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12062
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#20844;&#24179;&#24615;&#21407;&#21017;&#8212;&#8212;&#24179;&#31561;&#20445;&#25252;&#65292;&#20854;&#20851;&#38190;&#22312;&#20110;&#23558;&#38169;&#35823;&#20998;&#31867;&#30340;&#39118;&#38505;&#22343;&#31561;&#21270;&#65292;&#36991;&#20813;&#20102;&#35768;&#22810;&#23545;&#20256;&#32479;&#20998;&#31867;&#24179;&#31561;&#21407;&#21017;&#30340;&#21453;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#21313;&#24180;&#65292;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#21746;&#23398;&#30340;&#25991;&#29486;&#24418;&#25104;&#20102;&#19981;&#21516;&#30340;&#31639;&#27861;&#20844;&#24179;&#24615;&#26631;&#20934;&#12290;&#20854;&#20013;&#26368;&#21463;&#20105;&#35758;&#30340;&#20998;&#31867;&#24179;&#31561;&#35201;&#27714;&#65292;&#39044;&#27979;&#31639;&#27861;&#30340;&#38169;&#35823;&#20998;&#31867;&#22312;&#34987;&#20445;&#25252;&#29305;&#24449;&#25152;&#25351;&#31034;&#30340;&#32676;&#20307;&#20013;&#20197;&#30456;&#31561;&#39057;&#29575;&#21457;&#29983;&#12290;&#23613;&#31649;&#20998;&#31867;&#24179;&#31561;&#20855;&#26377;&#30452;&#35266;&#21560;&#24341;&#21147;&#65292;&#20294;&#24050;&#21463;&#21040;&#25915;&#20987;&#12290;&#25105;&#20204;&#36716;&#21521;&#19968;&#20010;&#30456;&#20851;&#21407;&#21017;&#65292;&#21363;&#24179;&#31561;&#20445;&#25252;&#65292;&#35813;&#21407;&#21017;&#26368;&#21021;&#26159;&#22312;&#21009;&#20107;&#21496;&#27861;&#39046;&#22495;&#21457;&#23637;&#36215;&#26469;&#30340;&#12290;&#24179;&#31561;&#20445;&#25252;&#30340;&#20851;&#38190;&#22312;&#20110;&#23558;&#38169;&#35823;&#20998;&#31867;&#30340;&#39118;&#38505;&#65288;&#23558;&#22312;&#35268;&#23450;&#30340;&#24847;&#20041;&#19978;&#20855;&#20307;&#35828;&#26126;&#65289;&#36827;&#34892;&#22343;&#31561;&#21270;&#65292;&#32780;&#19981;&#26159;&#23558;&#38169;&#35823;&#20998;&#31867;&#30340;&#27604;&#29575;&#22343;&#31561;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24179;&#31561;&#20445;&#25252;&#36991;&#20813;&#20102;&#35768;&#22810;&#23545;&#20998;&#31867;&#24179;&#31561;&#30340;&#21453;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12062v1 Announce Type: cross  Abstract: Over the last ten years the literature in computer science and philosophy has formulated different criteria of algorithmic fairness. One of the most discussed, classification parity, requires that the erroneous classifications of a predictive algorithm occur with equal frequency for groups picked out by protected characteristics. Despite its intuitive appeal, classification parity has come under attack. Multiple scenarios can be imagined in which - intuitively - a predictive algorithm does not treat any individual unfairly, and yet classification parity is violated. To make progress, we turn to a related principle, equal protection, originally developed in the context of criminal justice. Key to equal protection is equalizing the risks of erroneous classifications (in a sense to be specified) as opposed to equalizing the rates of erroneous classifications. We show that equal protection avoids many of the counterexamples to classificati
&lt;/p&gt;</description></item><item><title>DyExpert&#26159;&#19968;&#31181;&#29992;&#20110;&#36328;&#22495;&#38142;&#25509;&#39044;&#27979;&#30340;&#21160;&#24577;&#22270;&#27169;&#22411;&#65292;&#36890;&#36807;&#26126;&#30830;&#24314;&#27169;&#21382;&#21490;&#28436;&#21270;&#36807;&#31243;&#24182;&#32467;&#21512;&#38142;&#25509;&#39044;&#27979;&#65292;&#23427;&#21487;&#20197;&#23398;&#20064;&#29305;&#23450;&#19979;&#28216;&#22270;&#30340;&#28436;&#21270;&#27169;&#24335;&#65292;&#24182;&#22312;&#21508;&#20010;&#39046;&#22495;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02168</link><description>&lt;p&gt;
&#36328;&#22495;&#21160;&#24577;&#38142;&#25509;&#39044;&#27979;&#30340;&#19968;&#31181;&#22270;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
One Graph Model for Cross-domain Dynamic Link Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02168
&lt;/p&gt;
&lt;p&gt;
DyExpert&#26159;&#19968;&#31181;&#29992;&#20110;&#36328;&#22495;&#38142;&#25509;&#39044;&#27979;&#30340;&#21160;&#24577;&#22270;&#27169;&#22411;&#65292;&#36890;&#36807;&#26126;&#30830;&#24314;&#27169;&#21382;&#21490;&#28436;&#21270;&#36807;&#31243;&#24182;&#32467;&#21512;&#38142;&#25509;&#39044;&#27979;&#65292;&#23427;&#21487;&#20197;&#23398;&#20064;&#29305;&#23450;&#19979;&#28216;&#22270;&#30340;&#28436;&#21270;&#27169;&#24335;&#65292;&#24182;&#22312;&#21508;&#20010;&#39046;&#22495;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;DyExpert&#65292;&#19968;&#31181;&#29992;&#20110;&#36328;&#22495;&#38142;&#25509;&#39044;&#27979;&#30340;&#21160;&#24577;&#22270;&#27169;&#22411;&#12290;&#23427;&#21487;&#20197;&#26126;&#30830;&#22320;&#24314;&#27169;&#21382;&#21490;&#28436;&#21270;&#36807;&#31243;&#65292;&#23398;&#20064;&#29305;&#23450;&#19979;&#28216;&#22270;&#30340;&#28436;&#21270;&#27169;&#24335;&#65292;&#24182;&#36827;&#32780;&#36827;&#34892;&#29305;&#23450;&#27169;&#24335;&#30340;&#38142;&#25509;&#39044;&#27979;&#12290;DyExpert&#37319;&#29992;&#20102;&#35299;&#30721;&#22120;&#20248;&#21270;&#30340;transformer&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#28436;&#21270;&#24314;&#27169;&#21644;&#38142;&#25509;&#39044;&#27979;&#30340;&#8220;&#26465;&#20214;&#38142;&#25509;&#29983;&#25104;&#8221;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#24182;&#34892;&#35757;&#32451;&#21644;&#25512;&#26029;&#12290;DyExpert&#22312;&#21253;&#21547;6&#30334;&#19975;&#20010;&#21160;&#24577;&#36793;&#30340;&#24191;&#27867;&#21160;&#24577;&#22270;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#22312;&#20843;&#20010;&#26410;&#35757;&#32451;&#30340;&#22270;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;DyExpert&#22312;&#36328;&#22495;&#38142;&#25509;&#39044;&#27979;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#19982;&#30456;&#21516;&#35774;&#32622;&#19979;&#30340;&#20808;&#36827;&#22522;&#20934;&#30456;&#27604;&#65292;DyExpert&#22312;&#20843;&#20010;&#22270;&#19978;&#30340;&#24179;&#22343;&#31934;&#30830;&#24230;&#25552;&#39640;&#20102;11.40&#65285;&#12290;&#26356;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#26159;&#65292;&#22312;&#20845;&#20010;&#26410;&#35757;&#32451;&#30340;&#22270;&#19978;&#65292;&#23427;&#36229;&#36807;&#20102;&#20843;&#20010;&#20808;&#36827;&#22522;&#32447;&#30340;&#20840;&#30417;&#30563;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work proposes DyExpert, a dynamic graph model for cross-domain link prediction. It can explicitly model historical evolving processes to learn the evolution pattern of a specific downstream graph and subsequently make pattern-specific link predictions. DyExpert adopts a decode-only transformer and is capable of efficiently parallel training and inference by \textit{conditioned link generation} that integrates both evolution modeling and link prediction. DyExpert is trained by extensive dynamic graphs across diverse domains, comprising 6M dynamic edges. Extensive experiments on eight untrained graphs demonstrate that DyExpert achieves state-of-the-art performance in cross-domain link prediction. Compared to the advanced baseline under the same setting, DyExpert achieves an average of 11.40% improvement Average Precision across eight graphs. More impressive, it surpasses the fully supervised performance of 8 advanced baselines on 6 untrained graphs.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20165;&#26356;&#26032;&#23569;&#37096;&#20998;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#21442;&#25968;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#20840;&#21442;&#25968;&#37325;&#26032;&#35757;&#32451;&#30340;&#20570;&#27861;&#65292;&#22312;&#20462;&#21098;&#21518;&#24674;&#22797;&#25110;&#29978;&#33267;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;PERP&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#21644;&#23384;&#20648;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2312.15230</link><description>&lt;p&gt;
PERP: &#22312;LLMs&#26102;&#20195;&#37325;&#26032;&#24605;&#32771;&#20462;&#21098;-&#37325;&#26032;&#35757;&#32451;&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
PERP: Rethinking the Prune-Retrain Paradigm in the Era of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20165;&#26356;&#26032;&#23569;&#37096;&#20998;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#21442;&#25968;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#20840;&#21442;&#25968;&#37325;&#26032;&#35757;&#32451;&#30340;&#20570;&#27861;&#65292;&#22312;&#20462;&#21098;&#21518;&#24674;&#22797;&#25110;&#29978;&#33267;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;PERP&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#21644;&#23384;&#20648;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#20462;&#21098;&#23454;&#29616;&#39640;&#25928;&#21387;&#32553;&#65292;&#26174;&#33879;&#20943;&#23569;&#23384;&#20648;&#21644;&#35745;&#31639;&#38656;&#27714;&#21516;&#26102;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#12290;&#20687;&#36845;&#20195;&#24133;&#20540;&#20462;&#21098;&#65288;IMP&#65292;Han&#31561;&#65292;2015&#65289;&#36825;&#26679;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#21487;&#20197;&#21435;&#38500;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#65292;&#24182;&#38656;&#35201;&#26114;&#36149;&#30340;&#37325;&#26032;&#35757;&#32451;&#36807;&#31243;&#20197;&#22312;&#20462;&#21098;&#21518;&#24674;&#22797;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20852;&#36215;&#65292;&#30001;&#20110;&#20869;&#23384;&#21644;&#35745;&#31639;&#38480;&#21046;&#65292;&#23436;&#20840;&#37325;&#26032;&#35757;&#32451;&#21464;&#24471;&#19981;&#21487;&#34892;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#37325;&#26032;&#35757;&#32451;&#25152;&#26377;&#21442;&#25968;&#30340;&#20570;&#27861;&#65292;&#36890;&#36807;&#35777;&#26126;&#21482;&#26356;&#26032;&#23569;&#37096;&#20998;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#21442;&#25968;&#36890;&#24120;&#36275;&#20197;&#24674;&#22797;&#29978;&#33267;&#25552;&#39640;&#24615;&#33021;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#20165;&#37325;&#26032;&#35757;&#32451;GPT-&#32467;&#26500;&#30340;0.27%-0.35%&#30340;&#21442;&#25968;&#21363;&#21487;&#22312;&#19981;&#21516;&#31232;&#30095;&#27700;&#24179;&#19978;&#23454;&#29616;&#19982;&#19968;&#27425;&#24615;IMP&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21363;&#20462;&#21098;&#21518;&#21442;&#25968;&#39640;&#25928;&#37325;&#26032;&#35757;&#32451;&#65288;PERP&#65289;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Networks can be efficiently compressed through pruning, significantly reducing storage and computational demands while maintaining predictive performance. Simple yet effective methods like Iterative Magnitude Pruning (IMP, Han et al., 2015) remove less important parameters and require a costly retraining procedure to recover performance after pruning. However, with the rise of Large Language Models (LLMs), full retraining has become infeasible due to memory and compute constraints. In this study, we challenge the practice of retraining all parameters by demonstrating that updating only a small subset of highly expressive parameters is often sufficient to recover or even improve performance compared to full retraining. Surprisingly, retraining as little as 0.27%-0.35% of the parameters of GPT-architectures achieves comparable performance to One Shot IMP across various sparsity levels. Our approach, Parameter-Efficient Retraining after Pruning (PERP), drastically reduces compute a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#26426;&#22120;/&#28145;&#24230;&#23398;&#20064;&#30340;&#36719;&#20214;&#24037;&#31243;&#39046;&#22495;&#20013;&#21487;&#35299;&#37322;&#24615;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#24635;&#32467;&#20102;XAI&#25216;&#26415;&#22312;&#36719;&#20214;&#24037;&#31243;&#20013;&#30340;&#24212;&#29992;&#24773;&#20917;&#65292;&#26088;&#22312;&#25552;&#39640;AI&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#20197;&#35299;&#20915;&#23454;&#38469;&#37096;&#32626;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#39118;&#38505;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.14617</link><description>&lt;p&gt;
&#12298;&#22522;&#20110;&#26426;&#22120;/&#28145;&#24230;&#23398;&#20064;&#30340;&#36719;&#20214;&#24037;&#31243;&#30740;&#31350;&#20013;&#21487;&#35299;&#37322;&#24615;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#12299;
&lt;/p&gt;
&lt;p&gt;
A Systematic Literature Review on Explainability for Machine/Deep Learning-based Software Engineering Research. (arXiv:2401.14617v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14617
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#26426;&#22120;/&#28145;&#24230;&#23398;&#20064;&#30340;&#36719;&#20214;&#24037;&#31243;&#39046;&#22495;&#20013;&#21487;&#35299;&#37322;&#24615;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#24635;&#32467;&#20102;XAI&#25216;&#26415;&#22312;&#36719;&#20214;&#24037;&#31243;&#20013;&#30340;&#24212;&#29992;&#24773;&#20917;&#65292;&#26088;&#22312;&#25552;&#39640;AI&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#20197;&#35299;&#20915;&#23454;&#38469;&#37096;&#32626;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#39118;&#38505;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#65292;&#29305;&#21035;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#65292;&#22312;&#36719;&#20214;&#24037;&#31243;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#23601;&#65292;&#24182;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#20294;&#30001;&#20110;&#23427;&#20204;&#30340;&#40657;&#30418;&#29305;&#24615;&#65292;&#36825;&#20123;&#20855;&#26377;&#28508;&#21147;&#30340;AI&#39537;&#21160;&#30340;&#36719;&#20214;&#24037;&#31243;&#27169;&#22411;&#31163;&#23454;&#38469;&#37096;&#32626;&#36824;&#26377;&#24456;&#22823;&#30340;&#24046;&#36317;&#12290;&#36825;&#31181;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#23545;&#20110;&#22312;&#20851;&#38190;&#20219;&#21153;&#20013;&#24212;&#29992;&#36825;&#20123;&#27169;&#22411;&#65292;&#22914;&#28431;&#27934;&#26816;&#27979;&#65292;&#20915;&#31574;&#36879;&#26126;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#21364;&#24102;&#26469;&#20102;&#19981;&#24517;&#35201;&#30340;&#39118;&#38505;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;SE&#39046;&#22495;&#20013;&#26088;&#22312;&#25552;&#39640;AI&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#36827;&#34892;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#26469;&#38416;&#26126;&#36825;&#20010;&#36328;&#23398;&#31185;&#39046;&#22495;&#12290;&#35813;&#32508;&#36848;&#35206;&#30422;&#20102;SE&#21644;AI&#23398;&#26415;&#20250;&#35758;&#21644;&#26399;&#21002;&#20013;&#20986;&#29616;&#30340;&#30740;&#31350;&#65292;&#28085;&#30422;&#20102;21&#20010;&#29420;&#29305;&#30340;SE&#20219;&#21153;&#30340;63&#31687;&#35770;&#25991;&#12290;&#22522;&#20110;&#19977;&#20010;&#20851;&#38190;&#30340;&#30740;&#31350;&#38382;&#39064;&#65292;&#25105;&#20204;&#26088;&#22312;&#24635;&#32467;XAI&#25216;&#26415;&#22312;SE&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable achievements of Artificial Intelligence (AI) algorithms, particularly in Machine Learning (ML) and Deep Learning (DL), have fueled their extensive deployment across multiple sectors, including Software Engineering (SE). However, due to their black-box nature, these promising AI-driven SE models are still far from being deployed in practice. This lack of explainability poses unwanted risks for their applications in critical tasks, such as vulnerability detection, where decision-making transparency is of paramount importance. This paper endeavors to elucidate this interdisciplinary domain by presenting a systematic literature review of approaches that aim to improve the explainability of AI models within the context of SE. The review canvasses work appearing in the most prominent SE &amp; AI conferences and journals, and spans 63 papers across 21 unique SE tasks. Based on three key Research Questions (RQs), we aim to (1) summarize the SE tasks where XAI techniques have shown s
&lt;/p&gt;</description></item><item><title>HetGPT&#26159;&#19968;&#31181;&#39044;&#35757;&#32451;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#25552;&#31034;&#35843;&#25972;&#26469;&#35299;&#20915;&#39044;&#35757;&#32451;&#19982;&#19979;&#28216;&#20219;&#21153;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.15318</link><description>&lt;p&gt;
HetGPT: &#21033;&#29992;&#39044;&#35757;&#32451;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25552;&#31034;&#35843;&#25972;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks. (arXiv:2310.15318v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15318
&lt;/p&gt;
&lt;p&gt;
HetGPT&#26159;&#19968;&#31181;&#39044;&#35757;&#32451;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#25552;&#31034;&#35843;&#25972;&#26469;&#35299;&#20915;&#39044;&#35757;&#32451;&#19982;&#19979;&#28216;&#20219;&#21153;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#34920;&#29616;&#20026;&#34920;&#31034;&#21644;&#20998;&#26512;Web&#20013;&#30340;&#22797;&#26434;&#27169;&#24335;&#21644;&#20016;&#23500;&#20449;&#24687;&#30340;&#33258;&#28982;&#36873;&#25321;&#65292;&#20351;&#24471;&#22312;&#32447;&#39029;&#38754;&#20998;&#31867;&#21644;&#31038;&#20132;&#25512;&#33616;&#31561;&#24212;&#29992;&#25104;&#20026;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#8220;&#39044;&#35757;&#32451;&#65292;&#24494;&#35843;&#8221;&#33539;&#24335;&#22312;&#22270;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#26377;&#38480;&#26631;&#35760;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#24448;&#24448;&#23384;&#22312;&#39044;&#35757;&#32451;&#30446;&#26631;&#20219;&#21153;&#19982;&#19979;&#28216;&#20219;&#21153;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#38382;&#39064;&#12290;&#36825;&#31181;&#24046;&#36317;&#21487;&#33021;&#23548;&#33268;&#8220;&#36127;&#36716;&#31227;&#8221;&#38382;&#39064;&#65292;&#21363;&#39044;&#35757;&#32451;&#25152;&#33719;&#24471;&#30340;&#30693;&#35782;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#22522;&#20110;&#25552;&#31034;&#30340;&#23398;&#20064;&#30340;&#20852;&#36215;&#34920;&#26126;&#20102;&#23558;&#8220;&#39044;&#35757;&#32451;&#65292;&#25552;&#31034;&#8221;&#33539;&#24335;&#24212;&#29992;&#20110;&#22270;&#24418;&#30340;&#28508;&#21147;&#65292;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22270;&#24418;&#25552;&#31034;&#25216;&#26415;&#38024;&#23545;&#30340;&#26159;&#21516;&#36136;&#22270;&#65292;&#24573;&#35270;&#20102;Web&#22270;&#30340;&#20869;&#22312;&#24322;&#26500;&#24615;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;HetGPT&#65292;
&lt;/p&gt;
&lt;p&gt;
Graphs have emerged as a natural choice to represent and analyze the intricate patterns and rich information of the Web, enabling applications such as online page classification and social recommendation. The prevailing "pre-train, fine-tune" paradigm has been widely adopted in graph machine learning tasks, particularly in scenarios with limited labeled nodes. However, this approach often exhibits a misalignment between the training objectives of pretext tasks and those of downstream tasks. This gap can result in the "negative transfer" problem, wherein the knowledge gained from pre-training adversely affects performance in the downstream tasks. The surge in prompt-based learning within Natural Language Processing (NLP) suggests the potential of adapting a "pre-train, prompt" paradigm to graphs as an alternative. However, existing graph prompting techniques are tailored to homogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To bridge this gap, we propose HetGPT, a 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#20855;&#26377;&#21487;&#39564;&#35777;&#23433;&#20840;&#20445;&#35777;&#30340;&#26694;&#26550;&#8212;&#8212;&#28040;&#38500;&#21644;&#26816;&#26597;&#65292;&#29992;&#20110;&#23545;&#25239;&#25932;&#23545;&#25552;&#31034;&#12290;&#36890;&#36807;&#36880;&#20010;&#28040;&#38500;&#26631;&#35760;&#24182;&#20351;&#29992;&#23433;&#20840;&#36807;&#28388;&#22120;&#26816;&#26597;&#29983;&#25104;&#30340;&#23376;&#24207;&#21015;&#65292;&#30830;&#20445;&#20219;&#20309;&#25932;&#23545;&#20462;&#25913;&#30340;&#26377;&#23475;&#36755;&#20837;&#25552;&#31034;&#37117;&#33021;&#34987;&#27491;&#30830;&#26631;&#35782;&#20026;&#26377;&#23475;&#12290;</title><link>http://arxiv.org/abs/2309.02705</link><description>&lt;p&gt;
&#35777;&#26126;LLM&#23545;&#25239;&#25932;&#23545;&#25552;&#31034;&#30340;&#23433;&#20840;&#24615;
&lt;/p&gt;
&lt;p&gt;
Certifying LLM Safety against Adversarial Prompting. (arXiv:2309.02705v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#20855;&#26377;&#21487;&#39564;&#35777;&#23433;&#20840;&#20445;&#35777;&#30340;&#26694;&#26550;&#8212;&#8212;&#28040;&#38500;&#21644;&#26816;&#26597;&#65292;&#29992;&#20110;&#23545;&#25239;&#25932;&#23545;&#25552;&#31034;&#12290;&#36890;&#36807;&#36880;&#20010;&#28040;&#38500;&#26631;&#35760;&#24182;&#20351;&#29992;&#23433;&#20840;&#36807;&#28388;&#22120;&#26816;&#26597;&#29983;&#25104;&#30340;&#23376;&#24207;&#21015;&#65292;&#30830;&#20445;&#20219;&#20309;&#25932;&#23545;&#20462;&#25913;&#30340;&#26377;&#23475;&#36755;&#20837;&#25552;&#31034;&#37117;&#33021;&#34987;&#27491;&#30830;&#26631;&#35782;&#20026;&#26377;&#23475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#30830;&#20445;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#23433;&#20840;&#65292;&#20844;&#24320;&#20351;&#29992;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24341;&#20837;&#20102;&#25152;&#35859;&#30340;&#8220;&#27169;&#22411;&#23545;&#40784;&#8221;&#38450;&#25252;&#25514;&#26045;&#12290;&#19968;&#20010;&#23545;&#40784;&#30340;&#35821;&#35328;&#27169;&#22411;&#24212;&#35813;&#25298;&#32477;&#29992;&#25143;&#30340;&#35831;&#27714;&#29983;&#25104;&#26377;&#23475;&#20869;&#23481;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#23433;&#20840;&#25514;&#26045;&#23481;&#26131;&#21463;&#21040;&#25932;&#23545;&#25552;&#31034;&#30340;&#25915;&#20987;&#65292;&#25932;&#23545;&#25552;&#31034;&#21253;&#21547;&#24694;&#24847;&#35774;&#35745;&#30340;&#26631;&#35760;&#24207;&#21015;&#65292;&#20197;&#35268;&#36991;&#27169;&#22411;&#30340;&#23433;&#20840;&#38450;&#25252;&#24182;&#23548;&#33268;&#29983;&#25104;&#26377;&#23475;&#20869;&#23481;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#21487;&#39564;&#35777;&#23433;&#20840;&#20445;&#35777;&#30340;&#31532;&#19968;&#20010;&#23545;&#25239;&#25932;&#23545;&#25552;&#31034;&#30340;&#26694;&#26550;&#8212;&#8212;&#28040;&#38500;&#21644;&#26816;&#26597;&#12290;&#25105;&#20204;&#36880;&#20010;&#28040;&#38500;&#26631;&#35760;&#65292;&#24182;&#20351;&#29992;&#23433;&#20840;&#36807;&#28388;&#22120;&#26816;&#26597;&#29983;&#25104;&#30340;&#23376;&#24207;&#21015;&#12290;&#22914;&#26524;&#23433;&#20840;&#36807;&#28388;&#22120;&#26816;&#27979;&#21040;&#20219;&#20309;&#23376;&#24207;&#21015;&#25110;&#36755;&#20837;&#25552;&#31034;&#26377;&#23475;&#65292;&#25105;&#20204;&#30340;&#36807;&#31243;&#23558;&#23558;&#36755;&#20837;&#25552;&#31034;&#26631;&#35760;&#20026;&#26377;&#23475;&#12290;&#36825;&#20445;&#35777;&#20102;&#23545;&#20110;&#26576;&#20010;&#29305;&#23450;&#22823;&#23567;&#30340;&#26377;&#23475;&#36755;&#20837;&#25552;&#31034;&#30340;&#20219;&#20309;&#25932;&#23545;&#20462;&#25913;&#20063;&#23558;&#34987;&#26631;&#35760;&#20026;&#26377;&#23475;&#12290;&#25105;&#20204;&#23545;&#25239;&#19977;&#31181;&#25915;&#20987;&#27169;&#24335;&#65306;i)&#25932;&#23545;&#21518;&#32512;&#65292;&#21363;&#38468;&#21152;&#25932;&#23545;&#24207;&#21015;&#8230;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) released for public use incorporate guardrails to ensure their output is safe, often referred to as "model alignment." An aligned language model should decline a user's request to produce harmful content. However, such safety measures are vulnerable to adversarial prompts, which contain maliciously designed token sequences to circumvent the model's safety guards and cause it to produce harmful content. In this work, we introduce erase-and-check, the first framework to defend against adversarial prompts with verifiable safety guarantees. We erase tokens individually and inspect the resulting subsequences using a safety filter. Our procedure labels the input prompt as harmful if any subsequences or the input prompt are detected as harmful by the filter. This guarantees that any adversarial modification of a harmful prompt up to a certain size is also labeled harmful. We defend against three attack modes: i) adversarial suffix, which appends an adversarial seq
&lt;/p&gt;</description></item></channel></rss>