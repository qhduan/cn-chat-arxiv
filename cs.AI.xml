<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#38024;&#23545;&#21160;&#24577;&#22270;&#30340;&#26032;&#39062;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65306;GreeDy&#21644;CoDy&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;CoDy&#22312;&#23547;&#25214;&#37325;&#35201;&#21453;&#20107;&#23454;&#36755;&#20837;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#65292;&#25104;&#21151;&#29575;&#39640;&#36798;59%&#12290;</title><link>https://arxiv.org/abs/2403.16846</link><description>&lt;p&gt;
GreeDy&#21644;CoDy&#65306;&#21160;&#24577;&#22270;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#22120;
&lt;/p&gt;
&lt;p&gt;
GreeDy and CoDy: Counterfactual Explainers for Dynamic Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16846
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#38024;&#23545;&#21160;&#24577;&#22270;&#30340;&#26032;&#39062;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65306;GreeDy&#21644;CoDy&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;CoDy&#22312;&#23547;&#25214;&#37325;&#35201;&#21453;&#20107;&#23454;&#36755;&#20837;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#65292;&#25104;&#21151;&#29575;&#39640;&#36798;59%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;TGNNs&#65289;&#23545;&#20110;&#24314;&#27169;&#20855;&#26377;&#26102;&#38388;&#21464;&#21270;&#20132;&#20114;&#30340;&#21160;&#24577;&#22270;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#30001;&#20110;&#20854;&#22797;&#26434;&#30340;&#27169;&#22411;&#32467;&#26500;&#65292;&#22312;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#21453;&#20107;&#23454;&#35299;&#37322;&#23545;&#20110;&#29702;&#35299;&#27169;&#22411;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#65292;&#23427;&#30740;&#31350;&#36755;&#20837;&#22270;&#30340;&#21464;&#21270;&#22914;&#20309;&#24433;&#21709;&#32467;&#26524;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340; TGNNs &#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65306;GreeDy&#65288;&#21160;&#24577;&#22270;&#30340;&#36138;&#24515;&#35299;&#37322;&#22120;&#65289;&#21644; CoDy&#65288;&#21160;&#24577;&#22270;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#22120;&#65289;&#12290;&#23427;&#20204;&#23558;&#35299;&#37322;&#35270;&#20026;&#19968;&#20010;&#25628;&#32034;&#38382;&#39064;&#65292;&#23547;&#25214;&#25913;&#21464;&#27169;&#22411;&#39044;&#27979;&#30340;&#36755;&#20837;&#22270;&#20462;&#25913;&#12290;GreeDy &#20351;&#29992;&#31616;&#21333;&#30340;&#36138;&#24515;&#26041;&#27861;&#65292;&#32780; CoDy &#20351;&#29992;&#22797;&#26434;&#30340;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#31639;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#20004;&#31181;&#26041;&#27861;&#37117;&#33021;&#26377;&#25928;&#29983;&#25104;&#28165;&#26224;&#30340;&#35299;&#37322;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;CoDy &#30340;&#24615;&#33021;&#20248;&#20110; GreeDy &#21644;&#29616;&#26377;&#30340;&#20107;&#23454;&#26041;&#27861;&#65292;&#23547;&#25214;&#21040;&#37325;&#35201;&#30340;&#21453;&#20107;&#23454;&#36755;&#20837;&#30340;&#25104;&#21151;&#29575;&#25552;&#39640;&#20102;&#39640;&#36798; 59\%&#12290;&#36825;&#31361;&#20986;&#20102; CoDy &#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16846v1 Announce Type: cross  Abstract: Temporal Graph Neural Networks (TGNNs), crucial for modeling dynamic graphs with time-varying interactions, face a significant challenge in explainability due to their complex model structure. Counterfactual explanations, crucial for understanding model decisions, examine how input graph changes affect outcomes. This paper introduces two novel counterfactual explanation methods for TGNNs: GreeDy (Greedy Explainer for Dynamic Graphs) and CoDy (Counterfactual Explainer for Dynamic Graphs). They treat explanations as a search problem, seeking input graph alterations that alter model predictions. GreeDy uses a simple, greedy approach, while CoDy employs a sophisticated Monte Carlo Tree Search algorithm. Experiments show both methods effectively generate clear explanations. Notably, CoDy outperforms GreeDy and existing factual methods, with up to 59\% higher success rate in finding significant counterfactual inputs. This highlights CoDy's p
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36827;&#34892;&#22495;&#33258;&#36866;&#24212;&#30340;&#26368;&#20248;&#36755;&#36816;&#65292;&#21487;&#20197;&#23454;&#29616;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#28151;&#21512;&#25104;&#20998;&#20043;&#38388;&#30340;&#21305;&#37197;&#65292;&#20174;&#32780;&#22312;&#22833;&#25928;&#35786;&#26029;&#20013;&#21462;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13847</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36827;&#34892;&#22495;&#33258;&#36866;&#24212;&#30340;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Optimal Transport for Domain Adaptation through Gaussian Mixture Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13847
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36827;&#34892;&#22495;&#33258;&#36866;&#24212;&#30340;&#26368;&#20248;&#36755;&#36816;&#65292;&#21487;&#20197;&#23454;&#29616;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#28151;&#21512;&#25104;&#20998;&#20043;&#38388;&#30340;&#21305;&#37197;&#65292;&#20174;&#32780;&#22312;&#22833;&#25928;&#35786;&#26029;&#20013;&#21462;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#36827;&#34892;&#22495;&#33258;&#36866;&#24212;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#12290;&#36825;&#31181;&#31574;&#30053;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#31561;&#20215;&#30340;&#31163;&#25955;&#38382;&#39064;&#35299;&#20915;&#36830;&#32493;&#26368;&#20248;&#36755;&#36816;&#12290;&#26368;&#20248;&#36755;&#36816;&#35299;&#20915;&#26041;&#26696;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#28151;&#21512;&#25104;&#20998;&#20043;&#38388;&#30340;&#21305;&#37197;&#12290;&#36890;&#36807;&#36825;&#31181;&#21305;&#37197;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#22495;&#20043;&#38388;&#26144;&#23556;&#25968;&#25454;&#28857;&#65292;&#25110;&#32773;&#23558;&#26631;&#31614;&#20174;&#28304;&#22495;&#32452;&#20214;&#36716;&#31227;&#21040;&#30446;&#26631;&#22495;&#12290;&#25105;&#20204;&#22312;&#22833;&#25928;&#35786;&#26029;&#30340;&#20004;&#20010;&#22495;&#33258;&#36866;&#24212;&#22522;&#20934;&#27979;&#35797;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13847v1 Announce Type: cross  Abstract: In this paper we explore domain adaptation through optimal transport. We propose a novel approach, where we model the data distributions through Gaussian mixture models. This strategy allows us to solve continuous optimal transport through an equivalent discrete problem. The optimal transport solution gives us a matching between source and target domain mixture components. From this matching, we can map data points between domains, or transfer the labels from the source domain components towards the target domain. We experiment with 2 domain adaptation benchmarks in fault diagnosis, showing that our methods have state-of-the-art performance.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#22810;&#28304;&#30693;&#35782;&#22270;&#35889;&#19978;&#22238;&#31572;&#22797;&#26434;&#26597;&#35810;&#30340;&#32852;&#37030;&#24335;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#38544;&#31169;&#20445;&#25252;&#21644;&#31572;&#26696;&#26816;&#32034;&#30340;&#25361;&#25112;</title><link>https://arxiv.org/abs/2402.14609</link><description>&lt;p&gt;
&#32852;&#37030;&#24335;&#22797;&#26434;&#26597;&#35810;&#31572;&#26696;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Federated Complex Qeury Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14609
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#22810;&#28304;&#30693;&#35782;&#22270;&#35889;&#19978;&#22238;&#31572;&#22797;&#26434;&#26597;&#35810;&#30340;&#32852;&#37030;&#24335;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#38544;&#31169;&#20445;&#25252;&#21644;&#31572;&#26696;&#26816;&#32034;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#22797;&#26434;&#36923;&#36753;&#26597;&#35810;&#31572;&#26696;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#25191;&#34892;&#22797;&#26434;&#36923;&#36753;&#25512;&#29702;&#30340;&#33021;&#21147;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#22522;&#20110;&#22270;&#25512;&#29702;&#30340;&#19979;&#28216;&#20219;&#21153;&#65292;&#27604;&#22914;&#25628;&#32034;&#24341;&#25806;&#12290;&#26368;&#36817;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#65292;&#23558;&#30693;&#35782;&#22270;&#35889;&#23454;&#20307;&#21644;&#36923;&#36753;&#26597;&#35810;&#34920;&#31034;&#20026;&#23884;&#20837;&#21521;&#37327;&#65292;&#24182;&#20174;&#30693;&#35782;&#22270;&#35889;&#20013;&#25214;&#21040;&#36923;&#36753;&#26597;&#35810;&#30340;&#31572;&#26696;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#26597;&#35810;&#21333;&#20010;&#30693;&#35782;&#22270;&#35889;&#19978;&#65292;&#24182;&#19981;&#33021;&#24212;&#29992;&#20110;&#22810;&#20010;&#22270;&#24418;&#12290;&#27492;&#22806;&#65292;&#30452;&#25509;&#20849;&#20139;&#24102;&#26377;&#25935;&#24863;&#20449;&#24687;&#30340;&#30693;&#35782;&#22270;&#35889;&#21487;&#33021;&#20250;&#24102;&#26469;&#38544;&#31169;&#39118;&#38505;&#65292;&#20351;&#24471;&#20849;&#20139;&#21644;&#26500;&#24314;&#19968;&#20010;&#32858;&#21512;&#30693;&#35782;&#22270;&#35889;&#29992;&#20110;&#25512;&#29702;&#20197;&#26816;&#32034;&#26597;&#35810;&#31572;&#26696;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#22240;&#27492;&#65292;&#30446;&#21069;&#20173;&#28982;&#19981;&#28165;&#26970;&#22914;&#20309;&#22312;&#22810;&#28304;&#30693;&#35782;&#22270;&#35889;&#19978;&#22238;&#31572;&#26597;&#35810;&#12290;&#19968;&#20010;&#23454;&#20307;&#21487;&#33021;&#28041;&#21450;&#21040;&#22810;&#20010;&#30693;&#35782;&#22270;&#35889;&#65292;&#23545;&#22810;&#20010;&#30693;&#35782;&#22270;&#35889;&#36827;&#34892;&#25512;&#29702;&#65292;&#24182;&#22312;&#22810;&#28304;&#30693;&#35782;&#22270;&#35889;&#19978;&#22238;&#31572;&#22797;&#26434;&#26597;&#35810;&#23545;&#20110;&#21457;&#29616;&#30693;&#35782;&#26159;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14609v1 Announce Type: cross  Abstract: Complex logical query answering is a challenging task in knowledge graphs (KGs) that has been widely studied. The ability to perform complex logical reasoning is essential and supports various graph reasoning-based downstream tasks, such as search engines. Recent approaches are proposed to represent KG entities and logical queries into embedding vectors and find answers to logical queries from the KGs. However, existing proposed methods mainly focus on querying a single KG and cannot be applied to multiple graphs. In addition, directly sharing KGs with sensitive information may incur privacy risks, making it impractical to share and construct an aggregated KG for reasoning to retrieve query answers. Thus, it remains unknown how to answer queries on multi-source KGs. An entity can be involved in various knowledge graphs and reasoning on multiple KGs and answering complex queries on multi-source KGs is important in discovering knowledge 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#21033;&#29992;&#22522;&#20110;&#20989;&#25968;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#35270;&#35282;&#26469;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#34920;&#29616;&#26469;&#28304;&#65292;&#32467;&#26524;&#34920;&#26126;DNNs&#20043;&#25152;&#20197;&#25104;&#21151;&#65292;&#26159;&#22240;&#20026;&#23427;&#23545;&#20110;&#20855;&#26377;&#32467;&#26500;&#30340;&#25968;&#25454;&#65292;&#20855;&#22791;&#19968;&#31181;&#20869;&#22312;&#30340;&#22885;&#21345;&#22982;&#21059;&#20992;&#24335;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#36275;&#20197;&#25269;&#28040;&#20989;&#25968;&#25968;&#37327;&#21450;&#22797;&#26434;&#24230;&#30340;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2304.06670</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#21542;&#20855;&#22791;&#20869;&#32622;&#30340;&#22885;&#21345;&#22982;&#21059;&#20992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do deep neural networks have an inbuilt Occam's razor?. (arXiv:2304.06670v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06670
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21033;&#29992;&#22522;&#20110;&#20989;&#25968;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#35270;&#35282;&#26469;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#34920;&#29616;&#26469;&#28304;&#65292;&#32467;&#26524;&#34920;&#26126;DNNs&#20043;&#25152;&#20197;&#25104;&#21151;&#65292;&#26159;&#22240;&#20026;&#23427;&#23545;&#20110;&#20855;&#26377;&#32467;&#26500;&#30340;&#25968;&#25454;&#65292;&#20855;&#22791;&#19968;&#31181;&#20869;&#22312;&#30340;&#22885;&#21345;&#22982;&#21059;&#20992;&#24335;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#36275;&#20197;&#25269;&#28040;&#20989;&#25968;&#25968;&#37327;&#21450;&#22797;&#26434;&#24230;&#30340;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#21442;&#25968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#21331;&#36234;&#24615;&#33021;&#24517;&#39035;&#28304;&#33258;&#20110;&#32593;&#32476;&#26550;&#26500;&#12289;&#35757;&#32451;&#31639;&#27861;&#21644;&#25968;&#25454;&#32467;&#26500;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#20026;&#20102;&#21306;&#20998;&#36825;&#19977;&#20010;&#37096;&#20998;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#22522;&#20110;DNN&#25152;&#34920;&#36798;&#30340;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#35270;&#35282;&#26469;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#12290;&#32463;&#36807;&#32593;&#32476;&#30830;&#23450;&#30340;&#20989;&#25968;&#20808;&#39564;&#36890;&#36807;&#21033;&#29992;&#26377;&#24207;&#21644;&#28151;&#27788;&#29366;&#24577;&#20043;&#38388;&#30340;&#36716;&#21464;&#32780;&#21464;&#21270;&#12290;&#23545;&#20110;&#24067;&#23572;&#20989;&#25968;&#20998;&#31867;&#65292;&#25105;&#20204;&#21033;&#29992;&#20989;&#25968;&#30340;&#35823;&#24046;&#35889;&#22312;&#25968;&#25454;&#19978;&#36827;&#34892;&#21487;&#33021;&#24615;&#30340;&#36817;&#20284;&#12290;&#24403;&#19982;&#20808;&#39564;&#30456;&#32467;&#21512;&#26102;&#65292;&#23427;&#21487;&#20197;&#31934;&#30830;&#22320;&#39044;&#27979;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;DNN&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#35813;&#20998;&#26512;&#25581;&#31034;&#20102;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#20197;&#21450;&#20869;&#22312;&#30340;&#22885;&#21345;&#22982;&#21059;&#20992;&#24335;&#24402;&#32435;&#20559;&#24046;&#65292;&#21363;&#36275;&#20197;&#25269;&#28040;&#22797;&#26434;&#24230;&#38543;&#20989;&#25968;&#25968;&#37327;&#21576;&#25351;&#25968;&#22686;&#38271;&#32780;&#20135;&#29983;&#30340;&#24433;&#21709;&#65292;&#26159;DNNs&#25104;&#21151;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable performance of overparameterized deep neural networks (DNNs) must arise from an interplay between network architecture, training algorithms, and structure in the data. To disentangle these three components, we apply a Bayesian picture, based on the functions expressed by a DNN, to supervised learning. The prior over functions is determined by the network, and is varied by exploiting a transition between ordered and chaotic regimes. For Boolean function classification, we approximate the likelihood using the error spectrum of functions on data. When combined with the prior, this accurately predicts the posterior, measured for DNNs trained with stochastic gradient descent. This analysis reveals that structured data, combined with an intrinsic Occam's razor-like inductive bias towards (Kolmogorov) simple functions that is strong enough to counteract the exponential growth of the number of functions with complexity, is a key to the success of DNNs.
&lt;/p&gt;</description></item></channel></rss>