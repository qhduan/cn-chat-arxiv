<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;FGeo-HyperGNet&#65292;&#23558;&#24418;&#24335;&#31526;&#21495;&#31995;&#32479;&#21644;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#65292;&#29992;&#20110;&#35299;&#20915;&#20960;&#20309;&#38382;&#39064;&#65292;&#23454;&#29616;&#33258;&#21160;&#25191;&#34892;&#20154;&#31867;&#21270;&#30340;&#20960;&#20309;&#28436;&#32462;&#25512;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.11461</link><description>&lt;p&gt;
FGeo-HyperGNet: &#20960;&#20309;&#38382;&#39064;&#27714;&#35299;&#20013;&#38598;&#25104;&#24418;&#24335;&#31526;&#21495;&#31995;&#32479;&#21644;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
FGeo-HyperGNet: Geometry Problem Solving Integrating Formal Symbolic System and Hypergraph Neural Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11461
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;FGeo-HyperGNet&#65292;&#23558;&#24418;&#24335;&#31526;&#21495;&#31995;&#32479;&#21644;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#65292;&#29992;&#20110;&#35299;&#20915;&#20960;&#20309;&#38382;&#39064;&#65292;&#23454;&#29616;&#33258;&#21160;&#25191;&#34892;&#20154;&#31867;&#21270;&#30340;&#20960;&#20309;&#28436;&#32462;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#20309;&#38382;&#39064;&#30340;&#27714;&#35299;&#19968;&#30452;&#26159;&#33258;&#21160;&#25512;&#29702;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20013;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#36825;&#26159;&#25105;&#20204;&#31995;&#21015;&#20316;&#21697;&#20013;&#30340;&#31532;&#20116;&#31687;&#25991;&#31456;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#31070;&#32463;&#31526;&#21495;&#31995;&#32479;&#65292;&#29992;&#20110;&#33258;&#21160;&#25191;&#34892;&#31867;&#20284;&#20154;&#31867;&#30340;&#20960;&#20309;&#28436;&#32462;&#25512;&#29702;&#12290;&#31526;&#21495;&#37096;&#20998;&#26159;&#24314;&#31435;&#22312;FormalGeo&#19978;&#30340;&#24418;&#24335;&#31995;&#32479;&#65292;&#21487;&#20197;&#33258;&#21160;&#25191;&#34892;&#20960;&#20309;&#20851;&#31995;&#25512;&#29702;&#21644;&#20195;&#25968;&#35745;&#31639;&#65292;&#24182;&#23558;&#27714;&#35299;&#36807;&#31243;&#32452;&#32455;&#25104;&#19968;&#20010;&#24102;&#26377;&#26465;&#20214;&#20316;&#20026;&#36229;&#33410;&#28857;&#21644;&#23450;&#29702;&#20316;&#20026;&#36229;&#36793;&#30340;&#35299;&#20915;&#26041;&#26696;&#36229;&#26641;&#12290;&#31070;&#32463;&#37096;&#20998;&#31216;&#20026;HyperGNet&#65292;&#26159;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#21253;&#25324;&#19968;&#20010;&#32534;&#30721;&#22120;&#26469;&#26377;&#25928;&#32534;&#30721;&#36229;&#26641;&#30340;&#32467;&#26500;&#21644;&#35821;&#20041;&#20449;&#24687;&#65292;&#20197;&#21450;&#19968;&#20010;&#27714;&#35299;&#22120;&#26469;&#25552;&#20379;&#38382;&#39064;&#27714;&#35299;&#25351;&#23548;&#12290;&#31070;&#32463;&#37096;&#20998;&#26681;&#25454;&#36229;&#26641;&#39044;&#27979;&#23450;&#29702;&#65292;&#32780;&#31526;&#21495;&#37096;&#20998;&#24212;&#29992;&#23450;&#29702;&#24182;&#26356;&#26032;&#36229;&#26641;&#65292;&#20174;&#32780;&#24418;&#25104;&#19968;&#20010;&#39044;&#27979;-
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11461v1 Announce Type: new  Abstract: Geometry problem solving has always been a long-standing challenge in the fields of automated reasoning and artificial intelligence. This is the fifth article in a series of our works, we built a neural-symbolic system to automatically perform human-like geometric deductive reasoning. The symbolic part is a formal system built on FormalGeo, which can automatically perform geomertic relational reasoning and algebraic calculations and organize the solving process into a solution hypertree with conditions as hypernodes and theorems as hyperedges. The neural part, called HyperGNet, is a hypergraph neural network based on the attention mechanism, including a encoder to effectively encode the structural and semantic information of the hypertree, and a solver to provide problem-solving guidance. The neural part predicts theorems according to the hypertree, and the symbolic part applies theorems and updates the hypertree, thus forming a Predict-
&lt;/p&gt;</description></item><item><title>AI&#24605;&#24819;&#23545;&#20010;&#20307;&#21019;&#36896;&#21147;&#27809;&#26377;&#24433;&#21709;&#65292;&#20294;&#22686;&#21152;&#20102;&#25972;&#20307;&#24605;&#24819;&#22810;&#26679;&#24615;&#30340;&#25968;&#37327;&#21644;&#21464;&#21270;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.13481</link><description>&lt;p&gt;
AI&#24605;&#24819;&#22914;&#20309;&#24433;&#21709;&#20154;&#31867;&#24605;&#24819;&#30340;&#21019;&#36896;&#21147;&#12289;&#22810;&#26679;&#24615;&#21644;&#36827;&#21270;&#65306;&#26469;&#33258;&#19968;&#20010;&#22823;&#35268;&#27169;&#21160;&#24577;&#23454;&#39564;&#30340;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment. (arXiv:2401.13481v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13481
&lt;/p&gt;
&lt;p&gt;
AI&#24605;&#24819;&#23545;&#20010;&#20307;&#21019;&#36896;&#21147;&#27809;&#26377;&#24433;&#21709;&#65292;&#20294;&#22686;&#21152;&#20102;&#25972;&#20307;&#24605;&#24819;&#22810;&#26679;&#24615;&#30340;&#25968;&#37327;&#21644;&#21464;&#21270;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#36755;&#20986;&#30340;&#25509;&#35302;&#27491;&#22312;&#36805;&#36895;&#22686;&#21152;&#12290;&#35266;&#30475;&#21040;AI&#29983;&#25104;&#30340;&#24605;&#24819;&#23558;&#22914;&#20309;&#24433;&#21709;&#20154;&#31867;&#24605;&#24819;&#65311;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#20010;&#23454;&#39564;&#65288;800+&#21442;&#19982;&#32773;&#65292;40+&#20010;&#22269;&#23478;&#65289;&#65292;&#21442;&#19982;&#32773;&#35266;&#30475;&#20102;&#26469;&#33258;ChatGPT&#25110;&#20043;&#21069;&#23454;&#39564;&#21442;&#19982;&#32773;&#30340;&#21019;&#24847;&#24605;&#24819;&#65292;&#28982;&#21518;&#36827;&#34892;&#20102;&#33258;&#24049;&#30340;&#21019;&#24847;&#24605;&#32771;&#12290;&#25105;&#20204;&#21464;&#21270;&#20102;AI&#29983;&#25104;&#31034;&#20363;&#30340;&#25968;&#37327;&#65288;&#26080;&#12289;&#20302;&#12289;&#39640;&#26333;&#20809;&#65289;&#20197;&#21450;&#31034;&#20363;&#26159;&#21542;&#26631;&#35760;&#20026;&#8220;AI&#8221;&#65288;&#25259;&#38706;&#65289;&#12290;&#25105;&#20204;&#30340;&#21160;&#24577;&#23454;&#39564;&#35774;&#35745; - &#22312;&#21516;&#19968;&#23454;&#39564;&#26465;&#20214;&#19979;&#65292;&#20351;&#29992;&#20043;&#21069;&#21442;&#19982;&#32773;&#30340;&#24605;&#24819;&#20316;&#20026;&#26410;&#26469;&#21442;&#19982;&#32773;&#30340;&#21050;&#28608; - &#27169;&#25311;&#20102;&#25991;&#21270;&#21019;&#36896;&#30340;&#30456;&#20114;&#20381;&#36182;&#36807;&#31243;&#65306;&#21019;&#36896;&#24615;&#24605;&#24819;&#24314;&#31435;&#22312;&#20043;&#21069;&#30340;&#24605;&#24819;&#22522;&#30784;&#19978;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25429;&#25417;&#21040;&#20102;LLM&#8220;&#22312;&#25991;&#21270;&#24490;&#29615;&#20013;&#8221;&#30340;&#22797;&#21512;&#25928;&#24212;&#12290;&#25105;&#20204;&#21457;&#29616;&#39640;AI&#26333;&#20809;&#65288;&#20294;&#19981;&#26159;&#20302;AI&#26333;&#20809;&#65289;&#24182;&#27809;&#26377;&#24433;&#21709;&#20010;&#20154;&#24605;&#24819;&#30340;&#21019;&#36896;&#21147;&#65292;&#20294;&#22686;&#21152;&#20102;&#25972;&#20307;&#24605;&#24819;&#22810;&#26679;&#24615;&#30340;&#24179;&#22343;&#25968;&#37327;&#21644;&#21464;&#21270;&#36895;&#29575;&#12290;AI&#20351;&#24605;&#24819;&#22810;&#26679;&#24615;&#30340;&#32047;&#31215;&#25928;&#24212;&#22686;&#24378;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exposure to large language model output is rapidly increasing. How will seeing AI-generated ideas affect human ideas? We conducted an experiment (800+ participants, 40+ countries) where participants viewed creative ideas that were from ChatGPT or prior experimental participants and then brainstormed their own idea. We varied the number of AI-generated examples (none, low, or high exposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic experiment design -- ideas from prior participants in an experimental condition are used as stimuli for future participants in the same experimental condition -- mimics the interdependent process of cultural creation: creative ideas are built upon prior ideas. Hence, we capture the compounding effects of having LLMs 'in the culture loop'. We find that high AI exposure (but not low AI exposure) did not affect the creativity of individual ideas but did increase the average amount and rate of change of collective idea diversity. AI made 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26234;&#33021;&#24211;&#23384;&#31649;&#29702;&#31995;&#32479;&#65292;&#36890;&#36807;&#32467;&#21512;&#26465;&#30721;&#21644;&#20998;&#24067;&#24335;flutter&#24212;&#29992;&#25216;&#26415;&#65292;&#20197;&#21450;&#22823;&#25968;&#25454;&#20998;&#26512;&#23454;&#29616;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#65292;&#35299;&#20915;&#20102;&#24211;&#23384;&#31649;&#29702;&#20013;&#30340;&#20934;&#30830;&#24615;&#12289;&#30417;&#27979;&#24310;&#36831;&#21644;&#36807;&#24230;&#20381;&#36182;&#20027;&#35266;&#32463;&#39564;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.12365</link><description>&lt;p&gt;
&#19968;&#20010;&#39640;&#25928;&#30340;&#26234;&#33021;&#21322;&#33258;&#21160;&#20179;&#24211;&#24211;&#23384;&#30424;&#28857;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System. (arXiv:2309.12365v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26234;&#33021;&#24211;&#23384;&#31649;&#29702;&#31995;&#32479;&#65292;&#36890;&#36807;&#32467;&#21512;&#26465;&#30721;&#21644;&#20998;&#24067;&#24335;flutter&#24212;&#29992;&#25216;&#26415;&#65292;&#20197;&#21450;&#22823;&#25968;&#25454;&#20998;&#26512;&#23454;&#29616;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#65292;&#35299;&#20915;&#20102;&#24211;&#23384;&#31649;&#29702;&#20013;&#30340;&#20934;&#30830;&#24615;&#12289;&#30417;&#27979;&#24310;&#36831;&#21644;&#36807;&#24230;&#20381;&#36182;&#20027;&#35266;&#32463;&#39564;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#26029;&#21457;&#23637;&#30340;&#20379;&#24212;&#38142;&#31649;&#29702;&#32972;&#26223;&#19979;&#65292;&#39640;&#25928;&#30340;&#24211;&#23384;&#31649;&#29702;&#23545;&#20110;&#20225;&#19994;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#25163;&#24037;&#21644;&#32463;&#39564;&#39537;&#21160;&#30340;&#26041;&#27861;&#24448;&#24448;&#38590;&#20197;&#28385;&#36275;&#29616;&#20195;&#24066;&#22330;&#38656;&#27714;&#30340;&#22797;&#26434;&#24615;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26234;&#33021;&#24211;&#23384;&#31649;&#29702;&#31995;&#32479;&#65292;&#20197;&#35299;&#20915;&#19982;&#25968;&#25454;&#19981;&#20934;&#30830;&#12289;&#30417;&#27979;&#24310;&#36831;&#21644;&#36807;&#24230;&#20381;&#36182;&#20027;&#35266;&#32463;&#39564;&#30340;&#39044;&#27979;&#30456;&#20851;&#30340;&#25361;&#25112;&#12290;&#35813;&#31995;&#32479;&#32467;&#21512;&#20102;&#26465;&#30721;&#21644;&#20998;&#24067;&#24335; flutter &#24212;&#29992;&#25216;&#26415;&#65292;&#29992;&#20110;&#26234;&#33021;&#24863;&#30693;&#65292;&#24182;&#36890;&#36807;&#20840;&#38754;&#30340;&#22823;&#25968;&#25454;&#20998;&#26512;&#23454;&#29616;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#12290;&#36890;&#36807;&#20180;&#32454;&#30340;&#20998;&#26512;&#12289;&#31995;&#32479;&#35774;&#35745;&#12289;&#20851;&#38190;&#25216;&#26415;&#25506;&#32034;&#21644;&#27169;&#25311;&#39564;&#35777;&#65292;&#25104;&#21151;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#12290;&#35813;&#26234;&#33021;&#31995;&#32479;&#23454;&#29616;&#20102;&#20108;&#32423;&#30417;&#27979;&#12289;&#39640;&#39057;&#26816;&#26597;&#21644;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#39044;&#27979;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#33258;&#21160;&#21270;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the context of evolving supply chain management, the significance of efficient inventory management has grown substantially for businesses. However, conventional manual and experience-based approaches often struggle to meet the complexities of modern market demands. This research introduces an intelligent inventory management system to address challenges related to inaccurate data, delayed monitoring, and overreliance on subjective experience in forecasting. The proposed system integrates bar code and distributed flutter application technologies for intelligent perception, alongside comprehensive big data analytics to enable data-driven decision-making. Through meticulous analysis, system design, critical technology exploration, and simulation validation, the effectiveness of the proposed system is successfully demonstrated. The intelligent system facilitates second-level monitoring, high-frequency checks, and artificial intelligence-driven forecasting, consequently enhancing the au
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#30417;&#30563;&#22810;&#23545;&#35937;&#21457;&#29616;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#31181;&#19978;&#19979;&#25991;&#20998;&#38548;&#30340;&#27133;&#32467;&#26500;&#26469;&#23558;&#35270;&#35273;&#22330;&#20998;&#21106;&#20026;&#29420;&#31435;&#36816;&#21160;&#21306;&#22495;&#65292;&#24182;&#29992;&#23545;&#25239;&#24615;&#26631;&#20934;&#26469;&#20445;&#35777;&#35299;&#30721;&#22120;&#26080;&#27861;&#37325;&#26500;&#25972;&#20010;&#20809;&#27969;&#12290;</title><link>http://arxiv.org/abs/2304.01430</link><description>&lt;p&gt;
&#20998;&#31163;&#30340;&#20851;&#27880;&#21147;&#65306;&#22522;&#20110;&#19978;&#19979;&#25991;&#20998;&#31163;&#27133;&#30340;&#26080;&#30417;&#30563;&#22810;&#23545;&#35937;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots. (arXiv:2304.01430v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01430
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#30417;&#30563;&#22810;&#23545;&#35937;&#21457;&#29616;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#31181;&#19978;&#19979;&#25991;&#20998;&#38548;&#30340;&#27133;&#32467;&#26500;&#26469;&#23558;&#35270;&#35273;&#22330;&#20998;&#21106;&#20026;&#29420;&#31435;&#36816;&#21160;&#21306;&#22495;&#65292;&#24182;&#29992;&#23545;&#25239;&#24615;&#26631;&#20934;&#26469;&#20445;&#35777;&#35299;&#30721;&#22120;&#26080;&#27861;&#37325;&#26500;&#25972;&#20010;&#20809;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#35270;&#35273;&#22330;&#20998;&#21106;&#20026;&#29420;&#31435;&#36816;&#21160;&#21306;&#22495;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#22522;&#30784;&#30495;&#20540;&#25110;&#30417;&#30563;&#12290;&#23427;&#30001;&#22522;&#20110;&#27133;&#20851;&#27880;&#30340;&#23545;&#25239;&#26465;&#20214;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#26550;&#26500;&#32452;&#25104;&#65292;&#20462;&#25913;&#20026;&#20351;&#29992;&#22270;&#20687;&#20316;&#20026;&#19978;&#19979;&#25991;&#26469;&#35299;&#30721;&#20809;&#27969;&#65292;&#32780;&#19981;&#26159;&#23581;&#35797;&#37325;&#26500;&#22270;&#20687;&#26412;&#36523;&#12290;&#22312;&#32467;&#26524;&#30340;&#22810;&#27169;&#24335;&#34920;&#31034;&#20013;&#65292;&#19968;&#31181;&#27169;&#24335;&#65288;&#27969;&#65289;&#23558;&#39304;&#36865;&#32473;&#32534;&#30721;&#22120;&#20197;&#20135;&#29983;&#21333;&#29420;&#30340;&#28508;&#22312;&#20195;&#30721;&#65288;&#27133;&#65289;&#65292;&#32780;&#21478;&#19968;&#31181;&#27169;&#24335;&#65288;&#22270;&#20687;&#65289;&#23558;&#20915;&#23450;&#35299;&#30721;&#22120;&#20174;&#27133;&#29983;&#25104;&#31532;&#19968;&#20010;&#27169;&#24335;&#65288;&#27969;&#65289;&#12290;&#30001;&#20110;&#24815;&#24120;&#30340;&#33258;&#32534;&#30721;&#22522;&#20110;&#26368;&#23567;&#21270;&#37325;&#26500;&#35823;&#24046;&#65292;&#24182;&#19981;&#33021;&#38450;&#27490;&#25972;&#20010;&#27969;&#34987;&#32534;&#30721;&#21040;&#19968;&#20010;&#27133;&#20013;&#65292;&#22240;&#27492;&#25105;&#20204;&#23558;&#25439;&#22833;&#20462;&#25913;&#20026;&#22522;&#20110;&#19978;&#19979;&#25991;&#20449;&#24687;&#20998;&#31163;&#30340;&#23545;&#25239;&#24615;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a method to segment the visual field into independently moving regions, trained with no ground truth or supervision. It consists of an adversarial conditional encoder-decoder architecture based on Slot Attention, modified to use the image as context to decode optical flow without attempting to reconstruct the image itself. In the resulting multi-modal representation, one modality (flow) feeds the encoder to produce separate latent codes (slots), whereas the other modality (image) conditions the decoder to generate the first (flow) from the slots. This design frees the representation from having to encode complex nuisance variability in the image due to, for instance, illumination and reflectance properties of the scene. Since customary autoencoding based on minimizing the reconstruction error does not preclude the entire flow from being encoded into a single slot, we modify the loss to an adversarial criterion based on Contextual Information Separation. The resulting min-m
&lt;/p&gt;</description></item></channel></rss>