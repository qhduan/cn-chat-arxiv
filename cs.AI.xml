<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>SHIELD&#24341;&#20837;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#36890;&#36807;&#38544;&#34255;&#37096;&#20998;&#36755;&#20837;&#25968;&#25454;&#24182;&#35780;&#20272;&#39044;&#27979;&#32467;&#26524;&#30340;&#24046;&#24322;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2404.02611</link><description>&lt;p&gt;
SHIELD: &#19968;&#31181;&#29992;&#20110;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
SHIELD: A regularization technique for eXplainable Artificial Intelligence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02611
&lt;/p&gt;
&lt;p&gt;
SHIELD&#24341;&#20837;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#36890;&#36807;&#38544;&#34255;&#37096;&#20998;&#36755;&#20837;&#25968;&#25454;&#24182;&#35780;&#20272;&#39044;&#27979;&#32467;&#26524;&#30340;&#24046;&#24322;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#21508;&#20010;&#39046;&#22495;&#21464;&#24471;&#19981;&#21487;&#25110;&#32570;&#65292;&#23545;&#21487;&#35299;&#37322;&#24615;&#30340;&#38656;&#27714;&#19982;&#26085;&#20465;&#22686;&#12290;&#23613;&#31649;&#31185;&#23398;&#30028;&#30340;&#21162;&#21147;&#20027;&#35201;&#38598;&#20013;&#22312;&#20026;&#27169;&#22411;&#33719;&#21462;&#26356;&#22909;&#30340;&#35299;&#37322;&#19978;&#65292;&#20294;&#37325;&#35201;&#30340;&#26159;&#19981;&#35201;&#24573;&#35270;&#36825;&#20010;&#35299;&#37322;&#36807;&#31243;&#23545;&#25913;&#21892;&#35757;&#32451;&#30340;&#28508;&#21147;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#21162;&#21147;&#20027;&#35201;&#38598;&#20013;&#22312;&#20026;&#40657;&#30418;&#27169;&#22411;&#29983;&#25104;&#21644;&#35780;&#20272;&#35299;&#37322;&#19978;&#65292;&#20294;&#30452;&#25509;&#36890;&#36807;&#36825;&#20123;&#35780;&#20272;&#26469;&#22686;&#24378;&#27169;&#22411;&#20173;&#23384;&#22312;&#20851;&#38190;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;SHIELD&#65288;&#36873;&#25321;&#24615;&#38544;&#34255;&#36755;&#20837;&#35780;&#20272;&#23398;&#20064;&#21160;&#24577;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#26088;&#22312;&#36890;&#36807;&#38544;&#34255;&#37096;&#20998;&#36755;&#20837;&#25968;&#25454;&#24182;&#35780;&#20272;&#39044;&#27979;&#32467;&#26524;&#30340;&#24046;&#24322;&#26469;&#25913;&#21892;&#27169;&#22411;&#36136;&#37327;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;SHIELD&#27491;&#21017;&#21270;&#26080;&#32541;&#38598;&#25104;&#21040;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#21516;&#26102;&#20063;&#25913;&#21892;&#20102;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02611v1 Announce Type: new  Abstract: As Artificial Intelligence systems become integral across domains, the demand for explainability grows. While the effort by the scientific community is focused on obtaining a better explanation for the model, it is important not to ignore the potential of this explanation process to improve training as well. While existing efforts primarily focus on generating and evaluating explanations for black-box models, there remains a critical gap in directly enhancing models through these evaluations. This paper introduces SHIELD (Selective Hidden Input Evaluation for Learning Dynamics), a regularization technique for explainable artificial intelligence designed to improve model quality by concealing portions of input data and assessing the resulting discrepancy in predictions. In contrast to conventional approaches, SHIELD regularization seamlessly integrates into the objective function, enhancing model explainability while also improving perfor
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#29420;&#31435;&#20110;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#31283;&#20581;&#21453;&#21521;&#36807;&#31243;&#65292;&#36991;&#20813;&#20102;&#37325;&#26032;&#35757;&#32451;&#25110;&#24494;&#35843;&#65292;&#26377;&#25928;&#22788;&#29702;&#23545;&#25239;&#20928;&#21270;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#25439;&#22833;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.16067</link><description>&lt;p&gt;
&#38024;&#23545;&#23545;&#25239;&#20928;&#21270;&#30340;&#24378;&#22823;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Robust Diffusion Models for Adversarial Purification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16067
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#29420;&#31435;&#20110;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#31283;&#20581;&#21453;&#21521;&#36807;&#31243;&#65292;&#36991;&#20813;&#20102;&#37325;&#26032;&#35757;&#32451;&#25110;&#24494;&#35843;&#65292;&#26377;&#25928;&#22788;&#29702;&#23545;&#25239;&#20928;&#21270;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#25439;&#22833;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#65288;DM&#65289;&#30340;&#23545;&#25239;&#20928;&#21270;&#65288;AP&#65289;&#24050;&#34987;&#35777;&#26126;&#26159;&#23545;&#25239;&#35757;&#32451;&#65288;AT&#65289;&#26368;&#26377;&#21147;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24573;&#30053;&#20102;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#26412;&#36523;&#23545;&#23545;&#25239;&#25915;&#20987;&#24182;&#19981;&#31283;&#20581;&#36825;&#19968;&#20107;&#23454;&#12290;&#27492;&#22806;&#65292;&#25193;&#25955;&#36807;&#31243;&#24456;&#23481;&#26131;&#30772;&#22351;&#35821;&#20041;&#20449;&#24687;&#65292;&#22312;&#21453;&#21521;&#36807;&#31243;&#21518;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#20687;&#20294;&#19982;&#21407;&#22987;&#36755;&#20837;&#22270;&#20687;&#23436;&#20840;&#19981;&#21516;&#65292;&#23548;&#33268;&#26631;&#20934;&#31934;&#24230;&#19979;&#38477;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#19968;&#20010;&#33258;&#28982;&#30340;&#24819;&#27861;&#26159;&#21033;&#29992;&#23545;&#25239;&#35757;&#32451;&#31574;&#30053;&#37325;&#26032;&#35757;&#32451;&#25110;&#24494;&#35843;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#28982;&#32780;&#36825;&#22312;&#35745;&#31639;&#19978;&#26159;&#31105;&#27490;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20855;&#26377;&#23545;&#25239;&#24341;&#23548;&#30340;&#31283;&#20581;&#21453;&#21521;&#36807;&#31243;&#65292;&#23427;&#29420;&#31435;&#20110;&#32473;&#23450;&#30340;&#39044;&#35757;&#32451;DMs&#65292;&#24182;&#19988;&#36991;&#20813;&#20102;&#37325;&#26032;&#35757;&#32451;&#25110;&#24494;&#35843;DMs&#12290;&#36825;&#31181;&#24378;&#22823;&#30340;&#24341;&#23548;&#19981;&#20165;&#21487;&#20197;&#30830;&#20445;&#29983;&#25104;&#30340;&#20928;&#21270;&#31034;&#20363;&#20445;&#30041;&#26356;&#22810;&#30340;&#35821;&#20041;&#20869;&#23481;&#65292;&#36824;&#21487;&#20197;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16067v1 Announce Type: cross  Abstract: Diffusion models (DMs) based adversarial purification (AP) has shown to be the most powerful alternative to adversarial training (AT). However, these methods neglect the fact that pre-trained diffusion models themselves are not robust to adversarial attacks as well. Additionally, the diffusion process can easily destroy semantic information and generate a high quality image but totally different from the original input image after the reverse process, leading to degraded standard accuracy. To overcome these issues, a natural idea is to harness adversarial training strategy to retrain or fine-tune the pre-trained diffusion model, which is computationally prohibitive. We propose a novel robust reverse process with adversarial guidance, which is independent of given pre-trained DMs and avoids retraining or fine-tuning the DMs. This robust guidance can not only ensure to generate purified examples retaining more semantic content but also m
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#20998;&#23618;&#36755;&#20986;&#21453;&#39304;&#20248;&#21270;&#30340;&#26041;&#24335;&#65292;&#21033;&#29992;&#20056;&#23376;&#35825;&#23548;&#30340;&#25439;&#22833;&#26223;&#35266;&#35843;&#24230;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#22797;&#26434;&#25439;&#22833;&#20989;&#25968;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.13728</link><description>&lt;p&gt;
M-HOF-Opt: &#22810;&#30446;&#26631;&#20998;&#23618;&#36755;&#20986;&#21453;&#39304;&#20248;&#21270;&#65306;&#22522;&#20110;&#20056;&#23376;&#35825;&#23548;&#25439;&#22833;&#26223;&#35266;&#35843;&#24230;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
M-HOF-Opt: Multi-Objective Hierarchical Output Feedback Optimization via Multiplier Induced Loss Landscape Scheduling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13728
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#20998;&#23618;&#36755;&#20986;&#21453;&#39304;&#20248;&#21270;&#30340;&#26041;&#24335;&#65292;&#21033;&#29992;&#20056;&#23376;&#35825;&#23548;&#30340;&#25439;&#22833;&#26223;&#35266;&#35843;&#24230;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#22797;&#26434;&#25439;&#22833;&#20989;&#25968;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#25439;&#22833;&#20989;&#25968;&#30001;&#35768;&#22810;&#39033;&#32452;&#25104;&#26102;&#65292;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#23545;&#26435;&#37325;&#20056;&#23376;&#30340;&#32452;&#21512;&#36873;&#25321;&#24418;&#25104;&#20102;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#22270;&#27169;&#22411;&#65288;PGM&#65289;&#65292;&#29992;&#20110;&#32852;&#21512;&#27169;&#22411;&#21442;&#25968;&#21644;&#20056;&#23376;&#28436;&#21270;&#36807;&#31243;&#65292;&#20855;&#26377;&#22522;&#20110;&#36229;&#20307;&#31215;&#30340;&#20284;&#28982;&#65292;&#20419;&#36827;&#27599;&#20010;&#25439;&#22833;&#39033;&#30340;&#22810;&#30446;&#26631;&#19979;&#38477;&#12290;&#30456;&#24212;&#30340;&#21442;&#25968;&#21644;&#20056;&#23376;&#20272;&#35745;&#20316;&#20026;&#19968;&#20010;&#39034;&#24207;&#20915;&#31574;&#36807;&#31243;&#34987;&#36716;&#21270;&#20026;&#19968;&#20010;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#20854;&#20013;&#22810;&#30446;&#26631;&#19979;&#38477;&#30446;&#26631;&#34987;&#20998;&#23618;&#22320;&#20998;&#27966;&#21040;&#19968;&#31995;&#21015;&#32422;&#26463;&#20248;&#21270;&#23376;&#38382;&#39064;&#20013;&#12290;&#23376;&#38382;&#39064;&#32422;&#26463;&#26681;&#25454;&#24085;&#32047;&#25176;&#25903;&#37197;&#33258;&#21160;&#36866;&#24212;&#24182;&#20316;&#20026;&#20302;&#23618;&#20056;&#23376;&#25511;&#21046;&#22120;&#35843;&#24230;&#25439;&#22833;&#26223;&#35266;&#30340;&#35774;&#23450;&#28857;&#65292;&#36890;&#36807;&#27599;&#20010;&#25439;&#22833;&#39033;&#30340;&#36755;&#20986;&#21453;&#39304;&#26469;&#36816;&#34892;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#26080;&#20056;&#23376;&#30340;&#65292;&#24182;&#19988;&#22312;&#26102;&#20195;&#23610;&#24230;&#19978;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13728v1 Announce Type: new  Abstract: When a neural network parameterized loss function consists of many terms, the combinatorial choice of weight multipliers during the optimization process forms a challenging problem. To address this, we proposed a probabilistic graphical model (PGM) for the joint model parameter and multiplier evolution process, with a hypervolume based likelihood that promotes multi-objective descent of each loss term. The corresponding parameter and multiplier estimation as a sequential decision process is then cast into an optimal control problem, where the multi-objective descent goal is dispatched hierarchically into a series of constraint optimization sub-problems. The sub-problem constraint automatically adapts itself according to Pareto dominance and serves as the setpoint for the low level multiplier controller to schedule loss landscapes via output feedback of each loss term. Our method is multiplier-free and operates at the timescale of epochs,
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#65292;&#21487;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#38598;&#25104;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#25913;&#21892;&#24403;&#21069;&#32858;&#31867;&#20808;&#39564;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28165;&#26224;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#32858;&#31867;&#24615;&#33021;&#65292;&#23558;VMM&#19982;scVI&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;</title><link>https://arxiv.org/abs/2402.04412</link><description>&lt;p&gt;
VampPrior&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The VampPrior Mixture Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#65292;&#21487;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#38598;&#25104;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#25913;&#21892;&#24403;&#21069;&#32858;&#31867;&#20808;&#39564;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28165;&#26224;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#32858;&#31867;&#24615;&#33021;&#65292;&#23558;VMM&#19982;scVI&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;DLVMs&#65289;&#30340;&#32858;&#31867;&#20808;&#39564;&#38656;&#35201;&#39044;&#20808;&#23450;&#20041;&#32858;&#31867;&#30340;&#25968;&#37327;&#65292;&#24182;&#19988;&#23481;&#26131;&#21463;&#21040;&#36739;&#24046;&#30340;&#21021;&#22987;&#21270;&#30340;&#24433;&#21709;&#12290;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#21487;&#20197;&#36890;&#36807;&#21516;&#26102;&#25191;&#34892;&#38598;&#25104;&#21644;&#32858;&#31867;&#30340;&#26041;&#24335;&#26497;&#22823;&#22320;&#25913;&#36827;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;scRNA-seq&#20998;&#26512;&#12290;&#25105;&#20204;&#23558;VampPrior&#65288;Tomczak&#21644;Welling&#65292;2018&#65289;&#35843;&#25972;&#20026;Dirichlet&#36807;&#31243;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#24471;&#21040;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25512;&#29702;&#36807;&#31243;&#65292;&#20132;&#26367;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#21644;&#32463;&#39564;&#36125;&#21494;&#26031;&#65292;&#20197;&#28165;&#26970;&#22320;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#33719;&#24471;&#20102;&#26497;&#20855;&#31454;&#20105;&#21147;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;&#23558;VMM&#19982;&#24191;&#21463;&#27426;&#36814;&#30340;scRNA-seq&#38598;&#25104;&#26041;&#27861;scVI&#65288;Lopez&#31561;&#65292;2018&#65289;&#30456;&#32467;&#21512;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current clustering priors for deep latent variable models (DLVMs) require defining the number of clusters a-priori and are susceptible to poor initializations. Addressing these deficiencies could greatly benefit deep learning-based scRNA-seq analysis by performing integration and clustering simultaneously. We adapt the VampPrior (Tomczak &amp; Welling, 2018) into a Dirichlet process Gaussian mixture model, resulting in the VampPrior Mixture Model (VMM), a novel prior for DLVMs. We propose an inference procedure that alternates between variational inference and Empirical Bayes to cleanly distinguish variational and prior parameters. Using the VMM in a Variational Autoencoder attains highly competitive clustering performance on benchmark datasets. Augmenting scVI (Lopez et al., 2018), a popular scRNA-seq integration method, with the VMM significantly improves its performance and automatically arranges cells into biologically meaningful clusters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20809;&#28369;&#24615;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#36229;&#22270;&#30340;&#32467;&#26500;&#65292;&#24182;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#65292;&#33021;&#22815;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.14172</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#22522;&#20110;&#20809;&#28369;&#24615;&#20808;&#39564;&#25512;&#26029;&#36229;&#22270;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Hypergraph Structure Inference From Data Under Smoothness Prior. (arXiv:2308.14172v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14172
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20809;&#28369;&#24615;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#36229;&#22270;&#30340;&#32467;&#26500;&#65292;&#24182;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#65292;&#33021;&#22815;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#22312;&#22788;&#29702;&#28041;&#21450;&#22810;&#20010;&#23454;&#20307;&#30340;&#39640;&#38454;&#20851;&#31995;&#25968;&#25454;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#27809;&#26377;&#26126;&#30830;&#36229;&#22270;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#24076;&#26395;&#33021;&#22815;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#20986;&#26377;&#24847;&#20041;&#30340;&#36229;&#22270;&#32467;&#26500;&#65292;&#20197;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#35201;&#20040;&#37319;&#29992;&#31616;&#21333;&#39044;&#23450;&#20041;&#30340;&#35268;&#21017;&#65292;&#19981;&#33021;&#31934;&#30830;&#25429;&#25417;&#28508;&#22312;&#36229;&#22270;&#32467;&#26500;&#30340;&#20998;&#24067;&#65292;&#35201;&#20040;&#23398;&#20064;&#36229;&#22270;&#32467;&#26500;&#21644;&#33410;&#28857;&#29305;&#24449;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#20294;&#38656;&#35201;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#65288;&#21363;&#39044;&#20808;&#23384;&#22312;&#30340;&#36229;&#22270;&#32467;&#26500;&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#23616;&#38480;&#20110;&#23454;&#38469;&#24773;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20809;&#28369;&#24615;&#20808;&#39564;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#35774;&#35745;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#27809;&#26377;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;&#25152;&#25552;&#20986;&#30340;&#20808;&#39564;&#34920;&#31034;&#36229;&#36793;&#20013;&#30340;&#33410;&#28857;&#29305;&#24449;&#19982;&#21253;&#21547;&#35813;&#36229;&#36793;&#30340;&#36229;&#36793;&#30340;&#29305;&#24449;&#39640;&#24230;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs are important for processing data with higher-order relationships involving more than two entities. In scenarios where explicit hypergraphs are not readily available, it is desirable to infer a meaningful hypergraph structure from the node features to capture the intrinsic relations within the data. However, existing methods either adopt simple pre-defined rules that fail to precisely capture the distribution of the potential hypergraph structure, or learn a mapping between hypergraph structures and node features but require a large amount of labelled data, i.e., pre-existing hypergraph structures, for training. Both restrict their applications in practical scenarios. To fill this gap, we propose a novel smoothness prior that enables us to design a method to infer the probability for each potential hyperedge without labelled data as supervision. The proposed prior indicates features of nodes in a hyperedge are highly correlated by the features of the hyperedge containing th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35745;&#31639;&#26426;&#33258;&#36866;&#24212;&#27979;&#35797;&#20013;&#23384;&#22312;&#30340;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29992;&#25143;&#30340;&#32858;&#21512;&#24433;&#21709;&#20989;&#25968;&#26041;&#27861;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.11912</link><description>&lt;p&gt;
&#35299;&#20915;&#35745;&#31639;&#26426;&#33258;&#36866;&#24212;&#27979;&#35797;&#20013;&#30340;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65306;&#19968;&#31181;&#22522;&#20110;&#29992;&#25143;&#30340;&#32858;&#21512;&#24433;&#21709;&#20989;&#25968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Addressing Selection Bias in Computerized Adaptive Testing: A User-Wise Aggregate Influence Function Approach. (arXiv:2308.11912v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35745;&#31639;&#26426;&#33258;&#36866;&#24212;&#27979;&#35797;&#20013;&#23384;&#22312;&#30340;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29992;&#25143;&#30340;&#32858;&#21512;&#24433;&#21709;&#20989;&#25968;&#26041;&#27861;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#26426;&#33258;&#36866;&#24212;&#27979;&#35797;&#65288;CAT&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#39640;&#25928;&#27979;&#35797;&#27169;&#24335;&#65292;&#21487;&#20197;&#26681;&#25454;&#21463;&#35797;&#32773;&#22312;&#27979;&#35797;&#39046;&#22495;&#30340;&#29087;&#32451;&#31243;&#24230;&#36827;&#34892;&#36866;&#24212;&#12290;CAT&#38656;&#35201;&#39044;&#20808;&#35757;&#32451;&#30340;&#39033;&#30446;&#31616;&#20171;&#65292;&#22240;&#20026;CAT&#26681;&#25454;&#24050;&#27880;&#20876;&#39033;&#30446;&#30340;&#31616;&#20171;&#23454;&#26102;&#35780;&#20272;&#23398;&#29983;&#65292;&#24182;&#20351;&#29992;&#20505;&#36873;&#39033;&#30446;&#30340;&#31616;&#20171;&#36873;&#25321;&#19979;&#19968;&#20010;&#35201;&#25351;&#23548;&#30340;&#39033;&#30446;&#12290;&#28982;&#32780;&#65292;&#33719;&#21462;&#36825;&#26679;&#30340;&#39033;&#30446;&#31616;&#20171;&#26159;&#19968;&#20010;&#26114;&#36149;&#30340;&#36807;&#31243;&#65292;&#28041;&#21450;&#25910;&#38598;&#22823;&#37327;&#23494;&#38598;&#30340;&#39033;&#30446;&#21709;&#24212;&#25968;&#25454;&#65292;&#28982;&#21518;&#22312;&#25910;&#38598;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#35786;&#26029;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#21033;&#29992;CAT&#26381;&#21153;&#20013;&#25910;&#38598;&#30340;&#21709;&#24212;&#25968;&#25454;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#36825;&#24102;&#26469;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#21407;&#22240;&#26159;CAT&#24341;&#20837;&#20102;&#22266;&#26377;&#30340;&#36873;&#25321;&#20559;&#24046;&#65292;&#21363;&#29087;&#32451;&#31243;&#24230;&#26356;&#39640;&#30340;&#23398;&#29983;&#20250;&#25910;&#21040;&#26356;&#38590;&#30340;&#38382;&#39064;&#12290;&#23454;&#38469;&#19978;&#65292;&#24403;&#20351;&#29992;CAT&#21709;&#24212;&#25968;&#25454;&#36827;&#34892;&#31616;&#21333;&#35757;&#32451;&#35786;&#26029;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#39033;&#30446;&#31616;&#20171;&#19982;&#23454;&#38469;&#24773;&#20917;&#26174;&#33879;&#20559;&#31163;&#12290;&#20026;&#20102;&#35299;&#20915;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#29992;&#25143;&#30340;&#32858;&#21512;&#24433;&#21709;&#20989;&#25968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computerized Adaptive Testing (CAT) is a widely used, efficient test mode that adapts to the examinee's proficiency level in the test domain. CAT requires pre-trained item profiles, for CAT iteratively assesses the student real-time based on the registered items' profiles, and selects the next item to administer using candidate items' profiles. However, obtaining such item profiles is a costly process that involves gathering a large, dense item-response data, then training a diagnostic model on the collected data. In this paper, we explore the possibility of leveraging response data collected in the CAT service. We first show that this poses a unique challenge due to the inherent selection bias introduced by CAT, i.e., more proficient students will receive harder questions. Indeed, when naively training the diagnostic model using CAT response data, we observe that item profiles deviate significantly from the ground-truth. To tackle the selection bias issue, we propose the user-wise agg
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20803;&#25968;&#25454;&#30340; AI &#29983;&#25104;&#30340;&#22823;&#23398;&#29983;&#20316;&#19994;&#26816;&#27979;&#26041;&#27861; HowkGPT&#65292;&#36890;&#36807;&#35745;&#31639;&#22256;&#24785;&#24230;&#24471;&#20998;&#26469;&#21306;&#20998;&#23398;&#29983;&#25552;&#20132;&#21644; ChatGPT &#29983;&#25104;&#30340;&#20316;&#19994;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20998;&#26512;&#30340;&#31934;&#24230;&#65292;&#20197;&#24110;&#21161;&#32500;&#25252;&#23398;&#26415;&#35802;&#20449;&#21644;&#38450;&#27490;&#20316;&#24330;&#12290;</title><link>http://arxiv.org/abs/2305.18226</link><description>&lt;p&gt;
HowkGPT: &#22522;&#20110;&#19978;&#19979;&#25991;&#24863;&#30693;&#22256;&#24785;&#24230;&#20998;&#26512;&#30340; ChatGPT &#29983;&#25104;&#30340;&#22823;&#23398;&#29983;&#20316;&#19994;&#26816;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
HowkGPT: Investigating the Detection of ChatGPT-generated University Student Homework through Context-Aware Perplexity Analysis. (arXiv:2305.18226v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18226
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20803;&#25968;&#25454;&#30340; AI &#29983;&#25104;&#30340;&#22823;&#23398;&#29983;&#20316;&#19994;&#26816;&#27979;&#26041;&#27861; HowkGPT&#65292;&#36890;&#36807;&#35745;&#31639;&#22256;&#24785;&#24230;&#24471;&#20998;&#26469;&#21306;&#20998;&#23398;&#29983;&#25552;&#20132;&#21644; ChatGPT &#29983;&#25104;&#30340;&#20316;&#19994;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20998;&#26512;&#30340;&#31934;&#24230;&#65292;&#20197;&#24110;&#21161;&#32500;&#25252;&#23398;&#26415;&#35802;&#20449;&#21644;&#38450;&#27490;&#20316;&#24330;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#20351;&#29992;&#36234;&#26469;&#36234;&#26222;&#36941;&#65292;&#20154;&#20204;&#25285;&#24515;&#23427;&#20204;&#21487;&#33021;&#20250;&#21361;&#21450;&#23398;&#26415;&#35802;&#20449;&#12290;&#25945;&#32946;&#37096;&#38376;&#30446;&#21069;&#27491;&#22312;&#21162;&#21147;&#21306;&#20998;&#23398;&#29983;&#25552;&#20132;&#30340;&#23478;&#24237;&#20316;&#19994;&#21644;AI&#29983;&#25104;&#30340;&#20316;&#19994;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837; HowkGPT &#26631;&#35782;&#30001; AI &#29983;&#25104;&#30340;&#20316;&#19994;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;HowkGPT &#22522;&#20110;&#19968;&#32452;&#23398;&#26415;&#20316;&#19994;&#21644;&#30456;&#24212;&#20803;&#25968;&#25454;&#26500;&#24314;&#65292;&#24182;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340; LLM &#35745;&#31639;&#23398;&#29983;&#25552;&#20132;&#21644; ChatGPT &#29983;&#25104;&#30340;&#22238;&#31572;&#30340;&#22256;&#24785;&#24230;&#24471;&#20998;&#12290;&#28982;&#21518;&#65292;&#36825;&#20123;&#24471;&#20998;&#26377;&#21161;&#20110;&#24314;&#31435;&#21306;&#20998;&#25552;&#20132;&#20316;&#19994;&#26469;&#28304;&#30340;&#38408;&#20540;&#12290;&#37492;&#20110;&#23398;&#26415;&#24037;&#20316;&#30340;&#29305;&#27530;&#24615;&#21644;&#19978;&#19979;&#25991;&#24615;&#36136;&#65292;HowkGPT &#36824;&#36890;&#36807;&#23450;&#20041;&#20174;&#20803;&#25968;&#25454;&#20013;&#23548;&#20986;&#30340;&#31867;&#21035;&#29305;&#23450;&#30340;&#38408;&#20540;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#20998;&#26512;&#30340;&#31934;&#24230;&#12290;&#26412;&#30740;&#31350;&#24378;&#35843;&#20102;&#22312; LLM &#25991;&#26412;&#29983;&#25104;&#26102;&#26399;&#32500;&#25252;&#23398;&#26415;&#35802;&#20449;&#21644;&#38450;&#27490;&#20316;&#24330;&#30340;&#26377;&#25928;&#31574;&#30053;&#30340;&#20851;&#38190;&#24615;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the use of Large Language Models (LLMs) in text generation tasks proliferates, concerns arise over their potential to compromise academic integrity. The education sector currently tussles with distinguishing student-authored homework assignments from AI-generated ones. This paper addresses the challenge by introducing HowkGPT, designed to identify homework assignments generated by AI. HowkGPT is built upon a dataset of academic assignments and accompanying metadata [17] and employs a pretrained LLM to compute perplexity scores for student-authored and ChatGPT-generated responses. These scores then assist in establishing a threshold for discerning the origin of a submitted assignment. Given the specificity and contextual nature of academic work, HowkGPT further refines its analysis by defining category-specific thresholds derived from the metadata, enhancing the precision of the detection. This study emphasizes the critical need for effective strategies to uphold academic integrity a
&lt;/p&gt;</description></item><item><title>SketchOGD&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#23384;&#39640;&#25928;&#30340;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#29992;&#22312;&#32447;&#33609;&#22270;&#31639;&#27861;&#65292;&#23558;&#27169;&#22411;&#26799;&#24230;&#21387;&#32553;&#20026;&#22266;&#23450;&#22823;&#23567;&#30340;&#30697;&#38453;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#31639;&#27861;&#8212;&#8212;&#27491;&#20132;&#26799;&#24230;&#19979;&#38477;&#65288;OGD&#65289;&#12290;</title><link>http://arxiv.org/abs/2305.16424</link><description>&lt;p&gt;
SketchOGD&#65306;&#20869;&#23384;&#39640;&#25928;&#30340;&#25345;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SketchOGD: Memory-Efficient Continual Learning. (arXiv:2305.16424v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16424
&lt;/p&gt;
&lt;p&gt;
SketchOGD&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#23384;&#39640;&#25928;&#30340;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#29992;&#22312;&#32447;&#33609;&#22270;&#31639;&#27861;&#65292;&#23558;&#27169;&#22411;&#26799;&#24230;&#21387;&#32553;&#20026;&#22266;&#23450;&#22823;&#23567;&#30340;&#30697;&#38453;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#31639;&#27861;&#8212;&#8212;&#27491;&#20132;&#26799;&#24230;&#19979;&#38477;&#65288;OGD&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#19968;&#31995;&#21015;&#20219;&#21153;&#19978;&#25345;&#32493;&#35757;&#32451;&#26102;&#65292;&#23427;&#20204;&#23481;&#26131;&#24536;&#35760;&#20808;&#21069;&#20219;&#21153;&#19978;&#23398;&#20064;&#21040;&#30340;&#30693;&#35782;&#65292;&#36825;&#31181;&#29616;&#35937;&#31216;&#20026;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#29616;&#26377;&#30340;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#26041;&#27861;&#24448;&#24448;&#28041;&#21450;&#23384;&#20648;&#36807;&#21435;&#20219;&#21153;&#30340;&#20449;&#24687;&#65292;&#36825;&#24847;&#21619;&#30528;&#20869;&#23384;&#20351;&#29992;&#26159;&#30830;&#23450;&#23454;&#29992;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#23384;&#39640;&#25928;&#30340;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#19968;&#31181;&#24050;&#26377;&#30340;&#31639;&#27861;&#8212;&#8212;&#27491;&#20132;&#26799;&#24230;&#19979;&#38477;&#65288;OGD&#65289;&#12290;OGD&#21033;&#29992;&#20808;&#21069;&#27169;&#22411;&#26799;&#24230;&#26469;&#25214;&#21040;&#32500;&#25345;&#20808;&#21069;&#25968;&#25454;&#28857;&#24615;&#33021;&#30340;&#26435;&#37325;&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#20648;&#20808;&#21069;&#27169;&#22411;&#26799;&#24230;&#30340;&#20869;&#23384;&#25104;&#26412;&#38543;&#31639;&#27861;&#36816;&#34892;&#26102;&#38388;&#22686;&#38271;&#32780;&#22686;&#21152;&#65292;&#22240;&#27492;OGD&#19981;&#36866;&#29992;&#20110;&#20219;&#24847;&#38271;&#26102;&#38388;&#36328;&#24230;&#30340;&#36830;&#32493;&#23398;&#20064;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;SketchOGD&#12290;SketchOGD&#37319;&#29992;&#22312;&#32447;&#33609;&#22270;&#31639;&#27861;&#65292;&#23558;&#27169;&#22411;&#26799;&#24230;&#21387;&#32553;&#20026;&#22266;&#23450;&#22823;&#23567;&#30340;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
When machine learning models are trained continually on a sequence of tasks, they are liable to forget what they learned on previous tasks -- a phenomenon known as catastrophic forgetting. Proposed solutions to catastrophic forgetting tend to involve storing information about past tasks, meaning that memory usage is a chief consideration in determining their practicality. This paper proposes a memory-efficient solution to catastrophic forgetting, improving upon an established algorithm known as orthogonal gradient descent (OGD). OGD utilizes prior model gradients to find weight updates that preserve performance on prior datapoints. However, since the memory cost of storing prior model gradients grows with the runtime of the algorithm, OGD is ill-suited to continual learning over arbitrarily long time horizons. To address this problem, this paper proposes SketchOGD. SketchOGD employs an online sketching algorithm to compress model gradients as they are encountered into a matrix of a fix
&lt;/p&gt;</description></item></channel></rss>