<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#23450;&#20041;&#20102;&#35268;&#26684;&#36807;&#24230;&#25311;&#21512;&#38382;&#39064;&#65292;&#21363;&#31995;&#32479;&#36807;&#24230;&#20851;&#27880;&#25351;&#23450;&#25351;&#26631;&#32780;&#25439;&#23475;&#20102;&#39640;&#32423;&#35201;&#27714;&#21644;&#20219;&#21153;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.08425</link><description>&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#35268;&#26684;&#36807;&#24230;&#25311;&#21512;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Specification Overfitting in Artificial Intelligence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23450;&#20041;&#20102;&#35268;&#26684;&#36807;&#24230;&#25311;&#21512;&#38382;&#39064;&#65292;&#21363;&#31995;&#32479;&#36807;&#24230;&#20851;&#27880;&#25351;&#23450;&#25351;&#26631;&#32780;&#25439;&#23475;&#20102;&#39640;&#32423;&#35201;&#27714;&#21644;&#20219;&#21153;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#21644;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#26041;&#27861;&#32463;&#24120;&#34987;&#25209;&#35780;&#23384;&#22312;&#22266;&#26377;&#30340;&#20559;&#35265;&#65292;&#20197;&#21450;&#32570;&#20047;&#25511;&#21046;&#12289;&#38382;&#36131;&#21644;&#36879;&#26126;&#24230;&#65292;&#30417;&#31649;&#26426;&#26500;&#22240;&#27492;&#38590;&#20197;&#25511;&#21046;&#36825;&#31181;&#25216;&#26415;&#30340;&#28508;&#22312;&#36127;&#38754;&#24433;&#21709;&#12290;&#39640;&#32423;&#35201;&#27714;&#65292;&#22914;&#20844;&#24179;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#38656;&#35201;&#34987;&#24418;&#24335;&#21270;&#20026;&#20855;&#20307;&#30340;&#35268;&#26684;&#24230;&#37327;&#65292;&#32780;&#36825;&#20123;&#24230;&#37327;&#26159;&#25429;&#25417;&#22522;&#26412;&#35201;&#27714;&#30340;&#29420;&#31435;&#26041;&#38754;&#30340;&#19981;&#23436;&#32654;&#20195;&#29702;&#12290;&#37492;&#20110;&#19981;&#21516;&#25351;&#26631;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#30340;&#26435;&#34913;&#21450;&#20854;&#23545;&#36807;&#24230;&#20248;&#21270;&#30340;&#33030;&#24369;&#24615;&#65292;&#23558;&#35268;&#26684;&#24230;&#37327;&#25972;&#21512;&#21040;&#31995;&#32479;&#24320;&#21457;&#36807;&#31243;&#20013;&#24182;&#19981;&#26159;&#19968;&#20214;&#31616;&#21333;&#30340;&#20107;&#24773;&#12290;&#26412;&#25991;&#23450;&#20041;&#20102;&#35268;&#26684;&#36807;&#24230;&#25311;&#21512;&#65292;&#21363;&#31995;&#32479;&#36807;&#24230;&#20391;&#37325;&#20110;&#25351;&#23450;&#30340;&#24230;&#37327;&#65292;&#20174;&#32780;&#25439;&#23475;&#20102;&#39640;&#32423;&#35201;&#27714;&#21644;&#20219;&#21153;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#25991;&#29486;&#35843;&#30740;&#65292;&#23545;&#30740;&#31350;&#20154;&#21592;&#22914;&#20309;&#25552;&#20986;&#12289;&#27979;&#37327;&#21644;&#20248;&#21270;&#35268;&#26684;&#36827;&#34892;&#20102;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08425v1 Announce Type: new  Abstract: Machine learning (ML) and artificial intelligence (AI) approaches are often criticized for their inherent bias and for their lack of control, accountability, and transparency. Consequently, regulatory bodies struggle with containing this technology's potential negative side effects. High-level requirements such as fairness and robustness need to be formalized into concrete specification metrics, imperfect proxies that capture isolated aspects of the underlying requirements. Given possible trade-offs between different metrics and their vulnerability to over-optimization, integrating specification metrics in system development processes is not trivial. This paper defines specification overfitting, a scenario where systems focus excessively on specified metrics to the detriment of high-level requirements and task performance. We present an extensive literature survey to categorize how researchers propose, measure, and optimize specification
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#26102;&#31354;&#25968;&#25454;&#20013;&#24120;&#35265;&#30340;&#20998;&#24067;&#21464;&#21270;&#38382;&#39064;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#21435;&#28151;&#28102;&#26041;&#27861;&#24182;&#25552;&#20986;&#20102;&#21517;&#20026;DCA&#30340;&#29702;&#35770;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2311.12472</link><description>&lt;p&gt;
&#38024;&#23545;&#26102;&#31354;&#20559;&#31227;&#30340;&#33258;&#30417;&#30563;&#21435;&#28151;&#28102;&#65306;&#29702;&#35770;&#19982;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12472
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#26102;&#31354;&#25968;&#25454;&#20013;&#24120;&#35265;&#30340;&#20998;&#24067;&#21464;&#21270;&#38382;&#39064;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#21435;&#28151;&#28102;&#26041;&#27861;&#24182;&#25552;&#20986;&#20102;&#21517;&#20026;DCA&#30340;&#29702;&#35770;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#26102;&#31354;&#65288;ST&#65289;&#25968;&#25454;&#30340;&#37325;&#35201;&#24212;&#29992;&#65292;ST&#20132;&#36890;&#39044;&#27979;&#22312;&#25552;&#39640;&#22478;&#24066;&#20986;&#34892;&#25928;&#29575;&#21644;&#20419;&#36827;&#21487;&#25345;&#32493;&#21457;&#23637;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#26412;&#25991;&#39318;&#20808;&#36890;&#36807;&#26500;&#24314;&#36807;&#21435;&#20132;&#36890;&#25968;&#25454;&#12289;&#26410;&#26469;&#20132;&#36890;&#25968;&#25454;&#21644;&#22806;&#37096;ST&#19978;&#19979;&#25991;&#30340;&#22240;&#26524;&#22270;&#65292;&#31995;&#32479;&#22320;&#38416;&#26126;&#20102;&#36807;&#21435;&#33402;&#26415;&#20316;&#21697;&#22312;OOD&#20132;&#36890;&#25968;&#25454;&#19978;&#30340;&#22833;&#36133;&#26159;&#30001;&#20110;ST&#19978;&#19979;&#25991;&#20805;&#24403;&#20102;&#28151;&#28102;&#22240;&#32032;&#65292;&#21363;&#36807;&#21435;&#25968;&#25454;&#21644;&#26410;&#26469;&#25968;&#25454;&#30340;&#20849;&#21516;&#21407;&#22240;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#22240;&#26524;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#35299;&#20915;&#26041;&#26696;&#65292;&#31216;&#20026;Disentangled Contextual Adjustment&#65288;DCA&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.12472v2 Announce Type: replace  Abstract: As an important application of spatio-temporal (ST) data, ST traffic forecasting plays a crucial role in improving urban travel efficiency and promoting sustainable development. In practice, the dynamics of traffic data frequently undergo distributional shifts attributed to external factors such as time evolution and spatial differences. This entails forecasting models to handle the out-of-distribution (OOD) issue where test data is distributed differently from training data. In this work, we first formalize the problem by constructing a causal graph of past traffic data, future traffic data, and external ST contexts. We reveal that the failure of prior arts in OOD traffic data is due to ST contexts acting as a confounder, i.e., the common cause for past data and future ones. Then, we propose a theoretical solution named Disentangled Contextual Adjustment (DCA) from a causal lens. It differentiates invariant causal correlations again
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#24773;&#22659;&#36718;&#30424;&#36172;&#20013;&#30340;&#36716;&#31227;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#35782;&#21035;&#34892;&#20026;&#21644;&#22870;&#21169;&#22240;&#26524;&#25928;&#24212;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#22240;&#26524;&#32422;&#26463;&#26469;&#25913;&#36827;&#36718;&#30424;&#36172;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.03572</link><description>&lt;p&gt;
&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#24773;&#22659;&#36718;&#30424;&#36172;&#20013;&#30340;&#21487;&#35777;&#25928;&#29575;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient Learning in Partially Observable Contextual Bandit. (arXiv:2308.03572v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#24773;&#22659;&#36718;&#30424;&#36172;&#20013;&#30340;&#36716;&#31227;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#35782;&#21035;&#34892;&#20026;&#21644;&#22870;&#21169;&#22240;&#26524;&#25928;&#24212;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#22240;&#26524;&#32422;&#26463;&#26469;&#25913;&#36827;&#36718;&#30424;&#36172;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#24773;&#22659;&#36718;&#30424;&#36172;&#20013;&#30340;&#36716;&#31227;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#20154;&#20165;&#26377;&#26469;&#33258;&#20854;&#20182;&#20195;&#29702;&#20154;&#30340;&#26377;&#38480;&#30693;&#35782;&#65292;&#24182;&#19988;&#23545;&#38544;&#34255;&#30340;&#28151;&#28102;&#22240;&#32032;&#21482;&#26377;&#37096;&#20998;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#26469;&#35782;&#21035;&#25110;&#37096;&#20998;&#35782;&#21035;&#34892;&#20026;&#21644;&#22870;&#21169;&#20043;&#38388;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#26410;&#30693;&#20998;&#24067;&#30340;&#21407;&#22987;&#21151;&#33021;&#32422;&#26463;&#31163;&#25955;&#21270;&#20026;&#32447;&#24615;&#32422;&#26463;&#65292;&#24182;&#36890;&#36807;&#39034;&#24207;&#35299;&#32447;&#24615;&#35268;&#21010;&#26469;&#37319;&#26679;&#20860;&#23481;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#20197;&#32771;&#34385;&#20272;&#35745;&#35823;&#24046;&#24471;&#21040;&#22240;&#26524;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#37319;&#26679;&#31639;&#27861;&#20026;&#36866;&#24403;&#30340;&#37319;&#26679;&#20998;&#24067;&#25552;&#20379;&#20102;&#29702;&#24819;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#22240;&#26524;&#32422;&#26463;&#24212;&#29992;&#20110;&#25913;&#36827;&#32463;&#20856;&#30340;&#36718;&#30424;&#36172;&#31639;&#27861;&#65292;&#24182;&#20197;&#34892;&#21160;&#38598;&#21644;&#20989;&#25968;&#31354;&#38388;&#35268;&#27169;&#20026;&#21442;&#32771;&#25913;&#21464;&#20102;&#36951;&#25022;&#20540;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#20801;&#35768;&#25105;&#20204;&#22788;&#29702;&#19968;&#33324;&#24773;&#22659;&#20998;&#24067;&#30340;&#20989;&#25968;&#36924;&#36817;&#20219;&#21153;&#20013;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate transfer learning in partially observable contextual bandits, where agents have limited knowledge from other agents and partial information about hidden confounders. We first convert the problem to identifying or partially identifying causal effects between actions and rewards through optimization problems. To solve these optimization problems, we discretize the original functional constraints of unknown distributions into linear constraints, and sample compatible causal models via sequentially solving linear programmings to obtain causal bounds with the consideration of estimation error. Our sampling algorithms provide desirable convergence results for suitable sampling distributions. We then show how causal bounds can be applied to improving classical bandit algorithms and affect the regrets with respect to the size of action sets and function spaces. Notably, in the task with function approximation which allows us to handle general context distributions
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;SplitFC&#30340;&#36890;&#20449;&#39640;&#25928;&#30340;&#20998;&#21106;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#31181;&#33258;&#36866;&#24212;&#21387;&#32553;&#31574;&#30053;&#26469;&#20943;&#23569;&#20013;&#38388;&#29305;&#24449;&#21644;&#26799;&#24230;&#21521;&#37327;&#30340;&#36890;&#20449;&#24320;&#38144;&#65292;&#36825;&#20123;&#31574;&#30053;&#20998;&#21035;&#26159;&#33258;&#36866;&#24212;&#29305;&#24449;&#36880;&#28176;&#25481;&#33853;&#21644;&#33258;&#36866;&#24212;&#29305;&#24449;&#36880;&#28176;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.10805</link><description>&lt;p&gt;
&#36890;&#36807;&#33258;&#36866;&#24212;&#29305;&#24449;&#36880;&#28176;&#21387;&#32553;&#23454;&#29616;&#39640;&#25928;&#30340;&#20998;&#21106;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Split Learning via Adaptive Feature-Wise Compression. (arXiv:2307.10805v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10805
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;SplitFC&#30340;&#36890;&#20449;&#39640;&#25928;&#30340;&#20998;&#21106;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#31181;&#33258;&#36866;&#24212;&#21387;&#32553;&#31574;&#30053;&#26469;&#20943;&#23569;&#20013;&#38388;&#29305;&#24449;&#21644;&#26799;&#24230;&#21521;&#37327;&#30340;&#36890;&#20449;&#24320;&#38144;&#65292;&#36825;&#20123;&#31574;&#30053;&#20998;&#21035;&#26159;&#33258;&#36866;&#24212;&#29305;&#24449;&#36880;&#28176;&#25481;&#33853;&#21644;&#33258;&#36866;&#24212;&#29305;&#24449;&#36880;&#28176;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SplitFC&#30340;&#26032;&#39062;&#30340;&#36890;&#20449;&#39640;&#25928;&#30340;&#20998;&#21106;&#23398;&#20064;&#65288;SL&#65289;&#26694;&#26550;&#65292;&#23427;&#20943;&#23569;&#20102;&#22312;SL&#22521;&#35757;&#36807;&#31243;&#20013;&#20256;&#36755;&#20013;&#38388;&#29305;&#24449;&#21644;&#26799;&#24230;&#21521;&#37327;&#25152;&#38656;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;SplitFC&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#21033;&#29992;&#30697;&#38453;&#30340;&#21015;&#25152;&#23637;&#31034;&#30340;&#19981;&#21516;&#30340;&#31163;&#25955;&#31243;&#24230;&#12290;SplitFC&#25972;&#21512;&#20102;&#20004;&#31181;&#21387;&#32553;&#31574;&#30053;&#65306;&#65288;i&#65289;&#33258;&#36866;&#24212;&#29305;&#24449;&#36880;&#28176;&#25481;&#33853;&#21644;&#65288;ii&#65289;&#33258;&#36866;&#24212;&#29305;&#24449;&#36880;&#28176;&#37327;&#21270;&#12290;&#22312;&#31532;&#19968;&#31181;&#31574;&#30053;&#20013;&#65292;&#20013;&#38388;&#29305;&#24449;&#21521;&#37327;&#26681;&#25454;&#36825;&#20123;&#21521;&#37327;&#30340;&#26631;&#20934;&#20559;&#24046;&#30830;&#23450;&#33258;&#36866;&#24212;&#25481;&#33853;&#27010;&#29575;&#36827;&#34892;&#25481;&#33853;&#12290;&#28982;&#21518;&#65292;&#30001;&#20110;&#38142;&#24335;&#35268;&#21017;&#65292;&#19982;&#34987;&#20002;&#24323;&#30340;&#29305;&#24449;&#21521;&#37327;&#30456;&#20851;&#32852;&#30340;&#20013;&#38388;&#26799;&#24230;&#21521;&#37327;&#20063;&#20250;&#34987;&#20002;&#24323;&#12290;&#22312;&#31532;&#20108;&#31181;&#31574;&#30053;&#20013;&#65292;&#38750;&#20002;&#24323;&#30340;&#20013;&#38388;&#29305;&#24449;&#21644;&#26799;&#24230;&#21521;&#37327;&#20351;&#29992;&#22522;&#20110;&#21521;&#37327;&#33539;&#22260;&#30830;&#23450;&#30340;&#33258;&#36866;&#24212;&#37327;&#21270;&#32423;&#21035;&#36827;&#34892;&#37327;&#21270;&#12290;&#20026;&#20102;&#23613;&#37327;&#20943;&#23567;&#37327;&#21270;&#35823;&#24046;&#65292;&#26368;&#20248;&#37327;&#21270;&#26159;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel communication-efficient split learning (SL) framework, named SplitFC, which reduces the communication overhead required for transmitting intermediate feature and gradient vectors during the SL training process. The key idea of SplitFC is to leverage different dispersion degrees exhibited in the columns of the matrices. SplitFC incorporates two compression strategies: (i) adaptive feature-wise dropout and (ii) adaptive feature-wise quantization. In the first strategy, the intermediate feature vectors are dropped with adaptive dropout probabilities determined based on the standard deviation of these vectors. Then, by the chain rule, the intermediate gradient vectors associated with the dropped feature vectors are also dropped. In the second strategy, the non-dropped intermediate feature and gradient vectors are quantized using adaptive quantization levels determined based on the ranges of the vectors. To minimize the quantization error, the optimal quantizatio
&lt;/p&gt;</description></item></channel></rss>