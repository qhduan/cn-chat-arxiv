<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39046;&#22495;&#26080;&#20851;&#30340;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#22522;&#20110;&#29366;&#24577;&#36716;&#31227;&#31995;&#32479;&#30340;&#21160;&#24577;&#35268;&#21010;&#25551;&#36848;&#35821;&#35328;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#35768;&#22810;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#19978;&#20248;&#20110;&#20256;&#32479;&#30340;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#21644;&#32422;&#26463;&#35268;&#21010;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13883</link><description>&lt;p&gt;
&#39046;&#22495;&#26080;&#20851;&#30340;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Domain-Independent Dynamic Programming. (arXiv:2401.13883v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39046;&#22495;&#26080;&#20851;&#30340;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#22522;&#20110;&#29366;&#24577;&#36716;&#31227;&#31995;&#32479;&#30340;&#21160;&#24577;&#35268;&#21010;&#25551;&#36848;&#35821;&#35328;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#35768;&#22810;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#19978;&#20248;&#20110;&#20256;&#32479;&#30340;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#21644;&#32422;&#26463;&#35268;&#21010;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#22522;&#20110;&#27169;&#22411;&#30340;&#33539;&#20363;&#22914;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010; (MIP) &#21644;&#32422;&#26463;&#35268;&#21010; (CP) &#26088;&#22312;&#35299;&#32806;&#38382;&#39064;&#30340;&#24314;&#27169;&#21644;&#27714;&#35299;&#36807;&#31243;&#65292;&#36825;&#26159;&#22768;&#26126;&#24615;&#38382;&#39064;&#27714;&#35299;&#30340;&#8220;&#22307;&#26479;&#8221;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#39046;&#22495;&#26080;&#20851;&#30340;&#21160;&#24577;&#35268;&#21010;&#65288;DIDP&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#35268;&#21010; (DP) &#30340;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#34429;&#28982;DP&#24182;&#19981;&#26032;&#40092;&#65292;&#20294;&#36890;&#24120;&#23427;&#34987;&#20316;&#20026;&#19968;&#31181;&#29305;&#23450;&#38382;&#39064;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#21160;&#24577;&#35268;&#21010;&#25551;&#36848;&#35821;&#35328; (DyPDL)&#65292;&#19968;&#31181;&#22522;&#20110;&#29366;&#24577;&#36716;&#31227;&#31995;&#32479;&#30340;&#24418;&#24335;&#21270;&#35821;&#35328;&#65292;&#28789;&#24863;&#26469;&#33258;&#20110;AI&#35268;&#21010;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21551;&#21457;&#24335;&#25628;&#32034;&#31639;&#27861;&#21487;&#20197;&#29992;&#26469;&#27714;&#35299;DyPDL&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19971;&#31181;DIDP&#27714;&#35299;&#22120;&#12290;&#25105;&#20204;&#22312;&#24120;&#35265;&#30340;11&#20010;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#31867;&#21035;&#30340;&#22522;&#20934;&#23454;&#20363;&#19978;&#65292;&#23558;&#25105;&#20204;&#30340;DIDP&#27714;&#35299;&#22120;&#19982;&#21830;&#19994;MIP&#21644;CP&#27714;&#35299;&#22120;&#36827;&#34892;&#20102;&#23454;&#39564;&#27604;&#36739;&#65288;&#20998;&#21035;&#27714;&#35299;MIP&#21644;CP&#27169;&#22411;&#65289;&#12290;&#32467;&#26524;&#26174;&#31034;DIDP&#22312;&#20061;&#20010;&#38382;&#39064;&#31867;&#21035;&#20013;&#20248;&#20110;MIP&#65292;&#20063;&#20248;&#20110;CP&#22312;&#20061;&#20010;&#38382;&#39064;&#31867;&#21035;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
For combinatorial optimization problems, model-based paradigms such as mixed-integer programming (MIP) and constraint programming (CP) aim to decouple modeling and solving a problem: the `holy grail' of declarative problem solving. We propose domain-independent dynamic programming (DIDP), a new model-based paradigm based on dynamic programming (DP). While DP is not new, it has typically been implemented as a problem-specific method. We introduce Dynamic Programming Description Language (DyPDL), a formalism to define DP models based on a state transition system, inspired by AI planning. We show that heuristic search algorithms can be used to solve DyPDL models and propose seven DIDP solvers. We experimentally compare our DIDP solvers with commercial MIP and CP solvers (solving MIP and CP models, respectively) on common benchmark instances of eleven combinatorial optimization problem classes. We show that DIDP outperforms MIP in nine problem classes, CP also in nine problem classes, and 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#37327;&#23376;&#26497;&#22352;&#26631;&#24230;&#37327;&#23398;&#20064;(QPMeL)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32463;&#20856;&#27169;&#22411;&#23398;&#20064;&#37327;&#23376;&#27604;&#29305;&#30340;&#26497;&#22352;&#26631;&#24418;&#24335;&#30340;&#21442;&#25968;&#65292;&#28982;&#21518;&#20351;&#29992;&#27973;&#23618;PQC&#21644;&#21487;&#35757;&#32451;&#30340;&#38376;&#23618;&#26469;&#21019;&#24314;&#37327;&#23376;&#24577;&#21644;&#23398;&#20064;&#32416;&#32544;&#12290;&#19982;QMeL&#30456;&#27604;&#65292;QPMeL&#20855;&#26377;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.01655</link><description>&lt;p&gt;
&#37327;&#23376;&#26497;&#22352;&#26631;&#24230;&#37327;&#23398;&#20064;: &#39640;&#25928;&#32463;&#20856;&#23398;&#20064;&#30340;&#37327;&#23376;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Quantum Polar Metric Learning: Efficient Classically Learned Quantum Embeddings. (arXiv:2312.01655v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#37327;&#23376;&#26497;&#22352;&#26631;&#24230;&#37327;&#23398;&#20064;(QPMeL)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32463;&#20856;&#27169;&#22411;&#23398;&#20064;&#37327;&#23376;&#27604;&#29305;&#30340;&#26497;&#22352;&#26631;&#24418;&#24335;&#30340;&#21442;&#25968;&#65292;&#28982;&#21518;&#20351;&#29992;&#27973;&#23618;PQC&#21644;&#21487;&#35757;&#32451;&#30340;&#38376;&#23618;&#26469;&#21019;&#24314;&#37327;&#23376;&#24577;&#21644;&#23398;&#20064;&#32416;&#32544;&#12290;&#19982;QMeL&#30456;&#27604;&#65292;QPMeL&#20855;&#26377;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#22312;&#32463;&#20856;&#25968;&#25454;&#33539;&#30068;&#20013;&#34920;&#29616;&#20986;&#26497;&#26377;&#28508;&#21147;&#30340;&#32467;&#26524;&#65292;&#21019;&#24314;&#20102;&#20998;&#31163;&#26126;&#26174;&#30340;&#29305;&#24449;&#31354;&#38388;&#12290;&#36825;&#20010;&#24819;&#27861;&#20063;&#34987;&#24212;&#29992;&#21040;&#37327;&#23376;&#35745;&#31639;&#26426;&#20013;&#65292;&#36890;&#36807;&#37327;&#23376;&#24230;&#37327;&#23398;&#20064;(QMeL)&#12290;QMeL&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65292;&#39318;&#20808;&#20351;&#29992;&#32463;&#20856;&#27169;&#22411;&#23558;&#25968;&#25454;&#21387;&#32553;&#20197;&#36866;&#24212;&#26377;&#38480;&#25968;&#37327;&#30340;&#37327;&#23376;&#27604;&#29305;&#65292;&#28982;&#21518;&#20351;&#29992;&#21442;&#25968;&#21270;&#37327;&#23376;&#30005;&#36335;(PQC)&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#21019;&#24314;&#26356;&#22909;&#30340;&#20998;&#31163;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#22024;&#26434;&#20013;&#38388;&#35268;&#27169;&#37327;&#23376;(NISQ)&#35774;&#22791;&#19978;&#65292;QMeL&#35299;&#20915;&#26041;&#26696;&#23548;&#33268;&#30005;&#36335;&#23485;&#24230;&#21644;&#28145;&#24230;&#36739;&#22823;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#37327;&#23376;&#26497;&#22352;&#26631;&#24230;&#37327;&#23398;&#20064;(QPMeL)&#30340;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#32463;&#20856;&#27169;&#22411;&#23398;&#20064;&#19968;&#20010;&#37327;&#23376;&#27604;&#29305;&#30340;&#26497;&#22352;&#26631;&#24418;&#24335;&#30340;&#21442;&#25968;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20165;&#21253;&#21547;$R_y$&#21644;$R_z$&#38376;&#30340;&#27973;&#23618;PQC&#21019;&#24314;&#37327;&#23376;&#24577;&#65292;&#24182;&#21033;&#29992;&#21487;&#35757;&#32451;&#30340;$ZZ(\theta)$&#38376;&#23618;&#23398;&#20064;&#32416;&#32544;&#12290;&#30005;&#36335;&#36824;&#36890;&#36807;SWAP&#27979;&#35797;&#35745;&#31639;&#20445;&#30495;&#24230;&#65292;&#29992;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#20445;&#30495;&#24230;&#19977;&#20803;&#25439;&#22833;&#20989;&#25968;&#30340;&#35757;&#32451;&#65292;&#29992;&#20110;&#21516;&#26102;&#35757;&#32451;&#32463;&#20856;&#21644;&#37327;&#23376;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep metric learning has recently shown extremely promising results in the classical data domain, creating well-separated feature spaces. This idea was also adapted to quantum computers via Quantum Metric Learning(QMeL). QMeL consists of a 2 step process with a classical model to compress the data to fit into the limited number of qubits, then train a Parameterized Quantum Circuit(PQC) to create better separation in Hilbert Space. However, on Noisy Intermediate Scale Quantum (NISQ) devices. QMeL solutions result in high circuit width and depth, both of which limit scalability. We propose Quantum Polar Metric Learning (QPMeL) that uses a classical model to learn the parameters of the polar form of a qubit. We then utilize a shallow PQC with $R_y$ and $R_z$ gates to create the state and a trainable layer of $ZZ(\theta)$-gates to learn entanglement. The circuit also computes fidelity via a SWAP Test for our proposed Fidelity Triplet Loss function, used to train both classical and quantum 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#30340;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#39537;&#21160;&#30340;&#26816;&#27979;&#19982;&#36716;&#25442;&#65288;IT-DT&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#22312;&#26816;&#27979;&#21644;&#36716;&#25442;&#25991;&#26412;&#23545;&#25239;&#31034;&#20363;&#26041;&#38754;&#27880;&#37325;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#21033;&#29992;&#20102;&#27880;&#24847;&#21147;&#22270;&#12289;&#38598;&#25104;&#26799;&#24230;&#21644;&#27169;&#22411;&#21453;&#39304;&#31561;&#25216;&#26415;&#65292;&#22312;&#26816;&#27979;&#38454;&#27573;&#26377;&#21161;&#20110;&#35782;&#21035;&#23545;&#23545;&#25239;&#24615;&#20998;&#31867;&#26377;&#36129;&#29486;&#30340;&#26174;&#33879;&#29305;&#24449;&#21644;&#25200;&#21160;&#35789;&#35821;&#65292;&#24182;&#22312;&#36716;&#25442;&#38454;&#27573;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#23884;&#20837;&#21644;&#27169;&#22411;&#21453;&#39304;&#26469;&#29983;&#25104;&#25200;&#21160;&#35789;&#35821;&#30340;&#26368;&#20339;&#26367;&#20195;&#65292;&#20197;&#23558;&#23545;&#25239;&#24615;&#31034;&#20363;&#36716;&#25442;&#20026;&#27491;&#24120;&#31034;&#20363;&#12290;</title><link>http://arxiv.org/abs/2307.01225</link><description>&lt;p&gt;
&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#39537;&#21160;&#30340;&#25991;&#26412;&#23545;&#25239;&#31034;&#20363;&#30340;&#26816;&#27979;&#19982;&#36716;&#25442;&#65288;IT-DT&#65289;
&lt;/p&gt;
&lt;p&gt;
Interpretability and Transparency-Driven Detection and Transformation of Textual Adversarial Examples (IT-DT). (arXiv:2307.01225v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01225
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#30340;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#39537;&#21160;&#30340;&#26816;&#27979;&#19982;&#36716;&#25442;&#65288;IT-DT&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#22312;&#26816;&#27979;&#21644;&#36716;&#25442;&#25991;&#26412;&#23545;&#25239;&#31034;&#20363;&#26041;&#38754;&#27880;&#37325;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#21033;&#29992;&#20102;&#27880;&#24847;&#21147;&#22270;&#12289;&#38598;&#25104;&#26799;&#24230;&#21644;&#27169;&#22411;&#21453;&#39304;&#31561;&#25216;&#26415;&#65292;&#22312;&#26816;&#27979;&#38454;&#27573;&#26377;&#21161;&#20110;&#35782;&#21035;&#23545;&#23545;&#25239;&#24615;&#20998;&#31867;&#26377;&#36129;&#29486;&#30340;&#26174;&#33879;&#29305;&#24449;&#21644;&#25200;&#21160;&#35789;&#35821;&#65292;&#24182;&#22312;&#36716;&#25442;&#38454;&#27573;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#23884;&#20837;&#21644;&#27169;&#22411;&#21453;&#39304;&#26469;&#29983;&#25104;&#25200;&#21160;&#35789;&#35821;&#30340;&#26368;&#20339;&#26367;&#20195;&#65292;&#20197;&#23558;&#23545;&#25239;&#24615;&#31034;&#20363;&#36716;&#25442;&#20026;&#27491;&#24120;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#25991;&#26412;&#20998;&#31867;&#22120;&#22914;BERT&#12289;Roberta&#12289;T5&#21644;GPT-3&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#23545;&#20110;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#33030;&#24369;&#24615;&#25552;&#20986;&#20102;&#23433;&#20840;&#39118;&#38505;&#12290;&#29616;&#26377;&#30340;&#38450;&#24481;&#26041;&#27861;&#32570;&#20047;&#35299;&#37322;&#24615;&#65292;&#24456;&#38590;&#29702;&#35299;&#23545;&#25239;&#24615;&#20998;&#31867;&#24182;&#35782;&#21035;&#27169;&#22411;&#30340;&#28431;&#27934;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#39537;&#21160;&#30340;&#26816;&#27979;&#19982;&#36716;&#25442;&#65288;IT-DT&#65289;&#26694;&#26550;&#12290;&#23427;&#19987;&#27880;&#20110;&#22312;&#26816;&#27979;&#21644;&#36716;&#25442;&#25991;&#26412;&#23545;&#25239;&#31034;&#20363;&#26102;&#30340;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#12290;IT-DT&#21033;&#29992;&#27880;&#24847;&#21147;&#22270;&#12289;&#38598;&#25104;&#26799;&#24230;&#21644;&#27169;&#22411;&#21453;&#39304;&#31561;&#25216;&#26415;&#36827;&#34892;&#35299;&#37322;&#24615;&#26816;&#27979;&#12290;&#36825;&#26377;&#21161;&#20110;&#35782;&#21035;&#23545;&#23545;&#25239;&#24615;&#20998;&#31867;&#26377;&#36129;&#29486;&#30340;&#26174;&#33879;&#29305;&#24449;&#21644;&#25200;&#21160;&#35789;&#35821;&#12290;&#22312;&#36716;&#25442;&#38454;&#27573;&#65292;IT-DT&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#23884;&#20837;&#21644;&#27169;&#22411;&#21453;&#39304;&#26469;&#29983;&#25104;&#25200;&#21160;&#35789;&#35821;&#30340;&#26368;&#20339;&#26367;&#20195;&#12290;&#36890;&#36807;&#25214;&#21040;&#21512;&#36866;&#30340;&#26367;&#25442;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23558;&#23545;&#25239;&#24615;&#31034;&#20363;&#36716;&#25442;&#20026;&#27491;&#24120;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer-based text classifiers like BERT, Roberta, T5, and GPT-3 have shown impressive performance in NLP. However, their vulnerability to adversarial examples poses a security risk. Existing defense methods lack interpretability, making it hard to understand adversarial classifications and identify model vulnerabilities. To address this, we propose the Interpretability and Transparency-Driven Detection and Transformation (IT-DT) framework. It focuses on interpretability and transparency in detecting and transforming textual adversarial examples. IT-DT utilizes techniques like attention maps, integrated gradients, and model feedback for interpretability during detection. This helps identify salient features and perturbed words contributing to adversarial classifications. In the transformation phase, IT-DT uses pre-trained embeddings and model feedback to generate optimal replacements for perturbed words. By finding suitable substitutions, we aim to convert adversarial examples into
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22478;&#24066;&#35268;&#21010;&#19982;&#20154;&#24037;&#26234;&#33021;&#30340;&#20132;&#21449;&#24212;&#29992;&#65292;&#37325;&#28857;&#26159;&#33258;&#21160;&#21270;&#29992;&#22320;&#37197;&#32622;&#65292;&#36890;&#36807;&#23545;&#25239;&#23398;&#20064;&#12289;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#12289;&#28145;&#24230;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#12289;&#23545;&#35805;&#24335; AI &#21644;&#22320;&#29702;&#31354;&#38388;&#21644;&#26102;&#38388;&#26426;&#22120;&#23398;&#20064;&#31561;&#25216;&#26415;&#65292;AI &#21487;&#20197;&#20026;&#29616;&#20195;&#22478;&#24066;&#35268;&#21010;&#24102;&#26469;&#19981;&#23569;&#21019;&#26032;&#19982;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2304.03892</link><description>&lt;p&gt;
&#33258;&#21160;&#21270;&#22478;&#24066;&#35268;&#21010;&#65306;&#29983;&#25104;&#24335;&#21644;&#32842;&#22825;&#24335; AI &#30456;&#32467;&#21512;&#30340;&#22478;&#24066;&#35268;&#21010;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Towards Automated Urban Planning: When Generative and ChatGPT-like AI Meets Urban Planning. (arXiv:2304.03892v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22478;&#24066;&#35268;&#21010;&#19982;&#20154;&#24037;&#26234;&#33021;&#30340;&#20132;&#21449;&#24212;&#29992;&#65292;&#37325;&#28857;&#26159;&#33258;&#21160;&#21270;&#29992;&#22320;&#37197;&#32622;&#65292;&#36890;&#36807;&#23545;&#25239;&#23398;&#20064;&#12289;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#12289;&#28145;&#24230;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#12289;&#23545;&#35805;&#24335; AI &#21644;&#22320;&#29702;&#31354;&#38388;&#21644;&#26102;&#38388;&#26426;&#22120;&#23398;&#20064;&#31561;&#25216;&#26415;&#65292;AI &#21487;&#20197;&#20026;&#29616;&#20195;&#22478;&#24066;&#35268;&#21010;&#24102;&#26469;&#19981;&#23569;&#21019;&#26032;&#19982;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22478;&#24066;&#35268;&#21010;&#39046;&#22495;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#26366;&#32463;&#26159;&#29420;&#31435;&#21457;&#23637;&#30340;&#65292;&#20294;&#29616;&#22312;&#20004;&#20010;&#39046;&#22495;&#24320;&#22987;&#20132;&#21449;&#27719;&#21512;&#65292;&#20114;&#30456;&#20511;&#37492;&#21644;&#21463;&#30410;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22478;&#24066;&#35268;&#21010;&#20174;&#21487;&#25345;&#32493;&#24615;&#12289;&#29983;&#27963;&#12289;&#32463;&#27982;&#12289;&#28798;&#23475;&#21644;&#29615;&#22659;&#31561;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65292;&#22238;&#39038;&#20102;&#22478;&#24066;&#35268;&#21010;&#30340;&#22522;&#26412;&#27010;&#24565;&#65292;&#24182;&#23558;&#36825;&#20123;&#27010;&#24565;&#19982;&#26426;&#22120;&#23398;&#20064;&#30340;&#20851;&#38190;&#24320;&#25918;&#38382;&#39064;&#32852;&#31995;&#36215;&#26469;&#65292;&#21253;&#25324;&#23545;&#25239;&#23398;&#20064;&#12289;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#12289;&#28145;&#24230;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#12289;&#23545;&#35805;&#24335; AI &#20197;&#21450;&#22320;&#29702;&#31354;&#38388;&#21644;&#26102;&#38388;&#26426;&#22120;&#23398;&#20064;&#31561;&#65292;&#35780;&#20272;&#20102; AI &#22914;&#20309;&#20026;&#29616;&#20195;&#22478;&#24066;&#35268;&#21010;&#20570;&#20986;&#36129;&#29486;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#33258;&#21160;&#21270;&#29992;&#22320;&#37197;&#32622;&#65292;&#21363;&#20174;&#21608;&#22260;&#30340;&#22320;&#29702;&#31354;&#38388;&#12289;&#20154;&#31867;&#31227;&#21160;&#12289;&#31038;&#20132;&#23186;&#20307;&#12289;&#29615;&#22659;&#21644;&#32463;&#27982;&#27963;&#21160;&#20013;&#20026;&#30446;&#26631;&#21306;&#22495;&#29983;&#25104;&#22303;&#22320;&#29992;&#36884;&#21644;&#24314;&#31569;&#37197;&#32622;&#12290;&#26368;&#21518;&#65292;&#26412;&#25991;&#21246;&#30011;&#20102;&#38598;&#25104; AI &#21644;&#22478;&#24066;&#35268;&#21010;&#38754;&#20020;&#30340;&#19968;&#20123;&#25361;&#25112;&#21644;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
The two fields of urban planning and artificial intelligence (AI) arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we introduce the importance of urban planning from the sustainability, living, economic, disaster, and environmental perspectives. We review the fundamental concepts of urban planning and relate these concepts to crucial open problems of machine learning, including adversarial learning, generative neural networks, deep encoder-decoder networks, conversational AI, and geospatial and temporal machine learning, thereby assaying how AI can contribute to modern urban planning. Thus, a central problem is automated land-use configuration, which is formulated as the generation of land uses and building configuration for a target area from surrounding geospatial, human mobility, social media, environment, and economic activities. Finally, we delineate some 
&lt;/p&gt;</description></item></channel></rss>