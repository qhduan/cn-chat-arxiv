<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#20256;&#23548;&#30693;&#35782;&#22270;&#23884;&#20837;&#26041;&#27861;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#24402;&#32435;&#25512;&#29702;&#20219;&#21153;&#12290;&#36890;&#36807;&#24341;&#20837;&#24191;&#20041;&#30340;&#35856;&#27874;&#25193;&#23637;&#65292;&#21033;&#29992;&#20256;&#23548;&#23884;&#20837;&#26041;&#27861;&#23398;&#20064;&#30340;&#34920;&#31034;&#26469;&#25512;&#26029;&#22312;&#25512;&#29702;&#26102;&#24341;&#20837;&#30340;&#26032;&#23454;&#20307;&#30340;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2309.03773</link><description>&lt;p&gt;
&#25193;&#23637;&#20256;&#23548;&#30693;&#35782;&#22270;&#23884;&#20837;&#27169;&#22411;&#29992;&#20110;&#24402;&#32435;&#36923;&#36753;&#20851;&#31995;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Extending Transductive Knowledge Graph Embedding Models for Inductive Logical Relational Inference. (arXiv:2309.03773v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03773
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#20256;&#23548;&#30693;&#35782;&#22270;&#23884;&#20837;&#26041;&#27861;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#24402;&#32435;&#25512;&#29702;&#20219;&#21153;&#12290;&#36890;&#36807;&#24341;&#20837;&#24191;&#20041;&#30340;&#35856;&#27874;&#25193;&#23637;&#65292;&#21033;&#29992;&#20256;&#23548;&#23884;&#20837;&#26041;&#27861;&#23398;&#20064;&#30340;&#34920;&#31034;&#26469;&#25512;&#26029;&#22312;&#25512;&#29702;&#26102;&#24341;&#20837;&#30340;&#26032;&#23454;&#20307;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#30693;&#35782;&#22270;&#30340;&#19979;&#28216;&#25512;&#29702;&#20219;&#21153;&#65292;&#20363;&#22914;&#20851;&#31995;&#39044;&#27979;&#65292;&#22312;&#20256;&#23548;&#35774;&#32622;&#19979;&#24050;&#32463;&#25104;&#21151;&#22788;&#29702;&#20102;&#12290;&#20026;&#20102;&#22788;&#29702;&#24402;&#32435;&#35774;&#32622;&#65292;&#20063;&#23601;&#26159;&#22312;&#25512;&#29702;&#26102;&#24341;&#20837;&#26032;&#23454;&#20307;&#21040;&#30693;&#35782;&#22270;&#20013;&#65292;&#36739;&#26032;&#30340;&#24037;&#20316;&#36873;&#25321;&#20102;&#36890;&#36807;&#32593;&#32476;&#23376;&#22270;&#32467;&#26500;&#30340;&#22797;&#26434;&#20989;&#25968;&#23398;&#20064;&#30693;&#35782;&#22270;&#30340;&#38544;&#24335;&#34920;&#31034;&#30340;&#27169;&#22411;&#65292;&#36890;&#24120;&#30001;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21442;&#25968;&#21270;&#12290;&#36825;&#20123;&#27169;&#22411;&#30340;&#25104;&#26412;&#26159;&#22686;&#21152;&#30340;&#21442;&#25968;&#21270;&#12289;&#38477;&#20302;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#23545;&#20854;&#20182;&#19979;&#28216;&#25512;&#29702;&#20219;&#21153;&#30340;&#26377;&#38480;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#24191;&#20041;&#30340;&#35856;&#27874;&#25193;&#23637;&#26469;&#24357;&#21512;&#20256;&#32479;&#20256;&#23548;&#30693;&#35782;&#22270;&#23884;&#20837;&#26041;&#27861;&#21644;&#36739;&#26032;&#30340;&#24402;&#32435;&#20851;&#31995;&#39044;&#27979;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#36890;&#36807;&#21033;&#29992;&#36890;&#36807;&#20256;&#23548;&#23884;&#20837;&#26041;&#27861;&#23398;&#20064;&#30340;&#34920;&#31034;&#26469;&#25512;&#26029;&#22312;&#25512;&#29702;&#26102;&#24341;&#20837;&#30340;&#26032;&#23454;&#20307;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many downstream inference tasks for knowledge graphs, such as relation prediction, have been handled successfully by knowledge graph embedding techniques in the transductive setting. To address the inductive setting wherein new entities are introduced into the knowledge graph at inference time, more recent work opts for models which learn implicit representations of the knowledge graph through a complex function of a network's subgraph structure, often parametrized by graph neural network architectures. These come at the cost of increased parametrization, reduced interpretability and limited generalization to other downstream inference tasks. In this work, we bridge the gap between traditional transductive knowledge graph embedding approaches and more recent inductive relation prediction models by introducing a generalized form of harmonic extension which leverages representations learned through transductive embedding methods to infer representations of new entities introduced at infe
&lt;/p&gt;</description></item><item><title>SUNG&#26159;&#19968;&#31181;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#24341;&#23548;&#30340;&#31163;&#32447;&#21040;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#36890;&#36807;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#25506;&#32034;&#21644;&#24212;&#29992;&#20445;&#23432;Q&#20540;&#20272;&#35745;&#30340;&#25351;&#23548;&#19979;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#32769;&#21270;&#24378;&#21270;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2306.07541</link><description>&lt;p&gt;
&#19968;&#31181;&#31616;&#21333;&#32479;&#19968;&#30340;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#24341;&#23548;&#30340;&#31163;&#32447;&#21040;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Simple Unified Uncertainty-Guided Framework for Offline-to-Online Reinforcement Learning. (arXiv:2306.07541v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07541
&lt;/p&gt;
&lt;p&gt;
SUNG&#26159;&#19968;&#31181;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#24341;&#23548;&#30340;&#31163;&#32447;&#21040;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#36890;&#36807;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#25506;&#32034;&#21644;&#24212;&#29992;&#20445;&#23432;Q&#20540;&#20272;&#35745;&#30340;&#25351;&#23548;&#19979;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#32769;&#21270;&#24378;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20026;&#20381;&#38752;&#25968;&#25454;&#39537;&#21160;&#33539;&#20363;&#23398;&#20064;&#26234;&#33021;&#20307;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290; &#28982;&#32780;&#65292;&#21463;&#38480;&#20110;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#26377;&#38480;&#36136;&#37327;&#65292;&#20854;&#24615;&#33021;&#24120;&#24120;&#19981;&#22815;&#20248;&#31168;&#12290;&#22240;&#27492;&#65292;&#22312;&#37096;&#32626;&#20043;&#21069;&#36890;&#36807;&#39069;&#22806;&#30340;&#22312;&#32447;&#20132;&#20114;&#36827;&#19968;&#27493;&#24494;&#35843;&#26234;&#33021;&#20307;&#26159;&#26377;&#24517;&#35201;&#30340;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30001;&#20110;&#21463;&#21040;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#30340;&#21046;&#32422;&#65292;&#21363;&#21463;&#38480;&#30340;&#25506;&#32034;&#34892;&#20026;&#21644;&#29366;&#24577;-&#21160;&#20316;&#20998;&#24067;&#20559;&#31227;&#65292;&#31163;&#32447;&#21040;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32479;&#19968;&#30340;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#24341;&#23548;&#30340;&#65288;SUNG&#65289;&#26694;&#26550;&#65292;&#20854;&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#24037;&#20855;&#33258;&#28982;&#22320;&#32479;&#19968;&#20102;&#36825;&#20004;&#20010;&#25361;&#25112;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SUNG&#36890;&#36807;&#22522;&#20110;VAE&#30340;&#29366;&#24577;-&#21160;&#20316;&#35775;&#38382;&#23494;&#24230;&#20272;&#35745;&#22120;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#20419;&#36827;&#39640;&#25928;&#25506;&#32034;&#65292;SUNG&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#20048;&#35266;&#25506;&#32034;&#31574;&#30053;&#65292;&#20197;&#36873;&#25321;&#20855;&#26377;&#39640;&#20215;&#20540;&#21644;&#39640;&#19981;&#30830;&#23450;&#24615;&#30340;&#20449;&#24687;&#21160;&#20316;&#12290;&#27492;&#22806;&#65292;SUNG&#36890;&#36807;&#22312;&#19981;&#30830;&#23450;&#24615;&#25351;&#23548;&#19979;&#24212;&#29992;&#20445;&#23432;Q&#20540;&#20272;&#35745;&#26469;&#24320;&#21457;&#19968;&#31181;&#33258;&#36866;&#24212;&#21033;&#29992;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;Atari&#21644;MuJoCo&#22522;&#20934;&#27979;&#35797;&#19978;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;SUNG&#22987;&#32456;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31163;&#32447;&#21040;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#25509;&#36817;&#22312;&#32447;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL) provides a promising solution to learning an agent fully relying on a data-driven paradigm. However, constrained by the limited quality of the offline dataset, its performance is often sub-optimal. Therefore, it is desired to further finetune the agent via extra online interactions before deployment. Unfortunately, offline-to-online RL can be challenging due to two main challenges: constrained exploratory behavior and state-action distribution shift. To this end, we propose a Simple Unified uNcertainty-Guided (SUNG) framework, which naturally unifies the solution to both challenges with the tool of uncertainty. Specifically, SUNG quantifies uncertainty via a VAE-based state-action visitation density estimator. To facilitate efficient exploration, SUNG presents a practical optimistic exploration strategy to select informative actions with both high value and high uncertainty. Moreover, SUNG develops an adaptive exploitation method by applying conserva
&lt;/p&gt;</description></item></channel></rss>