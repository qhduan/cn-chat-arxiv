<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#26159;&#20855;&#26377;&#19968;&#23450;&#28508;&#21147;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.16851</link><description>&lt;p&gt;
ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can ChatGPT predict article retraction based on Twitter mentions?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#26159;&#20855;&#26377;&#19968;&#23450;&#28508;&#21147;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#26377;&#38382;&#39064;&#30340;&#30740;&#31350;&#25991;&#31456;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26681;&#25454;&#34987;&#25764;&#22238;&#25991;&#31456;&#22312;Twitter&#19978;&#30340;&#25552;&#21450;&#26159;&#21542;&#33021;&#22815;&#22312;&#25991;&#31456;&#34987;&#25764;&#22238;&#21069;&#21457;&#20986;&#20449;&#21495;&#65292;&#20174;&#32780;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;&#20998;&#26512;&#20102;&#21253;&#25324;3,505&#31687;&#24050;&#25764;&#22238;&#25991;&#31456;&#21450;&#20854;&#30456;&#20851;Twitter&#25552;&#21450;&#22312;&#20869;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#20351;&#29992;&#31895;&#31961;&#31934;&#30830;&#21305;&#37197;&#26041;&#27861;&#33719;&#21462;&#30340;&#20855;&#26377;&#31867;&#20284;&#29305;&#24449;&#30340;3,505&#31687;&#26410;&#25764;&#22238;&#25991;&#31456;&#12290;&#36890;&#36807;&#22235;&#31181;&#39044;&#27979;&#26041;&#27861;&#35780;&#20272;&#20102;Twitter&#25552;&#21450;&#22312;&#39044;&#27979;&#25991;&#31456;&#25764;&#22238;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#25163;&#21160;&#26631;&#27880;&#12289;&#20851;&#38190;&#35789;&#35782;&#21035;&#12289;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;ChatGPT&#12290;&#25163;&#21160;&#26631;&#27880;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#30340;&#30830;&#26377;&#34987;&#25764;&#22238;&#30340;&#25991;&#31456;&#65292;&#20854;Twitter&#25552;&#21450;&#21253;&#21547;&#22312;&#25764;&#22238;&#21069;&#21457;&#20986;&#20449;&#21495;&#30340;&#21487;&#35782;&#21035;&#35777;&#25454;&#65292;&#23613;&#31649;&#23427;&#20204;&#21482;&#21344;&#25152;&#26377;&#34987;&#25764;&#22238;&#25991;&#31456;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16851v1 Announce Type: cross  Abstract: Detecting problematic research articles timely is a vital task. This study explores whether Twitter mentions of retracted articles can signal potential problems with the articles prior to retraction, thereby playing a role in predicting future retraction of problematic articles. A dataset comprising 3,505 retracted articles and their associated Twitter mentions is analyzed, alongside 3,505 non-retracted articles with similar characteristics obtained using the Coarsened Exact Matching method. The effectiveness of Twitter mentions in predicting article retraction is evaluated by four prediction methods, including manual labelling, keyword identification, machine learning models, and ChatGPT. Manual labelling results indicate that there are indeed retracted articles with their Twitter mentions containing recognizable evidence signaling problems before retraction, although they represent only a limited share of all retracted articles with 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#30340;&#20381;&#36182;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#36866;&#24403;&#20381;&#36182;&#12290;&#35813;&#23450;&#20041;&#20998;&#31163;&#20102;&#20381;&#36182;&#30340;&#27010;&#24565;&#21644;&#20154;&#31867;&#22312;&#24418;&#25104;&#20934;&#30830;&#20449;&#24565;&#26102;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#20026;&#20154;&#31867;&#19982;&#20154;&#24037;&#26234;&#33021;&#20114;&#34917;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#30740;&#31350;&#35774;&#35745;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2401.15356</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#20381;&#36182;&#30340;&#32479;&#35745;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Statistical Framework for Measuring AI Reliance. (arXiv:2401.15356v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15356
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#30340;&#20381;&#36182;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#36866;&#24403;&#20381;&#36182;&#12290;&#35813;&#23450;&#20041;&#20998;&#31163;&#20102;&#20381;&#36182;&#30340;&#27010;&#24565;&#21644;&#20154;&#31867;&#22312;&#24418;&#25104;&#20934;&#30830;&#20449;&#24565;&#26102;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#20026;&#20154;&#31867;&#19982;&#20154;&#24037;&#26234;&#33021;&#20114;&#34917;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#30740;&#31350;&#35774;&#35745;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#32463;&#24120;&#22312;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#24110;&#21161;&#19979;&#20570;&#20915;&#31574;&#12290;&#19968;&#20010;&#24120;&#35265;&#27169;&#24335;&#26159;&#20154;&#24037;&#26234;&#33021;&#21521;&#20154;&#31867;&#25512;&#33616;&#34892;&#21160;&#65292;&#32780;&#20154;&#31867;&#20445;&#30041;&#23545;&#26368;&#32456;&#20915;&#31574;&#30340;&#25511;&#21046;&#26435;&#12290;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#30830;&#35748;&#65292;&#30830;&#20445;&#20154;&#31867;&#23545;&#20154;&#24037;&#26234;&#33021;&#30340;&#36866;&#24403;&#20381;&#36182;&#26159;&#23454;&#29616;&#20114;&#34917;&#24615;&#33021;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#30446;&#21069;&#22312;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#20013;&#20351;&#29992;&#30340;&#36866;&#24403;&#20381;&#36182;&#30340;&#23450;&#20041;&#32570;&#20047;&#24418;&#24335;&#21270;&#30340;&#32479;&#35745;&#22522;&#30784;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#30683;&#30462;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#30340;&#20381;&#36182;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#23427;&#23558;&#20381;&#36182;&#30340;&#27010;&#24565;&#19982;&#20154;&#31867;&#22312;&#21306;&#20998;&#20449;&#21495;&#24182;&#24418;&#25104;&#20934;&#30830;&#20449;&#24565;&#30340;&#25361;&#25112;&#20998;&#24320;&#12290;&#25105;&#20204;&#30340;&#23450;&#20041;&#20135;&#29983;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#26469;&#25351;&#23548;&#20154;&#31867;&#19982;&#20154;&#24037;&#26234;&#33021;&#20114;&#34917;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#30740;&#31350;&#35774;&#35745;&#21644;&#35299;&#37322;&#12290;&#21033;&#29992;&#26368;&#36817;&#30340;&#20154;&#24037;&#26234;&#33021;&#36741;&#21161;&#20915;&#31574;&#30740;&#31350;...
&lt;/p&gt;
&lt;p&gt;
Humans frequently make decisions with the aid of artificially intelligent (AI) systems. A common pattern is for the AI to recommend an action to the human who retains control over the final decision. Researchers have identified ensuring that a human has appropriate reliance on an AI as a critical component of achieving complementary performance. We argue that the current definition of appropriate reliance used in such research lacks formal statistical grounding and can lead to contradictions. We propose a formal definition of reliance, based on statistical decision theory, which separates the concepts of reliance as the probability the decision-maker follows the AI's prediction from challenges a human may face in differentiating the signals and forming accurate beliefs about the situation. Our definition gives rise to a framework that can be used to guide the design and interpretation of studies on human-AI complementarity and reliance. Using recent AI-advised decision making studies f
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23545;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#65288;AGI&#65289;&#27169;&#22411;&#21450;&#20854;&#21069;&#39537;&#36827;&#34892;&#20998;&#31867;&#12290;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19981;&#21516;&#23618;&#27425;&#30340;AGI&#24615;&#33021;&#12289;&#24191;&#27867;&#24615;&#21644;&#33258;&#20027;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#20849;&#21516;&#30340;&#35821;&#35328;&#29992;&#20110;&#27604;&#36739;&#27169;&#22411;&#12289;&#35780;&#20272;&#39118;&#38505;&#65292;&#24182;&#34913;&#37327;&#22312;AGI&#36335;&#24452;&#19978;&#30340;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2311.02462</link><description>&lt;p&gt;
AGI&#30340;&#23618;&#27425;&#65306;&#23558;AGI&#36335;&#24452;&#19978;&#30340;&#36827;&#23637;&#21487;&#25805;&#20316;&#21270;
&lt;/p&gt;
&lt;p&gt;
Levels of AGI: Operationalizing Progress on the Path to AGI. (arXiv:2311.02462v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23545;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#65288;AGI&#65289;&#27169;&#22411;&#21450;&#20854;&#21069;&#39537;&#36827;&#34892;&#20998;&#31867;&#12290;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19981;&#21516;&#23618;&#27425;&#30340;AGI&#24615;&#33021;&#12289;&#24191;&#27867;&#24615;&#21644;&#33258;&#20027;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#20849;&#21516;&#30340;&#35821;&#35328;&#29992;&#20110;&#27604;&#36739;&#27169;&#22411;&#12289;&#35780;&#20272;&#39118;&#38505;&#65292;&#24182;&#34913;&#37327;&#22312;AGI&#36335;&#24452;&#19978;&#30340;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#65288;AGI&#65289;&#27169;&#22411;&#21450;&#20854;&#21069;&#39537;&#30340;&#33021;&#21147;&#21644;&#34892;&#20026;&#36827;&#34892;&#20998;&#31867;&#12290;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;AGI&#24615;&#33021;&#12289;&#24191;&#27867;&#24615;&#21644;&#33258;&#20027;&#24615;&#30340;&#23618;&#27425;&#12290;&#25105;&#20204;&#24076;&#26395;&#36825;&#20010;&#26694;&#26550;&#33021;&#22815;&#20687;&#33258;&#21160;&#39550;&#39542;&#30340;&#23618;&#27425;&#19968;&#26679;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#20849;&#21516;&#30340;&#35821;&#35328;&#26469;&#27604;&#36739;&#27169;&#22411;&#12289;&#35780;&#20272;&#39118;&#38505;&#65292;&#24182;&#34913;&#37327;&#22312;AGI&#36335;&#24452;&#19978;&#30340;&#36827;&#23637;&#12290;&#20026;&#20102;&#24320;&#21457;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;AGI&#23450;&#20041;&#65292;&#24182;&#25552;&#21462;&#20986;&#20102;&#19968;&#20010;&#26377;&#29992;&#30340;AGI&#26412;&#20307;&#35770;&#24212;&#28385;&#36275;&#30340;&#20845;&#20010;&#21407;&#21017;&#12290;&#36825;&#20123;&#21407;&#21017;&#21253;&#25324;&#20851;&#27880;&#33021;&#21147;&#32780;&#19981;&#26159;&#26426;&#21046;&#65307;&#20998;&#21035;&#35780;&#20272;&#24191;&#27867;&#24615;&#21644;&#24615;&#33021;&#65307;&#23450;&#20041;AGI&#36335;&#24452;&#19978;&#30340;&#38454;&#27573;&#65292;&#32780;&#19981;&#26159;&#19987;&#27880;&#20110;&#32456;&#28857;&#12290;&#22522;&#20110;&#36825;&#20123;&#21407;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;AGI&#30340;&#23618;&#27425;&#8221;&#65292;&#26681;&#25454;&#33021;&#21147;&#30340;&#28145;&#24230;&#65288;&#24615;&#33021;&#65289;&#21644;&#24191;&#24230;&#65288;&#24191;&#27867;&#24615;&#65289;&#65292;&#24182;&#24605;&#32771;&#24403;&#21069;&#31995;&#32479;&#22914;&#20309;&#31526;&#21512;&#36825;&#20010;&#26412;&#20307;&#35770;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#23545;&#23454;&#29616;AGI&#25152;&#25552;&#20986;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a framework for classifying the capabilities and behavior of Artificial General Intelligence (AGI) models and their precursors. This framework introduces levels of AGI performance, generality, and autonomy. It is our hope that this framework will be useful in an analogous way to the levels of autonomous driving, by providing a common language to compare models, assess risks, and measure progress along the path to AGI. To develop our framework, we analyze existing definitions of AGI, and distill six principles that a useful ontology for AGI should satisfy. These principles include focusing on capabilities rather than mechanisms; separately evaluating generality and performance; and defining stages along the path toward AGI, rather than focusing on the endpoint. With these principles in mind, we propose 'Levels of AGI' based on depth (performance) and breadth (generality) of capabilities, and reflect on how current systems fit into this ontology. We discuss the challenging req
&lt;/p&gt;</description></item></channel></rss>