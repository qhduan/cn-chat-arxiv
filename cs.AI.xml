<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>ChatDBG&#26159;&#31532;&#19968;&#20010;AI-Powered&#35843;&#35797;&#21161;&#25163;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21040;&#20256;&#32479;&#35843;&#35797;&#22120;&#20013;&#65292;&#23454;&#29616;&#20102;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#23545;&#35805;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#12289;&#25191;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;</title><link>https://arxiv.org/abs/2403.16354</link><description>&lt;p&gt;
ChatDBG: &#19968;&#31181;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35843;&#35797;&#21161;&#25163;
&lt;/p&gt;
&lt;p&gt;
ChatDBG: An AI-Powered Debugging Assistant
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16354
&lt;/p&gt;
&lt;p&gt;
ChatDBG&#26159;&#31532;&#19968;&#20010;AI-Powered&#35843;&#35797;&#21161;&#25163;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21040;&#20256;&#32479;&#35843;&#35797;&#22120;&#20013;&#65292;&#23454;&#29616;&#20102;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#23545;&#35805;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#12289;&#25191;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;ChatDBG&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35843;&#35797;&#21161;&#25163;&#12290;ChatDBG&#38598;&#25104;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#65292;&#26174;&#33879;&#22686;&#24378;&#20102;&#20256;&#32479;&#35843;&#35797;&#22120;&#30340;&#21151;&#33021;&#21644;&#29992;&#25143;&#21451;&#22909;&#24615;&#12290;ChatDBG&#20801;&#35768;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#36827;&#34892;&#21327;&#20316;&#23545;&#35805;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#25552;&#20986;&#20851;&#20110;&#31243;&#24207;&#29366;&#24577;&#30340;&#22797;&#26434;&#38382;&#39064;&#65292;&#23545;&#23849;&#28291;&#25110;&#26029;&#35328;&#22833;&#36133;&#36827;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#35832;&#22914;&#8220;&#20026;&#20160;&#20040;x&#20026;&#31354;&#65311;&#8221;&#20043;&#31867;&#30340;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#26597;&#35810;&#65292;ChatDBG&#25480;&#20104;LLM&#33258;&#20027;&#26435;&#65292;&#36890;&#36807;&#21457;&#20986;&#21629;&#20196;&#26469;&#27983;&#35272;&#22534;&#26632;&#21644;&#26816;&#26597;&#31243;&#24207;&#29366;&#24577;&#36827;&#34892;&#35843;&#35797;&#65307;&#28982;&#21518;&#25253;&#21578;&#20854;&#21457;&#29616;&#24182;&#23558;&#25511;&#21046;&#26435;&#20132;&#36824;&#32473;&#31243;&#24207;&#21592;&#12290;&#25105;&#20204;&#30340;ChatDBG&#21407;&#22411;&#19982;&#26631;&#20934;&#35843;&#35797;&#22120;&#38598;&#25104;&#65292;&#21253;&#25324;LLDB&#12289;GDB&#21644;WinDBG&#29992;&#20110;&#26412;&#22320;&#20195;&#30721;&#20197;&#21450;&#29992;&#20110;Python&#30340;Pdb&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#20195;&#30721;&#38598;&#21512;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#20855;&#26377;&#24050;&#30693;&#38169;&#35823;&#30340;C/C++&#20195;&#30721;&#21644;&#19968;&#22871;Python&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;&#20107;&#20214;&#30340;&#23545;&#35937;&#26816;&#27979;&#30340;&#28151;&#21512;SNN-ANN&#32593;&#32476;&#65292;&#21253;&#25324;&#20102;&#26032;&#39062;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#26725;&#25509;&#27169;&#22359;&#65292;&#33021;&#22815;&#26377;&#25928;&#25429;&#25417;&#31232;&#30095;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#20851;&#31995;&#65292;&#20197;&#25552;&#39640;&#20219;&#21153;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.10173</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;&#20107;&#20214;&#30340;&#23545;&#35937;&#26816;&#27979;&#30340;&#28151;&#21512;SNN-ANN&#32593;&#32476;&#65292;&#20855;&#26377;&#31354;&#38388;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
A Hybrid SNN-ANN Network for Event-based Object Detection with Spatial and Temporal Attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10173
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;&#20107;&#20214;&#30340;&#23545;&#35937;&#26816;&#27979;&#30340;&#28151;&#21512;SNN-ANN&#32593;&#32476;&#65292;&#21253;&#25324;&#20102;&#26032;&#39062;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#26725;&#25509;&#27169;&#22359;&#65292;&#33021;&#22815;&#26377;&#25928;&#25429;&#25417;&#31232;&#30095;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#20851;&#31995;&#65292;&#20197;&#25552;&#39640;&#20219;&#21153;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20107;&#20214;&#30456;&#26426;&#25552;&#20379;&#39640;&#26102;&#38388;&#20998;&#36776;&#29575;&#21644;&#21160;&#24577;&#33539;&#22260;&#65292;&#20960;&#20046;&#27809;&#26377;&#36816;&#21160;&#27169;&#31946;&#65292;&#38750;&#24120;&#36866;&#21512;&#23545;&#35937;&#26816;&#27979;&#20219;&#21153;&#12290;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#65288;SNN&#65289;&#19982;&#20107;&#20214;&#39537;&#21160;&#24863;&#30693;&#25968;&#25454;&#22825;&#29983;&#21305;&#37197;&#65292;&#22312;&#31070;&#32463;&#24418;&#24577;&#30828;&#20214;&#19978;&#33021;&#22815;&#23454;&#29616;&#36229;&#20302;&#21151;&#32791;&#21644;&#20302;&#24310;&#36831;&#25512;&#26029;&#65292;&#32780;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANN&#65289;&#21017;&#23637;&#31034;&#20986;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#21160;&#24577;&#21644;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20174;&#32780;&#20855;&#26377;&#26356;&#22909;&#30340;&#20219;&#21153;&#24615;&#33021;&#12290;&#28151;&#21512;SNN-ANN&#26041;&#27861;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#33021;&#22815;&#21033;&#29992;SNN&#21644;ANN&#20307;&#31995;&#32467;&#26500;&#30340;&#20248;&#21183;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#22522;&#20110;&#28151;&#21512;&#27880;&#24847;&#21147;&#30340;SNN-ANN&#39592;&#24178;&#32593;&#32476;&#65292;&#29992;&#20110;&#20351;&#29992;&#20107;&#20214;&#30456;&#26426;&#36827;&#34892;&#23545;&#35937;&#26816;&#27979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;SNN-ANN&#26725;&#25509;&#27169;&#22359;&#65292;&#20174;SNN&#23618;&#20013;&#25429;&#25417;&#31232;&#30095;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#20851;&#31995;&#65292;&#24182;&#23558;&#20854;&#36716;&#25442;&#20026;&#23494;&#38598;&#29305;&#24449;&#22270;&#65292;&#20379;&#39592;&#24178;&#32593;&#32476;&#30340;ANN&#37096;&#20998;&#20351;&#29992;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;m
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10173v1 Announce Type: cross  Abstract: Event cameras offer high temporal resolution and dynamic range with minimal motion blur, making them promising for object detection tasks. While Spiking Neural Networks (SNNs) are a natural match for event-based sensory data and enable ultra-energy efficient and low latency inference on neuromorphic hardware, Artificial Neural Networks (ANNs) tend to display more stable training dynamics and faster convergence resulting in greater task performance. Hybrid SNN-ANN approaches are a promising alternative, enabling to leverage the strengths of both SNN and ANN architectures. In this work, we introduce the first Hybrid Attention-based SNN-ANN backbone for object detection using event cameras. We propose a novel Attention-based SNN-ANN bridge module to capture sparse spatial and temporal relations from the SNN layer and convert them into dense feature maps for the ANN part of the backbone. Experimental results demonstrate that our proposed m
&lt;/p&gt;</description></item><item><title>ALTO&#26159;&#19968;&#20010;&#32593;&#32476;&#32534;&#25490;&#22120;&#65292;&#38024;&#23545;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#26426;&#20250;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.04311</link><description>&lt;p&gt;
ALTO&#65306;&#19968;&#31181;&#29992;&#20110;&#22797;&#21512;AI&#31995;&#32479;&#30340;&#39640;&#25928;&#32593;&#32476;&#32534;&#25490;&#22120;
&lt;/p&gt;
&lt;p&gt;
ALTO: An Efficient Network Orchestrator for Compound AI Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04311
&lt;/p&gt;
&lt;p&gt;
ALTO&#26159;&#19968;&#20010;&#32593;&#32476;&#32534;&#25490;&#22120;&#65292;&#38024;&#23545;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#26426;&#20250;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ALTO&#65292;&#19968;&#31181;&#29992;&#20110;&#26377;&#25928;&#20026;&#35832;&#22914;&#35821;&#35328;&#27169;&#22411;&#31649;&#36947;&#20043;&#31867;&#30340;&#22797;&#21512;AI&#31995;&#32479;&#25552;&#20379;&#26381;&#21153;&#30340;&#32593;&#32476;&#32534;&#25490;&#22120;&#12290;ALTO&#36890;&#36807;&#21033;&#29992;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#29305;&#26377;&#30340;&#20248;&#21270;&#26426;&#20250;&#65306;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#12290;&#30001;&#20110;&#35821;&#35328;&#27169;&#22411;&#36880;&#20010;&#29983;&#25104;token&#30340;&#36755;&#20986;&#65292;ALTO&#22312;&#21487;&#33021;&#26102;&#26292;&#38706;&#20102;&#22312;&#38454;&#27573;&#20043;&#38388;&#27969;&#24335;&#20256;&#36755;&#20013;&#38388;&#36755;&#20986;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#22312;&#36328;&#20998;&#24067;&#24335;&#31649;&#36947;&#38454;&#27573;&#23454;&#20363;&#20043;&#38388;&#27969;&#24335;&#20256;&#36755;&#20013;&#38388;&#25968;&#25454;&#26102;&#20986;&#29616;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#32858;&#21512;&#24863;&#30693;&#36335;&#30001;&#25509;&#21475;&#21644;&#20998;&#24067;&#24335;&#25552;&#31034;&#24863;&#30693;&#35843;&#24230;&#20197;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#22797;&#26434;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#39564;&#35777;&#31649;&#36947;&#19978;&#23637;&#31034;&#20102;ALTO&#37096;&#20998;&#36755;&#20986;&#27969;&#24335;&#20256;&#36755;&#30340;&#24433;&#21709;&#65292;&#23558;&#21534;&#21520;&#37327;&#25552;&#39640;&#20102;&#26368;&#22810;3&#20493;&#65292;&#21516;&#26102;&#23558;&#22266;&#23450;&#24310;&#36831;&#30446;&#26631;&#35774;&#32622;&#20026;4&#31186;/&#35831;&#27714;&#65292;&#36824;&#20943;&#23569;&#20102;&#23614;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04311v1 Announce Type: new  Abstract: We present ALTO, a network orchestrator for efficiently serving compound AI systems such as pipelines of language models. ALTO achieves high throughput and low latency by taking advantage of an optimization opportunity specific to generative language models: streaming intermediate outputs. As language models produce outputs token by token, ALTO exposes opportunities to stream intermediate outputs between stages when possible. We highlight two new challenges of correctness and load balancing which emerge when streaming intermediate data across distributed pipeline stage instances. We also motivate the need for an aggregation-aware routing interface and distributed prompt-aware scheduling to address these challenges. We demonstrate the impact of ALTO's partial output streaming on a complex chatbot verification pipeline, increasing throughput by up to 3x for a fixed latency target of 4 seconds / request while also reducing tail latency by 1
&lt;/p&gt;</description></item><item><title>AQA-Bench&#26159;&#19968;&#20010;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#30740;&#31350;&#21457;&#29616;&#38381;&#28304;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26174;&#33879;&#20248;&#20110;&#24320;&#28304;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.09404</link><description>&lt;p&gt;
AQA-Bench&#65306;&#35780;&#20272;LLM&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#30340;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09404
&lt;/p&gt;
&lt;p&gt;
AQA-Bench&#26159;&#19968;&#20010;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#30740;&#31350;&#21457;&#29616;&#38381;&#28304;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26174;&#33879;&#20248;&#20110;&#24320;&#28304;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;AQA-Bench&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#65292;&#22914;&#28145;&#24230;&#20248;&#20808;&#25628;&#32034;&#65288;DFS&#65289;&#31561;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#35780;&#20272;&#22522;&#20934;&#27979;&#35797;&#30340;&#20851;&#38190;&#29305;&#28857;&#22312;&#20110;&#20854;&#20132;&#20114;&#24335;&#35780;&#20272;&#21327;&#35758;-&#20363;&#22914;&#65292;&#22312;DFS&#20013;&#65292;&#27599;&#20010;&#33410;&#28857;&#30340;&#21487;&#29992;&#36830;&#25509;&#36793;&#21462;&#20915;&#20110;&#27169;&#22411;&#23545;&#35813;&#33410;&#28857;&#30340;&#36941;&#21382;&#65292;&#22240;&#27492;&#38656;&#35201;LLM&#26377;&#25928;&#22320;&#35760;&#20303;&#24050;&#35775;&#38382;&#33410;&#28857;&#24182;&#31574;&#21010;&#21518;&#32493;&#31227;&#21160;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#20351;&#29992;&#19977;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#26500;&#24314;&#20102;AQA-Bench&#65292;&#20998;&#21035;&#26159;&#20108;&#20998;&#25628;&#32034;&#65292;&#28145;&#24230;&#20248;&#20808;&#25628;&#32034;&#21644;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#65292;&#24182;&#35780;&#20272;&#20102;12&#31181;&#19981;&#21516;&#30340;LLMs&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#25581;&#31034;&#20102;&#19968;&#20123;&#26377;&#36259;&#30340;&#21457;&#29616;&#65306;&#65288;1&#65289;&#31867;&#20284;GPT-4&#21644;Gemini&#31561;&#38381;&#28304;&#27169;&#22411;&#36890;&#24120;&#26174;&#31034;&#20986;&#24378;&#22823;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26126;&#26174;&#20248;&#20110;&#24320;&#28304;LLMs&#12290;&#65288;2&#65289;&#22825;&#30495;&#22320;&#25552;&#20379;&#20114;&#25805;&#20316;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09404v1 Announce Type: cross Abstract: This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol -- for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 12 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show strong sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing inter
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#23545;Stack Overflow&#38382;&#39064;&#30340;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;ChatGPT&#21644;LLaMA&#23545;&#20110;&#35813;&#24179;&#21488;&#30340;&#24433;&#21709;&#21644;&#21487;&#38752;&#24615;&#65292;&#20197;&#21450;&#23427;&#20204;&#22312;&#38271;&#26399;&#20869;&#21462;&#20195;Stack Overflow&#30340;&#25361;&#25112;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#22312;&#26576;&#20123;&#26041;&#38754;&#22833;&#36133;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#27604;LLMs&#30340;&#23454;&#35777;&#27604;&#36739;&#12290;</title><link>https://arxiv.org/abs/2402.08801</link><description>&lt;p&gt;
ChatGPT&#19982;LLaMA&#22312;Stack Overflow&#35752;&#35770;&#20013;&#30340;&#24433;&#21709;&#65292;&#21487;&#38752;&#24615;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08801
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#23545;Stack Overflow&#38382;&#39064;&#30340;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;ChatGPT&#21644;LLaMA&#23545;&#20110;&#35813;&#24179;&#21488;&#30340;&#24433;&#21709;&#21644;&#21487;&#38752;&#24615;&#65292;&#20197;&#21450;&#23427;&#20204;&#22312;&#38271;&#26399;&#20869;&#21462;&#20195;Stack Overflow&#30340;&#25361;&#25112;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#22312;&#26576;&#20123;&#26041;&#38754;&#22833;&#36133;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#27604;LLMs&#30340;&#23454;&#35777;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;2022&#24180;11&#26376;&#21457;&#24067;&#20197;&#26469;&#65292;ChatGPT&#24050;&#32463;&#22312;Stack Overflow&#19978;&#24341;&#36215;&#36720;&#21160;&#65292;&#36825;&#26159;&#24320;&#21457;&#20154;&#21592;&#20851;&#20110;&#32534;&#31243;&#21644;&#36719;&#20214;&#24320;&#21457;&#38382;&#39064;&#30340;&#39318;&#36873;&#24179;&#21488;&#12290;ChatGPT&#23637;&#31034;&#20102;&#29983;&#25104;&#21363;&#26102;&#12289;&#20154;&#31867;&#33324;&#22238;&#31572;&#25216;&#26415;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#24341;&#36215;&#20102;&#24320;&#21457;&#32773;&#31038;&#21306;&#23545;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#26102;&#20195;&#19979;&#20154;&#31867;&#39537;&#21160;&#24179;&#21488;&#28436;&#21464;&#35282;&#33394;&#30340;&#36777;&#35770;&#12290;ChatGPT&#21457;&#24067;&#20004;&#20010;&#26376;&#21518;&#65292;Meta&#21457;&#24067;&#20102;&#23427;&#33258;&#24049;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM) LLaMA&#12290;&#20026;&#20102; (i) &#27979;&#37327;&#29992;&#25143;&#23545;Stack Overflow&#30340;&#26102;&#38388;&#28436;&#36827;&#19979;&#30340;&#21442;&#19982;&#31243;&#24230;&#65307;(ii) &#37327;&#21270;LLMs&#22238;&#31572;&#30340;&#21487;&#38752;&#24615;&#21450;&#20854;&#22312;&#38271;&#26399;&#20869;&#21462;&#20195;Stack Overflow&#30340;&#28508;&#21147;&#65307;(iii) &#30830;&#23450;&#21644;&#29702;&#35299;LLMs&#22833;&#36133;&#30340;&#21407;&#22240;&#65307;(iv) &#23545;&#27604;LLMs&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#20998;&#26512;Stack Overflow&#19978;&#30340;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;LLMs&#26469;&#22238;&#31572;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08801v1 Announce Type: cross Abstract: Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the premier platform for developers' queries on programming and software development. Demonstrating an ability to generate instant, human-like responses to technical questions, ChatGPT has ignited debates within the developer community about the evolving role of human-driven platforms in the age of generative AI. Two months after ChatGPT's release, Meta released its answer with its own Large Language Model (LLM) called LLaMA: the race was on. We conducted an empirical study analyzing questions from Stack Overflow and using these LLMs to address them. This way, we aim to (ii) measure user engagement evolution with Stack Overflow over time; (ii) quantify the reliability of LLMs' answers and their potential to replace Stack Overflow in the long term; (iii) identify and understand why LLMs fails; and (iv) compare LLMs together. Our empirical results are unequivocal: C
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27491;&#24120;&#32467;&#26500;&#35268;&#33539;&#21270;&#26041;&#27861;&#65292;&#23454;&#29616;&#24320;&#25918;&#22270;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#23545;&#26410;&#30693;&#24322;&#24120;&#30340;&#24191;&#20041;&#26816;&#27979;&#33021;&#21147;</title><link>https://arxiv.org/abs/2311.06835</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#24120;&#32467;&#26500;&#35268;&#33539;&#21270;&#23454;&#29616;&#24320;&#25918;&#22270;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Open-Set Graph Anomaly Detection via Normal Structure Regularisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.06835
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27491;&#24120;&#32467;&#26500;&#35268;&#33539;&#21270;&#26041;&#27861;&#65292;&#23454;&#29616;&#24320;&#25918;&#22270;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#23545;&#26410;&#30693;&#24322;&#24120;&#30340;&#24191;&#20041;&#26816;&#27979;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#22270;&#24322;&#24120;&#26816;&#27979;&#65288;GAD&#65289;&#20219;&#21153;&#65292;&#21363;&#24320;&#25918;&#24335;GAD&#65292;&#26088;&#22312;&#20351;&#29992;&#23569;&#37327;&#26631;&#35760;&#30340;&#35757;&#32451;&#27491;&#24120;&#33410;&#28857;&#21644;&#24322;&#24120;&#33410;&#28857;&#65288;&#31216;&#20026;&#24050;&#30693;&#24322;&#24120;&#65289;&#26469;&#26816;&#27979;&#24322;&#24120;&#33410;&#28857;&#65292;&#36825;&#20123;&#33410;&#28857;&#26080;&#27861;&#23637;&#31034;&#25152;&#26377;&#21487;&#33021;&#30340;&#25512;&#29702;&#26102;&#24322;&#24120;&#12290;&#24050;&#26631;&#35760;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#20026;GAD&#27169;&#22411;&#25552;&#20379;&#20102;&#20851;&#38190;&#30340;&#24322;&#24120;&#20808;&#39564;&#30693;&#35782;&#65292;&#21487;&#22823;&#22823;&#38477;&#20302;&#26816;&#27979;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#26041;&#27861;&#24448;&#24448;&#36807;&#20998;&#24378;&#35843;&#25311;&#21512;&#24050;&#30693;&#24322;&#24120;&#65292;&#23548;&#33268;&#23545;&#26410;&#30693;&#24322;&#24120;&#65288;&#21363;&#26410;&#34987;&#26631;&#35760;&#30340;&#24322;&#24120;&#33410;&#28857;&#65289;&#30340;&#24369;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#34987;&#24341;&#20837;&#20197;&#22788;&#29702;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#65292;&#26410;&#33021;&#26377;&#25928;&#25429;&#25417;GAD&#30340;&#37325;&#35201;&#38750;&#27431;&#20960;&#37324;&#24503;&#29305;&#24449;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24320;&#25918;&#24335;GAD&#26041;&#27861;&#65292;&#21363;&#27491;&#24120;&#32467;&#26500;&#35268;&#33539;&#21270;&#65288;NSReg&#65289;&#65292;&#20197;&#23454;&#29616;&#23545;&#26410;&#30693;&#24322;&#24120;&#30340;&#24191;&#20041;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.06835v2 Announce Type: replace-cross  Abstract: This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to detect anomalous nodes using a small number of labelled training normal and anomaly nodes (known as seen anomalies) that cannot illustrate all possible inference-time abnormalities. The availability of that labelled data provides crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current methods tend to over-emphasise fitting the seen anomalies, leading to a weak generalisation ability to detect unseen anomalies, i.e., those that are not illustrated by the labelled anomaly nodes. Further, they were introduced to handle Euclidean data, failing to effectively capture important non-Euclidean features for GAD. In this work, we propose a novel open-set GAD approach, namely Normal Structure Regularisation (NSReg), to achieve generalised detection ability to unseen 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03756</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#36866;&#24212;&#24615;&#23454;&#39564;&#35774;&#35745;&#19982;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning. (arXiv:2401.03756v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#26159;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#20219;&#21153;&#20316;&#20026;&#19968;&#20010;&#24102;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification, BAI&#65289;&#38382;&#39064;&#26469;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#32473;&#23450;&#22810;&#20010;&#27835;&#30103;&#33218;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#35266;&#23519;&#19968;&#20010;&#21051;&#30011;&#23454;&#39564;&#21333;&#20301;&#30340;&#19978;&#19979;&#25991;&#65288;&#21327;&#21464;&#37327;&#65289;&#65292;&#24182;&#23558;&#35813;&#21333;&#20301;&#20998;&#37197;&#32473;&#20854;&#20013;&#19968;&#20010;&#27835;&#30103;&#33218;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#20915;&#31574;&#32773;&#25512;&#33616;&#19968;&#20010;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#39044;&#35745;&#20135;&#29983;&#26368;&#39640;&#26399;&#26395;&#32467;&#26524;&#30340;&#27835;&#30103;&#33218;&#65288;&#26368;&#20339;&#27835;&#30103;&#33218;&#65289;&#12290;&#35813;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#65288;&#31574;&#30053;&#36951;&#25022;&#65289;&#26469;&#34913;&#37327;&#65292;&#35813;&#36951;&#25022;&#34920;&#31034;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#65292;&#26368;&#20339;&#27835;&#30103;&#33218;&#21644;&#25512;&#33616;&#27835;&#30103;&#33218;&#30340;&#26465;&#20214;&#26399;&#26395;&#32467;&#26524;&#20043;&#38388;&#30340;&#26368;&#22823;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#21021;&#22987;&#27493;&#39588;&#26159;&#25512;&#23548;&#26368;&#22351;&#24773;&#20917;&#19979;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36817;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#36824;&#26263;&#31034;&#30528;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#19968;&#20123;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individualized treatment recommendation is a crucial task in evidence-based decision-making. In this study, we formulate this task as a fixed-budget best arm identification (BAI) problem with contextual information. In this setting, we consider an adaptive experiment given multiple treatment arms. At each round, a decision-maker observes a context (covariate) that characterizes an experimental unit and assigns the unit to one of the treatment arms. At the end of the experiment, the decision-maker recommends a treatment arm estimated to yield the highest expected outcome conditioned on a context (best treatment arm). The effectiveness of this decision is measured in terms of the worst-case expected simple regret (policy regret), which represents the largest difference between the conditional expected outcomes of the best and recommended treatment arms given a context. Our initial step is to derive asymptotic lower bounds for the worst-case expected simple regret, which also implies idea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#32454;&#21270;&#19982;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#20219;&#21153;&#30340;&#36129;&#29486;&#20998;&#37197;&#22870;&#21169;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;LFP&#21462;&#24471;&#20102;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12053</link><description>&lt;p&gt;
&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Layer-wise Feedback Propagation. (arXiv:2308.12053v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#32454;&#21270;&#19982;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#20219;&#21153;&#30340;&#36129;&#29486;&#20998;&#37197;&#22870;&#21169;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;LFP&#21462;&#24471;&#20102;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#20307;&#32780;&#35328;&#26159;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#35299;&#20915;&#32473;&#23450;&#20219;&#21153;&#30340;&#36129;&#29486;&#29420;&#31435;&#20998;&#37197;&#22870;&#21169;&#12290;&#36825;&#19982;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#19981;&#21516;&#65292;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26159;&#26397;&#21521;&#20272;&#35745;&#30340;&#25439;&#22833;&#26368;&#23567;&#20540;&#26356;&#26032;&#21442;&#25968;&#12290;LFP&#22312;&#27169;&#22411;&#20013;&#20256;&#25773;&#22870;&#21169;&#20449;&#21495;&#65292;&#32780;&#26080;&#38656;&#26799;&#24230;&#35745;&#31639;&#12290;&#23427;&#22686;&#24378;&#25509;&#25910;&#21040;&#27491;&#21453;&#39304;&#30340;&#32467;&#26500;&#65292;&#21516;&#26102;&#38477;&#20302;&#25509;&#25910;&#21040;&#36127;&#21453;&#39304;&#30340;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#30340;&#35282;&#24230;&#35777;&#26126;&#20102;LFP&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;LFP&#20811;&#26381;&#20102;&#26799;&#24230;&#26041;&#27861;&#30340;&#26576;&#20123;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#23545;&#26377;&#24847;&#20041;&#30340;&#23548;&#25968;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;LFP&#22914;&#20309;&#35299;&#20915;&#26799;&#24230;&#26041;&#27861;&#30456;&#20851;&#38382;&#39064;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present Layer-wise Feedback Propagation (LFP), a novel training approach for neural-network-like predictors that utilizes explainability, specifically Layer-wise Relevance Propagation(LRP), to assign rewards to individual connections based on their respective contributions to solving a given task. This differs from traditional gradient descent, which updates parameters towards anestimated loss minimum. LFP distributes a reward signal throughout the model without the need for gradient computations. It then strengthens structures that receive positive feedback while reducingthe influence of structures that receive negative feedback. We establish the convergence of LFP theoretically and empirically, and demonstrate its effectiveness in achieving comparable performance to gradient descent on various models and datasets. Notably, LFP overcomes certain limitations associated with gradient-based methods, such as reliance on meaningful derivatives. We further investigate how 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;AI&#23398;&#26415;&#30028;&#30340;78K&#30740;&#31350;&#20154;&#21592;&#30340;&#20998;&#26512;&#65292;&#30740;&#31350;&#21457;&#29616;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#20855;&#26377;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#65307;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#12290;&#25105;&#20204;&#40723;&#21169;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14597</link><description>&lt;p&gt;
&#22905;&#20204;&#30340;&#22768;&#38899;&#65306;&#20998;&#26512;&#20154;&#24037;&#26234;&#33021;&#20986;&#29256;&#39046;&#22495;&#30340;&#24615;&#21035;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Voices of Her: Analyzing Gender Differences in the AI Publication World. (arXiv:2305.14597v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14597
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;AI&#23398;&#26415;&#30028;&#30340;78K&#30740;&#31350;&#20154;&#21592;&#30340;&#20998;&#26512;&#65292;&#30740;&#31350;&#21457;&#29616;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#20855;&#26377;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#65307;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#12290;&#25105;&#20204;&#40723;&#21169;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#20998;&#26512;&#20102;&#23398;&#26415;&#30028;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#65292;&#20294;&#26159;&#25105;&#20204;&#20173;&#28982;&#32570;&#20047;&#19968;&#20010;&#20840;&#38754;&#30340;&#20154;&#24037;&#26234;&#33021;&#31038;&#21306;&#24615;&#21035;&#24046;&#24322;&#30340;&#20998;&#26512;&#65292;&#28085;&#30422;&#21508;&#31181;&#20027;&#39064;&#21644;&#19981;&#21516;&#30340;&#21457;&#23637;&#36235;&#21183;&#12290;&#25105;&#20204;&#20351;&#29992;AI Scholar&#25968;&#25454;&#38598;&#20013;&#30340;78K&#20301;AI&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#24615;&#21035;&#24046;&#24322;&#65306;&#65288;1&#65289;&#34429;&#28982;&#22899;&#24615;&#30740;&#31350;&#20154;&#21592;&#30340;&#24635;&#24341;&#29992;&#27425;&#25968;&#27604;&#30007;&#24615;&#23569;&#65292;&#20294;&#36825;&#31181;&#24341;&#29992;&#24046;&#24322;&#24182;&#19981;&#36866;&#29992;&#20110;&#25152;&#26377;&#23398;&#26415;&#24180;&#40836;&#32452;&#65307;&#65288;2&#65289;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#65307;&#65288;3&#65289;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#26174;&#31034;&#20986;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20026;&#25105;&#20204;&#30340;AI&#31038;&#21306;&#29616;&#26377;&#30340;&#20154;&#21475;&#32479;&#35745;&#36235;&#21183;&#25552;&#20379;&#20102;&#19968;&#20010;&#31383;&#21475;&#65292;&#24182;&#40723;&#21169;&#22312;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#21487;&#22312;https://github.com/causalNLP/ai-scholar-gender&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
While several previous studies have analyzed gender bias in research, we are still missing a comprehensive analysis of gender differences in the AI community, covering diverse topics and different development trends. Using the AI Scholar dataset of 78K researchers in the field of AI, we identify several gender differences: (1) Although female researchers tend to have fewer overall citations than males, this citation difference does not hold for all academic-age groups; (2) There exist large gender homophily in co-authorship on AI papers; (3) Female first-authored papers show distinct linguistic styles, such as longer text, more positive emotion words, and more catchy titles than male first-authored papers. Our analysis provides a window into the current demographic trends in our AI community, and encourages more gender equality and diversity in the future. Our code and data are at https://github.com/causalNLP/ai-scholar-gender.
&lt;/p&gt;</description></item></channel></rss>