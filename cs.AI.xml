<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#20998;&#26512;&#20102;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#21508;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#38899;&#27169;&#22411;&#20013;&#30340;&#26032;&#39062;&#29616;&#35937;&#65292;&#24182;&#23637;&#31034;&#20102;&#29305;&#24449;&#20132;&#20114;&#22914;&#20309;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.13106</link><description>&lt;p&gt;
&#35748;&#35782;&#20320;&#30340;&#38750;&#32447;&#24615;&#65306;Shapley&#20114;&#21160;&#25581;&#31034;&#25968;&#25454;&#30340;&#28508;&#22312;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Knowing Your Nonlinearities: Shapley Interactions Reveal the Underlying Structure of Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#20998;&#26512;&#20102;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#21508;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#38899;&#27169;&#22411;&#20013;&#30340;&#26032;&#39062;&#29616;&#35937;&#65292;&#24182;&#23637;&#31034;&#20102;&#29305;&#24449;&#20132;&#20114;&#22914;&#20309;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#37327;&#38750;&#32447;&#24615;&#29305;&#24449;&#20132;&#20114;&#26159;&#29702;&#35299;&#35768;&#22810;&#27169;&#22411;&#20013;&#22797;&#26434;&#24402;&#22240;&#27169;&#24335;&#30340;&#19968;&#31181;&#24050;&#24314;&#31435;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#26469;&#20998;&#26512;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#22810;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#12290;&#22312;&#32771;&#34385;&#25513;&#30721;&#21644;&#33258;&#22238;&#24402;&#35821;&#35328;&#27169;&#22411;&#65288;MLMs&#21644;ALMs&#65289;&#20013;&#30340;&#35821;&#35328;&#32467;&#26500;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;STII&#22312;&#24815;&#29992;&#34920;&#36798;&#20013;&#22686;&#21152;&#65292;MLMs&#38543;&#21477;&#27861;&#36317;&#31163;&#25193;&#23637;STII&#65292;&#26356;&#22810;&#22320;&#20381;&#36182;&#35821;&#27861;&#22312;&#20854;&#38750;&#32447;&#24615;&#32467;&#26500;&#20013;&#30456;&#27604;ALMs&#12290;&#25105;&#20204;&#30340;&#35821;&#38899;&#27169;&#22411;&#30740;&#31350;&#21453;&#26144;&#20102;&#21475;&#33108;&#24352;&#24320;&#31243;&#24230;&#20915;&#23450;&#38899;&#32032;&#26681;&#25454;&#19978;&#19979;&#25991;&#21464;&#21270;&#30340;&#25968;&#37327;&#30340;&#21407;&#21017;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#22270;&#20687;&#20998;&#31867;&#22120;&#24182;&#35828;&#26126;&#29305;&#24449;&#20132;&#20114;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#36328;&#23398;&#31185;&#24037;&#20316;&#21644;&#39046;&#22495;&#20043;&#38388;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13106v1 Announce Type: cross  Abstract: Measuring nonlinear feature interaction is an established approach to understanding complex patterns of attribution in many models. In this paper, we use Shapley Taylor interaction indices (STII) to analyze the impact of underlying data structure on model representations in a variety of modalities, tasks, and architectures. Considering linguistic structure in masked and auto-regressive language models (MLMs and ALMs), we find that STII increases within idiomatic expressions and that MLMs scale STII with syntactic distance, relying more on syntax in their nonlinear structure than ALMs do. Our speech model findings reflect the phonetic principal that the openness of the oral cavity determines how much a phoneme varies based on its context. Finally, we study image classifiers and illustrate that feature interactions intuitively reflect object boundaries. Our wide range of results illustrates the benefits of interdisciplinary work and doma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#24067;&#20102;&#19968;&#20010;&#22823;&#22411;&#26631;&#20934;&#25968;&#25454;&#38598;DREsS&#65292;&#29992;&#20110;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#33258;&#21160;&#20316;&#25991;&#35780;&#20998;&#65292;&#22312;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30772;&#22351;&#30340;&#20316;&#25991;&#22686;&#24378;&#31574;&#30053;CASE&#21518;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#30340;&#22522;&#32447;&#32467;&#26524;&#25552;&#39640;&#20102;45.44&#65285;&#12290;</title><link>https://arxiv.org/abs/2402.16733</link><description>&lt;p&gt;
DREsS: &#33521;&#35821;&#20316;&#20026;&#22806;&#35821;&#20889;&#20316;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#24067;&#20102;&#19968;&#20010;&#22823;&#22411;&#26631;&#20934;&#25968;&#25454;&#38598;DREsS&#65292;&#29992;&#20110;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#33258;&#21160;&#20316;&#25991;&#35780;&#20998;&#65292;&#22312;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30772;&#22351;&#30340;&#20316;&#25991;&#22686;&#24378;&#31574;&#30053;CASE&#21518;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#30340;&#22522;&#32447;&#32467;&#26524;&#25552;&#39640;&#20102;45.44&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#20316;&#25991;&#35780;&#20998;&#65288;AES&#65289;&#26159;&#33521;&#35821;&#20316;&#20026;&#22806;&#35821;&#20889;&#20316;&#25945;&#32946;&#20013;&#19968;&#31181;&#26377;&#29992;&#30340;&#24037;&#20855;&#65292;&#20026;&#23398;&#29983;&#21644;&#25945;&#24072;&#25552;&#20379;&#23454;&#26102;&#20316;&#25991;&#35780;&#20998;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;AES&#27169;&#22411;&#26159;&#22312;&#19982;EFL&#20889;&#20316;&#25945;&#32946;&#23454;&#38469;&#22330;&#26223;&#19981;&#30456;&#20851;&#30340;&#20316;&#25991;&#21644;&#20998;&#25968;&#19978;&#36827;&#34892;&#35757;&#32451;&#30340;&#65292;&#24182;&#19988;&#36890;&#24120;&#30001;&#20110;&#32570;&#20047;&#36866;&#24403;&#30340;&#25968;&#25454;&#38598;&#32780;&#25552;&#20379;&#21333;&#19968;&#30340;&#25972;&#20307;&#35780;&#20998;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;DREsS&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#33258;&#21160;&#20316;&#25991;&#35780;&#20998;&#30340;&#22823;&#22411;&#26631;&#20934;&#25968;&#25454;&#38598;&#12290;DREsS&#21253;&#25324;&#19977;&#20010;&#23376;&#25968;&#25454;&#38598;&#65306;DREsS_New&#65292;DREsS_Std.&#21644;DREsS_CASE&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;DREsS_New&#65292;&#36825;&#26159;&#19968;&#20010;&#30001;EFL&#26412;&#31185;&#29983;&#25776;&#20889;&#24182;&#30001;&#33521;&#35821;&#25945;&#32946;&#19987;&#23478;&#35780;&#20998;&#30340;&#30495;&#23454;&#35838;&#22530;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#36824;&#23558;&#29616;&#26377;&#30340;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#20316;&#25991;&#35780;&#20998;&#25968;&#25454;&#38598;&#26631;&#20934;&#21270;&#20026;DREsS_Std&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;CASE&#30340;&#22522;&#20110;&#30772;&#22351;&#30340;&#20316;&#25991;&#22686;&#24378;&#31574;&#30053;&#65292;&#29992;&#20110;&#29983;&#25104;20K&#20010;DREsS_CASE&#30340;&#21512;&#25104;&#26679;&#26412;&#65292;&#24182;&#23558;&#22522;&#32447;&#32467;&#26524;&#25552;&#39640;&#20102;45.44&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16733v1 Announce Type: new  Abstract: Automated essay scoring (AES) is a useful tool in English as a Foreign Language (EFL) writing education, offering real-time essay scores for students and instructors. However, previous AES models were trained on essays and scores irrelevant to the practical scenarios of EFL writing education and usually provided a single holistic score due to the lack of appropriate datasets. In this paper, we release DREsS, a large-scale, standard dataset for rubric-based automated essay scoring. DREsS comprises three sub-datasets: DREsS_New, DREsS_Std., and DREsS_CASE. We collect DREsS_New, a real-classroom dataset with 1.7K essays authored by EFL undergraduate students and scored by English education experts. We also standardize existing rubric-based essay scoring datasets as DREsS_Std. We suggest CASE, a corruption-based augmentation strategy for essays, which generates 20K synthetic samples of DREsS_CASE and improves the baseline results by 45.44%. 
&lt;/p&gt;</description></item><item><title>&#27604;&#36739;&#20256;&#32479;EEG&#19982;&#19977;&#26497;EEG&#22312;&#39640;&#24615;&#33021;&#21040;&#39076;&#25235;&#25569;BCI&#31995;&#32479;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#20449;&#22122;&#27604;&#12289;&#31354;&#38388;&#20998;&#36776;&#29575;&#12289;ERPs&#21644;&#23567;&#27874;&#26102;&#39057;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.09448</link><description>&lt;p&gt;
&#26222;&#36890;EEG&#19982;&#19977;&#26497;EEG&#22312;&#39640;&#24615;&#33021;&#21040;&#39076;&#25235;&#25569;BCI&#31995;&#32479;&#20013;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comparative Study of Conventional and Tripolar EEG for High-Performance Reach-to-Grasp BCI Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09448
&lt;/p&gt;
&lt;p&gt;
&#27604;&#36739;&#20256;&#32479;EEG&#19982;&#19977;&#26497;EEG&#22312;&#39640;&#24615;&#33021;&#21040;&#39076;&#25235;&#25569;BCI&#31995;&#32479;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#20449;&#22122;&#27604;&#12289;&#31354;&#38388;&#20998;&#36776;&#29575;&#12289;ERPs&#21644;&#23567;&#27874;&#26102;&#39057;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#27604;&#36739;&#20256;&#32479;EEG&#19982;&#19977;&#26497;EEG&#22312;&#25552;&#21319;&#36816;&#21160;&#38556;&#30861;&#20010;&#20307;&#30340;BCI&#24212;&#29992;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#37325;&#28857;&#26159;&#35299;&#35835;&#21644;&#35299;&#30721;&#21508;&#31181;&#25235;&#25569;&#21160;&#20316;&#65292;&#22914;&#21147;&#25569;&#21644;&#31934;&#30830;&#25569;&#25345;&#12290;&#30446;&#26631;&#26159;&#30830;&#23450;&#21738;&#31181;EEG&#25216;&#26415;&#22312;&#22788;&#29702;&#21644;&#32763;&#35793;&#19982;&#25235;&#25569;&#30456;&#20851;&#30340;&#33041;&#30005;&#20449;&#21495;&#26041;&#38754;&#26356;&#20026;&#26377;&#25928;&#12290;&#30740;&#31350;&#28041;&#21450;&#23545;&#21313;&#21517;&#20581;&#24247;&#21442;&#19982;&#32773;&#36827;&#34892;&#23454;&#39564;&#65292;&#21442;&#19982;&#32773;&#36827;&#34892;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#25569;&#25345;&#36816;&#21160;&#65306;&#21147;&#25569;&#21644;&#31934;&#30830;&#25569;&#25345;&#65292;&#26080;&#36816;&#21160;&#26465;&#20214;&#20316;&#20026;&#22522;&#32447;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#22312;&#35299;&#30721;&#25235;&#25569;&#21160;&#20316;&#26041;&#38754;&#23545;EEG&#21644;&#19977;&#26497;EEG&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#12290;&#35813;&#27604;&#36739;&#28085;&#30422;&#20102;&#20960;&#20010;&#20851;&#38190;&#21442;&#25968;&#65292;&#21253;&#25324;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#12289;&#36890;&#36807;&#21151;&#33021;&#36830;&#25509;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12289;ERPs&#21644;&#23567;&#27874;&#26102;&#39057;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36824;&#28041;&#21450;&#20174;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09448v1 Announce Type: cross  Abstract: This study aims to enhance BCI applications for individuals with motor impairments by comparing the effectiveness of tripolar EEG (tEEG) with conventional EEG. The focus is on interpreting and decoding various grasping movements, such as power grasp and precision grasp. The goal is to determine which EEG technology is more effective in processing and translating grasp related neural signals. The approach involved experimenting on ten healthy participants who performed two distinct grasp movements: power grasp and precision grasp, with a no movement condition serving as the baseline. Our research presents a thorough comparison between EEG and tEEG in decoding grasping movements. This comparison spans several key parameters, including signal to noise ratio (SNR), spatial resolution via functional connectivity, ERPs, and wavelet time frequency analysis. Additionally, our study involved extracting and analyzing statistical features from th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#26410;&#21457;&#24067;&#30740;&#31350;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#30001;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#26500;&#24314;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#32467;&#21512;&#35770;&#25991;&#20869;&#23481;&#21644;&#21382;&#21490;&#24341;&#29992;&#30340;&#20449;&#24687;&#65292;&#39640;&#20934;&#30830;&#24230;&#39044;&#27979;&#26410;&#26469;&#30340;&#28436;&#21270;&#32593;&#32476;&#21160;&#24577;&#21644;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.08640</link><description>&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22312;&#19981;&#26029;&#28436;&#21270;&#30340;&#30693;&#35782;&#22270;&#35889;&#19978;&#39044;&#27979;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#20027;&#39064;
&lt;/p&gt;
&lt;p&gt;
Forecasting high-impact research topics via machine learning on evolving knowledge graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08640
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#26410;&#21457;&#24067;&#30740;&#31350;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#30001;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#26500;&#24314;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#32467;&#21512;&#35770;&#25991;&#20869;&#23481;&#21644;&#21382;&#21490;&#24341;&#29992;&#30340;&#20449;&#24687;&#65292;&#39640;&#20934;&#30830;&#24230;&#39044;&#27979;&#26410;&#26469;&#30340;&#28436;&#21270;&#32593;&#32476;&#21160;&#24577;&#21644;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#20986;&#29256;&#29289;&#30340;&#25351;&#25968;&#22686;&#38271;&#23545;&#20154;&#31867;&#30740;&#31350;&#32773;&#26500;&#25104;&#20102;&#20005;&#23803;&#25361;&#25112;&#12290;&#23427;&#36843;&#20351;&#30740;&#31350;&#32773;&#23558;&#27880;&#24847;&#21147;&#38598;&#20013;&#22312;&#26356;&#29421;&#31364;&#30340;&#23376;&#39046;&#22495;&#19978;&#65292;&#20351;&#24471;&#21457;&#29616;&#20854;&#20182;&#39046;&#22495;&#30340;&#26032;&#39062;&#19988;&#26377;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#24819;&#27861;&#21644;&#21512;&#20316;&#21464;&#24471;&#22256;&#38590;&#12290;&#34429;&#28982;&#26377;&#21150;&#27861;&#39044;&#27979;&#31185;&#23398;&#35770;&#25991;&#26410;&#26469;&#30340;&#24341;&#29992;&#27425;&#25968;&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#31561;&#21040;&#30740;&#31350;&#23436;&#25104;&#24182;&#19988;&#35770;&#25991;&#20889;&#25104;&#21518;&#25165;&#33021;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#26679;&#23601;&#38169;&#36807;&#20102;&#24819;&#27861;&#26500;&#24605;&#30340;&#26089;&#26399;&#38454;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#39044;&#27979;&#20174;&#26410;&#34987;&#30740;&#31350;&#32773;&#21457;&#24067;&#30340;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#20854;&#20013;&#21253;&#21547;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#12290;&#23427;&#32467;&#21512;&#20102;&#20174;&#35770;&#25991;&#20869;&#23481;&#20013;&#21019;&#24314;&#30340;&#35821;&#20041;&#32593;&#32476;&#21644;&#20174;&#21382;&#21490;&#24341;&#29992;&#20013;&#21019;&#24314;&#30340;&#24433;&#21709;&#32593;&#32476;&#12290;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#65292;&#25105;&#20204;&#21487;&#20197;&#39640;&#20934;&#30830;&#24230;&#22320;&#39044;&#27979;&#28436;&#21270;&#32593;&#32476;&#30340;&#21160;&#24577;&#24773;&#20917;&#65292;&#20174;&#32780;&#39044;&#27979;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;&#25105;&#20204;&#39044;&#26399;&#36825;&#31181;&#33021;&#21147;&#23558;&#26377;&#21161;&#20110;&#30740;&#31350;&#32773;&#21457;&#29616;&#20855;&#26377;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#20998;&#26512;&#20195;&#29702;&#20154;&#20559;&#22909;&#20998;&#24067;&#30340;&#24179;&#22343;&#24773;&#20917;&#65292;&#25193;&#23637;&#20102;&#36845;&#20195;&#25237;&#31080;&#27169;&#22411;&#30340;&#25928;&#26524;&#20998;&#26512;&#12290;&#24182;&#19988;&#21306;&#20998;&#20102;&#36845;&#20195;&#22810;&#25968;&#21046;&#20309;&#26102;&#25913;&#21892;&#25110;&#38477;&#20302;&#28176;&#36817;&#31119;&#21033;&#12290;</title><link>https://arxiv.org/abs/2402.08144</link><description>&lt;p&gt;
&#36845;&#20195;&#25237;&#31080;&#30340;&#24179;&#22343;&#24773;&#20917;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Average-Case Analysis of Iterative Voting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08144
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#20998;&#26512;&#20195;&#29702;&#20154;&#20559;&#22909;&#20998;&#24067;&#30340;&#24179;&#22343;&#24773;&#20917;&#65292;&#25193;&#23637;&#20102;&#36845;&#20195;&#25237;&#31080;&#27169;&#22411;&#30340;&#25928;&#26524;&#20998;&#26512;&#12290;&#24182;&#19988;&#21306;&#20998;&#20102;&#36845;&#20195;&#22810;&#25968;&#21046;&#20309;&#26102;&#25913;&#21892;&#25110;&#38477;&#20302;&#28176;&#36817;&#31119;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36845;&#20195;&#25237;&#31080;&#26159;&#31038;&#20250;&#36873;&#25321;&#20013;&#37325;&#22797;&#25112;&#30053;&#20915;&#31574;&#30340;&#33258;&#28982;&#27169;&#22411;&#65292;&#24403;&#20195;&#29702;&#21487;&#20197;&#22312;&#26368;&#32456;&#30830;&#23450;&#32676;&#20307;&#20915;&#31574;&#20043;&#21069;&#26356;&#26032;&#20182;&#20204;&#30340;&#25237;&#31080;&#26102;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#36890;&#36807;&#23545;&#26080;&#24207;&#25991;&#21270;&#19979;&#20195;&#29702;&#20154;&#20559;&#22909;&#30340;&#26368;&#22351;&#24773;&#20917;&#21644;&#24179;&#22343;&#24773;&#20917;&#34920;&#29616;&#36827;&#34892;&#20998;&#26512;&#65292;&#36890;&#36807;&#25913;&#36827;&#23433;&#32435;&#22522;&#20215;&#26684;&#26469;&#20998;&#26512;&#36845;&#20195;&#22810;&#25968;&#21046;&#23545;&#24179;&#34913;&#28857;&#36873;&#20986;&#30340;&#32467;&#26524;&#31119;&#21033;&#30340;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#20043;&#21069;&#30340;&#20998;&#26512;&#21482;&#30740;&#31350;&#20102;&#22312;&#20195;&#29702;&#20154;&#20559;&#22909;&#36890;&#36807;&#26080;&#20559;&#25991;&#21270;&#20998;&#24067;&#30340;&#26368;&#22351;&#24773;&#20917;&#21644;&#24179;&#22343;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#23558;&#24179;&#22343;&#24773;&#20917;&#20998;&#26512;&#25193;&#23637;&#21040;&#26356;&#24191;&#27867;&#30340;&#20998;&#24067;&#31867;&#65292;&#24182;&#21306;&#20998;&#20986;&#36845;&#20195;&#22810;&#25968;&#21046;&#20309;&#26102;&#25913;&#21892;&#25110;&#38477;&#20302;&#28176;&#36817;&#31119;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;
Iterative voting is a natural model of repeated strategic decision-making in social choice when agents have the opportunity to update their votes prior to finalizing the group decision. Prior work has analyzed the efficacy of iterative plurality on the welfare of the chosen outcome at equilibrium, relative to the truthful vote profile, via an adaptation of the price of anarchy. However, prior analyses have only studied the worst-case and average-case performances when agents' preferences are distributed by the impartial culture. This work extends average-case analyses to a wider class of distributions and distinguishes when iterative plurality improves or degrades asymptotic welfare.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23558;&#19968;&#38454;&#36923;&#36753;&#19982;&#35745;&#25968;&#31526;&#21495;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#22312;&#22810;&#23545;&#25968;&#24230;&#32467;&#26500;&#19979;&#20197;&#27425;&#32447;&#24615;&#26102;&#38388;&#19968;&#33268;&#23398;&#20064;&#21487;&#23450;&#20041;&#30340;&#20998;&#31867;&#22120;&#65292;&#20026;&#21253;&#21547;&#25968;&#20540;&#26041;&#38754;&#30340;&#26426;&#22120;&#23398;&#20064;&#25193;&#23637;&#23398;&#20064;&#26694;&#26550;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;</title><link>https://arxiv.org/abs/1909.03820</link><description>&lt;p&gt;
&#29992;&#35745;&#25968;&#31526;&#21495;&#30340;&#19968;&#38454;&#36923;&#36753;&#23450;&#20041;&#30340;&#27010;&#24565;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning Concepts Definable in First-Order Logic with Counting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1909.03820
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23558;&#19968;&#38454;&#36923;&#36753;&#19982;&#35745;&#25968;&#31526;&#21495;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#22312;&#22810;&#23545;&#25968;&#24230;&#32467;&#26500;&#19979;&#20197;&#27425;&#32447;&#24615;&#26102;&#38388;&#19968;&#33268;&#23398;&#20064;&#21487;&#23450;&#20041;&#30340;&#20998;&#31867;&#22120;&#65292;&#20026;&#21253;&#21547;&#25968;&#20540;&#26041;&#38754;&#30340;&#26426;&#22120;&#23398;&#20064;&#25193;&#23637;&#23398;&#20064;&#26694;&#26550;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Grohe&#21644;Tur\'an&#24341;&#20837;&#30340;&#36923;&#36753;&#26694;&#26550;&#19979;&#30340;&#20851;&#31995;&#32972;&#26223;&#32467;&#26500;&#19978;&#30340;&#24067;&#23572;&#20998;&#31867;&#38382;&#39064;&#12290;&#20247;&#25152;&#21608;&#30693;(Grohe&#21644;Ritzert, LICS 2017)&#65292;&#22312;&#22810;&#23545;&#25968;&#24230;&#32467;&#26500;&#19978;&#30340;&#19968;&#38454;&#36923;&#36753;&#21487;&#23450;&#20041;&#30340;&#20998;&#31867;&#22120;&#21487;&#20197;&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#23398;&#20064;&#65292;&#20854;&#20013;&#32467;&#26500;&#30340;&#24230;&#21644;&#36816;&#34892;&#26102;&#38388;&#26159;&#20197;&#32467;&#26500;&#30340;&#22823;&#23567;&#20026;&#21333;&#20301;&#26469;&#34913;&#37327;&#30340;&#12290;&#25105;&#20204;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#30001;Kuske&#21644;Schweikardt(LICS 2017)&#24341;&#20837;&#30340;&#24102;&#35745;&#25968;&#30340;&#19968;&#38454;&#36923;&#36753;FOCN&#65292;&#23427;&#20316;&#20026;&#19968;&#20010;&#24191;&#27867;&#25512;&#24191;&#21508;&#31181;&#35745;&#25968;&#36923;&#36753;&#30340;&#34920;&#29616;&#36923;&#36753;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#22312;&#22810;&#23545;&#25968;&#24230;&#32467;&#26500;&#31867;&#19978;&#23450;&#20041;&#30340;FOCN&#20013;&#30340;&#20998;&#31867;&#22120;&#21487;&#20197;&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#19968;&#33268;&#22320;&#23398;&#20064;&#12290;&#36825;&#21487;&#20197;&#30475;&#20316;&#26159;&#23558;&#23398;&#20064;&#26694;&#26550;&#25193;&#23637;&#20197;&#21253;&#21547;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#20540;&#26041;&#38754;&#30340;&#31532;&#19968;&#27493;&#12290;&#25105;&#20204;&#23558;&#36825;&#19968;&#32467;&#26524;&#25193;&#23637;&#21040;&#20102;&#26080;&#35270;&#30340;&#27010;&#29575;
&lt;/p&gt;
&lt;p&gt;
arXiv:1909.03820v2 Announce Type: replace-cross  Abstract: We study Boolean classification problems over relational background structures in the logical framework introduced by Grohe and Tur\'an (TOCS 2004). It is known (Grohe and Ritzert, LICS 2017) that classifiers definable in first-order logic over structures of polylogarithmic degree can be learned in sublinear time, where the degree of the structure and the running time are measured in terms of the size of the structure. We generalise the results to the first-order logic with counting FOCN, which was introduced by Kuske and Schweikardt (LICS 2017) as an expressive logic generalising various other counting logics. Specifically, we prove that classifiers definable in FOCN over classes of structures of polylogarithmic degree can be consistently learned in sublinear time. This can be seen as a first step towards extending the learning framework to include numerical aspects of machine learning. We extend the result to agnostic probabl
&lt;/p&gt;</description></item><item><title>&#30001;&#20110;&#29992;&#25143;&#38656;&#27714;&#21644;&#26368;&#36817;&#30340;&#27861;&#35268;&#35201;&#27714;&#65292;&#38656;&#35201;&#23545;AI&#31995;&#32479;&#25152;&#20570;&#20986;&#30340;&#20915;&#31574;&#36827;&#34892;&#35299;&#37322;&#12290;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Sum-Product Networks&#27169;&#25311;&#23547;&#25214;&#39640;&#21487;&#33021;&#24615;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#25552;&#20379;&#28385;&#36275;&#22810;&#20010;&#24120;&#35265;&#35201;&#27714;&#30340;&#26368;&#20339;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2401.14086</link><description>&lt;p&gt;
&#20351;&#29992;Sum-Product Networks&#29983;&#25104;&#21487;&#33021;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Generating Likely Counterfactuals Using Sum-Product Networks. (arXiv:2401.14086v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14086
&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#29992;&#25143;&#38656;&#27714;&#21644;&#26368;&#36817;&#30340;&#27861;&#35268;&#35201;&#27714;&#65292;&#38656;&#35201;&#23545;AI&#31995;&#32479;&#25152;&#20570;&#20986;&#30340;&#20915;&#31574;&#36827;&#34892;&#35299;&#37322;&#12290;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Sum-Product Networks&#27169;&#25311;&#23547;&#25214;&#39640;&#21487;&#33021;&#24615;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#25552;&#20379;&#28385;&#36275;&#22810;&#20010;&#24120;&#35265;&#35201;&#27714;&#30340;&#26368;&#20339;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#29992;&#25143;&#38656;&#27714;&#21644;&#26368;&#36817;&#30340;&#27861;&#35268;&#65288;GDPR&#12289;AI&#27861;&#26696;&#65289;&#65292;&#38656;&#35201;&#35299;&#37322;AI&#31995;&#32479;&#25152;&#20570;&#20986;&#30340;&#20915;&#31574;&#12290;&#36825;&#20123;&#20915;&#31574;&#24448;&#24448;&#21482;&#33021;&#22312;&#20107;&#21518;&#35299;&#37322;&#65292;&#21453;&#20107;&#23454;&#25512;&#29702;&#25104;&#20026;&#24120;&#35265;&#30340;&#35299;&#37322;&#26041;&#24335;&#12290;&#20160;&#20040;&#26500;&#25104;&#20102;&#26368;&#20339;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#24517;&#39035;&#32771;&#34385;&#22810;&#20010;&#26041;&#38754;&#65292;&#20854;&#20013;&#8220;&#26679;&#26412;&#36317;&#31163;&#8221;&#26159;&#26368;&#24120;&#35265;&#30340;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#19968;&#35201;&#27714;&#32463;&#24120;&#20250;&#23548;&#33268;&#19981;&#22826;&#21487;&#33021;&#19988;&#22240;&#27492;&#20215;&#20540;&#26377;&#38480;&#30340;&#35299;&#37322;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#25552;&#20379;&#39640;&#21487;&#33021;&#24615;&#35299;&#37322;&#30340;&#31995;&#32479;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#65288;MIO&#65289;&#27169;&#25311;&#23547;&#25214;&#28385;&#36275;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#35768;&#22810;&#24120;&#35265;&#35201;&#27714;&#30340;&#26368;&#26377;&#21487;&#33021;&#35299;&#37322;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Sum-Product Network&#65288;SPN&#65289;&#30340;MIO&#34920;&#36798;&#65292;&#24182;&#20351;&#29992;SPN&#20272;&#35745;&#21453;&#20107;&#23454;&#30340;&#21487;&#33021;&#24615;&#65292;&#36825;&#23545;&#29420;&#31435;&#30340;&#20852;&#36259;&#20063;&#26377;&#29992;&#12290;&#19982;&#29983;&#25104;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#20960;&#31181;&#26041;&#27861;&#36827;&#34892;&#25968;&#20540;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to user demand and recent regulation (GDPR, AI Act), decisions made by AI systems need to be explained. These decisions are often explainable only post hoc, where counterfactual explanations are popular. The question of what constitutes the best counterfactual explanation must consider multiple aspects, where "distance from the sample" is the most common. We argue that this requirement frequently leads to explanations that are unlikely and, therefore, of limited value. Here, we present a system that provides high-likelihood explanations. We show that the search for the most likely explanations satisfying many common desiderata for counterfactual explanations can be modeled using mixed-integer optimization (MIO). In the process, we propose an MIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate the likelihood of a counterfactual, which can be of independent interest. A numerical comparison against several methods for generating counterfactual explanations is pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#35780;&#20272;&#32473;&#23450;&#36335;&#24452;&#35268;&#21010;&#20013;&#29305;&#23450;&#26102;&#38388;&#28857;&#19978;&#30340;&#21333;&#20010;&#32447;&#24615;&#26102;&#38388;&#36923;&#36753;(LTL)&#32422;&#26463;&#30340;&#30456;&#20851;&#24615;&#21644;&#29366;&#24577;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#20110;&#22312;&#31163;&#25955;&#26102;&#38388;&#12289;&#31163;&#25955;&#31354;&#38388;&#20013;&#25191;&#34892;&#26377;&#38480;&#35745;&#21010;&#30340;&#20195;&#29702;&#20219;&#21153;&#20013;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#26102;&#38388;&#28857;&#35299;&#37322;&#21644;&#35268;&#21017;&#21442;&#25968;&#29366;&#24577;&#30340;&#27934;&#23519;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.13956</link><description>&lt;p&gt;
&#32447;&#24615;&#26102;&#38388;&#36923;&#36753;&#35268;&#21017;&#30340;&#26102;&#38388;&#28857;&#35299;&#37322;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Pointwise-in-Time Explanation for Linear Temporal Logic Rules. (arXiv:2306.13956v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13956
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#35780;&#20272;&#32473;&#23450;&#36335;&#24452;&#35268;&#21010;&#20013;&#29305;&#23450;&#26102;&#38388;&#28857;&#19978;&#30340;&#21333;&#20010;&#32447;&#24615;&#26102;&#38388;&#36923;&#36753;(LTL)&#32422;&#26463;&#30340;&#30456;&#20851;&#24615;&#21644;&#29366;&#24577;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#20110;&#22312;&#31163;&#25955;&#26102;&#38388;&#12289;&#31163;&#25955;&#31354;&#38388;&#20013;&#25191;&#34892;&#26377;&#38480;&#35745;&#21010;&#30340;&#20195;&#29702;&#20219;&#21153;&#20013;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#26102;&#38388;&#28857;&#35299;&#37322;&#21644;&#35268;&#21017;&#21442;&#25968;&#29366;&#24577;&#30340;&#27934;&#23519;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#35780;&#20272;&#32473;&#23450;&#36335;&#24452;&#35268;&#21010;&#20013;&#29305;&#23450;&#26102;&#38388;&#28857;&#19978;&#30340;&#21333;&#20010;&#32447;&#24615;&#26102;&#38388;&#36923;&#36753;(LTL)&#32422;&#26463;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#20010;&#20219;&#21153;&#34987;&#25105;&#20204;&#31216;&#20026;&#8220;&#26102;&#38388;&#28857;&#35299;&#37322;&#8221;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#21547;&#29366;&#24577;&#35780;&#20272;&#31639;&#27861;&#30340;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#22312;Kripke&#32467;&#26500;&#21487;&#34920;&#36798;&#30340;&#31163;&#25955;&#26102;&#38388;&#12289;&#31163;&#25955;&#31354;&#38388;&#20013;&#25191;&#34892;&#26377;&#38480;&#35745;&#21010;&#30340;&#20195;&#29702;&#12290;&#22312;&#32473;&#23450;&#30340;&#32467;&#26500;&#19978;&#21644;&#24050;&#30693;&#32422;&#26463;&#20195;&#29702;&#30340;&#19968;&#32452;LTL&#35268;&#21017;&#30340;&#35745;&#21010;&#20013;&#65292;&#35813;&#31639;&#27861;&#38024;&#23545;&#20004;&#31181;&#31867;&#22411;&#30340;&#29992;&#25143;&#26597;&#35810;&#21709;&#24212;&#22320;&#29983;&#25104;&#35299;&#37322;&#12290;&#23545;&#20110;&#25152;&#36873;&#30340;&#26597;&#35810;&#26102;&#38388;&#65292;&#35299;&#37322;&#35782;&#21035;&#21738;&#20123;&#35268;&#21017;&#26159;&#27963;&#21160;&#30340;&#65292;&#21738;&#20123;&#35268;&#21017;&#21018;&#21018;&#34987;&#28385;&#36275;&#65292;&#21738;&#20123;&#35268;&#21017;&#26159;&#19981;&#27963;&#21160;&#30340;&#65292;&#20854;&#20013;&#26694;&#26550;&#29366;&#24577;&#26631;&#20934;&#26159;&#27491;&#24335;&#21644;&#30452;&#35266;&#22320;&#23450;&#20041;&#30340;&#12290;&#35299;&#37322;&#36824;&#21487;&#20197;&#21253;&#25324;&#21333;&#20010;&#35268;&#21017;&#21442;&#25968;&#30340;&#29366;&#24577;&#65292;&#20197;&#25552;&#20379;&#36827;&#19968;&#27493;&#30340;&#27934;&#23519;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#20171;&#32461;&#20102;&#36825;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20379;&#20102;&#20854;&#23454;&#29616;&#30340;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces a framework to assess the relevance of individual linear temporal logic (LTL) constraints at specific times in a given path plan, a task we refer to as "pointwise-in-time" explanation. We develop this framework, featuring a status assessment algorithm, for agents which execute finite plans in a discrete-time, discrete-space setting expressible via a Kripke structure. Given a plan on this structure and a set of LTL rules which are known to constrain the agent, the algorithm responds to two types of user queries to produce explanation. For the selected query time, explanations identify which rules are active, which have just been satisfied, and which are inactive, where the framework status criteria are formally and intuitively defined. Explanations may also include the status of individual rule arguments to provide further insight. In this paper, we systematically present this novel framework and provide an example of its implementation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25991;&#26412;&#33267;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#30340;&#22270;&#20687;&#21040;&#22270;&#20687;&#36716;&#25442;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#25968;&#25454;&#22686;&#24378;&#30340;&#22810;&#26679;&#24615;&#19981;&#36275;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#27867;&#21270;&#21040;&#26032;&#35270;&#35273;&#27010;&#24565;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#23569;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#21644;&#22270;&#20687;&#35782;&#21035;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.07944</link><description>&lt;p&gt;
&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#26377;&#25928;&#30340;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Effective Data Augmentation With Diffusion Models. (arXiv:2302.07944v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25991;&#26412;&#33267;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#30340;&#22270;&#20687;&#21040;&#22270;&#20687;&#36716;&#25442;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#25968;&#25454;&#22686;&#24378;&#30340;&#22810;&#26679;&#24615;&#19981;&#36275;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#27867;&#21270;&#21040;&#26032;&#35270;&#35273;&#27010;&#24565;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#23569;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#21644;&#22270;&#20687;&#35782;&#21035;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#26159;&#28145;&#24230;&#23398;&#20064;&#20013;&#26368;&#24120;&#35265;&#30340;&#24037;&#20855;&#20043;&#19968;&#65292;&#25903;&#25745;&#30528;&#26368;&#36817;&#21253;&#25324;&#20998;&#31867;&#12289;&#29983;&#25104;&#27169;&#22411;&#21644;&#34920;&#31034;&#23398;&#20064;&#22312;&#20869;&#30340;&#35768;&#22810;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#22686;&#24378;&#26041;&#27861;&#22312;&#25968;&#25454;&#30340;&#20851;&#38190;&#35821;&#20041;&#36724;&#19978;&#32570;&#20047;&#22810;&#26679;&#24615;&#65292;&#32570;&#20047;&#25913;&#21464;&#39640;&#32423;&#35821;&#20041;&#23646;&#24615;&#65288;&#22914;&#22330;&#26223;&#20013;&#30340;&#21160;&#29289;&#31181;&#31867;&#65289;&#20197;&#22686;&#24378;&#25968;&#25454;&#22810;&#26679;&#24615;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25991;&#26412;&#33267;&#22270;&#20687;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#30340;&#22270;&#20687;&#21040;&#22270;&#20687;&#36716;&#25442;&#26469;&#35299;&#20915;&#25968;&#25454;&#22686;&#24378;&#22810;&#26679;&#24615;&#19981;&#36275;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#29616;&#25104;&#30340;&#25193;&#25955;&#27169;&#22411;&#32534;&#36753;&#22270;&#20687;&#65292;&#25913;&#21464;&#23427;&#20204;&#30340;&#35821;&#20041;&#65292;&#33021;&#22815;&#27867;&#21270;&#21040;&#20165;&#29992;&#23569;&#37327;&#26631;&#35760;&#31034;&#20363;&#24471;&#21040;&#30340;&#26032;&#35270;&#35273;&#27010;&#24565;&#12290;&#25105;&#20204;&#22312;&#23569;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#26434;&#33609;&#35782;&#21035;&#20219;&#21153;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#35266;&#23519;&#21040;......
&lt;/p&gt;
&lt;p&gt;
Data augmentation is one of the most prevalent tools in deep learning, underpinning many recent advances, including those from classification, generative models, and representation learning. The standard approach to data augmentation combines simple transformations like rotations and flips to generate new images from existing ones. However, these new images lack diversity along key semantic axes present in the data. Current augmentations cannot alter the high-level semantic attributes, such as animal species present in a scene, to enhance the diversity of data. We address the lack of diversity in data augmentation with image-to-image transformations parameterized by pre-trained text-to-image diffusion models. Our method edits images to change their semantics using an off-the-shelf diffusion model, and generalizes to novel visual concepts from a few labelled examples. We evaluate our approach on few-shot image classification tasks, and on a real-world weed recognition task, and observe 
&lt;/p&gt;</description></item></channel></rss>