<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#23545;&#21019;&#24847;&#20135;&#19994;&#24102;&#26469;&#30340;&#29256;&#26435;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#20844;&#24179;&#20351;&#29992;&#26631;&#20934;&#21644;AI-&#29256;&#26435;&#24615;&#23545;AI&#21457;&#23637;&#21644;&#20844;&#21496;&#21033;&#28070;&#30340;&#24433;&#21709;</title><link>https://arxiv.org/abs/2402.17801</link><description>&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#19982;&#29256;&#26435;&#65306;&#19968;&#20010;&#21160;&#24577;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Generative AI and Copyright: A Dynamic Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17801
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#23545;&#21019;&#24847;&#20135;&#19994;&#24102;&#26469;&#30340;&#29256;&#26435;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#20844;&#24179;&#20351;&#29992;&#26631;&#20934;&#21644;AI-&#29256;&#26435;&#24615;&#23545;AI&#21457;&#23637;&#21644;&#20844;&#21496;&#21033;&#28070;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#30340;&#24555;&#36895;&#21457;&#23637;&#21363;&#23558;&#39072;&#35206;&#21019;&#24847;&#20135;&#19994;&#12290;&#22312;&#23545;&#36825;&#39033;&#26032;&#25216;&#26415;&#30340;&#24040;&#22823;&#20852;&#22859;&#20013;&#65292;&#20854;&#22312;&#21019;&#24847;&#20135;&#19994;&#20013;&#30340;&#26410;&#26469;&#21457;&#23637;&#21644;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#30340;&#20004;&#20010;&#29256;&#26435;&#38382;&#39064;&#26159;&#65306;1) &#34917;&#20607;&#37027;&#20123;&#29992;&#20110;&#35757;&#32451;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#30340;&#21019;&#20316;&#32773;&#65288;&#20844;&#24179;&#20351;&#29992;&#26631;&#20934;&#65289;&#65307;&#21644;2) AI&#29983;&#25104;&#30340;&#20869;&#23481;&#26159;&#21542;&#26377;&#36164;&#26684;&#33719;&#24471;&#29256;&#26435;&#20445;&#25252;&#65288;AI-&#29256;&#26435;&#24615;&#65289;&#12290;&#34429;&#28982;&#36825;&#20004;&#20010;&#38382;&#39064;&#24341;&#21457;&#20102;&#23398;&#26415;&#30028;&#21644;&#23454;&#36341;&#32773;&#20043;&#38388;&#28608;&#28872;&#30340;&#20105;&#35770;&#65292;&#20294;&#22823;&#22810;&#25968;&#20998;&#26512;&#37117;&#38598;&#20013;&#22312;&#23427;&#20204;&#23545;&#29616;&#26377;&#29256;&#26435;&#21407;&#21017;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#20004;&#20010;&#30417;&#31649;&#38382;&#39064;&#21450;&#20854;&#20114;&#21160;&#23545;&#32463;&#27982;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#20855;&#26377;&#20869;&#29983;&#20869;&#23481;&#21019;&#20316;&#21644;AI&#27169;&#22411;&#21457;&#23637;&#30340;&#21160;&#24577;&#27169;&#22411;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20844;&#24179;&#20351;&#29992;&#26631;&#20934;&#21644;AI-&#29256;&#26435;&#24615;&#23545;AI&#21457;&#23637;&#12289;AI&#20844;&#21496;&#21033;&#28070;&#12289;cr&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17801v1 Announce Type: cross  Abstract: The rapid advancement of generative AI is poised to disrupt the creative industry. Amidst the immense excitement for this new technology, its future development and applications in the creative industry hinge crucially upon two copyright issues: 1) the compensation to creators whose content has been used to train generative AI models (the fair use standard); and 2) the eligibility of AI-generated content for copyright protection (AI-copyrightability). While both issues have ignited heated debates among academics and practitioners, most analysis has focused on their challenges posed to existing copyright doctrines. In this paper, we aim to better understand the economic implications of these two regulatory issues and their interactions. By constructing a dynamic model with endogenous content creation and AI model development, we unravel the impacts of the fair use standard and AI-copyrightability on AI development, AI company profit, cr
&lt;/p&gt;</description></item><item><title>&#23558;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#23454;&#38469;&#21709;&#24212;&#39118;&#26684;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22266;&#26377;&#39118;&#26684;&#30456;&#21305;&#37197;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#23398;&#20064;&#32467;&#26524;&#65292;&#24320;&#21457;&#30340;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#31243;&#24230;&#22320;&#35843;&#25972;&#27169;&#22411;&#21709;&#24212;&#26469;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.11192</link><description>&lt;p&gt;
&#22914;&#26524;&#20320;&#35762;&#25105;&#30340;&#35821;&#35328;&#65292;&#25105;&#20250;&#26356;&#22909;&#22320;&#23398;&#20064;&#65306;&#20351;&#29992;&#39118;&#26684;&#23545;&#40784;&#21709;&#24212;&#35843;&#25972;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
I Learn Better If You Speak My Language: Enhancing Large Language Model Fine-Tuning with Style-Aligned Response Adjustments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11192
&lt;/p&gt;
&lt;p&gt;
&#23558;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#23454;&#38469;&#21709;&#24212;&#39118;&#26684;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22266;&#26377;&#39118;&#26684;&#30456;&#21305;&#37197;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#23398;&#20064;&#32467;&#26524;&#65292;&#24320;&#21457;&#30340;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#31243;&#24230;&#22320;&#35843;&#25972;&#27169;&#22411;&#21709;&#24212;&#26469;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#23567;&#25968;&#25454;&#38598;&#20026;&#29305;&#23450;&#20219;&#21153;&#24494;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26159;&#19968;&#20010;&#26222;&#36941;&#36935;&#21040;&#30340;&#20294;&#22797;&#26434;&#30340;&#25361;&#25112;&#12290;&#22312;&#26377;&#38480;&#30340;&#31034;&#20363;&#19978;&#36807;&#22810;&#25311;&#21512;&#21487;&#33021;&#20250;&#23545;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#20445;&#30041;&#21407;&#22987;&#25216;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#22320;&#23454;&#38469;&#21709;&#24212;&#39118;&#26684;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#23558;&#22320;&#23454;&#38469;&#21709;&#24212;&#39118;&#26684;&#19982;LLM&#22266;&#26377;&#39118;&#26684;&#21305;&#37197;&#20250;&#20135;&#29983;&#26356;&#22909;&#30340;&#23398;&#20064;&#32467;&#26524;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#28857;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#26368;&#23567;&#31243;&#24230;&#22320;&#20462;&#25913;LLM&#30340;&#29616;&#26377;&#21709;&#24212;&#20197;&#26356;&#27491;&#38169;&#35823;&#65292;&#20351;&#29992;&#36825;&#20123;&#35843;&#25972;&#21518;&#30340;&#21709;&#24212;&#20316;&#20026;&#35757;&#32451;&#30446;&#26631;&#12290;&#36825;&#31181;&#25216;&#26415;&#33021;&#22815;&#23454;&#29616;&#19982;&#27169;&#22411;&#22266;&#26377;&#21709;&#24212;&#39118;&#26684;&#19968;&#33268;&#30340;&#31934;&#30830;&#26356;&#27491;&#65292;&#32500;&#25252;&#27169;&#22411;&#30340;&#26680;&#24515;&#33021;&#21147;&#65292;&#20174;&#32780;&#36991;&#20813;&#36807;&#22810;&#25311;&#21512;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;LLM&#30340;&#29305;&#23450;&#20219;&#21153;&#20934;&#30830;&#24615;&#65292;&#32780;&#19988;&#20851;&#38190;&#22320;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11192v1 Announce Type: cross  Abstract: Fine-tuning large language models (LLMs) with a small data set for particular tasks is a widely encountered yet complex challenge. The potential for overfitting on a limited number of examples can negatively impact the model's ability to generalize and retain its original skills. Our research explores the impact of the style of ground-truth responses during the fine-tuning process. We found that matching the ground-truth response style with the LLM's inherent style results in better learning outcomes. Building on this insight, we developed a method that minimally alters the LLM's pre-existing responses to correct errors, using these adjusted responses as training targets. This technique enables precise corrections in line with the model's native response style, safeguarding the model's core capabilities and thus avoid overfitting. Our findings show that this approach not only improves the LLM's task-specific accuracy but also crucially
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#19982;&#26426;&#21046;&#35774;&#35745;&#30340;&#32467;&#21512;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#26080;&#27861;&#21516;&#26102;&#28385;&#36275;&#25152;&#26377;&#26399;&#26395;&#29305;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#36817;&#20284;&#28385;&#36275;&#29305;&#24615;&#35201;&#27714;&#30340;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.05683</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#19982;&#26426;&#21046;&#35774;&#35745;&#65306;&#20851;&#38190;&#32467;&#26524;&#21644;&#19968;&#20123;&#26032;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Learning Meets Mechanism Design: Key Results and Some Novel Applications. (arXiv:2401.05683v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#19982;&#26426;&#21046;&#35774;&#35745;&#30340;&#32467;&#21512;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#26080;&#27861;&#21516;&#26102;&#28385;&#36275;&#25152;&#26377;&#26399;&#26395;&#29305;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#36817;&#20284;&#28385;&#36275;&#29305;&#24615;&#35201;&#27714;&#30340;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#21046;&#35774;&#35745;&#26412;&#36136;&#19978;&#26159;&#23545;&#28216;&#25103;&#30340;&#36870;&#21521;&#24037;&#31243;&#65292;&#28041;&#21450;&#22312;&#21338;&#24328;&#20013;&#35825;&#23548;&#19968;&#31181;&#26041;&#24335;&#65292;&#20351;&#24471;&#35825;&#23548;&#30340;&#21338;&#24328;&#22312;&#21338;&#24328;&#22343;&#34913;&#20013;&#28385;&#36275;&#19968;&#32452;&#26399;&#26395;&#30340;&#29305;&#24615;&#12290;&#26426;&#21046;&#30340;&#26399;&#26395;&#29305;&#24615;&#21253;&#25324;&#28608;&#21169;&#20860;&#23481;&#24615;&#12289;&#20010;&#20307;&#21512;&#29702;&#24615;&#12289;&#31119;&#21033;&#26368;&#22823;&#21270;&#12289;&#25910;&#20837;&#26368;&#22823;&#21270;&#65288;&#25110;&#25104;&#26412;&#26368;&#23567;&#21270;&#65289;&#12289;&#20998;&#37197;&#20844;&#24179;&#31561;&#12290;&#26681;&#25454;&#26426;&#21046;&#35774;&#35745;&#29702;&#35770;&#65292;&#21482;&#26377;&#26576;&#20123;&#20005;&#26684;&#30340;&#23376;&#38598;&#21487;&#20197;&#21516;&#26102;&#34987;&#20219;&#20309;&#32473;&#23450;&#30340;&#26426;&#21046;&#23436;&#20840;&#28385;&#36275;&#12290;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#25152;&#38656;&#30340;&#26426;&#21046;&#21487;&#33021;&#38656;&#35201;&#19968;&#20123;&#22312;&#29702;&#35770;&#19978;&#26080;&#27861;&#21516;&#26102;&#28385;&#36275;&#30340;&#29305;&#24615;&#23376;&#38598;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#26174;&#33879;&#30340;&#36817;&#26399;&#26041;&#27861;&#26159;&#20351;&#29992;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#36866;&#24403;&#23450;&#20041;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#23398;&#20064;&#19968;&#20010;&#36817;&#20284;&#28385;&#36275;&#25152;&#38656;&#29305;&#24615;&#30340;&#26426;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#30456;&#20851;&#25991;&#29486;&#20013;&#20171;&#32461;&#20102;&#25216;&#26415;&#32454;&#33410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mechanism design is essentially reverse engineering of games and involves inducing a game among strategic agents in a way that the induced game satisfies a set of desired properties in an equilibrium of the game. Desirable properties for a mechanism include incentive compatibility, individual rationality, welfare maximisation, revenue maximisation (or cost minimisation), fairness of allocation, etc. It is known from mechanism design theory that only certain strict subsets of these properties can be simultaneously satisfied exactly by any given mechanism. Often, the mechanisms required by real-world applications may need a subset of these properties that are theoretically impossible to be simultaneously satisfied. In such cases, a prominent recent approach is to use a deep learning based approach to learn a mechanism that approximately satisfies the required properties by minimizing a suitably defined loss function. In this paper, we present, from relevant literature, technical details 
&lt;/p&gt;</description></item></channel></rss>