<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#26041;&#27861;&#65292;JudgeDeceiver&#65292;&#38024;&#23545;LLM-as-a-Judge&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#23454;&#29616;&#20102;&#26377;&#38024;&#23545;&#24615;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;&#35780;&#20272;&#25805;&#25511;&#12290;</title><link>https://arxiv.org/abs/2403.17710</link><description>&lt;p&gt;
&#22522;&#20110;&#20248;&#21270;&#30340;&#23545;LLM&#35780;&#21028;&#31995;&#32479;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Optimization-based Prompt Injection Attack to LLM-as-a-Judge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17710
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#26041;&#27861;&#65292;JudgeDeceiver&#65292;&#38024;&#23545;LLM-as-a-Judge&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#23454;&#29616;&#20102;&#26377;&#38024;&#23545;&#24615;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;&#35780;&#20272;&#25805;&#25511;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLM-as-a-Judge &#26159;&#19968;&#31181;&#21487;&#20197;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#35780;&#20272;&#25991;&#26412;&#20449;&#24687;&#30340;&#26032;&#39062;&#35299;&#20915;&#26041;&#26696;&#12290;&#26681;&#25454;&#29616;&#26377;&#30740;&#31350;&#65292;LLMs&#22312;&#25552;&#20379;&#20256;&#32479;&#20154;&#31867;&#35780;&#20272;&#30340;&#24341;&#20154;&#27880;&#30446;&#26367;&#20195;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#38024;&#23545;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;JudgeDeceiver&#65292;&#19968;&#31181;&#38024;&#23545;LLM-as-a-Judge&#37327;&#36523;&#23450;&#21046;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21046;&#23450;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#29992;&#20110;&#25915;&#20987;LLM-as-a-Judge&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#20248;&#21270;&#31639;&#27861;&#39640;&#25928;&#22320;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#65292;&#23454;&#29616;&#23545;&#27169;&#22411;&#35780;&#20272;&#30340;&#26377;&#38024;&#23545;&#24615;&#21644;&#26377;&#25928;&#30340;&#25805;&#20316;&#12290;&#19982;&#25163;&#24037;&#21046;&#20316;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#21151;&#25928;&#65292;&#32473;&#22522;&#20110;LLM&#30340;&#21028;&#26029;&#31995;&#32479;&#24403;&#21069;&#30340;&#23433;&#20840;&#33539;&#24335;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17710v1 Announce Type: cross  Abstract: LLM-as-a-Judge is a novel solution that can assess textual information with large language models (LLMs). Based on existing research studies, LLMs demonstrate remarkable performance in providing a compelling alternative to traditional human assessment. However, the robustness of these systems against prompt injection attacks remains an open question. In this work, we introduce JudgeDeceiver, a novel optimization-based prompt injection attack tailored to LLM-as-a-Judge. Our method formulates a precise optimization objective for attacking the decision-making process of LLM-as-a-Judge and utilizes an optimization algorithm to efficiently automate the generation of adversarial sequences, achieving targeted and effective manipulation of model evaluations. Compared to handcraft prompt injection attacks, our method demonstrates superior efficacy, posing a significant challenge to the current security paradigms of LLM-based judgment systems. T
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#36827;&#21270;&#26041;&#27861;&#30340;&#21333;&#26234;&#33021;&#20307;&#19982;&#22810;&#26234;&#33021;&#20307;&#31169;&#23494;&#20027;&#21160;&#24863;&#30693;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#26080;&#32447;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#31034;&#20363;&#29992;&#20363;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10112</link><description>&lt;p&gt;
&#21333;&#26234;&#33021;&#20307;&#19982;&#22810;&#26234;&#33021;&#20307;&#30340;&#31169;&#23494;&#20027;&#21160;&#24863;&#30693;&#65306;&#28145;&#24230;&#31070;&#32463;&#36827;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#36827;&#21270;&#26041;&#27861;&#30340;&#21333;&#26234;&#33021;&#20307;&#19982;&#22810;&#26234;&#33021;&#20307;&#31169;&#23494;&#20027;&#21160;&#24863;&#30693;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#26080;&#32447;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#31034;&#20363;&#29992;&#20363;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#23384;&#22312;&#31397;&#35270;&#32773;&#24773;&#20917;&#19979;&#30340;&#20027;&#21160;&#20551;&#35774;&#27979;&#35797;&#20013;&#30340;&#19968;&#20010;&#38598;&#20013;&#24335;&#38382;&#39064;&#21644;&#19968;&#20010;&#20998;&#25955;&#24335;&#38382;&#39064;&#12290;&#38024;&#23545;&#21253;&#25324;&#21333;&#20010;&#21512;&#27861;&#26234;&#33021;&#20307;&#30340;&#38598;&#20013;&#24335;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#31070;&#32463;&#36827;&#21270;&#65288;NE&#65289;&#30340;&#26032;&#26694;&#26550;&#65307;&#32780;&#38024;&#23545;&#20998;&#25955;&#24335;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;NE&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#20219;&#21153;&#65292;&#36825;&#31181;&#26041;&#27861;&#26377;&#36259;&#22320;&#20445;&#25345;&#20102;&#21333;&#19968;&#26234;&#33021;&#20307;NE&#30340;&#25152;&#26377;&#35745;&#31639;&#20248;&#21183;&#12290;&#36890;&#36807;&#23545;&#26080;&#32447;&#20256;&#24863;&#22120;&#32593;&#32476;&#19978;&#24322;&#24120;&#26816;&#27979;&#31034;&#20363;&#29992;&#20363;&#20013;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;EAHT&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#30340;&#20027;&#21160;&#20551;&#35774;&#27979;&#35797;&#31574;&#30053;&#20197;&#21450;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10112v1 Announce Type: new  Abstract: In this paper, we focus on one centralized and one decentralized problem of active hypothesis testing in the presence of an eavesdropper. For the centralized problem including a single legitimate agent, we present a new framework based on NeuroEvolution (NE), whereas, for the decentralized problem, we develop a novel NE-based method for solving collaborative multi-agent tasks, which interestingly maintains all computational benefits of single-agent NE. The superiority of the proposed EAHT approaches over conventional active hypothesis testing policies, as well as learning-based methods, is validated through numerical investigations in an example use case of anomaly detection over wireless sensor networks.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#26469;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2403.07151</link><description>&lt;p&gt;
&#19981;&#35201;&#24536;&#35760;&#25105;&#20570;&#30340;&#20107;&#65306;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;
Don't Forget What I did?: Assessing Client Contributions in Federated Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07151
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#26469;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#21327;&#20316;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#65292;&#22810;&#20010;&#23458;&#25143;&#21442;&#19982;&#35757;&#32451;ML&#27169;&#22411;&#65292;&#32780;&#19981;&#26292;&#38706;&#31169;&#20154;&#25968;&#25454;&#12290;&#20844;&#24179;&#20934;&#30830;&#35780;&#20272;&#23458;&#25143;&#36129;&#29486;&#22312;FL&#20013;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#20197;&#20419;&#36827;&#28608;&#21169;&#20998;&#37197;&#24182;&#40723;&#21169;&#22810;&#26679;&#21270;&#23458;&#25143;&#21442;&#19982;&#32479;&#19968;&#27169;&#22411;&#35757;&#32451;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#20110;&#35780;&#20272;&#22312;&#27599;&#20010;FL&#35757;&#32451;&#26102;&#26399;&#20013;&#30340;&#65288;&#28508;&#22312;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#65289;&#23458;&#25143;&#21442;&#19982;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07151v1 Announce Type: cross  Abstract: Federated Learning (FL) is a collaborative machine learning (ML) approach, where multiple clients participate in training an ML model without exposing the private data. Fair and accurate assessment of client contributions is an important problem in FL to facilitate incentive allocation and encouraging diverse clients to participate in a unified model training. Existing methods for assessing client contribution adopts co-operative game-theoretic concepts, such as Shapley values, but under simplified assumptions. In this paper, we propose a history-aware game-theoretic framework, called FLContrib, to assess client contributions when a subset of (potentially non-i.i.d.) clients participate in each epoch of FL training. By exploiting the FL training process and linearity of Shapley value, we develop FLContrib that yields a historical timeline of client contributions as FL training progresses over epochs. Additionally, to assess client cont
&lt;/p&gt;</description></item><item><title>MuseGraph&#23558;GNNs&#21644;LLMs&#30340;&#20248;&#21183;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#21644;&#36890;&#29992;&#30340;&#22270;&#25366;&#25496;&#26041;&#27861;&#65292;&#21487;&#20197;&#36328;&#19981;&#21516;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#20351;&#29992;</title><link>https://arxiv.org/abs/2403.04780</link><description>&lt;p&gt;
MuseGraph&#65306;&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#23548;&#21521;&#25351;&#20196;&#35843;&#25972;&#29992;&#20110;&#36890;&#29992;&#22270;&#25366;&#25496;
&lt;/p&gt;
&lt;p&gt;
MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04780
&lt;/p&gt;
&lt;p&gt;
MuseGraph&#23558;GNNs&#21644;LLMs&#30340;&#20248;&#21183;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#21644;&#36890;&#29992;&#30340;&#22270;&#25366;&#25496;&#26041;&#27861;&#65292;&#21487;&#20197;&#36328;&#19981;&#21516;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#20351;&#29992;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#20016;&#23500;&#23646;&#24615;&#30340;&#22270;&#22312;&#24314;&#27169;&#20114;&#32852;&#23454;&#20307;&#21644;&#25913;&#36827;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#39044;&#27979;&#26041;&#38754;&#33267;&#20851;&#37325;&#35201;&#12290;&#20256;&#32479;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#36890;&#24120;&#29992;&#20110;&#24314;&#27169;&#24102;&#23646;&#24615;&#30340;&#22270;&#65292;&#20294;&#38656;&#35201;&#22312;&#24212;&#29992;&#20110;&#19981;&#21516;&#22270;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#26102;&#36827;&#34892;&#37325;&#26032;&#35757;&#32451;&#12290;&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#24341;&#20837;&#20102;&#26032;&#30340;&#33539;&#20363;&#65292;&#20294;LLMs&#22312;&#22270;&#25366;&#25496;&#20013;&#30340;&#29983;&#25104;&#28508;&#21147;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550; MuseGraph&#65292;&#23427;&#26080;&#32541;&#25972;&#21512;&#20102;GNNs&#21644;LLMs&#30340;&#20248;&#21183;&#65292;&#24182;&#20419;&#36827;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#21644;&#36890;&#29992;&#30340;&#22270;&#25366;&#25496;&#26041;&#27861;&#65292;&#21487;&#36328;&#19981;&#21516;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#20351;&#29992;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#25552;&#20986;&#30340;&#33258;&#36866;&#24212;&#36755;&#20837;&#29983;&#25104;&#24341;&#20837;&#19968;&#20010;&#32039;&#20945;&#30340;&#22270;&#25551;&#36848;&#65292;&#20197;&#22312;&#35821;&#35328;&#20196;&#29260;&#38480;&#21046;&#30340;&#32422;&#26463;&#19979;&#23553;&#35013;&#26469;&#33258;&#22270;&#30340;&#20851;&#38190;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04780v1 Announce Type: cross  Abstract: Graphs with abundant attributes are essential in modeling interconnected entities and improving predictions in various real-world applications. Traditional Graph Neural Networks (GNNs), which are commonly used for modeling attributed graphs, need to be re-trained every time when applied to different graph tasks and datasets. Although the emergence of Large Language Models (LLMs) has introduced a new paradigm in natural language processing, the generative potential of LLMs in graph mining remains largely under-explored. To this end, we propose a novel framework MuseGraph, which seamlessly integrates the strengths of GNNs and LLMs and facilitates a more effective and generic approach for graph mining across different tasks and datasets. Specifically, we first introduce a compact graph description via the proposed adaptive input generation to encapsulate key information from the graph under the constraints of language token limitations. T
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#31070;&#32463;&#36827;&#21270;&#31639;&#27861;&#20248;&#21270;&#20154;&#24037;&#33008;&#33146;&#27835;&#30103;&#31574;&#30053;&#65292;&#20943;&#23569;&#31958;&#23615;&#30149;&#24739;&#32773;&#30340;&#34880;&#31958;&#20559;&#24046;&#65292;&#24182;&#19988;&#38477;&#20302;&#27880;&#23556;&#27425;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.07949</link><description>&lt;p&gt;
&#20248;&#21270;&#20154;&#24037;&#33008;&#33146;&#35774;&#35745;&#20197;&#25913;&#21892;&#31958;&#23615;&#30149;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Optimizing the Design of an Artificial Pancreas to Improve Diabetes Management
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07949
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#36827;&#21270;&#31639;&#27861;&#20248;&#21270;&#20154;&#24037;&#33008;&#33146;&#27835;&#30103;&#31574;&#30053;&#65292;&#20943;&#23569;&#31958;&#23615;&#30149;&#24739;&#32773;&#30340;&#34880;&#31958;&#20559;&#24046;&#65292;&#24182;&#19988;&#38477;&#20302;&#27880;&#23556;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31958;&#23615;&#30149;&#26159;&#19968;&#31181;&#24930;&#24615;&#30142;&#30149;&#65292;&#24433;&#21709;&#32654;&#22269;&#22659;&#20869;&#26377;3800&#19975;&#20154;&#65292;&#23427;&#20250;&#24433;&#21709;&#36523;&#20307;&#23558;&#39135;&#29289;&#36716;&#21270;&#20026;&#33021;&#37327;&#65288;&#21363;&#34880;&#31958;&#65289;&#30340;&#33021;&#21147;&#12290;&#26631;&#20934;&#30340;&#27835;&#30103;&#26041;&#27861;&#26159;&#36890;&#36807;&#20351;&#29992;&#20154;&#24037;&#33008;&#33146;&#65292;&#21363;&#25345;&#32493;&#33008;&#23707;&#32032;&#27893;&#65288;&#22522;&#30784;&#27880;&#23556;&#65289;&#65292;&#20197;&#21450;&#23450;&#26399;&#27880;&#23556;&#33008;&#23707;&#32032;&#65288;&#31361;&#21457;&#27880;&#23556;&#65289;&#26469;&#34917;&#20805;&#30899;&#27700;&#21270;&#21512;&#29289;&#25668;&#20837;&#37327;&#12290;&#27835;&#30103;&#30446;&#26631;&#26159;&#23558;&#34880;&#31958;&#20445;&#25345;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#30340;&#20013;&#24515;&#20301;&#32622;&#65292;&#36890;&#36807;&#25345;&#32493;&#34880;&#31958;&#27979;&#37327;&#26469;&#36827;&#34892;&#34913;&#37327;&#12290;&#27425;&#35201;&#30446;&#26631;&#26159;&#20943;&#23569;&#27880;&#23556;&#27425;&#25968;&#65292;&#22240;&#20026;&#23545;&#26576;&#20123;&#24739;&#32773;&#26469;&#35828;&#27880;&#23556;&#26159;&#19981;&#24841;&#24555;&#19988;&#38590;&#20197;&#23454;&#26045;&#30340;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#31070;&#32463;&#36827;&#21270;&#26469;&#21457;&#29616;&#27835;&#30103;&#30340;&#26368;&#20339;&#31574;&#30053;&#12290;&#22522;&#20110;30&#22825;&#30340;&#27835;&#30103;&#21644;&#21333;&#20010;&#24739;&#32773;&#30340;&#27979;&#37327;&#25968;&#25454;&#38598;&#65292;&#39318;&#20808;&#35757;&#32451;&#20102;&#38543;&#26426;&#26862;&#26519;&#26469;&#39044;&#27979;&#26410;&#26469;&#30340;&#34880;&#31958;&#27700;&#24179;&#12290;&#28982;&#21518;&#36890;&#36807;&#36827;&#21270;&#20102;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#25351;&#23450;&#30899;&#27700;&#21270;&#21512;&#29289;&#25668;&#20837;&#37327;&#12289;&#22522;&#30784;&#27880;&#23556;&#27700;&#24179;&#21644;&#31361;&#21457;&#27880;&#23556;&#12290;&#36827;&#21270;&#21457;&#29616;&#20102;&#19968;&#20010;&#24085;&#32047;&#25176;&#21069;&#27839;&#65292;&#20943;&#23569;&#20102;&#19982;&#30446;&#26631;&#20540;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diabetes, a chronic condition that impairs how the body turns food into energy, i.e. blood glucose, affects 38 million people in the US alone. The standard treatment is to supplement carbohydrate intake with an artificial pancreas, i.e. a continuous insulin pump (basal shots), as well as occasional insulin injections (bolus shots). The goal of the treatment is to keep blood glucose at the center of an acceptable range, as measured through a continuous glucose meter. A secondary goal is to minimize injections, which are unpleasant and difficult for some patients to implement. In this study, neuroevolution was used to discover an optimal strategy for the treatment. Based on a dataset of 30 days of treatment and measurements of a single patient, a random forest was first trained to predict future glucose levels. A neural network was then evolved to prescribe carbohydrates, basal pumping levels, and bolus injections. Evolution discovered a Pareto front that reduced deviation from the targe
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;Tennessee Eastman Process&#12290;&#35843;&#30740;&#24635;&#32467;&#20102;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#31639;&#27861;&#30340;&#20248;&#21155;&#21183;&#12290;&#36824;&#35752;&#35770;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#21644;&#26080;&#26631;&#35760;&#26679;&#26412;&#31561;&#25361;&#25112;&#65292;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#24212;&#23545;&#12290;&#27604;&#36739;&#20102;&#19981;&#21516;&#31639;&#27861;&#22312;Tennessee Eastman Process&#19978;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;</title><link>http://arxiv.org/abs/2401.10266</link><description>&lt;p&gt;
&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;: &#26041;&#27861;&#35770;&#21644;&#19981;&#30830;&#23450;&#24615;&#31649;&#29702;&#31574;&#30053;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Intelligent Condition Monitoring of Industrial Plants: An Overview of Methodologies and Uncertainty Management Strategies. (arXiv:2401.10266v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;Tennessee Eastman Process&#12290;&#35843;&#30740;&#24635;&#32467;&#20102;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#31639;&#27861;&#30340;&#20248;&#21155;&#21183;&#12290;&#36824;&#35752;&#35770;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#21644;&#26080;&#26631;&#35760;&#26679;&#26412;&#31561;&#25361;&#25112;&#65292;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#24212;&#23545;&#12290;&#27604;&#36739;&#20102;&#19981;&#21516;&#31639;&#27861;&#22312;Tennessee Eastman Process&#19978;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29366;&#24577;&#30417;&#27979;&#22312;&#29616;&#20195;&#24037;&#19994;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#21644;&#21487;&#38752;&#24615;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#22312;&#24037;&#19994;&#24212;&#29992;&#20013;&#26085;&#30410;&#21463;&#21040;&#23398;&#26415;&#30028;&#21644;&#34892;&#19994;&#20851;&#27880;&#30340;&#22686;&#38271;&#20027;&#39064;&#21644;&#19968;&#31181;&#24378;&#22823;&#30340;&#25925;&#38556;&#35782;&#21035;&#26041;&#24335;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#24320;&#28304;&#22522;&#20934;Tennessee Eastman Process&#65288;TEP&#65289;&#12290;&#22312;&#36825;&#39033;&#35843;&#26597;&#20013;&#65292;&#24635;&#32467;&#20102;&#29992;&#20110;&#24037;&#19994;&#21378;&#25151;&#29366;&#24577;&#30417;&#27979;&#12289;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#30340;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#27599;&#31181;&#31639;&#27861;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#36824;&#28085;&#30422;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#12289;&#26080;&#26631;&#35760;&#26679;&#26412;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#22788;&#29702;&#36825;&#20123;&#25361;&#25112;&#12290;&#26368;&#21518;&#65292;&#27604;&#36739;&#20102;&#21033;&#29992;Tennessee Eastman Process&#30340;&#19981;&#21516;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;
Condition monitoring plays a significant role in the safety and reliability of modern industrial systems. Artificial intelligence (AI) approaches are gaining attention from academia and industry as a growing subject in industrial applications and as a powerful way of identifying faults. This paper provides an overview of intelligent condition monitoring and fault detection and diagnosis methods for industrial plants with a focus on the open-source benchmark Tennessee Eastman Process (TEP). In this survey, the most popular and state-of-the-art deep learning (DL) and machine learning (ML) algorithms for industrial plant condition monitoring, fault detection, and diagnosis are summarized and the advantages and disadvantages of each algorithm are studied. Challenges like imbalanced data, unlabelled samples and how deep learning models can handle them are also covered. Finally, a comparison of the accuracies and specifications of different algorithms utilizing the Tennessee Eastman Process 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#26080;&#30417;&#30563;&#39046;&#22495;&#36716;&#25442;&#20013;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;MPA&#28040;&#38500;&#29702;&#35770;&#65292;&#35299;&#20915;&#20102;CycleGAN&#21450;&#20854;&#21464;&#20307;&#20135;&#29983;&#20869;&#23481;&#19981;&#23545;&#40784;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.09671</link><description>&lt;p&gt;
&#36808;&#21521;&#21487;&#35782;&#21035;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#36716;&#25442;&#65306;&#19968;&#31181;&#22810;&#26679;&#21270;&#20998;&#24067;&#21305;&#37197;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach. (arXiv:2401.09671v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#26080;&#30417;&#30563;&#39046;&#22495;&#36716;&#25442;&#20013;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;MPA&#28040;&#38500;&#29702;&#35770;&#65292;&#35299;&#20915;&#20102;CycleGAN&#21450;&#20854;&#21464;&#20307;&#20135;&#29983;&#20869;&#23481;&#19981;&#23545;&#40784;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39046;&#22495;&#36716;&#25442;&#65288;UDT&#65289;&#26088;&#22312;&#25214;&#21040;&#23558;&#19968;&#20010;&#39046;&#22495;&#30340;&#26679;&#26412;&#65288;&#20363;&#22914;&#32032;&#25551;&#65289;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#39046;&#22495;&#65288;&#20363;&#22914;&#29031;&#29255;&#65289;&#30340;&#20989;&#25968;&#65292;&#21516;&#26102;&#19981;&#25913;&#21464;&#39640;&#23618;&#35821;&#20041;&#24847;&#20041;&#65288;&#20063;&#31216;&#20026;&#8220;&#20869;&#23481;&#8221;&#65289;&#12290;&#36825;&#20123;&#36716;&#25442;&#20989;&#25968;&#36890;&#24120;&#36890;&#36807;&#36716;&#25442;&#28304;&#39046;&#22495;&#21644;&#30446;&#26631;&#39046;&#22495;&#30340;&#27010;&#29575;&#20998;&#24067;&#26469;&#23547;&#25214;&#12290;CycleGAN&#21487;&#20197;&#35828;&#26159;&#36825;&#19968;&#39046;&#22495;&#20013;&#26368;&#20855;&#20195;&#34920;&#24615;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#20013;&#25351;&#20986;CycleGAN&#21450;&#20854;&#21464;&#20307;&#21487;&#33021;&#26080;&#27861;&#35782;&#21035;&#25152;&#38656;&#30340;&#36716;&#25442;&#20989;&#25968;&#65292;&#24182;&#20135;&#29983;&#20869;&#23481;&#19981;&#23545;&#40784;&#30340;&#36716;&#25442;&#12290;&#36825;&#31181;&#23616;&#38480;&#24615;&#28304;&#20110;&#23398;&#20064;&#20934;&#21017;&#35299;&#31354;&#38388;&#20013;&#23384;&#22312;&#22810;&#20010;&#36716;&#25442;&#20989;&#25968;&#65292;&#31216;&#20026;&#8220;&#20445;&#24230;&#33258;&#21516;&#26500;&#65288;MPA&#65289;&#8221;&#12290;&#23613;&#31649;&#24847;&#35782;&#21040;&#20102;&#36825;&#31181;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#20294;&#35299;&#20915;&#26041;&#26696;&#20173;&#28982;&#38590;&#20197;&#25214;&#21040;&#12290;&#26412;&#30740;&#31350;&#28145;&#20837;&#25506;&#31350;&#20102;&#26680;&#24515;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;MPA&#28040;&#38500;&#29702;&#35770;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;...
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain translation (UDT) aims to find functions that convert samples from one domain (e.g., sketches) to another domain (e.g., photos) without changing the high-level semantic meaning (also referred to as ``content''). The translation functions are often sought by probability distribution matching of the transformed source domain and target domain. CycleGAN stands as arguably the most representative approach among this line of work. However, it was noticed in the literature that CycleGAN and variants could fail to identify the desired translation functions and produce content-misaligned translations. This limitation arises due to the presence of multiple translation functions -- referred to as ``measure-preserving automorphism" (MPA) -- in the solution space of the learning criteria. Despite awareness of such identifiability issues, solutions have remained elusive. This study delves into the core identifiability inquiry and introduces an MPA elimination theory. Our analysi
&lt;/p&gt;</description></item><item><title>&#36882;&#24402;&#24635;&#32467;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#38271;&#26399;&#23545;&#35805;&#35760;&#24518;&#65292;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#31995;&#32479;&#22312;&#38271;&#23545;&#35805;&#20013;&#35760;&#24518;&#37325;&#35201;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.15022</link><description>&lt;p&gt;
&#36882;&#24402;&#24635;&#32467;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#38271;&#26399;&#23545;&#35805;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models. (arXiv:2308.15022v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15022
&lt;/p&gt;
&lt;p&gt;
&#36882;&#24402;&#24635;&#32467;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#38271;&#26399;&#23545;&#35805;&#35760;&#24518;&#65292;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#31995;&#32479;&#22312;&#38271;&#23545;&#35805;&#20013;&#35760;&#24518;&#37325;&#35201;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24320;&#25918;&#39046;&#22495;&#30340;&#23545;&#35805;&#31995;&#32479;&#22312;&#38271;&#26399;&#23545;&#35805;&#20013;&#23481;&#26131;&#36951;&#24536;&#37325;&#35201;&#20449;&#24687;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#35757;&#32451;&#29305;&#23450;&#30340;&#26816;&#32034;&#22120;&#25110;&#24635;&#32467;&#22120;&#20174;&#36807;&#21435;&#33719;&#21462;&#20851;&#38190;&#20449;&#24687;&#65292;&#36825;&#38656;&#35201;&#32791;&#36153;&#26102;&#38388;&#19988;&#39640;&#24230;&#20381;&#36182;&#26631;&#35760;&#25968;&#25454;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36882;&#24402;&#29983;&#25104;&#24635;&#32467;/&#35760;&#24518;&#65292;&#20197;&#22686;&#24378;&#38271;&#26399;&#35760;&#24518;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#21050;&#28608;LLMs&#35760;&#20303;&#23567;&#23545;&#35805;&#19978;&#19979;&#25991;&#65292;&#28982;&#21518;&#36882;&#24402;&#22320;&#20351;&#29992;&#20043;&#21069;&#30340;&#35760;&#24518;&#21644;&#38543;&#21518;&#30340;&#23545;&#35805;&#20869;&#23481;&#20135;&#29983;&#26032;&#30340;&#35760;&#24518;&#12290;&#26368;&#21518;&#65292;LLM&#21487;&#20197;&#22312;&#26368;&#26032;&#35760;&#24518;&#30340;&#24110;&#21161;&#19979;&#36731;&#26494;&#29983;&#25104;&#39640;&#24230;&#19968;&#33268;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#20351;&#29992;ChatGPT&#21644;text-davinci-003&#36827;&#34892;&#35780;&#20272;&#65292;&#23545;&#24191;&#27867;&#20351;&#29992;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#38271;&#23545;&#35805;&#20013;&#21487;&#20197;&#29983;&#25104;&#26356;&#19968;&#33268;&#30340;&#21709;&#24212;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#23454;&#29616;LLM&#24314;&#27169;&#30340;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most open-domain dialogue systems suffer from forgetting important information, especially in a long-term conversation. Existing works usually train the specific retriever or summarizer to obtain key information from the past, which is time-consuming and highly depends on the quality of labeled data. To alleviate this problem, we propose to recursively generate summaries/ memory using large language models (LLMs) to enhance long-term memory ability. Specifically, our method first stimulates LLMs to memorize small dialogue contexts and then recursively produce new memory using previous memory and following contexts. Finally, the LLM can easily generate a highly consistent response with the help of the latest memory. We evaluate our method using ChatGPT and text-davinci-003, and the experiments on the widely-used public dataset show that our method can generate more consistent responses in a long-context conversation. Notably, our method is a potential solution to enable the LLM to model
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;&#38382;&#39064;&#12290;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#36755;&#20837;&#30340;&#20219;&#24847;&#27169;&#24577;&#65292;&#20351;&#20854;&#23884;&#20837;&#19982;&#20854;&#20182;&#27169;&#24577;&#30340;&#20219;&#24847;&#36755;&#20837;&#25509;&#36817;&#65292;&#20174;&#32780;&#23454;&#29616;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#30340;&#23545;&#40784;&#12290;&#35813;&#38382;&#39064;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#65292;&#23545;&#29983;&#25104;&#21644;&#20998;&#31867;&#20219;&#21153;&#20250;&#20135;&#29983;&#35823;&#23548;&#12290;</title><link>http://arxiv.org/abs/2308.11804</link><description>&lt;p&gt;
&#36825;&#19981;&#26159;&#19968;&#20010;&#33529;&#26524;&#65306;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Ceci n'est pas une pomme: Adversarial Illusions in Multi-Modal Embeddings. (arXiv:2308.11804v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11804
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;&#38382;&#39064;&#12290;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#36755;&#20837;&#30340;&#20219;&#24847;&#27169;&#24577;&#65292;&#20351;&#20854;&#23884;&#20837;&#19982;&#20854;&#20182;&#27169;&#24577;&#30340;&#20219;&#24847;&#36755;&#20837;&#25509;&#36817;&#65292;&#20174;&#32780;&#23454;&#29616;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#30340;&#23545;&#40784;&#12290;&#35813;&#38382;&#39064;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#65292;&#23545;&#29983;&#25104;&#21644;&#20998;&#31867;&#20219;&#21153;&#20250;&#20135;&#29983;&#35823;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#23558;&#22270;&#20687;&#12289;&#22768;&#38899;&#12289;&#25991;&#26412;&#12289;&#35270;&#39057;&#31561;&#26144;&#23556;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#23545;&#40784;&#19981;&#21516;&#27169;&#24577;&#30340;&#34920;&#31034;&#65288;&#20363;&#22914;&#23558;&#19968;&#24352;&#29399;&#30340;&#22270;&#20687;&#19982;&#19968;&#31181;&#21483;&#22768;&#30456;&#20851;&#32852;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#21487;&#20197;&#21463;&#21040;&#19968;&#31181;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#23545;&#25239;&#24187;&#35273;&#8221;&#30340;&#25915;&#20987;&#12290;&#32473;&#23450;&#20219;&#24847;&#27169;&#24577;&#30340;&#36755;&#20837;&#65292;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#23427;&#65292;&#20351;&#20854;&#23884;&#20837;&#25509;&#36817;&#20110;&#21478;&#19968;&#27169;&#24577;&#20013;&#20219;&#24847;&#23545;&#25163;&#36873;&#25321;&#30340;&#36755;&#20837;&#30340;&#23884;&#20837;&#12290;&#24187;&#35273;&#20351;&#23545;&#25163;&#33021;&#22815;&#23558;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#31561;&#36827;&#34892;&#23545;&#40784;&#12290;&#23545;&#25239;&#24187;&#35273;&#21033;&#29992;&#20102;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#25509;&#36817;&#24615;&#65292;&#22240;&#27492;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#12290;&#20351;&#29992;ImageBind&#23884;&#20837;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#27809;&#26377;&#20855;&#20307;&#19979;&#28216;&#20219;&#21153;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#23545;&#25239;&#24615;&#23545;&#40784;&#30340;&#36755;&#20837;&#22914;&#20309;&#35823;&#23548;&#22270;&#20687;&#29983;&#25104;&#12289;&#25991;&#26412;&#29983;&#25104;&#21644;&#38646;&#26679;&#20363;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-modal encoders map images, sounds, texts, videos, etc. into a single embedding space, aligning representations across modalities (e.g., associate an image of a dog with a barking sound). We show that multi-modal embeddings can be vulnerable to an attack we call "adversarial illusions." Given an input in any modality, an adversary can perturb it so as to make its embedding close to that of an arbitrary, adversary-chosen input in another modality. Illusions thus enable the adversary to align any image with any text, any text with any sound, etc.  Adversarial illusions exploit proximity in the embedding space and are thus agnostic to downstream tasks. Using ImageBind embeddings, we demonstrate how adversarially aligned inputs, generated without knowledge of specific downstream tasks, mislead image generation, text generation, and zero-shot classification.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#40065;&#26834;&#27169;&#24577;&#36830;&#25509;&#23548;&#21521;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#65292;&#23454;&#29616;&#31070;&#32463;&#32593;&#32476;&#23545;&#22810;&#26679;&#21270;$\ell_p$&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#22522;&#20110;&#31181;&#32676;&#23398;&#20064;&#30340;&#23398;&#20064;&#38454;&#27573;&#12290;</title><link>http://arxiv.org/abs/2303.10225</link><description>&lt;p&gt;
&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#23545;&#22810;&#26679;&#21270;$\ell_p$&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;:&#40065;&#26834;&#27169;&#24577;&#36830;&#25509;&#23548;&#21521;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Robust Mode Connectivity-Oriented Adversarial Defense: Enhancing Neural Network Robustness Against Diversified $\ell_p$ Attacks. (arXiv:2303.10225v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#40065;&#26834;&#27169;&#24577;&#36830;&#25509;&#23548;&#21521;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#65292;&#23454;&#29616;&#31070;&#32463;&#32593;&#32476;&#23545;&#22810;&#26679;&#21270;$\ell_p$&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#22522;&#20110;&#31181;&#32676;&#23398;&#20064;&#30340;&#23398;&#20064;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#26159;&#34913;&#37327;&#31070;&#32463;&#32593;&#32476;&#22312;&#25512;&#29702;&#38454;&#27573;&#25269;&#24481;&#23545;&#25239;&#24615;&#25915;&#20987;&#33021;&#21147;&#30340;&#20851;&#38190;&#27010;&#24565;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#20351;&#29992;&#30340;&#24378;&#21270;&#40065;&#26834;&#24615;&#35757;&#32451;&#25216;&#26415;&#33021;&#22815;&#25552;&#39640;&#23545;&#19968;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#20294;&#27169;&#22411;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#22810;&#26679;&#21270;&#30340;$\ell_p$&#25915;&#20987;&#12290;&#20026;&#20102;&#23454;&#29616;&#22810;&#26679;&#21270;&#30340;$\ell_p$&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#40065;&#26834;&#27169;&#24577;&#36830;&#25509; (RMC) &#23548;&#21521;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#65292;&#23427;&#21253;&#21547;&#20004;&#20010;&#22522;&#20110;&#31181;&#32676;&#23398;&#20064;&#30340;&#23398;&#20064;&#38454;&#27573;&#12290;&#31532;&#19968;&#20010;&#38454;&#27573;&#65292;RMC&#65292;&#33021;&#22815;&#25628;&#32034;&#20004;&#20010;&#39044;&#20808;&#35757;&#32451;&#27169;&#22411;&#20043;&#38388;&#30340;&#27169;&#22411;&#21442;&#25968;&#31354;&#38388;&#65292;&#24182;&#25214;&#21040;&#21253;&#21547;&#39640;&#40065;&#26834;&#24615;&#28857;&#30340;&#36335;&#24452;&#20197;&#25269;&#24481;&#22810;&#26679;&#21270;&#30340;$\ell_p$&#25915;&#20987;&#12290;&#22522;&#20110;RMC&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#31532;&#20108;&#20010;&#38454;&#27573;&#65292;&#22522;&#20110;RMC&#30340;&#20248;&#21270;&#65292;&#20854;&#20013;RMC&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#22810;&#26679;&#21270;$\ell_p$&#40065;&#26834;&#24615;&#36827;&#19968;&#27493;&#22686;&#24378;&#30340;&#22522;&#26412;&#21333;&#20803;&#12290;&#20026;&#20102;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#25105;&#20204;&#23558;&#23398;&#20064;&#19982;&#20165;&#36873;&#25321;&#23376;&#38598;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30456;&#32467;&#21512;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#32452;&#36739;&#23567;&#30340;&#20195;&#34920;&#24615;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#21487;&#29992;&#20110;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#23545;&#22810;&#26679;&#21270;$\ell_p$&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial robustness is a key concept in measuring the ability of neural networks to defend against adversarial attacks during the inference phase. Recent studies have shown that despite the success of improving adversarial robustness against a single type of attack using robust training techniques, models are still vulnerable to diversified $\ell_p$ attacks. To achieve diversified $\ell_p$ robustness, we propose a novel robust mode connectivity (RMC)-oriented adversarial defense that contains two population-based learning phases. The first phase, RMC, is able to search the model parameter space between two pre-trained models and find a path containing points with high robustness against diversified $\ell_p$ attacks. In light of the effectiveness of RMC, we develop a second phase, RMC-based optimization, with RMC serving as the basic unit for further enhancement of neural network diversified $\ell_p$ robustness. To increase computational efficiency, we incorporate learning with a sel
&lt;/p&gt;</description></item></channel></rss>