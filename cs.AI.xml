<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LawInstruct&#30340;&#22823;&#22411;&#27861;&#24459;&#25351;&#23548;&#25968;&#25454;&#38598;&#65292;&#35777;&#26126;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451;&#21644;&#25351;&#23548;&#35843;&#25972;&#21487;&#20197;&#25913;&#21892;&#22312;LegalBench&#19978;&#30340;&#24615;&#33021;&#65292;&#20026;&#22312;&#27861;&#24459;&#39046;&#22495;&#24320;&#21457;&#20855;&#26377;&#26356;&#24378;&#20449;&#24687;&#22788;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#36164;&#28304;&#12290;</title><link>https://arxiv.org/abs/2404.02127</link><description>&lt;p&gt;
FLawN-T5: &#26377;&#25928;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#28151;&#21512;&#22312;&#27861;&#24459;&#25512;&#29702;&#20013;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LawInstruct&#30340;&#22823;&#22411;&#27861;&#24459;&#25351;&#23548;&#25968;&#25454;&#38598;&#65292;&#35777;&#26126;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451;&#21644;&#25351;&#23548;&#35843;&#25972;&#21487;&#20197;&#25913;&#21892;&#22312;LegalBench&#19978;&#30340;&#24615;&#33021;&#65292;&#20026;&#22312;&#27861;&#24459;&#39046;&#22495;&#24320;&#21457;&#20855;&#26377;&#26356;&#24378;&#20449;&#24687;&#22788;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02127v1  &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495;  &#25688;&#35201;: &#25351;&#23548;&#35843;&#25972;&#26159;&#20351;&#35821;&#35328;&#27169;&#22411;&#23545;&#30452;&#25509;&#29992;&#25143;&#20132;&#20114;&#26377;&#25928;&#30340;&#37325;&#35201;&#27493;&#39588;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#27861;&#24459;&#20219;&#21153;&#20173;&#28982;&#36229;&#20986;&#20102;&#22823;&#22810;&#25968;&#24320;&#25918;&#24335;LLMs&#30340;&#33539;&#22260;&#65292;&#32780;&#19988;&#30446;&#21069;&#35813;&#39046;&#22495;&#36824;&#27809;&#26377;&#20219;&#20309;&#22823;&#35268;&#27169;&#30340;&#25968;&#25454;&#38598;&#12290;&#36825;&#20005;&#37325;&#38480;&#21046;&#20102;&#35813;&#24212;&#29992;&#39046;&#22495;&#30340;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#31574;&#21010;&#20102;&#19968;&#20010;&#21517;&#20026;LawInstruct&#30340;&#22823;&#22411;&#27861;&#24459;&#25351;&#23548;&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20102;17&#20010;&#21496;&#27861;&#31649;&#36758;&#21306;&#12289;24&#31181;&#35821;&#35328;&#65292;&#24635;&#35745;1200&#19975;&#20010;&#31034;&#20363;&#12290;&#25105;&#20204;&#21576;&#29616;&#35777;&#25454;&#34920;&#26126;&#65292;&#39046;&#22495;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451;&#21644;&#25351;&#23548;&#35843;&#25972;&#33021;&#22815;&#25913;&#21892;&#22312;LegalBench&#19978;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#23558;Flan-T5 XL&#22312;&#22522;&#20934;&#32447;&#19978;&#25552;&#39640;8&#20010;&#28857;&#25110;16%&#12290;&#28982;&#32780;&#65292;&#35813;&#25928;&#24212;&#24182;&#19981;&#36866;&#29992;&#20110;&#25152;&#26377;&#20219;&#21153;&#12289;&#35757;&#32451;&#27169;&#24335;&#12289;&#27169;&#22411;&#22823;&#23567;&#21644;&#20854;&#20182;&#22240;&#32032;&#12290;LawInstruct&#26159;&#19968;&#20010;&#36164;&#28304;&#65292;&#21487;&#20197;&#21152;&#36895;&#22312;&#27861;&#24459;&#39046;&#22495;&#24320;&#21457;&#20855;&#26377;&#26356;&#24378;&#20449;&#24687;&#22788;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02127v1 Announce Type: cross  Abstract: Instruction tuning is an important step in making language models useful for direct user interaction. However, many legal tasks remain out of reach for most open LLMs and there do not yet exist any large scale instruction datasets for the domain. This critically limits research in this application area. In this work, we curate LawInstruct, a large legal instruction dataset, covering 17 jurisdictions, 24 languages and a total of 12M examples. We present evidence that domain-specific pretraining and instruction tuning improve performance on LegalBench, including improving Flan-T5 XL by 8 points or 16\% over the baseline. However, the effect does not generalize across all tasks, training regimes, model sizes, and other factors. LawInstruct is a resource for accelerating the development of models with stronger information processing and decision making capabilities in the legal domain.
&lt;/p&gt;</description></item><item><title>&#37325;&#26032;&#23457;&#35270;&#20102;&#22522;&#20110;&#34920;&#31034;&#30340;&#19981;&#21464;&#24615;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;Asymmetrically Representation-regularized Adversarial Training (AR-AT)&#26469;&#35299;&#20915;&#8220;&#26799;&#24230;&#20914;&#31361;&#8221;&#21644;&#28151;&#21512;&#20998;&#24067;&#38382;&#39064;&#65292;&#25913;&#21892;&#40065;&#26834;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2402.14648</link><description>&lt;p&gt;
&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#37325;&#26032;&#24605;&#32771;&#19981;&#21464;&#24615;&#27491;&#21017;&#21270;&#20197;&#25913;&#21892;&#40065;&#26834;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14648
&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#20102;&#22522;&#20110;&#34920;&#31034;&#30340;&#19981;&#21464;&#24615;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;Asymmetrically Representation-regularized Adversarial Training (AR-AT)&#26469;&#35299;&#20915;&#8220;&#26799;&#24230;&#20914;&#31361;&#8221;&#21644;&#28151;&#21512;&#20998;&#24067;&#38382;&#39064;&#65292;&#25913;&#21892;&#40065;&#26834;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#23545;&#25239;&#35757;&#32451;&#19968;&#30452;&#26159;&#25269;&#25239;&#23545;&#25239;&#24615;&#26679;&#26412;&#65288;AEs&#65289;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#23384;&#22312;&#40065;&#26834;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#22522;&#20110;&#34920;&#31034;&#30340;&#19981;&#21464;&#24615;&#27491;&#21017;&#21270;&#65292;&#23398;&#20064;&#20855;&#26377;&#36776;&#21035;&#24615;&#21364;&#23545;&#25239;&#24615;&#19981;&#21464;&#30340;&#34920;&#31034;&#65292;&#26088;&#22312;&#32531;&#35299;&#36825;&#31181;&#26435;&#34913;&#12290;&#25105;&#20204;&#22312;&#32463;&#39564;&#19978;&#30830;&#23450;&#20102;&#22952;&#30861;&#19981;&#21464;&#24615;&#27491;&#21017;&#21270;&#30340;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;&#65288;1&#65289;&#19981;&#21464;&#24615;&#25439;&#22833;&#21644;&#20998;&#31867;&#30446;&#26631;&#20043;&#38388;&#30340;&#8220;&#26799;&#24230;&#20914;&#31361;&#8221;&#65292;&#34920;&#26126;&#23384;&#22312;&#8220;&#23849;&#28291;&#35299;&#8221;&#65292;&#20197;&#21450;&#65288;2&#65289;&#30001;&#20110;&#24178;&#20928;&#21644;&#23545;&#25239;&#24615;&#36755;&#20837;&#30340;&#20998;&#24067;&#21457;&#25955;&#32780;&#20986;&#29616;&#30340;&#28151;&#21512;&#20998;&#24067;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#23545;&#31216;&#34920;&#31034;&#27491;&#21017;&#21270;&#30340;&#23545;&#25239;&#35757;&#32451;&#65288;AR-AT&#65289;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#19968;&#20010;&#20572;&#27490;&#26799;&#24230;&#25805;&#20316;&#21644;&#19968;&#20010;&#39044;&#27979;&#22120;&#26469;&#36991;&#20813;&#8220;&#23849;&#28291;&#35299;&#8221;&#65292;&#28789;&#24863;&#26469;&#33258;&#26368;&#36817;&#30340;&#38750;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14648v1 Announce Type: cross  Abstract: Although adversarial training has been the state-of-the-art approach to defend against adversarial examples (AEs), they suffer from a robustness-accuracy trade-off. In this work, we revisit representation-based invariance regularization to learn discriminative yet adversarially invariant representations, aiming to mitigate this trade-off. We empirically identify two key issues hindering invariance regularization: (1) a "gradient conflict" between invariance loss and classification objectives, indicating the existence of "collapsing solutions," and (2) the mixture distribution problem arising from diverged distributions of clean and adversarial inputs. To address these issues, we propose Asymmetrically Representation-regularized Adversarial Training (AR-AT), which incorporates a stop-gradient operation and a pre-dictor in the invariance loss to avoid "collapsing solutions," inspired by a recent non-contrastive self-supervised learning a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;KG&#30693;&#35782;&#27880;&#20837;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#27604;&#36739;&#65292;&#25506;&#32034;&#20026;LLMs&#25552;&#20379;&#30693;&#35782;&#22270;&#35889;&#30693;&#35782;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#23427;&#20204;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.11541</link><description>&lt;p&gt;
&#36870;&#21521;&#35748;&#30693;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27604;&#25105;&#20204;&#24819;&#35937;&#30340;&#26356;&#25797;&#38271;&#29702;&#35299;&#30693;&#35782;&#22270;&#35889;
&lt;/p&gt;
&lt;p&gt;
Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;KG&#30693;&#35782;&#27880;&#20837;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#27604;&#36739;&#65292;&#25506;&#32034;&#20026;LLMs&#25552;&#20379;&#30693;&#35782;&#22270;&#35889;&#30693;&#35782;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#23427;&#20204;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#36890;&#36807;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#65288;KGs&#65289;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#24182;&#20943;&#23569;&#23427;&#20204;&#30340;&#24187;&#35273;&#30340;&#26041;&#27861;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#30446;&#21069;&#23545;&#22914;&#20309;&#20351;LLMs&#33021;&#22815;&#21363;&#26102;&#25972;&#21512;KGs&#20013;&#30340;&#32467;&#26500;&#21270;&#30693;&#35782;&#30340;&#25506;&#32034;&#36824;&#19981;&#36275;&#12290;&#26412;&#25991;&#37319;&#29992;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#65288;CQA&#65289;&#20316;&#20026;&#19968;&#39033;&#20219;&#21153;&#65292;&#35780;&#20272;LLM&#29702;&#35299;KG&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#23545;KG&#30693;&#35782;&#27880;&#20837;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#65288;&#20174;&#19977;&#20803;&#32452;&#21040;&#33258;&#28982;&#35821;&#35328;&#25991;&#26412;&#65289;&#65292;&#26088;&#22312;&#25506;&#32034;&#20026;LLMs&#25552;&#20379;KG&#30693;&#35782;&#30340;&#26368;&#20339;&#25552;&#31034;&#26041;&#27861;&#65292;&#20174;&#32780;&#22686;&#24378;&#23427;&#20204;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11541v1 Announce Type: cross  Abstract: Although the method of enhancing large language models' (LLMs') reasoning ability and reducing their hallucinations through the use of knowledge graphs (KGs) has received widespread attention, the exploration of how to enable LLMs to integrate the structured knowledge in KGs on-the-fly remains inadequate. Researchers often co-train KG embeddings and LLM parameters to equip LLMs with the ability of comprehending KG knowledge. However, this resource-hungry training paradigm significantly increases the model learning cost and is also unsuitable for non-open-source, black-box LLMs. In this paper, we employ complex question answering (CQA) as a task to assess the LLM's ability of comprehending KG knowledge. We conducted a comprehensive comparison of KG knowledge injection methods (from triples to natural language text), aiming to explore the optimal prompting method for supplying KG knowledge to LLMs, thereby enhancing their comprehension o
&lt;/p&gt;</description></item><item><title>ProtChatGPT&#26159;&#19968;&#20010;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23398;&#20064;&#21644;&#29702;&#35299;&#34507;&#30333;&#36136;&#32467;&#26500;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#19978;&#20256;&#34507;&#30333;&#36136;&#12289;&#25552;&#38382;&#21644;&#20132;&#20114;&#24335;&#23545;&#35805;&#31561;&#21151;&#33021;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#29702;&#35299;&#34507;&#30333;&#36136;&#30340;&#32467;&#26500;&#19982;&#21151;&#33021;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.09649</link><description>&lt;p&gt;
ProtChatGPT&#65306;&#29992;&#20110;&#29702;&#35299;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#34507;&#30333;&#36136;
&lt;/p&gt;
&lt;p&gt;
ProtChatGPT: Towards Understanding Proteins with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09649
&lt;/p&gt;
&lt;p&gt;
ProtChatGPT&#26159;&#19968;&#20010;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23398;&#20064;&#21644;&#29702;&#35299;&#34507;&#30333;&#36136;&#32467;&#26500;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#19978;&#20256;&#34507;&#30333;&#36136;&#12289;&#25552;&#38382;&#21644;&#20132;&#20114;&#24335;&#23545;&#35805;&#31561;&#21151;&#33021;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#29702;&#35299;&#34507;&#30333;&#36136;&#30340;&#32467;&#26500;&#19982;&#21151;&#33021;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34507;&#30333;&#36136;&#30740;&#31350;&#22312;&#21508;&#20010;&#22522;&#30784;&#23398;&#31185;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#29702;&#35299;&#20854;&#22797;&#26434;&#30340;&#32467;&#26500;&#19982;&#21151;&#33021;&#20851;&#31995;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26368;&#36817;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29702;&#35299;&#29305;&#23450;&#20219;&#21153;&#30340;&#30693;&#35782;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#36825;&#34920;&#26126;&#20102;&#29992;&#20110;&#34507;&#30333;&#36136;&#30340;ChatGPT-like&#31995;&#32479;&#22312;&#20419;&#36827;&#22522;&#30784;&#30740;&#31350;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ProtChatGPT&#65292;&#26088;&#22312;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23398;&#20064;&#21644;&#29702;&#35299;&#34507;&#30333;&#36136;&#32467;&#26500;&#12290;ProtChatGPT&#20351;&#29992;&#25143;&#21487;&#20197;&#19978;&#20256;&#34507;&#30333;&#36136;&#12289;&#25552;&#38382;&#24182;&#36827;&#34892;&#20132;&#20114;&#24335;&#23545;&#35805;&#20197;&#20135;&#29983;&#20840;&#38754;&#30340;&#22238;&#31572;&#12290;&#35813;&#31995;&#32479;&#21253;&#25324;&#34507;&#30333;&#32534;&#30721;&#22120;&#12289;&#34507;&#30333;&#35821;&#35328;&#30456;&#20851;&#36716;&#25442;&#22120;&#65288;PLP-former&#65289;&#12289;&#25237;&#24433;&#36866;&#37197;&#22120;&#21644;LLM&#12290;&#34507;&#30333;&#36136;&#39318;&#20808;&#36890;&#36807;&#34507;&#30333;&#32534;&#30721;&#22120;&#21644;PLP-former&#36827;&#34892;&#32534;&#30721;&#20197;&#20135;&#29983;&#34507;&#30333;&#36136;&#23884;&#20837;&#65292;&#28982;&#21518;&#36890;&#36807;&#36866;&#37197;&#22120;&#23558;&#20854;&#25237;&#23556;&#21040;&#19982;LLM&#30456;&#31526;&#21512;&#12290;&#26368;&#21518;&#65292;LLM&#23558;&#29992;&#25143;&#30340;&#38382;&#39064;&#19982;&#34507;&#30333;&#36136;&#23884;&#20837;&#36827;&#34892;&#32508;&#21512;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09649v1 Announce Type: cross  Abstract: Protein research is crucial in various fundamental disciplines, but understanding their intricate structure-function relationships remains challenging. Recent Large Language Models (LLMs) have made significant strides in comprehending task-specific knowledge, suggesting the potential for ChatGPT-like systems specialized in protein to facilitate basic research. In this work, we introduce ProtChatGPT, which aims at learning and understanding protein structures via natural languages. ProtChatGPT enables users to upload proteins, ask questions, and engage in interactive conversations to produce comprehensive answers. The system comprises protein encoders, a Protein-Language Pertaining Transformer (PLP-former), a projection adapter, and an LLM. The protein first undergoes protein encoders and PLP-former to produce protein embeddings, which are then projected by the adapter to conform with the LLM. The LLM finally combines user questions wit
&lt;/p&gt;</description></item><item><title>&#22312;&#36830;&#32493;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#23547;&#27714;&#24110;&#21161;&#26469;&#36991;&#20813;&#28798;&#38590;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#28798;&#38590;&#21457;&#29983;&#30340;&#27010;&#29575;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#36830;&#32493;1D&#29366;&#24577;&#31354;&#38388;&#21644;&#30456;&#23545;&#31616;&#21333;&#30340;&#22238;&#25253;&#20989;&#25968;&#19979;&#65292;&#36951;&#25022;&#21644;&#21521;&#23548;&#24072;&#26597;&#35810;&#29575;&#37117;&#36235;&#36817;&#20110;0&#12290;</title><link>https://arxiv.org/abs/2402.08062</link><description>&lt;p&gt;
&#36991;&#20813;&#36830;&#32493;&#31354;&#38388;&#20013;&#30340;&#28798;&#38590;&#65306;&#36890;&#36807;&#23547;&#27714;&#24110;&#21161;
&lt;/p&gt;
&lt;p&gt;
Avoiding Catastrophe in Continuous Spaces by Asking for Help
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08062
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#23547;&#27714;&#24110;&#21161;&#26469;&#36991;&#20813;&#28798;&#38590;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#28798;&#38590;&#21457;&#29983;&#30340;&#27010;&#29575;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#36830;&#32493;1D&#29366;&#24577;&#31354;&#38388;&#21644;&#30456;&#23545;&#31616;&#21333;&#30340;&#22238;&#25253;&#20989;&#25968;&#19979;&#65292;&#36951;&#25022;&#21644;&#21521;&#23548;&#24072;&#26597;&#35810;&#29575;&#37117;&#36235;&#36817;&#20110;0&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#20855;&#26377;&#27491;&#24335;&#36951;&#25022;&#20445;&#35777;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20551;&#35774;&#25152;&#26377;&#38169;&#35823;&#37117;&#26159;&#21487;&#36870;&#30340;&#65292;&#24182;&#20381;&#36182;&#20110;&#23581;&#35797;&#25152;&#26377;&#21487;&#33021;&#30340;&#36873;&#39033;&#12290;&#24403;&#19968;&#20123;&#38169;&#35823;&#26159;&#26080;&#27861;&#20462;&#22797;&#29978;&#33267;&#26159;&#28798;&#38590;&#24615;&#30340;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#20250;&#23548;&#33268;&#31967;&#31957;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#21457;&#29983;&#28798;&#38590;&#30340;&#27010;&#29575;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20551;&#35774;&#27599;&#36718;&#30340;&#22238;&#25253;&#20195;&#34920;&#20102;&#22312;&#35813;&#36718;&#36991;&#20813;&#28798;&#38590;&#30340;&#27010;&#29575;&#65292;&#24182;&#23581;&#35797;&#26368;&#22823;&#21270;&#22238;&#25253;&#30340;&#20056;&#31215;&#65288;&#24635;&#20307;&#36991;&#20813;&#28798;&#38590;&#30340;&#27010;&#29575;&#65289;&#12290;&#20026;&#20102;&#32473; agent &#19968;&#20123;&#25104;&#21151;&#30340;&#26426;&#20250;&#65292;&#25105;&#20204;&#20801;&#35768;&#26377;&#38480;&#27425;&#21521;&#23548;&#24072;&#25552;&#38382;&#65292;&#24182;&#20551;&#35774;&#22238;&#25253;&#20989;&#25968;&#20026; Lipschitz &#36830;&#32493;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#24403;&#26102;&#38388;&#36328;&#24230;&#22686;&#38271;&#26102;&#65292;&#23427;&#30340;&#36951;&#25022;&#21644;&#21521;&#23548;&#24072;&#26597;&#35810;&#29575;&#37117;&#36235;&#36817;&#20110; 0&#65292;&#20551;&#35774;&#26159;&#19968;&#20010;&#36830;&#32493;&#30340; 1D &#29366;&#24577;&#31354;&#38388;&#21644;&#30456;&#23545;"&#31616;&#21333;"&#30340;&#22238;&#25253;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#21305;&#37197;&#30340;&#19979;&#30028;&#65306;&#22312;&#27809;&#26377;&#31616;&#21333;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20219;&#20309;&#31639;&#27861;&#35201;&#20040;&#19981;&#26029;&#26597;&#35810;&#24322;&#24120;&#30340;&#34892;&#20026;&#65292;&#35201;&#20040;&#27599;&#27425;&#26597;&#35810;&#23436;&#20840;&#30456;&#21516;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most reinforcement learning algorithms with formal regret guarantees assume all mistakes are reversible and rely on essentially trying all possible options. This approach leads to poor outcomes when some mistakes are irreparable or even catastrophic. We propose a variant of the contextual bandit problem where the goal is to minimize the chance of catastrophe. Specifically, we assume that the payoff each round represents the chance of avoiding catastrophe that round, and try to maximize the product of payoffs (the overall chance of avoiding catastrophe). To give the agent some chance of success, we allow a limited number of queries to a mentor and assume a Lipschitz continuous payoff function. We present an algorithm whose regret and rate of querying the mentor both approach 0 as the time horizon grows, assuming a continuous 1D state space and a relatively "simple" payoff function. We also provide a matching lower bound: without the simplicity assumption: any algorithm either constantly
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#29289;&#20307;&#20013;&#24515;&#21270;&#23398;&#20064;&#20013;&#26126;&#30830;&#35299;&#24320;&#24418;&#29366;&#21644;&#32441;&#29702;&#25104;&#20998;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#28508;&#22312;&#31354;&#38388;&#21010;&#20998;&#20026;&#20004;&#20010;&#19981;&#37325;&#21472;&#30340;&#23376;&#38598;&#65292;&#20351;&#24471;&#27169;&#22411;&#26356;&#21152;&#31283;&#23450;&#21644;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2401.10148</link><description>&lt;p&gt;
&#22312;&#29289;&#20307;&#20013;&#24515;&#21270;&#23398;&#20064;&#20013;&#26126;&#30830;&#35299;&#24320;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Explicitly Disentangled Representations in Object-Centric Learning. (arXiv:2401.10148v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10148
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#29289;&#20307;&#20013;&#24515;&#21270;&#23398;&#20064;&#20013;&#26126;&#30830;&#35299;&#24320;&#24418;&#29366;&#21644;&#32441;&#29702;&#25104;&#20998;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#28508;&#22312;&#31354;&#38388;&#21010;&#20998;&#20026;&#20004;&#20010;&#19981;&#37325;&#21472;&#30340;&#23376;&#38598;&#65292;&#20351;&#24471;&#27169;&#22411;&#26356;&#21152;&#31283;&#23450;&#21644;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#21407;&#22987;&#35270;&#35273;&#25968;&#25454;&#20013;&#25552;&#21462;&#32467;&#26500;&#21270;&#34920;&#31034;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#37325;&#35201;&#19988;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#26368;&#36817;&#65292;&#26080;&#30417;&#30563;&#23398;&#20064;&#29289;&#20307;&#20013;&#24515;&#21270;&#34920;&#31034;&#30340;&#25216;&#26415;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#22686;&#24378;&#28508;&#22312;&#29305;&#24449;&#30340;&#31283;&#23450;&#24615;&#21487;&#20197;&#25552;&#39640;&#19979;&#28216;&#20219;&#21153;&#35757;&#32451;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#22312;&#36825;&#20010;&#26041;&#21521;&#19978;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#27493;&#39588;&#26159;&#35299;&#24320;&#23548;&#33268;&#25968;&#25454;&#21464;&#21270;&#30340;&#22240;&#32032;&#12290;&#20808;&#21069;&#65292;&#19981;&#21464;&#21345;&#27133;&#27880;&#24847;&#23454;&#29616;&#20102;&#20174;&#20854;&#20182;&#29305;&#24449;&#20013;&#35299;&#24320;&#20301;&#32622;&#12289;&#23610;&#24230;&#21644;&#26041;&#21521;&#12290;&#25193;&#23637;&#36825;&#19968;&#26041;&#27861;&#65292;&#25105;&#20204;&#30528;&#37325;&#20110;&#20998;&#31163;&#24418;&#29366;&#21644;&#32441;&#29702;&#32452;&#25104;&#37096;&#20998;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26550;&#26500;&#65292;&#23558;&#29289;&#20307;&#20013;&#24515;&#21270;&#27169;&#22411;&#20013;&#30340;&#24418;&#29366;&#21644;&#32441;&#29702;&#25104;&#20998;&#20559;&#32622;&#20026;&#28508;&#22312;&#31354;&#38388;&#32500;&#24230;&#30340;&#20004;&#20010;&#19981;&#37325;&#21472;&#23376;&#38598;&#12290;&#36825;&#20123;&#23376;&#38598;&#26159;&#20808;&#39564;&#24050;&#30693;&#30340;&#65292;&#22240;&#27492;&#22312;&#35757;&#32451;&#36807;&#31243;&#20043;&#21069;&#12290;&#22312;&#19968;&#31995;&#21015;&#29289;&#20307;&#20013;&#24515;&#21270;&#27979;&#35797;&#20013;&#36827;&#34892;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Extracting structured representations from raw visual data is an important and long-standing challenge in machine learning. Recently, techniques for unsupervised learning of object-centric representations have raised growing interest. In this context, enhancing the robustness of the latent features can improve the efficiency and effectiveness of the training of downstream tasks. A promising step in this direction is to disentangle the factors that cause variation in the data. Previously, Invariant Slot Attention disentangled position, scale, and orientation from the remaining features. Extending this approach, we focus on separating the shape and texture components. In particular, we propose a novel architecture that biases object-centric models toward disentangling shape and texture components into two non-overlapping subsets of the latent space dimensions. These subsets are known a priori, hence before the training process. Experiments on a range of object-centric benchmarks reveal t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#31639;&#27861;&#30340;&#19981;&#36879;&#26126;&#24615;&#65292;&#37325;&#28857;&#20851;&#27880;&#20154;&#24037;&#26234;&#33021;&#22312;&#22240;&#26524;&#36131;&#20219;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#23545;&#30446;&#21069;&#26368;&#22909;&#30340;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65288;Chat-GPT&#65289;&#30340;&#35780;&#20272;&#65292;&#21487;&#20197;&#20102;&#35299;&#20854;&#30446;&#21069;&#30340;&#24615;&#33021;&#20197;&#21450;&#21487;&#33021;&#30340;&#27861;&#24459;&#35268;&#21046;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2310.13192</link><description>&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#30340;&#19981;&#36879;&#26126;&#27861;&#24459;
&lt;/p&gt;
&lt;p&gt;
The opaque law of artificial intelligence. (arXiv:2310.13192v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13192
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#31639;&#27861;&#30340;&#19981;&#36879;&#26126;&#24615;&#65292;&#37325;&#28857;&#20851;&#27880;&#20154;&#24037;&#26234;&#33021;&#22312;&#22240;&#26524;&#36131;&#20219;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#23545;&#30446;&#21069;&#26368;&#22909;&#30340;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65288;Chat-GPT&#65289;&#30340;&#35780;&#20272;&#65292;&#21487;&#20197;&#20102;&#35299;&#20854;&#30446;&#21069;&#30340;&#24615;&#33021;&#20197;&#21450;&#21487;&#33021;&#30340;&#27861;&#24459;&#35268;&#21046;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#20998;&#26512;&#31639;&#27861;&#30340;&#19981;&#36879;&#26126;&#24615;&#65292;&#24182;&#23558;&#20854;&#32622;&#20110;&#20154;&#24037;&#26234;&#33021;&#22240;&#26524;&#36131;&#20219;&#30340;&#20844;&#24320;&#36777;&#35770;&#32972;&#26223;&#19979;&#36827;&#34892;&#35752;&#35770;&#65307;&#36890;&#36807;&#24212;&#29992;&#22270;&#28789;&#27979;&#35797;&#20013;&#25552;&#20986;&#30340;&#23545;&#35805;&#26041;&#27861;&#65292;&#25105;&#20204;&#24076;&#26395;&#35780;&#20272;&#29616;&#26377;&#26368;&#22909;&#30340;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65288;Chat-GPT&#65289;&#30340;&#24615;&#33021;&#65292;&#20197;&#30830;&#23450;&#20854;&#30446;&#21069;&#30340;&#33021;&#21147;&#21644;&#21487;&#33021;&#30340;&#27861;&#24459;&#35268;&#21046;&#24418;&#24335;&#12290;&#38382;&#39064;&#20998;&#26512;&#23558;&#22522;&#20110;&#23545;&#20256;&#32479;&#27861;&#24459;&#33539;&#30068;&#65288;&#22914;&#22240;&#26524;&#20851;&#31995;&#12289;&#24847;&#22270;&#21644;&#36807;&#22833;&#65289;&#30340;&#35780;&#35770;&#65292;&#20197;&#29702;&#35299;&#20154;&#24037;&#26234;&#33021;&#20351;&#29992;&#20013;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#20154;&#26426;&#20132;&#20114;&#12290;&#20174;&#35745;&#31639;&#26426;&#31185;&#23398;&#35282;&#24230;&#26469;&#30475;&#65292;&#25991;&#20013;&#36824;&#23558;&#25552;&#20986;&#19968;&#31181;&#38024;&#23545;Chat-GPT&#36827;&#34892;&#23454;&#38469;&#35810;&#38382;&#30340;&#26041;&#27861;&#65292;&#20197;&#25214;&#21040;&#20154;&#24037;&#26234;&#33021;&#36816;&#34892;&#36807;&#31243;&#20013;&#30340;&#19968;&#20123;&#20851;&#38190;&#38382;&#39064;&#12290;&#25991;&#31456;&#30340;&#32467;&#23614;&#23558;&#38598;&#20013;&#35752;&#35770;&#19968;&#20123;&#29616;&#26377;&#30340;&#31435;&#27861;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
The purpose of this paper is to analyse the opacity of algorithms, contextualized in the open debate on responsibility for artificial intelligence causation; with an experimental approach by which, applying the proposed conversational methodology of the Turing Test, we expect to evaluate the performance of one of the best existing NLP model of generative AI (Chat-GPT) to see how far it can go right now and how the shape of a legal regulation of it could be. The analysis of the problem will be supported by a comment of Italian classical law categories such as causality, intent and fault to understand the problem of the usage of AI, focusing in particular on the human-machine interaction. On the computer science side, for a technical point of view of the logic used to craft these algorithms, in the second chapter will be proposed a practical interrogation of Chat-GPT aimed at finding some critical points of the functioning of AI. The end of the paper will concentrate on some existing leg
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#39044;&#27979;&#32534;&#30721;&#30340;&#33041;&#21551;&#21457;&#24335;&#35745;&#31639;&#26234;&#33021;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#35299;&#20915;&#29616;&#26377;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#30340;&#19968;&#20123;&#37325;&#35201;&#38480;&#21046;&#65292;&#24182;&#20855;&#26377;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#26377;&#24076;&#26395;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.07870</link><description>&lt;p&gt;
&#36890;&#36807;&#39044;&#27979;&#32534;&#30721;&#23454;&#29616;&#33041;&#21551;&#21457;&#24335;&#35745;&#31639;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
Brain-Inspired Computational Intelligence via Predictive Coding. (arXiv:2308.07870v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07870
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#39044;&#27979;&#32534;&#30721;&#30340;&#33041;&#21551;&#21457;&#24335;&#35745;&#31639;&#26234;&#33021;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#35299;&#20915;&#29616;&#26377;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#30340;&#19968;&#20123;&#37325;&#35201;&#38480;&#21046;&#65292;&#24182;&#20855;&#26377;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#26377;&#24076;&#26395;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#27491;&#22312;&#36805;&#36895;&#25104;&#20026;&#26412;&#19990;&#32426;&#30340;&#20851;&#38190;&#25216;&#26415;&#20043;&#19968;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#22312;AI&#39046;&#22495;&#21462;&#24471;&#30340;&#22823;&#37096;&#20998;&#25104;&#26524;&#37117;&#26159;&#20351;&#29992;&#35823;&#24046;&#21453;&#21521;&#20256;&#25773;&#23398;&#20064;&#31639;&#27861;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25152;&#23454;&#29616;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#26222;&#21450;&#24212;&#29992;&#24050;&#32463;&#20984;&#26174;&#20986;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#35745;&#31639;&#25104;&#26412;&#39640;&#12289;&#38590;&#20197;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12289;&#32570;&#20047;&#40065;&#26834;&#24615;&#12289;&#19981;&#21487;&#38752;&#24615;&#21644;&#29983;&#29289;&#23398;&#19978;&#30340;&#19981;&#21512;&#29702;&#24615;&#12290;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#21487;&#33021;&#38656;&#35201;&#21463;&#21040;&#31070;&#32463;&#31185;&#23398;&#29702;&#35770;&#30340;&#21551;&#21457;&#21644;&#25351;&#23548;&#30340;&#26041;&#26696;&#12290;&#20854;&#20013;&#19968;&#31181;&#29702;&#35770;&#31216;&#20026;&#39044;&#27979;&#32534;&#30721;&#65288;PC&#65289;&#65292;&#22312;&#26426;&#22120;&#26234;&#33021;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#65292;&#20855;&#26377;&#20196;&#20154;&#20852;&#22859;&#30340;&#29305;&#24615;&#65292;&#20351;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#20215;&#20540;&#65306;PC&#21487;&#20197;&#27169;&#25311;&#19981;&#21516;&#33041;&#21306;&#30340;&#20449;&#24687;&#22788;&#29702;&#65292;&#21487;&#20197;&#29992;&#20110;&#35748;&#30693;&#25511;&#21046;&#21644;&#26426;&#22120;&#20154;&#25216;&#26415;&#65292;&#24182;&#22312;&#21464;&#20998;&#25512;&#29702;&#26041;&#38754;&#20855;&#26377;&#22362;&#23454;&#30340;&#25968;&#23398;&#22522;&#30784;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence (AI) is rapidly becoming one of the key technologies of this century. The majority of results in AI thus far have been achieved using deep neural networks trained with the error backpropagation learning algorithm. However, the ubiquitous adoption of this approach has highlighted some important limitations such as substantial computational cost, difficulty in quantifying uncertainty, lack of robustness, unreliability, and biological implausibility. It is possible that addressing these limitations may require schemes that are inspired and guided by neuroscience theories. One such theory, called predictive coding (PC), has shown promising performance in machine intelligence tasks, exhibiting exciting properties that make it potentially valuable for the machine learning community: PC can model information processing in different brain areas, can be used in cognitive control and robotics, and has a solid mathematical grounding in variational inference, offering a pow
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;Transformer&#26550;&#26500;&#65292;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#26102;&#38388;&#30456;&#20851;&#30340;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#32452;&#39057;&#29575;&#20989;&#25968;&#26469;&#34920;&#31034;&#25968;&#20540;&#29305;&#24449;&#65292;&#24182;&#37319;&#29992;&#21807;&#19968;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#32479;&#19968;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2302.06375</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#25152;&#26377;&#26102;&#38388;&#24207;&#21015;&#30340;Transformer&#65306;&#34920;&#31034;&#21644;&#35757;&#32451;&#20855;&#26377;&#26102;&#38388;&#30456;&#20851;&#30340;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
One Transformer for All Time Series: Representing and Training with Time-Dependent Heterogeneous Tabular Data. (arXiv:2302.06375v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06375
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;Transformer&#26550;&#26500;&#65292;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#26102;&#38388;&#30456;&#20851;&#30340;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#32452;&#39057;&#29575;&#20989;&#25968;&#26469;&#34920;&#31034;&#25968;&#20540;&#29305;&#24449;&#65292;&#24182;&#37319;&#29992;&#21807;&#19968;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#32479;&#19968;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23558;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#24212;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#38271;&#65292;&#20197;&#22797;&#21046;&#20854;&#20182;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#22312;&#36825;&#19968;&#32467;&#26500;&#21270;&#39046;&#22495;&#30340;&#25104;&#21151;&#12290;&#29305;&#21035;&#26377;&#36259;&#30340;&#26159;&#65292;&#34920;&#26684;&#25968;&#25454;&#20855;&#26377;&#26102;&#38388;&#20381;&#36182;&#24615;&#65292;&#20363;&#22914;&#37329;&#34701;&#20132;&#26131;&#12290;&#28982;&#32780;&#65292;&#34920;&#26684;&#20540;&#30340;&#24322;&#36136;&#24615;&#65292;&#20854;&#20013;&#31867;&#21035;&#20803;&#32032;&#19982;&#25968;&#20540;&#39033;&#28151;&#21512;&#65292;&#20351;&#24471;&#36825;&#31181;&#36866;&#24212;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;Transformer&#26550;&#26500;&#26469;&#34920;&#31034;&#24322;&#26500;&#30340;&#26102;&#38388;&#30456;&#20851;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#25968;&#20540;&#29305;&#24449;&#20351;&#29992;&#19968;&#32452;&#39057;&#29575;&#20989;&#25968;&#34920;&#31034;&#65292;&#24182;&#19988;&#25972;&#20010;&#32593;&#32476;&#20351;&#29992;&#21807;&#19968;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#32479;&#19968;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a recent growing interest in applying Deep Learning techniques to tabular data, in order to replicate the success of other Artificial Intelligence areas in this structured domain. Specifically interesting is the case in which tabular data have a time dependence, such as, for instance financial transactions. However, the heterogeneity of the tabular values, in which categorical elements are mixed with numerical items, makes this adaptation difficult. In this paper we propose a Transformer architecture to represent heterogeneous time-dependent tabular data, in which numerical features are represented using a set of frequency functions and the whole network is uniformly trained with a unique loss function.
&lt;/p&gt;</description></item></channel></rss>