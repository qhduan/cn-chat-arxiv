<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36825;&#31181;&#29420;&#29305;&#30340;Transformer&#27169;&#22411;&#22312;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#65292;&#20026;&#21487;&#38752;&#21644;&#21487;&#25345;&#32493;&#30340;&#30005;&#21147;&#31995;&#32479;&#36816;&#34892;&#25552;&#20379;&#20102;&#26377;&#21069;&#26223;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2403.16108</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#30340;Transformer&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Transformer approach for Electricity Price Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16108
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#29420;&#29305;&#30340;Transformer&#27169;&#22411;&#22312;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#65292;&#20026;&#21487;&#38752;&#21644;&#21487;&#25345;&#32493;&#30340;&#30005;&#21147;&#31995;&#32479;&#36816;&#34892;&#25552;&#20379;&#20102;&#26377;&#21069;&#26223;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32431;Transformer&#27169;&#22411;&#36827;&#34892;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#65288;EPF&#65289;&#30340;&#26032;&#26041;&#27861;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;&#27809;&#26377;&#20351;&#29992;&#20854;&#20182;&#36882;&#24402;&#32593;&#32476;&#32467;&#21512;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;&#22240;&#27492;&#65292;&#34920;&#26126;&#27880;&#24847;&#21147;&#23618;&#36275;&#20197;&#25429;&#25417;&#26102;&#38388;&#27169;&#24335;&#12290;&#35813;&#35770;&#25991;&#36824;&#36890;&#36807;&#20351;&#29992;&#24320;&#28304;EPF&#24037;&#20855;&#36827;&#34892;&#20102;&#23545;&#27169;&#22411;&#30340;&#20844;&#24179;&#27604;&#36739;&#65292;&#24182;&#25552;&#20379;&#20102;&#20195;&#30721;&#20197;&#22686;&#24378;EPF&#30740;&#31350;&#30340;&#21487;&#20877;&#29616;&#24615;&#21644;&#36879;&#26126;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;Transformer&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#20026;&#21487;&#38752;&#21644;&#21487;&#25345;&#32493;&#30340;&#30005;&#21147;&#31995;&#32479;&#36816;&#34892;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16108v1 Announce Type: cross  Abstract: This paper presents a novel approach to electricity price forecasting (EPF) using a pure Transformer model. As opposed to other alternatives, no other recurrent network is used in combination to the attention mechanism. Hence, showing that the attention layer is enough for capturing the temporal patterns. The paper also provides fair comparison of the models using the open-source EPF toolbox and provide the code to enhance reproducibility and transparency in EPF research. The results show that the Transformer model outperforms traditional methods, offering a promising solution for reliable and sustainable power system operation.
&lt;/p&gt;</description></item><item><title>FedComLoc&#21033;&#29992;Scaffnew&#31639;&#27861;&#30340;&#22522;&#30784;&#65292;&#24341;&#20837;&#20102;&#21387;&#32553;&#21644;&#26412;&#22320;&#35757;&#32451;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;</title><link>https://arxiv.org/abs/2403.09904</link><description>&lt;p&gt;
FedComLoc: &#31232;&#30095;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#36890;&#20449;&#39640;&#25928;&#20998;&#24067;&#24335;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
FedComLoc: Communication-Efficient Distributed Training of Sparse and Quantized Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09904
&lt;/p&gt;
&lt;p&gt;
FedComLoc&#21033;&#29992;Scaffnew&#31639;&#27861;&#30340;&#22522;&#30784;&#65292;&#24341;&#20837;&#20102;&#21387;&#32553;&#21644;&#26412;&#22320;&#35757;&#32451;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30001;&#20110;&#20854;&#20801;&#35768;&#24322;&#26500;&#23458;&#25143;&#31471;&#22312;&#26412;&#22320;&#22788;&#29702;&#20854;&#31169;&#26377;&#25968;&#25454;&#24182;&#19982;&#20013;&#22830;&#26381;&#21153;&#22120;&#20114;&#21160;&#65292;&#21516;&#26102;&#23562;&#37325;&#38544;&#31169;&#30340;&#29420;&#29305;&#29305;&#28857;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21463;&#21040;&#20102;&#21019;&#26032;&#30340;Scaffnew&#31639;&#27861;&#30340;&#21551;&#21457;&#65292;&#35813;&#31639;&#27861;&#22312;FL&#20013;&#22823;&#22823;&#25512;&#21160;&#20102;&#36890;&#20449;&#22797;&#26434;&#24615;&#30340;&#38477;&#20302;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;FedComLoc&#65288;&#32852;&#37030;&#21387;&#32553;&#21644;&#26412;&#22320;&#35757;&#32451;&#65289;&#65292;&#23558;&#23454;&#29992;&#19988;&#26377;&#25928;&#30340;&#21387;&#32553;&#38598;&#25104;&#21040;Scaffnew&#20013;&#65292;&#20197;&#36827;&#19968;&#27493;&#22686;&#24378;&#36890;&#20449;&#25928;&#29575;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#20351;&#29992;&#27969;&#34892;&#30340;TopK&#21387;&#32553;&#22120;&#21644;&#37327;&#21270;&#65292;&#23427;&#22312;&#22823;&#24133;&#20943;&#23569;&#24322;&#26500;&#20013;&#30340;&#36890;&#20449;&#24320;&#38144;&#26041;&#38754;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09904v1 Announce Type: cross  Abstract: Federated Learning (FL) has garnered increasing attention due to its unique characteristic of allowing heterogeneous clients to process their private data locally and interact with a central server, while being respectful of privacy. A critical bottleneck in FL is the communication cost. A pivotal strategy to mitigate this burden is \emph{Local Training}, which involves running multiple local stochastic gradient descent iterations between communication phases. Our work is inspired by the innovative \emph{Scaffnew} algorithm, which has considerably advanced the reduction of communication complexity in FL. We introduce FedComLoc (Federated Compressed and Local Training), integrating practical and effective compression into \emph{Scaffnew} to further enhance communication efficiency. Extensive experiments, using the popular TopK compressor and quantization, demonstrate its prowess in substantially reducing communication overheads in heter
&lt;/p&gt;</description></item><item><title>PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.04355</link><description>&lt;p&gt;
PQMass: &#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#30340;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#27010;&#29575;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04355
&lt;/p&gt;
&lt;p&gt;
PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#22522;&#20110;&#26679;&#26412;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#20272;&#35745;&#20004;&#20010;&#26679;&#26412;&#38598;&#21512;&#26469;&#33258;&#21516;&#19968;&#20998;&#24067;&#30340;&#27010;&#29575;&#65292;&#20026;&#35780;&#20272;&#21333;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#25110;&#27604;&#36739;&#22312;&#21516;&#19968;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#22810;&#20010;&#31454;&#20105;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#35745;&#19978;&#20005;&#26684;&#30340;&#26041;&#27861;&#12290;&#35813;&#27604;&#36739;&#21487;&#20197;&#36890;&#36807;&#23558;&#31354;&#38388;&#21010;&#20998;&#20026;&#38750;&#37325;&#21472;&#30340;&#21306;&#22495;&#24182;&#27604;&#36739;&#27599;&#20010;&#21306;&#22495;&#20013;&#30340;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#26469;&#36827;&#34892;&#12290;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#29983;&#25104;&#27169;&#22411;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#26679;&#26412;&#12290;&#23427;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#26080;&#38656;&#38477;&#32500;&#12290;&#26174;&#33879;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#20851;&#20110;&#30495;&#23454;&#20998;&#24067;&#23494;&#24230;&#30340;&#20551;&#35774;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#35757;&#32451;&#25110;&#25311;&#21512;&#20219;&#20309;&#36741;&#21161;&#27169;&#22411;&#12290;&#30456;&#21453;&#65292;&#23427;&#30528;&#37325;&#20110;&#36817;&#20284;&#35745;&#31639;&#23494;&#24230;&#30340;&#31215;&#20998;&#65288;&#27010;&#29575;&#36136;&#37327;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a comprehensive sample-based method for assessing the quality of generative models. The proposed approach enables the estimation of the probability that two sets of samples are drawn from the same distribution, providing a statistically rigorous method for assessing the performance of a single generative model or the comparison of multiple competing models trained on the same dataset. This comparison can be conducted by dividing the space into non-overlapping regions and comparing the number of data samples in each region. The method only requires samples from the generative model and the test data. It is capable of functioning directly on high-dimensional data, obviating the need for dimensionality reduction. Significantly, the proposed method does not depend on assumptions regarding the density of the true distribution, and it does not rely on training or fitting any auxiliary models. Instead, it focuses on approximating the integral of the density (probability mass) acros
&lt;/p&gt;</description></item></channel></rss>