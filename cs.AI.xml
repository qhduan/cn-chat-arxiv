<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#19987;&#38376;&#27169;&#22411;&#36890;&#24120;&#21482;&#38656;&#23569;&#37327;&#26631;&#35760;&#26679;&#26412;&#65288;100-1000&#20010;&#65289;&#23601;&#33021;&#19982;&#36890;&#29992;&#27169;&#22411;&#25345;&#24179;&#29978;&#33267;&#26356;&#22909;&#65292;&#21462;&#20915;&#20110;&#20219;&#21153;&#30340;&#22797;&#26434;&#24615;&#21644;&#32467;&#26524;&#30340;&#21464;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.12819</link><description>&lt;p&gt;
&#24494;&#35843;&#12289;&#25552;&#31034;&#12289;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#25351;&#23548;&#24494;&#35843;&#65306;&#25105;&#20204;&#38656;&#35201;&#22810;&#23569;&#26631;&#35760;&#26679;&#26412;&#65311;
&lt;/p&gt;
&lt;p&gt;
Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12819
&lt;/p&gt;
&lt;p&gt;
&#19987;&#38376;&#27169;&#22411;&#36890;&#24120;&#21482;&#38656;&#23569;&#37327;&#26631;&#35760;&#26679;&#26412;&#65288;100-1000&#20010;&#65289;&#23601;&#33021;&#19982;&#36890;&#29992;&#27169;&#22411;&#25345;&#24179;&#29978;&#33267;&#26356;&#22909;&#65292;&#21462;&#20915;&#20110;&#20219;&#21153;&#30340;&#22797;&#26434;&#24615;&#21644;&#32467;&#26524;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#35299;&#20915;&#20855;&#26377;&#26377;&#38480;&#26631;&#35760;&#25968;&#25454;&#30340;&#20219;&#21153;&#26102;&#65292;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#36873;&#25321;&#20351;&#29992;&#36890;&#29992;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32780;&#19981;&#36827;&#34892;&#36827;&#19968;&#27493;&#26356;&#26032;&#65292;&#25110;&#32773;&#20351;&#29992;&#23569;&#37327;&#31034;&#20363;&#26469;&#35843;&#25972;&#19987;&#38376;&#30340;&#36739;&#23567;&#27169;&#22411;&#12290; &#24403;&#26377;&#36275;&#22815;&#30340;&#26631;&#35760;&#21487;&#29992;&#26102;&#65292;&#19987;&#38376;&#30340;&#27169;&#22411;&#22312;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#20110;&#36890;&#29992;&#27169;&#22411;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#35843;&#26597;&#19987;&#38376;&#27169;&#22411;&#38656;&#35201;&#22810;&#23569;&#26631;&#35760;&#26679;&#26412;&#25165;&#33021;&#23454;&#29616;&#36825;&#31181;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#32771;&#34385;&#32467;&#26524;&#30340;&#21464;&#21270;&#12290;&#35266;&#23519;&#25552;&#31034;&#12289;&#19978;&#19979;&#25991;&#23398;&#20064;&#12289;&#24494;&#35843;&#21644;&#25351;&#23548;&#24494;&#35843;&#30340;&#34892;&#20026;&#65292;&#35782;&#21035;&#23427;&#20204;&#22312;&#22686;&#21152;&#19981;&#21516;&#22797;&#26434;&#24615;&#20219;&#21153;&#30340;&#26631;&#35760;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#26102;&#30340;&#25910;&#25903;&#24179;&#34913;&#28857;&#65292;&#25105;&#20204;&#21457;&#29616;&#19987;&#38376;&#27169;&#22411;&#36890;&#24120;&#21482;&#38656;&#23569;&#37327;&#26679;&#26412;&#65288;100-1000&#20010;&#65289;&#23601;&#33021;&#19982;&#36890;&#29992;&#27169;&#22411;&#25345;&#24179;&#29978;&#33267;&#26356;&#22909;&#12290; &#21516;&#26102;&#65292;&#25152;&#38656;&#30340;&#26631;&#35760;&#25968;&#25454;&#37327;&#24378;&#28872;&#20381;&#36182;&#20110;&#20219;&#21153;&#30340;&#22797;&#26434;&#24615;&#21644;&#32467;&#26524;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12819v1 Announce Type: cross  Abstract: When solving a task with limited labelled data, researchers can either use a general large language model without further update, or use the few examples to tune a specialised smaller model. When enough labels are available, the specialised models outperform the general ones on many NLP tasks. In this work, we aim to investigate how many labelled samples are required for the specialised models to achieve this superior performance, while taking the results variance into consideration. Observing the behaviour of prompting, in-context learning, fine-tuning and instruction-tuning, identifying their break-even points when increasing number of labelled training samples across three tasks of varying complexity, we find that the specialised models often need only few samples ($100-1000$) to be on par or better than the general ones. At the same time, the amount of required labelled data strongly depends on the task complexity and results varia
&lt;/p&gt;</description></item><item><title>&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#26041;&#27861;ECUP&#26088;&#22312;&#35299;&#20915;&#38142;&#36335;&#20559;&#24046;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#65292;&#22312;&#32447;&#33829;&#38144;&#20013;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2402.03379</link><description>&lt;p&gt;
&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#19982;&#19978;&#19979;&#25991;&#22686;&#24378;&#23398;&#20064;&#29992;&#20110;&#26234;&#33021;&#33829;&#38144;
&lt;/p&gt;
&lt;p&gt;
Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03379
&lt;/p&gt;
&lt;p&gt;
&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#26041;&#27861;ECUP&#26088;&#22312;&#35299;&#20915;&#38142;&#36335;&#20559;&#24046;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#65292;&#22312;&#32447;&#33829;&#38144;&#20013;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#21319;&#24314;&#27169;&#22312;&#22312;&#32447;&#33829;&#38144;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#23427;&#26088;&#22312;&#36890;&#36807;&#39044;&#27979;&#20010;&#20307;&#22788;&#29702;&#25928;&#26524;&#65288;ITE&#65289;&#26469;&#20934;&#30830;&#34913;&#37327;&#19981;&#21516;&#31574;&#30053;&#65288;&#22914;&#20248;&#24800;&#21048;&#25110;&#25240;&#25187;&#65289;&#23545;&#19981;&#21516;&#29992;&#25143;&#30340;&#24433;&#21709;&#12290;&#22312;&#30005;&#23376;&#21830;&#21153;&#29615;&#22659;&#20013;&#65292;&#29992;&#25143;&#34892;&#20026;&#36981;&#24490;&#30830;&#23450;&#30340;&#39034;&#24207;&#38142;&#36335;&#65292;&#21253;&#25324;&#23637;&#31034;&#12289;&#28857;&#20987;&#21644;&#36716;&#21270;&#12290;&#33829;&#38144;&#31574;&#30053;&#22312;&#36825;&#20010;&#38142;&#36335;&#20013;&#30340;&#27599;&#20010;&#38454;&#27573;&#37117;&#20250;&#20135;&#29983;&#19981;&#21516;&#30340;&#19978;&#21319;&#25928;&#24212;&#65292;&#24433;&#21709;&#30528;&#28857;&#20987;&#29575;&#21644;&#36716;&#21270;&#29575;&#31561;&#25351;&#26631;&#12290;&#23613;&#31649;&#20854;&#23454;&#29992;&#24615;&#65292;&#29616;&#26377;&#30740;&#31350;&#24573;&#35270;&#20102;&#29305;&#23450;&#22788;&#29702;&#20013;&#25152;&#26377;&#38454;&#27573;&#30340;&#30456;&#20114;&#24433;&#21709;&#65292;&#24182;&#26410;&#20805;&#20998;&#21033;&#29992;&#22788;&#29702;&#20449;&#24687;&#65292;&#21487;&#33021;&#32473;&#21518;&#32493;&#30340;&#33829;&#38144;&#20915;&#31574;&#24341;&#20837;&#20102;&#37325;&#22823;&#20559;&#24046;&#12290;&#26412;&#25991;&#23558;&#36825;&#20004;&#20010;&#38382;&#39064;&#31216;&#20026;&#38142;&#36335;&#20559;&#24046;&#38382;&#39064;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#20855;&#26377;&#19978;&#19979;&#25991;&#22686;&#24378;&#23398;&#20064;&#30340;&#20840;&#38142;&#36335;&#19978;&#21319;&#26041;&#27861;&#65288;ECUP&#65289;&#12290;ECUP&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#65306;
&lt;/p&gt;
&lt;p&gt;
Uplift modeling, vital in online marketing, seeks to accurately measure the impact of various strategies, such as coupons or discounts, on different users by predicting the Individual Treatment Effect (ITE). In an e-commerce setting, user behavior follows a defined sequential chain, including impression, click, and conversion. Marketing strategies exert varied uplift effects at each stage within this chain, impacting metrics like click-through and conversion rate. Despite its utility, existing research has neglected to consider the inter-task across all stages impacts within a specific treatment and has insufficiently utilized the treatment information, potentially introducing substantial bias into subsequent marketing decisions. We identify these two issues as the chain-bias problem and the treatment-unadaptive problem. This paper introduces the Entire Chain UPlift method with context-enhanced learning (ECUP), devised to tackle these issues. ECUP consists of two primary components: 1)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20998;&#26512;&#26234;&#33021;&#20307;&#38169;&#35823;&#35299;&#35835;&#25110;&#38169;&#35823;&#24863;&#30693;&#30495;&#23454;&#20915;&#31574;&#38382;&#39064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#23450;&#20041;&#26469;&#35780;&#20272;&#26234;&#33021;&#20307;&#22240;&#26524;&#24605;&#32500;&#27700;&#24179;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#31574;&#30053;&#26469;&#35782;&#21035;&#26234;&#33021;&#20307;&#22312;&#32570;&#20047;&#23436;&#20840;&#29702;&#24615;&#30340;&#24773;&#20917;&#19979;&#30340;&#20449;&#24565;&#12290;</title><link>http://arxiv.org/abs/2007.07703</link><description>&lt;p&gt;
&#12298;&#22240;&#26524;&#24605;&#32500;&#22833;&#36133;&#12299;
&lt;/p&gt;
&lt;p&gt;
Failures of Contingent Thinking. (arXiv:2007.07703v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.07703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20998;&#26512;&#26234;&#33021;&#20307;&#38169;&#35823;&#35299;&#35835;&#25110;&#38169;&#35823;&#24863;&#30693;&#30495;&#23454;&#20915;&#31574;&#38382;&#39064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34892;&#20026;&#23450;&#20041;&#26469;&#35780;&#20272;&#26234;&#33021;&#20307;&#22240;&#26524;&#24605;&#32500;&#27700;&#24179;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#31574;&#30053;&#26469;&#35782;&#21035;&#26234;&#33021;&#20307;&#22312;&#32570;&#20047;&#23436;&#20840;&#29702;&#24615;&#30340;&#24773;&#20917;&#19979;&#30340;&#20449;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20998;&#26512;&#19968;&#20010;&#38169;&#35823;&#35299;&#35835;&#25110;&#38169;&#35823;&#24863;&#30693;&#30495;&#23454;&#20915;&#31574;&#38382;&#39064;&#30340;&#26234;&#33021;&#20307;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31995;&#21015;&#34892;&#20026;&#22312;&#23454;&#39564;&#29615;&#22659;&#20013;&#35266;&#23519;&#21040;&#30340;&#34920;&#29616;&#20026;&#26080;&#27861;&#29702;&#35299;&#21547;&#20041;&#65292;&#25442;&#21477;&#35805;&#35828;&#65292;&#26080;&#27861;&#27491;&#30830;&#32771;&#34385;&#21508;&#31181;&#19982;&#20851;&#38190;&#25903;&#20184;&#30456;&#20851;&#30340;&#24773;&#20917;&#20043;&#38388;&#30340;&#36923;&#36753;&#20851;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#24863;&#30693;&#22240;&#26524;&#20851;&#31995;&#30340;&#34892;&#20026;&#23450;&#20041;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#31181;&#24341;&#23548;&#25216;&#26415;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;&#26234;&#33021;&#20307;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#35299;&#37322;&#30830;&#23450;&#20102;&#20854;&#34892;&#20026;&#30340;&#20027;&#35266;&#29366;&#24577;&#31354;&#38388;&#12290;&#36890;&#36807;&#20998;&#26512;&#36825;&#20010;&#29366;&#24577;&#31354;&#38388;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#39537;&#21160;&#32463;&#39564;&#29616;&#35937;&#30340;&#36923;&#36753;&#22797;&#26434;&#24615;&#30340;&#19981;&#21516;&#22522;&#20934;&#12290;&#25105;&#20204;&#21306;&#20998;&#20102;&#38745;&#24577;&#21644;&#21160;&#24577;&#30340;&#29702;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#26082;&#25552;&#20379;&#20102;&#35780;&#20272;&#26234;&#33021;&#20307;&#22240;&#26524;&#24605;&#32500;&#27700;&#24179;&#30340;&#26041;&#27861;&#65292;&#21448;&#25552;&#20379;&#20102;&#22312;&#27809;&#26377;&#23436;&#20840;&#29702;&#24615;&#30340;&#24773;&#20917;&#19979;&#35782;&#21035;&#20854;&#20449;&#24565;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a theoretical framework to analyze an agent who misinterprets or misperceives the true decision problem she faces. We show that a wide range of behavior observed in experimental settings manifest as failures to perceive implications, in other words, to properly account for the logical relationships between various payoff relevant contingencies. We present a behavioral definition of perceived implication, thereby providing an elicitation technique, and show that an agent's account of implication identifies a subjective state-space that underlies her behavior. By analyzing this state-space, we characterize distinct benchmarks of logical sophistication that drive empirical phenomena. We disentangle static and dynamic rationality. Thus, our framework delivers both a methodology for assessing an agent's level of contingent thinking and a strategy for identifying her beliefs in the absence full rationality.
&lt;/p&gt;</description></item></channel></rss>