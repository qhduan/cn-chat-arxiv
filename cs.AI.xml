<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21442;&#25968;&#21270;&#29256;&#26412;&#30340;&#20851;&#31995;GNNs&#65292;&#36890;&#36807;&#22312;$t$&#20026;&#26080;&#31351;&#22823;&#26102;&#20165;&#20351;&#29992;&#20108;&#27425;&#31354;&#38388;&#30340;&#23884;&#20837;&#26469;&#36817;&#20284;$3$-GNNs&#65292;&#23545;&#20110;&#36739;&#20302;&#30340;$t$&#20540;&#65292;&#36890;&#36807;&#20132;&#25442;&#36739;&#23569;&#30340;&#28040;&#24687;&#23454;&#29616;&#24369;&#30340;&#36817;&#20284;&#65292;&#21516;&#26102;&#36890;&#24120;&#20135;&#29983;&#20102;&#20960;&#20010;&#35268;&#21010;&#39046;&#22495;&#20013;&#25152;&#38656;&#30340;$C_3$&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2403.11734</link><description>&lt;p&gt;
&#23398;&#20064;&#21476;&#20856;&#35268;&#21010;&#39046;&#22495;&#30340;&#36890;&#29992;&#31574;&#30053;&#65306;&#36229;&#36234;$C_2$
&lt;/p&gt;
&lt;p&gt;
Learning General Policies for Classical Planning Domains: Getting Beyond C$_2$
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11734
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21442;&#25968;&#21270;&#29256;&#26412;&#30340;&#20851;&#31995;GNNs&#65292;&#36890;&#36807;&#22312;$t$&#20026;&#26080;&#31351;&#22823;&#26102;&#20165;&#20351;&#29992;&#20108;&#27425;&#31354;&#38388;&#30340;&#23884;&#20837;&#26469;&#36817;&#20284;$3$-GNNs&#65292;&#23545;&#20110;&#36739;&#20302;&#30340;$t$&#20540;&#65292;&#36890;&#36807;&#20132;&#25442;&#36739;&#23569;&#30340;&#28040;&#24687;&#23454;&#29616;&#24369;&#30340;&#36817;&#20284;&#65292;&#21516;&#26102;&#36890;&#24120;&#20135;&#29983;&#20102;&#20960;&#20010;&#35268;&#21010;&#39046;&#22495;&#20013;&#25152;&#38656;&#30340;$C_3$&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;GNN&#30340;&#26041;&#27861;&#29992;&#20110;&#23398;&#20064;&#36328;&#35268;&#21010;&#39046;&#22495;&#30340;&#36890;&#29992;&#31574;&#30053;&#21463;&#21040;$C_2$&#34920;&#36798;&#33021;&#21147;&#30340;&#38480;&#21046;&#65292;&#21363;&#19968;&#38454;&#36923;&#36753;&#21482;&#33021;&#21253;&#21547;&#20004;&#20010;&#21464;&#37327;&#21644;&#35745;&#25968;&#12290;&#36825;&#31181;&#38480;&#21046;&#21487;&#20197;&#36890;&#36807;&#36716;&#21521;$k$-GNNs&#65292;&#20854;&#20013;$k=3$&#65292;&#20854;&#20013;&#29289;&#20307;&#23884;&#20837;&#34987;&#19977;&#20803;&#32452;&#23884;&#20837;&#25152;&#26367;&#25442;&#65292;&#26469;&#20811;&#26381;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;$3$-GNNs&#20855;&#26377;$C_3$&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#19981;&#21516;&#20110;&#21463;&#38480;&#20110;$C_2$&#30340;$1$-&#21644;$2$-GNNs&#65292;&#23427;&#20204;&#38656;&#35201;&#22235;&#27425;&#26102;&#38388;&#36827;&#34892;&#28040;&#24687;&#20132;&#25442;&#21644;&#19977;&#27425;&#31354;&#38388;&#36827;&#34892;&#23884;&#20837;&#65292;&#20351;&#23427;&#20204;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21442;&#25968;&#21270;&#29256;&#26412;&#30340;&#20851;&#31995;GNNs&#12290;&#24403;$t$&#20026;&#26080;&#31351;&#22823;&#26102;&#65292;R-GNN[$t$]&#20165;&#20351;&#29992;&#20108;&#27425;&#31354;&#38388;&#30340;&#23884;&#20837;&#26469;&#36817;&#20284;$3$-GNNs&#12290;&#23545;&#20110;&#36739;&#20302;&#30340;$t$&#20540;&#65292;&#20363;&#22914;$t=1$&#21644;$t=2$&#65292;R-GNN[$t$]&#36890;&#36807;&#20132;&#25442;&#36739;&#23569;&#30340;&#28040;&#24687;&#23454;&#29616;&#20102;&#26356;&#24369;&#30340;&#36817;&#20284;&#65292;&#20294;&#26377;&#36259;&#30340;&#26159;&#65292;&#36890;&#24120;&#20135;&#29983;&#20102;&#22312;&#20960;&#20010;&#35268;&#21010;&#39046;&#22495;&#20013;&#25152;&#38656;&#30340;$C_3$&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#26032;&#30340;R-GNN[$t$] ar
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11734v1 Announce Type: new  Abstract: GNN-based approaches for learning general policies across planning domains are limited by the expressive power of $C_2$, namely; first-order logic with two variables and counting. This limitation can be overcomed by transitioning to $k$-GNNs, for $k=3$, wherein object embeddings are substituted with triplet embeddings. Yet, while $3$-GNNs have the expressive power of $C_3$, unlike $1$- and $2$-GNNs that are confined to $C_2$, they require quartic time for message exchange and cubic space for embeddings, rendering them impractical. In this work, we introduce a parameterized version of relational GNNs. When $t$ is infinity, R-GNN[$t$] approximates $3$-GNNs using only quadratic space for embeddings. For lower values of $t$, such as $t=1$ and $t=2$, R-GNN[$t$] achieves a weaker approximation by exchanging fewer messages, yet interestingly, often yield the $C_3$ features required in several planning domains. Furthermore, the new R-GNN[$t$] ar
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#31574;&#30053;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#21160;&#35780;&#20272;&#21644;&#36873;&#25321;&#65292;&#24182;&#36890;&#36807;&#36830;&#32493;&#39044;&#35757;&#32451;&#26174;&#33879;&#25552;&#39640;&#20102;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#12290;&#20027;&#35201;&#21019;&#26032;&#21253;&#25324;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#39564;&#35777;&#22120;&#65292;&#21457;&#24067;&#20102;&#39640;&#36136;&#37327;&#30340;AutoMathText&#25968;&#25454;&#38598;&#65292;&#24182;&#23454;&#29616;&#20102;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#30340;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.07625</link><description>&lt;p&gt;
AutoMathText&#65306;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#31574;&#30053;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#21160;&#35780;&#20272;&#21644;&#36873;&#25321;&#65292;&#24182;&#36890;&#36807;&#36830;&#32493;&#39044;&#35757;&#32451;&#26174;&#33879;&#25552;&#39640;&#20102;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#12290;&#20027;&#35201;&#21019;&#26032;&#21253;&#25324;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#39564;&#35777;&#22120;&#65292;&#21457;&#24067;&#20102;&#39640;&#36136;&#37327;&#30340;AutoMathText&#25968;&#25454;&#38598;&#65292;&#24182;&#23454;&#29616;&#20102;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36890;&#36807;&#25345;&#32493;&#30340;&#39044;&#35757;&#32451;&#25913;&#21892;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#25512;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31574;&#30053;&#65292;&#21033;&#29992;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#12290;&#19982;&#20256;&#32479;&#30340;&#26377;&#20154;&#24037;&#26631;&#27880;&#25968;&#25454;&#30340;&#30417;&#30563;&#24494;&#35843;&#25110;&#35757;&#32451;&#36807;&#30340;&#20998;&#31867;&#22120;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#38646;&#26679;&#26412;&#39564;&#35777;&#22120;&#65292;&#33258;&#20027;&#35780;&#20272;&#21644;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#25968;&#23398;&#20869;&#23481;&#65292;&#24182;&#21457;&#24067;&#20102;&#32463;&#36807;&#31574;&#21010;&#30340;&#24320;&#28304;AutoMathText&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#36229;&#36807;200GB&#30340;&#25968;&#25454;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#23545;AutoMathText&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#36830;&#32493;&#39044;&#35757;&#32451;&#65292;&#20351;&#24471;7B&#21442;&#25968;&#30340;Mistral&#35821;&#35328;&#27169;&#22411;&#22312;MATH&#25968;&#25454;&#38598;&#19978;&#30340;&#19979;&#28216;&#24615;&#33021;&#22823;&#24133;&#25552;&#21319;&#65292;&#32780;&#20196;&#29260;&#25968;&#37327;&#27604;&#20043;&#21069;&#30340;&#36830;&#32493;&#39044;&#35757;&#32451;&#24037;&#20316;&#20943;&#23569;&#20102;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;&#22522;&#20934;&#30340;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#25552;&#39640;&#20102;2&#20493;&#65292;&#31361;&#26174;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#22686;&#24378;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
To improve language models' proficiency in mathematical reasoning via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional supervised fine-tuning or trained classifiers with human-annotated data, our approach utilizes meta-prompted language models as zero-shot verifiers to autonomously evaluate and select high-quality mathematical content, and we release the curated open-source AutoMathText dataset encompassing over 200GB of data. To demonstrate the efficacy of our method, we continuously pretrained a 7B-parameter Mistral language model on the AutoMathText dataset, achieving substantial improvements in downstream performance on the MATH dataset with a token amount reduced by orders of magnitude compared to previous continuous pretraining works. Our method showcases a 2 times increase in pretraining token efficiency compared to baselines, underscoring the potential of our approach in enhancing
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23398;&#20064;&#30340;&#22768;&#26126;&#24615;&#38544;&#31169;&#20445;&#25252;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;Differentially-Private Stochastic Gradient Descent&#65288;DP-SGD&#65289;&#31639;&#27861;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26367;&#20195;&#37096;&#20998;&#23454;&#38469;&#25968;&#25454;&#26469;&#22238;&#31572;&#26597;&#35810;&#65292;&#24182;&#20801;&#35768;&#29992;&#25143;&#25351;&#23450;&#35201;&#20445;&#25252;&#30340;&#31169;&#20154;&#20449;&#24687;&#12290;&#27492;&#26694;&#26550;&#36824;&#21487;&#20197;&#33258;&#21160;&#36873;&#25321;&#36716;&#25442;&#35745;&#21010;&#21644;&#36229;&#21442;&#25968;&#65292;&#24182;&#20801;&#35768;&#20154;&#24037;&#19987;&#23478;&#23457;&#26680;&#21644;&#35843;&#25972;&#38544;&#31169;&#20445;&#25252;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.12393</link><description>&lt;p&gt;
&#22522;&#20110;&#23398;&#20064;&#30340;&#22768;&#26126;&#24615;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#32852;&#37030;&#31649;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Learning-based Declarative Privacy-Preserving Framework for Federated Data Management. (arXiv:2401.12393v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12393
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23398;&#20064;&#30340;&#22768;&#26126;&#24615;&#38544;&#31169;&#20445;&#25252;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;Differentially-Private Stochastic Gradient Descent&#65288;DP-SGD&#65289;&#31639;&#27861;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26367;&#20195;&#37096;&#20998;&#23454;&#38469;&#25968;&#25454;&#26469;&#22238;&#31572;&#26597;&#35810;&#65292;&#24182;&#20801;&#35768;&#29992;&#25143;&#25351;&#23450;&#35201;&#20445;&#25252;&#30340;&#31169;&#20154;&#20449;&#24687;&#12290;&#27492;&#26694;&#26550;&#36824;&#21487;&#20197;&#33258;&#21160;&#36873;&#25321;&#36716;&#25442;&#35745;&#21010;&#21644;&#36229;&#21442;&#25968;&#65292;&#24182;&#20801;&#35768;&#20154;&#24037;&#19987;&#23478;&#23457;&#26680;&#21644;&#35843;&#25972;&#38544;&#31169;&#20445;&#25252;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#20010;&#31169;&#26377;&#25968;&#25454;&#23396;&#23707;&#19978;&#36827;&#34892;&#32852;&#37030;&#26597;&#35810;&#22788;&#29702;&#26102;&#65292;&#24179;&#34913;&#38544;&#31169;&#21644;&#20934;&#30830;&#24615;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#28436;&#31034;&#19968;&#31181;&#33258;&#21160;&#21270;&#26032;&#20852;&#38544;&#31169;&#20445;&#25252;&#25216;&#26415;&#30340;&#31471;&#21040;&#31471;&#24037;&#20316;&#27969;&#65292;&#35813;&#25216;&#26415;&#20351;&#29992;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#31639;&#27861;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26367;&#25442;&#23454;&#38469;&#25968;&#25454;&#30340;&#37096;&#20998;&#26469;&#22238;&#31572;&#26597;&#35810;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26032;&#39062;&#22768;&#26126;&#24615;&#38544;&#31169;&#20445;&#25252;&#24037;&#20316;&#27969;&#20801;&#35768;&#29992;&#25143;&#25351;&#23450;&#8220;&#35201;&#20445;&#25252;&#30340;&#31169;&#20154;&#20449;&#24687;&#8221;&#32780;&#19981;&#26159;&#8220;&#22914;&#20309;&#20445;&#25252;&#8221;&#12290;&#22312;&#24213;&#23618;&#65292;&#31995;&#32479;&#33258;&#21160;&#36873;&#25321;&#26597;&#35810;-&#27169;&#22411;&#36716;&#25442;&#35745;&#21010;&#20197;&#21450;&#36229;&#21442;&#25968;&#12290;&#21516;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#24037;&#20316;&#27969;&#36824;&#20801;&#35768;&#20154;&#24037;&#19987;&#23478;&#23457;&#26680;&#21644;&#35843;&#25972;&#36873;&#25321;&#30340;&#38544;&#31169;&#20445;&#25252;&#26426;&#21046;&#65292;&#29992;&#20110;&#23457;&#35745;/&#21512;&#35268;&#21644;&#20248;&#21270;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is challenging to balance the privacy and accuracy for federated query processing over multiple private data silos. In this work, we will demonstrate an end-to-end workflow for automating an emerging privacy-preserving technique that uses a deep learning model trained using the Differentially-Private Stochastic Gradient Descent (DP-SGD) algorithm to replace portions of actual data to answer a query. Our proposed novel declarative privacy-preserving workflow allows users to specify "what private information to protect" rather than "how to protect". Under the hood, the system automatically chooses query-model transformation plans as well as hyper-parameters. At the same time, the proposed workflow also allows human experts to review and tune the selected privacy-preserving mechanism for audit/compliance, and optimization purposes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#36801;&#31227;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32570;&#22833;&#27169;&#24577;&#19979;&#36827;&#34892;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#32763;&#35793;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#30340;&#20869;&#23481;&#20197;&#37325;&#26500;&#32570;&#22833;&#30340;&#38899;&#39057;&#27169;&#24577;&#65292;&#24182;&#21033;&#29992;&#36328;&#27169;&#24577;&#27880;&#24847;&#26426;&#21046;&#36827;&#34892;&#24773;&#24863;&#39044;&#27979;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#21644;&#19982;&#23436;&#25972;&#22810;&#27169;&#24577;&#30417;&#30563;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.10747</link><description>&lt;p&gt;
&#32570;&#22833;&#27169;&#24577;&#19979;&#30340;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;:&#19968;&#31181;&#30693;&#35782;&#36801;&#31227;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach. (arXiv:2401.10747v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10747
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#36801;&#31227;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32570;&#22833;&#27169;&#24577;&#19979;&#36827;&#34892;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#32763;&#35793;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#30340;&#20869;&#23481;&#20197;&#37325;&#26500;&#32570;&#22833;&#30340;&#38899;&#39057;&#27169;&#24577;&#65292;&#24182;&#21033;&#29992;&#36328;&#27169;&#24577;&#27880;&#24847;&#26426;&#21046;&#36827;&#34892;&#24773;&#24863;&#39044;&#27979;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#21644;&#19982;&#23436;&#25972;&#22810;&#27169;&#24577;&#30417;&#30563;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#26088;&#22312;&#36890;&#36807;&#35270;&#35273;&#12289;&#35821;&#35328;&#21644;&#22768;&#38899;&#32447;&#32034;&#26469;&#35782;&#21035;&#20010;&#20307;&#34920;&#36798;&#30340;&#24773;&#32490;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#22823;&#22810;&#20551;&#35774;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#36807;&#31243;&#20013;&#25152;&#26377;&#27169;&#24577;&#37117;&#26159;&#21487;&#29992;&#30340;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#30340;&#31639;&#27861;&#23481;&#26131;&#21463;&#21040;&#32570;&#22833;&#27169;&#24577;&#30340;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#30693;&#35782;&#36801;&#31227;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#36827;&#34892;&#32763;&#35793;&#65292;&#20197;&#37325;&#26500;&#32570;&#22833;&#30340;&#38899;&#39057;&#27169;&#24577;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#36328;&#27169;&#24577;&#27880;&#24847;&#26426;&#21046;&#65292;&#20197;&#20445;&#30041;&#37325;&#26500;&#21644;&#35266;&#23519;&#21040;&#30340;&#27169;&#24577;&#30340;&#26368;&#22823;&#20449;&#24687;&#65292;&#29992;&#20110;&#24773;&#24863;&#39044;&#27979;&#12290;&#22312;&#19977;&#20010;&#20844;&#24320;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#30456;&#23545;&#20110;&#22522;&#32447;&#31639;&#27861;&#30340;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#23454;&#29616;&#20102;&#19982;&#20855;&#26377;&#23436;&#25972;&#22810;&#27169;&#24577;&#30417;&#30563;&#30340;&#20808;&#21069;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal sentiment analysis aims to identify the emotions expressed by individuals through visual, language, and acoustic cues. However, most of the existing research efforts assume that all modalities are available during both training and testing, making their algorithms susceptible to the missing modality scenario. In this paper, we propose a novel knowledge-transfer network to translate between different modalities to reconstruct the missing audio modalities. Moreover, we develop a cross-modality attention mechanism to retain the maximal information of the reconstructed and observed modalities for sentiment prediction. Extensive experiments on three publicly available datasets demonstrate significant improvements over baselines and achieve comparable results to the previous methods with complete multi-modality supervision.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#22478;&#24066;&#29615;&#22659;&#19979;&#30340;&#33258;&#20027;&#22810;&#26234;&#33021;&#20307;&#20986;&#31199;&#36710;&#36335;&#24452;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#28378;&#21160;&#20026;&#22522;&#30784;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#26469;&#20943;&#23569;&#35745;&#31639;&#37327;&#12290;</title><link>http://arxiv.org/abs/2311.01534</link><description>&lt;p&gt;
&#22823;&#22411;&#22320;&#22270;&#19978;&#30340;&#25353;&#38656;&#22478;&#24066;&#20986;&#34892;&#38382;&#39064;&#30340;&#36817;&#20284;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;&#25193;&#23637;&#29256;&#65289;
&lt;/p&gt;
&lt;p&gt;
Approximate Multiagent Reinforcement Learning for On-Demand Urban Mobility Problem on a Large Map (extended version). (arXiv:2311.01534v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#22478;&#24066;&#29615;&#22659;&#19979;&#30340;&#33258;&#20027;&#22810;&#26234;&#33021;&#20307;&#20986;&#31199;&#36710;&#36335;&#24452;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#28378;&#21160;&#20026;&#22522;&#30784;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#26469;&#20943;&#23569;&#35745;&#31639;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#22823;&#22411;&#22478;&#24066;&#29615;&#22659;&#19979;&#30340;&#33258;&#20027;&#22810;&#26234;&#33021;&#20307;&#20986;&#31199;&#36710;&#36335;&#24452;&#38382;&#39064;&#65292;&#26410;&#26469;&#20056;&#36710;&#35831;&#27714;&#30340;&#20301;&#32622;&#21644;&#25968;&#37327;&#20107;&#20808;&#26410;&#30693;&#65292;&#20294;&#36981;&#24490;&#20272;&#35745;&#30340;&#32463;&#39564;&#20998;&#24067;&#12290;&#26368;&#36817;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#22914;&#26524;&#22522;&#30784;&#31574;&#30053;&#26159;&#31283;&#23450;&#30340;&#65292;&#37027;&#20040;&#22522;&#20110;&#28378;&#21160;&#30340;&#31639;&#27861;&#19982;&#36825;&#26679;&#30340;&#22522;&#30784;&#31574;&#30053;&#20135;&#29983;&#25509;&#36817;&#26368;&#20248;&#30340;&#31283;&#23450;&#31574;&#30053;&#12290;&#23613;&#31649;&#22522;&#20110;&#28378;&#21160;&#30340;&#26041;&#27861;&#38750;&#24120;&#36866;&#21512;&#23398;&#20064;&#20855;&#26377;&#23545;&#26410;&#26469;&#38656;&#27714;&#32771;&#34385;&#30340;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#31574;&#30053;&#65292;&#20294;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#22823;&#22411;&#22478;&#24066;&#29615;&#22659;&#21487;&#33021;&#35745;&#31639;&#19978;&#24456;&#26114;&#36149;&#12290;&#22823;&#22411;&#29615;&#22659;&#24448;&#24448;&#26377;&#22823;&#37327;&#35831;&#27714;&#65292;&#22240;&#27492;&#38656;&#35201;&#22823;&#22411;&#30340;&#20986;&#31199;&#36710;&#38431;&#20445;&#35777;&#31283;&#23450;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#65288;&#36880;&#19968;&#65289;&#28378;&#21160;&#30340;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#65292;&#20854;&#20013;&#35745;&#31639;&#22797;&#26434;&#24615;&#38543;&#20195;&#29702;&#25968;&#37327;&#32447;&#24615;&#22686;&#38271;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#36880;&#19968;&#28378;&#21160;&#20026;&#22522;&#30784;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#20943;&#23569;&#35745;&#31639;&#37327;
&lt;/p&gt;
&lt;p&gt;
In this paper, we focus on the autonomous multiagent taxi routing problem for a large urban environment where the location and number of future ride requests are unknown a-priori, but follow an estimated empirical distribution. Recent theory has shown that if a base policy is stable then a rollout-based algorithm with such a base policy produces a near-optimal stable policy. Although, rollout-based approaches are well-suited for learning cooperative multiagent policies with considerations for future demand, applying such methods to a large urban environment can be computationally expensive. Large environments tend to have a large volume of requests, and hence require a large fleet of taxis to guarantee stability. In this paper, we aim to address the computational bottleneck of multiagent (one-at-a-time) rollout, where the computational complexity grows linearly in the number of agents. We propose an approximate one-at-a-time rollout-based two-phase algorithm that reduces the computatio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22312;&#29305;&#26435;&#21319;&#32423;&#22330;&#26223;&#20013;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#28183;&#36879;&#27979;&#35797;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#33258;&#21160;&#21270;&#30340;Linux&#29305;&#26435;&#21319;&#32423;&#22522;&#20934;&#21644;&#19968;&#20010;LLM-guided&#29305;&#26435;&#21319;&#32423;&#24037;&#20855;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;LLMs&#30340;&#19981;&#21516;&#25552;&#31034;&#35774;&#35745;&#12289;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#39640;&#32423;&#25351;&#23548;&#23545;&#27979;&#35797;&#30340;&#24433;&#21709;&#65292;&#24182;&#35752;&#35770;&#20102;LLMs&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.11409</link><description>&lt;p&gt;
&#35780;&#20272;LLMs&#22312;&#29305;&#26435;&#21319;&#32423;&#22330;&#26223;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Evaluating LLMs for Privilege-Escalation Scenarios. (arXiv:2310.11409v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22312;&#29305;&#26435;&#21319;&#32423;&#22330;&#26223;&#20013;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#28183;&#36879;&#27979;&#35797;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#33258;&#21160;&#21270;&#30340;Linux&#29305;&#26435;&#21319;&#32423;&#22522;&#20934;&#21644;&#19968;&#20010;LLM-guided&#29305;&#26435;&#21319;&#32423;&#24037;&#20855;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;LLMs&#30340;&#19981;&#21516;&#25552;&#31034;&#35774;&#35745;&#12289;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#39640;&#32423;&#25351;&#23548;&#23545;&#27979;&#35797;&#30340;&#24433;&#21709;&#65292;&#24182;&#35752;&#35770;&#20102;LLMs&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28183;&#36879;&#27979;&#35797;&#26159;&#32593;&#32476;&#23433;&#20840;&#30340;&#19968;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#23427;&#20801;&#35768;&#32452;&#32455;&#20027;&#21160;&#35782;&#21035;&#21644;&#20462;&#22797;&#31995;&#32479;&#20013;&#30340;&#28431;&#27934;&#65292;&#20174;&#32780;&#22686;&#24378;&#20854;&#23545;&#28508;&#22312;&#32593;&#32476;&#25915;&#20987;&#30340;&#38450;&#24481;&#26426;&#21046;&#12290;&#22312;&#28183;&#36879;&#27979;&#35797;&#39046;&#22495;&#65292;&#26368;&#36817;&#30340;&#19968;&#20010;&#36827;&#23637;&#26159;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#25105;&#20204;&#25506;&#32034;LLMs&#19982;&#28183;&#36879;&#27979;&#35797;&#30340;&#20132;&#21449;&#39046;&#22495;&#65292;&#20197;&#20102;&#35299;&#23427;&#20204;&#22312;&#29305;&#26435;&#21319;&#32423;&#22330;&#26223;&#20013;&#30340;&#33021;&#21147;&#21644;&#25361;&#25112;&#12290;&#25105;&#20204;&#20351;&#29992;&#26412;&#22320;&#34394;&#25311;&#26426;&#21019;&#24314;&#20102;&#19968;&#20010;&#33258;&#21160;&#21270;&#30340;Linux&#29305;&#26435;&#21319;&#32423;&#22522;&#20934;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;LLMs&#30340;&#29305;&#26435;&#21319;&#32423;&#24037;&#20855;&#65292;&#29992;&#20110;&#35780;&#20272;&#19981;&#21516;&#30340;LLMs&#21644;&#25552;&#31034;&#31574;&#30053;&#22312;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19981;&#21516;&#25552;&#31034;&#35774;&#35745;&#30340;&#24433;&#21709;&#65292;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#22909;&#22788;&#65292;&#20197;&#21450;&#21521;LLMs&#25552;&#20379;&#39640;&#32423;&#25351;&#23548;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;LLMs&#38754;&#20020;&#30340;&#25361;&#25112;&#39046;&#22495;&#65292;&#21253;&#25324;&#22312;&#27979;&#35797;&#36807;&#31243;&#20013;&#20445;&#25345;&#19987;&#27880;&#12289;&#22788;&#29702;&#38169;&#35823;&#20197;&#21450;&#19982;&#20256;&#32479;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Penetration testing, an essential component of cybersecurity, allows organizations to proactively identify and remediate vulnerabilities in their systems, thus bolstering their defense mechanisms against potential cyberattacks. One recent advancement in the realm of penetration testing is the utilization of Language Models (LLMs). We explore the intersection of LLMs and penetration testing to gain insight into their capabilities and challenges in the context of privilige escalation. We create an automated Linux privilege-escalation benchmark utilizing local virtual machines. We introduce an LLM-guided privilege-escalation tool designed for evaluating different LLMs and prompt strategies against our benchmark. We analyze the impact of different prompt designs, the benefits of in-context learning, and the advantages of offering high-level guidance to LLMs. We discuss challenging areas for LLMs, including maintaining focus during testing, coping with errors, and finally comparing them wit
&lt;/p&gt;</description></item><item><title>&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;AI&#30340;&#33258;&#21160;&#23398;&#29983;&#21453;&#39304;&#26694;&#26550;&#21487;&#20197;&#25552;&#20379;&#20016;&#23500;&#30340;&#21453;&#39304;&#65292;&#20294;&#24341;&#20837;&#20102;&#20262;&#29702;&#38382;&#39064;&#65292;&#24182;&#38656;&#35201;&#35299;&#20915;&#8220;&#22810;&#25968;&#20154;&#30340;&#26292;&#25919;&#8221;&#21644;&#24573;&#35270;&#38271;&#23614;&#20013;&#23569;&#25968;&#32676;&#20307;&#38656;&#27714;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.15334</link><description>&lt;p&gt;
&#19968;&#31181;&#36127;&#36131;&#20219;&#24320;&#21457;&#22522;&#20110;&#29983;&#25104;AI&#30340;&#33258;&#21160;&#23398;&#29983;&#21453;&#39304;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Framework for Responsible Development of Automated Student Feedback with Generative AI. (arXiv:2308.15334v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15334
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;AI&#30340;&#33258;&#21160;&#23398;&#29983;&#21453;&#39304;&#26694;&#26550;&#21487;&#20197;&#25552;&#20379;&#20016;&#23500;&#30340;&#21453;&#39304;&#65292;&#20294;&#24341;&#20837;&#20102;&#20262;&#29702;&#38382;&#39064;&#65292;&#24182;&#38656;&#35201;&#35299;&#20915;&#8220;&#22810;&#25968;&#20154;&#30340;&#26292;&#25919;&#8221;&#21644;&#24573;&#35270;&#38271;&#23614;&#20013;&#23569;&#25968;&#32676;&#20307;&#38656;&#27714;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#20016;&#23500;&#30340;&#21453;&#39304;&#23545;&#20110;&#25903;&#25345;&#23398;&#29983;&#23398;&#20064;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#29983;&#25104;AI&#23588;&#20854;&#26159;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#36827;&#23637;&#65292;&#20026;&#21521;&#23398;&#29983;&#25552;&#20379;&#21487;&#37325;&#22797;&#12289;&#21487;&#25193;&#23637;&#21644;&#21363;&#26102;&#29983;&#25104;&#30340;&#33258;&#21160;&#21453;&#39304;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#20351;&#24471;&#20043;&#21069;&#31232;&#32570;&#19988;&#26114;&#36149;&#30340;&#23398;&#20064;&#36164;&#28304;&#21464;&#24471;&#20016;&#23500;&#36215;&#26469;&#12290;&#20174;&#25216;&#26415;&#35282;&#24230;&#32780;&#35328;&#65292;&#36825;&#31181;&#26041;&#27861;&#26159;&#21487;&#34892;&#30340;&#65292;&#24471;&#30410;&#20110;&#26368;&#36817;&#20154;&#24037;&#26234;&#33021;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#36827;&#27493;&#65307;&#28982;&#32780;&#65292;&#37319;&#29992;&#36825;&#20123;&#25216;&#26415;&#20063;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#28508;&#22312;&#30340;&#20262;&#29702;&#38382;&#39064;&#65292;&#38656;&#35201;&#35748;&#30495;&#32771;&#34385;&#12290;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#21560;&#24341;&#21147;&#22312;&#20110;&#23427;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#33258;&#21160;&#21270;&#26368;&#20047;&#21619;&#30340;&#20219;&#21153;&#65307;&#20294;&#26159;&#36825;&#20063;&#21487;&#33021;&#23548;&#33268;&#8220;&#22810;&#25968;&#20154;&#30340;&#26292;&#25919;&#8221;&#65292;&#21363;&#24573;&#35270;&#20102;&#38271;&#23614;&#20013;&#23569;&#25968;&#32676;&#20307;&#30340;&#38656;&#27714;&#65292;&#22240;&#20026;&#36825;&#20123;&#38656;&#27714;&#24456;&#38590;&#33258;&#21160;&#21270;&#12290;&#22240;&#27492;&#65292;&#24320;&#21457;&#33021;&#22815;&#20135;&#29983;&#26377;&#20215;&#20540;&#21644;&#30495;&#23454;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Providing rich feedback to students is essential for supporting student learning. Recent advances in generative AI, particularly within large language modelling (LLM), provide the opportunity to deliver repeatable, scalable and instant automatically generated feedback to students, making abundant a previously scarce and expensive learning resource. Such an approach is feasible from a technical perspective due to these recent advances in Artificial Intelligence (AI) and Natural Language Processing (NLP); while the potential upside is a strong motivator, doing so introduces a range of potential ethical issues that must be considered as we apply these technologies. The attractiveness of AI systems is that they can effectively automate the most mundane tasks; but this risks introducing a "tyranny of the majority", where the needs of minorities in the long tail are overlooked because they are difficult to automate.  Developing machine learning models that can generate valuable and authentic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#22270;&#20687;&#20998;&#31867;&#25506;&#31350;&#20102;&#20154;&#26426;&#24863;&#30693;&#24046;&#24322;&#65292;&#21457;&#29616;&#21363;&#20351;&#20934;&#30830;&#29575;&#30456;&#20284;&#65292;&#20154;&#31867;&#21644;&#26426;&#22120;&#30340;&#31572;&#26696;&#20998;&#24067;&#20063;&#21487;&#33021;&#19981;&#21516;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#26399;&#20154;&#26426;&#21512;&#20316;&#26469;&#25552;&#39640;&#20219;&#21153;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.08733</link><description>&lt;p&gt;
&#20154;&#31867;&#21644;&#26426;&#22120;&#26377;&#30456;&#21516;&#30340;&#30524;&#30555;&#21527;&#65311;&#22522;&#20110;&#22270;&#20687;&#20998;&#31867;&#30340;&#20154;&#26426;&#24863;&#30693;&#24046;&#24322;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Do humans and machines have the same eyes? Human-machine perceptual differences on image classification. (arXiv:2304.08733v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#22270;&#20687;&#20998;&#31867;&#25506;&#31350;&#20102;&#20154;&#26426;&#24863;&#30693;&#24046;&#24322;&#65292;&#21457;&#29616;&#21363;&#20351;&#20934;&#30830;&#29575;&#30456;&#20284;&#65292;&#20154;&#31867;&#21644;&#26426;&#22120;&#30340;&#31572;&#26696;&#20998;&#24067;&#20063;&#21487;&#33021;&#19981;&#21516;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#26399;&#20154;&#26426;&#21512;&#20316;&#26469;&#25552;&#39640;&#20219;&#21153;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#33391;&#22909;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#36890;&#24120;&#36890;&#36807;&#27169;&#20223;&#20174;&#35757;&#32451;&#26631;&#31614;&#20013;&#23398;&#21040;&#30340;&#20154;&#31867;&#34892;&#20026;&#26469;&#35299;&#20915;&#35270;&#35273;&#20219;&#21153;&#12290;&#36817;&#26399;&#35270;&#35273;&#30740;&#31350;&#30340;&#22823;&#37096;&#20998;&#21162;&#21147;&#38598;&#20013;&#22312;&#20351;&#29992;&#26631;&#20934;&#21270;&#22522;&#20934;&#26469;&#27979;&#37327;&#27169;&#22411;&#20219;&#21153;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20102;&#35299;&#20154;&#19982;&#26426;&#22120;&#20043;&#38388;&#30340;&#24863;&#30693;&#24046;&#24322;&#26041;&#38754;&#30340;&#24037;&#20316;&#36824;&#24456;&#26377;&#38480;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#39318;&#20808;&#37327;&#21270;&#24182;&#20998;&#26512;&#20102;&#20004;&#31181;&#26469;&#28304;&#38169;&#35823;&#30340;&#32479;&#35745;&#20998;&#24067;&#12290;&#28982;&#21518;&#25105;&#20204;&#36890;&#36807;&#38590;&#24230;&#32423;&#21035;&#23545;&#20219;&#21153;&#36827;&#34892;&#25490;&#24207;&#65292;&#25506;&#35752;&#20154;&#31867;&#19982;&#26426;&#22120;&#19987;&#19994;&#30693;&#35782;&#30340;&#24046;&#24322;&#12290;&#21363;&#20351;&#20154;&#31867;&#21644;&#26426;&#22120;&#30340;&#25972;&#20307;&#20934;&#30830;&#24615;&#30456;&#20284;&#65292;&#31572;&#26696;&#30340;&#20998;&#24067;&#20063;&#21487;&#33021;&#20250;&#26377;&#25152;&#19981;&#21516;&#12290;&#21033;&#29992;&#20154;&#31867;&#21644;&#26426;&#22120;&#20043;&#38388;&#30340;&#24863;&#30693;&#24046;&#24322;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#20102;&#19968;&#31181;&#21518;&#26399;&#20154;&#26426;&#21512;&#20316;&#65292;&#20854;&#34920;&#29616;&#27604;&#21333;&#29420;&#30340;&#20154;&#25110;&#26426;&#22120;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Trained computer vision models are assumed to solve vision tasks by imitating human behavior learned from training labels. Most efforts in recent vision research focus on measuring the model task performance using standardized benchmarks. Limited work has been done to understand the perceptual difference between humans and machines. To fill this gap, our study first quantifies and analyzes the statistical distributions of mistakes from the two sources. We then explore human vs. machine expertise after ranking tasks by difficulty levels. Even when humans and machines have similar overall accuracies, the distribution of answers may vary. Leveraging the perceptual difference between humans and machines, we empirically demonstrate a post-hoc human-machine collaboration that outperforms humans or machines alone.
&lt;/p&gt;</description></item><item><title>&#31890;&#29699;&#20248;&#21270;&#31639;&#27861;(GBO)&#26159;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#24230;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#24341;&#20837;&#31890;&#29699;&#35745;&#31639;&#26469;&#25552;&#39640;&#20840;&#23616;&#25628;&#32034;&#33021;&#21147;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36825;&#20123;&#26041;&#38754;&#23427;&#27604;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2303.12807</link><description>&lt;p&gt;
&#31890;&#29699;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Granular-ball Optimization Algorithm. (arXiv:2303.12807v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12807
&lt;/p&gt;
&lt;p&gt;
&#31890;&#29699;&#20248;&#21270;&#31639;&#27861;(GBO)&#26159;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#24230;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#24341;&#20837;&#31890;&#29699;&#35745;&#31639;&#26469;&#25552;&#39640;&#20840;&#23616;&#25628;&#32034;&#33021;&#21147;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36825;&#20123;&#26041;&#38754;&#23427;&#27604;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#26234;&#33021;&#20248;&#21270;&#31639;&#27861;&#37117;&#26159;&#22522;&#20110;&#26368;&#23567;&#31890;&#24230;&#21363;&#28857;&#30340;&#35774;&#35745;&#65292;&#23548;&#33268;&#20840;&#23616;&#25628;&#32034;&#33021;&#21147;&#36739;&#24369;&#19988;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#24230;&#20248;&#21270;&#31639;&#27861;&#65292;&#21363;&#31890;&#29699;&#20248;&#21270;&#31639;&#27861;(GBO)&#65292;&#36890;&#36807;&#24341;&#20837;&#31890;&#29699;&#35745;&#31639;&#26469;&#23454;&#29616;&#12290;GBO&#20351;&#29992;&#22810;&#20010;&#31890;&#29699;&#26469;&#35206;&#30422;&#35299;&#31354;&#38388;&#65292;&#20351;&#29992;&#35768;&#22810;&#32454;&#23567;&#30340;&#32454;&#31890;&#24230;&#31890;&#29699;&#26469;&#25551;&#36848;&#37325;&#35201;&#37096;&#20998;&#65292;&#20351;&#29992;&#23569;&#37327;&#30340;&#22823;&#31895;&#31890;&#24230;&#31890;&#29699;&#26469;&#25551;&#36848;&#19981;&#37325;&#35201;&#30340;&#37096;&#20998;&#65292;&#31934;&#32454;&#30340;&#22810;&#31890;&#24230;&#25968;&#25454;&#25551;&#36848;&#33021;&#21147;&#25552;&#39640;&#20102;&#20840;&#23616;&#25628;&#32034;&#33021;&#21147;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#20108;&#21313;&#20010;&#22522;&#20934;&#20989;&#25968;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#26368;&#27969;&#34892;&#30340;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#30456;&#27604;&#65292;GBO&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#24555;&#30340;&#36895;&#24230;&#65292;&#26356;&#25509;&#36817;&#26368;&#20248;&#35299;&#65292;&#27809;&#26377;&#36229;&#21442;&#25968;&#65292;&#35774;&#35745;&#26356;&#31616;&#21333;&#12290;
&lt;/p&gt;
&lt;p&gt;
The existing intelligent optimization algorithms are designed based on the finest granularity, i.e., a point. This leads to weak global search ability and inefficiency. To address this problem, we proposed a novel multi-granularity optimization algorithm, namely granular-ball optimization algorithm (GBO), by introducing granular-ball computing. GBO uses many granular-balls to cover the solution space. Quite a lot of small and fine-grained granular-balls are used to depict the important parts, and a little number of large and coarse-grained granular-balls are used to depict the inessential parts. Fine multi-granularity data description ability results in a higher global search capability and faster convergence speed. In comparison with the most popular and state-of-the-art algorithms, the experiments on twenty benchmark functions demonstrate its better performance. The faster speed, higher approximation ability of optimal solution, no hyper-parameters, and simpler design of GBO make it 
&lt;/p&gt;</description></item></channel></rss>