<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#36755;&#20837;&#20984;&#25439;&#22833;&#32593;&#32476;&#65288;ICLN&#65289;&#65292;&#36890;&#36807;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20219;&#21153;&#25439;&#22833;&#65292;&#20026;&#20915;&#31574;&#38598;&#20013;&#23398;&#20064;&#25552;&#20379;&#20102;&#20840;&#23616;&#26367;&#20195;&#25439;&#22833;&#12290;</title><link>https://arxiv.org/abs/2403.01875</link><description>&lt;p&gt;
ICLN&#65306;&#36755;&#20837;&#20984;&#25439;&#22833;&#32593;&#32476;&#29992;&#20110;&#20915;&#31574;&#38598;&#20013;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
ICLN: Input Convex Loss Network for Decision Focused Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01875
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#36755;&#20837;&#20984;&#25439;&#22833;&#32593;&#32476;&#65288;ICLN&#65289;&#65292;&#36890;&#36807;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20219;&#21153;&#25439;&#22833;&#65292;&#20026;&#20915;&#31574;&#38598;&#20013;&#23398;&#20064;&#25552;&#20379;&#20102;&#20840;&#23616;&#26367;&#20195;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#30830;&#23450;&#24615;&#26465;&#20214;&#19979;&#30340;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#39044;&#27979;&#26410;&#30693;&#21442;&#25968;&#36890;&#24120;&#34987;&#35748;&#20026;&#19982;&#20248;&#21270;&#37096;&#20998;&#26080;&#20851;&#12290;&#20915;&#31574;&#38598;&#20013;&#23398;&#20064;&#65288;DFL&#65289;&#26159;&#19968;&#20010;&#38754;&#21521;&#20219;&#21153;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35843;&#25972;&#39044;&#27979;&#27169;&#22411;&#20197;&#20026;&#30456;&#24212;&#20219;&#21153;&#25552;&#20379;&#26356;&#22909;&#30340;&#20915;&#31574;&#26469;&#25972;&#21512;&#39044;&#27979;&#21644;&#20248;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#36755;&#20837;&#20984;&#25439;&#22833;&#32593;&#32476;&#65288;ICLN&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#20840;&#23616;&#26367;&#20195;&#25439;&#22833;&#65292;&#21487;&#20197;&#22312;&#19968;&#33324;&#30340;DFL&#33539;&#24335;&#20013;&#23454;&#29616;&#12290;ICLN&#36890;&#36807;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20219;&#21153;&#25439;&#22833;&#65292;&#24050;&#32463;&#34987;&#20445;&#35777;&#20026;&#26576;&#20123;&#24773;&#20917;&#19979;&#26159;&#20984;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01875v1 Announce Type: cross  Abstract: In decision-making problem under uncertainty, predicting unknown parameters is often considered independent of the optimization part. Decision-focused Learning (DFL) is a task-oriented framework to integrate prediction and optimization by adapting predictive model to give better decision for the corresponding task. Here, an inevitable challenge arises when computing gradients of the optimal decision with respect to the parameters. Existing researches cope this issue by smoothly reforming surrogate optimization or construct surrogate loss function that mimic task loss. However, they are applied to restricted optimization domain or build functions in a local manner leading a large computational time. In this paper, we propose Input Convex Loss Network (ICLN), a novel global surrogate loss which can be implemented in a general DFL paradigm. ICLN learns task loss via Input Convex Neural Networks which is guaranteed to be convex for some in
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#24314;&#27169;&#20113;&#31995;&#32479;&#20013;&#30340;&#35775;&#38382;&#25511;&#21046;&#31574;&#30053;&#65292;&#24182;&#24320;&#21457;&#20102;&#22522;&#20110;PDDL&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#26469;&#26816;&#27979;&#21487;&#33021;&#23548;&#33268;&#35832;&#22914;&#21202;&#32034;&#36719;&#20214;&#21644;&#25935;&#24863;&#25968;&#25454;&#22806;&#27844;&#31561;&#24191;&#27867;&#25915;&#20987;&#30340;&#23433;&#20840;&#28431;&#27934;&#12290;</title><link>https://arxiv.org/abs/2402.10985</link><description>&lt;p&gt;
&#21033;&#29992;AI&#35268;&#21010;&#25216;&#26415;&#26816;&#27979;&#20113;&#23433;&#20840;&#28431;&#27934;
&lt;/p&gt;
&lt;p&gt;
Leveraging AI Planning For Detecting Cloud Security Vulnerabilities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10985
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#24314;&#27169;&#20113;&#31995;&#32479;&#20013;&#30340;&#35775;&#38382;&#25511;&#21046;&#31574;&#30053;&#65292;&#24182;&#24320;&#21457;&#20102;&#22522;&#20110;PDDL&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#26469;&#26816;&#27979;&#21487;&#33021;&#23548;&#33268;&#35832;&#22914;&#21202;&#32034;&#36719;&#20214;&#21644;&#25935;&#24863;&#25968;&#25454;&#22806;&#27844;&#31561;&#24191;&#27867;&#25915;&#20987;&#30340;&#23433;&#20840;&#28431;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20113;&#35745;&#31639;&#26381;&#21153;&#25552;&#20379;&#20102;&#21487;&#25193;&#23637;&#19988;&#20855;&#26377;&#25104;&#26412;&#25928;&#30410;&#30340;&#25968;&#25454;&#23384;&#20648;&#12289;&#22788;&#29702;&#21644;&#21327;&#20316;&#35299;&#20915;&#26041;&#26696;&#12290;&#38543;&#30528;&#23427;&#20204;&#30340;&#26222;&#21450;&#65292;&#19982;&#20854;&#23433;&#20840;&#28431;&#27934;&#30456;&#20851;&#30340;&#25285;&#24551;&#20063;&#22312;&#22686;&#38271;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#25968;&#25454;&#27844;&#38706;&#21644;&#21202;&#32034;&#36719;&#20214;&#31561;&#22797;&#26434;&#25915;&#20987;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#34920;&#36798;&#20113;&#31995;&#32479;&#20013;&#19981;&#21516;&#23545;&#35937;&#65288;&#22914;&#29992;&#25143;&#12289;&#25968;&#25454;&#23384;&#20648;&#12289;&#23433;&#20840;&#35282;&#33394;&#65289;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#24314;&#27169;&#20113;&#31995;&#32479;&#20013;&#30340;&#35775;&#38382;&#25511;&#21046;&#31574;&#30053;&#12290;&#35775;&#38382;&#25511;&#21046;&#35823;&#37197;&#32622;&#36890;&#24120;&#26159;&#20113;&#25915;&#20987;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;PDDL&#27169;&#22411;&#65292;&#29992;&#20110;&#26816;&#27979;&#23433;&#20840;&#28431;&#27934;&#65292;&#20363;&#22914;&#21487;&#33021;&#23548;&#33268;&#24191;&#27867;&#25915;&#20987;&#65288;&#22914;&#21202;&#32034;&#36719;&#20214;&#65289;&#21644;&#25935;&#24863;&#25968;&#25454;&#22806;&#27844;&#31561;&#12290;&#35268;&#21010;&#22120;&#21487;&#20197;&#29983;&#25104;&#25915;&#20987;&#20197;&#35782;&#21035;&#20113;&#20013;&#30340;&#27492;&#31867;&#28431;&#27934;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;14&#20010;&#19981;&#21516;&#21830;&#19994;&#32452;&#32455;&#30340;&#30495;&#23454;&#20122;&#39532;&#36874;AWS&#20113;&#37197;&#32622;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10985v1 Announce Type: cross  Abstract: Cloud computing services provide scalable and cost-effective solutions for data storage, processing, and collaboration. Alongside their growing popularity, concerns related to their security vulnerabilities leading to data breaches and sophisticated attacks such as ransomware are growing. To address these, first, we propose a generic framework to express relations between different cloud objects such as users, datastores, security roles, to model access control policies in cloud systems. Access control misconfigurations are often the primary driver for cloud attacks. Second, we develop a PDDL model for detecting security vulnerabilities which can for example lead to widespread attacks such as ransomware, sensitive data exfiltration among others. A planner can then generate attacks to identify such vulnerabilities in the cloud. Finally, we test our approach on 14 real Amazon AWS cloud configurations of different commercial organizations
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#36890;&#36807;&#21160;&#24577;&#23398;&#20064;&#22120;&#36861;&#36394;&#27010;&#29575;&#21464;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36755;&#20986;&#20505;&#36873;&#39033;&#30446;&#21450;&#20854;&#27010;&#29575;&#26469;&#39044;&#27979;&#31163;&#25955;&#39033;&#30446;&#24207;&#21015;&#20013;&#19979;&#19968;&#20010;&#21487;&#33021;&#20986;&#29616;&#30340;&#39033;&#30446;&#12290;</title><link>https://arxiv.org/abs/2402.10142</link><description>&lt;p&gt;
&#36890;&#36807;&#21160;&#24577;&#23398;&#20064;&#22120;&#36861;&#36394;&#27010;&#29575;&#21464;&#21270;
&lt;/p&gt;
&lt;p&gt;
Tracking Changing Probabilities via Dynamic Learners
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10142
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#36890;&#36807;&#21160;&#24577;&#23398;&#20064;&#22120;&#36861;&#36394;&#27010;&#29575;&#21464;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36755;&#20986;&#20505;&#36873;&#39033;&#30446;&#21450;&#20854;&#27010;&#29575;&#26469;&#39044;&#27979;&#31163;&#25955;&#39033;&#30446;&#24207;&#21015;&#20013;&#19979;&#19968;&#20010;&#21487;&#33021;&#20986;&#29616;&#30340;&#39033;&#30446;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#19968;&#20010;&#39044;&#27979;&#22120;&#65292;&#21363;&#19968;&#20010;&#23398;&#20064;&#22120;&#65292;&#20854;&#36755;&#20837;&#26159;&#19968;&#31995;&#21015;&#31163;&#25955;&#39033;&#30446;&#12290;&#39044;&#27979;&#22120;&#30340;&#20219;&#21153;&#26159;&#22312;&#27599;&#20010;&#26102;&#38388;&#28857;&#36827;&#34892;&#27010;&#29575;&#22810;&#31867;&#21035;&#39044;&#27979;&#65292;&#21363;&#36890;&#36807;&#36755;&#20986;&#26377;&#38646;&#20010;&#25110;&#22810;&#20010;&#20505;&#36873;&#39033;&#30446;&#21450;&#20854;&#27010;&#29575;&#26469;&#39044;&#27979;&#25509;&#19979;&#26469;&#21487;&#33021;&#21457;&#29983;&#30340;&#39033;&#30446;&#65292;&#28982;&#21518;&#25581;&#31034;&#23454;&#38469;&#39033;&#30446;&#24182;&#20174;&#20013;&#23398;&#20064;&#12290;&#20026;&#20102;&#36755;&#20986;&#27010;&#29575;&#65292;&#39044;&#27979;&#22120;&#20250;&#36319;&#36394;&#20854;&#25152;&#35265;&#39033;&#30446;&#30340;&#27604;&#20363;&#12290;&#39044;&#27979;&#22120;&#20855;&#26377;&#24658;&#23450;&#65288;&#26377;&#38480;&#65289;&#30340;&#31354;&#38388;&#65292;&#25105;&#20204;&#23547;&#27714;&#39640;&#25928;&#30340;&#39044;&#27979;&#21644;&#26356;&#26032;&#25216;&#26415;&#65306;&#27969;&#26159;&#26080;&#30028;&#30340;&#65292;&#39033;&#30446;&#30340;&#38598;&#21512;&#23545;&#39044;&#27979;&#22120;&#26159;&#26410;&#30693;&#30340;&#65292;&#23427;&#20204;&#30340;&#24635;&#25968;&#20063;&#21487;&#33021;&#26080;&#38480;&#22686;&#38271;&#12290;&#27492;&#22806;&#65292;&#23384;&#22312;&#38750;&#24179;&#31283;&#24615;&#65306;&#39033;&#30446;&#30340;&#28508;&#22312;&#39057;&#29575;&#21487;&#33021;&#20250;&#19981;&#26102;&#21457;&#29983;&#26174;&#33879;&#21464;&#21270;&#12290;&#20363;&#22914;&#65292;&#26032;&#39033;&#30446;&#21487;&#33021;&#24320;&#22987;&#20986;&#29616;&#65292;&#19968;&#20123;&#24403;&#21069;&#39057;&#32321;&#20986;&#29616;&#30340;&#39033;&#30446;&#21487;&#33021;&#20877;&#27425;&#20572;&#27490;&#20986;&#29616;&#12290;&#30001;&#20110;&#26377;&#31354;&#38388;&#38480;&#21046;&#65292;&#39044;&#27979;&#22120;&#21482;&#38656;&#35201;&#25552;&#20379;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10142v1 Announce Type: cross  Abstract: Consider a predictor, a learner, whose input is a stream of discrete items. The predictor's task, at every time point, is probabilistic multiclass prediction, i.e., to predict which item may occur next by outputting zero or more candidate items, each with a probability, after which the actual item is revealed and the predictor learns from this observation. To output probabilities, the predictor keeps track of the proportions of the items it has seen. The predictor has constant (limited) space and we seek efficient prediction and update techniques: The stream is unbounded, the set of items is unknown to the predictor and their totality can also grow unbounded. Moreover, there is non-stationarity: the underlying frequencies of items may change, substantially, from time to time. For instance, new items may start appearing and a few currently frequent items may cease to occur again. The predictor, being space-bounded, need only provide pro
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#26435;&#34913;&#22788;&#29702;&#20154;&#24037;&#26234;&#33021;&#20262;&#29702;&#20013;&#30340;&#32039;&#24352;&#20851;&#31995;&#30340;&#20116;&#31181;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23454;&#26045;&#20840;&#38754;&#30340;&#20154;&#24037;&#26234;&#33021;/&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#12290;</title><link>https://arxiv.org/abs/2401.08103</link><description>&lt;p&gt;
&#35299;&#20915;&#22312;&#23454;&#26045;&#36127;&#36131;&#20219;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#20262;&#29702;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Resolving Ethics Trade-offs in Implementing Responsible AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.08103
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#26435;&#34913;&#22788;&#29702;&#20154;&#24037;&#26234;&#33021;&#20262;&#29702;&#20013;&#30340;&#32039;&#24352;&#20851;&#31995;&#30340;&#20116;&#31181;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23454;&#26045;&#20840;&#38754;&#30340;&#20154;&#24037;&#26234;&#33021;/&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#25226;&#39640;&#32423;&#20154;&#24037;&#26234;&#33021;&#20262;&#29702;&#21407;&#21017;&#24212;&#29992;&#21040;&#23454;&#38469;&#30340;&#20154;&#24037;&#26234;&#33021;/&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#24050;&#32463;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#22312;&#22788;&#29702;&#24213;&#23618;&#20154;&#24037;&#26234;&#33021;&#20262;&#29702;&#26041;&#38754;&#30340;&#32039;&#24352;&#20851;&#31995;&#26041;&#38754;&#20173;&#23384;&#22312;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20116;&#31181;&#22788;&#29702;&#36825;&#20123;&#20851;&#31995;&#30340;&#26041;&#27861;&#65292;&#20174;&#31616;&#21333;&#21040;&#22797;&#26434;&#19981;&#31561;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#32771;&#34385;&#30340;&#19978;&#19979;&#25991;&#31867;&#22411;&#12289;&#33539;&#22260;&#12289;&#34913;&#37327;&#19978;&#19979;&#25991;&#30340;&#26041;&#27861;&#21644;&#35777;&#26126;&#31243;&#24230;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;&#36825;&#20123;&#26041;&#27861;&#20013;&#27809;&#26377;&#19968;&#31181;&#36866;&#29992;&#20110;&#25152;&#26377;&#32452;&#32455;&#12289;&#31995;&#32479;&#25110;&#24212;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21253;&#25324;&#65306;&#65288;i&#65289;&#31215;&#26497;&#35782;&#21035;&#32039;&#24352;&#20851;&#31995;&#65292;&#65288;ii&#65289;&#20248;&#20808;&#22788;&#29702;&#21644;&#26435;&#34913;&#20262;&#29702;&#26041;&#38754;&#65292;&#65288;iii&#65289;&#35777;&#26126;&#21644;&#35760;&#24405;&#26435;&#34913;&#20915;&#31574;&#12290;&#35813;&#25552;&#35758;&#30340;&#26694;&#26550;&#26088;&#22312;&#20419;&#36827;&#23454;&#26045;&#31526;&#21512;&#28508;&#22312;&#30417;&#31649;&#35201;&#27714;&#30340;&#20840;&#38754;&#20154;&#24037;&#26234;&#33021;/&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
While the operationalisation of high-level AI ethics principles into practical AI/ML systems has made progress, there is still a theory-practice gap in managing tensions between the underlying AI ethics aspects. We cover five approaches for addressing the tensions via trade-offs, ranging from rudimentary to complex. The approaches differ in the types of considered context, scope, methods for measuring contexts, and degree of justification. None of the approaches is likely to be appropriate for all organisations, systems, or applications. To address this, we propose a framework which consists of: (i) proactive identification of tensions, (ii) prioritisation and weighting of ethics aspects, (iii) justification and documentation of trade-off decisions. The proposed framework aims to facilitate the implementation of well-rounded AI/ML systems that are appropriate for potential regulatory requirements.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#34920;&#31034;&#24037;&#31243;&#23545;LLMs&#36827;&#34892;&#36234;&#29425;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#23569;&#37327;&#26597;&#35810;&#23545;&#25552;&#21462;&#8220;&#23433;&#20840;&#27169;&#24335;&#8221;&#65292;&#25104;&#21151;&#35268;&#36991;&#30446;&#26631;&#27169;&#22411;&#30340;&#38450;&#24481;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36234;&#29425;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.06824</link><description>&lt;p&gt;
&#25171;&#24320;LLMs&#30340;&#28504;&#22810;&#25289;&#39764;&#30418;&#65306;&#36890;&#36807;&#34920;&#31034;&#24037;&#31243;&#23545;LLMs&#36827;&#34892;&#36234;&#29425;
&lt;/p&gt;
&lt;p&gt;
Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.06824
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#34920;&#31034;&#24037;&#31243;&#23545;LLMs&#36827;&#34892;&#36234;&#29425;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#23569;&#37327;&#26597;&#35810;&#23545;&#25552;&#21462;&#8220;&#23433;&#20840;&#27169;&#24335;&#8221;&#65292;&#25104;&#21151;&#35268;&#36991;&#30446;&#26631;&#27169;&#22411;&#30340;&#38450;&#24481;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36234;&#29425;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#29425;&#25216;&#26415;&#26088;&#22312;&#36890;&#36807;&#35825;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#23545;&#24694;&#24847;&#26597;&#35810;&#20135;&#29983;&#26377;&#27602;&#21709;&#24212;&#65292;&#26469;&#25506;&#32034;LLMs&#23433;&#20840;&#24615;&#36793;&#30028;&#65292;&#36825;&#22312;LLMs&#31038;&#21306;&#20869;&#26159;&#19968;&#20010;&#37325;&#35201;&#20851;&#27880;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;&#36890;&#36807;&#34920;&#31034;&#24037;&#31243;&#23545;LLMs&#36827;&#34892;&#36234;&#29425;&#65288;Jailbreaking LLMs through Representation Engineering&#65292;JRE&#65289;&#30340;&#26032;&#39062;&#36234;&#29425;&#26041;&#27861;&#65292;&#20854;&#20165;&#38656;&#35201;&#23569;&#37327;&#26597;&#35810;&#23545;&#20197;&#25552;&#21462;&#21487;&#29992;&#20110;&#35268;&#36991;&#30446;&#26631;&#27169;&#22411;&#38450;&#24481;&#30340;&#8220;&#23433;&#20840;&#27169;&#24335;&#8221;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36234;&#29425;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.06824v2 Announce Type: replace-cross  Abstract: Jailbreaking techniques aim to probe the boundaries of safety in large language models (LLMs) by inducing them to generate toxic responses to malicious queries, a significant concern within the LLM community. While existing jailbreaking methods primarily rely on prompt engineering, altering inputs to evade LLM safety mechanisms, they suffer from low attack success rates and significant time overheads, rendering them inflexible. To overcome these limitations, we propose a novel jailbreaking approach, named Jailbreaking LLMs through Representation Engineering (JRE). Our method requires only a small number of query pairs to extract ``safety patterns'' that can be used to circumvent the target model's defenses, achieving unprecedented jailbreaking performance. Building upon these findings, we also introduce a novel defense framework inspired by JRE principles, which demonstrates notable effectiveness. Extensive experimentation conf
&lt;/p&gt;</description></item><item><title>AgentBoard&#26159;&#19968;&#20010;&#32508;&#21512;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#35780;&#20272;&#26694;&#26550;&#65292;&#19987;&#20026;&#20998;&#26512;&#35780;&#20272;LLM&#26234;&#33021;&#20307;&#32780;&#35774;&#35745;&#65292;&#35299;&#20915;&#20102;&#22312;&#22810;&#36718;&#20132;&#20114;&#21644;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#20013;&#23545;&#26234;&#33021;&#20307;&#24615;&#33021;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#32454;&#31890;&#24230;&#30340;&#36827;&#23637;&#29575;&#25351;&#26631;&#21644;&#35780;&#20272;&#24037;&#20855;&#21253;&#12290;</title><link>http://arxiv.org/abs/2401.13178</link><description>&lt;p&gt;
AgentBoard: &#19968;&#31181;&#22810;&#36718;LLM&#26234;&#33021;&#20307;&#30340;&#20998;&#26512;&#35780;&#20272;&#26495;
&lt;/p&gt;
&lt;p&gt;
AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents. (arXiv:2401.13178v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13178
&lt;/p&gt;
&lt;p&gt;
AgentBoard&#26159;&#19968;&#20010;&#32508;&#21512;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#35780;&#20272;&#26694;&#26550;&#65292;&#19987;&#20026;&#20998;&#26512;&#35780;&#20272;LLM&#26234;&#33021;&#20307;&#32780;&#35774;&#35745;&#65292;&#35299;&#20915;&#20102;&#22312;&#22810;&#36718;&#20132;&#20114;&#21644;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#20013;&#23545;&#26234;&#33021;&#20307;&#24615;&#33021;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#32454;&#31890;&#24230;&#30340;&#36827;&#23637;&#29575;&#25351;&#26631;&#21644;&#35780;&#20272;&#24037;&#20855;&#21253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20316;&#20026;&#36890;&#29992;&#26234;&#33021;&#20307;&#23545;&#20110;&#29702;&#35299;&#20854;&#33021;&#21147;&#24182;&#20419;&#36827;&#20854;&#34701;&#20837;&#23454;&#38469;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#35780;&#20272;&#36807;&#31243;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#20027;&#35201;&#38556;&#30861;&#20043;&#19968;&#26159;&#22312;&#32479;&#19968;&#26694;&#26550;&#20869;&#23545;&#26234;&#33021;&#20307;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#24615;&#33021;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#29305;&#21035;&#26159;&#22312;&#32500;&#25252;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#21644;&#30830;&#20445;&#22810;&#36718;&#20132;&#20114;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#30340;&#35780;&#20272;&#26694;&#26550;&#20027;&#35201;&#20851;&#27880;&#26368;&#32456;&#25104;&#21151;&#29575;&#65292;&#36807;&#31243;&#20013;&#25552;&#20379;&#30340;&#35265;&#35299;&#24456;&#23569;&#65292;&#26080;&#27861;&#28145;&#20837;&#29702;&#35299;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;AgentBoard&#65292;&#36825;&#26159;&#19968;&#20010;&#21019;&#26032;&#30340;&#32508;&#21512;&#22522;&#20934;&#21644;&#20276;&#38543;&#30340;&#24320;&#28304;&#35780;&#20272;&#26694;&#26550;&#65292;&#19987;&#20026;LLM&#26234;&#33021;&#20307;&#30340;&#20998;&#26512;&#35780;&#20272;&#32780;&#35774;&#35745;&#12290;AgentBoard&#25552;&#20379;&#20102;&#19968;&#31181;&#32454;&#31890;&#24230;&#30340;&#36827;&#23637;&#29575;&#25351;&#26631;&#65292;&#25429;&#25417;&#36880;&#27493;&#30340;&#36827;&#23637;&#65292;&#20197;&#21450;&#19968;&#20010;&#32508;&#21512;&#30340;&#35780;&#20272;&#24037;&#20855;&#21253;&#65292;&#20855;&#26377;&#26131;&#20110;&#35780;&#20272;&#21644;&#20998;&#26512;&#27169;&#22411;&#33021;&#21147;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assess
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#19994;&#21153;&#27969;&#31243;&#35299;&#37322;&#30340;SAX4BPM&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#38598;&#25104;&#26469;&#32508;&#21512;&#21508;&#31181;&#36755;&#20837;&#35201;&#32032;&#65292;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#24773;&#22659;&#24863;&#30693;&#35299;&#37322;&#65288;SAX&#65289;&#12290;</title><link>http://arxiv.org/abs/2401.12846</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22914;&#20309;&#35299;&#37322;&#19994;&#21153;&#27969;&#31243;&#65311;
&lt;/p&gt;
&lt;p&gt;
How well can large language models explain business processes?. (arXiv:2401.12846v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12846
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#19994;&#21153;&#27969;&#31243;&#35299;&#37322;&#30340;SAX4BPM&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#38598;&#25104;&#26469;&#32508;&#21512;&#21508;&#31181;&#36755;&#20837;&#35201;&#32032;&#65292;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#24773;&#22659;&#24863;&#30693;&#35299;&#37322;&#65288;SAX&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21487;&#33021;&#22312;&#26410;&#26469;&#30340;AI&#36741;&#21161;&#19994;&#21153;&#27969;&#31243;&#31649;&#29702;&#31995;&#32479;&#65288;ABPMSs&#65289;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#20854;&#21151;&#33021;&#28085;&#30422;&#31995;&#32479;&#29983;&#21629;&#21608;&#26399;&#30340;&#21508;&#20010;&#38454;&#27573;&#12290;&#20854;&#20013;&#19968;&#20010;&#31995;&#32479;&#21151;&#33021;&#26159;&#24773;&#22659;&#24863;&#30693;&#35299;&#37322;&#65288;SAX&#65289;&#65292;&#23427;&#28041;&#21450;&#29983;&#25104;&#22312;&#32771;&#34385;&#25152;&#35299;&#37322;&#26465;&#20214;&#20986;&#29616;&#30340;&#27969;&#31243;&#19978;&#19979;&#25991;&#30340;&#21069;&#25552;&#19979;&#26082;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#21448;&#21487;&#20154;&#31867;&#35299;&#35835;&#30340;&#35299;&#37322;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24320;&#21457;&#29992;&#20110;&#29983;&#25104;SAX&#35299;&#37322;&#30340;SAX4BPM&#26694;&#26550;&#12290;SAX4BPM&#22871;&#20214;&#21253;&#25324;&#19968;&#32452;&#26381;&#21153;&#21644;&#19968;&#20010;&#20013;&#22830;&#30693;&#35782;&#24211;&#12290;&#36825;&#20123;&#26381;&#21153;&#30340;&#21151;&#33021;&#26159;&#33719;&#21462;&#26500;&#25104;SAX&#35299;&#37322;&#30340;&#21508;&#31181;&#30693;&#35782;&#35201;&#32032;&#12290;&#20854;&#20013;&#19968;&#20010;&#21019;&#26032;&#24615;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#26159;&#22240;&#26524;&#36807;&#31243;&#25191;&#34892;&#35270;&#22270;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#19982;LLM&#38598;&#25104;&#65292;&#20197;&#21033;&#29992;&#20854;&#32508;&#21512;&#21508;&#31181;&#36755;&#20837;&#35201;&#32032;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#36827;SAX&#35299;&#37322;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are likely to play a prominent role in future AI-augmented business process management systems (ABPMSs) catering functionalities across all system lifecycle stages. One such system's functionality is Situation-Aware eXplainability (SAX), which relates to generating causally sound and yet human-interpretable explanations that take into account the process context in which the explained condition occurred. In this paper, we present the SAX4BPM framework developed to generate SAX explanations. The SAX4BPM suite consists of a set of services and a central knowledge repository. The functionality of these services is to elicit the various knowledge ingredients that underlie SAX explanations. A key innovative component among these ingredients is the causal process execution view. In this work, we integrate the framework with an LLM to leverage its power to synthesize the various input ingredients for the sake of improved SAX explanations. Since the use of LLMs for
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20013;&#22686;&#24378;&#26041;&#27861;&#21644;&#19979;&#28216;&#24615;&#33021;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20027;&#35201;&#36890;&#36807;&#20998;&#31163;&#19981;&#21516;&#31867;&#21035;&#30340;&#33410;&#28857;&#26469;&#20026;&#19979;&#28216;&#20219;&#21153;&#20570;&#20986;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2310.03977</link><description>&lt;p&gt;
&#23436;&#32654;&#23545;&#40784;&#21487;&#33021;&#23545;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Perfect Alignment May be Poisonous to Graph Contrastive Learning. (arXiv:2310.03977v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03977
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20013;&#22686;&#24378;&#26041;&#27861;&#21644;&#19979;&#28216;&#24615;&#33021;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20027;&#35201;&#36890;&#36807;&#20998;&#31163;&#19981;&#21516;&#31867;&#21035;&#30340;&#33410;&#28857;&#26469;&#20026;&#19979;&#28216;&#20219;&#21153;&#20570;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#23545;&#40784;&#27491;&#26679;&#26412;&#21644;&#20998;&#31163;&#36127;&#26679;&#26412;&#26469;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#22312;&#22522;&#20110;&#22270;&#24418;&#30340;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#29305;&#23450;&#22686;&#24378;&#26041;&#27861;&#32972;&#21518;&#30340;&#20869;&#22312;&#35268;&#24459;&#30340;&#30740;&#31350;&#26377;&#38480;&#12290;&#20160;&#20040;&#26679;&#30340;&#22686;&#24378;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#19979;&#28216;&#24615;&#33021;&#65311;&#23545;&#27604;&#23398;&#20064;&#22914;&#20309;&#23454;&#38469;&#24433;&#21709;&#19979;&#28216;&#20219;&#21153;&#65311;&#20026;&#20160;&#20040;&#22686;&#24378;&#30340;&#24133;&#24230;&#24456;&#37325;&#35201;&#65311;&#26412;&#25991;&#35797;&#22270;&#36890;&#36807;&#24314;&#31435;&#22686;&#24378;&#26041;&#27861;&#21644;&#19979;&#28216;&#24615;&#33021;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20197;&#21450;&#23545;&#23545;&#27604;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#36827;&#34892;&#30740;&#31350;&#26469;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#22270;&#24418;&#23545;&#27604;&#23398;&#20064;&#20027;&#35201;&#36890;&#36807;&#20998;&#31163;&#19981;&#21516;&#31867;&#21035;&#32780;&#19981;&#26159;&#32858;&#38598;&#21516;&#19968;&#31867;&#21035;&#30340;&#33410;&#28857;&#26469;&#20026;&#19979;&#28216;&#20219;&#21153;&#20570;&#20986;&#36129;&#29486;&#12290;&#22240;&#27492;&#65292;&#26080;&#27861;&#35299;&#37322;&#23545;&#27604;&#23398;&#20064;&#30340;&#25104;&#21151;&#65292;&#21363;&#20840;&#37096;&#26679;&#26412;&#23436;&#32654;&#23545;&#40784;&#21644;&#22686;&#24378;&#37325;&#21472;&#12290;&#20026;&#20102;&#29702;&#35299;&#22686;&#24378;&#22914;&#20309;&#36741;&#21161;&#23545;&#27604;&#23398;&#20064;&#36807;&#31243;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Contrastive Learning (GCL) aims to learn node representations by aligning positive pairs and separating negative ones. However, limited research has been conducted on the inner law behind specific augmentations used in graph-based learning. What kind of augmentation will help downstream performance, how does contrastive learning actually influence downstream tasks, and why the magnitude of augmentation matters? This paper seeks to address these questions by establishing a connection between augmentation and downstream performance, as well as by investigating the generalization of contrastive learning. Our findings reveal that GCL contributes to downstream tasks mainly by separating different classes rather than gathering nodes of the same class. So perfect alignment and augmentation overlap which draw all intra-class samples the same can not explain the success of contrastive learning. Then in order to comprehend how augmentation aids the contrastive learning process, we conduct 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#32858;&#31867;&#30340;&#22270;&#20687;-&#25991;&#26412;&#22270;&#21305;&#37197;&#26469;&#24357;&#21512;&#39046;&#22495;&#24046;&#36317;&#65292;&#23398;&#20064;&#39046;&#22495;&#19981;&#21464;&#29305;&#24449;&#20197;&#23454;&#29616;&#22312;&#26410;&#35265;&#36807;&#39046;&#22495;&#19978;&#30340;&#33391;&#22909;&#27867;&#21270;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.02692</link><description>&lt;p&gt;
&#22522;&#20110;&#32858;&#31867;&#30340;&#22270;&#20687;-&#25991;&#26412;&#22270;&#21305;&#37197;&#26469;&#24357;&#21512;&#39046;&#22495;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Bridging the Domain Gap by Clustering-based Image-Text Graph Matching. (arXiv:2310.02692v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02692
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#32858;&#31867;&#30340;&#22270;&#20687;-&#25991;&#26412;&#22270;&#21305;&#37197;&#26469;&#24357;&#21512;&#39046;&#22495;&#24046;&#36317;&#65292;&#23398;&#20064;&#39046;&#22495;&#19981;&#21464;&#29305;&#24449;&#20197;&#23454;&#29616;&#22312;&#26410;&#35265;&#36807;&#39046;&#22495;&#19978;&#30340;&#33391;&#22909;&#27867;&#21270;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#39046;&#22495;&#19981;&#21464;&#34920;&#31034;&#23545;&#20110;&#35757;&#32451;&#21487;&#20197;&#24456;&#22909;&#22320;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30446;&#26631;&#20219;&#21153;&#39046;&#22495;&#30340;&#27169;&#22411;&#38750;&#24120;&#37325;&#35201;&#12290;&#25991;&#26412;&#25551;&#36848;&#26412;&#36523;&#21253;&#21547;&#27010;&#24565;&#30340;&#35821;&#20041;&#32467;&#26500;&#65292;&#36825;&#26679;&#30340;&#36741;&#21161;&#35821;&#20041;&#32447;&#32034;&#21487;&#20197;&#29992;&#20316;&#39046;&#22495;&#27010;&#25324;&#38382;&#39064;&#30340;&#26377;&#25928;&#26530;&#32445;&#23884;&#20837;&#12290;&#25105;&#20204;&#20351;&#29992;&#22810;&#27169;&#24577;&#22270;&#20687;&#21644;&#25991;&#26412;&#34701;&#21512;&#30340;&#22270;&#34920;&#31034;&#26469;&#33719;&#24471;&#22312;&#23616;&#37096;&#22270;&#20687;&#21644;&#25991;&#26412;&#25551;&#36848;&#31526;&#20043;&#38388;&#32771;&#34385;&#20869;&#22312;&#35821;&#20041;&#32467;&#26500;&#30340;&#39046;&#22495;&#19981;&#21464;&#26530;&#32445;&#23884;&#20837;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;(i)&#29992;&#22270;&#34920;&#31034;&#22270;&#20687;&#21644;&#25991;&#26412;&#25551;&#36848;&#65292;&#20197;&#21450;(ii)&#23558;&#22522;&#20110;&#22270;&#20687;&#33410;&#28857;&#29305;&#24449;&#30340;&#32858;&#31867;&#21644;&#21305;&#37197;&#24212;&#29992;&#21040;&#25991;&#26412;&#22270;&#20013;&#65292;&#26469;&#23398;&#20064;&#39046;&#22495;&#19981;&#21464;&#29305;&#24449;&#12290;&#25105;&#20204;&#20351;&#29992;&#22823;&#35268;&#27169;&#20844;&#20849;&#25968;&#25454;&#38598;&#65288;&#22914;CUB-DG&#21644;DomainBed&#65289;&#36827;&#34892;&#23454;&#39564;&#65292;&#24182;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#19982;&#25110;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#23558;&#22312;&#20986;&#29256;&#21518;&#20844;&#24320;&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning domain-invariant representations is important to train a model that can generalize well to unseen target task domains. Text descriptions inherently contain semantic structures of concepts and such auxiliary semantic cues can be used as effective pivot embedding for domain generalization problems. Here, we use multimodal graph representations, fusing images and text, to get domain-invariant pivot embeddings by considering the inherent semantic structure between local images and text descriptors. Specifically, we aim to learn domain-invariant features by (i) representing the image and text descriptions with graphs, and by (ii) clustering and matching the graph-based image node features into textual graphs simultaneously. We experiment with large-scale public datasets, such as CUB-DG and DomainBed, and our model achieves matched or better state-of-the-art performance on these datasets. Our code will be publicly available upon publication.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#31070;&#32463;&#31526;&#21495;&#32422;&#26463;&#26469;&#35843;&#33410;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#38750;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#19979;&#24378;&#21046;&#25191;&#34892;&#20219;&#24847;&#30340;&#36923;&#36753;&#32422;&#26463;&#65292;&#20174;&#32780;&#33719;&#24471;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#12289;&#26080;&#38656;&#39069;&#22806;&#35757;&#32451;&#30340;&#26465;&#20214;&#37319;&#26679;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.16534</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#31526;&#21495;&#32422;&#26463;&#26469;&#35843;&#33410;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conditioning Score-Based Generative Models by Neuro-Symbolic Constraints. (arXiv:2308.16534v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#31070;&#32463;&#31526;&#21495;&#32422;&#26463;&#26469;&#35843;&#33410;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#38750;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#19979;&#24378;&#21046;&#25191;&#34892;&#20219;&#24847;&#30340;&#36923;&#36753;&#32422;&#26463;&#65292;&#20174;&#32780;&#33719;&#24471;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#12289;&#26080;&#38656;&#39069;&#22806;&#35757;&#32451;&#30340;&#26465;&#20214;&#37319;&#26679;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#21644;&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#26465;&#20214;&#21644;&#38750;&#26465;&#20214;&#29983;&#25104;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#26465;&#20214;&#29983;&#25104;&#22522;&#20110;&#29305;&#23450;&#35757;&#32451;&#30340;&#26465;&#20214;&#27169;&#22411;&#25110;&#20998;&#31867;&#22120;&#25351;&#23548;&#65292;&#36825;&#38656;&#35201;&#35757;&#32451;&#19968;&#20010;&#22122;&#22768;&#20381;&#36182;&#30340;&#20998;&#31867;&#22120;&#65292;&#21363;&#20351;&#23545;&#20110;&#26410;&#25439;&#22351;&#25968;&#25454;&#30340;&#20998;&#31867;&#22120;&#24050;&#32463;&#32473;&#20986;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#38750;&#26465;&#20214;&#35780;&#20998;&#29983;&#25104;&#27169;&#22411;&#20013;&#37319;&#26679;&#65292;&#21487;&#20197;&#24378;&#21046;&#25191;&#34892;&#20219;&#24847;&#30340;&#36923;&#36753;&#32422;&#26463;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#35757;&#32451;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#25805;&#32437;&#23398;&#20064;&#24471;&#21040;&#30340;&#35780;&#20998;&#65292;&#20197;&#20415;&#22312;&#29992;&#25143;&#23450;&#20041;&#30340;&#32422;&#26463;&#26465;&#20214;&#19979;&#20174;&#38750;&#24402;&#19968;&#21270;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#28789;&#27963;&#32780;&#25968;&#20540;&#31283;&#23450;&#30340;&#31070;&#32463;&#31526;&#21495;&#26694;&#26550;&#65292;&#29992;&#20110;&#32534;&#30721;&#36719;&#36923;&#36753;&#32422;&#26463;&#12290;&#23558;&#36825;&#20004;&#20010;&#32452;&#25104;&#37096;&#20998;&#32467;&#21512;&#36215;&#26469;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#20294;&#26159;&#36817;&#20284;&#30340;&#26465;&#20214;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#26377;&#25928;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#26469;&#25913;&#36827;&#36817;&#20284;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based and diffusion models have emerged as effective approaches for both conditional and unconditional generation. Still conditional generation is based on either a specific training of a conditional model or classifier guidance, which requires training a noise-dependent classifier, even when the classifier for uncorrupted data is given. We propose an approach to sample from unconditional score-based generative models enforcing arbitrary logical constraints, without any additional training. Firstly, we show how to manipulate the learned score in order to sample from an un-normalized distribution conditional on a user-defined constraint. Then, we define a flexible and numerically stable neuro-symbolic framework for encoding soft logical constraints. Combining these two ingredients we obtain a general, but approximate, conditional sampling algorithm. We further developed effective heuristics aimed at improving the approximation. Finally, we show the effectiveness of our approach fo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;ChatGPT&#21644;GPT-4&#30340;&#20808;&#21069;&#35780;&#20272;&#36827;&#34892;&#20102;&#32508;&#21512;&#20998;&#26512;&#65292;&#20851;&#27880;&#20854;&#35821;&#35328;&#21644;&#25512;&#29702;&#33021;&#21147;&#12289;&#31185;&#23398;&#30693;&#35782;&#21644;&#20262;&#29702;&#32771;&#34385;&#65292;&#25552;&#20986;&#20102;&#20960;&#20010;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2308.12488</link><description>&lt;p&gt;
GPTEval: &#23545;ChatGPT&#21644;GPT-4&#35780;&#20272;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
GPTEval: A Survey on Assessments of ChatGPT and GPT-4. (arXiv:2308.12488v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;ChatGPT&#21644;GPT-4&#30340;&#20808;&#21069;&#35780;&#20272;&#36827;&#34892;&#20102;&#32508;&#21512;&#20998;&#26512;&#65292;&#20851;&#27880;&#20854;&#35821;&#35328;&#21644;&#25512;&#29702;&#33021;&#21147;&#12289;&#31185;&#23398;&#30693;&#35782;&#21644;&#20262;&#29702;&#32771;&#34385;&#65292;&#25552;&#20986;&#20102;&#20960;&#20010;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#30340;&#20986;&#29616;&#24341;&#21457;&#20102;&#23186;&#20307;&#23545;&#20854;&#25200;&#20081;&#31038;&#20250;&#21644;&#32463;&#27982;&#31995;&#32479;&#28508;&#21147;&#30340;&#35768;&#22810;&#29468;&#27979;&#12290;&#20854;&#24778;&#20154;&#30340;&#35821;&#35328;&#33021;&#21147;&#28608;&#36215;&#23398;&#32773;&#20204;&#23545;&#20854;&#22312;&#19981;&#21516;&#39046;&#22495;&#34920;&#29616;&#30340;&#27987;&#21402;&#20852;&#36259;&#12290;&#24050;&#32463;&#26377;&#35768;&#22810;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#21644;GPT-4&#22312;&#19981;&#21516;&#20219;&#21153;&#21644;&#23398;&#31185;&#20013;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#19968;&#39033;&#32508;&#21512;&#24615;&#30340;&#32508;&#36848;&#24635;&#32467;&#38598;&#20307;&#35780;&#20272;&#32467;&#26524;&#12290;&#26412;&#35843;&#26597;&#30340;&#30446;&#26631;&#26159;&#23545;ChatGPT&#21644;GPT-4&#30340;&#20808;&#21069;&#35780;&#20272;&#36827;&#34892;&#28145;&#20837;&#20998;&#26512;&#65292;&#37325;&#28857;&#20851;&#27880;&#20854;&#35821;&#35328;&#21644;&#25512;&#29702;&#33021;&#21147;&#12289;&#31185;&#23398;&#30693;&#35782;&#21644;&#20262;&#29702;&#32771;&#34385;&#12290;&#27492;&#22806;&#65292;&#23545;&#29616;&#26377;&#35780;&#20272;&#26041;&#27861;&#36827;&#34892;&#20102;&#26816;&#26597;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#20010;&#26410;&#26469;&#30740;&#31350;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.
&lt;/p&gt;</description></item></channel></rss>