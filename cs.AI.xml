<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411; CF-CBMs&#65292;&#21487;&#20197;&#21516;&#26102;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#12289;&#35299;&#37322;&#21644;&#24819;&#35937;&#33021;&#21147;&#30340;&#19981;&#36275;&#65292;&#20026;&#37096;&#32626;&#21487;&#38752;&#30340;AI&#20195;&#29702;&#12289;&#26657;&#20934;&#20154;&#31867;&#20449;&#20219;&#21644;&#21152;&#28145;&#20154;&#26426;&#20132;&#20114;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01408</link><description>&lt;p&gt;
&#36890;&#36807;&#21453;&#20107;&#23454;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#25856;&#30331;&#35299;&#37322;&#24615;&#30340;&#38454;&#26799;
&lt;/p&gt;
&lt;p&gt;
Climbing the Ladder of Interpretability with Counterfactual Concept Bottleneck Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411; CF-CBMs&#65292;&#21487;&#20197;&#21516;&#26102;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#12289;&#35299;&#37322;&#21644;&#24819;&#35937;&#33021;&#21147;&#30340;&#19981;&#36275;&#65292;&#20026;&#37096;&#32626;&#21487;&#38752;&#30340;AI&#20195;&#29702;&#12289;&#26657;&#20934;&#20154;&#31867;&#20449;&#20219;&#21644;&#21152;&#28145;&#20154;&#26426;&#20132;&#20114;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#27809;&#26377;&#21516;&#26102;&#35299;&#20915;&#19977;&#20010;&#22522;&#26412;&#38382;&#39064;&#30340;&#35774;&#35745;&#65306;&#39044;&#27979;&#31867;&#21035;&#26631;&#31614;&#20197;&#35299;&#20915;&#32473;&#23450;&#30340;&#20998;&#31867;&#20219;&#21153;&#65288;&#8220;&#26159;&#20160;&#20040;&#65311;&#8221;&#65289;&#65292;&#35299;&#37322;&#20219;&#21153;&#39044;&#27979;&#65288;&#8220;&#20026;&#20160;&#20040;&#65311;&#8221;&#65289;&#65292;&#24182;&#24819;&#35937;&#21487;&#33021;&#23548;&#33268;&#19981;&#21516;&#39044;&#27979;&#30340;&#26367;&#20195;&#24773;&#26223;&#65288;&#8220;&#22914;&#26524;&#24590;&#26679;&#65311;&#8221;&#65289;&#12290;&#26080;&#27861;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#20195;&#34920;&#20102;&#37096;&#32626;&#21487;&#38752;&#30340;AI&#20195;&#29702;&#12289;&#26657;&#20934;&#20154;&#31867;&#20449;&#20219;&#21644;&#21152;&#28145;&#20154;&#26426;&#20132;&#20114;&#30340;&#20851;&#38190;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CF-CBMs&#65289;&#65292;&#36825;&#26159;&#19968;&#31867;&#33021;&#22815;&#39640;&#25928;&#21516;&#26102;&#35299;&#20915;&#19978;&#36848;&#26597;&#35810;&#32780;&#26080;&#38656;&#36827;&#34892;&#20107;&#21518;&#25628;&#32034;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;CF-CBMs&#33021;&#22815;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#65288;&#8220;&#26159;&#20160;&#20040;&#65311;&#8221;&#65289;&#65292;&#23545;&#20219;&#21153;&#39044;&#27979;&#25552;&#20379;&#31616;&#21333;&#30340;&#35299;&#37322;&#65288;&#8220;&#20026;&#20160;&#20040;&#65311;&#8221;&#65289;&#65292;&#20197;&#21450;&#21487;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#24773;&#20917;&#65288;&#8220;&#22914;&#26524;&#24590;&#26679;&#65311;&#8221;&#65289;&#12290;CF-CBMs&#36824;&#21487;&#20197;&#23545;&#27010;&#24565;&#24178;&#39044;&#30340;&#24433;&#21709;&#36827;&#34892;&#37319;&#26679;&#25110;&#20272;&#35745;&#26368;&#21487;&#33021;&#30340;&#21453;&#20107;&#23454;&#24773;&#20917;&#65292;&#20197;&#35299;&#37322;&#20107;&#20214;&#65292;&#24182;&#20248;&#21270;&#20135;&#29983;&#22810;&#26679;&#21270;&#30340;&#21453;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current deep learning models are not designed to simultaneously address three fundamental questions: predict class labels to solve a given classification task (the "What?"), explain task predictions (the "Why?"), and imagine alternative scenarios that could result in different predictions (the "What if?"). The inability to answer these questions represents a crucial gap in deploying reliable AI agents, calibrating human trust, and deepening human-machine interaction. To bridge this gap, we introduce CounterFactual Concept Bottleneck Models (CF-CBMs), a class of models designed to efficiently address the above queries all at once without the need to run post-hoc searches. Our results show that CF-CBMs produce: accurate predictions (the "What?"), simple explanations for task predictions (the "Why?"), and interpretable counterfactuals (the "What if?"). CF-CBMs can also sample or estimate the most probable counterfactual to: (i) explain the effect of concept interventions on tasks, (ii) sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#21407;&#29702;&#35770;&#25512;&#29702;&#24378;&#24230;&#21464;&#21270;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#20351;&#29992;Problog&#24037;&#20855;&#35745;&#31639;&#25439;&#22833;&#24230;&#37327;&#65292;&#26368;&#32456;&#24471;&#20986;&#20102;&#20851;&#20110;&#19981;&#21516;&#36951;&#24536;&#31574;&#30053;&#24378;&#24230;&#30340;&#30740;&#31350;&#26041;&#27861;&#21644;&#23454;&#38469;&#24212;&#29992;&#31034;&#20363;&#12290;</title><link>https://arxiv.org/abs/2404.02454</link><description>&lt;p&gt;
&#34913;&#37327;&#36951;&#24536;&#31574;&#30053;&#30340;&#25512;&#29702;&#24378;&#24230;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Techniques for Measuring the Inferential Strength of Forgetting Policies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#21407;&#29702;&#35770;&#25512;&#29702;&#24378;&#24230;&#21464;&#21270;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#20351;&#29992;Problog&#24037;&#20855;&#35745;&#31639;&#25439;&#22833;&#24230;&#37327;&#65292;&#26368;&#32456;&#24471;&#20986;&#20102;&#20851;&#20110;&#19981;&#21516;&#36951;&#24536;&#31574;&#30053;&#24378;&#24230;&#30340;&#30740;&#31350;&#26041;&#27861;&#21644;&#23454;&#38469;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#34920;&#31034;&#20013;&#30340;&#36951;&#24536;&#25216;&#26415;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#24378;&#22823;&#19988;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#30693;&#35782;&#24037;&#31243;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#19981;&#21516;&#30340;&#36951;&#24536;&#31574;&#30053;&#25110;&#19981;&#21516;&#36951;&#24536;&#25805;&#20316;&#31526;&#30340;&#20351;&#29992;&#22914;&#20309;&#24433;&#21709;&#21407;&#29702;&#35770;&#30340;&#25512;&#29702;&#24378;&#24230;&#20960;&#20046;&#27809;&#26377;&#30740;&#31350;&#12290;&#26412;&#25991;&#26088;&#22312;&#26681;&#25454;&#27169;&#22411;&#35745;&#25968;&#21644;&#27010;&#29575;&#29702;&#35770;&#30340;&#30452;&#35273;&#23450;&#20041;&#29992;&#20110;&#34913;&#37327;&#25512;&#29702;&#24378;&#24230;&#21464;&#21270;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#30740;&#31350;&#20102;&#27492;&#31867;&#25439;&#22833;&#24230;&#37327;&#30340;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#30693;&#35782;&#24037;&#31243;&#24037;&#20855;&#65292;&#29992;&#20110;&#20351;&#29992;Problog&#35745;&#31639;&#25439;&#22833;&#24230;&#37327;&#12290;&#35770;&#25991;&#21253;&#25324;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#21644;&#30830;&#23450;&#19981;&#21516;&#36951;&#24536;&#31574;&#30053;&#24378;&#24230;&#30340;&#24037;&#20316;&#26041;&#27861;&#65292;&#20197;&#21450;&#23637;&#31034;&#22914;&#20309;&#21033;&#29992;Problog&#24212;&#29992;&#29702;&#35770;&#32467;&#26524;&#30340;&#20855;&#20307;&#31034;&#20363;&#12290;&#34429;&#28982;&#37325;&#28857;&#26159;&#36951;&#24536;&#65292;&#20294;&#32467;&#26524;&#26356;&#20026;&#26222;&#36941;&#65292;&#24182;&#19988;&#24212;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02454v1 Announce Type: new  Abstract: The technique of forgetting in knowledge representation has been shown to be a powerful and useful knowledge engineering tool with widespread application. Yet, very little research has been done on how different policies of forgetting, or use of different forgetting operators, affects the inferential strength of the original theory. The goal of this paper is to define loss functions for measuring changes in inferential strength based on intuitions from model counting and probability theory. Properties of such loss measures are studied and a pragmatic knowledge engineering tool is proposed for computing loss measures using Problog. The paper includes a working methodology for studying and determining the strength of different forgetting policies, in addition to concrete examples showing how to apply the theoretical results using Problog. Although the focus is on forgetting, the results are much more general and should have wider applicati
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#20013;&#24615;&#33021;&#21644;&#21487;&#34892;&#24615;&#21463;&#24433;&#21709;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.17338</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#30340;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning-based Receding Horizon Control using Adaptive Control Barrier Functions for Safety-Critical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17338
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#20013;&#24615;&#33021;&#21644;&#21487;&#34892;&#24615;&#21463;&#24433;&#21709;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#25511;&#21046;&#26041;&#27861;&#20026;&#23433;&#20840;&#20851;&#38190;&#38382;&#39064;&#25552;&#20379;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#24456;&#23481;&#26131;&#21464;&#24471;&#26840;&#25163;&#12290;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;(CBFs)&#20316;&#20026;&#19968;&#31181;&#27969;&#34892;&#25216;&#26415;&#20986;&#29616;&#65292;&#36890;&#36807;&#20854;&#21069;&#21521;&#19981;&#21464;&#24615;&#23646;&#24615;&#65292;&#26377;&#21033;&#20110;&#36890;&#36807;&#22312;&#25439;&#22833;&#19968;&#20123;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#24335;&#22320;&#20445;&#35777;&#23433;&#20840;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#23450;&#20041;&#24615;&#33021;&#30446;&#26631;&#20197;&#21450;&#24517;&#39035;&#22987;&#32456;&#25191;&#34892;&#30340;&#22522;&#20110;CBF&#30340;&#23433;&#20840;&#32422;&#26463;&#12290;&#36951;&#25022;&#30340;&#26159;&#65292;&#20004;&#20010;&#20851;&#38190;&#22240;&#32032;&#21487;&#33021;&#20250;&#23545;&#24615;&#33021;&#21644;&#35299;&#20915;&#26041;&#26696;&#30340;&#21487;&#34892;&#24615;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65306;(i)&#25104;&#26412;&#20989;&#25968;&#21450;&#20854;&#30456;&#20851;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#20197;&#21450;(ii)&#22312;CBF&#32422;&#26463;&#20869;&#36827;&#34892;&#21442;&#25968;&#26657;&#20934;&#65292;&#25429;&#25417;&#24615;&#33021;&#21644;&#20445;&#23432;&#24615;&#20043;&#38388;&#30340;&#25240;&#34935;&#65292;&#20197;&#21450;&#19981;&#21487;&#34892;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#30340;&#24378;&#21270;&#23398;&#20064;(RL)&#28378;&#21160;&#35270;&#37326;&#25511;&#21046;(RHC)&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17338v1 Announce Type: cross  Abstract: Optimal control methods provide solutions to safety-critical problems but easily become intractable. Control Barrier Functions (CBFs) have emerged as a popular technique that facilitates their solution by provably guaranteeing safety, through their forward invariance property, at the expense of some performance loss. This approach involves defining a performance objective alongside CBF-based safety constraints that must always be enforced. Unfortunately, both performance and solution feasibility can be significantly impacted by two key factors: (i) the selection of the cost function and associated parameters, and (ii) the calibration of parameters within the CBF-based constraints, which capture the trade-off between performance and conservativeness. %as well as infeasibility. To address these challenges, we propose a Reinforcement Learning (RL)-based Receding Horizon Control (RHC) approach leveraging Model Predictive Control (MPC) with
&lt;/p&gt;</description></item><item><title>LS&#26041;&#27861;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#35757;&#32451;&#20013;&#30340;&#26631;&#31614;&#24179;&#28369;&#25928;&#26524;&#34987;&#21457;&#29616;&#20250;&#36127;&#38754;&#24433;&#21709;&#36873;&#25321;&#24615;&#20998;&#31867;&#65292;&#36890;&#36807;&#24433;&#21709;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#27492;&#30740;&#31350;&#38416;&#26126;&#20102;&#36825;&#19968;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2403.14715</link><description>&lt;p&gt;
&#29702;&#35299;&#20026;&#20309;&#26631;&#31614;&#24179;&#28369;&#20250;&#38477;&#20302;&#36873;&#25321;&#24615;&#20998;&#31867;&#30340;&#25928;&#26524;&#20197;&#21450;&#22914;&#20309;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Understanding Why Label Smoothing Degrades Selective Classification and How to Fix It
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14715
&lt;/p&gt;
&lt;p&gt;
LS&#26041;&#27861;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#35757;&#32451;&#20013;&#30340;&#26631;&#31614;&#24179;&#28369;&#25928;&#26524;&#34987;&#21457;&#29616;&#20250;&#36127;&#38754;&#24433;&#21709;&#36873;&#25321;&#24615;&#20998;&#31867;&#65292;&#36890;&#36807;&#24433;&#21709;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#27492;&#30740;&#31350;&#38416;&#26126;&#20102;&#36825;&#19968;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#31614;&#24179;&#28369;&#65288;LS&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#35757;&#32451;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22312;&#25552;&#39640;&#27979;&#35797;&#20934;&#30830;&#24615;&#26041;&#38754;&#25928;&#26524;&#26174;&#33879;&#65292;&#24182;&#19988;&#23454;&#29616;&#31616;&#21333;&#12290;"&#30828;"&#30340;one-hot&#26631;&#31614;&#36890;&#36807;&#23558;&#27010;&#29575;&#36136;&#37327;&#22343;&#21248;&#20998;&#37197;&#32473;&#20854;&#20182;&#31867;&#21035;&#26469;&#36827;&#34892;"&#24179;&#28369;&#21270;"&#65292;&#20174;&#32780;&#20943;&#23569;&#36807;&#24230;&#25311;&#21512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;LS&#22914;&#20309;&#36127;&#38754;&#24433;&#21709;&#36873;&#25321;&#24615;&#20998;&#31867;&#65288;SC&#65289;- &#20854;&#30446;&#26631;&#26159;&#21033;&#29992;&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26469;&#25298;&#32477;&#38169;&#35823;&#20998;&#31867;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#31995;&#21015;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#20174;&#32463;&#39564;&#19978;&#35777;&#26126;LS&#20250;&#23548;&#33268;SC&#30340;&#19968;&#33268;&#24615;&#38477;&#32423;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;logit&#32423;&#21035;&#30340;&#26799;&#24230;&#26469;&#35299;&#37322;&#36825;&#19968;&#28857;&#65292;&#34920;&#26126;LS&#36890;&#36807;&#22312;&#38169;&#35823;&#27010;&#29575;&#20302;&#26102;&#26356;&#21152;&#27491;&#21017;&#21270;&#26368;&#22823;logit&#65292;&#32780;&#22312;&#38169;&#35823;&#27010;&#29575;&#39640;&#26102;&#26356;&#23569;&#27491;&#21017;&#21270;&#65292;&#21152;&#21095;&#20102;&#36807;&#24230;&#33258;&#20449;&#21644;&#20302;&#33258;&#20449;&#12290;&#36825;&#38416;&#26126;&#20102;&#20197;&#21069;&#25253;&#36947;&#30340;&#24378;&#20998;&#31867;&#22120;&#22312;SC&#20013;&#24615;&#33021;&#19981;&#20339;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14715v1 Announce Type: cross  Abstract: Label smoothing (LS) is a popular regularisation method for training deep neural network classifiers due to its effectiveness in improving test accuracy and its simplicity in implementation. "Hard" one-hot labels are "smoothed" by uniformly distributing probability mass to other classes, reducing overfitting. In this work, we reveal that LS negatively affects selective classification (SC) - where the aim is to reject misclassifications using a model's predictive uncertainty. We first demonstrate empirically across a range of tasks and architectures that LS leads to a consistent degradation in SC. We then explain this by analysing logit-level gradients, showing that LS exacerbates overconfidence and underconfidence by regularising the max logit more when the probability of error is low, and less when the probability of error is high. This elucidates previously reported experimental results where strong classifiers underperform in SC. We
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#31574;&#30053;&#65292;&#24213;&#29289;&#33539;&#22260;&#23545;&#27604;&#23398;&#20064;&#65292;&#20197;&#23398;&#20064;&#36866;&#21512;&#21270;&#23398;&#21453;&#24212;&#24615;&#30340;&#21407;&#23376;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.16882</link><description>&lt;p&gt;
&#24213;&#29289;&#33539;&#22260;&#23545;&#27604;&#23398;&#20064;&#65306;&#37325;&#26032;&#21033;&#29992;&#20154;&#31867;&#20559;&#35265;&#23398;&#20064;&#21407;&#23376;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Substrate Scope Contrastive Learning: Repurposing Human Bias to Learn Atomic Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16882
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#31574;&#30053;&#65292;&#24213;&#29289;&#33539;&#22260;&#23545;&#27604;&#23398;&#20064;&#65292;&#20197;&#23398;&#20064;&#36866;&#21512;&#21270;&#23398;&#21453;&#24212;&#24615;&#30340;&#21407;&#23376;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#26159;&#20998;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#23545;&#24314;&#27169;&#25104;&#21151;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65292;&#23588;&#20854;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#12290;&#24191;&#20041;&#39044;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#27010;&#24565;&#25512;&#21160;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#34507;&#30333;&#36136;&#24037;&#31243;&#31561;&#39046;&#22495;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#31867;&#20284;&#30340;&#26041;&#27861;&#22312;&#23567;&#26377;&#26426;&#20998;&#23376;&#26041;&#38754;&#24182;&#26410;&#21462;&#24471;&#31867;&#20284;&#30340;&#25104;&#21151;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#31574;&#30053;&#65292;&#21363;&#24213;&#29289;&#33539;&#22260;&#23545;&#27604;&#23398;&#20064;&#65292;&#23427;&#23398;&#20064;&#36866;&#21512;&#21270;&#23398;&#21453;&#24212;&#24615;&#30340;&#21407;&#23376;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#20197;&#24050;&#21457;&#34920;&#30340;&#24213;&#29289;&#33539;&#22260;&#34920;&#20013;&#24213;&#29289;&#30340;&#20998;&#32452;&#21644;&#20135;&#29289;&#25910;&#29575;&#20316;&#20026;&#21270;&#23398;&#21453;&#24212;&#24615;&#30456;&#20284;&#24615;&#25110;&#19981;&#30456;&#20284;&#24615;&#30340;&#34913;&#37327;&#12290;&#25105;&#20204;&#20851;&#27880; CAS Content Collection &#20013;&#30340; 20,798 &#20010;&#33459;&#39321;&#21348;&#20195;&#28867;&#65292;&#28085;&#30422;&#25968;&#21315;&#31687;&#20986;&#29256;&#29289;&#65292;&#20197;&#23398;&#20064;&#33459;&#39321;&#21348;&#20195;&#28867;&#30340;&#21453;&#24212;&#24615;&#34920;&#31034;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16882v1 Announce Type: cross  Abstract: Learning molecular representation is a critical step in molecular machine learning that significantly influences modeling success, particularly in data-scarce situations. The concept of broadly pre-training neural networks has advanced fields such as computer vision, natural language processing, and protein engineering. However, similar approaches for small organic molecules have not achieved comparable success. In this work, we introduce a novel pre-training strategy, substrate scope contrastive learning, which learns atomic representations tailored to chemical reactivity. This method considers the grouping of substrates and their yields in published substrate scope tables as a measure of their similarity or dissimilarity in terms of chemical reactivity. We focus on 20,798 aryl halides in the CAS Content Collection spanning thousands of publications to learn a representation of aryl halide reactivity. We validate our pre-training appr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#36712;&#36857;&#20013;&#23398;&#20064;&#35268;&#21010;&#34892;&#21160;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#23588;&#20854;&#20851;&#27880;&#22312;&#21442;&#25968;&#26410;&#25552;&#20379;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#32423;&#21035;&#30340;&#36319;&#36394;&#36136;&#37327;&#20197;&#21450;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10726</link><description>&lt;p&gt;
&#20174;&#29366;&#24577;&#36712;&#36857;&#20013;&#23398;&#20064;&#35268;&#21010;&#34892;&#21160;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Planning Action Models from State Traces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10726
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#36712;&#36857;&#20013;&#23398;&#20064;&#35268;&#21010;&#34892;&#21160;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#23588;&#20854;&#20851;&#27880;&#22312;&#21442;&#25968;&#26410;&#25552;&#20379;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#32423;&#21035;&#30340;&#36319;&#36394;&#36136;&#37327;&#20197;&#21450;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#20174;&#29366;&#24577;&#36712;&#36857;&#20013;&#23398;&#20064;STRIPS&#39046;&#22495;&#27169;&#22411;&#30340;&#26041;&#27861;&#36890;&#24120;&#20174;&#35201;&#23398;&#20064;&#30340;&#34892;&#21160;&#30340;&#21517;&#31216;&#21644;&#21442;&#25968;&#24320;&#22987;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#30340;&#21807;&#19968;&#20219;&#21153;&#26159;&#25512;&#26029;&#32473;&#23450;&#34892;&#21160;&#30340;&#21069;&#25552;&#26465;&#20214;&#21644;&#25928;&#24212;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#23398;&#20064;&#26102;&#26410;&#25552;&#20379;&#23398;&#20064;&#34892;&#21160;&#30340;&#21442;&#25968;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#26681;&#25454;&#25552;&#20379;&#30340;&#20449;&#24687;&#23450;&#20041;&#20102;&#20004;&#20010;&#32423;&#21035;&#30340;&#36319;&#36394;&#36136;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;&#22312;&#19968;&#20010;&#32423;&#21035;(L1)&#20013;&#65292;&#36712;&#36857;&#20013;&#30340;&#29366;&#24577;&#34987;&#26631;&#35760;&#20026;&#34892;&#21160;&#21517;&#31216;&#65292;&#22240;&#27492;&#25105;&#20204;&#21487;&#20197;&#25512;&#26029;&#20986;&#34892;&#21160;&#30340;&#25968;&#37327;&#21644;&#21517;&#31216;&#65292;&#20294;&#25105;&#20204;&#20173;&#38656;&#35201;&#24324;&#28165;&#21442;&#25968;&#30340;&#25968;&#37327;&#21644;&#31867;&#22411;&#12290;&#22312;&#21478;&#19968;&#20010;&#32423;&#21035;(L2)&#20013;&#65292;&#29366;&#24577;&#36824;&#39069;&#22806;&#26631;&#35760;&#26377;&#26500;&#25104;&#30456;&#24212;&#22522;&#20110;&#23545;&#35937;&#30340;&#34892;&#21160;&#30340;&#21442;&#25968;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20173;&#28982;&#38656;&#35201;&#25512;&#26029;&#23398;&#20064;&#34892;&#21160;&#20013;&#21442;&#25968;&#30340;&#31867;&#22411;&#12290;&#25105;&#20204;&#23545;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#36827;&#34892;&#20102;&#23454;&#39564;&#35780;&#20272;&#65292;&#24182;&#23558;&#20854;&#19982;&#20854;&#20182;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10726v1 Announce Type: new  Abstract: Previous STRIPS domain model acquisition approaches that learn from state traces start with the names and parameters of the actions to be learned. Therefore their only task is to deduce the preconditions and effects of the given actions. In this work, we explore learning in situations when the parameters of learned actions are not provided. We define two levels of trace quality based on which information is provided and present an algorithm for each. In one level (L1), the states in the traces are labeled with action names, so we can deduce the number and names of the actions, but we still need to work out the number and types of parameters. In the other level (L2), the states are additionally labeled with objects that constitute the parameters of the corresponding grounded actions. Here we still need to deduce the types of the parameters in the learned actions. We experimentally evaluate the proposed algorithms and compare them with the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35760;&#24518;&#21270;&#34892;&#20026;&#65292;&#21457;&#29616;&#35760;&#24518;&#21270;&#20542;&#21521;&#20110;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#19978;&#21457;&#29983;&#12290;&#36890;&#36807;&#23450;&#20041;&#26377;&#25928;&#27169;&#22411;&#35760;&#24518;&#21270; (EMM) &#36825;&#19968;&#25351;&#26631;&#65292;&#37327;&#21270;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#37197;&#32622;&#23545;&#35760;&#24518;&#21270;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.02664</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#35760;&#24518;&#21270;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Memorization in Diffusion Models. (arXiv:2310.02664v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35760;&#24518;&#21270;&#34892;&#20026;&#65292;&#21457;&#29616;&#35760;&#24518;&#21270;&#20542;&#21521;&#20110;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#19978;&#21457;&#29983;&#12290;&#36890;&#36807;&#23450;&#20041;&#26377;&#25928;&#27169;&#22411;&#35760;&#24518;&#21270; (EMM) &#36825;&#19968;&#25351;&#26631;&#65292;&#37327;&#21270;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#37197;&#32622;&#23545;&#35760;&#24518;&#21270;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#20854;&#29983;&#25104;&#26032;&#39062;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#33021;&#21147;&#65292;&#25193;&#25955;&#27169;&#22411;&#24341;&#36215;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#20856;&#22411;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#21363;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#65292;&#25193;&#25955;&#27169;&#22411;&#21482;&#33021;&#29983;&#25104;&#22797;&#21046;&#35757;&#32451;&#25968;&#25454;&#30340;&#26679;&#26412;&#65292;&#36825;&#34920;&#26126;&#22312;&#29702;&#35770;&#19978;&#20250;&#20986;&#29616;&#35760;&#24518;&#21270;&#30340;&#34892;&#20026;&#65292;&#36825;&#19982;&#29616;&#26377;&#20808;&#36827;&#25193;&#25955;&#27169;&#22411;&#30340;&#26222;&#36941;&#27867;&#21270;&#33021;&#21147;&#30456;&#30683;&#30462;&#65292;&#22240;&#27492;&#38656;&#35201;&#28145;&#20837;&#29702;&#35299;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#35760;&#24518;&#21270;&#34892;&#20026;&#20542;&#21521;&#20110;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#19978;&#21457;&#29983;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26377;&#25928;&#27169;&#22411;&#35760;&#24518;&#21270;(EMM)&#30340;&#23450;&#20041;&#65292;&#36825;&#26159;&#19968;&#31181;&#34913;&#37327;&#23398;&#20064;&#30340;&#25193;&#25955;&#27169;&#22411;&#22312;&#26368;&#22823;&#25968;&#25454;&#38598;&#19978;&#36817;&#20284;&#20854;&#29702;&#35770;&#26368;&#20248;&#28857;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#24433;&#21709;&#36825;&#20123;&#35760;&#24518;&#21270;&#34892;&#20026;&#30340;&#37325;&#35201;&#22240;&#32032;&#65292;&#37325;&#28857;&#20851;&#27880;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to their capacity to generate novel and high-quality samples, diffusion models have attracted significant research interest in recent years. Notably, the typical training objective of diffusion models, i.e., denoising score matching, has a closed-form optimal solution that can only generate training data replicating samples. This indicates that a memorization behavior is theoretically expected, which contradicts the common generalization ability of state-of-the-art diffusion models, and thus calls for a deeper understanding. Looking into this, we first observe that memorization behaviors tend to occur on smaller-sized datasets, which motivates our definition of effective model memorization (EMM), a metric measuring the maximum size of training data at which a learned diffusion model approximates its theoretical optimum. Then, we quantify the impact of the influential factors on these memorization behaviors in terms of EMM, focusing primarily on data distribution, model configuratio
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#36229;&#36234;&#19968;&#38454;&#36923;&#36753;&#30340;&#25552;&#21319;&#25512;&#29702;&#38382;&#39064;&#65292;&#25193;&#23637;&#20102;&#35745;&#25968;&#37327;&#35789;&#25193;&#23637;&#30340;&#20004;&#20010;&#21464;&#37327;&#30340;&#19968;&#38454;&#36923;&#36753;&#29255;&#27573;&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#65292;&#24182;&#22312;&#38480;&#23450;&#20102;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#20102;&#19981;&#21516;&#23646;&#24615;&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.11738</link><description>&lt;p&gt;
&#36229;&#20986;&#19968;&#38454;&#36923;&#36753;&#30340;&#25552;&#21319;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Lifted Inference beyond First-Order Logic. (arXiv:2308.11738v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11738
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#36229;&#36234;&#19968;&#38454;&#36923;&#36753;&#30340;&#25552;&#21319;&#25512;&#29702;&#38382;&#39064;&#65292;&#25193;&#23637;&#20102;&#35745;&#25968;&#37327;&#35789;&#25193;&#23637;&#30340;&#20004;&#20010;&#21464;&#37327;&#30340;&#19968;&#38454;&#36923;&#36753;&#29255;&#27573;&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#65292;&#24182;&#22312;&#38480;&#23450;&#20102;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#20102;&#19981;&#21516;&#23646;&#24615;&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#20851;&#31995;&#23398;&#20064;&#27169;&#22411;&#20013;&#65292;&#21152;&#26435;&#19968;&#38454;&#27169;&#22411;&#35745;&#25968;(WFOMC)&#26159;&#27010;&#29575;&#25512;&#29702;&#30340;&#22522;&#30784;&#12290;&#30001;&#20110;WFOMC&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#35745;&#31639;&#30340;&#65288;$\#$P&#23436;&#20840;&#65289;&#65292;&#22240;&#27492;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36827;&#34892;WFOMC&#30340;&#36923;&#36753;&#30862;&#29255;&#38750;&#24120;&#26377;&#24847;&#20041;&#12290;&#36825;&#26679;&#30340;&#30862;&#29255;&#34987;&#31216;&#20026;&#22495;&#21487;&#25552;&#21319;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35745;&#25968;&#37327;&#35789;&#65288;$\mathrm{C^2}$&#65289;&#25193;&#23637;&#30340;&#20004;&#20010;&#21464;&#37327;&#30340;&#19968;&#38454;&#36923;&#36753;&#29255;&#27573;&#20013;&#65292;&#21487;&#20197;&#36827;&#34892;&#22495;&#25552;&#21319;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#22914;&#24341;&#29992;&#32593;&#32476;&#20013;&#30340;&#38750;&#24490;&#29615;&#24615;&#21644;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#36830;&#36890;&#24615;&#65292;&#19981;&#33021;&#22312;$\mathrm{C^2}$&#25110;&#19968;&#38454;&#36923;&#36753;&#20013;&#24314;&#27169;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;$\mathrm{C^2}$&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#65292;&#21253;&#25324;&#22810;&#20010;&#36825;&#26679;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23558;$\mathrm{C^2}$&#21477;&#23376;&#30340;&#19968;&#20010;&#20851;&#31995;&#38480;&#23450;&#20026;&#34920;&#31034;&#26377;&#21521;&#26080;&#29615;&#22270;&#12289;&#36830;&#36890;&#22270;&#12289;&#26641;&#65288;&#25110;&#26377;&#21521;&#26641;&#65289;&#25110;&#26862;&#26519;&#65288;&#25110;&#26377;&#21521;&#26862;&#26519;&#65289;&#26102;&#65292;&#23427;&#20173;&#28982;&#20445;&#25345;&#20102;&#22495;&#21487;&#25552;&#21319;&#24615;&#12290;&#25152;&#26377;&#25105;&#20204;&#30340;&#32467;&#26524;&#37117;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Weighted First Order Model Counting (WFOMC) is fundamental to probabilistic inference in statistical relational learning models. As WFOMC is known to be intractable in general ($\#$P-complete), logical fragments that admit polynomial time WFOMC are of significant interest. Such fragments are called domain liftable. Recent works have shown that the two-variable fragment of first order logic extended with counting quantifiers ($\mathrm{C^2}$) is domain-liftable. However, many properties of real-world data, like acyclicity in citation networks and connectivity in social networks, cannot be modeled in $\mathrm{C^2}$, or first order logic in general. In this work, we expand the domain liftability of $\mathrm{C^2}$ with multiple such properties. We show that any $\mathrm{C^2}$ sentence remains domain liftable when one of its relations is restricted to represent a directed acyclic graph, a connected graph, a tree (resp. a directed tree) or a forest (resp. a directed forest). All our results r
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27979;&#35797;&#20102;GPT-4&#22312;&#31185;&#23398;&#21644;&#25968;&#23398;&#38382;&#39064;&#19978;&#20351;&#29992;Wolfram Alpha&#21644;Code Interpreter&#25554;&#20214;&#30340;&#25928;&#26524;&#65292;&#32467;&#26524;&#34920;&#26126;&#25554;&#20214;&#26174;&#33879;&#25552;&#21319;&#20102;GPT&#30340;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#65292;&#20294;&#25509;&#21475;&#25925;&#38556;&#20173;&#28982;&#26159;&#20854;&#21487;&#38752;&#24615;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.05713</link><description>&lt;p&gt;
&#36890;&#36807;&#22312;&#25968;&#23398;&#21644;&#31185;&#23398;&#38382;&#39064;&#19978;&#20351;&#29992;Wolfram Alpha&#21644;Code Interpreter&#25554;&#20214;&#27979;&#35797;GPT-4
&lt;/p&gt;
&lt;p&gt;
Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems. (arXiv:2308.05713v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27979;&#35797;&#20102;GPT-4&#22312;&#31185;&#23398;&#21644;&#25968;&#23398;&#38382;&#39064;&#19978;&#20351;&#29992;Wolfram Alpha&#21644;Code Interpreter&#25554;&#20214;&#30340;&#25928;&#26524;&#65292;&#32467;&#26524;&#34920;&#26126;&#25554;&#20214;&#26174;&#33879;&#25552;&#21319;&#20102;GPT&#30340;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#65292;&#20294;&#25509;&#21475;&#25925;&#38556;&#20173;&#28982;&#26159;&#20854;&#21487;&#38752;&#24615;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25253;&#21578;&#25551;&#36848;&#20102;&#22312;2023&#24180;6&#26376;&#33267;8&#26376;&#26399;&#38388;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#22312;&#31185;&#23398;&#21644;&#25968;&#23398;&#39046;&#22495;&#36827;&#34892;&#30340;105&#20010;&#21407;&#21019;&#38382;&#39064;&#30340;&#27979;&#35797;&#65292;&#20854;&#20013;&#20351;&#29992;&#20102;Wolfram Alpha&#21644;Code Interpreter&#25554;&#20214;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#34920;&#26126;&#65292;&#36825;&#20123;&#25554;&#20214;&#26174;&#33879;&#22686;&#24378;&#20102;GPT&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#32463;&#24120;&#20986;&#29616;&#8220;&#25509;&#21475;&#8221;&#25925;&#38556;&#65307;&#20063;&#23601;&#26159;&#35828;&#65292;GPT&#32463;&#24120;&#22312;&#38382;&#39064;&#30340;&#34920;&#36848;&#19978;&#36935;&#21040;&#22256;&#38590;&#65292;&#26080;&#27861;&#20174;&#25554;&#20214;&#20013;&#24471;&#21040;&#26377;&#29992;&#30340;&#31572;&#26696;&#12290;&#35299;&#20915;&#36825;&#20123;&#25509;&#21475;&#25925;&#38556;&#20284;&#20046;&#26159;&#20351;GPT&#25104;&#20026;&#21487;&#38752;&#30340;&#22823;&#23398;&#32423;&#35745;&#31639;&#38382;&#39064;&#24037;&#20855;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
This report describes a test of the large language model GPT-4 with the Wolfram Alpha and the Code Interpreter plug-ins on 105 original problems in science and math, at the high school and college levels, carried out in June-August 2023. Our tests suggest that the plug-ins significantly enhance GPT's ability to solve these problems. Having said that, there are still often "interface" failures; that is, GPT often has trouble formulating problems in a way that elicits useful answers from the plug-ins. Fixing these interface failures seems like a central challenge in making GPT a reliable tool for college-level calculation problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#26102;&#38388;&#35270;&#37326;&#30340;&#37325;&#35201;&#24615;&#65292;&#21457;&#29616;&#30701;&#20110;&#23454;&#38469;&#20540;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#21487;&#20197;&#26356;&#24555;&#19988;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#22870;&#21169;&#20989;&#25968;&#65292;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21628;&#21505;&#22312;IRL&#20013;&#21516;&#26102;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#12290;</title><link>http://arxiv.org/abs/2307.06541</link><description>&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Effective Horizon of Inverse Reinforcement Learning. (arXiv:2307.06541v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#26102;&#38388;&#35270;&#37326;&#30340;&#37325;&#35201;&#24615;&#65292;&#21457;&#29616;&#30701;&#20110;&#23454;&#38469;&#20540;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#21487;&#20197;&#26356;&#24555;&#19988;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#22870;&#21169;&#20989;&#25968;&#65292;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21628;&#21505;&#22312;IRL&#20013;&#21516;&#26102;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#31639;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#22522;&#20110;&#32473;&#23450;&#26102;&#38388;&#35270;&#37326;&#30340;&#65288;&#21069;&#21521;&#65289;&#24378;&#21270;&#23398;&#20064;&#25110;&#35268;&#21010;&#26469;&#35745;&#31639;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#31574;&#30053;&#65292;&#28982;&#21518;&#23558;&#35813;&#31574;&#30053;&#19982;&#19987;&#23478;&#28436;&#31034;&#21305;&#37197;&#12290;&#26102;&#38388;&#35270;&#37326;&#22312;&#30830;&#23450;&#22870;&#21169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;IRL&#31639;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#27604;&#22320;&#38754;&#23454;&#38469;&#20540;&#26356;&#30701;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#36890;&#24120;&#33021;&#26356;&#24555;&#22320;&#20135;&#29983;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#23545;&#27492;&#29616;&#35937;&#36827;&#34892;&#20102;&#27491;&#24335;&#20998;&#26512;&#24182;&#32473;&#20986;&#20102;&#35299;&#37322;&#65306;&#26102;&#38388;&#35270;&#37326;&#25511;&#21046;&#20102;&#24341;&#21457;&#31574;&#30053;&#31867;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#26377;&#38480;&#25968;&#25454;&#19979;&#20943;&#36731;&#36807;&#25311;&#21512;&#12290;&#36825;&#19968;&#20998;&#26512;&#20026;IRL&#30340;&#26377;&#25928;&#35270;&#37326;&#36873;&#25321;&#25552;&#20379;&#20102;&#21407;&#21017;&#24615;&#25351;&#23548;&#12290;&#23427;&#20063;&#20419;&#20351;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#32463;&#20856;&#30340;IRL&#20844;&#24335;&#65306;&#19982;&#20165;&#20855;&#26377;&#32473;&#23450;&#35270;&#37326;&#30340;&#22870;&#21169;&#30456;&#27604;&#65292;&#20849;&#21516;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#35270;&#37326;&#26356;&#21152;&#33258;&#28982;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#36825;&#19968;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse reinforcement learning (IRL) algorithms often rely on (forward) reinforcement learning or planning over a given time horizon to compute an approximately optimal policy for a hypothesized reward function and then match this policy with expert demonstrations. The time horizon plays a critical role in determining both the accuracy of reward estimate and the computational efficiency of IRL algorithms. Interestingly, an effective time horizon shorter than the ground-truth value often produces better results faster. This work formally analyzes this phenomenon and provides an explanation: the time horizon controls the complexity of an induced policy class and mitigates overfitting with limited data. This analysis leads to a principled choice of the effective horizon for IRL. It also prompts us to reexamine the classic IRL formulation: it is more natural to learn jointly the reward and the effective horizon together rather than the reward alone with a given horizon. Our experimental re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#25968;&#25454;&#20998;&#31867;&#30340;&#31283;&#20581;&#30340;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#26080;&#38656;&#35843;&#21442;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#65292;&#24050;&#22312;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#20013;&#24471;&#21040;&#35777;&#26126;&#27604;&#20854;&#20182;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2306.13985</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#30340;&#39640;&#32500;&#25968;&#25454;&#31283;&#20581;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Robust Classification of High-Dimensional Data using Data-Adaptive Energy Distance. (arXiv:2306.13985v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13985
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#25968;&#25454;&#20998;&#31867;&#30340;&#31283;&#20581;&#30340;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#26080;&#38656;&#35843;&#21442;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#65292;&#24050;&#22312;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#20013;&#24471;&#21040;&#35777;&#26126;&#27604;&#20854;&#20182;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#65292;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#65288;HDLSS&#65289;&#25968;&#25454;&#30340;&#20998;&#31867;&#38754;&#20020;&#25361;&#25112;&#65292;&#20363;&#22914;&#22522;&#22240;&#34920;&#36798;&#30740;&#31350;&#12289;&#30284;&#30151;&#30740;&#31350;&#21644;&#21307;&#23398;&#25104;&#20687;&#31561;&#39046;&#22495;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20123;&#19987;&#38376;&#20026;HDLSS&#25968;&#25454;&#35774;&#35745;&#30340;&#20998;&#31867;&#22120;&#30340;&#24320;&#21457;&#21644;&#20998;&#26512;&#12290;&#36825;&#20123;&#20998;&#31867;&#22120;&#27809;&#26377;&#35843;&#33410;&#21442;&#25968;&#65292;&#24182;&#19988;&#26159;&#31283;&#20581;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#21463;&#24213;&#23618;&#25968;&#25454;&#20998;&#24067;&#30340;&#20219;&#20309;&#30697;&#26465;&#20214;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#19968;&#20123;&#30456;&#24403;&#26222;&#36941;&#30340;&#26465;&#20214;&#19979;&#65292;&#23427;&#20204;&#22312;HDLSS&#28176;&#36817;&#21306;&#22495;&#20869;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#12290;&#36824;&#27604;&#36739;&#20102;&#25152;&#25552;&#20986;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#30340;&#25903;&#25345;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#20998;&#31867;&#25216;&#26415;&#20248;&#20110;&#20960;&#31181;&#24191;&#27867;&#35748;&#21487;&#30340;&#26041;&#27861;&#30340;&#26377;&#24076;&#26395;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classification of high-dimensional low sample size (HDLSS) data poses a challenge in a variety of real-world situations, such as gene expression studies, cancer research, and medical imaging. This article presents the development and analysis of some classifiers that are specifically designed for HDLSS data. These classifiers are free of tuning parameters and are robust, in the sense that they are devoid of any moment conditions of the underlying data distributions. It is shown that they yield perfect classification in the HDLSS asymptotic regime, under some fairly general conditions. The comparative performance of the proposed classifiers is also investigated. Our theoretical results are supported by extensive simulation studies and real data analysis, which demonstrate promising advantages of the proposed classification techniques over several widely recognized methods.
&lt;/p&gt;</description></item></channel></rss>