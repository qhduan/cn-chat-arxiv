<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#22312;&#25968;&#25454;&#27969;&#24418;&#20869;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#22312;&#30446;&#26631;&#20989;&#25968;&#23450;&#20041;&#30340;Boltzmann&#20998;&#24067;&#21644;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#20056;&#31215;&#19978;&#36827;&#34892;&#25277;&#26679;&#26469;&#35299;&#20915;&#20855;&#26377;&#26410;&#30693;&#32422;&#26463;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.18012</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#20855;&#26377;&#26410;&#30693;&#32422;&#26463;&#30340;&#20248;&#21270;&#32422;&#26463;&#25277;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18012
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#22312;&#25968;&#25454;&#27969;&#24418;&#20869;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#22312;&#30446;&#26631;&#20989;&#25968;&#23450;&#20041;&#30340;Boltzmann&#20998;&#24067;&#21644;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#20056;&#31215;&#19978;&#36827;&#34892;&#25277;&#26679;&#26469;&#35299;&#20915;&#20855;&#26377;&#26410;&#30693;&#32422;&#26463;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22788;&#29702;&#29616;&#23454;&#19990;&#30028;&#30340;&#20248;&#21270;&#38382;&#39064;&#22312;&#20998;&#26512;&#23458;&#35266;&#20989;&#25968;&#25110;&#32422;&#26463;&#19981;&#21487;&#29992;&#26102;&#21464;&#24471;&#23588;&#20026;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#35768;&#22810;&#30740;&#31350;&#24050;&#32463;&#35299;&#20915;&#20102;&#26410;&#30693;&#30446;&#26631;&#30340;&#38382;&#39064;&#65292;&#20294;&#26377;&#38480;&#30740;&#31350;&#20851;&#27880;&#20102;&#32422;&#26463;&#26465;&#20214;&#26410;&#26126;&#30830;&#32473;&#20986;&#30340;&#24773;&#20917;&#12290;&#24573;&#30053;&#36825;&#20123;&#32422;&#26463;&#21487;&#33021;&#23548;&#33268;&#22312;&#23454;&#36341;&#20013;&#19981;&#29616;&#23454;&#30340;&#34394;&#20551;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#31181;&#26410;&#30693;&#32422;&#26463;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#22312;&#25968;&#25454;&#27969;&#24418;&#20869;&#36827;&#34892;&#20248;&#21270;&#12290;&#20026;&#20102;&#23558;&#20248;&#21270;&#36807;&#31243;&#38480;&#21046;&#22312;&#25968;&#25454;&#27969;&#24418;&#20869;&#65292;&#25105;&#20204;&#23558;&#21407;&#22987;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#26500;&#36896;&#20026;&#36890;&#36807;&#23458;&#35266;&#20989;&#25968;&#23450;&#20041;&#30340;Boltzmann&#20998;&#24067;&#21644;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#20056;&#31215;&#30340;&#25277;&#26679;&#38382;&#39064;&#12290;&#20026;&#20102;&#22686;&#24378;&#25277;&#26679;&#25928;&#29575;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#26694;&#26550;&#65292;&#20197;&#24341;&#23548;&#25193;&#25955;&#36807;&#31243;&#36827;&#34892;&#39044;&#28909;&#65292;&#28982;&#21518;&#26159;Langevin&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18012v1 Announce Type: cross  Abstract: Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. To enhance sampling efficiency, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dyna
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#37327;&#23376;&#26497;&#22352;&#26631;&#24230;&#37327;&#23398;&#20064;(QPMeL)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32463;&#20856;&#27169;&#22411;&#23398;&#20064;&#37327;&#23376;&#27604;&#29305;&#30340;&#26497;&#22352;&#26631;&#24418;&#24335;&#30340;&#21442;&#25968;&#65292;&#28982;&#21518;&#20351;&#29992;&#27973;&#23618;PQC&#21644;&#21487;&#35757;&#32451;&#30340;&#38376;&#23618;&#26469;&#21019;&#24314;&#37327;&#23376;&#24577;&#21644;&#23398;&#20064;&#32416;&#32544;&#12290;&#19982;QMeL&#30456;&#27604;&#65292;QPMeL&#20855;&#26377;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.01655</link><description>&lt;p&gt;
&#37327;&#23376;&#26497;&#22352;&#26631;&#24230;&#37327;&#23398;&#20064;: &#39640;&#25928;&#32463;&#20856;&#23398;&#20064;&#30340;&#37327;&#23376;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Quantum Polar Metric Learning: Efficient Classically Learned Quantum Embeddings. (arXiv:2312.01655v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#37327;&#23376;&#26497;&#22352;&#26631;&#24230;&#37327;&#23398;&#20064;(QPMeL)&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32463;&#20856;&#27169;&#22411;&#23398;&#20064;&#37327;&#23376;&#27604;&#29305;&#30340;&#26497;&#22352;&#26631;&#24418;&#24335;&#30340;&#21442;&#25968;&#65292;&#28982;&#21518;&#20351;&#29992;&#27973;&#23618;PQC&#21644;&#21487;&#35757;&#32451;&#30340;&#38376;&#23618;&#26469;&#21019;&#24314;&#37327;&#23376;&#24577;&#21644;&#23398;&#20064;&#32416;&#32544;&#12290;&#19982;QMeL&#30456;&#27604;&#65292;QPMeL&#20855;&#26377;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#22312;&#32463;&#20856;&#25968;&#25454;&#33539;&#30068;&#20013;&#34920;&#29616;&#20986;&#26497;&#26377;&#28508;&#21147;&#30340;&#32467;&#26524;&#65292;&#21019;&#24314;&#20102;&#20998;&#31163;&#26126;&#26174;&#30340;&#29305;&#24449;&#31354;&#38388;&#12290;&#36825;&#20010;&#24819;&#27861;&#20063;&#34987;&#24212;&#29992;&#21040;&#37327;&#23376;&#35745;&#31639;&#26426;&#20013;&#65292;&#36890;&#36807;&#37327;&#23376;&#24230;&#37327;&#23398;&#20064;(QMeL)&#12290;QMeL&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65292;&#39318;&#20808;&#20351;&#29992;&#32463;&#20856;&#27169;&#22411;&#23558;&#25968;&#25454;&#21387;&#32553;&#20197;&#36866;&#24212;&#26377;&#38480;&#25968;&#37327;&#30340;&#37327;&#23376;&#27604;&#29305;&#65292;&#28982;&#21518;&#20351;&#29992;&#21442;&#25968;&#21270;&#37327;&#23376;&#30005;&#36335;(PQC)&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#21019;&#24314;&#26356;&#22909;&#30340;&#20998;&#31163;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#22024;&#26434;&#20013;&#38388;&#35268;&#27169;&#37327;&#23376;(NISQ)&#35774;&#22791;&#19978;&#65292;QMeL&#35299;&#20915;&#26041;&#26696;&#23548;&#33268;&#30005;&#36335;&#23485;&#24230;&#21644;&#28145;&#24230;&#36739;&#22823;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#37327;&#23376;&#26497;&#22352;&#26631;&#24230;&#37327;&#23398;&#20064;(QPMeL)&#30340;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#32463;&#20856;&#27169;&#22411;&#23398;&#20064;&#19968;&#20010;&#37327;&#23376;&#27604;&#29305;&#30340;&#26497;&#22352;&#26631;&#24418;&#24335;&#30340;&#21442;&#25968;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20165;&#21253;&#21547;$R_y$&#21644;$R_z$&#38376;&#30340;&#27973;&#23618;PQC&#21019;&#24314;&#37327;&#23376;&#24577;&#65292;&#24182;&#21033;&#29992;&#21487;&#35757;&#32451;&#30340;$ZZ(\theta)$&#38376;&#23618;&#23398;&#20064;&#32416;&#32544;&#12290;&#30005;&#36335;&#36824;&#36890;&#36807;SWAP&#27979;&#35797;&#35745;&#31639;&#20445;&#30495;&#24230;&#65292;&#29992;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#20445;&#30495;&#24230;&#19977;&#20803;&#25439;&#22833;&#20989;&#25968;&#30340;&#35757;&#32451;&#65292;&#29992;&#20110;&#21516;&#26102;&#35757;&#32451;&#32463;&#20856;&#21644;&#37327;&#23376;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep metric learning has recently shown extremely promising results in the classical data domain, creating well-separated feature spaces. This idea was also adapted to quantum computers via Quantum Metric Learning(QMeL). QMeL consists of a 2 step process with a classical model to compress the data to fit into the limited number of qubits, then train a Parameterized Quantum Circuit(PQC) to create better separation in Hilbert Space. However, on Noisy Intermediate Scale Quantum (NISQ) devices. QMeL solutions result in high circuit width and depth, both of which limit scalability. We propose Quantum Polar Metric Learning (QPMeL) that uses a classical model to learn the parameters of the polar form of a qubit. We then utilize a shallow PQC with $R_y$ and $R_z$ gates to create the state and a trainable layer of $ZZ(\theta)$-gates to learn entanglement. The circuit also computes fidelity via a SWAP Test for our proposed Fidelity Triplet Loss function, used to train both classical and quantum 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#35760;&#24518;&#30340;&#21078;&#26512;&#65292;&#25581;&#31034;&#20102;&#23574;&#38160;&#24847;&#35782;&#26368;&#23567;&#21270;&#31639;&#27861;&#22312;&#38750;&#20856;&#22411;&#25968;&#25454;&#28857;&#19978;&#23454;&#29616;&#30340;&#27867;&#21270;&#25910;&#30410;&#12290;&#21516;&#26102;&#65292;&#20063;&#21457;&#29616;&#20102;&#19982;&#27492;&#31639;&#27861;&#30456;&#20851;&#30340;&#26356;&#39640;&#38544;&#31169;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#32531;&#35299;&#31574;&#30053;&#65292;&#20197;&#36798;&#21040;&#26356;&#29702;&#24819;&#30340;&#20934;&#30830;&#24230;&#19982;&#38544;&#31169;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2310.00488</link><description>&lt;p&gt;
&#20851;&#20110;&#23574;&#38160;&#24847;&#35782;&#26368;&#23567;&#21270;&#30340;&#35760;&#24518;&#21644;&#38544;&#31169;&#39118;&#38505;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Memorization and Privacy Risks of Sharpness Aware Minimization. (arXiv:2310.00488v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#35760;&#24518;&#30340;&#21078;&#26512;&#65292;&#25581;&#31034;&#20102;&#23574;&#38160;&#24847;&#35782;&#26368;&#23567;&#21270;&#31639;&#27861;&#22312;&#38750;&#20856;&#22411;&#25968;&#25454;&#28857;&#19978;&#23454;&#29616;&#30340;&#27867;&#21270;&#25910;&#30410;&#12290;&#21516;&#26102;&#65292;&#20063;&#21457;&#29616;&#20102;&#19982;&#27492;&#31639;&#27861;&#30456;&#20851;&#30340;&#26356;&#39640;&#38544;&#31169;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#32531;&#35299;&#31574;&#30053;&#65292;&#20197;&#36798;&#21040;&#26356;&#29702;&#24819;&#30340;&#20934;&#30830;&#24230;&#19982;&#38544;&#31169;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#35774;&#35745;&#23547;&#27714;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#20248;&#21270;&#20013;&#26356;&#24179;&#22374;&#30340;&#26497;&#20540;&#30340;&#31639;&#27861;&#25104;&#20026;&#28966;&#28857;&#65292;&#22240;&#20026;&#26377;&#32463;&#39564;&#35777;&#25454;&#34920;&#26126;&#36825;&#20250;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#19978;&#23548;&#33268;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#35760;&#24518;&#35270;&#35282;&#26469;&#21078;&#26512;&#36825;&#20123;&#24615;&#33021;&#25910;&#30410;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#24110;&#21161;&#25105;&#20204;&#30830;&#23450;&#30456;&#23545;&#20110;&#26222;&#36890;SGD&#65292;&#23547;&#27714;&#26356;&#24179;&#22374;&#26497;&#20540;&#30340;&#31639;&#27861;&#22312;&#21738;&#20123;&#25968;&#25454;&#28857;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23574;&#38160;&#24847;&#35782;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#25152;&#23454;&#29616;&#30340;&#27867;&#21270;&#25910;&#30410;&#22312;&#38750;&#20856;&#22411;&#25968;&#25454;&#28857;&#19978;&#29305;&#21035;&#26174;&#33879;&#65292;&#36825;&#38656;&#35201;&#35760;&#24518;&#12290;&#36825;&#19968;&#35748;&#35782;&#24110;&#21161;&#25105;&#20204;&#25581;&#31034;&#19982;SAM&#30456;&#20851;&#30340;&#26356;&#39640;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#24182;&#36890;&#36807;&#35814;&#23613;&#30340;&#23454;&#35777;&#35780;&#20272;&#36827;&#34892;&#39564;&#35777;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#32531;&#35299;&#31574;&#30053;&#65292;&#20197;&#23454;&#29616;&#26356;&#29702;&#24819;&#30340;&#20934;&#30830;&#24230;&#19982;&#38544;&#31169;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many recent works, there is an increased focus on designing algorithms that seek flatter optima for neural network loss optimization as there is empirical evidence that it leads to better generalization performance in many datasets. In this work, we dissect these performance gains through the lens of data memorization in overparameterized models. We define a new metric that helps us identify which data points specifically do algorithms seeking flatter optima do better when compared to vanilla SGD. We find that the generalization gains achieved by Sharpness Aware Minimization (SAM) are particularly pronounced for atypical data points, which necessitate memorization. This insight helps us unearth higher privacy risks associated with SAM, which we verify through exhaustive empirical evaluations. Finally, we propose mitigation strategies to achieve a more desirable accuracy vs privacy tradeoff.
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#30340;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#23427;&#25552;&#20379;&#20102;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#26159;&#21487;&#34892;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.01449</link><description>&lt;p&gt;
&#23558;&#23454;&#39564;&#25968;&#25454;&#19982;&#35266;&#27979;&#25968;&#25454;&#32467;&#21512;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Double Machine Learning Approach to Combining Experimental and Observational Data. (arXiv:2307.01449v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01449
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#30340;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#23427;&#25552;&#20379;&#20102;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#36890;&#24120;&#30001;&#20110;&#26080;&#27861;&#27979;&#35797;&#30340;&#20551;&#35774;&#32780;&#32570;&#20047;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#20351;&#20174;&#19994;&#20154;&#21592;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#36739;&#36731;&#30340;&#20551;&#35774;&#19979;&#27979;&#35797;&#22806;&#37096;&#25928;&#24230;&#21644;&#21487;&#24573;&#35270;&#24615;&#30340;&#36829;&#21453;&#24773;&#20917;&#12290;&#24403;&#21482;&#26377;&#19968;&#20010;&#20551;&#35774;&#34987;&#36829;&#21453;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#24378;&#35843;&#20102;&#20934;&#30830;&#35782;&#21035;&#36829;&#21453;&#30340;&#20551;&#35774;&#23545;&#19968;&#33268;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#30340;&#24517;&#35201;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#19977;&#20010;&#23454;&#38469;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#20854;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Experimental and observational studies often lack validity due to untestable assumptions. We propose a double machine learning approach to combine experimental and observational studies, allowing practitioners to test for assumption violations and estimate treatment effects consistently. Our framework tests for violations of external validity and ignorability under milder assumptions. When only one assumption is violated, we provide semi-parametrically efficient treatment effect estimators. However, our no-free-lunch theorem highlights the necessity of accurately identifying the violated assumption for consistent treatment effect estimation. We demonstrate the applicability of our approach in three real-world case studies, highlighting its relevance for practical settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26234;&#33021;&#35786;&#26029;&#26694;&#26550;&#65292;&#38024;&#23545;&#20302;&#36164;&#28304;&#29615;&#22659;&#23454;&#29616;&#26089;&#26399;&#26816;&#27979;&#21644;&#20998;&#31867;&#32954;&#37096;&#32467;&#33410;&#65292;&#24182;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.00046</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#32954;&#30284;&#35786;&#26029;&#33258;&#21160;&#21270;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#21644;&#20998;&#31867;&#32954;&#37096;&#32467;&#33410;
&lt;/p&gt;
&lt;p&gt;
An automated end-to-end deep learning-based framework for lung cancer diagnosis by detecting and classifying the lung nodules. (arXiv:2305.00046v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26234;&#33021;&#35786;&#26029;&#26694;&#26550;&#65292;&#38024;&#23545;&#20302;&#36164;&#28304;&#29615;&#22659;&#23454;&#29616;&#26089;&#26399;&#26816;&#27979;&#21644;&#20998;&#31867;&#32954;&#37096;&#32467;&#33410;&#65292;&#24182;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32954;&#30284;&#26159;&#20840;&#29699;&#30284;&#30151;&#30456;&#20851;&#27515;&#20129;&#30340;&#20027;&#35201;&#21407;&#22240;&#65292;&#22312;&#20302;&#36164;&#28304;&#29615;&#22659;&#20013;&#26089;&#26399;&#35786;&#26029;&#23545;&#20110;&#25913;&#21892;&#24739;&#32773;&#30103;&#25928;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#30340;&#26159;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#33258;&#21160;&#21270;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#29992;&#20110;&#26089;&#26399;&#26816;&#27979;&#21644;&#20998;&#31867;&#32954;&#37096;&#32467;&#33410;&#65292;&#29305;&#21035;&#26159;&#38024;&#23545;&#20302;&#36164;&#28304;&#29615;&#22659;&#12290;&#35813;&#26694;&#26550;&#30001;&#19977;&#20010;&#38454;&#27573;&#32452;&#25104;&#65306;&#20351;&#29992;&#25913;&#36827;&#30340;3D Res-U-Net&#36827;&#34892;&#32954;&#20998;&#21106;&#12289;&#20351;&#29992;YOLO-v5&#36827;&#34892;&#32467;&#33410;&#26816;&#27979;&#12289;&#20351;&#29992;&#22522;&#20110;Vision Transformer&#30340;&#26550;&#26500;&#36827;&#34892;&#20998;&#31867;&#12290;&#25105;&#20204;&#22312;&#24320;&#25918;&#30340;&#25968;&#25454;&#38598;LUNA16&#19978;&#23545;&#35813;&#26694;&#26550;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#30340;&#24615;&#33021;&#26159;&#20351;&#29992;&#21508;&#39046;&#22495;&#30340;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#34913;&#37327;&#30340;&#12290;&#35813;&#26694;&#26550;&#22312;&#32954;&#37096;&#20998;&#21106;dice&#31995;&#25968;&#19978;&#36798;&#21040;&#20102;98.82&#65285;&#65292;&#21516;&#26102;&#26816;&#27979;&#32954;&#32467;&#33410;&#30340;&#24179;&#22343;&#20934;&#30830;&#24230;&#20026;0.76 mAP&#12290;
&lt;/p&gt;
&lt;p&gt;
Lung cancer is a leading cause of cancer-related deaths worldwide, and early detection is crucial for improving patient outcomes. Nevertheless, early diagnosis of cancer is a major challenge, particularly in low-resource settings where access to medical resources and trained radiologists is limited. The objective of this study is to propose an automated end-to-end deep learning-based framework for the early detection and classification of lung nodules, specifically for low-resource settings. The proposed framework consists of three stages: lung segmentation using a modified 3D U-Net named 3D Res-U-Net, nodule detection using YOLO-v5, and classification with a Vision Transformer-based architecture. We evaluated the proposed framework on a publicly available dataset, LUNA16. The proposed framework's performance was measured using the respective domain's evaluation matrices. The proposed framework achieved a 98.82% lung segmentation dice score while detecting the lung nodule with 0.76 mAP
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#22522;&#20110;GNN&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#20248;&#21270;&#26381;&#21153;&#36136;&#37327;&#65292;&#35299;&#20915;ONTS&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.13773</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65306;&#23398;&#20064;&#28151;&#21512;&#25972;&#25968;&#27169;&#22411;&#30340;&#27934;&#35265;
&lt;/p&gt;
&lt;p&gt;
A Graph Neural Network Approach to Nanosatellite Task Scheduling: Insights into Learning Mixed-Integer Models. (arXiv:2303.13773v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13773
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#22522;&#20110;GNN&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#20248;&#21270;&#26381;&#21153;&#36136;&#37327;&#65292;&#35299;&#20915;ONTS&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#22914;&#20309;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26356;&#26377;&#25928;&#22320;&#35843;&#24230;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#12290;&#22312;&#31163;&#32447;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#65288;ONTS&#65289;&#38382;&#39064;&#20013;&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#22312;&#36712;&#36947;&#19978;&#25191;&#34892;&#20219;&#21153;&#30340;&#26368;&#20339;&#23433;&#25490;&#65292;&#21516;&#26102;&#32771;&#34385;&#26381;&#21153;&#36136;&#37327;&#65288;QoS&#65289;&#26041;&#38754;&#30340;&#32771;&#34385;&#22240;&#32032;&#65292;&#22914;&#20248;&#20808;&#32423;&#65292;&#26368;&#23567;&#21644;&#26368;&#22823;&#28608;&#27963;&#20107;&#20214;&#65292;&#25191;&#34892;&#26102;&#38388;&#26694;&#26550;&#65292;&#21608;&#26399;&#21644;&#25191;&#34892;&#31383;&#21475;&#65292;&#20197;&#21450;&#21355;&#26143;&#30005;&#21147;&#36164;&#28304;&#21644;&#33021;&#37327;&#25910;&#38598;&#21644;&#31649;&#29702;&#30340;&#22797;&#26434;&#24615;&#30340;&#32422;&#26463;&#12290;ONTS&#38382;&#39064;&#24050;&#32463;&#20351;&#29992;&#20256;&#32479;&#30340;&#25968;&#23398;&#20844;&#24335;&#21644;&#31934;&#30830;&#26041;&#27861;&#36827;&#34892;&#20102;&#22788;&#29702;&#65292;&#20294;&#26159;&#23427;&#20204;&#22312;&#38382;&#39064;&#30340;&#25361;&#25112;&#24615;&#26696;&#20363;&#20013;&#30340;&#36866;&#29992;&#24615;&#26377;&#38480;&#12290;&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;GNN&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#24050;&#32463;&#25104;&#21151;&#24212;&#29992;&#20110;&#35768;&#22810;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#26053;&#34892;&#21830;&#38382;&#39064;&#65292;&#35843;&#24230;&#38382;&#39064;&#21644;&#35774;&#26045;&#25918;&#32622;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;ONTS&#38382;&#39064;&#30340;MILP&#23454;&#20363;&#23436;&#20840;&#34920;&#31034;&#25104;&#20108;&#20998;&#22270;&#32593;&#32476;&#32467;&#26500;&#26469;&#24212;&#29992;GNN&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates how to schedule nanosatellite tasks more efficiently using Graph Neural Networks (GNN). In the Offline Nanosatellite Task Scheduling (ONTS) problem, the goal is to find the optimal schedule for tasks to be carried out in orbit while taking into account Quality-of-Service (QoS) considerations such as priority, minimum and maximum activation events, execution time-frames, periods, and execution windows, as well as constraints on the satellite's power resources and the complexity of energy harvesting and management. The ONTS problem has been approached using conventional mathematical formulations and precise methods, but their applicability to challenging cases of the problem is limited. This study examines the use of GNNs in this context, which has been effectively applied to many optimization problems, including traveling salesman problems, scheduling problems, and facility placement problems. Here, we fully represent MILP instances of the ONTS problem in biparti
&lt;/p&gt;</description></item></channel></rss>