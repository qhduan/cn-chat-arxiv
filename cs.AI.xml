<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#29983;&#29289;&#20998;&#23376;&#19982;&#33258;&#28982;&#35821;&#35328;&#30456;&#32467;&#21512;&#30340;&#22810;&#27169;&#24577;&#23398;&#20064;&#20026;&#20840;&#38754;&#34920;&#31034;&#21644;&#20998;&#26512;&#29983;&#29289;&#20998;&#23376;&#24320;&#36767;&#20102;&#26032;&#36884;&#24452;&#12290;</title><link>https://arxiv.org/abs/2403.01528</link><description>&lt;p&gt;
&#21033;&#29992;&#29983;&#29289;&#20998;&#23376;&#21644;&#33258;&#28982;&#35821;&#35328;&#30340;&#22810;&#27169;&#24577;&#23398;&#20064;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01528
&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#20998;&#23376;&#19982;&#33258;&#28982;&#35821;&#35328;&#30456;&#32467;&#21512;&#30340;&#22810;&#27169;&#24577;&#23398;&#20064;&#20026;&#20840;&#38754;&#34920;&#31034;&#21644;&#20998;&#26512;&#29983;&#29289;&#20998;&#23376;&#24320;&#36767;&#20102;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#29983;&#29289;&#20998;&#23376;&#24314;&#27169;&#19982;&#33258;&#28982;&#35821;&#35328;&#65288;BL&#65289;&#24050;&#32463;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#12289;&#21270;&#23398;&#21644;&#29983;&#29289;&#23398;&#20132;&#21449;&#39046;&#22495;&#20013;&#30340;&#19968;&#20010;&#20855;&#26377;&#21069;&#26223;&#30340;&#36328;&#23398;&#31185;&#39046;&#22495;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#25991;&#26412;&#25968;&#25454;&#28304;&#20013;&#21253;&#21547;&#30340;&#29983;&#29289;&#20998;&#23376;&#30340;&#20016;&#23500;&#22810;&#38754;&#25551;&#36848;&#65292;&#22686;&#24378;&#25105;&#20204;&#23545;&#22522;&#26412;&#29702;&#35299;&#65292;&#24182;&#23454;&#29616;&#29983;&#29289;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#31561;&#35745;&#31639;&#20219;&#21153;&#12290;&#36890;&#36807;&#23558;&#33258;&#28982;&#35821;&#35328;&#20013;&#34920;&#36798;&#30340;&#24494;&#22937;&#21465;&#36848;&#19982;&#36890;&#36807;&#21508;&#31181;&#20998;&#23376;&#24314;&#27169;&#25216;&#26415;&#25551;&#36848;&#30340;&#29983;&#29289;&#20998;&#23376;&#30340;&#32467;&#26500;&#21644;&#21151;&#33021;&#32454;&#33410;&#34701;&#21512;&#65292;&#25171;&#24320;&#20102;&#20840;&#38754;&#34920;&#24449;&#21644;&#20998;&#26512;&#29983;&#29289;&#20998;&#23376;&#30340;&#26032;&#36884;&#24452;&#12290;&#36890;&#36807;&#23558;&#22260;&#32469;&#29983;&#29289;&#20998;&#23376;&#30340;&#19978;&#19979;&#25991;&#35821;&#35328;&#25968;&#25454;&#32435;&#20837;&#24314;&#27169;&#20013;&#65292;BL&#26088;&#22312;&#25429;&#25417;&#21253;&#21547;&#35821;&#35328;&#20256;&#36798;&#30340;&#31526;&#21495;&#29305;&#24615;&#20197;&#21450;&#25968;&#37327;&#21270;&#32467;&#26500;&#29305;&#24449;&#30340;&#25972;&#20307;&#35270;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01528v1 Announce Type: cross  Abstract: The integration of biomolecular modeling with natural language (BL) has emerged as a promising interdisciplinary area at the intersection of artificial intelligence, chemistry and biology. This approach leverages the rich, multifaceted descriptions of biomolecules contained within textual data sources to enhance our fundamental understanding and enable downstream computational tasks such as biomolecule property prediction. The fusion of the nuanced narratives expressed through natural language with the structural and functional specifics of biomolecules described via various molecular modeling techniques opens new avenues for comprehensively representing and analyzing biomolecules. By incorporating the contextual language data that surrounds biomolecules into their modeling, BL aims to capture a holistic view encompassing both the symbolic qualities conveyed through language as well as quantitative structural characteristics. In this r
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#22810;&#31890;&#24230;&#34701;&#21512;&#32593;&#32476;&#65288;EMGF&#65289;&#29992;&#20110;&#22522;&#20110;&#26041;&#38754;&#30340;&#24773;&#24863;&#20998;&#26512;&#65292;&#36890;&#36807;&#25972;&#21512;&#19981;&#21516;&#30340;&#35821;&#35328;&#21644;&#32467;&#26500;&#29305;&#24449;&#65292;&#21253;&#25324;&#21477;&#27861;&#20381;&#36182;&#12289;&#32452;&#25104;&#12289;&#27880;&#24847;&#21147;&#35821;&#20041;&#21644;&#22806;&#37096;&#30693;&#35782;&#22270;&#35889;&#31561;&#65292;&#26469;&#25552;&#39640;&#24773;&#24863;&#20998;&#26512;&#30340;&#24615;&#33021;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07787</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#22810;&#31890;&#24230;&#34701;&#21512;&#32593;&#32476;&#29992;&#20110;&#22522;&#20110;&#26041;&#38754;&#30340;&#24773;&#24863;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07787
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#22810;&#31890;&#24230;&#34701;&#21512;&#32593;&#32476;&#65288;EMGF&#65289;&#29992;&#20110;&#22522;&#20110;&#26041;&#38754;&#30340;&#24773;&#24863;&#20998;&#26512;&#65292;&#36890;&#36807;&#25972;&#21512;&#19981;&#21516;&#30340;&#35821;&#35328;&#21644;&#32467;&#26500;&#29305;&#24449;&#65292;&#21253;&#25324;&#21477;&#27861;&#20381;&#36182;&#12289;&#32452;&#25104;&#12289;&#27880;&#24847;&#21147;&#35821;&#20041;&#21644;&#22806;&#37096;&#30693;&#35782;&#22270;&#35889;&#31561;&#65292;&#26469;&#25552;&#39640;&#24773;&#24863;&#20998;&#26512;&#30340;&#24615;&#33021;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26041;&#38754;&#30340;&#24773;&#24863;&#20998;&#26512;&#65288;ABSA&#65289;&#35780;&#20272;&#25991;&#26412;&#20013;&#30340;&#24773;&#24863;&#34920;&#36798;&#20197;&#29702;&#35299;&#24773;&#24863;&#20449;&#24687;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#25972;&#21512;&#20102;&#22806;&#37096;&#30693;&#35782;&#65292;&#22914;&#30693;&#35782;&#22270;&#35889;&#65292;&#20197;&#21152;&#24378;ABSA&#27169;&#22411;&#20013;&#30340;&#35821;&#20041;&#29305;&#24449;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20381;&#36182;&#21644;&#32452;&#25104;&#26641;&#19978;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#36827;&#34892;&#21477;&#27861;&#20998;&#26512;&#12290;&#38543;&#30528;ABSA&#30340;&#19981;&#26029;&#21457;&#23637;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#21019;&#26032;&#30340;&#35821;&#35328;&#21644;&#32467;&#26500;&#29305;&#24449;&#34987;&#34701;&#20837;&#20854;&#20013;&#65288;&#20363;&#22914;&#28508;&#22312;&#22270;&#65289;&#65292;&#20294;&#36825;&#20063;&#24341;&#20837;&#20102;&#22797;&#26434;&#24615;&#21644;&#28151;&#28102;&#12290;&#30446;&#21069;&#65292;&#23578;&#19981;&#23384;&#22312;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#22810;&#26679;&#24615;&#30340;&#35821;&#35328;&#21644;&#32467;&#26500;&#29305;&#24449;&#38598;&#25104;&#21040;ABSA&#20013;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#21487;&#25193;&#23637;&#30340;&#22810;&#31890;&#24230;&#34701;&#21512;&#65288;EMGF&#65289;&#32593;&#32476;&#65292;&#23427;&#25972;&#21512;&#20102;&#26469;&#33258;&#21477;&#27861;&#20381;&#36182;&#21644;&#32452;&#25104;&#12289;&#27880;&#24847;&#21147;&#35821;&#20041;&#21644;&#22806;&#37096;&#30693;&#35782;&#22270;&#35889;&#30340;&#20449;&#24687;&#12290;EMGF&#37197;&#22791;&#20102;&#22810;&#38170;&#28857;&#19977;&#20803;&#23398;&#20064;&#21644;&#27491;&#20132;&#25237;&#24433;&#65292;&#39640;&#25928;&#22320;&#21033;&#29992;&#20102;&#36825;&#20123;&#29305;&#24449;&#30340;&#32508;&#21512;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information. Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models. Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs. EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20840;&#23616;&#21407;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#33258;&#30417;&#30563;&#20449;&#24687;&#30340;&#27491;&#21017;&#21270;&#19979;&#23398;&#20064;&#25968;&#25454;&#34920;&#31034;&#65292;&#20197;&#32531;&#35299;&#36127;&#38754;&#34920;&#31034;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20943;&#23569;&#25345;&#32493;&#23398;&#20064;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;</title><link>http://arxiv.org/abs/2205.12186</link><description>&lt;p&gt;
&#22522;&#20110;&#20840;&#23616;&#21407;&#22411;&#30340;&#22686;&#24378;&#25345;&#32493;&#23398;&#20064;: &#23545;&#25239;&#36127;&#34920;&#31034;&#28418;&#31227;
&lt;/p&gt;
&lt;p&gt;
Enhancing Continual Learning with Global Prototypes: Counteracting Negative Representation Drift. (arXiv:2205.12186v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12186
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20840;&#23616;&#21407;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#33258;&#30417;&#30563;&#20449;&#24687;&#30340;&#27491;&#21017;&#21270;&#19979;&#23398;&#20064;&#25968;&#25454;&#34920;&#31034;&#65292;&#20197;&#32531;&#35299;&#36127;&#38754;&#34920;&#31034;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20943;&#23569;&#25345;&#32493;&#23398;&#20064;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#23398;&#20064;&#26088;&#22312;&#23398;&#20064;&#19968;&#31995;&#21015;&#20219;&#21153;&#65292;&#20854;&#20013;&#25968;&#25454;&#20998;&#24067;&#20174;&#19968;&#20010;&#20219;&#21153;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20219;&#21153;&#12290;&#22312;&#35757;&#32451;&#26032;&#20219;&#21153;&#25968;&#25454;&#26102;&#65292;&#26087;&#20219;&#21153;&#30340;&#25968;&#25454;&#34920;&#31034;&#21487;&#33021;&#20250;&#28418;&#31227;&#12290;&#19968;&#20123;&#36127;&#38754;&#30340;&#34920;&#31034;&#28418;&#31227;&#21487;&#33021;&#20250;&#23548;&#33268;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#22240;&#20026;&#20250;&#23548;&#33268;&#20174;&#26412;&#22320;&#23398;&#20064;&#30340;&#31867;&#21035;&#21407;&#22411;&#21644;&#25968;&#25454;&#34920;&#31034;&#22312;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#36739;&#24046;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#31181;&#34920;&#31034;&#28418;&#31227;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20840;&#23616;&#21407;&#22411;&#25351;&#23548;&#23398;&#20064;&#65292;&#29992;&#33258;&#30417;&#30563;&#20449;&#24687;&#30340;&#27491;&#21017;&#21270;&#26469;&#23398;&#20064;&#25968;&#25454;&#34920;&#31034;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#23545;&#20110;NLP&#20219;&#21153;&#65292;&#25105;&#20204;&#23558;&#27599;&#20010;&#20219;&#21153;&#20197;&#23631;&#34109;&#35821;&#35328;&#24314;&#27169;&#30340;&#26041;&#24335;&#36827;&#34892;&#20844;&#24335;&#21270;&#65292;&#24182;&#36890;&#36807;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#30456;&#37051;&#27880;&#24847;&#26426;&#21046;&#23398;&#20064;&#20219;&#21153;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#23398;&#20064;&#20986;&#20855;&#26377;&#36739;&#23569;&#34920;&#31034;&#28418;&#31227;&#30340;&#30456;&#24403;&#19968;&#33268;&#30340;&#34920;&#31034;&#65292;&#24182;&#22312;&#19981;&#37325;&#26032;&#37319;&#26679;&#36807;&#21435;&#20219;&#21153;&#30340;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#20943;&#23569;&#25345;&#32493;&#23398;&#20064;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;
&lt;/p&gt;
&lt;p&gt;
Continual learning (CL) aims to learn a sequence of tasks over time, with data distributions shifting from one task to another. When training on new task data, data representations from old tasks may drift. Some negative representation drift can result in catastrophic forgetting, by causing the locally learned class prototypes and data representations to correlate poorly across tasks. To mitigate such representation drift, we propose a method that finds global prototypes to guide the learning, and learns data representations with the regularization of the self-supervised information. Specifically, for NLP tasks, we formulate each task in a masked language modeling style, and learn the task via a neighbor attention mechanism over a pre-trained language model. Experimental results show that our proposed method can learn fairly consistent representations with less representation drift, and significantly reduce catastrophic forgetting in CL without resampling data from past tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#22686;&#24378;&#30340;&#24515;&#30005;&#22270;&#21487;&#20197;&#26377;&#25928;&#22320;&#35782;&#21035;&#26032;&#21457;&#31958;&#23615;&#30149;&#25104;&#20154;&#24739;&#32773;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;ADA&#39118;&#38505;&#26816;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#29305;&#24322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.02900</link><description>&lt;p&gt;
&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#22686;&#24378;&#30340;&#24515;&#30005;&#22270;&#36827;&#34892;&#26032;&#21457;&#31958;&#23615;&#30149;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
New-Onset Diabetes Assessment Using Artificial Intelligence-Enhanced Electrocardiography. (arXiv:2205.02900v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#22686;&#24378;&#30340;&#24515;&#30005;&#22270;&#21487;&#20197;&#26377;&#25928;&#22320;&#35782;&#21035;&#26032;&#21457;&#31958;&#23615;&#30149;&#25104;&#20154;&#24739;&#32773;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;ADA&#39118;&#38505;&#26816;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#29305;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26410;&#35786;&#26029;&#30340;&#31958;&#23615;&#30149;&#22312;&#24739;&#32773;&#20013;&#21344;21.4&#65285;&#65292;&#30001;&#20110;&#31579;&#26597;&#29575;&#30340;&#38480;&#21046;&#65292;&#31958;&#23615;&#30149;&#21487;&#33021;&#28508;&#20239;&#26080;&#30151;&#29366;&#32780;&#26410;&#34987;&#26816;&#27979;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#22686;&#24378;&#30340;&#24515;&#30005;&#22270;&#65288;ECG&#65289;&#26469;&#30830;&#23450;&#26032;&#21457;&#31958;&#23615;&#30149;&#30340;&#25104;&#20154;&#24739;&#32773;&#12290; &#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#20351;&#29992;12&#23548;&#32852;&#24515;&#30005;&#22270;&#21644;&#21487;&#29992;&#30340;&#20154;&#21475;&#32479;&#35745;&#23398;&#25968;&#25454;&#26469;&#20272;&#35745;HbA1c&#12290; &#25105;&#20204;&#22238;&#39038;&#24615;&#22320;&#25910;&#38598;&#20102;&#19968;&#32452;&#21253;&#21547;&#26377;&#37197;&#23545;&#30340;ECG&#21644;HbA1c&#25968;&#25454;&#30340;&#30149;&#20154;&#25968;&#25454;&#38598;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;ADA&#39118;&#38505;&#26816;&#27979;&#65292;&#22522;&#20110;ECG&#30340;&#35780;&#20272;&#25928;&#26524;&#26356;&#22909;&#12290;AI&#22686;&#24378;&#30340;ECG&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#36798;&#21040;81&#65285;&#65292;&#28789;&#25935;&#24230;&#20026;80&#65285;&#65292;&#29305;&#24322;&#24615;&#20026;82&#65285;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20154;&#24037;&#26234;&#33021;&#22686;&#24378;&#30340;ECG&#21487;&#20197;&#25104;&#20026;&#26032;&#21457;&#31958;&#23615;&#30149;&#25104;&#20154;&#24739;&#32773;&#30340;&#19968;&#20010;&#26377;&#21069;&#26223;&#30340;&#24037;&#20855;&#65292;&#29305;&#21035;&#26159;&#22312;&#20256;&#32479;&#31579;&#26597;&#26041;&#27861;&#26377;&#38480;&#30340;&#20154;&#32676;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Undiagnosed diabetes is present in 21.4% of adults with diabetes. Diabetes can remain asymptomatic and undetected due to limitations in screening rates. To address this issue, questionnaires, such as the American Diabetes Association (ADA) Risk test, have been recommended for use by physicians and the public. Based on evidence that blood glucose concentration can affect cardiac electrophysiology, we hypothesized that an artificial intelligence (AI)-enhanced electrocardiogram (ECG) could identify adults with new-onset diabetes. We trained a neural network to estimate HbA1c using a 12-lead ECG and readily available demographics. We retrospectively assembled a dataset comprised of patients with paired ECG and HbA1c data. The population of patients who receive both an ECG and HbA1c may a biased sample of the complete outpatient population, so we adjusted the importance placed on each patient to generate a more representative pseudo-population. We found ECG-based assessment outperforms the 
&lt;/p&gt;</description></item></channel></rss>