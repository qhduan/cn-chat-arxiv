<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#23581;&#35797;&#24635;&#32467;&#21644;&#35780;&#20272;&#30001;&#35813;&#39046;&#22495;&#36804;&#20170;&#36827;&#23637;&#32780;&#24418;&#25104;&#30340;NLP&#39564;&#35777;&#27969;&#31243;&#30340;&#19968;&#33324;&#32452;&#25104;&#37096;&#20998;&#65292;&#36129;&#29486;&#22312;&#20110;&#25552;&#20986;&#20102;&#23558;&#21477;&#23376;&#23884;&#20837;&#36830;&#32493;&#31354;&#38388;&#24471;&#21040;&#30340;&#21487;&#39564;&#35777;&#23376;&#31354;&#38388;&#30340;&#19968;&#33324;&#25551;&#36848;&#12290;</title><link>https://arxiv.org/abs/2403.10144</link><description>&lt;p&gt;
NLP&#39564;&#35777;&#65306;&#36208;&#21521;&#19968;&#31181;&#36890;&#29992;&#30340;&#29992;&#20110;&#35748;&#35777;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#35770;
&lt;/p&gt;
&lt;p&gt;
NLP Verification: Towards a General Methodology for Certifying Robustness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23581;&#35797;&#24635;&#32467;&#21644;&#35780;&#20272;&#30001;&#35813;&#39046;&#22495;&#36804;&#20170;&#36827;&#23637;&#32780;&#24418;&#25104;&#30340;NLP&#39564;&#35777;&#27969;&#31243;&#30340;&#19968;&#33324;&#32452;&#25104;&#37096;&#20998;&#65292;&#36129;&#29486;&#22312;&#20110;&#25552;&#20986;&#20102;&#23558;&#21477;&#23376;&#23884;&#20837;&#36830;&#32493;&#31354;&#38388;&#24471;&#21040;&#30340;&#21487;&#39564;&#35777;&#23376;&#31354;&#38388;&#30340;&#19968;&#33324;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#21151;&#65292;&#30830;&#20445;&#23427;&#20204;&#30340;&#23433;&#20840;&#24615;&#21644;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#65306;&#22312;&#23433;&#20840;&#20851;&#38190;&#30340;&#24773;&#22659;&#20013;&#65292;&#36825;&#20123;&#27169;&#22411;&#24517;&#39035;&#23545;&#21464;&#21270;&#25110;&#25915;&#20987;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#33021;&#23545;&#20854;&#36755;&#20986;&#32473;&#20986;&#20445;&#35777;&#12290;&#19982;&#35745;&#31639;&#26426;&#35270;&#35273;&#19981;&#21516;&#65292;NLP&#32570;&#20047;&#19968;&#20010;&#32479;&#19968;&#30340;&#39564;&#35777;&#26041;&#27861;&#35770;&#65292;&#23613;&#31649;&#36817;&#24180;&#26469;&#25991;&#29486;&#20013;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#23545;&#20110;NLP&#39564;&#35777;&#30340;&#23454;&#29992;&#38382;&#39064;&#24120;&#24120;&#28041;&#21450;&#19981;&#28145;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23581;&#35797;&#25552;&#28860;&#21644;&#35780;&#20272;&#19968;&#20010;NLP&#39564;&#35777;&#27969;&#31243;&#30340;&#19968;&#33324;&#32452;&#25104;&#37096;&#20998;&#65292;&#35813;&#27969;&#31243;&#26469;&#28304;&#20110;&#36804;&#20170;&#20026;&#27490;&#35813;&#39046;&#22495;&#30340;&#36827;&#23637;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26377;&#20004;&#26041;&#38754;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23558;&#21477;&#23376;&#23884;&#20837;&#36830;&#32493;&#31354;&#38388;&#24471;&#21040;&#30340;&#21487;&#39564;&#35777;&#23376;&#31354;&#38388;&#30340;&#19968;&#33324;&#25551;&#36848;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#21487;&#39564;&#35777;&#23376;&#31354;&#38388;&#30340;&#35821;&#20041;&#27867;&#21270;&#25216;&#26415;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10144v1 Announce Type: cross  Abstract: Deep neural networks have exhibited substantial success in the field of Natural Language Processing (NLP) and ensuring their safety and reliability is crucial: there are safety critical contexts where such models must be robust to variability or attack, and give guarantees over their output. Unlike Computer Vision, NLP lacks a unified verification methodology and, despite recent advancements in literature, they are often light on the pragmatical issues of NLP verification. In this paper, we make an attempt to distil and evaluate general components of an NLP verification pipeline, that emerges from the progress in the field to date. Our contributions are two-fold. Firstly, we give a general characterisation of verifiable subspaces that result from embedding sentences into continuous spaces. We identify, and give an effective method to deal with, the technical challenge of semantic generalisability of verified subspaces; and propose it a
&lt;/p&gt;</description></item><item><title>&#35843;&#26597;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#31181;&#26063;&#21644;&#24615;&#21035;&#20559;&#35265;&#65292;&#23588;&#20854;&#23545;&#19982;&#40657;&#20154;&#22899;&#24615;&#30456;&#20851;&#30340;&#21517;&#23383;&#34920;&#29616;&#26368;&#19981;&#21033;&#12290;&#23457;&#35745;&#22312;&#27169;&#22411;&#37096;&#32626;&#21644;&#23454;&#26045;&#26102;&#30340;&#37325;&#35201;&#24615;&#24471;&#21040;&#24378;&#35843;&#12290;</title><link>https://arxiv.org/abs/2402.14875</link><description>&lt;p&gt;
&#21517;&#23383;&#30340;&#21547;&#20041;&#26159;&#20160;&#20040;&#65311;&#23457;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#31181;&#26063;&#21644;&#24615;&#21035;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
What's in a Name? Auditing Large Language Models for Race and Gender Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14875
&lt;/p&gt;
&lt;p&gt;
&#35843;&#26597;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#31181;&#26063;&#21644;&#24615;&#21035;&#20559;&#35265;&#65292;&#23588;&#20854;&#23545;&#19982;&#40657;&#20154;&#22899;&#24615;&#30456;&#20851;&#30340;&#21517;&#23383;&#34920;&#29616;&#26368;&#19981;&#21033;&#12290;&#23457;&#35745;&#22312;&#27169;&#22411;&#37096;&#32626;&#21644;&#23454;&#26045;&#26102;&#30340;&#37325;&#35201;&#24615;&#24471;&#21040;&#24378;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37319;&#29992;&#23457;&#35745;&#35774;&#35745;&#26469;&#35843;&#26597;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#65292;&#21253;&#25324;GPT-4&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#21457;&#27169;&#22411;&#22312;&#21508;&#31181;&#24773;&#26223;&#19979;&#20026;&#20010;&#20154;&#25552;&#20379;&#24314;&#35758;&#65292;&#27604;&#22914;&#22312;&#36141;&#36710;&#35848;&#21028;&#25110;&#36873;&#20030;&#32467;&#26524;&#39044;&#27979;&#36807;&#31243;&#20013;&#12290;&#25105;&#20204;&#21457;&#29616;&#35813;&#24314;&#35758;&#31995;&#32479;&#24615;&#22320;&#23545;&#19982;&#31181;&#26063;&#23569;&#25968;&#32676;&#20307;&#21644;&#22899;&#24615;&#24120;&#35265;&#30456;&#20851;&#30340;&#21517;&#23383;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#19982;&#40657;&#20154;&#22899;&#24615;&#30456;&#20851;&#30340;&#21517;&#23383;&#24471;&#21040;&#30340;&#32467;&#26524;&#26368;&#19981;&#21033;&#12290;&#36825;&#20123;&#20559;&#35265;&#22312;42&#20010;&#25552;&#31034;&#27169;&#26495;&#21644;&#22810;&#20010;&#27169;&#22411;&#20013;&#37117;&#26159;&#19968;&#33268;&#30340;&#65292;&#34920;&#26126;&#36825;&#26159;&#19968;&#20010;&#31995;&#32479;&#24615;&#38382;&#39064;&#65292;&#32780;&#19981;&#26159;&#23396;&#31435;&#20107;&#20214;&#12290;&#22312;&#25552;&#31034;&#20013;&#25552;&#20379;&#25968;&#20540;&#12289;&#19982;&#20915;&#31574;&#30456;&#20851;&#30340;&#38170;&#28857;&#21487;&#20197;&#25104;&#21151;&#25269;&#28040;&#20559;&#35265;&#65292;&#32780;&#23450;&#24615;&#32454;&#33410;&#30340;&#24433;&#21709;&#24182;&#19981;&#19968;&#33268;&#65292;&#29978;&#33267;&#21487;&#33021;&#20250;&#21152;&#21095;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#24378;&#35843;&#20102;&#22312;&#35821;&#35328;&#27169;&#22411;&#37096;&#32626;&#21644;&#23454;&#26045;&#26102;&#36827;&#34892;&#23457;&#35745;&#30340;&#37325;&#35201;&#24615;&#65292;&#20197;&#20943;&#36731;&#20854;&#28508;&#22312;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14875v1 Announce Type: cross  Abstract: We employ an audit design to investigate biases in state-of-the-art large language models, including GPT-4. In our study, we elicit prompt the models for advice regarding an individual across a variety of scenarios, such as during car purchase negotiations or election outcome predictions. We find that the advice systematically disadvantages names that are commonly associated with racial minorities and women. Names associated with Black women receive the least advantageous outcomes. The biases are consistent across 42 prompt templates and several models, indicating a systemic issue rather than isolated incidents. While providing numerical, decision-relevant anchors in the prompt can successfully counteract the biases, qualitative details have inconsistent effects and may even increase disparities. Our findings underscore the importance of conducting audits at the point of LLM deployment and implementation to mitigate their potential for
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#35270;&#35282;&#65292;&#28145;&#20837;&#30740;&#31350;&#20102;LLMs&#20013;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#21644;&#20986;&#29616;&#29616;&#35937;&#12290;&#36890;&#36807;&#24341;&#20837;&#33258;&#32452;&#32455;&#21644;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#30340;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#30340;&#21160;&#24577;&#28436;&#21270;&#36807;&#31243;&#65292;&#23588;&#20854;&#20851;&#27880;&#35757;&#32451;&#20013;&#30340;&#22797;&#26434;&#34892;&#20026;&#12290;&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#31070;&#32463;&#20803;&#30340;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#22823;&#22411;&#27169;&#22411;&#20013;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#30340;&#23450;&#37327;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.09099</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#35270;&#35282;&#25506;&#32034;LLMs&#20013;&#30340;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#21644;&#20986;&#29616;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09099
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#35270;&#35282;&#65292;&#28145;&#20837;&#30740;&#31350;&#20102;LLMs&#20013;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#21644;&#20986;&#29616;&#29616;&#35937;&#12290;&#36890;&#36807;&#24341;&#20837;&#33258;&#32452;&#32455;&#21644;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#30340;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#30340;&#21160;&#24577;&#28436;&#21270;&#36807;&#31243;&#65292;&#23588;&#20854;&#20851;&#27880;&#35757;&#32451;&#20013;&#30340;&#22797;&#26434;&#34892;&#20026;&#12290;&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#31070;&#32463;&#20803;&#30340;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#22823;&#22411;&#27169;&#22411;&#20013;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#30340;&#23450;&#37327;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20197;&#24448;&#30340;&#22823;&#22411;&#27169;&#22411;&#20013;&#65292;&#20851;&#20110;&#20986;&#29616;&#29616;&#35937;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21151;&#33021;&#33021;&#21147;&#22914;&#20309;&#38543;&#27169;&#22411;&#35268;&#27169;&#30340;&#25193;&#22823;&#32780;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36229;&#36234;&#20102;&#36825;&#19968;&#20256;&#32479;&#33539;&#24335;&#65292;&#26088;&#22312;&#36890;&#36807;&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#27169;&#22411;&#35268;&#27169;&#65292;&#32780;&#26356;&#21152;&#20851;&#27880;&#35757;&#32451;&#36807;&#31243;&#20013;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#30340;&#22797;&#26434;&#34892;&#20026;&#65292;&#21152;&#28145;&#25105;&#20204;&#23545;LLMs&#20869;&#37096;&#20986;&#29616;&#29616;&#35937;&#30340;&#29702;&#35299;&#12290;&#36890;&#36807;&#24341;&#20837;&#8220;&#33258;&#32452;&#32455;&#8221;&#21644;&#8220;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#8221;&#27010;&#24565;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#22914;&#20309;&#21160;&#24577;&#28436;&#21270;&#65292;&#20174;&#32780;&#23548;&#33268;&#8220;&#20986;&#29616;&#29616;&#35937;&#8221;&#65292;&#36825;&#31181;&#29616;&#35937;&#21453;&#26144;&#20102;&#33258;&#28982;&#31995;&#32479;&#20013;&#31616;&#21333;&#30340;&#24494;&#35266;&#30456;&#20114;&#20316;&#29992;&#22914;&#20309;&#23548;&#33268;&#22797;&#26434;&#30340;&#23439;&#35266;&#34892;&#20026;&#12290;&#20026;&#20102;&#23450;&#37327;&#20998;&#26512;&#35757;&#32451;&#36807;&#31243;&#20013;&#22823;&#22411;&#27169;&#22411;&#20013;&#31070;&#32463;&#20803;&#20043;&#38388;&#19981;&#26029;&#28436;&#21270;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#31070;&#32463;&#20803;&#30340;&#22810;&#37325;&#20998;&#24418;&#20998;&#26512;&#65288;NeuroMFA&#65289;&#12290;&#21033;&#29992;NeuroMFA&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#30340;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09099v1 Announce Type: new Abstract: Prior studies on the emergence in large models have primarily focused on how the functional capabilities of large language models (LLMs) scale with model size. Our research, however, transcends this traditional paradigm, aiming to deepen our understanding of the emergence within LLMs by placing a special emphasis not just on the model size but more significantly on the complex behavior of neuron interactions during the training process. By introducing the concepts of "self-organization" and "multifractal analysis," we explore how neuron interactions dynamically evolve during training, leading to "emergence," mirroring the phenomenon in natural systems where simple micro-level interactions give rise to complex macro-level behaviors. To quantitatively analyze the continuously evolving interactions among neurons in large models during training, we propose the Neuron-based Multifractal Analysis (NeuroMFA). Utilizing NeuroMFA, we conduct a com
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20998;&#26694;&#26550;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#23450;&#20041;&#22312;&#30417;&#31649;&#26041;&#38754;&#30340;&#21512;&#36866;&#24615;&#12290;&#30740;&#31350;&#26088;&#22312;&#25490;&#38500;&#36890;&#36807;AI&#30417;&#31649;&#25552;&#26696;&#25152;&#37319;&#29992;&#30340;&#19981;&#24688;&#24403;&#30340;AI&#23450;&#20041;&#23545;ICT&#25216;&#26415;&#12289;&#26041;&#27861;&#21644;&#38750;AI&#20316;&#21697;&#30340;&#24433;&#21709;&#65292;&#24182;&#22238;&#24402;&#21040;&#20197;&#21069;&#22312;&#20854;&#20182;&#25104;&#21151;&#25216;&#26415;&#30417;&#31649;&#20013;&#35266;&#23519;&#21040;&#30340;&#21407;&#21017;&#12290;</title><link>https://arxiv.org/abs/2402.05048</link><description>&lt;p&gt;
&#20320;&#30340;AI&#26377;&#22810;&#20040;VADER&#65311;&#38754;&#21521;&#36866;&#29992;&#20110;&#30417;&#31649;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23450;&#20041;&#30340;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20998;&#26694;&#26550;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#23450;&#20041;&#22312;&#30417;&#31649;&#26041;&#38754;&#30340;&#21512;&#36866;&#24615;&#12290;&#30740;&#31350;&#26088;&#22312;&#25490;&#38500;&#36890;&#36807;AI&#30417;&#31649;&#25552;&#26696;&#25152;&#37319;&#29992;&#30340;&#19981;&#24688;&#24403;&#30340;AI&#23450;&#20041;&#23545;ICT&#25216;&#26415;&#12289;&#26041;&#27861;&#21644;&#38750;AI&#20316;&#21697;&#30340;&#24433;&#21709;&#65292;&#24182;&#22238;&#24402;&#21040;&#20197;&#21069;&#22312;&#20854;&#20182;&#25104;&#21151;&#25216;&#26415;&#30417;&#31649;&#20013;&#35266;&#23519;&#21040;&#30340;&#21407;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#25512;&#21160;&#20102;&#35768;&#22810;&#20449;&#24687;&#21644;&#36890;&#20449;&#25216;&#26415;&#65288;ICT&#65289;&#31361;&#30772;&#12290;&#28982;&#32780;&#65292;&#33258;&#22270;&#28789;&#27979;&#35797;&#25552;&#35758;&#20197;&#26469;&#65292;ICT&#31995;&#32479;&#30340;&#33539;&#22260;&#24050;&#36828;&#36828;&#36229;&#20986;&#20102;AI&#12290;&#20851;&#38190;&#26159;&#65292;&#26368;&#36817;&#30340;AI&#30417;&#31649;&#25552;&#26696;&#37319;&#29992;&#20102;&#24433;&#21709;ICT&#25216;&#26415;&#12289;&#26041;&#27861;&#21644;&#31995;&#32479;&#30340;AI&#23450;&#20041;&#65292;&#32780;&#36825;&#20123;&#24182;&#19981;&#26159;AI&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#29978;&#33267;&#21253;&#25324;&#25968;&#23398;&#12289;&#32479;&#35745;&#21644;&#24037;&#31243;&#39046;&#22495;&#30340;&#20316;&#21697;&#20063;&#20250;&#21463;&#21040;&#24433;&#21709;&#12290;&#20196;&#20154;&#25285;&#24551;&#30340;&#26159;&#65292;&#20174;&#35199;&#26041;&#31038;&#20250;&#21040;&#20840;&#29699;&#21335;&#26041;&#65292;&#37117;&#21457;&#29616;&#20102;AI&#23450;&#20041;&#19978;&#30340;&#38169;&#35823;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20998;&#26694;&#26550;&#65292;&#29992;&#20110;&#34913;&#37327;AI&#23450;&#20041;&#22312;&#30417;&#31649;&#26041;&#38754;&#30340;&#21512;&#36866;&#24615;&#12290;&#25105;&#20204;&#30340;&#22312;&#32447;&#12289;&#20844;&#24320;&#21487;&#29992;&#30340;VADER&#26694;&#26550;&#35780;&#20998;&#20102;&#24212;&#35813;&#20316;&#20026;AI&#23450;&#20041;&#30340;&#21069;&#25552;&#30340;&#35206;&#30422;&#33539;&#22260;&#65292;&#36825;&#20123;&#23450;&#20041;&#26088;&#22312;&#65288;i&#65289;&#37325;&#29616;&#20854;&#20182;&#25104;&#21151;&#25216;&#26415;&#30417;&#31649;&#20013;&#35266;&#23519;&#21040;&#30340;&#21407;&#21017;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#21253;&#25324;&#25152;&#26377;&#30340;AI&#25216;&#26415;&#21644;&#26041;&#27861;&#65292;&#21516;&#26102;&#25490;&#38500;&#38750;AI&#30340;&#20316;&#21697;&#12290;&#20851;&#20110;&#21518;&#32773;&#65292;&#25105;&#20204;&#30340;&#35780;&#20998;&#22522;&#20110;&#19968;&#31181;...
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence (AI) has driven many information and communication technology (ICT) breakthroughs. Nonetheless, the scope of ICT systems has expanded far beyond AI since the Turing test proposal. Critically, recent AI regulation proposals adopt AI definitions affecting ICT techniques, approaches, and systems that are not AI. In some cases, even works from mathematics, statistics, and engineering would be affected. Worryingly, AI misdefinitions are observed from Western societies to the Global South. In this paper, we propose a framework to score how \textit{validated as appropriately-defined for regulation} (VADER) an AI definition is. Our online, publicly-available VADER framework scores the coverage of premises that should underlie AI definitions for regulation, which aim to (i) reproduce principles observed in other successful technology regulations, and (ii) include all AI techniques and approaches while excluding non-AI works. Regarding the latter, our score is based on a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20840;&#38754;&#35843;&#26597;&#20102;&#23569;&#26679;&#26412;&#23398;&#20064;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25506;&#35752;&#20102;&#35813;&#26041;&#27861;&#22312;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#38480;&#21046;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.03017</link><description>&lt;p&gt;
&#21521;&#32511;&#33394;&#19988;&#31867;&#20154;&#30340;&#20154;&#24037;&#26234;&#33021;&#36808;&#36827;&#65306;&#24403;&#20195;&#23569;&#26679;&#26412;&#23398;&#20064;&#26041;&#27861;&#30340;&#20840;&#38754;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Toward Green and Human-Like Artificial Intelligence: A Complete Survey on Contemporary Few-Shot Learning Approaches
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03017
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#35843;&#26597;&#20102;&#23569;&#26679;&#26412;&#23398;&#20064;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25506;&#35752;&#20102;&#35813;&#26041;&#27861;&#22312;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#38480;&#21046;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#21462;&#24471;&#20102;&#24191;&#27867;&#30340;&#25104;&#21151;&#65292;&#20294;&#20854;&#23545;&#25968;&#25454;&#30340;&#38656;&#27714;&#21644;&#35745;&#31639;&#30340;&#26114;&#36149;&#24615;&#20351;&#20854;&#22312;&#35768;&#22810;&#25968;&#25454;&#21463;&#38480;&#30340;&#30495;&#23454;&#24212;&#29992;&#20013;&#19981;&#23454;&#29992;&#12290;&#23569;&#26679;&#26412;&#23398;&#20064;&#65288;FSL&#65289;&#26088;&#22312;&#36890;&#36807;&#23454;&#29616;&#23545;&#26032;&#23398;&#20064;&#20219;&#21153;&#30340;&#24555;&#36895;&#36866;&#24212;&#26469;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#24182;&#22312;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#26174;&#33879;&#21457;&#23637;&#12290;&#26412;&#35843;&#26597;&#25552;&#20379;&#20102;&#35813;&#39046;&#22495;&#26368;&#26032;&#36827;&#23637;&#30340;&#20840;&#38754;&#27010;&#36848;&#12290;&#39318;&#20808;&#65292;&#27491;&#24335;&#23450;&#20041;&#20102;FSL&#65292;&#24182;&#20171;&#32461;&#20102;&#23427;&#19982;&#19981;&#21516;&#23398;&#20064;&#39046;&#22495;&#30340;&#20851;&#31995;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#25193;&#23637;&#20102;&#20197;&#21069;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23545;&#32463;&#20856;&#21644;&#26032;&#39046;&#22495;&#20013;&#30340;&#23454;&#38469;&#24212;&#29992;&#36827;&#34892;&#20102;&#25551;&#36848;&#12290;&#26368;&#21518;&#65292;&#35752;&#35770;&#20102;&#22609;&#36896;&#35813;&#39046;&#22495;&#30340;&#26368;&#26032;&#36235;&#21183;&#12289;&#31361;&#20986;&#25361;&#25112;&#21644;&#26377;&#21069;&#36884;&#30340;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite deep learning's widespread success, its data-hungry and computationally expensive nature makes it impractical for many data-constrained real-world applications. Few-Shot Learning (FSL) aims to address these limitations by enabling rapid adaptation to novel learning tasks, seeing significant growth in recent years. This survey provides a comprehensive overview of the field's latest advancements. Initially, FSL is formally defined, and its relationship with different learning fields is presented. A novel taxonomy is introduced, extending previously proposed ones, and real-world applications in classic and novel fields are described. Finally, recent trends shaping the field, outstanding challenges, and promising future research directions are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25903;&#25345;&#31574;&#30053;&#30340;&#31639;&#27861; $\texttt{THREAD}$&#65292;&#21487;&#20197;&#20026;&#20915;&#31574;&#32773;&#25552;&#20379;&#19981;&#21516;&#24418;&#24335;&#30340;&#25903;&#25345;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102; $\texttt{Modiste}$ &#24037;&#20855;&#26469;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#21307;&#23398;&#35786;&#26029;&#20915;&#31574;&#25903;&#25345;&#65292;&#20351;&#29992; $\texttt{THREAD}$ &#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25903;&#25345;&#31574;&#30053;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;&#39044;&#26399;&#30340;&#35786;&#26029;&#27491;&#30830;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#20005;&#37325;&#24182;&#21457;&#30151;&#30340;&#39118;&#38505;&#65292;&#21516;&#26102;&#25512;&#33616;&#20102;&#26356;&#23569;&#21644;&#26356;&#20415;&#23452;&#30340;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2304.06701</link><description>&lt;p&gt;
&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25903;&#25345;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Learning Personalized Decision Support Policies. (arXiv:2304.06701v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25903;&#25345;&#31574;&#30053;&#30340;&#31639;&#27861; $\texttt{THREAD}$&#65292;&#21487;&#20197;&#20026;&#20915;&#31574;&#32773;&#25552;&#20379;&#19981;&#21516;&#24418;&#24335;&#30340;&#25903;&#25345;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102; $\texttt{Modiste}$ &#24037;&#20855;&#26469;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#21307;&#23398;&#35786;&#26029;&#20915;&#31574;&#25903;&#25345;&#65292;&#20351;&#29992; $\texttt{THREAD}$ &#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25903;&#25345;&#31574;&#30053;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;&#39044;&#26399;&#30340;&#35786;&#26029;&#27491;&#30830;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#20005;&#37325;&#24182;&#21457;&#30151;&#30340;&#39118;&#38505;&#65292;&#21516;&#26102;&#25512;&#33616;&#20102;&#26356;&#23569;&#21644;&#26356;&#20415;&#23452;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#20307;&#20915;&#31574;&#32773;&#21487;&#33021;&#38656;&#35201;&#19981;&#21516;&#24418;&#24335;&#30340;&#25903;&#25345;&#26469;&#25552;&#39640;&#20915;&#31574;&#32467;&#26524;&#65292;&#20294;&#37325;&#35201;&#30340;&#38382;&#39064;&#26159;&#65292;&#21738;&#31181;&#24418;&#24335;&#30340;&#25903;&#25345;&#20250;&#22312;&#20302;&#25104;&#26412;&#19979;&#23548;&#33268;&#20934;&#30830;&#30340;&#20915;&#31574;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23398;&#20064;&#20915;&#31574;&#25903;&#25345;&#31574;&#30053;&#30340;&#26041;&#27861;&#65292;&#23427;&#22312;&#32473;&#23450;&#36755;&#20837;&#26102;&#36873;&#25321;&#26159;&#21542;&#20197;&#21450;&#22914;&#20309;&#25552;&#20379;&#25903;&#25345;&#12290;&#25105;&#20204;&#32771;&#34385;&#27809;&#26377;&#20808;&#39564;&#20449;&#24687;&#30340;&#20915;&#31574;&#32773;&#65292;&#24182;&#23558;&#23398;&#20064;&#21508;&#33258;&#30340;&#31574;&#30053;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#36825;&#20010;&#38382;&#39064;&#26435;&#34913;&#20102;&#20934;&#30830;&#24615;&#21644;&#25104;&#26412;&#12290;&#20351;&#29992;&#38543;&#26426;&#29615;&#22659;&#30340;&#25216;&#26415;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; $\texttt{THREAD}$&#65292;&#36825;&#26159;&#19968;&#31181;&#20010;&#24615;&#21270;&#20915;&#31574;&#25903;&#25345;&#31574;&#30053;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#36229;&#21442;&#25968;&#35843;&#25972;&#31574;&#30053;&#65292;&#20197;&#21033;&#29992;&#27169;&#25311;&#20154;&#31867;&#34892;&#20026;&#26469;&#30830;&#23450;&#25104;&#26412;-&#24615;&#33021;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20379;&#35745;&#31639;&#23454;&#39564;&#26469;&#35777;&#26126; $\texttt{THREAD}$ &#30456;&#23545;&#20110;&#32447;&#19979;&#22522;&#32447;&#30340;&#20248;&#21183;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25512;&#20986;&#20102;&#19968;&#20010;&#20132;&#20114;&#24335;&#24037;&#20855; $\texttt{Modiste}$&#65292;&#23427;&#20026;&#29616;&#23454;&#20013;&#30340;&#21307;&#23398;&#35786;&#26029;&#25552;&#20379;&#20010;&#24615;&#21270;&#20915;&#31574;&#25903;&#25345;&#12290;$\texttt{Modiste}$ &#20351;&#29992; $\texttt{THREAD}$ &#20026;&#27599;&#20301;&#21307;&#29983;&#23398;&#20064;&#20010;&#24615;&#21270;&#30340;&#20915;&#31574;&#25903;&#25345;&#31574;&#30053;&#65292;&#24182;&#25512;&#33616;&#20010;&#24615;&#21270;&#30740;&#31350;&#20197;&#20248;&#21270;&#24739;&#32773;&#30340;&#39044;&#26399;&#32467;&#26524;&#24182;&#23558;&#20005;&#37325;&#24182;&#21457;&#30151;&#30340;&#39118;&#38505;&#38477;&#33267;&#26368;&#20302;&#12290;&#20351;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102; $\texttt{Modiste}$ &#26174;&#33879;&#25552;&#39640;&#20102;&#39044;&#26399;&#30340;&#35786;&#26029;&#27491;&#30830;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#20005;&#37325;&#24182;&#21457;&#30151;&#30340;&#39118;&#38505;&#65292;&#21516;&#26102;&#25512;&#33616;&#20102;&#26356;&#23569;&#21644;&#26356;&#20415;&#23452;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individual human decision-makers may benefit from different forms of support to improve decision outcomes. However, a key question is which form of support will lead to accurate decisions at a low cost. In this work, we propose learning a decision support policy that, for a given input, chooses which form of support, if any, to provide. We consider decision-makers for whom we have no prior information and formalize learning their respective policies as a multi-objective optimization problem that trades off accuracy and cost. Using techniques from stochastic contextual bandits, we propose $\texttt{THREAD}$, an online algorithm to personalize a decision support policy for each decision-maker, and devise a hyper-parameter tuning strategy to identify a cost-performance trade-off using simulated human behavior. We provide computational experiments to demonstrate the benefits of $\texttt{THREAD}$ compared to offline baselines. We then introduce $\texttt{Modiste}$, an interactive tool that pr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;24&#31181;&#19981;&#21516;&#37327;&#21270;&#26041;&#27861;&#22312;&#36229;&#36807;40&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20840;&#38754;&#23454;&#35777;&#27604;&#36739;&#65292;&#22635;&#34917;&#20102;&#37327;&#21270;&#26041;&#27861;&#27604;&#36739;&#30740;&#31350;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#20108;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;&#22522;&#20110;&#38408;&#20540;&#36873;&#25321;&#30340;Median Sweep&#21644;TSMax&#26041;&#27861;&#12289;DyS&#26694;&#26550;&#21644;&#24343;&#37324;&#24503;&#26364;&#30340;&#26041;&#27861;&#34920;&#29616;&#26368;&#20339;&#65307;&#32780;&#22312;&#22810;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;Generaliz&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2103.03223</link><description>&lt;p&gt;
&#37327;&#21270;&#26041;&#27861;&#30340;&#27604;&#36739;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A Comparative Evaluation of Quantification Methods. (arXiv:2103.03223v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.03223
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;24&#31181;&#19981;&#21516;&#37327;&#21270;&#26041;&#27861;&#22312;&#36229;&#36807;40&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20840;&#38754;&#23454;&#35777;&#27604;&#36739;&#65292;&#22635;&#34917;&#20102;&#37327;&#21270;&#26041;&#27861;&#27604;&#36739;&#30740;&#31350;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#20108;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;&#22522;&#20110;&#38408;&#20540;&#36873;&#25321;&#30340;Median Sweep&#21644;TSMax&#26041;&#27861;&#12289;DyS&#26694;&#26550;&#21644;&#24343;&#37324;&#24503;&#26364;&#30340;&#26041;&#27861;&#34920;&#29616;&#26368;&#20339;&#65307;&#32780;&#22312;&#22810;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;Generaliz&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#26159;&#25351;&#22312;&#25968;&#25454;&#38598;&#20013;&#39044;&#27979;&#31867;&#21035;&#20998;&#24067;&#30340;&#38382;&#39064;&#12290;&#23427;&#20063;&#20195;&#34920;&#30528;&#19968;&#20010;&#22312;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#26029;&#21457;&#23637;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#36817;&#24180;&#26469;&#25552;&#20986;&#20102;&#22823;&#37327;&#19981;&#21516;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#19968;&#20221;&#20840;&#38754;&#30340;&#23454;&#35777;&#27604;&#36739;&#37327;&#21270;&#26041;&#27861;&#30340;&#30740;&#31350;&#65292;&#20197;&#25903;&#25345;&#31639;&#27861;&#36873;&#25321;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#36229;&#36807;40&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;24&#31181;&#19981;&#21516;&#37327;&#21270;&#26041;&#27861;&#30340;&#24443;&#24213;&#23454;&#35777;&#24615;&#24615;&#33021;&#27604;&#36739;&#65292;&#21253;&#25324;&#20108;&#20998;&#31867;&#21644;&#22810;&#20998;&#31867;&#37327;&#21270;&#35774;&#32622;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#27809;&#26377;&#21333;&#19968;&#31639;&#27861;&#33021;&#22815;&#22312;&#25152;&#26377;&#31454;&#20105;&#23545;&#25163;&#20013;&#22987;&#32456;&#34920;&#29616;&#26368;&#20339;&#65292;&#20294;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#32452;&#22312;&#20108;&#20998;&#31867;&#35774;&#32622;&#20013;&#34920;&#29616;&#26368;&#20339;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#38408;&#20540;&#36873;&#25321;&#30340;Median Sweep&#21644;TSMax&#26041;&#27861;&#12289;DyS&#26694;&#26550;&#21644;&#24343;&#37324;&#24503;&#26364;&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#22810;&#20998;&#31867;&#35774;&#32622;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#21478;&#19968;&#32452;&#31639;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#21253;&#25324;Generaliz&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantification represents the problem of predicting class distributions in a dataset. It also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. However, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. In this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on overall more than 40 data sets, considering binary as well as multiclass quantification settings. We observe that no single algorithm generally outperforms all competitors, but identify a group of methods including the threshold selection-based Median Sweep and TSMax methods, the DyS framework, and Friedman's method that performs best in the binary setting. For the multiclass setting, we observe that a different group of algorithms yields good performance, including the Generaliz
&lt;/p&gt;</description></item></channel></rss>