<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>WiGenAI&#36890;&#36807;&#24341;&#20837;&#25193;&#25955;&#27169;&#22411;&#65292;&#23558;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#20110;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#20013;&#65292;&#20026;&#30740;&#31350;&#22880;&#23450;&#22522;&#30784;&#12290;&#36825;&#31687;&#25991;&#31456;&#20171;&#32461;&#20102;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#26032;&#33539;&#24335;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#22312;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#25193;&#25955;&#27169;&#22411;&#22312;&#24320;&#21457;&#38887;&#24615;&#30340;AI&#26412;&#22320;&#36890;&#20449;&#31995;&#32479;&#20013;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.07312</link><description>&lt;p&gt;
WiGenAI: &#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#26080;&#32447;&#21644;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#20132;&#32455;
&lt;/p&gt;
&lt;p&gt;
WiGenAI: The Symphony of Wireless and Generative AI via Diffusion Models. (arXiv:2310.07312v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07312
&lt;/p&gt;
&lt;p&gt;
WiGenAI&#36890;&#36807;&#24341;&#20837;&#25193;&#25955;&#27169;&#22411;&#65292;&#23558;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#20110;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#20013;&#65292;&#20026;&#30740;&#31350;&#22880;&#23450;&#22522;&#30784;&#12290;&#36825;&#31687;&#25991;&#31456;&#20171;&#32461;&#20102;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#26032;&#33539;&#24335;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#22312;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#25193;&#25955;&#27169;&#22411;&#22312;&#24320;&#21457;&#38887;&#24615;&#30340;AI&#26412;&#22320;&#36890;&#20449;&#31995;&#32479;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21019;&#26032;&#30340;&#22522;&#30784;&#27169;&#22411;&#65292;&#22914;GPT-3&#21644;&#31283;&#23450;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24050;&#32463;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#23454;&#29616;&#20102;&#33539;&#24335;&#36716;&#21464;&#65292;&#21521;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#21457;&#23637;&#12290;&#20174;&#25968;&#25454;&#36890;&#20449;&#21644;&#32593;&#32476;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#20154;&#24037;&#26234;&#33021;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#39044;&#35745;&#23558;&#24191;&#27867;&#24212;&#29992;&#20110;&#26410;&#26469;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#30340;&#26032;&#19968;&#20195;&#20013;&#65292;&#24378;&#35843;&#20102;&#22312;&#26032;&#20852;&#36890;&#20449;&#22330;&#26223;&#20013;&#38656;&#35201;&#26032;&#39062;&#30340;AI&#26412;&#22320;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#20171;&#32461;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#22312;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#65292;&#20026;&#35813;&#39046;&#22495;&#30340;&#30740;&#31350;&#22880;&#23450;&#22522;&#30784;&#12290;&#20171;&#32461;&#20102;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#26032;&#33539;&#24335;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#20204;&#22312;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#12290;&#36824;&#25552;&#20379;&#20102;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#24320;&#21457;&#20855;&#26377;&#38887;&#24615;&#30340;AI&#26412;&#22320;&#36890;&#20449;&#31995;&#32479;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#23637;&#31034;&#20854;&#22312;&#29983;&#25104;&#27169;&#22411;&#30340;&#24212;&#29992;&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Innovative foundation models, such as GPT-3 and stable diffusion models, have made a paradigm shift in the realm of artificial intelligence (AI) towards generative AI-based systems. In unison, from data communication and networking perspective, AI and machine learning (AI/ML) algorithms are envisioned to be pervasively incorporated into the future generations of wireless communications systems, highlighting the need for novel AI-native solutions for the emergent communication scenarios. In this article, we outline the applications of generative AI in wireless communication systems to lay the foundations for research in this field. Diffusion-based generative models, as the new state-of-the-art paradigm of generative models, are introduced, and their applications in wireless communication systems are discussed. Two case studies are also presented to showcase how diffusion models can be exploited for the development of resilient AI-native communication systems. Specifically, we propose de
&lt;/p&gt;</description></item><item><title>MiniGPT-5&#20351;&#29992;&#29983;&#25104;&#20973;&#25454;&#20316;&#20026;&#26725;&#26753;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#20132;&#38169;&#35270;&#35273;&#19982;&#35821;&#35328;&#29983;&#25104;&#25216;&#26415;&#65292;&#24182;&#36890;&#36807;&#29420;&#29305;&#30340;&#20004;&#38454;&#27573;&#35757;&#32451;&#31574;&#30053;&#21644;&#26080;&#20998;&#31867;&#22120;&#30340;&#25351;&#23548;&#26469;&#23454;&#29616;&#26080;&#25551;&#36848;&#30340;&#22810;&#27169;&#24577;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2310.02239</link><description>&lt;p&gt;
MiniGPT-5: &#36890;&#36807;&#29983;&#25104;&#20973;&#25454;&#23454;&#29616;&#20132;&#38169;&#30340;&#35270;&#35273;&#19982;&#35821;&#35328;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens. (arXiv:2310.02239v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02239
&lt;/p&gt;
&lt;p&gt;
MiniGPT-5&#20351;&#29992;&#29983;&#25104;&#20973;&#25454;&#20316;&#20026;&#26725;&#26753;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#20132;&#38169;&#35270;&#35273;&#19982;&#35821;&#35328;&#29983;&#25104;&#25216;&#26415;&#65292;&#24182;&#36890;&#36807;&#29420;&#29305;&#30340;&#20004;&#38454;&#27573;&#35757;&#32451;&#31574;&#30053;&#21644;&#26080;&#20998;&#31867;&#22120;&#30340;&#25351;&#23548;&#26469;&#23454;&#29616;&#26080;&#25551;&#36848;&#30340;&#22810;&#27169;&#24577;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22240;&#20854;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#30340;&#36827;&#23637;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#23637;&#31034;&#20102;&#22312;&#25991;&#26412;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#26080;&#19982;&#20262;&#27604;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#21516;&#26102;&#29983;&#25104;&#20855;&#26377;&#36830;&#36143;&#25991;&#26412;&#21465;&#36848;&#30340;&#22270;&#20687;&#20173;&#28982;&#26159;&#19968;&#20010;&#19981;&#26029;&#21457;&#23637;&#30340;&#21069;&#27839;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#20132;&#38169;&#35270;&#35273;&#19982;&#35821;&#35328;&#29983;&#25104;&#25216;&#26415;&#65292;&#20197;"&#29983;&#25104;&#20973;&#25454;"&#30340;&#27010;&#24565;&#20026;&#22522;&#30784;&#65292;&#20316;&#20026;&#21327;&#35843;&#22270;&#20687;&#25991;&#26412;&#36755;&#20986;&#30340;&#26725;&#26753;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#29305;&#28857;&#26159;&#29420;&#29305;&#30340;&#20004;&#38454;&#27573;&#35757;&#32451;&#31574;&#30053;&#65292;&#37325;&#28857;&#26159;&#26080;&#25551;&#36848;&#30340;&#22810;&#27169;&#24577;&#29983;&#25104;&#65292;&#35757;&#32451;&#36807;&#31243;&#19981;&#38656;&#35201;&#23545;&#22270;&#20687;&#36827;&#34892;&#20840;&#38754;&#30340;&#25551;&#36848;&#12290;&#20026;&#20102;&#22686;&#24378;&#27169;&#22411;&#30340;&#23436;&#25972;&#24615;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#26080;&#20998;&#31867;&#22120;&#30340;&#25351;&#23548;&#65292;&#22686;&#24378;&#20102;&#29983;&#25104;&#20973;&#25454;&#22312;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;MiniGPT-5&#22312;MMDialog&#25968;&#25454;&#38598;&#19978;&#30456;&#27604;&#22522;&#32447;Divter&#27169;&#22411;&#26377;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#22987;&#32456;&#25552;&#20379;&#20248;&#36234;&#25110;&#21487;&#27604;&#30340;&#22810;&#27169;&#24577;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have garnered significant attention for their advancements in natural language processing, demonstrating unparalleled prowess in text comprehension and generation. Yet, the simultaneous generation of images with coherent textual narratives remains an evolving frontier. In response, we introduce an innovative interleaved vision-and-language generation technique anchored by the concept of "generative vokens," acting as the bridge for harmonized image-text outputs. Our approach is characterized by a distinctive two-staged training strategy focusing on description-free multimodal generation, where the training requires no comprehensive descriptions of images. To bolster model integrity, classifier-free guidance is incorporated, enhancing the effectiveness of vokens on image generation. Our model, MiniGPT-5, exhibits substantial improvement over the baseline Divter model on the MMDialog dataset and consistently delivers superior or comparable multimodal outputs 
&lt;/p&gt;</description></item></channel></rss>