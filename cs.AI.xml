<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36890;&#36807;&#24341;&#20837;&#32467;&#26500;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#24341;&#23548;&#30340;SQL&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;SQL&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#25191;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13284</link><description>&lt;p&gt;
&#32467;&#26500;&#24341;&#23548;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;SQL&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Structure Guided Large Language Model for SQL Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13284
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#32467;&#26500;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#24341;&#23548;&#30340;SQL&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;SQL&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#25191;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20934;&#30830;&#30340;&#32467;&#26500;&#21270;&#26597;&#35810;&#35821;&#35328;&#65288;SQL&#65289;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#23558;&#29992;&#25143;&#30340;&#35821;&#20041;&#26597;&#35810;&#19982;&#32467;&#26500;&#21270;&#25968;&#25454;&#24211;&#21305;&#37197;&#65292;&#28982;&#21518;&#29983;&#25104;&#32467;&#26500;&#21270;SQL&#26041;&#38754;&#12290;&#29616;&#26377;&#27169;&#22411;&#36890;&#24120;&#23558;&#26597;&#35810;&#21644;&#25968;&#25454;&#24211;&#27169;&#24335;&#36755;&#20837;&#21040;LLM&#20013;&#65292;&#24182;&#20381;&#36182;LLM&#25191;&#34892;&#35821;&#20041;-&#32467;&#26500;&#21305;&#37197;&#24182;&#29983;&#25104;&#32467;&#26500;&#21270;SQL&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35299;&#20915;&#26041;&#26696;&#24573;&#30053;&#20102;&#29992;&#25143;&#26597;&#35810;&#21644;&#25968;&#25454;&#24211;&#20013;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#32780;&#36825;&#20123;&#20449;&#24687;&#21487;&#20197;&#29992;&#26469;&#22686;&#24378;&#32467;&#26500;&#21270;SQL&#30340;&#29983;&#25104;&#12290;&#36825;&#19968;&#30095;&#24573;&#21487;&#33021;&#23548;&#33268;&#19981;&#20934;&#30830;&#25110;&#26080;&#27861;&#25191;&#34892;&#30340;SQL&#29983;&#25104;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#21040;SQL&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#22266;&#26377;&#30340;&#32467;&#26500;&#20449;&#24687;&#26469;&#25913;&#21892;LLM&#30340;SQL&#29983;&#25104;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#30340;&#32467;&#26500;&#24341;&#23548;SQL&#65288;SGU-SQL&#65289;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13284v1 Announce Type: cross  Abstract: Generating accurate Structured Querying Language (SQL) is a long-standing problem, especially in matching users' semantic queries with structured databases and then generating structured SQL. Existing models typically input queries and database schemas into the LLM and rely on the LLM to perform semantic-structure matching and generate structured SQL. However, such solutions overlook the structural information within user queries and databases, which can be utilized to enhance the generation of structured SQL. This oversight can lead to inaccurate or unexecutable SQL generation. To fully exploit the structure, we propose a structure-to-SQL framework, which leverages the inherent structure information to improve the SQL generation of LLMs. Specifically, we introduce our Structure Guided SQL~(SGU-SQL) generation model. SGU-SQL first links user queries and databases in a structure-enhanced manner. It then decomposes complicated linked str
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#32473;&#20986;&#21709;&#24212;&#26102;&#23384;&#22312;&#19968;&#20010;&#20215;&#20540;&#20559;&#22909;&#30340;&#26426;&#21046;&#65292;&#20542;&#21521;&#20110;&#20559;&#21521;&#29702;&#24819;&#29366;&#24577;&#65292;&#36825;&#31181;&#20559;&#24046;&#20250;&#23545;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.11005</link><description>&lt;p&gt;
&#25506;&#31350;&#20215;&#20540;&#20559;&#22909;&#65306;LLMs&#20559;&#21521;&#29702;&#24819;&#29366;&#24577;&#30340;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Exploring Value Biases: How LLMs Deviate Towards the Ideal
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11005
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#32473;&#20986;&#21709;&#24212;&#26102;&#23384;&#22312;&#19968;&#20010;&#20215;&#20540;&#20559;&#22909;&#30340;&#26426;&#21046;&#65292;&#20542;&#21521;&#20110;&#20559;&#21521;&#29702;&#24819;&#29366;&#24577;&#65292;&#36825;&#31181;&#20559;&#24046;&#20250;&#23545;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34987;&#37096;&#32626;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#21709;&#24212;&#23545;&#31038;&#20250;&#20135;&#29983;&#30528;&#36234;&#26469;&#36234;&#22823;&#30340;&#24433;&#21709;&#12290;&#29702;&#35299;LLMs&#22312;&#32473;&#20986;&#21709;&#24212;&#26102;&#30340;&#38750;&#25925;&#24847;&#26426;&#21046;&#23545;&#20110;&#35299;&#37322;&#23427;&#20204;&#30340;&#24615;&#33021;&#24182;&#36776;&#21035;&#23427;&#20204;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;&#20559;&#24046;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#31867;&#20284;&#20110;&#20154;&#31867;&#30740;&#31350;&#20013;&#65292;&#36825;&#31181;&#26080;&#24847;&#35782;&#30340;&#21709;&#24212;&#34987;&#31216;&#20026;&#25277;&#26679;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#30340;&#36825;&#31181;&#25277;&#26679;&#29616;&#35937;&#65292;&#21457;&#29616;LLMs&#30340;&#25277;&#26679;&#20542;&#21521;&#20110;&#20559;&#29233;&#39640;&#20215;&#20540;&#36873;&#39033;&#12290;&#20215;&#20540;&#20559;&#22909;&#23545;&#24212;&#20110;&#20174;&#26368;&#21487;&#33021;&#30340;&#21709;&#24212;&#21521;LLM&#20013;&#20195;&#34920;&#30340;&#29702;&#24819;&#20215;&#20540;&#30340;&#36716;&#21464;&#12290;&#23454;&#38469;&#19978;&#65292;&#21363;&#20415;&#26159;&#36890;&#36807;&#19978;&#19979;&#25991;&#25552;&#31034;&#23398;&#20064;&#21040;&#30340;&#26032;&#23454;&#20307;&#65292;&#36825;&#31181;&#25928;&#26524;&#20063;&#33021;&#22815;&#20877;&#29616;&#12290;&#25105;&#20204;&#34920;&#26126;&#36825;&#31181;&#20559;&#24046;&#34920;&#29616;&#22312;&#24847;&#24819;&#19981;&#21040;&#30340;&#22320;&#26041;&#65292;&#24182;&#23545;&#36873;&#25321;&#20856;&#22411;&#23454;&#20363;&#31561;&#30456;&#20851;&#24212;&#29992;&#22330;&#26223;&#20135;&#29983;&#24433;&#21709;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#20215;&#20540;&#20559;&#22909;&#22312;&#19981;&#21516;&#20998;&#31867;&#30340;LLMs&#20013;&#37117;&#24456;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11005v1 Announce Type: cross  Abstract: Large-Language-Models (LLMs) are deployed in a wide range of applications, and their response has an increasing social impact. Understanding the non-deliberate(ive) mechanism of LLMs in giving responses is essential in explaining their performance and discerning their biases in real-world applications. This is analogous to human studies, where such inadvertent responses are referred to as sampling. We study this sampling of LLMs in light of value bias and show that the sampling of LLMs tends to favour high-value options. Value bias corresponds to this shift of response from the most likely towards an ideal value represented in the LLM. In fact, this effect can be reproduced even with new entities learnt via in-context prompting. We show that this bias manifests in unexpected places and has implications on relevant application scenarios, like choosing exemplars. The results show that value bias is strong in LLMs across different categor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#38382;&#39064;&#65292;&#21363;&#26410;&#39044;&#26399;&#30340;&#20449;&#24687;&#27745;&#26579;&#35757;&#32451;&#25968;&#25454;&#65292;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#35780;&#20272;&#65292;&#29992;&#25143;&#21487;&#33021;&#30001;&#20110;&#32570;&#20047;&#29702;&#35299;&#32780;&#24573;&#35270;&#20851;&#38190;&#27493;&#39588;&#65292;&#23548;&#33268;&#20048;&#35266;&#30340;&#24615;&#33021;&#20272;&#35745;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#19981;&#25104;&#31435;&#12290;</title><link>http://arxiv.org/abs/2401.13796</link><description>&lt;p&gt;
&#19981;&#35201;&#25353;&#25353;&#38062;&#65281;&#25506;&#32034;&#26426;&#22120;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning. (arXiv:2401.13796v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13796
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#38382;&#39064;&#65292;&#21363;&#26410;&#39044;&#26399;&#30340;&#20449;&#24687;&#27745;&#26579;&#35757;&#32451;&#25968;&#25454;&#65292;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#35780;&#20272;&#65292;&#29992;&#25143;&#21487;&#33021;&#30001;&#20110;&#32570;&#20047;&#29702;&#35299;&#32780;&#24573;&#35270;&#20851;&#38190;&#27493;&#39588;&#65292;&#23548;&#33268;&#20048;&#35266;&#30340;&#24615;&#33021;&#20272;&#35745;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#19981;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#65292;&#20026;&#22810;&#20010;&#39046;&#22495;&#25552;&#20379;&#20102;&#39044;&#27979;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;ML&#24037;&#20855;&#30340;&#26085;&#30410;&#21487;&#33719;&#24471;&#24615;&#65292;&#35768;&#22810;&#20174;&#19994;&#32773;&#32570;&#20047;&#28145;&#20837;&#30340;ML&#19987;&#19994;&#30693;&#35782;&#65292;&#37319;&#29992;&#20102;&#8220;&#25353;&#25353;&#38062;&#8221;&#26041;&#27861;&#65292;&#21033;&#29992;&#29992;&#25143;&#21451;&#22909;&#30340;&#30028;&#38754;&#32780;&#24573;&#35270;&#20102;&#24213;&#23618;&#31639;&#27861;&#30340;&#28145;&#20837;&#29702;&#35299;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#20415;&#21033;&#65292;&#20294;&#23427;&#24341;&#21457;&#20102;&#23545;&#32467;&#26524;&#21487;&#38752;&#24615;&#30340;&#25285;&#24551;&#65292;&#23548;&#33268;&#20102;&#38169;&#35823;&#30340;&#24615;&#33021;&#35780;&#20272;&#31561;&#25361;&#25112;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;ML&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#21363;&#25968;&#25454;&#27844;&#38706;&#65292;&#20854;&#20013;&#26410;&#39044;&#26399;&#30340;&#20449;&#24687;&#27745;&#26579;&#20102;&#35757;&#32451;&#25968;&#25454;&#65292;&#24433;&#21709;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#35780;&#20272;&#12290;&#30001;&#20110;&#32570;&#20047;&#29702;&#35299;&#65292;&#29992;&#25143;&#21487;&#33021;&#20250;&#26080;&#24847;&#20013;&#24573;&#35270;&#20851;&#38190;&#27493;&#39588;&#65292;&#20174;&#32780;&#23548;&#33268;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#30340;&#20048;&#35266;&#24615;&#33021;&#20272;&#35745;&#12290;&#35780;&#20272;&#24615;&#33021;&#19982;&#23454;&#38469;&#22312;&#26032;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#30340;&#24046;&#24322;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20851;&#27880;&#28857;&#12290;&#26412;&#25991;&#29305;&#21035;&#23558;ML&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#20998;&#20026;&#19981;&#21516;&#31867;&#21035;&#65292;&#24182;&#35752;&#35770;&#20102;&#30456;&#20851;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) has revolutionized various domains, offering predictive capabilities in several areas. However, with the increasing accessibility of ML tools, many practitioners, lacking deep ML expertise, adopt a "push the button" approach, utilizing user-friendly interfaces without a thorough understanding of underlying algorithms. While this approach provides convenience, it raises concerns about the reliability of outcomes, leading to challenges such as incorrect performance evaluation. This paper addresses a critical issue in ML, known as data leakage, where unintended information contaminates the training data, impacting model performance evaluation. Users, due to a lack of understanding, may inadvertently overlook crucial steps, leading to optimistic performance estimates that may not hold in real-world scenarios. The discrepancy between evaluated and actual performance on new data is a significant concern. In particular, this paper categorizes data leakage in ML, discussi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#23398;&#20064;&#26377;&#38480;&#33258;&#21160;&#26426;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#32422;&#26463;&#20248;&#21270;&#31639;&#27861;&#21644;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#26696;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14111</link><description>&lt;p&gt;
&#36890;&#36807;&#31163;&#25955;&#20248;&#21270;&#23454;&#29616;&#21487;&#35299;&#37322;&#24615;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Interpretable Anomaly Detection via Discrete Optimization. (arXiv:2303.14111v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14111
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#23398;&#20064;&#26377;&#38480;&#33258;&#21160;&#26426;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#32422;&#26463;&#20248;&#21270;&#31639;&#27861;&#21644;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#26696;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#26816;&#27979;&#22312;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#20013;&#37117;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#20363;&#22914;&#32593;&#32476;&#23433;&#20840;&#12289;&#25191;&#27861;&#12289;&#21307;&#23398;&#21644;&#27450;&#35784;&#20445;&#25252;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#20915;&#31574;&#36807;&#31243;&#24448;&#24448;&#38590;&#20197;&#29702;&#35299;&#65292;&#36825;&#36890;&#24120;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#24212;&#29992;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#24207;&#21015;&#25968;&#25454;&#20013;&#23398;&#20064;&#21487;&#35299;&#37322;&#24615;&#30340;&#24322;&#24120;&#26816;&#27979;&#22120;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20174;&#32473;&#23450;&#30340;&#26410;&#26631;&#35760;&#24207;&#21015;&#22810;&#37325;&#38598;&#20013;&#23398;&#20064;&#30830;&#23450;&#24615;&#26377;&#38480;&#33258;&#21160;&#26426; &#65288;DFA&#65289;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#38382;&#39064;&#26159;&#35745;&#31639;&#38590;&#39064;&#65292;&#24182;&#22522;&#20110;&#32422;&#26463;&#20248;&#21270;&#24320;&#21457;&#20102;&#20004;&#20010;&#23398;&#20064;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#20248;&#21270;&#38382;&#39064;&#24341;&#20837;&#20102;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#26696;&#65292;&#20197;&#25552;&#39640;&#25105;&#20204;&#30340;DFA&#30340;&#25972;&#20307;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#21407;&#22411;&#23454;&#29616;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;F1&#20998;&#25968;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anomaly detection is essential in many application domains, such as cyber security, law enforcement, medicine, and fraud protection. However, the decision-making of current deep learning approaches is notoriously hard to understand, which often limits their practical applicability. To overcome this limitation, we propose a framework for learning inherently interpretable anomaly detectors from sequential data. More specifically, we consider the task of learning a deterministic finite automaton (DFA) from a given multi-set of unlabeled sequences. We show that this problem is computationally hard and develop two learning algorithms based on constraint optimization. Moreover, we introduce novel regularization schemes for our optimization problems that improve the overall interpretability of our DFAs. Using a prototype implementation, we demonstrate that our approach shows promising results in terms of accuracy and F1 score.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#20998;&#21106;&#20219;&#21153;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20845;&#20010;&#24230;&#37327;&#26469;&#35780;&#20272;&#22522;&#20110;&#26799;&#24230;&#12289;&#20256;&#25773;&#25110;&#24178;&#25200;&#30340;&#20107;&#21518;&#21487;&#35270;&#21270;&#35299;&#37322;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#26102;&#38388;&#24207;&#21015;&#30340;&#35299;&#37322;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#20449;&#24230;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.07861</link><description>&lt;p&gt;
&#19981;&#35201;&#35823;&#20250;&#25105;&#65306;&#22914;&#20309;&#23558;&#28145;&#24230;&#35270;&#35273;&#35299;&#37322;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Don't Get Me Wrong: How to Apply Deep Visual Interpretations to Time Series. (arXiv:2203.07861v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.07861
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#20998;&#21106;&#20219;&#21153;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20845;&#20010;&#24230;&#37327;&#26469;&#35780;&#20272;&#22522;&#20110;&#26799;&#24230;&#12289;&#20256;&#25773;&#25110;&#24178;&#25200;&#30340;&#20107;&#21518;&#21487;&#35270;&#21270;&#35299;&#37322;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#26102;&#38388;&#24207;&#21015;&#30340;&#35299;&#37322;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#20449;&#24230;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#27491;&#30830;&#35299;&#37322;&#21644;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38750;&#24120;&#37325;&#35201;&#12290;&#38024;&#23545;&#22270;&#20687;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#35299;&#37322;&#24615;&#35270;&#35273;&#35299;&#37322;&#26041;&#27861;&#20801;&#35768;&#39046;&#22495;&#19987;&#23478;&#39564;&#35777;&#21644;&#29702;&#35299;&#20960;&#20046;&#20219;&#20309;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#24403;&#25512;&#24191;&#21040;&#20219;&#24847;&#26102;&#38388;&#24207;&#21015;&#26102;&#65292;&#23427;&#20204;&#22312;&#26412;&#36136;&#19978;&#26356;&#21152;&#22797;&#26434;&#21644;&#22810;&#26679;&#21270;&#12290;&#19968;&#20010;&#21487;&#35270;&#21270;&#35299;&#37322;&#26159;&#21542;&#35299;&#37322;&#20102;&#26377;&#25928;&#30340;&#25512;&#29702;&#25110;&#25429;&#25417;&#20102;&#23454;&#38469;&#29305;&#24449;&#26159;&#38590;&#20197;&#21028;&#26029;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#38656;&#35201;&#23458;&#35266;&#35780;&#20272;&#26469;&#33719;&#24471;&#21487;&#20449;&#30340;&#36136;&#37327;&#25351;&#26631;&#65292;&#32780;&#19981;&#26159;&#30450;&#30446;&#20449;&#20219;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21253;&#25324;&#20845;&#20010;&#27491;&#20132;&#24230;&#37327;&#65292;&#29992;&#20110;&#38024;&#23545;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#20998;&#21106;&#20219;&#21153;&#30340;&#22522;&#20110;&#26799;&#24230;&#12289;&#20256;&#25773;&#25110;&#24178;&#25200;&#30340;&#20107;&#21518;&#35270;&#35273;&#35299;&#37322;&#26041;&#27861;&#12290;&#23454;&#39564;&#30740;&#31350;&#21253;&#25324;&#20102;&#24120;&#35265;&#30340;&#26102;&#38388;&#24207;&#21015;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20061;&#31181;&#21487;&#35270;&#21270;&#35299;&#37322;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;UCR r&#31561;&#22810;&#26679;&#30340;&#25968;&#25454;&#38598;&#35780;&#20272;&#20102;&#36825;&#20123;&#21487;&#35270;&#21270;&#35299;&#37322;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The correct interpretation and understanding of deep learning models are essential in many applications. Explanatory visual interpretation approaches for image, and natural language processing allow domain experts to validate and understand almost any deep learning model. However, they fall short when generalizing to arbitrary time series, which is inherently less intuitive and more diverse. Whether a visualization explains valid reasoning or captures the actual features is difficult to judge. Hence, instead of blind trust, we need an objective evaluation to obtain trustworthy quality metrics. We propose a framework of six orthogonal metrics for gradient-, propagation- or perturbation-based post-hoc visual interpretation methods for time series classification and segmentation tasks. An experimental study includes popular neural network architectures for time series and nine visual interpretation methods. We evaluate the visual interpretation methods with diverse datasets from the UCR r
&lt;/p&gt;</description></item></channel></rss>