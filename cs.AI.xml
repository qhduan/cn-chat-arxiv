<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23610;&#24230;&#19981;&#21464;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65288;SI-MTL&#65289;&#65292;&#36890;&#36807;&#23545;&#20219;&#21153;&#25439;&#22833;&#36827;&#34892;&#23545;&#25968;&#21464;&#25442;&#21644;&#23545;&#20219;&#21153;&#26799;&#24230;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#35299;&#20915;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#24179;&#34913;&#38382;&#39064;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#39046;&#20808;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12029</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#23610;&#24230;&#19981;&#21464;&#20219;&#21153;&#24179;&#34913;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Scale-Invariant Task Balancing Approach for Multi-Task Learning. (arXiv:2308.12029v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12029
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23610;&#24230;&#19981;&#21464;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65288;SI-MTL&#65289;&#65292;&#36890;&#36807;&#23545;&#20219;&#21153;&#25439;&#22833;&#36827;&#34892;&#23545;&#25968;&#21464;&#25442;&#21644;&#23545;&#20219;&#21153;&#26799;&#24230;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#35299;&#20915;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#24179;&#34913;&#38382;&#39064;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#39046;&#20808;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#26159;&#19968;&#31181;&#21516;&#26102;&#23398;&#20064;&#22810;&#20010;&#30456;&#20851;&#20219;&#21153;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#20219;&#21153;&#24179;&#34913;&#20173;&#28982;&#26159;MTL&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#25439;&#22833;/&#26799;&#24230;&#23610;&#24230;&#30340;&#19981;&#24179;&#34913;&#32463;&#24120;&#23548;&#33268;&#24615;&#33021;&#25240;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23610;&#24230;&#19981;&#21464;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;SI-MTL&#65289;&#26041;&#27861;&#65292;&#20174;&#25439;&#22833;&#21644;&#26799;&#24230;&#35282;&#24230;&#32531;&#35299;&#20102;&#20219;&#21153;&#24179;&#34913;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;SI-MTL&#21253;&#21547;&#23545;&#25152;&#26377;&#20219;&#21153;&#25439;&#22833;&#36827;&#34892;&#30340;&#23545;&#25968;&#21464;&#25442;&#65292;&#20197;&#30830;&#20445;&#22312;&#25439;&#22833;&#27700;&#24179;&#19978;&#20855;&#26377;&#23610;&#24230;&#19981;&#21464;&#24615;&#65292;&#20197;&#21450;&#19968;&#31181;&#26799;&#24230;&#24179;&#34913;&#26041;&#27861;SI-G&#65292;&#23427;&#23558;&#25152;&#26377;&#20219;&#21153;&#30340;&#26799;&#24230;&#24402;&#19968;&#21270;&#20026;&#19982;&#26368;&#22823;&#26799;&#24230;&#33539;&#25968;&#30456;&#21516;&#30340;&#22823;&#23567;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#19968;&#33268;&#35777;&#26126;&#20102;SI-G&#30340;&#26377;&#25928;&#24615;&#21644;SI-MTL&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning (MTL), a learning paradigm to learn multiple related tasks simultaneously, has achieved great success in various fields. However, task-balancing remains a significant challenge in MTL, with the disparity in loss/gradient scales often leading to performance compromises. In this paper, we propose a Scale-Invariant Multi-Task Learning (SI-MTL) method to alleviate the task-balancing problem from both loss and gradient perspectives. Specifically, SI-MTL contains a logarithm transformation which is performed on all task losses to ensure scale-invariant at the loss level, and a gradient balancing method, SI-G, which normalizes all task gradients to the same magnitude as the maximum gradient norm. Extensive experiments conducted on several benchmark datasets consistently demonstrate the effectiveness of SI-G and the state-of-the-art performance of SI-MTL.
&lt;/p&gt;</description></item></channel></rss>