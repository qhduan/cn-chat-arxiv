<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#23433;&#20840;&#38388;&#38548;RRT*&#65288;SI-RRT*&#65289;&#20004;&#32423;&#26041;&#27861;&#65292;&#20302;&#32423;&#37319;&#29992;&#37319;&#26679;&#35268;&#21010;&#22120;&#25214;&#21040;&#21333;&#20010;&#26426;&#22120;&#20154;&#30340;&#26080;&#30896;&#25758;&#36712;&#36857;&#65292;&#39640;&#32423;&#36890;&#36807;&#20248;&#20808;&#35268;&#21010;&#25110;&#22522;&#20110;&#20914;&#31361;&#30340;&#25628;&#32034;&#35299;&#20915;&#26426;&#22120;&#20154;&#38388;&#20914;&#31361;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;SI-RRT*&#33021;&#22815;&#24555;&#36895;&#25214;&#21040;&#39640;&#36136;&#37327;&#35299;&#20915;&#26041;&#26696;</title><link>https://arxiv.org/abs/2404.01752</link><description>&lt;p&gt;
&#23433;&#20840;&#38388;&#38548;RRT*&#29992;&#20110;&#36830;&#32493;&#31354;&#38388;&#20013;&#21487;&#25193;&#23637;&#30340;&#22810;&#26426;&#22120;&#20154;&#36335;&#24452;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Safe Interval RRT* for Scalable Multi-Robot Path Planning in Continuous Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01752
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#23433;&#20840;&#38388;&#38548;RRT*&#65288;SI-RRT*&#65289;&#20004;&#32423;&#26041;&#27861;&#65292;&#20302;&#32423;&#37319;&#29992;&#37319;&#26679;&#35268;&#21010;&#22120;&#25214;&#21040;&#21333;&#20010;&#26426;&#22120;&#20154;&#30340;&#26080;&#30896;&#25758;&#36712;&#36857;&#65292;&#39640;&#32423;&#36890;&#36807;&#20248;&#20808;&#35268;&#21010;&#25110;&#22522;&#20110;&#20914;&#31361;&#30340;&#25628;&#32034;&#35299;&#20915;&#26426;&#22120;&#20154;&#38388;&#20914;&#31361;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;SI-RRT*&#33021;&#22815;&#24555;&#36895;&#25214;&#21040;&#39640;&#36136;&#37327;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#36830;&#32493;&#31354;&#38388;&#20013;&#35299;&#20915;&#22810;&#26426;&#22120;&#20154;&#36335;&#24452;&#35268;&#21010;&#65288;MRPP&#65289;&#38382;&#39064;&#20197;&#25214;&#21040;&#26080;&#20914;&#31361;&#36335;&#24452;&#30340;&#38382;&#39064;&#12290;&#38382;&#39064;&#30340;&#22256;&#38590;&#20027;&#35201;&#26469;&#33258;&#20004;&#20010;&#22240;&#32032;&#12290;&#39318;&#20808;&#65292;&#28041;&#21450;&#22810;&#20010;&#26426;&#22120;&#20154;&#20250;&#23548;&#33268;&#32452;&#21512;&#20915;&#31574;&#65292;&#20351;&#25628;&#32034;&#31354;&#38388;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#20854;&#27425;&#65292;&#36830;&#32493;&#31354;&#38388;&#21576;&#29616;&#20986;&#28508;&#22312;&#26080;&#38480;&#30340;&#29366;&#24577;&#21644;&#21160;&#20316;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#32423;&#26041;&#27861;&#65292;&#20302;&#32423;&#26159;&#22522;&#20110;&#37319;&#26679;&#30340;&#35268;&#21010;&#22120;&#23433;&#20840;&#38388;&#38548;RRT*&#65288;SI-RRT*&#65289;&#65292;&#29992;&#20110;&#25214;&#21040;&#21333;&#20010;&#26426;&#22120;&#20154;&#30340;&#26080;&#30896;&#25758;&#36712;&#36857;&#12290;&#39640;&#32423;&#21487;&#20197;&#20351;&#29992;&#33021;&#22815;&#35299;&#20915;&#26426;&#22120;&#20154;&#38388;&#20914;&#31361;&#30340;&#20219;&#20309;&#26041;&#27861;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#31181;&#20195;&#34920;&#24615;&#26041;&#27861;&#65292;&#21363;&#20248;&#20808;&#35268;&#21010;&#65288;SI-CPP&#65289;&#21644;&#22522;&#20110;&#20914;&#31361;&#30340;&#25628;&#32034;&#65288;SI-CCBS&#65289;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SI-RRT*&#33021;&#22815;&#24555;&#36895;&#25214;&#21040;&#39640;&#36136;&#37327;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#19988;&#25152;&#38656;&#30340;&#26679;&#26412;&#25968;&#37327;&#36739;&#23569;&#12290;SI-CPP&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#32780;SI-CCBS&#20135;&#29983;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01752v1 Announce Type: cross  Abstract: In this paper, we consider the problem of Multi-Robot Path Planning (MRPP) in continuous space to find conflict-free paths. The difficulty of the problem arises from two primary factors. First, the involvement of multiple robots leads to combinatorial decision-making, which escalates the search space exponentially. Second, the continuous space presents potentially infinite states and actions. For this problem, we propose a two-level approach where the low level is a sampling-based planner Safe Interval RRT* (SI-RRT*) that finds a collision-free trajectory for individual robots. The high level can use any method that can resolve inter-robot conflicts where we employ two representative methods that are Prioritized Planning (SI-CPP) and Conflict Based Search (SI-CCBS). Experimental results show that SI-RRT* can find a high-quality solution quickly with a small number of samples. SI-CPP exhibits improved scalability while SI-CCBS produces 
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#24187;&#35273;&#26816;&#27979;&#26088;&#22312;&#22635;&#34917;&#29616;&#26377;&#35268;&#21010;&#32773;&#32570;&#23569;&#30340;&#24120;&#35782;&#25512;&#29702;&#65292;&#20197;&#36866;&#29992;&#20110;&#36229;&#20986;&#20998;&#24067;&#20219;&#21153;&#30340;&#22330;&#26223;&#12290;</title><link>https://arxiv.org/abs/2403.16527</link><description>&lt;p&gt;
&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#24187;&#35273;&#26816;&#27979;&#65306;&#28789;&#27963;&#23450;&#20041;&#19982;&#29616;&#26377;&#25216;&#26415;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16527
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#24187;&#35273;&#26816;&#27979;&#26088;&#22312;&#22635;&#34917;&#29616;&#26377;&#35268;&#21010;&#32773;&#32570;&#23569;&#30340;&#24120;&#35782;&#25512;&#29702;&#65292;&#20197;&#36866;&#29992;&#20110;&#36229;&#20986;&#20998;&#24067;&#20219;&#21153;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20027;&#31995;&#32479;&#21363;&#23558;&#26080;&#22788;&#19981;&#22312;&#65292;&#20174;&#21046;&#36896;&#19994;&#30340;&#33258;&#20027;&#24615;&#21040;&#20892;&#19994;&#39046;&#22495;&#30340;&#26426;&#22120;&#20154;&#65292;&#20174;&#21307;&#30103;&#21161;&#29702;&#21040;&#23089;&#20048;&#20135;&#19994;&#12290;&#22823;&#22810;&#25968;&#31995;&#32479;&#26159;&#36890;&#36807;&#27169;&#22359;&#21270;&#30340;&#23376;&#32452;&#20214;&#24320;&#21457;&#30340;&#65292;&#29992;&#20110;&#20915;&#31574;&#12289;&#35268;&#21010;&#21644;&#25511;&#21046;&#65292;&#36825;&#20123;&#32452;&#20214;&#21487;&#33021;&#26159;&#25163;&#24037;&#35774;&#35745;&#30340;&#65292;&#20063;&#21487;&#33021;&#26159;&#22522;&#20110;&#23398;&#20064;&#30340;&#12290;&#34429;&#28982;&#29616;&#26377;&#26041;&#27861;&#22312;&#23427;&#20204;&#19987;&#38376;&#35774;&#35745;&#30340;&#24773;&#22659;&#19979;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#27979;&#35797;&#26102;&#19981;&#21487;&#36991;&#20813;&#22320;&#20250;&#22312;&#32597;&#35265;&#30340;&#12289;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#30340;&#22330;&#26223;&#19979;&#34920;&#29616;&#29305;&#21035;&#24046;&#12290;&#22522;&#20110;&#22810;&#20010;&#20219;&#21153;&#35757;&#32451;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#20852;&#36215;&#65292;&#20197;&#21450;&#20174;&#21508;&#20010;&#39046;&#22495;&#37319;&#38598;&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#30456;&#20449;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#25552;&#20379;&#29616;&#26377;&#35268;&#21010;&#32773;&#25152;&#32570;&#20047;&#30340;&#24120;&#35782;&#25512;&#29702;&#12290;&#30740;&#31350;&#20154;&#21592;&#35748;&#20026;&#65292;&#36825;&#31181;&#24120;&#35782;&#25512;&#29702;&#23558;&#24357;&#21512;&#31639;&#27861;&#24320;&#21457;&#21644;&#37096;&#32626;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#36866;&#29992;&#20110;&#36229;&#20986;&#20998;&#24067;&#20219;&#21153;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16527v1 Announce Type: new  Abstract: Autonomous systems are soon to be ubiquitous, from manufacturing autonomy to agricultural field robots, and from health care assistants to the entertainment industry. The majority of these systems are developed with modular sub-components for decision-making, planning, and control that may be hand-engineered or learning-based. While these existing approaches have been shown to perform well under the situations they were specifically designed for, they can perform especially poorly in rare, out-of-distribution scenarios that will undoubtedly arise at test-time. The rise of foundation models trained on multiple tasks with impressively large datasets from a variety of fields has led researchers to believe that these models may provide common sense reasoning that existing planners are missing. Researchers posit that this common sense reasoning will bridge the gap between algorithm development and deployment to out-of-distribution tasks, like
&lt;/p&gt;</description></item><item><title>NeuPAN &#26159;&#19968;&#31181;&#23454;&#26102;&#12289;&#39640;&#24230;&#20934;&#30830;&#12289;&#26080;&#22320;&#22270;&#12289;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#20154;&#19988;&#23545;&#29615;&#22659;&#19981;&#21464;&#30340;&#26426;&#22120;&#20154;&#23548;&#33322;&#35299;&#20915;&#26041;&#26696;&#65292;&#26368;&#22823;&#30340;&#21019;&#26032;&#22312;&#20110;&#23558;&#21407;&#22987;&#28857;&#30452;&#25509;&#26144;&#23556;&#21040;&#23398;&#20064;&#21040;&#30340;&#22810;&#24103;&#36317;&#31163;&#31354;&#38388;&#65292;&#24182;&#20855;&#26377;&#31471;&#21040;&#31471;&#27169;&#22411;&#23398;&#20064;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#21487;&#35777;&#26126;&#30340;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2403.06828</link><description>&lt;p&gt;
NeuPAN:&#30452;&#25509;&#28857;&#26426;&#22120;&#20154;&#23548;&#33322;&#30340;&#31471;&#21040;&#31471;&#22522;&#20110;&#27169;&#22411;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
NeuPAN: Direct Point Robot Navigation with End-to-End Model-based Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06828
&lt;/p&gt;
&lt;p&gt;
NeuPAN &#26159;&#19968;&#31181;&#23454;&#26102;&#12289;&#39640;&#24230;&#20934;&#30830;&#12289;&#26080;&#22320;&#22270;&#12289;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#20154;&#19988;&#23545;&#29615;&#22659;&#19981;&#21464;&#30340;&#26426;&#22120;&#20154;&#23548;&#33322;&#35299;&#20915;&#26041;&#26696;&#65292;&#26368;&#22823;&#30340;&#21019;&#26032;&#22312;&#20110;&#23558;&#21407;&#22987;&#28857;&#30452;&#25509;&#26144;&#23556;&#21040;&#23398;&#20064;&#21040;&#30340;&#22810;&#24103;&#36317;&#31163;&#31354;&#38388;&#65292;&#24182;&#20855;&#26377;&#31471;&#21040;&#31471;&#27169;&#22411;&#23398;&#20064;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#21487;&#35777;&#26126;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25317;&#25380;&#29615;&#22659;&#20013;&#23545;&#38750;&#20840;&#21521;&#26426;&#22120;&#20154;&#36827;&#34892;&#23548;&#33322;&#38656;&#35201;&#26497;&#20854;&#31934;&#30830;&#30340;&#24863;&#30693;&#21644;&#36816;&#21160;&#20197;&#36991;&#20813;&#30896;&#25758;&#12290;&#26412;&#25991;&#25552;&#20986;NeuPAN&#65306;&#19968;&#31181;&#23454;&#26102;&#12289;&#39640;&#24230;&#20934;&#30830;&#12289;&#26080;&#22320;&#22270;&#12289;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#20154;&#65292;&#19988;&#23545;&#29615;&#22659;&#19981;&#21464;&#30340;&#26426;&#22120;&#20154;&#23548;&#33322;&#35299;&#20915;&#26041;&#26696;&#12290;NeuPAN&#37319;&#29992;&#32039;&#32806;&#21512;&#30340;&#24863;&#30693;-&#36816;&#21160;&#26694;&#26550;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#26377;&#20004;&#20010;&#20851;&#38190;&#21019;&#26032;&#65306;1&#65289;&#23427;&#30452;&#25509;&#23558;&#21407;&#22987;&#28857;&#26144;&#23556;&#21040;&#23398;&#20064;&#21040;&#30340;&#22810;&#24103;&#36317;&#31163;&#31354;&#38388;&#65292;&#36991;&#20813;&#20102;&#20174;&#24863;&#30693;&#21040;&#25511;&#21046;&#30340;&#35823;&#24046;&#20256;&#25773;&#65307;2&#65289;&#20174;&#31471;&#21040;&#31471;&#22522;&#20110;&#27169;&#22411;&#23398;&#20064;&#30340;&#35282;&#24230;&#36827;&#34892;&#35299;&#37322;&#65292;&#23454;&#29616;&#20102;&#21487;&#35777;&#26126;&#30340;&#25910;&#25947;&#12290;NeuPAN&#30340;&#20851;&#38190;&#22312;&#20110;&#21033;&#29992;&#25554;&#25300;&#24335;&#65288;PnP&#65289;&#20132;&#26367;&#26368;&#23567;&#21270;&#20256;&#24863;&#22120;&#65288;PAN&#65289;&#32593;&#32476;&#35299;&#39640;&#32500;&#31471;&#21040;&#31471;&#25968;&#23398;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#21547;&#21508;&#31181;&#28857;&#32423;&#32422;&#26463;&#65292;&#20351;NeuPAN&#33021;&#22815;&#30452;&#25509;&#29983;&#25104;&#23454;&#26102;&#12289;&#31471;&#21040;&#31471;&#12289;&#29289;&#29702;&#21487;&#35299;&#37322;&#30340;&#36816;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06828v1 Announce Type: cross  Abstract: Navigating a nonholonomic robot in a cluttered environment requires extremely accurate perception and locomotion for collision avoidance. This paper presents NeuPAN: a real-time, highly-accurate, map-free, robot-agnostic, and environment-invariant robot navigation solution. Leveraging a tightly-coupled perception-locomotion framework, NeuPAN has two key innovations compared to existing approaches: 1) it directly maps raw points to a learned multi-frame distance space, avoiding error propagation from perception to control; 2) it is interpretable from an end-to-end model-based learning perspective, enabling provable convergence. The crux of NeuPAN is to solve a high-dimensional end-to-end mathematical model with various point-level constraints using the plug-and-play (PnP) proximal alternating-minimization network (PAN) with neurons in the loop. This allows NeuPAN to generate real-time, end-to-end, physically-interpretable motions direct
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;RAGFormer&#30340;&#26032;&#26694;&#26550;&#65292;&#21516;&#26102;&#23558;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#23884;&#20837;&#30446;&#26631;&#33410;&#28857;&#65292;&#20197;&#25913;&#36827;&#27450;&#35784;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.17472</link><description>&lt;p&gt;
&#36890;&#36807;&#34701;&#21512;&#20840;&#23616;&#21644;&#23616;&#37096;&#20851;&#31995;&#20132;&#20114;&#36827;&#34892;&#27450;&#35784;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Fraud Detection with Binding Global and Local Relational Interaction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17472
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;RAGFormer&#30340;&#26032;&#26694;&#26550;&#65292;&#21516;&#26102;&#23558;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#23884;&#20837;&#30446;&#26631;&#33410;&#28857;&#65292;&#20197;&#25913;&#36827;&#27450;&#35784;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#23545;&#20110;&#27450;&#35784;&#26816;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#22312;&#25972;&#20307;&#35270;&#35282;&#20013;&#32534;&#30721;&#33410;&#28857;&#20132;&#20114;&#21644;&#32858;&#21512;&#29305;&#24449;&#12290;&#26368;&#36817;&#65292;&#20855;&#26377;&#20986;&#33394;&#24207;&#21015;&#32534;&#30721;&#33021;&#21147;&#30340;Transformer&#32593;&#32476;&#22312;&#25991;&#29486;&#20013;&#20063;&#34920;&#29616;&#20986;&#20248;&#20110;&#20854;&#20182;&#22522;&#20110;GNN&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;GNN&#21644;&#22522;&#20110;Transformer&#30340;&#32593;&#32476;&#21482;&#32534;&#30721;&#25972;&#20010;&#22270;&#30340;&#19968;&#20010;&#35270;&#35282;&#65292;&#32780;GNN&#32534;&#30721;&#20840;&#23616;&#29305;&#24449;&#65292;Transformer&#32593;&#32476;&#32534;&#30721;&#23616;&#37096;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#24573;&#35270;&#20102;&#20351;&#29992;&#21333;&#29420;&#32593;&#32476;&#32534;&#30721;&#24322;&#26500;&#22270;&#30340;&#20840;&#23616;&#20132;&#20114;&#29305;&#24449;&#65292;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;Relation-Aware GNN with transFormer&#65288;RAGFormer&#65289;&#30340;&#26032;&#39062;&#26694;&#26550;&#65292;&#23558;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#21516;&#26102;&#23884;&#20837;&#30446;&#26631;&#33410;&#28857;&#20013;&#12290;&#36825;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#32593;&#32476;&#24212;&#29992;&#20102;&#19968;&#20010;&#20462;&#25913;&#21518;&#30340;GAGA&#27169;&#22359;&#65292;&#20854;&#20013;&#27599;&#20010;Transformer&#23618;&#21518;&#38754;&#37117;&#36319;&#30528;&#19968;&#20010;&#36328;&#20851;&#31995;&#32858;&#21512;&#23618;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17472v1 Announce Type: cross  Abstract: Graph Neural Network has been proved to be effective for fraud detection for its capability to encode node interaction and aggregate features in a holistic view. Recently, Transformer network with great sequence encoding ability, has also outperformed other GNN-based methods in literatures. However, both GNN-based and Transformer-based networks only encode one perspective of the whole graph, while GNN encodes global features and Transformer network encodes local ones. Furthermore, previous works ignored encoding global interaction features of the heterogeneous graph with separate networks, thus leading to suboptimal performance. In this work, we present a novel framework called Relation-Aware GNN with transFormer (RAGFormer) which simultaneously embeds local and global features into a target node. The simple yet effective network applies a modified GAGA module where each transformer layer is followed by a cross-relation aggregation lay
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#28151;&#21512;&#21442;&#19982;&#24335;&#31995;&#32479;&#20013;&#30340;&#20215;&#20540;&#20559;&#22909;&#20272;&#35745;&#25552;&#20986;&#20102;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#21442;&#19982;&#32773;&#20114;&#21160;&#35299;&#20915;&#20102;&#36873;&#25321;&#19982;&#21160;&#26426;&#20043;&#38388;&#30340;&#20914;&#31361;&#65292;&#24182;&#37325;&#28857;&#27604;&#36739;&#20102;&#20174;&#21160;&#26426;&#20013;&#20272;&#35745;&#30340;&#20215;&#20540;&#19982;&#20165;&#20174;&#36873;&#25321;&#20013;&#20272;&#35745;&#30340;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2402.16751</link><description>&lt;p&gt;
&#28151;&#21512;&#21442;&#19982;&#24335;&#31995;&#32479;&#20013;&#30340;&#20215;&#20540;&#20559;&#22909;&#20272;&#35745;&#21644;&#28040;&#27495;
&lt;/p&gt;
&lt;p&gt;
Value Preferences Estimation and Disambiguation in Hybrid Participatory Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#28151;&#21512;&#21442;&#19982;&#24335;&#31995;&#32479;&#20013;&#30340;&#20215;&#20540;&#20559;&#22909;&#20272;&#35745;&#25552;&#20986;&#20102;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#21442;&#19982;&#32773;&#20114;&#21160;&#35299;&#20915;&#20102;&#36873;&#25321;&#19982;&#21160;&#26426;&#20043;&#38388;&#30340;&#20914;&#31361;&#65292;&#24182;&#37325;&#28857;&#27604;&#36739;&#20102;&#20174;&#21160;&#26426;&#20013;&#20272;&#35745;&#30340;&#20215;&#20540;&#19982;&#20165;&#20174;&#36873;&#25321;&#20013;&#20272;&#35745;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28151;&#21512;&#21442;&#19982;&#24335;&#31995;&#32479;&#20013;&#29702;&#35299;&#20844;&#27665;&#30340;&#20215;&#20540;&#35266;&#23545;&#20110;&#20197;&#20844;&#27665;&#20026;&#20013;&#24515;&#30340;&#25919;&#31574;&#21046;&#23450;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#35774;&#24819;&#20102;&#19968;&#20010;&#28151;&#21512;&#21442;&#19982;&#24335;&#31995;&#32479;&#65292;&#22312;&#36825;&#20010;&#31995;&#32479;&#20013;&#65292;&#21442;&#19982;&#32773;&#20570;&#20986;&#36873;&#25321;&#24182;&#25552;&#20379;&#36873;&#25321;&#30340;&#21160;&#26426;&#65292;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#36890;&#36807;&#19982;&#20182;&#20204;&#20114;&#21160;&#26469;&#20272;&#35745;&#20182;&#20204;&#30340;&#20215;&#20540;&#20559;&#22909;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#22312;&#21442;&#19982;&#32773;&#30340;&#36873;&#25321;&#21644;&#21160;&#26426;&#20043;&#38388;&#26816;&#27979;&#21040;&#20914;&#31361;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#20272;&#35745;&#20215;&#20540;&#20559;&#22909;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#36890;&#36807;&#19982;&#21442;&#19982;&#32773;&#20114;&#21160;&#26469;&#35299;&#20915;&#26816;&#27979;&#21040;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#23558;&#8220;&#29645;&#35270;&#26159;&#32463;&#36807;&#28145;&#24605;&#29087;&#34385;&#30340;&#26377;&#24847;&#20041;&#34892;&#20026;&#8221;&#36825;&#19968;&#21746;&#23398;&#31435;&#22330;&#25805;&#20316;&#21270;&#12290;&#20063;&#23601;&#26159;&#22914;&#26524;&#21442;&#19982;&#32773;&#30340;&#36873;&#25321;&#26159;&#22522;&#20110;&#23545;&#20215;&#20540;&#20559;&#22909;&#30340;&#28145;&#24605;&#29087;&#34385;&#65292;&#37027;&#20040;&#21487;&#20197;&#22312;&#21442;&#19982;&#32773;&#20026;&#36873;&#25321;&#25552;&#20379;&#30340;&#21160;&#26426;&#20013;&#35266;&#23519;&#21040;&#20215;&#20540;&#20559;&#22909;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#20248;&#20808;&#32771;&#34385;&#20174;&#21160;&#26426;&#20013;&#20272;&#35745;&#30340;&#20215;&#20540;&#32780;&#19981;&#26159;&#20165;&#20174;&#36873;&#25321;&#20013;&#20272;&#35745;&#30340;&#20215;&#20540;&#30340;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16751v1 Announce Type: cross  Abstract: Understanding citizens' values in participatory systems is crucial for citizen-centric policy-making. We envision a hybrid participatory system where participants make choices and provide motivations for those choices, and AI agents estimate their value preferences by interacting with them. We focus on situations where a conflict is detected between participants' choices and motivations, and propose methods for estimating value preferences while addressing detected inconsistencies by interacting with the participants. We operationalize the philosophical stance that "valuing is deliberatively consequential." That is, if a participant's choice is based on a deliberation of value preferences, the value preferences can be observed in the motivation the participant provides for the choice. Thus, we propose and compare value estimation methods that prioritize the values estimated from motivations over the values estimated from choices alone.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#20013;&#20943;&#23569;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#20195;&#20215;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09401</link><description>&lt;p&gt;
&#20351;&#29992;&#20027;&#21160;&#26597;&#35810;&#30340;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback with Active Queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#20013;&#20943;&#23569;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#20195;&#20215;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#23545;&#40784;&#65292;&#22312;&#26500;&#24314;&#29616;&#20195;&#29983;&#25104;&#27169;&#22411;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#24403;&#21069;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#20294;&#24448;&#24448;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#65292;&#32780;&#36825;&#31181;&#25968;&#25454;&#25910;&#38598;&#36153;&#26102;&#36153;&#21147;&#12290;&#26412;&#25991;&#21463;&#21040;&#20027;&#21160;&#23398;&#20064;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#36890;&#36807;&#25552;&#20986;&#26597;&#35810;&#25928;&#29575;&#39640;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#23545;&#40784;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#19978;&#19979;&#25991;&#31454;&#20105;&#20108;&#33218;&#24378;&#30423;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;APPO&#65289;&#31639;&#27861;&#65292;&#20855;&#26377;$\tilde{O}(d^2/\Delta)$&#30340;&#36951;&#25022;&#30028;&#21644;$\tilde{O}(d^2/\Delta^2)$&#30340;&#26597;&#35810;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;$d$&#26159;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#24230;&#65292;$\Delta$&#26159;&#25152;&#26377;&#19978;&#19979;&#25991;&#20013;&#30340;&#27425;&#20248;&#24046;&#36317;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ADPO&#65292;&#36825;&#26159;&#25105;&#20204;&#31639;&#27861;&#30340;&#23454;&#38469;&#29256;&#26412;&#65292;&#22522;&#20110;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09401v1 Announce Type: cross Abstract: Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20869;&#30465;&#35268;&#21010;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#24341;&#23548;&#35821;&#35328;&#39537;&#21160;&#30340;&#20195;&#29702;&#26426;&#22120;&#20154;&#25913;&#36827;&#33258;&#36523;&#19981;&#30830;&#23450;&#24615;&#30340;&#31995;&#32479;&#26041;&#27861;&#12290;&#36890;&#36807;&#35782;&#21035;&#20219;&#21153;&#19981;&#30830;&#23450;&#24615;&#24182;&#20027;&#21160;&#23547;&#27714;&#28548;&#28165;&#65292;&#20869;&#30465;&#26174;&#33879;&#25552;&#39640;&#20102;&#26426;&#22120;&#20154;&#20219;&#21153;&#35268;&#21010;&#30340;&#25104;&#21151;&#29575;&#21644;&#23433;&#20840;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06529</link><description>&lt;p&gt;
&#20869;&#30465;&#35268;&#21010;&#65306;&#24341;&#23548;&#35821;&#35328;&#39537;&#21160;&#30340;&#20195;&#29702;&#26426;&#22120;&#20154;&#25913;&#36827;&#33258;&#36523;&#30340;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06529
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20869;&#30465;&#35268;&#21010;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#24341;&#23548;&#35821;&#35328;&#39537;&#21160;&#30340;&#20195;&#29702;&#26426;&#22120;&#20154;&#25913;&#36827;&#33258;&#36523;&#19981;&#30830;&#23450;&#24615;&#30340;&#31995;&#32479;&#26041;&#27861;&#12290;&#36890;&#36807;&#35782;&#21035;&#20219;&#21153;&#19981;&#30830;&#23450;&#24615;&#24182;&#20027;&#21160;&#23547;&#27714;&#28548;&#28165;&#65292;&#20869;&#30465;&#26174;&#33879;&#25552;&#39640;&#20102;&#26426;&#22120;&#20154;&#20219;&#21153;&#35268;&#21010;&#30340;&#25104;&#21151;&#29575;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23637;&#31034;&#20102;&#20808;&#36827;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20351;&#24471;&#26426;&#22120;&#20154;&#33021;&#22815;&#29702;&#35299;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#65292;&#24182;&#36890;&#36807;&#36866;&#24403;&#30340;&#22522;&#30784;&#22609;&#36896;&#26469;&#31574;&#30053;&#24615;&#22320;&#36827;&#34892;&#39640;&#32423;&#34892;&#21160;&#35268;&#21010;&#12290;&#28982;&#32780;&#65292;LLM&#20135;&#29983;&#30340;&#24187;&#35273;&#21487;&#33021;&#23548;&#33268;&#26426;&#22120;&#20154;&#33258;&#20449;&#22320;&#25191;&#34892;&#19982;&#29992;&#25143;&#30446;&#26631;&#19981;&#31526;&#25110;&#22312;&#26497;&#31471;&#24773;&#20917;&#19979;&#19981;&#23433;&#20840;&#30340;&#35745;&#21010;&#12290;&#27492;&#22806;&#65292;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#20013;&#30340;&#22266;&#26377;&#27495;&#20041;&#21487;&#33021;&#24341;&#21457;&#20219;&#21153;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#22810;&#20010;&#26377;&#25928;&#36873;&#39033;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;LLMs&#24517;&#39035;&#35782;&#21035;&#27492;&#31867;&#19981;&#30830;&#23450;&#24615;&#24182;&#20027;&#21160;&#23547;&#27714;&#28548;&#28165;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#20869;&#30465;&#35268;&#21010;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#31995;&#32479;&#26041;&#27861;&#65292;&#24341;&#23548;LLMs&#22312;&#26080;&#38656;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#24418;&#25104;&#24847;&#35782;&#21040;&#19981;&#30830;&#23450;&#24615;&#30340;&#26426;&#22120;&#20154;&#20219;&#21153;&#25191;&#34892;&#35745;&#21010;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20219;&#21153;&#32423;&#26426;&#22120;&#20154;&#35268;&#21010;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#35777;&#26126;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;LLM&#30340;&#35268;&#21010;&#26041;&#27861;&#30456;&#27604;&#65292;&#20869;&#30465;&#26174;&#33879;&#25552;&#39640;&#20102;&#25104;&#21151;&#29575;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) exhibit advanced reasoning skills, enabling robots to comprehend natural language instructions and strategically plan high-level actions through proper grounding. However, LLM hallucination may result in robots confidently executing plans that are misaligned with user goals or, in extreme cases, unsafe. Additionally, inherent ambiguity in natural language instructions can induce task uncertainty, particularly in situations where multiple valid options exist. To address this issue, LLMs must identify such uncertainty and proactively seek clarification. This paper explores the concept of introspective planning as a systematic method for guiding LLMs in forming uncertainty--aware plans for robotic task execution without the need for fine-tuning. We investigate uncertainty quantification in task-level robot planning and demonstrate that introspection significantly improves both success rates and safety compared to state-of-the-art LLM-based planning approaches.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35843;&#26597;&#20102;&#20154;&#24037;&#26234;&#33021;&#20013;&#29702;&#24615;&#19982;&#38750;&#29702;&#24615;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#26410;&#35299;&#38382;&#39064;&#12290;&#37325;&#28857;&#35752;&#35770;&#20102;&#34892;&#20026;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#38750;&#29702;&#24615;&#34892;&#20026;&#21487;&#33021;&#26159;&#26368;&#20248;&#30340;&#24773;&#20917;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#26469;&#22788;&#29702;&#38750;&#29702;&#24615;&#20195;&#29702;&#65292;&#20294;&#20173;&#23384;&#22312;&#25361;&#25112;&#21644;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.17165</link><description>&lt;p&gt;
(&#38750;)&#29702;&#24615;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#24212;&#29992;&#65306;&#29616;&#29366;&#12289;&#30740;&#31350;&#25361;&#25112;&#21644;&#26410;&#35299;&#20043;&#38382;
&lt;/p&gt;
&lt;p&gt;
(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17165
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35843;&#26597;&#20102;&#20154;&#24037;&#26234;&#33021;&#20013;&#29702;&#24615;&#19982;&#38750;&#29702;&#24615;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#26410;&#35299;&#38382;&#39064;&#12290;&#37325;&#28857;&#35752;&#35770;&#20102;&#34892;&#20026;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#38750;&#29702;&#24615;&#34892;&#20026;&#21487;&#33021;&#26159;&#26368;&#20248;&#30340;&#24773;&#20917;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#26469;&#22788;&#29702;&#38750;&#29702;&#24615;&#20195;&#29702;&#65292;&#20294;&#20173;&#23384;&#22312;&#25361;&#25112;&#21644;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#24615;&#27010;&#24565;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20013;&#21344;&#25454;&#30528;&#37325;&#35201;&#22320;&#20301;&#12290;&#26080;&#35770;&#26159;&#27169;&#25311;&#20154;&#31867;&#25512;&#29702;&#36824;&#26159;&#36861;&#27714;&#26377;&#38480;&#26368;&#20248;&#24615;&#65292;&#25105;&#20204;&#36890;&#24120;&#24076;&#26395;&#20351;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#23613;&#21487;&#33021;&#29702;&#24615;&#12290;&#23613;&#31649;&#36825;&#20010;&#27010;&#24565;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#38750;&#24120;&#26680;&#24515;&#65292;&#20294;&#23545;&#20110;&#20160;&#20040;&#26500;&#25104;&#29702;&#24615;&#20195;&#29702;&#24182;&#27809;&#26377;&#32479;&#19968;&#30340;&#23450;&#20041;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#29702;&#24615;&#19982;&#38750;&#29702;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36825;&#20010;&#39046;&#22495;&#30340;&#26410;&#35299;&#38382;&#39064;&#12290;&#22312;&#20854;&#20182;&#39046;&#22495;&#23545;&#29702;&#24615;&#30340;&#29702;&#35299;&#23545;&#20854;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#27010;&#24565;&#20135;&#29983;&#20102;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#32463;&#27982;&#23398;&#12289;&#21746;&#23398;&#21644;&#24515;&#29702;&#23398;&#26041;&#38754;&#30340;&#30740;&#31350;&#12290;&#30528;&#37325;&#32771;&#34385;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#30340;&#34892;&#20026;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#26576;&#20123;&#24773;&#22659;&#20013;&#38750;&#29702;&#24615;&#34892;&#20026;&#21487;&#33021;&#26159;&#26368;&#20248;&#30340;&#24773;&#20917;&#12290;&#20851;&#20110;&#22788;&#29702;&#38750;&#29702;&#24615;&#20195;&#29702;&#30340;&#26041;&#27861;&#24050;&#32463;&#24471;&#21040;&#20102;&#19968;&#20123;&#21457;&#23637;&#65292;&#21253;&#25324;&#35782;&#21035;&#21644;&#20132;&#20114;&#31561;&#26041;&#38754;&#30340;&#30740;&#31350;&#65292;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#39046;&#22495;&#30340;&#24037;&#20316;&#20173;&#28982;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#21644;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.17165v2 Announce Type: replace Abstract: The concept of rationality is central to the field of artificial intelligence. Whether we are seeking to simulate human reasoning, or the goal is to achieve bounded optimality, we generally seek to make artificial agents as rational as possible. Despite the centrality of the concept within AI, there is no unified definition of what constitutes a rational agent. This article provides a survey of rationality and irrationality in artificial intelligence, and sets out the open questions in this area. The understanding of rationality in other fields has influenced its conception within artificial intelligence, in particular work in economics, philosophy and psychology. Focusing on the behaviour of artificial agents, we consider irrational behaviours that can prove to be optimal in certain scenarios. Some methods have been developed to deal with irrational agents, both in terms of identification and interaction, however work in this area re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#65292;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#12290;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.08731</link><description>&lt;p&gt;
&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#22312;&#19990;&#30028;&#27169;&#22411;&#20013;&#23454;&#29616;&#26032;&#39062;&#24615;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Simple Way to Incorporate Novelty Detection in World Models. (arXiv:2310.08731v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#65292;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#12290;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#19990;&#30028;&#27169;&#22411;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#24403;&#19990;&#30028;&#26426;&#21046;&#25110;&#23646;&#24615;&#21457;&#29983;&#31361;&#28982;&#21464;&#21270;&#26102;&#65292;&#20195;&#29702;&#30340;&#24615;&#33021;&#21644;&#21487;&#38752;&#24615;&#21487;&#33021;&#20250;&#26174;&#33879;&#19979;&#38477;&#12290;&#25105;&#20204;&#23558;&#35270;&#35273;&#23646;&#24615;&#25110;&#29366;&#24577;&#36716;&#25442;&#30340;&#31361;&#21464;&#31216;&#20026;&#8220;&#26032;&#39062;&#24615;&#8221;&#12290;&#22312;&#29983;&#25104;&#30340;&#19990;&#30028;&#27169;&#22411;&#26694;&#26550;&#20013;&#23454;&#26045;&#26032;&#39062;&#24615;&#26816;&#27979;&#26159;&#20445;&#25252;&#37096;&#32626;&#26102;&#20195;&#29702;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36793;&#30028;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19982;&#24207;&#21015;&#20915;&#31574;&#30456;&#20851;&#30340;&#26032;&#39062;&#24615;&#26816;&#27979;&#26412;&#20307;&#35770;&#65292;&#28982;&#21518;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#20195;&#29702;&#22312;&#19990;&#30028;&#27169;&#22411;&#20013;&#23398;&#20064;&#30340;&#36716;&#25442;&#20998;&#24067;&#20013;&#26816;&#27979;&#26032;&#39062;&#24615;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as {\em novelties}. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We first provide an ontology of novelty detection relevant to sequential decision making, then we provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional ma
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;EMR&#25968;&#25454;&#38598;&#20043;&#38388;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#30340;&#39044;&#21518;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#36807;&#28193;&#27169;&#22411;&#35299;&#20915;&#20102;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.07799</link><description>&lt;p&gt;
&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;EMR&#25968;&#25454;&#38598;&#20043;&#38388;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#30340;&#39044;&#21518;&#39044;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Transfer-Learning-Based Prognosis Prediction Paradigm that Bridges Data Distribution Shift across EMR Datasets. (arXiv:2310.07799v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07799
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;EMR&#25968;&#25454;&#38598;&#20043;&#38388;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#30340;&#39044;&#21518;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#36807;&#28193;&#27169;&#22411;&#35299;&#20915;&#20102;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#23545;&#26032;&#20852;&#30142;&#30149;&#30340;&#20449;&#24687;&#26377;&#38480;&#65292;&#30151;&#29366;&#24456;&#38590;&#34987;&#23519;&#35273;&#21644;&#35748;&#35782;&#21040;&#65292;&#22240;&#27492;&#21487;&#33021;&#24573;&#35270;&#20020;&#24202;&#24178;&#39044;&#30340;&#31383;&#21475;&#12290;&#26399;&#26395;&#33021;&#22815;&#24314;&#31435;&#19968;&#20010;&#26377;&#25928;&#30340;&#39044;&#21518;&#27169;&#22411;&#65292;&#36741;&#21161;&#21307;&#29983;&#36827;&#34892;&#27491;&#30830;&#35786;&#26029;&#21644;&#21046;&#23450;&#20010;&#24615;&#21270;&#27835;&#30103;&#26041;&#26696;&#65292;&#20174;&#32780;&#21450;&#26102;&#39044;&#38450;&#19981;&#21033;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#30142;&#30149;&#26089;&#26399;&#38454;&#27573;&#65292;&#30001;&#20110;&#25968;&#25454;&#25910;&#38598;&#21644;&#20020;&#24202;&#32463;&#39564;&#26377;&#38480;&#65292;&#20877;&#21152;&#19978;&#23545;&#38544;&#31169;&#21644;&#20262;&#29702;&#30340;&#32771;&#34385;&#65292;&#23548;&#33268;&#21487;&#20379;&#21442;&#32771;&#30340;&#25968;&#25454;&#21463;&#38480;&#65292;&#29978;&#33267;&#38590;&#20197;&#27491;&#30830;&#26631;&#35760;&#25968;&#25454;&#26631;&#31614;&#12290;&#27492;&#22806;&#65292;&#19981;&#21516;&#30142;&#30149;&#25110;&#21516;&#19968;&#30142;&#30149;&#19981;&#21516;&#26469;&#28304;&#30340;&#30005;&#23376;&#21307;&#30103;&#35760;&#24405;&#65288;EMR&#65289;&#25968;&#25454;&#21487;&#33021;&#23384;&#22312;&#20005;&#37325;&#30340;&#36328;&#25968;&#25454;&#38598;&#29305;&#24449;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#20005;&#37325;&#24433;&#21709;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#29575;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#24314;&#31435;&#19968;&#20010;&#20174;&#28304;&#25968;&#25454;&#38598;&#21040;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#36807;&#28193;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#29305;&#24449;&#36827;&#34892;&#32422;&#26463;&#65292;&#26469;&#35299;&#20915;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the limited information about emerging diseases, symptoms are hard to be noticed and recognized, so that the window for clinical intervention could be ignored. An effective prognostic model is expected to assist doctors in making right diagnosis and designing personalized treatment plan, so to promptly prevent unfavorable outcomes. However, in the early stage of a disease, limited data collection and clinical experiences, plus the concern out of privacy and ethics, may result in restricted data availability for reference, to the extent that even data labels are difficult to mark correctly. In addition, Electronic Medical Record (EMR) data of different diseases or of different sources of the same disease can prove to be having serious cross-dataset feature misalignment problems, greatly mutilating the efficiency of deep learning models. This article introduces a transfer learning method to build a transition model from source dataset to target dataset. By way of constraining the 
&lt;/p&gt;</description></item></channel></rss>