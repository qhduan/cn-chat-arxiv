<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;Off-FSP&#65292;&#36825;&#26159;&#31454;&#20105;&#28216;&#25103;&#30340;&#31532;&#19968;&#20010;&#23454;&#29992;&#30340;&#26080;&#27169;&#22411;&#31163;&#32447;RL&#31639;&#27861;&#65292;&#36890;&#36807;&#35843;&#25972;&#22266;&#23450;&#25968;&#25454;&#38598;&#30340;&#26435;&#37325;&#65292;&#20351;&#29992;&#37325;&#35201;&#24615;&#25277;&#26679;&#65292;&#27169;&#25311;&#19982;&#21508;&#31181;&#23545;&#25163;&#30340;&#20114;&#21160;&#12290;</title><link>https://arxiv.org/abs/2403.00841</link><description>&lt;p&gt;
&#31454;&#20105;&#28216;&#25103;&#30340;&#31163;&#32447;&#34394;&#26500;&#33258;&#25105;&#23545;&#24328;
&lt;/p&gt;
&lt;p&gt;
Offline Fictitious Self-Play for Competitive Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Off-FSP&#65292;&#36825;&#26159;&#31454;&#20105;&#28216;&#25103;&#30340;&#31532;&#19968;&#20010;&#23454;&#29992;&#30340;&#26080;&#27169;&#22411;&#31163;&#32447;RL&#31639;&#27861;&#65292;&#36890;&#36807;&#35843;&#25972;&#22266;&#23450;&#25968;&#25454;&#38598;&#30340;&#26435;&#37325;&#65292;&#20351;&#29992;&#37325;&#35201;&#24615;&#25277;&#26679;&#65292;&#27169;&#25311;&#19982;&#21508;&#31181;&#23545;&#25163;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22240;&#20854;&#22312;&#20197;&#21069;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#20013;&#25913;&#36827;&#31574;&#30053;&#32780;&#19981;&#38656;&#35201;&#22312;&#32447;&#20132;&#20114;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#37325;&#35270;&#12290;&#23613;&#31649;&#22312;&#21333;&#19968;&#26234;&#33021;&#20307;&#35774;&#32622;&#20013;&#21462;&#24471;&#25104;&#21151;&#65292;&#20294;&#31163;&#32447;&#22810;&#26234;&#33021;&#20307;RL&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#31454;&#20105;&#28216;&#25103;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;Off-FSP&#65292;&#36825;&#26159;&#31454;&#20105;&#28216;&#25103;&#30340;&#31532;&#19968;&#20010;&#23454;&#29992;&#30340;&#26080;&#27169;&#22411;&#31163;&#32447;RL&#31639;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#35843;&#25972;&#22266;&#23450;&#25968;&#25454;&#38598;&#30340;&#26435;&#37325;&#65292;&#20351;&#29992;&#37325;&#35201;&#24615;&#25277;&#26679;&#27169;&#25311;&#19982;&#21508;&#31181;&#23545;&#25163;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00841v1 Announce Type: cross  Abstract: Offline Reinforcement Learning (RL) has received significant interest due to its ability to improve policies in previously collected datasets without online interactions. Despite its success in the single-agent setting, offline multi-agent RL remains a challenge, especially in competitive games. Firstly, unaware of the game structure, it is impossible to interact with the opponents and conduct a major learning paradigm, self-play, for competitive games. Secondly, real-world datasets cannot cover all the state and action space in the game, resulting in barriers to identifying Nash equilibrium (NE). To address these issues, this paper introduces Off-FSP, the first practical model-free offline RL algorithm for competitive games. We start by simulating interactions with various opponents by adjusting the weights of the fixed dataset with importance sampling. This technique allows us to learn best responses to different opponents and employ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#20102;&#36234;&#29425;&#25552;&#31034;&#65292;&#25104;&#21151;&#22320;&#32469;&#36807;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26377;&#23475;&#38382;&#39064;&#30340;&#26816;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#25915;&#20987;&#25104;&#21151;&#29575;&#39640;&#36798;59.42%&#12290;</title><link>https://arxiv.org/abs/2402.10601</link><description>&lt;p&gt;
&#20351;&#29992;&#21333;&#35789;&#26367;&#25442;&#23494;&#30721;&#26469;&#36234;&#29425;&#19987;&#26377;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Jailbreaking Proprietary Large Language Models using Word Substitution Cipher
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10601
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#20102;&#36234;&#29425;&#25552;&#31034;&#65292;&#25104;&#21151;&#22320;&#32469;&#36807;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26377;&#23475;&#38382;&#39064;&#30340;&#26816;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#25915;&#20987;&#25104;&#21151;&#29575;&#39640;&#36798;59.42%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36981;&#24490;&#36947;&#24503;&#21644;&#20262;&#29702;&#20934;&#21017;&#65292;&#20294;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#21517;&#20026;Jailbreak&#30340;&#21019;&#24847;&#25552;&#31034;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#25552;&#31034;&#21487;&#20197;&#32469;&#36807;&#23545;&#40784;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36234;&#29425;&#25552;&#31034;&#21253;&#21547;&#33258;&#28982;&#35821;&#35328;&#65288;&#20027;&#35201;&#26159;&#33521;&#35821;&#65289;&#20013;&#30340;&#26377;&#23475;&#38382;&#39064;&#65292;&#21487;&#20197;&#34987;LLMs&#33258;&#36523;&#26816;&#27979;&#21040;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#30340;&#36234;&#29425;&#25552;&#31034;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#26368;&#20808;&#36827;&#30340;LLM&#65292;GPT-4&#19978;&#36827;&#34892;&#20102;&#19968;&#20010;&#35797;&#28857;&#30740;&#31350;&#65292;&#35299;&#30721;&#20102;&#20351;&#29992;&#21508;&#31181;&#23494;&#30721;&#25216;&#26415;&#21152;&#23494;&#30340;&#20960;&#20010;&#23433;&#20840;&#21477;&#23376;&#65292;&#21457;&#29616;&#31616;&#21333;&#30340;&#21333;&#35789;&#26367;&#25442;&#23494;&#30721;&#21487;&#20197;&#34987;&#26368;&#26377;&#25928;&#22320;&#35299;&#30721;&#12290;&#21463;&#27492;&#32467;&#26524;&#21551;&#21457;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#32534;&#30721;&#25216;&#26415;&#26469;&#32534;&#20889;&#36234;&#29425;&#25552;&#31034;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23558;&#19981;&#23433;&#20840;&#21333;&#35789;&#26144;&#23556;&#21040;&#23433;&#20840;&#21333;&#35789;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#26144;&#23556;&#30340;&#21333;&#35789;&#25552;&#20986;&#19981;&#23433;&#20840;&#38382;&#39064;&#30340;&#26144;&#23556;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#36234;&#29425;&#25915;&#20987;&#25104;&#21151;&#29575;&#65288;&#39640;&#36798;59.42%&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10601v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are aligned to moral and ethical guidelines but remain susceptible to creative prompts called Jailbreak that can bypass the alignment process. However, most jailbreaking prompts contain harmful questions in the natural language (mainly English), which can be detected by the LLM themselves. In this paper, we present jailbreaking prompts encoded using cryptographic techniques. We first present a pilot study on the state-of-the-art LLM, GPT-4, in decoding several safe sentences that have been encrypted using various cryptographic techniques and find that a straightforward word substitution cipher can be decoded most effectively. Motivated by this result, we use this encoding technique for writing jailbreaking prompts. We present a mapping of unsafe words with safe words and ask the unsafe question using these mapped words. Experimental results show an attack success rate (up to 59.42%) of our proposed jailbrea
&lt;/p&gt;</description></item></channel></rss>