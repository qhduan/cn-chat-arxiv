<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31639;&#27861;&#23450;&#20215;&#20195;&#29702;&#22312;&#23521;&#22836;&#24066;&#22330;&#29615;&#22659;&#20013;&#33258;&#20027;&#21246;&#32467;&#65292;&#23545;&#28040;&#36153;&#32773;&#21033;&#30410;&#26377;&#23475;&#65292;&#20854;&#35828;&#26126;&#20070;&#20013;&#30340;&#30701;&#35821;&#21464;&#21270;&#21487;&#33021;&#22686;&#21152;&#21246;&#32467;&#12290;</title><link>https://arxiv.org/abs/2404.00806</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31639;&#27861;&#21246;&#32467;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Collusion by Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00806
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31639;&#27861;&#23450;&#20215;&#20195;&#29702;&#22312;&#23521;&#22836;&#24066;&#22330;&#29615;&#22659;&#20013;&#33258;&#20027;&#21246;&#32467;&#65292;&#23545;&#28040;&#36153;&#32773;&#21033;&#30410;&#26377;&#23475;&#65292;&#20854;&#35828;&#26126;&#20070;&#20013;&#30340;&#30701;&#35821;&#21464;&#21270;&#21487;&#33021;&#22686;&#21152;&#21246;&#32467;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00806v1 &#20844;&#21578;&#31867;&#22411;:&#20132;&#21449;&#25688;&#35201;:&#31639;&#27861;&#23450;&#20215;&#30340;&#20852;&#36215;&#24341;&#36215;&#20102;&#23545;&#31639;&#27861;&#21246;&#32467;&#30340;&#25285;&#24551;&#12290;&#25105;&#20204;&#23545;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29305;&#21035;&#26159;GPT-4&#30340;&#31639;&#27861;&#23450;&#20215;&#20195;&#29702;&#36827;&#34892;&#23454;&#39564;&#12290;&#25105;&#20204;&#21457;&#29616;&#65306;&#65288;1&#65289;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#22312;&#23450;&#20215;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#65288;2&#65289;&#22522;&#20110;LLM&#30340;&#23450;&#20215;&#20195;&#29702;&#22312;&#23521;&#22836;&#24066;&#22330;&#29615;&#22659;&#20013;&#33258;&#20027;&#21246;&#32467;&#65292;&#25439;&#23475;&#28040;&#36153;&#32773;&#21033;&#30410;&#65292;&#65288;3&#65289;LLM&#35828;&#26126;&#20070;&#20013;&#30475;&#20284;&#26080;&#23475;&#30701;&#35821;("&#25552;&#31034;")&#30340;&#21464;&#21270;&#21487;&#33021;&#20250;&#22686;&#21152;&#21246;&#32467;&#12290;&#36825;&#20123;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#25293;&#21334;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24378;&#35843;&#20102;&#26377;&#20851;&#31639;&#27861;&#23450;&#20215;&#30340;&#21453;&#22404;&#26029;&#30417;&#31649;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#21457;&#29616;&#20102;&#22522;&#20110;LLM&#30340;&#23450;&#20215;&#20195;&#29702;&#25152;&#38754;&#20020;&#30340;&#30417;&#31649;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00806v1 Announce Type: cross  Abstract: The rise of algorithmic pricing raises concerns of algorithmic collusion. We conduct experiments with algorithmic pricing agents based on Large Language Models (LLMs), and specifically GPT-4. We find that (1) LLM-based agents are adept at pricing tasks, (2) LLM-based pricing agents autonomously collude in oligopoly settings to the detriment of consumers, and (3) variation in seemingly innocuous phrases in LLM instructions ("prompts") may increase collusion. These results extend to auction settings. Our findings underscore the need for antitrust regulation regarding algorithmic pricing, and uncover regulatory challenges unique to LLM-based pricing agents.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23548;&#33322;&#31995;&#32479;&#22312;&#22478;&#24066;&#29615;&#22659;&#20013;&#30340;&#23433;&#20840;&#28431;&#27934;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;NPS Attack&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#28155;&#21152;&#21518;&#32512;&#26469;&#25805;&#32437;&#23548;&#33322;&#27169;&#22411;&#65292;&#23548;&#33268;&#19981;&#27491;&#30830;&#30340;&#34892;&#20026;&#12290;&#35813;&#30740;&#31350;&#23545;&#33258;&#21160;&#39550;&#39542;&#12289;&#29289;&#27969;&#21644;&#32039;&#24613;&#26381;&#21153;&#31561;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>https://arxiv.org/abs/2402.09546</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22478;&#24066;&#29615;&#22659;&#20013;&#23548;&#33322;&#26102;&#26377;&#22810;&#23433;&#20840;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09546
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23548;&#33322;&#31995;&#32479;&#22312;&#22478;&#24066;&#29615;&#22659;&#20013;&#30340;&#23433;&#20840;&#28431;&#27934;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;NPS Attack&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#28155;&#21152;&#21518;&#32512;&#26469;&#25805;&#32437;&#23548;&#33322;&#27169;&#22411;&#65292;&#23548;&#33268;&#19981;&#27491;&#30830;&#30340;&#34892;&#20026;&#12290;&#35813;&#30740;&#31350;&#23545;&#33258;&#21160;&#39550;&#39542;&#12289;&#29289;&#27969;&#21644;&#32039;&#24613;&#26381;&#21153;&#31561;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#20154;&#21644;&#33258;&#21160;&#21270;&#39046;&#22495;&#65292;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23548;&#33322;&#31995;&#32479;&#26368;&#36817;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#26041;&#38754;&#21463;&#21040;&#30340;&#20851;&#27880;&#30456;&#23545;&#36739;&#23569;&#12290;&#26412;&#25991;&#22312;&#22478;&#24066;&#25143;&#22806;&#29615;&#22659;&#20013;&#39318;&#27425;&#25506;&#32034;&#20102;LLM-based&#23548;&#33322;&#27169;&#22411;&#30340;&#28431;&#27934;&#65292;&#36825;&#26159;&#19968;&#20010;&#20851;&#38190;&#39046;&#22495;&#65292;&#22240;&#20026;&#35813;&#25216;&#26415;&#24191;&#27867;&#24212;&#29992;&#20110;&#33258;&#21160;&#39550;&#39542;&#12289;&#29289;&#27969;&#21644;&#32039;&#24613;&#26381;&#21153;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;Navigational Prompt Suffix (NPS) Attack&#65292;&#36890;&#36807;&#23558;&#26799;&#24230;&#23548;&#20986;&#30340;&#21518;&#32512;&#28155;&#21152;&#21040;&#21407;&#22987;&#23548;&#33322;&#25552;&#31034;&#65292;&#25805;&#32437;LLM-based&#23548;&#33322;&#27169;&#22411;&#65292;&#20174;&#32780;&#23548;&#33268;&#19981;&#27491;&#30830;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#23545;&#22522;&#20110;LLMs&#30340;&#23548;&#33322;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#35813;&#27169;&#22411;&#37319;&#29992;&#21508;&#31181;LLMs&#36827;&#34892;&#25512;&#29702;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26469;&#33258;Touchdown&#21644;Map2Seq&#34903;&#26223;&#25968;&#25454;&#38598;&#65292;&#22312;few-shot&#23398;&#20064;&#21644;fine-tuning&#37197;&#32622;&#19979;&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;NPS Attack&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09546v1 Announce Type: cross  Abstract: In the field of robotics and automation, navigation systems based on Large Language Models (LLMs) have recently shown impressive performance. However, the security aspects of these systems have received relatively less attention. This paper pioneers the exploration of vulnerabilities in LLM-based navigation models in urban outdoor environments, a critical area given the technology's widespread application in autonomous driving, logistics, and emergency services. Specifically, we introduce a novel Navigational Prompt Suffix (NPS) Attack that manipulates LLM-based navigation models by appending gradient-derived suffixes to the original navigational prompt, leading to incorrect actions. We conducted comprehensive experiments on an LLMs-based navigation model that employs various LLMs for reasoning. Our results, derived from the Touchdown and Map2Seq street-view datasets under both few-shot learning and fine-tuning configurations, demonstr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAR&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06104</link><description>&lt;p&gt;
&#21151;&#33021;&#23545;&#40784;&#22238;&#24402;&#65306;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#26126;&#30830;&#23398;&#20064;&#20989;&#25968;&#23548;&#25968;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06104
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAR&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#24402;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#20219;&#21153;&#65292;&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20256;&#32479;&#30340;&#22238;&#24402;&#26041;&#27861;&#20027;&#35201;&#36890;&#36807;&#20351;&#29992;&#25439;&#22833;&#20989;&#25968;&#26469;&#23558;&#27169;&#22411;&#39044;&#27979;&#19982;&#27599;&#20010;&#20010;&#20307;&#25968;&#25454;&#26679;&#26412;&#30340;&#30495;&#23454;&#20540;&#23545;&#40784;&#65292;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#22312;&#19981;&#21516;&#26679;&#26412;&#20043;&#38388;&#20851;&#31995;&#30340;&#39044;&#27979;&#19981;&#22815;&#20248;&#21270;&#12290;&#36817;&#26399;&#30340;&#30740;&#31350;&#24037;&#20316;&#24341;&#20837;&#20102;&#26631;&#31614;&#30456;&#20284;&#24615;&#20449;&#24687;&#26469;&#25913;&#36827;&#22238;&#24402;&#26041;&#27861;&#65292;&#20294;&#22312;&#23436;&#20840;&#25429;&#25417;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#26041;&#38754;&#20173;&#23384;&#22312;&#26126;&#26174;&#30340;&#24046;&#36317;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FAR&#65288;&#21151;&#33021;&#23545;&#40784;&#22238;&#24402;&#65289;&#20316;&#20026;&#19968;&#31181;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20845;&#20010;&#39046;&#22495;&#30340;&#20843;&#20010;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample, which, as we show, can result in sub-optimal prediction of the relationships between the different samples. Recent research endeavors have introduced novel perspectives by incorporating label similarity information to regression. However, a notable gap persists in these approaches when it comes to fully capturing the intricacies of the underlying ground truth function. In this work, we propose FAR (Function Aligned Regression) as a arguably better and more efficient solution to fit the underlying function of ground truth by capturing functional derivatives. We demonstrate the effectiveness of the proposed method practically on 2 synthetic datasets and on 8 extensive real-world tasks from 6 b
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35831;&#27714;&#25104;&#21592;&#26631;&#31614;&#21644;&#25104;&#23545;&#20559;&#22909;&#26469;&#25193;&#23637;&#20027;&#21160;&#35268;&#33539;&#23398;&#20064;&#65292;&#25552;&#39640;&#23398;&#20064;&#24418;&#24335;&#35268;&#33539;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#23454;&#39564;&#20013;&#65292;&#32467;&#26524;&#34920;&#26126;&#36890;&#36807;&#23398;&#20064;&#25104;&#21592;&#21644;&#20559;&#22909;&#30340;&#32452;&#21512;&#21487;&#20197;&#31283;&#23450;&#21644;&#26041;&#20415;&#22320;&#35782;&#21035;&#35268;&#33539;&#12290;</title><link>http://arxiv.org/abs/2307.10434</link><description>&lt;p&gt;
&#20174;&#25104;&#21592;&#21644;&#20559;&#22909;&#26597;&#35810;&#20013;&#23398;&#20064;&#24418;&#24335;&#35268;&#33539;
&lt;/p&gt;
&lt;p&gt;
Learning Formal Specifications from Membership and Preference Queries. (arXiv:2307.10434v1 [cs.FL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10434
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35831;&#27714;&#25104;&#21592;&#26631;&#31614;&#21644;&#25104;&#23545;&#20559;&#22909;&#26469;&#25193;&#23637;&#20027;&#21160;&#35268;&#33539;&#23398;&#20064;&#65292;&#25552;&#39640;&#23398;&#20064;&#24418;&#24335;&#35268;&#33539;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#23454;&#39564;&#20013;&#65292;&#32467;&#26524;&#34920;&#26126;&#36890;&#36807;&#23398;&#20064;&#25104;&#21592;&#21644;&#20559;&#22909;&#30340;&#32452;&#21512;&#21487;&#20197;&#31283;&#23450;&#21644;&#26041;&#20415;&#22320;&#35782;&#21035;&#35268;&#33539;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#30740;&#31350;&#24191;&#27867;&#30340;&#23398;&#20064;&#24418;&#24335;&#35268;&#33539;&#30340;&#26041;&#27861;&#65292;&#20363;&#22914;&#33258;&#21160;&#26426;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#23558;&#20027;&#21160;&#35268;&#33539;&#23398;&#20064;&#25193;&#23637;&#21040;&#35831;&#27714;&#32452;&#21512;&#25104;&#21592;&#26631;&#31614;&#21644;&#25104;&#23545;&#20559;&#22909;&#65288;&#23545;&#25104;&#21592;&#26631;&#31614;&#30340;&#19968;&#31181;&#27969;&#34892;&#26367;&#20195;&#26041;&#24335;&#65289;&#12290;&#25104;&#23545;&#20559;&#22909;&#21644;&#25104;&#21592;&#26631;&#31614;&#30340;&#32452;&#21512;&#20801;&#35768;&#26356;&#28789;&#27963;&#30340;&#20027;&#21160;&#35268;&#33539;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#20808;&#21069;&#20165;&#20381;&#36182;&#25104;&#21592;&#26631;&#31614;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;&#20004;&#20010;&#19981;&#21516;&#30340;&#39046;&#22495;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24191;&#27867;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20174;&#20004;&#31181;&#27169;&#24335;&#23398;&#20064;&#21487;&#20197;&#36890;&#36807;&#25104;&#21592;&#21644;&#20559;&#22909;&#26469;&#31283;&#20581;&#21644;&#26041;&#20415;&#22320;&#35782;&#21035;&#35268;&#33539;&#12290;
&lt;/p&gt;
&lt;p&gt;
Active learning is a well-studied approach to learning formal specifications, such as automata. In this work, we extend active specification learning by proposing a novel framework that strategically requests a combination of membership labels and pair-wise preferences, a popular alternative to membership labels. The combination of pair-wise preferences and membership labels allows for a more flexible approach to active specification learning, which previously relied on membership labels only. We instantiate our framework in two different domains, demonstrating the generality of our approach. Our results suggest that learning from both modalities allows us to robustly and conveniently identify specifications via membership and preferences.
&lt;/p&gt;</description></item><item><title>MDI+&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#26367;&#25442;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;&#24230;&#37327;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#26356;&#36866;&#21512;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2307.01932</link><description>&lt;p&gt;
MDI+:&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MDI+: A Flexible Random Forest-Based Feature Importance Framework. (arXiv:2307.01932v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01932
&lt;/p&gt;
&lt;p&gt;
MDI+&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#26367;&#25442;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;&#24230;&#37327;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#26356;&#36866;&#21512;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#19981;&#32431;&#24230;&#20943;&#23569;&#30340;&#24179;&#22343;&#20540;(MDI)&#26159;&#38543;&#26426;&#26862;&#26519;(RF)&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20272;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;RF&#20013;&#27599;&#20010;&#26641;&#30340;&#29305;&#24449;$X_k$&#30340;MDI&#31561;&#20215;&#20110;&#21709;&#24212;&#21464;&#37327;&#22312;&#20915;&#31574;&#26641;&#38598;&#21512;&#19978;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#26410;&#24402;&#19968;&#21270;$R^2$&#20540;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#35299;&#37322;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;MDI+&#65292;MDI+&#36890;&#36807;&#20801;&#35768;&#20998;&#26512;&#20154;&#21592;&#23558;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;$R^2$&#24230;&#37327;&#26367;&#25442;&#20026;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;(GLM)&#21644;&#26356;&#36866;&#21512;&#32473;&#23450;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#22522;&#20110;&#21487;&#39044;&#27979;&#24615;&#12289;&#21487;&#35745;&#31639;&#24615;&#21644;&#31283;&#23450;&#24615;&#26694;&#26550;&#36873;&#25321;&#36866;&#24403;&#30340;GLM&#21644;&#24230;&#37327;&#30340;&#25351;&#23548;&#65292;&#20197;&#36827;&#34892;&#30495;&#23454;&#25968;&#25454;&#31185;&#23398;&#30740;&#31350;&#12290;&#22823;&#37327;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#25311;&#32467;&#26524;&#26174;&#31034;&#65292;MDI+&#22312;&#24615;&#33021;&#19978;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#30340;MDI&#12290;
&lt;/p&gt;
&lt;p&gt;
Mean decrease in impurity (MDI) is a popular feature importance measure for random forests (RFs). We show that the MDI for a feature $X_k$ in each tree in an RF is equivalent to the unnormalized $R^2$ value in a linear regression of the response on the collection of decision stumps that split on $X_k$. We use this interpretation to propose a flexible feature importance framework called MDI+. Specifically, MDI+ generalizes MDI by allowing the analyst to replace the linear regression model and $R^2$ metric with regularized generalized linear models (GLMs) and metrics better suited for the given data structure. Moreover, MDI+ incorporates additional features to mitigate known biases of decision trees against additive or smooth models. We further provide guidance on how practitioners can choose an appropriate GLM and metric based upon the Predictability, Computability, Stability framework for veridical data science. Extensive data-inspired simulations show that MDI+ significantly outperfor
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#65292;&#21487;&#20197;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20294;&#38656;&#35201;&#27491;&#30830;&#20351;&#29992;&#27491;&#21017;&#21270;&#25216;&#26415;&#20197;&#36991;&#20813;&#27425;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2211.13723</link><description>&lt;p&gt;
&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#26469;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improving Multi-task Learning via Seeking Task-based Flat Regions. (arXiv:2211.13723v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13723
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#65292;&#21487;&#20197;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20294;&#38656;&#35201;&#27491;&#30830;&#20351;&#29992;&#27491;&#21017;&#21270;&#25216;&#26415;&#20197;&#36991;&#20813;&#27425;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#19988;&#24378;&#22823;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#29992;&#20110;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#36890;&#36807;&#21333;&#20010;&#39592;&#24178;&#23398;&#20064;&#22810;&#20010;&#30446;&#26631;&#12290;&#19982;&#21333;&#29420;&#35757;&#32451;&#20219;&#21153;&#30456;&#27604;&#65292;MTL&#26174;&#30528;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#26469;&#28508;&#22312;&#22320;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#23427;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#39046;&#22495;&#65292;&#20174;&#35745;&#31639;&#26426;&#35270;&#35273;&#21040;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35821;&#38899;&#35782;&#21035;&#12290;&#20854;&#20013;&#65292;MTL&#30340;&#19968;&#20010;&#26032;&#20852;&#30740;&#31350;&#26041;&#21521;&#38598;&#20013;&#22312;&#25805;&#32437;&#20219;&#21153;&#26799;&#24230;&#20197;&#25512;&#23548;&#20986;&#23545;&#25152;&#26377;&#20219;&#21153;&#26377;&#30410;&#30340;&#26368;&#32456;&#26799;&#24230;&#19979;&#38477;&#26041;&#21521;&#12290;&#23613;&#31649;&#22312;&#35768;&#22810;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#20294;&#26159;&#22312;&#23454;&#38469;&#38382;&#39064;&#19978;&#30452;&#25509;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;&#32780;&#19981;&#20351;&#29992;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#35299;&#12290;&#29305;&#21035;&#26159;&#65292;&#26631;&#20934;&#35757;&#32451;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#26368;&#23567;&#21270;&#32463;&#39564;&#25439;&#22833;&#65292;&#24456;&#23481;&#26131;&#36973;&#21463;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-Task Learning (MTL) is a widely-used and powerful learning paradigm for training deep neural networks that allows learning more than one objective by a single backbone. Compared to training tasks separately, MTL significantly reduces computational costs, improves data efficiency, and potentially enhances model performance by leveraging knowledge across tasks. Hence, it has been adopted in a variety of applications, ranging from computer vision to natural language processing and speech recognition. Among them, there is an emerging line of work in MTL that focuses on manipulating the task gradient to derive an ultimate gradient descent direction to benefit all tasks. Despite achieving impressive results on many benchmarks, directly applying these approaches without using appropriate regularization techniques might lead to suboptimal solutions on real-world problems. In particular, standard training that minimizes the empirical loss on the training data can easily suffer from overfi
&lt;/p&gt;</description></item></channel></rss>