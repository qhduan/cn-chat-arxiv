<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>TSGCNeXt&#26159;&#19968;&#20010;&#29992;&#20110;&#22522;&#20110;&#39592;&#26550;&#30340;&#21160;&#20316;&#35782;&#21035;&#30340;&#27169;&#22411;&#65292;&#20855;&#26377;&#38271;&#26399;&#23398;&#20064;&#28508;&#21147;&#65292;&#23427;&#37319;&#29992;&#21160;&#38745;&#24577;&#22810;&#22270;&#21367;&#31215;&#26469;&#27719;&#38598;&#22810;&#20010;&#29420;&#31435;&#25299;&#25169;&#22270;&#30340;&#29305;&#24449;&#65292;&#20197;&#21450;&#26500;&#24314;&#20102;&#19968;&#20010;&#22270;&#24418;&#21367;&#31215;&#35757;&#32451;&#21152;&#36895;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2304.11631</link><description>&lt;p&gt;
TSGCNeXt&#65306;&#20855;&#22791;&#38271;&#26399;&#23398;&#20064;&#28508;&#21147;&#30340;&#39640;&#25928;&#22522;&#20110;&#39592;&#26550;&#30340;&#21160;&#20316;&#35782;&#21035;&#30340;&#21160;&#38745;&#24577;&#22810;&#22270;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
TSGCNeXt: Dynamic-Static Multi-Graph Convolution for Efficient Skeleton-Based Action Recognition with Long-term Learning Potential. (arXiv:2304.11631v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11631
&lt;/p&gt;
&lt;p&gt;
TSGCNeXt&#26159;&#19968;&#20010;&#29992;&#20110;&#22522;&#20110;&#39592;&#26550;&#30340;&#21160;&#20316;&#35782;&#21035;&#30340;&#27169;&#22411;&#65292;&#20855;&#26377;&#38271;&#26399;&#23398;&#20064;&#28508;&#21147;&#65292;&#23427;&#37319;&#29992;&#21160;&#38745;&#24577;&#22810;&#22270;&#21367;&#31215;&#26469;&#27719;&#38598;&#22810;&#20010;&#29420;&#31435;&#25299;&#25169;&#22270;&#30340;&#29305;&#24449;&#65292;&#20197;&#21450;&#26500;&#24314;&#20102;&#19968;&#20010;&#22270;&#24418;&#21367;&#31215;&#35757;&#32451;&#21152;&#36895;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#30340;&#21457;&#23637;&#65292;&#22522;&#20110;&#39592;&#26550;&#30340;&#21160;&#20316;&#35782;&#21035;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#26524;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#36235;&#21521;&#20110;&#26500;&#24314;&#20855;&#26377;&#20887;&#20313;&#35757;&#32451;&#30340;&#22797;&#26434;&#23398;&#20064;&#26426;&#21046;&#65292;&#24182;&#23384;&#22312;&#38271;&#26102;&#38388;&#24207;&#21015;&#30340;&#29942;&#39048;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Temporal-Spatio Graph ConvNeXt&#65288;TSGCNeXt&#65289;&#26469;&#25506;&#32034;&#38271;&#26102;&#38388;&#39592;&#39612;&#24207;&#21015;&#30340;&#39640;&#25928;&#23398;&#20064;&#26426;&#21046;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22270;&#24418;&#23398;&#20064;&#26426;&#21046;&#65292;&#21160;&#38745;&#20998;&#31163;&#22810;&#22270;&#21367;&#31215;&#65288;DS-SMG&#65289;&#65292;&#20197;&#27719;&#38598;&#22810;&#20010;&#29420;&#31435;&#25299;&#25169;&#22270;&#30340;&#29305;&#24449;&#24182;&#36991;&#20813;&#33410;&#28857;&#20449;&#24687;&#22312;&#21160;&#24577;&#21367;&#31215;&#26399;&#38388;&#34987;&#24573;&#30053;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22270;&#24418;&#21367;&#31215;&#35757;&#32451;&#21152;&#36895;&#26426;&#21046;&#65292;&#20197;55.08&#65285;&#30340;&#36895;&#24230;&#25552;&#39640;&#21160;&#24577;&#22270;&#24418;&#23398;&#20064;&#30340;&#21453;&#21521;&#20256;&#25773;&#35745;&#31639;&#36895;&#24230;&#12290;&#26368;&#21518;&#65292;TSGCNeXt&#36890;&#36807;&#19977;&#20010;&#26102;&#31354;&#23398;&#20064;&#27169;&#22359;&#37325;&#26032;&#26500;&#24314;&#20102;GCN&#30340;&#25972;&#20307;&#32467;&#26500;&#65292;&#23454;&#29616;&#20102;&#26356;&#21152;&#39640;&#25928;&#30340;&#22522;&#20110;&#39592;&#26550;&#30340;&#21160;&#20316;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Skeleton-based action recognition has achieved remarkable results in human action recognition with the development of graph convolutional networks (GCNs). However, the recent works tend to construct complex learning mechanisms with redundant training and exist a bottleneck for long time-series. To solve these problems, we propose the Temporal-Spatio Graph ConvNeXt (TSGCNeXt) to explore efficient learning mechanism of long temporal skeleton sequences. Firstly, a new graph learning mechanism with simple structure, Dynamic-Static Separate Multi-graph Convolution (DS-SMG) is proposed to aggregate features of multiple independent topological graphs and avoid the node information being ignored during dynamic convolution. Next, we construct a graph convolution training acceleration mechanism to optimize the back-propagation computing of dynamic graph learning with 55.08\% speed-up. Finally, the TSGCNeXt restructure the overall structure of GCN with three Spatio-temporal learning modules,effic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#30340;&#20805;&#20998;&#19981;&#21464;&#23398;&#20064;&#65292;&#35266;&#23519;&#21040;&#20043;&#21069;&#30340;&#24037;&#20316;&#21482;&#23398;&#20064;&#20102;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#20805;&#20998;&#19981;&#21464;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25351;&#20986;&#22312;&#20998;&#24067;&#36716;&#31227;&#26102;&#65292;&#20174;&#35757;&#32451;&#38598;&#20013;&#23398;&#20064;&#30340;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#21487;&#33021;&#19981;&#36866;&#29992;&#20110;&#27979;&#35797;&#38598;&#65292;&#38480;&#21046;&#20102;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2210.13533</link><description>&lt;p&gt;
&#20998;&#24067;&#36716;&#31227;&#30340;&#20805;&#20998;&#19981;&#21464;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sufficient Invariant Learning for Distribution Shift. (arXiv:2210.13533v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13533
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#30340;&#20805;&#20998;&#19981;&#21464;&#23398;&#20064;&#65292;&#35266;&#23519;&#21040;&#20043;&#21069;&#30340;&#24037;&#20316;&#21482;&#23398;&#20064;&#20102;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#20805;&#20998;&#19981;&#21464;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25351;&#20986;&#22312;&#20998;&#24067;&#36716;&#31227;&#26102;&#65292;&#20174;&#35757;&#32451;&#38598;&#20013;&#23398;&#20064;&#30340;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#21487;&#33021;&#19981;&#36866;&#29992;&#20110;&#27979;&#35797;&#38598;&#65292;&#38480;&#21046;&#20102;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23637;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#30340;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#20445;&#35777;&#24615;&#33021;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#25913;&#21892;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#36328;&#32452;&#25110;&#39046;&#22495;&#30340;&#19981;&#21464;&#29305;&#24449;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20043;&#21069;&#30340;&#24037;&#20316;&#21482;&#37096;&#20998;&#22320;&#23398;&#20064;&#20102;&#19981;&#21464;&#29305;&#24449;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#24037;&#20316;&#20391;&#37325;&#20110;&#26377;&#38480;&#30340;&#19981;&#21464;&#29305;&#24449;&#65292;&#20294;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#20805;&#20998;&#19981;&#21464;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#12290;&#30001;&#20110;&#21482;&#26377;&#35757;&#32451;&#38598;&#26159;&#32463;&#39564;&#24615;&#30340;&#65292;&#20174;&#35757;&#32451;&#38598;&#20013;&#23398;&#20064;&#24471;&#21040;&#30340;&#37096;&#20998;&#19981;&#21464;&#29305;&#24449;&#21487;&#33021;&#19981;&#23384;&#22312;&#20110;&#20998;&#24067;&#36716;&#31227;&#26102;&#30340;&#27979;&#35797;&#38598;&#20013;&#12290;&#22240;&#27492;&#65292;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#25552;&#39640;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;&#26412;&#25991;&#35748;&#20026;&#20174;&#35757;&#32451;&#38598;&#20013;&#23398;&#20064;&#20805;&#20998;&#30340;&#19981;&#21464;&#29305;&#24449;&#23545;&#20110;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning algorithms have shown remarkable performance in diverse applications. However, it is still challenging to guarantee performance in distribution shifts when distributions of training and test datasets are different. There have been several approaches to improve the performance in distribution shift cases by learning invariant features across groups or domains. However, we observe that the previous works only learn invariant features partially. While the prior works focus on the limited invariant features, we first raise the importance of the sufficient invariant features. Since only training sets are given empirically, the learned partial invariant features from training sets might not be present in the test sets under distribution shift. Therefore, the performance improvement on distribution shifts might be limited. In this paper, we argue that learning sufficient invariant features from the training set is crucial for the distribution shift case. Concretely, we newly 
&lt;/p&gt;</description></item></channel></rss>