<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#33258;&#21160;&#25512;&#29702;&#31995;&#32479;&#30340;&#21487;&#23457;&#26597;&#24615;&#21644;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#36890;&#36807;&#25216;&#26415;&#21644;&#31038;&#20250;&#25514;&#26045;&#30456;&#32467;&#21512;&#30340;&#26041;&#24335;&#26469;&#22686;&#21152;&#20449;&#20219;&#30340;&#21487;&#33021;&#27493;&#39588;&#12290;</title><link>http://arxiv.org/abs/2309.12351</link><description>&lt;p&gt;
&#22312;&#33258;&#21160;&#25512;&#29702;&#20013;&#24314;&#31435;&#20449;&#20219;
&lt;/p&gt;
&lt;p&gt;
Establishing trust in automated reasoning. (arXiv:2309.12351v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#33258;&#21160;&#25512;&#29702;&#31995;&#32479;&#30340;&#21487;&#23457;&#26597;&#24615;&#21644;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#36890;&#36807;&#25216;&#26415;&#21644;&#31038;&#20250;&#25514;&#26045;&#30456;&#32467;&#21512;&#30340;&#26041;&#24335;&#26469;&#22686;&#21152;&#20449;&#20219;&#30340;&#21487;&#33021;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#19978;&#19990;&#32426;40&#24180;&#20195;&#24320;&#22987;&#65292;&#35745;&#31639;&#26426;&#30340;&#33258;&#21160;&#25512;&#29702;&#24050;&#32463;&#25104;&#20026;&#31185;&#23398;&#30740;&#31350;&#20013;&#26085;&#30410;&#37325;&#35201;&#30340;&#24037;&#20855;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#33258;&#21160;&#25512;&#29702;&#30340;&#35268;&#21017;&#20027;&#35201;&#30001;&#20154;&#31867;&#20197;&#31243;&#24207;&#28304;&#20195;&#30721;&#30340;&#24418;&#24335;&#21046;&#23450;&#12290;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20174;&#22823;&#37327;&#25968;&#25454;&#20013;&#24471;&#20986;&#30340;&#35268;&#21017;&#26159;&#19968;&#31181;&#20114;&#34917;&#30340;&#26041;&#27861;&#65292;&#30446;&#21069;&#27491;&#22312;&#31215;&#26497;&#21457;&#23637;&#20013;&#12290;&#20026;&#20160;&#20040;&#25105;&#20204;&#24212;&#35813;&#20449;&#20219;&#36825;&#20123;&#31995;&#32479;&#20197;&#21450;&#19982;&#20854;&#24110;&#21161;&#19979;&#33719;&#24471;&#30340;&#32467;&#26524;&#30340;&#38382;&#39064;&#65292;&#24050;&#32463;&#34987;&#31185;&#23398;&#21746;&#23398;&#23478;&#20204;&#35752;&#35770;&#36807;&#65292;&#20294;&#20174;&#23454;&#36341;&#32773;&#37027;&#37324;&#25910;&#21040;&#30340;&#20851;&#27880;&#36824;&#24456;&#23569;&#12290;&#26412;&#30740;&#31350;&#37325;&#28857;&#20851;&#27880;&#29420;&#31435;&#23457;&#26597;&#65292;&#36825;&#26159;&#31185;&#23398;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#20449;&#20219;&#26469;&#28304;&#65292;&#24182;&#30830;&#23450;&#24433;&#21709;&#20854;&#21487;&#23457;&#26597;&#24615;&#30340;&#33258;&#21160;&#25512;&#29702;&#31995;&#32479;&#30340;&#29305;&#24615;&#12290;&#23427;&#36824;&#35752;&#35770;&#20102;&#36890;&#36807;&#25216;&#26415;&#21644;&#31038;&#20250;&#25514;&#26045;&#30456;&#32467;&#21512;&#26469;&#22686;&#21152;&#21487;&#23457;&#26597;&#24615;&#21644;&#21487;&#20449;&#24230;&#30340;&#21487;&#33021;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since its beginnings in the 1940s, automated reasoning by computers has become a tool of ever growing importance in scientific research. So far, the rules underlying automated reasoning have mainly been formulated by humans, in the form of program source code. Rules derived from large amounts of data, via machine learning techniques, are a complementary approach currently under intense development. The question of why we should trust these systems, and the results obtained with their help, has been discussed by philosophers of science but has so far received little attention by practitioners. The present work focuses on independent reviewing, an important source of trust in science, and identifies the characteristics of automated reasoning systems that affect their reviewability. It also discusses possible steps towards increasing reviewability and trustworthiness via a combination of technical and social measures.
&lt;/p&gt;</description></item></channel></rss>