<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36890;&#36807;&#30740;&#31350;&#22312;&#32447;&#23398;&#20064;&#21644;&#21338;&#24328;&#35770;&#20013;&#30340;&#22522;&#20934;&#20915;&#31574;&#35774;&#32622;&#65292;&#35780;&#20272;LLM&#20195;&#29702;&#30340;&#20132;&#20114;&#34892;&#20026;&#21644;&#24615;&#33021;&#65292;&#20197;&#20102;&#35299;&#23427;&#20204;&#22312;&#22810;&#20195;&#29702;&#29615;&#22659;&#20013;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.16843</link><description>&lt;p&gt;
LLM&#20195;&#29702;&#26159;&#21542;&#20250;&#24863;&#21040;&#21518;&#24724;&#65311;&#22312;&#32447;&#23398;&#20064;&#21644;&#28216;&#25103;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Do LLM Agents Have Regret? A Case Study in Online Learning and Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16843
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#22312;&#32447;&#23398;&#20064;&#21644;&#21338;&#24328;&#35770;&#20013;&#30340;&#22522;&#20934;&#20915;&#31574;&#35774;&#32622;&#65292;&#35780;&#20272;LLM&#20195;&#29702;&#30340;&#20132;&#20114;&#34892;&#20026;&#21644;&#24615;&#33021;&#65292;&#20197;&#20102;&#35299;&#23427;&#20204;&#22312;&#22810;&#20195;&#29702;&#29615;&#22659;&#20013;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#29992;&#20110;(&#20132;&#20114;&#24335;)&#20915;&#31574;&#21046;&#23450;&#65292;&#36890;&#36807;&#24320;&#21457;&#22522;&#20110;LLM&#30340;&#33258;&#20027;&#20195;&#29702;&#12290;&#23613;&#31649;&#23427;&#20204;&#21462;&#24471;&#20102;&#19981;&#26029;&#30340;&#25104;&#21151;&#65292;&#20294;LLM&#20195;&#29702;&#22312;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#34920;&#29616;&#23578;&#26410;&#36890;&#36807;&#23450;&#37327;&#25351;&#26631;&#36827;&#34892;&#20805;&#20998;&#35843;&#26597;&#65292;&#29305;&#21035;&#26159;&#22312;&#23427;&#20204;&#30456;&#20114;&#20316;&#29992;&#26102;&#30340;&#22810;&#20195;&#29702;&#35774;&#32622;&#20013;&#65292;&#36825;&#26159;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#20856;&#22411;&#22330;&#26223;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;LLM&#20195;&#29702;&#22312;&#36825;&#20123;&#20132;&#20114;&#29615;&#22659;&#20013;&#30340;&#38480;&#21046;&#65292;&#25105;&#20204;&#24314;&#35758;&#30740;&#31350;&#23427;&#20204;&#22312;&#22312;&#32447;&#23398;&#20064;&#21644;&#21338;&#24328;&#35770;&#30340;&#22522;&#20934;&#20915;&#31574;&#35774;&#32622;&#20013;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#36890;&#36807;\emph{&#21518;&#24724;}&#24615;&#33021;&#25351;&#26631;&#36827;&#34892;&#35780;&#20272;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#32463;&#20856;(&#38750;&#24179;&#31283;)&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#20013;&#32463;&#39564;&#24615;&#22320;&#30740;&#31350;LLMs&#30340;&#26080;&#21518;&#24724;&#34892;&#20026;&#65292;&#20197;&#21450;&#24403;LLM&#20195;&#29702;&#36890;&#36807;&#36827;&#34892;&#37325;&#22797;&#28216;&#25103;&#36827;&#34892;&#20132;&#20114;&#26102;&#22343;&#34913;&#30340;&#20986;&#29616;&#12290;&#28982;&#21518;&#25105;&#20204;&#23545;&#26080;&#21518;&#24724;&#34892;&#20026;&#25552;&#20379;&#19968;&#20123;&#29702;&#35770;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16843v1 Announce Type: cross  Abstract: Large language models (LLMs) have been increasingly employed for (interactive) decision-making, via the development of LLM-based autonomous agents. Despite their emerging successes, the performance of LLM agents in decision-making has not been fully investigated through quantitative metrics, especially in the multi-agent setting when they interact with each other, a typical scenario in real-world LLM-agent applications. To better understand the limits of LLM agents in these interactive environments, we propose to study their interactions in benchmark decision-making settings in online learning and game theory, through the performance metric of \emph{regret}. We first empirically study the {no-regret} behaviors of LLMs in canonical (non-stationary) online learning problems, as well as the emergence of equilibria when LLM agents interact through playing repeated games. We then provide some theoretical insights into the no-regret behavior
&lt;/p&gt;</description></item><item><title>Multi&#26159;&#19968;&#20010;&#22810;&#27169;&#24577;&#29702;&#35299;&#30340;&#25490;&#34892;&#27036;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#32508;&#21512;&#25968;&#25454;&#38598;&#65292;&#35780;&#20272;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#29702;&#35299;&#22797;&#26434;&#22270;&#34920;&#21644;&#31185;&#23398;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;&#23427;&#20860;&#20855;&#20934;&#30830;&#21644;&#24320;&#25918;&#24335;&#30340;&#22238;&#31572;&#24418;&#24335;&#65292;&#25361;&#25112;MLLM&#30340;&#21508;&#31181;&#20219;&#21153;&#65292;&#24182;&#21253;&#21547;&#36229;&#36807;18,000&#20010;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.03173</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#65306;&#25991;&#26412;&#21644;&#22270;&#20687;&#30340;&#22810;&#27169;&#24577;&#29702;&#35299;&#25490;&#34892;&#27036;
&lt;/p&gt;
&lt;p&gt;
Multi: Multimodal Understanding Leaderboard with Text and Images
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03173
&lt;/p&gt;
&lt;p&gt;
Multi&#26159;&#19968;&#20010;&#22810;&#27169;&#24577;&#29702;&#35299;&#30340;&#25490;&#34892;&#27036;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#32508;&#21512;&#25968;&#25454;&#38598;&#65292;&#35780;&#20272;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#29702;&#35299;&#22797;&#26434;&#22270;&#34920;&#21644;&#31185;&#23398;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;&#23427;&#20860;&#20855;&#20934;&#30830;&#21644;&#24320;&#25918;&#24335;&#30340;&#22238;&#31572;&#24418;&#24335;&#65292;&#25361;&#25112;MLLM&#30340;&#21508;&#31181;&#20219;&#21153;&#65292;&#24182;&#21253;&#21547;&#36229;&#36807;18,000&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLM&#65289;&#30340;&#24555;&#36895;&#36827;&#23637;&#24378;&#35843;&#20102;&#21521;&#23398;&#26415;&#30028;&#24341;&#20837;&#20855;&#26377;&#25361;&#25112;&#24615;&#32780;&#21448;&#30495;&#23454;&#30340;&#22522;&#20934;&#30340;&#38656;&#27714;&#12290;&#29616;&#26377;&#30340;&#22522;&#20934;&#20027;&#35201;&#20851;&#27880;&#31616;&#21333;&#30340;&#33258;&#28982;&#22270;&#20687;&#29702;&#35299;&#65292;&#20294;Multi&#25104;&#20026;&#20102;MLLM&#30340;&#23574;&#31471;&#22522;&#20934;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#32508;&#21512;&#24615;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;MLLM&#23545;&#29702;&#35299;&#22797;&#26434;&#22270;&#34920;&#21644;&#31185;&#23398;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;&#35813;&#22522;&#20934;&#21453;&#26144;&#20102;&#24403;&#21069;&#30495;&#23454;&#30340;&#32771;&#35797;&#39118;&#26684;&#65292;&#25552;&#20379;&#22810;&#27169;&#24577;&#30340;&#36755;&#20837;&#65292;&#24182;&#35201;&#27714;&#20934;&#30830;&#25110;&#24320;&#25918;&#24335;&#30340;&#22238;&#31572;&#65292;&#31867;&#20284;&#20110;&#29616;&#23454;&#20013;&#30340;&#23398;&#26657;&#32771;&#35797;&#12290;&#23427;&#36890;&#36807;&#21508;&#31181;&#20219;&#21153;&#25361;&#25112;MLLM&#65292;&#20174;&#20844;&#24335;&#25512;&#23548;&#21040;&#22270;&#20687;&#32454;&#33410;&#20998;&#26512;&#65292;&#20197;&#21450;&#36328;&#27169;&#24577;&#25512;&#29702;&#12290;Multi&#21253;&#25324;&#36229;&#36807;18,000&#20010;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#19981;&#21516;&#26684;&#24335;&#30340;&#22522;&#20110;&#31185;&#23398;&#30340;&#38382;&#31572;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;Multi-Elite&#65292;&#19968;&#20010;&#21253;&#21547;500&#20010;&#38382;&#39064;&#30340;&#23376;&#38598;&#65292;&#29992;&#20110;&#27979;&#35797;MLLM&#30340;&#26497;&#31471;&#24773;&#20917;&#65292;&#20197;&#21450;Multi-Extend&#65292;&#36890;&#36807;&#36229;&#36807;4..&#12290;
&lt;/p&gt;
&lt;p&gt;
Rapid progress in multimodal large language models (MLLMs) highlights the need to introduce challenging yet realistic benchmarks to the academic community. Existing benchmarks primarily focus on simple natural image understanding, but Multi emerges as a cutting-edge benchmark for MLLMs, offering a comprehensive dataset for evaluating MLLMs against understanding complex figures and tables, and scientific questions. This benchmark, reflecting current realistic examination styles, provides multimodal inputs and requires responses that are either precise or open-ended, similar to real-life school tests. It challenges MLLMs with a variety of tasks, ranging from formula derivation to image detail analysis, and cross-modality reasoning. Multi includes over 18,000 questions, with a focus on science-based QA in diverse formats. We also introduce Multi-Elite, a 500-question subset for testing the extremities of MLLMs, and Multi-Extend, which enhances In-Context Learning research with more than 4
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#21069;&#39069;&#21494;&#30382;&#23618;&#21551;&#21457;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35268;&#21010;&#26550;&#26500;&#65292;&#21033;&#29992;&#22810;&#20010;&#22522;&#20110;LLM&#30340;&#27169;&#22359;&#23454;&#29616;&#35268;&#21010;&#30340;&#33258;&#20027;&#21327;&#35843;&#65292;&#20174;&#32780;&#22312;&#22788;&#29702;&#38656;&#35201;&#22810;&#27493;&#25512;&#29702;&#25110;&#30446;&#26631;&#23548;&#21521;&#35268;&#21010;&#30340;&#20219;&#21153;&#26102;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.00194</link><description>&lt;p&gt;
&#21463;&#21069;&#39069;&#21494;&#30382;&#23618;&#21551;&#21457;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35268;&#21010;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models. (arXiv:2310.00194v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00194
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#21069;&#39069;&#21494;&#30382;&#23618;&#21551;&#21457;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35268;&#21010;&#26550;&#26500;&#65292;&#21033;&#29992;&#22810;&#20010;&#22522;&#20110;LLM&#30340;&#27169;&#22359;&#23454;&#29616;&#35268;&#21010;&#30340;&#33258;&#20027;&#21327;&#35843;&#65292;&#20174;&#32780;&#22312;&#22788;&#29702;&#38656;&#35201;&#22810;&#27493;&#25512;&#29702;&#25110;&#30446;&#26631;&#23548;&#21521;&#35268;&#21010;&#30340;&#20219;&#21153;&#26102;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#24778;&#20154;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#22312;&#38656;&#35201;&#22810;&#27493;&#25512;&#29702;&#25110;&#30446;&#26631;&#23548;&#21521;&#35268;&#21010;&#30340;&#20219;&#21153;&#20013;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#20154;&#33041;&#20013;&#33719;&#21462;&#28789;&#24863;&#65292;&#21363;&#36890;&#36807;&#21069;&#39069;&#21494;&#30382;&#23618;&#65288;PFC&#65289;&#20013;&#19987;&#38376;&#27169;&#22359;&#30340;&#37325;&#22797;&#20132;&#20114;&#26469;&#23436;&#25104;&#35268;&#21010;&#12290;&#36825;&#20123;&#27169;&#22359;&#25191;&#34892;&#20914;&#31361;&#30417;&#27979;&#12289;&#29366;&#24577;&#39044;&#27979;&#12289;&#29366;&#24577;&#35780;&#20272;&#12289;&#20219;&#21153;&#20998;&#35299;&#21644;&#20219;&#21153;&#21327;&#35843;&#31561;&#21151;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;LLM&#26377;&#26102;&#33021;&#22815;&#21333;&#29420;&#25191;&#34892;&#36825;&#20123;&#21151;&#33021;&#65292;&#20294;&#22312;&#26381;&#21153;&#20110;&#19968;&#20010;&#30446;&#26631;&#26102;&#24448;&#24448;&#38590;&#20197;&#33258;&#20027;&#21327;&#35843;&#23427;&#20204;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#22810;&#20010;&#22522;&#20110;LLM&#65288;GPT-4&#65289;&#27169;&#22359;&#30340;&#40657;&#30418;&#26550;&#26500;&#12290;&#35813;&#26550;&#26500;&#36890;&#36807;&#19987;&#38376;&#30340;PFC&#21551;&#21457;&#27169;&#22359;&#30340;&#20132;&#20114;&#23558;&#19968;&#20010;&#26356;&#22823;&#30340;&#38382;&#39064;&#20998;&#35299;&#20026;&#22810;&#20010;&#23545;LLM&#30340;&#31616;&#30701;&#33258;&#21160;&#35843;&#29992;&#65292;&#20174;&#32780;&#25913;&#21892;&#35268;&#21010;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#35268;&#21010;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#32452;&#21512;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) demonstrate impressive performance on a wide variety of tasks, but they often struggle with tasks that require multi-step reasoning or goal-directed planning. To address this, we take inspiration from the human brain, in which planning is accomplished via the recurrent interaction of specialized modules in the prefrontal cortex (PFC). These modules perform functions such as conflict monitoring, state prediction, state evaluation, task decomposition, and task coordination. We find that LLMs are sometimes capable of carrying out these functions in isolation, but struggle to autonomously coordinate them in the service of a goal. Therefore, we propose a black box architecture with multiple LLM-based (GPT-4) modules. The architecture improves planning through the interaction of specialized PFC-inspired modules that break down a larger problem into multiple brief automated calls to the LLM. We evaluate the combined architecture on two challenging planning tasks -
&lt;/p&gt;</description></item><item><title>LLM-FuncMapper&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;LLM&#23454;&#29616;&#23545;&#24314;&#31569;&#27861;&#35268;&#20013;&#22797;&#26434;&#26465;&#27454;&#30340;&#20989;&#25968;&#35782;&#21035;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;&#21407;&#23376;&#20989;&#25968;&#21644;&#24320;&#21457;&#25552;&#31034;&#27169;&#26495;&#26469;&#35299;&#20915;&#20256;&#32479;&#36923;&#36753;&#34920;&#31034;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2308.08728</link><description>&lt;p&gt;
LLM-FuncMapper:&#36890;&#36807;LLM&#35299;&#37322;&#24314;&#31569;&#27861;&#35268;&#20013;&#30340;&#22797;&#26434;&#26465;&#27454;&#30340;&#20989;&#25968;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
LLM-FuncMapper: Function Identification for Interpreting Complex Clauses in Building Codes via LLM. (arXiv:2308.08728v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08728
&lt;/p&gt;
&lt;p&gt;
LLM-FuncMapper&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;LLM&#23454;&#29616;&#23545;&#24314;&#31569;&#27861;&#35268;&#20013;&#22797;&#26434;&#26465;&#27454;&#30340;&#20989;&#25968;&#35782;&#21035;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;&#21407;&#23376;&#20989;&#25968;&#21644;&#24320;&#21457;&#25552;&#31034;&#27169;&#26495;&#26469;&#35299;&#20915;&#20256;&#32479;&#36923;&#36753;&#34920;&#31034;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#33258;&#21160;&#21270;&#35268;&#21017;&#26816;&#26597;&#65288;ARC&#65289;&#30340;&#20851;&#38190;&#38454;&#27573;&#65292;&#23545;&#30417;&#31649;&#24615;&#25991;&#26412;&#30340;&#35268;&#21017;&#35299;&#37322;&#38656;&#35201;&#30456;&#24403;&#22823;&#30340;&#21162;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#39046;&#22495;&#30693;&#35782;&#21644;&#20256;&#32479;&#36923;&#36753;&#34920;&#31034;&#30340;&#34920;&#36798;&#33021;&#21147;&#26377;&#38480;&#65292;&#35299;&#37322;&#20855;&#26377;&#38544;&#24335;&#23646;&#24615;&#25110;&#22797;&#26434;&#35745;&#31639;&#36923;&#36753;&#30340;&#30417;&#31649;&#26465;&#27454;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22240;&#27492;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35782;&#21035;&#21508;&#31181;&#30417;&#31649;&#26465;&#27454;&#25152;&#38656;&#30340;&#39044;&#23450;&#20041;&#20989;&#25968;&#30340;&#26041;&#27861;LLM-FuncMapper&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#23545;&#24314;&#31569;&#27861;&#35268;&#36827;&#34892;&#31995;&#32479;&#20998;&#26512;&#65292;&#23450;&#20041;&#20102;&#19968;&#31995;&#21015;&#21407;&#23376;&#20989;&#25968;&#65292;&#20197;&#25429;&#25417;&#38544;&#24335;&#23646;&#24615;&#21644;&#22797;&#26434;&#32422;&#26463;&#30340;&#20849;&#20139;&#35745;&#31639;&#36923;&#36753;&#65292;&#21019;&#24314;&#20102;&#24120;&#35265;&#22359;&#30340;&#25968;&#25454;&#24211;&#65292;&#29992;&#20110;&#35299;&#37322;&#30417;&#31649;&#26465;&#27454;&#12290;&#28982;&#21518;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#20855;&#26377;&#24605;&#32500;&#38142;&#30340;&#25552;&#31034;&#27169;&#26495;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#20998;&#31867;&#30340;&#35843;&#20248;&#31574;&#30053;&#36827;&#19968;&#27493;&#22686;&#24378;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#20989;&#25968;&#35782;&#21035;&#21151;&#33021;&#12290;&#26368;&#21518;&#65292;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a vital stage of automated rule checking (ARC), rule interpretation of regulatory texts requires considerable effort. However, interpreting regulatory clauses with implicit properties or complex computational logic is still challenging due to the lack of domain knowledge and limited expressibility of conventional logic representations. Thus, LLM-FuncMapper, an approach to identifying predefined functions needed to interpret various regulatory clauses based on the large language model (LLM), is proposed. First, by systematically analysis of building codes, a series of atomic functions are defined to capture shared computational logics of implicit properties and complex constraints, creating a database of common blocks for interpreting regulatory clauses. Then, a prompt template with the chain of thought is developed and further enhanced with a classification-based tuning strategy, to enable common LLMs for effective function identification. Finally, the proposed approach is validated
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20248;&#21270;&#38382;&#39064;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#12290;&#36890;&#36807;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#19978;&#21319;&#21644;&#25237;&#24433;&#27425;&#26799;&#24230;&#19979;&#38477;&#26356;&#26032;&#21464;&#37327;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20840;&#23616;&#25910;&#25947;&#20013;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#36895;&#29575;&#65292;&#32780;&#19988;&#19981;&#21463;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#22823;&#23567;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2206.02346</link><description>&lt;p&gt;
&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#22312;&#32422;&#26463;MDP&#20013;&#30340;&#25910;&#25947;&#24615;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence and sample complexity of natural policy gradient primal-dual methods for constrained MDPs. (arXiv:2206.02346v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02346
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20248;&#21270;&#38382;&#39064;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#12290;&#36890;&#36807;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#19978;&#21319;&#21644;&#25237;&#24433;&#27425;&#26799;&#24230;&#19979;&#38477;&#26356;&#26032;&#21464;&#37327;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20840;&#23616;&#25910;&#25947;&#20013;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#36895;&#29575;&#65292;&#32780;&#19988;&#19981;&#21463;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#22823;&#23567;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#65292;&#26088;&#22312;&#26368;&#22823;&#21270;&#39044;&#26399;&#24635;&#22870;&#21169;&#65292;&#21516;&#26102;&#28385;&#36275;&#23545;&#39044;&#26399;&#24635;&#25928;&#29992;&#30340;&#32422;&#26463;&#12290;&#25105;&#20204;&#20351;&#29992;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#26469;&#35299;&#20915;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;&#32422;&#26463;MDP&#65289;&#30340;&#25240;&#25187;&#26080;&#38480;&#26102;&#24207;&#20248;&#21270;&#25511;&#21046;&#38382;&#39064;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21407;&#22987;-&#23545;&#20598;&#65288;NPG-PD&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#19978;&#21319;&#26356;&#26032;&#21407;&#22987;&#21464;&#37327;&#65292;&#36890;&#36807;&#25237;&#24433;&#27425;&#26799;&#24230;&#19979;&#38477;&#26356;&#26032;&#23545;&#20598;&#21464;&#37327;&#12290;&#23613;&#31649;&#24213;&#23618;&#26368;&#22823;&#21270;&#28041;&#21450;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#21644;&#38750;&#20984;&#32422;&#26463;&#38598;&#65292;&#20294;&#22312;softmax&#31574;&#30053;&#21442;&#25968;&#21270;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20248;&#21270;&#38388;&#38553;&#21644;&#32422;&#26463;&#36829;&#35268;&#26041;&#38754;&#23454;&#29616;&#20840;&#23616;&#25910;&#25947;&#65292;&#24182;&#20855;&#26377;&#27425;&#32447;&#24615;&#36895;&#29575;&#12290;&#27492;&#31867;&#25910;&#25947;&#19982;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#30340;&#22823;&#23567;&#26080;&#20851;&#65292;&#21363;&#26080;&#32500;&#24230;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#23545;&#25968;&#32447;&#24615;&#21644;&#19968;&#33324;&#24179;&#28369;&#31574;&#30053;&#21442;&#25968;&#21270;&#65292;&#25105;&#20204;&#30830;&#31435;&#20102;&#25910;&#25947;&#24615;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study sequential decision making problems aimed at maximizing the expected total reward while satisfying a constraint on the expected total utility. We employ the natural policy gradient method to solve the discounted infinite-horizon optimal control problem for Constrained Markov Decision Processes (constrained MDPs). Specifically, we propose a new Natural Policy Gradient Primal-Dual (NPG-PD) method that updates the primal variable via natural policy gradient ascent and the dual variable via projected sub-gradient descent. Although the underlying maximization involves a nonconcave objective function and a nonconvex constraint set, under the softmax policy parametrization we prove that our method achieves global convergence with sublinear rates regarding both the optimality gap and the constraint violation. Such convergence is independent of the size of the state-action space, i.e., it is~dimension-free. Furthermore, for log-linear and general smooth policy parametrizations, we esta
&lt;/p&gt;</description></item></channel></rss>