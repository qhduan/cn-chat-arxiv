<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#31216;&#20026;&#35821;&#20041;&#21521;&#37327;&#30340;&#33041;&#25509;&#22320;&#65292;&#36890;&#36807;&#24494;&#35843;&#39044;&#35757;&#32451;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#20351;&#20854;&#26356;&#22909;&#22320;&#19982;&#20154;&#31867;&#22823;&#33041;&#20013;&#35270;&#35273;&#21050;&#28608;&#30340;&#31070;&#32463;&#34920;&#31034;&#23545;&#40784;&#12290;</title><link>https://arxiv.org/abs/2403.15176</link><description>&lt;p&gt;
&#35821;&#20041;&#21521;&#37327;&#30340;&#33041;&#25509;&#22320;&#25913;&#21892;&#20102;&#31070;&#32463;&#35299;&#30721;&#35270;&#35273;&#21050;&#28608;
&lt;/p&gt;
&lt;p&gt;
Brain-grounding of semantic vectors improves neural decoding of visual stimuli
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15176
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#31216;&#20026;&#35821;&#20041;&#21521;&#37327;&#30340;&#33041;&#25509;&#22320;&#65292;&#36890;&#36807;&#24494;&#35843;&#39044;&#35757;&#32451;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#20351;&#20854;&#26356;&#22909;&#22320;&#19982;&#20154;&#31867;&#22823;&#33041;&#20013;&#35270;&#35273;&#21050;&#28608;&#30340;&#31070;&#32463;&#34920;&#31034;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21457;&#23637;&#20934;&#30830;&#20840;&#38754;&#30340;&#31639;&#27861;&#26469;&#35299;&#30721;&#22823;&#33041;&#20869;&#23481;&#26159;&#31070;&#32463;&#31185;&#23398;&#21644;&#33041;&#26426;&#25509;&#21475;&#39046;&#22495;&#30340;&#19968;&#20010;&#38271;&#26399;&#30446;&#26631;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#20102;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23558;&#22823;&#33041;&#27963;&#21160;&#27169;&#24335;&#26144;&#23556;&#21040;&#19968;&#20010;&#35821;&#20041;&#21521;&#37327;&#34920;&#31034;&#30340;&#31070;&#32463;&#35299;&#30721;&#30340;&#21487;&#34892;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#31216;&#20026;&#35821;&#20041;&#21521;&#37327;&#30340;&#33041;&#25509;&#22320;&#65292;&#23427;&#23545;&#39044;&#35757;&#32451;&#30340;&#29305;&#24449;&#21521;&#37327;&#36827;&#34892;&#24494;&#35843;&#65292;&#20197;&#26356;&#22909;&#22320;&#19982;&#20154;&#31867;&#22823;&#33041;&#20013;&#35270;&#35273;&#21050;&#28608;&#30340;&#31070;&#32463;&#34920;&#31034;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15176v1 Announce Type: cross  Abstract: Developing algorithms for accurate and comprehensive neural decoding of mental contents is one of the long-cherished goals in the field of neuroscience and brain-machine interfaces. Previous studies have demonstrated the feasibility of neural decoding by training machine learning models to map brain activity patterns into a semantic vector representation of stimuli. These vectors, hereafter referred as pretrained feature vectors, are usually derived from semantic spaces based solely on image and/or text features and therefore they might have a totally different characteristics than how visual stimuli is represented in the human brain, resulting in limiting the capability of brain decoders to learn this mapping. To address this issue, we propose a representation learning framework, termed brain-grounding of semantic vectors, which fine-tunes pretrained feature vectors to better align with the neural representation of visual stimuli in t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20165;&#26356;&#26032;&#23569;&#37096;&#20998;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#21442;&#25968;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#20840;&#21442;&#25968;&#37325;&#26032;&#35757;&#32451;&#30340;&#20570;&#27861;&#65292;&#22312;&#20462;&#21098;&#21518;&#24674;&#22797;&#25110;&#29978;&#33267;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;PERP&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#21644;&#23384;&#20648;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2312.15230</link><description>&lt;p&gt;
PERP: &#22312;LLMs&#26102;&#20195;&#37325;&#26032;&#24605;&#32771;&#20462;&#21098;-&#37325;&#26032;&#35757;&#32451;&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
PERP: Rethinking the Prune-Retrain Paradigm in the Era of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20165;&#26356;&#26032;&#23569;&#37096;&#20998;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#21442;&#25968;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#20840;&#21442;&#25968;&#37325;&#26032;&#35757;&#32451;&#30340;&#20570;&#27861;&#65292;&#22312;&#20462;&#21098;&#21518;&#24674;&#22797;&#25110;&#29978;&#33267;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;PERP&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#21644;&#23384;&#20648;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#20462;&#21098;&#23454;&#29616;&#39640;&#25928;&#21387;&#32553;&#65292;&#26174;&#33879;&#20943;&#23569;&#23384;&#20648;&#21644;&#35745;&#31639;&#38656;&#27714;&#21516;&#26102;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#12290;&#20687;&#36845;&#20195;&#24133;&#20540;&#20462;&#21098;&#65288;IMP&#65292;Han&#31561;&#65292;2015&#65289;&#36825;&#26679;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#21487;&#20197;&#21435;&#38500;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#65292;&#24182;&#38656;&#35201;&#26114;&#36149;&#30340;&#37325;&#26032;&#35757;&#32451;&#36807;&#31243;&#20197;&#22312;&#20462;&#21098;&#21518;&#24674;&#22797;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20852;&#36215;&#65292;&#30001;&#20110;&#20869;&#23384;&#21644;&#35745;&#31639;&#38480;&#21046;&#65292;&#23436;&#20840;&#37325;&#26032;&#35757;&#32451;&#21464;&#24471;&#19981;&#21487;&#34892;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#37325;&#26032;&#35757;&#32451;&#25152;&#26377;&#21442;&#25968;&#30340;&#20570;&#27861;&#65292;&#36890;&#36807;&#35777;&#26126;&#21482;&#26356;&#26032;&#23569;&#37096;&#20998;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#21442;&#25968;&#36890;&#24120;&#36275;&#20197;&#24674;&#22797;&#29978;&#33267;&#25552;&#39640;&#24615;&#33021;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#20165;&#37325;&#26032;&#35757;&#32451;GPT-&#32467;&#26500;&#30340;0.27%-0.35%&#30340;&#21442;&#25968;&#21363;&#21487;&#22312;&#19981;&#21516;&#31232;&#30095;&#27700;&#24179;&#19978;&#23454;&#29616;&#19982;&#19968;&#27425;&#24615;IMP&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21363;&#20462;&#21098;&#21518;&#21442;&#25968;&#39640;&#25928;&#37325;&#26032;&#35757;&#32451;&#65288;PERP&#65289;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Networks can be efficiently compressed through pruning, significantly reducing storage and computational demands while maintaining predictive performance. Simple yet effective methods like Iterative Magnitude Pruning (IMP, Han et al., 2015) remove less important parameters and require a costly retraining procedure to recover performance after pruning. However, with the rise of Large Language Models (LLMs), full retraining has become infeasible due to memory and compute constraints. In this study, we challenge the practice of retraining all parameters by demonstrating that updating only a small subset of highly expressive parameters is often sufficient to recover or even improve performance compared to full retraining. Surprisingly, retraining as little as 0.27%-0.35% of the parameters of GPT-architectures achieves comparable performance to One Shot IMP across various sparsity levels. Our approach, Parameter-Efficient Retraining after Pruning (PERP), drastically reduces compute a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#38899;&#20048;&#29983;&#25104;AI&#39046;&#22495;&#20013;&#30340;&#29256;&#26435;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;AI&#38899;&#20048;&#29983;&#25104;&#24179;&#21488;&#30340;&#29256;&#31246;&#27169;&#22411;&#65292;&#24182;&#25506;&#35752;&#20102;&#23545;AI&#29983;&#25104;&#38899;&#20048;&#36827;&#34892;&#29256;&#26435;&#24402;&#22240;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2312.06646</link><description>&lt;p&gt;
&#35745;&#31639;&#29256;&#26435;: &#38754;&#21521;&#38899;&#20048;&#29983;&#25104;AI&#30340;&#29256;&#31246;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Computational Copyright: Towards A Royalty Model for Music Generative AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.06646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#38899;&#20048;&#29983;&#25104;AI&#39046;&#22495;&#20013;&#30340;&#29256;&#26435;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;AI&#38899;&#20048;&#29983;&#25104;&#24179;&#21488;&#30340;&#29256;&#31246;&#27169;&#22411;&#65292;&#24182;&#25506;&#35752;&#20102;&#23545;AI&#29983;&#25104;&#38899;&#20048;&#36827;&#34892;&#29256;&#26435;&#24402;&#22240;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;AI&#30340;&#36827;&#27493;&#24341;&#21457;&#20102;&#29256;&#26435;&#25361;&#25112;&#65292;&#22312;&#38899;&#20048;&#34892;&#19994;&#23588;&#20026;&#31361;&#20986;&#12290;&#26412;&#25991;&#20851;&#27880;&#36825;&#20123;&#25361;&#25112;&#30340;&#32463;&#27982;&#26041;&#38754;&#65292;&#24378;&#35843;&#32463;&#27982;&#24433;&#21709;&#22312;&#29256;&#26435;&#39046;&#22495;&#20013;&#26500;&#25104;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#40657;&#30418;&#29983;&#25104;AI&#25216;&#26415;&#30340;&#22797;&#26434;&#24615;&#19981;&#20165;&#34920;&#26126;&#65292;&#32780;&#19988;&#38656;&#35201;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#32570;&#22833;&#65292;&#23548;&#33268;&#30417;&#31649;&#25361;&#25112;&#12290;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#20026;AI&#38899;&#20048;&#29983;&#25104;&#24179;&#21488;&#25552;&#20986;&#28508;&#22312;&#30340;&#29256;&#31246;&#27169;&#22411;&#26469;&#24357;&#34917;&#24403;&#21069;&#26041;&#27861;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#23545;Spotify&#21644;YouTube&#31561;&#24179;&#21488;&#29616;&#26377;&#29256;&#31246;&#27169;&#22411;&#30340;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#23558;&#20854;&#35843;&#25972;&#21040;AI&#29983;&#25104;&#38899;&#20048;&#30340;&#29420;&#29305;&#32972;&#26223;&#20013;&#12290;&#25105;&#20204;&#38754;&#20020;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#26159;&#23558;AI&#29983;&#25104;&#30340;&#38899;&#20048;&#24402;&#22240;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#26377;&#24433;&#21709;&#21147;&#30340;&#29256;&#26435;&#20869;&#23481;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21033;&#29992;&#25968;&#25454;&#24402;&#22240;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advancement of generative AI has given rise to pressing copyright challenges, particularly in music industry. This paper focuses on the economic aspects of these challenges, emphasizing that the economic impact constitutes a central issue in the copyright arena. The complexity of the black-box generative AI technologies not only suggests but necessitates algorithmic solutions. However, such solutions have been largely missing, leading to regulatory challenges in this landscape. We aim to bridge the gap in current approaches by proposing potential royalty models for revenue sharing on AI music generation platforms. Our methodology involves a detailed analysis of existing royalty models in platforms like Spotify and YouTube, and adapting these to the unique context of AI-generated music. A significant challenge we address is the attribution of AI-generated music to influential copyrighted content in the training data. To this end, we present algorithmic solutions employing data attri
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992; EHR &#25968;&#25454;&#36827;&#34892;&#22823;&#35268;&#27169;&#32959;&#30244;&#39118;&#38505;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#21482;&#38656;&#21033;&#29992;&#21382;&#21490;&#30340;&#21307;&#30103;&#26381;&#21153;&#20195;&#30721;&#21644;&#35786;&#26029;&#20449;&#24687;&#26469;&#23454;&#29616;&#26368;&#23567;&#21270;&#30340;&#25968;&#25454;&#38656;&#27714;&#65292;&#36890;&#36807;&#23558;&#23384;&#27963;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#23454;&#29616;&#23545;&#24739;&#32773;&#30284;&#30151;&#39118;&#38505;&#30340;&#20010;&#24615;&#21270;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2309.15039</link><description>&lt;p&gt;
&#32467;&#21512;&#23384;&#27963;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#36827;&#34892;&#32959;&#30244;&#39118;&#38505;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Combining Survival Analysis and Machine Learning for Mass Cancer Risk Prediction using EHR data. (arXiv:2309.15039v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15039
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992; EHR &#25968;&#25454;&#36827;&#34892;&#22823;&#35268;&#27169;&#32959;&#30244;&#39118;&#38505;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#21482;&#38656;&#21033;&#29992;&#21382;&#21490;&#30340;&#21307;&#30103;&#26381;&#21153;&#20195;&#30721;&#21644;&#35786;&#26029;&#20449;&#24687;&#26469;&#23454;&#29616;&#26368;&#23567;&#21270;&#30340;&#25968;&#25454;&#38656;&#27714;&#65292;&#36890;&#36807;&#23558;&#23384;&#27963;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#23454;&#29616;&#23545;&#24739;&#32773;&#30284;&#30151;&#39118;&#38505;&#30340;&#20010;&#24615;&#21270;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32431;&#31929;&#30340;&#21307;&#23398;&#32959;&#30244;&#31579;&#26597;&#26041;&#27861;&#36890;&#24120;&#36153;&#29992;&#39640;&#26114;&#12289;&#32791;&#26102;&#38271;&#65292;&#24182;&#19988;&#20165;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;&#20808;&#36827;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#26041;&#27861;&#22312;&#30284;&#30151;&#26816;&#27979;&#26041;&#38754;&#21457;&#25381;&#20102;&#24040;&#22823;&#20316;&#29992;&#65292;&#20294;&#38656;&#35201;&#29305;&#23450;&#25110;&#28145;&#20837;&#30340;&#21307;&#23398;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#38754;&#24433;&#21709;&#20102;&#30284;&#30151;&#31579;&#26597;&#26041;&#27861;&#30340;&#22823;&#35268;&#27169;&#23454;&#26045;&#12290;&#22240;&#27492;&#65292;&#22522;&#20110;&#24050;&#26377;&#30340;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#25968;&#25454;&#23545;&#24739;&#32773;&#36827;&#34892;&#22823;&#35268;&#27169;&#20010;&#24615;&#21270;&#30284;&#30151;&#39118;&#38505;&#35780;&#20272;&#24212;&#29992;AI&#26041;&#27861;&#26159;&#19968;&#31181;&#39072;&#35206;&#24615;&#30340;&#25913;&#21464;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;EHR&#25968;&#25454;&#36827;&#34892;&#22823;&#35268;&#27169;&#32959;&#30244;&#39118;&#38505;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#30340;&#25968;&#25454;&#36138;&#23146;&#31574;&#30053;&#33073;&#39062;&#32780;&#20986;&#65292;&#20165;&#38656;&#35201;&#26469;&#33258;EHR&#30340;&#21307;&#30103;&#26381;&#21153;&#20195;&#30721;&#21644;&#35786;&#26029;&#21382;&#21490;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#20108;&#20998;&#31867;&#38382;&#39064;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;175441&#21517;&#19981;&#35760;&#21517;&#30340;&#24739;&#32773;&#65288;&#20854;&#20013;2861&#21517;&#34987;&#35786;&#26029;&#20026;&#30284;&#30151;&#65289;&#12290;&#20316;&#20026;&#22522;&#20934;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#23558;&#23384;&#27963;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;
&lt;/p&gt;
&lt;p&gt;
Purely medical cancer screening methods are often costly, time-consuming, and weakly applicable on a large scale. Advanced Artificial Intelligence (AI) methods greatly help cancer detection but require specific or deep medical data. These aspects affect the mass implementation of cancer screening methods. For these reasons, it is a disruptive change for healthcare to apply AI methods for mass personalized assessment of the cancer risk among patients based on the existing Electronic Health Records (EHR) volume.  This paper presents a novel method for mass cancer risk prediction using EHR data. Among other methods, our one stands out by the minimum data greedy policy, requiring only a history of medical service codes and diagnoses from EHR. We formulate the problem as a binary classification. This dataset contains 175 441 de-identified patients (2 861 diagnosed with cancer). As a baseline, we implement a solution based on a recurrent neural network (RNN). We propose a method that combine
&lt;/p&gt;</description></item></channel></rss>