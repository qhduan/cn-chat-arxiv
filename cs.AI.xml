<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>LLM&#21551;&#29992;&#20102;&#22522;&#20110;&#31574;&#30053;&#30340;&#22810;&#27169;&#26597;&#35810;&#20248;&#21270;&#22120;&#65292;&#25670;&#33073;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#20026;&#26597;&#35810;&#20248;&#21270;&#24102;&#26469;&#20840;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.13597</link><description>&lt;p&gt;
&#19981;&#20877;&#26377;&#20248;&#21270;&#35268;&#21017;: &#22522;&#20110;LLM&#30340;&#22522;&#20110;&#31574;&#30053;&#30340;&#22810;&#27169;&#26597;&#35810;&#20248;&#21270;&#22120;&#65288;&#29256;&#26412;1&#65289;
&lt;/p&gt;
&lt;p&gt;
No more optimization rules: LLM-enabled policy-based multi-modal query optimizer (version 1)
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13597
&lt;/p&gt;
&lt;p&gt;
LLM&#21551;&#29992;&#20102;&#22522;&#20110;&#31574;&#30053;&#30340;&#22810;&#27169;&#26597;&#35810;&#20248;&#21270;&#22120;&#65292;&#25670;&#33073;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#20026;&#26597;&#35810;&#20248;&#21270;&#24102;&#26469;&#20840;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#26631;&#24535;&#30528;&#19968;&#20010;&#37325;&#35201;&#26102;&#21051;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#30740;&#31350;&#20102;LLM&#22312;&#26597;&#35810;&#35268;&#21010;&#20013;&#30340;&#33021;&#21147;&#65292;&#21253;&#25324;&#21333;&#27169;&#21644;&#22810;&#27169;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;LLM&#30340;&#26597;&#35810;&#20248;&#21270;&#33021;&#21147;&#36824;&#27809;&#26377;&#30456;&#20851;&#30740;&#31350;&#12290;&#20316;&#20026;&#26174;&#33879;&#24433;&#21709;&#26597;&#35810;&#35745;&#21010;&#25191;&#34892;&#24615;&#33021;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#19981;&#24212;&#38169;&#36807;&#36825;&#31181;&#20998;&#26512;&#21644;&#23581;&#35797;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#29616;&#26377;&#30340;&#26597;&#35810;&#20248;&#21270;&#22120;&#36890;&#24120;&#26159;&#22522;&#20110;&#35268;&#21017;&#25110;&#22522;&#20110;&#35268;&#21017;+&#22522;&#20110;&#25104;&#26412;&#30340;&#65292;&#21363;&#23427;&#20204;&#20381;&#36182;&#20110;&#20154;&#24037;&#21019;&#24314;&#30340;&#35268;&#21017;&#26469;&#23436;&#25104;&#26597;&#35810;&#35745;&#21010;&#37325;&#20889;/&#36716;&#25442;&#12290;&#37492;&#20110;&#29616;&#20195;&#20248;&#21270;&#22120;&#21253;&#25324;&#25968;&#30334;&#33267;&#25968;&#21315;&#26465;&#35268;&#21017;&#65292;&#25353;&#29031;&#31867;&#20284;&#26041;&#24335;&#35774;&#35745;&#19968;&#20010;&#22810;&#27169;&#26597;&#35810;&#20248;&#21270;&#22120;&#23558;&#32791;&#36153;&#22823;&#37327;&#26102;&#38388;&#65292;&#22240;&#20026;&#25105;&#20204;&#23558;&#19981;&#24471;&#19981;&#21015;&#20030;&#23613;&#21487;&#33021;&#22810;&#30340;&#22810;&#27169;&#20248;&#21270;&#35268;&#21017;&#65292;&#32780;&#36825;&#24182;&#27809;&#26377;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13597v1 Announce Type: cross  Abstract: Large language model (LLM) has marked a pivotal moment in the field of machine learning and deep learning. Recently its capability for query planning has been investigated, including both single-modal and multi-modal queries. However, there is no work on the query optimization capability of LLM. As a critical (or could even be the most important) step that significantly impacts the execution performance of the query plan, such analysis and attempts should not be missed. From another aspect, existing query optimizers are usually rule-based or rule-based + cost-based, i.e., they are dependent on manually created rules to complete the query plan rewrite/transformation. Given the fact that modern optimizers include hundreds to thousands of rules, designing a multi-modal query optimizer following a similar way is significantly time-consuming since we will have to enumerate as many multi-modal optimization rules as possible, which has not be
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#21644;&#28436;&#31034;&#23398;&#20064; DFA&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#20855;&#22791;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07051</link><description>&lt;p&gt;
$L^*LM$: &#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23450;&#20041;&#31034;&#20363;&#23398;&#20064;&#33258;&#21160;&#26426;
&lt;/p&gt;
&lt;p&gt;
$L^*LM$: Learning Automata from Examples using Natural Language Oracles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07051
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#21644;&#28436;&#31034;&#23398;&#20064; DFA&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#20855;&#22791;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#23478;&#28436;&#31034;&#24050;&#34987;&#35777;&#26126;&#26159;&#31616;&#21270;&#38388;&#25509;&#25351;&#23450;&#22797;&#26434;&#20219;&#21153;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#31639;&#27861;&#29978;&#33267;&#25903;&#25345;&#20174;&#28436;&#31034;&#20013;&#25552;&#21462;&#26126;&#30830;&#30340;&#24418;&#24335;&#35268;&#33539;&#65292;&#22914;&#30830;&#23450;&#24615;&#26377;&#38480;&#33258;&#21160;&#26426;&#65288;DFA&#65289;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#25216;&#26415;&#36890;&#24120;&#19981;&#20855;&#22791;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#28436;&#31034;&#21644;&#33258;&#28982;&#35821;&#35328;&#20013;&#23398;&#20064; DFA&#12290;&#30001;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20174;&#19987;&#23478;&#28436;&#31034;&#20013;&#23398;&#20064; DFA &#30340;&#25968;&#25454;&#25928;&#29575;&#26174;&#33879;&#25552;&#39640;&#12290;&#20174;&#25216;&#26415;&#19978;&#35762;&#65292;$L^*LM$ &#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#22238;&#31572;&#20851;&#20110;&#24213;&#23618;&#20219;&#21153;&#30340;&#25104;&#21592;&#26597;&#35810;&#12290;&#28982;&#21518;&#23558;&#20854;&#19982;&#26368;&#36817;&#30340;&#28436;&#31034;&#23398;&#20064;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23558;&#23398;&#20064;&#36716;&#21270;&#20026;&#19968;&#31995;&#21015;&#24102;&#26631;&#31614;&#31034;&#20363;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#20004;&#31181;&#27169;&#24577;&#30456;&#20114;&#34917;&#20805;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Expert demonstrations have proven an easy way to indirectly specify complex tasks. Recent algorithms even support extracting unambiguous formal specifications, e.g. deterministic finite automata (DFA), from demonstrations. Unfortunately, these techniques are generally not sample efficient. In this work, we introduce $L^*LM$, an algorithm for learning DFAs from both demonstrations and natural language. Due to the expressivity of natural language, we observe a significant improvement in the data efficiency of learning DFAs from expert demonstrations. Technically, $L^*LM$ leverages large language models to answer membership queries about the underlying task. This is then combined with recent techniques for transforming learning from demonstrations into a sequence of labeled example learning problems. In our experiments, we observe the two modalities complement each other, yielding a powerful few-shot learner.
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.01763</link><description>&lt;p&gt;
&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36935;&#19978;&#21521;&#37327;&#25968;&#25454;&#24211;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
When Large Language Models Meet Vector Databases: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#22312;&#20154;&#31867;&#25991;&#23383;&#22788;&#29702;&#21644;&#29983;&#25104;&#26041;&#38754;&#24320;&#21551;&#20102;&#26032;&#30340;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23427;&#20204;&#30340;&#26174;&#33879;&#22686;&#38271;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30528;&#21253;&#25324;&#24187;&#35273;&#12289;&#20559;&#35265;&#12289;&#23454;&#26102;&#30693;&#35782;&#26356;&#26032;&#20197;&#21450;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#23454;&#26045;&#21644;&#32500;&#25252;&#30340;&#39640;&#25104;&#26412;&#31561;&#37325;&#35201;&#25361;&#25112;&#12290;&#32780;&#21478;&#19968;&#31181;&#26085;&#30410;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#21521;&#37327;&#25968;&#25454;&#24211;&#21017;&#20026;&#36825;&#20123;&#25361;&#25112;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20123;&#25968;&#25454;&#24211;&#25797;&#38271;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#19988;&#23545;&#20110;&#39640;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#21644;&#35821;&#20041;&#25628;&#32034;&#31561;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25972;&#21512;&#65292;&#23427;&#20204;&#26174;&#33879;&#22686;&#24378;&#20102;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#26356;&#26377;&#25928;&#22320;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#36827;&#34892;&#20102;&#28145;&#20837;&#32780;&#29420;&#29305;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent burst in Large Language Models has opened new frontiers in human-like text processing and generation. However, alongside their remarkable growth, Large Language Models have encountered critical challenges including issues of hallucination, bias, real-time knowledge updates, and the high costs of implementation and maintenance in commercial settings. Vector Databases, another increasingly popular tool, offer potential solutions to these challenges. These databases are adept at handling high-dimensional data and are crucial for tasks such as efficient information retrieval and semantic search. By integrating with Large Language Models, they significantly enhance AI systems' ability to manage and utilize diverse data more effectively. This survey paper provides an in-depth and unique analysis of the intersection between Large Language Models and Vector Databases.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20998;&#23618;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#29983;&#29289;&#27963;&#24615;&#24182;&#25214;&#21040;&#19982;&#20043;&#30456;&#20851;&#30340;&#26368;&#37325;&#35201;&#30340;&#25104;&#20998;&#12290;</title><link>https://arxiv.org/abs/2402.01744</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#23618;&#22270;&#35299;&#37322;&#25581;&#31034;&#20998;&#23376;&#25104;&#20998;
&lt;/p&gt;
&lt;p&gt;
Unveiling Molecular Moieties through Hierarchical Graph Explainability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01744
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20998;&#23618;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#29983;&#29289;&#27963;&#24615;&#24182;&#25214;&#21040;&#19982;&#20043;&#30456;&#20851;&#30340;&#26368;&#37325;&#35201;&#30340;&#25104;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#22312;&#25903;&#25345;&#20307;&#22806;&#34394;&#25311;&#31579;&#36873;&#26041;&#38754;&#24050;&#32463;&#20986;&#29616;&#22810;&#24180;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#21367;&#31215;&#26550;&#26500;&#23454;&#29616;&#39640;&#31934;&#24230;&#22810;&#38774;&#26631;&#31579;&#36873;&#30340;GNN&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#20998;&#23618;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#25216;&#26415;&#65292;&#36890;&#36807;&#21033;&#29992;&#20449;&#24687;&#20256;&#36882;&#26426;&#21046;&#65292;&#22312;&#21407;&#23376;&#12289;&#29615;&#21644;&#25972;&#20010;&#20998;&#23376;&#23618;&#38754;&#19978;&#30452;&#25509;&#25429;&#33719;&#20449;&#24687;&#65292;&#20174;&#32780;&#25214;&#21040;&#19982;&#29983;&#29289;&#27963;&#24615;&#39044;&#27979;&#30456;&#20851;&#30340;&#26368;&#37325;&#35201;&#30340;&#25104;&#20998;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#22312;&#25903;&#25345;&#34394;&#25311;&#31579;&#36873;&#26041;&#38754;&#30340;&#20108;&#21313;&#20010;&#32454;&#32990;&#21608;&#26399;&#20381;&#36182;&#24615;&#28608;&#37238;&#38774;&#26631;&#19978;&#25253;&#36947;&#20102;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;GNN&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#20998;&#31867;&#22120;&#36229;&#36234;&#20102;&#20316;&#32773;&#25552;&#20986;&#30340;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#20010;&#20165;&#38024;&#23545;CDK1&#30340;&#39640;&#28789;&#25935;&#24230;&#29256;&#26412;&#30340;GNN&#65292;&#20197;&#20351;&#29992;&#25105;&#20204;&#30340;&#35299;&#37322;&#22120;&#26469;&#36991;&#20813;&#22810;&#31867;&#21035;&#27169;&#22411;&#22266;&#26377;&#30340;&#20559;&#24046;&#12290;&#20998;&#23618;&#35299;&#37322;&#22120;&#24050;&#32463;&#30001;&#19968;&#20301;&#19987;&#23478;&#21270;&#23398;&#23478;&#22312;19&#20010;CDK1&#25209;&#20934;&#33647;&#29289;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background: Graph Neural Networks (GNN) have emerged in very recent years as a powerful tool for supporting in silico Virtual Screening. In this work we present a GNN which uses Graph Convolutional architectures to achieve very accurate multi-target screening. We also devised a hierarchical Explainable Artificial Intelligence (XAI) technique to catch information directly at atom, ring, and whole molecule level by leveraging the message passing mechanism. In this way, we find the most relevant moieties involved in bioactivity prediction. Results: We report a state-of-the-art GNN classifier on twenty Cyclin-dependent Kinase targets in support of VS. Our classifier outperforms previous SOTA approaches proposed by the authors. Moreover, a CDK1-only high-sensitivity version of the GNN has been designed to use our explainer in order to avoid the inherent bias of multi-class models. The hierarchical explainer has been validated by an expert chemist on 19 approved drugs on CDK1. Our explainer 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBMs&#65289;&#26159;&#21542;&#33021;&#22815;&#27491;&#30830;&#25429;&#25417;&#21040;&#27010;&#24565;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#31243;&#24230;&#65292;&#36890;&#36807;&#20998;&#26512;&#23545;&#20110;&#27010;&#24565;&#23616;&#37096;&#24615;&#20043;&#22806;&#29305;&#24449;&#30340;&#21464;&#21270;&#22914;&#20309;&#24433;&#21709;&#27010;&#24565;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2401.01259</link><description>&lt;p&gt;
&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#26159;&#21542;&#36981;&#24490;&#23616;&#37096;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do Concept Bottleneck Models Obey Locality?. (arXiv:2401.01259v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBMs&#65289;&#26159;&#21542;&#33021;&#22815;&#27491;&#30830;&#25429;&#25417;&#21040;&#27010;&#24565;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#31243;&#24230;&#65292;&#36890;&#36807;&#20998;&#26512;&#23545;&#20110;&#27010;&#24565;&#23616;&#37096;&#24615;&#20043;&#22806;&#29305;&#24449;&#30340;&#21464;&#21270;&#22914;&#20309;&#24433;&#21709;&#27010;&#24565;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#24565;&#22522;&#30784;&#23398;&#20064;&#36890;&#36807;&#35299;&#37322;&#20854;&#39044;&#27979;&#32467;&#26524;&#20351;&#29992;&#20154;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#65292;&#25913;&#21892;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#22312;&#36825;&#31181;&#33539;&#24335;&#19979;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20005;&#37325;&#20381;&#36182;&#20110;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#29420;&#31435;&#20110;&#20854;&#20182;&#27010;&#24565;&#30340;&#32473;&#23450;&#27010;&#24565;&#30340;&#23384;&#22312;&#25110;&#19981;&#23384;&#22312;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#28872;&#26263;&#31034;&#36825;&#31181;&#20551;&#35774;&#21487;&#33021;&#22312;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBMs&#65289;&#36825;&#19968;&#20856;&#22411;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#21487;&#35299;&#37322;&#26550;&#26500;&#20013;&#19981;&#33021;&#25104;&#31435;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#36825;&#20123;&#27010;&#24565;&#26082;&#22312;&#31354;&#38388;&#19978;&#65288;&#36890;&#36807;&#23427;&#20204;&#30340;&#20540;&#23436;&#20840;&#30001;&#22266;&#23450;&#23376;&#38598;&#30340;&#29305;&#24449;&#23450;&#20041;&#65289;&#21448;&#22312;&#35821;&#20041;&#19978;&#65288;&#36890;&#36807;&#23427;&#20204;&#30340;&#20540;&#20165;&#19982;&#39044;&#23450;&#20041;&#30340;&#22266;&#23450;&#23376;&#38598;&#30340;&#27010;&#24565;&#30456;&#20851;&#32852;&#65289;&#23450;&#20301;&#26102;&#65292;CBMs&#26159;&#21542;&#27491;&#30830;&#25429;&#25417;&#21040;&#27010;&#24565;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#31243;&#24230;&#12290;&#20026;&#20102;&#29702;&#35299;&#23616;&#37096;&#24615;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#27010;&#24565;&#20043;&#22806;&#30340;&#29305;&#24449;&#21464;&#21270;&#23545;&#27010;&#24565;&#39044;&#27979;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Concept-based learning improves a deep learning model's interpretability by explaining its predictions via human-understandable concepts. Deep learning models trained under this paradigm heavily rely on the assumption that neural networks can learn to predict the presence or absence of a given concept independently of other concepts. Recent work, however, strongly suggests that this assumption may fail to hold in Concept Bottleneck Models (CBMs), a quintessential family of concept-based interpretable architectures. In this paper, we investigate whether CBMs correctly capture the degree of conditional independence across concepts when such concepts are localised both spatially, by having their values entirely defined by a fixed subset of features, and semantically, by having their values correlated with only a fixed subset of predefined concepts. To understand locality, we analyse how changes to features outside of a concept's spatial or semantic locality impact concept predictions. Our
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#19981;&#21516;&#30340;&#22270;&#25299;&#25169;&#23384;&#22312;&#19979;&#65292;&#22270;&#25193;&#25955;&#26041;&#31243;&#22914;&#20309;&#23545;GNN&#36827;&#34892;&#22806;&#25512;&#21644;&#27010;&#25324;&#65292;&#25581;&#31034;&#20102;&#22522;&#20110;&#23616;&#37096;&#25193;&#25955;&#30340;&#29616;&#26377;&#27169;&#22411;&#22312;&#27010;&#25324;&#33021;&#21147;&#19978;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#38750;&#23616;&#37096;&#25193;&#25955;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.06417</link><description>&lt;p&gt;
&#29992;&#20110;&#22270;&#23398;&#20064;&#20013;&#30340;&#25299;&#25169;&#27010;&#25324;&#30340;&#27969;&#21160;&#25193;&#25955;&#21464;&#21387;&#22120;
&lt;/p&gt;
&lt;p&gt;
Advective Diffusion Transformers for Topological Generalization in Graph Learning. (arXiv:2310.06417v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#19981;&#21516;&#30340;&#22270;&#25299;&#25169;&#23384;&#22312;&#19979;&#65292;&#22270;&#25193;&#25955;&#26041;&#31243;&#22914;&#20309;&#23545;GNN&#36827;&#34892;&#22806;&#25512;&#21644;&#27010;&#25324;&#65292;&#25581;&#31034;&#20102;&#22522;&#20110;&#23616;&#37096;&#25193;&#25955;&#30340;&#29616;&#26377;&#27169;&#22411;&#22312;&#27010;&#25324;&#33021;&#21147;&#19978;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#38750;&#23616;&#37096;&#25193;&#25955;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#25193;&#25955;&#26041;&#31243;&#19982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#23494;&#20999;&#30456;&#20851;&#65292;&#24182;&#19988;&#26368;&#36817;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#20316;&#20026;&#20998;&#26512;GNN&#21160;&#21147;&#23398;&#12289;&#24418;&#24335;&#21270;&#20854;&#34920;&#36798;&#33021;&#21147;&#21644;&#35777;&#26126;&#26550;&#26500;&#36873;&#25321;&#30340;&#26377;&#21407;&#21017;&#30340;&#26694;&#26550;&#12290;&#22270;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;GNN&#30340;&#27010;&#25324;&#33021;&#21147;&#12290;&#24403;&#21069;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#38480;&#21046;&#22312;&#20110;&#20551;&#35774;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20013;&#30340;&#22270;&#25299;&#25169;&#26469;&#33258;&#30456;&#21516;&#30340;&#20998;&#24067;&#12290;&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#22270;&#25193;&#25955;&#26041;&#31243;&#22312;&#19981;&#21516;&#22270;&#25299;&#25169;&#23384;&#22312;&#19979;&#30340;&#22806;&#25512;&#21644;&#27010;&#25324;&#33021;&#21147;&#65292;&#36808;&#20986;&#20102;&#35299;&#26512;GNN&#27010;&#25324;&#24615;&#30340;&#19968;&#27493;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22522;&#20110;&#22270;&#19978;&#23616;&#37096;&#25193;&#25955;&#30340;&#29616;&#26377;&#27169;&#22411;&#22312;&#27010;&#25324;&#33021;&#21147;&#19978;&#30340;&#19981;&#36275;&#65292;&#36825;&#26159;&#30001;&#20110;&#23545;&#25299;&#25169;&#21464;&#21270;&#30340;&#25351;&#25968;&#25935;&#24863;&#24615;&#24341;&#36215;&#30340;&#12290;&#38543;&#21518;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#38750;&#23616;&#37096;&#25193;&#25955;&#30340;&#28508;&#21147;&#65292;&#23427;&#20513;&#23548;&#23545;&#23436;&#20840;&#36830;&#25509;&#30340;&#28508;&#22312;&#22270;&#36827;&#34892;&#29305;&#24449;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph diffusion equations are intimately related to graph neural networks (GNNs) and have recently attracted attention as a principled framework for analyzing GNN dynamics, formalizing their expressive power, and justifying architectural choices. One key open questions in graph learning is the generalization capabilities of GNNs. A major limitation of current approaches hinges on the assumption that the graph topologies in the training and test sets come from the same distribution. In this paper, we make steps towards understanding the generalization of GNNs by exploring how graph diffusion equations extrapolate and generalize in the presence of varying graph topologies. We first show deficiencies in the generalization capability of existing models built upon local diffusion on graphs, stemming from the exponential sensitivity to topology variation. Our subsequent analysis reveals the promise of non-local diffusion, which advocates for feature propagation over fully-connected latent gr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20114;&#21160;&#20013;&#38754;&#20020;&#30340;&#21516;&#36136;&#21270;&#21644;&#20559;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#25913;&#21892;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20114;&#21160;&#30340;&#35299;&#20915;&#21150;&#27861;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#36755;&#20986;&#32780;&#19981;&#29306;&#29298;&#29983;&#20135;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.10448</link><description>&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20114;&#21160;&#20197;&#21450;&#31038;&#20250;&#38519;&#38449;
&lt;/p&gt;
&lt;p&gt;
Human-AI Interactions and Societal Pitfalls. (arXiv:2309.10448v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10448
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20114;&#21160;&#20013;&#38754;&#20020;&#30340;&#21516;&#36136;&#21270;&#21644;&#20559;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#25913;&#21892;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20114;&#21160;&#30340;&#35299;&#20915;&#21150;&#27861;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#36755;&#20986;&#32780;&#19981;&#29306;&#29298;&#29983;&#20135;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#19982;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21512;&#20316;&#26102;&#65292;&#29992;&#25143;&#21487;&#33021;&#20250;&#30475;&#21040;&#29983;&#20135;&#21147;&#30340;&#25552;&#21319;&#65292;&#20294;AI&#29983;&#25104;&#30340;&#20869;&#23481;&#21487;&#33021;&#19981;&#23436;&#20840;&#31526;&#21512;&#20182;&#20204;&#30340;&#20559;&#22909;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#31181;&#24433;&#21709;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#20854;&#20013;&#24322;&#36136;&#29992;&#25143;&#36873;&#25321;&#19982;AI&#20849;&#20139;&#22810;&#23569;&#20449;&#24687;&#65292;&#38754;&#20020;&#36755;&#20986;&#20445;&#30495;&#24230;&#21644;&#36890;&#20449;&#25104;&#26412;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20010;&#20307;&#20915;&#31574;&#19982;AI&#35757;&#32451;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#21487;&#33021;&#23548;&#33268;&#31038;&#20250;&#25361;&#25112;&#12290;&#36755;&#20986;&#21487;&#33021;&#21464;&#24471;&#26356;&#21152;&#21516;&#36136;&#21270;&#65292;&#29305;&#21035;&#26159;&#24403;AI&#22312;AI&#29983;&#25104;&#30340;&#20869;&#23481;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#12290;&#32780;&#20219;&#20309;AI&#30340;&#20559;&#35265;&#21487;&#33021;&#25104;&#20026;&#31038;&#20250;&#20559;&#35265;&#12290;&#35299;&#20915;&#21516;&#36136;&#21270;&#21644;&#20559;&#35265;&#38382;&#39064;&#30340;&#21150;&#27861;&#26159;&#25913;&#36827;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#30340;&#20114;&#21160;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#36755;&#20986;&#32780;&#19981;&#29306;&#29298;&#29983;&#20135;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
When working with generative artificial intelligence (AI), users may see productivity gains, but the AI-generated content may not match their preferences exactly. To study this effect, we introduce a Bayesian framework in which heterogeneous users choose how much information to share with the AI, facing a trade-off between output fidelity and communication cost. We show that the interplay between these individual-level decisions and AI training may lead to societal challenges. Outputs may become more homogenized, especially when the AI is trained on AI-generated content. And any AI bias may become societal bias. A solution to the homogenization and bias issues is to improve human-AI interactions, enabling personalized outputs without sacrificing productivity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#36827;&#34892;&#20102;&#33539;&#22260;&#35780;&#20272;&#65292;&#24182;&#35201;&#27714;&#23545;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#27979;&#35797;&#12289;&#20351;&#29992;&#20844;&#35748;&#25968;&#25454;&#38598;&#20197;&#21450;&#30830;&#20445;&#32467;&#26524;&#21487;&#22797;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.04532</link><description>&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#26368;&#26032;&#36235;&#21183;&#65306;&#19968;&#20010;&#33539;&#22260;&#35780;&#20272;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Latest Trends in Artificial Intelligence Technology: A Scoping Review. (arXiv:2305.04532v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#36827;&#34892;&#20102;&#33539;&#22260;&#35780;&#20272;&#65292;&#24182;&#35201;&#27714;&#23545;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#27979;&#35797;&#12289;&#20351;&#29992;&#20844;&#35748;&#25968;&#25454;&#38598;&#20197;&#21450;&#30830;&#20445;&#32467;&#26524;&#21487;&#22797;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#24050;&#32463;&#24191;&#27867;&#24212;&#29992;&#20110;&#22810;&#20010;&#39046;&#22495;&#12290;&#26234;&#33021;&#25163;&#26426;&#12289;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#12289;&#25628;&#32034;&#24341;&#25806;&#21644;&#33258;&#20027;&#39550;&#39542;&#36710;&#36742;&#31561;&#24212;&#29992;&#31243;&#24207;&#37117;&#21033;&#29992;&#20102;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#25353;&#29031; PRISMA &#26694;&#26550;&#23545;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#36827;&#34892;&#20102;&#33539;&#22260;&#35780;&#20272;&#12290;&#30446;&#26631;&#26159;&#23547;&#25214;&#24212;&#29992;&#20110;&#19981;&#21516;&#39046;&#22495;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30740;&#31350;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#12290;&#20174;&#20154;&#24037;&#26234;&#33021;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#36873;&#21462;&#20102;&#19977;&#20010;&#30693;&#21517;&#26399;&#21002;&#65306;&#12298;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#26434;&#24535;&#12299;&#12289;&#12298;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#26434;&#24535;&#12299;&#21644;&#12298;&#26426;&#22120;&#23398;&#20064;&#12299;&#65292;&#24182;&#35266;&#23519;&#20102;2022&#24180;&#21457;&#34920;&#30340;&#25991;&#31456;&#12290;&#23545;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#20102;&#19968;&#23450;&#30340;&#36164;&#26684;&#35201;&#27714;&#65306;&#25216;&#26415;&#24517;&#39035;&#38024;&#23545;&#21487;&#27604;&#36739;&#30340;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#27979;&#35797;&#65292;&#24517;&#39035;&#20351;&#29992;&#20844;&#35748;&#25110;&#20854;&#20182;&#20805;&#20998;&#35777;&#26126;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#24212;&#29992;&#65292;&#24182;&#30830;&#20445;&#32467;&#26524;&#21487;&#22797;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence is more ubiquitous in multiple domains. Smartphones, social media platforms, search engines, and autonomous vehicles are just a few examples of applications that utilize artificial intelligence technologies to enhance their performance. This study carries out a scoping review of the current state-of-the-art artificial intelligence technologies following the PRISMA framework. The goal was to find the most advanced technologies used in different domains of artificial intelligence technology research. Three recognized journals were used from artificial intelligence and machine learning domain: Journal of Artificial Intelligence Research, Journal of Machine Learning Research, and Machine Learning, and articles published in 2022 were observed. Certain qualifications were laid for the technological solutions: the technology must be tested against comparable solutions, commonly approved or otherwise well justified datasets must be used while applying, and results must 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#40065;&#26834;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#35774;&#35745;&#26377;&#24847;&#20041;&#21644;&#21487;&#35299;&#37322;&#30340;&#25552;&#31034;&#38598;&#65292;&#25552;&#39640;&#23567;&#26679;&#26412;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.10805</link><description>&lt;p&gt;
RPLKG: &#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#40065;&#26834;&#25552;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
RPLKG: Robust Prompt Learning with Knowledge Graph. (arXiv:2304.10805v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#40065;&#26834;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#35774;&#35745;&#26377;&#24847;&#20041;&#21644;&#21487;&#35299;&#37322;&#30340;&#25552;&#31034;&#38598;&#65292;&#25552;&#39640;&#23567;&#26679;&#26412;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#27169;&#22411;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#21487;&#36801;&#31227;&#30340;&#65292;&#24182;&#19988;&#23545;&#26410;&#30693;&#25968;&#25454;&#38598;&#20855;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#26368;&#36817;&#65292;&#35832;&#22914;CLIP&#20043;&#31867;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26174;&#30528;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#28982;&#32780;&#65292;&#24403;&#26631;&#35760;&#25968;&#25454;&#38598;&#26377;&#38480;&#26102;&#65292;&#26032;&#25968;&#25454;&#38598;&#25110;&#39046;&#22495;&#30340;&#27867;&#21270;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#25552;&#39640;&#23567;&#26679;&#26412;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#24050;&#32463;&#36827;&#34892;&#20102;&#21508;&#31181;&#21162;&#21147;&#65292;&#22914;&#25552;&#31034;&#23398;&#20064;&#21644;&#36866;&#37197;&#22120;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#23569;&#26679;&#26412;&#33258;&#36866;&#24212;&#26041;&#27861;&#19981;&#20855;&#22791;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#38656;&#35201;&#39640;&#35745;&#31639;&#25104;&#26412;&#26469;&#36827;&#34892;&#33258;&#36866;&#24212;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#40065;&#26834;&#25552;&#31034;&#23398;&#20064;&#65288;RPLKG&#65289;&#12290;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#65292;&#25105;&#20204;&#33258;&#21160;&#35774;&#35745;&#20986;&#21508;&#31181;&#21487;&#35299;&#37322;&#21644;&#26377;&#24847;&#20041;&#30340;&#25552;&#31034;&#38598;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#19968;&#27425;&#27491;&#21521;&#20256;&#36882;&#21518;&#33719;&#24471;&#25552;&#31034;&#38598;&#30340;&#32531;&#23384;&#23884;&#20837;&#12290;&#20043;&#21518;&#65292;&#27169;&#22411;&#20351;&#29992;GumbelSoftmax&#20248;&#21270;&#25552;&#31034;&#36873;&#25321;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale pre-trained models have been known that they are transferable, and they generalize well on the unseen dataset. Recently, multimodal pre-trained models such as CLIP show significant performance improvement in diverse experiments. However, when the labeled dataset is limited, the generalization of a new dataset or domain is still challenging. To improve the generalization performance on few-shot learning, there have been diverse efforts, such as prompt learning and adapter. However, the current few-shot adaptation methods are not interpretable, and they require a high computation cost for adaptation. In this study, we propose a new method, robust prompt learning with knowledge graph (RPLKG). Based on the knowledge graph, we automatically design diverse interpretable and meaningful prompt sets. Our model obtains cached embeddings of prompt sets after one forwarding from a large pre-trained model. After that, model optimizes the prompt selection processes with GumbelSoftmax. In
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#36890;&#29992;&#27169;&#22411;&#8212;&#8212;&#19981;&#23450;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;&#65307;&#23427;&#21487;&#20197;&#36827;&#34892;&#26080;&#30417;&#30563;&#32858;&#31867;&#21644;&#20351;&#29992;&#24456;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#22823;&#35268;&#27169;&#20998;&#31867;&#65292;&#20854;&#29702;&#35770;&#20248;&#21183;&#20307;&#29616;&#22312;&#26032;&#30340;&#27010;&#29575;&#29702;&#35770;&#21644;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#12290;</title><link>http://arxiv.org/abs/2303.11536</link><description>&lt;p&gt;
&#19981;&#23450;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Indeterminate Probability Neural Network. (arXiv:2303.11536v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11536
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#36890;&#29992;&#27169;&#22411;&#8212;&#8212;&#19981;&#23450;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;&#65307;&#23427;&#21487;&#20197;&#36827;&#34892;&#26080;&#30417;&#30563;&#32858;&#31867;&#21644;&#20351;&#29992;&#24456;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#22823;&#35268;&#27169;&#20998;&#31867;&#65292;&#20854;&#29702;&#35770;&#20248;&#21183;&#20307;&#29616;&#22312;&#26032;&#30340;&#27010;&#29575;&#29702;&#35770;&#21644;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;IPNN&#30340;&#26032;&#22411;&#36890;&#29992;&#27169;&#22411;&#65292;&#23427;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#27010;&#29575;&#35770;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#22312;&#20256;&#32479;&#27010;&#29575;&#35770;&#20013;&#65292;&#27010;&#29575;&#30340;&#35745;&#31639;&#26159;&#22522;&#20110;&#20107;&#20214;&#30340;&#21457;&#29983;&#65292;&#32780;&#36825;&#22312;&#24403;&#21069;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#20960;&#20046;&#19981;&#20351;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#29702;&#35770;&#65292;&#23427;&#26159;&#32463;&#20856;&#27010;&#29575;&#35770;&#30340;&#25193;&#23637;&#65292;&#24182;&#20351;&#32463;&#20856;&#27010;&#29575;&#35770;&#25104;&#20026;&#25105;&#20204;&#29702;&#35770;&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#34987;&#23450;&#20041;&#20026;&#27010;&#29575;&#20107;&#20214;&#65292;&#24182;&#22522;&#20110;&#36825;&#20123;&#20107;&#20214;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#25512;&#23548;&#20986;&#20998;&#31867;&#20219;&#21153;&#30340;&#25512;&#29702;&#27169;&#22411;&#12290;IPNN&#23637;&#29616;&#20102;&#26032;&#30340;&#29305;&#24615;&#65306;&#23427;&#22312;&#36827;&#34892;&#20998;&#31867;&#30340;&#21516;&#26102;&#21487;&#20197;&#25191;&#34892;&#26080;&#30417;&#30563;&#32858;&#31867;&#12290;&#27492;&#22806;&#65292;IPNN&#33021;&#22815;&#20351;&#29992;&#38750;&#24120;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#38750;&#24120;&#22823;&#30340;&#20998;&#31867;&#65292;&#20363;&#22914;100&#20010;&#36755;&#20986;&#33410;&#28857;&#30340;&#27169;&#22411;&#21487;&#20197;&#20998;&#31867;10&#20159;&#31867;&#21035;&#12290;&#29702;&#35770;&#20248;&#21183;&#20307;&#29616;&#22312;&#26032;&#30340;&#27010;&#29575;&#29702;&#35770;&#21644;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#65292;&#24182;&#19988;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;IPNN&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new general model called IPNN - Indeterminate Probability Neural Network, which combines neural network and probability theory together. In the classical probability theory, the calculation of probability is based on the occurrence of events, which is hardly used in current neural networks. In this paper, we propose a new general probability theory, which is an extension of classical probability theory, and makes classical probability theory a special case to our theory. Besides, for our proposed neural network framework, the output of neural network is defined as probability events, and based on the statistical analysis of these events, the inference model for classification task is deduced. IPNN shows new property: It can perform unsupervised clustering while doing classification. Besides, IPNN is capable of making very large classification with very small neural network, e.g. model with 100 output nodes can classify 10 billion categories. Theoretical advantages are refl
&lt;/p&gt;</description></item></channel></rss>