<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GraphInstruct&#30340;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#22686;&#24378;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;GraphLM&#21644;&#25552;&#20986;GraphLM+&#27169;&#22411;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#22270;&#25512;&#29702;&#33021;&#21147;&#22686;&#24378;&#12290;</title><link>https://arxiv.org/abs/2403.04483</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#29702;&#35299;&#21644;&#25512;&#29702;&#21151;&#33021;&#22686;&#24378;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;GraphInstruct
&lt;/p&gt;
&lt;p&gt;
GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04483
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GraphInstruct&#30340;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#22686;&#24378;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;GraphLM&#21644;&#25552;&#20986;GraphLM+&#27169;&#22411;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#22270;&#25512;&#29702;&#33021;&#21147;&#22686;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21644;&#22686;&#24378;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36890;&#29992;&#33021;&#21147;&#19968;&#30452;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#22270;&#26159;&#29616;&#23454;&#19990;&#30028;&#20013;&#24120;&#35265;&#30340;&#25968;&#25454;&#32467;&#26500;&#65292;&#29702;&#35299;&#22270;&#25968;&#25454;&#23545;&#20110;&#25512;&#36827;&#36890;&#29992;&#26234;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35780;&#20272;&#21644;&#22686;&#24378;LLMs&#30340;&#22270;&#29702;&#35299;&#33021;&#21147;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GraphInstruct&#30340;&#22522;&#20934;&#65292;&#20840;&#38754;&#21253;&#25324;21&#20010;&#32463;&#20856;&#22270;&#25512;&#29702;&#20219;&#21153;&#65292;&#25552;&#20379;&#22810;&#26679;&#30340;&#22270;&#29983;&#25104;&#27969;&#27700;&#32447;&#21644;&#35814;&#32454;&#30340;&#25512;&#29702;&#27493;&#39588;&#12290;&#22522;&#20110;GraphInstruct&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#39640;&#25928;&#30340;&#25351;&#23548;&#35843;&#25972;&#26500;&#24314;&#20102;GraphLM&#65292;&#23637;&#31034;&#20986;&#26174;&#33879;&#30340;&#22270;&#29702;&#35299;&#33021;&#21147;&#12290;&#20026;&#20102;&#22686;&#24378;LLM&#30340;&#22270;&#25512;&#29702;&#33021;&#21147;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27493;&#39588;&#25513;&#30721;&#35757;&#32451;&#31574;&#30053;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;GraphLM+&#30340;&#27169;&#22411;&#12290;&#20316;&#20026;&#22686;&#24378;LLMs&#22270;&#29702;&#35299;&#21644;&#25512;&#29702;&#33021;&#21147;&#30340;&#20808;&#39537;&#24615;&#21162;&#21147;&#20043;&#19968;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04483v1 Announce Type: new  Abstract: Evaluating and enhancing the general capabilities of large language models (LLMs) has been an important research topic. Graph is a common data structure in the real world, and understanding graph data is a crucial part for advancing general intelligence. To evaluate and enhance the graph understanding abilities of LLMs, in this paper, we propose a benchmark named GraphInstruct, which comprehensively includes 21 classical graph reasoning tasks, providing diverse graph generation pipelines and detailed reasoning steps. Based on GraphInstruct, we further construct GraphLM through efficient instruction-tuning, which shows prominent graph understanding capability. In order to enhance the LLM with graph reasoning capability as well, we propose a step mask training strategy, and construct a model named GraphLM+. As one of the pioneering efforts to enhance the graph understanding and reasoning abilities of LLMs, extensive experiments have demons
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.10656</link><description>&lt;p&gt;
&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65306;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20154;&#31867;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21307;&#30103;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#21892;&#36523;&#20307;&#21644;&#31934;&#31070;&#29366;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65288;VHGM&#65289;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#26377;&#20851;&#21307;&#30103;&#20445;&#20581;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20010;&#24615;&#30340;&#23646;&#24615;&#12290;VHGM&#26159;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20351;&#29992;&#25513;&#30721;&#24314;&#27169;&#35757;&#32451;&#65292;&#22312;&#24050;&#30693;&#23646;&#24615;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#23646;&#24615;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#21033;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#39640;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#25968;&#20540;&#35780;&#20272;&#20102;VHGM&#21450;&#20854;&#35757;&#32451;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20316;&#20026;VHGM&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#24212;&#29992;&#31243;&#24207;&#65292;&#28436;&#31034;&#20102;&#29992;&#25143;&#24773;&#22659;&#65292;&#20363;&#22914;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
&lt;/p&gt;</description></item><item><title>Arukikata&#26053;&#28216;&#28216;&#35760;&#25968;&#25454;&#38598;&#26159;&#19968;&#20010;&#21253;&#21547;&#36229;&#36807;3100&#19975;&#20010;&#26085;&#25991;&#21333;&#35789;&#30340;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;4672&#20010;&#26085;&#26412;&#22269;&#20869;&#28216;&#35760;&#21644;9607&#20010;&#28023;&#22806;&#28216;&#35760;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#21487;&#37325;&#22797;&#21644;&#36879;&#26126;&#30340;&#30740;&#31350;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.11444</link><description>&lt;p&gt;
Arukikata&#26053;&#28216;&#28216;&#35760;&#25968;&#25454;&#38598; (arXiv:2305.11444v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
Arukikata Travelogue Dataset. (arXiv:2305.11444v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11444
&lt;/p&gt;
&lt;p&gt;
Arukikata&#26053;&#28216;&#28216;&#35760;&#25968;&#25454;&#38598;&#26159;&#19968;&#20010;&#21253;&#21547;&#36229;&#36807;3100&#19975;&#20010;&#26085;&#25991;&#21333;&#35789;&#30340;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;4672&#20010;&#26085;&#26412;&#22269;&#20869;&#28216;&#35760;&#21644;9607&#20010;&#28023;&#22806;&#28216;&#35760;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#21487;&#37325;&#22797;&#21644;&#36879;&#26126;&#30340;&#30740;&#31350;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21019;&#24314;&#20102;Arukikata&#26053;&#28216;&#28216;&#35760;&#25968;&#25454;&#38598;&#65292;&#24182;&#20813;&#36153;&#25552;&#20379;&#32473;&#23398;&#26415;&#30740;&#31350;&#20351;&#29992;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#36229;&#36807;3100&#19975;&#20010;&#26085;&#25991;&#21333;&#35789;&#65292;&#21253;&#25324;4672&#20010;&#26085;&#26412;&#22269;&#20869;&#28216;&#35760;&#21644;9607&#20010;&#28023;&#22806;&#28216;&#35760;&#12290;&#22312;&#25105;&#20204;&#25552;&#20379;&#25968;&#25454;&#38598;&#20043;&#21069;&#65292;&#24456;&#38590;&#33719;&#24471;&#21487;&#29992;&#20110;&#30740;&#31350;&#30340;&#24191;&#27867;&#26053;&#28216;&#28216;&#35760;&#25968;&#25454;&#65292;&#27599;&#20010;&#30740;&#31350;&#20154;&#21592;&#37117;&#24517;&#39035;&#20934;&#22791;&#33258;&#24049;&#30340;&#25968;&#25454;&#12290;&#36825;&#38459;&#30861;&#20102;&#23545;&#29616;&#26377;&#30740;&#31350;&#30340;&#22797;&#21046;&#20197;&#21450;&#23545;&#23454;&#39564;&#32467;&#26524;&#36827;&#34892;&#20844;&#27491;&#27604;&#36739;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#20351;&#24471;&#20219;&#20309;&#30740;&#31350;&#20154;&#21592;&#37117;&#21487;&#20197;&#23545;&#30456;&#21516;&#30340;&#25968;&#25454;&#36827;&#34892;&#30740;&#31350;&#65292;&#24182;&#30830;&#20445;&#30740;&#31350;&#30340;&#36879;&#26126;&#24230;&#21644;&#21487;&#37325;&#22797;&#24615;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#30340;&#23398;&#26415;&#24847;&#20041;&#12289;&#29305;&#28857;&#21644;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
We have constructed Arukikata Travelogue Dataset and released it free of charge for academic research. This dataset is a Japanese text dataset with a total of over 31 million words, comprising 4,672 Japanese domestic travelogues and 9,607 overseas travelogues. Before providing our dataset, there was a scarcity of widely available travelogue data for research purposes, and each researcher had to prepare their own data. This hinders the replication of existing studies and fair comparative analysis of experimental results. Our dataset enables any researchers to conduct investigation on the same data and to ensure transparency and reproducibility in research. In this paper, we describe the academic significance, characteristics, and prospects of our dataset.
&lt;/p&gt;</description></item></channel></rss>