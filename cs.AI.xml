<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36825;&#39033;&#35843;&#26597;&#32508;&#36848;&#20102;&#22522;&#20110;LLM&#30340;&#22810;&#36718;&#23545;&#35805;&#31995;&#32479;&#30340;&#30740;&#31350;&#65292;&#24182;&#37325;&#28857;&#20171;&#32461;&#20102;LLMs&#30340;&#24212;&#29992;&#21644;&#26368;&#26032;&#36827;&#23637;&#65292;&#23545;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#21644;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#31995;&#32479;&#36827;&#34892;&#20102;&#28085;&#30422;&#65292;&#24182;&#35752;&#35770;&#20102;&#30456;&#20851;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#65292;&#20197;&#21450;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#21644;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.18013</link><description>&lt;p&gt;
&#22522;&#20110;LLM&#30340;&#22810;&#36718;&#23545;&#35805;&#31995;&#32479;&#26368;&#26032;&#36827;&#23637;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18013
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#32508;&#36848;&#20102;&#22522;&#20110;LLM&#30340;&#22810;&#36718;&#23545;&#35805;&#31995;&#32479;&#30340;&#30740;&#31350;&#65292;&#24182;&#37325;&#28857;&#20171;&#32461;&#20102;LLMs&#30340;&#24212;&#29992;&#21644;&#26368;&#26032;&#36827;&#23637;&#65292;&#23545;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#21644;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#31995;&#32479;&#36827;&#34892;&#20102;&#28085;&#30422;&#65292;&#24182;&#35752;&#35770;&#20102;&#30456;&#20851;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#65292;&#20197;&#21450;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#21644;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#20840;&#38754;&#22238;&#39038;&#20102;&#20851;&#20110;&#22810;&#36718;&#23545;&#35805;&#31995;&#32479;&#30340;&#30740;&#31350;&#65292;&#29305;&#21035;&#20391;&#37325;&#20110;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#22810;&#36718;&#23545;&#35805;&#31995;&#32479;&#12290;&#26412;&#25991;&#26088;&#22312;&#65288;a&#65289;&#24635;&#32467;&#29616;&#26377;&#30340;LLMs&#21644;&#36866;&#24212;LLMs&#36827;&#34892;&#19979;&#28216;&#20219;&#21153;&#30340;&#26041;&#27861;&#65307;&#65288;b&#65289;&#35814;&#32454;&#38416;&#36848;&#22810;&#36718;&#23545;&#35805;&#31995;&#32479;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#28085;&#30422;&#22522;&#20110;LLM&#30340;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#65288;ODD&#65289;&#21644;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#65288;TOD&#65289;&#31995;&#32479;&#65292;&#20197;&#21450;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#65307;&#65288;c&#65289;&#35752;&#35770;&#30001;&#20110;LLMs&#30340;&#21457;&#23637;&#21644;&#23545;&#22810;&#36718;&#23545;&#35805;&#31995;&#32479;&#19981;&#26029;&#22686;&#21152;&#30340;&#38656;&#27714;&#32780;&#20135;&#29983;&#30340;&#26410;&#26469;&#37325;&#28857;&#21644;&#26368;&#26032;&#30740;&#31350;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18013v1 Announce Type: cross  Abstract: This survey provides a comprehensive review of research on multi-turn dialogue systems, with a particular focus on multi-turn dialogue systems based on large language models (LLMs). This paper aims to (a) give a summary of existing LLMs and approaches for adapting LLMs to downstream tasks; (b) elaborate recent advances in multi-turn dialogue systems, covering both LLM-based open-domain dialogue (ODD) and task-oriented dialogue (TOD) systems, along with datasets and evaluation metrics; (c) discuss some future emphasis and recent research problems arising from the development of LLMs and the increasing demands on multi-turn dialogue systems.
&lt;/p&gt;</description></item><item><title>JMA&#26159;&#19968;&#31181;&#36890;&#29992;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#20960;&#20046;&#26368;&#20248;&#30340;&#23450;&#21521;&#23545;&#25239;&#26679;&#26412;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;Jacobian&#24341;&#36215;&#30340;&#39532;&#27663;&#36317;&#31163;&#65292;&#32771;&#34385;&#20102;&#23558;&#36755;&#20837;&#26679;&#26412;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;&#22312;&#32473;&#23450;&#26041;&#21521;&#19978;&#31227;&#21160;&#25152;&#38656;&#30340;&#25237;&#20837;&#12290;&#35813;&#31639;&#27861;&#22312;&#35299;&#20915;&#23545;&#25239;&#26679;&#26412;&#38382;&#39064;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2401.01199</link><description>&lt;p&gt;
JMA:&#19968;&#31181;&#24555;&#36895;&#29983;&#25104;&#20960;&#20046;&#26368;&#20248;&#23450;&#21521;&#23545;&#25239;&#26679;&#26412;&#30340;&#36890;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example. (arXiv:2401.01199v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01199
&lt;/p&gt;
&lt;p&gt;
JMA&#26159;&#19968;&#31181;&#36890;&#29992;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#20960;&#20046;&#26368;&#20248;&#30340;&#23450;&#21521;&#23545;&#25239;&#26679;&#26412;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;Jacobian&#24341;&#36215;&#30340;&#39532;&#27663;&#36317;&#31163;&#65292;&#32771;&#34385;&#20102;&#23558;&#36755;&#20837;&#26679;&#26412;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;&#22312;&#32473;&#23450;&#26041;&#21521;&#19978;&#31227;&#21160;&#25152;&#38656;&#30340;&#25237;&#20837;&#12290;&#35813;&#31639;&#27861;&#22312;&#35299;&#20915;&#23545;&#25239;&#26679;&#26412;&#38382;&#39064;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#20026;&#27490;&#65292;&#22823;&#22810;&#25968;&#29992;&#20110;&#29983;&#25104;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#23450;&#21521;&#23545;&#25239;&#26679;&#26412;&#30340;&#26041;&#27861;&#37117;&#26159;&#39640;&#24230;&#27425;&#20248;&#30340;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#22686;&#21152;&#30446;&#26631;&#31867;&#21035;&#30340;&#21487;&#33021;&#24615;&#65292;&#22240;&#27492;&#38544;&#21547;&#22320;&#19987;&#27880;&#20110;&#19968;&#28909;&#32534;&#30721;&#35774;&#32622;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21152;&#36890;&#29992;&#30340;&#12289;&#29702;&#35770;&#19978;&#21487;&#38752;&#30340;&#23450;&#21521;&#25915;&#20987;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#26368;&#23567;&#21270;&#38597;&#21487;&#27604;&#24341;&#36215;&#30340;&#39532;&#27663;&#36317;&#31163;&#65288;JMA&#65289;&#39033;&#65292;&#32771;&#34385;&#23558;&#36755;&#20837;&#26679;&#26412;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;&#22312;&#32473;&#23450;&#26041;&#21521;&#19978;&#31227;&#21160;&#25152;&#38656;&#30340;&#25237;&#20837;&#65288;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#65289;&#12290;&#36890;&#36807;&#21033;&#29992;&#27779;&#23572;&#22827;&#20108;&#37325;&#24615;&#23450;&#29702;&#27714;&#35299;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#23558;&#38382;&#39064;&#31616;&#21270;&#20026;&#35299;&#38750;&#36127;&#26368;&#23567;&#20108;&#20056;&#65288;NNLS&#65289;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20026;Szegedy&#31561;&#20154;&#26368;&#21021;&#24341;&#20837;&#30340;&#23545;&#25239;&#26679;&#26412;&#38382;&#39064;&#30340;&#32447;&#24615;&#21270;&#29256;&#26412;&#25552;&#20379;&#20102;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#30340;&#25915;&#20987;&#30340;&#24191;&#27867;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most of the approaches proposed so far to craft targeted adversarial examples against Deep Learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings. In this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a Jacobian-induced MAhalanobis distance (JMA) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction. The minimization is solved by exploiting the Wolfe duality theorem, reducing the problem to the solution of a Non-Negative Least Square (NNLS) problem. The proposed algorithm provides an optimal solution to a linearized version of the adversarial example problem originally introduced by Szegedy et al. \cite{szegedy2013intriguing}. The experiments we carried out confirm the generality of the proposed attack which is proven to be 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#22810;&#26426;&#22120;&#20154;&#32452;&#35013;&#35268;&#21010;&#30340;&#31639;&#27861;&#22534;&#26632;&#65292;&#21487;&#20197;&#22312;&#30701;&#26102;&#38388;&#20869;&#21512;&#25104;&#22797;&#26434;&#35013;&#37197;&#30340;&#24314;&#36896;&#35745;&#21010;&#65292;&#24182;&#35299;&#20915;&#20102;&#31227;&#21160;&#33258;&#20027;&#26426;&#22120;&#20154;&#22312;&#21046;&#36896;&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2311.00192</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#22810;&#26426;&#22120;&#20154;&#32452;&#35013;&#35268;&#21010;&#29992;&#20110;&#33258;&#20027;&#21046;&#36896;
&lt;/p&gt;
&lt;p&gt;
Large-Scale Multi-Robot Assembly Planning for Autonomous Manufacturing. (arXiv:2311.00192v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00192
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#22810;&#26426;&#22120;&#20154;&#32452;&#35013;&#35268;&#21010;&#30340;&#31639;&#27861;&#22534;&#26632;&#65292;&#21487;&#20197;&#22312;&#30701;&#26102;&#38388;&#20869;&#21512;&#25104;&#22797;&#26434;&#35013;&#37197;&#30340;&#24314;&#36896;&#35745;&#21010;&#65292;&#24182;&#35299;&#20915;&#20102;&#31227;&#21160;&#33258;&#20027;&#26426;&#22120;&#20154;&#22312;&#21046;&#36896;&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31227;&#21160;&#33258;&#20027;&#26426;&#22120;&#20154;&#26377;&#28508;&#21147;&#38761;&#26032;&#21046;&#36896;&#27969;&#31243;&#12290;&#28982;&#32780;&#65292;&#23558;&#22823;&#22411;&#26426;&#22120;&#20154;&#32676;&#20307;&#24212;&#29992;&#20110;&#21046;&#36896;&#39046;&#22495;&#38656;&#35201;&#35299;&#20915;&#19968;&#20123;&#25361;&#25112;&#65292;&#21253;&#25324;&#22312;&#20849;&#20139;&#24037;&#20316;&#31354;&#38388;&#20013;&#23454;&#29616;&#26080;&#30896;&#25758;&#31227;&#21160;&#65292;&#26377;&#25928;&#30340;&#22810;&#26426;&#22120;&#20154;&#21327;&#20316;&#26469;&#25805;&#32437;&#21644;&#36816;&#36755;&#22823;&#22411;&#36127;&#36733;&#65292;&#30001;&#20110;&#32806;&#21512;&#30340;&#21046;&#36896;&#27969;&#31243;&#23548;&#33268;&#22797;&#26434;&#30340;&#20219;&#21153;&#20998;&#37197;&#65292;&#20197;&#21450;&#23884;&#22871;&#23376;&#35013;&#37197;&#20214;&#30340;&#24182;&#34892;&#35013;&#37197;&#21644;&#36816;&#36755;&#30340;&#31354;&#38388;&#35268;&#21010;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#31639;&#27861;&#22534;&#26632;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#22810;&#26426;&#22120;&#20154;&#32452;&#35013;&#35268;&#21010;&#65292;&#21487;&#20197;&#22312;&#20960;&#20998;&#38047;&#20869;&#21512;&#25104;&#20855;&#26377;&#25968;&#21315;&#20010;&#37096;&#20214;&#30340;&#22797;&#26434;&#35013;&#37197;&#30340;&#24314;&#36896;&#35745;&#21010;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25509;&#21463;&#31867;&#20284;CAD&#30340;&#20135;&#21697;&#35268;&#33539;&#65292;&#24182;&#33258;&#21160;&#20026;&#19968;&#32452;&#26426;&#22120;&#20154;&#35268;&#21010;&#20840;&#26632;&#35013;&#37197;&#36807;&#31243;&#26469;&#21046;&#36896;&#20135;&#21697;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#22534;&#26632;&#65292;&#21253;&#25324;&#65306;(i)&#36845;&#20195;&#24452;&#21521;&#24067;&#23616;&#20248;&#21270;&#36807;&#31243;&#65292;&#23450;&#20041;&#21046;&#36896;&#36807;&#31243;&#30340;&#20840;&#23616;&#35843;&#24230;&#24067;&#23616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mobile autonomous robots have the potential to revolutionize manufacturing processes. However, employing large robot fleets in manufacturing requires addressing challenges including collision-free movement in a shared workspace, effective multi-robot collaboration to manipulate and transport large payloads, complex task allocation due to coupled manufacturing processes, and spatial planning for parallel assembly and transportation of nested subassemblies. We propose a full algorithmic stack for large-scale multi-robot assembly planning that addresses these challenges and can synthesize construction plans for complex assemblies with thousands of parts in a matter of minutes. Our approach takes in a CAD-like product specification and automatically plans a full-stack assembly procedure for a group of robots to manufacture the product. We propose an algorithmic stack that comprises: (i) an iterative radial layout optimization procedure to define a global staging layout for the manufacturin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;SI SL&#65292;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#21644;&#27169;&#22411;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#35268;&#21010;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#19982;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#26041;&#26696;&#30340;&#27604;&#36739;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.08029</link><description>&lt;p&gt;
&#35268;&#21010;&#23398;&#20064;&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Planning to Learn: A Novel Algorithm for Active Learning during Model-Based Planning. (arXiv:2308.08029v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08029
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;SI SL&#65292;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#21644;&#27169;&#22411;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#35268;&#21010;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#19982;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#26041;&#26696;&#30340;&#27604;&#36739;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#25512;&#29702;&#26159;&#19968;&#31181;&#36817;&#26399;&#30340;&#23545;&#19981;&#30830;&#23450;&#24615;&#24773;&#22659;&#19979;&#35268;&#21010;&#24314;&#27169;&#30340;&#26694;&#26550;&#12290;&#29616;&#22312;&#20154;&#20204;&#24050;&#32463;&#24320;&#22987;&#35780;&#20272;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#20197;&#21450;&#22914;&#20309;&#25913;&#36827;&#23427;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#25299;&#23637;-&#22797;&#26434;&#27169;&#22411;&#20248;&#21270;&#31639;&#27861;&#36890;&#36807;&#36882;&#24402;&#20915;&#31574;&#26641;&#25628;&#32034;&#22312;&#22810;&#27493;&#35268;&#21010;&#38382;&#39064;&#19978;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#24456;&#23569;&#26377;&#24037;&#20316;&#23545;&#27604;SI&#19982;&#20854;&#20182;&#24050;&#24314;&#31435;&#30340;&#35268;&#21010;&#31639;&#27861;&#12290;SI&#31639;&#27861;&#20063;&#20027;&#35201;&#20851;&#27880;&#25512;&#29702;&#32780;&#19981;&#26159;&#23398;&#20064;&#12290;&#26412;&#25991;&#26377;&#20004;&#20010;&#30446;&#26631;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#27604;&#36739;SI&#19982;&#26088;&#22312;&#35299;&#20915;&#30456;&#20284;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26041;&#26696;&#30340;&#24615;&#33021;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SI&#22797;&#26434;&#23398;&#20064;&#65288;SL&#65289;&#30340;&#25299;&#23637;&#65292;&#35813;&#25299;&#23637;&#22312;&#35268;&#21010;&#36807;&#31243;&#20013;&#26356;&#21152;&#20805;&#20998;&#22320;&#24341;&#20837;&#20102;&#20027;&#21160;&#23398;&#20064;&#12290;SL&#32500;&#25345;&#23545;&#26410;&#26469;&#35266;&#27979;&#19979;&#27599;&#20010;&#31574;&#30053;&#19979;&#27169;&#22411;&#21442;&#25968;&#22914;&#20309;&#21464;&#21270;&#30340;&#20449;&#24565;&#12290;&#36825;&#20801;&#35768;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#30340;&#22238;&#39038;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Active Inference is a recent framework for modeling planning under uncertainty. Empirical and theoretical work have now begun to evaluate the strengths and weaknesses of this approach and how it might be improved. A recent extension - the sophisticated inference (SI) algorithm - improves performance on multi-step planning problems through recursive decision tree search. However, little work to date has been done to compare SI to other established planning algorithms. SI was also developed with a focus on inference as opposed to learning. The present paper has two aims. First, we compare performance of SI to Bayesian reinforcement learning (RL) schemes designed to solve similar problems. Second, we present an extension of SI sophisticated learning (SL) - that more fully incorporates active learning during planning. SL maintains beliefs about how model parameters would change under the future observations expected under each policy. This allows a form of counterfactual retrospective in
&lt;/p&gt;</description></item></channel></rss>