<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#33258;&#20027;&#24335;MARL&#65288;SPMARL&#65289;&#20197;&#35299;&#20915;&#24403;&#21069;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#35838;&#31243;&#29983;&#25104;&#30340;&#38382;&#39064;&#65292;&#20248;&#20808;&#32771;&#34385;&#22522;&#20110;&#20219;&#21153;&#30340;&#20248;&#20808;&#32423;&#12290;</title><link>https://arxiv.org/abs/2205.10016</link><description>&lt;p&gt;
&#23398;&#20064;&#36827;&#24230;&#39537;&#21160;&#30340;&#22810;&#26234;&#33021;&#20307;&#35838;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning Progress Driven Multi-Agent Curriculum
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.10016
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#33258;&#20027;&#24335;MARL&#65288;SPMARL&#65289;&#20197;&#35299;&#20915;&#24403;&#21069;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#35838;&#31243;&#29983;&#25104;&#30340;&#38382;&#39064;&#65292;&#20248;&#20808;&#32771;&#34385;&#22522;&#20110;&#20219;&#21153;&#30340;&#20248;&#20808;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35838;&#31243;&#24378;&#21270;&#23398;&#20064;&#65288;CRL&#65289;&#26088;&#22312;&#36890;&#36807;&#36880;&#28176;&#22686;&#21152;&#20219;&#21153;&#30340;&#38590;&#24230;&#65288;&#36890;&#24120;&#30001;&#21487;&#23454;&#29616;&#30340;&#39044;&#26399;&#22238;&#25253;&#37327;&#21270;&#65289;&#26469;&#21152;&#24555;&#23398;&#20064;&#36895;&#24230;&#12290;&#21463;CRL&#22312;&#21333;&#26234;&#33021;&#20307;&#29615;&#22659;&#20013;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#19968;&#20123;&#30740;&#31350;&#23581;&#35797;&#23558;CRL&#24212;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#65292;&#20351;&#29992;&#26234;&#33021;&#20307;&#25968;&#37327;&#26469;&#25511;&#21046;&#20219;&#21153;&#38590;&#24230;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#36890;&#24120;&#20351;&#29992;&#25163;&#21160;&#23450;&#20041;&#30340;&#35838;&#31243;&#65292;&#22914;&#32447;&#24615;&#26041;&#26696;&#12290;&#26412;&#25991;&#39318;&#20808;&#23558;&#26368;&#20808;&#36827;&#30340;&#21333;&#26234;&#33021;&#20307;&#33258;&#20027;&#24335;CRL&#24212;&#29992;&#20110;&#31232;&#30095;&#22870;&#21169;MARL&#12290;&#34429;&#28982;&#34920;&#29616;&#20196;&#20154;&#28385;&#24847;&#65292;&#20294;&#25105;&#20204;&#30830;&#23450;&#20102;&#29616;&#26377;&#22522;&#20110;&#22870;&#21169;&#30340;CRL&#26041;&#27861;&#29983;&#25104;&#30340;&#35838;&#31243;&#23384;&#22312;&#20004;&#20010;&#28508;&#22312;&#32570;&#38519;&#65306;&#65288;1&#65289;&#39640;&#22238;&#25253;&#30340;&#20219;&#21153;&#21487;&#33021;&#19981;&#25552;&#20379;&#20449;&#24687;&#37327;&#22823;&#30340;&#23398;&#20064;&#20449;&#21495;&#65292;&#65288;2&#65289;&#22312;&#22810;&#26234;&#33021;&#20307;&#20135;&#29983;&#26356;&#39640;&#22238;&#25253;&#30340;&#20219;&#21153;&#20013;&#65292;&#21152;&#21095;&#20102;&#23398;&#20998;&#20998;&#37197;&#22256;&#38590;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#33258;&#20027;&#24335;MARL&#65288;SPMARL&#65289;&#65292;&#20197;&#22522;&#20110;&#20219;&#21153;&#30340;&#20248;&#20808;&#32423;&#36827;&#34892;&#23433;&#25490;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2205.10016v2 Announce Type: replace  Abstract: Curriculum reinforcement learning (CRL) aims to speed up learning by gradually increasing the difficulty of a task, usually quantified by the achievable expected return. Inspired by the success of CRL in single-agent settings, a few works have attempted to apply CRL to multi-agent reinforcement learning (MARL) using the number of agents to control task difficulty. However, existing works typically use manually defined curricula such as a linear scheme. In this paper, we first apply state-of-the-art single-agent self-paced CRL to sparse reward MARL. Although with satisfying performance, we identify two potential flaws of the curriculum generated by existing reward-based CRL methods: (1) tasks with high returns may not provide informative learning signals and (2) the exacerbated credit assignment difficulty in tasks where more agents yield higher returns. Thereby, we further propose self-paced MARL (SPMARL) to prioritize tasks based on
&lt;/p&gt;</description></item><item><title>CreativeSynth&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#27169;&#24577;&#25193;&#25955;&#30340;&#21019;&#26032;&#32479;&#19968;&#26694;&#26550;&#65292;&#36890;&#36807;&#25972;&#21512;&#22810;&#27169;&#24577;&#29305;&#24449;&#21644;&#23450;&#21046;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#35821;&#20041;&#20869;&#23481;&#23548;&#20837;&#21040;&#33402;&#26415;&#39046;&#22495;&#20013;&#65292;&#33021;&#22815;&#21327;&#35843;&#22810;&#27169;&#24577;&#36755;&#20837;&#21644;&#22810;&#20219;&#21153;&#65292;&#22312;&#33402;&#26415;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2401.14066</link><description>&lt;p&gt;
CreativeSynth&#65306;&#22522;&#20110;&#22810;&#27169;&#24577;&#25193;&#25955;&#30340;&#35270;&#35273;&#33402;&#26415;&#21019;&#24847;&#34701;&#21512;&#19982;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion. (arXiv:2401.14066v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14066
&lt;/p&gt;
&lt;p&gt;
CreativeSynth&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#27169;&#24577;&#25193;&#25955;&#30340;&#21019;&#26032;&#32479;&#19968;&#26694;&#26550;&#65292;&#36890;&#36807;&#25972;&#21512;&#22810;&#27169;&#24577;&#29305;&#24449;&#21644;&#23450;&#21046;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#35821;&#20041;&#20869;&#23481;&#23548;&#20837;&#21040;&#33402;&#26415;&#39046;&#22495;&#20013;&#65292;&#33021;&#22815;&#21327;&#35843;&#22810;&#27169;&#24577;&#36755;&#20837;&#21644;&#22810;&#20219;&#21153;&#65292;&#22312;&#33402;&#26415;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#27493;&#65292;&#23637;&#31034;&#20102;&#20854;&#21512;&#25104;&#21508;&#31181;&#39640;&#36136;&#37327;&#22270;&#20687;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#33402;&#26415;&#22270;&#20687;&#32534;&#36753;&#38754;&#20020;&#20004;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#29992;&#25143;&#24448;&#24448;&#38590;&#20197;&#26500;&#24314;&#35814;&#32454;&#25551;&#36848;&#36755;&#20837;&#22270;&#20687;&#35270;&#35273;&#20803;&#32032;&#30340;&#25991;&#26412;&#25552;&#31034;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#27169;&#22411;&#22312;&#29305;&#23450;&#21306;&#22495;&#36827;&#34892;&#20462;&#25913;&#26102;&#24120;&#24120;&#20250;&#30772;&#22351;&#25972;&#20307;&#33402;&#26415;&#39118;&#26684;&#65292;&#20351;&#24471;&#23454;&#29616;&#19968;&#33268;&#19988;&#20855;&#26377;&#23457;&#32654;&#32479;&#19968;&#30340;&#20316;&#21697;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38556;&#30861;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#32479;&#19968;&#26694;&#26550;CreativeSynth&#65292;&#35813;&#26694;&#26550;&#22522;&#20110;&#20855;&#26377;&#21327;&#35843;&#22810;&#27169;&#24577;&#36755;&#20837;&#21644;&#22810;&#20219;&#21153;&#33021;&#21147;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#25972;&#21512;&#22810;&#27169;&#24577;&#29305;&#24449;&#21644;&#23450;&#21046;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;CreativeSynth&#23454;&#29616;&#20102;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#35821;&#20041;&#20869;&#23481;&#23548;&#20837;&#21040;&#33402;&#26415;&#39046;&#22495;&#20013;&#65292;&#23454;&#29616;&#20102;&#21453;&#36716;&#21644;&#23454;&#26102;&#39118;&#26684;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale text-to-image generative models have made impressive strides, showcasing their ability to synthesize a vast array of high-quality images. However, adapting these models for artistic image editing presents two significant challenges. Firstly, users struggle to craft textual prompts that meticulously detail visual elements of the input image. Secondly, prevalent models, when effecting modifications in specific zones, frequently disrupt the overall artistic style, complicating the attainment of cohesive and aesthetically unified artworks. To surmount these obstacles, we build the innovative unified framework CreativeSynth, which is based on a diffusion model with the ability to coordinate multimodal inputs and multitask in the field of artistic image generation. By integrating multimodal features with customized attention mechanisms, CreativeSynth facilitates the importation of real-world semantic content into the domain of art through inversion and real-time style transfer. T
&lt;/p&gt;</description></item></channel></rss>