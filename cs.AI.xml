<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35774;&#35745;&#19968;&#31181;&#26032;&#39062;&#30340;&#20960;&#36718;&#24037;&#20316;&#27969;&#31243;&#65292;&#19987;&#38376;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#30340;&#30456;&#20851;&#21028;&#26029;&#65292;&#33021;&#22815;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#27880;&#37322;&#32773;&#30340;&#36807;&#31243;&#24182;&#25972;&#21512;&#19987;&#23478;&#25512;&#29702;&#65292;&#25552;&#39640;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.18405</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18405
&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#19968;&#31181;&#26032;&#39062;&#30340;&#20960;&#36718;&#24037;&#20316;&#27969;&#31243;&#65292;&#19987;&#38376;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#30340;&#30456;&#20851;&#21028;&#26029;&#65292;&#33021;&#22815;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#27880;&#37322;&#32773;&#30340;&#36807;&#31243;&#24182;&#25972;&#21512;&#19987;&#23478;&#25512;&#29702;&#65292;&#25552;&#39640;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25910;&#38598;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#30340;&#30456;&#20851;&#21028;&#20915;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#19988;&#32791;&#26102;&#30340;&#20219;&#21153;&#12290;&#20934;&#30830;&#21028;&#26029;&#20004;&#20010;&#27861;&#24459;&#26696;&#20363;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#38656;&#35201;&#38405;&#35835;&#20887;&#38271;&#30340;&#25991;&#26412;&#24182;&#20855;&#22791;&#39640;&#27700;&#24179;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#20197;&#25552;&#21462;&#27861;&#24459;&#20107;&#23454;&#24182;&#20316;&#20986;&#21496;&#27861;&#21028;&#26029;&#12290;&#38543;&#30528;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#19968;&#20123;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;LLM&#65288;Large Language Models&#65289;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#26159;&#26377;&#21069;&#36884;&#30340;&#12290;&#28982;&#32780;&#65292;&#23558;&#19968;&#33324;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#21487;&#38752;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#26041;&#27861;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20960;&#36718;&#24037;&#20316;&#27969;&#31243;&#65292;&#19987;&#38376;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#30340;&#30456;&#20851;&#21028;&#26029;&#12290;&#25152;&#25552;&#20986;&#30340;&#24037;&#20316;&#27969;&#31243;&#23558;&#27880;&#37322;&#36807;&#31243;&#20998;&#35299;&#20026;&#19968;&#31995;&#21015;&#38454;&#27573;&#65292;&#27169;&#20223;&#20154;&#31867;&#27880;&#37322;&#32773;&#25152;&#20351;&#29992;&#30340;&#36807;&#31243;&#65292;&#24182;&#20351;&#19987;&#23478;&#25512;&#29702;&#33021;&#22815;&#28789;&#27963;&#22320;&#25972;&#21512;&#20197;&#22686;&#24378;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18405v1 Announce Type: new  Abstract: Collecting relevant judgments for legal case retrieval is a challenging and time-consuming task. Accurately judging the relevance between two legal cases requires a considerable effort to read the lengthy text and a high level of domain expertise to extract Legal Facts and make juridical judgments. With the advent of advanced large language models, some recent studies have suggested that it is promising to use LLMs for relevance judgment. Nonetheless, the method of employing a general large language model for reliable relevance judgments in legal case retrieval is yet to be thoroughly explored. To fill this research gap, we devise a novel few-shot workflow tailored to the relevant judgment of legal cases. The proposed workflow breaks down the annotation process into a series of stages, imitating the process employed by human annotators and enabling a flexible integration of expert reasoning to enhance the accuracy of relevance judgments.
&lt;/p&gt;</description></item><item><title>&#20248;&#21270;&#30340;Transformer&#27169;&#22411;DistilBERT&#29992;&#20110;&#26816;&#27979;&#38035;&#40060;&#37038;&#20214;&#65292;&#36890;&#36807;&#39044;&#22788;&#29702;&#25216;&#26415;&#35299;&#20915;&#20102;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;</title><link>https://arxiv.org/abs/2402.13871</link><description>&lt;p&gt;
&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;Transformer&#30340;&#38035;&#40060;&#37038;&#20214;&#26816;&#27979;&#27169;&#22411;&#65306;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13871
&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#30340;Transformer&#27169;&#22411;DistilBERT&#29992;&#20110;&#26816;&#27979;&#38035;&#40060;&#37038;&#20214;&#65292;&#36890;&#36807;&#39044;&#22788;&#29702;&#25216;&#26415;&#35299;&#20915;&#20102;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38035;&#40060;&#37038;&#20214;&#26159;&#19968;&#31181;&#20005;&#37325;&#30340;&#32593;&#32476;&#23041;&#32961;&#65292;&#35797;&#22270;&#36890;&#36807;&#21457;&#36865;&#34394;&#20551;&#37038;&#20214;&#26469;&#27450;&#39575;&#29992;&#25143;&#65292;&#24847;&#22270;&#26159;&#31363;&#21462;&#26426;&#23494;&#20449;&#24687;&#25110;&#36896;&#25104;&#36130;&#21153;&#25439;&#22833;&#12290;&#25915;&#20987;&#32773;&#24120;&#24120;&#20882;&#20805;&#21487;&#20449;&#23454;&#20307;&#65292;&#21033;&#29992;&#25216;&#26415;&#36827;&#27493;&#21644;&#22797;&#26434;&#24615;&#20351;&#24471;&#38035;&#40060;&#30340;&#26816;&#27979;&#21644;&#39044;&#38450;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#23613;&#31649;&#36827;&#34892;&#20102;&#22823;&#37327;&#23398;&#26415;&#30740;&#31350;&#65292;&#20294;&#38035;&#40060;&#37038;&#20214;&#26816;&#27979;&#22312;&#32593;&#32476;&#23433;&#20840;&#39046;&#22495;&#20173;&#28982;&#26159;&#19968;&#20010;&#25345;&#32493;&#19988;&#20005;&#23803;&#30340;&#25361;&#25112;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#25513;&#30422;&#35821;&#35328;&#27169;&#22411;&#65288;MLMs&#65289;&#25317;&#26377;&#24040;&#22823;&#28508;&#21147;&#65292;&#33021;&#22815;&#25552;&#20379;&#21019;&#26032;&#35299;&#20915;&#26041;&#26696;&#26469;&#35299;&#20915;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#30740;&#31350;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#36807;&#20248;&#21270;&#30340;&#12289;&#32463;&#36807;&#24494;&#35843;&#30340;&#22522;&#20110;Transformer&#30340;DistilBERT&#27169;&#22411;&#65292;&#29992;&#20110;&#26816;&#27979;&#38035;&#40060;&#37038;&#20214;&#12290;&#22312;&#26816;&#27979;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#32452;&#38035;&#40060;&#37038;&#20214;&#25968;&#25454;&#38598;&#65292;&#24182;&#21033;&#29992;&#39044;&#22788;&#29702;&#25216;&#26415;&#26469;&#28165;&#29702;&#21644;&#35299;&#20915;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#23454;&#39564;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13871v1 Announce Type: cross  Abstract: Phishing email is a serious cyber threat that tries to deceive users by sending false emails with the intention of stealing confidential information or causing financial harm. Attackers, often posing as trustworthy entities, exploit technological advancements and sophistication to make detection and prevention of phishing more challenging. Despite extensive academic research, phishing detection remains an ongoing and formidable challenge in the cybersecurity landscape. Large Language Models (LLMs) and Masked Language Models (MLMs) possess immense potential to offer innovative solutions to address long-standing challenges. In this research paper, we present an optimized, fine-tuned transformer-based DistilBERT model designed for the detection of phishing emails. In the detection process, we work with a phishing email dataset and utilize the preprocessing techniques to clean and solve the imbalance class issues. Through our experiments, 
&lt;/p&gt;</description></item></channel></rss>