<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#20174;&#36801;&#31227;&#23398;&#20064;&#30340;&#35282;&#24230;&#25506;&#35752;&#20102;&#22914;&#20309;&#23558;&#20854;&#19982;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20026;&#36807;&#31243;&#25511;&#21046;&#24102;&#26469;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.00247</link><description>&lt;p&gt;
&#21033;&#29992;&#36801;&#31227;&#23398;&#20064;&#20419;&#36827;&#36807;&#31243;&#25511;&#21046;&#30340;&#24378;&#21270;&#23398;&#20064;&#65306;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Facilitating Reinforcement Learning for Process Control Using Transfer Learning: Perspectives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#36801;&#31227;&#23398;&#20064;&#30340;&#35282;&#24230;&#25506;&#35752;&#20102;&#22914;&#20309;&#23558;&#20854;&#19982;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20026;&#36807;&#31243;&#25511;&#21046;&#24102;&#26469;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#36801;&#31227;&#23398;&#20064;&#30340;&#35282;&#24230;&#65292;&#20026;&#36807;&#31243;&#25511;&#21046;&#20013;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#25552;&#20379;&#20102;&#28145;&#20837;&#35265;&#35299;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#36807;&#31243;&#24037;&#19994;&#39046;&#22495;&#24212;&#29992;DRL&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#20197;&#21450;&#24341;&#20837;&#36801;&#31227;&#23398;&#20064;&#30340;&#24517;&#35201;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#25552;&#20379;&#20102;&#24314;&#35758;&#21644;&#23637;&#26395;&#65292;&#25506;&#35752;&#20102;&#22914;&#20309;&#23558;&#36801;&#31227;&#23398;&#20064;&#19982;DRL&#32467;&#21512;&#36215;&#26469;&#21152;&#24378;&#36807;&#31243;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00247v1 Announce Type: cross  Abstract: This paper provides insights into deep reinforcement learning (DRL) for process control from the perspective of transfer learning. We analyze the challenges of applying DRL in the field of process industries and the necessity of introducing transfer learning. Furthermore, recommendations and prospects are provided for future research directions on how transfer learning can be integrated with DRL to empower process control.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#26032;&#39062;&#30340;&#26694;&#26550;SFFormer&#65292;&#32467;&#21512;&#20102;&#22810;&#22836;&#20132;&#21449;&#27880;&#24847;&#21147;&#29305;&#24449;&#34701;&#21512;&#27169;&#22359;&#65292;&#22522;&#20110;dMRI&#32420;&#32500;&#26463;&#36861;&#36394;&#65292;&#39044;&#27979;&#20102;&#20027;&#35266;&#35821;&#35328;&#34920;&#29616;&#65292;&#25299;&#23637;&#20102;&#33041;&#32467;&#26500;&#19982;&#20154;&#31867;&#35748;&#30693;&#21151;&#33021;&#30340;&#20851;&#32852;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.19001</link><description>&lt;p&gt;
&#36328;&#39046;&#22495;&#30340;&#32420;&#32500;&#31751;&#24418;&#29366;&#20998;&#26512;&#29992;&#20110;&#35821;&#35328;&#34920;&#29616;&#35748;&#30693;&#20998;&#25968;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Cross--domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#26032;&#39062;&#30340;&#26694;&#26550;SFFormer&#65292;&#32467;&#21512;&#20102;&#22810;&#22836;&#20132;&#21449;&#27880;&#24847;&#21147;&#29305;&#24449;&#34701;&#21512;&#27169;&#22359;&#65292;&#22522;&#20110;dMRI&#32420;&#32500;&#26463;&#36861;&#36394;&#65292;&#39044;&#27979;&#20102;&#20027;&#35266;&#35821;&#35328;&#34920;&#29616;&#65292;&#25299;&#23637;&#20102;&#33041;&#32467;&#26500;&#19982;&#20154;&#31867;&#35748;&#30693;&#21151;&#33021;&#30340;&#20851;&#32852;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24418;&#29366;&#22312;&#35745;&#31639;&#26426;&#22270;&#24418;&#23398;&#20013;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#65292;&#25552;&#20379;&#20102;&#26377;&#20851;&#23545;&#35937;&#24418;&#24577;&#21644;&#21151;&#33021;&#30340;&#20449;&#24687;&#29305;&#24449;&#12290;&#33041;&#25104;&#20687;&#20013;&#30340;&#24418;&#29366;&#20998;&#26512;&#21487;&#24110;&#21161;&#35299;&#37322;&#20154;&#33041;&#32467;&#26500;&#21644;&#21151;&#33021;&#30340;&#30456;&#20851;&#24615;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#33041;&#30340;3D&#30333;&#36136;&#36830;&#25509;&#30340;&#24418;&#29366;&#21450;&#20854;&#19982;&#20154;&#31867;&#35748;&#30693;&#21151;&#33021;&#30340;&#28508;&#22312;&#39044;&#27979;&#20851;&#31995;&#12290;&#25105;&#20204;&#20351;&#29992;&#25193;&#25955;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;dMRI&#65289;&#32420;&#32500;&#26463;&#36861;&#36394;&#23558;&#22823;&#33041;&#36830;&#25509;&#37325;&#24314;&#20026;3D&#28857;&#24207;&#21015;&#12290;&#20026;&#20102;&#25551;&#36848;&#27599;&#20010;&#36830;&#25509;&#65292;&#25105;&#20204;&#25552;&#21462;&#20102;12&#20010;&#24418;&#29366;&#25551;&#36848;&#31526;&#20197;&#21450;&#20256;&#32479;&#30340;dMRI&#36830;&#25509;&#21644;&#32452;&#32455;&#24494;&#32467;&#26500;&#29305;&#24449;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#24418;&#29366;&#34701;&#21512;&#32420;&#32500;&#31751;&#21464;&#25442;&#22120;&#65288;SFFormer&#65289;&#65292;&#21033;&#29992;&#22810;&#22836;&#20132;&#21449;&#27880;&#24847;&#21147;&#29305;&#24449;&#34701;&#21512;&#27169;&#22359;&#22522;&#20110;dMRI&#32420;&#32500;&#26463;&#36861;&#36394;&#26469;&#39044;&#27979;&#29305;&#23450;&#20010;&#20307;&#30340;&#35821;&#35328;&#34920;&#29616;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19001v1 Announce Type: cross  Abstract: Shape plays an important role in computer graphics, offering informative features to convey an object's morphology and functionality. Shape analysis in brain imaging can help interpret structural and functionality correlations of the human brain. In this work, we investigate the shape of the brain's 3D white matter connections and its potential predictive relationship to human cognitive function. We reconstruct brain connections as sequences of 3D points using diffusion magnetic resonance imaging (dMRI) tractography. To describe each connection, we extract 12 shape descriptors in addition to traditional dMRI connectivity and tissue microstructure features. We introduce a novel framework, Shape--fused Fiber Cluster Transformer (SFFormer), that leverages a multi-head cross-attention feature fusion module to predict subject-specific language performance based on dMRI tractography. We assess the performance of the method on a large dataset
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29615;&#22659;&#25193;&#25955;&#21518;&#39564;&#37319;&#26679;&#35299;&#20915;&#36870;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22312;&#21463;&#25439;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#22312;&#22270;&#20687;&#24674;&#22797;&#21644;MRI&#27169;&#22411;&#35757;&#32451;&#20013;&#21462;&#24471;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.08728</link><description>&lt;p&gt;
&#20351;&#29992;&#29615;&#22659;&#25193;&#25955;&#21518;&#39564;&#37319;&#26679;&#65306;&#22312;&#21463;&#25439;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#35299;&#20915;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models trained on Corrupted Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08728
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29615;&#22659;&#25193;&#25955;&#21518;&#39564;&#37319;&#26679;&#35299;&#20915;&#36870;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22312;&#21463;&#25439;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#22312;&#22270;&#20687;&#24674;&#22797;&#21644;MRI&#27169;&#22411;&#35757;&#32451;&#20013;&#21462;&#24471;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#20351;&#29992;&#20174;&#32447;&#24615;&#21463;&#25439;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#25193;&#25955;&#27169;&#22411;&#35299;&#20915;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;Ambient Diffusion Posterior Sampling (A-DPS)&#65292;&#21033;&#29992;&#19968;&#20010;&#39044;&#20808;&#22312;&#19968;&#31181;&#31867;&#22411;&#30340;&#25439;&#22351;&#25968;&#25454;&#19978;&#36827;&#34892;&#36807;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#22312;&#21487;&#33021;&#26469;&#33258;&#19981;&#21516;&#21069;&#21521;&#36807;&#31243;&#65288;&#20363;&#22914;&#22270;&#20687;&#27169;&#31946;&#65289;&#30340;&#27979;&#37327;&#26465;&#20214;&#19979;&#25191;&#34892;&#21518;&#39564;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#26631;&#20934;&#33258;&#28982;&#22270;&#20687;&#25968;&#25454;&#38598;&#65288;CelebA&#12289;FFHQ &#21644; AFHQ&#65289;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102; A-DPS &#26377;&#26102;&#22312;&#36895;&#24230;&#21644;&#24615;&#33021;&#19978;&#37117;&#33021;&#32988;&#36807;&#22312;&#28165;&#27905;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#20960;&#20010;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#29615;&#22659;&#25193;&#25955;&#26694;&#26550;&#65292;&#20197;&#20165;&#35775;&#38382;&#20613;&#37324;&#21494;&#23376;&#37319;&#26679;&#30340;&#22810;&#32447;&#22280; MRI &#27979;&#37327;&#25968;&#25454;&#26469;&#35757;&#32451; MRI &#27169;&#22411;&#65292;&#20854;&#21152;&#36895;&#22240;&#23376;&#20026;&#19981;&#21516;&#30340;&#21152;&#36895;&#22240;&#23376;&#65288;R=2&#12289;4&#12289;6&#12289;8&#65289;&#12290;&#25105;&#20204;&#20877;&#27425;&#35266;&#23519;&#21040;&#65292;&#22312;&#39640;&#24230;&#23376;&#37319;&#26679;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#26356;&#36866;&#29992;&#20110;&#35299;&#20915;&#39640;&#21152;&#36895; MRI &#36870;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08728v1 Announce Type: cross  Abstract: We provide a framework for solving inverse problems with diffusion models learned from linearly corrupted data. Our method, Ambient Diffusion Posterior Sampling (A-DPS), leverages a generative model pre-trained on one type of corruption (e.g. image inpainting) to perform posterior sampling conditioned on measurements from a potentially different forward process (e.g. image blurring). We test the efficacy of our approach on standard natural image datasets (CelebA, FFHQ, and AFHQ) and we show that A-DPS can sometimes outperform models trained on clean data for several image restoration tasks in both speed and performance. We further extend the Ambient Diffusion framework to train MRI models with access only to Fourier subsampled multi-coil MRI measurements at various acceleration factors (R=2, 4, 6, 8). We again observe that models trained on highly subsampled data are better priors for solving inverse problems in the high acceleration r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#29992;&#20110;&#27491;&#24335;&#35748;&#35777;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#33021;&#21147;&#65292;&#35777;&#20070;&#23450;&#37327;&#21270;&#19988;&#21253;&#21547;&#39640;&#32622;&#20449;&#24230;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#30740;&#31350;&#21457;&#29616;&#65292;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#25552;&#39640;&#65292;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.15929</link><description>&lt;p&gt;
QuaCer-C&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#23450;&#37327;&#35748;&#35777;
&lt;/p&gt;
&lt;p&gt;
QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#29992;&#20110;&#27491;&#24335;&#35748;&#35777;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#33021;&#21147;&#65292;&#35777;&#20070;&#23450;&#37327;&#21270;&#19988;&#21253;&#21547;&#39640;&#32622;&#20449;&#24230;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#30740;&#31350;&#21457;&#29616;&#65292;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#25552;&#39640;&#65292;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30740;&#31350;&#24182;&#26410;&#23545;LLMs&#30340;&#34920;&#29616;&#25552;&#20379;&#27491;&#24335;&#30340;&#20445;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;LLM&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#25105;&#20204;&#22312;&#27492;&#23545;&#30693;&#21517;LLMs&#30340;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#36827;&#34892;&#27491;&#24335;&#35748;&#35777;&#12290;&#25105;&#20204;&#30340;&#35777;&#20070;&#26159;&#23450;&#37327;&#30340; - &#23427;&#20204;&#21253;&#25324;&#23545;&#30446;&#26631;LLM&#22312;&#20219;&#20309;&#30456;&#20851;&#30693;&#35782;&#29702;&#35299;&#25552;&#31034;&#19978;&#32473;&#20986;&#27491;&#30830;&#31572;&#26696;&#30340;&#27010;&#29575;&#30340;&#39640;&#32622;&#20449;&#24230;&#32039;&#23494;&#30028;&#38480;&#12290;&#25105;&#20204;&#38024;&#23545;Llama&#12289;Vicuna&#21644;Mistral LLMs&#30340;&#35777;&#20070;&#34920;&#26126;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#38543;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#25552;&#39640;&#65292;&#24182;&#19988;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15929v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive performance on several benchmarks. However, traditional studies do not provide formal guarantees on the performance of LLMs. In this work, we propose a novel certification framework for LLM, QuaCer-C, wherein we formally certify the knowledge-comprehension capabilities of popular LLMs. Our certificates are quantitative - they consist of high-confidence, tight bounds on the probability that the target LLM gives the correct answer on any relevant knowledge comprehension prompt. Our certificates for the Llama, Vicuna, and Mistral LLMs indicate that the knowledge comprehension capability improves with an increase in the number of parameters and that the Mistral model is less performant than the rest in this evaluation.
&lt;/p&gt;</description></item><item><title>WikiMT++&#26159;&#19968;&#20010;&#25193;&#23637;&#21644;&#31934;&#32454;&#29256;&#26412;&#30340;WikiMusicText&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#20102;1010&#20010;&#32463;&#36807;&#31574;&#21010;&#30340;ABC&#35760;&#35889;&#27861;&#30340;&#20027;&#39064;&#26354;&#12290;&#23427;&#28155;&#21152;&#20102;&#23458;&#35266;&#23646;&#24615;&#21644;&#20027;&#35266;&#24773;&#24863;&#23646;&#24615;&#65292;&#22686;&#24378;&#20102;&#25968;&#25454;&#38598;&#30340;&#24212;&#29992;&#22330;&#26223;&#21644;&#21487;&#29992;&#24615;&#65292;&#24182;&#36890;&#36807;CLaMP&#26469;&#32416;&#27491;&#23646;&#24615;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.13259</link><description>&lt;p&gt;
WikiMT++&#25968;&#25454;&#38598;&#21345;&#29255;
&lt;/p&gt;
&lt;p&gt;
WikiMT++ Dataset Card. (arXiv:2309.13259v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13259
&lt;/p&gt;
&lt;p&gt;
WikiMT++&#26159;&#19968;&#20010;&#25193;&#23637;&#21644;&#31934;&#32454;&#29256;&#26412;&#30340;WikiMusicText&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#20102;1010&#20010;&#32463;&#36807;&#31574;&#21010;&#30340;ABC&#35760;&#35889;&#27861;&#30340;&#20027;&#39064;&#26354;&#12290;&#23427;&#28155;&#21152;&#20102;&#23458;&#35266;&#23646;&#24615;&#21644;&#20027;&#35266;&#24773;&#24863;&#23646;&#24615;&#65292;&#22686;&#24378;&#20102;&#25968;&#25454;&#38598;&#30340;&#24212;&#29992;&#22330;&#26223;&#21644;&#21487;&#29992;&#24615;&#65292;&#24182;&#36890;&#36807;CLaMP&#26469;&#32416;&#27491;&#23646;&#24615;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
WikiMT++&#26159;WikiMusicText&#65288;WikiMT&#65289;&#30340;&#25193;&#23637;&#21644;&#31934;&#32454;&#29256;&#26412;&#65292;&#21253;&#21547;&#20102;1010&#20010;&#32463;&#36807;&#31574;&#21010;&#30340;ABC&#35760;&#35889;&#27861;&#30340;&#20027;&#39064;&#26354;&#12290;&#20026;&#20102;&#25193;&#23637;WikiMT&#30340;&#24212;&#29992;&#22330;&#26223;&#65292;&#25105;&#20204;&#28155;&#21152;&#20102;&#23458;&#35266;&#23646;&#24615;&#65288;&#19987;&#36753;&#12289;&#27468;&#35789;&#12289;&#35270;&#39057;&#65289;&#21644;&#20027;&#35266;&#24773;&#24863;&#23646;&#24615;&#65288;12&#20010;&#24773;&#24863;&#24418;&#23481;&#35789;&#65289;&#21644;&#24773;&#24863;4Q&#65288;Russell 4Q&#65289;&#65292;&#22686;&#24378;&#20102;&#20854;&#22312;&#38899;&#20048;&#20449;&#24687;&#26816;&#32034;&#12289;&#26465;&#20214;&#38899;&#20048;&#29983;&#25104;&#12289;&#33258;&#21160;&#20316;&#26354;&#21644;&#24773;&#24863;&#20998;&#31867;&#31561;&#26041;&#38754;&#30340;&#21487;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23454;&#29616;&#20102;CLaMP&#26469;&#32416;&#27491;&#20174;WikiMT&#32487;&#25215;&#30340;&#23646;&#24615;&#65292;&#20197;&#20943;&#23569;&#21407;&#22987;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#20013;&#24341;&#20837;&#30340;&#38169;&#35823;&#65292;&#22686;&#24378;&#20102;&#25968;&#25454;&#38598;&#30340;&#20934;&#30830;&#24615;&#21644;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
WikiMT++ is an expanded and refined version of WikiMusicText (WikiMT), featuring 1010 curated lead sheets in ABC notation. To expand application scenarios of WikiMT, we add both objective (album, lyrics, video) and subjective emotion (12 emotion adjectives) and emo\_4q (Russell 4Q) attributes, enhancing its usability for music information retrieval, conditional music generation, automatic composition, and emotion classification, etc. Additionally, CLaMP is implemented to correct the attributes inherited from WikiMT to reduce errors introduced during original data collection and enhance the accuracy and completeness of our dataset.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;AI-&#20225;&#19994;&#20248;&#21270;&#30340;&#21327;&#21516;&#36741;&#21161;&#31995;&#32479;&#65292;&#36890;&#36807;&#37319;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20943;&#23569;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#38656;&#27714;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2309.13218</link><description>&lt;p&gt;
AI-&#20225;&#19994;&#20248;&#21270;&#30340;&#21327;&#21516;&#36741;&#21161;&#65306;&#19968;&#20010;&#26694;&#26550;&#21644;&#22312;&#29983;&#20135;&#35843;&#24230;&#20013;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling. (arXiv:2309.13218v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13218
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;AI-&#20225;&#19994;&#20248;&#21270;&#30340;&#21327;&#21516;&#36741;&#21161;&#31995;&#32479;&#65292;&#36890;&#36807;&#37319;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20943;&#23569;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#38656;&#27714;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20225;&#19994;&#20248;&#21270;&#26159;&#23547;&#25214;&#21644;&#23454;&#26045;&#39640;&#25928;&#21644;&#20855;&#26377;&#25104;&#26412;&#25928;&#30410;&#30340;&#36816;&#33829;&#26041;&#24335;&#65292;&#20197;&#20026;&#20225;&#19994;&#24102;&#26469;&#31454;&#20105;&#20248;&#21183;&#30340;&#36807;&#31243;&#12290;&#32508;&#21512;&#38382;&#39064;&#34920;&#36848;&#26159;&#20225;&#19994;&#20248;&#21270;&#30340;&#19968;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#23427;&#22260;&#32469;&#30528;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#23637;&#24320;&#65292;&#22240;&#27492;&#24456;&#26377;&#21487;&#33021;&#25104;&#20026;&#29942;&#39048;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#36890;&#36807;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21487;&#20197;&#28508;&#22312;&#22320;&#20943;&#23569;&#38382;&#39064;&#34920;&#36848;&#20013;&#25152;&#38656;&#30340;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#24320;&#21457;&#29992;&#20110;&#38382;&#39064;&#34920;&#36848;&#30340;LLM&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#35201;&#27714;&#12289;&#20196;&#29260;&#38480;&#21046;&#20197;&#21450;LLM&#20013;&#32570;&#20047;&#36866;&#24403;&#30340;&#24615;&#33021;&#24230;&#37327;&#12290;&#20026;&#20102;&#20943;&#23569;&#22823;&#37327;&#35757;&#32451;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#26368;&#36817;&#20154;&#20204;&#24320;&#22987;&#20851;&#27880;&#23545;&#39044;&#35757;&#32451;&#30340;LLM&#36827;&#34892;&#24494;&#35843;&#20197;&#36866;&#24212;&#19979;&#28216;&#20219;&#21153;&#65292;&#32780;&#19981;&#26159;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#19968;&#20010;&#29305;&#23450;&#20219;&#21153;&#30340;LLM&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;AI-&#20225;&#19994;&#20248;&#21270;&#30340;&#21327;&#21516;&#36741;&#21161;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Business optimisation is the process of finding and implementing efficient and cost-effective means of operation to bring a competitive advantage for businesses. Synthesizing problem formulations is an integral part of business optimisation which is centred around human expertise, thus with a high potential of becoming a bottleneck. With the recent advancements in Large Language Models (LLMs), human expertise needed in problem formulation can potentially be minimized using Artificial Intelligence (AI). However, developing a LLM for problem formulation is challenging, due to training data requirements, token limitations, and the lack of appropriate performance metrics in LLMs. To minimize the requirement of large training data, considerable attention has recently been directed towards fine-tuning pre-trained LLMs for downstream tasks, rather than training a LLM from scratch for a specific task. In this paper, we adopt this approach and propose an AI-Copilot for business optimisation by 
&lt;/p&gt;</description></item></channel></rss>