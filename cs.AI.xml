<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01454</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#19968;&#31181;&#32479;&#35745;&#22240;&#26524;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#30340;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#65288;SCD&#65289;&#20013;&#65292;&#23558;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#20316;&#20026;&#32422;&#26463;&#23884;&#20837;&#21040;&#31639;&#27861;&#20013;&#34987;&#24191;&#27867;&#25509;&#21463;&#65292;&#22240;&#20026;&#36825;&#23545;&#20110;&#21019;&#24314;&#19968;&#33268;&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#27169;&#22411;&#26159;&#37325;&#35201;&#30340;&#65292;&#23613;&#31649;&#35782;&#21035;&#32972;&#26223;&#30693;&#35782;&#30340;&#25361;&#25112;&#34987;&#35748;&#21487;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#23558;LLM&#30340;&#8220;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#65288;SCP&#65289;&#8221;&#19982;SCD&#26041;&#27861;&#21644;&#22522;&#20110;&#30693;&#35782;&#30340;&#22240;&#26524;&#25512;&#26029;&#65288;KBCI&#65289;&#30456;&#32467;&#21512;&#65292;&#23545;SCD&#36827;&#34892;&#20808;&#39564;&#30693;&#35782;&#22686;&#24378;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4&#21487;&#20197;&#20351;LLM-KBCI&#30340;&#36755;&#20986;&#19982;&#24102;&#26377;LLM-KBCI&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;SCD&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#65292;&#22914;&#26524;GPT-4&#32463;&#21382;&#20102;SCP&#65292;&#37027;&#20040;SCD&#30340;&#32467;&#26524;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#21892;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;LLM&#19981;&#21547;&#26377;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;LLM&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#20854;&#32972;&#26223;&#30693;&#35782;&#26469;&#25913;&#36827;SCD&#12290;
&lt;/p&gt;
&lt;p&gt;
In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through "statistical causal prompting (SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#37329;&#34701;&#20132;&#26131;&#25968;&#25454;&#36890;&#29992;&#34920;&#31034;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#26412;&#22320;&#12289;&#20840;&#23616;&#21644;&#22806;&#37096;&#35821;&#22659;&#65292;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#25972;&#21512;&#22806;&#37096;&#20449;&#24687;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#26412;&#22320;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#36229;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.02047</link><description>&lt;p&gt;
&#37329;&#34701;&#20132;&#26131;&#25968;&#25454;&#30340;&#36890;&#29992;&#34920;&#31034;&#65306;&#34701;&#21512;&#26412;&#22320;&#12289;&#20840;&#23616;&#21644;&#22806;&#37096;&#35821;&#22659;
&lt;/p&gt;
&lt;p&gt;
Universal representations for financial transactional data: embracing local, global, and external contexts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02047
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#37329;&#34701;&#20132;&#26131;&#25968;&#25454;&#36890;&#29992;&#34920;&#31034;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#26412;&#22320;&#12289;&#20840;&#23616;&#21644;&#22806;&#37096;&#35821;&#22659;&#65292;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#25972;&#21512;&#22806;&#37096;&#20449;&#24687;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#26412;&#22320;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#36229;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37329;&#34701;&#20132;&#26131;&#30340;&#26377;&#25928;&#22788;&#29702;&#23545;&#38134;&#34892;&#25968;&#25454;&#20998;&#26512;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#19968;&#39046;&#22495;&#20013;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#19987;&#27880;&#20110;&#20026;&#29420;&#31435;&#38382;&#39064;&#25552;&#20379;&#19987;&#38376;&#21270;&#35299;&#20915;&#26041;&#26696;&#65292;&#32780;&#19981;&#26159;&#26500;&#24314;&#36866;&#29992;&#20110;&#35768;&#22810;&#38382;&#39064;&#30340;&#36890;&#29992;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#35299;&#20915;&#21508;&#31181;&#20225;&#19994;&#25361;&#25112;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#32771;&#34385;&#25968;&#25454;&#29305;&#23450;&#24615;&#30340;&#26032;&#39062;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25972;&#21512;&#22806;&#37096;&#20449;&#24687;&#21040;&#23458;&#25143;&#34920;&#31034;&#30340;&#26041;&#24335;&#65292;&#20511;&#37492;&#20854;&#20182;&#23458;&#25143;&#34892;&#21160;&#30340;&#35265;&#35299;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20934;&#65292;&#25551;&#36848;&#20102;&#20840;&#29699;&#33539;&#22260;&#20869;&#30340;&#34920;&#31034;&#36136;&#37327;&#65292;&#28041;&#21450;&#25972;&#20010;&#20132;&#26131;&#21382;&#21490;&#65307;&#26412;&#22320;&#33539;&#22260;&#20869;&#65292;&#21453;&#26144;&#23458;&#25143;&#24403;&#21069;&#29366;&#24577;&#65307;&#21160;&#24577;&#33539;&#22260;&#20869;&#65292;&#25429;&#25417;&#34920;&#31034;&#38543;&#26102;&#38388;&#28436;&#21464;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#29983;&#25104;&#26041;&#27861;&#22312;&#26412;&#22320;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#23545;&#20110;&#19979;&#19968;&#20010;MCC&#39044;&#27979;&#20219;&#21153;&#30340;ROC-AUC&#25552;&#21319;&#39640;&#36798;14&#65285;&#65292;&#23545;&#20110;dow...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02047v1 Announce Type: cross  Abstract: Effective processing of financial transactions is essential for banking data analysis. However, in this domain, most methods focus on specialized solutions to stand-alone problems instead of constructing universal representations suitable for many problems. We present a representation learning framework that addresses diverse business challenges. We also suggest novel generative models that account for data specifics, and a way to integrate external information into a client's representation, leveraging insights from other customers' actions. Finally, we offer a benchmark, describing representation quality globally, concerning the entire transaction history; locally, reflecting the client's current state; and dynamically, capturing representation evolution over time. Our generative approach demonstrates superior performance in local tasks, with an increase in ROC-AUC of up to 14\% for the next MCC prediction task and up to 46\% for dow
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;BirdSet&#22522;&#20934;&#65292;&#29992;&#20110;&#40479;&#31867;&#29983;&#29289;&#22768;&#23398;&#20013;&#30340;&#20998;&#31867;&#20219;&#21153;&#65292;&#25972;&#21512;&#24320;&#28304;&#40479;&#31867;&#24405;&#38899;&#25968;&#25454;&#38598;&#21512;&#65292;&#20840;&#38754;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#21644;&#35782;&#21035;&#28508;&#22312;&#19981;&#36275;&#12290;</title><link>https://arxiv.org/abs/2403.10380</link><description>&lt;p&gt;
BirdSet&#65306;&#40479;&#31867;&#29983;&#29289;&#22768;&#23398;&#20998;&#31867;&#30340;&#22810;&#20219;&#21153;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
BirdSet: A Multi-Task Benchmark for Classification in Avian Bioacoustics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10380
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;BirdSet&#22522;&#20934;&#65292;&#29992;&#20110;&#40479;&#31867;&#29983;&#29289;&#22768;&#23398;&#20013;&#30340;&#20998;&#31867;&#20219;&#21153;&#65292;&#25972;&#21512;&#24320;&#28304;&#40479;&#31867;&#24405;&#38899;&#25968;&#25454;&#38598;&#21512;&#65292;&#20840;&#38754;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#21644;&#35782;&#21035;&#28508;&#22312;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#40479;&#31867;&#29983;&#29289;&#22768;&#23398;&#39046;&#22495;&#35786;&#26029;&#29615;&#22659;&#20581;&#24247;&#21644;&#29983;&#29289;&#22810;&#26679;&#24615;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#20294;&#30740;&#31350;&#20013;&#23384;&#22312;&#30340;&#19981;&#19968;&#33268;&#24615;&#32473;&#36825;&#19968;&#39046;&#22495;&#30340;&#36827;&#23637;&#24102;&#26469;&#20102;&#26174;&#33879;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;BirdSet&#22522;&#20934;&#65292;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#32508;&#21512;&#30740;&#31350;&#21162;&#21147;&#65292;&#20197;&#20840;&#38754;&#20998;&#31867;&#40479;&#31867;&#40483;&#21483;&#22768;&#12290;BirdSet&#23558;&#24320;&#28304;&#40479;&#31867;&#24405;&#38899;&#25972;&#21512;&#21040;&#19968;&#20010;&#31934;&#24515;&#31574;&#21010;&#30340;&#25968;&#25454;&#38598;&#21512;&#20013;&#65292;&#25552;&#20379;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#28145;&#20837;&#29702;&#35299;&#65292;&#24182;&#35782;&#21035;&#36328;&#19981;&#21516;&#30740;&#31350;&#30340;&#28508;&#22312;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10380v1 Announce Type: cross  Abstract: Deep learning (DL) models have emerged as a powerful tool in avian bioacoustics to diagnose environmental health and biodiversity. However, inconsistencies in research pose notable challenges hindering progress in this domain. Reliable DL models need to analyze bird calls flexibly across various species and environments to fully harness the potential of bioacoustics in a cost-effective passive acoustic monitoring scenario. Data fragmentation and opacity across studies complicate a comprehensive evaluation of general model performance. To overcome these challenges, we present the BirdSet benchmark, a unified framework consolidating research efforts with a holistic approach for classifying bird vocalizations in avian bioacoustics. BirdSet harmonizes open-source bird recordings into a curated dataset collection. This unified approach provides an in-depth understanding of model performance and identifies potential shortcomings across diffe
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#25968;&#25454;&#39537;&#21160;&#20998;&#21106;&#21644;&#23618;&#27425;&#20998;&#21106;&#31243;&#24207;&#65292;DSEG-LIME&#25913;&#36827;&#20102;&#22270;&#20687;&#35299;&#37322;&#33021;&#21147;&#65292;&#25552;&#39640;&#20102;&#22270;&#20687;&#20998;&#31867;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.07733</link><description>&lt;p&gt;
DSEG-LIME -- &#36890;&#36807;&#23618;&#27425;&#21270;&#25968;&#25454;&#39537;&#21160;&#20998;&#21106;&#25552;&#21319;&#22270;&#20687;&#35299;&#37322;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
DSEG-LIME -- Improving Image Explanation by Hierarchical Data-Driven Segmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07733
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#25968;&#25454;&#39537;&#21160;&#20998;&#21106;&#21644;&#23618;&#27425;&#20998;&#21106;&#31243;&#24207;&#65292;DSEG-LIME&#25913;&#36827;&#20102;&#22270;&#20687;&#35299;&#37322;&#33021;&#21147;&#65292;&#25552;&#39640;&#20102;&#22270;&#20687;&#20998;&#31867;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#22312;&#25581;&#31034;&#22797;&#26434;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20915;&#31574;&#36807;&#31243;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;LIME (Local Interpretable Model-agnostic Explanations) &#26159;&#19968;&#20010;&#24191;&#20026;&#20154;&#30693;&#30340;&#29992;&#20110;&#22270;&#20687;&#20998;&#26512;&#30340;XAI&#26694;&#26550;&#12290;&#23427;&#21033;&#29992;&#22270;&#20687;&#20998;&#21106;&#26469;&#21019;&#24314;&#29305;&#24449;&#20197;&#35782;&#21035;&#30456;&#20851;&#30340;&#20998;&#31867;&#21306;&#22495;&#12290;&#28982;&#32780;&#65292;&#36739;&#24046;&#30340;&#20998;&#21106;&#21487;&#33021;&#20250;&#24433;&#21709;&#35299;&#37322;&#30340;&#19968;&#33268;&#24615;&#24182;&#21066;&#24369;&#21508;&#20010;&#21306;&#22495;&#30340;&#37325;&#35201;&#24615;&#65292;&#20174;&#32780;&#24433;&#21709;&#25972;&#20307;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#38024;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DSEG-LIME (Data-Driven Segmentation LIME)&#65292;&#20855;&#26377;: i) &#29992;&#20110;&#29983;&#25104;&#20154;&#31867;&#21487;&#35782;&#21035;&#29305;&#24449;&#30340;&#25968;&#25454;&#39537;&#21160;&#20998;&#21106;, &#21644; ii) &#36890;&#36807;&#32452;&#21512;&#23454;&#29616;&#30340;&#23618;&#27425;&#20998;&#21106;&#31243;&#24207;&#12290;&#25105;&#20204;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#19978;&#20351;&#29992;&#26469;&#33258;ImageNet&#25968;&#25454;&#38598;&#30340;&#22270;&#20687;&#23545;DSEG-LIME&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;-&#36825;&#20123;&#24773;&#26223;&#19981;&#21253;&#21547;&#29305;&#23450;&#39046;&#22495;&#30340;&#30693;&#35782;&#12290;&#20998;&#26512;&#21253;&#25324;&#20351;&#29992;&#24050;&#24314;&#31435;&#30340;XAI&#25351;&#26631;&#36827;&#34892;&#23450;&#37327;&#35780;&#20272;&#65292;&#20197;&#21450;&#36827;&#19968;&#27493;&#30340;&#23450;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07733v1 Announce Type: cross  Abstract: Explainable Artificial Intelligence is critical in unraveling decision-making processes in complex machine learning models. LIME (Local Interpretable Model-agnostic Explanations) is a well-known XAI framework for image analysis. It utilizes image segmentation to create features to identify relevant areas for classification. Consequently, poor segmentation can compromise the consistency of the explanation and undermine the importance of the segments, affecting the overall interpretability. Addressing these challenges, we introduce DSEG-LIME (Data-Driven Segmentation LIME), featuring: i) a data-driven segmentation for human-recognized feature generation, and ii) a hierarchical segmentation procedure through composition. We benchmark DSEG-LIME on pre-trained models with images from the ImageNet dataset - scenarios without domain-specific knowledge. The analysis includes a quantitative evaluation using established XAI metrics, complemented
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20445;&#25252;&#20010;&#20154;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25239;&#24615;LLM&#25512;&#26029;&#30340;&#21311;&#21517;&#21270;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2402.13846</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#20808;&#36827;&#30340;&#21311;&#21517;&#21270;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Advanced Anonymizers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13846
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20445;&#25252;&#20010;&#20154;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25239;&#24615;LLM&#25512;&#26029;&#30340;&#21311;&#21517;&#21270;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#38544;&#31169;&#30740;&#31350;&#39046;&#22495;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23427;&#20204;&#22312;&#25512;&#26029;&#30495;&#23454;&#19990;&#30028;&#22312;&#32447;&#25991;&#26412;&#20013;&#30340;&#20010;&#20154;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#25509;&#36817;&#20154;&#31867;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;&#38543;&#30528;&#27169;&#22411;&#33021;&#21147;&#30340;&#19981;&#26029;&#22686;&#24378;&#65292;&#29616;&#26377;&#30340;&#25991;&#26412;&#21311;&#21517;&#21270;&#26041;&#27861;&#24403;&#21069;&#24050;&#32463;&#33853;&#21518;&#20110;&#30417;&#31649;&#35201;&#27714;&#21644;&#23545;&#25239;&#23041;&#32961;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#20010;&#20154;&#22914;&#20309;&#26377;&#25928;&#22320;&#20445;&#25252;&#20182;&#20204;&#22312;&#20998;&#20139;&#22312;&#32447;&#25991;&#26412;&#26102;&#30340;&#20010;&#20154;&#25968;&#25454;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#20004;&#27493;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35774;&#32622;&#65292;&#29992;&#20110;&#35780;&#20272;&#38754;&#23545;&#23545;&#25239;&#24615;LLM&#30340;&#25512;&#26029;&#26102;&#30340;&#21311;&#21517;&#21270;&#25928;&#26524;&#65292;&#20174;&#32780;&#20801;&#35768;&#33258;&#28982;&#22320;&#27979;&#37327;&#21311;&#21517;&#21270;&#24615;&#33021;&#65292;&#21516;&#26102;&#32416;&#27491;&#20102;&#20197;&#21069;&#25351;&#26631;&#30340;&#19968;&#20123;&#32570;&#38519;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;LLM&#30340;&#23545;&#25239;&#24615;&#21311;&#21517;&#21270;&#26694;&#26550;&#65292;&#21033;&#29992;LLM&#30340;&#24378;&#22823;&#25512;&#26029;&#33021;&#21147;&#26469;&#25351;&#23548;&#25105;&#20204;&#30340;&#21311;&#21517;&#21270;&#36807;&#31243;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#30340;&#21311;&#21517;&#21270;&#23454;&#36341;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13846v1 Announce Type: cross  Abstract: Recent work in privacy research on large language models has shown that they achieve near human-level performance at inferring personal data from real-world online texts. With consistently increasing model capabilities, existing text anonymization methods are currently lacking behind regulatory requirements and adversarial threats. This raises the question of how individuals can effectively protect their personal data in sharing online texts. In this work, we take two steps to answer this question: We first present a new setting for evaluating anonymizations in the face of adversarial LLMs inferences, allowing for a natural measurement of anonymization performance while remedying some of the shortcomings of previous metrics. We then present our LLM-based adversarial anonymization framework leveraging the strong inferential capabilities of LLMs to inform our anonymization procedure. In our experimental evaluation, we show on real-world 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102; Persona-DB&#65292;&#19968;&#20010;&#31616;&#21333;&#21364;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23618;&#32423;&#26500;&#24314;&#36807;&#31243;&#21644;&#21327;&#21516;&#20248;&#21270;&#65292;&#25913;&#21892;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#20013;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#26816;&#32034;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.11060</link><description>&lt;p&gt;
Persona-DB&#65306;&#29992;&#20110;&#21709;&#24212;&#39044;&#27979;&#30340;&#39640;&#25928;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#19982;&#21327;&#21516;&#25968;&#25454;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11060
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102; Persona-DB&#65292;&#19968;&#20010;&#31616;&#21333;&#21364;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23618;&#32423;&#26500;&#24314;&#36807;&#31243;&#21644;&#21327;&#21516;&#20248;&#21270;&#65292;&#25913;&#21892;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#20013;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#26816;&#32034;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20010;&#24615;&#21270;&#20132;&#20114;&#38656;&#27714;&#30340;&#22686;&#21152;&#65292;&#38656;&#35201;&#24320;&#21457;&#33021;&#22815;&#20934;&#30830;&#24555;&#36895;&#35782;&#21035;&#29992;&#25143;&#24847;&#35265;&#21644;&#20559;&#22909;&#30340;&#26041;&#27861;&#12290;&#26816;&#32034;&#22686;&#24378;&#20316;&#20026;&#19968;&#31181;&#26377;&#25928;&#31574;&#30053;&#20986;&#29616;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#36866;&#24212;&#22823;&#37327;&#29992;&#25143;&#32780;&#26080;&#38656;&#36827;&#34892;&#24494;&#35843;&#30340;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22686;&#24378;&#26816;&#32034;&#38454;&#27573;&#65292;&#24182;&#23545;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#20248;&#21270;&#36827;&#34892;&#20102;&#26377;&#38480;&#30340;&#25506;&#32034;&#65292;&#36825;&#26159;&#20010;&#24615;&#21270;&#31561;&#20219;&#21153;&#30340;&#20851;&#38190;&#26041;&#38754;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#19968;&#20010;&#26032;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#30528;&#37325;&#20110;&#22914;&#20309;&#26356;&#26377;&#25928;&#22320;&#34920;&#31034;&#25968;&#25454;&#65292;&#20197;&#20415;&#22312;LLM&#23450;&#21046;&#30340;&#24773;&#22659;&#19979;&#26356;&#26377;&#25928;&#22320;&#36827;&#34892;&#26816;&#32034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Persona-DB&#65292;&#36825;&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#19968;&#20010;&#20998;&#23618;&#26500;&#24314;&#36807;&#31243;&#65292;&#20197;&#25913;&#21892;&#36328;&#20219;&#21153;&#32972;&#26223;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#36827;&#34892;&#21327;&#21516;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11060v1 Announce Type: cross  Abstract: The increasing demand for personalized interactions with large language models (LLMs) calls for the development of methodologies capable of accurately and efficiently identifying user opinions and preferences. Retrieval augmentation emerges as an effective strategy, as it can accommodate a vast number of users without the costs from fine-tuning. Existing research, however, has largely focused on enhancing the retrieval stage and devoted limited exploration toward optimizing the representation of the database, a crucial aspect for tasks such as personalization. In this work, we examine the problem from a novel angle, focusing on how data can be better represented for more efficient retrieval in the context of LLM customization. To tackle this challenge, we introduce Persona-DB, a simple yet effective framework consisting of a hierarchical construction process to improve generalization across task contexts and collaborative refinement to
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAR&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06104</link><description>&lt;p&gt;
&#21151;&#33021;&#23545;&#40784;&#22238;&#24402;&#65306;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#26126;&#30830;&#23398;&#20064;&#20989;&#25968;&#23548;&#25968;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06104
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAR&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#24402;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#20219;&#21153;&#65292;&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20256;&#32479;&#30340;&#22238;&#24402;&#26041;&#27861;&#20027;&#35201;&#36890;&#36807;&#20351;&#29992;&#25439;&#22833;&#20989;&#25968;&#26469;&#23558;&#27169;&#22411;&#39044;&#27979;&#19982;&#27599;&#20010;&#20010;&#20307;&#25968;&#25454;&#26679;&#26412;&#30340;&#30495;&#23454;&#20540;&#23545;&#40784;&#65292;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#22312;&#19981;&#21516;&#26679;&#26412;&#20043;&#38388;&#20851;&#31995;&#30340;&#39044;&#27979;&#19981;&#22815;&#20248;&#21270;&#12290;&#36817;&#26399;&#30340;&#30740;&#31350;&#24037;&#20316;&#24341;&#20837;&#20102;&#26631;&#31614;&#30456;&#20284;&#24615;&#20449;&#24687;&#26469;&#25913;&#36827;&#22238;&#24402;&#26041;&#27861;&#65292;&#20294;&#22312;&#23436;&#20840;&#25429;&#25417;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#26041;&#38754;&#20173;&#23384;&#22312;&#26126;&#26174;&#30340;&#24046;&#36317;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FAR&#65288;&#21151;&#33021;&#23545;&#40784;&#22238;&#24402;&#65289;&#20316;&#20026;&#19968;&#31181;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20845;&#20010;&#39046;&#22495;&#30340;&#20843;&#20010;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample, which, as we show, can result in sub-optimal prediction of the relationships between the different samples. Recent research endeavors have introduced novel perspectives by incorporating label similarity information to regression. However, a notable gap persists in these approaches when it comes to fully capturing the intricacies of the underlying ground truth function. In this work, we propose FAR (Function Aligned Regression) as a arguably better and more efficient solution to fit the underlying function of ground truth by capturing functional derivatives. We demonstrate the effectiveness of the proposed method practically on 2 synthetic datasets and on 8 extensive real-world tasks from 6 b
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#23613;&#31649;&#23427;&#20204;&#33021;&#22815;&#34701;&#20837;&#21644;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#12290;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#38656;&#35201;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.06049</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Limits of Large Language Models in Debating Humans
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06049
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#23613;&#31649;&#23427;&#20204;&#33021;&#22815;&#34701;&#20837;&#21644;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#12290;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#38656;&#35201;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#19982;&#20154;&#31867;&#30340;&#20114;&#21160;&#20013;&#23637;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#28508;&#21147;&#12290;&#38543;&#21518;&#65292;&#23558;&#23427;&#20204;&#20316;&#20026;&#20154;&#24037;&#20195;&#34920;&#21644;&#26367;&#20195;&#21697;&#36827;&#34892;&#31038;&#20250;&#23398;&#23454;&#39564;&#30340;&#28508;&#22312;&#24212;&#29992;&#26159;&#19968;&#20010;&#20196;&#20154;&#28608;&#21160;&#30340;&#21069;&#26223;&#12290;&#20294;&#26159;&#36825;&#20010;&#24819;&#27861;&#26377;&#22810;&#21487;&#34892;&#21602;&#65311;&#26412;&#25991;&#35797;&#22270;&#36890;&#36807;&#19968;&#39033;&#39044;&#20808;&#27880;&#20876;&#30340;&#30740;&#31350;&#26469;&#27979;&#35797;&#29616;&#38454;&#27573;LLMs&#30340;&#23616;&#38480;&#24615;&#65292;&#35813;&#30740;&#31350;&#23558;&#30495;&#23454;&#30340;&#20154;&#31867;&#19982;&#25198;&#28436;&#20154;&#31867;&#30340;LLM&#20195;&#29702;&#32467;&#21512;&#36215;&#26469;&#12290;&#26412;&#30740;&#31350;&#30528;&#37325;&#25506;&#35752;&#36777;&#35770;&#20026;&#22522;&#30784;&#30340;&#24847;&#35265;&#20849;&#35782;&#24418;&#25104;&#22312;&#19977;&#31181;&#29615;&#22659;&#19979;&#30340;&#24773;&#20917;&#65306;&#20165;&#20154;&#31867;&#12289;&#20195;&#29702;&#21644;&#20154;&#31867;&#12289;&#20165;&#20195;&#29702;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#29702;&#35299;LLM&#20195;&#29702;&#23545;&#20154;&#31867;&#30340;&#24433;&#21709;&#65292;&#24182;&#35780;&#20272;&#23427;&#20204;&#22312;&#36777;&#35770;&#26041;&#38754;&#30340;&#33021;&#21147;&#26159;&#21542;&#19982;&#20154;&#31867;&#30456;&#20284;&#12290;&#25105;&#20204;&#21457;&#29616;LLMs&#33021;&#22815;&#34701;&#20837;&#24182;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#65292;&#26368;&#32456;&#34892;&#20026;&#19982;&#20154;&#31867;&#26377;&#25152;&#20559;&#31163;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#36825;&#20123;&#20027;&#35201;&#32570;&#38519;&#65292;&#24182;&#39044;&#35745;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#24517;&#39035;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown remarkable promise in their ability to interact proficiently with humans. Subsequently, their potential use as artificial confederates and surrogates in sociological experiments involving conversation is an exciting prospect. But how viable is this idea? This paper endeavors to test the limits of current-day LLMs with a pre-registered study integrating real people with LLM agents acting as people. The study focuses on debate-based opinion consensus formation in three environments: humans only, agents and humans, and agents only. Our goal is to understand how LLM agents influence humans, and how capable they are in debating like humans. We find that LLMs can blend in and facilitate human productivity but are less convincing in debate, with their behavior ultimately deviating from human's. We elucidate these primary failings and anticipate that LLMs must evolve further before being viable debaters.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20851;&#27880;&#25968;&#25454;&#38598;&#33976;&#39311;&#19982;&#20854;&#27867;&#21270;&#33021;&#21147;&#30340;&#20851;&#31995;&#65292;&#23588;&#20854;&#26159;&#22312;&#38754;&#23545;&#19981;&#24120;&#35265;&#30340;&#23376;&#32452;&#30340;&#26679;&#26412;&#26102;&#65292;&#22914;&#20309;&#30830;&#20445;&#27169;&#22411;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#35757;&#32451;&#21487;&#20197;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.04676</link><description>&lt;p&gt;
&#24102;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#20998;&#32452;&#20998;&#24067;&#40065;&#26834;&#25968;&#25454;&#38598;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Group Distributionally Robust Dataset Distillation with Risk Minimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04676
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20851;&#27880;&#25968;&#25454;&#38598;&#33976;&#39311;&#19982;&#20854;&#27867;&#21270;&#33021;&#21147;&#30340;&#20851;&#31995;&#65292;&#23588;&#20854;&#26159;&#22312;&#38754;&#23545;&#19981;&#24120;&#35265;&#30340;&#23376;&#32452;&#30340;&#26679;&#26412;&#26102;&#65292;&#22914;&#20309;&#30830;&#20445;&#27169;&#22411;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#35757;&#32451;&#21487;&#20197;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#38598;&#33976;&#39311;&#65288;DD&#65289;&#24050;&#25104;&#20026;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#26500;&#24314;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#22312;&#25429;&#25417;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#22522;&#26412;&#20449;&#24687;&#26041;&#38754;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#65292;&#20174;&#32780;&#26041;&#20415;&#20934;&#30830;&#35757;&#32451;&#31070;&#32463;&#27169;&#22411;&#12290;&#20854;&#24212;&#29992;&#28085;&#30422;&#20102;&#36716;&#31227;&#23398;&#20064;&#12289;&#32852;&#37030;&#23398;&#20064;&#21644;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31561;&#21508;&#20010;&#39046;&#22495;&#12290;&#26500;&#24314;&#21512;&#25104;&#25968;&#25454;&#30340;&#26368;&#27969;&#34892;&#26041;&#27861;&#20381;&#36182;&#20110;&#20351;&#27169;&#22411;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#30340;&#25910;&#25947;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#28982;&#32780;&#65292;&#30446;&#26631;&#26159;&#23558;&#35757;&#32451;&#25968;&#25454;&#38598;&#35270;&#20026;&#36741;&#21161;&#65292;&#23601;&#20687;&#35757;&#32451;&#38598;&#26159;&#20154;&#21475;&#20998;&#24067;&#30340;&#36817;&#20284;&#26367;&#20195;&#21697;&#19968;&#26679;&#65292;&#32780;&#21518;&#32773;&#25165;&#26159;&#25105;&#20204;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#12290;&#23613;&#31649;&#20854;&#21463;&#27426;&#36814;&#31243;&#24230;&#24456;&#39640;&#65292;&#20294;&#23578;&#26410;&#25506;&#32034;&#30340;&#19968;&#20010;&#26041;&#38754;&#26159;DD&#19982;&#20854;&#27867;&#21270;&#33021;&#21147;&#30340;&#20851;&#31995;&#65292;&#29305;&#21035;&#26159;&#36328;&#19981;&#24120;&#35265;&#30340;&#23376;&#32452;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#24403;&#38754;&#23545;&#26469;&#33258;&#32597;&#35265;&#23376;&#32452;&#30340;&#26679;&#26412;&#26102;&#65292;&#25105;&#20204;&#22914;&#20309;&#30830;&#20445;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dataset distillation (DD) has emerged as a widely adopted technique for crafting a synthetic dataset that captures the essential information of a training dataset, facilitating the training of accurate neural models. Its applications span various domains, including transfer learning, federated learning, and neural architecture search. The most popular methods for constructing the synthetic data rely on matching the convergence properties of training the model with the synthetic dataset and the training dataset. However, targeting the training dataset must be thought of as auxiliary in the same sense that the training set is an approximate substitute for the population distribution, and the latter is the data of interest. Yet despite its popularity, an aspect that remains unexplored is the relationship of DD to its generalization, particularly across uncommon subgroups. That is, how can we ensure that a model trained on the synthetic dataset performs well when faced with samples from re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PA-RL&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#29109;&#29575;&#26469;&#24341;&#23548;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#12290;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#23454;&#29616;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#22312;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#20540;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2311.18703</link><description>&lt;p&gt;
&#36890;&#36807;&#29109;&#29575;&#26368;&#23567;&#21270;&#23454;&#29616;&#21487;&#39044;&#27979;&#30340;&#24378;&#21270;&#23398;&#20064;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.18703
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PA-RL&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#29109;&#29575;&#26469;&#24341;&#23548;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#12290;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#23454;&#29616;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#22312;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#26234;&#33021;&#20307;&#27809;&#26377;&#21160;&#26426;&#23637;&#31034;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#65292;&#36890;&#24120;&#36890;&#36807;&#31574;&#30053;&#29109;&#27491;&#21017;&#21270;&#25512;&#21160;&#26234;&#33021;&#20307;&#22312;&#25506;&#32034;&#19978;&#38543;&#26426;&#21270;&#20854;&#34892;&#20026;&#12290;&#20174;&#20154;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#20351;&#24471;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#24456;&#38590;&#35299;&#37322;&#21644;&#39044;&#27979;&#65307;&#20174;&#23433;&#20840;&#35282;&#24230;&#26469;&#30475;&#65292;&#26356;&#38590;&#20197;&#36827;&#34892;&#24418;&#24335;&#21270;&#39564;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#21487;&#39044;&#27979;&#24615;&#24863;&#30693;&#24378;&#21270;&#23398;&#20064;&#65288;PA-RL&#65289;&#65292;&#29992;&#20110;&#24341;&#23548;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#65292;&#20854;&#21033;&#29992;&#29366;&#24577;&#24207;&#21015;&#29109;&#29575;&#20316;&#20026;&#21487;&#39044;&#27979;&#24615;&#24230;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#29109;&#29575;&#21046;&#23450;&#20026;&#24179;&#22343;&#22870;&#21169;&#30446;&#26631;&#65292;&#24182;&#19988;&#30001;&#20110;&#20854;&#29109;&#22870;&#21169;&#20989;&#25968;&#20381;&#36182;&#20110;&#31574;&#30053;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21160;&#20316;&#30456;&#20851;&#30340;&#26367;&#20195;&#29109;&#65292;&#20197;&#21033;&#29992;PG&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26368;&#23567;&#21270;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#30340;&#30830;&#23450;&#24615;&#31574;&#30053;&#23384;&#22312;&#65292;&#24182;&#19988;&#26368;&#23567;&#21270;&#20102;&#23454;&#38469;&#29109;&#29575;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#23398;&#20064;&#21040;&#30340;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#19982;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Reinforcement Learning (RL), agents have no incentive to exhibit predictable behaviors, and are often pushed (through e.g. policy entropy regularization) to randomize their actions in favor of exploration. From a human perspective, this makes RL agents hard to interpret and predict, and from a safety perspective, even harder to formally verify. We propose a novel method to induce predictable behavior in RL agents, referred to as Predictability-Aware RL (PA-RL), which employs the state sequence entropy rate as a predictability measure. We show how the entropy rate can be formulated as an average reward objective, and since its entropy reward function is policy-dependent, we introduce an action-dependent surrogate entropy enabling the use of PG methods. We prove that deterministic policies minimizing the average surrogate reward exist and also minimize the actual entropy rate, and show how, given a learned dynamical model, we are able to approximate the value function associated to th
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#38656;&#28436;&#31034;&#30340;&#20998;&#23618;&#35268;&#21010;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#22797;&#26434;&#30340;&#38271;&#26102;&#38388;&#20219;&#21153;&#65292;&#20026;&#27599;&#20010;&#38454;&#27573;&#25552;&#20379;&#24037;&#20855;&#21517;&#31216;&#21644;Python&#20195;&#30721;&#12290;</title><link>https://arxiv.org/abs/2311.02787</link><description>&lt;p&gt;
&#21046;&#20316;&#19968;&#20010;&#29980;&#29980;&#22280;&#65306;&#29992;&#20110;&#38646;&#26679;&#26412;&#21464;&#24418;&#25805;&#32437;&#30340;&#20998;&#23618;EMD&#31354;&#38388;&#35268;&#21010;&#19982;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Make a Donut: Hierarchical EMD-Space Planning for Zero-Shot Deformable Manipulation with Tools
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02787
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#38656;&#28436;&#31034;&#30340;&#20998;&#23618;&#35268;&#21010;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#22797;&#26434;&#30340;&#38271;&#26102;&#38388;&#20219;&#21153;&#65292;&#20026;&#27599;&#20010;&#38454;&#27573;&#25552;&#20379;&#24037;&#20855;&#21517;&#31216;&#21644;Python&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#24418;&#29289;&#20307;&#25805;&#32437;&#26159;&#26426;&#22120;&#20154;&#39046;&#22495;&#20013;&#26368;&#36855;&#20154;&#21448;&#26368;&#33392;&#24040;&#30340;&#25361;&#25112;&#20043;&#19968;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#25216;&#26415;&#20027;&#35201;&#20381;&#36182;&#20110;&#36890;&#36807;&#28436;&#31034;&#23398;&#20064;&#28508;&#22312;&#21160;&#24577;&#65292;&#36890;&#24120;&#34920;&#31034;&#20026;&#31890;&#23376;&#25110;&#22270;&#20687;&#20043;&#19968;&#65292;&#20294;&#23384;&#22312;&#19968;&#20010;&#37325;&#35201;&#38480;&#21046;&#65306;&#33719;&#21462;&#36866;&#24403;&#30340;&#28436;&#31034;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#38271;&#26102;&#38388;&#20219;&#21153;&#65292;&#21487;&#33021;&#26159;&#22256;&#38590;&#30340;&#12290;&#27492;&#22806;&#65292;&#23436;&#20840;&#22522;&#20110;&#28436;&#31034;&#36827;&#34892;&#23398;&#20064;&#21487;&#33021;&#20250;&#38459;&#30861;&#27169;&#22411;&#36229;&#36234;&#28436;&#31034;&#20219;&#21153;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26080;&#38656;&#28436;&#31034;&#30340;&#20998;&#23618;&#35268;&#21010;&#26041;&#27861;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#30340;&#38271;&#26102;&#38388;&#20219;&#21153;&#32780;&#26080;&#38656;&#20219;&#20309;&#35757;&#32451;&#12290;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#34920;&#36798;&#19982;&#25351;&#23450;&#20219;&#21153;&#23545;&#24212;&#30340;&#39640;&#23618;&#12289;&#38454;&#27573;-by-&#38454;&#27573;&#35745;&#21010;&#12290;&#23545;&#20110;&#27599;&#20010;&#21333;&#29420;&#38454;&#27573;&#65292;LLM&#25552;&#20379;&#24037;&#20855;&#30340;&#21517;&#31216;&#21644;Python&#20195;&#30721;&#65292;&#20197;&#21046;&#20316;&#20013;&#38388;&#23376;&#30446;&#26631;&#28857;&#20113;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.02787v2 Announce Type: replace-cross  Abstract: Deformable object manipulation stands as one of the most captivating yet formidable challenges in robotics. While previous techniques have predominantly relied on learning latent dynamics through demonstrations, typically represented as either particles or images, there exists a pertinent limitation: acquiring suitable demonstrations, especially for long-horizon tasks, can be elusive. Moreover, basing learning entirely on demonstrations can hamper the model's ability to generalize beyond the demonstrated tasks. In this work, we introduce a demonstration-free hierarchical planning approach capable of tackling intricate long-horizon tasks without necessitating any training. We employ large language models (LLMs) to articulate a high-level, stage-by-stage plan corresponding to a specified task. For every individual stage, the LLM provides both the tool's name and the Python code to craft intermediate subgoal point clouds. With the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#29992;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#21542;&#35760;&#24518;&#20102;&#24050;&#30693;&#26412;&#20307;&#35770;&#30340;&#20449;&#24687;&#20197;&#21450;&#35760;&#24518;&#30340;&#31243;&#24230;&#65292;&#32467;&#26524;&#26174;&#31034;LLMs&#37096;&#20998;&#22320;&#20102;&#35299;&#26412;&#20307;&#35770;&#30340;&#27010;&#24565;&#65292;&#35760;&#24518;&#31243;&#24230;&#19982;&#20854;&#22312;Web&#19978;&#30340;&#27969;&#34892;&#31243;&#24230;&#25104;&#27491;&#27604;&#12290;</title><link>http://arxiv.org/abs/2401.14931</link><description>&lt;p&gt;
LLM&#26159;&#21542;&#33021;&#35760;&#24518;&#26412;&#20307;&#35770;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do LLMs Dream of Ontologies?. (arXiv:2401.14931v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#29992;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#21542;&#35760;&#24518;&#20102;&#24050;&#30693;&#26412;&#20307;&#35770;&#30340;&#20449;&#24687;&#20197;&#21450;&#35760;&#24518;&#30340;&#31243;&#24230;&#65292;&#32467;&#26524;&#26174;&#31034;LLMs&#37096;&#20998;&#22320;&#20102;&#35299;&#26412;&#20307;&#35770;&#30340;&#27010;&#24565;&#65292;&#35760;&#24518;&#31243;&#24230;&#19982;&#20854;&#22312;Web&#19978;&#30340;&#27969;&#34892;&#31243;&#24230;&#25104;&#27491;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26368;&#36817;&#22312;&#33258;&#21160;&#25991;&#26412;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#12290;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#20381;&#36182;&#20110;&#24213;&#23618;&#31070;&#32463;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#30340;&#21442;&#25968;&#25968;&#37327;&#65292;&#36825;&#20351;&#24471;LLMs&#33021;&#22815;&#35760;&#24518;&#35757;&#32451;&#36807;&#31243;&#20013;&#25509;&#35302;&#21040;&#30340;&#22823;&#37327;&#25968;&#25454;&#30340;&#19968;&#37096;&#20998;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#29992;&#39044;&#35757;&#32451;LLMs&#26159;&#21542;&#35760;&#24518;&#20102;&#24050;&#30693;&#26412;&#20307;&#35770;&#30340;&#20449;&#24687;&#20197;&#21450;&#35760;&#24518;&#30340;&#31243;&#24230;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#37096;&#20998;&#22320;&#20102;&#35299;&#26412;&#20307;&#35770;&#65306;&#23427;&#20204;&#21487;&#20197;&#35760;&#24518;&#25991;&#26412;&#20013;&#25552;&#21040;&#30340;&#26412;&#20307;&#35770;&#27010;&#24565;&#65292;&#20294;&#20854;&#23545;&#27010;&#24565;&#30340;&#35760;&#24518;&#31243;&#24230;&#20284;&#20046;&#19982;&#20854;&#22312;Web&#19978;&#30340;&#27969;&#34892;&#31243;&#24230;&#25104;&#27604;&#20363;&#21464;&#21270;&#65292;&#22240;&#20026;Web&#26159;&#23427;&#20204;&#35757;&#32451;&#26448;&#26009;&#30340;&#20027;&#35201;&#26469;&#28304;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#36890;&#36807;&#27979;&#37327;&#19981;&#21516;&#25552;&#31034;&#37325;&#22797;&#12289;&#26597;&#35810;&#35821;&#35328;&#21644;&#30830;&#23450;&#24230;&#30340;&#36755;&#20986;&#19968;&#33268;&#24615;&#26469;&#20272;&#35745;LLMs&#23545;&#26412;&#20307;&#35770;&#20449;&#24687;&#30340;&#35760;&#24518;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have recently revolutionized automated text understanding and generation. The performance of these models relies on the high number of parameters of the underlying neural architectures, which allows LLMs to memorize part of the vast quantity of data seen during the training. This paper investigates whether and to what extent general-purpose pre-trained LLMs have memorized information from known ontologies. Our results show that LLMs partially know ontologies: they can, and do indeed, memorize concepts from ontologies mentioned in the text, but the level of memorization of their concepts seems to vary proportionally to their popularity on the Web, the primary source of their training material. We additionally propose new metrics to estimate the degree of memorization of ontological information in LLMs by measuring the consistency of the output produced across different prompt repetitions, query languages, and degrees of determinism.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#27700;&#21360;&#25216;&#26415;&#24212;&#29992;&#20110;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#30340;&#28431;&#27934;&#65292;&#24182;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#27700;&#21360;&#26426;&#21046;&#23481;&#26131;&#34987;&#23545;&#25163;&#30772;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.07726</link><description>&lt;p&gt;
&#23545;&#27700;&#21360;&#25216;&#26415;&#24212;&#29992;&#20110;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#30340;&#28431;&#27934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards the Vulnerability of Watermarking Artificial Intelligence Generated Content. (arXiv:2310.07726v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07726
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#27700;&#21360;&#25216;&#26415;&#24212;&#29992;&#20110;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#30340;&#28431;&#27934;&#65292;&#24182;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#27700;&#21360;&#26426;&#21046;&#23481;&#26131;&#34987;&#23545;&#25163;&#30772;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#65288;AIGC&#65289;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#35768;&#22810;&#21830;&#19994;&#26381;&#21153;&#24050;&#32463;&#25512;&#20986;&#12290;&#36825;&#20123;&#26381;&#21153;&#21033;&#29992;&#20808;&#36827;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#22914;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20026;&#29992;&#25143;&#29983;&#25104;&#21019;&#24847;&#20869;&#23481;&#65288;&#20363;&#22914;&#36924;&#30495;&#30340;&#22270;&#20687;&#12289;&#27969;&#30021;&#30340;&#21477;&#23376;&#65289;&#12290;&#23545;&#20110;&#27492;&#31867;&#29983;&#25104;&#20869;&#23481;&#30340;&#20351;&#29992;&#38656;&#35201;&#39640;&#24230;&#30417;&#31649;&#65292;&#22240;&#20026;&#26381;&#21153;&#25552;&#20379;&#21830;&#38656;&#35201;&#30830;&#20445;&#29992;&#25143;&#19981;&#36829;&#21453;&#20351;&#29992;&#25919;&#31574;&#65288;&#20363;&#22914;&#28389;&#29992;&#21830;&#19994;&#21270;&#12289;&#29983;&#25104;&#21644;&#20998;&#21457;&#19981;&#23433;&#20840;&#30340;&#20869;&#23481;&#65289;&#12290;&#26368;&#36817;&#25552;&#20986;&#20102;&#35768;&#22810;&#27700;&#21360;&#25216;&#26415;&#65292;&#20294;&#26159;&#26412;&#25991;&#34920;&#26126;&#23545;&#25163;&#21487;&#20197;&#36731;&#26131;&#30772;&#35299;&#36825;&#20123;&#27700;&#21360;&#26426;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#21487;&#33021;&#30340;&#25915;&#20987;&#26041;&#24335;&#65306;&#65288;1&#65289;&#27700;&#21360;&#21435;&#38500;&#65306;&#23545;&#25163;&#21487;&#20197;&#36731;&#26494;&#22320;&#20174;&#29983;&#25104;&#20869;&#23481;&#20013;&#21024;&#38500;&#23884;&#20837;&#30340;&#27700;&#21360;&#65292;&#28982;&#21518;&#33258;&#30001;&#20351;&#29992;&#32780;&#19981;&#21463;&#26381;&#21153;&#25552;&#20379;&#21830;&#30340;&#38480;&#21046;&#65307;&#65288;2&#65289;&#27700;&#21360;&#20266;&#36896;&#65306;&#23545;&#25163;&#21487;&#20197;&#21019;&#24314;&#38750;&#27861;&#30340;&#27700;&#21360;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence Generated Content (AIGC) is gaining great popularity in social media, with many commercial services available. These services leverage advanced generative models, such as latent diffusion models and large language models, to generate creative content (e.g., realistic images, fluent sentences) for users. The usage of such generated content needs to be highly regulated, as the service providers need to ensure the users do not violate the usage policies (e.g., abuse for commercialization, generating and distributing unsafe content).  Numerous watermarking approaches have been proposed recently. However, in this paper, we show that an adversary can easily break these watermarking mechanisms. Specifically, we consider two possible attacks. (1) Watermark removal: the adversary can easily erase the embedded watermark from the generated content and then use it freely without the regulation of the service provider. (2) Watermark forge: the adversary can create illegal co
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#30340;&#26500;&#24314;&#27969;&#31243;&#12289;&#20851;&#38190;&#25216;&#26415;&#21644;&#21033;&#29992;&#26041;&#27861;&#20197;&#21450;&#29616;&#26377;&#36164;&#28304;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.04802</link><description>&lt;p&gt;
&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;&#32508;&#36848;&#65306;&#36164;&#28304;&#12289;&#24212;&#29992;&#21644;&#21069;&#26223;
&lt;/p&gt;
&lt;p&gt;
A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#30340;&#26500;&#24314;&#27969;&#31243;&#12289;&#20851;&#38190;&#25216;&#26415;&#21644;&#21033;&#29992;&#26041;&#27861;&#20197;&#21450;&#29616;&#26377;&#36164;&#28304;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#24050;&#25104;&#20026;&#32452;&#32455;&#21307;&#23398;&#30693;&#35782;&#30340;&#26377;&#32467;&#26500;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#20026;&#24037;&#20855;&#65292;&#25552;&#20379;&#20102;&#21307;&#23398;&#27010;&#24565;&#21450;&#20854;&#20851;&#31995;&#30340;&#20840;&#38754;&#35270;&#22270;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#35206;&#30422;&#33539;&#22260;&#26377;&#38480;&#31561;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#65292;&#24378;&#35843;&#20102;&#22312;HKG&#39046;&#22495;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24517;&#35201;&#24615;&#12290;&#26412;&#32508;&#36848;&#26159;HKG&#30340;&#31532;&#19968;&#20221;&#32508;&#21512;&#27010;&#36848;&#12290;&#25105;&#20204;&#24635;&#32467;&#20102;HKG&#26500;&#24314;&#30340;&#27969;&#31243;&#21644;&#20851;&#38190;&#25216;&#26415;&#65288;&#21363;&#20174;&#22836;&#24320;&#22987;&#21644;&#36890;&#36807;&#38598;&#25104;&#65289;&#65292;&#20197;&#21450;&#24120;&#35265;&#30340;&#21033;&#29992;&#26041;&#27861;&#65288;&#21363;&#22522;&#20110;&#27169;&#22411;&#21644;&#38750;&#22522;&#20110;&#27169;&#22411;&#65289;&#12290;&#20026;&#20102;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#36164;&#28304;&#65292;&#25105;&#20204;&#26681;&#25454;&#23427;&#20204;&#25429;&#33719;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#24212;&#29992;&#39046;&#22495;&#65288;&#35813;&#36164;&#28304;&#23384;&#20648;&#20110;https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase&#65289;&#32452;&#32455;&#20102;&#29616;&#26377;&#30340;HKG&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;&#22312;&#24212;&#29992;&#37096;&#20998;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
&lt;/p&gt;</description></item></channel></rss>