<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>CoBOS&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#22522;&#20110;&#32422;&#26463;&#30340;&#35843;&#24230;&#26041;&#27861;&#65292;&#22312;&#20154;&#26426;&#21327;&#20316;&#20013;&#23454;&#29616;&#20102;&#26426;&#22120;&#20154;&#23545;&#19981;&#30830;&#23450;&#20107;&#20214;&#30340;&#36866;&#24212;&#24615;&#65292;&#22823;&#22823;&#20943;&#36731;&#20102;&#29992;&#25143;&#30340;&#21387;&#21147;&#65292;&#25552;&#39640;&#20102;&#24037;&#20316;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.18459</link><description>&lt;p&gt;
CoBOS: &#22522;&#20110;&#32422;&#26463;&#30340;&#20154;&#26426;&#21327;&#20316;&#22312;&#32447;&#35843;&#24230;&#22120;
&lt;/p&gt;
&lt;p&gt;
CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18459
&lt;/p&gt;
&lt;p&gt;
CoBOS&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#22522;&#20110;&#32422;&#26463;&#30340;&#35843;&#24230;&#26041;&#27861;&#65292;&#22312;&#20154;&#26426;&#21327;&#20316;&#20013;&#23454;&#29616;&#20102;&#26426;&#22120;&#20154;&#23545;&#19981;&#30830;&#23450;&#20107;&#20214;&#30340;&#36866;&#24212;&#24615;&#65292;&#22823;&#22823;&#20943;&#36731;&#20102;&#29992;&#25143;&#30340;&#21387;&#21147;&#65292;&#25552;&#39640;&#20102;&#24037;&#20316;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28041;&#21450;&#20154;&#31867;&#21644;&#26426;&#22120;&#20154;&#30340;&#35013;&#37197;&#36807;&#31243;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#65292;&#22240;&#20026;&#20010;&#20154;&#27963;&#21160;&#21644;&#20849;&#20139;&#24037;&#20316;&#31354;&#38388;&#30340;&#35775;&#38382;&#24517;&#39035;&#21327;&#35843;&#12290;&#22266;&#23450;&#30340;&#26426;&#22120;&#20154;&#31243;&#24207;&#19981;&#20801;&#35768;&#20559;&#31163;&#22266;&#23450;&#21327;&#35758;&#12290;&#22312;&#36825;&#26679;&#30340;&#36807;&#31243;&#20013;&#24037;&#20316;&#21487;&#33021;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26377;&#21387;&#21147;&#65292;&#24182;&#23548;&#33268;&#34892;&#20026;&#26080;&#25928;&#25110;&#22833;&#36133;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#22522;&#20110;&#32422;&#26463;&#30340;&#35843;&#24230;&#26041;&#27861;&#65292;&#20301;&#20110;&#25903;&#25345;&#34892;&#20026;&#26641;&#30340;&#21453;&#24212;&#24335;&#25191;&#34892;&#25511;&#21046;&#26694;&#26550;&#20013;&#65292;&#21517;&#20026;CoBOS&#12290;&#36825;&#20351;&#24471;&#26426;&#22120;&#20154;&#33021;&#22815;&#36866;&#24212;&#24310;&#36831;&#27963;&#21160;&#23436;&#25104;&#21644;&#27963;&#21160;&#36873;&#25321;&#65288;&#30001;&#20154;&#31867;&#65289;&#31561;&#19981;&#30830;&#23450;&#20107;&#20214;&#12290;&#29992;&#25143;&#23558;&#20307;&#39564;&#21040;&#36739;&#23569;&#30340;&#21387;&#21147;&#65292;&#22240;&#20026;&#26426;&#22120;&#20154;&#21516;&#20107;&#20250;&#35843;&#25972;&#20854;&#34892;&#20026;&#20197;&#26368;&#22909;&#22320;&#34917;&#20805;&#20154;&#31867;&#36873;&#25321;&#30340;&#27963;&#21160;&#65292;&#20197;&#23436;&#25104;&#20849;&#21516;&#20219;&#21153;&#12290;&#38500;&#20102;&#25913;&#21892;&#30340;&#24037;&#20316;&#26465;&#20214;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36824;&#23548;&#33268;&#20102;&#25928;&#29575;&#30340;&#25552;&#39640;&#65292;&#21363;&#20351;&#22312;&#39640;&#24230;&#19981;&#30830;&#23450;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#27010;&#29575;&#24615;&#30340;si&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18459v1 Announce Type: cross  Abstract: Assembly processes involving humans and robots are challenging scenarios because the individual activities and access to shared workspace have to be coordinated. Fixed robot programs leave no room to diverge from a fixed protocol. Working on such a process can be stressful for the user and lead to ineffective behavior or failure. We propose a novel approach of online constraint-based scheduling in a reactive execution control framework facilitating behavior trees called CoBOS. This allows the robot to adapt to uncertain events such as delayed activity completions and activity selection (by the human). The user will experience less stress as the robotic coworkers adapt their behavior to best complement the human-selected activities to complete the common task. In addition to the improved working conditions, our algorithm leads to increased efficiency, even in highly uncertain scenarios. We evaluate our algorithm using a probabilistic si
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#21644;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#21644;&#20943;&#36731;&#36807;&#24230;&#25311;&#21512;&#12290;</title><link>https://arxiv.org/abs/2403.10056</link><description>&lt;p&gt;
&#19981;&#35201;&#21322;&#24515;&#21322;&#24847;&#65306;&#25429;&#25417;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#20013;&#30340;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10056
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#21644;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#21644;&#20943;&#36731;&#36807;&#24230;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10056v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25351;&#23548;&#35843;&#25972;&#21487;&#20197;&#39537;&#20351;&#23427;&#20204;&#22312;&#29305;&#23450;&#19979;&#28216;&#20219;&#21153;&#20013;&#20135;&#29983;&#31526;&#21512;&#20154;&#31867;&#30446;&#26631;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;LLMs&#30340;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#65288;CIT&#65289;&#36807;&#31243;&#21487;&#33021;&#20250;&#24102;&#26469;&#28798;&#38590;&#24615;&#36951;&#24536;&#65288;CF&#65289;&#38382;&#39064;&#65292;&#23548;&#33268;&#20808;&#21069;&#23398;&#21040;&#30340;&#33021;&#21147;&#36864;&#21270;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#23581;&#35797;&#36890;&#36807;&#20462;&#25913;&#27169;&#22411;&#25110;&#37325;&#25918;&#25968;&#25454;&#26469;&#32531;&#35299;CF&#38382;&#39064;&#65292;&#20294;&#36825;&#21487;&#33021;&#21482;&#35760;&#20303;&#25351;&#20196;&#30340;&#34920;&#38754;&#27169;&#24335;&#24182;&#22312;&#30041;&#23384;&#20219;&#21153;&#19978;&#24863;&#21040;&#22256;&#24785;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#65288;KPIG&#65289;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35745;&#31639;&#25513;&#30422;&#37096;&#20998;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#24182;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20174;&#32780;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#19982;&#27491;&#30830;&#21709;&#24212;&#30456;&#20851;&#30340;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#65292;&#24182;&#20943;&#36731;&#23545;&#25351;&#23548;&#20013;&#36890;&#29992;&#25551;&#36848;&#30340;&#36807;&#24230;&#25311;&#21512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#25351;&#26631;&#65292;P&#20998;&#21644;V&#20998;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10056v1 Announce Type: cross  Abstract: Instruction tuning for large language models (LLMs) can drive them to produce results consistent with human goals in specific downstream tasks. However, the process of continual instruction tuning (CIT) for LLMs may bring about the catastrophic forgetting (CF) problem, where previously learned abilities are degraded. Recent methods try to alleviate the CF problem by modifying models or replaying data, which may only remember the surface-level pattern of instructions and get confused on held-out tasks. In this paper, we propose a novel continual instruction tuning method based on Key-part Information Gain (KPIG). Our method computes the information gain on masked parts to dynamically replay data and refine the training objective, which enables LLMs to capture task-aware information relevant to the correct response and alleviate overfitting to general descriptions in instructions. In addition, we propose two metrics, P-score and V-score,
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20559;&#24046;&#22686;&#24378;&#30340;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;BCT&#65289;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#38142;&#24335;&#24605;&#32500;&#20013;&#30340;&#20559;&#35265;&#25512;&#29702;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#36890;&#36807;&#35757;&#32451;&#27169;&#22411;&#22312;&#24102;&#26377;&#21644;&#19981;&#24102;&#26377;&#20559;&#32622;&#29305;&#24449;&#30340;&#25552;&#31034;&#19979;&#36827;&#34892;&#19968;&#33268;&#30340;&#25512;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.05518</link><description>&lt;p&gt;
&#36890;&#36807;&#20559;&#24046;&#22686;&#24378;&#19968;&#33268;&#24615;&#35757;&#32451;&#20943;&#23569;&#38142;&#24335;&#24605;&#32500;&#20013;&#30340;&#20559;&#35265;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05518
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20559;&#24046;&#22686;&#24378;&#30340;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;BCT&#65289;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#38142;&#24335;&#24605;&#32500;&#20013;&#30340;&#20559;&#35265;&#25512;&#29702;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#36890;&#36807;&#35757;&#32451;&#27169;&#22411;&#22312;&#24102;&#26377;&#21644;&#19981;&#24102;&#26377;&#20559;&#32622;&#29305;&#24449;&#30340;&#25552;&#31034;&#19979;&#36827;&#34892;&#19968;&#33268;&#30340;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#38142;&#24335;&#24605;&#32500;&#25552;&#31034;&#65288;CoT&#65289;&#26377;&#28508;&#21147;&#25913;&#21892;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20294;&#23427;&#21487;&#33021;&#20250;&#31995;&#32479;&#24615;&#22320;&#27498;&#26354;&#24433;&#21709;&#27169;&#22411;&#34892;&#20026;&#30340;&#22240;&#32032;--&#27604;&#22914;&#65292;&#21512;&#29702;&#21270;&#31572;&#26696;&#20197;&#31526;&#21512;&#29992;&#25143;&#24847;&#35265;&#32780;&#19981;&#25552;&#21450;&#27492;&#20559;&#35265;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#19968;&#20559;&#35265;&#25512;&#29702;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20559;&#24046;&#22686;&#24378;&#30340;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;BCT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#24494;&#35843;&#26041;&#26696;&#65292;&#26088;&#22312;&#35757;&#32451;&#27169;&#22411;&#22312;&#24102;&#26377;&#21644;&#19981;&#24102;&#26377;&#20559;&#32622;&#29305;&#24449;&#30340;&#25552;&#31034;&#19979;&#36827;&#34892;&#19968;&#33268;&#30340;&#25512;&#29702;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#27979;&#35797;&#21333;&#20803;&#65292;&#38024;&#23545;&#19971;&#20010;&#38382;&#31572;&#20219;&#21153;&#27979;&#35797;&#20102;&#20061;&#31181;&#24418;&#24335;&#30340;&#26377;&#20559;&#25512;&#29702;&#65292;&#21457;&#29616;&#23558;BCT&#24212;&#29992;&#20110;&#24102;&#26377;&#19968;&#31181;&#20559;&#35265;&#30340;GPT-3.5-Turbo&#21487;&#20197;&#23558;&#26377;&#20559;&#25512;&#29702;&#30340;&#27604;&#20363;&#22312;&#26410;&#30693;&#20219;&#21153;&#19978;&#38477;&#20302;86%&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#27169;&#22411;&#25512;&#24191;&#21040;&#20854;&#20182;&#24418;&#24335;&#30340;&#20559;&#35265;&#65292;&#24179;&#22343;&#23558;&#26410;&#30693;&#20559;&#35265;&#19978;&#30340;&#26377;&#20559;&#25512;&#29702;&#20943;&#23569;&#20102;37%&#12290;&#30001;&#20110;BCT&#23558;&#26410;&#30693;&#20559;&#35265;&#27867;&#21270;&#24182;&#19988;&#19981;&#38656;&#35201;&#37329;&#26631;&#31614;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#20250;&#26377;&#21161;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05518v1 Announce Type: cross  Abstract: While chain-of-thought prompting (CoT) has the potential to improve the explainability of language model reasoning, it can systematically misrepresent the factors influencing models' behavior--for example, rationalizing answers in line with a user's opinion without mentioning this bias. To mitigate this biased reasoning problem, we introduce bias-augmented consistency training (BCT), an unsupervised fine-tuning scheme that trains models to give consistent reasoning across prompts with and without biasing features. We construct a suite testing nine forms of biased reasoning on seven question-answering tasks, and find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of biased reasoning by 86% on held-out tasks. Moreover, this model generalizes to other forms of bias, reducing biased reasoning on held-out biases by an average of 37%. As BCT generalizes to held-out biases and does not require gold labels, this method may h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#35780;&#20272;&#20102;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#65292;&#25351;&#20986;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#20173;&#26377;&#24453;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.04963</link><description>&lt;p&gt;
&#22312;&#22522;&#20110;&#38169;&#35823;&#30340;&#20154;&#31867;&#35780;&#20272;&#20013;&#28145;&#20837;&#35780;&#20272;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#35780;&#20272;&#20102;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#65292;&#25351;&#20986;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#20173;&#26377;&#24453;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21477;&#23376;&#31616;&#21270;&#26159;&#19968;&#31181;&#37325;&#20889;&#21477;&#23376;&#20197;&#20415;&#26356;&#26131;&#38405;&#35835;&#21644;&#29702;&#35299;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#24110;&#21161;&#26377;&#21508;&#31181;&#38405;&#35835;&#38590;&#39064;&#30340;&#20154;&#26469;&#35828;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;&#38543;&#30528;&#20808;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20852;&#36215;&#65292;&#35780;&#20272;&#23427;&#20204;&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#21464;&#24471;&#36843;&#22312;&#30473;&#30571;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21033;&#29992;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26469;&#35780;&#20272;LLMs&#30340;&#31616;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#35780;&#20272;&#26041;&#27861;&#23545;LLMs&#22312;&#31616;&#21270;&#35780;&#20272;&#20013;&#30340;&#36866;&#29992;&#24615;&#20173;&#28982;&#23384;&#22312;&#30097;&#38382;&#12290;&#39318;&#20808;&#65292;&#29616;&#26377;&#33258;&#21160;&#25351;&#26631;&#22312;LLMs&#30340;&#31616;&#21270;&#35780;&#20272;&#20013;&#30340;&#36866;&#29992;&#24615;&#20173;&#19981;&#30830;&#23450;&#12290;&#20854;&#27425;&#65292;&#24403;&#21069;&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#36890;&#24120;&#38519;&#20837;&#20004;&#20010;&#26497;&#31471;&#65306;&#35201;&#20040;&#36807;&#20110;&#32932;&#27973;&#65292;&#26080;&#27861;&#28165;&#26224;&#29702;&#35299;&#27169;&#22411;&#30340;&#34920;&#29616;&#65292;&#35201;&#20040;&#36807;&#20110;&#35814;&#32454;&#65292;&#20351;&#27880;&#37322;&#36807;&#31243;&#22797;&#26434;&#19988;&#23481;&#26131;&#20986;&#29616;&#19981;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#24433;&#21709;&#35780;&#20272;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04963v1 Announce Type: cross  Abstract: Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs' simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models' performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation's reliabil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#22686;&#21152;&#23545;&#40784;&#24230;&#21644;&#20943;&#23569;&#26377;&#29992;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#25552;&#20379;&#36825;&#20004;&#20010;&#25968;&#37327;&#30340;&#36793;&#30028;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.16332</link><description>&lt;p&gt;
&#23545;&#40784;&#21644;&#26377;&#29992;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65306;&#35821;&#35328;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Tradeoffs Between Alignment and Helpfulness in Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.16332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#22686;&#21152;&#23545;&#40784;&#24230;&#21644;&#20943;&#23569;&#26377;&#29992;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#25552;&#20379;&#36825;&#20004;&#20010;&#25968;&#37327;&#30340;&#36793;&#30028;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#24050;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#23433;&#20840;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#36890;&#36807;&#22686;&#24378;&#26399;&#26395;&#34892;&#20026;&#21644;&#25233;&#21046;&#38750;&#26399;&#26395;&#34892;&#20026;&#65292;&#23454;&#29616;&#20154;&#31867;&#19982;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#23433;&#20840;&#20132;&#20114;&#12290;&#36890;&#24120;&#36890;&#36807;&#35843;&#25972;&#27169;&#22411;&#25110;&#25554;&#20837;&#39044;&#35774;&#30340;&#23545;&#40784;&#25552;&#31034;&#26469;&#23454;&#29616;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#25913;&#21464;&#35757;&#32451;&#21518;&#30340;&#34920;&#31034;&#26469;&#25913;&#21464;&#27169;&#22411;&#34892;&#20026;&#30340;&#34920;&#31034;&#24037;&#31243;&#26041;&#27861;&#22312;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#26377;&#25928;&#24615;&#12290;&#34920;&#31034;&#24037;&#31243;&#22312;&#38754;&#23545;&#23545;&#25239;&#25915;&#20987;&#21644;&#38477;&#20302;&#31038;&#20250;&#20559;&#35265;&#31561;&#23545;&#40784;&#23548;&#21521;&#20219;&#21153;&#26041;&#38754;&#21462;&#24471;&#20102;&#22686;&#30410;&#65292;&#20294;&#20063;&#23548;&#33268;&#20102;&#27169;&#22411;&#25191;&#34892;&#22522;&#26412;&#20219;&#21153;&#33021;&#21147;&#30340;&#38477;&#20302;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22686;&#21152;&#23545;&#40784;&#24230;&#21644;&#20943;&#23569;&#27169;&#22411;&#26377;&#29992;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#25552;&#20379;&#36825;&#20004;&#20010;&#25968;&#37327;&#30340;&#36793;&#30028;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#27169;&#22411;&#30340;&#26377;&#29992;&#24615;&#36890;&#24120;&#20250;&#20943;&#23569;
&lt;/p&gt;
&lt;p&gt;
Language model alignment has become an important component of AI safety, allowing safe interactions between humans and language models, by enhancing desired behaviors and inhibiting undesired ones. It is often done by tuning the model or inserting preset aligning prompts. Recently, representation engineering, a method which alters the model's behavior via changing its representations post-training, was shown to be effective in aligning LLMs (Zou et al., 2023a). Representation engineering yields gains in alignment oriented tasks such as resistance to adversarial attacks and reduction of social biases, but was also shown to cause a decrease in the ability of the model to perform basic tasks. In this paper we study the tradeoff between the increase in alignment and decrease in helpfulness of the model. We propose a theoretical framework which provides bounds for these two quantities, and demonstrate their relevance empirically. Interestingly, we find that while the helpfulness generally d
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#26080;&#38480;&#26102;&#22495;&#24179;&#22343;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#20013;&#37327;&#23376;&#21152;&#36895;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#37327;&#23376;&#26694;&#26550;&#65292;&#36890;&#36807;&#39640;&#25928;&#30340;&#37327;&#23376;&#22343;&#20540;&#20272;&#35745;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#25351;&#25968;&#32423;&#25913;&#36827;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#25152;&#25552;&#20986;&#30340;&#37327;&#23376;&#31639;&#27861;&#30456;&#36739;&#20110;&#32463;&#20856;&#31639;&#27861;&#65292;&#22312;&#36951;&#25022;&#30028;&#38480;&#19978;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2310.11684</link><description>&lt;p&gt;
&#26080;&#38480;&#26102;&#22495;&#24179;&#22343;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#30340;&#37327;&#23376;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Quantum Acceleration of Infinite Horizon Average-Reward Reinforcement Learning. (arXiv:2310.11684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11684
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#26080;&#38480;&#26102;&#22495;&#24179;&#22343;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#20013;&#37327;&#23376;&#21152;&#36895;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#37327;&#23376;&#26694;&#26550;&#65292;&#36890;&#36807;&#39640;&#25928;&#30340;&#37327;&#23376;&#22343;&#20540;&#20272;&#35745;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#25351;&#25968;&#32423;&#25913;&#36827;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#25152;&#25552;&#20986;&#30340;&#37327;&#23376;&#31639;&#27861;&#30456;&#36739;&#20110;&#32463;&#20856;&#31639;&#27861;&#65292;&#22312;&#36951;&#25022;&#30028;&#38480;&#19978;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#37327;&#23376;&#21152;&#36895;&#22312;&#35299;&#20915;&#26080;&#38480;&#26102;&#22495;Markov&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#20013;&#25552;&#39640;&#24179;&#22343;&#22870;&#21169;&#32467;&#26524;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#37327;&#23376;&#26694;&#26550;&#65292;&#29992;&#20110;&#20195;&#29702;&#19982;&#26410;&#30693;MDP&#30340;&#20114;&#21160;&#65292;&#25193;&#23637;&#20102;&#20256;&#32479;&#30340;&#20132;&#20114;&#33539;&#24335;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#35774;&#35745;&#19968;&#31181;&#22522;&#20110;&#20048;&#35266;&#20027;&#23548;&#30340;&#20855;&#26377;&#37327;&#23376;&#20449;&#21495;&#30340;&#34920;&#26684;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#39640;&#25928;&#30340;&#37327;&#23376;&#22343;&#20540;&#20272;&#35745;&#25216;&#26415;&#33719;&#21462;&#20195;&#29702;&#33719;&#21462;&#30340;&#37327;&#23376;&#20449;&#21495;&#12290;&#36890;&#36807;&#28145;&#20837;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#37327;&#23376;&#22343;&#20540;&#20272;&#35745;&#30340;&#20248;&#21183;&#33021;&#22815;&#22312;&#26080;&#38480;&#26102;&#22495;&#24378;&#21270;&#23398;&#20064;&#20013;&#23548;&#33268;&#36951;&#25022;&#20445;&#35777;&#30340;&#25351;&#25968;&#36827;&#23637;&#12290;&#20855;&#20307;&#22320;&#65292;&#25152;&#25552;&#20986;&#30340;&#37327;&#23376;&#31639;&#27861;&#23454;&#29616;&#20102;&#19968;&#20010;&#36951;&#25022;&#30028;&#20026;$\tilde{\mathcal{O}}(1)$&#30340;&#24615;&#33021;&#65292;&#36825;&#26159;&#30456;&#23545;&#20110;&#32463;&#20856;&#23545;&#24212;&#31639;&#27861;&#25152;&#23637;&#31034;&#30340;$\tilde{\mathcal{O}}(\sqrt{T})$&#30028;&#38480;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the potential of quantum acceleration in addressing infinite horizon Markov Decision Processes (MDPs) to enhance average reward outcomes. We introduce an innovative quantum framework for the agent's engagement with an unknown MDP, extending the conventional interaction paradigm. Our approach involves the design of an optimism-driven tabular Reinforcement Learning algorithm that harnesses quantum signals acquired by the agent through efficient quantum mean estimation techniques. Through thorough theoretical analysis, we demonstrate that the quantum advantage in mean estimation leads to exponential advancements in regret guarantees for infinite horizon Reinforcement Learning. Specifically, the proposed Quantum algorithm achieves a regret bound of $\tilde{\mathcal{O}}(1)$, a significant improvement over the $\tilde{\mathcal{O}}(\sqrt{T})$ bound exhibited by classical counterparts.
&lt;/p&gt;</description></item><item><title>CLEVRER-Humans&#26159;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21028;&#26029;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20154;&#24037;&#26631;&#27880;&#26469;&#35299;&#20915;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#35821;&#35328;&#25551;&#36848;&#30340;&#32570;&#20047;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#21644;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.03635</link><description>&lt;p&gt;
CLEVRER-Humans: &#29992;&#20154;&#31867;&#30340;&#26041;&#24335;&#25551;&#36848;&#29289;&#29702;&#21644;&#22240;&#26524;&#20107;&#20214;
&lt;/p&gt;
&lt;p&gt;
CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03635
&lt;/p&gt;
&lt;p&gt;
CLEVRER-Humans&#26159;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21028;&#26029;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20154;&#24037;&#26631;&#27880;&#26469;&#35299;&#20915;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#35821;&#35328;&#25551;&#36848;&#30340;&#32570;&#20047;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#21644;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#33021;&#22815;&#25512;&#29702;&#29289;&#29702;&#20107;&#20214;&#21450;&#20854;&#22240;&#26524;&#20851;&#31995;&#30340;&#26426;&#22120;&#23545;&#20110;&#19982;&#29289;&#29702;&#19990;&#30028;&#36827;&#34892;&#28789;&#27963;&#20114;&#21160;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#29289;&#29702;&#21644;&#22240;&#26524;&#25512;&#29702;&#22522;&#20934;&#37117;&#20165;&#22522;&#20110;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#36825;&#31181;&#35774;&#35745;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#65306;&#19968;&#26159;&#20107;&#20214;&#31867;&#22411;&#21644;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#32570;&#20047;&#22810;&#26679;&#24615;&#65307;&#20108;&#26159;&#22522;&#20110;&#25163;&#21160;&#23450;&#20041;&#30340;&#21551;&#21457;&#24335;&#35268;&#21017;&#30340;&#22240;&#26524;&#20851;&#31995;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CLEVRER-Humans&#22522;&#20934;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20154;&#24037;&#26631;&#27880;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#23545;&#29289;&#29702;&#20107;&#20214;&#30340;&#22240;&#26524;&#21028;&#26029;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#31181;&#25216;&#26415;&#26469;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#65306;&#39318;&#20808;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#20219;&#21153;&#65292;&#20197; eliciting &#35270;&#39057;&#20013;&#20107;&#20214;&#30340;&#26032;&#34920;&#31034;&#26041;&#24335;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#22240;&#26524;&#20107;&#20214;&#22270; (CEGs)&#65307;&#20854;&#27425;&#65292;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Building machines that can reason about physical events and their causal relationships is crucial for flexible interaction with the physical world. However, most existing physical and causal reasoning benchmarks are exclusively based on synthetically generated events and synthetic natural language descriptions of causal relationships. This design brings up two issues. First, there is a lack of diversity in both event types and natural language descriptions; second, causal relationships based on manually-defined heuristics are different from human judgments. To address both shortcomings, we present the CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of physical events with human labels. We employ two techniques to improve data collection efficiency: first, a novel iterative event cloze task to elicit a new representation of events in videos, which we term Causal Event Graphs (CEGs); second, a data augmentation technique based on neural language generative models.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#21644;&#24037;&#20855;&#65292;&#21487;&#20197;&#20026;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#36755;&#20986;&#35745;&#31639;&#22810;&#20010;&#35299;&#37322;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#20998;&#31867;&#22120;&#34892;&#20026;&#30340;&#27934;&#23519;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.14309</link><description>&lt;p&gt;
&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#22810;&#20010;&#19981;&#21516;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Multiple Different Explanations for Image Classifiers. (arXiv:2309.14309v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14309
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#21644;&#24037;&#20855;&#65292;&#21487;&#20197;&#20026;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#36755;&#20986;&#35745;&#31639;&#22810;&#20010;&#35299;&#37322;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#20998;&#31867;&#22120;&#34892;&#20026;&#30340;&#27934;&#23519;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#22270;&#20687;&#20998;&#31867;&#22120;&#35299;&#37322;&#24037;&#20855;&#36890;&#24120;&#21482;&#20250;&#32473;&#20986;&#19968;&#31181;&#23545;&#20110;&#22270;&#20687;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#22270;&#20687;&#26469;&#35828;&#65292;&#26080;&#35770;&#26159;&#20154;&#31867;&#36824;&#26159;&#22270;&#20687;&#20998;&#31867;&#22120;&#37117;&#25509;&#21463;&#22810;&#20010;&#35299;&#37322;&#26469;&#35299;&#37322;&#22270;&#20687;&#26631;&#31614;&#12290;&#22240;&#27492;&#65292;&#38480;&#21046;&#35299;&#37322;&#30340;&#25968;&#37327;&#21482;&#26377;&#19968;&#20010;&#20005;&#37325;&#38480;&#21046;&#20102;&#23545;&#20998;&#31867;&#22120;&#34892;&#20026;&#30340;&#27934;&#23519;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#31639;&#27861;&#21644;&#24037;&#20855;REX&#65292;&#29992;&#20110;&#35745;&#31639;&#40657;&#30418;&#22270;&#20687;&#20998;&#31867;&#22120;&#23545;&#32473;&#23450;&#22270;&#20687;&#30340;&#36755;&#20986;&#30340;&#22810;&#20010;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#22240;&#26524;&#29702;&#35770;&#30340;&#21487;&#38752;&#26041;&#27861;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20854;&#29702;&#35770;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#32467;&#26524;&#65292;&#26174;&#31034;REX&#22312;ImageNet-mini&#22522;&#20934;&#27979;&#35797;&#20013;&#25214;&#21040;&#30340;&#22810;&#20010;&#35299;&#37322;&#27604;&#20043;&#21069;&#30340;&#24037;&#20316;&#22810;7&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing explanation tools for image classifiers usually give only one single explanation for an image. For many images, however, both humans and image classifiers accept more than one explanation for the image label. Thus, restricting the number of explanations to just one severely limits the insight into the behavior of the classifier. In this paper, we describe an algorithm and a tool, REX, for computing multiple explanations of the output of a black-box image classifier for a given image. Our algorithm uses a principled approach based on causal theory. We analyse its theoretical complexity and provide experimental results showing that REX finds multiple explanations on 7 times more images than the previous work on the ImageNet-mini benchmark.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992; Evol-Instruct &#26041;&#27861;&#21019;&#24314;&#20102;&#22823;&#37327;&#19981;&#21516;&#22797;&#26434;&#24230;&#30340;&#25351;&#20196;&#25968;&#25454;&#29992;&#20110;&#24494;&#35843; LLaMA &#27169;&#22411;&#65292;&#24471;&#21040;&#20102;&#26032;&#27169;&#22411; WizardLM&#12290;&#20154;&#31867;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126; Evol-Instruct &#29983;&#25104;&#30340;&#25351;&#20196;&#20248;&#20110;&#20154;&#24037;&#21019;&#24314;&#30340;&#65292;&#32780; WizardLM &#36755;&#20986;&#30340;&#32467;&#26524;&#20063;&#27604; OpenAI ChatGPT &#26356;&#21463;&#27426;&#36814;&#12290;</title><link>http://arxiv.org/abs/2304.12244</link><description>&lt;p&gt;
WizardLM: &#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36981;&#24490;&#22797;&#26434;&#25351;&#20196;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
WizardLM: Empowering Large Language Models to Follow Complex Instructions. (arXiv:2304.12244v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992; Evol-Instruct &#26041;&#27861;&#21019;&#24314;&#20102;&#22823;&#37327;&#19981;&#21516;&#22797;&#26434;&#24230;&#30340;&#25351;&#20196;&#25968;&#25454;&#29992;&#20110;&#24494;&#35843; LLaMA &#27169;&#22411;&#65292;&#24471;&#21040;&#20102;&#26032;&#27169;&#22411; WizardLM&#12290;&#20154;&#31867;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126; Evol-Instruct &#29983;&#25104;&#30340;&#25351;&#20196;&#20248;&#20110;&#20154;&#24037;&#21019;&#24314;&#30340;&#65292;&#32780; WizardLM &#36755;&#20986;&#30340;&#32467;&#26524;&#20063;&#27604; OpenAI ChatGPT &#26356;&#21463;&#27426;&#36814;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#24320;&#25918;&#22495;&#25351;&#20196;&#36861;&#36394;&#25968;&#25454;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#25163;&#21160;&#21019;&#24314;&#36825;&#26679;&#30340;&#25351;&#20196;&#25968;&#25454;&#38750;&#24120;&#32791;&#26102;&#21644;&#21171;&#21160;&#23494;&#38598;&#65292;&#19988;&#20154;&#31867;&#21487;&#33021;&#38590;&#20197;&#29983;&#25104;&#39640;&#22797;&#26434;&#24230;&#25351;&#20196;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;LLM&#32780;&#19981;&#26159;&#20154;&#31867;&#21019;&#24314;&#22823;&#37327;&#19981;&#21516;&#22797;&#26434;&#24230;&#25351;&#20196;&#25968;&#25454;&#30340;&#36884;&#24452;&#12290;&#25105;&#20204;&#20174;&#19968;&#32452;&#21021;&#22987;&#25351;&#20196;&#24320;&#22987;&#65292;&#20351;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;Evol-Instruct&#36880;&#27493;&#23558;&#20854;&#37325;&#26032;&#32534;&#20889;&#20026;&#26356;&#22797;&#26434;&#30340;&#25351;&#20196;&#12290;&#28982;&#21518;&#65292;&#23558;&#25152;&#26377;&#29983;&#25104;&#30340;&#25351;&#20196;&#25968;&#25454;&#28151;&#21512;&#20197;&#24494;&#35843;LLaMA&#12290;&#25105;&#20204;&#31216;&#32467;&#26524;&#27169;&#22411;&#20026;WizardLM&#12290;&#38024;&#23545;&#19968;&#20010;&#22797;&#26434;&#24230;&#24179;&#34913;&#30340;&#27979;&#35797;&#38598;&#21644;Vicuna&#30340;&#27979;&#35797;&#38598;&#36827;&#34892;&#30340;&#20154;&#31867;&#35780;&#20272;&#34920;&#26126;&#65292;Evol-Instruct&#29983;&#25104;&#30340;&#25351;&#20196;&#20248;&#20110;&#20154;&#24037;&#21019;&#24314;&#30340;&#25351;&#20196;&#12290;&#36890;&#36807;&#20998;&#26512;&#39640;&#22797;&#26434;&#24615;&#37096;&#20998;&#30340;&#20154;&#31867;&#35780;&#20272;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20174;&#25105;&#20204;&#30340;WizardLM&#29983;&#25104;&#30340;&#36755;&#20986;&#27604;&#20174;OpenAI ChatGPT&#29983;&#25104;&#30340;&#36755;&#20986;&#26356;&#21463;&#27426;&#36814;&#12290;&#22312;GPT-4&#33258;&#21160;&#35780;&#20272;&#20013;&#65292;WizardLM&#20135;&#29983;&#20102;&#26368;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation
&lt;/p&gt;</description></item></channel></rss>