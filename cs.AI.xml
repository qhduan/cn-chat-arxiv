<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#23545;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#22810;&#36873;&#39064;&#22238;&#31572;&#30340;&#21512;&#29702;&#24615;&#36827;&#34892;&#20102;&#22238;&#39038;&#65292;&#21457;&#29616;&#24403;&#21069;&#22522;&#20110;&#22810;&#36873;&#39064;&#22238;&#31572;&#30340;&#22522;&#20934;&#21487;&#33021;&#26080;&#27861;&#20805;&#20998;&#25429;&#25417;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#33021;&#21147;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01349</link><description>&lt;p&gt;
&#36229;&#36234;&#31572;&#26696;&#65306;&#23545;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#22810;&#36873;&#39064;&#22238;&#31572;&#30340;&#21512;&#29702;&#24615;&#30340;&#22238;&#39038;
&lt;/p&gt;
&lt;p&gt;
Beyond the Answers: Reviewing the Rationality of Multiple Choice Question Answering for the Evaluation of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01349
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#22810;&#36873;&#39064;&#22238;&#31572;&#30340;&#21512;&#29702;&#24615;&#36827;&#34892;&#20102;&#22238;&#39038;&#65292;&#21457;&#29616;&#24403;&#21069;&#22522;&#20110;&#22810;&#36873;&#39064;&#22238;&#31572;&#30340;&#22522;&#20934;&#21487;&#33021;&#26080;&#27861;&#20805;&#20998;&#25429;&#25417;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#21457;&#20102;&#19968;&#22330;&#33539;&#24335;&#36716;&#21464;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#23545;LLMs&#30340;&#20840;&#38754;&#35780;&#20272;&#20173;&#28982;&#26159;&#31038;&#21306;&#38754;&#20020;&#30340;&#24517;&#28982;&#25361;&#25112;&#12290;&#26368;&#36817;&#65292;&#23558;&#22810;&#36873;&#39064;&#22238;&#31572;&#65288;MCQA&#65289;&#20316;&#20026;LLMs&#30340;&#22522;&#20934;&#24050;&#32463;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;MCQA&#20316;&#20026;LLMs&#35780;&#20272;&#26041;&#27861;&#30340;&#21512;&#29702;&#24615;&#12290;&#22914;&#26524;LLMs&#30495;&#27491;&#29702;&#35299;&#38382;&#39064;&#30340;&#35821;&#20041;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#24212;&#35813;&#22312;&#20174;&#30456;&#21516;&#38382;&#39064;&#27966;&#29983;&#30340;&#21508;&#31181;&#37197;&#32622;&#19978;&#34920;&#29616;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;LLMs&#30340;&#21709;&#24212;&#19968;&#33268;&#24615;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#25105;&#20204;&#23558;&#20043;&#23450;&#20041;&#20026;LLMs&#30340;&#21709;&#24212;&#21487;&#21464;&#24615;&#32508;&#21512;&#24449;&#65288;REVAS&#65289;&#65292;&#36825;&#34920;&#26126;&#30446;&#21069;&#22522;&#20110;MCQA&#30340;&#22522;&#20934;&#21487;&#33021;&#26080;&#27861;&#20805;&#20998;&#25429;&#25417;LLMs&#30340;&#30495;&#23454;&#33021;&#21147;&#65292;&#24378;&#35843;&#20102;&#23545;&#26356;&#21512;&#36866;&#30340;&#35780;&#20272;&#26041;&#27861;&#30340;&#38656;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the field of natural language processing (NLP), Large Language Models (LLMs) have precipitated a paradigm shift, markedly enhancing performance in natural language generation tasks. Despite these advancements, the comprehensive evaluation of LLMs remains an inevitable challenge for the community. Recently, the utilization of Multiple Choice Question Answering (MCQA) as a benchmark for LLMs has gained considerable traction. This study investigates the rationality of MCQA as an evaluation method for LLMs. If LLMs genuinely understand the semantics of questions, their performance should exhibit consistency across the varied configurations derived from the same questions. Contrary to this expectation, our empirical findings suggest a notable disparity in the consistency of LLM responses, which we define as REsponse VAriability Syndrome (REVAS) of the LLMs, indicating that current MCQA-based benchmarks may not adequately capture the true capabilities of LLMs, which underscores the need f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#25913;&#36827;&#30340;&#28145;&#24230;&#21367;&#31215;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;(mDCGAN)&#65292;&#38024;&#23545;&#39640;&#36136;&#37327;&#33402;&#26415;&#21697;&#29983;&#25104;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#35299;&#20915;&#20102;&#26222;&#36941;&#35757;&#32451;&#38382;&#39064;&#65292;&#26377;&#25928;&#25506;&#32034;&#25277;&#35937;&#32472;&#30011;&#20013;&#30340;&#39068;&#33394;&#21644;&#31508;&#35302;&#27169;&#24335;&#12290;</title><link>https://arxiv.org/abs/2403.18397</link><description>&lt;p&gt;
&#20351;&#29992;&#25913;&#36827;&#30340;&#28145;&#24230;&#21367;&#31215;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#22312;&#25277;&#35937;&#33402;&#26415;&#20013;&#36827;&#34892;&#39068;&#33394;&#21644;&#31508;&#35302;&#27169;&#24335;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Colour and Brush Stroke Pattern Recognition in Abstract Art using Modified Deep Convolutional Generative Adversarial Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#25913;&#36827;&#30340;&#28145;&#24230;&#21367;&#31215;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;(mDCGAN)&#65292;&#38024;&#23545;&#39640;&#36136;&#37327;&#33402;&#26415;&#21697;&#29983;&#25104;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#35299;&#20915;&#20102;&#26222;&#36941;&#35757;&#32451;&#38382;&#39064;&#65292;&#26377;&#25928;&#25506;&#32034;&#25277;&#35937;&#32472;&#30011;&#20013;&#30340;&#39068;&#33394;&#21644;&#31508;&#35302;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25277;&#35937;&#33402;&#26415;&#26159;&#19968;&#31181;&#24191;&#21463;&#27426;&#36814;&#12289;&#34987;&#24191;&#27867;&#35752;&#35770;&#30340;&#33402;&#26415;&#24418;&#24335;&#65292;&#36890;&#24120;&#33021;&#22815;&#25551;&#32472;&#20986;&#33402;&#26415;&#23478;&#30340;&#24773;&#24863;&#12290;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#23581;&#35797;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#30340;&#36793;&#32536;&#26816;&#27979;&#12289;&#31508;&#35302;&#21644;&#24773;&#24863;&#35782;&#21035;&#31639;&#27861;&#26469;&#30740;&#31350;&#25277;&#35937;&#33402;&#26415;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#31070;&#32463;&#32593;&#32476;(GAN)&#23545;&#24191;&#27867;&#20998;&#24067;&#30340;&#25277;&#35937;&#32472;&#30011;&#36827;&#34892;&#30740;&#31350;&#12290; GAN&#20855;&#26377;&#23398;&#20064;&#21644;&#20877;&#29616;&#20998;&#24067;&#30340;&#33021;&#21147;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#26377;&#25928;&#22320;&#25506;&#32034;&#21644;&#30740;&#31350;&#29983;&#25104;&#30340;&#22270;&#20687;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#25361;&#25112;&#22312;&#20110;&#24320;&#21457;&#19968;&#31181;&#33021;&#22815;&#20811;&#26381;&#24120;&#35265;&#35757;&#32451;&#38382;&#39064;&#30340;&#39640;&#25928;GAN&#26550;&#26500;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#39640;&#36136;&#37327;&#33402;&#26415;&#21697;&#29983;&#25104;&#30340;&#25913;&#36827;DCGAN(mDCGAN)&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#23545;&#25152;&#20570;&#20462;&#25913;&#30340;&#28145;&#20837;&#25506;&#35752;&#65292;&#28145;&#20837;&#30740;&#31350;DCGAN&#30340;&#22797;&#26434;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18397v1 Announce Type: cross  Abstract: Abstract Art is an immensely popular, discussed form of art that often has the ability to depict the emotions of an artist. Many researchers have made attempts to study abstract art in the form of edge detection, brush stroke and emotion recognition algorithms using machine and deep learning. This papers describes the study of a wide distribution of abstract paintings using Generative Adversarial Neural Networks(GAN). GANs have the ability to learn and reproduce a distribution enabling researchers and scientists to effectively explore and study the generated image space. However, the challenge lies in developing an efficient GAN architecture that overcomes common training pitfalls. This paper addresses this challenge by introducing a modified-DCGAN (mDCGAN) specifically designed for high-quality artwork generation. The approach involves a thorough exploration of the modifications made, delving into the intricate workings of DCGANs, opt
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#24322;&#36136;&#20132;&#20114;&#35780;&#20998;&#32593;&#32476;&#65288;HIRE&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#24322;&#36136;&#20132;&#20114;&#27169;&#22359;&#65288;HIM&#65289;&#26469;&#20849;&#21516;&#24314;&#27169;&#24322;&#36136;&#20132;&#20114;&#24182;&#30452;&#25509;&#25512;&#26029;&#37325;&#35201;&#29305;&#24449;</title><link>https://arxiv.org/abs/2403.17740</link><description>&lt;p&gt;
&#19968;&#20307;&#21270;&#65306;&#24322;&#36136;&#20132;&#20114;&#24314;&#27169;&#29992;&#20110;&#20919;&#21551;&#21160;&#35780;&#20998;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
All-in-One: Heterogeneous Interaction Modeling for Cold-Start Rating Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17740
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#24322;&#36136;&#20132;&#20114;&#35780;&#20998;&#32593;&#32476;&#65288;HIRE&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#24322;&#36136;&#20132;&#20114;&#27169;&#22359;&#65288;HIM&#65289;&#26469;&#20849;&#21516;&#24314;&#27169;&#24322;&#36136;&#20132;&#20114;&#24182;&#30452;&#25509;&#25512;&#26029;&#37325;&#35201;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20919;&#21551;&#21160;&#35780;&#20998;&#39044;&#27979;&#26159;&#25512;&#33616;&#31995;&#32479;&#20013;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#24050;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#35768;&#22810;&#26041;&#27861;&#24050;&#32463;&#34987;&#25552;&#20986;&#65292;&#21033;&#29992;&#29616;&#26377;&#25968;&#25454;&#20043;&#38388;&#30340;&#26174;&#24335;&#20851;&#31995;&#65292;&#20363;&#22914;&#21327;&#21516;&#36807;&#28388;&#12289;&#31038;&#20132;&#25512;&#33616;&#21644;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#65292;&#20197;&#32531;&#35299;&#20919;&#21551;&#21160;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#25968;&#25454;&#19981;&#36275;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#19981;&#21516;&#35282;&#33394;&#20043;&#38388;&#30340;&#25968;&#25454;&#26500;&#24314;&#30340;&#26174;&#24335;&#20851;&#31995;&#21487;&#33021;&#19981;&#21487;&#38752;&#19988;&#26080;&#20851;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#29305;&#23450;&#25512;&#33616;&#20219;&#21153;&#30340;&#24615;&#33021;&#19978;&#38480;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;&#24322;&#36136;&#20132;&#20114;&#35780;&#20998;&#32593;&#32476;&#65288;HIRE&#65289;&#12290;HIRE&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#39044;&#20808;&#23450;&#20041;&#30340;&#20132;&#20114;&#27169;&#24335;&#25110;&#25163;&#21160;&#26500;&#24314;&#30340;&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#24322;&#36136;&#20132;&#20114;&#27169;&#22359;&#65288;HIM&#65289;&#65292;&#26469;&#20849;&#21516;&#24314;&#27169;&#24322;&#36136;&#20132;&#20114;&#24182;&#30452;&#25509;&#25512;&#26029;&#37325;&#35201;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17740v1 Announce Type: cross  Abstract: Cold-start rating prediction is a fundamental problem in recommender systems that has been extensively studied. Many methods have been proposed that exploit explicit relations among existing data, such as collaborative filtering, social recommendations and heterogeneous information network, to alleviate the data insufficiency issue for cold-start users and items. However, the explicit relations constructed based on data between different roles may be unreliable and irrelevant, which limits the performance ceiling of the specific recommendation task. Motivated by this, in this paper, we propose a flexible framework dubbed heterogeneous interaction rating network (HIRE). HIRE dose not solely rely on the pre-defined interaction pattern or the manually constructed heterogeneous information network. Instead, we devise a Heterogeneous Interaction Module (HIM) to jointly model the heterogeneous interactions and directly infer the important in
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22270;&#19978;&#23398;&#20064;&#30340;&#31616;&#21333;&#26367;&#20195;&#26041;&#27861;&#65292;&#31216;&#20026;&#25513;&#30721;&#27880;&#24847;&#21147;&#65288;MAG&#65289;&#65292;&#20854;&#21033;&#29992;&#27880;&#24847;&#21147;&#30697;&#38453;&#26469;&#21019;&#24314;&#23450;&#21046;&#30340;&#27880;&#24847;&#21147;&#27169;&#24335;&#65292;&#22312;&#38271;&#36317;&#31163;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#24182;&#32988;&#36807;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10793</link><description>&lt;p&gt;
&#25513;&#30721;&#27880;&#24847;&#21147;&#26159;&#22270;&#30340;&#20851;&#38190;
&lt;/p&gt;
&lt;p&gt;
Masked Attention is All You Need for Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10793
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22270;&#19978;&#23398;&#20064;&#30340;&#31616;&#21333;&#26367;&#20195;&#26041;&#27861;&#65292;&#31216;&#20026;&#25513;&#30721;&#27880;&#24847;&#21147;&#65288;MAG&#65289;&#65292;&#20854;&#21033;&#29992;&#27880;&#24847;&#21147;&#30697;&#38453;&#26469;&#21019;&#24314;&#23450;&#21046;&#30340;&#27880;&#24847;&#21147;&#27169;&#24335;&#65292;&#22312;&#38271;&#36317;&#31163;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#24182;&#32988;&#36807;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#21644;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#30340;&#21464;&#31181;&#20027;&#35201;&#29992;&#20110;&#22312;&#22270;&#19978;&#23398;&#20064;&#65292;&#36825;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24402;&#21151;&#20110;&#23427;&#20204;&#30340;&#28789;&#27963;&#24615;&#12289;&#36895;&#24230;&#21644;&#20196;&#20154;&#28385;&#24847;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#35774;&#35745;&#24378;&#22823;&#32780;&#36890;&#29992;&#30340;GNNs&#38656;&#35201;&#22823;&#37327;&#30340;&#30740;&#31350;&#24037;&#20316;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#31934;&#24515;&#36873;&#25321;&#30340;&#25163;&#24037;&#21046;&#20316;&#30340;&#28040;&#24687;&#20256;&#36882;&#25805;&#20316;&#31526;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22270;&#19978;&#23398;&#20064;&#30340;&#38750;&#24120;&#31616;&#21333;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#23427;&#23436;&#20840;&#20381;&#36182;&#20110;&#27880;&#24847;&#21147;&#12290;&#22270;&#34987;&#34920;&#31034;&#20026;&#33410;&#28857;&#25110;&#36793;&#38598;&#65292;&#24182;&#36890;&#36807;&#25513;&#30721;&#27880;&#24847;&#26435;&#37325;&#30697;&#38453;&#26469;&#24378;&#21046;&#23427;&#20204;&#30340;&#36830;&#25509;&#65292;&#26377;&#25928;&#22320;&#20026;&#27599;&#20010;&#22270;&#21019;&#24314;&#23450;&#21046;&#30340;&#27880;&#24847;&#21147;&#27169;&#24335;&#12290;&#23613;&#31649;&#20854;&#31616;&#21333;&#24615;&#65292;&#29992;&#20110;&#22270;&#30340;&#25513;&#30721;&#27880;&#24847;&#21147;&#65288;MAG&#65289;&#22312;&#38271;&#36317;&#31163;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#22312;55&#22810;&#20010;&#33410;&#28857;&#21644;&#22270;&#32423;&#20219;&#21153;&#19978;&#20248;&#20110;&#24378;&#28040;&#24687;&#20256;&#36882;&#22522;&#32447;&#21644;&#26356;&#22797;&#26434;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10793v1 Announce Type: cross  Abstract: Graph neural networks (GNNs) and variations of the message passing algorithm are the predominant means for learning on graphs, largely due to their flexibility, speed, and satisfactory performance. The design of powerful and general purpose GNNs, however, requires significant research efforts and often relies on handcrafted, carefully-chosen message passing operators. Motivated by this, we propose a remarkably simple alternative for learning on graphs that relies exclusively on attention. Graphs are represented as node or edge sets and their connectivity is enforced by masking the attention weight matrix, effectively creating custom attention patterns for each graph. Despite its simplicity, masked attention for graphs (MAG) has state-of-the-art performance on long-range tasks and outperforms strong message passing baselines and much more involved attention-based methods on over 55 node and graph-level tasks. We also show significantly 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;SimMLP&#65292;&#36890;&#36807;&#22312;&#22270;&#19978;&#26080;&#30417;&#30563;&#23398;&#20064;MLPs&#65292;&#25552;&#39640;&#20102;&#22312;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.08918</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#22312;&#22270;&#19978;&#23398;&#20064;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#21152;&#36895;&#22270;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Graph Inference Acceleration by Learning MLPs on Graphs without Supervision
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08918
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;SimMLP&#65292;&#36890;&#36807;&#22312;&#22270;&#19978;&#26080;&#30417;&#30563;&#23398;&#20064;MLPs&#65292;&#25552;&#39640;&#20102;&#22312;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24050;&#32463;&#22312;&#21508;&#31181;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20102;&#26377;&#25928;&#24615;&#65292;&#20294;&#26159;&#23427;&#20204;&#23545;&#28040;&#24687;&#20256;&#36882;&#30340;&#20381;&#36182;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#30340;&#37096;&#32626;&#65292;&#27604;&#22914;&#37329;&#34701;&#27450;&#35784;&#26816;&#27979;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#20174;GNNs&#20013;&#25552;&#21462;&#30693;&#35782;&#21040;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLPs&#65289;&#26469;&#21152;&#36895;&#25512;&#29702;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20219;&#21153;&#29305;&#23450;&#30340;&#26377;&#30417;&#30563;&#33976;&#39311;&#38480;&#21046;&#20102;&#23545;&#26410;&#35265;&#33410;&#28857;&#30340;&#27867;&#21270;&#65292;&#32780;&#22312;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#36825;&#31181;&#24773;&#20917;&#24456;&#24120;&#35265;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;SimMLP&#65292;&#29992;&#20110;&#22312;&#22270;&#19978;&#26080;&#30417;&#30563;&#23398;&#20064;MLPs&#65292;&#20197;&#22686;&#24378;&#27867;&#21270;&#33021;&#21147;&#12290;SimMLP&#21033;&#29992;&#33258;&#30417;&#30563;&#23545;&#40784;GNNs&#21644;MLPs&#20043;&#38388;&#30340;&#33410;&#28857;&#29305;&#24449;&#21644;&#22270;&#32467;&#26500;&#20043;&#38388;&#30340;&#31934;&#32454;&#21644;&#27867;&#21270;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#26469;&#20943;&#36731;&#24179;&#20961;&#35299;&#30340;&#39118;&#38505;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08918v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) have demonstrated effectiveness in various graph learning tasks, yet their reliance on message-passing constraints their deployment in latency-sensitive applications such as financial fraud detection. Recent works have explored distilling knowledge from GNNs to Multi-Layer Perceptrons (MLPs) to accelerate inference. However, this task-specific supervised distillation limits generalization to unseen nodes, which are prevalent in latency-sensitive applications. To this end, we present \textbf{\textsc{SimMLP}}, a \textbf{\textsc{Sim}}ple yet effective framework for learning \textbf{\textsc{MLP}}s on graphs without supervision, to enhance generalization. \textsc{SimMLP} employs self-supervised alignment between GNNs and MLPs to capture the fine-grained and generalizable correlation between node features and graph structures, and proposes two strategies to alleviate the risk of trivial solutions. Theoretically, w
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;PAC&#38544;&#31169;&#20445;&#25252;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#31169;&#26377;&#20998;&#31867;&#22120;&#25351;&#23548;&#38598;&#25104;&#21040;&#37319;&#26679;&#36807;&#31243;&#20013;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#65292;&#24182;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#34913;&#37327;&#38544;&#31169;&#27700;&#24179;&#65292;&#22312;&#20445;&#25252;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#21331;&#36234;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2312.01201</link><description>&lt;p&gt;
PAC&#38544;&#31169;&#20445;&#25252;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
PAC Privacy Preserving Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.01201
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;PAC&#38544;&#31169;&#20445;&#25252;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#31169;&#26377;&#20998;&#31867;&#22120;&#25351;&#23548;&#38598;&#25104;&#21040;&#37319;&#26679;&#36807;&#31243;&#20013;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#65292;&#24182;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#34913;&#37327;&#38544;&#31169;&#27700;&#24179;&#65292;&#22312;&#20445;&#25252;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#21331;&#36234;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#38544;&#31169;&#20445;&#25252;&#27491;&#22312;&#24341;&#36215;&#30740;&#31350;&#20154;&#21592;&#30340;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#25193;&#25955;&#27169;&#22411;&#65288;DMs&#65289;&#65292;&#23588;&#20854;&#26159;&#20855;&#26377;&#20005;&#26684;&#30340;&#24046;&#20998;&#38544;&#31169;&#65292;&#26377;&#21487;&#33021;&#29983;&#25104;&#26082;&#20855;&#26377;&#39640;&#38544;&#31169;&#24615;&#21448;&#20855;&#26377;&#33391;&#22909;&#35270;&#35273;&#36136;&#37327;&#30340;&#22270;&#20687;&#12290;&#28982;&#32780;&#65292;&#25361;&#25112;&#22312;&#20110;&#30830;&#20445;&#22312;&#31169;&#26377;&#21270;&#29305;&#23450;&#25968;&#25454;&#23646;&#24615;&#26102;&#30340;&#24378;&#22823;&#20445;&#25252;&#65292;&#24403;&#21069;&#27169;&#22411;&#22312;&#36825;&#20123;&#26041;&#38754;&#32463;&#24120;&#23384;&#22312;&#19981;&#36275;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;PAC&#38544;&#31169;&#20445;&#25252;&#25193;&#25955;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#31181;&#21033;&#29992;&#25193;&#25955;&#21407;&#29702;&#24182;&#30830;&#20445;&#8220;&#21487;&#33021;&#22823;&#33268;&#27491;&#30830;&#65288;PAC&#65289;&#8221;&#38544;&#31169;&#24615;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#31169;&#26377;&#20998;&#31867;&#22120;&#25351;&#23548;&#38598;&#25104;&#21040;Langevin&#37319;&#26679;&#36807;&#31243;&#20013;&#26469;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#12290;&#27492;&#22806;&#65292;&#35748;&#35782;&#21040;&#22312;&#34913;&#37327;&#27169;&#22411;&#38544;&#31169;&#24615;&#26041;&#38754;&#23384;&#22312;&#24046;&#36317;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#34913;&#37327;&#38544;&#31169;&#27700;&#24179;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#36890;&#36807;&#36825;&#20010;&#26032;&#24230;&#37327;&#26631;&#20934;&#35780;&#20272;&#65292;&#24182;&#36890;&#36807;&#39640;&#26031;&#30697;&#38453;&#35745;&#31639;&#25903;&#25345;PAC&#30028;&#38480;&#65292;&#34920;&#29616;&#20986;&#26356;&#20248;&#24322;&#30340;&#38544;&#31169;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.01201v2 Announce Type: replace-cross  Abstract: Data privacy protection is garnering increased attention among researchers. Diffusion models (DMs), particularly with strict differential privacy, can potentially produce images with both high privacy and visual quality. However, challenges arise such as in ensuring robust protection in privatizing specific data attributes, areas where current models often fall short. To address these challenges, we introduce the PAC Privacy Preserving Diffusion Model, a model leverages diffusion principles and ensure Probably Approximately Correct (PAC) privacy. We enhance privacy protection by integrating a private classifier guidance into the Langevin Sampling Process. Additionally, recognizing the gap in measuring the privacy of models, we have developed a novel metric to gauge privacy levels. Our model, assessed with this new metric and supported by Gaussian matrix computations for the PAC bound, has shown superior performance in privacy p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#29305;&#24449;&#20998;&#24067;&#20559;&#26012;&#30340;&#32852;&#37030;&#23398;&#20064;&#25552;&#20986;&#20102;FedRDN&#26041;&#27861;&#65292;&#22312;&#36755;&#20837;&#23618;&#32423;&#19978;&#23454;&#29616;&#20102;&#25968;&#25454;&#22686;&#24378;&#65292;&#23558;&#25972;&#20010;&#32852;&#37030;&#25968;&#25454;&#38598;&#30340;&#32479;&#35745;&#20449;&#24687;&#27880;&#20837;&#21040;&#26412;&#22320;&#23458;&#25143;&#31471;&#25968;&#25454;&#20013;&#65292;&#20197;&#32531;&#35299;&#29305;&#24449;&#28418;&#31227;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.09363</link><description>&lt;p&gt;
&#19968;&#31181;&#31616;&#21333;&#30340;&#38754;&#21521;&#29305;&#24449;&#20998;&#24067;&#20559;&#26012;&#32852;&#37030;&#23398;&#20064;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Simple Data Augmentation for Feature Distribution Skewed Federated Learning. (arXiv:2306.09363v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09363
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#29305;&#24449;&#20998;&#24067;&#20559;&#26012;&#30340;&#32852;&#37030;&#23398;&#20064;&#25552;&#20986;&#20102;FedRDN&#26041;&#27861;&#65292;&#22312;&#36755;&#20837;&#23618;&#32423;&#19978;&#23454;&#29616;&#20102;&#25968;&#25454;&#22686;&#24378;&#65292;&#23558;&#25972;&#20010;&#32852;&#37030;&#25968;&#25454;&#38598;&#30340;&#32479;&#35745;&#20449;&#24687;&#27880;&#20837;&#21040;&#26412;&#22320;&#23458;&#25143;&#31471;&#25968;&#25454;&#20013;&#65292;&#20197;&#32531;&#35299;&#29305;&#24449;&#28418;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#20998;&#24067;&#24335;&#21327;&#20316;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#30830;&#20445;&#38544;&#31169;&#20445;&#25252;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#24322;&#26500;&#24615;&#65288;&#21363;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65289;&#65292;&#23427;&#30340;&#24615;&#33021;&#24517;&#28982;&#21463;&#21040;&#24433;&#21709;&#12290;&#26412;&#25991;&#38024;&#23545;&#29305;&#24449;&#20998;&#24067;&#20559;&#26012;&#30340;FL&#22330;&#26223;&#23637;&#24320;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#20197;&#20943;&#36731;&#30001;&#26412;&#22320;&#25968;&#25454;&#38598;&#20043;&#38388;&#28508;&#22312;&#20998;&#24067;&#19981;&#21516;&#23548;&#33268;&#30340;&#29305;&#24449;&#28418;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) facilitates collaborative learning among multiple clients in a distributed manner, while ensuring privacy protection. However, its performance is inevitably degraded as suffering data heterogeneity, i.e., non-IID data. In this paper, we focus on the feature distribution skewed FL scenario, which is widespread in real-world applications. The main challenge lies in the feature shift caused by the different underlying distributions of local datasets. While the previous attempts achieved progress, few studies pay attention to the data itself, the root of this issue. Therefore, the primary goal of this paper is to develop a general data augmentation technique at the input level, to mitigate the feature shift. To achieve this goal, we propose FedRDN, a simple yet remarkably effective data augmentation method for feature distribution skewed FL, which randomly injects the statistics of the dataset from the entire federation into the client's data. By this, our method ca
&lt;/p&gt;</description></item></channel></rss>