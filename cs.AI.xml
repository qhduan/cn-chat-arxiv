<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#22810;&#29983;&#25104;&#20195;&#29702;&#31995;&#32479;&#22312;&#22478;&#24066;&#35268;&#21010;&#20013;&#27169;&#25311;&#31038;&#21306;&#20915;&#31574;&#65292;&#21457;&#29616;&#27807;&#36890;&#26377;&#21161;&#20110;&#38598;&#20307;&#25512;&#29702;&#65292;&#32780;&#21253;&#21547;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#21644;&#29983;&#27963;&#20215;&#20540;&#23548;&#33268;&#24847;&#35265;&#20998;&#27495;&#12290;&#36825;&#20026;&#22478;&#24066;&#35268;&#21010;&#21644;&#31038;&#21306;&#21442;&#19982;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.11314</link><description>&lt;p&gt;
&#22810;&#29983;&#25104;&#20195;&#29702;&#38598;&#20307;&#20915;&#31574;&#22312;&#22478;&#24066;&#35268;&#21010;&#20013;&#30340;&#24212;&#29992;&#65306;Kendall Square&#25913;&#36896;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multi-Generative Agent Collective Decision-Making in Urban Planning: A Case Study for Kendall Square Renovation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11314
&lt;/p&gt;
&lt;p&gt;
&#22810;&#29983;&#25104;&#20195;&#29702;&#31995;&#32479;&#22312;&#22478;&#24066;&#35268;&#21010;&#20013;&#27169;&#25311;&#31038;&#21306;&#20915;&#31574;&#65292;&#21457;&#29616;&#27807;&#36890;&#26377;&#21161;&#20110;&#38598;&#20307;&#25512;&#29702;&#65292;&#32780;&#21253;&#21547;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#21644;&#29983;&#27963;&#20215;&#20540;&#23548;&#33268;&#24847;&#35265;&#20998;&#27495;&#12290;&#36825;&#20026;&#22478;&#24066;&#35268;&#21010;&#21644;&#31038;&#21306;&#21442;&#19982;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22810;&#29983;&#25104;&#20195;&#29702;&#31995;&#32479;&#65292;&#29992;&#20110;&#27169;&#25311; Kendall Square Volpe &#22823;&#21414;&#25913;&#36896;&#30340;&#31038;&#21306;&#20915;&#31574;&#36807;&#31243;&#12290;&#36890;&#36807;&#19982;&#24403;&#22320;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#35775;&#35848;&#65292;&#25105;&#20204;&#30340;&#27169;&#25311;&#32467;&#21512;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#27807;&#36890;&#12289;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#21644;&#29983;&#27963;&#20215;&#20540;&#22312;&#20195;&#29702;&#25552;&#31034;&#20013;&#30340;&#24212;&#29992;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#20195;&#29702;&#20043;&#38388;&#30340;&#27807;&#36890;&#25913;&#21892;&#20102;&#38598;&#20307;&#25512;&#29702;&#65292;&#32780;&#21253;&#21547;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#21644;&#29983;&#27963;&#20215;&#20540;&#23548;&#33268;&#20102;&#26356;&#26126;&#26174;&#30340;&#24847;&#35265;&#20998;&#27495;&#12290;&#36825;&#20123;&#21457;&#29616;&#20984;&#26174;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#29702;&#35299;&#22797;&#26434;&#31038;&#20250;&#20114;&#21160;&#21644;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#28508;&#22312;&#24212;&#29992;&#65292;&#20026;&#22478;&#24066;&#35268;&#21010;&#21644; Kendall Square &#31561;&#22810;&#26679;&#21270;&#29615;&#22659;&#20013;&#30340;&#31038;&#21306;&#21442;&#19982;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11314v1 Announce Type: cross  Abstract: In this study, we develop a multiple-generative agent system to simulate community decision-making for the redevelopment of Kendall Square's Volpe building. Drawing on interviews with local stakeholders, our simulations incorporated varying degrees of communication, demographic data, and life values in the agent prompts. The results revealed that communication among agents improved collective reasoning, while the inclusion of demographic and life values led to more distinct opinions. These findings highlight the potential application of AI in understanding complex social interactions and decision-making processes, offering valuable insights for urban planning and community engagement in diverse settings like Kendall Square.
&lt;/p&gt;</description></item><item><title>&#35780;&#20272;&#20102;&#20061;&#20010;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#21457;&#29616;&#20854;&#20013;80&#65285;&#21253;&#21547;&#35760;&#24518;&#25968;&#25454;&#65292;&#20294;&#21253;&#21547;&#26368;&#22810;&#35760;&#24518;&#20869;&#23481;&#30340;&#36755;&#20986;&#26356;&#21487;&#33021;&#26159;&#39640;&#36136;&#37327;&#30340;&#12290;&#25552;&#20986;&#20102;&#32531;&#35299;&#31574;&#30053;&#20197;&#38477;&#20302;&#35760;&#24518;&#25991;&#26412;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.08637</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36755;&#20986;&#30340;&#35780;&#20272;&#65306;&#35805;&#35821;&#21644;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
An Evaluation on Large Language Model Outputs: Discourse and Memorization. (arXiv:2304.08637v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08637
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#20102;&#20061;&#20010;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#21457;&#29616;&#20854;&#20013;80&#65285;&#21253;&#21547;&#35760;&#24518;&#25968;&#25454;&#65292;&#20294;&#21253;&#21547;&#26368;&#22810;&#35760;&#24518;&#20869;&#23481;&#30340;&#36755;&#20986;&#26356;&#21487;&#33021;&#26159;&#39640;&#36136;&#37327;&#30340;&#12290;&#25552;&#20986;&#20102;&#32531;&#35299;&#31574;&#30053;&#20197;&#38477;&#20302;&#35760;&#24518;&#25991;&#26412;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#20061;&#20010;&#26368;&#24191;&#27867;&#21487;&#29992;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#30340;&#21508;&#31181;&#36755;&#20986;&#36827;&#34892;&#20102;&#32463;&#39564;&#24615;&#35780;&#20272;&#12290;&#25105;&#20204;&#20351;&#29992;&#29616;&#25104;&#30340;&#24037;&#20855;&#36827;&#34892;&#20998;&#26512;&#65292;&#21457;&#29616;&#22312;&#19982;&#36755;&#20986;&#30149;&#24577;&#65288;&#20363;&#22914;&#65292;&#21453;&#20107;&#23454;&#21644;&#36923;&#36753;&#19978;&#30340;&#38169;&#35823;&#38472;&#36848;&#65289;&#20197;&#21450;&#19981;&#20445;&#25345;&#20027;&#39064;&#31561;&#26041;&#38754;&#30340;&#20851;&#31995;&#20013;&#65292;&#35760;&#24518;&#25991;&#26412;&#30334;&#20998;&#27604;&#12289;&#29420;&#29305;&#25991;&#26412;&#30334;&#20998;&#27604;&#21644;&#25972;&#20307;&#36755;&#20986;&#36136;&#37327;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;80.0&#65285;&#30340;&#36755;&#20986;&#21253;&#21547;&#35760;&#24518;&#25968;&#25454;&#65292;&#20294;&#21253;&#21547;&#26368;&#22810;&#35760;&#24518;&#20869;&#23481;&#30340;&#36755;&#20986;&#20063;&#26356;&#26377;&#21487;&#33021;&#34987;&#35748;&#20026;&#20855;&#26377;&#39640;&#36136;&#37327;&#12290;&#25105;&#20204;&#35752;&#35770;&#21644;&#35780;&#20272;&#20102;&#32531;&#35299;&#31574;&#30053;&#65292;&#24182;&#26174;&#31034;&#65292;&#22312;&#35780;&#20272;&#30340;&#27169;&#22411;&#20013;&#65292;&#36755;&#20986;&#30340;&#35760;&#24518;&#25991;&#26412;&#29575;&#26377;&#25152;&#38477;&#20302;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23601;&#23398;&#20064;&#12289;&#35760;&#24518;&#21644;&#35780;&#20272;&#20248;&#36136;&#25991;&#26412;&#30340;&#28508;&#22312;&#24433;&#21709;&#36827;&#34892;&#20102;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an empirical evaluation of various outputs generated by nine of the most widely-available large language models (LLMs). Our analysis is done with off-the-shelf, readily-available tools. We find a correlation between percentage of memorized text, percentage of unique text, and overall output quality, when measured with respect to output pathologies such as counterfactual and logically-flawed statements, and general failures like not staying on topic. Overall, 80.0% of the outputs evaluated contained memorized data, but outputs containing the most memorized content were also more likely to be considered of high quality. We discuss and evaluate mitigation strategies, showing that, in the models evaluated, the rate of memorized text being output is reduced. We conclude with a discussion on potential implications around what it means to learn, to memorize, and to evaluate quality text.
&lt;/p&gt;</description></item></channel></rss>