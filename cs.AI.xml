<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#30340;&#27169;&#22411;&#39044;&#27979;&#26041;&#27861;&#26377;&#21161;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#30340;&#31574;&#30053;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.13213</link><description>&lt;p&gt;
&#36719;&#26368;&#22823;&#27010;&#29575;&#65288;&#22823;&#37096;&#20998;&#26102;&#20505;&#65289;&#22312;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#39044;&#27979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27491;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Softmax Probabilities (Mostly) Predict Large Language Model Correctness on Multiple-Choice Q&amp;A
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13213
&lt;/p&gt;
&lt;p&gt;
&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#30340;&#27169;&#22411;&#39044;&#27979;&#26041;&#27861;&#26377;&#21161;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#30340;&#31574;&#30053;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#36807;&#24230;&#33258;&#20449;&#20173;&#28982;&#26159;&#19968;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#35774;&#22312;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#38169;&#35823;&#31572;&#26696;&#23558;&#19982;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#36739;&#23567;&#30456;&#20851;&#65292;&#30456;&#27604;&#20043;&#19979;&#27491;&#30830;&#31572;&#26696;&#36739;&#22823;&#12290;&#25105;&#20204;&#22312;&#21313;&#20010;&#24320;&#28304;LLMs&#21644;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#20840;&#38754;&#35780;&#20272;&#20102;&#36825;&#19968;&#20551;&#35774;&#65292;&#22312;&#34920;&#29616;&#33391;&#22909;&#30340;&#21407;&#22987;&#38382;&#31572;&#20219;&#21153;&#20013;&#21457;&#29616;&#20102;&#23545;&#25105;&#20204;&#20551;&#35774;&#30340;&#24378;&#26377;&#21147;&#35777;&#25454;&#12290;&#23545;&#20110;&#34920;&#29616;&#26368;&#20339;&#30340;&#20845;&#20010;LLMs&#65292;&#20174;MSP&#23548;&#20986;&#30340;AUROC&#22312;59/60&#20010;&#23454;&#20363;&#20013;&#37117;&#20248;&#20110;&#38543;&#26426;&#26426;&#20250;&#65292;p &lt; 10^{-4}&#12290;&#22312;&#36825;&#20845;&#20010;LLMs&#20013;&#65292;&#24179;&#22343;AUROC&#33539;&#22260;&#22312;60%&#33267;69%&#20043;&#38388;&#12290;&#21033;&#29992;&#36825;&#20123;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#24323;&#26435;&#36873;&#39033;&#30340;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#36890;&#36807;&#26681;&#25454;&#21021;&#22987;&#27169;&#22411;&#21709;&#24212;&#30340;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#29992;&#39044;softmax logits&#32780;&#19981;&#26159;softmax&#36827;&#34892;&#20102;&#30456;&#21516;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13213v1 Announce Type: cross  Abstract: Although large language models (LLMs) perform impressively on many tasks, overconfidence remains a problem. We hypothesized that on multiple-choice Q&amp;A tasks, wrong answers would be associated with smaller maximum softmax probabilities (MSPs) compared to correct answers. We comprehensively evaluate this hypothesis on ten open-source LLMs and five datasets, and find strong evidence for our hypothesis among models which perform well on the original Q&amp;A task. For the six LLMs with the best Q&amp;A performance, the AUROC derived from the MSP was better than random chance with p &lt; 10^{-4} in 59/60 instances. Among those six LLMs, the average AUROC ranged from 60% to 69%. Leveraging these findings, we propose a multiple-choice Q&amp;A task with an option to abstain and show that performance can be improved by selectively abstaining based on the MSP of the initial model response. We also run the same experiments with pre-softmax logits instead of sof
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26680;&#25197;&#26354;&#20989;&#25968;&#23545;Mixup&#25968;&#25454;&#36827;&#34892;&#20010;&#24615;&#21270;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#26469;&#23454;&#29616;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#30456;&#20284;&#25968;&#25454;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#65292;&#36824;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01434</link><description>&lt;p&gt;
&#36890;&#36807;&#26680;&#25197;&#26354;&#20989;&#25968;&#23450;&#21046;Mixup&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Tailoring Mixup to Data using Kernel Warping functions. (arXiv:2311.01434v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26680;&#25197;&#26354;&#20989;&#25968;&#23545;Mixup&#25968;&#25454;&#36827;&#34892;&#20010;&#24615;&#21270;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#26469;&#23454;&#29616;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#30456;&#20284;&#25968;&#25454;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#65292;&#36824;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#26159;&#23398;&#20064;&#39640;&#25928;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#37325;&#35201;&#22522;&#30784;&#12290;&#22312;&#25152;&#26377;&#25552;&#20986;&#30340;&#22686;&#24378;&#25216;&#26415;&#20013;&#65292;&#32447;&#24615;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#28857;&#65288;&#20063;&#31216;&#20026;Mixup&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#36873;&#25321;&#21512;&#36866;&#30340;&#28857;&#36827;&#34892;&#28151;&#21512;&#65292;&#25110;&#32773;&#24212;&#29992;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#25554;&#20540;&#65292;&#32780;&#25105;&#20204;&#21017;&#23545;&#26356;&#30456;&#20284;&#30340;&#28857;&#36827;&#34892;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#24863;&#20852;&#36259;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#25197;&#26354;&#20989;&#25968;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#21462;&#20915;&#20110;&#35201;&#32452;&#21512;&#30340;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#39640;&#25928;&#32780;&#28789;&#27963;&#30340;&#26694;&#26550;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#20197;&#36991;&#20813;&#22810;&#26679;&#24615;&#30340;&#25439;&#22833;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26082;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21448;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/ENSTA-U2IS/torch-uncertainty&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data augmentation is an essential building block for learning efficient deep learning models. Among all augmentation techniques proposed so far, linear interpolation of training data points, also called mixup, has found to be effective for a large panel of applications. While the majority of works have focused on selecting the right points to mix, or applying complex non-linear interpolation, we are interested in mixing similar points more frequently and strongly than less similar ones. To this end, we propose to dynamically change the underlying distribution of interpolation coefficients through warping functions, depending on the similarity between data points to combine. We define an efficient and flexible framework to do so without losing in diversity. We provide extensive experiments for classification and regression tasks, showing that our proposed method improves both performance and calibration of models. Code available in https://github.com/ENSTA-U2IS/torch-uncertainty
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#24110;&#21161;&#25237;&#36164;&#32773;&#25581;&#31034;&#20225;&#19994;&#39118;&#38505;&#30340;&#20215;&#20540;&#65292;&#36890;&#36807;&#20174;&#25910;&#30410;&#30005;&#35805;&#30340;&#19978;&#19979;&#25991;&#20013;&#29983;&#25104;&#39118;&#38505;&#25688;&#35201;&#21644;&#35780;&#20272;&#65292;&#36825;&#20123;&#22522;&#20110;GPT&#30340;&#24230;&#37327;&#20855;&#26377;&#26174;&#33879;&#30340;&#20449;&#24687;&#20869;&#23481;&#65292;&#33021;&#22815;&#39044;&#27979;&#20225;&#19994;&#23618;&#38754;&#27874;&#21160;&#24615;&#21644;&#25237;&#36164;&#21019;&#26032;&#36873;&#25321;&#12290;&#27492;&#22806;&#65292;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#36824;&#33021;&#26377;&#25928;&#26816;&#27979;&#26032;&#20852;&#39118;&#38505;&#65292;&#24182;&#19988;&#36825;&#20123;&#24230;&#37327;&#22312;&#32929;&#26435;&#24066;&#22330;&#20013;&#36215;&#21040;&#23450;&#20215;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.17721</link><description>&lt;p&gt;
&#20174;&#35762;&#35805;&#25991;&#26412;&#21040;&#27934;&#23519;&#21147;&#65306;&#21033;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#25581;&#31034;&#20225;&#19994;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
From Transcripts to Insights: Uncovering Corporate Risks Using Generative AI. (arXiv:2310.17721v1 [econ.GN])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17721
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#24110;&#21161;&#25237;&#36164;&#32773;&#25581;&#31034;&#20225;&#19994;&#39118;&#38505;&#30340;&#20215;&#20540;&#65292;&#36890;&#36807;&#20174;&#25910;&#30410;&#30005;&#35805;&#30340;&#19978;&#19979;&#25991;&#20013;&#29983;&#25104;&#39118;&#38505;&#25688;&#35201;&#21644;&#35780;&#20272;&#65292;&#36825;&#20123;&#22522;&#20110;GPT&#30340;&#24230;&#37327;&#20855;&#26377;&#26174;&#33879;&#30340;&#20449;&#24687;&#20869;&#23481;&#65292;&#33021;&#22815;&#39044;&#27979;&#20225;&#19994;&#23618;&#38754;&#27874;&#21160;&#24615;&#21644;&#25237;&#36164;&#21019;&#26032;&#36873;&#25321;&#12290;&#27492;&#22806;&#65292;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#36824;&#33021;&#26377;&#25928;&#26816;&#27979;&#26032;&#20852;&#39118;&#38505;&#65292;&#24182;&#19988;&#36825;&#20123;&#24230;&#37327;&#22312;&#32929;&#26435;&#24066;&#22330;&#20013;&#36215;&#21040;&#23450;&#20215;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#32034;&#20102;&#20351;&#29992;ChatGPT&#31561;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#24110;&#21161;&#25237;&#36164;&#32773;&#25581;&#31034;&#20225;&#19994;&#39118;&#38505;&#32500;&#24230;&#30340;&#20215;&#20540;&#12290;&#25105;&#20204;&#24320;&#21457;&#24182;&#39564;&#35777;&#20102;&#25919;&#27835;&#12289;&#27668;&#20505;&#21644;&#20154;&#24037;&#26234;&#33021;&#30456;&#20851;&#39118;&#38505;&#30340;&#20225;&#19994;&#23618;&#38754;&#39118;&#38505;&#25950;&#21475;&#24230;&#37327;&#12290;&#20351;&#29992;GPT 3.5&#27169;&#22411;&#20174;&#25910;&#30410;&#30005;&#35805;&#30340;&#32972;&#26223;&#25552;&#20379;&#30340;&#19978;&#19979;&#25991;&#29983;&#25104;&#39118;&#38505;&#25688;&#35201;&#21644;&#35780;&#20272;&#65292;&#25105;&#20204;&#21457;&#29616;&#22522;&#20110;GPT&#30340;&#24230;&#37327;&#20855;&#26377;&#26174;&#33879;&#30340;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#22312;&#39044;&#27979;&#65288;&#24322;&#24120;&#65289;&#20225;&#19994;&#23618;&#38754;&#27874;&#21160;&#24615;&#21644;&#20225;&#19994;&#30340;&#36873;&#25321;&#65288;&#22914;&#25237;&#36164;&#21644;&#21019;&#26032;&#65289;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#39118;&#38505;&#24230;&#37327;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#39118;&#38505;&#35780;&#20272;&#20013;&#30340;&#20449;&#24687;&#20248;&#20110;&#39118;&#38505;&#25688;&#35201;&#65292;&#36825;&#35777;&#26126;&#20102;&#36890;&#29992;&#20154;&#24037;&#26234;&#33021;&#30693;&#35782;&#30340;&#20215;&#20540;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#23545;&#20110;&#21457;&#29616;&#26032;&#20852;&#39118;&#38505;&#65288;&#22914;&#36817;&#20960;&#20010;&#23395;&#24230;&#39129;&#21319;&#30340;&#20154;&#24037;&#26234;&#33021;&#39118;&#38505;&#65289;&#38750;&#24120;&#26377;&#25928;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;GPT&#30340;&#35757;&#32451;&#31383;&#21475;&#20869;&#22806;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#22312;&#32929;&#26435;&#24066;&#22330;&#20013;&#23450;&#20215;&#12290;&#32508;&#19978;&#25152;&#36848;&#65292;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#39118;&#38505;&#27979;&#37327;&#26041;&#27861;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore the value of generative AI tools, such as ChatGPT, in helping investors uncover dimensions of corporate risk. We develop and validate firm-level measures of risk exposure to political, climate, and AI-related risks. Using the GPT 3.5 model to generate risk summaries and assessments from the context provided by earnings call transcripts, we show that GPT-based measures possess significant information content and outperform the existing risk measures in predicting (abnormal) firm-level volatility and firms' choices such as investment and innovation. Importantly, information in risk assessments dominates that in risk summaries, establishing the value of general AI knowledge. We also find that generative AI is effective at detecting emerging risks, such as AI risk, which has soared in recent quarters. Our measures perform well both within and outside the GPT's training window and are priced in equity markets. Taken together, an AI-based approach to risk measurement provides usef
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#29983;&#25104;&#24335; AI &#24037;&#20855; ChatGPT &#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#23637;&#31034;&#32929;&#31080;&#24066;&#22330;&#30456;&#20851;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#20449;&#24687;&#33192;&#32960;&#25351;&#26631;&#24182;&#35777;&#26126;&#20854;&#19982;&#36127;&#38754;&#30340;&#36164;&#26412;&#24066;&#22330;&#21518;&#26524;&#30456;&#20851;&#65292;&#21516;&#26102;&#23637;&#31034;&#20854;&#22312;&#26500;&#24314;&#38024;&#23545;&#24615;&#24635;&#32467;&#26041;&#38754;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10224</link><description>&lt;p&gt;
&#33192;&#32960;&#30340;&#25259;&#38706;&#65306;ChatGPT&#26159;&#21542;&#33021;&#24110;&#21161;&#25237;&#36164;&#32773;&#22788;&#29702;&#36130;&#21153;&#20449;&#24687;&#65311;
&lt;/p&gt;
&lt;p&gt;
Bloated Disclosures: Can ChatGPT Help Investors Process Financial Information?. (arXiv:2306.10224v1 [econ.GN])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10224
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#29983;&#25104;&#24335; AI &#24037;&#20855; ChatGPT &#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#23637;&#31034;&#32929;&#31080;&#24066;&#22330;&#30456;&#20851;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#20449;&#24687;&#33192;&#32960;&#25351;&#26631;&#24182;&#35777;&#26126;&#20854;&#19982;&#36127;&#38754;&#30340;&#36164;&#26412;&#24066;&#22330;&#21518;&#26524;&#30456;&#20851;&#65292;&#21516;&#26102;&#23637;&#31034;&#20854;&#22312;&#26500;&#24314;&#38024;&#23545;&#24615;&#24635;&#32467;&#26041;&#38754;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335; AI &#24037;&#20855;&#65288;&#22914; ChatGPT&#65289;&#21487;&#20197;&#20174;&#26681;&#26412;&#19978;&#25913;&#21464;&#25237;&#36164;&#32773;&#22788;&#29702;&#20449;&#24687;&#30340;&#26041;&#24335;&#12290;&#25105;&#20204;&#20351;&#29992;&#32929;&#31080;&#24066;&#22330;&#20316;&#20026;&#23454;&#39564;&#23460;&#65292;&#25506;&#31350;&#36825;&#20123;&#24037;&#20855;&#22312;&#24635;&#32467;&#22797;&#26434;&#30340;&#20844;&#21496;&#25259;&#38706;&#20449;&#24687;&#26102;&#30340;&#32463;&#27982;&#25928;&#29992;&#12290;&#24635;&#32467;&#25688;&#35201;&#26126;&#26174;&#26356;&#30701;&#65292;&#36890;&#24120;&#27604;&#21407;&#22987;&#25991;&#26412;&#32553;&#30701;&#36229;&#36807; 70%&#65292;&#32780;&#20449;&#24687;&#20869;&#23481;&#24471;&#21040;&#22686;&#24378;&#12290;&#24403;&#19968;&#20221;&#25991;&#20214;&#20855;&#26377;&#31215;&#26497;&#65288;&#28040;&#26497;&#65289;&#24773;&#24863;&#26102;&#65292;&#20854;&#24635;&#32467;&#21464;&#24471;&#26356;&#31215;&#26497;&#65288;&#28040;&#26497;&#65289;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#24635;&#32467;&#23545;&#35299;&#37322;&#32929;&#24066;&#23545;&#25259;&#38706;&#20449;&#24687;&#30340;&#21453;&#24212;&#26356;&#26377;&#25928;&#12290;&#22522;&#20110;&#36825;&#20123;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20449;&#24687;&#8220;&#33192;&#32960;&#8221;&#25351;&#26631;&#12290;&#25105;&#20204;&#26174;&#31034;&#65292;&#33192;&#32960;&#30340;&#25259;&#38706;&#19982;&#36127;&#38754;&#30340;&#36164;&#26412;&#24066;&#22330;&#21518;&#26524;&#30456;&#20851;&#65292;&#20363;&#22914;&#26356;&#20302;&#30340;&#20215;&#26684;&#26377;&#25928;&#24615;&#21644;&#26356;&#39640;&#30340;&#20449;&#24687;&#19981;&#23545;&#31216;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#27169;&#22411;&#22312;&#26500;&#24314;&#38024;&#23545;&#24615;&#24635;&#32467;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#20197;&#30830;&#23450;&#20844;&#21496;&#30340;&#65288;&#38750;&#65289;&#36130;&#21153;&#34920;&#29616;&#21644;&#39118;&#38505;&#12290;&#24635;&#20043;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20687; ChatGPT &#36825;&#26679;&#30340;&#29983;&#25104;&#24335; AI &#24037;&#20855;&#21487;&#20197;&#26377;&#25928;&#22320;&#24110;&#21161;&#25237;&#36164;&#32773;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#36130;&#21153;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI tools such as ChatGPT can fundamentally change the way investors process information. We probe the economic usefulness of these tools in summarizing complex corporate disclosures using the stock market as a laboratory. The unconstrained summaries are dramatically shorter, often by more than 70% compared to the originals, whereas their information content is amplified. When a document has a positive (negative) sentiment, its summary becomes more positive (negative). More importantly, the summaries are more effective at explaining stock market reactions to the disclosed information. Motivated by these findings, we propose a measure of information "bloat." We show that bloated disclosure is associated with adverse capital markets consequences, such as lower price efficiency and higher information asymmetry. Finally, we show that the model is effective at constructing targeted summaries that identify firms' (non-)financial performance and risks. Collectively, our results indi
&lt;/p&gt;</description></item><item><title>MedAlpaca&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;&#21307;&#30103;&#20250;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#21512;&#65292;&#26088;&#22312;&#36890;&#36807;&#32454;&#21270;&#35843;&#25972;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#25913;&#21892;&#21307;&#30103;&#24037;&#20316;&#27969;&#31243;&#21644;&#21307;&#29983;&#35748;&#35777;&#32771;&#35797;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.08247</link><description>&lt;p&gt;
MedAlpaca -- &#19968;&#20010;&#24320;&#28304;&#30340;&#21307;&#30103;&#20250;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#21512;
&lt;/p&gt;
&lt;p&gt;
MedAlpaca -- An Open-Source Collection of Medical Conversational AI Models and Training Data. (arXiv:2304.08247v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08247
&lt;/p&gt;
&lt;p&gt;
MedAlpaca&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;&#21307;&#30103;&#20250;&#35805;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#21512;&#65292;&#26088;&#22312;&#36890;&#36807;&#32454;&#21270;&#35843;&#25972;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#25913;&#21892;&#21307;&#30103;&#24037;&#20316;&#27969;&#31243;&#21644;&#21307;&#29983;&#35748;&#35777;&#32771;&#35797;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;OpenAI&#30340;GPT&#31995;&#21015;&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19981;&#26029;&#21457;&#23637;&#65292;&#25105;&#20204;&#35265;&#35777;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#36234;&#26469;&#36234;&#24191;&#27867;&#30340;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#20986;&#29616;&#12290;&#22312;&#21307;&#23398;&#39046;&#22495;&#65292;&#36825;&#20123;&#35821;&#35328;&#27169;&#22411;&#22312;&#25913;&#21892;&#21307;&#30103;&#24037;&#20316;&#27969;&#31243;&#12289;&#35786;&#26029;&#12289;&#24739;&#32773;&#25252;&#29702;&#21644;&#25945;&#32946;&#26041;&#38754;&#20855;&#26377;&#30456;&#24403;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#36843;&#20999;&#38656;&#35201;&#24320;&#28304;&#27169;&#22411;&#65292;&#20197;&#22312;&#26412;&#22320;&#37096;&#32626;&#20197;&#20445;&#25252;&#24739;&#32773;&#38544;&#31169;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#36229;&#36807;16&#19975;&#26465;&#25968;&#25454;&#65292;&#19987;&#38376;&#20026;&#20102;&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#21270;&#35843;&#25972;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#21307;&#30103;&#24212;&#29992;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20844;&#24320;&#21487;&#35775;&#38382;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#19978;&#23545;&#36825;&#20123;&#25968;&#25454;&#38598;&#36827;&#34892;&#32454;&#21270;&#35843;&#25972;&#30340;&#24433;&#21709;&#65292;&#24182;&#38543;&#21518;&#36890;&#36807;&#27604;&#36739;&#20165;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#32454;&#21270;&#35843;&#25972;&#27169;&#22411;&#22312;&#26410;&#26469;&#21307;&#29983;&#24517;&#39035;&#36890;&#36807;&#30340;&#32771;&#35797;&#20013;&#30340;&#34920;&#29616;&#26469;&#23637;&#31034;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As large language models (LLMs) like OpenAI's GPT series continue to make strides, we witness the emergence of artificial intelligence applications in an ever-expanding range of fields. In medicine, these LLMs hold considerable promise for improving medical workflows, diagnostics, patient care, and education. Yet, there is an urgent need for open-source models that can be deployed on-premises to safeguard patient privacy. In our work, we present an innovative dataset consisting of over 160,000 entries, specifically crafted to fine-tune LLMs for effective medical applications. We investigate the impact of fine-tuning these datasets on publicly accessible pre-trained LLMs, and subsequently, we juxtapose the performance of pre-trained-only models against the fine-tuned models concerning the examinations that future medical doctors must pass to achieve certification.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22240;&#26524;&#20851;&#31995;&#22312;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24517;&#35201;&#24615;&#21644;&#36866;&#29992;&#24615;&#65292;&#24378;&#35843;&#20102;&#38750;&#22240;&#26524;&#39044;&#27979;&#30340;&#31038;&#20250;&#24433;&#21709;&#21644;&#27861;&#24459;&#21453;&#27495;&#35270;&#36807;&#31243;&#20381;&#36182;&#20110;&#22240;&#26524;&#20027;&#24352;&#12290;&#21516;&#26102;&#35752;&#35770;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#24212;&#29992;&#22240;&#26524;&#20851;&#31995;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2207.04053</link><description>&lt;p&gt;
&#35770;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#20013;&#22240;&#26524;&#20851;&#31995;&#30340;&#24517;&#35201;&#24615;&#21644;&#36866;&#29992;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Need and Applicability of Causality for Fair Machine Learning. (arXiv:2207.04053v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.04053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22240;&#26524;&#20851;&#31995;&#22312;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24517;&#35201;&#24615;&#21644;&#36866;&#29992;&#24615;&#65292;&#24378;&#35843;&#20102;&#38750;&#22240;&#26524;&#39044;&#27979;&#30340;&#31038;&#20250;&#24433;&#21709;&#21644;&#27861;&#24459;&#21453;&#27495;&#35270;&#36807;&#31243;&#20381;&#36182;&#20110;&#22240;&#26524;&#20027;&#24352;&#12290;&#21516;&#26102;&#35752;&#35770;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#24212;&#29992;&#22240;&#26524;&#20851;&#31995;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#22312;&#27969;&#34892;&#30149;&#23398;&#12289;&#25919;&#27835;&#21644;&#31038;&#20250;&#31185;&#23398;&#20013;&#30340;&#24120;&#35265;&#24212;&#29992;&#26696;&#20363;&#22806;&#65292;&#20107;&#23454;&#35777;&#26126;&#22240;&#26524;&#20851;&#31995;&#22312;&#35780;&#20272;&#33258;&#21160;&#20915;&#31574;&#30340;&#20844;&#27491;&#24615;&#26041;&#38754;&#21313;&#20998;&#37325;&#35201;&#65292;&#26080;&#35770;&#26159;&#22312;&#27861;&#24459;&#19978;&#36824;&#26159;&#26085;&#24120;&#29983;&#27963;&#20013;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#20026;&#20309;&#22240;&#26524;&#20851;&#31995;&#23545;&#20844;&#24179;&#24615;&#35780;&#20272;&#23588;&#20026;&#37325;&#35201;&#30340;&#35770;&#28857;&#21644;&#31034;&#20363;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#25351;&#20986;&#20102;&#38750;&#22240;&#26524;&#39044;&#27979;&#30340;&#31038;&#20250;&#24433;&#21709;&#20197;&#21450;&#20381;&#36182;&#22240;&#26524;&#20027;&#24352;&#30340;&#27861;&#24459;&#21453;&#27495;&#35270;&#36807;&#31243;&#12290;&#25105;&#20204;&#26368;&#21518;&#35752;&#35770;&#20102;&#24212;&#29992;&#22240;&#26524;&#20851;&#31995;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#25361;&#25112;&#21644;&#23616;&#38480;&#24615;&#65292;&#20197;&#21450;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Besides its common use cases in epidemiology, political, and social sciences, causality turns out to be crucial in evaluating the fairness of automated decisions, both in a legal and everyday sense. We provide arguments and examples, of why causality is particularly important for fairness evaluation. In particular, we point out the social impact of non-causal predictions and the legal anti-discrimination process that relies on causal claims. We conclude with a discussion about the challenges and limitations of applying causality in practical scenarios as well as possible solutions.
&lt;/p&gt;</description></item></channel></rss>