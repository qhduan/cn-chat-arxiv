<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38899;&#20048;&#35821;&#27861;&#35843;&#33410;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#36890;&#36807;&#24212;&#29992;&#38899;&#20048;&#29702;&#35770;&#20013;&#30340;&#21644;&#24358;&#36827;&#34892;&#35268;&#21017;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#33258;&#28982;&#22320;&#36319;&#38543;&#20854;&#20182;&#28608;&#27963;&#65292;&#26368;&#32456;&#23558;&#27010;&#24565;&#30340;&#26144;&#23556;&#32467;&#26500;&#21270;&#20026;&#38899;&#20048;&#20116;&#24230;&#22278;&#12290;</title><link>https://arxiv.org/abs/2403.00790</link><description>&lt;p&gt;
&#21033;&#29992;&#38899;&#20048;&#20116;&#24230;&#22278;&#26500;&#24314;&#27010;&#24565;&#31354;&#38388;&#65306;&#22522;&#20110;&#38899;&#20048;&#35821;&#27861;&#28608;&#27963;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00790
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38899;&#20048;&#35821;&#27861;&#35843;&#33410;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#36890;&#36807;&#24212;&#29992;&#38899;&#20048;&#29702;&#35770;&#20013;&#30340;&#21644;&#24358;&#36827;&#34892;&#35268;&#21017;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#33258;&#28982;&#22320;&#36319;&#38543;&#20854;&#20182;&#28608;&#27963;&#65292;&#26368;&#32456;&#23558;&#27010;&#24565;&#30340;&#26144;&#23556;&#32467;&#26500;&#21270;&#20026;&#38899;&#20048;&#20116;&#24230;&#22278;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#31163;&#25955;&#31070;&#32463;&#32593;&#32476;&#65288;&#22914;&#23574;&#23792;&#32593;&#32476;&#65289;&#30340;&#32467;&#26500;&#19982;&#38050;&#29748;&#26354;&#30340;&#26500;&#25104;&#20043;&#38388;&#30340;&#26377;&#36259;&#30456;&#20284;&#20043;&#22788;&#12290;&#34429;&#28982;&#20004;&#32773;&#37117;&#28041;&#21450;&#25353;&#39034;&#24207;&#25110;&#24182;&#34892;&#28608;&#27963;&#30340;&#33410;&#28857;&#25110;&#38899;&#31526;&#65292;&#20294;&#21518;&#32773;&#21463;&#30410;&#20110;&#20016;&#23500;&#30340;&#38899;&#20048;&#29702;&#35770;&#65292;&#20197;&#25351;&#23548;&#26377;&#24847;&#20041;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#38899;&#20048;&#35821;&#27861;&#26469;&#35843;&#33410;&#23574;&#23792;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28608;&#27963;&#65292;&#20801;&#35768;&#23558;&#31526;&#21495;&#34920;&#31034;&#20026;&#21560;&#24341;&#23376;&#12290;&#36890;&#36807;&#24212;&#29992;&#38899;&#20048;&#29702;&#35770;&#20013;&#30340;&#21644;&#24358;&#36827;&#34892;&#35268;&#21017;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26576;&#20123;&#28608;&#27963;&#22914;&#20309;&#33258;&#28982;&#22320;&#36319;&#38543;&#20854;&#20182;&#28608;&#27963;&#65292;&#31867;&#20284;&#20110;&#21560;&#24341;&#30340;&#27010;&#24565;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#35843;&#21046;&#38899;&#35843;&#30340;&#27010;&#24565;&#65292;&#20197;&#22312;&#32593;&#32476;&#20869;&#23548;&#33322;&#19981;&#21516;&#30340;&#21560;&#24341;&#30406;&#22320;&#12290;&#26368;&#32456;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#27169;&#22411;&#20013;&#27010;&#24565;&#30340;&#26144;&#23556;&#26159;&#30001;&#38899;&#20048;&#20116;&#24230;&#22278;&#26500;&#25104;&#30340;&#65292;&#31361;&#20986;&#20102;&#21033;&#29992;&#38899;&#20048;&#29702;&#35770;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00790v1 Announce Type: cross  Abstract: In this paper, we explore the intriguing similarities between the structure of a discrete neural network, such as a spiking network, and the composition of a piano piece. While both involve nodes or notes that are activated sequentially or in parallel, the latter benefits from the rich body of music theory to guide meaningful combinations. We propose a novel approach that leverages musical grammar to regulate activations in a spiking neural network, allowing for the representation of symbols as attractors. By applying rules for chord progressions from music theory, we demonstrate how certain activations naturally follow others, akin to the concept of attraction. Furthermore, we introduce the concept of modulating keys to navigate different basins of attraction within the network. Ultimately, we show that the map of concepts in our model is structured by the musical circle of fifths, highlighting the potential for leveraging music theor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20808;&#22825;&#20215;&#20540;&#39537;&#21160;&#22686;&#24378;&#23398;&#20064;&#65288;IVRL&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#22810;&#26234;&#33021;&#20307;&#22312;&#21512;&#20316;&#20013;&#30340;&#22797;&#26434;&#34892;&#20026;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#24314;&#31435;&#26234;&#33021;&#20307;&#23545;&#32676;&#20307;&#25928;&#29992;&#21644;&#31995;&#32479;&#25104;&#26412;&#30340;&#35748;&#30693;&#65292;&#28385;&#36275;&#20854;&#21512;&#20316;&#20249;&#20276;&#30340;&#38656;&#27714;&#65292;&#25903;&#25345;&#20854;&#31038;&#21306;&#24182;&#34701;&#20837;&#20154;&#31867;&#31038;&#20250;&#12290;</title><link>http://arxiv.org/abs/2401.05572</link><description>&lt;p&gt;
&#29992;&#20110;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#20808;&#22825;&#20215;&#20540;&#39537;&#21160;&#22686;&#24378;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Innate-Values-driven Reinforcement Learning for Cooperative Multi-Agent Systems. (arXiv:2401.05572v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20808;&#22825;&#20215;&#20540;&#39537;&#21160;&#22686;&#24378;&#23398;&#20064;&#65288;IVRL&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#22810;&#26234;&#33021;&#20307;&#22312;&#21512;&#20316;&#20013;&#30340;&#22797;&#26434;&#34892;&#20026;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#24314;&#31435;&#26234;&#33021;&#20307;&#23545;&#32676;&#20307;&#25928;&#29992;&#21644;&#31995;&#32479;&#25104;&#26412;&#30340;&#35748;&#30693;&#65292;&#28385;&#36275;&#20854;&#21512;&#20316;&#20249;&#20276;&#30340;&#38656;&#27714;&#65292;&#25903;&#25345;&#20854;&#31038;&#21306;&#24182;&#34701;&#20837;&#20154;&#31867;&#31038;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#22825;&#20215;&#20540;&#25551;&#36848;&#20102;&#26234;&#33021;&#20307;&#30340;&#20869;&#22312;&#21160;&#26426;&#65292;&#21453;&#26144;&#20102;&#20182;&#20204;&#36861;&#27714;&#30446;&#26631;&#21644;&#21457;&#23637;&#22810;&#26679;&#25216;&#33021;&#20197;&#28385;&#36275;&#21508;&#31181;&#38656;&#27714;&#30340;&#22266;&#26377;&#20852;&#36259;&#21644;&#20559;&#22909;&#12290;&#24378;&#21270;&#23398;&#20064;&#30340;&#26412;&#36136;&#26159;&#22522;&#20110;&#22870;&#21169;&#39537;&#21160;&#65288;&#22914;&#25928;&#29992;&#65289;&#30340;&#34892;&#20026;&#20114;&#21160;&#23398;&#20064;&#65292;&#31867;&#20284;&#20110;&#33258;&#28982;&#26234;&#33021;&#20307;&#12290;&#29305;&#21035;&#26159;&#22312;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#65292;&#24314;&#31435;&#26234;&#33021;&#20307;&#23545;&#24179;&#34913;&#32676;&#20307;&#25928;&#29992;&#21644;&#31995;&#32479;&#25104;&#26412;&#30340;&#35748;&#30693;&#65292;&#28385;&#36275;&#32676;&#20307;&#25104;&#21592;&#22312;&#21512;&#20316;&#20013;&#30340;&#38656;&#27714;&#65292;&#26159;&#20010;&#20307;&#20026;&#25903;&#25345;&#20854;&#31038;&#21306;&#21644;&#34701;&#20837;&#20154;&#31867;&#31038;&#20250;&#32780;&#23398;&#20064;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#22797;&#21512;&#20869;&#22312;&#20215;&#20540;&#22686;&#24378;&#23398;&#20064;&#27169;&#22411; - &#20808;&#22825;&#20215;&#20540;&#39537;&#21160;&#22686;&#24378;&#23398;&#20064;&#65292;&#29992;&#20110;&#25551;&#36848;&#22810;&#26234;&#33021;&#20307;&#21512;&#20316;&#20013;&#22797;&#26434;&#30340;&#20114;&#21160;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Innate values describe agents' intrinsic motivations, which reflect their inherent interests and preferences to pursue goals and drive them to develop diverse skills satisfying their various needs. The essence of reinforcement learning (RL) is learning from interaction based on reward-driven (such as utilities) behaviors, much like natural agents. It is an excellent model to describe the innate-values-driven (IV) behaviors of AI agents. Especially in multi-agent systems (MAS), building the awareness of AI agents to balance the group utilities and system costs and satisfy group members' needs in their cooperation is a crucial problem for individuals learning to support their community and integrate human society in the long term. This paper proposes a hierarchical compound intrinsic value reinforcement learning model -innate-values-driven reinforcement learning termed IVRL to describe the complex behaviors of multi-agent interaction in their cooperation. We implement the IVRL architec
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23450;&#24615;&#19987;&#23478;&#30693;&#35782;&#30340;&#37327;&#21270;&#20195;&#29702;&#27169;&#22411;&#24320;&#21457;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#23558;&#23450;&#24615;&#25968;&#25454;&#32763;&#35793;&#25104;&#23450;&#37327;&#35268;&#21017;&#65292;&#20026;&#27169;&#22411;&#26500;&#24314;&#32773;&#21644;&#39046;&#22495;&#19987;&#23478;&#25552;&#20379;&#20102;&#19968;&#20010;&#31995;&#32479;&#21644;&#36879;&#26126;&#30340;&#24314;&#27169;&#36807;&#31243;&#12290;&#20197;&#19968;&#20010;&#26377;&#32452;&#32455;&#29359;&#32618;&#30340;&#24212;&#29992;&#26696;&#20363;&#20026;&#20363;&#65292;&#28436;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.00505</link><description>&lt;p&gt;
&#22522;&#20110;&#23450;&#24615;&#19987;&#23478;&#30693;&#35782;&#30340;&#37327;&#21270;&#20195;&#29702;&#27169;&#22411;&#24320;&#21457;&#26694;&#26550;&#65306;&#19968;&#20010;&#26377;&#32452;&#32455;&#29359;&#32618;&#30340;&#24212;&#29992;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
Framework for developing quantitative agent based models based on qualitative expert knowledge: an organised crime use-case. (arXiv:2308.00505v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00505
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23450;&#24615;&#19987;&#23478;&#30693;&#35782;&#30340;&#37327;&#21270;&#20195;&#29702;&#27169;&#22411;&#24320;&#21457;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#23558;&#23450;&#24615;&#25968;&#25454;&#32763;&#35793;&#25104;&#23450;&#37327;&#35268;&#21017;&#65292;&#20026;&#27169;&#22411;&#26500;&#24314;&#32773;&#21644;&#39046;&#22495;&#19987;&#23478;&#25552;&#20379;&#20102;&#19968;&#20010;&#31995;&#32479;&#21644;&#36879;&#26126;&#30340;&#24314;&#27169;&#36807;&#31243;&#12290;&#20197;&#19968;&#20010;&#26377;&#32452;&#32455;&#29359;&#32618;&#30340;&#24212;&#29992;&#26696;&#20363;&#20026;&#20363;&#65292;&#28436;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#23545;&#25191;&#27861;&#30446;&#30340;&#24314;&#27169;&#29359;&#32618;&#32593;&#32476;&#65292;&#38656;&#35201;&#23558;&#26377;&#38480;&#30340;&#25968;&#25454;&#36716;&#21270;&#20026;&#32463;&#36807;&#39564;&#35777;&#30340;&#22522;&#20110;&#20195;&#29702;&#30340;&#27169;&#22411;&#12290;&#24403;&#21069;&#21009;&#20107;&#23398;&#24314;&#27169;&#20013;&#32570;&#23569;&#19968;&#20010;&#20026;&#27169;&#22411;&#26500;&#24314;&#32773;&#21644;&#39046;&#22495;&#19987;&#23478;&#25552;&#20379;&#31995;&#32479;&#21644;&#36879;&#26126;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#24314;&#31435;&#20102;&#35745;&#31639;&#29359;&#32618;&#24314;&#27169;&#30340;&#24314;&#27169;&#36807;&#31243;&#65292;&#21253;&#25324;&#23558;&#23450;&#24615;&#25968;&#25454;&#36716;&#21270;&#20026;&#23450;&#37327;&#35268;&#21017;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FREIDA&#65288;&#22522;&#20110;&#19987;&#23478;&#30693;&#35782;&#39537;&#21160;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;&#27169;&#22411;&#26694;&#26550;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#29359;&#32618;&#21487;&#21345;&#22240;&#26367;&#20195;&#27169;&#22411;&#65288;CCRM&#65289;&#23558;&#20316;&#20026;&#31034;&#20363;&#26696;&#20363;&#65292;&#20197;&#28436;&#31034;FREIDA&#26041;&#27861;&#12290;&#23545;&#20110;CCRM&#65292;&#27491;&#22312;&#24314;&#27169;&#33655;&#20848;&#30340;&#19968;&#20010;&#26377;&#32452;&#32455;&#21487;&#21345;&#22240;&#32593;&#32476;&#65292;&#35797;&#22270;&#36890;&#36807;&#31227;&#38500;&#39318;&#33041;&#33410;&#28857;&#65292;&#20351;&#21097;&#20313;&#20195;&#29702;&#37325;&#26032;&#32452;&#32455;&#65292;&#24182;&#23558;&#32593;&#32476;&#24674;&#22797;&#21040;&#31283;&#23450;&#29366;&#24577;&#12290;&#23450;&#24615;&#25968;&#25454;&#28304;&#65292;&#20363;&#22914;&#26696;&#20214;&#25991;&#20214;&#65292;&#25991;&#29486;&#21644;&#37319;&#35775;&#65292;&#34987;&#36716;&#21270;&#20026;&#32463;&#39564;&#27861;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to model criminal networks for law enforcement purposes, a limited supply of data needs to be translated into validated agent-based models. What is missing in current criminological modelling is a systematic and transparent framework for modelers and domain experts that establishes a modelling procedure for computational criminal modelling that includes translating qualitative data into quantitative rules. For this, we propose FREIDA (Framework for Expert-Informed Data-driven Agent-based models). Throughout the paper, the criminal cocaine replacement model (CCRM) will be used as an example case to demonstrate the FREIDA methodology. For the CCRM, a criminal cocaine network in the Netherlands is being modelled where the kingpin node is being removed, the goal being for the remaining agents to reorganize after the disruption and return the network into a stable state. Qualitative data sources such as case files, literature and interviews are translated into empirical laws, and c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#23545;&#27604;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#27973;&#32780;&#23485;&#30340;&#32467;&#26500;&#65292;&#32467;&#21512;&#35880;&#24910;&#30340;&#26435;&#37325;&#21021;&#22987;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#31561;&#23454;&#39564;&#26041;&#27861;&#65292;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20223;&#30495;&#22522;&#20934;&#27979;&#35797;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#24182;&#28436;&#31034;&#20102;&#23545;&#27604;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#30340;&#26426;&#22120;&#20154;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2306.03346</link><description>&lt;p&gt;
&#31283;&#23450;&#23545;&#27604;&#24378;&#21270;&#23398;&#20064;: &#31163;&#32447;&#30446;&#26631;&#36798;&#25104;&#30340;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Stabilizing Contrastive RL: Techniques for Offline Goal Reaching. (arXiv:2306.03346v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03346
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#23545;&#27604;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#27973;&#32780;&#23485;&#30340;&#32467;&#26500;&#65292;&#32467;&#21512;&#35880;&#24910;&#30340;&#26435;&#37325;&#21021;&#22987;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#31561;&#23454;&#39564;&#26041;&#27861;&#65292;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20223;&#30495;&#22522;&#20934;&#27979;&#35797;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#24182;&#28436;&#31034;&#20102;&#23545;&#27604;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#30340;&#26426;&#22120;&#20154;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#24050;&#32463;&#24320;&#21457;&#20102;&#33258;&#30417;&#30563;&#26041;&#27861;&#65292;&#24378;&#21270;&#23398;&#20064;&#20063;&#21487;&#20197;&#34987;&#35270;&#20026;&#33258;&#30417;&#30563;&#38382;&#39064;&#65306;&#23398;&#20064;&#36798;&#21040;&#20219;&#20309;&#30446;&#26631;&#65292;&#32780;&#19981;&#38656;&#35201;&#20154;&#31867;&#25351;&#23450;&#30340;&#22870;&#21169;&#25110;&#26631;&#31614;&#12290;&#28982;&#32780;&#65292;&#20026;&#24378;&#21270;&#23398;&#20064;&#24314;&#31435;&#33258;&#30417;&#30563;&#22522;&#30784;&#23454;&#38469;&#19978;&#38754;&#20020;&#30528;&#19968;&#20123;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#22522;&#20110;&#27492;&#21069;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#32454;&#33268;&#30340;&#21078;&#26512;&#23454;&#39564;&#65292;&#24182;&#21457;&#29616;&#19968;&#20010;&#27973;&#32780;&#23485;&#30340;&#32467;&#26500;&#65292;&#32467;&#21512;&#35880;&#24910;&#30340;&#26435;&#37325;&#21021;&#22987;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#65292;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#19982;&#23545;&#27604;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20223;&#30495;&#22522;&#20934;&#27979;&#35797;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#28436;&#31034;&#20102;&#36890;&#36807;&#36825;&#20123;&#35774;&#35745;&#20915;&#31574;&#65292;&#23545;&#27604;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#20219;&#21153;&#65292;&#20854;&#20013;&#20219;&#21153;&#30001;&#35757;&#32451;&#21518;&#25552;&#20379;&#30340;&#21333;&#20010;&#30446;&#26631;&#22270;&#20687;&#25351;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the same way that the computer vision (CV) and natural language processing (NLP) communities have developed self-supervised methods, reinforcement learning (RL) can be cast as a self-supervised problem: learning to reach any goal, without requiring human-specified rewards or labels. However, actually building a self-supervised foundation for RL faces some important challenges. Building on prior contrastive approaches to this RL problem, we conduct careful ablation experiments and discover that a shallow and wide architecture, combined with careful weight initialization and data augmentation, can significantly boost the performance of these contrastive RL approaches on challenging simulated benchmarks. Additionally, we demonstrate that, with these design decisions, contrastive approaches can solve real-world robotic manipulation tasks, with tasks being specified by a single goal image provided after training.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#23884;&#20837;&#24335;GPU&#23454;&#29616;&#30340;&#36731;&#37327;&#32423;&#31435;&#20307;&#21305;&#37197;&#31995;&#32479;-StereoVAE&#65292;&#35813;&#31995;&#32479;&#37319;&#29992;&#22522;&#20110;VAE&#30340;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#23545;&#20256;&#32479;&#21305;&#37197;&#26041;&#27861;&#29983;&#25104;&#30340;&#23567;&#23610;&#23544;&#31895;&#31961;&#35270;&#24046;&#22270;&#36827;&#34892;&#19978;&#37319;&#26679;&#19982;&#32454;&#21270;&#65292;&#36798;&#21040;&#20102;&#25552;&#39640;&#21305;&#37197;&#31934;&#24230;&#21644;&#20445;&#35777;&#23454;&#26102;&#22788;&#29702;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.11566</link><description>&lt;p&gt;
&#36890;&#36807;&#23884;&#20837;&#24335;GPU&#23454;&#29616;&#30340;&#36731;&#37327;&#32423;&#31435;&#20307;&#21305;&#37197;&#31995;&#32479;-StereoVAE
&lt;/p&gt;
&lt;p&gt;
StereoVAE: A lightweight stereo matching system through embedded GPUs. (arXiv:2305.11566v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#23884;&#20837;&#24335;GPU&#23454;&#29616;&#30340;&#36731;&#37327;&#32423;&#31435;&#20307;&#21305;&#37197;&#31995;&#32479;-StereoVAE&#65292;&#35813;&#31995;&#32479;&#37319;&#29992;&#22522;&#20110;VAE&#30340;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#23545;&#20256;&#32479;&#21305;&#37197;&#26041;&#27861;&#29983;&#25104;&#30340;&#23567;&#23610;&#23544;&#31895;&#31961;&#35270;&#24046;&#22270;&#36827;&#34892;&#19978;&#37319;&#26679;&#19982;&#32454;&#21270;&#65292;&#36798;&#21040;&#20102;&#25552;&#39640;&#21305;&#37197;&#31934;&#24230;&#21644;&#20445;&#35777;&#23454;&#26102;&#22788;&#29702;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#23884;&#20837;&#24335;GPU&#23454;&#29616;&#30340;&#36731;&#37327;&#32423;&#31435;&#20307;&#21305;&#37197;&#31995;&#32479;-StereoVAE&#65292;&#23427;&#25171;&#30772;&#20102;&#31435;&#20307;&#21305;&#37197;&#20013;&#31934;&#24230;&#21644;&#22788;&#29702;&#36895;&#24230;&#20043;&#38388;&#30340;&#24179;&#34913;&#65292;&#20351;&#24471;&#25105;&#20204;&#30340;&#23884;&#20837;&#24335;&#31995;&#32479;&#33021;&#22815;&#22312;&#20445;&#35777;&#23454;&#26102;&#22788;&#29702;&#30340;&#21516;&#26102;&#36827;&#19968;&#27493;&#25552;&#39640;&#21305;&#37197;&#31934;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#26500;&#24314;&#19968;&#20010;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#65292;&#23545;&#20256;&#32479;&#21305;&#37197;&#26041;&#27861;&#29983;&#25104;&#30340;&#23567;&#23610;&#23544;&#31895;&#31961;&#35270;&#24046;&#22270;&#36827;&#34892;&#19978;&#37319;&#26679;&#19982;&#32454;&#21270;&#12290;&#36825;&#31181;&#28151;&#21512;&#32467;&#26500;&#19981;&#20165;&#21487;&#20197;&#24102;&#26469;&#20256;&#32479;&#26041;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#20248;&#21183;&#65292;&#36824;&#21487;&#20197;&#20445;&#35777;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#19979;&#30340;&#21305;&#37197;&#31934;&#24230;&#12290;&#23545;KITTI 2015&#22522;&#20934;&#27979;&#35797;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#36731;&#37327;&#32423;&#31435;&#20307;&#21305;&#37197;&#31995;&#32479;&#22312;&#25552;&#39640;&#30001;&#19981;&#21516;&#31639;&#27861;&#29983;&#25104;&#30340;&#31895;&#31961;&#35270;&#24046;&#22270;&#30340;&#20934;&#30830;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#39640;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#22312;&#23884;&#20837;&#24335;GPU&#19978;&#23454;&#26102;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a lightweight system for stereo matching through embedded GPUs. It breaks the trade-off between accuracy and processing speed in stereo matching, enabling our embedded system to further improve the matching accuracy while ensuring real-time processing. The main idea of our method is to construct a tiny neural network based on variational auto-encoder (VAE) to upsample and refinement a small size of coarse disparity map, which is first generated by a traditional matching method. The proposed hybrid structure cannot only bring the advantage of traditional methods in terms of computational complexity, but also ensure the matching accuracy under the impact of neural network. Extensive experiments on the KITTI 2015 benchmark demonstrate that our tiny system exhibits high robustness in improving the accuracy of the coarse disparity maps generated by different algorithms, while also running in real-time on embedded GPUs.
&lt;/p&gt;</description></item></channel></rss>