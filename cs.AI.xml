<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#65292;&#36890;&#36807;&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#65292;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.07204</link><description>&lt;p&gt;
&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#25918;&#39046;&#22495;&#22478;&#24066;&#34892;&#31243;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Synergizing Spatial Optimization with Large Language Models for Open-Domain Urban Itinerary Planning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#65292;&#36890;&#36807;&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#65292;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#12290;OUIP&#19982;&#20256;&#32479;&#34892;&#31243;&#35268;&#21010;&#19981;&#21516;&#65292;&#20256;&#32479;&#35268;&#21010;&#38480;&#21046;&#20102;&#29992;&#25143;&#34920;&#36798;&#26356;&#35814;&#32454;&#30340;&#38656;&#27714;&#65292;&#38459;&#30861;&#20102;&#30495;&#27491;&#30340;&#20010;&#24615;&#21270;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#22312;&#22788;&#29702;&#22810;&#26679;&#21270;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38750;&#23454;&#26102;&#20449;&#24687;&#12289;&#19981;&#23436;&#25972;&#30340;&#30693;&#35782;&#21644;&#19981;&#36275;&#30340;&#31354;&#38388;&#24847;&#35782;&#65292;&#23427;&#20204;&#26080;&#27861;&#29420;&#31435;&#22320;&#25552;&#20379;&#28385;&#24847;&#30340;&#29992;&#25143;&#20307;&#39564;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;ItiNera&#30340;OUIP&#31995;&#32479;&#65292;&#23558;&#31354;&#38388;&#20248;&#21270;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#27969;&#27700;&#32447;&#65292;&#29992;&#20110;&#25552;&#21462;&#21644;&#26356;&#26032;&#20852;&#36259;&#28857;&#29305;&#24449;&#65292;&#20197;&#21019;&#24314;&#29992;&#25143;&#33258;&#24049;&#30340;&#20010;&#24615;&#21270;&#20852;&#36259;&#28857;&#25968;&#25454;&#24211;&#12290;&#23545;&#20110;&#27599;&#20010;&#29992;&#25143;&#35831;&#27714;&#65292;&#25105;&#20204;&#21033;&#29992;LLM&#36827;&#34892;&#21327;&#21516;&#23454;&#29616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we for the first time propose the task of Open-domain Urban Itinerary Planning (OUIP) for citywalk, which directly generates itineraries based on users' requests described in natural language. OUIP is different from conventional itinerary planning, which limits users from expressing more detailed needs and hinders true personalization. Recently, large language models (LLMs) have shown potential in handling diverse tasks. However, due to non-real-time information, incomplete knowledge, and insufficient spatial awareness, they are unable to independently deliver a satisfactory user experience in OUIP. Given this, we present ItiNera, an OUIP system that synergizes spatial optimization with Large Language Models (LLMs) to provide services that customize urban itineraries based on users' needs. Specifically, we develop an LLM-based pipeline for extracting and updating POI features to create a user-owned personalized POI database. For each user request, we leverage LLM in coop
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#20013;&#36710;&#20869;&#20154;&#26426;&#20132;&#20114;&#30340;&#29616;&#29366;&#21644;&#26032;&#20852;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#21253;&#23481;&#24615;HCI&#35774;&#35745;&#21407;&#21017;&#65292;&#26088;&#22312;&#22686;&#24378;&#20056;&#23458;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2401.14571</link><description>&lt;p&gt;
&#21521;&#21253;&#23481;&#24615;&#39537;&#21160;&#65306;&#37325;&#26032;&#23457;&#35270;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#20013;&#30340;&#36710;&#20869;&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;
Driving Towards Inclusion: Revisiting In-Vehicle Interaction in Autonomous Vehicles. (arXiv:2401.14571v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#20013;&#36710;&#20869;&#20154;&#26426;&#20132;&#20114;&#30340;&#29616;&#29366;&#21644;&#26032;&#20852;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#21253;&#23481;&#24615;HCI&#35774;&#35745;&#21407;&#21017;&#65292;&#26088;&#22312;&#22686;&#24378;&#20056;&#23458;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#30446;&#21069;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#20013;&#36710;&#20869;&#20154;&#26426;&#20132;&#20114;&#65288;HCI&#65289;&#30340;&#29616;&#29366;&#65292;&#29305;&#21035;&#20851;&#27880;&#21253;&#23481;&#24615;&#21644;&#21487;&#35775;&#38382;&#24615;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#32771;&#23519;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#20013;&#21253;&#23481;&#24615;HCI&#30340;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#35774;&#35745;&#21407;&#21017;&#65292;&#35780;&#20272;&#29616;&#26377;HCI&#31995;&#32479;&#65292;&#24182;&#30830;&#23450;&#21487;&#33021;&#22686;&#24378;&#20056;&#23458;&#20307;&#39564;&#30340;&#26032;&#20852;&#25216;&#26415;&#12290;&#26412;&#25991;&#39318;&#20808;&#27010;&#36848;&#20102;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#25216;&#26415;&#30340;&#29616;&#29366;&#65292;&#28982;&#21518;&#23545;&#36825;&#19968;&#32972;&#26223;&#19979;HCI&#30340;&#37325;&#35201;&#24615;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;&#25509;&#19979;&#26469;&#65292;&#26412;&#25991;&#32508;&#36848;&#20102;&#21253;&#23481;&#24615;HCI&#35774;&#35745;&#21407;&#21017;&#30340;&#29616;&#26377;&#25991;&#29486;&#65292;&#24182;&#35780;&#20272;&#20102;&#24403;&#21069;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#20013;HCI&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#12290;&#26412;&#25991;&#36824;&#30830;&#23450;&#20102;&#21487;&#33021;&#22686;&#24378;&#20056;&#23458;&#20307;&#39564;&#30340;&#26032;&#20852;&#25216;&#26415;&#65292;&#22914;&#35821;&#38899;&#28608;&#27963;&#30028;&#38754;&#12289;&#35302;&#35273;&#21453;&#39304;&#31995;&#32479;&#21644;&#22686;&#24378;&#29616;&#23454;&#26174;&#31034;&#12290;&#26368;&#21518;&#65292;&#26412;&#25991;&#24635;&#32467;&#20102;&#30740;&#31350;&#30340;&#37325;&#35201;&#21457;&#29616;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a comprehensive literature review of the current state of in-vehicle human-computer interaction (HCI) in the context of self-driving vehicles, with a specific focus on inclusion and accessibility. This study's aim is to examine the user-centered design principles for inclusive HCI in self-driving vehicles, evaluate existing HCI systems, and identify emerging technologies that have the potential to enhance the passenger experience. The paper begins by providing an overview of the current state of self-driving vehicle technology, followed by an examination of the importance of HCI in this context. Next, the paper reviews the existing literature on inclusive HCI design principles and evaluates the effectiveness of current HCI systems in self-driving vehicles. The paper also identifies emerging technologies that have the potential to enhance the passenger experience, such as voice-activated interfaces, haptic feedback systems, and augmented reality displays. Finally, th
&lt;/p&gt;</description></item><item><title>RAPGen&#26159;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#20351;&#29992;Retrieval-Augmented Prompt Generation&#65288;RAPGen&#65289;&#26041;&#27861;&#65292;&#21363;&#20174;&#39044;&#20808;&#26500;&#24314;&#30340;&#24615;&#33021;Bug&#20462;&#22797;&#30693;&#35782;&#24211;&#20013;&#26816;&#32034;&#25552;&#31034;&#25351;&#20196;&#24182;&#29983;&#25104;&#25552;&#31034;&#65292;&#28982;&#21518;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#29983;&#25104;&#20462;&#22797;&#26041;&#26696;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#20195;&#30721;&#20302;&#25928;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#19987;&#23478;&#39564;&#35777;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;RAPGen&#22312;60%&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#29983;&#25104;&#19982;&#24320;&#21457;&#32773;&#31561;&#25928;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#25913;&#36827;&#24314;&#35758;&#65292;&#20854;&#20013;&#32422;39%&#30340;&#24314;&#35758;&#23436;&#20840;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2306.17077</link><description>&lt;p&gt;
RAPGen: &#19968;&#31181;&#35299;&#20915;&#38646;&#26679;&#26412;&#20195;&#30721;&#20302;&#25928;&#38382;&#39064;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot. (arXiv:2306.17077v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17077
&lt;/p&gt;
&lt;p&gt;
RAPGen&#26159;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#20351;&#29992;Retrieval-Augmented Prompt Generation&#65288;RAPGen&#65289;&#26041;&#27861;&#65292;&#21363;&#20174;&#39044;&#20808;&#26500;&#24314;&#30340;&#24615;&#33021;Bug&#20462;&#22797;&#30693;&#35782;&#24211;&#20013;&#26816;&#32034;&#25552;&#31034;&#25351;&#20196;&#24182;&#29983;&#25104;&#25552;&#31034;&#65292;&#28982;&#21518;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#29983;&#25104;&#20462;&#22797;&#26041;&#26696;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#20195;&#30721;&#20302;&#25928;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#19987;&#23478;&#39564;&#35777;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;RAPGen&#22312;60%&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#29983;&#25104;&#19982;&#24320;&#21457;&#32773;&#31561;&#25928;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#25913;&#36827;&#24314;&#35758;&#65292;&#20854;&#20013;&#32422;39%&#30340;&#24314;&#35758;&#23436;&#20840;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24615;&#33021;Bug&#26159;&#19968;&#31181;&#21363;&#20351;&#22312;&#32463;&#36807;&#20805;&#20998;&#27979;&#35797;&#30340;&#21830;&#19994;&#20135;&#21697;&#20013;&#20063;&#21487;&#33021;&#20986;&#29616;&#30340;&#38750;&#21151;&#33021;&#24615;&#38382;&#39064;&#12290;&#20462;&#22797;&#36825;&#20123;&#24615;&#33021;Bug&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Retrieval-Augmented Prompt Generation&#65288;RAPGen&#65289;&#30340;&#26032;&#26041;&#27861;&#12290;&#32473;&#23450;&#19968;&#20010;&#23384;&#22312;&#24615;&#33021;&#38382;&#39064;&#30340;&#20195;&#30721;&#29255;&#27573;&#65292;RAPGen&#39318;&#20808;&#20174;&#39044;&#20808;&#26500;&#24314;&#30340;&#20043;&#21069;&#24615;&#33021;Bug&#20462;&#22797;&#30693;&#35782;&#24211;&#20013;&#26816;&#32034;&#19968;&#20010;&#25552;&#31034;&#25351;&#20196;&#65292;&#28982;&#21518;&#20351;&#29992;&#26816;&#32034;&#21040;&#30340;&#25351;&#20196;&#29983;&#25104;&#19968;&#20010;&#25552;&#31034;&#12290;&#28982;&#21518;&#65292;&#23427;&#22312;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#20351;&#29992;&#36825;&#20010;&#25552;&#31034;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;Codex&#65289;&#19978;&#29983;&#25104;&#19968;&#20010;&#20462;&#22797;&#26041;&#26696;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#21508;&#31181;&#25552;&#31034;&#21464;&#20307;&#21644;&#29616;&#26377;&#26041;&#27861;&#22312;&#24615;&#33021;Bug&#20462;&#22797;&#20219;&#21153;&#20013;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;RAPGen&#22312;60%&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#29983;&#25104;&#19982;&#24320;&#21457;&#32773;&#31561;&#25928;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#25913;&#36827;&#24314;&#35758;&#65292;&#22312;&#32463;&#36807;&#19987;&#23478;&#39564;&#35777;&#30340;&#36807;&#21435;C#&#24320;&#21457;&#32773;&#25152;&#20570;&#30340;&#24615;&#33021;&#26356;&#25913;&#25968;&#25454;&#38598;&#20013;&#26377;&#32422;39%&#30340;&#24314;&#35758;&#23436;&#20840;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performance bugs are non-functional bugs that can even manifest in well-tested commercial products. Fixing these performance bugs is an important yet challenging problem. In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction. It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix. We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing. Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#34892;&#20026;&#30340;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#26469;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#21363;&#35299;&#37322;&#21333;&#20803;&#26356;&#21152;&#21487;&#35299;&#37322;&#19988;&#32771;&#34385;&#20102;&#23439;&#35266;&#32423;&#29305;&#24449;&#21644;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#12290;</title><link>http://arxiv.org/abs/2006.02482</link><description>&lt;p&gt;
&#29992;&#22240;&#26524;&#23398;&#20064;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#30340;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning. (arXiv:2006.02482v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.02482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#34892;&#20026;&#30340;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#26469;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#21363;&#35299;&#37322;&#21333;&#20803;&#26356;&#21152;&#21487;&#35299;&#37322;&#19988;&#32771;&#34385;&#20102;&#23439;&#35266;&#32423;&#29305;&#24449;&#21644;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#23398;&#26041;&#27861;&#22312;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#27169;&#22411;&#65288;&#20363;&#22914;&#22522;&#20110;&#22270;&#20687;&#20687;&#32032;&#25968;&#25454;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#37325;&#35201;&#32570;&#28857;&#65306;&#65288;i&#65289;&#8220;&#35299;&#37322;&#21333;&#20803;&#8221;&#26159;&#30456;&#20851;&#39044;&#27979;&#27169;&#22411;&#30340;&#24494;&#35266;&#32423;&#36755;&#20837;&#65292;&#20363;&#22914;&#22270;&#20687;&#20687;&#32032;&#65292;&#32780;&#19981;&#26159;&#26356;&#26377;&#29992;&#20110;&#29702;&#35299;&#22914;&#20309;&#21487;&#33021;&#25913;&#21464;&#31639;&#27861;&#34892;&#20026;&#30340;&#21487;&#35299;&#37322;&#30340;&#23439;&#35266;&#32423;&#29305;&#24449;&#65307;&#65288;ii&#65289;&#29616;&#26377;&#26041;&#27861;&#20551;&#35774;&#29305;&#24449;&#19982;&#30446;&#26631;&#27169;&#22411;&#39044;&#27979;&#20043;&#38388;&#19981;&#23384;&#22312;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#65292;&#36825;&#22312;&#35299;&#37322;&#21333;&#20803;&#26159;&#23439;&#35266;&#32423;&#21464;&#37327;&#26102;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#22312;&#20998;&#26512;&#20154;&#21592;&#26080;&#27861;&#35775;&#38382;&#30446;&#26631;&#39044;&#27979;&#31639;&#27861;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#30340;&#37325;&#35201;&#24773;&#20917;&#65292;&#32780;&#21482;&#33021;&#26681;&#25454;&#29305;&#23450;&#36755;&#20837;&#26597;&#35810;&#27169;&#22411;&#36755;&#20986;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#25105;&#20204;&#25552;&#20986;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#65292;&#20801;&#35768;&#26356;&#22909;&#22320;&#29702;&#35299;&#31639;&#27861;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal approaches to post-hoc explainability for black-box prediction models (e.g., deep neural networks trained on image pixel data) have become increasingly popular. However, existing approaches have two important shortcomings: (i) the "explanatory units" are micro-level inputs into the relevant prediction model, e.g., image pixels, rather than interpretable macro-level features that are more useful for understanding how to possibly change the algorithm's behavior, and (ii) existing approaches assume there exists no unmeasured confounding between features and target model predictions, which fails to hold when the explanatory units are macro-level variables. Our focus is on the important setting where the analyst has no access to the inner workings of the target prediction algorithm, rather only the ability to query the output of the model in response to a particular input. To provide causal explanations in such a setting, we propose to learn causal graphical representations that allo
&lt;/p&gt;</description></item></channel></rss>