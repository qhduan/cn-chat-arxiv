<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;Grover&#21644;Deutsch-Josza&#31561;&#22522;&#30784;&#37327;&#23376;&#31639;&#27861;&#65292;&#36890;&#36807;&#19968;&#32452;&#31934;&#24515;&#26500;&#24314;&#30340;&#26465;&#20214;&#65292;&#25512;&#26029;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#27573;&#26102;&#38388;&#20869;&#26159;&#21542;&#20855;&#26377;&#32487;&#32493;&#32500;&#25345;&#21160;&#24577;&#27963;&#21160;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.18963</link><description>&lt;p&gt;
&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#25512;&#26029;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#21160;&#24577;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Using Quantum Computing to Infer Dynamic Behaviors of Biological and Artificial Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;Grover&#21644;Deutsch-Josza&#31561;&#22522;&#30784;&#37327;&#23376;&#31639;&#27861;&#65292;&#36890;&#36807;&#19968;&#32452;&#31934;&#24515;&#26500;&#24314;&#30340;&#26465;&#20214;&#65292;&#25512;&#26029;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#27573;&#26102;&#38388;&#20869;&#26159;&#21542;&#20855;&#26377;&#32487;&#32493;&#32500;&#25345;&#21160;&#24577;&#27963;&#21160;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#38382;&#39064;&#31867;&#21035;&#30340;&#25506;&#32034;&#26159;&#37327;&#23376;&#35745;&#31639;&#30740;&#31350;&#30340;&#19968;&#20010;&#27963;&#36291;&#39046;&#22495;&#12290;&#19968;&#20010;&#22522;&#26412;&#19978;&#23436;&#20840;&#26410;&#34987;&#25506;&#35752;&#30340;&#20027;&#39064;&#26159;&#20351;&#29992;&#37327;&#23376;&#31639;&#27861;&#21644;&#35745;&#31639;&#26469;&#25506;&#32034;&#21644;&#35810;&#38382;&#31070;&#32463;&#32593;&#32476;&#30340;&#21151;&#33021;&#21160;&#24577;&#12290;&#36825;&#26159;&#23558;&#37327;&#23376;&#35745;&#31639;&#24212;&#29992;&#20110;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#21644;&#20223;&#30495;&#30340;&#23578;&#26410;&#25104;&#29087;&#30340;&#20027;&#39064;&#30340;&#19968;&#20010;&#32452;&#25104;&#37096;&#20998;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#31934;&#24515;&#26500;&#24314;&#30340;&#19968;&#32452;&#26465;&#20214;&#26469;&#20351;&#29992;&#20004;&#20010;&#22522;&#30784;&#37327;&#23376;&#31639;&#27861;&#65292;Grover&#21644;Deutsch-Josza&#65292;&#20197;&#20351;&#36755;&#20986;&#27979;&#37327;&#20855;&#26377;&#19968;&#31181;&#35299;&#37322;&#65292;&#20445;&#35777;&#25105;&#20204;&#33021;&#22815;&#25512;&#26029;&#19968;&#20010;&#31616;&#21333;&#30340;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#65288;&#36866;&#29992;&#20110;&#29983;&#29289;&#21644;&#20154;&#24037;&#32593;&#32476;&#65289;&#22312;&#19968;&#27573;&#26102;&#38388;&#21518;&#26159;&#21542;&#26377;&#21487;&#33021;&#32487;&#32493;&#32500;&#25345;&#21160;&#24577;&#27963;&#21160;&#12290;&#25110;&#32773;&#36825;&#20123;&#21160;&#24577;&#20445;&#35777;&#20250;&#20572;&#27490;&#65292;&#35201;&#20040;&#26159;&#36890;&#36807;'&#30315;&#30187;'&#21160;&#24577;&#65292;&#35201;&#20040;&#26159;&#38745;&#27490;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18963v1 Announce Type: cross  Abstract: The exploration of new problem classes for quantum computation is an active area of research. An essentially completely unexplored topic is the use of quantum algorithms and computing to explore and ask questions \textit{about} the functional dynamics of neural networks. This is a component of the still-nascent topic of applying quantum computing to the modeling and simulations of biological and artificial neural networks. In this work, we show how a carefully constructed set of conditions can use two foundational quantum algorithms, Grover and Deutsch-Josza, in such a way that the output measurements admit an interpretation that guarantees we can infer if a simple representation of a neural network (which applies to both biological and artificial networks) after some period of time has the potential to continue sustaining dynamic activity. Or whether the dynamics are guaranteed to stop either through 'epileptic' dynamics or quiescence
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;npm&#29983;&#24577;&#31995;&#32479;&#20013;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#20197;&#21327;&#21161;&#23433;&#20840;&#20998;&#26512;&#24072;&#35782;&#21035;&#24694;&#24847;&#36719;&#20214;&#21253;</title><link>https://arxiv.org/abs/2403.12196</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;npm&#29983;&#24577;&#31995;&#32479;&#20013;&#26816;&#27979;&#24694;&#24847;&#36719;&#20214;
&lt;/p&gt;
&lt;p&gt;
Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12196
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;npm&#29983;&#24577;&#31995;&#32479;&#20013;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#20197;&#21327;&#21161;&#23433;&#20840;&#20998;&#26512;&#24072;&#35782;&#21035;&#24694;&#24847;&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gartner 2022&#24180;&#30340;&#25253;&#21578;&#39044;&#27979;&#65292;&#21040;2025&#24180;&#65292;&#20840;&#29699;45%&#30340;&#32452;&#32455;&#23558;&#36973;&#36935;&#36719;&#20214;&#20379;&#24212;&#38142;&#25915;&#20987;&#65292;&#20984;&#26174;&#20102;&#25913;&#21892;&#36719;&#20214;&#20379;&#24212;&#38142;&#23433;&#20840;&#23545;&#31038;&#21306;&#21644;&#22269;&#23478;&#21033;&#30410;&#30340;&#36843;&#20999;&#24615;&#12290;&#24403;&#21069;&#30340;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#25216;&#26415;&#36890;&#36807;&#36807;&#28388;&#33391;&#24615;&#21644;&#24694;&#24847;&#36719;&#20214;&#21253;&#26469;&#36741;&#21161;&#25163;&#21160;&#23457;&#26680;&#36807;&#31243;&#65292;&#28982;&#32780;&#36825;&#31181;&#25216;&#26415;&#23384;&#22312;&#36739;&#39640;&#30340;&#35823;&#25253;&#29575;&#21644;&#26377;&#38480;&#30340;&#33258;&#21160;&#21270;&#25903;&#25345;&#12290;&#22240;&#27492;&#65292;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#25216;&#26415;&#21487;&#20197;&#21463;&#30410;&#20110;&#20808;&#36827;&#12289;&#26356;&#33258;&#21160;&#21270;&#30340;&#26041;&#27861;&#65292;&#24471;&#21040;&#20934;&#30830;&#19988;&#35823;&#25253;&#36739;&#23569;&#30340;&#32467;&#26524;&#12290;&#35813;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#24110;&#21161;&#23433;&#20840;&#20998;&#26512;&#24072;&#35782;&#21035;npm&#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#24694;&#24847;&#36719;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12196v1 Announce Type: cross  Abstract: The Gartner 2022 report predicts that 45% of organizations worldwide will encounter software supply chain attacks by 2025, highlighting the urgency to improve software supply chain security for community and national interests. Current malware detection techniques aid in the manual review process by filtering benign and malware packages, yet such techniques have high false-positive rates and limited automation support. Therefore, malware detection techniques could benefit from advanced, more automated approaches for accurate and minimally false-positive results. The goal of this study is to assist security analysts in identifying malicious packages through the empirical study of large language models (LLMs) to detect potential malware in the npm ecosystem.   We present SocketAI Scanner, a multi-stage decision-maker malware detection workflow using iterative self-refinement and zero-shot-role-play-Chain of Thought (CoT) prompting techni
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#27010;&#25324;&#24615;&#22240;&#26524;&#22270;&#21644;&#20998;&#26512;&#20027;&#39064;&#28151;&#28102;&#25928;&#24212;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;SuCI&#65292;&#23454;&#29616;&#20102;&#22810;&#27169;&#24577;&#20154;&#31867;&#24847;&#22270;&#29702;&#35299;&#30340;&#21435;&#20559;&#35265;&#65292;&#35299;&#20915;&#20102;MIU&#27169;&#22411;&#21463;&#20027;&#20307;&#21464;&#24322;&#38382;&#39064;&#22256;&#25200;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.05025</link><description>&lt;p&gt;
&#36890;&#36807;&#20027;&#39064;&#21435;&#30456;&#20851;&#23454;&#29616;&#22810;&#27169;&#24577;&#20154;&#31867;&#24847;&#22270;&#29702;&#35299;&#21435;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Towards Multimodal Human Intention Understanding Debiasing via Subject-Deconfounding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05025
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#27010;&#25324;&#24615;&#22240;&#26524;&#22270;&#21644;&#20998;&#26512;&#20027;&#39064;&#28151;&#28102;&#25928;&#24212;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;SuCI&#65292;&#23454;&#29616;&#20102;&#22810;&#27169;&#24577;&#20154;&#31867;&#24847;&#22270;&#29702;&#35299;&#30340;&#21435;&#20559;&#35265;&#65292;&#35299;&#20915;&#20102;MIU&#27169;&#22411;&#21463;&#20027;&#20307;&#21464;&#24322;&#38382;&#39064;&#22256;&#25200;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05025v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#25688;&#35201;: &#22810;&#27169;&#24577;&#24847;&#22270;&#29702;&#35299;(MIU)&#26159;&#20154;&#31867;&#34920;&#36798;&#20998;&#26512;(&#20363;&#22914;&#24773;&#24863;&#25110;&#24189;&#40664;)&#19981;&#21487;&#25110;&#32570;&#30340;&#32452;&#25104;&#37096;&#20998;&#65292;&#28041;&#21450;&#35270;&#35273;&#23039;&#21183;&#12289;&#35821;&#35328;&#20869;&#23481;&#21644;&#22768;&#23398;&#34892;&#20026;&#31561;&#24322;&#26500;&#27169;&#24577;&#12290;&#29616;&#26377;&#24037;&#20316;&#22987;&#32456;&#19987;&#27880;&#20110;&#35774;&#35745;&#22797;&#26434;&#30340;&#32467;&#26500;&#25110;&#34701;&#21512;&#31574;&#30053;&#65292;&#21462;&#24471;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#37117;&#21463;&#21040;&#20027;&#39064;&#21464;&#24322;&#38382;&#39064;&#30340;&#22256;&#25200;&#65292;&#22240;&#20026;&#19981;&#21516;&#20027;&#39064;&#20043;&#38388;&#30340;&#25968;&#25454;&#20998;&#24067;&#24046;&#24322;&#23548;&#33268;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#20855;&#26377;&#19981;&#21516;&#34920;&#36798;&#20064;&#24815;&#21644;&#29305;&#24449;&#30340;&#19981;&#21516;&#20027;&#39064;&#65292;MIU&#27169;&#22411;&#24456;&#23481;&#26131;&#34987;&#35823;&#23548;&#65292;&#20197;&#23398;&#20064;&#29305;&#23450;&#20110;&#20027;&#39064;&#30340;&#20266;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#26174;&#30528;&#38480;&#21046;&#20102;&#36328;&#26410;&#25509;&#35302;&#20027;&#39064;&#30340;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#21463;&#36825;&#19968;&#35266;&#23519;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#27010;&#25324;&#24615;&#22240;&#26524;&#22270;&#26469;&#21046;&#23450;MIU&#36807;&#31243;&#65292;&#24182;&#20998;&#26512;&#20027;&#39064;&#30340;&#28151;&#28102;&#25928;&#24212;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SuCI&#65292;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22240;&#26524;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05025v1 Announce Type: new  Abstract: Multimodal intention understanding (MIU) is an indispensable component of human expression analysis (e.g., sentiment or humor) from heterogeneous modalities, including visual postures, linguistic contents, and acoustic behaviors. Existing works invariably focus on designing sophisticated structures or fusion strategies to achieve impressive improvements. Unfortunately, they all suffer from the subject variation problem due to data distribution discrepancies among subjects. Concretely, MIU models are easily misled by distinct subjects with different expression customs and characteristics in the training data to learn subject-specific spurious correlations, significantly limiting performance and generalizability across uninitiated subjects.Motivated by this observation, we introduce a recapitulative causal graph to formulate the MIU procedure and analyze the confounding effect of subjects. Then, we propose SuCI, a simple yet effective caus
&lt;/p&gt;</description></item><item><title>TreeEval&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#22522;&#20934;&#35780;&#20272;&#26041;&#27861;&#65292;&#36890;&#36807;&#26641;&#35268;&#21010;&#31574;&#30053;&#25552;&#21319;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35780;&#20272;&#25928;&#29575;&#21644;&#23436;&#25972;&#24615;</title><link>https://arxiv.org/abs/2402.13125</link><description>&lt;p&gt;
TreeEval&#65306;&#36890;&#36807;&#26641;&#35268;&#21010;&#23454;&#29616;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26080;&#22522;&#20934;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13125
&lt;/p&gt;
&lt;p&gt;
TreeEval&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#22522;&#20934;&#35780;&#20272;&#26041;&#27861;&#65292;&#36890;&#36807;&#26641;&#35268;&#21010;&#31574;&#30053;&#25552;&#21319;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35780;&#20272;&#25928;&#29575;&#21644;&#23436;&#25972;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#24314;&#31435;&#20102;&#35768;&#22810;&#26032;&#30340;&#22522;&#20934;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#35745;&#31639;&#25972;&#20307;&#24471;&#20998;&#25110;&#20351;&#29992;&#21478;&#19968;&#20010;LLM&#20316;&#20026;&#35780;&#21028;&#32773;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#30001;&#20110;&#22522;&#20934;&#30340;&#20844;&#24320;&#35775;&#38382;&#21644;&#35780;&#20272;&#36807;&#31243;&#30340;&#19981;&#28789;&#27963;&#32780;&#36973;&#21463;&#25968;&#25454;&#27844;&#28431;&#30340;&#22256;&#25200;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;TreeEval&#65292;&#36825;&#26159;&#19968;&#31181;&#26080;&#22522;&#20934;&#35780;&#20272;&#26041;&#27861;&#65292;&#35753;&#19968;&#20010;&#39640;&#24615;&#33021;&#30340;LLM&#20027;&#25345;&#19968;&#20010;&#19981;&#21487;&#37325;&#29616;&#30340;&#35780;&#20272;&#20250;&#35805;&#65292;&#20174;&#26681;&#26412;&#19978;&#36991;&#20813;&#20102;&#25968;&#25454;&#27844;&#28431;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;LLM&#20805;&#24403;&#19968;&#20010;&#32771;&#23448;&#65292;&#25552;&#20986;&#19968;&#31995;&#21015;&#20851;&#20110;&#19968;&#20010;&#20027;&#39064;&#30340;&#38382;&#39064;&#65292;&#24182;&#37319;&#29992;&#26641;&#35268;&#21010;&#31574;&#30053;&#65292;&#32771;&#34385;&#24403;&#21069;&#30340;&#35780;&#20272;&#29366;&#24577;&#26469;&#20915;&#23450;&#19979;&#19968;&#20010;&#38382;&#39064;&#30340;&#29983;&#25104;&#65292;&#30830;&#20445;&#35780;&#20272;&#36807;&#31243;&#30340;&#23436;&#25972;&#24615;&#21644;&#25928;&#29575;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#19981;&#21516;&#21442;&#25968;&#22823;&#23567;&#30340;6&#20010;&#27169;&#22411;&#65292;&#21253;&#25324;7B&#12289;13B&#21644;33B&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#26368;&#39640;&#30340;&#30456;&#20851;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13125v1 Announce Type: cross  Abstract: Recently, numerous new benchmarks have been established to evaluate the performance of large language models (LLMs) via either computing a holistic score or employing another LLM as a judge. However, these approaches suffer from data leakage due to the open access of the benchmark and inflexible evaluation process. To address this issue, we introduce $\textbf{TreeEval}$, a benchmark-free evaluation method for LLMs that let a high-performance LLM host an irreproducible evaluation session and essentially avoids the data leakage. Moreover, this LLM performs as an examiner to raise up a series of questions under a topic with a tree planing strategy, which considers the current evaluation status to decide the next question generation and ensures the completeness and efficiency of the evaluation process. We evaluate $6$ models of different parameter sizes, including $7$B, $13$B, and $33$B, and ultimately achieved the highest correlation coef
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22266;&#20307;&#24223;&#29289;&#22312;&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#26816;&#27979;&#26041;&#27861;&#12290;&#30740;&#31350;&#32773;&#21033;&#29992;&#22320;&#29699;&#35266;&#27979;&#21355;&#26143;&#25552;&#20379;&#30340;&#39640;&#20998;&#36776;&#29575;&#25968;&#25454;&#65292;&#36890;&#36807;&#36965;&#24863;&#22270;&#20687;&#23454;&#29616;&#20102;&#22266;&#20307;&#24223;&#29289;&#22788;&#32622;&#22330;&#22320;&#30340;&#35782;&#21035;&#12289;&#30417;&#27979;&#21644;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2402.09066</link><description>&lt;p&gt;
&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#22266;&#20307;&#24223;&#29289;&#26816;&#27979;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Solid Waste Detection in Remote Sensing Images: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22266;&#20307;&#24223;&#29289;&#22312;&#36965;&#24863;&#22270;&#20687;&#20013;&#30340;&#26816;&#27979;&#26041;&#27861;&#12290;&#30740;&#31350;&#32773;&#21033;&#29992;&#22320;&#29699;&#35266;&#27979;&#21355;&#26143;&#25552;&#20379;&#30340;&#39640;&#20998;&#36776;&#29575;&#25968;&#25454;&#65292;&#36890;&#36807;&#36965;&#24863;&#22270;&#20687;&#23454;&#29616;&#20102;&#22266;&#20307;&#24223;&#29289;&#22788;&#32622;&#22330;&#22320;&#30340;&#35782;&#21035;&#12289;&#30417;&#27979;&#21644;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21644;&#34920;&#24449;&#38750;&#27861;&#22266;&#20307;&#24223;&#29289;&#22788;&#32622;&#22330;&#22320;&#23545;&#29615;&#22659;&#20445;&#25252;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#24212;&#23545;&#27745;&#26579;&#21644;&#20581;&#24247;&#21361;&#23475;&#12290;&#19981;&#24403;&#31649;&#29702;&#30340;&#22403;&#22334;&#22635;&#22475;&#22330;&#36890;&#36807;&#38632;&#27700;&#28183;&#36879;&#27745;&#26579;&#22303;&#22756;&#21644;&#22320;&#19979;&#27700;&#65292;&#23545;&#21160;&#29289;&#21644;&#20154;&#31867;&#26500;&#25104;&#23041;&#32961;&#12290;&#20256;&#32479;&#30340;&#22635;&#22475;&#22330;&#36776;&#35782;&#26041;&#27861;&#65292;&#22914;&#29616;&#22330;&#26816;&#26597;&#65292;&#32791;&#26102;&#19988;&#26114;&#36149;&#12290;&#36965;&#24863;&#25216;&#26415;&#26159;&#29992;&#20110;&#35782;&#21035;&#21644;&#30417;&#27979;&#22266;&#20307;&#24223;&#29289;&#22788;&#32622;&#22330;&#22320;&#30340;&#19968;&#31181;&#32463;&#27982;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#23454;&#29616;&#24191;&#27867;&#35206;&#30422;&#21644;&#22810;&#27425;&#33719;&#21462;&#12290;&#22320;&#29699;&#35266;&#27979;&#65288;EO&#65289;&#21355;&#26143;&#37197;&#22791;&#20102;&#19968;&#31995;&#21015;&#20256;&#24863;&#22120;&#21644;&#25104;&#20687;&#33021;&#21147;&#65292;&#20960;&#21313;&#24180;&#26469;&#19968;&#30452;&#25552;&#20379;&#39640;&#20998;&#36776;&#29575;&#30340;&#25968;&#25454;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#19987;&#38376;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#36965;&#24863;&#22270;&#20687;&#25191;&#34892;&#19968;&#31995;&#21015;&#20219;&#21153;&#65292;&#22914;&#24223;&#29289;&#22330;&#22320;&#26816;&#27979;&#12289;&#20542;&#20498;&#22330;&#30417;&#27979;&#21644;&#36866;&#23452;&#20301;&#32622;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09066v1 Announce Type: cross Abstract: The detection and characterization of illegal solid waste disposal sites are essential for environmental protection, particularly for mitigating pollution and health hazards. Improperly managed landfills contaminate soil and groundwater via rainwater infiltration, posing threats to both animals and humans. Traditional landfill identification approaches, such as on-site inspections, are time-consuming and expensive. Remote sensing is a cost-effective solution for the identification and monitoring of solid waste disposal sites that enables broad coverage and repeated acquisitions over time. Earth Observation (EO) satellites, equipped with an array of sensors and imaging capabilities, have been providing high-resolution data for several decades. Researchers proposed specialized techniques that leverage remote sensing imagery to perform a range of tasks such as waste site detection, dumping site monitoring, and assessment of suitable locati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;IRLEED&#65292;&#23427;&#36890;&#36807;&#20272;&#35745;&#28436;&#31034;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#26469;&#35299;&#20915;&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#27425;&#20248;&#21644;&#24322;&#36136;&#28436;&#31034;&#30340;&#38382;&#39064;&#12290;IRLEED&#36890;&#36807;&#32467;&#21512;&#28436;&#31034;&#32773;&#27425;&#20248;&#24615;&#30340;&#26222;&#36866;&#27169;&#22411;&#21644;&#26368;&#22823;&#29109;IRL&#26694;&#26550;&#65292;&#26377;&#25928;&#22320;&#20174;&#22810;&#26679;&#30340;&#27425;&#20248;&#28436;&#31034;&#20013;&#24471;&#20986;&#26368;&#20339;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.01886</link><description>&lt;p&gt;
&#36890;&#36807;&#20272;&#35745;&#28436;&#31034;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#30340;&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Inverse Reinforcement Learning by Estimating Expertise of Demonstrators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;IRLEED&#65292;&#23427;&#36890;&#36807;&#20272;&#35745;&#28436;&#31034;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#26469;&#35299;&#20915;&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#27425;&#20248;&#21644;&#24322;&#36136;&#28436;&#31034;&#30340;&#38382;&#39064;&#12290;IRLEED&#36890;&#36807;&#32467;&#21512;&#28436;&#31034;&#32773;&#27425;&#20248;&#24615;&#30340;&#26222;&#36866;&#27169;&#22411;&#21644;&#26368;&#22823;&#29109;IRL&#26694;&#26550;&#65292;&#26377;&#25928;&#22320;&#20174;&#22810;&#26679;&#30340;&#27425;&#20248;&#28436;&#31034;&#20013;&#24471;&#20986;&#26368;&#20339;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27169;&#20223;&#23398;&#20064;&#20013;&#65292;&#21033;&#29992;&#27425;&#20248;&#21644;&#24322;&#36136;&#30340;&#28436;&#31034;&#25552;&#20986;&#20102;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#24615;&#36136;&#21508;&#19981;&#30456;&#21516;&#12290;&#28982;&#32780;&#65292;&#26631;&#20934;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;&#23558;&#36825;&#20123;&#25968;&#25454;&#38598;&#35270;&#20026;&#21516;&#36136;&#30340;&#65292;&#20174;&#32780;&#32487;&#25215;&#20102;&#27425;&#20248;&#28436;&#31034;&#30340;&#32570;&#38519;&#12290;&#20808;&#21069;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#65292;&#22914;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#23376;&#38598;&#12289;&#32622;&#20449;&#24230;&#25490;&#21517;&#25110;&#26126;&#30830;&#30340;&#29615;&#22659;&#30693;&#35782;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;IRLEED&#65288;&#36890;&#36807;&#20272;&#35745;&#28436;&#31034;&#32773;&#30340;&#19987;&#19994;&#30693;&#35782;&#30340;&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#20811;&#26381;&#36825;&#20123;&#38556;&#30861;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#21069;&#23545;&#28436;&#31034;&#32773;&#19987;&#19994;&#30693;&#35782;&#36827;&#34892;&#20102;&#35299;&#12290;IRLEED&#36890;&#36807;&#23558;&#28436;&#31034;&#32773;&#27425;&#20248;&#24615;&#30340;&#26222;&#36866;&#27169;&#22411;&#19982;&#26368;&#22823;&#29109;IRL&#26694;&#26550;&#30456;&#32467;&#21512;&#65292;&#26469;&#22788;&#29702;&#22870;&#21169;&#20559;&#24046;&#21644;&#34892;&#21160;&#26041;&#24046;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#20174;&#22810;&#26679;&#30340;&#27425;&#20248;&#28436;&#31034;&#20013;&#24471;&#20986;&#26368;&#20248;&#31574;&#30053;&#12290;&#22312;&#22312;&#32447;&#21644;&#31163;&#32447;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Imitation Learning (IL), utilizing suboptimal and heterogeneous demonstrations presents a substantial challenge due to the varied nature of real-world data. However, standard IL algorithms consider these datasets as homogeneous, thereby inheriting the deficiencies of suboptimal demonstrators. Previous approaches to this issue typically rely on impractical assumptions like high-quality data subsets, confidence rankings, or explicit environmental knowledge. This paper introduces IRLEED, Inverse Reinforcement Learning by Estimating Expertise of Demonstrators, a novel framework that overcomes these hurdles without prior knowledge of demonstrator expertise. IRLEED enhances existing Inverse Reinforcement Learning (IRL) algorithms by combining a general model for demonstrator suboptimality to address reward bias and action variance, with a Maximum Entropy IRL framework to efficiently derive the optimal policy from diverse, suboptimal demonstrations. Experiments in both online and offline I
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#29983;&#25104;&#24189;&#28789;&#30340;&#28508;&#22312;&#23454;&#26045;&#35774;&#35745;&#31354;&#38388;&#21644;&#20854;&#23545;&#20010;&#20154;&#21644;&#31038;&#20250;&#30340;&#23454;&#38469;&#21644;&#20262;&#29702;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#30740;&#31350;&#35758;&#31243;&#20197;&#20415;&#20351;&#20154;&#20204;&#33021;&#22815;&#23433;&#20840;&#32780;&#26377;&#30410;&#22320;&#21019;&#24314;&#21644;&#19982;&#20154;&#24037;&#26234;&#33021;&#26469;&#19990;&#36827;&#34892;&#20114;&#21160;&#12290;</title><link>https://arxiv.org/abs/2402.01662</link><description>&lt;p&gt;
&#29983;&#25104;&#24189;&#28789;&#65306;&#39044;&#27979;&#20154;&#24037;&#26234;&#33021;&#26469;&#19990;&#30340;&#30410;&#22788;&#21644;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01662
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#29983;&#25104;&#24189;&#28789;&#30340;&#28508;&#22312;&#23454;&#26045;&#35774;&#35745;&#31354;&#38388;&#21644;&#20854;&#23545;&#20010;&#20154;&#21644;&#31038;&#20250;&#30340;&#23454;&#38469;&#21644;&#20262;&#29702;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#30740;&#31350;&#35758;&#31243;&#20197;&#20415;&#20351;&#20154;&#20204;&#33021;&#22815;&#23433;&#20840;&#32780;&#26377;&#30410;&#22320;&#21019;&#24314;&#21644;&#19982;&#20154;&#24037;&#26234;&#33021;&#26469;&#19990;&#36827;&#34892;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#24615;&#33021;&#30340;&#24191;&#24230;&#21644;&#28145;&#24230;&#19978;&#36805;&#36895;&#25552;&#21319;&#65292;&#23427;&#20204;&#36234;&#26469;&#36234;&#36866;&#21512;&#21019;&#24314;&#21151;&#33021;&#24378;&#22823;&#12289;&#36924;&#30495;&#30340;&#20195;&#29702;&#20154;&#65292;&#21253;&#25324;&#22522;&#20110;&#29305;&#23450;&#20154;&#29289;&#24314;&#27169;&#30340;&#20195;&#29702;&#20154;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#39044;&#35745;&#65292;&#22312;&#25105;&#20204;&#26377;&#29983;&#20043;&#24180;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#26222;&#36941;&#20351;&#29992;&#23450;&#21046;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#20154;&#19982;&#29233;&#30340;&#20154;&#21644;/&#25110;&#26356;&#24191;&#22823;&#30340;&#19990;&#30028;&#36827;&#34892;&#20114;&#21160;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#29983;&#25104;&#24189;&#28789;&#65292;&#22240;&#20026;&#36825;&#20123;&#20195;&#29702;&#20154;&#23558;&#33021;&#22815;&#29983;&#25104;&#26032;&#39062;&#30340;&#20869;&#23481;&#65292;&#32780;&#19981;&#21482;&#26159;&#22797;&#36848;&#20854;&#21019;&#20316;&#32773;&#22312;&#29983;&#21069;&#30340;&#20869;&#23481;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#35752;&#35770;&#20102;&#29983;&#25104;&#24189;&#28789;&#28508;&#22312;&#23454;&#26045;&#30340;&#35774;&#35745;&#31354;&#38388;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#29983;&#25104;&#24189;&#28789;&#30340;&#23454;&#38469;&#21644;&#20262;&#29702;&#24433;&#21709;&#65292;&#21253;&#25324;&#23545;&#20010;&#20154;&#21644;&#31038;&#20250;&#30340;&#28508;&#22312;&#31215;&#26497;&#21644;&#28040;&#26497;&#24433;&#21709;&#12290;&#22522;&#20110;&#36825;&#20123;&#32771;&#34385;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#30740;&#31350;&#35758;&#31243;&#65292;&#26088;&#22312;&#20351;&#20154;&#20204;&#33021;&#22815;&#23433;&#20840;&#32780;&#26377;&#30410;&#22320;&#21019;&#24314;&#21644;&#19982;&#20154;&#24037;&#26234;&#33021;&#26469;&#19990;&#36827;&#34892;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
As AI systems quickly improve in both breadth and depth of performance, they lend themselves to creating increasingly powerful and realistic agents, including the possibility of agents modeled on specific people. We anticipate that within our lifetimes it may become common practice for people to create a custom AI agent to interact with loved ones and/or the broader world after death. We call these generative ghosts, since such agents will be capable of generating novel content rather than merely parroting content produced by their creator while living. In this paper, we first discuss the design space of potential implementations of generative ghosts. We then discuss the practical and ethical implications of generative ghosts, including potential positive and negative impacts on individuals and society. Based on these considerations, we lay out a research agenda for the AI and HCI research communities to empower people to create and interact with AI afterlives in a safe and beneficial 
&lt;/p&gt;</description></item><item><title>AgentMixer&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20801;&#35768;&#26234;&#33021;&#20307;&#36890;&#36807;&#31574;&#30053;&#20462;&#25913;&#26469;&#23454;&#29616;&#21327;&#21516;&#20915;&#31574;&#12290;&#36890;&#36807;&#26500;&#36896;&#32852;&#21512;&#31574;&#30053;&#20026;&#21508;&#20010;&#37096;&#20998;&#31574;&#30053;&#30340;&#38750;&#32447;&#24615;&#32452;&#21512;&#65292;&#21487;&#23454;&#29616;&#37096;&#20998;&#21487;&#35266;&#27979;&#26234;&#33021;&#20307;&#30340;&#31283;&#23450;&#35757;&#32451;&#21644;&#20998;&#25955;&#25191;&#34892;&#12290;</title><link>http://arxiv.org/abs/2401.08728</link><description>&lt;p&gt;
AgentMixer: &#22810;&#26234;&#33021;&#20307;&#30456;&#20851;&#31574;&#30053;&#22240;&#23376;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
AgentMixer: Multi-Agent Correlated Policy Factorization. (arXiv:2401.08728v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08728
&lt;/p&gt;
&lt;p&gt;
AgentMixer&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20801;&#35768;&#26234;&#33021;&#20307;&#36890;&#36807;&#31574;&#30053;&#20462;&#25913;&#26469;&#23454;&#29616;&#21327;&#21516;&#20915;&#31574;&#12290;&#36890;&#36807;&#26500;&#36896;&#32852;&#21512;&#31574;&#30053;&#20026;&#21508;&#20010;&#37096;&#20998;&#31574;&#30053;&#30340;&#38750;&#32447;&#24615;&#32452;&#21512;&#65292;&#21487;&#23454;&#29616;&#37096;&#20998;&#21487;&#35266;&#27979;&#26234;&#33021;&#20307;&#30340;&#31283;&#23450;&#35757;&#32451;&#21644;&#20998;&#25955;&#25191;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#20013;&#24335;&#35757;&#32451;&#19982;&#20998;&#25955;&#24335;&#25191;&#34892;&#65288;CTDE&#65289;&#24191;&#27867;&#24212;&#29992;&#20110;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21033;&#29992;&#38598;&#20013;&#24335;&#20540;&#20989;&#25968;&#26469;&#31283;&#23450;&#37096;&#20998;&#21487;&#35266;&#23519;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#26234;&#33021;&#20307;&#22522;&#20110;&#26412;&#22320;&#35266;&#27979;&#29420;&#31435;&#22320;&#20570;&#20915;&#31574;&#65292;&#36825;&#21487;&#33021;&#19981;&#20250;&#23548;&#33268;&#20855;&#26377;&#36275;&#22815;&#21327;&#35843;&#24615;&#30340;&#30456;&#20851;&#32852;&#30340;&#32852;&#21512;&#31574;&#30053;&#12290;&#21463;&#30456;&#20851;&#22343;&#34913;&#27010;&#24565;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#24341;&#20837;"&#31574;&#30053;&#20462;&#25913;"&#26469;&#20026;&#26234;&#33021;&#20307;&#25552;&#20379;&#21327;&#35843;&#31574;&#30053;&#30340;&#26426;&#21046;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;AgentMixer&#65292;&#23558;&#32852;&#21512;&#23436;&#20840;&#21487;&#35266;&#27979;&#31574;&#30053;&#26500;&#36896;&#20026;&#21508;&#20010;&#37096;&#20998;&#21487;&#35266;&#27979;&#31574;&#30053;&#30340;&#38750;&#32447;&#24615;&#32452;&#21512;&#12290;&#20026;&#20102;&#23454;&#29616;&#20998;&#25955;&#24335;&#25191;&#34892;&#65292;&#21487;&#20197;&#36890;&#36807;&#27169;&#20223;&#32852;&#21512;&#31574;&#30053;&#26469;&#24471;&#21040;&#21508;&#20010;&#37096;&#20998;&#31574;&#30053;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#31181;&#27169;&#20223;&#23398;&#20064;&#21487;&#33021;&#20250;&#23548;&#33268;&#30001;&#20110;&#32852;&#21512;&#31574;&#30053;&#21644;&#20010;&#20307;&#31574;&#30053;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#32780;&#23548;&#33268;&#30340;&#38750;&#23545;&#31216;&#23398;&#20064;&#22833;&#36133;&#12290;
&lt;/p&gt;
&lt;p&gt;
Centralized training with decentralized execution (CTDE) is widely employed to stabilize partially observable multi-agent reinforcement learning (MARL) by utilizing a centralized value function during training. However, existing methods typically assume that agents make decisions based on their local observations independently, which may not lead to a correlated joint policy with sufficient coordination. Inspired by the concept of correlated equilibrium, we propose to introduce a \textit{strategy modification} to provide a mechanism for agents to correlate their policies. Specifically, we present a novel framework, AgentMixer, which constructs the joint fully observable policy as a non-linear combination of individual partially observable policies. To enable decentralized execution, one can derive individual policies by imitating the joint policy. Unfortunately, such imitation learning can lead to \textit{asymmetric learning failure} caused by the mismatch between joint policy and indi
&lt;/p&gt;</description></item><item><title>&#20010;&#20307;&#21270;&#26102;&#38388;&#24207;&#21015;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#29983;&#25104;&#27169;&#22411;IGNITE&#36890;&#36807;&#23398;&#20064;&#20010;&#20307;&#30340;&#21160;&#24577;&#29305;&#24449;&#65292;&#32467;&#21512;&#20154;&#21475;&#29305;&#24449;&#21644;&#27835;&#30103;&#20449;&#24687;&#65292;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#30495;&#23454;&#20540;&#65292;&#20026;&#20010;&#20307;&#21270;&#21307;&#30103;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.04402</link><description>&lt;p&gt;
IGNITE: &#20010;&#20307;&#21270;&#26102;&#38388;&#24207;&#21015;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
IGNITE: Individualized GeNeration of Imputations in Time-series Electronic health records. (arXiv:2401.04402v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04402
&lt;/p&gt;
&lt;p&gt;
&#20010;&#20307;&#21270;&#26102;&#38388;&#24207;&#21015;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#29983;&#25104;&#27169;&#22411;IGNITE&#36890;&#36807;&#23398;&#20064;&#20010;&#20307;&#30340;&#21160;&#24577;&#29305;&#24449;&#65292;&#32467;&#21512;&#20154;&#21475;&#29305;&#24449;&#21644;&#27835;&#30103;&#20449;&#24687;&#65292;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#30495;&#23454;&#20540;&#65292;&#20026;&#20010;&#20307;&#21270;&#21307;&#30103;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20026;&#25512;&#21160;&#20010;&#20307;&#21270;&#21307;&#30103;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#26041;&#24335;&#65292;&#21487;&#20197;&#26681;&#25454;&#20010;&#20307;&#24046;&#24322;&#37327;&#36523;&#23450;&#21046;&#27835;&#30103;&#26041;&#26696;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#35768;&#22810;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#20511;&#21161;&#20016;&#23500;&#30340;&#32437;&#21521;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#26469;&#30740;&#31350;&#24739;&#32773;&#30340;&#29983;&#29702;&#21644;&#27835;&#30103;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#32437;&#21521;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#24448;&#24448;&#31232;&#30095;&#19988;&#23384;&#22312;&#22823;&#37327;&#32570;&#22833;&#65292;&#20854;&#20013;&#32570;&#22833;&#30340;&#20449;&#24687;&#20063;&#21487;&#33021;&#21453;&#26144;&#24739;&#32773;&#30340;&#20581;&#24247;&#29366;&#20917;&#12290;&#22240;&#27492;&#65292;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#22312;&#20010;&#20307;&#21270;&#21307;&#30103;&#20013;&#30340;&#25104;&#21151;&#20005;&#37325;&#20381;&#36182;&#20110;&#22914;&#20309;&#20174;&#29983;&#29702;&#25968;&#25454;&#12289;&#27835;&#30103;&#20197;&#21450;&#25968;&#25454;&#20013;&#30340;&#32570;&#22833;&#20540;&#26469;&#34920;&#31034;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#22312;&#20010;&#20307;&#30340;&#20154;&#21475;&#29305;&#24449;&#21644;&#27835;&#30103;&#30340;&#26465;&#20214;&#19979;&#65292;&#23398;&#20064;&#22810;&#21464;&#37327;&#25968;&#25454;&#30340;&#24739;&#32773;&#21160;&#24577;&#65292;&#24182;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#30495;&#23454;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Electronic Health Records present a valuable modality for driving personalized medicine, where treatment is tailored to fit individual-level differences. For this purpose, many data-driven machine learning and statistical models rely on the wealth of longitudinal EHRs to study patients' physiological and treatment effects. However, longitudinal EHRs tend to be sparse and highly missing, where missingness could also be informative and reflect the underlying patient's health status. Therefore, the success of data-driven models for personalized medicine highly depends on how the EHR data is represented from physiological data, treatments, and the missing values in the data. To this end, we propose a novel deep-learning model that learns the underlying patient dynamics over time across multivariate data to generate personalized realistic values conditioning on an individual's demographic characteristics and treatments. Our proposed model, IGNITE (Individualized GeNeration of Imputations in
&lt;/p&gt;</description></item></channel></rss>