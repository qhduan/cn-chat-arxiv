<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;Grover&#21644;Deutsch-Josza&#31561;&#22522;&#30784;&#37327;&#23376;&#31639;&#27861;&#65292;&#36890;&#36807;&#19968;&#32452;&#31934;&#24515;&#26500;&#24314;&#30340;&#26465;&#20214;&#65292;&#25512;&#26029;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#27573;&#26102;&#38388;&#20869;&#26159;&#21542;&#20855;&#26377;&#32487;&#32493;&#32500;&#25345;&#21160;&#24577;&#27963;&#21160;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.18963</link><description>&lt;p&gt;
&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#25512;&#26029;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#21160;&#24577;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Using Quantum Computing to Infer Dynamic Behaviors of Biological and Artificial Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;Grover&#21644;Deutsch-Josza&#31561;&#22522;&#30784;&#37327;&#23376;&#31639;&#27861;&#65292;&#36890;&#36807;&#19968;&#32452;&#31934;&#24515;&#26500;&#24314;&#30340;&#26465;&#20214;&#65292;&#25512;&#26029;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#27573;&#26102;&#38388;&#20869;&#26159;&#21542;&#20855;&#26377;&#32487;&#32493;&#32500;&#25345;&#21160;&#24577;&#27963;&#21160;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#38382;&#39064;&#31867;&#21035;&#30340;&#25506;&#32034;&#26159;&#37327;&#23376;&#35745;&#31639;&#30740;&#31350;&#30340;&#19968;&#20010;&#27963;&#36291;&#39046;&#22495;&#12290;&#19968;&#20010;&#22522;&#26412;&#19978;&#23436;&#20840;&#26410;&#34987;&#25506;&#35752;&#30340;&#20027;&#39064;&#26159;&#20351;&#29992;&#37327;&#23376;&#31639;&#27861;&#21644;&#35745;&#31639;&#26469;&#25506;&#32034;&#21644;&#35810;&#38382;&#31070;&#32463;&#32593;&#32476;&#30340;&#21151;&#33021;&#21160;&#24577;&#12290;&#36825;&#26159;&#23558;&#37327;&#23376;&#35745;&#31639;&#24212;&#29992;&#20110;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#21644;&#20223;&#30495;&#30340;&#23578;&#26410;&#25104;&#29087;&#30340;&#20027;&#39064;&#30340;&#19968;&#20010;&#32452;&#25104;&#37096;&#20998;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#31934;&#24515;&#26500;&#24314;&#30340;&#19968;&#32452;&#26465;&#20214;&#26469;&#20351;&#29992;&#20004;&#20010;&#22522;&#30784;&#37327;&#23376;&#31639;&#27861;&#65292;Grover&#21644;Deutsch-Josza&#65292;&#20197;&#20351;&#36755;&#20986;&#27979;&#37327;&#20855;&#26377;&#19968;&#31181;&#35299;&#37322;&#65292;&#20445;&#35777;&#25105;&#20204;&#33021;&#22815;&#25512;&#26029;&#19968;&#20010;&#31616;&#21333;&#30340;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#65288;&#36866;&#29992;&#20110;&#29983;&#29289;&#21644;&#20154;&#24037;&#32593;&#32476;&#65289;&#22312;&#19968;&#27573;&#26102;&#38388;&#21518;&#26159;&#21542;&#26377;&#21487;&#33021;&#32487;&#32493;&#32500;&#25345;&#21160;&#24577;&#27963;&#21160;&#12290;&#25110;&#32773;&#36825;&#20123;&#21160;&#24577;&#20445;&#35777;&#20250;&#20572;&#27490;&#65292;&#35201;&#20040;&#26159;&#36890;&#36807;'&#30315;&#30187;'&#21160;&#24577;&#65292;&#35201;&#20040;&#26159;&#38745;&#27490;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18963v1 Announce Type: cross  Abstract: The exploration of new problem classes for quantum computation is an active area of research. An essentially completely unexplored topic is the use of quantum algorithms and computing to explore and ask questions \textit{about} the functional dynamics of neural networks. This is a component of the still-nascent topic of applying quantum computing to the modeling and simulations of biological and artificial neural networks. In this work, we show how a carefully constructed set of conditions can use two foundational quantum algorithms, Grover and Deutsch-Josza, in such a way that the output measurements admit an interpretation that guarantees we can infer if a simple representation of a neural network (which applies to both biological and artificial networks) after some period of time has the potential to continue sustaining dynamic activity. Or whether the dynamics are guaranteed to stop either through 'epileptic' dynamics or quiescence
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#26088;&#22312;&#25552;&#39640;LLM&#22312;&#22270;&#25968;&#25454;&#20013;&#30340;&#20851;&#31995;&#25366;&#25496;&#25928;&#29575;&#21644;&#33021;&#21147;&#65292;&#36890;&#36807;&#25972;&#21512;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#21033;&#29992;&#36793;&#32536;&#20449;&#24687;&#26469;&#29702;&#35299;&#22797;&#26434;&#33410;&#28857;&#20851;&#31995;&#65292;&#24182;&#20174;&#22270;&#32467;&#26500;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#27934;&#35265;&#12290;</title><link>https://arxiv.org/abs/2402.09617</link><description>&lt;p&gt;
&#22686;&#24378;LLM&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#65306;&#21033;&#29992;&#36793;&#32536;&#20449;&#24687;&#36827;&#34892;&#20248;&#21270;&#25512;&#33616;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09617
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#26088;&#22312;&#25552;&#39640;LLM&#22312;&#22270;&#25968;&#25454;&#20013;&#30340;&#20851;&#31995;&#25366;&#25496;&#25928;&#29575;&#21644;&#33021;&#21147;&#65292;&#36890;&#36807;&#25972;&#21512;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#21033;&#29992;&#36793;&#32536;&#20449;&#24687;&#26469;&#29702;&#35299;&#22797;&#26434;&#33410;&#28857;&#20851;&#31995;&#65292;&#24182;&#20174;&#22270;&#32467;&#26500;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#33394;&#24615;&#33021;&#19981;&#20165;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#30740;&#31350;&#26684;&#23616;&#65292;&#36824;&#23637;&#31034;&#20102;&#23427;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#21331;&#36234;&#24212;&#29992;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#25366;&#25496;&#22270;&#25968;&#25454;&#20013;&#30340;&#20851;&#31995;&#26041;&#38754;&#30340;&#28508;&#21147;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#36817;&#24180;&#26469;&#28909;&#38376;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#22312;&#20851;&#31995;&#25366;&#25496;&#26041;&#38754;&#26377;&#22823;&#37327;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#23574;&#31471;&#30740;&#31350;&#23578;&#26410;&#26377;&#25928;&#25972;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#23548;&#33268;&#22312;&#22270;&#20851;&#31995;&#25366;&#25496;&#20219;&#21153;&#20013;&#30340;&#25928;&#29575;&#21644;&#33021;&#21147;&#21463;&#38480;&#12290;&#19968;&#20010;&#20027;&#35201;&#30340;&#25361;&#25112;&#26159;LLM&#26080;&#27861;&#28145;&#20837;&#21033;&#29992;&#22270;&#20013;&#30340;&#36793;&#32536;&#20449;&#24687;&#65292;&#32780;&#36825;&#23545;&#20110;&#29702;&#35299;&#22797;&#26434;&#33410;&#28857;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#31181;&#24046;&#36317;&#38480;&#21046;&#20102;LLM&#20174;&#22270;&#32467;&#26500;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#27934;&#35265;&#30340;&#28508;&#21147;&#65292;&#38480;&#21046;&#20102;&#23427;&#22312;&#26356;&#22797;&#26434;&#30340;&#22522;&#20110;&#22270;&#30340;&#20998;&#26512;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09617v1 Announce Type: new  Abstract: The extraordinary performance of large language models has not only reshaped the research landscape in the field of NLP but has also demonstrated its exceptional applicative potential in various domains. However, the potential of these models in mining relationships from graph data remains under-explored. Graph neural networks, as a popular research area in recent years, have numerous studies on relationship mining. Yet, current cutting-edge research in graph neural networks has not been effectively integrated with large language models, leading to limited efficiency and capability in graph relationship mining tasks. A primary challenge is the inability of LLMs to deeply exploit the edge information in graphs, which is critical for understanding complex node relationships. This gap limits the potential of LLMs to extract meaningful insights from graph structures, limiting their applicability in more complex graph-based analysis. We focus
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Boosting&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.14890</link><description>&lt;p&gt;
Boosting&#29992;&#20110;&#30028;&#23450;&#26368;&#24046;&#20998;&#31867;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Boosting for Bounding the Worst-class Error. (arXiv:2310.14890v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14890
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Boosting&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#26368;&#24046;&#31867;&#21035;&#35823;&#24046;&#29575;&#30340;&#38382;&#39064;&#65292;&#32780;&#19981;&#26159;&#38024;&#23545;&#25152;&#26377;&#31867;&#21035;&#30340;&#26631;&#20934;&#35823;&#24046;&#29575;&#30340;&#24179;&#22343;&#12290;&#20363;&#22914;&#65292;&#19968;&#20010;&#19977;&#31867;&#21035;&#20998;&#31867;&#20219;&#21153;&#65292;&#20854;&#20013;&#21508;&#31867;&#21035;&#30340;&#35823;&#24046;&#29575;&#20998;&#21035;&#20026;10&#65285;&#65292;10&#65285;&#21644;40&#65285;&#65292;&#20854;&#26368;&#24046;&#31867;&#21035;&#35823;&#24046;&#29575;&#20026;40&#65285;&#65292;&#32780;&#22312;&#31867;&#21035;&#24179;&#34913;&#26465;&#20214;&#19979;&#30340;&#24179;&#22343;&#35823;&#24046;&#29575;&#20026;20&#65285;&#12290;&#26368;&#24046;&#31867;&#21035;&#38169;&#35823;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24456;&#37325;&#35201;&#12290;&#20363;&#22914;&#65292;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#23545;&#20110;&#24694;&#24615;&#32959;&#30244;&#31867;&#21035;&#20855;&#26377;40&#65285;&#30340;&#38169;&#35823;&#29575;&#32780;&#33391;&#24615;&#21644;&#20581;&#24247;&#31867;&#21035;&#20855;&#26377;10&#65285;&#30340;&#38169;&#35823;&#29575;&#26159;&#19981;&#33021;&#34987;&#25509;&#21463;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#19978;&#30028;&#30340;&#25552;&#21319;&#31639;&#27861;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#27867;&#21270;&#30028;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#23545;&#35757;&#32451;&#38598;&#30340;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper tackles the problem of the worst-class error rate, instead of the standard error rate averaged over all classes. For example, a three-class classification task with class-wise error rates of 10\%, 10\%, and 40\% has a worst-class error rate of 40\%, whereas the average is 20\% under the class-balanced condition. The worst-class error is important in many applications. For example, in a medical image classification task, it would not be acceptable for the malignant tumor class to have a 40\% error rate, while the benign and healthy classes have 10\% error rates.We propose a boosting algorithm that guarantees an upper bound of the worst-class training error and derive its generalization bound. Experimental results show that the algorithm lowers worst-class test error rates while avoiding overfitting to the training set.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#26469;&#28304;&#22270;&#21644;Transformer&#30340;&#39640;&#32423;&#25345;&#20037;&#24615;&#23041;&#32961;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;Transformer&#30340;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#25552;&#21462;&#31995;&#32479;&#29366;&#24577;&#30340;&#38271;&#26399;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26469;&#28304;&#20998;&#26512;&#23454;&#29616;&#23545;&#38271;&#26399;&#36816;&#34892;&#31995;&#32479;&#30340;&#27010;&#25324;&#65292;&#20197;&#26816;&#27979;&#32531;&#24930;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2304.02838</link><description>&lt;p&gt;
&#22522;&#20110;Transformer&#21644;&#26469;&#28304;&#22270;&#30340;&#39640;&#32423;&#25345;&#20037;&#24615;&#23041;&#32961;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph. (arXiv:2304.02838v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#26469;&#28304;&#22270;&#21644;Transformer&#30340;&#39640;&#32423;&#25345;&#20037;&#24615;&#23041;&#32961;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;Transformer&#30340;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#25552;&#21462;&#31995;&#32479;&#29366;&#24577;&#30340;&#38271;&#26399;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26469;&#28304;&#20998;&#26512;&#23454;&#29616;&#23545;&#38271;&#26399;&#36816;&#34892;&#31995;&#32479;&#30340;&#27010;&#25324;&#65292;&#20197;&#26816;&#27979;&#32531;&#24930;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#39640;&#32423;&#25345;&#20037;&#24615;&#23041;&#32961;&#65288;APT&#65289;&#25915;&#20987;&#30340;&#38271;&#26399;&#28508;&#20239;&#12289;&#38544;&#31192;&#22810;&#38454;&#27573;&#25915;&#20987;&#27169;&#24335;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;APT&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#26469;&#28304;&#22270;&#25552;&#20379;&#30340;&#21382;&#21490;&#20449;&#24687;&#36827;&#34892;APT&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;Transformer&#30340;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#25552;&#21462;&#31995;&#32479;&#29366;&#24577;&#30340;&#38271;&#26399;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26469;&#28304;&#20998;&#26512;&#23454;&#29616;&#23545;&#38271;&#26399;&#36816;&#34892;&#31995;&#32479;&#30340;&#27010;&#25324;&#65292;&#20197;&#26816;&#27979;&#32531;&#24930;&#25915;&#20987;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#24341;&#20837;&#20102;&#24322;&#24120;&#35780;&#20998;&#65292;&#21487;&#35780;&#20272;&#19981;&#21516;&#31995;&#32479;&#29366;&#24577;&#30340;&#24322;&#24120;&#24615;&#12290;&#27599;&#20010;&#29366;&#24577;&#37117;&#26377;&#30456;&#24212;&#30340;&#30456;&#20284;&#24230;&#21644;&#38548;&#31163;&#24230;&#20998;&#25968;&#30340;&#24322;&#24120;&#20998;&#25968;&#35745;&#31639;&#12290;&#20026;&#20102;&#35780;&#20272;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
APT detection is difficult to detect due to the long-term latency, covert and slow multistage attack patterns of Advanced Persistent Threat (APT). To tackle these issues, we propose TBDetector, a transformer-based advanced persistent threat detection method for APT attack detection. Considering that provenance graphs provide rich historical information and have the powerful attacks historic correlation ability to identify anomalous activities, TBDetector employs provenance analysis for APT detection, which summarizes long-running system execution with space efficiency and utilizes transformer with self-attention based encoder-decoder to extract long-term contextual features of system states to detect slow-acting attacks. Furthermore, we further introduce anomaly scores to investigate the anomaly of different system states, where each state is calculated with an anomaly score corresponding to its similarity score and isolation score. To evaluate the effectiveness of the proposed method,
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;&#29616;&#23454;&#19990;&#30028;&#20013;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#25968;&#25454;&#23548;&#21521;&#26550;&#26500;&#65288;DOA&#65289;&#30340;&#37319;&#29992;&#24773;&#20917;&#65292;&#21457;&#29616;&#23613;&#31649;&#27809;&#26377;&#26126;&#30830;&#25552;&#21450;DOA&#65292;&#20294;&#35768;&#22810;&#35770;&#25991;&#20013;&#30340;&#35774;&#35745;&#20915;&#31574;&#40664;&#40664;&#22320;&#36981;&#24490;&#20102;DOA&#30340;&#21407;&#21017;&#12290;</title><link>http://arxiv.org/abs/2302.04810</link><description>&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#65306;&#22522;&#20110;&#25968;&#25454;&#23548;&#21521;&#26550;&#26500;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Real-world Machine Learning Systems: A survey from a Data-Oriented Architecture Perspective. (arXiv:2302.04810v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;&#29616;&#23454;&#19990;&#30028;&#20013;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#25968;&#25454;&#23548;&#21521;&#26550;&#26500;&#65288;DOA&#65289;&#30340;&#37319;&#29992;&#24773;&#20917;&#65292;&#21457;&#29616;&#23613;&#31649;&#27809;&#26377;&#26126;&#30830;&#25552;&#21450;DOA&#65292;&#20294;&#35768;&#22810;&#35770;&#25991;&#20013;&#30340;&#35774;&#35745;&#20915;&#31574;&#40664;&#40664;&#22320;&#36981;&#24490;&#20102;DOA&#30340;&#21407;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;&#20154;&#24037;&#26234;&#33021;&#30340;&#20852;&#36259;&#19981;&#26029;&#22686;&#38271;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#27491;&#22312;&#20316;&#20026;&#29616;&#23454;&#19990;&#30028;&#31995;&#32479;&#30340;&#19968;&#37096;&#20998;&#37096;&#32626;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#35774;&#35745;&#12289;&#23454;&#29616;&#21644;&#32500;&#25252;&#21463;&#21040;&#29616;&#23454;&#19990;&#30028;&#29615;&#22659;&#30340;&#25361;&#25112;&#65292;&#36825;&#20123;&#29615;&#22659;&#20135;&#29983;&#20102;&#26356;&#22810;&#30340;&#24322;&#26500;&#25968;&#25454;&#65292;&#29992;&#25143;&#38656;&#35201;&#26356;&#24555;&#30340;&#21709;&#24212;&#36895;&#24230;&#21644;&#39640;&#25928;&#30340;&#36164;&#28304;&#28040;&#32791;&#12290;&#36825;&#20123;&#35201;&#27714;&#23558;&#26222;&#36941;&#23384;&#22312;&#30340;&#36719;&#20214;&#26550;&#26500;&#25512;&#21521;&#20102;&#26497;&#38480;&#65292;&#24403;&#37096;&#32626;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#31995;&#32479;&#26102;&#12290;&#25968;&#25454;&#23548;&#21521;&#26550;&#26500;&#65288;DOA&#65289;&#26159;&#19968;&#20010;&#26032;&#20852;&#30340;&#27010;&#24565;&#65292;&#23427;&#33021;&#26356;&#22909;&#22320;&#20026;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#31995;&#32479;&#25552;&#20379;&#25903;&#25345;&#12290;DOA&#25193;&#23637;&#20102;&#24403;&#21069;&#30340;&#26550;&#26500;&#65292;&#21019;&#24314;&#20102;&#25968;&#25454;&#39537;&#21160;&#12289;&#26494;&#32806;&#21512;&#12289;&#21435;&#20013;&#24515;&#21270;&#21644;&#24320;&#25918;&#30340;&#31995;&#32479;&#12290;&#23613;&#31649;&#37096;&#32626;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#35770;&#25991;&#20013;&#27809;&#26377;&#25552;&#21040;DOA&#65292;&#20294;&#23427;&#20204;&#30340;&#20316;&#32773;&#22312;&#35774;&#35745;&#19978;&#38544;&#21547;&#22320;&#36981;&#24490;&#20102;DOA&#12290;&#20026;&#20160;&#20040;&#12289;&#22914;&#20309;&#20197;&#21450;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#37319;&#29992;DOA&#22312;&#36825;&#20123;&#31995;&#32479;&#20013;&#23578;&#19981;&#28165;&#26970;&#12290;&#38544;&#21547;&#30340;&#35774;&#35745;&#20915;&#31574;&#38480;&#21046;&#20102;&#20174;&#19994;&#32773;&#23545;&#20110;&#35774;&#35745;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#31995;&#32479;&#26102;DOA&#30340;&#35748;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning models are being deployed as parts of real-world systems with the upsurge of interest in artificial intelligence. The design, implementation, and maintenance of such systems are challenged by real-world environments that produce larger amounts of heterogeneous data and users requiring increasingly faster responses with efficient resource consumption. These requirements push prevalent software architectures to the limit when deploying ML-based systems. Data-oriented Architecture (DOA) is an emerging concept that equips systems better for integrating ML models. DOA extends current architectures to create data-driven, loosely coupled, decentralised, open systems. Even though papers on deployed ML-based systems do not mention DOA, their authors made design decisions that implicitly follow DOA. The reasons why, how, and the extent to which DOA is adopted in these systems are unclear. Implicit design decisions limit the practitioners' knowledge of DOA to design ML-based syst
&lt;/p&gt;</description></item></channel></rss>