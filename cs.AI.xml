<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>RO-LMM&#26159;&#19968;&#20010;&#38024;&#23545;&#25918;&#23556;&#32959;&#30244;&#23398;&#39046;&#22495;&#35774;&#35745;&#30340;&#22810;&#21151;&#33021;&#22823;&#22411;&#22810;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;Consistency Embedding Fine-Tuning&#65288;CEFTune&#65289;&#25216;&#26415;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#20445;&#25345;&#22788;&#29702;&#24178;&#20928;&#36755;&#20837;&#33021;&#21147;&#30340;&#21516;&#26102;&#25552;&#21319;&#23545;&#22024;&#26434;&#36755;&#20837;&#30340;&#40065;&#26834;&#24615;&#65292;&#29992;&#20110;&#25918;&#23556;&#27835;&#30103;&#35745;&#21010;&#21644;&#30446;&#26631;&#20307;&#31215;&#20998;&#21106;&#12290;</title><link>https://arxiv.org/abs/2311.15876</link><description>&lt;p&gt;
LMM&#36741;&#21161;&#30340;&#19968;&#33268;&#24615;&#23884;&#20837;&#19979;&#20083;&#33146;&#30284;&#27835;&#30103;&#30446;&#26631;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
LMM-Assisted Breast Cancer Treatment Target Segmentation with Consistency Embedding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15876
&lt;/p&gt;
&lt;p&gt;
RO-LMM&#26159;&#19968;&#20010;&#38024;&#23545;&#25918;&#23556;&#32959;&#30244;&#23398;&#39046;&#22495;&#35774;&#35745;&#30340;&#22810;&#21151;&#33021;&#22823;&#22411;&#22810;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;Consistency Embedding Fine-Tuning&#65288;CEFTune&#65289;&#25216;&#26415;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#20445;&#25345;&#22788;&#29702;&#24178;&#20928;&#36755;&#20837;&#33021;&#21147;&#30340;&#21516;&#26102;&#25552;&#21319;&#23545;&#22024;&#26434;&#36755;&#20837;&#30340;&#40065;&#26834;&#24615;&#65292;&#29992;&#20110;&#25918;&#23556;&#27835;&#30103;&#35745;&#21010;&#21644;&#30446;&#26631;&#20307;&#31215;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#30340;&#26368;&#26032;&#36827;&#23637;&#28145;&#21051;&#24433;&#21709;&#20102;&#21307;&#23398;&#39046;&#22495;&#65292;&#20026;&#38477;&#20302;&#20020;&#24202;&#24037;&#20316;&#37327;&#25552;&#20379;&#20102;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#21463;&#38480;&#20110;&#25191;&#34892;&#21333;&#27169;&#24335;&#20219;&#21153;&#65292;&#19982;&#21307;&#23398;&#19987;&#19994;&#20154;&#21592;&#25152;&#20351;&#29992;&#30340;&#32508;&#21512;&#26041;&#27861;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;RO-LMM&#65292;&#19968;&#20010;&#19987;&#20026;&#25918;&#23556;&#32959;&#30244;&#23398;&#39046;&#22495;&#35774;&#35745;&#30340;&#22810;&#21151;&#33021;&#22823;&#22411;&#22810;&#27169;&#22411;&#65288;LMM&#65289;&#12290;&#35813;&#27169;&#22411;&#28085;&#30422;&#20102;&#20020;&#24202;&#24037;&#20316;&#27969;&#20013;&#30340;&#19968;&#31995;&#21015;&#20219;&#21153;&#65292;&#25797;&#38271;&#20020;&#24202;&#25253;&#21578;&#25688;&#35201;&#12289;&#25918;&#30103;&#27835;&#30103;&#35745;&#21010;&#24314;&#35758;&#21644;&#35745;&#21010;&#24341;&#23548;&#30340;&#30446;&#26631;&#20307;&#31215;&#20998;&#21106;&#12290;&#20026;&#20102;&#25191;&#34892;&#36830;&#32493;&#30340;&#20020;&#24202;&#20219;&#21153;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#19968;&#33268;&#24615;&#23884;&#20837;&#24494;&#35843;&#65288;CEFTune&#65289;&#25216;&#26415;&#65292;&#25552;&#21319;&#20102;LMM&#23545;&#22024;&#26434;&#36755;&#20837;&#30340;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#22788;&#29702;&#24178;&#20928;&#36755;&#20837;&#30340;&#33021;&#21147;&#65292;&#24182;&#23558;&#35813;&#27010;&#24565;&#36716;&#21270;&#20026;LMM&#39537;&#21160;&#30340;&#20998;&#21106;&#26694;&#26550;&#65292;&#21363;&#19968;&#33268;&#24615;&#23884;&#20837;S&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.15876v2 Announce Type: replace-cross  Abstract: Recent advancements in Artificial Intelligence (AI) have profoundly influenced medical fields, by providing tools to reduce clinical workloads. However, most AI models are constrained to execute unimodal tasks, in stark contrast to the comprehensive approaches utilized by medical professionals. To address this, here we present RO-LMM, a multi-purpose large multimodal model (LMM) tailored for the field of radiation oncology. This model covers series of tasks within clinical workflow, adept at clinical report summarization, radiation treatment plan suggestion, and plan-guided target volume segmentation. In particular, to perform consecutive clinical tasks, we further present a novel Consistency Embedding Fine-Tuning (CEFTune) technique, which boosts LMM's robustness to noisy inputs while preserving the capability of handling clean inputs, and transform this concept into LMM-driven segmentation framework as Consistency Embedding S
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;EAUC&#20316;&#20026;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20197;&#25581;&#31034;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#38544;&#34255;&#30340;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;RMSE&#21644;MAE&#26080;&#27861;&#25429;&#25417;&#21040;&#36825;&#31181;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.10690</link><description>&lt;p&gt;
&#36229;&#36234;RMSE&#21644;MAE&#65306;&#24341;&#20837;EAUC&#26469;&#25581;&#31034;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#30340;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#22240;&#32032;
&lt;/p&gt;
&lt;p&gt;
Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models. (arXiv:2401.10690v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10690
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;EAUC&#20316;&#20026;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20197;&#25581;&#31034;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#38544;&#34255;&#30340;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;RMSE&#21644;MAE&#26080;&#27861;&#25429;&#25417;&#21040;&#36825;&#31181;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#19968;&#23545;&#23454;&#20307;&#30340;&#23454;&#20540;&#32467;&#26524;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#37117;&#26159;&#22522;&#30784;&#30340;&#65288;&#20363;&#22914;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#39044;&#27979;&#29992;&#25143;&#23545;&#20135;&#21697;&#30340;&#35780;&#20998;&#65289;&#65292;&#22312;&#35768;&#22810;&#20854;&#20182;&#39046;&#22495;&#20013;&#20063;&#26377;&#35768;&#22810;&#28508;&#21147;&#20294;&#23578;&#26410;&#28145;&#20837;&#25506;&#32034;&#65288;&#20363;&#22914;&#65292;&#22312;&#20010;&#24615;&#21270;&#33647;&#29702;&#23398;&#20013;&#36817;&#20284;&#30830;&#23450;&#24739;&#32773;&#30340;&#36866;&#24403;&#21058;&#37327;&#65289;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20010;&#20307;&#23454;&#20307;&#35266;&#23519;&#20540;&#20998;&#24067;&#30340;&#38750;&#22343;&#21248;&#24615;&#23548;&#33268;&#20102;&#26368;&#20808;&#36827;&#27169;&#22411;&#20013;&#30340;&#20005;&#37325;&#20559;&#35265;&#39044;&#27979;&#65292;&#20559;&#21521;&#20110;&#23454;&#20307;&#30340;&#35266;&#23519;&#36807;&#21435;&#20540;&#30340;&#24179;&#22343;&#20540;&#65292;&#24182;&#22312;&#21478;&#31867;&#20294;&#21516;&#26679;&#37325;&#35201;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#27604;&#38543;&#26426;&#39044;&#27979;&#26356;&#24046;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;&#22343;&#26041;&#26681;&#35823;&#24046;&#65288;RMSE&#65289;&#21644;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#19981;&#36275;&#20197;&#25429;&#25417;&#21040;&#36825;&#31181;&#29616;&#35937;&#65292;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;&#21478;&#31867;&#20559;&#35265;&#65292;&#24182;&#24341;&#20837;&#21478;&#31867;-&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;EAUC&#65289;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#34917;&#20805;&#24230;&#37327;&#65292;&#21487;&#20197;&#22312;&#25152;&#26377;&#30740;&#31350;&#30340;&#27169;&#22411;&#20013;&#37327;&#21270;&#23427;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dyadic regression models, which predict real-valued outcomes for pairs of entities, are fundamental in many domains (e.g. predicting the rating of a user to a product in Recommender Systems) and promising and under exploration in many others (e.g. approximating the adequate dosage of a drug for a patient in personalized pharmacology). In this work, we demonstrate that non-uniformity in the observed value distributions of individual entities leads to severely biased predictions in state-of-the-art models, skewing predictions towards the average of observed past values for the entity and providing worse-than-random predictive power in eccentric yet equally important cases. We show that the usage of global error metrics like Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) is insufficient to capture this phenomenon, which we name eccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as a new complementary metric that can quantify it in all studied models
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#65292;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#12290;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.08731</link><description>&lt;p&gt;
&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#22312;&#19990;&#30028;&#27169;&#22411;&#20013;&#23454;&#29616;&#26032;&#39062;&#24615;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Simple Way to Incorporate Novelty Detection in World Models. (arXiv:2310.08731v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#65292;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#12290;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#19990;&#30028;&#27169;&#22411;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#24403;&#19990;&#30028;&#26426;&#21046;&#25110;&#23646;&#24615;&#21457;&#29983;&#31361;&#28982;&#21464;&#21270;&#26102;&#65292;&#20195;&#29702;&#30340;&#24615;&#33021;&#21644;&#21487;&#38752;&#24615;&#21487;&#33021;&#20250;&#26174;&#33879;&#19979;&#38477;&#12290;&#25105;&#20204;&#23558;&#35270;&#35273;&#23646;&#24615;&#25110;&#29366;&#24577;&#36716;&#25442;&#30340;&#31361;&#21464;&#31216;&#20026;&#8220;&#26032;&#39062;&#24615;&#8221;&#12290;&#22312;&#29983;&#25104;&#30340;&#19990;&#30028;&#27169;&#22411;&#26694;&#26550;&#20013;&#23454;&#26045;&#26032;&#39062;&#24615;&#26816;&#27979;&#26159;&#20445;&#25252;&#37096;&#32626;&#26102;&#20195;&#29702;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36793;&#30028;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19982;&#24207;&#21015;&#20915;&#31574;&#30456;&#20851;&#30340;&#26032;&#39062;&#24615;&#26816;&#27979;&#26412;&#20307;&#35770;&#65292;&#28982;&#21518;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#20195;&#29702;&#22312;&#19990;&#30028;&#27169;&#22411;&#20013;&#23398;&#20064;&#30340;&#36716;&#25442;&#20998;&#24067;&#20013;&#26816;&#27979;&#26032;&#39062;&#24615;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as {\em novelties}. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We first provide an ontology of novelty detection relevant to sequential decision making, then we provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional ma
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Q&#30340;&#31574;&#30053;&#35268;&#21017;&#26063;&#20013;&#30340;&#22343;&#34913;&#20559;&#24046;&#65288;&#25110; Qb-equilibria&#65289;&#65292;&#21363;Q&#20540;&#22312;&#19981;&#21516;&#30417;&#27979;&#25216;&#26415;&#19979;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.12647</link><description>&lt;p&gt;
&#22522;&#20110;Q&#30340;&#22343;&#34913;
&lt;/p&gt;
&lt;p&gt;
Q-based Equilibria. (arXiv:2304.12647v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12647
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Q&#30340;&#31574;&#30053;&#35268;&#21017;&#26063;&#20013;&#30340;&#22343;&#34913;&#20559;&#24046;&#65288;&#25110; Qb-equilibria&#65289;&#65292;&#21363;Q&#20540;&#22312;&#19981;&#21516;&#30417;&#27979;&#25216;&#26415;&#19979;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#65292;Q&#23398;&#20064;&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#35268;&#21017;&#65292;&#20854;&#20026;&#27599;&#20010;&#26367;&#20195;&#26041;&#26696;&#25552;&#20379;&#20272;&#35745;&#20540;(&#21363;Q&#20540;)&#65292;&#35813;&#20540;&#19982;&#20043;&#21069;&#30340;&#20915;&#31574;&#30456;&#20851;&#12290;&#19968;&#20010;&#26420;&#32032;&#30340;&#31574;&#30053;&#26159;&#22987;&#32456;&#36873;&#25321;&#20855;&#26377;&#26368;&#39640;Q&#20540;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#26063;&#22522;&#20110;Q&#30340;&#31574;&#30053;&#35268;&#21017;&#65292;&#36825;&#20123;&#35268;&#21017;&#21487;&#33021;&#31995;&#32479;&#22320;&#25903;&#25345;&#26576;&#20123;&#26367;&#20195;&#26041;&#26696;&#32780;&#19981;&#26159;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#65292;&#20363;&#22914;&#21253;&#21547;&#26377;&#21033;&#21512;&#20316;&#30340;&#23485;&#23481;&#20559;&#24046;&#30340;&#35268;&#21017;&#12290;&#22312; Compte &#21644; Postlewaite [2018] &#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#22312;&#36825;&#20010; Q-based &#35268;&#21017;&#26063;&#20013;&#23547;&#25214;&#22343;&#34913;&#20559;&#24046;&#65288;&#25110; Qb-equilibria&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;&#30417;&#27979;&#25216;&#26415;&#19979;&#30340;&#32463;&#20856;&#21338;&#24328;&#12290;
&lt;/p&gt;
&lt;p&gt;
In dynamic environments, Q-learning is an adaptative rule that provides an estimate (a Q-value) of the continuation value associated with each alternative. A naive policy consists in always choosing the alternative with highest Q-value. We consider a family of Q-based policy rules that may systematically favor some alternatives over others, for example rules that incorporate a leniency bias that favors cooperation. In the spirit of Compte and Postlewaite [2018], we look for equilibrium biases (or Qb-equilibria) within this family of Q-based rules. We examine classic games under various monitoring technologies.
&lt;/p&gt;</description></item></channel></rss>