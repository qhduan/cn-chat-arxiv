<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#22312;transformers&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#31163;&#25955;&#21457;&#23637;&#38454;&#27573;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#26816;&#27979;&#36825;&#20123;&#38454;&#27573;&#30340;&#20851;&#38190;&#37324;&#31243;&#30865;&#12290;&#25105;&#20204;&#20351;&#29992;&#34892;&#20026;&#21644;&#32467;&#26500;&#24230;&#37327;&#39564;&#35777;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02364</link><description>&lt;p&gt;
&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#30340;&#21457;&#23637;&#26223;&#35266;
&lt;/p&gt;
&lt;p&gt;
The Developmental Landscape of In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02364
&lt;/p&gt;
&lt;p&gt;
&#22312;transformers&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#31163;&#25955;&#21457;&#23637;&#38454;&#27573;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#26816;&#27979;&#36825;&#20123;&#38454;&#27573;&#30340;&#20851;&#38190;&#37324;&#31243;&#30865;&#12290;&#25105;&#20204;&#20351;&#29992;&#34892;&#20026;&#21644;&#32467;&#26500;&#24230;&#37327;&#39564;&#35777;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;transformers&#20013;&#65292;&#24403;&#23427;&#20204;&#36890;&#36807;&#35821;&#35328;&#24314;&#27169;&#25110;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#19978;&#19979;&#25991;&#23398;&#20064;&#26159;&#22914;&#20309;&#20197;&#31163;&#25955;&#30340;&#21457;&#23637;&#38454;&#27573;&#20986;&#29616;&#30340;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#26816;&#27979;&#20998;&#38548;&#36825;&#20123;&#38454;&#27573;&#30340;&#20851;&#38190;&#37324;&#31243;&#30865;&#65292;&#36890;&#36807;&#25506;&#27979;&#21442;&#25968;&#31354;&#38388;&#21644;&#20989;&#25968;&#31354;&#38388;&#20013;&#31181;&#32676;&#25439;&#22833;&#30340;&#20960;&#20309;&#29305;&#24449;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31995;&#21015;&#34892;&#20026;&#21644;&#32467;&#26500;&#24230;&#37327;&#30740;&#31350;&#36825;&#20123;&#26032;&#26041;&#27861;&#25581;&#31034;&#30340;&#38454;&#27573;&#65292;&#20197;&#24314;&#31435;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that in-context learning emerges in transformers in discrete developmental stages, when they are trained on either language modeling or linear regression tasks. We introduce two methods for detecting the milestones that separate these stages, by probing the geometry of the population loss in both parameter space and function space. We study the stages revealed by these new methods using a range of behavioral and structural metrics to establish their validity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#35889;&#35282;&#24230;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20102;GNNs&#30340;&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#38382;&#39064;&#65292;&#24182;&#22312;&#30495;&#23454;&#29983;&#29289;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#21457;&#29616;GNNs&#22312;&#24230;&#20998;&#24067;&#21644;&#35889;&#20998;&#24067;&#20559;&#31227;&#26102;&#22343;&#34920;&#29616;&#25935;&#24863;&#65292;&#22312;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#22823;&#22270;&#19978;&#30340;&#24615;&#33021;&#20173;&#28982;&#19979;&#38477;&#65292;&#25581;&#31034;&#20102; GNNs&#30340;&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15611</link><description>&lt;p&gt;
&#22522;&#20110;&#35889;&#35282;&#24230;&#21078;&#26512;&#29983;&#29289;&#25968;&#25454;&#20013;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#65306;&#35266;&#28857;&#21644;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
Size Generalizability of Graph Neural Networks on Biological Data: Insights and Practices from the Spectral Perspective. (arXiv:2305.15611v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#35889;&#35282;&#24230;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20102;GNNs&#30340;&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#38382;&#39064;&#65292;&#24182;&#22312;&#30495;&#23454;&#29983;&#29289;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#21457;&#29616;GNNs&#22312;&#24230;&#20998;&#24067;&#21644;&#35889;&#20998;&#24067;&#20559;&#31227;&#26102;&#22343;&#34920;&#29616;&#25935;&#24863;&#65292;&#22312;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#22823;&#22270;&#19978;&#30340;&#24615;&#33021;&#20173;&#28982;&#19979;&#38477;&#65292;&#25581;&#31034;&#20102; GNNs&#30340;&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476; (GNNs) &#26159;&#21542;&#20855;&#26377;&#20174;&#23567;&#22270;&#20013;&#23398;&#20064;&#30340;&#30693;&#35782;&#21487;&#25512;&#24191;&#21040;&#21516;&#19968;&#39046;&#22495;&#30340;&#22823;&#22270;&#20013;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#19981;&#21516;&#22823;&#23567;&#30340;&#22270;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#65292;&#23588;&#20854;&#26159;&#24230;&#20998;&#24067;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#28982;&#32780;&#65292;&#22312;&#29983;&#29289;&#25968;&#25454;&#38598;&#20013;&#65292;&#24230;&#25968;&#26159;&#26377;&#30028;&#30340;&#65292;&#22240;&#27492;&#24230;&#20998;&#24067;&#30340;&#20559;&#31227;&#24456;&#23567;&#12290;&#21363;&#20351;&#24230;&#20998;&#24067;&#20559;&#31227;&#24456;&#23567;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;GNNs&#22312;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#22823;&#22270;&#19978;&#30340;&#24615;&#33021;&#20173;&#28982;&#19979;&#38477;&#65292;&#26263;&#31034;&#26377;&#20854;&#20182;&#21407;&#22240;&#12290;&#20107;&#23454;&#19978;&#65292;&#20197;&#24448;&#23545;&#20110;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#21508;&#31181;&#22270;&#23610;&#23544;&#24341;&#36215;&#30340;&#20998;&#24067;&#20559;&#31227;&#31867;&#22411;&#21644;&#23646;&#24615;&#30340;&#25506;&#32034;&#19981;&#36275;&#12290;&#27492;&#22806;&#65292;&#20197;&#21069;&#30340;&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#20998;&#26512;&#22823;&#22810;&#38598;&#20013;&#22312;&#31354;&#38388;&#39046;&#22495;&#12290;&#20026;&#22635;&#34917;&#36825;&#20123;&#31354;&#30333;&#65292;&#25105;&#20204;&#37319;&#29992;&#35889;&#35282;&#24230;&#21435;&#30740;&#31350;GNNs&#22312;&#29983;&#29289;&#22270;&#25968;&#25454;&#19978;&#30340;&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#19968;&#20010;&#26032;&#26694;&#26550;&#26469;&#27169;&#25311;&#21508;&#31181;&#31867;&#22411;&#30340;&#24230;&#20998;&#24067;&#20559;&#31227;&#65292;&#24182;&#21033;&#29992;&#23427;&#26469;&#27979;&#35797;GNNs &#22312;&#30495;&#23454;&#29983;&#29289;&#25968;&#25454;&#38598;&#19978;&#30340;&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#38500;&#20102;&#24230;&#20998;&#24067;&#20559;&#31227;&#22806;&#65292;GNNs &#36824;&#23545;&#22270;&#22823;&#23567;&#21464;&#21270;&#24341;&#36215;&#30340;&#35889;&#20998;&#24067;&#20559;&#31227;&#24456;&#25935;&#24863;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#19981;&#21516;&#30340;GNN&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#34920;&#26126;&#65292;&#19968;&#20123;&#27169;&#22411;&#27604;&#20854;&#20182;&#27169;&#22411;&#26356;&#20855;&#26377;&#23610;&#23544;&#27867;&#21270;&#24615;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#20851;&#20110;GNNs&#23610;&#23544;&#21487;&#27867;&#21270;&#24615;&#38382;&#39064;&#30340;&#26032;&#35266;&#28857;&#21644;&#23454;&#36341;&#65292;&#24182;&#20026;&#35813;&#39046;&#22495;&#30340;&#26410;&#26469;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#30410;&#30340;&#27934;&#23519;&#21644;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the question of whether the knowledge learned by graph neural networks (GNNs) from small graphs is generalizable to large graphs in the same domain. Prior works suggest that the distribution shift, particularly in the degree distribution, between graphs of different sizes can lead to performance degradation in the graph classification task. However, this may not be the case for biological datasets where the degrees are bounded and the distribution shift of degrees is small. Even with little degree distribution shift, our observations show that GNNs' performance on larger graphs from the same datasets still degrades, suggesting other causes. In fact, there has been a lack of exploration in real datasets to understand the types and properties of distribution shifts caused by various graph sizes. Furthermore, previous analyses of size generalizability mostly focus on the spatial domain.  To fill these gaps, we take the spectral perspective and study the size generalizabilit
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#65292;&#24182;&#21487;&#30830;&#20445;&#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.04095</link><description>&lt;p&gt;
&#22522;&#20110;&#23494;&#38053;&#38145;&#27169;&#22359;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Gradient Leakage Defense with Key-Lock Module for Federated Learning. (arXiv:2305.04095v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#65292;&#24182;&#21487;&#30830;&#20445;&#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#38544;&#31169;&#20445;&#25252;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20854;&#20013;&#31169;&#26377;&#25968;&#25454;&#20445;&#25345;&#26412;&#22320;&#65292;&#20801;&#35768;&#23433;&#20840;&#35745;&#31639;&#21644;&#26412;&#22320;&#27169;&#22411;&#26799;&#24230;&#19982;&#31532;&#19977;&#26041;&#21442;&#25968;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#20132;&#25442;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#20849;&#20139;&#30340;&#26799;&#24230;&#21487;&#33021;&#20250;&#21361;&#21450;&#38544;&#31169;&#24182;&#24674;&#22797;&#25935;&#24863;&#20449;&#24687;&#12290;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#20998;&#26512;&#21644;&#23545;&#26799;&#24230;&#27844;&#28431;&#38382;&#39064;&#30340;&#26032;&#35270;&#35282;&#12290;&#36825;&#20123;&#29702;&#35770;&#24037;&#20316;&#23548;&#33268;&#20102;&#19968;&#31181;&#26032;&#30340;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#12290;&#21482;&#26377;&#38145;&#23450;&#30340;&#26799;&#24230;&#34987;&#20256;&#36755;&#21040;&#21442;&#25968;&#26381;&#21153;&#22120;&#36827;&#34892;&#20840;&#23616;&#27169;&#22411;&#32858;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#23398;&#20064;&#26041;&#27861;&#23545;&#26799;&#24230;&#27844;&#38706;&#25915;&#20987;&#20855;&#26377;&#25269;&#25239;&#21147;&#65292;&#24182;&#19988;&#25152;&#35774;&#35745;&#21644;&#35757;&#32451;&#30340;&#23494;&#38053;&#38145;&#27169;&#22359;&#21487;&#20197;&#30830;&#20445;&#65292;&#27809;&#26377;&#23494;&#38053;&#38145;&#27169;&#22359;&#30340;&#31169;&#26377;&#20449;&#24687;&#65306;a) &#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a widely adopted privacy-preserving machine learning approach where private data remains local, enabling secure computations and the exchange of local model gradients between local clients and third-party parameter servers. However, recent findings reveal that privacy may be compromised and sensitive information potentially recovered from shared gradients. In this study, we offer detailed analysis and a novel perspective on understanding the gradient leakage problem. These theoretical works lead to a new gradient leakage defense technique that secures arbitrary model architectures using a private key-lock module. Only the locked gradient is transmitted to the parameter server for global model aggregation. Our proposed learning method is resistant to gradient leakage attacks, and the key-lock module is designed and trained to ensure that, without the private information of the key-lock module: a) reconstructing private training data from the shared gradient is
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;UCN&#30340;&#26032;&#22411;&#22240;&#26524;&#27169;&#22411;&#65292;&#23427;&#32771;&#34385;&#20102;&#26102;&#38388;&#24310;&#36831;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#24471;&#21040;&#30340;&#32593;&#32476;&#32467;&#26500;&#30340;&#21807;&#19968;&#24615;&#65292;&#35299;&#20915;&#20102;&#22240;&#26524;&#35299;&#37322;&#24615;&#21644;&#38750;&#38745;&#24577;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.10085</link><description>&lt;p&gt;
&#20174;&#38750;&#38745;&#27490;&#26102;&#38388;&#24207;&#21015;&#20013;&#35782;&#21035;&#29420;&#29305;&#30340;&#22240;&#26524;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Identifying Unique Causal Network from Nonstationary Time Series. (arXiv:2211.10085v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10085
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;UCN&#30340;&#26032;&#22411;&#22240;&#26524;&#27169;&#22411;&#65292;&#23427;&#32771;&#34385;&#20102;&#26102;&#38388;&#24310;&#36831;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#24471;&#21040;&#30340;&#32593;&#32476;&#32467;&#26500;&#30340;&#21807;&#19968;&#24615;&#65292;&#35299;&#20915;&#20102;&#22240;&#26524;&#35299;&#37322;&#24615;&#21644;&#38750;&#38745;&#24577;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#25968;&#25454;&#23494;&#38598;&#22411;&#22330;&#26223;&#19979;&#65292;&#35782;&#21035;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#29992;&#20110;&#27492;&#20851;&#38190;&#20219;&#21153;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#31639;&#27861;&#20165;&#32771;&#34385;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BN&#65289;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20123;&#22522;&#20110;BN&#30340;&#27169;&#22411;&#20165;&#20855;&#26377;&#26377;&#38480;&#30340;&#22240;&#26524;&#21487;&#35299;&#37322;&#24615;&#65292;&#22240;&#20026;&#23384;&#22312;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#20381;&#36182;&#20110;&#38745;&#27490;&#24615;&#20551;&#35774;&#65292;&#32780;&#26469;&#33258;&#22797;&#26434;&#31995;&#32479;&#30340;&#35768;&#22810;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#26159;&#38750;&#38745;&#27490;&#30340;&#12290;&#38750;&#38745;&#27490;&#30340;&#26102;&#38388;&#24207;&#21015;&#24102;&#26469;&#20102;&#25968;&#25454;&#38598;&#28418;&#31227;&#38382;&#39064;&#65292;&#23548;&#33268;&#36825;&#20123;&#31639;&#27861;&#30340;&#24615;&#33021;&#19981;&#20339;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20123;&#31354;&#30333;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Unique Causal Network&#65288;UCN&#65289;&#30340;&#26032;&#22411;&#22240;&#26524;&#27169;&#22411;&#12290;&#19982;&#20197;&#21069;&#30340;&#22522;&#20110;BN&#30340;&#27169;&#22411;&#19981;&#21516;&#65292;UCN&#32771;&#34385;&#20102;&#26102;&#38388;&#24310;&#36831;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#24471;&#21040;&#30340;&#32593;&#32476;&#32467;&#26500;&#30340;&#21807;&#19968;&#24615;&#65292;&#35299;&#20915;&#20102;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;UCN&#30340;&#21487;&#20998;&#35299;&#24615;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#26356;&#39640;&#30340;...
&lt;/p&gt;
&lt;p&gt;
Identifying causality is a challenging task in many data-intensive scenarios. Many algorithms have been proposed for this critical task. However, most of them consider the learning algorithms for directed acyclic graph (DAG) of Bayesian network (BN). These BN-based models only have limited causal explainability because of the issue of Markov equivalence class. Moreover, they are dependent on the assumption of stationarity, whereas many sampling time series from complex system are nonstationary. The nonstationary time series bring dataset shift problem, which leads to the unsatisfactory performances of these algorithms. To fill these gaps, a novel causation model named Unique Causal Network (UCN) is proposed in this paper. Different from the previous BN-based models, UCN considers the influence of time delay, and proves the uniqueness of obtained network structure, which addresses the issue of Markov equivalence class. Furthermore, based on the decomposability property of UCN, a higher-
&lt;/p&gt;</description></item></channel></rss>