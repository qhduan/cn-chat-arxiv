<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36890;&#36807;&#22522;&#20110;&#20840;&#38754;&#36816;&#33829;&#25104;&#26412;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#37319;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#20248;&#21270;&#33258;&#20027;&#21345;&#36710;&#30340;&#25112;&#26415;&#20915;&#31574;&#65292;&#23558;&#39640;&#32423;&#20915;&#31574;&#19982;&#20302;&#32423;&#25511;&#21046;&#20998;&#31163;&#65292;&#24182;&#37319;&#29992;&#19981;&#21516;&#25216;&#24039;&#25552;&#21319;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.06524</link><description>&lt;p&gt;
&#22522;&#20110;&#20840;&#38754;&#36816;&#33829;&#25104;&#26412;&#22870;&#21169;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#33258;&#20027;&#21345;&#36710;&#25112;&#26415;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Tactical Decision Making for Autonomous Trucks by Deep Reinforcement Learning with Total Cost of Operation Based Reward
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06524
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#20840;&#38754;&#36816;&#33829;&#25104;&#26412;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#37319;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#20248;&#21270;&#33258;&#20027;&#21345;&#36710;&#30340;&#25112;&#26415;&#20915;&#31574;&#65292;&#23558;&#39640;&#32423;&#20915;&#31574;&#19982;&#20302;&#32423;&#25511;&#21046;&#20998;&#31163;&#65292;&#24182;&#37319;&#29992;&#19981;&#21516;&#25216;&#24039;&#25552;&#21319;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#33258;&#20027;&#21345;&#36710;&#30340;&#25112;&#26415;&#20915;&#31574;&#21046;&#23450;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#38024;&#23545;&#39640;&#36895;&#20844;&#36335;&#22330;&#26223;&#20013;&#30340;&#33258;&#36866;&#24212;&#24033;&#33322;&#25511;&#21046;&#65288;ACC&#65289;&#21644;&#21464;&#36947;&#21160;&#20316;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#21644;&#22522;&#20110;&#29289;&#29702;&#27169;&#22411;&#30340;&#20302;&#32423;&#25511;&#21046;&#22120;&#20043;&#38388;&#20998;&#31163;&#39640;&#32423;&#20915;&#31574;&#36807;&#31243;&#21644;&#20302;&#32423;&#25511;&#21046;&#21160;&#20316;&#26159;&#26377;&#30410;&#30340;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;&#22312;&#21345;&#36710;&#30340;&#20840;&#38754;&#36816;&#33829;&#25104;&#26412;&#65288;TCOP&#65289;&#20026;&#22522;&#30784;&#30340;&#22810;&#30446;&#26631;&#22870;&#21169;&#20989;&#25968;&#20248;&#21270;&#24615;&#33021;&#30340;&#19981;&#21516;&#26041;&#27861;&#65307;&#36890;&#36807;&#20026;&#22870;&#21169;&#20998;&#37327;&#28155;&#21152;&#26435;&#37325;&#65292;&#36890;&#36807;&#23545;&#22870;&#21169;&#20998;&#37327;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#35838;&#31243;&#23398;&#20064;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06524v1 Announce Type: cross  Abstract: We develop a deep reinforcement learning framework for tactical decision making in an autonomous truck, specifically for Adaptive Cruise Control (ACC) and lane change maneuvers in a highway scenario. Our results demonstrate that it is beneficial to separate high-level decision-making processes and low-level control actions between the reinforcement learning agent and the low-level controllers based on physical models. In the following, we study optimizing the performance with a realistic and multi-objective reward function based on Total Cost of Operation (TCOP) of the truck using different approaches; by adding weights to reward components, by normalizing the reward components and by using curriculum learning techniques.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#24046;&#20998;&#38544;&#31169;&#32447;&#24615;&#25506;&#27979;&#65288;LP&#65289;&#21644;&#23436;&#20840;&#24494;&#35843;&#65288;FT&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#25506;&#32034;&#20102;&#20174;&#32447;&#24615;&#25506;&#27979;&#36807;&#28193;&#21040;&#23436;&#20840;&#24494;&#35843;&#65288;LP-FT&#65289;&#30340;&#39034;&#24207;&#24494;&#35843;&#29616;&#35937;&#21450;&#20854;&#23545;&#27979;&#35797;&#25439;&#22833;&#30340;&#24433;&#21709;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#22312;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#24046;&#20998;&#38544;&#31169;&#24494;&#35843;&#25910;&#25947;&#24615;&#30340;&#29702;&#35770;&#27934;&#35265;&#21644;&#38544;&#31169;&#39044;&#31639;&#20998;&#37197;&#30340;&#25928;&#29992;&#26354;&#32447;&#12290;</title><link>https://arxiv.org/abs/2402.18905</link><description>&lt;p&gt;
&#35770;&#24046;&#20998;&#38544;&#31169;&#24494;&#35843;&#30340;&#25910;&#25947;&#24615;&#65306;&#24212;&#32447;&#24615;&#25506;&#27979;&#36824;&#26159;&#23436;&#20840;&#24494;&#35843;&#65311;
&lt;/p&gt;
&lt;p&gt;
On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#24046;&#20998;&#38544;&#31169;&#32447;&#24615;&#25506;&#27979;&#65288;LP&#65289;&#21644;&#23436;&#20840;&#24494;&#35843;&#65288;FT&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#25506;&#32034;&#20102;&#20174;&#32447;&#24615;&#25506;&#27979;&#36807;&#28193;&#21040;&#23436;&#20840;&#24494;&#35843;&#65288;LP-FT&#65289;&#30340;&#39034;&#24207;&#24494;&#35843;&#29616;&#35937;&#21450;&#20854;&#23545;&#27979;&#35797;&#25439;&#22833;&#30340;&#24433;&#21709;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#22312;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#24046;&#20998;&#38544;&#31169;&#24494;&#35843;&#25910;&#25947;&#24615;&#30340;&#29702;&#35770;&#27934;&#35265;&#21644;&#38544;&#31169;&#39044;&#31639;&#20998;&#37197;&#30340;&#25928;&#29992;&#26354;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#26426;&#22120;&#23398;&#20064;&#27969;&#27700;&#32447;&#36890;&#24120;&#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#30340;&#36807;&#31243;&#65306;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#38750;&#31169;&#26377;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#20351;&#29992;DP&#20248;&#21270;&#25216;&#26415;&#22312;&#31169;&#26377;&#25968;&#25454;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#22312;DP&#35774;&#32622;&#20013;&#65292;&#24050;&#32463;&#35266;&#23519;&#21040;&#23436;&#20840;&#24494;&#35843;&#26377;&#26102;&#20505;&#24182;&#19981;&#24635;&#26159;&#20135;&#29983;&#26368;&#20339;&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#65292;&#21363;&#20351;&#23545;&#20110;&#20998;&#24067;&#20869;&#25968;&#25454;&#20063;&#26159;&#22914;&#27492;&#12290;&#26412;&#25991;&#65288;1&#65289;&#20998;&#26512;&#20102;DP&#32447;&#24615;&#25506;&#27979;&#65288;LP&#65289;&#21644;&#23436;&#20840;&#24494;&#35843;&#65288;FT&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#20197;&#21450;&#65288;2&#65289;&#25506;&#32034;&#20102;&#39034;&#24207;&#24494;&#35843;&#30340;&#29616;&#35937;&#65292;&#20174;&#32447;&#24615;&#25506;&#27979;&#24320;&#22987;&#65292;&#36807;&#28193;&#21040;&#23436;&#20840;&#24494;&#35843;&#65288;LP-FT&#65289;&#65292;&#20197;&#21450;&#23427;&#23545;&#27979;&#35797;&#25439;&#22833;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#20851;DP&#24494;&#35843;&#22312;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#30340;&#29702;&#35770;&#27934;&#35265;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#30830;&#23450;&#38544;&#31169;&#39044;&#31639;&#22312;&#32447;&#24615;&#25506;&#27979;&#21644;&#23436;&#20840;&#24494;&#35843;&#20043;&#38388;&#20998;&#37197;&#30340;&#25928;&#29992;&#26354;&#32447;&#12290;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#23545;&#21508;&#31181;&#22522;&#20934;&#21644;&#27169;&#22411;&#30340;&#32463;&#39564;&#35780;&#20272;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18905v1 Announce Type: cross  Abstract: Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by fine-tuning on private data using DP optimization techniques. In the DP setting, it has been observed that full fine-tuning may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2) explores the phenomenon of sequential fine-tuning, starting with linear probing and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP fine-tuning within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full fine-tuning. The theoretical results are supported by empirical evaluations on various benchmarks and models.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25506;&#35752;&#20102;&#20010;&#20307;&#26234;&#33021;&#26159;&#21542;&#23545;&#20110;&#38598;&#20307;&#26234;&#33021;&#30340;&#20135;&#29983;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#21450;&#24590;&#26679;&#30340;&#20010;&#20307;&#26234;&#33021;&#26377;&#21033;&#20110;&#26356;&#22823;&#30340;&#38598;&#20307;&#26234;&#33021;&#12290;&#22312;Lotka-Volterra&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20123;&#20010;&#20307;&#34892;&#20026;&#65292;&#29305;&#21035;&#26159;&#25504;&#39135;&#32773;&#30340;&#34892;&#20026;&#65292;&#26377;&#21033;&#20110;&#19982;&#20854;&#20182;&#31181;&#32676;&#20849;&#23384;&#65292;&#20294;&#22914;&#26524;&#29454;&#29289;&#21644;&#25504;&#39135;&#32773;&#37117;&#36275;&#22815;&#26234;&#33021;&#20197;&#25512;&#26029;&#24444;&#27492;&#30340;&#34892;&#20026;&#65292;&#20849;&#23384;&#23558;&#20276;&#38543;&#30528;&#20004;&#20010;&#31181;&#32676;&#30340;&#26080;&#38480;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2012.12689</link><description>&lt;p&gt;
&#20803;&#32032;&#36234;&#31528;&#65292;&#25972;&#20307;&#36234;&#32874;&#26126;&#12290;&#25110;&#32773;&#65292;&#21487;&#33021;&#24182;&#38750;&#22914;&#27492;&#65311;
&lt;/p&gt;
&lt;p&gt;
The Less Intelligent the Elements, the More Intelligent the Whole. Or, Possibly Not?. (arXiv:2012.12689v2 [eess.SY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.12689
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#20010;&#20307;&#26234;&#33021;&#26159;&#21542;&#23545;&#20110;&#38598;&#20307;&#26234;&#33021;&#30340;&#20135;&#29983;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#21450;&#24590;&#26679;&#30340;&#20010;&#20307;&#26234;&#33021;&#26377;&#21033;&#20110;&#26356;&#22823;&#30340;&#38598;&#20307;&#26234;&#33021;&#12290;&#22312;Lotka-Volterra&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20123;&#20010;&#20307;&#34892;&#20026;&#65292;&#29305;&#21035;&#26159;&#25504;&#39135;&#32773;&#30340;&#34892;&#20026;&#65292;&#26377;&#21033;&#20110;&#19982;&#20854;&#20182;&#31181;&#32676;&#20849;&#23384;&#65292;&#20294;&#22914;&#26524;&#29454;&#29289;&#21644;&#25504;&#39135;&#32773;&#37117;&#36275;&#22815;&#26234;&#33021;&#20197;&#25512;&#26029;&#24444;&#27492;&#30340;&#34892;&#20026;&#65292;&#20849;&#23384;&#23558;&#20276;&#38543;&#30528;&#20004;&#20010;&#31181;&#32676;&#30340;&#26080;&#38480;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#22823;&#33041;&#20013;&#30340;&#31070;&#32463;&#20803;&#19982;&#31038;&#20250;&#20013;&#30340;&#20154;&#31867;&#20043;&#38388;&#30340;&#21033;&#32500;&#22374;&#31867;&#27604;&#65292;&#38382;&#33258;&#24049;&#26159;&#21542;&#20010;&#20307;&#26234;&#33021;&#23545;&#20110;&#38598;&#20307;&#26234;&#33021;&#30340;&#20135;&#29983;&#26159;&#24517;&#35201;&#30340;&#65292;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#24590;&#26679;&#30340;&#20010;&#20307;&#26234;&#33021;&#26377;&#21033;&#20110;&#26356;&#22823;&#30340;&#38598;&#20307;&#26234;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#36830;&#25509;&#20027;&#20041;&#35748;&#30693;&#31185;&#23398;&#12289;&#22522;&#20110;&#20195;&#29702;&#30340;&#24314;&#27169;&#12289;&#32676;&#20307;&#24515;&#29702;&#23398;&#12289;&#32463;&#27982;&#23398;&#21644;&#29289;&#29702;&#23398;&#30340;&#19981;&#21516;&#27934;&#35265;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#27934;&#35265;&#24212;&#29992;&#20110;Lotka-Volterra&#27169;&#22411;&#20013;&#23548;&#33268;&#25504;&#39135;&#32773;&#21644;&#29454;&#29289;&#35201;&#20040;&#20849;&#23384;&#35201;&#20040;&#20840;&#29699;&#28781;&#32477;&#30340;&#26234;&#33021;&#31867;&#22411;&#21644;&#31243;&#24230;&#12290;&#25105;&#20204;&#21457;&#29616;&#20960;&#20010;&#20010;&#20307;&#34892;&#20026; - &#23588;&#20854;&#26159;&#25504;&#39135;&#32773;&#30340;&#34892;&#20026; - &#26377;&#21033;&#20110;&#20849;&#23384;&#65292;&#26368;&#32456;&#22312;&#19968;&#20010;&#24179;&#34913;&#28857;&#21608;&#22260;&#20135;&#29983;&#38663;&#33633;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20063;&#21457;&#29616;&#65292;&#22914;&#26524;&#29454;&#29289;&#21644;&#25504;&#39135;&#32773;&#37117;&#36275;&#22815;&#26234;&#33021;&#20197;&#25512;&#26029;&#24444;&#27492;&#30340;&#34892;&#20026;&#65292;&#20849;&#23384;&#23601;&#20250;&#20276;&#38543;&#30528;&#20004;&#20010;&#31181;&#32676;&#30340;&#26080;&#38480;&#22686;&#38271;&#12290;&#30001;&#20110;Lotka-Volterra&#27169;&#22411;&#26159;&#19981;&#31283;&#23450;&#30340;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore a Leviathan analogy between neurons in a brain and human beings in society, asking ourselves whether individual intelligence is necessary for collective intelligence to emerge and, most importantly, what sort of individual intelligence is conducive of greater collective intelligence. We first review disparate insights from connectionist cognitive science, agent-based modeling, group psychology, economics and physics. Subsequently, we apply these insights to the sort and degrees of intelligence that in the Lotka-Volterra model lead to either co-existence or global extinction of predators and preys.  We find several individual behaviors -- particularly of predators -- that are conducive to co-existence, eventually with oscillations around an equilibrium. However, we also find that if both preys and predators are sufficiently intelligent to extrapolate one other's behavior, co-existence comes along with indefinite growth of both populations. Since the Lotka-Volterra model is al
&lt;/p&gt;</description></item></channel></rss>