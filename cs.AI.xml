<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20026;&#32032;&#25551;&#34917;&#19969;&#37197;&#22791;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20301;&#32622;&#32534;&#30721;&#26469;&#20445;&#25252;&#19981;&#21516;&#32472;&#22270;&#29256;&#26412;&#30340;&#26041;&#27861;&#65292;&#23558;&#32472;&#22270;&#39034;&#24207;&#20449;&#24687;&#23884;&#20837;&#22270;&#33410;&#28857;&#20013;&#65292;&#20197;&#26356;&#22909;&#22320;&#23398;&#20064;&#22270;&#24418;&#32032;&#25551;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2403.17525</link><description>&lt;p&gt;
&#20026;&#22270;&#24418;&#32032;&#25551;&#34920;&#31034;&#35013;&#22791;&#20855;&#26377;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20301;&#32622;&#32534;&#30721;&#30340;&#32032;&#25551;&#34917;&#19969;
&lt;/p&gt;
&lt;p&gt;
Equipping Sketch Patches with Context-Aware Positional Encoding for Graphic Sketch Representation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17525
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20026;&#32032;&#25551;&#34917;&#19969;&#37197;&#22791;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20301;&#32622;&#32534;&#30721;&#26469;&#20445;&#25252;&#19981;&#21516;&#32472;&#22270;&#29256;&#26412;&#30340;&#26041;&#27861;&#65292;&#23558;&#32472;&#22270;&#39034;&#24207;&#20449;&#24687;&#23884;&#20837;&#22270;&#33410;&#28857;&#20013;&#65292;&#20197;&#26356;&#22909;&#22320;&#23398;&#20064;&#22270;&#24418;&#32032;&#25551;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#24133;&#32032;&#25551;&#30340;&#32472;&#21046;&#39034;&#24207;&#35760;&#24405;&#20102;&#23427;&#26159;&#22914;&#20309;&#36880;&#31508;&#30001;&#20154;&#31867;&#21019;&#24314;&#30340;&#12290;&#23545;&#20110;&#22270;&#24418;&#32032;&#25551;&#34920;&#31034;&#23398;&#20064;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#36890;&#36807;&#26681;&#25454;&#22522;&#20110;&#26102;&#38388;&#30340;&#26368;&#36817;&#37051;&#31574;&#30053;&#23558;&#27599;&#20010;&#34917;&#19969;&#19982;&#21478;&#19968;&#20010;&#30456;&#36830;&#65292;&#23558;&#32032;&#25551;&#32472;&#22270;&#39034;&#24207;&#27880;&#20837;&#21040;&#22270;&#36793;&#26500;&#24314;&#20013;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#26500;&#24314;&#30340;&#22270;&#36793;&#21487;&#33021;&#19981;&#21487;&#38752;&#65292;&#22240;&#20026;&#32032;&#25551;&#21487;&#33021;&#26377;&#19981;&#21516;&#29256;&#26412;&#30340;&#32472;&#22270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32463;&#36807;&#21464;&#20307;&#32472;&#21046;&#20445;&#25252;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20026;&#32032;&#25551;&#34917;&#19969;&#37197;&#22791;&#20855;&#26377;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20301;&#32622;&#32534;&#30721;(PE)&#65292;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#32472;&#22270;&#39034;&#24207;&#26469;&#23398;&#20064;&#22270;&#24418;&#32032;&#25551;&#34920;&#31034;&#12290;&#25105;&#20204;&#27809;&#26377;&#23558;&#32032;&#25551;&#32472;&#21046;&#27880;&#20837;&#21040;&#22270;&#36793;&#20013;&#65292;&#32780;&#26159;&#20165;&#23558;&#36825;&#20123;&#39034;&#24207;&#20449;&#24687;&#23884;&#20837;&#21040;&#22270;&#33410;&#28857;&#20013;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#27599;&#20010;&#34917;&#19969;&#23884;&#20837;&#37117;&#37197;&#22791;&#26377;&#27491;&#24358;&#32477;&#23545;PE&#65292;&#20197;&#31361;&#20986;&#32472;&#22270;&#39034;&#24207;&#20013;&#30340;&#39034;&#24207;&#20301;&#32622;&#12290;&#23427;&#30340;&#30456;&#37051;&#34917;&#19969;&#25353;self-att&#30340;&#20215;&#20540;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17525v1 Announce Type: cross  Abstract: The drawing order of a sketch records how it is created stroke-by-stroke by a human being. For graphic sketch representation learning, recent studies have injected sketch drawing orders into graph edge construction by linking each patch to another in accordance to a temporal-based nearest neighboring strategy. However, such constructed graph edges may be unreliable, since a sketch could have variants of drawings. In this paper, we propose a variant-drawing-protected method by equipping sketch patches with context-aware positional encoding (PE) to make better use of drawing orders for learning graphic sketch representation. Instead of injecting sketch drawings into graph edges, we embed these sequential information into graph nodes only. More specifically, each patch embedding is equipped with a sinusoidal absolute PE to highlight the sequential position in the drawing order. And its neighboring patches, ranked by the values of self-att
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;MaleficNet 2.0&#65292;&#19968;&#31181;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#23884;&#20837;&#24694;&#24847;&#36719;&#20214;&#30340;&#26032;&#25216;&#26415;&#65292;&#20854;&#27880;&#20837;&#25216;&#26415;&#20855;&#26377;&#38544;&#34109;&#24615;&#65292;&#19981;&#20250;&#38477;&#20302;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#19988;&#23545;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20013;&#30340;&#24694;&#24847;&#26377;&#25928;&#36127;&#36733;&#36827;&#34892;&#27880;&#20837;</title><link>https://arxiv.org/abs/2403.03593</link><description>&lt;p&gt;
&#24744;&#20449;&#20219;&#24744;&#30340;&#27169;&#22411;&#21527;&#65311;&#28145;&#24230;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#26032;&#20852;&#30340;&#24694;&#24847;&#36719;&#20214;&#23041;&#32961;
&lt;/p&gt;
&lt;p&gt;
Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03593
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;MaleficNet 2.0&#65292;&#19968;&#31181;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#23884;&#20837;&#24694;&#24847;&#36719;&#20214;&#30340;&#26032;&#25216;&#26415;&#65292;&#20854;&#27880;&#20837;&#25216;&#26415;&#20855;&#26377;&#38544;&#34109;&#24615;&#65292;&#19981;&#20250;&#38477;&#20302;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#19988;&#23545;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20013;&#30340;&#24694;&#24847;&#26377;&#25928;&#36127;&#36733;&#36827;&#34892;&#27880;&#20837;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#39640;&#36136;&#37327;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#36825;&#26159;&#22240;&#20026;&#38656;&#35201;&#35745;&#31639;&#21644;&#25216;&#26415;&#35201;&#27714;&#12290;&#36234;&#26469;&#36234;&#22810;&#30340;&#20010;&#20154;&#12289;&#26426;&#26500;&#21644;&#20844;&#21496;&#36234;&#26469;&#36234;&#22810;&#22320;&#20381;&#36182;&#20110;&#22312;&#20844;&#20849;&#20195;&#30721;&#24211;&#20013;&#25552;&#20379;&#30340;&#39044;&#35757;&#32451;&#30340;&#31532;&#19977;&#26041;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#30452;&#25509;&#20351;&#29992;&#25110;&#38598;&#25104;&#21040;&#20135;&#21697;&#31649;&#36947;&#20013;&#32780;&#27809;&#26377;&#29305;&#27530;&#30340;&#39044;&#38450;&#25514;&#26045;&#65292;&#22240;&#20026;&#23427;&#20204;&#23454;&#38469;&#19978;&#21482;&#26159;&#20197;&#24352;&#37327;&#24418;&#24335;&#30340;&#25968;&#25454;&#65292;&#34987;&#35748;&#20026;&#26159;&#23433;&#20840;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#20379;&#24212;&#38142;&#23041;&#32961;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;MaleficNet 2.0&#65292;&#19968;&#31181;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#23884;&#20837;&#33258;&#35299;&#21387;&#33258;&#25191;&#34892;&#24694;&#24847;&#36719;&#20214;&#30340;&#26032;&#25216;&#26415;&#12290;MaleficNet 2.0&#20351;&#29992;&#25193;&#39057;&#20449;&#36947;&#32534;&#30721;&#32467;&#21512;&#32416;&#38169;&#25216;&#26415;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#20013;&#27880;&#20837;&#24694;&#24847;&#26377;&#25928;&#36733;&#33655;&#12290;MaleficNet 2.0&#27880;&#20837;&#25216;&#26415;&#20855;&#26377;&#38544;&#34109;&#24615;&#65292;&#19981;&#20250;&#38477;&#20302;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#23545;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03593v1 Announce Type: cross  Abstract: Training high-quality deep learning models is a challenging task due to computational and technical requirements. A growing number of individuals, institutions, and companies increasingly rely on pre-trained, third-party models made available in public repositories. These models are often used directly or integrated in product pipelines with no particular precautions, since they are effectively just data in tensor form and considered safe. In this paper, we raise awareness of a new machine learning supply chain threat targeting neural networks. We introduce MaleficNet 2.0, a novel technique to embed self-extracting, self-executing malware in neural networks. MaleficNet 2.0 uses spread-spectrum channel coding combined with error correction techniques to inject malicious payloads in the parameters of deep neural networks. MaleficNet 2.0 injection technique is stealthy, does not degrade the performance of the model, and is robust against 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#25361;&#25112;&#19982;&#24320;&#25918;&#38382;&#39064;&#65292;&#21253;&#25324;&#20219;&#21153;&#20998;&#37197;&#20248;&#21270;&#12289;&#22686;&#24378;&#25512;&#29702;&#33021;&#21147;&#12289;&#31649;&#29702;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#25913;&#21892;&#20869;&#23384;&#31649;&#29702;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#22312;&#21306;&#22359;&#38142;&#31995;&#32479;&#20013;&#30340;&#28508;&#21147;&#21644;&#26410;&#26469;&#21457;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.03578</link><description>&lt;p&gt;
LLM&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#65306;&#25361;&#25112;&#19982;&#24320;&#25918;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
LLM Multi-Agent Systems: Challenges and Open Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03578
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#25361;&#25112;&#19982;&#24320;&#25918;&#38382;&#39064;&#65292;&#21253;&#25324;&#20219;&#21153;&#20998;&#37197;&#20248;&#21270;&#12289;&#22686;&#24378;&#25512;&#29702;&#33021;&#21147;&#12289;&#31649;&#29702;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#25913;&#21892;&#20869;&#23384;&#31649;&#29702;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#22312;&#21306;&#22359;&#38142;&#31995;&#32479;&#20013;&#30340;&#28508;&#21147;&#21644;&#26410;&#26469;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#29616;&#26377;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#30740;&#31350;&#24037;&#20316;&#65292;&#24182;&#35782;&#21035;&#20986;&#23578;&#26410;&#20805;&#20998;&#35299;&#20915;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#21033;&#29992;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20869;&#20010;&#20307;&#26234;&#33021;&#20307;&#30340;&#22810;&#26679;&#33021;&#21147;&#21644;&#35282;&#33394;&#65292;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#36890;&#36807;&#21327;&#20316;&#26469;&#22788;&#29702;&#22797;&#26434;&#20219;&#21153;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20248;&#21270;&#20219;&#21153;&#20998;&#37197;&#12289;&#36890;&#36807;&#36845;&#20195;&#36777;&#35770;&#20419;&#36827;&#24378;&#22823;&#25512;&#29702;&#12289;&#31649;&#29702;&#22797;&#26434;&#21644;&#20998;&#23618;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20197;&#21450;&#22686;&#24378;&#20869;&#23384;&#31649;&#29702;&#20197;&#25903;&#25345;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20869;&#30340;&#22797;&#26434;&#20132;&#20114;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#22312;&#21306;&#22359;&#38142;&#31995;&#32479;&#20013;&#24212;&#29992;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#28508;&#21147;&#65292;&#20197;&#21551;&#31034;&#20854;&#22312;&#30495;&#23454;&#20998;&#24067;&#24335;&#31995;&#32479;&#20013;&#30340;&#26410;&#26469;&#21457;&#23637;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores existing works of multi-agent systems and identifies challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents within a multi-agent system, these systems can tackle complex tasks through collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore the potential application of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#35299;&#26500;&#20154;&#24037;&#26234;&#33021;&#36131;&#20219;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21253;&#21547;&#22235;&#31181;&#36131;&#20219;&#24847;&#20041;&#30340;&#26377;&#25928;&#32452;&#21512;&#65292;&#20197;&#25903;&#25345;&#23545;&#20154;&#24037;&#26234;&#33021;&#36131;&#20219;&#30340;&#23454;&#36341;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2308.02608</link><description>&lt;p&gt;
&#35299;&#26500;&#20154;&#24037;&#26234;&#33021;&#36131;&#20219;
&lt;/p&gt;
&lt;p&gt;
Unravelling Responsibility for AI. (arXiv:2308.02608v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35299;&#26500;&#20154;&#24037;&#26234;&#33021;&#36131;&#20219;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21253;&#21547;&#22235;&#31181;&#36131;&#20219;&#24847;&#20041;&#30340;&#26377;&#25928;&#32452;&#21512;&#65292;&#20197;&#25903;&#25345;&#23545;&#20154;&#24037;&#26234;&#33021;&#36131;&#20219;&#30340;&#23454;&#36341;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#28041;&#21450;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#22797;&#26434;&#24773;&#20917;&#19979;&#21512;&#29702;&#24605;&#32771;&#36131;&#20219;&#24212;&#35813;&#25918;&#22312;&#20309;&#22788;&#65292;&#25105;&#20204;&#39318;&#20808;&#38656;&#35201;&#19968;&#20010;&#36275;&#22815;&#28165;&#26224;&#21644;&#35814;&#32454;&#30340;&#36328;&#23398;&#31185;&#35789;&#27719;&#26469;&#35848;&#35770;&#36131;&#20219;&#12290;&#36131;&#20219;&#26159;&#19968;&#31181;&#19977;&#20803;&#20851;&#31995;&#65292;&#28041;&#21450;&#21040;&#19968;&#20010;&#34892;&#20026;&#32773;&#12289;&#19968;&#20010;&#20107;&#20214;&#21644;&#19968;&#31181;&#36131;&#20219;&#26041;&#24335;&#12290;&#20316;&#20026;&#19968;&#31181;&#26377;&#24847;&#35782;&#30340;&#20026;&#20102;&#25903;&#25345;&#23545;&#20154;&#24037;&#26234;&#33021;&#36131;&#20219;&#36827;&#34892;&#23454;&#36341;&#25512;&#29702;&#30340;&#8220;&#35299;&#26500;&#8221;&#36131;&#20219;&#27010;&#24565;&#30340;&#21162;&#21147;&#65292;&#26412;&#25991;&#37319;&#21462;&#20102;&#8220;&#34892;&#20026;&#32773;A&#23545;&#20107;&#20214;O&#36127;&#36131;&#8221;&#30340;&#19977;&#37096;&#20998;&#34920;&#36848;&#65292;&#24182;&#30830;&#23450;&#20102;A&#12289;&#36127;&#36131;&#12289;O&#30340;&#23376;&#31867;&#21035;&#30340;&#26377;&#25928;&#32452;&#21512;&#12290;&#36825;&#20123;&#26377;&#25928;&#32452;&#21512;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#36131;&#20219;&#20018;&#8221;&#65292;&#20998;&#20026;&#22235;&#31181;&#36131;&#20219;&#24847;&#20041;&#65306;&#35282;&#33394;&#36131;&#20219;&#12289;&#22240;&#26524;&#36131;&#20219;&#12289;&#27861;&#24459;&#36131;&#20219;&#21644;&#36947;&#24503;&#36131;&#20219;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#36816;&#34892;&#31034;&#20363;&#36827;&#34892;&#20102;&#35828;&#26126;&#65292;&#19968;&#20010;&#28041;&#21450;&#21307;&#30103;AI&#31995;&#32479;&#65292;&#21478;&#19968;&#20010;&#28041;&#21450;AV&#19982;&#34892;&#20154;&#30340;&#33268;&#21629;&#30896;&#25758;&#12290;
&lt;/p&gt;
&lt;p&gt;
To reason about where responsibility does and should lie in complex situations involving AI-enabled systems, we first need a sufficiently clear and detailed cross-disciplinary vocabulary for talking about responsibility. Responsibility is a triadic relation involving an actor, an occurrence, and a way of being responsible. As part of a conscious effort towards 'unravelling' the concept of responsibility to support practical reasoning about responsibility for AI, this paper takes the three-part formulation, 'Actor A is responsible for Occurrence O' and identifies valid combinations of subcategories of A, is responsible for, and O. These valid combinations - which we term "responsibility strings" - are grouped into four senses of responsibility: role-responsibility; causal responsibility; legal liability-responsibility; and moral responsibility. They are illustrated with two running examples, one involving a healthcare AI-based system and another the fatal collision of an AV with a pedes
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02293</link><description>&lt;p&gt;
&#29992;&#27491;&#21017;&#21270;&#39640;&#38454;&#24635;&#21464;&#24046;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02293
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#39640;&#24230;&#34920;&#36798;&#30340;&#21442;&#25968;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#24314;&#27169;&#22797;&#26434;&#27010;&#24565;&#65292;&#20294;&#35757;&#32451;&#36825;&#31181;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#24050;&#30693;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#19968;&#31181;k&#38454;&#24635;&#21464;&#24046;&#65288;k-TV&#65289;&#27491;&#21017;&#21270;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#35201;&#35757;&#32451;&#30340;&#21442;&#25968;&#27169;&#22411;&#30340;k&#38454;&#23548;&#25968;&#30340;&#24179;&#26041;&#31215;&#20998;&#65292;&#36890;&#36807;&#24809;&#32602;k-TV&#26469;&#20135;&#29983;&#19968;&#20010;&#26356;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;&#23613;&#31649;&#23558;k-TV&#39033;&#24212;&#29992;&#20110;&#19968;&#33324;&#30340;&#21442;&#25968;&#27169;&#22411;&#30001;&#20110;&#31215;&#20998;&#32780;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#65292;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#24102;&#26377;k-TV&#27491;&#21017;&#21270;&#30340;&#19968;&#33324;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#26174;&#24335;&#30340;&#25968;&#20540;&#31215;&#20998;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#32467;&#26500;&#20219;&#24847;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#36827;&#34892;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#20248;&#21270;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
&lt;/p&gt;</description></item></channel></rss>