<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#35770;&#25991;&#35752;&#35770;&#20102;&#38754;&#20020;&#33021;&#28304;&#12289;&#23545;&#40784;&#21644;&#20174;&#29421;&#20041;&#20154;&#24037;&#26234;&#33021;&#21040;AGI&#30340;&#19977;&#22823;&#25361;&#25112;&#30340;&#31995;&#32479;&#21270;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#22312;&#33021;&#28304;&#28040;&#32791;&#12289;&#31995;&#32479;&#35774;&#35745;&#21644;&#23545;&#40784;&#38382;&#39064;&#19978;&#23384;&#22312;&#19981;&#36275;&#65292;&#32780;&#31995;&#32479;&#35774;&#35745;&#22312;&#35299;&#20915;&#23545;&#40784;&#12289;&#33021;&#28304;&#21644;AGI&#22823;&#25361;&#25112;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.15274</link><description>&lt;p&gt;
&#31995;&#32479;&#21270;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#29992;&#20110;AGI&#65306;&#35299;&#20915;&#23545;&#40784;&#12289;&#33021;&#28304;&#21644;AGI&#22823;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges. (arXiv:2310.15274v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15274
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35752;&#35770;&#20102;&#38754;&#20020;&#33021;&#28304;&#12289;&#23545;&#40784;&#21644;&#20174;&#29421;&#20041;&#20154;&#24037;&#26234;&#33021;&#21040;AGI&#30340;&#19977;&#22823;&#25361;&#25112;&#30340;&#31995;&#32479;&#21270;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#22312;&#33021;&#28304;&#28040;&#32791;&#12289;&#31995;&#32479;&#35774;&#35745;&#21644;&#23545;&#40784;&#38382;&#39064;&#19978;&#23384;&#22312;&#19981;&#36275;&#65292;&#32780;&#31995;&#32479;&#35774;&#35745;&#22312;&#35299;&#20915;&#23545;&#40784;&#12289;&#33021;&#28304;&#21644;AGI&#22823;&#25361;&#25112;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#38754;&#20020;&#30528;&#19977;&#22823;&#25361;&#25112;&#65306;&#33021;&#28304;&#22721;&#22418;&#12289;&#23545;&#40784;&#38382;&#39064;&#21644;&#20174;&#29421;&#20041;&#20154;&#24037;&#26234;&#33021;&#21040;AGI&#30340;&#39134;&#36291;&#12290;&#24403;&#20195;&#20154;&#24037;&#26234;&#33021;&#35299;&#20915;&#26041;&#26696;&#22312;&#27169;&#22411;&#35757;&#32451;&#21644;&#26085;&#24120;&#36816;&#34892;&#36807;&#31243;&#20013;&#28040;&#32791;&#30528;&#19981;&#21487;&#25345;&#32493;&#30340;&#33021;&#28304;&#12290;&#26356;&#31967;&#31957;&#30340;&#26159;&#65292;&#33258;2020&#24180;&#20197;&#26469;&#65292;&#27599;&#20010;&#26032;&#30340;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#25152;&#38656;&#30340;&#35745;&#31639;&#37327;&#27599;&#20004;&#20010;&#26376;&#23601;&#32763;&#20493;&#65292;&#30452;&#25509;&#23548;&#33268;&#33021;&#28304;&#28040;&#32791;&#30340;&#22686;&#21152;&#12290;&#20174;&#20154;&#24037;&#26234;&#33021;&#21040;AGI&#30340;&#39134;&#36291;&#38656;&#35201;&#22810;&#20010;&#21151;&#33021;&#23376;&#31995;&#32479;&#20197;&#24179;&#34913;&#30340;&#26041;&#24335;&#36816;&#20316;&#65292;&#36825;&#38656;&#35201;&#19968;&#20010;&#31995;&#32479;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#32570;&#20047;&#31995;&#32479;&#35774;&#35745;&#65307;&#21363;&#20351;&#31995;&#32479;&#29305;&#24449;&#22312;&#20154;&#33041;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#65292;&#20174;&#23427;&#22788;&#29702;&#20449;&#24687;&#30340;&#26041;&#24335;&#21040;&#23427;&#20570;&#20986;&#20915;&#31574;&#30340;&#26041;&#24335;&#12290;&#21516;&#26679;&#65292;&#24403;&#21069;&#30340;&#23545;&#40784;&#21644;&#20154;&#24037;&#26234;&#33021;&#20262;&#29702;&#26041;&#27861;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#35270;&#20102;&#31995;&#32479;&#35774;&#35745;&#65292;&#28982;&#32780;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#33041;&#30340;&#31995;&#32479;&#26550;&#26500;&#22312;&#20581;&#24247;&#30340;&#36947;&#24503;&#20915;&#31574;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#31995;&#32479;&#35774;&#35745;&#22312;&#35299;&#20915;&#23545;&#40784;&#12289;&#33021;&#28304;&#21644;AGI&#22823;&#25361;&#25112;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
AI faces a trifecta of grand challenges the Energy Wall, the Alignment Problem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume unsustainable amounts of energy during model training and daily operations.Making things worse, the amount of computation required to train each new AI model has been doubling every 2 months since 2020, directly translating to increases in energy consumption.The leap from AI to AGI requires multiple functional subsystems operating in a balanced manner, which requires a system architecture. However, the current approach to artificial intelligence lacks system design; even though system characteristics play a key role in the human brain from the way it processes information to how it makes decisions. Similarly, current alignment and AI ethics approaches largely ignore system design, yet studies show that the brains system architecture plays a critical role in healthy moral decisions.In this paper, we argue that system design is critically im
&lt;/p&gt;</description></item><item><title>RL4CO&#26159;&#19968;&#20010;&#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#30340;&#24191;&#27867;&#24378;&#21270;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;&#65292;&#30528;&#37325;&#20110;&#21487;&#25193;&#23637;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#30340;&#35780;&#20272;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20123;&#26368;&#26032;&#26041;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#30340;&#34920;&#29616;&#30456;&#23545;&#36739;&#24046;&#65292;&#24378;&#35843;&#20102;&#23545;&#31070;&#32463;CO&#27714;&#35299;&#22120;&#24615;&#33021;&#30340;&#24179;&#34913;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.17100</link><description>&lt;p&gt;
RL4CO: &#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#30340;&#24191;&#27867;&#24378;&#21270;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark. (arXiv:2306.17100v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17100
&lt;/p&gt;
&lt;p&gt;
RL4CO&#26159;&#19968;&#20010;&#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#30340;&#24191;&#27867;&#24378;&#21270;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;&#65292;&#30528;&#37325;&#20110;&#21487;&#25193;&#23637;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#30340;&#35780;&#20272;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20123;&#26368;&#26032;&#26041;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#30340;&#34920;&#29616;&#30456;&#23545;&#36739;&#24046;&#65292;&#24378;&#35843;&#20102;&#23545;&#31070;&#32463;CO&#27714;&#35299;&#22120;&#24615;&#33021;&#30340;&#24179;&#34913;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;RL4CO&#65292;&#36825;&#26159;&#19968;&#20010;&#24191;&#27867;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#65288;CO&#65289;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;RL4CO&#37319;&#29992;&#26368;&#20808;&#36827;&#30340;&#36719;&#20214;&#24211;&#21644;&#26368;&#20339;&#23454;&#36341;&#65292;&#22914;&#27169;&#22359;&#21270;&#21644;&#37197;&#32622;&#31649;&#29702;&#65292;&#20197;&#20415;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#36731;&#26494;&#20462;&#25913;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12289;&#29615;&#22659;&#21644;&#31639;&#27861;&#12290;&#19982;&#29616;&#26377;&#30340;&#19987;&#27880;&#20110;&#29305;&#23450;&#20219;&#21153;&#65288;&#22914;&#26053;&#34892;&#25512;&#38144;&#21592;&#38382;&#39064;&#65289;&#36827;&#34892;&#24615;&#33021;&#35780;&#20272;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#24378;&#35843;&#21487;&#25193;&#23637;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#23545;&#20110;&#21508;&#31181;&#20248;&#21270;&#20219;&#21153;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36824;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#21508;&#31181;&#27169;&#22411;&#22312;&#26679;&#26412;&#25928;&#29575;&#12289;&#38646;-shot&#27867;&#21270;&#21644;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19968;&#20123;&#26368;&#26032;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#22312;&#20351;&#29992;&#36825;&#20123;&#26032;&#25351;&#26631;&#36827;&#34892;&#35780;&#20272;&#26102;&#33853;&#21518;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#34920;&#26126;&#26377;&#24517;&#35201;&#26356;&#21152;&#24179;&#34913;&#22320;&#35780;&#20272;&#31070;&#32463;CO&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#24076;&#26395;RL4CO&#33021;&#22815;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#19968;&#20010;&#32508;&#21512;&#24615;&#30340;&#22522;&#20934;&#27979;&#35797;&#24037;&#20855;&#65292;&#20197;&#36827;&#19968;&#27493;&#25512;&#21160;&#24378;&#21270;&#23398;&#20064;&#22312;&#32452;&#21512;&#20248;&#21270;&#39046;&#22495;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark. RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms. Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks. We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models. Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers. We hope RL4CO will 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65292;&#21363;&#20854;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#65306;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#65292;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#30410;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#12290;</title><link>http://arxiv.org/abs/2306.04542</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65306;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65292;&#21363;&#20854;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#65306;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#65292;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#30410;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36880;&#28176;&#28155;&#21152;&#21644;&#21024;&#38500;&#22122;&#22768;&#26469;&#23398;&#20064;&#35757;&#32451;&#25968;&#25454;&#30340;&#28508;&#22312;&#20998;&#24067;&#20197;&#29983;&#25104;&#25968;&#25454;&#12290;&#25193;&#25955;&#27169;&#22411;&#30340;&#32452;&#25104;&#37096;&#20998;&#24050;&#32463;&#21463;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#65292;&#35768;&#22810;&#35774;&#35745;&#36873;&#25321;&#34987;&#25552;&#20986;&#12290;&#29616;&#26377;&#30340;&#35780;&#35770;&#20027;&#35201;&#20851;&#27880;&#39640;&#23618;&#27425;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23545;&#32452;&#20214;&#30340;&#35774;&#35745;&#22522;&#30784;&#35206;&#30422;&#36739;&#23569;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#20840;&#38754;&#32780;&#36830;&#36143;&#30340;&#32508;&#36848;&#65292;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#32452;&#20214;&#35774;&#35745;&#36873;&#25321;&#36827;&#34892;&#20998;&#26512;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32508;&#36848;&#25353;&#29031;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#36827;&#34892;&#32452;&#32455;&#65292;&#21363;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#25552;&#20379;&#25193;&#25955;&#27169;&#22411;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#65292;&#26377;&#21161;&#20110;&#26410;&#26469;&#30740;&#31350;&#20998;&#26512;&#20010;&#20307;&#32452;&#20214;&#12289;&#35774;&#35745;&#36873;&#25321;&#30340;&#36866;&#29992;&#24615;&#20197;&#21450;&#25193;&#25955;&#27169;&#22411;&#30340;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are generative models, which gradually add and remove noise to learn the underlying distribution of training data for data generation. The components of diffusion models have gained significant attention with many design choices proposed. Existing reviews have primarily focused on higher-level solutions, thereby covering less on the design fundamentals of components. This study seeks to address this gap by providing a comprehensive and coherent review on component-wise design choices in diffusion models. Specifically, we organize this review according to their three key components, namely the forward process, the reverse process, and the sampling procedure. This allows us to provide a fine-grained perspective of diffusion models, benefiting future studies in the analysis of individual components, the applicability of design choices, and the implementation of diffusion models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;XAI&#35780;&#20272;&#20013;&#26368;&#26222;&#36941;&#30340;&#20154;&#20026;&#27010;&#24565;&#8212;&#8212;&#35299;&#37322;&#21512;&#29702;&#24615;&#12290;&#34429;&#28982;&#19968;&#30452;&#34987;&#21046;&#23450;&#20026;AI&#21487;&#35299;&#37322;&#24615;&#20219;&#21153;&#30340;&#37325;&#35201;&#35780;&#20272;&#30446;&#26631;&#65292;&#20294;&#26159;&#35780;&#20272;XAI&#30340;&#21512;&#29702;&#24615;&#26377;&#26102;&#26159;&#26377;&#23475;&#30340;&#65292;&#19988;&#26080;&#27861;&#36798;&#21040;&#27169;&#22411;&#21487;&#29702;&#35299;&#24615;&#12289;&#36879;&#26126;&#24230;&#21644;&#21487;&#20449;&#24230;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2303.17707</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#20154;&#24037;&#26234;&#33021;&#21487;&#35299;&#37322;&#24615;&#19982;&#21512;&#29702;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rethinking AI Explainability and Plausibility. (arXiv:2303.17707v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17707
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;XAI&#35780;&#20272;&#20013;&#26368;&#26222;&#36941;&#30340;&#20154;&#20026;&#27010;&#24565;&#8212;&#8212;&#35299;&#37322;&#21512;&#29702;&#24615;&#12290;&#34429;&#28982;&#19968;&#30452;&#34987;&#21046;&#23450;&#20026;AI&#21487;&#35299;&#37322;&#24615;&#20219;&#21153;&#30340;&#37325;&#35201;&#35780;&#20272;&#30446;&#26631;&#65292;&#20294;&#26159;&#35780;&#20272;XAI&#30340;&#21512;&#29702;&#24615;&#26377;&#26102;&#26159;&#26377;&#23475;&#30340;&#65292;&#19988;&#26080;&#27861;&#36798;&#21040;&#27169;&#22411;&#21487;&#29702;&#35299;&#24615;&#12289;&#36879;&#26126;&#24230;&#21644;&#21487;&#20449;&#24230;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20351;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#31639;&#27861;&#31526;&#21512;&#20154;&#31867;&#20132;&#27969;&#35268;&#33539;&#65292;&#25903;&#25345;&#20154;&#31867;&#25512;&#29702;&#36807;&#31243;&#65292;&#24182;&#28385;&#36275;&#20154;&#31867;&#23545;&#20110;AI&#35299;&#37322;&#30340;&#38656;&#27714;&#65292;&#35774;&#23450;&#36866;&#24403;&#30340;&#35780;&#20272;&#30446;&#26631;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#35299;&#37322;&#21512;&#29702;&#24615;&#65292;&#36825;&#26159;XAI&#35780;&#20272;&#20013;&#26368;&#26222;&#36941;&#30340;&#20154;&#20026;&#27010;&#24565;&#12290;&#21512;&#29702;&#24615;&#34913;&#37327;&#26426;&#22120;&#35299;&#37322;&#19982;&#20154;&#31867;&#35299;&#37322;&#30456;&#27604;&#30340;&#21512;&#29702;&#31243;&#24230;&#12290;&#21512;&#29702;&#24615;&#19968;&#30452;&#34987;&#20256;&#32479;&#22320;&#21046;&#23450;&#20026;AI&#21487;&#35299;&#37322;&#24615;&#20219;&#21153;&#30340;&#37325;&#35201;&#35780;&#20272;&#30446;&#26631;&#12290;&#25105;&#20204;&#21453;&#23545;&#36825;&#20010;&#24819;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#20248;&#21270;&#21644;&#35780;&#20272;XAI&#30340;&#21512;&#29702;&#24615;&#26377;&#26102;&#26159;&#26377;&#23475;&#30340;&#65292;&#19988;&#26080;&#27861;&#36798;&#21040;&#27169;&#22411;&#21487;&#29702;&#35299;&#24615;&#12289;&#36879;&#26126;&#24230;&#21644;&#21487;&#20449;&#24230;&#30340;&#30446;&#30340;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#35780;&#20272;XAI&#31639;&#27861;&#30340;&#21512;&#29702;&#24615;&#20250;&#35268;&#33539;&#26426;&#22120;&#35299;&#37322;&#65292;&#20197;&#34920;&#36798;&#19982;&#20154;&#31867;&#35299;&#37322;&#23436;&#20840;&#30456;&#21516;&#30340;&#20869;&#23481;&#65292;&#36825;&#20559;&#31163;&#20102;&#20154;&#31867;&#35299;&#37322;&#30340;&#22522;&#26412;&#21160;&#26426;&#65306;&#34920;&#36798;&#33258;&#24049;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Setting proper evaluation objectives for explainable artificial intelligence (XAI) is vital for making XAI algorithms follow human communication norms, support human reasoning processes, and fulfill human needs for AI explanations. In this article, we examine explanation plausibility, which is the most pervasive human-grounded concept in XAI evaluation. Plausibility measures how reasonable the machine explanation is compared to the human explanation. Plausibility has been conventionally formulated as an important evaluation objective for AI explainability tasks. We argue against this idea, and show how optimizing and evaluating XAI for plausibility is sometimes harmful, and always ineffective to achieve model understandability, transparency, and trustworthiness. Specifically, evaluating XAI algorithms for plausibility regularizes the machine explanation to express exactly the same content as human explanation, which deviates from the fundamental motivation for humans to explain: expres
&lt;/p&gt;</description></item></channel></rss>