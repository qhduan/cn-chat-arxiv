<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#30740;&#31350;&#23454;&#35777;&#20998;&#26512;&#20102;11&#31181;&#27969;&#34892;&#30340;&#19987;&#38376;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20116;&#31181;&#35821;&#35328;&#19978;&#29983;&#25104;&#30340;&#36755;&#20986;&#65292;&#21457;&#29616;&#20854;&#20013;26.4%&#21040;73.7%&#30340;&#20195;&#30721;&#32763;&#35793;&#38656;&#35201;&#21518;&#22788;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.17214</link><description>&lt;p&gt;
&#25506;&#31350;&#36755;&#20986;&#26684;&#24335;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20195;&#30721;&#32763;&#35793;&#35780;&#20272;&#20013;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23454;&#35777;&#20998;&#26512;&#20102;11&#31181;&#27969;&#34892;&#30340;&#19987;&#38376;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20116;&#31181;&#35821;&#35328;&#19978;&#29983;&#25104;&#30340;&#36755;&#20986;&#65292;&#21457;&#29616;&#20854;&#20013;26.4%&#21040;73.7%&#30340;&#20195;&#30721;&#32763;&#35793;&#38656;&#35201;&#21518;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#20195;&#30721;&#32763;&#35793;&#26159;&#36719;&#20214;&#24037;&#31243;&#20013;&#38271;&#26399;&#23384;&#22312;&#19988;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#26377;&#21161;&#20110;&#29616;&#20195;&#21270;&#36951;&#30041;&#31995;&#32479;&#65292;&#30830;&#20445;&#36328;&#24179;&#21488;&#20860;&#23481;&#24615;&#65292;&#25552;&#21319;&#36719;&#20214;&#24615;&#33021;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21450;&#20854;&#22312;&#20195;&#30721;&#32763;&#35793;&#20013;&#30340;&#24212;&#29992;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23545;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#30340;&#38656;&#27714;&#36234;&#26469;&#36234;&#24378;&#28872;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#22312;&#20116;&#31181;&#35821;&#35328;&#65288;&#21253;&#25324;C&#12289;C++&#12289;Go&#12289;Java&#21644;Python&#65289;&#19978;&#65292;&#20174;1B&#21040;46.7B&#30340;&#21442;&#25968;&#33539;&#22260;&#20869;&#23545;&#21313;&#19968;&#31181;&#27969;&#34892;&#30340;&#19987;&#38376;&#35843;&#25972;&#30340;LLMs&#29983;&#25104;&#30340;&#36755;&#20986;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#24182;&#28085;&#30422;3820&#20010;&#32763;&#35793;&#23545;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21457;&#29616;&#65292;&#22312;&#25105;&#20204;&#35780;&#20272;&#30340;LLMs&#20013;&#65292;26.4%&#21040;73.7%&#30340;&#20195;&#30721;&#32763;&#35793;&#38656;&#35201;&#21518;&#22788;&#29702;&#65292;&#22240;&#20026;&#36825;&#20123;&#32763;&#35793;&#36890;&#24120;&#21253;&#21547;&#20195;&#30721;&#12289;&#24341;&#21495;&#21644;&#25991;&#26412;&#30340;&#28151;&#21512;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#32431;&#28304;&#20195;&#30721;&#12290;&#24573;&#35270;&#36825;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#26684;&#24335;&#21487;&#33021;&#19981;&#32463;&#24847;&#38388;&#23548;&#33268;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17214v1 Announce Type: cross  Abstract: Code translation between programming languages is a long-existing and critical task in software engineering, facilitating the modernization of legacy systems, ensuring cross-platform compatibility, and enhancing software performance. With the recent advances in large language models (LLMs) and their applications to code translation, there is an increasing need for comprehensive evaluation of these models. In this study, we empirically analyze the generated outputs of eleven popular instruct-tuned LLMs with parameters ranging from 1B up to 46.7B on 3,820 translation pairs across five languages, including C, C++, Go, Java, and Python. Our analysis found that between 26.4% and 73.7% of code translations produced by our evaluated LLMs necessitate post-processing, as these translations often include a mix of code, quotes, and text rather than being purely source code. Overlooking the output format of these models can inadvertently lead to u
&lt;/p&gt;</description></item><item><title>DeAL&#26159;&#19968;&#20010;&#20801;&#35768;&#29992;&#25143;&#33258;&#23450;&#20041;&#22870;&#21169;&#20989;&#25968;&#24182;&#23454;&#29616;&#35299;&#30721;&#26102;&#23545;&#40784;LLMs&#30340;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2402.06147</link><description>&lt;p&gt;
DeAL&#65306;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35299;&#30721;&#26102;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
DeAL: Decoding-time Alignment for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06147
&lt;/p&gt;
&lt;p&gt;
DeAL&#26159;&#19968;&#20010;&#20801;&#35768;&#29992;&#25143;&#33258;&#23450;&#20041;&#22870;&#21169;&#20989;&#25968;&#24182;&#23454;&#29616;&#35299;&#30721;&#26102;&#23545;&#40784;LLMs&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29616;&#22312;&#26399;&#26395;&#29983;&#25104;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#30340;&#20869;&#23481;&#12290;&#30446;&#21069;&#30340;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#27169;&#22411;&#35757;&#32451;&#26102;&#38388;&#23545;&#40784;&#19978;&#65292;&#36890;&#36807;&#35832;&#22914;&#24378;&#21270;&#23398;&#20064;&#19982;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#31561;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#19981;&#28165;&#26970;&#36825;&#20123;&#26041;&#27861;&#26159;&#21542;&#26377;&#25928;&#22320;&#25945;&#23548;&#27169;&#22411;&#23545;&#40784;&#30446;&#26631;&#12290;&#39318;&#20808;&#65292;&#26080;&#27861;&#25972;&#21512;&#22810;&#20010;&#33258;&#23450;&#20041;&#22870;&#21169;&#21644;&#20381;&#36182;&#27169;&#22411;&#24320;&#21457;&#32773;&#23545;&#36890;&#29992;&#21644;&#38745;&#24577;&#21407;&#21017;&#30340;&#29702;&#35299;&#26159;&#20027;&#35201;&#23616;&#38480;&#12290;&#20854;&#27425;&#65292;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#27531;&#30041;&#24046;&#36317;&#20197;&#21450;&#36825;&#20123;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#20063;&#20540;&#24471;&#36136;&#30097;&#65288;&#20363;&#22914;&#65292;&#21363;&#20351;&#22312;&#23433;&#20840;&#35757;&#32451;&#21518;&#20173;&#28982;&#23481;&#26131;&#34987;&#36234;&#29425;&#65289;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DeAL&#65292;&#19968;&#20010;&#20801;&#35768;&#29992;&#25143;&#33258;&#23450;&#20041;&#22870;&#21169;&#20989;&#25968;&#24182;&#23454;&#29616;&#35299;&#30721;&#26102;&#23545;&#40784;LLMs&#65288;DeAL&#65289;&#30340;&#26694;&#26550;&#12290;&#26680;&#24515;&#24605;&#24819;&#22312;&#20110;&#23558;&#35299;&#30721;&#35270;&#20026;&#19968;&#20010;&#21551;&#21457;&#24335;&#24341;&#23548;&#30340;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#20419;&#20351;&#20351;&#29992;&#21508;&#31181;&#23545;&#40784;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20197;&#32534;&#31243;&#32422;&#26463;&#20026;&#20363;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are nowadays expected to generate content aligned with human preferences. Current work focuses on alignment at model training time, through techniques such as Reinforcement Learning with Human Feedback (RLHF). However, it is unclear if such methods are an effective choice to teach alignment objectives to the model. First, the inability to incorporate multiple, custom rewards and reliance on a model developer's view of universal and static principles are key limitations. Second, the residual gaps in model training and the reliability of such approaches are also questionable (e.g. susceptibility to jail-breaking even after safety training). To address these, we propose DeAL, a framework that allows the user to customize reward functions and enables Decoding-time Alignment of LLMs (DeAL). At its core, we view decoding as a heuristic-guided search process and facilitate the use of a wide variety of alignment objectives. Our experiments with programmatic constra
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;COAT&#65306;&#22240;&#26524;&#34920;&#31034;&#21161;&#25163;&#65292;&#35813;&#21161;&#25163;&#20174;&#21407;&#22987;&#35266;&#27979;&#25968;&#25454;&#20013;&#25552;&#21462;&#28508;&#22312;&#30340;&#22240;&#26524;&#22240;&#23376;&#65292;&#24182;&#23558;&#20854;&#36716;&#21270;&#20026;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#20026;&#25506;&#32034;&#38544;&#34255;&#19990;&#30028;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#20250;&#12290;</title><link>https://arxiv.org/abs/2402.03941</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25506;&#32034;&#38544;&#34255;&#19990;&#30028;
&lt;/p&gt;
&lt;p&gt;
Discovery of the Hidden World with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03941
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;COAT&#65306;&#22240;&#26524;&#34920;&#31034;&#21161;&#25163;&#65292;&#35813;&#21161;&#25163;&#20174;&#21407;&#22987;&#35266;&#27979;&#25968;&#25454;&#20013;&#25552;&#21462;&#28508;&#22312;&#30340;&#22240;&#26524;&#22240;&#23376;&#65292;&#24182;&#23558;&#20854;&#36716;&#21270;&#20026;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#20026;&#25506;&#32034;&#38544;&#34255;&#19990;&#30028;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#36215;&#28304;&#20110;&#20174;&#24050;&#30693;&#20107;&#23454;&#21644;&#35266;&#23519;&#20013;&#21457;&#29616;&#26032;&#30340;&#22240;&#26524;&#30693;&#35782;&#12290;&#20256;&#32479;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#39640;&#36136;&#37327;&#30340;&#27979;&#37327;&#21464;&#37327;&#65292;&#36890;&#24120;&#30001;&#20154;&#31867;&#19987;&#23478;&#25552;&#20379;&#65292;&#20197;&#25214;&#21040;&#22240;&#26524;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#65292;&#22240;&#26524;&#21464;&#37327;&#36890;&#24120;&#26080;&#27861;&#33719;&#21462;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23835;&#36215;&#20026;&#20174;&#21407;&#22987;&#35266;&#27979;&#25968;&#25454;&#20013;&#21457;&#29616;&#39640;&#32423;&#38544;&#34255;&#21464;&#37327;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#20250;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;COAT&#65306;&#22240;&#26524;&#34920;&#31034;&#21161;&#25163;&#12290;COAT&#23558;LLMs&#20316;&#20026;&#22240;&#32032;&#25552;&#20379;&#22120;&#24341;&#20837;&#65292;&#25552;&#21462;&#20986;&#26469;&#33258;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#28508;&#22312;&#22240;&#26524;&#22240;&#23376;&#12290;&#27492;&#22806;&#65292;LLMs&#36824;&#21487;&#20197;&#34987;&#25351;&#31034;&#25552;&#20379;&#29992;&#20110;&#25910;&#38598;&#25968;&#25454;&#20540;&#65288;&#20363;&#22914;&#27880;&#37322;&#26631;&#20934;&#65289;&#30340;&#39069;&#22806;&#20449;&#24687;&#65292;&#24182;&#23558;&#21407;&#22987;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#36827;&#19968;&#27493;&#35299;&#26512;&#20026;&#32467;&#26500;&#21270;&#25968;&#25454;&#12290;&#27880;&#37322;&#25968;&#25454;&#23558;&#34987;&#36755;&#20837;&#21040;...
&lt;/p&gt;
&lt;p&gt;
Science originates with discovering new causal knowledge from a combination of known facts and observations. Traditional causal discovery approaches mainly rely on high-quality measured variables, usually given by human experts, to find causal relations. However, the causal variables are usually unavailable in a wide range of real-world applications. The rise of large language models (LLMs) that are trained to learn rich knowledge from the massive observations of the world, provides a new opportunity to assist with discovering high-level hidden variables from the raw observational data. Therefore, we introduce COAT: Causal representatiOn AssistanT. COAT incorporates LLMs as a factor proposer that extracts the potential causal factors from unstructured data. Moreover, LLMs can also be instructed to provide additional information used to collect data values (e.g., annotation criteria) and to further parse the raw unstructured data into structured data. The annotated data will be fed to a
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35843;&#26597;&#20102;&#25945;&#32946;&#39046;&#22495;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#24635;&#32467;&#20102;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2401.07518</link><description>&lt;p&gt;
&#25945;&#32946;&#39046;&#22495;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#35843;&#26597;&#65306;&#20998;&#31867;&#20307;&#31995;&#12289;&#31995;&#32479;&#32508;&#36848;&#21644;&#26410;&#26469;&#36235;&#21183;
&lt;/p&gt;
&lt;p&gt;
Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.07518
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35843;&#26597;&#20102;&#25945;&#32946;&#39046;&#22495;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#24635;&#32467;&#20102;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#26088;&#22312;&#36890;&#36807;&#35745;&#31639;&#26426;&#31185;&#23398;&#39046;&#22495;&#30340;&#25216;&#26415;&#20998;&#26512;&#25991;&#26412;&#65292;&#24212;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#12289;&#21830;&#19994;&#21644;&#25945;&#32946;&#39046;&#22495;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#25945;&#32946;&#39046;&#22495;&#65292;NLP&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#25945;&#23398;&#21644;&#23398;&#20064;&#26041;&#38754;&#30340;&#24110;&#21161;&#12290;&#26412;&#35843;&#26597;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#35299;&#20915;&#19982;&#25945;&#32946;&#39046;&#22495;&#30456;&#20851;&#30340;&#38382;&#39064;&#65292;&#24182;&#22238;&#39038;&#20102;NLP&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20174;&#20171;&#32461;&#30456;&#20851;&#32972;&#26223;&#24320;&#22987;&#65292;&#28982;&#21518;&#25552;&#20986;&#25945;&#32946;&#39046;&#22495;NLP&#30340;&#20998;&#31867;&#31995;&#32479;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#26681;&#25454;&#19978;&#36848;&#20998;&#31867;&#31995;&#32479;&#35828;&#26126;&#20219;&#21153;&#23450;&#20041;&#12289;&#25361;&#25112;&#21644;&#30456;&#24212;&#30340;&#25216;&#26415;&#12290;&#20043;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#39046;&#22495;&#20013;&#30340;&#19968;&#20123;&#29616;&#26377;&#28436;&#31034;&#65292;&#24182;&#24635;&#32467;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural Language Processing (NLP) aims to analyze the text via techniques in the computer science field. It serves the applications in healthcare, commerce, and education domains. Particularly, NLP has been applied to the education domain to help teaching and learning. In this survey, we review recent advances in NLP with a focus on solving problems related to the education domain. In detail, we begin with introducing the relevant background. Then, we present the taxonomy of NLP in the education domain. Next, we illustrate the task definition, challenges, and corresponding techniques based on the above taxonomy. After that, we showcase some off-the-shelf demonstrations in this domain and conclude with future directions.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#25512;&#29305;&#25968;&#25454;&#36827;&#34892;&#20132;&#36890;&#29992;&#25143;&#21453;&#39304;&#30340;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#23569;&#26679;&#26412;&#23398;&#20064;&#35782;&#21035;&#25512;&#29305;&#20013;&#30340;&#38382;&#39064;&#65292;&#24182;&#37319;&#29992;&#35789;&#20856;&#24773;&#24863;&#20998;&#26512;&#27169;&#22411;&#35780;&#20272;&#25512;&#29305;&#24773;&#24863;&#30340;&#24378;&#24230;&#21644;&#26497;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.07086</link><description>&lt;p&gt;
&#21033;&#29992;&#25512;&#29305;&#25968;&#25454;&#36827;&#34892;&#20132;&#36890;&#29992;&#25143;&#21453;&#39304;&#30340;&#24773;&#24863;&#20998;&#26512;&#65306;&#19968;&#20010;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Leveraging Twitter Data for Sentiment Analysis of Transit User Feedback: An NLP Framework. (arXiv:2310.07086v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#25512;&#29305;&#25968;&#25454;&#36827;&#34892;&#20132;&#36890;&#29992;&#25143;&#21453;&#39304;&#30340;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#23569;&#26679;&#26412;&#23398;&#20064;&#35782;&#21035;&#25512;&#29305;&#20013;&#30340;&#38382;&#39064;&#65292;&#24182;&#37319;&#29992;&#35789;&#20856;&#24773;&#24863;&#20998;&#26512;&#27169;&#22411;&#35780;&#20272;&#25512;&#29305;&#24773;&#24863;&#30340;&#24378;&#24230;&#21644;&#26497;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#36890;&#36807;&#20132;&#36890;&#35843;&#26597;&#25910;&#38598;&#29992;&#25143;&#21453;&#39304;&#30340;&#26041;&#27861;&#24448;&#24448;&#32791;&#26102;&#12289;&#36164;&#28304;&#23494;&#38598;&#19988;&#26114;&#36149;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#25512;&#29305;&#31561;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#24191;&#27867;&#12289;&#20016;&#23500;&#19988;&#24265;&#20215;&#30340;&#25968;&#25454;&#65292;&#26469;&#20102;&#35299;&#29992;&#25143;&#23545;&#21508;&#31181;&#26381;&#21153;&#38382;&#39064;&#30340;&#24863;&#30693;&#12290;&#25512;&#29305;&#20316;&#20026;&#19968;&#20010;&#24494;&#21338;&#24179;&#21488;&#65292;&#25176;&#31649;&#20102;&#22823;&#37327;&#23454;&#26102;&#30340;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#65292;&#20854;&#20013;&#32463;&#24120;&#21253;&#21547;&#26377;&#20851;&#21508;&#31181;&#20135;&#21697;&#12289;&#26381;&#21153;&#21644;&#20307;&#39564;&#30340;&#26377;&#20215;&#20540;&#30340;&#21453;&#39304;&#21644;&#24847;&#35265;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#36890;&#36807;&#20004;&#31181;&#25216;&#26415;&#31616;&#21270;&#20102;&#25910;&#38598;&#21644;&#20998;&#26512;&#29992;&#25143;&#21453;&#39304;&#30340;&#36807;&#31243;&#65292;&#26080;&#38656;&#26114;&#36149;&#19988;&#32791;&#26102;&#30340;&#29992;&#25143;&#21453;&#39304;&#35843;&#26597;&#12290;&#39318;&#20808;&#65292;&#23427;&#21033;&#29992;&#23569;&#26679;&#26412;&#23398;&#20064;&#36827;&#34892;&#25512;&#29305;&#20998;&#31867;&#65292;&#26377;&#25928;&#22320;&#35782;&#21035;&#25512;&#29305;&#20013;&#25551;&#36848;&#30340;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#23427;&#37319;&#29992;&#22522;&#20110;&#35789;&#20856;&#30340;&#24773;&#24863;&#20998;&#26512;&#27169;&#22411;&#26469;&#35780;&#20272;&#25512;&#29305;&#24773;&#24863;&#30340;&#24378;&#24230;&#21644;&#26497;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional methods of collecting user feedback through transit surveys are often time-consuming, resource intensive, and costly. In this paper, we propose a novel NLP-based framework that harnesses the vast, abundant, and inexpensive data available on social media platforms like Twitter to understand users' perceptions of various service issues. Twitter, being a microblogging platform, hosts a wealth of real-time user-generated content that often includes valuable feedback and opinions on various products, services, and experiences. The proposed framework streamlines the process of gathering and analyzing user feedback without the need for costly and time-consuming user feedback surveys using two techniques. First, it utilizes few-shot learning for tweet classification within predefined categories, allowing effective identification of the issues described in tweets. It then employs a lexicon-based sentiment analysis model to assess the intensity and polarity of the tweet sentiments, d
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#21512;&#25104;&#20266;&#35013;&#25968;&#25454;&#20197;&#25913;&#21892;&#23545;&#33258;&#28982;&#22330;&#26223;&#20013;&#20266;&#35013;&#29289;&#20307;&#26816;&#27979;&#30340;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#36924;&#30495;&#30340;&#20266;&#35013;&#22270;&#20687;&#65292;&#24182;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#20248;&#20110;&#30446;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.06701</link><description>&lt;p&gt;
&#20266;&#35013;&#22270;&#20687;&#21512;&#25104;&#26159;&#25552;&#39640;&#20266;&#35013;&#29289;&#20307;&#26816;&#27979;&#30340;&#20851;&#38190;
&lt;/p&gt;
&lt;p&gt;
Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection. (arXiv:2308.06701v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06701
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#21512;&#25104;&#20266;&#35013;&#25968;&#25454;&#20197;&#25913;&#21892;&#23545;&#33258;&#28982;&#22330;&#26223;&#20013;&#20266;&#35013;&#29289;&#20307;&#26816;&#27979;&#30340;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#36924;&#30495;&#30340;&#20266;&#35013;&#22270;&#20687;&#65292;&#24182;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#20248;&#20110;&#30446;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34701;&#20837;&#33258;&#28982;&#22330;&#26223;&#30340;&#20266;&#35013;&#29289;&#20307;&#32473;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26816;&#27979;&#21644;&#21512;&#25104;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#20266;&#35013;&#29289;&#20307;&#26816;&#27979;&#26159;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#19968;&#20010;&#20851;&#38190;&#20219;&#21153;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#28982;&#32780;&#30001;&#20110;&#25968;&#25454;&#26377;&#38480;&#65292;&#35813;&#30740;&#31350;&#35838;&#39064;&#19968;&#30452;&#21463;&#21040;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#21512;&#25104;&#20266;&#35013;&#25968;&#25454;&#20197;&#22686;&#24378;&#23545;&#33258;&#28982;&#22330;&#26223;&#20013;&#20266;&#35013;&#29289;&#20307;&#26816;&#27979;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#36924;&#30495;&#30340;&#20266;&#35013;&#22270;&#20687;&#65292;&#36825;&#20123;&#22270;&#20687;&#21487;&#20197;&#29992;&#26469;&#35757;&#32451;&#29616;&#26377;&#30340;&#29289;&#20307;&#26816;&#27979;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#20266;&#35013;&#29615;&#22659;&#29983;&#25104;&#22120;&#65292;&#30001;&#20266;&#35013;&#20998;&#24067;&#20998;&#31867;&#22120;&#36827;&#34892;&#30417;&#30563;&#65292;&#21512;&#25104;&#20266;&#35013;&#22270;&#20687;&#65292;&#28982;&#21518;&#23558;&#20854;&#36755;&#20837;&#25105;&#20204;&#30340;&#29983;&#25104;&#22120;&#20197;&#25193;&#23637;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#65288;COD10k&#12289;CAMO&#21644;CHAMELEON&#65289;&#19978;&#30340;&#25928;&#26524;&#36229;&#36807;&#20102;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#23427;&#22312;&#25913;&#21892;&#20266;&#35013;&#29289;&#20307;&#26816;&#27979;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Camouflaged objects that blend into natural scenes pose significant challenges for deep-learning models to detect and synthesize. While camouflaged object detection is a crucial task in computer vision with diverse real-world applications, this research topic has been constrained by limited data availability. We propose a framework for synthesizing camouflage data to enhance the detection of camouflaged objects in natural scenes. Our approach employs a generative model to produce realistic camouflage images, which can be used to train existing object detection models. Specifically, we use a camouflage environment generator supervised by a camouflage distribution classifier to synthesize the camouflage images, which are then fed into our generator to expand the dataset. Our framework outperforms the current state-of-the-art method on three datasets (COD10k, CAMO, and CHAMELEON), demonstrating its effectiveness in improving camouflaged object detection. This approach can serve as a plug-
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;ChipGPT&#65292;&#19968;&#20010;&#33258;&#21160;&#21270;&#35774;&#35745;&#29615;&#22659;&#65292;&#23427;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#33258;&#28982;&#35821;&#35328;&#35268;&#33539;&#29983;&#25104;&#30828;&#20214;&#36923;&#36753;&#35774;&#35745;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#20154;&#24037;&#35774;&#35745;&#24615;&#33021;&#30456;&#23218;&#32654;&#30340;&#32467;&#26524;&#65292;&#19988;&#21487;&#33410;&#30465;&#36229;&#36807;75&#65285;&#30340;&#32534;&#30721;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2305.14019</link><description>&lt;p&gt;
ChipGPT: &#36828;&#31163;&#33258;&#28982;&#35821;&#35328;&#30828;&#20214;&#35774;&#35745;&#36824;&#26377;&#22810;&#36828;
&lt;/p&gt;
&lt;p&gt;
ChipGPT: How far are we from natural language hardware design. (arXiv:2305.14019v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14019
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;ChipGPT&#65292;&#19968;&#20010;&#33258;&#21160;&#21270;&#35774;&#35745;&#29615;&#22659;&#65292;&#23427;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#33258;&#28982;&#35821;&#35328;&#35268;&#33539;&#29983;&#25104;&#30828;&#20214;&#36923;&#36753;&#35774;&#35745;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#20154;&#24037;&#35774;&#35745;&#24615;&#33021;&#30456;&#23218;&#32654;&#30340;&#32467;&#26524;&#65292;&#19988;&#21487;&#33410;&#30465;&#36229;&#36807;75&#65285;&#30340;&#32534;&#30721;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;ChatGPT&#23637;&#31034;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#26426;&#22120;&#26234;&#33021;&#65292;&#23427;&#22312;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#20132;&#20114;&#26469;&#21327;&#21161;&#30828;&#20214;&#24037;&#31243;&#24072;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#36923;&#36753;&#35774;&#35745;&#26041;&#38754;&#20063;&#34920;&#29616;&#20986;&#26497;&#20339;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35780;&#20272;LLMs&#21327;&#21161;&#30828;&#20214;&#35774;&#35745;&#36807;&#31243;&#30340;&#28508;&#21147;&#65292;&#26412;&#25991;&#23581;&#35797;&#28436;&#31034;&#19968;&#20010;&#33258;&#21160;&#21270;&#35774;&#35745;&#29615;&#22659;&#65292;&#35813;&#29615;&#22659;&#21033;&#29992;LLMs&#20174;&#33258;&#28982;&#35821;&#35328;&#35268;&#33539;&#29983;&#25104;&#30828;&#20214;&#36923;&#36753;&#35774;&#35745;&#12290;&#20026;&#20102;&#23454;&#29616;&#26356;&#26131;&#29992;&#19988;&#26356;&#39640;&#25928;&#30340;&#33455;&#29255;&#24320;&#21457;&#27969;&#31243;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LLMs&#30340;&#21487;&#25193;&#23637;&#30340;&#22235;&#38454;&#27573;&#38646;&#20195;&#30721;&#36923;&#36753;&#35774;&#35745;&#26694;&#26550;&#65292;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;&#39318;&#20808;&#65292;&#28436;&#31034;&#29256;&#26412;ChipGPT&#36890;&#36807;&#20026;LLM&#29983;&#25104;&#25552;&#31034;&#24320;&#22987;&#65292;&#28982;&#21518;&#20135;&#29983;&#21021;&#22987;Verilog&#31243;&#24207;&#12290; &#20854;&#27425;&#65292;&#36755;&#20986;&#31649;&#29702;&#22120;&#32416;&#27491;&#21644;&#20248;&#21270;&#36825;&#20123;&#31243;&#24207;&#65292;&#28982;&#21518;&#23558;&#23427;&#20204;&#25910;&#38598;&#21040;&#26368;&#32456;&#30340;&#35774;&#35745;&#31354;&#38388;&#20013;&#12290;&#26368;&#21518;&#65292;ChipGPT&#23558;&#22312;&#27492;&#31354;&#38388;&#20013;&#25628;&#32034;&#20197;&#36873;&#25321;&#31526;&#21512;&#30446;&#26631;&#25351;&#26631;&#30340;&#26368;&#20248;&#35774;&#35745;&#12290;&#35780;&#20272;&#34920;&#26126;&#65292;&#30001;ChipGPT&#35774;&#35745;&#30340;&#36923;&#36753;&#30005;&#36335;&#30340;&#24615;&#33021;&#19982;&#20154;&#24037;&#35774;&#35745;&#30340;&#24615;&#33021;&#30456;&#24403;&#65292;&#24182;&#19988;&#25972;&#20010;&#36807;&#31243;&#33410;&#30465;&#20102;&#36229;&#36807;75&#65285;&#30340;&#32534;&#30721;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
As large language models (LLMs) like ChatGPT exhibited unprecedented machine intelligence, it also shows great performance in assisting hardware engineers to realize higher-efficiency logic design via natural language interaction. To estimate the potential of the hardware design process assisted by LLMs, this work attempts to demonstrate an automated design environment that explores LLMs to generate hardware logic designs from natural language specifications. To realize a more accessible and efficient chip development flow, we present a scalable four-stage zero-code logic design framework based on LLMs without retraining or finetuning. At first, the demo, ChipGPT, begins by generating prompts for the LLM, which then produces initial Verilog programs. Second, an output manager corrects and optimizes these programs before collecting them into the final design space. Eventually, ChipGPT will search through this space to select the optimal design under the target metrics. The evaluation sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;Distantly-Supervised Named Entity Recognition&#20013;&#38169;&#35823;&#21644;&#19981;&#23436;&#25972;&#26631;&#27880;&#22122;&#22768;&#30340;&#20998;&#31163;&#31574;&#30053;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22411;&#26500;&#24314;&#26469;&#24212;&#23545;&#20004;&#31181;&#31867;&#22411;&#30340;&#22122;&#22768;&#12290;</title><link>http://arxiv.org/abs/2305.04076</link><description>&lt;p&gt;
SANTA&#65306;Distantly-Supervised Named Entity Recognition&#20013;&#22788;&#29702;&#38169;&#35823;&#21644;&#19981;&#23436;&#25972;&#26631;&#27880;&#22122;&#22768;&#30340;&#20998;&#31163;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition. (arXiv:2305.04076v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;Distantly-Supervised Named Entity Recognition&#20013;&#38169;&#35823;&#21644;&#19981;&#23436;&#25972;&#26631;&#27880;&#22122;&#22768;&#30340;&#20998;&#31163;&#31574;&#30053;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22411;&#26500;&#24314;&#26469;&#24212;&#23545;&#20004;&#31181;&#31867;&#22411;&#30340;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36828;&#31243;&#30417;&#30563;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#26377;&#25928;&#22320;&#20943;&#36731;&#20102;&#30417;&#30563;&#35774;&#32622;&#20013;&#32791;&#26102;&#19988;&#26114;&#36149;&#30340;&#27880;&#37322;&#36127;&#25285;&#65292;&#20294;&#26159;&#26080;&#19978;&#19979;&#25991;&#30340;&#21305;&#37197;&#36807;&#31243;&#21644;&#30693;&#35782;&#24211;&#30340;&#26377;&#38480;&#35206;&#30422;&#24341;&#20837;&#20102;&#19981;&#20934;&#30830;&#21644;&#19981;&#23436;&#25972;&#30340;&#26631;&#27880;&#22122;&#38899;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#19981;&#21516;&#30340;&#31574;&#30053;&#26469;&#22788;&#29702;&#20004;&#31181;&#31867;&#22411;&#30340;&#22122;&#22768;&#30340;SANTA&#65292;&#20197;&#35299;&#20915;&#30001;&#19981;&#20934;&#30830;&#21644;&#19981;&#23436;&#25972;&#26631;&#27880;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distantly-Supervised Named Entity Recognition effectively alleviates the burden of time-consuming and expensive annotation in the supervised setting. But the context-free matching process and the limited coverage of knowledge bases introduce inaccurate and incomplete annotation noise respectively. Previous studies either considered only incomplete annotation noise or indiscriminately handle two types of noise with the same strategy. In this paper, we argue that the different causes of two types of noise bring up the requirement of different strategies in model architecture. Therefore, we propose the SANTA to handle these two types of noise separately with (1) Memory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity problem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate decision boundary shifting problem caused by incomplete annotation and a noise-tolerant loss to improve the robustness. Benefiting from our separate tailored strategies, we co
&lt;/p&gt;</description></item><item><title>&#22312;&#32447;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#30340;&#20803;&#23398;&#20064;&#33539;&#20363;&#65292;&#26088;&#22312;&#33258;&#21160;&#21270;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35774;&#35745;&#25439;&#22833;&#20989;&#25968;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#27599;&#27425;&#26356;&#26032;&#22522;&#26412;&#27169;&#22411;&#21442;&#25968;&#21518;&#33258;&#36866;&#24212;&#22320;&#22312;&#32447;&#26356;&#26032;&#25439;&#22833;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#31283;&#23450;&#22320;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2301.13247</link><description>&lt;p&gt;
&#22312;&#32447;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Loss Function Learning. (arXiv:2301.13247v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13247
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#30340;&#20803;&#23398;&#20064;&#33539;&#20363;&#65292;&#26088;&#22312;&#33258;&#21160;&#21270;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35774;&#35745;&#25439;&#22833;&#20989;&#25968;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#27599;&#27425;&#26356;&#26032;&#22522;&#26412;&#27169;&#22411;&#21442;&#25968;&#21518;&#33258;&#36866;&#24212;&#22320;&#22312;&#32447;&#26356;&#26032;&#25439;&#22833;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#31283;&#23450;&#22320;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#30340;&#20803;&#23398;&#20064;&#33539;&#20363;&#65292;&#26088;&#22312;&#33258;&#21160;&#21270;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35774;&#35745;&#25439;&#22833;&#20989;&#25968;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#29616;&#26377;&#30340;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#25216;&#26415;&#24050;&#32463;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#32463;&#24120;&#25913;&#21892;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#21644;&#26368;&#32456;&#25512;&#29702;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#30340;&#19968;&#20010;&#37325;&#35201;&#38480;&#21046;&#26159;&#25439;&#22833;&#20989;&#25968;&#20197;&#32447;&#19979;&#26041;&#24335;&#36827;&#34892;&#20803;&#23398;&#20064;&#65292;&#20803;&#30446;&#26631;&#20165;&#32771;&#34385;&#35757;&#32451;&#30340;&#21069;&#20960;&#20010;&#27493;&#39588;&#65292;&#36825;&#19982;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#20351;&#29992;&#30340;&#26102;&#38388;&#33539;&#22260;&#30456;&#27604;&#26174;&#33879;&#36739;&#30701;&#12290;&#36825;&#23548;&#33268;&#23545;&#20110;&#22312;&#35757;&#32451;&#24320;&#22987;&#26102;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;&#35757;&#32451;&#32467;&#26463;&#26102;&#34920;&#29616;&#19981;&#20339;&#30340;&#25439;&#22833;&#20989;&#25968;&#23384;&#22312;&#26126;&#26174;&#30340;&#20559;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#27599;&#27425;&#26356;&#26032;&#22522;&#26412;&#27169;&#22411;&#21442;&#25968;&#21518;&#33258;&#36866;&#24212;&#22320;&#22312;&#32447;&#26356;&#26032;&#25439;&#22833;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#31283;&#23450;&#22320;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Loss function learning is a new meta-learning paradigm that aims to automate the essential task of designing a loss function for a machine learning model. Existing techniques for loss function learning have shown promising results, often improving a model's training dynamics and final inference performance. However, a significant limitation of these techniques is that the loss functions are meta-learned in an offline fashion, where the meta-objective only considers the very first few steps of training, which is a significantly shorter time horizon than the one typically used for training deep neural networks. This causes significant bias towards loss functions that perform well at the very start of training but perform poorly at the end of training. To address this issue we propose a new loss function learning technique for adaptively updating the loss function online after each update to the base model parameters. The experimental results show that our proposed method consistently out
&lt;/p&gt;</description></item></channel></rss>