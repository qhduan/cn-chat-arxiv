<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>FairTargetSim&#25552;&#20379;&#20102;&#19968;&#20010;&#20132;&#20114;&#24335;&#27169;&#25311;&#22120;&#65292;&#23637;&#31034;&#20102;&#30446;&#26631;&#21464;&#37327;&#23450;&#20041;&#23545;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#36866;&#29992;&#20110;&#31639;&#27861;&#24320;&#21457;&#32773;&#12289;&#30740;&#31350;&#20154;&#21592;&#21644;&#38750;&#25216;&#26415;&#21033;&#30410;&#30456;&#20851;&#32773;&#12290;</title><link>https://arxiv.org/abs/2403.06031</link><description>&lt;p&gt;
FairTargetSim&#65306;&#29992;&#20110;&#29702;&#35299;&#21644;&#35299;&#37322;&#30446;&#26631;&#21464;&#37327;&#23450;&#20041;&#20844;&#24179;&#24615;&#24433;&#21709;&#30340;&#20132;&#20114;&#24335;&#27169;&#25311;&#22120;
&lt;/p&gt;
&lt;p&gt;
FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06031
&lt;/p&gt;
&lt;p&gt;
FairTargetSim&#25552;&#20379;&#20102;&#19968;&#20010;&#20132;&#20114;&#24335;&#27169;&#25311;&#22120;&#65292;&#23637;&#31034;&#20102;&#30446;&#26631;&#21464;&#37327;&#23450;&#20041;&#23545;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#36866;&#29992;&#20110;&#31639;&#27861;&#24320;&#21457;&#32773;&#12289;&#30740;&#31350;&#20154;&#21592;&#21644;&#38750;&#25216;&#26415;&#21033;&#30410;&#30456;&#20851;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#38656;&#35201;&#20026;&#39044;&#27979;&#25110;&#20915;&#31574;&#23450;&#20041;&#30446;&#26631;&#21464;&#37327;&#65292;&#36825;&#20010;&#36807;&#31243;&#21487;&#33021;&#23545;&#20844;&#24179;&#24615;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#65306;&#20559;&#35265;&#36890;&#24120;&#24050;&#32463;&#34987;&#32534;&#30721;&#22312;&#30446;&#26631;&#21464;&#37327;&#23450;&#20041;&#26412;&#36523;&#20013;&#65292;&#32780;&#19981;&#26159;&#22312;&#20219;&#20309;&#25968;&#25454;&#25910;&#38598;&#25110;&#35757;&#32451;&#20043;&#21069;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20132;&#20114;&#24335;&#27169;&#25311;&#22120;&#65292;FairTargetSim (FTS)&#65292;&#23637;&#31034;&#20102;&#30446;&#26631;&#21464;&#37327;&#23450;&#20041;&#22914;&#20309;&#24433;&#21709;&#20844;&#24179;&#24615;&#12290;FTS&#26159;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#65292;&#36866;&#29992;&#20110;&#31639;&#27861;&#24320;&#21457;&#32773;&#12289;&#30740;&#31350;&#20154;&#21592;&#21644;&#38750;&#25216;&#26415;&#21033;&#30410;&#30456;&#20851;&#32773;&#12290;FTS&#20351;&#29992;&#20102;&#31639;&#27861;&#25307;&#32856;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#21644;&#29992;&#25143;&#23450;&#20041;&#30340;&#30446;&#26631;&#21464;&#37327;&#12290;FTS&#26159;&#24320;&#28304;&#30340;&#65292;&#21487;&#22312;&#20197;&#19979;&#32593;&#22336;&#25214;&#21040;&#65306;http://tinyurl.com/ftsinterface&#12290;&#26412;&#25991;&#38468;&#24102;&#30340;&#35270;&#39057;&#32593;&#22336;&#20026;&#65306;http://tinyurl.com/ijcaifts&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06031v1 Announce Type: cross  Abstract: Machine learning requires defining one's target variable for predictions or decisions, a process that can have profound implications on fairness: biases are often encoded in target variable definition itself, before any data collection or training. We present an interactive simulator, FairTargetSim (FTS), that illustrates how target variable definition impacts fairness. FTS is a valuable tool for algorithm developers, researchers, and non-technical stakeholders. FTS uses a case study of algorithmic hiring, using real-world data and user-defined target variables. FTS is open-source and available at: http://tinyurl.com/ftsinterface. The video accompanying this paper is here: http://tinyurl.com/ijcaifts.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20197;&#20302;&#35745;&#31639;&#36164;&#28304;&#28040;&#32791;&#20026;&#20013;&#24515;&#30340;&#39640;&#25928;&#30693;&#35782;&#24211;&#38382;&#31572;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#32447;&#32034;&#24341;&#23548;&#36335;&#24452;&#25506;&#32034;&#30340;&#26041;&#24335;&#65292;&#23558;&#30693;&#35782;&#24211;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39640;&#25928;&#22320;&#34701;&#21512;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#23545;&#27169;&#22411;&#33021;&#21147;&#30340;&#35201;&#27714;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.13444</link><description>&lt;p&gt;
&#20197;&#20302;&#35745;&#31639;&#36164;&#28304;&#28040;&#32791;&#20026;&#20013;&#24515;&#30340;&#39640;&#25928;&#30693;&#35782;&#24211;&#38382;&#31572;&#26694;&#26550;&#65306;&#22522;&#20110;&#32447;&#32034;&#24341;&#23548;&#36335;&#24452;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption. (arXiv:2401.13444v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13444
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20197;&#20302;&#35745;&#31639;&#36164;&#28304;&#28040;&#32791;&#20026;&#20013;&#24515;&#30340;&#39640;&#25928;&#30693;&#35782;&#24211;&#38382;&#31572;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#32447;&#32034;&#24341;&#23548;&#36335;&#24452;&#25506;&#32034;&#30340;&#26041;&#24335;&#65292;&#23558;&#30693;&#35782;&#24211;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39640;&#25928;&#22320;&#34701;&#21512;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#23545;&#27169;&#22411;&#33021;&#21147;&#30340;&#35201;&#27714;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#26356;&#26032;&#23427;&#20204;&#30340;&#30693;&#35782;&#38754;&#20250;&#24102;&#26469;&#25361;&#25112;&#65292;&#24403;&#38754;&#23545;&#19981;&#29087;&#24713;&#30340;&#26597;&#35810;&#26102;&#21487;&#33021;&#23548;&#33268;&#19981;&#20934;&#30830;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#30740;&#31350;&#20102;&#23558;&#30693;&#35782;&#22270;&#35889;&#19982;LLMs&#38598;&#25104;&#30340;&#26041;&#27861;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#23558;LLMs&#35270;&#20026;&#20027;&#35201;&#30340;&#20915;&#31574;&#32773;&#65292;&#23545;&#20854;&#33021;&#21147;&#25552;&#20986;&#20102;&#36739;&#39640;&#30340;&#35201;&#27714;&#12290;&#23545;&#20110;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#19988;&#24615;&#33021;&#30456;&#23545;&#36739;&#24046;&#30340;LLMs&#26469;&#35828;&#65292;&#36825;&#26159;&#19981;&#22826;&#21512;&#36866;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20197;&#32447;&#32034;&#24341;&#23548;&#36335;&#24452;&#25506;&#32034;&#20026;&#26680;&#24515;&#30340;&#30693;&#35782;&#24211;&#38382;&#31572;&#26694;&#26550;&#65288;CGPE&#65289;&#65292;&#23427;&#23558;&#30693;&#35782;&#24211;&#19982;LLMs&#39640;&#25928;&#22320;&#34701;&#21512;&#65292;&#23545;&#27169;&#22411;&#30340;&#33021;&#21147;&#35201;&#27714;&#36739;&#20302;&#12290;&#21463;&#20154;&#31867;&#25163;&#21160;&#26816;&#32034;&#30693;&#35782;&#30340;&#26041;&#27861;&#21551;&#21457;&#65292;CGPE&#21033;&#29992;&#38382;&#39064;&#20013;&#30340;&#20449;&#24687;&#20316;&#20026;&#32447;&#32034;&#65292;&#31995;&#32479;&#22320;&#25506;&#32034;&#30693;&#35782;&#24211;&#20013;&#25152;&#38656;&#30340;&#30693;&#35782;&#36335;&#24452;&#12290;&#24320;&#28304;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;CGPE&#20248;&#20110;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#38750;&#24120;&#36866;&#29992;&#20110;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#19988;&#24615;&#33021;&#36739;&#24046;&#30340;LLMs&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent times, large language models (LLMs) have showcased remarkable capabilities. However, updating their knowledge poses challenges, potentially leading to inaccuracies when confronted with unfamiliar queries. While integrating knowledge graphs with LLMs has been explored, existing approaches treat LLMs as primary decision-makers, imposing high demands on their capabilities. This is particularly unsuitable for LLMs with lower computational costs and relatively poorer performance. In this paper, we introduce a Clue-Guided Path Exploration framework (CGPE) that efficiently merges a knowledge base with an LLM, placing less stringent requirements on the model's capabilities. Inspired by the method humans use to manually retrieve knowledge, CGPE employs information from the question as clues to systematically explore the required knowledge path within the knowledge base. Experiments on open-source datasets reveal that CGPE outperforms previous methods and is highly applicable to LLMs w
&lt;/p&gt;</description></item><item><title>VFedMH&#26159;&#19968;&#31181;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#21069;&#21521;&#20256;&#25773;&#36807;&#31243;&#20013;&#32858;&#21512;&#21442;&#19982;&#32773;&#30340;&#23884;&#20837;&#26469;&#22788;&#29702;&#21442;&#19982;&#32773;&#20043;&#38388;&#30340;&#24322;&#26500;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;VFL&#26041;&#27861;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.13367</link><description>&lt;p&gt;
VFedMH: &#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#29992;&#20110;&#35757;&#32451;&#22810;&#21442;&#19982;&#26041;&#24322;&#26500;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
VFedMH: Vertical Federated Learning for Training Multi-party Heterogeneous Models. (arXiv:2310.13367v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13367
&lt;/p&gt;
&lt;p&gt;
VFedMH&#26159;&#19968;&#31181;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#21069;&#21521;&#20256;&#25773;&#36807;&#31243;&#20013;&#32858;&#21512;&#21442;&#19982;&#32773;&#30340;&#23884;&#20837;&#26469;&#22788;&#29702;&#21442;&#19982;&#32773;&#20043;&#38388;&#30340;&#24322;&#26500;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;VFL&#26041;&#27861;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#65288;VFL&#65289;&#20316;&#20026;&#19968;&#31181;&#38598;&#25104;&#26679;&#26412;&#23545;&#40784;&#21644;&#29305;&#24449;&#21512;&#24182;&#30340;&#26032;&#22411;&#35757;&#32451;&#33539;&#24335;&#65292;&#24050;&#32463;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;VFL&#26041;&#27861;&#22312;&#22788;&#29702;&#21442;&#19982;&#32773;&#20043;&#38388;&#23384;&#22312;&#24322;&#26500;&#26412;&#22320;&#27169;&#22411;&#26102;&#38754;&#20020;&#25361;&#25112;&#65292;&#36825;&#24433;&#21709;&#20102;&#20248;&#21270;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VFedMH&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#22810;&#26041;&#24322;&#26500;&#27169;&#22411;&#12290;VFedMH&#30340;&#37325;&#28857;&#26159;&#22312;&#21069;&#21521;&#20256;&#25773;&#26399;&#38388;&#32858;&#21512;&#27599;&#20010;&#21442;&#19982;&#32773;&#30693;&#35782;&#30340;&#23884;&#20837;&#65292;&#32780;&#19981;&#26159;&#20013;&#38388;&#32467;&#26524;&#12290;&#20027;&#21160;&#26041;&#65292;&#25317;&#26377;&#26679;&#26412;&#30340;&#26631;&#31614;&#21644;&#29305;&#24449;&#65292;&#22312;VFedMH&#20013;&#23433;&#20840;&#22320;&#32858;&#21512;&#26412;&#22320;&#23884;&#20837;&#20197;&#33719;&#24471;&#20840;&#23616;&#30693;&#35782;&#23884;&#20837;&#65292;&#24182;&#23558;&#20854;&#21457;&#36865;&#32473;&#34987;&#21160;&#26041;&#12290;&#34987;&#21160;&#26041;&#20165;&#25317;&#26377;&#26679;&#26412;&#30340;&#29305;&#24449;&#65292;&#28982;&#21518;&#21033;&#29992;&#20840;&#23616;&#23884;&#20837;&#22312;&#20854;&#26412;&#22320;&#24322;&#26500;&#32593;&#32476;&#19978;&#36827;&#34892;&#21069;&#21521;&#20256;&#25773;&#12290;&#28982;&#32780;&#65292;&#34987;&#21160;&#26041;&#19981;&#25317;&#26377;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vertical Federated Learning (VFL) has gained increasing attention as a novel training paradigm that integrates sample alignment and feature union. However, existing VFL methods face challenges when dealing with heterogeneous local models among participants, which affects optimization convergence and generalization. To address this issue, this paper proposes a novel approach called Vertical Federated learning for training Multi-parties Heterogeneous models (VFedMH). VFedMH focuses on aggregating the embeddings of each participant's knowledge instead of intermediate results during forward propagation. The active party, who possesses labels and features of the sample, in VFedMH securely aggregates local embeddings to obtain global knowledge embeddings, and sends them to passive parties. The passive parties, who own only features of the sample, then utilize the global embeddings to propagate forward on their local heterogeneous networks. However, the passive party does not own the labels, 
&lt;/p&gt;</description></item><item><title>GRAPES&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#35782;&#21035;&#22312;&#35757;&#32451;&#22270;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#26102;&#20855;&#26377;&#24433;&#21709;&#21147;&#30340;&#33410;&#28857;&#38598;&#21512;&#65292;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20869;&#23384;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2310.03399</link><description>&lt;p&gt;
GRAPES: &#23398;&#20064;&#29992;&#20110;&#21487;&#25193;&#23637;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#22270;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks. (arXiv:2310.03399v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03399
&lt;/p&gt;
&lt;p&gt;
GRAPES&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#35782;&#21035;&#22312;&#35757;&#32451;&#22270;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#26102;&#20855;&#26377;&#24433;&#21709;&#21147;&#30340;&#33410;&#28857;&#38598;&#21512;&#65292;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20869;&#23384;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#36890;&#36807;&#20197;&#19981;&#21516;&#26041;&#24335;&#32858;&#21512;&#21608;&#22260;&#20449;&#24687;&#26469;&#23398;&#20064;&#22270;&#20013;&#33410;&#28857;&#30340;&#34920;&#31034;&#12290;&#38543;&#30528;&#36825;&#20123;&#32593;&#32476;&#30340;&#21152;&#28145;&#65292;&#30001;&#20110;&#37051;&#22495;&#23610;&#23544;&#30340;&#22686;&#21152;&#65292;&#23427;&#20204;&#30340;&#24863;&#21463;&#37326;&#21576;&#25351;&#25968;&#22686;&#38271;&#65292;&#23548;&#33268;&#39640;&#20869;&#23384;&#28040;&#32791;&#12290;&#22270;&#37319;&#26679;&#36890;&#36807;&#23545;&#22270;&#20013;&#33410;&#28857;&#36827;&#34892;&#25277;&#26679;&#26469;&#35299;&#20915;GNNs&#20013;&#30340;&#20869;&#23384;&#38382;&#39064;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;GNNs&#21487;&#20197;&#25193;&#23637;&#21040;&#26356;&#22823;&#30340;&#22270;&#12290;&#22823;&#22810;&#25968;&#37319;&#26679;&#26041;&#27861;&#19987;&#27880;&#20110;&#22266;&#23450;&#30340;&#37319;&#26679;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#36825;&#21487;&#33021;&#26080;&#27861;&#25512;&#24191;&#21040;&#19981;&#21516;&#30340;&#32467;&#26500;&#25110;&#20219;&#21153;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;GRAPES&#65292;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23398;&#20064;&#35782;&#21035;&#29992;&#20110;&#35757;&#32451;GNN&#20998;&#31867;&#22120;&#30340;&#19968;&#32452;&#20855;&#26377;&#24433;&#21709;&#21147;&#30340;&#33410;&#28857;&#12290;GRAPES&#20351;&#29992;GFlowNet&#26469;&#23398;&#20064;&#32473;&#23450;&#20998;&#31867;&#30446;&#26631;&#30340;&#33410;&#28857;&#37319;&#26679;&#27010;&#29575;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#23567;&#35268;&#27169;&#21644;&#22823;&#35268;&#27169;&#22270;&#22522;&#20934;&#19978;&#35780;&#20272;&#20102;GRAPES&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#37319;&#26679;&#26041;&#27861;&#30456;&#27604;&#65292;GRAPES&#21363;&#20351;&#22312;&#37319;&#26679;&#27604;&#20363;&#36739;&#20302;&#30340;&#24773;&#20917;&#19979;&#20173;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) learn the representation of nodes in a graph by aggregating the neighborhood information in various ways. As these networks grow in depth, their receptive field grows exponentially due to the increase in neighborhood sizes, resulting in high memory costs. Graph sampling solves memory issues in GNNs by sampling a small ratio of the nodes in the graph. This way, GNNs can scale to much larger graphs. Most sampling methods focus on fixed sampling heuristics, which may not generalize to different structures or tasks. We introduce GRAPES, an adaptive graph sampling method that learns to identify sets of influential nodes for training a GNN classifier. GRAPES uses a GFlowNet to learn node sampling probabilities given the classification objectives. We evaluate GRAPES across several small- and large-scale graph benchmarks and demonstrate its effectiveness in accuracy and scalability. In contrast to existing sampling methods, GRAPES maintains high accuracy even with 
&lt;/p&gt;</description></item></channel></rss>