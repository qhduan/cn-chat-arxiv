<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#24037;&#19994;&#29289;&#32852;&#32593;&#29992;&#25143;&#35774;&#22791;&#65288;IIoT UEs&#65289;&#30340;&#24847;&#22270;&#24863;&#30693;DRL&#19978;&#34892;&#21160;&#24577;&#35843;&#24230;&#22120;&#65292;&#36890;&#36807;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#23398;&#20064;&#22914;&#20309;&#35843;&#24230;&#36890;&#20449;&#36164;&#28304;&#65292;&#24182;&#21033;&#29992;&#22270;&#32467;&#26500;&#30340;&#31616;&#21270;&#26041;&#26696;&#21152;&#36895;&#25910;&#25947;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#35843;&#24230;&#26041;&#26696;&#65292;&#33021;&#26377;&#25928;&#20445;&#35777;IIoT UEs&#30340;&#24847;&#22270;&#34920;&#36798;&#12290;</title><link>https://arxiv.org/abs/2403.18364</link><description>&lt;p&gt;
&#38754;&#21521;5G-NR&#30340;&#24847;&#22270;&#24863;&#30693;DRL&#19978;&#34892;&#21160;&#24577;&#35843;&#24230;&#22120;
&lt;/p&gt;
&lt;p&gt;
Intent-Aware DRL-Based Uplink Dynamic Scheduler for 5G-NR
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18364
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#24037;&#19994;&#29289;&#32852;&#32593;&#29992;&#25143;&#35774;&#22791;&#65288;IIoT UEs&#65289;&#30340;&#24847;&#22270;&#24863;&#30693;DRL&#19978;&#34892;&#21160;&#24577;&#35843;&#24230;&#22120;&#65292;&#36890;&#36807;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#23398;&#20064;&#22914;&#20309;&#35843;&#24230;&#36890;&#20449;&#36164;&#28304;&#65292;&#24182;&#21033;&#29992;&#22270;&#32467;&#26500;&#30340;&#31616;&#21270;&#26041;&#26696;&#21152;&#36895;&#25910;&#25947;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#35843;&#24230;&#26041;&#26696;&#65292;&#33021;&#26377;&#25928;&#20445;&#35777;IIoT UEs&#30340;&#24847;&#22270;&#34920;&#36798;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#25903;&#25345;&#24037;&#19994;&#29289;&#32852;&#32593;&#29992;&#25143;&#35774;&#22791;&#65288;IIoT UEs&#65289;&#20855;&#26377;&#24847;&#22270;&#65288;&#21363;&#25152;&#35831;&#27714;&#30340;&#26381;&#21153;&#36136;&#37327;&#65288;QoS&#65289;&#65289;&#21644;&#38543;&#26426;&#27969;&#37327;&#21040;&#36798;&#30340;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#30340;&#38598;&#20013;&#21160;&#24577;&#35843;&#24230;&#22120;&#65292;&#29992;&#20110;&#23398;&#20064;&#22914;&#20309;&#22312;IIoT UEs&#20043;&#38388;&#35843;&#24230;&#21487;&#29992;&#36890;&#20449;&#36164;&#28304;&#30340;&#26102;&#38388;&#39057;&#29575;&#36164;&#28304;&#12290;&#25152;&#25552;&#20986;&#30340;&#35843;&#24230;&#22120;&#21033;&#29992;RL&#26694;&#26550;&#26469;&#36866;&#24212;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#21644;&#27969;&#37327;&#21040;&#36798;&#20013;&#30340;&#21160;&#24577;&#21464;&#21270;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#30340;&#31616;&#21270;&#26041;&#26696;&#65292;&#20197;&#20943;&#23569;RL&#26694;&#26550;&#30340;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#65292;&#20197;&#23454;&#29616;&#24555;&#36895;&#25910;&#25947;&#21644;&#26356;&#22909;&#30340;&#23398;&#20064;&#31574;&#30053;&#12290;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20960;&#31181;&#20256;&#32479;&#35843;&#24230;&#26041;&#26696;&#65288;&#22914;&#36718;&#35810;&#12289;&#21322;&#38745;&#24577;&#21644;&#21551;&#21457;&#24335;&#26041;&#27861;&#65289;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#26234;&#33021;&#35843;&#24230;&#22120;&#22312;&#20445;&#35777;IIoT UEs&#25152;&#34920;&#36798;&#30340;&#24847;&#22270;&#26041;&#38754;&#20855;&#26377;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18364v1 Announce Type: cross  Abstract: We investigate the problem of supporting Industrial Internet of Things user equipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and random traffic arrival. A deep reinforcement learning (DRL) based centralized dynamic scheduler for time-frequency resources is proposed to learn how to schedule the available communication resources among the IIoT UEs. The proposed scheduler leverages an RL framework to adapt to the dynamic changes in the wireless communication system and traffic arrivals. Moreover, a graph-based reduction scheme is proposed to reduce the state and action space of the RL framework to allow fast convergence and a better learning strategy. Simulation results demonstrate the effectiveness of the proposed intelligent scheduler in guaranteeing the expressed intent of IIoT UEs compared to several traditional scheduling schemes, such as round-robin, semi-static, and heuristic approaches. The proposed sche
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#22797;&#26434;&#20132;&#21449;&#36335;&#21475;&#30340;&#20449;&#21495;&#25511;&#21046;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#38454;&#27573;&#32039;&#24613;&#24615;&#27010;&#24565;&#21644;&#21487;&#35299;&#37322;&#30340;&#26641;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#20449;&#21495;&#36716;&#25442;&#26399;&#38388;&#36873;&#25321;&#28608;&#27963;&#30340;&#20449;&#21495;&#30456;&#20301;&#12290;</title><link>https://arxiv.org/abs/2403.17328</link><description>&lt;p&gt;
&#36890;&#36807;&#36951;&#20256;&#32534;&#31243;&#23398;&#20064;&#20132;&#36890;&#20449;&#21495;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Learning Traffic Signal Control via Genetic Programming
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17328
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#22797;&#26434;&#20132;&#21449;&#36335;&#21475;&#30340;&#20449;&#21495;&#25511;&#21046;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#38454;&#27573;&#32039;&#24613;&#24615;&#27010;&#24565;&#21644;&#21487;&#35299;&#37322;&#30340;&#26641;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#20449;&#21495;&#36716;&#25442;&#26399;&#38388;&#36873;&#25321;&#28608;&#27963;&#30340;&#20449;&#21495;&#30456;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#20449;&#21495;&#25511;&#21046;&#23545;&#25552;&#39640;&#20132;&#36890;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#65292;&#22312;&#23547;&#27714;&#26356;&#26377;&#25928;&#30340;&#20132;&#36890;&#20449;&#21495;&#25511;&#21046;&#31574;&#30053;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22312;DRL&#20013;&#22870;&#21169;&#30340;&#35774;&#35745;&#39640;&#24230;&#20381;&#36182;&#39046;&#22495;&#30693;&#35782;&#25165;&#33021;&#25910;&#25947;&#21040;&#26377;&#25928;&#31574;&#30053;&#65292;&#32780;&#26368;&#32456;&#31574;&#30053;&#20063;&#23384;&#22312;&#35299;&#37322;&#22256;&#38590;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#22797;&#26434;&#36335;&#21475;&#30340;&#20449;&#21495;&#25511;&#21046;&#30340;&#23398;&#20064;&#26041;&#27861;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#20449;&#21495;&#30456;&#35774;&#35745;&#20102;&#19968;&#20010;&#38454;&#27573;&#32039;&#24613;&#24615;&#30340;&#27010;&#24565;&#12290;&#22312;&#20449;&#21495;&#21464;&#25442;&#26399;&#38388;&#65292;&#20132;&#36890;&#28783;&#25511;&#21046;&#31574;&#30053;&#26681;&#25454;&#38454;&#27573;&#32039;&#24613;&#24615;&#36873;&#25321;&#35201;&#28608;&#27963;&#30340;&#19979;&#19968;&#20010;&#30456;&#20301;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#32039;&#24613;&#21151;&#33021;&#34920;&#31034;&#20026;&#21487;&#35299;&#37322;&#30340;&#26641;&#32467;&#26500;&#12290;&#32039;&#24613;&#21151;&#33021;&#21487;&#20197;&#26681;&#25454;&#24403;&#21069;&#36947;&#36335;&#26465;&#20214;&#20026;&#29305;&#23450;&#30456;&#20301;&#35745;&#31639;&#30456;&#20301;&#32039;&#24613;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17328v1 Announce Type: new  Abstract: The control of traffic signals is crucial for improving transportation efficiency. Recently, learning-based methods, especially Deep Reinforcement Learning (DRL), garnered substantial success in the quest for more efficient traffic signal control strategies. However, the design of rewards in DRL highly demands domain knowledge to converge to an effective policy, and the final policy also presents difficulties in terms of explainability. In this work, a new learning-based method for signal control in complex intersections is proposed. In our approach, we design a concept of phase urgency for each signal phase. During signal transitions, the traffic light control strategy selects the next phase to be activated based on the phase urgency. We then proposed to represent the urgency function as an explainable tree structure. The urgency function can calculate the phase urgency for a specific phase based on the current road conditions. Genetic 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;npm&#29983;&#24577;&#31995;&#32479;&#20013;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#20197;&#21327;&#21161;&#23433;&#20840;&#20998;&#26512;&#24072;&#35782;&#21035;&#24694;&#24847;&#36719;&#20214;&#21253;</title><link>https://arxiv.org/abs/2403.12196</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;npm&#29983;&#24577;&#31995;&#32479;&#20013;&#26816;&#27979;&#24694;&#24847;&#36719;&#20214;
&lt;/p&gt;
&lt;p&gt;
Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12196
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;npm&#29983;&#24577;&#31995;&#32479;&#20013;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#20197;&#21327;&#21161;&#23433;&#20840;&#20998;&#26512;&#24072;&#35782;&#21035;&#24694;&#24847;&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gartner 2022&#24180;&#30340;&#25253;&#21578;&#39044;&#27979;&#65292;&#21040;2025&#24180;&#65292;&#20840;&#29699;45%&#30340;&#32452;&#32455;&#23558;&#36973;&#36935;&#36719;&#20214;&#20379;&#24212;&#38142;&#25915;&#20987;&#65292;&#20984;&#26174;&#20102;&#25913;&#21892;&#36719;&#20214;&#20379;&#24212;&#38142;&#23433;&#20840;&#23545;&#31038;&#21306;&#21644;&#22269;&#23478;&#21033;&#30410;&#30340;&#36843;&#20999;&#24615;&#12290;&#24403;&#21069;&#30340;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#25216;&#26415;&#36890;&#36807;&#36807;&#28388;&#33391;&#24615;&#21644;&#24694;&#24847;&#36719;&#20214;&#21253;&#26469;&#36741;&#21161;&#25163;&#21160;&#23457;&#26680;&#36807;&#31243;&#65292;&#28982;&#32780;&#36825;&#31181;&#25216;&#26415;&#23384;&#22312;&#36739;&#39640;&#30340;&#35823;&#25253;&#29575;&#21644;&#26377;&#38480;&#30340;&#33258;&#21160;&#21270;&#25903;&#25345;&#12290;&#22240;&#27492;&#65292;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#25216;&#26415;&#21487;&#20197;&#21463;&#30410;&#20110;&#20808;&#36827;&#12289;&#26356;&#33258;&#21160;&#21270;&#30340;&#26041;&#27861;&#65292;&#24471;&#21040;&#20934;&#30830;&#19988;&#35823;&#25253;&#36739;&#23569;&#30340;&#32467;&#26524;&#12290;&#35813;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#24110;&#21161;&#23433;&#20840;&#20998;&#26512;&#24072;&#35782;&#21035;npm&#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#24694;&#24847;&#36719;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12196v1 Announce Type: cross  Abstract: The Gartner 2022 report predicts that 45% of organizations worldwide will encounter software supply chain attacks by 2025, highlighting the urgency to improve software supply chain security for community and national interests. Current malware detection techniques aid in the manual review process by filtering benign and malware packages, yet such techniques have high false-positive rates and limited automation support. Therefore, malware detection techniques could benefit from advanced, more automated approaches for accurate and minimally false-positive results. The goal of this study is to assist security analysts in identifying malicious packages through the empirical study of large language models (LLMs) to detect potential malware in the npm ecosystem.   We present SocketAI Scanner, a multi-stage decision-maker malware detection workflow using iterative self-refinement and zero-shot-role-play-Chain of Thought (CoT) prompting techni
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Prompt-Singer&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#29992;&#33258;&#28982;&#35821;&#35328;&#25511;&#21046;&#27468;&#25163;&#24615;&#21035;&#12289;&#38899;&#22495;&#21644;&#38899;&#37327;&#30340;&#21809;&#27468;&#22768;&#38899;&#21512;&#25104;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#22522;&#20110;&#35299;&#30721;&#22120;&#30340;&#21464;&#21387;&#22120;&#27169;&#22411;&#26550;&#26500;&#21644;&#33539;&#22260;&#26059;&#24459;&#35299;&#32806;&#30340;&#38899;&#39640;&#34920;&#31034;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.11780</link><description>&lt;p&gt;
Prompt-Singer: &#24102;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#30340;&#21487;&#25511;&#21809;&#27468;&#22768;&#38899;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural Language Prompt
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11780
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Prompt-Singer&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#29992;&#33258;&#28982;&#35821;&#35328;&#25511;&#21046;&#27468;&#25163;&#24615;&#21035;&#12289;&#38899;&#22495;&#21644;&#38899;&#37327;&#30340;&#21809;&#27468;&#22768;&#38899;&#21512;&#25104;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#22522;&#20110;&#35299;&#30721;&#22120;&#30340;&#21464;&#21387;&#22120;&#27169;&#22411;&#26550;&#26500;&#21644;&#33539;&#22260;&#26059;&#24459;&#35299;&#32806;&#30340;&#38899;&#39640;&#34920;&#31034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#21809;&#27468;&#22768;&#38899;&#21512;&#25104;(SVS)&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#38899;&#39057;&#36136;&#37327;&#21644;&#33258;&#28982;&#24230;&#65292;&#28982;&#32780;&#23427;&#20204;&#32570;&#20047;&#26174;&#24335;&#25511;&#21046;&#21512;&#25104;&#21809;&#27468;&#39118;&#26684;&#23646;&#24615;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;Prompt-Singer&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#29992;&#33258;&#28982;&#35821;&#35328;&#25511;&#21046;&#27468;&#25163;&#24615;&#21035;&#12289;&#38899;&#22495;&#21644;&#38899;&#37327;&#30340;SVS&#26041;&#27861;&#12290;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#20165;&#35299;&#30721;&#22120;&#30340;&#21464;&#21387;&#22120;&#27169;&#22411;&#26550;&#26500;&#65292;&#20855;&#26377;&#22810;&#23610;&#24230;&#23618;&#27425;&#32467;&#26500;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#20998;&#31163;&#38899;&#39640;&#34920;&#31034;&#30340;&#33539;&#22260;&#26059;&#24459;&#35299;&#32806;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22522;&#20110;&#25991;&#26412;&#30340;&#38899;&#22495;&#25511;&#21046;&#21516;&#26102;&#20445;&#25345;&#20102;&#26059;&#24459;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#21508;&#31181;&#23454;&#39564;&#35774;&#32622;&#65292;&#21253;&#25324;&#19981;&#21516;&#31867;&#22411;&#30340;&#25991;&#26412;&#34920;&#31034;&#65292;&#25991;&#26412;&#32534;&#30721;&#22120;&#24494;&#35843;&#65292;&#20197;&#21450;&#24341;&#20837;&#35821;&#38899;&#25968;&#25454;&#20197;&#20943;&#36731;&#25968;&#25454;&#31232;&#32570;&#24615;&#65292;&#26088;&#22312;&#20419;&#36827;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#33391;&#22909;&#30340;&#25511;&#21046;&#33021;&#21147;&#21644;&#38899;&#39057;&#36136;&#37327;&#12290;&#38899;&#39057;&#31034;&#20363;&#21487;&#35775;&#38382; http://prompt-singer.
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11780v1 Announce Type: cross  Abstract: Recent singing-voice-synthesis (SVS) methods have achieved remarkable audio quality and naturalness, yet they lack the capability to control the style attributes of the synthesized singing explicitly. We propose Prompt-Singer, the first SVS method that enables attribute controlling on singer gender, vocal range and volume with natural language. We adopt a model architecture based on a decoder-only transformer with a multi-scale hierarchy, and design a range-melody decoupled pitch representation that enables text-conditioned vocal range control while keeping melodic accuracy. Furthermore, we explore various experiment settings, including different types of text representations, text encoder fine-tuning, and introducing speech data to alleviate data scarcity, aiming to facilitate further research. Experiments show that our model achieves favorable controlling ability and audio quality. Audio samples are available at http://prompt-singer.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20010;&#24615;&#21270;&#19987;&#23478;&#31034;&#33539;&#30340;&#27010;&#24565;&#65292;&#20026;&#27599;&#20010;&#26234;&#20307;&#25110;&#19981;&#21516;&#31867;&#22411;&#30340;&#26234;&#20307;&#25552;&#20379;&#38024;&#23545;&#20010;&#20154;&#30446;&#26631;&#30340;&#25351;&#23548;&#65292;&#35299;&#20915;&#20102;&#22810;&#26234;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#32852;&#21512;&#31034;&#33539;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.08936</link><description>&lt;p&gt;
&#36229;&#36234;&#32852;&#21512;&#31034;&#33539;&#65306;&#20010;&#24615;&#21270;&#19987;&#23478;&#25351;&#23548;&#29992;&#20110;&#39640;&#25928;&#22810;&#26234;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08936
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20010;&#24615;&#21270;&#19987;&#23478;&#31034;&#33539;&#30340;&#27010;&#24565;&#65292;&#20026;&#27599;&#20010;&#26234;&#20307;&#25110;&#19981;&#21516;&#31867;&#22411;&#30340;&#26234;&#20307;&#25552;&#20379;&#38024;&#23545;&#20010;&#20154;&#30446;&#26631;&#30340;&#25351;&#23548;&#65292;&#35299;&#20915;&#20102;&#22810;&#26234;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#32852;&#21512;&#31034;&#33539;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#38754;&#20020;&#26377;&#25928;&#25506;&#32034;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#32852;&#21512;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#30340;&#22823;&#23567;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#34429;&#28982;&#31034;&#33539;&#24341;&#23548;&#23398;&#20064;&#22312;&#21333;&#26234;&#20307;&#29615;&#22659;&#20013;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#30410;&#30340;&#65292;&#20294;&#20854;&#30452;&#25509;&#24212;&#29992;&#20110;&#22810;&#26234;&#20307;&#24378;&#21270;&#23398;&#20064;&#21463;&#21040;&#33719;&#24471;&#32852;&#21512;&#19987;&#23478;&#31034;&#33539;&#30340;&#23454;&#38469;&#22256;&#38590;&#30340;&#38459;&#30861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20010;&#24615;&#21270;&#19987;&#23478;&#31034;&#33539;&#30340;&#26032;&#27010;&#24565;&#65292;&#38024;&#23545;&#27599;&#20010;&#21333;&#20010;&#26234;&#20307;&#25110;&#26356;&#24191;&#27867;&#22320;&#35828;&#65292;&#22242;&#38431;&#20013;&#27599;&#31181;&#31867;&#22411;&#30340;&#26234;&#20307;&#36827;&#34892;&#20102;&#23450;&#21046;&#12290;&#36825;&#20123;&#31034;&#33539;&#20165;&#28041;&#21450;&#21333;&#26234;&#20307;&#34892;&#20026;&#20197;&#21450;&#27599;&#20010;&#26234;&#20307;&#22914;&#20309;&#23454;&#29616;&#20010;&#20154;&#30446;&#26631;&#65292;&#32780;&#19981;&#28041;&#21450;&#20219;&#20309;&#21512;&#20316;&#20803;&#32032;&#65292;&#22240;&#27492;&#30450;&#30446;&#27169;&#20223;&#23427;&#20204;&#19981;&#20250;&#23454;&#29616;&#21512;&#20316;&#30001;&#20110;&#28508;&#22312;&#20914;&#31361;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36873;&#25321;&#24615;&#22320;&#21033;&#29992;&#20010;&#24615;&#21270;&#19987;&#23478;&#31034;&#33539;&#20316;&#20026;&#25351;&#23548;&#65292;&#24182;&#20801;&#35768;&#26234;&#20307;&#23398;&#20064;&#21327;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08936v1 Announce Type: cross  Abstract: Multi-Agent Reinforcement Learning (MARL) algorithms face the challenge of efficient exploration due to the exponential increase in the size of the joint state-action space. While demonstration-guided learning has proven beneficial in single-agent settings, its direct applicability to MARL is hindered by the practical difficulty of obtaining joint expert demonstrations. In this work, we introduce a novel concept of personalized expert demonstrations, tailored for each individual agent or, more broadly, each individual type of agent within a heterogeneous team. These demonstrations solely pertain to single-agent behaviors and how each agent can achieve personal goals without encompassing any cooperative elements, thus naively imitating them will not achieve cooperation due to potential conflicts. To this end, we propose an approach that selectively utilizes personalized expert demonstrations as guidance and allows agents to learn to coo
&lt;/p&gt;</description></item><item><title>&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#26088;&#22312;&#33258;&#21160;&#21270;&#25968;&#25454;&#22686;&#24378;&#36807;&#31243;&#65292;&#20026;&#25913;&#21892;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#33021;&#25552;&#20379;&#20102;&#26356;&#39640;&#25928;&#30340;&#26041;&#24335;&#12290;</title><link>https://arxiv.org/abs/2403.08352</link><description>&lt;p&gt;
&#21033;&#29992;&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#21450;&#19982;&#20256;&#32479;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#24615;&#33021;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08352
&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#26088;&#22312;&#33258;&#21160;&#21270;&#25968;&#25454;&#22686;&#24378;&#36807;&#31243;&#65292;&#20026;&#25913;&#21892;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#33021;&#25552;&#20379;&#20102;&#26356;&#39640;&#25928;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#34987;&#35748;&#20026;&#26159;&#24120;&#29992;&#20110;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#33021;&#30340;&#26368;&#37325;&#35201;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#12290;&#23427;&#20027;&#35201;&#28041;&#21450;&#24212;&#29992;&#36866;&#24403;&#30340;&#25968;&#25454;&#36716;&#25442;&#25805;&#20316;&#65292;&#20197;&#21019;&#24314;&#20855;&#26377;&#25152;&#38656;&#23646;&#24615;&#30340;&#26032;&#25968;&#25454;&#26679;&#26412;&#12290;&#23613;&#31649;&#20854;&#26377;&#25928;&#24615;&#65292;&#36825;&#19968;&#36807;&#31243;&#36890;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#25163;&#21160;&#21019;&#24314;&#21644;&#27979;&#35797;&#19981;&#21516;&#20505;&#36873;&#22686;&#24378;&#21450;&#20854;&#36229;&#21442;&#25968;&#38656;&#32791;&#36153;&#22823;&#37327;&#26102;&#38388;&#12290;&#33258;&#21160;&#21270;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#26088;&#22312;&#33258;&#21160;&#21270;&#36825;&#19968;&#36807;&#31243;&#12290;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#21407;&#21017;&#12290;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#20110;AutoML&#30340;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#30340;&#20840;&#38754;&#35843;&#26597;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20351;&#29992;AutoML&#23454;&#29616;&#25968;&#25454;&#22686;&#24378;&#30340;&#21508;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#25968;&#25454;&#25805;&#20316;&#12289;&#25968;&#25454;&#38598;&#25104;&#21644;&#25968;&#25454;&#21512;&#25104;&#25216;&#26415;&#12290;&#25105;&#20204;&#35814;&#32454;&#35752;&#35770;&#20102;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08352v1 Announce Type: cross  Abstract: Data augmentation is arguably the most important regularization technique commonly used to improve generalization performance of machine learning models. It primarily involves the application of appropriate data transformation operations to create new data samples with desired properties. Despite its effectiveness, the process is often challenging because of the time-consuming trial and error procedures for creating and testing different candidate augmentations and their hyperparameters manually. Automated data augmentation methods aim to automate the process. State-of-the-art approaches typically rely on automated machine learning (AutoML) principles. This work presents a comprehensive survey of AutoML-based data augmentation techniques. We discuss various approaches for accomplishing data augmentation with AutoML, including data manipulation, data integration and data synthesis techniques. We present extensive discussion of technique
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#23558;&#38142;&#24335;&#35268;&#21017;&#20248;&#21270;&#20026;&#26641;&#24418;&#35268;&#21017;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#26377;&#25928;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#25512;&#29702;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.05130</link><description>&lt;p&gt;
&#20174;&#38142;&#21040;&#26641;&#65306;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#23558;&#38142;&#24335;&#35268;&#21017;&#20248;&#21270;&#20026;&#26641;&#24418;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
From Chain to Tree: Refining Chain-like Rules into Tree-like Rules on Knowledge Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05130
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#23558;&#38142;&#24335;&#35268;&#21017;&#20248;&#21270;&#20026;&#26641;&#24418;&#35268;&#21017;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#26377;&#25928;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#25512;&#29702;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#24456;&#22909;&#35299;&#37322;&#33021;&#21147;&#21644;&#21487;&#25511;&#24615;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#22312;&#35832;&#22914;&#30693;&#35782;&#25512;&#29702;&#21644;&#20915;&#31574;&#25903;&#25345;&#31561;&#35768;&#22810;&#20219;&#21153;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#23398;&#20064;&#38142;&#24335;&#35268;&#21017;&#19978;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#35821;&#20041;&#34920;&#36798;&#21644;&#20934;&#30830;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#38142;&#24335;&#35268;&#21017;&#36890;&#24120;&#20250;&#22312;&#19981;&#27491;&#30830;&#30340;&#22522;&#30784;&#20540;&#19978;&#35302;&#21457;&#65292;&#20135;&#29983;&#19981;&#20934;&#30830;&#29978;&#33267;&#38169;&#35823;&#30340;&#25512;&#29702;&#32467;&#26524;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#26641;&#29366;&#35268;&#21017;&#30340;&#27010;&#24565;&#65292;&#20197;&#25193;&#23637;&#24212;&#29992;&#33539;&#22260;&#24182;&#25552;&#39640;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#23558;&#38142;&#24335;&#35268;&#21017;&#20248;&#21270;&#20026;&#26641;&#29366;&#35268;&#21017;&#12290;&#23545;&#22235;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#27604;&#36739;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#21487;&#20197;&#36731;&#26494;&#36866;&#24212;&#20854;&#20182;&#38142;&#24335;&#35268;&#21017;&#24402;&#32435;&#26041;&#27861;&#65292;&#24182;&#19988;&#20248;&#21270;&#21518;&#30340;&#26641;&#29366;&#35268;&#21017;&#22987;&#32456;&#22312;&#38142;&#25509;&#39044;&#27979;&#19978;&#34920;&#29616;&#20248;&#20110;&#38142;&#24335;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05130v1 Announce Type: new  Abstract: With good explanatory power and controllability, rule-based methods play an important role in many tasks such as knowledge reasoning and decision support. However, existing studies primarily focused on learning chain-like rules, which limit their semantic expressions and accurate prediction abilities. As a result, chain-like rules usually fire on the incorrect grounding values, producing inaccurate or even erroneous reasoning results. In this paper, we propose the concept of tree-like rules on knowledge graphs to expand the application scope and improve the reasoning ability of rule-based methods. Meanwhile, we propose an effective framework for refining chain-like rules into tree-like rules. Experimental comparisons on four public datasets show that the proposed framework can easily adapt to other chain-like rule induction methods and the refined tree-like rules consistently achieve better performances than chain-like rules on link pred
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#33258;&#36866;&#24212;&#29468;&#24819;&#30340;&#22312;&#32447;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;IT&#22522;&#30784;&#35774;&#26045;&#30340;&#33258;&#21160;&#21270;&#23433;&#20840;&#21709;&#24212;&#26041;&#27861;&#65292;&#20854;&#20013;&#28216;&#25103;&#21442;&#19982;&#32773;&#36890;&#36807;Bayesian&#23398;&#20064;&#35843;&#25972;&#29468;&#24819;&#65292;&#24182;&#36890;&#36807;&#25512;&#28436;&#26356;&#26032;&#31574;&#30053;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#26368;&#20339;&#25311;&#21512;&#65292;&#25552;&#39640;&#20102;&#25512;&#28436;&#22312;&#29468;&#24819;&#27169;&#22411;&#19979;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.12499</link><description>&lt;p&gt;
&#36890;&#36807;&#33258;&#36866;&#24212;&#29468;&#24819;&#30340;&#22312;&#32447;&#23398;&#20064;&#23454;&#29616;&#33258;&#21160;&#21270;&#23433;&#20840;&#21709;&#24212;
&lt;/p&gt;
&lt;p&gt;
Automated Security Response through Online Learning with Adaptive Conjectures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12499
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#33258;&#36866;&#24212;&#29468;&#24819;&#30340;&#22312;&#32447;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;IT&#22522;&#30784;&#35774;&#26045;&#30340;&#33258;&#21160;&#21270;&#23433;&#20840;&#21709;&#24212;&#26041;&#27861;&#65292;&#20854;&#20013;&#28216;&#25103;&#21442;&#19982;&#32773;&#36890;&#36807;Bayesian&#23398;&#20064;&#35843;&#25972;&#29468;&#24819;&#65292;&#24182;&#36890;&#36807;&#25512;&#28436;&#26356;&#26032;&#31574;&#30053;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#26368;&#20339;&#25311;&#21512;&#65292;&#25552;&#39640;&#20102;&#25512;&#28436;&#22312;&#29468;&#24819;&#27169;&#22411;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;IT&#22522;&#30784;&#35774;&#26045;&#30340;&#33258;&#21160;&#21270;&#23433;&#20840;&#21709;&#24212;&#65292;&#24182;&#23558;&#25915;&#20987;&#32773;&#21644;&#38450;&#24481;&#32773;&#20043;&#38388;&#30340;&#20114;&#21160;&#24418;&#24335;&#34920;&#36848;&#20026;&#19968;&#20010;&#37096;&#20998;&#35266;&#27979;&#12289;&#38750;&#24179;&#31283;&#21338;&#24328;&#12290;&#25105;&#20204;&#25918;&#23485;&#20102;&#28216;&#25103;&#27169;&#22411;&#27491;&#30830;&#35268;&#23450;&#30340;&#26631;&#20934;&#20551;&#35774;&#65292;&#24182;&#32771;&#34385;&#27599;&#20010;&#21442;&#19982;&#32773;&#23545;&#27169;&#22411;&#26377;&#19968;&#20010;&#27010;&#29575;&#24615;&#29468;&#24819;&#65292;&#21487;&#33021;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#38169;&#35823;&#35268;&#23450;&#65292;&#21363;&#30495;&#23454;&#27169;&#22411;&#30340;&#27010;&#29575;&#20026;0&#12290;&#36825;&#31181;&#24418;&#24335;&#20801;&#35768;&#25105;&#20204;&#25429;&#25417;&#20851;&#20110;&#22522;&#30784;&#35774;&#26045;&#21644;&#21442;&#19982;&#32773;&#24847;&#22270;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#22312;&#32447;&#23398;&#20064;&#26377;&#25928;&#30340;&#28216;&#25103;&#31574;&#30053;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20010;&#21442;&#19982;&#32773;&#36890;&#36807;&#36125;&#21494;&#26031;&#23398;&#20064;&#36845;&#20195;&#22320;&#35843;&#25972;&#20854;&#29468;&#24819;&#65292;&#24182;&#36890;&#36807;&#25512;&#28436;&#26356;&#26032;&#20854;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29468;&#24819;&#20250;&#25910;&#25947;&#21040;&#26368;&#20339;&#25311;&#21512;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#20855;&#26377;&#29468;&#27979;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#25512;&#28436;&#23454;&#29616;&#24615;&#33021;&#25913;&#36827;&#30340;&#19978;&#38480;&#12290;&#20026;&#20102;&#21051;&#30011;&#28216;&#25103;&#30340;&#31283;&#23450;&#29366;&#24577;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Berk-Nash&#24179;&#34913;&#30340;&#19968;&#20010;&#21464;&#31181;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12499v1 Announce Type: cross  Abstract: We study automated security response for an IT infrastructure and formulate the interaction between an attacker and a defender as a partially observed, non-stationary game. We relax the standard assumption that the game model is correctly specified and consider that each player has a probabilistic conjecture about the model, which may be misspecified in the sense that the true model has probability 0. This formulation allows us to capture uncertainty about the infrastructure and the intents of the players. To learn effective game strategies online, we design a novel method where a player iteratively adapts its conjecture using Bayesian learning and updates its strategy through rollout. We prove that the conjectures converge to best fits, and we provide a bound on the performance improvement that rollout enables with a conjectured model. To characterize the steady state of the game, we propose a variant of the Berk-Nash equilibrium. We 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#27169;&#22411;&#37325;&#26032;&#22522;&#24213;&#30340;&#29616;&#35937;&#65292;&#24182;&#21457;&#29616;&#20102;&#29616;&#26377;&#21305;&#37197;&#31639;&#27861;&#30340;&#19981;&#36275;&#12290;&#36890;&#36807;&#36866;&#24403;&#30340;&#37325;&#24402;&#19968;&#21270;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#21305;&#37197;&#31639;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#23427;&#19982;&#37325;&#24402;&#19968;&#21270;&#36807;&#31243;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36825;&#20026;&#21098;&#26525;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35299;&#65292;&#25512;&#21160;&#20102;&#19968;&#31181;&#36731;&#37327;&#19988;&#26377;&#25928;&#30340;&#21518;&#21098;&#26525;&#25554;&#20214;&#30340;&#24320;&#21457;&#12290;</title><link>https://arxiv.org/abs/2402.05966</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#27169;&#22411;&#37325;&#26032;&#22522;&#24213;&#21644;&#32447;&#24615;&#27169;&#24577;&#36830;&#25509;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rethink Model Re-Basin and the Linear Mode Connectivity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#27169;&#22411;&#37325;&#26032;&#22522;&#24213;&#30340;&#29616;&#35937;&#65292;&#24182;&#21457;&#29616;&#20102;&#29616;&#26377;&#21305;&#37197;&#31639;&#27861;&#30340;&#19981;&#36275;&#12290;&#36890;&#36807;&#36866;&#24403;&#30340;&#37325;&#24402;&#19968;&#21270;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#21305;&#37197;&#31639;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#23427;&#19982;&#37325;&#24402;&#19968;&#21270;&#36807;&#31243;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36825;&#20026;&#21098;&#26525;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35299;&#65292;&#25512;&#21160;&#20102;&#19968;&#31181;&#36731;&#37327;&#19988;&#26377;&#25928;&#30340;&#21518;&#21098;&#26525;&#25554;&#20214;&#30340;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#36275;&#22815;&#23485;&#30340;&#27169;&#22411;&#26469;&#35828;&#65292;&#22823;&#37096;&#20998;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#35299;&#21487;&#20197;&#25910;&#25947;&#21040;&#30456;&#21516;&#30340;&#22522;&#24213;&#65292;&#21482;&#26159;&#39034;&#24207;&#21487;&#33021;&#19981;&#21516;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#27169;&#22411;&#37325;&#26032;&#22522;&#24213;&#30340;&#38454;&#27573;&#65292;&#23545;&#20110;&#27169;&#22411;&#24179;&#22343;&#21270;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#37325;&#26032;&#22522;&#24213;&#31574;&#30053;&#22312;&#25928;&#26524;&#19978;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#22240;&#20026;&#23545;&#24213;&#23618;&#26426;&#21046;&#30340;&#29702;&#35299;&#19981;&#22815;&#20840;&#38754;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#37325;&#26032;&#23457;&#35270;&#20102;&#26631;&#20934;&#20570;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#29616;&#26377;&#21305;&#37197;&#31639;&#27861;&#30340;&#39057;&#32321;&#19981;&#36275;&#20043;&#22788;&#65292;&#25105;&#20204;&#36890;&#36807;&#36866;&#24403;&#30340;&#37325;&#24402;&#19968;&#21270;&#26469;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#26356;&#30452;&#25509;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#21305;&#37197;&#31639;&#27861;&#19982;&#37325;&#24402;&#19968;&#21270;&#36807;&#31243;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36825;&#31181;&#35266;&#28857;&#19981;&#20165;&#28548;&#28165;&#21644;&#25913;&#36827;&#20102;&#20197;&#21069;&#30340;&#30740;&#31350;&#32467;&#26524;&#65292;&#36824;&#20419;&#36827;&#20102;&#26032;&#30340;&#27934;&#35265;&#12290;&#20363;&#22914;&#65292;&#23427;&#23558;&#32447;&#24615;&#27169;&#24577;&#36830;&#25509;&#24615;&#19982;&#21098;&#26525;&#32852;&#31995;&#36215;&#26469;&#65292;&#20174;&#32780;&#28608;&#21457;&#20102;&#19968;&#31181;&#36731;&#37327;&#19988;&#26377;&#25928;&#30340;&#21518;&#21098;&#26525;&#25554;&#20214;&#65292;&#21487;&#20197;&#30452;&#25509;&#19982;&#20219;&#20309;&#29616;&#26377;&#30340;&#21098;&#26525;&#25216;&#26415;&#21512;&#24182;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies suggest that with sufficiently wide models, most SGD solutions can, up to permutation, converge into the same basin. This phenomenon, known as the model re-basin regime, has significant implications for model averaging. However, current re-basin strategies are limited in effectiveness due to a lack of comprehensive understanding of underlying mechanisms. Addressing this gap, our work revisits standard practices and uncovers the frequent inadequacies of existing matching algorithms, which we show can be mitigated through proper re-normalization. By introducing a more direct analytical approach, we expose the interaction between matching algorithms and re-normalization processes. This perspective not only clarifies and refines previous findings but also facilitates novel insights. For instance, it connects the linear mode connectivity to pruning, motivating a lightweight yet effective post-pruning plug-in that can be directly merged with any existing pruning techniques. Ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22478;&#24066;&#22522;&#30784;&#27169;&#22411;&#22312;&#26234;&#33021;&#22478;&#24066;&#21457;&#23637;&#20013;&#30340;&#37325;&#35201;&#24615;&#21644;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#20998;&#31867;&#26041;&#27861;&#12290;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#38754;&#20020;&#30528;&#19968;&#20123;&#25361;&#25112;&#65292;&#22914;&#32570;&#20047;&#28165;&#26224;&#30340;&#23450;&#20041;&#21644;&#31995;&#32479;&#24615;&#30340;&#32508;&#36848;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#21644;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.01749</link><description>&lt;p&gt;
&#36808;&#21521;&#22478;&#24066;&#26234;&#33021;&#65306;&#22478;&#24066;&#22522;&#30784;&#27169;&#22411;&#32508;&#36848;&#19982;&#23637;&#26395;
&lt;/p&gt;
&lt;p&gt;
Towards Urban General Intelligence: A Review and Outlook of Urban Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01749
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22478;&#24066;&#22522;&#30784;&#27169;&#22411;&#22312;&#26234;&#33021;&#22478;&#24066;&#21457;&#23637;&#20013;&#30340;&#37325;&#35201;&#24615;&#21644;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#20998;&#31867;&#26041;&#27861;&#12290;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#38754;&#20020;&#30528;&#19968;&#20123;&#25361;&#25112;&#65292;&#22914;&#32570;&#20047;&#28165;&#26224;&#30340;&#23450;&#20041;&#21644;&#31995;&#32479;&#24615;&#30340;&#32508;&#36848;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#21644;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#29616;&#24050;&#25104;&#20026;&#26234;&#33021;&#22478;&#24066;&#26381;&#21153;&#36827;&#27493;&#30340;&#26680;&#24515;&#65292;&#23545;&#25552;&#39640;&#22478;&#24066;&#29615;&#22659;&#30340;&#25928;&#29575;&#12289;&#21487;&#25345;&#32493;&#24615;&#21644;&#23452;&#23621;&#24615;&#36215;&#21040;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#26368;&#36817;&#20986;&#29616;&#30340;ChatGPT&#31561;&#22522;&#30784;&#27169;&#22411;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#26631;&#24535;&#30528;&#19968;&#20010;&#38761;&#21629;&#24615;&#30340;&#36716;&#21464;&#12290;&#23427;&#20204;&#22312;&#19978;&#19979;&#25991;&#29702;&#35299;&#12289;&#38382;&#39064;&#35299;&#20915;&#21644;&#36866;&#24212;&#21508;&#31181;&#20219;&#21153;&#26041;&#38754;&#30340;&#26080;&#19982;&#20262;&#27604;&#30340;&#33021;&#21147;&#34920;&#26126;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#25972;&#21512;&#21040;&#22478;&#24066;&#39046;&#22495;&#20013;&#21487;&#33021;&#23545;&#26234;&#33021;&#22478;&#24066;&#30340;&#21457;&#23637;&#20135;&#29983;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;&#23613;&#31649;&#23545;&#22478;&#24066;&#22522;&#30784;&#27169;&#22411;&#65288;UFMs&#65289;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#38271;&#65292;&#20294;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#38754;&#20020;&#30528;&#19968;&#20123;&#25361;&#25112;&#65292;&#22914;&#32570;&#20047;&#28165;&#26224;&#30340;&#23450;&#20041;&#12289;&#31995;&#32479;&#24615;&#30340;&#32508;&#36848;&#21644;&#21487;&#26222;&#36941;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#39318;&#20808;&#20171;&#32461;&#20102;UFM&#30340;&#27010;&#24565;&#65292;&#24182;&#35752;&#35770;&#20102;&#26500;&#24314;&#23427;&#20204;&#25152;&#38754;&#20020;&#30340;&#29420;&#29305;&#25361;&#25112;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#25968;&#25454;&#20026;&#20013;&#24515;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#23545;&#24403;&#21069;&#19982;UFM&#30456;&#20851;&#30340;&#24037;&#20316;&#36827;&#34892;&#20102;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning techniques are now integral to the advancement of intelligent urban services, playing a crucial role in elevating the efficiency, sustainability, and livability of urban environments. The recent emergence of foundation models such as ChatGPT marks a revolutionary shift in the fields of machine learning and artificial intelligence. Their unparalleled capabilities in contextual understanding, problem solving, and adaptability across a wide range of tasks suggest that integrating these models into urban domains could have a transformative impact on the development of smart cities. Despite growing interest in Urban Foundation Models~(UFMs), this burgeoning field faces challenges such as a lack of clear definitions, systematic reviews, and universalizable solutions. To this end, this paper first introduces the concept of UFM and discusses the unique challenges involved in building them. We then propose a data-centric taxonomy that categorizes current UFM-related works, base
&lt;/p&gt;</description></item><item><title>AutoPlanBench&#26159;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#36716;&#25442;PDDL&#35268;&#21010;&#22522;&#20934;&#27979;&#35797;&#20026;&#25991;&#26412;&#25551;&#36848;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#21069;&#26368;&#22909;&#30340;LLM&#35268;&#21010;&#22120;&#22312;&#26576;&#20123;&#35268;&#21010;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#31168;&#65292;&#20294;&#23545;&#20110;&#20854;&#20182;&#20219;&#21153;&#26469;&#35828;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2311.09830</link><description>&lt;p&gt;
AutoPlanBench: &#20174;PDDL&#33258;&#21160;&#29983;&#25104;LLM&#35268;&#21010;&#22120;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
AutoPlanBench: Automatically generating benchmarks for LLM planners from PDDL
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09830
&lt;/p&gt;
&lt;p&gt;
AutoPlanBench&#26159;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#36716;&#25442;PDDL&#35268;&#21010;&#22522;&#20934;&#27979;&#35797;&#20026;&#25991;&#26412;&#25551;&#36848;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#21069;&#26368;&#22909;&#30340;LLM&#35268;&#21010;&#22120;&#22312;&#26576;&#20123;&#35268;&#21010;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#31168;&#65292;&#20294;&#23545;&#20110;&#20854;&#20182;&#20219;&#21153;&#26469;&#35828;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#65288;&#36923;&#36753;-&#27010;&#29575;&#27169;&#22411;&#65289;&#22312;&#35268;&#21010;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#65292;&#20294;&#26159;&#23427;&#20204;&#22312;&#35268;&#21010;&#21644;&#25512;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#23578;&#19981;&#26126;&#30830;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;AutoPlanBench&#65292;&#19968;&#31181;&#23558;PDDL&#20013;&#30340;&#35268;&#21010;&#22522;&#20934;&#27979;&#35797;&#33258;&#21160;&#36716;&#25442;&#20026;&#25991;&#26412;&#25551;&#36848;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#25105;&#20204;&#26041;&#27861;&#21019;&#24314;&#30340;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#22909;&#30340;LLM&#35268;&#21010;&#22120;&#22312;&#26576;&#20123;&#35268;&#21010;&#20219;&#21153;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#20854;&#20182;&#20219;&#21153;&#20173;&#28982;&#36229;&#20986;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#33021;&#21147;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
LLMs are being increasingly used for planning-style tasks, but their capabilities for planning and reasoning are poorly understood. We present AutoPlanBench, a novel method for automatically converting planning benchmarks written in PDDL into textual descriptions and offer a benchmark dataset created with our method. We show that while the best LLM planners do well on some planning tasks, others remain out of reach of current methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25913;&#36827;&#25688;&#35201;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#20154;&#24037;&#32534;&#36753;&#30340;&#21453;&#39304;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#24207;&#21015;&#23545;&#40784;&#65288;&#19981;&#65289;&#20284;&#28982;&#35757;&#32451;(SALT)&#25216;&#26415;&#23558;&#20154;&#24037;&#32534;&#36753;&#25968;&#25454;&#19982;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#32467;&#21512;&#36215;&#26469;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#21307;&#23398;&#39046;&#22495;&#25688;&#35201;&#29983;&#25104;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.05857</link><description>&lt;p&gt;
&#20351;&#29992;&#20154;&#24037;&#32534;&#36753;&#25913;&#36827;&#25688;&#35201;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Improving Summarization with Human Edits. (arXiv:2310.05857v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25913;&#36827;&#25688;&#35201;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#20154;&#24037;&#32534;&#36753;&#30340;&#21453;&#39304;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#24207;&#21015;&#23545;&#40784;&#65288;&#19981;&#65289;&#20284;&#28982;&#35757;&#32451;(SALT)&#25216;&#26415;&#23558;&#20154;&#24037;&#32534;&#36753;&#25968;&#25454;&#19982;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#32467;&#21512;&#36215;&#26469;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#21307;&#23398;&#39046;&#22495;&#25688;&#35201;&#29983;&#25104;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#20154;&#31867;&#21453;&#39304;&#33539;&#24335;&#23398;&#20064;&#21487;&#20197;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#25991;&#26412;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#22312;&#36890;&#29992;&#39046;&#22495;&#25277;&#35937;&#21270;&#25688;&#35201;&#29983;&#25104;&#20013;&#20351;&#29992;&#20154;&#31867;&#21453;&#39304;&#26469;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#65292;&#24182;&#33719;&#24471;&#20102;&#36229;&#36234;&#20256;&#32479;&#20284;&#28982;&#35757;&#32451;&#30340;&#25688;&#35201;&#36136;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#19968;&#31181;&#36739;&#23569;&#25506;&#32034;&#30340;&#20154;&#31867;&#21453;&#39304;&#24418;&#24335;&#8212;&#8212;&#20154;&#24037;&#32534;&#36753;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#8212;&#8212;&#24207;&#21015;&#23545;&#40784;&#65288;&#19981;&#65289;&#20284;&#28982;&#35757;&#32451;(SALT)&#65292;&#22312;&#35757;&#32451;&#24490;&#29615;&#20013;&#21516;&#26102;&#20351;&#29992;&#20154;&#24037;&#32534;&#36753;&#21644;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#20351;&#29992;&#29616;&#26377;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#22522;&#20934;&#25688;&#35201;&#26469;&#27169;&#25311;&#20154;&#24037;&#32534;&#36753;&#65292;&#20197;&#21450;&#22312;&#35757;&#32451;&#21518;&#33719;&#21462;&#30340;&#27169;&#22411;&#29983;&#25104;&#25688;&#35201;&#65292;&#20197;&#20943;&#23569;&#23545;&#26114;&#36149;&#30340;&#20154;&#24037;&#32534;&#36753;&#25968;&#25454;&#30340;&#38656;&#27714;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23558;&#20154;&#31867;&#21453;&#39304;&#30340;&#25506;&#32034;&#20174;&#36890;&#29992;&#39046;&#22495;&#25688;&#35201;&#29983;&#25104;&#25193;&#23637;&#21040;&#21307;&#23398;&#39046;&#22495;&#25688;&#35201;&#29983;&#25104;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;SALT&#22312;&#25913;&#36827;&#25688;&#35201;&#29983;&#25104;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown the promise of learning with human feedback paradigms to produce human-determined high-quality text. Existing works use human feedback to train large language models (LLMs) in general domain abstractive summarization and have obtained summary quality exceeding traditional likelihood training. In this paper, we focus on a less explored form of human feedback -- Human Edits. We propose Sequence Alignment (un)Likelihood Training (SALT), a novel technique to use both the human-edited and model-generated data together in the training loop. In addition, we demonstrate simulating Human Edits with ground truth summaries coming from existing training data -Imitation edits, along with the model-generated summaries obtained after the training, to reduce the need for expensive human-edit data. In our experiments, we extend human feedback exploration from general domain summarization to medical domain summarization. Our results demonstrate the effectiveness of SALT in improv
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#21453;&#28436;&#36807;&#31243;&#65288;ZIP&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#22270;&#20687;&#23646;&#24615;&#32534;&#36753;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#29983;&#25104;&#30340;&#35270;&#35273;&#21442;&#32771;&#21644;&#25991;&#26412;&#24341;&#23548;&#27880;&#20837;&#25193;&#25955;&#27169;&#22411;&#30340;&#35821;&#20041;&#28508;&#31354;&#38388;&#65292;&#21487;&#20197;&#22312;&#25991;&#26412;&#25552;&#31034;&#30340;&#30452;&#35266;&#25511;&#21046;&#19979;&#20135;&#29983;&#22810;&#26679;&#30340;&#20869;&#23481;&#21644;&#23646;&#24615;&#65292;&#24182;&#23637;&#29616;&#20986;&#23545;&#19981;&#21516;&#23646;&#24615;&#25805;&#20316;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.15854</link><description>&lt;p&gt;
&#22270;&#20687;&#23646;&#24615;&#32534;&#36753;&#30340;&#38646;&#26679;&#26412;&#21453;&#28436;&#36807;&#31243;&#19982;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models. (arXiv:2308.15854v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15854
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#21453;&#28436;&#36807;&#31243;&#65288;ZIP&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#22270;&#20687;&#23646;&#24615;&#32534;&#36753;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#29983;&#25104;&#30340;&#35270;&#35273;&#21442;&#32771;&#21644;&#25991;&#26412;&#24341;&#23548;&#27880;&#20837;&#25193;&#25955;&#27169;&#22411;&#30340;&#35821;&#20041;&#28508;&#31354;&#38388;&#65292;&#21487;&#20197;&#22312;&#25991;&#26412;&#25552;&#31034;&#30340;&#30452;&#35266;&#25511;&#21046;&#19979;&#20135;&#29983;&#22810;&#26679;&#30340;&#20869;&#23481;&#21644;&#23646;&#24615;&#65292;&#24182;&#23637;&#29616;&#20986;&#23545;&#19981;&#21516;&#23646;&#24615;&#25805;&#20316;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#22312;&#22270;&#20687;&#32534;&#36753;&#20013;&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20542;&#21521;&#20110;&#20351;&#29992;&#22270;&#20687;&#24341;&#23548;&#26041;&#27861;&#65292;&#25552;&#20379;&#35270;&#35273;&#21442;&#32771;&#20294;&#32570;&#20047;&#35821;&#20041;&#36830;&#36143;&#24615;&#30340;&#25511;&#21046;&#65292;&#25110;&#32773;&#20351;&#29992;&#25991;&#26412;&#24341;&#23548;&#26041;&#27861;&#65292;&#30830;&#20445;&#23545;&#25991;&#26412;&#24341;&#23548;&#30340;&#24544;&#23454;&#65292;&#20294;&#32570;&#20047;&#35270;&#35273;&#36136;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38646;&#26679;&#26412;&#21453;&#28436;&#36807;&#31243;&#65288;ZIP&#65289;&#26694;&#26550;&#65292;&#23427;&#23558;&#29983;&#25104;&#30340;&#35270;&#35273;&#21442;&#32771;&#21644;&#25991;&#26412;&#24341;&#23548;&#30340;&#34701;&#21512;&#27880;&#20837;&#21040;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#35821;&#20041;&#28508;&#31354;&#38388;&#20013;&#12290;&#20165;&#20351;&#29992;&#19968;&#20010;&#24494;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20986;&#30340;ZIP&#22312;&#25991;&#26412;&#25552;&#31034;&#30340;&#30452;&#35266;&#25511;&#21046;&#19979;&#20135;&#29983;&#22810;&#26679;&#30340;&#20869;&#23481;&#21644;&#23646;&#24615;&#12290;&#27492;&#22806;&#65292;ZIP&#22312;&#30495;&#23454;&#22270;&#20687;&#19978;&#23637;&#31034;&#20102;&#23545;&#22495;&#20869;&#21644;&#22495;&#22806;&#23646;&#24615;&#25805;&#20316;&#30340;&#26174;&#33879;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35814;&#32454;&#30340;&#23454;&#39564;&#12290;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;ZIP&#20135;&#29983;&#20102;&#19982;&#20043;&#30456;&#24403;&#36136;&#37327;&#30340;&#22270;&#20687;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36924;&#30495;&#30340;&#32534;&#36753;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models have shown outstanding performance in image editing. Existing works tend to use either image-guided methods, which provide a visual reference but lack control over semantic coherence, or text-guided methods, which ensure faithfulness to text guidance but lack visual quality. To address the problem, we propose the Zero-shot Inversion Process (ZIP), a framework that injects a fusion of generated visual reference and text guidance into the semantic latent space of a \textit{frozen} pre-trained diffusion model. Only using a tiny neural network, the proposed ZIP produces diverse content and attributes under the intuitive control of the text prompt. Moreover, ZIP shows remarkable robustness for both in-domain and out-of-domain attribute manipulation on real images. We perform detailed experiments on various benchmark datasets. Compared to state-of-the-art methods, ZIP produces images of equivalent quality while providing a realistic editing effect.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20174;&#19981;&#30830;&#23450;&#24615;&#30340;&#35282;&#24230;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#36890;&#36807;&#23454;&#39564;&#21457;&#29616;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#22312;&#25506;&#32034;&#21644;&#25269;&#21046;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19981;&#33391;&#34892;&#20026;&#26041;&#38754;&#20855;&#26377;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.10236</link><description>&lt;p&gt;
&#19977;&#24605;&#32780;&#21518;&#34892;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models. (arXiv:2307.10236v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#19981;&#30830;&#23450;&#24615;&#30340;&#35282;&#24230;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#25506;&#32034;&#24615;&#30740;&#31350;&#65292;&#36890;&#36807;&#23454;&#39564;&#21457;&#29616;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#22312;&#25506;&#32034;&#21644;&#25269;&#21046;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19981;&#33391;&#34892;&#20026;&#26041;&#38754;&#20855;&#26377;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#36817;&#24615;&#33021;&#31361;&#30772;&#20026;&#20247;&#22810;&#24037;&#19994;&#24212;&#29992;&#21644;&#39046;&#22495;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;&#28982;&#32780;&#65292;LLMs&#30340;&#38169;&#35823;&#29983;&#25104;&#65292;&#22914;&#34394;&#20551;&#39044;&#27979;&#12289;&#38169;&#35823;&#20449;&#24687;&#21644;&#24187;&#35273;&#65292;&#20063;&#24341;&#21457;&#20102;&#23545;LLMs&#21487;&#38752;&#24615;&#30340;&#20005;&#37325;&#20851;&#27880;&#65292;&#23588;&#20854;&#22312;&#23545;&#23433;&#20840;&#12289;&#21487;&#38752;&#24615;&#26377;&#25935;&#24863;&#30340;&#22330;&#26223;&#20013;&#65292;&#21487;&#33021;&#38459;&#30861;&#20854;&#22312;&#23454;&#38469;&#20013;&#30340;&#24212;&#29992;&#12290;&#23613;&#31649;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24050;&#32463;&#26174;&#31034;&#20986;&#20854;&#22312;&#35299;&#37322;&#19968;&#33324;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#30340;&#39044;&#27979;&#39118;&#38505;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#20294;&#20851;&#20110;&#23427;&#26159;&#21542;&#20197;&#21450;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#26377;&#21161;&#20110;&#25506;&#32034;LLMs&#30340;&#33021;&#21147;&#21644;&#25269;&#21046;&#20854;&#19981;&#33391;&#34892;&#20026;&#26041;&#38754;&#30693;&#20043;&#29978;&#23569;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#25991;&#20174;&#19981;&#30830;&#23450;&#24615;&#30340;&#35282;&#24230;&#24320;&#23637;&#20102;&#20851;&#20110;LLMs&#39118;&#38505;&#35780;&#20272;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20351;&#29992;12&#31181;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#21644;4&#20010;LLMs&#22312;4&#20010;&#37325;&#35201;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#35843;&#26597;&#19981;&#30830;&#23450;&#24615;&#22312;&#25506;&#32034;LLMs&#33021;&#21147;&#21644;&#23545;&#25239;&#20854;&#19981;&#33391;&#34892;&#20026;&#26041;&#38754;&#30340;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent performance leap of Large Language Models (LLMs) opens up new opportunities across numerous industrial applications and domains. However, erroneous generations, such as false predictions, misinformation, and hallucination made by LLMs, have also raised severe concerns for the trustworthiness of LLMs', especially in safety-, security- and reliability-sensitive scenarios, potentially hindering real-world adoptions. While uncertainty estimation has shown its potential for interpreting the prediction risks made by general machine learning (ML) models, little is known about whether and to what extent it can help explore an LLM's capabilities and counteract its undesired behavior. To bridge the gap, in this paper, we initiate an exploratory study on the risk assessment of LLMs from the lens of uncertainty. In particular, we experiment with twelve uncertainty estimation methods and four LLMs on four prominent natural language processing (NLP) tasks to investigate to what extent unc
&lt;/p&gt;</description></item><item><title>LaDe&#26159;&#31532;&#19968;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#26411;&#31471;&#37197;&#36865;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#20102;&#25968;&#30334;&#19975;&#20010;&#26469;&#33258;&#20135;&#19994;&#30028;&#30340;&#21253;&#35065;&#65292;&#20855;&#26377;&#22823;&#35268;&#27169;&#12289;&#20840;&#38754;&#30340;&#20449;&#24687;&#21644;&#22810;&#26679;&#24615;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.10675</link><description>&lt;p&gt;
LaDe: &#20135;&#19994;&#30028;&#31532;&#19968;&#20010;&#20840;&#38754;&#30340;&#26411;&#31471;&#37197;&#36865;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
LaDe: The First Comprehensive Last-mile Delivery Dataset from Industry. (arXiv:2306.10675v2 [cs.DB] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10675
&lt;/p&gt;
&lt;p&gt;
LaDe&#26159;&#31532;&#19968;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#26411;&#31471;&#37197;&#36865;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#20102;&#25968;&#30334;&#19975;&#20010;&#26469;&#33258;&#20135;&#19994;&#30028;&#30340;&#21253;&#35065;&#65292;&#20855;&#26377;&#22823;&#35268;&#27169;&#12289;&#20840;&#38754;&#30340;&#20449;&#24687;&#21644;&#22810;&#26679;&#24615;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#26411;&#31471;&#37197;&#36865;&#25968;&#25454;&#38598;&#23545;&#20110;&#29289;&#27969;&#12289;&#20379;&#24212;&#38142;&#31649;&#29702;&#21644;&#26102;&#31354;&#25968;&#25454;&#25366;&#25496;&#30340;&#30740;&#31350;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#36804;&#20170;&#24050;&#32463;&#24320;&#21457;&#20102;&#22823;&#37327;&#31639;&#27861;&#65292;&#20294;&#23578;&#26080;&#20844;&#35748;&#30340;&#12289;&#20844;&#24320;&#21487;&#29992;&#30340;&#26411;&#31471;&#37197;&#36865;&#25968;&#25454;&#38598;&#26469;&#25903;&#25345;&#36825;&#20010;&#39046;&#22495;&#30340;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;LaDe&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#26411;&#31471;&#37197;&#36865;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#20102;&#25968;&#30334;&#19975;&#20010;&#26469;&#33258;&#20135;&#19994;&#30028;&#30340;&#21253;&#35065;&#12290;LaDe&#20855;&#26377;&#19977;&#20010;&#29420;&#29305;&#30340;&#29305;&#28857;&#65306;(1)&#22823;&#35268;&#27169;&#12290;&#23427;&#28041;&#21450;&#21040;6&#20010;&#26376;&#30340;&#30495;&#23454;&#36816;&#33829;&#20013;&#30340;10,677k&#20010;&#21253;&#35065;&#21644;21k&#20010;&#24555;&#36882;&#21592;&#12290;(2)&#20840;&#38754;&#30340;&#20449;&#24687;&#12290;&#23427;&#25552;&#20379;&#21407;&#22987;&#21253;&#35065;&#20449;&#24687;&#65292;&#22914;&#20301;&#32622;&#21644;&#26102;&#38388;&#35201;&#27714;&#65292;&#20197;&#21450;&#20219;&#21153;&#20107;&#20214;&#20449;&#24687;&#65292;&#35760;&#24405;&#20102;&#24555;&#36882;&#21592;&#20309;&#26102;&#20309;&#22320;&#36827;&#34892;&#20219;&#21153;&#25509;&#21463;&#21644;&#23436;&#25104;&#12290;(3)&#22810;&#26679;&#24615;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#25324;&#26469;&#33258;&#21508;&#31181;&#22330;&#26223;&#30340;&#25968;&#25454;&#65292;&#21253;&#25324;&#21253;&#35065;&#30340;&#21462;&#36865;&#21644;&#26469;&#33258;&#22810;&#20010;&#22478;&#24066;&#30340;&#25968;&#25454;&#65292;&#27599;&#20010;&#22478;&#24066;&#37117;&#26377;&#20854;&#29420;&#29305;&#30340;&#26102;&#31354;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world last-mile delivery datasets are crucial for research in logistics, supply chain management, and spatio-temporal data mining. Despite a plethora of algorithms developed to date, no widely accepted, publicly available last-mile delivery dataset exists to support research in this field. In this paper, we introduce \texttt{LaDe}, the first publicly available last-mile delivery dataset with millions of packages from the industry. LaDe has three unique characteristics: (1) Large-scale. It involves 10,677k packages of 21k couriers over 6 months of real-world operation. (2) Comprehensive information. It offers original package information, such as its location and time requirements, as well as task-event information, which records when and where the courier is while events such as task-accept and task-finish events happen. (3) Diversity. The dataset includes data from various scenarios, including package pick-up and delivery, and from multiple cities, each with its unique spatio-tem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#21307;&#30103;&#20445;&#20581;&#20013;&#30340;&#24212;&#29992;&#21644;&#32771;&#34385;&#20262;&#29702;&#21644;&#21746;&#23398;&#21407;&#21017;&#20197;&#30830;&#20445;&#21487;&#38752;&#30340;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#30340;&#37325;&#35201;&#24615;&#12290;&#20154;&#24037;&#26234;&#33021;&#22312;&#21307;&#30103;&#20013;&#24102;&#26469;&#20102;&#26356;&#22810;&#25361;&#25112;&#65292;&#24517;&#39035;&#35299;&#20915;&#20559;&#35265;&#12289;&#36879;&#26126;&#24230;&#12289;&#33258;&#20027;&#26435;&#12289;&#36131;&#20219;&#21644;&#38382;&#36131;&#21046;&#31561;&#38382;&#39064;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#35299;&#20915;&#21150;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.11530</link><description>&lt;p&gt;
&#36890;&#36807;&#20262;&#29702;&#21644;&#21746;&#23398;&#21407;&#21017;&#30830;&#20445;&#21487;&#20449;&#36182;&#30340;&#21307;&#30103;&#20154;&#24037;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
Ensuring Trustworthy Medical Artificial Intelligencethrough Ethical and Philosophical Principles. (arXiv:2304.11530v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#21307;&#30103;&#20445;&#20581;&#20013;&#30340;&#24212;&#29992;&#21644;&#32771;&#34385;&#20262;&#29702;&#21644;&#21746;&#23398;&#21407;&#21017;&#20197;&#30830;&#20445;&#21487;&#38752;&#30340;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#30340;&#37325;&#35201;&#24615;&#12290;&#20154;&#24037;&#26234;&#33021;&#22312;&#21307;&#30103;&#20013;&#24102;&#26469;&#20102;&#26356;&#22810;&#25361;&#25112;&#65292;&#24517;&#39035;&#35299;&#20915;&#20559;&#35265;&#12289;&#36879;&#26126;&#24230;&#12289;&#33258;&#20027;&#26435;&#12289;&#36131;&#20219;&#21644;&#38382;&#36131;&#21046;&#31561;&#38382;&#39064;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#21487;&#33021;&#30340;&#35299;&#20915;&#21150;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#22312;&#21307;&#30103;&#25252;&#29702;&#26041;&#38754;&#20855;&#26377;&#26497;&#22823;&#30340;&#28508;&#21147;&#65292;&#21487;&#20197;&#36890;&#36807;&#25552;&#39640;&#21307;&#30103;&#19987;&#23478;&#21644;&#24739;&#32773;&#30340;&#20307;&#39564;&#26469;&#24443;&#24213;&#25913;&#21464;&#20247;&#22810;&#21307;&#30103;&#25252;&#29702;&#12290;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35745;&#31639;&#26426;&#36741;&#21161;&#35786;&#26029;&#24037;&#20855;&#22914;&#26524;&#33021;&#22815;&#34920;&#29616;&#20986;&#33394;&#29978;&#33267;&#19982;&#20020;&#24202;&#19987;&#23478;&#30340;&#27700;&#24179;&#30456;&#24403;&#65292;&#23601;&#21487;&#20197;&#20135;&#29983;&#24040;&#22823;&#30340;&#25928;&#30410;&#12290;&#22240;&#27492;&#65292;&#21457;&#23637;&#20013;&#22269;&#23478;&#21487;&#20197;&#25552;&#20379;&#20808;&#36827;&#30340;&#21307;&#30103;&#25252;&#29702;&#26381;&#21153;&#65292;&#24182;&#35299;&#20915;&#32570;&#20047;&#19987;&#19994;&#21307;&#30103;&#20174;&#19994;&#32773;&#30340;&#38382;&#39064;&#12290;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#24037;&#20855;&#21487;&#20197;&#33410;&#30465;&#26102;&#38388;&#12289;&#36164;&#28304;&#21644;&#25972;&#20307;&#27835;&#30103;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#19982;&#20154;&#31867;&#30456;&#27604;&#65292;&#20154;&#24037;&#26234;&#33021;&#21487;&#20197;&#25581;&#31034;&#22823;&#37327;&#36755;&#20837;&#25968;&#25454;&#20013;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#29978;&#33267;&#21487;&#20197;&#20026;&#21307;&#23398;&#25552;&#20379;&#26032;&#30340;&#22522;&#20110;&#35777;&#25454;&#30340;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#22312;&#21307;&#30103;&#25252;&#29702;&#20013;&#25972;&#21512;&#20154;&#24037;&#26234;&#33021;&#20063;&#24102;&#26469;&#20102;&#20960;&#20010;&#20262;&#29702;&#21644;&#21746;&#23398;&#19978;&#30340;&#38382;&#39064;&#65292;&#22914;&#20559;&#35265;&#12289;&#36879;&#26126;&#24230;&#12289;&#33258;&#20027;&#26435;&#12289;&#36131;&#20219;&#21644;&#38382;&#36131;&#21046;&#65292;&#36825;&#20123;&#38382;&#39064;&#24517;&#39035;&#22312;&#23558;&#36825;&#20123;&#24037;&#20855;&#25972;&#21512;&#21040;&#20020;&#24202;&#29615;&#22659;&#20043;&#21069;&#24471;&#21040;&#35299;&#20915;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#21307;&#30103;&#25252;&#29702;&#20013;&#30340;&#26368;&#26032;&#24212;&#29992;&#20197;&#21450;&#32771;&#34385;&#20262;&#29702;&#21644;&#21746;&#23398;&#21407;&#21017;&#20197;&#30830;&#20445;&#21487;&#20449;&#36182;&#30340;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#19982;&#21307;&#30103;&#25252;&#29702;&#20013;&#30340;&#20154;&#24037;&#26234;&#33021;&#30456;&#20851;&#30340;&#21508;&#31181;&#25361;&#25112;&#65292;&#21253;&#25324;&#25968;&#25454;&#20559;&#35265;&#12289;&#36879;&#26126;&#24230;&#30340;&#38656;&#35201;&#12289;&#33258;&#20027;&#20915;&#31574;&#30340;&#38382;&#39064;&#20197;&#21450;&#38382;&#36131;&#21046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#30340;&#28508;&#22312;&#26041;&#26696;&#65292;&#21253;&#25324;&#30830;&#20445;&#36879;&#26126;&#24230;&#21644;&#38382;&#36131;&#21046;&#30340;&#26694;&#26550;&#20197;&#21450;&#25351;&#23548;&#20154;&#24037;&#26234;&#33021;&#24320;&#21457;&#32773;&#32771;&#34385;&#20262;&#29702;&#21407;&#21017;&#30340;&#25351;&#21335;&#12290;&#36890;&#36807;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#24182;&#23454;&#26045;&#20262;&#29702;&#21644;&#21746;&#23398;&#21407;&#21017;&#65292;&#25105;&#20204;&#21487;&#20197;&#30830;&#20445;&#24320;&#21457;&#20986;&#31526;&#21512;&#35786;&#25152;&#35774;&#32622;&#30340;&#21463;&#20449;&#20219;&#30340;&#21307;&#30103;&#20154;&#24037;&#26234;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence (AI) methods have great potential to revolutionize numerous medical care by enhancing the experience of medical experts and patients. AI based computer-assisted diagnosis tools can have a tremendous benefit if they can outperform or perform similarly to the level of a clinical expert. As a result, advanced healthcare services can be affordable in developing nations, and the problem of a lack of expert medical practitioners can be addressed. AI based tools can save time, resources, and overall cost for patient treatment. Furthermore, in contrast to humans, AI can uncover complex relations in the data from a large set of inputs and even lead to new evidence-based knowledge in medicine. However, integrating AI in healthcare raises several ethical and philosophical concerns, such as bias, transparency, autonomy, responsibility and accountability, which must be addressed before integrating such tools into clinical settings. In this article, we emphasize recent advanc
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27604;&#36739;&#22235;&#31181;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#21644;&#21160;&#24577;&#22240;&#23376;&#27169;&#22411;&#23545;&#32654;&#22269;GDP&#23395;&#24230;&#22686;&#38271;&#30340;&#39044;&#27979;&#34920;&#29616;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#24179;&#34913;&#32463;&#27982;&#22686;&#38271;&#26399;&#38388;&#65292;&#26356;&#38271;&#30340;&#36755;&#20837;&#24207;&#21015;&#33021;&#22815;&#23454;&#29616;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#20294;&#26159;&#36825;&#31181;&#25928;&#26524;&#20250;&#22312;&#19981;&#21040;&#20004;&#24180;&#30340;&#26102;&#38388;&#20869;&#28040;&#22833;&#12290;&#22312;&#32463;&#27982;&#21160;&#33633;&#26102;&#26399;&#65292;&#38271;&#26399;&#35760;&#24518;&#30340;&#25928;&#26524;&#21464;&#24471;&#26126;&#26174;&#12290;</title><link>http://arxiv.org/abs/2304.05805</link><description>&lt;p&gt;
&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22269;&#20869;&#29983;&#20135;&#24635;&#20540;&#65306;&#38271;&#26399;&#35760;&#24518;&#26377;&#22810;&#22823;&#30340;&#20316;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
GDP nowcasting with artificial neural networks: How much does long-term memory matter?. (arXiv:2304.05805v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05805
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27604;&#36739;&#22235;&#31181;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#21644;&#21160;&#24577;&#22240;&#23376;&#27169;&#22411;&#23545;&#32654;&#22269;GDP&#23395;&#24230;&#22686;&#38271;&#30340;&#39044;&#27979;&#34920;&#29616;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#24179;&#34913;&#32463;&#27982;&#22686;&#38271;&#26399;&#38388;&#65292;&#26356;&#38271;&#30340;&#36755;&#20837;&#24207;&#21015;&#33021;&#22815;&#23454;&#29616;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#20294;&#26159;&#36825;&#31181;&#25928;&#26524;&#20250;&#22312;&#19981;&#21040;&#20004;&#24180;&#30340;&#26102;&#38388;&#20869;&#28040;&#22833;&#12290;&#22312;&#32463;&#27982;&#21160;&#33633;&#26102;&#26399;&#65292;&#38271;&#26399;&#35760;&#24518;&#30340;&#25928;&#26524;&#21464;&#24471;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#19981;&#21516;&#30340;&#32479;&#35745;&#27169;&#22411;&#24212;&#29992;&#20110;&#32654;&#22269;&#32463;&#27982;&#23395;&#24230;&#22269;&#20869;&#29983;&#20135;&#24635;&#20540;&#65288;GDP&#65289;&#22686;&#38271;&#39044;&#27979;&#12290;&#20351;&#29992;&#27599;&#26376;&#30340;FRED-MD&#25968;&#25454;&#24211;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#21160;&#24577;&#22240;&#23376;&#27169;&#22411;&#65288;DFM&#65289;&#21644;&#22235;&#20010;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#30340;&#39044;&#27979;&#34920;&#29616;&#65306;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#12289;&#19968;&#32500;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;1D CNN&#65289;&#12289;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#65288;LSTM&#65289;&#21644;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;&#65288;GRU&#65289;&#12290;&#23454;&#35777;&#20998;&#26512;&#21576;&#29616;&#20102;&#20004;&#20010;&#19981;&#21516;&#35780;&#20272;&#21608;&#26399;&#30340;&#32467;&#26524;&#12290;&#31532;&#19968;&#20010;&#21608;&#26399;&#65288;2010&#24180;&#31532;1&#23395;&#24230;&#33267;2019&#24180;&#31532;4&#23395;&#24230;&#65289;&#20855;&#26377;&#24179;&#34913;&#30340;&#32463;&#27982;&#22686;&#38271;&#65292;&#32780;&#31532;&#20108;&#20010;&#21608;&#26399;&#65288;2010&#24180;&#31532;1&#23395;&#24230;&#33267;2022&#24180;&#31532;3&#23395;&#24230;&#65289;&#36824;&#21253;&#25324;COVID-19&#34928;&#36864;&#26399;&#38388;&#30340;&#26102;&#38388;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#26356;&#38271;&#30340;&#36755;&#20837;&#24207;&#21015;&#22312;&#24179;&#34913;&#32463;&#27982;&#22686;&#38271;&#26399;&#38388;&#33021;&#22815;&#23454;&#29616;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#22312;&#19968;&#20010;&#30456;&#23545;&#36739;&#20302;&#30340;&#38408;&#20540;&#20540;&#65288;&#32422;&#20845;&#20010;&#23395;&#24230;&#25110;&#21313;&#20843;&#20010;&#26376;&#65289;&#20197;&#21518;&#65292;&#36825;&#31181;&#25928;&#24212;&#20250;&#28040;&#22833;&#12290;&#22312;&#32463;&#27982;&#21160;&#33633;&#26399;&#65288;&#22914;COVID-19&#34928;&#36864;&#26399;&#38388;&#65289;&#65292;&#38271;&#26399;&#35760;&#24518;&#30340;&#25928;&#26524;&#20250;&#21464;&#24471;&#36739;&#20026;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;
In our study, we apply different statistical models to nowcast quarterly GDP growth for the US economy. Using the monthly FRED-MD database, we compare the nowcasting performance of the dynamic factor model (DFM) and four artificial neural networks (ANNs): the multilayer perceptron (MLP), the one-dimensional convolutional neural network (1D CNN), the long short-term memory network (LSTM), and the gated recurrent unit (GRU). The empirical analysis presents the results from two distinctively different evaluation periods. The first (2010:Q1 -- 2019:Q4) is characterized by balanced economic growth, while the second (2010:Q1 -- 2022:Q3) also includes periods of the COVID-19 recession. According to our results, longer input sequences result in more accurate nowcasts in periods of balanced economic growth. However, this effect ceases above a relatively low threshold value of around six quarters (eighteen months). During periods of economic turbulence (e.g., during the COVID-19 recession), long
&lt;/p&gt;</description></item></channel></rss>