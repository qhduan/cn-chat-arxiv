<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>ChatDBG&#26159;&#31532;&#19968;&#20010;AI-Powered&#35843;&#35797;&#21161;&#25163;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21040;&#20256;&#32479;&#35843;&#35797;&#22120;&#20013;&#65292;&#23454;&#29616;&#20102;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#23545;&#35805;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#12289;&#25191;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;</title><link>https://arxiv.org/abs/2403.16354</link><description>&lt;p&gt;
ChatDBG: &#19968;&#31181;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35843;&#35797;&#21161;&#25163;
&lt;/p&gt;
&lt;p&gt;
ChatDBG: An AI-Powered Debugging Assistant
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16354
&lt;/p&gt;
&lt;p&gt;
ChatDBG&#26159;&#31532;&#19968;&#20010;AI-Powered&#35843;&#35797;&#21161;&#25163;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21040;&#20256;&#32479;&#35843;&#35797;&#22120;&#20013;&#65292;&#23454;&#29616;&#20102;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#23545;&#35805;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#12289;&#25191;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;ChatDBG&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35843;&#35797;&#21161;&#25163;&#12290;ChatDBG&#38598;&#25104;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#65292;&#26174;&#33879;&#22686;&#24378;&#20102;&#20256;&#32479;&#35843;&#35797;&#22120;&#30340;&#21151;&#33021;&#21644;&#29992;&#25143;&#21451;&#22909;&#24615;&#12290;ChatDBG&#20801;&#35768;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#36827;&#34892;&#21327;&#20316;&#23545;&#35805;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#25552;&#20986;&#20851;&#20110;&#31243;&#24207;&#29366;&#24577;&#30340;&#22797;&#26434;&#38382;&#39064;&#65292;&#23545;&#23849;&#28291;&#25110;&#26029;&#35328;&#22833;&#36133;&#36827;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#35832;&#22914;&#8220;&#20026;&#20160;&#20040;x&#20026;&#31354;&#65311;&#8221;&#20043;&#31867;&#30340;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#26597;&#35810;&#65292;ChatDBG&#25480;&#20104;LLM&#33258;&#20027;&#26435;&#65292;&#36890;&#36807;&#21457;&#20986;&#21629;&#20196;&#26469;&#27983;&#35272;&#22534;&#26632;&#21644;&#26816;&#26597;&#31243;&#24207;&#29366;&#24577;&#36827;&#34892;&#35843;&#35797;&#65307;&#28982;&#21518;&#25253;&#21578;&#20854;&#21457;&#29616;&#24182;&#23558;&#25511;&#21046;&#26435;&#20132;&#36824;&#32473;&#31243;&#24207;&#21592;&#12290;&#25105;&#20204;&#30340;ChatDBG&#21407;&#22411;&#19982;&#26631;&#20934;&#35843;&#35797;&#22120;&#38598;&#25104;&#65292;&#21253;&#25324;LLDB&#12289;GDB&#21644;WinDBG&#29992;&#20110;&#26412;&#22320;&#20195;&#30721;&#20197;&#21450;&#29992;&#20110;Python&#30340;Pdb&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#20195;&#30721;&#38598;&#21512;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#20855;&#26377;&#24050;&#30693;&#38169;&#35823;&#30340;C/C++&#20195;&#30721;&#21644;&#19968;&#22871;Python&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#20581;&#24247;&#20445;&#20581;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;</title><link>https://arxiv.org/abs/2403.05720</link><description>&lt;p&gt;
&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05720
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#20581;&#24247;&#20445;&#20581;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#65288;BHC&#65289;&#25688;&#35201;&#26159;&#36890;&#36807;&#24635;&#32467;&#20020;&#24202;&#35760;&#24405;&#32780;&#29983;&#25104;&#30340;&#24120;&#35265;&#20020;&#24202;&#25991;&#20214;&#12290;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#21160;&#21270;&#23454;&#38469;&#20219;&#21153;&#26041;&#38754;&#23637;&#29616;&#20986;&#26174;&#33879;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;&#21307;&#30103;&#24212;&#29992;&#65288;&#22914;BHC&#21512;&#25104;&#65289;&#20013;&#30340;&#33021;&#21147;&#23578;&#26410;&#24471;&#21040;&#23637;&#31034;&#12290;&#20026;&#20102;&#20351;LLMs&#33021;&#22815;&#36866;&#24212;BHC&#21512;&#25104;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#21547;&#20174;MIMIC-IV&#35760;&#24405;&#20013;&#25552;&#21462;&#30340;&#32463;&#36807;&#39044;&#22788;&#29702;&#30340;&#25968;&#25454;&#38598;&#65292;&#23553;&#35013;&#20102;&#20020;&#24202;&#35760;&#24405;&#21644;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#65288;BHC&#65289;&#23545;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20004;&#20010;&#36890;&#29992;LLMs&#21644;&#19977;&#20010;&#21307;&#30103;&#39046;&#22495;&#36866;&#24212;&#30340;LLMs&#30340;&#24615;&#33021;&#65292;&#20197;&#25913;&#36827;&#20174;&#20020;&#24202;&#35760;&#24405;&#29983;&#25104;BHC&#12290;&#25105;&#20204;&#20351;&#29992;&#20020;&#24202;&#35760;&#24405;&#20316;&#20026;&#36755;&#20837;&#26469;&#29983;&#25104;BHC&#65292;&#37319;&#29992;&#22522;&#20110;&#25552;&#31034;&#30340;&#65288;&#20351;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#65289;&#21644;&#22522;&#20110;&#24494;&#35843;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#26469;&#24212;&#29992;&#20110;&#19977;&#20010;&#24320;&#28304;LLMs&#65288;Clinical-T5-Large&#65292;Llama2-13B&#65292;FLAN-UL2&#65289;&#21644;&#20004;&#20010;&#19987;&#26377;LLMs&#65288;GPT-3.5&#65292;GPT-4&#65289;&#12290;&#25105;&#20204;&#23450;&#37327;&#35780;&#20272;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05720v1 Announce Type: cross  Abstract: Brief hospital course (BHC) summaries are common clinical documents generated by summarizing clinical notes. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as BHC synthesis have not been shown. To enable the adaptation of LLMs for BHC synthesis, we introduce a novel benchmark consisting of a pre-processed dataset extracted from MIMIC-IV notes, encapsulating clinical note, and brief hospital course (BHC) pairs. We assess the performance of two general-purpose LLMs and three healthcare-adapted LLMs to improve BHC synthesis from clinical notes. Using clinical notes as input for generating BHCs, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to three open-source LLMs (Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5, GPT-4). We quantitatively evaluate the performa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#31995;&#32479;&#27010;&#36848;&#20102;&#19987;&#21033;&#39046;&#22495;&#30340;&#20219;&#21153;&#21644;&#26041;&#27861;&#65292;&#24378;&#35843;&#20102;&#35821;&#35328;&#22788;&#29702;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#36817;&#26399;&#20986;&#29616;&#30340;&#36890;&#29992;&#29983;&#25104;&#26041;&#27861;&#22312;&#19987;&#21033;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.04105</link><description>&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#25506;&#32034;&#19987;&#21033;&#39046;&#22495;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence Exploring the Patent Field
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31995;&#32479;&#27010;&#36848;&#20102;&#19987;&#21033;&#39046;&#22495;&#30340;&#20219;&#21153;&#21644;&#26041;&#27861;&#65292;&#24378;&#35843;&#20102;&#35821;&#35328;&#22788;&#29702;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#36817;&#26399;&#20986;&#29616;&#30340;&#36890;&#29992;&#29983;&#25104;&#26041;&#27861;&#22312;&#19987;&#21033;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04105v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#30340; &#25688;&#35201;&#65306;&#20808;&#36827;&#30340;&#35821;&#35328;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#25215;&#35834;&#22312;&#20197;&#21069;&#24191;&#27867;&#20381;&#36182;&#25163;&#24037;&#25805;&#20316;&#30340;&#19987;&#21033;&#21644;&#25216;&#26415;&#30693;&#35782;&#31649;&#29702;&#39046;&#22495;&#24102;&#26469;&#24040;&#22823;&#30340;&#25928;&#29575;&#25913;&#36827;&#12290;&#36825;&#20010;&#39046;&#22495;&#23637;&#31034;&#20102;&#22823;&#35268;&#27169;&#32780;&#22797;&#26434;&#30340;&#25968;&#25454;&#65292;&#20855;&#26377;&#38750;&#24120;&#20934;&#30830;&#30340;&#20869;&#23481;&#21644;&#35821;&#35328;&#34920;&#36798;&#36825;&#20123;&#20869;&#23481;&#12290;&#29305;&#21035;&#26159;&#65292;&#19987;&#21033;&#25991;&#26412;&#22312;&#21508;&#20010;&#26041;&#38754;&#21487;&#33021;&#19982;&#24179;&#20961;&#30340;&#25991;&#26412;&#26377;&#25152;&#19981;&#21516;&#65292;&#36825;&#24102;&#26469;&#20102;&#37325;&#22823;&#30340;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;&#26412;&#25991;&#31995;&#32479;&#27010;&#36848;&#20102;&#19982;&#19987;&#21033;&#26377;&#20851;&#30340;&#20219;&#21153;&#21644;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#20851;&#27880;&#19981;&#26029;&#28436;&#21464;&#21644;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;&#35821;&#35328;&#22788;&#29702;&#65292;&#23588;&#20854;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#21450;&#26368;&#36817;&#25512;&#21160;&#26222;&#36890;&#29983;&#25104;&#26041;&#27861;&#30340;&#25552;&#21319;&#65292;&#26377;&#26395;&#25104;&#20026;&#19987;&#21033;&#39046;&#22495;&#30340;&#21464;&#38761;&#32773;&#12290;&#19987;&#21033;&#25991;&#29486;&#20197;&#21450;&#22260;&#32469;&#19987;&#21033;&#30340;&#22522;&#20110;&#20107;&#23454;&#30340;&#35770;&#35777;&#31243;&#24207;&#20284;&#20046;&#20960;&#20046;&#26159;&#19968;&#20010;&#29702;&#24819;&#30340;&#20351;&#29992;&#26696;&#20363;&#12290;&#28982;&#32780;&#65292;&#19987;&#21033;&#28041;&#21450;&#35768;&#22810;&#29616;&#26377;&#27169;&#22411;&#24456;&#38590;&#22788;&#29702;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04105v1 Announce Type: new  Abstract: Advanced language-processing and machine-learning techniques promise massive efficiency improvements in the previously widely manual field of patent and technical knowledge management. This field presents large-scale and complex data with very precise contents and language representation of those contents. Particularly, patent texts can differ from mundane texts in various aspects, which entails significant opportunities and challenges. This paper presents a systematic overview of patent-related tasks and popular methodologies with a special focus on evolving and promising techniques. Language processing and particularly large language models as well as the recent boost of general generative methods promise to become game changers in the patent field. The patent literature and the fact-based argumentative procedures around patents appear almost as an ideal use case. However, patents entail a number of difficulties with which existing mod
&lt;/p&gt;</description></item><item><title>WildfireGPT&#26159;&#19968;&#20010;&#38024;&#23545;&#37326;&#28779;&#20998;&#26512;&#30340;&#23450;&#21046;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#20379;&#39046;&#22495;&#29305;&#23450;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#31185;&#23398;&#20934;&#30830;&#24615;&#65292;&#23558;&#29992;&#25143;&#26597;&#35810;&#36716;&#21270;&#20026;&#20851;&#20110;&#37326;&#28779;&#39118;&#38505;&#30340;&#21487;&#25805;&#20316;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.07877</link><description>&lt;p&gt;
WildfireGPT&#65306;&#38024;&#23545;&#37326;&#28779;&#20998;&#26512;&#30340;&#23450;&#21046;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
WildfireGPT: Tailored Large Language Model for Wildfire Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07877
&lt;/p&gt;
&lt;p&gt;
WildfireGPT&#26159;&#19968;&#20010;&#38024;&#23545;&#37326;&#28779;&#20998;&#26512;&#30340;&#23450;&#21046;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#20379;&#39046;&#22495;&#29305;&#23450;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#31185;&#23398;&#20934;&#30830;&#24615;&#65292;&#23558;&#29992;&#25143;&#26597;&#35810;&#36716;&#21270;&#20026;&#20851;&#20110;&#37326;&#28779;&#39118;&#38505;&#30340;&#21487;&#25805;&#20316;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#20195;&#34920;&#20102;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#39046;&#22495;&#30340;&#19968;&#31181;&#21464;&#38761;&#24615;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;LLMs&#26159;&#36890;&#29992;&#27169;&#22411;&#65292;&#35757;&#32451;&#20110;&#24191;&#27867;&#30340;&#25991;&#26412;&#35821;&#26009;&#24211;&#65292;&#24448;&#24448;&#38590;&#20197;&#25552;&#20379;&#29305;&#23450;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#23588;&#20854;&#26159;&#22312;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#30340;&#39046;&#22495;&#65292;&#27604;&#22914;&#37326;&#28779;&#32454;&#33410;&#22312;&#26356;&#24191;&#27867;&#30340;&#27668;&#20505;&#21464;&#21270;&#32972;&#26223;&#19979;&#12290;&#23545;&#20110;&#20851;&#27880;&#37326;&#28779;&#24377;&#24615;&#21644;&#36866;&#24212;&#24615;&#30340;&#20915;&#31574;&#32773;&#21644;&#25919;&#31574;&#21046;&#23450;&#32773;&#26469;&#35828;&#65292;&#33719;&#21462;&#19981;&#20165;&#20934;&#30830;&#32780;&#19988;&#39046;&#22495;&#29305;&#23450;&#30340;&#21709;&#24212;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#19981;&#26159;&#27867;&#27867;&#32780;&#35848;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;WildfireGPT&#65292;&#19968;&#20010;&#21407;&#22411;LLM&#20195;&#29702;&#65292;&#26088;&#22312;&#23558;&#29992;&#25143;&#26597;&#35810;&#36716;&#21270;&#20026;&#20851;&#20110;&#37326;&#28779;&#39118;&#38505;&#30340;&#21487;&#25805;&#20316;&#35265;&#35299;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20379;&#27668;&#20505;&#39044;&#27979;&#21644;&#31185;&#23398;&#25991;&#29486;&#31561;&#39069;&#22806;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#20016;&#23500;WildfireGPT&#65292;&#20197;&#30830;&#20445;&#20854;&#20449;&#24687;&#20855;&#26377;&#26102;&#25928;&#24615;&#12289;&#30456;&#20851;&#24615;&#21644;&#31185;&#23398;&#20934;&#30830;&#24615;&#12290;&#36825;&#20351;&#24471;WildfireGPT&#25104;&#20026;&#19968;&#20010;&#26377;&#25928;&#30340;&#24037;&#20855;&#26469;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent advancement of large language models (LLMs) represents a transformational capability at the frontier of artificial intelligence (AI) and machine learning (ML). However, LLMs are generalized models, trained on extensive text corpus, and often struggle to provide context-specific information, particularly in areas requiring specialized knowledge such as wildfire details within the broader context of climate change. For decision-makers and policymakers focused on wildfire resilience and adaptation, it is crucial to obtain responses that are not only precise but also domain-specific, rather than generic. To that end, we developed WildfireGPT, a prototype LLM agent designed to transform user queries into actionable insights on wildfire risks. We enrich WildfireGPT by providing additional context such as climate projections and scientific literature to ensure its information is current, relevant, and scientifically accurate. This enables WildfireGPT to be an effective tool for del
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#36848;&#20102;LLMs&#19982;&#20855;&#36523;&#26234;&#33021;&#22312;&#23548;&#33322;&#39046;&#22495;&#30340;&#20849;&#29983;&#20851;&#31995;&#65292;&#24182;&#35780;&#20272;&#20102;&#29616;&#26377;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#30340;&#20248;&#32570;&#28857;&#12290;</title><link>http://arxiv.org/abs/2311.00530</link><description>&lt;p&gt;
LLMs&#23545;&#20855;&#36523;&#23548;&#33322;&#30340;&#21457;&#23637;
&lt;/p&gt;
&lt;p&gt;
The Development of LLMs for Embodied Navigation. (arXiv:2311.00530v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;LLMs&#19982;&#20855;&#36523;&#26234;&#33021;&#22312;&#23548;&#33322;&#39046;&#22495;&#30340;&#20849;&#29983;&#20851;&#31995;&#65292;&#24182;&#35780;&#20272;&#20102;&#29616;&#26377;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#35832;&#22914;&#29983;&#25104;&#39044;&#35757;&#32451;&#21464;&#21387;&#22120;&#65288;GPT&#65289;&#20043;&#31867;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#20855;&#26377;&#28508;&#21147;&#12290;LLMs&#19982;&#20855;&#36523;&#26234;&#33021;&#30340;&#24212;&#29992;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#22312;&#20247;&#22810;&#24212;&#29992;&#20013;&#65292;&#23548;&#33322;&#20219;&#21153;&#23588;&#20026;&#24341;&#20154;&#27880;&#30446;&#65292;&#22240;&#20026;&#23427;&#20204;&#35201;&#27714;&#23545;&#29615;&#22659;&#26377;&#28145;&#20837;&#30340;&#29702;&#35299;&#21644;&#24555;&#36895;&#12289;&#20934;&#30830;&#30340;&#20915;&#31574;&#33021;&#21147;&#12290;LLMs&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#20854;&#24378;&#22823;&#30340;&#35821;&#35328;&#21644;&#22270;&#20687;&#22788;&#29702;&#33021;&#21147;&#65292;&#22686;&#24378;&#20855;&#36523;&#26234;&#33021;&#31995;&#32479;&#22312;&#29615;&#22659;&#24863;&#30693;&#21644;&#20915;&#31574;&#25903;&#25345;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#20840;&#38754;&#24635;&#32467;&#20102;LLMs&#19982;&#20855;&#36523;&#26234;&#33021;&#20043;&#38388;&#22312;&#23548;&#33322;&#26041;&#38754;&#30340;&#20849;&#29983;&#20851;&#31995;&#65292;&#23457;&#35270;&#20102;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12289;&#30740;&#31350;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#20102;&#29616;&#26377;&#30340;&#20855;&#36523;&#23548;&#33322;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#30340;&#20248;&#32570;&#28857;&#12290;&#26368;&#21518;&#65292;&#26412;&#25991;&#38416;&#26126;&#20102;LLMs&#22312;&#20855;&#36523;&#23548;&#33322;&#39046;&#22495;&#30340;&#21019;&#26032;&#21644;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, the rapid advancement of Large Language Models (LLMs) such as the Generative Pre-trained Transformer (GPT) has attracted increasing attention due to their potential in a variety of practical applications. The application of LLMs with Embodied Intelligence has emerged as a significant area of focus. Among the myriad applications of LLMs, navigation tasks are particularly noteworthy because they demand a deep understanding of the environment and quick, accurate decision-making. LLMs can augment embodied intelligence systems with sophisticated environmental perception and decision-making support, leveraging their robust language and image-processing capabilities. This article offers an exhaustive summary of the symbiosis between LLMs and embodied intelligence with a focus on navigation. It reviews state-of-the-art models, research methodologies, and assesses the advantages and disadvantages of existing embodied navigation models and datasets. Finally, the article elucidat
&lt;/p&gt;</description></item></channel></rss>