<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36890;&#36807;&#23545;&#39640;&#26031;&#36755;&#20837;&#19979;&#27880;&#24847;&#21147;&#24471;&#20998;&#31232;&#30095;&#24615;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#31232;&#30095;&#24615;&#30340;&#29305;&#24449;&#21450;&#20854;&#23545;&#35745;&#31639;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2404.02690</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#39640;&#26031;&#20998;&#24067;&#36755;&#20837;&#19979;&#33258;&#28982;&#31232;&#30095;
&lt;/p&gt;
&lt;p&gt;
Attention is Naturally Sparse with Gaussian Distributed Input
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02690
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#39640;&#26031;&#36755;&#20837;&#19979;&#27880;&#24847;&#21147;&#24471;&#20998;&#31232;&#30095;&#24615;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#31232;&#30095;&#24615;&#30340;&#29305;&#24449;&#21450;&#20854;&#23545;&#35745;&#31639;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35745;&#31639;&#24378;&#24230;&#26159;&#20851;&#38190;&#29942;&#39048;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;transformer&#26550;&#26500;&#20013;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;$O(n^2)$&#22797;&#26434;&#24230;&#12290;&#31232;&#30095;&#27880;&#24847;&#21147;&#20316;&#20026;&#19968;&#20010;&#20851;&#38190;&#21019;&#26032;&#24212;&#36816;&#32780;&#29983;&#65292;&#26088;&#22312;&#20943;&#23569;&#35745;&#31639;&#36127;&#33655;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#23545;LLMs&#20869;&#30340;&#27880;&#24847;&#21147;&#20998;&#25968;&#31232;&#30095;&#24615;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#26031;&#36755;&#20837;&#26694;&#26550;&#19979;&#12290;&#36890;&#36807;&#24314;&#31435;&#19968;&#32452;&#22522;&#30784;&#20551;&#35774;&#24182;&#37319;&#29992;&#19968;&#31181;&#31995;&#32479;&#30340;&#29702;&#35770;&#26041;&#27861;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#27880;&#24847;&#21147;&#20998;&#25968;&#31232;&#30095;&#24615;&#30340;&#20869;&#22312;&#29305;&#24449;&#21450;&#20854;&#23545;&#35745;&#31639;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#25552;&#20379;&#20102;&#23545;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#31232;&#30095;&#24615;&#34920;&#29616;&#24418;&#24335;&#30340;&#35814;&#32454;&#29702;&#35770;&#26816;&#26597;&#65292;&#25581;&#31034;&#20102;&#22312;&#35745;&#31639;&#33410;&#32422;&#21644;&#27169;&#22411;&#26377;&#25928;&#24615;&#20043;&#38388;&#28508;&#22312;&#26435;&#34913;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02690v1 Announce Type: cross  Abstract: The computational intensity of Large Language Models (LLMs) is a critical bottleneck, primarily due to the $O(n^2)$ complexity of the attention mechanism in transformer architectures. Addressing this, sparse attention emerges as a key innovation, aiming to reduce computational load while maintaining model performance. This study presents a rigorous theoretical analysis of the sparsity in attention scores within LLMs, particularly under the framework of Gaussian inputs. By establishing a set of foundational assumptions and employing a methodical theoretical approach, we unravel the intrinsic characteristics of attention score sparsity and its implications on computational efficiency. Our main contribution lies in providing a detailed theoretical examination of how sparsity manifests in attention mechanisms, offering insights into the potential trade-offs between computational savings and model effectiveness. This work not only advances 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#39038;&#20102;&#20540;&#24471;&#20449;&#36182;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;TAI&#65289;&#21644;&#20854;&#21508;&#31181;&#23450;&#20041;&#65292;&#20027;&#24352;&#19981;&#24212;&#23558;&#8220;&#36127;&#36131;&#20219;&#30340;&#8221;&#25110;&#8220;&#36947;&#24503;&#30340;&#8221;&#20154;&#24037;&#26234;&#33021;&#31561;&#26415;&#35821;&#35270;&#20026;TAI&#30340;&#26367;&#20195;&#65292;&#32780;&#26159;&#25552;&#20513;&#20197;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#39118;&#38505;&#12289;&#23433;&#20840;&#24615;&#12289;&#21487;&#35299;&#37322;&#24615;&#21644;&#21487;&#38752;&#24615;&#31561;&#20851;&#38190;&#23646;&#24615;&#20026;&#20013;&#24515;&#30340;&#26041;&#27861;&#65292;&#35748;&#35782;&#21040;&#22320;&#32536;&#25919;&#27835;&#21644;&#22320;&#29702;&#21407;&#22240;&#23548;&#33268;&#30340;&#20154;&#24037;&#26234;&#33021;&#30417;&#31649;&#24046;&#24322;&#23545;&#36328;&#22269;&#20844;&#21496;&#26500;&#25104;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.15457</link><description>&lt;p&gt;
&#36208;&#21521;&#20540;&#24471;&#20449;&#36182;&#30340;&#20154;&#24037;&#26234;&#33021;&#20043;&#26053;-&#31532;&#19968;&#37096;&#20998;&#65306;&#36861;&#27714;&#21153;&#23454;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
The Journey to Trustworthy AI- Part 1: Pursuit of Pragmatic Frameworks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#20540;&#24471;&#20449;&#36182;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;TAI&#65289;&#21644;&#20854;&#21508;&#31181;&#23450;&#20041;&#65292;&#20027;&#24352;&#19981;&#24212;&#23558;&#8220;&#36127;&#36131;&#20219;&#30340;&#8221;&#25110;&#8220;&#36947;&#24503;&#30340;&#8221;&#20154;&#24037;&#26234;&#33021;&#31561;&#26415;&#35821;&#35270;&#20026;TAI&#30340;&#26367;&#20195;&#65292;&#32780;&#26159;&#25552;&#20513;&#20197;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#39118;&#38505;&#12289;&#23433;&#20840;&#24615;&#12289;&#21487;&#35299;&#37322;&#24615;&#21644;&#21487;&#38752;&#24615;&#31561;&#20851;&#38190;&#23646;&#24615;&#20026;&#20013;&#24515;&#30340;&#26041;&#27861;&#65292;&#35748;&#35782;&#21040;&#22320;&#32536;&#25919;&#27835;&#21644;&#22320;&#29702;&#21407;&#22240;&#23548;&#33268;&#30340;&#20154;&#24037;&#26234;&#33021;&#30417;&#31649;&#24046;&#24322;&#23545;&#36328;&#22269;&#20844;&#21496;&#26500;&#25104;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#20540;&#24471;&#20449;&#36182;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;TAI&#65289;&#21450;&#20854;&#21508;&#31181;&#23450;&#20041;&#12290;&#32771;&#34385;&#21040;&#20219;&#20309;&#31038;&#20250;&#20013;&#23562;&#37325;&#30340;&#21407;&#21017;&#65292;TAI&#36890;&#24120;&#34987;&#19968;&#20123;&#23646;&#24615;&#25152;&#29305;&#24449;&#65292;&#20854;&#20013;&#19968;&#20123;&#23646;&#24615;&#24050;&#23548;&#33268;&#30417;&#31649;&#25110;&#24037;&#31243;&#32972;&#26223;&#19979;&#30340;&#28151;&#28102;&#12290;&#25105;&#20204;&#21453;&#23545;&#20351;&#29992;&#35832;&#22914;&#8220;&#36127;&#36131;&#20219;&#30340;&#8221;&#25110;&#8220;&#36947;&#24503;&#30340;&#8221;&#20154;&#24037;&#26234;&#33021;&#31561;&#26415;&#35821;&#26469;&#26367;&#20195;TAI&#12290;&#20026;&#20102;&#24110;&#21161;&#28548;&#28165;&#20219;&#20309;&#28151;&#20081;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#23427;&#20204;&#25243;&#22312;&#33041;&#21518;&#12290;&#37492;&#20110;TAI&#22266;&#26377;&#30340;&#20027;&#35266;&#24615;&#21644;&#22797;&#26434;&#24615;&#65292;&#24320;&#21457;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#34987;&#35748;&#20026;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20027;&#24352;&#37319;&#21462;&#20197;&#20844;&#24179;&#24615;&#12289;&#20559;&#35265;&#12289;&#39118;&#38505;&#12289;&#23433;&#20840;&#24615;&#12289;&#21487;&#35299;&#37322;&#24615;&#21644;&#21487;&#38752;&#24615;&#31561;&#20851;&#38190;&#23646;&#24615;&#20026;&#20013;&#24515;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23457;&#35270;&#20102;&#27491;&#22312;&#36827;&#34892;&#30340;&#30417;&#31649;&#29615;&#22659;&#65292;&#37325;&#28857;&#20851;&#27880;&#27431;&#30431;&#12289;&#20013;&#22269;&#21644;&#32654;&#22269;&#30340;&#20513;&#35758;&#12290;&#25105;&#20204;&#35748;&#35782;&#21040;&#65292;&#22522;&#20110;&#22320;&#32536;&#25919;&#27835;&#21644;&#22320;&#29702;&#21407;&#22240;&#32780;&#19981;&#21516;&#30340;&#20154;&#24037;&#26234;&#33021;&#30417;&#31649;&#23545;&#36328;&#22269;&#20844;&#21496;&#26500;&#25104;&#39069;&#22806;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15457v1 Announce Type: cross  Abstract: This paper reviews Trustworthy Artificial Intelligence (TAI) and its various definitions. Considering the principles respected in any society, TAI is often characterized by a few attributes, some of which have led to confusion in regulatory or engineering contexts. We argue against using terms such as Responsible or Ethical AI as substitutes for TAI. And to help clarify any confusion, we suggest leaving them behind. Given the subjectivity and complexity inherent in TAI, developing a universal framework is deemed infeasible. Instead, we advocate for approaches centered on addressing key attributes and properties such as fairness, bias, risk, security, explainability, and reliability. We examine the ongoing regulatory landscape, with a focus on initiatives in the EU, China, and the USA. We recognize that differences in AI regulations based on geopolitical and geographical reasons pose an additional challenge for multinational companies. 
&lt;/p&gt;</description></item><item><title>&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20010;&#24615;&#21270;&#36127;&#37319;&#26679;&#25216;&#26415;&#22312;&#22686;&#37327;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#26356;&#26032;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#26102;&#36935;&#21040;&#30340;&#36951;&#24536;&#28798;&#38590;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.03993</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#36127;&#37319;&#26679;&#22312;&#25512;&#33616;&#31995;&#32479;&#22686;&#37327;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Personalized Negative Reservoir for Incremental Learning in Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03993
&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20010;&#24615;&#21270;&#36127;&#37319;&#26679;&#25216;&#26415;&#22312;&#22686;&#37327;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#26356;&#26032;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#26102;&#36935;&#21040;&#30340;&#36951;&#24536;&#28798;&#38590;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#24050;&#25104;&#20026;&#22312;&#32447;&#24179;&#21488;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#27599;&#22825;&#35757;&#32451;&#25968;&#25454;&#37327;&#19981;&#26029;&#25193;&#22823;&#65292;&#29992;&#25143;&#20114;&#21160;&#27425;&#25968;&#19981;&#26029;&#22686;&#21152;&#12290;&#25506;&#32034;&#26356;&#22823;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#27169;&#22411;&#24050;&#25104;&#20026;&#25913;&#21892;&#29992;&#25143;&#20307;&#39564;&#30340;&#24517;&#35201;&#36861;&#27714;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#36827;&#23637;&#24102;&#26469;&#20102;&#26356;&#22823;&#30340;&#35745;&#31639;&#36127;&#25285;&#12290;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#65292;&#19968;&#26086;&#25512;&#33616;&#31995;&#32479;&#27169;&#22411;&#34987;&#35757;&#32451;&#21644;&#37096;&#32626;&#65292;&#36890;&#24120;&#38656;&#35201;&#39057;&#32321;&#26356;&#26032;&#20197;&#36866;&#24212;&#26032;&#30340;&#23458;&#25143;&#25968;&#25454;&#12290;&#32047;&#31215;&#36215;&#26469;&#65292;&#25968;&#25454;&#37327;&#30340;&#22686;&#21152;&#24517;&#23558;&#20351;&#24471;&#20174;&#22836;&#24320;&#22987;&#36827;&#34892;&#20840;&#37327;&#37325;&#35757;&#32451;&#21464;&#24471;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#12290;&#20165;&#20165;&#22312;&#26032;&#25968;&#25454;&#19978;&#36827;&#34892;&#31616;&#21333;&#24494;&#35843;&#20250;&#36935;&#21040;&#24050;&#34987;&#24191;&#27867;&#35760;&#24405;&#30340;&#36951;&#24536;&#28798;&#38590;&#38382;&#39064;&#12290;&#23613;&#31649;&#36127;&#37319;&#26679;&#22312;&#20351;&#29992;&#38544;&#24335;&#21453;&#39304;&#36827;&#34892;&#35757;&#32451;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#19968;&#37096;&#20998;&#65292;&#20294;&#30446;&#21069;&#24182;&#19981;&#23384;&#22312;&#19987;&#38376;&#38024;&#23545;&#22686;&#37327;&#23398;&#20064;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03993v1 Announce Type: cross  Abstract: Recommender systems have become an integral part of online platforms. Every day the volume of training data is expanding and the number of user interactions is constantly increasing. The exploration of larger and more expressive models has become a necessary pursuit to improve user experience. However, this progression carries with it an increased computational burden. In commercial settings, once a recommendation system model has been trained and deployed it typically needs to be updated frequently as new client data arrive. Cumulatively, the mounting volume of data is guaranteed to eventually make full batch retraining of the model from scratch computationally infeasible. Naively fine-tuning solely on the new data runs into the well-documented problem of catastrophic forgetting. Despite the fact that negative sampling is a crucial part of training with implicit feedback, no specialized technique exists that is tailored to the increme
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#22312;&#33521;&#25991;&#21644;&#20013;&#25991;&#30005;&#23376;&#37038;&#20214;&#25968;&#25454;&#38598;&#20013;&#29992;&#20110;&#22403;&#22334;&#37038;&#20214;&#26816;&#27979;&#30340;&#24615;&#33021;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.15537</link><description>&lt;p&gt;
&#35780;&#20272;ChatGPT&#29992;&#20110;&#22403;&#22334;&#37038;&#20214;&#26816;&#27979;&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Performance of ChatGPT for Spam Email Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15537
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#22312;&#33521;&#25991;&#21644;&#20013;&#25991;&#30005;&#23376;&#37038;&#20214;&#25968;&#25454;&#38598;&#20013;&#29992;&#20110;&#22403;&#22334;&#37038;&#20214;&#26816;&#27979;&#30340;&#24615;&#33021;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#37038;&#20214;&#32487;&#32493;&#26159;&#19987;&#19994;&#21644;&#21830;&#19994;&#39046;&#22495;&#20013;&#33267;&#20851;&#37325;&#35201;&#19988;&#24191;&#27867;&#20351;&#29992;&#30340;&#36890;&#20449;&#23186;&#20171;&#12290;&#28982;&#32780;&#65292;&#22403;&#22334;&#37038;&#20214;&#30340;&#26222;&#21450;&#32473;&#29992;&#25143;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#65292;&#25200;&#20081;&#20102;&#20182;&#20204;&#30340;&#26085;&#24120;&#24037;&#20316;&#24182;&#38477;&#20302;&#20102;&#29983;&#20135;&#29575;&#12290;&#22240;&#27492;&#65292;&#22522;&#20110;&#20869;&#23481;&#20934;&#30830;&#22320;&#35782;&#21035;&#21644;&#36807;&#28388;&#22403;&#22334;&#37038;&#20214;&#23545;&#32593;&#32476;&#23433;&#20840;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;ChatGPT&#65292;&#22312;&#35832;&#22914;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#31561;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#20854;&#22312;&#22403;&#22334;&#37038;&#20214;&#35782;&#21035;&#26041;&#38754;&#30340;&#28508;&#21147;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#30740;&#31350;&#23581;&#35797;&#35780;&#20272;ChatGPT&#22312;&#33521;&#25991;&#21644;&#20013;&#25991;&#30005;&#23376;&#37038;&#20214;&#25968;&#25454;&#38598;&#20013;&#29992;&#20110;&#22403;&#22334;&#37038;&#20214;&#35782;&#21035;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#21033;&#29992;ChatGPT&#36827;&#34892;&#22403;&#22334;&#37038;&#20214;&#26816;&#27979;&#65292;&#37319;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#38656;&#35201;&#25552;&#31034;&#35828;&#26126;&#21644;&#23569;&#37327;&#31034;&#33539;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15537v1 Announce Type: cross  Abstract: Email continues to be a pivotal and extensively utilized communication medium within professional and commercial domains. Nonetheless, the prevalence of spam emails poses a significant challenge for users, disrupting their daily routines and diminishing productivity. Consequently, accurately identifying and filtering spam based on content has become crucial for cybersecurity. Recent advancements in natural language processing, particularly with large language models like ChatGPT, have shown remarkable performance in tasks such as question answering and text generation. However, its potential in spam identification remains underexplored. To fill in the gap, this study attempts to evaluate ChatGPT's capabilities for spam identification in both English and Chinese email datasets. We employ ChatGPT for spam email detection using in-context learning, which requires a prompt instruction and a few demonstrations. We also investigate how the t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#21453;&#20107;&#23454;&#20998;&#26512;&#26694;&#26550;&#35780;&#20272;&#20102;&#21313;&#20010;&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#23545;&#22235;&#31181;&#32534;&#31243;&#27010;&#24565;&#30340;&#29702;&#35299;&#24773;&#20917;&#65292;&#21457;&#29616;&#24403;&#21069;&#27169;&#22411;&#32570;&#20047;&#23545;&#25968;&#25454;&#27969;&#21644;&#25511;&#21046;&#27969;&#31561;&#27010;&#24565;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.05980</link><description>&lt;p&gt;
&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#26159;&#21542;&#29702;&#35299;&#32534;&#31243;&#27010;&#24565;&#65311;&#19968;&#31181;&#40657;&#30418;&#26041;&#27861;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Do Large Code Models Understand Programming Concepts? A Black-box Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#21453;&#20107;&#23454;&#20998;&#26512;&#26694;&#26550;&#35780;&#20272;&#20102;&#21313;&#20010;&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#23545;&#22235;&#31181;&#32534;&#31243;&#27010;&#24565;&#30340;&#29702;&#35299;&#24773;&#20917;&#65292;&#21457;&#29616;&#24403;&#21069;&#27169;&#22411;&#32570;&#20047;&#23545;&#25968;&#25454;&#27969;&#21644;&#25511;&#21046;&#27969;&#31561;&#27010;&#24565;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#30340;&#25104;&#21151;&#20063;&#20351;&#20854;&#22312;&#20195;&#30721;&#29983;&#25104;&#21644;&#32534;&#30721;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#12290;&#34429;&#28982;&#26377;&#24456;&#22810;&#24037;&#20316;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#20195;&#30721;&#34917;&#20840;&#21644;&#32534;&#36753;&#31561;&#20219;&#21153;&#19978;&#30340;&#20986;&#33394;&#24615;&#33021;&#65292;&#20294;&#20026;&#20160;&#20040;&#23427;&#20204;&#33021;&#22815;&#25104;&#21151;&#36824;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#36890;&#36807;&#25506;&#32034;&#33258;&#22238;&#24402;&#27169;&#22411;&#23545;&#24213;&#23618;&#31243;&#24207;&#30340;&#36923;&#36753;&#32467;&#26500;&#29702;&#35299;&#31243;&#24230;&#65292;&#26469;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#32534;&#31243;&#27010;&#24565;&#35859;&#35789;&#30340;&#21453;&#20107;&#23454;&#20998;&#26512;&#65288;CACP&#65289;&#20316;&#20026;&#19968;&#31181;&#21453;&#20107;&#23454;&#27979;&#35797;&#26694;&#26550;&#65292;&#20197;&#35780;&#20272;&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#26159;&#21542;&#29702;&#35299;&#32534;&#31243;&#27010;&#24565;&#12290;&#21482;&#36890;&#36807;&#40657;&#30418;&#35775;&#38382;&#27169;&#22411;&#65292;&#25105;&#20204;&#20351;&#29992;CACP&#35780;&#20272;&#20102;&#21313;&#20010;&#27969;&#34892;&#30340;&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#23545;&#22235;&#20010;&#19981;&#21516;&#32534;&#31243;&#27010;&#24565;&#30340;&#29702;&#35299;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21069;&#27169;&#22411;&#32570;&#20047;&#23545;&#25968;&#25454;&#27969;&#21644;&#25511;&#21046;&#27969;&#31561;&#27010;&#24565;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models' success on text generation has also made them better at code generation and coding tasks. While a lot of work has demonstrated their remarkable performance on tasks such as code completion and editing, it is still unclear as to why. We help bridge this gap by exploring to what degree auto-regressive models understand the logical constructs of the underlying programs. We propose Counterfactual Analysis for Programming Concept Predicates (CACP) as a counterfactual testing framework to evaluate whether Large Code Models understand programming concepts. With only black-box access to the model, we use CACP to evaluate ten popular Large Code Models for four different programming concepts. Our findings suggest that current models lack understanding of concepts such as data flow and control flow.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#32508;&#36848;&#19981;&#21516;&#30340;&#26041;&#27861;&#20197;&#21450;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#25913;&#36827;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.04059</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Deep Learning for Multivariate Time Series Imputation: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#32508;&#36848;&#19981;&#21516;&#30340;&#26041;&#27861;&#20197;&#21450;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#25913;&#36827;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26222;&#36941;&#23384;&#22312;&#30340;&#32570;&#22833;&#20540;&#23548;&#33268;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#37096;&#20998;&#35266;&#27979;&#65292;&#30772;&#22351;&#20102;&#26102;&#38388;&#24207;&#21015;&#30340;&#23436;&#25972;&#24615;&#65292;&#38459;&#30861;&#20102;&#26377;&#25928;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#12290;&#26368;&#36817;&#65292;&#28145;&#24230;&#23398;&#20064;&#25554;&#34917;&#26041;&#27861;&#22312;&#25552;&#39640;&#25439;&#22351;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36136;&#37327;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#36827;&#32780;&#25552;&#39640;&#20102;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#23545;&#26368;&#36817;&#25552;&#20986;&#30340;&#28145;&#24230;&#23398;&#20064;&#25554;&#34917;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24378;&#35843;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#26469;&#36827;&#34892;&#20102;&#32467;&#26500;&#21270;&#30340;&#32508;&#36848;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#23454;&#35777;&#23454;&#39564;&#65292;&#30740;&#31350;&#20102;&#19981;&#21516;&#26041;&#27861;&#65292;&#24182;&#27604;&#36739;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#25913;&#36827;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;&#20102;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#26412;&#25991;&#30340;&#25152;&#26377;&#20195;&#30721;&#21644;&#37197;&#32622;&#65292;&#21253;&#25324;&#23450;&#26399;&#32500;&#25252;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#35770;&#25991;&#21015;&#34920;&#65292;&#21487;&#20197;&#22312;&#20197;&#19979;&#20301;&#32622;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ubiquitous missing values cause the multivariate time series data to be partially observed, destroying the integrity of time series and hindering the effective time series data analysis. Recently deep learning imputation methods have demonstrated remarkable success in elevating the quality of corrupted time series data, subsequently enhancing performance in downstream tasks. In this paper, we conduct a comprehensive survey on the recently proposed deep learning imputation methods. First, we propose a taxonomy for the reviewed methods, and then provide a structured review of these methods by highlighting their strengths and limitations. We also conduct empirical experiments to study different methods and compare their enhancement for downstream tasks. Finally, the open issues for future research on multivariate time series imputation are pointed out. All code and configurations of this work, including a regularly maintained multivariate time series imputation paper list, can be foun
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27169;&#25311;&#25509;&#25910;&#32773;&#34892;&#20026;&#30340;&#36125;&#21494;&#26031;&#21149;&#23548;&#38382;&#39064;&#20013;&#65292;&#21457;&#36865;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#26368;&#20248;&#28040;&#24687;&#31574;&#30053;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#26597;&#35810;&#31639;&#27861;&#65292;&#20197;&#20248;&#21270;&#20854;&#39044;&#26399;&#25928;&#29992;&#12290;</title><link>https://arxiv.org/abs/2311.18138</link><description>&lt;p&gt;
&#36890;&#36807;&#27169;&#25311;&#36827;&#34892;&#31639;&#27861;&#24615;&#21149;&#23548;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Persuasion Through Simulation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.18138
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27169;&#25311;&#25509;&#25910;&#32773;&#34892;&#20026;&#30340;&#36125;&#21494;&#26031;&#21149;&#23548;&#38382;&#39064;&#20013;&#65292;&#21457;&#36865;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#26368;&#20248;&#28040;&#24687;&#31574;&#30053;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#26597;&#35810;&#31639;&#27861;&#65292;&#20197;&#20248;&#21270;&#20854;&#39044;&#26399;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#36125;&#21494;&#26031;&#21149;&#23548;&#38382;&#39064;&#65292;&#20854;&#20013;&#21457;&#36865;&#32773;&#24076;&#26395;&#35828;&#26381;&#25509;&#25910;&#32773;&#37319;&#21462;&#20108;&#20803;&#34892;&#20026;&#65292;&#20363;&#22914;&#36141;&#20080;&#20135;&#21697;&#12290;&#21457;&#36865;&#32773;&#20102;&#35299;&#19990;&#30028;&#30340;&#65288;&#20108;&#20803;&#65289;&#29366;&#24577;&#65292;&#27604;&#22914;&#20135;&#21697;&#36136;&#37327;&#26159;&#39640;&#36824;&#26159;&#20302;&#65292;&#20294;&#26159;&#23545;&#25509;&#25910;&#32773;&#30340;&#20449;&#24565;&#21644;&#25928;&#29992;&#21482;&#26377;&#26377;&#38480;&#30340;&#20449;&#24687;&#12290;&#21463;&#21040;&#23458;&#25143;&#35843;&#26597;&#12289;&#29992;&#25143;&#30740;&#31350;&#21644;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20801;&#35768;&#21457;&#36865;&#32773;&#36890;&#36807;&#26597;&#35810;&#27169;&#25311;&#25509;&#25910;&#32773;&#30340;&#34892;&#20026;&#26469;&#20102;&#35299;&#26356;&#22810;&#20851;&#20110;&#25509;&#25910;&#32773;&#30340;&#20449;&#24687;&#12290;&#22312;&#22266;&#23450;&#25968;&#37327;&#30340;&#26597;&#35810;&#20043;&#21518;&#65292;&#21457;&#36865;&#32773;&#25215;&#35834;&#19968;&#20010;&#28040;&#24687;&#31574;&#30053;&#65292;&#25509;&#25910;&#32773;&#26681;&#25454;&#25910;&#21040;&#30340;&#28040;&#24687;&#26469;&#26368;&#22823;&#21270;&#22905;&#30340;&#39044;&#26399;&#25928;&#29992;&#26469;&#37319;&#21462;&#34892;&#21160;&#12290;&#25105;&#20204;&#23545;&#21457;&#36865;&#32773;&#22312;&#20219;&#20309;&#25509;&#25910;&#32773;&#31867;&#22411;&#20998;&#24067;&#19979;&#30340;&#26368;&#20248;&#28040;&#24687;&#31574;&#30053;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#26597;&#35810;&#31639;&#27861;&#65292;&#20248;&#21270;&#20102;&#36825;&#20010;&#36125;&#21494;&#26031;&#21149;&#23548;&#28216;&#25103;&#20013;&#21457;&#36865;&#32773;&#30340;&#39044;&#26399;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.18138v2 Announce Type: replace-cross Abstract: We study a Bayesian persuasion problem where a sender wants to persuade a receiver to take a binary action, such as purchasing a product. The sender is informed about the (binary) state of the world, such as whether the quality of the product is high or low, but only has limited information about the receiver's beliefs and utilities. Motivated by customer surveys, user studies, and recent advances in generative AI, we allow the sender to learn more about the receiver by querying an oracle that simulates the receiver's behavior. After a fixed number of queries, the sender commits to a messaging policy and the receiver takes the action that maximizes her expected utility given the message she receives. We characterize the sender's optimal messaging policy given any distribution over receiver types. We then design a polynomial-time querying algorithm that optimizes the sender's expected utility in this Bayesian persuasion game. We 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.18304</link><description>&lt;p&gt;
&#23398;&#20064;&#38750;&#31283;&#24577;&#26465;&#20214;&#19979;&#30340;&#31283;&#23450;&#24615;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38750;&#31283;&#23450;&#29615;&#22659;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#26469;&#36873;&#25321;&#19968;&#20010;&#22238;&#28335;&#31383;&#21475;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#65292;&#21516;&#26102;&#23558;&#32047;&#31215;&#20559;&#24046;&#20445;&#25345;&#22312;&#19982;&#38543;&#26426;&#35823;&#24046;&#30456;&#23545;&#21487;&#25509;&#21463;&#30340;&#33539;&#22260;&#20869;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#26410;&#30693;&#38750;&#31283;&#23450;&#24615;&#30340;&#36866;&#24212;&#24615;&#12290;&#24403;&#20154;&#21475;&#25439;&#22833;&#20989;&#25968;&#24378;&#20984;&#25110;&#20165;&#28385;&#36275;Lipschitz&#26465;&#20214;&#26102;&#65292;&#36951;&#25022;&#30028;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#65292;&#20165;&#21463;&#23545;&#25968;&#22240;&#23376;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26680;&#24515;&#26159;&#20004;&#20010;&#26032;&#39062;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#20989;&#25968;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#23558;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#20026;&#20934;&#31283;&#24577;&#29255;&#27573;&#30340;&#20998;&#21106;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#28151;&#20081;&#29615;&#22659;&#20013;&#25235;&#21462;&#24050;&#37319;&#25688;&#30340;&#35199;&#32418;&#26623;&#31319;&#26524;&#30340;&#35270;&#35273;&#24341;&#23548;&#26426;&#22120;&#20154;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#21033;&#29992;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35270;&#35273;&#31995;&#32479;&#26469;&#35782;&#21035;&#31319;&#26524;&#24182;&#30830;&#23450;&#36866;&#21512;&#25235;&#21462;&#30340;&#20301;&#32622;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#26469;&#25490;&#24207;&#25235;&#21462;&#23039;&#21183;&#65292;&#24182;&#23454;&#29616;&#26080;&#35302;&#35273;&#20256;&#24863;&#22120;&#25110;&#20960;&#20309;&#27169;&#22411;&#30340;&#22841;&#25345;&#25235;&#21462;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#31995;&#32479;&#20855;&#26377;100%&#30340;&#28165;&#29702;&#29575;&#21644;93%&#30340;&#19968;&#27425;&#24615;&#25104;&#21151;&#25235;&#21462;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.17170</link><description>&lt;p&gt;
&#29992;&#20110;&#22312;&#28151;&#20081;&#29615;&#22659;&#20013;&#25235;&#21462;&#24050;&#37319;&#25688;&#30340;&#35199;&#32418;&#26623;&#31319;&#26524;&#30340;&#35270;&#35273;&#24341;&#23548;&#26426;&#22120;&#20154;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Vision-Guided Robotic System for Grasping Harvested Tomato Trusses in Cluttered Environments. (arXiv:2309.17170v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17170
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#28151;&#20081;&#29615;&#22659;&#20013;&#25235;&#21462;&#24050;&#37319;&#25688;&#30340;&#35199;&#32418;&#26623;&#31319;&#26524;&#30340;&#35270;&#35273;&#24341;&#23548;&#26426;&#22120;&#20154;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#21033;&#29992;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35270;&#35273;&#31995;&#32479;&#26469;&#35782;&#21035;&#31319;&#26524;&#24182;&#30830;&#23450;&#36866;&#21512;&#25235;&#21462;&#30340;&#20301;&#32622;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#26469;&#25490;&#24207;&#25235;&#21462;&#23039;&#21183;&#65292;&#24182;&#23454;&#29616;&#26080;&#35302;&#35273;&#20256;&#24863;&#22120;&#25110;&#20960;&#20309;&#27169;&#22411;&#30340;&#22841;&#25345;&#25235;&#21462;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#31995;&#32479;&#20855;&#26377;100%&#30340;&#28165;&#29702;&#29575;&#21644;93%&#30340;&#19968;&#27425;&#24615;&#25104;&#21151;&#25235;&#21462;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#23545;&#20110;&#35199;&#32418;&#26623;&#30340;&#31216;&#37325;&#21644;&#21253;&#35013;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#24037;&#25805;&#20316;&#12290;&#33258;&#21160;&#21270;&#30340;&#20027;&#35201;&#38556;&#30861;&#22312;&#20110;&#24320;&#21457;&#19968;&#20010;&#21487;&#38752;&#30340;&#29992;&#20110;&#24050;&#37319;&#25688;&#30340;&#31319;&#26524;&#30340;&#26426;&#22120;&#20154;&#25235;&#21462;&#31995;&#32479;&#30340;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#25235;&#21462;&#22534;&#25918;&#22312;&#35013;&#31665;&#20013;&#30340;&#31319;&#26524;&#65292;&#36825;&#26159;&#23427;&#20204;&#22312;&#37319;&#25688;&#21518;&#24120;&#35265;&#30340;&#23384;&#20648;&#21644;&#36816;&#36755;&#26041;&#24335;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35270;&#35273;&#31995;&#32479;&#65292;&#39318;&#20808;&#35782;&#21035;&#20986;&#35013;&#31665;&#20013;&#30340;&#21333;&#20010;&#31319;&#26524;&#65292;&#28982;&#21518;&#30830;&#23450;&#33550;&#37096;&#30340;&#36866;&#21512;&#25235;&#21462;&#30340;&#20301;&#32622;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20855;&#26377;&#22312;&#32447;&#23398;&#20064;&#33021;&#21147;&#30340;&#25235;&#21462;&#23039;&#21183;&#25490;&#24207;&#31639;&#27861;&#12290;&#22312;&#36873;&#25321;&#20102;&#26368;&#26377;&#21069;&#26223;&#30340;&#25235;&#21462;&#23039;&#21183;&#20043;&#21518;&#65292;&#26426;&#22120;&#20154;&#25191;&#34892;&#19968;&#31181;&#26080;&#38656;&#35302;&#35273;&#20256;&#24863;&#22120;&#25110;&#20960;&#20309;&#27169;&#22411;&#30340;&#22841;&#25345;&#25235;&#21462;&#12290;&#23454;&#39564;&#23460;&#23454;&#39564;&#35777;&#26126;&#65292;&#37197;&#22791;&#20102;&#19968;&#20010;&#25163;&#30524;&#19968;&#20307;&#30340;RGB-D&#30456;&#26426;&#30340;&#26426;&#22120;&#20154;&#25805;&#32437;&#22120;&#20174;&#22534;&#20013;&#25441;&#36215;&#25152;&#26377;&#30340;&#31319;&#26524;&#30340;&#28165;&#29702;&#29575;&#36798;&#21040;100%&#12290;93%&#30340;&#31319;&#26524;&#22312;&#31532;&#19968;&#27425;&#23581;&#35797;&#26102;&#25104;&#21151;&#25235;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
Currently, truss tomato weighing and packaging require significant manual work. The main obstacle to automation lies in the difficulty of developing a reliable robotic grasping system for already harvested trusses. We propose a method to grasp trusses that are stacked in a crate with considerable clutter, which is how they are commonly stored and transported after harvest. The method consists of a deep learning-based vision system to first identify the individual trusses in the crate and then determine a suitable grasping location on the stem. To this end, we have introduced a grasp pose ranking algorithm with online learning capabilities. After selecting the most promising grasp pose, the robot executes a pinch grasp without needing touch sensors or geometric models. Lab experiments with a robotic manipulator equipped with an eye-in-hand RGB-D camera showed a 100% clearance rate when tasked to pick all trusses from a pile. 93% of the trusses were successfully grasped on the first try,
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#26088;&#22312;&#25552;&#39640;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#65292;&#36890;&#36807;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#30340;&#21512;&#20316;&#26469;&#35299;&#20915;&#25512;&#29702;&#35884;&#35823;&#12290;</title><link>http://arxiv.org/abs/2308.11914</link><description>&lt;p&gt;
&#36808;&#21521;&#22240;&#26524;GPT&#65306;&#36890;&#36807;&#20419;&#36827;LLMs&#20013;&#30340;&#22240;&#26524;&#19968;&#33268;&#24615;&#65292;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#30340;&#26041;&#27861;&#23454;&#29616;&#24544;&#23454;&#30340;&#30693;&#35782;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs. (arXiv:2308.11914v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11914
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#26088;&#22312;&#25552;&#39640;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#65292;&#36890;&#36807;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#30340;&#21512;&#20316;&#26469;&#35299;&#20915;&#25512;&#29702;&#35884;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;LLMs&#30340;&#21457;&#23637;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#20173;&#28982;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#30001;&#20110;&#30693;&#35782;&#22238;&#24518;&#21644;&#25512;&#29702;&#30340;&#33030;&#24369;&#24615;&#24341;&#36215;&#30340;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#36890;&#36807;&#40723;&#21169;LLMs&#33258;&#20027;&#35745;&#21010;&#21644;&#35299;&#20915;&#38382;&#39064;&#25110;&#24191;&#27867;&#37319;&#26679;&#25512;&#29702;&#38142;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#26410;&#33021;&#35299;&#20915;&#27010;&#24565;&#21644;&#25512;&#29702;&#35884;&#35823;&#12290;&#20026;&#20102;&#20943;&#23569;&#25512;&#29702;&#35884;&#35823;&#65292;&#25105;&#20204;&#20174;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#20013;&#24471;&#21040;&#21551;&#21457;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#22686;&#21152;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#22810;&#20010;&#26234;&#33021;&#20307;&#65288;&#21363;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#65289;&#22312;&#25512;&#29702;&#21644;&#19968;&#33268;&#24615;&#33539;&#24335;&#20013;&#21327;&#20316;&#24037;&#20316;&#65292;&#20197;&#25552;&#39640;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#12290;&#25512;&#29702;&#22120;&#19987;&#27880;&#20110;&#25552;&#20379;&#20855;&#26377;&#20154;&#31867;&#22240;&#26524;&#20851;&#31995;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#24320;&#25918;&#39046;&#22495;&#30340;&#38382;&#39064;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22240;&#26524;&#35780;&#20272;&#22120;&#20195;&#29702;&#26816;&#26597;&#35299;&#20915;&#26041;&#26696;&#20013;&#30340;&#31572;&#26696;&#26159;&#21542;&#20174;&#38382;&#39064;&#20013;&#22240;&#26524;&#25512;&#23548;&#20986;&#26469;&#65292;&#21453;&#20043;&#20134;&#28982;&#65292;&#24182;&#29992;&#19968;&#20010;&#21453;&#20107;&#23454;&#30340;&#31572;&#26696;&#26469;&#26367;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite advancements in LLMs, knowledge-based reasoning remains a longstanding issue due to the fragility of knowledge recall and inference. Existing methods primarily encourage LLMs to autonomously plan and solve problems or to extensively sample reasoning chains without addressing the conceptual and inferential fallacies. Attempting to alleviate inferential fallacies and drawing inspiration from multi-agent collaboration, we present a framework to increase faithfulness and causality for knowledge-based reasoning. Specifically, we propose to employ multiple intelligent agents (i.e., reasoner and causal evaluator) to work collaboratively in a reasoning-and-consensus paradigm for elevated reasoning faithfulness. The reasoners focus on providing solutions with human-like causality to solve open-domain problems. On the other hand, the causal evaluator agent scrutinizes if the answer in a solution is causally deducible from the question and vice versa, with a counterfactual answer replacin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#20449;&#24687;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#39044;&#35757;&#32451;&#22270;&#21367;&#31215;&#32593;&#32476;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#30340;&#22522;&#22240;&#34920;&#36798;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#20272;&#35745;&#22120;&#26469;&#39640;&#25928;&#20272;&#35745;&#36793;&#32536;&#24178;&#25200;&#25928;&#24212;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.00116</link><description>&lt;p&gt;
&#21033;&#29992;&#21464;&#20998;&#22240;&#26524;&#25512;&#26029;&#21644;&#31934;&#32454;&#20851;&#31995;&#20449;&#24687;&#39044;&#27979;&#32454;&#32990;&#21709;&#24212;
&lt;/p&gt;
&lt;p&gt;
Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information. (arXiv:2210.00116v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00116
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#20449;&#24687;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#39044;&#35757;&#32451;&#22270;&#21367;&#31215;&#32593;&#32476;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#30340;&#22522;&#22240;&#34920;&#36798;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#20272;&#35745;&#22120;&#26469;&#39640;&#25928;&#20272;&#35745;&#36793;&#32536;&#24178;&#25200;&#25928;&#24212;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#32454;&#32990;&#22312;&#24178;&#25200;&#19979;&#30340;&#21709;&#24212;&#21487;&#33021;&#20026;&#33647;&#29289;&#30740;&#21457;&#21644;&#20010;&#24615;&#21270;&#27835;&#30103;&#24102;&#26469;&#37325;&#35201;&#22909;&#22788;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#21464;&#20998;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#65288;&#21363;&#32454;&#32990;&#26410;&#30495;&#23454;&#25509;&#25910;&#30340;&#24178;&#25200;&#65289;&#30340;&#22522;&#22240;&#34920;&#36798;&#65292;&#21033;&#29992;&#20195;&#34920;&#29983;&#29289;&#23398;&#30693;&#35782;&#30340;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#65288;GRN&#65289;&#20449;&#24687;&#26469;&#36741;&#21161;&#20010;&#24615;&#21270;&#32454;&#32990;&#21709;&#24212;&#39044;&#27979;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#25968;&#25454;&#33258;&#36866;&#24212;GRN&#24320;&#21457;&#20102;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#29992;&#20110;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#39044;&#35757;&#32451;&#65292;&#22312;&#27169;&#22411;&#24615;&#33021;&#19978;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#22522;&#22240;&#20851;&#31995;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advanta
&lt;/p&gt;</description></item></channel></rss>