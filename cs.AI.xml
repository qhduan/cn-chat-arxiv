<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2309.14073</link><description>&lt;p&gt;
&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65306;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35745;&#31639;&#36825;&#20010;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20195;&#25968;&#35745;&#31639;&#31283;&#23450;&#27169;&#22411;&#28385;&#36275;&#32473;&#23450;&#30340;&#38480;&#21046;&#26465;&#20214;&#65292;&#21516;&#26102;&#27809;&#26377;&#20351;&#29992;&#31526;&#21495;ASP&#25110;SAT&#27714;&#35299;&#22120;&#65292;&#20026;&#21152;&#36895;&#36890;&#36807;&#24182;&#34892;&#25216;&#26415;&#25552;&#20379;&#20102;&#21487;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.06821</link><description>&lt;p&gt;
&#36808;&#21521;&#31471;&#21040;&#31471;ASP&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Towards end-to-end ASP computation. (arXiv:2306.06821v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06821
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20195;&#25968;&#35745;&#31639;&#31283;&#23450;&#27169;&#22411;&#28385;&#36275;&#32473;&#23450;&#30340;&#38480;&#21046;&#26465;&#20214;&#65292;&#21516;&#26102;&#27809;&#26377;&#20351;&#29992;&#31526;&#21495;ASP&#25110;SAT&#27714;&#35299;&#22120;&#65292;&#20026;&#21152;&#36895;&#36890;&#36807;&#24182;&#34892;&#25216;&#26415;&#25552;&#20379;&#20102;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#29992;&#32447;&#24615;&#20195;&#25968;&#35745;&#31639;&#28385;&#36275;&#32473;&#23450;&#38480;&#21046;&#26465;&#20214;&#30340;&#31283;&#23450;&#27169;&#22411;&#65292;&#20197;&#21450;ASP&#30340;&#35745;&#31639;&#12290;&#19968;&#31181;&#26500;&#36896;&#25104;&#30697;&#38453;&#21270;&#27491;&#24120;&#36923;&#36753;&#31243;&#24207;&#12289;Lin-Zhao&#23450;&#29702;&#20013;&#30340;&#24490;&#29615;&#20844;&#24335;&#21644;&#38480;&#21046;&#26465;&#20214;&#30340;&#20195;&#20215;&#20989;&#25968;&#30340;&#25968;&#20540;&#26368;&#23567;&#21270;&#30340;&#21521;&#37327;&#31354;&#38388;&#30452;&#25509;&#23454;&#29616;Lin-Zhao&#23450;&#29702;&#30340;&#24605;&#36335;&#65292;&#22240;&#27492;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#27809;&#26377;&#20351;&#29992;&#31526;&#21495;ASP&#25110;SAT&#27714;&#35299;&#22120;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#29992;&#20110;&#32553;&#23567;&#31243;&#24207;&#22823;&#23567;&#30340;&#39044;&#35745;&#31639;&#21644;&#29992;&#20110;&#20943;&#23569;&#35745;&#31639;&#38590;&#24230;&#30340;&#24490;&#29615;&#20844;&#24335;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#25105;&#20204;&#29992;&#32534;&#31243;&#31034;&#20363;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#27979;&#35797;&#65292;&#21253;&#25324;&#19977;&#33394;&#28034;&#33394;&#38382;&#39064;&#21644;&#21704;&#23494;&#39039;&#29615;&#38382;&#39064;&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#32431;&#31929;&#25968;&#20540;&#26041;&#27861;&#65292;&#24182;&#19988;&#21482;&#21253;&#21547;&#21521;&#37327;/&#30697;&#38453;&#25805;&#20316;&#65292;&#22240;&#27492;&#21487;&#20197;&#36890;&#36807;&#24182;&#34892;&#25216;&#26415;&#65288;&#20363;&#22914;&#22810;&#26680;&#21644;GPU&#65289;&#36827;&#34892;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an end-to-end approach for answer set programming (ASP) and linear algebraically compute stable models satisfying given constraints. The idea is to implement Lin-Zhao's theorem \cite{Lin04} together with constraints directly in vector spaces as numerical minimization of a cost function constructed from a matricized normal logic program, loop formulas in Lin-Zhao's theorem and constraints, thereby no use of symbolic ASP or SAT solvers involved in our approach. We also propose precomputation that shrinks the program size and heuristics for loop formulas to reduce computational difficulty. We empirically test our approach with programming examples including the 3-coloring and Hamiltonian cycle problems. As our approach is purely numerical and only contains vector/matrix operations, acceleration by parallel technologies such as many-cores and GPUs is expected.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;Q&#32593;&#32476;&#23398;&#20064;&#21551;&#21457;&#24335;&#20989;&#25968;&#65292;&#36890;&#36807;&#21482;&#36827;&#34892;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#35745;&#31639;&#30456;&#37051;&#33410;&#28857;&#30340;&#36716;&#31227;&#25104;&#26412;&#21644;&#21551;&#21457;&#24335;&#20540;&#20043;&#21644;&#65292;&#24182;&#22312;&#19981;&#26174;&#24335;&#29983;&#25104;&#36825;&#20123;&#23376;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#25351;&#23548;&#25628;&#32034;&#30340;Q*&#25628;&#32034;&#31639;&#27861;&#65292;&#20197;&#22823;&#24133;&#20943;&#23569;&#35745;&#31639;&#26102;&#38388;&#12290;&#22312;&#39764;&#26041;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#35299;&#20915;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2102.04518</link><description>&lt;p&gt;
&#19981;&#25193;&#23637;&#30340;A*&#25628;&#32034;&#65306;&#29992;&#28145;&#24230;Q&#32593;&#32476;&#23398;&#20064;&#21551;&#21457;&#24335;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks. (arXiv:2102.04518v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.04518
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;Q&#32593;&#32476;&#23398;&#20064;&#21551;&#21457;&#24335;&#20989;&#25968;&#65292;&#36890;&#36807;&#21482;&#36827;&#34892;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#35745;&#31639;&#30456;&#37051;&#33410;&#28857;&#30340;&#36716;&#31227;&#25104;&#26412;&#21644;&#21551;&#21457;&#24335;&#20540;&#20043;&#21644;&#65292;&#24182;&#22312;&#19981;&#26174;&#24335;&#29983;&#25104;&#36825;&#20123;&#23376;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#25351;&#23548;&#25628;&#32034;&#30340;Q*&#25628;&#32034;&#31639;&#27861;&#65292;&#20197;&#22823;&#24133;&#20943;&#23569;&#35745;&#31639;&#26102;&#38388;&#12290;&#22312;&#39764;&#26041;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#35299;&#20915;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#22320;&#20351;&#29992; A* &#25628;&#32034;&#35299;&#20915;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#38382;&#39064;&#23545;&#20110;&#20154;&#24037;&#26234;&#33021;&#31038;&#21306;&#20960;&#21313;&#24180;&#26469;&#19968;&#30452;&#38750;&#24120;&#37325;&#35201;&#12290;&#36825;&#26159;&#22240;&#20026; A* &#25628;&#32034;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#38656;&#27714;&#38543;&#30528;&#21160;&#20316;&#31354;&#38388;&#30340;&#22823;&#23567;&#21576;&#32447;&#24615;&#22686;&#38271;&#12290;&#24403; A* &#25628;&#32034;&#20351;&#29992;&#35745;&#31639;&#20195;&#20215;&#39640;&#26114;&#30340;&#20989;&#25968;&#36924;&#36817;&#22120;&#65288;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#23398;&#20064;&#21551;&#21457;&#24335;&#20989;&#25968;&#26102;&#65292;&#36825;&#31181;&#36127;&#25285;&#21464;&#24471;&#26356;&#21152;&#26126;&#26174;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102; Q* &#25628;&#32034;&#65292;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230; Q &#32593;&#32476;&#24341;&#23548;&#25628;&#32034;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#20197;&#21033;&#29992;&#19968;&#20010;&#20107;&#23454;&#65292;&#21363;&#22312;&#19981;&#26174;&#24335;&#29983;&#25104;&#36825;&#20123;&#23376;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#33410;&#28857;&#30340;&#23376;&#33410;&#28857;&#30340;&#36716;&#31227;&#25104;&#26412;&#21644;&#21551;&#21457;&#24335;&#20540;&#20043;&#21644;&#21487;&#20197;&#36890;&#36807;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#35745;&#31639;&#12290;&#36825;&#26174;&#30528;&#38477;&#20302;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#19988;&#27599;&#27425;&#36845;&#20195;&#21482;&#38656;&#35201;&#29983;&#25104;&#19968;&#20010;&#33410;&#28857;&#12290;&#25105;&#20204;&#20351;&#29992; Q* &#25628;&#32034;&#26469;&#35299;&#20915;&#39764;&#26041;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#20204;&#34920;&#31034;&#20026;&#19968;&#20010;&#21253;&#21547; 1872 &#20010;&#20803;&#21160;&#20316;&#30340;&#22823;&#21160;&#20316;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficiently solving problems with large action spaces using A* search has been of importance to the artificial intelligence community for decades. This is because the computation and memory requirements of A* search grow linearly with the size of the action space. This burden becomes even more apparent when A* search uses a heuristic function learned by computationally expensive function approximators, such as deep neural networks. To address this problem, we introduce Q* search, a search algorithm that uses deep Q-networks to guide search in order to take advantage of the fact that the sum of the transition costs and heuristic values of the children of a node can be computed with a single forward pass through a deep Q-network without explicitly generating those children. This significantly reduces computation time and requires only one node to be generated per iteration. We use Q* search to solve the Rubik's cube when formulated with a large action space that includes 1872 meta-action
&lt;/p&gt;</description></item></channel></rss>