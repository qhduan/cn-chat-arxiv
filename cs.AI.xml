<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>ALTO&#26159;&#19968;&#20010;&#32593;&#32476;&#32534;&#25490;&#22120;&#65292;&#38024;&#23545;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#26426;&#20250;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.04311</link><description>&lt;p&gt;
ALTO&#65306;&#19968;&#31181;&#29992;&#20110;&#22797;&#21512;AI&#31995;&#32479;&#30340;&#39640;&#25928;&#32593;&#32476;&#32534;&#25490;&#22120;
&lt;/p&gt;
&lt;p&gt;
ALTO: An Efficient Network Orchestrator for Compound AI Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04311
&lt;/p&gt;
&lt;p&gt;
ALTO&#26159;&#19968;&#20010;&#32593;&#32476;&#32534;&#25490;&#22120;&#65292;&#38024;&#23545;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#26426;&#20250;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ALTO&#65292;&#19968;&#31181;&#29992;&#20110;&#26377;&#25928;&#20026;&#35832;&#22914;&#35821;&#35328;&#27169;&#22411;&#31649;&#36947;&#20043;&#31867;&#30340;&#22797;&#21512;AI&#31995;&#32479;&#25552;&#20379;&#26381;&#21153;&#30340;&#32593;&#32476;&#32534;&#25490;&#22120;&#12290;ALTO&#36890;&#36807;&#21033;&#29992;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#29305;&#26377;&#30340;&#20248;&#21270;&#26426;&#20250;&#65306;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#12290;&#30001;&#20110;&#35821;&#35328;&#27169;&#22411;&#36880;&#20010;&#29983;&#25104;token&#30340;&#36755;&#20986;&#65292;ALTO&#22312;&#21487;&#33021;&#26102;&#26292;&#38706;&#20102;&#22312;&#38454;&#27573;&#20043;&#38388;&#27969;&#24335;&#20256;&#36755;&#20013;&#38388;&#36755;&#20986;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#22312;&#36328;&#20998;&#24067;&#24335;&#31649;&#36947;&#38454;&#27573;&#23454;&#20363;&#20043;&#38388;&#27969;&#24335;&#20256;&#36755;&#20013;&#38388;&#25968;&#25454;&#26102;&#20986;&#29616;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#32858;&#21512;&#24863;&#30693;&#36335;&#30001;&#25509;&#21475;&#21644;&#20998;&#24067;&#24335;&#25552;&#31034;&#24863;&#30693;&#35843;&#24230;&#20197;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#22797;&#26434;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#39564;&#35777;&#31649;&#36947;&#19978;&#23637;&#31034;&#20102;ALTO&#37096;&#20998;&#36755;&#20986;&#27969;&#24335;&#20256;&#36755;&#30340;&#24433;&#21709;&#65292;&#23558;&#21534;&#21520;&#37327;&#25552;&#39640;&#20102;&#26368;&#22810;3&#20493;&#65292;&#21516;&#26102;&#23558;&#22266;&#23450;&#24310;&#36831;&#30446;&#26631;&#35774;&#32622;&#20026;4&#31186;/&#35831;&#27714;&#65292;&#36824;&#20943;&#23569;&#20102;&#23614;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04311v1 Announce Type: new  Abstract: We present ALTO, a network orchestrator for efficiently serving compound AI systems such as pipelines of language models. ALTO achieves high throughput and low latency by taking advantage of an optimization opportunity specific to generative language models: streaming intermediate outputs. As language models produce outputs token by token, ALTO exposes opportunities to stream intermediate outputs between stages when possible. We highlight two new challenges of correctness and load balancing which emerge when streaming intermediate data across distributed pipeline stage instances. We also motivate the need for an aggregation-aware routing interface and distributed prompt-aware scheduling to address these challenges. We demonstrate the impact of ALTO's partial output streaming on a complex chatbot verification pipeline, increasing throughput by up to 3x for a fixed latency target of 4 seconds / request while also reducing tail latency by 1
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#23545;&#30693;&#35782;&#33976;&#39311;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#36827;&#34892;&#20102;&#28145;&#20837;&#27604;&#36739;&#65292;&#21253;&#25324;&#20248;&#21270;&#30340;&#28201;&#24230;&#21644;&#26435;&#37325;&#21442;&#25968;&#30340;&#35843;&#25972;&#65292;&#20197;&#21450;&#25968;&#25454;&#20998;&#21306;KD&#65292;&#25581;&#31034;&#20102;&#26368;&#26377;&#25928;&#30340;&#30693;&#35782;&#33976;&#39311;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.14922</link><description>&lt;p&gt;
&#38024;&#23545;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#30693;&#35782;&#33976;&#39311;&#30340;&#23454;&#36341;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;
Practical Insights into Knowledge Distillation for Pre-Trained Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14922
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#23545;&#30693;&#35782;&#33976;&#39311;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#36827;&#34892;&#20102;&#28145;&#20837;&#27604;&#36739;&#65292;&#21253;&#25324;&#20248;&#21270;&#30340;&#28201;&#24230;&#21644;&#26435;&#37325;&#21442;&#25968;&#30340;&#35843;&#25972;&#65292;&#20197;&#21450;&#25968;&#25454;&#20998;&#21306;KD&#65292;&#25581;&#31034;&#20102;&#26368;&#26377;&#25928;&#30340;&#30693;&#35782;&#33976;&#39311;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#23545;&#30693;&#35782;&#33976;&#39311;&#65288;KD&#65289;&#36807;&#31243;&#30340;&#22686;&#24378;&#65292;&#36825;&#26159;&#30693;&#35782;&#20256;&#36755;&#20013;&#19968;&#20010;&#26032;&#20852;&#39046;&#22495;&#65292;&#24182;&#23545;&#20998;&#24067;&#24335;&#35757;&#32451;&#21644;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;&#23613;&#31649;&#37319;&#29992;&#20102;&#35768;&#22810;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#26469;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#20043;&#38388;&#20256;&#36882;&#30693;&#35782;&#65292;&#20294;&#22312;&#36825;&#20123;&#22330;&#26223;&#20013;&#20102;&#35299;&#30693;&#35782;&#33976;&#39311;&#30340;&#24212;&#29992;&#20173;&#28982;&#32570;&#20047;&#20840;&#38754;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#23545;&#22810;&#31181;&#30693;&#35782;&#33976;&#39311;&#25216;&#26415;&#36827;&#34892;&#20102;&#24191;&#27867;&#27604;&#36739;&#65292;&#21253;&#25324;&#26631;&#20934;KD&#12289;&#32463;&#36807;&#20248;&#21270;&#28201;&#24230;&#21644;&#26435;&#37325;&#21442;&#25968;&#35843;&#25972;&#30340;KD&#12289;&#28145;&#24230;&#30456;&#20114;&#23398;&#20064;&#20197;&#21450;&#25968;&#25454;&#20998;&#21306;KD&#12290;&#25105;&#20204;&#35780;&#20272;&#36825;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#31574;&#30053;&#19979;&#30340;&#34920;&#29616;&#65292;&#20197;&#30830;&#23450;&#27599;&#31181;&#26041;&#27861;&#26368;&#26377;&#25928;&#30340;&#24773;&#22659;&#12290;&#36890;&#36807;&#35814;&#32454;&#30740;&#31350;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#32467;&#21512;&#24191;&#27867;&#30340;&#32593;&#26684;&#25628;&#32034;&#35780;&#20272;&#26469;&#33719;&#21462;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14922v1 Announce Type: cross  Abstract: This research investigates the enhancement of knowledge distillation (KD) processes in pre-trained models, an emerging field in knowledge transfer with significant implications for distributed training and federated learning environments. These environments benefit from reduced communication demands and accommodate various model architectures. Despite the adoption of numerous KD approaches for transferring knowledge among pre-trained models, a comprehensive understanding of KD's application in these scenarios is lacking. Our study conducts an extensive comparison of multiple KD techniques, including standard KD, tuned KD (via optimized temperature and weight parameters), deep mutual learning, and data partitioning KD. We assess these methods across various data distribution strategies to identify the most effective contexts for each. Through detailed examination of hyperparameter tuning, informed by extensive grid search evaluations, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#31185;&#23398;&#39046;&#22495;&#20013;&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#26426;&#22120;&#20154;&#30340;&#28431;&#27934;&#19982;&#39118;&#38505;&#65292;&#24182;&#24378;&#35843;&#20102;&#23545;&#23433;&#20840;&#25514;&#26045;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04247</link><description>&lt;p&gt;
&#20248;&#20808;&#23433;&#20840;&#20445;&#38556;&#32780;&#38750;&#33258;&#27835;&#65306;&#31185;&#23398;&#20013;LLM&#26234;&#33021;&#26426;&#22120;&#20154;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#31185;&#23398;&#39046;&#22495;&#20013;&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#26426;&#22120;&#20154;&#30340;&#28431;&#27934;&#19982;&#39118;&#38505;&#65292;&#24182;&#24378;&#35843;&#20102;&#23545;&#23433;&#20840;&#25514;&#26045;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39537;&#21160;&#30340;&#26234;&#33021;&#26426;&#22120;&#20154;&#22312;&#21508;&#20010;&#23398;&#31185;&#20013;&#33258;&#20027;&#36827;&#34892;&#23454;&#39564;&#21644;&#20419;&#36827;&#31185;&#23398;&#21457;&#29616;&#26041;&#38754;&#23637;&#31034;&#20102;&#24040;&#22823;&#30340;&#21069;&#26223;&#12290;&#23613;&#31649;&#23427;&#20204;&#30340;&#33021;&#21147;&#38750;&#24120;&#26377;&#21069;&#36884;&#65292;&#20294;&#20063;&#24341;&#20837;&#20102;&#19968;&#20123;&#26032;&#30340;&#28431;&#27934;&#65292;&#38656;&#35201;&#20180;&#32454;&#32771;&#34385;&#23433;&#20840;&#24615;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#20013;&#23384;&#22312;&#26174;&#33879;&#30340;&#31354;&#30333;&#65292;&#23578;&#26410;&#23545;&#36825;&#20123;&#28431;&#27934;&#36827;&#34892;&#20840;&#38754;&#25506;&#35752;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#31185;&#23398;&#39046;&#22495;&#20013;&#22522;&#20110;LLM&#30340;&#26426;&#22120;&#20154;&#30340;&#28431;&#27934;&#36827;&#34892;&#28145;&#20837;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#35823;&#29992;&#21487;&#33021;&#24102;&#26469;&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#24182;&#24378;&#35843;&#20102;&#23545;&#23433;&#20840;&#25514;&#26045;&#30340;&#38656;&#27714;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#39318;&#20808;&#20840;&#38754;&#27010;&#36848;&#20102;&#31185;&#23398;LLM&#26426;&#22120;&#20154;&#22266;&#26377;&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#32771;&#34385;&#20102;&#29992;&#25143;&#24847;&#22270;&#12289;&#29305;&#23450;&#30340;&#31185;&#23398;&#39046;&#22495;&#20197;&#21450;&#23427;&#20204;&#23545;&#22806;&#37096;&#29615;&#22659;&#21487;&#33021;&#36896;&#25104;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#20123;&#28431;&#27934;&#30340;&#36215;&#28304;&#21644;&#25552;&#20379;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intelligent agents powered by large language models (LLMs) have demonstrated substantial promise in autonomously conducting experiments and facilitating scientific discoveries across various disciplines. While their capabilities are promising, they also introduce novel vulnerabilities that demand careful consideration for safety. However, there exists a notable gap in the literature, as there has been no comprehensive exploration of these vulnerabilities. This position paper fills this gap by conducting a thorough examination of vulnerabilities in LLM-based agents within scientific domains, shedding light on potential risks associated with their misuse and emphasizing the need for safety measures. We begin by providing a comprehensive overview of the potential risks inherent to scientific LLM agents, taking into account user intent, the specific scientific domain, and their potential impact on the external environment. Then, we delve into the origins of these vulnerabilities and provid
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#22240;&#26524;&#24863;&#30693;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#20013;&#12290;&#24863;&#30693;&#23545;&#20915;&#31574;&#30340;&#20844;&#24179;&#24615;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#22240;&#20026;&#20844;&#24179;&#24615;&#26159;&#19982;&#32972;&#26223;&#30456;&#20851;&#30340;&#65292;&#24182;&#19988;&#20854;&#35299;&#37322;&#21462;&#20915;&#20110;&#35780;&#21028;&#20154;&#26159;&#35841;&#12290;</title><link>http://arxiv.org/abs/2401.13408</link><description>&lt;p&gt;
&#22240;&#26524;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Causal Perception. (arXiv:2401.13408v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13408
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#22240;&#26524;&#24863;&#30693;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#20013;&#12290;&#24863;&#30693;&#23545;&#20915;&#31574;&#30340;&#20844;&#24179;&#24615;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#22240;&#20026;&#20844;&#24179;&#24615;&#26159;&#19982;&#32972;&#26223;&#30456;&#20851;&#30340;&#65292;&#24182;&#19988;&#20854;&#35299;&#37322;&#21462;&#20915;&#20110;&#35780;&#21028;&#20154;&#26159;&#35841;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20004;&#20010;&#20010;&#20307;&#23545;&#30456;&#21516;&#30340;&#20449;&#24687;&#36827;&#34892;&#19981;&#21516;&#35299;&#35835;&#26102;&#65292;&#24863;&#30693;&#20250;&#21457;&#29983;&#12290;&#23613;&#31649;&#36825;&#26159;&#19968;&#20010;&#24050;&#30693;&#29616;&#35937;&#65292;&#23545;&#20915;&#31574;&#20013;&#20559;&#35265;&#26377;&#24433;&#21709;&#65292;&#20294;&#26159;&#24863;&#30693;&#22312;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#20013;&#20173;&#28982;&#34987;&#24573;&#35270;&#12290;&#24863;&#30693;&#23545;&#20110;ADM&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#25110;&#20844;&#24179;&#20351;&#29992;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#22240;&#20026;&#20844;&#24179;&#26412;&#36523;&#26159;&#19982;&#32972;&#26223;&#30456;&#20851;&#30340;&#65292;&#20854;&#35299;&#37322;&#21462;&#20915;&#20110;&#35780;&#21028;&#20154;&#26159;&#35841;&#12290;&#26412;&#25991;&#23558;&#24863;&#30693;&#22312;&#22240;&#26524;&#25512;&#29702;&#20013;&#24418;&#24335;&#21270;&#65292;&#20197;&#25429;&#25417;&#20010;&#20307;&#30340;&#35299;&#37322;&#34892;&#20026;&#12290;&#25105;&#20204;&#36824;&#23558;&#20010;&#20307;&#32463;&#39564;&#24418;&#24335;&#21270;&#20026;&#39069;&#22806;&#30340;&#22240;&#26524;&#30693;&#35782;&#65292;&#20010;&#20307;&#20250;&#20351;&#29992;&#36825;&#20123;&#30693;&#35782;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23450;&#20041;&#21644;&#35752;&#35770;&#20102;&#26131;&#24341;&#21457;&#24863;&#30693;&#30340;&#23646;&#24615;&#65292;&#21363;&#26131;&#24341;&#21457;&#24863;&#30693;&#30340;&#23646;&#24615;&#12290;&#25935;&#24863;&#23646;&#24615;&#65292;&#22914;&#24615;&#21035;&#21644;&#31181;&#26063;&#65292;&#23601;&#26159;&#26131;&#24341;&#21457;&#24863;&#30693;&#30340;&#26126;&#30830;&#31034;&#20363;&#12290;&#25105;&#20204;&#26681;&#25454;&#22240;&#26524;&#21407;&#21017;&#23450;&#20041;&#20102;&#20004;&#31181;&#24863;&#30693;&#65292;&#21363;&#19981;&#24544;&#23454;&#24863;&#30693;&#21644;&#19981;&#19968;&#33268;&#24863;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;
Perception occurs when two individuals interpret the same information differently. Despite being a known phenomenon with implications for bias in decision-making, as individuals' experience determines interpretation, perception remains largely overlooked in automated decision-making (ADM) systems. In particular, it can have considerable effects on the fairness or fair usage of an ADM system, as fairness itself is context-specific and its interpretation dependent on who is judging. In this work, we formalize perception under causal reasoning to capture the act of interpretation by an individual. We also formalize individual experience as additional causal knowledge that comes with and is used by an individual. Further, we define and discuss loaded attributes, which are attributes prone to evoke perception. Sensitive attributes, such as gender and race, are clear examples of loaded attributes. We define two kinds of causal perception, unfaithful and inconsistent, based on the causal prop
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#23454;&#26102;&#24863;&#30693;&#33021;&#21147;&#30340;IoT&#32593;&#32476;&#35774;&#35745;&#30340;&#22522;&#20110;&#26679;&#26412;&#39537;&#21160;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#37319;&#26679;&#36807;&#31243;&#26469;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#25552;&#39640;&#25972;&#20307;&#20934;&#30830;&#24615;&#65292;&#24182;&#35299;&#20915;&#33021;&#25928;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.07497</link><description>&lt;p&gt;
&#22522;&#20110;&#26679;&#26412;&#39537;&#21160;&#30340;&#32852;&#37030;&#23398;&#20064;&#29992;&#20110;&#33021;&#25928;&#21644;&#23454;&#26102;IoT&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Sample-Driven Federated Learning for Energy-Efficient and Real-Time IoT Sensing. (arXiv:2310.07497v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#23454;&#26102;&#24863;&#30693;&#33021;&#21147;&#30340;IoT&#32593;&#32476;&#35774;&#35745;&#30340;&#22522;&#20110;&#26679;&#26412;&#39537;&#21160;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#37319;&#26679;&#36807;&#31243;&#26469;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#25552;&#39640;&#25972;&#20307;&#20934;&#30830;&#24615;&#65292;&#24182;&#35299;&#20915;&#33021;&#25928;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#39046;&#22495;&#65292;&#26368;&#36817;&#30340;&#21069;&#27839;&#26041;&#27861;&#22312;&#25910;&#25947;&#20998;&#26512;&#20013;&#20005;&#37325;&#20381;&#36182;&#20110;&#29702;&#24819;&#26465;&#20214;&#12290;&#29305;&#21035;&#22320;&#65292;&#36825;&#20123;&#26041;&#27861;&#20551;&#35774;IoT&#35774;&#22791;&#19978;&#30340;&#35757;&#32451;&#25968;&#25454;&#20855;&#26377;&#19982;&#20840;&#23616;&#25968;&#25454;&#20998;&#24067;&#30456;&#20284;&#30340;&#23646;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#26102;&#24863;&#30693;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#20013;&#65292;&#36825;&#31181;&#26041;&#27861;&#26080;&#27861;&#25429;&#25417;&#21040;&#25968;&#25454;&#29305;&#24449;&#30340;&#20840;&#38754;&#33539;&#22260;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#23454;&#26102;&#24863;&#30693;&#33021;&#21147;&#30340;IoT&#32593;&#32476;&#35774;&#35745;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32771;&#34385;&#20102;&#30001;&#29992;&#25143;&#25968;&#25454;&#37319;&#26679;&#36807;&#31243;&#24341;&#36215;&#30340;&#27867;&#21270;&#24046;&#36317;&#12290;&#36890;&#36807;&#26377;&#25928;&#22320;&#25511;&#21046;&#36825;&#20010;&#37319;&#26679;&#36807;&#31243;&#65292;&#25105;&#20204;&#21487;&#20197;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#24182;&#25552;&#39640;&#25972;&#20307;&#20934;&#30830;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#39318;&#20808;&#21046;&#23450;&#20102;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#21033;&#29992;&#37319;&#26679;&#36807;&#31243;&#21516;&#26102;&#20943;&#23569;&#36807;&#25311;&#21512;&#21644;&#26368;&#22823;&#21270;&#20934;&#30830;&#24615;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#30340;&#26367;&#20195;&#20248;&#21270;&#38382;&#39064;&#25797;&#38271;&#22788;&#29702;&#33021;&#25928;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the domain of Federated Learning (FL) systems, recent cutting-edge methods heavily rely on ideal conditions convergence analysis. Specifically, these approaches assume that the training datasets on IoT devices possess similar attributes to the global data distribution. However, this approach fails to capture the full spectrum of data characteristics in real-time sensing FL systems. In order to overcome this limitation, we suggest a new approach system specifically designed for IoT networks with real-time sensing capabilities. Our approach takes into account the generalization gap due to the user's data sampling process. By effectively controlling this sampling process, we can mitigate the overfitting issue and improve overall accuracy. In particular, We first formulate an optimization problem that harnesses the sampling process to concurrently reduce overfitting while maximizing accuracy. In pursuit of this objective, our surrogate optimization problem is adept at handling energy ef
&lt;/p&gt;</description></item></channel></rss>