<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36890;&#36807;&#21306;&#22359;&#38142;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#36131;&#20219;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#26550;&#26500;&#65292;&#25552;&#39640;&#33258;&#20027;&#20195;&#29702;&#30340;&#20449;&#20219;&#21644;&#23433;&#20840;&#24615;&#65292;&#22686;&#24378;&#20195;&#29702;&#19982;&#29992;&#25143;&#20043;&#38388;&#30340;&#27807;&#36890;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.09567</link><description>&lt;p&gt;
&#36890;&#36807;&#21306;&#22359;&#38142;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#33258;&#20027;&#20195;&#29702;&#30340;&#20449;&#20219;&#65306;&#19968;&#31181;&#36890;&#36807;&#21306;&#22359;&#38142;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#36131;&#20219;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09567
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21306;&#22359;&#38142;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#36131;&#20219;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#26550;&#26500;&#65292;&#25552;&#39640;&#33258;&#20027;&#20195;&#29702;&#30340;&#20449;&#20219;&#21644;&#23433;&#20840;&#24615;&#65292;&#22686;&#24378;&#20195;&#29702;&#19982;&#29992;&#25143;&#20043;&#38388;&#30340;&#27807;&#36890;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20027;&#20195;&#29702;&#22312;&#28041;&#21450;&#20154;&#31867;&#20114;&#21160;&#30340;&#29615;&#22659;&#20013;&#30340;&#37096;&#32626;&#26085;&#30410;&#24341;&#36215;&#23433;&#20840;&#20851;&#27880;&#12290;&#22240;&#27492;&#65292;&#20102;&#35299;&#20107;&#20214;&#32972;&#21518;&#30340;&#24773;&#20917;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#38656;&#35201;&#24320;&#21457;&#33021;&#22815;&#21521;&#38750;&#19987;&#23478;&#29992;&#25143;&#35299;&#37322;&#20854;&#34892;&#20026;&#30340;&#33021;&#21147;&#12290;&#36825;&#20123;&#35299;&#37322;&#22312;&#25552;&#39640;&#21487;&#20449;&#24230;&#21644;&#23433;&#20840;&#24615;&#26041;&#38754;&#33267;&#20851;&#37325;&#35201;&#65292;&#20316;&#20026;&#38450;&#33539;&#22833;&#36133;&#12289;&#38169;&#35823;&#21644;&#35823;&#35299;&#30340;&#25514;&#26045;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#26377;&#21161;&#20110;&#25913;&#21892;&#27807;&#36890;&#65292;&#24357;&#21512;&#20195;&#29702;&#21644;&#29992;&#25143;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#20174;&#32780;&#25552;&#39640;&#23427;&#20204;&#30456;&#20114;&#20316;&#29992;&#30340;&#25928;&#26524;&#12290;&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20026;&#22522;&#20110;ROS&#30340;&#31227;&#21160;&#26426;&#22120;&#20154;&#23454;&#26045;&#30340;&#36131;&#20219;&#21644;&#21487;&#35299;&#37322;&#24615;&#26550;&#26500;&#12290;&#25152;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#32452;&#20214;&#12290;&#39318;&#20808;&#65292;&#19968;&#20010;&#31867;&#20284;&#40657;&#30418;&#30340;&#20803;&#32032;&#29992;&#20110;&#25552;&#20379;&#38382;&#36131;&#21046;&#65292;&#20855;&#26377;&#36890;&#36807;&#21306;&#22359;&#38142;&#25216;&#26415;&#23454;&#29616;&#30340;&#38450;&#31713;&#25913;&#23646;&#24615;&#12290;&#20854;&#27425;&#65292;&#19968;&#20010;&#36127;&#36131;&#30340;&#32452;&#20214;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09567v1 Announce Type: cross  Abstract: The deployment of autonomous agents in environments involving human interaction has increasingly raised security concerns. Consequently, understanding the circumstances behind an event becomes critical, requiring the development of capabilities to justify their behaviors to non-expert users. Such explanations are essential in enhancing trustworthiness and safety, acting as a preventive measure against failures, errors, and misunderstandings. Additionally, they contribute to improving communication, bridging the gap between the agent and the user, thereby improving the effectiveness of their interactions. This work presents an accountability and explainability architecture implemented for ROS-based mobile robots. The proposed solution consists of two main components. Firstly, a black box-like element to provide accountability, featuring anti-tampering properties achieved through blockchain technology. Secondly, a component in charge of 
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#22635;&#34917;&#20102;&#26377;&#20851;&#20225;&#19994;&#20013;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;GenAI&#65289;&#27835;&#29702;&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#26088;&#22312;&#21033;&#29992;&#19994;&#21153;&#26426;&#20250;&#24182;&#20943;&#36731;&#19982;GenAI&#25972;&#21512;&#30456;&#20851;&#39118;&#38505;&#12290;</title><link>https://arxiv.org/abs/2403.08802</link><description>&lt;p&gt;
&#20225;&#19994;&#20013;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#27835;&#29702;
&lt;/p&gt;
&lt;p&gt;
Governance of Generative Artificial Intelligence for Companies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#22635;&#34917;&#20102;&#26377;&#20851;&#20225;&#19994;&#20013;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;GenAI&#65289;&#27835;&#29702;&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#26088;&#22312;&#21033;&#29992;&#19994;&#21153;&#26426;&#20250;&#24182;&#20943;&#36731;&#19982;GenAI&#25972;&#21512;&#30456;&#20851;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;GenAI&#65289;&#65292;&#29305;&#21035;&#26159;&#20687;ChatGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24050;&#36805;&#36895;&#36827;&#20837;&#20225;&#19994;&#65292;&#20294;&#32570;&#20047;&#20805;&#20998;&#30340;&#27835;&#29702;&#65292;&#24102;&#26469;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;&#23613;&#31649;&#23545;GenAI&#20855;&#26377;&#21464;&#38761;&#24615;&#36136;&#21644;&#30417;&#31649;&#25514;&#26045;&#30340;&#24191;&#27867;&#35752;&#35770;&#65292;&#20294;&#26377;&#38480;&#30340;&#30740;&#31350;&#28041;&#21450;&#32452;&#32455;&#27835;&#29702;&#65292;&#21253;&#25324;&#25216;&#26415;&#21644;&#19994;&#21153;&#35270;&#35282;&#12290;&#26412;&#32508;&#36848;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#35843;&#26597;&#20102;&#26368;&#36817;&#30340;&#30740;&#31350;&#12290;&#23427;&#19981;&#20165;&#20165;&#26159;&#24635;&#32467;&#65292;&#36824;&#36890;&#36807;&#21046;&#23450;&#36866;&#29992;&#20110;&#20225;&#19994;&#20869;&#30340;GenAI&#27835;&#29702;&#26694;&#26550;&#26469;&#36827;&#34892;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#35814;&#32454;&#25551;&#36848;&#20102;&#33539;&#22260;&#12289;&#30446;&#26631;&#21644;&#27835;&#29702;&#26426;&#21046;&#65292;&#26088;&#22312;&#21033;&#29992;&#19994;&#21153;&#26426;&#20250;&#24182;&#20943;&#36731;&#19982;GenAI&#25972;&#21512;&#30456;&#20851;&#39118;&#38505;&#12290;&#35813;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#19987;&#27880;&#20110;GenAI&#27835;&#29702;&#30340;&#26041;&#27861;&#65292;&#20026;&#20225;&#19994;&#22312;&#36127;&#36131;&#20219;&#30340;AI&#37319;&#29992;&#25361;&#25112;&#20013;&#25552;&#20379;&#20102;&#23454;&#29992;&#35265;&#35299;&#12290;&#23545;&#20110;&#25216;&#26415;&#20154;&#21592;&#26469;&#35828;&#65292;&#20063;&#26377;&#21161;&#20110;&#25299;&#23485;&#20182;&#20204;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08802v1 Announce Type: new  Abstract: Generative Artificial Intelligence (GenAI), specifically large language models like ChatGPT, has swiftly entered organizations without adequate governance, posing both opportunities and risks. Despite extensive debates on GenAI's transformative nature and regulatory measures, limited research addresses organizational governance, encompassing technical and business perspectives. This review paper fills this gap by surveying recent works. It goes beyond mere summarization by developing a framework for GenAI governance within companies. Our framework outlines the scope, objectives, and governance mechanisms tailored to harness business opportunities and mitigate risks associated with GenAI integration. This research contributes a focused approach to GenAI governance, offering practical insights for companies navigating the challenges of responsible AI adoption. It is also valuable for a technical audience to broaden their perspective as inc
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#28041;&#21450;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#32467;&#26524;&#19982;&#30446;&#26631;&#30340;&#26399;&#26395;Wasserstein-1&#36317;&#31163;&#30340;&#32553;&#25918;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.15801</link><description>&lt;p&gt;
&#20851;&#20110;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension. (arXiv:2401.15801v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15801
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#28041;&#21450;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#32467;&#26524;&#19982;&#30446;&#26631;&#30340;&#26399;&#26395;Wasserstein-1&#36317;&#31163;&#30340;&#32553;&#25918;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#20854;&#32479;&#35745;&#20934;&#30830;&#24615;&#30340;&#29702;&#35770;&#20445;&#35777;&#20173;&#28982;&#30456;&#23545;&#24754;&#35266;&#12290;&#29305;&#21035;&#26159;&#22312;&#24212;&#29992;GANs&#30340;&#25968;&#25454;&#20998;&#24067;&#65288;&#22914;&#33258;&#28982;&#22270;&#20687;&#65289;&#20013;&#65292;&#36890;&#24120;&#20551;&#35774;&#20854;&#22312;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#20013;&#20855;&#26377;&#22266;&#26377;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#20294;&#36825;&#22312;&#29616;&#26377;&#20998;&#26512;&#20013;&#24448;&#24448;&#27809;&#26377;&#24471;&#21040;&#21453;&#26144;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#36890;&#36807;&#25512;&#23548;&#20851;&#20110;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#26469;&#24357;&#21512;GANs&#21450;&#20854;&#21452;&#21521;&#21464;&#20307;BiGANs&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#20998;&#26512;&#22320;&#35777;&#26126;&#65292;&#22914;&#26524;&#25105;&#20204;&#26377;&#26469;&#33258;&#26410;&#30693;&#30446;&#26631;&#20998;&#24067;&#30340; n &#20010;&#26679;&#26412;&#65292;&#24182;&#19988;&#36873;&#25321;&#20102;&#36866;&#24403;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#37027;&#20040;&#20174;&#30446;&#26631;&#20013;&#20272;&#35745;&#24471;&#20986;&#30340;&#26399;&#26395; Wasserstein-1 &#36317;&#31163;&#20250;&#25353;&#29031; $O(n^{-1/d_\mu })$ &#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\left( n^{-1/d_\mu } \right)$
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#20132;&#25442;&#28436;&#31639;&#20013;&#32771;&#34385;&#20102;&#38598;&#21512;&#35774;&#22791;&#30340;&#21160;&#24577;&#21512;&#20316;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#38598;&#20307;&#36807;&#31243;&#30340;&#25277;&#35937;&#34920;&#31034;&#65292;&#29992;&#20110;&#32534;&#31243;&#35745;&#31639;&#38598;&#20307;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2401.11212</link><description>&lt;p&gt;
&#22312;&#20132;&#25442;&#28436;&#31639;&#20013;&#32534;&#31243;&#20998;&#24067;&#24335;&#38598;&#20307;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Programming Distributed Collective Processes in the eXchange Calculus. (arXiv:2401.11212v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11212
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#20132;&#25442;&#28436;&#31639;&#20013;&#32771;&#34385;&#20102;&#38598;&#21512;&#35774;&#22791;&#30340;&#21160;&#24577;&#21512;&#20316;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#38598;&#20307;&#36807;&#31243;&#30340;&#25277;&#35937;&#34920;&#31034;&#65292;&#29992;&#20110;&#32534;&#31243;&#35745;&#31639;&#38598;&#20307;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#36235;&#21183;&#22914;&#29289;&#32852;&#32593;&#65288;IoT&#65289;&#25552;&#20986;&#20102;&#22312;&#20960;&#20046;&#25152;&#26377;&#29615;&#22659;&#20013;&#23494;&#38598;&#21644;&#22810;&#23610;&#24230;&#37096;&#32626;&#35745;&#31639;&#35774;&#22791;&#30340;&#24895;&#26223;&#12290;&#19968;&#20010;&#31361;&#20986;&#30340;&#24037;&#31243;&#25361;&#25112;&#22260;&#32469;&#30528;&#32534;&#31243;&#36825;&#31181;&#35745;&#31639;&#29983;&#24577;&#31995;&#32479;&#30340;&#38598;&#20307;&#33258;&#36866;&#24212;&#34892;&#20026;&#12290;&#36825;&#38656;&#35201;&#33021;&#22815;&#25429;&#25417;&#27010;&#24565;&#65288;&#21160;&#24577;&#21512;&#20316;&#35774;&#22791;&#32676;&#32452;&#65289;&#21644;&#38598;&#20307;&#20219;&#21153;&#65288;&#30001;&#21512;&#22863;&#32452;&#25191;&#34892;&#30340;&#32852;&#21512;&#27963;&#21160;&#65289;&#30340;&#25277;&#35937;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#19982;&#37051;&#23621;&#20132;&#20114;&#24182;&#20197;&#20960;&#20046;&#21516;&#27493;&#30340;&#24863;&#30693;-&#35745;&#31639;-&#20132;&#20114;&#24490;&#29615;&#25191;&#34892;&#30340;&#35774;&#22791;&#38598;&#21512;&#65292;&#20854;&#20013;&#35745;&#31639;&#30001;&#19968;&#20010;&#23558;&#24863;&#30693;&#20540;&#21644;&#20256;&#20837;&#28040;&#24687;&#26144;&#23556;&#21040;&#36755;&#20986;&#21644;&#20256;&#20986;&#28040;&#24687;&#30340;&#21333;&#20010;&#31243;&#24207;&#32473;&#20986;&#12290;&#20026;&#20102;&#25903;&#25345;&#25972;&#20010;&#35745;&#31639;&#38598;&#20307;&#30340;&#32534;&#31243;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#38598;&#20307;&#36807;&#31243;&#30340;&#25277;&#35937;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23450;&#20041;&#21512;&#22863;&#32452;&#30340;&#24418;&#25104;&#36923;&#36753;&#21644;&#23427;&#30340;&#38598;&#20307;&#20219;&#21153;&#12290;&#25105;&#20204;&#22312;&#20132;&#25442;&#28436;&#31639;&#20013;&#24418;&#24335;&#21270;&#20102;&#36825;&#31181;&#25277;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent trends like the Internet of Things (IoT) suggest a vision of dense and multi-scale deployments of computing devices in nearly all kinds of environments. A prominent engineering challenge revolves around programming the collective adaptive behaviour of such computational ecosystems. This requires abstractions able to capture concepts like ensembles (dynamic groups of cooperating devices) and collective tasks (joint activities carried out by ensembles). In this work, we consider collections of devices interacting with neighbours and that execute in nearly-synchronised sense-compute-interact rounds, where the computation is given by a single program mapping sensing values and incoming messages to output and outcoming messages. To support programming whole computational collectives, we propose the abstraction of a distributed collective process, which can be used to define at once the ensemble formation logic and its collective task. We formalise the abstraction in the eXchange Calc
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2310.20360</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#25968;&#23398;&#20171;&#32461;&#65306;&#26041;&#27861;&#12289;&#23454;&#29616;&#21644;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory. (arXiv:2310.20360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#26088;&#22312;&#20171;&#32461;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20027;&#39064;&#12290;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65288;&#22914;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#12289;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12289;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#12289;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#21644;&#24102;&#26377;&#25209;&#24402;&#19968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65289;&#20197;&#21450;&#19981;&#21516;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;&#22522;&#26412;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#12289;&#21152;&#36895;&#26041;&#27861;&#21644;&#33258;&#36866;&#24212;&#26041;&#27861;&#65289;&#12290;&#25105;&#20204;&#36824;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20960;&#20010;&#29702;&#35770;&#26041;&#38754;&#65292;&#22914;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#65288;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#30340;&#24494;&#31215;&#20998;&#65289;&#12289;&#20248;&#21270;&#29702;&#35770;&#65288;&#21253;&#25324;Kurdyka-Lojasiewicz&#19981;&#31561;&#24335;&#65289;&#21644;&#27867;&#21270;&#35823;&#24046;&#12290;&#22312;&#26412;&#20070;&#30340;&#26368;&#21518;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#36824;&#22238;&#39038;&#20102;&#19968;&#20123;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#26041;&#27861;&#65292;&#21253;&#25324;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#21644;&#28145;&#24230;Galerkin&#26041;&#27861;&#12290;&#24076;&#26395;&#26412;&#20070;&#33021;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;
This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet 
&lt;/p&gt;</description></item></channel></rss>