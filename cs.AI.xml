<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36890;&#36807;&#30740;&#31350;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#36807;&#31243;&#20013;&#23384;&#22312;&#20960;&#20309;&#24341;&#23548;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2402.08269</link><description>&lt;p&gt;
&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20960;&#20309;&#24341;&#23548;&#38544;&#24335;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Geometry-induced Implicit Regularization in Deep ReLU Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08269
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#36807;&#31243;&#20013;&#23384;&#22312;&#20960;&#20309;&#24341;&#23548;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20855;&#26377;&#27604;&#35757;&#32451;&#26679;&#26412;&#26356;&#22810;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#19981;&#20250;&#36807;&#25311;&#21512;&#12290;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#20986;&#29616;&#65292;&#23545;&#8220;&#22909;&#8221;&#30340;&#32593;&#32476;&#26377;&#21033;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#25105;&#20204;&#19981;&#32771;&#34385;&#25152;&#26377;&#21487;&#33021;&#30340;&#32593;&#32476;&#65292;&#32780;&#21482;&#32771;&#34385;&#8220;&#22909;&#8221;&#30340;&#32593;&#32476;&#65292;&#21442;&#25968;&#25968;&#37327;&#23601;&#19981;&#26159;&#19968;&#20010;&#36275;&#22815;&#34913;&#37327;&#22797;&#26434;&#24615;&#30340;&#25351;&#26631;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#21738;&#20123;&#32593;&#32476;&#21463;&#21040;&#38738;&#30544;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#12290;&#24403;&#36755;&#20837;&#22266;&#23450;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#38598;&#21512;&#30340;&#32500;&#24230;&#20250;&#21457;&#29983;&#21464;&#21270;&#65292;&#24182;&#19988;&#23616;&#37096;&#32500;&#24230;&#65292;&#21363;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#65292;&#20960;&#20046;&#24635;&#26159;&#30001;&#38544;&#34255;&#23618;&#20013;&#30340;&#28608;&#27963;&#27169;&#24335;&#20915;&#23450;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#23545;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#23545;&#31216;&#24615;&#65288;&#31070;&#32463;&#20803;&#25490;&#21015;&#21644;&#27491;&#21521;&#32553;&#25918;&#65289;&#26159;&#19981;&#21464;&#30340;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#20250;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#20248;&#21270;&#36807;&#31243;&#20855;&#26377;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that neural networks with many more parameters than training examples do not overfit. Implicit regularization phenomena, which are still not well understood, occur during optimization and 'good' networks are favored. Thus the number of parameters is not an adequate measure of complexity if we do not consider all possible networks but only the 'good' ones. To better understand which networks are favored during optimization, we study the geometry of the output set as parameters vary. When the inputs are fixed, we prove that the dimension of this set changes and that the local dimension, called batch functional dimension, is almost surely determined by the activation patterns in the hidden layers. We prove that the batch functional dimension is invariant to the symmetries of the network parameterization: neuron permutations and positive rescalings. Empirically, we establish that the batch functional dimension decreases during optimization. As a consequence, optimization l
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.06388</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#21450;&#20854;&#22312;&#20462;&#25913;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#19978;&#30340;&#31574;&#30053;&#26799;&#24230;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06388
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21253;&#21547;&#30340;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#36981;&#24490;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65307;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#24212;&#29992;&#20110;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#20462;&#25913;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#39318;&#27425;&#23581;&#35797;&#24314;&#31435;&#20102;&#19968;&#20010;&#38543;&#26426;&#20248;&#21183;&#23398;&#20064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#25512;&#24191;&#20102;&#38543;&#26426;&#20248;&#21183;&#30340;&#27010;&#24565;&#20197;&#20351;&#20854;&#33021;&#22815;&#22312;&#20219;&#24847;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#36827;&#34892;&#27604;&#36739;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#26469;&#22788;&#29702;&#36830;&#32493;&#24615;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.02698</link><description>&lt;p&gt;
&#36229;&#36234;&#26399;&#26395;: &#29616;&#23454;&#20013;&#23454;&#29616;&#38543;&#26426;&#20248;&#21183;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Expectations: Learning with Stochastic Dominance Made Practical
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02698
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#39318;&#27425;&#23581;&#35797;&#24314;&#31435;&#20102;&#19968;&#20010;&#38543;&#26426;&#20248;&#21183;&#23398;&#20064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#25512;&#24191;&#20102;&#38543;&#26426;&#20248;&#21183;&#30340;&#27010;&#24565;&#20197;&#20351;&#20854;&#33021;&#22815;&#22312;&#20219;&#24847;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#36827;&#34892;&#27604;&#36739;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#26469;&#22788;&#29702;&#36830;&#32493;&#24615;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#20248;&#21183;&#27169;&#22411;&#23545;&#20915;&#31574;&#26102;&#20855;&#26377;&#39118;&#38505;&#21388;&#24694;&#20559;&#22909;&#30340;&#19981;&#30830;&#23450;&#32467;&#26524;&#36827;&#34892;&#24314;&#27169;&#65292;&#30456;&#27604;&#20110;&#20165;&#20165;&#20381;&#36182;&#26399;&#26395;&#20540;&#65292;&#33258;&#28982;&#22320;&#25429;&#25417;&#20102;&#24213;&#23618;&#19981;&#30830;&#23450;&#24615;&#30340;&#20869;&#22312;&#32467;&#26500;&#12290;&#23613;&#31649;&#22312;&#29702;&#35770;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#38543;&#26426;&#20248;&#21183;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#21364;&#24456;&#23569;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#20197;&#19979;&#25361;&#25112;&#65306;$\textbf{i)}$ &#38543;&#26426;&#20248;&#21183;&#30340;&#21407;&#22987;&#27010;&#24565;&#20165;&#25552;&#20379;&#20102;$\textit{&#37096;&#20998;&#24207;}$&#65292;&#22240;&#27492;&#19981;&#33021;&#20316;&#20026;&#26368;&#20248;&#24615;&#20934;&#21017;&#65307;&#21644; $\textbf{ii)}$ &#30001;&#20110;&#35780;&#20272;&#38543;&#26426;&#20248;&#21183;&#30340;&#36830;&#32493;&#24615;&#26412;&#36136;&#65292;&#30446;&#21069;&#36824;&#32570;&#20047;&#39640;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23581;&#35797;&#24314;&#31435;&#19968;&#20010;&#19982;&#38543;&#26426;&#20248;&#21183;&#23398;&#20064;&#30456;&#20851;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#38543;&#26426;&#20248;&#21183;&#27010;&#24565;&#25512;&#24191;&#65292;&#20351;&#24471;&#20219;&#24847;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#27604;&#36739;&#25104;&#20026;&#21487;&#33021;&#12290;&#25509;&#19979;&#26469;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#35780;&#20272;&#38543;&#26426;&#20248;&#21183;&#30340;&#36830;&#32493;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic dominance models risk-averse preferences for decision making with uncertain outcomes, which naturally captures the intrinsic structure of the underlying uncertainty, in contrast to simply resorting to the expectations. Despite theoretically appealing, the application of stochastic dominance in machine learning has been scarce, due to the following challenges: $\textbf{i)}$, the original concept of stochastic dominance only provides a $\textit{partial order}$, therefore, is not amenable to serve as an optimality criterion; and $\textbf{ii)}$, an efficient computational recipe remains lacking due to the continuum nature of evaluating stochastic dominance.%, which barriers its application for machine learning.   In this work, we make the first attempt towards establishing a general framework of learning with stochastic dominance. We first generalize the stochastic dominance concept to enable feasible comparisons between any arbitrary pair of random variables. We next develop a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#24403;&#21069;&#22522;&#20110;3D&#39592;&#26550;&#30340;&#20154;&#21592;&#20877;&#35782;&#21035;&#26041;&#27861;&#12289;&#27169;&#22411;&#35774;&#35745;&#12289;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;&#30340;&#31995;&#32479;&#35843;&#30740;&#65292;&#22635;&#34917;&#20102;&#30456;&#20851;&#30740;&#31350;&#24635;&#32467;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2401.15296</link><description>&lt;p&gt;
&#22522;&#20110;3D&#39592;&#26550;&#30340;&#20154;&#21592;&#20877;&#35782;&#21035;&#65306;&#26041;&#27861;&#12289;&#35774;&#35745;&#12289;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on 3D Skeleton Based Person Re-Identification: Approaches, Designs, Challenges, and Future Directions. (arXiv:2401.15296v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15296
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#24403;&#21069;&#22522;&#20110;3D&#39592;&#26550;&#30340;&#20154;&#21592;&#20877;&#35782;&#21035;&#26041;&#27861;&#12289;&#27169;&#22411;&#35774;&#35745;&#12289;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;&#30340;&#31995;&#32479;&#35843;&#30740;&#65292;&#22635;&#34917;&#20102;&#30456;&#20851;&#30740;&#31350;&#24635;&#32467;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;3D&#39592;&#26550;&#36827;&#34892;&#20154;&#21592;&#20877;&#35782;&#21035;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#26032;&#20852;&#30740;&#31350;&#39046;&#22495;&#65292;&#24341;&#36215;&#20102;&#27169;&#24335;&#35782;&#21035;&#31038;&#21306;&#30340;&#26497;&#22823;&#20852;&#36259;&#12290;&#36817;&#24180;&#26469;&#65292;&#38024;&#23545;&#39592;&#26550;&#24314;&#27169;&#21644;&#29305;&#24449;&#23398;&#20064;&#20013;&#31361;&#20986;&#38382;&#39064;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#20855;&#26377;&#29420;&#29305;&#20248;&#21183;&#30340;&#22522;&#20110;3D&#39592;&#26550;&#30340;&#20154;&#21592;&#20877;&#35782;&#21035;&#65288;SRID&#65289;&#26041;&#27861;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#23545;&#36825;&#20123;&#30740;&#31350;&#21450;&#20854;&#25361;&#25112;&#36827;&#34892;&#32508;&#21512;&#24635;&#32467;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#36890;&#36807;&#23545;&#24403;&#21069;SRID&#26041;&#27861;&#12289;&#27169;&#22411;&#35774;&#35745;&#12289;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;&#30340;&#31995;&#32479;&#35843;&#30740;&#65292;&#35797;&#22270;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#23450;&#20041;&#20102;SRID&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;SRID&#30740;&#31350;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#24635;&#32467;&#20102;&#24120;&#29992;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#12289;&#24120;&#29992;&#30340;&#27169;&#22411;&#26550;&#26500;&#65292;&#24182;&#23545;&#19981;&#21516;&#26041;&#27861;&#30340;&#29305;&#28857;&#36827;&#34892;&#20102;&#20998;&#26512;&#35780;&#20215;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35814;&#32454;&#38416;&#36848;&#20102;SRID&#27169;&#22411;&#30340;&#35774;&#35745;&#21407;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Person re-identification via 3D skeletons is an important emerging research area that triggers great interest in the pattern recognition community. With distinctive advantages for many application scenarios, a great diversity of 3D skeleton based person re-identification (SRID) methods have been proposed in recent years, effectively addressing prominent problems in skeleton modeling and feature learning. Despite recent advances, to the best of our knowledge, little effort has been made to comprehensively summarize these studies and their challenges. In this paper, we attempt to fill this gap by providing a systematic survey on current SRID approaches, model designs, challenges, and future directions. Specifically, we first formulate the SRID problem, and propose a taxonomy of SRID research with a summary of benchmark datasets, commonly-used model architectures, and an analytical review of different methods' characteristics. Then, we elaborate on the design principles of SRID models fro
&lt;/p&gt;</description></item><item><title>HCVP&#26159;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#23545;&#27604;&#35270;&#35273;&#25552;&#31034;&#30340;&#39046;&#22495;&#27867;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#27169;&#22411;&#23558;&#19981;&#21464;&#29305;&#24449;&#19982;&#29305;&#23450;&#29305;&#24449;&#20998;&#31163;&#65292;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.09716</link><description>&lt;p&gt;
HCVP: &#22522;&#20110;&#23618;&#27425;&#23545;&#27604;&#35270;&#35273;&#25552;&#31034;&#30340;&#39046;&#22495;&#27867;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization. (arXiv:2401.09716v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09716
&lt;/p&gt;
&lt;p&gt;
HCVP&#26159;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#23545;&#27604;&#35270;&#35273;&#25552;&#31034;&#30340;&#39046;&#22495;&#27867;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#27169;&#22411;&#23558;&#19981;&#21464;&#29305;&#24449;&#19982;&#29305;&#23450;&#29305;&#24449;&#20998;&#31163;&#65292;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#27867;&#21270;&#65288;DG&#65289;&#26088;&#22312;&#36890;&#36807;&#23398;&#20064;&#19981;&#21464;&#29305;&#24449;&#26469;&#21019;&#24314;&#22312;&#26410;&#30693;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#33394;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22312;DG&#20013;&#65292;&#23558;&#27169;&#22411;&#38480;&#21046;&#22312;&#22266;&#23450;&#32467;&#26500;&#25110;&#32479;&#19968;&#21442;&#25968;&#21270;&#20013;&#20197;&#21253;&#21547;&#19981;&#21464;&#29305;&#24449;&#30340;&#20027;&#27969;&#23454;&#36341;&#21487;&#33021;&#20250;&#19981;&#21487;&#36991;&#20813;&#22320;&#34701;&#21512;&#29305;&#23450;&#26041;&#38754;&#12290;&#36825;&#31181;&#26041;&#27861;&#38590;&#20197;&#23545;&#39046;&#22495;&#38388;&#21464;&#21270;&#36827;&#34892;&#32454;&#24494;&#21306;&#20998;&#65292;&#21487;&#33021;&#23545;&#26576;&#20123;&#39046;&#22495;&#23384;&#22312;&#20559;&#35265;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#23545;&#22495;&#19981;&#21464;&#29305;&#24449;&#30340;&#31934;&#30830;&#23398;&#20064;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#26088;&#22312;&#20026;&#27169;&#22411;&#25552;&#20379;&#39046;&#22495;&#32423;&#21644;&#20219;&#21153;&#29305;&#23450;&#30340;&#29305;&#24449;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#26356;&#26377;&#25928;&#22320;&#24341;&#23548;&#27169;&#22411;&#23558;&#19981;&#21464;&#29305;&#24449;&#19982;&#29305;&#23450;&#29305;&#24449;&#20998;&#31163;&#65292;&#20174;&#32780;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#39046;&#22495;&#27867;&#21270;&#33539;&#24335;&#20013;&#65292;&#20511;&#37492;&#20102;&#35270;&#35273;&#25552;&#31034;&#30340;&#26032;&#36235;&#21183;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#8220;HCVP&#8221;&#65288;&#23618;&#27425;&#23545;&#27604;&#35270;&#35273;&#25552;&#31034;&#65289;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain Generalization (DG) endeavors to create machine learning models that excel in unseen scenarios by learning invariant features. In DG, the prevalent practice of constraining models to a fixed structure or uniform parameterization to encapsulate invariant features can inadvertently blend specific aspects. Such an approach struggles with nuanced differentiation of inter-domain variations and may exhibit bias towards certain domains, hindering the precise learning of domain-invariant features. Recognizing this, we introduce a novel method designed to supplement the model with domain-level and task-specific characteristics. This approach aims to guide the model in more effectively separating invariant features from specific characteristics, thereby boosting the generalization. Building on the emerging trend of visual prompts in the DG paradigm, our work introduces the novel \textbf{H}ierarchical \textbf{C}ontrastive \textbf{V}isual \textbf{P}rompt (HCVP) methodology. This represents 
&lt;/p&gt;</description></item><item><title>GRACE&#26159;&#19968;&#31181;&#21028;&#21035;&#22120;&#24341;&#23548;&#30340;&#24605;&#32500;&#38142;&#25512;&#29702;&#30340;&#36880;&#27493;&#35299;&#30721;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#27491;&#30830;&#24615;&#21028;&#21035;&#22120;&#26469;&#35780;&#20998;&#19979;&#19968;&#27493;&#20505;&#36873;&#65292;&#35299;&#20915;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#27493;&#25512;&#29702;&#20013;&#23481;&#26131;&#24471;&#21040;&#38169;&#35823;&#31572;&#26696;&#30340;&#38382;&#39064;&#12290;&#22312;&#22810;&#20010;&#25968;&#23398;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#20013;&#65292;GRACE&#30456;&#36739;&#20110;&#20854;&#20182;&#26041;&#27861;&#22312;&#24615;&#33021;&#19978;&#26377;&#26126;&#26174;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2305.14934</link><description>&lt;p&gt;
GRACE: &#21028;&#21035;&#22120;&#24341;&#23548;&#30340;&#24605;&#32500;&#38142;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
GRACE: Discriminator-Guided Chain-of-Thought Reasoning. (arXiv:2305.14934v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14934
&lt;/p&gt;
&lt;p&gt;
GRACE&#26159;&#19968;&#31181;&#21028;&#21035;&#22120;&#24341;&#23548;&#30340;&#24605;&#32500;&#38142;&#25512;&#29702;&#30340;&#36880;&#27493;&#35299;&#30721;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#27491;&#30830;&#24615;&#21028;&#21035;&#22120;&#26469;&#35780;&#20998;&#19979;&#19968;&#27493;&#20505;&#36873;&#65292;&#35299;&#20915;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#27493;&#25512;&#29702;&#20013;&#23481;&#26131;&#24471;&#21040;&#38169;&#35823;&#31572;&#26696;&#30340;&#38382;&#39064;&#12290;&#22312;&#22810;&#20010;&#25968;&#23398;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#20013;&#65292;GRACE&#30456;&#36739;&#20110;&#20854;&#20182;&#26041;&#27861;&#22312;&#24615;&#33021;&#19978;&#26377;&#26126;&#26174;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#27493;&#25512;&#29702;&#30340;&#32972;&#26223;&#19979;&#65292;&#20363;&#22914;&#20351;&#29992;&#24605;&#32500;&#38142;&#65292;&#35821;&#35328;&#27169;&#22411;&#24448;&#24448;&#20250;&#23545;&#38169;&#35823;&#30340;&#27493;&#39588;&#20998;&#37197;&#36739;&#39640;&#30340;&#21487;&#33021;&#24615;&#12290;&#22240;&#27492;&#65292;&#20248;&#21270;&#35299;&#20915;&#26041;&#26696;&#21487;&#33021;&#24615;&#30340;&#35299;&#30721;&#31574;&#30053;&#24448;&#24448;&#20250;&#20135;&#29983;&#38169;&#35823;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;GRACE&#30340;&#24341;&#23548;&#24605;&#32500;&#38142;&#25512;&#29702;&#30340;&#36880;&#27493;&#35299;&#30721;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#19968;&#20010;&#27491;&#30830;&#24615;&#21028;&#21035;&#22120;&#35757;&#32451;&#26469;&#24341;&#23548;&#35299;&#30721;&#36807;&#31243;&#20135;&#29983;&#27491;&#30830;&#30340;&#25512;&#29702;&#27493;&#39588;&#12290;GRACE&#20351;&#29992;&#19968;&#20010;&#22312;&#27491;&#30830;&#21644;&#38169;&#35823;&#27493;&#39588;&#19978;&#36827;&#34892;&#23545;&#27604;&#25439;&#22833;&#35757;&#32451;&#30340;&#21028;&#21035;&#22120;&#65292;&#35813;&#21028;&#21035;&#22120;&#22312;&#35299;&#30721;&#36807;&#31243;&#20013;&#22522;&#20110;&#27491;&#30830;&#24615;&#23545;&#19979;&#19968;&#27493;&#20505;&#36873;&#36827;&#34892;&#35780;&#20998;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;GRACE&#21482;&#38656;&#35201;&#20174;&#35821;&#35328;&#27169;&#22411;&#20013;&#37319;&#26679;&#65292;&#32780;&#19981;&#38656;&#35201;&#36827;&#34892;&#35821;&#35328;&#27169;&#22411;&#30340;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;&#25105;&#20204;&#20351;&#29992;FLAN-T5&#21644;LLaMA&#31995;&#21015;&#30340;&#27169;&#22411;&#65292;&#23545;&#22235;&#20010;&#25968;&#23398;&#21644;&#20004;&#20010;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#36827;&#34892;&#20102;GRACE&#30340;&#35780;&#20272;&#65292;&#22312;&#22823;&#22810;&#25968;&#35774;&#32622;&#20013;&#65292;&#19982;&#36138;&#23146;&#35299;&#30721;&#12289;&#39564;&#35777;&#22120;&#21644;&#33258;&#19968;&#33268;&#24615;&#30456;&#27604;&#65292;GRACE&#23637;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the context of multi-step reasoning, e.g., with chain-of-thought, language models (LMs) can easily assign a high likelihood to incorrect steps. As a result, decoding strategies that optimize for solution likelihood often yield incorrect solutions. To address this issue, we propose Guiding chain-of-thought ReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise decoding approach that steers the decoding process towards producing correct reasoning steps. GRACE employs a discriminator trained with a contrastive loss over correct and incorrect steps, which is used during decoding to score next-step candidates based on their correctness. Importantly, GRACE only requires sampling from the LM, without the need for LM training or fine-tuning. Using models from FLAN-T5 and LLaMA families, we evaluate GRACE over four math and two symbolic reasoning tasks, where it exhibits substantial performance gains compared to greedy decoding, verifiers, and self-consistency in most settings. When 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;RemOve-And-Retrain&#65288;ROAR&#65289;&#21327;&#35758;&#30340;&#21487;&#38752;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;ROAR&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#23646;&#24615;&#21487;&#33021;&#26377;&#26356;&#23569;&#30340;&#26377;&#20851;&#20915;&#31574;&#30340;&#37325;&#35201;&#20449;&#24687;&#65292;&#36825;&#31181;&#20559;&#24046;&#31216;&#20026;&#27611;&#31961;&#24230;&#20559;&#24046;&#65292;&#24182;&#25552;&#37266;&#20154;&#20204;&#19981;&#35201;&#22312;ROAR&#25351;&#26631;&#19978;&#36827;&#34892;&#30450;&#30446;&#30340;&#20381;&#36182;&#12290;</title><link>http://arxiv.org/abs/2304.13836</link><description>&lt;p&gt;
&#35770;RemOve-And-Retrain&#30340;&#38519;&#38449;&#65306;&#25968;&#25454;&#22788;&#29702;&#19981;&#31561;&#24335;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
On Pitfalls of $\textit{RemOve-And-Retrain}$: Data Processing Inequality Perspective. (arXiv:2304.13836v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;RemOve-And-Retrain&#65288;ROAR&#65289;&#21327;&#35758;&#30340;&#21487;&#38752;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;ROAR&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#23646;&#24615;&#21487;&#33021;&#26377;&#26356;&#23569;&#30340;&#26377;&#20851;&#20915;&#31574;&#30340;&#37325;&#35201;&#20449;&#24687;&#65292;&#36825;&#31181;&#20559;&#24046;&#31216;&#20026;&#27611;&#31961;&#24230;&#20559;&#24046;&#65292;&#24182;&#25552;&#37266;&#20154;&#20204;&#19981;&#35201;&#22312;ROAR&#25351;&#26631;&#19978;&#36827;&#34892;&#30450;&#30446;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;RemOve-And-Retrain&#65288;ROAR&#65289;&#21327;&#35758;&#30340;&#21487;&#38752;&#24615;&#65292;&#35813;&#21327;&#35758;&#29992;&#20110;&#27979;&#37327;&#29305;&#24449;&#37325;&#35201;&#24615;&#20272;&#35745;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#32972;&#26223;&#21644;&#23454;&#35777;&#23454;&#39564;&#20013;&#21457;&#29616;&#65292;&#20855;&#26377;&#36739;&#23569;&#26377;&#20851;&#20915;&#31574;&#21151;&#33021;&#30340;&#20449;&#24687;&#30340;&#23646;&#24615;&#22312;ROAR&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#26356;&#22909;&#65292;&#19982;ROAR&#30340;&#21407;&#22987;&#30446;&#30340;&#30456;&#30683;&#30462;&#12290;&#36825;&#31181;&#29616;&#35937;&#20063;&#20986;&#29616;&#22312;&#26368;&#36817;&#25552;&#20986;&#30340;&#21464;&#20307;RemOve-And-Debias&#65288;ROAD&#65289;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ROAR&#24402;&#22240;&#24230;&#37327;&#20013;&#27611;&#31961;&#24230;&#20559;&#24046;&#30340;&#19968;&#33268;&#36235;&#21183;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#37266;&#20154;&#20204;&#19981;&#35201;&#30450;&#30446;&#20381;&#36182;ROAR&#30340;&#24615;&#33021;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper assesses the reliability of the RemOve-And-Retrain (ROAR) protocol, which is used to measure the performance of feature importance estimates. Our findings from the theoretical background and empirical experiments indicate that attributions that possess less information about the decision function can perform better in ROAR benchmarks, conflicting with the original purpose of ROAR. This phenomenon is also observed in the recently proposed variant RemOve-And-Debias (ROAD), and we propose a consistent trend of blurriness bias in ROAR attribution metrics. Our results caution against uncritical reliance on ROAR metrics.
&lt;/p&gt;</description></item></channel></rss>