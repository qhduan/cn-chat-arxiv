<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#24212;&#29992;&#39537;&#21160;&#30740;&#31350;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#21487;&#20197;&#19982;&#26041;&#27861;&#39537;&#21160;&#30740;&#31350;&#26377;&#30410;&#22320;&#21327;&#21516;&#65292;&#20294;&#30446;&#21069;&#23457;&#26597;&#12289;&#25307;&#32856;&#21644;&#25945;&#23398;&#23454;&#36341;&#24448;&#24448;&#38459;&#30861;&#20102;&#36825;&#31181;&#21019;&#26032;&#12290;</title><link>https://arxiv.org/abs/2403.17381</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#39537;&#21160;&#21019;&#26032;
&lt;/p&gt;
&lt;p&gt;
Application-Driven Innovation in Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17381
&lt;/p&gt;
&lt;p&gt;
&#24212;&#29992;&#39537;&#21160;&#30740;&#31350;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#21487;&#20197;&#19982;&#26041;&#27861;&#39537;&#21160;&#30740;&#31350;&#26377;&#30410;&#22320;&#21327;&#21516;&#65292;&#20294;&#30446;&#21069;&#23457;&#26597;&#12289;&#25307;&#32856;&#21644;&#25945;&#23398;&#23454;&#36341;&#24448;&#24448;&#38459;&#30861;&#20102;&#36825;&#31181;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#19981;&#26029;&#22686;&#38271;&#65292;&#21463;&#29305;&#23450;&#29616;&#23454;&#25361;&#25112;&#21551;&#21457;&#30340;&#21019;&#26032;&#31639;&#27861;&#21464;&#24471;&#26085;&#30410;&#37325;&#35201;&#12290;&#36825;&#26679;&#30340;&#24037;&#20316;&#19981;&#20165;&#22312;&#24212;&#29992;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#20063;&#22312;&#26426;&#22120;&#23398;&#20064;&#26412;&#36523;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#39537;&#21160;&#30740;&#31350;&#30340;&#33539;&#24335;&#65292;&#23558;&#20854;&#19982;&#26356;&#26631;&#20934;&#30340;&#26041;&#27861;&#39537;&#21160;&#30740;&#31350;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#24212;&#29992;&#39537;&#21160;&#26426;&#22120;&#23398;&#20064;&#30340;&#22909;&#22788;&#65292;&#20197;&#21450;&#36825;&#31181;&#26041;&#27861;&#22914;&#20309;&#21487;&#20197;&#19982;&#26041;&#27861;&#39537;&#21160;&#24037;&#20316;&#26377;&#30410;&#22320;&#21327;&#21516;&#12290;&#23613;&#31649;&#20855;&#26377;&#36825;&#20123;&#22909;&#22788;&#65292;&#25105;&#20204;&#21457;&#29616;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#23457;&#26597;&#12289;&#25307;&#32856;&#21644;&#25945;&#23398;&#23454;&#36341;&#24448;&#24448;&#38459;&#30861;&#20102;&#24212;&#29992;&#39537;&#21160;&#21019;&#26032;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#22914;&#20309;&#25913;&#36827;&#36825;&#20123;&#27969;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17381v1 Announce Type: cross  Abstract: As applications of machine learning proliferate, innovative algorithms inspired by specific real-world challenges have become increasingly important. Such work offers the potential for significant impact not merely in domains of application but also in machine learning itself. In this paper, we describe the paradigm of application-driven research in machine learning, contrasting it with the more standard paradigm of methods-driven research. We illustrate the benefits of application-driven machine learning and how this approach can productively synergize with methods-driven work. Despite these benefits, we find that reviewing, hiring, and teaching practices in machine learning often hold back application-driven innovation. We outline how these processes may be improved.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21327;&#21516;&#24863;&#30693;&#27169;&#22411;&#21644;&#35777;&#25454;&#29702;&#35770;&#26694;&#26550;&#19979;&#30340;&#32452;&#21512;&#35268;&#21017;&#65292;&#26469;&#25552;&#39640;WSNs&#26816;&#27979;&#33021;&#21147;&#30340;&#23398;&#20064;&#22411;&#20256;&#24863;&#22120;&#37096;&#32626;&#32593;&#32476;&#65288;LSDNet&#65289;&#12290;</title><link>https://arxiv.org/abs/2403.15728</link><description>&lt;p&gt;
&#21487;&#23398;&#20064;&#30340;&#35777;&#25454;&#21327;&#21516;&#24863;&#30693;&#27169;&#22411;&#30340;WSN&#37096;&#32626;
&lt;/p&gt;
&lt;p&gt;
Learnable WSN Deployment of Evidential Collaborative Sensing Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21327;&#21516;&#24863;&#30693;&#27169;&#22411;&#21644;&#35777;&#25454;&#29702;&#35770;&#26694;&#26550;&#19979;&#30340;&#32452;&#21512;&#35268;&#21017;&#65292;&#26469;&#25552;&#39640;WSNs&#26816;&#27979;&#33021;&#21147;&#30340;&#23398;&#20064;&#22411;&#20256;&#24863;&#22120;&#37096;&#32626;&#32593;&#32476;&#65288;LSDNet&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#32447;&#20256;&#24863;&#22120;&#32593;&#32476;&#65288;WSNs&#65289;&#20013;&#65292;&#35206;&#30422;&#21644;&#37096;&#32626;&#26159;&#36827;&#34892;&#26816;&#27979;&#20219;&#21153;&#26102;&#26368;&#20851;&#38190;&#30340;&#20004;&#20010;&#38382;&#39064;&#12290;&#20294;&#36890;&#24120;&#26469;&#33258;&#20256;&#24863;&#22120;&#30340;&#26816;&#27979;&#20449;&#24687;&#24182;&#27809;&#26377;&#34987;&#20805;&#20998;&#21033;&#29992;&#21644;&#39640;&#25928;&#25972;&#21512;&#12290;&#26412;&#25991;&#26088;&#22312;&#23454;&#29616;WSN&#37096;&#32626;&#30340;&#26368;&#20339;&#35206;&#30422;&#36136;&#37327;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#20256;&#24863;&#22120;&#30340;&#21327;&#21516;&#24863;&#30693;&#27169;&#22411;&#65292;&#21033;&#29992;&#35777;&#25454;&#29702;&#35770;&#26694;&#26550;&#19979;&#30340;&#32452;&#21512;&#35268;&#21017;&#24471;&#21040;&#30340;&#21327;&#21516;&#20449;&#24687;&#26469;&#22686;&#24378;WSNs&#30340;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15728v1 Announce Type: new  Abstract: In wireless sensor networks (WSNs), coverage and deployment are two most crucial issues when conducting detection tasks. However, the detection information collected from sensors is oftentimes not fully utilized and efficiently integrated. Such sensing model and deployment strategy, thereby, cannot reach the maximum quality of coverage, particularly when the amount of sensors within WSNs expands significantly. In this article, we aim at achieving the optimal coverage quality of WSN deployment. We develop a collaborative sensing model of sensors to enhance detection capabilities of WSNs, by leveraging the collaborative information derived from the combination rule under the framework of evidence theory. In this model, the performance evaluation of evidential fusion systems is adopted as the criterion of the sensor selection. A learnable sensor deployment network (LSDNet) considering both sensor contribution and detection capability, is pr
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#36523;&#26426;&#22120;&#20154;&#23398;&#20064;&#20195;&#29702;NBCagent&#65292;&#36890;&#36807;&#25216;&#33021;&#29305;&#23450;&#30340;&#28436;&#21270;&#35268;&#21010;&#22120;&#21644;&#25216;&#33021;&#20849;&#20139;&#30340;&#35821;&#20041;&#28210;&#26579;&#27169;&#22359;&#65292;&#23454;&#29616;&#20174;&#35270;&#35273;&#35266;&#27979;&#20013;&#36830;&#32493;&#23398;&#20064;&#26032;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#25216;&#33021;&#30693;&#35782;&#12290;</title><link>https://arxiv.org/abs/2403.00336</link><description>&lt;p&gt;
&#27704;&#19981;&#20572;&#27490;&#30340;&#20855;&#36523;&#26426;&#22120;&#20154;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Never-Ending Embodied Robot Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00336
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#36523;&#26426;&#22120;&#20154;&#23398;&#20064;&#20195;&#29702;NBCagent&#65292;&#36890;&#36807;&#25216;&#33021;&#29305;&#23450;&#30340;&#28436;&#21270;&#35268;&#21010;&#22120;&#21644;&#25216;&#33021;&#20849;&#20139;&#30340;&#35821;&#20041;&#28210;&#26579;&#27169;&#22359;&#65292;&#23454;&#29616;&#20174;&#35270;&#35273;&#35266;&#27979;&#20013;&#36830;&#32493;&#23398;&#20064;&#26032;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#25216;&#33021;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20381;&#36182;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#20855;&#36523;&#26426;&#22120;&#20154;&#21487;&#20197;&#36890;&#36807;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20174;&#35270;&#35273;&#35266;&#27979;&#20013;&#25191;&#34892;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#26426;&#22120;&#20154;&#25805;&#20316;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#35270;&#35273;&#34892;&#20026;&#20811;&#38534;&#20195;&#29702;&#22312;&#36866;&#24212;&#19968;&#31995;&#21015;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26410;&#35265;&#20219;&#21153;&#26102;&#65292;&#20250;&#36973;&#21463;&#25805;&#32437;&#24615;&#33021;&#19979;&#38477;&#20197;&#21450;&#25216;&#33021;&#30693;&#35782;&#36951;&#24536;&#30340;&#22256;&#25200;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;NBCagent&#22312;&#20855;&#36523;&#26426;&#22120;&#20154;&#20013;&#25506;&#35752;&#20102;&#19978;&#36848;&#25361;&#25112;&#65292;&#36825;&#26159;&#19968;&#31181;&#24320;&#21019;&#24615;&#30340;&#12289;&#20197;&#35821;&#35328;&#20026;&#26465;&#20214;&#30340;&#27704;&#19981;&#20572;&#27490;&#34892;&#20026;&#20811;&#38534;&#20195;&#29702;&#65292;&#21487;&#20197;&#19981;&#26029;&#20174;&#29305;&#23450;&#25216;&#33021;&#21644;&#20849;&#20139;&#25216;&#33021;&#23646;&#24615;&#20013;&#23398;&#20064;&#26032;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#25216;&#33021;&#30340;&#35266;&#23519;&#30693;&#35782;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#29305;&#23450;&#25216;&#33021;&#19981;&#26029;&#28436;&#21270;&#30340;&#35268;&#21010;&#22120;&#26469;&#36827;&#34892;&#30693;&#35782;&#35299;&#32806;&#65292;&#36825;&#21487;&#20197;&#20174;&#28508;&#22312;&#21644;&#20302;&#31209;&#31354;&#38388;&#20013;&#19981;&#26029;&#21521;&#25105;&#20204;&#30340;NBCagent&#20195;&#29702;&#23884;&#20837;&#26032;&#30340;&#25216;&#33021;&#29305;&#23450;&#30693;&#35782;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25216;&#33021;&#20849;&#20139;&#35821;&#20041;&#28210;&#26579;&#27169;&#22359;&#21644;&#19968;&#20010;&#25216;&#33021;&#20849;&#20139;&#34920;&#31034;&#21306;&#20998;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00336v1 Announce Type: cross  Abstract: Relying on large language models (LLMs), embodied robots could perform complex multimodal robot manipulation tasks from visual observations with powerful generalization ability. However, most visual behavior-cloning agents suffer from manipulation performance degradation and skill knowledge forgetting when adapting into a series of challenging unseen tasks. We here investigate the above challenge with NBCagent in embodied robots, a pioneering language-conditioned Never-ending Behavior-Cloning agent, which can continually learn observation knowledge of novel robot manipulation skills from skill-specific and skill-shared attributes. Specifically, we establish a skill-specific evolving planner to perform knowledge decoupling, which can continually embed novel skill-specific knowledge in our NBCagent agent from latent and low-rank space. Meanwhile, we propose a skill-shared semantics rendering module and a skill-shared representation disti
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;AI&#20195;&#29702;&#29992;&#20110;&#20219;&#21153;&#35268;&#21010;&#21644;&#24037;&#20855;&#20351;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#26694;&#26550;&#65292;&#35774;&#35745;&#20102;&#20004;&#31181;&#20195;&#29702;&#26469;&#25191;&#34892;&#25512;&#29702;&#36807;&#31243;&#65292;&#23454;&#20363;&#21270;&#20102;&#26694;&#26550;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#20219;&#21153;&#35268;&#21010;&#21644;&#24037;&#20855;&#20351;&#29992;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.03427</link><description>&lt;p&gt;
TPTU: &#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;AI&#20195;&#29702;&#29992;&#20110;&#20219;&#21153;&#35268;&#21010;&#21644;&#24037;&#20855;&#20351;&#29992;
&lt;/p&gt;
&lt;p&gt;
TPTU: Large Language Model-based AI Agents for Task Planning and Tool Usage. (arXiv:2308.03427v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03427
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;AI&#20195;&#29702;&#29992;&#20110;&#20219;&#21153;&#35268;&#21010;&#21644;&#24037;&#20855;&#20351;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#26694;&#26550;&#65292;&#35774;&#35745;&#20102;&#20004;&#31181;&#20195;&#29702;&#26469;&#25191;&#34892;&#25512;&#29702;&#36807;&#31243;&#65292;&#23454;&#20363;&#21270;&#20102;&#26694;&#26550;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#20219;&#21153;&#35268;&#21010;&#21644;&#24037;&#20855;&#20351;&#29992;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#23613;&#31649;&#23427;&#20204;&#38750;&#24120;&#24378;&#22823;&#65292;&#20294;&#26159;LLMs&#30340;&#20869;&#22312;&#29983;&#25104;&#33021;&#21147;&#21487;&#33021;&#19981;&#36275;&#20197;&#22788;&#29702;&#22797;&#26434;&#30340;&#20219;&#21153;&#65292;&#36825;&#20123;&#20219;&#21153;&#38656;&#35201;&#32467;&#21512;&#20219;&#21153;&#35268;&#21010;&#21644;&#22806;&#37096;&#24037;&#20855;&#30340;&#20351;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#38376;&#20026;LLM-based AI Agents&#37327;&#36523;&#23450;&#21046;&#30340;&#32467;&#26500;&#26694;&#26550;&#65292;&#24182;&#35752;&#35770;&#20102;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#25152;&#24517;&#38656;&#30340;&#20851;&#38190;&#33021;&#21147;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#20195;&#29702;&#65288;&#21363;&#19968;&#27493;&#20195;&#29702;&#21644;&#36830;&#32493;&#20195;&#29702;&#65289;&#26469;&#25191;&#34892;&#25512;&#29702;&#36807;&#31243;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;LLMs&#23454;&#20363;&#21270;&#20102;&#36825;&#20010;&#26694;&#26550;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#22312;&#20856;&#22411;&#20219;&#21153;&#20013;&#30340;&#20219;&#21153;&#35268;&#21010;&#21644;&#24037;&#20855;&#20351;&#29992;&#33021;&#21147;&#12290;&#36890;&#36807;&#24378;&#35843;&#20851;&#38190;&#21457;&#29616;&#21644;&#25361;&#25112;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#25552;&#20379;&#19968;&#20010;&#26377;&#21161;&#20110;&#22312;&#20182;&#20204;&#30340;AI&#24212;&#29992;&#20013;&#21457;&#25381;LLMs&#33021;&#21147;&#30340;&#26377;&#29992;&#36164;&#28304;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;
&lt;/p&gt;
&lt;p&gt;
With recent advancements in natural language processing, Large Language Models (LLMs) have emerged as powerful tools for various real-world applications. Despite their prowess, the intrinsic generative abilities of LLMs may prove insufficient for handling complex tasks which necessitate a combination of task planning and the usage of external tools. In this paper, we first propose a structured framework tailored for LLM-based AI Agents and discuss the crucial capabilities necessary for tackling intricate problems. Within this framework, we design two distinct types of agents (i.e., one-step agent and sequential agent) to execute the inference process. Subsequently, we instantiate the framework using various LLMs and evaluate their Task Planning and Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings and challenges, our goal is to provide a helpful resource for researchers and practitioners to leverage the power of LLMs in their AI applications. Our study emphasiz
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#22797;&#26434;&#24615;&#21644;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#25216;&#26415;HouYi&#65292;&#24182;&#25581;&#31034;&#20102;&#24212;&#29992;&#31243;&#24207;&#25552;&#31034;&#26426;&#21046;&#20013;&#20197;&#21069;&#26410;&#30693;&#21644;&#20005;&#37325;&#20302;&#20272;&#30340;&#28431;&#27934;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21628;&#21505;&#36827;&#19968;&#27493;&#24320;&#21457;&#20840;&#38754;&#30340;&#38450;&#24481;&#25514;&#26045;&#65292;&#20197;&#25269;&#24481;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2306.05499</link><description>&lt;p&gt;
LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Prompt Injection attack against LLM-integrated Applications. (arXiv:2306.05499v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#22797;&#26434;&#24615;&#21644;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#25216;&#26415;HouYi&#65292;&#24182;&#25581;&#31034;&#20102;&#24212;&#29992;&#31243;&#24207;&#25552;&#31034;&#26426;&#21046;&#20013;&#20197;&#21069;&#26410;&#30693;&#21644;&#20005;&#37325;&#20302;&#20272;&#30340;&#28431;&#27934;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21628;&#21505;&#36827;&#19968;&#27493;&#24320;&#21457;&#20840;&#38754;&#30340;&#38450;&#24481;&#25514;&#26045;&#65292;&#20197;&#25269;&#24481;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#22240;&#20854;&#21331;&#36234;&#30340;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#32780;&#22312;&#23427;&#20204;&#21608;&#22260;&#21050;&#28608;&#20102;&#19968;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#24212;&#29992;&#29983;&#24577;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#21508;&#31181;&#26381;&#21153;&#20013;&#30340;&#24191;&#27867;&#34701;&#21512;&#24102;&#26469;&#20102;&#37325;&#22823;&#30340;&#23433;&#20840;&#39118;&#38505;&#12290;&#26412;&#30740;&#31350;&#23558;&#35299;&#26500;&#23454;&#38469;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#22797;&#26434;&#24615;&#21644;&#24433;&#21709;&#12290;&#26368;&#21021;&#65292;&#25105;&#20204;&#23545;&#21313;&#20010;&#21830;&#19994;&#24212;&#29992;&#31243;&#24207;&#36827;&#34892;&#20102;&#25506;&#32034;&#24615;&#20998;&#26512;&#65292;&#31361;&#20986;&#20102;&#30446;&#21069;&#25915;&#20987;&#31574;&#30053;&#22312;&#23454;&#36341;&#20013;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290;&#21463;&#36825;&#20123;&#38480;&#21046;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#38543;&#21518;&#21046;&#23450;&#20102;HouYi&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#25216;&#26415;&#65292;&#23427;&#20511;&#37492;&#20102;&#20256;&#32479;&#30340;Web&#27880;&#20837;&#25915;&#20987;&#12290;HouYi&#20998;&#20026;&#19977;&#20010;&#20851;&#38190;&#20803;&#32032;: &#19968;&#20010;&#26080;&#32541;&#38598;&#25104;&#30340;&#39044;&#26500;&#24314;&#25552;&#31034;&#12289;&#19968;&#20010;&#27880;&#20837;&#25552;&#31034;&#35825;&#23548;&#19978;&#19979;&#25991;&#20998;&#21306;&#20197;&#21450;&#19968;&#20010;&#24694;&#24847;&#36733;&#33655;&#65292;&#26088;&#22312;&#23454;&#29616;&#25915;&#20987;&#30446;&#26631;&#12290;&#21033;&#29992;HouYi&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#24212;&#29992;&#31243;&#24207;&#25552;&#31034;&#26426;&#21046;&#20013;&#20197;&#21069;&#26410;&#30693;&#21644;&#20005;&#37325;&#20302;&#20272;&#30340;&#28431;&#27934;&#65292;&#24182;&#28436;&#31034;&#20102;&#32469;&#36807;&#26368;&#20808;&#36827;&#30340;&#26816;&#27979;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21628;&#21505;&#36827;&#19968;&#27493;&#30740;&#31350;&#24320;&#21457;&#20840;&#38754;&#30340;&#38450;&#24481;&#25514;&#26045;&#65292;&#20197;&#25269;&#24481;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and sev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#20998;&#25955;&#31574;&#30053;&#30340;MARL&#31639;&#27861;&#22312;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#19979;&#30340;&#27425;&#26368;&#20248;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36716;&#21270;&#19982;&#33976;&#39311;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#23558;&#22810;&#26234;&#33021;&#20307;MDP&#36716;&#21270;&#20026;&#21333;&#26234;&#33021;&#20307;MDP&#20197;&#23454;&#29616;&#20998;&#25955;&#25191;&#34892;&#12290;</title><link>http://arxiv.org/abs/2207.11143</link><description>&lt;p&gt;
&#12298;&#37319;&#29992;&#36716;&#21270;&#19982;&#33976;&#39311;&#26694;&#26550;&#23454;&#29616;&#21512;&#20316;MARL&#20840;&#23616;&#26368;&#20248;&#24615;&#12299;
&lt;/p&gt;
&lt;p&gt;
Towards Global Optimality in Cooperative MARL with the Transformation And Distillation Framework. (arXiv:2207.11143v3 [cs.MA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#20998;&#25955;&#31574;&#30053;&#30340;MARL&#31639;&#27861;&#22312;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#19979;&#30340;&#27425;&#26368;&#20248;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36716;&#21270;&#19982;&#33976;&#39311;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#23558;&#22810;&#26234;&#33021;&#20307;MDP&#36716;&#21270;&#20026;&#21333;&#26234;&#33021;&#20307;MDP&#20197;&#23454;&#29616;&#20998;&#25955;&#25191;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#20998;&#25955;&#25191;&#34892;&#26159;&#19968;&#39033;&#26680;&#24515;&#38656;&#27714;&#12290;&#30446;&#21069;&#65292;&#22823;&#22810;&#25968;&#27969;&#34892;&#30340;MARL&#31639;&#27861;&#37319;&#29992;&#20998;&#25955;&#31574;&#30053;&#26469;&#23454;&#29616;&#20998;&#25955;&#25191;&#34892;&#65292;&#24182;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#20316;&#20026;&#20248;&#21270;&#22120;&#12290;&#28982;&#32780;&#65292;&#22312;&#32771;&#34385;&#21040;&#20248;&#21270;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#31639;&#27861;&#20960;&#20046;&#27809;&#26377;&#20219;&#20309;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#26799;&#24230;&#19979;&#38477;&#34987;&#36873;&#20026;&#20248;&#21270;&#26041;&#27861;&#26102;&#65292;&#21508;&#31181;&#27969;&#34892;&#30340;&#20998;&#25955;&#31574;&#30053;MARL&#31639;&#27861;&#22312;&#29609;&#20855;&#20219;&#21153;&#20013;&#37117;&#26159;&#27425;&#26368;&#20248;&#30340;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#20004;&#31181;&#24120;&#35265;&#30340;&#37319;&#29992;&#20998;&#25955;&#31574;&#30053;&#30340;&#31639;&#27861;&#8212;&#8212;&#22810;&#26234;&#33021;&#20307;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#21644;&#20540;&#20998;&#35299;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26102;&#30340;&#27425;&#26368;&#20248;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36716;&#21270;&#19982;&#33976;&#39311;&#65288;TAD&#65289;&#26694;&#26550;&#65292;&#23427;&#23558;&#22810;&#26234;&#33021;&#20307;MDP&#37325;&#26032;&#21046;&#23450;&#20026;&#19968;&#31181;&#20855;&#26377;&#36830;&#32493;&#32467;&#26500;&#30340;&#29305;&#27530;&#21333;&#26234;&#33021;&#20307;MDP&#65292;&#24182;&#36890;&#36807;&#33976;&#39311;&#23454;&#29616;&#20998;&#25955;&#25191;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decentralized execution is one core demand in cooperative multi-agent reinforcement learning (MARL). Recently, most popular MARL algorithms have adopted decentralized policies to enable decentralized execution and use gradient descent as their optimizer. However, there is hardly any theoretical analysis of these algorithms taking the optimization method into consideration, and we find that various popular MARL algorithms with decentralized policies are suboptimal in toy tasks when gradient descent is chosen as their optimization method. In this paper, we theoretically analyze two common classes of algorithms with decentralized policies -- multi-agent policy gradient methods and value-decomposition methods to prove their suboptimality when gradient descent is used. In addition, we propose the Transformation And Distillation (TAD) framework, which reformulates a multi-agent MDP as a special single-agent MDP with a sequential structure and enables decentralized execution by distilling the
&lt;/p&gt;</description></item></channel></rss>