<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#28145;&#24230;&#25903;&#25345;&#21521;&#37327;&#65288;DSVs&#65289;&#30340;&#27010;&#24565;&#65292;&#20171;&#32461;&#20102;DeepKKT&#26465;&#20214;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;DSVs&#19982;SVM&#20013;&#30340;&#25903;&#25345;&#21521;&#37327;&#31867;&#20284;&#65292;&#20026;&#35299;&#37322;&#27169;&#22411;&#20915;&#31574;&#26631;&#20934;&#25552;&#20379;&#20102;&#26041;&#27861;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#21487;&#20197;&#26377;&#25928;&#22320;&#20351;&#29992;DSVs&#37325;&#26500;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.17329</link><description>&lt;p&gt;
&#28145;&#24230;&#25903;&#25345;&#21521;&#37327;
&lt;/p&gt;
&lt;p&gt;
Deep Support Vectors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17329
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#28145;&#24230;&#25903;&#25345;&#21521;&#37327;&#65288;DSVs&#65289;&#30340;&#27010;&#24565;&#65292;&#20171;&#32461;&#20102;DeepKKT&#26465;&#20214;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;DSVs&#19982;SVM&#20013;&#30340;&#25903;&#25345;&#21521;&#37327;&#31867;&#20284;&#65292;&#20026;&#35299;&#37322;&#27169;&#22411;&#20915;&#31574;&#26631;&#20934;&#25552;&#20379;&#20102;&#26041;&#27861;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#21487;&#20197;&#26377;&#25928;&#22320;&#20351;&#29992;DSVs&#37325;&#26500;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#30340;&#25104;&#21151;&#36890;&#24120;&#34987;&#24402;&#22240;&#20110;&#20854;&#19982;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#22312;&#29702;&#35770;&#19978;&#30340;&#31561;&#20215;&#24615;&#65292;&#20294;&#36825;&#31181;&#20851;&#31995;&#30340;&#23454;&#38469;&#24433;&#21709;&#23578;&#26410;&#24471;&#21040;&#20840;&#38754;&#25506;&#35752;&#12290;&#26412;&#25991;&#22312;&#36825;&#19968;&#39046;&#22495;&#24320;&#23637;&#20102;&#19968;&#39033;&#25506;&#32034;&#65292;&#37325;&#28857;&#20851;&#27880;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#28145;&#24230;&#25903;&#25345;&#21521;&#37327;&#65288;DSVs&#65289;&#30340;&#35782;&#21035;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;DeepKKT&#26465;&#20214;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#19968;&#31181;&#19987;&#20026;&#28145;&#24230;&#23398;&#20064;&#37327;&#36523;&#23450;&#21046;&#30340;&#20256;&#32479;Karush-Kuhn-Tucker&#65288;KKT&#65289;&#26465;&#20214;&#30340;&#35843;&#25972;&#29256;&#26412;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;DSVs&#19982;SVM&#20013;&#30340;&#25903;&#25345;&#21521;&#37327;&#20043;&#38388;&#23384;&#22312;&#30456;&#20284;&#24615;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#37322;&#27169;&#22411;&#20915;&#31574;&#26631;&#20934;&#30340;&#20999;&#23454;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20351;&#29992;DSVs&#37325;&#26500;&#27169;&#22411;&#65292;&#31867;&#20284;&#20110;SVM&#20013;&#30340;&#36807;&#31243;&#12290;&#20195;&#30721;&#23558;&#20250;&#20844;&#24320;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17329v1 Announce Type: cross  Abstract: While the success of deep learning is commonly attributed to its theoretical equivalence with Support Vector Machines (SVM), the practical implications of this relationship have not been thoroughly explored. This paper pioneers an exploration in this domain, specifically focusing on the identification of Deep Support Vectors (DSVs) within deep learning models. We introduce the concept of DeepKKT conditions, an adaptation of the traditional Karush-Kuhn-Tucker (KKT) conditions tailored for deep learning. Through empirical investigations, we illustrate that DSVs exhibit similarities to support vectors in SVM, offering a tangible method to interpret the decision-making criteria of models. Additionally, our findings demonstrate that models can be effectively reconstructed using DSVs, resembling the process in SVM. The code will be available.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Brain-inspired and Self-based Artificial Intelligence&#65288;BriSe AI&#65289;&#30340;&#26032;&#20154;&#24037;&#26234;&#33021;&#33539;&#24335;&#65292;&#36890;&#36807;&#33258;&#25105;&#32452;&#32455;&#30340;&#26041;&#24335;&#21327;&#35843;&#21508;&#31181;&#35748;&#30693;&#21151;&#33021;&#21644;&#23398;&#20064;&#31574;&#30053;&#65292;&#20197;&#26500;&#24314;&#20154;&#31867;&#27700;&#24179;&#30340;AI&#27169;&#22411;&#21644;&#26426;&#22120;&#20154;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.18784</link><description>&lt;p&gt;
&#22823;&#33041;&#21551;&#21457;&#21644;&#22522;&#20110;&#33258;&#25105;&#30340;&#20154;&#24037;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
Brain-inspired and Self-based Artificial Intelligence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18784
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Brain-inspired and Self-based Artificial Intelligence&#65288;BriSe AI&#65289;&#30340;&#26032;&#20154;&#24037;&#26234;&#33021;&#33539;&#24335;&#65292;&#36890;&#36807;&#33258;&#25105;&#32452;&#32455;&#30340;&#26041;&#24335;&#21327;&#35843;&#21508;&#31181;&#35748;&#30693;&#21151;&#33021;&#21644;&#23398;&#20064;&#31574;&#30053;&#65292;&#20197;&#26500;&#24314;&#20154;&#31867;&#27700;&#24179;&#30340;AI&#27169;&#22411;&#21644;&#26426;&#22120;&#20154;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25361;&#25112;&#20102;&#24403;&#21069;AI&#30340;&#25903;&#25345;&#32773;&#25152;&#35859; "&#24605;&#32771;&#26426;&#22120;" &#30340;&#35266;&#24565;&#65292;&#22240;&#20026;&#23427;&#20204;&#32570;&#20047;&#33258;&#25105;&#24847;&#35782;&#12290;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Brain-inspired and Self-based Artificial Intelligence&#65288;BriSe AI&#65289;&#30340;&#26032;&#20154;&#24037;&#26234;&#33021;&#33539;&#24335;&#65292;&#26088;&#22312;&#36890;&#36807;&#33258;&#25105;&#32452;&#32455;&#30340;&#26041;&#24335;&#21327;&#35843;&#21508;&#31181;&#35748;&#30693;&#21151;&#33021;&#21644;&#23398;&#20064;&#31574;&#30053;&#65292;&#26500;&#24314;&#20154;&#31867;&#27700;&#24179;&#30340;AI&#27169;&#22411;&#21644;&#26426;&#22120;&#20154;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18784v1 Announce Type: new  Abstract: The question "Can machines think?" and the Turing Test to assess whether machines could achieve human-level intelligence is one of the roots of AI. With the philosophical argument "I think, therefore I am", this paper challenge the idea of a "thinking machine" supported by current AIs since there is no sense of self in them. Current artificial intelligence is only seemingly intelligent information processing and does not truly understand or be subjectively aware of oneself and perceive the world with the self as human intelligence does. In this paper, we introduce a Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to coordinating various cognitive functions and learning strategies in a self-organized manner to build human-level AI models and robotic applications. Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the future AI, rooted with a practical hi
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#20174;&#21270;&#23398;&#25991;&#29486;&#20013;&#39640;&#20445;&#30495;&#25552;&#21462;&#20449;&#24687;&#65292;&#20805;&#24403;&#21270;&#23398;&#21161;&#25163;&#30340;&#35282;&#33394;&#65292;&#33258;&#21160;&#21270;&#25968;&#25454;&#25910;&#38598;&#21644;&#20998;&#26512;&#65292;&#20174;&#32780;&#25552;&#39640;&#24037;&#20316;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.12993</link><description>&lt;p&gt;
&#29992;&#20110;&#21270;&#23398;&#25991;&#29486;&#25968;&#25454;&#25366;&#25496;&#30340;&#33258;&#20027;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
An Autonomous Large Language Model Agent for Chemical Literature Data Mining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12993
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#20174;&#21270;&#23398;&#25991;&#29486;&#20013;&#39640;&#20445;&#30495;&#25552;&#21462;&#20449;&#24687;&#65292;&#20805;&#24403;&#21270;&#23398;&#21161;&#25163;&#30340;&#35282;&#33394;&#65292;&#33258;&#21160;&#21270;&#25968;&#25454;&#25910;&#38598;&#21644;&#20998;&#26512;&#65292;&#20174;&#32780;&#25552;&#39640;&#24037;&#20316;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21270;&#23398;&#21512;&#25104;&#23545;&#20110;&#25512;&#21160;&#26448;&#26009;&#21512;&#25104;&#21644;&#33647;&#29289;&#21457;&#29616;&#33267;&#20851;&#37325;&#35201;&#65292;&#24433;&#21709;&#30528;&#21253;&#25324;&#29615;&#22659;&#31185;&#23398;&#21644;&#21307;&#30103;&#20445;&#20581;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#12290;&#21270;&#23398;&#39046;&#22495;&#30340;&#25216;&#26415;&#19978;&#21319;&#20351;&#24471;&#20135;&#29983;&#20102;&#22823;&#37327;&#30340;&#21270;&#23398;&#25968;&#25454;&#65292;&#25361;&#25112;&#30740;&#31350;&#20154;&#21592;&#21435;&#35782;&#21035;&#27169;&#24335;&#24182;&#32454;&#21270;&#21512;&#25104;&#36807;&#31243;&#12290;&#20154;&#24037;&#26234;&#33021;&#36890;&#36807;&#20998;&#26512;&#25968;&#25454;&#26469;&#20248;&#21270;&#21512;&#25104;&#24182;&#25552;&#39640;&#20135;&#37327;&#12290;&#28982;&#32780;&#65292;&#20154;&#24037;&#26234;&#33021;&#22312;&#22788;&#29702;&#25991;&#29486;&#25968;&#25454;&#26041;&#38754;&#38754;&#20020;&#30528;&#25361;&#25112;&#65292;&#22240;&#20026;&#21270;&#23398;&#25991;&#29486;&#30340;&#32467;&#26500;&#19981;&#35268;&#25972;&#65292;&#20889;&#20316;&#39118;&#26684;&#22810;&#26679;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#22256;&#38590;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#26694;&#26550;&#65292;&#33021;&#22815;&#20174;&#24191;&#27867;&#30340;&#21270;&#23398;&#25991;&#29486;&#20013;&#39640;&#20445;&#30495;&#22320;&#25552;&#21462;&#20449;&#24687;&#12290;&#36825;&#20010;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#37319;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#24555;&#36895;&#29983;&#25104;&#21644;&#36845;&#20195;&#20248;&#21270;&#12290;&#23427;&#20805;&#24403;&#21270;&#23398;&#21161;&#25163;&#30340;&#35282;&#33394;&#65292;&#33258;&#21160;&#21270;&#25968;&#25454;&#25910;&#38598;&#21644;&#20998;&#26512;&#65292;&#20174;&#32780;&#33410;&#30465;&#20154;&#21147;&#24182;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12993v1 Announce Type: cross  Abstract: Chemical synthesis, which is crucial for advancing material synthesis and drug discovery, impacts various sectors including environmental science and healthcare. The rise of technology in chemistry has generated extensive chemical data, challenging researchers to discern patterns and refine synthesis processes. Artificial intelligence (AI) helps by analyzing data to optimize synthesis and increase yields. However, AI faces challenges in processing literature data due to the unstructured format and diverse writing style of chemical literature. To overcome these difficulties, we introduce an end-to-end AI agent framework capable of high-fidelity extraction from extensive chemical literature. This AI agent employs large language models (LLMs) for prompt generation and iterative optimization. It functions as a chemistry assistant, automating data collection and analysis, thereby saving manpower and enhancing performance. Our framework's ef
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22686;&#24378;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#30340;&#26032;&#26694;&#26550;ResQuNNs&#65292;&#22312;quanvolutional&#23618;&#20013;&#24341;&#20837;&#21487;&#35757;&#32451;&#24615;&#65292;&#36890;&#36807;&#27531;&#24046;&#23398;&#20064;&#30340;&#27010;&#24565;&#35299;&#20915;&#20102;&#36328;&#23618;&#26799;&#24230;&#35775;&#38382;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.09146</link><description>&lt;p&gt;
ResQuNNs: &#23454;&#29616;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#28145;&#24230;&#23398;&#20064;&#30340;&#26032;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22686;&#24378;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#30340;&#26032;&#26694;&#26550;ResQuNNs&#65292;&#22312;quanvolutional&#23618;&#20013;&#24341;&#20837;&#21487;&#35757;&#32451;&#24615;&#65292;&#36890;&#36807;&#27531;&#24046;&#23398;&#20064;&#30340;&#27010;&#24565;&#35299;&#20915;&#20102;&#36328;&#23618;&#26799;&#24230;&#35775;&#38382;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;QuNNs&#65289;&#24615;&#33021;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21487;&#35757;&#32451;&#30340;quanvolutional&#23618;&#24182;&#35299;&#20915;&#19982;&#20854;&#30456;&#20851;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;&#20256;&#32479;&#30340;quanvolutional&#23618;&#34429;&#28982;&#26377;&#21161;&#20110;&#29305;&#24449;&#25552;&#21462;&#65292;&#20294;&#24448;&#24448;&#26159;&#38745;&#24577;&#30340;&#65292;&#36866;&#24212;&#24615;&#26377;&#38480;&#12290;&#19982;&#26368;&#20808;&#36827;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36890;&#36807;&#22312;&#36825;&#20123;&#23618;&#20869;&#37096;&#36827;&#34892;&#35757;&#32451;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;QuNNs&#30340;&#28789;&#27963;&#24615;&#21644;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#22810;&#20010;&#21487;&#35757;&#32451;&#30340;quanvolutional&#23618;&#30340;&#24341;&#20837;&#32473;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#24102;&#26469;&#20102;&#22797;&#26434;&#24615;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#38590;&#20197;&#22312;&#36825;&#20123;&#23618;&#20043;&#38388;&#35775;&#38382;&#26799;&#24230;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26550;&#26500;&#65292;Residual Quanvolutional Neural Networks (ResQuNNs)&#65292;&#21033;&#29992;&#27531;&#24046;&#23398;&#20064;&#30340;&#27010;&#24565;&#65292;&#22312;&#36825;&#20123;&#23618;&#20043;&#38388;&#28155;&#21152;&#36339;&#36807;&#36830;&#25509;&#20197;&#20419;&#36827;&#26799;&#24230;&#30340;&#27969;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09146v1 Announce Type: new Abstract: In this paper, we present a novel framework for enhancing the performance of Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional layers and addressing the critical challenges associated with them. Traditional quanvolutional layers, although beneficial for feature extraction, have largely been static, offering limited adaptability. Unlike state-of-the-art, our research overcomes this limitation by enabling training within these layers, significantly increasing the flexibility and potential of QuNNs. However, the introduction of multiple trainable quanvolutional layers induces complexities in gradient-based optimization, primarily due to the difficulty in accessing gradients across these layers. To resolve this, we propose a novel architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging the concept of residual learning, which facilitates the flow of gradients by adding skip connections between 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#19981;&#21516;&#23616;&#37096;&#24615;&#23545;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#21457;&#29616;&#36825;&#20123;&#26041;&#27861;&#22312;&#24615;&#33021;&#21644;&#29983;&#29289;&#23398;&#21512;&#29702;&#24615;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25506;&#35752;&#20102;SNN&#30340;&#38544;&#24335;&#24490;&#29615;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.01782</link><description>&lt;p&gt;
&#20351;&#29992;&#19981;&#21516;&#23616;&#37096;&#24615;&#23545;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Spiking Neural Network Learning Methods with Varying Locality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#19981;&#21516;&#23616;&#37096;&#24615;&#23545;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#21457;&#29616;&#36825;&#20123;&#26041;&#27861;&#22312;&#24615;&#33021;&#21644;&#29983;&#29289;&#23398;&#21512;&#29702;&#24615;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25506;&#35752;&#20102;SNN&#30340;&#38544;&#24335;&#24490;&#29615;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNN&#65289;&#25552;&#20379;&#26356;&#30495;&#23454;&#30340;&#31070;&#32463;&#21160;&#21147;&#23398;&#65292;&#22312;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#24050;&#32463;&#26174;&#31034;&#20986;&#19982;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANN&#65289;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#20449;&#24687;&#22312;SNN&#20013;&#20197;&#33033;&#20914;&#24418;&#24335;&#36827;&#34892;&#22788;&#29702;&#65292;&#37319;&#29992;&#20107;&#20214;&#39537;&#21160;&#26426;&#21046;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#33021;&#28304;&#28040;&#32791;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#33033;&#20914;&#26426;&#21046;&#30340;&#38750;&#21487;&#24494;&#24615;&#65292;&#35757;&#32451;SNN&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;&#26102;&#38388;&#21453;&#21521;&#20256;&#25773;&#65288;BPTT&#65289;&#24050;&#32463;&#26174;&#31034;&#20986;&#19968;&#23450;&#30340;&#25928;&#26524;&#65292;&#20294;&#22312;&#35745;&#31639;&#21644;&#23384;&#20648;&#25104;&#26412;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#29983;&#29289;&#23398;&#19978;&#19981;&#21487;&#34892;&#12290;&#30456;&#21453;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#20855;&#26377;&#19981;&#21516;&#23616;&#37096;&#24615;&#30340;&#26367;&#20195;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26377;&#30456;&#20284;&#20043;&#22788;&#65292;&#21516;&#26102;&#22312;&#29983;&#29289;&#23398;&#21512;&#29702;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#25506;&#35752;&#20102;SNN&#30340;&#38544;&#24335;&#24490;&#29615;&#29305;&#24615;&#65292;&#24182;&#36827;&#34892;&#20102;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics, have shown to achieve performance comparable to Artificial Neural Networks (ANNs) in several machine learning tasks. Information is processed as spikes within SNNs in an event-based mechanism that significantly reduces energy consumption. However, training SNNs is challenging due to the non-differentiable nature of the spiking mechanism. Traditional approaches, such as Backpropagation Through Time (BPTT), have shown effectiveness but comes with additional computational and memory costs and are biologically implausible. In contrast, recent works propose alternative learning methods with varying degrees of locality, demonstrating success in classification tasks. In this work, we show that these methods share similarities during the training process, while they present a trade-off between biological plausibility and performance. Further, this research examines the implicitly recurrent nature of SNNs and investigat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#35757;&#32451;&#21644;&#21518;&#38376;&#25915;&#20987;&#30340;&#20132;&#21449;&#28857;&#65292;&#24341;&#20837;&#20102;Adversarial Robustness Unhardening&#65288;ARU&#65289;&#65292;&#36890;&#36807;&#26377;&#24847;&#20171;&#20837;&#20998;&#25955;&#24335;&#35757;&#32451;&#36807;&#31243;&#20013;&#30772;&#22351;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#20351;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#26356;&#24191;&#27867;&#30340;&#36867;&#36991;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2310.11594</link><description>&lt;p&gt;
Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning. (arXiv:2310.11594v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning. (arXiv:2310.11594v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11594
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#35757;&#32451;&#21644;&#21518;&#38376;&#25915;&#20987;&#30340;&#20132;&#21449;&#28857;&#65292;&#24341;&#20837;&#20102;Adversarial Robustness Unhardening&#65288;ARU&#65289;&#65292;&#36890;&#36807;&#26377;&#24847;&#20171;&#20837;&#20998;&#25955;&#24335;&#35757;&#32451;&#36807;&#31243;&#20013;&#30772;&#22351;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#20351;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#26356;&#24191;&#27867;&#30340;&#36867;&#36991;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20170;&#30340;&#25968;&#25454;&#39537;&#21160;&#29615;&#22659;&#20013;&#65292;&#32500;&#25252;&#29992;&#25143;&#38544;&#31169;&#21644;&#37322;&#25918;&#25968;&#25454;&#28508;&#21147;&#20043;&#38388;&#24494;&#22937;&#30340;&#24179;&#34913;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#20851;&#27880;&#28857;&#12290;&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#20197;&#38544;&#31169;&#20026;&#20013;&#24515;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#23454;&#29616;&#20102;&#21327;&#20316;&#27169;&#22411;&#35757;&#32451;&#32780;&#26080;&#38656;&#20849;&#20139;&#25968;&#25454;&#12290;&#36825;&#31181;&#20998;&#25955;&#24335;&#26041;&#27861;&#24102;&#26469;&#20102;&#23433;&#20840;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#24694;&#24847;&#23454;&#20307;&#27880;&#20837;&#25439;&#22351;&#25968;&#25454;&#30340;&#20013;&#27602;&#21644;&#21518;&#38376;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26368;&#21021;&#21463;&#21040;&#27979;&#35797;&#26102;&#38388;&#36867;&#36991;&#25915;&#20987;&#30340;&#21551;&#21457;&#65292;&#25506;&#35752;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#35757;&#32451;&#21644;&#21518;&#38376;&#25915;&#20987;&#30340;&#20132;&#21449;&#28857;&#65292;&#24341;&#20837;&#20102;Adversarial Robustness Unhardening&#65288;ARU&#65289;&#12290;ARU&#34987;&#19968;&#37096;&#20998;&#23545;&#25163;&#20351;&#29992;&#65292;&#20197;&#26377;&#24847;&#20171;&#20837;&#20998;&#25955;&#24335;&#35757;&#32451;&#36807;&#31243;&#20013;&#30772;&#22351;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#20351;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#26356;&#24191;&#27867;&#30340;&#36867;&#36991;&#25915;&#20987;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#35777;&#23454;&#39564;&#65292;&#35780;&#20272;&#20102;ARU&#23545;&#23545;&#25239;&#24615;&#35757;&#32451;&#21644;&#29616;&#26377;&#30340;&#40065;&#26834;&#32858;&#21512;&#38450;&#24481;&#31574;&#30053;&#23545;&#20013;&#27602;&#21644;&#21518;&#38376;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's data-driven landscape, the delicate equilibrium between safeguarding user privacy and unleashing data potential stands as a paramount concern. Federated learning, which enables collaborative model training without necessitating data sharing, has emerged as a privacy-centric solution. This decentralized approach brings forth security challenges, notably poisoning and backdoor attacks where malicious entities inject corrupted data. Our research, initially spurred by test-time evasion attacks, investigates the intersection of adversarial training and backdoor attacks within federated learning, introducing Adversarial Robustness Unhardening (ARU). ARU is employed by a subset of adversaries to intentionally undermine model robustness during decentralized training, rendering models susceptible to a broader range of evasion attacks. We present extensive empirical experiments evaluating ARU's impact on adversarial training and existing robust aggregation defenses against poisoning a
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20154;&#21592;&#30740;&#31350;&#20102;&#22312;&#25968;&#25454;&#21463;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#32553;&#25918;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#26368;&#20248;&#24615;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#32771;&#34385;&#21040;&#37325;&#22797;&#20196;&#29260;&#21644;&#36807;&#37327;&#21442;&#25968;&#30340;&#20215;&#20540;&#36882;&#20943;&#12290;</title><link>http://arxiv.org/abs/2305.16264</link><description>&lt;p&gt;
&#32553;&#25918;&#25968;&#25454;&#21463;&#38480;&#30340;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Scaling Data-Constrained Language Models. (arXiv:2305.16264v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16264
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#30740;&#31350;&#20102;&#22312;&#25968;&#25454;&#21463;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#32553;&#25918;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#26368;&#20248;&#24615;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#32771;&#34385;&#21040;&#37325;&#22797;&#20196;&#29260;&#21644;&#36807;&#37327;&#21442;&#25968;&#30340;&#20215;&#20540;&#36882;&#20943;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#22312;&#25193;&#23637;&#35821;&#35328;&#27169;&#22411;&#30340;&#36235;&#21183;&#28041;&#21450;&#22686;&#21152;&#21442;&#25968;&#35745;&#25968;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#12290;&#25512;&#26029;&#36825;&#20010;&#36235;&#21183;&#34920;&#26126;&#65292;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#21487;&#33021;&#24456;&#24555;&#23601;&#20250;&#21463;&#21040;&#20114;&#32852;&#32593;&#19978;&#21487;&#29992;&#25991;&#26412;&#25968;&#25454;&#30340;&#38480;&#21046;&#12290;&#20986;&#20110;&#27492;&#38480;&#21046;&#30340;&#21160;&#26426;&#65292;&#25105;&#20204;&#30740;&#31350;&#22312;&#25968;&#25454;&#21463;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#32553;&#25918;&#35821;&#35328;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36816;&#34892;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#65292;&#21464;&#21270;&#25968;&#25454;&#37325;&#22797;&#31243;&#24230;&#21644;&#35745;&#31639;&#39044;&#31639;&#65292;&#33539;&#22260;&#36798;&#21040;&#20102;9000&#20159;&#20010;&#35757;&#32451;&#20196;&#29260;&#21644;9&#20159;&#21442;&#25968;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#26377;&#38480;&#30340;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#39640;&#36798;4&#27425;&#37325;&#22797;&#25968;&#25454;&#30340;&#35757;&#32451;&#19982;&#20351;&#29992;&#21807;&#19968;&#25968;&#25454;&#30456;&#27604;&#23545;&#25439;&#22833;&#30340;&#36129;&#29486;&#24494;&#19981;&#36275;&#36947;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#26356;&#22810;&#30340;&#37325;&#22797;&#25968;&#25454;&#65292;&#28155;&#21152;&#35745;&#31639;&#30340;&#20215;&#20540;&#26368;&#32456;&#20250;&#34928;&#20943;&#20026;&#38646;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#32463;&#39564;&#35777;&#20102;&#19968;&#20010;&#35745;&#31639;&#26368;&#20248;&#24615;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#32771;&#34385;&#21040;&#37325;&#22797;&#20196;&#29260;&#21644;&#36807;&#37327;&#21442;&#25968;&#30340;&#20215;&#20540;&#36882;&#20943;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23581;&#35797;&#20102;&#32531;&#35299;&#25968;&#25454;&#31232;&#32570;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity,
&lt;/p&gt;</description></item></channel></rss>