<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#22810;&#22238;&#21512;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#30475;&#20284;&#33391;&#24615;&#30340;&#23545;&#35805;&#26041;&#24335;&#36880;&#28176;&#21319;&#32423;&#19982;&#27169;&#22411;&#30340;&#20132;&#20114;&#65292;&#25104;&#21151;&#31361;&#30772;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2404.01833</link><description>&lt;p&gt;
&#20255;&#22823;&#65292;&#29616;&#22312;&#20889;&#19968;&#31687;&#20851;&#20110;&#27492;&#30340;&#25991;&#31456;&#65306;Crescendo&#22810;&#22238;&#21512;LLM&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01833
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#22810;&#22238;&#21512;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#30475;&#20284;&#33391;&#24615;&#30340;&#23545;&#35805;&#26041;&#24335;&#36880;&#28176;&#21319;&#32423;&#19982;&#27169;&#22411;&#30340;&#20132;&#20114;&#65292;&#25104;&#21151;&#31361;&#30772;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27969;&#34892;&#31243;&#24230;&#22823;&#24133;&#19978;&#21319;&#65292;&#24182;&#19988;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#24212;&#29992;&#20110;&#22810;&#20010;&#39046;&#22495;&#12290;&#36825;&#20123;LLMs&#22312;&#35774;&#35745;&#19978;&#36991;&#20813;&#28041;&#21450;&#38750;&#27861;&#25110;&#19981;&#36947;&#24503;&#30340;&#35805;&#39064;&#65292;&#20197;&#36991;&#20813;&#23545;&#36127;&#36131;&#20219;&#30340;AI&#36896;&#25104;&#20260;&#23475;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#20986;&#29616;&#20102;&#19968;&#31995;&#21015;&#25915;&#20987;&#65292;&#34987;&#31216;&#20026;&#8220;&#36234;&#29425;&#8221;&#65292;&#26088;&#22312;&#31361;&#30772;&#36825;&#31181;&#23545;&#40784;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#36234;&#29425;&#25915;&#20987;&#26088;&#22312;&#32553;&#23567;&#27169;&#22411;&#33021;&#20570;&#30340;&#19982;&#24895;&#24847;&#20570;&#30340;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Crescendo&#30340;&#26032;&#22411;&#36234;&#29425;&#25915;&#20987;&#12290;&#19982;&#29616;&#26377;&#30340;&#36234;&#29425;&#26041;&#27861;&#19981;&#21516;&#65292;Crescendo&#26159;&#19968;&#31181;&#22810;&#22238;&#21512;&#36234;&#29425;&#65292;&#20197;&#19968;&#31181;&#30475;&#20284;&#33391;&#24615;&#30340;&#26041;&#24335;&#19982;&#27169;&#22411;&#36827;&#34892;&#20132;&#20114;&#12290;&#23427;&#20174;&#26377;&#20851;&#25163;&#22836;&#20219;&#21153;&#30340;&#19968;&#33324;&#25552;&#31034;&#25110;&#38382;&#39064;&#24320;&#22987;&#65292;&#28982;&#21518;&#36880;&#28176;&#21319;&#32423;&#23545;&#35805;&#65292;&#24341;&#29992;&#27169;&#22411;&#30340;&#22238;&#22797;&#65292;&#36880;&#28176;&#23548;&#33268;&#25104;&#21151;&#36234;&#29425;&#12290;&#25105;&#20204;&#22312;&#21253;&#25324;ChatGPT&#12289;Gemini Pr&#22312;&#20869;&#30340;&#21508;&#31181;&#20844;&#20849;&#31995;&#32479;&#19978;&#35780;&#20272;&#20102;Crescendo&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01833v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have risen significantly in popularity and are increasingly being adopted across multiple applications. These LLMs are heavily aligned to resist engaging in illegal or unethical topics as a means to avoid contributing to responsible AI harms. However, a recent line of attacks, known as "jailbreaks", seek to overcome this alignment. Intuitively, jailbreak attacks aim to narrow the gap between what the model can do and what it is willing to do. In this paper, we introduce a novel jailbreak attack called Crescendo. Unlike existing jailbreak methods, Crescendo is a multi-turn jailbreak that interacts with the model in a seemingly benign manner. It begins with a general prompt or question about the task at hand and then gradually escalates the dialogue by referencing the model's replies, progressively leading to a successful jailbreak. We evaluate Crescendo on various public systems, including ChatGPT, Gemini Pr
&lt;/p&gt;</description></item><item><title>&#36825;&#19968;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;108&#20301;&#27597;&#35821;&#20026;&#21345;&#26031;&#33922;&#21033;&#20122;&#35821;&#35828;&#35805;&#32773;&#30340;&#24085;&#37329;&#26862;&#30149;&#24739;&#32773;&#35821;&#38899;&#35821;&#26009;&#24211;&#65292;&#28085;&#30422;&#20102;&#22810;&#31181;&#35821;&#38899;&#20219;&#21153;&#65292;&#36890;&#36807;&#25163;&#21160;&#21644;&#33258;&#21160;&#36716;&#24405;&#30830;&#20445;&#20102;&#25968;&#25454;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.02371</link><description>&lt;p&gt;
NeuroVoz&#65306;&#24085;&#37329;&#26862;&#30149;&#24739;&#32773;&#35821;&#38899;&#30340;&#21345;&#26031;&#33922;&#21033;&#20122;&#35821;&#35821;&#26009;&#24211;
&lt;/p&gt;
&lt;p&gt;
NeuroVoz: a Castillian Spanish corpus of parkinsonian speech
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02371
&lt;/p&gt;
&lt;p&gt;
&#36825;&#19968;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;108&#20301;&#27597;&#35821;&#20026;&#21345;&#26031;&#33922;&#21033;&#20122;&#35821;&#35828;&#35805;&#32773;&#30340;&#24085;&#37329;&#26862;&#30149;&#24739;&#32773;&#35821;&#38899;&#35821;&#26009;&#24211;&#65292;&#28085;&#30422;&#20102;&#22810;&#31181;&#35821;&#38899;&#20219;&#21153;&#65292;&#36890;&#36807;&#25163;&#21160;&#21644;&#33258;&#21160;&#36716;&#24405;&#30830;&#20445;&#20102;&#25968;&#25454;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35821;&#38899;&#20998;&#26512;&#36827;&#34892;&#24085;&#37329;&#26862;&#30149;&#65288;PD&#65289;&#35786;&#26029;&#30340;&#36827;&#23637;&#21463;&#21040;&#20844;&#24320;&#21487;&#29992;&#12289;&#22810;&#26679;&#21270;&#30340;&#35821;&#35328;&#25968;&#25454;&#38598;&#30340;&#26174;&#33879;&#32570;&#20047;&#30340;&#38459;&#30861;&#65292;&#38480;&#21046;&#20102;&#29616;&#26377;&#30740;&#31350;&#32467;&#26524;&#30340;&#21487;&#20877;&#29616;&#24615;&#21644;&#36827;&#19968;&#27493;&#25506;&#32034;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#35821;&#26009;&#24211;&#65292;&#21253;&#25324;&#26469;&#33258;108&#20301;&#27597;&#35821;&#20026;&#21345;&#26031;&#33922;&#21033;&#20122;&#35821;&#30340;&#35828;&#35805;&#32773;&#65292;&#21253;&#25324;55&#21517;&#20581;&#24247;&#23545;&#29031;&#32452;&#21644;53&#21517;&#34987;&#35786;&#26029;&#24739;&#26377;PD&#30340;&#20010;&#20307;&#65292;&#25152;&#26377;&#36825;&#20123;&#20010;&#20307;&#37117;&#22312;&#33647;&#29289;&#27835;&#30103;&#19979;&#65292;&#24182;&#19988;&#22312;&#33647;&#29289;&#20248;&#21270;&#29366;&#24577;&#19979;&#36827;&#34892;&#35760;&#24405;&#12290; &#36825;&#19968;&#29420;&#29305;&#25968;&#25454;&#38598;&#28085;&#30422;&#20102;&#24191;&#27867;&#30340;&#35821;&#38899;&#20219;&#21153;&#65292;&#21253;&#25324;&#25345;&#32493;&#21457;&#38899;&#20116;&#20010;&#35199;&#29677;&#29273;&#20803;&#38899;&#12289;&#21457;&#38899;&#27979;&#35797;&#12289;16&#20010;&#21548;&#21518;&#37325;&#22797;&#30340;&#35805;&#35821;&#20197;&#21450;&#33258;&#30001;&#29420;&#30333;&#12290;&#35813;&#25968;&#25454;&#38598;&#36890;&#36807;&#19987;&#23478;&#25163;&#21160;&#36716;&#24405;&#21548;&#21518;&#37325;&#22797;&#20219;&#21153;&#24378;&#35843;&#20934;&#30830;&#24615;&#21644;&#21487;&#38752;&#24615;&#65292;&#24182;&#21033;&#29992;Whisper&#36827;&#34892;&#33258;&#21160;&#29420;&#30333;&#36716;&#24405;&#65292;&#20351;&#20854;&#25104;&#20026;&#24085;&#37329;&#26862;&#30149;&#24739;&#32773;&#35821;&#38899;&#30340;&#26368;&#23436;&#25972;&#30340;&#20844;&#24320;&#35821;&#26009;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02371v1 Announce Type: cross  Abstract: The advancement of Parkinson's Disease (PD) diagnosis through speech analysis is hindered by a notable lack of publicly available, diverse language datasets, limiting the reproducibility and further exploration of existing research.   In response to this gap, we introduce a comprehensive corpus from 108 native Castilian Spanish speakers, comprising 55 healthy controls and 53 individuals diagnosed with PD, all of whom were under pharmacological treatment and recorded in their medication-optimized state. This unique dataset features a wide array of speech tasks, including sustained phonation of the five Spanish vowels, diadochokinetic tests, 16 listen-and-repeat utterances, and free monologues. The dataset emphasizes accuracy and reliability through specialist manual transcriptions of the listen-and-repeat tasks and utilizes Whisper for automated monologue transcriptions, making it the most complete public corpus of Parkinsonian speech, 
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Syntactic Ghost&#30340;&#26032;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26080;&#24863;&#30693;&#21644;&#36890;&#29992;&#30340;&#21518;&#38376;&#26893;&#20837;&#12290;</title><link>https://arxiv.org/abs/2402.18945</link><description>&lt;p&gt;
Syntactic Ghost&#65306;&#19968;&#31181;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#30340;&#26080;&#24863;&#30693;&#36890;&#29992;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18945
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Syntactic Ghost&#30340;&#26032;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26080;&#24863;&#30693;&#21644;&#36890;&#29992;&#30340;&#21518;&#38376;&#26893;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#34987;&#21457;&#29616;&#23481;&#26131;&#21463;&#21040;&#21518;&#38376;&#25915;&#20987;&#65292;&#21487;&#20197;&#23558;&#28431;&#27934;&#36716;&#31227;&#21040;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;PLM&#21518;&#38376;&#25915;&#20987;&#37319;&#29992;&#26126;&#26174;&#30340;&#35302;&#21457;&#22120;&#65292;&#22312;&#25163;&#21160;&#23545;&#20934;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#65292;&#22240;&#27492;&#22312;&#25928;&#26524;&#12289;&#38544;&#21311;&#24615;&#21644;&#36890;&#29992;&#24615;&#26041;&#38754;&#26080;&#27861;&#21516;&#26102;&#28385;&#36275;&#26399;&#26395;&#30446;&#26631;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19981;&#21487;&#35265;&#21644;&#36890;&#29992;&#30340;&#21518;&#38376;&#26893;&#20837;&#65292;&#31216;&#20026;Syntactic Ghost&#65288;&#31616;&#31216;&#20026;synGhost&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#35813;&#26041;&#27861;&#25932;&#24847;&#22320;&#20351;&#29992;&#20855;&#26377;&#19981;&#21516;&#39044;&#23450;&#20041;&#21477;&#27861;&#32467;&#26500;&#30340;&#27602;&#23475;&#26679;&#26412;&#20316;&#20026;&#38544;&#34109;&#35302;&#21457;&#22120;&#65292;&#28982;&#21518;&#23558;&#21518;&#38376;&#26893;&#20837;&#21040;&#39044;&#35757;&#32451;&#34920;&#31034;&#31354;&#38388;&#65292;&#32780;&#19981;&#20250;&#30772;&#22351;&#21407;&#22987;&#30693;&#35782;&#12290;&#27602;&#23475;&#26679;&#26412;&#30340;&#36755;&#20986;&#34920;&#31034;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23613;&#21487;&#33021;&#22343;&#21248;&#22320;&#20998;&#24067;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#24418;&#25104;&#24191;&#27867;&#30340;&#21518;&#38376;&#12290;&#27492;&#22806;&#65292;&#22312;&#20142;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18945v1 Announce Type: cross  Abstract: Pre-trained language models (PLMs) have been found susceptible to backdoor attacks, which can transfer vulnerabilities to various downstream tasks. However, existing PLM backdoors are conducted with explicit triggers under the manually aligned, thus failing to satisfy expectation goals simultaneously in terms of effectiveness, stealthiness, and universality. In this paper, we propose a novel approach to achieve invisible and general backdoor implantation, called \textbf{Syntactic Ghost} (synGhost for short). Specifically, the method hostilely manipulates poisoned samples with different predefined syntactic structures as stealth triggers and then implants the backdoor to pre-trained representation space without disturbing the primitive knowledge. The output representations of poisoned samples are distributed as uniformly as possible in the feature space via contrastive learning, forming a wide range of backdoors. Additionally, in light 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23454;&#29616;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#65288;JITAIs&#65289;&#30340;&#21487;&#34892;&#24615;&#12290;&#36890;&#36807;&#27979;&#35797;GPT-4&#27169;&#22411;&#20197;&#20419;&#36827;&#38376;&#35786;&#24515;&#33039;&#24247;&#22797;&#20013;&#24515;&#30340;&#24515;&#33039;&#20581;&#24247;&#20307;&#32946;&#27963;&#21160;&#30340;&#20351;&#29992;&#26696;&#20363;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;450&#20010;JITAI&#20915;&#31574;&#21644;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2402.08658</link><description>&lt;p&gt;
&#26368;&#21518;&#30340;JITAI&#65311;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21457;&#25918;&#21450;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#20013;&#30340;&#19981;&#21512;&#29702;&#26377;&#25928;&#24615;&#65306;&#22312;&#21069;&#30651;&#24615;&#24515;&#33039;&#24247;&#22797;&#29615;&#22659;&#20013;&#20419;&#36827;&#20307;&#32946;&#27963;&#21160;
&lt;/p&gt;
&lt;p&gt;
The Last JITAI? The Unreasonable Effectiveness of Large Language Models in Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23454;&#29616;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#65288;JITAIs&#65289;&#30340;&#21487;&#34892;&#24615;&#12290;&#36890;&#36807;&#27979;&#35797;GPT-4&#27169;&#22411;&#20197;&#20419;&#36827;&#38376;&#35786;&#24515;&#33039;&#24247;&#22797;&#20013;&#24515;&#30340;&#24515;&#33039;&#20581;&#24247;&#20307;&#32946;&#27963;&#21160;&#30340;&#20351;&#29992;&#26696;&#20363;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;450&#20010;JITAI&#20915;&#31574;&#21644;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25968;&#23383;&#20581;&#24247;&#20013;&#35302;&#21457;&#21644;&#20010;&#24615;&#21270;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#65288;JITAIs&#65289;&#20869;&#23481;&#30340;&#21487;&#34892;&#24615;&#12290;JITAIs&#34987;&#35270;&#20026;&#21487;&#25345;&#32493;&#34892;&#20026;&#25913;&#21464;&#30340;&#20851;&#38190;&#26426;&#21046;&#65292;&#23558;&#24178;&#39044;&#25514;&#26045;&#26681;&#25454;&#20010;&#20307;&#30340;&#24403;&#21069;&#24773;&#22659;&#21644;&#38656;&#27714;&#36827;&#34892;&#35843;&#25972;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#22522;&#20110;&#35268;&#21017;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;JITAI&#23454;&#26045;&#20013;&#38754;&#20020;&#21487;&#25193;&#23637;&#24615;&#21644;&#21487;&#38752;&#24615;&#30340;&#38480;&#21046;&#65292;&#20363;&#22914;&#32570;&#20047;&#20010;&#24615;&#21270;&#12289;&#31649;&#29702;&#22810;&#21442;&#25968;&#31995;&#32479;&#22256;&#38590;&#20197;&#21450;&#25968;&#25454;&#31232;&#30095;&#24615;&#31561;&#38382;&#39064;&#12290;&#20026;&#20102;&#30740;&#31350;&#36890;&#36807;LLMs&#23454;&#29616;JITAI&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22312;&#38376;&#35786;&#24515;&#33039;&#24247;&#22797;&#20013;&#20419;&#36827;&#24515;&#33039;&#20581;&#24247;&#20307;&#32946;&#27963;&#21160;&#30340;&#20351;&#29992;&#26696;&#20363;&#30340;&#29616;&#20195;&#26368;&#39640;&#24615;&#33021;&#27169;&#22411;&#8220;GPT-4&#8221;&#30340;&#23454;&#20363;&#20316;&#20026;&#35302;&#21457;&#21644;&#20010;&#24615;&#21270;JITAIs&#30340;&#22522;&#30784;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#29983;&#25104;&#20102;&#24635;&#20849;450&#20010;&#24314;&#35758;&#30340;JITAI&#20915;&#31574;&#21644;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explored the viability of Large Language Models (LLMs) for triggering and personalizing content for Just-in-Time Adaptive Interventions (JITAIs) in digital health. JITAIs are being explored as a key mechanism for sustainable behavior change, adapting interventions to an individual's current context and needs. However, traditional rule-based and machine learning models for JITAI implementation face scalability and reliability limitations, such as lack of personalization, difficulty in managing multi-parametric systems, and issues with data sparsity. To investigate JITAI implementation via LLMs, we tested the contemporary overall performance-leading model 'GPT-4' with examples grounded in the use case of fostering heart-healthy physical activity in outpatient cardiac rehabilitation. Three personas and five sets of context information per persona were used as a basis of triggering and personalizing JITAIs. Subsequently, we generated a total of 450 proposed JITAI decisions and message c
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;AgentHPO&#25216;&#26415;&#36890;&#36807;&#33258;&#21160;&#21270;&#36229;&#21442;&#25968;&#20248;&#21270;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#22823;&#22823;&#20943;&#23569;&#20102;&#35797;&#39564;&#27425;&#25968;&#65292;&#31616;&#21270;&#20102;&#35774;&#32622;&#36807;&#31243;&#65292;&#25552;&#21319;&#20102;&#35299;&#37322;&#24615;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;</title><link>https://arxiv.org/abs/2402.01881</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Large Language Model Agent for Hyper-Parameter Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01881
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;AgentHPO&#25216;&#26415;&#36890;&#36807;&#33258;&#21160;&#21270;&#36229;&#21442;&#25968;&#20248;&#21270;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#22823;&#22823;&#20943;&#23569;&#20102;&#35797;&#39564;&#27425;&#25968;&#65292;&#31616;&#21270;&#20102;&#35774;&#32622;&#36807;&#31243;&#65292;&#25552;&#21319;&#20102;&#35299;&#37322;&#24615;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#21442;&#25968;&#20248;&#21270;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#12289;&#22823;&#37327;&#23454;&#39564;&#20197;&#21450;&#39640;&#35745;&#31639;&#21644;&#20154;&#21147;&#36164;&#28304;&#12290;&#23613;&#31649;&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#35797;&#39564;&#25928;&#29575;&#12289;&#35774;&#32622;&#22797;&#26434;&#24615;&#21644;&#20114;&#25805;&#20316;&#24615;&#26041;&#38754;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#24335;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#33258;&#21160;&#21270;&#19981;&#21516;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#65292;&#31216;&#20026;AgentHPO&#65288;LLM Agent-based Hyperparameter Optimization&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;AgentHPO&#33258;&#20027;&#22788;&#29702;&#20219;&#21153;&#20449;&#24687;&#65292;&#26681;&#25454;&#21382;&#21490;&#35797;&#39564;&#23545;&#29305;&#23450;&#36229;&#21442;&#25968;&#65288;HPs&#65289;&#36827;&#34892;&#23454;&#39564;&#65292;&#24182;&#36827;&#34892;&#36845;&#20195;&#20248;&#21270;&#12290;&#19982;&#20256;&#32479;&#30340;AutoML&#26041;&#27861;&#30456;&#27604;&#65292;&#36825;&#31181;&#31867;&#20284;&#20154;&#31867;&#30340;&#20248;&#21270;&#36807;&#31243;&#26497;&#22823;&#22320;&#20943;&#23569;&#20102;&#25152;&#38656;&#30340;&#35797;&#39564;&#27425;&#25968;&#65292;&#31616;&#21270;&#20102;&#35774;&#32622;&#36807;&#31243;&#65292;&#24182;&#25552;&#21319;&#20102;&#35299;&#37322;&#24615;&#21644;&#29992;&#25143;&#20449;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hyperparameter optimization is critical in modern machine learning, requiring expert knowledge, numerous trials, and high computational and human resources. Despite the advancements in Automated Machine Learning (AutoML), challenges in terms of trial efficiency, setup complexity, and interoperability still persist. To address these issues, we introduce a novel paradigm leveraging Large Language Models (LLMs) to automate hyperparameter optimization across diverse machine learning tasks, which is named AgentHPO (short for LLM Agent-based Hyperparameter Optimization). Specifically, AgentHPO processes the task information autonomously, conducts experiments with specific hyperparameters (HPs), and iteratively optimizes them based on historical trials. This human-like optimization process largely reduces the number of required trials, simplifies the setup process, and enhances interpretability and user trust, compared to traditional AutoML methods. Extensive empirical experiments conducted o
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2310.20360</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#25968;&#23398;&#20171;&#32461;&#65306;&#26041;&#27861;&#12289;&#23454;&#29616;&#21644;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory. (arXiv:2310.20360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#26088;&#22312;&#20171;&#32461;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20027;&#39064;&#12290;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65288;&#22914;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#12289;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12289;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#12289;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#21644;&#24102;&#26377;&#25209;&#24402;&#19968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65289;&#20197;&#21450;&#19981;&#21516;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;&#22522;&#26412;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#12289;&#21152;&#36895;&#26041;&#27861;&#21644;&#33258;&#36866;&#24212;&#26041;&#27861;&#65289;&#12290;&#25105;&#20204;&#36824;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20960;&#20010;&#29702;&#35770;&#26041;&#38754;&#65292;&#22914;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#65288;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#30340;&#24494;&#31215;&#20998;&#65289;&#12289;&#20248;&#21270;&#29702;&#35770;&#65288;&#21253;&#25324;Kurdyka-Lojasiewicz&#19981;&#31561;&#24335;&#65289;&#21644;&#27867;&#21270;&#35823;&#24046;&#12290;&#22312;&#26412;&#20070;&#30340;&#26368;&#21518;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#36824;&#22238;&#39038;&#20102;&#19968;&#20123;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#26041;&#27861;&#65292;&#21253;&#25324;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#21644;&#28145;&#24230;Galerkin&#26041;&#27861;&#12290;&#24076;&#26395;&#26412;&#20070;&#33021;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;
This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#36229;&#36234;&#19968;&#38454;&#36923;&#36753;&#30340;&#25552;&#21319;&#25512;&#29702;&#38382;&#39064;&#65292;&#25193;&#23637;&#20102;&#35745;&#25968;&#37327;&#35789;&#25193;&#23637;&#30340;&#20004;&#20010;&#21464;&#37327;&#30340;&#19968;&#38454;&#36923;&#36753;&#29255;&#27573;&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#65292;&#24182;&#22312;&#38480;&#23450;&#20102;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#20102;&#19981;&#21516;&#23646;&#24615;&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.11738</link><description>&lt;p&gt;
&#36229;&#20986;&#19968;&#38454;&#36923;&#36753;&#30340;&#25552;&#21319;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Lifted Inference beyond First-Order Logic. (arXiv:2308.11738v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11738
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#36229;&#36234;&#19968;&#38454;&#36923;&#36753;&#30340;&#25552;&#21319;&#25512;&#29702;&#38382;&#39064;&#65292;&#25193;&#23637;&#20102;&#35745;&#25968;&#37327;&#35789;&#25193;&#23637;&#30340;&#20004;&#20010;&#21464;&#37327;&#30340;&#19968;&#38454;&#36923;&#36753;&#29255;&#27573;&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#65292;&#24182;&#22312;&#38480;&#23450;&#20102;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#20102;&#19981;&#21516;&#23646;&#24615;&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#20851;&#31995;&#23398;&#20064;&#27169;&#22411;&#20013;&#65292;&#21152;&#26435;&#19968;&#38454;&#27169;&#22411;&#35745;&#25968;(WFOMC)&#26159;&#27010;&#29575;&#25512;&#29702;&#30340;&#22522;&#30784;&#12290;&#30001;&#20110;WFOMC&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#35745;&#31639;&#30340;&#65288;$\#$P&#23436;&#20840;&#65289;&#65292;&#22240;&#27492;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36827;&#34892;WFOMC&#30340;&#36923;&#36753;&#30862;&#29255;&#38750;&#24120;&#26377;&#24847;&#20041;&#12290;&#36825;&#26679;&#30340;&#30862;&#29255;&#34987;&#31216;&#20026;&#22495;&#21487;&#25552;&#21319;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35745;&#25968;&#37327;&#35789;&#65288;$\mathrm{C^2}$&#65289;&#25193;&#23637;&#30340;&#20004;&#20010;&#21464;&#37327;&#30340;&#19968;&#38454;&#36923;&#36753;&#29255;&#27573;&#20013;&#65292;&#21487;&#20197;&#36827;&#34892;&#22495;&#25552;&#21319;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#22914;&#24341;&#29992;&#32593;&#32476;&#20013;&#30340;&#38750;&#24490;&#29615;&#24615;&#21644;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#36830;&#36890;&#24615;&#65292;&#19981;&#33021;&#22312;$\mathrm{C^2}$&#25110;&#19968;&#38454;&#36923;&#36753;&#20013;&#24314;&#27169;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;$\mathrm{C^2}$&#30340;&#22495;&#21487;&#25552;&#21319;&#24615;&#65292;&#21253;&#25324;&#22810;&#20010;&#36825;&#26679;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23558;$\mathrm{C^2}$&#21477;&#23376;&#30340;&#19968;&#20010;&#20851;&#31995;&#38480;&#23450;&#20026;&#34920;&#31034;&#26377;&#21521;&#26080;&#29615;&#22270;&#12289;&#36830;&#36890;&#22270;&#12289;&#26641;&#65288;&#25110;&#26377;&#21521;&#26641;&#65289;&#25110;&#26862;&#26519;&#65288;&#25110;&#26377;&#21521;&#26862;&#26519;&#65289;&#26102;&#65292;&#23427;&#20173;&#28982;&#20445;&#25345;&#20102;&#22495;&#21487;&#25552;&#21319;&#24615;&#12290;&#25152;&#26377;&#25105;&#20204;&#30340;&#32467;&#26524;&#37117;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Weighted First Order Model Counting (WFOMC) is fundamental to probabilistic inference in statistical relational learning models. As WFOMC is known to be intractable in general ($\#$P-complete), logical fragments that admit polynomial time WFOMC are of significant interest. Such fragments are called domain liftable. Recent works have shown that the two-variable fragment of first order logic extended with counting quantifiers ($\mathrm{C^2}$) is domain-liftable. However, many properties of real-world data, like acyclicity in citation networks and connectivity in social networks, cannot be modeled in $\mathrm{C^2}$, or first order logic in general. In this work, we expand the domain liftability of $\mathrm{C^2}$ with multiple such properties. We show that any $\mathrm{C^2}$ sentence remains domain liftable when one of its relations is restricted to represent a directed acyclic graph, a connected graph, a tree (resp. a directed tree) or a forest (resp. a directed forest). All our results r
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35752;&#35770;&#20102;&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#24212;&#29992;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#30740;&#31350;&#26041;&#21521;&#65292;&#36890;&#36807;&#27604;&#36739;qGAN&#21644;QCBM&#31561;&#27169;&#22411;&#65292;&#23637;&#31034;&#20102;&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#23454;&#29616;&#37327;&#23376;&#20248;&#21183;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.08448</link><description>&lt;p&gt;
&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#23454;&#29616;&#37327;&#23376;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;qGAN&#65289;&#21644;QCBM
&lt;/p&gt;
&lt;p&gt;
Implementing Quantum Generative Adversarial Network (qGAN) and QCBM in Finance. (arXiv:2308.08448v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08448
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35752;&#35770;&#20102;&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#24212;&#29992;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#30740;&#31350;&#26041;&#21521;&#65292;&#36890;&#36807;&#27604;&#36739;qGAN&#21644;QCBM&#31561;&#27169;&#22411;&#65292;&#23637;&#31034;&#20102;&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#23454;&#29616;&#37327;&#23376;&#20248;&#21183;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;QML&#65289;&#26159;&#19968;&#20010;&#36328;&#23398;&#31185;&#30340;&#39046;&#22495;&#65292;&#30001;&#20004;&#20010;&#26368;&#20855;&#21019;&#26032;&#24615;&#30340;&#30740;&#31350;&#39046;&#22495;&#32452;&#25104;&#65306;&#37327;&#23376;&#35745;&#31639;&#21644;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#65292;ML&#21644;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#34987;&#35748;&#20026;&#26159;&#23558;&#21463;&#21040;&#37327;&#23376;&#35745;&#31639;&#26426;&#20852;&#36215;&#24433;&#21709;&#30340;&#31532;&#19968;&#20010;&#39046;&#22495;&#12290;&#36825;&#39033;&#24037;&#20316;&#35752;&#35770;&#20102;&#22312;&#37329;&#34701;&#20013;&#24212;&#29992;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;QML&#65289;&#30340;&#19968;&#20123;&#26032;&#30740;&#31350;&#39046;&#22495;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#20123;&#24050;&#22312;&#37329;&#34701;&#30028;&#24341;&#36215;&#20851;&#27880;&#30340;QML&#27169;&#22411;&#65292;&#20197;&#21450;&#20351;&#29992;&#27169;&#25311;&#29615;&#22659;&#20013;&#30340;&#30495;&#23454;&#37329;&#34701;&#25968;&#25454;&#38598;&#23545;qGAN&#65288;&#37327;&#23376;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65289;&#21644;QCBM&#65288;&#37327;&#23376;&#30005;&#36335;Born&#26426;&#65289;&#31561;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;&#23545;&#20110;qGAN&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#37492;&#21035;&#22120;&#21644;&#29983;&#25104;&#22120;&#30340;&#37327;&#23376;&#30005;&#36335;&#65292;&#24182;&#23637;&#31034;&#20102;&#26410;&#26469;&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#36890;&#36807;QML&#23454;&#29616;&#37327;&#23376;&#20248;&#21183;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum machine learning (QML) is a cross-disciplinary subject made up of two of the most exciting research areas: quantum computing and classical machine learning (ML), with ML and artificial intelligence (AI) being projected as the first fields that will be impacted by the rise of quantum machines. Quantum computers are being used today in drug discovery, material &amp; molecular modelling and finance. In this work, we discuss some upcoming active new research areas in application of quantum machine learning (QML) in finance. We discuss certain QML models that has become areas of active interest in the financial world for various applications. We use real world financial dataset and compare models such as qGAN (quantum generative adversarial networks) and QCBM (quantum circuit Born machine) among others, using simulated environments. For the qGAN, we define quantum circuits for discriminators and generators and show promises of future quantum advantage via QML in finance.
&lt;/p&gt;</description></item><item><title>&#36825;&#20221;&#30333;&#30382;&#20070;&#26159;&#23545;&#32654;&#22269;&#22269;&#23478;&#30005;&#20449;&#21644;&#20449;&#24687;&#31649;&#29702;&#23616;&#30340;&#8220;AI&#38382;&#36131;&#25919;&#31574;&#35780;&#35770;&#35831;&#27714;&#8221;&#30340;&#22238;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#30456;&#20114;&#20851;&#32852;&#30340;AI&#38382;&#36131;&#25919;&#31574;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2307.13658</link><description>&lt;p&gt;
&#20851;&#20110;AI&#38382;&#36131;&#25919;&#31574;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Towards an AI Accountability Policy. (arXiv:2307.13658v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13658
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#30333;&#30382;&#20070;&#26159;&#23545;&#32654;&#22269;&#22269;&#23478;&#30005;&#20449;&#21644;&#20449;&#24687;&#31649;&#29702;&#23616;&#30340;&#8220;AI&#38382;&#36131;&#25919;&#31574;&#35780;&#35770;&#35831;&#27714;&#8221;&#30340;&#22238;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#30456;&#20114;&#20851;&#32852;&#30340;AI&#38382;&#36131;&#25919;&#31574;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#30333;&#30382;&#20070;&#26159;&#23545;&#32654;&#22269;&#22269;&#23478;&#30005;&#20449;&#21644;&#20449;&#24687;&#31649;&#29702;&#23616;&#30340;&#8220;AI&#38382;&#36131;&#25919;&#31574;&#35780;&#35770;&#35831;&#27714;&#8221;&#20316;&#20986;&#30340;&#22238;&#24212;&#12290;&#22312;&#22238;&#31572;&#30456;&#20851;&#38382;&#39064;&#30340;&#20851;&#38190;&#21477;&#23376;&#26411;&#23614;&#65292;&#25552;&#20379;&#20102;&#35201;&#27714;&#35780;&#35770;&#30340;&#38382;&#39064;&#32534;&#21495;&#30340;&#19978;&#26631;&#12290;&#35813;&#30333;&#30382;&#20070;&#25552;&#20986;&#20102;&#19968;&#32452;&#30456;&#20114;&#20851;&#32852;&#30340;AI&#38382;&#36131;&#25919;&#31574;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
This white paper is a response to the "AI Accountability Policy Request for Comments" by the National Telecommunications and Information Administration of the United States. The question numbers for which comments were requested are provided in superscripts at the end of key sentences answering the respective questions. The white paper offers a set of interconnected recommendations for an AI accountability policy.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;TOPSIS&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;TOPSIS-Explorer&#20915;&#31574;&#25903;&#25345;&#24037;&#20855;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21487;&#35270;&#21270;&#26041;&#24335;&#35299;&#37322;&#26435;&#37325;&#21644;&#32858;&#21512;&#23545;&#25490;&#21517;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;&#23545;&#23454;&#38469;&#24212;&#29992;&#26377;&#30528;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2306.07706</link><description>&lt;p&gt;
&#26397;&#30528;&#21487;&#35299;&#37322;&#24615;TOPSIS&#65306;&#26435;&#37325;&#21644;&#32858;&#21512;&#23545;&#25490;&#21517;&#30340;&#24433;&#21709;&#30340;&#35270;&#35273;&#27934;&#23519;&#21147;
&lt;/p&gt;
&lt;p&gt;
Towards Explainable TOPSIS: Visual Insights into the Effects of Weights and Aggregations on Rankings. (arXiv:2306.07706v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07706
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;TOPSIS&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;TOPSIS-Explorer&#20915;&#31574;&#25903;&#25345;&#24037;&#20855;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21487;&#35270;&#21270;&#26041;&#24335;&#35299;&#37322;&#26435;&#37325;&#21644;&#32858;&#21512;&#23545;&#25490;&#21517;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;&#23545;&#23454;&#38469;&#24212;&#29992;&#26377;&#30528;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26631;&#20934;&#20915;&#31574;&#20998;&#26512;&#65288;MCDA&#65289;&#22312;&#21508;&#20010;&#34892;&#19994;&#20013;&#24191;&#27867;&#29992;&#20110;&#35780;&#20272;&#21644;&#25490;&#21517;&#22791;&#36873;&#26041;&#26696;&#12290;&#22312;&#20247;&#22810;MCDA&#26041;&#27861;&#20013;&#65292;TOPSIS&#20173;&#28982;&#26159;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#26368;&#21463;&#27426;&#36814;&#30340;&#36873;&#25321;&#20043;&#19968;&#12290;TOPSIS&#35745;&#31639;&#32771;&#34385;&#30340;&#22791;&#36873;&#26041;&#26696;&#19982;&#20004;&#20010;&#39044;&#23450;&#20041;&#26041;&#26696;&#65288;&#21363;&#29702;&#24819;&#29366;&#24577;&#21644;&#21453;&#29702;&#24819;&#29366;&#24577;&#65289;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#36317;&#31163;&#30340;&#32858;&#21512;&#20540;&#21019;&#24314;&#22791;&#36873;&#26041;&#26696;&#30340;&#25490;&#21517;&#12290;&#28982;&#32780;&#65292;TOPSIS&#30340;&#20869;&#37096;&#24037;&#20316;&#35299;&#37322;&#26159;&#22256;&#38590;&#30340;&#65292;&#29305;&#21035;&#26159;&#24403;&#26631;&#20934;&#25968;&#30446;&#24456;&#22823;&#26102;&#12290;&#20026;&#27492;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#21487;&#20197;&#20351;&#29992;&#22791;&#36873;&#26041;&#26696;&#30340;&#24179;&#22343;&#20540;&#65288;M&#65289;&#21644;&#26631;&#20934;&#20559;&#24046;&#65288;SD&#65289;&#26469;&#34920;&#31034;TOPSIS&#32858;&#21512;&#20540;&#65292;&#20174;&#32780;&#21019;&#24314;MSD&#31354;&#38388;&#65292;&#36825;&#26159;&#19968;&#31181;&#21487;&#35270;&#21270;&#24182;&#35299;&#37322;&#32858;&#21512;&#30340;&#24037;&#20855;&#12290;&#21363;&#20351;MSD&#31354;&#38291;&#38750;&#24120;&#26377;&#29992;&#65292;&#20294;&#23427;&#20551;&#35774;&#26631;&#20934;&#21516;&#26679;&#37325;&#35201;&#65292;&#20351;&#20854;&#22312;&#23454;&#38469;&#25490;&#21517;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#38477;&#20302; &#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#24191;&#20102; TOPSIS &#32467;&#26524;&#30340;&#36716;&#25442;&#65292;&#20351;&#24471;&#19981;&#21516;&#30340;&#26631;&#20934;&#21487;&#20197;&#35299;&#37322;&#20026;&#35270;&#35273;&#19978;&#30340; MSD &#31354;&#38388;&#65292;&#20197;&#27492;&#26469;&#22788;&#29702;&#23558;&#26435;&#37325;&#21152;&#20837;TOPSIS&#38382;&#39064;&#30340;&#22330;&#26223;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#21152;&#26435; MSD &#31354;&#38388;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#20915;&#31574;&#25903;&#25345;&#24037;&#20855;&#65292;&#31216;&#20026; TOPSIS-Explorer&#65292;&#25552;&#20379;&#26131;&#20110;&#29702;&#35299;&#30340;&#35270;&#35273;&#27934;&#23519;&#21147;&#65292;&#20197;&#20998;&#26512;&#19981;&#21516;&#26435;&#37325;&#21644;&#32858;&#21512;&#20540;&#23545;&#25490;&#21517;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20379;&#24212;&#21830;&#36873;&#25321;&#23454;&#38469;&#26696;&#20363;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#23427;&#22312;&#25552;&#20379;&#21487;&#35299;&#37322;TOPSIS&#32467;&#26524;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-Criteria Decision Analysis (MCDA) is extensively used across diverse industries to assess and rank alternatives. Among numerous MCDA methods developed to solve real-world ranking problems, TOPSIS remains one of the most popular choices in many application areas. TOPSIS calculates distances between the considered alternatives and two predefined ones, namely the ideal and the anti-ideal, and creates a ranking of the alternatives according to a chosen aggregation of these distances. However, the interpretation of the inner workings of TOPSIS is difficult, especially when the number of criteria is large. To this end, recent research has shown that TOPSIS aggregations can be expressed using the means (M) and standard deviations (SD) of alternatives, creating MSD-space, a tool for visualizing and explaining aggregations. Even though MSD-space is highly useful, it assumes equally important criteria, making it less applicable to real-world ranking problems. In this paper, we generalize t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#35299;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#25903;&#25345;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65292;&#36890;&#36807;&#22270;&#35299;&#22411;&#21644;&#20551;&#35774;&#24615;&#25512;&#29702;&#65292;&#32553;&#23567;&#21487;&#35299;&#37322;&#24615;&#24046;&#36317;&#12290;&#36890;&#36807;&#20020;&#24202;&#24212;&#29992;&#30740;&#31350;&#21644;&#24314;&#27169;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;DiagramNet&#19981;&#20165;&#33021;&#25552;&#20379;&#24544;&#23454;&#30340;&#26434;&#38899;&#24418;&#29366;&#35299;&#37322;&#65292;&#36824;&#20855;&#26377;&#36739;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#19988;&#22270;&#35299;&#22411;&#35299;&#37322;&#22312;&#20020;&#24202;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;&#26356;&#21463;&#25512;&#23815;&#12290;</title><link>http://arxiv.org/abs/2302.01241</link><description>&lt;p&gt;
&#22270;&#35299;&#21270;&#65306;&#21033;&#29992;&#22270;&#35299;&#22411;AI&#35299;&#37322;&#23545;&#20551;&#35774;&#24615;&#28436;&#32462;&#25512;&#29702;&#30340;&#29702;&#24615;&#21270;
&lt;/p&gt;
&lt;p&gt;
Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses. (arXiv:2302.01241v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#35299;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#25903;&#25345;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65292;&#36890;&#36807;&#22270;&#35299;&#22411;&#21644;&#20551;&#35774;&#24615;&#25512;&#29702;&#65292;&#32553;&#23567;&#21487;&#35299;&#37322;&#24615;&#24046;&#36317;&#12290;&#36890;&#36807;&#20020;&#24202;&#24212;&#29992;&#30740;&#31350;&#21644;&#24314;&#27169;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;DiagramNet&#19981;&#20165;&#33021;&#25552;&#20379;&#24544;&#23454;&#30340;&#26434;&#38899;&#24418;&#29366;&#35299;&#37322;&#65292;&#36824;&#20855;&#26377;&#36739;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#19988;&#22270;&#35299;&#22411;&#35299;&#37322;&#22312;&#20020;&#24202;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;&#26356;&#21463;&#25512;&#23815;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#21487;&#35270;&#21270;&#24037;&#20855;&#24050;&#32463;&#34987;&#24320;&#21457;&#20986;&#26469;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#38656;&#35201;&#29992;&#25143;&#36827;&#19968;&#27493;&#25512;&#29702;&#26469;&#35299;&#37322;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;XAI&#24212;&#35813;&#25903;&#25345;&#22270;&#35299;&#22411;&#21644;&#20551;&#35774;&#24615;&#25512;&#29702;&#65292;&#20197;&#20415;AI&#33021;&#22815;&#36827;&#34892;&#20551;&#35774;&#29983;&#25104;&#21644;&#35780;&#20272;&#65292;&#20174;&#32780;&#20943;&#23569;&#21487;&#35299;&#37322;&#24615;&#24046;&#36317;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22270;&#35299;&#21270;&#26041;&#27861;&#65292;&#20197;i)&#36827;&#34892;Peircean&#25512;&#23548;-&#28436;&#32462;&#25512;&#29702;&#65292;ii)&#36981;&#24490;&#39046;&#22495;&#24815;&#20363;&#65292;&#21644;iii)&#29992;&#22270;&#31034;&#25110;&#35821;&#35328;&#36827;&#34892;&#35299;&#37322;&#12290;&#25105;&#20204;&#22312;&#20020;&#24202;&#24212;&#29992;&#39046;&#22495;&#23454;&#29616;&#20102;DiagramNet&#65292;&#20197;&#39044;&#27979;&#24515;&#33039;&#21548;&#35786;&#20013;&#30340;&#24515;&#33039;&#35786;&#26029;&#65292;&#24182;&#29992;&#22522;&#20110;&#24418;&#29366;&#30340;&#26434;&#38899;&#22270;&#35299;&#36827;&#34892;&#35299;&#37322;&#12290;&#22312;&#24314;&#27169;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;DiagramNet&#19981;&#20165;&#25552;&#20379;&#20102;&#24544;&#23454;&#30340;&#26434;&#38899;&#24418;&#29366;&#35299;&#37322;&#65292;&#32780;&#19988;&#27604;&#22522;&#32447;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#21307;&#23398;&#29983;&#30340;&#23450;&#24615;&#29992;&#25143;&#30740;&#31350;&#23637;&#31034;&#20102;&#22270;&#35299;&#22411;&#35299;&#37322;&#30340;&#21487;&#29702;&#35299;&#24615;&#21644;&#21487;&#20449;&#24230;&#65292;&#24182;&#34920;&#26126;&#22312;&#20020;&#24202;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;&#65292;&#22270;&#35299;&#24335;&#35299;&#37322;&#27604;&#20854;&#20182;&#26041;&#24335;&#26356;&#21463;&#25512;&#23815;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many visualizations have been developed for explainable AI (XAI), but they often require further reasoning by users to interpret. We argue that XAI should support diagrammatic and abductive reasoning for the AI to perform hypothesis generation and evaluation to reduce the interpretability gap. We propose Diagrammatization to i) perform Peircean abductive-deductive reasoning, ii) follow domain conventions, and iii) explain with diagrams visually or verbally. We implemented DiagramNet for a clinical application to predict cardiac diagnoses from heart auscultation, and explain with shape-based murmur diagrams. In modeling studies, we found that DiagramNet not only provides faithful murmur shape explanations, but also has better prediction performance than baseline models. We further demonstrate the interpretability and trustworthiness of diagrammatic explanations in a qualitative user study with medical students, showing that clinically-relevant, diagrammatic explanations are preferred ov
&lt;/p&gt;</description></item></channel></rss>