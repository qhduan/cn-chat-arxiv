<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20813;&#20808;&#39564;&#27491;&#26080;&#26631;&#23398;&#20064;&#30340;&#23545;&#27604;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#29305;&#24449;&#31354;&#38388;&#24182;&#21033;&#29992;&#23884;&#20837;&#30340;&#27987;&#24230;&#29305;&#24615;&#23545;&#26410;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#20266;&#26631;&#31614;&#22788;&#29702;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#22810;&#20010;&#26631;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#31867;&#20808;&#39564;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.06038</link><description>&lt;p&gt;
&#20813;&#20808;&#39564;&#27491;&#26080;&#26631;&#65288;Positive Unlabeled&#65289;&#23398;&#20064;&#30340;&#23545;&#27604;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Contrastive Approach to Prior Free Positive Unlabeled Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06038
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20813;&#20808;&#39564;&#27491;&#26080;&#26631;&#23398;&#20064;&#30340;&#23545;&#27604;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#29305;&#24449;&#31354;&#38388;&#24182;&#21033;&#29992;&#23884;&#20837;&#30340;&#27987;&#24230;&#29305;&#24615;&#23545;&#26410;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#20266;&#26631;&#31614;&#22788;&#29702;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#22810;&#20010;&#26631;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#31867;&#20808;&#39564;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#26080;&#26631;&#65288;Positive Unlabeled&#65289;&#23398;&#20064;&#26159;&#25351;&#22312;&#32473;&#23450;&#23569;&#37327;&#26631;&#35760;&#30340;&#27491;&#26679;&#26412;&#21644;&#19968;&#32452;&#26410;&#26631;&#35760;&#26679;&#26412;&#65288;&#21487;&#33021;&#26159;&#27491;&#20363;&#25110;&#36127;&#20363;&#65289;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#19968;&#20010;&#20108;&#20998;&#31867;&#22120;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27491;&#26080;&#26631;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20445;&#35777;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#23398;&#20064;&#29305;&#24449;&#31354;&#38388;&#65292;&#24182;&#21033;&#29992;&#23884;&#20837;&#30340;&#27987;&#24230;&#29305;&#24615;&#23545;&#26410;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#20266;&#26631;&#31614;&#22788;&#29702;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#26631;&#20934;&#27491;&#26080;&#26631;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36731;&#26494;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#27491;&#26080;&#26631;&#23398;&#20064;&#26041;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#31867;&#20808;&#39564;&#30340;&#20272;&#35745;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26631;&#35760;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#65292;&#32780;&#22823;&#22810;&#25968;&#27491;&#26080;&#26631;&#23398;&#20064;&#31639;&#27861;&#21017;&#22833;&#36133;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#31616;&#21333;&#30340;&#29702;&#35770;&#20998;&#26512;&#26469;&#25512;&#21160;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#65292;&#24182;&#20026;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#20102;&#19968;&#33324;&#21270;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Positive Unlabeled (PU) learning refers to the task of learning a binary classifier given a few labeled positive samples, and a set of unlabeled samples (which could be positive or negative). In this paper, we propose a novel PU learning framework, that starts by learning a feature space through pretext-invariant representation learning and then applies pseudo-labeling to the unlabeled examples, leveraging the concentration property of the embeddings. Overall, our proposed approach handily outperforms state-of-the-art PU learning methods across several standard PU benchmark datasets, while not requiring a-priori knowledge or estimate of class prior. Remarkably, our method remains effective even when labeled data is scant, where most PU learning algorithms falter. We also provide simple theoretical analysis motivating our proposed algorithms and establish generalization guarantee for our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26159;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#30740;&#31350;&#39046;&#22495;&#30340;&#31995;&#32479;&#32508;&#36848;&#65292;&#24635;&#32467;&#20102;&#26368;&#26032;&#26368;&#20808;&#36827;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#26377;&#21161;&#20110;&#20102;&#35299;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#20013;&#30340;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2307.06162</link><description>&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23545;&#29983;&#29702;&#20449;&#21495;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Deep Generative Models for Physiological Signals: A Systematic Literature Review. (arXiv:2307.06162v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#30740;&#31350;&#39046;&#22495;&#30340;&#31995;&#32479;&#32508;&#36848;&#65292;&#24635;&#32467;&#20102;&#26368;&#26032;&#26368;&#20808;&#36827;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#26377;&#21161;&#20110;&#20102;&#35299;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#20013;&#30340;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#65292;&#29305;&#21035;&#26159;&#24515;&#30005;&#22270;&#12289;&#33041;&#30005;&#22270;&#12289;&#20809;&#30005;&#23481;&#25239;&#22270;&#21644;&#32908;&#30005;&#22270;&#39046;&#22495;&#30340;&#25991;&#29486;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#12290;&#19982;&#24050;&#26377;&#30340;&#32508;&#36848;&#25991;&#31456;&#30456;&#27604;&#65292;&#26412;&#25991;&#26159;&#31532;&#19968;&#31687;&#24635;&#32467;&#26368;&#26032;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#32508;&#36848;&#12290;&#36890;&#36807;&#20998;&#26512;&#19982;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30456;&#20851;&#30340;&#26368;&#26032;&#30740;&#31350;&#65292;&#20197;&#21450;&#36825;&#20123;&#27169;&#22411;&#30340;&#20027;&#35201;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#26412;&#32508;&#36848;&#20026;&#23545;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#29983;&#29702;&#20449;&#21495;&#30340;&#25972;&#20307;&#29702;&#35299;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24378;&#35843;&#37319;&#29992;&#30340;&#35780;&#20272;&#21327;&#35758;&#21644;&#26368;&#24120;&#29992;&#30340;&#29983;&#29702;&#25968;&#25454;&#24211;&#65292;&#26412;&#32508;&#36848;&#26377;&#21161;&#20110;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a systematic literature review on deep generative models for physiological signals, particularly electrocardiogram, electroencephalogram, photoplethysmogram and electromyogram. Compared to the existing review papers, we present the first review that summarizes the recent state-of-the-art deep generative models. By analysing the state-of-the-art research related to deep generative models along with their main applications and challenges, this review contributes to the overall understanding of these models applied to physiological signals. Additionally, by highlighting the employed evaluation protocol and the most used physiological databases, this review facilitates the assessment and benchmarking of deep generative models.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;&#26412;&#22320;&#22788;&#29702;&#22120;&#27665;&#20027;&#8221;&#30340;&#31639;&#27861;Cooperator&#65292;&#35813;&#31639;&#27861;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#34920;&#29616;&#27604;Transformer&#31639;&#27861;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.10449</link><description>&lt;p&gt;
&#21512;&#20316;&#26159;&#20320;&#25152;&#38656;&#35201;&#30340;&#12290; &#65288;arXiv:2305.10449v1 [cs.LG]&#65289;
&lt;/p&gt;
&lt;p&gt;
Cooperation Is All You Need. (arXiv:2305.10449v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10449
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;&#26412;&#22320;&#22788;&#29702;&#22120;&#27665;&#20027;&#8221;&#30340;&#31639;&#27861;Cooperator&#65292;&#35813;&#31639;&#27861;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#34920;&#29616;&#27604;Transformer&#31639;&#27861;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36229;&#36234;&#8220;&#26641;&#31361;&#27665;&#20027;&#8221;&#20043;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;Cooperator&#30340;&#8220;&#26412;&#22320;&#22788;&#29702;&#22120;&#27665;&#20027;&#8221;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23558;&#23427;&#20204;&#19982;&#22522;&#20110;Transformers&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65288;&#20363;&#22914;ChatGPT&#65289;&#22312;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#30340;&#21151;&#33021;&#36827;&#34892;&#27604;&#36739;&#12290; Transformers&#22522;&#20110;&#38271;&#26399;&#20197;&#26469;&#30340;&#8220;&#31215;&#20998;-&#21457;&#23556;&#8221;&#8220;&#28857;&#8221;&#31070;&#32463;&#20803;&#30340;&#27010;&#24565;&#65292;&#32780;Cooperator&#21017;&#21463;&#21040;&#26368;&#36817;&#31070;&#32463;&#29983;&#29289;&#23398;&#31361;&#30772;&#30340;&#21551;&#31034;&#65292;&#36825;&#20123;&#31361;&#30772;&#34920;&#26126;&#65292;&#31934;&#31070;&#29983;&#27963;&#30340;&#32454;&#32990;&#22522;&#30784;&#21462;&#20915;&#20110;&#26032;&#30382;&#23618;&#20013;&#20855;&#26377;&#20004;&#20010;&#21151;&#33021;&#19978;&#19981;&#21516;&#28857;&#30340;&#19978;&#30382;&#31070;&#32463;&#20803;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#29992;&#20110;RL&#26102;&#65292;&#22522;&#20110;Cooperator&#30340;&#31639;&#27861;&#23398;&#20064;&#36895;&#24230;&#27604;&#22522;&#20110;Transformer&#30340;&#31639;&#27861;&#24555;&#24471;&#22810;&#65292;&#21363;&#20351;&#23427;&#20204;&#20855;&#26377;&#30456;&#21516;&#25968;&#37327;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Going beyond 'dendritic democracy', we introduce a 'democracy of local processors', termed Cooperator. Here we compare their capabilities when used in permutation-invariant neural networks for reinforcement learning (RL), with machine learning algorithms based on Transformers, such as ChatGPT. Transformers are based on the long-standing conception of integrate-and-fire 'point' neurons, whereas Cooperator is inspired by recent neurobiological breakthroughs suggesting that the cellular foundations of mental life depend on context-sensitive pyramidal neurons in the neocortex which have two functionally distinct points. We show that when used for RL, an algorithm based on Cooperator learns far quicker than that based on Transformer, even while having the same number of parameters.
&lt;/p&gt;</description></item></channel></rss>