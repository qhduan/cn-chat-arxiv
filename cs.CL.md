# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MambaByte: Token-free Selective State Space Model.](http://arxiv.org/abs/2401.13660) | MambaByte是一种无标记的选择性状态空间模型，通过在字节级别上进行自回归训练，解决了标准自回归Transformer在处理长序列时的性能问题，并展现了与最先进的子词Transformer相媲美甚至更优的性能，从而证明了MambaByte在无标记语言建模方面的有效性。 |
| [^2] | [VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks.](http://arxiv.org/abs/2401.13649) | VisualWebArena是一个评估多模态Web代理性能的基准，在真实的“视觉基础任务”上对代理进行了测试。它要求代理准确处理图像-文本输入，解释自然语言指令，并在网站上执行动作来完成用户定义的目标。 |
| [^3] | [DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning.](http://arxiv.org/abs/2401.13621) | 本论文提出了一种新颖的对比学习方法，通过引入离散和连续的噪声进行自我监督句子表示学习。实验证明，这种方法在语义文本相似度和迁移任务中表现出色，并且与其他方法相媲美。 |
| [^4] | [MM-LLMs: Recent Advances in MultiModal Large Language Models.](http://arxiv.org/abs/2401.13601) | 近年来，多模式大语言模型（MM-LLMs）通过成本效益高的训练策略取得了显著进展，扩展了现有的语言模型的多模输入和输出支持。本论文提供了一份综合调查报告，介绍了MM-LLMs的设计和训练方案，整理了现有的MM-LLMs及其性能，总结了关键训练方法，并探讨了未来的研究方向。 |
| [^5] | [Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction.](http://arxiv.org/abs/2401.13598) | 该论文提出了一种零样本文档级关系三元组抽取（ZeroDocRTE）框架，通过从LLMs中检索和去噪知识来生成标记数据，该方法可以减少获取新关系数据的时间和劳动成本。 |
| [^6] | [Graph Guided Question Answer Generation for Procedural Question-Answering.](http://arxiv.org/abs/2401.13594) | 本文提出了一种生成详尽的高质量训练数据的方法，用于训练紧凑的、任务特定的QA模型，从而在特定问答任务中与GPT变体模型具有竞争力。这种方法利用过程性文本的结构化特性，通过将每个步骤和整个流程表示为图形，并以图节点为条件，在详尽和可控的方式下自动生成QA对。 |
| [^7] | [Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes.](http://arxiv.org/abs/2401.13588) | 在实际医疗领域中对大型语言模型（LLMs）进行更深入和实用的评估是必要的，该研究旨在评估LLMs在成人重症护理医学复杂环境中的表现。 |
| [^8] | [Prompt Weight Experiments for LLM Instruction Fine-Tuning.](http://arxiv.org/abs/2401.13586) | LLM指令微调中，对于短提示完成数据集，提示词标记分类损失加权（PLW）与性能呈负二次关系，而长提示完成数据集则不受PLW影响。 |
| [^9] | [Large Malaysian Language Model Based on Mistral for Enhanced Local Language Understanding.](http://arxiv.org/abs/2401.13565) | 本文介绍了Mistral 7B大规模语言模型在马来西亚语言数据集上的预训练进展和性能优化，证明了继续预训练和扩展上下文长度对提升语言理解能力的有效性，并对比了其在Tatabahasa上的优越性能。 |
| [^10] | [SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation.](http://arxiv.org/abs/2401.13527) | SpeechGPT-Gen是一个8亿参数的语音大型语言模型，通过Chain-of-Information Generation方法来解耦语义和感知信息，在语音生成方面提高了效率。 |
| [^11] | [Can GPT-3.5 Generate and Code Discharge Summaries?.](http://arxiv.org/abs/2401.13512) | GPT-3.5被用于生成和标注医疗文件以进行数据增强，结果显示其对ICD-10代码的编码性能良好，并且生成的文件在临床可接受性评估中得到了认可。 |
| [^12] | [How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment.](http://arxiv.org/abs/2401.13481) | AI思想对个体创造力没有影响，但增加了整体思想多样性的数量和变化速率。 |
| [^13] | [SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval.](http://arxiv.org/abs/2401.13478) | SciMMIR是一个专门用于科学领域的多模态信息检索基准，通过开放获取的论文集合提取与科学领域相关的图像-文本配对，从而弥补了现有基准在此领域中的差距。 |
| [^14] | [SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering.](http://arxiv.org/abs/2401.13463) | SpeechDPR是第一个用于开放领域口语问答的端到端框架，能够从口语存档中检索可能包含答案的段落。通过融合无监督ASR和文本密集检索器的知识，SpeechDPR能够获得较好的性能，并且在UASR性能较差时表现更加鲁棒。 |
| [^15] | [Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption.](http://arxiv.org/abs/2401.13444) | 该论文介绍了一种以低计算资源消耗为中心的高效知识库问答框架，通过引入线索引导路径探索的方式，将知识库与大型语言模型高效地融合，从而降低了对模型能力的要求，并在实验证明了其优越性能。 |
| [^16] | [Text Categorization Can Enhance Domain-Agnostic Stopword Extraction.](http://arxiv.org/abs/2401.13398) | 本文研究了文本分类在自然语言处理中简化停用词提取的作用，通过混合统计和语言学方法创建全面的停用词列表，提高了非洲语言的自然语言处理水平。 |
| [^17] | [InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions.](http://arxiv.org/abs/2401.13313) | 本论文提出了InstructDoc数据集，该数据集包含了30个具有统一指令的VDU数据集，并通过新的基于指令的文档阅读和理解模型InstructDr来提高VDU任务的泛化性能。实验证明，InstructDr可以通过给定的指令有效适应新的VDU数据集、任务和领域，并且在没有具体训练的情况下胜过现有的多模态LLMs和ChatGPT。 |
| [^18] | [MaLA-500: Massive Language Adaptation of Large Language Models.](http://arxiv.org/abs/2401.13303) | MaLA-500是一种大型语言模型，设计用于覆盖534种语言，并通过在LLaMA 2上进行训练来提高效果。 |
| [^19] | [Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models.](http://arxiv.org/abs/2401.13298) | 本文提出了一种通过大型语言模型之间的多模态辩论实现可解释的有害模因检测方法。通过推理有害和无害立场之间的相互矛盾理由，生成可读的解释，提升有害模因检测的效果。 |
| [^20] | [Can AI Assistants Know What They Don't Know?.](http://arxiv.org/abs/2401.13275) | 本文研究了AI助手是否能知道自己不知道的事情，并通过自然语言表达出来的问题。为了回答这个问题，我们构建了一个特定模型的"I don't know"（Idk）数据集，并与AI助手进行对齐。 |
| [^21] | [MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, ASR Error Detection, and ASR Error Correction.](http://arxiv.org/abs/2401.13260) | 本文提出了一种名为MF-AED-AEC的方法，通过融合多模态、ASR错误检测和ASR错误修正，通过增强ASR文本的语义一致性来改进语音情感识别的性能。 |
| [^22] | [UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems.](http://arxiv.org/abs/2401.13256) | 这项研究提出了一种统一多源检索增强生成系统（UniMS-RAG），通过统一知识源选择、知识检索和回复生成三个子任务，使语言模型能够根据需求自适应地检索证据和评估关联性，从而生成个性化的回复。 |
| [^23] | [SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning.](http://arxiv.org/abs/2401.13246) | SEER是一种通过最大化基于结构的回报来促进结构化推理和解释的新方法。 |
| [^24] | [From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning.](http://arxiv.org/abs/2401.13229) | 该论文介绍了一种基于多样性的方法，从而优化人类注释和少样本学习。传统的随机选择数据方法忽视了数据的特征和模型的需求，而该方法将考虑这些因素，以提高数据选择的效率。 |
| [^25] | [Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models.](http://arxiv.org/abs/2401.13227) | 本研究探索了在大规模异构图上应用大型语言模型进行图学习的方法，提出了LPNL框架用于可扩展链接预测。通过创新的提示语和采样流程，以及分而治之的策略，成功解决了大规模图中的信息过载问题，并在实验中表现出了优越的性能。 |
| [^26] | [TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data.](http://arxiv.org/abs/2401.13223) | TAT-LLM是一种专门用于离散推理的语言模型，针对混合表格和文本数据上的问答任务。该模型通过分步流水线的方式，包括提取器、推理器和执行器，利用LLMs的强大能力来解决问题。而为了应对成本、延迟和数据安全风险等挑战，我们开发了TAT-LLM，一个专门针对此任务的较小LLM。 |
| [^27] | [ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement.](http://arxiv.org/abs/2401.13218) | ULTRA是一种层级框架，利用大型语言模型在事件论证提取中进行经济高效的处理，通过自我优化和候选论证集合的生成，解决了位置偏差问题。 |
| [^28] | [MLLMReID: Multimodal Large Language Model-based Person Re-identification.](http://arxiv.org/abs/2401.13201) | MLLMReID是一种基于多模态大语言模型的人物再识别方法，通过微调模型并将其视觉编码器作为主干进行优化，解决了MLLM在ReID任务中的设计指令和特征学习效果的问题。 |
| [^29] | [AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents.](http://arxiv.org/abs/2401.13178) | AgentBoard是一个综合的基准测试和评估框架，专为分析评估LLM智能体而设计，解决了在多轮交互和部分可观察环境中对智能体性能进行基准测试的挑战，并提供了细粒度的进展率指标和评估工具包。 |
| [^30] | [CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering.](http://arxiv.org/abs/2401.13170) | CFMatch提出了一个在开放域问答中将自动答案等价评估与人工专家判断对齐的方法，通过提供明确一致的评估指南并引入高效、稳健且轻量级的判别式AE分类器匹配方法来解决当前评估指标与人类判断不一致的问题。 |
| [^31] | [Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages.](http://arxiv.org/abs/2401.13165) | 本章论文研究了低资源语言中机器翻译中的性别相关错误，以孟加拉语为例，讨论了性别的假设和推断，以及这些错误导致的后殖民和社会影响。同时提出了提升语言地位的潜在解决方案。 |
| [^32] | [SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection.](http://arxiv.org/abs/2401.13160) | 本文提出了一种新的训练方法SpacTor-T5，结合了跨度破坏和替换词汇检测的混合目标函数，并采用两阶段课程表进行预训练。在实验中，SpacTor-T5在各种NLP任务中取得了与标准SC预训练相同的下游性能，同时大大减少了预训练迭代次数和总FLOP。 |
| [^33] | [Locality enhanced dynamic biasing and sampling strategies for contextual ASR.](http://arxiv.org/abs/2401.13146) | 本文研究了上下文ASR中增强的本地偏置和采样策略，通过分析不同的采样策略并引入邻域注意力（NA），相对于基准模型，在LibriSpeech数据集和稀有词评估上平均相对词错误率（WER）改善了25.84%。 |
| [^34] | [The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts.](http://arxiv.org/abs/2401.13136) | 本文研究了在多语言环境中，LLMs面临的安全挑战以及缓解这些挑战的方法。在不同语言中，LLMs对恶意提示的响应存在差异，低资源语言下的响应更容易产生不安全、不相关的结果。对于这种差异的原因，本文还研究了使用强化学习和有监督微调等方法对数据进行调节的影响。 |
| [^35] | [Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace: Insights from a Manually Annotated Twitter Dataset.](http://arxiv.org/abs/2401.13133) | 本研究利用transformer-based语言模型研究尼日利亚人对COVID-19疫苗的接受程度，并通过分析和可视化发现大多数推文表达中立情感，没有对特定疫苗类型的强烈偏好。 |
| [^36] | [Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains.](http://arxiv.org/abs/2401.13129) | 本文研究了在科学和工程领域中的种子引导下对细粒度实体进行类型划分的任务，提出了用无标注语料库找到更多实体来丰富监督信息的方法，并使用多头注意力的条件随机场模型进行实体划分。 |
| [^37] | [Towards Trustable Language Models: Investigating Information Quality of Large Language Models.](http://arxiv.org/abs/2401.13086) | 这项研究探讨了大规模语言模型的信息质量问题，发现标记化不可靠、偏见以及信息质量下降可能导致幻觉、捏造信息，从而对企业决策产生错误影响。 |
| [^38] | [IndiText Boost: Text Augmentation for Low Resource India Languages.](http://arxiv.org/abs/2401.13085) | 本论文研究了针对低资源印度语言的文本增强方法，包括Easy Data Augmentation、Back Translation、Paraphrasing、使用LLMs进行文本生成以及使用LLMs进行文本扩展等技术。通过二元和多类文本分类实验，研究发现基本的数据增强技术可以显著提升性能。 |
| [^39] | [TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur'anic QA.](http://arxiv.org/abs/2401.13060) | 本文介绍了我们在《古兰经问答2023》共享任务中的应用，通过利用迁移学习和投票集成来提高预测稳定性，使用不同的Transformer模型和阈值机制来解决低资源训练数据的挑战。我们的最佳系统在隐藏数据集上取得了显著提升。 |
| [^40] | [Evaluating and Enhancing Large Language Models Performance in Domain-specific Medicine: Osteoarthritis Management with DocOA.](http://arxiv.org/abs/2401.12998) | 本研究评估了大型语言模型在特定领域医学中的表现，并以骨关节炎管理为例进行了增强。研究结果发现，通用语言模型相对于领域特定的骨关节炎管理模型在提供个性化治疗建议方面表现不佳，而专门模型表现有明显提升。 |
| [^41] | [Progressive Distillation Based on Masked Generation Feature Method for Knowledge Graph Completion.](http://arxiv.org/abs/2401.12997) | 本文提出了一种基于遮蔽生成特征的渐进蒸馏方法，用于知识图谱补全任务，通过预蒸馏和压缩预训练模型，以及引入遮蔽生成的教师-学生特征，显著降低了模型的复杂性，并解决了特征表示能力差距的问题。 |
| [^42] | [A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes.](http://arxiv.org/abs/2401.12996) | 通过翻译了的临床记录进行自然语言处理，发现了存在问题的鸦片使用的退伍军人。与仅通过诊断代码识别的鸦片使用障碍患者相比，这些患者具有不同的人口统计学和临床特征。 |
| [^43] | [Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed Response Generation in Dialogues.](http://arxiv.org/abs/2401.12995) | 本文探索了代码混合对话中的回应生成，并提出了一种利用从对话中获取的五大人格特质来增强回应生成性能的方法。 |
| [^44] | [Automated Scoring of Clinical Patient Notes using Advanced NLP and Pseudo Labeling.](http://arxiv.org/abs/2401.12994) | 本研究介绍了一种使用先进的自然语言处理和伪标签技术自动评分临床病人笔记的方法，提高了评估的效率和效果，同时缩短了训练时间。实验结果显示模型性能的改进，表明在临床笔记评估方面可能存在潜在的转变。 |
| [^45] | [Estimating the severity of dental and oral problems via sentiment classification over clinical reports.](http://arxiv.org/abs/2401.12993) | 通过分析放射学报告的文本，自动系统可以准确估计口腔问题的严重程度，对于患者的及时决策至关重要。 |
| [^46] | [TranSentence: Speech-to-speech Translation via Language-agnostic Sentence-level Speech Encoding without Language-parallel Data.](http://arxiv.org/abs/2401.12992) | 本文介绍了一种使用语言无关的语句级语音编码实现的语音到语音翻译方法，该方法不需要语言平行语音数据，并且可用于多语言翻译。 |
| [^47] | [Topic Modelling: Going Beyond Token Outputs.](http://arxiv.org/abs/2401.12990) | 这篇论文提出了一种将传统主题建模方法的输出扩展到仅限于隔离令牌列表之外的新方法。 |
| [^48] | [Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports.](http://arxiv.org/abs/2401.12989) | 本研究评估了使用语言模型从社交媒体数据中监测枪支暴力事件的可行性。研究团队使用经过微调的BERT模型识别巴西的枪支暴力报告并取得了高准确度。研究结果有助于人权组织收集包含所需数据的全面数据库。 |
| [^49] | [Few-Shot Learning for Chronic Disease Management: Leveraging Large Language Models and Multi-Prompt Engineering with Medical Knowledge Injection.](http://arxiv.org/abs/2401.12988) | 本研究提出了慢性病管理的少样本学习框架，利用大型语言模型和多Prompt工程进行精神障碍的检测，通过个性化的提示和医疗知识注入来解决数据挑战，实现慢性病管理的目标。 |
| [^50] | [TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation.](http://arxiv.org/abs/2401.12987) | TelME是一种教师导向的多模融合网络，通过跨模态知识蒸馏实现对话中情绪识别的优化，取得了在多说话人数据集MELD上的最先进性能。 |
| [^51] | [Crowdsourced Adaptive Surveys.](http://arxiv.org/abs/2401.12986) | 众包自适应调查方法（CSAS）结合自然语言处理和自适应算法，能够根据用户输入演变问题库，并在调查中适应新的问题，应用在拉丁裔信息环境和议题重要性领域，能够识别难以通过传统方法跟踪的主张或问题。 |
| [^52] | [The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias.](http://arxiv.org/abs/2401.12985) | 本研究通过引入人工生成的聊天机器人数据集和考虑往返测试的设置，评估了情感分析系统（SASs）的偏见。结果显示，在聊天机器人数据上评估SASs显示出更多的偏见，而往返测试则更真实地展示了SASs的性能。 |
| [^53] | [Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding.](http://arxiv.org/abs/2401.12983) | 本研究通过对三个大型语言模型（LLMs）在机械工程领域中解决概念性问题的能力进行评估，发现GPT-4在各个力学主题的问题回答方面表现优于其他两个模型和人类对照组，显示出潜在的未来改进空间。 |
| [^54] | [Text Classification: A Review, Empirical, and Experimental Evaluation.](http://arxiv.org/abs/2401.12982) | 本论文提出了一种新颖的方法分类法，将文本分类算法层次化地分为精细的类别和具体技术，用以解决现有综述的局限性。 |
| [^55] | [A General-purpose AI Avatar in Healthcare.](http://arxiv.org/abs/2401.12981) | 这项研究探讨了在医疗领域中使用通用AI化身进行交互的潜力和方法。通过使用词典和改进机制，创建了一个通用的医疗AI化身应用框架，提供更具吸引力的人机交互，增强了聊天机器人的对话能力和个性特点，实现更好人工智能与患者之间交流的方式。 |
| [^56] | [Identifying Risk Patterns in Brazilian Police Reports Preceding Femicides: A Long Short Term Memory (LSTM) Based Analysis.](http://arxiv.org/abs/2401.12980) | 该研究使用LSTM技术识别巴西警方报告中女性谋杀前的行为模式，并成功实现了对受害者被谋杀风险的分类和预测，为预防女性谋杀做出了贡献。 |
| [^57] | [Anisotropy Is Inherent to Self-Attention in Transformers.](http://arxiv.org/abs/2401.12143) | 本文发现自注意力在Transformer中是固有的各向异性现象，该现象在各种任务和数据集上都普遍存在，不仅限于长尾分布和语言模型。 |
| [^58] | [Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines.](http://arxiv.org/abs/2401.11120) | 该论文研究了将临床实践指南纳入大型语言模型以增强临床决策支持的方法。他们开发了三种方法，并对四个大型语言模型进行了评估，在COVID-19门诊治疗方面取得了较高的性能。 |
| [^59] | [Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media.](http://arxiv.org/abs/2401.10841) | 这项研究提出了一种方法，可以检测新出现的编码恶意术语，为极端社交媒体中的反犹太恶意言论提供了解决方案。 |
| [^60] | [Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring.](http://arxiv.org/abs/2401.08517) | 这个论文研究了一种基于知识图谱情境化的LLM聊天机器人，作为学生学习推荐的解释工具和指导。通过定义上下文并利用人工策划的信息源来调控LLM的生成，聊天机器人能在与学生对话中提供解释和指导。 |
| [^61] | [Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine.](http://arxiv.org/abs/2401.08396) | GPT-4 Vision在医学领域中具有专家级准确度，但在图像理解方面存在缺陷。 |
| [^62] | [Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers.](http://arxiv.org/abs/2401.06461) | 本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。 |
| [^63] | [How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs.](http://arxiv.org/abs/2401.06373) | 本文通过将LLMs视为人类交流者，探索了每天语言互动和AI安全之间忽视的交叉点，并提出了一种通过说服LLMs进行越狱的方法。研究结果表明，说服显著提高了越狱性能，在多个风险类别上均取得了超过92%的攻击成功率。 |
| [^64] | [Fine-tuning and Utilization Methods of Domain-specific LLMs.](http://arxiv.org/abs/2401.02981) | 本研究调查了领域特定LLM的微调和利用方法，以金融领域为例，详细介绍了数据集选择、预处理、模型选择以及在金融领域LLM微调中的关键因素。研究探讨了领域特定词汇的构建和安全合规性的考虑因素，并提供了在金融领域生成领域特定LLM的过程和实施方法。多种金融案例被涵盖在内，包括股票价格预测、金融新闻情绪分析、自动文档处理、研究和信息提取等。 |
| [^65] | [NLP for Maternal Healthcare: Perspectives and Guiding Principles in the Age of LLMs.](http://arxiv.org/abs/2312.11803) | 本研究旨在为母婴健康领域使用自然语言处理（NLP）提供指导原则，并通过调查和研讨会的互动讨论，从受影响者的声音中总结出结果，为使用大型语言模型（LLMs）等工具的健康应用提供伦理框架和指导原则。 |
| [^66] | [Language Modeling on a SpiNNaker 2 Neuromorphic Chip.](http://arxiv.org/abs/2312.09084) | 该论文介绍了在SpiNNaker 2神经形态芯片上实现语言建模的首次尝试。通过利用基于事件的架构和大规模异步处理的硬件，该方法有望在减少能耗的同时保持竞争任务性能。 |
| [^67] | [A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift.](http://arxiv.org/abs/2311.14743) | 本论文基于奖励模型的准确性和校准度评估了基础模型在分布转移下的性能。实验结果显示奖励模型对于提示和响应的转移具有不同的敏感性，并呈现出新颖的校准模式和准确性下降。同时，将常用的OOD检测技术引入到奖励模型设置中，用于检测分布转移。 |
| [^68] | [Formally Specifying the High-Level Behavior of LLM-Based Agents.](http://arxiv.org/abs/2310.08535) | 本文介绍了一个最小生成框架，通过在高级声明中定义所需的代理人行为，然后构建解码监视器，从而实现了基于LLM的代理人的快速设计和实施。 |
| [^69] | [Conversational Health Agents: A Personalized LLM-Powered Agent Framework.](http://arxiv.org/abs/2310.02374) | 该论文介绍了一个基于LLM的会话式健康代理框架，旨在为代理赋予批判性思维、知识获取和问题解决能力，实现个性化的健康护理服务。该框架能够无缝集成医疗工具，实现多语言和多模态对话，并与多种用户数据分析工具连接。 |
| [^70] | [Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns.](http://arxiv.org/abs/2310.01749) | 堆栈注意力为Transformers模型处理层次模式提供了能力，通过结合堆栈和注意力机制，它能有效地学习和识别任意深度的语法结构，特别适用于具有解析难度的上下文无关语言。 |
| [^71] | [Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering.](http://arxiv.org/abs/2309.17249) | 本研究提出了一种名为批量校准（BC）的方法，用于解决大型语言模型中提示脆弱性和偏见因素导致的性能下降问题。BC通过控制批量输入的上下文偏见，统一了现有的校准方法，并具有零-shot和仅推理的特点。 |
| [^72] | [How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?.](http://arxiv.org/abs/2309.08565) | 本文研究了如何将预训练的多语言翻译模型中的属性控制器迁移到没有监督数据的语言。通过全面分析不同数据场景下的训练和推断时控制技术，揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。 |
| [^73] | [Reward Engineering for Generating Semi-structured Explanation.](http://arxiv.org/abs/2309.08347) | 本论文提出了一种奖励工程方法，在生成语言模型的半结构化解释方面取得了增强效果，解决了模型推理能力验证的问题。 |
| [^74] | [PromptASR for contextualized ASR with controllable style.](http://arxiv.org/abs/2309.07414) | PromptASR是一个框架，将提示集成到端到端自动语音识别系统中，实现了具有可控风格的语境化语音转录。在实验中，使用前一话语的真实文本作为内容提示时，相对于基线ASR系统，该系统在阅读图书数据集和内部数据集上分别获得了21.9％和6.8％的词错误率降低。此外，该系统可以采用单词级偏置列表作为提示来提高对罕见单词的识别准确性。同时，该系统还可以使用额外的样式提示来引导ASR系统输出不同风格的转录。 |
| [^75] | [Statistical Rejection Sampling Improves Preference Optimization.](http://arxiv.org/abs/2309.06657) | 本文提出了一种名为统计拒绝抽样的新方法，改进了优化偏好的过程，并解决了传统方法中缺乏奖励模型和从最优策略采样偏好对的问题。 |
| [^76] | [Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models.](http://arxiv.org/abs/2308.15812) | 本研究分析了对于对齐和评估大型语言模型而言，设计反馈选择是评分还是排名对结果的影响。研究发现评分和排名所推断出的偏好存在不一致问题，并且注释者的偏见也会影响结果。同时，研究还发现反馈协议的选择也对评估结果有显著影响。 |
| [^77] | [CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias.](http://arxiv.org/abs/2308.12539) | CALM是一个用于量化语言模型偏见的多任务基准数据集，相比先前数据集更加多样和可靠，能更好地捕捉评估模型偏见所需的语言变化的广度。 |
| [^78] | [VELMA: Verbalization Embodiment of LLM Agents for Vision and Language Navigation in Street View.](http://arxiv.org/abs/2307.06082) | VELMA是一个口头化的LLM智能体，利用人类写作的导航指令中的地标并结合CLIP来进行视觉环境的理解，以实现在街景中的视觉和语言导航。 |
| [^79] | [Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment.](http://arxiv.org/abs/2306.08877) | 该论文提出了一种名为SynGen的方法，通过语法分析和交叉注意力图的对齐来解决文本条件的图像生成模型中实体和视觉属性之间错误关联的问题。 |
| [^80] | [Stack Over-Flowing with Results: The Case for Domain-Specific Pre-Training Over One-Size-Fits-All Models.](http://arxiv.org/abs/2306.03268) | 本文主张在大型预训练模型的潮流中，还应推广面向特定领域的预训练模型，并以 StackOverflow 为例展示了其优越性。 |
| [^81] | [OWQ: Lessons learned from activation outliers for weight quantization in large language models.](http://arxiv.org/abs/2306.02272) | 在大语言模型的推理中，要使用多个服务器贵重的GPU导致显著的成本障碍，OWQ提出的一种后训练量化方法可以在最小质量损失的情况下减少这种限制。它可以通过考虑激活离群值来确定权值量化误差的因素，并为易受攻击的权重分配高精度，具有与OPTQ相当的质量。 |
| [^82] | [Large Language Models are Zero-Shot Rankers for Recommender Systems.](http://arxiv.org/abs/2305.08845) | 大型语言模型表现出有希望的零-shot排名能力，但在感知历史互动顺序和受到偏见影响方面存在问题。本研究通过特殊设计的提示和引导策略来缓解这些问题。 |
| [^83] | [Interpretability at Scale: Identifying Causal Mechanisms in Alpaca.](http://arxiv.org/abs/2305.08809) | 通过使用分布式对齐搜索（DAS）方法，我们在大型语言模型中实现了规模上的解释性，这使得我们能够高效地搜索到解释性因果结构，并应用于Alpaca模型中。 |
| [^84] | [ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation.](http://arxiv.org/abs/2303.13716) | 本文研究了合成通用基准的局限性，发现逻辑形式（LF）的细节可能影响模型性能。作者对COGS基准进行了研究，结果表明基础模型能够获得足够的掌握。作者还强调了设计能准确捕捉自然语言语义的LF的重要性。 |
| [^85] | [Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies.](http://arxiv.org/abs/2202.12312) | 本论文通过对预训练模型进行可控实验证明转移学习的困难性，发现模型可以从句法风格的转变中恢复，但无法从词汇不对齐和嵌入矩阵重新初始化中恢复，即使进行了大量预训练。 |
| [^86] | [A New Sentence Extraction Strategy for Unsupervised Extractive Summarization Methods.](http://arxiv.org/abs/2112.03203) | 本文提出了一种新的句子提取策略，用于改善特征分布和降低摘要句子之间的相互信息，该策略适用于现有的无监督抽取式摘要方法，并在实验证明了其有效性。 |

# 详细

[^1]: MambaByte: 无标记选择性状态空间模型

    MambaByte: Token-free Selective State Space Model. (arXiv:2401.13660v1 [cs.CL])

    [http://arxiv.org/abs/2401.13660](http://arxiv.org/abs/2401.13660)

    MambaByte是一种无标记的选择性状态空间模型，通过在字节级别上进行自回归训练，解决了标准自回归Transformer在处理长序列时的性能问题，并展现了与最先进的子词Transformer相媲美甚至更优的性能，从而证明了MambaByte在无标记语言建模方面的有效性。

    

    无标记语言模型直接从原始字节学习，消除了子词标记化的偏差。然而，操作字节会导致序列长度显著增加，在这种情况下，标准自回归Transformer的扩展性较差。我们尝试了MambaByte，它是基于字节序列自回归训练的无标记适应Mamba状态空间模型。我们的实验表明，与其他字节级模型相比，MambaByte具有计算效率。我们还发现，MambaByte在性能上与甚至胜过最先进的子词Transformer。此外，由于长度的线性扩展，MambaByte在推理过程中获得了快速性能，相比之下，Transformer则没有。我们的研究结果证实了MambaByte在实现无标记语言建模方面的可行性。

    Token-free language models learn directly from raw bytes and remove the bias of subword tokenization. Operating on bytes, however, results in significantly longer sequences, and standard autoregressive Transformers scale poorly in such settings. We experiment with MambaByte, a token-free adaptation of the Mamba state space model, trained autoregressively on byte sequences. Our experiments indicate the computational efficiency of MambaByte compared to other byte-level models. We also find MambaByte to be competitive with and even outperform state-of-the-art subword Transformers. Furthermore, owing to linear scaling in length, MambaByte benefits from fast inference compared to Transformers. Our findings establish the viability of MambaByte in enabling token-free language modeling.
    
[^2]: VisualWebArena: 在真实视觉Web任务上评估多模态代理

    VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks. (arXiv:2401.13649v1 [cs.LG])

    [http://arxiv.org/abs/2401.13649](http://arxiv.org/abs/2401.13649)

    VisualWebArena是一个评估多模态Web代理性能的基准，在真实的“视觉基础任务”上对代理进行了测试。它要求代理准确处理图像-文本输入，解释自然语言指令，并在网站上执行动作来完成用户定义的目标。

    

    能够在网络上进行计划、推理和执行动作的自主代理为自动化计算机任务提供了一个有前途的途径。然而，现有的大多数基准主要关注基于文本的代理，在效果上忽视了许多需要视觉信息才能有效解决的自然任务。鉴于大多数计算机界面是为人类感知而设计的，视觉信息往往以文本数据无法有效利用的方式增强文本数据。为了弥补这一差距，我们引入了VisualWebArena，这是一个设计用于评估多模态Web代理在真实的“视觉基础任务”上性能的基准。VisualWebArena包括一组多样且复杂的基于Web的任务，评估自主多模态代理的各种能力。为了在这个基准上执行，代理需要准确处理图像-文本输入，解释自然语言指令，并在网站上执行动作以完成用户定义的目标。

    Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks. However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively solve. Given that most computer interfaces cater to human perception, visual information often augments textual data in ways that text-only models struggle to harness effectively. To bridge this gap, we introduce VisualWebArena, a benchmark designed to assess the performance of multimodal web agents on realistic \textit{visually grounded tasks}. VisualWebArena comprises of a set of diverse and complex web-based tasks that evaluate various capabilities of autonomous multimodal agents. To perform on this benchmark, agents need to accurately process image-text inputs, interpret natural language instructions, and execute actions on websites to accomplish user-defined objectives. We conduct an ext
    
[^3]: DenoSent：用于自我监督句子表示学习的去噪目标

    DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning. (arXiv:2401.13621v1 [cs.CL])

    [http://arxiv.org/abs/2401.13621](http://arxiv.org/abs/2401.13621)

    本论文提出了一种新颖的对比学习方法，通过引入离散和连续的噪声进行自我监督句子表示学习。实验证明，这种方法在语义文本相似度和迁移任务中表现出色，并且与其他方法相媲美。

    

    对比学习方法主导着句子表示学习。这些方法通过拉近相似的句子表示并将不相似的句子表示推开来规范表示空间，在各种自然语言处理任务中已被证明有效，例如，语义文本相似度（STS）任务。然而，对于这些方法来说，学习细粒度语义是具有挑战性的，因为它们只从句间的角度学习，即，它们的监督信号来自数据样本之间的关系。在这项工作中，我们提出了一种新颖的去噪目标，它继承了另一个视角，即句内的视角。通过引入离散和连续的噪声，我们生成带有噪声的句子，然后训练我们的模型将其恢复为原始形式。我们的实证评估证明，这种方法在语义文本相似度（STS）和广泛的迁移任务中表现出色，与其他方法相媲美。

    Contrastive-learning-based methods have dominated sentence representation learning. These methods regularize the representation space by pulling similar sentence representations closer and pushing away the dissimilar ones and have been proven effective in various NLP tasks, e.g., semantic textual similarity (STS) tasks. However, it is challenging for these methods to learn fine-grained semantics as they only learn from the inter-sentence perspective, i.e., their supervision signal comes from the relationship between data samples. In this work, we propose a novel denoising objective that inherits from another perspective, i.e., the intra-sentence perspective. By introducing both discrete and continuous noise, we generate noisy sentences and then train our model to restore them to their original form. Our empirical evaluations demonstrate that this approach delivers competitive results on both semantic textual similarity (STS) and a wide range of transfer tasks, standing up well in compa
    
[^4]: MM-LLMs: 多模式大语言模型的最新进展

    MM-LLMs: Recent Advances in MultiModal Large Language Models. (arXiv:2401.13601v1 [cs.CL])

    [http://arxiv.org/abs/2401.13601](http://arxiv.org/abs/2401.13601)

    近年来，多模式大语言模型（MM-LLMs）通过成本效益高的训练策略取得了显著进展，扩展了现有的语言模型的多模输入和输出支持。本论文提供了一份综合调查报告，介绍了MM-LLMs的设计和训练方案，整理了现有的MM-LLMs及其性能，总结了关键训练方法，并探讨了未来的研究方向。

    

    在过去的一年中，多模式大语言模型（MM-LLMs）取得了显著的进展，通过成本效益高的训练策略，增强了现有的LLMs对多模输入或输出的支持。这些结果模型不仅保留了LLMs固有的推理和决策能力，还赋予了各种多模任务。本文提供了一份综合性的调查报告，旨在促进对MM-LLMs的进一步研究。具体而言，我们首先概述了模型架构和训练流程的一般设计方案。随后，我们简要介绍了26种现有的MM-LLMs，每种都以其具体的公式为特征。此外，我们还回顾了MM-LLMs在主流基准测试上的性能，并总结了提高MM-LLMs效力的关键训练方法。最后，我们探讨了MM-LLMs的有前途的方向，同时还为该领域的最新发展提供了实时追踪网站。我们希望这份调查报告能够促进对MM-LLMs的进一步研究。

    In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks. In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs. Specifically, we first outline general design formulations for model architecture and training pipeline. Subsequently, we provide brief introductions of $26$ existing MM-LLMs, each characterized by its specific formulations. Additionally, we review the performance of MM-LLMs on mainstream benchmarks and summarize key training recipes to enhance the potency of MM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently maintaining a real-time tracking website for the latest developments in the field. We hope that this surv
    
[^5]: 通过一致性指导在LLMs中进行知识检索和去噪以实现零样本文档级关系三元组抽取

    Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction. (arXiv:2401.13598v1 [cs.CL])

    [http://arxiv.org/abs/2401.13598](http://arxiv.org/abs/2401.13598)

    该论文提出了一种零样本文档级关系三元组抽取（ZeroDocRTE）框架，通过从LLMs中检索和去噪知识来生成标记数据，该方法可以减少获取新关系数据的时间和劳动成本。

    

    文档级关系三元组抽取（DocRTE）是信息系统中的一个基本任务，旨在从文档中同时提取带有语义关系的实体。现有的方法严重依赖大量标记完整的数据。然而，收集和注释新出现的关系的数据耗时且劳动密集。最近的先进大型语言模型（LLMs），如ChatGPT和LLaMA，展现了令人印象深刻的长文本生成能力，启发我们探索一种用于获取具有新关系的自动标记文档的替代方法。在本文中，我们提出了一个零样本文档级关系三元组抽取（ZeroDocRTE）框架，该框架通过从LLMs中检索和去噪知识来生成标记数据，称为GenRDK。具体而言，我们提出了一种检索提示链以指导ChatGPT逐步生成标记的长文本数据。为了提高合成数据的质量，我们提出了一种基于去噪策略的方法

    Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in information systems that aims to simultaneously extract entities with semantic relations from a document. Existing methods heavily rely on a substantial amount of fully labeled data. However, collecting and annotating data for newly emerging relations is time-consuming and labor-intensive. Recent advanced Large Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text generation capabilities, inspiring us to explore an alternative approach for obtaining auto-labeled documents with new relations. In this paper, we propose a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework, which generates labeled data by retrieval and denoising knowledge from LLMs, called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide ChatGPT to generate labeled long-text data step by step. To improve the quality of synthetic data, we propose a denoising strategy based on t
    
[^6]: 用于程序性问答的图形引导问题生成方法

    Graph Guided Question Answer Generation for Procedural Question-Answering. (arXiv:2401.13594v1 [cs.CL])

    [http://arxiv.org/abs/2401.13594](http://arxiv.org/abs/2401.13594)

    本文提出了一种生成详尽的高质量训练数据的方法，用于训练紧凑的、任务特定的QA模型，从而在特定问答任务中与GPT变体模型具有竞争力。这种方法利用过程性文本的结构化特性，通过将每个步骤和整个流程表示为图形，并以图节点为条件，在详尽和可控的方式下自动生成QA对。

    

    本文针对特定任务的问答(QA)问题进行研究，提出了一种生成详尽高质量训练数据的方法，使我们能够训练紧凑的、针对特定任务的QA模型，并与GPT变体模型竞争。关键的技术支持是一种从过程文本中自动生成问题-答案的新机制，它可以处理大量的文本指令，并产生详尽的领域内QA训练数据。目前的QA数据生成方法会产生形式良好且多样化的数据，但其非详尽性不利于训练QA模型。相反，我们利用过程性文本的高度结构化特性，将每个步骤和整个流程表示为图形，并以图节点为条件，自动以详尽和可控的方式生成QA对。对我们方法的全面评估表明：1) 使用我们的方法训练的小型模型能够达到竞争水平。

    In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our 
    
[^7]: 评估大型语言模型在从成人重症护理电子病历中提取语义概念的背景下的应用

    Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes. (arXiv:2401.13588v1 [cs.CL])

    [http://arxiv.org/abs/2401.13588](http://arxiv.org/abs/2401.13588)

    在实际医疗领域中对大型语言模型（LLMs）进行更深入和实用的评估是必要的，该研究旨在评估LLMs在成人重症护理医学复杂环境中的表现。

    

    鉴于大型语言模型（LLMs）的出色表现，该研究将焦点转向了医疗健康领域。然而，它们在实际临床应用中的表现尚未得到充分探讨。传统的问答任务评估不能完全捕捉到复杂的上下文信息。这种差距凸显了在实际医疗领域中对LLMs进行更深入和实用的评估的需求。该研究旨在使用系统化和易于理解的分析方法，包括临床医生注释和裁定，评估LLMs在成人重症护理医学复杂环境中的表现。

    The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance. However, their performance in actual clinical applications has been underexplored. Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts. This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings. Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication. Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes. Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians. Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an
    
[^8]: LLM指令微调中的提示权重实验

    Prompt Weight Experiments for LLM Instruction Fine-Tuning. (arXiv:2401.13586v1 [cs.LG])

    [http://arxiv.org/abs/2401.13586](http://arxiv.org/abs/2401.13586)

    LLM指令微调中，对于短提示完成数据集，提示词标记分类损失加权（PLW）与性能呈负二次关系，而长提示完成数据集则不受PLW影响。

    

    我们进行了一项小型研究，分析了提示词标记分类损失加权（PLW）如何影响在指令任务上进行微调的7B大小的LLaMA模型的性能。我们使用多个指令数据集重现了斯坦福大学的Alpaca实验，其中包括LLaMA 1和LLaMA 2。我们发现，在我们的短提示完成数据集上微调的模型与PLW之间存在负二次关系，而在长提示完成数据集上微调的模型不受PLW的影响。

    We present a small study analyzing how prompt token classification loss weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1 and LLaMA 2 using multiple instruction datasets. We found that models fine-tuned on our short-completion dataset have a negative quadratic relationship with PLW while models fine-tuned on long-completion datasets were unaffected by PLW.
    
[^9]: 基于Mistral的大规模马来西亚语言模型，提升本地语言理解能力

    Large Malaysian Language Model Based on Mistral for Enhanced Local Language Understanding. (arXiv:2401.13565v1 [cs.CL])

    [http://arxiv.org/abs/2401.13565](http://arxiv.org/abs/2401.13565)

    本文介绍了Mistral 7B大规模语言模型在马来西亚语言数据集上的预训练进展和性能优化，证明了继续预训练和扩展上下文长度对提升语言理解能力的有效性，并对比了其在Tatabahasa上的优越性能。

    

    本文提出了Mistral 7B的预训练的重要进展，使用了32.6GB的数据集，相当于11亿个标记。我们研究了扩展上下文长度的影响，发布了上下文长度为4096和32768的模型，并使用特定的16384上下文长度的指令调整模型，我们称之为马来西亚Mistral。我们的实验证明了继续预训练的有效性以及扩展上下文长度对Mistral 7B语言理解能力的影响。此外，我们发布了一个专门调整了16384上下文长度的模型，展示了其捕捉微妙语言细节的潜力。此外，我们的研究还对比了马来西亚Mistral与ChatGPT3.5和Claude 2等著名语言模型，并呈现了令人信服的结果表明马来西亚Mistral在Tatabahasa上的优越性能。

    In this paper, we present significant advancements in the pretraining of Mistral 7B, a large-scale language model, using a dataset of 32.6 GB, equivalent to 1.1 billion tokens. We explore the impact of extending the context length, releasing models with context lengths of 4096 and 32768 tokens, and further refining performance with a specialized 16384 context length instruction-tuned model, we called it Malaysian Mistral.  Our experiments demonstrate the efficacy of continue pretraining and the influence of extended context lengths on Mistral 7B's language understanding capabilities. Additionally, we release a model specifically tuned with a 16384 context length instruction, showcasing its potential for capturing nuanced language intricacies.  Furthermore, our research contributes to the benchmarking of Malaysian Mistral against prominent language models, including ChatGPT3.5 and Claude 2. We present compelling results indicating Malaysian Mistral's superior performance on Tatabahasa (
    
[^10]: SpeechGPT-Gen: 缩放信息链语音生成

    SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation. (arXiv:2401.13527v1 [cs.CL])

    [http://arxiv.org/abs/2401.13527](http://arxiv.org/abs/2401.13527)

    SpeechGPT-Gen是一个8亿参数的语音大型语言模型，通过Chain-of-Information Generation方法来解耦语义和感知信息，在语音生成方面提高了效率。

    

    凭借有效的语音建模，当前的语音大型语言模型（SLLMs）在上下文语音生成和对未见过的说话人的高效泛化方面展示出了出色的能力。然而，现有的信息建模过程受到一定冗余的限制，导致语音生成效率低下。我们提出了信息链生成（CoIG）的方法，用于解耦大规模语音生成中的语义和感知信息。在此基础上，我们开发了SpeechGPT-Gen，一个8亿参数的SLLM，能够高效地进行语义和感知信息建模。它包括一个基于LLM的自回归模型用于语义信息建模，以及一个使用流匹配进行感知信息建模的非自回归模型。此外，我们引入了将语义信息注入先验分布以增强流匹配效率的新方法。广泛的实验结果表明…

    Benefiting from effective speech modeling, current Speech Large Language Models (SLLMs) have demonstrated exceptional capabilities in in-context speech generation and efficient generalization to unseen speakers. However, the prevailing information modeling process is encumbered by certain redundancies, leading to inefficiencies in speech generation. We propose Chain-of-Information Generation (CoIG), a method for decoupling semantic and perceptual information in large-scale speech generation. Building on this, we develop SpeechGPT-Gen, an 8-billion-parameter SLLM efficient in semantic and perceptual information modeling. It comprises an autoregressive model based on LLM for semantic information modeling and a non-autoregressive model employing flow matching for perceptual information modeling. Additionally, we introduce the novel approach of infusing semantic information into the prior distribution to enhance the efficiency of flow matching. Extensive experimental results demonstrate th
    
[^11]: GPT-3.5能否生成和标注出院摘要？

    Can GPT-3.5 Generate and Code Discharge Summaries?. (arXiv:2401.13512v1 [cs.CL])

    [http://arxiv.org/abs/2401.13512](http://arxiv.org/abs/2401.13512)

    GPT-3.5被用于生成和标注医疗文件以进行数据增强，结果显示其对ICD-10代码的编码性能良好，并且生成的文件在临床可接受性评估中得到了认可。

    

    目的：探究GPT-3.5在生成和标注具有ICD-10代码的医疗文件方面的应用，用于低资源标签的数据增强。材料和方法：利用GPT-3.5基于MIMIC-IV数据集中罕见（生成）代码的ICD-10代码描述列表生成和标注了9,606份出院摘要。将其与基线训练集结合，形成一个增强训练集。使用神经编码模型在基线和增强数据上进行训练，并在MIMIC-IV测试集上进行评估。我们报告了全代码集、生成代码及其所属代码族的微观和宏观F1得分。采用弱层次混淆矩阵来确定后面两个代码集中的代码族内和代码族外的编码错误。对GPT-3.5的编码性能进行了自行生成数据和真实MIMIC-IV数据的评估。临床专业人员对生成的文件进行了临床可接受性评估。结果和结论：增强微小

    Objective: To investigate GPT-3.5 in generating and coding medical documents with ICD-10 codes for data augmentation on low-resources labels.  Materials and Methods: Employing GPT-3.5 we generated and coded 9,606 discharge summaries based on lists of ICD-10 code descriptions of patients with infrequent (generation) codes within the MIMIC-IV dataset. Combined with the baseline training set, this formed an augmented training set. Neural coding models were trained on baseline and augmented data and evaluated on a MIMIC-IV test set. We report micro- and macro-F1 scores on the full codeset, generation codes, and their families. Weak Hierarchical Confusion Matrices were employed to determine within-family and outside-of-family coding errors in the latter codesets. The coding performance of GPT-3.5 was evaluated both on prompt-guided self-generated data and real MIMIC-IV data. Clinical professionals evaluated the clinical acceptability of the generated documents.  Results: Augmentation slight
    
[^12]: AI思想如何影响人类思想的创造力、多样性和进化：来自一个大规模动态实验的证据

    How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment. (arXiv:2401.13481v1 [cs.CY])

    [http://arxiv.org/abs/2401.13481](http://arxiv.org/abs/2401.13481)

    AI思想对个体创造力没有影响，但增加了整体思想多样性的数量和变化速率。

    

    大规模语言模型输出的接触正在迅速增加。观看到AI生成的思想将如何影响人类思想？我们进行了一个实验（800+参与者，40+个国家），参与者观看了来自ChatGPT或之前实验参与者的创意思想，然后进行了自己的创意思考。我们变化了AI生成示例的数量（无、低、高曝光）以及示例是否标记为“AI”（披露）。我们的动态实验设计 - 在同一实验条件下，使用之前参与者的思想作为未来参与者的刺激 - 模拟了文化创造的相互依赖过程：创造性思想建立在之前的思想基础上。因此，我们捕捉到了LLM“在文化循环中”的复合效应。我们发现高AI曝光（但不是低AI曝光）并没有影响个人思想的创造力，但增加了整体思想多样性的平均数量和变化速率。AI使思想多样性的累积效应增强了。

    Exposure to large language model output is rapidly increasing. How will seeing AI-generated ideas affect human ideas? We conducted an experiment (800+ participants, 40+ countries) where participants viewed creative ideas that were from ChatGPT or prior experimental participants and then brainstormed their own idea. We varied the number of AI-generated examples (none, low, or high exposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic experiment design -- ideas from prior participants in an experimental condition are used as stimuli for future participants in the same experimental condition -- mimics the interdependent process of cultural creation: creative ideas are built upon prior ideas. Hence, we capture the compounding effects of having LLMs 'in the culture loop'. We find that high AI exposure (but not low AI exposure) did not affect the creativity of individual ideas but did increase the average amount and rate of change of collective idea diversity. AI made 
    
[^13]: SciMMIR:科学多模态信息检索的基准评测

    SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval. (arXiv:2401.13478v1 [cs.IR])

    [http://arxiv.org/abs/2401.13478](http://arxiv.org/abs/2401.13478)

    SciMMIR是一个专门用于科学领域的多模态信息检索基准，通过开放获取的论文集合提取与科学领域相关的图像-文本配对，从而弥补了现有基准在此领域中的差距。

    

    多模态信息检索（MMIR）是一个快速发展的领域，通过先进的表示学习和跨模态对齐研究，在图像-文本配对方面取得了显著进展。然而，在科学领域内评估图像-文本配对的MMIR性能的当前基准存在明显差距，学术语言中描述的图表和表格图像通常不起重要作用。为了弥补这一差距，我们利用开放获取的论文集合构建了一个专门的科学MMIR（SciMMIR）基准，以提取与科学领域相关的数据。该基准包含了530K个精心策划的从科学文档中提取的图像-文本配对，这些图像-文本配对来自于具有详细标题的科学文档中的图表和表格。我们还使用两级子集-子类别层次注释对图像-文本配对进行了注释，以促进对基准模型的更全面评估。我们对零样本和微调进行了评估。

    Multi-modal information retrieval (MMIR) is a rapidly evolving field, where significant progress, particularly in image-text pairing, has been made through advanced representation learning and cross-modality alignment research. However, current benchmarks for evaluating MMIR performance in image-text pairing within the scientific domain show a notable gap, where chart and table images described in scholarly language usually do not play a significant role. To bridge this gap, we develop a specialised scientific MMIR (SciMMIR) benchmark by leveraging open-access paper collections to extract data relevant to the scientific domain. This benchmark comprises 530K meticulously curated image-text pairs, extracted from figures and tables with detailed captions in scientific documents. We further annotate the image-text pairs with two-level subset-subcategory hierarchy annotations to facilitate a more comprehensive evaluation of the baselines. We conducted zero-shot and fine-tuning evaluations o
    
[^14]: SpeechDPR: 开放领域口语问答的端到端口语段落检索

    SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering. (arXiv:2401.13463v1 [cs.CL])

    [http://arxiv.org/abs/2401.13463](http://arxiv.org/abs/2401.13463)

    SpeechDPR是第一个用于开放领域口语问答的端到端框架，能够从口语存档中检索可能包含答案的段落。通过融合无监督ASR和文本密集检索器的知识，SpeechDPR能够获得较好的性能，并且在UASR性能较差时表现更加鲁棒。

    

    口语问答(SQA)是机器通过在给定口语段落中找到答案范围来回答用户问题的关键。过去的SQA方法没有使用ASR，以避免识别错误和词汇外问题。然而，实际的开放领域SQA(openSQA)问题中，机器需要首先从口语存档中检索可能包含答案的段落。本文提出了第一个已知的用于openSQA问题检索组件的端到端框架SpeechDPR。SpeechDPR通过从无监督ASR(UASR)和文本密集检索器(TDR)的级联模型中提炼知识，学习句子级语义表示。不需要手动转录的语音数据。初步实验表明，与级联的UASR和TDR模型相比，性能相当，并且在UASR性能较差时显著提高，验证了这种方法更加鲁棒。

    Spoken Question Answering (SQA) is essential for machines to reply to user's question by finding the answer span within a given spoken passage. SQA has been previously achieved without ASR to avoid recognition errors and Out-of-Vocabulary (OOV) problems. However, the real-world problem of Open-domain SQA (openSQA), in which the machine needs to first retrieve passages that possibly contain the answer from a spoken archive in addition, was never considered. This paper proposes the first known end-to-end framework, Speech Dense Passage Retriever (SpeechDPR), for the retrieval component of the openSQA problem. SpeechDPR learns a sentence-level semantic representation by distilling knowledge from the cascading model of unsupervised ASR (UASR) and text dense retriever (TDR). No manually transcribed speech data is needed. Initial experiments showed performance comparable to the cascading model of UASR and TDR, and significantly better when UASR was poor, verifying this approach is more robus
    
[^15]: 以低计算资源消耗为中心的高效知识库问答框架：基于线索引导路径探索

    Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption. (arXiv:2401.13444v1 [cs.CL])

    [http://arxiv.org/abs/2401.13444](http://arxiv.org/abs/2401.13444)

    该论文介绍了一种以低计算资源消耗为中心的高效知识库问答框架，通过引入线索引导路径探索的方式，将知识库与大型语言模型高效地融合，从而降低了对模型能力的要求，并在实验证明了其优越性能。

    

    在最近的研究中，大型语言模型（LLMs）展示了出色的能力。然而，更新它们的知识面会带来挑战，当面对不熟悉的查询时可能导致不准确性。虽然已经研究了将知识图谱与LLMs集成的方法，但现有方法将LLMs视为主要的决策者，对其能力提出了较高的要求。对于计算成本较低且性能相对较差的LLMs来说，这是不太合适的。本文介绍了一种以线索引导路径探索为核心的知识库问答框架（CGPE），它将知识库与LLMs高效地融合，对模型的能力要求较低。受人类手动检索知识的方法启发，CGPE利用问题中的信息作为线索，系统地探索知识库中所需的知识路径。开源数据集上的实验证明，CGPE优于先前的方法，并且非常适用于计算成本较低且性能较差的LLMs。

    In recent times, large language models (LLMs) have showcased remarkable capabilities. However, updating their knowledge poses challenges, potentially leading to inaccuracies when confronted with unfamiliar queries. While integrating knowledge graphs with LLMs has been explored, existing approaches treat LLMs as primary decision-makers, imposing high demands on their capabilities. This is particularly unsuitable for LLMs with lower computational costs and relatively poorer performance. In this paper, we introduce a Clue-Guided Path Exploration framework (CGPE) that efficiently merges a knowledge base with an LLM, placing less stringent requirements on the model's capabilities. Inspired by the method humans use to manually retrieve knowledge, CGPE employs information from the question as clues to systematically explore the required knowledge path within the knowledge base. Experiments on open-source datasets reveal that CGPE outperforms previous methods and is highly applicable to LLMs w
    
[^16]: 文本分类可以增强领域无关的停用词提取

    Text Categorization Can Enhance Domain-Agnostic Stopword Extraction. (arXiv:2401.13398v1 [cs.CL])

    [http://arxiv.org/abs/2401.13398](http://arxiv.org/abs/2401.13398)

    本文研究了文本分类在自然语言处理中简化停用词提取的作用，通过混合统计和语言学方法创建全面的停用词列表，提高了非洲语言的自然语言处理水平。

    

    本文研究了文本分类在自然语言处理中简化停用词提取的作用，特别关注了包括法语在内的9种非洲语言。通过利用MasakhaNEWS、African Stopwords Project和MasakhaPOS数据集，我们发现，文本分类可以有效地识别大多数考察语言中超过80％的领域无关的停用词。然而，语言变异导致某些语言的识别率较低。有趣的是，我们发现虽然超过40％的停用词在各类新闻中都是共同的，但少于15％的停用词是某一类别独有的。不常见的停用词增加了文本的深度，但它们是否被分类为停用词则取决于上下文。因此，结合统计和语言学方法可以创建全面的停用词列表，凸显了我们混合方法的价值。这项研究提高了非洲语言的自然语言处理水平，并强调了文本分类的重要性。

    This paper investigates the role of text categorization in streamlining stopword extraction in natural language processing (NLP), specifically focusing on nine African languages alongside French. By leveraging the MasakhaNEWS, African Stopwords Project, and MasakhaPOS datasets, our findings emphasize that text categorization effectively identifies domain-agnostic stopwords with over 80% detection success rate for most examined languages. Nevertheless, linguistic variances result in lower detection rates for certain languages. Interestingly, we find that while over 40% of stopwords are common across news categories, less than 15% are unique to a single category. Uncommon stopwords add depth to text but their classification as stopwords depends on context. Therefore combining statistical and linguistic approaches creates comprehensive stopword lists, highlighting the value of our hybrid method. This research enhances NLP for African languages and underscores the importance of text catego
    
[^17]: InstructDoc：一个用于通过指令实现对视觉文档理解的零样本泛化的数据集

    InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions. (arXiv:2401.13313v1 [cs.CV])

    [http://arxiv.org/abs/2401.13313](http://arxiv.org/abs/2401.13313)

    本论文提出了InstructDoc数据集，该数据集包含了30个具有统一指令的VDU数据集，并通过新的基于指令的文档阅读和理解模型InstructDr来提高VDU任务的泛化性能。实验证明，InstructDr可以通过给定的指令有效适应新的VDU数据集、任务和领域，并且在没有具体训练的情况下胜过现有的多模态LLMs和ChatGPT。

    

    本研究探讨了通过人工编写的指令在真实世界文档上完成各种视觉文档理解（VDU）任务（例如问答和信息提取）的问题。为此，我们提出了InstructDoc，这是第一个包含30个公开可用的VDU数据集的大规模收集，每个数据集都具有统一格式的多样指令，涵盖了12个不同任务和包括开放文档类型/格式。此外，为了提高在VDU任务上的泛化性能，我们设计了一种新的基于指令的文档阅读与理解模型InstructDr，它通过可训练的桥接模块连接文档图像、图像编码器和大型语言模型（LLMs）。实验证明，InstructDr能够通过给定的指令有效适应新的VDU数据集、任务和领域，并且在没有具体训练的情况下胜过现有的多模态LLMs和ChatGPT。

    We study the problem of completing various visual document understanding (VDU) tasks, e.g., question answering and information extraction, on real-world documents through human-written instructions. To this end, we propose InstructDoc, the first large-scale collection of 30 publicly available VDU datasets, each with diverse instructions in a unified format, which covers a wide range of 12 tasks and includes open document types/formats. Furthermore, to enhance the generalization performance on VDU tasks, we design a new instruction-based document reading and understanding model, InstructDr, that connects document images, image encoders, and large language models (LLMs) through a trainable bridging module. Experiments demonstrate that InstructDr can effectively adapt to new VDU datasets, tasks, and domains via given instructions and outperforms existing multimodal LLMs and ChatGPT without specific training.
    
[^18]: MaLA-500: 大规模语言适应大型语言模型

    MaLA-500: Massive Language Adaptation of Large Language Models. (arXiv:2401.13303v1 [cs.CL])

    [http://arxiv.org/abs/2401.13303](http://arxiv.org/abs/2401.13303)

    MaLA-500是一种大型语言模型，设计用于覆盖534种语言，并通过在LLaMA 2上进行训练来提高效果。

    

    大型语言模型在自然语言处理领域取得了突破。然而，由于其主要设计针对英语或一小部分语言，其在低资源语言上效果有限。为了填补这一差距，我们引入了MaLA-500，这是一种新颖的大型语言模型，设计用于覆盖534种语言。为了训练MaLA-500，我们采用了词汇扩展和在LLaMA 2上的持续预训练。我们在SIB-200上进行的实验表明，MaLA-500在上下文学习结果方面取得了最先进的成果。我们在https://huggingface.co/MaLA-LM上发布了MaLA-500。

    Large language models have advanced the state of the art in natural language processing. However, their predominant design for English or a limited set of languages creates a substantial gap in their effectiveness for low-resource languages. To bridge this gap, we introduce MaLA-500, a novel large language model designed to cover an extensive range of 534 languages. To train MaLA-500, we employ vocabulary extension and continued pretraining on LLaMA 2 with Glot500-c. Our experiments on SIB-200 show that MaLA-500 achieves state-of-the-art in-context learning results. We release MaLA-500 at https://huggingface.co/MaLA-LM
    
[^19]: 通过大型语言模型之间的多模态辩论实现可解释的有害模因检测

    Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models. (arXiv:2401.13298v1 [cs.CL])

    [http://arxiv.org/abs/2401.13298](http://arxiv.org/abs/2401.13298)

    本文提出了一种通过大型语言模型之间的多模态辩论实现可解释的有害模因检测方法。通过推理有害和无害立场之间的相互矛盾理由，生成可读的解释，提升有害模因检测的效果。

    

    社交媒体时代充斥着互联网模因，需要明确掌握和有效识别有害模因。由于模因中蕴含的隐含含义不能通过表面文本和图像明确传达，这一任务带来了重大挑战。然而，现有的有害模因检测方法未提供可读的解释以揭示这种隐含含义以支持其检测决策。在本文中，我们提出了一种可解释的有害模因检测方法，通过推理有害和无害立场之间的相互矛盾理由来实现。具体而言，受大型语言模型在文本生成和推理方面的强大能力启发，我们首先引发大型语言模型之间的多模态辩论，生成基于矛盾论据的解释。然后，我们提出使用精调的小型语言模型作为辩论裁判来推断有害性，以促进有害和无害信息的多模态融合。

    The age of social media is flooded with Internet memes, necessitating a clear grasp and effective identification of harmful ones. This task presents a significant challenge due to the implicit meaning embedded in memes, which is not explicitly conveyed through the surface text and image. However, existing harmful meme detection methods do not present readable explanations that unveil such implicit meaning to support their detection decisions. In this paper, we propose an explainable approach to detect harmful memes, achieved through reasoning over conflicting rationales from both harmless and harmful positions. Specifically, inspired by the powerful capacity of Large Language Models (LLMs) on text generation and reasoning, we first elicit multimodal debate between LLMs to generate the explanations derived from the contradictory arguments. Then we propose to fine-tune a small language model as the debate judge for harmfulness inference, to facilitate multimodal fusion between the harmfu
    
[^20]: AI助手是否能知道自己不知道的事情?

    Can AI Assistants Know What They Don't Know?. (arXiv:2401.13275v1 [cs.CL])

    [http://arxiv.org/abs/2401.13275](http://arxiv.org/abs/2401.13275)

    本文研究了AI助手是否能知道自己不知道的事情，并通过自然语言表达出来的问题。为了回答这个问题，我们构建了一个特定模型的"I don't know"（Idk）数据集，并与AI助手进行对齐。

    

    最近，基于大型语言模型（LLMs）的AI助手在对话、解决数学问题、编写代码和使用工具等许多任务中表现出令人惊讶的性能。尽管LLMs具有深入的世界知识，但在面对某些知识密集型任务（如开放领域问答）时仍然会出现事实错误。AI助手的这种不真实回答可能在实际应用中造成重大风险。我们认为，AI助手拒绝回答自己不知道的问题是减少幻觉和使助手真实的关键方法。因此，在本文中，我们提出问题“AI助手是否能知道自己不知道的事情，并通过自然语言表达出来？”为了回答这个问题，我们为助手构建了一个特定模型的“I don't know”(Idk)数据集，其中包含了已知和未知的问题，基于现有的开放领域问答数据集。然后我们将助手与其相应的Idk数据进行对齐。

    Recently, AI assistants based on large language models (LLMs) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools. Although LLMs possess intensive world knowledge, they still make factual errors when facing some knowledge intensive tasks, like open-domain question answering. These untruthful responses from the AI assistant may cause significant risks in practical applications. We believe that an AI assistant's refusal to answer questions it does not know is a crucial method for reducing hallucinations and making the assistant truthful. Therefore, in this paper, we ask the question "Can AI assistants know what they don't know and express them through natural language?" To answer this question, we construct a model-specific "I don't know" (Idk) dataset for an assistant, which contains its known and unknown questions, based on existing open-domain question answering datasets. Then we align the assistant with its corresponding I
    
[^21]: MF-AED-AEC: 通过融合多模态、ASR错误检测和ASR错误修正实现语音情感识别

    MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, ASR Error Detection, and ASR Error Correction. (arXiv:2401.13260v1 [cs.CL])

    [http://arxiv.org/abs/2401.13260](http://arxiv.org/abs/2401.13260)

    本文提出了一种名为MF-AED-AEC的方法，通过融合多模态、ASR错误检测和ASR错误修正，通过增强ASR文本的语义一致性来改进语音情感识别的性能。

    

    语音情感识别（SER）中普遍采用的方法是通过整合音频和文本信息来全面识别说话者的情感，其中文本通常通过自动语音识别（ASR）获取。这种方法的一个重要问题是，文本模态中的ASR错误会使SER的性能变差。之前的研究提出使用辅助的ASR错误检测任务来自适应地分配ASR假设中每个词的权重。然而，这种方法的改进潜力有限，因为它没有解决文本中语义信息的一致性。此外，不同模态之间的固有异质性导致它们表示之间的分布差异，使它们的融合具有挑战性。因此，在本文中，我们引入了两个辅助任务，ASR错误检测（AED）和ASR错误修正（AEC），以增强ASR文本的语义一致性，并进一步引入了一种新颖的多模态融合方法。

    The prevalent approach in speech emotion recognition (SER) involves integrating both audio and textual information to comprehensively identify the speaker's emotion, with the text generally obtained through automatic speech recognition (ASR). An essential issue of this approach is that ASR errors from the text modality can worsen the performance of SER. Previous studies have proposed using an auxiliary ASR error detection task to adaptively assign weights of each word in ASR hypotheses. However, this approach has limited improvement potential because it does not address the coherence of semantic information in the text. Additionally, the inherent heterogeneity of different modalities leads to distribution gaps between their representations, making their fusion challenging. Therefore, in this paper, we incorporate two auxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), to enhance the semantic coherence of ASR text, and further introduce a novel multi-modal fusion 
    
[^22]: UniMS-RAG: 用于个性化对话系统的统一多源检索增强生成模型

    UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems. (arXiv:2401.13256v1 [cs.CL])

    [http://arxiv.org/abs/2401.13256](http://arxiv.org/abs/2401.13256)

    这项研究提出了一种统一多源检索增强生成系统（UniMS-RAG），通过统一知识源选择、知识检索和回复生成三个子任务，使语言模型能够根据需求自适应地检索证据和评估关联性，从而生成个性化的回复。

    

    大型语言模型在许多自然语言理解和生成任务中展示出了非凡的能力。然而，在对话系统中涉及到多个信息源时，个性化问题仍然是一个令人向往的属性。为了更好地计划和整合多个信息源在生成个性化回复中的使用，我们首先将其分解为三个子任务：知识源选择、知识检索和回复生成。然后，我们提出了一种新颖的统一多源检索增强生成系统（UniMS-RAG）。具体来说，我们在训练期间使用相同的序列到序列范式将这三个子任务统一起来，通过使用特殊的令牌，即行动令牌和评估令牌，能够自适应地检索证据并评估关联性。使语言模型能够生成行动令牌有助于与各种知识源进行交互，使其能够适应其上下文和生成个性化的回复。

    Large Language Models (LLMs) has shown exceptional capabilities in many natual language understanding and generation tasks. However, the personalization issue still remains a much-coveted property, especially when it comes to the multiple sources involved in the dialogue system. To better plan and incorporate the use of multiple sources in generating personalized response, we firstly decompose it into three sub-tasks: Knowledge Source Selection, Knowledge Retrieval, and Response Generation. We then propose a novel Unified Multi-Source Retrieval-Augmented Generation system (UniMS-RAG) Specifically, we unify these three sub-tasks with different formulations into the same sequence-to-sequence paradigm during the training, to adaptively retrieve evidences and evaluate the relevance on-demand using special tokens, called acting tokens and evaluation tokens. Enabling language models to generate acting tokens facilitates interaction with various knowledge sources, allowing them to adapt their
    
[^23]: SEER: 通过强化学习促进结构化推理和解释

    SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning. (arXiv:2401.13246v1 [cs.CL])

    [http://arxiv.org/abs/2401.13246](http://arxiv.org/abs/2401.13246)

    SEER是一种通过最大化基于结构的回报来促进结构化推理和解释的新方法。

    

    阐明从问题到答案的推理过程，通过结构化解释是根本重要的，因为它显著增强了问答系统的解释性和可信度。然而，结构化解释要求模型进行复杂的结构化推理，这带来了巨大的挑战。大多数现有方法集中在通过监督学习进行单步推理，忽视步骤之间的逻辑依赖关系。同时，现有的基于强化学习（RL）的方法忽视了结构化关系，阻碍了RL在结构化推理中的潜力。在本文中，我们提出了一种名为SEER的新方法，通过最大化基于结构的回报，以促进结构化推理和解释。我们提出的基于结构的回报准确描述了结构化推理中固有的分层和分支结构，有效地捕捉了状态之间的复杂关系。我们还引入了一种细粒度的奖励函数。

    Elucidating the reasoning process with structured explanations from question to answer is fundamentally crucial, as it significantly enhances the interpretability and trustworthiness of question-answering (QA) systems. However, structured explanations demand models to perform intricate structured reasoning, which poses great challenges. Most existing methods focus on single-step reasoning through supervised learning, ignoring logical dependencies between steps. Meanwhile, existing reinforcement learning (RL)-based methods overlook the structured relationships, impeding RL's potential in structured reasoning. In this paper, we propose SEER, a novel method that maximizes a structure-based return to facilitate structured reasoning and explanation. Our proposed structure-based return precisely describes the hierarchical and branching structure inherent in structured reasoning, effectively capturing the intricate relationships between states. We also introduce a fine-grained reward function
    
[^24]: 从随机到有信息选择数据：基于多样性的方法优化人类注释和少样本学习

    From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning. (arXiv:2401.13229v1 [cs.CL])

    [http://arxiv.org/abs/2401.13229](http://arxiv.org/abs/2401.13229)

    该论文介绍了一种基于多样性的方法，从而优化人类注释和少样本学习。传统的随机选择数据方法忽视了数据的特征和模型的需求，而该方法将考虑这些因素，以提高数据选择的效率。

    

    自然语言处理中的一个主要挑战是获取用于监督学习的注释数据。一种选择是使用众包平台进行数据注释。然而，众包引入了与注释者的经验、一致性和偏见相关的问题。另一种选择是使用零样本方法，但与少样本或完全监督的方法相比，零样本方法有其局限性。最近由大型语言模型推动的最新进展显示出潜力，但在数据严重受限的专业领域中，它们往往难以适应。因此，最常见的方法是人类随机注释一组数据点来构建初始数据集。然而，随机抽样数据进行注释通常效率低下，因为它忽视了数据的特征和模型的特定需求。当处理不平衡数据集时，情况更加糟糕，因为随机抽样倾向于严重偏向多数类别，导致过多的注释数据。

    A major challenge in Natural Language Processing is obtaining annotated data for supervised learning. An option is the use of crowdsourcing platforms for data annotation. However, crowdsourcing introduces issues related to the annotator's experience, consistency, and biases. An alternative is to use zero-shot methods, which in turn have limitations compared to their few-shot or fully supervised counterparts. Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data. The most common approaches therefore involve the human itself randomly annotating a set of datapoints to build initial datasets. But randomly sampling data to be annotated is often inefficient as it ignores the characteristics of the data and the specific needs of the model. The situation worsens when working with imbalanced datasets, as random sampling tends to heavily bias towards the majority classes, leading to excessive annotated data. To
    
[^25]: 大规模异构图上基于大型语言模型的链接预测的可扩展性研究

    Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models. (arXiv:2401.13227v1 [cs.CL])

    [http://arxiv.org/abs/2401.13227](http://arxiv.org/abs/2401.13227)

    本研究探索了在大规模异构图上应用大型语言模型进行图学习的方法，提出了LPNL框架用于可扩展链接预测。通过创新的提示语和采样流程，以及分而治之的策略，成功解决了大规模图中的信息过载问题，并在实验中表现出了优越的性能。

    

    探索将大规模语言模型应用于图学习是一项新颖的努力。然而，大图中蕴含的大量信息给这一过程带来了重大挑战。本文侧重于链接预测任务，并介绍了LPNL（Link Prediction via Natural Language），这是一个基于大型语言模型的框架，用于大规模异构图上的可扩展链接预测。我们设计了能以自然语言表达图细节的创新提示语。我们提出了一个两阶段的采样流程，从大规模异构图中提取关键信息，并采用分而治之的策略来控制输入令牌数量在预定限制内，解决了信息过载的挑战。我们还通过自监督学习设计了一个用于链接预测的T5模型进行微调。在大型公共异构图上进行的广泛实验表明，LPNL的性能超过了各种先进的基准模型。

    Exploring the application of large-scale language models to graph learning is a novel endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to this process. This paper focuses on the link prediction task and introduces LPNL (Link Prediction via Natural Language), a framework based on a large language model designed for scalable link prediction on large-scale heterogeneous graphs.We design novel prompts for link prediction that articulate graph details in natural language. We propose a two-stage sampling pipeline to extract crucial information from large-scale heterogeneous graphs, and a divide-and-conquer strategy to control the input token count within predefined limits, addressing the challenge of overwhelming information. We fine-tune a T5 model based on our self-supervised learning designed for for link prediction. Extensive experiments on a large public heterogeneous graphs demonstrate that LPNL outperforms various advanced baselin
    
[^26]: TAT-LLM: 一种针对表格和文本数据的专用语言模型用于离散推理

    TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data. (arXiv:2401.13223v1 [cs.CL])

    [http://arxiv.org/abs/2401.13223](http://arxiv.org/abs/2401.13223)

    TAT-LLM是一种专门用于离散推理的语言模型，针对混合表格和文本数据上的问答任务。该模型通过分步流水线的方式，包括提取器、推理器和执行器，利用LLMs的强大能力来解决问题。而为了应对成本、延迟和数据安全风险等挑战，我们开发了TAT-LLM，一个专门针对此任务的较小LLM。

    

    在这项工作中，我们解决了在混合表格和文本数据上进行问答的问题，这在Web上非常常见（如SEC文件），通常需要离散推理能力。最近，像GPT-4这样的大型语言模型展示了强大的多步骤推理能力。我们考虑利用LLMs的强大能力来解决我们的任务。我们提出了面向表格和文本问答的分步流水线的抽象，包括提取器、推理器和执行器三个关键步骤，并首先设计了一份指令来实例化该流水线并验证GPT-4优于所有现有方法。然而，利用像GPT-4这样的在线LLM存在成本、延迟和数据安全风险等各种挑战，这促使我们专门针对此任务开发较小的LLM。我们通过对现有专家标注数据集自动生成的训练数据对LLaMA 2进行微调，开发了TAT-LLM语言模型。

    In this work, we address question answering (QA) over a hybrid of tabular and textual data that are very common content on the Web (e.g. SEC filings), where discrete reasoning capabilities are often required. Recently, large language models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning capabilities. We then consider harnessing the amazing power of LLMs to solve our task. We abstract a Step-wise Pipeline for tabular and textual QA, which consists of three key steps, including Extractor, Reasoner and Executor, and initially design an instruction to instantiate the pipeline and validate that GPT-4 outperforms all existing methods. However, utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk, which motivates us to specialize smaller LLMs in this task. We develop a TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated automatically from existing expert-annotated datasets following the Step-w
    
[^27]: ULTRA:通过层级建模和逐对优化释放LLMs在事件论证提取中的潜力

    ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement. (arXiv:2401.13218v1 [cs.CL])

    [http://arxiv.org/abs/2401.13218](http://arxiv.org/abs/2401.13218)

    ULTRA是一种层级框架，利用大型语言模型在事件论证提取中进行经济高效的处理，通过自我优化和候选论证集合的生成，解决了位置偏差问题。

    

    将事件在话语中进行结构化提取是至关重要的，因为它可以更深入地理解交流模式和行为趋势。事件论证提取（EAE）是事件中心理解的核心任务，其任务是为给定事件识别特定角色的文本范围（即论证）。文档级EAE（DocEAE）侧重于散布在整个文档中的论证。在这项工作中，我们探索了开源的大型语言模型（LLMs，例如Flan-UL2）在DocEAE任务中的能力。为此，我们提出了ULTRA，一种层级框架，通过更加经济高效地提取事件论证，从而在方法中只需要少于50个注释，并且不需要访问昂贵的API端点。此外，它缓解了LLMs固有的位置偏差问题。ULTRA首先顺序阅读文档的文本块以生成候选论证集合，随后通过自我优化学习放弃非相关的候选。我们进一步介绍了...

    Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a given event. Document-level EAE (DocEAE) focuses on arguments that are scattered across an entire document. In this work, we explore the capabilities of open source Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. To this end, we propose ULTRA, a hierarchical framework that extracts event arguments more cost-effectively -- the method needs as few as 50 annotations and doesn't require hitting costly API endpoints. Further, it alleviates the positional bias issue intrinsic to LLMs. ULTRA first sequentially reads text chunks of a document to generate a candidate argument set, upon which ULTRA learns to drop non-pertinent candidates through self-refinement. We further introduce
    
[^28]: MLLMReID: 基于多模态大语言模型的人物再识别

    MLLMReID: Multimodal Large Language Model-based Person Re-identification. (arXiv:2401.13201v1 [cs.CV])

    [http://arxiv.org/abs/2401.13201](http://arxiv.org/abs/2401.13201)

    MLLMReID是一种基于多模态大语言模型的人物再识别方法，通过微调模型并将其视觉编码器作为主干进行优化，解决了MLLM在ReID任务中的设计指令和特征学习效果的问题。

    

    多模态大语言模型（MLLM）在许多任务中取得了令人满意的结果。然而，它们在人物再识别（ReID）任务中的表现尚未被研究。本文将研究如何将它们适应于ReID任务。一种直观的想法是使用ReID图像-文本数据集对MLLM进行微调，然后将它们的视觉编码器作为ReID的主干。然而，仍存在两个明显的问题：（1）为ReID设计指令时，MLLM可能过度拟合特定指令，而设计各种指令将导致更高的成本。（2）LLM的潜在图像特征向量没有参与损失计算。指令学习，对齐图像-文本特征，导致间接优化和学习目标不充分利用特征，限制了人物特征学习的效果。为了解决这些问题，本文提出了MLLMReID：基于多模态大语言模型的ReID。首先，我们提出了公共指令。

    Multimodal large language models (MLLM) have achieved satisfactory results in many tasks. However, their performance in the task of person re-identification (ReID) has not been explored to date. This paper will investigate how to adapt them for the task of ReID. An intuitive idea is to fine-tune MLLM with ReID image-text datasets, and then use their visual encoder as a backbone for ReID. However, there still exist two apparent issues: (1) Designing instructions for ReID, MLLMs may overfit specific instructions, and designing a variety of instructions will lead to higher costs. (2) Latent image feature vectors from LLMs are not involved in loss computation. Instructional learning, aligning image-text features, results in indirect optimization and a learning objective that inadequately utilizes features, limiting effectiveness in person feature learning. To address these problems, this paper proposes MLLMReID: Multimodal Large Language Model-based ReID. Firstly, we proposed Common Instru
    
[^29]: AgentBoard: 一种多轮LLM智能体的分析评估板

    AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents. (arXiv:2401.13178v1 [cs.CL])

    [http://arxiv.org/abs/2401.13178](http://arxiv.org/abs/2401.13178)

    AgentBoard是一个综合的基准测试和评估框架，专为分析评估LLM智能体而设计，解决了在多轮交互和部分可观察环境中对智能体性能进行基准测试的挑战，并提供了细粒度的进展率指标和评估工具包。

    

    评估大型语言模型（LLM）作为通用智能体对于理解其能力并促进其融入实际应用至关重要。然而，评估过程面临重大挑战。主要障碍之一是在统一框架内对智能体在不同场景下的性能进行基准测试，特别是在维护部分可观察环境和确保多轮交互方面。此外，当前的评估框架主要关注最终成功率，过程中提供的见解很少，无法深入理解模型的能力。为了解决这些挑战，我们引入了AgentBoard，这是一个创新的综合基准和伴随的开源评估框架，专为LLM智能体的分析评估而设计。AgentBoard提供了一种细粒度的进展率指标，捕捉逐步的进展，以及一个综合的评估工具包，具有易于评估和分析模型能力的功能。

    Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assess
    
[^30]: CFMatch: 将自动答案等价评估与人工专家判断在开放域问答中对齐

    CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering. (arXiv:2401.13170v1 [cs.CL])

    [http://arxiv.org/abs/2401.13170](http://arxiv.org/abs/2401.13170)

    CFMatch提出了一个在开放域问答中将自动答案等价评估与人工专家判断对齐的方法，通过提供明确一致的评估指南并引入高效、稳健且轻量级的判别式AE分类器匹配方法来解决当前评估指标与人类判断不一致的问题。

    

    问答系统只有在我们知道答案是否正确的情况下才能取得进展，但对于许多最具挑战和有趣的问答示例，当前用于确定答案等价性的评估指标通常与人类判断不一致，尤其是来自大型语言模型（LLM）的更冗长、自由形式的答案。存在两个挑战：缺乏数据和模型过大：基于LLM的评分器可以更好地与人工评判员相关联，但这个任务只在有限的问答数据集上进行了测试，即使可用，对模型的更新也有限，因为LLM过大且往往昂贵。我们通过提供明确一致的指南来解决这两个问题，这些指南用于从专业人工问答比赛中采纳机器问答在答案等价性评估方面的标准。我们还引入了一种标准评估和一种更高效、稳健且轻量级的判别式AE分类器匹配方法（CFMatch，大小小于1MB），经过训练和验证以更准确地评估答案等价性。

    Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current evaluation metrics to determine answer equivalence (AE) often do not align with human judgments, particularly more verbose, free-form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big: LLM-based scorers can correlate better with human judges, but this task has only been tested on limited QA datasets, and even when available, update of the model is limited because LLMs are large and often expensive. We rectify both of these issues by providing clear and consistent guidelines for evaluating AE in machine QA adopted from professional human QA contests. We also introduce a combination of standard evaluation and a more efficient, robust, and lightweight discriminate AE classifier-based matching method (CFMatch, smaller than 1 MB), trained and validated to more accurately evalu
    
[^31]: 在处理低资源语言时，机器翻译中称呼错误和性别假设问题的研究

    Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages. (arXiv:2401.13165v1 [cs.CL])

    [http://arxiv.org/abs/2401.13165](http://arxiv.org/abs/2401.13165)

    本章论文研究了低资源语言中机器翻译中的性别相关错误，以孟加拉语为例，讨论了性别的假设和推断，以及这些错误导致的后殖民和社会影响。同时提出了提升语言地位的潜在解决方案。

    

    本章论文针对低资源语言中机器翻译中的性别相关错误进行研究。我们首先解释了低资源语言的概念，并探讨了造成这种语言层级的社会和计算因素的不可分割性。通过对我们的母语孟加拉语进行案例研究，我们展示了当源文本中没有提供相应信息时，性别如何被假设和推断出来，并以高资源英语进行翻译。我们讨论了这些错误导致语言消失和表征伤害的后殖民和社会影响，并讨论了提升语言地位的潜在解决方案，以在机器翻译中赋予语言更多的权威性。

    This chapter focuses on gender-related errors in machine translation (MT) in the context of low-resource languages. We begin by explaining what low-resource languages are, examining the inseparable social and computational factors that create such linguistic hierarchies. We demonstrate through a case study of our mother tongue Bengali, a global language spoken by almost 300 million people but still classified as low-resource, how gender is assumed and inferred in translations to and from the high(est)-resource English when no such information is provided in source texts. We discuss the postcolonial and societal impacts of such errors leading to linguistic erasure and representational harms, and conclude by discussing potential solutions towards uplifting languages by providing them more agency in MT conversations.
    
[^32]: SpacTor-T5：使用跨度破坏和替换词汇检测进行T5模型的预训练

    SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection. (arXiv:2401.13160v1 [cs.LG])

    [http://arxiv.org/abs/2401.13160](http://arxiv.org/abs/2401.13160)

    本文提出了一种新的训练方法SpacTor-T5，结合了跨度破坏和替换词汇检测的混合目标函数，并采用两阶段课程表进行预训练。在实验中，SpacTor-T5在各种NLP任务中取得了与标准SC预训练相同的下游性能，同时大大减少了预训练迭代次数和总FLOP。

    

    预训练大型语言模型被认为是极其耗费资源且经常低效，未能充分利用训练文本序列中所蕴含的信息。本文提出了SpacTor，一种新的训练方法，包括(1)将跨度破坏(SC)和替换词汇检测(RTD)结合的混合目标函数，和(2)一个两阶段课程表，首先在初始的$\tau$迭代中优化混合目标函数，然后过渡到标准的SC损失。我们通过实验证明，混合目标函数的有效性与两阶段预训练进度表密切相关，并对此进行了详细分析。在我们对各种NLP任务进行的编码器-解码器架构(T5)的实验中，SpacTor-T5与标准的SC预训练具有相同的下游性能，同时使预训练迭代减少50%，总FLOP减少40%。另外，在给定相同的计算预算的情况下，我们发现SpacTor具有比标准SC预训练更好的性能。

    Pre-training large language models is known to be extremely resource intensive and often times inefficient, under-utilizing the information encapsulated in the training text sequences. In this paper, we present SpacTor, a new training procedure consisting of (1) a hybrid objective combining span corruption (SC) and token replacement detection (RTD), and (2) a two-stage curriculum that optimizes the hybrid objective over the initial $\tau$ iterations, then transitions to standard SC loss. We show empirically that the effectiveness of the hybrid objective is tied to the two-stage pre-training schedule, and provide extensive analysis on why this is the case. In our experiments with encoder-decoder architectures (T5) on a variety of NLP tasks, SpacTor-T5 yields the same downstream performance as standard SC pre-training, while enabling a 50% reduction in pre-training iterations and 40% reduction in total FLOPs. Alternatively, given the same amount of computing budget, we find that SpacTor 
    
[^33]: 在上下文ASR中增强的本地偏置和采样策略

    Locality enhanced dynamic biasing and sampling strategies for contextual ASR. (arXiv:2401.13146v1 [eess.AS])

    [http://arxiv.org/abs/2401.13146](http://arxiv.org/abs/2401.13146)

    本文研究了上下文ASR中增强的本地偏置和采样策略，通过分析不同的采样策略并引入邻域注意力（NA），相对于基准模型，在LibriSpeech数据集和稀有词评估上平均相对词错误率（WER）改善了25.84%。

    

    自动语音识别（ASR）在识别时间变化的稀有短语时仍然面临挑战。上下文偏置（CB）模块可以将ASR模型偏向于与上下文相关的短语。在训练过程中，根据一种采样策略从大量短语中选择一组偏置短语。本文首先分析了不同的采样策略，通过相关性图表揭示了CB在不同训练阶段之间的偏置嵌入关系。其次，我们引入了邻域注意力（NA），将自注意力（SA）局部化到最近的相邻帧，进一步改进CB的输出结果。结果显示，与基准相比，该方法在LibriSpeech数据集和稀有词评估上平均相对词错误率（WER）改善了25.84%。

    Automatic Speech Recognition (ASR) still face challenges when recognizing time-variant rare-phrases. Contextual biasing (CB) modules bias ASR model towards such contextually-relevant phrases. During training, a list of biasing phrases are selected from a large pool of phrases following a sampling strategy. In this work we firstly analyse different sampling strategies to provide insights into the training of CB for ASR with correlation plots between the bias embeddings among various training stages. Secondly, we introduce a neighbourhood attention (NA) that localizes self attention (SA) to the nearest neighbouring frames to further refine the CB output. The results show that this proposed approach provides on average a 25.84% relative WER improvement on LibriSpeech sets and rare-word evaluation compared to the baseline.
    
[^34]: 语言障碍：剖析LLMs在多语言环境中的安全挑战

    The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts. (arXiv:2401.13136v1 [cs.CL])

    [http://arxiv.org/abs/2401.13136](http://arxiv.org/abs/2401.13136)

    本文研究了在多语言环境中，LLMs面临的安全挑战以及缓解这些挑战的方法。在不同语言中，LLMs对恶意提示的响应存在差异，低资源语言下的响应更容易产生不安全、不相关的结果。对于这种差异的原因，本文还研究了使用强化学习和有监督微调等方法对数据进行调节的影响。

    

    随着大型语言模型（LLMs）对全球社区的影响不断扩大，它们在多语言环境中的安全挑战对齐研究变得至关重要。本文研究了LLMs在不同语言中面临的安全挑战的变化，并讨论了缓解这些问题的方法。通过比较当前最先进的LLMs在高资源语言和低资源语言中对同一组恶意提示的响应情况，我们观察到（1）当恶意提示用低资源语言编写时，LLMs往往更容易生成不安全的响应，（2）LLMs在低资源语言下更容易生成与恶意提示无关的响应。为了理解造成这种差异的原因，我们研究了使用与人类反馈的强化学习（RLHF）或有监督微调（SFT）进行指导调节对HH-RLHF数据集的影响。令人惊讶的是，虽然使用高资源语言进行训练可以改善模型的对齐性，但通过训练仍会产生不一致的结果。

    As the influence of large language models (LLMs) spans across global communities, their safety challenges in multilingual settings become paramount for alignment research. This paper examines the variations in safety challenges faced by LLMs across different languages and discusses approaches to alleviating such concerns. By comparing how state-of-the-art LLMs respond to the same set of malicious prompts written in higher- vs. lower-resource languages, we observe that (1) LLMs tend to generate unsafe responses much more often when a malicious prompt is written in a lower-resource language, and (2) LLMs tend to generate more irrelevant responses to malicious prompts in lower-resource languages. To understand where the discrepancy can be attributed, we study the effect of instruction tuning with reinforcement learning from human feedback (RLHF) or supervised finetuning (SFT) on the HH-RLHF dataset. Surprisingly, while training with high-resource languages improves model alignment, traini
    
[^35]: 在尼日利亚网络空间分析COVID-19疫苗情感：来自手动注释的Twitter数据集的洞察。（arXiv:2401.13133v1[cs.CL]）

    Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace: Insights from a Manually Annotated Twitter Dataset. (arXiv:2401.13133v1 [cs.CL])

    [http://arxiv.org/abs/2401.13133](http://arxiv.org/abs/2401.13133)

    本研究利用transformer-based语言模型研究尼日利亚人对COVID-19疫苗的接受程度，并通过分析和可视化发现大多数推文表达中立情感，没有对特定疫苗类型的强烈偏好。

    

    在抗击COVID-19大流行方面取得了许多成功，最初采用了各种预防措施，如封锁、社交距离和使用口罩。最近，已经开发出了各种疫苗，以帮助预防或减轻COVID-19感染的严重程度。尽管这些预防措施和疫苗的有效性，但在社交媒体平台（如Twitter）上存在一些争议。在本文中，我们利用最先进的基于transformer的语言模型来研究尼日利亚人对疫苗的接受程度。我们通过抓取多语言推文使用相关的标签和关键字开发了一个新颖的数据集。我们的分析和可视化结果显示，大多数推文表达了关于COVID-19疫苗的中立情感，一些人表达了积极的观点，并且没有对特定疫苗类型的强烈偏好，尽管Moderna稍微得到了更多的正面评价。

    Numerous successes have been achieved in combating the COVID-19 pandemic, initially using various precautionary measures like lockdowns, social distancing, and the use of face masks. More recently, various vaccinations have been developed to aid in the prevention or reduction of the severity of the COVID-19 infection. Despite the effectiveness of the precautionary measures and the vaccines, there are several controversies that are massively shared on social media platforms like Twitter. In this paper, we explore the use of state-of-the-art transformer-based language models to study people's acceptance of vaccines in Nigeria. We developed a novel dataset by crawling multi-lingual tweets using relevant hashtags and keywords. Our analysis and visualizations revealed that most tweets expressed neutral sentiments about COVID-19 vaccines, with some individuals expressing positive views, and there was no strong preference for specific vaccine types, although Moderna received slightly more pos
    
[^36]: 在科学和工程领域中的种子引导下对细粒度实体进行类型划分

    Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains. (arXiv:2401.13129v1 [cs.CL])

    [http://arxiv.org/abs/2401.13129](http://arxiv.org/abs/2401.13129)

    本文研究了在科学和工程领域中的种子引导下对细粒度实体进行类型划分的任务，提出了用无标注语料库找到更多实体来丰富监督信息的方法，并使用多头注意力的条件随机场模型进行实体划分。

    

    准确地对文本片段中的实体提供类型划分是各种自然语言处理应用的基本任务。许多先前的方法依赖于大量的人工注释数据来执行实体类型划分。然而，在高度专业化的科学和工程领域（例如软件工程和安全领域）中收集此类数据可能耗时且昂贵，更不用提这些模型如果需要应用于保密数据集时，训练和推断数据之间的领域差异。在本文中，我们研究了在科学和工程领域中的种子引导下对细粒度实体类型进行划分的任务，该任务以实体的名称和一些种子实体作为唯一的监督，并旨在将新的实体提及分类为已知和未知类型（即没有种子实体的类型）。为了解决这个问题，我们提出了SEType，首先利用上下文化的无标注语料库找到每个已知类型的更多实体来丰富弱监督信息，然后使用一种带有两层多头注意力的条件随机场模型对实体进行划分。

    Accurately typing entity mentions from text segments is a fundamental task for various natural language processing applications. Many previous approaches rely on massive human-annotated data to perform entity typing. Nevertheless, collecting such data in highly specialized science and engineering domains (e.g., software engineering and security) can be time-consuming and costly, without mentioning the domain gaps between training and inference data if the model needs to be applied to confidential datasets. In this paper, we study the task of seed-guided fine-grained entity typing in science and engineering domains, which takes the name and a few seed entities for each entity type as the only supervision and aims to classify new entity mentions into both seen and unseen types (i.e., those without seed entities). To solve this problem, we propose SEType which first enriches the weak supervision by finding more entities for each seen type from an unlabeled corpus using the contextualized 
    
[^37]: 向可信赖的语言模型迈进：探究大规模语言模型的信息质量

    Towards Trustable Language Models: Investigating Information Quality of Large Language Models. (arXiv:2401.13086v1 [cs.CL])

    [http://arxiv.org/abs/2401.13086](http://arxiv.org/abs/2401.13086)

    这项研究探讨了大规模语言模型的信息质量问题，发现标记化不可靠、偏见以及信息质量下降可能导致幻觉、捏造信息，从而对企业决策产生错误影响。

    

    大规模语言模型（LLM）正在迅速生成大量信息，用户越来越依赖和信任这些数据。尽管LLM取得了显著进展，但由于信息质量的挑战，LLM生成的信息并不完全可信。具体而言，LLM在预训练过程中的标记化不可靠、存在偏见，导致信息质量的完整性下降。此外，由于信息质量下降的问题，LLM可能会产生幻觉、捏造信息。不可靠的信息可能导致企业做出错误决策，影响经济活动。在这项工作中，我们引入了LLM的新颖数学信息质量评估方法，进一步分析和突出了信息质量挑战，以系统地扩展语言模型。

    Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.
    
[^38]: IndiText Boost: 低资源条件下印度语言的文本增强

    IndiText Boost: Text Augmentation for Low Resource India Languages. (arXiv:2401.13085v1 [cs.CL])

    [http://arxiv.org/abs/2401.13085](http://arxiv.org/abs/2401.13085)

    本论文研究了针对低资源印度语言的文本增强方法，包括Easy Data Augmentation、Back Translation、Paraphrasing、使用LLMs进行文本生成以及使用LLMs进行文本扩展等技术。通过二元和多类文本分类实验，研究发现基本的数据增强技术可以显著提升性能。

    

    文本增强是低资源语言中重要的任务，它有助于解决数据稀缺问题。通过数据增强策略来应对数据稀缺问题。多年来，已经对英语进行了大量的数据增强工作，而在印度语言方面却做得很少。这与使用数据增强来处理数据稀缺的事实相反。在这项工作中，我们重点实施Easy Data Augmentation、Back Translation、Paraphrasing、使用LLMs进行文本生成以及使用LLMs进行文本扩展等技术，用于不同语言的文本分类。我们重点关注6种印度语言：信德语、马拉地语、印地语、古吉拉特语、泰卢固语和梵语。据我们所知，目前没有类似的工作用于印度语言的文本增强。我们进行了二元和多类文本分类，以使我们的结果更具可比性。我们得到了令人惊讶的结果，基本的数据增强技术可显著提升性能。

    Text Augmentation is an important task for low-resource languages. It helps deal with the problem of data scarcity. A data augmentation strategy is used to deal with the problem of data scarcity. Through the years, much work has been done on data augmentation for the English language. In contrast, very less work has been done on Indian languages. This is contrary to the fact that data augmentation is used to deal with data scarcity. In this work, we focus on implementing techniques like Easy Data Augmentation, Back Translation, Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for text classification on different languages. We focus on 6 Indian languages namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to our knowledge, no such work exists for text augmentation on Indian languages. We carry out binary as well as multi-class text classification to make our results more comparable. We get surprising results as basic data augmentation techniq
    
[^39]: TCE在《古兰经问答2023》共享任务中的应用: 低资源增强Transformer-基于集成方法的古兰经问答

    TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur'anic QA. (arXiv:2401.13060v1 [cs.CL])

    [http://arxiv.org/abs/2401.13060](http://arxiv.org/abs/2401.13060)

    本文介绍了我们在《古兰经问答2023》共享任务中的应用，通过利用迁移学习和投票集成来提高预测稳定性，使用不同的Transformer模型和阈值机制来解决低资源训练数据的挑战。我们的最佳系统在隐藏数据集上取得了显著提升。

    

    本文介绍了我们在《古兰经问答2023》共享任务A和B中的方法。为了解决训练数据资源稀缺的挑战，我们依靠迁移学习和投票集成来提高在多次运行中的预测稳定性。此外，我们采用不同的体系结构和学习机制，针对两个任务使用一系列的阿拉伯语预训练Transformer模型。为了识别无法回答的问题，我们提出使用一个阈值机制。我们的最佳系统在隐藏数据集上的性能大大超过基准性能，任务A的MAP得分为25.05%，任务B的局部平均准确率(pAP)为57.11%。

    In this paper, we present our approach to tackle Qur'an QA 2023 shared tasks A and B. To address the challenge of low-resourced training data, we rely on transfer learning together with a voting ensemble to improve prediction stability across multiple runs. Additionally, we employ different architectures and learning mechanisms for a range of Arabic pre-trained transformer-based models for both tasks. To identify unanswerable questions, we propose using a thresholding mechanism. Our top-performing systems greatly surpass the baseline performance on the hidden split, achieving a MAP score of 25.05% for task A and a partial Average Precision (pAP) of 57.11% for task B.
    
[^40]: 评估和提升大型语言模型在特定领域医学中的表现：以DocOA为例的骨关节炎管理

    Evaluating and Enhancing Large Language Models Performance in Domain-specific Medicine: Osteoarthritis Management with DocOA. (arXiv:2401.12998v1 [cs.CL])

    [http://arxiv.org/abs/2401.12998](http://arxiv.org/abs/2401.12998)

    本研究评估了大型语言模型在特定领域医学中的表现，并以骨关节炎管理为例进行了增强。研究结果发现，通用语言模型相对于领域特定的骨关节炎管理模型在提供个性化治疗建议方面表现不佳，而专门模型表现有明显提升。

    

    大型语言模型（LLMs）在特定领域医学中的效能，尤其是在管理骨关节炎（OA）等复杂疾病方面，仍然大部分未被探索。本研究聚焦于评估和提升LLMs在特定领域的临床能力，以骨关节炎（OA）管理为案例研究。开发了一个特定领域的基准框架，评估LLMs在领域特定知识和真实临床场景中的临床应用之间的表现。开发了一种针对OA管理的专门LLM，名为DocOA，它结合了检索增强生成（RAG）和指令提示。通过客观和人工评估，比较了GPT-3.5、GPT-4和专门助手DocOA的性能。结果显示，通用LLMs如GPT-3.5和GPT-4在OA管理这种专门领域中的表现较差，尤其是在提供个性化治疗建议方面。然而，DocOA显示了显著的表现提升。

    The efficacy of large language models (LLMs) in domain-specific medicine, particularly for managing complex diseases such as osteoarthritis (OA), remains largely unexplored. This study focused on evaluating and enhancing the clinical capabilities of LLMs in specific domains, using osteoarthritis (OA) management as a case study. A domain specific benchmark framework was developed, which evaluate LLMs across a spectrum from domain-specific knowledge to clinical applications in real-world clinical scenarios. DocOA, a specialized LLM tailored for OA management that integrates retrieval-augmented generation (RAG) and instruction prompts, was developed. The study compared the performance of GPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and human evaluations. Results showed that general LLMs like GPT-3.5 and GPT-4 were less effective in the specialized domain of OA management, particularly in providing personalized treatment recommendations. However, DocOA showed signifi
    
[^41]: 基于遮蔽生成特征方法的渐进蒸馏用于知识图谱补全

    Progressive Distillation Based on Masked Generation Feature Method for Knowledge Graph Completion. (arXiv:2401.12997v1 [cs.CL])

    [http://arxiv.org/abs/2401.12997](http://arxiv.org/abs/2401.12997)

    本文提出了一种基于遮蔽生成特征的渐进蒸馏方法，用于知识图谱补全任务，通过预蒸馏和压缩预训练模型，以及引入遮蔽生成的教师-学生特征，显著降低了模型的复杂性，并解决了特征表示能力差距的问题。

    

    最近几年，基于预训练语言模型 (PLM) 的知识图谱补全 (KGC) 模型展示了有希望的结果。然而，PLM 模型的大量参数和高计算成本对其在下游任务中的应用提出了挑战。本文提出了一种基于遮蔽生成特征的渐进蒸馏方法，用于 KGC 任务，旨在显著降低预训练模型的复杂性。具体而言，我们对 PLM 进行预蒸馏，得到高质量的教师模型，并压缩 PLM 网络得到多等级的学生模型。然而，传统的特征蒸馏在教师模型中只有单一信息表示的限制。为了解决这个问题，我们提出了教师-学生特征的遮蔽生成，其中包含更丰富的表示信息。此外，教师和学生之间存在显著的表示能力差距。因此，我们设计了一种渐进式的蒸馏方法。

    In recent years, knowledge graph completion (KGC) models based on pre-trained language model (PLM) have shown promising results. However, the large number of parameters and high computational cost of PLM models pose challenges for their application in downstream tasks. This paper proposes a progressive distillation method based on masked generation features for KGC task, aiming to significantly reduce the complexity of pre-trained models. Specifically, we perform pre-distillation on PLM to obtain high-quality teacher models, and compress the PLM network to obtain multi-grade student models. However, traditional feature distillation suffers from the limitation of having a single representation of information in teacher models. To solve this problem, we propose masked generation of teacher-student features, which contain richer representation information. Furthermore, there is a significant gap in representation ability between teacher and student. Therefore, we design a progressive dist
    
[^42]: 通过临床记录的自然语言处理与使用诊断代码对比发现存在问题的疗效性鸦片使用的退伍军人：一项比较研究

    A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes. (arXiv:2401.12996v1 [cs.CL])

    [http://arxiv.org/abs/2401.12996](http://arxiv.org/abs/2401.12996)

    通过翻译了的临床记录进行自然语言处理，发现了存在问题的鸦片使用的退伍军人。与仅通过诊断代码识别的鸦片使用障碍患者相比，这些患者具有不同的人口统计学和临床特征。

    

    背景：电子健康记录是鸦片类药物研究的数据来源。众所周知，鸦片类药物滥用难以通过诊断代码进行编码，但是存在问题的鸦片使用可以记录在临床记录中。目标：我们的目标是1）从各种临床记录中识别存在问题的鸦片使用；2）比较仅通过临床记录记录存在问题鸦片使用的患者与使用ICD鸦片使用障碍诊断代码的患者的特征。材料与方法：我们开发并使用自然语言处理（NLP）工具，对来自两个退伍军人事务所区域的患者队列（n=222,371）的临床记录进行分析以识别存在问题的鸦片使用的患者。我们还使用一组ICD诊断代码来识别来自相同队列的患有鸦片使用障碍的患者。我们比较了仅通过NLP识别出的患者与通过诊断代码识别出的患者的人口统计学和临床特征。

    Background: Electronic health records (EHRs) are a data source for opioid research. Opioid use disorder is known to be under-coded as a diagnosis, yet problematic opioid use can be documented in clinical notes.  Objectives: Our goals were 1) to identify problematic opioid use from a full range of clinical notes; and 2) to compare the characteristics of patients identified as having problematic opioid use, exclusively documented in clinical notes, to those having documented ICD opioid use disorder diagnostic codes.  Materials and Methods: We developed and applied a natural language processing (NLP) tool to the clinical notes of a patient cohort (n=222,371) from two Veteran Affairs service regions to identify patients with problematic opioid use. We also used a set of ICD diagnostic codes to identify patients with opioid use disorder from the same cohort. We compared the demographic and clinical characteristics of patients identified only through NLP, to those of patients identified thro
    
[^43]: 协调代码混合对话：在对话中基于人格辅助的代码混合回应生成

    Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed Response Generation in Dialogues. (arXiv:2401.12995v1 [cs.CL])

    [http://arxiv.org/abs/2401.12995](http://arxiv.org/abs/2401.12995)

    本文探索了代码混合对话中的回应生成，并提出了一种利用从对话中获取的五大人格特质来增强回应生成性能的方法。

    

    代码混合是在一个对话中混合多种语言的现象，特别是在回应生成的上下文中，引入了独特的挑战。捕捉代码混合的复杂性被证明是一项艰巨的任务，因为个体的说话风格和文化背景会产生各种各样的变异。在本研究中，我们探索了代码混合对话中的回应生成。我们介绍了一种新颖的方法，重点是利用从对话中以无监督方式获取的五大人格特质来增强回应生成的性能。这些推断出来的人格属性被无缝地编织到对话上下文中，使用一种新颖的融合机制PA3。它使用一种有效的两步注意力公式来融合对话和个性信息。这种融合不仅增强了生成回应的上下文相关性，还提高了模型的整体性能。

    Code-mixing, the blending of multiple languages within a single conversation, introduces a distinctive challenge, particularly in the context of response generation. Capturing the intricacies of code-mixing proves to be a formidable task, given the wide-ranging variations influenced by individual speaking styles and cultural backgrounds. In this study, we explore response generation within code-mixed conversations. We introduce a novel approach centered on harnessing the Big Five personality traits acquired in an unsupervised manner from the conversations to bolster the performance of response generation. These inferred personality attributes are seamlessly woven into the fabric of the dialogue context, using a novel fusion mechanism, PA3. It uses an effective two-step attention formulation to fuse the dialogue and personality information. This fusion not only enhances the contextual relevance of generated responses but also elevates the overall performance of the model. Our experiment
    
[^44]: 使用先进的自然语言处理和伪标签技术自动评分临床病人笔记

    Automated Scoring of Clinical Patient Notes using Advanced NLP and Pseudo Labeling. (arXiv:2401.12994v1 [cs.CL])

    [http://arxiv.org/abs/2401.12994](http://arxiv.org/abs/2401.12994)

    本研究介绍了一种使用先进的自然语言处理和伪标签技术自动评分临床病人笔记的方法，提高了评估的效率和效果，同时缩短了训练时间。实验结果显示模型性能的改进，表明在临床笔记评估方面可能存在潜在的转变。

    

    临床病人笔记对于记录病人互动、诊断和治疗计划在医疗实践中至关重要。确保对这些笔记的准确评估对于医学教育和认证至关重要。然而，手动评估复杂且耗时，往往导致评估结果的可变性和资源消耗的增加。为了应对这些挑战，本研究引入了一种利用最先进的自然语言处理技术，具体包括封掩语言建模(MLM)预训练和伪标签的方法。我们的方法在不降低性能的前提下，显著提高了效率和效果，并大大减少了训练时间。实验结果展示了模型性能的提高，表明临床笔记评估可能发生转变。

    Clinical patient notes are critical for documenting patient interactions, diagnoses, and treatment plans in medical practice. Ensuring accurate evaluation of these notes is essential for medical education and certification. However, manual evaluation is complex and time-consuming, often resulting in variability and resource-intensive assessments. To tackle these challenges, this research introduces an approach leveraging state-of-the-art Natural Language Processing (NLP) techniques, specifically Masked Language Modeling (MLM) pretraining, and pseudo labeling. Our methodology enhances efficiency and effectiveness, significantly reducing training time without compromising performance. Experimental results showcase improved model performance, indicating a potential transformation in clinical note assessment.
    
[^45]: 通过情感分类来估计口腔问题的严重程度

    Estimating the severity of dental and oral problems via sentiment classification over clinical reports. (arXiv:2401.12993v1 [cs.CL])

    [http://arxiv.org/abs/2401.12993](http://arxiv.org/abs/2401.12993)

    通过分析放射学报告的文本，自动系统可以准确估计口腔问题的严重程度，对于患者的及时决策至关重要。

    

    分析作者在文本中的情感作为一种识别文本极性的技术，在医学和牙科等各个领域中都可以很实用和有用。目前，由于患者对自身状况了解有限、难以接触专科医生或者对疾病的恐惧，尤其是在大流行病条件下，接收放射学报告和咨询医生之间可能存在延迟。在某些情况下，这种延迟可能对患者带来重大风险，因此及时决策至关重要。通过分析放射学报告的文本，自动系统可以通知患者其病情恶化程度，这在及时决策方面将产生巨大影响。本研究收集了来自Shiraz大学医学科学院的1,134份锥束计算机断层摄影（CBCT）照片报告数据集。每个案例都经过检查，由专家对每个文档上的患者状况标注了严重程度。

    Analyzing authors' sentiments in texts as a technique for identifying text polarity can be practical and useful in various fields, including medicine and dentistry. Currently, due to factors such as patients' limited knowledge about their condition, difficulties in accessing specialist doctors, or fear of illness, particularly in pandemic conditions, there might be a delay between receiving a radiology report and consulting a doctor. In some cases, this delay can pose significant risks to the patient, making timely decision-making crucial. Having an automatic system that can inform patients about the deterioration of their condition by analyzing the text of radiology reports could greatly impact timely decision-making. In this study, a dataset comprising 1,134 cone-beam computed tomography (CBCT) photo reports was collected from the Shiraz University of Medical Sciences. Each case was examined, and an expert labeled a severity level for the patient's condition on each document. After p
    
[^46]: 通过语言无关的语句级语音编码实现的语音对语音翻译

    TranSentence: Speech-to-speech Translation via Language-agnostic Sentence-level Speech Encoding without Language-parallel Data. (arXiv:2401.12992v1 [cs.CL])

    [http://arxiv.org/abs/2401.12992](http://arxiv.org/abs/2401.12992)

    本文介绍了一种使用语言无关的语句级语音编码实现的语音到语音翻译方法，该方法不需要语言平行语音数据，并且可用于多语言翻译。

    

    虽然语音到语音翻译领域有了显著的进展，但传统模型仍需要源语言和目标语言之间的语言平行语音数据进行训练。本文介绍了一种新颖的语音到语音翻译方法，该方法不需要语言平行语音数据。为了实现这一点，我们首先采用了一种语言无关的语句级语音编码，它可以捕捉到语音的语义信息，而不受语言的影响。然后我们通过训练模型，基于从语言无关的句子级语音编码器中获得的编码嵌入生成语音。我们可以使用来自源语言语音的语言无关语音嵌入在推理阶段生成目标语言语音，尽管我们仅在目标语言的单语数据上进行训练。此外，我们还将该方法扩展到多语言语音到语音翻译。实验结果证明这种方法的有效性。

    Although there has been significant advancement in the field of speech-to-speech translation, conventional models still require language-parallel speech data between the source and target languages for training. In this paper, we introduce TranSentence, a novel speech-to-speech translation without language-parallel speech data. To achieve this, we first adopt a language-agnostic sentence-level speech encoding that captures the semantic information of speech, irrespective of language. We then train our model to generate speech based on the encoded embedding obtained from a language-agnostic sentence-level speech encoder that is pre-trained with various languages. With this method, despite training exclusively on the target language's monolingual data, we can generate target language speech in the inference stage using language-agnostic speech embedding from the source language speech. Furthermore, we extend TranSentence to multilingual speech-to-speech translation. The experimental resu
    
[^47]: 主题建模：超越令牌输出

    Topic Modelling: Going Beyond Token Outputs. (arXiv:2401.12990v1 [cs.CL])

    [http://arxiv.org/abs/2401.12990](http://arxiv.org/abs/2401.12990)

    这篇论文提出了一种将传统主题建模方法的输出扩展到仅限于隔离令牌列表之外的新方法。

    

    主题建模是一种文本挖掘技术，用于从多个文档中识别显著主题。通常输出是由常常共同出现在这些文档中的隔离令牌组成的主题集合。从人类的角度来看，这些输出可能不足以充分推断主题的含义；因此，它们的可解释性常常被错误地理解。尽管有几项研究试图自动扩展主题描述以增强主题模型的解释性，但它们依赖于可能不可用的外部语言资源，并需要保持最新以生成相关结果，并在训练或处理数据时存在隐私问题。本文提出了一种将传统主题建模方法的输出扩展到仅限于隔离令牌列表之外的新方法。

    Topic modelling is a text mining technique for identifying salient themes from a number of documents. The output is commonly a set of topics consisting of isolated tokens that often co-occur in such documents. Manual effort is often associated with interpreting a topic's description from such tokens. However, from a human's perspective, such outputs may not adequately provide enough information to infer the meaning of the topics; thus, their interpretability is often inaccurately understood. Although several studies have attempted to automatically extend topic descriptions as a means of enhancing the interpretation of topic models, they rely on external language sources that may become unavailable, must be kept up-to-date to generate relevant results, and present privacy issues when training on or processing data. This paper presents a novel approach towards extending the output of traditional topic modelling methods beyond a list of isolated tokens. This approach removes the dependenc
    
[^48]: 在交火中：评估使用语言模型众包枪支暴力报告的效果

    Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports. (arXiv:2401.12989v1 [cs.CL])

    [http://arxiv.org/abs/2401.12989](http://arxiv.org/abs/2401.12989)

    本研究评估了使用语言模型从社交媒体数据中监测枪支暴力事件的可行性。研究团队使用经过微调的BERT模型识别巴西的枪支暴力报告并取得了高准确度。研究结果有助于人权组织收集包含所需数据的全面数据库。

    

    枪支暴力是一个紧迫且不断增长的人权问题，影响着社会的方方面面，从医疗保健和教育到心理学和经济学。可靠的枪支事件数据对于制定更有效的公共政策和应急响应至关重要。然而，缺乏全面的数据库和面对面调查的风险阻止了人权组织在大多数国家收集所需的数据。在这里，我们与一家巴西人权组织合作，对语言模型进行系统评估，以帮助监测来自社交媒体数据的现实世界枪支事件。我们提出了一个在Twitter上经过微调的基于BERT的模型，用于区分枪支暴力报告和普通葡萄牙语文本。我们的模型达到了高达0.97的AUC分数。然后，我们将我们的模型整合到一个Web应用程序中，并在实时干预中对其进行测试。我们研究并采访巴西分析师，他们在持续进行社交媒体事实核查。

    Gun violence is a pressing and growing human rights issue that affects nearly every dimension of the social fabric, from healthcare and education to psychology and the economy. Reliable data on firearm events is paramount to developing more effective public policy and emergency responses. However, the lack of comprehensive databases and the risks of in-person surveys prevent human rights organizations from collecting needed data in most countries. Here, we partner with a Brazilian human rights organization to conduct a systematic evaluation of language models to assist with monitoring real-world firearm events from social media data. We propose a fine-tuned BERT-based model trained on Twitter (now X) texts to distinguish gun violence reports from ordinary Portuguese texts. Our model achieves a high AUC score of 0.97. We then incorporate our model into a web application and test it in a live intervention. We study and interview Brazilian analysts who continuously fact-check social media
    
[^49]: 慢性病管理的少样本学习：利用大型语言模型和多Prompt工程与医疗知识注入

    Few-Shot Learning for Chronic Disease Management: Leveraging Large Language Models and Multi-Prompt Engineering with Medical Knowledge Injection. (arXiv:2401.12988v1 [cs.CL])

    [http://arxiv.org/abs/2401.12988](http://arxiv.org/abs/2401.12988)

    本研究提出了慢性病管理的少样本学习框架，利用大型语言模型和多Prompt工程进行精神障碍的检测，通过个性化的提示和医疗知识注入来解决数据挑战，实现慢性病管理的目标。

    

    本研究利用最先进的人工智能技术进行慢性病管理，特别是通过用户生成的文本内容来检测各种精神障碍。现有研究通常依赖于全监督机器学习，这带来了一些挑战，比如注释庞大的训练数据对于每种疾病的费时费力的手动过程，以及需要为每个问题设计专门的深度学习架构。为了解决这些挑战，我们提出了一个新颖的框架，利用了先进的人工智能技术，包括大型语言模型和多Prompt工程。具体而言，我们解决了数据驱动慢性病管理中的两个关键技术挑战：（1）开发个性化的提示来表示每个用户的独特性，以及（2）将医疗知识融入到提示中，为慢性病检测提供上下文，指导学习目标，并实现预测目标。我们使用四种精神障碍来评估我们的方法。

    This study harnesses state-of-the-art AI technology for chronic disease management, specifically in detecting various mental disorders through user-generated textual content. Existing studies typically rely on fully supervised machine learning, which presents challenges such as the labor-intensive manual process of annotating extensive training data for each disease and the need to design specialized deep learning architectures for each problem. To address such challenges, we propose a novel framework that leverages advanced AI techniques, including large language models and multi-prompt engineering. Specifically, we address two key technical challenges in data-driven chronic disease management: (1) developing personalized prompts to represent each user's uniqueness and (2) incorporating medical knowledge into prompts to provide context for chronic disease detection, instruct learning objectives, and operationalize prediction goals. We evaluate our method using four mental disorders, w
    
[^50]: TelME：教师导向的多模融合网络用于对话中的情绪识别

    TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation. (arXiv:2401.12987v1 [cs.CL])

    [http://arxiv.org/abs/2401.12987](http://arxiv.org/abs/2401.12987)

    TelME是一种教师导向的多模融合网络，通过跨模态知识蒸馏实现对话中情绪识别的优化，取得了在多说话人数据集MELD上的最先进性能。

    

    对话中的情绪识别在使对话系统能够有效回应用户请求方面起着至关重要的作用。对话中的情绪可以通过音频、视觉和文本等多种模态的表示进行识别。然而，由于非语言模态对识别情绪的贡献较弱，多模态情绪识别一直被认为是一项具有挑战性的任务。本文提出了一种用于对话中情绪识别的教师导向多模融合网络（TelME）。TelME通过跨模态知识蒸馏将信息从作为教师的语言模型传递给非语言的学生，从而优化了弱模态的效能。然后，我们采用一种移动融合方法将多模态特征组合起来，其中学生网络支持教师。TelME在MELD（一种用于对话情绪识别的多说话人数据集）上实现了最先进的性能。最后，我们通过额外的实验论证了我们组件的有效性。

    Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue systems to effectively respond to user requests. The emotions in a conversation can be identified by the representations from various modalities, such as audio, visual, and text. However, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal knowledge distillation to transfer information from a language model acting as the teacher to the non-verbal students, thereby optimizing the efficacy of the weak modalities. We then combine multimodal features using a shifting fusion approach in which student networks support the teacher. TelME achieves state-of-the-art performance in MELD, a multi-speaker conversation dataset for ERC. Finally, we demonstrate the effectiveness of our components through additional expe
    
[^51]: 众包自适应调查

    Crowdsourced Adaptive Surveys. (arXiv:2401.12986v1 [cs.CL])

    [http://arxiv.org/abs/2401.12986](http://arxiv.org/abs/2401.12986)

    众包自适应调查方法（CSAS）结合自然语言处理和自适应算法，能够根据用户输入演变问题库，并在调查中适应新的问题，应用在拉丁裔信息环境和议题重要性领域，能够识别难以通过传统方法跟踪的主张或问题。

    

    公众舆论调查对于民主决策至关重要，但对于传统调查方法来说，快速变化的信息环境和在小众社区中衡量观点可能是具有挑战性的。本文介绍了一种众包自适应调查方法（CSAS），它将自然语言处理和自适应算法的进展结合起来，生成随着用户输入不断演变的问题库。CSAS方法将参与者提供的开放式文本转换为Likert式项目，并应用多臂赌博算法来确定应优先考虑在调查中的用户提供问题。该方法的自适应性允许探索新的调查问题，同时在调查长度上施加最小的成本。在拉丁裔信息环境和议题重要性领域的应用展示了CSAS识别可能难以通过标准方法跟踪的主张或问题的能力。最后，我提出 Conclusion by di的结束语。

    Public opinion surveys are vital for informing democratic decision-making, but responding to rapidly changing information environments and measuring beliefs within niche communities can be challenging for traditional survey methods. This paper introduces a crowdsourced adaptive survey methodology (CSAS) that unites advances in natural language processing and adaptive algorithms to generate question banks that evolve with user input. The CSAS method converts open-ended text provided by participants into Likert-style items and applies a multi-armed bandit algorithm to determine user-provided questions that should be prioritized in the survey. The method's adaptive nature allows for the exploration of new survey questions, while imposing minimal costs in survey length. Applications in the domains of Latino information environments and issue importance showcase CSAS's ability to identify claims or issues that might otherwise be difficult to track using standard approaches. I conclude by di
    
[^52]: 人类与合成测试数据以及往返测试对偏见分析系统评估的影响

    The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias. (arXiv:2401.12985v1 [cs.CL])

    [http://arxiv.org/abs/2401.12985](http://arxiv.org/abs/2401.12985)

    本研究通过引入人工生成的聊天机器人数据集和考虑往返测试的设置，评估了情感分析系统（SASs）的偏见。结果显示，在聊天机器人数据上评估SASs显示出更多的偏见，而往返测试则更真实地展示了SASs的性能。

    

    情感分析系统（SASs）是数据驱动的人工智能系统，当给定一段文本作为输入时，可以输出情感极性和情感强度。和其他人工智能一样，当SASs面临数据变化时，也会出现不稳定的行为，这可能会导致在AI与人类合作时出现问题，特别是涉及到保护属性（如性别、种族和年龄）的数据时，我们可能会对其存在偏见的信任感产生疑虑。最近，提出了一种在黑盒设置中评估SASs的方法，该方法无需训练数据或代码，并通过使用合成英文数据对其进行偏见评级。我们通过引入两个人工生成的聊天机器人数据集来扩展这个方法，并考虑了往返测试的设置，即通过一个中间语言将数据从一种语言翻译为相同语言。我们发现这些设置可以更真实地展示SASs的性能。具体来说，我们发现在聊天机器人数据上评估SASs显示出比合成数据更多的偏见，并且使用西班牙语和丹麦语进行往返测试。

    Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that output polarity and emotional intensity when given a piece of text as input. Like other AIs, SASs are also known to have unstable behavior when subjected to changes in data which can make it problematic to trust out of concerns like bias when AI works with humans and data has protected attributes like gender, race, and age. Recently, an approach was introduced to assess SASs in a blackbox setting without training data or code, and rating them for bias using synthetic English data. We augment it by introducing two human-generated chatbot datasets and also consider a round-trip setting of translating the data from one language to the same through an intermediate language. We find that these settings show SASs performance in a more realistic light. Specifically, we find that rating SASs on the chatbot data showed more bias compared to the synthetic data, and round-tripping using Spanish and Danish 
    
[^53]: 在机械工程教育中评估大型语言模型：关于以力学为重点的概念理解的研究

    Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding. (arXiv:2401.12983v1 [cs.CL])

    [http://arxiv.org/abs/2401.12983](http://arxiv.org/abs/2401.12983)

    本研究通过对三个大型语言模型（LLMs）在机械工程领域中解决概念性问题的能力进行评估，发现GPT-4在各个力学主题的问题回答方面表现优于其他两个模型和人类对照组，显示出潜在的未来改进空间。

    

    本研究是对大型语言模型（LLMs）在机械工程领域中解决概念性问题的能力进行的开创性研究，重点是力学。我们使用包含126个多项选择题的手工制作的考试来进行考察，涵盖了力学课程的各个方面，包括流体力学、机械振动、工程静力学和动力学、材料力学、弹性理论和连续介质力学。我们对三个LLM进行了评估，包括ChatGPT（GPT-3.5）、ChatGPT（GPT-4）和Claude（Claude-2.1），并将其与具有或没有机械工程背景的工程教职员和学生进行了比较。研究结果显示，在各种力学主题的问题回答方面，除了连续介质力学外，GPT-4的表现优于其他两个LLM和人类对照组。这表明GPT模型在处理符号计算和张量分析方面有潜在的未来改进空间。

    This study is a pioneering endeavor to investigate the capabilities of Large Language Models (LLMs) in addressing conceptual questions within the domain of mechanical engineering with a focus on mechanics. Our examination involves a manually crafted exam encompassing 126 multiple-choice questions, spanning various aspects of mechanics courses, including Fluid Mechanics, Mechanical Vibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of Elasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5), ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against engineering faculties and students with or without mechanical engineering background. The findings reveal GPT-4's superior performance over the other two LLMs and human cohorts in answering questions across various mechanics topics, except for Continuum Mechanics. This signals the potential future improvements for GPT models in handling symbolic calculations and tensor analyses
    
[^54]: 文本分类：一项回顾、实证和实验评估

    Text Classification: A Review, Empirical, and Experimental Evaluation. (arXiv:2401.12982v1 [cs.CL])

    [http://arxiv.org/abs/2401.12982](http://arxiv.org/abs/2401.12982)

    本论文提出了一种新颖的方法分类法，将文本分类算法层次化地分为精细的类别和具体技术，用以解决现有综述的局限性。

    

    数据的爆炸性和广泛增长使得使用文本分类从大量数据中提取关键信息成为必要。因此，对于经典和深度学习的文本分类方法的研究出现了激增。尽管文献中提出了许多方法，但仍然迫切需要一份全面和最新的综述。现有的综述文章将文本分类算法分为广泛的类别，这可能导致对无关算法的错误分类，以及使用相同度量标准对其质量和行为进行错误评估。为了解决这些局限性，我们的论文引入了一种新颖的方法分类法，将算法层次化地分为精细的类别和具体技术。该分类法包括方法学类别、方法学技术和方法学子技术。我们的研究是首次利用这种方法分类法对算法进行分类的调查。

    The explosive and widespread growth of data necessitates the use of text classification to extract crucial information from vast amounts of data. Consequently, there has been a surge of research in both classical and deep learning text classification methods. Despite the numerous methods proposed in the literature, there is still a pressing need for a comprehensive and up-to-date survey. Existing survey papers categorize algorithms for text classification into broad classes, which can lead to the misclassification of unrelated algorithms and incorrect assessments of their qualities and behaviors using the same metrics. To address these limitations, our paper introduces a novel methodological taxonomy that classifies algorithms hierarchically into fine-grained classes and specific techniques. The taxonomy includes methodology categories, methodology techniques, and methodology sub-techniques. Our study is the first survey to utilize this methodological taxonomy for classifying algorithm
    
[^55]: 一个通用的医疗人工智能化身

    A General-purpose AI Avatar in Healthcare. (arXiv:2401.12981v1 [cs.CL])

    [http://arxiv.org/abs/2401.12981](http://arxiv.org/abs/2401.12981)

    这项研究探讨了在医疗领域中使用通用AI化身进行交互的潜力和方法。通过使用词典和改进机制，创建了一个通用的医疗AI化身应用框架，提供更具吸引力的人机交互，增强了聊天机器人的对话能力和个性特点，实现更好人工智能与患者之间交流的方式。

    

    最近机器学习和自然语言处理的进展推动了人工智能作为医疗行业中宝贵工具的快速发展。使用大型语言模型(LLM)作为对话代理或聊天机器人有潜力帮助医生诊断患者、检测疾病的早期症状以及向患者提供健康建议。本文关注聊天机器人在医疗领域的作用，探索使用化身来使人工智能的交互对患者更具吸引力。通过使用三类别提示词典和提示改进机制，演示了一个通用的医疗人工智能化身应用框架。建议采用两阶段方法对通用的医疗人工智能语言模型进行微调，并创建不同的医疗人工智能化身与用户讨论医学问题。提示工程增强了聊天机器人的对话能力和人格特点，培养了与患者更具人类交流方式的互动。归根结底，该论文提出了在医疗领域中实现更好人工智能与患者之间交流的方法。

    Recent advancements in machine learning and natural language processing have led to the rapid development of artificial intelligence (AI) as a valuable tool in the healthcare industry. Using large language models (LLMs) as conversational agents or chatbots has the potential to assist doctors in diagnosing patients, detecting early symptoms of diseases, and providing health advice to patients. This paper focuses on the role of chatbots in healthcare and explores the use of avatars to make AI interactions more appealing to patients. A framework of a general-purpose AI avatar application is demonstrated by using a three-category prompt dictionary and prompt improvement mechanism. A two-phase approach is suggested to fine-tune a general-purpose AI language model and create different AI avatars to discuss medical issues with users. Prompt engineering enhances the chatbot's conversational abilities and personality traits, fostering a more human-like interaction with patients. Ultimately, the
    
[^56]: 在巴西警方报告中识别女性谋杀前的风险模式：基于LSTM的分析

    Identifying Risk Patterns in Brazilian Police Reports Preceding Femicides: A Long Short Term Memory (LSTM) Based Analysis. (arXiv:2401.12980v1 [cs.CL])

    [http://arxiv.org/abs/2401.12980](http://arxiv.org/abs/2401.12980)

    该研究使用LSTM技术识别巴西警方报告中女性谋杀前的行为模式，并成功实现了对受害者被谋杀风险的分类和预测，为预防女性谋杀做出了贡献。

    

    女性谋杀是指男性伴侣或家庭成员对女性受害者的杀害，并与性别暴力有关。研究表明，在这些谋杀之前存在一种加剧的暴力模式，如果能评估受害者面临的危险程度，就有可能预防这种情况。机器学习提供了一种有前景的方法，可以基于对暴力行为的描述来预测风险水平。在本研究中，我们使用了长短期记忆（LSTM）技术来识别巴西警方报告中女性谋杀前的行为模式。我们的第一个目标是将这些报告的内容分类为受害者被谋杀的较低风险或较高风险，准确率达到了66%。在第二种方法中，我们开发了一个模型来预测受害者在一系列模式化事件中可能经历的下一步行动。这两种方法都对我们理解预防女性谋杀有所贡献。

    Femicide refers to the killing of a female victim, often perpetrated by an intimate partner or family member, and is also associated with gender-based violence. Studies have shown that there is a pattern of escalating violence leading up to these killings, highlighting the potential for prevention if the level of danger to the victim can be assessed. Machine learning offers a promising approach to address this challenge by predicting risk levels based on textual descriptions of the violence. In this study, we employed the Long Short Term Memory (LSTM) technique to identify patterns of behavior in Brazilian police reports preceding femicides. Our first objective was to classify the content of these reports as indicating either a lower or higher risk of the victim being murdered, achieving an accuracy of 66%. In the second approach, we developed a model to predict the next action a victim might experience within a sequence of patterned events. Both approaches contribute to the understand
    
[^57]: 自注意力在Transformer中是固有的各向异性

    Anisotropy Is Inherent to Self-Attention in Transformers. (arXiv:2401.12143v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.12143](http://arxiv.org/abs/2401.12143)

    本文发现自注意力在Transformer中是固有的各向异性现象，该现象在各种任务和数据集上都普遍存在，不仅限于长尾分布和语言模型。

    

    表示退化问题是基于Transformer的自监督学习方法中普遍观察到的现象。在自然语言处理中，它以各向异性的形式出现，这是隐藏表示的独特属性，使其在角度距离（余弦相似度）方面意外地彼此靠近。最近的一些研究表明，各向异性是在长尾分布的令牌上优化交叉熵损失的结果。我们在本文中展示，各向异性也可以在具有特定目标的语言模型中经验观察到，这些模型不应直接受到相同后果的影响。我们还展示了各向异性问题扩展到在其他模态上训练的Transformer。我们的观察表明，各向异性实际上是Transformer-based模型固有的。

    The representation degeneration problem is a phenomenon that is widely observed among self-supervised learning methods based on Transformers. In NLP, it takes the form of anisotropy, a singular property of hidden representations which makes them unexpectedly close to each other in terms of angular distance (cosine-similarity). Some recent works tend to show that anisotropy is a consequence of optimizing the cross-entropy loss on long-tailed distributions of tokens. We show in this paper that anisotropy can also be observed empirically in language models with specific objectives that should not suffer directly from the same consequences. We also show that the anisotropy problem extends to Transformers trained on other modalities. Our observations suggest that anisotropy is actually inherent to Transformers-based models.
    
[^58]: 将临床实践指南纳入大型语言模型以增强临床决策支持

    Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines. (arXiv:2401.11120v1 [cs.CL])

    [http://arxiv.org/abs/2401.11120](http://arxiv.org/abs/2401.11120)

    该论文研究了将临床实践指南纳入大型语言模型以增强临床决策支持的方法。他们开发了三种方法，并对四个大型语言模型进行了评估，在COVID-19门诊治疗方面取得了较高的性能。

    

    大型语言模型（LLM），搭配临床实践指南（CPGs），可以显著提高临床决策支持（CDS）。然而，将CPGs纳入LLMs的方法并未得到充分研究。我们开发了三种不同的方法将CPGs纳入LLMs：二元决策树（BDT），程序辅助图构建（PAGC），以及思维链少样本提示（CoT-FSP）。为评估所提方法的有效性，我们创建了一组合成患者描述，并对由四个LLMs生成的响应进行自动和人工评估：GPT-4，GPT-3.5 Turbo，LLaMA和PaLM 2。零样本提示（ZSP）被用作基线方法。我们以COVID-19门诊治疗的临床决策支持为案例研究。四个LLMs在增加了CPGs后相对于基线ZSP展现了提高的性能。BDT在自动评估中表现优于CoT-FSP和PAGC。所有提出的方法都表现出了较高的性能。

    Background Large Language Models (LLMs), enhanced with Clinical Practice Guidelines (CPGs), can significantly improve Clinical Decision Support (CDS). However, methods for incorporating CPGs into LLMs are not well studied. Methods We develop three distinct methods for incorporating CPGs into LLMs: Binary Decision Tree (BDT), Program-Aided Graph Construction (PAGC), and Chain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of the proposed methods, we create a set of synthetic patient descriptions and conduct both automatic and human evaluation of the responses generated by four LLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was used as the baseline method. We focus on CDS for COVID-19 outpatient treatment as the case study. Results All four LLMs exhibit improved performance when enhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP and PAGC in automatic evaluation. All of the proposed methods demonstrated high per
    
[^59]: 使用LLMs发现极端社交媒体中的编码反犹太恶意言论的出现

    Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media. (arXiv:2401.10841v1 [cs.CL])

    [http://arxiv.org/abs/2401.10841](http://arxiv.org/abs/2401.10841)

    这项研究提出了一种方法，可以检测新出现的编码恶意术语，为极端社交媒体中的反犹太恶意言论提供了解决方案。

    

    网络仇恨言论的蔓延给社交媒体平台带来了一个难题。一个特殊的挑战与使用编码语言的群体有关，这些群体既想为其用户创造归属感，又想回避检测。编码语言发展迅速，并且随着时间的推移使用方式不同。本文提出了一种检测新出现的编码恶意术语的方法论。该方法在在线反犹太言论的环境中进行了测试。该方法考虑了从社交媒体平台上抓取的帖子，通常是极端主义用户使用的。帖子是使用与以前已知的针对犹太人的仇恨言论相关的种子表达式进行抓取的。该方法首先通过识别每个帖子最具代表性的表达式，并计算它们在整个语料库中的频率。过滤掉语法不一致的表达式和之前遇到过的表达式，以便关注新出现的良好形式的术语。然后进行了语义评估。

    Online hate speech proliferation has created a difficult problem for social media platforms. A particular challenge relates to the use of coded language by groups interested in both creating a sense of belonging for its users and evading detection. Coded language evolves quickly and its use varies over time. This paper proposes a methodology for detecting emerging coded hate-laden terminology. The methodology is tested in the context of online antisemitic discourse. The approach considers posts scraped from social media platforms, often used by extremist users. The posts are scraped using seed expressions related to previously known discourse of hatred towards Jews. The method begins by identifying the expressions most representative of each post and calculating their frequency in the whole corpus. It filters out grammatically incoherent expressions as well as previously encountered ones so as to focus on emergent well-formed terminology. This is followed by an assessment of semantic s
    
[^60]: 支持学生决策的学习推荐：基于知识图谱情境化的LLM聊天机器人，实现对话解释和指导

    Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring. (arXiv:2401.08517v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.08517](http://arxiv.org/abs/2401.08517)

    这个论文研究了一种基于知识图谱情境化的LLM聊天机器人，作为学生学习推荐的解释工具和指导。通过定义上下文并利用人工策划的信息源来调控LLM的生成，聊天机器人能在与学生对话中提供解释和指导。

    

    学生对学习推荐的决策与其理解推荐原因的能力是不可分割的；他们能否根据这种理解进行修改。在各种解释性方法中，聊天机器人具有与同行或导师讨论类似的潜力来与学生进行对话。然而，尽管生成式人工智能（GenAI）和大型语言模型（LLM）的进展，聊天机器人的能力仍然不足以取代人类导师。因此，我们提出了一种方法，利用聊天机器人作为对话的中介和解释的有限和受控生成的来源，以利用LLM的潜力的同时减少其潜在风险。所提出的基于LLM的聊天机器人支持学生理解学习路径推荐。我们使用知识图谱（KG）作为人工策划的信息源，通过定义其提示的上下文来调控LLM的输出。

    Student commitment towards a learning recommendation is not separable from their understanding of the reasons it was recommended to them; and their ability to modify it based on that understanding. Among explainability approaches, chatbots offer the potential to engage the student in a conversation, similar to a discussion with a peer or a mentor. The capabilities of chatbots, however, are still not sufficient to replace a human mentor, despite the advancements of generative AI (GenAI) and large language models (LLM). Therefore, we propose an approach to utilize chatbots as mediators of the conversation and sources of limited and controlled generation of explanations, to harvest the potential of LLMs while reducing their potential risks at the same time. The proposed LLM-based chatbot supports students in understanding learning-paths recommendations. We use a knowledge graph (KG) as a human-curated source of information, to regulate the LLM's output through defining its prompt's contex
    
[^61]: GPT-4 Vision在医学领域中专家级准确度背后的隐藏缺陷

    Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine. (arXiv:2401.08396v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.08396](http://arxiv.org/abs/2401.08396)

    GPT-4 Vision在医学领域中具有专家级准确度，但在图像理解方面存在缺陷。

    

    最近的研究表明，具有Vision功能的GPT-4在医学挑战任务中表现优于人类医生。然而，这些评估主要关注多项选择题的准确度。本研究通过对GPT-4V在解决新英格兰医学杂志图像挑战中的图像理解、医学知识回忆和逐步多模态推理的原理进行全面分析，扩展了当前的研究范围。评估结果证实，GPT-4V在多项选择准确度上优于人类医生（88.0% vs. 77.0%，p=0.034）。GPT-4V在医生回答错误的情况下，也能表现出超过80%的准确度。然而，我们发现，GPT-4V在最终做出正确选择的情况下，经常提供有缺陷的推理（27.3%），其中最突出的是图像理解（21.6%）。

    Recent studies indicate that Generative Pre-trained Transformer 4 with Vision (GPT-4V) outperforms human physicians in medical challenge tasks. However, these evaluations primarily focused on the accuracy of multi-choice questions alone. Our study extends the current scope by conducting a comprehensive analysis of GPT-4V's rationales of image comprehension, recall of medical knowledge, and step-by-step multimodal reasoning when solving New England Journal of Medicine (NEJM) Image Challenges - an imaging quiz designed to test the knowledge and diagnostic capabilities of medical professionals. Evaluation results confirmed that GPT-4V outperforms human physicians regarding multi-choice accuracy (88.0% vs. 77.0%, p=0.034). GPT-4V also performs well in cases where physicians incorrectly answer, with over 80% accuracy. However, we discovered that GPT-4V frequently presents flawed rationales in cases where it makes the correct final choices (27.3%), most prominent in image comprehension (21.6
    
[^62]: 代码之间的界限：揭示机器和人类程序员之间不同的模式

    Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. (arXiv:2401.06461v1 [cs.SE])

    [http://arxiv.org/abs/2401.06461](http://arxiv.org/abs/2401.06461)

    本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。

    

    大型语言模型在代码生成方面取得了显著的进展，但它们模糊了机器和人类源代码之间的区别，导致软件产物的完整性和真实性问题。本文通过对代码长度、词汇多样性和自然性等属性的严格分析，揭示了机器和人类代码固有的独特模式。在我们的研究中特别注意到，代码的结构分割是识别其来源的关键因素。基于我们的发现，我们提出了一种名为DetectCodeGPT的新型机器生成代码检测方法，该方法改进了DetectGPT。

    Large language models have catalyzed an unprecedented wave in code generation. While achieving significant advances, they blur the distinctions between machine-and human-authored source code, causing integrity and authenticity issues of software artifacts. Previous methods such as DetectGPT have proven effective in discerning machine-generated texts, but they do not identify and harness the unique patterns of machine-generated code. Thus, its applicability falters when applied to code. In this paper, we carefully study the specific patterns that characterize machine and human-authored code. Through a rigorous analysis of code attributes such as length, lexical diversity, and naturalness, we expose unique pat-terns inherent to each source. We particularly notice that the structural segmentation of code is a critical factor in identifying its provenance. Based on our findings, we propose a novel machine-generated code detection method called DetectCodeGPT, which improves DetectGPT by cap
    
[^63]: 如何使Johnny说服LLMs越狱：通过人性化LLMs重新思考对AI安全的挑战

    How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs. (arXiv:2401.06373v1 [cs.CL])

    [http://arxiv.org/abs/2401.06373](http://arxiv.org/abs/2401.06373)

    本文通过将LLMs视为人类交流者，探索了每天语言互动和AI安全之间忽视的交叉点，并提出了一种通过说服LLMs进行越狱的方法。研究结果表明，说服显著提高了越狱性能，在多个风险类别上均取得了超过92%的攻击成功率。

    

    大多数传统的AI安全研究将AI模型视为机器，并集中在由安全专家开发的基于算法的攻击上。随着大型语言模型（LLMs）的普及和竞争力越来越强，非专家用户在日常互动中也可能产生风险。本文介绍了一种新的视角，将LLMs作为类似人类的交流者来越狱，以探索每天语言互动和AI安全之间被忽视的交叉点。具体而言，我们研究如何说服LLMs越狱。首先，我们提出了一个从几十年的社会科学研究中得出的说服分类法。然后，我们应用这个分类法来自动生成可解释的说服对抗提示（PAP）来越狱LLMs。结果显示，说服显著提高了越狱性能，在所有风险类别上PAP在Llama 2-7b Chat、GPT-3.5和GPT-4上的攻击成功率在10次试验中均超过92%，超过了最近的基于算法的攻击。

    Most traditional AI safety research has approached AI models as machines and centered on algorithm-focused attacks developed by security experts. As large language models (LLMs) become increasingly common and competent, non-expert users can also impose risks during daily interactions. This paper introduces a new perspective to jailbreak LLMs as human-like communicators, to explore this overlooked intersection between everyday language interaction and AI safety. Specifically, we study how to persuade LLMs to jailbreak them. First, we propose a persuasion taxonomy derived from decades of social science research. Then, we apply the taxonomy to automatically generate interpretable persuasive adversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion significantly increases the jailbreak performance across all risk categories: PAP consistently achieves an attack success rate of over $92\%$ on Llama 2-7b Chat, GPT-3.5, and GPT-4 in $10$ trials, surpassing recent algorithm-focu
    
[^64]: 领域特定LLM的微调和利用方法

    Fine-tuning and Utilization Methods of Domain-specific LLMs. (arXiv:2401.02981v1 [cs.CL])

    [http://arxiv.org/abs/2401.02981](http://arxiv.org/abs/2401.02981)

    本研究调查了领域特定LLM的微调和利用方法，以金融领域为例，详细介绍了数据集选择、预处理、模型选择以及在金融领域LLM微调中的关键因素。研究探讨了领域特定词汇的构建和安全合规性的考虑因素，并提供了在金融领域生成领域特定LLM的过程和实施方法。多种金融案例被涵盖在内，包括股票价格预测、金融新闻情绪分析、自动文档处理、研究和信息提取等。

    

    最近发布的预训练的大型语言模型（LLM）引起了相当大的关注，但关于领域特定LLM的微调和应用的研究仍然很少。本研究调查了领域特定LLM的微调和利用方法，重点关注LLM的趋势、基础模型和用于领域特定预训练的方法。以金融行业为例，详细介绍了数据集选择、预处理、模型选择以及在金融领域LLM微调中关键的考虑因素。针对金融数据的独特特点，本研究探讨了领域特定词汇的构建，以及安全性和合规性的考虑因素。在LLM微调的实际应用中，本研究概述了在金融领域生成领域特定LLM的过程和实施方法。包括股票价格预测、金融新闻情绪分析、自动文档处理、研究和信息提取等多种金融案例被涵盖在内。

    Recent releases of pre-trained Large Language Models (LLMs) have gained considerable traction, yet research on fine-tuning and employing domain-specific LLMs remains scarce. This study investigates approaches for fine-tuning and leveraging domain-specific LLMs, highlighting trends in LLMs, foundational models, and methods for domain-specific pre-training. Focusing on the financial sector, it details dataset selection, preprocessing, model choice, and considerations crucial for LLM fine-tuning in finance. Addressing the unique characteristics of financial data, the study explores the construction of domain-specific vocabularies and considerations for security and regulatory compliance. In the practical application of LLM fine-tuning, the study outlines the procedure and implementation for generating domain-specific LLMs in finance. Various financial cases, including stock price prediction, sentiment analysis of financial news, automated document processing, research, information extract
    
[^65]: 母婴健康的自然语言处理研究：在LLMs时代的观点和指导原则

    NLP for Maternal Healthcare: Perspectives and Guiding Principles in the Age of LLMs. (arXiv:2312.11803v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11803](http://arxiv.org/abs/2312.11803)

    本研究旨在为母婴健康领域使用自然语言处理（NLP）提供指导原则，并通过调查和研讨会的互动讨论，从受影响者的声音中总结出结果，为使用大型语言模型（LLMs）等工具的健康应用提供伦理框架和指导原则。

    

    迫切需要伦理框架来指导如何利用大型语言模型（LLMs）等工具进行医疗应用的自然语言处理（NLP）。医疗领域面临着权力平衡、系统性健康差距、历史不公和经济限制等挑战。在直接倾听最受影响者的声音的基础上，并以某一特定医疗环境的案例研究为重点，我们提出了一套在母婴健康领域中使用NLP的指导原则。我们在一个为期一天的研讨会上，组织了一个以LLM为基础的聊天机器人演示的互动会话，并额外调查了30名医疗工作者和30名分娩者对于母婴健康背景下NLP工具的价值、需求和感知。我们对调查结果和互动讨论进行了定量和定性分析，总结出了我们的研究结果。

    Ethical frameworks for the use of natural language processing (NLP) are urgently needed to shape how large language models (LLMs) and similar tools are used for healthcare applications. Healthcare faces existing challenges including the balance of power in clinician-patient relationships, systemic health disparities, historical injustices, and economic constraints. Drawing directly from the voices of those most affected, and focusing on a case study of a specific healthcare setting, we propose a set of guiding principles for the use of NLP in maternal healthcare. We led an interactive session centered on an LLM-based chatbot demonstration during a full-day workshop with 39 participants, and additionally surveyed 30 healthcare workers and 30 birthing people about their values, needs, and perceptions of NLP tools in the context of maternal health. We conducted quantitative and qualitative analyses of the survey results and interactive discussions to consolidate our findings into a set of
    
[^66]: 在SpiNNaker 2神经形态芯片上进行语言建模

    Language Modeling on a SpiNNaker 2 Neuromorphic Chip. (arXiv:2312.09084v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2312.09084](http://arxiv.org/abs/2312.09084)

    该论文介绍了在SpiNNaker 2神经形态芯片上实现语言建模的首次尝试。通过利用基于事件的架构和大规模异步处理的硬件，该方法有望在减少能耗的同时保持竞争任务性能。

    

    随着大型语言模型的规模迅速增长，所需的计算能力也在增加。基于神经形态设备上的事件驱动网络提供了一种显著降低推理能耗的潜在方式。然而，迄今为止，大多数可以在神经形态硬件上运行的基于事件的网络，包括脉冲神经网络(SNN)，在语言建模方面的任务性能甚至不能与LSTM模型相媲美。因此，在神经形态设备上进行语言建模似乎是一个遥远的可能性。在这项工作中，我们首次在神经形态设备上实现了一个语言模型 - 具体来说是基于最近发布的名为EGRU的基于事件的架构的SpiNNaker 2芯片。SpiNNaker 2是一个设计用于大规模异步处理的众核神经形态芯片，而EGRU是为了在保持竞争任务性能的同时高效利用这种硬件而设计的。这个实现标志着在神经形态设备上进行语言建模的第一个

    As large language models continue to scale in size rapidly, so too does the computational power required to run them. Event-based networks on neuromorphic devices offer a potential way to reduce energy consumption for inference significantly. However, to date, most event-based networks that can run on neuromorphic hardware, including spiking neural networks (SNNs), have not achieved task performance even on par with LSTM models for language modeling. As a result, language modeling on neuromorphic devices has seemed a distant prospect. In this work, we demonstrate the first-ever implementation of a language model on a neuromorphic device - specifically the SpiNNaker 2 chip based on a recently published event-based architecture called the EGRU. SpiNNaker 2 is a many-core neuromorphic chip designed for large-scale asynchronous processing, while the EGRU is architected to leverage such hardware efficiently while maintaining competitive task performance. This implementation marks the firs
    
[^67]: 基准分析奖励模型在分布转移下准确分析基础模型的能力的能力

    A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift. (arXiv:2311.14743v7 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.14743](http://arxiv.org/abs/2311.14743)

    本论文基于奖励模型的准确性和校准度评估了基础模型在分布转移下的性能。实验结果显示奖励模型对于提示和响应的转移具有不同的敏感性，并呈现出新颖的校准模式和准确性下降。同时，将常用的OOD检测技术引入到奖励模型设置中，用于检测分布转移。

    

    最近，基础模型，特别是大型语言模型（LLM），引起了广泛的关注和应用。利用人类反馈进行强化学习（RLHF）包括训练奖励模型来捕捉期望的行为，然后用于对齐LLM。这些奖励模型还在推断时用于估计LLM响应与期望行为的一致性。然而，很少有工作来衡量这些奖励模型在分布转移下的鲁棒性。在这项工作中，我们评估了通过准确性和校准度（即准确性和信心的匹配程度）衡量的奖励模型性能如何受到分布转移的影响。我们展示了由于OOD提示和响应而产生的新型校准模式和准确性下降，并且发现奖励模型对响应的转移比提示更敏感。此外，我们还将常用于分类的OOD检测技术适应到奖励模型设置中，以检测这些提示和响应的分布转移。

    Foundation models, specifically Large Language Models (LLMs), have lately gained wide-spread attention and adoption. Reinforcement Learning with Human Feedback (RLHF) involves training a reward model to capture desired behaviors, which is then used to align LLM's. These reward models are additionally used at inference-time to estimate LLM responses' adherence to those desired behaviors. However, there is little work measuring how robust these reward models are to distribution shifts. In this work, we evaluate how reward model performance measured via accuracy and calibration (i.e. alignment between accuracy and confidence) - is affected by distribution shift. We show novel calibration patterns and accuracy drops due to OOD prompts and responses, and that the reward model is more sensitive to shifts in responses than prompts. Additionally, we adapt an OOD detection technique commonly used in classification to the reward model setting to detect these distribution shifts in prompts and 
    
[^68]: 正式规定基于LLM的代理人的高级行为

    Formally Specifying the High-Level Behavior of LLM-Based Agents. (arXiv:2310.08535v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.08535](http://arxiv.org/abs/2310.08535)

    本文介绍了一个最小生成框架，通过在高级声明中定义所需的代理人行为，然后构建解码监视器，从而实现了基于LLM的代理人的快速设计和实施。

    

    最近，由LLM驱动的自主目标驱动型代理人已成为解决具有挑战性问题的有前途的工具，而无需获得昂贵的任务特定的精细调整模型。目前，这类代理人的设计和实施是临时性的，因为LLM-based代理人可能应用于的各种任务的广泛性质意味着不能有一种适用于所有情况的代理人设计方法。在这项工作中，我们旨在通过提出一个简化代理人构建过程的最小生成框架来减轻设计和实施新代理人的难度。我们引入的框架允许用户以高级声明的规范方式定义所需的代理人行为，然后使用这个规范构建解码监视器，以确保LLM会产生具有所需行为的输出。我们的声明性方法，即描述行为而不考虑如何实施或强制执行，可以实现快速设计

    Autonomous, goal-driven agents powered by LLMs have recently emerged as promising tools for solving challenging problems without the need for task-specific finetuned models that can be expensive to procure. Currently, the design and implementation of such agents is ad hoc, as the wide variety of tasks that LLM-based agents may be applied to naturally means there can be no one-size-fits-all approach to agent design. In this work we aim to alleviate the difficulty of designing and implementing new agents by proposing a minimalistic generation framework that simplifies the process of building agents. The framework we introduce allows the user to define desired agent behaviors in a high-level, declarative specification that is then used to construct a decoding monitor which guarantees the LLM will produce an output exhibiting the desired behavior. Our declarative approach, in which the behavior is described without concern for how it should be implemented or enforced, enables rapid design,
    
[^69]: 会话式健康代理：个性化的基于LLM的代理框架

    Conversational Health Agents: A Personalized LLM-Powered Agent Framework. (arXiv:2310.02374v1 [cs.CL])

    [http://arxiv.org/abs/2310.02374](http://arxiv.org/abs/2310.02374)

    该论文介绍了一个基于LLM的会话式健康代理框架，旨在为代理赋予批判性思维、知识获取和问题解决能力，实现个性化的健康护理服务。该框架能够无缝集成医疗工具，实现多语言和多模态对话，并与多种用户数据分析工具连接。

    

    会话式健康代理（CHAs）是一种互动系统，旨在通过进行共情对话和处理多模态数据来增强个人健康护理服务。当前的CHAs，特别是那些利用大型语言模型（LLMs）的系统，主要关注对话，但往往缺乏全面的代理能力。这包括从可穿戴设备、全天候数据收集源和电子健康记录中获取个人用户的健康数据的能力，以及整合最新发布的健康见解，并与已建立的多模态数据分析工具连接。我们正在开发一个框架，通过赋予CHAs批判性思维、知识获取和问题解决能力来增强它们的能力。我们的CHA平台由LLMs驱动，无缝集成了医疗工具，实现了多语言和多模态对话，并与各种用户数据分析工具进行接口。我们展示了其在处理复杂医疗任务方面的熟练性。

    Conversational Health Agents (CHAs) are interactive systems designed to enhance personal healthcare services by engaging in empathetic conversations and processing multimodal data. While current CHAs, especially those utilizing Large Language Models (LLMs), primarily focus on conversation, they often lack comprehensive agent capabilities. This includes the ability to access personal user health data from wearables, 24/7 data collection sources, and electronic health records, as well as integrating the latest published health insights and connecting with established multimodal data analysis tools. We are developing a framework to empower CHAs by equipping them with critical thinking, knowledge acquisition, and problem-solving abilities. Our CHA platform, powered by LLMs, seamlessly integrates healthcare tools, enables multilingual and multimodal conversations, and interfaces with a variety of user data analysis tools. We illustrate its proficiency in handling complex healthcare tasks, s
    
[^70]: 堆栈注意力: 提升Transformers对层次模式建模的能力

    Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns. (arXiv:2310.01749v1 [cs.CL])

    [http://arxiv.org/abs/2310.01749](http://arxiv.org/abs/2310.01749)

    堆栈注意力为Transformers模型处理层次模式提供了能力，通过结合堆栈和注意力机制，它能有效地学习和识别任意深度的语法结构，特别适用于具有解析难度的上下文无关语言。

    

    注意力机制，尤其是缩放点积注意力，在自然语言处理中已被证明非常有效，但它对于处理任意嵌套深度的层次模式没有机制，这限制了它识别某些句法结构的能力。为解决这一缺陷，我们提出了堆栈注意力：一种结合了堆栈的注意力操作符，受到它们与上下文无关语言（CFLs）的理论联系的启发。我们展示了堆栈注意力类似于标准注意力，但它具有不需要句法监督的语法潜在模型。我们提出了两种变体：与确定性下推自动机（PDAs）相关的一种，以及基于非确定性PDAs的一种，这使得transformers能够识别任意的CFLs。我们展示了使用堆栈注意力的transformers在学习标准transformers难以应对的CFLs方面非常有效，并在最大解析难度的CFL上取得了强大的结果。我们还展示了堆栈注意力的效果更好。

    Attention, specifically scaled dot-product attention, has proven effective for natural language, but it does not have a mechanism for handling hierarchical patterns of arbitrary nesting depth, which limits its ability to recognize certain syntactic structures. To address this shortcoming, we propose stack attention: an attention operator that incorporates stacks, inspired by their theoretical connections to context-free languages (CFLs). We show that stack attention is analogous to standard attention, but with a latent model of syntax that requires no syntactic supervision. We propose two variants: one related to deterministic pushdown automata (PDAs) and one based on nondeterministic PDAs, which allows transformers to recognize arbitrary CFLs. We show that transformers with stack attention are very effective at learning CFLs that standard transformers struggle on, achieving strong results on a CFL with theoretically maximal parsing difficulty. We also show that stack attention is more
    
[^71]: 批量校准：重新思考上下文学习和提示工程的校准方法

    Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering. (arXiv:2309.17249v1 [cs.CL])

    [http://arxiv.org/abs/2309.17249](http://arxiv.org/abs/2309.17249)

    本研究提出了一种名为批量校准（BC）的方法，用于解决大型语言模型中提示脆弱性和偏见因素导致的性能下降问题。BC通过控制批量输入的上下文偏见，统一了现有的校准方法，并具有零-shot和仅推理的特点。

    

    提示和上下文学习已成为大型语言模型（LLM）的高效学习范式。然而，LLM存在提示脆弱性和各种偏见因素，包括但不限于格式、选择性的表达方式和上下文学习示例。为解决这个导致性能下降的问题，已经开发了校准方法来减轻这些偏见的影响并恢复LLM的性能。在这项工作中，我们首先对现有的校准方法进行了系统分析，提供了统一的观点并揭示了失败案例。受这些分析的启发，我们提出了批量校准（BC），这是一种简单而直观的方法，可以从批量输入中控制上下文偏见，统一了各种先前的方法，并有效地解决了上述问题。BC是零-shot、仅推理和额外成本可忽略。在少-shot设置中，我们进一步扩展BC以实现全部翻译

    Prompting and in-context learning (ICL) have become efficient learning paradigms for large language models (LLMs). However, LLMs suffer from prompt brittleness and various bias factors in the prompt, including but not limited to the formatting, the choice verbalizers, and the ICL examples. To address this problem that results in unexpected performance degradation, calibration methods have been developed to mitigate the effects of these biases while recovering LLM performance. In this work, we first conduct a systematic analysis of the existing calibration methods, where we both provide a unified view and reveal the failure cases. Inspired by these analyses, we propose Batch Calibration (BC), a simple yet intuitive method that controls the contextual bias from the batched input, unifies various prior approaches, and effectively addresses the aforementioned issues. BC is zero-shot, inference-only, and incurs negligible additional costs. In the few-shot setup, we further extend BC to allo
    
[^72]: 预训练多语言翻译模型上的属性控制器能否迁移到其他语言？

    How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?. (arXiv:2309.08565v1 [cs.CL])

    [http://arxiv.org/abs/2309.08565](http://arxiv.org/abs/2309.08565)

    本文研究了如何将预训练的多语言翻译模型中的属性控制器迁移到没有监督数据的语言。通过全面分析不同数据场景下的训练和推断时控制技术，揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。

    

    最近，将机器翻译模型定制为符合细粒度属性（如形式）已取得了巨大进展。然而，当前方法大多依赖于至少一些带有属性注释的监督数据。因此，数据稀缺仍然是将此定制能力普及到更广泛语言范围，尤其是低资源语言的一个瓶颈。鉴于最近在预训练大规模多语言翻译模型方面取得的进展，我们将它们作为对没有监督数据的语言进行属性控制能力迁移的基础。在这项工作中，我们基于预训练的NLLB-200模型对属性控制器的迁移进行了全面分析。我们研究了在各种数据场景下的训练和推断时控制技术，并揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。我们显示出两种范式是互补的，通过一致的改进来证明。

    Customizing machine translation models to comply with fine-grained attributes such as formality has seen tremendous progress recently. However, current approaches mostly rely on at least some supervised data with attribute annotation. Data scarcity therefore remains a bottleneck to democratizing such customization possibilities to a wider range of languages, lower-resource ones in particular. Given recent progress in pretrained massively multilingual translation models, we use them as a foundation to transfer the attribute controlling capabilities to languages without supervised data. In this work, we present a comprehensive analysis of transferring attribute controllers based on a pretrained NLLB-200 model. We investigate both training- and inference-time control techniques under various data scenarios, and uncover their relative strengths and weaknesses in zero-shot performance and domain robustness. We show that both paradigms are complementary, as shown by consistent improvements o
    
[^73]: 生成半结构化解释的奖励工程

    Reward Engineering for Generating Semi-structured Explanation. (arXiv:2309.08347v1 [cs.CL])

    [http://arxiv.org/abs/2309.08347](http://arxiv.org/abs/2309.08347)

    本论文提出了一种奖励工程方法，在生成语言模型的半结构化解释方面取得了增强效果，解决了模型推理能力验证的问题。

    

    半结构化解释描绘了一个推理者的隐式过程和显式表示。这种解释突出了在特定查询中可用信息如何与推理者从内部权重产生的信息相结合，以生成答案。尽管语言模型的生成能力最近有所改进，但生成结构化解释以验证模型真正的推理能力仍然是一个挑战。对于规模不是很大的语言模型而言，这个问题尤为明显，因为推理者被期望将顺序的答案与体现正确展示和正确推理过程的结构化解释相结合。在这项工作中，我们首先强调了监督微调(SFT)在应对这一挑战方面的局限性，然后在强化学习(RL)中引入了一种精心设计的奖励工程方法，以更好地解决这个问题。我们研究了多种奖励聚合方法，并提供了一种...

    Semi-structured explanation depicts the implicit process of a reasoner with an explicit representation. This explanation highlights how available information in a specific query is supplemented with information a reasoner produces from its internal weights towards generating an answer. Despite the recent improvements in generative capabilities of language models, producing structured explanations to verify model's true reasoning capabilities remains a challenge. This issue is particularly pronounced for not-so-large LMs, as the reasoner is expected to couple a sequential answer with a structured explanation which embodies both the correct presentation and the correct reasoning process. In this work, we first underscore the limitations of supervised fine-tuning (SFT) in tackling this challenge, and then introduce a carefully crafted reward engineering method in reinforcement learning (RL) to better address this problem. We investigate multiple reward aggregation methods and provide a de
    
[^74]: 具有可控风格的语境化自动语音识别中的PromptASR

    PromptASR for contextualized ASR with controllable style. (arXiv:2309.07414v1 [eess.AS])

    [http://arxiv.org/abs/2309.07414](http://arxiv.org/abs/2309.07414)

    PromptASR是一个框架，将提示集成到端到端自动语音识别系统中，实现了具有可控风格的语境化语音转录。在实验中，使用前一话语的真实文本作为内容提示时，相对于基线ASR系统，该系统在阅读图书数据集和内部数据集上分别获得了21.9％和6.8％的词错误率降低。此外，该系统可以采用单词级偏置列表作为提示来提高对罕见单词的识别准确性。同时，该系统还可以使用额外的样式提示来引导ASR系统输出不同风格的转录。

    

    对于大型语言模型来说，提示非常重要，因为它们提供了主题或逻辑关系等上下文信息。受此启发，我们提出了PromptASR，这是一个将提示集成到端到端自动语音识别（E2E ASR）系统中，以实现具有可控风格的语境化语音转录的框架。具体地，专用文本编码器对文本提示进行编码，并通过跨两种模态的特征交互将编码注入到语音编码器中。当使用前面话语的真实文本作为内容提示时，与基线ASR系统相比，所提出的系统在阅读图书数据集和内部数据集上分别实现了21.9％和6.8％的相对词错误率降低。系统还可以采用单词级偏置列表作为提示，以提高对罕见单词的识别准确性。还可以给文本编码器提供额外的样式提示，并引导ASR系统输出不同风格的转录。代码可供使用。

    Prompts are crucial to large language models as they provide context information such as topic or logical relationships. Inspired by this, we propose PromptASR, a framework that integrates prompts in end-to-end automatic speech recognition (E2E ASR) systems to achieve contextualized ASR with controllable style of transcriptions. Specifically, a dedicated text encoder encodes the text prompts and the encodings are injected into the speech encoder by cross-attending the features from two modalities. When using the ground truth text from preceding utterances as content prompt, the proposed system achieves 21.9% and 6.8% relative word error rate reductions on a book reading dataset and an in-house dataset compared to a baseline ASR system. The system can also take word-level biasing lists as prompt to improve recognition accuracy on rare words. An additional style prompt can be given to the text encoder and guide the ASR system to output different styles of transcriptions. The code is avai
    
[^75]: 统计拒绝抽样改进了优化偏好方法

    Statistical Rejection Sampling Improves Preference Optimization. (arXiv:2309.06657v1 [cs.CL])

    [http://arxiv.org/abs/2309.06657](http://arxiv.org/abs/2309.06657)

    本文提出了一种名为统计拒绝抽样的新方法，改进了优化偏好的过程，并解决了传统方法中缺乏奖励模型和从最优策略采样偏好对的问题。

    

    提高语言模型与人类偏好的一致性仍然是一个活跃的研究挑战。之前的方法主要使用强化学习从人类反馈中学习（RLHF），通过在线强化学习方法如近端策略优化（PPO）。最近，离线方法如序列似然校准（SLiC）和直接偏好优化（DPO）已经成为有吸引力的替代方案，提供了稳定性和可扩展性的改进，同时保持了竞争性能。SLiC通过使用从经过监督微调（SFT）策略中采样的序列对来优化其损失函数，而DPO直接根据偏好数据优化语言模型，无需单独的奖励模型。然而，目标最优策略的最大似然估计器（MLE）需要从该策略中采样标记的偏好对。DPO缺乏奖励模型限制其从最优策略中采样偏好对的能力，而SLiC则受到了限制。

    Improving the alignment of language models with human preferences remains an active research challenge. Previous approaches have primarily utilized Reinforcement Learning from Human Feedback (RLHF) via online RL methods such as Proximal Policy Optimization (PPO). Recently, offline methods such as Sequence Likelihood Calibration (SLiC) and Direct Preference Optimization (DPO) have emerged as attractive alternatives, offering improvements in stability and scalability while maintaining competitive performance. SLiC refines its loss function using sequence pairs sampled from a supervised fine-tuned (SFT) policy, while DPO directly optimizes language models based on preference data, foregoing the need for a separate reward model. However, the maximum likelihood estimator (MLE) of the target optimal policy requires labeled preference pairs sampled from that policy. DPO's lack of a reward model constrains its ability to sample preference pairs from the optimal policy, and SLiC is restricted t
    
[^76]: 透过偏好看大型语言模型的反馈获取：揭示对齐的重要性

    Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models. (arXiv:2308.15812v1 [cs.LG])

    [http://arxiv.org/abs/2308.15812](http://arxiv.org/abs/2308.15812)

    本研究分析了对于对齐和评估大型语言模型而言，设计反馈选择是评分还是排名对结果的影响。研究发现评分和排名所推断出的偏好存在不一致问题，并且注释者的偏见也会影响结果。同时，研究还发现反馈协议的选择也对评估结果有显著影响。

    

    大型语言模型（LLMs）与人类价值观和意图的对齐承诺涉及使用人工智能或人类反馈。稠密的反馈注释获取和整合成本较高，而稀疏的反馈则涉及结构性设计选择，即评分（例如，在1-7的范围内对回答A进行评分）和排名（例如，回答A是否比回答B更好？）。在这项工作中，我们分析了这种设计选择对LLMs的对齐和评估的影响。我们发现，评分和排名所推断出的偏好在人类和AI注释者中都存在严重的不一致问题，达到了60%。我们的后续分析确定了解释这个现象的各种注释者偏见方面，比如人类注释者更喜欢密集回答并在两个选项之间更青睐准确性。令我们惊讶的是，我们还观察到反馈协议的选择对对齐的LLMs的评估也有显著影响。特别是，我们发现LLMs的评估结果因为反馈协议的选择而有所不同。

    Aligning large language models (LLMs) with human values and intents critically involves the use of human or AI feedback. While dense feedback annotations are expensive to acquire and integrate, sparse feedback presents a structural design choice between ratings (e.g., score Response A on a scale of 1-7) and rankings (e.g., is Response A better than Response B?). In this work, we analyze the effect of this design choice for the alignment and evaluation of LLMs. We uncover an inconsistency problem wherein the preferences inferred from ratings and rankings significantly disagree 60% for both human and AI annotators. Our subsequent analysis identifies various facets of annotator biases that explain this phenomena, such as human annotators would rate denser responses higher while preferring accuracy during pairwise judgments. To our surprise, we also observe that the choice of feedback protocol also has a significant effect on the evaluation of aligned LLMs. In particular, we find that LLMs
    
[^77]: CALM: 一种用于全面评估语言模型偏见的多任务基准数据集

    CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias. (arXiv:2308.12539v1 [cs.CL])

    [http://arxiv.org/abs/2308.12539](http://arxiv.org/abs/2308.12539)

    CALM是一个用于量化语言模型偏见的多任务基准数据集，相比先前数据集更加多样和可靠，能更好地捕捉评估模型偏见所需的语言变化的广度。

    

    随着语言模型（LMs）的不断增强，量化和比较它们在社会和人口学偏见方面的能力以及潜在的危害变得越来越重要。先前的偏见测量数据集对于人工设计模板的扰动敏感，因此不可靠。为了保证可靠性，我们引入了全面评估语言模型偏见（CALM）的基准数据集，用于量化LMs在三个任务上的偏见。我们整合了来自不同领域（如维基百科和新闻文章）的16个现有数据集，过滤出224个模板，并构建了一个包含78,400个示例的数据集。我们通过平均语义相似性和模板长度的变异程度等指标，比较CALM与先前数据集的多样性，并测试其对细微扰动的敏感性。我们展示了我们的数据集相对于先前数据集更加多样和可靠，因此能更好地捕捉评估模型偏见所需的语言变化的广度。我们评估了20个大型语言模型的偏见。

    As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language 
    
[^78]: VELMA: LLM智能体在街景中进行视觉和语言导航的口头化体现

    VELMA: Verbalization Embodiment of LLM Agents for Vision and Language Navigation in Street View. (arXiv:2307.06082v1 [cs.AI])

    [http://arxiv.org/abs/2307.06082](http://arxiv.org/abs/2307.06082)

    VELMA是一个口头化的LLM智能体，利用人类写作的导航指令中的地标并结合CLIP来进行视觉环境的理解，以实现在街景中的视觉和语言导航。

    

    在现实世界环境中的增量决策是具有挑战性的以体现人工智能的任务之一。其中最具挑战性的场景之一是视觉和语言导航(VLN)，它需要视觉和自然语言理解以及空间和时间推理能力。这个体现智能体需要在街景等真实世界环境的观察基础上准确理解导航指令。尽管LLM在其他研究领域取得了令人印象深刻的结果，但如何最好地将它们与交互式视觉环境连接起来仍然是一个持续的问题。在这项工作中，我们提出了VELMA，一种使用轨迹和视觉环境观察的口头化作为下一步操作的上下文提示的LLM智能体。视觉信息通过一个流程进行口头化，该流程从人类编写的导航指令中提取地标，并使用CLIP来确定它们在当前全景视图中的可见性。

    Incremental decision making in real-world environments is one of the most challenging tasks in embodied artificial intelligence. One particularly demanding scenario is Vision and Language Navigation~(VLN) which requires visual and natural language understanding as well as spatial and temporal reasoning capabilities. The embodied agent needs to ground its understanding of navigation instructions in observations of a real-world environment like Street View. Despite the impressive results of LLMs in other research areas, it is an ongoing problem of how to best connect them with an interactive visual environment. In this work, we propose VELMA, an embodied LLM agent that uses a verbalization of the trajectory and of visual environment observations as contextual prompt for the next action. Visual information is verbalized by a pipeline that extracts landmarks from the human written navigation instructions and uses CLIP to determine their visibility in the current panorama view. We show that
    
[^79]: 在扩散模型中的语言绑定：通过注意力图对齐增强属性对应性

    Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment. (arXiv:2306.08877v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.08877](http://arxiv.org/abs/2306.08877)

    该论文提出了一种名为SynGen的方法，通过语法分析和交叉注意力图的对齐来解决文本条件的图像生成模型中实体和视觉属性之间错误关联的问题。

    

    文本条件的图像生成模型常常在实体和其视觉属性之间生成错误的关联。这反映了在提示中的实体和修饰符的语言绑定以及生成的图像中相应元素的视觉绑定之间的映射受到损害。例如，一个类似“一个粉色的向日葵和一个黄色的火烈鸟”的查询可能会错误地产生一张黄色的向日葵和一只粉色的火烈鸟的图像。为了解决这个问题，我们提出了一个名为SynGen的方法，该方法首先对提示进行句法分析以识别实体和它们的修饰符，然后使用一种新型的损失函数，鼓励交叉注意力图与语言绑定的语法一致。具体而言，我们鼓励实体和其修饰符的注意力图之间有大量的重叠，并且与其他实体和修饰符词之间的重叠很小。损失在推理过程中进行优化，无需重新训练或微调模型。对三个提示数据集进行的人工评估...

    Text-conditioned image generation models often generate incorrect associations between entities and their visual attributes. This reflects an impaired mapping between linguistic binding of entities and modifiers in the prompt and visual binding of the corresponding elements in the generated image. As one notable example, a query like "a pink sunflower and a yellow flamingo" may incorrectly produce an image of a yellow sunflower and a pink flamingo. To remedy this issue, we propose SynGen, an approach which first syntactically analyses the prompt to identify entities and their modifiers, and then uses a novel loss function that encourages the cross-attention maps to agree with the linguistic binding reflected by the syntax. Specifically, we encourage large overlap between attention maps of entities and their modifiers, and small overlap with other entities and modifier words. The loss is optimized during inference, without retraining or fine-tuning the model. Human evaluation on three d
    
[^80]: 面向特定领域的预训练模型：相比一锅粥式模型，千万不要让领域的供给不足受到波及

    Stack Over-Flowing with Results: The Case for Domain-Specific Pre-Training Over One-Size-Fits-All Models. (arXiv:2306.03268v1 [cs.CL])

    [http://arxiv.org/abs/2306.03268](http://arxiv.org/abs/2306.03268)

    本文主张在大型预训练模型的潮流中，还应推广面向特定领域的预训练模型，并以 StackOverflow 为例展示了其优越性。

    

    大型预训练神经语言模型（如OpenAI的GPT系列）为NLP和软件工程带来了极大的进展。然而，我们认为这种追求大而全的潮流应该与针对特定目的、规模适中的预训练模型相结合。本文以StackOverflow为例，展示了我们的面向特定领域的预训练模型相对于通用模型在验证困惑度和迁移学习准确性方面表现更优。

    Large pre-trained neural language models have brought immense progress to both NLP and software engineering. Models in OpenAI's GPT series now dwarf Google's BERT and Meta's RoBERTa, which previously set new benchmarks on a wide range of NLP applications. These models are trained on massive corpora of heterogeneous data from web crawls, which enables them to learn general language patterns and semantic relationships. However, the largest models are both expensive to train and deploy and are often closed-source, so we lack access to their data and design decisions. We argue that this trend towards large, general-purpose models should be complemented with single-purpose, more modestly sized pre-trained models. In this work, we take StackOverflow (SO) as a domain example in which large volumes of rich aligned code and text data is available. We adopt standard practices for pre-training large language models, including using a very large context size (2,048 tokens), batch size (0.5M tokens
    
[^81]: OWQ：大语言模型权重量化中激活离群值的启示

    OWQ: Lessons learned from activation outliers for weight quantization in large language models. (arXiv:2306.02272v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02272](http://arxiv.org/abs/2306.02272)

    在大语言模型的推理中，要使用多个服务器贵重的GPU导致显著的成本障碍，OWQ提出的一种后训练量化方法可以在最小质量损失的情况下减少这种限制。它可以通过考虑激活离群值来确定权值量化误差的因素，并为易受攻击的权重分配高精度，具有与OPTQ相当的质量。

    

    拥有数十亿个参数的大型语言模型(LLMs)通过简单的提示调整和少量的示例，在各种语言任务中展现出令人惊叹的结果，而无需进行任务特定的微调。然而，它们巨大的尺寸要求甚至在推理时使用多个服务器级的GPU，从而产生了显著的成本障碍。为了解决这一限制，我们提出了一种新型的后训练量化方法来量化权重，减少质量损失。虽然已知激活离群值在激活量化中存在问题，但我们的理论分析表明，通过考虑激活离群值，我们可以确定导致权重量化误差的因素。我们提出了一种创新的后训练量化方案，名为Outlier-Aware Weight Quantization (OWQ)，它可以识别易受攻击的权重并为它们分配高精度。我们的大量实验表明，OWQ生成的3.01位模型具有与OPTQ生成的4位模型相当的质量。

    Large language models (LLMs) with hundreds of billions of parameters show impressive results across various language tasks using simple prompt tuning and few-shot examples, without the need for task-specific fine-tuning. However, their enormous size requires multiple server-grade GPUs even for inference, creating a significant cost barrier. To address this limitation, we introduce a novel post-training quantization method for weights with minimal quality degradation. While activation outliers are known to be problematic in activation quantization, our theoretical analysis suggests that we can identify factors contributing to weight quantization errors by considering activation outliers. We propose an innovative PTQ scheme called outlier-aware weight quantization (OWQ), which identifies vulnerable weights and allocates high-precision to them. Our extensive experiments demonstrate that the 3.01-bit models produced by OWQ exhibit comparable quality to the 4-bit models generated by OPTQ.
    
[^82]: 大型语言模型是零-shot推荐系统排名者

    Large Language Models are Zero-Shot Rankers for Recommender Systems. (arXiv:2305.08845v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2305.08845](http://arxiv.org/abs/2305.08845)

    大型语言模型表现出有希望的零-shot排名能力，但在感知历史互动顺序和受到偏见影响方面存在问题。本研究通过特殊设计的提示和引导策略来缓解这些问题。

    

    最近，大型语言模型（例如GPT-4）展示出了令人印象深刻的通用任务解决能力，包括潜力接近推荐任务。在这一研究方向上，本文旨在研究作为推荐系统排名模型的LLMs的能力。

    Recently, large language models (LLMs) (e.g., GPT-4) have demonstrated impressive general-purpose task-solving abilities, including the potential to approach recommendation tasks. Along this line of research, this work aims to investigate the capacity of LLMs that act as the ranking model for recommender systems. We first formalize the recommendation problem as a conditional ranking task, considering sequential interaction histories as conditions and the items retrieved by other candidate generation models as candidates. To solve the ranking task by LLMs, we carefully design the prompting template and conduct extensive experiments on two widely-used datasets. We show that LLMs have promising zero-shot ranking abilities but (1) struggle to perceive the order of historical interactions, and (2) can be biased by popularity or item positions in the prompts. We demonstrate that these issues can be alleviated using specially designed prompting and bootstrapping strategies. Equipped with thes
    
[^83]: 规模上的解释性：在Alpaca中识别因果机制

    Interpretability at Scale: Identifying Causal Mechanisms in Alpaca. (arXiv:2305.08809v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08809](http://arxiv.org/abs/2305.08809)

    通过使用分布式对齐搜索（DAS）方法，我们在大型语言模型中实现了规模上的解释性，这使得我们能够高效地搜索到解释性因果结构，并应用于Alpaca模型中。

    

    对于AI安全而言，获得大型通用语言模型的人类可解释性解释是一个紧急目标。然而，同样重要的是我们的解释性方法能够忠实于模型行为底层的因果动力学，且能够在未见输入上具有鲁棒泛化性。分布式对齐搜索（DAS）是一种强大的渐变下降方法，它基于一种因果抽象理论，已经发现了可解释的符号算法和针对特定任务进行细调的小型深度学习模型之间的完美对齐。在本文中，我们通过用学习得到的参数来替换剩余的蛮力搜索步骤，显著扩展了DAS，这种方法我们称之为无边界DAS。这使得我们能够在大型语言模型中高效地搜索可解释的因果结构，同时它们遵循指令。我们将无边界DAS应用于Alpaca模型（7B参数），它可以快速解决一个简单的数值推理问题。通过无边界DAS，我们发现...

    Obtaining human-interpretable explanations of large, general-purpose language models is an urgent goal for AI safety. However, it is just as important that our interpretability methods are faithful to the causal dynamics underlying model behavior and able to robustly generalize to unseen inputs. Distributed Alignment Search (DAS) is a powerful gradient descent method grounded in a theory of causal abstraction that has uncovered perfect alignments between interpretable symbolic algorithms and small deep learning models fine-tuned for specific tasks. In the present paper, we scale DAS significantly by replacing the remaining brute-force search steps with learned parameters -- an approach we call Boundless DAS. This enables us to efficiently search for interpretable causal structure in large language models while they follow instructions. We apply Boundless DAS to the Alpaca model (7B parameters), which, off the shelf, solves a simple numerical reasoning problem. With Boundless DAS, we di
    
[^84]: ReCOGS: 一个逻辑形式的细节如何影响语义解释的评估

    ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation. (arXiv:2303.13716v1 [cs.CL])

    [http://arxiv.org/abs/2303.13716](http://arxiv.org/abs/2303.13716)

    本文研究了合成通用基准的局限性，发现逻辑形式（LF）的细节可能影响模型性能。作者对COGS基准进行了研究，结果表明基础模型能够获得足够的掌握。作者还强调了设计能准确捕捉自然语言语义的LF的重要性。

    

    合成通用基准旨在评估模型是否能够准确地计算新句子的含义，但是用逻辑形式（LF）预测来操作。这引发了一个担忧，即所选择的LF的语义无关的细节可能会塑造模型的性能。我们认为COGS基准（Kim和Linzen，2020）实现了这一关注点。COGS提出了看起来对现有模型来说不可能的通用分割，这可能被视为对这些模型的控诉。然而，我们表明负面结果跟COGS LFs的细节相关。将这些LF转换为语义等效的LF，并分解出与语义解释无关的能力，我们发现即使是基线模型也能获得足够的掌握。最近的COGS LFs无变量翻译表明了类似的结论，但我们观察到这种格式不是语义等效的；它无法准确表示一些COGS的含义。这些发现促进我们对当前的合成通用基准的局限性的理解，并强调设计准确捕捉自然语言语义的LF的重要性。

    Compositional generalization benchmarks seek to assess whether models can accurately compute meanings for novel sentences, but operationalize this in terms of logical form (LF) prediction. This raises the concern that semantically irrelevant details of the chosen LFs could shape model performance. We argue that this concern is realized for the COGS benchmark (Kim and Linzen, 2020). COGS poses generalization splits that appear impossible for present-day models, which could be taken as an indictment of those models. However, we show that the negative results trace to incidental features of COGS LFs. Converting these LFs to semantically equivalent ones and factoring out capabilities unrelated to semantic interpretation, we find that even baseline models get traction. A recent variable-free translation of COGS LFs suggests similar conclusions, but we observe this format is not semantically equivalent; it is incapable of accurately representing some COGS meanings. These findings inform our 
    
[^85]: Oolong: 用可控实验证明转移学习的困难性

    Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies. (arXiv:2202.12312v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.12312](http://arxiv.org/abs/2202.12312)

    本论文通过对预训练模型进行可控实验证明转移学习的困难性，发现模型可以从句法风格的转变中恢复，但无法从词汇不对齐和嵌入矩阵重新初始化中恢复，即使进行了大量预训练。

    

    当我们将预训练的语言模型转移到新的语言时，有许多变化因素同时发生。为了解交叉语言变体的不同因素（如句法相似性和词汇相似性）的影响，我们提出了一组可控制的转移研究：我们系统地转换GLUE基准测试的语言，逐个改变一种交叉语言变体的因素，然后测量预训练模型在后续性能中的降低。我们发现，模型可以在句法风格的转变中很大程度上恢复，但无法从词汇不对齐和嵌入矩阵重新初始化中恢复，即使在1500万令牌的继续预训练的情况下。%另一方面，在低数据范围内转移到具有不对齐词汇的数据集中很难恢复。此外，转移语言中的高质量分词器也不会使词汇对齐变得更容易。我们的实验提供了关于交叉语言转移因素的洞察。

    When we transfer a pretrained language model to a new language, there are many axes of variation that change at once. To disentangle the impact of different factors like syntactic similarity and vocabulary similarity, we propose a set of controlled transfer studies: we systematically transform the language of the GLUE benchmark, altering one axis of crosslingual variation at a time, and then measure the resulting drops in a pretrained model's downstream performance. We find that models can largely recover from syntactic-style shifts, but cannot recover from vocabulary misalignment and embedding matrix re-initialization, even with continued pretraining on 15 million tokens. %On the other hand, transferring to a dataset with an unaligned vocabulary is extremely hard to recover from in the low-data regime. Moreover, good-quality tokenizers in the transfer language do not make vocabulary alignment easier. Our experiments provide insights into the factors of cross-lingual transfer that rese
    
[^86]: 一种新的用于无监督抽取式摘要方法的句子提取策略

    A New Sentence Extraction Strategy for Unsupervised Extractive Summarization Methods. (arXiv:2112.03203v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.03203](http://arxiv.org/abs/2112.03203)

    本文提出了一种新的句子提取策略，用于改善特征分布和降低摘要句子之间的相互信息，该策略适用于现有的无监督抽取式摘要方法，并在实验证明了其有效性。

    

    最近几年，由于神经网络模型的研究，文本摘要方法再次引起了广泛关注。当前大部分基于神经网络模型的文本摘要方法都是需要大规模数据集的监督方法。然而，在实际应用中，获取大规模数据集是困难的。本文从信息论的角度对抽取式文本摘要方法进行建模，并使用统一的框架描述了无监督抽取方法。为了改善特征分布并降低摘要句子之间的相互信息，我们提出了一种新的句子提取策略，可以应用于现有的无监督抽取方法。我们在不同的数据集上进行了实验，结果表明我们的策略确实有效并符合预期。

    In recent years, text summarization methods have attracted much attention again thanks to the researches on neural network models. Most of the current text summarization methods based on neural network models are supervised methods which need large-scale datasets. However, large-scale datasets are difficult to obtain in practical applications. In this paper, we model the task of extractive text summarization methods from the perspective of Information Theory, and then describe the unsupervised extractive methods with a uniform framework. To improve the feature distribution and to decrease the mutual information of summarization sentences, we propose a new sentence extraction strategy which can be applied to existing unsupervised extractive methods. Experiments are carried out on different datasets, and results show that our strategy is indeed effective and in line with expectations.
    

