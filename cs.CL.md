# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification](https://arxiv.org/abs/2402.10735) | 我们提出了一个逻辑推理框架，用于评估ChatGPT在声明验证中的推理能力，发现其在归纳推理方面存在困难，并提出了一种缓解方法。 |

# 详细

[^1]: 在声明验证的背景下评估ChatGPT的推理能力

    Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification

    [https://arxiv.org/abs/2402.10735](https://arxiv.org/abs/2402.10735)

    我们提出了一个逻辑推理框架，用于评估ChatGPT在声明验证中的推理能力，发现其在归纳推理方面存在困难，并提出了一种缓解方法。

    

    当前有关LLMs的推理能力的辩论正在日益激烈。我们从声明/谣言验证的角度来审视这个问题。我们提出了第一个逻辑推理框架，旨在将任何声明或传言与证据结合，拆分成验证所需的基本推理步骤。基于我们的框架，我们整理了两个注释集合，其中包括来自维基百科的合成数据集和源自Twitter上流传的谣言的真实数据集。我们使用它们来评估GPT-3.5-Turbo和GPT-4（以下简称为ChatGPT）在我们框架的背景下的推理能力，并提供了彻底的分析。我们的研究表明，ChatGPT在归纳推理方面存在困难，尽管可以通过使用手动的思维链路（Chain of Thought，CoT）来缓解这一问题，而非零编码（Zero Shot，ZS）和ZS CoT方法。我们的研究有助于不断增长的研究领域，表明Cha

    arXiv:2402.10735v1 Announce Type: new  Abstract: The reasoning capabilities of LLMs are currently hotly debated. We examine the issue from the perspective of claim/rumour verification. We propose the first logical reasoning framework designed to break down any claim or rumor paired with evidence into the atomic reasoning steps necessary for verification. Based on our framework, we curate two annotated collections of such claim/evidence pairs: a synthetic dataset from Wikipedia and a real-world set stemming from rumours circulating on Twitter. We use them to evaluate the reasoning capabilities of GPT-3.5-Turbo and GPT-4 (hereinafter referred to as ChatGPT) within the context of our framework, providing a thorough analysis. Our results show that ChatGPT struggles in abductive reasoning, although this can be somewhat mitigated by using manual Chain of Thought (CoT) as opposed to Zero Shot (ZS) and ZS CoT approaches. Our study contributes to the growing body of research suggesting that Cha
    

