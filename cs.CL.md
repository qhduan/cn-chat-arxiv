# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Structured Information Matters: Incorporating Abstract Meaning Representation into LLMs for Improved Open-Domain Dialogue Evaluation](https://arxiv.org/abs/2404.01129) | 将抽象意义表示结合到LLMs中，提出了一个简单有效的框架用于改善开放领域对话评估 |
| [^2] | [Concurrent Linguistic Error Detection (CLED) for Large Language Models](https://arxiv.org/abs/2403.16393) | 提出了一种针对大型语言模型的并发语言错误检测方案，通过提取文本的语言特征并使用分类器进行错误检测。 |

# 详细

[^1]: 结构化信息很重要：将抽象意义表示引入LLMs以改善开放领域对话评估

    Structured Information Matters: Incorporating Abstract Meaning Representation into LLMs for Improved Open-Domain Dialogue Evaluation

    [https://arxiv.org/abs/2404.01129](https://arxiv.org/abs/2404.01129)

    将抽象意义表示结合到LLMs中，提出了一个简单有效的框架用于改善开放领域对话评估

    

    arXiv:2404.01129v1 公告类型：新的 摘要：自动的开放领域对话评估已经引起越来越多的关注。可训练的评估指标通常是通过训练具有真正正例和随机选择的负例回复来训练的，导致它们倾向于将更高内容相似性的回复分配更高的得分给定一个上下文。然而，对抗性的负面回复具有与上下文高内容相似性，同时在语义上不同。因此，现有的评估指标不足以评估这类回复，导致与人类判断之间的相关性较低。虽然最近的研究已经显示出在利用大型语言模型（LLMs）进行开放领域对话评估方面有一定效果，但它们仍然在有效处理对抗性负面示例方面遇到挑战。在本文中，我们提出了一个简单而有效的框架用于开放领域对话评估，它结合了领域特定的语言模型（SLMs）。

    arXiv:2404.01129v1 Announce Type: new  Abstract: Automatic open-domain dialogue evaluation has attracted increasing attention. Trainable evaluation metrics are commonly trained with true positive and randomly selected negative responses, resulting in a tendency for them to assign a higher score to the responses that share higher content similarity with a given context. However, adversarial negative responses possess high content similarity with the contexts whilst being semantically different. Therefore, existing evaluation metrics are not robust enough to evaluate such responses, resulting in low correlations with human judgments. While recent studies have shown some efficacy in utilizing Large Language Models (LLMs) for open-domain dialogue evaluation, they still encounter challenges in effectively handling adversarial negative examples. In this paper, we propose a simple yet effective framework for open-domain dialogue evaluation, which combines domain-specific language models (SLMs
    
[^2]: 大型语言模型的并发语言错误检测（CLED）

    Concurrent Linguistic Error Detection (CLED) for Large Language Models

    [https://arxiv.org/abs/2403.16393](https://arxiv.org/abs/2403.16393)

    提出了一种针对大型语言模型的并发语言错误检测方案，通过提取文本的语言特征并使用分类器进行错误检测。

    

    大型语言模型（LLMs）的广泛采用使得它们的可靠性成为一个紧迫问题。错误的检测是减轻其对系统影响的第一步，因此，LLMs的高效错误检测是一个重要问题。基于对LLMs输出进行的观察，我们提出进行并发语言错误检测（CLED）；该方案提取LLMs生成文本的一些语言特征，并将它们输入到一个并发分类器中进行错误检测。

    arXiv:2403.16393v1 Announce Type: new  Abstract: The wide adoption of Large language models (LLMs) makes their dependability a pressing concern. Detection of errors is the first step to mitigating their impact on a system and thus, efficient error detection for LLMs is an important issue. In many settings, the LLM is considered as a black box with no access to the internal nodes; this prevents the use of many error detection schemes that need access to the model's internal nodes. An interesting observation is that the output of LLMs in error-free operation should be valid and normal text. Therefore, when the text is not valid or differs significantly from normal text, it is likely that there is an error. Based on this observation we propose to perform Concurrent Linguistic Error Detection (CLED); this scheme extracts some linguistic features of the text generated by the LLM and feeds them to a concurrent classifier that detects errors. Since the proposed error detection mechanism only 
    

