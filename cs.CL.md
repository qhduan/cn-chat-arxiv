# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Whose LLM is it Anyway? Linguistic Comparison and LLM Attribution for GPT-3.5, GPT-4 and Bard](https://arxiv.org/abs/2402.14533) | 通过对GPT-3.5、GPT-4和Bard生成的文本进行语言分析比较，发现不同的LLM之间存在显著的语言变化，可以以88%的准确率通过简单的分类模型将文本归因于相应的LLM来源。 |
| [^2] | [Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports.](http://arxiv.org/abs/2401.12989) | 本研究评估了使用语言模型从社交媒体数据中监测枪支暴力事件的可行性。研究团队使用经过微调的BERT模型识别巴西的枪支暴力报告并取得了高准确度。研究结果有助于人权组织收集包含所需数据的全面数据库。 |
| [^3] | [Semantic Parsing for Question Answering over Knowledge Graphs.](http://arxiv.org/abs/2401.06772) | 本文介绍了一种新的方法，利用图到段映射来实现问题回答知识图谱。该方法侧重于语义解析，解决了理解问题中的隐含实体、关系和复杂约束的挑战。通过结合规则和神经网络技术，构建了高精度和全面的语义段序列，实现了问题陈述的有效表示。 |
| [^4] | [Rule-Guided Joint Embedding Learning of Knowledge Graphs.](http://arxiv.org/abs/2401.02968) | 本文介绍了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络，并通过规则和字面信息的表示计算置信度和相关性指标，以提高知识图谱嵌入学习的效果。 |

# 详细

[^1]: 《它到底是谁的LLM？GPT-3.5、GPT-4和Bard的语言比较和LLM属性归因》

    Whose LLM is it Anyway? Linguistic Comparison and LLM Attribution for GPT-3.5, GPT-4 and Bard

    [https://arxiv.org/abs/2402.14533](https://arxiv.org/abs/2402.14533)

    通过对GPT-3.5、GPT-4和Bard生成的文本进行语言分析比较，发现不同的LLM之间存在显著的语言变化，可以以88%的准确率通过简单的分类模型将文本归因于相应的LLM来源。

    

    大型语言模型（LLMs）能够生成与或超越人类质量相似的文本。然而，LLMs是否倾向于表现出类似于人类作者的独特语言风格尚不清楚。通过全面的语言分析，我们比较了由当今最流行的三种LLMs（GPT-3.5、GPT-4和Bard）生成的文本的词汇、词性分布、依赖分布和情感与多样输入。结果显示出显著的语言变化，进而使我们能够使用简单的现成分类模型以88%的准确率将给定文本归因于其LLM来源。讨论了这一有趣发现的理论和实践影响。

    arXiv:2402.14533v1 Announce Type: new  Abstract: Large Language Models (LLMs) are capable of generating text that is similar to or surpasses human quality. However, it is unclear whether LLMs tend to exhibit distinctive linguistic styles akin to how human authors do. Through a comprehensive linguistic analysis, we compare the vocabulary, Part-Of-Speech (POS) distribution, dependency distribution, and sentiment of texts generated by three of the most popular LLMS today (GPT-3.5, GPT-4, and Bard) to diverse inputs. The results point to significant linguistic variations which, in turn, enable us to attribute a given text to its LLM origin with a favorable 88\% accuracy using a simple off-the-shelf classification model. Theoretical and practical implications of this intriguing finding are discussed.
    
[^2]: 在交火中：评估使用语言模型众包枪支暴力报告的效果

    Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports. (arXiv:2401.12989v1 [cs.CL])

    [http://arxiv.org/abs/2401.12989](http://arxiv.org/abs/2401.12989)

    本研究评估了使用语言模型从社交媒体数据中监测枪支暴力事件的可行性。研究团队使用经过微调的BERT模型识别巴西的枪支暴力报告并取得了高准确度。研究结果有助于人权组织收集包含所需数据的全面数据库。

    

    枪支暴力是一个紧迫且不断增长的人权问题，影响着社会的方方面面，从医疗保健和教育到心理学和经济学。可靠的枪支事件数据对于制定更有效的公共政策和应急响应至关重要。然而，缺乏全面的数据库和面对面调查的风险阻止了人权组织在大多数国家收集所需的数据。在这里，我们与一家巴西人权组织合作，对语言模型进行系统评估，以帮助监测来自社交媒体数据的现实世界枪支事件。我们提出了一个在Twitter上经过微调的基于BERT的模型，用于区分枪支暴力报告和普通葡萄牙语文本。我们的模型达到了高达0.97的AUC分数。然后，我们将我们的模型整合到一个Web应用程序中，并在实时干预中对其进行测试。我们研究并采访巴西分析师，他们在持续进行社交媒体事实核查。

    Gun violence is a pressing and growing human rights issue that affects nearly every dimension of the social fabric, from healthcare and education to psychology and the economy. Reliable data on firearm events is paramount to developing more effective public policy and emergency responses. However, the lack of comprehensive databases and the risks of in-person surveys prevent human rights organizations from collecting needed data in most countries. Here, we partner with a Brazilian human rights organization to conduct a systematic evaluation of language models to assist with monitoring real-world firearm events from social media data. We propose a fine-tuned BERT-based model trained on Twitter (now X) texts to distinguish gun violence reports from ordinary Portuguese texts. Our model achieves a high AUC score of 0.97. We then incorporate our model into a web application and test it in a live intervention. We study and interview Brazilian analysts who continuously fact-check social media
    
[^3]: 问题回答知识图谱的语义解析

    Semantic Parsing for Question Answering over Knowledge Graphs. (arXiv:2401.06772v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.06772](http://arxiv.org/abs/2401.06772)

    本文介绍了一种新的方法，利用图到段映射来实现问题回答知识图谱。该方法侧重于语义解析，解决了理解问题中的隐含实体、关系和复杂约束的挑战。通过结合规则和神经网络技术，构建了高精度和全面的语义段序列，实现了问题陈述的有效表示。

    

    本文介绍了一种新的方法，利用图到段映射来实现问题回答知识图谱。该方法侧重于语义解析，这是解释问题陈述的关键方法。挑战在于理解问题中的隐含实体、关系以及时间、排序和聚合等复杂约束，这些约束在知识图谱的背景下进行上下文处理。我们的框架采用了基于规则和基于神经网络的技术的组合，解析并构建了高精度和全面的语义段序列。这些序列形成语义查询图，有效地表示问题陈述。我们将问题语义解析作为一个序列生成任务，利用编码器-解码器神经网络将自然语言问题转化为语义段。此外，为了增强对隐含实体和关系的解析，我们结合了图神经网络。

    In this paper, we introduce a novel method with graph-to-segment mapping for question answering over knowledge graphs, which helps understanding question utterances. This method centers on semantic parsing, a key approach for interpreting these utterances. The challenges lie in comprehending implicit entities, relationships, and complex constraints like time, ordinality, and aggregation within questions, contextualized by the knowledge graph. Our framework employs a combination of rule-based and neural-based techniques to parse and construct highly accurate and comprehensive semantic segment sequences. These sequences form semantic query graphs, effectively representing question utterances. We approach question semantic parsing as a sequence generation task, utilizing an encoder-decoder neural network to transform natural language questions into semantic segments. Moreover, to enhance the parsing of implicit entities and relations, we incorporate a graph neural network that leverages t
    
[^4]: 知识图谱的规则引导联合嵌入学习

    Rule-Guided Joint Embedding Learning of Knowledge Graphs. (arXiv:2401.02968v1 [cs.CL])

    [http://arxiv.org/abs/2401.02968](http://arxiv.org/abs/2401.02968)

    本文介绍了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络，并通过规则和字面信息的表示计算置信度和相关性指标，以提高知识图谱嵌入学习的效果。

    

    在最近的研究中，关注点主要集中在增强知识图谱嵌入学习上，该学习将知识图谱中的实体和关系编码为低维向量空间。尽管当前模型主要考虑这些图谱的结构方面，但在知识图谱中存在着丰富的上下文和字面信息，可以用于更有效的嵌入学习。本文引入了一种新型模型，该模型将上下文和字面信息容纳到实体和关系的嵌入中，利用图卷积网络。具体地，对于上下文信息，我们通过置信度和相关性指标评估其重要性。我们开发了一种独特的基于规则的方法来计算置信度指标，并从字面信息的表示中得出相关性指标。我们通过对两个已建立的基准数据集进行详尽的实验证实了我们模型的性能。

    In recent studies, the focus has been on enhancing knowledge graph embedding learning, which encodes entities and relations in knowledge graphs into low-dimensional vector spaces. While current models mainly consider the structural aspects of these graphs, there's a wealth of contextual and literal information in knowledge graphs that can be utilized for more effective embeddings. This paper introduces a novel model that incorporates both contextual and literal information into entity and relation embeddings, utilizing graph convolutional networks. Specifically, for contextual information, we assess its significance through confidence and relatedness metrics. A unique rule-based method is developed to calculate the confidence metric, and the relatedness metric is derived from the literal information's representations. We validated our model's performance with thorough experiments on two established benchmark datasets.
    

