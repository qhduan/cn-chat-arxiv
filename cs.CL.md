# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers](https://arxiv.org/abs/2401.17196) | 本文研究了文本分类中单词扰动的脆弱性问题，并提出了一种新的度量指标以评估分类器的鲁棒性。同时，本文引入了SP-Attack和SP-Defense方法来针对单词扰动进行攻击和防御，实现更高的攻击成功率和更好的句子含义保持。 |

# 详细

[^1]: 一个单词的改变即可：为文本分类器设计攻击与防御策略

    Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers

    [https://arxiv.org/abs/2401.17196](https://arxiv.org/abs/2401.17196)

    本文研究了文本分类中单词扰动的脆弱性问题，并提出了一种新的度量指标以评估分类器的鲁棒性。同时，本文引入了SP-Attack和SP-Defense方法来针对单词扰动进行攻击和防御，实现更高的攻击成功率和更好的句子含义保持。

    

    在文本分类中，创建对抗样本意味着在句子中微妙地扰动几个单词而不改变其含义，导致分类器错误分类。令人担忧的是，现有方法生成的对抗样本中有相当部分只改变了一个单词。这种单词扰动的脆弱性代表了分类器的一个重大弱点，恶意用户可以利用它高效地创建大量对抗样本。本文研究了这个问题并作出了以下关键贡献：(1) 我们引入了一种新的度量指标 \r{ho} 来定量评估分类器对于单词扰动的鲁棒性。(2) 我们提出了 SP-Attack，旨在利用单词扰动的脆弱性，实现更高的攻击成功率，更好地保持句子的含义，同时降低与现有对抗方法相比的计算成本。(3) 我们提出了 SP-Defense，旨在改进分类器的抵抗单词扰动的能力，减小攻击效果。

    In text classification, creating an adversarial example means subtly perturbing a few words in a sentence without changing its meaning, causing it to be misclassified by a classifier. A concerning observation is that a significant portion of adversarial examples generated by existing methods change only one word. This single-word perturbation vulnerability represents a significant weakness in classifiers, which malicious users can exploit to efficiently create a multitude of adversarial examples. This paper studies this problem and makes the following key contributions: (1) We introduce a novel metric \r{ho} to quantitatively assess a classifier's robustness against single-word perturbation. (2) We present the SP-Attack, designed to exploit the single-word perturbation vulnerability, achieving a higher attack success rate, better preserving sentence meaning, while reducing computation costs compared to state-of-the-art adversarial methods. (3) We propose SP-Defense, which aims to impro
    

