# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](https://arxiv.org/abs/2404.01245) | 该论文提出了一个通用框架，用于设计大型语言模型水印的统计效率和检测规则，通过关键统计量和秘密密钥控制误报率，同时评估水印检测规则的能力。 |
| [^2] | [NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models](https://arxiv.org/abs/2403.01777) | 这项研究介绍了一个旨在评估多模态大型语言模型推理能力的动态基准NPHardEval4V，发现在推理能力方面不同模型存在显著差异，并揭示了相对于LLMs，MLLMs的推理性能较弱。 |
| [^3] | [Cross-lingual Offensive Language Detection: A Systematic Review of Datasets, Transfer Approaches and Challenges.](http://arxiv.org/abs/2401.09244) | 这篇论文对社交媒体中跨语言冒犯性语言检测的技术进行了系统综述，分析了67篇相关论文，并总结了跨语言转移学习的三种主要方法。同时，还探讨了该领域的挑战和未来的研究机会。 |

# 详细

[^1]: 大型语言模型水印的统计框架: 枢轴、检测效率和最优规则

    A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules

    [https://arxiv.org/abs/2404.01245](https://arxiv.org/abs/2404.01245)

    该论文提出了一个通用框架，用于设计大型语言模型水印的统计效率和检测规则，通过关键统计量和秘密密钥控制误报率，同时评估水印检测规则的能力。

    

    自ChatGPT于2022年11月推出以来，将几乎不可察觉的统计信号嵌入到大型语言模型（LLMs）生成的文本中，也被称为水印，已被用作从其人类撰写对应物上可证检测LLM生成文本的原则性方法。 本文介绍了一个通用灵活的框架，用于推理水印的统计效率并设计强大的检测规则。受水印检测的假设检验公式启发，我们的框架首先选择文本的枢轴统计量和由LLM提供给验证器的秘密密钥，以实现控制误报率（将人类撰写的文本错误地检测为LLM生成的错误）。 接下来，该框架允许通过获取渐近错误负率（将LLM生成文本错误地检测为人类撰写的错误）的封闭形式表达式来评估水印检测规则的能力。

    arXiv:2404.01245v1 Announce Type: cross  Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of 
    
[^2]: NPHardEval4V: 多模态大型语言模型的动态推理基准

    NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models

    [https://arxiv.org/abs/2403.01777](https://arxiv.org/abs/2403.01777)

    这项研究介绍了一个旨在评估多模态大型语言模型推理能力的动态基准NPHardEval4V，发现在推理能力方面不同模型存在显著差异，并揭示了相对于LLMs，MLLMs的推理性能较弱。

    

    理解多模态大型语言模型（MLLMs）的推理能力是一个重要的研究领域。在这项研究中，我们引入了一个动态基准，NPHardEval4V，旨在解决评估MLLM纯粹推理能力方面的现有差距。我们的基准旨在提供一个平台，以解开诸多因素（如图像识别和指令遵循）对模型整体性能的影响，从而专注于评估它们的推理能力。我们的研究发现不同模型在推理能力方面存在显著差异，并突出了相较于LLMs，MLLMs在推理方面表现相对较弱。我们还研究了不同提示样式（包括视觉、文本和结合视觉与文本提示）对MLLM推理能力的影响，展示了多模态输入在模型性能中的不同影响。

    arXiv:2403.01777v1 Announce Type: new  Abstract: Understanding the reasoning capabilities of Multimodal Large Language Models (MLLMs) is an important area of research. In this study, we introduce a dynamic benchmark, NPHardEval4V, aimed at addressing the existing gaps in evaluating the pure reasoning abilities of MLLMs. Our benchmark aims to provide a venue to disentangle the effect of various factors such as image recognition and instruction following, from the overall performance of the models, allowing us to focus solely on evaluating their reasoning abilities. Our findings reveal significant discrepancies in reasoning abilities across different models and highlight the relatively weak performance of MLLMs compared to LLMs in terms of reasoning. We also investigate the impact of different prompting styles, including visual, text, and combined vision and text prompts, on the reasoning abilities of MLLMs, demonstrating the different impacts of multimodal inputs in model performance. U
    
[^3]: 跨语言冒犯性语言检测：数据集、转移方法和挑战的系统综述

    Cross-lingual Offensive Language Detection: A Systematic Review of Datasets, Transfer Approaches and Challenges. (arXiv:2401.09244v1 [cs.CL])

    [http://arxiv.org/abs/2401.09244](http://arxiv.org/abs/2401.09244)

    这篇论文对社交媒体中跨语言冒犯性语言检测的技术进行了系统综述，分析了67篇相关论文，并总结了跨语言转移学习的三种主要方法。同时，还探讨了该领域的挑战和未来的研究机会。

    

    社交媒体上冒犯性语言的普及和迅速发展增加了检测的复杂性，尤其突显了在不同语言中识别此类内容的挑战。本综述系统性、全面地探讨了社交媒体中跨语言转移学习（CLTL）技术在冒犯性语言检测中的应用。我们的研究是该领域首个专注于跨语言情景的全面概述。我们分析了67篇相关论文，并对这些研究进行了各个维度的分类，包括使用的多语种数据集的特征、使用的跨语言资源以及实施的具体CLTL策略。此外，根据“何种转移”，我们还总结了三种主要的CLTL转移方法：实例、特征和参数转移。此外，我们还对该领域当前的挑战和未来的研究机会进行了探讨。

    The growing prevalence and rapid evolution of offensive language in social media amplify the complexities of detection, particularly highlighting the challenges in identifying such content across diverse languages. This survey presents a systematic and comprehensive exploration of Cross-Lingual Transfer Learning (CLTL) techniques in offensive language detection in social media. Our study stands as the first holistic overview to focus exclusively on the cross-lingual scenario in this domain. We analyse 67 relevant papers and categorise these studies across various dimensions, including the characteristics of multilingual datasets used, the cross-lingual resources employed, and the specific CLTL strategies implemented. According to "what to transfer", we also summarise three main CLTL transfer approaches: instance, feature, and parameter transfer. Additionally, we shed light on the current challenges and future research opportunities in this field. Furthermore, we have made our survey re
    

