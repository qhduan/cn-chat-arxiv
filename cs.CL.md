# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation](https://arxiv.org/abs/2403.00046) | SEED提出了一种名为Sample-Efficient adaptation with Error-Driven learning的新颖适应方法，利用LLMs产生的错误作为学习机会，从而实现对代码生成任务的高效学习。 |

# 详细

[^1]: 使用样本高效适应对大型语言模型进行自定义以进行代码生成

    SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation

    [https://arxiv.org/abs/2403.00046](https://arxiv.org/abs/2403.00046)

    SEED提出了一种名为Sample-Efficient adaptation with Error-Driven learning的新颖适应方法，利用LLMs产生的错误作为学习机会，从而实现对代码生成任务的高效学习。

    

    虽然大型语言模型（LLMs）在代码生成方面取得了重大进展，但在特定场景下仍然存在困难。这些场景通常需要调整LLMs以满足特定需求，但实际可用的训练数据有限，导致代码生成性能较差。如何有效地调整LLMs以适应新场景并使用更少的训练样本是当前代码生成面临的主要挑战。在本文中，我们提出了一种名为SEED的新颖适应方法，即Sample-Efficient adaptation with Error-Driven learning for code generation。SEED利用LLMs产生的错误作为学习机会，利用错误修订来克服自身缺点，从而实现有效学习。具体而言，SEED涉及识别LLMs生成的错误代码，使用Self-revise进行代码修订，优化模型并迭代地进行适应。

    arXiv:2403.00046v1 Announce Type: cross  Abstract: Although Large Language Models (LLMs) have made significant progress in code generation, they still struggle with code generation tasks in specific scenarios. These scenarios usually necessitate the adaptation of LLMs to fulfill specific needs, but the limited training data available in practice leads to poor code generation performance. How to effectively adapt LLMs to new scenarios with fewer training samples is a major challenge for current code generation. In this paper, we propose a novel adaptation approach named SEED, which stands for Sample-Efficient adaptation with Error-Driven learning for code generation. SEED leverages the errors made by LLMs as learning opportunities, using error revision to overcome its own shortcomings, thus achieving efficient learning. Specifically, SEED involves identifying error code generated by LLMs, employing Self-revise for code revision, optimizing the model with revised code, and iteratively ad
    

