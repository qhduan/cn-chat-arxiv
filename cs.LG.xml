<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#22312;&#20984;&#22810;&#38754;&#20307;&#32593;&#26684;&#19978;&#65292;&#25552;&#20986;&#20102;&#29992;&#20004;&#20010;&#38544;&#34255;&#23618;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#26469;&#24369;&#34920;&#31034;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#65292;&#24182;&#26681;&#25454;&#32593;&#26684;&#20013;&#30340;&#22810;&#38754;&#20307;&#21644;&#36229;&#24179;&#38754;&#30340;&#25968;&#37327;&#20934;&#30830;&#30830;&#23450;&#20102;&#25152;&#38656;&#30340;&#31070;&#32463;&#20803;&#25968;&#65292;&#24314;&#31435;&#20102;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#26377;&#38480;&#20803;&#20989;&#25968;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.05809</link><description>&lt;p&gt;
&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#26377;&#38480;&#20803;
&lt;/p&gt;
&lt;p&gt;
Shallow ReLU neural networks and finite elements
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05809
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20984;&#22810;&#38754;&#20307;&#32593;&#26684;&#19978;&#65292;&#25552;&#20986;&#20102;&#29992;&#20004;&#20010;&#38544;&#34255;&#23618;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#26469;&#24369;&#34920;&#31034;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#65292;&#24182;&#26681;&#25454;&#32593;&#26684;&#20013;&#30340;&#22810;&#38754;&#20307;&#21644;&#36229;&#24179;&#38754;&#30340;&#25968;&#37327;&#20934;&#30830;&#30830;&#23450;&#20102;&#25152;&#38656;&#30340;&#31070;&#32463;&#20803;&#25968;&#65292;&#24314;&#31435;&#20102;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#26377;&#38480;&#20803;&#20989;&#25968;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25351;&#20986;&#22312;&#20984;&#22810;&#38754;&#20307;&#32593;&#26684;&#19978;&#65292;&#21487;&#20197;&#29992;&#20004;&#20010;&#38544;&#34255;&#23618;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#24369;&#24847;&#20041;&#19979;&#34920;&#31034;&#65288;&#36830;&#32493;&#25110;&#19981;&#36830;&#32493;&#30340;&#65289;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#28041;&#21450;&#21040;&#30340;&#22810;&#38754;&#20307;&#21644;&#36229;&#24179;&#38754;&#30340;&#25968;&#37327;&#65292;&#20934;&#30830;&#32473;&#20986;&#20102;&#24369;&#34920;&#31034;&#25152;&#38656;&#30340;&#20004;&#20010;&#38544;&#34255;&#23618;&#30340;&#31070;&#32463;&#20803;&#25968;&#12290;&#36825;&#20123;&#32467;&#26524;&#33258;&#28982;&#22320;&#36866;&#29992;&#20110;&#24120;&#25968;&#21644;&#32447;&#24615;&#26377;&#38480;&#20803;&#20989;&#25968;&#12290;&#36825;&#31181;&#24369;&#34920;&#31034;&#24314;&#31435;&#20102;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#26377;&#38480;&#20803;&#20989;&#25968;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#24182;&#20026;&#36890;&#36807;&#26377;&#38480;&#20803;&#20989;&#25968;&#20998;&#26512;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;$L^p$&#33539;&#25968;&#20013;&#30340;&#36924;&#36817;&#33021;&#21147;&#25552;&#20379;&#20102;&#35270;&#35282;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#26368;&#36817;&#24352;&#37327;&#31070;&#32463;&#32593;&#32476;&#23545;&#24352;&#37327;&#26377;&#38480;&#20803;&#20989;&#25968;&#30340;&#20005;&#26684;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05809v1 Announce Type: cross  Abstract: We point out that (continuous or discontinuous) piecewise linear functions on a convex polytope mesh can be represented by two-hidden-layer ReLU neural networks in a weak sense. In addition, the numbers of neurons of the two hidden layers required to weakly represent are accurately given based on the numbers of polytopes and hyperplanes involved in this mesh. The results naturally hold for constant and linear finite element functions. Such weak representation establishes a bridge between shallow ReLU neural networks and finite element functions, and leads to a perspective for analyzing approximation capability of ReLU neural networks in $L^p$ norm via finite element functions. Moreover, we discuss the strict representation for tensor finite element functions via the recent tensor neural networks.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#36807;&#31243;&#20013;&#23384;&#22312;&#20960;&#20309;&#24341;&#23548;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2402.08269</link><description>&lt;p&gt;
&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20960;&#20309;&#24341;&#23548;&#38544;&#24335;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Geometry-induced Implicit Regularization in Deep ReLU Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08269
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#36807;&#31243;&#20013;&#23384;&#22312;&#20960;&#20309;&#24341;&#23548;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20855;&#26377;&#27604;&#35757;&#32451;&#26679;&#26412;&#26356;&#22810;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#19981;&#20250;&#36807;&#25311;&#21512;&#12290;&#38544;&#24335;&#27491;&#21017;&#21270;&#29616;&#35937;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#20986;&#29616;&#65292;&#23545;&#8220;&#22909;&#8221;&#30340;&#32593;&#32476;&#26377;&#21033;&#12290;&#22240;&#27492;&#65292;&#22914;&#26524;&#25105;&#20204;&#19981;&#32771;&#34385;&#25152;&#26377;&#21487;&#33021;&#30340;&#32593;&#32476;&#65292;&#32780;&#21482;&#32771;&#34385;&#8220;&#22909;&#8221;&#30340;&#32593;&#32476;&#65292;&#21442;&#25968;&#25968;&#37327;&#23601;&#19981;&#26159;&#19968;&#20010;&#36275;&#22815;&#34913;&#37327;&#22797;&#26434;&#24615;&#30340;&#25351;&#26631;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#21738;&#20123;&#32593;&#32476;&#21463;&#21040;&#38738;&#30544;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21442;&#25968;&#21464;&#21270;&#26102;&#36755;&#20986;&#38598;&#21512;&#30340;&#20960;&#20309;&#29305;&#24449;&#12290;&#24403;&#36755;&#20837;&#22266;&#23450;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#38598;&#21512;&#30340;&#32500;&#24230;&#20250;&#21457;&#29983;&#21464;&#21270;&#65292;&#24182;&#19988;&#23616;&#37096;&#32500;&#24230;&#65292;&#21363;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#65292;&#20960;&#20046;&#24635;&#26159;&#30001;&#38544;&#34255;&#23618;&#20013;&#30340;&#28608;&#27963;&#27169;&#24335;&#20915;&#23450;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#23545;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#23545;&#31216;&#24615;&#65288;&#31070;&#32463;&#20803;&#25490;&#21015;&#21644;&#27491;&#21521;&#32553;&#25918;&#65289;&#26159;&#19981;&#21464;&#30340;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#25209;&#27425;&#21151;&#33021;&#32500;&#24230;&#20250;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#20248;&#21270;&#36807;&#31243;&#20855;&#26377;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that neural networks with many more parameters than training examples do not overfit. Implicit regularization phenomena, which are still not well understood, occur during optimization and 'good' networks are favored. Thus the number of parameters is not an adequate measure of complexity if we do not consider all possible networks but only the 'good' ones. To better understand which networks are favored during optimization, we study the geometry of the output set as parameters vary. When the inputs are fixed, we prove that the dimension of this set changes and that the local dimension, called batch functional dimension, is almost surely determined by the activation patterns in the hidden layers. We prove that the batch functional dimension is invariant to the symmetries of the network parameterization: neuron permutations and positive rescalings. Empirically, we establish that the batch functional dimension decreases during optimization. As a consequence, optimization l
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.06388</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#21450;&#20854;&#22312;&#20462;&#25913;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#19978;&#30340;&#31574;&#30053;&#26799;&#24230;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06388
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21253;&#21547;&#30340;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#36981;&#24490;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65307;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#24212;&#29992;&#20110;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#20462;&#25913;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#39318;&#27425;&#23581;&#35797;&#24314;&#31435;&#20102;&#19968;&#20010;&#38543;&#26426;&#20248;&#21183;&#23398;&#20064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#25512;&#24191;&#20102;&#38543;&#26426;&#20248;&#21183;&#30340;&#27010;&#24565;&#20197;&#20351;&#20854;&#33021;&#22815;&#22312;&#20219;&#24847;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#36827;&#34892;&#27604;&#36739;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#26469;&#22788;&#29702;&#36830;&#32493;&#24615;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.02698</link><description>&lt;p&gt;
&#36229;&#36234;&#26399;&#26395;: &#29616;&#23454;&#20013;&#23454;&#29616;&#38543;&#26426;&#20248;&#21183;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Expectations: Learning with Stochastic Dominance Made Practical
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02698
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#39318;&#27425;&#23581;&#35797;&#24314;&#31435;&#20102;&#19968;&#20010;&#38543;&#26426;&#20248;&#21183;&#23398;&#20064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#25512;&#24191;&#20102;&#38543;&#26426;&#20248;&#21183;&#30340;&#27010;&#24565;&#20197;&#20351;&#20854;&#33021;&#22815;&#22312;&#20219;&#24847;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#36827;&#34892;&#27604;&#36739;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#26469;&#22788;&#29702;&#36830;&#32493;&#24615;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#20248;&#21183;&#27169;&#22411;&#23545;&#20915;&#31574;&#26102;&#20855;&#26377;&#39118;&#38505;&#21388;&#24694;&#20559;&#22909;&#30340;&#19981;&#30830;&#23450;&#32467;&#26524;&#36827;&#34892;&#24314;&#27169;&#65292;&#30456;&#27604;&#20110;&#20165;&#20165;&#20381;&#36182;&#26399;&#26395;&#20540;&#65292;&#33258;&#28982;&#22320;&#25429;&#25417;&#20102;&#24213;&#23618;&#19981;&#30830;&#23450;&#24615;&#30340;&#20869;&#22312;&#32467;&#26500;&#12290;&#23613;&#31649;&#22312;&#29702;&#35770;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#38543;&#26426;&#20248;&#21183;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#21364;&#24456;&#23569;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#20197;&#19979;&#25361;&#25112;&#65306;$\textbf{i)}$ &#38543;&#26426;&#20248;&#21183;&#30340;&#21407;&#22987;&#27010;&#24565;&#20165;&#25552;&#20379;&#20102;$\textit{&#37096;&#20998;&#24207;}$&#65292;&#22240;&#27492;&#19981;&#33021;&#20316;&#20026;&#26368;&#20248;&#24615;&#20934;&#21017;&#65307;&#21644; $\textbf{ii)}$ &#30001;&#20110;&#35780;&#20272;&#38543;&#26426;&#20248;&#21183;&#30340;&#36830;&#32493;&#24615;&#26412;&#36136;&#65292;&#30446;&#21069;&#36824;&#32570;&#20047;&#39640;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23581;&#35797;&#24314;&#31435;&#19968;&#20010;&#19982;&#38543;&#26426;&#20248;&#21183;&#23398;&#20064;&#30456;&#20851;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#38543;&#26426;&#20248;&#21183;&#27010;&#24565;&#25512;&#24191;&#65292;&#20351;&#24471;&#20219;&#24847;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#27604;&#36739;&#25104;&#20026;&#21487;&#33021;&#12290;&#25509;&#19979;&#26469;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#35780;&#20272;&#38543;&#26426;&#20248;&#21183;&#30340;&#36830;&#32493;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic dominance models risk-averse preferences for decision making with uncertain outcomes, which naturally captures the intrinsic structure of the underlying uncertainty, in contrast to simply resorting to the expectations. Despite theoretically appealing, the application of stochastic dominance in machine learning has been scarce, due to the following challenges: $\textbf{i)}$, the original concept of stochastic dominance only provides a $\textit{partial order}$, therefore, is not amenable to serve as an optimality criterion; and $\textbf{ii)}$, an efficient computational recipe remains lacking due to the continuum nature of evaluating stochastic dominance.%, which barriers its application for machine learning.   In this work, we make the first attempt towards establishing a general framework of learning with stochastic dominance. We first generalize the stochastic dominance concept to enable feasible comparisons between any arbitrary pair of random variables. We next develop a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#30340;&#26032;&#39062;&#21644;&#32039;&#20945;&#30340;&#29305;&#24449;&#25551;&#36848;&#65292;&#36890;&#36807;&#21327;&#26041;&#24046;&#26680;&#23545;&#24212;&#30340;GP&#26679;&#26412;&#36335;&#24452;&#36798;&#21040;&#19968;&#23450;&#27491;&#21017;&#24615;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#23545;&#24120;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;GPs&#30340;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;</title><link>https://arxiv.org/abs/2312.14886</link><description>&lt;p&gt;
&#26469;&#33258;&#21327;&#26041;&#24046;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sample Path Regularity of Gaussian Processes from the Covariance Kernel
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#30340;&#26032;&#39062;&#21644;&#32039;&#20945;&#30340;&#29305;&#24449;&#25551;&#36848;&#65292;&#36890;&#36807;&#21327;&#26041;&#24046;&#26680;&#23545;&#24212;&#30340;GP&#26679;&#26412;&#36335;&#24452;&#36798;&#21040;&#19968;&#23450;&#27491;&#21017;&#24615;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#23545;&#24120;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;GPs&#30340;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26159;&#23450;&#20041;&#20989;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#26368;&#24120;&#35265;&#24418;&#24335;&#20027;&#20041;&#12290;&#23613;&#31649;GPs&#30340;&#24212;&#29992;&#24191;&#27867;&#65292;&#20294;&#23545;&#20110;GP&#26679;&#26412;&#36335;&#24452;&#30340;&#20840;&#38754;&#29702;&#35299;&#65292;&#21363;&#23427;&#20204;&#23450;&#20041;&#27010;&#29575;&#27979;&#24230;&#30340;&#20989;&#25968;&#31354;&#38388;&#65292;&#23578;&#32570;&#20047;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;GPs&#19981;&#26159;&#36890;&#36807;&#27010;&#29575;&#27979;&#24230;&#26500;&#24314;&#30340;&#65292;&#32780;&#26159;&#36890;&#36807;&#22343;&#20540;&#20989;&#25968;&#21644;&#21327;&#26041;&#24046;&#26680;&#26500;&#24314;&#30340;&#12290;&#26412;&#25991;&#38024;&#23545;&#21327;&#26041;&#24046;&#26680;&#25552;&#20379;&#20102;GP&#26679;&#26412;&#36335;&#24452;&#36798;&#21040;&#32473;&#23450;&#27491;&#21017;&#24615;&#25152;&#38656;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12290;&#25105;&#20204;&#20351;&#29992;H\"older&#27491;&#21017;&#24615;&#26694;&#26550;&#65292;&#22240;&#20026;&#23427;&#25552;&#20379;&#20102;&#29305;&#21035;&#31616;&#21333;&#30340;&#26465;&#20214;&#65292;&#22312;&#24179;&#31283;&#21644;&#21508;&#21521;&#21516;&#24615;GPs&#30340;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#31616;&#21270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#20801;&#35768;&#23545;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24120;&#29992;&#30340;GPs&#30340;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#36827;&#34892;&#26032;&#39062;&#19988;&#24322;&#24120;&#32039;&#20945;&#30340;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14886v2 Announce Type: replace  Abstract: Gaussian processes (GPs) are the most common formalism for defining probability distributions over spaces of functions. While applications of GPs are myriad, a comprehensive understanding of GP sample paths, i.e. the function spaces over which they define a probability measure, is lacking. In practice, GPs are not constructed through a probability measure, but instead through a mean function and a covariance kernel. In this paper we provide necessary and sufficient conditions on the covariance kernel for the sample paths of the corresponding GP to attain a given regularity. We use the framework of H\"older regularity as it grants particularly straightforward conditions, which simplify further in the cases of stationary and isotropic GPs. We then demonstrate that our results allow for novel and unusually tight characterisations of the sample path regularities of the GPs commonly used in machine learning applications, such as the Mat\'
&lt;/p&gt;</description></item><item><title>MFAI&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;&#26469;&#20811;&#26381;&#30001;&#20110;&#25968;&#25454;&#36136;&#37327;&#24046;&#23548;&#33268;&#30340;&#25361;&#25112;&#65292;&#20855;&#26377;&#28789;&#27963;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#23545;&#36741;&#21161;&#20449;&#24687;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2303.02566</link><description>&lt;p&gt;
MFAI:&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#26469;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
MFAI: A Scalable Bayesian Matrix Factorization Approach to Leveraging Auxiliary Information
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2303.02566
&lt;/p&gt;
&lt;p&gt;
MFAI&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;&#26469;&#20811;&#26381;&#30001;&#20110;&#25968;&#25454;&#36136;&#37327;&#24046;&#23548;&#33268;&#30340;&#25361;&#25112;&#65292;&#20855;&#26377;&#28789;&#27963;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#23545;&#36741;&#21161;&#20449;&#24687;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#22312;&#25968;&#25454;&#36136;&#37327;&#24046;&#30340;&#24773;&#20917;&#19979;&#24448;&#24448;&#34920;&#29616;&#19981;&#20339;&#65292;&#20363;&#22914;&#25968;&#25454;&#31232;&#30095;&#24615;&#39640;&#21644;&#20449;&#22122;&#27604;&#20302;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#32771;&#34385;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;&#30340;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;&#65292;&#36741;&#21161;&#20449;&#24687;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26159;&#22823;&#37327;&#21487;&#29992;&#30340;&#65292;&#20197;&#20811;&#26381;&#30001;&#20110;&#25968;&#25454;&#36136;&#37327;&#24046;&#24341;&#36215;&#30340;&#25361;&#25112;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#31616;&#21333;&#32447;&#24615;&#27169;&#22411;&#23558;&#36741;&#21161;&#20449;&#24687;&#19982;&#20027;&#25968;&#25454;&#30697;&#38453;&#32467;&#21512;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#26799;&#24230;&#22686;&#24378;&#26641;&#38598;&#25104;&#21040;&#27010;&#29575;&#30697;&#38453;&#20998;&#35299;&#26694;&#26550;&#20013;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;(MFAI)&#12290;&#22240;&#27492;&#65292;MFAI&#33258;&#28982;&#22320;&#32487;&#25215;&#20102;&#26799;&#24230;&#22686;&#24378;&#26641;&#30340;&#20960;&#20010;&#26174;&#33879;&#29305;&#28857;&#65292;&#22914;&#28789;&#27963;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#31995;&#12289;&#23545;&#36741;&#21161;&#20449;&#24687;&#20013;&#30340;&#19981;&#30456;&#20851;&#29305;&#24449;&#21644;&#32570;&#22833;&#20540;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;MFAI&#20013;&#30340;&#21442;&#25968;&#21487;&#20197;&#22312;&#32463;&#39564;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#33258;&#21160;&#30830;&#23450;&#65292;&#20351;&#20854;&#36866;&#24212;&#20110;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
In various practical situations, matrix factorization methods suffer from poor data quality, such as high data sparsity and low signal-to-noise ratio (SNR). Here, we consider a matrix factorization problem by utilizing auxiliary information, which is massively available in real-world applications, to overcome the challenges caused by poor data quality. Unlike existing methods that mainly rely on simple linear models to combine auxiliary information with the main data matrix, we propose to integrate gradient boosted trees in the probabilistic matrix factorization framework to effectively leverage auxiliary information (MFAI). Thus, MFAI naturally inherits several salient features of gradient boosted trees, such as the capability of flexibly modeling nonlinear relationships and robustness to irrelevant features and missing values in auxiliary information. The parameters in MFAI can be automatically determined under the empirical Bayes framework, making it adaptive to the utilization of a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.11143</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#30340;&#24503;&#22269;&#39640;&#20998;&#36776;&#29575;&#23460;&#20869;&#27681;&#27668;&#22320;&#22270;
&lt;/p&gt;
&lt;p&gt;
A new high-resolution indoor radon map for Germany using a machine learning based probabilistic exposure model. (arXiv:2310.11143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23460;&#20869;&#27681;&#27668;&#26159;&#19968;&#31181;&#33268;&#30284;&#30340;&#25918;&#23556;&#24615;&#27668;&#20307;&#65292;&#21487;&#20197;&#22312;&#23460;&#20869;&#31215;&#32047;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#20840;&#22269;&#33539;&#22260;&#20869;&#30340;&#23460;&#20869;&#27681;&#26292;&#38706;&#26159;&#22522;&#20110;&#24191;&#27867;&#30340;&#27979;&#37327;&#27963;&#21160;&#20272;&#35745;&#24471;&#26469;&#30340;&#12290;&#28982;&#32780;&#65292;&#26679;&#26412;&#30340;&#29305;&#24449;&#24448;&#24448;&#19982;&#20154;&#21475;&#29305;&#24449;&#19981;&#21516;&#65292;&#36825;&#26159;&#30001;&#20110;&#35768;&#22810;&#30456;&#20851;&#22240;&#32032;&#65292;&#22914;&#22320;&#36136;&#28304;&#27681;&#27668;&#30340;&#21487;&#29992;&#24615;&#25110;&#27004;&#23618;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#26679;&#26412;&#22823;&#23567;&#36890;&#24120;&#19981;&#20801;&#35768;&#20197;&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#36827;&#34892;&#26292;&#38706;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#27604;&#32431;&#25968;&#25454;&#26041;&#27861;&#26356;&#21152;&#29616;&#23454;&#22320;&#20272;&#35745;&#23460;&#20869;&#27681;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#38454;&#27573;&#24314;&#27169;&#26041;&#27861;&#65306;1&#65289;&#24212;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#65292;&#20351;&#29992;&#29615;&#22659;&#21644;&#24314;&#31569;&#25968;&#25454;&#20316;&#20026;&#39044;&#27979;&#22240;&#23376;&#65292;&#20272;&#35745;&#20102;&#24503;&#22269;&#27599;&#20010;&#20303;&#23429;&#27004;&#30340;&#27599;&#20010;&#27004;&#23618;&#30340;&#23460;&#20869;&#27681;&#27010;&#29575;&#20998;&#24067;&#20989;&#25968;&#65307;2&#65289;&#20351;&#29992;&#27010;&#29575;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#25216;&#26415;&#20351;&#23427;&#20204;&#32452;&#21512;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor radon exposure at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sample often differ from the characteristics of the population due to the large number of relevant factors such as the availability of geogenic radon or floor level. Furthermore, the sample size usually does not allow exposure estimation with high spatial resolution. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. We applied a two-stage modelling approach: 1) a quantile regression forest using environmental and building data as predictors was applied to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany; (2) a probabilistic Monte Carlo sampling technique enabled the combination and
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31561;&#21464;Transformer&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#34507;&#30333;&#36136;-&#37197;&#20307;&#23545;&#25509;&#65292;&#36890;&#36807;&#34701;&#21512;&#37197;&#20307;&#30340;&#22270;&#23618;&#29305;&#24449;&#65292;&#24182;&#20351;&#29992;TAMformer&#27169;&#22359;&#23398;&#20064;&#37197;&#20307;&#21644;&#34507;&#30333;&#36136;&#30340;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#23545;&#37197;&#20307;&#20301;&#23039;&#30340;&#20934;&#30830;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20248;&#21270;&#26041;&#27861;&#29983;&#25104;&#31934;&#28860;&#30340;&#37197;&#20307;&#20301;&#23039;&#12290;</title><link>http://arxiv.org/abs/2310.08061</link><description>&lt;p&gt;
ETDock: &#19968;&#31181;&#26032;&#39062;&#30340;&#31561;&#21464;Transformer&#29992;&#20110;&#34507;&#30333;&#36136;-&#37197;&#20307;&#23545;&#25509;
&lt;/p&gt;
&lt;p&gt;
ETDock: A Novel Equivariant Transformer for Protein-Ligand Docking. (arXiv:2310.08061v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08061
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31561;&#21464;Transformer&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#34507;&#30333;&#36136;-&#37197;&#20307;&#23545;&#25509;&#65292;&#36890;&#36807;&#34701;&#21512;&#37197;&#20307;&#30340;&#22270;&#23618;&#29305;&#24449;&#65292;&#24182;&#20351;&#29992;TAMformer&#27169;&#22359;&#23398;&#20064;&#37197;&#20307;&#21644;&#34507;&#30333;&#36136;&#30340;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#23545;&#37197;&#20307;&#20301;&#23039;&#30340;&#20934;&#30830;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20248;&#21270;&#26041;&#27861;&#29983;&#25104;&#31934;&#28860;&#30340;&#37197;&#20307;&#20301;&#23039;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#34507;&#30333;&#36136;&#21644;&#37197;&#20307;&#20043;&#38388;&#30340;&#23545;&#25509;&#26159;&#33647;&#29289;&#24320;&#21457;&#20013;&#20851;&#38190;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#23545;&#25509;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#35780;&#20998;&#20989;&#25968;&#65292;&#32780;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#23545;&#25509;&#26041;&#27861;&#36890;&#24120;&#24573;&#30053;&#20102;&#34507;&#30333;&#36136;&#21644;&#37197;&#20307;&#30340;3D&#31354;&#38388;&#20449;&#24687;&#20197;&#21450;&#37197;&#20307;&#30340;&#22270;&#23618;&#29305;&#24449;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#34507;&#30333;&#36136;-&#37197;&#20307;&#23545;&#25509;&#20301;&#23039;&#39044;&#27979;&#30340;&#31561;&#21464;Transformer&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#29305;&#24449;&#22788;&#29702;&#26469;&#34701;&#21512;&#37197;&#20307;&#30340;&#22270;&#23618;&#29305;&#24449;&#65292;&#28982;&#21518;&#20351;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;TAMformer&#27169;&#22359;&#23398;&#20064;&#37197;&#20307;&#21644;&#34507;&#30333;&#36136;&#30340;&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#39044;&#27979;&#30340;&#36317;&#31163;&#30697;&#38453;&#30340;&#36845;&#20195;&#20248;&#21270;&#26041;&#27861;&#26469;&#29983;&#25104;&#31934;&#28860;&#30340;&#37197;&#20307;&#20301;&#23039;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting the docking between proteins and ligands is a crucial and challenging task for drug discovery. However, traditional docking methods mainly rely on scoring functions, and deep learning-based docking approaches usually neglect the 3D spatial information of proteins and ligands, as well as the graph-level features of ligands, which limits their performance. To address these limitations, we propose an equivariant transformer neural network for protein-ligand docking pose prediction. Our approach involves the fusion of ligand graph-level features by feature processing, followed by the learning of ligand and protein representations using our proposed TAMformer module. Additionally, we employ an iterative optimization approach based on the predicted distance matrix to generate refined ligand poses. The experimental results on real datasets show that our model can achieve state-of-the-art performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;RemOve-And-Retrain&#65288;ROAR&#65289;&#21327;&#35758;&#30340;&#21487;&#38752;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;ROAR&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#23646;&#24615;&#21487;&#33021;&#26377;&#26356;&#23569;&#30340;&#26377;&#20851;&#20915;&#31574;&#30340;&#37325;&#35201;&#20449;&#24687;&#65292;&#36825;&#31181;&#20559;&#24046;&#31216;&#20026;&#27611;&#31961;&#24230;&#20559;&#24046;&#65292;&#24182;&#25552;&#37266;&#20154;&#20204;&#19981;&#35201;&#22312;ROAR&#25351;&#26631;&#19978;&#36827;&#34892;&#30450;&#30446;&#30340;&#20381;&#36182;&#12290;</title><link>http://arxiv.org/abs/2304.13836</link><description>&lt;p&gt;
&#35770;RemOve-And-Retrain&#30340;&#38519;&#38449;&#65306;&#25968;&#25454;&#22788;&#29702;&#19981;&#31561;&#24335;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
On Pitfalls of $\textit{RemOve-And-Retrain}$: Data Processing Inequality Perspective. (arXiv:2304.13836v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;RemOve-And-Retrain&#65288;ROAR&#65289;&#21327;&#35758;&#30340;&#21487;&#38752;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;ROAR&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#23646;&#24615;&#21487;&#33021;&#26377;&#26356;&#23569;&#30340;&#26377;&#20851;&#20915;&#31574;&#30340;&#37325;&#35201;&#20449;&#24687;&#65292;&#36825;&#31181;&#20559;&#24046;&#31216;&#20026;&#27611;&#31961;&#24230;&#20559;&#24046;&#65292;&#24182;&#25552;&#37266;&#20154;&#20204;&#19981;&#35201;&#22312;ROAR&#25351;&#26631;&#19978;&#36827;&#34892;&#30450;&#30446;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;RemOve-And-Retrain&#65288;ROAR&#65289;&#21327;&#35758;&#30340;&#21487;&#38752;&#24615;&#65292;&#35813;&#21327;&#35758;&#29992;&#20110;&#27979;&#37327;&#29305;&#24449;&#37325;&#35201;&#24615;&#20272;&#35745;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#32972;&#26223;&#21644;&#23454;&#35777;&#23454;&#39564;&#20013;&#21457;&#29616;&#65292;&#20855;&#26377;&#36739;&#23569;&#26377;&#20851;&#20915;&#31574;&#21151;&#33021;&#30340;&#20449;&#24687;&#30340;&#23646;&#24615;&#22312;ROAR&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#26356;&#22909;&#65292;&#19982;ROAR&#30340;&#21407;&#22987;&#30446;&#30340;&#30456;&#30683;&#30462;&#12290;&#36825;&#31181;&#29616;&#35937;&#20063;&#20986;&#29616;&#22312;&#26368;&#36817;&#25552;&#20986;&#30340;&#21464;&#20307;RemOve-And-Debias&#65288;ROAD&#65289;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ROAR&#24402;&#22240;&#24230;&#37327;&#20013;&#27611;&#31961;&#24230;&#20559;&#24046;&#30340;&#19968;&#33268;&#36235;&#21183;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#37266;&#20154;&#20204;&#19981;&#35201;&#30450;&#30446;&#20381;&#36182;ROAR&#30340;&#24615;&#33021;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper assesses the reliability of the RemOve-And-Retrain (ROAR) protocol, which is used to measure the performance of feature importance estimates. Our findings from the theoretical background and empirical experiments indicate that attributions that possess less information about the decision function can perform better in ROAR benchmarks, conflicting with the original purpose of ROAR. This phenomenon is also observed in the recently proposed variant RemOve-And-Debias (ROAD), and we propose a consistent trend of blurriness bias in ROAR attribution metrics. Our results caution against uncritical reliance on ROAR metrics.
&lt;/p&gt;</description></item></channel></rss>