<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;Robust Average Gradient Algorithm&#65288;RAGA&#65289;&#65292;&#26412;&#30740;&#31350;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#35299;&#20915;&#20102;&#24694;&#24847;&#25308;&#21344;&#24237;&#25915;&#20987;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#24322;&#26500;&#25968;&#25454;&#38598;&#19978;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#24182;&#23637;&#31034;&#20102;RAGA&#30340;&#33391;&#22909;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13374</link><description>&lt;p&gt;
&#20855;&#26377;&#23545;&#25968;&#25454;&#24322;&#26500;&#24615;&#30340;&#33258;&#36866;&#24212;&#30340;&#25308;&#21344;&#24237;&#24377;&#24615;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Byzantine-resilient Federated Learning With Adaptivity to Data Heterogeneity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13374
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;Robust Average Gradient Algorithm&#65288;RAGA&#65289;&#65292;&#26412;&#30740;&#31350;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#35299;&#20915;&#20102;&#24694;&#24847;&#25308;&#21344;&#24237;&#25915;&#20987;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#24322;&#26500;&#25968;&#25454;&#38598;&#19978;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#24182;&#23637;&#31034;&#20102;RAGA&#30340;&#33391;&#22909;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22788;&#29702;&#20102;&#22312;&#23384;&#22312;&#24694;&#24847;&#25308;&#21344;&#24237;&#25915;&#20987;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#30340;&#24773;&#20917;&#19979;&#30340;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#40065;&#26834;&#24179;&#22343;&#26799;&#24230;&#31639;&#27861;&#65288;RAGA&#65289;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20960;&#20309;&#20013;&#20301;&#25968;&#36827;&#34892;&#32858;&#21512;&#65292;&#24182;&#21487;&#20197;&#33258;&#30001;&#36873;&#25321;&#26412;&#22320;&#26356;&#26032;&#30340;&#36718;&#25968;&#12290;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24377;&#24615;&#26041;&#27861;&#19981;&#21516;&#65292;&#36825;&#20123;&#26041;&#27861;&#22522;&#20110;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#25110;&#22343;&#21248;&#20998;&#24067;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#25910;&#25947;&#20998;&#26512;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23545;&#24378;&#20984;&#21644;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#22312;&#24322;&#26500;&#25968;&#25454;&#38598;&#19978;&#30340;&#25910;&#25947;&#20998;&#26512;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#21482;&#35201;&#24694;&#24847;&#29992;&#25143;&#25968;&#25454;&#38598;&#30340;&#27604;&#20363;&#23567;&#20110;&#19968;&#21322;&#65292;RAGA&#23601;&#21487;&#20197;&#20197;$\mathcal{O}({1}/{T^{2/3- \delta}})$&#30340;&#36895;&#24230;&#23454;&#29616;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#25910;&#25947;&#65292;&#20854;&#20013;$T$&#20026;&#36845;&#20195;&#27425;&#25968;&#65292;$\delta \in (0, 2/3)$&#65292;&#23545;&#20110;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#21017;&#21576;&#32447;&#24615;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#31283;&#23450;&#28857;&#25110;&#20840;&#23616;&#26368;&#20248;&#35299;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13374v1 Announce Type: new  Abstract: This paper deals with federated learning (FL) in the presence of malicious Byzantine attacks and data heterogeneity. A novel Robust Average Gradient Algorithm (RAGA) is proposed, which leverages the geometric median for aggregation and can freely select the round number for local updating. Different from most existing resilient approaches, which perform convergence analysis based on strongly-convex loss function or homogeneously distributed dataset, we conduct convergence analysis for not only strongly-convex but also non-convex loss function over heterogeneous dataset. According to our theoretical analysis, as long as the fraction of dataset from malicious users is less than half, RAGA can achieve convergence at rate $\mathcal{O}({1}/{T^{2/3- \delta}})$ where $T$ is the iteration number and $\delta \in (0, 2/3)$ for non-convex loss function, and at linear rate for strongly-convex loss function. Moreover, stationary point or global optim
&lt;/p&gt;</description></item><item><title>&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23545;&#36755;&#20837;&#20013;&#20559;&#35265;&#29305;&#24449;&#19982;&#26631;&#31614;&#20043;&#38388;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#25935;&#24863;&#65292;&#26412;&#25991;&#22238;&#39038;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#26368;&#26032;&#26041;&#27861;&#65292;&#21516;&#26102;&#24635;&#32467;&#20102;&#25968;&#25454;&#38598;&#12289;&#22522;&#20934;&#21644;&#24230;&#37327;&#26631;&#20934;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.12715</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Spurious Correlations in Machine Learning: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12715
&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23545;&#36755;&#20837;&#20013;&#20559;&#35265;&#29305;&#24449;&#19982;&#26631;&#31614;&#20043;&#38388;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#25935;&#24863;&#65292;&#26412;&#25991;&#22238;&#39038;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#26368;&#26032;&#26041;&#27861;&#65292;&#21516;&#26102;&#24635;&#32467;&#20102;&#25968;&#25454;&#38598;&#12289;&#22522;&#20934;&#21644;&#24230;&#37327;&#26631;&#20934;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23545;&#36755;&#20837;&#20013;&#20559;&#35265;&#29305;&#24449;&#65288;&#20363;&#22914;&#32972;&#26223;&#12289;&#32441;&#29702;&#21644;&#27425;&#35201;&#23545;&#35937;&#65289;&#19982;&#30456;&#24212;&#26631;&#31614;&#20043;&#38388;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#25935;&#24863;&#12290;&#36825;&#20123;&#29305;&#24449;&#21450;&#20854;&#19982;&#26631;&#31614;&#30340;&#30456;&#20851;&#24615;&#34987;&#31216;&#20026;&#8220;&#34394;&#20551;&#8221;&#65292;&#22240;&#20026;&#23427;&#20204;&#24448;&#24448;&#38543;&#30528;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#32780;&#25913;&#21464;&#65292;&#36825;&#21487;&#33021;&#23545;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#40065;&#26834;&#24615;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#22312;&#36825;&#39033;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#20840;&#38754;&#23457;&#26597;&#20102;&#36825;&#19968;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#20851;&#20110;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#34394;&#20551;&#30456;&#20851;&#24615;&#30340;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#20998;&#31867;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#25968;&#25454;&#38598;&#12289;&#22522;&#20934;&#21644;&#24230;&#37327;&#26631;&#20934;&#65292;&#20197;&#24110;&#21161;&#26410;&#26469;&#30340;&#30740;&#31350;&#12290;&#26412;&#25991;&#26368;&#21518;&#35752;&#35770;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#21644;&#26410;&#26469;&#30740;&#31350;&#25361;&#25112;&#65292;&#26088;&#22312;&#20026;&#30456;&#20851;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12715v1 Announce Type: new  Abstract: Machine learning systems are known to be sensitive to spurious correlations between biased features of the inputs (e.g., background, texture, and secondary objects) and the corresponding labels. These features and their correlations with the labels are known as "spurious" because they tend to change with shifts in real-world data distributions, which can negatively impact the model's generalization and robustness. In this survey, we provide a comprehensive review of this issue, along with a taxonomy of current state-of-the-art methods for addressing spurious correlations in machine learning models. Additionally, we summarize existing datasets, benchmarks, and metrics to aid future research. The paper concludes with a discussion of the recent advancements and future research challenges in this field, aiming to provide valuable insights for researchers in the related domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.08201</link><description>&lt;p&gt;
&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation in Markov Decision Processes under Weak Distributional Overlap
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#20013;&#65292;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#22312;&#24207;&#21015;&#21487;&#24573;&#30053;&#24615;&#19979;&#23545;&#31163;&#31574;&#30053;&#35780;&#20272;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#65306;&#23427;&#20204;&#24050;&#32463;&#35777;&#26126;&#20102;&#38543;&#30528;&#26102;&#38271;T&#30340;&#25910;&#25947;&#36895;&#24230;&#20026;$1/\sqrt{T}$&#65292;&#22312;&#22823;&#26679;&#26412;&#20013;&#20855;&#26377;&#32479;&#35745;&#25928;&#29575;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#25191;&#34892;&#39044;&#20272;&#20219;&#21153;&#65292;&#20855;&#26377;&#27169;&#22359;&#21270;&#23454;&#29616;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#32467;&#26524;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20351;&#29992;&#20102;&#24378;&#20998;&#24067;&#37325;&#21472;&#20551;&#35774;&#65292;&#21363;&#30446;&#26631;&#25919;&#31574;&#21644;&#25968;&#25454;&#25910;&#38598;&#25919;&#31574;&#30340;&#31283;&#24577;&#20998;&#24067;&#30456;&#24046;&#22312;&#26377;&#38480;&#22240;&#23376;&#20869;&#65292;&#32780;&#36825;&#20010;&#20551;&#35774;&#36890;&#24120;&#21482;&#22312;MDP&#30340;&#29366;&#24577;&#31354;&#38388;&#26377;&#30028;&#26102;&#25165;&#21487;&#20449;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#22312;&#24369;&#20998;&#24067;&#37325;&#21472;&#27010;&#24565;&#19979;&#30340;MDP&#31163;&#31574;&#30053;&#35780;&#20272;&#20219;&#21153;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;&#24403;&#30446;&#26631;&#21644;&#25968;&#25454;&#25910;&#38598;&#30340;&#20998;&#24067;&#27604;&#29575;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Doubly robust methods hold considerable promise for off-policy evaluation in Markov decision processes (MDPs) under sequential ignorability: They have been shown to converge as $1/\sqrt{T}$ with the horizon $T$, to be statistically efficient in large samples, and to allow for modular implementation where preliminary estimation tasks can be executed using standard reinforcement learning techniques. Existing results, however, make heavy use of a strong distributional overlap assumption whereby the stationary distributions of the target policy and the data-collection policy are within a bounded factor of each other -- and this assumption is typically only credible when the state space of the MDP is bounded. In this paper, we re-visit the task of off-policy evaluation in MDPs under a weaker notion of distributional overlap, and introduce a class of truncated doubly robust (TDR) estimators which we find to perform well in this setting. When the distribution ratio of the target and data-coll
&lt;/p&gt;</description></item><item><title>EUGENE&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#26080;&#30417;&#30563;&#22270;&#32534;&#36753;&#36317;&#31163;&#36817;&#20284;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#29983;&#25104;&#32534;&#36753;&#36335;&#24452;&#26469;&#36817;&#20284;&#35745;&#31639;&#22270;&#32534;&#36753;&#36317;&#31163;&#65292;&#21516;&#26102;&#28040;&#38500;&#20102;ground-truth&#29983;&#25104;&#21644;&#25968;&#25454;&#29305;&#23450;&#35757;&#32451;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.05885</link><description>&lt;p&gt;
EUGENE: &#21487;&#35299;&#37322;&#30340;&#26080;&#30417;&#30563;&#22270;&#32534;&#36753;&#36317;&#31163;&#36817;&#20284;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
EUGENE: Explainable Unsupervised Approximation of Graph Edit Distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05885
&lt;/p&gt;
&lt;p&gt;
EUGENE&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#26080;&#30417;&#30563;&#22270;&#32534;&#36753;&#36317;&#31163;&#36817;&#20284;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#29983;&#25104;&#32534;&#36753;&#36335;&#24452;&#26469;&#36817;&#20284;&#35745;&#31639;&#22270;&#32534;&#36753;&#36317;&#31163;&#65292;&#21516;&#26102;&#28040;&#38500;&#20102;ground-truth&#29983;&#25104;&#21644;&#25968;&#25454;&#29305;&#23450;&#35757;&#32451;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#29289;&#23398;&#12289;&#21270;&#23398;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#31561;&#39046;&#22495;&#65292;&#38656;&#35201;&#35782;&#21035;&#19982;&#26597;&#35810;&#22270;&#32467;&#26500;&#36317;&#31163;&#36739;&#23567;&#30340;&#22270;&#24418;&#12290;&#22312;&#22810;&#31181;&#27979;&#37327;&#22270;&#38388;&#36317;&#31163;&#30340;&#26041;&#27861;&#20013;&#65292;&#22270;&#32534;&#36753;&#36317;&#31163;&#65288;GED&#65289;&#22240;&#20854;&#21487;&#29702;&#35299;&#24615;&#32780;&#34987;&#35748;&#20026;&#26159;&#39318;&#36873;&#65292;&#20294;&#20854;&#35745;&#31639;&#30340;NP&#38590;&#24230;&#38480;&#21046;&#20102;&#20854;&#24212;&#29992;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;GED&#36817;&#20284;&#26041;&#27861;&#20027;&#35201;&#37319;&#29992;&#31070;&#32463;&#26041;&#27861;&#65292;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#65288;i&#65289;&#32570;&#23569;&#19982;&#36817;&#20284;&#30340;GED&#23545;&#24212;&#30340;&#35299;&#37322;&#24615;&#32534;&#36753;&#36335;&#24452;&#65307;&#65288;ii&#65289;&#38656;&#35201;&#36890;&#36807;NP&#38590;&#38382;&#39064;&#29983;&#25104;ground-truth GED&#36827;&#34892;&#35757;&#32451;&#65307;&#65288;iii&#65289;&#38656;&#35201;&#22312;&#27599;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#29420;&#31435;&#35757;&#32451;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20195;&#25968;&#26080;&#30417;&#30563;&#26041;&#27861;EUGENE&#65292;&#23427;&#36817;&#20284;&#35745;&#31639;GED&#24182;&#29983;&#25104;&#19982;&#36817;&#20284;&#25104;&#26412;&#23545;&#24212;&#30340;&#32534;&#36753;&#36335;&#24452;&#65292;&#21516;&#26102;&#28040;&#38500;&#20102;&#29983;&#25104;ground-truth&#21644;&#25968;&#25454;&#29305;&#23450;&#35757;&#32451;&#30340;&#38656;&#27714;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;&#65292;EUGENE&#30340;&#19978;&#36848;&#20248;&#28857;&#24182;&#19981;&#20197;&#25928;&#21147;&#20026;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
The need to identify graphs having small structural distance from a query arises in biology, chemistry, recommender systems, and social network analysis. Among several methods to measure inter graph distance, Graph Edit Distance (GED) is preferred for its comprehensibility, yet hindered by the NP-hardness of its computation. State-of-the-art GED approximations predominantly employ neural methods, which, however, (i) lack an explanatory edit path corresponding to the approximated GED; (ii) require the NP-hard generation of ground-truth GEDs for training; and (iii) necessitate separate training on each dataset. In this paper, we propose an efficient algebraic unsuper vised method, EUGENE, that approximates GED and yields edit paths corresponding to the approx imated cost, while eliminating the need for ground truth generation and data-specific training. Extensive experimental evaluation demonstrates that the aforementioned benefits of EUGENE do not come at the cost of efficacy. Specifica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#36880;&#27493;&#21487;&#25512;&#24191;&#30340;&#20934;&#21017;&#65292;&#29992;&#20110;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#35782;&#21035;&#21644;&#20998;&#31867;&#19981;&#21516;&#24418;&#24335;&#30340;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#12290;&#36890;&#36807;&#23545;&#31181;&#26063;&#20027;&#20041;&#30340;&#27010;&#24565;&#21270;&#21644;&#19978;&#19979;&#25991;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;XLM-R&#21644;XLM-R-Racismo&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#31181;&#26063;&#20027;&#20041;&#20998;&#31867;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.09333</link><description>&lt;p&gt;
&#26426;&#22120;&#33021;&#22815;&#30475;&#21040;&#39068;&#33394;&#65306;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#20998;&#31867;&#19981;&#21516;&#24418;&#24335;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#30340;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Machines Do See Color: A Guideline to Classify Different Forms of Racist Discourse in Large Corpora. (arXiv:2401.09333v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09333
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#36880;&#27493;&#21487;&#25512;&#24191;&#30340;&#20934;&#21017;&#65292;&#29992;&#20110;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#35782;&#21035;&#21644;&#20998;&#31867;&#19981;&#21516;&#24418;&#24335;&#30340;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#12290;&#36890;&#36807;&#23545;&#31181;&#26063;&#20027;&#20041;&#30340;&#27010;&#24565;&#21270;&#21644;&#19978;&#19979;&#25991;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;XLM-R&#21644;XLM-R-Racismo&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#31181;&#26063;&#20027;&#20041;&#20998;&#31867;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#35782;&#21035;&#21644;&#20998;&#31867;&#25991;&#26412;&#20013;&#30340;&#31181;&#26063;&#20027;&#20041;&#35821;&#35328;&#30340;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#23567;&#35268;&#27169;&#30340;&#36136;&#24615;&#26041;&#27861;&#25110;&#22823;&#35268;&#27169;&#30340;&#26041;&#27861;&#65292;&#19987;&#27880;&#20110;&#26126;&#26174;&#30340;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#36880;&#27493;&#21487;&#25512;&#24191;&#30340;&#20934;&#21017;&#65292;&#29992;&#20110;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#35782;&#21035;&#21644;&#20998;&#31867;&#19981;&#21516;&#24418;&#24335;&#30340;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#31181;&#26063;&#20027;&#20041;&#21450;&#20854;&#19981;&#21516;&#34920;&#29616;&#24418;&#24335;&#36827;&#34892;&#27010;&#24565;&#21270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#31181;&#26063;&#20027;&#20041;&#34920;&#29616;&#24418;&#24335;&#32622;&#20110;&#24863;&#20852;&#36259;&#30340;&#26102;&#38388;&#21644;&#22320;&#28857;&#32972;&#26223;&#19979;&#65292;&#20197;&#20415;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#35782;&#21035;&#23427;&#20204;&#30340;&#35805;&#35821;&#24418;&#24335;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;XLM-RoBERTa&#65288;XLM-R&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#20808;&#36827;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#30340;&#36328;&#35821;&#35328;&#30417;&#30563;&#25991;&#26412;&#20998;&#31867;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;XLM-R&#21644;XLM-R-Racismo&#65288;&#25105;&#20204;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#65289;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#23545;&#31181;&#26063;&#20027;&#20041;&#36827;&#34892;&#20998;&#31867;&#30340;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#28041;&#21450;2018&#24180;&#33267;2021&#24180;&#21380;&#29916;&#22810;&#23572;&#26412;&#22303;&#32676;&#20307;&#30340;&#25512;&#25991;&#35821;&#26009;&#24211;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current methods to identify and classify racist language in text rely on small-n qualitative approaches or large-n approaches focusing exclusively on overt forms of racist discourse. This article provides a step-by-step generalizable guideline to identify and classify different forms of racist discourse in large corpora. In our approach, we start by conceptualizing racism and its different manifestations. We then contextualize these racist manifestations to the time and place of interest, which allows researchers to identify their discursive form. Finally, we apply XLM-RoBERTa (XLM-R), a cross-lingual model for supervised text classification with a cutting-edge contextual understanding of text. We show that XLM-R and XLM-R-Racismo, our pretrained model, outperform other state-of-the-art approaches in classifying racism in large corpora. We illustrate our approach using a corpus of tweets relating to the Ecuadorian ind\'igena community between 2018 and 2021.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#31526;&#21495;&#21270;&#27169;&#20223;&#23398;&#20064;&#65288;SIL&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#24402;&#32435;&#36923;&#36753;&#32534;&#31243;&#65288;ILP&#65289;&#26469;&#23398;&#20064;&#20174;&#29616;&#26377;&#25968;&#25454;&#38598;&#20013;&#33719;&#21462;&#36879;&#26126;&#12289;&#21487;&#35299;&#37322;&#21644;&#27867;&#21270;&#30340;&#39550;&#39542;&#31574;&#30053;&#12290;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#30456;&#27604;&#65292;SIL&#19981;&#20165;&#25552;&#39640;&#20102;&#39550;&#39542;&#31574;&#30053;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#36824;&#26174;&#33879;&#25913;&#36827;&#20102;&#23427;&#20204;&#22312;&#21508;&#31181;&#39550;&#39542;&#24773;&#20917;&#19979;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.16025</link><description>&lt;p&gt;
&#31526;&#21495;&#21270;&#27169;&#20223;&#23398;&#20064;&#65306;&#20174;&#40657;&#30418;&#21040;&#21487;&#35299;&#37322;&#30340;&#39550;&#39542;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies. (arXiv:2309.16025v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#31526;&#21495;&#21270;&#27169;&#20223;&#23398;&#20064;&#65288;SIL&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#24402;&#32435;&#36923;&#36753;&#32534;&#31243;&#65288;ILP&#65289;&#26469;&#23398;&#20064;&#20174;&#29616;&#26377;&#25968;&#25454;&#38598;&#20013;&#33719;&#21462;&#36879;&#26126;&#12289;&#21487;&#35299;&#37322;&#21644;&#27867;&#21270;&#30340;&#39550;&#39542;&#31574;&#30053;&#12290;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#30456;&#27604;&#65292;SIL&#19981;&#20165;&#25552;&#39640;&#20102;&#39550;&#39542;&#31574;&#30053;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#36824;&#26174;&#33879;&#25913;&#36827;&#20102;&#23427;&#20204;&#22312;&#21508;&#31181;&#39550;&#39542;&#24773;&#20917;&#19979;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#20027;&#35201;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20379;&#20102;&#20174;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#33719;&#21462;&#39550;&#39542;&#31574;&#30053;&#30340;&#26377;&#25928;&#25163;&#27573;&#65292;&#20294;&#22312;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#26041;&#38754;&#23384;&#22312;&#26174;&#33879;&#23616;&#38480;&#24615;&#12290;&#36825;&#20123;&#32570;&#28857;&#22312;&#33258;&#21160;&#39550;&#39542;&#31561;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#23588;&#20026;&#20196;&#20154;&#25285;&#24551;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#31526;&#21495;&#21270;&#27169;&#20223;&#23398;&#20064;&#65288;SIL&#65289;&#65292;&#19968;&#31181;&#20351;&#29992;&#24402;&#32435;&#36923;&#36753;&#32534;&#31243;&#65288;ILP&#65289;&#23398;&#20064;&#20174;&#21487;&#29992;&#25968;&#25454;&#38598;&#20013;&#33719;&#21462;&#36879;&#26126;&#12289;&#21487;&#35299;&#37322;&#21644;&#27867;&#21270;&#30340;&#39550;&#39542;&#31574;&#30053;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#26469;&#35299;&#20915;&#36825;&#20123;&#23616;&#38480;&#24615;&#12290;&#21033;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;highD&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#27604;&#36739;&#20998;&#26512;&#65292;&#19982;&#24403;&#21069;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;SIL&#19981;&#20165;&#25552;&#39640;&#20102;&#39550;&#39542;&#31574;&#30053;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#36824;&#26174;&#33879;&#25552;&#39640;&#20102;&#23427;&#20204;&#22312;&#21508;&#31181;&#39550;&#39542;&#24773;&#20917;&#19979;&#30340;&#36866;&#29992;&#24615;&#12290;&#22240;&#27492;&#65292;&#36825;&#39033;&#24037;&#20316;&#20026;&#23454;&#29616;&#26356;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#39550;&#39542;&#31574;&#30053;&#25171;&#24320;&#20102;&#19968;&#26465;&#26032;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current methods of imitation learning (IL), primarily based on deep neural networks, offer efficient means for obtaining driving policies from real-world data but suffer from significant limitations in interpretability and generalizability. These shortcomings are particularly concerning in safety-critical applications like autonomous driving. In this paper, we address these limitations by introducing Symbolic Imitation Learning (SIL), a groundbreaking method that employs Inductive Logic Programming (ILP) to learn driving policies which are transparent, explainable and generalisable from available datasets. Utilizing the real-world highD dataset, we subject our method to a rigorous comparative analysis against prevailing neural-network-based IL methods. Our results demonstrate that SIL not only enhances the interpretability of driving policies but also significantly improves their applicability across varied driving situations. Hence, this work offers a novel pathway to more reliable an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24352;&#37327;&#22238;&#24402;&#36827;&#34892;&#23569;&#26679;&#26412;&#20010;&#24615;&#21270;&#26174;&#33879;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#20197;&#20445;&#30041;&#20010;&#24615;&#21270;&#26174;&#33879;&#24615;&#22270;&#30340;&#32467;&#26500;&#20840;&#23616;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2307.02799</link><description>&lt;p&gt;
&#29992;&#24352;&#37327;&#22238;&#24402;&#36827;&#34892;&#23569;&#26679;&#26412;&#20010;&#24615;&#21270;&#26174;&#33879;&#24615;&#39044;&#27979;&#65292;&#20445;&#30041;&#32467;&#26500;&#20840;&#23616;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Few-Shot Personalized Saliency Prediction Using Tensor Regression for Preserving Structural Global Information. (arXiv:2307.02799v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02799
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24352;&#37327;&#22238;&#24402;&#36827;&#34892;&#23569;&#26679;&#26412;&#20010;&#24615;&#21270;&#26174;&#33879;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#20197;&#20445;&#30041;&#20010;&#24615;&#21270;&#26174;&#33879;&#24615;&#22270;&#30340;&#32467;&#26500;&#20840;&#23616;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24352;&#37327;&#21040;&#30697;&#38453;&#22238;&#24402;&#36827;&#34892;&#23569;&#26679;&#26412;&#20010;&#24615;&#21270;&#26174;&#33879;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#20197;&#20445;&#30041;&#20010;&#24615;&#21270;&#26174;&#33879;&#24615;&#22270;&#65288;PSM&#65289;&#30340;&#32467;&#26500;&#20840;&#23616;&#20449;&#24687;&#12290;&#19982;&#19968;&#33324;&#30340;&#26174;&#33879;&#24615;&#22270;&#30456;&#27604;&#65292;PSM&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#22240;&#20026;&#23427;&#30340;&#26144;&#23556;&#25351;&#31034;&#20102;&#20010;&#20307;&#29305;&#23450;&#30340;&#35270;&#35273;&#27880;&#24847;&#21147;&#65292;&#23545;&#20110;&#20174;&#20957;&#35270;&#21306;&#22495;&#30340;&#24322;&#36136;&#24615;&#20013;&#33719;&#21462;&#20010;&#20307;&#35270;&#35273;&#20559;&#22909;&#38750;&#24120;&#26377;&#29992;&#12290;PSM&#30340;&#39044;&#27979;&#26159;&#20026;&#20102;&#33719;&#21462;&#26410;&#35265;&#22270;&#20687;&#30340;PSM&#65292;&#20294;&#30001;&#20110;&#20010;&#20307;&#20957;&#35270;&#27169;&#24335;&#30340;&#22797;&#26434;&#24615;&#65292;&#20854;&#39044;&#27979;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20026;&#20102;&#20174;&#26377;&#38480;&#30340;&#30524;&#21160;&#25968;&#25454;&#20013;&#35782;&#21035;&#20010;&#20307;&#20957;&#35270;&#27169;&#24335;&#65292;&#20808;&#21069;&#30340;&#26041;&#27861;&#37319;&#29992;&#20010;&#20307;&#20043;&#38388;&#20957;&#35270;&#36235;&#21183;&#30340;&#30456;&#20284;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#20808;&#21069;&#30340;&#26041;&#27861;&#20013;&#65292;PSMs&#34987;&#21521;&#37327;&#21270;&#20197;&#36866;&#24212;&#39044;&#27979;&#27169;&#22411;&#65292;&#20174;&#32780;&#24573;&#35270;&#20102;&#19982;&#22270;&#20687;&#23545;&#24212;&#30340;PSMs&#30340;&#32467;&#26500;&#20840;&#23616;&#20449;&#24687;&#12290;&#20026;&#20102;&#33258;&#21160;&#25581;&#31034;PSMs&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;...
&lt;/p&gt;
&lt;p&gt;
This paper presents a few-shot personalized saliency prediction using tensor-to-matrix regression for preserving the structural global information of personalized saliency maps (PSMs). In contrast to a general saliency map, a PSM has been great potential since its map indicates the person-specific visual attention that is useful for obtaining individual visual preferences from heterogeneity of gazed areas. The PSM prediction is needed for acquiring the PSM for the unseen image, but its prediction is still a challenging task due to the complexity of individual gaze patterns. For recognizing individual gaze patterns from the limited amount of eye-tracking data, the previous methods adopt the similarity of gaze tendency between persons. However, in the previous methods, the PSMs are vectorized for the prediction model. In this way, the structural global information of the PSMs corresponding to the image is ignored. For automatically revealing the relationship between PSMs, we focus on the
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#30340;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#23427;&#25552;&#20379;&#20102;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#26159;&#21487;&#34892;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.01449</link><description>&lt;p&gt;
&#23558;&#23454;&#39564;&#25968;&#25454;&#19982;&#35266;&#27979;&#25968;&#25454;&#32467;&#21512;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Double Machine Learning Approach to Combining Experimental and Observational Data. (arXiv:2307.01449v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01449
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#30340;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#23427;&#25552;&#20379;&#20102;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#36890;&#24120;&#30001;&#20110;&#26080;&#27861;&#27979;&#35797;&#30340;&#20551;&#35774;&#32780;&#32570;&#20047;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#20351;&#20174;&#19994;&#20154;&#21592;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#36739;&#36731;&#30340;&#20551;&#35774;&#19979;&#27979;&#35797;&#22806;&#37096;&#25928;&#24230;&#21644;&#21487;&#24573;&#35270;&#24615;&#30340;&#36829;&#21453;&#24773;&#20917;&#12290;&#24403;&#21482;&#26377;&#19968;&#20010;&#20551;&#35774;&#34987;&#36829;&#21453;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#24378;&#35843;&#20102;&#20934;&#30830;&#35782;&#21035;&#36829;&#21453;&#30340;&#20551;&#35774;&#23545;&#19968;&#33268;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#30340;&#24517;&#35201;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#19977;&#20010;&#23454;&#38469;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#20854;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Experimental and observational studies often lack validity due to untestable assumptions. We propose a double machine learning approach to combine experimental and observational studies, allowing practitioners to test for assumption violations and estimate treatment effects consistently. Our framework tests for violations of external validity and ignorability under milder assumptions. When only one assumption is violated, we provide semi-parametrically efficient treatment effect estimators. However, our no-free-lunch theorem highlights the necessity of accurately identifying the violated assumption for consistent treatment effect estimation. We demonstrate the applicability of our approach in three real-world case studies, highlighting its relevance for practical settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20855;&#26377;&#38750;&#30697;&#24418;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#24378;&#20581;MDP&#30340;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#25237;&#23556;Langevin&#21160;&#21147;&#23398;&#31639;&#27861;&#21644;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#12290;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.19004</link><description>&lt;p&gt;
&#38750;&#30697;&#24418;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#24378;&#20581;MDP&#30340;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Algorithms for Robust MDPs with Non-Rectangular Uncertainty Sets. (arXiv:2305.19004v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19004
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20855;&#26377;&#38750;&#30697;&#24418;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#24378;&#20581;MDP&#30340;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#25237;&#23556;Langevin&#21160;&#21147;&#23398;&#31639;&#27861;&#21644;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#12290;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#20855;&#26377;&#38750;&#30697;&#24418;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#24378;&#20581;&#26080;&#38480;&#26102;&#22495;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#24378;&#20581;MDP&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#24615;&#25361;&#25112;&#12290;&#30830;&#23454;&#65292;&#26174;&#31034;&#32479;&#35745;&#26368;&#20248;&#24615;&#36136;&#24182;&#20805;&#20998;&#21033;&#29992;&#26377;&#38480;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#24448;&#24448;&#19981;&#26159;&#30697;&#24418;&#30340;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#23545;&#24212;&#30340;&#24378;&#20581;MDPs&#19981;&#33021;&#29992;&#21160;&#24577;&#35268;&#21010;&#25216;&#26415;&#35299;&#20915;&#65292;&#24182;&#19988;&#23454;&#38469;&#19978;&#26159;&#21487;&#35777;&#26126;&#30340;&#19981;&#21487;&#35299;&#20915;&#30340;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#24320;&#21457;&#19968;&#20010;&#38024;&#23545;&#24378;&#20581;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#37327;&#36523;&#23450;&#21046;&#30340;&#25237;&#23556;Langevin&#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#25552;&#20379;&#20840;&#23616;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36817;&#20284;&#35299;&#20915;&#20102;&#24378;&#20581;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#36817;&#20284;&#35823;&#24046;&#19982;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#38750;&#30697;&#24418;&#24230;&#37327;&#25104;&#27604;&#20363;&#12290;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#25237;&#24433;Langevin&#21160;&#21147;&#23398;&#31639;&#27861;&#21487;&#20197;&#36991;&#20813;&#23616;&#37096;&#26368;&#20248;&#65292;&#32780;&#31639;&#27861;&#26159;&#37327;&#36523;&#23450;&#21046;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a policy gradient algorithm for robust infinite-horizon Markov Decision Processes (MDPs) with non-rectangular uncertainty sets, thereby addressing an open challenge in the robust MDP literature. Indeed, uncertainty sets that display statistical optimality properties and make optimal use of limited data often fail to be rectangular. Unfortunately, the corresponding robust MDPs cannot be solved with dynamic programming techniques and are in fact provably intractable. This prompts us to develop a projected Langevin dynamics algorithm tailored to the robust policy evaluation problem, which offers global optimality guarantees. We also propose a deterministic policy gradient method that solves the robust policy evaluation problem approximately, and we prove that the approximation error scales with a new measure of non-rectangularity of the uncertainty set. Numerical experiments showcase that our projected Langevin dynamics algorithm can escape local optima, while algorithms tailor
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#65292;&#21487;&#20197;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20294;&#38656;&#35201;&#27491;&#30830;&#20351;&#29992;&#27491;&#21017;&#21270;&#25216;&#26415;&#20197;&#36991;&#20813;&#27425;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2211.13723</link><description>&lt;p&gt;
&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#26469;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improving Multi-task Learning via Seeking Task-based Flat Regions. (arXiv:2211.13723v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13723
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#65292;&#21487;&#20197;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20294;&#38656;&#35201;&#27491;&#30830;&#20351;&#29992;&#27491;&#21017;&#21270;&#25216;&#26415;&#20197;&#36991;&#20813;&#27425;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#19988;&#24378;&#22823;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#29992;&#20110;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#36890;&#36807;&#21333;&#20010;&#39592;&#24178;&#23398;&#20064;&#22810;&#20010;&#30446;&#26631;&#12290;&#19982;&#21333;&#29420;&#35757;&#32451;&#20219;&#21153;&#30456;&#27604;&#65292;MTL&#26174;&#30528;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#26469;&#28508;&#22312;&#22320;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#23427;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#39046;&#22495;&#65292;&#20174;&#35745;&#31639;&#26426;&#35270;&#35273;&#21040;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35821;&#38899;&#35782;&#21035;&#12290;&#20854;&#20013;&#65292;MTL&#30340;&#19968;&#20010;&#26032;&#20852;&#30740;&#31350;&#26041;&#21521;&#38598;&#20013;&#22312;&#25805;&#32437;&#20219;&#21153;&#26799;&#24230;&#20197;&#25512;&#23548;&#20986;&#23545;&#25152;&#26377;&#20219;&#21153;&#26377;&#30410;&#30340;&#26368;&#32456;&#26799;&#24230;&#19979;&#38477;&#26041;&#21521;&#12290;&#23613;&#31649;&#22312;&#35768;&#22810;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#20294;&#26159;&#22312;&#23454;&#38469;&#38382;&#39064;&#19978;&#30452;&#25509;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;&#32780;&#19981;&#20351;&#29992;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#35299;&#12290;&#29305;&#21035;&#26159;&#65292;&#26631;&#20934;&#35757;&#32451;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#26368;&#23567;&#21270;&#32463;&#39564;&#25439;&#22833;&#65292;&#24456;&#23481;&#26131;&#36973;&#21463;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-Task Learning (MTL) is a widely-used and powerful learning paradigm for training deep neural networks that allows learning more than one objective by a single backbone. Compared to training tasks separately, MTL significantly reduces computational costs, improves data efficiency, and potentially enhances model performance by leveraging knowledge across tasks. Hence, it has been adopted in a variety of applications, ranging from computer vision to natural language processing and speech recognition. Among them, there is an emerging line of work in MTL that focuses on manipulating the task gradient to derive an ultimate gradient descent direction to benefit all tasks. Despite achieving impressive results on many benchmarks, directly applying these approaches without using appropriate regularization techniques might lead to suboptimal solutions on real-world problems. In particular, standard training that minimizes the empirical loss on the training data can easily suffer from overfi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#20445;&#35777;&#30340;&#26174;&#24335;&#20108;&#38454;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#20985;&#26080;&#32422;&#26463;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20108;&#38454;&#20449;&#24687;&#21152;&#36895;&#39069;&#22806;&#26799;&#24230;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#36845;&#20195;&#36807;&#31243;&#20013;&#20445;&#25345;&#22312;&#26377;&#30028;&#38598;&#20869;&#65292;&#36798;&#21040;&#20102;&#19982;&#29702;&#35770;&#19979;&#30028;&#30456;&#21305;&#37197;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2210.12860</link><description>&lt;p&gt;
&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#20445;&#35777;&#30340;&#26174;&#24335;&#20108;&#38454;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Explicit Second-Order Min-Max Optimization Methods with Optimal Convergence Guarantee. (arXiv:2210.12860v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#20445;&#35777;&#30340;&#26174;&#24335;&#20108;&#38454;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#20985;&#26080;&#32422;&#26463;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20108;&#38454;&#20449;&#24687;&#21152;&#36895;&#39069;&#22806;&#26799;&#24230;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#36845;&#20195;&#36807;&#31243;&#20013;&#20445;&#25345;&#22312;&#26377;&#30028;&#38598;&#20869;&#65292;&#36798;&#21040;&#20102;&#19982;&#29702;&#35770;&#19979;&#30028;&#30456;&#21305;&#37197;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#31934;&#30830;&#21644;&#19981;&#31934;&#30830;&#27491;&#21017;&#21270;&#29275;&#39039;&#22411;&#26041;&#27861;&#65292;&#29992;&#20110;&#27714;&#35299;&#20984;&#20985;&#26080;&#32422;&#26463;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#38382;&#39064;&#30340;&#20840;&#23616;&#38797;&#28857;&#12290;&#19982;&#19968;&#38454;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#23545;&#20110;&#20108;&#38454;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#26041;&#27861;&#30340;&#29702;&#35299;&#30456;&#23545;&#36739;&#23569;&#65292;&#22240;&#20026;&#21033;&#29992;&#20108;&#38454;&#20449;&#24687;&#33719;&#24471;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;&#26356;&#21152;&#22797;&#26434;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#20108;&#38454;&#20449;&#24687;&#21152;&#36895;&#39069;&#22806;&#26799;&#24230;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#19981;&#31934;&#30830;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#23454;&#29616;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#29983;&#25104;&#30340;&#36845;&#20195;&#20445;&#25345;&#22312;&#26377;&#30028;&#38598;&#20869;&#65292;&#24182;&#19988;&#24179;&#22343;&#36845;&#20195;&#25910;&#25947;&#21040;&#19968;&#20010; $\epsilon$-&#38797;&#28857;&#65292;&#25152;&#38656;&#36845;&#20195;&#27425;&#25968;&#20026; $O(\epsilon^{-2/3})$&#65292;&#20854;&#20013;&#20351;&#29992;&#20102;&#21463;&#38480;&#38388;&#38553;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#19982;&#35813;&#39046;&#22495;&#24050;&#32463;&#24314;&#31435;&#30340;&#29702;&#35770;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#32780;&#19988;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#30452;&#35266;&#30340;&#20108;&#38454;&#26041;&#27861;&#25910;&#25947;&#20998;&#26512;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#26377;&#30028;&#24615;&#35201;&#27714;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;
&lt;/p&gt;
&lt;p&gt;
We propose and analyze exact and inexact regularized Newton-type methods for finding a global saddle point of \emph{convex-concave} unconstrained min-max optimization problems. Compared to first-order methods, our understanding of second-order methods for min-max optimization is relatively limited, as obtaining global rates of convergence with second-order information is much more involved. In this paper, we examine how second-order information can be used to speed up extra-gradient methods, even under inexactness. Specifically, we show that the proposed algorithms generate iterates that remain within a bounded set and the averaged iterates converge to an $\epsilon$-saddle point within $O(\epsilon^{-2/3})$ iterations in terms of a restricted gap function. Our algorithms match the theoretically established lower bound in this context and our analysis provides a simple and intuitive convergence analysis for second-order methods without any boundedness requirements. Finally, we present a 
&lt;/p&gt;</description></item><item><title>TabText&#26159;&#19968;&#31181;&#22788;&#29702;&#21644;&#29305;&#24449;&#25552;&#21462;&#26694;&#26550;&#65292;&#36890;&#36807;&#36716;&#25442;&#20869;&#23481;&#20026;&#35821;&#35328;&#24182;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20174;&#34920;&#26684;&#25968;&#25454;&#20013;&#25552;&#21462;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#36890;&#36807;&#24212;&#29992;TabText&#26694;&#26550;&#21487;&#20197;&#29983;&#25104;&#39640;&#24615;&#33021;&#19988;&#31616;&#21333;&#30340;&#26426;&#22120;&#23398;&#20064;&#22522;&#20934;&#27169;&#22411;&#65292;&#20943;&#23569;&#25968;&#25454;&#39044;&#22788;&#29702;&#30340;&#24037;&#20316;&#37327;&#12290;&#35813;&#26694;&#26550;&#22312;&#21307;&#30103;&#39044;&#27979;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2206.10381</link><description>&lt;p&gt;
TabText:&#19968;&#31181;&#28789;&#27963;&#21644;&#19978;&#19979;&#25991;&#21270;&#30340;&#34920;&#26684;&#25968;&#25454;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
TabText: A Flexible and Contextual Approach to Tabular Data Representation. (arXiv:2206.10381v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10381
&lt;/p&gt;
&lt;p&gt;
TabText&#26159;&#19968;&#31181;&#22788;&#29702;&#21644;&#29305;&#24449;&#25552;&#21462;&#26694;&#26550;&#65292;&#36890;&#36807;&#36716;&#25442;&#20869;&#23481;&#20026;&#35821;&#35328;&#24182;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20174;&#34920;&#26684;&#25968;&#25454;&#20013;&#25552;&#21462;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#36890;&#36807;&#24212;&#29992;TabText&#26694;&#26550;&#21487;&#20197;&#29983;&#25104;&#39640;&#24615;&#33021;&#19988;&#31616;&#21333;&#30340;&#26426;&#22120;&#23398;&#20064;&#22522;&#20934;&#27169;&#22411;&#65292;&#20943;&#23569;&#25968;&#25454;&#39044;&#22788;&#29702;&#30340;&#24037;&#20316;&#37327;&#12290;&#35813;&#26694;&#26550;&#22312;&#21307;&#30103;&#39044;&#27979;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#23545;&#20110;&#22312;&#21508;&#20010;&#34892;&#19994;&#20013;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#24182;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;&#34920;&#26684;&#20013;&#25152;&#26377;&#21487;&#29992;&#30340;&#20449;&#24687;&#65292;&#24573;&#35270;&#20102;&#37325;&#35201;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#22914;&#21015;&#26631;&#39064;&#25551;&#36848;&#12290;&#27492;&#22806;&#65292;&#23558;&#25968;&#25454;&#39044;&#22788;&#29702;&#25104;&#34920;&#26684;&#26684;&#24335;&#20173;&#28982;&#26159;&#27169;&#22411;&#24320;&#21457;&#20013;&#19968;&#39033;&#32791;&#26102;&#30340;&#29942;&#39048;&#12290;&#26412;&#24037;&#20316;&#24341;&#20837;&#20102;TabText&#65292;&#19968;&#31181;&#22788;&#29702;&#21644;&#29305;&#24449;&#25552;&#21462;&#26694;&#26550;&#65292;&#23558;&#19978;&#19979;&#25991;&#20449;&#24687;&#20174;&#34920;&#26684;&#25968;&#25454;&#32467;&#26500;&#20013;&#25552;&#21462;&#20986;&#26469;&#12290;TabText&#36890;&#36807;&#23558;&#20869;&#23481;&#36716;&#25442;&#20026;&#35821;&#35328;&#65292;&#24182;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26469;&#35299;&#20915;&#22788;&#29702;&#22256;&#38590;&#12290;&#25105;&#20204;&#22312;&#28085;&#30422;&#24739;&#32773;&#20986;&#38498;&#12289;ICU&#20837;&#38498;&#21644;&#27515;&#20129;&#31561;&#20061;&#20010;&#21307;&#30103;&#39044;&#27979;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65306;1) &#24212;&#29992;&#25105;&#20204;&#30340;TabText&#26694;&#26550;&#21487;&#20197;&#29983;&#25104;&#24615;&#33021;&#20248;&#31168;&#19988;&#31616;&#21333;&#30340;&#26426;&#22120;&#23398;&#20064;&#22522;&#20934;&#27169;&#22411;&#65292;&#21482;&#38656;&#26368;&#23569;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#65307;2) &#22686;&#24378;&#39044;&#22788;&#29702;&#21518;&#30340;&#25968;&#25454;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#25552;&#21319;&#27169;&#22411;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Tabular data is essential for applying machine learning tasks across various industries. However, traditional data processing methods do not fully utilize all the information available in the tables, ignoring important contextual information such as column header descriptions. In addition, pre-processing data into a tabular format can remain a labor-intensive bottleneck in model development. This work introduces TabText, a processing and feature extraction framework that extracts contextual information from tabular data structures. TabText addresses processing difficulties by converting the content into language and utilizing pre-trained large language models (LLMs). We evaluate our framework on nine healthcare prediction tasks ranging from patient discharge, ICU admission, and mortality. We show that 1) applying our TabText framework enables the generation of high-performing and simple machine learning baseline models with minimal data pre-processing, and 2) augmenting pre-processed t
&lt;/p&gt;</description></item></channel></rss>