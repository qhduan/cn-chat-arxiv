<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36890;&#36807;&#25552;&#20986;&#30340;Hessian-free&#22312;&#32447;&#36951;&#24536;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#36817;&#20046;&#30636;&#26102;&#30340;&#22312;&#32447;&#36951;&#24536;&#65292;&#20165;&#38656;&#35201;&#36827;&#34892;&#30690;&#37327;&#21152;&#27861;&#25805;&#20316;&#12290;</title><link>https://arxiv.org/abs/2404.01712</link><description>&lt;p&gt;
&#36890;&#36807;&#20813;Hessian&#37325;&#26032;&#25972;&#21512;&#20010;&#20307;&#25968;&#25454;&#32479;&#35745;&#23454;&#29616;&#39640;&#25928;&#22312;&#32447;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Efficient Online Unlearning via Hessian-Free Recollection of Individual Data Statistics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01712
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#30340;Hessian-free&#22312;&#32447;&#36951;&#24536;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#36817;&#20046;&#30636;&#26102;&#30340;&#22312;&#32447;&#36951;&#24536;&#65292;&#20165;&#38656;&#35201;&#36827;&#34892;&#30690;&#37327;&#21152;&#27861;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#36951;&#24536;&#26088;&#22312;&#36890;&#36807;&#20351;&#27169;&#22411;&#33021;&#22815;&#36873;&#25321;&#24615;&#22320;&#24536;&#35760;&#29305;&#23450;&#25968;&#25454;&#26469;&#32500;&#25252;&#25968;&#25454;&#25152;&#26377;&#32773;&#30340;&#34987;&#36951;&#24536;&#26435;&#21033;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#34920;&#26126;&#65292;&#19968;&#31181;&#25968;&#25454;&#36951;&#24536;&#30340;&#26041;&#27861;&#26159;&#36890;&#36807;&#39044;&#20808;&#35745;&#31639;&#21644;&#23384;&#20648;&#25658;&#24102;&#20108;&#38454;&#20449;&#24687;&#30340;&#32479;&#35745;&#25968;&#25454;&#65292;&#20197;&#25913;&#36827;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#20381;&#36182;&#20110;&#33499;&#21051;&#30340;&#20551;&#35774;&#65292;&#32780;&#19988;&#35745;&#31639;/&#23384;&#20648;&#21463;&#21040;&#27169;&#22411;&#21442;&#25968;&#32500;&#24230;&#30340;&#35781;&#21650;&#65292;&#36825;&#20351;&#24471;&#38590;&#20197;&#24212;&#29992;&#21040;&#22823;&#22810;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20813;Hessian&#22312;&#32447;&#36951;&#24536;&#26041;&#27861;&#12290;&#25105;&#20204;&#24314;&#35758;&#20026;&#27599;&#20010;&#25968;&#25454;&#28857;&#32500;&#25252;&#19968;&#20010;&#32479;&#35745;&#21521;&#37327;&#65292;&#36890;&#36807;&#37325;&#26032;&#35757;&#32451;&#21644;&#23398;&#20064;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#20223;&#23556;&#38543;&#26426;&#36882;&#24402;&#36924;&#36817;&#26469;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#36817;&#20046;&#30636;&#26102;&#30340;&#22312;&#32447;&#36951;&#24536;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#36827;&#34892;&#30690;&#37327;&#21152;&#27861;&#25805;&#20316;&#12290;&#22522;&#20110;&#37325;&#26032;&#25910;&#38598;&#36951;&#24536;&#25968;&#25454;&#32479;&#35745;&#30340;&#31574;&#30053;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01712v1 Announce Type: cross  Abstract: Machine unlearning strives to uphold the data owners' right to be forgotten by enabling models to selectively forget specific data. Recent methods suggest that one approach of data forgetting is by precomputing and storing statistics carrying second-order information to improve computational and memory efficiency. However, they rely on restrictive assumptions and the computation/storage suffer from the curse of model parameter dimensionality, making it challenging to apply to most deep neural networks. In this work, we propose a Hessian-free online unlearning method. We propose to maintain a statistical vector for each data point, computed through affine stochastic recursion approximation of the difference between retrained and learned models. Our proposed algorithm achieves near-instantaneous online unlearning as it only requires a vector addition operation. Based on the strategy that recollecting statistics for forgetting data, the p
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;MATS-Gym&#65292;&#19968;&#20010;&#29992;&#20110;&#22312;CARLA&#20013;&#35757;&#32451;&#26234;&#33021;&#20307;&#30340;&#22810;&#26234;&#33021;&#20307;&#20132;&#36890;&#22330;&#26223;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#21160;&#29983;&#25104;&#20855;&#26377;&#21487;&#21464;&#26234;&#33021;&#20307;&#25968;&#37327;&#30340;&#20132;&#36890;&#22330;&#26223;&#24182;&#25972;&#21512;&#20102;&#21508;&#31181;&#29616;&#26377;&#30340;&#20132;&#36890;&#22330;&#26223;&#25551;&#36848;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.17805</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#33258;&#20027;&#39550;&#39542;&#22330;&#26223;&#39537;&#21160;&#30340;&#35838;&#31243;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17805
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;MATS-Gym&#65292;&#19968;&#20010;&#29992;&#20110;&#22312;CARLA&#20013;&#35757;&#32451;&#26234;&#33021;&#20307;&#30340;&#22810;&#26234;&#33021;&#20307;&#20132;&#36890;&#22330;&#26223;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#21160;&#29983;&#25104;&#20855;&#26377;&#21487;&#21464;&#26234;&#33021;&#20307;&#25968;&#37327;&#30340;&#20132;&#36890;&#22330;&#26223;&#24182;&#25972;&#21512;&#20102;&#21508;&#31181;&#29616;&#26377;&#30340;&#20132;&#36890;&#22330;&#26223;&#25551;&#36848;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26679;&#21270;&#21644;&#22797;&#26434;&#35757;&#32451;&#22330;&#26223;&#30340;&#33258;&#21160;&#21270;&#29983;&#25104;&#22312;&#35768;&#22810;&#22797;&#26434;&#23398;&#20064;&#20219;&#21153;&#20013;&#26159;&#37325;&#35201;&#30340;&#12290;&#29305;&#21035;&#26159;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#39046;&#22495;&#65292;&#22914;&#33258;&#20027;&#39550;&#39542;&#65292;&#33258;&#21160;&#29983;&#25104;&#35838;&#31243;&#34987;&#35748;&#20026;&#23545;&#33719;&#24471;&#24378;&#20581;&#21644;&#36890;&#29992;&#31574;&#30053;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#20805;&#28385;&#25361;&#25112;&#30340;&#20223;&#30495;&#29615;&#22659;&#20013;&#65292;&#20026;&#20132;&#36890;&#22330;&#26223;&#20013;&#30340;&#22810;&#20010;&#24322;&#26500;&#26234;&#33021;&#20307;&#36827;&#34892;&#35774;&#35745;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19968;&#39033;&#32321;&#29712;&#19988;&#32791;&#26102;&#30340;&#20219;&#21153;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MATS-Gym&#65292;&#19968;&#20010;&#29992;&#20110;&#22312;&#39640;&#20445;&#30495;&#39550;&#39542;&#27169;&#25311;&#22120;CARLA&#20013;&#35757;&#32451;&#26234;&#33021;&#20307;&#30340;&#22810;&#26234;&#33021;&#20307;&#20132;&#36890;&#22330;&#26223;&#26694;&#26550;&#12290;MATS-Gym&#26159;&#19968;&#20010;&#29992;&#20110;&#33258;&#20027;&#39550;&#39542;&#30340;&#22810;&#26234;&#33021;&#20307;&#35757;&#32451;&#26694;&#26550;&#65292;&#20351;&#29992;&#37096;&#20998;&#22330;&#26223;&#35268;&#33539;&#29983;&#25104;&#20855;&#26377;&#21487;&#21464;&#26234;&#33021;&#20307;&#25968;&#37327;&#30340;&#20132;&#36890;&#22330;&#26223;&#12290;&#36825;&#31687;&#35770;&#25991;&#23558;&#21508;&#31181;&#29616;&#26377;&#30340;&#20132;&#36890;&#22330;&#26223;&#25551;&#36848;&#26041;&#27861;&#32479;&#19968;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#35757;&#32451;&#26694;&#26550;&#20013;&#65292;&#24182;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#19982;&#20854;&#20182;&#33258;&#20027;&#39550;&#39542;&#31639;&#27861;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17805v1 Announce Type: cross  Abstract: The automated generation of diverse and complex training scenarios has been an important ingredient in many complex learning tasks. Especially in real-world application domains, such as autonomous driving, auto-curriculum generation is considered vital for obtaining robust and general policies. However, crafting traffic scenarios with multiple, heterogeneous agents is typically considered as a tedious and time-consuming task, especially in more complex simulation environments. In our work, we introduce MATS-Gym, a Multi-Agent Traffic Scenario framework to train agents in CARLA, a high-fidelity driving simulator. MATS-Gym is a multi-agent training framework for autonomous driving that uses partial scenario specifications to generate traffic scenarios with variable numbers of agents. This paper unifies various existing approaches to traffic scenario description into a single training framework and demonstrates how it can be integrated wi
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23558;&#27169;&#22411;&#20998;&#21306;&#21040;&#19981;&#21516;GPU&#19978;&#65292;&#24182;&#29983;&#25104;&#21512;&#25104;&#20013;&#38388;&#26631;&#31614;&#26469;&#35757;&#32451;&#21508;&#20010;&#37096;&#20998;&#30340;&#26041;&#27861;&#65292;&#20197;&#32531;&#35299;&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#21387;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.11204</link><description>&lt;p&gt;
&#36890;&#36807;&#21512;&#25104;&#20013;&#38388;&#26631;&#31614;&#36827;&#34892;&#20998;&#21306;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Partitioned Neural Network Training via Synthetic Intermediate Labels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11204
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23558;&#27169;&#22411;&#20998;&#21306;&#21040;&#19981;&#21516;GPU&#19978;&#65292;&#24182;&#29983;&#25104;&#21512;&#25104;&#20013;&#38388;&#26631;&#31614;&#26469;&#35757;&#32451;&#21508;&#20010;&#37096;&#20998;&#30340;&#26041;&#27861;&#65292;&#20197;&#32531;&#35299;&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#21387;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#26222;&#21450;&#65292;&#29305;&#21035;&#26159;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#23545;&#36164;&#28304;&#23494;&#38598;&#22411;&#35757;&#32451;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290; GPU &#20869;&#23384;&#32422;&#26463;&#24050;&#32463;&#25104;&#20026;&#35757;&#32451;&#36825;&#20123;&#24222;&#22823;&#27169;&#22411;&#30340;&#19968;&#20010;&#26126;&#26174;&#29942;&#39048;&#12290;&#29616;&#26377;&#31574;&#30053;&#65292;&#21253;&#25324;&#25968;&#25454;&#24182;&#34892;&#12289;&#27169;&#22411;&#24182;&#34892;&#12289;&#27969;&#27700;&#32447;&#24182;&#34892;&#21644;&#23436;&#20840;&#20998;&#29255;&#25968;&#25454;&#24182;&#34892;&#65292;&#25552;&#20379;&#20102;&#37096;&#20998;&#35299;&#20915;&#26041;&#26696;&#12290; &#29305;&#21035;&#26159;&#27169;&#22411;&#24182;&#34892;&#20801;&#35768;&#23558;&#25972;&#20010;&#27169;&#22411;&#20998;&#24067;&#22312;&#22810;&#20010; GPU &#19978;&#65292;&#20294;&#38543;&#21518;&#30340;&#36825;&#20123;&#20998;&#21306;&#20043;&#38388;&#30340;&#25968;&#25454;&#36890;&#20449;&#20943;&#24930;&#20102;&#35757;&#32451;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#20026;&#22312;&#27599;&#20010; GPU &#19978;&#23384;&#20648;&#36741;&#21161;&#21442;&#25968;&#25152;&#38656;&#30340;&#22823;&#37327;&#20869;&#23384;&#24320;&#38144;&#22686;&#21152;&#20102;&#35745;&#31639;&#38656;&#27714;&#12290; &#26412;&#30740;&#31350;&#20027;&#24352;&#19981;&#20351;&#29992;&#25972;&#20010;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;&#26159;&#23558;&#27169;&#22411;&#20998;&#21306;&#21040; GPU &#19978;&#65292;&#24182;&#29983;&#25104;&#21512;&#25104;&#20013;&#38388;&#26631;&#31614;&#26469;&#35757;&#32451;&#21508;&#20010;&#37096;&#20998;&#12290; &#36890;&#36807;&#38543;&#26426;&#36807;&#31243;&#29983;&#25104;&#30340;&#36825;&#20123;&#26631;&#31614;&#20943;&#32531;&#20102;&#35757;&#32451;&#20013;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#21387;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11204v1 Announce Type: cross  Abstract: The proliferation of extensive neural network architectures, particularly deep learning models, presents a challenge in terms of resource-intensive training. GPU memory constraints have become a notable bottleneck in training such sizable models. Existing strategies, including data parallelism, model parallelism, pipeline parallelism, and fully sharded data parallelism, offer partial solutions. Model parallelism, in particular, enables the distribution of the entire model across multiple GPUs, yet the ensuing data communication between these partitions slows down training. Additionally, the substantial memory overhead required to store auxiliary parameters on each GPU compounds computational demands. Instead of using the entire model for training, this study advocates partitioning the model across GPUs and generating synthetic intermediate labels to train individual segments. These labels, produced through a random process, mitigate me
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#32771;&#34385;&#20102;&#22312;&#26082;&#26377;&#30495;&#23454;&#19987;&#23478;&#21448;&#26377;&#23545;&#25239;&#24615;&#19987;&#23478;&#30340;&#24773;&#20917;&#19979;&#30340;&#20108;&#20803;&#20915;&#31574;&#32858;&#21512;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#35774;&#35745;&#40065;&#26834;&#32858;&#21512;&#22120;&#20197;&#26368;&#23567;&#21270;&#36951;&#25022;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#30495;&#23454;&#19987;&#23478;&#26159;&#23545;&#31216;&#30340;&#19988;&#23545;&#25239;&#24615;&#19987;&#23478;&#19981;&#22826;&#22810;&#26102;&#65292;&#25130;&#23614;&#22343;&#20540;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.08222</link><description>&lt;p&gt;
&#20855;&#26377;&#23545;&#25239;&#24615;&#19987;&#23478;&#30340;&#40065;&#26834;&#20915;&#31574;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Robust Decision Aggregation with Adversarial Experts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08222
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#32771;&#34385;&#20102;&#22312;&#26082;&#26377;&#30495;&#23454;&#19987;&#23478;&#21448;&#26377;&#23545;&#25239;&#24615;&#19987;&#23478;&#30340;&#24773;&#20917;&#19979;&#30340;&#20108;&#20803;&#20915;&#31574;&#32858;&#21512;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#35774;&#35745;&#40065;&#26834;&#32858;&#21512;&#22120;&#20197;&#26368;&#23567;&#21270;&#36951;&#25022;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#30495;&#23454;&#19987;&#23478;&#26159;&#23545;&#31216;&#30340;&#19988;&#23545;&#25239;&#24615;&#19987;&#23478;&#19981;&#22826;&#22810;&#26102;&#65292;&#25130;&#23614;&#22343;&#20540;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#26082;&#26377;&#30495;&#23454;&#19987;&#23478;&#21448;&#26377;&#23545;&#25239;&#24615;&#19987;&#23478;&#30340;&#24773;&#20917;&#19979;&#30340;&#20108;&#20803;&#20915;&#31574;&#32858;&#21512;&#38382;&#39064;&#12290;&#30495;&#23454;&#19987;&#23478;&#23558;&#20250;&#22914;&#23454;&#25253;&#21578;&#20182;&#20204;&#30340;&#31169;&#20154;&#20449;&#21495;&#65292;&#24182;&#33719;&#24471;&#36866;&#24403;&#30340;&#28608;&#21169;&#65292;&#32780;&#23545;&#25239;&#24615;&#19987;&#23478;&#21487;&#20197;&#20219;&#24847;&#25253;&#21578;&#12290;&#20915;&#31574;&#32773;&#38656;&#35201;&#35774;&#35745;&#19968;&#20010;&#40065;&#26834;&#30340;&#32858;&#21512;&#22120;&#65292;&#26681;&#25454;&#19987;&#23478;&#30340;&#25253;&#21578;&#26469;&#39044;&#27979;&#19990;&#30028;&#30340;&#30495;&#23454;&#29366;&#24577;&#12290;&#20915;&#31574;&#32773;&#19981;&#20102;&#35299;&#20855;&#20307;&#30340;&#20449;&#24687;&#32467;&#26500;&#65292;&#21363;&#20449;&#21495;&#12289;&#29366;&#24577;&#20197;&#21450;&#23545;&#25239;&#24615;&#19987;&#23478;&#30340;&#31574;&#30053;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#25105;&#20204;&#24076;&#26395;&#25214;&#21040;&#22312;&#26368;&#22351;&#20449;&#24687;&#32467;&#26500;&#19979;&#26368;&#23567;&#21270;&#36951;&#25022;&#30340;&#26368;&#20248;&#32858;&#21512;&#22120;&#12290;&#36951;&#25022;&#34987;&#23450;&#20041;&#20026;&#32858;&#21512;&#22120;&#21644;&#19968;&#20010;&#22522;&#20934;&#20043;&#38388;&#30340;&#26399;&#26395;&#25439;&#22833;&#24046;&#65292;&#35813;&#22522;&#20934;&#26681;&#25454;&#32852;&#21512;&#20998;&#24067;&#21644;&#30495;&#23454;&#19987;&#23478;&#30340;&#25253;&#21578;&#20570;&#20986;&#26368;&#20248;&#20915;&#31574;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#30495;&#23454;&#19987;&#23478;&#26159;&#23545;&#31216;&#30340;&#19988;&#23545;&#25239;&#24615;&#19987;&#23478;&#19981;&#22826;&#22810;&#26102;&#65292;&#25130;&#23614;&#22343;&#20540;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08222v1 Announce Type: cross  Abstract: We consider a binary decision aggregation problem in the presence of both truthful and adversarial experts. The truthful experts will report their private signals truthfully with proper incentive, while the adversarial experts can report arbitrarily. The decision maker needs to design a robust aggregator to forecast the true state of the world based on the reports of experts. The decision maker does not know the specific information structure, which is a joint distribution of signals, states, and strategies of adversarial experts. We want to find the optimal aggregator minimizing regret under the worst information structure. The regret is defined by the difference in expected loss between the aggregator and a benchmark who makes the optimal decision given the joint distribution and reports of truthful experts.   We prove that when the truthful experts are symmetric and adversarial experts are not too numerous, the truncated mean is opt
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26680;&#20989;&#25968;&#30340;&#24555;&#36895;&#36941;&#21382;&#25628;&#32034;&#26041;&#27861;&#65292;&#20854;&#22312;&#25628;&#32034;&#31354;&#38388;&#32500;&#24230;&#19978;&#20855;&#26377;&#32447;&#24615;&#22797;&#26434;&#24230;&#65292;&#21487;&#20197;&#25512;&#24191;&#21040;&#26446;&#32676;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27979;&#35797;&#23637;&#31034;&#27604;&#29616;&#26377;&#31639;&#27861;&#24555;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>https://arxiv.org/abs/2403.01536</link><description>&lt;p&gt;
&#20351;&#29992;&#26680;&#20989;&#25968;&#30340;&#24555;&#36895;&#36941;&#21382;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Fast Ergodic Search with Kernel Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01536
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26680;&#20989;&#25968;&#30340;&#24555;&#36895;&#36941;&#21382;&#25628;&#32034;&#26041;&#27861;&#65292;&#20854;&#22312;&#25628;&#32034;&#31354;&#38388;&#32500;&#24230;&#19978;&#20855;&#26377;&#32447;&#24615;&#22797;&#26434;&#24230;&#65292;&#21487;&#20197;&#25512;&#24191;&#21040;&#26446;&#32676;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27979;&#35797;&#23637;&#31034;&#27604;&#29616;&#26377;&#31639;&#27861;&#24555;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36941;&#21382;&#25628;&#32034;&#20351;&#24471;&#23545;&#20449;&#24687;&#20998;&#24067;&#36827;&#34892;&#26368;&#20339;&#25506;&#32034;&#25104;&#20026;&#21487;&#33021;&#65292;&#21516;&#26102;&#20445;&#35777;&#20102;&#23545;&#25628;&#32034;&#31354;&#38388;&#30340;&#28176;&#36817;&#35206;&#30422;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#22312;&#25628;&#32034;&#31354;&#38388;&#32500;&#24230;&#19978;&#20855;&#26377;&#25351;&#25968;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#23616;&#38480;&#20110;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#36941;&#21382;&#25628;&#32034;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#21452;&#37325;&#30340;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#26680;&#30340;&#36941;&#21382;&#24230;&#37327;&#65292;&#24182;&#23558;&#20854;&#20174;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#25512;&#24191;&#21040;&#26446;&#32676;&#19978;&#12290;&#25105;&#20204;&#27491;&#24335;&#35777;&#26126;&#20102;&#25152;&#24314;&#35758;&#30340;&#24230;&#37327;&#19982;&#26631;&#20934;&#36941;&#21382;&#24230;&#37327;&#19968;&#33268;&#65292;&#21516;&#26102;&#20445;&#35777;&#20102;&#22312;&#25628;&#32034;&#31354;&#38388;&#32500;&#24230;&#19978;&#20855;&#26377;&#32447;&#24615;&#22797;&#26434;&#24230;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#26680;&#36941;&#21382;&#24230;&#37327;&#30340;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#65292;&#36825;&#20351;&#24471;&#36712;&#36857;&#20248;&#21270;&#21464;&#24471;&#26356;&#21152;&#39640;&#25928;&#12290;&#20840;&#38754;&#30340;&#25968;&#20540;&#22522;&#20934;&#27979;&#35797;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33267;&#23569;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#24555;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01536v1 Announce Type: cross  Abstract: Ergodic search enables optimal exploration of an information distribution while guaranteeing the asymptotic coverage of the search space. However, current methods typically have exponential computation complexity in the search space dimension and are restricted to Euclidean space. We introduce a computationally efficient ergodic search method. Our contributions are two-fold. First, we develop a kernel-based ergodic metric and generalize it from Euclidean space to Lie groups. We formally prove the proposed metric is consistent with the standard ergodic metric while guaranteeing linear complexity in the search space dimension. Secondly, we derive the first-order optimality condition of the kernel ergodic metric for nonlinear systems, which enables efficient trajectory optimization. Comprehensive numerical benchmarks show that the proposed method is at least two orders of magnitude faster than the state-of-the-art algorithm. Finally, we d
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;EBBS&#65292;&#37197;&#21512;&#26032;&#39062;&#30340;&#21452;&#23618;&#26463;&#25628;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#20248;&#20110;&#30452;&#25509;&#21644;&#36890;&#36807;&#31532;&#19977;&#35821;&#35328;&#36827;&#34892;&#30340;&#32763;&#35793;&#65292;&#24182;&#23454;&#29616;&#30693;&#35782;&#33976;&#39311;&#26469;&#25552;&#39640;&#25512;&#29702;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.00144</link><description>&lt;p&gt;
EBBS: &#19968;&#20010;&#20855;&#26377;&#21452;&#23618;&#26463;&#25628;&#32034;&#30340;&#38598;&#25104;&#26041;&#27861;&#29992;&#20110;&#38646;&#32763;&#35793;&#26426;&#22120;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00144
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;EBBS&#65292;&#37197;&#21512;&#26032;&#39062;&#30340;&#21452;&#23618;&#26463;&#25628;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#20248;&#20110;&#30452;&#25509;&#21644;&#36890;&#36807;&#31532;&#19977;&#35821;&#35328;&#36827;&#34892;&#30340;&#32763;&#35793;&#65292;&#24182;&#23454;&#29616;&#30693;&#35782;&#33976;&#39311;&#26469;&#25552;&#39640;&#25512;&#29702;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#25105;&#20204;&#29992;&#29305;&#23450;&#30340;&#32763;&#35793;&#26041;&#21521;&#35757;&#32451;&#22810;&#35821;&#35328;&#27169;&#22411;&#26102;&#65292;&#38646;&#32763;&#35793;&#30340;&#33021;&#21147;&#23601;&#20250;&#20986;&#29616;&#65307;&#27169;&#22411;&#21487;&#20197;&#30452;&#25509;&#22312;&#26410;&#35265;&#36807;&#30340;&#26041;&#21521;&#36827;&#34892;&#32763;&#35793;&#12290;&#21478;&#22806;&#65292;&#38646;&#32763;&#35793;&#20063;&#21487;&#20197;&#36890;&#36807;&#31532;&#19977;&#31181;&#35821;&#35328;&#65288;&#20363;&#22914;&#33521;&#35821;&#65289;&#26469;&#23454;&#29616;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#30452;&#25509;&#21644;&#36890;&#36807;&#31532;&#19977;&#31181;&#35821;&#35328;&#36827;&#34892;&#30340;&#32763;&#35793;&#37117;&#23384;&#22312;&#22122;&#38899;&#65292;&#24182;&#19988;&#34920;&#29616;&#19981;&#23613;&#22914;&#20154;&#24847;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;EBBS&#65292;&#19968;&#20010;&#20855;&#26377;&#26032;&#39062;&#30340;&#21452;&#23618;&#26463;&#25628;&#32034;&#31639;&#27861;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#20854;&#20013;&#27599;&#20010;&#38598;&#25104;&#32452;&#20214;&#22312;&#19979;&#23618;&#36880;&#27493;&#25506;&#32034;&#33258;&#24049;&#30340;&#39044;&#27979;&#65292;&#20294;&#23427;&#20204;&#36890;&#36807;&#19978;&#23618;&#30340;&#8220;&#36719;&#25237;&#31080;&#8221;&#26426;&#21046;&#36827;&#34892;&#21516;&#27493;&#12290;&#22312;&#20004;&#20010;&#27969;&#34892;&#30340;&#22810;&#35821;&#35328;&#32763;&#35793;&#25968;&#25454;&#38598;&#19978;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;EBBS&#22987;&#32456;&#20248;&#20110;&#30452;&#25509;&#21644;&#36890;&#36807;&#31532;&#19977;&#31181;&#35821;&#35328;&#36827;&#34892;&#30340;&#32763;&#35793;&#65292;&#20197;&#21450;&#29616;&#26377;&#30340;&#38598;&#25104;&#25216;&#26415;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#38598;&#25104;&#30340;&#30693;&#35782;&#20256;&#22238;&#21040;&#22810;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20197;&#25552;&#39640;&#25512;&#29702;&#25928;&#29575;&#65307;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;E
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00144v1 Announce Type: cross  Abstract: The ability of zero-shot translation emerges when we train a multilingual model with certain translation directions; the model can then directly translate in unseen directions. Alternatively, zero-shot translation can be accomplished by pivoting through a third language (e.g., English). In our work, we observe that both direct and pivot translations are noisy and achieve less satisfactory performance. We propose EBBS, an ensemble method with a novel bi-level beam search algorithm, where each ensemble component explores its own prediction step by step at the lower level but they are synchronized by a "soft voting" mechanism at the upper level. Results on two popular multilingual translation datasets show that EBBS consistently outperforms direct and pivot translations as well as existing ensemble techniques. Further, we can distill the ensemble's knowledge back to the multilingual model to improve inference efficiency; profoundly, our E
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;IPRO&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#20998;&#35299;&#20219;&#21153;&#20026;&#19968;&#31995;&#21015;&#21333;&#30446;&#26631;&#38382;&#39064;&#26041;&#27861;&#65292;&#21487;&#21487;&#38752;&#22320;&#25581;&#31034;&#22810;&#30446;&#26631;&#24378;&#21270;&#23398;&#20064;&#20013;&#23454;&#29616;&#26368;&#20248;&#34920;&#29616;&#30340;&#31574;&#30053;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#65292;&#21516;&#26102;&#25552;&#20379;&#25910;&#25947;&#20445;&#35777;&#21644;&#26410;&#21457;&#29616;&#35299;&#30340;&#36317;&#31163;&#19978;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.07182</link><description>&lt;p&gt;
&#20998;&#32780;&#27835;&#20043;&#65306;&#29992;&#22810;&#30446;&#26631;&#24378;&#21270;&#23398;&#20064;&#21487;&#38752;&#22320;&#25581;&#31034;&#24085;&#32047;&#25176;&#21069;&#27839;
&lt;/p&gt;
&lt;p&gt;
Divide and Conquer: Provably Unveiling the Pareto Front with Multi-Objective Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07182
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;IPRO&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#20998;&#35299;&#20219;&#21153;&#20026;&#19968;&#31995;&#21015;&#21333;&#30446;&#26631;&#38382;&#39064;&#26041;&#27861;&#65292;&#21487;&#21487;&#38752;&#22320;&#25581;&#31034;&#22810;&#30446;&#26631;&#24378;&#21270;&#23398;&#20064;&#20013;&#23454;&#29616;&#26368;&#20248;&#34920;&#29616;&#30340;&#31574;&#30053;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#65292;&#21516;&#26102;&#25552;&#20379;&#25910;&#25947;&#20445;&#35777;&#21644;&#26410;&#21457;&#29616;&#35299;&#30340;&#36317;&#31163;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#30446;&#26631;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#33719;&#21462;&#22312;&#19981;&#21516;&#20559;&#22909;&#19979;&#23454;&#29616;&#26368;&#20248;&#34920;&#29616;&#30340;&#31574;&#30053;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#36845;&#20195;&#24085;&#32047;&#25176;&#21442;&#32771;&#20248;&#21270;&#65288;IPRO&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#21407;&#21017;&#24615;&#31639;&#27861;&#65292;&#23427;&#23558;&#25214;&#21040;&#24085;&#32047;&#25176;&#21069;&#27839;&#30340;&#20219;&#21153;&#20998;&#35299;&#25104;&#19968;&#31995;&#21015;&#20855;&#26377;&#21508;&#31181;&#35299;&#20915;&#26041;&#27861;&#30340;&#21333;&#30446;&#26631;&#38382;&#39064;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#27599;&#20010;&#27493;&#39588;&#20013;&#24314;&#31435;&#25910;&#25947;&#20445;&#35777;&#24182;&#25552;&#20379;&#26410;&#21457;&#29616;&#24085;&#32047;&#25176;&#26368;&#20248;&#35299;&#30340;&#36317;&#31163;&#19978;&#38480;&#12290;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;IPRO&#33021;&#22815;&#19982;&#38656;&#35201;&#39069;&#22806;&#39046;&#22495;&#30693;&#35782;&#30340;&#26041;&#27861;&#30456;&#21305;&#37197;&#25110;&#20248;&#20110;&#23427;&#20204;&#12290;&#36890;&#36807;&#21033;&#29992;&#38382;&#39064;&#29305;&#23450;&#30340;&#21333;&#30446;&#26631;&#27714;&#35299;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#26377;&#26395;&#22312;&#22810;&#30446;&#26631;&#24378;&#21270;&#23398;&#20064;&#20043;&#22806;&#30340;&#24212;&#29992;&#20013;&#21457;&#25381;&#20316;&#29992;&#65292;&#27604;&#22914;&#36335;&#24452;&#35268;&#21010;&#21644;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A significant challenge in multi-objective reinforcement learning is obtaining a Pareto front of policies that attain optimal performance under different preferences. We introduce Iterated Pareto Referent Optimisation (IPRO), a principled algorithm that decomposes the task of finding the Pareto front into a sequence of single-objective problems for which various solution methods exist. This enables us to establish convergence guarantees while providing an upper bound on the distance to undiscovered Pareto optimal solutions at each step. Empirical evaluations demonstrate that IPRO matches or outperforms methods that require additional domain knowledge. By leveraging problem-specific single-objective solvers, our approach also holds promise for applications beyond multi-objective reinforcement learning, such as in pathfinding and optimisation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20110;TD&#23398;&#20064;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.15719</link><description>&lt;p&gt;
&#20851;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#21450;&#20854;&#22312;TD&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Rates of Convergence in the Central Limit Theorem for Markov Chains, with an Application to TD Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20110;TD&#23398;&#20064;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;Stein&#26041;&#27861;&#35777;&#26126;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#30340;&#12289;&#30690;&#37327;&#20540;&#38789;&#24046;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#21033;&#29992;&#27850;&#26494;&#26041;&#31243;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#20989;&#25968;&#12290;&#28982;&#21518;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#24212;&#29992;&#20110;&#24314;&#31435;&#22522;&#20110;&#24179;&#22343;&#30340;&#38750;&#28176;&#36817;&#30340;TD&#23398;&#20064;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a non-asymptotic central limit theorem for vector-valued martingale differences using Stein's method, and use Poisson's equation to extend the result to functions of Markov Chains. We then show that these results can be applied to establish a non-asymptotic central limit theorem for Temporal Difference (TD) learning with averaging.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25351;&#20986;&#65292;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#38500;&#20102;&#34920;&#36798;&#24615;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#65292;&#21487;&#22788;&#29702;&#24615;&#20063;&#36215;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#30001;&#20110;&#31163;&#32447;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#21644;&#29615;&#22659;&#21160;&#24577;&#30340;&#38543;&#26426;&#24615;&#65292;&#38656;&#35201;&#31934;&#30830;&#19988;&#39640;&#25928;&#22320;&#22238;&#31572;&#21508;&#31181;&#27010;&#29575;&#26597;&#35810;&#65292;&#20197;&#25214;&#21040;&#26377;&#22870;&#21169;&#30340;&#21160;&#20316;&#12290;&#22522;&#20110;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;Trifle&#65288;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#21487;&#22788;&#29702;&#25512;&#29702;&#65289;&#26041;&#27861;&#65292;&#21033;&#29992;&#29616;&#20195;&#21487;&#22788;&#29702;&#27010;&#29575;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.00094</link><description>&lt;p&gt;
&#34920;&#36798;&#24314;&#27169;&#23545;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#19981;&#36275;&#65306;&#21487;&#22788;&#29702;&#30340;&#25512;&#29702;&#35282;&#24230;
&lt;/p&gt;
&lt;p&gt;
Expressive Modeling Is Insufficient for Offline RL: A Tractable Inference Perspective. (arXiv:2311.00094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25351;&#20986;&#65292;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#38500;&#20102;&#34920;&#36798;&#24615;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#65292;&#21487;&#22788;&#29702;&#24615;&#20063;&#36215;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#30001;&#20110;&#31163;&#32447;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#21644;&#29615;&#22659;&#21160;&#24577;&#30340;&#38543;&#26426;&#24615;&#65292;&#38656;&#35201;&#31934;&#30830;&#19988;&#39640;&#25928;&#22320;&#22238;&#31572;&#21508;&#31181;&#27010;&#29575;&#26597;&#35810;&#65292;&#20197;&#25214;&#21040;&#26377;&#22870;&#21169;&#30340;&#21160;&#20316;&#12290;&#22522;&#20110;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;Trifle&#65288;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#21487;&#22788;&#29702;&#25512;&#29702;&#65289;&#26041;&#27861;&#65292;&#21033;&#29992;&#29616;&#20195;&#21487;&#22788;&#29702;&#27010;&#29575;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#19968;&#31181;&#27969;&#34892;&#30340;&#33539;&#20363;&#26159;&#20808;&#23558;&#31163;&#32447;&#36712;&#36857;&#25311;&#21512;&#21040;&#19968;&#20010;&#24207;&#21015;&#27169;&#22411;&#20013;&#65292;&#28982;&#21518;&#36890;&#36807;&#35813;&#27169;&#22411;&#25552;&#31034;&#39640;&#26399;&#26395;&#22238;&#25253;&#30340;&#21160;&#20316;&#12290;&#34429;&#28982;&#26222;&#36941;&#35748;&#20026;&#34920;&#36798;&#24615;&#26356;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#21487;&#20197;&#24102;&#26469;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#26412;&#25991;&#24378;&#35843;&#20102;&#21487;&#22788;&#29702;&#24615;&#65292;&#21363;&#31934;&#30830;&#32780;&#39640;&#25928;&#22320;&#22238;&#31572;&#21508;&#31181;&#27010;&#29575;&#26597;&#35810;&#30340;&#33021;&#21147;&#65292;&#21516;&#26679;&#36215;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30001;&#20110;&#31163;&#32447;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#21644;&#29615;&#22659;&#21160;&#24577;&#24102;&#26469;&#30340;&#22522;&#26412;&#38543;&#26426;&#24615;&#65292;&#38656;&#35201;&#36827;&#34892;&#39640;&#24230;&#38750;&#24179;&#20961;&#30340;&#26465;&#20214;/&#32422;&#26463;&#29983;&#25104;&#65292;&#20197;&#24341;&#20986;&#26377;&#22870;&#21169;&#30340;&#21160;&#20316;&#12290;&#34429;&#28982;&#20173;&#28982;&#21487;&#20197;&#36817;&#20284;&#22788;&#29702;&#36825;&#20123;&#26597;&#35810;&#65292;&#20294;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#31181;&#31895;&#31961;&#30340;&#20272;&#35745;&#26174;&#33879;&#21066;&#24369;&#20102;&#34920;&#36798;&#24615;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#24102;&#26469;&#30340;&#22909;&#22788;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;Trifle&#65288;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#21487;&#22788;&#29702;&#25512;&#29702;&#65289;&#65292;&#23427;&#21033;&#29992;&#20102;&#29616;&#20195;&#21487;&#22788;&#29702;&#27010;&#29575;&#27169;&#22411;&#65288;TPM&#65289;&#26469;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
A popular paradigm for offline Reinforcement Learning (RL) tasks is to first fit the offline trajectories to a sequence model, and then prompt the model for actions that lead to high expected return. While a common consensus is that more expressive sequence models imply better performance, this paper highlights that tractability, the ability to exactly and efficiently answer various probabilistic queries, plays an equally important role. Specifically, due to the fundamental stochasticity from the offline data-collection policies and the environment dynamics, highly non-trivial conditional/constrained generation is required to elicit rewarding actions. While it is still possible to approximate such queries, we observe that such crude estimates significantly undermine the benefits brought by expressive sequence models. To overcome this problem, this paper proposes Trifle (Tractable Inference for Offline RL), which leverages modern Tractable Probabilistic Models (TPMs) to bridge the gap b
&lt;/p&gt;</description></item><item><title>MimicTouch&#26159;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#27169;&#20223;&#20154;&#31867;&#30340;&#35302;&#35273;&#24341;&#23548;&#25511;&#21046;&#31574;&#30053;&#65292;&#36890;&#36807;&#25910;&#38598;&#26469;&#33258;&#20154;&#31867;&#31034;&#33539;&#32773;&#30340;&#22810;&#27169;&#24577;&#35302;&#35273;&#25968;&#25454;&#38598;&#65292;&#26469;&#23398;&#20064;&#24182;&#25191;&#34892;&#22797;&#26434;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.16917</link><description>&lt;p&gt;
MimicTouch: &#20351;&#29992;&#22810;&#27169;&#24577;&#35302;&#35273;&#21453;&#39304;&#23398;&#20064;&#20154;&#31867;&#30340;&#25511;&#21046;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
MimicTouch: Learning Human's Control Strategy with Multi-Modal Tactile Feedback. (arXiv:2310.16917v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16917
&lt;/p&gt;
&lt;p&gt;
MimicTouch&#26159;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#27169;&#20223;&#20154;&#31867;&#30340;&#35302;&#35273;&#24341;&#23548;&#25511;&#21046;&#31574;&#30053;&#65292;&#36890;&#36807;&#25910;&#38598;&#26469;&#33258;&#20154;&#31867;&#31034;&#33539;&#32773;&#30340;&#22810;&#27169;&#24577;&#35302;&#35273;&#25968;&#25454;&#38598;&#65292;&#26469;&#23398;&#20064;&#24182;&#25191;&#34892;&#22797;&#26434;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#20154;&#25216;&#26415;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#35302;&#35273;&#22788;&#29702;&#30340;&#25972;&#21512;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#23398;&#20064;&#25191;&#34892;&#20687;&#23545;&#20934;&#21644;&#25554;&#20837;&#36825;&#26679;&#22797;&#26434;&#20219;&#21153;&#26102;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#20381;&#36182;&#26426;&#22120;&#20154;&#36965;&#25805;&#20316;&#25968;&#25454;&#21644;&#24378;&#21270;&#23398;&#20064;&#65292;&#24573;&#35270;&#20102;&#20154;&#31867;&#21463;&#35302;&#35273;&#21453;&#39304;&#24341;&#23548;&#19979;&#30340;&#25511;&#21046;&#31574;&#30053;&#25152;&#25552;&#20379;&#30340;&#20016;&#23500;&#35265;&#35299;&#12290;&#20026;&#20102;&#21033;&#29992;&#20154;&#31867;&#24863;&#35273;&#65292;&#29616;&#26377;&#30340;&#20174;&#20154;&#31867;&#23398;&#20064;&#30340;&#26041;&#27861;&#20027;&#35201;&#21033;&#29992;&#35270;&#35273;&#21453;&#39304;&#65292;&#24120;&#24120;&#24573;&#35270;&#20102;&#20154;&#31867;&#26412;&#33021;&#22320;&#21033;&#29992;&#35302;&#35273;&#21453;&#39304;&#23436;&#25104;&#22797;&#26434;&#25805;&#20316;&#30340;&#23453;&#36149;&#32463;&#39564;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;"MimicTouch"&#65292;&#27169;&#20223;&#20154;&#31867;&#30340;&#35302;&#35273;&#24341;&#23548;&#25511;&#21046;&#31574;&#30053;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20174;&#20154;&#31867;&#31034;&#33539;&#32773;&#37027;&#37324;&#25910;&#38598;&#22810;&#27169;&#24577;&#35302;&#35273;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#20154;&#31867;&#35302;&#35273;&#24341;&#23548;&#30340;&#25511;&#21046;&#31574;&#30053;&#26469;&#23436;&#25104;&#20219;&#21153;&#12290;&#25509;&#19979;&#26469;&#30340;&#27493;&#39588;&#28041;&#21450;&#25351;&#20196;&#30340;&#20256;&#36882;&#65292;&#20854;&#20013;&#26426;&#22120;&#20154;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#30340;&#35302;&#35273;&#24341;&#23548;&#31574;&#30053;&#26469;&#25191;&#34892;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
In robotics and artificial intelligence, the integration of tactile processing is becoming increasingly pivotal, especially in learning to execute intricate tasks like alignment and insertion. However, existing works focusing on tactile methods for insertion tasks predominantly rely on robot teleoperation data and reinforcement learning, which do not utilize the rich insights provided by human's control strategy guided by tactile feedback. For utilizing human sensations, methodologies related to learning from humans predominantly leverage visual feedback, often overlooking the invaluable tactile feedback that humans inherently employ to finish complex manipulations. Addressing this gap, we introduce "MimicTouch", a novel framework that mimics human's tactile-guided control strategy. In this framework, we initially collect multi-modal tactile datasets from human demonstrators, incorporating human tactile-guided control strategies for task completion. The subsequent step involves instruc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#32454;&#21270;&#19982;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#20219;&#21153;&#30340;&#36129;&#29486;&#20998;&#37197;&#22870;&#21169;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;LFP&#21462;&#24471;&#20102;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12053</link><description>&lt;p&gt;
&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Layer-wise Feedback Propagation. (arXiv:2308.12053v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#32454;&#21270;&#19982;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#20219;&#21153;&#30340;&#36129;&#29486;&#20998;&#37197;&#22870;&#21169;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;LFP&#21462;&#24471;&#20102;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#20307;&#32780;&#35328;&#26159;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#35299;&#20915;&#32473;&#23450;&#20219;&#21153;&#30340;&#36129;&#29486;&#29420;&#31435;&#20998;&#37197;&#22870;&#21169;&#12290;&#36825;&#19982;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#19981;&#21516;&#65292;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26159;&#26397;&#21521;&#20272;&#35745;&#30340;&#25439;&#22833;&#26368;&#23567;&#20540;&#26356;&#26032;&#21442;&#25968;&#12290;LFP&#22312;&#27169;&#22411;&#20013;&#20256;&#25773;&#22870;&#21169;&#20449;&#21495;&#65292;&#32780;&#26080;&#38656;&#26799;&#24230;&#35745;&#31639;&#12290;&#23427;&#22686;&#24378;&#25509;&#25910;&#21040;&#27491;&#21453;&#39304;&#30340;&#32467;&#26500;&#65292;&#21516;&#26102;&#38477;&#20302;&#25509;&#25910;&#21040;&#36127;&#21453;&#39304;&#30340;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#30340;&#35282;&#24230;&#35777;&#26126;&#20102;LFP&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;LFP&#20811;&#26381;&#20102;&#26799;&#24230;&#26041;&#27861;&#30340;&#26576;&#20123;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#23545;&#26377;&#24847;&#20041;&#30340;&#23548;&#25968;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;LFP&#22914;&#20309;&#35299;&#20915;&#26799;&#24230;&#26041;&#27861;&#30456;&#20851;&#38382;&#39064;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present Layer-wise Feedback Propagation (LFP), a novel training approach for neural-network-like predictors that utilizes explainability, specifically Layer-wise Relevance Propagation(LRP), to assign rewards to individual connections based on their respective contributions to solving a given task. This differs from traditional gradient descent, which updates parameters towards anestimated loss minimum. LFP distributes a reward signal throughout the model without the need for gradient computations. It then strengthens structures that receive positive feedback while reducingthe influence of structures that receive negative feedback. We establish the convergence of LFP theoretically and empirically, and demonstrate its effectiveness in achieving comparable performance to gradient descent on various models and datasets. Notably, LFP overcomes certain limitations associated with gradient-based methods, such as reliance on meaningful derivatives. We further investigate how 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#26367;&#20195;&#29305;&#24449;&#36873;&#25321;&#30340;&#27010;&#24565;&#65292;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#32422;&#26463;&#23450;&#20041;&#20102;&#26367;&#20195;&#29305;&#24449;&#38598;&#65292;&#20351;&#29992;&#25143;&#21487;&#20197;&#25511;&#21046;&#26367;&#20195;&#30340;&#25968;&#37327;&#21644;&#24046;&#24322;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#38382;&#39064;&#30340;NP-hard&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#22914;&#20309;&#23558;&#20256;&#32479;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#20316;&#20026;&#30446;&#26631;&#38598;&#25104;&#12290;&#23454;&#39564;&#35777;&#26126;&#26367;&#20195;&#29305;&#24449;&#38598;&#30830;&#23454;&#21487;&#20197;&#20855;&#26377;&#39640;&#39044;&#27979;&#36136;&#37327;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#20960;&#20010;&#24433;&#21709;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2307.11607</link><description>&lt;p&gt;
&#21033;&#29992;&#26367;&#20195;&#29305;&#24449;&#36873;&#25321;&#25214;&#21040;&#26368;&#20248;&#30340;&#22810;&#26679;&#29305;&#24449;&#38598;
&lt;/p&gt;
&lt;p&gt;
Finding Optimal Diverse Feature Sets with Alternative Feature Selection. (arXiv:2307.11607v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11607
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#26367;&#20195;&#29305;&#24449;&#36873;&#25321;&#30340;&#27010;&#24565;&#65292;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#32422;&#26463;&#23450;&#20041;&#20102;&#26367;&#20195;&#29305;&#24449;&#38598;&#65292;&#20351;&#29992;&#25143;&#21487;&#20197;&#25511;&#21046;&#26367;&#20195;&#30340;&#25968;&#37327;&#21644;&#24046;&#24322;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#38382;&#39064;&#30340;NP-hard&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#22914;&#20309;&#23558;&#20256;&#32479;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#20316;&#20026;&#30446;&#26631;&#38598;&#25104;&#12290;&#23454;&#39564;&#35777;&#26126;&#26367;&#20195;&#29305;&#24449;&#38598;&#30830;&#23454;&#21487;&#20197;&#20855;&#26377;&#39640;&#39044;&#27979;&#36136;&#37327;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#20960;&#20010;&#24433;&#21709;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#36873;&#25321;&#26159;&#33719;&#21462;&#23567;&#22411;&#12289;&#21487;&#35299;&#37322;&#19988;&#39640;&#31934;&#24230;&#39044;&#27979;&#27169;&#22411;&#30340;&#19968;&#31181;&#24120;&#35265;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#36890;&#24120;&#21482;&#33021;&#24471;&#21040;&#19968;&#20010;&#29305;&#24449;&#38598;&#65292;&#36825;&#22312;&#26576;&#20123;&#22330;&#26223;&#19979;&#21487;&#33021;&#19981;&#36275;&#22815;&#12290;&#20363;&#22914;&#65292;&#29992;&#25143;&#21487;&#33021;&#23545;&#23547;&#25214;&#20855;&#26377;&#30456;&#20284;&#39044;&#27979;&#36136;&#37327;&#20294;&#25552;&#20379;&#19981;&#21516;&#25968;&#25454;&#35299;&#37322;&#30340;&#26367;&#20195;&#29305;&#24449;&#38598;&#24863;&#20852;&#36259;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26367;&#20195;&#29305;&#24449;&#36873;&#25321;&#65292;&#24182;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#32422;&#26463;&#23450;&#20041;&#20102;&#26367;&#20195;&#29305;&#24449;&#65292;&#24182;&#20351;&#29992;&#25143;&#21487;&#20197;&#25511;&#21046;&#26367;&#20195;&#30340;&#25968;&#37327;&#21644;&#24046;&#24322;&#24615;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#24182;&#23637;&#31034;&#20102;&#20854;NP-hard&#24615;&#36136;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#22914;&#20309;&#23558;&#20256;&#32479;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#20316;&#20026;&#30446;&#26631;&#38598;&#25104;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;30&#20010;&#20998;&#31867;&#25968;&#25454;&#38598;&#35780;&#20272;&#20102;&#26367;&#20195;&#29305;&#24449;&#36873;&#25321;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#26367;&#20195;&#29305;&#24449;&#38598;&#30830;&#23454;&#21487;&#33021;&#20855;&#26377;&#36739;&#39640;&#30340;&#39044;&#27979;&#36136;&#37327;&#65292;&#24182;&#20998;&#26512;&#20102;&#20960;&#20010;&#24433;&#21709;&#36825;&#19968;&#32467;&#26524;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature selection is popular for obtaining small, interpretable, yet highly accurate prediction models. Conventional feature-selection methods typically yield one feature set only, which might not suffice in some scenarios. For example, users might be interested in finding alternative feature sets with similar prediction quality, offering different explanations of the data. In this article, we introduce alternative feature selection and formalize it as an optimization problem. In particular, we define alternatives via constraints and enable users to control the number and dissimilarity of alternatives. Next, we analyze the complexity of this optimization problem and show NP-hardness. Further, we discuss how to integrate conventional feature-selection methods as objectives. Finally, we evaluate alternative feature selection with 30 classification datasets. We observe that alternative feature sets may indeed have high prediction quality, and we analyze several factors influencing this ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25191;&#34892;&#39044;&#27979;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25214;&#21040;&#20855;&#26377;&#25191;&#34892;&#31283;&#23450;&#24615;&#30340;&#20998;&#31867;&#22120;&#26469;&#36866;&#29992;&#20110;&#25968;&#25454;&#20998;&#24067;&#12290;&#36890;&#36807;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#30456;&#23545;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#20540;&#21487;Lipschitz&#36830;&#32493;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#25918;&#23485;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#20551;&#35774;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2304.06879</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#19979;&#30340;&#25191;&#34892;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Performative Prediction with Neural Networks. (arXiv:2304.06879v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25191;&#34892;&#39044;&#27979;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25214;&#21040;&#20855;&#26377;&#25191;&#34892;&#31283;&#23450;&#24615;&#30340;&#20998;&#31867;&#22120;&#26469;&#36866;&#29992;&#20110;&#25968;&#25454;&#20998;&#24067;&#12290;&#36890;&#36807;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#30456;&#23545;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#20540;&#21487;Lipschitz&#36830;&#32493;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#25918;&#23485;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#20551;&#35774;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25191;&#34892;&#39044;&#27979;&#26159;&#19968;&#31181;&#23398;&#20064;&#27169;&#22411;&#24182;&#24433;&#21709;&#20854;&#39044;&#27979;&#25968;&#25454;&#30340;&#26694;&#26550;&#12290;&#26412;&#25991;&#26088;&#22312;&#25214;&#21040;&#20998;&#31867;&#22120;&#65292;&#20351;&#20854;&#20855;&#26377;&#25191;&#34892;&#31283;&#23450;&#24615;&#65292;&#21363;&#36866;&#29992;&#20110;&#20854;&#20135;&#29983;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#26368;&#20339;&#20998;&#31867;&#22120;&#12290;&#22312;&#20351;&#29992;&#37325;&#22797;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#25214;&#21040;&#20855;&#26377;&#25191;&#34892;&#31283;&#23450;&#24615;&#30340;&#20998;&#31867;&#22120;&#30340;&#26631;&#20934;&#25910;&#25947;&#32467;&#26524;&#20013;&#65292;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#23545;&#20110;&#27169;&#22411;&#21442;&#25968;&#26159;&#21487;Lipschitz&#36830;&#32493;&#30340;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25439;&#22833;&#24517;&#39035;&#23545;&#36825;&#20123;&#21442;&#25968;&#24378;&#20984;&#21644;&#24179;&#28369;&#65307;&#21542;&#21017;&#65292;&#35813;&#26041;&#27861;&#23558;&#22312;&#26576;&#20123;&#38382;&#39064;&#19978;&#21457;&#25955;&#12290;&#28982;&#32780;&#26412;&#25991;&#21017;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#26159;&#30456;&#23545;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#20540;&#21487;Lipschitz&#36830;&#32493;&#30340;&#65292;&#36825;&#26159;&#25191;&#34892;&#31995;&#32479;&#30340;&#26356;&#21152;&#33258;&#28982;&#30340;&#20551;&#35774;&#12290;&#32467;&#26524;&#65292;&#25105;&#20204;&#33021;&#22815;&#26174;&#33879;&#25918;&#23485;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#20551;&#35774;&#35201;&#27714;&#12290;&#20316;&#20026;&#19968;&#20010;&#35828;&#26126;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#24314;&#27169;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#37325;&#37319;&#26679;&#36807;&#31243;&#65292;&#24182;&#20351;&#29992;&#20854;&#26469;&#23454;&#35777;&#25191;&#34892;&#31283;&#23450;&#24615;&#30456;&#23545;&#20110;&#20854;&#20182;&#30446;&#26631;&#30340;&#25928;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performative prediction is a framework for learning models that influence the data they intend to predict. We focus on finding classifiers that are performatively stable, i.e. optimal for the data distribution they induce. Standard convergence results for finding a performatively stable classifier with the method of repeated risk minimization assume that the data distribution is Lipschitz continuous to the model's parameters. Under this assumption, the loss must be strongly convex and smooth in these parameters; otherwise, the method will diverge for some problems. In this work, we instead assume that the data distribution is Lipschitz continuous with respect to the model's predictions, a more natural assumption for performative systems. As a result, we are able to significantly relax the assumptions on the loss function. In particular, we do not need to assume convexity with respect to the model's parameters. As an illustration, we introduce a resampling procedure that models realisti
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#35299;&#20915;&#20102;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2104.10751</link><description>&lt;p&gt;
&#20998;&#31867;&#35268;&#21017;&#29983;&#25104;&#65306;&#21487;&#25193;&#23637;&#24615;&#65292;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rule Generation for Classification: Scalability, Interpretability, and Fairness. (arXiv:2104.10751v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.10751
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#35299;&#20915;&#20102;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#20855;&#26377;&#32422;&#26463;&#26465;&#20214;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#65292;&#22240;&#27492;&#21487;&#25193;&#23637;&#21040;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#25152;&#24471;&#23450;&#20215;&#23376;&#38382;&#39064;&#34987;&#35777;&#26126;&#26159;NP&#38590;&#38382;&#39064;&#12290;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#20915;&#31574;&#26641;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#19968;&#20010;&#20195;&#29702;&#23450;&#20215;&#23376;&#38382;&#39064;&#20197;&#21152;&#36895;&#12290;&#35813;&#26041;&#27861;&#36820;&#22238;&#19968;&#32452;&#35268;&#21017;&#20197;&#21450;&#23427;&#20204;&#30340;&#26368;&#20248;&#26435;&#37325;&#65292;&#25351;&#31034;&#27599;&#20010;&#35268;&#21017;&#23545;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#35268;&#21017;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#26469;&#35299;&#20915;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#23616;&#37096;&#35299;&#37322;&#24615;&#65292;&#24182;&#23558;&#20844;&#24179;&#24615;&#30340;&#19968;&#33324;&#20998;&#31163;&#20934;&#21017;&#25512;&#24191;&#21040;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#21644;&#31867;&#21035;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#26469;&#35814;&#32454;&#38416;&#36848;&#20854;&#19981;&#21516;&#26041;&#38754;&#12290;&#25152;&#25552;&#20986;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#23398;&#20064;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#36798;&#21040;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new rule-based optimization method for classification with constraints. The proposed method leverages column generation for linear programming, and hence, is scalable to large datasets. The resulting pricing subproblem is shown to be NP-Hard. We recourse to a decision tree-based heuristic and solve a proxy pricing subproblem for acceleration. The method returns a set of rules along with their optimal weights indicating the importance of each rule for learning. We address interpretability and fairness by assigning cost coefficients to the rules and introducing additional constraints. In particular, we focus on local interpretability and generalize separation criterion in fairness to multiple sensitive attributes and classes. We test the performance of the proposed methodology on a collection of datasets and present a case study to elaborate on its different aspects. The proposed rule-based learning method exhibits a good compromise between local interpretability and fairn
&lt;/p&gt;</description></item></channel></rss>