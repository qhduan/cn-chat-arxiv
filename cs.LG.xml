<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#25552;&#31034;&#31574;&#30053;&#23558;&#36712;&#36857;&#25968;&#25454;&#20998;&#35299;&#20026;&#26102;&#38388;&#21644;&#35821;&#35328;&#25551;&#36848;&#30340;&#23376;&#20219;&#21153;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#26102;&#38388;&#30456;&#20284;&#24615;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#20004;&#31181;&#26032;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;</title><link>https://arxiv.org/abs/2403.17238</link><description>&lt;p&gt;
&#22522;&#20110;&#26102;&#38388;&#21644;&#35821;&#20041;&#35780;&#20272;&#25351;&#26631;&#30340;&#22522;&#30784;&#27169;&#22411;&#22312;&#26426;&#22120;&#20154;&#23376;&#20219;&#21153;&#20107;&#21518;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Temporal and Semantic Evaluation Metrics for Foundation Models in Post-Hoc Analysis of Robotic Sub-tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17238
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#25552;&#31034;&#31574;&#30053;&#23558;&#36712;&#36857;&#25968;&#25454;&#20998;&#35299;&#20026;&#26102;&#38388;&#21644;&#35821;&#35328;&#25551;&#36848;&#30340;&#23376;&#20219;&#21153;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#26102;&#38388;&#30456;&#20284;&#24615;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#20004;&#31181;&#26032;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#20219;&#21153;&#21644;&#36816;&#21160;&#35268;&#21010;&#65288;TAMP&#65289;&#39046;&#22495;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#20351;&#29992;&#24102;&#26377;&#36136;&#37327;&#26631;&#35760;&#25968;&#25454;&#30340;&#35821;&#35328;&#30417;&#30563;&#26426;&#22120;&#20154;&#36712;&#36857;&#36827;&#34892;&#25511;&#21046;&#31574;&#30053;&#35757;&#32451;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#20195;&#29702;&#20219;&#21153;&#25104;&#21151;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#31867;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#23545;&#23558;&#36825;&#20123;&#26041;&#27861;&#25193;&#23637;&#21040;&#19968;&#33324;&#29992;&#20363;&#26500;&#25104;&#37325;&#22823;&#38556;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#30340;&#22522;&#30784;&#27169;&#22411;&#65288;FMs&#65289;&#30340;&#25552;&#31034;&#31574;&#30053;&#65292;&#21253;&#25324;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#65292;&#23558;&#36712;&#36857;&#25968;&#25454;&#20998;&#35299;&#20026;&#22522;&#20110;&#26102;&#38388;&#21644;&#33258;&#28982;&#35821;&#35328;&#30340;&#25551;&#36848;&#24615;&#23376;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20026;&#26500;&#25104;&#23436;&#25972;&#36712;&#36857;&#30340;&#24213;&#23618;&#23376;&#20219;&#21153;&#25552;&#20379;&#20102;&#22522;&#20110;&#26102;&#38388;&#21644;&#35821;&#35328;&#30340;&#25551;&#36848;&#12290;&#20026;&#20102;&#20005;&#26684;&#35780;&#20272;&#25105;&#20204;&#30340;&#33258;&#21160;&#26631;&#35760;&#26694;&#26550;&#30340;&#36136;&#37327;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861; SIMILARITY &#26469;&#29983;&#25104;&#20004;&#31181;&#26032;&#39062;&#30340;&#25351;&#26631;&#65292;&#21363;&#26102;&#38388;&#30456;&#20284;&#24615;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17238v1 Announce Type: cross  Abstract: Recent works in Task and Motion Planning (TAMP) show that training control policies on language-supervised robot trajectories with quality labeled data markedly improves agent task success rates. However, the scarcity of such data presents a significant hurdle to extending these methods to general use cases. To address this concern, we present an automated framework to decompose trajectory data into temporally bounded and natural language-based descriptive sub-tasks by leveraging recent prompting strategies for Foundation Models (FMs) including both Large Language Models (LLMs) and Vision Language Models (VLMs). Our framework provides both time-based and language-based descriptions for lower-level sub-tasks that comprise full trajectories. To rigorously evaluate the quality of our automatic labeling framework, we contribute an algorithm SIMILARITY to produce two novel metrics, temporal similarity and semantic similarity. The metrics me
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25945;&#32946;&#39046;&#22495;&#20013;&#24212;&#29992;&#30340;&#19977;&#38454;&#27573;&#30417;&#30563;&#24494;&#35843;&#27169;&#22411;&#65292;&#36890;&#36807;&#20808;&#39564;&#21644;&#25968;&#25454;&#37325;&#21472;&#20272;&#35745;&#23454;&#29616;&#20102;&#25945;&#32946;&#30693;&#35782;&#30340;&#32467;&#26500;&#25286;&#21368;&#21644;&#22686;&#37327;&#24341;&#23548;&#36755;&#20986;&#12290;</title><link>https://arxiv.org/abs/2403.15426</link><description>&lt;p&gt;
&#25945;&#32946;&#29615;&#22659;&#19979;&#38598;&#25104;&#24378;&#20808;&#39564;&#27169;&#22359;&#21644;&#25968;&#25454;&#37325;&#21472;&#20272;&#35745;&#30340;&#19977;&#38454;&#27573;SFT&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15426
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25945;&#32946;&#39046;&#22495;&#20013;&#24212;&#29992;&#30340;&#19977;&#38454;&#27573;&#30417;&#30563;&#24494;&#35843;&#27169;&#22411;&#65292;&#36890;&#36807;&#20808;&#39564;&#21644;&#25968;&#25454;&#37325;&#21472;&#20272;&#35745;&#23454;&#29616;&#20102;&#25945;&#32946;&#30693;&#35782;&#30340;&#32467;&#26500;&#25286;&#21368;&#21644;&#22686;&#37327;&#24341;&#23548;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#22522;&#20110;&#20808;&#39564;&#30340;&#19977;&#38454;&#27573;&#30417;&#30563;&#24494;&#35843;&#27169;&#22411;&#65292;&#35777;&#26126;&#27604;&#20256;&#32479;&#24494;&#35843;&#26041;&#27861;&#26356;&#26377;&#31454;&#20105;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23454;&#29616;&#20102;&#25945;&#32946;&#30693;&#35782;&#30340;&#32467;&#26500;&#25286;&#21368;&#21644;&#22686;&#37327;&#24341;&#23548;&#36755;&#20986;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#37319;&#26679;&#22120;&#21644;&#37325;&#21472;&#20272;&#35745;&#31070;&#32463;&#32593;&#32476;&#23545;&#19977;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#20581;&#22766;&#30340;&#20998;&#31867;&#65292;&#23558;&#39044;&#22788;&#29702;&#25968;&#25454;&#38598;&#20998;&#19977;&#25209;&#27880;&#20837;&#39044;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;LORA&#24494;&#35843;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20808;&#39564;&#27169;&#22359;&#65292;&#23558;&#31995;&#32479;&#25552;&#31034;&#12289;&#21521;&#37327;&#25968;&#25454;&#24211;&#21644;&#25277;&#35937;&#35821;&#27861;&#26641;&#20219;&#21153;&#20998;&#21106;&#30456;&#32467;&#21512;&#12290;&#26368;&#21518;&#65292;&#23545;&#22522;&#20110;&#20808;&#39564;&#30340;&#24494;&#35843;&#27169;&#22411;&#24212;&#29992;&#20102;&#21387;&#32553;&#26041;&#27861;&#21644;&#27491;&#21017;&#21270;&#32422;&#26463;&#65292;&#38543;&#21518;&#22312;&#36755;&#20986;&#31471;&#36827;&#34892;&#25991;&#26412;&#36807;&#28388;&#20197;&#33719;&#24471;&#22686;&#37327;&#24341;&#23548;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20195;&#34920;&#20102;&#30495;&#27491;&#20197;&#20016;&#23500;&#30340;&#25945;&#32946;&#30693;&#35782;&#12289;&#20998;&#27493;&#25351;&#23548;&#30340;&#29305;&#28857;&#20307;&#29616;&#23548;&#24072;&#35282;&#33394;&#30340;&#31532;&#19968;&#39033;&#30740;&#31350;&#21162;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15426v1 Announce Type: cross  Abstract: In this paper, we propose an end-to-end prior-based three-phases supervised fine-tuned model, which is proved more competitive than traditional fine-tuning method. More specifically, our model realizes the structural disassembly and incremental guided output of educational knowledge. To this end, we robustify data classification of three types via a sampler and overlap estimation neural network, and inject the preprocessing datasets into pre-trained model in three batches for LORA fine-tuning. Then, we design a prior module couples system prompt, vector databases, and abstract syntax tree task segmentation. Finally, the compression method and regularization constraint are applied to the prior-based fine-tuned model, followed by text filter at the output end to obtain incremental guided results. Our model represents the first research effort to truly embody the tutor role with the features of abundant educational knowledge, step-by-step
&lt;/p&gt;</description></item><item><title>CMDI&#32858;&#31867;&#26041;&#27861;&#21019;&#26032;&#24615;&#22320;&#23558;&#20108;&#32500;&#32467;&#26500;&#20449;&#24687;&#29702;&#35770;&#34701;&#20837;&#32858;&#31867;&#36807;&#31243;&#20013;&#65292;&#24357;&#34917;&#20102;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#32858;&#31867;&#26041;&#27861;&#20013;&#24573;&#30053;&#30340;&#38543;&#26426;&#28216;&#36208;&#35775;&#38382;&#33410;&#28857;&#21644;&#25968;&#25454;&#20013;&#23884;&#20837;&#30340;&#32467;&#26500;&#20449;&#24687;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.13846</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#22270;&#26368;&#22823;&#35299;&#30721;&#20449;&#24687;&#30340;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Clustering Method with Graph Maximum Decoding Information
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13846
&lt;/p&gt;
&lt;p&gt;
CMDI&#32858;&#31867;&#26041;&#27861;&#21019;&#26032;&#24615;&#22320;&#23558;&#20108;&#32500;&#32467;&#26500;&#20449;&#24687;&#29702;&#35770;&#34701;&#20837;&#32858;&#31867;&#36807;&#31243;&#20013;&#65292;&#24357;&#34917;&#20102;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#32858;&#31867;&#26041;&#27861;&#20013;&#24573;&#30053;&#30340;&#38543;&#26426;&#28216;&#36208;&#35775;&#38382;&#33410;&#28857;&#21644;&#25968;&#25454;&#20013;&#23884;&#20837;&#30340;&#32467;&#26500;&#20449;&#24687;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22270;&#27169;&#22411;&#30340;&#32858;&#31867;&#26041;&#27861;&#22240;&#20854;&#22312;&#21508;&#31181;&#30693;&#35782;&#39046;&#22495;&#20013;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#32780;&#22791;&#21463;&#20851;&#27880;&#12290;&#20854;&#33021;&#22815;&#19982;&#20854;&#20182;&#30456;&#20851;&#24212;&#29992;&#26080;&#32541;&#38598;&#25104;&#30340;&#36866;&#24212;&#24615;&#36171;&#20104;&#20102;&#22522;&#20110;&#22270;&#27169;&#22411;&#30340;&#32858;&#31867;&#20998;&#26512;&#33021;&#21147;&#65292;&#21487;&#20197;&#24378;&#22823;&#22320;&#20174;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#8220;&#33258;&#28982;&#20851;&#32852;&#8221;&#25110;&#8220;&#22270;&#32467;&#26500;&#8221;&#65292;&#26377;&#21161;&#20110;&#24314;&#27169;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#23613;&#31649;&#36825;&#31181;&#26041;&#27861;&#25928;&#26524;&#26174;&#33879;&#65292;&#20294;&#24403;&#21069;&#21033;&#29992;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#30340;&#32858;&#31867;&#26041;&#27861;&#24573;&#30053;&#20102;&#33410;&#28857;&#20043;&#38388;&#38543;&#26426;&#28216;&#36208;&#35775;&#38382;&#20197;&#21450;&#25968;&#25454;&#20013;&#23884;&#20837;&#30340;&#32467;&#26500;&#20449;&#24687;&#25152;&#24102;&#26469;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#20869;&#26368;&#22823;&#21270;&#35299;&#30721;&#20449;&#24687;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;CMDI&#12290;CMDI&#21019;&#26032;&#22320;&#23558;&#20108;&#32500;&#32467;&#26500;&#20449;&#24687;&#29702;&#35770;&#32435;&#20837;&#21040;&#32858;&#31867;&#36807;&#31243;&#20013;&#65292;&#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#65306;&#22270;&#32467;&#26500;&#25552;&#21462;&#21644;&#22270;&#39030;&#28857;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13846v1 Announce Type: cross  Abstract: The clustering method based on graph models has garnered increased attention for its widespread applicability across various knowledge domains. Its adaptability to integrate seamlessly with other relevant applications endows the graph model-based clustering analysis with the ability to robustly extract "natural associations" or "graph structures" within datasets, facilitating the modelling of relationships between data points. Despite its efficacy, the current clustering method utilizing the graph-based model overlooks the uncertainty associated with random walk access between nodes and the embedded structural information in the data. To address this gap, we present a novel Clustering method for Maximizing Decoding Information within graph-based models, named CMDI. CMDI innovatively incorporates two-dimensional structural information theory into the clustering process, consisting of two phases: graph structure extraction and graph vert
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35270;&#35273;&#21464;&#31181;&#22312;&#35782;&#21035;&#12289;&#25512;&#29702;&#21644;&#22522;&#20934;&#30830;&#23450;&#31561;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#22810;&#27169;&#24577;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#24191;&#27867;&#33021;&#21147;&#21644;&#38480;&#21046;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;</title><link>https://arxiv.org/abs/2403.13164</link><description>&lt;p&gt;
VL-ICL Bench: &#22522;&#20110;&#32454;&#33410;&#30340;&#22810;&#27169;&#24577;&#19978;&#19979;&#25991;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#32454;&#33410;&#20043;&#39764;
&lt;/p&gt;
&lt;p&gt;
VL-ICL Bench: The Devil in the Details of Benchmarking Multimodal In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13164
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35270;&#35273;&#21464;&#31181;&#22312;&#35782;&#21035;&#12289;&#25512;&#29702;&#21644;&#22522;&#20934;&#30830;&#23450;&#31561;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#22810;&#27169;&#24577;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#24191;&#27867;&#33021;&#21147;&#21644;&#38480;&#21046;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20197;&#20854;&#33879;&#21517;&#30340;&#20986;&#29616;&#24335;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#32780;&#38395;&#21517;&#8212;&#8212;&#21363;&#22312;&#20165;&#25552;&#20379;&#20960;&#20010;&#31034;&#20363;&#20316;&#20026;&#25552;&#31034;&#30340;&#24773;&#20917;&#19979;&#65292;&#24555;&#36895;&#36866;&#24212;&#26032;&#20219;&#21153;&#30340;&#33021;&#21147;&#65292;&#32780;&#26080;&#38656;&#26356;&#26032;&#27169;&#22411;&#30340;&#26435;&#37325;&#12290;&#26500;&#24314;&#22312;LLMs&#20043;&#19978;&#30340;&#35270;&#35273;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;VLLMs&#65289;&#22312;&#35782;&#21035;&#12289;&#25512;&#29702;&#21644;&#22522;&#20934;&#30830;&#23450;&#31561;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;\emph{&#22810;&#27169;&#24577;ICL}&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#23569;&#26679;&#26412;&#35270;&#35273;&#38382;&#39064;&#22238;&#31572;&#65288;VQA&#65289;&#21644;&#22270;&#20687;&#23383;&#24149;&#19978;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#20108;&#32773;&#26082;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;ICL&#30340;&#20248;&#21183;&#65292;&#20063;&#27809;&#26377;&#27979;&#35797;&#20854;&#38480;&#21046;&#12290;&#23545;&#22810;&#27169;&#24577;ICL&#30340;&#26356;&#24191;&#27867;&#33021;&#21147;&#21644;&#23616;&#38480;&#24615;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#22810;&#27169;&#24577;&#19978;&#19979;&#25991;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797; VL-ICL Bench&#65292;&#28085;&#30422;&#20102;&#28041;&#21450;&#22270;&#20687;&#21644;&#25991;&#26412;&#20316;&#20026;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#24191;&#27867;&#20219;&#21153;&#33539;&#22260;&#65292;&#24182;&#28085;&#30422;&#20102;&#20174;{&#24863;&#30693;&#21040;&#25512;&#29702;&#21644;&#38271;&#26399;&#19978;&#19979;&#25991;&#38271;&#24230;}&#30340;&#19981;&#21516;&#31867;&#22411;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13164v1 Announce Type: new  Abstract: Large language models (LLMs) famously exhibit emergent in-context learning (ICL) -- the ability to rapidly adapt to new tasks using few-shot examples provided as a prompt, without updating the model's weights. Built on top of LLMs, vision large language models (VLLMs) have advanced significantly in areas such as recognition, reasoning, and grounding. However, investigations into \emph{multimodal ICL} have predominantly focused on few-shot visual question answering (VQA), and image captioning, which we will show neither exploit the strengths of ICL, nor test its limitations. The broader capabilities and limitations of multimodal ICL remain under-explored. In this study, we introduce a comprehensive benchmark VL-ICL Bench for multimodal in-context learning, encompassing a broad spectrum of tasks that involve both images and text as inputs and outputs, and different types of challenges, from {perception to reasoning and long context length}
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20445;&#25345;&#27169;&#22411;&#39640;&#20934;&#30830;&#24615;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10045</link><description>&lt;p&gt;
&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#23454;&#29616;&#23545;&#25239;&#40065;&#26834;&#24615;&#25968;&#25454;&#38598;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
Towards Adversarially Robust Dataset Distillation by Curvature Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20445;&#25345;&#27169;&#22411;&#39640;&#20934;&#30830;&#24615;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#38598;&#31934;&#28860;&#65288;DD&#65289;&#20801;&#35768;&#23558;&#25968;&#25454;&#38598;&#31934;&#28860;&#20026;&#21407;&#22987;&#22823;&#23567;&#30340;&#20998;&#25968;&#65292;&#21516;&#26102;&#20445;&#30041;&#20016;&#23500;&#30340;&#20998;&#24067;&#20449;&#24687;&#65292;&#20351;&#24471;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#33410;&#30465;&#26174;&#33879;&#35745;&#31639;&#36127;&#36733;&#30340;&#21516;&#26102;&#36798;&#21040;&#21487;&#27604;&#30340;&#20934;&#30830;&#24615;&#12290;&#26368;&#36817;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#25552;&#39640;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25506;&#32034;DD&#30340;&#19968;&#31181;&#26032;&#35270;&#35282;&#12290;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20351;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#20445;&#25345;&#39640;&#31934;&#24230;&#30340;&#21516;&#26102;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23558;&#26354;&#29575;&#27491;&#21017;&#21270;&#32435;&#20837;&#21040;&#31934;&#28860;&#36807;&#31243;&#20013;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#26032;&#26041;&#27861;&#65292;&#32780;&#36825;&#31181;&#26041;&#27861;&#30340;&#35745;&#31639;&#24320;&#38144;&#27604;&#26631;&#20934;&#30340;&#23545;&#25239;&#35757;&#32451;&#35201;&#23569;&#24471;&#22810;&#12290;&#22823;&#37327;&#30340;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#22312;&#20934;&#30830;&#24615;&#19978;&#20248;&#20110;&#26631;&#20934;&#23545;&#25239;&#35757;&#32451;&#65292;&#21516;&#26102;&#22312;&#23545;&#25239;&#24615;&#33021;&#26041;&#38754;&#20063;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10045v1 Announce Type: new  Abstract: Dataset distillation (DD) allows datasets to be distilled to fractions of their original size while preserving the rich distributional information so that models trained on the distilled datasets can achieve a comparable accuracy while saving significant computational loads. Recent research in this area has been focusing on improving the accuracy of models trained on distilled datasets. In this paper, we aim to explore a new perspective of DD. We study how to embed adversarial robustness in distilled datasets, so that models trained on these datasets maintain the high accuracy and meanwhile acquire better adversarial robustness. We propose a new method that achieves this goal by incorporating curvature regularization into the distillation process with much less computational overhead than standard adversarial training. Extensive empirical experiments suggest that our method not only outperforms standard adversarial training on both accur
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;5G&#32593;&#32476;&#20013;&#26816;&#27979;&#24178;&#25200;&#32773;&#30340;&#26032;&#22411;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#36890;&#36807;&#24341;&#20837;&#21452;&#38408;&#20540;&#28145;&#24230;&#23398;&#20064;&#24178;&#25200;&#26816;&#27979;&#22120;&#65292;&#19987;&#27880;&#20110;SSB&#30340;RF&#39046;&#22495;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.02645</link><description>&lt;p&gt;
&#22312;5G RF&#39046;&#22495;&#65292;&#29992;&#20110;&#24178;&#25200;&#26816;&#27979;&#30340;&#31354;&#20013;&#21452;&#38408;&#20540;&#28145;&#24230;&#23398;&#20064;&#22120;
&lt;/p&gt;
&lt;p&gt;
Over-The-Air Double-Threshold Deep Learner for Jamming Detection in 5G RF domain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02645
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;5G&#32593;&#32476;&#20013;&#26816;&#27979;&#24178;&#25200;&#32773;&#30340;&#26032;&#22411;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#36890;&#36807;&#24341;&#20837;&#21452;&#38408;&#20540;&#28145;&#24230;&#23398;&#20064;&#24178;&#25200;&#26816;&#27979;&#22120;&#65292;&#19987;&#27880;&#20110;SSB&#30340;RF&#39046;&#22495;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;5G&#26080;&#32447;&#36890;&#20449;&#30340;&#21457;&#23637;&#65292;&#21516;&#27493;&#20449;&#21495;&#22359;&#65288;SSB&#65289;&#22312;&#35774;&#22791;&#21516;&#27493;&#21644;&#26381;&#21153;&#21487;&#35775;&#38382;&#24615;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;SSB&#20256;&#36755;&#20855;&#26377;&#21487;&#39044;&#27979;&#24615;&#65292;&#21253;&#25324;&#20027;&#35201;&#21516;&#27493;&#20449;&#21495;&#65288;PSS&#65289;&#21644;&#27425;&#35201;&#21516;&#27493;&#20449;&#21495;&#65288;SSS&#65289;&#65292;&#24178;&#25200;&#25915;&#20987;&#26159;&#37325;&#35201;&#23041;&#32961;&#12290;&#26412;&#25991;&#21033;&#29992;RF&#39046;&#22495;&#30693;&#35782;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;5G&#32593;&#32476;&#24178;&#25200;&#26816;&#27979;&#25216;&#26415;&#12290;&#19982;&#29616;&#26377;&#30340;&#22823;&#22810;&#20381;&#36182;&#32593;&#32476;&#21442;&#25968;&#30340;&#24178;&#25200;&#26816;&#27979;&#31639;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#36890;&#36807;&#19987;&#27880;&#20110;SSB&#24341;&#20837;&#20102;&#21452;&#38408;&#20540;&#28145;&#24230;&#23398;&#20064;&#24178;&#25200;&#26816;&#27979;&#22120;&#12290;&#35813;&#26816;&#27979;&#26041;&#27861;&#20391;&#37325;&#20110;RF&#39046;&#22495;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#65292;&#26080;&#38656;&#19982;&#29616;&#26377;&#32593;&#32476;&#22522;&#30784;&#35774;&#26045;&#38598;&#25104;&#12290;&#36890;&#36807;&#38598;&#25104;&#19968;&#20010;&#39044;&#22788;&#29702;&#22359;&#26469;&#25552;&#21462;PSS&#30456;&#20851;&#24615;&#21644;&#27599;&#20010;&#31354;&#38386;&#36164;&#28304;&#20803;&#32032;&#30340;&#33021;&#37327;&#65288;EPNRE&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02645v1 Announce Type: cross  Abstract: With the evolution of 5G wireless communications, the Synchronization Signal Block (SSB) plays a critical role in the synchronization of devices and accessibility of services. However, due to the predictable nature of SSB transmission, including the Primary and Secondary Synchronization Signals (PSS and SSS), jamming attacks are critical threats. By leveraging RF domain knowledge, this work presents a novel deep learning-based technique for detecting jammers in 5G networks. Unlike the existing jamming detection algorithms that mostly rely on network parameters, we introduce a double threshold deep learning jamming detector by focusing on the SSB. The detection method is focused on RF domain features and improves the robustness of the network without requiring integration with the pre-existing network infrastructure. By integrating a preprocessing block that extracts PSS correlation and energy per null resource elements (EPNRE) characte
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;</title><link>https://arxiv.org/abs/2402.05928</link><description>&lt;p&gt;
&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65306;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#30340;&#24179;&#26041;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#24615;&#65288;&#946;-&#28151;&#21512;&#65289;&#25968;&#25454;&#21644;&#24179;&#26041;&#25439;&#22833;&#30340;&#32479;&#35745;&#23398;&#20064;&#65292;&#22312;&#19968;&#20010;&#20551;&#35774;&#31867;&#21035;&#934;_p&#30340;&#23376;&#38598;F&#20013;&#65292;&#20854;&#20013;&#934;_p&#26159;&#33539;&#25968;&#8741;f&#8741;_&#934;_p&#8801;sup_m&#8805;1 m^{-1/p}&#8741;f&#8741;_L^m&#65292;&#20854;&#20013;p&#8712;[2&#65292;&#8734;]&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21160;&#26426;&#26159;&#22312;&#20855;&#26377;&#20381;&#36182;&#24615;&#25968;&#25454;&#30340;&#23398;&#20064;&#20013;&#23547;&#25214;&#23574;&#38160;&#30340;&#22122;&#22768;&#20132;&#20114;&#39033;&#25110;&#26041;&#24046;&#20195;&#29702;&#12290;&#22312;&#27809;&#26377;&#20219;&#20309;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20856;&#22411;&#30340;&#38750;&#28176;&#36817;&#32467;&#26524;&#26174;&#31034;&#20986;&#26041;&#24046;&#20195;&#29702;&#36890;&#36807;&#24213;&#23618;&#21327;&#21464;&#37327;&#36807;&#31243;&#30340;&#28151;&#21512;&#26102;&#38388;&#36827;&#34892;&#20102;&#20056;&#31215;&#32553;&#20943;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#22312;&#25105;&#20204;&#30340;&#20551;&#35774;&#31867;&#21035;F&#19978;&#65292;L^2&#21644;&#934;_p&#30340;&#25299;&#25169;&#26159;&#21487;&#27604;&#36739;&#30340;&#65292;&#21363;&#934;_p&#26159;&#19968;&#20010;&#24369;&#20122;&#39640;&#26031;&#31867;&#21035;&#65306;&#8741;f&#8741;_&#934;_p&#8818;&#8741;f&#8741;_L^2^&#951;&#65292;&#20854;&#20013;&#951;&#8712;(0&#65292;1]&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#22312;&#20854;&#20027;&#23548;&#39033;&#20013;&#21482;&#23454;&#29616;&#20102;&#19968;&#31181;&#21482;&#20381;&#36182;&#20110;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#35768;&#22810;&#20381;&#36182;&#24615;&#25968;&#25454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study statistical learning with dependent ($\beta$-mixing) data and square loss in a hypothesis class $\mathscr{F}\subset L_{\Psi_p}$ where $\Psi_p$ is the norm $\|f\|_{\Psi_p} \triangleq \sup_{m\geq 1} m^{-1/p} \|f\|_{L^m} $ for some $p\in [2,\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data. Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \emph{multiplicatively} by the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\Psi_p$ are comparable on our hypothesis class $\mathscr{F}$ -- that is, $\mathscr{F}$ is a weakly sub-Gaussian class: $\|f\|_{\Psi_p} \lesssim \|f\|_{L^2}^\eta$ for some $\eta\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. Our result holds whether t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#32676;&#32593;&#32476;&#24178;&#25200;&#19979;&#20010;&#20307;&#21270;&#31574;&#30053;&#35780;&#20272;&#19982;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21482;&#20551;&#35774;&#21322;&#21442;&#25968;&#32467;&#26500;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#21644;&#23398;&#20064;&#26368;&#20248;&#30340;&#20010;&#20307;&#21270;&#22788;&#29702;&#35268;&#21017;&#12290;</title><link>https://arxiv.org/abs/2311.02467</link><description>&lt;p&gt;
&#38598;&#32676;&#32593;&#32476;&#24178;&#25200;&#19979;&#30340;&#20010;&#20307;&#21270;&#31574;&#30053;&#35780;&#20272;&#19982;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Individualized Policy Evaluation and Learning under Clustered Network Interference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#32676;&#32593;&#32476;&#24178;&#25200;&#19979;&#20010;&#20307;&#21270;&#31574;&#30053;&#35780;&#20272;&#19982;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21482;&#20551;&#35774;&#21322;&#21442;&#25968;&#32467;&#26500;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#21644;&#23398;&#20064;&#26368;&#20248;&#30340;&#20010;&#20307;&#21270;&#22788;&#29702;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#29616;&#22312;&#26377;&#24456;&#22810;&#20851;&#20110;&#25919;&#31574;&#35780;&#20272;&#21644;&#23398;&#20064;&#30340;&#25991;&#29486;&#65292;&#20294;&#22823;&#37096;&#20998;&#20043;&#21069;&#30340;&#24037;&#20316;&#37117;&#20551;&#35774;&#19968;&#20010;&#20010;&#20307;&#30340;&#22788;&#29702;&#20998;&#37197;&#19981;&#20250;&#24433;&#21709;&#21478;&#19968;&#20010;&#20010;&#20307;&#30340;&#32467;&#26524;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24573;&#35270;&#24178;&#25200;&#21487;&#33021;&#23548;&#33268;&#35780;&#20272;&#20559;&#35823;&#21644;&#26080;&#25928;&#30340;&#23398;&#20064;&#31574;&#30053;&#12290;&#20363;&#22914;&#65292;&#22788;&#29702;&#26377;&#24456;&#22810;&#26379;&#21451;&#30340;&#26377;&#24433;&#21709;&#21147;&#30340;&#20010;&#20307;&#21487;&#33021;&#20135;&#29983;&#27491;&#21521;&#28322;&#20986;&#25928;&#24212;&#65292;&#20174;&#32780;&#25913;&#21892;&#20010;&#20307;&#21270;&#22788;&#29702;&#35268;&#21017;&#65288;ITR&#65289;&#30340;&#25972;&#20307;&#24615;&#33021;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#38598;&#32676;&#32593;&#32476;&#24178;&#25200;&#65288;&#20063;&#31216;&#20026;&#37096;&#20998;&#24178;&#25200;&#65289;&#19979;&#35780;&#20272;&#21644;&#23398;&#20064;&#26368;&#20248;ITR&#30340;&#38382;&#39064;&#65292;&#22312;&#35813;&#38382;&#39064;&#20013;&#65292;&#21333;&#20301;&#32858;&#31867;&#20174;&#19968;&#20010;&#24635;&#20307;&#20013;&#25277;&#26679;&#65292;&#24182;&#19988;&#22312;&#27599;&#20010;&#32858;&#31867;&#20013;&#21333;&#20301;&#20043;&#38388;&#21487;&#33021;&#20114;&#30456;&#24433;&#21709;&#12290;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#24378;&#21046;&#38480;&#21046;&#28322;&#20986;&#25928;&#24212;&#19981;&#21516;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21482;&#20551;&#35774;&#21322;&#21442;&#25968;&#32467;&#26500;&#27169;&#22411;&#65292;&#27599;&#20010;&#21333;&#20301;&#30340;&#32467;&#26524;&#26159;&#32858;&#31867;&#20013;&#30340;&#20010;&#20307;&#22788;&#29702;&#30340;&#21152;&#27861;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
While there now exists a large literature on policy evaluation and learning, much of prior work assumes that the treatment assignment of one unit does not affect the outcome of another unit. Unfortunately, ignoring interference may lead to biased policy evaluation and ineffective learned policies. For example, treating influential individuals who have many friends can generate positive spillover effects, thereby improving the overall performance of an individualized treatment rule (ITR). We consider the problem of evaluating and learning an optimal ITR under clustered network interference (also known as partial interference) where clusters of units are sampled from a population and units may influence one another within each cluster. Unlike previous methods that impose strong restrictions on spillover effects, the proposed methodology only assumes a semiparametric structural model where each unit's outcome is an additive function of individual treatments within the cluster. Under this 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;TNTRules&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#37322;&#65292;&#22635;&#34917;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#20043;&#38388;&#30340;&#38388;&#38553;&#12290;</title><link>http://arxiv.org/abs/2401.13334</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Explainable Bayesian Optimization. (arXiv:2401.13334v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13334
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;TNTRules&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#37322;&#65292;&#22635;&#34917;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#20043;&#38388;&#30340;&#38388;&#38553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#19994;&#39046;&#22495;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#20154;&#24037;&#26234;&#33021;&#21327;&#20316;&#21442;&#25968;&#35843;&#20248;&#30340;&#25511;&#21046;&#31995;&#32479;&#20013;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36817;&#20284;&#35823;&#24046;&#21644;&#31616;&#21270;&#30446;&#26631;&#65292;BO&#30340;&#35299;&#20915;&#26041;&#26696;&#21487;&#33021;&#20559;&#31163;&#20154;&#31867;&#19987;&#23478;&#30340;&#30495;&#23454;&#30446;&#26631;&#65292;&#38656;&#35201;&#21518;&#32493;&#35843;&#25972;&#12290;BO&#30340;&#40657;&#30418;&#29305;&#24615;&#38480;&#21046;&#20102;&#21327;&#20316;&#35843;&#20248;&#36807;&#31243;&#65292;&#22240;&#20026;&#19987;&#23478;&#19981;&#20449;&#20219;BO&#30340;&#24314;&#35758;&#12290;&#30446;&#21069;&#30340;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#19981;&#36866;&#29992;&#20110;&#20248;&#21270;&#38382;&#39064;&#65292;&#22240;&#27492;&#26080;&#27861;&#35299;&#20915;&#27492;&#38388;&#38553;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#38388;&#38553;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TNTRules&#65288;TUNE-NOTUNE&#35268;&#21017;&#65289;&#65292;&#19968;&#31181;&#20107;&#21518;&#22522;&#20110;&#35268;&#21017;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#20248;&#21270;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#23545;&#22522;&#20934;&#20248;&#21270;&#38382;&#39064;&#21644;&#23454;&#38469;&#36229;&#21442;&#25968;&#20248;&#21270;&#20219;&#21153;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;TNTRules&#22312;&#29983;&#25104;&#39640;&#36136;&#37327;&#35299;&#37322;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;XAI&#26041;&#27861;&#12290;&#36825;&#39033;&#24037;&#20316;&#23545;BO&#21644;XAI&#30340;&#20132;&#21449;&#39046;&#22495;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In industry, Bayesian optimization (BO) is widely applied in the human-AI collaborative parameter tuning of cyber-physical systems. However, BO's solutions may deviate from human experts' actual goal due to approximation errors and simplified objectives, requiring subsequent tuning. The black-box nature of BO limits the collaborative tuning process because the expert does not trust the BO recommendations. Current explainable AI (XAI) methods are not tailored for optimization and thus fall short of addressing this gap. To bridge this gap, we propose TNTRules (TUNE-NOTUNE Rules), a post-hoc, rule-based explainability method that produces high quality explanations through multiobjective optimization. Our evaluation of benchmark optimization problems and real-world hyperparameter optimization tasks demonstrates TNTRules' superiority over state-of-the-art XAI methods in generating high quality explanations. This work contributes to the intersection of BO and XAI, providing interpretable opt
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;CDVAE&#65289;&#26469;&#35299;&#20915;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#21644;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#26469;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;</title><link>http://arxiv.org/abs/2310.10559</link><description>&lt;p&gt;
&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Causal Dynamic Variational Autoencoder for Counterfactual Regression in Longitudinal Data. (arXiv:2310.10559v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10559
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;CDVAE&#65289;&#26469;&#35299;&#20915;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#21644;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#26469;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24456;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#22914;&#31934;&#20934;&#21307;&#23398;&#12289;&#27969;&#34892;&#30149;&#23398;&#12289;&#32463;&#27982;&#21644;&#24066;&#22330;&#33829;&#38144;&#20013;&#65292;&#20272;&#35745;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#26159;&#30456;&#20851;&#30340;&#12290;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#35201;&#20040;&#20551;&#35774;&#20102;&#25152;&#26377;&#28151;&#26434;&#21464;&#37327;&#30340;&#35266;&#27979;&#32467;&#26524;&#65292;&#35201;&#20040;&#35797;&#22270;&#25512;&#26029;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21464;&#37327;&#12290;&#25105;&#20204;&#37319;&#21462;&#20102;&#19981;&#21516;&#30340;&#35266;&#28857;&#65292;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#21363;&#20165;&#24433;&#21709;&#32467;&#26524;&#24207;&#21015;&#30340;&#35843;&#25972;&#21464;&#37327;&#12290;&#22312;&#26080;&#28151;&#26434;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20197;&#26410;&#35266;&#27979;&#21040;&#30340;&#39118;&#38505;&#22240;&#32032;&#23548;&#33268;&#30340;&#27835;&#30103;&#21453;&#24212;&#20013;&#30340;&#26410;&#30693;&#24322;&#36136;&#24615;&#20026;&#30446;&#26631;&#65292;&#20272;&#35745;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE&#65289;&#12290;&#25105;&#20204;&#24212;&#23545;&#20102;&#26102;&#21464;&#25928;&#24212;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;&#22312;&#23398;&#20064;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#30340;&#26377;&#25928;&#24615;&#21644;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33324;&#21270;&#30028;&#38480;&#30340;&#29702;&#35770;&#32467;&#26524;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22240;&#26524;DVAE&#65288;CDVAE&#65289;&#12290;&#35813;&#27169;&#22411;&#23558;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#19982;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating treatment effects over time is relevant in many real-world applications, such as precision medicine, epidemiology, economy, and marketing. Many state-of-the-art methods either assume the observations of all confounders or seek to infer the unobserved ones. We take a different perspective by assuming unobserved risk factors, i.e., adjustment variables that affect only the sequence of outcomes. Under unconfoundedness, we target the Individual Treatment Effect (ITE) estimation with unobserved heterogeneity in the treatment response due to missing risk factors. We address the challenges posed by time-varying effects and unobserved adjustment variables. Led by theoretical results over the validity of the learned adjustment variables and generalization bounds over the treatment effect, we devise Causal DVAE (CDVAE). This model combines a Dynamic Variational Autoencoder (DVAE) framework with a weighting strategy using propensity scores to estimate counterfactual responses. The CDVA
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22270;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#26080;&#32447;&#36164;&#28304;&#20998;&#37197;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#25299;&#25169;&#20449;&#24687;&#21644;&#25490;&#21015;&#29305;&#24615;&#65292;&#38477;&#20302;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#35757;&#32451;&#22797;&#26434;&#24615;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#39044;&#27979;&#21151;&#29575;&#20998;&#37197;&#38382;&#39064;&#26469;&#39564;&#35777;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.03906</link><description>&lt;p&gt;
&#22270;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#26080;&#32447;&#36164;&#28304;&#20998;&#37197;
&lt;/p&gt;
&lt;p&gt;
Graph Reinforcement Learning for Radio Resource Allocation. (arXiv:2203.03906v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.03906
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22270;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#26080;&#32447;&#36164;&#28304;&#20998;&#37197;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#25299;&#25169;&#20449;&#24687;&#21644;&#25490;&#21015;&#29305;&#24615;&#65292;&#38477;&#20302;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#35757;&#32451;&#22797;&#26434;&#24615;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#39044;&#27979;&#21151;&#29575;&#20998;&#37197;&#38382;&#39064;&#26469;&#39564;&#35777;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#22788;&#29702;&#26080;&#27169;&#22411;&#21644;&#31471;&#21040;&#31471;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;(DRL)&#22312;&#36164;&#28304;&#20998;&#37197;&#26041;&#38754;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;DRL&#30340;&#39640;&#35757;&#32451;&#22797;&#26434;&#24615;&#38480;&#21046;&#20102;&#23427;&#22312;&#21160;&#24577;&#26080;&#32447;&#31995;&#32479;&#20013;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#20026;&#20102;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#65292;&#25105;&#20204;&#37319;&#29992;&#22270;&#24378;&#21270;&#23398;&#20064;&#26469;&#21033;&#29992;&#26080;&#32447;&#36890;&#20449;&#20013;&#35768;&#22810;&#38382;&#39064;&#22266;&#26377;&#30340;&#20004;&#31181;&#20851;&#31995;&#20808;&#39564;&#65306;&#25299;&#25169;&#20449;&#24687;&#21644;&#25490;&#21015;&#29305;&#24615;&#12290;&#20026;&#20102;&#31995;&#32479;&#22320;&#35774;&#35745;&#22270;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#26469;&#21033;&#29992;&#36825;&#20004;&#20010;&#20808;&#39564;&#65292;&#25105;&#20204;&#39318;&#20808;&#26500;&#24605;&#20102;&#19968;&#31181;&#23558;&#29366;&#24577;&#30697;&#38453;&#36716;&#25442;&#20026;&#29366;&#24577;&#22270;&#30340;&#26041;&#27861;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26469;&#28385;&#36275;&#29702;&#24819;&#30340;&#25490;&#21015;&#29305;&#24615;&#12290;&#20026;&#20102;&#23637;&#31034;&#22914;&#20309;&#24212;&#29992;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20197;&#28145;&#24230;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;(DDPG)&#20026;&#20363;&#65292;&#20248;&#21270;&#20102;&#20004;&#20010;&#20195;&#34920;&#24615;&#30340;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#12290;&#19968;&#20010;&#26159;&#39044;&#27979;&#21151;&#29575;&#20998;&#37197;&#65292;&#26088;&#22312;&#26368;&#23567;&#21270;&#33021;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning (DRL) for resource allocation has been investigated extensively owing to its ability of handling model-free and end-to-end problems. Yet the high training complexity of DRL hinders its practical use in dynamic wireless systems. To reduce the training cost, we resort to graph reinforcement learning for exploiting two kinds of relational priors inherent in many problems in wireless communications: topology information and permutation properties. To design graph reinforcement learning framework systematically for harnessing the two priors, we first conceive a method to transform state matrix into state graph, and then propose a general method for graph neural networks to satisfy desirable permutation properties. To demonstrate how to apply the proposed methods, we take deep deterministic policy gradient (DDPG) as an example for optimizing two representative resource allocation problems. One is predictive power allocation that minimizes the energy consumed for e
&lt;/p&gt;</description></item></channel></rss>