<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#32852;&#37030;&#31169;&#26377;&#26412;&#22320;&#35757;&#32451;&#31639;&#27861;&#65288;Fed-PLT&#65289;&#65292;&#36890;&#36807;&#20801;&#35768;&#37096;&#20998;&#21442;&#19982;&#21644;&#26412;&#22320;&#35757;&#32451;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#36890;&#20449;&#36718;&#27425;&#65292;&#21516;&#26102;&#19981;&#24433;&#21709;&#20934;&#30830;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#26412;&#22320;&#35757;&#32451;&#26469;&#22686;&#24378;&#38544;&#31169;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17572</link><description>&lt;p&gt;
&#36890;&#36807;&#26412;&#22320;&#35757;&#32451;&#22686;&#24378;&#32852;&#37030;&#23398;&#20064;&#30340;&#38544;&#31169;&#24615;
&lt;/p&gt;
&lt;p&gt;
Enhancing Privacy in Federated Learning through Local Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17572
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#32852;&#37030;&#31169;&#26377;&#26412;&#22320;&#35757;&#32451;&#31639;&#27861;&#65288;Fed-PLT&#65289;&#65292;&#36890;&#36807;&#20801;&#35768;&#37096;&#20998;&#21442;&#19982;&#21644;&#26412;&#22320;&#35757;&#32451;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#36890;&#20449;&#36718;&#27425;&#65292;&#21516;&#26102;&#19981;&#24433;&#21709;&#20934;&#30830;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#26412;&#22320;&#35757;&#32451;&#26469;&#22686;&#24378;&#38544;&#31169;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#32852;&#37030;&#31169;&#26377;&#26412;&#22320;&#35757;&#32451;&#31639;&#27861;&#65288;Fed-PLT&#65289;&#65292;&#20197;&#20811;&#26381;&#65288;i&#65289;&#26114;&#36149;&#30340;&#36890;&#20449;&#21644;&#65288;ii&#65289;&#38544;&#31169;&#20445;&#25252;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#20801;&#35768;&#37096;&#20998;&#21442;&#19982;&#21644;&#26412;&#22320;&#35757;&#32451;&#26469;&#35299;&#20915;&#65288;i&#65289;&#65292;&#36825;&#26174;&#33879;&#20943;&#23569;&#20102;&#20013;&#22830;&#21327;&#35843;&#21592;&#21644;&#35745;&#31639;&#20195;&#29702;&#20043;&#38388;&#30340;&#36890;&#20449;&#36718;&#27425;&#12290;&#31639;&#27861;&#22312;&#26412;&#22320;&#35757;&#32451;&#30340;&#20351;&#29992;&#19978;&#36798;&#21040;&#20102;&#30446;&#21069;&#25216;&#26415;&#27700;&#24179;&#65292;&#21487;&#20197;&#35777;&#26126;&#19981;&#20250;&#24433;&#21709;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#20195;&#29702;&#21487;&#20197;&#28789;&#27963;&#36873;&#25321;&#21508;&#31181;&#26412;&#22320;&#35757;&#32451;&#27714;&#35299;&#22120;&#65292;&#22914;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#21644;&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#20351;&#29992;&#26412;&#22320;&#35757;&#32451;&#26469;&#22686;&#24378;&#38544;&#31169;&#24615;&#65292;&#35299;&#20915;&#20102;&#28857;&#65288;ii&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#24046;&#20998;&#38544;&#31169;&#30028;&#38480;&#65292;&#24182;&#24378;&#35843;&#23427;&#20204;&#23545;&#26412;&#22320;&#35757;&#32451;&#32426;&#20803;&#25968;&#30340;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17572v1 Announce Type: new  Abstract: In this paper we propose the federated private local training algorithm (Fed-PLT) for federated learning, to overcome the challenges of (i) expensive communications and (ii) privacy preservation. We address (i) by allowing for both partial participation and local training, which significantly reduce the number of communication rounds between the central coordinator and computing agents. The algorithm matches the state of the art in the sense that the use of local training demonstrably does not impact accuracy. Additionally, agents have the flexibility to choose from various local training solvers, such as (stochastic) gradient descent and accelerated gradient descent. Further, we investigate how employing local training can enhance privacy, addressing point (ii). In particular, we derive differential privacy bounds and highlight their dependence on the number of local training epochs. We assess the effectiveness of the proposed algorithm
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#21152;&#24615;&#22122;&#22768;&#30340;&#21508;&#21521;&#21516;&#24615;&#20316;&#20026;&#32422;&#26463;&#65292;&#25913;&#36827;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#30495;&#24230;&#65292;&#39564;&#35777;&#23454;&#39564;&#34920;&#26126;&#36825;&#31181;&#32422;&#26463;&#30340;&#25972;&#21512;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.16790</link><description>&lt;p&gt;
Iso-Diffusion: &#20351;&#29992;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#30340;&#21508;&#21521;&#21516;&#24615;&#25913;&#36827;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Iso-Diffusion: Improving Diffusion Probabilistic Models Using the Isotropy of the Additive Gaussian Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16790
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#21152;&#24615;&#22122;&#22768;&#30340;&#21508;&#21521;&#21516;&#24615;&#20316;&#20026;&#32422;&#26463;&#65292;&#25913;&#36827;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#30495;&#24230;&#65292;&#39564;&#35777;&#23454;&#39564;&#34920;&#26126;&#36825;&#31181;&#32422;&#26463;&#30340;&#25972;&#21512;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPMs&#65289;&#22312;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#21462;&#24471;&#20102;&#24456;&#22823;&#25104;&#23601;&#12290;&#23613;&#31649;&#23427;&#20204;&#24615;&#33021;&#24456;&#39640;&#65292;&#20294;&#36824;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#21033;&#29992;&#24378;&#21152;&#32467;&#26500;&#23436;&#25972;&#24615;&#30340;&#32479;&#35745;&#23646;&#24615;&#26469;&#25552;&#39640;&#26679;&#26412;&#20445;&#30495;&#24230;&#65292;&#22914;&#21508;&#21521;&#21516;&#24615;&#12290;&#20165;&#20943;&#23567;&#21152;&#24615;&#21644;&#39044;&#27979;&#22122;&#22768;&#20043;&#38388;&#30340;&#22343;&#26041;&#35823;&#24046;&#24182;&#19981;&#33021;&#24378;&#21152;&#23545;&#39044;&#27979;&#22122;&#22768;&#20026;&#21508;&#21521;&#21516;&#24615;&#30340;&#32422;&#26463;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21463;&#21040;&#21160;&#21147;&#65292;&#21033;&#29992;&#21152;&#24615;&#22122;&#22768;&#30340;&#21508;&#21521;&#21516;&#24615;&#20316;&#20026;&#30446;&#26631;&#20989;&#25968;&#30340;&#32422;&#26463;&#26469;&#22686;&#24378;DDPMs&#30340;&#20445;&#30495;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#31616;&#21333;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;DDPM&#21464;&#20307;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22235;&#20010;&#21512;&#25104;2D&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#20197;&#21450;&#26080;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#27491;&#22914;&#32467;&#26524;&#25152;&#31034;&#65292;&#36825;&#31181;&#32422;&#26463;&#30340;&#25972;&#21512;&#25913;&#21892;&#20102;2D&#25968;&#25454;&#38598;&#30340;&#20445;&#30495;&#24230;&#25351;&#26631;Precision&#21644;Density&#20197;&#21450;&#26080;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16790v1 Announce Type: new  Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have accomplished much in the realm of generative AI. Despite their high performance, there is room for improvement, especially in terms of sample fidelity by utilizing statistical properties that impose structural integrity, such as isotropy. Minimizing the mean squared error between the additive and predicted noise alone does not impose constraints on the predicted noise to be isotropic. Thus, we were motivated to utilize the isotropy of the additive noise as a constraint on the objective function to enhance the fidelity of DDPMs. Our approach is simple and can be applied to any DDPM variant. We validate our approach by presenting experiments conducted on four synthetic 2D datasets as well as on unconditional image generation. As demonstrated by the results, the incorporation of this constraint improves the fidelity metrics, Precision and Density for the 2D datasets as well as for the un
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;ObjectDR&#65292;&#21033;&#29992;&#23545;&#35937;-centric&#30340;&#22495;&#38543;&#26426;&#21270;&#21512;&#25104;&#21333;&#35270;&#22270;3D&#24418;&#29366;&#37325;&#24314;&#20013;&#32570;&#20047;&#30340;&#37197;&#23545;&#25968;&#25454;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#21644;&#35299;&#32806;&#26694;&#26550;&#26469;&#29983;&#25104;&#21644;&#20445;&#30041;&#23545;&#35937;&#36718;&#24275;&#20197;&#21450;&#24191;&#27867;&#21464;&#21270;&#30340;&#25968;&#25454;&#65292;&#20174;&#32780;&#20026;&#22521;&#35757;&#27169;&#22411;&#25429;&#25417;&#22495;&#19981;&#21464;&#24615;&#20960;&#20309;&#24418;&#29366;&#12290;</title><link>https://arxiv.org/abs/2403.14539</link><description>&lt;p&gt;
Object-Centric Domain Randomization&#29992;&#20110;&#37326;&#22806;3D&#24418;&#29366;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Object-Centric Domain Randomization for 3D Shape Reconstruction in the Wild
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14539
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;ObjectDR&#65292;&#21033;&#29992;&#23545;&#35937;-centric&#30340;&#22495;&#38543;&#26426;&#21270;&#21512;&#25104;&#21333;&#35270;&#22270;3D&#24418;&#29366;&#37325;&#24314;&#20013;&#32570;&#20047;&#30340;&#37197;&#23545;&#25968;&#25454;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#21644;&#35299;&#32806;&#26694;&#26550;&#26469;&#29983;&#25104;&#21644;&#20445;&#30041;&#23545;&#35937;&#36718;&#24275;&#20197;&#21450;&#24191;&#27867;&#21464;&#21270;&#30340;&#25968;&#25454;&#65292;&#20174;&#32780;&#20026;&#22521;&#35757;&#27169;&#22411;&#25429;&#25417;&#22495;&#19981;&#21464;&#24615;&#20960;&#20309;&#24418;&#29366;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#35270;&#22270;3D&#24418;&#29366;&#22312;&#37326;&#22806;&#30340;&#37325;&#24314;&#38754;&#20020;&#30340;&#26368;&#22823;&#25361;&#25112;&#20043;&#19968;&#26159;&#26469;&#33258;&#30495;&#23454;&#29615;&#22659;&#20013;&#30340;&lt;3D&#24418;&#29366;&#65292;2D&#22270;&#20687;&gt;-&#37197;&#23545;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#12290;&#21463;&#22495;&#38543;&#26426;&#21270;&#24341;&#20154;&#27880;&#30446;&#30340;&#25104;&#23601;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ObjectDR&#65292;&#36890;&#36807;&#23545;&#23545;&#35937;&#22806;&#35266;&#21644;&#32972;&#26223;&#30340;&#35270;&#35273;&#21464;&#21270;&#36827;&#34892;&#38543;&#26426;&#20223;&#30495;&#65292;&#21512;&#25104;&#36825;&#31181;&#37197;&#23545;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#21512;&#25104;&#26694;&#26550;&#21033;&#29992;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;ControlNet&#65289;&#29983;&#25104;&#31526;&#21512;&#31354;&#38388;&#26465;&#20214;&#65288;&#20363;&#22914;2.5D&#33609;&#22270;&#65289;&#30340;&#22270;&#20687;&#65292;&#36825;&#20123;&#26465;&#20214;&#21487;&#20197;&#36890;&#36807;&#20174;&#23545;&#35937;&#38598;&#21512;&#65288;&#20363;&#22914;Objaverse-XL&#65289;&#30340;&#28210;&#26579;&#36807;&#31243;&#33719;&#24471;3D&#24418;&#29366;&#12290;&#20026;&#20102;&#27169;&#25311;&#22810;&#26679;&#21270;&#30340;&#21464;&#21270;&#21516;&#26102;&#20445;&#30041;&#23884;&#20837;&#31354;&#38388;&#26465;&#20214;&#20013;&#30340;&#23545;&#35937;&#36718;&#24275;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#20010;&#21033;&#29992;&#21021;&#22987;&#23545;&#35937;&#25351;&#23548;&#30340;&#35299;&#32806;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14539v1 Announce Type: cross  Abstract: One of the biggest challenges in single-view 3D shape reconstruction in the wild is the scarcity of &lt;3D shape, 2D image&gt;-paired data from real-world environments. Inspired by remarkable achievements via domain randomization, we propose ObjectDR which synthesizes such paired data via a random simulation of visual variations in object appearances and backgrounds. Our data synthesis framework exploits a conditional generative model (e.g., ControlNet) to generate images conforming to spatial conditions such as 2.5D sketches, which are obtainable through a rendering process of 3D shapes from object collections (e.g., Objaverse-XL). To simulate diverse variations while preserving object silhouettes embedded in spatial conditions, we also introduce a disentangled framework which leverages an initial object guidance. After synthesizing a wide range of data, we pre-train a model on them so that it learns to capture a domain-invariant geometry p
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#22312;ImageNet&#19978;&#30340;&#22810;&#31181;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#65292;&#21457;&#29616;&#34429;&#28982;&#26377;&#29702;&#35770;&#21162;&#21147;&#65292;&#20294;&#23454;&#36341;&#20013;&#23578;&#26410;&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#30340;&#35299;&#24320;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#21738;&#20123;&#20272;&#35745;&#22120;&#22312;&#29305;&#23450;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20026;&#20174;&#19994;&#32773;&#25552;&#20379;&#35265;&#35299;&#24182;&#25351;&#23548;&#26410;&#26469;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2402.19460</link><description>&lt;p&gt;
&#20026;&#26631;&#20934;&#21270;&#30340;&#20219;&#21153;&#19987;&#38376;&#25351;&#23450;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65306;&#19987;&#38376;&#30340;&#19981;&#30830;&#23450;&#24615;&#29992;&#20110;&#19987;&#38376;&#30340;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19460
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#22312;ImageNet&#19978;&#30340;&#22810;&#31181;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#65292;&#21457;&#29616;&#34429;&#28982;&#26377;&#29702;&#35770;&#21162;&#21147;&#65292;&#20294;&#23454;&#36341;&#20013;&#23578;&#26410;&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#30340;&#35299;&#24320;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#21738;&#20123;&#20272;&#35745;&#22120;&#22312;&#29305;&#23450;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20026;&#20174;&#19994;&#32773;&#25552;&#20379;&#35265;&#35299;&#24182;&#25351;&#23548;&#26410;&#26469;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#26366;&#32463;&#26159;&#19968;&#20010;&#29420;&#31435;&#30340;&#20219;&#21153;&#65292;&#24050;&#32463;&#21457;&#23637;&#25104;&#20026;&#19968;&#20010;&#21253;&#21547;&#39044;&#27979;&#25233;&#21046;&#12289;&#36234;&#30028;&#26816;&#27979;&#20197;&#21450;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#20869;&#30340;&#20219;&#21153;&#35889;&#31995;&#12290;&#26368;&#26032;&#30340;&#30446;&#26631;&#26159;&#35299;&#24320;&#19981;&#30830;&#23450;&#24615;&#65306;&#26500;&#24314;&#22810;&#20010;&#20272;&#35745;&#22120;&#65292;&#27599;&#20010;&#37117;&#19987;&#38376;&#23450;&#21046;&#20110;&#19968;&#20010;&#29305;&#23450;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#26377;&#22823;&#37327;&#19981;&#21516;&#24847;&#22270;&#30340;&#26368;&#26032;&#36827;&#23637;&#8212;&#8212;&#36825;&#20123;&#24448;&#24448;&#23436;&#20840;&#20559;&#31163;&#23454;&#38469;&#34892;&#20026;&#12290;&#26412;&#25991;&#22312;ImageNet&#19978;&#23545;&#22810;&#31181;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#26377;&#30528;&#39047;&#26377;&#24076;&#26395;&#30340;&#29702;&#35770;&#21162;&#21147;&#65292;&#23454;&#36341;&#20013;&#20173;&#26410;&#23454;&#29616;&#35299;&#24320;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#21738;&#20123;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#22312;&#21738;&#20123;&#29305;&#23450;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20026;&#20174;&#19994;&#32773;&#25552;&#20379;&#35265;&#35299;&#24182;&#24341;&#23548;&#26410;&#26469;&#30740;&#31350;&#26397;&#30528;&#22522;&#20110;&#20219;&#21153;&#21644;&#35299;&#24320;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#21457;&#23637;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312; https://github.com/bmucsanyi/bud &#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19460v1 Announce Type: new  Abstract: Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one task. Hence, there is a plethora of recent advances with different intentions - that often entirely deviate from practical behavior. This paper conducts a comprehensive evaluation of numerous uncertainty estimators across diverse tasks on ImageNet. We find that, despite promising theoretical endeavors, disentanglement is not yet achieved in practice. Additionally, we reveal which uncertainty estimators excel at which specific tasks, providing insights for practitioners and guiding future research toward task-centric and disentangled uncertainty estimation methods. Our code is available at https://github.com/bmucsanyi/bud.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#26469;&#26356;&#24555;&#12289;&#26356;&#21487;&#25193;&#23637;&#22320;&#35745;&#31639;&#23545;&#31216;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65292;&#20854;&#20013;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#30697;&#38453;&#33609;&#22270;&#26469;&#35745;&#31639;&#21021;&#22987;&#20302;&#31209;&#36755;&#20837;&#30697;&#38453;&#65292;&#21478;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#26464;&#26438;&#24471;&#20998;&#37319;&#26679;&#26469;&#36817;&#20284;&#35299;&#20915;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#30340;&#22270;&#32858;&#31867;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.08134</link><description>&lt;p&gt;
&#23545;&#31216;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#30340;&#38543;&#26426;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Randomized Algorithms for Symmetric Nonnegative Matrix Factorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08134
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#26469;&#26356;&#24555;&#12289;&#26356;&#21487;&#25193;&#23637;&#22320;&#35745;&#31639;&#23545;&#31216;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65292;&#20854;&#20013;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#30697;&#38453;&#33609;&#22270;&#26469;&#35745;&#31639;&#21021;&#22987;&#20302;&#31209;&#36755;&#20837;&#30697;&#38453;&#65292;&#21478;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#26464;&#26438;&#24471;&#20998;&#37319;&#26679;&#26469;&#36817;&#20284;&#35299;&#20915;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#30340;&#22270;&#32858;&#31867;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;SymNMF&#65289;&#26159;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#31181;&#23558;&#23545;&#31216;&#30697;&#38453;&#36817;&#20284;&#34920;&#31034;&#20026;&#38750;&#36127;&#12289;&#20302;&#31209;&#30697;&#38453;&#21450;&#20854;&#36716;&#32622;&#30340;&#25216;&#26415;&#12290;&#20026;&#20102;&#35774;&#35745;&#26356;&#24555;&#12289;&#26356;&#21487;&#25193;&#23637;&#30340;SymNMF&#31639;&#27861;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;&#31532;&#19968;&#31181;&#31639;&#27861;&#20351;&#29992;&#38543;&#26426;&#30697;&#38453;&#33609;&#22270;&#35745;&#31639;&#21021;&#22987;&#30340;&#20302;&#31209;&#36755;&#20837;&#30697;&#38453;&#65292;&#24182;&#21033;&#29992;&#35813;&#36755;&#20837;&#36805;&#36895;&#35745;&#31639;SymNMF&#12290;&#31532;&#20108;&#31181;&#31639;&#27861;&#20351;&#29992;&#38543;&#26426;&#26464;&#26438;&#24471;&#20998;&#37319;&#26679;&#26469;&#36817;&#20284;&#35299;&#20915;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#12290;&#35768;&#22810;&#25104;&#21151;&#30340;SymNMF&#26041;&#27861;&#20381;&#36182;&#20110;&#65288;&#36817;&#20284;&#65289;&#35299;&#20915;&#19968;&#31995;&#21015;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#26464;&#26438;&#24471;&#20998;&#37319;&#26679;&#21487;&#20197;&#20197;&#39640;&#27010;&#29575;&#36817;&#20284;&#35299;&#20915;&#38750;&#36127;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#65292;&#36798;&#21040;&#25152;&#36873;&#31934;&#24230;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#30340;&#22270;&#32858;&#31867;&#20219;&#21153;&#20013;&#65292;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symmetric Nonnegative Matrix Factorization (SymNMF) is a technique in data analysis and machine learning that approximates a symmetric matrix with a product of a nonnegative, low-rank matrix and its transpose. To design faster and more scalable algorithms for SymNMF we develop two randomized algorithms for its computation. The first algorithm uses randomized matrix sketching to compute an initial low-rank input matrix and proceeds to use this input to rapidly compute a SymNMF. The second algorithm uses randomized leverage score sampling to approximately solve constrained least squares problems. Many successful methods for SymNMF rely on (approximately) solving sequences of constrained least squares problems. We prove theoretically that leverage score sampling can approximately solve nonnegative least squares problems to a chosen accuracy with high probability. Finally we demonstrate that both methods work well in practice by applying them to graph clustering tasks on large real world d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26412;&#30340;&#26368;&#22823;&#29109;&#28304;&#20998;&#24067;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#20808;&#20445;&#30041;&#19981;&#30830;&#23450;&#24615;&#26469;&#36873;&#25321;&#21512;&#36866;&#30340;&#28304;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20999;&#29255;-&#29926;&#30707;&#22374;&#26031;&#22374;&#36317;&#31163;&#23545;&#25968;&#25454;&#38598;&#21644;&#27169;&#25311;&#36827;&#34892;&#34913;&#37327;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#30340;&#27169;&#25311;&#22120;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#26356;&#39640;&#29109;&#30340;&#28304;&#20998;&#24067;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#25311;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07808</link><description>&lt;p&gt;
Sourcerer: &#22522;&#20110;&#26679;&#26412;&#30340;&#26368;&#22823;&#29109;&#28304;&#20998;&#24067;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26412;&#30340;&#26368;&#22823;&#29109;&#28304;&#20998;&#24067;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#20808;&#20445;&#30041;&#19981;&#30830;&#23450;&#24615;&#26469;&#36873;&#25321;&#21512;&#36866;&#30340;&#28304;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20999;&#29255;-&#29926;&#30707;&#22374;&#26031;&#22374;&#36317;&#31163;&#23545;&#25968;&#25454;&#38598;&#21644;&#27169;&#25311;&#36827;&#34892;&#34913;&#37327;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#30340;&#27169;&#25311;&#22120;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#26356;&#39640;&#29109;&#30340;&#28304;&#20998;&#24067;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#25311;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#24314;&#27169;&#24212;&#29992;&#36890;&#24120;&#38656;&#35201;&#20272;&#35745;&#19982;&#35266;&#27979;&#25968;&#25454;&#38598;&#19968;&#33268;&#30340;&#21442;&#25968;&#20998;&#24067;&#65292;&#34987;&#31216;&#20026;&#28304;&#20998;&#24067;&#20272;&#35745;&#30340;&#25512;&#29702;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#38382;&#39064;&#21487;&#33021;&#26159;&#19981;&#36866;&#23450;&#30340;&#65292;&#22240;&#20026;&#35768;&#22810;&#19981;&#21516;&#30340;&#28304;&#20998;&#24067;&#21487;&#33021;&#20135;&#29983;&#30456;&#21516;&#30340;&#25968;&#25454;&#20998;&#24067;&#19968;&#33268;&#30340;&#27169;&#25311;&#32467;&#26524;&#12290;&#20026;&#20102;&#22312;&#20247;&#22810;&#21516;&#26679;&#26377;&#25928;&#30340;&#28304;&#20013;&#20570;&#20986;&#26377;&#21407;&#21017;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30446;&#26631;&#26368;&#22823;&#29109;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#21363;&#20248;&#20808;&#20445;&#30041;&#23613;&#21487;&#33021;&#22810;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23436;&#20840;&#22522;&#20110;&#26679;&#26412;&#65292;&#21033;&#29992;&#20999;&#29255;-&#29926;&#30707;&#22374;&#26031;&#22374;&#36317;&#31163;&#26469;&#34913;&#37327;&#25968;&#25454;&#38598;&#19982;&#27169;&#25311;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#22240;&#27492;&#36866;&#29992;&#20110;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#27169;&#25311;&#22120;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#20219;&#21153;&#19978;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#34920;&#26126;&#23427;&#21487;&#20197;&#24674;&#22797;&#20855;&#26377;&#26356;&#39640;&#29109;&#30340;&#28304;&#20998;&#24067;&#65292;&#32780;&#19981;&#29306;&#29298;&#27169;&#25311;&#30340;&#20934;&#30830;&#24615;&#12290;&#26368;&#21518;&#65292;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#25512;&#26029;&#28304;&#20998;&#24067;...
&lt;/p&gt;
&lt;p&gt;
Scientific modeling applications often require estimating a distribution of parameters consistent with a dataset of observations - an inference task also known as source distribution estimation. This problem can be ill-posed, however, since many different source distributions might produce the same distribution of data-consistent simulations. To make a principled choice among many equally valid sources, we propose an approach which targets the maximum entropy distribution, i.e., prioritizes retaining as much uncertainty as possible. Our method is purely sample-based - leveraging the Sliced-Wasserstein distance to measure the discrepancy between the dataset and simulations - and thus suitable for simulators with intractable likelihoods. We benchmark our method on several tasks, and show that it can recover source distributions with substantially higher entropy without sacrificing the fidelity of the simulations. Finally, to demonstrate the utility of our approach, we infer source distri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#24357;&#25955;&#30913;&#20849;&#25391;&#25104;&#20687;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#24494;&#32467;&#26500;&#26144;&#23556;&#12289;&#32420;&#32500;&#26463;&#25551;&#35760;&#12289;&#30333;&#36136;&#32420;&#32500;&#26463;&#20998;&#26512;&#20197;&#21450;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#21327;&#35843;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#29616;&#26377;&#26041;&#27861;&#30340;&#24635;&#32467;&#65292;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#20027;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.00019</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#24357;&#25955;&#30913;&#20849;&#25391;&#25104;&#20687;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Diffusion MRI with Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#24357;&#25955;&#30913;&#20849;&#25391;&#25104;&#20687;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#24494;&#32467;&#26500;&#26144;&#23556;&#12289;&#32420;&#32500;&#26463;&#25551;&#35760;&#12289;&#30333;&#36136;&#32420;&#32500;&#26463;&#20998;&#26512;&#20197;&#21450;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#21327;&#35843;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#29616;&#26377;&#26041;&#27861;&#30340;&#24635;&#32467;&#65292;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24357;&#25955;&#21152;&#26435;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;dMRI&#65289;&#20855;&#26377;&#38750;&#20405;&#20837;&#24615;&#35780;&#20272;&#22823;&#33041;&#24494;&#32467;&#26500;&#21644;&#32467;&#26500;&#36830;&#25509;&#30340;&#29420;&#29305;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20998;&#26512;dMRI&#25968;&#25454;&#20197;&#25552;&#21462;&#20020;&#24202;&#21644;&#31185;&#23398;&#30446;&#30340;&#30340;&#26377;&#29992;&#20449;&#24687;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290; dMRI&#27979;&#37327;&#36890;&#24120;&#21463;&#21040;&#24378;&#22122;&#22768;&#21644;&#20266;&#24433;&#30340;&#24178;&#25200;&#65292;&#25968;&#25454;&#20013;&#36890;&#24120;&#23384;&#22312;&#39640;&#30340;&#20250;&#35805;&#38388;&#21644;&#25195;&#25551;&#32773;&#38388;&#24322;&#36136;&#24615;&#65292;&#20197;&#21450;&#22823;&#33041;&#32467;&#26500;&#30340;&#30456;&#24403;&#22823;&#30340;&#20010;&#20307;&#38388;&#21464;&#24322;&#65292;&#24182;&#19988;&#27979;&#37327;&#21644;&#24863;&#20852;&#36259;&#29616;&#35937;&#20043;&#38388;&#30340;&#20851;&#31995;&#21487;&#33021;&#38750;&#24120;&#22797;&#26434;&#12290;&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;dMRI&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#22810;&#12290;&#26412;&#25991;&#26088;&#22312;&#35780;&#20272;&#36825;&#20123;&#23581;&#35797;&#65292;&#37325;&#28857;&#20851;&#27880;&#24050;&#32463;&#35299;&#20915;&#20102;&#24494;&#32467;&#26500;&#26144;&#23556;&#12289;&#32420;&#32500;&#26463;&#25551;&#35760;&#12289;&#30333;&#36136;&#32420;&#32500;&#26463;&#20998;&#26512;&#20197;&#21450;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#21327;&#35843;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#24635;&#32467;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#20027;&#35201;&#21457;&#29616;&#12289;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion-weighted magnetic resonance imaging (dMRI) offers unique capabilities such as noninvasive assessment of brain's micro-structure and structural connectivity. However, analyzing the dMRI data to extract useful information for clinical and scientific purposes is challenging. The dMRI measurements often suffer from strong noise and artifacts, there is usually high inter-session and inter-scanner heterogeneity in the data and considerable inter-subject variability in brain structure, and the relationship between measurements and the phenomena of interest can be highly complex. Recent years have witnessed increasing use of machine learning methods for dMRI analysis. This manuscript aims to assess these efforts, with a focus on methods that have addressed micro-structure mapping, tractography, white matter tract analysis, as well as data preprocessing and harmonization. We summarize the main findings, strengths, and weaknesses of the existing methods and suggest topics for future re
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DeepInception&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#35282;&#33394;&#25198;&#28436;&#33021;&#21147;&#26500;&#24314;&#26032;&#39062;&#30340;&#23884;&#22871;&#22330;&#26223;&#65292;&#25104;&#21151;&#20652;&#30496;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#20026;&#30772;&#35299;&#32773;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;DeepInception&#22312;&#30772;&#35299;&#25104;&#21151;&#29575;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#24182;&#25581;&#31034;&#20102;&#24320;&#28304;&#21644;&#38381;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#20851;&#38190;&#24369;&#28857;&#12290;</title><link>https://arxiv.org/abs/2311.03191</link><description>&lt;p&gt;
DeepInception: &#20652;&#30496;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#20026;&#30772;&#35299;&#32773;
&lt;/p&gt;
&lt;p&gt;
DeepInception: Hypnotize Large Language Model to Be Jailbreaker
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DeepInception&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#35282;&#33394;&#25198;&#28436;&#33021;&#21147;&#26500;&#24314;&#26032;&#39062;&#30340;&#23884;&#22871;&#22330;&#26223;&#65292;&#25104;&#21151;&#20652;&#30496;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#20026;&#30772;&#35299;&#32773;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;DeepInception&#22312;&#30772;&#35299;&#25104;&#21151;&#29575;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#24182;&#25581;&#31034;&#20102;&#24320;&#28304;&#21644;&#38381;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#20851;&#38190;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#21463;&#21040;&#30772;&#35299;&#25915;&#20987;&#65292;&#20351;&#24471;&#23433;&#20840;&#25514;&#26045;&#26080;&#25928;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#30772;&#35299;&#30740;&#31350;&#36890;&#24120;&#37319;&#29992;&#26292;&#21147;&#20248;&#21270;&#25110;&#39640;&#35745;&#31639;&#25104;&#26412;&#30340;&#22806;&#25512;&#26041;&#27861;&#65292;&#36825;&#21487;&#33021;&#24182;&#19981;&#23454;&#38469;&#25110;&#26377;&#25928;&#12290;&#26412;&#25991;&#21463;&#21040;&#20197;&#31859;&#23572;&#26684;&#25289;&#22982;&#23454;&#39564;&#20026;&#28789;&#24863;&#65292;&#20851;&#20110;&#26435;&#23041;&#21147;&#37327;&#23545;&#20110;&#24341;&#21457;&#26377;&#23475;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;DeepInception&#65292;&#21487;&#20197;&#36731;&#26494;&#22320;&#20652;&#30496;LLM&#25104;&#20026;&#30772;&#35299;&#32773;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;DeepInception&#21033;&#29992;LLM&#30340;&#35282;&#33394;&#25198;&#28436;&#33021;&#21147;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#23884;&#22871;&#22330;&#26223;&#26469;&#34892;&#20026;&#65292;&#23454;&#29616;&#20102;&#22312;&#27491;&#24120;&#22330;&#26223;&#19979;&#36867;&#36991;&#20351;&#29992;&#25511;&#21046;&#30340;&#33258;&#36866;&#24212;&#26041;&#24335;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;DeepInception&#22312;&#30772;&#35299;&#25104;&#21151;&#29575;&#26041;&#38754;&#19982;&#20197;&#24448;&#30340;&#26041;&#27861;&#31454;&#20105;&#21147;&#30456;&#24403;&#65292;&#24182;&#21487;&#20197;&#22312;&#21518;&#32493;&#20132;&#20114;&#20013;&#23454;&#29616;&#25345;&#32493;&#30340;&#30772;&#35299;&#65292;&#25581;&#31034;&#20102;&#24320;&#28304;&#21644;&#38381;&#28304;LLM&#30340;&#33258;&#22833;&#20851;&#38190;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite remarkable success in various applications, large language models (LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails void. However, previous studies for jailbreaks usually resort to brute-force optimization or extrapolations of a high computation cost, which might not be practical or effective. In this paper, inspired by the Milgram experiment w.r.t. the authority power for inciting harmfulness, we disclose a lightweight method, termed DeepInception, which can easily hypnotize LLM to be a jailbreaker. Specifically, DeepInception leverages the personification ability of LLM to construct a novel nested scene to behave, which realizes an adaptive way to escape the usage control in a normal scenario. Empirically, our DeepInception can achieve competitive jailbreak success rates with previous counterparts and realize a continuous jailbreak in subsequent interactions, which reveals the critical weakness of self-losing on both open and closed-source LLMs l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23041;&#32961;&#12290;&#36890;&#36807;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#21253;&#25324;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#65292;&#25991;&#31456;&#25581;&#31034;&#20102;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#21333;&#35302;&#21457;&#25915;&#20987;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.15295</link><description>&lt;p&gt;
&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#65306;&#26356;&#22810;&#35302;&#21457;&#22120;&#65292;&#26356;&#22810;&#23041;&#32961;
&lt;/p&gt;
&lt;p&gt;
Multi-Trigger Backdoor Attacks: More Triggers, More Threats. (arXiv:2401.15295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23041;&#32961;&#12290;&#36890;&#36807;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#21253;&#25324;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#65292;&#25991;&#31456;&#25581;&#31034;&#20102;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#21333;&#35302;&#21457;&#25915;&#20987;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#38376;&#25915;&#20987;&#24050;&#32463;&#25104;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#65288;&#39044;&#65289;&#35757;&#32451;&#21644;&#37096;&#32626;&#30340;&#20027;&#35201;&#23041;&#32961;&#12290;&#23613;&#31649;&#21518;&#38376;&#25915;&#20987;&#22312;&#19968;&#20123;&#30740;&#31350;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#25506;&#35752;&#65292;&#20294;&#20854;&#20013;&#22823;&#37096;&#20998;&#37117;&#38598;&#20013;&#22312;&#20351;&#29992;&#21333;&#20010;&#31867;&#22411;&#30340;&#35302;&#21457;&#22120;&#26469;&#27745;&#26579;&#25968;&#25454;&#38598;&#30340;&#21333;&#35302;&#21457;&#25915;&#20987;&#19978;&#12290;&#21487;&#20197;&#35828;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#21518;&#38376;&#25915;&#20987;&#21487;&#33021;&#26356;&#21152;&#22797;&#26434;&#65292;&#20363;&#22914;&#65292;&#21516;&#19968;&#25968;&#25454;&#38598;&#21487;&#33021;&#23384;&#22312;&#22810;&#20010;&#23545;&#25163;&#65292;&#22914;&#26524;&#35813;&#25968;&#25454;&#38598;&#20855;&#26377;&#36739;&#39640;&#30340;&#20215;&#20540;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#35302;&#21457;&#25915;&#20987;&#35774;&#32622;&#19979;&#21518;&#38376;&#25915;&#20987;&#30340;&#23454;&#38469;&#23041;&#32961;&#65292;&#22810;&#20010;&#23545;&#25163;&#21033;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#35302;&#21457;&#22120;&#26469;&#27745;&#26579;&#21516;&#19968;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#25552;&#20986;&#21644;&#30740;&#31350;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#36825;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#30340;&#37325;&#35201;&#35748;&#35782;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21333;&#35302;&#21457;&#25915;&#20987;&#24448;&#24448;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Backdoor attacks have emerged as a primary threat to (pre-)training and deployment of deep neural networks (DNNs). While backdoor attacks have been extensively studied in a body of works, most of them were focused on single-trigger attacks that poison a dataset using a single type of trigger. Arguably, real-world backdoor attacks can be much more complex, e.g., the existence of multiple adversaries for the same dataset if it is of high value. In this work, we investigate the practical threat of backdoor attacks under the setting of \textbf{multi-trigger attacks} where multiple adversaries leverage different types of triggers to poison the same dataset. By proposing and investigating three types of multi-trigger attacks, including parallel, sequential, and hybrid attacks, we provide a set of important understandings of the coexisting, overwriting, and cross-activating effects between different triggers on the same dataset. Moreover, we show that single-trigger attacks tend to cause over
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#21551;&#29992;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26500;&#24314;&#26412;&#22320;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#20445;&#35777;&#24191;&#27867;&#31867;&#21035;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#21160;&#21147;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#12290;&#35813;&#26041;&#27861;&#26159;&#39640;&#25928;&#30340;&#65292;&#23545;&#21442;&#32771;&#25511;&#21046;&#22120;&#30340;&#24178;&#39044;&#26368;&#23567;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#21644;&#27604;&#36739;&#26696;&#20363;&#23637;&#31034;&#20102;&#20854;&#21151;&#25928;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14907</link><description>&lt;p&gt;
&#23398;&#20064;&#26412;&#22320;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#20197;&#23454;&#29616;&#28151;&#21512;&#31995;&#32479;&#30340;&#23433;&#20840;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Learning Local Control Barrier Functions for Safety Control of Hybrid Systems. (arXiv:2401.14907v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14907
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#21551;&#29992;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26500;&#24314;&#26412;&#22320;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65292;&#20197;&#20445;&#35777;&#24191;&#27867;&#31867;&#21035;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#21160;&#21147;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#12290;&#35813;&#26041;&#27861;&#26159;&#39640;&#25928;&#30340;&#65292;&#23545;&#21442;&#32771;&#25511;&#21046;&#22120;&#30340;&#24178;&#39044;&#26368;&#23567;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#21644;&#27604;&#36739;&#26696;&#20363;&#23637;&#31034;&#20102;&#20854;&#21151;&#25928;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#21160;&#21147;&#31995;&#32479;&#22312;&#23454;&#38469;&#30340;&#26426;&#22120;&#20154;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#24120;&#28041;&#21450;&#36830;&#32493;&#29366;&#24577;&#21644;&#31163;&#25955;&#29366;&#24577;&#20999;&#25442;&#12290;&#23433;&#20840;&#24615;&#26159;&#28151;&#21512;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#39318;&#35201;&#20851;&#27880;&#28857;&#12290;&#29616;&#26377;&#30340;&#28151;&#21512;&#31995;&#32479;&#30340;&#23433;&#20840;&#20851;&#38190;&#25511;&#21046;&#26041;&#27861;&#35201;&#20040;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#65292;&#23545;&#31995;&#32479;&#24615;&#33021;&#26377;&#25439;&#65292;&#35201;&#20040;&#20165;&#36866;&#29992;&#20110;&#23567;&#35268;&#27169;&#31995;&#32479;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#21551;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#26412;&#22320;&#25511;&#21046;&#23631;&#38556;&#20989;&#25968;&#65288;CBFs&#65289;&#65292;&#20197;&#20445;&#35777;&#24191;&#27867;&#31867;&#21035;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#21160;&#21147;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#12290;&#26368;&#32456;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#23433;&#20840;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;CBF&#20999;&#25442;&#25511;&#21046;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#65292;&#23545;&#20219;&#20309;&#21442;&#32771;&#25511;&#21046;&#22120;&#30340;&#24178;&#39044;&#26368;&#23567;&#65292;&#24182;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#31995;&#32479;&#12290;&#36890;&#36807;&#20004;&#20010;&#26426;&#22120;&#20154;&#31034;&#20363;&#65288;&#21253;&#25324;&#39640;&#32500;&#33258;&#20027;&#36187;&#36710;&#26696;&#20363;&#65289;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26694;&#26550;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#24182;&#19982;&#20854;&#20182;&#22522;&#20110;CBF&#30340;&#26041;&#27861;&#21644;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#23637;&#31034;&#20102;&#20854;&#21151;&#25928;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hybrid dynamical systems are ubiquitous as practical robotic applications often involve both continuous states and discrete switchings. Safety is a primary concern for hybrid robotic systems. Existing safety-critical control approaches for hybrid systems are either computationally inefficient, detrimental to system performance, or limited to small-scale systems. To amend these drawbacks, in this paper, we propose a learningenabled approach to construct local Control Barrier Functions (CBFs) to guarantee the safety of a wide class of nonlinear hybrid dynamical systems. The end result is a safe neural CBFbased switching controller. Our approach is computationally efficient, minimally invasive to any reference controller, and applicable to large-scale systems. We empirically evaluate our framework and demonstrate its efficacy and flexibility through two robotic examples including a high-dimensional autonomous racing case, against other CBF-based approaches and model predictive control.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#26500;&#25968;&#25454;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#21512;&#20316;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#20986;&#27599;&#20010;&#23458;&#25143;&#31471;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21457;&#29616;&#21482;&#26377;&#19982;&#25317;&#26377;&#26356;&#22810;&#35757;&#32451;&#25968;&#25454;&#21644;&#30456;&#20284;&#25968;&#25454;&#20998;&#24067;&#30340;&#23458;&#25143;&#31471;&#21512;&#20316;&#65292;&#25165;&#33021;&#25913;&#21892;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#26681;&#25454;&#36825;&#19968;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#23618;&#27425;&#32858;&#31867;&#30340;&#21512;&#20316;&#35757;&#32451;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.13236</link><description>&lt;p&gt;
&#22914;&#20309;&#21512;&#20316;&#65306;&#26397;&#30528;&#26368;&#22823;&#21270;&#24322;&#26500;&#25968;&#25454;&#32852;&#37030;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#33021;&#36808;&#36827;
&lt;/p&gt;
&lt;p&gt;
How to Collaborate: Towards Maximizing the Generalization Performance in Cross-Silo Federated Learning. (arXiv:2401.13236v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#26500;&#25968;&#25454;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#21512;&#20316;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#20986;&#27599;&#20010;&#23458;&#25143;&#31471;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21457;&#29616;&#21482;&#26377;&#19982;&#25317;&#26377;&#26356;&#22810;&#35757;&#32451;&#25968;&#25454;&#21644;&#30456;&#20284;&#25968;&#25454;&#20998;&#24067;&#30340;&#23458;&#25143;&#31471;&#21512;&#20316;&#65292;&#25165;&#33021;&#25913;&#21892;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#26681;&#25454;&#36825;&#19968;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#23618;&#27425;&#32858;&#31867;&#30340;&#21512;&#20316;&#35757;&#32451;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20316;&#20026;&#19968;&#31181;&#20445;&#25252;&#38544;&#31169;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#26694;&#26550;&#65292;&#21560;&#24341;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20851;&#27880;&#20132;&#21449;&#25968;&#25454;&#28304;&#30340;FL&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#22312;&#35757;&#32451;&#21518;&#25104;&#20026;&#27169;&#22411;&#25152;&#26377;&#32773;&#65292;&#24182;&#19988;&#21482;&#20851;&#24515;&#27169;&#22411;&#22312;&#26412;&#22320;&#25968;&#25454;&#19978;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#30001;&#20110;&#25968;&#25454;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#35201;&#27714;&#25152;&#26377;&#23458;&#25143;&#31471;&#21442;&#21152;&#21333;&#19968;&#30340;FL&#35757;&#32451;&#36807;&#31243;&#21487;&#33021;&#20250;&#23548;&#33268;&#27169;&#22411;&#24615;&#33021;&#19979;&#38477;&#12290;&#20026;&#20102;&#35843;&#26597;&#21512;&#20316;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20102;&#27599;&#20010;&#23458;&#25143;&#31471;&#22312;&#19982;&#20854;&#20182;&#23458;&#25143;&#31471;&#21512;&#20316;&#25110;&#29420;&#31435;&#35757;&#32451;&#26102;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20165;&#36890;&#36807;&#19982;&#20855;&#26377;&#26356;&#22810;&#35757;&#32451;&#25968;&#25454;&#21644;&#30456;&#20284;&#25968;&#25454;&#20998;&#24067;&#30340;&#20854;&#20182;&#23458;&#25143;&#31471;&#21512;&#20316;&#65292;&#21487;&#20197;&#25913;&#21892;&#23458;&#25143;&#31471;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#23558;&#23458;&#25143;&#31471;&#20998;&#25104;&#22810;&#20010;&#21512;&#20316;&#32452;&#26469;&#21046;&#23450;&#23458;&#25143;&#31471;&#25928;&#29992;&#26368;&#22823;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#32858;&#31867;&#30340;&#21512;&#20316;&#35757;&#32451;&#65288;HCCT&#65289;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) has attracted vivid attention as a privacy-preserving distributed learning framework. In this work, we focus on cross-silo FL, where clients become the model owners after training and are only concerned about the model's generalization performance on their local data. Due to the data heterogeneity issue, asking all the clients to join a single FL training process may result in model performance degradation. To investigate the effectiveness of collaboration, we first derive a generalization bound for each client when collaborating with others or when training independently. We show that the generalization performance of a client can be improved only by collaborating with other clients that have more training data and similar data distribution. Our analysis allows us to formulate a client utility maximization problem by partitioning clients into multiple collaborating groups. A hierarchical clustering-based collaborative training (HCCT) scheme is then proposed, wh
&lt;/p&gt;</description></item><item><title>Powerformer&#26159;&#19968;&#31181;&#36866;&#24212;&#19981;&#21516;&#20256;&#36755;&#21306;&#27573;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#65292;&#29992;&#20110;&#23398;&#20064;&#31283;&#20581;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#34920;&#31034;&#12290;&#23427;&#36890;&#36807;&#24320;&#21457;&#19987;&#29992;&#30340;&#21306;&#27573;&#33258;&#36866;&#24212;&#27880;&#24847;&#26426;&#21046;&#65292;&#24182;&#24341;&#20837;&#22270;&#31070;&#32463;&#32593;&#32476;&#20256;&#25773;&#21644;&#22810;&#22240;&#32032;&#27880;&#24847;&#26426;&#21046;&#26469;&#25552;&#20379;&#26356;&#21152;&#31283;&#20581;&#30340;&#29366;&#24577;&#34920;&#31034;&#12290;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#30005;&#21147;&#31995;&#32479;&#22330;&#26223;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2401.02771</link><description>&lt;p&gt;
Powerformer&#65306;&#36866;&#24212;&#19981;&#21516;&#20256;&#36755;&#21306;&#27573;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#29992;&#20110;&#30005;&#21147;&#27969;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Powerformer: A Section-adaptive Transformer for Power Flow Adjustment. (arXiv:2401.02771v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02771
&lt;/p&gt;
&lt;p&gt;
Powerformer&#26159;&#19968;&#31181;&#36866;&#24212;&#19981;&#21516;&#20256;&#36755;&#21306;&#27573;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#65292;&#29992;&#20110;&#23398;&#20064;&#31283;&#20581;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#34920;&#31034;&#12290;&#23427;&#36890;&#36807;&#24320;&#21457;&#19987;&#29992;&#30340;&#21306;&#27573;&#33258;&#36866;&#24212;&#27880;&#24847;&#26426;&#21046;&#65292;&#24182;&#24341;&#20837;&#22270;&#31070;&#32463;&#32593;&#32476;&#20256;&#25773;&#21644;&#22810;&#22240;&#32032;&#27880;&#24847;&#26426;&#21046;&#26469;&#25552;&#20379;&#26356;&#21152;&#31283;&#20581;&#30340;&#29366;&#24577;&#34920;&#31034;&#12290;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#30005;&#21147;&#31995;&#32479;&#22330;&#26223;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19987;&#20026;&#23398;&#20064;&#31283;&#20581;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#34920;&#31034;&#32780;&#37327;&#36523;&#23450;&#21046;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#65292;&#26088;&#22312;&#20248;&#21270;&#36328;&#19981;&#21516;&#20256;&#36755;&#21306;&#27573;&#30340;&#30005;&#21147;&#35843;&#24230;&#20197;&#36827;&#34892;&#30005;&#21147;&#27969;&#35843;&#25972;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#26041;&#27861;&#21517;&#20026;Powerformer&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#19987;&#29992;&#30340;&#21306;&#27573;&#33258;&#36866;&#24212;&#27880;&#24847;&#26426;&#21046;&#65292;&#19982;&#20256;&#32479;&#21464;&#21387;&#22120;&#20013;&#20351;&#29992;&#30340;&#33258;&#27880;&#24847;&#20998;&#31163;&#24320;&#26469;&#12290;&#35813;&#26426;&#21046;&#26377;&#25928;&#22320;&#23558;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#19982;&#20256;&#36755;&#21306;&#27573;&#20449;&#24687;&#25972;&#21512;&#22312;&#19968;&#36215;&#65292;&#26377;&#21161;&#20110;&#24320;&#21457;&#31283;&#20581;&#30340;&#29366;&#24577;&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#32771;&#34385;&#30005;&#21147;&#31995;&#32479;&#30340;&#22270;&#25299;&#25169;&#21644;&#27597;&#32447;&#33410;&#28857;&#30340;&#30005;&#27668;&#23646;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#23450;&#21046;&#31574;&#30053;&#26469;&#36827;&#19968;&#27493;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#65306;&#22270;&#31070;&#32463;&#32593;&#32476;&#20256;&#25773;&#21644;&#22810;&#22240;&#32032;&#27880;&#24847;&#26426;&#21046;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#30005;&#21147;&#31995;&#32479;&#22330;&#26223;&#65288;&#21253;&#25324;IEEE 118&#33410;&#28857;&#31995;&#32479;&#12289;&#20013;&#22269;&#23454;&#38469;300&#33410;&#28857;&#31995;&#32479;&#21644;&#19968;&#20010;&#22823;&#22411;&#31995;&#32479;&#65289;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a novel transformer architecture tailored for learning robust power system state representations, which strives to optimize power dispatch for the power flow adjustment across different transmission sections. Specifically, our proposed approach, named Powerformer, develops a dedicated section-adaptive attention mechanism, separating itself from the self-attention used in conventional transformers. This mechanism effectively integrates power system states with transmission section information, which facilitates the development of robust state representations. Furthermore, by considering the graph topology of power system and the electrical attributes of bus nodes, we introduce two customized strategies to further enhance the expressiveness: graph neural network propagation and multi-factor attention mechanism. Extensive evaluations are conducted on three power system scenarios, including the IEEE 118-bus system, a realistic 300-bus system in China, and a large-
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#32479;&#19968;&#33258;&#30417;&#30563;&#32858;&#31867;&#21644;&#33021;&#37327;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#21270;&#30340;&#25512;&#23548;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#21487;&#38752;&#22320;&#24809;&#32602;&#22833;&#36133;&#27169;&#24335;&#30340;&#19979;&#30028;&#12290;&#36825;&#20010;&#19979;&#30028;&#20351;&#24471;&#33021;&#22815;&#35757;&#32451;&#19968;&#20010;&#26631;&#20934;&#30340;&#39592;&#26550;&#26550;&#26500;&#65292;&#32780;&#26080;&#38656;&#20351;&#29992;&#38750;&#23545;&#31216;&#20803;&#32032;&#12290;</title><link>http://arxiv.org/abs/2401.00873</link><description>&lt;p&gt;
&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#32479;&#19968;&#33258;&#30417;&#30563;&#32858;&#31867;&#21644;&#33021;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Unification of Self-Supervised Clustering and Energy-Based Models. (arXiv:2401.00873v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00873
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#32479;&#19968;&#33258;&#30417;&#30563;&#32858;&#31867;&#21644;&#33021;&#37327;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#21270;&#30340;&#25512;&#23548;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#21487;&#38752;&#22320;&#24809;&#32602;&#22833;&#36133;&#27169;&#24335;&#30340;&#19979;&#30028;&#12290;&#36825;&#20010;&#19979;&#30028;&#20351;&#24471;&#33021;&#22815;&#35757;&#32451;&#19968;&#20010;&#26631;&#20934;&#30340;&#39592;&#26550;&#26550;&#26500;&#65292;&#32780;&#26080;&#38656;&#20351;&#29992;&#38750;&#23545;&#31216;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#37327;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#27969;&#34892;&#19988;&#24378;&#22823;&#30340;&#26041;&#27861;&#65292;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#21508;&#31181;&#35757;&#32451;&#30446;&#26631;&#12290;&#26412;&#30740;&#31350;&#23545;&#26368;&#20808;&#36827;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#30446;&#26631;&#36827;&#34892;&#36125;&#21494;&#26031;&#20998;&#26512;&#65292;&#38416;&#26126;&#20102;&#27599;&#20010;&#31867;&#21035;&#20013;&#28508;&#22312;&#30340;&#27010;&#29575;&#22270;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22522;&#26412;&#21407;&#29702;&#20986;&#21457;&#25512;&#23548;&#36825;&#20123;&#27169;&#22411;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#20998;&#26512;&#36824;&#34920;&#26126;&#20102;&#23558;&#33258;&#30417;&#30563;&#23398;&#20064;&#19982;&#22522;&#20110;&#20284;&#28982;&#30340;&#29983;&#25104;&#27169;&#22411;&#33258;&#28982;&#25972;&#21512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#22522;&#20110;&#32858;&#31867;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#21644;&#33021;&#37327;&#27169;&#22411;&#39046;&#22495;&#20013;&#23454;&#29616;&#20102;&#36825;&#20010;&#27010;&#24565;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#19979;&#30028;&#65292;&#32463;&#35777;&#26126;&#33021;&#21487;&#38752;&#22320;&#24809;&#32602;&#26368;&#37325;&#35201;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#26032;&#25552;&#20986;&#30340;&#19979;&#30028;&#20351;&#24471;&#33021;&#22815;&#35757;&#32451;&#19968;&#20010;&#26631;&#20934;&#30340;&#39592;&#24178;&#26550;&#26500;&#65292;&#32780;&#26080;&#38656;&#20351;&#29992;&#35832;&#22914;&#20572;&#27490;&#26799;&#24230;&#12289;&#21160;&#37327;&#32534;&#30721;&#22120;&#25110;&#19987;&#38376;&#30340;&#32858;&#31867;&#31561;&#38750;&#23545;&#31216;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning is a popular and powerful method for utilizing large amounts of unlabeled data, for which a wide variety of training objectives have been proposed in the literature. In this study, we perform a Bayesian analysis of state-of-the-art self-supervised learning objectives, elucidating the underlying probabilistic graphical models in each class and presenting a standardized methodology for their derivation from first principles. The analysis also indicates a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a novel lower bound which is proven to reliably penalize the most important failure modes. Furthermore, this newly proposed lower bound enables the training of a standard backbone architecture without the necessity for asymmetric elements such as stop gradients, momentum encoders, or specialized clusteri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25193;&#23637;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#33539;&#22260;&#65292;&#20174;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#36716;&#21270;&#20026;&#22810;&#39033;&#24335;&#27169;&#22411;&#65292;&#24182;&#30740;&#31350;&#20102;&#37096;&#20998;&#21442;&#25968;&#20445;&#25345;&#19981;&#21464;&#26102;&#30340;&#37096;&#20998;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.15580</link><description>&lt;p&gt;
&#36879;&#36807;&#21464;&#21270;&#30340;&#35270;&#35282;&#65292;&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#22810;&#39033;&#24335;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Identifiable Latent Polynomial Causal Models Through the Lens of Change. (arXiv:2310.15580v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25193;&#23637;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#33539;&#22260;&#65292;&#20174;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#36716;&#21270;&#20026;&#22810;&#39033;&#24335;&#27169;&#22411;&#65292;&#24182;&#30740;&#31350;&#20102;&#37096;&#20998;&#21442;&#25968;&#20445;&#25345;&#19981;&#21464;&#26102;&#30340;&#37096;&#20998;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26088;&#22312;&#20174;&#35266;&#23519;&#21040;&#30340;&#20302;&#32423;&#25968;&#25454;&#20013;&#25581;&#31034;&#28508;&#22312;&#30340;&#39640;&#32423;&#22240;&#26524;&#34920;&#31034;&#12290;&#20854;&#20013;&#19968;&#20010;&#20027;&#35201;&#20219;&#21153;&#26159;&#25552;&#20379;&#21487;&#38752;&#30340;&#20445;&#35777;&#65292;&#20197;&#30830;&#20445;&#35782;&#21035;&#20986;&#36825;&#20123;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#21363;&#21487;&#35782;&#21035;&#24615;&#12290;&#26368;&#36817;&#30340;&#19968;&#39033;&#31361;&#30772;&#24615;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#20043;&#38388;&#22312;&#22810;&#20010;&#29615;&#22659;&#19979;&#30340;&#22240;&#26524;&#24433;&#21709;&#30340;&#21464;&#21270;&#26469;&#25506;&#32034;&#21487;&#35782;&#21035;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#36827;&#23637;&#24314;&#31435;&#22312;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#20005;&#26684;&#36981;&#24490;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#30340;&#20551;&#35774;&#22522;&#30784;&#19978;&#12290;&#26412;&#25991;&#23558;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#33539;&#22260;&#25193;&#23637;&#21040;&#28041;&#21450;&#38750;&#32447;&#24615;&#22240;&#26524;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#36825;&#20123;&#20851;&#31995;&#30001;&#22810;&#39033;&#24335;&#27169;&#22411;&#34920;&#31034;&#65292;&#24182;&#19988;&#22122;&#22768;&#20998;&#24067;&#31526;&#21512;&#25351;&#25968;&#20998;&#24067;&#26063;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#25152;&#26377;&#22240;&#26524;&#21442;&#25968;&#26045;&#21152;&#21464;&#21270;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#22312;&#37096;&#20998;&#21442;&#25968;&#20445;&#25345;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32463;&#39564;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal representation learning aims to unveil latent high-level causal representations from observed low-level data. One of its primary tasks is to provide reliable assurance of identifying these latent causal models, known as identifiability. A recent breakthrough explores identifiability by leveraging the change of causal influences among latent causal variables across multiple environments \citep{liu2022identifying}. However, this progress rests on the assumption that the causal relationships among latent causal variables adhere strictly to linear Gaussian models. In this paper, we extend the scope of latent causal models to involve nonlinear causal relationships, represented by polynomial models, and general noise distributions conforming to the exponential family. Additionally, we investigate the necessity of imposing changes on all causal parameters and present partial identifiability results when part of them remains unchanged. Further, we propose a novel empirical estimation me
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#30340;&#24378;&#30423;&#28216;&#25103;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#20540;&#26469;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12563</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#24378;&#30423;&#28216;&#25103;&#30340;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Approximate information maximization for bandit games. (arXiv:2310.12563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#30340;&#24378;&#30423;&#28216;&#25103;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#20540;&#26469;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29109;&#26368;&#22823;&#21270;&#21644;&#33258;&#30001;&#33021;&#26368;&#23567;&#21270;&#26159;&#29992;&#20110;&#27169;&#25311;&#21508;&#31181;&#29289;&#29702;&#31995;&#32479;&#21160;&#24577;&#30340;&#19968;&#33324;&#29289;&#29702;&#21407;&#29702;&#12290;&#20854;&#20013;&#21253;&#25324;&#20351;&#29992;&#33258;&#30001;&#33021;&#21407;&#29702;&#23545;&#22823;&#33041;&#20869;&#30340;&#20915;&#31574;&#36827;&#34892;&#24314;&#27169;&#65292;&#20351;&#29992;&#20449;&#24687;&#29942;&#39048;&#21407;&#29702;&#23545;&#35775;&#38382;&#38544;&#34255;&#21464;&#37327;&#26102;&#20248;&#21270;&#20934;&#30830;&#24615;&#21644;&#22797;&#26434;&#24615;&#30340;&#26435;&#34913;&#65292;&#20197;&#21450;&#20351;&#29992;&#20449;&#24687;&#26368;&#22823;&#21270;&#36827;&#34892;&#38543;&#26426;&#29615;&#22659;&#23548;&#33322;&#12290;&#22522;&#20110;&#36825;&#19968;&#21407;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24378;&#30423;&#31639;&#27861;&#31867;&#21035;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#31995;&#32479;&#20013;&#19968;&#20010;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#26469;&#36827;&#34892;&#20248;&#21270;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#29289;&#29702;&#30340;&#36817;&#20284;&#20998;&#26512;&#29109;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;&#20197;&#39044;&#27979;&#27599;&#20010;&#21160;&#20316;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#36138;&#23146;&#22320;&#36873;&#25321;&#20449;&#24687;&#22686;&#30410;&#26368;&#22823;&#30340;&#21160;&#20316;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#12290;&#21463;&#21040;&#20854;&#32463;&#39564;&#24615;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entropy maximization and free energy minimization are general physical principles for modeling the dynamics of various physical systems. Notable examples include modeling decision-making within the brain using the free-energy principle, optimizing the accuracy-complexity trade-off when accessing hidden variables with the information bottleneck principle (Tishby et al., 2000), and navigation in random environments using information maximization (Vergassola et al., 2007). Built on this principle, we propose a new class of bandit algorithms that maximize an approximation to the information of a key variable within the system. To this end, we develop an approximated analytical physics-based representation of an entropy to forecast the information gain of each action and greedily choose the one with the largest information gain. This method yields strong performances in classical bandit settings. Motivated by its empirical success, we prove its asymptotic optimality for the two-armed bandit
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#32806;&#36807;&#31243;&#26469;&#21457;&#29616;&#21487;&#20197;&#19982;&#20027;&#20219;&#21153;&#19968;&#36215;&#21033;&#29992;&#30340;&#19981;&#30456;&#20851;&#30340;&#20998;&#31867;&#20219;&#21153;&#21644;&#30456;&#20851;&#26631;&#31614;&#65292;&#20174;&#32780;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20419;&#36827;&#36741;&#21161;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.09278</link><description>&lt;p&gt;
&#35299;&#32806;&#28508;&#22312;&#31354;&#38388;&#20419;&#36827;&#25968;&#25454;&#39537;&#21160;&#30340;&#36741;&#21161;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning. (arXiv:2310.09278v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#32806;&#36807;&#31243;&#26469;&#21457;&#29616;&#21487;&#20197;&#19982;&#20027;&#20219;&#21153;&#19968;&#36215;&#21033;&#29992;&#30340;&#19981;&#30456;&#20851;&#30340;&#20998;&#31867;&#20219;&#21153;&#21644;&#30456;&#20851;&#26631;&#31614;&#65292;&#20174;&#32780;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20419;&#36827;&#36741;&#21161;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#36741;&#21161;&#30446;&#26631;&#24120;&#24120;&#34987;&#29992;&#26469;&#22312;&#25968;&#25454;&#31232;&#32570;&#25110;&#32773;&#20027;&#35201;&#20219;&#21153;&#38750;&#24120;&#22797;&#26434;&#30340;&#24773;&#20917;&#19979;&#20419;&#36827;&#23398;&#20064;&#12290;&#36825;&#20010;&#24819;&#27861;&#20027;&#35201;&#21463;&#21040;&#21516;&#26102;&#35299;&#20915;&#22810;&#20010;&#20219;&#21153;&#24102;&#26469;&#30340;&#25913;&#36827;&#27867;&#21270;&#33021;&#21147;&#30340;&#21551;&#21457;&#65292;&#20174;&#32780;&#20135;&#29983;&#26356;&#24378;&#22823;&#30340;&#20849;&#20139;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#25214;&#21040;&#33021;&#20135;&#29983;&#26399;&#26395;&#25913;&#36827;&#30340;&#26368;&#20248;&#36741;&#21161;&#20219;&#21153;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#36890;&#24120;&#38656;&#35201;&#25163;&#21160;&#35774;&#35745;&#30340;&#25216;&#24039;&#25110;&#32773;&#26114;&#36149;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;Detaux&#65292;&#36890;&#36807;&#24369;&#30417;&#30563;&#30340;&#35299;&#32806;&#36807;&#31243;&#22312;&#20219;&#20309;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#27169;&#22411;&#20013;&#21457;&#29616;&#21487;&#20197;&#19982;&#20027;&#35201;&#20219;&#21153;&#19968;&#36215;&#21033;&#29992;&#30340;&#19981;&#30456;&#20851;&#30340;&#20998;&#31867;&#20219;&#21153;&#21644;&#30456;&#20851;&#26631;&#31614;&#12290;&#35299;&#32806;&#36807;&#31243;&#22312;&#34920;&#31034;&#23618;&#38754;&#24037;&#20316;&#65292;&#23558;&#19982;&#20027;&#35201;&#20219;&#21153;&#30456;&#20851;&#30340;&#19968;&#20010;&#23376;&#31354;&#38388;&#19982;&#20219;&#24847;&#25968;&#37327;&#30340;&#27491;&#20132;&#23376;&#31354;&#38388;&#20998;&#31163;&#24320;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
In deep learning, auxiliary objectives are often used to facilitate learning in situations where data is scarce, or the principal task is extremely complex. This idea is primarily inspired by the improved generalization capability induced by solving multiple tasks simultaneously, which leads to a more robust shared representation. Nevertheless, finding optimal auxiliary tasks that give rise to the desired improvement is a crucial problem that often requires hand-crafted solutions or expensive meta-learning approaches. In this paper, we propose a novel framework, dubbed Detaux, whereby a weakly supervised disentanglement procedure is used to discover new unrelated classification tasks and the associated labels that can be exploited with the principal task in any Multi-Task Learning (MTL) model. The disentanglement procedure works at a representation level, isolating a subspace related to the principal task, plus an arbitrary number of orthogonal subspaces. In the most disentangled subsp
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#20844;&#24179;&#24615;&#30340;&#28151;&#21512;&#25928;&#24212;&#28145;&#24230;&#23398;&#20064;&#65288;MEDL&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#35299;&#20915;&#25968;&#25454;&#38598;&#31751;&#38388;&#20851;&#32852;&#21644;&#19981;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#65292;&#26469;&#25552;&#39640;&#23545;&#31751;&#20998;&#24067;&#25968;&#25454;&#30340;&#20844;&#24179;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.03146</link><description>&lt;p&gt;
&#22686;&#24378;&#20844;&#24179;&#24615;&#30340;&#28151;&#21512;&#25928;&#24212;&#28145;&#24230;&#23398;&#20064;&#22312;&#31751;&#65288;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#65289;&#25968;&#25454;&#19978;&#25913;&#21892;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fairness-enhancing mixed effects deep learning improves fairness on in- and out-of-distribution clustered (non-iid) data. (arXiv:2310.03146v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03146
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#20844;&#24179;&#24615;&#30340;&#28151;&#21512;&#25928;&#24212;&#28145;&#24230;&#23398;&#20064;&#65288;MEDL&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#26102;&#35299;&#20915;&#25968;&#25454;&#38598;&#31751;&#38388;&#20851;&#32852;&#21644;&#19981;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#65292;&#26469;&#25552;&#39640;&#23545;&#31751;&#20998;&#24067;&#25968;&#25454;&#30340;&#20844;&#24179;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#28145;&#24230;&#23398;&#20064;&#22312;&#20004;&#20010;&#26680;&#24515;&#38382;&#39064;&#19978;&#23384;&#22312;&#22256;&#25200;&#12290;&#39318;&#20808;&#65292;&#23427;&#20551;&#35774;&#35757;&#32451;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#28982;&#32780;&#65292;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#23558;&#26679;&#26412;&#25353;&#20849;&#20139;&#30340;&#27979;&#37327;&#20540;&#36827;&#34892;&#20998;&#32452;&#65288;&#20363;&#22914;&#65292;&#30740;&#31350;&#21442;&#19982;&#32773;&#25110;&#32454;&#32990;&#65289;&#65292;&#36829;&#21453;&#20102;&#36825;&#19968;&#20551;&#35774;&#12290;&#22312;&#36825;&#20123;&#22330;&#26223;&#20013;&#65292;&#28145;&#24230;&#23398;&#20064;&#21487;&#33021;&#26174;&#31034;&#20986;&#24615;&#33021;&#19979;&#38477;&#12289;&#27867;&#21270;&#33021;&#21147;&#26377;&#38480;&#21644;&#35299;&#37322;&#24615;&#38382;&#39064;&#65292;&#24182;&#20276;&#38543;&#30528;&#31751;&#28151;&#28102;&#24341;&#36215;&#30340;&#31532;&#19968;&#22411;&#21644;&#31532;&#20108;&#22411;&#38169;&#35823;&#12290;&#20854;&#27425;&#65292;&#27169;&#22411;&#36890;&#24120;&#34987;&#35757;&#32451;&#20197;&#23454;&#29616;&#25972;&#20307;&#20934;&#30830;&#24615;&#65292;&#24448;&#24448;&#24573;&#35270;&#20102;&#34987;&#20302;&#20272;&#30340;&#32676;&#20307;&#65292;&#22312;&#36151;&#27454;&#25209;&#20934;&#25110;&#30830;&#23450;&#20581;&#24247;&#20445;&#38505;&#36153;&#29575;&#31561;&#20851;&#38190;&#39046;&#22495;&#24341;&#20837;&#20559;&#35265;&#65292;&#36825;&#20123;&#20559;&#35265;&#21487;&#33021;&#20250;&#20005;&#37325;&#24433;&#21709;&#20010;&#20154;&#30340;&#29983;&#27963;&#36136;&#37327;&#12290;&#20026;&#20102;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#25928;&#24212;&#28145;&#24230;&#23398;&#20064;&#65288;MEDL&#65289;&#26694;&#26550;&#12290;MEDL&#36890;&#36807;&#24341;&#20837;&#20197;&#19979;&#20869;&#23481;&#20998;&#21035;&#37327;&#21270;&#31751;&#19981;&#21464;&#30340;&#22266;&#23450;&#25928;&#24212;&#21644;&#31751;&#29305;&#23450;&#30340;&#38543;&#26426;&#25928;&#24212;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#25361;&#25112;&#65306;1&#65289;&#19968;&#20010;&#31751;&#23545;&#25163;&#65292;&#40723;&#21169;&#31751;&#38388;&#24046;&#24322;&#30340;&#26368;&#23567;&#21270;&#65307;
&lt;/p&gt;
&lt;p&gt;
Traditional deep learning (DL) suffers from two core problems. Firstly, it assumes training samples are independent and identically distributed. However, numerous real-world datasets group samples by shared measurements (e.g., study participants or cells), violating this assumption. In these scenarios, DL can show compromised performance, limited generalization, and interpretability issues, coupled with cluster confounding causing Type 1 and 2 errors. Secondly, models are typically trained for overall accuracy, often neglecting underrepresented groups and introducing biases in crucial areas like loan approvals or determining health insurance rates, such biases can significantly impact one's quality of life. To address both of these challenges simultaneously, we present a mixed effects deep learning (MEDL) framework. MEDL separately quantifies cluster-invariant fixed effects (FE) and cluster-specific random effects (RE) through the introduction of: 1) a cluster adversary which encourage
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Adversarial ModSecurity&#65292;&#23427;&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#26469;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#38450;&#28779;&#22681;&#12290;&#36890;&#36807;&#23558;&#26680;&#24515;&#35268;&#21017;&#38598;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#35782;&#21035;&#24182;&#38450;&#24481;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AdvModSec&#22312;&#35757;&#32451;&#21518;&#33021;&#22815;&#26377;&#25928;&#22320;&#24212;&#23545;&#36825;&#31867;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2308.04964</link><description>&lt;p&gt;
Adversarial ModSecurity: &#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning. (arXiv:2308.04964v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04964
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Adversarial ModSecurity&#65292;&#23427;&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#26469;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#38450;&#28779;&#22681;&#12290;&#36890;&#36807;&#23558;&#26680;&#24515;&#35268;&#21017;&#38598;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#35782;&#21035;&#24182;&#38450;&#24481;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AdvModSec&#22312;&#35757;&#32451;&#21518;&#33021;&#22815;&#26377;&#25928;&#22320;&#24212;&#23545;&#36825;&#31867;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ModSecurity&#34987;&#24191;&#27867;&#35748;&#21487;&#20026;&#26631;&#20934;&#30340;&#24320;&#28304;Web&#24212;&#29992;&#38450;&#28779;&#22681;(WAF)&#65292;&#30001;OWASP&#22522;&#37329;&#20250;&#32500;&#25252;&#12290;&#23427;&#36890;&#36807;&#19982;&#26680;&#24515;&#35268;&#21017;&#38598;&#36827;&#34892;&#21305;&#37197;&#26469;&#26816;&#27979;&#24694;&#24847;&#35831;&#27714;&#65292;&#35782;&#21035;&#20986;&#24120;&#35265;&#30340;&#25915;&#20987;&#27169;&#24335;&#12290;&#27599;&#20010;&#35268;&#21017;&#22312;CRS&#20013;&#37117;&#34987;&#25163;&#21160;&#20998;&#37197;&#19968;&#20010;&#26435;&#37325;&#65292;&#22522;&#20110;&#30456;&#24212;&#25915;&#20987;&#30340;&#20005;&#37325;&#31243;&#24230;&#65292;&#22914;&#26524;&#35302;&#21457;&#35268;&#21017;&#30340;&#26435;&#37325;&#20043;&#21644;&#36229;&#36807;&#32473;&#23450;&#30340;&#38408;&#20540;&#65292;&#23601;&#20250;&#34987;&#26816;&#27979;&#20026;&#24694;&#24847;&#35831;&#27714;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#31616;&#21333;&#30340;&#31574;&#30053;&#22312;&#26816;&#27979;SQL&#27880;&#20837;&#25915;&#20987;&#26041;&#38754;&#24456;&#19981;&#26377;&#25928;&#65292;&#22240;&#20026;&#23427;&#24448;&#24448;&#20250;&#38459;&#27490;&#35768;&#22810;&#21512;&#27861;&#35831;&#27714;&#65292;&#21516;&#26102;&#36824;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#21363;&#25925;&#24847;&#25805;&#32437;&#20197;&#36867;&#36991;&#26816;&#27979;&#30340;&#25915;&#20987;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026;AdvModSec&#30340;&#24378;&#22823;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#23558;CRS&#35268;&#21017;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#24182;&#32463;&#36807;&#35757;&#32451;&#20197;&#26816;&#27979;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;AdvModSec&#22312;&#38024;&#23545;&#35813;&#25915;&#20987;&#30340;&#27969;&#37327;&#19978;&#36827;&#34892;&#35757;&#32451;&#21518;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
ModSecurity is widely recognized as the standard open-source Web Application Firewall (WAF), maintained by the OWASP Foundation. It detects malicious requests by matching them against the Core Rule Set, identifying well-known attack patterns. Each rule in the CRS is manually assigned a weight, based on the severity of the corresponding attack, and a request is detected as malicious if the sum of the weights of the firing rules exceeds a given threshold. In this work, we show that this simple strategy is largely ineffective for detecting SQL injection (SQLi) attacks, as it tends to block many legitimate requests, while also being vulnerable to adversarial SQLi attacks, i.e., attacks intentionally manipulated to evade detection. To overcome these issues, we design a robust machine learning model, named AdvModSec, which uses the CRS rules as input features, and it is trained to detect adversarial SQLi attacks. Our experiments show that AdvModSec, being trained on the traffic directed towa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36861;&#36394;&#21644;&#24635;&#32467;&#20102;&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;MLLM&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21253;&#25324;&#22810;&#27169;&#24577;&#25351;&#20196;&#35843;&#25972;&#12289;&#22810;&#27169;&#24577;&#19978;&#19979;&#25991;&#23398;&#20064;&#12289;&#22810;&#27169;&#24577;&#24605;&#32500;&#38142;&#21644;LLM&#36741;&#21161;&#35270;&#35273;&#25512;&#29702;&#31561;&#24212;&#29992;&#65292;&#25351;&#20986;&#20102;&#29616;&#26377;&#25361;&#25112;&#21644;&#26377;&#21069;&#36884;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2306.13549</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Multimodal Large Language Models. (arXiv:2306.13549v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36861;&#36394;&#21644;&#24635;&#32467;&#20102;&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;MLLM&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21253;&#25324;&#22810;&#27169;&#24577;&#25351;&#20196;&#35843;&#25972;&#12289;&#22810;&#27169;&#24577;&#19978;&#19979;&#25991;&#23398;&#20064;&#12289;&#22810;&#27169;&#24577;&#24605;&#32500;&#38142;&#21644;LLM&#36741;&#21161;&#35270;&#35273;&#25512;&#29702;&#31561;&#24212;&#29992;&#65292;&#25351;&#20986;&#20102;&#29616;&#26377;&#25361;&#25112;&#21644;&#26377;&#21069;&#36884;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;MLLM&#65289;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#30740;&#31350;&#28909;&#28857;&#65292;&#20351;&#29992;&#24378;&#22823;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#22823;&#33041;&#25191;&#34892;&#22810;&#27169;&#24577;&#20219;&#21153;&#12290;MLLM &#30340;&#24778;&#20154;&#33021;&#21147;&#65292;&#22914;&#22522;&#20110;&#22270;&#20687;&#32534;&#20889;&#25925;&#20107;&#21644;&#26080;OCR&#25968;&#23398;&#25512;&#29702;&#31561;&#65292;&#22312;&#20256;&#32479;&#26041;&#27861;&#20013;&#24456;&#23569;&#35265;&#65292;&#34920;&#26126;&#20102;&#36890;&#21521;&#20154;&#24037;&#26234;&#33021;&#30340;&#28508;&#22312;&#36335;&#24452;&#12290;&#26412;&#25991;&#26088;&#22312;&#36861;&#36394;&#21644;&#24635;&#32467; MLLM &#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102; MLLM &#30340;&#26500;&#25104;&#65292;&#27010;&#36848;&#20102;&#30456;&#20851;&#27010;&#24565;&#12290;&#28982;&#21518;&#65292;&#35752;&#35770;&#20102;&#20851;&#38190;&#25216;&#26415;&#21644;&#24212;&#29992;&#65292;&#21253;&#25324;&#22810;&#27169;&#24577;&#25351;&#20196;&#35843;&#25972;&#65288;M-IT&#65289;&#12289;&#22810;&#27169;&#24577;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;M-ICL&#65289;&#12289;&#22810;&#27169;&#24577;&#24605;&#32500;&#38142;&#65288;M-CoT&#65289;&#21644;LLM&#36741;&#21161;&#35270;&#35273;&#25512;&#29702;&#65288;LAVR&#65289;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#29616;&#26377;&#30340;&#25361;&#25112;&#65292;&#24182;&#25351;&#20986;&#20102;&#26377;&#21069;&#36884;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#37492;&#20110; MLLM &#26102;&#20195;&#25165;&#21018;&#21018;&#24320;&#22987;&#65292;&#25105;&#20204;&#20250;&#19981;&#26029;&#26356;&#26032;&#36825;&#20010;&#32508;&#36848;&#65292;&#24182;&#24076;&#26395;&#33021;&#28608;&#21457;&#26356;&#22810;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal Large Language Model (MLLM) recently has been a new rising research hotspot, which uses powerful Large Language Models (LLMs) as a brain to perform multimodal tasks. The surprising emergent capabilities of MLLM, such as writing stories based on images and OCR-free math reasoning, are rare in traditional methods, suggesting a potential path to artificial general intelligence. In this paper, we aim to trace and summarize the recent progress of MLLM. First of all, we present the formulation of MLLM and delineate its related concepts. Then, we discuss the key techniques and applications, including Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning (M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning (LAVR). Finally, we discuss existing challenges and point out promising research directions. In light of the fact that the era of MLLM has only just begun, we will keep updating this survey and hope it can inspire more research. An associated
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#19981;&#21516;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#23450;&#20041;&#21644;&#38543;&#26426;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;Lasso&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.10413</link><description>&lt;p&gt;
&#20351;&#29992;Lasso&#30340;&#31614;&#21517;&#19968;&#33268;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Consistency of Signatures Using Lasso. (arXiv:2305.10413v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#19981;&#21516;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#23450;&#20041;&#21644;&#38543;&#26426;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;Lasso&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31614;&#21517;&#21464;&#25442;&#26159;&#36830;&#32493;&#21644;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#36845;&#20195;&#36335;&#24452;&#31215;&#20998;&#65292;&#23427;&#20204;&#30340;&#26222;&#36941;&#38750;&#32447;&#24615;&#36890;&#36807;&#32447;&#24615;&#21270;&#29305;&#24449;&#36873;&#25321;&#38382;&#39064;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#21644;&#25968;&#20540;&#19978;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#26356;&#25509;&#36817;&#24067;&#26391;&#36816;&#21160;&#25110;&#20855;&#26377;&#36739;&#24369;&#36328;&#32500;&#24230;&#30456;&#20851;&#24615;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#31614;&#21517;&#23450;&#20041;&#20026;It\^o&#31215;&#20998;&#30340;Lasso&#22238;&#24402;&#26356;&#20855;&#19968;&#33268;&#24615;&#65307;&#23545;&#20110;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#20854;&#31614;&#21517;&#23450;&#20041;&#20026;Stratonovich&#31215;&#20998;&#22312;Lasso&#22238;&#24402;&#20013;&#20855;&#26377;&#26356;&#39640;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#32479;&#35745;&#25512;&#26029;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#21644;&#38543;&#26426;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signature transforms are iterated path integrals of continuous and discrete-time time series data, and their universal nonlinearity linearizes the problem of feature selection. This paper revisits the consistency issue of Lasso regression for the signature transform, both theoretically and numerically. Our study shows that, for processes and time series that are closer to Brownian motion or random walk with weaker inter-dimensional correlations, the Lasso regression is more consistent for their signatures defined by It\^o integrals; for mean reverting processes and time series, their signatures defined by Stratonovich integrals have more consistency in the Lasso regression. Our findings highlight the importance of choosing appropriate definitions of signatures and stochastic models in statistical inference and machine learning.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#26041;&#27861;&#65288;MCF&#65289;&#65292;&#29992;&#20110;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#19979;&#30340;&#25968;&#25454;&#32858;&#31867;&#65292;&#20854;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;&#21487;&#27979;&#37327;&#20998;&#21306;&#24207;&#21015;&#30340;&#23618;&#27425;&#20851;&#31995;&#21644;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2305.04281</link><description>&lt;p&gt;
&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;
&lt;/p&gt;
&lt;p&gt;
Persistent Homology of the Multiscale Clustering Filtration. (arXiv:2305.04281v2 [math.AT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04281
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#26041;&#27861;&#65288;MCF&#65289;&#65292;&#29992;&#20110;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#19979;&#30340;&#25968;&#25454;&#32858;&#31867;&#65292;&#20854;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;&#21487;&#27979;&#37327;&#20998;&#21306;&#24207;&#21015;&#30340;&#23618;&#27425;&#20851;&#31995;&#21644;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#25968;&#25454;&#32858;&#31867;&#24212;&#29992;&#20013;&#65292;&#19981;&#20165;&#24076;&#26395;&#25214;&#21040;&#19968;&#31181;&#21333;&#19968;&#30340;&#20998;&#21306;&#26041;&#24335;&#65292;&#36824;&#24076;&#26395;&#25214;&#21040;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#25110;&#31895;&#31961;&#23618;&#27425;&#19979;&#30340;&#25968;&#25454;&#30340;&#19968;&#31995;&#21015;&#20998;&#21306;&#26041;&#24335;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#26159;&#20998;&#26512;&#21644;&#27604;&#36739;&#25903;&#25745;&#36825;&#31181;&#22810;&#23610;&#24230;&#25968;&#25454;&#25551;&#36848;&#30340;&#65288;&#19981;&#19968;&#23450;&#26159;&#23618;&#27425;&#24615;&#30340;&#65289;&#20998;&#21306;&#24207;&#21015;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#25277;&#35937;&#21333;&#32431;&#22797;&#24418;&#30340;&#36807;&#28388;&#65292;&#31216;&#20026;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#65288;MCF&#65289;&#65292;&#23427;&#32534;&#30721;&#20102;&#36328;&#23610;&#24230;&#30340;&#20219;&#24847;&#27169;&#24335;&#30340;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#35777;&#26126;&#20102;MCF&#20135;&#29983;&#31283;&#23450;&#30340;&#25345;&#20037;&#22270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MCF&#30340;&#38646;&#32500;&#25345;&#20037;&#21516;&#35843;&#27979;&#37327;&#20102;&#20998;&#21306;&#24207;&#21015;&#20013;&#30340;&#23618;&#27425;&#20851;&#31995;&#31243;&#24230;&#65292;&#32780;&#39640;&#32500;&#25345;&#20037;&#21516;&#35843;&#21017;&#36319;&#36394;&#20102;&#20998;&#21306;&#24207;&#21015;&#20013;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;&#20026;&#20102;&#25299;&#23485;MCF&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#31561;&#20215;&#30340;&#26500;&#36896;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many applications in data clustering, it is desirable to find not just a single partition into clusters but a sequence of partitions describing the data at different scales, or levels of coarseness. A natural problem then is to analyse and compare the (not necessarily hierarchical) sequences of partitions that underpin such multiscale descriptions of data. Here, we introduce a filtration of abstract simplicial complexes, denoted the Multiscale Clustering Filtration (MCF), which encodes arbitrary patterns of cluster assignments across scales, and we prove that the MCF produces stable persistence diagrams. We then show that the zero-dimensional persistent homology of the MCF measures the degree of hierarchy in the sequence of partitions, and that the higher-dimensional persistent homology tracks the emergence and resolution of conflicts between cluster assignments across the sequence of partitions. To broaden the theoretical foundations of the MCF, we also provide an equivalent constr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;Koopman&#31639;&#23376;&#30340;&#36127;&#36733;&#21160;&#24577;&#20998;&#35299;&#26041;&#27861;&#65292;&#33021;&#22815;&#32534;&#30721;&#30005;&#32593;&#36127;&#36733;&#21160;&#24577;&#30340;&#20016;&#23500;&#29305;&#24449;&#65292;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#65292;&#21516;&#26102;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2304.07832</link><description>&lt;p&gt;
&#22522;&#20110;Koopman&#27169;&#24577;&#20998;&#35299;&#30340;&#30005;&#32593;&#36127;&#36733;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Characterizing the load profile in power grids by Koopman mode decomposition of interconnected dynamics. (arXiv:2304.07832v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07832
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;Koopman&#31639;&#23376;&#30340;&#36127;&#36733;&#21160;&#24577;&#20998;&#35299;&#26041;&#27861;&#65292;&#33021;&#22815;&#32534;&#30721;&#30005;&#32593;&#36127;&#36733;&#21160;&#24577;&#30340;&#20016;&#23500;&#29305;&#24449;&#65292;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#65292;&#21516;&#26102;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#21147;&#36127;&#36733;&#39044;&#27979;&#23545;&#20110;&#26377;&#25928;&#31649;&#29702;&#21644;&#20248;&#21270;&#30005;&#32593;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#31639;&#23376;&#29702;&#35770;&#26694;&#26550;&#20869;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#35782;&#21035;&#36127;&#36733;&#21160;&#24577;&#12290;&#25105;&#20204;&#20351;&#29992;Koopman&#31639;&#23376;&#26469;&#34920;&#31034;&#36127;&#36733;&#25968;&#25454;&#65292;&#35813;&#31639;&#23376;&#22266;&#26377;&#20110;&#24213;&#23618;&#21160;&#24577;&#12290;&#36890;&#36807;&#35745;&#31639;&#30456;&#24212;&#30340;&#29305;&#24449;&#20989;&#25968;&#65292;&#25105;&#20204;&#23558;&#36127;&#36733;&#21160;&#24577;&#20998;&#35299;&#20026;&#30456;&#24178;&#30340;&#26102;&#31354;&#27169;&#24335;&#65292;&#36825;&#20123;&#27169;&#24335;&#26159;&#21160;&#24577;&#30340;&#26368;&#24378;&#29305;&#24449;&#12290;&#27599;&#20010;&#27169;&#24335;&#26681;&#25454;&#20854;&#21333;&#19968;&#39057;&#29575;&#29420;&#31435;&#28436;&#21270;&#65292;&#22522;&#20110;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#21487;&#39044;&#27979;&#24615;&#12290;&#25105;&#20204;&#24378;&#35843;&#65292;&#36127;&#36733;&#21160;&#24577;&#26159;&#22522;&#20110;&#22266;&#26377;&#20110;&#21160;&#24577;&#30340;&#30456;&#24178;&#30340;&#26102;&#31354;&#27169;&#24335;&#26500;&#24314;&#30340;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#26102;&#38388;&#23610;&#24230;&#19978;&#32534;&#30721;&#20016;&#23500;&#30340;&#21160;&#24577;&#29305;&#24449;&#12290;&#36825;&#20123;&#29305;&#24449;&#19982;&#30005;&#32593;&#30340;&#29289;&#29702;&#29305;&#24449;&#65288;&#22914;&#23395;&#33410;&#24615;&#21644;&#23567;&#26102;&#27169;&#24335;&#65289;&#26377;&#20851;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#23545;&#24213;&#23618;&#21160;&#24577;&#30340;&#26377;&#24847;&#20041;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Electricity load forecasting is crucial for effectively managing and optimizing power grids. Over the past few decades, various statistical and deep learning approaches have been used to develop load forecasting models. This paper presents an interpretable machine learning approach that identifies load dynamics using data-driven methods within an operator-theoretic framework. We represent the load data using the Koopman operator, which is inherent to the underlying dynamics. By computing the corresponding eigenfunctions, we decompose the load dynamics into coherent spatiotemporal patterns that are the most robust features of the dynamics. Each pattern evolves independently according to its single frequency, making its predictability based on linear dynamics. We emphasize that the load dynamics are constructed based on coherent spatiotemporal patterns that are intrinsic to the dynamics and are capable of encoding rich dynamical features at multiple time scales. These features are relate
&lt;/p&gt;</description></item><item><title>SoftED metrics &#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20107;&#20214;&#26816;&#27979;&#30340;&#26032;&#25351;&#26631;&#65292;&#26082;&#21253;&#25324;&#26102;&#38388;&#30340;&#27010;&#24565;&#65292;&#21448;&#21253;&#25324;&#23545;&#30456;&#37051;&#26816;&#27979;&#30340;&#26102;&#38388;&#23481;&#24525;&#24230;&#65292;&#23427;&#20204;&#33021;&#22815;&#21516;&#26102;&#35780;&#20272;&#20107;&#20214;&#26816;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#20854;&#26816;&#27979;&#26159;&#21542;&#20195;&#34920;&#20107;&#20214;&#12290;</title><link>http://arxiv.org/abs/2304.00439</link><description>&lt;p&gt;
SoftED: &#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20107;&#20214;&#26816;&#27979;&#30340;&#36719;&#35780;&#20272;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
SoftED: Metrics for Soft Evaluation of Time Series Event Detection. (arXiv:2304.00439v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00439
&lt;/p&gt;
&lt;p&gt;
SoftED metrics &#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20107;&#20214;&#26816;&#27979;&#30340;&#26032;&#25351;&#26631;&#65292;&#26082;&#21253;&#25324;&#26102;&#38388;&#30340;&#27010;&#24565;&#65292;&#21448;&#21253;&#25324;&#23545;&#30456;&#37051;&#26816;&#27979;&#30340;&#26102;&#38388;&#23481;&#24525;&#24230;&#65292;&#23427;&#20204;&#33021;&#22815;&#21516;&#26102;&#35780;&#20272;&#20107;&#20214;&#26816;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#20854;&#26816;&#27979;&#26159;&#21542;&#20195;&#34920;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#20107;&#20214;&#26816;&#27979;&#26041;&#27861;&#36890;&#24120;&#36890;&#36807;&#26631;&#20934;&#30340;&#20998;&#31867;&#25351;&#26631;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#20123;&#25351;&#26631;&#20165;&#20851;&#27880;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#20107;&#20214;&#26816;&#27979;&#30340;&#19981;&#20934;&#30830;&#24448;&#24448;&#26159;&#30001;&#20110;&#21069;&#21518;&#30456;&#20851;&#20107;&#20214;&#22312;&#30456;&#37051;&#26816;&#27979;&#20013;&#30340;&#21453;&#24212;&#20135;&#29983;&#30340;&#12290;&#36825;&#20123;&#26816;&#27979;&#23545;&#20110;&#35302;&#21457;&#24517;&#35201;&#30340;&#34892;&#21160;&#25110;&#24110;&#21161;&#20943;&#36731;&#19981;&#33391;&#21518;&#26524;&#38750;&#24120;&#26377;&#20215;&#20540;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#30340;&#25351;&#26631;&#23545;&#20110;&#20107;&#20214;&#26816;&#27979;&#26469;&#35828;&#26159;&#19981;&#20805;&#20998;&#21644;&#19981;&#36866;&#24403;&#30340;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#19968;&#31181;&#25351;&#26631;&#65292;&#26082;&#21253;&#25324;&#26102;&#38388;&#30340;&#27010;&#24565;&#65292;&#21448;&#21253;&#25324;&#23545;&#30456;&#37051;&#26816;&#27979;&#30340;&#26102;&#38388;&#23481;&#24525;&#24230;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25351;&#26631;&#38598;&#21512;&#8220;SoftED metrics&#8221;&#65292;&#26088;&#22312;&#36719;&#35780;&#20272;&#20107;&#20214;&#26816;&#27979;&#26041;&#27861;&#12290;&#23427;&#20204;&#21487;&#20197;&#35780;&#20272;&#26816;&#27979;&#30340;&#20934;&#30830;&#24615;&#20197;&#21450;&#20854;&#26816;&#27979;&#26159;&#21542;&#20195;&#34920;&#20107;&#20214;&#12290;&#36890;&#36807;&#23558;&#20107;&#20214;&#21644;&#20195;&#34920;&#24615;&#26816;&#27979;&#30456;&#32467;&#21512;&#65292;&#24182;&#22312;36\%&#20197;&#19978;&#30340;&#23454;&#39564;&#20013;&#21152;&#20837;&#26102;&#38388;&#23481;&#24525;&#24230;&#65292;&#25552;&#39640;&#20102;&#20107;&#20214;&#26816;&#27979;&#30340;&#35780;&#20272;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series event detection methods are evaluated mainly by standard classification metrics that focus solely on detection accuracy. However, inaccuracy in detecting an event can often result from its preceding or delayed effects reflected in neighboring detections. These detections are valuable to trigger necessary actions or help mitigate unwelcome consequences. In this context, current metrics are insufficient and inadequate for the context of event detection. There is a demand for metrics that incorporate both the concept of time and temporal tolerance for neighboring detections. This paper introduces SoftED metrics, a new set of metrics designed for soft evaluating event detection methods. They enable the evaluation of both detection accuracy and the degree to which their detections represent events. They improved event detection evaluation by associating events and their representative detections, incorporating temporal tolerance in over 36\% of experiments compared to the usual 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#22120;&#8212;&#8212;&#26368;&#20248;&#20998;&#31867;&#26862;&#26519;&#65292;&#36890;&#36807;&#25968;&#23398;&#20248;&#21270;&#26041;&#27861;&#26500;&#24314;&#26368;&#20248;&#30340;&#20915;&#31574;&#26641;&#38598;&#25104;&#23454;&#29616;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#27604;&#38543;&#26426;&#26862;&#26519;&#20351;&#29992;&#25968;&#37327;&#32423;&#26356;&#23569;&#30340;&#26641;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2211.10502</link><description>&lt;p&gt;
&#26368;&#20248;&#20998;&#31867;&#26862;&#26519;&#30340;&#25968;&#23398;&#35268;&#21010;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Mathematical Programming Approach to Optimal Classification Forests. (arXiv:2211.10502v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10502
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#22120;&#8212;&#8212;&#26368;&#20248;&#20998;&#31867;&#26862;&#26519;&#65292;&#36890;&#36807;&#25968;&#23398;&#20248;&#21270;&#26041;&#27861;&#26500;&#24314;&#26368;&#20248;&#30340;&#20915;&#31574;&#26641;&#38598;&#25104;&#23454;&#29616;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#27604;&#38543;&#26426;&#26862;&#26519;&#20351;&#29992;&#25968;&#37327;&#32423;&#26356;&#23569;&#30340;&#26641;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#22120;&#26063;&#32676;&#8212;&#8212;&#26368;&#20248;&#20998;&#31867;&#26862;&#26519;&#65292;&#21033;&#29992;&#26368;&#20248;&#30340;&#20915;&#31574;&#26641;&#38598;&#25104;&#26469;&#24471;&#20986;&#20934;&#30830;&#19988;&#21487;&#35299;&#37322;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#25968;&#23398;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#26500;&#24314;&#32473;&#23450;&#25968;&#37327;&#30340;&#26641;&#65292;&#27599;&#20010;&#26641;&#20026;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#35266;&#27979;&#20540;&#25552;&#20379;&#19968;&#20010;&#39044;&#27979;&#31867;&#21035;&#12290;&#36890;&#36807;&#22312;&#26862;&#26519;&#20013;&#30340;&#27599;&#26869;&#26641;&#20013;&#36873;&#20986;&#34987;&#26368;&#39057;&#32321;&#39044;&#27979;&#30340;&#31867;&#21035;&#26469;&#27714;&#24471;&#20998;&#31867;&#35268;&#21017;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#20844;&#24335;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#35745;&#31639;&#23454;&#39564;&#32467;&#26524;&#65292;&#25105;&#20204;&#35748;&#20026;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26641;&#30340;&#20998;&#31867;&#26041;&#27861;&#30456;&#27604;&#65292;&#20855;&#26377;&#21516;&#31561;&#25110;&#26356;&#39640;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#23454;&#29616;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#20363;&#22914;&#65292;&#27604;&#38543;&#26426;&#26862;&#26519;&#20351;&#29992;&#25968;&#37327;&#32423;&#26356;&#23569;&#30340;&#26641;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19977;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce Optimal Classification Forests, a new family of classifiers that takes advantage of an optimal ensemble of decision trees to derive accurate and interpretable classifiers. We propose a novel mathematical optimization-based methodology in which a given number of trees are simultaneously constructed, each of them providing a predicted class for the observations in the feature space. The classification rule is derived by assigning to each observation its most frequently predicted class among the trees in the forest. We provide a mixed integer linear programming formulation for the problem. We report the results of our computational experiments, from which we conclude that our proposed method has equal or superior performance compared with state-of-the-art tree-based classification methods. More importantly, it achieves high prediction accuracy with, for example, orders of magnitude fewer trees than random forests. We also present three real-world case studies s
&lt;/p&gt;</description></item></channel></rss>