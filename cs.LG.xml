<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#30340;&#22266;&#23450;&#20998;&#37197;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#20197;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#21152;&#28145;&#20102;&#25105;&#20204;&#23545;&#20110;&#35813;&#38382;&#39064;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.05878</link><description>&lt;p&gt;
&#22522;&#20110;&#20808;&#39564;&#20381;&#36182;&#20998;&#37197;&#30340;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Prior-Dependent Allocations for Bayesian Fixed-Budget Best-Arm Identification in Structured Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#30340;&#22266;&#23450;&#20998;&#37197;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#20197;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#21152;&#28145;&#20102;&#25105;&#20204;&#23545;&#20110;&#35813;&#38382;&#39064;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#21644;&#29615;&#22659;&#32467;&#26500;&#20351;&#29992;&#22266;&#23450;&#20998;&#37197;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#23427;&#22312;&#24615;&#33021;&#19978;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#20998;&#23618;BAI&#30340;&#39318;&#20010;&#20808;&#39564;&#20381;&#36182;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;&#23427;&#33021;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#25105;&#20204;&#24191;&#27867;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#22266;&#23450;&#39044;&#31639;BAI&#26041;&#27861;&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#20854;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25913;&#36827;&#20102;&#23545;&#20110;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;BAI&#30340;&#29702;&#35299;&#65292;&#24182;&#31361;&#20986;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of Bayesian fixed-budget best-arm identification (BAI) in structured bandits. We propose an algorithm that uses fixed allocations based on the prior information and the structure of the environment. We provide theoretical bounds on its performance across diverse models, including the first prior-dependent upper bounds for linear and hierarchical BAI. Our key contribution is introducing new proof methods that result in tighter bounds for multi-armed BAI compared to existing methods. We extensively compare our approach to other fixed-budget BAI methods, demonstrating its consistent and robust performance in various settings. Our work improves our understanding of Bayesian fixed-budget BAI in structured bandits and highlights the effectiveness of our approach in practical scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#22686;&#21152;&#20102;&#23545;&#20854;&#29702;&#35770;&#29702;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#29992;&#20110;&#36873;&#25321;&#36866;&#24403;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.03985</link><description>&lt;p&gt;
&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#38598;&#25104;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03985
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#22686;&#21152;&#20102;&#23545;&#20854;&#29702;&#35770;&#29702;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#29992;&#20110;&#36873;&#25321;&#36866;&#24403;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#20026;&#30417;&#30563;&#23398;&#20064;&#29983;&#25104;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#22909;&#22788;&#65292;&#21253;&#25324;&#22686;&#21152;&#20934;&#30830;&#24615;&#12289;&#26356;&#26377;&#25928;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#36825;&#20123;&#22909;&#22788;&#22312;&#32463;&#39564;&#19978;&#26377;&#26126;&#30830;&#30340;&#25903;&#25345;&#65292;&#20294;&#23545;&#23427;&#20204;&#30340;&#29702;&#35770;&#29702;&#35299;&#30446;&#21069;&#38750;&#24120;&#26377;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#20351;&#29992;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#20960;&#31181;&#35774;&#32622;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#65292;&#26469;&#22686;&#21152;&#29702;&#35770;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#39044;&#27979;&#65292;&#23545;&#20110;&#39640;&#26041;&#24046;&#30340;&#19979;&#28216;&#39044;&#27979;&#22120;&#65292;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#23558;&#29305;&#21035;&#26377;&#30410;&#65292;&#24182;&#20026;&#22343;&#26041;&#35823;&#24046;&#21644;Brier&#20998;&#25968;&#30340;&#24773;&#20917;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#27861;&#21017;&#26469;&#36873;&#25321;&#21512;&#36866;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#25968;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#35780;&#20272;&#19968;&#20010;&#38598;&#25104;&#22312;&#22810;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20960;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20197;&#21450;&#19979;&#28216;&#39044;&#27979;&#22120;&#19978;&#30340;&#24615;&#33021;&#26469;&#30740;&#31350;&#25105;&#20204;&#30340;&#29702;&#35770;&#22312;&#23454;&#36341;&#20013;&#30340;&#25928;&#26524;&#12290;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#27934;&#23519;&#20063;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets. Our theory predicts multiple synthetic datasets to be especially beneficial for high-variance downstream predictors, and yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice by evaluating the performance of an ensemble over many synthetic datasets for several real datasets and downstream predictors. The results follow our theory, showing that our insights are also practically relevant.
&lt;/p&gt;</description></item><item><title>SafEDMD&#26159;&#19968;&#31181;&#22522;&#20110;EDMD&#30340;&#23398;&#20064;&#26550;&#26500;&#65292;&#36890;&#36807;&#31283;&#23450;&#24615;&#21644;&#35748;&#35777;&#23548;&#21521;&#65292;&#29983;&#25104;&#21487;&#38752;&#30340;&#25968;&#25454;&#39537;&#21160;&#26367;&#20195;&#27169;&#22411;&#65292;&#24182;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#36827;&#34892;&#35748;&#35777;&#25511;&#21046;&#22120;&#35774;&#35745;&#12290;&#23427;&#22312;&#22810;&#20010;&#22522;&#20934;&#31034;&#20363;&#19978;&#23637;&#31034;&#20102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.03145</link><description>&lt;p&gt;
SafEDMD&#65306;&#19968;&#31181;&#19987;&#20026;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#25968;&#25454;&#39537;&#21160;&#25511;&#21046;&#32780;&#35774;&#35745;&#30340;&#35748;&#35777;&#23398;&#20064;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
SafEDMD: A certified learning architecture tailored to data-driven control of nonlinear dynamical systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03145
&lt;/p&gt;
&lt;p&gt;
SafEDMD&#26159;&#19968;&#31181;&#22522;&#20110;EDMD&#30340;&#23398;&#20064;&#26550;&#26500;&#65292;&#36890;&#36807;&#31283;&#23450;&#24615;&#21644;&#35748;&#35777;&#23548;&#21521;&#65292;&#29983;&#25104;&#21487;&#38752;&#30340;&#25968;&#25454;&#39537;&#21160;&#26367;&#20195;&#27169;&#22411;&#65292;&#24182;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#36827;&#34892;&#35748;&#35777;&#25511;&#21046;&#22120;&#35774;&#35745;&#12290;&#23427;&#22312;&#22810;&#20010;&#22522;&#20934;&#31034;&#20363;&#19978;&#23637;&#31034;&#20102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Koopman&#31639;&#23376;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#21160;&#24577;&#25511;&#21046;&#31995;&#32479;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#20854;&#20013;&#31639;&#23376;&#36890;&#36807;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#21551;&#21457;&#24335;&#36817;&#20284;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31283;&#23450;&#24615;&#21644;&#35748;&#35777;&#23548;&#21521;&#30340;EDMD&#65288;SafEDMD&#65289;&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;EDMD&#30340;&#23398;&#20064;&#26550;&#26500;&#65292;&#23427;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#35777;&#20070;&#65292;&#20174;&#32780;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#29983;&#25104;&#21487;&#38752;&#30340;&#26367;&#20195;&#27169;&#22411;&#12290;&#20026;&#20102;&#30830;&#20445;SafEDMD&#30340;&#21487;&#38752;&#24615;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#27604;&#20363;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#22312;&#21407;&#28857;&#22788;&#28040;&#22833;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#25511;&#21046;&#20219;&#21153;&#65292;&#20174;&#32780;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#36827;&#34892;&#35748;&#35777;&#25511;&#21046;&#22120;&#35774;&#35745;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#22522;&#20934;&#31034;&#20363;&#35828;&#26126;&#20102;&#25152;&#24320;&#21457;&#30340;&#26426;&#21046;&#65292;&#24182;&#24378;&#35843;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Koopman operator serves as the theoretical backbone for machine learning of dynamical control systems, where the operator is heuristically approximated by extended dynamic mode decomposition (EDMD). In this paper, we propose Stability- and certificate-oriented EDMD (SafEDMD): a novel EDMD-based learning architecture which comes along with rigorous certificates, resulting in a reliable surrogate model generated in a data-driven fashion. To ensure trustworthiness of SafEDMD, we derive proportional error bounds, which vanish at the origin and are tailored for control tasks, leading to certified controller design based on semi-definite programming. We illustrate the developed machinery by means of several benchmark examples and highlight the advantages over state-of-the-art methods.
&lt;/p&gt;</description></item><item><title>&#24352;&#37327;&#32593;&#32476;&#21487;&#20197;&#24110;&#21161;&#21457;&#23637;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20016;&#23500;&#30340;&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#12290;&#22312;&#32593;&#32476;&#23433;&#20840;&#20013;&#65292;&#25105;&#20204;&#30340;&#26080;&#30417;&#30563;&#32858;&#31867;&#31639;&#27861;&#22522;&#20110;&#30697;&#38453;&#20056;&#31215;&#29366;&#24577;&#65292;&#22312;&#24615;&#33021;&#19978;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30456;&#23218;&#32654;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#33021;&#25552;&#21462;&#29305;&#24449;&#27010;&#29575;&#12289;&#29109;&#21644;&#20114;&#20449;&#24687;&#65292;&#25552;&#20379;&#20102;&#20998;&#31867;&#24322;&#24120;&#30340;&#24341;&#20154;&#20837;&#32988;&#30340;&#21465;&#36848;&#65292;&#24182;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36879;&#26126;&#24230;&#21644;&#21487;&#35299;&#37322;&#24615;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2401.00867</link><description>&lt;p&gt;
&#24352;&#37327;&#32593;&#32476;&#22312;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#22312;&#32593;&#32476;&#23433;&#20840;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Tensor Networks for Explainable Machine Learning in Cybersecurity. (arXiv:2401.00867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00867
&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#32593;&#32476;&#21487;&#20197;&#24110;&#21161;&#21457;&#23637;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20016;&#23500;&#30340;&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#12290;&#22312;&#32593;&#32476;&#23433;&#20840;&#20013;&#65292;&#25105;&#20204;&#30340;&#26080;&#30417;&#30563;&#32858;&#31867;&#31639;&#27861;&#22522;&#20110;&#30697;&#38453;&#20056;&#31215;&#29366;&#24577;&#65292;&#22312;&#24615;&#33021;&#19978;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30456;&#23218;&#32654;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#33021;&#25552;&#21462;&#29305;&#24449;&#27010;&#29575;&#12289;&#29109;&#21644;&#20114;&#20449;&#24687;&#65292;&#25552;&#20379;&#20102;&#20998;&#31867;&#24322;&#24120;&#30340;&#24341;&#20154;&#20837;&#32988;&#30340;&#21465;&#36848;&#65292;&#24182;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36879;&#26126;&#24230;&#21644;&#21487;&#35299;&#37322;&#24615;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#24352;&#37327;&#32593;&#32476;&#22914;&#20309;&#24110;&#21161;&#21457;&#23637;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22522;&#20110;&#30697;&#38453;&#20056;&#31215;&#29366;&#24577;&#65288;MPS&#65289;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#23454;&#38469;&#20351;&#29992;&#26696;&#20363;&#20013;&#30340;&#23545;&#25163;&#29983;&#25104;&#30340;&#23041;&#32961;&#24773;&#25253;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#35777;&#26126;&#65292;MPS&#22312;&#24615;&#33021;&#26041;&#38754;&#21487;&#20197;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#33258;&#32534;&#30721;&#22120;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30456;&#23218;&#32654;&#65292;&#21516;&#26102;&#25552;&#20379;&#26356;&#20016;&#23500;&#30340;&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#22320;&#20419;&#36827;&#20102;&#29305;&#24449;&#27010;&#29575;&#12289;&#20911;&#183;&#35834;&#20234;&#26364;&#29109;&#21644;&#20114;&#20449;&#24687;&#30340;&#25552;&#21462;&#65292;&#20026;&#24322;&#24120;&#20998;&#31867;&#25552;&#20379;&#20102;&#24341;&#20154;&#20837;&#32988;&#30340;&#21465;&#36848;&#65292;&#24182;&#20419;&#36827;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36879;&#26126;&#24230;&#21644;&#21487;&#35299;&#37322;&#24615;&#27700;&#24179;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#20154;&#24037;&#26234;&#33021;&#20915;&#31574;&#30340;&#22522;&#26412;&#21407;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we show how tensor networks help in developing explainability of machine learning algorithms. Specifically, we develop an unsupervised clustering algorithm based on Matrix Product States (MPS) and apply it in the context of a real use-case of adversary-generated threat intelligence. Our investigation proves that MPS rival traditional deep learning models such as autoencoders and GANs in terms of performance, while providing much richer model interpretability. Our approach naturally facilitates the extraction of feature-wise probabilities, Von Neumann Entropy, and mutual information, offering a compelling narrative for classification of anomalies and fostering an unprecedented level of transparency and interpretability, something fundamental to understand the rationale behind artificial intelligence decisions.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25239;&#24615;&#34892;&#20026;&#30340;&#38887;&#24615;&#22635;&#34917;&#20102;&#29616;&#26377;&#30740;&#31350;&#31354;&#30333;&#65292;&#24182;&#21457;&#29616;&#28508;&#22312;&#29305;&#24449;&#22312;&#30456;&#21516;&#20449;&#24687;&#22833;&#30495;&#27700;&#24179;&#19979;&#27604;&#36755;&#20837;&#34920;&#31034;&#26356;&#21152;&#38887;&#24615;&#65292;&#24182;&#19988;&#23545;&#25239;&#24615;&#38887;&#24615;&#30001;&#29305;&#24449;&#32500;&#24230;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#20849;&#21516;&#20915;&#23450;&#12290;</title><link>http://arxiv.org/abs/2309.17401</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#28508;&#22312;&#34920;&#31034;&#20013;&#30340;&#23545;&#25239;&#24615;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarial Machine Learning in Latent Representations of Neural Networks. (arXiv:2309.17401v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17401
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25239;&#24615;&#34892;&#20026;&#30340;&#38887;&#24615;&#22635;&#34917;&#20102;&#29616;&#26377;&#30740;&#31350;&#31354;&#30333;&#65292;&#24182;&#21457;&#29616;&#28508;&#22312;&#29305;&#24449;&#22312;&#30456;&#21516;&#20449;&#24687;&#22833;&#30495;&#27700;&#24179;&#19979;&#27604;&#36755;&#20837;&#34920;&#31034;&#26356;&#21152;&#38887;&#24615;&#65292;&#24182;&#19988;&#23545;&#25239;&#24615;&#38887;&#24615;&#30001;&#29305;&#24449;&#32500;&#24230;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#20849;&#21516;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#20943;&#36731;&#31227;&#21160;&#35774;&#22791;&#30340;&#35745;&#31639;&#36127;&#25285;&#65292;&#24182;&#38477;&#20302;&#36793;&#32536;&#35745;&#31639;&#22330;&#26223;&#20013;&#30340;&#31471;&#21040;&#31471;&#25512;&#29702;&#24310;&#36831;&#12290;&#23613;&#31649;&#24050;&#32463;&#23545;&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#20110;&#23545;&#25239;&#24615;&#34892;&#20026;&#30340;&#38887;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20005;&#26684;&#20998;&#26512;&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25239;&#24615;&#34892;&#20026;&#30340;&#38887;&#24615;&#26469;&#22635;&#34917;&#29616;&#26377;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#32622;&#20110;&#20449;&#24687;&#35770;&#30340;&#32972;&#26223;&#19979;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#30340;&#34913;&#37327;&#25351;&#26631;&#26469;&#34913;&#37327;&#22833;&#30495;&#21644;&#38887;&#24615;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#34920;&#26126;&#65306;&#65288;i&#65289;&#22312;&#20551;&#35774;&#20855;&#26377;&#30456;&#21516;&#20449;&#24687;&#22833;&#30495;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#65292;&#28508;&#22312;&#29305;&#24449;&#22987;&#32456;&#27604;&#36755;&#20837;&#34920;&#31034;&#26356;&#21152;&#38887;&#24615;&#65307;&#65288;ii&#65289;&#23545;&#25239;&#24615;&#38887;&#24615;&#21516;&#26102;&#30001;&#29305;&#24449;&#32500;&#24230;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#20915;&#23450;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#20998;&#26512;&#65292;&#32771;&#34385;&#20102;6&#31181;&#19981;&#21516;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed deep neural networks (DNNs) have been shown to reduce the computational burden of mobile devices and decrease the end-to-end inference latency in edge computing scenarios. While distributed DNNs have been studied, to the best of our knowledge the resilience of distributed DNNs to adversarial action still remains an open problem. In this paper, we fill the existing research gap by rigorously analyzing the robustness of distributed DNNs against adversarial action. We cast this problem in the context of information theory and introduce two new measurements for distortion and robustness. Our theoretical findings indicate that (i) assuming the same level of information distortion, latent features are always more robust than input representations; (ii) the adversarial robustness is jointly determined by the feature dimension and the generalization capability of the DNN. To test our theoretical findings, we perform extensive experimental analysis by considering 6 different DNN arc
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#26368;&#20248;&#20256;&#36755;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;SPD&#27969;&#24418;&#19978;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#29702;&#35770;&#21644;SPD&#27969;&#24418;&#30340;&#23545;&#25968;&#27431;&#20960;&#37324;&#24471;&#20960;&#20309;&#65292;&#25105;&#20204;&#20811;&#26381;&#20102;&#21327;&#26041;&#24046;&#30697;&#38453;&#25805;&#20316;&#30340;&#22797;&#26434;&#24615;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2201.05745</link><description>&lt;p&gt;
&#22522;&#20110;SPD&#27969;&#24418;&#30340;&#28145;&#24230;&#26368;&#20248;&#20256;&#36755;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Deep Optimal Transport for Domain Adaptation on SPD Manifolds. (arXiv:2201.05745v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.05745
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#26368;&#20248;&#20256;&#36755;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;SPD&#27969;&#24418;&#19978;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#29702;&#35770;&#21644;SPD&#27969;&#24418;&#30340;&#23545;&#25968;&#27431;&#20960;&#37324;&#24471;&#20960;&#20309;&#65292;&#25105;&#20204;&#20811;&#26381;&#20102;&#21327;&#26041;&#24046;&#30697;&#38453;&#25805;&#20316;&#30340;&#22797;&#26434;&#24615;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#30028;&#23545;&#20110;&#22312;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#27969;&#24418;&#19978;&#35299;&#20915;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;DA&#65289;&#38382;&#39064;&#34920;&#29616;&#20986;&#20102;&#24456;&#22823;&#20852;&#36259;&#12290;&#36825;&#31181;&#20852;&#36259;&#28304;&#20110;&#21307;&#30103;&#35774;&#22791;&#20135;&#29983;&#30340;&#22797;&#26434;&#31070;&#32463;&#29289;&#29702;&#25968;&#25454;&#65288;&#22914;&#33041;&#30005;&#22270;&#12289;&#33041;&#30913;&#22270;&#21644;&#25193;&#25955;&#24352;&#37327;&#25104;&#20687;&#65289;&#22312;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#23384;&#22312;&#25968;&#25454;&#20998;&#24067;&#30340;&#20559;&#31227;&#12290;&#36825;&#20123;&#25968;&#25454;&#34920;&#31034;&#20197;&#20449;&#21495;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#24418;&#24335;&#34920;&#31034;&#65292;&#24182;&#20855;&#26377;&#23545;&#31216;&#24615;&#21644;&#27491;&#23450;&#24615;&#30340;&#23646;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#22797;&#26434;&#25805;&#20316;&#29305;&#24615;&#65292;&#30452;&#25509;&#23558;&#20808;&#21069;&#30340;&#32463;&#39564;&#21644;&#35299;&#20915;&#26041;&#26696;&#24212;&#29992;&#20110;DA&#38382;&#39064;&#23384;&#22312;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31867;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;&#28145;&#24230;&#26368;&#20248;&#20256;&#36755;&#12290;&#36825;&#19968;&#31867;&#26041;&#27861;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#29702;&#35770;&#65292;&#24182;&#21033;&#29992;SPD&#27969;&#24418;&#30340;&#23545;&#25968;&#27431;&#20960;&#37324;&#24471;&#20960;&#20309;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;...
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been significant interest in solving the domain adaptation (DA) problem on symmetric positive definite (SPD) manifolds within the machine learning community. This interest stems from the fact that complex neurophysiological data generated by medical equipment, such as electroencephalograms, magnetoencephalograms, and diffusion tensor imaging, often exhibit a shift in data distribution across different domains. These data representations, represented by signal covariance matrices, possess properties of symmetry and positive definiteness. However, directly applying previous experiences and solutions to the DA problem poses challenges due to the manipulation complexities of covariance matrices.To address this, our research introduces a category of deep learning-based transfer learning approaches called deep optimal transport. This category utilizes optimal transport theory and leverages the Log-Euclidean geometry for SPD manifolds. Additionally, we present a com
&lt;/p&gt;</description></item></channel></rss>