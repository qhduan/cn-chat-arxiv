<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411; CF-CBMs&#65292;&#21487;&#20197;&#21516;&#26102;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#12289;&#35299;&#37322;&#21644;&#24819;&#35937;&#33021;&#21147;&#30340;&#19981;&#36275;&#65292;&#20026;&#37096;&#32626;&#21487;&#38752;&#30340;AI&#20195;&#29702;&#12289;&#26657;&#20934;&#20154;&#31867;&#20449;&#20219;&#21644;&#21152;&#28145;&#20154;&#26426;&#20132;&#20114;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01408</link><description>&lt;p&gt;
&#36890;&#36807;&#21453;&#20107;&#23454;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#25856;&#30331;&#35299;&#37322;&#24615;&#30340;&#38454;&#26799;
&lt;/p&gt;
&lt;p&gt;
Climbing the Ladder of Interpretability with Counterfactual Concept Bottleneck Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411; CF-CBMs&#65292;&#21487;&#20197;&#21516;&#26102;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#12289;&#35299;&#37322;&#21644;&#24819;&#35937;&#33021;&#21147;&#30340;&#19981;&#36275;&#65292;&#20026;&#37096;&#32626;&#21487;&#38752;&#30340;AI&#20195;&#29702;&#12289;&#26657;&#20934;&#20154;&#31867;&#20449;&#20219;&#21644;&#21152;&#28145;&#20154;&#26426;&#20132;&#20114;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#27809;&#26377;&#21516;&#26102;&#35299;&#20915;&#19977;&#20010;&#22522;&#26412;&#38382;&#39064;&#30340;&#35774;&#35745;&#65306;&#39044;&#27979;&#31867;&#21035;&#26631;&#31614;&#20197;&#35299;&#20915;&#32473;&#23450;&#30340;&#20998;&#31867;&#20219;&#21153;&#65288;&#8220;&#26159;&#20160;&#20040;&#65311;&#8221;&#65289;&#65292;&#35299;&#37322;&#20219;&#21153;&#39044;&#27979;&#65288;&#8220;&#20026;&#20160;&#20040;&#65311;&#8221;&#65289;&#65292;&#24182;&#24819;&#35937;&#21487;&#33021;&#23548;&#33268;&#19981;&#21516;&#39044;&#27979;&#30340;&#26367;&#20195;&#24773;&#26223;&#65288;&#8220;&#22914;&#26524;&#24590;&#26679;&#65311;&#8221;&#65289;&#12290;&#26080;&#27861;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#20195;&#34920;&#20102;&#37096;&#32626;&#21487;&#38752;&#30340;AI&#20195;&#29702;&#12289;&#26657;&#20934;&#20154;&#31867;&#20449;&#20219;&#21644;&#21152;&#28145;&#20154;&#26426;&#20132;&#20114;&#30340;&#20851;&#38190;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CF-CBMs&#65289;&#65292;&#36825;&#26159;&#19968;&#31867;&#33021;&#22815;&#39640;&#25928;&#21516;&#26102;&#35299;&#20915;&#19978;&#36848;&#26597;&#35810;&#32780;&#26080;&#38656;&#36827;&#34892;&#20107;&#21518;&#25628;&#32034;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;CF-CBMs&#33021;&#22815;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#65288;&#8220;&#26159;&#20160;&#20040;&#65311;&#8221;&#65289;&#65292;&#23545;&#20219;&#21153;&#39044;&#27979;&#25552;&#20379;&#31616;&#21333;&#30340;&#35299;&#37322;&#65288;&#8220;&#20026;&#20160;&#20040;&#65311;&#8221;&#65289;&#65292;&#20197;&#21450;&#21487;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#24773;&#20917;&#65288;&#8220;&#22914;&#26524;&#24590;&#26679;&#65311;&#8221;&#65289;&#12290;CF-CBMs&#36824;&#21487;&#20197;&#23545;&#27010;&#24565;&#24178;&#39044;&#30340;&#24433;&#21709;&#36827;&#34892;&#37319;&#26679;&#25110;&#20272;&#35745;&#26368;&#21487;&#33021;&#30340;&#21453;&#20107;&#23454;&#24773;&#20917;&#65292;&#20197;&#35299;&#37322;&#20107;&#20214;&#65292;&#24182;&#20248;&#21270;&#20135;&#29983;&#22810;&#26679;&#21270;&#30340;&#21453;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current deep learning models are not designed to simultaneously address three fundamental questions: predict class labels to solve a given classification task (the "What?"), explain task predictions (the "Why?"), and imagine alternative scenarios that could result in different predictions (the "What if?"). The inability to answer these questions represents a crucial gap in deploying reliable AI agents, calibrating human trust, and deepening human-machine interaction. To bridge this gap, we introduce CounterFactual Concept Bottleneck Models (CF-CBMs), a class of models designed to efficiently address the above queries all at once without the need to run post-hoc searches. Our results show that CF-CBMs produce: accurate predictions (the "What?"), simple explanations for task predictions (the "Why?"), and interpretable counterfactuals (the "What if?"). CF-CBMs can also sample or estimate the most probable counterfactual to: (i) explain the effect of concept interventions on tasks, (ii) sh
&lt;/p&gt;</description></item><item><title>LS&#26041;&#27861;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#35757;&#32451;&#20013;&#30340;&#26631;&#31614;&#24179;&#28369;&#25928;&#26524;&#34987;&#21457;&#29616;&#20250;&#36127;&#38754;&#24433;&#21709;&#36873;&#25321;&#24615;&#20998;&#31867;&#65292;&#36890;&#36807;&#24433;&#21709;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#27492;&#30740;&#31350;&#38416;&#26126;&#20102;&#36825;&#19968;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2403.14715</link><description>&lt;p&gt;
&#29702;&#35299;&#20026;&#20309;&#26631;&#31614;&#24179;&#28369;&#20250;&#38477;&#20302;&#36873;&#25321;&#24615;&#20998;&#31867;&#30340;&#25928;&#26524;&#20197;&#21450;&#22914;&#20309;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Understanding Why Label Smoothing Degrades Selective Classification and How to Fix It
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14715
&lt;/p&gt;
&lt;p&gt;
LS&#26041;&#27861;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#35757;&#32451;&#20013;&#30340;&#26631;&#31614;&#24179;&#28369;&#25928;&#26524;&#34987;&#21457;&#29616;&#20250;&#36127;&#38754;&#24433;&#21709;&#36873;&#25321;&#24615;&#20998;&#31867;&#65292;&#36890;&#36807;&#24433;&#21709;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#27492;&#30740;&#31350;&#38416;&#26126;&#20102;&#36825;&#19968;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#31614;&#24179;&#28369;&#65288;LS&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#35757;&#32451;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22312;&#25552;&#39640;&#27979;&#35797;&#20934;&#30830;&#24615;&#26041;&#38754;&#25928;&#26524;&#26174;&#33879;&#65292;&#24182;&#19988;&#23454;&#29616;&#31616;&#21333;&#12290;"&#30828;"&#30340;one-hot&#26631;&#31614;&#36890;&#36807;&#23558;&#27010;&#29575;&#36136;&#37327;&#22343;&#21248;&#20998;&#37197;&#32473;&#20854;&#20182;&#31867;&#21035;&#26469;&#36827;&#34892;"&#24179;&#28369;&#21270;"&#65292;&#20174;&#32780;&#20943;&#23569;&#36807;&#24230;&#25311;&#21512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;LS&#22914;&#20309;&#36127;&#38754;&#24433;&#21709;&#36873;&#25321;&#24615;&#20998;&#31867;&#65288;SC&#65289;- &#20854;&#30446;&#26631;&#26159;&#21033;&#29992;&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26469;&#25298;&#32477;&#38169;&#35823;&#20998;&#31867;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#31995;&#21015;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#20174;&#32463;&#39564;&#19978;&#35777;&#26126;LS&#20250;&#23548;&#33268;SC&#30340;&#19968;&#33268;&#24615;&#38477;&#32423;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;logit&#32423;&#21035;&#30340;&#26799;&#24230;&#26469;&#35299;&#37322;&#36825;&#19968;&#28857;&#65292;&#34920;&#26126;LS&#36890;&#36807;&#22312;&#38169;&#35823;&#27010;&#29575;&#20302;&#26102;&#26356;&#21152;&#27491;&#21017;&#21270;&#26368;&#22823;logit&#65292;&#32780;&#22312;&#38169;&#35823;&#27010;&#29575;&#39640;&#26102;&#26356;&#23569;&#27491;&#21017;&#21270;&#65292;&#21152;&#21095;&#20102;&#36807;&#24230;&#33258;&#20449;&#21644;&#20302;&#33258;&#20449;&#12290;&#36825;&#38416;&#26126;&#20102;&#20197;&#21069;&#25253;&#36947;&#30340;&#24378;&#20998;&#31867;&#22120;&#22312;SC&#20013;&#24615;&#33021;&#19981;&#20339;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14715v1 Announce Type: cross  Abstract: Label smoothing (LS) is a popular regularisation method for training deep neural network classifiers due to its effectiveness in improving test accuracy and its simplicity in implementation. "Hard" one-hot labels are "smoothed" by uniformly distributing probability mass to other classes, reducing overfitting. In this work, we reveal that LS negatively affects selective classification (SC) - where the aim is to reject misclassifications using a model's predictive uncertainty. We first demonstrate empirically across a range of tasks and architectures that LS leads to a consistent degradation in SC. We then explain this by analysing logit-level gradients, showing that LS exacerbates overconfidence and underconfidence by regularising the max logit more when the probability of error is low, and less when the probability of error is high. This elucidates previously reported experimental results where strong classifiers underperform in SC. We
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#31038;&#21306;&#25289;&#31080;&#30340;&#21160;&#24577;&#22810;&#27493;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#20351;&#24471;&#23545;&#25163;&#33021;&#22815;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#26469;&#31574;&#21010;&#30446;&#26631;&#36873;&#27665;&#30340;&#25805;&#32437;&#12290;</title><link>https://arxiv.org/abs/2403.12399</link><description>&lt;p&gt;
&#23558;&#32593;&#32476;&#36873;&#20030;&#21270;&#65306;&#29992;&#20110;&#31038;&#21306;&#25289;&#31080;&#30340;&#21160;&#24577;&#22810;&#27493;&#23545;&#25239;&#24615;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Electioneering the Network: Dynamic Multi-Step Adversarial Attacks for Community Canvassing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#31038;&#21306;&#25289;&#31080;&#30340;&#21160;&#24577;&#22810;&#27493;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#20351;&#24471;&#23545;&#25163;&#33021;&#22815;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#26469;&#31574;&#21010;&#30446;&#26631;&#36873;&#27665;&#30340;&#25805;&#32437;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20170;&#22825;&#30340;&#19990;&#30028;&#20013;&#65292;&#23545;&#20110;&#31038;&#21306;&#25289;&#31080;&#30340;&#22312;&#32447;&#31038;&#20132;&#32593;&#32476;&#25805;&#32437;&#38382;&#39064;&#26159;&#19968;&#20010;&#30495;&#27491;&#20851;&#27880;&#30340;&#38382;&#39064;&#12290;&#21463;&#36873;&#27665;&#27169;&#22411;&#12289;&#32593;&#32476;&#19978;&#30340;&#35266;&#28857;&#21644;&#26497;&#21270;&#21160;&#24577;&#30340;&#30740;&#31350;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#31038;&#21306;&#25289;&#31080;&#24314;&#27169;&#20026;&#19968;&#20010;&#36890;&#36807;&#23545;GNN&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#32780;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#30340;&#21160;&#24577;&#36807;&#31243;&#12290;&#29616;&#26377;&#30340;GNN&#25915;&#20987;&#37117;&#26159;&#21333;&#27493;&#30340;&#65292;&#27809;&#26377;&#32771;&#34385;&#32593;&#32476;&#20013;&#20449;&#24687;&#20256;&#25773;&#30340;&#21160;&#24577;&#32423;&#32852;&#29305;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#29616;&#23454;&#30340;&#22330;&#26223;&#65292;&#21363;&#23545;&#25163;&#20351;&#29992;GNN&#20316;&#20026;&#20195;&#29702;&#26469;&#39044;&#27979;&#21644;&#25805;&#32437;&#36873;&#27665;&#20559;&#22909;&#65292;&#29305;&#21035;&#26159;&#19981;&#30830;&#23450;&#30340;&#36873;&#27665;&#12290;&#23545;GNN&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#25915;&#20987;&#36890;&#30693;&#23545;&#25163;&#21487;&#20197;&#36827;&#34892;&#25112;&#30053;&#25805;&#32437;&#65292;&#20197;&#20351;&#24471;&#30446;&#26631;&#36873;&#27665;&#20837;&#25945;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;$\textit{&#31038;&#21306;&#25289;&#31080;&#30340;&#26368;&#23567;&#39044;&#31639;&#25915;&#20987;}$&#65288;MBACC&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;MBACC&#38382;&#39064;&#26159;NP&#22256;&#38590;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#21160;&#24577;&#22810;&#27493;&#23545;&#25239;&#24615;&#31038;&#21306;&#25289;&#31080;&#65288;MAC&#65289;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;MAC m
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12399v1 Announce Type: new  Abstract: The problem of online social network manipulation for community canvassing is of real concern in today's world. Motivated by the study of voter models, opinion and polarization dynamics on networks, we model community canvassing as a dynamic process over a network enabled via gradient-based attacks on GNNs. Existing attacks on GNNs are all single-step and do not account for the dynamic cascading nature of information diffusion in networks. We consider the realistic scenario where an adversary uses a GNN as a proxy to predict and manipulate voter preferences, especially uncertain voters. Gradient-based attacks on the GNN inform the adversary of strategic manipulations that can be made to proselytize targeted voters. In particular, we explore $\textit{minimum budget attacks for community canvassing}$ (MBACC). We show that the MBACC problem is NP-Hard and propose Dynamic Multi-Step Adversarial Community Canvassing (MAC) to address it. MAC m
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#31574;&#30053;&#65292;&#24213;&#29289;&#33539;&#22260;&#23545;&#27604;&#23398;&#20064;&#65292;&#20197;&#23398;&#20064;&#36866;&#21512;&#21270;&#23398;&#21453;&#24212;&#24615;&#30340;&#21407;&#23376;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.16882</link><description>&lt;p&gt;
&#24213;&#29289;&#33539;&#22260;&#23545;&#27604;&#23398;&#20064;&#65306;&#37325;&#26032;&#21033;&#29992;&#20154;&#31867;&#20559;&#35265;&#23398;&#20064;&#21407;&#23376;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Substrate Scope Contrastive Learning: Repurposing Human Bias to Learn Atomic Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16882
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#31574;&#30053;&#65292;&#24213;&#29289;&#33539;&#22260;&#23545;&#27604;&#23398;&#20064;&#65292;&#20197;&#23398;&#20064;&#36866;&#21512;&#21270;&#23398;&#21453;&#24212;&#24615;&#30340;&#21407;&#23376;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#26159;&#20998;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#23545;&#24314;&#27169;&#25104;&#21151;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65292;&#23588;&#20854;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#12290;&#24191;&#20041;&#39044;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#27010;&#24565;&#25512;&#21160;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#34507;&#30333;&#36136;&#24037;&#31243;&#31561;&#39046;&#22495;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#31867;&#20284;&#30340;&#26041;&#27861;&#22312;&#23567;&#26377;&#26426;&#20998;&#23376;&#26041;&#38754;&#24182;&#26410;&#21462;&#24471;&#31867;&#20284;&#30340;&#25104;&#21151;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#31574;&#30053;&#65292;&#21363;&#24213;&#29289;&#33539;&#22260;&#23545;&#27604;&#23398;&#20064;&#65292;&#23427;&#23398;&#20064;&#36866;&#21512;&#21270;&#23398;&#21453;&#24212;&#24615;&#30340;&#21407;&#23376;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#20197;&#24050;&#21457;&#34920;&#30340;&#24213;&#29289;&#33539;&#22260;&#34920;&#20013;&#24213;&#29289;&#30340;&#20998;&#32452;&#21644;&#20135;&#29289;&#25910;&#29575;&#20316;&#20026;&#21270;&#23398;&#21453;&#24212;&#24615;&#30456;&#20284;&#24615;&#25110;&#19981;&#30456;&#20284;&#24615;&#30340;&#34913;&#37327;&#12290;&#25105;&#20204;&#20851;&#27880; CAS Content Collection &#20013;&#30340; 20,798 &#20010;&#33459;&#39321;&#21348;&#20195;&#28867;&#65292;&#28085;&#30422;&#25968;&#21315;&#31687;&#20986;&#29256;&#29289;&#65292;&#20197;&#23398;&#20064;&#33459;&#39321;&#21348;&#20195;&#28867;&#30340;&#21453;&#24212;&#24615;&#34920;&#31034;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16882v1 Announce Type: cross  Abstract: Learning molecular representation is a critical step in molecular machine learning that significantly influences modeling success, particularly in data-scarce situations. The concept of broadly pre-training neural networks has advanced fields such as computer vision, natural language processing, and protein engineering. However, similar approaches for small organic molecules have not achieved comparable success. In this work, we introduce a novel pre-training strategy, substrate scope contrastive learning, which learns atomic representations tailored to chemical reactivity. This method considers the grouping of substrates and their yields in published substrate scope tables as a measure of their similarity or dissimilarity in terms of chemical reactivity. We focus on 20,798 aryl halides in the CAS Content Collection spanning thousands of publications to learn a representation of aryl halide reactivity. We validate our pre-training appr
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#24322;&#24120;&#26816;&#27979;&#31995;&#32479;&#20013;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#20132;&#21449;&#19968;&#33268;&#24322;&#24120;&#26816;&#27979;&#65292;&#36890;&#36807;&#26657;&#20934;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.16388</link><description>&lt;p&gt;
&#20855;&#26377;&#20132;&#21449;&#19968;&#33268;$p$-&#20540;&#30340;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification in Anomaly Detection with Cross-Conformal $p$-Values
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16388
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#24322;&#24120;&#26816;&#27979;&#31995;&#32479;&#20013;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#20132;&#21449;&#19968;&#33268;&#24322;&#24120;&#26816;&#27979;&#65292;&#36890;&#36807;&#26657;&#20934;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21487;&#38752;&#12289;&#21487;&#20449;&#21644;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#26085;&#30410;&#22686;&#21152;&#65292;&#23545;&#24322;&#24120;&#26816;&#27979;&#31995;&#32479;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#35201;&#27714;&#21464;&#24471;&#24840;&#21457;&#37325;&#35201;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#25511;&#21046;&#31867;&#22411;I&#38169;&#35823;&#29575;($\alpha$)&#32780;&#21448;&#19981;&#25439;&#23475;&#31995;&#32479;&#30340;&#32479;&#35745;&#21151;&#29575;($1-\beta$)&#21487;&#20197;&#24314;&#31435;&#20449;&#20219;&#65292;&#24182;&#20943;&#23569;&#19982;&#20551;&#21457;&#29616;&#30456;&#20851;&#30340;&#25104;&#26412;&#65292;&#29305;&#21035;&#26159;&#24403;&#21518;&#32493;&#31243;&#24207;&#26114;&#36149;&#26102;&#12290;&#21033;&#29992;&#31526;&#21512;&#39044;&#27979;&#21407;&#21017;&#30340;&#26041;&#27861;&#26377;&#26395;&#36890;&#36807;&#26657;&#20934;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#20026;&#24322;&#24120;&#26816;&#27979;&#25552;&#20379;&#30456;&#24212;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#35813;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#24322;&#24120;&#26816;&#27979;&#26694;&#26550;&#65292;&#31216;&#20026;&#20132;&#21449;&#19968;&#33268;&#24322;&#24120;&#26816;&#27979;&#65292;&#24314;&#31435;&#22312;&#20026;&#39044;&#27979;&#20219;&#21153;&#35774;&#35745;&#30340;&#33879;&#21517;&#20132;&#21449;&#19968;&#33268;&#26041;&#27861;&#20043;&#19978;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#20182;&#22635;&#34917;&#20102;&#22312;&#24402;&#32435;&#19968;&#33268;&#24322;&#24120;&#26816;&#27979;&#29615;&#22659;&#20013;&#25193;&#23637;&#20808;&#21069;&#30740;&#31350;&#30340;&#33258;&#28982;&#30740;&#31350;&#31354;&#30333;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16388v1 Announce Type: cross  Abstract: Given the growing significance of reliable, trustworthy, and explainable machine learning, the requirement of uncertainty quantification for anomaly detection systems has become increasingly important. In this context, effectively controlling Type I error rates ($\alpha$) without compromising the statistical power ($1-\beta$) of these systems can build trust and reduce costs related to false discoveries, particularly when follow-up procedures are expensive. Leveraging the principles of conformal prediction emerges as a promising approach for providing respective statistical guarantees by calibrating a model's uncertainty. This work introduces a novel framework for anomaly detection, termed cross-conformal anomaly detection, building upon well-known cross-conformal methods designed for prediction tasks. With that, it addresses a natural research gap by extending previous works in the context of inductive conformal anomaly detection, rel
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#21487;&#20998;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;DP-SGD&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#30456;&#20284;&#24615;&#25439;&#22833;&#20989;&#25968;&#30340;$L_2$&#25935;&#24863;&#24230;&#22686;&#38271;&#38543;&#30528;&#25209;&#37327;&#22823;&#23567;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.03104</link><description>&lt;p&gt;
&#38750;&#21487;&#20998;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;DP-SGD&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DP-SGD for non-decomposable objective functions. (arXiv:2310.03104v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03104
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#21487;&#20998;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;DP-SGD&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#30456;&#20284;&#24615;&#25439;&#22833;&#20989;&#25968;&#30340;$L_2$&#25935;&#24863;&#24230;&#22686;&#38271;&#38543;&#30528;&#25209;&#37327;&#22823;&#23567;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#26159;&#24320;&#21457;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24120;&#35265;&#27493;&#39588;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#30001;&#20110;&#32570;&#23569;&#26631;&#31614;&#65292;&#38656;&#35201;&#20351;&#29992;&#22522;&#20110;&#30456;&#20284;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#22914;&#23545;&#27604;&#25439;&#22833;&#65292;&#26469;&#20248;&#21270;&#30456;&#20284;&#36755;&#20837;&#20043;&#38388;&#30340;&#36317;&#31163;&#24182;&#26368;&#22823;&#21270;&#19981;&#21516;&#36755;&#20837;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#38543;&#30528;&#38544;&#31169;&#38382;&#39064;&#30340;&#22686;&#22810;&#65292;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#26469;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#21464;&#24471;&#26356;&#21152;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#29983;&#25104;&#36755;&#20837;&#30340;&#26041;&#24335;&#65292;&#23427;&#20204;&#30340;$L_2$&#25935;&#24863;&#24230;&#20250;&#38543;&#30528;&#25209;&#37327;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#36825;&#23545;&#20110;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#26041;&#27861;&#65288;&#22914;DP-SGD&#65289;&#29305;&#21035;&#19981;&#21033;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;DP-SGD&#21464;&#20307;&#65292;&#29992;&#20110;&#22522;&#20110;&#30456;&#20284;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#29305;&#21035;&#26159;&#24120;&#29992;&#30340;&#23545;&#27604;&#25439;&#22833;&#65292;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24335;&#22788;&#29702;&#30446;&#26631;&#20989;&#25968;&#30340;&#26799;&#24230;&#65292;&#20351;&#24471;&#26799;&#24230;&#30340;&#25935;&#24863;&#24230;&#23545;&#20110;&#25209;&#37327;&#22823;&#23567;&#26159;$O(1)$&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised pre-training is a common step in developing computer vision models and large language models. In this setting, the absence of labels requires the use of similarity-based loss functions, such as contrastive loss, that favor minimizing the distance between similar inputs and maximizing the distance between distinct inputs. As privacy concerns mount, training these models using differential privacy has become more important. However, due to how inputs are generated for these losses, one of their undesirable properties is that their $L_2$ sensitivity can grow with increasing batch size. This property is particularly disadvantageous for differentially private training methods, such as DP-SGD. To overcome this issue, we develop a new DP-SGD variant for similarity based loss functions -- in particular the commonly used contrastive loss -- that manipulates gradients of the objective function in a novel way to obtain a senstivity of the summed gradient that is $O(1)$ for batch size
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35760;&#24518;&#21270;&#34892;&#20026;&#65292;&#21457;&#29616;&#35760;&#24518;&#21270;&#20542;&#21521;&#20110;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#19978;&#21457;&#29983;&#12290;&#36890;&#36807;&#23450;&#20041;&#26377;&#25928;&#27169;&#22411;&#35760;&#24518;&#21270; (EMM) &#36825;&#19968;&#25351;&#26631;&#65292;&#37327;&#21270;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#37197;&#32622;&#23545;&#35760;&#24518;&#21270;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.02664</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#35760;&#24518;&#21270;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Memorization in Diffusion Models. (arXiv:2310.02664v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35760;&#24518;&#21270;&#34892;&#20026;&#65292;&#21457;&#29616;&#35760;&#24518;&#21270;&#20542;&#21521;&#20110;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#19978;&#21457;&#29983;&#12290;&#36890;&#36807;&#23450;&#20041;&#26377;&#25928;&#27169;&#22411;&#35760;&#24518;&#21270; (EMM) &#36825;&#19968;&#25351;&#26631;&#65292;&#37327;&#21270;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#37197;&#32622;&#23545;&#35760;&#24518;&#21270;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#20854;&#29983;&#25104;&#26032;&#39062;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#33021;&#21147;&#65292;&#25193;&#25955;&#27169;&#22411;&#24341;&#36215;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#20856;&#22411;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#21363;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#65292;&#25193;&#25955;&#27169;&#22411;&#21482;&#33021;&#29983;&#25104;&#22797;&#21046;&#35757;&#32451;&#25968;&#25454;&#30340;&#26679;&#26412;&#65292;&#36825;&#34920;&#26126;&#22312;&#29702;&#35770;&#19978;&#20250;&#20986;&#29616;&#35760;&#24518;&#21270;&#30340;&#34892;&#20026;&#65292;&#36825;&#19982;&#29616;&#26377;&#20808;&#36827;&#25193;&#25955;&#27169;&#22411;&#30340;&#26222;&#36941;&#27867;&#21270;&#33021;&#21147;&#30456;&#30683;&#30462;&#65292;&#22240;&#27492;&#38656;&#35201;&#28145;&#20837;&#29702;&#35299;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#35760;&#24518;&#21270;&#34892;&#20026;&#20542;&#21521;&#20110;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#19978;&#21457;&#29983;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26377;&#25928;&#27169;&#22411;&#35760;&#24518;&#21270;(EMM)&#30340;&#23450;&#20041;&#65292;&#36825;&#26159;&#19968;&#31181;&#34913;&#37327;&#23398;&#20064;&#30340;&#25193;&#25955;&#27169;&#22411;&#22312;&#26368;&#22823;&#25968;&#25454;&#38598;&#19978;&#36817;&#20284;&#20854;&#29702;&#35770;&#26368;&#20248;&#28857;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#24433;&#21709;&#36825;&#20123;&#35760;&#24518;&#21270;&#34892;&#20026;&#30340;&#37325;&#35201;&#22240;&#32032;&#65292;&#37325;&#28857;&#20851;&#27880;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to their capacity to generate novel and high-quality samples, diffusion models have attracted significant research interest in recent years. Notably, the typical training objective of diffusion models, i.e., denoising score matching, has a closed-form optimal solution that can only generate training data replicating samples. This indicates that a memorization behavior is theoretically expected, which contradicts the common generalization ability of state-of-the-art diffusion models, and thus calls for a deeper understanding. Looking into this, we first observe that memorization behaviors tend to occur on smaller-sized datasets, which motivates our definition of effective model memorization (EMM), a metric measuring the maximum size of training data at which a learned diffusion model approximates its theoretical optimum. Then, we quantify the impact of the influential factors on these memorization behaviors in terms of EMM, focusing primarily on data distribution, model configuratio
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;SEA&#65292;&#19968;&#31181;&#29992;&#20110;&#24402;&#22240;&#22522;&#20110;&#26597;&#35810;&#30340;&#40657;&#30418;&#25915;&#20987;&#30340;&#26426;&#22120;&#23398;&#20064;&#23433;&#20840;&#31995;&#32479;&#65292;&#36890;&#36807;&#21033;&#29992;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#26694;&#26550;&#26469;&#29702;&#35299;&#25915;&#20987;&#30340;&#28436;&#21464;&#36807;&#31243;&#65292;&#24182;&#26377;&#25928;&#24402;&#22240;&#25915;&#20987;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#31532;&#20108;&#27425;&#20986;&#29616;&#30340;&#25915;&#20987;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#26088;&#22312;&#23454;&#29616;&#21462;&#35777;&#21644;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#24773;&#25253;&#20849;&#20139;&#12290;</title><link>http://arxiv.org/abs/2308.11845</link><description>&lt;p&gt;
SEA&#65306;&#21487;&#20849;&#20139;&#21644;&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;&#26597;&#35810;&#30340;&#40657;&#30418;&#25915;&#20987;&#24402;&#22240;
&lt;/p&gt;
&lt;p&gt;
SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks. (arXiv:2308.11845v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11845
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;SEA&#65292;&#19968;&#31181;&#29992;&#20110;&#24402;&#22240;&#22522;&#20110;&#26597;&#35810;&#30340;&#40657;&#30418;&#25915;&#20987;&#30340;&#26426;&#22120;&#23398;&#20064;&#23433;&#20840;&#31995;&#32479;&#65292;&#36890;&#36807;&#21033;&#29992;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#26694;&#26550;&#26469;&#29702;&#35299;&#25915;&#20987;&#30340;&#28436;&#21464;&#36807;&#31243;&#65292;&#24182;&#26377;&#25928;&#24402;&#22240;&#25915;&#20987;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#31532;&#20108;&#27425;&#20986;&#29616;&#30340;&#25915;&#20987;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#26088;&#22312;&#23454;&#29616;&#21462;&#35777;&#21644;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#24773;&#25253;&#20849;&#20139;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#26469;&#33258;&#22522;&#20110;&#26597;&#35810;&#30340;&#40657;&#30418;&#25915;&#20987;&#30340;&#25932;&#23545;&#26679;&#26412;&#30340;&#25915;&#20987;&#12290;&#23613;&#31649;&#26377;&#21508;&#31181;&#21162;&#21147;&#26469;&#26816;&#27979;&#21644;&#38450;&#27490;&#36825;&#20123;&#25915;&#20987;&#65292;&#20294;&#20173;&#28982;&#38656;&#35201;&#19968;&#31181;&#26356;&#20840;&#38754;&#30340;&#26041;&#27861;&#26469;&#35760;&#24405;&#12289;&#20998;&#26512;&#21644;&#20998;&#20139;&#25915;&#20987;&#35777;&#25454;&#12290;&#34429;&#28982;&#32463;&#20856;&#23433;&#20840;&#39046;&#22495;&#21463;&#30410;&#20110;&#25104;&#29087;&#30340;&#21462;&#35777;&#21644;&#24773;&#25253;&#20849;&#20139;&#25216;&#26415;&#65292;&#20294;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#23578;&#26410;&#25214;&#21040;&#19968;&#31181;&#26041;&#24335;&#26469;&#23545;&#25915;&#20987;&#32773;&#36827;&#34892;&#30011;&#20687;&#65292;&#24182;&#20998;&#20139;&#20851;&#20110;&#20182;&#20204;&#30340;&#20449;&#24687;&#12290;&#20026;&#27492;&#65292;&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;SEA&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#23433;&#20840;&#31995;&#32479;&#65292;&#29992;&#20110;&#20026;&#21462;&#35777;&#30446;&#30340;&#34920;&#24449;&#23545;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#40657;&#30418;&#25915;&#20987;&#65292;&#24182;&#20419;&#36827;&#21487;&#35299;&#37322;&#30340;&#24773;&#25253;&#20849;&#20139;&#12290;SEA&#21033;&#29992;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#26694;&#26550;&#23558;&#35266;&#23519;&#21040;&#30340;&#26597;&#35810;&#24207;&#21015;&#24402;&#22240;&#20110;&#24050;&#30693;&#30340;&#25915;&#20987;&#65292;&#22240;&#27492;&#23427;&#33021;&#22815;&#29702;&#35299;&#25915;&#20987;&#30340;&#28436;&#21464;&#36807;&#31243;&#32780;&#19981;&#20165;&#20165;&#20851;&#27880;&#26368;&#32456;&#30340;&#25932;&#23545;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;SEA&#33021;&#22815;&#26377;&#25928;&#36827;&#34892;&#25915;&#20987;&#24402;&#22240;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#31532;&#20108;&#27425;&#20986;&#29616;&#30340;&#25915;&#20987;&#65292;&#20063;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) systems are vulnerable to adversarial examples, particularly those from query-based black-box attacks. Despite various efforts to detect and prevent such attacks, there is a need for a more comprehensive approach to logging, analyzing, and sharing evidence of attacks. While classic security benefits from well-established forensics and intelligence sharing, Machine Learning is yet to find a way to profile its attackers and share information about them. In response, this paper introduces SEA, a novel ML security system to characterize black-box attacks on ML systems for forensic purposes and to facilitate human-explainable intelligence sharing. SEA leverages the Hidden Markov Models framework to attribute the observed query sequence to known attacks. It thus understands the attack's progression rather than just focusing on the final adversarial examples. Our evaluations reveal that SEA is effective at attack attribution, even on their second occurrence, and is robus
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#26102;&#38388;&#35270;&#37326;&#30340;&#37325;&#35201;&#24615;&#65292;&#21457;&#29616;&#30701;&#20110;&#23454;&#38469;&#20540;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#21487;&#20197;&#26356;&#24555;&#19988;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#22870;&#21169;&#20989;&#25968;&#65292;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21628;&#21505;&#22312;IRL&#20013;&#21516;&#26102;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#12290;</title><link>http://arxiv.org/abs/2307.06541</link><description>&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Effective Horizon of Inverse Reinforcement Learning. (arXiv:2307.06541v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#26102;&#38388;&#35270;&#37326;&#30340;&#37325;&#35201;&#24615;&#65292;&#21457;&#29616;&#30701;&#20110;&#23454;&#38469;&#20540;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#21487;&#20197;&#26356;&#24555;&#19988;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#22870;&#21169;&#20989;&#25968;&#65292;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21628;&#21505;&#22312;IRL&#20013;&#21516;&#26102;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#31639;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#22522;&#20110;&#32473;&#23450;&#26102;&#38388;&#35270;&#37326;&#30340;&#65288;&#21069;&#21521;&#65289;&#24378;&#21270;&#23398;&#20064;&#25110;&#35268;&#21010;&#26469;&#35745;&#31639;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#31574;&#30053;&#65292;&#28982;&#21518;&#23558;&#35813;&#31574;&#30053;&#19982;&#19987;&#23478;&#28436;&#31034;&#21305;&#37197;&#12290;&#26102;&#38388;&#35270;&#37326;&#22312;&#30830;&#23450;&#22870;&#21169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;IRL&#31639;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#27604;&#22320;&#38754;&#23454;&#38469;&#20540;&#26356;&#30701;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#36890;&#24120;&#33021;&#26356;&#24555;&#22320;&#20135;&#29983;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#23545;&#27492;&#29616;&#35937;&#36827;&#34892;&#20102;&#27491;&#24335;&#20998;&#26512;&#24182;&#32473;&#20986;&#20102;&#35299;&#37322;&#65306;&#26102;&#38388;&#35270;&#37326;&#25511;&#21046;&#20102;&#24341;&#21457;&#31574;&#30053;&#31867;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#26377;&#38480;&#25968;&#25454;&#19979;&#20943;&#36731;&#36807;&#25311;&#21512;&#12290;&#36825;&#19968;&#20998;&#26512;&#20026;IRL&#30340;&#26377;&#25928;&#35270;&#37326;&#36873;&#25321;&#25552;&#20379;&#20102;&#21407;&#21017;&#24615;&#25351;&#23548;&#12290;&#23427;&#20063;&#20419;&#20351;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#32463;&#20856;&#30340;IRL&#20844;&#24335;&#65306;&#19982;&#20165;&#20855;&#26377;&#32473;&#23450;&#35270;&#37326;&#30340;&#22870;&#21169;&#30456;&#27604;&#65292;&#20849;&#21516;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#35270;&#37326;&#26356;&#21152;&#33258;&#28982;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#36825;&#19968;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse reinforcement learning (IRL) algorithms often rely on (forward) reinforcement learning or planning over a given time horizon to compute an approximately optimal policy for a hypothesized reward function and then match this policy with expert demonstrations. The time horizon plays a critical role in determining both the accuracy of reward estimate and the computational efficiency of IRL algorithms. Interestingly, an effective time horizon shorter than the ground-truth value often produces better results faster. This work formally analyzes this phenomenon and provides an explanation: the time horizon controls the complexity of an induced policy class and mitigates overfitting with limited data. This analysis leads to a principled choice of the effective horizon for IRL. It also prompts us to reexamine the classic IRL formulation: it is more natural to learn jointly the reward and the effective horizon together rather than the reward alone with a given horizon. Our experimental re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#25968;&#25454;&#20998;&#31867;&#30340;&#31283;&#20581;&#30340;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#26080;&#38656;&#35843;&#21442;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#65292;&#24050;&#22312;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#20013;&#24471;&#21040;&#35777;&#26126;&#27604;&#20854;&#20182;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2306.13985</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#30340;&#39640;&#32500;&#25968;&#25454;&#31283;&#20581;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Robust Classification of High-Dimensional Data using Data-Adaptive Energy Distance. (arXiv:2306.13985v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13985
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#25968;&#25454;&#20998;&#31867;&#30340;&#31283;&#20581;&#30340;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#26080;&#38656;&#35843;&#21442;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#65292;&#24050;&#22312;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#20013;&#24471;&#21040;&#35777;&#26126;&#27604;&#20854;&#20182;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#65292;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#65288;HDLSS&#65289;&#25968;&#25454;&#30340;&#20998;&#31867;&#38754;&#20020;&#25361;&#25112;&#65292;&#20363;&#22914;&#22522;&#22240;&#34920;&#36798;&#30740;&#31350;&#12289;&#30284;&#30151;&#30740;&#31350;&#21644;&#21307;&#23398;&#25104;&#20687;&#31561;&#39046;&#22495;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20123;&#19987;&#38376;&#20026;HDLSS&#25968;&#25454;&#35774;&#35745;&#30340;&#20998;&#31867;&#22120;&#30340;&#24320;&#21457;&#21644;&#20998;&#26512;&#12290;&#36825;&#20123;&#20998;&#31867;&#22120;&#27809;&#26377;&#35843;&#33410;&#21442;&#25968;&#65292;&#24182;&#19988;&#26159;&#31283;&#20581;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#21463;&#24213;&#23618;&#25968;&#25454;&#20998;&#24067;&#30340;&#20219;&#20309;&#30697;&#26465;&#20214;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#19968;&#20123;&#30456;&#24403;&#26222;&#36941;&#30340;&#26465;&#20214;&#19979;&#65292;&#23427;&#20204;&#22312;HDLSS&#28176;&#36817;&#21306;&#22495;&#20869;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#12290;&#36824;&#27604;&#36739;&#20102;&#25152;&#25552;&#20986;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#30340;&#25903;&#25345;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#20998;&#31867;&#25216;&#26415;&#20248;&#20110;&#20960;&#31181;&#24191;&#27867;&#35748;&#21487;&#30340;&#26041;&#27861;&#30340;&#26377;&#24076;&#26395;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classification of high-dimensional low sample size (HDLSS) data poses a challenge in a variety of real-world situations, such as gene expression studies, cancer research, and medical imaging. This article presents the development and analysis of some classifiers that are specifically designed for HDLSS data. These classifiers are free of tuning parameters and are robust, in the sense that they are devoid of any moment conditions of the underlying data distributions. It is shown that they yield perfect classification in the HDLSS asymptotic regime, under some fairly general conditions. The comparative performance of the proposed classifiers is also investigated. Our theoretical results are supported by extensive simulation studies and real data analysis, which demonstrate promising advantages of the proposed classification techniques over several widely recognized methods.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#24182;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.01144</link><description>&lt;p&gt;
UniASM&#65306;&#26080;&#38656;&#24494;&#35843;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
UniASM: Binary Code Similarity Detection without Fine-tuning. (arXiv:2211.01144v3 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01144
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#24182;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#34987;&#24191;&#27867;&#29992;&#20110;&#21508;&#31181;&#20108;&#36827;&#21046;&#20998;&#26512;&#20219;&#21153;&#65292;&#22914;&#28431;&#27934;&#25628;&#32034;&#12289;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#12289;&#20811;&#38534;&#26816;&#27979;&#21644;&#34917;&#19969;&#20998;&#26512;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22522;&#20110;&#23398;&#20064;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;&#27604;&#20256;&#32479;&#30340;&#22522;&#20110;&#29305;&#24449;&#30340;&#26041;&#27861;&#26356;&#22909;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;transformer&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#29992;&#20110;&#23398;&#20064;&#20108;&#36827;&#21046;&#20989;&#25968;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#22686;&#21152;&#20102;tokens&#30340;&#35821;&#20041;&#20449;&#24687;&#24182;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Binary code similarity detection (BCSD) is widely used in various binary analysis tasks such as vulnerability search, malware detection, clone detection, and patch analysis. Recent studies have shown that the learning-based binary code embedding models perform better than the traditional feature-based approaches. In this paper, we propose a novel transformer-based binary code embedding model named UniASM to learn representations of the binary functions. We design two new training tasks to make the spatial distribution of the generated vectors more uniform, which can be used directly in BCSD without any fine-tuning. In addition, we present a new tokenization approach for binary functions, which increases the token's semantic information and mitigates the out-of-vocabulary (OOV) problem. We conduct an in-depth analysis of the factors affecting model performance through ablation experiments and obtain some new and valuable findings. The experimental results show that UniASM outperforms th
&lt;/p&gt;</description></item></channel></rss>