<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;Spotify&#29992;&#25143;&#23646;&#24615;&#19982;&#20182;&#20204;&#20844;&#24320;&#25773;&#25918;&#21015;&#34920;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#29305;&#21035;&#20851;&#27880;&#35782;&#21035;&#19982;&#29992;&#25143;&#20010;&#20154;&#23646;&#24615;&#30456;&#20851;&#30340;&#38899;&#20048;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2401.14296</link><description>&lt;p&gt;
"All of Me": &#20174;&#20844;&#24320;&#30340;Spotify&#25773;&#25918;&#21015;&#34920;&#20013;&#25366;&#25496;&#29992;&#25143;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
"All of Me": Mining Users' Attributes from their Public Spotify Playlists. (arXiv:2401.14296v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14296
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;Spotify&#29992;&#25143;&#23646;&#24615;&#19982;&#20182;&#20204;&#20844;&#24320;&#25773;&#25918;&#21015;&#34920;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#29305;&#21035;&#20851;&#27880;&#35782;&#21035;&#19982;&#29992;&#25143;&#20010;&#20154;&#23646;&#24615;&#30456;&#20851;&#30340;&#38899;&#20048;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#38899;&#20048;&#27969;&#23186;&#20307;&#26102;&#20195;&#65292;&#20687;Spotify&#36825;&#26679;&#30340;&#24179;&#21488;&#19978;&#30340;&#25773;&#25918;&#21015;&#34920;&#24050;&#32463;&#25104;&#20026;&#20010;&#20154;&#38899;&#20048;&#20307;&#39564;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#20154;&#20204;&#21019;&#24314;&#24182;&#20844;&#24320;&#20998;&#20139;&#33258;&#24049;&#30340;&#25773;&#25918;&#21015;&#34920;&#65292;&#20197;&#34920;&#36798;&#20182;&#20204;&#30340;&#38899;&#20048;&#21697;&#21619;&#65292;&#25512;&#24191;&#20182;&#20204;&#26368;&#21916;&#29233;&#30340;&#33402;&#26415;&#23478;&#30340;&#21457;&#29616;&#65292;&#24182;&#20419;&#36827;&#31038;&#20132;&#32852;&#31995;&#12290;&#36825;&#20123;&#21487;&#20197;&#20844;&#24320;&#35775;&#38382;&#30340;&#25773;&#25918;&#21015;&#34920;&#36229;&#36234;&#20102;&#20165;&#20165;&#38899;&#20048;&#20559;&#22909;&#30340;&#30028;&#38480;&#65306;&#23427;&#20204;&#26159;&#20016;&#23500;&#27934;&#23519;&#29992;&#25143;&#23646;&#24615;&#21644;&#36523;&#20221;&#30340;&#26469;&#28304;&#12290;&#20363;&#22914;&#65292;&#32769;&#24180;&#20154;&#30340;&#38899;&#20048;&#20559;&#22909;&#21487;&#33021;&#26356;&#20559;&#21521;&#20110;&#24343;&#20848;&#20811;&#183;&#36763;&#32435;&#23624;&#65292;&#32780;&#27604;&#33673;&#183;&#33406;&#21033;&#20160;&#20173;&#28982;&#26159;&#21313;&#20960;&#23681;&#38738;&#23569;&#24180;&#30340;&#39318;&#36873;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#25773;&#25918;&#21015;&#34920;&#25104;&#20026;&#20102;&#19968;&#25159;&#20102;&#35299;&#38899;&#20048;&#36523;&#20221;&#22810;&#26679;&#32780;&#19981;&#26029;&#28436;&#21464;&#30340;&#31383;&#21475;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Spotify&#29992;&#25143;&#23646;&#24615;&#21644;&#20182;&#20204;&#30340;&#20844;&#24320;&#25773;&#25918;&#21015;&#34920;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#35782;&#21035;&#19982;&#29992;&#25143;&#20010;&#20154;&#23646;&#24615;&#30456;&#20851;&#30340;&#32463;&#24120;&#20986;&#29616;&#30340;&#38899;&#20048;&#29305;&#24449;&#65292;&#20363;&#22914;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#65292;&#20064;&#24815;&#25110;&#20010;&#24615;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the age of digital music streaming, playlists on platforms like Spotify have become an integral part of individuals' musical experiences. People create and publicly share their own playlists to express their musical tastes, promote the discovery of their favorite artists, and foster social connections. These publicly accessible playlists transcend the boundaries of mere musical preferences: they serve as sources of rich insights into users' attributes and identities. For example, the musical preferences of elderly individuals may lean more towards Frank Sinatra, while Billie Eilish remains a favored choice among teenagers. These playlists thus become windows into the diverse and evolving facets of one's musical identity.  In this work, we investigate the relationship between Spotify users' attributes and their public playlists. In particular, we focus on identifying recurring musical characteristics associated with users' individual attributes, such as demographics, habits, or perso
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;APGAI&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#31574;&#30053;&#25552;&#39640;&#20102;&#22909;&#33218;&#35782;&#21035;&#25928;&#29575;&#65292;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#26377;&#33391;&#22909;&#23454;&#39564;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.10359</link><description>&lt;p&gt;
&#19968;&#20010;&#36866;&#29992;&#20110;&#22909;&#33218;&#35782;&#21035;&#30340;&#38543;&#26102;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Anytime Algorithm for Good Arm Identification. (arXiv:2310.10359v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10359
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;APGAI&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#31574;&#30053;&#25552;&#39640;&#20102;&#22909;&#33218;&#35782;&#21035;&#25928;&#29575;&#65292;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#26377;&#33391;&#22909;&#23454;&#39564;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22909;&#33218;&#35782;&#21035;&#65288;GAI&#65289;&#20013;&#65292;&#30446;&#26631;&#26159;&#35782;&#21035;&#20854;&#20013;&#19968;&#20010;&#24179;&#22343;&#24615;&#33021;&#36229;&#36807;&#32473;&#23450;&#38408;&#20540;&#30340;&#33218;&#65292;&#31216;&#20026;&#22909;&#33218;&#65288;&#22914;&#26524;&#23384;&#22312;&#65289;&#12290;&#30446;&#21069;&#24456;&#23569;&#26377;&#30740;&#31350;&#22312;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;GAI&#65292;&#21363;&#22312;&#20808;&#30830;&#23450;&#22909;&#39044;&#31639;&#20043;&#21518;&#65292;&#25110;&#32773;&#22312;&#20219;&#20309;&#26102;&#21051;&#37117;&#21487;&#20197;&#35201;&#27714;&#25512;&#33616;&#30340;&#38543;&#26102;&#35774;&#32622;&#19979;&#36827;&#34892;GAI&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;APGAI&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;&#65292;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#12290;APGAI&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#35774;&#23450;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24471;&#20986;&#20854;&#20219;&#20309;&#26102;&#21051;&#30340;&#35823;&#24046;&#27010;&#29575;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#19978;&#30028;&#34920;&#26126;&#65292;&#33258;&#36866;&#24212;&#31574;&#30053;&#22312;&#26816;&#27979;&#27809;&#26377;&#22909;&#33218;&#30340;&#26102;&#20505;&#27604;&#22343;&#21248;&#37319;&#26679;&#26356;&#39640;&#25928;&#12290;&#20854;&#27425;&#65292;&#24403;APGAI&#19982;&#19968;&#20010;&#20572;&#27490;&#35268;&#21017;&#32467;&#21512;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20219;&#20309;&#32622;&#20449;&#27700;&#24179;&#19979;&#30340;&#39044;&#26399;&#37319;&#26679;&#22797;&#26434;&#24615;&#30340;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;APGAI&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#19978;&#30340;&#33391;&#22909;&#23454;&#39564;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#25152;&#26377;&#35774;&#32622;&#20013;&#30340;GAI&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#24191;&#27867;&#30340;&#27010;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
In good arm identification (GAI), the goal is to identify one arm whose average performance exceeds a given threshold, referred to as good arm, if it exists. Few works have studied GAI in the fixed-budget setting, when the sampling budget is fixed beforehand, or the anytime setting, when a recommendation can be asked at any time. We propose APGAI, an anytime and parameter-free sampling rule for GAI in stochastic bandits. APGAI can be straightforwardly used in fixed-confidence and fixed-budget settings. First, we derive upper bounds on its probability of error at any time. They show that adaptive strategies are more efficient in detecting the absence of good arms than uniform sampling. Second, when APGAI is combined with a stopping rule, we prove upper bounds on the expected sampling complexity, holding at any confidence level. Finally, we show good empirical performance of APGAI on synthetic and real-world data. Our work offers an extensive overview of the GAI problem in all settings.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#21033;&#29992;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#26500;&#24314;&#20102;TLRC&#65292;&#24182;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.16858</link><description>&lt;p&gt;
Transductive Learning&#30340;&#23574;&#38160;&#27867;&#21270;&#65306;&#19968;&#31181;Transductive Local Rademacher Complexity&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sharp Generalization of Transductive Learning: A Transductive Local Rademacher Complexity Approach. (arXiv:2309.16858v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16858
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#21033;&#29992;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#26500;&#24314;&#20102;TLRC&#65292;&#24182;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#20256;&#32479;&#30340;local rademacher complexity (LRC)&#30340;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;transductive&#35774;&#32622;&#20013;&#65292;&#30456;&#23545;&#20110;&#20856;&#22411;&#30340;LRC&#26041;&#27861;&#22312;&#24402;&#32435;&#35774;&#32622;&#20013;&#30340;&#20998;&#26512;&#26377;&#20102;&#30456;&#24403;&#22823;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Rademacher complex&#30340;&#23616;&#37096;&#21270;&#24037;&#20855;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;transductive learning&#38382;&#39064;&#65292;&#24182;&#22312;&#36866;&#24403;&#26465;&#20214;&#19979;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#30028;&#38480;&#12290;&#19982;LRC&#30340;&#21457;&#23637;&#31867;&#20284;&#65292;&#25105;&#20204;&#36890;&#36807;&#20174;&#29420;&#31435;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#24320;&#22987;&#26500;&#24314;TLRC&#65292;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We introduce a new tool, Transductive Local Rademacher Complexity (TLRC), to analyze the generalization performance of transductive learning methods and motivate new transductive learning algorithms. Our work extends the idea of the popular Local Rademacher Complexity (LRC) to the transductive setting with considerable changes compared to the analysis of typical LRC methods in the inductive setting. We present a localized version of Rademacher complexity based tool wihch can be applied to various transductive learning problems and gain sharp bounds under proper conditions. Similar to the development of LRC, we build TLRC by starting from a sharp concentration inequality for independent variables with variance information. The prediction function class of a transductive learning model is then divided into pieces with a sub-root function being the upper bound for the Rademacher complexity of each piece, and the variance of all the functions in each piece is limited. A carefully designed 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#20844;&#21496;&#30408;&#21033;&#65292;&#20294;&#21516;&#26679;&#23384;&#22312;&#36807;&#24230;&#21453;&#24212;&#30340;&#38382;&#39064;&#65292;&#32780;&#20256;&#32479;&#22521;&#35757;&#30340;&#32929;&#24066;&#20998;&#26512;&#24072;&#21644;&#32463;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22521;&#35757;&#30340;&#20998;&#26512;&#24072;&#30456;&#27604;&#20250;&#20135;&#29983;&#36739;&#23569;&#30340;&#36807;&#24230;&#21453;&#24212;&#12290;</title><link>http://arxiv.org/abs/2303.16158</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20934;&#30830;&#39044;&#27979;&#36130;&#25253;&#65292;&#20294;&#21516;&#26679;&#23384;&#22312;&#36807;&#24230;&#21453;&#24212;
&lt;/p&gt;
&lt;p&gt;
Behavioral Machine Learning? Computer Predictions of Corporate Earnings also Overreact. (arXiv:2303.16158v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#20844;&#21496;&#30408;&#21033;&#65292;&#20294;&#21516;&#26679;&#23384;&#22312;&#36807;&#24230;&#21453;&#24212;&#30340;&#38382;&#39064;&#65292;&#32780;&#20256;&#32479;&#22521;&#35757;&#30340;&#32929;&#24066;&#20998;&#26512;&#24072;&#21644;&#32463;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22521;&#35757;&#30340;&#20998;&#26512;&#24072;&#30456;&#27604;&#20250;&#20135;&#29983;&#36739;&#23569;&#30340;&#36807;&#24230;&#21453;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#37327;&#35777;&#25454;&#34920;&#26126;&#65292;&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#39044;&#27979;&#33021;&#21147;&#27604;&#20154;&#31867;&#26356;&#20026;&#20934;&#30830;&#12290;&#20294;&#26159;&#65292;&#25991;&#29486;&#24182;&#26410;&#27979;&#35797;&#31639;&#27861;&#39044;&#27979;&#26159;&#21542;&#26356;&#20026;&#29702;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20960;&#20010;&#31639;&#27861;&#65288;&#21253;&#25324;&#32447;&#24615;&#22238;&#24402;&#21644;&#19968;&#31181;&#21517;&#20026;Gradient Boosted Regression Trees&#30340;&#27969;&#34892;&#31639;&#27861;&#65289;&#23545;&#20110;&#20844;&#21496;&#30408;&#21033;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#32467;&#26524;&#21457;&#29616;&#65292;GBRT&#24179;&#22343;&#32988;&#36807;&#32447;&#24615;&#22238;&#24402;&#21644;&#20154;&#31867;&#32929;&#24066;&#20998;&#26512;&#24072;&#65292;&#20294;&#20173;&#23384;&#22312;&#36807;&#24230;&#21453;&#24212;&#19988;&#26080;&#27861;&#28385;&#36275;&#29702;&#24615;&#39044;&#26399;&#26631;&#20934;&#12290;&#36890;&#36807;&#38477;&#20302;&#23398;&#20064;&#29575;&#65292;&#21487;&#26368;&#23567;&#31243;&#24230;&#19978;&#20943;&#23569;&#36807;&#24230;&#21453;&#24212;&#31243;&#24230;&#65292;&#20294;&#36825;&#20250;&#29306;&#29298;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22521;&#35757;&#36807;&#30340;&#32929;&#24066;&#20998;&#26512;&#24072;&#27604;&#20256;&#32479;&#35757;&#32451;&#30340;&#20998;&#26512;&#24072;&#20135;&#29983;&#30340;&#36807;&#24230;&#21453;&#24212;&#36739;&#23569;&#12290;&#27492;&#22806;&#65292;&#32929;&#24066;&#20998;&#26512;&#24072;&#30340;&#39044;&#27979;&#21453;&#26144;&#20986;&#26426;&#22120;&#31639;&#27861;&#27809;&#26377;&#25429;&#25417;&#21040;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is considerable evidence that machine learning algorithms have better predictive abilities than humans in various financial settings. But, the literature has not tested whether these algorithmic predictions are more rational than human predictions. We study the predictions of corporate earnings from several algorithms, notably linear regressions and a popular algorithm called Gradient Boosted Regression Trees (GBRT). On average, GBRT outperformed both linear regressions and human stock analysts, but it still overreacted to news and did not satisfy rational expectation as normally defined. By reducing the learning rate, the magnitude of overreaction can be minimized, but it comes with the cost of poorer out-of-sample prediction accuracy. Human stock analysts who have been trained in machine learning methods overreact less than traditionally trained analysts. Additionally, stock analyst predictions reflect information not otherwise available to machine algorithms.
&lt;/p&gt;</description></item><item><title>&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#20026;&#22312;&#32447;&#24191;&#21578;&#39046;&#22495;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#20197;&#24212;&#23545;&#20256;&#32479;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2209.15635</link><description>&lt;p&gt;
&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#29992;&#20110;&#39640;&#25928;&#22312;&#32447;&#24191;&#21578;
&lt;/p&gt;
&lt;p&gt;
Vertical Semi-Federated Learning for Efficient Online Advertising. (arXiv:2209.15635v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15635
&lt;/p&gt;
&lt;p&gt;
&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#20026;&#22312;&#32447;&#24191;&#21578;&#39046;&#22495;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#20197;&#24212;&#23545;&#20256;&#32479;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26550;&#26500;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;1&#65289;&#36866;&#29992;&#33539;&#22260;&#21463;&#38480;&#20110;&#37325;&#21472;&#26679;&#26412;&#65307;2&#65289;&#23454;&#26102;&#32852;&#21512;&#26381;&#21153;&#30340;&#31995;&#32479;&#25361;&#25112;&#36739;&#39640;&#65292;&#36825;&#38480;&#21046;&#20102;&#20854;&#22312;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#35774;&#32622;&#8212;&#8212;&#21322;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;(Semi-VFL)&#65292;&#20197;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#12290;&#21322;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26088;&#22312;&#23454;&#29616;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#23454;&#38469;&#24037;&#19994;&#24212;&#29992;&#26041;&#24335;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#34920;&#29616;&#20248;&#20110;&#21333;&#26041;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#23616;&#37096;&#26381;&#21153;&#30340;&#20415;&#21033;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31934;&#24515;&#35774;&#35745;&#30340;&#32852;&#21512;&#29305;&#26435;&#23398;&#20064;&#26694;&#26550;(JPL)&#65292;&#26469;&#35299;&#20915;&#34987;&#21160;&#26041;&#29305;&#24449;&#32570;&#22833;&#21644;&#36866;&#24212;&#25972;&#20010;&#26679;&#26412;&#31354;&#38388;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#25512;&#29702;&#39640;&#25928;&#30340;&#36866;&#29992;&#20110;&#25972;&#20010;&#26679;&#26412;&#31354;&#38388;&#30340;&#21333;&#26041;&#23398;&#29983;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#32852;&#21512;&#29305;&#24449;&#25193;&#23637;&#30340;&#20248;&#21183;&#12290;&#26032;&#30340;&#34920;&#31034;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
The traditional vertical federated learning schema suffers from two main issues: 1) restricted applicable scope to overlapped samples and 2) high system challenge of real-time federated serving, which limits its application to advertising systems. To this end, we advocate a new learning setting Semi-VFL (Vertical Semi-Federated Learning) to tackle these challenge. Semi-VFL is proposed to achieve a practical industry application fashion for VFL, by learning a federation-aware local model which performs better than single-party models and meanwhile maintain the convenience of local-serving. For this purpose, we propose the carefully designed Joint Privileged Learning framework (JPL) to i) alleviate the absence of the passive party's feature and ii) adapt to the whole sample space. Specifically, we build an inference-efficient single-party student model applicable to the whole sample space and meanwhile maintain the advantage of the federated feature extension. New representation distilla
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Transformer&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#36923;&#36753;&#32508;&#21512;&#32467;&#26524;&#36136;&#37327;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32467;&#26500;&#36716;&#25442;&#34920;&#31034;&#20026;&#21521;&#37327;&#24182;&#25552;&#21462;&#20248;&#21270;&#24207;&#21015;&#30340;&#29305;&#24449;&#65292;&#20197;&#21450;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#30005;&#36335;&#30340;&#22270;&#34920;&#31034;&#21644;&#39044;&#27979;QoR&#12290;</title><link>http://arxiv.org/abs/2207.11437</link><description>&lt;p&gt;
&#20351;&#29992;Transformer&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#36923;&#36753;&#32508;&#21512;&#32467;&#26524;&#30340;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
The prediction of the quality of results in Logic Synthesis using Transformer and Graph Neural Networks. (arXiv:2207.11437v2 [cs.AR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11437
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Transformer&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#36923;&#36753;&#32508;&#21512;&#32467;&#26524;&#36136;&#37327;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32467;&#26500;&#36716;&#25442;&#34920;&#31034;&#20026;&#21521;&#37327;&#24182;&#25552;&#21462;&#20248;&#21270;&#24207;&#21015;&#30340;&#29305;&#24449;&#65292;&#20197;&#21450;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#30005;&#36335;&#30340;&#22270;&#34920;&#31034;&#21644;&#39044;&#27979;QoR&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36923;&#36753;&#32508;&#21512;&#38454;&#27573;&#65292;&#32508;&#21512;&#24037;&#20855;&#20013;&#30340;&#32467;&#26500;&#36716;&#25442;&#38656;&#35201;&#19982;&#20248;&#21270;&#24207;&#21015;&#32467;&#21512;&#65292;&#24182;&#20316;&#29992;&#20110;&#30005;&#36335;&#65292;&#20197;&#28385;&#36275;&#25351;&#23450;&#30340;&#30005;&#36335;&#38754;&#31215;&#21644;&#24310;&#36831;&#12290;&#28982;&#32780;&#65292;&#36923;&#36753;&#32508;&#21512;&#20248;&#21270;&#24207;&#21015;&#30340;&#36816;&#34892;&#26102;&#38388;&#36739;&#38271;&#65292;&#20026;&#30005;&#36335;&#23545;&#32508;&#21512;&#20248;&#21270;&#24207;&#21015;&#30340;&#32467;&#26524;&#36136;&#37327;&#65288;QoR&#65289;&#36827;&#34892;&#39044;&#27979;&#21487;&#20197;&#24110;&#21161;&#24037;&#31243;&#24072;&#26356;&#24555;&#22320;&#25214;&#21040;&#26356;&#22909;&#30340;&#20248;&#21270;&#24207;&#21015;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#26410;&#35265;&#36807;&#30340;&#30005;&#36335;-&#20248;&#21270;&#24207;&#21015;&#23545;&#30340;QoR&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#23884;&#20837;&#26041;&#27861;&#23558;&#32467;&#26500;&#36716;&#25442;&#36716;&#21270;&#20026;&#21521;&#37327;&#65292;&#24182;&#21033;&#29992;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#25216;&#26415;&#65288;Transformer&#65289;&#25552;&#21462;&#20248;&#21270;&#24207;&#21015;&#30340;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20351;&#27169;&#22411;&#30340;&#39044;&#27979;&#36807;&#31243;&#33021;&#22815;&#20174;&#30005;&#36335;&#27867;&#21270;&#21040;&#30005;&#36335;&#65292;&#30005;&#36335;&#30340;&#22270;&#34920;&#31034;&#34987;&#34920;&#31034;&#20026;&#37051;&#25509;&#30697;&#38453;&#21644;&#29305;&#24449;&#30697;&#38453;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#34987;&#29992;&#20110;&#23398;&#20064;&#30005;&#36335;&#30340;&#22270;&#34920;&#31034;&#21644;&#39044;&#27979;QoR&#12290;
&lt;/p&gt;
&lt;p&gt;
In the logic synthesis stage, structure transformations in the synthesis tool need to be combined into optimization sequences and act on the circuit to meet the specified circuit area and delay. However, logic synthesis optimization sequences are time-consuming to run, and predicting the quality of the results (QoR) against the synthesis optimization sequence for a circuit can help engineers find a better optimization sequence faster. In this work, we propose a deep learning method to predict the QoR of unseen circuit-optimization sequences pairs. Specifically, the structure transformations are translated into vectors by embedding methods and advanced natural language processing (NLP) technology (Transformer) is used to extract the features of the optimization sequences. In addition, to enable the prediction process of the model to be generalized from circuit to circuit, the graph representation of the circuit is represented as an adjacency matrix and a feature matrix. Graph neural net
&lt;/p&gt;</description></item></channel></rss>