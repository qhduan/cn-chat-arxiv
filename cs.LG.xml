<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36866;&#37197;&#22120;&#35843;&#25972;&#26041;&#27861;&#22312;&#25345;&#32493;&#23398;&#20064;&#20013;&#23637;&#29616;&#20986;&#36739;&#20248;&#24615;&#33021;&#65292;&#25552;&#20986;&#20102;&#22686;&#37327;&#35843;&#25972;&#20849;&#20139;&#36866;&#37197;&#22120;&#21644;&#21033;&#29992;&#23384;&#20648;&#21407;&#22411;&#36827;&#34892;&#29305;&#24449;&#37319;&#26679;&#21644;&#26356;&#26032;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#27169;&#22411;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.19979</link><description>&lt;p&gt;
&#35821;&#20041;&#36716;&#31227;&#22686;&#37327;&#36866;&#37197;&#22120;&#35843;&#25972;&#26159;&#19968;&#31181;&#25345;&#32493;&#30340; ViTransformer
&lt;/p&gt;
&lt;p&gt;
Semantically-Shifted Incremental Adapter-Tuning is A Continual ViTransformer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19979
&lt;/p&gt;
&lt;p&gt;
&#36866;&#37197;&#22120;&#35843;&#25972;&#26041;&#27861;&#22312;&#25345;&#32493;&#23398;&#20064;&#20013;&#23637;&#29616;&#20986;&#36739;&#20248;&#24615;&#33021;&#65292;&#25552;&#20986;&#20102;&#22686;&#37327;&#35843;&#25972;&#20849;&#20139;&#36866;&#37197;&#22120;&#21644;&#21033;&#29992;&#23384;&#20648;&#21407;&#22411;&#36827;&#34892;&#29305;&#24449;&#37319;&#26679;&#21644;&#26356;&#26032;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#27169;&#22411;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31867;&#22686;&#37327;&#23398;&#20064;&#65288;CIL&#65289;&#26088;&#22312;&#20351;&#27169;&#22411;&#33021;&#22815;&#22312;&#20811;&#26381;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#21516;&#26102;&#25345;&#32493;&#23398;&#20064;&#26032;&#30340;&#31867;&#21035;&#12290;&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#22312;&#25345;&#32493;&#23398;&#20064;&#32972;&#26223;&#19979;&#30340;&#19981;&#21516;&#21442;&#25968;&#39640;&#25928;&#35843;&#25972;&#65288;PET&#65289;&#26041;&#27861;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#36866;&#37197;&#22120;&#35843;&#25972;&#34920;&#29616;&#20248;&#20110;&#22522;&#20110;&#25552;&#31034;&#30340;&#26041;&#27861;&#65292;&#29978;&#33267;&#22312;&#27599;&#20010;&#23398;&#20064;&#20250;&#35805;&#20013;&#27809;&#26377;&#21442;&#25968;&#25193;&#23637;&#30340;&#24773;&#20917;&#19979;&#20063;&#22914;&#27492;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22686;&#37327;&#35843;&#25972;&#20849;&#20139;&#36866;&#37197;&#22120;&#32780;&#19981;&#26045;&#21152;&#21442;&#25968;&#26356;&#26032;&#32422;&#26463;&#65292;&#22686;&#24378;&#39592;&#24178;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#23384;&#20648;&#30340;&#21407;&#22411;&#20013;&#25277;&#21462;&#29305;&#24449;&#26679;&#26412;&#26469;&#37325;&#26032;&#35757;&#32451;&#32479;&#19968;&#30340;&#20998;&#31867;&#22120;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;&#25105;&#20204;&#20272;&#35745;&#26087;&#21407;&#22411;&#30340;&#35821;&#20041;&#36716;&#31227;&#65292;&#32780;&#26080;&#27861;&#35775;&#38382;&#36807;&#21435;&#30340;&#26679;&#26412;&#65292;&#24182;&#36880;&#20010;&#20250;&#35805;&#26356;&#26032;&#23384;&#20648;&#30340;&#21407;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#28040;&#38500;&#20102;&#27169;&#22411;&#30340;&#25193;&#23637;&#21644;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19979v1 Announce Type: cross  Abstract: Class-incremental learning (CIL) aims to enable models to continuously learn new classes while overcoming catastrophic forgetting. The introduction of pre-trained models has brought new tuning paradigms to CIL. In this paper, we revisit different parameter-efficient tuning (PET) methods within the context of continual learning. We observe that adapter tuning demonstrates superiority over prompt-based methods, even without parameter expansion in each learning session. Motivated by this, we propose incrementally tuning the shared adapter without imposing parameter update constraints, enhancing the learning capacity of the backbone. Additionally, we employ feature sampling from stored prototypes to retrain a unified classifier, further improving its performance. We estimate the semantic shift of old prototypes without access to past samples and update stored prototypes session by session. Our proposed method eliminates model expansion and
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#22522;&#20110;Bregman&#25955;&#24230;&#65292;&#36890;&#36807;&#24341;&#20837;&#20849;&#36717;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;\textsc{ConjNorm}&#26041;&#27861;&#65292;&#20197;&#22312;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#25628;&#32034;&#26368;&#20339;&#35268;&#33539;&#31995;&#25968;$p$&#26469;&#37325;&#26032;&#26500;&#24819;&#23494;&#24230;&#20989;&#25968;&#35774;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.17888</link><description>&lt;p&gt;
ConjNorm&#65306;&#29992;&#20110;&#24322;&#24120;&#20998;&#24067;&#26816;&#27979;&#30340;&#21487;&#22788;&#29702;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17888
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#22522;&#20110;Bregman&#25955;&#24230;&#65292;&#36890;&#36807;&#24341;&#20837;&#20849;&#36717;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;\textsc{ConjNorm}&#26041;&#27861;&#65292;&#20197;&#22312;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#25628;&#32034;&#26368;&#20339;&#35268;&#33539;&#31995;&#25968;$p$&#26469;&#37325;&#26032;&#26500;&#24819;&#23494;&#24230;&#20989;&#25968;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#32493;&#24322;&#24120;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#22312;&#21487;&#38752;&#26426;&#22120;&#23398;&#20064;&#20013;&#21463;&#21040;&#23494;&#20999;&#20851;&#27880;&#12290;&#35768;&#22810;&#24037;&#20316;&#33268;&#21147;&#20110;&#25512;&#23548;&#22522;&#20110;logits&#12289;&#36317;&#31163;&#25110;&#20005;&#26684;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#30340;&#35780;&#20998;&#20989;&#25968;&#65292;&#20197;&#35782;&#21035;&#24471;&#20998;&#20302;&#30340;OOD&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20272;&#35745;&#24471;&#20998;&#21487;&#33021;&#26080;&#27861;&#20934;&#30830;&#21453;&#26144;&#30495;&#23454;&#25968;&#25454;&#23494;&#24230;&#25110;&#26045;&#21152;&#19981;&#20999;&#23454;&#38469;&#30340;&#32422;&#26463;&#12290;&#20026;&#20102;&#22312;&#22522;&#20110;&#23494;&#24230;&#24471;&#20998;&#35774;&#35745;&#26041;&#38754;&#25552;&#20379;&#19968;&#20010;&#32479;&#19968;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;Bregman&#25955;&#24230;&#20026;&#22522;&#30784;&#30340;&#26032;&#39062;&#29702;&#35770;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23558;&#20998;&#24067;&#32771;&#34385;&#25193;&#23637;&#21040;&#28085;&#30422;&#19968;&#31995;&#21015;&#25351;&#25968;&#26063;&#20998;&#24067;&#12290;&#21033;&#29992;&#25105;&#20204;&#23450;&#29702;&#20013;&#25581;&#31034;&#30340;&#20849;&#36717;&#32422;&#26463;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;\textsc{ConjNorm}&#26041;&#27861;&#65292;&#23558;&#23494;&#24230;&#20989;&#25968;&#35774;&#35745;&#37325;&#26032;&#26500;&#24819;&#20026;&#38024;&#23545;&#32473;&#23450;&#25968;&#25454;&#38598;&#25628;&#32034;&#26368;&#20339;&#35268;&#33539;&#31995;&#25968;$p$&#30340;&#36807;&#31243;&#12290;&#37492;&#20110;&#24402;&#19968;&#21270;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26080;&#20559;&#21644;&#35299;&#26512;&#21487;&#36861;&#36394;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17888v1 Announce Type: cross  Abstract: Post-hoc out-of-distribution (OOD) detection has garnered intensive attention in reliable machine learning. Many efforts have been dedicated to deriving score functions based on logits, distances, or rigorous data distribution assumptions to identify low-scoring OOD samples. Nevertheless, these estimate scores may fail to accurately reflect the true data density or impose impractical constraints. To provide a unified perspective on density-based score design, we propose a novel theoretical framework grounded in Bregman divergence, which extends distribution considerations to encompass an exponential family of distributions. Leveraging the conjugation constraint revealed in our theorem, we introduce a \textsc{ConjNorm} method, reframing density function design as a search for the optimal norm coefficient $p$ against the given dataset. In light of the computational challenges of normalization, we devise an unbiased and analytically tract
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20844;&#24179;GNN&#30340;&#23545;&#25239;&#24615;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#20844;&#24179;GNN&#30340;&#20551;&#35774;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#27492;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01591</link><description>&lt;p&gt;
&#26356;&#22909;&#30340;&#20844;&#24179;&#24615;&#32988;&#20110;&#36951;&#25022;&#65306;&#38024;&#23545;&#20844;&#24179;GNN&#30340;&#23545;&#25239;&#24615;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;
&lt;/p&gt;
&lt;p&gt;
Better Fair than Sorry: Adversarial Missing Data Imputation for Fair GNNs. (arXiv:2311.01591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01591
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20844;&#24179;GNN&#30340;&#23545;&#25239;&#24615;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#20844;&#24179;GNN&#30340;&#20551;&#35774;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#27492;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#32570;&#22833;&#20445;&#25252;&#23646;&#24615;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20844;&#24179;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#35768;&#22810;&#30456;&#20851;&#20219;&#21153;&#20013;&#65292;&#20915;&#31574;&#21487;&#33021;&#20250;&#23545;&#29305;&#23450;&#31038;&#21306;&#20135;&#29983;&#19981;&#25104;&#27604;&#20363;&#30340;&#24433;&#21709;&#65292;&#32780;GNNs&#24050;&#32463;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20844;&#24179;GNNs&#24037;&#20316;&#35201;&#20040;&#20551;&#35774;&#20445;&#25252;&#23646;&#24615;&#26159;&#23436;&#20840;&#34987;&#35266;&#23519;&#21040;&#30340;&#65292;&#35201;&#20040;&#20551;&#35774;&#32570;&#22833;&#25968;&#25454;&#30340;&#22635;&#20805;&#26159;&#20844;&#24179;&#30340;&#12290;&#23454;&#38469;&#19978;&#65292;&#22635;&#20805;&#20013;&#30340;&#20559;&#24046;&#20250;&#20256;&#25773;&#21040;&#27169;&#22411;&#30340;&#32467;&#26524;&#20013;&#65292;&#23548;&#33268;&#23427;&#20204;&#36807;&#39640;&#22320;&#20272;&#35745;&#20102;&#20854;&#39044;&#27979;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;Better Fair than Sorry&#65288;BFtS&#65289;&#65292;&#20026;&#20844;&#24179;GNNs&#20351;&#29992;&#30340;&#20445;&#25252;&#23646;&#24615;&#30340;&#20844;&#24179;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;BFtS&#32972;&#21518;&#30340;&#20851;&#38190;&#35774;&#35745;&#21407;&#21017;&#26159;&#22635;&#20805;&#24212;&#35813;&#36817;&#20284;&#20110;&#20844;&#24179;GNN&#30340;&#26368;&#22256;&#38590;&#24773;&#20917;&#65292;&#21363;&#22312;&#26368;&#20248;&#21270;&#20844;&#24179;&#24615;&#26368;&#22256;&#38590;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#19977;&#26041;&#23545;&#25239;&#26041;&#26696;&#26469;&#23454;&#29616;&#36825;&#20010;&#24819;&#27861;&#65292;&#22312;&#36825;&#20010;&#26041;&#26696;&#20013;&#65292;&#20004;&#20010;&#23545;&#25163;&#20849;&#21516;&#23545;&#25239;&#20844;&#24179;GNN&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;BFtS&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the problem of learning fair Graph Neural Networks (GNNs) under missing protected attributes. GNNs have achieved state-of-the-art results in many relevant tasks where decisions might disproportionately impact specific communities. However, existing work on fair GNNs assumes that either protected attributes are fully-observed or that the missing data imputation is fair. In practice, biases in the imputation will be propagated to the model outcomes, leading them to overestimate the fairness of their predictions. We address this challenge by proposing Better Fair than Sorry (BFtS), a fair missing data imputation model for protected attributes used by fair GNNs. The key design principle behind BFtS is that imputations should approximate the worst-case scenario for the fair GNN -- i.e. when optimizing fairness is the hardest. We implement this idea using a 3-player adversarial scheme where two adversaries collaborate against the fair GNN. Experiments using synthetic and
&lt;/p&gt;</description></item></channel></rss>