<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#22312;&#25968;&#25454;&#27969;&#23398;&#20064;&#20013;&#35745;&#31639;&#20915;&#31574;&#26641;&#26368;&#20339;&#20998;&#21106;&#28857;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27969;&#24335;&#35745;&#31639;&#21644;&#22823;&#35268;&#27169;&#24182;&#34892;&#27169;&#22411;&#20013;&#39640;&#25928;&#36816;&#34892;</title><link>https://arxiv.org/abs/2403.19867</link><description>&lt;p&gt;
&#22312;&#27969;&#24335;&#21644;&#22823;&#35268;&#27169;&#24182;&#34892;&#27169;&#22411;&#20013;&#25214;&#21040;&#20915;&#31574;&#26641;&#20998;&#21106;&#28857;
&lt;/p&gt;
&lt;p&gt;
Finding Decision Tree Splits in Streaming and Massively Parallel Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19867
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22312;&#25968;&#25454;&#27969;&#23398;&#20064;&#20013;&#35745;&#31639;&#20915;&#31574;&#26641;&#26368;&#20339;&#20998;&#21106;&#28857;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27969;&#24335;&#35745;&#31639;&#21644;&#22823;&#35268;&#27169;&#24182;&#34892;&#27169;&#22411;&#20013;&#39640;&#25928;&#36816;&#34892;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#27969;&#31639;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#20915;&#31574;&#26641;&#23398;&#20064;&#20013;&#30340;&#26368;&#20248;&#20998;&#21106;&#28857;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#32473;&#23450;&#35266;&#27979;&#25968;&#25454;&#27969;$x_i$&#21450;&#20854;&#26631;&#31614;$y_i$&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#23558;&#25968;&#25454;&#20998;&#20026;&#20004;&#32452;&#30340;&#26368;&#20339;&#20998;&#21106;&#28857;$j$&#65292;&#20351;&#24471;&#22343;&#26041;&#35823;&#24046;&#65288;&#22238;&#24402;&#38382;&#39064;&#65289;&#25110;&#35823;&#20998;&#31867;&#29575;&#65288;&#20998;&#31867;&#38382;&#39064;&#65289;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22810;&#31181;&#24555;&#36895;&#30340;&#25968;&#25454;&#27969;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#20351;&#29992;&#20122;&#32447;&#24615;&#31354;&#38388;&#21644;&#23569;&#37327;&#27425;&#25968;&#30340;&#36941;&#21382;&#12290;&#36825;&#20123;&#31639;&#27861;&#36824;&#21487;&#20197;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#24182;&#34892;&#35745;&#31639;&#27169;&#22411;&#20013;&#12290;&#23613;&#31649;&#19981;&#33021;&#30452;&#25509;&#27604;&#36739;&#65292;&#20294;&#25105;&#20204;&#30340;&#24037;&#20316;&#19982;Domingos&#21644;Hulten&#30340;&#24320;&#21019;&#24615;&#24037;&#20316;&#65288;KDD 2000&#65289;&#30456;&#20114;&#34917;&#20805;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19867v1 Announce Type: cross  Abstract: In this work, we provide data stream algorithms that compute optimal splits in decision tree learning. In particular, given a data stream of observations $x_i$ and their labels $y_i$, the goal is to find the optimal split point $j$ that divides the data into two sets such that the mean squared error (for regression) or misclassification rate (for classification) is minimized. We provide various fast streaming algorithms that use sublinear space and a small number of passes for these problems. These algorithms can also be extended to the massively parallel computation model. Our work, while not directly comparable, complements the seminal work of Domingos and Hulten (KDD 2000).
&lt;/p&gt;</description></item><item><title>HyperMagNet&#26159;&#19968;&#31181;&#22522;&#20110;&#30913;&#24230;&#25289;&#26222;&#25289;&#26031;&#30340;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#23558;&#36229;&#22270;&#34920;&#31034;&#20026;&#38750;&#21487;&#36870;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#24182;&#26500;&#24314;&#30913;&#24230;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#20316;&#20026;&#36755;&#20837;&#65292;&#23427;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09676</link><description>&lt;p&gt;
HyperMagNet:&#19968;&#31181;&#22522;&#20110;&#30913;&#24230;&#25289;&#26222;&#25289;&#26031;&#30340;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
HyperMagNet: A Magnetic Laplacian based Hypergraph Neural Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09676
&lt;/p&gt;
&lt;p&gt;
HyperMagNet&#26159;&#19968;&#31181;&#22522;&#20110;&#30913;&#24230;&#25289;&#26222;&#25289;&#26031;&#30340;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#23558;&#36229;&#22270;&#34920;&#31034;&#20026;&#38750;&#21487;&#36870;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#24182;&#26500;&#24314;&#30913;&#24230;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#20316;&#20026;&#36755;&#20837;&#65292;&#23427;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#31185;&#23398;&#39046;&#22495;&#65292;&#36229;&#22270;&#26159;&#23545;&#23637;&#31034;&#22810;&#31181;&#20851;&#31995;&#30340;&#25968;&#25454;&#30340;&#33258;&#28982;&#27169;&#22411;&#65292;&#32780;&#22270;&#21482;&#33021;&#25429;&#25417;&#21040;&#20004;&#20004;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#30340;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#36890;&#36807;&#23545;&#31216;&#30697;&#38453;&#34920;&#31034;&#23558;&#36229;&#22270;&#26377;&#25928;&#22320;&#31616;&#21270;&#20026;&#26080;&#21521;&#22270;&#65292;&#21487;&#33021;&#20250;&#20002;&#22833;&#37325;&#35201;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#23558;&#36229;&#22270;&#34920;&#31034;&#20026;&#38750;&#21487;&#36870;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#12290;&#25105;&#20204;&#20351;&#29992;&#35813;&#39532;&#23572;&#21487;&#22827;&#38142;&#26500;&#24314;&#20102;&#19968;&#20010;&#22797;&#25968;&#22467;&#23572;&#31859;&#29305;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453; - &#30913;&#24230;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#35813;&#30697;&#38453;&#20316;&#20026;&#25105;&#20204;&#25552;&#20986;&#30340;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;HyperMagNet&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#25928;&#26524;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#22522;&#20110;&#22270;&#31616;&#21270;&#30340;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09676v1 Announce Type: new  Abstract: In data science, hypergraphs are natural models for data exhibiting multi-way relations, whereas graphs only capture pairwise. Nonetheless, many proposed hypergraph neural networks effectively reduce hypergraphs to undirected graphs via symmetrized matrix representations, potentially losing important information. We propose an alternative approach to hypergraph neural networks in which the hypergraph is represented as a non-reversible Markov chain. We use this Markov chain to construct a complex Hermitian Laplacian matrix - the magnetic Laplacian - which serves as the input to our proposed hypergraph neural network. We study HyperMagNet for the task of node classification, and demonstrate its effectiveness over graph-reduction based hypergraph neural networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20998;&#23618;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#29983;&#29289;&#27963;&#24615;&#24182;&#25214;&#21040;&#19982;&#20043;&#30456;&#20851;&#30340;&#26368;&#37325;&#35201;&#30340;&#25104;&#20998;&#12290;</title><link>https://arxiv.org/abs/2402.01744</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#23618;&#22270;&#35299;&#37322;&#25581;&#31034;&#20998;&#23376;&#25104;&#20998;
&lt;/p&gt;
&lt;p&gt;
Unveiling Molecular Moieties through Hierarchical Graph Explainability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01744
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20998;&#23618;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#29983;&#29289;&#27963;&#24615;&#24182;&#25214;&#21040;&#19982;&#20043;&#30456;&#20851;&#30340;&#26368;&#37325;&#35201;&#30340;&#25104;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#22312;&#25903;&#25345;&#20307;&#22806;&#34394;&#25311;&#31579;&#36873;&#26041;&#38754;&#24050;&#32463;&#20986;&#29616;&#22810;&#24180;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#21367;&#31215;&#26550;&#26500;&#23454;&#29616;&#39640;&#31934;&#24230;&#22810;&#38774;&#26631;&#31579;&#36873;&#30340;GNN&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#20998;&#23618;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#25216;&#26415;&#65292;&#36890;&#36807;&#21033;&#29992;&#20449;&#24687;&#20256;&#36882;&#26426;&#21046;&#65292;&#22312;&#21407;&#23376;&#12289;&#29615;&#21644;&#25972;&#20010;&#20998;&#23376;&#23618;&#38754;&#19978;&#30452;&#25509;&#25429;&#33719;&#20449;&#24687;&#65292;&#20174;&#32780;&#25214;&#21040;&#19982;&#29983;&#29289;&#27963;&#24615;&#39044;&#27979;&#30456;&#20851;&#30340;&#26368;&#37325;&#35201;&#30340;&#25104;&#20998;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#22312;&#25903;&#25345;&#34394;&#25311;&#31579;&#36873;&#26041;&#38754;&#30340;&#20108;&#21313;&#20010;&#32454;&#32990;&#21608;&#26399;&#20381;&#36182;&#24615;&#28608;&#37238;&#38774;&#26631;&#19978;&#25253;&#36947;&#20102;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;GNN&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#20998;&#31867;&#22120;&#36229;&#36234;&#20102;&#20316;&#32773;&#25552;&#20986;&#30340;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#20010;&#20165;&#38024;&#23545;CDK1&#30340;&#39640;&#28789;&#25935;&#24230;&#29256;&#26412;&#30340;GNN&#65292;&#20197;&#20351;&#29992;&#25105;&#20204;&#30340;&#35299;&#37322;&#22120;&#26469;&#36991;&#20813;&#22810;&#31867;&#21035;&#27169;&#22411;&#22266;&#26377;&#30340;&#20559;&#24046;&#12290;&#20998;&#23618;&#35299;&#37322;&#22120;&#24050;&#32463;&#30001;&#19968;&#20301;&#19987;&#23478;&#21270;&#23398;&#23478;&#22312;19&#20010;CDK1&#25209;&#20934;&#33647;&#29289;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background: Graph Neural Networks (GNN) have emerged in very recent years as a powerful tool for supporting in silico Virtual Screening. In this work we present a GNN which uses Graph Convolutional architectures to achieve very accurate multi-target screening. We also devised a hierarchical Explainable Artificial Intelligence (XAI) technique to catch information directly at atom, ring, and whole molecule level by leveraging the message passing mechanism. In this way, we find the most relevant moieties involved in bioactivity prediction. Results: We report a state-of-the-art GNN classifier on twenty Cyclin-dependent Kinase targets in support of VS. Our classifier outperforms previous SOTA approaches proposed by the authors. Moreover, a CDK1-only high-sensitivity version of the GNN has been designed to use our explainer in order to avoid the inherent bias of multi-class models. The hierarchical explainer has been validated by an expert chemist on 19 approved drugs on CDK1. Our explainer 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;IMA-GloVe-GA&#65292;&#19968;&#20010;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#22810;&#27493;&#25512;&#29702;&#30340;&#36845;&#20195;&#31070;&#32463;&#25512;&#29702;&#32593;&#32476;&#65292;&#22312;&#36229;&#39046;&#22495;&#27867;&#21270;&#26041;&#38754;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2207.14000</link><description>&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#19978;&#30340;&#22810;&#27493;&#28436;&#32462;&#25512;&#29702;&#65306;&#22522;&#20110;&#36229;&#39046;&#22495;&#27867;&#21270;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2207.14000
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;IMA-GloVe-GA&#65292;&#19968;&#20010;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#22810;&#27493;&#25512;&#29702;&#30340;&#36845;&#20195;&#31070;&#32463;&#25512;&#29702;&#32593;&#32476;&#65292;&#22312;&#36229;&#39046;&#22495;&#27867;&#21270;&#26041;&#38754;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#28145;&#24230;&#23398;&#20064;&#19982;&#31526;&#21495;&#36923;&#36753;&#25512;&#29702;&#32467;&#21512;&#36215;&#26469;&#65292;&#26088;&#22312;&#20805;&#20998;&#21033;&#29992;&#36825;&#20004;&#20010;&#39046;&#22495;&#30340;&#25104;&#21151;&#65292;&#24182;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#21463;DeepLogic&#21551;&#21457;&#65292;&#35813;&#27169;&#22411;&#32463;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#65292;&#29992;&#20110;&#25191;&#34892;&#36923;&#36753;&#31243;&#24207;&#25512;&#29702;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;IMA-GloVe-GA&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#22810;&#27493;&#25512;&#29702;&#30340;&#36845;&#20195;&#31070;&#32463;&#25512;&#29702;&#32593;&#32476;&#12290;&#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;&#25512;&#29702;&#26159;&#20351;&#29992;&#22522;&#20110;RNN&#30340;&#36845;&#20195;&#20869;&#23384;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30340;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#20010;&#38376;&#20851;&#27880;&#26426;&#21046;&#12290;&#25105;&#20204;&#22312;PARARULES&#12289;CONCEPTRULES V1&#21644;CONCEPTRULES V2&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;IMA-GloVe-GA&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#24102;&#26377;&#38376;&#20851;&#27880;&#26426;&#21046;&#30340;DeepLogic&#27604;DeepLogic&#21644;&#20854;&#20182;RNN&#22522;&#32447;&#27169;&#22411;&#33021;&#22815;&#23454;&#29616;&#26356;&#39640;&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#35268;&#21017;&#34987;&#25171;&#20081;&#26102;&#27604;RoBERTa-Large&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#36229;&#39046;&#22495;&#27867;&#21270;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#35299;&#20915;&#24403;&#21069;&#22810;&#27493;&#25512;&#29702;&#25968;&#25454;&#38598;&#20013;&#25512;&#29702;&#28145;&#24230;&#19981;&#24179;&#34913;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
arXiv:2207.14000v2 Announce Type: replace-cross  Abstract: Combining deep learning with symbolic logic reasoning aims to capitalize on the success of both fields and is drawing increasing attention. Inspired by DeepLogic, an end-to-end model trained to perform inference on logic programs, we introduce IMA-GloVe-GA, an iterative neural inference network for multi-step reasoning expressed in natural language. In our model, reasoning is performed using an iterative memory neural network based on RNN with a gate attention mechanism. We evaluate IMA-GloVe-GA on three datasets: PARARULES, CONCEPTRULES V1 and CONCEPTRULES V2. Experimental results show DeepLogic with gate attention can achieve higher test accuracy than DeepLogic and other RNN baseline models. Our model achieves better out-of-distribution generalisation than RoBERTa-Large when the rules have been shuffled. Furthermore, to address the issue of unbalanced distribution of reasoning depths in the current multi-step reasoning datase
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#26469;&#38477;&#20302;&#35745;&#31639;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.20285</link><description>&lt;p&gt;
&#36890;&#36807;&#20197;&#35745;&#31639;&#20026;&#20195;&#20215;&#21152;&#36895;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Accelerating Generalized Linear Models by Trading off Computation for Uncertainty. (arXiv:2310.20285v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#26469;&#38477;&#20302;&#35745;&#31639;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLMs&#65289;&#23450;&#20041;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#27169;&#20998;&#31867;&#12289;&#26377;&#24207;&#21644;&#36830;&#32493;&#25968;&#25454;&#65292;&#24182;&#19988;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;GLMs&#30340;&#31934;&#30830;&#25512;&#26029;&#20195;&#20215;&#22826;&#39640;&#65292;&#22240;&#27492;&#38656;&#35201;&#22312;&#23454;&#36341;&#20013;&#36827;&#34892;&#36817;&#20284;&#12290;&#36896;&#25104;&#30340;&#36817;&#20284;&#35823;&#24046;&#23545;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#65292;&#24182;&#19988;&#27809;&#26377;&#34987;&#32771;&#34385;&#22312;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20013;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#36845;&#20195;&#26041;&#27861;&#65292;&#26126;&#30830;&#22320;&#23545;&#36825;&#20010;&#35823;&#24046;&#24314;&#27169;&#12290;&#23427;&#20204;&#38750;&#24120;&#36866;&#21512;&#24182;&#34892;&#35745;&#31639;&#30828;&#20214;&#65292;&#26377;&#25928;&#22320;&#22238;&#25910;&#35745;&#31639;&#24182;&#21387;&#32553;&#20449;&#24687;&#65292;&#20197;&#20943;&#23569;GLMs&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#19968;&#20010;&#23454;&#38469;&#30340;&#22823;&#22411;&#20998;&#31867;&#38382;&#39064;&#19978;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#26126;&#30830;&#22320;&#23558;&#20943;&#23569;&#35745;&#31639;&#19982;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#26435;&#34913;&#26469;&#26174;&#33879;&#21152;&#36895;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in GLMs is prohibitively expensive for large datasets, thus requiring approximations in practice. The resulting approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. In this work, we introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for GLMs. As we demonstrate on a realistically large classification problem, our method significantly accelerates training by explicitly trading off reduced computation for increased uncertainty.
&lt;/p&gt;</description></item><item><title>&#24322;&#27493;&#22270;&#29983;&#25104;&#22120;&#65288;AGG&#65289;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#36890;&#36807;&#33410;&#28857;&#29983;&#25104;&#36827;&#34892;&#25968;&#25454;&#25554;&#34917;&#65292;&#24182;&#38544;&#24335;&#23398;&#20064;&#20256;&#24863;&#22120;&#27979;&#37327;&#30340;&#22240;&#26524;&#22270;&#34920;&#31034;&#65292;&#21462;&#24471;&#20102;state-of-the-art&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.17335</link><description>&lt;p&gt;
&#24322;&#27493;&#22270;&#29983;&#25104;&#22120;
&lt;/p&gt;
&lt;p&gt;
Asynchronous Graph Generators. (arXiv:2309.17335v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17335
&lt;/p&gt;
&lt;p&gt;
&#24322;&#27493;&#22270;&#29983;&#25104;&#22120;&#65288;AGG&#65289;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#36890;&#36807;&#33410;&#28857;&#29983;&#25104;&#36827;&#34892;&#25968;&#25454;&#25554;&#34917;&#65292;&#24182;&#38544;&#24335;&#23398;&#20064;&#20256;&#24863;&#22120;&#27979;&#37327;&#30340;&#22240;&#26524;&#22270;&#34920;&#31034;&#65292;&#21462;&#24471;&#20102;state-of-the-art&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#24322;&#27493;&#22270;&#29983;&#25104;&#22120;&#65288;AGG&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#22810;&#36890;&#36947;&#26102;&#38388;&#24207;&#21015;&#30340;&#26032;&#22411;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;AGG&#23558;&#35266;&#27979;&#20540;&#24314;&#27169;&#20026;&#21160;&#24577;&#22270;&#19978;&#30340;&#33410;&#28857;&#65292;&#24182;&#36890;&#36807;&#36716;&#23548;&#24335;&#33410;&#28857;&#29983;&#25104;&#36827;&#34892;&#25968;&#25454;&#25554;&#34917;&#12290;AGG&#19981;&#20381;&#36182;&#20110;&#24490;&#29615;&#32452;&#20214;&#25110;&#23545;&#26102;&#38388;&#35268;&#24459;&#30340;&#20551;&#35774;&#65292;&#20351;&#29992;&#21487;&#23398;&#20064;&#30340;&#23884;&#20837;&#23558;&#27979;&#37327;&#20540;&#12289;&#26102;&#38388;&#25139;&#21644;&#20803;&#25968;&#25454;&#30452;&#25509;&#34920;&#31034;&#22312;&#33410;&#28857;&#20013;&#65292;&#24182;&#21033;&#29992;&#27880;&#24847;&#26426;&#21046;&#26469;&#23398;&#20064;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36825;&#26679;&#65292;&#25152;&#25552;&#20986;&#30340;&#26550;&#26500;&#38544;&#24335;&#22320;&#23398;&#20064;&#20256;&#24863;&#22120;&#27979;&#37327;&#30340;&#22240;&#26524;&#22270;&#34920;&#31034;&#65292;&#21487;&#20197;&#22522;&#20110;&#26410;&#35265;&#26102;&#38388;&#25139;&#21644;&#20803;&#25968;&#25454;&#23545;&#26032;&#30340;&#27979;&#37327;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;AGG&#22312;&#27010;&#24565;&#21644;&#23454;&#35777;&#20004;&#26041;&#38754;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#24182;&#31616;&#35201;&#35752;&#35770;&#20102;&#25968;&#25454;&#22686;&#24378;&#23545;AGG&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AGG&#22312;t
&lt;/p&gt;
&lt;p&gt;
We introduce the asynchronous graph generator (AGG), a novel graph neural network architecture for multi-channel time series which models observations as nodes on a dynamic graph and can thus perform data imputation by transductive node generation. Completely free from recurrent components or assumptions about temporal regularity, AGG represents measurements, timestamps and metadata directly in the nodes via learnable embeddings, to then leverage attention to learn expressive relationships across the variables of interest. This way, the proposed architecture implicitly learns a causal graph representation of sensor measurements which can be conditioned on unseen timestamps and metadata to predict new measurements by an expansion of the learnt graph. The proposed AGG is compared both conceptually and empirically to previous work, and the impact of data augmentation on the performance of AGG is also briefly discussed. Our experiments reveal that AGG achieved state-of-the-art results in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2303.17765</link><description>&lt;p&gt;
&#23398;&#20064;&#30456;&#20284;&#30340;&#32447;&#24615;&#34920;&#31034;&#65306;&#36866;&#24212;&#24615;&#12289;&#26497;&#23567;&#21270;&#12289;&#20197;&#21450;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness. (arXiv:2303.17765v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#28982;&#32780;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#27424;&#32570;&#12290;&#26412;&#25991;&#26088;&#22312;&#29702;&#35299;&#20174;&#20855;&#26377;&#30456;&#20284;&#20294;&#24182;&#38750;&#23436;&#20840;&#30456;&#21516;&#30340;&#32447;&#24615;&#34920;&#31034;&#30340;&#20219;&#21153;&#20013;&#23398;&#20064;&#65292;&#21516;&#26102;&#22788;&#29702;&#24322;&#24120;&#20540;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21333;&#20219;&#21153;&#25110;&#20165;&#30446;&#26631;&#23398;&#20064;&#26102;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \textit{adaptive} to the similarity structure and \textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;</title><link>http://arxiv.org/abs/2002.08907</link><description>&lt;p&gt;
&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;
&lt;/p&gt;
&lt;p&gt;
Second-order Conditional Gradient Sliding. (arXiv:2002.08907v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.08907
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#38656;&#35201;&#39640;&#31934;&#24230;&#35299;&#20915;&#38382;&#39064;&#26102;&#65292;&#32422;&#26463;&#20108;&#38454;&#20984;&#20248;&#21270;&#31639;&#27861;&#26159;&#39318;&#36873;&#65292;&#22240;&#20026;&#23427;&#20204;&#20855;&#26377;&#23616;&#37096;&#20108;&#27425;&#25910;&#25947;&#24615;&#12290;&#36825;&#20123;&#31639;&#27861;&#22312;&#27599;&#27425;&#36845;&#20195;&#26102;&#38656;&#35201;&#35299;&#20915;&#19968;&#20010;&#32422;&#26463;&#20108;&#27425;&#23376;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;\emph{&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;}&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#19968;&#31181;&#26080;&#25237;&#24433;&#31639;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#23376;&#38382;&#39064;&#12290;&#24403;&#21487;&#34892;&#22495;&#26159;&#19968;&#20010;&#22810;&#38754;&#20307;&#26102;&#65292;&#35813;&#31639;&#27861;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;&#36827;&#20837;&#20108;&#27425;&#25910;&#25947;&#38454;&#27573;&#21518;&#65292;SOCGS&#31639;&#27861;&#38656;&#36890;&#36807;$\mathcal{O}(\log(\log 1/\varepsilon))$&#27425;&#19968;&#38454;&#21644;Hessian&#27491;&#20132;&#35843;&#29992;&#20197;&#21450;$\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$&#27425;&#32447;&#24615;&#26368;&#23567;&#21270;&#27491;&#20132;&#35843;&#29992;&#26469;&#23454;&#29616;$\varepsilon$-&#26368;&#20248;&#35299;&#12290;&#24403;&#21487;&#34892;&#22495;&#21482;&#33021;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#27491;&#20132;&#35843;&#29992;&#39640;&#25928;&#35775;&#38382;&#26102;&#65292;&#27492;&#31639;&#27861;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constrained second-order convex optimization algorithms are the method of choice when a high accuracy solution to a problem is needed, due to their local quadratic convergence. These algorithms require the solution of a constrained quadratic subproblem at every iteration. We present the \emph{Second-Order Conditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free algorithm to solve the constrained quadratic subproblems inexactly. When the feasible region is a polytope the algorithm converges quadratically in primal gap after a finite number of linearly convergent iterations. Once in the quadratic regime the SOCGS algorithm requires $\mathcal{O}(\log(\log 1/\varepsilon))$ first-order and Hessian oracle calls and $\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$ linear minimization oracle calls to achieve an $\varepsilon$-optimal solution. This algorithm is useful when the feasible region can only be accessed efficiently through a linear optimization oracle, 
&lt;/p&gt;</description></item></channel></rss>