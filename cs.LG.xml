<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#33268;&#21147;&#20110;&#30740;&#31350;&#36830;&#32493;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#29109;&#27491;&#21017;&#21270;&#24494;&#35843;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20998;&#26512;&#22914;&#20309;&#25193;&#23637;&#21040;&#28041;&#21450;&#19968;&#33324;$f$-&#25955;&#24230;&#27491;&#21017;&#21270;&#30340;&#24494;&#35843;&#20013;&#12290;</title><link>https://arxiv.org/abs/2403.06279</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#25511;&#21046;&#36827;&#34892;&#25193;&#25955;&#27169;&#22411;&#30340;&#24494;&#35843;&#65306;&#29109;&#27491;&#21017;&#21270;&#21450;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning of diffusion models via stochastic control: entropy regularization and beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06279
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#30740;&#31350;&#36830;&#32493;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#29109;&#27491;&#21017;&#21270;&#24494;&#35843;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20998;&#26512;&#22914;&#20309;&#25193;&#23637;&#21040;&#28041;&#21450;&#19968;&#33324;$f$-&#25955;&#24230;&#27491;&#21017;&#21270;&#30340;&#24494;&#35843;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#21457;&#23637;&#24182;&#23545;&#36830;&#32493;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#20013;&#29109;&#27491;&#21017;&#21270;&#24494;&#35843;&#38382;&#39064;&#36827;&#34892;&#20005;&#26684;&#22788;&#29702;&#65292;&#35813;&#38382;&#39064;&#26368;&#36817;&#30001;&#19978;&#21407;&#31561;&#20154;&#25552;&#20986;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20998;&#26512;&#25193;&#23637;&#21040;&#28041;&#21450;&#19968;&#33324;$f$-&#25955;&#24230;&#27491;&#21017;&#21270;&#30340;&#24494;&#35843;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06279v1 Announce Type: cross  Abstract: This paper aims to develop and provide a rigorous treatment to the problem of entropy regularized fine-tuning in the context of continuous-time diffusion models, which was recently proposed by Uehara et al. ( arXiv:2402.15194, 2024). We also show how the analysis can be extended to fine-tuning involving a general $f$-divergence regularizer.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; SpongeNet &#30340;&#26032;&#22411;&#28023;&#32501;&#25915;&#20987;&#65292;&#36890;&#36807;&#30452;&#25509;&#20316;&#29992;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#21442;&#25968;&#65292;&#25104;&#21151;&#22686;&#21152;&#20102;&#35270;&#35273;&#27169;&#22411;&#30340;&#33021;&#32791;&#65292;&#32780;&#19988;&#25152;&#38656;&#30340;&#26679;&#26412;&#25968;&#37327;&#26356;&#23569;&#12290;</title><link>https://arxiv.org/abs/2402.06357</link><description>&lt;p&gt;
SpongeNet &#25915;&#20987;&#65306;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#28023;&#32501;&#26435;&#37325;&#20013;&#27602;
&lt;/p&gt;
&lt;p&gt;
The SpongeNet Attack: Sponge Weight Poisoning of Deep Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; SpongeNet &#30340;&#26032;&#22411;&#28023;&#32501;&#25915;&#20987;&#65292;&#36890;&#36807;&#30452;&#25509;&#20316;&#29992;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#21442;&#25968;&#65292;&#25104;&#21151;&#22686;&#21152;&#20102;&#35270;&#35273;&#27169;&#22411;&#30340;&#33021;&#32791;&#65292;&#32780;&#19988;&#25152;&#38656;&#30340;&#26679;&#26412;&#25968;&#37327;&#26356;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28023;&#32501;&#25915;&#20987;&#26088;&#22312;&#22686;&#21152;&#22312;&#30828;&#20214;&#21152;&#36895;&#22120;&#19978;&#37096;&#32626;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#33021;&#32791;&#21644;&#35745;&#31639;&#26102;&#38388;&#12290;&#29616;&#26377;&#30340;&#28023;&#32501;&#25915;&#20987;&#21487;&#20197;&#36890;&#36807;&#28023;&#32501;&#31034;&#20363;&#36827;&#34892;&#25512;&#29702;&#65292;&#20063;&#21487;&#20197;&#36890;&#36807;&#28023;&#32501;&#20013;&#27602;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36827;&#34892;&#12290;&#28023;&#32501;&#31034;&#20363;&#21033;&#29992;&#28155;&#21152;&#21040;&#27169;&#22411;&#36755;&#20837;&#30340;&#25200;&#21160;&#26469;&#22686;&#21152;&#33021;&#37327;&#21644;&#24310;&#36831;&#65292;&#32780;&#28023;&#32501;&#20013;&#27602;&#21017;&#25913;&#21464;&#27169;&#22411;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#24341;&#21457;&#25512;&#29702;&#26102;&#30340;&#33021;&#37327;/&#24310;&#36831;&#25928;&#24212;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28023;&#32501;&#25915;&#20987;&#65292;&#31216;&#20026; SpongeNet&#12290;SpongeNet &#26159;&#31532;&#19968;&#20010;&#30452;&#25509;&#20316;&#29992;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#21442;&#25968;&#30340;&#28023;&#32501;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#28023;&#32501;&#20013;&#27602;&#65292;SpongeNet &#21487;&#20197;&#25104;&#21151;&#22686;&#21152;&#35270;&#35273;&#27169;&#22411;&#30340;&#33021;&#32791;&#65292;&#24182;&#19988;&#25152;&#38656;&#30340;&#26679;&#26412;&#25968;&#37327;&#26356;&#23569;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22914;&#26524;&#19981;&#19987;&#38376;&#38024;&#23545;&#28023;&#32501;&#20013;&#27602;&#36827;&#34892;&#35843;&#25972;&#65288;&#21363;&#20943;&#23567;&#25209;&#24402;&#19968;&#21270;&#20559;&#24046;&#20540;&#65289;&#65292;&#21017;&#27602;&#23475;&#38450;&#24481;&#20250;&#22833;&#25928;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26174;&#31034;&#20986;&#28023;&#32501;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sponge attacks aim to increase the energy consumption and computation time of neural networks deployed on hardware accelerators. Existing sponge attacks can be performed during inference via sponge examples or during training via Sponge Poisoning. Sponge examples leverage perturbations added to the model's input to increase energy and latency, while Sponge Poisoning alters the objective function of a model to induce inference-time energy/latency effects.   In this work, we propose a novel sponge attack called SpongeNet. SpongeNet is the first sponge attack that is performed directly on the parameters of a pre-trained model. Our experiments show that SpongeNet can successfully increase the energy consumption of vision models with fewer samples required than Sponge Poisoning. Our experiments indicate that poisoning defenses are ineffective if not adjusted specifically for the defense against Sponge Poisoning (i.e., they decrease batch normalization bias values). Our work shows that Spong
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;CLIP&#29992;&#20110;&#21333;&#30446;&#28145;&#24230;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#32852;&#21512;&#35757;&#32451;&#21453;&#21367;&#31215;&#35299;&#30721;&#22120;&#21644;&#21487;&#23398;&#20064;&#23884;&#20837;&#30697;&#38453;&#65292;&#20351;&#24471;CLIP&#33021;&#22815;&#29702;&#35299;&#28145;&#24230;&#65292;&#35813;&#26041;&#27861;&#22312;&#28145;&#24230;&#20272;&#35745;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#24182;&#20248;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.03251</link><description>&lt;p&gt;
CLIP&#21487;&#20197;&#29702;&#35299;&#28145;&#24230;
&lt;/p&gt;
&lt;p&gt;
CLIP Can Understand Depth
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;CLIP&#29992;&#20110;&#21333;&#30446;&#28145;&#24230;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#32852;&#21512;&#35757;&#32451;&#21453;&#21367;&#31215;&#35299;&#30721;&#22120;&#21644;&#21487;&#23398;&#20064;&#23884;&#20837;&#30697;&#38453;&#65292;&#20351;&#24471;CLIP&#33021;&#22815;&#29702;&#35299;&#28145;&#24230;&#65292;&#35813;&#26041;&#27861;&#22312;&#28145;&#24230;&#20272;&#35745;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#24182;&#20248;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20851;&#20110;&#23558;CLIP&#25512;&#24191;&#21040;&#21333;&#30446;&#28145;&#24230;&#20272;&#35745;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#32593;&#32476;&#29228;&#21462;&#30340;&#25968;&#25454;&#19978;&#39044;&#35757;&#32451;&#30340;CLIP&#22312;&#22270;&#20687;&#22359;&#21644;&#19982;&#28145;&#24230;&#30456;&#20851;&#30340;&#25552;&#31034;&#20043;&#38388;&#24471;&#21040;&#36866;&#24403;&#30456;&#20284;&#24615;&#26159;&#20302;&#25928;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36866;&#24212;CLIP&#29992;&#20110;&#26377;&#24847;&#20041;&#30340;&#23494;&#38598;&#39044;&#27979;&#21333;&#30446;&#28145;&#24230;&#20272;&#35745;&#65292;&#32780;&#26080;&#38656;&#24494;&#35843;&#20854;&#21407;&#22987;&#30340;&#35270;&#35273;-&#35821;&#35328;&#23545;&#40784;&#12290;&#36890;&#36807;&#32852;&#21512;&#35757;&#32451;&#19968;&#20010;&#32039;&#20945;&#30340;&#21453;&#21367;&#31215;&#35299;&#30721;&#22120;&#21644;&#19968;&#20010;&#21517;&#20026;mirror&#30340;&#23567;&#22411;&#21487;&#23398;&#20064;&#23884;&#20837;&#30697;&#38453;&#20316;&#20026;&#20854;&#25991;&#26412;&#32534;&#30721;&#22120;&#30340;&#38745;&#24577;&#25552;&#31034;&#65292;CLIP&#33021;&#22815;&#29702;&#35299;&#28145;&#24230;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;NYU Depth v2&#21644;KITTI&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20986;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#19982;&#20960;&#20010;&#20808;&#21069;&#30340;&#20165;&#35270;&#35273;&#27169;&#22411;&#30456;&#21305;&#37197;&#65292;&#32780;&#19988;&#32988;&#36807;&#20102;&#27599;&#20010;&#22522;&#20110;CLIP&#30340;&#28145;&#24230;&#20272;&#35745;&#27169;&#22411;&#12290;&#20851;&#20110;&#26102;&#38388;&#28145;&#24230;&#19968;&#33268;&#24615;&#21644;&#31354;&#38388;&#36830;&#32493;&#24615;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#33021;&#22815;&#26377;&#25928;&#22320;&#20248;&#21270;CLIP&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#26102;&#28382;&#30740;&#31350;&#36827;&#34892;&#20102;&#28040;&#34701;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies on generalizing CLIP for monocular depth estimation reveal that CLIP pre-trained on web-crawled data is inefficient for deriving proper similarities between image patches and depth-related prompts. In this paper, we adapt CLIP for meaningful quality of monocular depth estimation with dense prediction, without fine-tuning its original vision-language alignment. By jointly training a compact deconvolutional decoder with a tiny learnable embedding matrix named mirror, as a static prompt for its text encoder, CLIP is enabled to understand depth. With this approach, our model exhibits impressive performance matching several previous state-of-the-art vision-only models on the NYU Depth v2 and KITTI datasets, outperforming every CLIP-based depth estimation model with a large margin. Experiments on temporal depth consistency and spatial continuity demonstrate that the prior knowledge of CLIP can be effectively refined by our proposed framework. Furthermore, an ablation study on 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#22312;&#26631;&#31614;&#31232;&#32570;&#30340;Learning-To-Rank&#38382;&#39064;&#20013;&#65292;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#27169;&#22411;&#26159;&#21542;&#33021;&#32988;&#36807;GBDTs&#21644;&#20854;&#20182;&#38750;&#39044;&#35757;&#32451;&#27169;&#22411;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;SimCLR-Rank&#26041;&#27861;&#36827;&#34892;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#22823;&#37327;&#26080;&#26631;&#31614;&#25968;&#25454;&#21644;&#26377;&#38480;&#26631;&#31614;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2308.00177</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#27169;&#22411;&#22312;&#26631;&#31614;&#31232;&#32570;&#30340;Learning-To-Rank&#20013;&#32988;&#36807;GBDTs
&lt;/p&gt;
&lt;p&gt;
Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity. (arXiv:2308.00177v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#22312;&#26631;&#31614;&#31232;&#32570;&#30340;Learning-To-Rank&#38382;&#39064;&#20013;&#65292;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#27169;&#22411;&#26159;&#21542;&#33021;&#32988;&#36807;GBDTs&#21644;&#20854;&#20182;&#38750;&#39044;&#35757;&#32451;&#27169;&#22411;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;SimCLR-Rank&#26041;&#27861;&#36827;&#34892;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#22823;&#37327;&#26080;&#26631;&#31614;&#25968;&#25454;&#21644;&#26377;&#38480;&#26631;&#31614;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#25991;&#26412;&#21644;&#22270;&#20687;&#39046;&#22495;&#26159;&#26368;&#20808;&#36827;&#30340;&#65292;&#20294;&#23427;&#20204;&#22312;&#34920;&#26684;&#24418;&#24335;&#30340;Learning-To-Rank&#38382;&#39064;&#19978;&#23578;&#26410;&#19968;&#33268;&#22320;&#32988;&#36807;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;(GBDTs)&#12290;&#36817;&#26399;&#22312;&#25991;&#26412;&#21644;&#22270;&#20687;&#20219;&#21153;&#19978;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21462;&#24471;&#30340;&#24615;&#33021;&#25552;&#21319;&#20027;&#35201;&#20381;&#36182;&#20110;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#20102;&#27604;&#26377;&#26631;&#31614;&#25968;&#25454;&#22810;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#36824;&#26410;&#24212;&#29992;&#20110;Learning-To-Rank&#38382;&#39064;&#65292;&#32780;&#35813;&#38382;&#39064;&#36890;&#24120;&#20135;&#29983;&#22823;&#37327;&#26080;&#26631;&#31614;&#25968;&#25454;&#12290;&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#26159;&#21542;&#33021;&#25552;&#39640;LTR&#24615;&#33021;&#65292;&#19982;GBDTs&#21644;&#20854;&#20182;&#38750;&#39044;&#35757;&#32451;&#27169;&#22411;&#30456;&#27604;&#12290;&#36890;&#36807;&#20351;&#29992;&#31616;&#21333;&#30340;&#35774;&#35745;&#36873;&#25321;(&#21253;&#25324;SimCLR-Rank&#65292;&#36825;&#26159;&#25105;&#20204;&#38024;&#23545;&#25490;&#21517;&#38382;&#39064;&#20462;&#25913;&#30340;SimCLR&#26041;&#27861;)&#65292;&#25105;&#20204;&#20135;&#29983;&#20102;&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#26377;&#22823;&#37327;&#26080;&#26631;&#31614;&#25968;&#25454;&#19988;&#26377;&#38480;&#26631;&#31614;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#33879;&#20248;&#20110;GBDTs(&#21644;&#20854;&#20182;&#38750;&#39044;&#35757;&#32451;&#27169;&#22411;)&#12290;
&lt;/p&gt;
&lt;p&gt;
While deep learning (DL) models are state-of-the-art in text and image domains, they have not yet consistently outperformed Gradient Boosted Decision Trees (GBDTs) on tabular Learning-To-Rank (LTR) problems. Most of the recent performance gains attained by DL models in text and image tasks have used unsupervised pretraining, which exploits orders of magnitude more unlabeled data than labeled data. To the best of our knowledge, unsupervised pretraining has not been applied to the LTR problem, which often produces vast amounts of unlabeled data. In this work, we study whether unsupervised pretraining can improve LTR performance over GBDTs and other non-pretrained models. Using simple design choices--including SimCLR-Rank, our ranking-specific modification of SimCLR (an unsupervised pretraining method for images)--we produce pretrained deep learning models that soundly outperform GBDTs (and other non-pretrained models) in the case where labeled data is vastly outnumbered by unlabeled data
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#38544;&#31169;&#25104;&#26412;&#30340;&#26032;&#32467;&#26524;&#65292;&#21487;&#29992;&#20110;&#25512;&#26029;&#26679;&#26412;&#20998;&#24067;&#24182;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#35823;&#29992;&#12290;&#38543;&#30528;&#37319;&#26679;&#27425;&#25968;&#36235;&#36817;&#26080;&#38480;&#22823;&#65292;&#27492;&#26041;&#27861;&#36880;&#28176;&#28385;&#36275;&#26356;&#20005;&#26684;&#30340;&#24046;&#20998;&#38544;&#31169;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2210.06140</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#65306;&#26032;&#30340;&#38544;&#31169;&#20998;&#26512;&#19982;&#25512;&#26029;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies. (arXiv:2210.06140v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#38544;&#31169;&#25104;&#26412;&#30340;&#26032;&#32467;&#26524;&#65292;&#21487;&#29992;&#20110;&#25512;&#26029;&#26679;&#26412;&#20998;&#24067;&#24182;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#35823;&#29992;&#12290;&#38543;&#30528;&#37319;&#26679;&#27425;&#25968;&#36235;&#36817;&#26080;&#38480;&#22823;&#65292;&#27492;&#26041;&#27861;&#36880;&#28176;&#28385;&#36275;&#26356;&#20005;&#26684;&#30340;&#24046;&#20998;&#38544;&#31169;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36890;&#36807;&#24341;&#20837;&#38543;&#26426;&#24615;&#26469;&#20445;&#25252;&#20010;&#20154;&#20449;&#24687;&#65292;&#20294;&#22312;&#24212;&#29992;&#20013;&#65292;&#32479;&#35745;&#25512;&#26029;&#20173;&#28982;&#32570;&#20047;&#36890;&#29992;&#25216;&#26415;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#21457;&#24067;&#22810;&#20010;&#31169;&#26377;&#24341;&#23548;&#37319;&#26679;&#20272;&#35745;&#26469;&#25512;&#26029;&#26679;&#26412;&#20998;&#24067;&#24182;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#38544;&#31169;&#20998;&#26512;&#25552;&#20379;&#20102;&#21333;&#20010;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#20272;&#35745;&#30340;&#38544;&#31169;&#25104;&#26412;&#26032;&#32467;&#26524;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#65292;&#24182;&#25351;&#20986;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#24341;&#23548;&#37319;&#26679;&#30340;&#19968;&#20123;&#35823;&#29992;&#12290;&#20351;&#29992;Gaussian-DP&#65288;GDP&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#35777;&#26126;&#20174;&#28385;&#36275; $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP &#30340;&#26426;&#21046;&#20013;&#37322;&#25918; $B$ &#20010;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#20272;&#35745;&#65292;&#22312; $B$ &#36235;&#36817;&#26080;&#38480;&#22823;&#26102;&#28176;&#36817;&#22320;&#28385;&#36275; $\mu$-GDP&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#24341;&#23548;&#37319;&#26679;&#20272;&#35745;&#30340;&#21453;&#21367;&#31215;&#23545;&#26679;&#26412;&#20998;&#24067;&#36827;&#34892;&#20934;&#30830;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private (DP) mechanisms protect individual-level information by introducing randomness into the statistical analysis procedure. Despite the availability of numerous DP tools, there remains a lack of general techniques for conducting statistical inference under DP. We examine a DP bootstrap procedure that releases multiple private bootstrap estimates to infer the sampling distribution and construct confidence intervals (CIs). Our privacy analysis presents new results on the privacy cost of a single DP bootstrap estimate, applicable to any DP mechanisms, and identifies some misapplications of the bootstrap in the existing literature. Using the Gaussian-DP (GDP) framework (Dong et al.,2022), we show that the release of $B$ DP bootstrap estimates from mechanisms satisfying $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP asymptotically satisfies $\mu$-GDP as $B$ goes to infinity. Moreover, we use deconvolution with the DP bootstrap estimates to accurately infer the sampling distribution
&lt;/p&gt;</description></item></channel></rss>