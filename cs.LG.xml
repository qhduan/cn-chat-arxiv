<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;AdaptSFL&#33258;&#36866;&#24212;&#20998;&#21106;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#20197;&#21152;&#36895;&#36164;&#28304;&#21463;&#38480;&#36793;&#32536;&#31995;&#32479;&#20013;&#30340;&#23398;&#20064;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13101</link><description>&lt;p&gt;
AdaptSFL&#65306;&#36164;&#28304;&#21463;&#38480;&#36793;&#32536;&#32593;&#32476;&#20013;&#30340;&#33258;&#36866;&#24212;&#20998;&#21106;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
AdaptSFL: Adaptive Split Federated Learning in Resource-constrained Edge Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13101
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;AdaptSFL&#33258;&#36866;&#24212;&#20998;&#21106;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#20197;&#21152;&#36895;&#36164;&#28304;&#21463;&#38480;&#36793;&#32536;&#31995;&#32479;&#20013;&#30340;&#23398;&#20064;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26085;&#30410;&#22797;&#26434;&#20351;&#24471;&#23558;&#20854;&#27665;&#20027;&#21270;&#21040;&#36164;&#28304;&#26377;&#38480;&#30340;&#36793;&#32536;&#35774;&#22791;&#38754;&#20020;&#37325;&#35201;&#38556;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#36890;&#36807;&#27169;&#22411;&#20998;&#21306;&#23558;&#20027;&#35201;&#35757;&#32451;&#24037;&#20316;&#36127;&#33655;&#36716;&#31227;&#21040;&#26381;&#21153;&#22120;&#19978;&#65292;&#24182;&#22312;&#36793;&#32536;&#35774;&#22791;&#20043;&#38388;&#23454;&#29616;&#24182;&#34892;&#35757;&#32451;&#30340;&#20998;&#21106;&#32852;&#37030;&#23398;&#20064;&#65288;SFL&#65289;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#31995;&#32479;&#20248;&#21270;&#26497;&#22823;&#22320;&#24433;&#21709;&#20102;&#36164;&#28304;&#21463;&#38480;&#31995;&#32479;&#19979;SFL&#30340;&#24615;&#33021;&#65292;&#20294;&#36825;&#20010;&#38382;&#39064;&#20173;&#28982;&#24456;&#22823;&#31243;&#24230;&#19978;&#27809;&#26377;&#34987;&#25506;&#32034;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;SFL&#30340;&#25910;&#25947;&#20998;&#26512;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#20998;&#21106;&#65288;MS&#65289;&#21644;&#23458;&#25143;&#31471;&#27169;&#22411;&#32858;&#21512;&#65288;MA&#65289;&#23545;&#23398;&#20064;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#20316;&#20026;&#29702;&#35770;&#22522;&#30784;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AdaptSFL&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#36164;&#28304;&#33258;&#36866;&#24212;SFL&#26694;&#26550;&#65292;&#20197;&#21152;&#36895;&#36164;&#28304;&#21463;&#38480;&#36793;&#32536;&#35745;&#31639;&#31995;&#32479;&#19979;&#30340;SFL&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;AdaptSFL&#33258;&#36866;&#24212;&#22320;&#25511;&#21046;&#23458;&#25143;&#31471;MA&#21644;MS&#65292;&#20197;&#24179;&#34913;&#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13101v1 Announce Type: new  Abstract: The increasing complexity of deep neural networks poses significant barriers to democratizing them to resource-limited edge devices. To address this challenge, split federated learning (SFL) has emerged as a promising solution by of floading the primary training workload to a server via model partitioning while enabling parallel training among edge devices. However, although system optimization substantially influences the performance of SFL under resource-constrained systems, the problem remains largely uncharted. In this paper, we provide a convergence analysis of SFL which quantifies the impact of model splitting (MS) and client-side model aggregation (MA) on the learning performance, serving as a theoretical foundation. Then, we propose AdaptSFL, a novel resource-adaptive SFL framework, to expedite SFL under resource-constrained edge computing systems. Specifically, AdaptSFL adaptively controls client-side MA and MS to balance commun
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#65292;&#20197;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#22312;&#34920;&#31034;&#21160;&#21147;&#24179;&#34913;&#21644;&#36866;&#29992;&#20110;&#25968;&#25454;&#21516;&#21270;&#23454;&#39564;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.03702</link><description>&lt;p&gt;
&#22312;&#32447;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#19982;&#31070;&#32463;&#32593;&#32476;: &#24212;&#29992;&#20110;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Online model error correction with neural networks: application to the Integrated Forecasting System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03702
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#65292;&#20197;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#22312;&#34920;&#31034;&#21160;&#21147;&#24179;&#34913;&#21644;&#36866;&#29992;&#20110;&#25968;&#25454;&#21516;&#21270;&#23454;&#39564;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#22312;&#20840;&#29699;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#30340;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#24320;&#21457;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#36825;&#20123;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#20855;&#26377;&#20854;&#20248;&#21183;&#65292;&#23588;&#20854;&#26159;&#20934;&#30830;&#24615;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#38656;&#27714;&#65292;&#20294;&#20063;&#23384;&#22312;&#20854;&#24369;&#28857;&#65306;&#23427;&#20204;&#38590;&#20197;&#34920;&#31034;&#22522;&#26412;&#21160;&#21147;&#24179;&#34913;&#65292;&#24182;&#19988;&#36828;&#26410;&#36866;&#29992;&#20110;&#36164;&#26009;&#21516;&#21270;&#23454;&#39564;&#12290;&#28151;&#21512;&#24314;&#27169;&#20986;&#29616;&#20026;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#30340;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;&#28151;&#21512;&#27169;&#22411;&#23558;&#22522;&#20110;&#29289;&#29702;&#30340;&#26680;&#24515;&#32452;&#20214;&#19982;&#32479;&#35745;&#32452;&#20214;&#65288;&#36890;&#24120;&#26159;&#31070;&#32463;&#32593;&#32476;&#65289;&#38598;&#25104;&#22312;&#19968;&#36215;&#65292;&#20197;&#22686;&#24378;&#39044;&#27979;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#36816;&#34892;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#65288;IFS&#65289;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#12290;&#31070;&#32463;&#32593;&#32476;&#26368;&#21021;&#20250;&#31163;&#32447;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#20351;&#29992;&#22823;&#37327;&#36816;&#34892;&#20998;&#26512;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03702v1 Announce Type: cross  Abstract: In recent years, there has been significant progress in the development of fully data-driven global numerical weather prediction models. These machine learning weather prediction models have their strength, notably accuracy and low computational requirements, but also their weakness: they struggle to represent fundamental dynamical balances, and they are far from being suitable for data assimilation experiments. Hybrid modelling emerges as a promising approach to address these limitations. Hybrid models integrate a physics-based core component with a statistical component, typically a neural network, to enhance prediction capabilities. In this article, we propose to develop a model error correction for the operational Integrated Forecasting System (IFS) of the European Centre for Medium-Range Weather Forecasts using a neural network. The neural network is initially pre-trained offline using a large dataset of operational analyses and a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;</title><link>https://arxiv.org/abs/2402.17732</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;
&lt;/p&gt;
&lt;p&gt;
Batched Nonparametric Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17732
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#21160;&#20316;&#30340;&#26399;&#26395;&#22870;&#21169;&#34987;&#24314;&#27169;&#20026;&#21327;&#21464;&#37327;&#30340;&#24179;&#28369;&#20989;&#25968;&#65292;&#24182;&#19988;&#31574;&#30053;&#26356;&#26032;&#26159;&#22312;&#27599;&#20010;Observations&#25209;&#27425;&#32467;&#26463;&#26102;&#36827;&#34892;&#30340;&#12290;&#25105;&#20204;&#20026;&#36825;&#31181;&#35774;&#32622;&#24314;&#31435;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Batched Successive Elimination with Dynamic Binning&#65288;BaSEDB&#65289;&#30340;&#26041;&#26696;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21518;&#24724;&#65288;&#36798;&#21040;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#23454;&#36136;&#19978;&#65292;BaSEDB&#21160;&#24577;&#22320;&#23558;&#21327;&#21464;&#37327;&#31354;&#38388;&#20998;&#21106;&#25104;&#26356;&#23567;&#30340;&#31665;&#23376;&#65292;&#24182;&#20180;&#32454;&#35843;&#25972;&#23427;&#20204;&#30340;&#23485;&#24230;&#20197;&#31526;&#21512;&#25209;&#27425;&#22823;&#23567;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#38745;&#24577;&#20998;&#31665;&#30340;&#38750;&#26368;&#20248;&#24615;&#65292;&#31361;&#20986;&#20102;&#21160;&#24577;&#20998;&#31665;&#30340;&#24517;&#35201;&#24615;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23436;&#20840;&#22312;&#32447;&#35774;&#32622;&#20013;&#65292;&#20960;&#20046;&#24658;&#23450;&#25968;&#37327;&#30340;&#31574;&#30053;&#26356;&#26032;&#21487;&#20197;&#36798;&#21040;&#26368;&#20339;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17732v1 Announce Type: cross  Abstract: We study nonparametric contextual bandits under batch constraints, where the expected reward for each action is modeled as a smooth function of covariates, and the policy updates are made at the end of each batch of observations. We establish a minimax regret lower bound for this setting and propose Batched Successive Elimination with Dynamic Binning (BaSEDB) that achieves optimal regret (up to logarithmic factors). In essence, BaSEDB dynamically splits the covariate space into smaller bins, carefully aligning their widths with the batch size. We also show the suboptimality of static binning under batch constraints, highlighting the necessity of dynamic binning. Additionally, our results suggest that a nearly constant number of policy updates can attain optimal regret in the fully online setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21033;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#26679;&#26412;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#31574;&#30053;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#65292;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#65292;&#24182;&#35777;&#26126;&#20854;&#25910;&#25947;&#36895;&#24230;&#20248;&#20110;&#38543;&#26426;&#36873;&#25321;&#12290;&#21516;&#26102;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#30340;SIFT&#26041;&#27861;&#65292;&#24182;&#22312;&#35757;&#32451;BERT&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.07052</link><description>&lt;p&gt;
&#29702;&#35299;&#36890;&#36807;&#20351;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Understanding the Training Speedup from Sampling with Approximate Losses
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21033;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#26679;&#26412;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#31574;&#30053;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#65292;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#65292;&#24182;&#35777;&#26126;&#20854;&#25910;&#25947;&#36895;&#24230;&#20248;&#20110;&#38543;&#26426;&#36873;&#25321;&#12290;&#21516;&#26102;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#30340;SIFT&#26041;&#27861;&#65292;&#24182;&#22312;&#35757;&#32451;BERT&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#36873;&#25321;&#20855;&#26377;&#36739;&#22823;&#25439;&#22833;/&#26799;&#24230;&#30340;&#26679;&#26412;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#35757;&#32451;&#27493;&#39588;&#30340;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#30340;&#24320;&#38144;&#24448;&#24448;&#36807;&#39640;&#65292;&#26080;&#27861;&#22312;&#24635;&#20307;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#33719;&#24471;&#26377;&#24847;&#20041;&#30340;&#25552;&#21319;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#30340;&#36138;&#23146;&#26041;&#27861;&#65292;&#32780;&#19981;&#26159;&#20934;&#30830;&#25439;&#22833;&#65292;&#20197;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#12290;&#23545;&#20110;&#24179;&#28369;&#20984;&#25439;&#22833;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#36138;&#23146;&#31574;&#30053;&#21487;&#20197;&#22312;&#27604;&#38543;&#26426;&#36873;&#25321;&#26356;&#23569;&#30340;&#36845;&#20195;&#27425;&#25968;&#20869;&#25910;&#25947;&#21040;&#24179;&#22343;&#25439;&#22833;&#30340;&#26368;&#23567;&#20540;&#30340;&#24120;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#36824;&#29702;&#35770;&#19978;&#37327;&#21270;&#20102;&#36817;&#20284;&#27700;&#24179;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#20197;&#36827;&#34892;&#26679;&#26412;&#36873;&#25321;&#30340;SIFT&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;SIFT&#22312;&#35757;&#32451;&#19968;&#20010;&#20855;&#26377;1.1&#20159;&#21442;&#25968;&#30340;12&#23618;BERT&#22522;&#30784;&#27169;&#22411;&#19978;&#30340;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#65288;&#20197;&#35757;&#32451;&#26102;&#38388;&#21644;&#21453;&#21521;&#20256;&#25773;&#27493;&#39588;&#30340;&#25968;&#37327;&#34913;&#37327;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that selecting samples with large losses/gradients can significantly reduce the number of training steps. However, the selection overhead is often too high to yield any meaningful gains in terms of overall training time. In this work, we focus on the greedy approach of selecting samples with large \textit{approximate losses} instead of exact losses in order to reduce the selection overhead. For smooth convex losses, we show that such a greedy strategy can converge to a constant factor of the minimum value of the average loss in fewer iterations than the standard approach of random selection. We also theoretically quantify the effect of the approximation level. We then develop SIFT which uses early exiting to obtain approximate losses with an intermediate layer's representations for sample selection. We evaluate SIFT on the task of training a 110M parameter 12-layer BERT base model and show significant gains (in terms of training hours and number of backpropagation step
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#37096;&#32626;&#22312;6G&#36793;&#32536;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#30001;LLMs&#25903;&#25345;&#30340;&#20851;&#38190;&#24212;&#29992;&#65292;&#24182;&#20174;&#21709;&#24212;&#26102;&#38388;&#12289;&#24102;&#23485;&#25104;&#26412;&#21644;&#25968;&#25454;&#38544;&#31169;&#31561;&#26041;&#38754;&#20998;&#26512;&#20102;&#20113;&#31471;&#37096;&#32626;&#38754;&#20020;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;6G&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;(MEC)&#31995;&#32479;&#21487;&#33021;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#26696;&#65292;&#24182;&#35752;&#35770;&#20102;&#36793;&#32536;&#35757;&#32451;&#21644;&#36793;&#32536;&#25512;&#29702;&#30340;&#21019;&#26032;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2309.16739</link><description>&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33267;6G&#36793;&#32536;&#65306;&#35270;&#37326;&#12289;&#25361;&#25112;&#21644;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities. (arXiv:2309.16739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#37096;&#32626;&#22312;6G&#36793;&#32536;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#30001;LLMs&#25903;&#25345;&#30340;&#20851;&#38190;&#24212;&#29992;&#65292;&#24182;&#20174;&#21709;&#24212;&#26102;&#38388;&#12289;&#24102;&#23485;&#25104;&#26412;&#21644;&#25968;&#25454;&#38544;&#31169;&#31561;&#26041;&#38754;&#20998;&#26512;&#20102;&#20113;&#31471;&#37096;&#32626;&#38754;&#20020;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;6G&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;(MEC)&#31995;&#32479;&#21487;&#33021;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#26696;&#65292;&#24182;&#35752;&#35770;&#20102;&#36793;&#32536;&#35757;&#32451;&#21644;&#36793;&#32536;&#25512;&#29702;&#30340;&#21019;&#26032;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#33021;&#21147;&#65292;&#27491;&#22312;&#25913;&#21464;&#20154;&#24037;&#26234;&#33021;&#30340;&#21457;&#23637;&#24182;&#26377;&#21487;&#33021;&#22609;&#36896;&#25105;&#20204;&#30340;&#26410;&#26469;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLMs&#30340;&#22810;&#27169;&#24577;&#29305;&#24615;&#65292;&#24403;&#21069;&#30340;&#22522;&#20110;&#20113;&#30340;&#37096;&#32626;&#38754;&#20020;&#30528;&#19968;&#20123;&#20851;&#38190;&#25361;&#25112;&#65306;1) &#21709;&#24212;&#26102;&#38388;&#38271;&#65307;2) &#39640;&#24102;&#23485;&#25104;&#26412;&#65307;&#20197;&#21450;3) &#36829;&#21453;&#25968;&#25454;&#38544;&#31169;&#12290;6G&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;(MEC)&#31995;&#32479;&#21487;&#33021;&#35299;&#20915;&#36825;&#20123;&#36843;&#20999;&#38382;&#39064;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;6G&#36793;&#32536;&#37096;&#32626;LLMs&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#30001;&#22810;&#27169;&#24577;LLMs&#25552;&#20379;&#25903;&#25345;&#30340;&#20851;&#38190;&#24212;&#29992;&#65292;&#21253;&#25324;&#26426;&#22120;&#20154;&#25216;&#26415;&#21644;&#21307;&#30103;&#20445;&#20581;&#65292;&#20197;&#31361;&#20986;&#22312;&#32456;&#31471;&#29992;&#25143;&#38468;&#36817;&#37096;&#32626;LLMs&#30340;&#38656;&#27714;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#22312;&#36793;&#32536;&#37096;&#32626;LLMs&#26102;&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#65292;&#24182;&#35774;&#24819;&#20102;&#36866;&#29992;&#20110;LLMs&#30340;6G MEC&#26550;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#20004;&#20010;&#35774;&#35745;&#26041;&#38754;&#65292;&#21363;LLMs&#30340;&#36793;&#32536;&#35757;&#32451;&#21644;&#36793;&#32536;&#25512;&#29702;&#12290;&#22312;&#36825;&#20004;&#20010;&#26041;&#38754;&#65292;&#32771;&#34385;&#21040;&#36793;&#32536;&#30340;&#22266;&#26377;&#36164;&#28304;&#38480;&#21046;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#21508;&#31181;&#21069;&#27839;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing AI development and potentially shaping our future. However, given their multimodality, the status quo cloud-based deployment faces some critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article, we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs, including robotics and healthcare, to highlight the need for deploying LLMs in the vicinity of end users. Then, we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore, we delve into two design aspects, i.e., edge training and edge inference for LLMs. In both aspects, considering the inherent resource limitations at the edge, we discuss various cutting-edge techniques, i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31616;&#26131;&#27880;&#24847;&#21147;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#29992;&#20110;&#25552;&#39640;Transformer&#31070;&#32463;&#32593;&#32476;&#22312;&#28151;&#27788;&#31995;&#32479;&#26102;&#38388;&#21160;&#24577;&#39044;&#27979;&#20013;&#30340;&#40065;&#26834;&#24615;&#12290;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#38190;&#12289;&#26597;&#35810;&#21644;softmax&#65292;&#30452;&#25509;&#23558;&#27880;&#24847;&#21147;&#24471;&#20998;&#20316;&#20026;&#21487;&#23398;&#20064;&#21442;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#37325;&#26500;&#21644;&#39044;&#27979;&#28151;&#27788;&#31995;&#32479;&#30340;&#26102;&#38388;&#21160;&#24577;&#26041;&#38754;&#27604;&#20256;&#32479;&#30340;&#33258;&#27880;&#24847;&#26426;&#21046;&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#26041;&#27861;&#26356;&#20855;&#40065;&#26834;&#24615;&#21644;&#31616;&#21270;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.12874</link><description>&lt;p&gt;
&#31616;&#26131;&#27880;&#24847;&#21147;&#65306;&#19968;&#31181;&#29992;&#20110;Transformer&#30340;&#31616;&#21333;&#33258;&#27880;&#24847;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Easy attention: A simple self-attention mechanism for Transformers. (arXiv:2308.12874v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12874
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31616;&#26131;&#27880;&#24847;&#21147;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#29992;&#20110;&#25552;&#39640;Transformer&#31070;&#32463;&#32593;&#32476;&#22312;&#28151;&#27788;&#31995;&#32479;&#26102;&#38388;&#21160;&#24577;&#39044;&#27979;&#20013;&#30340;&#40065;&#26834;&#24615;&#12290;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#38190;&#12289;&#26597;&#35810;&#21644;softmax&#65292;&#30452;&#25509;&#23558;&#27880;&#24847;&#21147;&#24471;&#20998;&#20316;&#20026;&#21487;&#23398;&#20064;&#21442;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#37325;&#26500;&#21644;&#39044;&#27979;&#28151;&#27788;&#31995;&#32479;&#30340;&#26102;&#38388;&#21160;&#24577;&#26041;&#38754;&#27604;&#20256;&#32479;&#30340;&#33258;&#27880;&#24847;&#26426;&#21046;&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#26041;&#27861;&#26356;&#20855;&#40065;&#26834;&#24615;&#21644;&#31616;&#21270;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#39640;&#29992;&#20110;&#28151;&#27788;&#31995;&#32479;&#26102;&#38388;&#21160;&#24577;&#39044;&#27979;&#30340;Transformer&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#31216;&#20026;&#31616;&#26131;&#27880;&#24847;&#21147;&#12290;&#30001;&#20110;&#33258;&#27880;&#24847;&#26426;&#21046;&#20165;&#20351;&#29992;&#26597;&#35810;&#21644;&#38190;&#30340;&#20869;&#31215;&#65292;&#22240;&#27492;&#35777;&#26126;&#20102;&#20026;&#20102;&#33719;&#21462;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#25152;&#38656;&#30340;&#27880;&#24847;&#21147;&#24471;&#20998;&#65292;&#24182;&#19981;&#38656;&#35201;&#38190;&#12289;&#26597;&#35810;&#21644;softmax&#12290;&#36890;&#36807;&#22312;softmax&#27880;&#24847;&#21147;&#24471;&#20998;&#19978;&#23454;&#26045;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35266;&#23519;&#21040;&#33258;&#27880;&#24847;&#21147;&#22312;&#27880;&#24847;&#21147;&#24471;&#20998;&#30340;&#24352;&#25104;&#31354;&#38388;&#20013;&#21387;&#32553;&#20102;&#26469;&#33258;&#26597;&#35810;&#21644;&#38190;&#30340;&#36129;&#29486;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31616;&#26131;&#27880;&#24847;&#21147;&#26041;&#27861;&#30452;&#25509;&#23558;&#27880;&#24847;&#21147;&#24471;&#20998;&#20316;&#20026;&#21487;&#23398;&#20064;&#21442;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#37325;&#26500;&#21644;&#39044;&#27979;&#23637;&#29616;&#26356;&#24378;&#40065;&#26834;&#24615;&#21644;&#26356;&#23569;&#22797;&#26434;&#24615;&#30340;&#28151;&#27788;&#31995;&#32479;&#30340;&#26102;&#38388;&#21160;&#24577;&#26102;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#32467;&#26524;&#65292;&#27604;&#33258;&#27880;&#24847;&#26426;&#21046;&#25110;&#24191;&#27867;&#20351;&#29992;&#30340;&#38271;&#30701;&#26399;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
To improve the robustness of transformer neural networks used for temporal-dynamics prediction of chaotic systems, we propose a novel attention mechanism called easy attention. Due to the fact that self attention only makes usage of the inner product of queries and keys, it is demonstrated that the keys, queries and softmax are not necessary for obtaining the attention score required to capture long-term dependencies in temporal sequences. Through implementing singular-value decomposition (SVD) on the softmax attention score, we further observe that the self attention compresses contribution from both queries and keys in the spanned space of the attention score. Therefore, our proposed easy-attention method directly treats the attention scores as learnable parameters. This approach produces excellent results when reconstructing and predicting the temporal dynamics of chaotic systems exhibiting more robustness and less complexity than the self attention or the widely-used long short-ter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;YNN&#30340;&#26041;&#27861;&#65292;&#23558;&#21516;&#19968;&#32423;&#21035;&#30340;ANN&#33410;&#28857;&#36830;&#25509;&#22312;&#19968;&#36215;&#24418;&#25104;&#31070;&#32463;&#27169;&#22359;&#65292;&#35299;&#20915;&#20102;&#26222;&#36890;ANN&#26080;&#27861;&#20849;&#20139;&#20449;&#24687;&#30340;&#32570;&#38519;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#20449;&#24687;&#20256;&#36755;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02157</link><description>&lt;p&gt;
&#23558;&#31070;&#32463;&#32593;&#32476;&#36716;&#21270;&#20026;Yoked&#31070;&#32463;&#32593;&#32476;&#20197;&#25913;&#36827;ANN&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Transforming to Yoked Neural Networks to Improve ANN Structure. (arXiv:2306.02157v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;YNN&#30340;&#26041;&#27861;&#65292;&#23558;&#21516;&#19968;&#32423;&#21035;&#30340;ANN&#33410;&#28857;&#36830;&#25509;&#22312;&#19968;&#36215;&#24418;&#25104;&#31070;&#32463;&#27169;&#22359;&#65292;&#35299;&#20915;&#20102;&#26222;&#36890;ANN&#26080;&#27861;&#20849;&#20139;&#20449;&#24687;&#30340;&#32570;&#38519;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#20449;&#24687;&#20256;&#36755;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#37096;&#20998;&#24050;&#32463;&#23384;&#22312;&#30340;&#32463;&#20856;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANN&#65289;&#37117;&#34987;&#35774;&#35745;&#25104;&#26641;&#24418;&#32467;&#26500;&#20197;&#27169;&#25311;&#31070;&#32463;&#32593;&#32476;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#26641;&#24418;&#32467;&#26500;&#30340;&#36830;&#25509;&#19981;&#36275;&#20197;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#12290;&#21516;&#19968;&#32423;&#21035;&#30340;&#33410;&#28857;&#19981;&#33021;&#36830;&#25509;&#22312;&#19968;&#36215;&#65292;&#21363;&#36825;&#20123;&#31070;&#32463;&#20803;&#19981;&#33021;&#30456;&#20114;&#20849;&#20139;&#20449;&#24687;&#65292;&#36825;&#26159;ANN&#30340;&#19968;&#20010;&#37325;&#22823;&#32570;&#38519;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21363;&#20026;&#21516;&#19968;&#32423;&#21035;&#30340;&#33410;&#28857;&#24314;&#31435;&#21452;&#21521;&#23436;&#20840;&#22270;&#65292;&#23558;&#21516;&#19968;&#32423;&#21035;&#30340;&#33410;&#28857;&#36830;&#25509;&#21040;&#19968;&#36215;&#24418;&#25104;&#31070;&#32463;&#27169;&#22359;&#12290;&#25105;&#20204;&#25226;&#25105;&#20204;&#30340;&#27169;&#22411;&#31216;&#20026;YNN&#12290;YNN&#26174;&#33879;&#20419;&#36827;&#20102;&#20449;&#24687;&#20256;&#36755;&#65292;&#26126;&#26174;&#26377;&#21161;&#20110;&#25552;&#39640;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;YNN&#21487;&#20197;&#26356;&#22909;&#22320;&#27169;&#25311;&#31070;&#32463;&#32593;&#32476;&#65292;&#30456;&#27604;&#20854;&#20182;ANN&#26041;&#27861;&#26377;&#30528;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most existing classical artificial neural networks (ANN) are designed as a tree structure to imitate neural networks. In this paper, we argue that the connectivity of a tree is not sufficient to characterize a neural network. The nodes of the same level of a tree cannot be connected with each other, i.e., these neural unit cannot share information with each other, which is a major drawback of ANN. Although ANN has been significantly improved in recent years to more complex structures, such as the directed acyclic graph (DAG), these methods also have unidirectional and acyclic bias for ANN. In this paper, we propose a method to build a bidirectional complete graph for the nodes in the same level of an ANN, which yokes the nodes of the same level to formulate a neural module. We call our model as YNN in short. YNN promotes the information transfer significantly which obviously helps in improving the performance of the method. Our YNN can imitate neural networks much better compared with 
&lt;/p&gt;</description></item><item><title>EPIC&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25554;&#20540;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#22270;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#32534;&#36753;&#36317;&#31163;&#29983;&#25104;&#19982;&#21407;&#22987;&#22270;&#30456;&#20284;&#20294;&#26377;&#32467;&#26500;&#21464;&#21270;&#30340;&#26032;&#22270;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20998;&#31867;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.01310</link><description>&lt;p&gt;
EPIC: &#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#20195;&#20215;&#23454;&#29616;&#30340;&#32534;&#36753;&#36335;&#24452;&#25554;&#20540;&#30340;&#22270;&#24418;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
EPIC: Graph Augmentation with Edit Path Interpolation via Learnable Cost. (arXiv:2306.01310v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01310
&lt;/p&gt;
&lt;p&gt;
EPIC&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25554;&#20540;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#22270;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#32534;&#36753;&#36317;&#31163;&#29983;&#25104;&#19982;&#21407;&#22987;&#22270;&#30456;&#20284;&#20294;&#26377;&#32467;&#26500;&#21464;&#21270;&#30340;&#26032;&#22270;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20998;&#31867;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#20294;&#29616;&#26377;&#22270;&#25968;&#25454;&#38598;&#30340;&#26377;&#38480;&#35268;&#27169;&#21644;&#22810;&#26679;&#24615;&#32463;&#24120;&#38480;&#21046;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EPIC&#65288;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#20195;&#20215;&#23454;&#29616;&#30340;&#32534;&#36753;&#36335;&#24452;&#25554;&#20540;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#25554;&#20540;&#30340;&#22686;&#24378;&#22270;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#22270;&#32534;&#36753;&#36317;&#31163;&#26469;&#29983;&#25104;&#19982;&#21407;&#22987;&#22270;&#30456;&#20284;&#20294;&#32467;&#26500;&#26377;&#25152;&#21464;&#21270;&#30340;&#26032;&#22270;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#24102;&#26631;&#31614;&#30340;&#22270;&#26469;&#23398;&#20064;&#22270;&#32534;&#36753;&#36317;&#31163;&#65292;&#24182;&#21033;&#29992;&#36825;&#19968;&#30693;&#35782;&#22312;&#21407;&#22987;&#22270;&#23545;&#20043;&#38388;&#21019;&#24314;&#20102;&#22270;&#32534;&#36753;&#36335;&#24452;&#12290;&#36890;&#36807;&#20174;&#22270;&#32534;&#36753;&#36335;&#24452;&#20013;&#38543;&#26426;&#25277;&#26679;&#30340;&#22270;&#24418;&#65292;&#25105;&#20204;&#20016;&#23500;&#20102;&#35757;&#32451;&#38598;&#20197;&#22686;&#24378;&#20998;&#31867;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#34920;&#26126;&#23427;&#22312;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#22686;&#24378;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph-based models have become increasingly important in various domains, but the limited size and diversity of existing graph datasets often limit their performance. To address this issue, we propose EPIC (Edit Path Interpolation via learnable Cost), a novel interpolation-based method for augmenting graph datasets. Our approach leverages graph edit distance to generate new graphs that are similar to the original ones but exhibit some variation in their structures. To achieve this, we learn the graph edit distance through a comparison of labeled graphs and utilize this knowledge to create graph edit paths between pairs of original graphs. With randomly sampled graphs from a graph edit path, we enrich the training set to enhance the generalization capability of classification models. We demonstrate the effectiveness of our approach on several benchmark datasets and show that it outperforms existing augmentation methods in graph classification tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.18270</link><description>&lt;p&gt;
&#23398;&#20064;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#27425;(&#24040;&#22823;)&#30340;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning Two-Layer Neural Networks, One (Giant) Step at a Time. (arXiv:2305.18270v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18270
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#30740;&#31350;&#20102;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26377;&#21161;&#20110;&#22312;&#26680;&#24515;&#33539;&#22260;&#20043;&#22806;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#25209;&#37327;&#22823;&#23567;&#21644;&#22810;&#20010;(&#20294;&#26377;&#38480;&#30340;)&#27493;&#39588;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#27493;&#39588;&#36807;&#31243;&#65292;&#21457;&#29616;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#21487;&#20197;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#20294;&#21482;&#36866;&#21512;&#23398;&#20064;&#21333;&#19968;&#26041;&#21521;&#25110;&#21333;&#32034;&#24341;&#27169;&#22411;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;$n=O(d^2)$&#23545;&#20110;&#23398;&#20064;&#22810;&#20010;&#26041;&#21521;&#21644;&#19987;&#19994;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#8220;&#30828;&#8221;&#26041;&#21521;&#32570;&#20047;&#21069;$\ell$&#20010;Hermite&#31995;&#25968;&#65292;&#20173;&#26410;&#34987;&#21457;&#29616;&#65292;&#24182;&#19988;&#38656;&#35201;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d^\ell)$&#25165;&#33021;&#34987;&#26799;&#24230;&#19979;&#38477;&#25429;&#33719;&#12290;&#32463;&#36807;&#20960;&#27425;&#36845;&#20195;&#65292;&#24773;&#20917;&#21457;&#29983;&#21464;&#21270;&#65306;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#36275;&#20197;&#23398;&#20064;&#26032;&#30340;&#30446;&#26631;&#26041;&#21521;&#65292;&#36825;&#20123;&#26041;&#21521;&#22312;Hermite&#22522;&#30784;&#19978;&#32447;&#24615;&#36830;&#25509;&#21040;&#20043;&#21069;&#23398;&#20064;&#30340;&#26041;&#21521;&#25152;&#28085;&#30422;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the training dynamics of shallow neural networks, investigating the conditions under which a limited number of large batch gradient descent steps can facilitate feature learning beyond the kernel regime. We compare the influence of batch size and that of multiple (but finitely many) steps. Our analysis of a single-step process reveals that while a batch size of $n = O(d)$ enables feature learning, it is only adequate for learning a single direction, or a single-index model. In contrast, $n = O(d^2)$ is essential for learning multiple directions and specialization. Moreover, we demonstrate that ``hard'' directions, which lack the first $\ell$ Hermite coefficients, remain unobserved and require a batch size of $n = O(d^\ell)$ for being captured by gradient descent. Upon iterating a few steps, the scenario changes: a batch-size of $n = O(d)$ is enough to learn new target directions spanning the subspace linearly connected in the Hermite basis to the previously learned directions,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#27454;&#21517;&#20026; Torch-Choice &#30340; PyTorch &#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#31649;&#29702;&#25968;&#25454;&#24211;&#12289;&#26500;&#24314;&#22810;&#39033;&#24335;Logit&#21644;&#23884;&#22871;Logit&#27169;&#22411;&#65292;&#24182;&#25903;&#25345;GPU&#21152;&#36895;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.01906</link><description>&lt;p&gt;
Torch-Choice: &#29992;Python&#23454;&#29616;&#22823;&#35268;&#27169;&#36873;&#25321;&#24314;&#27169;&#30340;PyTorch&#21253;
&lt;/p&gt;
&lt;p&gt;
Torch-Choice: A PyTorch Package for Large-Scale Choice Modelling with Python. (arXiv:2304.01906v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#27454;&#21517;&#20026; Torch-Choice &#30340; PyTorch &#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#31649;&#29702;&#25968;&#25454;&#24211;&#12289;&#26500;&#24314;&#22810;&#39033;&#24335;Logit&#21644;&#23884;&#22871;Logit&#27169;&#22411;&#65292;&#24182;&#25903;&#25345;GPU&#21152;&#36895;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
$\texttt{torch-choice}$ &#26159;&#19968;&#27454;&#24320;&#28304;&#36719;&#20214;&#21253;&#65292;&#20351;&#29992;Python&#21644;PyTorch&#23454;&#29616;&#28789;&#27963;&#12289;&#24555;&#36895;&#30340;&#36873;&#25321;&#24314;&#27169;&#12290;&#23427;&#25552;&#20379;&#20102; $\texttt{ChoiceDataset}$ &#25968;&#25454;&#32467;&#26500;&#65292;&#20197;&#20415;&#28789;&#27963;&#32780;&#39640;&#25928;&#22320;&#31649;&#29702;&#25968;&#25454;&#24211;&#12290;&#26412;&#25991;&#28436;&#31034;&#20102;&#22914;&#20309;&#20174;&#21508;&#31181;&#26684;&#24335;&#30340;&#25968;&#25454;&#24211;&#20013;&#26500;&#24314; $\texttt{ChoiceDataset}$&#65292;&#24182;&#23637;&#31034;&#20102; $\texttt{ChoiceDataset}$ &#30340;&#21508;&#31181;&#21151;&#33021;&#12290;&#35813;&#36719;&#20214;&#21253;&#23454;&#29616;&#20102;&#20004;&#31181;&#24120;&#29992;&#30340;&#27169;&#22411;: &#22810;&#39033;&#24335;Logit&#21644;&#23884;&#22871;Logit&#27169;&#22411;&#65292;&#24182;&#25903;&#25345;&#27169;&#22411;&#20272;&#35745;&#26399;&#38388;&#30340;&#27491;&#21017;&#21270;&#12290;&#35813;&#36719;&#20214;&#21253;&#36824;&#25903;&#25345;&#20351;&#29992;GPU&#36827;&#34892;&#20272;&#35745;&#65292;&#20351;&#20854;&#21487;&#20197;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#32780;&#19988;&#22312;&#35745;&#31639;&#19978;&#26356;&#39640;&#25928;&#12290;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;R&#39118;&#26684;&#30340;&#20844;&#24335;&#23383;&#31526;&#20018;&#25110;Python&#23383;&#20856;&#36827;&#34892;&#21021;&#22987;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102; $\texttt{torch-choice}$ &#21644; R&#20013;&#30340; $\texttt{mlogit}$ &#22312;&#20197;&#19979;&#20960;&#20010;&#26041;&#38754;&#30340;&#35745;&#31639;&#25928;&#29575;: (1) &#35266;&#27979;&#25968;&#22686;&#21152;&#26102;&#65292;(2) &#21327;&#21464;&#37327;&#20010;&#25968;&#22686;&#21152;&#26102;&#65292; (3) &#27979;&#35797;&#25968;&#21319;&#39640;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
The $\texttt{torch-choice}$ is an open-source library for flexible, fast choice modeling with Python and PyTorch. $\texttt{torch-choice}$ provides a $\texttt{ChoiceDataset}$ data structure to manage databases flexibly and memory-efficiently. The paper demonstrates constructing a $\texttt{ChoiceDataset}$ from databases of various formats and functionalities of $\texttt{ChoiceDataset}$. The package implements two widely used models, namely the multinomial logit and nested logit models, and supports regularization during model estimation. The package incorporates the option to take advantage of GPUs for estimation, allowing it to scale to massive datasets while being computationally efficient. Models can be initialized using either R-style formula strings or Python dictionaries. We conclude with a comparison of the computational efficiencies of $\texttt{torch-choice}$ and $\texttt{mlogit}$ in R as (1) the number of observations increases, (2) the number of covariates increases, and (3) th
&lt;/p&gt;</description></item></channel></rss>