<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#21033;&#29992;&#21152;&#24615;&#22122;&#22768;&#30340;&#21508;&#21521;&#21516;&#24615;&#20316;&#20026;&#32422;&#26463;&#65292;&#25913;&#36827;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#30495;&#24230;&#65292;&#39564;&#35777;&#23454;&#39564;&#34920;&#26126;&#36825;&#31181;&#32422;&#26463;&#30340;&#25972;&#21512;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.16790</link><description>&lt;p&gt;
Iso-Diffusion: &#20351;&#29992;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#30340;&#21508;&#21521;&#21516;&#24615;&#25913;&#36827;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Iso-Diffusion: Improving Diffusion Probabilistic Models Using the Isotropy of the Additive Gaussian Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16790
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#21152;&#24615;&#22122;&#22768;&#30340;&#21508;&#21521;&#21516;&#24615;&#20316;&#20026;&#32422;&#26463;&#65292;&#25913;&#36827;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#30495;&#24230;&#65292;&#39564;&#35777;&#23454;&#39564;&#34920;&#26126;&#36825;&#31181;&#32422;&#26463;&#30340;&#25972;&#21512;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPMs&#65289;&#22312;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#21462;&#24471;&#20102;&#24456;&#22823;&#25104;&#23601;&#12290;&#23613;&#31649;&#23427;&#20204;&#24615;&#33021;&#24456;&#39640;&#65292;&#20294;&#36824;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#21033;&#29992;&#24378;&#21152;&#32467;&#26500;&#23436;&#25972;&#24615;&#30340;&#32479;&#35745;&#23646;&#24615;&#26469;&#25552;&#39640;&#26679;&#26412;&#20445;&#30495;&#24230;&#65292;&#22914;&#21508;&#21521;&#21516;&#24615;&#12290;&#20165;&#20943;&#23567;&#21152;&#24615;&#21644;&#39044;&#27979;&#22122;&#22768;&#20043;&#38388;&#30340;&#22343;&#26041;&#35823;&#24046;&#24182;&#19981;&#33021;&#24378;&#21152;&#23545;&#39044;&#27979;&#22122;&#22768;&#20026;&#21508;&#21521;&#21516;&#24615;&#30340;&#32422;&#26463;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21463;&#21040;&#21160;&#21147;&#65292;&#21033;&#29992;&#21152;&#24615;&#22122;&#22768;&#30340;&#21508;&#21521;&#21516;&#24615;&#20316;&#20026;&#30446;&#26631;&#20989;&#25968;&#30340;&#32422;&#26463;&#26469;&#22686;&#24378;DDPMs&#30340;&#20445;&#30495;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#31616;&#21333;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;DDPM&#21464;&#20307;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22235;&#20010;&#21512;&#25104;2D&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#20197;&#21450;&#26080;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#27491;&#22914;&#32467;&#26524;&#25152;&#31034;&#65292;&#36825;&#31181;&#32422;&#26463;&#30340;&#25972;&#21512;&#25913;&#21892;&#20102;2D&#25968;&#25454;&#38598;&#30340;&#20445;&#30495;&#24230;&#25351;&#26631;Precision&#21644;Density&#20197;&#21450;&#26080;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16790v1 Announce Type: new  Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have accomplished much in the realm of generative AI. Despite their high performance, there is room for improvement, especially in terms of sample fidelity by utilizing statistical properties that impose structural integrity, such as isotropy. Minimizing the mean squared error between the additive and predicted noise alone does not impose constraints on the predicted noise to be isotropic. Thus, we were motivated to utilize the isotropy of the additive noise as a constraint on the objective function to enhance the fidelity of DDPMs. Our approach is simple and can be applied to any DDPM variant. We validate our approach by presenting experiments conducted on four synthetic 2D datasets as well as on unconditional image generation. As demonstrated by the results, the incorporation of this constraint improves the fidelity metrics, Precision and Density for the 2D datasets as well as for the un
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#30693;&#35782;&#33976;&#39311;&#30340;&#24046;&#20998;&#31169;&#23494;&#31639;&#27861;</title><link>https://arxiv.org/abs/2403.00932</link><description>&lt;p&gt;
&#36890;&#36807;&#21512;&#25104;&#25991;&#26412;&#29983;&#25104;&#30340;&#24046;&#20998;&#31169;&#23494;&#30693;&#35782;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Knowledge Distillation via Synthetic Text Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00932
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#30693;&#35782;&#33976;&#39311;&#30340;&#24046;&#20998;&#31169;&#23494;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#35768;&#22810;&#19981;&#21516;&#30340;&#19979;&#28216;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#38544;&#31169;&#30340;&#22686;&#21152;&#32039;&#36843;&#24615;&#35201;&#27714;LLMs&#22312;&#31169;&#26377;&#25968;&#25454;&#19978;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;(DP)&#36827;&#34892;&#35757;&#32451;&#12290;&#21516;&#26102;&#65292;&#36824;&#38656;&#35201;&#21387;&#32553;LLMs&#20197;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#35774;&#22791;&#25110;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#36827;&#34892;&#30495;&#23454;&#37096;&#32626;&#12290;&#24046;&#20998;&#38544;&#31169;&#21644;&#27169;&#22411;&#21387;&#32553;&#36890;&#24120;&#24517;&#39035;&#22312;&#23454;&#29616;&#20854;&#30446;&#26631;&#30340;&#36807;&#31243;&#20013;&#26435;&#34913;&#25928;&#29992;&#25439;&#22833;&#12290;&#27492;&#22806;&#65292;&#21516;&#26102;&#23454;&#29616;&#36825;&#20004;&#32773;&#21487;&#33021;&#23548;&#33268;&#26356;&#22810;&#30340;&#25928;&#29992;&#25439;&#22833;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24046;&#20998;&#31169;&#23494;&#30693;&#35782;&#33976;&#39311;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;&#30001;&#24046;&#20998;&#31169;&#23494;LLM&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;&#25945;&#24072;&#27169;&#22411;&#30340;&#30693;&#35782;&#20197;&#20004;&#31181;&#26041;&#24335;&#36716;&#31227;&#21040;&#23398;&#29983;&#27169;&#22411;&#19978;&#65306;&#19968;&#31181;&#26159;&#26469;&#33258;&#21512;&#25104;&#25968;&#25454;&#26412;&#36523;&#30340;&#30828;&#26631;&#31614;&#65292;&#21478;&#19968;&#31181;&#26159;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#35780;&#20272;&#30340;&#25945;&#24072;&#27169;&#22411;&#30340;&#36755;&#20986;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00932v1 Announce Type: cross  Abstract: Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy requires LLMs to train with Differential Privacy (DP) on private data. Concurrently it is also necessary to compress LLMs for real-life deployments on resource-constrained devices or latency-sensitive applications. Differential privacy and model compression generally must trade off utility loss to achieve their objectives. Moreover, concurrently achieving both can result in even more utility loss. To this end, we propose a novel differentially private knowledge distillation algorithm that exploits synthetic data generated by a differentially private LLM. The knowledge of a teacher model is transferred onto the student in two ways: one way from the synthetic data itself, the hard labels, and the other way by the output distribution of the teacher model evaluated on the synthetic data
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#19979;&#30340;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#36817;&#20284;&#36807;&#31243;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#31639;&#27861;&#34920;&#29616;&#20248;&#31168;&#12290;</title><link>http://arxiv.org/abs/2307.03034</link><description>&lt;p&gt;
&#24102;&#26377;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#30340;&#19981;&#23433;&#23450;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;
&lt;/p&gt;
&lt;p&gt;
PCL-Indexability and Whittle Index for Restless Bandits with General Observation Models. (arXiv:2307.03034v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#19979;&#30340;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#36817;&#20284;&#36807;&#31243;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#31639;&#27861;&#34920;&#29616;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#65292;&#29992;&#20110;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#30001;&#20110;&#36164;&#28304;&#32422;&#26463;&#25110;&#29615;&#22659;&#25110;&#22266;&#26377;&#22122;&#22768;&#65292;&#29609;&#23478;&#25805;&#20316;&#38656;&#35201;&#22522;&#20110;&#26576;&#31181;&#26377;&#35823;&#24046;&#30340;&#21453;&#39304;&#26426;&#21046;&#12290;&#36890;&#36807;&#24314;&#31435;&#21453;&#39304;/&#35266;&#27979;&#21160;&#21147;&#23398;&#30340;&#19968;&#33324;&#27010;&#29575;&#27169;&#22411;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#34920;&#36848;&#20026;&#19968;&#20010;&#20174;&#20219;&#24847;&#21021;&#22987;&#20449;&#24565;&#65288;&#20808;&#39564;&#20449;&#24687;&#65289;&#24320;&#22987;&#30340;&#20855;&#26377;&#21487;&#25968;&#20449;&#24565;&#29366;&#24577;&#31354;&#38388;&#30340;&#19981;&#23433;&#23450;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#21033;&#29992;&#20855;&#26377;&#37096;&#20998;&#23432;&#24658;&#23450;&#24459;&#65288;PCL&#65289;&#30340;&#21487;&#23454;&#29616;&#21306;&#22495;&#26041;&#27861;&#65292;&#20998;&#26512;&#20102;&#26080;&#38480;&#29366;&#24577;&#38382;&#39064;&#30340;&#21487;&#32034;&#24341;&#24615;&#21644;&#20248;&#20808;&#32423;&#32034;&#24341;&#65288;Whittle&#32034;&#24341;&#65289;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#36807;&#31243;&#65292;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#20197;&#24212;&#29992;Ni&#241;o-Mora&#21644;Bertsimas&#38024;&#23545;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#30340;AG&#31639;&#27861;&#30340;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider a general observation model for restless multi-armed bandit problems. The operation of the player needs to be based on certain feedback mechanism that is error-prone due to resource constraints or environmental or intrinsic noises. By establishing a general probabilistic model for dynamics of feedback/observation, we formulate the problem as a restless bandit with a countable belief state space starting from an arbitrary initial belief (a priori information). We apply the achievable region method with partial conservation law (PCL) to the infinite-state problem and analyze its indexability and priority index (Whittle index). Finally, we propose an approximation process to transform the problem into which the AG algorithm of Ni\~no-Mora and Bertsimas for finite-state problems can be applied to. Numerical experiments show that our algorithm has an excellent performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2305.15786</link><description>&lt;p&gt;
&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#30340;&#29702;&#35770;&#20445;&#35777;&#21450;&#20854;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting. (arXiv:2305.15786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#21512;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#24037;&#20855;&#20043;&#19968;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#26377;&#25928;&#22320;&#20943;&#23569;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#38024;&#23545;&#40657;&#30418;&#22522;&#23398;&#20064;&#22120;&#30340;&#22823;&#22810;&#25968;&#38598;&#21512;&#26041;&#27861;&#37117;&#23646;&#20110;&#8220;&#21472;&#21152;&#27867;&#21270;&#8221;&#33539;&#30068;&#65292;&#21363;&#35757;&#32451;&#19968;&#20010;&#25509;&#21463;&#22522;&#23398;&#20064;&#22120;&#25512;&#29702;&#20316;&#20026;&#36755;&#20837;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#34429;&#28982;&#21472;&#21152;&#27867;&#21270;&#22312;&#23454;&#36341;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#20173;&#28982;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#8220;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#8221;&#21472;&#21152;&#27867;&#21270;&#20013;&#30340;&#26368;&#20339;&#21472;&#21152;&#27867;&#21270;&#24182;&#19981;&#27604;&#26368;&#20248;&#35299;&#34920;&#29616;&#8220;&#24046;&#24471;&#22810;&#8221;&#12290;&#36825;&#19968;&#32467;&#26524;&#21152;&#24378;&#21644;&#22823;&#22823;&#25193;&#23637;&#20102;Van der Laan&#31561;&#20154;&#65288;2007&#24180;&#65289;&#30340;&#32467;&#26524;&#12290;&#21463;&#21040;&#29702;&#35770;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#27010;&#29575;&#39044;&#27979;&#30340;&#32972;&#26223;&#19979;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#19981;&#21516;&#25935;&#24863;&#24615;&#30340;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling is among the most popular tools in machine learning (ML) due to its effectiveness in minimizing variance and thus improving generalization. Most ensembling methods for black-box base learners fall under the umbrella of "stacked generalization," namely training an ML algorithm that takes the inferences from the base learners as input. While stacking has been widely applied in practice, its theoretical properties are poorly understood. In this paper, we prove a novel result, showing that choosing the best stacked generalization from a (finite or finite-dimensional) family of stacked generalizations based on cross-validated performance does not perform "much worse" than the oracle best. Our result strengthens and significantly extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis, we further propose a particular family of stacked generalizations in the context of probabilistic forecasting, each one with a different sensitivity for how much the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#22312;&#31038;&#20132;&#23186;&#20307;&#20013;&#26816;&#27979;&#25233;&#37057;&#30151;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21019;&#26032;&#22320;&#26816;&#27979;&#21644;&#35299;&#37322;&#25233;&#37057;&#30151;&#29366;&#21450;&#20854;&#25345;&#32493;&#26102;&#38388;&#65292;&#24182;&#36890;&#36807;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#21457;&#29616;&#20102;&#26032;&#30340;&#26410;&#27880;&#24847;&#21040;&#30340;&#30151;&#29366;&#12290;</title><link>http://arxiv.org/abs/2305.13127</link><description>&lt;p&gt;
&#20160;&#20040;&#30151;&#29366;&#20197;&#21450;&#25345;&#32493;&#22810;&#20037;&#65311;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#29992;&#20110;&#31038;&#20132;&#23186;&#20307;&#20013;&#30340;&#25233;&#37057;&#30151;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media. (arXiv:2305.13127v2 [q-bio.QM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#22312;&#31038;&#20132;&#23186;&#20307;&#20013;&#26816;&#27979;&#25233;&#37057;&#30151;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21019;&#26032;&#22320;&#26816;&#27979;&#21644;&#35299;&#37322;&#25233;&#37057;&#30151;&#29366;&#21450;&#20854;&#25345;&#32493;&#26102;&#38388;&#65292;&#24182;&#36890;&#36807;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#21457;&#29616;&#20102;&#26032;&#30340;&#26410;&#27880;&#24847;&#21040;&#30340;&#30151;&#29366;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25233;&#37057;&#30151;&#26159;&#26368;&#24120;&#35265;&#21644;&#20005;&#37325;&#30340;&#31934;&#31070;&#30142;&#30149;&#65292;&#24341;&#21457;&#20102;&#20005;&#37325;&#30340;&#32463;&#27982;&#21644;&#31038;&#20250;&#24433;&#21709;&#12290;&#25233;&#37057;&#30151;&#30340;&#26816;&#27979;&#23545;&#20110;&#26089;&#26399;&#24178;&#39044;&#20197;&#20943;&#36731;&#36825;&#20123;&#21518;&#26524;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#31181;&#39640;&#39118;&#38505;&#30340;&#20915;&#31574;&#26412;&#36136;&#19978;&#38656;&#35201;&#21487;&#35299;&#37322;&#24615;&#12290;&#34429;&#28982;&#26377;&#19968;&#20123;&#25233;&#37057;&#30151;&#26816;&#27979;&#30740;&#31350;&#35797;&#22270;&#22522;&#20110;&#37325;&#35201;&#24615;&#20998;&#25968;&#25110;&#20851;&#27880;&#26435;&#37325;&#35299;&#37322;&#20915;&#31574;&#65292;&#20294;&#36825;&#20123;&#35299;&#37322;&#19982;&#20020;&#24202;&#25233;&#37057;&#30151;&#35786;&#26029;&#26631;&#20934;&#19981;&#19968;&#33268;&#65292;&#21518;&#32773;&#22522;&#20110;&#25233;&#37057;&#30151;&#29366;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#36981;&#24490;&#35745;&#31639;&#35774;&#35745;&#31185;&#23398;&#33539;&#24335;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#23610;&#24230;&#26102;&#38388;&#21407;&#22411;&#32593;&#32476;(MSTPNet)&#12290;MSTPNet&#21019;&#26032;&#22320;&#26816;&#27979;&#21644;&#35299;&#37322;&#25233;&#37057;&#30151;&#29366;&#21450;&#20854;&#25345;&#32493;&#26102;&#38388;&#12290;&#20351;&#29992;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#36827;&#34892;&#28145;&#20837;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;MSTPNet&#22312;F1&#20998;&#25968;0.851&#19978;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#25233;&#37057;&#30151;&#26816;&#27979;&#26041;&#27861;&#12290;&#36825;&#20010;&#32467;&#26524;&#36824;&#25581;&#31034;&#20102;&#26410;&#22312;&#35843;&#26597;&#26041;&#27861;&#20013;&#27880;&#24847;&#21040;&#30340;&#26032;&#30151;&#29366;&#65292;&#20363;&#22914;&#20998;&#20139;&#12290;
&lt;/p&gt;
&lt;p&gt;
Depression is the most prevalent and serious mental illness, which induces grave financial and societal ramifications. Depression detection is key for early intervention to mitigate those consequences. Such a high-stake decision inherently necessitates interpretability. Although a few depression detection studies attempt to explain the decision based on the importance score or attention weights, these explanations misalign with the clinical depression diagnosis criterion that is based on depressive symptoms. To fill this gap, we follow the computational design science paradigm to develop a novel Multi-Scale Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and interprets depressive symptoms as well as how long they last. Extensive empirical analyses using a large-scale dataset show that MSTPNet outperforms state-of-the-art depression detection methods with an F1-score of 0.851. This result also reveals new symptoms that are unnoted in the survey approach, such as shari
&lt;/p&gt;</description></item></channel></rss>