<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#26377;&#38480;&#25968;&#25454;&#37327;&#22238;&#31572;&#31639;&#27861;&#24615;&#33021;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#40657;&#30418;&#27979;&#35797;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#22238;&#31572;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;&#38598;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#21644;&#29305;&#23450;&#27169;&#22411;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.07388</link><description>&lt;p&gt;
&#26080;&#20551;&#35774;&#27979;&#35797;&#31639;&#27861;&#24615;&#33021;&#30340;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
The Limits of Assumption-free Tests for Algorithm Performance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07388
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#26377;&#38480;&#25968;&#25454;&#37327;&#22238;&#31572;&#31639;&#27861;&#24615;&#33021;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#40657;&#30418;&#27979;&#35797;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#22238;&#31572;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;&#38598;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#21644;&#29305;&#23450;&#27169;&#22411;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#35780;&#20215;&#21644;&#27604;&#36739;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#22522;&#26412;&#30340;&#38382;&#39064;&#65292;&#19968;&#20010;&#31639;&#27861;&#22312;&#32473;&#23450;&#30340;&#24314;&#27169;&#20219;&#21153;&#20013;&#34920;&#29616;&#22914;&#20309;&#65292;&#21738;&#20010;&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#65311;&#35768;&#22810;&#26041;&#27861;&#24050;&#32463;&#24320;&#21457;&#20986;&#26469;&#35780;&#20272;&#31639;&#27861;&#24615;&#33021;&#65292;&#36890;&#24120;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#31574;&#30053;&#65292;&#23558;&#24863;&#20852;&#36259;&#30340;&#31639;&#27861;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#23376;&#38598;&#19978;&#37325;&#26032;&#35757;&#32451;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#30041;&#20986;&#25968;&#25454;&#28857;&#19978;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#24191;&#27867;&#20351;&#29992;&#36825;&#20123;&#31243;&#24207;&#65292;&#20294;&#23545;&#20110;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#26377;&#38480;&#30340;&#25968;&#25454;&#37327;&#19979;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#30340;&#19968;&#20123;&#22522;&#26412;&#38480;&#21046;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21306;&#20998;&#20102;&#20004;&#20010;&#38382;&#39064;: &#31639;&#27861;$A$&#22312;&#22823;&#23567;&#20026;$n$&#30340;&#35757;&#32451;&#38598;&#19978;&#23398;&#20064;&#38382;&#39064;&#26377;&#22810;&#22909;&#65292;&#20197;&#21450;&#22312;&#29305;&#23450;&#22823;&#23567;&#20026;$n$&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;$A$&#25152;&#20135;&#29983;&#30340;&#29305;&#23450;&#25311;&#21512;&#27169;&#22411;&#26377;&#22810;&#22909;&#65311;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#35777;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#23558;&#31639;&#27861;&#35270;&#20026;&#40657;&#30418;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#26080;&#27861;&#20934;&#30830;&#22320;&#22238;&#31572;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithm evaluation and comparison are fundamental questions in machine learning and statistics -- how well does an algorithm perform at a given modeling task, and which algorithm performs best? Many methods have been developed to assess algorithm performance, often based around cross-validation type strategies, retraining the algorithm of interest on different subsets of the data and assessing its performance on the held-out data points. Despite the broad use of such procedures, the theoretical properties of these methods are not yet fully understood. In this work, we explore some fundamental limits for answering these questions with limited amounts of data. In particular, we make a distinction between two questions: how good is an algorithm $A$ at the problem of learning from a training set of size $n$, versus, how good is a particular fitted model produced by running $A$ on a particular training data set of size $n$?   Our main results prove that, for any test that treats the algor
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AT-PINNs&#30340;&#23545;&#25239;&#35757;&#32451;&#31574;&#30053;&#65292;&#36890;&#36807;&#23545;&#25239;&#26679;&#26412;&#30340;&#24494;&#35843;&#26469;&#22686;&#24378;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#36827;&#34892;&#20855;&#26377;&#26102;&#38388;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2310.11789</link><description>&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#30340;&#23545;&#25239;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Adversarial Training for Physics-Informed Neural Networks. (arXiv:2310.11789v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11789
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AT-PINNs&#30340;&#23545;&#25239;&#35757;&#32451;&#31574;&#30053;&#65292;&#36890;&#36807;&#23545;&#25239;&#26679;&#26412;&#30340;&#24494;&#35843;&#26469;&#22686;&#24378;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#36827;&#34892;&#20855;&#26377;&#26102;&#38388;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#19978;&#26174;&#31034;&#20986;&#24040;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#19981;&#36275;&#30340;&#40065;&#26834;&#24615;&#65292;&#26222;&#36890;&#30340;PINNs&#22312;&#35299;&#20915;&#28041;&#21450;&#22810;&#23610;&#24230;&#34892;&#20026;&#25110;&#20855;&#26377;&#23574;&#38160;&#25110;&#25391;&#33633;&#29305;&#24449;&#30340;&#22797;&#26434;PDE&#26102;&#32463;&#24120;&#38754;&#20020;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#22522;&#20110;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#23545;&#25239;&#25915;&#20987;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#25239;&#35757;&#32451;&#31574;&#30053;&#65292;&#34987;&#31216;&#20026;AT-PINNs&#12290;AT-PINNs&#36890;&#36807;&#23545;&#25239;&#26679;&#26412;&#30340;&#24494;&#35843;&#26469;&#22686;&#24378;PINNs&#30340;&#40065;&#26834;&#24615;&#65292;&#21487;&#20197;&#20934;&#30830;&#35782;&#21035;&#27169;&#22411;&#22833;&#25928;&#20301;&#32622;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#24341;&#23548;&#27169;&#22411;&#19987;&#27880;&#20110;&#36825;&#20123;&#21306;&#22495;&#12290;AT-PINNs&#36824;&#21487;&#20197;&#36890;&#36807;&#36873;&#25321;&#22260;&#32469;&#26102;&#38388;&#21021;&#22987;&#20540;&#30340;&#21021;&#22987;&#25311;&#21512;&#28857;&#26469;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#12290;&#25105;&#20204;&#23558;AT-PINNs&#24212;&#29992;&#20110;&#20855;&#26377;&#22810;&#23610;&#24230;&#31995;&#25968;&#30340;&#26925;&#22278;&#26041;&#31243;&#12289;&#20855;&#26377;&#22810;&#23792;&#35299;&#30340;&#27850;&#26494;&#26041;&#31243;&#12289;&#20855;&#26377;&#23574;&#38160;&#35299;&#30340;Burgers&#26041;&#31243;&#20197;&#21450;Allen-Cahn&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks have shown great promise in solving partial differential equations. However, due to insufficient robustness, vanilla PINNs often face challenges when solving complex PDEs, especially those involving multi-scale behaviors or solutions with sharp or oscillatory characteristics. To address these issues, based on the projected gradient descent adversarial attack, we proposed an adversarial training strategy for PINNs termed by AT-PINNs. AT-PINNs enhance the robustness of PINNs by fine-tuning the model with adversarial samples, which can accurately identify model failure locations and drive the model to focus on those regions during training. AT-PINNs can also perform inference with temporal causality by selecting the initial collocation points around temporal initial values. We implement AT-PINNs to the elliptic equation with multi-scale coefficients, Poisson equation with multi-peak solutions, Burgers equation with sharp solutions and the Allen-Cahn equati
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#36229;&#22768;&#22270;&#20687;&#20013;&#32467;&#33410;&#24322;&#36136;&#22806;&#35266;&#23548;&#33268;&#30340;&#38590;&#20197;&#36827;&#34892;&#36880;&#20010;&#32467;&#33410;&#26816;&#26597;&#30340;&#38382;&#39064;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#32467;&#33410;&#37325;&#26032;&#35782;&#21035;&#31995;&#32479;&#65292;&#22312;&#25968;&#30334;&#20010;&#20083;&#33146;&#36229;&#22768;&#35270;&#39057;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.06339</link><description>&lt;p&gt;
&#33258;&#21160;&#35782;&#21035;&#21644;&#21306;&#20998;&#36229;&#22768;&#35270;&#39057;&#20013;&#30340;&#32467;&#33410;&#65292;&#20197;&#20415;&#36827;&#34892;&#36880;&#32467;&#33410;&#26816;&#26597;
&lt;/p&gt;
&lt;p&gt;
Automatic nodule identification and differentiation in ultrasound videos to facilitate per-nodule examination. (arXiv:2310.06339v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#36229;&#22768;&#22270;&#20687;&#20013;&#32467;&#33410;&#24322;&#36136;&#22806;&#35266;&#23548;&#33268;&#30340;&#38590;&#20197;&#36827;&#34892;&#36880;&#20010;&#32467;&#33410;&#26816;&#26597;&#30340;&#38382;&#39064;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#32467;&#33410;&#37325;&#26032;&#35782;&#21035;&#31995;&#32479;&#65292;&#22312;&#25968;&#30334;&#20010;&#20083;&#33146;&#36229;&#22768;&#35270;&#39057;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22768;&#26159;&#20581;&#24247;&#31579;&#26597;&#20013;&#37325;&#35201;&#30340;&#35786;&#26029;&#25216;&#26415;&#65292;&#20855;&#26377;&#26080;&#21019;&#12289;&#32463;&#27982;&#12289;&#26080;&#36752;&#23556;&#31561;&#20248;&#28857;&#65292;&#22240;&#27492;&#22312;&#32467;&#33410;&#30340;&#35786;&#26029;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#36229;&#22768;&#22270;&#20687;&#20013;&#65292;&#21333;&#20010;&#32467;&#33410;&#22312;&#19981;&#21516;&#30340;&#20999;&#38754;&#35270;&#22270;&#19979;&#21487;&#33021;&#21576;&#29616;&#20986;&#24322;&#36136;&#30340;&#22806;&#35266;&#65292;&#36825;&#20351;&#24471;&#36880;&#20010;&#32467;&#33410;&#26816;&#26597;&#21464;&#24471;&#22256;&#38590;&#12290;&#36229;&#22768;&#26816;&#26597;&#36890;&#24120;&#20381;&#36182;&#20110;&#36229;&#22768;&#24072;&#30340;&#19987;&#19994;&#30693;&#35782;&#21644;&#20020;&#24202;&#32463;&#39564;&#12290;&#36229;&#22768;&#24072;&#36890;&#24120;&#36890;&#36807;&#26816;&#26597;&#32467;&#33410;&#29305;&#24449;&#21644;&#21608;&#22260;&#32467;&#26500;&#65288;&#22914;&#33146;&#20307;&#21644;&#23548;&#31649;&#65289;&#26469;&#21306;&#20998;&#19981;&#21516;&#30340;&#32467;&#33410;&#65292;&#36825;&#26159;&#32321;&#29712;&#19988;&#32791;&#26102;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#25968;&#30334;&#20010;&#20083;&#33146;&#36229;&#22768;&#35270;&#39057;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#32467;&#33410;&#37325;&#26032;&#35782;&#21035;&#31995;&#32479;&#65292;&#21253;&#25324;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25552;&#21462;&#22120;&#65292;&#21487;&#20197;&#20174;&#36755;&#20837;&#35270;&#39057;&#29255;&#27573;&#20013;&#25552;&#21462;&#29305;&#24449;&#21521;&#37327;&#65292;&#20197;&#21450;&#23454;&#26102;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#23558;&#29305;&#24449;&#21521;&#37327;&#25353;&#32467;&#33410;&#20998;&#32452;&#12290;&#35813;&#31995;&#32479;&#33719;&#24471;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ultrasound is a vital diagnostic technique in health screening, with the advantages of non-invasive, cost-effective, and radiation free, and therefore is widely applied in the diagnosis of nodules. However, it relies heavily on the expertise and clinical experience of the sonographer. In ultrasound images, a single nodule might present heterogeneous appearances in different cross-sectional views which makes it hard to perform per-nodule examination. Sonographers usually discriminate different nodules by examining the nodule features and the surrounding structures like gland and duct, which is cumbersome and time-consuming. To address this problem, we collected hundreds of breast ultrasound videos and built a nodule reidentification system that consists of two parts: an extractor based on the deep learning model that can extract feature vectors from the input video clips and a real-time clustering algorithm that automatically groups feature vectors by nodules. The system obtains satisfa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#20197;&#21450;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#30340;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#39044;&#27979;&#21644;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2307.08038</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind Fields. (arXiv:2307.08038v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08038
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#20197;&#21450;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#30340;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#39044;&#27979;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#39118;&#22330;&#25968;&#25454;&#23545;&#20110;&#27668;&#20505;&#12289;&#28023;&#27915;&#21644;&#27668;&#35937;&#30740;&#31350;&#20013;&#30340;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#20110;&#39118;&#25968;&#25454;&#24448;&#24448;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#39640;&#31354;&#38388;&#21464;&#24322;&#24615;&#21644;&#24322;&#36136;&#24615;&#65292;&#22240;&#27492;&#23545;&#20855;&#26377;&#20004;&#20010;&#32500;&#24230;&#36895;&#24230;&#30340;&#21452;&#21464;&#37327;&#39118;&#22330;&#36827;&#34892;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#25110;&#19979;&#32553;&#25918;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#31354;&#38388;&#32479;&#35745;&#23398;&#20013;&#65292;&#24120;&#29992;cokriging&#26469;&#39044;&#27979;&#21452;&#21464;&#37327;&#31354;&#38388;&#22330;&#12290;&#28982;&#32780;&#65292;cokriging&#39044;&#27979;&#22120;&#38500;&#20102;&#23545;&#39640;&#26031;&#36807;&#31243;&#26377;&#25928;&#22806;&#65292;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;cokriging&#35745;&#31639;&#37327;&#24040;&#22823;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#26159;&#19968;&#20010;&#30001;&#31354;&#38388;&#24452;&#21521;&#22522;&#20989;&#25968;&#26500;&#24314;&#30340;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#65292;&#29992;&#20110;&#21452;&#21464;&#37327;&#31354;&#38388;&#25968;&#25454;&#39044;&#27979;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#30340;cokriging&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
High spatial resolution wind data are essential for a wide range of applications in climate, oceanographic and meteorological studies. Large-scale spatial interpolation or downscaling of bivariate wind fields having velocity in two dimensions is a challenging task because wind data tend to be non-Gaussian with high spatial variability and heterogeneity. In spatial statistics, cokriging is commonly used for predicting bivariate spatial fields. However, the cokriging predictor is not optimal except for Gaussian processes. Additionally, cokriging is computationally prohibitive for large datasets. In this paper, we propose a method, called bivariate DeepKriging, which is a spatially dependent deep neural network (DNN) with an embedding layer constructed by spatial radial basis functions for bivariate spatial data prediction. We then develop a distribution-free uncertainty quantification method based on bootstrap and ensemble DNN. Our proposed approach outperforms the traditional cokriging 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20102;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#36845;&#20195;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.11497</link><description>&lt;p&gt;
&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#24120;&#27493;&#38271;SGD&#30340;&#25910;&#25947;&#21644;&#38598;&#20013;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Convergence and concentration properties of constant step-size SGD through Markov chains. (arXiv:2306.11497v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20102;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#36845;&#20195;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20248;&#21270;&#24179;&#28369;&#19988;&#24378;&#20984;&#30340;&#30446;&#26631;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20854;&#24615;&#36136;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#36731;&#24494;&#21463;&#25511;&#26041;&#24046;&#30340;&#26080;&#20559;&#26799;&#24230;&#20272;&#35745;&#65292;&#36845;&#20195;&#20197;&#24635;&#21464;&#24046;&#36317;&#31163;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#22312;&#19982;&#20197;&#21069;&#24037;&#20316;&#30456;&#27604;&#26799;&#24230;&#22122;&#22768;&#20998;&#24067;&#30340;&#25918;&#23485;&#20551;&#35774;&#19979;&#65292;&#22312;Wasserstein-2&#36317;&#31163;&#19979;&#24314;&#31435;&#20102;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;&#30001;&#20110;&#26497;&#38480;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#36136;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#36825;&#20123;&#23545;&#20110;&#26799;&#24230;&#25104;&#31435;&#26102;&#65292;&#21518;&#32773;&#32487;&#25215;&#20102;&#20122;&#39640;&#26031;&#25110;&#20122;&#25351;&#25968;&#27987;&#24230;&#29305;&#24615;&#12290;&#36825;&#20801;&#35768;&#25512;&#23548;&#20986;&#23545;&#20110;&#26368;&#32456;&#20272;&#35745;&#30340;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;&#26368;&#21518;&#65292;&#22312;&#36825;&#31181;&#26465;&#20214;&#19979;&#65292;&#22312;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;Polyak-Ruppert&#24207;&#21015;&#30340;&#23614;&#37096;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#26080;&#32500;&#24230;&#20559;&#24046;&#38480;&#21046;&#12290;&#25152;&#26377;&#32467;&#26524;&#22343;&#20026;&#38750;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#21518;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the optimization of a smooth and strongly convex objective using constant step-size stochastic gradient descent (SGD) and study its properties through the prism of Markov chains. We show that, for unbiased gradient estimates with mildly controlled variance, the iteration converges to an invariant distribution in total variation distance. We also establish this convergence in Wasserstein-2 distance under a relaxed assumption on the gradient noise distribution compared to previous work. Thanks to the invariance property of the limit distribution, our analysis shows that the latter inherits sub-Gaussian or sub-exponential concentration properties when these hold true for the gradient. This allows the derivation of high-confidence bounds for the final estimate. Finally, under such conditions in the linear case, we obtain a dimension-free deviation bound for the Polyak-Ruppert average of a tail sequence. All our results are non-asymptotic and their consequences are discussed thr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.00833</link><description>&lt;p&gt;
&#33258;&#19979;&#32780;&#19978;&#20309;&#26102;&#20987;&#36133;&#33258;&#19978;&#32780;&#19979;&#36827;&#34892;&#20998;&#23618;&#31038;&#21306;&#26816;&#27979;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Bottom-up Beat Top-down in Hierarchical Community Detection?. (arXiv:2306.00833v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#30340;&#20998;&#23618;&#32858;&#31867;&#26159;&#25351;&#26597;&#25214;&#19968;&#32452;&#31038;&#21306;&#30340;&#26641;&#24418;&#32467;&#26500;&#65292;&#20854;&#20013;&#23618;&#27425;&#32467;&#26500;&#30340;&#36739;&#20302;&#32423;&#21035;&#26174;&#31034;&#26356;&#32454;&#31890;&#24230;&#30340;&#31038;&#21306;&#32467;&#26500;&#12290;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#31639;&#27861;&#26377;&#20004;&#20010;&#20027;&#35201;&#31867;&#21035;&#65306;&#33258;&#19978;&#32780;&#19979;&#30340;&#31639;&#27861;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#31639;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;&#20998;&#23618;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#36825;&#31181;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#22312;&#23618;&#27425;&#32467;&#26500;&#30340;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#24674;&#22797;&#26465;&#20214;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#33258;&#19978;&#32780;&#19979;&#31639;&#27861;&#30340;&#26465;&#20214;&#26469;&#35828;&#65292;&#38480;&#21046;&#26356;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hierarchical clustering of networks consists in finding a tree of communities, such that lower levels of the hierarchy reveal finer-grained community structures. There are two main classes of algorithms tackling this problem. Divisive ($\textit{top-down}$) algorithms recursively partition the nodes into two communities, until a stopping rule indicates that no further split is needed. In contrast, agglomerative ($\textit{bottom-up}$) algorithms first identify the smallest community structure and then repeatedly merge the communities using a $\textit{linkage}$ method. In this article, we establish theoretical guarantees for the recovery of the hierarchical tree and community structure of a Hierarchical Stochastic Block Model by a bottom-up algorithm. We also establish that this bottom-up algorithm attains the information-theoretic threshold for exact recovery at intermediate levels of the hierarchy. Notably, these recovery conditions are less restrictive compared to those existing for to
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;Matroid&#32422;&#26463;&#19979;&#27969;&#24335;&#23376;&#27169;&#26368;&#22823;&#21270;&#20013;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#27969;&#24335;&#31639;&#27861;&#21644;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#26469;&#26435;&#34913;&#25928;&#29575;&#12289;&#36136;&#37327;&#21644;&#20844;&#24179;&#24615;&#65292;&#24182;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.15118</link><description>&lt;p&gt;
&#22312;&#19968;&#20010;Matroid&#32422;&#26463;&#19979;&#27969;&#24335;&#23376;&#27169;&#26368;&#22823;&#21270;&#20013;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fairness in Streaming Submodular Maximization over a Matroid Constraint. (arXiv:2305.15118v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15118
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;Matroid&#32422;&#26463;&#19979;&#27969;&#24335;&#23376;&#27169;&#26368;&#22823;&#21270;&#20013;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#27969;&#24335;&#31639;&#27861;&#21644;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#26469;&#26435;&#34913;&#25928;&#29575;&#12289;&#36136;&#37327;&#21644;&#20844;&#24179;&#24615;&#65292;&#24182;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24335;&#23376;&#27169;&#26368;&#22823;&#21270;&#26159;&#20174;&#19968;&#20010;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#36873;&#25321;&#19968;&#20010;&#20195;&#34920;&#24615;&#23376;&#38598;&#30340;&#33258;&#28982;&#27169;&#22411;&#12290;&#22914;&#26524;&#25968;&#25454;&#28857;&#20855;&#26377;&#25935;&#24863;&#23646;&#24615;&#65292;&#22914;&#24615;&#21035;&#25110;&#31181;&#26063;&#65292;&#24378;&#21046;&#20844;&#24179;&#24615;&#20197;&#36991;&#20813;&#20559;&#35265;&#21644;&#27495;&#35270;&#21464;&#24471;&#37325;&#35201;&#12290;&#36825;&#24341;&#36215;&#20102;&#23545;&#24320;&#21457;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26497;&#22823;&#20852;&#36259;&#12290;&#26368;&#36817;&#65292;&#36825;&#26679;&#30340;&#31639;&#27861;&#24050;&#32463;&#34987;&#24320;&#21457;&#29992;&#20110;&#22522;&#20110;&#22522;&#25968;&#32422;&#26463;&#30340;&#21333;&#35843;&#23376;&#27169;&#26368;&#22823;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#33258;&#28982;&#25512;&#24191;&#21040;&#19968;&#20010;Matroid&#32422;&#26463;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#27969;&#24335;&#31639;&#27861;&#20197;&#21450;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#36825;&#20123;&#32467;&#26524;&#22312;&#25928;&#29575;&#12289;&#36136;&#37327;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#25552;&#20379;&#20102;&#26435;&#34913;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#30693;&#21517;&#30340;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#23545;&#25105;&#20204;&#30340;&#21457;&#29616;&#36827;&#34892;&#20102;&#32463;&#39564;&#35777;&#23454;&#65306;&#22522;&#20110;&#31034;&#20363;&#30340;&#32858;&#31867;&#12289;&#30005;&#24433;&#25512;&#33616;&#21644;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#26368;&#22823;&#35206;&#30422;&#12290;
&lt;/p&gt;
&lt;p&gt;
Streaming submodular maximization is a natural model for the task of selecting a representative subset from a large-scale dataset. If datapoints have sensitive attributes such as gender or race, it becomes important to enforce fairness to avoid bias and discrimination. This has spurred significant interest in developing fair machine learning algorithms. Recently, such algorithms have been developed for monotone submodular maximization under a cardinality constraint.  In this paper, we study the natural generalization of this problem to a matroid constraint. We give streaming algorithms as well as impossibility results that provide trade-offs between efficiency, quality and fairness. We validate our findings empirically on a range of well-known real-world applications: exemplar-based clustering, movie recommendation, and maximum coverage in social networks.
&lt;/p&gt;</description></item><item><title>VeML&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#22823;&#35268;&#27169;&#39640;&#32500;&#25968;&#25454;&#30340;&#31471;&#21040;&#31471;&#26426;&#22120;&#23398;&#20064;&#29983;&#21629;&#21608;&#26399;&#30340;&#29256;&#26412;&#31649;&#29702;&#31995;&#32479;&#65292;&#22312;&#35299;&#20915;&#29983;&#21629;&#21608;&#26399;&#39640;&#25104;&#26412;&#38382;&#39064;&#12289;&#25968;&#25454;&#30456;&#20284;&#24615;&#35745;&#31639;&#21644;&#25968;&#25454;&#27169;&#24335;&#20998;&#26512;&#31561;&#20851;&#38190;&#38382;&#39064;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2304.13037</link><description>&lt;p&gt;
VeML&#65306;&#22823;&#35268;&#27169;&#39640;&#32500;&#25968;&#25454;&#30340;&#31471;&#21040;&#31471;&#26426;&#22120;&#23398;&#20064;&#29983;&#21629;&#21608;&#26399;
&lt;/p&gt;
&lt;p&gt;
VeML: An End-to-End Machine Learning Lifecycle for Large-scale and High-dimensional Data. (arXiv:2304.13037v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13037
&lt;/p&gt;
&lt;p&gt;
VeML&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#22823;&#35268;&#27169;&#39640;&#32500;&#25968;&#25454;&#30340;&#31471;&#21040;&#31471;&#26426;&#22120;&#23398;&#20064;&#29983;&#21629;&#21608;&#26399;&#30340;&#29256;&#26412;&#31649;&#29702;&#31995;&#32479;&#65292;&#22312;&#35299;&#20915;&#29983;&#21629;&#21608;&#26399;&#39640;&#25104;&#26412;&#38382;&#39064;&#12289;&#25968;&#25454;&#30456;&#20284;&#24615;&#35745;&#31639;&#21644;&#25968;&#25454;&#27169;&#24335;&#20998;&#26512;&#31561;&#20851;&#38190;&#38382;&#39064;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31471;&#21040;&#31471;&#30340;&#26426;&#22120;&#23398;&#20064;&#29983;&#21629;&#21608;&#26399;&#21253;&#21547;&#35768;&#22810;&#36845;&#20195;&#36807;&#31243;&#65292;&#20174;&#25968;&#25454;&#20934;&#22791;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35774;&#35745;&#21040;&#27169;&#22411;&#35757;&#32451;&#65292;&#20877;&#21040;&#37096;&#32626;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#29992;&#20110;&#25512;&#29702;&#12290;&#24403;&#26500;&#24314;&#19968;&#20010;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#31471;&#21040;&#31471;&#29983;&#21629;&#21608;&#26399;&#26102;&#65292;&#24517;&#39035;&#35774;&#35745;&#21644;&#25191;&#34892;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31649;&#36947;&#65292;&#36825;&#20250;&#20135;&#29983;&#22823;&#37327;&#30340;&#29983;&#21629;&#21608;&#26399;&#29256;&#26412;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;VeML&#65292;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#31471;&#21040;&#31471;&#26426;&#22120;&#23398;&#20064;&#29983;&#21629;&#21608;&#26399;&#30340;&#29256;&#26412;&#31649;&#29702;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#35299;&#20915;&#20102;&#20854;&#20182;&#31995;&#32479;&#27809;&#26377;&#35299;&#20915;&#30340;&#20960;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#26500;&#24314;&#26426;&#22120;&#23398;&#20064;&#29983;&#21629;&#21608;&#26399;&#30340;&#39640;&#25104;&#26412;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#38024;&#23545;&#22823;&#35268;&#27169;&#21644;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#35758;&#23558;&#22312;&#25105;&#20204;&#31995;&#32479;&#20013;&#31649;&#29702;&#30340;&#31867;&#20284;&#25968;&#25454;&#38598;&#30340;&#29983;&#21629;&#21608;&#26399;&#36716;&#31227;&#21040;&#26032;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#24515;&#38598;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35745;&#31639;&#22823;&#35268;&#27169;&#39640;&#32500;&#25968;&#25454;&#30340;&#30456;&#20284;&#24615;&#12290;&#21478;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;&#30001;&#20110;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#24046;&#24322;&#32780;&#23548;&#33268;&#27169;&#22411;&#20934;&#30830;&#24615;&#19979;&#38477;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#25454;&#27169;&#24335;&#20998;&#26512;&#26041;&#27861;&#26469;&#26816;&#27979;&#20808;&#21069;&#20351;&#29992;&#30340;&#25968;&#25454;&#21644;&#26032;&#25968;&#25454;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#20351;&#29992;&#25143;&#21487;&#20197;&#33258;&#23450;&#20041;&#26426;&#22120;&#23398;&#20064;&#29983;&#21629;&#21608;&#26399;&#24037;&#20316;&#27969;&#65292;&#24182;&#23558;&#29983;&#21629;&#21608;&#26399;&#30340;&#21508;&#20010;&#38454;&#27573;&#19982;&#20854;API&#36830;&#25509;&#36215;&#26469;&#65292;&#20316;&#20026;&#29992;&#25143;&#36816;&#34892;&#33258;&#23450;&#20041;&#20195;&#30721;&#30340;&#26725;&#26753;&#12290; VeML&#24050;&#24212;&#29992;&#20110;&#22788;&#29702;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
An end-to-end machine learning (ML) lifecycle consists of many iterative processes, from data preparation and ML model design to model training and then deploying the trained model for inference. When building an end-to-end lifecycle for an ML problem, many ML pipelines must be designed and executed that produce a huge number of lifecycle versions. Therefore, this paper introduces VeML, a Version management system dedicated to end-to-end ML Lifecycle. Our system tackles several crucial problems that other systems have not solved. First, we address the high cost of building an ML lifecycle, especially for large-scale and high-dimensional dataset. We solve this problem by proposing to transfer the lifecycle of similar datasets managed in our system to the new training data. We design an algorithm based on the core set to compute similarity for large-scale, high-dimensional data efficiently. Another critical issue is the model accuracy degradation by the difference between training data a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#27604;&#36739;&#20102;&#20004;&#31867;&#39640;&#32500;&#22810;&#35270;&#35282;&#32858;&#31867;&#26041;&#27861;&#65288;&#22522;&#20110;&#22270;&#21644;&#22522;&#20110;&#23376;&#31354;&#38388;&#65289;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#22914;&#20309;&#22788;&#29702;&#39640;&#38454;&#30456;&#20851;&#24615;&#65292;&#24182;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2303.08582</link><description>&lt;p&gt;
&#39640;&#32500;&#22810;&#35270;&#35282;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
High-dimensional multi-view clustering methods. (arXiv:2303.08582v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#27604;&#36739;&#20102;&#20004;&#31867;&#39640;&#32500;&#22810;&#35270;&#35282;&#32858;&#31867;&#26041;&#27861;&#65288;&#22522;&#20110;&#22270;&#21644;&#22522;&#20110;&#23376;&#31354;&#38388;&#65289;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#22914;&#20309;&#22788;&#29702;&#39640;&#38454;&#30456;&#20851;&#24615;&#65292;&#24182;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#30456;&#27604;&#20110;&#21333;&#35270;&#35282;&#32858;&#31867;&#65292;&#22810;&#35270;&#35282;&#32858;&#31867;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#20013;&#12290;&#23427;&#21487;&#20197;&#25552;&#20379;&#26356;&#22810;&#30340;&#25968;&#25454;&#20449;&#24687;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#19968;&#20123;&#25361;&#25112;&#65292;&#22914;&#22914;&#20309;&#32452;&#21512;&#36825;&#20123;&#35270;&#35282;&#25110;&#29305;&#24449;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24352;&#37327;&#34920;&#31034;&#19978;&#65292;&#32780;&#19981;&#26159;&#23558;&#25968;&#25454;&#35270;&#20026;&#31616;&#21333;&#30340;&#30697;&#38453;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#25968;&#25454;&#20043;&#38388;&#30340;&#39640;&#38454;&#30456;&#20851;&#24615;&#65292;&#32780;&#22522;&#20110;&#30697;&#38453;&#30340;&#26041;&#27861;&#21017;&#38590;&#20197;&#25429;&#25417;&#36825;&#31181;&#30456;&#20851;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23558;&#30740;&#31350;&#21644;&#27604;&#36739;&#36825;&#20123;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22522;&#20110;&#22270;&#30340;&#32858;&#31867;&#21644;&#23376;&#31354;&#38388;&#32858;&#31867;&#65292;&#20197;&#21450;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-view clustering has been widely used in recent years in comparison to single-view clustering, for clear reasons, as it offers more insights into the data, which has brought with it some challenges, such as how to combine these views or features. Most of recent work in this field focuses mainly on tensor representation instead of treating the data as simple matrices. This permits to deal with the high-order correlation between the data which the based matrix approach struggles to capture. Accordingly, we will examine and compare these approaches, particularly in two categories, namely graph-based clustering and subspace-based clustering. We will conduct and report experiments of the main clustering methods over a benchmark datasets.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#26410;&#30693;&#21040;&#36798;&#21644;&#26381;&#21153;&#29575;&#30340;&#25490;&#38431;&#31995;&#32479;&#20013;&#30340;&#20837;&#22330;&#25511;&#21046;&#38382;&#39064;&#12290;&#36890;&#36807;&#35266;&#23519;&#21040;&#21040;&#36798;&#26102;&#38388;&#21644;&#31995;&#32479;&#29366;&#24577;&#65292;&#25105;&#20204;&#26088;&#22312;&#35774;&#35745;&#19968;&#31181;&#35843;&#24230;&#31574;&#30053;&#65292;&#20197;&#26368;&#22823;&#21270;&#35843;&#24230;&#21592;&#30340;&#38271;&#26399;&#24179;&#22343;&#22238;&#25253;&#12290;&#26631;&#20934;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#19981;&#36866;&#29992;&#20110;&#27492;&#38382;&#39064;&#65292;&#22240;&#20026;&#35843;&#24230;&#21592;&#26080;&#27861;&#35266;&#23519;&#21040;&#26381;&#21153;&#26102;&#38388;&#21644;&#31163;&#24320;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2202.02419</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#26410;&#30693;&#26381;&#21153;&#29575;&#30340;&#25490;&#38431;&#31995;&#32479;&#20013;&#19968;&#32452;&#31163;&#25955;&#30340;&#26368;&#20248;&#20998;&#37197;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Learning a Discrete Set of Optimal Allocation Rules in a Queueing System with Unknown Service Rate. (arXiv:2202.02419v2 [eess.SY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.02419
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#26410;&#30693;&#21040;&#36798;&#21644;&#26381;&#21153;&#29575;&#30340;&#25490;&#38431;&#31995;&#32479;&#20013;&#30340;&#20837;&#22330;&#25511;&#21046;&#38382;&#39064;&#12290;&#36890;&#36807;&#35266;&#23519;&#21040;&#21040;&#36798;&#26102;&#38388;&#21644;&#31995;&#32479;&#29366;&#24577;&#65292;&#25105;&#20204;&#26088;&#22312;&#35774;&#35745;&#19968;&#31181;&#35843;&#24230;&#31574;&#30053;&#65292;&#20197;&#26368;&#22823;&#21270;&#35843;&#24230;&#21592;&#30340;&#38271;&#26399;&#24179;&#22343;&#22238;&#25253;&#12290;&#26631;&#20934;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#19981;&#36866;&#29992;&#20110;&#27492;&#38382;&#39064;&#65292;&#22240;&#20026;&#35843;&#24230;&#21592;&#26080;&#27861;&#35266;&#23519;&#21040;&#26381;&#21153;&#26102;&#38388;&#21644;&#31163;&#24320;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#24212;&#29992;&#20110;&#36890;&#20449;&#32593;&#32476;&#12289;&#21628;&#21483;&#20013;&#24515;&#20197;&#21450;&#35774;&#35745;&#29983;&#20135;&#31995;&#32479;&#12289;&#28040;&#24687;&#31995;&#32479;&#21644;&#22522;&#20110;&#24212;&#29992;&#30340;&#20572;&#36710;&#31995;&#32479;&#31561;&#29616;&#20195;&#24212;&#29992;&#39046;&#22495;&#20043;&#22806;&#30340;Erlang-B&#38459;&#22622;&#27169;&#22411;&#20013;&#65292;&#32771;&#34385;&#21040;&#21040;&#36798;&#21644;&#26381;&#21153;&#29575;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#23545;&#35813;&#31995;&#32479;&#30340;&#20837;&#22330;&#25511;&#21046;&#36827;&#34892;&#30740;&#31350;&#12290;&#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;&#22312;&#27599;&#20010;&#20316;&#19994;&#21040;&#36798;&#26102;&#65292;&#35843;&#24230;&#21592;&#20915;&#23450;&#23558;&#20316;&#19994;&#20998;&#37197;&#32473;&#19968;&#20010;&#21487;&#29992;&#30340;&#26381;&#21153;&#22120;&#25110;&#32773;&#38459;&#22622;&#23427;&#12290;&#27599;&#20010;&#24050;&#26381;&#21153;&#30340;&#20316;&#19994;&#20026;&#35843;&#24230;&#21592;&#24102;&#26469;&#20102;&#22266;&#23450;&#30340;&#22238;&#25253;&#65292;&#20294;&#20063;&#23548;&#33268;&#20102;&#27599;&#21333;&#20301;&#26381;&#21153;&#26102;&#38388;&#30340;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#31181;&#35843;&#24230;&#31574;&#30053;&#65292;&#22522;&#20110;&#20165;&#35266;&#23519;&#21040;&#21040;&#36798;&#26102;&#38388;&#21644;&#27599;&#27425;&#21040;&#36798;&#26102;&#31995;&#32479;&#29366;&#24577;&#30340;&#24773;&#20917;&#65292;&#20174;&#32780;&#26368;&#22823;&#21270;&#35843;&#24230;&#21592;&#30340;&#38271;&#26399;&#24179;&#22343;&#22238;&#25253;&#65292;&#36825;&#21453;&#26144;&#20102;&#23545;&#36825;&#31181;&#31995;&#32479;&#30340;&#29616;&#23454;&#37319;&#26679;&#12290;&#20851;&#38190;&#26159;&#65292;&#35843;&#24230;&#21592;&#26082;&#19981;&#35266;&#23519;&#26381;&#21153;&#26102;&#38388;&#20063;&#19981;&#35266;&#23519;&#31163;&#24320;&#26102;&#38388;&#65292;&#22240;&#27492;&#19981;&#33021;&#24212;&#29992;&#20351;&#29992;&#22870;&#21169;&#20449;&#21495;&#30340;&#26631;&#20934;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#25105;&#20204;&#30340;&#23398;&#20064;&#22522;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Motivated by the wide range of modern applications of the Erlang-B blocking model beyond communication networks and call centers to sizing and pricing in design production systems, messaging systems, and app-based parking systems, we study admission control for such a system but with unknown arrival and service rates. In our model, at every job arrival, a dispatcher decides to assign the job to an available server or block it. Every served job yields a fixed reward for the dispatcher, but it also results in a cost per unit time of service. Our goal is to design a dispatching policy that maximizes the long-term average reward for the dispatcher based on observing only the arrival times and the state of the system at each arrival that reflects a realistic sampling of such systems. Critically, the dispatcher observes neither the service times nor departure times so that standard reinforcement learning-based approaches that use reward signals do not apply. Hence, we develop our learning-ba
&lt;/p&gt;</description></item></channel></rss>