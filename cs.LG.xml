<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35757;&#32451;&#24471;&#21040;&#30340;LLM&#27169;&#22411;&#36890;&#24120;&#26159;&#31232;&#30095;&#30340;&#65292;&#20026;&#20102;&#25552;&#39640;&#25928;&#29575;&#65292;&#30740;&#31350;&#20102;&#22312;&#35757;&#32451;&#35821;&#26009;&#19978;&#36798;&#21040;&#25152;&#38656;&#20934;&#30830;&#24230;&#30340;&#21442;&#25968;&#26368;&#23569;&#30340;&#39640;&#25928;LLM&#27169;&#22411;&#65292;&#24471;&#20986;&#20102;&#21442;&#25968;&#25968;&#37327;&#19982;&#33258;&#28982;&#35757;&#32451;&#35821;&#26009;&#35268;&#27169;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#25193;&#23637;&#21487;&#20197;&#25581;&#31034;&#26032;&#25216;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.14746</link><description>&lt;p&gt;
&#25193;&#23637;&#39640;&#25928;&#30340;LLM&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Scaling Efficient LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14746
&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#24471;&#21040;&#30340;LLM&#27169;&#22411;&#36890;&#24120;&#26159;&#31232;&#30095;&#30340;&#65292;&#20026;&#20102;&#25552;&#39640;&#25928;&#29575;&#65292;&#30740;&#31350;&#20102;&#22312;&#35757;&#32451;&#35821;&#26009;&#19978;&#36798;&#21040;&#25152;&#38656;&#20934;&#30830;&#24230;&#30340;&#21442;&#25968;&#26368;&#23569;&#30340;&#39640;&#25928;LLM&#27169;&#22411;&#65292;&#24471;&#20986;&#20102;&#21442;&#25968;&#25968;&#37327;&#19982;&#33258;&#28982;&#35757;&#32451;&#35821;&#26009;&#35268;&#27169;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#25193;&#23637;&#21487;&#20197;&#25581;&#31034;&#26032;&#25216;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#24471;&#21040;&#30340;LLM&#27169;&#22411;&#36890;&#24120;&#26159;&#31232;&#30095;&#30340;&#65292;&#21363;&#22823;&#37096;&#20998;&#21442;&#25968;&#20026;&#38646;&#65292;&#36825;&#24341;&#21457;&#20102;&#20851;&#20110;&#25928;&#29575;&#30340;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#25928;&#30340;LLM&#27169;&#22411;&#65292;&#21363;&#37027;&#20123;&#22312;&#35757;&#32451;&#35821;&#26009;&#19978;&#36798;&#21040;&#25152;&#38656;&#20934;&#30830;&#24230;&#30340;&#21442;&#25968;&#26368;&#23569;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#24403;&#21069;&#35268;&#27169;&#19979;&#35757;&#32451;&#25439;&#22833;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#20272;&#35745;&#65292;&#20197;&#33719;&#24471;&#33258;&#28982;&#35757;&#32451;&#35821;&#26009;&#20013;&#29420;&#29305;&#24207;&#21015;&#25968;&#37327;&#19978;&#19979;&#30028;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26263;&#31034;&#65306;(1)&#35201;&#22312;&#35757;&#32451;&#35821;&#26009;&#20013;&#34920;&#31034;&#30340;&#25216;&#33021;&#25968;&#37327;&#32763;&#20493;&#65292;&#38656;&#35201;&#23558;&#35821;&#26009;&#35268;&#27169;&#22823;&#32422;&#25193;&#23637;&#19977;&#21040;&#20116;&#20493;&#65292;(2)&#23545;&#20110;&#39640;&#25928;&#30340;LLM&#27169;&#22411;&#65292;&#21442;&#25968;&#25968;&#37327;$N$&#21644;&#33258;&#28982;&#35757;&#32451;&#35821;&#26009;&#35268;&#27169;$D$&#28385;&#36275;$N \sim D^{0.58}$&#30340;&#20851;&#31995;&#65292;(3)&#22914;&#26524;&#19968;&#20010;LLM&#27169;&#22411;&#30340;&#21442;&#25968;&#25968;&#37327;&#23567;&#20110;&#35757;&#32451;&#35821;&#26009;&#20013;&#30340;&#29420;&#29305;&#24207;&#21015;&#25968;&#37327;&#65292;&#25193;&#23637;&#21487;&#20197;&#25581;&#31034;&#20986;&#26032;&#30340;&#25216;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14746v1 Announce Type: new  Abstract: Trained LLMs are typically sparse in that most of the parameters are zero, raising questions on efficiency. In response, we inquire into efficient LLMs, i.e. those with the fewest parameters that achieve the desired accuracy on a training corpus. Specifically, we compare theoretical and empirical estimates for training loss at current scale to obtain upper and lower bounds on the number of unique sequences in a natural training corpus as a function of its size. Our result implies (1) to double the number of skills represented in a training corpus, the corpus must scale roughly between three and five fold (2) for efficient LLMs, the number of parameters $N$ and the size $D$ of a natural training corpus scale as $N \sim D^{0.58}$ (3) if the number of parameters of an LLM is smaller than the number of unique sequences in the training corpus, scaling up can uncover emergent skills.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#36924;&#36817;&#30340;&#32852;&#37030;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36817;&#20284;&#26679;&#26412;&#26799;&#24230;&#21644;&#32553;&#23567;&#27493;&#38271;&#26469;&#23450;&#20301;&#25104;&#26412;&#20989;&#25968;&#30340;&#26497;&#23567;&#20540;&#65292;&#23454;&#29616;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#23545;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#21327;&#20316;&#35757;&#32451;&#30340;&#25928;&#26524;&#65292;&#24182;&#22312;&#25968;&#20540;&#27169;&#25311;&#20013;&#19982;&#26631;&#20934;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>https://arxiv.org/abs/2402.12945</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#36924;&#36817;&#30340;&#32852;&#37030;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stochastic Approximation Approach to Federated Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#36924;&#36817;&#30340;&#32852;&#37030;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36817;&#20284;&#26679;&#26412;&#26799;&#24230;&#21644;&#32553;&#23567;&#27493;&#38271;&#26469;&#23450;&#20301;&#25104;&#26412;&#20989;&#25968;&#30340;&#26497;&#23567;&#20540;&#65292;&#23454;&#29616;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#23545;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#21327;&#20316;&#35757;&#32451;&#30340;&#25928;&#26524;&#65292;&#24182;&#22312;&#25968;&#20540;&#27169;&#25311;&#20013;&#19982;&#26631;&#20934;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#26694;&#26550;&#19979;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#12290; FL&#26159;&#19968;&#31181;&#21327;&#20316;&#26041;&#24335;&#65292;&#29992;&#20110;&#36328;&#19981;&#21516;&#21442;&#19982;&#26041;&#25110;&#23458;&#25143;&#31471;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#23558;&#23427;&#20204;&#30340;&#25968;&#25454;&#38598;&#20013;&#12290; &#27599;&#20010;&#23458;&#25143;&#31471;&#23558;&#26681;&#25454;&#21508;&#33258;&#30340;&#25968;&#25454;&#35757;&#32451;&#19968;&#20010;&#27169;&#22411;&#65292;&#24182;&#23450;&#26399;&#23558;&#26435;&#37325;&#21457;&#36865;&#21040;&#26381;&#21153;&#22120;&#36827;&#34892;&#32858;&#21512;&#12290; &#26381;&#21153;&#22120;&#23545;&#36825;&#20123;&#26435;&#37325;&#36827;&#34892;&#32858;&#21512;&#65292;&#28982;&#21518;&#23458;&#25143;&#31471;&#20351;&#29992;&#36825;&#20123;&#26435;&#37325;&#37325;&#26032;&#21021;&#22987;&#21270;&#20854;&#31070;&#32463;&#32593;&#32476;&#24182;&#32487;&#32493;&#35757;&#32451;&#12290; SA&#26159;&#19968;&#31181;&#20351;&#29992;&#36817;&#20284;&#26679;&#26412;&#26799;&#24230;&#21644;&#32553;&#23567;&#27493;&#38271;&#26469;&#23450;&#20301;&#25104;&#26412;&#20989;&#25968;&#26497;&#23567;&#20540;&#30340;&#36845;&#20195;&#31639;&#27861;&#12290; &#26412;&#25991;&#20013;&#65292;&#23458;&#25143;&#31471;&#20351;&#29992;&#38543;&#26426;&#36924;&#36817;&#36845;&#20195;&#26356;&#26032;&#20854;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#12290; &#32467;&#26524;&#34920;&#26126;&#65292;&#32858;&#21512;&#26435;&#37325;&#36319;&#36394;&#19968;&#20010;&#33258;&#27835;ODE&#12290; &#36827;&#34892;&#20102;&#25968;&#20540;&#27169;&#25311;&#65292;&#24182;&#23558;&#32467;&#26524;&#19982;FedAvg&#21644;FedProx&#31561;&#26631;&#20934;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12945v1 Announce Type: new  Abstract: This paper examines Federated learning (FL) in a Stochastic Approximation (SA) framework. FL is a collaborative way to train neural network models across various participants or clients without centralizing their data. Each client will train a model on their respective data and send the weights across to a the server periodically for aggregation. The server aggregates these weights which are then used by the clients to re-initialize their neural network and continue the training. SA is an iterative algorithm that uses approximate sample gradients and tapering step size to locate a minimizer of a cost function. In this paper the clients use a stochastic approximation iterate to update the weights of its neural network. It is shown that the aggregated weights track an autonomous ODE. Numerical simulations are performed and the results are compared with standard algorithms like FedAvg and FedProx. It is observed that the proposed algorithm 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#33258;&#34892;&#36710;&#20849;&#20139;&#31995;&#32479;&#20013;&#21160;&#24577;&#20877;&#24179;&#34913;&#38382;&#39064;&#30340;&#26102;&#31354;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#23454;&#29616;&#29420;&#31435;&#21644;&#21327;&#20316;&#30340;&#36710;&#36742;&#20877;&#24179;&#34913;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#25968;&#23398;&#20248;&#21270;&#26041;&#27861;&#30340;&#19981;&#23454;&#38469;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.03589</link><description>&lt;p&gt;
&#33258;&#34892;&#36710;&#20849;&#20139;&#31995;&#32479;&#20013;&#21160;&#24577;&#20877;&#24179;&#34913;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Reinforcement Learning Approach for Dynamic Rebalancing in Bike-Sharing System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#33258;&#34892;&#36710;&#20849;&#20139;&#31995;&#32479;&#20013;&#21160;&#24577;&#20877;&#24179;&#34913;&#38382;&#39064;&#30340;&#26102;&#31354;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#23454;&#29616;&#29420;&#31435;&#21644;&#21327;&#20316;&#30340;&#36710;&#36742;&#20877;&#24179;&#34913;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#25968;&#23398;&#20248;&#21270;&#26041;&#27861;&#30340;&#19981;&#23454;&#38469;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#34892;&#36710;&#20849;&#20139;&#31995;&#32479;&#25552;&#20379;&#29615;&#20445;&#30340;&#22478;&#24066;&#20986;&#34892;&#26041;&#24335;&#65292;&#26377;&#21161;&#20110;&#32531;&#35299;&#20132;&#36890;&#25317;&#22581;&#65292;&#20419;&#36827;&#20581;&#24247;&#29983;&#27963;&#26041;&#24335;&#12290;&#30001;&#20110;&#34892;&#31243;&#38656;&#27714;&#30340;&#38543;&#26426;&#24615;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#26377;&#25928;&#36816;&#33829;&#21644;&#20445;&#25345;&#39640;&#23458;&#25143;&#28385;&#24847;&#24230;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24120;&#24120;&#20986;&#29616;&#28385;&#31449;&#25110;&#31354;&#31449;&#29616;&#35937;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20351;&#29992;&#36710;&#36742;&#37325;&#26032;&#20998;&#37197;&#33258;&#34892;&#36710;&#21040;&#19981;&#21516;&#31449;&#28857;&#30340;&#20877;&#24179;&#34913;&#31574;&#30053;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26102;&#31354;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24102;&#26377;&#22810;&#36742;&#36710;&#36742;&#30340;&#21160;&#24577;&#20877;&#24179;&#34913;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#22312;&#36830;&#32493;&#26102;&#38388;&#26694;&#26550;&#20013;&#23558;&#38382;&#39064;&#24314;&#27169;&#20026;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;&#36825;&#20801;&#35768;&#29420;&#31435;&#21644;&#21327;&#20316;&#30340;&#36710;&#36742;&#20877;&#24179;&#34913;&#65292;&#28040;&#38500;&#20102;&#22522;&#20110;&#26102;&#38388;&#31163;&#25955;&#21270;&#27169;&#22411;&#30340;&#19981;&#20999;&#23454;&#38469;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bike-Sharing Systems provide eco-friendly urban mobility, contributing to the alleviation of traffic congestion and to healthier lifestyles. Efficiently operating such systems and maintaining high customer satisfaction is challenging due to the stochastic nature of trip demand, leading to full or empty stations. Devising effective rebalancing strategies using vehicles to redistribute bikes among stations is therefore of uttermost importance for operators. As a promising alternative to classical mathematical optimization, reinforcement learning is gaining ground to solve sequential decision-making problems. This paper introduces a spatio-temporal reinforcement learning algorithm for the dynamic rebalancing problem with multiple vehicles. We first formulate the problem as a Multi-agent Markov Decision Process in a continuous time framework. This allows for independent and cooperative vehicle rebalancing, eliminating the impractical restriction of time-discretized models where vehicle dep
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;&#31639;&#27861;&#65288;D-SOBA&#65289;&#65292;&#39318;&#27425;&#38416;&#26126;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#22312;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2402.03167</link><description>&lt;p&gt;
&#22270;&#19978;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;: &#26080;&#29615;&#31639;&#27861;&#26356;&#26032;&#21644;&#30636;&#24577;&#36845;&#20195;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Decentralized Bilevel Optimization over Graphs: Loopless Algorithmic Update and Transient Iteration Complexity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03167
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;&#31639;&#27861;&#65288;D-SOBA&#65289;&#65292;&#39318;&#27425;&#38416;&#26126;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#22312;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21452;&#32423;&#20248;&#21270;&#65288;SBO&#65289;&#22312;&#22788;&#29702;&#23884;&#22871;&#32467;&#26500;&#26041;&#38754;&#30340;&#22810;&#26679;&#24615;&#20351;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#22823;&#35268;&#27169;SBO&#65292;&#21435;&#20013;&#24515;&#21270;&#26041;&#27861;&#20316;&#20026;&#26377;&#25928;&#30340;&#33539;&#20363;&#20986;&#29616;&#65292;&#20854;&#20013;&#33410;&#28857;&#19982;&#30452;&#25509;&#30456;&#37051;&#33410;&#28857;&#36827;&#34892;&#36890;&#20449;&#65292;&#26080;&#38656;&#20013;&#22830;&#26381;&#21153;&#22120;&#65292;&#20174;&#32780;&#25552;&#39640;&#36890;&#20449;&#25928;&#29575;&#21644;&#22686;&#24378;&#31639;&#27861;&#30340;&#31283;&#20581;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#21435;&#20013;&#24515;&#21270;SBO&#31639;&#27861;&#38754;&#20020;&#25361;&#25112;&#65292;&#21253;&#25324;&#26114;&#36149;&#30340;&#20869;&#37096;&#24490;&#29615;&#26356;&#26032;&#21644;&#23545;&#32593;&#32476;&#25299;&#25169;&#12289;&#25968;&#25454;&#24322;&#26500;&#24615;&#21644;&#23884;&#22871;&#21452;&#32423;&#31639;&#27861;&#32467;&#26500;&#30340;&#24433;&#21709;&#19981;&#26126;&#30830;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;SBO&#65288;D-SOBA&#65289;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#20854;&#30636;&#24577;&#36845;&#20195;&#22797;&#26434;&#24615;&#65292;&#39318;&#27425;&#28548;&#28165;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic bilevel optimization (SBO) is becoming increasingly essential in machine learning due to its versatility in handling nested structures. To address large-scale SBO, decentralized approaches have emerged as effective paradigms in which nodes communicate with immediate neighbors without a central server, thereby improving communication efficiency and enhancing algorithmic robustness. However, current decentralized SBO algorithms face challenges, including expensive inner-loop updates and unclear understanding of the influence of network topology, data heterogeneity, and the nested bilevel algorithmic structures. In this paper, we introduce a single-loop decentralized SBO (D-SOBA) algorithm and establish its transient iteration complexity, which, for the first time, clarifies the joint influence of network topology and data heterogeneity on decentralized bilevel algorithms. D-SOBA achieves the state-of-the-art asymptotic rate, asymptotic gradient/Hessian complexity, and transien
&lt;/p&gt;</description></item><item><title>TinyFormer&#26159;&#19968;&#20010;&#20855;&#26377;SuperNAS&#12289;SparseNAS&#21644;SparseEngine&#32452;&#25104;&#30340;&#26694;&#26550;&#65292;&#19987;&#38376;&#29992;&#20110;&#22312;MCUs&#19978;&#24320;&#21457;&#21644;&#37096;&#32626;&#36164;&#28304;&#39640;&#25928;&#30340;transformer&#27169;&#22411;&#12290;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#25552;&#20986;&#20102;SparseEngine&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#22312;MCUs&#19978;&#25191;&#34892;&#31232;&#30095;&#27169;&#22411;&#30340;transformer&#25512;&#29702;&#30340;&#37096;&#32626;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2311.01759</link><description>&lt;p&gt;
TinyFormer: &#39640;&#25928;&#30340;Transformer&#35774;&#35745;&#21644;&#22312;&#23567;&#22411;&#35774;&#22791;&#19978;&#30340;&#37096;&#32626;
&lt;/p&gt;
&lt;p&gt;
TinyFormer: Efficient Transformer Design and Deployment on Tiny Devices. (arXiv:2311.01759v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01759
&lt;/p&gt;
&lt;p&gt;
TinyFormer&#26159;&#19968;&#20010;&#20855;&#26377;SuperNAS&#12289;SparseNAS&#21644;SparseEngine&#32452;&#25104;&#30340;&#26694;&#26550;&#65292;&#19987;&#38376;&#29992;&#20110;&#22312;MCUs&#19978;&#24320;&#21457;&#21644;&#37096;&#32626;&#36164;&#28304;&#39640;&#25928;&#30340;transformer&#27169;&#22411;&#12290;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#25552;&#20986;&#20102;SparseEngine&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#22312;MCUs&#19978;&#25191;&#34892;&#31232;&#30095;&#27169;&#22411;&#30340;transformer&#25512;&#29702;&#30340;&#37096;&#32626;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#23884;&#20837;&#24335;&#29289;&#32852;&#32593;&#24212;&#29992;&#20013;&#65292;&#20197;&#24494;&#25511;&#21046;&#22120;&#21333;&#20803;&#65288;MCUs&#65289;&#20026;&#20195;&#34920;&#30340;&#23567;&#22411;&#35774;&#22791;&#19978;&#24320;&#21457;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20005;&#37325;&#30340;&#30828;&#20214;&#36164;&#28304;&#38480;&#21046;&#65292;&#22914;&#20309;&#39640;&#25928;&#22320;&#35774;&#35745;&#21644;&#37096;&#32626;&#26368;&#26032;&#30340;&#20808;&#36827;&#27169;&#22411;&#65288;&#22914;transformer&#65289;&#22312;&#23567;&#22411;&#35774;&#22791;&#19978;&#26159;&#19968;&#39033;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TinyFormer&#65292;&#36825;&#26159;&#19968;&#20010;&#29305;&#21035;&#35774;&#35745;&#29992;&#20110;&#22312;MCUs&#19978;&#24320;&#21457;&#21644;&#37096;&#32626;&#36164;&#28304;&#39640;&#25928;&#30340;transformer&#30340;&#26694;&#26550;&#12290;TinyFormer&#20027;&#35201;&#30001;SuperNAS&#12289;SparseNAS&#21644;SparseEngine&#32452;&#25104;&#12290;&#20854;&#20013;&#65292;SuperNAS&#26088;&#22312;&#20174;&#24191;&#22823;&#30340;&#25628;&#32034;&#31354;&#38388;&#20013;&#23547;&#25214;&#36866;&#24403;&#30340;&#36229;&#32593;&#32476;&#12290;SparseNAS&#35780;&#20272;&#26368;&#20339;&#30340;&#31232;&#30095;&#21333;&#36335;&#24452;&#27169;&#22411;&#65292;&#21253;&#25324;&#20174;&#24050;&#35782;&#21035;&#30340;&#36229;&#32593;&#32476;&#20013;&#25552;&#21462;&#30340;transformer&#26550;&#26500;&#12290;&#26368;&#21518;&#65292;SparseEngine&#23558;&#25628;&#32034;&#21040;&#30340;&#31232;&#30095;&#27169;&#22411;&#39640;&#25928;&#22320;&#37096;&#32626;&#21040;MCUs&#19978;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;SparseEngine&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;MCUs&#19978;&#25191;&#34892;&#31232;&#30095;&#27169;&#22411;&#30340;transformer&#25512;&#29702;&#30340;&#37096;&#32626;&#26694;&#26550;&#12290;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;TinyFormer&#22312;&#20445;&#25345;&#25512;&#29702;&#31934;&#24230;&#30340;&#21516;&#26102;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;transformer&#27169;&#22411;&#65292;&#20943;&#23569;&#20102;&#22823;&#32422;78&#65285;&#30340;&#25512;&#29702;&#35745;&#31639;&#37327;&#21644;53&#65285;&#30340;&#27169;&#22411;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Developing deep learning models on tiny devices (e.g. Microcontroller units, MCUs) has attracted much attention in various embedded IoT applications. However, it is challenging to efficiently design and deploy recent advanced models (e.g. transformers) on tiny devices due to their severe hardware resource constraints. In this work, we propose TinyFormer, a framework specifically designed to develop and deploy resource-efficient transformers on MCUs. TinyFormer mainly consists of SuperNAS, SparseNAS and SparseEngine. Separately, SuperNAS aims to search for an appropriate supernet from a vast search space. SparseNAS evaluates the best sparse single-path model including transformer architecture from the identified supernet. Finally, SparseEngine efficiently deploys the searched sparse models onto MCUs. To the best of our knowledge, SparseEngine is the first deployment framework capable of performing inference of sparse models with transformer on MCUs. Evaluation results on the CIFAR-10 da
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.00098</link><description>&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#23398;&#20064;&#36827;&#34892;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Federated Learning with Differential Privacy for End-to-End Speech Recognition. (arXiv:2310.00098v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20294;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#39046;&#22495;&#20165;&#38480;&#20110;&#21021;&#27493;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#32852;&#37030;&#23398;&#20064;&#19981;&#33021;&#26412;&#36136;&#19978;&#20445;&#35777;&#29992;&#25143;&#38544;&#31169;&#65292;&#24182;&#38656;&#35201;&#24046;&#20998;&#38544;&#31169;&#26469;&#25552;&#20379;&#31283;&#20581;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36824;&#19981;&#28165;&#26970;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#20808;&#21069;&#24037;&#20316;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20026;&#32852;&#37030;&#23398;&#20064;&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;&#30340;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#22522;&#20934;&#65292;&#24182;&#24314;&#31435;&#31532;&#19968;&#20010;&#22522;&#32447;&#26469;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#32852;&#37030;&#23398;&#20064;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#30740;&#31350;&#65292;&#25506;&#32034;&#20102;&#26368;&#26032;&#30340;&#22823;&#22411;&#31471;&#21040;&#31471;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65306;&#26550;&#26500;&#35774;&#35745;&#65292;&#31181;&#23376;&#27169;&#22411;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#65292;&#39046;&#22495;&#36716;&#31227;&#65292;&#20197;&#21450;cohort&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#21512;&#29702;&#30340;&#20013;&#22830;&#32858;&#21512;&#25968;&#37327;&#65292;&#25105;&#20204;&#33021;&#22815;&#35757;&#32451;&#20986;&#21363;&#20351;&#22312;&#24322;&#26500;&#25968;&#25454;&#12289;&#26469;&#33258;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#31181;&#23376;&#27169;&#22411;&#25110;&#26080;&#39044;&#20808;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#25509;&#36817;&#26368;&#20248;&#30340;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
While federated learning (FL) has recently emerged as a promising approach to train machine learning models, it is limited to only preliminary explorations in the domain of automatic speech recognition (ASR). Moreover, FL does not inherently guarantee user privacy and requires the use of differential privacy (DP) for robust privacy guarantees. However, we are not aware of prior work on applying DP to FL for ASR. In this paper, we aim to bridge this research gap by formulating an ASR benchmark for FL with DP and establishing the first baselines. First, we extend the existing research on FL for ASR by exploring different aspects of recent $\textit{large end-to-end transformer models}$: architecture design, seed models, data heterogeneity, domain shift, and impact of cohort size. With a $\textit{practical}$ number of central aggregations we are able to train $\textbf{FL models}$ that are \textbf{nearly optimal} even with heterogeneous data, a seed model from another domain, or no pre-trai
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23610;&#24230;&#19981;&#21464;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65288;SI-MTL&#65289;&#65292;&#36890;&#36807;&#23545;&#20219;&#21153;&#25439;&#22833;&#36827;&#34892;&#23545;&#25968;&#21464;&#25442;&#21644;&#23545;&#20219;&#21153;&#26799;&#24230;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#35299;&#20915;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#24179;&#34913;&#38382;&#39064;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#39046;&#20808;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12029</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#23610;&#24230;&#19981;&#21464;&#20219;&#21153;&#24179;&#34913;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Scale-Invariant Task Balancing Approach for Multi-Task Learning. (arXiv:2308.12029v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12029
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23610;&#24230;&#19981;&#21464;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65288;SI-MTL&#65289;&#65292;&#36890;&#36807;&#23545;&#20219;&#21153;&#25439;&#22833;&#36827;&#34892;&#23545;&#25968;&#21464;&#25442;&#21644;&#23545;&#20219;&#21153;&#26799;&#24230;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#35299;&#20915;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#24179;&#34913;&#38382;&#39064;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#39046;&#20808;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#26159;&#19968;&#31181;&#21516;&#26102;&#23398;&#20064;&#22810;&#20010;&#30456;&#20851;&#20219;&#21153;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#20219;&#21153;&#24179;&#34913;&#20173;&#28982;&#26159;MTL&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#25439;&#22833;/&#26799;&#24230;&#23610;&#24230;&#30340;&#19981;&#24179;&#34913;&#32463;&#24120;&#23548;&#33268;&#24615;&#33021;&#25240;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23610;&#24230;&#19981;&#21464;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;SI-MTL&#65289;&#26041;&#27861;&#65292;&#20174;&#25439;&#22833;&#21644;&#26799;&#24230;&#35282;&#24230;&#32531;&#35299;&#20102;&#20219;&#21153;&#24179;&#34913;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;SI-MTL&#21253;&#21547;&#23545;&#25152;&#26377;&#20219;&#21153;&#25439;&#22833;&#36827;&#34892;&#30340;&#23545;&#25968;&#21464;&#25442;&#65292;&#20197;&#30830;&#20445;&#22312;&#25439;&#22833;&#27700;&#24179;&#19978;&#20855;&#26377;&#23610;&#24230;&#19981;&#21464;&#24615;&#65292;&#20197;&#21450;&#19968;&#31181;&#26799;&#24230;&#24179;&#34913;&#26041;&#27861;SI-G&#65292;&#23427;&#23558;&#25152;&#26377;&#20219;&#21153;&#30340;&#26799;&#24230;&#24402;&#19968;&#21270;&#20026;&#19982;&#26368;&#22823;&#26799;&#24230;&#33539;&#25968;&#30456;&#21516;&#30340;&#22823;&#23567;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#19968;&#33268;&#35777;&#26126;&#20102;SI-G&#30340;&#26377;&#25928;&#24615;&#21644;SI-MTL&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning (MTL), a learning paradigm to learn multiple related tasks simultaneously, has achieved great success in various fields. However, task-balancing remains a significant challenge in MTL, with the disparity in loss/gradient scales often leading to performance compromises. In this paper, we propose a Scale-Invariant Multi-Task Learning (SI-MTL) method to alleviate the task-balancing problem from both loss and gradient perspectives. Specifically, SI-MTL contains a logarithm transformation which is performed on all task losses to ensure scale-invariant at the loss level, and a gradient balancing method, SI-G, which normalizes all task gradients to the same magnitude as the maximum gradient norm. Extensive experiments conducted on several benchmark datasets consistently demonstrate the effectiveness of SI-G and the state-of-the-art performance of SI-MTL.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20302;&#28201;&#33976;&#39311;&#65288;LTD&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20462;&#25913;&#30340;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#29983;&#25104;&#36719;&#26631;&#31614;&#65292;&#35299;&#20915;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#24120;&#29992;&#30340;&#29420;&#28909;&#21521;&#37327;&#26631;&#31614;&#24102;&#26469;&#30340;&#23398;&#20064;&#22256;&#38590;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.02331</link><description>&lt;p&gt;
&#20302;&#28201;&#33976;&#39311;&#65306;&#29992;&#20110;&#31283;&#20581;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
LTD: Low Temperature Distillation for Robust Adversarial Training. (arXiv:2111.02331v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.02331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20302;&#28201;&#33976;&#39311;&#65288;LTD&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20462;&#25913;&#30340;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#29983;&#25104;&#36719;&#26631;&#31614;&#65292;&#35299;&#20915;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#24120;&#29992;&#30340;&#29420;&#28909;&#21521;&#37327;&#26631;&#31614;&#24102;&#26469;&#30340;&#23398;&#20064;&#22256;&#38590;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;&#25239;&#25915;&#20987;&#30340;&#31283;&#20581;&#24615;&#12290;&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#26159;&#36825;&#20123;&#27169;&#22411;&#30340;&#33258;&#28982;&#20934;&#30830;&#24615;&#21644;&#31283;&#20581;&#20934;&#30830;&#24615;&#20043;&#38388;&#23384;&#22312;&#30528;&#26174;&#33879;&#24046;&#36317;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#21457;&#29616;&#20102;&#36825;&#20010;&#24046;&#36317;&#30340;&#19968;&#20010;&#20027;&#35201;&#21407;&#22240;&#26159;&#24120;&#29992;&#30340;&#29420;&#28909;&#21521;&#37327;&#20316;&#20026;&#26631;&#31614;&#65292;&#36825;&#38459;&#30861;&#20102;&#22270;&#20687;&#35782;&#21035;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#29992;&#29420;&#28909;&#21521;&#37327;&#34920;&#31034;&#27169;&#31946;&#22270;&#20687;&#26159;&#19981;&#20934;&#30830;&#30340;&#65292;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#24471;&#21040;&#27425;&#20248;&#35299;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20043;&#20026;&#20302;&#28201;&#33976;&#39311;&#65288;LTD&#65289;&#65292;&#23427;&#20351;&#29992;&#20462;&#25913;&#30340;&#30693;&#35782;&#33976;&#39311;&#26694;&#26550;&#29983;&#25104;&#36719;&#26631;&#31614;&#12290;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;LTD&#22312;&#25945;&#24072;&#27169;&#22411;&#20013;&#20351;&#29992;&#30456;&#23545;&#36739;&#20302;&#30340;&#28201;&#24230;&#65292;&#32780;&#23545;&#25945;&#24072;&#21644;&#23398;&#29983;&#27169;&#22411;&#20351;&#29992;&#22266;&#23450;&#20294;&#19981;&#21516;&#30340;&#28201;&#24230;&#12290;&#36825;&#20010;&#20462;&#25913;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#65292;&#32780;&#19981;&#20250;&#36935;&#21040;&#24050;&#32463;&#22312;&#20808;&#21069;&#24037;&#20316;&#20013;&#35299;&#20915;&#30340;&#26799;&#24230;&#25513;&#30721;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training has been widely used to enhance the robustness of neural network models against adversarial attacks. Despite the popularity of neural network models, a significant gap exists between the natural and robust accuracy of these models. In this paper, we identify one of the primary reasons for this gap is the common use of one-hot vectors as labels, which hinders the learning process for image recognition. Representing ambiguous images with one-hot vectors is imprecise and may lead the model to suboptimal solutions. To overcome this issue, we propose a novel method called Low Temperature Distillation (LTD) that generates soft labels using the modified knowledge distillation framework. Unlike previous approaches, LTD uses a relatively low temperature in the teacher model and fixed, but different temperatures for the teacher and student models. This modification boosts the model's robustness without encountering the gradient masking problem that has been addressed in defe
&lt;/p&gt;</description></item></channel></rss>