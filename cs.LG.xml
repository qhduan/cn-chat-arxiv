<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25972;&#21512;&#27491;&#24358;&#20989;&#25968;&#21040;&#20302;&#31209;&#20998;&#35299;&#36807;&#31243;&#20013;&#65292;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#39640;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.19243</link><description>&lt;p&gt;
&#29992;&#27491;&#24358;&#28608;&#27963;&#30340;&#20302;&#31209;&#30697;&#38453;&#23454;&#29616;&#21442;&#25968;&#39640;&#25928;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sine Activated Low-Rank Matrices for Parameter Efficient Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19243
&lt;/p&gt;
&lt;p&gt;
&#25972;&#21512;&#27491;&#24358;&#20989;&#25968;&#21040;&#20302;&#31209;&#20998;&#35299;&#36807;&#31243;&#20013;&#65292;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#20998;&#35299;&#24050;&#32463;&#25104;&#20026;&#22312;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#22686;&#24378;&#21442;&#25968;&#25928;&#29575;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#21508;&#31181;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#36825;&#20123;&#25216;&#26415;&#26174;&#33879;&#38477;&#20302;&#20102;&#21442;&#25968;&#25968;&#37327;&#65292;&#21462;&#24471;&#20102;&#31616;&#27905;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#24120;&#35265;&#30340;&#25361;&#25112;&#26159;&#22312;&#21442;&#25968;&#25928;&#29575;&#21644;&#27169;&#22411;&#20934;&#30830;&#24615;&#20043;&#38388;&#20570;&#20986;&#22949;&#21327;&#65292;&#21442;&#25968;&#20943;&#23569;&#24448;&#24448;&#23548;&#33268;&#20934;&#30830;&#24615;&#19981;&#21450;&#23436;&#25972;&#31209;&#23545;&#24212;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#22312;&#20302;&#31209;&#20998;&#35299;&#36807;&#31243;&#20013;&#25972;&#21512;&#20102;&#19968;&#20010;&#27491;&#24358;&#20989;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#20445;&#30041;&#20102;&#20302;&#31209;&#26041;&#27861;&#30340;&#21442;&#25968;&#25928;&#29575;&#29305;&#24615;&#30340;&#22909;&#22788;&#65292;&#36824;&#22686;&#21152;&#20102;&#20998;&#35299;&#30340;&#31209;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#34987;&#35777;&#26126;&#26159;&#29616;&#26377;&#20302;&#31209;&#27169;&#22411;&#30340;&#19968;&#31181;&#36866;&#24212;&#24615;&#22686;&#24378;&#65292;&#27491;&#22914;&#20854;&#25104;&#21151;&#35777;&#23454;&#30340;&#37027;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19243v1 Announce Type: new  Abstract: Low-rank decomposition has emerged as a vital tool for enhancing parameter efficiency in neural network architectures, gaining traction across diverse applications in machine learning. These techniques significantly lower the number of parameters, striking a balance between compactness and performance. However, a common challenge has been the compromise between parameter efficiency and the accuracy of the model, where reduced parameters often lead to diminished accuracy compared to their full-rank counterparts. In this work, we propose a novel theoretical framework that integrates a sinusoidal function within the low-rank decomposition process. This approach not only preserves the benefits of the parameter efficiency characteristic of low-rank methods but also increases the decomposition's rank, thereby enhancing model accuracy. Our method proves to be an adaptable enhancement for existing low-rank models, as evidenced by its successful 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#31216;&#20026;&#22343;&#21248;&#27491;&#21017;&#21270;&#23610;&#24230;&#19981;&#21464;&#30340;&#26356;&#19968;&#33324;&#27169;&#22411;&#65292;&#25581;&#31034;&#20102;&#20302;&#31209;&#36924;&#36817;&#27169;&#22411;&#20013;&#23610;&#24230;&#19981;&#21464;&#24615;&#23548;&#33268;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#25928;&#26524;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#29702;&#35299;&#27491;&#21017;&#21270;&#20989;&#25968;&#30340;&#20316;&#29992;&#24182;&#25351;&#23548;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#12290;</title><link>https://arxiv.org/abs/2403.18517</link><description>&lt;p&gt;
&#38024;&#23545;&#27491;&#21017;&#21270;&#38750;&#36127;&#23610;&#24230;&#19981;&#21464;&#20302;&#31209;&#36924;&#36817;&#27169;&#22411;&#30340;&#39640;&#25928;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Algorithms for Regularized Nonnegative Scale-invariant Low-rank Approximation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18517
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#31216;&#20026;&#22343;&#21248;&#27491;&#21017;&#21270;&#23610;&#24230;&#19981;&#21464;&#30340;&#26356;&#19968;&#33324;&#27169;&#22411;&#65292;&#25581;&#31034;&#20102;&#20302;&#31209;&#36924;&#36817;&#27169;&#22411;&#20013;&#23610;&#24230;&#19981;&#21464;&#24615;&#23548;&#33268;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#25928;&#26524;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#29702;&#35299;&#27491;&#21017;&#21270;&#20989;&#25968;&#30340;&#20316;&#29992;&#24182;&#25351;&#23548;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#38750;&#36127;&#20302;&#31209;&#36924;&#36817;&#65292;&#22914;&#31232;&#30095;&#30340;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#25110;&#31232;&#30095;&#30340;&#38750;&#36127;Tucker&#20998;&#35299;&#65292;&#26159;&#20855;&#26377;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#30340;&#38477;&#32500;&#27169;&#22411;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#20998;&#25903;&#12290;&#28982;&#32780;&#65292;&#20174;&#23454;&#36341;&#35282;&#24230;&#26469;&#30475;&#65292;&#30001;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#22810;&#22240;&#32032;&#29305;&#24615;&#20197;&#21450;&#32570;&#20047;&#25903;&#25345;&#36825;&#20123;&#36873;&#25321;&#30340;&#29702;&#35770;&#65292;&#27491;&#21017;&#21270;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#31995;&#25968;&#30340;&#36873;&#25321;&#65292;&#20197;&#21450;&#39640;&#25928;&#31639;&#27861;&#30340;&#35774;&#35745;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#25913;&#36827;&#36825;&#20123;&#38382;&#39064;&#12290;&#36890;&#36807;&#30740;&#31350;&#19968;&#20010;&#31216;&#20026;&#22343;&#21248;&#27491;&#21017;&#21270;&#23610;&#24230;&#19981;&#21464;&#30340;&#26356;&#19968;&#33324;&#27169;&#22411;&#65292;&#25105;&#20204;&#35777;&#26126;&#20302;&#31209;&#36924;&#36817;&#27169;&#22411;&#20013;&#22266;&#26377;&#30340;&#23610;&#24230;&#19981;&#21464;&#24615;&#23548;&#33268;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#20855;&#26377;&#24847;&#24819;&#19981;&#21040;&#30340;&#26377;&#30410;&#21644;&#26377;&#23475;&#25928;&#26524;&#12290;&#36825;&#19968;&#21457;&#29616;&#20351;&#25105;&#20204;&#33021;&#22815;&#26356;&#22909;&#22320;&#29702;&#35299;&#20302;&#31209;&#36924;&#36817;&#27169;&#22411;&#20013;&#27491;&#21017;&#21270;&#20989;&#25968;&#30340;&#20316;&#29992;&#65292;&#25351;&#23548;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18517v1 Announce Type: new  Abstract: Regularized nonnegative low-rank approximations such as sparse Nonnegative Matrix Factorization or sparse Nonnegative Tucker Decomposition are an important branch of dimensionality reduction models with enhanced interpretability. However, from a practical perspective, the choice of regularizers and regularization coefficients, as well as the design of efficient algorithms, is challenging because of the multifactor nature of these models and the lack of theory to back these choices. This paper aims at improving upon these issues. By studying a more general model called the Homogeneous Regularized Scale-Invariant, we prove that the scale-invariance inherent to low-rank approximation models causes an implicit regularization with both unexpected beneficial and detrimental effects. This observation allows to better understand the effect of regularization functions in low-rank approximation models, to guide the choice of the regularization hyp
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#20915;&#31574;&#26641;&#35299;&#37322;&#22522;&#20110;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#35786;&#26029;&#27169;&#22411;&#65292;&#24110;&#21161;&#20020;&#24202;&#21307;&#29983;&#25552;&#39640;&#35782;&#21035;&#19981;&#20934;&#30830;&#39044;&#27979;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#22686;&#24378;&#21307;&#23398;&#35786;&#26029;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12394</link><description>&lt;p&gt;
&#21033;&#29992;&#29983;&#29289;&#26631;&#24535;&#29289;&#25552;&#39640;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#21644;&#21487;&#38752;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving Model's Interpretability and Reliability using Biomarkers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12394
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#20915;&#31574;&#26641;&#35299;&#37322;&#22522;&#20110;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#35786;&#26029;&#27169;&#22411;&#65292;&#24110;&#21161;&#20020;&#24202;&#21307;&#29983;&#25552;&#39640;&#35782;&#21035;&#19981;&#20934;&#30830;&#39044;&#27979;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#22686;&#24378;&#21307;&#23398;&#35786;&#26029;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#19988;&#20855;&#26377;&#35299;&#37322;&#24615;&#30340;&#35786;&#26029;&#27169;&#22411;&#22312;&#21307;&#23398;&#36825;&#20010;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#22522;&#20110;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#32954;&#37096;&#36229;&#22768;&#35786;&#26029;&#27969;&#31243;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#22686;&#24378;&#20020;&#24202;&#21307;&#29983;&#30340;&#35786;&#26029;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#35780;&#20272;&#20915;&#31574;&#26641;&#20998;&#31867;&#22120;&#21033;&#29992;&#29983;&#29289;&#26631;&#24535;&#29289;&#25552;&#20379;&#30340;&#35299;&#37322;&#26159;&#21542;&#33021;&#22815;&#25913;&#21892;&#29992;&#25143;&#35782;&#21035;&#27169;&#22411;&#19981;&#20934;&#30830;&#39044;&#27979;&#33021;&#21147;&#65292;&#19982;&#20256;&#32479;&#30340;&#26174;&#33879;&#24615;&#22270;&#30456;&#27604;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#34920;&#26126;&#65292;&#22522;&#20110;&#20020;&#24202;&#24314;&#31435;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#30340;&#20915;&#31574;&#26641;&#35299;&#37322;&#33021;&#22815;&#24110;&#21161;&#20020;&#24202;&#21307;&#29983;&#26816;&#27979;&#21040;&#20551;&#38451;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#21307;&#23398;&#35786;&#26029;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12394v1 Announce Type: cross  Abstract: Accurate and interpretable diagnostic models are crucial in the safety-critical field of medicine. We investigate the interpretability of our proposed biomarker-based lung ultrasound diagnostic pipeline to enhance clinicians' diagnostic capabilities. The objective of this study is to assess whether explanations from a decision tree classifier, utilizing biomarkers, can improve users' ability to identify inaccurate model predictions compared to conventional saliency maps. Our findings demonstrate that decision tree explanations, based on clinically established biomarkers, can assist clinicians in detecting false positives, thus improving the reliability of diagnostic models in medicine.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#25968;&#25454;&#28246;&#20013;&#30340;&#25968;&#25454;&#21457;&#29616;&#36827;&#34892;&#28145;&#20837;&#20998;&#26512;&#65292;&#30528;&#37325;&#20110;&#34920;&#26684;&#22686;&#24378;&#65292;&#25552;&#20986;&#20102;&#20934;&#30830;&#26816;&#32034;&#36830;&#25509;&#20505;&#36873;&#20154;&#30340;&#37325;&#35201;&#24615;&#21644;&#31616;&#21333;&#21512;&#24182;&#26041;&#27861;&#30340;&#25928;&#29575;&#65292;&#20197;&#21450;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#22909;&#22788;&#21644;&#23616;&#38480;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06282</link><description>&lt;p&gt;
&#33719;&#21462;&#12289;&#21512;&#24182;&#12289;&#39044;&#27979;&#65306;&#36890;&#36807;&#25968;&#25454;&#28246;&#22686;&#24378;&#34920;&#26684;
&lt;/p&gt;
&lt;p&gt;
Retrieve, Merge, Predict: Augmenting Tables with Data Lakes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#25968;&#25454;&#28246;&#20013;&#30340;&#25968;&#25454;&#21457;&#29616;&#36827;&#34892;&#28145;&#20837;&#20998;&#26512;&#65292;&#30528;&#37325;&#20110;&#34920;&#26684;&#22686;&#24378;&#65292;&#25552;&#20986;&#20102;&#20934;&#30830;&#26816;&#32034;&#36830;&#25509;&#20505;&#36873;&#20154;&#30340;&#37325;&#35201;&#24615;&#21644;&#31616;&#21333;&#21512;&#24182;&#26041;&#27861;&#30340;&#25928;&#29575;&#65292;&#20197;&#21450;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#22909;&#22788;&#21644;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#25968;&#25454;&#28246;&#20013;&#30340;&#25968;&#25454;&#21457;&#29616;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#37325;&#28857;&#26159;&#32473;&#23450;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#30340;&#34920;&#26684;&#22686;&#24378;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19977;&#20010;&#20027;&#35201;&#27493;&#39588;&#20013;&#20351;&#29992;&#30340;&#26367;&#20195;&#26041;&#27861;&#65306;&#26816;&#32034;&#21487;&#36830;&#25509;&#30340;&#34920;&#26684;&#12289;&#21512;&#24182;&#20449;&#24687;&#21644;&#39044;&#27979;&#32467;&#26524;&#34920;&#26684;&#12290;&#20316;&#20026;&#25968;&#25454;&#28246;&#65292;&#26412;&#25991;&#20351;&#29992;&#20102;YADL&#65288;&#21478;&#19968;&#20010;&#25968;&#25454;&#28246;&#65289;-&#25105;&#20204;&#24320;&#21457;&#30340;&#19968;&#31181;&#29992;&#20110;&#22522;&#20934;&#27979;&#35797;&#27492;&#25968;&#25454;&#21457;&#29616;&#20219;&#21153;&#30340;&#26032;&#22411;&#25968;&#25454;&#38598;-&#21644;Open Data US&#65292;&#19968;&#20010;&#34987;&#24341;&#29992;&#30340;&#30495;&#23454;&#25968;&#25454;&#28246;&#12290;&#36890;&#36807;&#23545;&#36825;&#20004;&#20010;&#25968;&#25454;&#28246;&#30340;&#31995;&#32479;&#24615;&#25506;&#32034;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#27010;&#36848;&#20102;&#20934;&#30830;&#26816;&#32034;&#36830;&#25509;&#20505;&#36873;&#20154;&#30340;&#37325;&#35201;&#24615;&#20197;&#21450;&#31616;&#21333;&#21512;&#24182;&#26041;&#27861;&#30340;&#25928;&#29575;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#22909;&#22788;&#21644;&#23616;&#38480;&#24615;&#65292;&#26088;&#22312;&#25351;&#23548;&#26410;&#26469;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an in-depth analysis of data discovery in data lakes, focusing on table augmentation for given machine learning tasks. We analyze alternative methods used in the three main steps: retrieving joinable tables, merging information, and predicting with the resultant table. As data lakes, the paper uses YADL (Yet Another Data Lake) -- a novel dataset we developed as a tool for benchmarking this data discovery task -- and Open Data US, a well-referenced real data lake. Through systematic exploration on both lakes, our study outlines the importance of accurately retrieving join candidates and the efficiency of simple merging methods. We report new insights on the benefits of existing solutions and on their limitations, aiming at guiding future research in this space.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;D-Mapper&#30340;&#20998;&#24067;&#24341;&#23548;Mapper&#31639;&#27861;&#65292;&#20351;&#29992;&#27010;&#29575;&#27169;&#22411;&#21644;&#25968;&#25454;&#22266;&#26377;&#29305;&#24449;&#29983;&#25104;&#23494;&#24230;&#24341;&#23548;&#30340;&#35206;&#30422;&#65292;&#24182;&#25552;&#20379;&#22686;&#24378;&#30340;&#25299;&#25169;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2401.12237</link><description>&lt;p&gt;
&#19968;&#31181;&#20998;&#24067;&#24341;&#23548;&#30340;Mapper&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A distribution-guided Mapper algorithm. (arXiv:2401.12237v1 [math.AT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12237
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;D-Mapper&#30340;&#20998;&#24067;&#24341;&#23548;Mapper&#31639;&#27861;&#65292;&#20351;&#29992;&#27010;&#29575;&#27169;&#22411;&#21644;&#25968;&#25454;&#22266;&#26377;&#29305;&#24449;&#29983;&#25104;&#23494;&#24230;&#24341;&#23548;&#30340;&#35206;&#30422;&#65292;&#24182;&#25552;&#20379;&#22686;&#24378;&#30340;&#25299;&#25169;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#26426;&#65306;Mapper&#31639;&#27861;&#26159;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#25506;&#32034;&#25968;&#25454;&#24418;&#29366;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#20351;&#29992;&#25968;&#25454;&#38598;&#20316;&#20026;&#36755;&#20837;&#65292;Mapper&#31639;&#27861;&#36755;&#20986;&#20195;&#34920;&#25972;&#20010;&#25968;&#25454;&#38598;&#25299;&#25169;&#29305;&#24449;&#30340;&#22270;&#24418;&#12290;&#36825;&#20010;&#22270;&#24418;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#25968;&#25454;&#30340;&#19968;&#20010;Reeb&#22270;&#30340;&#36817;&#20284;&#12290;&#32463;&#20856;&#30340;Mapper&#31639;&#27861;&#20351;&#29992;&#22266;&#23450;&#30340;&#21306;&#38388;&#38271;&#24230;&#21644;&#37325;&#21472;&#27604;&#29575;&#65292;&#36825;&#21487;&#33021;&#26080;&#27861;&#25581;&#31034;&#25968;&#25454;&#30340;&#24494;&#22937;&#29305;&#24449;&#65292;&#23588;&#20854;&#26159;&#24403;&#24213;&#23618;&#32467;&#26500;&#22797;&#26434;&#26102;&#12290;&#32467;&#26524;&#65306;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;D-Mapper&#30340;&#20998;&#24067;&#24341;&#23548;Mapper&#31639;&#27861;&#65292;&#21033;&#29992;&#27010;&#29575;&#27169;&#22411;&#30340;&#23646;&#24615;&#21644;&#25968;&#25454;&#22266;&#26377;&#29305;&#24449;&#29983;&#25104;&#23494;&#24230;&#24341;&#23548;&#30340;&#35206;&#30422;&#65292;&#24182;&#25552;&#20379;&#22686;&#24378;&#30340;&#25299;&#25169;&#29305;&#24449;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20316;&#20026;&#38750;&#27010;&#29575;&#24615;&#26041;&#27861;&#30340;&#26367;&#20195;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24230;&#37327;&#26469;&#32771;&#34385;&#37325;&#21472;&#32858;&#31867;&#30340;&#36136;&#37327;&#21644;&#25193;&#23637;&#25345;&#32493;&#21516;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivation: The Mapper algorithm is an essential tool to explore shape of data in topology data analysis. With a dataset as an input, the Mapper algorithm outputs a graph representing the topological features of the whole dataset. This graph is often regarded as an approximation of a reeb graph of data. The classic Mapper algorithm uses fixed interval lengths and overlapping ratios, which might fail to reveal subtle features of data, especially when the underlying structure is complex.  Results: In this work, we introduce a distribution guided Mapper algorithm named D-Mapper, that utilizes the property of the probability model and data intrinsic characteristics to generate density guided covers and provides enhanced topological features. Our proposed algorithm is a probabilistic model-based approach, which could serve as an alternative to non-prababilistic ones. Moreover, we introduce a metric accounting for both the quality of overlap clustering and extended persistence homology to me
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#20854;&#26799;&#24230;&#65292;&#21363;&#20351;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#12290;&#36825;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#21487;&#35777;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.04535</link><description>&lt;p&gt;
&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;: &#20272;&#35745;&#12289;&#21464;&#37327;&#36873;&#25321;&#21450;&#20854;&#20182;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Deep Sobolev Regression: Estimation, Variable Selection and Beyond. (arXiv:2401.04535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04535
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#20854;&#26799;&#24230;&#65292;&#21363;&#20351;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#12290;&#36825;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#21487;&#35777;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;SDORE&#65292;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#20272;&#35745;&#28508;&#22312;&#30340;&#22238;&#24402;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#12290;SDORE&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#65292;&#24182;&#37319;&#29992;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#20801;&#35768;&#23545;&#26080;&#26631;&#31614;&#25968;&#25454;&#35745;&#31639;&#26799;&#24230;&#33539;&#25968;&#12290;&#25105;&#20204;&#23545;SDORE&#30340;&#25910;&#25947;&#36895;&#24230;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#24314;&#31435;&#20102;&#22238;&#24402;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#26368;&#20248;&#36895;&#29575;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#22312;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#20851;&#32852;&#30340;&#25554;&#20540;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#20026;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#21644;&#30830;&#23450;&#31070;&#32463;&#32593;&#32476;&#30340;&#22823;&#23567;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#20808;&#39564;&#25351;&#23548;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#21487;&#35777;&#20248;&#21183;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;SDORE&#26159;&#31532;&#19968;&#20010;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#30340;&#21487;&#35777;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose SDORE, a semi-supervised deep Sobolev regressor, for the nonparametric estimation of the underlying regression function and its gradient. SDORE employs deep neural networks to minimize empirical risk with gradient norm regularization, allowing computation of the gradient norm on unlabeled data. We conduct a comprehensive analysis of the convergence rates of SDORE and establish a minimax optimal rate for the regression function. Crucially, we also derive a convergence rate for the associated plug-in gradient estimator, even in the presence of significant domain shift. These theoretical findings offer valuable prior guidance for selecting regularization parameters and determining the size of the neural network, while showcasing the provable advantage of leveraging unlabeled data in semi-supervised learning. To the best of our knowledge, SDORE is the first provable neural network-based approach that simultaneously estimates the regression function and its gradient, with diverse
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#27599;&#36718;&#25237;&#24433;&#30340;&#25968;&#37327;&#26469;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08911</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Methods for Non-stationary Online Learning. (arXiv:2309.08911v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08911
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#27599;&#36718;&#25237;&#24433;&#30340;&#25968;&#37327;&#26469;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#29305;&#21035;&#26159;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#65292;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#34987;&#25552;&#20986;&#20316;&#20026;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#20004;&#20010;&#21407;&#21017;&#24615;&#24615;&#33021;&#24230;&#37327;&#12290;&#20026;&#20102;&#20248;&#21270;&#23427;&#20204;&#65292;&#36890;&#24120;&#37319;&#29992;&#20004;&#23618;&#22312;&#32447;&#38598;&#25104;&#65292;&#30001;&#20110;&#38750;&#24179;&#31283;&#24615;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#65292;&#20854;&#20013;&#32500;&#25252;&#19968;&#32452;&#22522;&#23398;&#20064;&#22120;&#65292;&#24182;&#37319;&#29992;&#20803;&#31639;&#27861;&#22312;&#36816;&#34892;&#36807;&#31243;&#20013;&#36319;&#36394;&#26368;&#20339;&#23398;&#20064;&#22120;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20004;&#23618;&#32467;&#26500;&#24341;&#21457;&#20102;&#20851;&#20110;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#25285;&#24551; -&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#21516;&#26102;&#32500;&#25252;$\mathcal{O}(\log T)$&#20010;&#22522;&#23398;&#20064;&#22120;&#65292;&#23545;&#20110;&#19968;&#20010;$T$&#36718;&#22312;&#32447;&#28216;&#25103;&#65292;&#22240;&#27492;&#27599;&#36718;&#25191;&#34892;&#22810;&#27425;&#25237;&#24433;&#21040;&#21487;&#34892;&#22495;&#19978;&#65292;&#24403;&#22495;&#24456;&#22797;&#26434;&#26102;&#65292;&#36825;&#25104;&#20026;&#35745;&#31639;&#29942;&#39048;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#23558;&#27599;&#36718;&#30340;&#25237;&#24433;&#27425;&#25968;&#20174;$\mathcal{O}(\log T)$&#38477;&#20302;&#21040;...
&lt;/p&gt;
&lt;p&gt;
Non-stationary online learning has drawn much attention in recent years. In particular, dynamic regret and adaptive regret are proposed as two principled performance measures for online convex optimization in non-stationary environments. To optimize them, a two-layer online ensemble is usually deployed due to the inherent uncertainty of the non-stationarity, in which a group of base-learners are maintained and a meta-algorithm is employed to track the best one on the fly. However, the two-layer structure raises the concern about the computational complexity -- those methods typically maintain $\mathcal{O}(\log T)$ base-learners simultaneously for a $T$-round online game and thus perform multiple projections onto the feasible domain per round, which becomes the computational bottleneck when the domain is complicated. In this paper, we present efficient methods for optimizing dynamic regret and adaptive regret, which reduce the number of projections per round from $\mathcal{O}(\log T)$ t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#36229;&#36793;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#33410;&#28857;&#32858;&#21512;&#21644;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26469;&#35299;&#20915;&#36229;&#36793;&#39044;&#27979;&#20013;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#25429;&#25417;&#33410;&#28857;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#32531;&#35299;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.05798</link><description>&lt;p&gt;
&#22686;&#24378;&#19978;&#19979;&#25991;&#24863;&#30693;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#36229;&#36793;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Enhancing Hyperedge Prediction with Context-Aware Self-Supervised Learning. (arXiv:2309.05798v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05798
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#36229;&#36793;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#33410;&#28857;&#32858;&#21512;&#21644;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26469;&#35299;&#20915;&#36229;&#36793;&#39044;&#27979;&#20013;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#25429;&#25417;&#33410;&#28857;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#32531;&#35299;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#21487;&#20197;&#33258;&#28982;&#22320;&#24314;&#27169;&#32676;&#32452;&#20851;&#31995;&#65288;&#20363;&#22914;&#65292;&#19968;&#32452;&#20849;&#21516;&#36141;&#20080;&#29289;&#21697;&#30340;&#29992;&#25143;&#65289;&#65292;hyperedge&#39044;&#27979;&#26159;&#39044;&#27979;&#26410;&#26469;&#25110;&#26410;&#35266;&#23519;&#21040;&#30340;&#36229;&#36793;&#30340;&#20219;&#21153;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#37117;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#30740;&#31350;&#20013;&#24456;&#23569;&#25506;&#35752;&#20197;&#19979;&#25361;&#25112;&#65306;&#65288;C1&#65289;&#22914;&#20309;&#32858;&#21512;&#27599;&#20010;&#36229;&#36793;&#20505;&#36873;&#20013;&#30340;&#33410;&#28857;&#20197;&#20934;&#30830;&#39044;&#27979;&#36229;&#36793;&#65311;&#65288;C2&#65289;&#22914;&#20309;&#32531;&#35299;&#36229;&#36793;&#39044;&#27979;&#20013;&#22266;&#26377;&#30340;&#25968;&#25454;&#31232;&#30095;&#38382;&#39064;&#65311;&#20026;&#20102;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36229;&#36793;&#39044;&#27979;&#26694;&#26550;CASH&#65292;&#23427;&#37319;&#29992;&#20102;&#65288;1&#65289;&#19978;&#19979;&#25991;&#24863;&#30693;&#33410;&#28857;&#32858;&#21512;&#65292;&#31934;&#30830;&#25429;&#25417;&#27599;&#20010;&#36229;&#36793;&#20013;&#33410;&#28857;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#29992;&#20110;&#35299;&#20915;&#25361;&#25112;&#65288;C1&#65289;&#65292;&#20197;&#21450;&#65288;2&#65289;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#22312;&#36229;&#36793;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#22686;&#24378;&#36229;&#22270;&#34920;&#31034;&#65292;&#20197;&#24212;&#23545;&#25361;&#25112;&#65288;C2&#65289;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#25361;&#25112;&#65288;C2&#65289;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36229;&#36793;&#24863;&#30693;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs can naturally model group-wise relations (e.g., a group of users who co-purchase an item) as hyperedges. Hyperedge prediction is to predict future or unobserved hyperedges, which is a fundamental task in many real-world applications (e.g., group recommendation). Despite the recent breakthrough of hyperedge prediction methods, the following challenges have been rarely studied: (C1) How to aggregate the nodes in each hyperedge candidate for accurate hyperedge prediction? and (C2) How to mitigate the inherent data sparsity problem in hyperedge prediction? To tackle both challenges together, in this paper, we propose a novel hyperedge prediction framework (CASH) that employs (1) context-aware node aggregation to precisely capture complex relations among nodes in each hyperedge for (C1) and (2) self-supervised contrastive learning in the context of hyperedge prediction to enhance hypergraph representations for (C2). Furthermore, as for (C2), we propose a hyperedge-aware augmenta
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#20010;&#30005;&#36335;&#35745;&#31639;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#25152;&#26377;&#21442;&#25968;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#36739;&#20302;&#30340;&#30005;&#36335;&#28145;&#24230;&#21644;&#36739;&#23569;&#30340;&#32534;&#35793;&#26102;&#38388;&#65292;&#20174;&#32780;&#21152;&#36895;&#20102;&#24635;&#20307;&#36816;&#34892;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2307.08167</link><description>&lt;p&gt;
&#20351;&#29992;&#21333;&#20010;&#30005;&#36335;&#35745;&#31639;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#25152;&#26377;&#21442;&#25968;&#30340;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Computing the gradients with respect to all parameters of a quantum neural network using a single circuit. (arXiv:2307.08167v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08167
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#20010;&#30005;&#36335;&#35745;&#31639;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#25152;&#26377;&#21442;&#25968;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#36739;&#20302;&#30340;&#30005;&#36335;&#28145;&#24230;&#21644;&#36739;&#23569;&#30340;&#32534;&#35793;&#26102;&#38388;&#65292;&#20174;&#32780;&#21152;&#36895;&#20102;&#24635;&#20307;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20351;&#29992;&#21442;&#25968;&#24179;&#31227;&#35268;&#21017;&#35745;&#31639;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#26102;&#65292;&#38656;&#35201;&#23545;&#32593;&#32476;&#30340;&#21333;&#20010;&#21487;&#35843;&#21442;&#25968;&#35745;&#31639;&#20004;&#27425;&#20195;&#20215;&#20989;&#25968;&#12290;&#24403;&#21442;&#25968;&#24635;&#25968;&#36739;&#39640;&#26102;&#65292;&#38656;&#35201;&#35843;&#25972;&#21644;&#36816;&#34892;&#22810;&#27425;&#29992;&#20110;&#35745;&#31639;&#30340;&#37327;&#23376;&#30005;&#36335;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20351;&#29992;&#19968;&#20010;&#30005;&#36335;&#35745;&#31639;&#25152;&#26377;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#36739;&#20302;&#30340;&#30005;&#36335;&#28145;&#24230;&#21644;&#36739;&#23569;&#30340;&#32463;&#20856;&#23492;&#23384;&#22120;&#12290;&#25105;&#20204;&#36824;&#22312;&#30495;&#23454;&#37327;&#23376;&#30828;&#20214;&#21644;&#27169;&#25311;&#22120;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#30005;&#36335;&#32534;&#35793;&#26102;&#38388;&#26126;&#26174;&#32553;&#30701;&#30340;&#20248;&#21183;&#65292;&#20174;&#32780;&#21152;&#36895;&#20102;&#24635;&#20307;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
When computing the gradients of a quantum neural network using the parameter-shift rule, the cost function needs to be calculated twice for the gradient with respect to a single adjustable parameter of the network. When the total number of parameters is high, the quantum circuit for the computation has to be adjusted and run for many times. Here we propose an approach to compute all the gradients using a single circuit only, with a much reduced circuit depth and less classical registers. We also demonstrate experimentally, on both real quantum hardware and simulator, that our approach has the advantages that the circuit takes a significantly shorter time to compile than the conventional approach, resulting in a speedup on the total runtime.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.10656</link><description>&lt;p&gt;
&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65306;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20154;&#31867;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21307;&#30103;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#21892;&#36523;&#20307;&#21644;&#31934;&#31070;&#29366;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65288;VHGM&#65289;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#26377;&#20851;&#21307;&#30103;&#20445;&#20581;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20010;&#24615;&#30340;&#23646;&#24615;&#12290;VHGM&#26159;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20351;&#29992;&#25513;&#30721;&#24314;&#27169;&#35757;&#32451;&#65292;&#22312;&#24050;&#30693;&#23646;&#24615;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#23646;&#24615;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#21033;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#39640;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#25968;&#20540;&#35780;&#20272;&#20102;VHGM&#21450;&#20854;&#35757;&#32451;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20316;&#20026;VHGM&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#24212;&#29992;&#31243;&#24207;&#65292;&#28436;&#31034;&#20102;&#29992;&#25143;&#24773;&#22659;&#65292;&#20363;&#22914;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#26469;&#20248;&#21270;&#20219;&#20309;&#32452;&#21512;&#30340;&#21487;&#20998;&#31163;&#30446;&#26631;&#21644;&#32422;&#26463;&#26465;&#20214;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#27604;&#36890;&#29992;&#27714;&#35299;&#22120;&#34920;&#29616;&#24471;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.19706</link><description>&lt;p&gt;
&#21487;&#20998;&#30446;&#26631;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#65306;&#25512;&#21160;&#21160;&#24577;&#35268;&#21010;&#30340;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Optimal Decision Trees for Separable Objectives: Pushing the Limits of Dynamic Programming. (arXiv:2305.19706v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19706
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#26469;&#20248;&#21270;&#20219;&#20309;&#32452;&#21512;&#30340;&#21487;&#20998;&#31163;&#30446;&#26631;&#21644;&#32422;&#26463;&#26465;&#20214;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#27604;&#36890;&#29992;&#27714;&#35299;&#22120;&#34920;&#29616;&#24471;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26641;&#30340;&#20840;&#23616;&#20248;&#21270;&#22312;&#20934;&#30830;&#24615;&#65292;&#22823;&#23567;&#21644;&#20154;&#31867;&#21487;&#29702;&#35299;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#21069;&#26223;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26041;&#27861;&#20173;&#28982;&#20381;&#36182;&#20110;&#36890;&#29992;&#27714;&#35299;&#22120;&#65292;&#21487;&#25193;&#23637;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#38382;&#39064;&#12290;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#26356;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#36890;&#36807;&#23558;&#23376;&#26641;&#20316;&#20026;&#29420;&#31435;&#30340;&#23376;&#38382;&#39064;&#35299;&#20915;&#26469;&#21033;&#29992;&#26641;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#36825;&#20165;&#36866;&#29992;&#20110;&#21487;&#20197;&#20998;&#21035;&#20248;&#21270;&#23376;&#26641;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#35814;&#32454;&#30740;&#31350;&#20102;&#36825;&#31181;&#20851;&#31995;&#65292;&#24182;&#23637;&#31034;&#20102;&#23454;&#29616;&#36825;&#31181;&#21487;&#20998;&#31163;&#32422;&#26463;&#21644;&#30446;&#26631;&#20219;&#24847;&#32452;&#21512;&#30340;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#12290;&#22312;&#22235;&#20010;&#24212;&#29992;&#39046;&#22495;&#30340;&#23454;&#39564;&#34920;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26222;&#36866;&#24615;&#65292;&#21516;&#26102;&#20063;&#27604;&#36890;&#29992;&#27714;&#35299;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Global optimization of decision trees has shown to be promising in terms of accuracy, size, and consequently human comprehensibility. However, many of the methods used rely on general-purpose solvers for which scalability remains an issue. Dynamic programming methods have been shown to scale much better because they exploit the tree structure by solving subtrees as independent subproblems. However, this only works when an objective can be optimized separately for subtrees. We explore this relationship in detail and show necessary and sufficient conditions for such separability and generalize previous dynamic programming approaches into a framework that can optimize any combination of separable objectives and constraints. Experiments on four application domains show the general applicability of this framework, while outperforming the scalability of general-purpose solvers by a large margin.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;GAN&#30340;&#31616;&#21270;&#24314;&#27169;&#26041;&#27861;GAROM&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#65292;&#33021;&#22815;&#23398;&#20064;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#65292;&#24182;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.15881</link><description>&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#31616;&#21270;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Reduced Order Modelling. (arXiv:2305.15881v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15881
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;GAN&#30340;&#31616;&#21270;&#24314;&#27169;&#26041;&#27861;GAROM&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#65292;&#33021;&#22815;&#23398;&#20064;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#65292;&#24182;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30340;&#31616;&#21270;&#24314;&#27169;&#26041;&#27861;&#8212;&#8212;GAROM&#12290;GAN&#22312;&#22810;&#20010;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#22312;&#31616;&#21270;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#21364;&#40092;&#26377;&#30740;&#31350;&#12290;&#25105;&#20204;&#23558;GAN&#21644;ROM&#26694;&#26550;&#30456;&#32467;&#21512;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#65292;&#33021;&#22815;&#23398;&#20064;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#12290;&#25105;&#20204;&#23558;&#37492;&#21035;&#22120;&#32593;&#32476;&#24314;&#27169;&#20026;&#33258;&#32534;&#30721;&#22120;&#65292;&#25552;&#21462;&#36755;&#20837;&#30340;&#30456;&#20851;&#29305;&#24449;&#65292;&#24182;&#23558;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#20316;&#20026;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#32593;&#32476;&#30340;&#36755;&#20837;&#26465;&#20214;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#25512;&#26029;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#25454;&#35777;&#26126;&#20102;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#36827;&#34892;&#20102;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we present GAROM, a new approach for reduced order modelling (ROM) based on generative adversarial networks (GANs). GANs have the potential to learn data distribution and generate more realistic data. While widely applied in many areas of deep learning, little research is done on their application for ROM, i.e. approximating a high-fidelity model with a simpler one. In this work, we combine the GAN and ROM framework, by introducing a data-driven generative adversarial model able to learn solutions to parametric differential equations. The latter is achieved by modelling the discriminator network as an autoencoder, extracting relevant features of the input, and applying a conditioning mechanism to the generator and discriminator networks specifying the differential equation parameters. We show how to apply our methodology for inference, provide experimental evidence of the model generalisation, and perform a convergence study of the method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20307;&#31995;&#32467;&#26500;&#65292;&#29983;&#25104;&#27169;&#22411;&#38598;&#25104;&#31070;&#32463;&#32593;&#32476;&#65288;MINN&#65289;&#20197;&#20801;&#35768;&#22312;&#23398;&#20064;&#31995;&#32479;&#29289;&#29702;&#21160;&#24577;&#26041;&#38754;&#36827;&#34892;&#25972;&#21512;&#65292;&#24212;&#29992;&#20110;&#38146;&#31163;&#23376;&#30005;&#27744;&#30340;&#30005;&#21270;&#23398;&#21160;&#21147;&#23398;&#24314;&#27169;&#65292;&#24182;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#35299;&#37322;&#24615;&#12289;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2304.14422</link><description>&lt;p&gt;
MINN&#65306;&#23398;&#20064;&#24494;&#20998;&#20195;&#25968;&#26041;&#31243;&#30340;&#21160;&#24577;&#21644;&#24212;&#29992;&#20110;&#30005;&#27744;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
MINN: Learning the dynamics of differential-algebraic equations and application to battery modeling. (arXiv:2304.14422v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20307;&#31995;&#32467;&#26500;&#65292;&#29983;&#25104;&#27169;&#22411;&#38598;&#25104;&#31070;&#32463;&#32593;&#32476;&#65288;MINN&#65289;&#20197;&#20801;&#35768;&#22312;&#23398;&#20064;&#31995;&#32479;&#29289;&#29702;&#21160;&#24577;&#26041;&#38754;&#36827;&#34892;&#25972;&#21512;&#65292;&#24212;&#29992;&#20110;&#38146;&#31163;&#23376;&#30005;&#27744;&#30340;&#30005;&#21270;&#23398;&#21160;&#21147;&#23398;&#24314;&#27169;&#65292;&#24182;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#35299;&#37322;&#24615;&#12289;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25972;&#21512;&#22522;&#20110;&#29289;&#29702;&#21644;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#24050;&#32463;&#25104;&#20026;&#24314;&#27169;&#21487;&#25345;&#32493;&#33021;&#28304;&#31995;&#32479;&#30340;&#24120;&#35265;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#29616;&#26377;&#30340;&#25991;&#29486;&#20027;&#35201;&#38598;&#20013;&#22312;&#29983;&#25104;&#29992;&#20110;&#26367;&#20195;&#22522;&#20110;&#29289;&#29702;&#27169;&#22411;&#30340;&#25968;&#25454;&#39537;&#21160;&#26367;&#20195;&#27169;&#22411;&#19978;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20197;&#36895;&#24230;&#20026;&#20195;&#20215;&#25442;&#21462;&#31934;&#24230;&#65292;&#20294;&#32570;&#20047;&#22522;&#20110;&#29289;&#29702;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#12289;&#36866;&#24212;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#32780;&#36825;&#20123;&#29305;&#28857;&#22312;&#20248;&#21270;&#21644;&#25511;&#21046;&#23454;&#38469;&#21160;&#24577;&#31995;&#32479;&#30340;&#24314;&#27169;&#20013;&#36890;&#24120;&#26159;&#19981;&#21487;&#25110;&#32570;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20307;&#31995;&#32467;&#26500;&#26469;&#29983;&#25104;&#27169;&#22411;&#38598;&#25104;&#31070;&#32463;&#32593;&#32476;&#65288;MINN&#65289;&#65292;&#20197;&#20801;&#35768;&#22312;&#23398;&#20064;&#31995;&#32479;&#29289;&#29702;&#21160;&#24577;&#26041;&#38754;&#36827;&#34892;&#25972;&#21512;&#12290;&#33719;&#24471;&#30340;&#28151;&#21512;&#27169;&#22411;&#35299;&#20915;&#20102;&#25511;&#21046;&#23548;&#21521;&#24314;&#27169;&#20013;&#19968;&#20010;&#23578;&#26410;&#35299;&#20915;&#30340;&#30740;&#31350;&#38382;&#39064;&#65292;&#21363;&#22914;&#20309;&#21516;&#26102;&#33719;&#24471;&#29289;&#29702;&#27934;&#23519;&#21147;&#12289;&#25968;&#23383;&#31934;&#24230;&#21644;&#35745;&#31639;&#21487;&#34892;&#24615;&#30340;&#26368;&#20248;&#31616;&#21270;&#27169;&#22411;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#24212;&#29992;&#20110;&#38146;&#31163;&#23376;&#30005;&#27744;&#30340;&#30005;&#21270;&#23398;&#21160;&#21147;&#23398;&#24314;&#27169;&#65292;&#24182;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#35299;&#37322;&#24615;&#12289;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
The concept of integrating physics-based and data-driven approaches has become popular for modeling sustainable energy systems. However, the existing literature mainly focuses on the data-driven surrogates generated to replace physics-based models. These models often trade accuracy for speed but lack the generalisability, adaptability, and interpretability inherent in physics-based models, which are often indispensable in the modeling of real-world dynamic systems for optimization and control purposes. In this work, we propose a novel architecture for generating model-integrated neural networks (MINN) to allow integration on the level of learning physics-based dynamics of the system. The obtained hybrid model solves an unsettled research problem in control-oriented modeling, i.e., how to obtain an optimally simplified model that is physically insightful, numerically accurate, and computationally tractable simultaneously. We apply the proposed neural network architecture to model the el
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;ClusterNet&#65292;&#19968;&#31181;&#22522;&#20110;&#24863;&#30693;&#30340;&#20998;&#24067;&#24335;&#25968;&#25454;&#32858;&#31867;&#27169;&#22411;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#22522;&#20110;&#28857;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21453;&#26144;&#20154;&#31867;&#24863;&#30693;&#30340;&#32858;&#31867;&#21487;&#20998;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.14185</link><description>&lt;p&gt;
ClusterNet&#65306;&#19968;&#31181;&#22522;&#20110;&#24863;&#30693;&#30340;&#20998;&#24067;&#24335;&#25968;&#25454;&#32858;&#31867;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ClusterNet: A Perception-Based Clustering Model for Scattered Data. (arXiv:2304.14185v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14185
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;ClusterNet&#65292;&#19968;&#31181;&#22522;&#20110;&#24863;&#30693;&#30340;&#20998;&#24067;&#24335;&#25968;&#25454;&#32858;&#31867;&#27169;&#22411;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#22522;&#20110;&#28857;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21453;&#26144;&#20154;&#31867;&#24863;&#30693;&#30340;&#32858;&#31867;&#21487;&#20998;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25955;&#28857;&#22270;&#20013;&#30340;&#32858;&#31867;&#20998;&#31163;&#26159;&#19968;&#20010;&#36890;&#24120;&#30001;&#24191;&#27867;&#20351;&#29992;&#30340;&#32858;&#31867;&#25216;&#26415;&#65288;&#20363;&#22914;k-means&#25110;DBSCAN&#65289;&#26469;&#35299;&#20915;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#20123;&#31639;&#27861;&#22522;&#20110;&#38750;&#24863;&#30693;&#24230;&#37327;&#65292;&#23427;&#20204;&#30340;&#36755;&#20986;&#32463;&#24120;&#19981;&#33021;&#21453;&#26144;&#20986;&#20154;&#31867;&#32858;&#31867;&#24863;&#30693;&#12290;&#20026;&#20102;&#24357;&#21512;&#20154;&#31867;&#32858;&#31867;&#24863;&#30693;&#21644;&#26426;&#22120;&#35745;&#31639;&#32858;&#31867;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#22788;&#29702;&#20998;&#24067;&#24335;&#25968;&#25454;&#30340;&#23398;&#20064;&#31574;&#30053;&#12290;&#20026;&#20102;&#22312;&#36825;&#20123;&#25968;&#25454;&#19978;&#23398;&#20064;&#24863;&#30693;&#32858;&#31867;&#20998;&#31163;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#20247;&#21253;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#24037;&#20316;&#65292;&#20854;&#20013;&#21253;&#25324;384&#20010;&#20154;&#32676;&#24037;&#20316;&#32773;&#23545;&#21452;&#21464;&#37327;&#25968;&#25454;&#30340;7,320&#20010;&#28857;&#32858;&#31867;&#20174;&#23646;&#36827;&#34892;&#20102;&#26631;&#35760;&#12290;&#22522;&#20110;&#36825;&#20123;&#25968;&#25454;&#65292;&#25105;&#20204;&#33021;&#22815;&#35757;&#32451;ClusterNet&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#28857;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#34987;&#35757;&#32451;&#25104;&#21453;&#26144;&#20154;&#31867;&#24863;&#30693;&#30340;&#32858;&#31867;&#21487;&#20998;&#24615;&#12290;&#20026;&#20102;&#22312;&#20154;&#31867;&#27880;&#37322;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;ClusterNet&#65292;&#25105;&#20204;&#30465;&#30053;&#20102;&#22312;2D&#30011;&#24067;&#19978;&#28210;&#26579;&#25955;&#28857;&#22270;&#65292;&#32780;&#26159;&#20351;&#29992;&#20102;&#19968;&#20010;PointNet++&#26550;&#26500;&#65292;&#20351;&#20854;&#33021;&#22815;&#30452;&#25509;&#25512;&#29702;&#28857;&#20113;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#22522;&#20110;&#24863;&#30693;&#30340;&#20998;&#24067;&#24335;&#25968;&#25454;&#32858;&#31867;&#27169;&#22411;&#65292;ClusterNet&#12290;
&lt;/p&gt;
&lt;p&gt;
Cluster separation in scatterplots is a task that is typically tackled by widely used clustering techniques, such as for instance k-means or DBSCAN. However, as these algorithms are based on non-perceptual metrics, their output often does not reflect human cluster perception. To bridge the gap between human cluster perception and machine-computed clusters, we propose a learning strategy which directly operates on scattered data. To learn perceptual cluster separation on this data, we crowdsourced a large scale dataset, consisting of 7,320 point-wise cluster affiliations for bivariate data, which has been labeled by 384 human crowd workers. Based on this data, we were able to train ClusterNet, a point-based deep learning model, trained to reflect human perception of cluster separability. In order to train ClusterNet on human annotated data, we omit rendering scatterplots on a 2D canvas, but rather use a PointNet++ architecture enabling inference on point clouds directly. In this work, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#36172;&#21338;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#33258;&#36866;&#24212;&#36873;&#25321;&#21738;&#20123;&#23458;&#25143;&#31471;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#35757;&#32451;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#35813;&#31639;&#27861;&#21487;&#25552;&#39640;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2112.14332</link><description>&lt;p&gt;
&#22522;&#20110;&#36172;&#21338;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;&#33258;&#36866;&#24212;&#23458;&#25143;&#31471;&#37319;&#26679;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Adaptive Client Sampling in Federated Learning via Online Learning with Bandit Feedback. (arXiv:2112.14332v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.14332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#36172;&#21338;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#33258;&#36866;&#24212;&#36873;&#25321;&#21738;&#20123;&#23458;&#25143;&#31471;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#35757;&#32451;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#35813;&#31639;&#27861;&#21487;&#25552;&#39640;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#36890;&#20449;&#25104;&#26412;&#39640;&#65292;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#31995;&#32479;&#38656;&#35201;&#37319;&#26679;&#19968;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#27599;&#19968;&#36718;&#35757;&#32451;&#12290;&#22240;&#27492;&#65292;&#23458;&#25143;&#31471;&#37319;&#26679;&#22312;FL&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#20316;&#29992;&#65292;&#23427;&#24433;&#21709;&#29992;&#20110;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#23613;&#31649;&#20855;&#26377;&#37325;&#35201;&#24615;&#65292;&#20294;&#26377;&#25928;&#37319;&#26679;&#23458;&#25143;&#31471;&#26041;&#38754;&#30340;&#30740;&#31350;&#24456;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#23458;&#25143;&#31471;&#37319;&#26679;&#24314;&#27169;&#20026;&#22312;&#24102;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;&#20219;&#21153;&#65292;&#20351;&#29992;&#22312;&#32447;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#65288;OSMD&#65289;&#31639;&#27861;&#26469;&#26368;&#23567;&#21270;&#37319;&#26679;&#26041;&#24046;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#37319;&#26679;&#26041;&#27861;&#22914;&#20309;&#25552;&#39640;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#20026;&#20102;&#22788;&#29702;OSMD&#20013;&#20381;&#36182;&#20110;&#26410;&#30693;&#38382;&#39064;&#21442;&#25968;&#30340;&#35843;&#25972;&#21442;&#25968;&#65292;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;&#38598;&#25104;&#26041;&#27861;&#21644;&#32763;&#20493;&#25216;&#24039;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#30456;&#23545;&#20110;&#20219;&#20309;&#37319;&#26679;&#24207;&#21015;&#30340;&#21160;&#24577;&#36951;&#25022;&#30028;&#12290;&#36951;&#25022;&#30028;&#21462;&#20915;&#20110;&#27604;&#36739;&#24207;&#21015;&#30340;&#24635;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the high cost of communication, federated learning (FL) systems need to sample a subset of clients that are involved in each round of training. As a result, client sampling plays an important role in FL systems as it affects the convergence rate of optimization algorithms used to train machine learning models. Despite its importance, there is limited work on how to sample clients effectively. In this paper, we cast client sampling as an online learning task with bandit feedback, which we solve with an online stochastic mirror descent (OSMD) algorithm designed to minimize the sampling variance. We then theoretically show how our sampling method can improve the convergence speed of optimization algorithms. To handle the tuning parameters in OSMD that depend on the unknown problem parameters, we use the online ensemble method and doubling trick. We prove a dynamic regret bound relative to any sampling sequence. The regret bound depends on the total variation of the comparator seque
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#65292;&#25552;&#39640;&#20102;&#22312;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#20272;&#35745;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.06818</link><description>&lt;p&gt;
&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#65306;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Dynamic treatment effects: high-dimensional inference under model misspecification. (arXiv:2111.06818v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.06818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#65292;&#25552;&#39640;&#20102;&#22312;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#20272;&#35745;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#22312;&#21508;&#20010;&#23398;&#31185;&#20013;&#37117;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#21487;&#20197;&#25552;&#20379;&#26377;&#20851;&#24178;&#39044;&#30340;&#26102;&#21464;&#22240;&#26524;&#24433;&#21709;&#30340;&#24494;&#22937;&#35265;&#35299;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#8220;&#32500;&#25968;&#28798;&#38590;&#8221;&#21644;&#26102;&#21464;&#28151;&#26434;&#30340;&#23384;&#22312;&#65292;&#36825;&#31181;&#20272;&#35745;&#23384;&#22312;&#30528;&#25361;&#25112;&#65292;&#21487;&#33021;&#23548;&#33268;&#20272;&#35745;&#20559;&#35823;&#12290;&#27492;&#22806;&#65292;&#27491;&#30830;&#22320;&#35268;&#23450;&#26085;&#30410;&#22686;&#22810;&#30340;&#27835;&#30103;&#20998;&#37197;&#21644;&#22810;&#37325;&#26292;&#38706;&#30340;&#32467;&#26524;&#27169;&#22411;&#20284;&#20046;&#36807;&#20110;&#22797;&#26434;&#12290;&#37492;&#20110;&#36825;&#20123;&#25361;&#25112;&#65292;&#21452;&#37325;&#40065;&#26834;&#24615;&#30340;&#27010;&#24565;&#65292;&#22312;&#20801;&#35768;&#27169;&#22411;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#65292;&#26159;&#38750;&#24120;&#26377;&#20215;&#20540;&#30340;&#65292;&#28982;&#32780;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24182;&#27809;&#26377;&#23454;&#29616;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21516;&#26102;&#23545;&#27835;&#30103;&#20998;&#37197;&#21644;&#32467;&#26524;&#27169;&#22411;&#36827;&#34892;&#40065;&#26834;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#24207;&#21015;&#27169;&#22411;&#21452;&#37325;&#40065;&#26834;&#24615;&#8221;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#24403;&#27599;&#20010;&#26102;&#38388;&#26292;&#38706;&#37117;&#26159;&#21452;&#37325;&#40065;&#26834;&#24615;&#30340;&#26102;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#26102;&#38388;&#28857;&#19978;&#23454;&#29616;&#21452;&#37325;&#40065;&#26834;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#39640;&#20102;&#39640;&#32500;&#29615;&#22659;&#19979;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating dynamic treatment effects is essential across various disciplines, offering nuanced insights into the time-dependent causal impact of interventions. However, this estimation presents challenges due to the "curse of dimensionality" and time-varying confounding, which can lead to biased estimates. Additionally, correctly specifying the growing number of treatment assignments and outcome models with multiple exposures seems overly complex. Given these challenges, the concept of double robustness, where model misspecification is permitted, is extremely valuable, yet unachieved in practical applications. This paper introduces a new approach by proposing novel, robust estimators for both treatment assignments and outcome models. We present a "sequential model double robust" solution, demonstrating that double robustness over multiple time points can be achieved when each time exposure is doubly robust. This approach improves the robustness and reliability of dynamic treatment effe
&lt;/p&gt;</description></item></channel></rss>