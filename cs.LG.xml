<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.19516</link><description>&lt;p&gt;
&#38024;&#23545;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation on Stochastic Blockmodels for Directed Graph Clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19516
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#23398;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#23558;&#32858;&#31867;&#38382;&#39064;&#24314;&#27169;&#20026;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;DSBM&#65289;&#20013;&#28508;&#22312;&#31038;&#21306;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#23545;DSBM&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#65292;&#20174;&#32780;&#30830;&#23450;&#32473;&#23450;&#35266;&#23519;&#21040;&#30340;&#22270;&#32467;&#26500;&#26102;&#26368;&#21487;&#33021;&#30340;&#31038;&#21306;&#20998;&#37197;&#12290;&#38500;&#20102;&#32479;&#35745;&#35266;&#28857;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24314;&#31435;&#20102;&#36825;&#31181;MLE&#20844;&#24335;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#27969;&#20248;&#21270;&#21551;&#21457;&#24335;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#35813;&#21551;&#21457;&#24335;&#21516;&#26102;&#32771;&#34385;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#26377;&#21521;&#22270;&#32479;&#35745;&#37327;&#65306;&#36793;&#23494;&#24230;&#21644;&#36793;&#26041;&#21521;&#12290;&#22522;&#20110;&#36825;&#31181;&#26377;&#21521;&#32858;&#31867;&#30340;&#26032;&#20844;&#24335;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#65292;&#20998;&#21035;&#26159;&#35889;&#32858;&#31867;&#31639;&#27861;&#21644;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#25105;&#20204;&#20026;&#35889;&#32858;&#31867;&#31639;&#27861;&#30340;&#38169;&#35823;&#32858;&#31867;&#39030;&#28857;&#25968;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19516v1 Announce Type: cross  Abstract: This paper studies the directed graph clustering problem through the lens of statistics, where we formulate clustering as estimating underlying communities in the directed stochastic block model (DSBM). We conduct the maximum likelihood estimation (MLE) on the DSBM and thereby ascertain the most probable community assignment given the observed graph structure. In addition to the statistical point of view, we further establish the equivalence between this MLE formulation and a novel flow optimization heuristic, which jointly considers two important directed graph statistics: edge density and edge orientation. Building on this new formulation of directed clustering, we introduce two efficient and interpretable directed clustering algorithms, a spectral clustering algorithm and a semidefinite programming based clustering algorithm. We provide a theoretical upper bound on the number of misclustered vertices of the spectral clustering algor
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Deep Sign-Preserving WENO&#65288;DSP-WENO&#65289;&#30340;&#21464;&#31181;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;WENO&#21152;&#26435;&#31574;&#30053;&#65292;&#20197;&#25913;&#36827;&#22312;&#38663;&#33633;&#38468;&#36817;&#34920;&#29616;&#19981;&#20339;&#30340;WENO&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.14848</link><description>&lt;p&gt;
&#23398;&#20064;WENO&#29992;&#20110;&#29109;&#31283;&#23450;&#26041;&#26696;&#20197;&#35299;&#20915;&#23432;&#24658;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
Learning WENO for entropy stable schemes to solve conservation laws
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14848
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Deep Sign-Preserving WENO&#65288;DSP-WENO&#65289;&#30340;&#21464;&#31181;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;WENO&#21152;&#26435;&#31574;&#30053;&#65292;&#20197;&#25913;&#36827;&#22312;&#38663;&#33633;&#38468;&#36817;&#34920;&#29616;&#19981;&#20339;&#30340;WENO&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29109;&#26465;&#20214;&#22312;&#25552;&#21462;&#31995;&#32479;&#23432;&#24658;&#24459;&#30340;&#29289;&#29702;&#30456;&#20851;&#35299;&#26102;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#22240;&#27492;&#20419;&#20351;&#26500;&#24314;&#28385;&#36275;&#31163;&#25955;&#26465;&#20214;&#30340;&#29109;&#31283;&#23450;&#26041;&#26696;&#12290; TeCNO&#26041;&#26696;&#65288;Fjordholm&#31561;&#65292;2012&#65289;&#24418;&#25104;&#20102;&#19968;&#31867;&#20219;&#24847;&#39640;&#38454;&#29109;&#31283;&#23450;&#26377;&#38480;&#24046;&#20998;&#27714;&#35299;&#22120;&#65292;&#23427;&#20204;&#38656;&#35201;&#28385;&#36275;&#27599;&#20010;&#21333;&#20803;&#26684;&#30028;&#38754;&#30340;&#31526;&#21495;&#29305;&#24615;&#30340;&#19987;&#19994;&#37325;&#26500;&#31639;&#27861;&#12290;&#26368;&#36817;&#65292;&#35774;&#35745;&#20102;&#28385;&#36275;&#31526;&#21495;&#29305;&#24615;&#30340;&#31532;&#19977;&#38454;WENO&#26041;&#26696;&#65292;&#31216;&#20026;SP-WENO&#65288;Fjordholm&#21644;Ray&#65292;2016&#65289;&#21644;SP-WENOc&#65288;Ray&#65292;2018&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;WENO&#31639;&#27861;&#22312;&#38663;&#33633;&#38468;&#36817;&#30340;&#24615;&#33021;&#21487;&#33021;&#24456;&#24046;&#65292;&#25968;&#20540;&#35299;&#34920;&#29616;&#20986;&#22823;&#30340;&#20154;&#24037;&#25391;&#33633;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SP-WENO&#30340;&#19968;&#20010;&#21464;&#31181;&#65292;&#31216;&#20026;Deep Sign-Preserving WENO&#65288;DSP-WENO&#65289;&#65292;&#22312;&#20854;&#20013;&#65292;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#34987;&#35757;&#32451;&#26469;&#23398;&#20064;WENO&#21152;&#26435;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14848v1 Announce Type: cross  Abstract: Entropy conditions play a crucial role in the extraction of a physically relevant solution for a system of conservation laws, thus motivating the construction of entropy stable schemes that satisfy a discrete analogue of such conditions. TeCNO schemes (Fjordholm et al. 2012) form a class of arbitrary high-order entropy stable finite difference solvers, which require specialized reconstruction algorithms satisfying the sign property at each cell interface. Recently, third-order WENO schemes called SP-WENO (Fjordholm and Ray, 2016) and SP-WENOc (Ray, 2018) have been designed to satisfy the sign property. However, these WENO algorithms can perform poorly near shocks, with the numerical solutions exhibiting large spurious oscillations. In the present work, we propose a variant of the SP-WENO, termed as Deep Sign-Preserving WENO (DSP-WENO), where a neural network is trained to learn the WENO weighting strategy. The sign property and third-o
&lt;/p&gt;</description></item><item><title>&#22312;&#20984;&#22810;&#38754;&#20307;&#32593;&#26684;&#19978;&#65292;&#25552;&#20986;&#20102;&#29992;&#20004;&#20010;&#38544;&#34255;&#23618;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#26469;&#24369;&#34920;&#31034;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#65292;&#24182;&#26681;&#25454;&#32593;&#26684;&#20013;&#30340;&#22810;&#38754;&#20307;&#21644;&#36229;&#24179;&#38754;&#30340;&#25968;&#37327;&#20934;&#30830;&#30830;&#23450;&#20102;&#25152;&#38656;&#30340;&#31070;&#32463;&#20803;&#25968;&#65292;&#24314;&#31435;&#20102;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#26377;&#38480;&#20803;&#20989;&#25968;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.05809</link><description>&lt;p&gt;
&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#26377;&#38480;&#20803;
&lt;/p&gt;
&lt;p&gt;
Shallow ReLU neural networks and finite elements
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05809
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20984;&#22810;&#38754;&#20307;&#32593;&#26684;&#19978;&#65292;&#25552;&#20986;&#20102;&#29992;&#20004;&#20010;&#38544;&#34255;&#23618;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#26469;&#24369;&#34920;&#31034;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#65292;&#24182;&#26681;&#25454;&#32593;&#26684;&#20013;&#30340;&#22810;&#38754;&#20307;&#21644;&#36229;&#24179;&#38754;&#30340;&#25968;&#37327;&#20934;&#30830;&#30830;&#23450;&#20102;&#25152;&#38656;&#30340;&#31070;&#32463;&#20803;&#25968;&#65292;&#24314;&#31435;&#20102;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#26377;&#38480;&#20803;&#20989;&#25968;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25351;&#20986;&#22312;&#20984;&#22810;&#38754;&#20307;&#32593;&#26684;&#19978;&#65292;&#21487;&#20197;&#29992;&#20004;&#20010;&#38544;&#34255;&#23618;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#24369;&#24847;&#20041;&#19979;&#34920;&#31034;&#65288;&#36830;&#32493;&#25110;&#19981;&#36830;&#32493;&#30340;&#65289;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#28041;&#21450;&#21040;&#30340;&#22810;&#38754;&#20307;&#21644;&#36229;&#24179;&#38754;&#30340;&#25968;&#37327;&#65292;&#20934;&#30830;&#32473;&#20986;&#20102;&#24369;&#34920;&#31034;&#25152;&#38656;&#30340;&#20004;&#20010;&#38544;&#34255;&#23618;&#30340;&#31070;&#32463;&#20803;&#25968;&#12290;&#36825;&#20123;&#32467;&#26524;&#33258;&#28982;&#22320;&#36866;&#29992;&#20110;&#24120;&#25968;&#21644;&#32447;&#24615;&#26377;&#38480;&#20803;&#20989;&#25968;&#12290;&#36825;&#31181;&#24369;&#34920;&#31034;&#24314;&#31435;&#20102;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#26377;&#38480;&#20803;&#20989;&#25968;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#24182;&#20026;&#36890;&#36807;&#26377;&#38480;&#20803;&#20989;&#25968;&#20998;&#26512;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;$L^p$&#33539;&#25968;&#20013;&#30340;&#36924;&#36817;&#33021;&#21147;&#25552;&#20379;&#20102;&#35270;&#35282;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#26368;&#36817;&#24352;&#37327;&#31070;&#32463;&#32593;&#32476;&#23545;&#24352;&#37327;&#26377;&#38480;&#20803;&#20989;&#25968;&#30340;&#20005;&#26684;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05809v1 Announce Type: cross  Abstract: We point out that (continuous or discontinuous) piecewise linear functions on a convex polytope mesh can be represented by two-hidden-layer ReLU neural networks in a weak sense. In addition, the numbers of neurons of the two hidden layers required to weakly represent are accurately given based on the numbers of polytopes and hyperplanes involved in this mesh. The results naturally hold for constant and linear finite element functions. Such weak representation establishes a bridge between shallow ReLU neural networks and finite element functions, and leads to a perspective for analyzing approximation capability of ReLU neural networks in $L^p$ norm via finite element functions. Moreover, we discuss the strict representation for tensor finite element functions via the recent tensor neural networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;T-TAME&#65292;&#19968;&#31181;&#36866;&#29992;&#20110;&#21367;&#31215;&#32593;&#32476;&#21644;&#35270;&#35273;Transformer&#30340;&#21487;&#35757;&#32451;&#27880;&#24847;&#26426;&#21046;&#65292;&#20026;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#25552;&#20379;&#20102;&#36890;&#29992;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.04523</link><description>&lt;p&gt;
T-TAME&#65306;&#29992;&#20110;&#35299;&#37322;&#21367;&#31215;&#32593;&#32476;&#21644;&#35270;&#35273;Transformer&#30340;&#21487;&#35757;&#32451;&#27880;&#24847;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
T-TAME: Trainable Attention Mechanism for Explaining Convolutional Networks and Vision Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04523
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;T-TAME&#65292;&#19968;&#31181;&#36866;&#29992;&#20110;&#21367;&#31215;&#32593;&#32476;&#21644;&#35270;&#35273;Transformer&#30340;&#21487;&#35757;&#32451;&#27880;&#24847;&#26426;&#21046;&#65292;&#20026;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#25552;&#20379;&#20102;&#36890;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Vision Transformers&#21644;&#20854;&#20182;&#29992;&#20110;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#21457;&#23637;&#21644;&#24212;&#29992;&#24555;&#36895;&#22686;&#38271;&#12290;&#28982;&#32780;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#8220;&#40657;&#21283;&#23376;&#8221;&#29305;&#24615;&#26159;&#22312;&#38656;&#35201;&#35299;&#37322;&#24615;&#30340;&#24212;&#29992;&#20013;&#37319;&#29992;&#30340;&#38556;&#30861;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#29992;&#20110;&#29983;&#25104;&#35299;&#37322;&#30340;&#25216;&#26415;&#65292;&#20027;&#35201;&#29992;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#20294;&#26159;&#23558;&#36825;&#20123;&#25216;&#26415;&#36866;&#24212;&#21040;&#35270;&#35273;Transformer&#30340;&#26032;&#33539;&#24335;&#26159;&#38750;&#24179;&#20961;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;T-TAME&#65292;Transformer&#20860;&#23481;&#30340;&#21487;&#35757;&#32451;&#27880;&#24847;&#26426;&#21046;&#29992;&#20110;&#35299;&#37322;&#65292;&#36825;&#26159;&#19968;&#31181;&#35828;&#26126;&#29992;&#20110;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26550;&#26500;&#21644;&#35757;&#32451;&#25216;&#26415;&#21487;&#20197;&#36731;&#26494;&#24212;&#29992;&#20110;&#20219;&#20309;&#21367;&#31215;&#25110;&#31867;&#20284;Vision Transformer&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20351;&#29992;&#31934;&#31616;&#30340;&#35757;&#32451;&#26041;&#27861;&#12290;&#35757;&#32451;&#21518;&#65292;&#35299;&#37322;&#22270;&#21487;&#20197;&#22312;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#35745;&#31639;&#20986;&#65307;&#36825;&#20123;&#35299;&#37322;&#22270;&#21487;&#20197;&#19982;Convolutional Neural Networks&#20013;&#29983;&#25104;&#30340;&#35299;&#37322;&#22270;&#30456;&#23218;&#32654;&#25110;&#32773;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04523v1 Announce Type: cross  Abstract: The development and adoption of Vision Transformers and other deep-learning architectures for image classification tasks has been rapid. However, the "black box" nature of neural networks is a barrier to adoption in applications where explainability is essential. While some techniques for generating explanations have been proposed, primarily for Convolutional Neural Networks, adapting such techniques to the new paradigm of Vision Transformers is non-trivial. This paper presents T-TAME, Transformer-compatible Trainable Attention Mechanism for Explanations, a general methodology for explaining deep neural networks used in image classification tasks. The proposed architecture and training technique can be easily applied to any convolutional or Vision Transformer-like neural network, using a streamlined training approach. After training, explanation maps can be computed in a single forward pass; these explanation maps are comparable to or 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#26410;&#30693;&#25298;&#32477;&#12289;&#26032;&#31867;&#21035;&#21457;&#29616;&#21644;&#31867;&#21035;&#22686;&#37327;&#23398;&#20064;&#65292;&#26412;&#25991;&#25299;&#23637;&#20102;&#24320;&#25918;&#19990;&#30028;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#22810;&#20010;&#28508;&#22312;&#26041;&#21521;</title><link>https://arxiv.org/abs/2403.01759</link><description>&lt;p&gt;
&#24320;&#25918;&#19990;&#30028;&#26426;&#22120;&#23398;&#20064;&#65306;&#22238;&#39038;&#19982;&#26032;&#23637;&#26395;
&lt;/p&gt;
&lt;p&gt;
Open-world Machine Learning: A Review and New Outlooks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01759
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#26410;&#30693;&#25298;&#32477;&#12289;&#26032;&#31867;&#21035;&#21457;&#29616;&#21644;&#31867;&#21035;&#22686;&#37327;&#23398;&#20064;&#65292;&#26412;&#25991;&#25299;&#23637;&#20102;&#24320;&#25918;&#19990;&#30028;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#22810;&#20010;&#28508;&#22312;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#22522;&#20110;&#23553;&#38381;&#19990;&#30028;&#20551;&#35774;&#65292;&#21363;&#20551;&#23450;&#29615;&#22659;&#26159;&#38745;&#24577;&#30340;&#65292;&#27169;&#22411;&#19968;&#26086;&#37096;&#32626;&#23601;&#26159;&#22266;&#23450;&#30340;&#12290;&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#65292;&#36825;&#31181;&#22522;&#26412;&#19988;&#30456;&#24403;&#24188;&#31258;&#30340;&#20551;&#35774;&#21487;&#33021;&#19981;&#25104;&#31435;&#65292;&#22240;&#20026;&#24320;&#25918;&#29615;&#22659;&#22797;&#26434;&#12289;&#21160;&#24577;&#19988;&#20805;&#28385;&#26410;&#30693;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25298;&#32477;&#26410;&#30693;&#12289;&#21457;&#29616;&#26032;&#22855;&#28857;&#65292;&#28982;&#21518;&#36880;&#27493;&#23398;&#20064;&#65292;&#21487;&#20197;&#20351;&#27169;&#22411;&#20687;&#29983;&#29289;&#31995;&#32479;&#19968;&#26679;&#23433;&#20840;&#22320;&#24182;&#25345;&#32493;&#36827;&#21270;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#26410;&#30693;&#25298;&#32477;&#12289;&#26032;&#31867;&#21035;&#21457;&#29616;&#21644;&#31867;&#21035;&#22686;&#37327;&#23398;&#20064;&#22312;&#32479;&#19968;&#33539;&#24335;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#24320;&#25918;&#19990;&#30028;&#26426;&#22120;&#23398;&#20064;&#30340;&#25972;&#20307;&#35266;&#28857;&#12290;&#35814;&#32454;&#35752;&#35770;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#25361;&#25112;&#12289;&#21407;&#21017;&#21644;&#23616;&#38480;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20960;&#20010;&#26410;&#26469;&#30740;&#31350;&#30340;&#28508;&#22312;&#26041;&#21521;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;&#19968;&#20221;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01759v1 Announce Type: new  Abstract: Machine learning has achieved remarkable success in many applications. However, existing studies are largely based on the closed-world assumption, which assumes that the environment is stationary, and the model is fixed once deployed. In many real-world applications, this fundamental and rather naive assumption may not hold because an open environment is complex, dynamic, and full of unknowns. In such cases, rejecting unknowns, discovering novelties, and then incrementally learning them, could enable models to be safe and evolve continually as biological systems do. This paper provides a holistic view of open-world machine learning by investigating unknown rejection, novel class discovery, and class-incremental learning in a unified paradigm. The challenges, principles, and limitations of current methodologies are discussed in detail. Finally, we discuss several potential directions for future research. This paper aims to provide a compr
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;&#36164;&#28304;&#39640;&#25928;&#30340;&#22312;&#32447;RNN&#31639;&#27861;&#22312;&#25918;&#30103;&#27835;&#30103;&#36807;&#31243;&#20013;&#20934;&#30830;&#39044;&#27979;&#21628;&#21560;&#36816;&#21160;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.01607</link><description>&lt;p&gt;
&#38024;&#23545;&#22806;&#37096;&#23548;&#21521;&#25918;&#30103;&#20013;&#23433;&#20840;&#22686;&#24378;&#30340;&#21628;&#21560;&#36816;&#21160;&#39044;&#27979;&#19982;&#22312;&#32447;&#23398;&#20064;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Respiratory motion forecasting with online learning of recurrent neural networks for safety enhancement in externally guided radiotherapy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01607
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;&#36164;&#28304;&#39640;&#25928;&#30340;&#22312;&#32447;RNN&#31639;&#27861;&#22312;&#25918;&#30103;&#27835;&#30103;&#36807;&#31243;&#20013;&#20934;&#30830;&#39044;&#27979;&#21628;&#21560;&#36816;&#21160;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32954;&#37096;&#25918;&#30103;&#20013;&#65292;&#32418;&#22806;&#25668;&#20687;&#22836;&#21487;&#20197;&#35760;&#24405;&#33016;&#37096;&#21453;&#23556;&#29289;&#20307;&#30340;&#20301;&#32622;&#65292;&#20197;&#25512;&#26029;&#30001;&#20110;&#21628;&#21560;&#32780;&#31227;&#21160;&#30340;&#32959;&#30244;&#20301;&#32622;&#65292;&#20294;&#27835;&#30103;&#31995;&#32479;&#30340;&#24310;&#36831;&#24433;&#21709;&#20102;&#25918;&#23556;&#26463;&#31934;&#24230;&#12290;&#23454;&#26102;&#24490;&#29615;&#23398;&#20064;&#65288;RTRL&#65289;&#26159;&#19968;&#20010;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#23398;&#20064;&#38750;&#24179;&#31283;&#21628;&#21560;&#25968;&#25454;&#20013;&#30340;&#27169;&#24335;&#65292;&#20294;&#20855;&#26377;&#36739;&#39640;&#30340;&#22797;&#26434;&#24615;&#12290;&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#36164;&#28304;&#39640;&#25928;&#30340;&#22312;&#32447;RNN&#31639;&#27861;&#65292;&#21363;&#26080;&#20559;&#22312;&#32447;&#24490;&#29615;&#20248;&#21270;&#65288;UORO&#65289;&#12289;&#31232;&#30095;-1&#27493;&#36924;&#36817;&#65288;SnAp-1&#65289;&#21644;&#35299;&#32806;&#31070;&#32463;&#25509;&#21475;&#65288;DNI&#65289;&#65292;&#20197;&#20934;&#30830;&#39044;&#27979;&#25918;&#30103;&#27835;&#30103;&#36807;&#31243;&#20013;&#30340;&#21628;&#21560;&#36816;&#21160;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#20581;&#24247;&#21463;&#35797;&#32773;&#33016;&#37096;&#22806;&#37096;&#26631;&#35760;&#29289;&#30340;&#21253;&#21547;3D&#20301;&#32622;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24433;&#21709;&#21644;&#21363;&#26102;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#21387;&#32553;&#20197;&#21450;&#32447;&#24615;&#31995;&#25968;&#30340;&#20934;&#30830;&#26356;&#26032;&#29992;&#20110;&#20449;&#29992;&#20998;&#37197;&#30340;SnAp-1&#21644;DNI&#30340;&#39640;&#25928;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01607v1 Announce Type: new  Abstract: In lung radiotherapy, infrared cameras can record the location of reflective objects on the chest to infer the position of the tumor moving due to breathing, but treatment system latencies hinder radiation beam precision. Real-time recurrent learning (RTRL), is a potential solution as it can learn patterns within non-stationary respiratory data but has high complexity. This study assesses the capabilities of resource-efficient online RNN algorithms, namely unbiased online recurrent optimization (UORO), sparse-1 step approximation (SnAp-1), and decoupled neural interfaces (DNI) to forecast respiratory motion during radiotherapy treatment accurately. We use time series containing the 3D position of external markers on the chest of healthy subjects. We propose efficient implementations for SnAp-1 and DNI based on compression of the influence and immediate Jacobian matrices and an accurate update of the linear coefficients used in credit ass
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22686;&#21152;&#37327;&#21270;&#32500;&#24230;&#65292;GPTVQ&#26041;&#27861;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#37327;&#21270;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20248;&#32467;&#26524;&#65292;&#19981;&#20165;&#26174;&#33879;&#25913;&#21892;&#20102;&#22823;&#23567;&#19982;&#20934;&#30830;&#24615;&#30340;&#26435;&#34913;&#65292;&#36824;&#25552;&#39640;&#20102;&#22788;&#29702;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.15319</link><description>&lt;p&gt;
GPTVQ&#65306;LLM&#37327;&#21270;&#20013;&#32500;&#24230;&#30340;&#31119;&#38899;
&lt;/p&gt;
&lt;p&gt;
GPTVQ: The Blessing of Dimensionality for LLM Quantization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15319
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22686;&#21152;&#37327;&#21270;&#32500;&#24230;&#65292;GPTVQ&#26041;&#27861;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#37327;&#21270;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20248;&#32467;&#26524;&#65292;&#19981;&#20165;&#26174;&#33879;&#25913;&#21892;&#20102;&#22823;&#23567;&#19982;&#20934;&#30830;&#24615;&#30340;&#26435;&#34913;&#65292;&#36824;&#25552;&#39640;&#20102;&#22788;&#29702;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#22686;&#21152;&#37327;&#21270;&#32500;&#24230;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#37327;&#21270;&#30340;&#22823;&#23567;&#19982;&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GPTVQ&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#24555;&#36895;&#21518;&#35757;&#32451;&#21521;&#37327;&#37327;&#21270;&#65288;VQ&#65289;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20132;&#26367;&#36827;&#34892;&#19968;&#20010;&#25110;&#22810;&#20010;&#21015;&#30340;&#37327;&#21270;&#65292;&#24182;&#20351;&#29992;&#26469;&#33258;&#27599;&#23618;&#36755;&#20986;&#37325;&#24314;MSE&#30340;Hessian&#20449;&#24687;&#26469;&#26356;&#26032;&#20854;&#20313;&#26410;&#37327;&#21270;&#30340;&#26435;&#37325;&#12290;&#37327;&#21270;&#30721;&#20070;&#20351;&#29992;&#19968;&#31181;&#39640;&#25928;&#30340;&#25968;&#25454;&#24863;&#30693;&#29256;&#26412;&#30340;EM&#31639;&#27861;&#36827;&#34892;&#21021;&#22987;&#21270;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#20351;&#29992;&#25972;&#25968;&#37327;&#21270;&#21644;&#22522;&#20110;SVD&#30340;&#21387;&#32553;&#36827;&#19968;&#27493;&#21387;&#32553;&#30721;&#20070;&#12290;GPTVQ&#22312;&#35832;&#22914;Llama-v2&#21644;Mistral&#31561;&#21508;&#31181;LLMs&#19978;&#24314;&#31435;&#20102;&#26032;&#30340;&#26368;&#26032;&#25216;&#26415;&#65292;&#22823;&#23567;&#19982;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#39640;&#25928;&#65306;&#22312;&#21333;&#20010;H100&#19978;&#65292;&#22788;&#29702;&#19968;&#20010;Llamav2-70B&#38656;&#35201;3&#33267;11&#23567;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15319v1 Announce Type: cross  Abstract: In this work we show that the size versus accuracy trade-off of neural network quantization can be significantly improved by increasing the quantization dimensionality. We propose the GPTVQ method, a new fast method for post-training vector quantization (VQ) that scales well to Large Language Models (LLMs). Our method interleaves quantization of one or more columns with updates to the remaining unquantized weights, using information from the Hessian of the per-layer output reconstruction MSE. Quantization codebooks are initialized using an efficient data-aware version of the EM algorithm. The codebooks are then updated, and further compressed by using integer quantization and SVD-based compression. GPTVQ establishes a new state-of-the art in the size vs accuracy trade-offs on a wide range of LLMs such as Llama-v2 and Mistral. Furthermore, our method is efficient: on a single H100 it takes between 3 and 11 hours to process a Llamav2-70B
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#22312;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#21160;&#21147;&#31995;&#32479;&#20013;&#23398;&#20064;&#39044;&#27979;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#26469;&#37327;&#21270;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.06614</link><description>&lt;p&gt;
&#21160;&#21147;&#31995;&#32479;&#20013;&#39034;&#24207;&#39044;&#27979;&#30340;&#22797;&#26434;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Complexity of Sequential Prediction in Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06614
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#22312;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#21160;&#21147;&#31995;&#32479;&#20013;&#23398;&#20064;&#39044;&#27979;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#26469;&#37327;&#21270;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#39044;&#27979;&#21160;&#21147;&#31995;&#32479;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#23545;&#21160;&#21147;&#31995;&#32479;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#65292;&#24182;&#20174;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#35813;&#38382;&#39064;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning to predict the next state of a dynamical system when the underlying evolution function is unknown. Unlike previous work, we place no parametric assumptions on the dynamical system, and study the problem from a learning theory perspective. We define new combinatorial measures and dimensions and show that they quantify the optimal mistake and regret bounds in the realizable and agnostic setting respectively.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PA-RL&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#29109;&#29575;&#26469;&#24341;&#23548;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#12290;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#23454;&#29616;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#22312;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#20540;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2311.18703</link><description>&lt;p&gt;
&#36890;&#36807;&#29109;&#29575;&#26368;&#23567;&#21270;&#23454;&#29616;&#21487;&#39044;&#27979;&#30340;&#24378;&#21270;&#23398;&#20064;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.18703
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PA-RL&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#29109;&#29575;&#26469;&#24341;&#23548;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#12290;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#23454;&#29616;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#22312;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#26234;&#33021;&#20307;&#27809;&#26377;&#21160;&#26426;&#23637;&#31034;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#65292;&#36890;&#24120;&#36890;&#36807;&#31574;&#30053;&#29109;&#27491;&#21017;&#21270;&#25512;&#21160;&#26234;&#33021;&#20307;&#22312;&#25506;&#32034;&#19978;&#38543;&#26426;&#21270;&#20854;&#34892;&#20026;&#12290;&#20174;&#20154;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#20351;&#24471;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#24456;&#38590;&#35299;&#37322;&#21644;&#39044;&#27979;&#65307;&#20174;&#23433;&#20840;&#35282;&#24230;&#26469;&#30475;&#65292;&#26356;&#38590;&#20197;&#36827;&#34892;&#24418;&#24335;&#21270;&#39564;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#21487;&#39044;&#27979;&#24615;&#24863;&#30693;&#24378;&#21270;&#23398;&#20064;&#65288;PA-RL&#65289;&#65292;&#29992;&#20110;&#24341;&#23548;&#26234;&#33021;&#20307;&#23637;&#29616;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#65292;&#20854;&#21033;&#29992;&#29366;&#24577;&#24207;&#21015;&#29109;&#29575;&#20316;&#20026;&#21487;&#39044;&#27979;&#24615;&#24230;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#29109;&#29575;&#21046;&#23450;&#20026;&#24179;&#22343;&#22870;&#21169;&#30446;&#26631;&#65292;&#24182;&#19988;&#30001;&#20110;&#20854;&#29109;&#22870;&#21169;&#20989;&#25968;&#20381;&#36182;&#20110;&#31574;&#30053;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21160;&#20316;&#30456;&#20851;&#30340;&#26367;&#20195;&#29109;&#65292;&#20197;&#21033;&#29992;PG&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26368;&#23567;&#21270;&#24179;&#22343;&#26367;&#20195;&#22870;&#21169;&#30340;&#30830;&#23450;&#24615;&#31574;&#30053;&#23384;&#22312;&#65292;&#24182;&#19988;&#26368;&#23567;&#21270;&#20102;&#23454;&#38469;&#29109;&#29575;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#23398;&#20064;&#21040;&#30340;&#21160;&#24577;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#36817;&#20284;&#35745;&#31639;&#19982;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Reinforcement Learning (RL), agents have no incentive to exhibit predictable behaviors, and are often pushed (through e.g. policy entropy regularization) to randomize their actions in favor of exploration. From a human perspective, this makes RL agents hard to interpret and predict, and from a safety perspective, even harder to formally verify. We propose a novel method to induce predictable behavior in RL agents, referred to as Predictability-Aware RL (PA-RL), which employs the state sequence entropy rate as a predictability measure. We show how the entropy rate can be formulated as an average reward objective, and since its entropy reward function is policy-dependent, we introduce an action-dependent surrogate entropy enabling the use of PG methods. We prove that deterministic policies minimizing the average surrogate reward exist and also minimize the actual entropy rate, and show how, given a learned dynamical model, we are able to approximate the value function associated to th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#23637;&#31034;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65288;FPS&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#24310;&#36831;&#21709;&#24212;&#30340;&#27010;&#24565;&#26469;&#35299;&#20915;&#23637;&#31034;&#24615;&#24341;&#36215;&#30340;&#20998;&#24067;&#21464;&#21270;&#65292;&#24182;&#23454;&#29616;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2310.06077</link><description>&lt;p&gt;
&#21487;&#23637;&#31034;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Performative Time-Series Forecasting. (arXiv:2310.06077v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#23637;&#31034;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65288;FPS&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#24310;&#36831;&#21709;&#24212;&#30340;&#27010;&#24565;&#26469;&#35299;&#20915;&#23637;&#31034;&#24615;&#24341;&#36215;&#30340;&#20998;&#24067;&#21464;&#21270;&#65292;&#24182;&#23454;&#29616;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26159;&#21508;&#20010;&#39046;&#22495;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#22312;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#23454;&#36136;&#24615;&#30340;&#36827;&#23637;&#12290;&#35768;&#22810;&#29616;&#23454;&#29983;&#27963;&#22330;&#26223;&#65292;&#22914;&#20844;&#20849;&#21355;&#29983;&#12289;&#32463;&#27982;&#21644;&#31038;&#20250;&#24212;&#29992;&#65292;&#28041;&#21450;&#21040;&#21453;&#39304;&#24490;&#29615;&#65292;&#20854;&#20013;&#39044;&#27979;&#32467;&#26524;&#21487;&#33021;&#20250;&#24433;&#21709;&#21040;&#39044;&#27979;&#30340;&#32467;&#26524;&#65292;&#36827;&#32780;&#25913;&#21464;&#30446;&#26631;&#21464;&#37327;&#30340;&#20998;&#24067;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#23637;&#31034;&#24615;&#65292;&#24341;&#20837;&#20102;&#21487;&#33021;&#20986;&#29616;&#8220;&#33258;&#25105;&#25269;&#28040;&#8221;&#25110;&#8220;&#33258;&#25105;&#23454;&#29616;&#8221;&#30340;&#39044;&#27979;&#30340;&#28508;&#21147;&#12290;&#23613;&#31649;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#23545;&#20998;&#31867;&#38382;&#39064;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#65292;&#20294;&#23637;&#31034;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#35270;&#35282;&#19979;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#24191;&#27867;&#25506;&#35752;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#21487;&#23637;&#31034;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;PeTS&#65289;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#65292;&#35299;&#20915;&#20102;&#24403;&#21487;&#33021;&#23384;&#22312;&#23637;&#31034;&#24615;&#24341;&#36215;&#30340;&#20998;&#24067;&#21464;&#21270;&#26102;&#30340;&#20934;&#30830;&#39044;&#27979;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;&#65292;&#29305;&#24449;&#23637;&#31034;&#24615;&#36716;&#31227;&#65288;FPS&#65289;&#65292;&#23427;&#21033;&#29992;&#24310;&#36831;&#21709;&#24212;&#30340;&#27010;&#24565;&#26469;&#39044;&#27979;&#20998;&#24067;&#30340;&#21464;&#21270;&#21644;&#38543;&#21518;&#30340;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-series forecasting is a critical challenge in various domains and has witnessed substantial progress in recent years. Many real-life scenarios, such as public health, economics, and social applications, involve feedback loops where predictions can influence the predicted outcome, subsequently altering the target variable's distribution. This phenomenon, known as performativity, introduces the potential for 'self-negating' or 'self-fulfilling' predictions. Despite extensive studies in classification problems across domains, performativity remains largely unexplored in the context of time-series forecasting from a machine-learning perspective.  In this paper, we formalize performative time-series forecasting (PeTS), addressing the challenge of accurate predictions when performativity-induced distribution shifts are possible. We propose a novel approach, Feature Performative-Shifting (FPS), which leverages the concept of delayed response to anticipate distribution shifts and subseque
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#31614;&#35299;&#21367;&#31215;&#25216;&#26415;(LD)&#65292;&#36890;&#36807;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#30340;&#36870;&#26144;&#23556;&#36827;&#34892;&#39640;&#25928;&#30340;&#36817;&#20284;&#65292;&#26469;&#35299;&#20915;&#22312;&#22823;&#35268;&#27169;&#23646;&#24615;&#22270;&#19978;&#36827;&#34892;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#26102;&#30340;&#23398;&#20064;&#20559;&#24046;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.14907</link><description>&lt;p&gt;
&#23545;&#22823;&#35268;&#27169;&#23646;&#24615;&#22270;&#19978;&#30340;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#36827;&#34892;&#26631;&#31614;&#35299;&#21367;&#31215;&#20197;&#25269;&#25239;&#23398;&#20064;&#20559;&#24046;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias. (arXiv:2309.14907v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14907
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#31614;&#35299;&#21367;&#31215;&#25216;&#26415;(LD)&#65292;&#36890;&#36807;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#30340;&#36870;&#26144;&#23556;&#36827;&#34892;&#39640;&#25928;&#30340;&#36817;&#20284;&#65292;&#26469;&#35299;&#20915;&#22312;&#22823;&#35268;&#27169;&#23646;&#24615;&#22270;&#19978;&#36827;&#34892;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#26102;&#30340;&#23398;&#20064;&#20559;&#24046;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24102;&#23646;&#24615;&#30340;&#22270;&#20013;&#65292;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#23545;&#35768;&#22810;&#37325;&#35201;&#30340;&#19979;&#28216;&#20219;&#21153;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#20026;&#20102;&#21516;&#26102;&#32534;&#30721;&#23646;&#24615;&#21644;&#22270;&#32467;&#26500;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#36827;&#34892;&#25972;&#21512;&#65292;&#20854;&#20013;&#39044;&#35757;&#32451;&#27169;&#22411;&#20316;&#20026;&#33410;&#28857;&#32534;&#30721;&#22120;(NEs)&#26469;&#32534;&#30721;&#23646;&#24615;&#12290;&#30001;&#20110;&#22312;&#22823;&#35268;&#27169;&#22270;&#19978;&#21516;&#26102;&#35757;&#32451;&#22823;&#22411;NEs&#21644;GNNs&#23384;&#22312;&#20005;&#37325;&#30340;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#65292;&#35768;&#22810;&#26041;&#27861;&#25552;&#20986;&#20102;&#20998;&#21035;&#35757;&#32451;NEs&#21644;GNNs&#30340;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#22312;NEs&#30340;&#35757;&#32451;&#38454;&#27573;&#20013;&#65292;&#20182;&#20204;&#27809;&#26377;&#32771;&#34385;&#21040;GNNs&#20013;&#30340;&#29305;&#24449;&#21367;&#31215;&#65292;&#23548;&#33268;&#20102;&#19982;&#32852;&#21512;&#35757;&#32451;&#30456;&#27604;&#30340;&#26174;&#33879;&#23398;&#20064;&#20559;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26631;&#31614;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#21363;&#26631;&#31614;&#35299;&#21367;&#31215;(LD)&#65292;&#36890;&#36807;&#23545;GNNs&#30340;&#36870;&#26144;&#23556;&#36827;&#34892;&#26032;&#39062;&#19988;&#39640;&#24230;&#21487;&#20280;&#32553;&#30340;&#36817;&#20284;&#65292;&#20197;&#20943;&#36731;&#23398;&#20064;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Node representation learning on attributed graphs -- whose nodes are associated with rich attributes (e.g., texts and protein sequences) -- plays a crucial role in many important downstream tasks. To encode the attributes and graph structures simultaneously, recent studies integrate pre-trained models with graph neural networks (GNNs), where pre-trained models serve as node encoders (NEs) to encode the attributes. As jointly training large NEs and GNNs on large-scale graphs suffers from severe scalability issues, many methods propose to train NEs and GNNs separately. Consequently, they do not take feature convolutions in GNNs into consideration in the training phase of NEs, leading to a significant learning bias from that by the joint training. To address this challenge, we propose an efficient label regularization technique, namely Label Deconvolution (LD), to alleviate the learning bias by a novel and highly scalable approximation to the inverse mapping of GNNs. The inverse mapping l
&lt;/p&gt;</description></item><item><title>Conti&#20844;&#21496;&#30340;&#32842;&#22825;&#35760;&#24405;&#27844;&#38706;&#32473;&#25105;&#20204;&#25552;&#20379;&#20102;&#20102;&#35299;&#21202;&#32034;&#36719;&#20214;&#26381;&#21153;&#36816;&#33829;&#21830;&#20869;&#37096;&#36816;&#20316;&#30340;&#26426;&#20250;&#12290;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21644;&#21487;&#35270;&#21270;&#31574;&#30053;&#65292;&#30740;&#31350;&#21457;&#29616;&#19994;&#21153;&#12289;&#25216;&#26415;&#12289;&#20869;&#37096;&#20219;&#21153;&#31649;&#29702;&#12289;&#24694;&#24847;&#36719;&#20214;&#21644;&#23458;&#25143;&#26381;&#21153;&#26159;Conti&#25104;&#21592;&#35752;&#35770;&#30340;&#20027;&#35201;&#20027;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.16061</link><description>&lt;p&gt;
Conti&#20844;&#21496;&#65306;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#20102;&#35299;&#19968;&#20010;&#22823;&#22411;&#21202;&#32034;&#36719;&#20214;&#26381;&#21153;&#36816;&#33829;&#21830;&#30340;&#20869;&#37096;&#35752;&#35770;
&lt;/p&gt;
&lt;p&gt;
Conti Inc.: Understanding the Internal Discussions of a large Ransomware-as-a-Service Operator with Machine Learning. (arXiv:2308.16061v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16061
&lt;/p&gt;
&lt;p&gt;
Conti&#20844;&#21496;&#30340;&#32842;&#22825;&#35760;&#24405;&#27844;&#38706;&#32473;&#25105;&#20204;&#25552;&#20379;&#20102;&#20102;&#35299;&#21202;&#32034;&#36719;&#20214;&#26381;&#21153;&#36816;&#33829;&#21830;&#20869;&#37096;&#36816;&#20316;&#30340;&#26426;&#20250;&#12290;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21644;&#21487;&#35270;&#21270;&#31574;&#30053;&#65292;&#30740;&#31350;&#21457;&#29616;&#19994;&#21153;&#12289;&#25216;&#26415;&#12289;&#20869;&#37096;&#20219;&#21153;&#31649;&#29702;&#12289;&#24694;&#24847;&#36719;&#20214;&#21644;&#23458;&#25143;&#26381;&#21153;&#26159;Conti&#25104;&#21592;&#35752;&#35770;&#30340;&#20027;&#35201;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21202;&#32034;&#36719;&#20214;&#26381;&#21153;&#65288;RaaS&#65289;&#27491;&#22312;&#22686;&#21152;&#21202;&#32034;&#36719;&#20214;&#25915;&#20987;&#30340;&#35268;&#27169;&#21644;&#22797;&#26434;&#24615;&#12290;&#20102;&#35299;RaaS&#32972;&#21518;&#30340;&#20869;&#37096;&#36816;&#20316;&#19968;&#30452;&#26159;&#20010;&#25361;&#25112;&#65292;&#22240;&#20026;&#27492;&#31867;&#27963;&#21160;&#26159;&#38750;&#27861;&#30340;&#12290;&#26368;&#36817;Conti&#20844;&#21496;&#27844;&#38706;&#30340;&#32842;&#22825;&#35760;&#24405;&#32473;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20102;&#35299;&#36825;&#31867;&#32452;&#32455;&#20869;&#37096;&#36816;&#20316;&#30340;&#33391;&#26426;&#12290;&#26412;&#25991;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#21644;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#65288;LDA&#65289;&#31561;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#21450;&#21487;&#35270;&#21270;&#31574;&#30053;&#65292;&#20998;&#26512;&#20102;Conti&#20844;&#21496;&#32842;&#22825;&#35760;&#24405;&#20013;&#30340;&#20027;&#35201;&#20027;&#39064;&#35752;&#35770;&#12290;&#21457;&#29616;&#20102;&#20116;&#20010;&#35752;&#35770;&#20027;&#39064;&#65306;1&#65289;&#19994;&#21153;&#65292;2&#65289;&#25216;&#26415;&#65292;3&#65289;&#20869;&#37096;&#20219;&#21153;/&#31649;&#29702;&#65292;4&#65289;&#24694;&#24847;&#36719;&#20214;&#65292;5&#65289;&#23458;&#25143;&#26381;&#21153;/&#38382;&#39064;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;Conti&#25104;&#21592;&#30340;&#20027;&#39064;&#20998;&#24067;&#26174;&#31034;&#65292;&#21482;&#26377;4%&#30340;&#20154;&#36827;&#34892;&#20102;&#19987;&#38376;&#30340;&#35752;&#35770;&#65292;&#32780;&#20960;&#20046;&#25152;&#26377;&#20154;&#65288;96%&#65289;&#37117;&#26159;&#20840;&#33021;&#22411;&#65292;&#24847;&#21619;&#30528;&#20182;&#20204;&#30340;&#35752;&#35770;&#37117;&#22260;&#32469;&#30528;&#36825;&#20116;&#20010;&#20027;&#39064;&#23637;&#24320;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ransomware-as-a-service (RaaS) is increasing the scale and complexity of ransomware attacks. Understanding the internal operations behind RaaS has been a challenge due to the illegality of such activities. The recent chat leak of the Conti RaaS operator, one of the most infamous ransomware operators on the international scene, offers a key opportunity to better understand the inner workings of such organizations. This paper analyzes the main topic discussions in the Conti chat leak using machine learning techniques such as Natural Language Processing (NLP) and Latent Dirichlet Allocation (LDA), as well as visualization strategies. Five discussion topics are found: 1) Business, 2) Technical, 3) Internal tasking/Management, 4) Malware, and 5) Customer Service/Problem Solving. Moreover, the distribution of topics among Conti members shows that only 4% of individuals have specialized discussions while almost all individuals (96%) are all-rounders, meaning that their discussions revolve aro
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#21487;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#65306;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#36805;&#36895;&#20943;&#23567;&#65307;&#31532;&#20108;&#38454;&#27573;&#20013;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#32531;&#24930;&#20943;&#23567;&#12290;&#36825;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.08247</link><description>&lt;p&gt;
&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#20004;&#20010;&#38454;&#27573;&#30340;&#32553;&#25918;&#24459;
&lt;/p&gt;
&lt;p&gt;
Two Phases of Scaling Laws for Nearest Neighbor Classifiers. (arXiv:2308.08247v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08247
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#21487;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#65306;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#36805;&#36895;&#20943;&#23567;&#65307;&#31532;&#20108;&#38454;&#27573;&#20013;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#32531;&#24930;&#20943;&#23567;&#12290;&#36825;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32553;&#25918;&#24459;&#26159;&#25351;&#24403;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;&#27169;&#22411;&#30340;&#27979;&#35797;&#24615;&#33021;&#20250;&#25552;&#39640;&#30340;&#35266;&#23519;&#32467;&#26524;&#12290;&#24555;&#36895;&#30340;&#32553;&#25918;&#24459;&#24847;&#21619;&#30528;&#36890;&#36807;&#22686;&#21152;&#25968;&#25454;&#21644;&#27169;&#22411;&#22823;&#23567;&#23601;&#33021;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#22686;&#21152;&#26356;&#22810;&#25968;&#25454;&#30340;&#22909;&#22788;&#21487;&#33021;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#12290;&#25105;&#20204;&#21457;&#29616;&#32553;&#25918;&#24459;&#21487;&#33021;&#26377;&#20004;&#20010;&#38454;&#27573;&#65306;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#19988;&#24555;&#36895;&#20943;&#23567;&#65307;&#32780;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#19988;&#20943;&#23567;&#24471;&#24930;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#31361;&#26174;&#20102;&#25968;&#25454;&#20998;&#24067;&#22312;&#20915;&#23450;&#27867;&#21270;&#35823;&#24046;&#20013;&#30340;&#22797;&#26434;&#24615;&#12290;&#24403;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
A scaling law refers to the observation that the test performance of a model improves as the number of training data increases. A fast scaling law implies that one can solve machine learning problems by simply boosting the data and the model sizes. Yet, in many cases, the benefit of adding more data can be negligible. In this work, we study the rate of scaling laws of nearest neighbor classifiers. We show that a scaling law can have two phases: in the first phase, the generalization error depends polynomially on the data dimension and decreases fast; whereas in the second phase, the error depends exponentially on the data dimension and decreases slowly. Our analysis highlights the complexity of the data distribution in determining the generalization error. When the data distributes benignly, our result suggests that nearest neighbor classifier can achieve a generalization error that depends polynomially, instead of exponentially, on the data dimension.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#20511;&#37492;&#20102;&#22810;&#20010;&#25991;&#29486;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38236;&#20687;&#19979;&#38477;&#21644;&#20849;&#36717;&#26799;&#24230;&#30340;&#25216;&#26415;&#65292;&#33021;&#22815;&#39640;&#25928;&#20934;&#30830;&#22320;&#35745;&#31639;Wasserstein&#36317;&#31163;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#27604;&#20854;&#20182;&#31639;&#27861;&#20855;&#26377;&#24555;&#36895;&#25910;&#25947;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2307.08507</link><description>&lt;p&gt;
&#20511;&#37492;&#29109;&#26368;&#20248;&#36755;&#36816;&#12289;&#38236;&#20687;&#19979;&#38477;&#21644;&#20849;&#36717;&#26799;&#24230;&#30340;&#25991;&#29486;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#39640;&#25928;&#20934;&#30830;&#30340;&#26368;&#20248;&#36755;&#36816;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient and Accurate Optimal Transport with Mirror Descent and Conjugate Gradients. (arXiv:2307.08507v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08507
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#20511;&#37492;&#20102;&#22810;&#20010;&#25991;&#29486;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38236;&#20687;&#19979;&#38477;&#21644;&#20849;&#36717;&#26799;&#24230;&#30340;&#25216;&#26415;&#65292;&#33021;&#22815;&#39640;&#25928;&#20934;&#30830;&#22320;&#35745;&#31639;Wasserstein&#36317;&#31163;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#27604;&#20854;&#20182;&#31639;&#27861;&#20855;&#26377;&#24555;&#36895;&#25910;&#25947;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#36755;&#36816;&#31639;&#27861;&#65292;&#36890;&#36807;&#20511;&#37492;&#29109;&#26368;&#20248;&#36755;&#36816;&#12289;&#38236;&#20687;&#19979;&#38477;&#21644;&#20849;&#36717;&#26799;&#24230;&#30340;&#25991;&#29486;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#25193;&#23637;&#19988;&#21487;&#22312;GPU&#19978;&#24182;&#34892;&#35745;&#31639;&#65292;&#33021;&#22815;&#20197;&#26497;&#39640;&#30340;&#31934;&#24230;&#35745;&#31639;Wasserstein&#36317;&#31163;&#65292;&#20351;&#30456;&#23545;&#35823;&#24046;&#36798;&#21040;$10^{-8}$&#65292;&#24182;&#19988;&#27809;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#23454;&#35777;&#19978;&#65292;&#19982;&#21253;&#25324;&#23545;&#25968;&#22495;&#31283;&#23450;Sinkhorn&#31639;&#27861;&#22312;&#20869;&#30340;&#22810;&#31181;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#26356;&#24555;&#22320;&#36798;&#21040;&#39640;&#31934;&#24230;&#35299;&#65292;&#20855;&#26377;&#26356;&#30701;&#30340;&#22681;&#38047;&#26102;&#38388;&#12290;&#25105;&#20204;&#35814;&#32454;&#22320;&#20998;&#26512;&#20102;&#31639;&#27861;&#21644;&#38382;&#39064;&#21442;&#25968;&#65292;&#24182;&#22312;MNIST&#22270;&#20687;&#19978;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#19982;&#21508;&#31181;&#26368;&#26032;&#30340;&#39640;&#32500;&#38382;&#39064;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#25104;&#20026;&#20174;&#19994;&#20154;&#21592;&#26368;&#20248;&#36755;&#36816;&#24037;&#20855;&#21253;&#20013;&#26377;&#29992;&#30340;&#34917;&#20805;&#12290;
&lt;/p&gt;
&lt;p&gt;
We design a novel algorithm for optimal transport by drawing from the entropic optimal transport, mirror descent and conjugate gradients literatures. Our scalable and GPU parallelizable algorithm is able to compute the Wasserstein distance with extreme precision, reaching relative error rates of $10^{-8}$ without numerical stability issues. Empirically, the algorithm converges to high precision solutions more quickly in terms of wall-clock time than a variety of algorithms including log-domain stabilized Sinkhorn's Algorithm. We provide careful ablations with respect to algorithm and problem parameters, and present benchmarking over upsampled MNIST images, comparing to various recent algorithms over high-dimensional problems. The results suggest that our algorithm can be a useful addition to the practitioner's optimal transport toolkit.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#25506;&#35752;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#37325;&#28857;&#26159;&#36890;&#36807;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#30340;&#35889;&#20998;&#26512;&#26469;&#29702;&#35299;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2306.17301</link><description>&lt;p&gt;
&#27973;&#23618;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65306;&#19968;&#20010;&#25968;&#20540;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Why Shallow Networks Struggle with Approximating and Learning High Frequency: A Numerical Study. (arXiv:2306.17301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#25506;&#35752;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#37325;&#28857;&#26159;&#36890;&#36807;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#30340;&#35889;&#20998;&#26512;&#26469;&#29702;&#35299;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#20998;&#26512;&#21644;&#23454;&#39564;&#30340;&#32508;&#21512;&#25968;&#20540;&#30740;&#31350;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#26426;&#22120;&#31934;&#24230;&#21644;&#35745;&#31639;&#25104;&#26412;&#31561;&#23454;&#38469;&#22240;&#32032;&#20013;&#65292;&#22788;&#29702;&#39640;&#39057;&#29575;&#30340;&#36924;&#36817;&#21644;&#23398;&#20064;&#23384;&#22312;&#22256;&#38590;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30740;&#31350;&#20102;&#20197;&#19979;&#22522;&#26412;&#35745;&#31639;&#38382;&#39064;&#65306;&#65288;1&#65289;&#22312;&#26377;&#38480;&#30340;&#26426;&#22120;&#31934;&#24230;&#19979;&#21487;&#20197;&#36798;&#21040;&#30340;&#26368;&#20339;&#31934;&#24230;&#65292;&#65288;2&#65289;&#23454;&#29616;&#32473;&#23450;&#31934;&#24230;&#25152;&#38656;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#20197;&#21450;&#65288;3&#65289;&#23545;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#30740;&#31350;&#30340;&#20851;&#38190;&#26159;&#30456;&#24212;&#28608;&#27963;&#20989;&#25968;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#30340;&#35889;&#20998;&#26512;&#65292;&#35813;&#20998;&#26512;&#36824;&#26174;&#31034;&#20102;&#28608;&#27963;&#20989;&#25968;&#23646;&#24615;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, a comprehensive numerical study involving analysis and experiments shows why a two-layer neural network has difficulties handling high frequencies in approximation and learning when machine precision and computation cost are important factors in real practice. In particular, the following fundamental computational issues are investigated: (1) the best accuracy one can achieve given a finite machine precision, (2) the computation cost to achieve a given accuracy, and (3) stability with respect to perturbations. The key to the study is the spectral analysis of the corresponding Gram matrix of the activation functions which also shows how the properties of the activation function play a role in the picture.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedJETs&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#32852;&#37030;&#28151;&#21512;&#19987;&#23478;&#30340;&#26694;&#26550;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#23454;&#29616;&#39640;&#25928;&#21450;&#26102;&#30340;&#20010;&#24615;&#21270;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#35757;&#32451;&#19987;&#38376;&#30340;&#19987;&#23478;&#65292;&#24182;&#21033;&#29992;&#38376;&#25511;&#20989;&#25968;&#23558;&#36755;&#20837;&#36335;&#30001;&#21040;&#30456;&#20851;&#30340;&#19987;&#23478;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.08586</link><description>&lt;p&gt;
FedJETs&#65306;&#20855;&#26377;&#32852;&#37030;&#28151;&#21512;&#19987;&#23478;&#30340;&#39640;&#25928;&#21450;&#26102;&#20010;&#24615;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
FedJETs: Efficient Just-In-Time Personalization with Federated Mixture of Experts. (arXiv:2306.08586v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedJETs&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#32852;&#37030;&#28151;&#21512;&#19987;&#23478;&#30340;&#26694;&#26550;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#23454;&#29616;&#39640;&#25928;&#21450;&#26102;&#30340;&#20010;&#24615;&#21270;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#35757;&#32451;&#19987;&#38376;&#30340;&#19987;&#23478;&#65292;&#24182;&#21033;&#29992;&#38376;&#25511;&#20989;&#25968;&#23558;&#36755;&#20837;&#36335;&#30001;&#21040;&#30456;&#20851;&#30340;&#19987;&#23478;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#30446;&#26631;&#20043;&#19968;&#26159;&#21019;&#24314;&#33021;&#22815;&#36866;&#24212;&#27599;&#20010;&#21442;&#19982;&#23458;&#25143;&#31471;&#19978;&#19979;&#25991;&#30340;&#20010;&#24615;&#21270;&#27169;&#22411;&#65292;&#21516;&#26102;&#21033;&#29992;&#20849;&#20139;&#20840;&#23616;&#27169;&#22411;&#30340;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#20010;&#24615;&#21270;&#38656;&#35201;&#20351;&#29992;&#23458;&#25143;&#26631;&#35760;&#30340;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#20197;&#23454;&#29616;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#36825;&#22312;&#26032;&#26469;&#30340;&#23458;&#25143;&#31471;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#22312;&#38544;&#31169;&#26041;&#38754;&#20063;&#23384;&#22312;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#22914;&#20309;&#22312;&#36825;&#20123;&#22330;&#26223;&#20013;&#23454;&#29616;&#21450;&#26102;&#20010;&#24615;&#21270;&#20173;&#28982;&#26159;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;FedJETs&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;FL&#35774;&#32622;&#20013;&#20351;&#29992;&#8220;&#19987;&#23478;&#28151;&#21512;&#65288;MoE&#65289;&#8221;&#26694;&#26550;&#30340;&#26032;&#39062;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#23458;&#25143;&#30340;&#22810;&#26679;&#24615;&#65292;&#22312;&#19981;&#21516;&#30340;&#31867;&#21035;&#23376;&#38598;&#19978;&#35757;&#32451;&#19987;&#38376;&#30340;&#19987;&#23478;&#65292;&#24182;&#21033;&#29992;&#19968;&#20010;&#38376;&#25511;&#20989;&#25968;&#23558;&#36755;&#20837;&#36335;&#30001;&#21040;&#26368;&#30456;&#20851;&#30340;&#19987;&#23478;&#12290;&#25105;&#20204;&#30340;&#38376;&#25511;&#20989;&#25968;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#20849;&#20139;&#19987;&#23478;&#30340;&#30693;&#35782;&#65292;&#20197;&#22686;&#24378;&#20854;&#21363;&#26102;&#30340;&#36335;&#30001;&#20915;&#31574;&#12290;&#20540;&#24471;&#19968;&#25552;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#23558;&#20934;&#30830;&#24615;&#25552;&#39640;&#39640;&#36798;18&#65285;&#65292;&#36798;&#21040;&#29616;&#26377;&#25216;&#26415;&#27700;&#24179;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the goals in Federated Learning (FL) is to create personalized models that can adapt to the context of each participating client, while utilizing knowledge from a shared global model. Yet, often, personalization requires a fine-tuning step using clients' labeled data in order to achieve good performance. This may not be feasible in scenarios where incoming clients are fresh and/or have privacy concerns. It, then, remains open how one can achieve just-in-time personalization in these scenarios. We propose FedJETs, a novel solution by using a Mixture-of-Experts (MoE) framework within a FL setup. Our method leverages the diversity of the clients to train specialized experts on different subsets of classes, and a gating function to route the input to the most relevant expert(s). Our gating function harnesses the knowledge of a pretrained model common expert to enhance its routing decisions on-the-fly. As a highlight, our approach can improve accuracy up to 18\% in state of the art F
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#20195;&#26367;&#23494;&#24230;&#27604;&#26469;&#20272;&#35745;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20004;&#32452;&#25968;&#25454;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#36991;&#20813;&#20102;&#20998;&#31867;&#22120;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15612</link><description>&lt;p&gt;
&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning. (arXiv:2305.15612v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15612
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#20195;&#26367;&#23494;&#24230;&#27604;&#26469;&#20272;&#35745;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20004;&#32452;&#25968;&#25454;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#36991;&#20813;&#20102;&#20998;&#31867;&#22120;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#31185;&#23398;&#19982;&#24037;&#31243;&#30340;&#22810;&#20010;&#39046;&#22495;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#33021;&#39640;&#25928;&#22320;&#25214;&#21040;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#36890;&#24120;&#65292;&#19968;&#20010;&#27010;&#29575;&#22238;&#24402;&#27169;&#22411;&#65292;&#22914;&#39640;&#26031;&#36807;&#31243;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#34987;&#24191;&#27867;&#29992;&#20316;&#26367;&#20195;&#20989;&#25968;&#65292;&#29992;&#20110;&#27169;&#25311;&#22312;&#32473;&#23450;&#36755;&#20837;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#20989;&#25968;&#35780;&#20272;&#30340;&#26174;&#24335;&#20998;&#24067;&#12290;&#38500;&#20102;&#22522;&#20110;&#27010;&#29575;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#24050;&#34987;&#25552;&#20986;&#26469;&#20272;&#35745;&#30456;&#23545;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#30456;&#23545;&#25509;&#36817;&#21644;&#30456;&#23545;&#36828;&#31163;&#30340;&#20004;&#32452;&#23494;&#24230;&#27604;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#21457;&#23637;&#36825;&#19968;&#30740;&#31350;&#65292;&#21487;&#20197;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#26469;&#20272;&#35745;&#36825;&#20004;&#32452;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#32780;&#19981;&#26159;&#23494;&#24230;&#27604;&#12290;&#28982;&#32780;&#65292;&#27492;&#31574;&#30053;&#20013;&#20351;&#29992;&#30340;&#30417;&#30563;&#20998;&#31867;&#22120;&#20542;&#21521;&#20110;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization has attracted huge attention from diverse research areas in science and engineering, since it is capable of finding a global optimum of an expensive-to-evaluate black-box function efficiently. In general, a probabilistic regression model, e.g., Gaussian processes, random forests, and Bayesian neural networks, is widely used as a surrogate function to model an explicit distribution over function evaluations given an input to estimate and a training dataset. Beyond the probabilistic regression-based Bayesian optimization, density ratio estimation-based Bayesian optimization has been suggested in order to estimate a density ratio of the groups relatively close and relatively far to a global optimum. Developing this line of research further, a supervised classifier can be employed to estimate a class probability for the two groups instead of a density ratio. However, the supervised classifiers used in this strategy tend to be overconfident for a global solution candid
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#22312;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#20256;&#36882;&#26377;&#29992;&#20449;&#24687;&#30340;&#36807;&#31243;&#20013;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#65292;&#20855;&#26377;&#39640;&#25928;&#21644;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#31561;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.05529</link><description>&lt;p&gt;
&#21033;&#29992;Birth-Death &#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#21152;&#36895;Langevin&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Accelerate Langevin Sampling with Birth-Death process and Exploration Component. (arXiv:2305.05529v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05529
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#22312;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#20256;&#36882;&#26377;&#29992;&#20449;&#24687;&#30340;&#36807;&#31243;&#20013;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#65292;&#20855;&#26377;&#39640;&#25928;&#21644;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#65292;&#37319;&#26679;&#24050;&#30693;&#27010;&#29575;&#20998;&#24067;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#38024;&#23545;&#22810;&#23792;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#12290;&#35813;&#26041;&#27861;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#8220;&#19977;&#24605;&#32780;&#21518;&#34892;&#8221;&#12290;&#25105;&#20204;&#20445;&#30041;&#20004;&#32452;&#37319;&#26679;&#22120;&#65292;&#19968;&#32452;&#22312;&#36739;&#39640;&#28201;&#24230;&#19979;&#65292;&#19968;&#32452;&#22312;&#21407;&#22987;&#28201;&#24230;&#19979;&#12290;&#21069;&#32773;&#20316;&#20026;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#23558;&#26377;&#29992;&#20449;&#24687;&#20256;&#36882;&#32473;&#21518;&#32773;&#30340;&#20808;&#39537;&#65292;&#21518;&#32773;&#22312;&#25509;&#25910;&#20449;&#24687;&#21518;&#23545;&#30446;&#26631;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22343;&#22330;&#26497;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#25506;&#32034;&#36807;&#31243;&#22914;&#20309;&#20915;&#23450;&#37319;&#26679;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23545;&#20197;&#21069;&#25991;&#29486;&#20013;&#30340;&#23454;&#39564;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#24182;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling a probability distribution with known likelihood is a fundamental task in computational science and engineering. Aiming at multimodality, we propose a new sampling method that takes advantage of both birth-death process and exploration component. The main idea of this method is \textit{look before you leap}. We keep two sets of samplers, one at warmer temperature and one at original temperature. The former one serves as pioneer in exploring new modes and passing useful information to the other, while the latter one samples the target distribution after receiving the information. We derive a mean-field limit and show how the exploration process determines sampling efficiency. Moreover, we prove exponential asymptotic convergence under mild assumption. Finally, we test on experiments from previous literature and compared our methodology to previous ones.
&lt;/p&gt;</description></item></channel></rss>