<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>GRAPHGINI&#22312;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#39318;&#27425;&#24341;&#20837;&#20102;&#22522;&#23612;&#31995;&#25968;&#20316;&#20026;&#20844;&#24179;&#24615;&#24230;&#37327;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#23454;&#29616;&#20010;&#20307;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#65292;&#24182;&#20445;&#25345;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12937</link><description>&lt;p&gt;
GRAPHGINI&#65306;&#22312;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#20419;&#36827;&#20010;&#20307;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
GRAPHGINI: Fostering Individual and Group Fairness in Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12937
&lt;/p&gt;
&lt;p&gt;
GRAPHGINI&#22312;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#39318;&#27425;&#24341;&#20837;&#20102;&#22522;&#23612;&#31995;&#25968;&#20316;&#20026;&#20844;&#24179;&#24615;&#24230;&#37327;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#23454;&#29616;&#20010;&#20307;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#65292;&#24182;&#20445;&#25345;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#26085;&#30410;&#22686;&#38271;&#30340;&#25285;&#24551;&#65292;&#21363;&#22312;&#32570;&#20047;&#20844;&#24179;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;GNN&#21487;&#33021;&#20250;&#20135;&#29983;&#20559;&#35265;&#20915;&#31574;&#65292;&#20174;&#32780;&#19981;&#25104;&#27604;&#20363;&#22320;&#24433;&#21709;&#21040;&#24369;&#21183;&#32676;&#20307;&#25110;&#20010;&#20154;&#12290;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#39318;&#27425;&#24341;&#20837;&#20102;&#19968;&#31181;&#23558;&#22522;&#23612;&#31995;&#25968;&#20316;&#20026;&#20844;&#24179;&#24615;&#24230;&#37327;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;GNN&#26694;&#26550;&#20869;&#20351;&#29992;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#65292;GRAPHGINI&#65292;&#22312;&#21333;&#20010;&#31995;&#32479;&#20013;&#22788;&#29702;&#20010;&#20307;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#30340;&#20004;&#20010;&#19981;&#21516;&#30446;&#26631;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;GRAPHGINI&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#27880;&#24847;&#21147;&#20998;&#25968;&#26469;&#23454;&#26045;&#20010;&#20307;&#20844;&#24179;&#24615;&#65292;&#36825;&#26377;&#21161;&#20110;&#36890;&#36807;&#31867;&#20284;&#33410;&#28857;&#32858;&#21512;&#26356;&#22810;&#20449;&#24687;&#12290;&#22522;&#20110;&#21551;&#21457;&#24335;&#30340;&#26368;&#22823;&#32435;&#20160;&#31038;&#20250;&#31119;&#21033;&#32422;&#26463;&#30830;&#20445;&#20102;&#26368;&#22823;&#21487;&#33021;&#30340;&#32676;&#20307;&#20844;&#24179;&#12290;&#20010;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#37117;&#26159;&#20197;&#21487;&#24494;&#20998;&#30340;&#22522;&#23612;&#31995;&#25968;&#30340;&#36817;&#20284;&#24418;&#24335;&#38472;&#36848;&#30340;&#12290;&#36825;&#31181;&#36817;&#20284;&#26159;&#19968;&#20010;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12937v1 Announce Type: new  Abstract: We address the growing apprehension that GNNs, in the absence of fairness constraints, might produce biased decisions that disproportionately affect underprivileged groups or individuals. Departing from previous work, we introduce for the first time a method for incorporating the Gini coefficient as a measure of fairness to be used within the GNN framework. Our proposal, GRAPHGINI, works with the two different goals of individual and group fairness in a single system, while maintaining high prediction accuracy. GRAPHGINI enforces individual fairness through learnable attention scores that help in aggregating more information through similar nodes. A heuristic-based maximum Nash social welfare constraint ensures the maximum possible group fairness. Both the individual fairness constraint and the group fairness constraint are stated in terms of a differentiable approximation of the Gini coefficient. This approximation is a contribution tha
&lt;/p&gt;</description></item><item><title>TIGT&#26159;&#19968;&#31181;&#22522;&#20110;&#25299;&#25169;&#20449;&#24687;&#30340;&#26032;&#22411;&#22270;&#24418;&#21464;&#25442;&#22120;&#65292;&#36890;&#36807;&#22686;&#24378;&#21306;&#20998;&#22270;&#21516;&#26500;&#24615;&#30340;&#33021;&#21147;&#21644;&#25552;&#39640;&#22270;&#24418;&#21464;&#25442;&#22120;&#24615;&#33021;&#65292;&#23454;&#29616;&#20102;&#23545;&#22270;&#21516;&#26500;&#24615;&#30340;&#26816;&#27979;&#21644;&#25972;&#20307;&#24615;&#33021;&#30340;&#22686;&#24378;&#12290;</title><link>https://arxiv.org/abs/2402.02005</link><description>&lt;p&gt;
&#22522;&#20110;&#25299;&#25169;&#20449;&#24687;&#30340;&#22270;&#24418;&#21464;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Topology-Informed Graph Transformer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02005
&lt;/p&gt;
&lt;p&gt;
TIGT&#26159;&#19968;&#31181;&#22522;&#20110;&#25299;&#25169;&#20449;&#24687;&#30340;&#26032;&#22411;&#22270;&#24418;&#21464;&#25442;&#22120;&#65292;&#36890;&#36807;&#22686;&#24378;&#21306;&#20998;&#22270;&#21516;&#26500;&#24615;&#30340;&#33021;&#21147;&#21644;&#25552;&#39640;&#22270;&#24418;&#21464;&#25442;&#22120;&#24615;&#33021;&#65292;&#23454;&#29616;&#20102;&#23545;&#22270;&#21516;&#26500;&#24615;&#30340;&#26816;&#27979;&#21644;&#25972;&#20307;&#24615;&#33021;&#30340;&#22686;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#24418;&#22120;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35270;&#35273;&#39046;&#22495;&#20013;&#21462;&#24471;&#20102;&#31361;&#30772;&#24615;&#30340;&#25104;&#26524;&#65292;&#20026;&#19982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#38598;&#25104;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;&#22686;&#24378;&#22270;&#24418;&#21464;&#25442;&#22120;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#22686;&#24378;&#21306;&#20998;&#22270;&#30340;&#21516;&#26500;&#24615;&#30340;&#21306;&#20998;&#33021;&#21147;&#65292;&#36825;&#22312;&#25552;&#39640;&#23427;&#20204;&#30340;&#39044;&#27979;&#24615;&#33021;&#20013;&#36215;&#21040;&#20851;&#38190;&#20316;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#24418;&#22120;&#8212;&#8212;&#8220;&#22522;&#20110;&#25299;&#25169;&#20449;&#24687;&#30340;&#22270;&#24418;&#21464;&#25442;&#22120;&#65288;TIGT&#65289;&#8221;&#65292;&#23427;&#22686;&#24378;&#20102;&#26816;&#27979;&#22270;&#21516;&#26500;&#24615;&#30340;&#21306;&#20998;&#33021;&#21147;&#21644;&#22270;&#24418;&#21464;&#25442;&#22120;&#30340;&#25972;&#20307;&#24615;&#33021;&#12290;TIGT&#30001;&#22235;&#20010;&#32452;&#20214;&#32452;&#25104;&#65306;&#19968;&#20010;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;&#24490;&#29615;&#23376;&#22270;&#30340;&#38750;&#21516;&#26500;&#21367;&#19978;&#30340;&#25299;&#25169;&#20301;&#32622;&#23884;&#20837;&#23618;&#65292;&#20197;&#30830;&#20445;&#21807;&#19968;&#30340;&#22270;&#34920;&#31034;&#65307;&#19968;&#20010;&#21452;&#36335;&#24452;&#28040;&#24687;&#20256;&#36882;&#23618;&#65292;&#20197;&#26126;&#30830;&#22320;&#32534;&#30721;&#25299;&#25169;&#29305;&#24449;&#65307;&#19968;&#20010;&#20840;&#23616;&#27880;&#24847;&#26426;&#21046;&#65307;&#21644;&#19968;&#20010;&#22270;&#20449;&#24687;&#23618;&#65292;&#29992;&#20110;&#37325;&#26032;&#26657;&#20934;&#36890;&#36947;&#32423;&#30340;&#22270;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers have revolutionized performance in Natural Language Processing and Vision, paving the way for their integration with Graph Neural Networks (GNNs). One key challenge in enhancing graph transformers is strengthening the discriminative power of distinguishing isomorphisms of graphs, which plays a crucial role in boosting their predictive performances. To address this challenge, we introduce 'Topology-Informed Graph Transformer (TIGT)', a novel transformer enhancing both discriminative power in detecting graph isomorphisms and the overall performance of Graph Transformers. TIGT consists of four components: A topological positional embedding layer using non-isomorphic universal covers based on cyclic subgraphs of graphs to ensure unique graph representation: A dual-path message-passing layer to explicitly encode topological characteristics throughout the encoder layers: A global attention mechanism: And a graph information layer to recalibrate channel-wise graph features for be
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#35777;&#26126;signSGD&#31639;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#25910;&#25947;&#24615;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#20998;&#26512;&#20013;&#30340;&#32570;&#38519;&#65292;&#25552;&#20986;&#20102;SignRVR&#21644;SignRVM&#31639;&#27861;&#65292;&#24182;&#19988;&#37117;&#20197;&#36739;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.15976</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#30340;&#22522;&#20110;&#31526;&#21495;&#38543;&#26426;&#37325;&#25490;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex Optimization. (arXiv:2310.15976v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15976
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#35777;&#26126;signSGD&#31639;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#25910;&#25947;&#24615;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#20998;&#26512;&#20013;&#30340;&#32570;&#38519;&#65292;&#25552;&#20986;&#20102;SignRVR&#21644;SignRVM&#31639;&#27861;&#65292;&#24182;&#19988;&#37117;&#20197;&#36739;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#36890;&#20449;&#25928;&#29575;&#36739;&#39640;&#65292;signSGD&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#24456;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#23545;signSGD&#30340;&#20998;&#26512;&#22522;&#20110;&#20551;&#35774;&#27599;&#27425;&#36845;&#20195;&#20013;&#30340;&#25968;&#25454;&#37117;&#26159;&#26377;&#25918;&#22238;&#37319;&#26679;&#30340;&#65292;&#36825;&#19982;&#23454;&#38469;&#23454;&#29616;&#20013;&#25968;&#25454;&#30340;&#38543;&#26426;&#37325;&#25490;&#21644;&#39034;&#24207;&#39304;&#36865;&#36827;&#31639;&#27861;&#30340;&#24773;&#20917;&#30456;&#30683;&#30462;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;signSGD&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#39318;&#20010;&#25910;&#25947;&#32467;&#26524;&#12290;&#32473;&#23450;&#25968;&#25454;&#38598;&#22823;&#23567;$n$&#65292;&#25968;&#25454;&#36845;&#20195;&#27425;&#25968;$T$&#65292;&#21644;&#38543;&#26426;&#26799;&#24230;&#30340;&#26041;&#24046;&#38480;&#21046;$\sigma^2$&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SignRR&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;signSGD&#30456;&#21516;&#65292;&#20026;$O(\log(nT)/\sqrt{nT} + \|\sigma\|_1)$ \citep{bernstein2018signsgd}&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102; SignRVR &#21644; SignRVM&#65292;&#20998;&#21035;&#21033;&#29992;&#20102;&#26041;&#24046;&#32422;&#20943;&#26799;&#24230;&#21644;&#21160;&#37327;&#26356;&#26032;&#65292;&#37117;&#20197;$O(\log(nT)/\sqrt{nT})$&#30340;&#36895;&#24230;&#25910;&#25947;&#12290;&#19982;signSGD&#30340;&#20998;&#26512;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#38656;&#35201;&#27599;&#27425;&#36845;&#20195;&#20013;&#26497;&#22823;&#30340;&#25209;&#27425;&#22823;&#23567;&#19982;&#21516;&#31561;&#25968;&#37327;&#30340;&#26799;&#24230;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
signSGD is popular in nonconvex optimization due to its communication efficiency. Yet, existing analyses of signSGD rely on assuming that data are sampled with replacement in each iteration, contradicting the practical implementation where data are randomly reshuffled and sequentially fed into the algorithm. We bridge this gap by proving the first convergence result of signSGD with random reshuffling (SignRR) for nonconvex optimization. Given the dataset size $n$, the number of epochs of data passes $T$, and the variance bound of a stochastic gradient $\sigma^2$, we show that SignRR has the same convergence rate $O(\log(nT)/\sqrt{nT} + \|\sigma\|_1)$ as signSGD \citep{bernstein2018signsgd}. We then present SignRVR and SignRVM, which leverage variance-reduced gradients and momentum updates respectively, both converging at $O(\log(nT)/\sqrt{nT})$. In contrast with the analysis of signSGD, our results do not require an extremely large batch size in each iteration to be of the same order a
&lt;/p&gt;</description></item></channel></rss>