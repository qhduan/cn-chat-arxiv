<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#24212;&#29992;&#39537;&#21160;&#30740;&#31350;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#21487;&#20197;&#19982;&#26041;&#27861;&#39537;&#21160;&#30740;&#31350;&#26377;&#30410;&#22320;&#21327;&#21516;&#65292;&#20294;&#30446;&#21069;&#23457;&#26597;&#12289;&#25307;&#32856;&#21644;&#25945;&#23398;&#23454;&#36341;&#24448;&#24448;&#38459;&#30861;&#20102;&#36825;&#31181;&#21019;&#26032;&#12290;</title><link>https://arxiv.org/abs/2403.17381</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#39537;&#21160;&#21019;&#26032;
&lt;/p&gt;
&lt;p&gt;
Application-Driven Innovation in Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17381
&lt;/p&gt;
&lt;p&gt;
&#24212;&#29992;&#39537;&#21160;&#30740;&#31350;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#21487;&#20197;&#19982;&#26041;&#27861;&#39537;&#21160;&#30740;&#31350;&#26377;&#30410;&#22320;&#21327;&#21516;&#65292;&#20294;&#30446;&#21069;&#23457;&#26597;&#12289;&#25307;&#32856;&#21644;&#25945;&#23398;&#23454;&#36341;&#24448;&#24448;&#38459;&#30861;&#20102;&#36825;&#31181;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#19981;&#26029;&#22686;&#38271;&#65292;&#21463;&#29305;&#23450;&#29616;&#23454;&#25361;&#25112;&#21551;&#21457;&#30340;&#21019;&#26032;&#31639;&#27861;&#21464;&#24471;&#26085;&#30410;&#37325;&#35201;&#12290;&#36825;&#26679;&#30340;&#24037;&#20316;&#19981;&#20165;&#22312;&#24212;&#29992;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#20063;&#22312;&#26426;&#22120;&#23398;&#20064;&#26412;&#36523;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#39537;&#21160;&#30740;&#31350;&#30340;&#33539;&#24335;&#65292;&#23558;&#20854;&#19982;&#26356;&#26631;&#20934;&#30340;&#26041;&#27861;&#39537;&#21160;&#30740;&#31350;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#24212;&#29992;&#39537;&#21160;&#26426;&#22120;&#23398;&#20064;&#30340;&#22909;&#22788;&#65292;&#20197;&#21450;&#36825;&#31181;&#26041;&#27861;&#22914;&#20309;&#21487;&#20197;&#19982;&#26041;&#27861;&#39537;&#21160;&#24037;&#20316;&#26377;&#30410;&#22320;&#21327;&#21516;&#12290;&#23613;&#31649;&#20855;&#26377;&#36825;&#20123;&#22909;&#22788;&#65292;&#25105;&#20204;&#21457;&#29616;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#23457;&#26597;&#12289;&#25307;&#32856;&#21644;&#25945;&#23398;&#23454;&#36341;&#24448;&#24448;&#38459;&#30861;&#20102;&#24212;&#29992;&#39537;&#21160;&#21019;&#26032;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#22914;&#20309;&#25913;&#36827;&#36825;&#20123;&#27969;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17381v1 Announce Type: cross  Abstract: As applications of machine learning proliferate, innovative algorithms inspired by specific real-world challenges have become increasingly important. Such work offers the potential for significant impact not merely in domains of application but also in machine learning itself. In this paper, we describe the paradigm of application-driven research in machine learning, contrasting it with the more standard paradigm of methods-driven research. We illustrate the benefits of application-driven machine learning and how this approach can productively synergize with methods-driven work. Despite these benefits, we find that reviewing, hiring, and teaching practices in machine learning often hold back application-driven innovation. We outline how these processes may be improved.
&lt;/p&gt;</description></item><item><title>LOOPer&#26159;&#38024;&#23545;&#22810;&#38754;&#20307;&#32534;&#35793;&#22120;&#30340;&#23398;&#20064;&#22411;&#33258;&#21160;&#20195;&#30721;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#24314;&#31435;&#25104;&#26412;&#27169;&#22411;&#26469;&#25351;&#23548;&#22810;&#38754;&#20307;&#20248;&#21270;&#25628;&#32034;&#65292;&#31361;&#30772;&#20102;&#20256;&#32479;&#32534;&#35793;&#22120;&#22312;&#36873;&#25321;&#20195;&#30721;&#36716;&#25442;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.11522</link><description>&lt;p&gt;
LOOPer: &#19968;&#20010;&#38024;&#23545;&#22810;&#38754;&#20307;&#32534;&#35793;&#22120;&#30340;&#23398;&#20064;&#22411;&#33258;&#21160;&#20195;&#30721;&#20248;&#21270;&#22120;
&lt;/p&gt;
&lt;p&gt;
LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11522
&lt;/p&gt;
&lt;p&gt;
LOOPer&#26159;&#38024;&#23545;&#22810;&#38754;&#20307;&#32534;&#35793;&#22120;&#30340;&#23398;&#20064;&#22411;&#33258;&#21160;&#20195;&#30721;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#24314;&#31435;&#25104;&#26412;&#27169;&#22411;&#26469;&#25351;&#23548;&#22810;&#38754;&#20307;&#20248;&#21270;&#25628;&#32034;&#65292;&#31361;&#30772;&#20102;&#20256;&#32479;&#32534;&#35793;&#22120;&#22312;&#36873;&#25321;&#20195;&#30721;&#36716;&#25442;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22810;&#38754;&#20307;&#32534;&#35793;&#22120;&#22312;&#23454;&#29616;&#39640;&#32423;&#20195;&#30721;&#36716;&#25442;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#25104;&#21151;&#65292;&#20294;&#22312;&#36873;&#25321;&#33021;&#22815;&#24102;&#26469;&#26368;&#20339;&#21152;&#36895;&#30340;&#26368;&#26377;&#21033;&#36716;&#25442;&#26041;&#38754;&#20173;&#28982;&#38754;&#20020;&#25361;&#25112;&#12290;&#36825;&#20419;&#20351;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26500;&#24314;&#25104;&#26412;&#27169;&#22411;&#26469;&#24341;&#23548;&#22810;&#38754;&#20307;&#20248;&#21270;&#30340;&#25628;&#32034;&#12290;&#26368;&#20808;&#36827;&#30340;&#22810;&#38754;&#20307;&#32534;&#35793;&#22120;&#24050;&#32463;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#27010;&#24565;&#39564;&#35777;&#12290;&#34429;&#28982;&#36825;&#31181;&#27010;&#24565;&#39564;&#35777;&#26174;&#31034;&#20986;&#20102;&#24076;&#26395;&#65292;&#20294;&#20173;&#28982;&#23384;&#22312;&#26174;&#33879;&#38480;&#21046;&#12290;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#25104;&#26412;&#27169;&#22411;&#30340;&#26368;&#20808;&#36827;&#22810;&#38754;&#20307;&#32534;&#35793;&#22120;&#21482;&#25903;&#25345;&#23569;&#37327;&#20223;&#23556;&#21464;&#25442;&#30340;&#23376;&#38598;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#24212;&#29992;&#22797;&#26434;&#20195;&#30721;&#21464;&#25442;&#30340;&#33021;&#21147;&#12290;&#23427;&#20204;&#36824;&#21482;&#25903;&#25345;&#20855;&#26377;&#21333;&#20010;&#24490;&#29615;&#23884;&#22871;&#21644;&#30697;&#24418;&#36845;&#20195;&#22495;&#30340;&#31616;&#21333;&#31243;&#24207;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#23545;&#35768;&#22810;&#31243;&#24207;&#30340;&#36866;&#29992;&#24615;&#12290;&#36825;&#20123;&#38480;&#21046;&#26174;&#33879;&#24433;&#21709;&#20102;&#36825;&#26679;&#30340;&#32534;&#35793;&#22120;&#21644;&#33258;&#21160;&#35843;&#24230;&#22120;&#30340;&#36890;&#29992;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11522v1 Announce Type: cross  Abstract: While polyhedral compilers have shown success in implementing advanced code transformations, they still have challenges in selecting the most profitable transformations that lead to the best speedups. This has motivated the use of machine learning to build cost models to guide the search for polyhedral optimizations. State-of-the-art polyhedral compilers have demonstrated a viable proof-of-concept of this approach. While such a proof-of-concept has shown promise, it still has significant limitations. State-of-the-art polyhedral compilers that use a deep-learning cost model only support a small subset of affine transformations, limiting their ability to apply complex code transformations. They also only support simple programs that have a single loop nest and a rectangular iteration domain, limiting their applicability to many programs. These limitations significantly impact the generality of such compilers and autoschedulers and put in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26631;&#20934;&#29289;&#20307;&#26816;&#27979;&#22120;&#22312;&#22797;&#26434;&#30340;&#24037;&#19994;&#32456;&#31471;&#26465;&#23545;&#35937;&#26816;&#27979;&#24212;&#29992;&#20013;&#30340;&#27169;&#25311;&#21040;&#30495;&#23454;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.04809</link><description>&lt;p&gt;
&#30740;&#31350;&#21512;&#25104;&#35757;&#32451;&#25968;&#25454;&#23545;&#32456;&#31471;&#26465;&#23545;&#35937;&#26816;&#27979;&#24037;&#19994;&#24212;&#29992;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Investigation of the Impact of Synthetic Training Data in the Industrial Application of Terminal Strip Object Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26631;&#20934;&#29289;&#20307;&#26816;&#27979;&#22120;&#22312;&#22797;&#26434;&#30340;&#24037;&#19994;&#32456;&#31471;&#26465;&#23545;&#35937;&#26816;&#27979;&#24212;&#29992;&#20013;&#30340;&#27169;&#25311;&#21040;&#30495;&#23454;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#19994;&#21046;&#36896;&#20013;&#65292;&#23384;&#22312;&#35768;&#22810;&#26816;&#26597;&#25110;&#26816;&#27979;&#29305;&#23450;&#23545;&#35937;&#30340;&#20219;&#21153;&#65292;&#30446;&#21069;&#36825;&#20123;&#20219;&#21153;&#36890;&#24120;&#30001;&#20154;&#24037;&#25110;&#32463;&#20856;&#22270;&#20687;&#22788;&#29702;&#26041;&#27861;&#25191;&#34892;&#12290;&#22240;&#27492;&#65292;&#22312;&#24037;&#19994;&#29615;&#22659;&#24341;&#20837;&#26368;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26377;&#21487;&#33021;&#25552;&#39640;&#29983;&#20135;&#25928;&#29575;&#24182;&#23454;&#29616;&#26032;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#25910;&#38598;&#21644;&#26631;&#35760;&#36275;&#22815;&#30340;&#25968;&#25454;&#36890;&#24120;&#26159;&#22256;&#38590;&#30340;&#65292;&#36825;&#20351;&#24471;&#36825;&#31867;&#39033;&#30446;&#30340;&#23454;&#26045;&#21464;&#24471;&#22797;&#26434;&#12290;&#22240;&#27492;&#65292;&#22270;&#20687;&#21512;&#25104;&#26041;&#27861;&#36890;&#24120;&#29992;&#20110;&#20174;3D&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#33258;&#21160;&#26631;&#27880;&#36825;&#20123;&#25968;&#25454;&#65292;&#23613;&#31649;&#36825;&#20250;&#23548;&#33268;&#19968;&#20010;&#27169;&#25311;&#21040;&#30495;&#23454;&#39046;&#22495;&#24046;&#36317;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26631;&#20934;&#29289;&#20307;&#26816;&#27979;&#22120;&#22312;&#22797;&#26434;&#30340;&#24037;&#19994;&#32456;&#31471;&#26465;&#23545;&#35937;&#26816;&#27979;&#24212;&#29992;&#20013;&#30340;&#27169;&#25311;&#21040;&#30495;&#23454;&#27867;&#21270;&#24615;&#33021;&#12290;&#36890;&#36807;&#32467;&#21512;&#39046;&#22495;&#38543;&#26426;&#21270;&#21644;&#39046;&#22495;&#30693;&#35782;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#22270;&#20687;&#21512;&#25104;&#27969;&#27700;&#32447;&#65292;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04809v1 Announce Type: cross  Abstract: In industrial manufacturing, numerous tasks of visually inspecting or detecting specific objects exist that are currently performed manually or by classical image processing methods. Therefore, introducing recent deep learning models to industrial environments holds the potential to increase productivity and enable new applications. However, gathering and labeling sufficient data is often intractable, complicating the implementation of such projects. Hence, image synthesis methods are commonly used to generate synthetic training data from 3D models and annotate them automatically, although it results in a sim-to-real domain gap. In this paper, we investigate the sim-to-real generalization performance of standard object detectors on the complex industrial application of terminal strip object detection. Combining domain randomization and domain knowledge, we created an image synthesis pipeline for automatically generating the training da
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22522;&#20110;GAN&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#23431;&#23449;&#23398;&#27169;&#25311;&#20013;&#23581;&#35797;&#39044;&#27979;&#32467;&#26500;&#28436;&#21270;&#65292;&#21457;&#29616;&#22312;2D&#27169;&#25311;&#20013;&#33021;&#22815;&#24456;&#22909;&#22320;&#39044;&#27979;&#26263;&#29289;&#36136;&#22330;&#30340;&#32467;&#26500;&#28436;&#21270;&#65292;&#20294;&#22312;3D&#27169;&#25311;&#20013;&#34920;&#29616;&#26356;&#24046;&#65292;&#25552;&#20379;&#36895;&#24230;&#22330;&#20316;&#20026;&#36755;&#20837;&#21518;&#32467;&#26524;&#26174;&#33879;&#25913;&#21892;&#12290;</title><link>https://arxiv.org/abs/2403.02171</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;GAN&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#39044;&#27979;&#23431;&#23449;&#22823;&#23610;&#24230;&#32467;&#26500;&#28436;&#21270;
&lt;/p&gt;
&lt;p&gt;
Predicting large scale cosmological structure evolution with GAN-based autoencoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02171
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;GAN&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#23431;&#23449;&#23398;&#27169;&#25311;&#20013;&#23581;&#35797;&#39044;&#27979;&#32467;&#26500;&#28436;&#21270;&#65292;&#21457;&#29616;&#22312;2D&#27169;&#25311;&#20013;&#33021;&#22815;&#24456;&#22909;&#22320;&#39044;&#27979;&#26263;&#29289;&#36136;&#22330;&#30340;&#32467;&#26500;&#28436;&#21270;&#65292;&#20294;&#22312;3D&#27169;&#25311;&#20013;&#34920;&#29616;&#26356;&#24046;&#65292;&#25552;&#20379;&#36895;&#24230;&#22330;&#20316;&#20026;&#36755;&#20837;&#21518;&#32467;&#26524;&#26174;&#33879;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23431;&#23449;&#23398;&#27169;&#25311;&#22312;&#20174;&#21021;&#22987;&#26465;&#20214;&#39044;&#27979;&#21644;&#29702;&#35299;&#22823;&#23610;&#24230;&#32467;&#26500;&#24418;&#25104;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#25105;&#20204;&#21033;&#29992;&#22522;&#20110;GAN&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#23581;&#35797;&#39044;&#27979;&#27169;&#25311;&#20013;&#30340;&#32467;&#26500;&#28436;&#21270;&#12290;&#33258;&#21160;&#32534;&#30721;&#22120;&#26159;&#22312;&#25551;&#36848;&#26263;&#29289;&#36136;&#22330;&#28436;&#21270;&#30340;2D&#21644;3D N&#20307;&#27169;&#25311;&#29983;&#25104;&#30340;&#22270;&#20687;&#21644;&#31435;&#26041;&#20307;&#19978;&#36827;&#34892;&#35757;&#32451;&#30340;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#33258;&#21160;&#32534;&#30721;&#22120;&#21487;&#20197;&#24456;&#22909;&#22320;&#39044;&#27979;2D&#27169;&#25311;&#26263;&#29289;&#36136;&#22330;&#30340;&#32467;&#26500;&#28436;&#21270;&#65292;&#20294;&#22312;&#31867;&#20284;&#26465;&#20214;&#19979;&#65292;&#20165;&#20351;&#29992;&#23494;&#24230;&#22330;&#20316;&#20026;&#36755;&#20837;&#24773;&#20917;&#19979;&#65292;&#22312;3D&#27169;&#25311;&#20013;&#34920;&#29616;&#26126;&#26174;&#26356;&#24046;&#12290;&#28982;&#32780;&#65292;&#25552;&#20379;&#36895;&#24230;&#22330;&#20316;&#20026;&#36755;&#20837;&#33021;&#22815;&#22823;&#22823;&#25913;&#21892;&#32467;&#26524;&#65292;&#39044;&#27979;&#31867;&#20284;&#65292;&#32780;&#26080;&#35770;&#36755;&#20837;&#21644;&#30446;&#26631;&#20043;&#38388;&#30340;&#26102;&#38388;&#24046;&#24322;&#22914;&#20309;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02171v1 Announce Type: cross  Abstract: Cosmological simulations play a key role in the prediction and understanding of large scale structure formation from initial conditions. We make use of GAN-based Autoencoders (AEs) in an attempt to predict structure evolution within simulations. The AEs are trained on images and cubes issued from respectively 2D and 3D N-body simulations describing the evolution of the dark matter (DM) field. We find that while the AEs can predict structure evolution for 2D simulations of DM fields well, using only the density fields as input, they perform significantly more poorly in similar conditions for 3D simulations. However, additionally providing velocity fields as inputs greatly improves results, with similar predictions regardless of time-difference between input and target.
&lt;/p&gt;</description></item><item><title>DE$^3$-BERT&#26159;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#32593;&#32476;&#21644;&#36317;&#31163;&#24230;&#37327;&#30340;&#22686;&#24378;&#36317;&#31163;&#26089;&#26399;&#20572;&#27490;&#26694;&#26550;&#65292;&#29992;&#20110;&#25552;&#39640;BERT&#31561;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#26029;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05948</link><description>&lt;p&gt;
DE$^3$-BERT: &#22522;&#20110;&#21407;&#22411;&#32593;&#32476;&#30340;&#22686;&#24378;&#36317;&#31163;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#65292;&#29992;&#20110;BERT
&lt;/p&gt;
&lt;p&gt;
DE$^3$-BERT: Distance-Enhanced Early Exiting for BERT based on Prototypical Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05948
&lt;/p&gt;
&lt;p&gt;
DE$^3$-BERT&#26159;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#32593;&#32476;&#21644;&#36317;&#31163;&#24230;&#37327;&#30340;&#22686;&#24378;&#36317;&#31163;&#26089;&#26399;&#20572;&#27490;&#26694;&#26550;&#65292;&#29992;&#20110;&#25552;&#39640;BERT&#31561;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#26029;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#25191;&#34892;&#30340;&#23618;&#25968;&#65292;&#25552;&#39640;&#20102;&#20687;BERT&#36825;&#26679;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#26029;&#36895;&#24230;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#20165;&#32771;&#34385;&#20102;&#26469;&#33258;&#21333;&#20010;&#27979;&#35797;&#26679;&#26412;&#30340;&#23616;&#37096;&#20449;&#24687;&#26469;&#30830;&#23450;&#26089;&#26399;&#20572;&#27490;&#30340;&#25351;&#26631;&#65292;&#32780;&#26410;&#21033;&#29992;&#26679;&#26412;&#32676;&#20307;&#25552;&#20379;&#30340;&#20840;&#23616;&#20449;&#24687;&#12290;&#36825;&#23548;&#33268;&#23545;&#39044;&#27979;&#27491;&#30830;&#24615;&#30340;&#20272;&#35745;&#19981;&#22815;&#20934;&#30830;&#65292;&#20174;&#32780;&#20135;&#29983;&#38169;&#35823;&#30340;&#26089;&#26399;&#20572;&#27490;&#20915;&#31574;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#26377;&#25928;&#32467;&#21512;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#20197;&#30830;&#20445;&#21487;&#38752;&#30340;&#26089;&#26399;&#20572;&#27490;&#30340;&#24517;&#35201;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#21033;&#29992;&#21407;&#22411;&#32593;&#32476;&#23398;&#20064;&#31867;&#21035;&#21407;&#22411;&#65292;&#24182;&#35774;&#35745;&#20102;&#26679;&#26412;&#21644;&#31867;&#21035;&#21407;&#22411;&#20043;&#38388;&#30340;&#36317;&#31163;&#24230;&#37327;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#20840;&#23616;&#20449;&#24687;&#26469;&#20272;&#35745;&#26089;&#26399;&#39044;&#27979;&#30340;&#27491;&#30830;&#24615;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;DE$^3$-BERT&#22686;&#24378;&#36317;&#31163;&#26089;&#26399;&#20572;&#27490;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Early exiting has demonstrated its effectiveness in accelerating the inference of pre-trained language models like BERT by dynamically adjusting the number of layers executed. However, most existing early exiting methods only consider local information from an individual test sample to determine their exiting indicators, failing to leverage the global information offered by sample population. This leads to suboptimal estimation of prediction correctness, resulting in erroneous exiting decisions. To bridge the gap, we explore the necessity of effectively combining both local and global information to ensure reliable early exiting during inference. Purposefully, we leverage prototypical networks to learn class prototypes and devise a distance metric between samples and class prototypes. This enables us to utilize global information for estimating the correctness of early predictions. On this basis, we propose a novel Distance-Enhanced Early Exiting framework for BERT (DE$^3$-BERT). DE$^3
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2312.08531</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.08531
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#37324;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#65292;&#22240;&#20026;&#23427;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#20294;&#32570;&#20047;&#29702;&#35770;&#29702;&#35299;&#12290;&#23545;&#20110;Lipschitz&#20984;&#20989;&#25968;&#65292;&#19981;&#21516;&#30340;&#30740;&#31350;&#24314;&#31435;&#20102;&#26368;&#20339;&#30340;$O(\log(1/\delta)\log T/\sqrt{T})$&#25110;$O(\sqrt{\log(1/\delta)/T})$&#26368;&#32456;&#36845;&#20195;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36895;&#29575;&#65292;&#20854;&#20013;$T$&#26159;&#26102;&#38388;&#36328;&#24230;&#65292;$\delta$&#26159;&#22833;&#36133;&#27010;&#29575;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#35777;&#26126;&#36825;&#20123;&#30028;&#38480;&#65292;&#25152;&#26377;&#29616;&#26377;&#30340;&#24037;&#20316;&#35201;&#20040;&#23616;&#38480;&#20110;&#32039;&#33268;&#22495;&#65292;&#35201;&#20040;&#38656;&#35201;&#20960;&#20046;&#32943;&#23450;&#26377;&#30028;&#30340;&#22122;&#22768;&#12290;&#24456;&#33258;&#28982;&#22320;&#20250;&#38382;&#65292;&#19981;&#38656;&#35201;&#36825;&#20004;&#20010;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;SGD&#30340;&#26368;&#32456;&#36845;&#20195;&#26159;&#21542;&#20173;&#28982;&#21487;&#20197;&#20445;&#35777;&#26368;&#20339;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#38500;&#20102;&#36825;&#20010;&#37325;&#35201;&#38382;&#39064;&#22806;&#65292;&#36824;&#26377;&#24456;&#22810;&#29702;&#35770;&#38382;&#39064;&#20173;&#28982;&#27809;&#26377;&#31572;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.08531v2 Announce Type: replace  Abstract: In the past several years, the last-iterate convergence of the Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due to its good performance in practice but lack of theoretical understanding. For Lipschitz convex functions, different works have established the optimal $O(\log(1/\delta)\log T/\sqrt{T})$ or $O(\sqrt{\log(1/\delta)/T})$ high-probability convergence rates for the final iterate, where $T$ is the time horizon and $\delta$ is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noises. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smoot
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#12289;&#21487;&#25193;&#23637;&#19988;&#20445;&#25252;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31995;&#32479;&#65292;&#20351;&#30495;&#23454;&#25968;&#25454;&#30340;&#36129;&#29486;&#32773;&#33021;&#22815;&#21442;&#19982;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#38544;&#31169;&#21644;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#26356;&#22909;&#22320;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2310.20062</link><description>&lt;p&gt;
&#21435;&#20013;&#24515;&#21270;&#12289;&#21487;&#25193;&#23637;&#19988;&#20445;&#25252;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Decentralised, Scalable and Privacy-Preserving Synthetic Data Generation. (arXiv:2310.20062v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20062
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#12289;&#21487;&#25193;&#23637;&#19988;&#20445;&#25252;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31995;&#32479;&#65292;&#20351;&#30495;&#23454;&#25968;&#25454;&#30340;&#36129;&#29486;&#32773;&#33021;&#22815;&#21442;&#19982;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#65292;&#20174;&#32780;&#25552;&#20379;&#26356;&#22909;&#30340;&#38544;&#31169;&#21644;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#26356;&#22909;&#22320;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#20316;&#20026;&#19968;&#31181;&#26377;&#28508;&#21147;&#30340;&#26041;&#24335;&#22312;&#38477;&#20302;&#38544;&#31169;&#39118;&#38505;&#30340;&#21516;&#26102;&#21457;&#25381;&#25968;&#25454;&#20215;&#20540;&#12290;&#21512;&#25104;&#25968;&#25454;&#30340;&#28508;&#21147;&#19981;&#20165;&#23616;&#38480;&#20110;&#38544;&#31169;&#21451;&#22909;&#30340;&#25968;&#25454;&#21457;&#24067;&#65292;&#36824;&#21253;&#25324;&#22312;&#22521;&#35757;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#31561;&#20351;&#29992;&#26696;&#20363;&#20013;&#34917;&#20805;&#30495;&#23454;&#25968;&#25454;&#65292;&#20351;&#20854;&#26356;&#20844;&#24179;&#12289;&#26356;&#33021;&#25269;&#25239;&#20998;&#24067;&#36716;&#21464;&#31561;&#12290;&#23545;&#20110;&#25552;&#20379;&#26356;&#22909;&#30340;&#38544;&#31169;&#21644;&#32479;&#35745;&#20445;&#35777;&#20197;&#21450;&#26356;&#22909;&#22320;&#22312;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#30340;&#31639;&#27861;&#36827;&#23637;&#24341;&#36215;&#20102;&#24191;&#27867;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36127;&#36131;&#20219;&#21644;&#20540;&#24471;&#20449;&#36182;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26469;&#35828;&#65292;&#20165;&#20851;&#27880;&#36825;&#20123;&#31639;&#27861;&#26041;&#38754;&#26159;&#19981;&#22815;&#30340;&#65292;&#32780;&#24212;&#35813;&#32771;&#34385;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#27969;&#31243;&#30340;&#25972;&#20307;&#35270;&#35282;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#31995;&#32479;&#65292;&#20801;&#35768;&#30495;&#23454;&#25968;&#25454;&#30340;&#36129;&#29486;&#32773;&#22312;&#27809;&#26377;&#20381;&#36182;&#20110;&#20540;&#24471;&#20449;&#36182;&#30340;&#20013;&#24515;&#30340;&#24773;&#20917;&#19979;&#33258;&#20027;&#21442;&#19982;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#25105;&#20204;&#30340;&#27169;&#22359;&#21270;&#12289;&#36890;&#29992;&#21270;&#21644;&#21487;&#25193;&#23637;&#30340;&#35299;&#20915;&#26041;&#26696;&#22522;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Synthetic data is emerging as a promising way to harness the value of data, while reducing privacy risks. The potential of synthetic data is not limited to privacy-friendly data release, but also includes complementing real data in use-cases such as training machine learning algorithms that are more fair and robust to distribution shifts etc. There is a lot of interest in algorithmic advances in synthetic data generation for providing better privacy and statistical guarantees and for its better utilisation in machine learning pipelines. However, for responsible and trustworthy synthetic data generation, it is not sufficient to focus only on these algorithmic aspects and instead, a holistic view of the synthetic data generation pipeline must be considered. We build a novel system that allows the contributors of real data to autonomously participate in differentially private synthetic data generation without relying on a trusted centre. Our modular, general and scalable solution is based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#20219;&#21153;&#21644;&#26041;&#27861;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2307.14397</link><description>&lt;p&gt;
&#20851;&#20110;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#29983;&#25104;&#24314;&#27169;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot. (arXiv:2307.14397v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#20219;&#21153;&#21644;&#26041;&#27861;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#29983;&#25104;&#24314;&#27169;&#26088;&#22312;&#23398;&#20064;&#29983;&#25104;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#32479;&#35745;&#30456;&#20284;&#30340;&#26032;&#25968;&#25454;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#31216;&#20026;&#25968;&#25454;&#32422;&#26463;&#19979;&#30340;&#29983;&#25104;&#24314;&#27169;&#65288;GM-DC&#65289;&#12290;&#36825;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20027;&#39064;&#65292;&#24403;&#25968;&#25454;&#33719;&#21462;&#20855;&#26377;&#25361;&#25112;&#24615;&#26102;&#65292;&#20363;&#22914;&#21307;&#30103;&#24212;&#29992;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#32972;&#26223;&#12289;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#20998;&#31867;&#20307;&#31995;&#65306;&#19968;&#20010;&#26159;GM-DC&#20219;&#21153;&#20998;&#31867;&#65292;&#21478;&#19968;&#20010;&#26159;GM-DC&#26041;&#27861;&#20998;&#31867;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;GM-DC&#20219;&#21153;&#21644;&#26041;&#27861;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#30740;&#31350;&#31354;&#30333;&#12289;&#30740;&#31350;&#36235;&#21183;&#21644;&#26410;&#26469;&#25506;&#32034;&#30340;&#28508;&#22312;&#36884;&#24452;&#12290;&#39033;&#30446;&#32593;&#31449;&#65306;https://gmdc-survey.github.io&#12290;
&lt;/p&gt;
&lt;p&gt;
In machine learning, generative modeling aims to learn to generate new data statistically similar to the training data distribution. In this paper, we survey learning generative models under limited data, few shots and zero shot, referred to as Generative Modeling under Data Constraint (GM-DC). This is an important topic when data acquisition is challenging, e.g. healthcare applications. We discuss background, challenges, and propose two taxonomies: one on GM-DC tasks and another on GM-DC approaches. Importantly, we study interactions between different GM-DC tasks and approaches. Furthermore, we highlight research gaps, research trends, and potential avenues for future exploration. Project website: https://gmdc-survey.github.io.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#20998;&#25955;&#31574;&#30053;&#30340;MARL&#31639;&#27861;&#22312;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#19979;&#30340;&#27425;&#26368;&#20248;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36716;&#21270;&#19982;&#33976;&#39311;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#23558;&#22810;&#26234;&#33021;&#20307;MDP&#36716;&#21270;&#20026;&#21333;&#26234;&#33021;&#20307;MDP&#20197;&#23454;&#29616;&#20998;&#25955;&#25191;&#34892;&#12290;</title><link>http://arxiv.org/abs/2207.11143</link><description>&lt;p&gt;
&#12298;&#37319;&#29992;&#36716;&#21270;&#19982;&#33976;&#39311;&#26694;&#26550;&#23454;&#29616;&#21512;&#20316;MARL&#20840;&#23616;&#26368;&#20248;&#24615;&#12299;
&lt;/p&gt;
&lt;p&gt;
Towards Global Optimality in Cooperative MARL with the Transformation And Distillation Framework. (arXiv:2207.11143v3 [cs.MA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#20998;&#25955;&#31574;&#30053;&#30340;MARL&#31639;&#27861;&#22312;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#19979;&#30340;&#27425;&#26368;&#20248;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36716;&#21270;&#19982;&#33976;&#39311;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#23558;&#22810;&#26234;&#33021;&#20307;MDP&#36716;&#21270;&#20026;&#21333;&#26234;&#33021;&#20307;MDP&#20197;&#23454;&#29616;&#20998;&#25955;&#25191;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#20998;&#25955;&#25191;&#34892;&#26159;&#19968;&#39033;&#26680;&#24515;&#38656;&#27714;&#12290;&#30446;&#21069;&#65292;&#22823;&#22810;&#25968;&#27969;&#34892;&#30340;MARL&#31639;&#27861;&#37319;&#29992;&#20998;&#25955;&#31574;&#30053;&#26469;&#23454;&#29616;&#20998;&#25955;&#25191;&#34892;&#65292;&#24182;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#20316;&#20026;&#20248;&#21270;&#22120;&#12290;&#28982;&#32780;&#65292;&#22312;&#32771;&#34385;&#21040;&#20248;&#21270;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#31639;&#27861;&#20960;&#20046;&#27809;&#26377;&#20219;&#20309;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#26799;&#24230;&#19979;&#38477;&#34987;&#36873;&#20026;&#20248;&#21270;&#26041;&#27861;&#26102;&#65292;&#21508;&#31181;&#27969;&#34892;&#30340;&#20998;&#25955;&#31574;&#30053;MARL&#31639;&#27861;&#22312;&#29609;&#20855;&#20219;&#21153;&#20013;&#37117;&#26159;&#27425;&#26368;&#20248;&#30340;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#20004;&#31181;&#24120;&#35265;&#30340;&#37319;&#29992;&#20998;&#25955;&#31574;&#30053;&#30340;&#31639;&#27861;&#8212;&#8212;&#22810;&#26234;&#33021;&#20307;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#21644;&#20540;&#20998;&#35299;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26102;&#30340;&#27425;&#26368;&#20248;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36716;&#21270;&#19982;&#33976;&#39311;&#65288;TAD&#65289;&#26694;&#26550;&#65292;&#23427;&#23558;&#22810;&#26234;&#33021;&#20307;MDP&#37325;&#26032;&#21046;&#23450;&#20026;&#19968;&#31181;&#20855;&#26377;&#36830;&#32493;&#32467;&#26500;&#30340;&#29305;&#27530;&#21333;&#26234;&#33021;&#20307;MDP&#65292;&#24182;&#36890;&#36807;&#33976;&#39311;&#23454;&#29616;&#20998;&#25955;&#25191;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decentralized execution is one core demand in cooperative multi-agent reinforcement learning (MARL). Recently, most popular MARL algorithms have adopted decentralized policies to enable decentralized execution and use gradient descent as their optimizer. However, there is hardly any theoretical analysis of these algorithms taking the optimization method into consideration, and we find that various popular MARL algorithms with decentralized policies are suboptimal in toy tasks when gradient descent is chosen as their optimization method. In this paper, we theoretically analyze two common classes of algorithms with decentralized policies -- multi-agent policy gradient methods and value-decomposition methods to prove their suboptimality when gradient descent is used. In addition, we propose the Transformation And Distillation (TAD) framework, which reformulates a multi-agent MDP as a special single-agent MDP with a sequential structure and enables decentralized execution by distilling the
&lt;/p&gt;</description></item></channel></rss>