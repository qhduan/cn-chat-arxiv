<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#20004;&#38454;&#27573;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#36890;&#36807;&#22521;&#20859;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#29305;&#24449;&#65292;&#21253;&#25324;&#26412;&#22320;&#21644;&#36328;&#39046;&#22495;&#29305;&#24449;&#65292;&#20197;&#22686;&#24378;&#23545;&#26410;&#30693;&#20998;&#24067;&#39046;&#22495;&#30340;&#27867;&#21270;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20808;&#39564;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#26469;&#20998;&#31163;&#28508;&#22312;&#31354;&#38388;&#65292;&#24182;&#19988;&#22312;&#22810;&#20010;&#32593;&#32476;&#23433;&#20840;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#27169;&#22411;&#30340;&#25928;&#33021;&#12290;</title><link>http://arxiv.org/abs/2312.17300</link><description>&lt;p&gt;
&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#36890;&#36807;&#39046;&#22495;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#25913;&#21892;&#20837;&#20405;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Improving Intrusion Detection with Domain-Invariant Representation Learning in Latent Space. (arXiv:2312.17300v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.17300
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#20004;&#38454;&#27573;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#36890;&#36807;&#22521;&#20859;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#29305;&#24449;&#65292;&#21253;&#25324;&#26412;&#22320;&#21644;&#36328;&#39046;&#22495;&#29305;&#24449;&#65292;&#20197;&#22686;&#24378;&#23545;&#26410;&#30693;&#20998;&#24067;&#39046;&#22495;&#30340;&#27867;&#21270;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20808;&#39564;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#26469;&#20998;&#31163;&#28508;&#22312;&#31354;&#38388;&#65292;&#24182;&#19988;&#22312;&#22810;&#20010;&#32593;&#32476;&#23433;&#20840;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#27169;&#22411;&#30340;&#25928;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#27867;&#21270;&#32858;&#28966;&#20110;&#21033;&#29992;&#26469;&#33258;&#20855;&#26377;&#20016;&#23500;&#35757;&#32451;&#25968;&#25454;&#21644;&#26631;&#31614;&#30340;&#22810;&#20010;&#30456;&#20851;&#39046;&#22495;&#30340;&#30693;&#35782;&#65292;&#22686;&#24378;&#23545;&#26410;&#30693;&#20998;&#24067;&#65288;IN&#65289;&#21644;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#39046;&#22495;&#30340;&#25512;&#29702;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#20351;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20174;&#36328;&#36234;&#22810;&#20010;&#39046;&#22495;&#30340;&#29305;&#24449;&#20013;&#22521;&#20859;&#19968;&#20010;&#28508;&#22312;&#31354;&#38388;&#65292;&#21253;&#25324;&#26412;&#22320;&#21644;&#36328;&#39046;&#22495;&#65292;&#20197;&#22686;&#24378;&#23545;IN&#21644;OOD&#39046;&#22495;&#30340;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23581;&#35797;&#36890;&#36807;&#26368;&#23567;&#21270;&#20808;&#39564;&#19982;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#26469;&#20998;&#31163;&#28508;&#22312;&#31354;&#38388;&#65292;&#26377;&#25928;&#28040;&#38500;&#34394;&#20551;&#29305;&#24449;&#30456;&#20851;&#24615;&#12290;&#32508;&#21512;&#32780;&#35328;&#65292;&#32852;&#21512;&#20248;&#21270;&#23558;&#20419;&#36827;&#39046;&#22495;&#19981;&#21464;&#29305;&#24449;&#23398;&#20064;&#12290;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#20998;&#31867;&#25351;&#26631;&#35780;&#20272;&#27169;&#22411;&#22312;&#22810;&#20010;&#32593;&#32476;&#23433;&#20840;&#25968;&#25454;&#38598;&#19978;&#30340;&#25928;&#33021;&#65292;&#23545;&#27604;&#20102;&#29616;&#20195;&#39046;&#22495;&#27867;&#21270;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain generalization focuses on leveraging knowledge from multiple related domains with ample training data and labels to enhance inference on unseen in-distribution (IN) and out-of-distribution (OOD) domains. In our study, we introduce a two-phase representation learning technique using multi-task learning. This approach aims to cultivate a latent space from features spanning multiple domains, encompassing both native and cross-domains, to amplify generalization to IN and OOD territories. Additionally, we attempt to disentangle the latent space by minimizing the mutual information between the prior and latent space, effectively de-correlating spurious feature correlations. Collectively, the joint optimization will facilitate domain-invariant feature learning. We assess the model's efficacy across multiple cybersecurity datasets, using standard classification metrics on both unseen IN and OOD sets, and juxtapose the results with contemporary domain generalization methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#32929;&#24066;&#20215;&#26684;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#36873;&#25321;&#26368;&#20339;&#30340;&#25216;&#26415;&#25351;&#26631;&#32452;&#21512;&#26469;&#23454;&#29616;&#26368;&#23569;&#35823;&#24046;&#30340;&#39044;&#27979;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#19981;&#21516;&#30340;&#21253;&#35013;&#22120;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#20855;&#26377;&#19981;&#21516;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.09903</link><description>&lt;p&gt;
&#35780;&#20272;&#29305;&#24449;&#36873;&#25321;&#22312;&#32929;&#24066;&#20215;&#26684;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#20197;&#30830;&#23450;&#26368;&#26377;&#25928;&#30340;&#25216;&#26415;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Evaluation of feature selection performance for identification of best effective technical indicators on stock market price prediction. (arXiv:2310.09903v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#32929;&#24066;&#20215;&#26684;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#36873;&#25321;&#26368;&#20339;&#30340;&#25216;&#26415;&#25351;&#26631;&#32452;&#21512;&#26469;&#23454;&#29616;&#26368;&#23569;&#35823;&#24046;&#30340;&#39044;&#27979;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#19981;&#21516;&#30340;&#21253;&#35013;&#22120;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#20855;&#26377;&#19981;&#21516;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#25216;&#26415;&#25351;&#26631;&#23545;&#32929;&#24066;&#39044;&#27979;&#30340;&#24433;&#21709;&#65292;&#29305;&#24449;&#36873;&#25321;&#23545;&#36873;&#25321;&#26368;&#20339;&#25351;&#26631;&#33267;&#20851;&#37325;&#35201;&#12290;&#19968;&#31181;&#32771;&#34385;&#22312;&#29305;&#24449;&#36873;&#25321;&#36807;&#31243;&#20013;&#27169;&#22411;&#24615;&#33021;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#26159;&#21253;&#35013;&#22120;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#29305;&#24449;&#36873;&#25321;&#37492;&#23450;&#20986;&#26368;&#23569;&#35823;&#24046;&#30340;&#39044;&#27979;&#32929;&#24066;&#20215;&#26684;&#30340;&#26368;&#20339;&#32929;&#24066;&#25351;&#26631;&#32452;&#21512;&#12290;&#20026;&#35780;&#20272;&#21253;&#35013;&#22120;&#29305;&#24449;&#36873;&#25321;&#25216;&#26415;&#23545;&#32929;&#24066;&#39044;&#27979;&#30340;&#24433;&#21709;&#65292;&#26412;&#25991;&#22312;&#36807;&#21435;10&#24180;&#33529;&#26524;&#20844;&#21496;&#30340;&#25968;&#25454;&#19978;&#20351;&#29992;&#20102;10&#20010;&#35780;&#20272;&#22120;&#21644;123&#20010;&#25216;&#26415;&#25351;&#26631;&#36827;&#34892;&#20102;SFS&#21644;SBS&#30340;&#32771;&#23519;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#23558;&#30001;3&#22825;&#26102;&#38388;&#31383;&#21475;&#21019;&#24314;&#30340;&#25968;&#25454;&#36716;&#21270;&#20026;&#36866;&#29992;&#20110;&#22238;&#24402;&#26041;&#27861;&#30340;&#36755;&#20837;&#12290;&#20174;&#35266;&#23519;&#32467;&#26524;&#21487;&#20197;&#24471;&#20986;&#65306;&#65288;1&#65289;&#27599;&#31181;&#21253;&#35013;&#22120;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#20855;&#26377;&#19981;&#21516;&#30340;&#32467;&#26524;&#65292;&#27599;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#20063;&#26377;&#25152;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the influence of many factors, including technical indicators on stock market prediction, feature selection is important to choose the best indicators. One of the feature selection methods that consider the performance of models during feature selection is the wrapper feature selection method. The aim of this research is to identify a combination of the best stock market indicators through feature selection to predict the stock market price with the least error. In order to evaluate the impact of wrapper feature selection techniques on stock market prediction, in this paper SFS and SBS with 10 estimators and 123 technical indicators have been examined on the last 10 years of Apple Company. Also, by the proposed method, the data created by the 3-day time window were converted to the appropriate input for regression methods. Based on the results observed: (1) Each wrapper feature selection method has different results with different machine learning methods, and each method is mor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#19968;&#31181;&#26080;&#23548;&#25968;&#25439;&#22833;&#26041;&#27861;&#22312;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#26925;&#22278;&#22411;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#35757;&#32451;&#25439;&#22833;&#20559;&#24046;&#19982;&#26102;&#38388;&#38388;&#38548;&#21644;&#31354;&#38388;&#26799;&#24230;&#25104;&#27491;&#27604;&#65292;&#19982;&#34892;&#36208;&#32773;&#22823;&#23567;&#25104;&#21453;&#27604;&#65292;&#21516;&#26102;&#26102;&#38388;&#38388;&#38548;&#24517;&#39035;&#36275;&#22815;&#38271;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#27979;&#35797;&#32467;&#26524;&#20197;&#25903;&#25345;&#25105;&#20204;&#30340;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2309.16829</link><description>&lt;p&gt;
&#26080;&#23548;&#25968;&#25439;&#22833;&#26041;&#27861;&#22312;&#27714;&#35299;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An analysis of the derivative-free loss method for solving PDEs. (arXiv:2309.16829v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16829
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#19968;&#31181;&#26080;&#23548;&#25968;&#25439;&#22833;&#26041;&#27861;&#22312;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#26925;&#22278;&#22411;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#35757;&#32451;&#25439;&#22833;&#20559;&#24046;&#19982;&#26102;&#38388;&#38388;&#38548;&#21644;&#31354;&#38388;&#26799;&#24230;&#25104;&#27491;&#27604;&#65292;&#19982;&#34892;&#36208;&#32773;&#22823;&#23567;&#25104;&#21453;&#27604;&#65292;&#21516;&#26102;&#26102;&#38388;&#38388;&#38548;&#24517;&#39035;&#36275;&#22815;&#38271;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#27979;&#35797;&#32467;&#26524;&#20197;&#25903;&#25345;&#25105;&#20204;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26080;&#23548;&#25968;&#25439;&#22833;&#26041;&#27861;&#22312;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#19968;&#31867;&#26925;&#22278;&#22411;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#24212;&#29992;&#12290;&#26080;&#23548;&#25968;&#25439;&#22833;&#26041;&#27861;&#37319;&#29992;&#36153;&#26364;-&#21345;&#20811;&#20844;&#24335;&#65292;&#32467;&#21512;&#38543;&#26426;&#34892;&#36208;&#32773;&#21450;&#20854;&#23545;&#24212;&#30340;&#24179;&#22343;&#20540;&#12290;&#25105;&#20204;&#32771;&#23519;&#20102;&#36153;&#26364;-&#21345;&#20811;&#20844;&#24335;&#20013;&#19982;&#26102;&#38388;&#38388;&#38548;&#30456;&#20851;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#34892;&#36208;&#32773;&#22823;&#23567;&#23545;&#35745;&#31639;&#25928;&#29575;&#12289;&#21487;&#35757;&#32451;&#24615;&#21644;&#37319;&#26679;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#35757;&#32451;&#25439;&#22833;&#20559;&#24046;&#19982;&#26102;&#38388;&#38388;&#38548;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#31354;&#38388;&#26799;&#24230;&#25104;&#27491;&#27604;&#65292;&#19982;&#34892;&#36208;&#32773;&#22823;&#23567;&#25104;&#21453;&#27604;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#26102;&#38388;&#38388;&#38548;&#24517;&#39035;&#36275;&#22815;&#38271;&#25165;&#33021;&#35757;&#32451;&#32593;&#32476;&#12290;&#36825;&#20123;&#20998;&#26512;&#32467;&#26524;&#35828;&#26126;&#65292;&#22312;&#26102;&#38388;&#38388;&#38548;&#30340;&#26368;&#20248;&#19979;&#30028;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#21487;&#20197;&#36873;&#25321;&#23613;&#21487;&#33021;&#23567;&#30340;&#34892;&#36208;&#32773;&#22823;&#23567;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#25903;&#25345;&#25105;&#20204;&#20998;&#26512;&#30340;&#25968;&#20540;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study analyzes the derivative-free loss method to solve a certain class of elliptic PDEs using neural networks. The derivative-free loss method uses the Feynman-Kac formulation, incorporating stochastic walkers and their corresponding average values. We investigate the effect of the time interval related to the Feynman-Kac formulation and the walker size in the context of computational efficiency, trainability, and sampling errors. Our analysis shows that the training loss bias is proportional to the time interval and the spatial gradient of the neural network while inversely proportional to the walker size. We also show that the time interval must be sufficiently long to train the network. These analytic results tell that we can choose the walker size as small as possible based on the optimal lower bound of the time interval. We also provide numerical tests supporting our analysis.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#30340;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#39537;&#21160;&#30340;&#26816;&#27979;&#19982;&#36716;&#25442;&#65288;IT-DT&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#22312;&#26816;&#27979;&#21644;&#36716;&#25442;&#25991;&#26412;&#23545;&#25239;&#31034;&#20363;&#26041;&#38754;&#27880;&#37325;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#21033;&#29992;&#20102;&#27880;&#24847;&#21147;&#22270;&#12289;&#38598;&#25104;&#26799;&#24230;&#21644;&#27169;&#22411;&#21453;&#39304;&#31561;&#25216;&#26415;&#65292;&#22312;&#26816;&#27979;&#38454;&#27573;&#26377;&#21161;&#20110;&#35782;&#21035;&#23545;&#23545;&#25239;&#24615;&#20998;&#31867;&#26377;&#36129;&#29486;&#30340;&#26174;&#33879;&#29305;&#24449;&#21644;&#25200;&#21160;&#35789;&#35821;&#65292;&#24182;&#22312;&#36716;&#25442;&#38454;&#27573;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#23884;&#20837;&#21644;&#27169;&#22411;&#21453;&#39304;&#26469;&#29983;&#25104;&#25200;&#21160;&#35789;&#35821;&#30340;&#26368;&#20339;&#26367;&#20195;&#65292;&#20197;&#23558;&#23545;&#25239;&#24615;&#31034;&#20363;&#36716;&#25442;&#20026;&#27491;&#24120;&#31034;&#20363;&#12290;</title><link>http://arxiv.org/abs/2307.01225</link><description>&lt;p&gt;
&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#39537;&#21160;&#30340;&#25991;&#26412;&#23545;&#25239;&#31034;&#20363;&#30340;&#26816;&#27979;&#19982;&#36716;&#25442;&#65288;IT-DT&#65289;
&lt;/p&gt;
&lt;p&gt;
Interpretability and Transparency-Driven Detection and Transformation of Textual Adversarial Examples (IT-DT). (arXiv:2307.01225v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01225
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#30340;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#39537;&#21160;&#30340;&#26816;&#27979;&#19982;&#36716;&#25442;&#65288;IT-DT&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#22312;&#26816;&#27979;&#21644;&#36716;&#25442;&#25991;&#26412;&#23545;&#25239;&#31034;&#20363;&#26041;&#38754;&#27880;&#37325;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#21033;&#29992;&#20102;&#27880;&#24847;&#21147;&#22270;&#12289;&#38598;&#25104;&#26799;&#24230;&#21644;&#27169;&#22411;&#21453;&#39304;&#31561;&#25216;&#26415;&#65292;&#22312;&#26816;&#27979;&#38454;&#27573;&#26377;&#21161;&#20110;&#35782;&#21035;&#23545;&#23545;&#25239;&#24615;&#20998;&#31867;&#26377;&#36129;&#29486;&#30340;&#26174;&#33879;&#29305;&#24449;&#21644;&#25200;&#21160;&#35789;&#35821;&#65292;&#24182;&#22312;&#36716;&#25442;&#38454;&#27573;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#23884;&#20837;&#21644;&#27169;&#22411;&#21453;&#39304;&#26469;&#29983;&#25104;&#25200;&#21160;&#35789;&#35821;&#30340;&#26368;&#20339;&#26367;&#20195;&#65292;&#20197;&#23558;&#23545;&#25239;&#24615;&#31034;&#20363;&#36716;&#25442;&#20026;&#27491;&#24120;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#25991;&#26412;&#20998;&#31867;&#22120;&#22914;BERT&#12289;Roberta&#12289;T5&#21644;GPT-3&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#23545;&#20110;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#33030;&#24369;&#24615;&#25552;&#20986;&#20102;&#23433;&#20840;&#39118;&#38505;&#12290;&#29616;&#26377;&#30340;&#38450;&#24481;&#26041;&#27861;&#32570;&#20047;&#35299;&#37322;&#24615;&#65292;&#24456;&#38590;&#29702;&#35299;&#23545;&#25239;&#24615;&#20998;&#31867;&#24182;&#35782;&#21035;&#27169;&#22411;&#30340;&#28431;&#27934;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#39537;&#21160;&#30340;&#26816;&#27979;&#19982;&#36716;&#25442;&#65288;IT-DT&#65289;&#26694;&#26550;&#12290;&#23427;&#19987;&#27880;&#20110;&#22312;&#26816;&#27979;&#21644;&#36716;&#25442;&#25991;&#26412;&#23545;&#25239;&#31034;&#20363;&#26102;&#30340;&#35299;&#37322;&#24615;&#21644;&#36879;&#26126;&#24615;&#12290;IT-DT&#21033;&#29992;&#27880;&#24847;&#21147;&#22270;&#12289;&#38598;&#25104;&#26799;&#24230;&#21644;&#27169;&#22411;&#21453;&#39304;&#31561;&#25216;&#26415;&#36827;&#34892;&#35299;&#37322;&#24615;&#26816;&#27979;&#12290;&#36825;&#26377;&#21161;&#20110;&#35782;&#21035;&#23545;&#23545;&#25239;&#24615;&#20998;&#31867;&#26377;&#36129;&#29486;&#30340;&#26174;&#33879;&#29305;&#24449;&#21644;&#25200;&#21160;&#35789;&#35821;&#12290;&#22312;&#36716;&#25442;&#38454;&#27573;&#65292;IT-DT&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#23884;&#20837;&#21644;&#27169;&#22411;&#21453;&#39304;&#26469;&#29983;&#25104;&#25200;&#21160;&#35789;&#35821;&#30340;&#26368;&#20339;&#26367;&#20195;&#12290;&#36890;&#36807;&#25214;&#21040;&#21512;&#36866;&#30340;&#26367;&#25442;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23558;&#23545;&#25239;&#24615;&#31034;&#20363;&#36716;&#25442;&#20026;&#27491;&#24120;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer-based text classifiers like BERT, Roberta, T5, and GPT-3 have shown impressive performance in NLP. However, their vulnerability to adversarial examples poses a security risk. Existing defense methods lack interpretability, making it hard to understand adversarial classifications and identify model vulnerabilities. To address this, we propose the Interpretability and Transparency-Driven Detection and Transformation (IT-DT) framework. It focuses on interpretability and transparency in detecting and transforming textual adversarial examples. IT-DT utilizes techniques like attention maps, integrated gradients, and model feedback for interpretability during detection. This helps identify salient features and perturbed words contributing to adversarial classifications. In the transformation phase, IT-DT uses pre-trained embeddings and model feedback to generate optimal replacements for perturbed words. By finding suitable substitutions, we aim to convert adversarial examples into
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#32593;&#32476;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;(NIDS)&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#36827;&#34892;&#20102;&#20998;&#31867;&#65292;&#21516;&#26102;&#25506;&#31350;&#20102;&#25345;&#32493;&#20877;&#35757;&#32451;&#23545;NIDS&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#21363;&#20351;&#27809;&#26377;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#25345;&#32493;&#20877;&#35757;&#32451;&#20063;&#21487;&#20197;&#20943;&#23569;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.05494</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#25239;&#24615;&#28431;&#27934;&#25915;&#20987;&#30340;&#23454;&#29992;&#24615;&#27979;&#35797;&#65306;&#21160;&#24577;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Adversarial Evasion Attacks Practicality in Networks: Testing the Impact of Dynamic Learning. (arXiv:2306.05494v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#32593;&#32476;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;(NIDS)&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#36827;&#34892;&#20102;&#20998;&#31867;&#65292;&#21516;&#26102;&#25506;&#31350;&#20102;&#25345;&#32493;&#20877;&#35757;&#32451;&#23545;NIDS&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#21363;&#20351;&#27809;&#26377;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#25345;&#32493;&#20877;&#35757;&#32451;&#20063;&#21487;&#20197;&#20943;&#23569;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#32593;&#32476;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;(NIDS)&#20013;&#65292;&#30001;&#20110;&#20854;&#33258;&#21160;&#21270;&#30340;&#29305;&#24615;&#21644;&#22312;&#22788;&#29702;&#21644;&#20998;&#31867;&#22823;&#37327;&#25968;&#25454;&#19978;&#30340;&#39640;&#31934;&#24230;&#12290;&#20294;&#26426;&#22120;&#23398;&#20064;&#23384;&#22312;&#32570;&#38519;&#65292;&#20854;&#20013;&#26368;&#22823;&#30340;&#38382;&#39064;&#20043;&#19968;&#26159;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#20854;&#30446;&#30340;&#26159;&#20351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20135;&#29983;&#38169;&#35823;&#30340;&#39044;&#27979;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#29420;&#29305;&#30340;&#36129;&#29486;&#65306;&#23545;&#25239;&#24615;&#25915;&#20987;&#23545;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;NIDS&#23454;&#29992;&#24615;&#38382;&#39064;&#30340;&#20998;&#31867;&#21644;&#23545;&#25345;&#32493;&#35757;&#32451;&#23545;NIDS&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#21363;&#20351;&#27809;&#26377;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#25345;&#32493;&#20877;&#35757;&#32451;&#20063;&#21487;&#20197;&#20943;&#23569;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#23545;&#25239;&#24615;&#25915;&#20987;&#21487;&#33021;&#20250;&#21361;&#21450;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;NIDS&#65292;&#20294;&#25345;&#32493;&#20877;&#35757;&#32451;&#21487;&#24102;&#26469;&#19968;&#23450;&#30340;&#32531;&#35299;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) has become ubiquitous, and its deployment in Network Intrusion Detection Systems (NIDS) is inevitable due to its automated nature and high accuracy in processing and classifying large volumes of data. However, ML has been found to have several flaws, on top of them are adversarial attacks, which aim to trick ML models into producing faulty predictions. While most adversarial attack research focuses on computer vision datasets, recent studies have explored the practicality of such attacks against ML-based network security entities, especially NIDS.  This paper presents two distinct contributions: a taxonomy of practicality issues associated with adversarial attacks against ML-based NIDS and an investigation of the impact of continuous training on adversarial attacks against NIDS. Our experiments indicate that continuous re-training, even without adversarial training, can reduce the effect of adversarial attacks. While adversarial attacks can harm ML-based NIDSs, ou
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19981;&#30830;&#23450;&#26368;&#22823;&#29109;&#21407;&#29702;&#65292;&#35813;&#21407;&#29702;&#21487;&#20197;&#22788;&#29702;&#27169;&#22411;&#20803;&#32032;&#19981;&#21487;&#35266;&#27979;&#30340;&#24773;&#20917;&#65292;&#24182;&#20248;&#20110;&#29305;&#23450;&#26465;&#20214;&#19979;&#30340;&#26368;&#22823;&#29109;&#26041;&#27861;&#12290;&#21516;&#26102;&#23558;&#40657;&#21283;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20986;&#29992;&#20316;&#19981;&#30830;&#23450;&#26426;&#22120;&#29109;&#26694;&#26550;&#30340;&#36755;&#20837;&#65292;&#24615;&#33021;&#24471;&#21040;&#20102;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2305.09868</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#26368;&#22823;&#29109;&#21407;&#29702;
&lt;/p&gt;
&lt;p&gt;
The Principle of Uncertain Maximum Entropy. (arXiv:2305.09868v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09868
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19981;&#30830;&#23450;&#26368;&#22823;&#29109;&#21407;&#29702;&#65292;&#35813;&#21407;&#29702;&#21487;&#20197;&#22788;&#29702;&#27169;&#22411;&#20803;&#32032;&#19981;&#21487;&#35266;&#27979;&#30340;&#24773;&#20917;&#65292;&#24182;&#20248;&#20110;&#29305;&#23450;&#26465;&#20214;&#19979;&#30340;&#26368;&#22823;&#29109;&#26041;&#27861;&#12290;&#21516;&#26102;&#23558;&#40657;&#21283;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20986;&#29992;&#20316;&#19981;&#30830;&#23450;&#26426;&#22120;&#29109;&#26694;&#26550;&#30340;&#36755;&#20837;&#65292;&#24615;&#33021;&#24471;&#21040;&#20102;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#29109;&#21407;&#29702;&#22312;&#20449;&#24687;&#29702;&#35770;&#20013;&#30340;&#24341;&#20837;&#65292;&#20026;&#32479;&#35745;&#21147;&#23398;&#65292;&#26426;&#22120;&#23398;&#20064;&#21644;&#29983;&#24577;&#23398;&#31561;&#21508;&#20010;&#39046;&#22495;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#20854;&#24471;&#21040;&#30340;&#35299;&#20915;&#26041;&#26696;&#20316;&#20026;&#20652;&#21270;&#21058;&#65292;&#20419;&#36827;&#30740;&#31350;&#20154;&#21592;&#23558;&#20182;&#20204;&#30340;&#32463;&#39564;&#35266;&#23519;&#26144;&#23556;&#21040;&#33719;&#21462;&#26080;&#20559;&#27169;&#22411;&#65292;&#21516;&#26102;&#21152;&#28145;&#20102;&#23545;&#22797;&#26434;&#31995;&#32479;&#21644;&#29616;&#35937;&#30340;&#29702;&#35299;&#12290;&#28982;&#32780;&#65292;&#22312;&#27169;&#22411;&#20803;&#32032;&#19981;&#30452;&#25509;&#21487;&#35266;&#27979;&#30340;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#23384;&#22312;&#22122;&#22768;&#25110;&#30524;&#37096;&#36974;&#25377;&#30340;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#26368;&#22823;&#29109;&#26041;&#27861;&#21487;&#33021;&#20250;&#22833;&#36133;&#65292;&#22240;&#20026;&#23427;&#20204;&#26080;&#27861;&#21305;&#37197;&#29305;&#24449;&#32422;&#26463;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#30830;&#23450;&#26368;&#22823;&#29109;&#21407;&#29702;&#20316;&#20026;&#19968;&#31181;&#26041;&#27861;&#65292;&#23613;&#31649;&#23384;&#22312;&#20219;&#24847;&#22122;&#22768;&#35266;&#23519;&#65292;&#23427;&#21516;&#26102;&#23558;&#25152;&#26377;&#21487;&#29992;&#20449;&#24687;&#32534;&#30721;&#65292;&#32780;&#19988;&#20248;&#20110;&#19968;&#20123;&#29305;&#23450;&#26465;&#20214;&#19979;&#30340;&#26368;&#22823;&#29109;&#26041;&#27861;&#30340;&#20934;&#30830;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#40657;&#21283;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20986;&#29992;&#20316;&#19981;&#30830;&#23450;&#26426;&#22120;&#29109;&#26694;&#26550;&#30340;&#36755;&#20837;&#65292;&#20174;&#32780;&#22312;&#19982;&#26368;&#22823;&#20284;&#28982;&#31639;&#27861;&#30456;&#27604;&#26102;&#24314;&#31435;&#20102;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The principle of maximum entropy, as introduced by Jaynes in information theory, has contributed to advancements in various domains such as Statistical Mechanics, Machine Learning, and Ecology. Its resultant solutions have served as a catalyst, facilitating researchers in mapping their empirical observations to the acquisition of unbiased models, whilst deepening the understanding of complex systems and phenomena. However, when we consider situations in which the model elements are not directly observable, such as when noise or ocular occlusion is present, possibilities arise for which standard maximum entropy approaches may fail, as they are unable to match feature constraints. Here we show the Principle of Uncertain Maximum Entropy as a method that both encodes all available information in spite of arbitrarily noisy observations while surpassing the accuracy of some ad-hoc methods. Additionally, we utilize the output of a black-box machine learning model as input into an uncertain ma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22478;&#24066;&#35268;&#21010;&#19982;&#20154;&#24037;&#26234;&#33021;&#30340;&#20132;&#21449;&#24212;&#29992;&#65292;&#37325;&#28857;&#26159;&#33258;&#21160;&#21270;&#29992;&#22320;&#37197;&#32622;&#65292;&#36890;&#36807;&#23545;&#25239;&#23398;&#20064;&#12289;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#12289;&#28145;&#24230;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#12289;&#23545;&#35805;&#24335; AI &#21644;&#22320;&#29702;&#31354;&#38388;&#21644;&#26102;&#38388;&#26426;&#22120;&#23398;&#20064;&#31561;&#25216;&#26415;&#65292;AI &#21487;&#20197;&#20026;&#29616;&#20195;&#22478;&#24066;&#35268;&#21010;&#24102;&#26469;&#19981;&#23569;&#21019;&#26032;&#19982;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2304.03892</link><description>&lt;p&gt;
&#33258;&#21160;&#21270;&#22478;&#24066;&#35268;&#21010;&#65306;&#29983;&#25104;&#24335;&#21644;&#32842;&#22825;&#24335; AI &#30456;&#32467;&#21512;&#30340;&#22478;&#24066;&#35268;&#21010;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Towards Automated Urban Planning: When Generative and ChatGPT-like AI Meets Urban Planning. (arXiv:2304.03892v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22478;&#24066;&#35268;&#21010;&#19982;&#20154;&#24037;&#26234;&#33021;&#30340;&#20132;&#21449;&#24212;&#29992;&#65292;&#37325;&#28857;&#26159;&#33258;&#21160;&#21270;&#29992;&#22320;&#37197;&#32622;&#65292;&#36890;&#36807;&#23545;&#25239;&#23398;&#20064;&#12289;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#12289;&#28145;&#24230;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#12289;&#23545;&#35805;&#24335; AI &#21644;&#22320;&#29702;&#31354;&#38388;&#21644;&#26102;&#38388;&#26426;&#22120;&#23398;&#20064;&#31561;&#25216;&#26415;&#65292;AI &#21487;&#20197;&#20026;&#29616;&#20195;&#22478;&#24066;&#35268;&#21010;&#24102;&#26469;&#19981;&#23569;&#21019;&#26032;&#19982;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22478;&#24066;&#35268;&#21010;&#39046;&#22495;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#26366;&#32463;&#26159;&#29420;&#31435;&#21457;&#23637;&#30340;&#65292;&#20294;&#29616;&#22312;&#20004;&#20010;&#39046;&#22495;&#24320;&#22987;&#20132;&#21449;&#27719;&#21512;&#65292;&#20114;&#30456;&#20511;&#37492;&#21644;&#21463;&#30410;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22478;&#24066;&#35268;&#21010;&#20174;&#21487;&#25345;&#32493;&#24615;&#12289;&#29983;&#27963;&#12289;&#32463;&#27982;&#12289;&#28798;&#23475;&#21644;&#29615;&#22659;&#31561;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65292;&#22238;&#39038;&#20102;&#22478;&#24066;&#35268;&#21010;&#30340;&#22522;&#26412;&#27010;&#24565;&#65292;&#24182;&#23558;&#36825;&#20123;&#27010;&#24565;&#19982;&#26426;&#22120;&#23398;&#20064;&#30340;&#20851;&#38190;&#24320;&#25918;&#38382;&#39064;&#32852;&#31995;&#36215;&#26469;&#65292;&#21253;&#25324;&#23545;&#25239;&#23398;&#20064;&#12289;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#12289;&#28145;&#24230;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#32593;&#32476;&#12289;&#23545;&#35805;&#24335; AI &#20197;&#21450;&#22320;&#29702;&#31354;&#38388;&#21644;&#26102;&#38388;&#26426;&#22120;&#23398;&#20064;&#31561;&#65292;&#35780;&#20272;&#20102; AI &#22914;&#20309;&#20026;&#29616;&#20195;&#22478;&#24066;&#35268;&#21010;&#20570;&#20986;&#36129;&#29486;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#33258;&#21160;&#21270;&#29992;&#22320;&#37197;&#32622;&#65292;&#21363;&#20174;&#21608;&#22260;&#30340;&#22320;&#29702;&#31354;&#38388;&#12289;&#20154;&#31867;&#31227;&#21160;&#12289;&#31038;&#20132;&#23186;&#20307;&#12289;&#29615;&#22659;&#21644;&#32463;&#27982;&#27963;&#21160;&#20013;&#20026;&#30446;&#26631;&#21306;&#22495;&#29983;&#25104;&#22303;&#22320;&#29992;&#36884;&#21644;&#24314;&#31569;&#37197;&#32622;&#12290;&#26368;&#21518;&#65292;&#26412;&#25991;&#21246;&#30011;&#20102;&#38598;&#25104; AI &#21644;&#22478;&#24066;&#35268;&#21010;&#38754;&#20020;&#30340;&#19968;&#20123;&#25361;&#25112;&#21644;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
The two fields of urban planning and artificial intelligence (AI) arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we introduce the importance of urban planning from the sustainability, living, economic, disaster, and environmental perspectives. We review the fundamental concepts of urban planning and relate these concepts to crucial open problems of machine learning, including adversarial learning, generative neural networks, deep encoder-decoder networks, conversational AI, and geospatial and temporal machine learning, thereby assaying how AI can contribute to modern urban planning. Thus, a central problem is automated land-use configuration, which is formulated as the generation of land uses and building configuration for a target area from surrounding geospatial, human mobility, social media, environment, and economic activities. Finally, we delineate some 
&lt;/p&gt;</description></item></channel></rss>