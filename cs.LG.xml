<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#35757;&#32451;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#22312;&#22797;&#26434;&#30340;&#27611;&#32454;&#34880;&#31649;&#32593;&#32476;&#20013;&#25104;&#21151;&#22320;&#23454;&#29616;&#20102;&#30913;&#24615;&#24494;&#28216;&#27891;&#22120;&#30340;&#36335;&#24452;&#35268;&#21010;&#12290;</title><link>https://arxiv.org/abs/2404.02171</link><description>&lt;p&gt;
&#30913;&#24615;&#24494;&#28216;&#27891;&#22120;&#22312;&#39640;&#20445;&#30495;&#24230;&#27169;&#25311;&#20154;&#20307;&#27611;&#32454;&#34880;&#31649;&#20013;&#30340;&#36335;&#24452;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Path planning of magnetic microswimmers in high-fidelity simulations of capillaries with deep reinforcement learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#35757;&#32451;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#22312;&#22797;&#26434;&#30340;&#27611;&#32454;&#34880;&#31649;&#32593;&#32476;&#20013;&#25104;&#21151;&#22320;&#23454;&#29616;&#20102;&#30913;&#24615;&#24494;&#28216;&#27891;&#22120;&#30340;&#36335;&#24452;&#35268;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#22914;&#23450;&#21521;&#33647;&#29289;&#36755;&#36865;&#12289;&#24494;&#21019;&#25163;&#26415;&#25110;&#24863;&#30693;&#20381;&#36182;&#20110;&#20197;&#26368;&#23567;&#21019;&#20260;&#26041;&#24335;&#21040;&#36798;&#36523;&#20307;&#20869;&#31934;&#30830;&#21306;&#22495;&#12290;&#20154;&#24037;&#32454;&#33740;&#38829;&#27611;(ABFs)&#24050;&#34987;&#35270;&#20026;&#36890;&#36807;&#24490;&#29615;&#31995;&#32479;&#23548;&#33322;&#23436;&#25104;&#27492;&#20219;&#21153;&#30340;&#28508;&#22312;&#24037;&#20855;&#12290;&#34429;&#28982;&#22312;&#31616;&#21333;&#22330;&#26223;&#20013;&#24050;&#20102;&#35299;ABFs&#30340;&#25511;&#21046;&#21644;&#28216;&#27891;&#29305;&#24615;&#65292;&#20294;&#23427;&#20204;&#22312;&#34880;&#28082;&#20013;&#30340;&#34892;&#20026;&#20173;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;ABFs&#22312;&#20154;&#31867;&#35270;&#32593;&#33180;&#20013;&#22797;&#26434;&#27611;&#32454;&#34880;&#31649;&#32593;&#32476;&#20013;&#28436;&#21270;&#30340;&#27169;&#25311;&#12290;&#36890;&#36807;&#20043;&#21069;&#22312;&#38477;&#38454;&#27169;&#22411;&#19978;&#35757;&#32451;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;ABF&#34987;&#31283;&#20581;&#22320;&#24341;&#23548;&#21040;&#25351;&#23450;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02171v1 Announce Type: cross  Abstract: Biomedical applications such as targeted drug delivery, microsurgery or sensing rely on reaching precise areas within the body in a minimally invasive way. Artificial bacterial flagella (ABFs) have emerged as potential tools for this task by navigating through the circulatory system. While the control and swimming characteristics of ABFs is understood in simple scenarios, their behavior within the bloodstream remains unclear. We conduct simulations of ABFs evolving in the complex capillary networks found in the human retina. The ABF is robustly guided to a prescribed target by a reinforcement learning agent previously trained on a reduced order model.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#21183;&#22312;&#33258;&#30001;&#33021;&#35745;&#31639;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#20351;&#29992;&#31561;&#21464;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;MLPs&#26469;&#20934;&#30830;&#39044;&#27979;&#33258;&#30001;&#33021;&#21644;&#36807;&#28193;&#24577;&#65292;&#32771;&#34385;&#21040;&#20998;&#23376;&#26500;&#22411;&#30340;&#33021;&#37327;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.13952</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#30456;&#20114;&#20316;&#29992;&#21183;&#22312;&#33258;&#30001;&#33021;&#35745;&#31639;&#20013;&#30340;&#24212;&#29992;&#32771;&#34385;
&lt;/p&gt;
&lt;p&gt;
Considerations in the use of ML interaction potentials for free energy calculations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13952
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#21183;&#22312;&#33258;&#30001;&#33021;&#35745;&#31639;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#20351;&#29992;&#31561;&#21464;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;MLPs&#26469;&#20934;&#30830;&#39044;&#27979;&#33258;&#30001;&#33021;&#21644;&#36807;&#28193;&#24577;&#65292;&#32771;&#34385;&#21040;&#20998;&#23376;&#26500;&#22411;&#30340;&#33021;&#37327;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21183;&#65288;MLPs&#65289;&#20855;&#26377;&#20934;&#30830;&#24314;&#27169;&#20998;&#23376;&#33021;&#37327;&#21644;&#33258;&#30001;&#33021;&#26223;&#35266;&#30340;&#28508;&#21147;&#65292;&#35813;&#20934;&#30830;&#24615;&#21487;&#23218;&#32654;&#37327;&#23376;&#21147;&#23398;&#65292;&#24182;&#20855;&#26377;&#31867;&#20284;&#32463;&#20856;&#27169;&#25311;&#30340;&#25928;&#29575;&#12290;&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#20351;&#29992;&#31561;&#21464;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;MLPs&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#24314;&#27169;&#24179;&#34913;&#20998;&#23376;&#36712;&#36857;&#20013;&#24050;&#34987;&#35777;&#26126;&#26377;&#25928;&#12290;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;MLPs&#33021;&#21542;&#20934;&#30830;&#39044;&#27979;&#33258;&#30001;&#33021;&#21644;&#36807;&#28193;&#24577;&#65292;&#35201;&#32771;&#34385;&#20998;&#23376;&#26500;&#22411;&#30340;&#33021;&#37327;&#21644;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#26816;&#26597;&#20102;&#35757;&#32451;&#25968;&#25454;&#20013;&#38598;&#20307;&#21464;&#37327;&#65288;CVs&#65289;&#30340;&#20998;&#24067;&#22914;&#20309;&#24433;&#21709;MLP&#22312;&#30830;&#23450;&#31995;&#32479;&#33258;&#30001;&#33021;&#38754;&#65288;FES&#65289;&#26102;&#30340;&#20934;&#30830;&#24615;&#65292;&#20351;&#29992;Metadynamics&#27169;&#25311;&#23545;&#19969;&#28919;&#21644;&#19993;&#27688;&#37240;&#20108;&#32957;&#65288;ADP&#65289;&#36827;&#34892;&#23454;&#39564;&#12290;&#35813;&#30740;&#31350;&#28041;&#21450;&#23545;&#22235;&#21313;&#19977;&#20010;MLP&#36827;&#34892;&#35757;&#32451;&#65292;&#20854;&#20013;&#19968;&#21322;&#22522;&#20110;&#32463;&#20856;&#20998;&#23376;&#21160;&#21147;&#23398;&#25968;&#25454;&#65292;&#20854;&#20313;&#30340;&#22522;&#20110;&#20174;&#22836;&#35745;&#31639;&#30340;&#33021;&#37327;&#12290;&#36825;&#20123;MLPs&#36827;&#34892;&#20102;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13952v1 Announce Type: cross  Abstract: Machine learning potentials (MLPs) offer the potential to accurately model the energy and free energy landscapes of molecules with the precision of quantum mechanics and an efficiency similar to classical simulations. This research focuses on using equivariant graph neural networks MLPs due to their proven effectiveness in modeling equilibrium molecular trajectories. A key issue addressed is the capability of MLPs to accurately predict free energies and transition states by considering both the energy and the diversity of molecular configurations. We examined how the distribution of collective variables (CVs) in the training data affects MLP accuracy in determining the free energy surface (FES) of systems, using Metadynamics simulations for butane and alanine dipeptide (ADP). The study involved training forty-three MLPs, half based on classical molecular dynamics data and the rest on ab initio computed energies. The MLPs were trained u
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;TREET&#65292;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#20256;&#36755;&#29109;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;Donsker-Vardhan&#34920;&#31034;&#27861;&#21644;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#23545;&#31283;&#23450;&#36807;&#31243;&#30340;&#20256;&#36755;&#29109;&#20272;&#35745;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20272;&#35745;TE&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#24182;&#23637;&#31034;&#20102;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#26041;&#26696;&#20248;&#21270;&#36890;&#20449;&#36890;&#36947;&#23481;&#37327;&#21644;&#20272;&#35745;&#22120;&#30340;&#35760;&#24518;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.06919</link><description>&lt;p&gt;
TREET: &#22522;&#20110;Transformer&#30340;&#20256;&#36755;&#29109;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
TREET: TRansfer Entropy Estimation via Transformer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06919
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;TREET&#65292;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#20256;&#36755;&#29109;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;Donsker-Vardhan&#34920;&#31034;&#27861;&#21644;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#23545;&#31283;&#23450;&#36807;&#31243;&#30340;&#20256;&#36755;&#29109;&#20272;&#35745;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20272;&#35745;TE&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#24182;&#23637;&#31034;&#20102;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#26041;&#26696;&#20248;&#21270;&#36890;&#20449;&#36890;&#36947;&#23481;&#37327;&#21644;&#20272;&#35745;&#22120;&#30340;&#35760;&#24518;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#36755;&#29109;&#65288;TE&#65289;&#26159;&#20449;&#24687;&#35770;&#20013;&#25581;&#31034;&#36807;&#31243;&#20043;&#38388;&#20449;&#24687;&#27969;&#21160;&#26041;&#21521;&#30340;&#24230;&#37327;&#65292;&#23545;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TREET&#30340;&#22522;&#20110;Transformer&#30340;&#20256;&#36755;&#29109;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#31283;&#23450;&#36807;&#31243;&#30340;TE&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;Donsker-Vardhan&#65288;DV&#65289;&#34920;&#31034;&#27861;&#23545;TE&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#21033;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#36827;&#34892;&#31070;&#32463;&#20272;&#35745;&#20219;&#21153;&#12290;&#25105;&#20204;&#23545;TREET&#36827;&#34892;&#20102;&#35814;&#32454;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#23558;&#20854;&#19982;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#20026;&#20102;&#22686;&#21152;&#20854;&#36866;&#29992;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#21151;&#33021;&#34920;&#31034;&#24341;&#29702;&#30340;&#20272;&#35745;TE&#20248;&#21270;&#26041;&#26696;&#12290;&#20043;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#32852;&#21512;&#20248;&#21270;&#26041;&#26696;&#26469;&#20248;&#21270;&#20855;&#26377;&#35760;&#24518;&#24615;&#30340;&#36890;&#20449;&#36890;&#36947;&#23481;&#37327;&#65292;&#36825;&#26159;&#20449;&#24687;&#35770;&#20013;&#30340;&#19968;&#20010;&#20856;&#22411;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#35760;&#24518;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer entropy (TE) is a measurement in information theory that reveals the directional flow of information between processes, providing valuable insights for a wide range of real-world applications. This work proposes Transfer Entropy Estimation via Transformers (TREET), a novel transformer-based approach for estimating the TE for stationary processes. The proposed approach employs Donsker-Vardhan (DV) representation to TE and leverages the attention mechanism for the task of neural estimation. We propose a detailed theoretical and empirical study of the TREET, comparing it to existing methods. To increase its applicability, we design an estimated TE optimization scheme that is motivated by the functional representation lemma. Afterwards, we take advantage of the joint optimization scheme to optimize the capacity of communication channels with memory, which is a canonical optimization problem in information theory, and show the memory capabilities of our estimator. Finally, we apply
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65288;LAIMs&#65289;&#29983;&#25104;&#30340;&#22810;&#23186;&#20307;&#20869;&#23481;&#30340;&#26816;&#27979;&#26041;&#27861;&#21644;&#30740;&#31350;&#36827;&#23637;&#65292;&#26088;&#22312;&#22635;&#34917;&#29616;&#26377;&#30740;&#31350;&#20013;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#31867;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#32431;&#26816;&#27979;&#21644;&#24212;&#29992;&#22330;&#26223;&#20004;&#20010;&#35282;&#24230;&#26469;&#22686;&#24378;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.00045</link><description>&lt;p&gt;
&#26816;&#27979;&#22823;&#22411;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#29983;&#25104;&#30340;&#22810;&#23186;&#20307;&#20869;&#23481;&#65306;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Detecting Multimedia Generated by Large AI Models: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65288;LAIMs&#65289;&#29983;&#25104;&#30340;&#22810;&#23186;&#20307;&#20869;&#23481;&#30340;&#26816;&#27979;&#26041;&#27861;&#21644;&#30740;&#31350;&#36827;&#23637;&#65292;&#26088;&#22312;&#22635;&#34917;&#29616;&#26377;&#30740;&#31350;&#20013;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#31867;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#32431;&#26816;&#27979;&#21644;&#24212;&#29992;&#22330;&#26223;&#20004;&#20010;&#35282;&#24230;&#26469;&#22686;&#24378;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65288;LAIMs&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#23588;&#20854;&#26159;&#25193;&#25955;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#26631;&#24535;&#30528;&#19968;&#31181;&#26032;&#30340;&#26102;&#20195;&#65292;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#30340;&#22810;&#23186;&#20307;&#20869;&#23481;&#34987;&#36234;&#26469;&#36234;&#22810;&#22320;&#25972;&#21512;&#21040;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#12290;&#23613;&#31649;&#22312;&#35768;&#22810;&#39046;&#22495;&#26377;&#30410;&#65292;&#20294;&#36825;&#20123;&#20869;&#23481;&#20063;&#24102;&#26469;&#20102;&#37325;&#22823;&#39118;&#38505;&#65292;&#21253;&#25324;&#28508;&#22312;&#30340;&#28389;&#29992;&#12289;&#31038;&#20250;&#30772;&#22351;&#21644;&#20262;&#29702;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#26816;&#27979;&#30001;LAIMs&#29983;&#25104;&#30340;&#22810;&#23186;&#20307;&#20869;&#23481;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#30456;&#20851;&#30740;&#31350;&#20063;&#22823;&#24133;&#22686;&#21152;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#30446;&#21069;&#20173;&#28982;&#23384;&#22312;&#19968;&#20010;&#26126;&#26174;&#30340;&#38382;&#39064;&#65292;&#21363;&#32570;&#20047;&#31995;&#32479;&#24615;&#30340;&#35843;&#26597;&#30740;&#31350;&#65292;&#19987;&#38376;&#20851;&#27880;&#26816;&#27979;LAIMs&#29983;&#25104;&#30340;&#22810;&#23186;&#20307;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20221;&#20840;&#38754;&#28085;&#30422;&#29616;&#26377;&#30740;&#31350;&#30340;&#35843;&#26597;&#25253;&#21578;&#65292;&#37325;&#28857;&#20851;&#27880;&#26816;&#27979;LAIMs&#29983;&#25104;&#30340;&#22810;&#23186;&#20307;&#20869;&#23481;&#65288;&#22914;&#25991;&#26412;&#12289;&#22270;&#20687;&#12289;&#35270;&#39057;&#12289;&#38899;&#39057;&#21644;&#22810;&#27169;&#24577;&#20869;&#23481;&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26816;&#27979;&#26041;&#27861;&#20998;&#31867;&#27861;&#65292;&#25353;&#23186;&#20307;&#24418;&#24335;&#20998;&#31867;&#65292;&#24182;&#19982;&#32431;&#26816;&#27979;&#65288;&#26088;&#22312;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#65289;&#21644;&#24212;&#29992;&#22330;&#26223;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid advancement of Large AI Models (LAIMs), particularly diffusion models and large language models, has marked a new era where AI-generated multimedia is increasingly integrated into various aspects of daily life. Although beneficial in numerous fields, this content presents significant risks, including potential misuse, societal disruptions, and ethical concerns. Consequently, detecting multimedia generated by LAIMs has become crucial, with a marked rise in related research. Despite this, there remains a notable gap in systematic surveys that focus specifically on detecting LAIM-generated multimedia. Addressing this, we provide the first survey to comprehensively cover existing research on detecting multimedia (such as text, images, videos, audio, and multimodal content) created by LAIMs. Specifically, we introduce a novel taxonomy for detection methods, categorized by media modality, and aligned with two perspectives: pure detection (aiming to enhance detection performance) an
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#27668;&#20505;&#27169;&#22411;&#22810;&#23610;&#24230;&#23376;&#32593;&#26684;&#21442;&#25968;&#21270;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#23376;&#32593;&#26684;&#24378;&#36843;&#20540;&#26469;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17496</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#27668;&#20505;&#27169;&#22411;&#23376;&#32593;&#26684;&#21442;&#25968;&#21270;&#22810;&#23610;&#24230;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Data-driven multiscale modeling of subgrid parameterizations in climate models. (arXiv:2303.17496v1 [physics.ao-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17496
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#27668;&#20505;&#27169;&#22411;&#22810;&#23610;&#24230;&#23376;&#32593;&#26684;&#21442;&#25968;&#21270;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#23376;&#32593;&#26684;&#24378;&#36843;&#20540;&#26469;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23376;&#32593;&#26684;&#21442;&#25968;&#21270;&#26159;&#30446;&#21069;&#27668;&#20505;&#27169;&#22411;&#20013;&#37325;&#35201;&#30340;&#32452;&#25104;&#37096;&#20998;&#65292;&#29992;&#20110;&#34920;&#31034;&#20302;&#20110;&#27169;&#22411;&#20998;&#36776;&#29575;&#19979;&#21457;&#29983;&#30340;&#29289;&#29702;&#36807;&#31243;&#65292;&#20174;&#32780;&#20135;&#29983;&#20934;&#30830;&#30340;&#38271;&#26399;&#27668;&#20505;&#39044;&#27979;&#12290;&#24050;&#32463;&#23581;&#35797;&#20102;&#22810;&#31181;&#26041;&#27861;&#26469;&#35774;&#35745;&#36825;&#20123;&#32452;&#20214;&#65292;&#21253;&#25324;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#36825;&#20010;&#39044;&#27979;&#38382;&#39064;&#30340;&#27010;&#24565;&#39564;&#35777;&#12290;&#25105;&#20204;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#39044;&#27979;&#27979;&#35797;&#27169;&#22411;&#19978;&#30340;&#23376;&#32593;&#26684;&#24378;&#36843;&#20540;&#65292;&#24182;&#30740;&#31350;&#22312;&#31934;&#32454;-&#31895;&#31961;&#21644;&#31895;&#31961;-&#31934;&#32454;&#26041;&#21521;&#19978;&#20351;&#29992;&#39069;&#22806;&#20449;&#24687;&#21487;&#20197;&#33719;&#24471;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Subgrid parameterizations, which represent physical processes occurring below the resolution of current climate models, are an important component in producing accurate, long-term predictions for the climate. A variety of approaches have been tested to design these components, including deep learning methods. In this work, we evaluate a proof of concept illustrating a multiscale approach to this prediction problem. We train neural networks to predict subgrid forcing values on a testbed model and examine improvements in prediction accuracy that can be obtained by using additional information in both fine-to-coarse and coarse-to-fine directions.
&lt;/p&gt;</description></item></channel></rss>