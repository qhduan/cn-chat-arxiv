<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#23454;&#29616;&#20102;&#32422;$O(1/\epsilon)$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#30456;&#27604;&#20808;&#21069;&#25991;&#29486;&#20013;&#24050;&#26377;&#30340;$O(1/\epsilon^2)$&#26679;&#26412;&#22797;&#26434;&#24230;&#26377;&#25152;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.16324</link><description>&lt;p&gt;
&#23454;&#29616;&#32422;$O(1/\epsilon)$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#29992;&#20110;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Achieving $\tilde{O}(1/\epsilon)$ Sample Complexity for Constrained Markov Decision Process
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16324
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#23454;&#29616;&#20102;&#32422;$O(1/\epsilon)$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#30456;&#27604;&#20808;&#21069;&#25991;&#29486;&#20013;&#24050;&#26377;&#30340;$O(1/\epsilon^2)$&#26679;&#26412;&#22797;&#26434;&#24230;&#26377;&#25152;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDP&#65289;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#22312;&#39034;&#24207;&#23398;&#20064;&#21644;&#20915;&#31574;&#20013;&#28385;&#36275;&#23433;&#20840;&#24615;&#25110;&#36164;&#28304;&#32422;&#26463;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25317;&#26377;&#26377;&#38480;&#36164;&#28304;&#21644;&#26410;&#30693;&#36716;&#31227;&#27010;&#29575;&#30340;MDP&#12290;&#22312;&#27599;&#20010;&#38454;&#27573;&#65292;&#25105;&#20204;&#37319;&#21462;&#19968;&#20010;&#34892;&#21160;&#65292;&#25910;&#38598;&#22870;&#21169;&#24182;&#28040;&#32791;&#19968;&#20123;&#36164;&#28304;&#65292;&#25152;&#26377;&#20551;&#35774;&#37117;&#26159;&#26410;&#30693;&#30340;&#65292;&#24182;&#19988;&#38656;&#35201;&#38543;&#30528;&#26102;&#38388;&#23398;&#20064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36808;&#20986;&#20102;&#20026;CMDP&#38382;&#39064;&#25512;&#23548;&#20986;&#26368;&#20248;&#30340;&#38382;&#39064;&#30456;&#20851;&#20445;&#35777;&#30340;&#31532;&#19968;&#27493;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#23545;&#25968;&#36951;&#25022;&#30028;&#38480;&#65292;&#36825;&#36716;&#21270;&#20026;$O(\frac{\kappa}{\epsilon}\cdot\log^2(1/\epsilon))$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#20854;&#20013;$\kappa$&#26159;&#19968;&#20010;&#19982;&#38382;&#39064;&#30456;&#20851;&#30340;&#21442;&#25968;&#65292;&#20294;&#19982;$\epsilon$&#26080;&#20851;&#12290;&#25105;&#20204;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#25913;&#36827;&#20102;&#20808;&#21069;&#25991;&#29486;&#20013;&#38024;&#23545;CMDP&#38382;&#39064;&#24314;&#31435;&#30340;$O(1/\epsilon^2)$&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16324v1 Announce Type: new  Abstract: We consider the reinforcement learning problem for the constrained Markov decision process (CMDP), which plays a central role in satisfying safety or resource constraints in sequential learning and decision-making. In this problem, we are given finite resources and a MDP with unknown transition probabilities. At each stage, we take an action, collecting a reward and consuming some resources, all assumed to be unknown and need to be learned over time. In this work, we take the first step towards deriving optimal problem-dependent guarantees for the CMDP problems. We derive a logarithmic regret bound, which translates into a $O(\frac{\kappa}{\epsilon}\cdot\log^2(1/\epsilon))$ sample complexity bound, with $\kappa$ being a problem-dependent parameter, yet independent of $\epsilon$. Our sample complexity bound improves upon the state-of-art $O(1/\epsilon^2)$ sample complexity for CMDP problems established in the previous literature, in terms
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#38382;&#39064;&#12289;&#22312;&#20219;&#24847;&#25968;&#37327;&#25308;&#21344;&#24237;&#25915;&#20987;&#32773;&#19979;&#30340;&#26032;&#26041;&#27861;&#65292;&#26680;&#24515;&#26159;&#19968;&#31181;&#30452;&#25509;&#30340;&#39640;&#32500;&#21322;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#20855;&#26377;&#26497;&#23567;&#26497;&#20540;&#32479;&#35745;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.13352</link><description>&lt;p&gt;
&#39640;&#32500;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#22312;&#20219;&#24847;&#25968;&#37327;&#25308;&#21344;&#24237;&#25915;&#20987;&#32773;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High Dimensional Distributed Gradient Descent with Arbitrary Number of Byzantine Attackers. (arXiv:2307.13352v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#38382;&#39064;&#12289;&#22312;&#20219;&#24847;&#25968;&#37327;&#25308;&#21344;&#24237;&#25915;&#20987;&#32773;&#19979;&#30340;&#26032;&#26041;&#27861;&#65292;&#26680;&#24515;&#26159;&#19968;&#31181;&#30452;&#25509;&#30340;&#39640;&#32500;&#21322;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#20855;&#26377;&#26497;&#23567;&#26497;&#20540;&#32479;&#35745;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20855;&#26377;&#25308;&#21344;&#24237;&#25925;&#38556;&#30340;&#24378;&#40065;&#26834;&#20998;&#24067;&#24335;&#23398;&#20064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22823;&#22810;&#21463;&#21040;&#32500;&#24230;&#35781;&#21650;&#30340;&#38480;&#21046;&#65292;&#38543;&#30528;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#65292;&#36825;&#20010;&#38382;&#39064;&#21464;&#24471;&#36234;&#26469;&#36234;&#20005;&#37325;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#38382;&#39064;&#12289;&#22312;&#20219;&#24847;&#25968;&#37327;&#25308;&#21344;&#24237;&#25915;&#20987;&#32773;&#19979;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#35774;&#35745;&#26680;&#24515;&#26159;&#19968;&#31181;&#30452;&#25509;&#30340;&#39640;&#32500;&#21322;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#24819;&#27861;&#26159;&#39318;&#20808;&#35782;&#21035;&#19968;&#20010;&#23376;&#31354;&#38388;&#65292;&#36890;&#36807;&#24037;&#20316;&#26426;&#19978;&#20256;&#30340;&#26799;&#24230;&#21521;&#37327;&#20272;&#35745;&#19982;&#35813;&#23376;&#31354;&#38388;&#22402;&#30452;&#30340;&#22343;&#20540;&#20998;&#37327;&#65292;&#32780;&#36890;&#36807;&#36741;&#21161;&#25968;&#25454;&#38598;&#20272;&#35745;&#35813;&#23376;&#31354;&#38388;&#20869;&#30340;&#22343;&#20540;&#20998;&#37327;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#29992;&#20316;&#20998;&#24067;&#24335;&#23398;&#20064;&#38382;&#39064;&#30340;&#32858;&#21512;&#22120;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#26032;&#26041;&#27861;&#20855;&#26377;&#26497;&#23567;&#26497;&#20540;&#32479;&#35745;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#24471;&#21040;&#20102;&#26174;&#33879;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust distributed learning with Byzantine failures has attracted extensive research interests in recent years. However, most of existing methods suffer from curse of dimensionality, which is increasingly serious with the growing complexity of modern machine learning models. In this paper, we design a new method that is suitable for high dimensional problems, under arbitrary number of Byzantine attackers. The core of our design is a direct high dimensional semi-verified mean estimation method. Our idea is to identify a subspace first. The components of mean value perpendicular to this subspace can be estimated via gradient vectors uploaded from worker machines, while the components within this subspace are estimated using auxiliary dataset. We then use our new method as the aggregator of distributed learning problems. Our theoretical analysis shows that the new method has minimax optimal statistical rates. In particular, the dependence on dimensionality is significantly improved compar
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.10656</link><description>&lt;p&gt;
&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65306;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20154;&#31867;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21307;&#30103;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#21892;&#36523;&#20307;&#21644;&#31934;&#31070;&#29366;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65288;VHGM&#65289;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#26377;&#20851;&#21307;&#30103;&#20445;&#20581;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20010;&#24615;&#30340;&#23646;&#24615;&#12290;VHGM&#26159;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20351;&#29992;&#25513;&#30721;&#24314;&#27169;&#35757;&#32451;&#65292;&#22312;&#24050;&#30693;&#23646;&#24615;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#23646;&#24615;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#21033;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#39640;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#25968;&#20540;&#35780;&#20272;&#20102;VHGM&#21450;&#20854;&#35757;&#32451;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20316;&#20026;VHGM&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#24212;&#29992;&#31243;&#24207;&#65292;&#28436;&#31034;&#20102;&#29992;&#25143;&#24773;&#22659;&#65292;&#20363;&#22914;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
&lt;/p&gt;</description></item></channel></rss>