<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24448;&#36820;&#35774;&#35745;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#20026;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#26356;&#26377;&#25928;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#39057;&#29575;&#21487;&#20197;&#38477;&#20302;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.17285</link><description>&lt;p&gt;
&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24448;&#36820;&#35774;&#35745;&#36827;&#34892;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Analysis of Switchback Designs in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24448;&#36820;&#35774;&#35745;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#20026;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#26356;&#26377;&#25928;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#39057;&#29575;&#21487;&#20197;&#38477;&#20302;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;A/B&#27979;&#35797;&#20013;&#24448;&#36820;&#35774;&#35745;&#30340;&#35814;&#32454;&#30740;&#31350;&#65292;&#36825;&#20123;&#35774;&#35745;&#38543;&#26102;&#38388;&#22312;&#22522;&#20934;&#21644;&#26032;&#31574;&#30053;&#20043;&#38388;&#20132;&#26367;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20840;&#38754;&#35780;&#20272;&#36825;&#20123;&#35774;&#35745;&#23545;&#20854;&#20135;&#29983;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#20272;&#35745;&#22120;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#22823;&#22823;&#31616;&#21270;&#20102;&#36825;&#20123;ATE&#30340;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#22312;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#29615;&#22659;&#20013;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65306;(i) &#24403;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#21576;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#30340;&#20132;&#26367;&#35774;&#35745;&#26356;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#30340;&#39057;&#29575;&#24448;&#24448;&#20250;&#38477;&#20302;ATE&#20272;&#35745;&#22120;&#30340;MSE&#12290;(ii) &#28982;&#32780;&#65292;&#24403;&#35823;&#24046;&#19981;&#30456;&#20851;&#26102;&#65292;&#25152;&#26377;&#36825;&#20123;&#35774;&#35745;&#21464;&#24471;&#28176;&#36817;&#31561;&#25928;&#12290;(iii) &#22312;&#22823;&#22810;&#25968;&#35823;&#24046;&#20026;&#36127;&#30456;&#20851;&#26102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17285v1 Announce Type: cross  Abstract: This paper offers a detailed investigation of switchback designs in A/B testing, which alternate between baseline and new policies over time. Our aim is to thoroughly evaluate the effects of these designs on the accuracy of their resulting average treatment effect (ATE) estimators. We propose a novel "weak signal analysis" framework, which substantially simplifies the calculations of the mean squared errors (MSEs) of these ATEs in Markov decision process environments. Our findings suggest that (i) when the majority of reward errors are positively correlated, the switchback design is more efficient than the alternating-day design which switches policies in a daily basis. Additionally, increasing the frequency of policy switches tends to reduce the MSE of the ATE estimator. (ii) When the errors are uncorrelated, however, all these designs become asymptotically equivalent. (iii) In cases where the majority of errors are negative correlate
&lt;/p&gt;</description></item><item><title>ChatDBG&#26159;&#31532;&#19968;&#20010;AI-Powered&#35843;&#35797;&#21161;&#25163;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21040;&#20256;&#32479;&#35843;&#35797;&#22120;&#20013;&#65292;&#23454;&#29616;&#20102;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#23545;&#35805;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#12289;&#25191;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;</title><link>https://arxiv.org/abs/2403.16354</link><description>&lt;p&gt;
ChatDBG: &#19968;&#31181;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35843;&#35797;&#21161;&#25163;
&lt;/p&gt;
&lt;p&gt;
ChatDBG: An AI-Powered Debugging Assistant
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16354
&lt;/p&gt;
&lt;p&gt;
ChatDBG&#26159;&#31532;&#19968;&#20010;AI-Powered&#35843;&#35797;&#21161;&#25163;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21040;&#20256;&#32479;&#35843;&#35797;&#22120;&#20013;&#65292;&#23454;&#29616;&#20102;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#23545;&#35805;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#12289;&#25191;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;ChatDBG&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35843;&#35797;&#21161;&#25163;&#12290;ChatDBG&#38598;&#25104;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#65292;&#26174;&#33879;&#22686;&#24378;&#20102;&#20256;&#32479;&#35843;&#35797;&#22120;&#30340;&#21151;&#33021;&#21644;&#29992;&#25143;&#21451;&#22909;&#24615;&#12290;ChatDBG&#20801;&#35768;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#36827;&#34892;&#21327;&#20316;&#23545;&#35805;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#25552;&#20986;&#20851;&#20110;&#31243;&#24207;&#29366;&#24577;&#30340;&#22797;&#26434;&#38382;&#39064;&#65292;&#23545;&#23849;&#28291;&#25110;&#26029;&#35328;&#22833;&#36133;&#36827;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#35832;&#22914;&#8220;&#20026;&#20160;&#20040;x&#20026;&#31354;&#65311;&#8221;&#20043;&#31867;&#30340;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#26597;&#35810;&#65292;ChatDBG&#25480;&#20104;LLM&#33258;&#20027;&#26435;&#65292;&#36890;&#36807;&#21457;&#20986;&#21629;&#20196;&#26469;&#27983;&#35272;&#22534;&#26632;&#21644;&#26816;&#26597;&#31243;&#24207;&#29366;&#24577;&#36827;&#34892;&#35843;&#35797;&#65307;&#28982;&#21518;&#25253;&#21578;&#20854;&#21457;&#29616;&#24182;&#23558;&#25511;&#21046;&#26435;&#20132;&#36824;&#32473;&#31243;&#24207;&#21592;&#12290;&#25105;&#20204;&#30340;ChatDBG&#21407;&#22411;&#19982;&#26631;&#20934;&#35843;&#35797;&#22120;&#38598;&#25104;&#65292;&#21253;&#25324;LLDB&#12289;GDB&#21644;WinDBG&#29992;&#20110;&#26412;&#22320;&#20195;&#30721;&#20197;&#21450;&#29992;&#20110;Python&#30340;Pdb&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#20195;&#30721;&#38598;&#21512;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#20855;&#26377;&#24050;&#30693;&#38169;&#35823;&#30340;C/C++&#20195;&#30721;&#21644;&#19968;&#22871;Python&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#22270;&#20687;&#25551;&#36848;&#20855;&#20307;&#24615;&#65292;&#29992;&#20110;&#35780;&#20272;&#26631;&#39064;&#25991;&#26412;&#30340;&#20855;&#20307;&#24615;&#21644;&#30456;&#20851;&#24615;&#65292;&#20197;&#24110;&#21161;&#22312;&#22810;&#27169;&#24577;&#23398;&#20064;&#20013;&#38548;&#31163;&#25552;&#20379;&#26368;&#24378;&#20449;&#21495;&#30340;&#26368;&#20855;&#20307;&#26679;&#26412;&#12290;</title><link>https://arxiv.org/abs/2403.01306</link><description>&lt;p&gt;
ICC&#65306;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#31579;&#36873;&#30340;&#22270;&#20687;&#25551;&#36848;&#20855;&#20307;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
ICC: Quantifying Image Caption Concreteness for Multimodal Dataset Curation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01306
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#22270;&#20687;&#25551;&#36848;&#20855;&#20307;&#24615;&#65292;&#29992;&#20110;&#35780;&#20272;&#26631;&#39064;&#25991;&#26412;&#30340;&#20855;&#20307;&#24615;&#21644;&#30456;&#20851;&#24615;&#65292;&#20197;&#24110;&#21161;&#22312;&#22810;&#27169;&#24577;&#23398;&#20064;&#20013;&#38548;&#31163;&#25552;&#20379;&#26368;&#24378;&#20449;&#21495;&#30340;&#26368;&#20855;&#20307;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01306v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#38024;&#23545;&#37197;&#23545;&#25991;&#26412;-&#22270;&#20687;&#25968;&#25454;&#30340;Web&#35268;&#27169;&#35757;&#32451;&#22312;&#22810;&#27169;&#24577;&#23398;&#20064;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#20294;&#25361;&#25112;&#22312;&#37326;&#22806;&#25968;&#25454;&#38598;&#30340;&#39640;&#22122;&#22768;&#29305;&#24615;&#12290;&#26631;&#20934;&#25968;&#25454;&#36807;&#28388;&#26041;&#27861;&#25104;&#21151;&#21435;&#38500;&#20102;&#19981;&#21305;&#37197;&#30340;&#25991;&#26412;-&#22270;&#20687;&#23545;&#65292;&#20294;&#20801;&#35768;&#35821;&#20041;&#30456;&#20851;&#20294;&#38750;&#24120;&#25277;&#35937;&#25110;&#20027;&#35266;&#30340;&#25991;&#26412;&#12290;&#36825;&#20123;&#26041;&#27861;&#32570;&#20047;&#32454;&#31890;&#24230;&#30340;&#33021;&#21147;&#26469;&#38548;&#31163;&#25552;&#20379;&#22312;&#22024;&#26434;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#26368;&#24378;&#20449;&#21495;&#30340;&#26368;&#20855;&#20307;&#26679;&#26412;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#22270;&#20687;&#25551;&#36848;&#20855;&#20307;&#24615;&#65292;&#35780;&#20272;&#27809;&#26377;&#22270;&#20687;&#21442;&#32771;&#30340;&#26631;&#39064;&#25991;&#26412;&#20197;&#34913;&#37327;&#20854;&#20855;&#20307;&#24615;&#21644;&#30456;&#20851;&#24615;&#65292;&#20197;&#20379;&#22312;&#22810;&#27169;&#24577;&#23398;&#20064;&#20013;&#20351;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#34913;&#37327;&#35270;&#35273;-&#35821;&#20041;&#20449;&#24687;&#25439;&#22833;&#30340;&#24378;&#22522;&#30784;&#27169;&#22411;&#26469;&#36827;&#34892;&#35780;&#20272;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#19982;&#20154;&#31867;&#23545;&#21333;&#35789;&#21644;&#21477;&#23376;&#32423;&#25991;&#26412;&#20855;&#20307;&#24615;&#30340;&#35780;&#20272;&#39640;&#24230;&#30456;&#20851;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01306v1 Announce Type: new  Abstract: Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild. Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly abstract or subjective text. These approaches lack the fine-grained ability to isolate the most concrete samples that provide the strongest signal for learning in a noisy dataset. In this work, we propose a new metric, image caption concreteness, that evaluates caption text without an image reference to measure its concreteness and relevancy for use in multimodal learning. Our approach leverages strong foundation models for measuring visual-semantic information loss in multimodal representations. We demonstrate that this strongly correlates with human evaluation of concreteness in both single-word and sentence-level texts. Moreover, we show tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;HJB&#31639;&#23376;&#30340;&#38543;&#26426;&#31995;&#32479;&#31070;&#32463;&#26368;&#20248;&#25511;&#21046;&#22120;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#23398;&#20064;&#30340;&#26041;&#27861;&#35299;&#20915;&#39640;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.15592</link><description>&lt;p&gt;
&#22522;&#20110;&#36335;&#24452;HJB&#31639;&#23376;&#30340;&#38543;&#26426;&#31995;&#32479;&#31070;&#32463;&#26368;&#20248;&#25511;&#21046;&#22120;
&lt;/p&gt;
&lt;p&gt;
Neural optimal controller for stochastic systems via pathwise HJB operator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;HJB&#31639;&#23376;&#30340;&#38543;&#26426;&#31995;&#32479;&#31070;&#32463;&#26368;&#20248;&#25511;&#21046;&#22120;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#23398;&#20064;&#30340;&#26041;&#27861;&#35299;&#20915;&#39640;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#22522;&#20110;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#23398;&#20064;&#21644;&#21160;&#24577;&#35268;&#21010;&#65292;&#20026;&#39640;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#24320;&#21457;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31639;&#27861;&#12290;&#19982;&#20381;&#36182;&#20110;Hamilton-Jacobi-Bellman&#65288;HJB&#65289;&#26041;&#31243;&#35299;&#30340;&#27010;&#29575;&#34920;&#31034;&#30340;&#32463;&#20856;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19982;HJB&#26041;&#31243;&#30456;&#20851;&#30340;&#36335;&#24452;&#31639;&#23376;&#65292;&#20174;&#32780;&#21487;&#20197;&#23450;&#20041;&#19968;&#20010;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#26681;&#25454;&#26368;&#20248;&#25511;&#21046;&#26159;&#21542;&#20855;&#26377;&#26174;&#24335;&#34920;&#31034;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#25968;&#20540;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#25130;&#26029;&#12289;&#36817;&#20284;&#21644;&#20248;&#21270;&#35823;&#24046;&#22914;&#20309;&#24433;&#21709;&#36825;&#20123;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#36827;&#34892;&#20102;&#35823;&#24046;&#20998;&#26512;&#12290;&#36890;&#36807;&#22312;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#19978;&#23637;&#31034;&#25968;&#20540;&#32467;&#26524;&#65292;&#35828;&#26126;&#20102;&#25152;&#25552;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15592v1 Announce Type: cross  Abstract: The aim of this work is to develop deep learning-based algorithms for high-dimensional stochastic control problems based on physics-informed learning and dynamic programming. Unlike classical deep learning-based methods relying on a probabilistic representation of the solution to the Hamilton--Jacobi--Bellman (HJB) equation, we introduce a pathwise operator associated with the HJB equation so that we can define a problem of physics-informed learning. According to whether the optimal control has an explicit representation, two numerical methods are proposed to solve the physics-informed learning problem. We provide an error analysis on how the truncation, approximation and optimization errors affect the accuracy of these methods. Numerical results on various applications are presented to illustrate the performance of the proposed algorithms.
&lt;/p&gt;</description></item><item><title>AQA-Bench&#26159;&#19968;&#20010;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#30740;&#31350;&#21457;&#29616;&#38381;&#28304;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26174;&#33879;&#20248;&#20110;&#24320;&#28304;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.09404</link><description>&lt;p&gt;
AQA-Bench&#65306;&#35780;&#20272;LLM&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#30340;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09404
&lt;/p&gt;
&lt;p&gt;
AQA-Bench&#26159;&#19968;&#20010;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#30740;&#31350;&#21457;&#29616;&#38381;&#28304;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26174;&#33879;&#20248;&#20110;&#24320;&#28304;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;AQA-Bench&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#65292;&#22914;&#28145;&#24230;&#20248;&#20808;&#25628;&#32034;&#65288;DFS&#65289;&#31561;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#35780;&#20272;&#22522;&#20934;&#27979;&#35797;&#30340;&#20851;&#38190;&#29305;&#28857;&#22312;&#20110;&#20854;&#20132;&#20114;&#24335;&#35780;&#20272;&#21327;&#35758;-&#20363;&#22914;&#65292;&#22312;DFS&#20013;&#65292;&#27599;&#20010;&#33410;&#28857;&#30340;&#21487;&#29992;&#36830;&#25509;&#36793;&#21462;&#20915;&#20110;&#27169;&#22411;&#23545;&#35813;&#33410;&#28857;&#30340;&#36941;&#21382;&#65292;&#22240;&#27492;&#38656;&#35201;LLM&#26377;&#25928;&#22320;&#35760;&#20303;&#24050;&#35775;&#38382;&#33410;&#28857;&#24182;&#31574;&#21010;&#21518;&#32493;&#31227;&#21160;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#20351;&#29992;&#19977;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#26500;&#24314;&#20102;AQA-Bench&#65292;&#20998;&#21035;&#26159;&#20108;&#20998;&#25628;&#32034;&#65292;&#28145;&#24230;&#20248;&#20808;&#25628;&#32034;&#21644;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#65292;&#24182;&#35780;&#20272;&#20102;12&#31181;&#19981;&#21516;&#30340;LLMs&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#25581;&#31034;&#20102;&#19968;&#20123;&#26377;&#36259;&#30340;&#21457;&#29616;&#65306;&#65288;1&#65289;&#31867;&#20284;GPT-4&#21644;Gemini&#31561;&#38381;&#28304;&#27169;&#22411;&#36890;&#24120;&#26174;&#31034;&#20986;&#24378;&#22823;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26126;&#26174;&#20248;&#20110;&#24320;&#28304;LLMs&#12290;&#65288;2&#65289;&#22825;&#30495;&#22320;&#25552;&#20379;&#20114;&#25805;&#20316;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09404v1 Announce Type: cross Abstract: This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol -- for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 12 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show strong sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing inter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#23433;&#20840;&#20445;&#35777;&#25506;&#32034;&#26694;&#26550;&#65292;&#20351;&#29992;&#26368;&#20248;&#25511;&#21046;&#23454;&#29616;&#20102;&#23545;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#26377;&#38480;&#26102;&#38388;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#30340;&#20445;&#35777;&#25506;&#32034;&#65292;&#21516;&#26102;&#20855;&#26377;&#35777;&#26126;&#30340;&#23433;&#20840;&#24615;&#21644;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06562</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#23433;&#20840;&#20445;&#35777;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Safe Guaranteed Exploration for Non-linear Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06562
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#23433;&#20840;&#20445;&#35777;&#25506;&#32034;&#26694;&#26550;&#65292;&#20351;&#29992;&#26368;&#20248;&#25511;&#21046;&#23454;&#29616;&#20102;&#23545;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#26377;&#38480;&#26102;&#38388;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#30340;&#20445;&#35777;&#25506;&#32034;&#65292;&#21516;&#26102;&#20855;&#26377;&#35777;&#26126;&#30340;&#23433;&#20840;&#24615;&#21644;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#20808;&#39564;&#26410;&#30693;&#32422;&#26463;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#23433;&#20840;&#25506;&#32034;&#26159;&#38480;&#21046;&#26426;&#22120;&#20154;&#33258;&#20027;&#24615;&#30340;&#22522;&#26412;&#25361;&#25112;&#12290;&#34429;&#28982;&#23433;&#20840;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#23545;&#36275;&#22815;&#25506;&#32034;&#30340;&#20445;&#35777;&#23545;&#20110;&#30830;&#20445;&#33258;&#20027;&#20219;&#21153;&#23436;&#25104;&#20063;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#23433;&#20840;&#20445;&#35777;&#25506;&#32034;&#26694;&#26550;&#65292;&#21033;&#29992;&#26368;&#20248;&#25511;&#21046;&#23454;&#29616;&#21069;&#25152;&#26410;&#26377;&#30340;&#32467;&#26524;&#65306;&#20855;&#26377;&#26377;&#38480;&#26102;&#38388;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#20445;&#35777;&#25506;&#32034;&#65292;&#21516;&#26102;&#22312;&#20219;&#24847;&#39640;&#27010;&#29575;&#19979;&#34987;&#35777;&#26126;&#26159;&#23433;&#20840;&#30340;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#21487;&#36866;&#29992;&#20110;&#20855;&#26377;&#22797;&#26434;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#21644;&#26410;&#30693;&#39046;&#22495;&#30340;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#12290;&#22522;&#20110;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;SageMPC&#65292;&#37319;&#29992;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#36827;&#34892;&#23433;&#20840;&#20445;&#35777;&#25506;&#32034;&#12290;SageMPC&#36890;&#36807;&#25972;&#21512;&#19977;&#31181;&#25216;&#26415;&#26469;&#25552;&#39640;&#25928;&#29575;&#65306;i) &#21033;&#29992;Lipschitz&#36793;&#30028;&#65292;ii) &#30446;&#26631;&#23548;&#21521;&#25506;&#32034;&#65292;&#21644;iii) &#36880;&#27493;&#35843;&#25972;&#39118;&#26684;&#30340;&#37325;&#26032;&#35268;&#21010;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Safely exploring environments with a-priori unknown constraints is a fundamental challenge that restricts the autonomy of robots. While safety is paramount, guarantees on sufficient exploration are also crucial for ensuring autonomous task completion. To address these challenges, we propose a novel safe guaranteed exploration framework using optimal control, which achieves first-of-its-kind results: guaranteed exploration for non-linear systems with finite time sample complexity bounds, while being provably safe with arbitrarily high probability. The framework is general and applicable to many real-world scenarios with complex non-linear dynamics and unknown domains. Based on this framework we propose an efficient algorithm, SageMPC, SAfe Guaranteed Exploration using Model Predictive Control. SageMPC improves efficiency by incorporating three techniques: i) exploiting a Lipschitz bound, ii) goal-directed exploration, and iii) receding horizon style re-planning, all while maintaining th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27491;&#24120;&#32467;&#26500;&#35268;&#33539;&#21270;&#26041;&#27861;&#65292;&#23454;&#29616;&#24320;&#25918;&#22270;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#23545;&#26410;&#30693;&#24322;&#24120;&#30340;&#24191;&#20041;&#26816;&#27979;&#33021;&#21147;</title><link>https://arxiv.org/abs/2311.06835</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#24120;&#32467;&#26500;&#35268;&#33539;&#21270;&#23454;&#29616;&#24320;&#25918;&#22270;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Open-Set Graph Anomaly Detection via Normal Structure Regularisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.06835
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27491;&#24120;&#32467;&#26500;&#35268;&#33539;&#21270;&#26041;&#27861;&#65292;&#23454;&#29616;&#24320;&#25918;&#22270;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#23545;&#26410;&#30693;&#24322;&#24120;&#30340;&#24191;&#20041;&#26816;&#27979;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#22270;&#24322;&#24120;&#26816;&#27979;&#65288;GAD&#65289;&#20219;&#21153;&#65292;&#21363;&#24320;&#25918;&#24335;GAD&#65292;&#26088;&#22312;&#20351;&#29992;&#23569;&#37327;&#26631;&#35760;&#30340;&#35757;&#32451;&#27491;&#24120;&#33410;&#28857;&#21644;&#24322;&#24120;&#33410;&#28857;&#65288;&#31216;&#20026;&#24050;&#30693;&#24322;&#24120;&#65289;&#26469;&#26816;&#27979;&#24322;&#24120;&#33410;&#28857;&#65292;&#36825;&#20123;&#33410;&#28857;&#26080;&#27861;&#23637;&#31034;&#25152;&#26377;&#21487;&#33021;&#30340;&#25512;&#29702;&#26102;&#24322;&#24120;&#12290;&#24050;&#26631;&#35760;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#20026;GAD&#27169;&#22411;&#25552;&#20379;&#20102;&#20851;&#38190;&#30340;&#24322;&#24120;&#20808;&#39564;&#30693;&#35782;&#65292;&#21487;&#22823;&#22823;&#38477;&#20302;&#26816;&#27979;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#26041;&#27861;&#24448;&#24448;&#36807;&#20998;&#24378;&#35843;&#25311;&#21512;&#24050;&#30693;&#24322;&#24120;&#65292;&#23548;&#33268;&#23545;&#26410;&#30693;&#24322;&#24120;&#65288;&#21363;&#26410;&#34987;&#26631;&#35760;&#30340;&#24322;&#24120;&#33410;&#28857;&#65289;&#30340;&#24369;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#34987;&#24341;&#20837;&#20197;&#22788;&#29702;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#65292;&#26410;&#33021;&#26377;&#25928;&#25429;&#25417;GAD&#30340;&#37325;&#35201;&#38750;&#27431;&#20960;&#37324;&#24503;&#29305;&#24449;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24320;&#25918;&#24335;GAD&#26041;&#27861;&#65292;&#21363;&#27491;&#24120;&#32467;&#26500;&#35268;&#33539;&#21270;&#65288;NSReg&#65289;&#65292;&#20197;&#23454;&#29616;&#23545;&#26410;&#30693;&#24322;&#24120;&#30340;&#24191;&#20041;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.06835v2 Announce Type: replace-cross  Abstract: This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to detect anomalous nodes using a small number of labelled training normal and anomaly nodes (known as seen anomalies) that cannot illustrate all possible inference-time abnormalities. The availability of that labelled data provides crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current methods tend to over-emphasise fitting the seen anomalies, leading to a weak generalisation ability to detect unseen anomalies, i.e., those that are not illustrated by the labelled anomaly nodes. Further, they were introduced to handle Euclidean data, failing to effectively capture important non-Euclidean features for GAD. In this work, we propose a novel open-set GAD approach, namely Normal Structure Regularisation (NSReg), to achieve generalised detection ability to unseen 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;Tanimoto&#26680;&#20844;&#24335;&#65292;&#20801;&#35768;&#34913;&#37327;&#20219;&#24847;&#23454;&#20540;&#20989;&#25968;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20809;&#28369;&#36924;&#36817;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2007.05943</link><description>&lt;p&gt;
&#23558;Tanimoto&#31867;&#22411;&#26680;&#27867;&#21270;&#21040;&#23454;&#20540;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
On the generalization of Tanimoto-type kernels to real valued functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.05943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;Tanimoto&#26680;&#20844;&#24335;&#65292;&#20801;&#35768;&#34913;&#37327;&#20219;&#24847;&#23454;&#20540;&#20989;&#25968;&#30340;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20809;&#28369;&#36924;&#36817;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Tanimoto&#26680;&#65288;Jaccard&#25351;&#25968;&#65289;&#26159;&#25551;&#36848;&#20108;&#20540;&#23646;&#24615;&#38598;&#30456;&#20284;&#24615;&#30340;&#30693;&#21517;&#24037;&#20855;&#12290;&#24050;&#23558;&#20854;&#25193;&#23637;&#21040;&#23646;&#24615;&#20026;&#38750;&#36127;&#23454;&#25968;&#20540;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;Tanimoto&#26680;&#20844;&#24335;&#65292;&#20801;&#35768;&#34913;&#37327;&#20219;&#24847;&#23454;&#20540;&#20989;&#25968;&#30340;&#30456;&#20284;&#24615;&#12290;&#36890;&#36807;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;&#30340;&#38598;&#21512;&#32479;&#19968;&#23646;&#24615;&#34920;&#31034;&#26469;&#26500;&#24314;&#27492;&#25193;&#23637;&#12290;&#22312;&#25512;&#23548;&#26680;&#30340;&#19968;&#33324;&#24418;&#24335;&#21518;&#65292;&#20174;&#26680;&#20989;&#25968;&#20013;&#25552;&#21462;&#20102;&#26174;&#24335;&#29305;&#24449;&#34920;&#31034;&#65292;&#24182;&#23637;&#31034;&#20102;&#23558;&#19968;&#33324;&#26680;&#21253;&#21547;&#21040;Tanimoto&#26680;&#20013;&#30340;&#31616;&#21333;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#26680;&#20063;&#34920;&#31034;&#20026;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#30340;&#21830;&#65292;&#24182;&#25552;&#20379;&#20102;&#20809;&#28369;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.05943v2 Announce Type: replace  Abstract: The Tanimoto kernel (Jaccard index) is a well known tool to describe the similarity between sets of binary attributes. It has been extended to the case when the attributes are nonnegative real values. This paper introduces a more general Tanimoto kernel formulation which allows to measure the similarity of arbitrary real-valued functions. This extension is constructed by unifying the representation of the attributes via properly chosen sets. After deriving the general form of the kernel, explicit feature representation is extracted from the kernel function, and a simply way of including general kernels into the Tanimoto kernel is shown. Finally, the kernel is also expressed as a quotient of piecewise linear functions, and a smooth approximation is provided.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03756</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#36866;&#24212;&#24615;&#23454;&#39564;&#35774;&#35745;&#19982;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning. (arXiv:2401.03756v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#26159;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#20219;&#21153;&#20316;&#20026;&#19968;&#20010;&#24102;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification, BAI&#65289;&#38382;&#39064;&#26469;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#32473;&#23450;&#22810;&#20010;&#27835;&#30103;&#33218;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#35266;&#23519;&#19968;&#20010;&#21051;&#30011;&#23454;&#39564;&#21333;&#20301;&#30340;&#19978;&#19979;&#25991;&#65288;&#21327;&#21464;&#37327;&#65289;&#65292;&#24182;&#23558;&#35813;&#21333;&#20301;&#20998;&#37197;&#32473;&#20854;&#20013;&#19968;&#20010;&#27835;&#30103;&#33218;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#20915;&#31574;&#32773;&#25512;&#33616;&#19968;&#20010;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#39044;&#35745;&#20135;&#29983;&#26368;&#39640;&#26399;&#26395;&#32467;&#26524;&#30340;&#27835;&#30103;&#33218;&#65288;&#26368;&#20339;&#27835;&#30103;&#33218;&#65289;&#12290;&#35813;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#65288;&#31574;&#30053;&#36951;&#25022;&#65289;&#26469;&#34913;&#37327;&#65292;&#35813;&#36951;&#25022;&#34920;&#31034;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#65292;&#26368;&#20339;&#27835;&#30103;&#33218;&#21644;&#25512;&#33616;&#27835;&#30103;&#33218;&#30340;&#26465;&#20214;&#26399;&#26395;&#32467;&#26524;&#20043;&#38388;&#30340;&#26368;&#22823;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#21021;&#22987;&#27493;&#39588;&#26159;&#25512;&#23548;&#26368;&#22351;&#24773;&#20917;&#19979;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36817;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#36824;&#26263;&#31034;&#30528;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#19968;&#20123;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individualized treatment recommendation is a crucial task in evidence-based decision-making. In this study, we formulate this task as a fixed-budget best arm identification (BAI) problem with contextual information. In this setting, we consider an adaptive experiment given multiple treatment arms. At each round, a decision-maker observes a context (covariate) that characterizes an experimental unit and assigns the unit to one of the treatment arms. At the end of the experiment, the decision-maker recommends a treatment arm estimated to yield the highest expected outcome conditioned on a context (best treatment arm). The effectiveness of this decision is measured in terms of the worst-case expected simple regret (policy regret), which represents the largest difference between the conditional expected outcomes of the best and recommended treatment arms given a context. Our initial step is to derive asymptotic lower bounds for the worst-case expected simple regret, which also implies idea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20462;&#25913;&#32479;&#35745;&#24615;&#27495;&#35270;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#30001;&#26426;&#22120;&#23398;&#20064;&#29983;&#25104;&#30340;&#21487;&#21512;&#21516;&#21270;&#20449;&#24565;&#65292;&#32473;&#30417;&#31649;&#32773;&#25552;&#20379;&#20102;&#19968;&#31181;&#36229;&#36807;&#32943;&#23450;&#34892;&#21160;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#35201;&#27714;&#20844;&#21496;&#36873;&#21462;&#19968;&#20010;&#24179;&#34913;&#19981;&#21516;&#32676;&#20307;&#30495;&#27491;&#38451;&#24615;&#29575;&#30340;&#20915;&#31574;&#31574;&#30053;&#65292;&#23454;&#29616;&#26426;&#20250;&#24179;&#31561;&#26469;&#28040;&#38500;&#32479;&#35745;&#24615;&#27495;&#35270;&#12290;</title><link>http://arxiv.org/abs/2310.04585</link><description>&lt;p&gt;
&#26426;&#20250;&#24179;&#31561;&#23545;&#32479;&#35745;&#24615;&#27495;&#35270;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Impact of Equal Opportunity on Statistical Discrimination. (arXiv:2310.04585v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04585
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20462;&#25913;&#32479;&#35745;&#24615;&#27495;&#35270;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#30001;&#26426;&#22120;&#23398;&#20064;&#29983;&#25104;&#30340;&#21487;&#21512;&#21516;&#21270;&#20449;&#24565;&#65292;&#32473;&#30417;&#31649;&#32773;&#25552;&#20379;&#20102;&#19968;&#31181;&#36229;&#36807;&#32943;&#23450;&#34892;&#21160;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#35201;&#27714;&#20844;&#21496;&#36873;&#21462;&#19968;&#20010;&#24179;&#34913;&#19981;&#21516;&#32676;&#20307;&#30495;&#27491;&#38451;&#24615;&#29575;&#30340;&#20915;&#31574;&#31574;&#30053;&#65292;&#23454;&#29616;&#26426;&#20250;&#24179;&#31561;&#26469;&#28040;&#38500;&#32479;&#35745;&#24615;&#27495;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20462;&#25913;&#20102;Coate&#21644;Loury&#65288;1993&#65289;&#30340;&#32463;&#20856;&#32479;&#35745;&#24615;&#27495;&#35270;&#27169;&#22411;&#65292;&#20551;&#35774;&#20844;&#21496;&#23545;&#20010;&#20307;&#26410;&#35266;&#23519;&#21040;&#30340;&#31867;&#21035;&#30340;&#20449;&#24565;&#26159;&#30001;&#26426;&#22120;&#23398;&#20064;&#29983;&#25104;&#30340;&#65292;&#22240;&#27492;&#26159;&#21487;&#21512;&#21516;&#21270;&#30340;&#12290;&#36825;&#25193;&#23637;&#20102;&#30417;&#31649;&#32773;&#30340;&#24037;&#20855;&#31665;&#65292;&#36229;&#20986;&#20102;&#20687;&#32943;&#23450;&#34892;&#21160;&#36825;&#26679;&#30340;&#26080;&#20449;&#24565;&#35268;&#23450;&#12290;&#21487;&#21512;&#21516;&#21270;&#30340;&#20449;&#24565;&#20351;&#24471;&#35201;&#27714;&#20844;&#21496;&#36873;&#25321;&#19968;&#20010;&#20915;&#31574;&#31574;&#30053;&#65292;&#20351;&#24471;&#19981;&#21516;&#32676;&#20307;&#20043;&#38388;&#30340;&#30495;&#27491;&#38451;&#24615;&#29575;&#30456;&#31561;&#65288;&#31639;&#27861;&#20844;&#24179;&#25991;&#29486;&#20013;&#25152;&#31216;&#30340;&#26426;&#20250;&#24179;&#31561;&#65289;&#25104;&#20026;&#21487;&#33021;&#12290;&#23613;&#31649;&#32943;&#23450;&#34892;&#21160;&#19981;&#19968;&#23450;&#33021;&#28040;&#38500;&#32479;&#35745;&#24615;&#27495;&#35270;&#65292;&#20294;&#26412;&#25991;&#34920;&#26126;&#23454;&#26045;&#26426;&#20250;&#24179;&#31561;&#21487;&#20197;&#20570;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
I modify the canonical statistical discrimination model of Coate and Loury (1993) by assuming the firm's belief about an individual's unobserved class is machine learning-generated and, therefore, contractible. This expands the toolkit of a regulator beyond belief-free regulations like affirmative action. Contractible beliefs make it feasible to require the firm to select a decision policy that equalizes true positive rates across groups -- what the algorithmic fairness literature calls equal opportunity. While affirmative action does not necessarily end statistical discrimination, I show that imposing equal opportunity does.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#32454;&#32990;&#31354;&#38388;&#26469;&#22686;&#24378;&#36229;&#22270;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#24320;&#21457;&#20102;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#30340;&#32454;&#32990;&#36229;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#65292;&#20026;&#26377;&#25928;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#32467;&#26500;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2309.17116</link><description>&lt;p&gt;
Sheaf Hypergraph Networks. (arXiv:2309.17116v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Sheaf Hypergraph Networks. (arXiv:2309.17116v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17116
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#32454;&#32990;&#31354;&#38388;&#26469;&#22686;&#24378;&#36229;&#22270;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#24320;&#21457;&#20102;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#30340;&#32454;&#32990;&#36229;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#65292;&#20026;&#26377;&#25928;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#32467;&#26500;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#38454;&#20851;&#31995;&#22312;&#33258;&#28982;&#30028;&#20013;&#21313;&#20998;&#26222;&#36941;&#65292;&#35768;&#22810;&#29616;&#35937;&#28041;&#21450;&#22797;&#26434;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#36229;&#20986;&#20102;&#31616;&#21333;&#30340;&#20004;&#20004;&#36830;&#25509;&#12290;&#22240;&#27492;&#65292;&#25552;&#21319;&#39640;&#38454;&#22788;&#29702;&#33021;&#21147;&#21487;&#20197;&#21152;&#36895;&#21508;&#20010;&#38656;&#35201;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#39046;&#22495;&#30340;&#21457;&#23637;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#36229;&#22270;&#26469;&#34920;&#31034;&#36825;&#20123;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#32454;&#32990;&#31354;&#38388;&#23545;&#36229;&#22270;&#36827;&#34892;&#22686;&#24378;&#65292;&#36825;&#26159;&#19968;&#31181;&#25968;&#23398;&#26500;&#36896;&#65292;&#22312;&#32500;&#25345;&#23616;&#37096;&#39640;&#38454;&#36830;&#36890;&#24615;&#30340;&#21516;&#26102;&#20026;&#20256;&#32479;&#36229;&#22270;&#28155;&#21152;&#39069;&#22806;&#30340;&#32467;&#26500;&#12290;&#21463;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20998;&#21035;&#24320;&#21457;&#20102;&#20004;&#31181;&#29420;&#29305;&#30340;&#32454;&#32990;&#36229;&#22270;&#25289;&#26222;&#25289;&#26031;&#30340;&#24418;&#24335;&#65306;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#23558;&#32454;&#32990;&#31354;&#38388;&#24341;&#20837;&#36229;&#22270;&#25289;&#26222;&#25289;&#26031;&#27604;&#26631;&#20934;&#30340;&#36229;&#22270;&#25193;&#25955;&#25552;&#20379;&#20102;&#26356;&#23500;&#26377;&#34920;&#29616;&#21147;&#30340;&#24402;&#32435;&#20559;&#35265;&#65292;&#20026;&#26377;&#25928;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#32467;&#26500;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;...
&lt;/p&gt;
&lt;p&gt;
Higher-order relations are widespread in nature, with numerous phenomena involving complex interactions that extend beyond simple pairwise connections. As a result, advancements in higher-order processing can accelerate the growth of various fields requiring structured data. Current approaches typically represent these interactions using hypergraphs. We enhance this representation by introducing cellular sheaves for hypergraphs, a mathematical construction that adds extra structure to the conventional hypergraph while maintaining their local, higherorder connectivity. Drawing inspiration from existing Laplacians in the literature, we develop two unique formulations of sheaf hypergraph Laplacians: linear and non-linear. Our theoretical analysis demonstrates that incorporating sheaves into the hypergraph Laplacian provides a more expressive inductive bias than standard hypergraph diffusion, creating a powerful instrument for effectively modelling complex data structures. We employ these 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#32454;&#21270;&#19982;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#20219;&#21153;&#30340;&#36129;&#29486;&#20998;&#37197;&#22870;&#21169;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;LFP&#21462;&#24471;&#20102;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12053</link><description>&lt;p&gt;
&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Layer-wise Feedback Propagation. (arXiv:2308.12053v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#32454;&#21270;&#19982;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#20219;&#21153;&#30340;&#36129;&#29486;&#20998;&#37197;&#22870;&#21169;&#65292;&#35813;&#26041;&#27861;&#20811;&#26381;&#20102;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;LFP&#21462;&#24471;&#20102;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#23618;&#32423;&#21453;&#39304;&#20256;&#25773;&#65288;LFP&#65289;&#8221;&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#20307;&#32780;&#35328;&#26159;&#23618;&#32423;&#30456;&#20851;&#24615;&#20256;&#25773;&#65288;LRP&#65289;&#65292;&#26681;&#25454;&#27599;&#20010;&#36830;&#25509;&#23545;&#35299;&#20915;&#32473;&#23450;&#20219;&#21153;&#30340;&#36129;&#29486;&#29420;&#31435;&#20998;&#37197;&#22870;&#21169;&#12290;&#36825;&#19982;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#19981;&#21516;&#65292;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26159;&#26397;&#21521;&#20272;&#35745;&#30340;&#25439;&#22833;&#26368;&#23567;&#20540;&#26356;&#26032;&#21442;&#25968;&#12290;LFP&#22312;&#27169;&#22411;&#20013;&#20256;&#25773;&#22870;&#21169;&#20449;&#21495;&#65292;&#32780;&#26080;&#38656;&#26799;&#24230;&#35745;&#31639;&#12290;&#23427;&#22686;&#24378;&#25509;&#25910;&#21040;&#27491;&#21453;&#39304;&#30340;&#32467;&#26500;&#65292;&#21516;&#26102;&#38477;&#20302;&#25509;&#25910;&#21040;&#36127;&#21453;&#39304;&#30340;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#30340;&#35282;&#24230;&#35777;&#26126;&#20102;LFP&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;LFP&#20811;&#26381;&#20102;&#26799;&#24230;&#26041;&#27861;&#30340;&#26576;&#20123;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#23545;&#26377;&#24847;&#20041;&#30340;&#23548;&#25968;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;LFP&#22914;&#20309;&#35299;&#20915;&#26799;&#24230;&#26041;&#27861;&#30456;&#20851;&#38382;&#39064;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present Layer-wise Feedback Propagation (LFP), a novel training approach for neural-network-like predictors that utilizes explainability, specifically Layer-wise Relevance Propagation(LRP), to assign rewards to individual connections based on their respective contributions to solving a given task. This differs from traditional gradient descent, which updates parameters towards anestimated loss minimum. LFP distributes a reward signal throughout the model without the need for gradient computations. It then strengthens structures that receive positive feedback while reducingthe influence of structures that receive negative feedback. We establish the convergence of LFP theoretically and empirically, and demonstrate its effectiveness in achieving comparable performance to gradient descent on various models and datasets. Notably, LFP overcomes certain limitations associated with gradient-based methods, such as reliance on meaningful derivatives. We further investigate how 
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#25193;&#23637;&#20102;split conformal prediction&#25216;&#26415;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#20316;&#20026;&#20005;&#37325;&#24615;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#20102;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2307.13124</link><description>&lt;p&gt;
&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction for frequency-severity modeling. (arXiv:2307.13124v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13124
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#25193;&#23637;&#20102;split conformal prediction&#25216;&#26415;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#20316;&#20026;&#20005;&#37325;&#24615;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#20102;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#23558;&#20998;&#21106;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#25193;&#23637;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;&#24403;&#22522;&#30784;&#20005;&#37325;&#24615;&#27169;&#22411;&#26159;&#38543;&#26426;&#26862;&#26519;&#26102;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#20004;&#38454;&#27573;&#20998;&#21106;&#31526;&#21512;&#24615;&#39044;&#27979;&#36807;&#31243;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a nonparametric model-agnostic framework for building prediction intervals of insurance claims, with finite sample statistical guarantees, extending the technique of split conformal prediction to the domain of two-stage frequency-severity modeling. The effectiveness of the framework is showcased with simulated and real datasets. When the underlying severity model is a random forest, we extend the two-stage split conformal prediction procedure, showing how the out-of-bag mechanism can be leveraged to eliminate the need for a calibration set and to enable the production of prediction intervals with adaptive width.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;AI&#23398;&#26415;&#30028;&#30340;78K&#30740;&#31350;&#20154;&#21592;&#30340;&#20998;&#26512;&#65292;&#30740;&#31350;&#21457;&#29616;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#20855;&#26377;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#65307;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#12290;&#25105;&#20204;&#40723;&#21169;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14597</link><description>&lt;p&gt;
&#22905;&#20204;&#30340;&#22768;&#38899;&#65306;&#20998;&#26512;&#20154;&#24037;&#26234;&#33021;&#20986;&#29256;&#39046;&#22495;&#30340;&#24615;&#21035;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Voices of Her: Analyzing Gender Differences in the AI Publication World. (arXiv:2305.14597v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14597
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;AI&#23398;&#26415;&#30028;&#30340;78K&#30740;&#31350;&#20154;&#21592;&#30340;&#20998;&#26512;&#65292;&#30740;&#31350;&#21457;&#29616;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#20855;&#26377;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#65307;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#12290;&#25105;&#20204;&#40723;&#21169;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#20998;&#26512;&#20102;&#23398;&#26415;&#30028;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#65292;&#20294;&#26159;&#25105;&#20204;&#20173;&#28982;&#32570;&#20047;&#19968;&#20010;&#20840;&#38754;&#30340;&#20154;&#24037;&#26234;&#33021;&#31038;&#21306;&#24615;&#21035;&#24046;&#24322;&#30340;&#20998;&#26512;&#65292;&#28085;&#30422;&#21508;&#31181;&#20027;&#39064;&#21644;&#19981;&#21516;&#30340;&#21457;&#23637;&#36235;&#21183;&#12290;&#25105;&#20204;&#20351;&#29992;AI Scholar&#25968;&#25454;&#38598;&#20013;&#30340;78K&#20301;AI&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#24615;&#21035;&#24046;&#24322;&#65306;&#65288;1&#65289;&#34429;&#28982;&#22899;&#24615;&#30740;&#31350;&#20154;&#21592;&#30340;&#24635;&#24341;&#29992;&#27425;&#25968;&#27604;&#30007;&#24615;&#23569;&#65292;&#20294;&#36825;&#31181;&#24341;&#29992;&#24046;&#24322;&#24182;&#19981;&#36866;&#29992;&#20110;&#25152;&#26377;&#23398;&#26415;&#24180;&#40836;&#32452;&#65307;&#65288;2&#65289;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#65307;&#65288;3&#65289;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#26174;&#31034;&#20986;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20026;&#25105;&#20204;&#30340;AI&#31038;&#21306;&#29616;&#26377;&#30340;&#20154;&#21475;&#32479;&#35745;&#36235;&#21183;&#25552;&#20379;&#20102;&#19968;&#20010;&#31383;&#21475;&#65292;&#24182;&#40723;&#21169;&#22312;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#21487;&#22312;https://github.com/causalNLP/ai-scholar-gender&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
While several previous studies have analyzed gender bias in research, we are still missing a comprehensive analysis of gender differences in the AI community, covering diverse topics and different development trends. Using the AI Scholar dataset of 78K researchers in the field of AI, we identify several gender differences: (1) Although female researchers tend to have fewer overall citations than males, this citation difference does not hold for all academic-age groups; (2) There exist large gender homophily in co-authorship on AI papers; (3) Female first-authored papers show distinct linguistic styles, such as longer text, more positive emotion words, and more catchy titles than male first-authored papers. Our analysis provides a window into the current demographic trends in our AI community, and encourages more gender equality and diversity in the future. Our code and data are at https://github.com/causalNLP/ai-scholar-gender.
&lt;/p&gt;</description></item></channel></rss>