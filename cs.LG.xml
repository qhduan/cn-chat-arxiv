<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>RealKIE&#25552;&#20379;&#20102;&#20116;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20225;&#19994;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;&#65292;&#20026;&#25237;&#36164;&#20998;&#26512;&#21644;&#27861;&#24459;&#25968;&#25454;&#22788;&#29702;&#31561;&#20219;&#21153;&#25552;&#20379;&#20102;&#29616;&#23454;&#30340;&#27979;&#35797;&#22522;&#22320;&#65292;&#24182;&#20026;NLP&#27169;&#22411;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2403.20101</link><description>&lt;p&gt;
RealKIE: &#20116;&#20010;&#26032;&#39062;&#30340;&#20225;&#19994;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
RealKIE: Five Novel Datasets for Enterprise Key Information Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20101
&lt;/p&gt;
&lt;p&gt;
RealKIE&#25552;&#20379;&#20102;&#20116;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20225;&#19994;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;&#65292;&#20026;&#25237;&#36164;&#20998;&#26512;&#21644;&#27861;&#24459;&#25968;&#25454;&#22788;&#29702;&#31561;&#20219;&#21153;&#25552;&#20379;&#20102;&#29616;&#23454;&#30340;&#27979;&#35797;&#22522;&#22320;&#65292;&#24182;&#20026;NLP&#27169;&#22411;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;RealKIE&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#25512;&#21160;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#26041;&#27861;&#21457;&#23637;&#30340;&#20116;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#22522;&#20934;&#65292;&#37325;&#28857;&#26159;&#20225;&#19994;&#24212;&#29992;&#12290;&#36825;&#20123;&#25968;&#25454;&#38598;&#21253;&#25324;&#32654;&#22269;SEC S1&#25991;&#20214;&#12289;&#32654;&#22269;&#20445;&#23494;&#21327;&#35758;&#12289;&#33521;&#22269;&#24904;&#21892;&#25253;&#21578;&#12289;FCC&#21457;&#31080;&#21644;&#36164;&#28304;&#21512;&#21516;&#31561;&#21508;&#31181;&#31867;&#22411;&#30340;&#25991;&#26723;&#12290;&#27599;&#20010;&#25968;&#25454;&#38598;&#37117;&#20855;&#26377;&#29420;&#29305;&#30340;&#25361;&#25112;&#65306;&#25991;&#26412;&#24207;&#21015;&#21270;&#19981;&#20339;&#12289;&#38271;&#25991;&#26723;&#20013;&#31232;&#30095;&#30340;&#27880;&#37322;&#21644;&#22797;&#26434;&#30340;&#34920;&#26684;&#24067;&#23616;&#12290;&#36825;&#20123;&#25968;&#25454;&#38598;&#20026;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#20219;&#21153;&#65288;&#22914;&#25237;&#36164;&#20998;&#26512;&#21644;&#27861;&#24459;&#25968;&#25454;&#22788;&#29702;&#65289;&#25552;&#20379;&#20102;&#19968;&#20010;&#29616;&#23454;&#30340;&#27979;&#35797;&#22522;&#22320;&#12290;&#38500;&#20102;&#20171;&#32461;&#36825;&#20123;&#25968;&#25454;&#38598;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23545;&#27880;&#37322;&#36807;&#31243;&#12289;&#25991;&#26723;&#22788;&#29702;&#25216;&#26415;&#21644;&#22522;&#32447;&#24314;&#27169;&#26041;&#27861;&#30340;&#28145;&#20837;&#25551;&#36848;&#12290;&#36825;&#19968;&#36129;&#29486;&#20419;&#36827;&#20102;&#33021;&#22815;&#22788;&#29702;&#23454;&#38469;&#25361;&#25112;&#30340;NLP&#27169;&#22411;&#30340;&#21457;&#23637;&#65292;&#24182;&#25903;&#25345;&#36827;&#19968;&#27493;&#30740;&#31350;&#21487;&#24212;&#29992;&#20110;&#24037;&#19994;&#30340;&#20449;&#24687;&#25552;&#21462;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20101v1 Announce Type: new  Abstract: We introduce RealKIE, a benchmark of five challenging datasets aimed at advancing key information extraction methods, with an emphasis on enterprise applications. The datasets include a diverse range of documents including SEC S1 Filings, US Non-disclosure Agreements, UK Charity Reports, FCC Invoices, and Resource Contracts. Each presents unique challenges: poor text serialization, sparse annotations in long documents, and complex tabular layouts. These datasets provide a realistic testing ground for key information extraction tasks like investment analysis and legal data processing.   In addition to presenting these datasets, we offer an in-depth description of the annotation process, document processing techniques, and baseline modeling approaches. This contribution facilitates the development of NLP models capable of handling practical challenges and supports further research into information extraction technologies applicable to indu
&lt;/p&gt;</description></item><item><title>PolyNet&#36890;&#36807;&#23398;&#20064;&#20114;&#34917;&#35299;&#20915;&#31574;&#30053;&#26469;&#25913;&#21892;&#35299;&#31354;&#38388;&#25506;&#32034;&#65292;&#36991;&#20813;&#20102;&#20154;&#20026;&#35268;&#21017;&#23548;&#33268;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.14048</link><description>&lt;p&gt;
PolyNet&#65306;&#23398;&#20064;&#31070;&#32463;&#32452;&#21512;&#20248;&#21270;&#30340;&#22810;&#26679;&#21270;&#35299;&#20915;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14048
&lt;/p&gt;
&lt;p&gt;
PolyNet&#36890;&#36807;&#23398;&#20064;&#20114;&#34917;&#35299;&#20915;&#31574;&#30053;&#26469;&#25913;&#21892;&#35299;&#31354;&#38388;&#25506;&#32034;&#65292;&#36991;&#20813;&#20102;&#20154;&#20026;&#35268;&#21017;&#23548;&#33268;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#26500;&#24314;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#65292;&#36805;&#36895;&#25509;&#36817;&#20154;&#31867;&#35774;&#35745;&#30340;&#31639;&#27861;&#24615;&#33021;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#32553;&#23567;&#24046;&#36317;&#65292;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#22312;&#25628;&#32034;&#36807;&#31243;&#20013;&#24517;&#39035;&#39640;&#25928;&#22320;&#25506;&#32034;&#35299;&#31354;&#38388;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#36890;&#36807;&#24378;&#21046;&#23454;&#26045;&#22810;&#26679;&#21270;&#35299;&#29983;&#25104;&#26469;&#20154;&#20026;&#22686;&#21152;&#25506;&#32034;&#65292;&#28982;&#32780;&#65292;&#36825;&#20123;&#35268;&#21017;&#21487;&#33021;&#25439;&#23475;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#65292;&#24182;&#19988;&#38590;&#20197;&#20026;&#26356;&#22797;&#26434;&#30340;&#38382;&#39064;&#35774;&#35745;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;PolyNet&#65292;&#19968;&#31181;&#36890;&#36807;&#23398;&#20064;&#20114;&#34917;&#35299;&#20915;&#31574;&#30053;&#26469;&#25913;&#21892;&#35299;&#31354;&#38388;&#25506;&#32034;&#30340;&#26041;&#27861;&#12290;&#19982;&#20854;&#20182;&#20316;&#21697;&#19981;&#21516;&#65292;PolyNet&#20165;&#20351;&#29992;&#21333;&#20010;&#35299;&#30721;&#22120;&#65292;&#24182;&#19988;&#35757;&#32451;&#22270;&#24335;&#19981;&#36890;&#36807;&#20154;&#20026;&#35268;&#21017;&#24378;&#21046;&#23454;&#26045;&#22810;&#26679;&#21270;&#35299;&#29983;&#25104;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#19978;&#35780;&#20272;PolyNet&#65292;&#24182;&#35266;&#23519;&#21040;&#38544;&#24335;&#22810;&#26679;&#24615;&#26426;&#21046;&#20801;&#35768;P
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14048v1 Announce Type: cross  Abstract: Reinforcement learning-based methods for constructing solutions to combinatorial optimization problems are rapidly approaching the performance of human-designed algorithms. To further narrow the gap, learning-based approaches must efficiently explore the solution space during the search process. Recent approaches artificially increase exploration by enforcing diverse solution generation through handcrafted rules, however, these rules can impair solution quality and are difficult to design for more complex problems. In this paper, we introduce PolyNet, an approach for improving exploration of the solution space by learning complementary solution strategies. In contrast to other works, PolyNet uses only a single-decoder and a training schema that does not enforce diverse solution generation through handcrafted rules. We evaluate PolyNet on four combinatorial optimization problems and observe that the implicit diversity mechanism allows P
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#26041;&#27861;&#31995;&#32479;&#22320;&#27979;&#35797;&#20102;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#20197;&#21450;&#35757;&#32451;&#32467;&#26463;&#26102;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#20851;&#32852;&#12290;</title><link>https://arxiv.org/abs/2402.06674</link><description>&lt;p&gt;
&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#30340;&#23454;&#38469;&#25104;&#21592;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Understanding Practical Membership Privacy of Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06674
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#26041;&#27861;&#31995;&#32479;&#22320;&#27979;&#35797;&#20102;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#20197;&#21450;&#35757;&#32451;&#32467;&#26463;&#26102;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24212;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#65288;MIA&#65289;&#26469;&#31995;&#32479;&#22320;&#27979;&#35797;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#12290;&#25105;&#20204;&#30340;&#37325;&#28857;&#26159;&#29702;&#35299;&#20351;&#25968;&#25454;&#38598;&#21644;&#26679;&#26412;&#23481;&#26131;&#21463;&#21040;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#29305;&#24615;&#12290;&#22312;&#25968;&#25454;&#38598;&#29305;&#24615;&#26041;&#38754;&#65292;&#25105;&#20204;&#21457;&#29616;&#25968;&#25454;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#24378;&#28872;&#30340;&#24130;&#24459;&#20381;&#36182;&#20851;&#31995;&#65292;&#36825;&#26159;&#20197;&#25915;&#20987;&#30340;&#30495;&#38451;&#24615;&#29575;&#65288;&#22312;&#20302;&#20551;&#38451;&#24615;&#29575;&#19979;&#27979;&#37327;&#65289;&#26469;&#34913;&#37327;&#30340;&#12290;&#23545;&#20110;&#20010;&#21035;&#26679;&#26412;&#32780;&#35328;&#65292;&#22312;&#35757;&#32451;&#32467;&#26463;&#26102;&#20135;&#29983;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We apply a state-of-the-art membership inference attack (MIA) to systematically test the practical privacy vulnerability of fine-tuning large image classification models.We focus on understanding the properties of data sets and samples that make them vulnerable to membership inference. In terms of data set properties, we find a strong power law dependence between the number of examples per class in the data and the MIA vulnerability, as measured by true positive rate of the attack at a low false positive rate. For an individual sample, large gradients at the end of training are strongly correlated with MIA vulnerability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#36824;&#27604;&#36739;&#20102;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#21644;&#20256;&#32479;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19982;&#27531;&#24046;&#36830;&#25509;&#30340;&#26550;&#26500;&#12290;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#20915;&#31574;&#26641;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#32780;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#22312;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#24182;&#27809;&#26377;&#36229;&#36807;&#20256;&#32479;MLP&#26550;&#26500;&#30340;&#31616;&#21270;&#21464;&#20307;&#12290;</title><link>https://arxiv.org/abs/2402.03970</link><description>&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#65306;&#27880;&#24847;&#21147;&#26159;&#21807;&#19968;&#38656;&#35201;&#30340;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Tabular Data: Is Attention All You Need?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#36824;&#27604;&#36739;&#20102;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#21644;&#20256;&#32479;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19982;&#27531;&#24046;&#36830;&#25509;&#30340;&#26550;&#26500;&#12290;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#20915;&#31574;&#26641;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#32780;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#22312;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#24182;&#27809;&#26377;&#36229;&#36807;&#20256;&#32479;MLP&#26550;&#26500;&#30340;&#31616;&#21270;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#24443;&#24213;&#25913;&#21464;&#20102;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#24182;&#22312;&#28041;&#21450;&#22270;&#20687;&#21644;&#25991;&#26412;&#25968;&#25454;&#30340;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#23601;&#12290;&#36951;&#25022;&#30340;&#26159;&#65292;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#22312;&#32467;&#26500;&#21270;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#20248;&#21183;&#23384;&#22312;&#30528;&#19981;&#19968;&#33268;&#30340;&#35777;&#25454;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#36824;&#27604;&#36739;&#20102;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#21644;&#20256;&#32479;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19982;&#27531;&#24046;&#36830;&#25509;&#30340;&#26550;&#26500;&#12290;&#19982;&#20043;&#21069;&#30340;&#30740;&#31350;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#23454;&#35777;&#21457;&#29616;&#34920;&#26126;&#31070;&#32463;&#32593;&#32476;&#22312;&#20915;&#31574;&#26641;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#22312;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#24182;&#27809;&#26377;&#36229;&#36807;&#20256;&#32479;MLP&#26550;&#26500;&#30340;&#31616;&#21270;&#21464;&#20307;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#24110;&#21161;&#30740;&#31350;&#21644;&#23454;&#36341;&#31038;&#21306;&#22312;&#26410;&#26469;&#30340;&#34920;&#26684;&#25968;&#25454;&#24212;&#29992;&#20013;&#20570;&#20986;&#26126;&#26234;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning has revolutionized the field of AI and led to remarkable achievements in applications involving image and text data. Unfortunately, there is inconclusive evidence on the merits of neural networks for structured tabular data. In this paper, we introduce a large-scale empirical study comparing neural networks against gradient-boosted decision trees on tabular data, but also transformer-based architectures against traditional multi-layer perceptrons (MLP) with residual connections. In contrast to prior work, our empirical findings indicate that neural networks are competitive against decision trees. Furthermore, we assess that transformer-based architectures do not outperform simpler variants of traditional MLP architectures on tabular datasets. As a result, this paper helps the research and practitioner communities make informed choices on deploying neural networks on future tabular data applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;Foundation&#27169;&#22411;&#38598;&#25104;&#32852;&#37030;&#23398;&#20064;&#20013;&#40065;&#26834;&#24615;&#12289;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30340;&#25361;&#25112;&#21644;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#24212;&#23545;&#31574;&#30053;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2402.01857</link><description>&lt;p&gt;
&#35780;&#20272;&#22522;&#20110;Foundation&#27169;&#22411;&#38598;&#25104;&#32852;&#37030;&#23398;&#20064;&#30340;&#40065;&#26834;&#24615;&#12289;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30340;&#31435;&#22330;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Assessing Robustness, Privacy, and Fairness in Federated Learning Integrated with Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;Foundation&#27169;&#22411;&#38598;&#25104;&#32852;&#37030;&#23398;&#20064;&#20013;&#40065;&#26834;&#24615;&#12289;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30340;&#25361;&#25112;&#21644;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#24212;&#23545;&#31574;&#30053;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#20998;&#25955;&#24335;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#22823;&#31361;&#30772;&#65292;&#20294;&#38754;&#20020;&#35832;&#22810;&#25361;&#25112;&#65292;&#22914;&#25968;&#25454;&#21487;&#29992;&#24615;&#26377;&#38480;&#21644;&#35745;&#31639;&#36164;&#28304;&#30340;&#21464;&#21270;&#24615;&#65292;&#36825;&#21487;&#33021;&#20250;&#38480;&#21046;&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;&#23558;Foundation&#27169;&#22411;&#65288;FM&#65289;&#38598;&#25104;&#21040;FL&#20013;&#65292;&#21487;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#25968;&#25454;&#22686;&#24378;&#22686;&#21152;&#25968;&#25454;&#20016;&#23500;&#24615;&#24182;&#20943;&#23569;&#35745;&#31639;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#38598;&#25104;&#24341;&#20837;&#20102;&#40065;&#26834;&#24615;&#12289;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#26041;&#38754;&#30340;&#26032;&#38382;&#39064;&#65292;&#22312;&#29616;&#26377;&#30740;&#31350;&#20013;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#35299;&#20915;&#12290;&#25105;&#20204;&#36890;&#36807;&#31995;&#32479;&#35780;&#20272;FM-FL&#38598;&#25104;&#23545;&#36825;&#20123;&#26041;&#38754;&#30340;&#24433;&#21709;&#65292;&#36827;&#34892;&#20102;&#21021;&#27493;&#35843;&#26597;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20854;&#20013;&#30340;&#26435;&#34913;&#21462;&#33293;&#65292;&#25581;&#31034;&#20102;&#35813;&#38598;&#25104;&#24341;&#20837;&#30340;&#23041;&#32961;&#21644;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#22871;&#29992;&#20110;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#26631;&#20934;&#21644;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#37492;&#23450;&#20102;&#21487;&#33021;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#19968;&#20123;&#21069;&#26223;&#26041;&#21521;&#21644;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL), while a breakthrough in decentralized machine learning, contends with significant challenges such as limited data availability and the variability of computational resources, which can stifle the performance and scalability of the models. The integration of Foundation Models (FMs) into FL presents a compelling solution to these issues, with the potential to enhance data richness and reduce computational demands through pre-training and data augmentation. However, this incorporation introduces novel issues in terms of robustness, privacy, and fairness, which have not been sufficiently addressed in the existing research. We make a preliminary investigation into this field by systematically evaluating the implications of FM-FL integration across these dimensions. We analyze the trade-offs involved, uncover the threats and issues introduced by this integration, and propose a set of criteria and strategies for navigating these challenges. Furthermore, we identify po
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LiNGAM-MMI&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22686;&#24378;LiNGAM&#27169;&#22411;&#20197;&#22788;&#29702;&#28151;&#28102;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;KL&#25955;&#24230;&#37327;&#21270;&#28151;&#28102;&#31243;&#24230;&#65292;&#24182;&#36890;&#36807;&#26368;&#30701;&#36335;&#24452;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#39640;&#25928;&#22320;&#30830;&#23450;&#21464;&#37327;&#39034;&#24207;&#65292;&#19981;&#35770;&#26159;&#21542;&#23384;&#22312;&#28151;&#28102;&#24773;&#20917;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LiNGAM-MMI&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#35782;&#21035;&#27491;&#30830;&#30340;&#21464;&#37327;&#39034;&#24207;&#12290;</title><link>http://arxiv.org/abs/2401.16661</link><description>&lt;p&gt;
&#20801;&#35768;&#28151;&#28102;&#30340;LiNGAM&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalization of LiNGAM that allows confounding. (arXiv:2401.16661v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16661
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LiNGAM-MMI&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22686;&#24378;LiNGAM&#27169;&#22411;&#20197;&#22788;&#29702;&#28151;&#28102;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;KL&#25955;&#24230;&#37327;&#21270;&#28151;&#28102;&#31243;&#24230;&#65292;&#24182;&#36890;&#36807;&#26368;&#30701;&#36335;&#24452;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#39640;&#25928;&#22320;&#30830;&#23450;&#21464;&#37327;&#39034;&#24207;&#65292;&#19981;&#35770;&#26159;&#21542;&#23384;&#22312;&#28151;&#28102;&#24773;&#20917;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LiNGAM-MMI&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#35782;&#21035;&#27491;&#30830;&#30340;&#21464;&#37327;&#39034;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LiNGAM&#20351;&#29992;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#26469;&#30830;&#23450;&#22240;&#26524;&#20851;&#31995;&#30340;&#21464;&#37327;&#39034;&#24207;&#65292;&#20294;&#22312;&#28151;&#28102;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#20808;&#21069;&#30340;&#26041;&#27861;&#22312;&#20445;&#25345;LiNGAM&#30340;&#22522;&#26412;&#32467;&#26500;&#30340;&#21516;&#26102;&#65292;&#35797;&#22270;&#35782;&#21035;&#21644;&#22788;&#29702;&#21463;&#28151;&#28102;&#24433;&#21709;&#30340;&#21464;&#37327;&#12290;&#32467;&#26524;&#26159;&#65292;&#19981;&#35770;&#26159;&#21542;&#23384;&#22312;&#28151;&#28102;&#65292;&#36825;&#20123;&#26041;&#27861;&#37117;&#38656;&#35201;&#22823;&#37327;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#24182;&#19988;&#19981;&#33021;&#30830;&#20445;&#26816;&#27979;&#21040;&#25152;&#26377;&#30340;&#28151;&#28102;&#31867;&#22411;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;LiNGAM-MMI&#23545;LiNGAM&#36827;&#34892;&#20102;&#22686;&#24378;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;KL&#25955;&#24230;&#37327;&#21270;&#28151;&#28102;&#31243;&#24230;&#65292;&#24182;&#23433;&#25490;&#21464;&#37327;&#20197;&#26368;&#23567;&#21270;&#20854;&#24433;&#21709;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#30701;&#36335;&#24452;&#38382;&#39064;&#30340;&#24418;&#24335;&#39640;&#25928;&#22320;&#23454;&#29616;&#20840;&#23616;&#26368;&#20248;&#30340;&#21464;&#37327;&#39034;&#24207;&#12290;&#22312;&#26080;&#28151;&#28102;&#30340;&#24773;&#20917;&#19979;&#65292;LiNGAM-MMI&#30340;&#22788;&#29702;&#25968;&#25454;&#25928;&#29575;&#19982;&#20256;&#32479;LiNGAM&#30456;&#24403;&#65292;&#21516;&#26102;&#26377;&#25928;&#22788;&#29702;&#28151;&#28102;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;LiNGAM-MMI&#26356;&#20934;&#30830;&#22320;&#30830;&#23450;&#20102;&#27491;&#30830;&#30340;&#21464;&#37327;&#39034;&#24207;...
&lt;/p&gt;
&lt;p&gt;
LiNGAM determines the variable order from cause to effect using additive noise models, but it faces challenges with confounding. Previous methods maintained LiNGAM's fundamental structure while trying to identify and address variables affected by confounding. As a result, these methods required significant computational resources regardless of the presence of confounding, and they did not ensure the detection of all confounding types. In contrast, this paper enhances LiNGAM by introducing LiNGAM-MMI, a method that quantifies the magnitude of confounding using KL divergence and arranges the variables to minimize its impact. This method efficiently achieves a globally optimal variable order through the shortest path problem formulation. LiNGAM-MMI processes data as efficiently as traditional LiNGAM in scenarios without confounding while effectively addressing confounding situations. Our experimental results suggest that LiNGAM-MMI more accurately determines the correct variable order, bo
&lt;/p&gt;</description></item><item><title>Sum-of-Parts&#27169;&#22411;&#36890;&#36807;&#26500;&#36896;&#20445;&#35777;&#29305;&#24449;&#32452;&#24402;&#22240;&#30340;&#24544;&#23454;&#24615;&#65292;&#23558;&#39044;&#27979;&#20998;&#35299;&#20026;&#21487;&#35299;&#37322;&#30340;&#20998;&#25968;&#20043;&#21644;&#65292;&#24110;&#21161;&#22825;&#20307;&#29289;&#29702;&#23398;&#23478;&#21457;&#29616;&#20102;&#20851;&#20110;&#26143;&#31995;&#24418;&#25104;&#30340;&#26032;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2310.16316</link><description>&lt;p&gt;
Sum-of-Parts&#27169;&#22411;&#65306;&#23545;&#29305;&#24449;&#32452;&#30340;&#24544;&#23454;&#24402;&#22240;
&lt;/p&gt;
&lt;p&gt;
Sum-of-Parts Models: Faithful Attributions for Groups of Features. (arXiv:2310.16316v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16316
&lt;/p&gt;
&lt;p&gt;
Sum-of-Parts&#27169;&#22411;&#36890;&#36807;&#26500;&#36896;&#20445;&#35777;&#29305;&#24449;&#32452;&#24402;&#22240;&#30340;&#24544;&#23454;&#24615;&#65292;&#23558;&#39044;&#27979;&#20998;&#35299;&#20026;&#21487;&#35299;&#37322;&#30340;&#20998;&#25968;&#20043;&#21644;&#65292;&#24110;&#21161;&#22825;&#20307;&#29289;&#29702;&#23398;&#23478;&#21457;&#29616;&#20102;&#20851;&#20110;&#26143;&#31995;&#24418;&#25104;&#30340;&#26032;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#37322;&#20934;&#30830;&#21453;&#26144;&#20102;&#20854;&#20915;&#31574;&#36807;&#31243;&#65292;&#21017;&#34987;&#35748;&#20026;&#26159;&#8220;&#24544;&#23454;&#8221;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#20363;&#22914;&#28145;&#24230;&#23398;&#20064;&#30340;&#29305;&#24449;&#24402;&#22240;&#31561;&#35299;&#37322;&#24182;&#19981;&#33021;&#20445;&#35777;&#24544;&#23454;&#65292;&#26377;&#21487;&#33021;&#20135;&#29983;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#35299;&#37322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;Sum-of-Parts&#65288;SOP&#65289;&#27169;&#22411;&#65292;&#23427;&#26159;&#19968;&#31867;&#27169;&#22411;&#65292;&#20854;&#39044;&#27979;&#20855;&#26377;&#36890;&#36807;&#26500;&#36896;&#20445;&#35777;&#24544;&#23454;&#30340;&#29305;&#24449;&#32452;&#24402;&#22240;&#12290;&#35813;&#27169;&#22411;&#23558;&#39044;&#27979;&#20998;&#35299;&#20026;&#21487;&#35299;&#37322;&#30340;&#20998;&#25968;&#20043;&#21644;&#65292;&#27599;&#20010;&#20998;&#25968;&#30452;&#25509;&#24402;&#22240;&#20110;&#19968;&#32452;&#31232;&#30095;&#29305;&#24449;&#12290;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#23545;SOP&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#22312;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#21033;&#29992;SOP&#25552;&#20379;&#30340;&#24544;&#23454;&#35299;&#37322;&#24110;&#21161;&#22825;&#20307;&#29289;&#29702;&#23398;&#23478;&#21457;&#29616;&#20102;&#20851;&#20110;&#26143;&#31995;&#24418;&#25104;&#30340;&#26032;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
An explanation of a machine learning model is considered "faithful" if it accurately reflects the model's decision-making process. However, explanations such as feature attributions for deep learning are not guaranteed to be faithful, and can produce potentially misleading interpretations. In this work, we develop Sum-of-Parts (SOP), a class of models whose predictions come with grouped feature attributions that are faithful-by-construction. This model decomposes a prediction into an interpretable sum of scores, each of which is directly attributable to a sparse group of features. We evaluate SOP on benchmarks with standard interpretability metrics, and in a case study, we use the faithful explanations from SOP to help astrophysicists discover new knowledge about galaxy formation.
&lt;/p&gt;</description></item><item><title>AgentBench&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#20316;&#20026;&#20195;&#29702;&#20154;&#30340;&#22810;&#32500;&#24230;&#22522;&#20934;&#65292;&#21457;&#29616;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#65292;&#21830;&#19994;LLMs&#22312;&#20805;&#24403;&#20195;&#29702;&#20154;&#26041;&#38754;&#34920;&#29616;&#24378;&#21170;&#65292;&#20294;&#19982;&#24320;&#28304;&#31454;&#20105;&#23545;&#25163;&#30456;&#27604;&#65292;&#23384;&#22312;&#26174;&#33879;&#24615;&#33021;&#24046;&#36317;&#12290;&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#22312;&#38271;&#26399;&#25512;&#29702;&#12289;&#20915;&#31574;&#21644;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#19978;&#30340;&#29942;&#39048;&#12290;</title><link>http://arxiv.org/abs/2308.03688</link><description>&lt;p&gt;
AgentBench: &#35780;&#20272;LLMs&#20316;&#20026;&#20195;&#29702;&#20154;
&lt;/p&gt;
&lt;p&gt;
AgentBench: Evaluating LLMs as Agents. (arXiv:2308.03688v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03688
&lt;/p&gt;
&lt;p&gt;
AgentBench&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#20316;&#20026;&#20195;&#29702;&#20154;&#30340;&#22810;&#32500;&#24230;&#22522;&#20934;&#65292;&#21457;&#29616;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#65292;&#21830;&#19994;LLMs&#22312;&#20805;&#24403;&#20195;&#29702;&#20154;&#26041;&#38754;&#34920;&#29616;&#24378;&#21170;&#65292;&#20294;&#19982;&#24320;&#28304;&#31454;&#20105;&#23545;&#25163;&#30456;&#27604;&#65292;&#23384;&#22312;&#26174;&#33879;&#24615;&#33021;&#24046;&#36317;&#12290;&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#22312;&#38271;&#26399;&#25512;&#29702;&#12289;&#20915;&#31574;&#21644;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#19978;&#30340;&#29942;&#39048;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#21464;&#24471;&#36234;&#26469;&#36234;&#26234;&#33021;&#21644;&#33258;&#20027;&#65292;&#38024;&#23545;&#20256;&#32479;&#30340;NLP&#20219;&#21153;&#20043;&#22806;&#30340;&#29616;&#23454;&#19990;&#30028;&#23454;&#38469;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#36843;&#20999;&#38656;&#35201;&#22312;&#20114;&#21160;&#29615;&#22659;&#20013;&#35780;&#20272;LLMs&#20316;&#20026;&#20195;&#29702;&#20154;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#19978;&#30340;&#25512;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;AgentBench&#65292;&#19968;&#20010;&#22810;&#32500;&#24230;&#28436;&#21464;&#30340;&#22522;&#20934;&#65292;&#30446;&#21069;&#21253;&#25324;8&#20010;&#19981;&#21516;&#30340;&#29615;&#22659;&#65292;&#20197;&#35780;&#20272;LLM&#20316;&#20026;&#20195;&#29702;&#20154;&#22312;&#22810;&#36718;&#24320;&#25918;&#24335;&#29983;&#25104;&#35774;&#32622;&#20013;&#30340;&#25512;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;27&#20010;&#22522;&#20110;API&#21644;&#24320;&#28304;&#30340;LLM&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;&#39030;&#32423;&#21830;&#19994;LLM&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#20195;&#29702;&#20154;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#19982;&#24320;&#28304;&#31454;&#20105;&#23545;&#25163;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#24456;&#22823;&#12290;&#25105;&#20204;&#25214;&#20986;&#20102;&#29615;&#22659;&#21644;LLM&#20013;&#22833;&#36133;&#30340;&#20856;&#22411;&#21407;&#22240;&#65292;&#34920;&#26126;&#38271;&#26399;&#25512;&#29702;&#12289;&#20915;&#31574;&#21644;&#36981;&#24490;&#25351;&#31034;&#33021;&#21147;&#19981;&#20339;&#26159;&#24320;&#21457;&#21487;&#29992;LLM&#20195;&#29702;&#20154;&#30340;&#20027;&#35201;&#38556;&#30861;&#12290;&#36890;&#36807;&#23545;&#20195;&#30721;&#21644;&#39640;&#36136;&#37327;&#36827;&#34892;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 27 API-based and open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and OSS competitors. We identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents. Training on code and high quality 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12658</link><description>&lt;p&gt;
&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#27714;&#35299;&#36866;&#24212;&#32467;&#26500;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fitted Value Iteration Methods for Bicausal Optimal Transport. (arXiv:2306.12658v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;(FVI)&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#36866;&#24212;&#32467;&#26500;&#30340;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;(OT)&#12290;&#22522;&#20110;&#21160;&#24577;&#35268;&#21010;&#30340;&#24418;&#24335;&#21270;&#34920;&#36848;&#65292;FVI&#37319;&#29992;&#20989;&#25968;&#31867;&#29992;&#20110;&#36817;&#20284;&#21452;&#22240;&#26524;OT&#20013;&#30340;&#20540;&#20989;&#25968;&#12290;&#22312;&#21487;&#38598;&#20013;&#26465;&#20214;&#21644;&#36817;&#20284;&#23436;&#22791;&#24615;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#65288;&#23616;&#37096;&#65289;Rademacher&#22797;&#26434;&#24230;&#35777;&#26126;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28145;&#24230;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#36866;&#24403;&#32467;&#26500;&#65292;&#28385;&#36275;&#26679;&#26412;&#22797;&#26434;&#24230;&#35777;&#26126;&#25152;&#38656;&#30340;&#20851;&#38190;&#20551;&#35774;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;FVI&#22312;&#26102;&#38388;&#36328;&#24230;&#22686;&#21152;&#26102;&#20248;&#20110;&#32447;&#24615;&#35268;&#21010;&#21644;&#36866;&#24212;&#24615;Sinkhorn&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#21487;&#25509;&#21463;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a fitted value iteration (FVI) method to compute bicausal optimal transport (OT) where couplings have an adapted structure. Based on the dynamic programming formulation, FVI adopts a function class to approximate the value functions in bicausal OT. Under the concentrability condition and approximate completeness assumption, we prove the sample complexity using (local) Rademacher complexity. Furthermore, we demonstrate that multilayer neural networks with appropriate structures satisfy the crucial assumptions required in sample complexity proofs. Numerical experiments reveal that FVI outperforms linear programming and adapted Sinkhorn methods in scalability as the time horizon increases, while still maintaining acceptable accuracy.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QATS&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#35299;&#30721;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#24207;&#21015;&#12290;&#23427;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20026;&#22810;&#23545;&#25968;&#21644;&#31435;&#26041;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#22411;HMM&#12290;</title><link>http://arxiv.org/abs/2305.18578</link><description>&lt;p&gt;
&#24555;&#36895;&#33258;&#36866;&#24212;&#19977;&#20803;&#20998;&#21106;&#65306;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#26377;&#25928;&#35299;&#30721;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quick Adaptive Ternary Segmentation: An Efficient Decoding Procedure For Hidden Markov Models. (arXiv:2305.18578v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18578
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QATS&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#35299;&#30721;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#24207;&#21015;&#12290;&#23427;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20026;&#22810;&#23545;&#25968;&#21644;&#31435;&#26041;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#22411;HMM&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#20197;&#19981;&#21487;&#35266;&#23519;&#30340;&#65288;&#38544;&#34255;&#30340;&#65289;&#39532;&#23572;&#21487;&#22827;&#38142;&#21644;&#21487;&#35266;&#27979;&#30340;&#36807;&#31243;&#20026;&#29305;&#24449;&#65292;&#21518;&#32773;&#26159;&#38544;&#34255;&#38142;&#30340;&#22122;&#22768;&#29256;&#26412;&#12290;&#20174;&#22024;&#26434;&#30340;&#35266;&#27979;&#20013;&#35299;&#30721;&#21407;&#22987;&#20449;&#21495;&#65288;&#21363;&#38544;&#34255;&#38142;&#65289;&#26159;&#20960;&#20046;&#25152;&#26377;&#22522;&#20110;HMM&#30340;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#30446;&#26631;&#12290;&#29616;&#26377;&#30340;&#35299;&#30721;&#31639;&#27861;&#65292;&#22914;&#32500;&#29305;&#27604;&#31639;&#27861;&#65292;&#22312;&#35266;&#27979;&#24207;&#21015;&#38271;&#24230;&#26368;&#22810;&#32447;&#24615;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#39532;&#23572;&#21487;&#22827;&#38142;&#29366;&#24577;&#31354;&#38388;&#30340;&#22823;&#23567;&#20013;&#20855;&#26377;&#27425;&#20108;&#27425;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24555;&#36895;&#33258;&#36866;&#24212;&#19977;&#20803;&#20998;&#21106;&#65288;QATS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20998;&#32780;&#27835;&#20043;&#30340;&#36807;&#31243;&#65292;&#21487;&#22312;&#24207;&#21015;&#38271;&#24230;&#30340;&#22810;&#23545;&#25968;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#29366;&#24577;&#31354;&#38388;&#30340;&#19977;&#27425;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#35299;&#30721;&#38544;&#34255;&#30340;&#24207;&#21015;&#65292;&#22240;&#27492;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#35268;&#27169;HMM&#12290;&#35813;&#31243;&#24207;&#36824;&#24314;&#35758;&#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#23384;&#20648;&#26041;&#24335;&#65292;&#21363;&#29305;&#23450;&#30340;&#32047;&#31215;&#24635;&#21644;&#12290;&#23454;&#36136;&#19978;&#65292;&#20272;&#35745;&#30340;&#29366;&#24577;&#24207;&#21015;&#25353;&#39034;&#24207;&#26368;&#22823;&#21270;&#23616;&#37096;&#20284;&#28982;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hidden Markov models (HMMs) are characterized by an unobservable (hidden) Markov chain and an observable process, which is a noisy version of the hidden chain. Decoding the original signal (i.e., hidden chain) from the noisy observations is one of the main goals in nearly all HMM based data analyses. Existing decoding algorithms such as the Viterbi algorithm have computational complexity at best linear in the length of the observed sequence, and sub-quadratic in the size of the state space of the Markov chain. We present Quick Adaptive Ternary Segmentation (QATS), a divide-and-conquer procedure which decodes the hidden sequence in polylogarithmic computational complexity in the length of the sequence, and cubic in the size of the state space, hence particularly suited for large scale HMMs with relatively few states. The procedure also suggests an effective way of data storage as specific cumulative sums. In essence, the estimated sequence of states sequentially maximizes local likeliho
&lt;/p&gt;</description></item><item><title>&#35813;&#25945;&#31243;&#20171;&#32461;&#20102;&#20998;&#25674;&#20248;&#21270;&#30340;&#22522;&#30784;&#65292;&#24182;&#24635;&#32467;&#20102;&#20854;&#22312;&#21464;&#20998;&#25512;&#26029;&#12289;&#31232;&#30095;&#32534;&#30721;&#12289;&#20803;&#23398;&#20064;&#12289;&#25511;&#21046;&#12289;&#24378;&#21270;&#23398;&#20064;&#12289;&#20984;&#20248;&#21270;&#12289;&#26368;&#20248;&#20256;&#36755;&#21644;&#28145;&#24230;&#24179;&#34913;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2202.00665</link><description>&lt;p&gt;
&#20851;&#20110;&#20998;&#25674;&#20248;&#21270;&#30340;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
Tutorial on amortized optimization. (arXiv:2202.00665v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.00665
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25945;&#31243;&#20171;&#32461;&#20102;&#20998;&#25674;&#20248;&#21270;&#30340;&#22522;&#30784;&#65292;&#24182;&#24635;&#32467;&#20102;&#20854;&#22312;&#21464;&#20998;&#25512;&#26029;&#12289;&#31232;&#30095;&#32534;&#30721;&#12289;&#20803;&#23398;&#20064;&#12289;&#25511;&#21046;&#12289;&#24378;&#21270;&#23398;&#20064;&#12289;&#20984;&#20248;&#21270;&#12289;&#26368;&#20248;&#20256;&#36755;&#21644;&#28145;&#24230;&#24179;&#34913;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#26159;&#19968;&#31181;&#26222;&#36941;&#30340;&#24314;&#27169;&#24037;&#20855;&#65292;&#32463;&#24120;&#22312;&#21453;&#22797;&#35299;&#20915;&#30456;&#21516;&#38382;&#39064;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#12290;&#20998;&#25674;&#20248;&#21270;&#26041;&#27861;&#20351;&#29992;&#23398;&#20064;&#26469;&#39044;&#27979;&#36825;&#20123;&#35774;&#32622;&#20013;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21033;&#29992;&#30456;&#20284;&#38382;&#39064;&#23454;&#20363;&#20043;&#38388;&#30340;&#20849;&#20139;&#32467;&#26500;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21464;&#20998;&#25512;&#26029;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#33021;&#22815;&#27604;&#19981;&#20351;&#29992;&#20998;&#25674;&#30340;&#20256;&#32479;&#20248;&#21270;&#26041;&#27861;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#22320;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#12290;&#26412;&#27425;&#25945;&#31243;&#20171;&#32461;&#20102;&#36825;&#20123;&#36827;&#27493;&#32972;&#21518;&#30340;&#20998;&#25674;&#20248;&#21270;&#22522;&#30784;&#65292;&#24182;&#27010;&#36848;&#20102;&#23427;&#20204;&#22312;&#21464;&#20998;&#25512;&#26029;&#12289;&#31232;&#30095;&#32534;&#30721;&#12289;&#22522;&#20110;&#26799;&#24230;&#30340;&#20803;&#23398;&#20064;&#12289;&#25511;&#21046;&#12289;&#24378;&#21270;&#23398;&#20064;&#12289;&#20984;&#20248;&#21270;&#12289;&#26368;&#20248;&#20256;&#36755;&#21644;&#28145;&#24230;&#24179;&#34913;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;&#12290;&#26412;&#25945;&#31243;&#30340;&#28304;&#20195;&#30721;&#21487;&#22312;https://github.com/facebookresearch/amortized-optimization-tutorial&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimization is a ubiquitous modeling tool and is often deployed in settings which repeatedly solve similar instances of the same problem. Amortized optimization methods use learning to predict the solutions to problems in these settings, exploiting the shared structure between similar problem instances. These methods have been crucial in variational inference and reinforcement learning and are capable of solving optimization problems many orders of magnitudes times faster than traditional optimization methods that do not use amortization. This tutorial presents an introduction to the amortized optimization foundations behind these advancements and overviews their applications in variational inference, sparse coding, gradient-based meta-learning, control, reinforcement learning, convex optimization, optimal transport, and deep equilibrium networks. The source code for this tutorial is available at https://github.com/facebookresearch/amortized-optimization-tutorial.
&lt;/p&gt;</description></item></channel></rss>