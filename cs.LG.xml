<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24179;&#26041;Sigmoid TanH&#65288;SST&#65289;&#28608;&#27963;&#20989;&#25968;&#65292;&#29992;&#20110;&#22686;&#24378;&#22312;&#25968;&#25454;&#38480;&#21046;&#19979;&#30340;&#39034;&#24207;&#27169;&#22411;&#23398;&#20064;&#33021;&#21147;&#12290;&#36890;&#36807;&#25968;&#23398;&#24179;&#26041;&#25918;&#22823;&#24378;&#28608;&#27963;&#21644;&#24369;&#28608;&#27963;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#25913;&#21892;&#26799;&#24230;&#27969;&#21644;&#20449;&#24687;&#36807;&#28388;&#12290;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#35780;&#20272;&#20102;SST&#39537;&#21160;&#30340;LSTM&#21644;GRU&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09034</link><description>&lt;p&gt;
&#20351;&#29992;&#24179;&#26041;Sigmoid TanH (SST)&#28608;&#27963;&#22312;&#25968;&#25454;&#38480;&#21046;&#19979;&#25552;&#39640;&#39034;&#24207;&#27169;&#22411;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Enhancing Sequential Model Performance with Squared Sigmoid TanH (SST) Activation Under Data Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09034
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24179;&#26041;Sigmoid TanH&#65288;SST&#65289;&#28608;&#27963;&#20989;&#25968;&#65292;&#29992;&#20110;&#22686;&#24378;&#22312;&#25968;&#25454;&#38480;&#21046;&#19979;&#30340;&#39034;&#24207;&#27169;&#22411;&#23398;&#20064;&#33021;&#21147;&#12290;&#36890;&#36807;&#25968;&#23398;&#24179;&#26041;&#25918;&#22823;&#24378;&#28608;&#27963;&#21644;&#24369;&#28608;&#27963;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#25913;&#21892;&#26799;&#24230;&#27969;&#21644;&#20449;&#24687;&#36807;&#28388;&#12290;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#35780;&#20272;&#20102;SST&#39537;&#21160;&#30340;LSTM&#21644;GRU&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28608;&#27963;&#20989;&#25968;&#36890;&#36807;&#24341;&#20837;&#38750;&#32447;&#24615;&#26469;&#20351;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#22797;&#26434;&#30340;&#34920;&#31034;&#12290;&#34429;&#28982;&#21069;&#39304;&#27169;&#22411;&#36890;&#24120;&#20351;&#29992;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65292;&#20294;&#26159;&#39034;&#24207;&#27169;&#22411;&#22914;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#12289;&#38271;&#30701;&#26102;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;&#65288;GRU&#65289;&#20173;&#28982;&#20381;&#36182;&#20110;Sigmoid&#21644;TanH&#28608;&#27963;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20256;&#32479;&#30340;&#28608;&#27963;&#20989;&#25968;&#24120;&#24120;&#22312;&#35757;&#32451;&#22312;&#23567;&#39034;&#24207;&#25968;&#25454;&#38598;&#19978;&#26102;&#38590;&#20197;&#24314;&#27169;&#31232;&#30095;&#27169;&#24335;&#20197;&#26377;&#25928;&#25429;&#33719;&#26102;&#38388;&#20381;&#36182;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29305;&#21035;&#38024;&#23545;&#22312;&#25968;&#25454;&#38480;&#21046;&#19979;&#22686;&#24378;&#39034;&#24207;&#27169;&#22411;&#23398;&#20064;&#33021;&#21147;&#30340;&#24179;&#26041;Sigmoid TanH&#65288;SST&#65289;&#28608;&#27963;&#12290;SST&#36890;&#36807;&#25968;&#23398;&#24179;&#26041;&#26469;&#25918;&#22823;&#24378;&#28608;&#27963;&#21644;&#24369;&#28608;&#27963;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#38543;&#30528;&#20449;&#21495;&#38543;&#26102;&#38388;&#20256;&#25773;&#65292;&#26377;&#21161;&#20110;&#25913;&#21892;&#26799;&#24230;&#27969;&#21644;&#20449;&#24687;&#36807;&#28388;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20351;&#29992;SST&#30340;LSTM&#21644;GRU&#27169;&#22411;&#22312;&#19981;&#21516;&#24212;&#29992;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09034v1 Announce Type: cross Abstract: Activation functions enable neural networks to learn complex representations by introducing non-linearities. While feedforward models commonly use rectified linear units, sequential models like recurrent neural networks, long short-term memory (LSTMs) and gated recurrent units (GRUs) still rely on Sigmoid and TanH activation functions. However, these classical activation functions often struggle to model sparse patterns when trained on small sequential datasets to effectively capture temporal dependencies. To address this limitation, we propose squared Sigmoid TanH (SST) activation specifically tailored to enhance the learning capability of sequential models under data constraints. SST applies mathematical squaring to amplify differences between strong and weak activations as signals propagate over time, facilitating improved gradient flow and information filtering. We evaluate SST-powered LSTMs and GRUs for diverse applications, such a
&lt;/p&gt;</description></item><item><title>APALU &#26159;&#19968;&#31181;&#21487;&#35757;&#32451;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#36890;&#36807;&#22686;&#24378;&#28145;&#24230;&#23398;&#20064;&#30340;&#23398;&#20064;&#24615;&#33021;&#65292;&#22312;&#36866;&#24212;&#22797;&#26434;&#25968;&#25454;&#34920;&#31034;&#30340;&#21516;&#26102;&#20445;&#25345;&#31283;&#23450;&#21644;&#39640;&#25928;&#12290; &#22312;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;APALU&#30456;&#23545;&#20110;&#20256;&#32479;&#28608;&#27963;&#20989;&#25968;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08244</link><description>&lt;p&gt;
APALU: &#19968;&#31181;&#21487;&#35757;&#32451;&#12289;&#36866;&#24212;&#24615;&#28608;&#27963;&#20989;&#25968;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
APALU: A Trainable, Adaptive Activation Function for Deep Learning Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08244
&lt;/p&gt;
&lt;p&gt;
APALU &#26159;&#19968;&#31181;&#21487;&#35757;&#32451;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#36890;&#36807;&#22686;&#24378;&#28145;&#24230;&#23398;&#20064;&#30340;&#23398;&#20064;&#24615;&#33021;&#65292;&#22312;&#36866;&#24212;&#22797;&#26434;&#25968;&#25454;&#34920;&#31034;&#30340;&#21516;&#26102;&#20445;&#25345;&#31283;&#23450;&#21644;&#39640;&#25928;&#12290; &#22312;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;APALU&#30456;&#23545;&#20110;&#20256;&#32479;&#28608;&#27963;&#20989;&#25968;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28608;&#27963;&#20989;&#25968;&#26159;&#28145;&#24230;&#23398;&#20064;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#26377;&#21161;&#20110;&#25552;&#21462;&#22797;&#26434;&#30340;&#25968;&#25454;&#27169;&#24335;&#12290;&#34429;&#28982;&#31867;&#20284;ReLU&#21450;&#20854;&#21464;&#31181;&#30340;&#32463;&#20856;&#28608;&#27963;&#20989;&#25968;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#38745;&#24577;&#29305;&#24615;&#21644;&#31616;&#27905;&#24615;&#65292;&#23613;&#31649;&#26377;&#21033;&#65292;&#20294;&#36890;&#24120;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#29305;&#23450;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#21487;&#35757;&#32451;&#30340;&#28608;&#27963;&#20989;&#25968;&#26377;&#26102;&#20063;&#38590;&#20197;&#36866;&#24212;&#25968;&#25454;&#30340;&#29420;&#29305;&#29305;&#24449;&#12290;&#38024;&#23545;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#35757;&#32451;&#28608;&#27963;&#20989;&#25968;&#65292;&#21363;&#33258;&#36866;&#24212;&#20998;&#27573;&#36924;&#36817;&#28608;&#27963;&#32447;&#24615;&#21333;&#20803;&#65288;APALU&#65289;&#65292;&#20197;&#22686;&#24378;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#30340;&#23398;&#20064;&#24615;&#33021;&#12290;&#23427;&#20855;&#26377;&#19968;&#22871;&#29420;&#29305;&#30340;&#29305;&#24615;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#20445;&#25345;&#31283;&#23450;&#21644;&#39640;&#25928;&#65292;&#24182;&#36866;&#24212;&#22797;&#26434;&#30340;&#25968;&#25454;&#34920;&#31034;&#12290;&#23454;&#39564;&#35777;&#23454;&#65292;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#65292;&#19982;&#24191;&#27867;&#20351;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#30456;&#27604;&#65292;APALU&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#22312;&#22270;&#20687;&#20998;&#31867;&#20013;&#65292;APALU&#25552;&#21319;&#20102;MobileNet&#21644;GoogleNet&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Activation function is a pivotal component of deep learning, facilitating the extraction of intricate data patterns. While classical activation functions like ReLU and its variants are extensively utilized, their static nature and simplicity, despite being advantageous, often limit their effectiveness in specialized tasks. The trainable activation functions also struggle sometimes to adapt to the unique characteristics of the data. Addressing these limitations, we introduce a novel trainable activation function, adaptive piecewise approximated activation linear unit (APALU), to enhance the learning performance of deep learning across a broad range of tasks. It presents a unique set of features that enable it to maintain stability and efficiency in the learning process while adapting to complex data representations. Experiments reveal significant improvements over widely used activation functions for different tasks. In image classification, APALU increases MobileNet and GoogleNet accur
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;Transformer&#31070;&#32463;&#32593;&#32476;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#20174;&#25972;&#40784;&#25490;&#21015;&#30340;&#31034;&#33539;&#20013;&#29702;&#35299;&#21644;&#22797;&#21046;&#25972;&#27905;&#30340;&#27010;&#24565;&#65292;&#20174;&#32780;&#23454;&#29616;&#25972;&#29702;&#29289;&#21697;&#30340;&#21151;&#33021;&#12290;</title><link>https://arxiv.org/abs/2310.04566</link><description>&lt;p&gt;
Knolling Bot: &#20174;&#25972;&#27905;&#30340;&#31034;&#33539;&#20013;&#23398;&#20064;&#26426;&#22120;&#20154;&#23545;&#35937;&#25490;&#21015;
&lt;/p&gt;
&lt;p&gt;
Knolling Bot: Learning Robotic Object Arrangement from Tidy Demonstrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.04566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;Transformer&#31070;&#32463;&#32593;&#32476;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#20174;&#25972;&#40784;&#25490;&#21015;&#30340;&#31034;&#33539;&#20013;&#29702;&#35299;&#21644;&#22797;&#21046;&#25972;&#27905;&#30340;&#27010;&#24565;&#65292;&#20174;&#32780;&#23454;&#29616;&#25972;&#29702;&#29289;&#21697;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22320;&#22336;&#65306;arXiv:2310.04566v2  &#20844;&#21578;&#31867;&#22411;&#65306;replace-cross  &#25688;&#35201;&#65306;&#35299;&#20915;&#23478;&#24237;&#31354;&#38388;&#20013;&#25955;&#20081;&#29289;&#21697;&#30340;&#25972;&#29702;&#25361;&#25112;&#21463;&#21040;&#25972;&#27905;&#24615;&#30340;&#22810;&#26679;&#24615;&#21644;&#20027;&#35266;&#24615;&#30340;&#22797;&#26434;&#24615;&#24433;&#21709;&#12290;&#27491;&#22914;&#20154;&#31867;&#35821;&#35328;&#30340;&#22797;&#26434;&#24615;&#20801;&#35768;&#21516;&#19968;&#29702;&#24565;&#30340;&#22810;&#31181;&#34920;&#36798;&#19968;&#26679;&#65292;&#23478;&#24237;&#25972;&#27905;&#20559;&#22909;&#21644;&#32452;&#32455;&#27169;&#24335;&#21464;&#21270;&#24191;&#27867;&#65292;&#22240;&#27492;&#39044;&#35774;&#29289;&#20307;&#20301;&#32622;&#23558;&#38480;&#21046;&#23545;&#26032;&#29289;&#20307;&#21644;&#29615;&#22659;&#30340;&#36866;&#24212;&#24615;&#12290;&#21463;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#36827;&#23637;&#21551;&#21457;&#65292;&#26412;&#25991;&#24341;&#20837;&#19968;&#31181;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#20174;&#25972;&#27905;&#24067;&#23616;&#30340;&#31034;&#33539;&#20013;&#29702;&#35299;&#21644;&#22797;&#21046;&#25972;&#27905;&#30340;&#27010;&#24565;&#65292;&#31867;&#20284;&#20110;&#20351;&#29992;&#20250;&#35805;&#25968;&#25454;&#38598;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#12290;&#25105;&#20204;&#21033;&#29992;&#19968;&#20010;Transformer&#31070;&#32463;&#32593;&#32476;&#26469;&#39044;&#27979;&#21518;&#32493;&#29289;&#20307;&#30340;&#25670;&#25918;&#20301;&#32622;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#8220;&#25972;&#29702;&#8221;&#31995;&#32479;&#65292;&#21033;&#29992;&#26426;&#26800;&#33218;&#21644;RGB&#30456;&#26426;&#22312;&#26700;&#23376;&#19978;&#32452;&#32455;&#19981;&#21516;&#22823;&#23567;&#21644;&#25968;&#37327;&#30340;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.04566v2 Announce Type: replace-cross  Abstract: Addressing the challenge of organizing scattered items in domestic spaces is complicated by the diversity and subjective nature of tidiness. Just as the complexity of human language allows for multiple expressions of the same idea, household tidiness preferences and organizational patterns vary widely, so presetting object locations would limit the adaptability to new objects and environments. Inspired by advancements in natural language processing (NLP), this paper introduces a self-supervised learning framework that allows robots to understand and replicate the concept of tidiness from demonstrations of well-organized layouts, akin to using conversational datasets to train Large Language Models(LLM). We leverage a transformer neural network to predict the placement of subsequent objects. We demonstrate a ``knolling'' system with a robotic arm and an RGB camera to organize items of varying sizes and quantities on a table. Our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#28151;&#21512;&#20219;&#21153;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#21487;&#25193;&#23637;&#21644;&#21487;&#36716;&#31227;&#30340;&#24102;&#23485;&#20998;&#37197;&#12290;&#36890;&#36807;&#24341;&#20837;GNN&#21644;HML&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#36890;&#20449;&#22330;&#26223;&#19979;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#21644;&#37319;&#26679;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.10253</link><description>&lt;p&gt;
&#28151;&#21512;&#20219;&#21153;&#20803;&#23398;&#20064;&#65306;&#19968;&#31181;&#29992;&#20110;&#21487;&#25193;&#23637;&#21644;&#21487;&#36716;&#31227;&#24102;&#23485;&#20998;&#37197;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Hybrid-Task Meta-Learning: A Graph Neural Network Approach for Scalable and Transferable Bandwidth Allocation. (arXiv:2401.10253v1 [cs.NI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10253
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#28151;&#21512;&#20219;&#21153;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#21487;&#25193;&#23637;&#21644;&#21487;&#36716;&#31227;&#30340;&#24102;&#23485;&#20998;&#37197;&#12290;&#36890;&#36807;&#24341;&#20837;GNN&#21644;HML&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#36890;&#20449;&#22330;&#26223;&#19979;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#21644;&#37319;&#26679;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#24102;&#23485;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#20855;&#26377;&#20197;&#19979;&#29305;&#28857;&#65306;1&#65289;&#38543;&#30528;&#29992;&#25143;&#25968;&#37327;&#30340;&#22686;&#21152;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#65307;2&#65289;&#33021;&#22815;&#22312;&#19981;&#21516;&#30340;&#36890;&#20449;&#22330;&#26223;&#19979;&#36827;&#34892;&#36716;&#31227;&#65292;&#20363;&#22914;&#38750;&#24179;&#31283;&#30340;&#26080;&#32447;&#20449;&#36947;&#12289;&#19981;&#21516;&#30340;&#26381;&#21153;&#36136;&#37327;&#35201;&#27714;&#21644;&#21160;&#24577;&#21487;&#29992;&#36164;&#28304;&#12290;&#20026;&#20102;&#25903;&#25345;&#21487;&#25193;&#23637;&#24615;&#65292;&#24102;&#23485;&#20998;&#37197;&#31574;&#30053;&#37319;&#29992;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#36827;&#34892;&#34920;&#31034;&#65292;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#38543;&#29992;&#25143;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#19981;&#21464;&#12290;&#20026;&#20102;&#23454;&#29616;GNN&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#28151;&#21512;&#20219;&#21153;&#20803;&#23398;&#20064;&#65288;HML&#65289;&#31639;&#27861;&#65292;&#22312;&#20803;&#35757;&#32451;&#36807;&#31243;&#20013;&#20351;&#29992;&#19981;&#21516;&#30340;&#36890;&#20449;&#22330;&#26223;&#26469;&#35757;&#32451;GNN&#30340;&#21021;&#22987;&#21442;&#25968;&#12290;&#28982;&#21518;&#65292;&#22312;&#20803;&#27979;&#35797;&#36807;&#31243;&#20013;&#65292;&#20351;&#29992;&#23569;&#37327;&#26679;&#26412;&#23545;GNN&#36827;&#34892;&#24494;&#35843;&#20197;&#36866;&#24212;&#26410;&#35265;&#36807;&#30340;&#36890;&#20449;&#22330;&#26223;&#12290;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#22522;&#20934;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;HML&#26041;&#27861;&#21487;&#20197;&#23558;&#21021;&#22987;&#24615;&#33021;&#25552;&#39640;8.79&#65285;&#65292;&#24182;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;73&#65285;&#12290;&#22312;&#24494;&#35843;&#21518;&#65292;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a deep learning-based bandwidth allocation policy that is: 1) scalable with the number of users and 2) transferable to different communication scenarios, such as non-stationary wireless channels, different quality-of-service (QoS) requirements, and dynamically available resources. To support scalability, the bandwidth allocation policy is represented by a graph neural network (GNN), with which the number of training parameters does not change with the number of users. To enable the generalization of the GNN, we develop a hybrid-task meta-learning (HML) algorithm that trains the initial parameters of the GNN with different communication scenarios during meta-training. Next, during meta-testing, a few samples are used to fine-tune the GNN with unseen communication scenarios. Simulation results demonstrate that our HML approach can improve the initial performance by $8.79\%$, and sampling efficiency by $73\%$, compared with existing benchmarks. After fine-tuning,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#24863;&#30693;-&#34892;&#21160;-&#36890;&#20449;(LPAC)&#26550;&#26500;&#65292;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#29615;&#22659;&#24863;&#30693;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#26426;&#22120;&#20154;&#20043;&#38388;&#30340;&#20449;&#24687;&#20132;&#27969;&#65292;&#27973;&#23618;&#22810;&#23618;&#24863;&#30693;&#26426;&#35745;&#31639;&#26426;&#22120;&#20154;&#30340;&#21160;&#20316;&#12290;&#20351;&#29992;&#38598;&#20013;&#24335;&#26174;&#24494;&#31639;&#27861;&#35757;&#32451;&#27169;&#22411;&#65292;&#23454;&#29616;&#26426;&#22120;&#20154;&#32676;&#20307;&#30340;&#21327;&#20316;&#12290;</title><link>http://arxiv.org/abs/2401.04855</link><description>&lt;p&gt;
LPAC: &#21487;&#23398;&#20064;&#30340;&#24863;&#30693;-&#34892;&#21160;-&#36890;&#20449;&#24490;&#29615;&#21450;&#20854;&#22312;&#35206;&#30422;&#25511;&#21046;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
LPAC: Learnable Perception-Action-Communication Loops with Applications to Coverage Control. (arXiv:2401.04855v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04855
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#24863;&#30693;-&#34892;&#21160;-&#36890;&#20449;(LPAC)&#26550;&#26500;&#65292;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#29615;&#22659;&#24863;&#30693;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#26426;&#22120;&#20154;&#20043;&#38388;&#30340;&#20449;&#24687;&#20132;&#27969;&#65292;&#27973;&#23618;&#22810;&#23618;&#24863;&#30693;&#26426;&#35745;&#31639;&#26426;&#22120;&#20154;&#30340;&#21160;&#20316;&#12290;&#20351;&#29992;&#38598;&#20013;&#24335;&#26174;&#24494;&#31639;&#27861;&#35757;&#32451;&#27169;&#22411;&#65292;&#23454;&#29616;&#26426;&#22120;&#20154;&#32676;&#20307;&#30340;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35206;&#30422;&#25511;&#21046;&#26159;&#25351;&#23548;&#26426;&#22120;&#20154;&#32676;&#20307;&#21327;&#21516;&#30417;&#27979;&#26410;&#30693;&#30340;&#24863;&#20852;&#36259;&#29305;&#24449;&#25110;&#29616;&#35937;&#30340;&#38382;&#39064;&#12290;&#22312;&#26377;&#38480;&#30340;&#36890;&#20449;&#21644;&#24863;&#30693;&#33021;&#21147;&#30340;&#20998;&#25955;&#35774;&#32622;&#20013;&#65292;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#24863;&#30693;-&#34892;&#21160;-&#36890;&#20449;(LPAC)&#26550;&#26500;&#26469;&#35299;&#20915;&#35206;&#30422;&#25511;&#21046;&#38382;&#39064;&#12290;&#22312;&#35813;&#35299;&#20915;&#26041;&#26696;&#20013;&#65292;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#22788;&#29702;&#20102;&#29615;&#22659;&#30340;&#23616;&#37096;&#24863;&#30693;&#65307;&#22270;&#31070;&#32463;&#32593;&#32476;(GNN)&#23454;&#29616;&#20102;&#37051;&#36817;&#26426;&#22120;&#20154;&#20043;&#38388;&#30340;&#30456;&#20851;&#20449;&#24687;&#36890;&#20449;&#65307;&#26368;&#21518;&#65292;&#27973;&#23618;&#22810;&#23618;&#24863;&#30693;&#26426;(MLP)&#35745;&#31639;&#26426;&#22120;&#20154;&#30340;&#21160;&#20316;&#12290;&#36890;&#20449;&#27169;&#22359;&#20013;&#30340;GNN&#36890;&#36807;&#35745;&#31639;&#24212;&#35813;&#19982;&#37051;&#23621;&#36890;&#20449;&#21738;&#20123;&#20449;&#24687;&#20197;&#21450;&#22914;&#20309;&#21033;&#29992;&#25509;&#25910;&#21040;&#30340;&#20449;&#24687;&#37319;&#21462;&#36866;&#24403;&#30340;&#34892;&#21160;&#26469;&#23454;&#29616;&#26426;&#22120;&#20154;&#32676;&#20307;&#30340;&#21327;&#20316;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#30693;&#26195;&#25972;&#20010;&#29615;&#22659;&#30340;&#38598;&#20013;&#24335;&#26174;&#24494;&#31639;&#27861;&#26469;&#36827;&#34892;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Coverage control is the problem of navigating a robot swarm to collaboratively monitor features or a phenomenon of interest not known a priori. The problem is challenging in decentralized settings with robots that have limited communication and sensing capabilities. This paper proposes a learnable Perception-Action-Communication (LPAC) architecture for the coverage control problem. In the proposed solution, a convolution neural network (CNN) processes localized perception of the environment; a graph neural network (GNN) enables communication of relevant information between neighboring robots; finally, a shallow multi-layer perceptron (MLP) computes robot actions. The GNN in the communication module enables collaboration in the robot swarm by computing what information to communicate with neighbors and how to use received information to take appropriate actions. We train models using imitation learning with a centralized clairvoyant algorithm that is aware of the entire environment. Eva
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25351;&#20986;&#65292;&#23545;&#20110;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#20989;&#25968;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#65292;&#20854;&#27425;&#20248;&#24615;&#24517;&#39035;&#24402;&#22240;&#20110;&#22823;&#30340;&#20559;&#24046;&#32780;&#38750;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;ERM&#30340;&#24179;&#26041;&#35823;&#24046;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#65292;&#26041;&#24046;&#39033;&#24517;&#28982;&#20855;&#26377;&#26497;&#23567;&#30340;&#22833;&#35823;&#29575;&#12290;&#20316;&#32773;&#36824;&#25552;&#20379;&#20102;Chatterjee&#30340;&#19981;&#21487;&#20801;&#35768;&#24615;&#23450;&#29702;&#30340;&#31616;&#21333;&#35777;&#26126;&#65292;&#24182;&#34920;&#31034;&#20182;&#20204;&#30340;&#20272;&#35745;&#34920;&#26126;ERM&#30340;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18508</link><description>&lt;p&gt;
&#35770;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#24046;&#12289;&#21487;&#20801;&#35768;&#24615;&#21644;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Variance, Admissibility, and Stability of Empirical Risk Minimization. (arXiv:2305.18508v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25351;&#20986;&#65292;&#23545;&#20110;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#20989;&#25968;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#65292;&#20854;&#27425;&#20248;&#24615;&#24517;&#39035;&#24402;&#22240;&#20110;&#22823;&#30340;&#20559;&#24046;&#32780;&#38750;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;ERM&#30340;&#24179;&#26041;&#35823;&#24046;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#65292;&#26041;&#24046;&#39033;&#24517;&#28982;&#20855;&#26377;&#26497;&#23567;&#30340;&#22833;&#35823;&#29575;&#12290;&#20316;&#32773;&#36824;&#25552;&#20379;&#20102;Chatterjee&#30340;&#19981;&#21487;&#20801;&#35768;&#24615;&#23450;&#29702;&#30340;&#31616;&#21333;&#35777;&#26126;&#65292;&#24182;&#34920;&#31034;&#20182;&#20204;&#30340;&#20272;&#35745;&#34920;&#26126;ERM&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#33021;&#20250;&#36798;&#21040;&#26497;&#23567;&#30340;&#26368;&#22823;&#22833;&#35823;&#29575;&#12290;&#26412;&#25991;&#30340;&#20851;&#38190;&#20449;&#24687;&#26159;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;ERM&#30340;&#27425;&#20248;&#24615;&#24517;&#39035;&#24402;&#22240;&#20110;&#22823;&#30340;&#20559;&#24046;&#32780;&#38750;&#26041;&#24046;&#12290;&#22312;ERM&#30340;&#24179;&#26041;&#35823;&#24046;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#65292;&#26041;&#24046;&#39033;&#24517;&#28982;&#20855;&#26377;&#26497;&#23567;&#30340;&#22833;&#35823;&#29575;&#12290;&#25105;&#20204;&#20026;&#22266;&#23450;&#35774;&#35745;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#12289;&#20351;&#29992;&#27010;&#29575;&#26041;&#27861;&#35777;&#26126;&#36825;&#19968;&#20107;&#23454;&#30340;&#35777;&#26126;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#38543;&#26426;&#35774;&#35745;&#35774;&#32622;&#19979;&#20026;&#21508;&#31181;&#27169;&#22411;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102; Chatterjee &#19981;&#21487;&#20801;&#35768;&#24615;&#23450;&#29702; (Chatterjee, 2014, Theorem 1.4) &#30340;&#31616;&#21333;&#35777;&#26126;&#65292;&#35813;&#23450;&#29702;&#25351;&#20986;&#65292;&#22312;&#22266;&#23450;&#35774;&#35745;&#35774;&#32622;&#20013;&#65292;ERM&#19981;&#33021;&#34987;&#25490;&#38500;&#20026;&#19968;&#31181;&#26368;&#20248;&#26041;&#27861;&#65292;&#24182;&#23558;&#35813;&#32467;&#26524;&#25193;&#23637;&#21040;&#38543;&#26426;&#35774;&#35745;&#35774;&#32622;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#34920;&#26126;ERM&#30340;&#31283;&#23450;&#24615;&#65292;&#20026;Caponnetto&#21644;Rakhlin(2006)&#30340;&#38750;Donsker&#31867;&#30340;&#20027;&#35201;&#32467;&#26524;&#25552;&#20379;&#20102;&#34917;&#20805;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that Empirical Risk Minimization (ERM) with squared loss may attain minimax suboptimal error rates (Birg\'e and Massart, 1993). The key message of this paper is that, under mild assumptions, the suboptimality of ERM must be due to large bias rather than variance. More precisely, in the bias-variance decomposition of the squared error of the ERM, the variance term necessarily enjoys the minimax rate. In the case of fixed design, we provide an elementary proof of this fact using the probabilistic method. Then, we prove this result for various models in the random design setting. In addition, we provide a simple proof of Chatterjee's admissibility theorem (Chatterjee, 2014, Theorem 1.4), which states that ERM cannot be ruled out as an optimal method, in the fixed design setting, and extend this result to the random design setting. We also show that our estimates imply stability of ERM, complementing the main result of Caponnetto and Rakhlin (2006) for non-Donsker classes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#65292;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2302.09051</link><description>&lt;p&gt;
&#22797;&#26434;&#38382;&#31572;&#21644;&#35821;&#35328;&#27169;&#22411;&#28151;&#21512;&#26550;&#26500;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Complex QA and language models hybrid architectures, Survey. (arXiv:2302.09051v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#65292;&#35752;&#35770;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#35821;&#35328;&#27169;&#22411;&#26550;&#26500;&#21644;&#31574;&#30053;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#28151;&#21512;&#25216;&#26415;&#22312;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#20013;&#30340;&#24212;&#29992;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#26631;&#20934;&#38382;&#39064;&#19978;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#65292;&#20294;&#22312;&#35299;&#20915;&#26356;&#20855;&#20307;&#30340;&#22797;&#26434;&#38382;&#39064;&#26102;&#65288;&#22914;&#22312;&#19981;&#21516;&#25991;&#21270;&#20013;&#20010;&#20154;&#33258;&#30001;&#27010;&#24565;&#30340;&#21464;&#21270;&#22914;&#20309;&#65311;&#20160;&#20040;&#26159;&#20026;&#20943;&#23569;&#27668;&#20505;&#21464;&#21270;&#32780;&#23454;&#29616;&#30340;&#26368;&#20339;&#21457;&#30005;&#26041;&#27861;&#32452;&#21512;&#65311;&#65289;&#65292;&#38656;&#35201;&#29305;&#23450;&#30340;&#26550;&#26500;&#12289;&#30693;&#35782;&#12289;&#25216;&#33021;&#12289;&#26041;&#27861;&#12289;&#25935;&#24863;&#25968;&#25454;&#20445;&#25252;&#12289;&#21487;&#35299;&#37322;&#24615;&#12289;&#20154;&#31867;&#23457;&#25209;&#21644;&#22810;&#21151;&#33021;&#21453;&#39304;&#12290;&#26368;&#36817;&#30340;&#39033;&#30446;&#22914;ChatGPT&#21644;GALACTICA&#20801;&#35768;&#38750;&#19987;&#19994;&#20154;&#21592;&#20102;&#35299;LLM&#22312;&#22797;&#26434;QA&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#20197;&#21450;&#21516;&#31561;&#24378;&#22823;&#30340;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23457;&#26597;&#25152;&#38656;&#30340;&#25216;&#33021;&#21644;&#35780;&#20272;&#25216;&#26415;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32508;&#36848;&#20102;&#29616;&#26377;&#30340;&#28151;&#21512;&#26550;&#26500;&#65292;&#23558;LLM&#19982;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#12289;&#20449;&#24687;&#26816;&#32034;&#12289;&#30693;&#35782;&#22270;&#35889;&#21644;&#20854;&#20182;AI/ML&#25216;&#26415;&#30456;&#32467;&#21512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;&#36825;&#20123;CQA&#31995;&#32479;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#26410;&#26469;&#30740;&#31350;&#30340;&#21487;&#33021;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper reviews the state-of-the-art of language models architectures and strategies for "complex" question-answering (QA, CQA, CPS) with a focus on hybridization. Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems (e.g. How does the concept of personal freedom vary between different cultures ? What is the best mix of power generation methods to reduce climate change ?) you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of LLM in complex QA. In this paper, we start by reviewing required skills and evaluation techniques. We integrate findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and an
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#21512;&#20154;&#26426;&#20915;&#31574;&#30340;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#31639;&#27861;&#25512;&#33616;&#23545;&#36873;&#25321;&#30340;&#24433;&#21709;&#21644;&#35774;&#35745;&#65292;&#29305;&#21035;&#20851;&#27880;&#31639;&#27861;&#23545;&#20559;&#22909;&#30340;&#25913;&#21464;&#65292;&#20197;&#35299;&#20915;&#31639;&#27861;&#36741;&#21161;&#21487;&#33021;&#24102;&#26469;&#30340;&#24847;&#22806;&#21518;&#26524;&#12290;</title><link>http://arxiv.org/abs/2208.07626</link><description>&lt;p&gt;
&#31639;&#27861;&#36741;&#21161;&#19979;&#30340;&#25512;&#33616;&#30456;&#20851;&#20559;&#22909;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Assistance with Recommendation-Dependent Preferences. (arXiv:2208.07626v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.07626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#21512;&#20154;&#26426;&#20915;&#31574;&#30340;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#31639;&#27861;&#25512;&#33616;&#23545;&#36873;&#25321;&#30340;&#24433;&#21709;&#21644;&#35774;&#35745;&#65292;&#29305;&#21035;&#20851;&#27880;&#31639;&#27861;&#23545;&#20559;&#22909;&#30340;&#25913;&#21464;&#65292;&#20197;&#35299;&#20915;&#31639;&#27861;&#36741;&#21161;&#21487;&#33021;&#24102;&#26469;&#30340;&#24847;&#22806;&#21518;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#31639;&#27861;&#25552;&#20379;&#39118;&#38505;&#35780;&#20272;&#26102;&#65292;&#25105;&#20204;&#36890;&#24120;&#23558;&#20854;&#35270;&#20026;&#23545;&#20154;&#31867;&#20915;&#31574;&#30340;&#26377;&#30410;&#36755;&#20837;&#65292;&#20363;&#22914;&#23558;&#39118;&#38505;&#35780;&#20998;&#21576;&#29616;&#32473;&#27861;&#23448;&#25110;&#21307;&#29983;&#12290;&#28982;&#32780;&#65292;&#20915;&#31574;&#32773;&#21487;&#33021;&#19981;&#20165;&#20165;&#21482;&#38024;&#23545;&#31639;&#27861;&#25552;&#20379;&#30340;&#20449;&#24687;&#20570;&#20986;&#21453;&#24212;&#12290;&#20915;&#31574;&#32773;&#36824;&#21487;&#33021;&#23558;&#31639;&#27861;&#25512;&#33616;&#35270;&#20026;&#40664;&#35748;&#25805;&#20316;&#65292;&#20351;&#20854;&#38590;&#20197;&#20559;&#31163;&#65292;&#20363;&#22914;&#27861;&#23448;&#22312;&#23545;&#34987;&#21578;&#36827;&#34892;&#39640;&#39118;&#38505;&#35780;&#20272;&#30340;&#26102;&#20505;&#19981;&#24895;&#24847;&#25512;&#32763;&#65292;&#25110;&#21307;&#29983;&#25285;&#24515;&#20559;&#31163;&#25512;&#33616;&#30340;&#31243;&#24207;&#20250;&#24102;&#26469;&#21518;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#31639;&#27861;&#36741;&#21161;&#30340;&#36825;&#31181;&#24847;&#22806;&#21518;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#21512;&#20154;&#26426;&#20915;&#31574;&#30340;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#12290;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#31639;&#27861;&#25512;&#33616;&#23545;&#36873;&#25321;&#30340;&#24433;&#21709;&#21644;&#35774;&#35745;&#65292;&#36825;&#31181;&#24433;&#21709;&#19981;&#20165;&#20165;&#26159;&#36890;&#36807;&#25913;&#21464;&#20449;&#24565;&#65292;&#36824;&#36890;&#36807;&#25913;&#21464;&#20559;&#22909;&#12290;&#25105;&#20204;&#20174;&#21046;&#24230;&#22240;&#32032;&#21644;&#34892;&#20026;&#32463;&#27982;&#23398;&#20013;&#30340;&#24050;&#26377;&#27169;&#22411;&#31561;&#26041;&#38754;&#36827;&#34892;&#20102;&#36825;&#20010;&#20551;&#35774;&#30340;&#21160;&#26426;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
When an algorithm provides risk assessments, we typically think of them as helpful inputs to human decisions, such as when risk scores are presented to judges or doctors. However, a decision-maker may not only react to the information provided by the algorithm. The decision-maker may also view the algorithmic recommendation as a default action, making it costly for them to deviate, such as when a judge is reluctant to overrule a high-risk assessment for a defendant or a doctor fears the consequences of deviating from recommended procedures. To address such unintended consequences of algorithmic assistance, we propose a principal-agent model of joint human-machine decision-making. Within this model, we consider the effect and design of algorithmic recommendations when they affect choices not just by shifting beliefs, but also by altering preferences. We motivate this assumption from institutional factors, such as a desire to avoid audits, as well as from well-established models in behav
&lt;/p&gt;</description></item></channel></rss>