<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#30740;&#31350;&#20102;&#20855;&#26377;&#35821;&#20041;&#24847;&#35782;&#30340;&#36828;&#31243;&#22810;&#39532;&#23572;&#21487;&#22827;&#28304;&#20272;&#35745;&#30340;&#26368;&#20248;&#35843;&#24230;&#31574;&#30053;&#20197;&#21450;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31574;&#30053;&#25628;&#32034;&#31639;&#27861; Insec-RVI&#12290;</title><link>https://arxiv.org/abs/2403.16855</link><description>&lt;p&gt;
&#20855;&#26377;&#35821;&#20041;&#24847;&#35782;&#30340;&#36828;&#31243;&#22810;&#39532;&#23572;&#21487;&#22827;&#28304;&#20272;&#35745;&#22312;&#32422;&#26463;&#26465;&#20214;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Semantic-Aware Remote Estimation of Multiple Markov Sources Under Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16855
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20855;&#26377;&#35821;&#20041;&#24847;&#35782;&#30340;&#36828;&#31243;&#22810;&#39532;&#23572;&#21487;&#22827;&#28304;&#20272;&#35745;&#30340;&#26368;&#20248;&#35843;&#24230;&#31574;&#30053;&#20197;&#21450;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31574;&#30053;&#25628;&#32034;&#31639;&#27861; Insec-RVI&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20002;&#22833;&#21644;&#21463;&#36895;&#29575;&#38480;&#21046;&#30340;&#36890;&#36947;&#19978;&#23545;&#22810;&#20010;&#39532;&#23572;&#21487;&#22827;&#28304;&#36827;&#34892;&#35821;&#20041;&#24863;&#30693;&#36890;&#20449;&#30340;&#36828;&#31243;&#20272;&#35745;&#12290;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#23558;&#25152;&#26377;&#28304;&#29366;&#24577;&#35270;&#20026;&#30456;&#31561;&#19981;&#21516;&#65292;&#25105;&#20204;&#21033;&#29992;&#20449;&#24687;&#30340;&#35821;&#20041;&#24182;&#32771;&#34385;&#36828;&#31243;&#25191;&#34892;&#22120;&#23545;&#19981;&#21516;&#29366;&#24577;&#30340;&#20272;&#35745;&#35823;&#24046;&#20855;&#26377;&#19981;&#21516;&#30340;&#23481;&#24525;&#24230;&#12290;&#25105;&#20204;&#26088;&#22312;&#25214;&#21040;&#19968;&#20010;&#26368;&#20248;&#35843;&#24230;&#31574;&#30053;&#65292;&#20197;&#22312;&#20256;&#36755;&#39057;&#29575;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#20272;&#35745;&#35823;&#24046;&#30340;&#38271;&#26399;&#29366;&#24577;&#30456;&#20851;&#25104;&#26412;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#36890;&#36807;&#21033;&#29992;&#24179;&#22343;&#25104;&#26412;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDP&#65289;&#29702;&#35770;&#21644;Lagrange&#21160;&#24577;&#35268;&#21010;&#23637;&#31034;&#20102;&#26368;&#20248;&#31574;&#30053;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#20248;&#32467;&#26500;&#32467;&#26524;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31574;&#30053;&#25628;&#32034;&#31639;&#27861;&#65292;&#31216;&#20026;&#20132;&#21449;&#25628;&#32034;&#21152;&#30456;&#23545;&#20540;&#36845;&#20195;&#65288;Insec-RVI&#65289;&#65292;&#21487;&#20197;&#20165;&#36890;&#36807;&#23569;&#37327;&#36845;&#20195;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;&#20026;&#20102;&#36991;&#20813;&#8220;&#32500;&#24230;&#35781;&#21650;&#8221;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16855v1 Announce Type: cross  Abstract: This paper studies semantic-aware communication for remote estimation of multiple Markov sources over a lossy and rate-constrained channel. Unlike most existing studies that treat all source states equally, we exploit the semantics of information and consider that the remote actuator has different tolerances for the estimation errors of different states. We aim to find an optimal scheduling policy that minimizes the long-term state-dependent costs of estimation errors under a transmission frequency constraint. We theoretically show the structure of the optimal policy by leveraging the average-cost Constrained Markov Decision Process (CMDP) theory and the Lagrangian dynamic programming. By exploiting the optimal structural results, we develop a novel policy search algorithm, termed intersection search plus relative value iteration (Insec-RVI), that can find the optimal policy using only a few iterations. To avoid the ``curse of dimensio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26799;&#24230;&#25552;&#21319;&#31639;&#27861;&#23545;&#20083;&#33146;&#30284;&#36827;&#34892;&#20998;&#31867;&#65292;&#20851;&#27880;&#25552;&#39640;&#21484;&#22238;&#29575;&#65292;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#26816;&#27979;&#21644;&#39044;&#27979;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.09548</link><description>&lt;p&gt;
&#20351;&#29992;&#26799;&#24230;&#25552;&#21319;&#31639;&#27861;&#23545;&#20083;&#33146;&#30284;&#36827;&#34892;&#20998;&#31867;&#65292;&#37325;&#28857;&#20943;&#23569;&#20551;&#38452;&#24615;&#21644;&#20351;&#29992; SHAP &#36827;&#34892;&#35299;&#37322;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09548
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26799;&#24230;&#25552;&#21319;&#31639;&#27861;&#23545;&#20083;&#33146;&#30284;&#36827;&#34892;&#20998;&#31867;&#65292;&#20851;&#27880;&#25552;&#39640;&#21484;&#22238;&#29575;&#65292;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#26816;&#27979;&#21644;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30284;&#30151;&#26159;&#19990;&#30028;&#19978;&#22842;&#36208;&#26368;&#22810;&#22899;&#24615;&#29983;&#21629;&#30340;&#30142;&#30149;&#20043;&#19968;&#65292;&#20854;&#20013;&#20083;&#33146;&#30284;&#21344;&#25454;&#20102;&#30284;&#30151;&#30149;&#20363;&#21644;&#27515;&#20129;&#20154;&#25968;&#26368;&#39640;&#30340;&#20301;&#32622;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#26089;&#26399;&#26816;&#27979;&#21487;&#20197;&#39044;&#38450;&#20083;&#33146;&#30284;&#65292;&#20174;&#32780;&#36827;&#34892;&#26089;&#26399;&#27835;&#30103;&#12290;&#35768;&#22810;&#30740;&#31350;&#20851;&#27880;&#30340;&#26159;&#22312;&#30284;&#30151;&#39044;&#27979;&#20013;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#30340;&#27169;&#22411;&#65292;&#20294;&#26377;&#26102;&#20165;&#20381;&#38752;&#20934;&#30830;&#24615;&#21487;&#33021;&#24182;&#38750;&#22987;&#32456;&#21487;&#38752;&#12290;&#26412;&#30740;&#31350;&#23545;&#20351;&#29992;&#25552;&#21319;&#25216;&#26415;&#22522;&#20110;&#19981;&#21516;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#39044;&#27979;&#20083;&#33146;&#30284;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#35843;&#26597;&#24615;&#30740;&#31350;&#65292;&#37325;&#28857;&#20851;&#27880;&#21484;&#22238;&#29575;&#25351;&#26631;&#12290;&#25552;&#21319;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#24050;&#34987;&#35777;&#26126;&#26159;&#26816;&#27979;&#21307;&#23398;&#30142;&#30149;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;&#21033;&#29992;&#21152;&#24030;&#22823;&#23398;&#23572;&#28286;&#20998;&#26657; (UCI) &#25968;&#25454;&#38598;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;&#27169;&#22411;&#20998;&#31867;&#22120;&#36827;&#34892;&#35757;&#32451;&#65292;&#20854;&#20013;&#21253;&#21547;&#21508;&#33258;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09548v1 Announce Type: new  Abstract: Cancer is one of the diseases that kill the most women in the world, with breast cancer being responsible for the highest number of cancer cases and consequently deaths. However, it can be prevented by early detection and, consequently, early treatment. Any development for detection or perdition this kind of cancer is important for a better healthy life. Many studies focus on a model with high accuracy in cancer prediction, but sometimes accuracy alone may not always be a reliable metric. This study implies an investigative approach to studying the performance of different machine learning algorithms based on boosting to predict breast cancer focusing on the recall metric. Boosting machine learning algorithms has been proven to be an effective tool for detecting medical diseases. The dataset of the University of California, Irvine (UCI) repository has been utilized to train and test the model classifier that contains their attributes. Th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20174;&#32780;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;</title><link>https://arxiv.org/abs/2403.04082</link><description>&lt;p&gt;
&#36890;&#36807;&#25554;&#20540;&#36827;&#34892;&#25512;&#26029;&#65306;&#23545;&#27604;&#34920;&#31034;&#21487;&#35777;&#26126;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04082
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20174;&#32780;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#25105;&#20204;&#22914;&#20309;&#22238;&#31572;&#35832;&#22914;&#8220;&#26410;&#26469;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#8221;&#21644;&#8220;&#25105;&#20204;&#26159;&#22914;&#20309;&#21040;&#36798;&#36825;&#37324;&#30340;&#65311;&#8221;&#36825;&#31867;&#27010;&#29575;&#25512;&#26029;&#38382;&#39064;&#22312;&#35266;&#27979;&#20540;&#20026;&#39640;&#32500;&#26102;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#38382;&#39064;&#22914;&#20309;&#36890;&#36807;&#23398;&#20064;&#34920;&#31034;&#30340;&#32039;&#20945;&#38381;&#24335;&#35299;&#20915;&#26041;&#26696;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#23545;&#27604;&#23398;&#20064;&#30340;&#21464;&#20307;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#34920;&#26126;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#34920;&#31034;&#32534;&#30721;&#20102;&#27010;&#29575;&#27604;&#12290;&#36890;&#36807;&#23558;&#20043;&#21069;&#30340;&#24037;&#20316;&#25193;&#23637;&#20197;&#34920;&#26126;&#34920;&#31034;&#30340;&#36793;&#38469;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#65292;&#25105;&#20204;&#38543;&#21518;&#35777;&#26126;&#34920;&#31034;&#30340;&#32852;&#21512;&#20998;&#24067;&#20063;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#36825;&#20123;&#32467;&#26524;&#20849;&#21516;&#34920;&#26126;&#65292;&#36890;&#36807;&#26102;&#38388;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#19968;&#31181;&#22270;&#24418;&#27169;&#22411;&#65292;&#20854;&#20013;&#23545;&#34920;&#31034;&#36827;&#34892;&#30340;&#25512;&#26029;&#65288;&#20363;&#22914;&#39044;&#27979;&#12289;&#35268;&#21010;&#65289;&#23545;&#24212;&#20110;&#21453;&#28436;&#20302;&#32500;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04082v1 Announce Type: new  Abstract: Given time series data, how can we answer questions like "what will happen in the future?" and "how did we get here?" These sorts of probabilistic inference questions are challenging when observations are high-dimensional. In this paper, we show how these questions can have compact, closed form solutions in terms of learned representations. The key idea is to apply a variant of contrastive learning to time series data. Prior work already shows that the representations learned by contrastive learning encode a probability ratio. By extending prior work to show that the marginal distribution over representations is Gaussian, we can then prove that joint distribution of representations is also Gaussian. Taken together, these results show that representations learned via temporal contrastive learning follow a Gauss-Markov chain, a graphical model where inference (e.g., prediction, planning) over representations corresponds to inverting a low-
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#19981;&#21516;&#25968;&#25454;&#22495;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#65292;&#25512;&#27979;&#20102;&#27169;&#22411;&#23545;&#29305;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2402.12264</link><description>&lt;p&gt;
&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification in fine-tuned LLMs using LoRA ensembles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12264
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#19981;&#21516;&#25968;&#25454;&#22495;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#65292;&#25512;&#27979;&#20102;&#27169;&#22411;&#23545;&#29305;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#29305;&#23450;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#23613;&#31649;&#23545;&#20110;&#31934;&#35843;&#27169;&#22411;&#23398;&#21040;&#20102;&#20160;&#20040;&#12289;&#36951;&#24536;&#20102;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#20449;&#20219;&#20854;&#39044;&#27979;&#20173;&#28982;&#32570;&#20047;&#19968;&#20010;&#19968;&#33324;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#23545;&#31934;&#35843;LLMs&#36827;&#34892;&#22522;&#20110;&#21518;&#39564;&#36924;&#36817;&#30340;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;Mistral-7b&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#20102;&#19977;&#20010;&#24120;&#35265;&#30340;&#22810;&#39033;&#36873;&#25321;&#25968;&#25454;&#38598;&#65292;&#24182;&#23545;&#20854;&#22312;&#31934;&#35843;&#36807;&#31243;&#20013;&#21644;&#20043;&#21518;&#23545;&#19981;&#21516;&#30446;&#26631;&#39046;&#22495;&#30340;&#24863;&#30693;&#22797;&#26434;&#24615;&#21644;&#27169;&#22411;&#25928;&#33021;&#36827;&#34892;&#20102;&#23450;&#37327;&#21644;&#23450;&#24615;&#30340;&#32467;&#35770;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22522;&#20110;&#25968;&#20540;&#23454;&#39564;&#25903;&#25345;&#65292;&#25105;&#20204;&#23545;&#37027;&#20123;&#23545;&#20110;&#32473;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#29109;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#25552;&#20986;&#20102;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12264v1 Announce Type: cross  Abstract: Fine-tuning large language models can improve task specific performance, although a general understanding of what the fine-tuned model has learned, forgotten and how to trust its predictions is still missing. We derive principled uncertainty quantification for fine-tuned LLMs with posterior approximations using computationally efficient low-rank adaptation ensembles. We analyze three common multiple-choice datasets using low-rank adaptation ensembles based on Mistral-7b, and draw quantitative and qualitative conclusions on their perceived complexity and model efficacy on the different target domains during and after fine-tuning. In particular, backed by the numerical experiments, we hypothesise about signals from entropic uncertainty measures for data domains that are inherently difficult for a given architecture to learn.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#35760;&#24518;&#26680;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#24182;&#22312;Sobolev&#33539;&#25968;Loss&#20989;&#25968;&#21644;RKHS&#27491;&#21017;&#21270;&#19979;&#23454;&#29616;&#22238;&#24402;&#65292;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#25913;&#36827;&#24615;&#33021;&#65292;&#23545;&#27604;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11705</link><description>&lt;p&gt;
&#22312;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#23398;&#20064;&#35760;&#24518;&#26680;
&lt;/p&gt;
&lt;p&gt;
Learning Memory Kernels in Generalized Langevin Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11705
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#35760;&#24518;&#26680;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#24182;&#22312;Sobolev&#33539;&#25968;Loss&#20989;&#25968;&#21644;RKHS&#27491;&#21017;&#21270;&#19979;&#23454;&#29616;&#22238;&#24402;&#65292;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#25913;&#36827;&#24615;&#33021;&#65292;&#23545;&#27604;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#30340;&#35760;&#24518;&#26680;&#12290;&#35813;&#26041;&#27861;&#26368;&#21021;&#21033;&#29992;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20174;&#36712;&#36857;&#25968;&#25454;&#20013;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#65292;&#28982;&#21518;&#36890;&#36807;&#22522;&#20110;Sobolev&#33539;&#25968;&#30340;&#22238;&#24402;&#21644;RKHS&#27491;&#21017;&#21270;&#26469;&#36827;&#34892;&#22238;&#24402;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20445;&#35777;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#20102;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#26680;&#20272;&#35745;&#35823;&#24046;&#21463;&#25511;&#20110;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#31034;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30456;&#23545;&#20110;&#20381;&#36182;&#20110;$L^2$&#25439;&#22833;&#20989;&#25968;&#30340;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#20197;&#21450;&#20174;&#36870;&#25289;&#26222;&#25289;&#26031;&#21464;&#25442;&#25512;&#23548;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#65292;&#36825;&#20123;&#31034;&#20363;&#31361;&#26174;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#21508;&#31181;&#26435;&#37325;&#21442;&#25968;&#36873;&#25321;&#19978;&#30340;&#25345;&#32493;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21253;&#25324;&#21147;&#21644;&#28418;&#31227;&#39033;&#22312;&#26041;&#31243;&#20013;&#30340;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11705v1 Announce Type: cross  Abstract: We introduce a novel approach for learning memory kernels in Generalized Langevin Equations. This approach initially utilizes a regularized Prony method to estimate correlation functions from trajectory data, followed by regression over a Sobolev norm-based loss function with RKHS regularization. Our approach guarantees improved performance within an exponentially weighted $L^2$ space, with the kernel estimation error controlled by the error in estimated correlation functions. We demonstrate the superiority of our estimator compared to other regression estimators that rely on $L^2$ loss functions and also an estimator derived from the inverse Laplace transform, using numerical examples that highlight its consistent advantage across various weight parameter selections. Additionally, we provide examples that include the application of force and drift terms in the equation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#28145;&#24230;&#31639;&#23376;&#32593;&#32476;&#32467;&#26500;&#21551;&#21457;&#30340;&#20989;&#25968;SDE&#36817;&#20284;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#23454;&#29616;&#23545;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#35299;&#30340;&#36817;&#20284;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#20943;&#36731;&#25351;&#25968;&#32423;&#22797;&#26434;&#24230;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.03028</link><description>&lt;p&gt;
&#21463;&#28145;&#24230;&#31639;&#23376;&#32593;&#32476;&#32467;&#26500;&#21551;&#21457;&#30340;&#20989;&#25968;SDE&#36817;&#20284;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Functional SDE approximation inspired by a deep operator network architecture
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#28145;&#24230;&#31639;&#23376;&#32593;&#32476;&#32467;&#26500;&#21551;&#21457;&#30340;&#20989;&#25968;SDE&#36817;&#20284;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#23454;&#29616;&#23545;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#35299;&#30340;&#36817;&#20284;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#20943;&#36731;&#25351;&#25968;&#32423;&#22797;&#26434;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#35299;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#32467;&#26500;&#28789;&#24863;&#26469;&#33258;&#20110;&#28145;&#24230;&#31639;&#23376;&#32593;&#32476;&#65288;DeepONets&#65289;&#30340;&#27010;&#24565;&#65292;&#23427;&#22522;&#20110;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#31639;&#23376;&#23398;&#20064;&#65292;&#20197;&#21450;&#22312;&#32593;&#32476;&#20013;&#34920;&#31034;&#30340;&#38477;&#32500;&#22522;&#30784;&#12290;&#22312;&#25105;&#20204;&#30340;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#38543;&#26426;&#36807;&#31243;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#65288;PCE&#65289;&#65292;&#24182;&#23558;&#30456;&#24212;&#30340;&#26550;&#26500;&#31216;&#20026;SDEONet&#12290;&#22312;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#39046;&#22495;&#20013;&#65292;PCE&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;SDE&#20013;&#24182;&#38750;&#22914;&#27492;&#65292;&#20256;&#32479;&#30340;&#37319;&#26679;&#26041;&#27861;&#21344;&#20027;&#23548;&#22320;&#20301;&#65292;&#32780;&#21151;&#33021;&#24615;&#26041;&#27861;&#24456;&#23569;&#35265;&#12290;&#25130;&#26029;&#30340;PCE&#23384;&#22312;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#65292;&#21363;&#38543;&#30528;&#26368;&#22823;&#22810;&#39033;&#24335;&#38454;&#25968;&#21644;&#22522;&#20989;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#20998;&#37327;&#30340;&#25968;&#37327;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#25152;&#25552;&#20986;&#30340;SDEONet&#32467;&#26500;&#26088;&#22312;&#36890;&#36807;&#23398;&#20064;&#26469;&#20943;&#36731;&#25351;&#25968;&#32423;&#22797;&#26434;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A novel approach to approximate solutions of Stochastic Differential Equations (SDEs) by Deep Neural Networks is derived and analysed. The architecture is inspired by the notion of Deep Operator Networks (DeepONets), which is based on operator learning in function spaces in terms of a reduced basis also represented in the network. In our setting, we make use of a polynomial chaos expansion (PCE) of stochastic processes and call the corresponding architecture SDEONet. The PCE has been used extensively in the area of uncertainty quantification (UQ) with parametric partial differential equations. This however is not the case with SDE, where classical sampling methods dominate and functional approaches are seen rarely. A main challenge with truncated PCEs occurs due to the drastic growth of the number of components with respect to the maximum polynomial degree and the number of basis elements. The proposed SDEONet architecture aims to alleviate the issue of exponential complexity by learni
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#65292;&#37327;&#23376;&#26550;&#26500;&#25628;&#32034;&#65288;QAS&#65289;&#30340;&#24615;&#33021;&#21487;&#20197;&#24471;&#20197;&#25552;&#21319;&#65292;&#32780;&#19981;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#26102;&#38388;&#36827;&#34892;&#26631;&#35760;&#12290;</title><link>https://arxiv.org/abs/2401.11576</link><description>&lt;p&gt;
&#21033;&#29992;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#36827;&#34892;&#37327;&#23376;&#26550;&#26500;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Quantum Architecture Search with Unsupervised Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.11576
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#65292;&#37327;&#23376;&#26550;&#26500;&#25628;&#32034;&#65288;QAS&#65289;&#30340;&#24615;&#33021;&#21487;&#20197;&#24471;&#20197;&#25552;&#21319;&#65292;&#32780;&#19981;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#26102;&#38388;&#36827;&#34892;&#26631;&#35760;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#36827;&#34892;&#37327;&#23376;&#26550;&#26500;&#25628;&#32034;&#65288;QAS&#65289;&#20195;&#34920;&#20102;&#19968;&#31181;&#21069;&#27839;&#26041;&#27861;&#65292;&#26377;&#26395;&#22312;&#22024;&#26434;&#30340;&#20013;&#38388;&#35268;&#27169;&#37327;&#23376;&#65288;NISQ&#65289;&#35774;&#22791;&#19978;&#23454;&#29616;&#28508;&#22312;&#30340;&#37327;&#23376;&#20248;&#21183;&#12290;&#22823;&#22810;&#25968;QAS&#31639;&#27861;&#23558;&#23427;&#20204;&#30340;&#25628;&#32034;&#31354;&#38388;&#21644;&#25628;&#32034;&#31639;&#27861;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#22240;&#27492;&#36890;&#24120;&#38656;&#35201;&#22312;&#25628;&#32034;&#36807;&#31243;&#20013;&#35780;&#20272;&#22823;&#37327;&#30340;&#37327;&#23376;&#30005;&#36335;&#12290;&#22522;&#20110;&#39044;&#27979;&#30340;QAS&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#30452;&#25509;&#26681;&#25454;&#30005;&#36335;&#32467;&#26500;&#20272;&#35745;&#30005;&#36335;&#30340;&#24615;&#33021;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#39640;&#24615;&#33021;&#30340;&#39044;&#27979;&#22120;&#36890;&#24120;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#26102;&#38388;&#36827;&#34892;&#26631;&#35760;&#65292;&#20197;&#33719;&#24471;&#22823;&#37327;&#24102;&#26631;&#31614;&#30340;&#37327;&#23376;&#30005;&#36335;&#12290;&#26368;&#36817;&#65292;&#19968;&#20010;&#32463;&#20856;&#30340;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31639;&#27861;Arch2vec&#21551;&#21457;&#25105;&#20204;&#65292;&#34920;&#26126;&#26550;&#26500;&#25628;&#32034;&#21487;&#20197;&#20174;&#23558;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#19982;&#25628;&#32034;&#36807;&#31243;&#20998;&#31163;&#20013;&#33719;&#30410;&#12290;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#26159;&#21542;&#33021;&#24110;&#21161;QAS
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.11576v2 Announce Type: replace-cross  Abstract: Utilizing unsupervised representation learning for quantum architecture search (QAS) represents a cutting-edge approach poised to realize potential quantum advantage on Noisy Intermediate-Scale Quantum (NISQ) devices. Most QAS algorithms combine their search space and search algorithms together and thus generally require evaluating a large number of quantum circuits during the search process. Predictor-based QAS algorithms can alleviate this problem by directly estimating the performance of circuits according to their structures. However, a high-performance predictor generally requires very time-consuming labeling to obtain a large number of labeled quantum circuits. Recently, a classical neural architecture search algorithm Arch2vec inspires us by showing that architecture search can benefit from decoupling unsupervised representation learning from the search process. Whether unsupervised representation learning can help QAS w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QUAVE&#30340;&#22235;&#20803;&#25968;&#23567;&#27874;&#32593;&#32476;&#65292;&#21487;&#20197;&#20174;&#21307;&#23398;&#22270;&#20687;&#20013;&#25552;&#21462;&#26174;&#33879;&#29305;&#24449;&#12290;&#35813;&#32593;&#32476;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#25110;&#32508;&#21512;&#20219;&#21153;&#32467;&#21512;&#20351;&#29992;&#65292;&#24182;&#25512;&#24191;&#20102;&#23545;&#21333;&#36890;&#36947;&#25968;&#25454;&#30340;&#37319;&#29992;&#12290;&#36890;&#36807;&#22235;&#20803;&#25968;&#23567;&#27874;&#21464;&#25442;&#21644;&#21152;&#26435;&#22788;&#29702;&#65292;QUAVE&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#36739;&#22823;&#21464;&#21270;&#30340;&#21307;&#23398;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2310.10224</link><description>&lt;p&gt;
&#36890;&#36807;&#22235;&#20803;&#25968;&#23567;&#27874;&#32593;&#32476;&#25512;&#24191;&#21307;&#23398;&#22270;&#20687;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Generalizing Medical Image Representations via Quaternion Wavelet Networks. (arXiv:2310.10224v2 [eess.IV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QUAVE&#30340;&#22235;&#20803;&#25968;&#23567;&#27874;&#32593;&#32476;&#65292;&#21487;&#20197;&#20174;&#21307;&#23398;&#22270;&#20687;&#20013;&#25552;&#21462;&#26174;&#33879;&#29305;&#24449;&#12290;&#35813;&#32593;&#32476;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#25110;&#32508;&#21512;&#20219;&#21153;&#32467;&#21512;&#20351;&#29992;&#65292;&#24182;&#25512;&#24191;&#20102;&#23545;&#21333;&#36890;&#36947;&#25968;&#25454;&#30340;&#37319;&#29992;&#12290;&#36890;&#36807;&#22235;&#20803;&#25968;&#23567;&#27874;&#21464;&#25442;&#21644;&#21152;&#26435;&#22788;&#29702;&#65292;QUAVE&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#36739;&#22823;&#21464;&#21270;&#30340;&#21307;&#23398;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#26469;&#33258;&#19981;&#21516;&#26469;&#28304;&#21644;&#21508;&#31181;&#20219;&#21153;&#30340;&#25968;&#25454;&#38598;&#26085;&#30410;&#22686;&#21152;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#25104;&#20026;&#19968;&#20010;&#24191;&#27867;&#30740;&#31350;&#30340;&#39046;&#22495;&#12290;&#24403;&#22788;&#29702;&#21307;&#23398;&#25968;&#25454;&#26102;&#65292;&#36825;&#20010;&#38382;&#39064;&#23588;&#20026;&#24191;&#27867;&#65292;&#22240;&#20026;&#32570;&#20047;&#26041;&#27861;&#35770;&#26631;&#20934;&#23548;&#33268;&#19981;&#21516;&#30340;&#25104;&#20687;&#20013;&#24515;&#25110;&#20351;&#29992;&#19981;&#21516;&#35774;&#22791;&#21644;&#36741;&#21161;&#22240;&#32032;&#33719;&#21462;&#30340;&#25968;&#25454;&#23384;&#22312;&#36739;&#22823;&#21464;&#21270;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#26222;&#36866;&#30340;&#12289;&#25968;&#25454;-&#21644;&#20219;&#21153;&#19981;&#21487;&#30693;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#20174;&#21307;&#23398;&#22270;&#20687;&#20013;&#25552;&#21462;&#26174;&#33879;&#29305;&#24449;&#12290;&#25152;&#25552;&#20986;&#30340;&#22235;&#20803;&#25968;&#23567;&#27874;&#32593;&#32476;&#65288;QUAVE&#65289;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#19982;&#20219;&#20309;&#29616;&#26377;&#30340;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#25110;&#32508;&#21512;&#20219;&#21153;&#30456;&#32467;&#21512;&#65292;&#24182;&#19988;&#21487;&#20197;&#32467;&#21512;&#23454;&#38469;&#12289;&#22235;&#20803;&#25968;&#25110;&#36229;&#22797;&#20540;&#27169;&#22411;&#65292;&#25512;&#24191;&#23427;&#20204;&#23545;&#21333;&#36890;&#36947;&#25968;&#25454;&#30340;&#37319;&#29992;&#12290;QUAVE&#39318;&#20808;&#36890;&#36807;&#22235;&#20803;&#25968;&#23567;&#27874;&#21464;&#25442;&#25552;&#21462;&#19981;&#21516;&#30340;&#23376;&#24102;&#65292;&#24471;&#21040;&#20302;&#39057;/&#36817;&#20284;&#39057;&#24102;&#21644;&#39640;&#39057;/&#32454;&#31890;&#24230;&#29305;&#24449;&#12290;&#28982;&#21518;&#65292;&#23427;&#23545;&#26368;&#26377;&#20195;&#34920;&#24615;&#30340;&#29305;&#24449;&#36827;&#34892;&#21152;&#26435;&#22788;&#29702;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#29305;&#24449;&#37325;&#35201;&#24615;&#19981;&#22343;&#21248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network generalizability is becoming a broad research field due to the increasing availability of datasets from different sources and for various tasks. This issue is even wider when processing medical data, where a lack of methodological standards causes large variations being provided by different imaging centers or acquired with various devices and cofactors. To overcome these limitations, we introduce a novel, generalizable, data- and task-agnostic framework able to extract salient features from medical images. The proposed quaternion wavelet network (QUAVE) can be easily integrated with any pre-existing medical image analysis or synthesis task, and it can be involved with real, quaternion, or hypercomplex-valued models, generalizing their adoption to single-channel data. QUAVE first extracts different sub-bands through the quaternion wavelet transform, resulting in both low-frequency/approximation bands and high-frequency/fine-grained features. Then, it weighs the most repr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;SpikeCLIP&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#23454;&#29616;&#20102;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#27169;&#24577;&#25193;&#23637;&#65292;&#24182;&#22312;&#33021;&#28304;&#25928;&#29575;&#21644;&#24615;&#33021;&#26041;&#38754;&#21462;&#24471;&#20102;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.06488</link><description>&lt;p&gt;
SpikeCLIP&#65306;&#19968;&#31181;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network. (arXiv:2310.06488v2 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;SpikeCLIP&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#23454;&#29616;&#20102;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#27169;&#24577;&#25193;&#23637;&#65292;&#24182;&#22312;&#33021;&#28304;&#25928;&#29575;&#21644;&#24615;&#33021;&#26041;&#38754;&#21462;&#24471;&#20102;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#24050;&#32463;&#35777;&#26126;&#20854;&#22312;&#35270;&#35273;&#21644;&#35821;&#35328;&#39046;&#22495;&#20013;&#33021;&#22815;&#23454;&#29616;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20855;&#26377;&#33021;&#25928;&#25552;&#39640;&#21644;&#31526;&#21512;&#29983;&#29289;&#21512;&#29702;&#24615;&#30340;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#23558;&#36825;&#31181;&#21333;&#27169;&#24577;&#30340;SNNs&#25193;&#23637;&#21040;&#22810;&#27169;&#24577;&#30340;&#24773;&#26223;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#24320;&#21457;&#30340;&#39046;&#22495;&#12290;&#21463;&#21040;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#65288;CLIP&#65289;&#27010;&#24565;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;SpikeCLIP&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#8220;&#23545;&#40784;&#39044;&#35757;&#32451;+&#21452;&#25439;&#22833;&#24494;&#35843;&#8221;&#30340;&#20004;&#27493;&#39588;&#37197;&#26041;&#65292;&#26469;&#35299;&#20915;&#33033;&#20914;&#35745;&#31639;&#32972;&#26223;&#19979;&#20004;&#31181;&#27169;&#24577;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#24120;&#29992;&#30340;&#29992;&#20110;&#22810;&#27169;&#24577;&#27169;&#22411;&#35780;&#20272;&#30340;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#65292;SNNs&#21462;&#24471;&#20102;&#19982;&#20854;DNNs&#23545;&#24212;&#29289;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#26174;&#33879;&#38477;&#20302;&#20102;&#33021;&#28304;&#28040;&#32791;&#12290;&#27492;&#22806;&#65292;SpikeCLIP&#22312;&#22270;&#20687;&#20998;&#31867;&#26041;&#38754;&#20445;&#25345;&#20102;&#31283;&#23450;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spiking neural networks (SNNs) have demonstrated the capability to achieve comparable performance to deep neural networks (DNNs) in both visual and linguistic domains while offering the advantages of improved energy efficiency and adherence to biological plausibility. However, the extension of such single-modality SNNs into the realm of multimodal scenarios remains an unexplored territory. Drawing inspiration from the concept of contrastive language-image pre-training (CLIP), we introduce a novel framework, named SpikeCLIP, to address the gap between two modalities within the context of spike-based computing through a two-step recipe involving ``Alignment Pre-training + Dual-Loss Fine-tuning". Extensive experiments demonstrate that SNNs achieve comparable results to their DNN counterparts while significantly reducing energy consumption across a variety of datasets commonly used for multimodal model evaluation. Furthermore, SpikeCLIP maintains robust performance in image classification 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;HurriCast&#65292;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24314;&#27169;&#30340;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#32452;&#21512;ARIMA&#27169;&#22411;&#21644;K-MEANS&#31639;&#27861;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#39123;&#39118;&#36235;&#21183;&#65292;&#24182;&#32467;&#21512;Autoencoder&#36827;&#34892;&#25913;&#36827;&#30340;&#39123;&#39118;&#27169;&#25311;&#65292;&#20174;&#32780;&#26377;&#25928;&#27169;&#25311;&#21382;&#21490;&#39123;&#39118;&#34892;&#20026;&#24182;&#25552;&#20379;&#35814;&#32454;&#30340;&#26410;&#26469;&#39044;&#27979;&#12290;&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#20840;&#38754;&#19988;&#26377;&#36873;&#25321;&#24615;&#30340;&#25968;&#25454;&#38598;&#65292;&#20016;&#23500;&#20102;&#23545;&#39123;&#39118;&#27169;&#24335;&#30340;&#29702;&#35299;&#65292;&#24182;&#20026;&#39118;&#38505;&#31649;&#29702;&#31574;&#30053;&#25552;&#20379;&#20102;&#21487;&#25805;&#20316;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2309.07174</link><description>&lt;p&gt;
HurriCast&#65306;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24314;&#27169;&#30340;&#33258;&#21160;&#21270;&#26694;&#26550;&#29992;&#20110;&#39123;&#39118;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
HurriCast: An Automatic Framework Using Machine Learning and Statistical Modeling for Hurricane Forecasting. (arXiv:2309.07174v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07174
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;HurriCast&#65292;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24314;&#27169;&#30340;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#32452;&#21512;ARIMA&#27169;&#22411;&#21644;K-MEANS&#31639;&#27861;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#39123;&#39118;&#36235;&#21183;&#65292;&#24182;&#32467;&#21512;Autoencoder&#36827;&#34892;&#25913;&#36827;&#30340;&#39123;&#39118;&#27169;&#25311;&#65292;&#20174;&#32780;&#26377;&#25928;&#27169;&#25311;&#21382;&#21490;&#39123;&#39118;&#34892;&#20026;&#24182;&#25552;&#20379;&#35814;&#32454;&#30340;&#26410;&#26469;&#39044;&#27979;&#12290;&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#20840;&#38754;&#19988;&#26377;&#36873;&#25321;&#24615;&#30340;&#25968;&#25454;&#38598;&#65292;&#20016;&#23500;&#20102;&#23545;&#39123;&#39118;&#27169;&#24335;&#30340;&#29702;&#35299;&#65292;&#24182;&#20026;&#39118;&#38505;&#31649;&#29702;&#31574;&#30053;&#25552;&#20379;&#20102;&#21487;&#25805;&#20316;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39123;&#39118;&#30001;&#20110;&#20854;&#28798;&#23475;&#24615;&#24433;&#21709;&#32780;&#22312;&#32654;&#22269;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#24456;&#37325;&#35201;&#65292;&#20445;&#38505;&#19994;&#22312;&#36825;&#26041;&#38754;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#20351;&#29992;&#22797;&#26434;&#30340;&#32479;&#35745;&#27169;&#22411;&#36827;&#34892;&#39118;&#38505;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#24120;&#24120;&#24573;&#35270;&#20851;&#38190;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#39123;&#39118;&#27169;&#24335;&#65292;&#24182;&#21463;&#21040;&#25968;&#25454;&#31232;&#32570;&#30340;&#38480;&#21046;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#26041;&#27861;&#65292;&#23558;ARIMA&#27169;&#22411;&#21644;K-MEANS&#30456;&#32467;&#21512;&#65292;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#39123;&#39118;&#36235;&#21183;&#65292;&#24182;&#20351;&#29992;Autoencoder&#36827;&#34892;&#25913;&#36827;&#30340;&#39123;&#39118;&#27169;&#25311;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#28151;&#21512;&#26041;&#27861;&#26377;&#25928;&#22320;&#27169;&#25311;&#20102;&#21382;&#21490;&#39123;&#39118;&#34892;&#20026;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#28508;&#22312;&#26410;&#26469;&#36335;&#24452;&#21644;&#24378;&#24230;&#30340;&#35814;&#32454;&#39044;&#27979;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#21033;&#29992;&#20840;&#38754;&#32780;&#26377;&#36873;&#25321;&#24615;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#30340;&#27169;&#25311;&#20016;&#23500;&#20102;&#23545;&#39123;&#39118;&#27169;&#24335;&#30340;&#24403;&#21069;&#29702;&#35299;&#65292;&#24182;&#20026;&#39118;&#38505;&#31649;&#29702;&#31574;&#30053;&#25552;&#20379;&#20102;&#21487;&#25805;&#20316;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hurricanes present major challenges in the U.S. due to their devastating impacts. Mitigating these risks is important, and the insurance industry is central in this effort, using intricate statistical models for risk assessment. However, these models often neglect key temporal and spatial hurricane patterns and are limited by data scarcity. This study introduces a refined approach combining the ARIMA model and K-MEANS to better capture hurricane trends, and an Autoencoder for enhanced hurricane simulations. Our experiments show that this hybrid methodology effectively simulate historical hurricane behaviors while providing detailed projections of potential future trajectories and intensities. Moreover, by leveraging a comprehensive yet selective dataset, our simulations enrich the current understanding of hurricane patterns and offer actionable insights for risk management strategies.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Adversarial ModSecurity&#65292;&#23427;&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#26469;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#38450;&#28779;&#22681;&#12290;&#36890;&#36807;&#23558;&#26680;&#24515;&#35268;&#21017;&#38598;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#35782;&#21035;&#24182;&#38450;&#24481;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AdvModSec&#22312;&#35757;&#32451;&#21518;&#33021;&#22815;&#26377;&#25928;&#22320;&#24212;&#23545;&#36825;&#31867;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2308.04964</link><description>&lt;p&gt;
Adversarial ModSecurity: &#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning. (arXiv:2308.04964v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04964
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Adversarial ModSecurity&#65292;&#23427;&#26159;&#19968;&#20010;&#20351;&#29992;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#26469;&#23545;&#25239;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#38450;&#28779;&#22681;&#12290;&#36890;&#36807;&#23558;&#26680;&#24515;&#35268;&#21017;&#38598;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#35782;&#21035;&#24182;&#38450;&#24481;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AdvModSec&#22312;&#35757;&#32451;&#21518;&#33021;&#22815;&#26377;&#25928;&#22320;&#24212;&#23545;&#36825;&#31867;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ModSecurity&#34987;&#24191;&#27867;&#35748;&#21487;&#20026;&#26631;&#20934;&#30340;&#24320;&#28304;Web&#24212;&#29992;&#38450;&#28779;&#22681;(WAF)&#65292;&#30001;OWASP&#22522;&#37329;&#20250;&#32500;&#25252;&#12290;&#23427;&#36890;&#36807;&#19982;&#26680;&#24515;&#35268;&#21017;&#38598;&#36827;&#34892;&#21305;&#37197;&#26469;&#26816;&#27979;&#24694;&#24847;&#35831;&#27714;&#65292;&#35782;&#21035;&#20986;&#24120;&#35265;&#30340;&#25915;&#20987;&#27169;&#24335;&#12290;&#27599;&#20010;&#35268;&#21017;&#22312;CRS&#20013;&#37117;&#34987;&#25163;&#21160;&#20998;&#37197;&#19968;&#20010;&#26435;&#37325;&#65292;&#22522;&#20110;&#30456;&#24212;&#25915;&#20987;&#30340;&#20005;&#37325;&#31243;&#24230;&#65292;&#22914;&#26524;&#35302;&#21457;&#35268;&#21017;&#30340;&#26435;&#37325;&#20043;&#21644;&#36229;&#36807;&#32473;&#23450;&#30340;&#38408;&#20540;&#65292;&#23601;&#20250;&#34987;&#26816;&#27979;&#20026;&#24694;&#24847;&#35831;&#27714;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#31616;&#21333;&#30340;&#31574;&#30053;&#22312;&#26816;&#27979;SQL&#27880;&#20837;&#25915;&#20987;&#26041;&#38754;&#24456;&#19981;&#26377;&#25928;&#65292;&#22240;&#20026;&#23427;&#24448;&#24448;&#20250;&#38459;&#27490;&#35768;&#22810;&#21512;&#27861;&#35831;&#27714;&#65292;&#21516;&#26102;&#36824;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#21363;&#25925;&#24847;&#25805;&#32437;&#20197;&#36867;&#36991;&#26816;&#27979;&#30340;&#25915;&#20987;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026;AdvModSec&#30340;&#24378;&#22823;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#23558;CRS&#35268;&#21017;&#20316;&#20026;&#36755;&#20837;&#29305;&#24449;&#65292;&#24182;&#32463;&#36807;&#35757;&#32451;&#20197;&#26816;&#27979;&#23545;&#25239;&#24615;SQL&#27880;&#20837;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;AdvModSec&#22312;&#38024;&#23545;&#35813;&#25915;&#20987;&#30340;&#27969;&#37327;&#19978;&#36827;&#34892;&#35757;&#32451;&#21518;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
ModSecurity is widely recognized as the standard open-source Web Application Firewall (WAF), maintained by the OWASP Foundation. It detects malicious requests by matching them against the Core Rule Set, identifying well-known attack patterns. Each rule in the CRS is manually assigned a weight, based on the severity of the corresponding attack, and a request is detected as malicious if the sum of the weights of the firing rules exceeds a given threshold. In this work, we show that this simple strategy is largely ineffective for detecting SQL injection (SQLi) attacks, as it tends to block many legitimate requests, while also being vulnerable to adversarial SQLi attacks, i.e., attacks intentionally manipulated to evade detection. To overcome these issues, we design a robust machine learning model, named AdvModSec, which uses the CRS rules as input features, and it is trained to detect adversarial SQLi attacks. Our experiments show that AdvModSec, being trained on the traffic directed towa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#35299;&#20915;&#37327;&#23376;&#35745;&#31639;&#20013;&#30340;&#20445;&#30495;&#24230;&#38382;&#39064;&#65292;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#39044;&#27979;&#37327;&#23376;&#30005;&#36335;&#30340;&#20445;&#30495;&#24230;&#12290;</title><link>http://arxiv.org/abs/2303.17523</link><description>&lt;p&gt;
&#21033;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#25552;&#39640;&#37327;&#23376;&#30005;&#36335;&#20445;&#30495;&#24230;
&lt;/p&gt;
&lt;p&gt;
Quantum Circuit Fidelity Improvement with Long Short-Term Memory Networks. (arXiv:2303.17523v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17523
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#35299;&#20915;&#37327;&#23376;&#35745;&#31639;&#20013;&#30340;&#20445;&#30495;&#24230;&#38382;&#39064;&#65292;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#39044;&#27979;&#37327;&#23376;&#30005;&#36335;&#30340;&#20445;&#30495;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#35745;&#31639;&#24050;&#36827;&#20837;&#22122;&#22768;&#20013;&#38388;&#35268;&#27169;&#37327;&#23376;&#65288;NISQ&#65289;&#26102;&#20195;&#65292;&#30446;&#21069;&#25105;&#20204;&#25317;&#26377;&#30340;&#37327;&#23376;&#22788;&#29702;&#22120;&#23545;&#36752;&#23556;&#21644;&#28201;&#24230;&#31561;&#29615;&#22659;&#21464;&#37327;&#25935;&#24863;&#65292;&#22240;&#27492;&#20250;&#20135;&#29983;&#22024;&#26434;&#30340;&#36755;&#20986;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#35768;&#22810;&#31639;&#27861;&#21644;&#24212;&#29992;&#31243;&#24207;&#29992;&#20110;NISQ&#22788;&#29702;&#22120;&#65292;&#20294;&#25105;&#20204;&#20173;&#38754;&#20020;&#30528;&#35299;&#37322;&#20854;&#22024;&#26434;&#32467;&#26524;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23545;&#25152;&#36873;&#25321;&#30340;&#37327;&#23376;&#24577;&#26377;&#22810;&#23569;&#20449;&#24515;&#65311;&#36825;&#31181;&#20449;&#24515;&#24456;&#37325;&#35201;&#65292;&#22240;&#20026;NISQ&#35745;&#31639;&#26426;&#23558;&#36755;&#20986;&#20854;&#37327;&#23376;&#20301;&#27979;&#37327;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#26377;&#26102;&#24456;&#38590;&#21306;&#20998;&#20998;&#24067;&#26159;&#21542;&#34920;&#31034;&#26377;&#24847;&#20041;&#30340;&#35745;&#31639;&#25110;&#21482;&#26159;&#38543;&#26426;&#22122;&#22768;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#37327;&#23376;&#30005;&#36335;&#20445;&#30495;&#24230;&#39044;&#27979;&#26694;&#26550;&#20026;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#38382;&#39064;&#65292;&#22240;&#27492;&#21487;&#20197;&#21033;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#31070;&#32463;&#32593;&#32476;&#30340;&#24378;&#22823;&#33021;&#21147;&#12290;&#19968;&#20010;&#23436;&#25972;&#30340;&#24037;&#20316;&#27969;&#31243;&#26469;&#26500;&#24314;&#35757;&#32451;&#30005;&#36335;
&lt;/p&gt;
&lt;p&gt;
Quantum computing has entered the Noisy Intermediate-Scale Quantum (NISQ) era. Currently, the quantum processors we have are sensitive to environmental variables like radiation and temperature, thus producing noisy outputs. Although many proposed algorithms and applications exist for NISQ processors, we still face uncertainties when interpreting their noisy results. Specifically, how much confidence do we have in the quantum states we are picking as the output? This confidence is important since a NISQ computer will output a probability distribution of its qubit measurements, and it is sometimes hard to distinguish whether the distribution represents meaningful computation or just random noise. This paper presents a novel approach to attack this problem by framing quantum circuit fidelity prediction as a Time Series Forecasting problem, therefore making it possible to utilize the power of Long Short-Term Memory (LSTM) neural networks. A complete workflow to build the training circuit d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23545;&#23545;&#35937;&#36712;&#36857;&#34920;&#31034;&#27169;&#22411;&#30340;&#22797;&#26434;&#24230;&#21644;&#25311;&#21512;&#35823;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#36827;&#34892;&#20102;&#32463;&#39564;&#20998;&#26512;&#65292;&#21457;&#29616;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#23601;&#33021;&#22815;&#39640;&#24230;&#37325;&#29616;&#30495;&#23454;&#19990;&#30028;&#30340;&#36712;&#36857;&#65292;&#36890;&#36807;&#20351;&#29992;&#32463;&#39564;&#36125;&#21494;&#26031;&#26041;&#27861;&#21487;&#20197;&#20026;&#36712;&#36857;&#36319;&#36394;&#38382;&#39064;&#20013;&#24517;&#35201;&#30340;&#36816;&#21160;&#27169;&#22411;&#25552;&#20379;&#20449;&#24687;&#65292;&#24182;&#21487;&#20197;&#24110;&#21161;&#35268;&#33539;&#39044;&#27979;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.01696</link><description>&lt;p&gt;
&#23545;&#35937;&#36712;&#36857;&#34920;&#31034;&#27169;&#22411;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Empirical Bayes Analysis of Object Trajectory Representation Models. (arXiv:2211.01696v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01696
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23545;&#23545;&#35937;&#36712;&#36857;&#34920;&#31034;&#27169;&#22411;&#30340;&#22797;&#26434;&#24230;&#21644;&#25311;&#21512;&#35823;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#36827;&#34892;&#20102;&#32463;&#39564;&#20998;&#26512;&#65292;&#21457;&#29616;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#23601;&#33021;&#22815;&#39640;&#24230;&#37325;&#29616;&#30495;&#23454;&#19990;&#30028;&#30340;&#36712;&#36857;&#65292;&#36890;&#36807;&#20351;&#29992;&#32463;&#39564;&#36125;&#21494;&#26031;&#26041;&#27861;&#21487;&#20197;&#20026;&#36712;&#36857;&#36319;&#36394;&#38382;&#39064;&#20013;&#24517;&#35201;&#30340;&#36816;&#21160;&#27169;&#22411;&#25552;&#20379;&#20449;&#24687;&#65292;&#24182;&#21487;&#20197;&#24110;&#21161;&#35268;&#33539;&#39044;&#27979;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#23545;&#35937;&#36712;&#36857;&#24314;&#27169;&#20013;&#30340;&#27169;&#22411;&#22797;&#26434;&#24230;&#21644;&#25311;&#21512;&#35823;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#32463;&#39564;&#20998;&#26512;&#12290;&#36890;&#36807;&#20998;&#26512;&#22810;&#20010;&#22823;&#22411;&#20844;&#20849;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#21457;&#29616;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#22312;&#30456;&#20851;&#26102;&#38388;&#33539;&#22260;&#20869;&#20351;&#29992;&#36739;&#23569;&#30340;&#27169;&#22411;&#22797;&#26434;&#24230;&#23601;&#33021;&#22815;&#39640;&#24230;&#37325;&#29616;&#30495;&#23454;&#19990;&#30028;&#30340;&#36712;&#36857;&#12290;&#36825;&#19968;&#21457;&#29616;&#20801;&#35768;&#23558;&#36712;&#36857;&#36319;&#36394;&#21644;&#39044;&#27979;&#20316;&#20026;&#36125;&#21494;&#26031;&#36807;&#28388;&#38382;&#39064;&#36827;&#34892;&#20844;&#24335;&#21270;&#12290;&#25105;&#20204;&#37319;&#29992;&#32463;&#39564;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#36825;&#20123;&#20808;&#39564;&#20998;&#24067;&#21487;&#20197;&#20026;&#36712;&#36857;&#36319;&#36394;&#38382;&#39064;&#20013;&#24517;&#35201;&#30340;&#36816;&#21160;&#27169;&#22411;&#25552;&#20379;&#20449;&#24687;&#65292;&#24182;&#21487;&#20197;&#24110;&#21161;&#35268;&#33539;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#20027;&#24352;&#22312;&#36712;&#36857;&#39044;&#27979;&#20219;&#21153;&#20013;&#20351;&#29992;&#32447;&#24615;&#36712;&#36857;&#34920;&#31034;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20204;&#30446;&#21069;&#24182;&#19981;&#20250;&#38480;&#21046;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an in-depth empirical analysis of the trade-off between model complexity and fit error in modelling object trajectories. Analyzing several large public datasets, we show that simple linear models do represent real-world trajectories with high fidelity over relevant time scales at very moderate model complexity. This finding allows the formulation of trajectory tracking and prediction as a Bayesian filtering problem. Using an Empirical Bayes approach, we estimate prior distributions over model parameters from the data. These prior distributions inform the motion models necessary in the trajectory tracking problem and can help regularize prediction models. We argue for the use of linear trajectory representation models in trajectory prediction tasks as they do not limit prediction performance currently.
&lt;/p&gt;</description></item></channel></rss>