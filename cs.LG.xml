<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#36229;&#20248;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#25104;&#21151;&#39044;&#27979;&#26377;&#26426;&#22826;&#38451;&#33021;&#30005;&#27744;&#25928;&#29575;&#36864;&#21270;&#65292;&#20934;&#30830;&#24230;&#39640;&#19988;&#20855;&#26377;&#23454;&#29992;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2404.00173</link><description>&lt;p&gt;
&#27604;&#36739;&#36229;&#20248;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20197;&#39044;&#27979;&#26377;&#26426;&#22826;&#38451;&#33021;&#30005;&#27744;&#25928;&#29575;&#36864;&#21270;
&lt;/p&gt;
&lt;p&gt;
Comparing Hyper-optimized Machine Learning Models for Predicting Efficiency Degradation in Organic Solar Cells
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00173
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#36229;&#20248;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#25104;&#21151;&#39044;&#27979;&#26377;&#26426;&#22826;&#38451;&#33021;&#30005;&#27744;&#25928;&#29575;&#36864;&#21270;&#65292;&#20934;&#30830;&#24230;&#39640;&#19988;&#20855;&#26377;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#20248;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#65292;&#26469;&#34920;&#31034;&#22810;&#23618;&#32467;&#26500;ITO/PEDOT:PSS/P3HT:PCBM/Al&#32858;&#21512;&#29289;&#26377;&#26426;&#22826;&#38451;&#33021;&#30005;&#27744;&#65288;OSCs&#65289;&#30340;&#21151;&#29575;&#36716;&#25442;&#25928;&#29575;&#65288;PCE&#65289;&#25152;&#36973;&#21463;&#30340;&#26102;&#38388;&#36864;&#21270;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#29983;&#25104;&#20102;&#19968;&#20010;&#21253;&#21547;996&#26465;&#25968;&#25454;&#30340;&#25968;&#25454;&#24211;&#65292;&#20854;&#20013;&#21253;&#25324;&#20851;&#20110;&#21046;&#36896;&#36807;&#31243;&#21644;&#29615;&#22659;&#26465;&#20214;&#30340;7&#20010;&#21464;&#37327;&#65292;&#36229;&#36807;180&#22825;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20381;&#38752;&#19968;&#20010;&#36719;&#20214;&#26694;&#26550;&#65292;&#27719;&#38598;&#20102;&#19968;&#31995;&#21015;&#33258;&#21160;&#21270;ML&#21327;&#35758;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#21629;&#20196;&#34892;&#30028;&#38754;&#39034;&#24207;&#22320;&#38024;&#23545;&#25105;&#20204;&#30340;&#25968;&#25454;&#24211;&#25191;&#34892;&#65292;&#20174;&#32780;&#36731;&#26494;&#22320;&#36890;&#36807;&#35814;&#23613;&#30340;&#22522;&#20934;&#27979;&#35797;&#26469;&#36229;&#20248;&#21270;&#21644;&#38543;&#26426;&#21270;ML&#27169;&#22411;&#30340;&#31181;&#23376;&#65292;&#20197;&#33719;&#24471;&#26368;&#20339;&#27169;&#22411;&#12290;&#25152;&#36798;&#21040;&#30340;&#20934;&#30830;&#24230;&#36798;&#21040;&#20102;&#24191;&#27867;&#36229;&#36807;0.90&#30340;&#31995;&#25968;&#30830;&#23450;&#20540;&#65288;R2&#65289;&#65292;&#32780;&#22343;&#26041;&#26681;&#35823;&#24046;&#65288;RMSE&#65289;&#12289;&#24179;&#26041;&#35823;&#24046;&#65288;SSE&#65289;&#21644;&#24179;&#22343;&#32477;&#23545;&#35823;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00173v1 Announce Type: new  Abstract: This work presents a set of optimal machine learning (ML) models to represent the temporal degradation suffered by the power conversion efficiency (PCE) of polymeric organic solar cells (OSCs) with a multilayer structure ITO/PEDOT:PSS/P3HT:PCBM/Al. To that aim, we generated a database with 996 entries, which includes up to 7 variables regarding both the manufacturing process and environmental conditions for more than 180 days. Then, we relied on a software framework that brings together a conglomeration of automated ML protocols that execute sequentially against our database by simply command-line interface. This easily permits hyper-optimizing and randomizing seeds of the ML models through exhaustive benchmarking so that optimal models are obtained. The accuracy achieved reaches values of the coefficient determination (R2) widely exceeding 0.90, whereas the root mean squared error (RMSE), sum of squared error (SSE), and mean absolute er
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#38024;&#23545;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#27969;&#37327;&#20998;&#26512;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#24635;&#32467;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26032;&#29305;&#24449;&#12289;&#26368;&#26032;&#36827;&#23637;&#21644;&#25361;&#25112;&#65292;&#35748;&#20026;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#21487;&#20197;&#25581;&#31034;CIoT&#39046;&#22495;&#20013;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.16149</link><description>&lt;p&gt;
&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#27969;&#37327;&#30340;&#35843;&#26597;&#65306;&#23433;&#20840;&#19982;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
A Survey on Consumer IoT Traffic: Security and Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16149
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#38024;&#23545;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#27969;&#37327;&#20998;&#26512;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#24635;&#32467;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26032;&#29305;&#24449;&#12289;&#26368;&#26032;&#36827;&#23637;&#21644;&#25361;&#25112;&#65292;&#35748;&#20026;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#21487;&#20197;&#25581;&#31034;CIoT&#39046;&#22495;&#20013;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#37324;&#65292;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#24050;&#32463;&#36827;&#20837;&#20102;&#20844;&#20247;&#29983;&#27963;&#12290;&#23613;&#31649;CIoT&#25552;&#39640;&#20102;&#20154;&#20204;&#26085;&#24120;&#29983;&#27963;&#30340;&#20415;&#21033;&#24615;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26032;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;&#25105;&#20204;&#23581;&#35797;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#36825;&#19968;&#23433;&#20840;&#39046;&#22495;&#20013;&#30340;&#27969;&#34892;&#26041;&#27861;&#65292;&#25214;&#20986;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#20174;&#27969;&#37327;&#20998;&#26512;&#20013;&#20102;&#35299;CIoT&#23433;&#20840;&#21644;&#38544;&#31169;&#26041;&#38754;&#30340;&#20869;&#23481;&#12290;&#26412;&#35843;&#26597;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#35282;&#24230;&#25506;&#35752;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#20013;&#30340;&#26032;&#29305;&#24449;&#12289;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26368;&#26032;&#36827;&#23637;&#20197;&#21450;&#23578;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#20174;2018&#24180;1&#26376;&#33267;2023&#24180;12&#26376;&#25910;&#38598;&#20102;310&#31687;&#19982;CIoT&#27969;&#37327;&#20998;&#26512;&#26377;&#20851;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#35282;&#24230;&#30340;&#35770;&#25991;&#65292;&#24635;&#32467;&#20102;&#35782;&#21035;&#20102;CIoT&#26032;&#29305;&#24449;&#30340;CIoT&#27969;&#37327;&#20998;&#26512;&#36807;&#31243;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#20116;&#20010;&#24212;&#29992;&#30446;&#26631;&#35814;&#32454;&#20171;&#32461;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#35774;&#22791;&#25351;&#32441;&#35782;&#21035;&#12289;&#29992;&#25143;&#27963;&#21160;&#25512;&#26029;&#12289;&#24694;&#24847;&#34892;&#20026;&#26816;&#27979;&#12289;&#38544;&#31169;&#27844;&#38706;&#20197;&#21450;&#36890;&#20449;&#27169;&#24335;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16149v1 Announce Type: cross  Abstract: For the past few years, the Consumer Internet of Things (CIoT) has entered public lives. While CIoT has improved the convenience of people's daily lives, it has also brought new security and privacy concerns. In this survey, we try to figure out what researchers can learn about the security and privacy of CIoT by traffic analysis, a popular method in the security community. From the security and privacy perspective, this survey seeks out the new characteristics in CIoT traffic analysis, the state-of-the-art progress in CIoT traffic analysis, and the challenges yet to be solved. We collected 310 papers from January 2018 to December 2023 related to CIoT traffic analysis from the security and privacy perspective and summarized the process of CIoT traffic analysis in which the new characteristics of CIoT are identified. Then, we detail existing works based on five application goals: device fingerprinting, user activity inference, malicious
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;DyCE&#65292;&#19968;&#20010;&#21160;&#24577;&#21487;&#37197;&#32622;&#30340;&#25552;&#21069;&#36864;&#20986;&#26694;&#26550;&#65292;&#23558;&#35774;&#35745;&#32771;&#34385;&#20174;&#24444;&#27492;&#21644;&#22522;&#30784;&#27169;&#22411;&#35299;&#32806;</title><link>https://arxiv.org/abs/2403.01695</link><description>&lt;p&gt;
DyCE&#65306;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#21387;&#32553;&#21644;&#25193;&#23637;&#30340;&#21160;&#24577;&#21487;&#37197;&#32622;&#36864;&#20986;
&lt;/p&gt;
&lt;p&gt;
DyCE: Dynamic Configurable Exiting for Deep Learning Compression and Scaling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01695
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;DyCE&#65292;&#19968;&#20010;&#21160;&#24577;&#21487;&#37197;&#32622;&#30340;&#25552;&#21069;&#36864;&#20986;&#26694;&#26550;&#65292;&#23558;&#35774;&#35745;&#32771;&#34385;&#20174;&#24444;&#27492;&#21644;&#22522;&#30784;&#27169;&#22411;&#35299;&#32806;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#27169;&#22411;&#38656;&#35201;&#22312;&#36164;&#28304;&#21463;&#38480;&#29615;&#22659;&#20013;&#26377;&#25928;&#37096;&#32626;&#26102;&#65292;&#20351;&#29992;&#32553;&#25918;&#21644;&#21387;&#32553;&#25216;&#26415;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#25216;&#26415;&#65292;&#22914;&#20462;&#21098;&#21644;&#37327;&#21270;&#65292;&#36890;&#24120;&#26159;&#38745;&#24577;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#21160;&#24577;&#21387;&#32553;&#26041;&#27861;&#65288;&#22914;&#25552;&#21069;&#36864;&#20986;&#65289;&#36890;&#36807;&#35782;&#21035;&#36755;&#20837;&#26679;&#26412;&#30340;&#22256;&#38590;&#31243;&#24230;&#24182;&#26681;&#25454;&#38656;&#35201;&#20998;&#37197;&#35745;&#31639;&#26469;&#38477;&#20302;&#22797;&#26434;&#24615;&#12290;&#21160;&#24577;&#26041;&#27861;&#65292;&#23613;&#31649;&#20855;&#26377;&#26356;&#39640;&#30340;&#28789;&#27963;&#24615;&#21644;&#19982;&#38745;&#24577;&#26041;&#27861;&#20849;&#23384;&#30340;&#28508;&#21147;&#65292;&#20294;&#22312;&#23454;&#29616;&#19978;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#21160;&#24577;&#37096;&#20998;&#30340;&#20219;&#20309;&#21464;&#21270;&#37117;&#20250;&#24433;&#21709;&#21518;&#32493;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#21160;&#24577;&#21387;&#32553;&#35774;&#35745;&#37117;&#26159;&#21333;&#29255;&#30340;&#65292;&#19982;&#22522;&#30784;&#27169;&#22411;&#32039;&#23494;&#38598;&#25104;&#65292;&#20174;&#32780;&#20351;&#20854;&#38590;&#20197;&#36866;&#24212;&#26032;&#39062;&#22522;&#30784;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;DyCE&#65292;&#19968;&#31181;&#21160;&#24577;&#21487;&#37197;&#32622;&#30340;&#25552;&#21069;&#36864;&#20986;&#26694;&#26550;&#65292;&#20174;&#32780;&#20351;&#35774;&#35745;&#32771;&#34385;&#30456;&#20114;&#35299;&#32806;&#20197;&#21450;&#19982;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01695v1 Announce Type: cross  Abstract: Modern deep learning (DL) models necessitate the employment of scaling and compression techniques for effective deployment in resource-constrained environments. Most existing techniques, such as pruning and quantization are generally static. On the other hand, dynamic compression methods, such as early exits, reduce complexity by recognizing the difficulty of input samples and allocating computation as needed. Dynamic methods, despite their superior flexibility and potential for co-existing with static methods, pose significant challenges in terms of implementation due to any changes in dynamic parts will influence subsequent processes. Moreover, most current dynamic compression designs are monolithic and tightly integrated with base models, thereby complicating the adaptation to novel base models. This paper introduces DyCE, an dynamic configurable early-exit framework that decouples design considerations from each other and from the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#23398;&#20064;&#22797;&#26434;&#24615;&#20316;&#20026;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#30340;&#35780;&#20998;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#22312;&#26377;&#38480;&#35745;&#31639;&#36164;&#28304;&#19979;&#24494;&#35843;&#36807;&#31243;&#20013;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.05356</link><description>&lt;p&gt;
&#25506;&#32034;&#29992;&#20110;&#19979;&#28216;&#25968;&#25454;&#20462;&#21098;&#30340;&#23398;&#20064;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Exploring Learning Complexity for Downstream Data Pruning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#23398;&#20064;&#22797;&#26434;&#24615;&#20316;&#20026;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#30340;&#35780;&#20998;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#22312;&#26377;&#38480;&#35745;&#31639;&#36164;&#28304;&#19979;&#24494;&#35843;&#36807;&#31243;&#20013;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#23545;&#20110;&#26377;&#38480;&#30340;&#35745;&#31639;&#36164;&#28304;&#30340;&#24494;&#35843;&#26500;&#25104;&#20102;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#19968;&#20010;&#30452;&#35266;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#20174;&#24494;&#35843;&#25968;&#25454;&#38598;&#20013;&#20462;&#21098;&#25481;&#20449;&#24687;&#36739;&#23569;&#30340;&#26679;&#26412;&#12290;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;&#35757;&#32451;&#30340;&#35780;&#20998;&#20989;&#25968;&#26469;&#37327;&#21270;&#25968;&#25454;&#23376;&#38598;&#30340;&#20449;&#24687;&#24615;&#65292;&#20294;&#30001;&#20110;&#21442;&#25968;&#26356;&#26032;&#30340;&#32321;&#37325;&#65292;&#20462;&#21098;&#25104;&#26412;&#21464;&#24471;&#19981;&#21487;&#24573;&#35270;&#12290;&#20026;&#20102;&#39640;&#25928;&#20462;&#21098;&#65292;&#23558;&#20960;&#20309;&#26041;&#27861;&#30340;&#30456;&#20284;&#24230;&#35780;&#20998;&#20989;&#25968;&#20174;&#22522;&#20110;&#35757;&#32451;&#30340;&#26041;&#27861;&#36866;&#24212;&#20026;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#27861;&#26159;&#21487;&#34892;&#30340;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20973;&#32463;&#39564;&#35777;&#26126;&#36825;&#31181;&#36866;&#24212;&#25197;&#26354;&#20102;&#21407;&#22987;&#30340;&#20462;&#21098;&#24182;&#23548;&#33268;&#19979;&#28216;&#20219;&#21153;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#23398;&#20064;&#22797;&#26434;&#24615;&#65288;LC&#65289;&#20316;&#20026;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#30340;&#35780;&#20998;&#20989;&#25968;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#23398;&#20064;&#22797;&#26434;&#24615;&#34987;&#23450;&#20041;&#20026;&#20855;&#26377;&#19981;&#21516;&#23481;&#37327;&#30340;&#23376;&#32593;&#32476;&#30340;&#24179;&#22343;&#39044;&#27979;&#32622;&#20449;&#24230;&#65292;&#23427;&#21253;&#21547;&#20102;&#22312;&#19968;&#20010;&#25910;&#25947;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
The over-parameterized pre-trained models pose a great challenge to fine-tuning with limited computation resources. An intuitive solution is to prune the less informative samples from the fine-tuning dataset. A series of training-based scoring functions are proposed to quantify the informativeness of the data subset but the pruning cost becomes non-negligible due to the heavy parameter updating. For efficient pruning, it is viable to adapt the similarity scoring function of geometric-based methods from training-based to training-free. However, we empirically show that such adaption distorts the original pruning and results in inferior performance on the downstream tasks. In this paper, we propose to treat the learning complexity (LC) as the scoring function for classification and regression tasks. Specifically, the learning complexity is defined as the average predicted confidence of subnets with different capacities, which encapsulates data processing within a converged model. Then we
&lt;/p&gt;</description></item><item><title>&#22312;&#32771;&#34385;-&#28982;&#21518;-&#36873;&#25321;&#30340;&#25490;&#21517;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#30830;&#23450;&#32771;&#34385;&#27010;&#29575;&#30340;&#30028;&#38480;&#12290;&#23613;&#31649;&#19981;&#33021;&#20934;&#30830;&#30830;&#23450;&#32771;&#34385;&#27010;&#29575;&#65292;&#20294;&#22312;&#24050;&#30693;&#22791;&#36873;&#26041;&#26696;&#25928;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#25512;&#26029;&#20986;&#22791;&#36873;&#27010;&#29575;&#30340;&#30456;&#23545;&#22823;&#23567;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.11016</link><description>&lt;p&gt;
&#22312;&#32771;&#34385;-&#28982;&#21518;-&#36873;&#25321;&#25490;&#21517;&#27169;&#22411;&#20013;&#30830;&#23450;&#32771;&#34385;&#27010;&#29575;&#30340;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Bounding Consideration Probabilities in Consider-Then-Choose Ranking Models. (arXiv:2401.11016v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11016
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32771;&#34385;-&#28982;&#21518;-&#36873;&#25321;&#30340;&#25490;&#21517;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#30830;&#23450;&#32771;&#34385;&#27010;&#29575;&#30340;&#30028;&#38480;&#12290;&#23613;&#31649;&#19981;&#33021;&#20934;&#30830;&#30830;&#23450;&#32771;&#34385;&#27010;&#29575;&#65292;&#20294;&#22312;&#24050;&#30693;&#22791;&#36873;&#26041;&#26696;&#25928;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#25512;&#26029;&#20986;&#22791;&#36873;&#27010;&#29575;&#30340;&#30456;&#23545;&#22823;&#23567;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36873;&#25321;&#29702;&#35770;&#20013;&#19968;&#31181;&#24120;&#35265;&#30340;&#35266;&#28857;&#35748;&#20026;&#65292;&#20010;&#20307;&#22312;&#20570;&#20986;&#36873;&#25321;&#20043;&#21069;&#65292;&#20250;&#20808;&#36827;&#34892;&#20004;&#27493;&#30340;&#36807;&#31243;&#65292;&#39318;&#20808;&#36873;&#25321;&#19968;&#20123;&#22791;&#36873;&#26041;&#26696;&#36827;&#34892;&#32771;&#34385;&#65292;&#28982;&#21518;&#20174;&#25152;&#24471;&#30340;&#32771;&#34385;&#38598;&#21512;&#20013;&#36827;&#34892;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#31181;&#8220;&#32771;&#34385;&#28982;&#21518;&#36873;&#25321;&#8221;&#30340;&#24773;&#26223;&#19979;&#25512;&#26029;&#26410;&#35266;&#23519;&#21040;&#30340;&#32771;&#34385;&#38598;&#21512;&#65288;&#25110;&#32773;&#22791;&#36873;&#26041;&#26696;&#30340;&#32771;&#34385;&#27010;&#29575;&#65289;&#38754;&#20020;&#30528;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#21363;&#20351;&#26159;&#23545;&#20110;&#20855;&#26377;&#24378;&#29420;&#31435;&#24615;&#20551;&#35774;&#30340;&#31616;&#21333;&#32771;&#34385;&#27169;&#22411;&#65292;&#22312;&#24050;&#30693;&#22791;&#36873;&#26041;&#26696;&#25928;&#29992;&#30340;&#24773;&#20917;&#19979;&#20063;&#26080;&#27861;&#30830;&#23450;&#36523;&#20221;&#12290;&#25105;&#20204;&#32771;&#34385;&#23558;&#32771;&#34385;-&#28982;&#21518;-&#36873;&#25321;&#27169;&#22411;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;top-k&#25490;&#21517;&#30340;&#24773;&#26223;&#65292;&#20551;&#35774;&#25490;&#21517;&#26159;&#26681;&#25454;Plackett-Luce&#27169;&#22411;&#22312;&#37319;&#26679;&#20102;&#32771;&#34385;&#38598;&#21512;&#21518;&#26500;&#24314;&#30340;&#12290;&#23613;&#31649;&#22312;&#36825;&#31181;&#24773;&#26223;&#19979;&#22791;&#36873;&#26041;&#26696;&#30340;&#32771;&#34385;&#27010;&#29575;&#20173;&#26087;&#19981;&#33021;&#30830;&#23450;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#33719;&#24471;&#22791;&#36873;&#26041;&#26696;&#25928;&#29992;&#30340;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#25512;&#26029;&#20986;&#22791;&#36873;&#27010;&#29575;&#30456;&#23545;&#22823;&#23567;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#23545;&#26399;&#26395;&#32771;&#34385;&#38598;&#21512;&#22823;&#23567;&#30340;&#26465;&#20214;&#36827;&#34892;&#25512;&#23548;&#65292;&#25105;&#20204;&#24471;&#21040;&#32477;&#23545;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common theory of choice posits that individuals make choices in a two-step process, first selecting some subset of the alternatives to consider before making a selection from the resulting consideration set. However, inferring unobserved consideration sets (or item consideration probabilities) in this "consider then choose" setting poses significant challenges, because even simple models of consideration with strong independence assumptions are not identifiable, even if item utilities are known. We consider a natural extension of consider-then-choose models to a top-$k$ ranking setting, where we assume rankings are constructed according to a Plackett-Luce model after sampling a consideration set. While item consideration probabilities remain non-identified in this setting, we prove that knowledge of item utilities allows us to infer bounds on the relative sizes of consideration probabilities. Additionally, given a condition on the expected consideration set size, we derive absolute u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20272;&#35745;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#35797;&#22270;&#24357;&#21512;&#29616;&#26377;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#20013;&#30340;&#24046;&#36317;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#25512;&#24191;&#33267;&#20219;&#24847;&#38750;&#39640;&#26031;&#20998;&#24067;&#30340;&#20849;&#36717;&#21464;&#25442;&#28388;&#27874;&#22120; (CTF)&#65292;&#24182;&#25552;&#20986;&#20102;&#20854;&#38598;&#21512;&#36817;&#20284;&#29256;&#26412; (ECTF)&#12290;</title><link>http://arxiv.org/abs/2310.10976</link><description>&lt;p&gt;
&#31934;&#30830;&#38750;&#32447;&#24615;&#29366;&#24577;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Exact nonlinear state estimation. (arXiv:2310.10976v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10976
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20272;&#35745;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#35797;&#22270;&#24357;&#21512;&#29616;&#26377;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#20013;&#30340;&#24046;&#36317;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#25512;&#24191;&#33267;&#20219;&#24847;&#38750;&#39640;&#26031;&#20998;&#24067;&#30340;&#20849;&#36717;&#21464;&#25442;&#28388;&#27874;&#22120; (CTF)&#65292;&#24182;&#25552;&#20986;&#20102;&#20854;&#38598;&#21512;&#36817;&#20284;&#29256;&#26412; (ECTF)&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22320;&#29699;&#31185;&#23398;&#20013;&#30340;&#22823;&#22810;&#25968;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#22522;&#20110;&#39640;&#26031;&#20551;&#35774;&#12290;&#23613;&#31649;&#36825;&#20123;&#20551;&#35774;&#26041;&#20415;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20294;&#23427;&#20204;&#20250;&#23548;&#33268;&#20998;&#26512;&#20559;&#24046;&#21644;&#21518;&#32493;&#39044;&#27979;&#24694;&#21270;&#12290;&#38750;&#21442;&#25968;&#12289;&#22522;&#20110;&#31890;&#23376;&#30340;&#25968;&#25454;&#21516;&#21270;&#31639;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#20854;&#22312;&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#20173;&#38754;&#20020;&#25805;&#20316;&#19978;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#20511;&#37492;&#20102;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35797;&#22270;&#24357;&#21512;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#20013;&#29616;&#26377;&#24046;&#36317;&#30340;&#26032;&#30340;&#38750;&#32447;&#24615;&#20272;&#35745;&#29702;&#35770;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#20849;&#36717;&#21464;&#25442;&#28388;&#27874;&#22120; (CTF)&#65292;&#24182;&#26174;&#31034;&#20854;&#33021;&#22815;&#25512;&#24191;&#33267;&#20219;&#24847;&#38750;&#39640;&#26031;&#20998;&#24067;&#12290;&#26032;&#30340;&#28388;&#27874;&#22120;&#20855;&#26377;&#20960;&#20010;&#20248;&#28857;&#65292;&#20363;&#22914;&#33021;&#22815;&#20445;&#30041;&#20808;&#21069;&#29366;&#24577;&#20013;&#30340;&#32479;&#35745;&#20851;&#31995;&#24182;&#25910;&#25947;&#33267;&#39640;&#31934;&#24230;&#30340;&#35266;&#27979;&#20540;&#12290;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#26032;&#29702;&#35770;&#30340;&#19968;&#20010;&#38598;&#21512;&#36817;&#20284; (ECTF)&#12290;
&lt;/p&gt;
&lt;p&gt;
The majority of data assimilation (DA) methods in the geosciences are based on Gaussian assumptions. While these assumptions facilitate efficient algorithms, they cause analysis biases and subsequent forecast degradations. Non-parametric, particle-based DA algorithms have superior accuracy, but their application to high-dimensional models still poses operational challenges. Drawing inspiration from recent advances in the field of generative artificial intelligence (AI), this article introduces a new nonlinear estimation theory which attempts to bridge the existing gap in DA methodology. Specifically, a Conjugate Transform Filter (CTF) is derived and shown to generalize the celebrated Kalman filter to arbitrarily non-Gaussian distributions. The new filter has several desirable properties, such as its ability to preserve statistical relationships in the prior state and convergence to highly accurate observations. An ensemble approximation of the new theory (ECTF) is also presented and va
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#36817;&#20284;&#23398;&#20064;&#27169;&#22411;&#65292;&#32479;&#19968;&#20102;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#21644;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#65288;NNGP&#65289;&#26680;&#65292;&#29992;&#20110;&#25551;&#36848;&#26080;&#38480;&#23485;&#24230;&#28145;&#23618;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#21147;&#23398;&#12290;</title><link>http://arxiv.org/abs/2309.04522</link><description>&lt;p&gt;
&#36830;&#25509;NTK&#21644;NNGP&#65306;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21160;&#21147;&#23398;&#22312;&#26680;&#21306;&#22495;&#30340;&#32479;&#19968;&#29702;&#35770;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Connecting NTK and NNGP: A Unified Theoretical Framework for Neural Network Learning Dynamics in the Kernel Regime. (arXiv:2309.04522v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#36817;&#20284;&#23398;&#20064;&#27169;&#22411;&#65292;&#32479;&#19968;&#20102;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#21644;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#65288;NNGP&#65289;&#26680;&#65292;&#29992;&#20110;&#25551;&#36848;&#26080;&#38480;&#23485;&#24230;&#28145;&#23618;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#36817;&#24180;&#26469;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#65292;&#20294;&#20854;&#23398;&#20064;&#36807;&#31243;&#32570;&#20047;&#19968;&#20010;&#23436;&#25972;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#23545;&#20110;&#26080;&#38480;&#23485;&#24230;&#32593;&#32476;&#65292;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#22312;&#36825;&#20010;&#33539;&#24335;&#20013;&#65292;&#20351;&#29992;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#29702;&#35770;&#26694;&#26550;&#26469;&#25551;&#36848;&#32593;&#32476;&#30340;&#36755;&#20986;&#65306;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#30340;&#26694;&#26550;&#65292;&#20551;&#35774;&#20102;&#32447;&#24615;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#21160;&#21147;&#23398;&#65307;&#21478;&#19968;&#31181;&#26159;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#65288;NNGP&#65289;&#26680;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#26694;&#26550;&#20043;&#38388;&#30340;&#20851;&#31995;&#19968;&#30452;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#36817;&#20284;&#23398;&#20064;&#27169;&#22411;&#65292;&#32479;&#19968;&#20102;&#36825;&#20004;&#31181;&#19981;&#21516;&#30340;&#29702;&#35770;&#65292;&#29992;&#20110;&#25551;&#36848;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#26080;&#38480;&#23485;&#24230;&#28145;&#23618;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#21644;&#23398;&#20064;&#21518;&#30340;&#32593;&#32476;&#36755;&#20837;-&#36755;&#20986;&#20989;&#25968;&#30340;&#31934;&#30830;&#20998;&#26512;&#34920;&#36798;&#24335;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#26102;&#38388;&#30456;&#20851;&#30340;&#31070;&#32463;&#21160;&#24577;&#26680;&#65288;NDK&#65289;&#65292;&#36825;&#20010;&#26680;&#21487;&#20197;&#21516;&#26102;&#20135;&#29983;NTK&#21644;NNGP&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial neural networks have revolutionized machine learning in recent years, but a complete theoretical framework for their learning process is still lacking. Substantial progress has been made for infinitely wide networks. In this regime, two disparate theoretical frameworks have been used, in which the network's output is described using kernels: one framework is based on the Neural Tangent Kernel (NTK) which assumes linearized gradient descent dynamics, while the Neural Network Gaussian Process (NNGP) kernel assumes a Bayesian framework. However, the relation between these two frameworks has remained elusive. This work unifies these two distinct theories using a Markov proximal learning model for learning dynamics in an ensemble of randomly initialized infinitely wide deep networks. We derive an exact analytical expression for the network input-output function during and after learning, and introduce a new time-dependent Neural Dynamical Kernel (NDK) from which both NTK and NNGP
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#36827;&#34892;&#35299;&#20915;&#65292;&#24182;&#20171;&#32461;&#20102;R2&#25928;&#29992;&#20989;&#25968;&#20316;&#20026;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#35813;&#25928;&#29992;&#20989;&#25968;&#21333;&#35843;&#19988;&#27425;&#27169;&#65292;&#21487;&#20197;&#20351;&#29992;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#35745;&#31639;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.11774</link><description>&lt;p&gt;
&#20351;&#29992;R2&#25928;&#29992;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multi-Objective Optimization Using the R2 Utility. (arXiv:2305.11774v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#36827;&#34892;&#35299;&#20915;&#65292;&#24182;&#20171;&#32461;&#20102;R2&#25928;&#29992;&#20989;&#25968;&#20316;&#20026;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#35813;&#25928;&#29992;&#20989;&#25968;&#21333;&#35843;&#19988;&#27425;&#27169;&#65292;&#21487;&#20197;&#20351;&#29992;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#35745;&#31639;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#25551;&#36848;&#22810;&#30446;&#26631;&#20043;&#38388;&#26368;&#20339;&#26435;&#34913;&#30340;&#28857;&#38598;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#30690;&#37327;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20174;&#19994;&#32773;&#24120;&#24120;&#20351;&#29992;&#26631;&#37327;&#21270;&#20989;&#25968;&#23558;&#22810;&#30446;&#26631;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#12290;&#36825;&#32452;&#26631;&#37327;&#21270;&#38382;&#39064;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#21333;&#30446;&#26631;&#20248;&#21270;&#25216;&#26415;&#26469;&#35299;&#20915;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32422;&#23450;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#36890;&#29992;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#31574;&#30053;&#22914;&#20309;&#26377;&#25928;&#22320;&#23558;&#21407;&#22987;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#36716;&#21270;&#20026;&#23450;&#20041;&#22312;&#38598;&#21512;&#19978;&#30340;&#21333;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38024;&#23545;&#36825;&#20010;&#26032;&#38382;&#39064;&#30340;&#36866;&#24403;&#31867;&#21035;&#30340;&#30446;&#26631;&#20989;&#25968;&#26159;R2&#25928;&#29992;&#20989;&#25968;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#26631;&#37327;&#21270;&#20248;&#21270;&#38382;&#39064;&#30340;&#21152;&#26435;&#31215;&#20998;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#25928;&#29992;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#21644;&#27425;&#27169;&#30340;&#38598;&#21512;&#20989;&#25968;&#65292;&#21487;&#20197;&#36890;&#36807;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#26377;&#25928;&#22320;&#35745;&#31639;&#20986;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of multi-objective optimization is to identify a collection of points which describe the best possible trade-offs between the multiple objectives. In order to solve this vector-valued optimization problem, practitioners often appeal to the use of scalarization functions in order to transform the multi-objective problem into a collection of single-objective problems. This set of scalarized problems can then be solved using traditional single-objective optimization techniques. In this work, we formalise this convention into a general mathematical framework. We show how this strategy effectively recasts the original multi-objective optimization problem into a single-objective optimization problem defined over sets. An appropriate class of objective functions for this new problem is the R2 utility function, which is defined as a weighted integral over the scalarized optimization problems. We show that this utility function is a monotone and submodular set function, which can be op
&lt;/p&gt;</description></item></channel></rss>