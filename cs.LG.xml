<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32447;&#24615;&#27880;&#24847;&#21147;&#24207;&#21015;&#24182;&#34892;&#65288;LASP&#65289;&#30340;&#39640;&#25928;&#24207;&#21015;&#24182;&#34892;&#26041;&#27861;&#65292;&#38024;&#23545;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#36890;&#36807;&#35774;&#35745;&#39640;&#25928;&#30340;&#28857;&#23545;&#28857;&#36890;&#20449;&#26426;&#21046;&#21644;&#25191;&#34892;&#20869;&#26680;&#34701;&#21512;&#26469;&#38477;&#20302;&#36890;&#20449;&#24320;&#38144;&#65292;&#24182;&#23454;&#29616;&#30828;&#20214;&#21451;&#22909;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.02882</link><description>&lt;p&gt;
&#32447;&#24615;&#27880;&#24847;&#21147;&#24207;&#21015;&#24182;&#34892;&#21270;
&lt;/p&gt;
&lt;p&gt;
Linear Attention Sequence Parallelism
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02882
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32447;&#24615;&#27880;&#24847;&#21147;&#24207;&#21015;&#24182;&#34892;&#65288;LASP&#65289;&#30340;&#39640;&#25928;&#24207;&#21015;&#24182;&#34892;&#26041;&#27861;&#65292;&#38024;&#23545;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#36890;&#36807;&#35774;&#35745;&#39640;&#25928;&#30340;&#28857;&#23545;&#28857;&#36890;&#20449;&#26426;&#21046;&#21644;&#25191;&#34892;&#20869;&#26680;&#34701;&#21512;&#26469;&#38477;&#20302;&#36890;&#20449;&#24320;&#38144;&#65292;&#24182;&#23454;&#29616;&#30828;&#20214;&#21451;&#22909;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#24182;&#34892;&#65288;SP&#65289;&#20316;&#20026;&#19968;&#31181;&#22788;&#29702;&#36229;&#20986;&#21333;&#20010;GPU&#20869;&#23384;&#38480;&#21046;&#30340;&#38271;&#24207;&#21015;&#30340;&#27969;&#34892;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;SP&#26041;&#27861;&#24182;&#26410;&#21033;&#29992;&#32447;&#24615;&#27880;&#24847;&#21147;&#29305;&#24615;&#65292;&#23548;&#33268;&#22312;&#22522;&#20110;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#24182;&#34892;&#25928;&#29575;&#21644;&#21487;&#29992;&#24615;&#19981;&#20339;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#32447;&#24615;&#27880;&#24847;&#21147;&#24207;&#21015;&#24182;&#34892;&#65288;LASP&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#19987;&#20026;&#22522;&#20110;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#37327;&#36523;&#23450;&#21046;&#30340;&#39640;&#25928;SP&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#28857;&#23545;&#28857;&#36890;&#20449;&#26426;&#21046;&#65292;&#20197;&#21033;&#29992;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;&#21491;&#20056;&#20869;&#26680;&#25216;&#24039;&#65292;&#20174;&#32780;&#26174;&#30528;&#38477;&#20302;SP&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#25191;&#34892;&#20869;&#26680;&#34701;&#21512;&#21644;&#20013;&#38388;&#29366;&#24577;&#32531;&#23384;&#26469;&#22686;&#24378;LASP&#30340;&#23454;&#38469;&#25928;&#29575;&#65292;&#20351;LASP&#22312;GPU&#38598;&#32676;&#19978;&#30340;&#30828;&#20214;&#21451;&#22909;&#24615;&#24471;&#21040;&#25552;&#21319;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#31934;&#24515;&#30830;&#20445;&#24207;&#21015;&#32423;LASP&#19982;&#25152;&#26377;&#31867;&#22411;&#30340;&#25209;&#32423;&#25968;&#25454;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02882v1 Announce Type: cross  Abstract: Sequence Parallel (SP) serves as a prevalent strategy to handle long sequences that exceed the memory limit of a single GPU. However, existing SP methods do not take advantage of linear attention features, resulting in sub-optimal parallelism efficiency and usability for linear attention-based language models. In this paper, we introduce Linear Attention Sequence Parallel (LASP), an efficient SP method tailored to linear attention-based language models. Specifically, we design an efficient point-to-point communication mechanism to leverage the right-product kernel trick of linear attention, which sharply decreases the communication overhead of SP. We also enhance the practical efficiency of LASP by performing kernel fusion and intermediate state caching, making the implementation of LASP hardware-friendly on GPU clusters. Furthermore, we meticulously ensure the compatibility of sequence-level LASP with all types of batch-level data par
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#25512;&#36827;&#32422;&#26463;&#30340;&#38750;&#20984;&#24615;&#30340;&#29702;&#35770;&#35265;&#35299;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#23545;&#30456;&#20851;&#23398;&#20064;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.07471</link><description>&lt;p&gt;
&#26377;&#20851;&#26576;&#20123;&#25512;&#36827;&#32422;&#26463;&#30340;&#38750;&#20984;&#24615;&#21450;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the nonconvexity of some push-forward constraints and its consequences in machine learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#25512;&#36827;&#32422;&#26463;&#30340;&#38750;&#20984;&#24615;&#30340;&#29702;&#35770;&#35265;&#35299;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#23545;&#30456;&#20851;&#23398;&#20064;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
push-forward&#25805;&#20316;&#20351;&#20154;&#33021;&#22815;&#36890;&#36807;&#30830;&#23450;&#24615;&#26144;&#23556;&#37325;&#26032;&#20998;&#37197;&#27010;&#29575;&#27979;&#24230;&#12290;&#23427;&#22312;&#32479;&#35745;&#21644;&#20248;&#21270;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65306;&#35768;&#22810;&#23398;&#20064;&#38382;&#39064;&#65288;&#29305;&#21035;&#26159;&#26469;&#33258;&#26368;&#20248;&#36755;&#36816;&#12289;&#29983;&#25104;&#24314;&#27169;&#21644;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#65289;&#21253;&#25324;&#20316;&#20026;&#27169;&#22411;&#19978;&#30340;&#25512;&#36827;&#26465;&#20214;&#25110;&#22788;&#32602;&#30340;&#32422;&#26463;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#32570;&#20047;&#20851;&#20110;&#36825;&#20123;&#32422;&#26463;&#30340;&#65288;&#38750;&#65289;&#20984;&#24615;&#21450;&#20854;&#23545;&#30456;&#20851;&#23398;&#20064;&#38382;&#39064;&#30340;&#24433;&#21709;&#30340;&#19968;&#33324;&#29702;&#35770;&#35265;&#35299;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#22312;&#31532;&#19968;&#37096;&#20998;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#32452;&#20989;&#25968;&#65288;&#23558;&#19968;&#20010;&#27010;&#29575;&#27979;&#24230;&#20256;&#36755;&#21040;&#21478;&#19968;&#20010;&#30340;&#26144;&#23556;&#65307;&#35825;&#23548;&#19981;&#21516;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30456;&#31561;&#36755;&#20986;&#20998;&#24067;&#30340;&#26144;&#23556;&#65289;&#30340;&#65288;&#38750;&#65289;&#20984;&#24615;&#30340;&#19968;&#31995;&#21015;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12290;&#36825;&#31361;&#20986;&#20102;&#23545;&#20110;&#22823;&#22810;&#25968;&#27010;&#29575;&#27979;&#24230;&#32780;&#35328;&#65292;&#36825;&#20123;&#25512;&#36827;&#32422;&#26463;&#26159;&#38750;&#20984;&#30340;&#12290;&#22312;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#19968;&#32467;&#26524;&#22914;&#20309;&#26263;&#31034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07471v1 Announce Type: cross  Abstract: The push-forward operation enables one to redistribute a probability measure through a deterministic map. It plays a key role in statistics and optimization: many learning problems (notably from optimal transport, generative modeling, and algorithmic fairness) include constraints or penalties framed as push-forward conditions on the model. However, the literature lacks general theoretical insights on the (non)convexity of such constraints and its consequences on the associated learning problems. This paper aims at filling this gap. In a first part, we provide a range of sufficient and necessary conditions for the (non)convexity of two sets of functions: the maps transporting one probability measure to another; the maps inducing equal output distributions across distinct probability measures. This highlights that for most probability measures, these push-forward constraints are not convex. In a second time, we show how this result impli
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20026;&#22810;&#20219;&#21153;&#23398;&#20064;&#24314;&#31435;&#22522;&#20110;&#21407;&#21017;&#30340;&#20219;&#21153;&#20998;&#32452;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#19978;&#20855;&#26377;&#20248;&#21183;&#65292;&#36890;&#36807;&#28789;&#27963;&#30340;&#25968;&#23398;&#35268;&#21010;&#24418;&#24335;&#35299;&#20915;&#20102;&#36164;&#28304;&#32422;&#26463;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.15328</link><description>&lt;p&gt;
&#20026;&#22810;&#20219;&#21153;&#23398;&#20064;&#24314;&#31435;&#22522;&#20110;&#21407;&#21017;&#30340;&#20219;&#21153;&#20998;&#32452;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Principled Task Grouping for Multi-Task Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15328
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20026;&#22810;&#20219;&#21153;&#23398;&#20064;&#24314;&#31435;&#22522;&#20110;&#21407;&#21017;&#30340;&#20219;&#21153;&#20998;&#32452;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#19978;&#20855;&#26377;&#20248;&#21183;&#65292;&#36890;&#36807;&#28789;&#27963;&#30340;&#25968;&#23398;&#35268;&#21010;&#24418;&#24335;&#35299;&#20915;&#20102;&#36164;&#28304;&#32422;&#26463;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#20013;&#20219;&#21153;&#20998;&#32452;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;&#29616;&#26377;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20851;&#38190;&#30340;&#29702;&#35770;&#21644;&#23454;&#38469;&#38480;&#21046;&#12290;&#19982;&#20043;&#21069;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#26356;&#20855;&#29702;&#35770;&#22522;&#30784;&#30340;&#26041;&#27861;&#65292;&#19981;&#20381;&#36182;&#20110;&#26500;&#24314;&#36716;&#31227;&#22686;&#30410;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#25968;&#23398;&#35268;&#21010;&#24418;&#24335;&#65292;&#21487;&#20197;&#36866;&#24212;&#21508;&#31181;&#36164;&#28304;&#32422;&#26463;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#20854;&#22810;&#21151;&#33021;&#24615;&#12290;&#22312;&#21508;&#31181;&#39046;&#22495;&#36827;&#34892;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#21253;&#25324;&#35745;&#31639;&#26426;&#35270;&#35273;&#25968;&#25454;&#38598;&#12289;&#32452;&#21512;&#20248;&#21270;&#22522;&#20934;&#21644;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#24191;&#27867;&#30340;&#22522;&#32447;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#65292;&#39564;&#35777;&#20102;&#20854;&#22312;MTL&#20013;&#30340;&#26377;&#25928;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15328v1 Announce Type: new  Abstract: This paper presents a novel approach to task grouping in Multitask Learning (MTL), advancing beyond existing methods by addressing key theoretical and practical limitations. Unlike prior studies, our approach offers a more theoretically grounded method that does not rely on restrictive assumptions for constructing transfer gains. We also propose a flexible mathematical programming formulation which can accommodate a wide spectrum of resource constraints, thus enhancing its versatility. Experimental results across diverse domains, including computer vision datasets, combinatorial optimization benchmarks and time series tasks, demonstrate the superiority of our method over extensive baselines, validating its effectiveness and general applicability in MTL.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20351;&#29992;&#23567;&#27874;&#20998;&#26512;&#25216;&#26415;&#23545;&#38750;&#20405;&#20837;&#24615;&#33041;&#30005;&#22270;&#20449;&#21495;&#36827;&#34892;&#35299;&#30721;&#65292;&#25104;&#21151;&#21306;&#20998;&#22797;&#26434;&#21644;&#33258;&#28982;&#30340;&#25235;&#25569;&#31867;&#22411;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#23567;&#27874;&#29305;&#24449;&#22312;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#25235;&#25569;&#21306;&#20998;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09447</link><description>&lt;p&gt;
&#38750;&#20405;&#20837;&#24615;&#33041;&#30005;&#22270;&#20449;&#21495;&#30340;&#23567;&#27874;&#20998;&#26512;&#21306;&#20998;&#22797;&#26434;&#21644;&#33258;&#28982;&#30340;&#25235;&#25569;&#31867;&#22411;
&lt;/p&gt;
&lt;p&gt;
Wavelet Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09447
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20351;&#29992;&#23567;&#27874;&#20998;&#26512;&#25216;&#26415;&#23545;&#38750;&#20405;&#20837;&#24615;&#33041;&#30005;&#22270;&#20449;&#21495;&#36827;&#34892;&#35299;&#30721;&#65292;&#25104;&#21151;&#21306;&#20998;&#22797;&#26434;&#21644;&#33258;&#28982;&#30340;&#25235;&#25569;&#31867;&#22411;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#23567;&#27874;&#29305;&#24449;&#22312;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#25235;&#25569;&#21306;&#20998;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#23545;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#20449;&#21495;&#36827;&#34892;&#35299;&#30721;&#65292;&#20026;&#28789;&#24039;&#30340;&#31070;&#32463;&#20551;&#32930;&#24320;&#21457;&#21644;&#33041;&#26426;&#25509;&#21475;&#65288;BCI&#65289;&#24212;&#29992;&#26469;&#21306;&#20998;&#25163;&#37096;&#25235;&#25569;&#65292;&#29305;&#21035;&#26159;&#38024;&#23545;&#36816;&#21160;&#38556;&#30861;&#24739;&#32773;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#19987;&#27880;&#20110;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;BCI&#24179;&#21488;&#21644;&#23567;&#27874;&#20449;&#21495;&#22788;&#29702;&#65292;&#21306;&#20998;&#20004;&#31181;&#22797;&#26434;&#30340;&#33258;&#28982;&#21147;&#37327;&#21644;&#31934;&#30830;&#25235;&#25569;&#31867;&#22411;&#20197;&#21450;&#19968;&#31181;&#20013;&#31435;&#26465;&#20214;&#20316;&#20026;&#26080;&#36816;&#21160;&#26465;&#20214;&#12290;&#23567;&#27874;&#20998;&#26512;&#28041;&#21450;&#20174;&#23567;&#27874;&#33021;&#37327;&#31995;&#25968;&#29983;&#25104;&#26102;&#38388;&#39057;&#29575;&#21644;&#25299;&#25169;&#22270;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21644;&#26032;&#22411;&#23567;&#27874;&#29305;&#24449;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#39640;&#24179;&#22343;&#20934;&#30830;&#29575;&#65306;&#22810;&#31867;&#21035;&#20026;85.16%&#65292;&#26080;&#36816;&#21160; vs &#21147;&#37327;&#20026;95.37%&#65292;&#26080;&#36816;&#21160; vs &#31934;&#30830;&#20026;95.40%&#65292;&#21147;&#37327; vs &#31934;&#30830;&#20026;88.07%&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#29305;&#24449;&#22312;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#25235;&#25569;&#21306;&#20998;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#19982;&#20808;&#21069;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#30740;&#31350;&#30340;&#20851;&#38190;&#37096;&#20998;&#26159;&#25490;&#21015;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09447v1 Announce Type: cross  Abstract: This research aims to decode hand grasps from Electroencephalograms (EEGs) for dexterous neuroprosthetic development and Brain-Computer Interface (BCI) applications, especially for patients with motor disorders. Particularly, it focuses on distinguishing two complex natural power and precision grasps in addition to a neutral condition as a no-movement condition using a new EEG-based BCI platform and wavelet signal processing. Wavelet analysis involved generating time-frequency and topographic maps from wavelet power coefficients. Then, by using machine learning techniques with novel wavelet features, we achieved high average accuracies: 85.16% for multiclass, 95.37% for No-Movement vs Power, 95.40% for No-Movement vs Precision, and 88.07% for Power vs Precision, demonstrating the effectiveness of these features in EEG-based grasp differentiation. In contrast to previous studies, a critical part of our study was permutation feature impo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20316;&#32773;&#24402;&#23646;&#27169;&#22411;&#22312;&#28436;&#35762;&#25991;&#26412;&#20013;&#21306;&#20998;&#21457;&#35328;&#20154;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20197;&#20250;&#35805;&#28436;&#35762;&#25991;&#26412;&#20026;&#37325;&#28857;&#30340;&#21457;&#35328;&#20154;&#24402;&#23646;&#22522;&#20934;&#12290;</title><link>https://arxiv.org/abs/2311.07564</link><description>&lt;p&gt;
&#20316;&#32773;&#24402;&#23646;&#27169;&#22411;&#33021;&#21542;&#21306;&#20998;&#28436;&#35762;&#25991;&#26412;&#20013;&#30340;&#21457;&#35328;&#20154;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Authorship Attribution Models Distinguish Speakers in Speech Transcripts?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20316;&#32773;&#24402;&#23646;&#27169;&#22411;&#22312;&#28436;&#35762;&#25991;&#26412;&#20013;&#21306;&#20998;&#21457;&#35328;&#20154;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20197;&#20250;&#35805;&#28436;&#35762;&#25991;&#26412;&#20026;&#37325;&#28857;&#30340;&#21457;&#35328;&#20154;&#24402;&#23646;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#32773;&#24402;&#23646;&#39564;&#35777;&#26159;&#30830;&#23450;&#20004;&#20010;&#19981;&#21516;&#20070;&#38754;&#26679;&#26412;&#26159;&#21542;&#21516;&#23646;&#19968;&#20316;&#32773;&#30340;&#20219;&#21153;&#65292;&#36890;&#24120;&#28041;&#21450;&#23545;&#20070;&#38754;&#25991;&#26412;&#30340;&#24402;&#22240;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#36716;&#24405;&#28436;&#35762;&#30340;&#24402;&#23646;&#38382;&#39064;&#65292;&#36825;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#20854;&#20013;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#65292;&#35768;&#22810;&#25991;&#20307;&#29305;&#24449;&#65292;&#22914;&#26631;&#28857;&#21644;&#22823;&#20889;&#65292;&#22312;&#36825;&#31181;&#24773;&#22659;&#19979;&#24182;&#19981;&#20855;&#22791;&#20449;&#24687;&#37327;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36716;&#24405;&#30340;&#28436;&#35762;&#21576;&#29616;&#20854;&#20182;&#27169;&#24335;&#65292;&#22914;&#22635;&#20805;&#35789;&#21644;&#22238;&#24212;&#24615;&#22768;&#38899;&#65288;&#20363;&#22914;&#8220;&#21999;&#8221;&#65292;&#8220;&#21999;&#65292;&#21999;&#8221;&#65289;&#65292;&#36825;&#20123;&#21487;&#33021;&#26159;&#19981;&#21516;&#21457;&#35328;&#20154;&#30340;&#29305;&#24449;&#24615;&#34920;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20197;&#20250;&#35805;&#28436;&#35762;&#25991;&#26412;&#20026;&#37325;&#28857;&#30340;&#21457;&#35328;&#20154;&#24402;&#23646;&#22522;&#20934;&#12290;&#20026;&#20102;&#38480;&#21046;&#21457;&#35328;&#20154;&#19982;&#35805;&#39064;&#20043;&#38388;&#30340;&#34394;&#20551;&#20851;&#32852;&#65292;&#25105;&#20204;&#20351;&#29992;&#20250;&#35805;&#25552;&#31034;&#21644;&#21442;&#19982;&#21516;&#19968;&#23545;&#35805;&#30340;&#21457;&#35328;&#20154;&#26500;&#24314;&#19981;&#21516;&#38590;&#24230;&#30340;&#39564;&#35777;&#35797;&#39564;&#12290;&#36890;&#36807;&#27604;&#36739;&#19968;&#31995;&#21015;&#26041;&#27861;&#65292;&#22312;&#36825;&#19968;&#26032;&#22522;&#20934;&#19978;&#24314;&#31435;&#20102;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07564v2 Announce Type: replace  Abstract: Authorship verification is the task of determining if two distinct writing samples share the same author and is typically concerned with the attribution of written text. In this paper, we explore the attribution of transcribed speech, which poses novel challenges. The main challenge is that many stylistic features, such as punctuation and capitalization, are not informative in this setting. On the other hand, transcribed speech exhibits other patterns, such as filler words and backchannels (e.g., 'um', 'uh-huh'), which may be characteristic of different speakers. We propose a new benchmark for speaker attribution focused on conversational speech transcripts. To limit spurious associations of speakers with topic, we employ both conversation prompts and speakers participating in the same conversation to construct verification trials of varying difficulties. We establish the state of the art on this new benchmark by comparing a suite of
&lt;/p&gt;</description></item><item><title>&#32852;&#37030;&#36951;&#24536;&#65288;FU&#65289;&#26159;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#25968;&#25454;&#38544;&#31169;&#38382;&#39064;&#30340;&#25112;&#30053;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#21457;&#23637;FU&#26041;&#27861;&#26102;&#38656;&#35201;&#24179;&#34913;&#38544;&#31169;&#12289;&#23433;&#20840;&#12289;&#25928;&#29992;&#21644;&#25928;&#29575;&#30340;&#31454;&#20105;&#24615;&#35201;&#27714;&#65292;&#20197;&#32500;&#25345;FL&#31995;&#32479;&#30340;&#25928;&#26524;&#21644;&#21487;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2310.19218</link><description>&lt;p&gt;
&#32852;&#37030;&#36951;&#24536;&#30340;&#32508;&#36848;&#65306;&#20998;&#31867;&#12289;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.19218
&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#36951;&#24536;&#65288;FU&#65289;&#26159;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#25968;&#25454;&#38544;&#31169;&#38382;&#39064;&#30340;&#25112;&#30053;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#21457;&#23637;FU&#26041;&#27861;&#26102;&#38656;&#35201;&#24179;&#34913;&#38544;&#31169;&#12289;&#23433;&#20840;&#12289;&#25928;&#29992;&#21644;&#25928;&#29575;&#30340;&#31454;&#20105;&#24615;&#35201;&#27714;&#65292;&#20197;&#32500;&#25345;FL&#31995;&#32479;&#30340;&#25928;&#26524;&#21644;&#21487;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#38544;&#31169;&#20445;&#25252;&#30340;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#21457;&#23637;&#65292;&#23545;&#23454;&#29616;&#34987;&#36951;&#24536;&#26435;&#30340;&#38656;&#27714;&#36234;&#26469;&#36234;&#22823;&#12290;&#30001;&#20110;FL&#30340;&#20998;&#25955;&#24615;&#36136;&#65292;&#23454;&#26045;&#36873;&#25321;&#24615;&#36951;&#24536;&#23588;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#20652;&#29983;&#20102;&#19968;&#20010;&#26032;&#30340;&#39046;&#22495;&#65292;&#21363;&#32852;&#37030;&#36951;&#24536;&#65288;FU&#65289;&#12290;FU&#20316;&#20026;&#35299;&#20915;&#25968;&#25454;&#38544;&#31169;&#38656;&#27714;&#30340;&#25112;&#30053;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#23454;&#26045;&#8220;&#34987;&#36951;&#24536;&#26435;&#8221;&#12290;&#24320;&#21457;FU&#26041;&#27861;&#30340;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#22312;&#38544;&#31169;&#12289;&#23433;&#20840;&#12289;&#25928;&#29992;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#22240;&#20026;&#36825;&#20123;&#22240;&#32032;&#24448;&#24448;&#20855;&#26377;&#31454;&#20105;&#24615;&#35201;&#27714;&#12290;&#22312;&#20445;&#25345;FL&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#29992;&#24615;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#36825;&#20123;&#26041;&#38754;&#30340;&#26368;&#20339;&#24179;&#34913;&#23545;&#20110;&#36981;&#23432;&#38544;&#31169;&#21644;&#23433;&#20840;&#26631;&#20934;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#32508;&#36848;&#23545;&#29616;&#26377;&#30340;FU&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#21253;&#25324;&#23545;&#21508;&#31181;&#35780;&#20272;&#25351;&#26631;&#30340;&#35814;&#32454;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
The evolution of privacy-preserving Federated Learning (FL) has led to an increasing demand for implementing the right to be forgotten. The implementation of selective forgetting is particularly challenging in FL due to its decentralized nature. This complexity has given rise to a new field, Federated Unlearning (FU). FU emerges as a strategic solution to address the increasing need for data privacy, including the implementation of the `right to be forgotten'. The primary challenge in developing FU approaches lies in balancing the trade-offs in privacy, security, utility, and efficiency, as these elements often have competing requirements. Achieving an optimal equilibrium among these facets is crucial for maintaining the effectiveness and usability of FL systems while adhering to privacy and security standards. This survey provides a comprehensive analysis of existing FU methods, incorporating a detailed review of the various evaluation metrics. Furthermore, we unify these diverse meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#65292;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.01762</link><description>&lt;p&gt;
&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel. (arXiv:2311.01762v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#65292;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#26159;&#32447;&#24615;&#23725;&#22238;&#24402;&#30340;&#25512;&#24191;&#65292;&#23427;&#22312;&#25968;&#25454;&#20013;&#26159;&#38750;&#32447;&#24615;&#30340;&#65292;&#20294;&#22312;&#21442;&#25968;&#20013;&#26159;&#32447;&#24615;&#30340;&#12290;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#36890;&#36807;&#38381;&#24335;&#35299;&#33719;&#24471;&#65292;&#20854;&#20013;&#21253;&#25324;&#30697;&#38453;&#27714;&#36870;&#65292;&#20063;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36845;&#20195;&#33719;&#24471;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25913;&#21464;&#26680;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#25506;&#35752;&#20102;&#36825;&#23545;&#27169;&#22411;&#22797;&#26434;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#20854;&#20013;&#24102;&#23485;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#33267;&#38646;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#35201;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#30340;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#65292;&#36890;&#36807;&#20132;&#21449;&#39564;&#35777;&#21644;&#36793;&#32536;&#20284;&#28982;&#26368;&#22823;&#21270;&#36873;&#25321;&#30340;&#24102;&#23485;&#12290;&#25105;&#20204;&#36824;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#35777;&#26126;&#20102;&#20351;&#29992;&#36880;&#28176;&#20943;&#23567;&#30340;&#24102;&#23485;&#26102;&#65292;&#25105;&#20204;&#33021;&#22815;...
&lt;/p&gt;
&lt;p&gt;
Kernel ridge regression, KRR, is a generalization of linear ridge regression that is non-linear in the data, but linear in the parameters. The solution can be obtained either as a closed-form solution, which includes a matrix inversion, or iteratively through gradient descent. Using the iterative approach opens up for changing the kernel during training, something that is investigated in this paper. We theoretically address the effects this has on model complexity and generalization. Based on our findings, we propose an update scheme for the bandwidth of translational-invariant kernels, where we let the bandwidth decrease to zero during training, thus circumventing the need for hyper-parameter selection. We demonstrate on real and synthetic data how decreasing the bandwidth during training outperforms using a constant bandwidth, selected by cross-validation and marginal likelihood maximization. We also show theoretically and empirically that using a decreasing bandwidth, we are able to
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.18304</link><description>&lt;p&gt;
&#23398;&#20064;&#38750;&#31283;&#24577;&#26465;&#20214;&#19979;&#30340;&#31283;&#23450;&#24615;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38750;&#31283;&#23450;&#29615;&#22659;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#26469;&#36873;&#25321;&#19968;&#20010;&#22238;&#28335;&#31383;&#21475;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#65292;&#21516;&#26102;&#23558;&#32047;&#31215;&#20559;&#24046;&#20445;&#25345;&#22312;&#19982;&#38543;&#26426;&#35823;&#24046;&#30456;&#23545;&#21487;&#25509;&#21463;&#30340;&#33539;&#22260;&#20869;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#26410;&#30693;&#38750;&#31283;&#23450;&#24615;&#30340;&#36866;&#24212;&#24615;&#12290;&#24403;&#20154;&#21475;&#25439;&#22833;&#20989;&#25968;&#24378;&#20984;&#25110;&#20165;&#28385;&#36275;Lipschitz&#26465;&#20214;&#26102;&#65292;&#36951;&#25022;&#30028;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#65292;&#20165;&#21463;&#23545;&#25968;&#22240;&#23376;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26680;&#24515;&#26159;&#20004;&#20010;&#26032;&#39062;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#20989;&#25968;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#23558;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#20026;&#20934;&#31283;&#24577;&#29255;&#27573;&#30340;&#20998;&#21106;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#35757;&#32451;&#21160;&#24577;&#21644;&#32463;&#39564;&#28023;&#26862;&#30697;&#38453;&#20197;&#21450;&#26799;&#24230;&#30697;&#38453;&#30340;&#35889;&#30340;&#32852;&#21512;&#28436;&#21270;&#65292;&#35777;&#26126;&#20102;&#22312;&#39640;&#32500;&#28151;&#21512;&#21644;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;SGD&#36712;&#36857;&#19982;&#28023;&#26862;&#30697;&#38453;&#21644;&#26799;&#24230;&#30697;&#38453;&#30340;&#26032;&#20852;&#20302;&#31209;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#21563;&#21512;&#12290;&#22312;&#22810;&#23618;&#35774;&#32622;&#20013;&#65292;&#36825;&#31181;&#23545;&#40784;&#20250;&#22312;&#27599;&#19968;&#23618;&#21457;&#29983;&#65292;&#24182;&#19988;&#22312;&#25910;&#25947;&#21040;&#20122;&#20248;&#20998;&#31867;&#22120;&#26102;&#20250;&#34920;&#29616;&#20986;&#31209;&#32570;&#20047;&#12290;</title><link>http://arxiv.org/abs/2310.03010</link><description>&lt;p&gt;
&#39640;&#32500;&#24230; SGD &#19982;&#26032;&#20852;&#30340;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#30456;&#21563;&#21512;
&lt;/p&gt;
&lt;p&gt;
High-dimensional SGD aligns with emerging outlier eigenspaces. (arXiv:2310.03010v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#35757;&#32451;&#21160;&#24577;&#21644;&#32463;&#39564;&#28023;&#26862;&#30697;&#38453;&#20197;&#21450;&#26799;&#24230;&#30697;&#38453;&#30340;&#35889;&#30340;&#32852;&#21512;&#28436;&#21270;&#65292;&#35777;&#26126;&#20102;&#22312;&#39640;&#32500;&#28151;&#21512;&#21644;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;SGD&#36712;&#36857;&#19982;&#28023;&#26862;&#30697;&#38453;&#21644;&#26799;&#24230;&#30697;&#38453;&#30340;&#26032;&#20852;&#20302;&#31209;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#21563;&#21512;&#12290;&#22312;&#22810;&#23618;&#35774;&#32622;&#20013;&#65292;&#36825;&#31181;&#23545;&#40784;&#20250;&#22312;&#27599;&#19968;&#23618;&#21457;&#29983;&#65292;&#24182;&#19988;&#22312;&#25910;&#25947;&#21040;&#20122;&#20248;&#20998;&#31867;&#22120;&#26102;&#20250;&#34920;&#29616;&#20986;&#31209;&#32570;&#20047;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21644;&#32463;&#39564;&#28023;&#26862;&#30697;&#38453;&#21644;&#26799;&#24230;&#30697;&#38453;&#30340;&#35889;&#30340;&#32852;&#21512;&#28436;&#21270;&#65292;&#23545;&#35757;&#32451;&#21160;&#24577;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#22810;&#31867;&#39640;&#32500;&#28151;&#21512;&#21644;1&#25110;2&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20004;&#20010;&#20856;&#22411;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;SGD&#36712;&#36857;&#36805;&#36895;&#19982;&#28023;&#26862;&#30697;&#38453;&#21644;&#26799;&#24230;&#30697;&#38453;&#30340;&#26032;&#20852;&#20302;&#31209;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#30456;&#21563;&#21512;&#12290;&#27492;&#22806;&#65292;&#22312;&#22810;&#23618;&#35774;&#32622;&#20013;&#65292;&#36825;&#31181;&#23545;&#40784;&#21457;&#29983;&#22312;&#27599;&#19968;&#23618;&#65292;&#26368;&#21518;&#19968;&#23618;&#30340;&#24322;&#24120;&#29305;&#24449;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#28436;&#21270;&#65292;&#24182;&#19988;&#22312;SGD&#25910;&#25947;&#21040;&#20122;&#20248;&#20998;&#31867;&#22120;&#26102;&#34920;&#29616;&#20986;&#31209;&#32570;&#20047;&#12290;&#36825;&#20026;&#36807;&#21435;&#21313;&#24180;&#20013;&#20851;&#20110;&#22312;&#36229;&#21442;&#25968;&#21270;&#32593;&#32476;&#20013;&#35757;&#32451;&#36807;&#31243;&#20013;&#28023;&#26862;&#30697;&#38453;&#21644;&#20449;&#24687;&#30697;&#38453;&#30340;&#35889;&#30340;&#24191;&#27867;&#25968;&#20540;&#30740;&#31350;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We rigorously study the joint evolution of training dynamics via stochastic gradient descent (SGD) and the spectra of empirical Hessian and gradient matrices. We prove that in two canonical classification tasks for multi-class high-dimensional mixtures and either 1 or 2-layer neural networks, the SGD trajectory rapidly aligns with emerging low-rank outlier eigenspaces of the Hessian and gradient matrices. Moreover, in multi-layer settings this alignment occurs per layer, with the final layer's outlier eigenspace evolving over the course of training, and exhibiting rank deficiency when the SGD converges to sub-optimal classifiers. This establishes some of the rich predictions that have arisen from extensive numerical studies in the last decade about the spectra of Hessian and information matrices over the course of training in overparametrized networks.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#35268;&#33539;&#21270;&#27969;&#35745;&#31639;&#20998;&#23376;&#30340;&#28608;&#21457;&#24577;&#65292;&#36890;&#36807;&#36924;&#36817;&#27874;&#20989;&#25968;&#24182;&#20248;&#21270;&#22522;&#20989;&#25968;&#30340;&#32447;&#24615;&#31354;&#38388;&#20869;&#30340;&#36817;&#20284;&#12290;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#37327;&#23376;&#31995;&#32479;&#20013;&#21462;&#24471;&#20102;&#20934;&#30830;&#21644;&#26377;&#25928;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#33021;&#37327;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#22522;&#32452;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#36827;&#34892;&#20102;&#26174;&#33879;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2308.16468</link><description>&lt;p&gt;
&#20351;&#29992;&#35268;&#33539;&#21270;&#27969;&#35745;&#31639;&#20998;&#23376;&#30340;&#28608;&#21457;&#24577;
&lt;/p&gt;
&lt;p&gt;
Computing excited states of molecules using normalizing flows. (arXiv:2308.16468v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16468
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#35268;&#33539;&#21270;&#27969;&#35745;&#31639;&#20998;&#23376;&#30340;&#28608;&#21457;&#24577;&#65292;&#36890;&#36807;&#36924;&#36817;&#27874;&#20989;&#25968;&#24182;&#20248;&#21270;&#22522;&#20989;&#25968;&#30340;&#32447;&#24615;&#31354;&#38388;&#20869;&#30340;&#36817;&#20284;&#12290;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#37327;&#23376;&#31995;&#32479;&#20013;&#21462;&#24471;&#20102;&#20934;&#30830;&#21644;&#26377;&#25928;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#33021;&#37327;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#22522;&#32452;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#36827;&#34892;&#20102;&#26174;&#33879;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#21464;&#20998;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#35745;&#31639;&#37327;&#23376;&#31995;&#32479;&#30340;&#22522;&#24577;&#21644;&#28608;&#21457;&#24577;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#36890;&#36807;&#19982;&#35268;&#33539;&#21270;&#27969;&#30340;&#32452;&#21512;&#26469;&#36924;&#36817;&#27874;&#20989;&#25968;&#65292;&#36825;&#20123;&#27874;&#20989;&#25968;&#20301;&#20110;&#22522;&#20989;&#25968;&#30340;&#32447;&#24615;&#31354;&#38388;&#20013;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#36890;&#36807;&#35745;&#31639;&#19977;&#21407;&#23376;H$_2$S&#20998;&#23376;&#30340;&#22823;&#37327;&#25391;&#21160;&#24577;&#20197;&#21450;&#20856;&#22411;&#30340;&#21333;&#30005;&#23376;&#31995;&#32479;&#65288;&#21253;&#25324;&#27682;&#21407;&#23376;&#12289;&#20998;&#23376;&#27682;&#31163;&#23376;&#21644;&#30899;&#21407;&#23376;&#22312;&#21333;&#28608;&#21457;&#30005;&#23376;&#36817;&#20284;&#19979;&#30340;&#22522;&#24577;&#21644;&#22810;&#20010;&#28608;&#21457;&#24577;&#65289;&#26469;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#20351;&#29992;&#21442;&#25968;&#36739;&#23569;&#30340;&#35268;&#33539;&#21270;&#27969;&#65292;&#33021;&#37327;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#22522;&#32452;&#25910;&#25947;&#36895;&#24230;&#20063;&#26377;&#26174;&#33879;&#25913;&#21892;&#12290;&#35813;&#26041;&#27861;&#20063;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#23545;&#26368;&#20339;&#25429;&#25417;&#24213;&#23618;&#29289;&#29702;&#30340;&#19968;&#32452;&#20869;&#31104;&#22352;&#26631;&#36827;&#34892;&#20248;&#21270;&#30340;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new nonlinear variational framework for simultaneously computing ground and excited states of quantum systems. Our approach is based on approximating wavefunctions in the linear span of basis functions that are augmented and optimized \emph{via} composition with normalizing flows. The accuracy and efficiency of our approach are demonstrated in the calculations of a large number of vibrational states of the triatomic H$_2$S molecule as well as ground and several excited electronic states of prototypical one-electron systems including the hydrogen atom, the molecular hydrogen ion, and a carbon atom in a single-active-electron approximation. The results demonstrate significant improvements in the accuracy of energy predictions and accelerated basis-set convergence even when using normalizing flows with a small number of parameters. The present approach can be also seen as the optimization of a set of intrinsic coordinates that best capture the underlying physics within the gi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#36172;&#21338;&#30340;&#26041;&#24335;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#25928;&#29575;&#65292;&#33021;&#22815;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#24182;&#22788;&#29702;&#22240;&#20998;&#24067;&#28418;&#31227;&#23548;&#33268;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.17570</link><description>&lt;p&gt;
&#36890;&#36807;&#36172;&#21338;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Auditing Fairness by Betting. (arXiv:2305.17570v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17570
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#36172;&#21338;&#30340;&#26041;&#24335;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#25928;&#29575;&#65292;&#33021;&#22815;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#24182;&#22788;&#29702;&#22240;&#20998;&#24067;&#28418;&#31227;&#23548;&#33268;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#29992;&#12289;&#39640;&#25928;&#12289;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#23457;&#35745;&#24050;&#37096;&#32626;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;&#30456;&#27604;&#20043;&#21069;&#20381;&#36182;&#20110;&#22266;&#23450;&#26679;&#26412;&#37327;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#24207;&#36143;&#30340;&#65292;&#24182;&#20801;&#35768;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#22240;&#27492;&#38750;&#24120;&#36866;&#29992;&#20110;&#36319;&#36394;&#29616;&#23454;&#19990;&#30028;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#20063;&#20801;&#35768;&#25968;&#25454;&#36890;&#36807;&#27010;&#29575;&#31574;&#30053;&#36827;&#34892;&#25910;&#38598;&#65292;&#32780;&#19981;&#26159;&#20174;&#20154;&#21475;&#20013;&#22343;&#21248;&#37319;&#26679;&#12290;&#36825;&#20351;&#24471;&#23457;&#35745;&#21487;&#20197;&#22312;&#20026;&#20854;&#20182;&#30446;&#30340;&#25910;&#38598;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#12290;&#27492;&#22806;&#65292;&#35813;&#31574;&#30053;&#21487;&#20197;&#38543;&#26102;&#38388;&#25913;&#21464;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#23376;&#20154;&#32676;&#21487;&#20197;&#20351;&#29992;&#19981;&#21516;&#30340;&#31574;&#30053;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#22240;&#27169;&#22411;&#21464;&#26356;&#25110;&#22522;&#30784;&#20154;&#32676;&#21464;&#26356;&#23548;&#33268;&#30340;&#20998;&#24067;&#28418;&#31227;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#26368;&#36817;&#20851;&#20110; anytime-valid &#25512;&#26029;&#21644;&#21338;&#24328;&#32479;&#35745;&#23398;&#30340;&#36827;&#23637;&#65292;&#23588;&#20854;&#26159;"&#36890;&#36807;&#36172;&#21338;&#36827;&#34892;&#27979;&#35797;"&#26694;&#26550;&#12290;&#36825;&#20123;&#32852;&#31995;&#30830;&#20445;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12289;&#24555;&#36895;&#21644;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide practical, efficient, and nonparametric methods for auditing the fairness of deployed classification and regression models. Whereas previous work relies on a fixed-sample size, our methods are sequential and allow for the continuous monitoring of incoming data, making them highly amenable to tracking the fairness of real-world systems. We also allow the data to be collected by a probabilistic policy as opposed to sampled uniformly from the population. This enables auditing to be conducted on data gathered for another purpose. Moreover, this policy may change over time and different policies may be used on different subpopulations. Finally, our methods can handle distribution shift resulting from either changes to the model or changes in the underlying population. Our approach is based on recent progress in anytime-valid inference and game-theoretic statistics-the "testing by betting" framework in particular. These connections ensure that our methods are interpretable, fast, 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#36873;&#25321;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#30340;&#21160;&#26426;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#22522;&#20110;&#20010;&#20154;&#30446;&#26631;&#21644;&#32972;&#26223;&#22240;&#32032;&#65292;&#35843;&#26597;&#36824;&#32473;&#20986;&#20102;&#20248;&#21270;&#27169;&#22411;&#30340;&#20845;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2203.01717</link><description>&lt;p&gt;
&#36873;&#25321;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#30340;&#20174;&#19994;&#32773;&#21160;&#26426;
&lt;/p&gt;
&lt;p&gt;
Practitioner Motives to Select Hyperparameter Optimization Methods. (arXiv:2203.01717v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.01717
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#36873;&#25321;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#30340;&#21160;&#26426;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#22522;&#20110;&#20010;&#20154;&#30446;&#26631;&#21644;&#32972;&#26223;&#22240;&#32032;&#65292;&#35843;&#26597;&#36824;&#32473;&#20986;&#20102;&#20248;&#21270;&#27169;&#22411;&#30340;&#20845;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#36827;&#30340;&#32534;&#31243;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#65292;&#22914;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#20855;&#26377;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#33021;&#22815;&#21487;&#38752;&#22320;&#25214;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#20540;&#12290;&#28982;&#32780;&#65292;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#32463;&#24120;&#24212;&#29992;&#26679;&#26412;&#25928;&#29575;&#36739;&#20302;&#30340;HPO&#26041;&#27861;&#65292;&#22914;&#32593;&#26684;&#25628;&#32034;&#65292;&#36825;&#36890;&#24120;&#23548;&#33268;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26410;&#32463;&#20248;&#21270;&#12290;&#25105;&#20204;&#24576;&#30097;&#65292;&#20174;&#19994;&#32773;&#36873;&#25321;HPO&#26041;&#27861;&#30340;&#21407;&#22240;&#22522;&#20110;&#20010;&#20154;&#21160;&#26426;&#65292;&#21253;&#25324;&#32972;&#26223;&#22240;&#32032;&#21644;&#20010;&#20154;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#20174;&#19994;&#32773;&#30340;&#21160;&#26426;&#20173;&#28982;&#38656;&#35201;&#28548;&#28165;&#65292;&#36825;&#22952;&#30861;&#20102;&#35780;&#20272;HPO&#26041;&#27861;&#20197;&#23454;&#29616;&#29305;&#23450;&#30446;&#26631;&#21644;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;HPO&#24037;&#20855;&#30340;&#24320;&#21457;&#12290;&#20026;&#20102;&#20102;&#35299;&#20174;&#19994;&#32773;&#20351;&#29992;&#29305;&#23450;HPO&#26041;&#27861;&#30340;&#21160;&#26426;&#65292;&#25105;&#20204;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#21253;&#25324;20&#20010;&#21322;&#32467;&#26500;&#21270;&#35775;&#35848;&#21644;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;&#65292;&#20849;&#26377;71&#21517;&#26426;&#22120;&#23398;&#20064;&#19987;&#23478;&#21442;&#19982;&#65292;&#20197;&#25910;&#38598;&#35775;&#35848;&#32467;&#26524;&#30340;&#22806;&#37096;&#26377;&#25928;&#24615;&#30340;&#35777;&#25454;&#12290;&#36890;&#36807;&#35774;&#32622;&#20845;&#20010;&#20027;&#35201;&#30446;&#26631;&#65288;&#20363;&#22914;&#65292;&#25913;&#36827;&#27169;&#22411;&#29702;&#35299;&#65289;&#65292;
&lt;/p&gt;
&lt;p&gt;
Advanced programmatic hyperparameter optimization (HPO) methods, such as Bayesian optimization, have high sample efficiency in reproducibly finding optimal hyperparameter values of machine learning (ML) models. Yet, ML practitioners often apply less sample-efficient HPO methods, such as grid search, which often results in under-optimized ML models. As a reason for this behavior, we suspect practitioners choose HPO methods based on individual motives, consisting of contextual factors and individual goals. However, practitioners' motives still need to be clarified, hindering the evaluation of HPO methods for achieving specific goals and the user-centered development of HPO tools. To understand practitioners' motives for using specific HPO methods, we used a mixed-methods approach involving 20 semi-structured interviews and a survey study with 71 ML experts to gather evidence of the external validity of the interview results. By presenting six main goals (e.g., improving model understandi
&lt;/p&gt;</description></item></channel></rss>