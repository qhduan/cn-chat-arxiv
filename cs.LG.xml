<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#20010;&#26377;&#37325;&#35201;&#24847;&#20041;&#30340;&#39046;&#22495;&#12290;&#26412;&#32508;&#36848;&#20998;&#31867;&#21644;&#20998;&#26512;&#20102;&#24050;&#26377;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#26500;&#24314;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;GNNs&#30340;&#26126;&#30830;&#25351;&#23548;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01138</link><description>&lt;p&gt;
&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#20010;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks in EEG-based Emotion Recognition: A Survey
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01138
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#20010;&#26377;&#37325;&#35201;&#24847;&#20041;&#30340;&#39046;&#22495;&#12290;&#26412;&#32508;&#36848;&#20998;&#31867;&#21644;&#20998;&#26512;&#20102;&#24050;&#26377;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#26500;&#24314;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;GNNs&#30340;&#26126;&#30830;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#23545;&#20110;&#20854;&#20182;&#27169;&#24335;&#65292;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#21487;&#20197;&#30452;&#35266;&#22320;&#21709;&#24212;&#20154;&#33041;&#20013;&#30340;&#24773;&#32490;&#27169;&#24335;&#65292;&#22240;&#27492;&#25104;&#20026;&#33041;-&#35745;&#31639;&#26426;&#25509;&#21475;&#39046;&#22495;&#26368;&#20851;&#27880;&#30340;&#20219;&#21153;&#20043;&#19968;&#12290;&#30001;&#20110;&#22823;&#33041;&#21306;&#22495;&#20043;&#38388;&#30340;&#20381;&#36182;&#19982;&#24773;&#32490;&#23494;&#20999;&#30456;&#20851;&#65292;&#22240;&#27492;&#21457;&#23637;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#36827;&#34892;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#36235;&#21183;&#12290;&#28982;&#32780;&#65292;&#24773;&#32490;&#24615;&#33041;&#30005;&#22270;&#20013;&#30340;&#22823;&#33041;&#21306;&#22495;&#20381;&#36182;&#20855;&#26377;&#29983;&#29702;&#22522;&#30784;&#65292;&#20351;&#24471;&#22312;&#36825;&#19968;&#39046;&#22495;&#20013;&#30340;GNNs&#19982;&#20854;&#20182;&#26102;&#38388;&#24207;&#21015;&#39046;&#22495;&#30340;GNNs&#26377;&#25152;&#21306;&#21035;&#12290;&#27492;&#22806;&#65292;&#22312;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#20013;&#26082;&#27809;&#26377;&#20840;&#38754;&#30340;&#32508;&#36848;&#65292;&#20063;&#27809;&#26377;&#26500;&#24314;GNNs&#30340;&#25351;&#23548;&#12290;&#22312;&#36825;&#39033;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#23545;&#24050;&#26377;&#26041;&#27861;&#22312;&#22270;&#26500;&#36896;&#30340;&#32479;&#19968;&#26694;&#26550;&#19979;&#36827;&#34892;&#20102;&#20998;&#31867;&#65292;&#25581;&#31034;&#20986;&#20854;&#20849;&#21516;&#28857;&#21644;&#24046;&#24322;&#12290;&#25105;&#20204;&#20174;&#26694;&#26550;&#30340;&#19977;&#20010;&#38454;&#27573;&#20998;&#26512;&#21644;&#20998;&#31867;&#26041;&#27861;&#65292;&#20026;&#26500;&#24314;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;GNNs&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#25351;&#23548;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#19968;&#20123;...
&lt;/p&gt;
&lt;p&gt;
Compared to other modalities, EEG-based emotion recognition can intuitively respond to the emotional patterns in the human brain and, therefore, has become one of the most concerning tasks in the brain-computer interfaces field. Since dependencies within brain regions are closely related to emotion, a significant trend is to develop Graph Neural Networks (GNNs) for EEG-based emotion recognition. However, brain region dependencies in emotional EEG have physiological bases that distinguish GNNs in this field from those in other time series fields. Besides, there is neither a comprehensive review nor guidance for constructing GNNs in EEG-based emotion recognition. In the survey, our categorization reveals the commonalities and differences of existing approaches under a unified framework of graph construction. We analyze and categorize methods from three stages in the framework to provide clear guidance on constructing GNNs in EEG-based emotion recognition. In addition, we discuss several 
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;(MARL)&#35782;&#21035;&#26410;&#31934;&#32454;&#35299;&#26512;&#30340;PDEs&#20013;&#30340;&#38381;&#21512;&#39033;&#65292;&#36890;&#36807;&#37096;&#32626;&#20013;&#22830;&#31574;&#30053;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#21644;&#21152;&#36895;&#27169;&#25311;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00972</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#35782;&#21035;&#31895;&#31890;&#24230;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#38381;&#21512;&#39033;
&lt;/p&gt;
&lt;p&gt;
Closure Discovery for Coarse-Grained Partial Differential Equations using Multi-Agent Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00972
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;(MARL)&#35782;&#21035;&#26410;&#31934;&#32454;&#35299;&#26512;&#30340;PDEs&#20013;&#30340;&#38381;&#21512;&#39033;&#65292;&#36890;&#36807;&#37096;&#32626;&#20013;&#22830;&#31574;&#30053;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#21644;&#21152;&#36895;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#22320;&#39044;&#27979;&#22825;&#27668;&#12289;&#37326;&#28779;&#21644;&#27969;&#34892;&#30149;&#31561;&#20851;&#38190;&#29616;&#35937;&#36890;&#24120;&#22522;&#20110;&#30001;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#25551;&#36848;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#25429;&#25417;&#36825;&#31181;PDEs&#20013;&#20840;&#38754;&#30340;&#26102;&#31354;&#23610;&#24230;&#33539;&#22260;&#30340;&#27169;&#25311;&#36890;&#24120;&#26159;&#20195;&#20215;&#39640;&#26114;&#30340;&#12290;&#22240;&#27492;&#65292;&#36890;&#24120;&#20250;&#20351;&#29992;&#21033;&#29992;&#21551;&#21457;&#24335;&#26041;&#27861;&#21644;&#32463;&#39564;&#38381;&#21512;&#39033;&#30340;&#31895;&#31890;&#24230;&#27169;&#25311;&#20316;&#20026;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;(MARL)&#35782;&#21035;&#26410;&#31934;&#32454;&#35299;&#26512;&#30340;PDEs&#20013;&#38381;&#21512;&#39033;&#30340;&#26032;&#39062;&#21644;&#31995;&#32479;&#30340;&#26041;&#27861;&#12290;MARL&#30340;&#24418;&#24335;&#21270;&#32467;&#21512;&#20102;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#21033;&#29992;&#37096;&#32626;&#20102;&#30001;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#39640;&#25928;&#34920;&#31034;&#30340;&#20013;&#22830;&#31574;&#30053;&#26469;&#21033;&#29992;&#23616;&#37096;&#24615;&#12290;&#36890;&#36807;&#23545;&#23545;&#27969;&#26041;&#31243;&#21644;Burgers&#26041;&#31243;&#30340;&#25968;&#20540;&#35299;&#36827;&#34892;&#28436;&#31034;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MARL&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;MARL&#23545;&#20110;&#20869;&#22806;&#20998;&#24067;&#30340;&#27979;&#35797;&#26696;&#20363;&#21487;&#20197;&#20934;&#30830;&#39044;&#27979;&#65292;&#24182;&#19988;&#19982;&#31934;&#32454;&#35299;&#26512;&#30456;&#27604;&#26377;&#26174;&#33879;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliable predictions of critical phenomena, such as weather, wildfires and epidemics are often founded on models described by Partial Differential Equations (PDEs). However, simulations that capture the full range of spatio-temporal scales in such PDEs are often prohibitively expensive. Consequently, coarse-grained simulations that employ heuristics and empirical closure terms are frequently utilized as an alternative. We propose a novel and systematic approach for identifying closures in under-resolved PDEs using Multi-Agent Reinforcement Learning (MARL). The MARL formulation incorporates inductive bias and exploits locality by deploying a central policy represented efficiently by Convolutional Neural Networks (CNN). We demonstrate the capabilities and limitations of MARL through numerical solutions of the advection equation and the Burgers' equation. Our results show accurate predictions for in- and out-of-distribution test cases as well as a significant speedup compared to resolving
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#39640;&#26031;&#36755;&#20837;&#19979;&#27880;&#24847;&#21147;&#24471;&#20998;&#31232;&#30095;&#24615;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#31232;&#30095;&#24615;&#30340;&#29305;&#24449;&#21450;&#20854;&#23545;&#35745;&#31639;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2404.02690</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#39640;&#26031;&#20998;&#24067;&#36755;&#20837;&#19979;&#33258;&#28982;&#31232;&#30095;
&lt;/p&gt;
&lt;p&gt;
Attention is Naturally Sparse with Gaussian Distributed Input
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02690
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#39640;&#26031;&#36755;&#20837;&#19979;&#27880;&#24847;&#21147;&#24471;&#20998;&#31232;&#30095;&#24615;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#31232;&#30095;&#24615;&#30340;&#29305;&#24449;&#21450;&#20854;&#23545;&#35745;&#31639;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35745;&#31639;&#24378;&#24230;&#26159;&#20851;&#38190;&#29942;&#39048;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;transformer&#26550;&#26500;&#20013;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;$O(n^2)$&#22797;&#26434;&#24230;&#12290;&#31232;&#30095;&#27880;&#24847;&#21147;&#20316;&#20026;&#19968;&#20010;&#20851;&#38190;&#21019;&#26032;&#24212;&#36816;&#32780;&#29983;&#65292;&#26088;&#22312;&#20943;&#23569;&#35745;&#31639;&#36127;&#33655;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#23545;LLMs&#20869;&#30340;&#27880;&#24847;&#21147;&#20998;&#25968;&#31232;&#30095;&#24615;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#26031;&#36755;&#20837;&#26694;&#26550;&#19979;&#12290;&#36890;&#36807;&#24314;&#31435;&#19968;&#32452;&#22522;&#30784;&#20551;&#35774;&#24182;&#37319;&#29992;&#19968;&#31181;&#31995;&#32479;&#30340;&#29702;&#35770;&#26041;&#27861;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#27880;&#24847;&#21147;&#20998;&#25968;&#31232;&#30095;&#24615;&#30340;&#20869;&#22312;&#29305;&#24449;&#21450;&#20854;&#23545;&#35745;&#31639;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#25552;&#20379;&#20102;&#23545;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#31232;&#30095;&#24615;&#34920;&#29616;&#24418;&#24335;&#30340;&#35814;&#32454;&#29702;&#35770;&#26816;&#26597;&#65292;&#25581;&#31034;&#20102;&#22312;&#35745;&#31639;&#33410;&#32422;&#21644;&#27169;&#22411;&#26377;&#25928;&#24615;&#20043;&#38388;&#28508;&#22312;&#26435;&#34913;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02690v1 Announce Type: cross  Abstract: The computational intensity of Large Language Models (LLMs) is a critical bottleneck, primarily due to the $O(n^2)$ complexity of the attention mechanism in transformer architectures. Addressing this, sparse attention emerges as a key innovation, aiming to reduce computational load while maintaining model performance. This study presents a rigorous theoretical analysis of the sparsity in attention scores within LLMs, particularly under the framework of Gaussian inputs. By establishing a set of foundational assumptions and employing a methodical theoretical approach, we unravel the intrinsic characteristics of attention score sparsity and its implications on computational efficiency. Our main contribution lies in providing a detailed theoretical examination of how sparsity manifests in attention mechanisms, offering insights into the potential trade-offs between computational savings and model effectiveness. This work not only advances 
&lt;/p&gt;</description></item><item><title>&#25972;&#21512;&#27491;&#24358;&#20989;&#25968;&#21040;&#20302;&#31209;&#20998;&#35299;&#36807;&#31243;&#20013;&#65292;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#39640;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.19243</link><description>&lt;p&gt;
&#29992;&#27491;&#24358;&#28608;&#27963;&#30340;&#20302;&#31209;&#30697;&#38453;&#23454;&#29616;&#21442;&#25968;&#39640;&#25928;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sine Activated Low-Rank Matrices for Parameter Efficient Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19243
&lt;/p&gt;
&lt;p&gt;
&#25972;&#21512;&#27491;&#24358;&#20989;&#25968;&#21040;&#20302;&#31209;&#20998;&#35299;&#36807;&#31243;&#20013;&#65292;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#20998;&#35299;&#24050;&#32463;&#25104;&#20026;&#22312;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#22686;&#24378;&#21442;&#25968;&#25928;&#29575;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#21508;&#31181;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#36825;&#20123;&#25216;&#26415;&#26174;&#33879;&#38477;&#20302;&#20102;&#21442;&#25968;&#25968;&#37327;&#65292;&#21462;&#24471;&#20102;&#31616;&#27905;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#24120;&#35265;&#30340;&#25361;&#25112;&#26159;&#22312;&#21442;&#25968;&#25928;&#29575;&#21644;&#27169;&#22411;&#20934;&#30830;&#24615;&#20043;&#38388;&#20570;&#20986;&#22949;&#21327;&#65292;&#21442;&#25968;&#20943;&#23569;&#24448;&#24448;&#23548;&#33268;&#20934;&#30830;&#24615;&#19981;&#21450;&#23436;&#25972;&#31209;&#23545;&#24212;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#22312;&#20302;&#31209;&#20998;&#35299;&#36807;&#31243;&#20013;&#25972;&#21512;&#20102;&#19968;&#20010;&#27491;&#24358;&#20989;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#20445;&#30041;&#20102;&#20302;&#31209;&#26041;&#27861;&#30340;&#21442;&#25968;&#25928;&#29575;&#29305;&#24615;&#30340;&#22909;&#22788;&#65292;&#36824;&#22686;&#21152;&#20102;&#20998;&#35299;&#30340;&#31209;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#34987;&#35777;&#26126;&#26159;&#29616;&#26377;&#20302;&#31209;&#27169;&#22411;&#30340;&#19968;&#31181;&#36866;&#24212;&#24615;&#22686;&#24378;&#65292;&#27491;&#22914;&#20854;&#25104;&#21151;&#35777;&#23454;&#30340;&#37027;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19243v1 Announce Type: new  Abstract: Low-rank decomposition has emerged as a vital tool for enhancing parameter efficiency in neural network architectures, gaining traction across diverse applications in machine learning. These techniques significantly lower the number of parameters, striking a balance between compactness and performance. However, a common challenge has been the compromise between parameter efficiency and the accuracy of the model, where reduced parameters often lead to diminished accuracy compared to their full-rank counterparts. In this work, we propose a novel theoretical framework that integrates a sinusoidal function within the low-rank decomposition process. This approach not only preserves the benefits of the parameter efficiency characteristic of low-rank methods but also increases the decomposition's rank, thereby enhancing model accuracy. Our method proves to be an adaptable enhancement for existing low-rank models, as evidenced by its successful 
&lt;/p&gt;</description></item><item><title>DrivAerNet&#25552;&#20379;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#39640;&#20445;&#30495;&#24230;&#30340;&#27773;&#36710;&#25968;&#25454;&#38598;&#65292;&#20197;&#35299;&#20915;&#24037;&#31243;&#24212;&#29992;&#20013;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#19981;&#36275;&#38382;&#39064;&#65292;&#32780;RegDGCNN&#21033;&#29992;&#36825;&#19968;&#25968;&#25454;&#38598;&#30452;&#25509;&#20174;3D&#32593;&#26684;&#25552;&#20379;&#39640;&#31934;&#24230;&#30340;&#38459;&#21147;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.08055</link><description>&lt;p&gt;
DrivAerNet&#65306;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#27668;&#21160;&#35774;&#35745;&#21644;&#22522;&#20110;&#22270;&#30340;&#38459;&#21147;&#39044;&#27979;&#30340;&#21442;&#25968;&#21270;&#27773;&#36710;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
DrivAerNet: A Parametric Car Dataset for Data-Driven Aerodynamic Design and Graph-Based Drag Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08055
&lt;/p&gt;
&lt;p&gt;
DrivAerNet&#25552;&#20379;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#39640;&#20445;&#30495;&#24230;&#30340;&#27773;&#36710;&#25968;&#25454;&#38598;&#65292;&#20197;&#35299;&#20915;&#24037;&#31243;&#24212;&#29992;&#20013;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#19981;&#36275;&#38382;&#39064;&#65292;&#32780;RegDGCNN&#21033;&#29992;&#36825;&#19968;&#25968;&#25454;&#38598;&#30452;&#25509;&#20174;3D&#32593;&#26684;&#25552;&#20379;&#39640;&#31934;&#24230;&#30340;&#38459;&#21147;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102; DrivAerNet&#65292;&#36825;&#26159;&#19968;&#20010;&#22823;&#35268;&#27169;&#39640;&#20445;&#30495;&#24230;&#30340;CFD&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;3D&#24037;&#19994;&#26631;&#20934;&#27773;&#36710;&#24418;&#29366;&#65292;&#20197;&#21450; RegDGCNN&#65292;&#36825;&#26159;&#19968;&#20010;&#21160;&#24577;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#26088;&#22312;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#27773;&#36710;&#27668;&#21160;&#35774;&#35745;&#12290;DrivAerNet&#25317;&#26377;4000&#20010;&#35814;&#32454;&#30340;3D&#27773;&#36710;&#32593;&#26684;&#65292;&#20351;&#29992;50&#19975;&#20010;&#34920;&#38754;&#32593;&#26684;&#38754;&#21644;&#20840;&#38754;&#27668;&#21160;&#24615;&#33021;&#25968;&#25454;&#65292;&#21253;&#25324;&#23436;&#25972;&#30340;3D&#21387;&#21147;&#12289;&#36895;&#24230;&#22330;&#21644;&#22721;&#38754;&#21098;&#20999;&#24212;&#21147;&#65292;&#28385;&#36275;&#20102;&#24037;&#31243;&#24212;&#29992;&#20013;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25152;&#38656;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#36843;&#20999;&#38656;&#27714;&#12290;&#23427;&#27604;&#20808;&#21069;&#21487;&#29992;&#30340;&#26368;&#22823;&#20844;&#24320;&#27773;&#36710;&#25968;&#25454;&#38598;&#22823;60&#65285;&#65292;&#20063;&#26159;&#21807;&#19968;&#21516;&#26102;&#27169;&#25311;&#36718;&#27586;&#21644;&#24213;&#30424;&#30340;&#24320;&#28304;&#25968;&#25454;&#38598;&#12290;RegDGCNN&#21033;&#29992;&#36825;&#19968;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#30452;&#25509;&#20174;3D&#32593;&#26684;&#25552;&#20379;&#39640;&#31934;&#24230;&#30340;&#38459;&#21147;&#20272;&#35745;&#65292;&#32469;&#36807;&#20102;&#20256;&#32479;&#38480;&#21046;&#65292;&#22914;&#38656;&#35201;2D&#22270;&#20687;&#28210;&#26579;&#25110;&#31526;&#21495;&#36317;&#31163;&#22330;&#65288;SDF&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08055v1 Announce Type: new  Abstract: This study introduces DrivAerNet, a large-scale high-fidelity CFD dataset of 3D industry-standard car shapes, and RegDGCNN, a dynamic graph convolutional neural network model, both aimed at aerodynamic car design through machine learning. DrivAerNet, with its 4000 detailed 3D car meshes using 0.5 million surface mesh faces and comprehensive aerodynamic performance data comprising of full 3D pressure, velocity fields, and wall-shear stresses, addresses the critical need for extensive datasets to train deep learning models in engineering applications. It is 60\% larger than the previously available largest public dataset of cars, and is the only open-source dataset that also models wheels and underbody. RegDGCNN leverages this large-scale dataset to provide high-precision drag estimates directly from 3D meshes, bypassing traditional limitations such as the need for 2D image rendering or Signed Distance Fields (SDF). By enabling fast drag e
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Solution Simplex Clustered Federated Learning&#65288;SosicFL&#65289;&#65292;&#36890;&#36807;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#30340;&#24605;&#24819;&#65292;&#20026;&#27599;&#20010;&#23458;&#25143;&#31471;&#20998;&#37197;&#21333;&#19968;&#21306;&#22495;&#65292;&#20174;&#32780;&#21516;&#26102;&#23454;&#29616;&#20102;&#23398;&#20064;&#26412;&#22320;&#21644;&#20840;&#23616;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2403.03333</link><description>&lt;p&gt;
Solution Simplex Clustering for Heterogeneous Federated Learning
&lt;/p&gt;
&lt;p&gt;
Solution Simplex Clustering for Heterogeneous Federated Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03333
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Solution Simplex Clustered Federated Learning&#65288;SosicFL&#65289;&#65292;&#36890;&#36807;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#30340;&#24605;&#24819;&#65292;&#20026;&#27599;&#20010;&#23458;&#25143;&#31471;&#20998;&#37197;&#21333;&#19968;&#21306;&#22495;&#65292;&#20174;&#32780;&#21516;&#26102;&#23454;&#29616;&#20102;&#23398;&#20064;&#26412;&#22320;&#21644;&#20840;&#23616;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;&#22312;&#39640;&#24230;&#24322;&#26500;&#30340;&#23458;&#25143;&#20998;&#24067;&#19979;&#23454;&#29616;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#36825;&#31181;&#22256;&#38590;&#37096;&#20998;&#28304;&#20110;&#20004;&#20010;&#30475;&#20284;&#30683;&#30462;&#30340;&#30446;&#26631;&#65306;&#36890;&#36807;&#32858;&#21512;&#26469;&#33258;&#23458;&#25143;&#31471;&#30340;&#20449;&#24687;&#26469;&#23398;&#20064;&#19968;&#20010;&#36890;&#29992;&#27169;&#22411;&#65292;&#20197;&#21450;&#23398;&#20064;&#24212;&#36866;&#24212;&#27599;&#20010;&#26412;&#22320;&#20998;&#24067;&#30340;&#26412;&#22320;&#20010;&#24615;&#21270;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Solution Simplex Clustered Federated Learning&#65288;SosicFL&#65289;&#26469;&#28040;&#38500;&#36825;&#31181;&#30683;&#30462;&#12290;&#22522;&#20110;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#30340;&#26368;&#26032;&#24605;&#24819;&#65292;SosicFL&#20026;&#27599;&#20010;&#23458;&#25143;&#31471;&#20998;&#37197;&#19968;&#20010;&#21333;&#32431;&#24418;&#20013;&#30340;&#23376;&#21306;&#22495;&#65292;&#24182;&#25191;&#34892;FL&#26469;&#23398;&#20064;&#19968;&#20010;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#12290;&#36825;&#20351;&#24471;&#23458;&#25143;&#31471;&#27169;&#22411;&#22312;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#30340;&#33258;&#30001;&#24230;&#33539;&#22260;&#20869;&#20855;&#26377;&#20854;&#29305;&#24449;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#23398;&#20064;&#19968;&#20010;&#20840;&#23616;&#36890;&#29992;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;SosicFL&#25913;&#21892;&#20102;&#24615;&#33021;&#65292;&#24182;&#21152;&#36895;&#20102;&#20840;&#23616;&#21644;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03333v1 Announce Type: new  Abstract: We tackle a major challenge in federated learning (FL) -- achieving good performance under highly heterogeneous client distributions. The difficulty partially arises from two seemingly contradictory goals: learning a common model by aggregating the information from clients, and learning local personalized models that should be adapted to each local distribution. In this work, we propose Solution Simplex Clustered Federated Learning (SosicFL) for dissolving such contradiction. Based on the recent ideas of learning solution simplices, SosicFL assigns a subregion in a simplex to each client, and performs FL to learn a common solution simplex. This allows the client models to possess their characteristics within the degrees of freedom in the solution simplex, and at the same time achieves the goal of learning a global common model. Our experiments show that SosicFL improves the performance and accelerates the training process for global and 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#22312;&#33521;&#25991;&#21644;&#20013;&#25991;&#30005;&#23376;&#37038;&#20214;&#25968;&#25454;&#38598;&#20013;&#29992;&#20110;&#22403;&#22334;&#37038;&#20214;&#26816;&#27979;&#30340;&#24615;&#33021;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.15537</link><description>&lt;p&gt;
&#35780;&#20272;ChatGPT&#29992;&#20110;&#22403;&#22334;&#37038;&#20214;&#26816;&#27979;&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Performance of ChatGPT for Spam Email Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15537
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#22312;&#33521;&#25991;&#21644;&#20013;&#25991;&#30005;&#23376;&#37038;&#20214;&#25968;&#25454;&#38598;&#20013;&#29992;&#20110;&#22403;&#22334;&#37038;&#20214;&#26816;&#27979;&#30340;&#24615;&#33021;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#37038;&#20214;&#32487;&#32493;&#26159;&#19987;&#19994;&#21644;&#21830;&#19994;&#39046;&#22495;&#20013;&#33267;&#20851;&#37325;&#35201;&#19988;&#24191;&#27867;&#20351;&#29992;&#30340;&#36890;&#20449;&#23186;&#20171;&#12290;&#28982;&#32780;&#65292;&#22403;&#22334;&#37038;&#20214;&#30340;&#26222;&#21450;&#32473;&#29992;&#25143;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#65292;&#25200;&#20081;&#20102;&#20182;&#20204;&#30340;&#26085;&#24120;&#24037;&#20316;&#24182;&#38477;&#20302;&#20102;&#29983;&#20135;&#29575;&#12290;&#22240;&#27492;&#65292;&#22522;&#20110;&#20869;&#23481;&#20934;&#30830;&#22320;&#35782;&#21035;&#21644;&#36807;&#28388;&#22403;&#22334;&#37038;&#20214;&#23545;&#32593;&#32476;&#23433;&#20840;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;ChatGPT&#65292;&#22312;&#35832;&#22914;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#31561;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#20854;&#22312;&#22403;&#22334;&#37038;&#20214;&#35782;&#21035;&#26041;&#38754;&#30340;&#28508;&#21147;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#30740;&#31350;&#23581;&#35797;&#35780;&#20272;ChatGPT&#22312;&#33521;&#25991;&#21644;&#20013;&#25991;&#30005;&#23376;&#37038;&#20214;&#25968;&#25454;&#38598;&#20013;&#29992;&#20110;&#22403;&#22334;&#37038;&#20214;&#35782;&#21035;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#21033;&#29992;ChatGPT&#36827;&#34892;&#22403;&#22334;&#37038;&#20214;&#26816;&#27979;&#65292;&#37319;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#38656;&#35201;&#25552;&#31034;&#35828;&#26126;&#21644;&#23569;&#37327;&#31034;&#33539;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15537v1 Announce Type: cross  Abstract: Email continues to be a pivotal and extensively utilized communication medium within professional and commercial domains. Nonetheless, the prevalence of spam emails poses a significant challenge for users, disrupting their daily routines and diminishing productivity. Consequently, accurately identifying and filtering spam based on content has become crucial for cybersecurity. Recent advancements in natural language processing, particularly with large language models like ChatGPT, have shown remarkable performance in tasks such as question answering and text generation. However, its potential in spam identification remains underexplored. To fill in the gap, this study attempts to evaluate ChatGPT's capabilities for spam identification in both English and Chinese email datasets. We employ ChatGPT for spam email detection using in-context learning, which requires a prompt instruction and a few demonstrations. We also investigate how the t
&lt;/p&gt;</description></item><item><title>TinyCL&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#20027;&#31995;&#32479;&#25345;&#32493;&#23398;&#20064;&#30340;&#39640;&#25928;&#30828;&#20214;&#26550;&#26500;&#65292;&#22312;CL&#20013;&#25903;&#25345;&#21069;&#21521;&#21644;&#21453;&#21521;&#20256;&#25773;&#65292;&#24182;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#30340;&#36830;&#32493;&#23398;&#20064;&#31574;&#30053;&#26469;&#20943;&#23569;&#20869;&#23384;&#35775;&#38382;&#12290;</title><link>https://arxiv.org/abs/2402.09780</link><description>&lt;p&gt;
TinyCL:&#19968;&#31181;&#29992;&#20110;&#33258;&#20027;&#31995;&#32479;&#25345;&#32493;&#23398;&#20064;&#30340;&#39640;&#25928;&#30828;&#20214;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
TinyCL: An Efficient Hardware Architecture for Continual Learning on Autonomous Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09780
&lt;/p&gt;
&lt;p&gt;
TinyCL&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#20027;&#31995;&#32479;&#25345;&#32493;&#23398;&#20064;&#30340;&#39640;&#25928;&#30828;&#20214;&#26550;&#26500;&#65292;&#22312;CL&#20013;&#25903;&#25345;&#21069;&#21521;&#21644;&#21453;&#21521;&#20256;&#25773;&#65292;&#24182;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#30340;&#36830;&#32493;&#23398;&#20064;&#31574;&#30053;&#26469;&#20943;&#23569;&#20869;&#23384;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#33539;&#24335;&#21253;&#25324;&#19981;&#26029;&#28436;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;&#20197;&#36880;&#27493;&#23398;&#20064;&#25191;&#34892;&#26032;&#20219;&#21153;&#65292;&#32780;&#19981;&#38477;&#20302;&#20808;&#21069;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#21363;&#36991;&#20813;&#25152;&#35859;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#28982;&#32780;&#65292;&#22312;&#22522;&#20110;CL&#30340;&#33258;&#20027;&#31995;&#32479;&#20013;&#65292;DNN&#21442;&#25968;&#26356;&#26032;&#23545;&#36164;&#28304;&#35201;&#27714;&#26497;&#39640;&#12290;&#29616;&#26377;&#30340;DNN&#21152;&#36895;&#22120;&#19981;&#33021;&#30452;&#25509;&#29992;&#20110;CL&#65292;&#22240;&#20026;&#23427;&#20204;&#21482;&#25903;&#25345;&#21069;&#21521;&#20256;&#25773;&#30340;&#25191;&#34892;&#12290;&#21482;&#26377;&#23569;&#25968;&#20808;&#21069;&#30340;&#26550;&#26500;&#25191;&#34892;&#21453;&#21521;&#20256;&#25773;&#21644;&#26435;&#37325;&#26356;&#26032;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#23545;CL&#30340;&#25511;&#21046;&#21644;&#31649;&#29702;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#30828;&#20214;&#26550;&#26500;TinyCL&#65292;&#29992;&#20110;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#33258;&#20027;&#31995;&#32479;&#19978;&#36827;&#34892;&#25345;&#32493;&#23398;&#20064;&#12290;&#23427;&#21253;&#25324;&#19968;&#20010;&#25191;&#34892;&#21069;&#21521;&#21644;&#21453;&#21521;&#20256;&#25773;&#30340;&#22788;&#29702;&#21333;&#20803;&#65292;&#20197;&#21450;&#19968;&#20010;&#31649;&#29702;&#22522;&#20110;&#20869;&#23384;&#30340;CL&#24037;&#20316;&#36127;&#36733;&#30340;&#25511;&#21046;&#21333;&#20803;&#12290;&#20026;&#20102;&#26368;&#23567;&#21270;&#20869;&#23384;&#35775;&#38382;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#28369;&#21160;&#31383;&#21475;&#30340;&#36830;&#32493;&#23398;&#20064;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09780v1 Announce Type: new  Abstract: The Continuous Learning (CL) paradigm consists of continuously evolving the parameters of the Deep Neural Network (DNN) model to progressively learn to perform new tasks without reducing the performance on previous tasks, i.e., avoiding the so-called catastrophic forgetting. However, the DNN parameter update in CL-based autonomous systems is extremely resource-hungry. The existing DNN accelerators cannot be directly employed in CL because they only support the execution of the forward propagation. Only a few prior architectures execute the backpropagation and weight update, but they lack the control and management for CL. Towards this, we design a hardware architecture, TinyCL, to perform CL on resource-constrained autonomous systems. It consists of a processing unit that executes both forward and backward propagation, and a control unit that manages memory-based CL workload. To minimize the memory accesses, the sliding window of the con
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#21453;&#20107;&#23454;&#20998;&#26512;&#26694;&#26550;&#35780;&#20272;&#20102;&#21313;&#20010;&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#23545;&#22235;&#31181;&#32534;&#31243;&#27010;&#24565;&#30340;&#29702;&#35299;&#24773;&#20917;&#65292;&#21457;&#29616;&#24403;&#21069;&#27169;&#22411;&#32570;&#20047;&#23545;&#25968;&#25454;&#27969;&#21644;&#25511;&#21046;&#27969;&#31561;&#27010;&#24565;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.05980</link><description>&lt;p&gt;
&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#26159;&#21542;&#29702;&#35299;&#32534;&#31243;&#27010;&#24565;&#65311;&#19968;&#31181;&#40657;&#30418;&#26041;&#27861;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Do Large Code Models Understand Programming Concepts? A Black-box Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#21453;&#20107;&#23454;&#20998;&#26512;&#26694;&#26550;&#35780;&#20272;&#20102;&#21313;&#20010;&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#23545;&#22235;&#31181;&#32534;&#31243;&#27010;&#24565;&#30340;&#29702;&#35299;&#24773;&#20917;&#65292;&#21457;&#29616;&#24403;&#21069;&#27169;&#22411;&#32570;&#20047;&#23545;&#25968;&#25454;&#27969;&#21644;&#25511;&#21046;&#27969;&#31561;&#27010;&#24565;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#30340;&#25104;&#21151;&#20063;&#20351;&#20854;&#22312;&#20195;&#30721;&#29983;&#25104;&#21644;&#32534;&#30721;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#12290;&#34429;&#28982;&#26377;&#24456;&#22810;&#24037;&#20316;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#20195;&#30721;&#34917;&#20840;&#21644;&#32534;&#36753;&#31561;&#20219;&#21153;&#19978;&#30340;&#20986;&#33394;&#24615;&#33021;&#65292;&#20294;&#20026;&#20160;&#20040;&#23427;&#20204;&#33021;&#22815;&#25104;&#21151;&#36824;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#36890;&#36807;&#25506;&#32034;&#33258;&#22238;&#24402;&#27169;&#22411;&#23545;&#24213;&#23618;&#31243;&#24207;&#30340;&#36923;&#36753;&#32467;&#26500;&#29702;&#35299;&#31243;&#24230;&#65292;&#26469;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#32534;&#31243;&#27010;&#24565;&#35859;&#35789;&#30340;&#21453;&#20107;&#23454;&#20998;&#26512;&#65288;CACP&#65289;&#20316;&#20026;&#19968;&#31181;&#21453;&#20107;&#23454;&#27979;&#35797;&#26694;&#26550;&#65292;&#20197;&#35780;&#20272;&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#26159;&#21542;&#29702;&#35299;&#32534;&#31243;&#27010;&#24565;&#12290;&#21482;&#36890;&#36807;&#40657;&#30418;&#35775;&#38382;&#27169;&#22411;&#65292;&#25105;&#20204;&#20351;&#29992;CACP&#35780;&#20272;&#20102;&#21313;&#20010;&#27969;&#34892;&#30340;&#22823;&#22411;&#20195;&#30721;&#27169;&#22411;&#23545;&#22235;&#20010;&#19981;&#21516;&#32534;&#31243;&#27010;&#24565;&#30340;&#29702;&#35299;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21069;&#27169;&#22411;&#32570;&#20047;&#23545;&#25968;&#25454;&#27969;&#21644;&#25511;&#21046;&#27969;&#31561;&#27010;&#24565;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models' success on text generation has also made them better at code generation and coding tasks. While a lot of work has demonstrated their remarkable performance on tasks such as code completion and editing, it is still unclear as to why. We help bridge this gap by exploring to what degree auto-regressive models understand the logical constructs of the underlying programs. We propose Counterfactual Analysis for Programming Concept Predicates (CACP) as a counterfactual testing framework to evaluate whether Large Code Models understand programming concepts. With only black-box access to the model, we use CACP to evaluate ten popular Large Code Models for four different programming concepts. Our findings suggest that current models lack understanding of concepts such as data flow and control flow.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#32508;&#36848;&#19981;&#21516;&#30340;&#26041;&#27861;&#20197;&#21450;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#25913;&#36827;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.04059</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Deep Learning for Multivariate Time Series Imputation: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#32508;&#36848;&#19981;&#21516;&#30340;&#26041;&#27861;&#20197;&#21450;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#25913;&#36827;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26222;&#36941;&#23384;&#22312;&#30340;&#32570;&#22833;&#20540;&#23548;&#33268;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#37096;&#20998;&#35266;&#27979;&#65292;&#30772;&#22351;&#20102;&#26102;&#38388;&#24207;&#21015;&#30340;&#23436;&#25972;&#24615;&#65292;&#38459;&#30861;&#20102;&#26377;&#25928;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#12290;&#26368;&#36817;&#65292;&#28145;&#24230;&#23398;&#20064;&#25554;&#34917;&#26041;&#27861;&#22312;&#25552;&#39640;&#25439;&#22351;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36136;&#37327;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#36827;&#32780;&#25552;&#39640;&#20102;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#23545;&#26368;&#36817;&#25552;&#20986;&#30340;&#28145;&#24230;&#23398;&#20064;&#25554;&#34917;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24378;&#35843;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#26469;&#36827;&#34892;&#20102;&#32467;&#26500;&#21270;&#30340;&#32508;&#36848;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#23454;&#35777;&#23454;&#39564;&#65292;&#30740;&#31350;&#20102;&#19981;&#21516;&#26041;&#27861;&#65292;&#24182;&#27604;&#36739;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#25913;&#36827;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;&#20102;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#26412;&#25991;&#30340;&#25152;&#26377;&#20195;&#30721;&#21644;&#37197;&#32622;&#65292;&#21253;&#25324;&#23450;&#26399;&#32500;&#25252;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#35770;&#25991;&#21015;&#34920;&#65292;&#21487;&#20197;&#22312;&#20197;&#19979;&#20301;&#32622;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ubiquitous missing values cause the multivariate time series data to be partially observed, destroying the integrity of time series and hindering the effective time series data analysis. Recently deep learning imputation methods have demonstrated remarkable success in elevating the quality of corrupted time series data, subsequently enhancing performance in downstream tasks. In this paper, we conduct a comprehensive survey on the recently proposed deep learning imputation methods. First, we propose a taxonomy for the reviewed methods, and then provide a structured review of these methods by highlighting their strengths and limitations. We also conduct empirical experiments to study different methods and compare their enhancement for downstream tasks. Finally, the open issues for future research on multivariate time series imputation are pointed out. All code and configurations of this work, including a regularly maintained multivariate time series imputation paper list, can be foun
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;State-Dependent Causal Inference&#65288;SDCI&#65289;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#19968;&#31867;&#23485;&#27867;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65292;&#25104;&#21151;&#22320;&#22238;&#22797;&#20986;&#28508;&#22312;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2110.06257</link><description>&lt;p&gt;
&#20174;&#26377;&#26465;&#20214;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#20013;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery from Conditionally Stationary Time Series
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2110.06257
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;State-Dependent Causal Inference&#65288;SDCI&#65289;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#19968;&#31867;&#23485;&#27867;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65292;&#25104;&#21151;&#22320;&#22238;&#22797;&#20986;&#28508;&#22312;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#65292;&#21363;&#20174;&#35266;&#27979;&#25968;&#25454;&#25512;&#26029;&#28508;&#22312;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#24050;&#34987;&#35777;&#26126;&#23545;AI&#31995;&#32479;&#20855;&#26377;&#26497;&#22823;&#25361;&#25112;&#12290;&#22312;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#32972;&#26223;&#19979;&#65292;&#20256;&#32479;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#20027;&#35201;&#32771;&#34385;&#20855;&#26377;&#23436;&#20840;&#35266;&#27979;&#21464;&#37327;&#21644;/&#25110;&#26469;&#33258;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#25968;&#25454;&#30340;&#21463;&#38480;&#22330;&#26223;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#26469;&#22788;&#29702;&#19968;&#31867;&#23485;&#27867;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65292;&#21363;&#22312;&#26465;&#20214;&#19978;&#26159;&#24179;&#31283;&#30340;&#26465;&#20214;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65292;&#20854;&#20013;&#38750;&#24179;&#31283;&#34892;&#20026;&#34987;&#24314;&#27169;&#20026;&#22312;&#19968;&#32452;&#65288;&#21487;&#33021;&#26159;&#38544;&#34255;&#30340;&#65289;&#29366;&#24577;&#21464;&#37327;&#19978;&#30340;&#24179;&#31283;&#24615;&#12290;&#21629;&#21517;&#20026;State-Dependent Causal Inference&#65288;SDCI&#65289;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#21487;&#35777;&#22320;&#22238;&#22797;&#20986;&#28508;&#22312;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#65292;&#35777;&#26126;&#22312;&#23436;&#20840;&#35266;&#23519;&#21040;&#30340;&#29366;&#24577;&#19979;&#65292;&#24182;&#22312;&#23384;&#22312;&#38544;&#34255;&#29366;&#24577;&#26102;&#32463;&#39564;&#24615;&#22320;&#23454;&#29616;&#12290;&#21518;&#32773;&#36890;&#36807;&#23545;&#21512;&#25104;&#32447;&#24615;&#31995;&#32479;&#21644;&#38750;&#32447;&#24615;&#31890;&#23376;&#30456;&#20114;&#20316;&#29992;&#25968;&#25454;&#30340;&#23454;&#39564;&#36827;&#34892;&#39564;&#35777;&#65292;SDCI&#23454;&#29616;&#20102;&#20248;&#20110;&#22522;&#32447;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2110.06257v2 Announce Type: replace  Abstract: Causal discovery, i.e., inferring underlying causal relationships from observational data, has been shown to be highly challenging for AI systems. In time series modeling context, traditional causal discovery methods mainly consider constrained scenarios with fully observed variables and/or data from stationary time-series. We develop a causal discovery approach to handle a wide class of non-stationary time-series that are conditionally stationary, where the non-stationary behaviour is modeled as stationarity conditioned on a set of (possibly hidden) state variables. Named State-Dependent Causal Inference (SDCI), our approach is able to recover the underlying causal dependencies, provably with fully-observed states and empirically with hidden states. The latter is confirmed by experiments on synthetic linear system and nonlinear particle interaction data, where SDCI achieves superior performance over baseline causal discovery methods
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#36890;&#36807;&#20803;&#34920;&#31034;&#36827;&#34892;&#34920;&#26684;&#25968;&#25454;&#39044;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#22312;&#24322;&#26500;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#26080;&#35757;&#32451;&#27867;&#21270;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2311.00055</link><description>&lt;p&gt;
&#36890;&#36807;&#20803;&#34920;&#31034;&#23545;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#36827;&#34892;&#26080;&#35757;&#32451;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Training-Free Generalization on Heterogeneous Tabular Data via Meta-Representation. (arXiv:2311.00055v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00055
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#36890;&#36807;&#20803;&#34920;&#31034;&#36827;&#34892;&#34920;&#26684;&#25968;&#25454;&#39044;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#22312;&#24322;&#26500;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#26080;&#35757;&#32451;&#27867;&#21270;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#28982;&#32780;&#65292;&#19981;&#21516;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#23646;&#24615;&#21644;&#31867;&#21035;&#31354;&#38388;&#30340;&#22266;&#26377;&#24322;&#36136;&#24615;&#38459;&#30861;&#20102;&#30693;&#35782;&#30340;&#26377;&#25928;&#20849;&#20139;&#65292;&#38480;&#21046;&#20102;&#34920;&#26684;&#27169;&#22411;&#20174;&#20854;&#20182;&#25968;&#25454;&#38598;&#20013;&#21463;&#30410;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#20803;&#34920;&#31034;&#36827;&#34892;&#34920;&#26684;&#25968;&#25454;&#39044;&#35757;&#32451;&#65288;TabPTM&#65289;&#65292;&#23427;&#20801;&#35768;&#19968;&#20010;&#34920;&#26684;&#27169;&#22411;&#22312;&#19968;&#32452;&#24322;&#26500;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#36825;&#20010;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20110;&#20855;&#26377;&#19981;&#21516;&#23646;&#24615;&#21644;&#31867;&#21035;&#30340;&#26410;&#35265;&#36807;&#30340;&#25968;&#25454;&#38598;&#65292;&#26080;&#38656;&#39069;&#22806;&#35757;&#32451;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;TabPTM&#36890;&#36807;&#23454;&#20363;&#21040;&#22266;&#23450;&#25968;&#37327;&#30340;&#21407;&#22411;&#30340;&#36317;&#31163;&#26469;&#34920;&#31034;&#19968;&#20010;&#23454;&#20363;&#65292;&#20174;&#32780;&#26631;&#20934;&#21270;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#19968;&#20010;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#34987;&#35757;&#32451;&#26469;&#23558;&#36825;&#20123;&#20803;&#34920;&#31034;&#19982;&#25968;&#25454;&#38598;&#29305;&#23450;&#30340;&#20998;&#31867;&#32622;&#20449;&#24230;&#20851;&#32852;&#36215;&#26469;&#65292;&#20351;TabPTM&#20855;&#26377;&#26080;&#38656;&#35757;&#32451;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#23454;TabPTM&#22312;&#26032;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tabular data is prevalent across various machine learning domains. Yet, the inherent heterogeneities in attribute and class spaces across different tabular datasets hinder the effective sharing of knowledge, limiting a tabular model to benefit from other datasets. In this paper, we propose Tabular data Pre-Training via Meta-representation (TabPTM), which allows one tabular model pre-training on a set of heterogeneous datasets. Then, this pre-trained model can be directly applied to unseen datasets that have diverse attributes and classes without additional training. Specifically, TabPTM represents an instance through its distance to a fixed number of prototypes, thereby standardizing heterogeneous tabular datasets. A deep neural network is then trained to associate these meta-representations with dataset-specific classification confidences, endowing TabPTM with the ability of training-free generalization. Experiments validate that TabPTM achieves promising performance in new datasets, 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.18304</link><description>&lt;p&gt;
&#23398;&#20064;&#38750;&#31283;&#24577;&#26465;&#20214;&#19979;&#30340;&#31283;&#23450;&#24615;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38750;&#31283;&#23450;&#29615;&#22659;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#26469;&#36873;&#25321;&#19968;&#20010;&#22238;&#28335;&#31383;&#21475;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#65292;&#21516;&#26102;&#23558;&#32047;&#31215;&#20559;&#24046;&#20445;&#25345;&#22312;&#19982;&#38543;&#26426;&#35823;&#24046;&#30456;&#23545;&#21487;&#25509;&#21463;&#30340;&#33539;&#22260;&#20869;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#26410;&#30693;&#38750;&#31283;&#23450;&#24615;&#30340;&#36866;&#24212;&#24615;&#12290;&#24403;&#20154;&#21475;&#25439;&#22833;&#20989;&#25968;&#24378;&#20984;&#25110;&#20165;&#28385;&#36275;Lipschitz&#26465;&#20214;&#26102;&#65292;&#36951;&#25022;&#30028;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#65292;&#20165;&#21463;&#23545;&#25968;&#22240;&#23376;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26680;&#24515;&#26159;&#20004;&#20010;&#26032;&#39062;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#20989;&#25968;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#23558;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#20026;&#20934;&#31283;&#24577;&#29255;&#27573;&#30340;&#20998;&#21106;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
&lt;/p&gt;</description></item><item><title>&#22312;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#65292;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#20844;&#24179;&#24615;&#65292;&#22240;&#20026;&#23436;&#20840;&#36981;&#23432;&#31639;&#27861;&#20915;&#31574;&#24456;&#23569;&#26159;&#29616;&#23454;&#21487;&#34892;&#30340;&#65292;&#22240;&#27492;&#25105;&#20204;&#38656;&#35201;&#35774;&#35745;&#31283;&#20581;&#20844;&#24179;&#30340;&#31639;&#27861;&#25512;&#33616;&#26469;&#25552;&#21319;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03647</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rethinking Fairness for Human-AI Collaboration. (arXiv:2310.03647v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03647
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#65292;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#20844;&#24179;&#24615;&#65292;&#22240;&#20026;&#23436;&#20840;&#36981;&#23432;&#31639;&#27861;&#20915;&#31574;&#24456;&#23569;&#26159;&#29616;&#23454;&#21487;&#34892;&#30340;&#65292;&#22240;&#27492;&#25105;&#20204;&#38656;&#35201;&#35774;&#35745;&#31283;&#20581;&#20844;&#24179;&#30340;&#31639;&#27861;&#25512;&#33616;&#26469;&#25552;&#21319;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#31639;&#27861;&#20844;&#24179;&#24615;&#26041;&#27861;&#26088;&#22312;&#30830;&#20445;&#20154;&#31867;&#20915;&#31574;&#32773;&#23436;&#20840;&#36981;&#23432;&#31639;&#27861;&#20915;&#31574;&#26102;&#23454;&#29616;&#20844;&#24179;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#65292;&#23436;&#20840;&#36981;&#23432;&#31639;&#27861;&#20915;&#31574;&#24456;&#23569;&#26159;&#29616;&#23454;&#25110;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20844;&#24179;&#31639;&#27861;&#30340;&#36873;&#25321;&#24615;&#36981;&#23432;&#20250;&#30456;&#23545;&#20110;&#20154;&#31867;&#20197;&#21069;&#30340;&#25919;&#31574;&#22686;&#21152;&#27495;&#35270;&#12290;&#22240;&#27492;&#65292;&#30830;&#20445;&#20844;&#24179;&#32467;&#26524;&#38656;&#35201;&#22522;&#26412;&#19981;&#21516;&#30340;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65292;&#20197;&#30830;&#20445;&#23545;&#20915;&#31574;&#32773;&#65288;&#20107;&#20808;&#19981;&#30693;&#36947;&#65289;&#30340;&#36981;&#23432;&#27169;&#24335;&#20855;&#26377;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#31181;&#36981;&#23432;&#31283;&#20581;&#20844;&#24179;&#30340;&#31639;&#27861;&#25512;&#33616;&#65292;&#26080;&#35770;&#20154;&#31867;&#30340;&#36981;&#23432;&#27169;&#24335;&#22914;&#20309;&#65292;&#23427;&#20204;&#37117;&#33021;&#30830;&#20445;&#22312;&#20915;&#31574;&#20013;&#25913;&#21892;&#20844;&#24179;&#24615;&#65288;&#24369;&#24418;&#24847;&#20041;&#19978;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#30830;&#23450;&#26368;&#20339;&#30340;&#24615;&#33021;&#25913;&#36827;&#36981;&#23432;&#31283;&#20581;&#20844;&#24179;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#35774;&#35745;&#31639;&#27861;&#25512;&#33616;&#21487;&#33021;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing approaches to algorithmic fairness aim to ensure equitable outcomes if human decision-makers comply perfectly with algorithmic decisions. However, perfect compliance with the algorithm is rarely a reality or even a desirable outcome in human-AI collaboration. Yet, recent studies have shown that selective compliance with fair algorithms can amplify discrimination relative to the prior human policy. As a consequence, ensuring equitable outcomes requires fundamentally different algorithmic design principles that ensure robustness to the decision-maker's (a priori unknown) compliance pattern. We define the notion of compliance-robustly fair algorithmic recommendations that are guaranteed to (weakly) improve fairness in decisions, regardless of the human's compliance pattern. We propose a simple optimization strategy to identify the best performance-improving compliance-robustly fair policy. However, we show that it may be infeasible to design algorithmic recommendations that are s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#22312;&#21435;&#37327;&#21270;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#28508;&#21147;&#19982;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#30830;&#31435;&#20102;&#20854;&#39640;&#25928;&#21435;&#37327;&#21270;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;PQC&#26550;&#26500;&#35774;&#35745;&#24314;&#35758;&#21644;&#35782;&#21035;&#20102;&#28508;&#22312;&#37327;&#23376;&#20248;&#21183;&#30340;&#24517;&#35201;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2309.11647</link><description>&lt;p&gt;
&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#22312;&#21435;&#37327;&#21270;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#28508;&#21147;&#19982;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Potential and limitations of random Fourier features for dequantizing quantum machine learning. (arXiv:2309.11647v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11647
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#22312;&#21435;&#37327;&#21270;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#28508;&#21147;&#19982;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#30830;&#31435;&#20102;&#20854;&#39640;&#25928;&#21435;&#37327;&#21270;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;PQC&#26550;&#26500;&#35774;&#35745;&#24314;&#35758;&#21644;&#35782;&#21035;&#20102;&#28508;&#22312;&#37327;&#23376;&#20248;&#21183;&#30340;&#24517;&#35201;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#26159;&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#26368;&#24191;&#27867;&#25506;&#32034;&#30340;&#24212;&#29992;&#20043;&#19968;&#12290;&#30446;&#21069;&#20027;&#35201;&#20851;&#27880;&#30340;&#26159;&#21464;&#20998;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65292;&#20854;&#20013;&#21442;&#25968;&#21270;&#37327;&#23376;&#30005;&#36335;&#34987;&#29992;&#20316;&#23398;&#20064;&#27169;&#22411;&#12290;&#36825;&#20123;&#21442;&#25968;&#21270;&#37327;&#23376;&#30005;&#36335;&#27169;&#22411;&#20855;&#26377;&#20016;&#23500;&#30340;&#32467;&#26500;&#65292;&#22240;&#27492;&#21487;&#33021;&#36890;&#36807;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#36827;&#34892;&#39640;&#25928;&#30340;&#21435;&#37327;&#21270;&#12290;&#26412;&#25991;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#30830;&#31435;&#20102;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#22312;&#21464;&#20998;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#25552;&#20379;&#39640;&#25928;&#21435;&#37327;&#21270;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#20307;&#30340;&#21442;&#25968;&#21270;&#37327;&#23376;&#30005;&#36335;&#26550;&#26500;&#35774;&#35745;&#24314;&#35758;&#65292;&#20197;&#21450;&#35782;&#21035;&#20102;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#21462;&#24471;&#28508;&#22312;&#37327;&#23376;&#20248;&#21183;&#30340;&#24517;&#35201;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum machine learning is arguably one of the most explored applications of near-term quantum devices. Much focus has been put on notions of variational quantum machine learning where parameterized quantum circuits (PQCs) are used as learning models. These PQC models have a rich structure which suggests that they might be amenable to efficient dequantization via random Fourier features (RFF). In this work, we establish necessary and sufficient conditions under which RFF does indeed provide an efficient dequantization of variational quantum machine learning for regression. We build on these insights to make concrete suggestions for PQC architecture design, and to identify structures which are necessary for a regression problem to admit a potential quantum advantage via PQC based optimization.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#20108;&#27425;&#35268;&#21010;&#36755;&#20837;&#35268;&#27169;&#21644;&#35299;&#20915;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.07735</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Nearly-Linear Time Algorithm for Structured Support Vector Machines. (arXiv:2307.07735v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07735
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#20108;&#27425;&#35268;&#21010;&#36755;&#20837;&#35268;&#27169;&#21644;&#35299;&#20915;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#27425;&#35268;&#21010;&#26159;&#20984;&#20248;&#21270;&#39046;&#22495;&#20013;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#35768;&#22810;&#23454;&#38469;&#20219;&#21153;&#21487;&#20197;&#34920;&#31034;&#20026;&#20108;&#27425;&#35268;&#21010;&#65292;&#20363;&#22914;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30427;&#34892;&#20043;&#21069;&#65292;&#32447;&#24615;SVM&#26159;&#36807;&#21435;&#19977;&#21313;&#24180;&#26469;&#26368;&#27969;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#20043;&#19968;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#19968;&#20010;&#20108;&#27425;&#35268;&#21010;&#30340;&#36755;&#20837;&#35268;&#27169;&#20026;&#920;(n^2)&#65288;&#20854;&#20013;n&#26159;&#21464;&#37327;&#30340;&#25968;&#37327;&#65289;&#65292;&#22240;&#27492;&#35299;&#20915;&#35813;&#38382;&#39064;&#38656;&#35201;&#937;(n^2)&#30340;&#26102;&#38388;&#12290;&#28982;&#32780;&#65292;SVM&#20135;&#29983;&#30340;&#20108;&#27425;&#35268;&#21010;&#30340;&#36755;&#20837;&#35268;&#27169;&#20026;O(n)&#65292;&#36825;&#20351;&#24471;&#35774;&#35745;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#25104;&#20026;&#21487;&#33021;&#12290;&#20004;&#20010;&#37325;&#35201;&#30340;SVM&#31867;&#21035;&#26159;&#20855;&#26377;&#20302;&#31209;&#26680;&#22240;&#24335;&#20998;&#35299;&#21644;&#20302;&#26641;&#23485;&#35268;&#27169;&#30340;&#31243;&#24207;&#12290;&#20302;&#26641;&#23485;&#20984;&#20248;&#21270;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65288;&#20363;&#22914;&#32447;&#24615;&#35268;&#21010;[Dong, Lee and Ye 2021]&#21644;&#21322;&#23450;&#35268;&#21010;[Gu and Song 2022]&#65289;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#24320;&#25918;&#38382;&#39064;&#26159;&#26159;&#21542;&#23384;&#22312;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quadratic programming is a fundamental problem in the field of convex optimization. Many practical tasks can be formulated as quadratic programming, for example, the support vector machine (SVM). Linear SVM is one of the most popular tools over the last three decades in machine learning before deep learning method dominating.  In general, a quadratic program has input size $\Theta(n^2)$ (where $n$ is the number of variables), thus takes $\Omega(n^2)$ time to solve. Nevertheless, quadratic programs coming from SVMs has input size $O(n)$, allowing the possibility of designing nearly-linear time algorithms. Two important classes of SVMs are programs admitting low-rank kernel factorizations and low-treewidth programs. Low-treewidth convex optimization has gained increasing interest in the past few years (e.g.~linear programming [Dong, Lee and Ye 2021] and semidefinite programming [Gu and Song 2022]). Therefore, an important open question is whether there exist nearly-linear time algorithms
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32467;&#21512;&#26426;&#22120;&#20154;&#21644;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#20154;&#26426;&#20132;&#20114;&#30340;&#26041;&#24335;&#19982;60&#21517;&#21442;&#19982;&#32773;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#20351;&#29992;&#36830;&#32493;&#23398;&#20064;&#21487;&#20197;&#25552;&#39640;&#26426;&#22120;&#20154;&#30340;&#33021;&#21147;&#65292;&#21442;&#19982;&#32773;&#26356;&#20542;&#21521;&#20110;&#19982;&#20854;&#36827;&#34892;&#21453;&#22797;&#20132;&#20114;&#65292;&#24182;&#25552;&#20379;&#26356;&#22810;&#30340;&#21453;&#39304;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2305.16332</link><description>&lt;p&gt;
&#36890;&#36807;&#20154;&#26426;&#20132;&#20114;&#23454;&#29616;&#36830;&#32493;&#23398;&#20064;--&#20154;&#31867;&#22312;&#19982;&#26426;&#22120;&#20154;&#21453;&#22797;&#20132;&#20114;&#20013;&#23545;&#26426;&#22120;&#20154;&#36830;&#32493;&#23398;&#20064;&#30340;&#30475;&#27861;
&lt;/p&gt;
&lt;p&gt;
Continual Learning through Human-Robot Interaction -- Human Perceptions of a Continual Learning Robot in Repeated Interactions. (arXiv:2305.16332v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32467;&#21512;&#26426;&#22120;&#20154;&#21644;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#20154;&#26426;&#20132;&#20114;&#30340;&#26041;&#24335;&#19982;60&#21517;&#21442;&#19982;&#32773;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#20351;&#29992;&#36830;&#32493;&#23398;&#20064;&#21487;&#20197;&#25552;&#39640;&#26426;&#22120;&#20154;&#30340;&#33021;&#21147;&#65292;&#21442;&#19982;&#32773;&#26356;&#20542;&#21521;&#20110;&#19982;&#20854;&#36827;&#34892;&#21453;&#22797;&#20132;&#20114;&#65292;&#24182;&#25552;&#20379;&#26356;&#22810;&#30340;&#21453;&#39304;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#21160;&#24577;&#30340;&#23454;&#38469;&#29615;&#22659;&#20013;&#38271;&#26399;&#37096;&#32626;&#36741;&#21161;&#26426;&#22120;&#20154;&#65292;&#26426;&#22120;&#20154;&#24517;&#39035;&#32487;&#32493;&#23398;&#20064;&#21644;&#36866;&#24212;&#20854;&#29615;&#22659;&#12290;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#24320;&#21457;&#20102;&#21508;&#31181;&#36830;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#30340;&#35745;&#31639;&#27169;&#22411;&#65292;&#21487;&#20197;&#20351;&#26426;&#22120;&#20154;&#19981;&#26029;&#20174;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#24182;&#36991;&#20813;&#36951;&#24536;&#20808;&#21069;&#30340;&#30693;&#35782;&#12290;&#34429;&#28982;&#36825;&#20123;CL&#27169;&#22411;&#21487;&#20197;&#32531;&#35299;&#38745;&#24577;&#12289;&#31995;&#32479;&#22320;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#36951;&#24536;&#65292;&#20294;&#20154;&#20204;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#22312;&#22810;&#27425;&#20132;&#20114;&#20013;&#36830;&#32493;&#23398;&#20064;&#30340;&#26426;&#22120;&#20154;&#26159;&#22914;&#20309;&#34987;&#20154;&#31867;&#29992;&#25143;&#25152;&#24863;&#30693;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31995;&#32479;&#65292;&#23558;&#30446;&#26631;&#35782;&#21035;&#30340;CL&#27169;&#22411;&#19982;Fetch&#31227;&#21160;&#25805;&#32437;&#26426;&#22120;&#20154;&#36827;&#34892;&#25972;&#21512;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#21442;&#19982;&#32773;&#22312;&#22810;&#20010;&#20250;&#35805;&#20013;&#30452;&#25509;&#25945;&#25480;&#21644;&#27979;&#35797;&#26426;&#22120;&#20154;&#12290;&#25105;&#20204;&#24320;&#23637;&#20102;&#19968;&#39033;&#29616;&#22330;&#30740;&#31350;&#65292;60&#21517;&#21442;&#19982;&#32773;&#22312;300&#20010;&#20250;&#35805;&#20013;&#19982;&#25105;&#20204;&#30340;&#31995;&#32479;&#20114;&#21160;&#65288;&#27599;&#20010;&#21442;&#19982;&#32773;5&#27425;&#20250;&#35805;&#65289;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#20004;&#32452;&#23454;&#39564;&#30340;&#30740;&#31350;&#65292;&#24182;&#20351;&#29992;&#19977;&#31181;&#19981;&#21516;&#30340;CL&#27169;&#22411;&#65288;&#19977;&#20010;&#23454;&#39564;&#26465;&#20214;&#65289;&#26469;&#20102;&#35299;&#20154;&#31867;&#23545;&#36830;&#32493;&#23398;&#20064;&#26426;&#22120;&#20154;&#30340;&#30475;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
For long-term deployment in dynamic real-world environments, assistive robots must continue to learn and adapt to their environments. Researchers have developed various computational models for continual learning (CL) that can allow robots to continually learn from limited training data, and avoid forgetting previous knowledge. While these CL models can mitigate forgetting on static, systematically collected datasets, it is unclear how human users might perceive a robot that continually learns over multiple interactions with them. In this paper, we developed a system that integrates CL models for object recognition with a Fetch mobile manipulator robot and allows human participants to directly teach and test the robot over multiple sessions. We conducted an in-person study with 60 participants who interacted with our system in 300 sessions (5 sessions per participant). We conducted a between-participant study with three different CL models (3 experimental conditions) to understand huma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#23558;&#25910;&#25947;&#32467;&#35770;&#20174;&#21482;&#36866;&#29992;&#20110;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#32858;&#21512;&#20989;&#25968;&#25193;&#23637;&#21040;&#25152;&#26377;&#20256;&#32479;&#32858;&#21512;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#26102;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.11140</link><description>&lt;p&gt;
&#22522;&#20110;&#28040;&#24687;&#20256;&#36882;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22823;&#35268;&#27169;&#38543;&#26426;&#22270;&#19978;&#30340;&#36890;&#29992;&#32858;&#21512;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#23558;&#25910;&#25947;&#32467;&#35770;&#20174;&#21482;&#36866;&#29992;&#20110;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#32858;&#21512;&#20989;&#25968;&#25193;&#23637;&#21040;&#25152;&#26377;&#20256;&#32479;&#32858;&#21512;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#26102;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24403;&#33410;&#28857;&#25968;&#37327;&#36235;&#36817;&#20110;&#26080;&#38480;&#26102;&#65292;&#35813;&#32593;&#32476;&#27169;&#22411;&#33021;&#25910;&#25947;&#20110;&#20854;&#36830;&#32493;&#27169;&#22411;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#35813;&#25910;&#25947;&#24615;&#32467;&#26524;&#21482;&#36866;&#29992;&#20110;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#20540;&#24418;&#24335;&#30340;&#32593;&#32476;&#32467;&#26500;&#12290;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#25193;&#23637;&#21040;&#21253;&#21547;&#25152;&#26377;&#20256;&#32479;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#22823;&#31867;&#32858;&#21512;&#20989;&#25968;&#19978;&#65292;&#20363;&#22914;&#22522;&#20110;&#27880;&#24847;&#21147;&#21644;&#26368;&#22823;&#21367;&#31215;&#30340;&#32593;&#32476;&#12290;&#22312;&#19968;&#23450;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#39640;&#27010;&#29575;&#30340;&#38750;&#28176;&#36827;&#19978;&#38480;&#26469;&#37327;&#21270;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#22522;&#20110;McDiarmid&#19981;&#31561;&#24335;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#29305;&#21035;&#22788;&#29702;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#30340;&#24773;&#20917;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#38750;&#24120;&#19981;&#21516;&#30340;&#35777;&#26126;&#25216;&#24039;&#65292;&#24182;&#20135;&#29983;&#20102;&#23450;&#24615;&#19981;&#21516;&#30340;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the convergence of message passing graph neural networks on random graph models to their continuous counterpart as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of degree-normalized means. We extend such results to a very large class of aggregation functions, that encompasses all classically used message passing graph neural networks, such as attention-based mesage passing or max convolutional message passing on top of (degree-normalized) convolutional message passing. Under mild assumptions, we give non asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, we treat the case where the aggregation is a coordinate-wise maximum separately, at it necessitates a very different proof technique and yields a qualitatively different convergence rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#20449;&#24687;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#39044;&#35757;&#32451;&#22270;&#21367;&#31215;&#32593;&#32476;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#30340;&#22522;&#22240;&#34920;&#36798;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#20272;&#35745;&#22120;&#26469;&#39640;&#25928;&#20272;&#35745;&#36793;&#32536;&#24178;&#25200;&#25928;&#24212;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.00116</link><description>&lt;p&gt;
&#21033;&#29992;&#21464;&#20998;&#22240;&#26524;&#25512;&#26029;&#21644;&#31934;&#32454;&#20851;&#31995;&#20449;&#24687;&#39044;&#27979;&#32454;&#32990;&#21709;&#24212;
&lt;/p&gt;
&lt;p&gt;
Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information. (arXiv:2210.00116v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00116
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#20449;&#24687;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#39044;&#35757;&#32451;&#22270;&#21367;&#31215;&#32593;&#32476;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#30340;&#22522;&#22240;&#34920;&#36798;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#20272;&#35745;&#22120;&#26469;&#39640;&#25928;&#20272;&#35745;&#36793;&#32536;&#24178;&#25200;&#25928;&#24212;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#32454;&#32990;&#22312;&#24178;&#25200;&#19979;&#30340;&#21709;&#24212;&#21487;&#33021;&#20026;&#33647;&#29289;&#30740;&#21457;&#21644;&#20010;&#24615;&#21270;&#27835;&#30103;&#24102;&#26469;&#37325;&#35201;&#22909;&#22788;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#21464;&#20998;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#65288;&#21363;&#32454;&#32990;&#26410;&#30495;&#23454;&#25509;&#25910;&#30340;&#24178;&#25200;&#65289;&#30340;&#22522;&#22240;&#34920;&#36798;&#65292;&#21033;&#29992;&#20195;&#34920;&#29983;&#29289;&#23398;&#30693;&#35782;&#30340;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#65288;GRN&#65289;&#20449;&#24687;&#26469;&#36741;&#21161;&#20010;&#24615;&#21270;&#32454;&#32990;&#21709;&#24212;&#39044;&#27979;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#25968;&#25454;&#33258;&#36866;&#24212;GRN&#24320;&#21457;&#20102;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#29992;&#20110;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#39044;&#35757;&#32451;&#65292;&#22312;&#27169;&#22411;&#24615;&#33021;&#19978;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#22522;&#22240;&#20851;&#31995;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advanta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25351;&#25968;&#31383;&#21475;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#22312;&#32447;&#21464;&#21270;&#26816;&#27979;&#31639;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2205.12706</link><description>&lt;p&gt;
&#22522;&#20110;&#25351;&#25968;&#31383;&#21475;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#22312;&#32447;&#21464;&#21270;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Maximum Mean Discrepancy on Exponential Windows for Online Change Detection. (arXiv:2205.12706v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12706
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25351;&#25968;&#31383;&#21475;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#22312;&#32447;&#21464;&#21270;&#26816;&#27979;&#31639;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a Maximum Mean Discrepancy on Exponential Windows (MMDEW) algorithm for online change detection, which efficiently detects changes in data streams.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#26512;&#25968;&#25454;&#27969;&#26102;&#65292;&#26816;&#27979;&#21464;&#21270;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#65292;&#20855;&#26377;&#35768;&#22810;&#24212;&#29992;&#65292;&#20363;&#22914;&#39044;&#27979;&#24615;&#32500;&#25252;&#12289;&#27450;&#35784;&#26816;&#27979;&#25110;&#21307;&#23398;&#12290;&#19968;&#31181;&#26816;&#27979;&#21464;&#21270;&#30340;&#21407;&#21017;&#26041;&#27861;&#26159;&#36890;&#36807;&#20551;&#35774;&#26816;&#39564;&#23558;&#27969;&#20013;&#35266;&#27979;&#20540;&#30340;&#20998;&#24067;&#30456;&#20114;&#27604;&#36739;&#12290;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65307;&#20063;&#31216;&#20026;&#33021;&#37327;&#36317;&#31163;&#65289;&#26159;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#19978;&#20247;&#25152;&#21608;&#30693;&#30340;&#65288;&#21322;&#65289;&#24230;&#37327;&#12290;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;MMD&#22312;&#26680;&#23500;&#38598;&#22495;&#19978;&#20135;&#29983;&#20102;&#24378;&#22823;&#30340;&#38750;&#21442;&#25968;&#20004;&#26679;&#26412;&#26816;&#39564;&#65292;&#36825;&#20351;&#24471;&#23427;&#22312;&#21464;&#21270;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;&#21464;&#24471;&#21487;&#21462;&#12290;&#28982;&#32780;&#65292;&#32463;&#20856;&#30340;MMD&#20272;&#35745;&#22120;&#20855;&#26377;&#20108;&#27425;&#22797;&#26434;&#24230;&#65292;&#36825;&#31105;&#27490;&#20102;&#23427;&#20204;&#22312;&#22312;&#32447;&#21464;&#21270;&#26816;&#27979;&#35774;&#32622;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#21464;&#21270;&#26816;&#27979;&#31639;&#27861;&#65292;&#22522;&#20110;&#25351;&#25968;&#31383;&#21475;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMDEW&#65289;&#65292;&#23427;&#21033;&#29992;MMD&#20004;&#26679;&#26412;&#26816;&#39564;&#65292;&#22312;&#20219;&#20309;&#26680;&#23500;&#38598;&#22495;&#19978;&#20419;&#36827;&#20854;&#26377;&#25928;&#30340;&#22312;&#32447;&#35745;&#31639;&#65292;&#24182;&#33021;&#22815;&#26816;&#27979;&#21040;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting changes is of fundamental importance when analyzing data streams and has many applications, e.g., predictive maintenance, fraud detection, or medicine. A principled approach to detect changes is to compare the distributions of observations within the stream to each other via hypothesis testing. Maximum mean discrepancy (MMD; also called energy distance) is a well-known (semi-)metric on the space of probability distributions. MMD gives rise to powerful non-parametric two-sample tests on kernel-enriched domains under mild conditions, which makes its deployment for change detection desirable. However, the classic MMD estimators suffer quadratic complexity, which prohibits their application in the online change detection setting. We propose a general-purpose change detection algorithm, Maximum Mean Discrepancy on Exponential Windows (MMDEW), which leverages the MMD two-sample test, facilitates its efficient online computation on any kernel-enriched domain, and is able to detect a
&lt;/p&gt;</description></item></channel></rss>