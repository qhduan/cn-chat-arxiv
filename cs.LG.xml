<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>FOCIL&#36890;&#36807;&#35757;&#32451;&#38543;&#26426;&#20462;&#21098;&#31232;&#30095;&#23376;&#32593;&#32476;&#23454;&#29616;&#22312;&#32447;&#25345;&#32493;&#31867;&#36882;&#22686;&#23398;&#20064;&#65292;&#22312;&#36991;&#20813;&#23384;&#20648;&#37325;&#25918;&#25968;&#25454;&#30340;&#21516;&#26102;&#26377;&#25928;&#38450;&#27490;&#36951;&#24536;&#12290;</title><link>https://arxiv.org/abs/2403.14684</link><description>&lt;p&gt;
FOCIL: &#36890;&#36807;&#35757;&#32451;&#38543;&#26426;&#20462;&#21098;&#31232;&#30095;&#19987;&#23478;&#36827;&#34892;&#22312;&#32447;&#31867;&#36882;&#22686;&#23398;&#20064;&#30340;&#24494;&#35843;&#21644;&#20923;&#32467;
&lt;/p&gt;
&lt;p&gt;
FOCIL: Finetune-and-Freeze for Online Class Incremental Learning by Training Randomly Pruned Sparse Experts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14684
&lt;/p&gt;
&lt;p&gt;
FOCIL&#36890;&#36807;&#35757;&#32451;&#38543;&#26426;&#20462;&#21098;&#31232;&#30095;&#23376;&#32593;&#32476;&#23454;&#29616;&#22312;&#32447;&#25345;&#32493;&#31867;&#36882;&#22686;&#23398;&#20064;&#65292;&#22312;&#36991;&#20813;&#23384;&#20648;&#37325;&#25918;&#25968;&#25454;&#30340;&#21516;&#26102;&#26377;&#25928;&#38450;&#27490;&#36951;&#24536;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#25345;&#32493;&#23398;&#20064;&#20013;&#30340;&#31867;&#36882;&#22686;&#23398;&#20064;&#65288;CIL&#65289;&#26088;&#22312;&#20174;&#25968;&#25454;&#27969;&#20013;&#33719;&#21462;&#19968;&#31995;&#21015;&#26032;&#31867;&#30340;&#30693;&#35782;&#65292;&#20165;&#20351;&#29992;&#27599;&#20010;&#25968;&#25454;&#28857;&#36827;&#34892;&#19968;&#27425;&#35757;&#32451;&#12290;&#19982;&#31163;&#32447;&#27169;&#24335;&#30456;&#27604;&#65292;&#36825;&#26356;&#21152;&#29616;&#23454;&#65292;&#31163;&#32447;&#27169;&#24335;&#20551;&#23450;&#25152;&#26377;&#26032;&#31867;&#30340;&#25968;&#25454;&#24050;&#32463;&#20934;&#22791;&#22909;&#12290;&#24403;&#21069;&#30340;&#22312;&#32447;CIL&#26041;&#27861;&#23384;&#20648;&#20808;&#21069;&#25968;&#25454;&#30340;&#23376;&#38598;&#65292;&#36825;&#20250;&#22312;&#20869;&#23384;&#21644;&#35745;&#31639;&#26041;&#38754;&#36896;&#25104;&#27785;&#37325;&#30340;&#24320;&#38144;&#65292;&#36824;&#23384;&#22312;&#38544;&#31169;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FOCIL&#30340;&#26032;&#22411;&#22312;&#32447;CIL&#26041;&#27861;&#12290;&#23427;&#36890;&#36807;&#35757;&#32451;&#38543;&#26426;&#20462;&#21098;&#31232;&#30095;&#23376;&#32593;&#32476;&#19981;&#26029;&#24494;&#35843;&#20027;&#20307;&#31995;&#32467;&#26500;&#65292;&#28982;&#21518;&#20923;&#32467;&#35757;&#32451;&#36830;&#25509;&#20197;&#38450;&#27490;&#36951;&#24536;&#12290;FOCIL&#36824;&#33258;&#36866;&#24212;&#30830;&#23450;&#27599;&#20010;&#20219;&#21153;&#30340;&#31232;&#30095;&#24230;&#32423;&#21035;&#21644;&#23398;&#20064;&#36895;&#29575;&#65292;&#24182;&#30830;&#20445;&#65288;&#20960;&#20046;&#65289;&#38646;&#36951;&#24536;&#36328;&#25152;&#26377;&#20219;&#21153;&#65292;&#19988;&#19981;&#23384;&#20648;&#20219;&#20309;&#37325;&#25918;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14684v1 Announce Type: cross  Abstract: Class incremental learning (CIL) in an online continual learning setting strives to acquire knowledge on a series of novel classes from a data stream, using each data point only once for training. This is more realistic compared to offline modes, where it is assumed that all data from novel class(es) is readily available. Current online CIL approaches store a subset of the previous data which creates heavy overhead costs in terms of both memory and computation, as well as privacy issues. In this paper, we propose a new online CIL approach called FOCIL. It fine-tunes the main architecture continually by training a randomly pruned sparse subnetwork for each task. Then, it freezes the trained connections to prevent forgetting. FOCIL also determines the sparsity level and learning rate per task adaptively and ensures (almost) zero forgetting across all tasks without storing any replay data. Experimental results on 10-Task CIFAR100, 20-Task
&lt;/p&gt;</description></item><item><title>NuGraph2 &#26159;&#19968;&#31181;&#29992;&#20110;&#28082;&#27689;&#26102;&#38388;&#25237;&#24433;&#23460;&#25506;&#27979;&#22120;&#20013;&#27169;&#25311;&#20013;&#24494;&#23376;&#30456;&#20114;&#20316;&#29992;&#20302;&#32423;&#37325;&#24314;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#22810;&#22836;&#27880;&#24847;&#21147;&#20256;&#36882;&#26426;&#21046;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#32972;&#26223;&#36807;&#28388;&#21644;&#35821;&#20041;&#26631;&#35760;&#12290;</title><link>https://arxiv.org/abs/2403.11872</link><description>&lt;p&gt;
NuGraph2&#65306;&#29992;&#20110;&#20013;&#24494;&#23376;&#29289;&#29702;&#20107;&#20214;&#37325;&#24314;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
NuGraph2: A Graph Neural Network for Neutrino Physics Event Reconstruction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11872
&lt;/p&gt;
&lt;p&gt;
NuGraph2 &#26159;&#19968;&#31181;&#29992;&#20110;&#28082;&#27689;&#26102;&#38388;&#25237;&#24433;&#23460;&#25506;&#27979;&#22120;&#20013;&#27169;&#25311;&#20013;&#24494;&#23376;&#30456;&#20114;&#20316;&#29992;&#20302;&#32423;&#37325;&#24314;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#22810;&#22836;&#27880;&#24847;&#21147;&#20256;&#36882;&#26426;&#21046;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#32972;&#26223;&#36807;&#28388;&#21644;&#35821;&#20041;&#26631;&#35760;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11872v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#28082;&#27689;&#26102;&#38388;&#25237;&#24433;&#23460;&#65288;LArTPC&#65289;&#25506;&#27979;&#22120;&#25216;&#26415;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#39640;&#20998;&#36776;&#29575;&#31890;&#23376;&#30456;&#20114;&#20316;&#29992;&#20449;&#24687;&#65292;&#20805;&#20998;&#21033;&#29992;&#36825;&#20123;&#20449;&#24687;&#38656;&#35201;&#20808;&#36827;&#30340;&#33258;&#21160;&#37325;&#24314;&#25216;&#26415;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;NuGraph2&#65292;&#19968;&#31181;&#29992;&#20110;LArTPC&#25506;&#27979;&#22120;&#20013;&#27169;&#25311;&#20013;&#24494;&#23376;&#30456;&#20114;&#20316;&#29992;&#20302;&#32423;&#37325;&#24314;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#12290;MicroBooNE&#25506;&#27979;&#22120;&#20960;&#20309;&#24418;&#29366;&#20013;&#30340;&#27169;&#25311;&#20013;&#24494;&#23376;&#30456;&#20114;&#20316;&#29992;&#34987;&#25551;&#36848;&#20026;&#24322;&#36136;&#22270;&#65292;&#27599;&#20010;&#25506;&#27979;&#22120;&#24179;&#38754;&#19978;&#30340;&#33021;&#37327;&#27785;&#31215;&#24418;&#25104;&#24179;&#38754;&#23376;&#22270;&#19978;&#30340;&#33410;&#28857;&#12290;&#35813;&#32593;&#32476;&#21033;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#20256;&#36882;&#26426;&#21046;&#23545;&#36825;&#20123;&#22270;&#33410;&#28857;&#25191;&#34892;&#32972;&#26223;&#36807;&#28388;&#21644;&#35821;&#20041;&#26631;&#35760;&#65292;&#20197;98.0\%&#30340;&#25928;&#29575;&#35782;&#21035;&#19982;&#20027;&#35201;&#29289;&#29702;&#30456;&#20114;&#20316;&#29992;&#30456;&#20851;&#32852;&#30340;&#33410;&#28857;&#65292;&#24182;&#20197;94.9\%&#30340;&#25928;&#29575;&#26681;&#25454;&#31890;&#23376;&#31867;&#22411;&#23558;&#20854;&#26631;&#35760;&#12290;&#35813;&#32593;&#32476;&#30452;&#25509;&#22312;&#25506;&#27979;&#22120;&#21487;&#35266;&#23519;&#37327;&#19978;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11872v1 Announce Type: cross  Abstract: Liquid Argon Time Projection Chamber (LArTPC) detector technology offers a wealth of high-resolution information on particle interactions, and leveraging that information to its full potential requires sophisticated automated reconstruction techniques. This article describes NuGraph2, a Graph Neural Network (GNN) for low-level reconstruction of simulated neutrino interactions in a LArTPC detector. Simulated neutrino interactions in the MicroBooNE detector geometry are described as heterogeneous graphs, with energy depositions on each detector plane forming nodes on planar subgraphs. The network utilizes a multi-head attention message-passing mechanism to perform background filtering and semantic labelling on these graph nodes, identifying those associated with the primary physics interaction with 98.0\% efficiency and labelling them according to particle type with 94.9\% efficiency. The network operates directly on detector observables
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#26550;&#26500;&#20013;&#23454;&#29616;&#38544;&#31169;&#21644;&#40065;&#26834;&#24615;&#30340;&#25104;&#26412;&#65292;&#25351;&#20986;&#25972;&#21512;&#36825;&#20004;&#20010;&#30446;&#26631;&#20250;&#29306;&#29298;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2312.14712</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#40065;&#26834;&#24615;&#12289;&#25928;&#29575;&#25110;&#38544;&#31169;&#65306;&#21482;&#33021;&#36873;&#20004;&#26679;
&lt;/p&gt;
&lt;p&gt;
Robustness, Efficiency, or Privacy: Pick Two in Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14712
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#26550;&#26500;&#20013;&#23454;&#29616;&#38544;&#31169;&#21644;&#40065;&#26834;&#24615;&#30340;&#25104;&#26412;&#65292;&#25351;&#20986;&#25972;&#21512;&#36825;&#20004;&#20010;&#30446;&#26631;&#20250;&#29306;&#29298;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#24212;&#29992;&#30340;&#25104;&#21151;&#20381;&#36182;&#20110;&#24222;&#22823;&#30340;&#25968;&#25454;&#38598;&#21644;&#20998;&#24067;&#24335;&#26550;&#26500;&#65292;&#38543;&#30528;&#23427;&#20204;&#30340;&#22686;&#38271;&#65292;&#36825;&#20123;&#26550;&#26500;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#65292;&#25968;&#25454;&#36890;&#24120;&#21253;&#21547;&#25935;&#24863;&#20449;&#24687;&#65292;&#25968;&#25454;&#27745;&#26579;&#21644;&#30828;&#20214;&#25925;&#38556;&#31561;&#38382;&#39064;&#24456;&#24120;&#35265;&#12290;&#30830;&#20445;&#38544;&#31169;&#21644;&#40065;&#26834;&#24615;&#23545;&#20110;ML&#22312;&#20844;&#20849;&#29983;&#27963;&#20013;&#30340;&#24191;&#27867;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#24335;ML&#26550;&#26500;&#20013;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#25152;&#24102;&#26469;&#30340;&#25104;&#26412;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#20998;&#24067;&#24335;ML&#20013;&#38544;&#31169;&#21644;&#40065;&#26834;&#24615;&#30340;&#21547;&#20041;&#65292;&#24182;&#38416;&#26126;&#20102;&#22914;&#20309;&#21333;&#29420;&#39640;&#25928;&#23454;&#29616;&#23427;&#20204;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35748;&#20026;&#25972;&#21512;&#36825;&#20004;&#20010;&#30446;&#26631;&#20250;&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#26377;&#26174;&#33879;&#30340;&#25240;&#34935;&#12290;&#31616;&#32780;&#35328;&#20043;&#65292;&#20256;&#32479;&#30340;&#22122;&#22768;&#27880;&#20837;&#36890;&#36807;&#38544;&#34255;&#27602;&#23475;&#36755;&#20837;&#26469;&#25439;&#23475;&#20934;&#30830;&#24615;&#65292;&#32780;&#21152;&#23494;&#26041;&#27861;&#19982;&#38450;&#27602;&#38450;&#24481;&#30456;&#20914;&#31361;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#38750;&#32447;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14712v2 Announce Type: replace  Abstract: The success of machine learning (ML) applications relies on vast datasets and distributed architectures which, as they grow, present major challenges. In real-world scenarios, where data often contains sensitive information, issues like data poisoning and hardware failures are common. Ensuring privacy and robustness is vital for the broad adoption of ML in public life. This paper examines the costs associated with achieving these objectives in distributed ML architectures, from both theoretical and empirical perspectives. We overview the meanings of privacy and robustness in distributed ML, and clarify how they can be achieved efficiently in isolation. However, we contend that the integration of these two objectives entails a notable compromise in computational efficiency. In short, traditional noise injection hurts accuracy by concealing poisoned inputs, while cryptographic methods clash with poisoning defenses due to their non-line
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;(FL-IDS)&#65292;&#26088;&#22312;&#35299;&#20915;FANETs&#20013;&#38598;&#20013;&#24335;&#31995;&#32479;&#25152;&#36935;&#21040;&#30340;&#25361;&#25112;&#65292;&#38477;&#20302;&#20102;&#35745;&#31639;&#21644;&#23384;&#20648;&#25104;&#26412;&#65292;&#36866;&#21512;&#36164;&#28304;&#21463;&#38480;&#30340;&#26080;&#20154;&#26426;&#12290;</title><link>https://arxiv.org/abs/2312.04135</link><description>&lt;p&gt;
&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#29992;&#20110;&#22686;&#24378;&#26080;&#20154;&#26426;&#38544;&#31169;&#21644;&#23433;&#20840;&#30340;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Novel Federated Learning-Based IDS for Enhancing UAVs Privacy and Security
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.04135
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;(FL-IDS)&#65292;&#26088;&#22312;&#35299;&#20915;FANETs&#20013;&#38598;&#20013;&#24335;&#31995;&#32479;&#25152;&#36935;&#21040;&#30340;&#25361;&#25112;&#65292;&#38477;&#20302;&#20102;&#35745;&#31639;&#21644;&#23384;&#20648;&#25104;&#26412;&#65292;&#36866;&#21512;&#36164;&#28304;&#21463;&#38480;&#30340;&#26080;&#20154;&#26426;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#20154;&#26426;&#22312;&#39134;&#34892;&#33258;&#32452;&#32455;&#32593;&#32476;(FANETs)&#20013;&#36816;&#34892;&#26102;&#20250;&#36935;&#21040;&#23433;&#20840;&#25361;&#25112;&#65292;&#22240;&#20026;&#36825;&#20123;&#32593;&#32476;&#20855;&#26377;&#21160;&#24577;&#21644;&#20998;&#24067;&#24335;&#30340;&#29305;&#24615;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#38598;&#20013;&#24335;&#20837;&#20405;&#26816;&#27979;&#19978;&#65292;&#20551;&#35774;&#19968;&#20010;&#20013;&#22830;&#23454;&#20307;&#36127;&#36131;&#23384;&#20648;&#21644;&#20998;&#26512;&#26469;&#33258;&#25152;&#26377;&#35774;&#22791;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#38754;&#20020;&#35745;&#31639;&#21644;&#23384;&#20648;&#25104;&#26412;&#20197;&#21450;&#21333;&#28857;&#25925;&#38556;&#39118;&#38505;&#31561;&#25361;&#25112;&#65292;&#23041;&#32961;&#21040;&#25968;&#25454;&#38544;&#31169;&#21644;&#21487;&#29992;&#24615;&#12290;&#25968;&#25454;&#22312;&#20114;&#36830;&#35774;&#22791;&#20043;&#38388;&#24191;&#27867;&#20998;&#25955;&#30340;&#24773;&#20917;&#31361;&#26174;&#20102;&#21435;&#20013;&#24515;&#21270;&#26041;&#27861;&#30340;&#24517;&#35201;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;(FL-IDS)&#65292;&#35299;&#20915;&#20102;FANETs&#20013;&#38598;&#20013;&#24335;&#31995;&#32479;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;FL-IDS&#22312;&#21435;&#20013;&#24515;&#21270;&#26041;&#24335;&#19979;&#36816;&#34892;&#65292;&#38477;&#20302;&#20102;&#23458;&#25143;&#31471;&#21644;&#20013;&#22830;&#26381;&#21153;&#22120;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#25104;&#26412;&#65292;&#36825;&#23545;&#20110;&#36164;&#28304;&#21463;&#38480;&#30340;&#26080;&#20154;&#26426;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.04135v2 Announce Type: replace-cross  Abstract: Unmanned aerial vehicles (UAVs) operating within Flying Ad-hoc Networks (FANETs) encounter security challenges due to the dynamic and distributed nature of these networks. Previous studies predominantly focused on centralized intrusion detection, assuming a central entity responsible for storing and analyzing data from all devices.However, these approaches face challenges including computation and storage costs, along with a single point of failure risk, threatening data privacy and availability. The widespread dispersion of data across interconnected devices underscores the necessity for decentralized approaches. This paper introduces the Federated Learning-based Intrusion Detection System (FL-IDS), addressing challenges encountered by centralized systems in FANETs. FL-IDS reduces computation and storage costs for both clients and the central server, crucial for resource-constrained UAVs. Operating in a decentralized manner, F
&lt;/p&gt;</description></item><item><title>PuriDefense&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#38450;&#24481;&#26426;&#21046;&#65292;&#36890;&#36807;&#20351;&#29992;&#36731;&#37327;&#32423;&#20928;&#21270;&#27169;&#22411;&#36827;&#34892;&#38543;&#26426;&#36335;&#24452;&#20928;&#21270;&#65292;&#20943;&#32531;&#22522;&#20110;&#26597;&#35810;&#30340;&#25915;&#20987;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#26377;&#25928;&#38450;&#24481;&#40657;&#30418;&#22522;&#20110;&#26597;&#35810;&#30340;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2401.10586</link><description>&lt;p&gt;
PuriDefense&#65306;&#29992;&#20110;&#38450;&#24481;&#40657;&#30418;&#22522;&#20110;&#26597;&#35810;&#30340;&#25915;&#20987;&#30340;&#38543;&#26426;&#23616;&#37096;&#38544;&#24335;&#23545;&#25239;&#20928;&#21270;
&lt;/p&gt;
&lt;p&gt;
PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks. (arXiv:2401.10586v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10586
&lt;/p&gt;
&lt;p&gt;
PuriDefense&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#38450;&#24481;&#26426;&#21046;&#65292;&#36890;&#36807;&#20351;&#29992;&#36731;&#37327;&#32423;&#20928;&#21270;&#27169;&#22411;&#36827;&#34892;&#38543;&#26426;&#36335;&#24452;&#20928;&#21270;&#65292;&#20943;&#32531;&#22522;&#20110;&#26597;&#35810;&#30340;&#25915;&#20987;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#26377;&#25928;&#38450;&#24481;&#40657;&#30418;&#22522;&#20110;&#26597;&#35810;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40657;&#30418;&#22522;&#20110;&#26597;&#35810;&#30340;&#25915;&#20987;&#23545;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#26381;&#21153;&#31995;&#32479;&#26500;&#25104;&#37325;&#22823;&#23041;&#32961;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#29983;&#25104;&#23545;&#25239;&#26679;&#26412;&#32780;&#19981;&#38656;&#35201;&#35775;&#38382;&#30446;&#26631;&#27169;&#22411;&#30340;&#26550;&#26500;&#21644;&#21442;&#25968;&#12290;&#20256;&#32479;&#30340;&#38450;&#24481;&#26426;&#21046;&#65292;&#22914;&#23545;&#25239;&#35757;&#32451;&#12289;&#26799;&#24230;&#25513;&#30422;&#21644;&#36755;&#20837;&#36716;&#25442;&#65292;&#35201;&#20040;&#24102;&#26469;&#24040;&#22823;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#35201;&#20040;&#25439;&#23475;&#38750;&#23545;&#25239;&#36755;&#20837;&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#38450;&#24481;&#26426;&#21046;PuriDefense&#65292;&#22312;&#20302;&#25512;&#29702;&#25104;&#26412;&#30340;&#32423;&#21035;&#19978;&#20351;&#29992;&#36731;&#37327;&#32423;&#20928;&#21270;&#27169;&#22411;&#30340;&#38543;&#26426;&#36335;&#24452;&#20928;&#21270;&#12290;&#36825;&#20123;&#27169;&#22411;&#21033;&#29992;&#23616;&#37096;&#38544;&#24335;&#20989;&#25968;&#24182;&#37325;&#24314;&#33258;&#28982;&#22270;&#20687;&#27969;&#24418;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23558;&#38543;&#26426;&#24615;&#32435;&#20837;&#20928;&#21270;&#36807;&#31243;&#26469;&#20943;&#32531;&#22522;&#20110;&#26597;&#35810;&#30340;&#25915;&#20987;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#23545;CIFAR-10&#21644;ImageNet&#30340;&#22823;&#37327;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#20928;&#21270;&#22120;&#38450;&#24481;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Black-box query-based attacks constitute significant threats to Machine Learning as a Service (MLaaS) systems since they can generate adversarial examples without accessing the target model's architecture and parameters. Traditional defense mechanisms, such as adversarial training, gradient masking, and input transformations, either impose substantial computational costs or compromise the test accuracy of non-adversarial inputs. To address these challenges, we propose an efficient defense mechanism, PuriDefense, that employs random patch-wise purifications with an ensemble of lightweight purification models at a low level of inference cost. These models leverage the local implicit function and rebuild the natural image manifold. Our theoretical analysis suggests that this approach slows down the convergence of query-based attacks by incorporating randomness into purifications. Extensive experiments on CIFAR-10 and ImageNet validate the effectiveness of our proposed purifier-based defen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#23398;&#20064;&#20316;&#20026;&#35745;&#31639;&#21463;&#38480;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#20027;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#21644;&#19968;&#22871;&#24037;&#20855;&#26469;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#38271;&#26399;&#20197;&#26469;&#30340;&#25361;&#25112;&#24182;&#20419;&#36827;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.04345</link><description>&lt;p&gt;
&#36830;&#32493;&#23398;&#20064;&#20316;&#20026;&#35745;&#31639;&#21463;&#38480;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Continual Learning as Computationally Constrained Reinforcement Learning. (arXiv:2307.04345v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#23398;&#20064;&#20316;&#20026;&#35745;&#31639;&#21463;&#38480;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#20027;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#21644;&#19968;&#22871;&#24037;&#20855;&#26469;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#38271;&#26399;&#20197;&#26469;&#30340;&#25361;&#25112;&#24182;&#20419;&#36827;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#33021;&#22815;&#22312;&#28459;&#38271;&#30340;&#29983;&#21629;&#21608;&#26399;&#20869;&#39640;&#25928;&#31215;&#32047;&#30693;&#35782;&#24182;&#21457;&#23637;&#36234;&#26469;&#36234;&#22797;&#26434;&#25216;&#33021;&#30340;&#26234;&#33021;&#20307;&#21487;&#20197;&#25512;&#21160;&#20154;&#24037;&#26234;&#33021;&#33021;&#21147;&#30340;&#21069;&#27839;&#12290;&#36830;&#32493;&#23398;&#20064;&#36825;&#19968;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#26159;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#25361;&#25112;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#20851;&#20110;&#36830;&#32493;&#23398;&#20064;&#30340;&#27010;&#24565;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#21644;&#19968;&#22871;&#24037;&#20855;&#65292;&#20197;&#20419;&#36827;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
An agent that efficiently accumulates knowledge to develop increasingly sophisticated skills over a long lifetime could advance the frontier of artificial intelligence capabilities. The design of such agents, which remains a long-standing challenge of artificial intelligence, is addressed by the subject of continual learning. This monograph clarifies and formalizes concepts of continual learning, introducing a framework and set of tools to stimulate further research.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20855;&#26377;&#32534;&#30721;&#25968;&#25454;&#32467;&#26500;&#30340;&#21464;&#20998;&#37327;&#23376;&#22238;&#24402;&#31639;&#27861;&#65292;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#27169;&#22411;&#35299;&#37322;&#24615;&#65292;&#24182;&#33021;&#26377;&#25928;&#22320;&#22788;&#29702;&#20114;&#36830;&#24230;&#36739;&#39640;&#30340;&#37327;&#23376;&#27604;&#29305;&#12290;&#31639;&#27861;&#36890;&#36807;&#21387;&#32553;&#32534;&#30721;&#21644;&#25968;&#23383;-&#27169;&#25311;&#38376;&#25805;&#20316;&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#22312;&#22122;&#22768;&#20013;&#23610;&#24230;&#37327;&#23376;&#35745;&#31639;&#26426;&#19978;&#30340;&#36816;&#34892;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.03334</link><description>&lt;p&gt;
&#20855;&#26377;&#32534;&#30721;&#25968;&#25454;&#32467;&#26500;&#30340;&#21464;&#20998;&#37327;&#23376;&#22238;&#24402;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Variational quantum regression algorithm with encoded data structure. (arXiv:2307.03334v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03334
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20855;&#26377;&#32534;&#30721;&#25968;&#25454;&#32467;&#26500;&#30340;&#21464;&#20998;&#37327;&#23376;&#22238;&#24402;&#31639;&#27861;&#65292;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#27169;&#22411;&#35299;&#37322;&#24615;&#65292;&#24182;&#33021;&#26377;&#25928;&#22320;&#22788;&#29702;&#20114;&#36830;&#24230;&#36739;&#39640;&#30340;&#37327;&#23376;&#27604;&#29305;&#12290;&#31639;&#27861;&#36890;&#36807;&#21387;&#32553;&#32534;&#30721;&#21644;&#25968;&#23383;-&#27169;&#25311;&#38376;&#25805;&#20316;&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#22312;&#22122;&#22768;&#20013;&#23610;&#24230;&#37327;&#23376;&#35745;&#31639;&#26426;&#19978;&#30340;&#36816;&#34892;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#37327;&#23376;&#31639;&#27861;(VQAs)&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#65292;&#22914;&#32452;&#21512;&#20248;&#21270;&#12289;&#37327;&#23376;&#21270;&#23398;&#27169;&#25311;&#12289;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#21644;&#22122;&#22768;&#37327;&#23376;&#35745;&#31639;&#26426;&#19978;&#30340;&#37327;&#23376;&#38169;&#35823;&#32416;&#27491;&#12290;&#23545;&#20110;&#21464;&#20998;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65292;&#23578;&#26410;&#24320;&#21457;&#20986;&#23558;&#27169;&#22411;&#35299;&#37322;&#24615;&#20869;&#23884;&#21040;&#31639;&#27861;&#20013;&#30340;&#21464;&#20998;&#31639;&#27861;&#12290;&#26412;&#25991;&#26500;&#24314;&#20102;&#19968;&#20010;&#37327;&#23376;&#22238;&#24402;&#31639;&#27861;&#65292;&#24182;&#30830;&#23450;&#20102;&#21464;&#20998;&#21442;&#25968;&#19982;&#23398;&#20064;&#22238;&#24402;&#31995;&#25968;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#65292;&#21516;&#26102;&#37319;&#29992;&#20102;&#23558;&#25968;&#25454;&#30452;&#25509;&#32534;&#30721;&#20026;&#21453;&#26144;&#32463;&#20856;&#25968;&#25454;&#34920;&#32467;&#26500;&#30340;&#37327;&#23376;&#24133;&#24230;&#30340;&#30005;&#36335;&#12290;&#35813;&#31639;&#27861;&#29305;&#21035;&#36866;&#29992;&#20110;&#20114;&#36830;&#24230;&#36739;&#39640;&#30340;&#37327;&#23376;&#27604;&#29305;&#12290;&#36890;&#36807;&#21387;&#32553;&#32534;&#30721;&#21644;&#25968;&#23383;-&#27169;&#25311;&#38376;&#25805;&#20316;&#65292;&#36816;&#34892;&#26102;&#38388;&#22797;&#26434;&#24230;&#22312;&#25968;&#25454;&#36755;&#20837;&#37327;&#32534;&#30721;&#30340;&#24773;&#20917;&#19979;&#23545;&#25968;&#32423;&#26356;&#26377;&#20248;&#21183;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#22122;&#22768;&#20013;&#23610;&#24230;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational quantum algorithms (VQAs) prevail to solve practical problems such as combinatorial optimization, quantum chemistry simulation, quantum machine learning, and quantum error correction on noisy quantum computers. For variational quantum machine learning, a variational algorithm with model interpretability built into the algorithm is yet to be exploited. In this paper, we construct a quantum regression algorithm and identify the direct relation of variational parameters to learned regression coefficients, while employing a circuit that directly encodes the data in quantum amplitudes reflecting the structure of the classical data table. The algorithm is particularly suitable for well-connected qubits. With compressed encoding and digital-analog gate operation, the run time complexity is logarithmically more advantageous than that for digital 2-local gate native hardware with the number of data entries encoded, a decent improvement in noisy intermediate-scale quantum computers a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#26080;&#38656;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#23454;&#29616;&#26368;&#20248;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#26469;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.11017</link><description>&lt;p&gt;
&#26080;&#31232;&#30095;&#24615;&#30340;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Contextual Bandit Problem without Sparsity. (arXiv:2306.11017v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11017
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#26080;&#38656;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#23454;&#29616;&#26368;&#20248;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#26469;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#39640;&#32500;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#29305;&#24449;&#25968; $p$ &#22823;&#20110;&#39044;&#31639; $T$ &#25110;&#29978;&#33267;&#26080;&#38480;&#21046;&#12290;&#19982;&#27492;&#39046;&#22495;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#19981;&#23545;&#22238;&#24402;&#31995;&#25968;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20381;&#38752;&#26368;&#36817;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#30740;&#31350;&#25104;&#26524;&#65292;&#20174;&#32780;&#33021;&#22815;&#22312;&#25968;&#25454;&#20998;&#24067;&#20855;&#26377;&#36739;&#23567;&#26377;&#25928;&#31209;&#26102;&#20998;&#26512;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25506;&#32034;-&#24320;&#21457; (EtC) &#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#26816;&#39564;&#20102;&#23427;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#20197; $T$ &#20026;&#21464;&#37327;&#65292;&#23548;&#20986;&#20102;ETC&#31639;&#27861;&#30340;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#34920;&#26126;&#36825;&#20010;&#36895;&#29575;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#26469;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457; (AEtC)&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#33258;&#36866;&#24212;&#22320;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#27169;&#25311;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this research, we investigate the high-dimensional linear contextual bandit problem where the number of features $p$ is greater than the budget $T$, or it may even be infinite. Differing from the majority of previous works in this field, we do not impose sparsity on the regression coefficients. Instead, we rely on recent findings on overparameterized models, which enables us to analyze the performance the minimum-norm interpolating estimator when data distributions have small effective ranks. We propose an explore-then-commit (EtC) algorithm to address this problem and examine its performance. Through our analysis, we derive the optimal rate of the ETC algorithm in terms of $T$ and show that this rate can be achieved by balancing exploration and exploitation. Moreover, we introduce an adaptive explore-then-commit (AEtC) algorithm that adaptively finds the optimal balance. We assess the performance of the proposed algorithms through a series of simulations.
&lt;/p&gt;</description></item><item><title>StyleNAT&#26159;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;transformer&#30340;&#22270;&#20687;&#29983;&#25104;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#37051;&#22495;&#27880;&#24847;&#21147;&#65288;NA&#65289;&#26469;&#25429;&#25417;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#65292;&#33021;&#22815;&#39640;&#25928;&#28789;&#27963;&#22320;&#36866;&#24212;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#22312;FFHQ-256&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.05770</link><description>&lt;p&gt;
StyleNAT&#65306;&#32473;&#27599;&#20010;&#22836;&#37096;&#19968;&#20010;&#26032;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
StyleNAT: Giving Each Head a New Perspective. (arXiv:2211.05770v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05770
&lt;/p&gt;
&lt;p&gt;
StyleNAT&#26159;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;transformer&#30340;&#22270;&#20687;&#29983;&#25104;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#37051;&#22495;&#27880;&#24847;&#21147;&#65288;NA&#65289;&#26469;&#25429;&#25417;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#65292;&#33021;&#22815;&#39640;&#25928;&#28789;&#27963;&#22320;&#36866;&#24212;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#22312;FFHQ-256&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#20687;&#29983;&#25104;&#19968;&#30452;&#26159;&#19968;&#20010;&#26082;&#26399;&#26395;&#21448;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#25191;&#34892;&#29983;&#25104;&#20219;&#21153;&#21516;&#26679;&#22256;&#38590;&#12290;&#36890;&#24120;&#65292;&#30740;&#31350;&#20154;&#21592;&#35797;&#22270;&#21019;&#24314;&#19968;&#20010;&#8220;&#19968;&#20992;&#20999;&#8221;&#30340;&#29983;&#25104;&#22120;&#65292;&#22312;&#21442;&#25968;&#31354;&#38388;&#20013;&#65292;&#21363;&#20351;&#26159;&#25130;&#28982;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#65292;&#20063;&#26377;&#24456;&#23569;&#30340;&#24046;&#24322;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;transformer&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;StyleNAT&#65292;&#26088;&#22312;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#29983;&#25104;&#65292;&#24182;&#20855;&#26377;&#21331;&#36234;&#30340;&#25928;&#29575;&#21644;&#28789;&#27963;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#26680;&#24515;&#26159;&#19968;&#20010;&#31934;&#24515;&#35774;&#35745;&#30340;&#26694;&#26550;&#65292;&#23427;&#23558;&#27880;&#24847;&#21147;&#22836;&#37096;&#21010;&#20998;&#20026;&#25429;&#25417;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#30340;&#26041;&#24335;&#65292;&#36825;&#26159;&#36890;&#36807;&#20351;&#29992;&#37051;&#22495;&#27880;&#24847;&#21147;&#65288;NA&#65289;&#23454;&#29616;&#30340;&#12290;&#30001;&#20110;&#19981;&#21516;&#30340;&#22836;&#37096;&#33021;&#22815;&#20851;&#27880;&#19981;&#21516;&#30340;&#24863;&#21463;&#37326;&#65292;&#27169;&#22411;&#33021;&#22815;&#26356;&#22909;&#22320;&#32467;&#21512;&#36825;&#20123;&#20449;&#24687;&#65292;&#24182;&#20197;&#39640;&#24230;&#28789;&#27963;&#30340;&#26041;&#24335;&#36866;&#24212;&#25163;&#22836;&#30340;&#25968;&#25454;&#12290;StyleNAT&#22312;FFHQ-256&#19978;&#33719;&#24471;&#20102;&#26032;&#30340;SOTA FID&#24471;&#20998;2.046 &#65292;&#20987;&#36133;&#20102;&#20197;&#21367;&#31215;&#27169;&#22411;&#65288;&#22914;StyleGAN-XL&#65289;&#21644;transformer&#27169;&#22411;&#65288;&#22914;HIT&#65289;&#20026;&#22522;&#30784;&#30340;&#20808;&#21069;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Image generation has been a long sought-after but challenging task, and performing the generation task in an efficient manner is similarly difficult. Often researchers attempt to create a "one size fits all" generator, where there are few differences in the parameter space for drastically different datasets. Herein, we present a new transformer-based framework, dubbed StyleNAT, targeting high-quality image generation with superior efficiency and flexibility. At the core of our model, is a carefully designed framework that partitions attention heads to capture local and global information, which is achieved through using Neighborhood Attention (NA). With different heads able to pay attention to varying receptive fields, the model is able to better combine this information, and adapt, in a highly flexible manner, to the data at hand. StyleNAT attains a new SOTA FID score on FFHQ-256 with 2.046, beating prior arts with convolutional models such as StyleGAN-XL and transformers such as HIT 
&lt;/p&gt;</description></item></channel></rss>