<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#25239;&#36951;&#24536;&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#65288;EATA&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#20027;&#21160;&#26679;&#26412;&#36873;&#25321;&#26631;&#20934;&#21644;&#24341;&#20837;Fisher&#27491;&#21017;&#21270;&#32422;&#26463;&#37325;&#35201;&#27169;&#22411;&#21442;&#25968;&#65292;&#23454;&#29616;&#20102;&#19981;&#20250;&#24536;&#35760;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#27979;&#35797;&#26102;&#38388;&#27169;&#22411;&#36866;&#24212;&#12290;</title><link>https://arxiv.org/abs/2403.11491</link><description>&lt;p&gt;
&#19981;&#20250;&#24536;&#21364;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#27979;&#35797;&#26102;&#38388;&#27169;&#22411;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Uncertainty-Calibrated Test-Time Model Adaptation without Forgetting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11491
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#25239;&#36951;&#24536;&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#65288;EATA&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#20027;&#21160;&#26679;&#26412;&#36873;&#25321;&#26631;&#20934;&#21644;&#24341;&#20837;Fisher&#27491;&#21017;&#21270;&#32422;&#26463;&#37325;&#35201;&#27169;&#22411;&#21442;&#25968;&#65292;&#23454;&#29616;&#20102;&#19981;&#20250;&#24536;&#35760;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#27979;&#35797;&#26102;&#38388;&#27169;&#22411;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#65288;TTA&#65289;&#26088;&#22312;&#36890;&#36807;&#26681;&#25454;&#20219;&#20309;&#27979;&#35797;&#26679;&#26412;&#35843;&#25972;&#32473;&#23450;&#27169;&#22411;&#65292;&#20197;&#24212;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#28508;&#22312;&#20998;&#24067;&#20559;&#31227;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;TTA&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#65292;&#20294;&#25105;&#20204;&#20173;&#28982;&#38754;&#20020;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#65306;1&#65289;&#20808;&#21069;&#30340;&#26041;&#27861;&#23545;&#27599;&#20010;&#27979;&#35797;&#26679;&#26412;&#25191;&#34892;&#21453;&#21521;&#20256;&#25773;&#65292;&#23548;&#33268;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#26080;&#27861;&#25215;&#21463;&#30340;&#20248;&#21270;&#25104;&#26412;&#65307;2&#65289;&#34429;&#28982;&#29616;&#26377;&#30340;TTA&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#22312;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#27979;&#35797;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#22312;TTA&#21518;&#22312;&#20998;&#24067;&#25968;&#25454;&#19978;&#36973;&#21463;&#20005;&#37325;&#24615;&#33021;&#19979;&#38477;&#65288;&#21363;&#25152;&#35859;&#30340;&#36951;&#24536;&#65289;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#25239;&#36951;&#24536;&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#65288;EATA&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#24320;&#21457;&#20102;&#19968;&#20010;&#20027;&#21160;&#26679;&#26412;&#36873;&#25321;&#26631;&#20934;&#65292;&#20197;&#35782;&#21035;&#21487;&#38752;&#19988;&#38750;&#20887;&#20313;&#30340;&#26679;&#26412;&#36827;&#34892;&#22312;&#27979;&#35797;&#26102;&#38388;&#30340;&#29109;&#26368;&#23567;&#21270;&#12290;&#20026;&#20102;&#32531;&#35299;&#36951;&#24536;&#65292;EATA&#24341;&#20837;&#20102;&#20174;&#27979;&#35797;&#26679;&#26412;&#20013;&#20272;&#35745;&#30340;Fisher&#27491;&#21017;&#21270;&#39033;&#65292;&#20197;&#32422;&#26463;&#37325;&#35201;&#30340;&#27169;&#22411;&#21442;&#25968;&#20813;&#20110;&#24613;&#21095;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11491v1 Announce Type: new  Abstract: Test-time adaptation (TTA) seeks to tackle potential distribution shifts between training and test data by adapting a given model w.r.t. any test sample. Although recent TTA has shown promising performance, we still face two key challenges: 1) prior methods perform backpropagation for each test sample, resulting in unbearable optimization costs to many applications; 2) while existing TTA can significantly improve the test performance on out-of-distribution data, they often suffer from severe performance degradation on in-distribution data after TTA (known as forgetting). To this end, we have proposed an Efficient Anti-Forgetting Test-Time Adaptation (EATA) method which develops an active sample selection criterion to identify reliable and non-redundant samples for test-time entropy minimization. To alleviate forgetting, EATA introduces a Fisher regularizer estimated from test samples to constrain important model parameters from drastic c
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#35268;&#21017;&#38388;&#38548;&#25968;&#25454;&#19978;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#28857;&#38388;&#36317;&#25351;&#25968;&#32423;&#23567;&#30340;&#24773;&#20917;&#19979;&#38656;&#35201;$\Omega(N)$&#20010;&#21442;&#25968;&#65292;&#21516;&#26102;&#25351;&#20986;&#29616;&#26377;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26080;&#27861;&#24212;&#29992;&#20110;&#36825;&#31181;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2302.00834</link><description>&lt;p&gt;
&#29992;&#20110;&#19981;&#35268;&#21017;&#38388;&#38548;&#25968;&#25454;&#30340;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#25554;&#20540;&#30340;&#23574;&#38160;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Sharp Lower Bounds on Interpolation by Deep ReLU Neural Networks at Irregularly Spaced Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.00834
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#35268;&#21017;&#38388;&#38548;&#25968;&#25454;&#19978;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#28857;&#38388;&#36317;&#25351;&#25968;&#32423;&#23567;&#30340;&#24773;&#20917;&#19979;&#38656;&#35201;$\Omega(N)$&#20010;&#21442;&#25968;&#65292;&#21516;&#26102;&#25351;&#20986;&#29616;&#26377;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26080;&#27861;&#24212;&#29992;&#20110;&#36825;&#31181;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#33021;&#21147;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#28145;&#24230;ReLU&#32593;&#32476;&#22914;&#20309;&#22312;&#21333;&#20301;&#29699;&#20013;&#30340;$N$&#20010;&#25968;&#25454;&#28857;&#19978;&#36827;&#34892;&#20540;&#30340;&#25554;&#20540;&#65292;&#36825;&#20123;&#28857;&#20043;&#38388;&#30456;&#36317;$\delta$&#12290;&#25105;&#20204;&#34920;&#26126;&#22312;$\delta$&#22312;$N$&#25351;&#25968;&#32423;&#23567;&#30340;&#21306;&#22495;&#20013;&#38656;&#35201;$\Omega(N)$&#20010;&#21442;&#25968;&#65292;&#36825;&#32473;&#20986;&#20102;&#35813;&#21306;&#22495;&#30340;&#23574;&#38160;&#32467;&#26524;&#65292;&#22240;&#20026;$O(N)$&#20010;&#21442;&#25968;&#24635;&#26159;&#36275;&#22815;&#30340;&#12290; &#36825;&#20063;&#34920;&#26126;&#29992;&#20110;&#35777;&#26126;VC&#32500;&#24230;&#19979;&#30028;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26080;&#27861;&#24212;&#29992;&#20110;&#19981;&#35268;&#21017;&#38388;&#38548;&#30340;&#25968;&#25454;&#28857;&#12290;&#26368;&#21518;&#65292;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#23884;&#20837;&#31471;&#28857;&#22788;&#20026;Sobolev&#31354;&#38388;&#23454;&#29616;&#30340;&#36817;&#20284;&#36895;&#29575;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.00834v2 Announce Type: replace  Abstract: We study the interpolation power of deep ReLU neural networks. Specifically, we consider the question of how efficiently, in terms of the number of parameters, deep ReLU networks can interpolate values at $N$ datapoints in the unit ball which are separated by a distance $\delta$. We show that $\Omega(N)$ parameters are required in the regime where $\delta$ is exponentially small in $N$, which gives the sharp result in this regime since $O(N)$ parameters are always sufficient. This also shows that the bit-extraction technique used to prove lower bounds on the VC dimension cannot be applied to irregularly spaced datapoints. Finally, as an application we give a lower bound on the approximation rates that deep ReLU neural networks can achieve for Sobolev spaces at the embedding endpoint.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#35299;&#20915;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.17772</link><description>&lt;p&gt;
&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;
&lt;/p&gt;
&lt;p&gt;
Learning Optimal Classification Trees Robust to Distribution Shifts. (arXiv:2310.17772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#35299;&#20915;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;/&#37096;&#32626;&#25968;&#25454;&#20043;&#38388;&#30340;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#26641;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#32463;&#24120;&#22312;&#39640;&#39118;&#38505;&#29615;&#22659;&#20013;&#20986;&#29616;&#65292;&#20363;&#22914;&#20844;&#20849;&#21355;&#29983;&#21644;&#31038;&#20250;&#24037;&#20316;&#65292;&#20854;&#20013;&#25968;&#25454;&#36890;&#24120;&#26159;&#36890;&#36807;&#33258;&#25105;&#25253;&#21578;&#30340;&#35843;&#26597;&#25910;&#38598;&#30340;&#65292;&#36825;&#20123;&#35843;&#26597;&#23545;&#38382;&#39064;&#30340;&#34920;&#36848;&#26041;&#24335;&#12289;&#35843;&#26597;&#36827;&#34892;&#30340;&#26102;&#38388;&#21644;&#22320;&#28857;&#12289;&#20197;&#21450;&#21463;&#35775;&#32773;&#19982;&#35843;&#26597;&#21592;&#20998;&#20139;&#20449;&#24687;&#30340;&#33298;&#36866;&#31243;&#24230;&#38750;&#24120;&#25935;&#24863;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#30340;&#23398;&#20064;&#26368;&#20248;&#40065;&#26834;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#23398;&#20064;&#26368;&#20248;&#40065;&#26834;&#26641;&#30340;&#38382;&#39064;&#21487;&#20197;&#31561;&#20215;&#22320;&#34920;&#36798;&#20026;&#19968;&#20010;&#20855;&#26377;&#39640;&#24230;&#38750;&#32447;&#24615;&#21644;&#19981;&#36830;&#32493;&#30446;&#26631;&#30340;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31561;&#20215;&#22320;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#20004;&#38454;&#27573;&#32447;&#24615;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#20026;&#27492;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#23450;&#21046;&#35299;&#20915;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning classification trees that are robust to distribution shifts between training and testing/deployment data. This problem arises frequently in high stakes settings such as public health and social work where data is often collected using self-reported surveys which are highly sensitive to e.g., the framing of the questions, the time when and place where the survey is conducted, and the level of comfort the interviewee has in sharing information with the interviewer. We propose a method for learning optimal robust classification trees based on mixed-integer robust optimization technology. In particular, we demonstrate that the problem of learning an optimal robust tree can be cast as a single-stage mixed-integer robust optimization problem with a highly nonlinear and discontinuous objective. We reformulate this problem equivalently as a two-stage linear robust optimization problem for which we devise a tailored solution procedure based on constraint gene
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#20851;&#20110;&#22810;&#21306;&#22495;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#30740;&#31350;&#65292;&#24182;&#22312;&#20840;&#23616;&#24037;&#20316;&#31354;&#38388;&#27169;&#22359;&#21270;&#32467;&#26500;&#19978;&#35777;&#26126;&#20102;&#26494;&#25955;&#31283;&#23450;&#24615;&#26465;&#20214;&#12290;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#20840;&#23616;&#24037;&#20316;&#31354;&#38388;&#31232;&#30095;&#32452;&#21512;&#32593;&#32476;&#22312;&#27979;&#35797;&#34920;&#29616;&#21644;&#38887;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#24378;&#35843;&#20102;&#31283;&#23450;&#24615;&#23545;&#20110;&#23454;&#29616;&#27169;&#22359;&#21270;RNN&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.01571</link><description>&lt;p&gt;
&#20840;&#23616;&#24037;&#20316;&#31354;&#38388;&#22522;&#20803;&#30340;&#25910;&#32553;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Contraction Properties of the Global Workspace Primitive. (arXiv:2310.01571v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#20851;&#20110;&#22810;&#21306;&#22495;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#30740;&#31350;&#65292;&#24182;&#22312;&#20840;&#23616;&#24037;&#20316;&#31354;&#38388;&#27169;&#22359;&#21270;&#32467;&#26500;&#19978;&#35777;&#26126;&#20102;&#26494;&#25955;&#31283;&#23450;&#24615;&#26465;&#20214;&#12290;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#20840;&#23616;&#24037;&#20316;&#31354;&#38388;&#31232;&#30095;&#32452;&#21512;&#32593;&#32476;&#22312;&#27979;&#35797;&#34920;&#29616;&#21644;&#38887;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#24378;&#35843;&#20102;&#31283;&#23450;&#24615;&#23545;&#20110;&#23454;&#29616;&#27169;&#22359;&#21270;RNN&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25512;&#21160;&#20851;&#20110;&#22810;&#21306;&#22495;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;(RNNs)&#30340;&#37325;&#35201;&#26032;&#20852;&#30740;&#31350;&#39046;&#22495;&#65292;&#25105;&#20204;&#22312;Kozachkov&#31561;&#20154;&#30340;&#8220;&#36882;&#24402;&#26500;&#24314;&#31283;&#23450;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#32452;&#35013;&#21697;&#8221;&#30340;&#22522;&#30784;&#19978;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#36827;&#34892;&#20102;&#25193;&#23637;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26550;&#26500;&#30340;&#26174;&#33879;&#29305;&#20363;&#30340;&#26494;&#25955;&#31283;&#23450;&#24615;&#26465;&#20214;&#65292;&#29305;&#21035;&#26159;&#38024;&#23545;&#20840;&#23616;&#24037;&#20316;&#31354;&#38388;&#27169;&#22359;&#21270;&#32467;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#20855;&#26377;&#23569;&#37327;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#20840;&#23616;&#24037;&#20316;&#31354;&#38388;&#31232;&#30095;&#32452;&#21512;&#32593;&#32476;&#36827;&#34892;&#23454;&#35777;&#25104;&#21151;&#65292;&#19981;&#20165;&#22312;&#25972;&#20307;&#27979;&#35797;&#34920;&#29616;&#26041;&#38754;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#65292;&#36824;&#23545;&#21333;&#20010;&#23376;&#32593;&#32476;&#30340;&#31227;&#38500;&#20855;&#26377;&#26356;&#22823;&#30340;&#38887;&#24615;&#12290;&#36825;&#20123;&#20840;&#23616;&#24037;&#20316;&#31354;&#38388;&#25509;&#35302;&#21306;&#25299;&#25169;&#30340;&#23454;&#35777;&#32467;&#26524;&#20381;&#36182;&#20110;&#31283;&#23450;&#24615;&#30340;&#20445;&#25345;&#65292;&#31361;&#20986;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#24037;&#20316;&#23545;&#20110;&#23454;&#29616;&#27169;&#22359;&#21270;RNN&#30340;&#25104;&#21151;&#30340;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#26356;&#24191;&#27867;&#22320;&#25506;&#32034;&#19981;&#21516;&#23376;&#32593;&#32476;&#27169;&#22359;&#20043;&#38388;&#30340;&#36830;&#25509;&#32467;&#26500;&#30340;&#31232;&#30095;&#24615;&#65292;
&lt;/p&gt;
&lt;p&gt;
To push forward the important emerging research field surrounding multi-area recurrent neural networks (RNNs), we expand theoretically and empirically on the provably stable RNNs of RNNs introduced by Kozachkov et al. in "RNNs of RNNs: Recursive Construction of Stable Assemblies of Recurrent Neural Networks". We prove relaxed stability conditions for salient special cases of this architecture, most notably for a global workspace modular structure. We then demonstrate empirical success for Global Workspace Sparse Combo Nets with a small number of trainable parameters, not only through strong overall test performance but also greater resilience to removal of individual subnetworks. These empirical results for the global workspace inter-area topology are contingent on stability preservation, highlighting the relevance of our theoretical work for enabling modular RNN success. Further, by exploring sparsity in the connectivity structure between different subnetwork modules more broadly, we 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23545;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#30740;&#31350;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#25512;&#21160;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#31934;&#32454;&#35821;&#35328;&#65292;&#20316;&#32773;&#26500;&#24314;&#20102;WhyShift&#23454;&#39564;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;$Y|X$-&#20559;&#31227;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.05284</link><description>&lt;p&gt;
&#20851;&#20110;&#38656;&#35201;&#25551;&#36848;&#20998;&#24067;&#20559;&#31227;&#30340;&#35821;&#35328;&#65306;&#22522;&#20110;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#26696;&#20363;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets. (arXiv:2307.05284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05284
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23545;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#30740;&#31350;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#25512;&#21160;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#31934;&#32454;&#35821;&#35328;&#65292;&#20316;&#32773;&#26500;&#24314;&#20102;WhyShift&#23454;&#39564;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;$Y|X$-&#20559;&#31227;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#20998;&#24067;&#20559;&#31227;&#38656;&#35201;&#19981;&#21516;&#30340;&#31639;&#27861;&#21644;&#25805;&#20316;&#24178;&#39044;&#12290;&#26041;&#27861;&#30740;&#31350;&#24517;&#39035;&#20197;&#20854;&#25152;&#28041;&#21450;&#30340;&#20855;&#20307;&#20559;&#31227;&#20026;&#22522;&#30784;&#12290;&#23613;&#31649;&#26032;&#20852;&#30340;&#22522;&#20934;&#25968;&#25454;&#20026;&#23454;&#35777;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#22522;&#30784;&#65292;&#20294;&#23427;&#20204;&#38544;&#21547;&#22320;&#20851;&#27880;&#21327;&#21464;&#37327;&#20559;&#31227;&#65292;&#24182;&#19988;&#23454;&#35777;&#21457;&#29616;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#20559;&#31227;&#31867;&#22411;&#65292;&#20363;&#22914;&#65292;&#24403;$Y|X$&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#65292;&#20043;&#21069;&#20851;&#20110;&#31639;&#27861;&#24615;&#33021;&#30340;&#35266;&#23519;&#21487;&#33021;&#26080;&#25928;&#12290;&#25105;&#20204;&#23545;5&#20010;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#36890;&#36807;&#23545;86,000&#20010;&#27169;&#22411;&#37197;&#32622;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#40723;&#21169;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#19968;&#31181;&#31934;&#32454;&#30340;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#35821;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;WhyShift&#65292;&#19968;&#20010;&#30001;&#31574;&#21010;&#30340;&#30495;&#23454;&#19990;&#30028;&#20559;&#31227;&#27979;&#35797;&#24179;&#21488;&#65292;&#22312;&#20854;&#20013;&#25105;&#20204;&#23545;&#25105;&#20204;&#22522;&#20934;&#24615;&#33021;&#30340;&#20559;&#31227;&#31867;&#22411;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#30001;&#20110;$Y|X$-&#20559;&#31227;&#22312;&#34920;&#26684;&#35774;&#32622;&#20013;&#24456;&#24120;&#35265;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#21463;&#21040;&#26368;&#22823;$Y|X$-&#20559;&#31227;&#24433;&#21709;&#30340;&#21327;&#21464;&#37327;&#21306;&#22495;&#65292;&#24182;&#35752;&#35770;&#20102;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Different distribution shifts require different algorithmic and operational interventions. Methodological research must be grounded by the specific shifts they address. Although nascent benchmarks provide a promising empirical foundation, they implicitly focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes. We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent. To encourage researchers to develop a refined language for distribution shifts, we build WhyShift, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over. Since $Y|X$-shifts are prevalent in tabular settings, we identify covariate regions that suffer the biggest $Y|X$-shifts and discuss implications for algorithm
&lt;/p&gt;</description></item></channel></rss>