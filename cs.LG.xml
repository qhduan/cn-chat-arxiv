<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026; $\mathrm{CAESAR}$ &#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#19968;&#20010;&#36817;&#20284;&#30340;&#26368;&#20248;&#31163;&#32447;&#37319;&#26679;&#20998;&#24067;&#65292;&#21516;&#26102;&#20272;&#35745;&#22810;&#20010;&#31574;&#30053;&#30340;&#20215;&#20540;&#65292;&#20197;&#35299;&#20915;&#22810;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.00195</link><description>&lt;p&gt;
&#36890;&#36807;&#23494;&#24230;&#20272;&#35745;&#36827;&#34892;&#22810;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Multiple-policy Evaluation via Density Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00195
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026; $\mathrm{CAESAR}$ &#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#19968;&#20010;&#36817;&#20284;&#30340;&#26368;&#20248;&#31163;&#32447;&#37319;&#26679;&#20998;&#24067;&#65292;&#21516;&#26102;&#20272;&#35745;&#22810;&#20010;&#31574;&#30053;&#30340;&#20215;&#20540;&#65292;&#20197;&#35299;&#20915;&#22810;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#22810;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#32473;&#23450;&#19968;&#32452; $K$ &#20010;&#30446;&#26631;&#31574;&#30053;&#65292;&#30446;&#26631;&#26159;&#20197;&#33267;&#23569; $1-\delta$ &#30340;&#27010;&#29575;&#35780;&#20272;&#23427;&#20204;&#30340;&#24615;&#33021;&#65288;&#26399;&#26395;&#24635;&#22870;&#21169;&#65289;&#36798;&#21040;&#31934;&#24230; $\epsilon$&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; $\mathrm{CAESAR}$ &#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#35745;&#31639;&#19968;&#20010;&#36817;&#20284;&#30340;&#26368;&#20248;&#31163;&#32447;&#37319;&#26679;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#20174;&#20013;&#37319;&#26679;&#30340;&#25968;&#25454;&#26469;&#21516;&#26102;&#20272;&#35745;&#31574;&#30053;&#20215;&#20540;&#12290;$\mathrm{CAESAR}$ &#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#12290;&#22312;&#31532;&#19968;&#20010;&#38454;&#27573;&#65292;&#25105;&#20204;&#20197;&#38543;&#30528; $\tilde{O}(\frac{1}{\epsilon})$ &#32553;&#25918;&#30340;&#20302;&#35746;&#21333;&#37319;&#26679;&#22797;&#26434;&#24615;&#29575;&#20135;&#29983;&#30446;&#26631;&#31574;&#30053;&#30340;&#35775;&#38382;&#20998;&#24067;&#30340;&#31895;&#30053;&#20272;&#35745;&#12290;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#25105;&#20204;&#36817;&#20284;&#26368;&#20248;&#31163;&#32447;&#37319;&#26679;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#20010;&#36880;&#27493;&#20108;&#27425;&#25439;&#22833;&#20989;&#25968;&#26469;&#35745;&#31639;&#25152;&#26377;&#30446;&#26631;&#31574;&#30053;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00195v1 Announce Type: cross  Abstract: In this work, we focus on the multiple-policy evaluation problem where we are given a set of $K$ target policies and the goal is to evaluate their performance (the expected total rewards) to an accuracy $\epsilon$ with probability at least $1-\delta$. We propose an algorithm named $\mathrm{CAESAR}$ to address this problem. Our approach is based on computing an approximate optimal offline sampling distribution and using the data sampled from it to perform the simultaneous estimation of the policy values. $\mathrm{CAESAR}$ consists of two phases. In the first one we produce coarse estimates of the vistation distributions of the target policies at a low order sample complexity rate that scales with $\tilde{O}(\frac{1}{\epsilon})$. In the second phase, we approximate the optimal offline sampling distribution and compute the importance weighting ratios for all target policies by minimizing a step-wise quadratic loss function inspired by the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102; Generalized Latent Equilibrium (GLE)&#65292;&#23427;&#26159;&#19968;&#31181;&#38024;&#23545;&#31070;&#32463;&#20803;&#32593;&#32476;&#30340;&#29289;&#29702;&#21160;&#24577;&#23616;&#37096;&#26102;&#31354;&#20449;&#29992;&#20998;&#37197;&#30340;&#35745;&#31639;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2403.16933</link><description>&lt;p&gt;
&#36890;&#36807;&#31354;&#38388;&#12289;&#26102;&#38388;&#21644;&#22823;&#33041;&#36827;&#34892;&#21453;&#21521;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Backpropagation through space, time, and the brain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16933
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102; Generalized Latent Equilibrium (GLE)&#65292;&#23427;&#26159;&#19968;&#31181;&#38024;&#23545;&#31070;&#32463;&#20803;&#32593;&#32476;&#30340;&#29289;&#29702;&#21160;&#24577;&#23616;&#37096;&#26102;&#31354;&#20449;&#29992;&#20998;&#37197;&#30340;&#35745;&#31639;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#38656;&#35201;&#26681;&#25454;&#23427;&#20204;&#23545;&#35299;&#20915;&#20219;&#21153;&#30340;&#30456;&#23545;&#36129;&#29486;&#26469;&#35843;&#25972;&#21333;&#20010;&#31361;&#35302;&#12290;&#28982;&#32780;&#65292;&#26080;&#35770;&#26159;&#29983;&#29289;&#36824;&#26159;&#20154;&#24037;&#30340;&#29289;&#29702;&#31070;&#32463;&#31995;&#32479;&#37117;&#21463;&#21040;&#26102;&#31354;&#23616;&#38480;&#12290;&#36825;&#26679;&#30340;&#32593;&#32476;&#22914;&#20309;&#25191;&#34892;&#39640;&#25928;&#30340;&#20449;&#29992;&#20998;&#37197;&#65292;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20173;&#26159;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#38169;&#35823;&#30340;&#21453;&#21521;&#20256;&#25773;&#31639;&#27861;&#20960;&#20046;&#26222;&#36941;&#34987;&#31354;&#38388;&#65288;BP&#65289;&#21644;&#26102;&#38388;&#65288;BPTT&#65289;&#20004;&#31181;&#26041;&#24335;&#32473;&#20986;&#31572;&#26696;&#12290;&#28982;&#32780;&#65292;BP(TT)&#34987;&#24191;&#27867;&#35748;&#20026;&#20381;&#36182;&#20110;&#19981;&#20855;&#29983;&#29289;&#23398;&#24847;&#20041;&#30340;&#20551;&#35774;&#65292;&#29305;&#21035;&#26159;&#20851;&#20110;&#26102;&#31354;&#23616;&#38480;&#24615;&#65292;&#32780;&#27491;&#21521;&#20256;&#25773;&#27169;&#22411;&#65292;&#22914;&#23454;&#26102;&#36882;&#24402;&#23398;&#20064;&#65288;RTRL&#65289;&#65292;&#21017;&#21463;&#21040;&#20869;&#23384;&#32422;&#26463;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#24191;&#20041;&#28508;&#22312;&#24179;&#34913;&#65288;GLE&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#38024;&#23545;&#31070;&#32463;&#20803;&#29289;&#29702;&#21160;&#24577;&#32593;&#32476;&#23436;&#20840;&#23616;&#37096;&#26102;&#31354;&#20449;&#29992;&#20998;&#37197;&#30340;&#35745;&#31639;&#26694;&#26550;&#12290;&#25105;&#20204;&#20174;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16933v1 Announce Type: cross  Abstract: Effective learning in neuronal networks requires the adaptation of individual synapses given their relative contribution to solving a task. However, physical neuronal systems -- whether biological or artificial -- are constrained by spatio-temporal locality. How such networks can perform efficient credit assignment, remains, to a large extent, an open question. In Machine Learning, the answer is almost universally given by the error backpropagation algorithm, through both space (BP) and time (BPTT). However, BP(TT) is well-known to rely on biologically implausible assumptions, in particular with respect to spatiotemporal (non-)locality, while forward-propagation models such as real-time recurrent learning (RTRL) suffer from prohibitive memory constraints. We introduce Generalized Latent Equilibrium (GLE), a computational framework for fully local spatio-temporal credit assignment in physical, dynamical networks of neurons. We start by 
&lt;/p&gt;</description></item><item><title>&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#29983;&#25104;&#22810;&#20010;&#21453;&#20107;&#23454;&#31034;&#20363;&#20197;&#25429;&#33719;&#24322;&#24120;&#30340;&#22810;&#26679;&#27010;&#24565;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#23545;&#35302;&#21457;&#24322;&#24120;&#26816;&#27979;&#22120;&#26426;&#21046;&#30340;&#39640;&#32423;&#35821;&#20041;&#35299;&#37322;&#65292;&#20801;&#35768;&#25506;&#32034;&#8220;&#20551;&#35774;&#24773;&#26223;&#8221;&#12290;</title><link>https://arxiv.org/abs/2402.14469</link><description>&lt;p&gt;
&#37325;&#26032;&#26500;&#24819;&#24322;&#24120;&#65306;&#22914;&#26524;&#24322;&#24120;&#26159;&#27491;&#24120;&#30340;&#21602;&#65311;
&lt;/p&gt;
&lt;p&gt;
Reimagining Anomalies: What If Anomalies Were Normal?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14469
&lt;/p&gt;
&lt;p&gt;
&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#29983;&#25104;&#22810;&#20010;&#21453;&#20107;&#23454;&#31034;&#20363;&#20197;&#25429;&#33719;&#24322;&#24120;&#30340;&#22810;&#26679;&#27010;&#24565;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#23545;&#35302;&#21457;&#24322;&#24120;&#26816;&#27979;&#22120;&#26426;&#21046;&#30340;&#39640;&#32423;&#35821;&#20041;&#35299;&#37322;&#65292;&#20801;&#35768;&#25506;&#32034;&#8220;&#20551;&#35774;&#24773;&#26223;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#22312;&#22270;&#20687;&#24322;&#24120;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#31361;&#30772;&#65292;&#20294;&#20854;&#22797;&#26434;&#24615;&#32473;&#29702;&#35299;&#20026;&#20309;&#23454;&#20363;&#34987;&#39044;&#27979;&#20026;&#24322;&#24120;&#24102;&#26469;&#20102;&#30456;&#24403;&#22823;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#20026;&#27599;&#20010;&#24322;&#24120;&#29983;&#25104;&#22810;&#20010;&#21453;&#20107;&#23454;&#31034;&#20363;&#65292;&#25429;&#33719;&#24322;&#24120;&#30340;&#22810;&#26679;&#27010;&#24565;&#12290;&#21453;&#20107;&#23454;&#31034;&#20363;&#26159;&#23545;&#24322;&#24120;&#30340;&#20462;&#25913;&#65292;&#34987;&#24322;&#24120;&#26816;&#27979;&#22120;&#35270;&#20026;&#27491;&#24120;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#35302;&#21457;&#24322;&#24120;&#26816;&#27979;&#22120;&#26426;&#21046;&#30340;&#39640;&#32423;&#35821;&#20041;&#35299;&#37322;&#65292;&#20801;&#35768;&#29992;&#25143;&#25506;&#32034;&#8220;&#20551;&#35774;&#24773;&#26223;&#8221;&#12290;&#23545;&#19981;&#21516;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#20998;&#26512;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#26368;&#20808;&#36827;&#30340;&#24322;&#24120;&#26816;&#27979;&#22120;&#21487;&#20197;&#23454;&#29616;&#23545;&#26816;&#27979;&#22120;&#30340;&#39640;&#36136;&#37327;&#35821;&#20041;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14469v1 Announce Type: cross  Abstract: Deep learning-based methods have achieved a breakthrough in image anomaly detection, but their complexity introduces a considerable challenge to understanding why an instance is predicted to be anomalous. We introduce a novel explanation method that generates multiple counterfactual examples for each anomaly, capturing diverse concepts of anomalousness. A counterfactual example is a modification of the anomaly that is perceived as normal by the anomaly detector. The method provides a high-level semantic explanation of the mechanism that triggered the anomaly detector, allowing users to explore "what-if scenarios." Qualitative and quantitative analyses across various image datasets show that the method applied to state-of-the-art anomaly detectors can achieve high-quality semantic explanations of detectors.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23398;&#20064;&#31639;&#23376;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#30446;&#26631;&#31639;&#23376;&#30340;&#35268;&#21017;&#26465;&#20214;&#65292;&#24182;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21450;&#32447;&#24615;&#36817;&#20284;&#25910;&#25947;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04691</link><description>&lt;p&gt;
&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Learning Operators with Stochastic Gradient Descent in General Hilbert Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23398;&#20064;&#31639;&#23376;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#30446;&#26631;&#31639;&#23376;&#30340;&#35268;&#21017;&#26465;&#20214;&#65292;&#24182;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21450;&#32447;&#24615;&#36817;&#20284;&#25910;&#25947;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23398;&#20064;&#31639;&#23376;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#30446;&#26631;&#31639;&#23376;&#30340;&#24369;&#21644;&#24378;&#35268;&#21017;&#26465;&#20214;&#65292;&#20197;&#25551;&#36848;&#20854;&#20869;&#22312;&#32467;&#26500;&#21644;&#22797;&#26434;&#24615;&#12290;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#65292;&#24182;&#36827;&#34892;&#20102;&#26497;&#23567;&#20540;&#19979;&#30028;&#20998;&#26512;&#65292;&#36827;&#19968;&#27493;&#35828;&#26126;&#25105;&#20204;&#30340;&#25910;&#25947;&#20998;&#26512;&#21644;&#35268;&#21017;&#26465;&#20214;&#23450;&#37327;&#22320;&#21051;&#30011;&#20102;&#20351;&#29992;SGD&#31639;&#27861;&#35299;&#20915;&#31639;&#23376;&#23398;&#20064;&#38382;&#39064;&#30340;&#21487;&#34892;&#24615;&#12290;&#20540;&#24471;&#24378;&#35843;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#25910;&#25947;&#20998;&#26512;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#20173;&#28982;&#26377;&#25928;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SGD&#20272;&#35745;&#22120;&#23558;&#25910;&#25947;&#20110;&#38750;&#32447;&#24615;&#30446;&#26631;&#31639;&#23376;&#30340;&#26368;&#20339;&#32447;&#24615;&#36817;&#20284;&#12290;&#27492;&#22806;&#65292;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#24212;&#29992;&#20110;&#22522;&#20110;&#30690;&#37327;&#20540;&#21644;&#23454;&#20540;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#31639;&#23376;&#23398;&#20064;&#38382;&#39064;&#65292;&#20135;&#29983;&#20102;&#26032;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#20174;&#32780;&#23436;&#21892;&#20102;&#29616;&#26377;&#25991;&#29486;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates leveraging stochastic gradient descent (SGD) to learn operators between general Hilbert spaces. We propose weak and strong regularity conditions for the target operator to depict its intrinsic structure and complexity. Under these conditions, we establish upper bounds for convergence rates of the SGD algorithm and conduct a minimax lower bound analysis, further illustrating that our convergence analysis and regularity conditions quantitatively characterize the tractability of solving operator learning problems using the SGD algorithm. It is crucial to highlight that our convergence analysis is still valid for nonlinear operator learning. We show that the SGD estimator will converge to the best linear approximation of the nonlinear target operator. Moreover, applying our analysis to operator learning problems based on vector-valued and real-valued reproducing kernel Hilbert spaces yields new convergence results, thereby refining the conclusions of existing litera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#31574;&#30053;&#20215;&#20540;&#30340;&#31934;&#30830;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#24182;&#19988;&#20855;&#26377;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.12450</link><description>&lt;p&gt;
&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Convex Framework for Confounding Robust Inference. (arXiv:2309.12450v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25903;&#25745;&#40065;&#26834;&#25512;&#26029;&#30340;&#20984;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#31574;&#30053;&#20215;&#20540;&#30340;&#31934;&#30830;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#24182;&#19988;&#20855;&#26377;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21463;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#24433;&#21709;&#30340;&#31163;&#32447;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#24120;&#34987;&#29992;&#26469;&#22312;&#32473;&#23450;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19978;&#20272;&#35745;&#22312;&#26368;&#22351;&#28151;&#28102;&#24773;&#20917;&#19979;&#30340;&#31574;&#30053;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#36890;&#24120;&#20026;&#20102;&#21487;&#34892;&#24615;&#32780;&#37319;&#29992;&#19968;&#20123;&#31895;&#31961;&#30340;&#26494;&#24347;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30340;&#26041;&#27861;&#65292;&#23548;&#33268;&#23545;&#31574;&#30053;&#20215;&#20540;&#30340;&#20272;&#35745;&#36807;&#20110;&#20445;&#23432;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#20984;&#35268;&#21010;&#25552;&#20379;&#20102;&#31574;&#30053;&#20215;&#20540;&#30340;&#19968;&#20010;&#36739;&#20026;&#31934;&#30830;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#20351;&#24471;&#20854;&#33021;&#22815;&#36827;&#34892;&#22810;&#31181;&#25193;&#23637;&#65292;&#20363;&#22914;&#22522;&#20110;f-&#20998;&#27495;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#21644;&#20449;&#24687;&#20934;&#21017;&#30340;&#27169;&#22411;&#36873;&#25321;&#20197;&#21450;&#21033;&#29992;&#19978;&#30028;&#36827;&#34892;&#40065;&#26834;&#31574;&#30053;&#23398;&#20064;&#31561;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#24378;&#23545;&#20598;&#24615;&#37325;&#26032;&#34920;&#36848;&#20026;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#21033;&#29992;M&#25216;&#26415;&#25552;&#20379;&#20102;&#23545;&#25152;&#25552;&#20986;&#20272;&#35745;&#22120;&#30340;&#24378;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value using convex programming. The generality of our estimator enables various extensions such as sensitivity analysis with f-divergence, model selection with cross validation and information criterion, and robust policy learning with the sharp lower bound. Furthermore, our estimation method can be reformulated as an empirical risk minimization problem thanks to the strong duality, which enables us to provide strong theoretical guarantees of the proposed estimator using techniques of the M-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25554;&#20540;&#20449;&#24687;&#20934;&#21017;&#65292;&#29992;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#24314;&#31435;&#36125;&#21494;&#26031;&#23545;&#20598;&#24418;&#24335;&#65292;&#35813;&#20934;&#21017;&#23558;&#20808;&#39564;&#36873;&#25321;&#32435;&#20837;&#27169;&#22411;&#35780;&#20272;&#65292;&#24182;&#32771;&#34385;&#20102;&#20808;&#39564;&#35823;&#35774;&#12289;&#27169;&#22411;&#30340;&#20960;&#20309;&#21644;&#35889;&#29305;&#24615;&#12290;&#35813;&#20934;&#21017;&#22312;&#23454;&#35777;&#21644;&#29702;&#35770;&#34892;&#20026;&#26041;&#38754;&#19982;&#24050;&#30693;&#32467;&#26524;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2307.07785</link><description>&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#25554;&#20540;&#20449;&#24687;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
The Interpolating Information Criterion for Overparameterized Models. (arXiv:2307.07785v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25554;&#20540;&#20449;&#24687;&#20934;&#21017;&#65292;&#29992;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#24314;&#31435;&#36125;&#21494;&#26031;&#23545;&#20598;&#24418;&#24335;&#65292;&#35813;&#20934;&#21017;&#23558;&#20808;&#39564;&#36873;&#25321;&#32435;&#20837;&#27169;&#22411;&#35780;&#20272;&#65292;&#24182;&#32771;&#34385;&#20102;&#20808;&#39564;&#35823;&#35774;&#12289;&#27169;&#22411;&#30340;&#20960;&#20309;&#21644;&#35889;&#29305;&#24615;&#12290;&#35813;&#20934;&#21017;&#22312;&#23454;&#35777;&#21644;&#29702;&#35770;&#34892;&#20026;&#26041;&#38754;&#19982;&#24050;&#30693;&#32467;&#26524;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#36807;&#21442;&#25968;&#21270;&#20272;&#35745;&#22120;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#65292;&#20854;&#20013;&#27169;&#22411;&#21442;&#25968;&#30340;&#25968;&#37327;&#36229;&#36807;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#12290;&#20256;&#32479;&#30340;&#20449;&#24687;&#20934;&#21017;&#36890;&#24120;&#32771;&#34385;&#22823;&#25968;&#25454;&#26497;&#38480;&#65292;&#23545;&#27169;&#22411;&#22823;&#23567;&#36827;&#34892;&#24809;&#32602;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#20195;&#35774;&#32622;&#20013;&#65292;&#36825;&#20123;&#20934;&#21017;&#19981;&#36866;&#29992;&#65292;&#22240;&#20026;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#24448;&#24448;&#34920;&#29616;&#33391;&#22909;&#12290;&#23545;&#20110;&#20219;&#20309;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#25105;&#20204;&#35777;&#26126;&#23384;&#22312;&#19968;&#20010;&#23545;&#20598;&#30340;&#27424;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#20855;&#26377;&#30456;&#21516;&#30340;&#36793;&#32536;&#20284;&#28982;&#24615;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#36125;&#21494;&#26031;&#23545;&#20598;&#24418;&#24335;&#12290;&#36825;&#20351;&#24471;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#21487;&#20197;&#20351;&#29992;&#26356;&#22810;&#32463;&#20856;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#25554;&#20540;&#20449;&#24687;&#20934;&#21017;&#65292;&#19968;&#31181;&#33258;&#28982;&#22320;&#23558;&#20808;&#39564;&#36873;&#25321;&#32435;&#20837;&#27169;&#22411;&#36873;&#25321;&#30340;&#27169;&#22411;&#36136;&#37327;&#24230;&#37327;&#12290;&#25105;&#20204;&#30340;&#26032;&#20449;&#24687;&#20934;&#21017;&#32771;&#34385;&#20102;&#20808;&#39564;&#35823;&#35774;&#12289;&#27169;&#22411;&#30340;&#20960;&#20309;&#21644;&#35889;&#29305;&#24615;&#65292;&#24182;&#19988;&#22312;&#35813;&#21306;&#22495;&#19982;&#24050;&#30693;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#34892;&#20026;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of model selection is considered for the setting of interpolating estimators, where the number of model parameters exceeds the size of the dataset. Classical information criteria typically consider the large-data limit, penalizing model size. However, these criteria are not appropriate in modern settings where overparameterized models tend to perform well. For any overparameterized model, we show that there exists a dual underparameterized model that possesses the same marginal likelihood, thus establishing a form of Bayesian duality. This enables more classical methods to be used in the overparameterized setting, revealing the Interpolating Information Criterion, a measure of model quality that naturally incorporates the choice of prior into the model selection. Our new information criterion accounts for prior misspecification, geometric and spectral properties of the model, and is numerically consistent with known empirical and theoretical behavior in this regime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#23618;&#24352;&#37327;&#33609;&#22270;&#26469;&#36817;&#20284;&#39640;&#32500;&#27010;&#29575;&#23494;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;&#25216;&#26415;&#35299;&#20915;&#32447;&#24615;&#26041;&#31243;&#36798;&#21040;&#27492;&#30446;&#30340;&#65292;&#20854;&#31639;&#27861;&#22797;&#26434;&#24230;&#22312;&#39640;&#32500;&#23494;&#24230;&#32500;&#24230;&#19978;&#21576;&#32447;&#24615;&#35268;&#27169;&#12290;</title><link>http://arxiv.org/abs/2304.05305</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#23618;&#24352;&#37327;&#33609;&#22270;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling via Hierarchical Tensor Sketching. (arXiv:2304.05305v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05305
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#23618;&#24352;&#37327;&#33609;&#22270;&#26469;&#36817;&#20284;&#39640;&#32500;&#27010;&#29575;&#23494;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;&#25216;&#26415;&#35299;&#20915;&#32447;&#24615;&#26041;&#31243;&#36798;&#21040;&#27492;&#30446;&#30340;&#65292;&#20854;&#31639;&#27861;&#22797;&#26434;&#24230;&#22312;&#39640;&#32500;&#23494;&#24230;&#32500;&#24230;&#19978;&#21576;&#32447;&#24615;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32463;&#39564;&#20998;&#24067;&#26469;&#36817;&#20284;&#39640;&#32500;&#27010;&#29575;&#23494;&#24230;&#30340;&#20998;&#23618;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#25216;&#26415;&#65292;&#24182;&#28041;&#21450;&#22312;&#35813;&#24352;&#37327;&#32593;&#32476;&#20013;&#35299;&#32447;&#24615;&#26041;&#31243;&#20197;&#33719;&#24471;&#24352;&#37327;&#26680;&#24515;&#12290;&#35813;&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#22312;&#39640;&#32500;&#23494;&#24230;&#30340;&#32500;&#24230;&#19978;&#21576;&#32447;&#24615;&#35268;&#27169;&#12290;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#23545;&#20272;&#35745;&#35823;&#24046;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#27492;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a hierarchical tensor-network approach for approximating high-dimensional probability density via empirical distribution. This leverages randomized singular value decomposition (SVD) techniques and involves solving linear equations for tensor cores in this tensor network. The complexity of the resulting algorithm scales linearly in the dimension of the high-dimensional density. An analysis of estimation error demonstrates the effectiveness of this method through several numerical experiments.
&lt;/p&gt;</description></item></channel></rss>