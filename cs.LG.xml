<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>CATGNN&#26159;&#19968;&#31181;&#25104;&#26412;&#26377;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#20998;&#24067;&#24335;GNN&#35757;&#32451;&#31995;&#32479;&#65292;&#36890;&#36807;&#25509;&#21463;&#36793;&#27969;&#20316;&#20026;&#36755;&#20837;&#24182;&#25552;&#20986;&#21517;&#20026;SPRING&#30340;&#27969;&#24335;&#20998;&#21306;&#31639;&#27861;&#65292;&#23454;&#29616;&#23558;GNN&#35757;&#32451;&#25193;&#23637;&#21040;&#25968;&#21313;&#20159;&#20197;&#19978;&#35268;&#27169;&#30340;&#22270;&#20013;&#12290;</title><link>https://arxiv.org/abs/2404.02300</link><description>&lt;p&gt;
CATGNN&#65306;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25104;&#26412;&#26377;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
CATGNN: Cost-Efficient and Scalable Distributed Training for Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02300
&lt;/p&gt;
&lt;p&gt;
CATGNN&#26159;&#19968;&#31181;&#25104;&#26412;&#26377;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#20998;&#24067;&#24335;GNN&#35757;&#32451;&#31995;&#32479;&#65292;&#36890;&#36807;&#25509;&#21463;&#36793;&#27969;&#20316;&#20026;&#36755;&#20837;&#24182;&#25552;&#20986;&#21517;&#20026;SPRING&#30340;&#27969;&#24335;&#20998;&#21306;&#31639;&#27861;&#65292;&#23454;&#29616;&#23558;GNN&#35757;&#32451;&#25193;&#23637;&#21040;&#25968;&#21313;&#20159;&#20197;&#19978;&#35268;&#27169;&#30340;&#22270;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#23613;&#31649;&#24050;&#32463;&#24320;&#21457;&#20102;&#19981;&#21516;&#30340;GNN&#26550;&#26500;&#21644;&#35757;&#32451;&#31995;&#32479;&#65292;&#20294;&#22312;&#22823;&#35268;&#27169;&#23454;&#38469;&#22270;&#19978;&#36827;&#34892;GNN&#35757;&#32451;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#30340;&#20998;&#24067;&#24335;&#31995;&#32479;&#38656;&#35201;&#23558;&#25972;&#20010;&#22270;&#21152;&#36733;&#21040;&#20869;&#23384;&#20013;&#20197;&#36827;&#34892;&#22270;&#20998;&#21306;&#65292;&#38656;&#35201;&#22823;&#37327;&#20869;&#23384;&#31354;&#38388;&#26469;&#22788;&#29702;&#22823;&#22270;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#20351;&#29992;&#26222;&#36890;&#24037;&#20316;&#31449;&#22312;&#36825;&#20123;&#22823;&#22270;&#19978;&#36827;&#34892;GNN&#35757;&#32451;&#12290;&#26412;&#25991;&#25552;&#20986;CATGNN&#65292;&#19968;&#20010;&#25104;&#26412;&#25928;&#30410;&#39640;&#19988;&#21487;&#25193;&#23637;&#30340;&#20998;&#24067;&#24335;GNN&#35757;&#32451;&#31995;&#32479;&#65292;&#19987;&#27880;&#20110;&#22312;&#26377;&#38480;&#35745;&#31639;&#36164;&#28304;&#19979;&#23558;GNN&#35757;&#32451;&#25193;&#23637;&#21040;&#25968;&#21313;&#20159;&#29978;&#33267;&#26356;&#22823;&#35268;&#27169;&#30340;&#22270;&#20013;&#12290;&#22312;&#20854;&#20182;&#21151;&#33021;&#20013;&#65292;&#23427;&#25509;&#21463;&#19968;&#31995;&#21015;&#36793;&#20316;&#20026;&#36755;&#20837;&#65292;&#32780;&#19981;&#26159;&#23558;&#25972;&#20010;&#22270;&#21152;&#36733;&#21040;&#20869;&#23384;&#20013;&#36827;&#34892;&#20998;&#21306;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SPRING&#30340;&#26032;&#22411;&#27969;&#24335;&#20998;&#21306;&#31639;&#27861;&#65292;&#29992;&#20110;&#20998;&#24067;&#24335;GNN&#35757;&#32451;&#12290;&#25105;&#20204;&#22312;16&#20010;&#24320;&#25918;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;CATGNN&#19982;SPRING&#30340;&#27491;&#30830;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02300v1 Announce Type: new  Abstract: Graph neural networks have been shown successful in recent years. While different GNN architectures and training systems have been developed, GNN training on large-scale real-world graphs still remains challenging. Existing distributed systems load the entire graph in memory for graph partitioning, requiring a huge memory space to process large graphs and thus hindering GNN training on such large graphs using commodity workstations. In this paper, we propose CATGNN, a cost-efficient and scalable distributed GNN training system which focuses on scaling GNN training to billion-scale or larger graphs under limited computational resources. Among other features, it takes a stream of edges as input, instead of loading the entire graph in memory, for partitioning. We also propose a novel streaming partitioning algorithm named SPRING for distributed GNN training. We verify the correctness and effectiveness of CATGNN with SPRING on 16 open datase
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38598;&#25104;&#23398;&#20064;&#26694;&#26550;EL-MLFFs&#65292;&#21033;&#29992;&#22534;&#21472;&#26041;&#27861;&#25972;&#21512;&#26469;&#33258;&#19981;&#21516;MLFFs&#30340;&#39044;&#27979;&#65292;&#20174;&#32780;&#25552;&#39640;&#21147;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17507</link><description>&lt;p&gt;
EL-MLFFs&#65306;&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;&#30340;&#38598;&#25104;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
EL-MLFFs: Ensemble Learning of Machine Leaning Force Fields
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17507
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38598;&#25104;&#23398;&#20064;&#26694;&#26550;EL-MLFFs&#65292;&#21033;&#29992;&#22534;&#21472;&#26041;&#27861;&#25972;&#21512;&#26469;&#33258;&#19981;&#21516;MLFFs&#30340;&#39044;&#27979;&#65292;&#20174;&#32780;&#25552;&#39640;&#21147;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;&#65288;MLFFs&#65289;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24357;&#21512;&#37327;&#23376;&#21147;&#23398;&#26041;&#27861;&#30340;&#31934;&#30830;&#24615;&#21644;&#32463;&#20856;&#21147;&#22330;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;MLFF&#27169;&#22411;&#30340;&#20016;&#23500;&#24615;&#21644;&#20934;&#30830;&#39044;&#27979;&#21407;&#23376;&#21147;&#30340;&#25361;&#25112;&#32473;&#23427;&#20204;&#30340;&#23454;&#38469;&#24212;&#29992;&#24102;&#26469;&#20102;&#37325;&#22823;&#38556;&#30861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38598;&#25104;&#23398;&#20064;&#26694;&#26550;EL-MLFFs&#65292;&#21033;&#29992;&#22534;&#21472;&#26041;&#27861;&#25972;&#21512;&#26469;&#33258;&#19981;&#21516;MLFFs&#30340;&#39044;&#27979;&#65292;&#22686;&#24378;&#21147;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#26500;&#24314;&#20998;&#23376;&#32467;&#26500;&#30340;&#22270;&#34920;&#31034;&#24182;&#37319;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20316;&#20026;&#20803;&#27169;&#22411;&#65292;EL-MLFFs&#26377;&#25928;&#22320;&#25429;&#25417;&#21407;&#23376;&#38388;&#30456;&#20114;&#20316;&#29992;&#24182;&#25913;&#36827;&#21147;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65306;&#30002;&#28919;&#20998;&#23376;&#21644;&#21560;&#38468;&#22312;Cu&#65288;100&#65289;&#34920;&#38754;&#19978;&#30340;&#30002;&#37255;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;EL-MLFFs&#30456;&#23545;&#20110;&#21333;&#20010;MLFF&#26174;&#33879;&#25552;&#39640;&#20102;&#21147;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17507v1 Announce Type: new  Abstract: Machine learning force fields (MLFFs) have emerged as a promising approach to bridge the accuracy of quantum mechanical methods and the efficiency of classical force fields. However, the abundance of MLFF models and the challenge of accurately predicting atomic forces pose significant obstacles in their practical application. In this paper, we propose a novel ensemble learning framework, EL-MLFFs, which leverages the stacking method to integrate predictions from diverse MLFFs and enhance force prediction accuracy. By constructing a graph representation of molecular structures and employing a graph neural network (GNN) as the meta-model, EL-MLFFs effectively captures atomic interactions and refines force predictions. We evaluate our approach on two distinct datasets: methane molecules and methanol adsorbed on a Cu(100) surface. The results demonstrate that EL-MLFFs significantly improves force prediction accuracy compared to individual ML
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#26041;&#27861;&#26469;&#30740;&#31350;&#36825;&#20123;&#38544;&#34255;&#26497;&#23567;&#20540;&#30340;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2312.16819</link><description>&lt;p&gt;
&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;
&lt;/p&gt;
&lt;p&gt;
Hidden Minima in Two-Layer ReLU Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#38544;&#34255;&#26497;&#23567;&#20540;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#26041;&#27861;&#26469;&#30740;&#31350;&#36825;&#20123;&#38544;&#34255;&#26497;&#23567;&#20540;&#30340;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#25311;&#21512;&#20855;&#26377;$d$&#20010;&#36755;&#20837;&#12289;$k$&#20010;&#31070;&#32463;&#20803;&#20197;&#21450;&#30001;&#30446;&#26631;&#32593;&#32476;&#29983;&#25104;&#30340;&#26631;&#31614;&#30340;&#20004;&#23618;ReLU&#32593;&#32476;&#25152;&#28041;&#21450;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#26368;&#36817;&#21457;&#29616;&#20102;&#20004;&#31181;&#26080;&#31351;&#26063;&#30340;&#34394;&#20551;&#26497;&#23567;&#20540;&#65292;&#27599;&#20010;$d$&#23545;&#24212;&#19968;&#20010;&#26497;&#23567;&#20540;&#12290;&#23646;&#20110;&#31532;&#19968;&#31867;&#30340;&#26497;&#23567;&#20540;&#30340;&#25439;&#22833;&#22312;$d$&#22686;&#21152;&#26102;&#25910;&#25947;&#20110;&#38646;&#12290;&#22312;&#31532;&#20108;&#31867;&#20013;&#65292;&#25439;&#22833;&#20445;&#25345;&#36828;&#31163;&#20110;&#38646;&#12290;&#37027;&#20040;&#65292;&#22914;&#20309;&#36991;&#20813;&#23646;&#20110;&#21518;&#19968;&#31867;&#30340;&#26497;&#23567;&#20540;&#21602;&#65311;&#24184;&#36816;&#30340;&#26159;&#65292;&#36825;&#26679;&#30340;&#26497;&#23567;&#20540;&#20174;&#19981;&#20250;&#34987;&#26631;&#20934;&#20248;&#21270;&#26041;&#27861;&#26816;&#27979;&#21040;&#12290;&#21463;&#21040;&#27492;&#29616;&#35937;&#24615;&#36136;&#30340;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#30740;&#31350;&#38544;&#34255;&#26497;&#23567;&#20540;&#29420;&#29305;&#35299;&#26512;&#24615;&#36136;&#30340;&#26041;&#27861;&#12290;&#26681;&#25454;&#29616;&#26377;&#30340;&#20998;&#26512;&#65292;&#20004;&#31181;&#31867;&#22411;&#30340;Hessian&#35889;&#22312;$O(d^{-1/2})$&#39033;&#27169;&#24847;&#20041;&#19979;&#19968;&#33268; -- &#19981;&#22826;&#20048;&#35266;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#25439;&#22833;&#34987;&#26368;&#23567;&#21270;&#25110;&#26368;&#22823;&#21270;&#30340;&#26354;&#32447;&#36827;&#34892;&#65292;&#36890;&#24120;&#31216;&#20026;&#20999;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.16819v2 Announce Type: replace  Abstract: The optimization problem associated to fitting two-layer ReLU networks having $d$~inputs, $k$~neurons, and labels generated by a target network, is considered. Two types of infinite families of spurious minima, giving one minimum per $d$, were recently found. The loss at minima belonging to the first type converges to zero as $d$ increases. In the second type, the loss remains bounded away from zero. That being so, how may one avoid minima belonging to the latter type? Fortunately, such minima are never detected by standard optimization methods. Motivated by questions concerning the nature of this phenomenon, we develop methods to study distinctive analytic properties of hidden minima.   By existing analyses, the Hessian spectrum of both types agree modulo $O(d^{-1/2})$-terms -- not promising. Thus, rather, our investigation proceeds by studying curves along which the loss is minimized or maximized, generally referred to as tangency 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#24577;&#26799;&#24230;&#24179;&#34913;&#25915;&#20987;&#65288;DGBA&#65289;&#26694;&#26550;&#26469;&#25915;&#20987;&#22810;&#20219;&#21153;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#22238;&#31572;&#20102;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#30340;&#23433;&#20840;&#24615;&#12289;&#22810;&#20219;&#21153;&#25915;&#20987;&#21644;&#23545;&#25239;&#35757;&#32451;&#26159;&#21542;&#22686;&#24378;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#31561;&#23433;&#20840;&#30740;&#31350;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.12066</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#21160;&#24577;&#26799;&#24230;&#24179;&#34913;&#22686;&#24378;&#23545;&#25239;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Dynamic Gradient Balancing for Enhanced Adversarial Attacks on Multi-Task Models. (arXiv:2305.12066v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#24577;&#26799;&#24230;&#24179;&#34913;&#25915;&#20987;&#65288;DGBA&#65289;&#26694;&#26550;&#26469;&#25915;&#20987;&#22810;&#20219;&#21153;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#22238;&#31572;&#20102;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#30340;&#23433;&#20840;&#24615;&#12289;&#22810;&#20219;&#21153;&#25915;&#20987;&#21644;&#23545;&#25239;&#35757;&#32451;&#26159;&#21542;&#22686;&#24378;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#31561;&#23433;&#20840;&#30740;&#31350;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064; (MTL) &#21019;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#21333;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#25191;&#34892;&#22810;&#20010;&#20219;&#21153;&#12290;&#34429;&#28982;&#21333;&#20219;&#21153;&#20998;&#31867;&#22120;&#30340;&#23433;&#20840;&#24615;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#22810;&#20219;&#21153;&#27169;&#22411;&#65292;&#23384;&#22312;&#30528;&#20960;&#20010;&#20851;&#38190;&#30340;&#23433;&#20840;&#24615;&#30740;&#31350;&#38382;&#39064;&#65292;&#21253;&#25324;: 1&#65289;&#22810;&#20219;&#21153;&#27169;&#22411;&#23545;&#21333;&#20219;&#21153;&#23545;&#25239;&#26426;&#22120;&#23398;&#20064;&#25915;&#20987;&#30340;&#23433;&#20840;&#24615;&#22914;&#20309;&#65311;2&#65289;&#33021;&#21542;&#35774;&#35745;&#23545;&#25239;&#24615;&#25915;&#20987;&#26469;&#21516;&#26102;&#25915;&#20987;&#22810;&#20010;&#20219;&#21153;&#65311; 3&#65289;&#20219;&#21153;&#20849;&#20139;&#21644;&#23545;&#25239;&#35757;&#32451;&#26159;&#21542;&#22686;&#21152;&#20102;&#22810;&#20219;&#21153;&#27169;&#22411;&#23545;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65311;&#26412;&#25991;&#36890;&#36807;&#20180;&#32454;&#20998;&#26512;&#21644;&#20005;&#26684;&#30340;&#23454;&#39564;&#22238;&#31572;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#21333;&#20219;&#21153;&#30333;&#30418;&#25915;&#20987;&#30340;&#21021;&#32423;&#36716;&#21270;&#24182;&#20998;&#26512;&#20102;&#20854;&#22266;&#26377;&#32570;&#38519;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#26694;&#26550;&#65292;&#21160;&#24577;&#26799;&#24230;&#24179;&#34913;&#25915;&#20987;&#65288;DGBA&#65289;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#25226;&#25915;&#20987;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#38382;&#39064;&#20316;&#20026;&#19968;&#31181;&#22522;&#20110;&#24179;&#22343;&#30456;&#23545;&#25439;&#22833;&#21464;&#21270;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning (MTL) creates a single machine learning model called multi-task model to simultaneously perform multiple tasks. Although the security of single task classifiers has been extensively studied, there are several critical security research questions for multi-task models including 1) How secure are multi-task models to single task adversarial machine learning attacks, 2) Can adversarial attacks be designed to attack multiple tasks simultaneously, and 3) Does task sharing and adversarial training increase multi-task model robustness to adversarial attacks? In this paper, we answer these questions through careful analysis and rigorous experimentation. First, we develop na\"ive adaptation of single-task white-box attacks and analyze their inherent drawbacks. We then propose a novel attack framework, Dynamic Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking a multi-task model as an optimization problem based on averaged relative loss change, whi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;LSTM-GCN&#65292;&#23427;&#33021;&#22815;&#32467;&#21512;&#20215;&#20540;&#38142;&#25968;&#25454;&#20013;&#30340;&#22797;&#26434;&#32467;&#26500;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#20197;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#25429;&#33719;&#20215;&#20540;&#38142;&#25968;&#25454;&#20013;&#26410;&#21453;&#26144;&#22312;&#20215;&#26684;&#25968;&#25454;&#20013;&#30340;&#20449;&#24687;&#65292;&#26377;&#21161;&#20110;&#20132;&#26131;&#32773;&#20248;&#21270;&#20854;&#20132;&#26131;&#31574;&#30053;&#21644;&#26368;&#22823;&#21270;&#21033;&#28070;&#12290;</title><link>http://arxiv.org/abs/2303.09406</link><description>&lt;p&gt;
&#22522;&#20110;&#20215;&#20540;&#38142;&#25968;&#25454;&#30340;&#26102;&#38388;&#22270;&#27169;&#22411;&#36827;&#34892;&#32929;&#31080;&#20215;&#26684;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Stock Price Prediction Using Temporal Graph Model with Value Chain Data. (arXiv:2303.09406v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;LSTM-GCN&#65292;&#23427;&#33021;&#22815;&#32467;&#21512;&#20215;&#20540;&#38142;&#25968;&#25454;&#20013;&#30340;&#22797;&#26434;&#32467;&#26500;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#20197;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#25429;&#33719;&#20215;&#20540;&#38142;&#25968;&#25454;&#20013;&#26410;&#21453;&#26144;&#22312;&#20215;&#26684;&#25968;&#25454;&#20013;&#30340;&#20449;&#24687;&#65292;&#26377;&#21161;&#20110;&#20132;&#26131;&#32773;&#20248;&#21270;&#20854;&#20132;&#26131;&#31574;&#30053;&#21644;&#26368;&#22823;&#21270;&#21033;&#28070;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32929;&#31080;&#20215;&#26684;&#39044;&#27979;&#26159;&#37329;&#34701;&#20132;&#26131;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#20803;&#32032;&#65292;&#23427;&#21487;&#20197;&#24110;&#21161;&#20132;&#26131;&#32773;&#36827;&#34892;&#20080;&#21334;&#21644;&#25345;&#26377;&#32929;&#31080;&#30340;&#20915;&#31574;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#32929;&#31080;&#22238;&#25253;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#38271;&#30701;&#26399;&#35760;&#24518;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;LSTM-GCN&#65289;&#27169;&#22411;&#65292;&#23427;&#32467;&#21512;&#20102;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#32454;&#32990;&#65288;LSTM&#65289;&#12290;GCN&#29992;&#20110;&#25429;&#25417;&#20215;&#20540;&#38142;&#25968;&#25454;&#30340;&#22797;&#26434;&#25299;&#25169;&#32467;&#26500;&#21644;&#31354;&#38388;&#20381;&#36182;&#24615;&#65292;&#32780;LSTM&#21017;&#25429;&#25417;&#32929;&#31080;&#22238;&#25253;&#25968;&#25454;&#30340;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#21160;&#24577;&#21464;&#21270;&#12290;&#25105;&#20204;&#22312;&#30001;Eurostoxx 600&#21644;S&#65286;P 500&#32452;&#25104;&#30340;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;LSTM-GCN&#27169;&#22411;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#27169;&#22411;&#21487;&#20197;&#25429;&#33719;&#20215;&#20540;&#38142;&#25968;&#25454;&#20013;&#26410;&#23436;&#20840;&#21453;&#26144;&#22312;&#20215;&#26684;&#25968;&#25454;&#20013;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stock price prediction is a crucial element in financial trading as it allows traders to make informed decisions about buying, selling, and holding stocks. Accurate predictions of future stock prices can help traders optimize their trading strategies and maximize their profits. In this paper, we introduce a neural network-based stock return prediction method, the Long Short-Term Memory Graph Convolutional Neural Network (LSTM-GCN) model, which combines the Graph Convolutional Network (GCN) and Long Short-Term Memory (LSTM) Cells. Specifically, the GCN is used to capture complex topological structures and spatial dependence from value chain data, while the LSTM captures temporal dependence and dynamic changes in stock returns data. We evaluated the LSTM-GCN model on two datasets consisting of constituents of Eurostoxx 600 and S&amp;P 500. Our experiments demonstrate that the LSTM-GCN model can capture additional information from value chain data that are not fully reflected in price data, a
&lt;/p&gt;</description></item></channel></rss>