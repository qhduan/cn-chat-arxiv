<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#28508;&#22312;&#25968;&#25454;&#38598;&#33976;&#39311;&#65288;LD3M&#65289;&#65292;&#32467;&#21512;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#25193;&#25955;&#21644;&#25968;&#25454;&#38598;&#33976;&#39311;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#19981;&#21516;&#27169;&#22411;&#26550;&#26500;&#23548;&#33268;&#20934;&#30830;&#24615;&#19979;&#38477;&#21644;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.03881</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#28508;&#22312;&#25968;&#25454;&#38598;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Latent Dataset Distillation with Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03881
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#28508;&#22312;&#25968;&#25454;&#38598;&#33976;&#39311;&#65288;LD3M&#65289;&#65292;&#32467;&#21512;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#25193;&#25955;&#21644;&#25968;&#25454;&#38598;&#33976;&#39311;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#19981;&#21516;&#27169;&#22411;&#26550;&#26500;&#23548;&#33268;&#20934;&#30830;&#24615;&#19979;&#38477;&#21644;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#20256;&#32479;&#19978;&#20381;&#36182;&#20110;&#36234;&#26469;&#36234;&#22823;&#30340;&#25968;&#25454;&#38598;&#30340;&#21487;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#22823;&#22411;&#25968;&#25454;&#38598;&#24102;&#26469;&#23384;&#20648;&#25361;&#25112;&#65292;&#24182;&#19988;&#21253;&#21547;&#19968;&#20123;&#38750;&#24433;&#21709;&#21147;&#26679;&#26412;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21487;&#20197;&#34987;&#24573;&#30053;&#32780;&#19981;&#24433;&#21709;&#27169;&#22411;&#26368;&#32456;&#30340;&#20934;&#30830;&#24615;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38480;&#21046;&#65292;&#20986;&#29616;&#20102;&#23558;&#25968;&#25454;&#38598;&#20449;&#24687;&#33976;&#39311;&#25104;&#19968;&#32452;&#21387;&#32553;&#26679;&#26412;&#65288;&#21512;&#25104;&#26679;&#26412;&#65289;&#65292;&#21363;&#33976;&#39311;&#25968;&#25454;&#38598;&#30340;&#27010;&#24565;&#12290;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#26041;&#38754;&#26159;&#36873;&#25321;&#29992;&#20110;&#36830;&#25509;&#21407;&#22987;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#26550;&#26500;&#65288;&#36890;&#24120;&#26159;ConvNet&#65289;&#12290;&#28982;&#32780;&#65292;&#22914;&#26524;&#25152;&#20351;&#29992;&#30340;&#27169;&#22411;&#26550;&#26500;&#19982;&#33976;&#39311;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;&#27169;&#22411;&#19981;&#21516;&#65292;&#21017;&#26368;&#32456;&#20934;&#30830;&#24615;&#20250;&#38477;&#20302;&#12290;&#21478;&#19968;&#20010;&#25361;&#25112;&#26159;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#65292;&#20363;&#22914;128x128&#21450;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03881v1 Announce Type: cross  Abstract: The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both chal
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31181;&#20351;&#29992;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#36827;&#34892;MRI&#22270;&#20687;&#20998;&#21106;&#30340;&#26032;&#26041;&#27861;&#65292;&#30456;&#27604;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#65292;&#26080;&#38656;&#22823;&#37327;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#25552;&#20379;&#26356;&#21487;&#35299;&#37322;&#21644;&#31283;&#23450;&#30340;&#20998;&#21106;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2401.01160</link><description>&lt;p&gt;
&#26080;&#38656;&#35757;&#32451;&#30340;MRI&#31435;&#26041;&#25345;&#32493;&#21516;&#35843;&#20998;&#21106;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Train-Free Segmentation in MRI with Cubical Persistent Homology. (arXiv:2401.01160v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01160
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31181;&#20351;&#29992;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#36827;&#34892;MRI&#22270;&#20687;&#20998;&#21106;&#30340;&#26032;&#26041;&#27861;&#65292;&#30456;&#27604;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#65292;&#26080;&#38656;&#22823;&#37327;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#25552;&#20379;&#26356;&#21487;&#35299;&#37322;&#21644;&#31283;&#23450;&#30340;&#20998;&#21106;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#26032;&#30340;MRI&#25195;&#25551;&#20998;&#21106;&#26041;&#27861;&#65292;&#20351;&#29992;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65288;TDA&#65289;&#65292;&#30456;&#27604;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#20960;&#20010;&#20248;&#28857;&#12290;&#23427;&#20998;&#20026;&#19977;&#20010;&#27493;&#39588;&#65292;&#39318;&#20808;&#36890;&#36807;&#33258;&#21160;&#38408;&#20540;&#30830;&#23450;&#35201;&#20998;&#21106;&#30340;&#25972;&#20010;&#23545;&#35937;&#65292;&#28982;&#21518;&#26816;&#27979;&#19968;&#20010;&#24050;&#30693;&#25299;&#25169;&#32467;&#26500;&#30340;&#29420;&#29305;&#23376;&#38598;&#65292;&#26368;&#21518;&#25512;&#23548;&#20986;&#20998;&#21106;&#30340;&#21508;&#20010;&#32452;&#25104;&#37096;&#20998;&#12290;&#34429;&#28982;&#35843;&#29992;&#20102;TDA&#30340;&#32463;&#20856;&#24605;&#24819;&#65292;&#20294;&#36825;&#26679;&#30340;&#31639;&#27861;&#20174;&#26410;&#19982;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20998;&#31163;&#25552;&#20986;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#38500;&#20102;&#32771;&#34385;&#22270;&#20687;&#30340;&#21516;&#35843;&#24615;&#22806;&#65292;&#36824;&#32771;&#34385;&#20102;&#20195;&#34920;&#24615;&#21608;&#26399;&#30340;&#23450;&#20301;&#65292;&#36825;&#26159;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20284;&#20046;&#20174;&#26410;&#34987;&#21033;&#29992;&#36807;&#30340;&#20449;&#24687;&#12290;&#29305;&#21035;&#26159;&#65292;&#23427;&#25552;&#20379;&#20102;&#26080;&#38656;&#22823;&#37327;&#27880;&#37322;&#25968;&#25454;&#38598;&#36827;&#34892;&#20998;&#21106;&#30340;&#33021;&#21147;&#12290;TDA&#36824;&#36890;&#36807;&#23558;&#25299;&#25169;&#29305;&#24449;&#26126;&#30830;&#26144;&#23556;&#21040;&#20998;&#21106;&#32452;&#20214;&#26469;&#25552;&#20379;&#26356;&#21487;&#35299;&#37322;&#21644;&#31283;&#23450;&#30340;&#20998;&#21106;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
We describe a new general method for segmentation in MRI scans using Topological Data Analysis (TDA), offering several advantages over traditional machine learning approaches. It works in three steps, first identifying the whole object to segment via automatic thresholding, then detecting a distinctive subset whose topology is known in advance, and finally deducing the various components of the segmentation. Although convoking classical ideas of TDA, such an algorithm has never been proposed separately from deep learning methods. To achieve this, our approach takes into account, in addition to the homology of the image, the localization of representative cycles, a piece of information that seems never to have been exploited in this context. In particular, it offers the ability to perform segmentation without the need for large annotated data sets. TDA also provides a more interpretable and stable framework for segmentation by explicitly mapping topological features to segmentation comp
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32852;&#37030;&#32959;&#30244;&#20998;&#21106;&#20013;&#33258;&#36866;&#24212;&#26435;&#37325;&#32858;&#21512;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#30456;&#20284;&#24615;&#26435;&#37325;&#32858;&#21512;&#26041;&#27861;&#65288;SimAgg&#65289;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#20998;&#21106;&#33021;&#21147;&#65292;&#24182;&#22312;&#20445;&#25252;&#38544;&#31169;&#26041;&#38754;&#20570;&#20986;&#20102;&#39069;&#22806;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2308.00856</link><description>&lt;p&gt;
&#38024;&#23545;&#32852;&#37030;&#32959;&#30244;&#20998;&#21106;&#20013;&#33258;&#36866;&#24212;&#26435;&#37325;&#32858;&#21512;&#30340;&#24046;&#20998;&#38544;&#31169;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation. (arXiv:2308.00856v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32852;&#37030;&#32959;&#30244;&#20998;&#21106;&#20013;&#33258;&#36866;&#24212;&#26435;&#37325;&#32858;&#21512;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#30456;&#20284;&#24615;&#26435;&#37325;&#32858;&#21512;&#26041;&#27861;&#65288;SimAgg&#65289;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#20998;&#21106;&#33021;&#21147;&#65292;&#24182;&#22312;&#20445;&#25252;&#38544;&#31169;&#26041;&#38754;&#20570;&#20986;&#20102;&#39069;&#22806;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#20844;&#27491;&#30340;&#20840;&#23616;&#27169;&#22411;&#26469;&#20445;&#25252;&#20010;&#20307;&#23458;&#25143;&#25968;&#25454;&#30340;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#22312;&#22788;&#29702;&#19981;&#21516;&#23458;&#25143;&#25968;&#25454;&#26102;&#21487;&#33021;&#24341;&#20837;&#23433;&#20840;&#39118;&#38505;&#65292;&#20174;&#32780;&#21487;&#33021;&#21361;&#21450;&#38544;&#31169;&#21644;&#25968;&#25454;&#23436;&#25972;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#32852;&#37030;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#21106;&#20013;&#25193;&#23637;&#20102;&#30456;&#20284;&#24615;&#26435;&#37325;&#32858;&#21512;&#26041;&#27861;&#65288;SimAgg&#65289;&#21040;DP-SimAgg&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#38024;&#23545;&#22810;&#27169;&#24577;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;MRI&#65289;&#20013;&#30340;&#33041;&#32959;&#30244;&#20998;&#21106;&#30340;&#24046;&#20998;&#38544;&#31169;&#30456;&#20284;&#24615;&#21152;&#26435;&#32858;&#21512;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;DP-SimAgg&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#20998;&#21106;&#33021;&#21147;&#65292;&#36824;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#38544;&#31169;&#20445;&#25252;&#23618;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#35780;&#20272;&#65292;&#20197;&#35745;&#31639;&#24615;&#33021;&#20026;&#20027;&#35201;&#32771;&#34385;&#22240;&#32032;&#65292;&#35777;&#26126;&#20102;DP-SimAgg&#20351;..
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a distributed machine learning approach that safeguards privacy by creating an impartial global model while respecting the privacy of individual client data. However, the conventional FL method can introduce security risks when dealing with diverse client data, potentially compromising privacy and data integrity. To address these challenges, we present a differential privacy (DP) federated deep learning framework in medical image segmentation. In this paper, we extend our similarity weight aggregation (SimAgg) method to DP-SimAgg algorithm, a differentially private similarity-weighted aggregation algorithm for brain tumor segmentation in multi-modal magnetic resonance imaging (MRI). Our DP-SimAgg method not only enhances model segmentation capabilities but also provides an additional layer of privacy preservation. Extensive benchmarking and evaluation of our framework, with computational performance as a key consideration, demonstrate that DP-SimAgg enables a
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#20110;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;(SNNs)&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#40065;&#26834;&#24615;&#21644;&#36716;&#31227;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25104;&#21151;&#30340;&#30333;&#30418;&#23545;&#25239;&#25915;&#20987;SNNs&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#26367;&#20195;&#26799;&#24230;&#25216;&#26415;&#65292;&#24182;&#19988;&#38750;SNN&#26550;&#26500;&#21019;&#24314;&#30340;&#23545;&#25239;&#26679;&#26412;&#24448;&#24448;&#19981;&#34987;SNNs&#35823;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2209.03358</link><description>&lt;p&gt;
&#25915;&#20987;&#33033;&#20914;&#65306;&#20851;&#20110;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#21487;&#36716;&#31227;&#24615;&#19982;&#23433;&#20840;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Attacking the Spike: On the Transferability and Security of Spiking Neural Networks to Adversarial Examples. (arXiv:2209.03358v3 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.03358
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#20110;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;(SNNs)&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#40065;&#26834;&#24615;&#21644;&#36716;&#31227;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25104;&#21151;&#30340;&#30333;&#30418;&#23545;&#25239;&#25915;&#20987;SNNs&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#26367;&#20195;&#26799;&#24230;&#25216;&#26415;&#65292;&#24182;&#19988;&#38750;SNN&#26550;&#26500;&#21019;&#24314;&#30340;&#23545;&#25239;&#26679;&#26412;&#24448;&#24448;&#19981;&#34987;SNNs&#35823;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;(SNNs)&#22240;&#20854;&#39640;&#33021;&#25928;&#21644;&#26368;&#36817;&#22312;&#20998;&#31867;&#24615;&#33021;&#19978;&#30340;&#36827;&#23637;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#19981;&#21516;&#65292;&#23545;SNNs&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#40065;&#26834;&#24615;&#30340;&#20998;&#26512;&#21644;&#30740;&#31350;&#20173;&#28982;&#30456;&#23545;&#19981;&#23436;&#21892;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#20110;&#25512;&#36827;SNNs&#30340;&#23545;&#25239;&#25915;&#20987;&#26041;&#38754;&#65292;&#24182;&#20570;&#20986;&#20102;&#19977;&#20010;&#20027;&#35201;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25104;&#21151;&#30340;&#30333;&#30418;&#23545;&#25239;&#25915;&#20987;SNNs&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#24213;&#23618;&#30340;&#26367;&#20195;&#26799;&#24230;&#25216;&#26415;&#65292;&#21363;&#20351;&#22312;&#23545;&#25239;&#24615;&#35757;&#32451;SNNs&#30340;&#24773;&#20917;&#19979;&#20063;&#19968;&#26679;&#12290;&#20854;&#27425;&#65292;&#21033;&#29992;&#26368;&#20339;&#30340;&#26367;&#20195;&#26799;&#24230;&#25216;&#26415;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#23545;&#25239;&#25915;&#20987;&#22312;SNNs&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26550;&#26500;&#22914;Vision Transformers(ViTs)&#21644;Big Transfer Convolutional Neural Networks(CNNs)&#20043;&#38388;&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#38750;SNN&#26550;&#26500;&#21019;&#24314;&#30340;&#23545;&#25239;&#26679;&#26412;&#24448;&#24448;&#19981;&#34987;SNNs&#35823;&#20998;&#31867;&#12290;&#31532;&#19977;&#65292;&#30001;&#20110;&#32570;&#20047;&#19968;&#20010;&#20849;&#24615;
&lt;/p&gt;
&lt;p&gt;
Spiking neural networks (SNNs) have attracted much attention for their high energy efficiency and for recent advances in their classification performance. However, unlike traditional deep learning approaches, the analysis and study of the robustness of SNNs to adversarial examples remain relatively underdeveloped. In this work, we focus on advancing the adversarial attack side of SNNs and make three major contributions. First, we show that successful white-box adversarial attacks on SNNs are highly dependent on the underlying surrogate gradient technique, even in the case of adversarially trained SNNs. Second, using the best surrogate gradient technique, we analyze the transferability of adversarial attacks on SNNs and other state-of-the-art architectures like Vision Transformers (ViTs) and Big Transfer Convolutional Neural Networks (CNNs). We demonstrate that the adversarial examples created by non-SNN architectures are not misclassified often by SNNs. Third, due to the lack of an ubi
&lt;/p&gt;</description></item></channel></rss>