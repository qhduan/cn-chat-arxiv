<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#30740;&#31350;&#30830;&#23450;&#20102;&#22312;&#28508;&#22312;&#38468;&#21152;&#22122;&#22768;&#27169;&#22411;&#32972;&#26223;&#19979;&#23548;&#33268;&#21487;&#35782;&#21035;&#24615;&#30340;&#20998;&#24067;&#21464;&#21270;&#31867;&#22411;&#30340;&#20805;&#20998;&#19988;&#24517;&#35201;&#26465;&#20214;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#24403;&#21482;&#26377;&#37096;&#20998;&#20998;&#24067;&#21464;&#21270;&#28385;&#36275;&#26465;&#20214;&#26102;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.15711</link><description>&lt;p&gt;
&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#31070;&#32463;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Identifiable Latent Neural Causal Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15711
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#30830;&#23450;&#20102;&#22312;&#28508;&#22312;&#38468;&#21152;&#22122;&#22768;&#27169;&#22411;&#32972;&#26223;&#19979;&#23548;&#33268;&#21487;&#35782;&#21035;&#24615;&#30340;&#20998;&#24067;&#21464;&#21270;&#31867;&#22411;&#30340;&#20805;&#20998;&#19988;&#24517;&#35201;&#26465;&#20214;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#24403;&#21482;&#26377;&#37096;&#20998;&#20998;&#24067;&#21464;&#21270;&#28385;&#36275;&#26465;&#20214;&#26102;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#24449;&#23398;&#20064;&#26088;&#22312;&#20174;&#20302;&#32423;&#35266;&#27979;&#25968;&#25454;&#20013;&#25581;&#31034;&#28508;&#22312;&#30340;&#39640;&#32423;&#22240;&#26524;&#34920;&#24449;&#12290;&#23427;&#29305;&#21035;&#25797;&#38271;&#39044;&#27979;&#22312;&#26410;&#35265;&#20998;&#24067;&#21464;&#21270;&#19979;&#65292;&#22240;&#20026;&#36825;&#20123;&#21464;&#21270;&#36890;&#24120;&#21487;&#20197;&#35299;&#37322;&#20026;&#24178;&#39044;&#30340;&#21518;&#26524;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;{&#24050;&#35265;}&#20998;&#24067;&#21464;&#21270;&#25104;&#20026;&#24110;&#21161;&#35782;&#21035;&#22240;&#26524;&#34920;&#24449;&#30340;&#33258;&#28982;&#31574;&#30053;&#65292;&#36827;&#32780;&#26377;&#21161;&#20110;&#39044;&#27979;&#20197;&#21069;{&#26410;&#35265;}&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#30830;&#23450;&#36825;&#20123;&#20998;&#24067;&#21464;&#21270;&#30340;&#31867;&#22411;&#65288;&#25110;&#26465;&#20214;&#65289;&#23545;&#20110;&#22240;&#26524;&#34920;&#24449;&#30340;&#21487;&#35782;&#21035;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#35813;&#24037;&#20316;&#24314;&#31435;&#20102;&#22312;&#28508;&#22312;&#38468;&#21152;&#22122;&#22768;&#27169;&#22411;&#32972;&#26223;&#19979;&#65292;&#34920;&#24449;&#23548;&#33268;&#21487;&#35782;&#21035;&#24615;&#30340;&#20998;&#24067;&#21464;&#21270;&#31867;&#22411;&#30340;&#20805;&#20998;&#19988;&#24517;&#35201;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24403;&#21482;&#26377;&#37096;&#20998;&#20998;&#24067;&#21464;&#21270;&#28385;&#36275;&#26465;&#20214;&#26102;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15711v1 Announce Type: new  Abstract: Causal representation learning seeks to uncover latent, high-level causal representations from low-level observed data. It is particularly good at predictions under unseen distribution shifts, because these shifts can generally be interpreted as consequences of interventions. Hence leveraging {seen} distribution shifts becomes a natural strategy to help identifying causal representations, which in turn benefits predictions where distributions are previously {unseen}. Determining the types (or conditions) of such distribution shifts that do contribute to the identifiability of causal representations is critical. This work establishes a {sufficient} and {necessary} condition characterizing the types of distribution shifts for identifiability in the context of latent additive noise models. Furthermore, we present partial identifiability results when only a portion of distribution shifts meets the condition. In addition, we extend our findin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#21457;&#29616;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#23545;&#19979;&#28216;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.04177</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#23610;&#24230;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Downstream Task Performance of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#21457;&#29616;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#23545;&#19979;&#28216;&#24615;&#33021;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23610;&#24230;&#24459;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#35265;&#35299;&#65292;&#21487;&#20197;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35774;&#35745;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#30740;&#31350;&#39044;&#35757;&#32451;&#65288;&#19978;&#28216;&#65289;&#25439;&#22833;&#30340;&#23610;&#24230;&#24459;&#12290;&#28982;&#32780;&#65292;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#65292;LLM&#20808;&#22312;&#26080;&#30417;&#30563;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#19979;&#28216;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#25105;&#20204;&#36890;&#24120;&#20063;&#20851;&#24515;&#19979;&#28216;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#23610;&#24230;&#34892;&#20026;&#65292;&#20854;&#20013;LLM&#34987;&#24494;&#35843;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;&#36873;&#25321;&#21644;&#22823;&#23567;&#23545;&#19979;&#28216;&#24615;&#33021;&#65288;&#32763;&#35793;&#36136;&#37327;&#65289;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#20004;&#20010;&#35780;&#20215;&#25351;&#26631;&#65306;&#19979;&#28216;&#20132;&#21449;&#29109;&#21644;BLEU&#20998;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#24494;&#35843;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#19982;&#19979;&#28216;&#25968;&#25454;&#30340;&#20998;&#24067;&#19968;&#33268;&#24615;&#26174;&#33879;&#24433;&#21709;&#23610;&#24230;&#34892;&#20026;&#12290;&#22312;&#20805;&#20998;&#19968;&#33268;&#24615;&#24773;&#20917;&#19979;&#65292;&#19979;&#28216;&#20132;&#21449;&#29109;&#21644;BLEU&#20998;&#25968;&#37117;&#20250;&#36880;&#28176;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scaling laws provide important insights that can guide the design of large language models (LLMs). Existing work has primarily focused on studying scaling laws for pretraining (upstream) loss. However, in transfer learning settings, in which LLMs are pretrained on an unsupervised dataset and then finetuned on a downstream task, we often also care about the downstream performance. In this work, we study the scaling behavior in a transfer learning setting, where LLMs are finetuned for machine translation tasks. Specifically, we investigate how the choice of the pretraining data and its size affect downstream performance (translation quality) as judged by two metrics: downstream cross-entropy and BLEU score. Our experiments indicate that the size of the finetuning dataset and the distribution alignment between the pretraining and downstream data significantly influence the scaling behavior. With sufficient alignment, both downstream cross-entropy and BLEU score improve monotonically with 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20844;&#24179;GNN&#30340;&#23545;&#25239;&#24615;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#20844;&#24179;GNN&#30340;&#20551;&#35774;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#27492;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01591</link><description>&lt;p&gt;
&#26356;&#22909;&#30340;&#20844;&#24179;&#24615;&#32988;&#20110;&#36951;&#25022;&#65306;&#38024;&#23545;&#20844;&#24179;GNN&#30340;&#23545;&#25239;&#24615;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;
&lt;/p&gt;
&lt;p&gt;
Better Fair than Sorry: Adversarial Missing Data Imputation for Fair GNNs. (arXiv:2311.01591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01591
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20844;&#24179;GNN&#30340;&#23545;&#25239;&#24615;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#20844;&#24179;GNN&#30340;&#20551;&#35774;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#27492;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#32570;&#22833;&#20445;&#25252;&#23646;&#24615;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20844;&#24179;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#35768;&#22810;&#30456;&#20851;&#20219;&#21153;&#20013;&#65292;&#20915;&#31574;&#21487;&#33021;&#20250;&#23545;&#29305;&#23450;&#31038;&#21306;&#20135;&#29983;&#19981;&#25104;&#27604;&#20363;&#30340;&#24433;&#21709;&#65292;&#32780;GNNs&#24050;&#32463;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20844;&#24179;GNNs&#24037;&#20316;&#35201;&#20040;&#20551;&#35774;&#20445;&#25252;&#23646;&#24615;&#26159;&#23436;&#20840;&#34987;&#35266;&#23519;&#21040;&#30340;&#65292;&#35201;&#20040;&#20551;&#35774;&#32570;&#22833;&#25968;&#25454;&#30340;&#22635;&#20805;&#26159;&#20844;&#24179;&#30340;&#12290;&#23454;&#38469;&#19978;&#65292;&#22635;&#20805;&#20013;&#30340;&#20559;&#24046;&#20250;&#20256;&#25773;&#21040;&#27169;&#22411;&#30340;&#32467;&#26524;&#20013;&#65292;&#23548;&#33268;&#23427;&#20204;&#36807;&#39640;&#22320;&#20272;&#35745;&#20102;&#20854;&#39044;&#27979;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;Better Fair than Sorry&#65288;BFtS&#65289;&#65292;&#20026;&#20844;&#24179;GNNs&#20351;&#29992;&#30340;&#20445;&#25252;&#23646;&#24615;&#30340;&#20844;&#24179;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;BFtS&#32972;&#21518;&#30340;&#20851;&#38190;&#35774;&#35745;&#21407;&#21017;&#26159;&#22635;&#20805;&#24212;&#35813;&#36817;&#20284;&#20110;&#20844;&#24179;GNN&#30340;&#26368;&#22256;&#38590;&#24773;&#20917;&#65292;&#21363;&#22312;&#26368;&#20248;&#21270;&#20844;&#24179;&#24615;&#26368;&#22256;&#38590;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#19977;&#26041;&#23545;&#25239;&#26041;&#26696;&#26469;&#23454;&#29616;&#36825;&#20010;&#24819;&#27861;&#65292;&#22312;&#36825;&#20010;&#26041;&#26696;&#20013;&#65292;&#20004;&#20010;&#23545;&#25163;&#20849;&#21516;&#23545;&#25239;&#20844;&#24179;GNN&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;BFtS&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the problem of learning fair Graph Neural Networks (GNNs) under missing protected attributes. GNNs have achieved state-of-the-art results in many relevant tasks where decisions might disproportionately impact specific communities. However, existing work on fair GNNs assumes that either protected attributes are fully-observed or that the missing data imputation is fair. In practice, biases in the imputation will be propagated to the model outcomes, leading them to overestimate the fairness of their predictions. We address this challenge by proposing Better Fair than Sorry (BFtS), a fair missing data imputation model for protected attributes used by fair GNNs. The key design principle behind BFtS is that imputations should approximate the worst-case scenario for the fair GNN -- i.e. when optimizing fairness is the hardest. We implement this idea using a 3-player adversarial scheme where two adversaries collaborate against the fair GNN. Experiments using synthetic and
&lt;/p&gt;</description></item><item><title>E2Net&#26159;&#19968;&#31181;&#36164;&#28304;&#39640;&#25928;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26680;&#24515;&#23376;&#32593;&#33976;&#39311;&#21644;&#31934;&#30830;&#30340;&#22238;&#25918;&#26679;&#26412;&#36873;&#25321;&#65292;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#21644;&#36739;&#23567;&#30340;&#36951;&#24536;&#65292;&#22312;&#30456;&#21516;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#38480;&#21046;&#19979;&#26368;&#22823;&#31243;&#24230;&#22320;&#20943;&#23569;&#20102;&#22788;&#29702;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2309.16117</link><description>&lt;p&gt;
E2Net: &#24377;&#24615;&#25193;&#23637;&#32593;&#32476;&#23454;&#29616;&#36164;&#28304;&#39640;&#25928;&#30340;&#25345;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
E2Net: Resource-Efficient Continual Learning with Elastic Expansion Network. (arXiv:2309.16117v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16117
&lt;/p&gt;
&lt;p&gt;
E2Net&#26159;&#19968;&#31181;&#36164;&#28304;&#39640;&#25928;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26680;&#24515;&#23376;&#32593;&#33976;&#39311;&#21644;&#31934;&#30830;&#30340;&#22238;&#25918;&#26679;&#26412;&#36873;&#25321;&#65292;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#21644;&#36739;&#23567;&#30340;&#36951;&#24536;&#65292;&#22312;&#30456;&#21516;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#38480;&#21046;&#19979;&#26368;&#22823;&#31243;&#24230;&#22320;&#20943;&#23569;&#20102;&#22788;&#29702;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#26088;&#22312;&#23398;&#20064;&#26032;&#20219;&#21153;&#32780;&#19981;&#28040;&#38500;&#20197;&#21069;&#30340;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#25345;&#32493;&#23398;&#20064;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#35745;&#31639;&#33021;&#21147;&#21644;&#23384;&#20648;&#23481;&#37327;&#25165;&#33021;&#36798;&#21040;&#20196;&#20154;&#28385;&#24847;&#30340;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36164;&#28304;&#39640;&#25928;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;&#24377;&#24615;&#25193;&#23637;&#32593;&#32476;&#65288;E2Net&#65289;&#12290;&#36890;&#36807;&#26680;&#24515;&#23376;&#32593;&#33976;&#39311;&#21644;&#31934;&#30830;&#30340;&#22238;&#25918;&#26679;&#26412;&#36873;&#25321;&#65292;E2Net&#22312;&#30456;&#21516;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#38480;&#21046;&#19979;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#24179;&#22343;&#20934;&#30830;&#24615;&#21644;&#36739;&#23567;&#30340;&#36951;&#24536;&#65292;&#24182;&#26368;&#22823;&#31243;&#24230;&#22320;&#20943;&#23569;&#20102;&#22788;&#29702;&#26102;&#38388;&#12290;&#22312;E2Net&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20195;&#34920;&#24615;&#32593;&#32476;&#33976;&#39311;&#65292;&#36890;&#36807;&#35780;&#20272;&#21442;&#25968;&#25968;&#37327;&#21644;&#19982;&#24037;&#20316;&#32593;&#32476;&#30340;&#36755;&#20986;&#30456;&#20284;&#24615;&#26469;&#35782;&#21035;&#20195;&#34920;&#24615;&#30340;&#26680;&#24515;&#23376;&#32593;&#65292;&#33976;&#39311;&#24037;&#20316;&#32593;&#32476;&#20869;&#30340;&#31867;&#20284;&#23376;&#32593;&#20197;&#20943;&#36731;&#23545;&#37325;&#28436;&#32531;&#20914;&#21306;&#30340;&#20381;&#36182;&#65292;&#24182;&#20419;&#36827;&#36328;&#20808;&#21069;&#20219;&#21153;&#30340;&#30693;&#35782;&#36716;&#31227;&#12290;&#20026;&#20102;&#25552;&#39640;&#23384;&#20648;&#36164;&#28304;&#21033;&#29992;&#29575;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#23376;&#32593;&#32422;&#26463;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Continual Learning methods are designed to learn new tasks without erasing previous knowledge. However, Continual Learning often requires massive computational power and storage capacity for satisfactory performance. In this paper, we propose a resource-efficient continual learning method called the Elastic Expansion Network (E2Net). Leveraging core subnet distillation and precise replay sample selection, E2Net achieves superior average accuracy and diminished forgetting within the same computational and storage constraints, all while minimizing processing time. In E2Net, we propose Representative Network Distillation to identify the representative core subnet by assessing parameter quantity and output similarity with the working network, distilling analogous subnets within the working network to mitigate reliance on rehearsal buffers and facilitating knowledge transfer across previous tasks. To enhance storage resource utilization, we then propose Subnet Constraint Experience Replay t
&lt;/p&gt;</description></item><item><title>&#24191;&#20041;&#39640;&#36895;&#20844;&#36335;&#32593;&#32476;&#32467;&#26500;&#22312;&#26399;&#26435;&#23450;&#20215;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#26356;&#30701;&#30340;&#35757;&#32451;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2307.07657</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#26399;&#26435;&#23450;&#20215;&#65306;&#23545;&#32593;&#32476;&#32467;&#26500;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Machine learning for option pricing: an empirical investigation of network architectures. (arXiv:2307.07657v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07657
&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#39640;&#36895;&#20844;&#36335;&#32593;&#32476;&#32467;&#26500;&#22312;&#26399;&#26435;&#23450;&#20215;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#26356;&#30701;&#30340;&#35757;&#32451;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20351;&#29992;&#36866;&#24403;&#30340;&#36755;&#20837;&#25968;&#25454;&#65288;&#27169;&#22411;&#21442;&#25968;&#65289;&#21644;&#30456;&#24212;&#36755;&#20986;&#25968;&#25454;&#65288;&#26399;&#26435;&#20215;&#26684;&#25110;&#38544;&#21547;&#27874;&#21160;&#29575;&#65289;&#26469;&#23398;&#20064;&#26399;&#26435;&#20215;&#26684;&#25110;&#38544;&#21547;&#27874;&#21160;&#29575;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#12290;&#22823;&#37096;&#20998;&#30456;&#20851;&#25991;&#29486;&#37117;&#20351;&#29992;&#65288;&#26222;&#36890;&#30340;&#65289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#26469;&#36830;&#25509;&#29992;&#20110;&#23398;&#20064;&#23558;&#36755;&#20837;&#26144;&#23556;&#21040;&#36755;&#20986;&#30340;&#31070;&#32463;&#20803;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#21463;&#21040;&#22270;&#20687;&#20998;&#31867;&#26041;&#27861;&#21644;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#26469;&#25506;&#31350;&#32593;&#32476;&#32467;&#26500;&#30340;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#31934;&#30830;&#24230;&#21644;&#35757;&#32451;&#26102;&#38388;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#26399;&#26435;&#23450;&#20215;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;Black-Scholes&#21644;Heston&#27169;&#22411;&#65292;&#24191;&#20041;&#39640;&#36895;&#20844;&#36335;&#32593;&#32476;&#32467;&#26500;&#30456;&#36739;&#20110;&#20854;&#20182;&#21464;&#20307;&#22312;&#22343;&#26041;&#35823;&#24046;&#21644;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#12290;&#27492;&#22806;&#65292;&#22312;&#35745;&#31639;&#38544;&#21547;&#27874;&#21160;&#29575;&#26041;&#38754;&#65292;
&lt;/p&gt;
&lt;p&gt;
We consider the supervised learning problem of learning the price of an option or the implied volatility given appropriate input data (model parameters) and corresponding output data (option prices or implied volatilities). The majority of articles in this literature considers a (plain) feed forward neural network architecture in order to connect the neurons used for learning the function mapping inputs to outputs. In this article, motivated by methods in image classification and recent advances in machine learning methods for PDEs, we investigate empirically whether and how the choice of network architecture affects the accuracy and training time of a machine learning algorithm. We find that for option pricing problems, where we focus on the Black--Scholes and the Heston model, the generalized highway network architecture outperforms all other variants, when considering the mean squared error and the training time as criteria. Moreover, for the computation of the implied volatility, a
&lt;/p&gt;</description></item></channel></rss>