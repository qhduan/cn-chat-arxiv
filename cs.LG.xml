<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#35302;&#35273;&#21453;&#39304;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#39063;&#31890;&#20171;&#36136;&#20013;&#26816;&#32034;&#22475;&#34255;&#30340;&#29289;&#20307;&#12290;&#36890;&#36807;&#27169;&#25311;&#20256;&#24863;&#22120;&#22122;&#22768;&#36827;&#34892;&#31471;&#21040;&#31471;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#33258;&#28982;&#20986;&#29616;&#30340;&#23398;&#20064;&#25512;&#21160;&#34892;&#20026;&#65292;&#24182;&#25104;&#21151;&#23558;&#20854;&#36801;&#31227;&#21040;&#23454;&#38469;&#30828;&#20214;&#19978;&#12290;</title><link>https://arxiv.org/abs/2402.04536</link><description>&lt;p&gt;
&#22522;&#20110;&#35302;&#35273;&#30340;&#20174;&#39063;&#31890;&#20171;&#36136;&#20013;&#26816;&#32034;&#29289;&#20307;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Tactile-based Object Retrieval From Granular Media
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04536
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#35302;&#35273;&#21453;&#39304;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#39063;&#31890;&#20171;&#36136;&#20013;&#26816;&#32034;&#22475;&#34255;&#30340;&#29289;&#20307;&#12290;&#36890;&#36807;&#27169;&#25311;&#20256;&#24863;&#22120;&#22122;&#22768;&#36827;&#34892;&#31471;&#21040;&#31471;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#33258;&#28982;&#20986;&#29616;&#30340;&#23398;&#20064;&#25512;&#21160;&#34892;&#20026;&#65292;&#24182;&#25104;&#21151;&#23558;&#20854;&#36801;&#31227;&#21040;&#23454;&#38469;&#30828;&#20214;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GEOTACT&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#39063;&#31890;&#20171;&#36136;&#20013;&#26816;&#32034;&#22475;&#34255;&#30340;&#29289;&#20307;&#12290;&#36825;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#38656;&#35201;&#19982;&#39063;&#31890;&#20171;&#36136;&#36827;&#34892;&#20132;&#20114;&#65292;&#24182;&#19988;&#20165;&#20381;&#38752;&#35302;&#35273;&#21453;&#39304;&#26469;&#23436;&#25104;&#65292;&#22240;&#20026;&#19968;&#20010;&#22475;&#34255;&#30340;&#29289;&#20307;&#21487;&#33021;&#23436;&#20840;&#34987;&#35270;&#35273;&#38544;&#34255;&#12290;&#22312;&#36825;&#31181;&#29615;&#22659;&#20013;&#65292;&#35302;&#35273;&#21453;&#39304;&#26412;&#36523;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#38656;&#35201;&#19982;&#21608;&#22260;&#20171;&#36136;&#36827;&#34892;&#26222;&#36941;&#25509;&#35302;&#65292;&#24182;&#19988;&#30001;&#35302;&#35273;&#35835;&#25968;&#24341;&#36215;&#30340;&#22266;&#26377;&#22122;&#22768;&#27700;&#24179;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#25311;&#20256;&#24863;&#22120;&#22122;&#22768;&#36827;&#34892;&#31471;&#21040;&#31471;&#35757;&#32451;&#30340;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#38382;&#39064;&#34920;&#36848;&#23548;&#33268;&#20102;&#23398;&#20064;&#25512;&#21160;&#34892;&#20026;&#30340;&#33258;&#28982;&#20986;&#29616;&#65292;&#25805;&#20316;&#22120;&#20351;&#29992;&#36825;&#20123;&#34892;&#20026;&#26469;&#20943;&#23569;&#19981;&#30830;&#23450;&#24615;&#24182;&#23558;&#29289;&#20307;&#24341;&#23548;&#21040;&#31283;&#23450;&#30340;&#25235;&#21462;&#20301;&#32622;&#65292;&#23613;&#31649;&#23384;&#22312;&#20551;&#30340;&#21644;&#22122;&#22768;&#30340;&#35302;&#35273;&#35835;&#25968;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#22521;&#35757;&#26041;&#26696;&#65292;&#21487;&#20197;&#22312;&#20223;&#30495;&#20013;&#23398;&#20064;&#36825;&#20123;&#34892;&#20026;&#65292;&#24182;&#22312;&#23454;&#38469;&#30828;&#20214;&#19978;&#36827;&#34892;&#38646;&#26679;&#26412;&#36801;&#31227;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;GEOTACT&#26159;&#31532;&#19968;&#20010;&#36825;&#26679;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce GEOTACT, a robotic manipulation method capable of retrieving objects buried in granular media. This is a challenging task due to the need to interact with granular media, and doing so based exclusively on tactile feedback, since a buried object can be completely hidden from vision. Tactile feedback is in itself challenging in this context, due to ubiquitous contact with the surrounding media, and the inherent noise level induced by the tactile readings. To address these challenges, we use a learning method trained end-to-end with simulated sensor noise. We show that our problem formulation leads to the natural emergence of learned pushing behaviors that the manipulator uses to reduce uncertainty and funnel the object to a stable grasp despite spurious and noisy tactile readings. We also introduce a training curriculum that enables learning these behaviors in simulation, followed by zero-shot transfer to real hardware. To the best of our knowledge, GEOTACT is the first meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2212.04382</link><description>&lt;p&gt;
&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#65306;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.04382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#35770;&#22522;&#20110;&#27169;&#22411;&#12289;&#35757;&#32451;&#25968;&#25454;&#36824;&#26159;&#20108;&#32773;&#32452;&#21512;&#65292;&#20998;&#31867;&#22120;&#23558;&#65288;&#21487;&#33021;&#22797;&#26434;&#30340;&#65289;&#36755;&#20837;&#25968;&#25454;&#24402;&#20837;&#30456;&#23545;&#36739;&#23569;&#30340;&#36755;&#20986;&#31867;&#21035;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#22312;&#36755;&#20837;&#31354;&#38388;&#20026;&#22270;&#30340;&#24773;&#20917;&#19979;&#65292;&#36793;&#30028;&#30340;&#32467;&#26500;&#8212;&#8212;&#37027;&#20123;&#34987;&#20998;&#31867;&#20026;&#19981;&#21516;&#31867;&#21035;&#30340;&#37051;&#36817;&#28857;&#8212;&#8212;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#30340;&#31185;&#23398;&#32972;&#26223;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#30001;&#19979;&#19968;&#20195;&#27979;&#24207;&#20202;&#29983;&#25104;&#30340;DNA&#35835;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36793;&#30028;&#26082;&#26159;&#24040;&#22823;&#30340;&#65292;&#21448;&#20855;&#26377;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#23427;&#23558;&#19968;&#20010;&#28857;&#30340;&#32467;&#26524;&#19982;&#20854;&#37051;&#23621;&#30340;&#32467;&#26524;&#20998;&#24067;&#36827;&#34892;&#27604;&#36739;&#12290;&#36825;&#20010;&#24230;&#37327;&#19981;&#20165;&#36861;&#36394;&#20102;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#20004;&#20010;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#36824;&#21487;&#20197;&#22312;&#27809;&#26377;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#30340;&#20998;&#31867;&#22120;&#19978;&#23454;&#29616;&#65292;&#20294;&#38656;&#35201;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether based on models, training data or a combination, classifiers place (possibly complex) input data into one of a relatively small number of output categories. In this paper, we study the structure of the boundary--those points for which a neighbor is classified differently--in the context of an input space that is a graph, so that there is a concept of neighboring inputs, The scientific setting is a model-based naive Bayes classifier for DNA reads produced by Next Generation Sequencers. We show that the boundary is both large and complicated in structure. We create a new measure of uncertainty, called Neighbor Similarity, that compares the result for a point to the distribution of results for its neighbors. This measure not only tracks two inherent uncertainty measures for the Bayes classifier, but also can be implemented, at a computational cost, for classifiers without inherent measures of uncertainty.
&lt;/p&gt;</description></item><item><title>FLex&amp;Chill &#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Logit Chilling&#26041;&#27861;&#25913;&#36827;&#26412;&#22320;&#32852;&#21512;&#23398;&#20064;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21152;&#24555;&#27169;&#22411;&#25910;&#25947;&#24182;&#25552;&#39640;&#25512;&#29702;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.09986</link><description>&lt;p&gt;
FLex&amp;Chill&#65306;&#36890;&#36807;Logit Chilling&#25913;&#36827;&#26412;&#22320;&#32852;&#21512;&#23398;&#20064;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
FLex&amp;Chill: Improving Local Federated Learning Training with Logit Chilling. (arXiv:2401.09986v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09986
&lt;/p&gt;
&lt;p&gt;
FLex&amp;Chill &#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Logit Chilling&#26041;&#27861;&#25913;&#36827;&#26412;&#22320;&#32852;&#21512;&#23398;&#20064;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21152;&#24555;&#27169;&#22411;&#25910;&#25947;&#24182;&#25552;&#39640;&#25512;&#29702;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#21512;&#23398;&#20064;&#30001;&#20110;&#26412;&#22320;&#23458;&#25143;&#31471;&#30340;&#38750;iid&#20998;&#24067;&#24335;&#35757;&#32451;&#25968;&#25454;&#32780;&#21463;&#21040;&#25968;&#25454;&#24322;&#36136;&#24615;&#30340;&#38459;&#30861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#21512;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;FLex&amp;Chill&#65292;&#21033;&#29992;&#20102;Logit Chilling&#26041;&#27861;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#32852;&#21512;&#23398;&#20064;&#31995;&#32479;&#20013;&#22266;&#26377;&#30340;&#38750;iid&#25968;&#25454;&#29305;&#24449;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#21152;&#24555;&#27169;&#22411;&#25910;&#25947;&#24182;&#25552;&#39640;&#25512;&#29702;&#31934;&#24230;&#12290;&#20174;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20840;&#23616;&#32852;&#21512;&#23398;&#20064;&#27169;&#22411;&#25910;&#25947;&#26102;&#38388;&#25552;&#39640;&#20102;6&#20493;&#65292;&#25512;&#29702;&#31934;&#24230;&#25552;&#39640;&#20102;3.37%&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning are inherently hampered by data heterogeneity: non-iid distributed training data over local clients. We propose a novel model training approach for federated learning, FLex&amp;Chill, which exploits the Logit Chilling method. Through extensive evaluations, we demonstrate that, in the presence of non-iid data characteristics inherent in federated learning systems, this approach can expedite model convergence and improve inference accuracy. Quantitatively, from our experiments, we observe up to 6X improvement in the global federated learning model convergence time, and up to 3.37% improvement in inference accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#19982;&#20998;&#24067;&#27010;&#25324;&#30340;&#26032;&#36830;&#25509;&#65292;&#35299;&#20915;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05805</link><description>&lt;p&gt;
&#25552;&#21319;&#25511;&#21046;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Boosted Control Functions. (arXiv:2310.05805v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#19982;&#20998;&#24067;&#27010;&#25324;&#30340;&#26032;&#36830;&#25509;&#65292;&#35299;&#20915;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#20026;&#20174;&#22823;&#37327;&#30340;&#21327;&#21464;&#37327;&#20013;&#20934;&#30830;&#39044;&#27979;&#30446;&#26631;&#25968;&#37327;&#25171;&#24320;&#20102;&#22823;&#38376;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#27979;&#26041;&#27861;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#19981;&#20339;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#38544;&#34255;&#28151;&#28102;&#30340;&#24773;&#20917;&#19979;&#12290;&#34429;&#28982;&#23545;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65288;&#20363;&#22914;&#20202;&#22120;&#21464;&#37327;&#65289;&#24050;&#32463;&#23545;&#38544;&#34255;&#28151;&#28102;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#39044;&#27979;&#20219;&#21153;&#26469;&#35828;&#24182;&#38750;&#22914;&#27492;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#35299;&#20915;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#30340;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#20998;&#24067;&#27010;&#25324;&#39046;&#22495;&#65292;&#20197;&#21450;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#30340;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#30340;&#26680;&#24515;&#26159;&#25551;&#36848;&#22312;&#19968;&#32452;&#20998;&#24067;&#36716;&#21464;&#19979;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#20998;&#24067;&#27010;&#25324;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#65288;SIMDGs&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning methods and the availability of large-scale data opened the door to accurately predict target quantities from large sets of covariates. However, existing prediction methods can perform poorly when the training and testing data are different, especially in the presence of hidden confounding. While hidden confounding is well studied for causal effect estimation (e.g., instrumental variables), this is not the case for prediction tasks. This work aims to bridge this gap by addressing predictions under different training and testing distributions in the presence of unobserved confounding. In particular, we establish a novel connection between the field of distribution generalization from machine learning, and simultaneous equation models and control function from econometrics. Central to our contribution are simultaneous equation models for distribution generalization (SIMDGs) which describe the data-generating process under a set of distributional shifts. Within thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#20844;&#21496;&#30408;&#21033;&#65292;&#20294;&#21516;&#26679;&#23384;&#22312;&#36807;&#24230;&#21453;&#24212;&#30340;&#38382;&#39064;&#65292;&#32780;&#20256;&#32479;&#22521;&#35757;&#30340;&#32929;&#24066;&#20998;&#26512;&#24072;&#21644;&#32463;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22521;&#35757;&#30340;&#20998;&#26512;&#24072;&#30456;&#27604;&#20250;&#20135;&#29983;&#36739;&#23569;&#30340;&#36807;&#24230;&#21453;&#24212;&#12290;</title><link>http://arxiv.org/abs/2303.16158</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20934;&#30830;&#39044;&#27979;&#36130;&#25253;&#65292;&#20294;&#21516;&#26679;&#23384;&#22312;&#36807;&#24230;&#21453;&#24212;
&lt;/p&gt;
&lt;p&gt;
Behavioral Machine Learning? Computer Predictions of Corporate Earnings also Overreact. (arXiv:2303.16158v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#20844;&#21496;&#30408;&#21033;&#65292;&#20294;&#21516;&#26679;&#23384;&#22312;&#36807;&#24230;&#21453;&#24212;&#30340;&#38382;&#39064;&#65292;&#32780;&#20256;&#32479;&#22521;&#35757;&#30340;&#32929;&#24066;&#20998;&#26512;&#24072;&#21644;&#32463;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22521;&#35757;&#30340;&#20998;&#26512;&#24072;&#30456;&#27604;&#20250;&#20135;&#29983;&#36739;&#23569;&#30340;&#36807;&#24230;&#21453;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#37327;&#35777;&#25454;&#34920;&#26126;&#65292;&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#39044;&#27979;&#33021;&#21147;&#27604;&#20154;&#31867;&#26356;&#20026;&#20934;&#30830;&#12290;&#20294;&#26159;&#65292;&#25991;&#29486;&#24182;&#26410;&#27979;&#35797;&#31639;&#27861;&#39044;&#27979;&#26159;&#21542;&#26356;&#20026;&#29702;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20960;&#20010;&#31639;&#27861;&#65288;&#21253;&#25324;&#32447;&#24615;&#22238;&#24402;&#21644;&#19968;&#31181;&#21517;&#20026;Gradient Boosted Regression Trees&#30340;&#27969;&#34892;&#31639;&#27861;&#65289;&#23545;&#20110;&#20844;&#21496;&#30408;&#21033;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#32467;&#26524;&#21457;&#29616;&#65292;GBRT&#24179;&#22343;&#32988;&#36807;&#32447;&#24615;&#22238;&#24402;&#21644;&#20154;&#31867;&#32929;&#24066;&#20998;&#26512;&#24072;&#65292;&#20294;&#20173;&#23384;&#22312;&#36807;&#24230;&#21453;&#24212;&#19988;&#26080;&#27861;&#28385;&#36275;&#29702;&#24615;&#39044;&#26399;&#26631;&#20934;&#12290;&#36890;&#36807;&#38477;&#20302;&#23398;&#20064;&#29575;&#65292;&#21487;&#26368;&#23567;&#31243;&#24230;&#19978;&#20943;&#23569;&#36807;&#24230;&#21453;&#24212;&#31243;&#24230;&#65292;&#20294;&#36825;&#20250;&#29306;&#29298;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22521;&#35757;&#36807;&#30340;&#32929;&#24066;&#20998;&#26512;&#24072;&#27604;&#20256;&#32479;&#35757;&#32451;&#30340;&#20998;&#26512;&#24072;&#20135;&#29983;&#30340;&#36807;&#24230;&#21453;&#24212;&#36739;&#23569;&#12290;&#27492;&#22806;&#65292;&#32929;&#24066;&#20998;&#26512;&#24072;&#30340;&#39044;&#27979;&#21453;&#26144;&#20986;&#26426;&#22120;&#31639;&#27861;&#27809;&#26377;&#25429;&#25417;&#21040;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is considerable evidence that machine learning algorithms have better predictive abilities than humans in various financial settings. But, the literature has not tested whether these algorithmic predictions are more rational than human predictions. We study the predictions of corporate earnings from several algorithms, notably linear regressions and a popular algorithm called Gradient Boosted Regression Trees (GBRT). On average, GBRT outperformed both linear regressions and human stock analysts, but it still overreacted to news and did not satisfy rational expectation as normally defined. By reducing the learning rate, the magnitude of overreaction can be minimized, but it comes with the cost of poorer out-of-sample prediction accuracy. Human stock analysts who have been trained in machine learning methods overreact less than traditionally trained analysts. Additionally, stock analyst predictions reflect information not otherwise available to machine algorithms.
&lt;/p&gt;</description></item></channel></rss>