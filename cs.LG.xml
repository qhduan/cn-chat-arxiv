<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#21435;&#22122;&#20316;&#20026;&#38024;&#23545;&#24178;&#20928;&#26631;&#31614;&#20013;&#27602;&#30340;&#35748;&#35777;&#38450;&#24481;&#65292;&#33021;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#21040;0-16%&#65292;&#21516;&#26102;&#20960;&#20046;&#19981;&#24433;&#21709;&#27979;&#35797;&#20934;&#30830;&#24615;&#65292;&#20026;&#26410;&#26469;&#24320;&#21457;&#26356;&#24378;&#24178;&#20928;&#26631;&#31614;&#25915;&#20987;&#21644;&#21033;&#29992;&#35813;&#38450;&#24481;&#25514;&#26045;&#20316;&#20026;&#24378;&#26377;&#21147;&#22522;&#30784;&#25552;&#20379;&#20102;&#37325;&#35201;&#21551;&#31034;&#12290;</title><link>https://arxiv.org/abs/2403.11981</link><description>&lt;p&gt;
&#25193;&#25955;&#21435;&#22122;&#20316;&#20026;&#19968;&#31181;&#38024;&#23545;&#24178;&#20928;&#26631;&#31614;&#20013;&#27602;&#30340;&#35748;&#35777;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Diffusion Denoising as a Certified Defense against Clean-label Poisoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11981
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#21435;&#22122;&#20316;&#20026;&#38024;&#23545;&#24178;&#20928;&#26631;&#31614;&#20013;&#27602;&#30340;&#35748;&#35777;&#38450;&#24481;&#65292;&#33021;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#21040;0-16%&#65292;&#21516;&#26102;&#20960;&#20046;&#19981;&#24433;&#21709;&#27979;&#35797;&#20934;&#30830;&#24615;&#65292;&#20026;&#26410;&#26469;&#24320;&#21457;&#26356;&#24378;&#24178;&#20928;&#26631;&#31614;&#25915;&#20987;&#21644;&#21033;&#29992;&#35813;&#38450;&#24481;&#25514;&#26045;&#20316;&#20026;&#24378;&#26377;&#21147;&#22522;&#30784;&#25552;&#20379;&#20102;&#37325;&#35201;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24178;&#20928;&#26631;&#31614;&#20013;&#27602;&#25915;&#20987;&#30340;&#35748;&#35777;&#38450;&#24481;&#26041;&#27861;&#12290;&#36825;&#20123;&#25915;&#20987;&#36890;&#36807;&#21521;&#35757;&#32451;&#25968;&#25454;&#20013;&#27880;&#20837;&#23569;&#37327;&#30340;&#27602;&#23475;&#26679;&#26412;&#65288;&#20363;&#22914;1%&#65289;&#65292;&#20854;&#20013;&#21253;&#21547;$p$-&#33539;&#25968;&#21463;&#38480;&#30340;&#23545;&#25239;&#24615;&#25200;&#21160;&#65292;&#20174;&#32780;&#35825;&#23548;&#23545;&#27979;&#35797;&#36755;&#20837;&#30340;&#30446;&#26631;&#35823;&#20998;&#31867;&#12290;&#21463;&#21040;$&#21435;&#22122;&#24179;&#28369;$&#23454;&#29616;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#19968;&#20010;&#29616;&#25104;&#30340;&#25193;&#25955;&#27169;&#22411;&#23545;&#31713;&#25913;&#30340;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#28040;&#27602;&#12290;&#25105;&#20204;&#24191;&#27867;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#38450;&#24481;&#25514;&#26045;&#23545;&#19971;&#31181;&#24178;&#20928;&#26631;&#31614;&#20013;&#27602;&#25915;&#20987;&#30340;&#38450;&#25252;&#25928;&#26524;&#65292;&#24182;&#19988;&#23558;&#23427;&#20204;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#21040;0-16%&#65292;&#21516;&#26102;&#27979;&#35797;&#20934;&#30830;&#24615;&#20960;&#20046;&#27809;&#26377;&#19979;&#38477;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#38450;&#24481;&#19982;&#29616;&#26377;&#30340;&#38024;&#23545;&#24178;&#20928;&#26631;&#31614;&#20013;&#27602;&#30340;&#23545;&#31574;&#36827;&#34892;&#27604;&#36739;&#65292;&#26174;&#31034;&#20986;&#25105;&#20204;&#30340;&#38450;&#24481;&#25928;&#26524;&#26368;&#20339;&#65292;&#24182;&#25552;&#20379;&#26368;&#20339;&#30340;&#27169;&#22411;&#25928;&#29992;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20984;&#26174;&#20102;&#26410;&#26469;&#38656;&#35201;&#24320;&#23637;&#26356;&#24378;&#22823;&#30340;&#24178;&#20928;&#26631;&#31614;&#25915;&#20987;&#24182;&#20351;&#29992;&#25105;&#20204;&#30340;&#35748;&#35777;&#20294;&#23454;&#29992;&#30340;&#38450;&#24481;&#20316;&#20026;&#31283;&#22266;&#22522;&#30784;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11981v1 Announce Type: cross  Abstract: We present a certified defense to clean-label poisoning attacks. These attacks work by injecting a small number of poisoning samples (e.g., 1%) that contain $p$-norm bounded adversarial perturbations into the training data to induce a targeted misclassification of a test-time input. Inspired by the adversarial robustness achieved by $denoised$ $smoothing$, we show how an off-the-shelf diffusion model can sanitize the tampered training data. We extensively test our defense against seven clean-label poisoning attacks and reduce their attack success to 0-16% with only a negligible drop in the test time accuracy. We compare our defense with existing countermeasures against clean-label poisoning, showing that the defense reduces the attack success the most and offers the best model utility. Our results highlight the need for future work on developing stronger clean-label attacks and using our certified yet practical defense as a strong base
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#22768;&#26126;&#24615;&#12289;&#32479;&#19968;API&#30340;Python&#24211;&#65292;&#36890;&#36807;&#31616;&#27905;&#30340;API&#35843;&#29992;&#31616;&#21270;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#27969;&#31243;</title><link>https://arxiv.org/abs/2403.08291</link><description>&lt;p&gt;
CleanAgent&#65306;&#22522;&#20110;LLM&#20195;&#29702;&#33258;&#21160;&#21270;&#25968;&#25454;&#26631;&#20934;&#21270;
&lt;/p&gt;
&lt;p&gt;
CleanAgent: Automating Data Standardization with LLM-based Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08291
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#22768;&#26126;&#24615;&#12289;&#32479;&#19968;API&#30340;Python&#24211;&#65292;&#36890;&#36807;&#31616;&#27905;&#30340;API&#35843;&#29992;&#31616;&#21270;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#27969;&#31243;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#26631;&#20934;&#21270;&#26159;&#25968;&#25454;&#31185;&#23398;&#29983;&#21629;&#21608;&#26399;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#19968;&#37096;&#20998;&#12290;&#34429;&#28982;&#35832;&#22914;Pandas&#20043;&#31867;&#30340;&#24037;&#20855;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21151;&#33021;&#65292;&#20294;&#23427;&#20204;&#30340;&#22797;&#26434;&#24615;&#20197;&#21450;&#38656;&#35201;&#23450;&#21046;&#20195;&#30721;&#20197;&#36866;&#24212;&#19981;&#21516;&#21015;&#31867;&#22411;&#30340;&#25163;&#21160;&#25805;&#20316;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;ChatGPT&#24050;&#32463;&#23637;&#29616;&#20986;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#20195;&#30721;&#29983;&#25104;&#33258;&#21160;&#21270;&#27492;&#36807;&#31243;&#30340;&#28508;&#21147;&#65292;&#20294;&#20173;&#38656;&#35201;&#19987;&#19994;&#31243;&#24230;&#30340;&#32534;&#31243;&#30693;&#35782;&#21644;&#25345;&#32493;&#20114;&#21160;&#20197;&#36827;&#34892;&#21450;&#26102;&#30340;&#23436;&#21892;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#30340;&#20851;&#38190;&#24819;&#27861;&#26159;&#25552;&#20986;&#19968;&#20010;&#20855;&#26377;&#22768;&#26126;&#24615;&#12289;&#32479;&#19968;API&#30340;Python&#24211;&#65292;&#29992;&#20110;&#26631;&#20934;&#21270;&#21015;&#31867;&#22411;&#65292;&#36890;&#36807;&#31616;&#27905;&#30340;API&#35843;&#29992;&#31616;&#21270;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#27969;&#31243;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;Dataprep.Clean&#65292;&#20316;&#20026;Dataprep&#24211;&#30340;&#19968;&#20010;&#32452;&#20214;&#65292;&#36890;&#36807;&#19968;&#34892;&#20195;&#30721;&#23454;&#29616;&#29305;&#23450;&#21015;&#31867;&#22411;&#30340;&#26631;&#20934;&#21270;&#65292;&#26497;&#22823;&#38477;&#20302;&#20102;&#22797;&#26434;&#24615;&#12290;&#28982;&#21518;&#25105;&#20204;&#20171;&#32461;&#20102;CleanAgen
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08291v1 Announce Type: cross  Abstract: Data standardization is a crucial part in data science life cycle. While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges. Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement. To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing column types, simplifying the code generation of LLM with concise API calls. We first propose Dataprep.Clean which is written as a component of the Dataprep Library, offers a significant reduction in complexity by enabling the standardization of specific column types with a single line of code. Then we introduce the CleanAgen
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#24182;&#25913;&#21892;&#27169;&#22411;&#30340;&#22806;&#22495;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.15734</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#23454;&#29616;&#39640;&#25928;&#30340;&#36816;&#31639;&#31526;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15734
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#24182;&#25913;&#21892;&#27169;&#22411;&#30340;&#22806;&#22495;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#35265;&#35777;&#20102;&#23558;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#19982;&#29289;&#29702;&#39046;&#22495;&#29305;&#23450;&#27934;&#23519;&#21147;&#30456;&#32467;&#21512;&#65292;&#20197;&#35299;&#20915;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#31185;&#23398;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#23494;&#38598;&#65292;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#38656;&#35201;&#22823;&#37327;PDE&#25968;&#25454;&#12290; &#36825;&#37325;&#26032;&#24341;&#20837;&#20102;&#23545;&#26114;&#36149;&#30340;&#25968;&#20540;PDE&#35299;&#20915;&#26041;&#26696;&#30340;&#38656;&#27714;&#65292;&#37096;&#20998;&#21066;&#24369;&#20102;&#36991;&#20813;&#36825;&#20123;&#26114;&#36149;&#27169;&#25311;&#30340;&#21407;&#22987;&#30446;&#26631;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#20026;&#20102;&#23547;&#27714;&#25968;&#25454;&#25928;&#29575;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#29992;&#20110;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#12290; &#20026;&#20102;&#20943;&#23569;&#23545;&#24102;&#26377;&#27169;&#25311;&#35299;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#37325;&#26500;&#30340;&#20195;&#29702;&#20219;&#21153;&#22312;&#26410;&#26631;&#35760;&#30340;PDE&#25968;&#25454;&#19978;&#39044;&#35757;&#32451;&#31070;&#32463;&#36816;&#31639;&#31526;&#12290; &#20026;&#20102;&#25552;&#39640;&#36229;&#20986;&#20998;&#24067;&#24615;&#33021;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24110;&#21161;&#31070;&#32463;&#36816;&#31639;&#31526;&#28789;&#27963;&#22320;&#21033;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#25104;&#26412;&#25110;&#35774;&#35745;&#12290; &#22312;&#21508;&#31181;PD&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15734v1 Announce Type: new  Abstract: Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insight for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining and in-context learning methods for PDE operator learning. To reduce the need for training data with simulated solutions, we pretrain neural operators on unlabeled PDE data using reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging in-context learning methods, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PD
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#29978;&#33267;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65307;&#21516;&#26102;&#65292;&#22312;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.10252</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#30028;&#21644;&#36864;&#21270;&#22122;&#22768;&#30340;&#32447;&#24615;&#31995;&#32479;&#22312;&#32447;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Online Control of Linear Systems with Unbounded and Degenerate Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10252
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#29978;&#33267;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65307;&#21516;&#26102;&#65292;&#22312;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21487;&#33021;&#23384;&#22312;&#26080;&#30028;&#21644;&#36864;&#21270;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#32447;&#24615;&#31995;&#32479;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#25104;&#26412;&#20989;&#25968;&#26410;&#30693;&#65292;&#34987;&#31216;&#20026;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#12290;&#19982;&#29616;&#26377;&#30340;&#20165;&#20551;&#35774;&#22122;&#22768;&#26377;&#30028;&#24615;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013; $ T $ &#34920;&#31034;&#26102;&#38388;&#36328;&#24230;&#12290;&#27492;&#22806;&#65292;&#24403;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#32780;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#20551;&#35774;&#65292;&#36825;&#22312;&#25991;&#29486;&#20013;&#26159;&#24517;&#38656;&#30340;&#12290;&#28040;&#38500;&#22122;&#22768;&#31209;&#30340;&#20851;&#38190;&#26159;&#19982;&#22122;&#22768;&#21327;&#26041;&#24046;&#30456;&#20851;&#32852;&#30340;&#31995;&#32479;&#36716;&#21270;&#12290;&#36825;&#21516;&#26102;&#23454;&#29616;&#20102;&#22312;&#32447;&#25511;&#21046;&#31639;&#27861;&#30340;&#21442;&#25968;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10252v1 Announce Type: cross  Abstract: This paper investigates the problem of controlling a linear system under possibly unbounded and degenerate noise with unknown cost functions, known as an online control problem. In contrast to the existing work, which assumes the boundedness of noise, we reveal that for convex costs, an $ \widetilde{O}(\sqrt{T}) $ regret bound can be achieved even for unbounded noise, where $ T $ denotes the time horizon. Moreover, when the costs are strongly convex, we establish an $ O({\rm poly} (\log T)) $ regret bound without the assumption that noise covariance is non-degenerate, which has been required in the literature. The key ingredient in removing the rank assumption on noise is a system transformation associated with the noise covariance. This simultaneously enables the parameter reduction of an online control algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#28176;&#21464;&#27969;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#25277;&#26679;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#31283;&#23450;&#36125;&#21494;&#26031;&#20998;&#31867;&#27169;&#22411;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#39044;&#27979;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#65292;&#20197;&#35780;&#20272;&#27169;&#22411;&#30340;&#26222;&#36866;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08151</link><description>&lt;p&gt;
&#28176;&#21464;&#27969;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#25277;&#26679;&#29992;&#20110;sigmoid&#20998;&#31867;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Gradient-flow adaptive importance sampling for Bayesian leave one out cross-validation for sigmoidal classification models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#28176;&#21464;&#27969;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#25277;&#26679;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#31283;&#23450;&#36125;&#21494;&#26031;&#20998;&#31867;&#27169;&#22411;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#39044;&#27979;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#65292;&#20197;&#35780;&#20272;&#27169;&#22411;&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#32452;&#26799;&#24230;&#27969;&#24341;&#23548;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#25277;&#26679;&#65288;IS&#65289;&#21464;&#25442;&#65292;&#29992;&#20110;&#31283;&#23450;&#36125;&#21494;&#26031;&#20998;&#31867;&#27169;&#22411;&#30340;&#28857;&#32423;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#65288;LOO&#65289;&#39044;&#27979;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#12290;&#21487;&#20197;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#26469;&#35780;&#20272;&#27169;&#22411;&#30340;&#26222;&#36866;&#24615;&#65292;&#20363;&#22914;&#35745;&#31639;&#19982;AIC&#31867;&#20284;&#30340;LOO&#25110;&#35745;&#31639;LOO ROC / PRC&#26354;&#32447;&#20197;&#21450;&#27966;&#29983;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#22914;AUROC&#21644;AUPRC&#12290;&#36890;&#36807;&#21464;&#20998;&#27861;&#21644;&#26799;&#24230;&#27969;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20004;&#20010;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#21333;&#27493;&#21464;&#25442;&#65292;&#21033;&#29992;&#26799;&#24230;&#20449;&#24687;&#23558;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#23436;&#25972;&#25968;&#25454;&#21518;&#39564;&#38752;&#36817;&#30446;&#26631;LOO&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#12290;&#36825;&#26679;&#65292;&#21464;&#25442;&#31283;&#23450;&#20102;&#37325;&#35201;&#24615;&#26435;&#37325;&#12290;&#22240;&#20026;&#21464;&#25442;&#28041;&#21450;&#21040;&#20284;&#28982;&#20989;&#25968;&#30340;&#26799;&#24230;&#65292;&#25152;&#20197;&#32467;&#26524;&#30340;&#33945;&#29305;&#21345;&#32599;&#31215;&#20998;&#20381;&#36182;&#20110;&#27169;&#22411;Hessian&#30340;Jacobian&#34892;&#21015;&#24335;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#36825;&#20123;Jacobian&#34892;&#21015;&#24335;&#30340;&#38381;&#21512;&#31934;&#30830;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a set of gradient-flow-guided adaptive importance sampling (IS) transformations to stabilize Monte-Carlo approximations of point-wise leave one out cross-validated (LOO) predictions for Bayesian classification models. One can leverage this methodology for assessing model generalizability by for instance computing a LOO analogue to the AIC or computing LOO ROC/PRC curves and derived metrics like the AUROC and AUPRC. By the calculus of variations and gradient flow, we derive two simple nonlinear single-step transformations that utilize gradient information to shift a model's pre-trained full-data posterior closer to the target LOO posterior predictive distributions. In doing so, the transformations stabilize importance weights. Because the transformations involve the gradient of the likelihood function, the resulting Monte Carlo integral depends on Jacobian determinants with respect to the model Hessian. We derive closed-form exact formulae for these Jacobian determinants in
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#65292;&#30028;&#38480;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;</title><link>https://arxiv.org/abs/2402.07723</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#37325;&#23614;SDEs&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds for Heavy-Tailed SDEs through the Fractional Fokker-Planck Equation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07723
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#65292;&#30028;&#38480;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#26469;&#65292;&#29702;&#35299;&#37325;&#23614;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#21033;&#29992;&#37325;&#23614;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20316;&#20026;&#20195;&#29702;&#26469;&#38416;&#26126;&#38543;&#26426;&#20248;&#21270;&#22120;&#30340;&#26377;&#36259;&#26041;&#38754;&#26102;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#25552;&#20379;&#39044;&#26399;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#35201;&#20040;&#24341;&#20837;&#20102;&#19981;&#21487;&#35745;&#31639;&#30340;&#20449;&#24687;&#35770;&#26415;&#35821;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#32570;&#28857;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19981;&#21547;&#20219;&#20309;&#38750;&#24179;&#20961;&#30340;&#20449;&#24687;&#35770;&#26415;&#35821;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22522;&#20110;&#20272;&#35745;&#19982;&#25152;&#35859;&#30340;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#30456;&#20851;&#32852;&#30340;&#29109;&#27969;&#65292;&#24320;&#21457;&#20102;&#26032;&#30340;&#35777;&#26126;&#25216;&#26415;&#65288;&#36825;&#26159;&#19968;&#31181;&#25511;&#21046;&#30456;&#24212;&#37325;&#23614;SDE&#20998;&#24067;&#28436;&#21270;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65289;&#12290;&#38500;&#20102;&#33719;&#24471;&#39640;&#27010;&#29575;&#30028;&#38480;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the generalization properties of heavy-tailed stochastic optimization algorithms has attracted increasing attention over the past years. While illuminating interesting aspects of stochastic optimizers by using heavy-tailed stochastic differential equations as proxies, prior works either provided expected generalization bounds, or introduced non-computable information theoretic terms. Addressing these drawbacks, in this work, we prove high-probability generalization bounds for heavy-tailed SDEs which do not contain any nontrivial information theoretic terms. To achieve this goal, we develop new proof techniques based on estimating the entropy flows associated with the so-called fractional Fokker-Planck equation (a partial differential equation that governs the evolution of the distribution of the corresponding heavy-tailed SDE). In addition to obtaining high-probability bounds, we show that our bounds have a better dependence on the dimension of parameters as compared to p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.05806</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#26657;&#20934;&#21644;&#31526;&#21512;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Calibration and Conformal Prediction of Deep Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20998;&#31867;&#24212;&#29992;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22522;&#20110;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#38656;&#35201;&#20276;&#38543;&#19968;&#20123;&#32622;&#20449;&#24230;&#25351;&#31034;&#12290;&#38024;&#23545;&#36825;&#20010;&#30446;&#26631;&#65292;&#26377;&#20004;&#31181;&#27969;&#34892;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#65306;1&#65289;&#26657;&#20934;&#65306;&#20462;&#25913;&#20998;&#31867;&#22120;&#30340;softmax&#20540;&#65292;&#20351;&#20854;&#26368;&#22823;&#20540;&#65288;&#19982;&#39044;&#27979;&#30456;&#20851;&#65289;&#26356;&#22909;&#22320;&#20272;&#35745;&#27491;&#30830;&#27010;&#29575;&#65307;&#21644;2&#65289;&#31526;&#21512;&#39044;&#27979;&#65288;CP&#65289;&#65306;&#35774;&#35745;&#19968;&#20010;&#22522;&#20110;softmax&#20540;&#30340;&#20998;&#25968;&#65292;&#20174;&#20013;&#20135;&#29983;&#19968;&#32452;&#39044;&#27979;&#65292;&#20855;&#26377;&#29702;&#35770;&#19978;&#20445;&#35777;&#27491;&#30830;&#31867;&#21035;&#36793;&#38469;&#35206;&#30422;&#30340;&#29305;&#24615;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#20004;&#31181;&#25351;&#31034;&#37117;&#21487;&#33021;&#26159;&#38656;&#35201;&#30340;&#65292;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#23578;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#65292;&#36825;&#26159;&#26368;&#24120;&#35265;&#30340;&#26657;&#20934;&#25216;&#26415;&#65292;&#23545;&#37325;&#35201;&#30340;CP&#26041;&#27861;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#20102;&#19968;&#39033;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#20854;&#20013;&#26174;&#31034;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#27934;&#23519;&#65292;&#20854;&#20013;&#21253;&#25324;&#20196;&#20154;&#24778;&#35766;&#30340;&#21457;&#29616;&#65292;&#21363;&#26657;&#20934;&#23545;&#27969;&#34892;&#30340;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many classification applications, the prediction of a deep neural network (DNN) based classifier needs to be accompanied with some confidence indication. Two popular post-processing approaches for that aim are: 1) calibration: modifying the classifier's softmax values such that their maximum (associated with the prediction) better estimates the correctness probability; and 2) conformal prediction (CP): devising a score (based on the softmax values) from which a set of predictions with theoretically guaranteed marginal coverage of the correct class is produced. While in practice both types of indications can be desired, so far the interplay between them has not been investigated. Toward filling this gap, in this paper we study the effect of temperature scaling, arguably the most common calibration technique, on prominent CP methods. We start with an extensive empirical study that among other insights shows that, surprisingly, calibration has a detrimental effect on popular adaptive C
&lt;/p&gt;</description></item><item><title>PreGIP&#26159;&#38024;&#23545;&#28145;&#24230;&#30693;&#35782;&#20135;&#26435;&#20445;&#25252;&#30340;&#19968;&#31181;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#35757;&#32451;&#27700;&#21360;&#25216;&#26415;&#65292;&#23427;&#36890;&#36807;&#28155;&#21152;&#26080;&#20219;&#21153;&#30340;&#27700;&#21360;&#25439;&#22833;&#26469;&#32473;&#39044;&#35757;&#32451;&#30340;GNN&#32534;&#30721;&#22120;&#30340;&#23884;&#20837;&#31354;&#38388;&#28155;&#21152;&#27700;&#21360;&#65292;&#24182;&#37319;&#29992;&#25239;&#24494;&#35843;&#30340;&#27700;&#21360;&#27880;&#20837;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.04435</link><description>&lt;p&gt;
PreGIP: &#38024;&#23545;&#28145;&#24230;&#30693;&#35782;&#20135;&#26435;&#20445;&#25252;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#35757;&#32451;&#27700;&#21360;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04435
&lt;/p&gt;
&lt;p&gt;
PreGIP&#26159;&#38024;&#23545;&#28145;&#24230;&#30693;&#35782;&#20135;&#26435;&#20445;&#25252;&#30340;&#19968;&#31181;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#35757;&#32451;&#27700;&#21360;&#25216;&#26415;&#65292;&#23427;&#36890;&#36807;&#28155;&#21152;&#26080;&#20219;&#21153;&#30340;&#27700;&#21360;&#25439;&#22833;&#26469;&#32473;&#39044;&#35757;&#32451;&#30340;GNN&#32534;&#30721;&#22120;&#30340;&#23884;&#20837;&#31354;&#38388;&#28155;&#21152;&#27700;&#21360;&#65292;&#24182;&#37319;&#29992;&#25239;&#24494;&#35843;&#30340;&#27700;&#21360;&#27880;&#20837;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#39044;&#35757;&#32451;&#22312;&#20419;&#36827;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#26174;&#31034;&#20986;&#24040;&#22823;&#30340;&#33021;&#21147;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#25968;&#25454;&#21644;&#35745;&#31639;&#36164;&#28304;&#65292;&#39044;&#35757;&#32451;&#30340;GNNs&#25104;&#20026;&#21512;&#27861;&#25317;&#26377;&#32773;&#30340;&#39640;&#20215;&#20540;&#30693;&#35782;&#20135;&#26435;&#65288;IP&#65289;&#12290;&#28982;&#32780;&#65292;&#23545;&#25163;&#21487;&#33021;&#20250;&#38750;&#27861;&#22797;&#21046;&#21644;&#37096;&#32626;&#39044;&#35757;&#32451;&#30340;GNN&#27169;&#22411;&#29992;&#20110;&#20854;&#19979;&#28216;&#20219;&#21153;&#12290;&#34429;&#28982;&#24050;&#32463;&#24320;&#22987;&#23581;&#35797;&#20026;IP&#20445;&#25252;&#28155;&#21152;GNN&#20998;&#31867;&#22120;&#30340;&#27700;&#21360;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#38656;&#35201;&#30446;&#26631;&#20998;&#31867;&#20219;&#21153;&#25165;&#33021;&#36827;&#34892;&#27700;&#21360;&#22788;&#29702;&#65292;&#22240;&#27492;&#19981;&#36866;&#29992;&#20110;GNN&#27169;&#22411;&#30340;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;PreGIP&#65292;&#29992;&#20110;&#22312;&#20445;&#25345;&#23884;&#20837;&#31354;&#38388;&#39640;&#36136;&#37327;&#30340;&#21516;&#26102;&#65292;&#32473;GNN&#32534;&#30721;&#22120;&#30340;&#39044;&#35757;&#32451;&#28155;&#21152;&#27700;&#21360;&#20197;&#36827;&#34892;IP&#20445;&#25252;&#12290;PreGIP&#24341;&#20837;&#20102;&#26080;&#20219;&#21153;&#30340;&#27700;&#21360;&#25439;&#22833;&#26469;&#32473;&#39044;&#35757;&#32451;&#30340;GNN&#32534;&#30721;&#22120;&#30340;&#23884;&#20837;&#31354;&#38388;&#28155;&#21152;&#27700;&#21360;&#12290;&#21516;&#26102;&#37319;&#29992;&#20102;&#25239;&#24494;&#35843;&#30340;&#27700;&#21360;&#27880;&#20837;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#21644;&#25193;&#23637;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretraining on Graph Neural Networks (GNNs) has shown great power in facilitating various downstream tasks. As pretraining generally requires huge amount of data and computational resources, the pretrained GNNs are high-value Intellectual Properties (IP) of the legitimate owner. However, adversaries may illegally copy and deploy the pretrained GNN models for their downstream tasks. Though initial efforts have been made to watermark GNN classifiers for IP protection, these methods require the target classification task for watermarking, and thus are not applicable to self-supervised pretraining of GNN models. Hence, in this work, we propose a novel framework named PreGIP to watermark the pretraining of GNN encoder for IP protection while maintain the high-quality of the embedding space. PreGIP incorporates a task-free watermarking loss to watermark the embedding space of pretrained GNN encoder. A finetuning-resistant watermark injection is further deployed. Theoretical analysis and exte
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#38598;&#25104;&#26041;&#27861;&#26469;&#22686;&#24378;&#22522;&#20110;&#20998;&#25968;&#30340;&#25277;&#26679;&#26041;&#27861;&#65292;&#25104;&#21151;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#31890;&#23376;&#38598;&#21512;&#21160;&#24577;&#35745;&#31639;&#36817;&#20284;&#21453;&#25193;&#25955;&#28418;&#31227;&#30340;&#26080;&#26799;&#24230;&#25277;&#26679;&#25216;&#26415;&#65292;&#24182;&#22312;&#22810;&#20010;&#31034;&#20363;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#23545;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#30340;&#24314;&#27169;&#21644;&#22312;&#22320;&#29699;&#29289;&#29702;&#31185;&#23398;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2401.17539</link><description>&lt;p&gt;
&#29992;&#38598;&#25104;&#26041;&#27861;&#22686;&#24378;&#22522;&#20110;&#20998;&#25968;&#30340;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Enhancing Score-Based Sampling Methods with Ensembles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17539
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#38598;&#25104;&#26041;&#27861;&#26469;&#22686;&#24378;&#22522;&#20110;&#20998;&#25968;&#30340;&#25277;&#26679;&#26041;&#27861;&#65292;&#25104;&#21151;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#31890;&#23376;&#38598;&#21512;&#21160;&#24577;&#35745;&#31639;&#36817;&#20284;&#21453;&#25193;&#25955;&#28418;&#31227;&#30340;&#26080;&#26799;&#24230;&#25277;&#26679;&#25216;&#26415;&#65292;&#24182;&#22312;&#22810;&#20010;&#31034;&#20363;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#23545;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#30340;&#24314;&#27169;&#21644;&#22312;&#22320;&#29699;&#29289;&#29702;&#31185;&#23398;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#22522;&#20110;&#20998;&#25968;&#30340;&#25277;&#26679;&#26041;&#27861;&#20013;&#24341;&#20837;&#20102;&#38598;&#25104;&#26041;&#27861;&#65292;&#20197;&#24320;&#21457;&#21033;&#29992;&#31890;&#23376;&#38598;&#21512;&#21160;&#24577;&#35745;&#31639;&#36817;&#20284;&#21453;&#25193;&#25955;&#28418;&#31227;&#30340;&#26080;&#26799;&#24230;&#25277;&#26679;&#25216;&#26415;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#24213;&#23618;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#23427;&#19982;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#21644;&#20808;&#21069;&#20171;&#32461;&#30340;F&#246;llmer&#25277;&#26679;&#22120;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#21508;&#31181;&#31034;&#20363;&#35777;&#26126;&#20102;&#38598;&#25104;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#65292;&#28085;&#30422;&#20102;&#20174;&#20302;&#32500;&#21040;&#20013;&#31561;&#32500;&#24230;&#30340;&#25277;&#26679;&#38382;&#39064;&#65292;&#21253;&#25324;&#22810;&#23792;&#21644;&#39640;&#24230;&#38750;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#19982;&#20256;&#32479;&#26041;&#27861;&#22914;NUTS&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#31361;&#20986;&#20102;&#22312;&#26799;&#24230;&#19981;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#38598;&#25104;&#31574;&#30053;&#22312;&#24314;&#27169;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22320;&#29699;&#29289;&#29702;&#31185;&#23398;&#30340;&#36125;&#21494;&#26031;&#21453;&#28436;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce ensembles within score-based sampling methods to develop gradient-free approximate sampling techniques that leverage the collective dynamics of particle ensembles to compute approximate reverse diffusion drifts. We introduce the underlying methodology, emphasizing its relationship with generative diffusion models and the previously introduced F\"ollmer sampler. We demonstrate the efficacy of ensemble strategies through various examples, ranging from low- to medium-dimensionality sampling problems, including multi-modal and highly non-Gaussian probability distributions, and provide comparisons to traditional methods like NUTS. Our findings highlight the potential of ensemble strategies for modeling complex probability distributions in situations where gradients are unavailable. Finally, we showcase its application in the context of Bayesian inversion problems within the geophysical sciences.
&lt;/p&gt;</description></item><item><title>&#22810;&#35821;&#35328;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#23384;&#22312;&#24615;&#21035;&#20559;&#35265;&#65307;&#36890;&#36807;MAGBIG&#35780;&#20272;&#27169;&#22411;&#26102;&#65292;&#21457;&#29616;&#27169;&#22411;&#23545;&#19981;&#21516;&#35821;&#35328;&#20855;&#26377;&#37325;&#35201;&#24046;&#24322;&#65307;&#25105;&#20204;&#21628;&#21505;&#30740;&#31350;&#22810;&#35821;&#35328;&#27169;&#22411;&#39046;&#22495;&#28040;&#38500;&#24615;&#21035;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2401.16092</link><description>&lt;p&gt;
&#22810;&#35821;&#35328;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#25918;&#22823;&#20102;&#24615;&#21035;&#21051;&#26495;&#21360;&#35937;&#65292;&#24182;&#19988;&#20462;&#27491;&#24037;&#31243;&#21487;&#33021;&#26080;&#27861;&#24110;&#21161;&#24744;
&lt;/p&gt;
&lt;p&gt;
Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and Prompt Engineering May Not Help You
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.16092
&lt;/p&gt;
&lt;p&gt;
&#22810;&#35821;&#35328;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#23384;&#22312;&#24615;&#21035;&#20559;&#35265;&#65307;&#36890;&#36807;MAGBIG&#35780;&#20272;&#27169;&#22411;&#26102;&#65292;&#21457;&#29616;&#27169;&#22411;&#23545;&#19981;&#21516;&#35821;&#35328;&#20855;&#26377;&#37325;&#35201;&#24046;&#24322;&#65307;&#25105;&#20204;&#21628;&#21505;&#30740;&#31350;&#22810;&#35821;&#35328;&#27169;&#22411;&#39046;&#22495;&#28040;&#38500;&#24615;&#21035;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#22312;&#22270;&#20687;&#36136;&#37327;&#12289;&#28789;&#27963;&#24615;&#21644;&#25991;&#26412;&#23545;&#40784;&#26041;&#38754;&#21462;&#24471;&#20102;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#65292;&#24182;&#22240;&#27492;&#22312;&#36234;&#26469;&#36234;&#22810;&#30340;&#24212;&#29992;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;&#36890;&#36807;&#25913;&#21892;&#22810;&#35821;&#35328;&#33021;&#21147;&#65292;&#26356;&#22810;&#30340;&#31038;&#32676;&#29616;&#22312;&#21487;&#20197;&#35775;&#38382;&#36825;&#31181;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#25105;&#20204;&#23558;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#22810;&#35821;&#35328;&#27169;&#22411;&#19982;&#21333;&#35821;&#27169;&#22411;&#19968;&#26679;&#21463;&#21040;(&#24615;&#21035;)&#20559;&#35265;&#30340;&#22256;&#25200;&#12290;&#27492;&#22806;&#65292;&#20154;&#20204;&#33258;&#28982;&#26399;&#26395;&#36825;&#20123;&#27169;&#22411;&#22312;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#25552;&#20379;&#31867;&#20284;&#30340;&#32467;&#26524;&#65292;&#20294;&#20107;&#23454;&#24182;&#38750;&#22914;&#27492;&#65292;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#23384;&#22312;&#37325;&#35201;&#30340;&#24046;&#24322;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26088;&#22312;&#20419;&#36827;&#27809;&#26377;&#24615;&#21035;&#20559;&#35265;&#30340;&#22810;&#35821;&#35328;&#27169;&#22411;&#30740;&#31350;&#30340;&#26032;&#22522;&#20934;MAGBIG&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#35821;&#35328;T2I&#27169;&#22411;&#26159;&#21542;&#36890;&#36807;MAGBIG&#25918;&#22823;&#20102;&#24615;&#21035;&#20559;&#35265;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#22810;&#35821;&#35328;&#25552;&#31034;&#35831;&#27714;&#29305;&#23450;&#32844;&#19994;&#25110;&#29305;&#36136;&#30340;&#20154;&#20687;&#22270;&#20687;(&#20351;&#29992;&#24418;&#23481;&#35789;)&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#20165;&#34920;&#26126;&#27169;&#22411;&#20559;&#31163;&#20102;&#35268;&#33539;&#30340;&#20551;&#35774;&#65292;...
&lt;/p&gt;
&lt;p&gt;
Text-to-image generation models have recently achieved astonishing results in image quality, flexibility, and text alignment and are consequently employed in a fast-growing number of applications. Through improvements in multilingual abilities, a larger community now has access to this kind of technology. Yet, as we will show, multilingual models suffer similarly from (gender) biases as monolingual models. Furthermore, the natural expectation is that these models will provide similar results across languages, but this is not the case and there are important differences between languages. Thus, we propose a novel benchmark MAGBIG intending to foster research in multilingual models without gender bias. We investigate whether multilingual T2I models magnify gender bias with MAGBIG. To this end, we use multilingual prompts requesting portrait images of persons of a certain occupation or trait (using adjectives). Our results show not only that models deviate from the normative assumption th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#38382;&#39064;&#65292;&#21363;&#26410;&#39044;&#26399;&#30340;&#20449;&#24687;&#27745;&#26579;&#35757;&#32451;&#25968;&#25454;&#65292;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#35780;&#20272;&#65292;&#29992;&#25143;&#21487;&#33021;&#30001;&#20110;&#32570;&#20047;&#29702;&#35299;&#32780;&#24573;&#35270;&#20851;&#38190;&#27493;&#39588;&#65292;&#23548;&#33268;&#20048;&#35266;&#30340;&#24615;&#33021;&#20272;&#35745;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#19981;&#25104;&#31435;&#12290;</title><link>http://arxiv.org/abs/2401.13796</link><description>&lt;p&gt;
&#19981;&#35201;&#25353;&#25353;&#38062;&#65281;&#25506;&#32034;&#26426;&#22120;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning. (arXiv:2401.13796v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13796
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#38382;&#39064;&#65292;&#21363;&#26410;&#39044;&#26399;&#30340;&#20449;&#24687;&#27745;&#26579;&#35757;&#32451;&#25968;&#25454;&#65292;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#35780;&#20272;&#65292;&#29992;&#25143;&#21487;&#33021;&#30001;&#20110;&#32570;&#20047;&#29702;&#35299;&#32780;&#24573;&#35270;&#20851;&#38190;&#27493;&#39588;&#65292;&#23548;&#33268;&#20048;&#35266;&#30340;&#24615;&#33021;&#20272;&#35745;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#19981;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#65292;&#20026;&#22810;&#20010;&#39046;&#22495;&#25552;&#20379;&#20102;&#39044;&#27979;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;ML&#24037;&#20855;&#30340;&#26085;&#30410;&#21487;&#33719;&#24471;&#24615;&#65292;&#35768;&#22810;&#20174;&#19994;&#32773;&#32570;&#20047;&#28145;&#20837;&#30340;ML&#19987;&#19994;&#30693;&#35782;&#65292;&#37319;&#29992;&#20102;&#8220;&#25353;&#25353;&#38062;&#8221;&#26041;&#27861;&#65292;&#21033;&#29992;&#29992;&#25143;&#21451;&#22909;&#30340;&#30028;&#38754;&#32780;&#24573;&#35270;&#20102;&#24213;&#23618;&#31639;&#27861;&#30340;&#28145;&#20837;&#29702;&#35299;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#20415;&#21033;&#65292;&#20294;&#23427;&#24341;&#21457;&#20102;&#23545;&#32467;&#26524;&#21487;&#38752;&#24615;&#30340;&#25285;&#24551;&#65292;&#23548;&#33268;&#20102;&#38169;&#35823;&#30340;&#24615;&#33021;&#35780;&#20272;&#31561;&#25361;&#25112;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;ML&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#21363;&#25968;&#25454;&#27844;&#38706;&#65292;&#20854;&#20013;&#26410;&#39044;&#26399;&#30340;&#20449;&#24687;&#27745;&#26579;&#20102;&#35757;&#32451;&#25968;&#25454;&#65292;&#24433;&#21709;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#35780;&#20272;&#12290;&#30001;&#20110;&#32570;&#20047;&#29702;&#35299;&#65292;&#29992;&#25143;&#21487;&#33021;&#20250;&#26080;&#24847;&#20013;&#24573;&#35270;&#20851;&#38190;&#27493;&#39588;&#65292;&#20174;&#32780;&#23548;&#33268;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#30340;&#20048;&#35266;&#24615;&#33021;&#20272;&#35745;&#12290;&#35780;&#20272;&#24615;&#33021;&#19982;&#23454;&#38469;&#22312;&#26032;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#30340;&#24046;&#24322;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20851;&#27880;&#28857;&#12290;&#26412;&#25991;&#29305;&#21035;&#23558;ML&#20013;&#30340;&#25968;&#25454;&#27844;&#38706;&#20998;&#20026;&#19981;&#21516;&#31867;&#21035;&#65292;&#24182;&#35752;&#35770;&#20102;&#30456;&#20851;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) has revolutionized various domains, offering predictive capabilities in several areas. However, with the increasing accessibility of ML tools, many practitioners, lacking deep ML expertise, adopt a "push the button" approach, utilizing user-friendly interfaces without a thorough understanding of underlying algorithms. While this approach provides convenience, it raises concerns about the reliability of outcomes, leading to challenges such as incorrect performance evaluation. This paper addresses a critical issue in ML, known as data leakage, where unintended information contaminates the training data, impacting model performance evaluation. Users, due to a lack of understanding, may inadvertently overlook crucial steps, leading to optimistic performance estimates that may not hold in real-world scenarios. The discrepancy between evaluated and actual performance on new data is a significant concern. In particular, this paper categorizes data leakage in ML, discussi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#26725;&#25509;&#20102;&#32852;&#37030;&#32858;&#31867;&#21644;&#23545;&#27604;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CCFC&#30340;&#26032;&#32852;&#37030;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#34920;&#31034;&#23398;&#20064;&#65292;CCFC&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#32858;&#31867;&#24615;&#33021;&#29978;&#33267;&#26159;&#26368;&#20339;&#22522;&#20934;&#26041;&#27861;&#30340;&#20004;&#20493;&#12290;&#19982;&#26368;&#30456;&#20851;&#30340;&#22522;&#20934;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#26368;&#26174;&#33879;&#30340;&#26696;&#20363;&#20013;&#65292;CCFC&#30340;NMI&#24471;&#20998;&#25552;&#39640;&#20102;0.4155&#12290;&#21516;&#26102;&#65292;CCFC&#36824;&#33021;&#26377;&#25928;&#22788;&#29702;&#32852;&#37030;&#22330;&#26223;&#19979;&#30340;&#25968;&#25454;&#20998;&#24067;&#21644;&#36136;&#37327;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2401.06634</link><description>&lt;p&gt;
CCFC&#65306;&#26725;&#25509;&#32852;&#37030;&#32858;&#31867;&#21644;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
CCFC: Bridging Federated Clustering and Contrastive Learning. (arXiv:2401.06634v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06634
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#26725;&#25509;&#20102;&#32852;&#37030;&#32858;&#31867;&#21644;&#23545;&#27604;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CCFC&#30340;&#26032;&#32852;&#37030;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#34920;&#31034;&#23398;&#20064;&#65292;CCFC&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#32858;&#31867;&#24615;&#33021;&#29978;&#33267;&#26159;&#26368;&#20339;&#22522;&#20934;&#26041;&#27861;&#30340;&#20004;&#20493;&#12290;&#19982;&#26368;&#30456;&#20851;&#30340;&#22522;&#20934;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#26368;&#26174;&#33879;&#30340;&#26696;&#20363;&#20013;&#65292;CCFC&#30340;NMI&#24471;&#20998;&#25552;&#39640;&#20102;0.4155&#12290;&#21516;&#26102;&#65292;CCFC&#36824;&#33021;&#26377;&#25928;&#22788;&#29702;&#32852;&#37030;&#22330;&#26223;&#19979;&#30340;&#25968;&#25454;&#20998;&#24067;&#21644;&#36136;&#37327;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#32858;&#31867;&#26159;&#23545;&#20110;&#32852;&#37030;&#22330;&#26223;&#20013;&#38598;&#20013;&#32858;&#31867;&#30340;&#37325;&#35201;&#25193;&#23637;&#65292;&#21487;&#20197;&#35753;&#22810;&#20010;&#25968;&#25454;&#25345;&#26377;&#23458;&#25143;&#31471;&#22312;&#20445;&#30041;&#26412;&#22320;&#25968;&#25454;&#30340;&#21516;&#26102;&#21327;&#21516;&#36827;&#34892;&#25968;&#25454;&#20998;&#32452;&#12290;&#22312;&#38598;&#20013;&#22330;&#26223;&#20013;&#65292;&#36890;&#36807;&#34920;&#31034;&#23398;&#20064;&#39537;&#21160;&#30340;&#32858;&#31867;&#22312;&#22788;&#29702;&#39640;&#32500;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#32852;&#37030;&#32858;&#31867;&#21644;&#34920;&#31034;&#23398;&#20064;&#30340;&#32467;&#21512;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#30740;&#31350;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#39318;&#20808;&#20026;&#23398;&#20064;&#32858;&#31867;&#21451;&#22909;&#30340;&#34920;&#31034;&#23450;&#21046;&#20102;&#19968;&#20010;&#32858;&#31867;&#23545;&#27604;&#27169;&#22411;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#27169;&#22411;&#20316;&#20026;&#25552;&#20986;&#26032;&#30340;&#32852;&#37030;&#32858;&#31867;&#26041;&#27861;&#30340;&#22522;&#30784;&#65292;&#31216;&#20026;&#32858;&#31867;&#23545;&#27604;&#32852;&#37030;&#32858;&#31867;&#65288;CCFC&#65289;&#12290;&#21463;&#30410;&#20110;&#34920;&#31034;&#23398;&#20064;&#65292;CCFC&#30340;&#32858;&#31867;&#24615;&#33021;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#29978;&#33267;&#26159;&#26368;&#20339;&#22522;&#20934;&#26041;&#27861;&#30340;&#20004;&#20493;&#12290;&#19982;&#26368;&#30456;&#20851;&#30340;&#22522;&#20934;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#26368;&#26174;&#33879;&#30340;&#26696;&#20363;&#20013;&#65292;&#36825;&#31181;&#25910;&#30410;&#23548;&#33268;NMI&#24471;&#20998;&#30340;&#26174;&#33879;&#25552;&#39640;&#65292;&#26368;&#39640;&#36798;&#21040;0.4155&#12290;&#27492;&#22806;&#65292;CCFC&#36824;&#21487;&#20197;&#26377;&#25928;&#22320;&#22788;&#29702;&#22312;&#32852;&#37030;&#22330;&#26223;&#19979;&#20986;&#29616;&#30340;&#25968;&#25454;&#20998;&#24067;&#21644;&#36136;&#37327;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated clustering, an essential extension of centralized clustering for federated scenarios, enables multiple data-holding clients to collaboratively group data while keeping their data locally. In centralized scenarios, clustering driven by representation learning has made significant advancements in handling high-dimensional complex data. However, the combination of federated clustering and representation learning remains underexplored. To bridge this, we first tailor a cluster-contrastive model for learning clustering-friendly representations. Then, we harness this model as the foundation for proposing a new federated clustering method, named cluster-contrastive federated clustering (CCFC). Benefiting from representation learning, the clustering performance of CCFC even double those of the best baseline methods in some cases. Compared to the most related baseline, the benefit results in substantial NMI score improvements of up to 0.4155 on the most conspicuous case. Moreover, CCF
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#22270;&#35889;&#26063;&#19978;&#30340;&#37319;&#26679;&#38598;&#29305;&#24615;&#65292;&#24182;&#23558;&#8220;&#21487;&#31227;&#38500;&#38598;&#21512;&#8221;&#21644;&#8220;&#21807;&#19968;&#24615;&#38598;&#21512;&#8221;&#30340;&#27010;&#24565;&#25512;&#24191;&#21040;&#20102;&#22270;&#35889;&#20449;&#21495;&#22788;&#29702;&#20013;&#12290;&#36890;&#36807;&#21033;&#29992;&#22270;&#35889;&#34920;&#31034;&#27861;&#65292;&#21487;&#20197;&#27604;&#36739;&#20855;&#26377;&#19981;&#21516;&#33410;&#28857;&#25968;&#21644;&#36793;&#25968;&#20197;&#21450;&#19981;&#21516;&#33410;&#28857;&#26631;&#35760;&#30340;&#22270;&#35889;&#20043;&#38388;&#30340;&#37319;&#26679;&#38598;&#65292;&#24182;&#35777;&#26126;&#20102;&#20855;&#26377;&#30456;&#21516;&#22270;&#35889;&#34920;&#31034;&#30340;&#37319;&#26679;&#38598;&#24207;&#21015;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06279</link><description>&lt;p&gt;
&#22270;&#35889;&#20449;&#21495;&#22788;&#29702;&#20013;&#30340;&#37319;&#26679;&#21644;&#21807;&#19968;&#24615;&#38598;
&lt;/p&gt;
&lt;p&gt;
Sampling and Uniqueness Sets in Graphon Signal Processing. (arXiv:2401.06279v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06279
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#22270;&#35889;&#26063;&#19978;&#30340;&#37319;&#26679;&#38598;&#29305;&#24615;&#65292;&#24182;&#23558;&#8220;&#21487;&#31227;&#38500;&#38598;&#21512;&#8221;&#21644;&#8220;&#21807;&#19968;&#24615;&#38598;&#21512;&#8221;&#30340;&#27010;&#24565;&#25512;&#24191;&#21040;&#20102;&#22270;&#35889;&#20449;&#21495;&#22788;&#29702;&#20013;&#12290;&#36890;&#36807;&#21033;&#29992;&#22270;&#35889;&#34920;&#31034;&#27861;&#65292;&#21487;&#20197;&#27604;&#36739;&#20855;&#26377;&#19981;&#21516;&#33410;&#28857;&#25968;&#21644;&#36793;&#25968;&#20197;&#21450;&#19981;&#21516;&#33410;&#28857;&#26631;&#35760;&#30340;&#22270;&#35889;&#20043;&#38388;&#30340;&#37319;&#26679;&#38598;&#65292;&#24182;&#35777;&#26126;&#20102;&#20855;&#26377;&#30456;&#21516;&#22270;&#35889;&#34920;&#31034;&#30340;&#37319;&#26679;&#38598;&#24207;&#21015;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#22270;&#35889;&#21644;&#22270;&#26497;&#38480;&#30340;&#29702;&#35770;&#65292;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#22270;&#35889;&#26063;&#19978;&#37319;&#26679;&#38598;&#30340;&#29305;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;&#8220;&#21487;&#31227;&#38500;&#38598;&#21512;&#8221;&#21644;&#8220;&#21807;&#19968;&#24615;&#38598;&#21512;&#8221;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#20102;&#22270;&#35889;&#20449;&#21495;&#39046;&#22495;&#65292;&#36825;&#20123;&#27010;&#24565;&#26368;&#21021;&#26159;&#29992;&#20110;&#20998;&#26512;&#22270;&#35889;&#19978;&#30340;&#20449;&#21495;&#30340;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;$\Lambda-$&#21487;&#31227;&#38500;&#38598;&#21512;&#30340;&#27491;&#24335;&#23450;&#20041;&#65292;&#24182;&#22312;&#24471;&#21040;&#20174;&#22270;&#35889;&#20013;&#19968;&#20010;&#32473;&#23450;$\Lambda-$&#21487;&#31227;&#38500;&#38598;&#21512;&#30340;&#34917;&#38598;&#20013;&#30340;&#26679;&#26412;&#26102;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#39057;&#24102;&#26377;&#38480;&#30340;&#22270;&#35889;&#20449;&#21495;&#21487;&#20197;&#20197;&#21807;&#19968;&#26041;&#24335;&#34920;&#31034;&#30340;&#26465;&#20214;&#12290;&#36890;&#36807;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#35889;&#34920;&#31034;&#27861;&#21487;&#20197;&#20316;&#20026;&#19968;&#31181;&#20849;&#21516;&#30340;&#26694;&#26550;&#26469;&#27604;&#36739;&#20855;&#26377;&#19981;&#21516;&#33410;&#28857;&#25968;&#21644;&#36793;&#25968;&#20197;&#21450;&#19981;&#21516;&#33410;&#28857;&#26631;&#35760;&#30340;&#22270;&#35889;&#20043;&#38388;&#30340;&#37319;&#26679;&#38598;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#25910;&#25947;&#21040;&#19968;&#20010;&#22270;&#35889;&#30340;&#22270;&#24207;&#21015;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20855;&#26377;&#30456;&#21516;$[0,1]$&#20013;&#22270;&#35889;&#34920;&#31034;&#30340;&#37319;&#26679;&#38598;&#24207;&#21015;&#20063;&#26159;&#25910;&#25947;&#30340;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study the properties of sampling sets on families of large graphs by leveraging the theory of graphons and graph limits. To this end, we extend to graphon signals the notion of removable and uniqueness sets, which was developed originally for the analysis of signals on graphs. We state the formal definition of a $\Lambda-$removable set and conditions under which a bandlimited graphon signal can be represented in a unique way when its samples are obtained from the complement of a given $\Lambda-$removable set in the graphon. By leveraging such results we show that graphon representations of graphs and graph signals can be used as a common framework to compare sampling sets between graphs with different numbers of nodes and edges, and different node labelings. Additionally, given a sequence of graphs that converges to a graphon, we show that the sequences of sampling sets whose graphon representation is identical in $[0,1]$ are convergent as well. We exploit the converge
&lt;/p&gt;</description></item><item><title>CAFE&#26159;&#19968;&#31181;&#20914;&#31361;&#24863;&#30693;&#30340;&#29305;&#24449;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#25552;&#20379;&#20102;&#23545;&#29305;&#24449;&#20914;&#31361;&#30340;&#22686;&#24378;&#40065;&#26834;&#24615;&#21644;&#26356;&#22909;&#30340;&#35299;&#37322;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.20363</link><description>&lt;p&gt;
CAFE: &#20914;&#31361;&#24863;&#30693;&#30340;&#29305;&#24449;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
CAFE: Conflict-Aware Feature-wise Explanations. (arXiv:2310.20363v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20363
&lt;/p&gt;
&lt;p&gt;
CAFE&#26159;&#19968;&#31181;&#20914;&#31361;&#24863;&#30693;&#30340;&#29305;&#24449;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#25552;&#20379;&#20102;&#23545;&#29305;&#24449;&#20914;&#31361;&#30340;&#22686;&#24378;&#40065;&#26834;&#24615;&#21644;&#26356;&#22909;&#30340;&#35299;&#37322;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#35299;&#37322;&#31070;&#32463;&#27169;&#22411;&#65292;&#36890;&#36807;&#30830;&#23450;&#21333;&#20010;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#26469;&#35299;&#37322;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;CAFE&#65288;&#20914;&#31361;&#24863;&#30693;&#30340;&#29305;&#24449;&#35299;&#37322;&#65289;&#65292;&#23427;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#19977;&#20010;&#23616;&#38480;&#24615;&#65306;&#23545;&#20914;&#31361;&#29305;&#24449;&#24433;&#21709;&#30340;&#24573;&#35270;&#65292;&#23545;&#20559;&#24046;&#39033;&#24433;&#21709;&#30340;&#32570;&#20047;&#32771;&#34385;&#65292;&#20197;&#21450;&#23545;&#28608;&#27963;&#20989;&#25968;&#23616;&#37096;&#21464;&#21270;&#36807;&#20110;&#25935;&#24863;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;CAFE&#25552;&#20379;&#20102;&#38450;&#27490;&#39640;&#20272;&#31070;&#32463;&#20803;&#36755;&#20837;&#24433;&#21709;&#30340;&#20445;&#25252;&#26426;&#21046;&#65292;&#24182;&#21333;&#29420;&#36861;&#36394;&#36755;&#20837;&#29305;&#24449;&#21644;&#20559;&#24046;&#30340;&#27491;&#21521;&#21644;&#36127;&#21521;&#24433;&#21709;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#31283;&#20581;&#24615;&#21644;&#21457;&#29616;&#29305;&#24449;&#20914;&#31361;&#30340;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;CAFE&#22312;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#19978;&#33021;&#26356;&#22909;&#22320;&#35782;&#21035;&#20914;&#31361;&#29305;&#24449;&#65292;&#24182;&#22312;&#20960;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26368;&#20339;&#30340;&#20840;&#38754;&#21487;&#20449;&#24230;&#65292;&#32780;&#35745;&#31639;&#24615;&#33021;&#20063;&#24456;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature attribution methods are widely used to explain neural models by determining the influence of individual input features on the models' outputs. We propose a novel feature attribution method, CAFE (Conflict-Aware Feature-wise Explanations), that addresses three limitations of the existing methods: their disregard for the impact of conflicting features, their lack of consideration for the influence of bias terms, and an overly high sensitivity to local variations in the underpinning activation functions. Unlike other methods, CAFE provides safeguards against overestimating the effects of neuron inputs and separately traces positive and negative influences of input features and biases, resulting in enhanced robustness and increased ability to surface feature conflicts. We show experimentally that CAFE is better able to identify conflicting features on synthetic tabular data and exhibits the best overall fidelity on several real-world tabular datasets, while being highly computation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DHTM&#30340;&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#22240;&#23376;&#22270;&#24418;&#24335;&#21644;&#22810;&#32452;&#25104;&#31070;&#32463;&#20803;&#27169;&#22411;&#65292;&#21033;&#29992;&#20998;&#24067;&#24335;&#34920;&#31034;&#12289;&#31232;&#30095;&#36716;&#31227;&#30697;&#38453;&#21644;&#23616;&#37096;Hebbian&#26679;&#23398;&#20064;&#35268;&#21017;&#26469;&#35299;&#20915;&#22312;&#32447;&#38544;&#34255;&#34920;&#31034;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;DHTM&#22312;&#21464;&#21270;&#30340;&#29615;&#22659;&#20013;&#27604;&#32463;&#20856;&#30340;LSTM&#25928;&#26524;&#26356;&#22909;&#65292;&#24182;&#19982;&#26356;&#20808;&#36827;&#30340;&#31867;&#20284;RNN&#30340;&#31639;&#27861;&#24615;&#33021;&#30456;&#24403;&#65292;&#21487;&#20197;&#21152;&#36895;&#32487;&#20219;&#32773;&#34920;&#31034;&#30340;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.13391</link><description>&lt;p&gt;
&#20351;&#29992;&#20998;&#24067;&#24335;Hebbian Temporal Memory&#23398;&#20064;&#32487;&#20219;&#32773;&#34920;&#31034;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning Successor Representations with Distributed Hebbian Temporal Memory. (arXiv:2310.13391v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DHTM&#30340;&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#22240;&#23376;&#22270;&#24418;&#24335;&#21644;&#22810;&#32452;&#25104;&#31070;&#32463;&#20803;&#27169;&#22411;&#65292;&#21033;&#29992;&#20998;&#24067;&#24335;&#34920;&#31034;&#12289;&#31232;&#30095;&#36716;&#31227;&#30697;&#38453;&#21644;&#23616;&#37096;Hebbian&#26679;&#23398;&#20064;&#35268;&#21017;&#26469;&#35299;&#20915;&#22312;&#32447;&#38544;&#34255;&#34920;&#31034;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;DHTM&#22312;&#21464;&#21270;&#30340;&#29615;&#22659;&#20013;&#27604;&#32463;&#20856;&#30340;LSTM&#25928;&#26524;&#26356;&#22909;&#65292;&#24182;&#19982;&#26356;&#20808;&#36827;&#30340;&#31867;&#20284;RNN&#30340;&#31639;&#27861;&#24615;&#33021;&#30456;&#24403;&#65292;&#21487;&#20197;&#21152;&#36895;&#32487;&#20219;&#32773;&#34920;&#31034;&#30340;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#32447;&#38544;&#34255;&#34920;&#31034;&#23398;&#20064;&#30340;&#25361;&#25112;&#65292;&#35813;&#26041;&#27861;&#29992;&#20110;&#22312;&#19981;&#31283;&#23450;&#30340;&#12289;&#37096;&#20998;&#21487;&#35266;&#27979;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#20915;&#31574;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#65292;&#20998;&#24067;&#24335;Hebbian Temporal Memory (DHTM)&#65292;&#22522;&#20110;&#22240;&#23376;&#22270;&#24418;&#24335;&#21644;&#22810;&#32452;&#25104;&#31070;&#32463;&#20803;&#27169;&#22411;&#12290;DHTM&#26088;&#22312;&#25429;&#25417;&#39034;&#24207;&#25968;&#25454;&#20851;&#31995;&#24182;&#23545;&#26410;&#26469;&#35266;&#23519;&#20316;&#20986;&#32047;&#31215;&#39044;&#27979;&#65292;&#24418;&#25104;&#32487;&#20219;&#32773;&#34920;&#31034;&#12290;&#21463;&#26032;&#30382;&#23618;&#30340;&#31070;&#32463;&#29983;&#29702;&#23398;&#27169;&#22411;&#21551;&#21457;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20998;&#24067;&#24335;&#34920;&#31034;&#12289;&#31232;&#30095;&#36716;&#31227;&#30697;&#38453;&#21644;&#23616;&#37096;Hebbian&#26679;&#23398;&#20064;&#35268;&#21017;&#20811;&#26381;&#20102;&#20256;&#32479;&#26102;&#38388;&#35760;&#24518;&#31639;&#27861;&#65288;&#22914;RNN&#21644;HMM&#65289;&#30340;&#19981;&#31283;&#23450;&#24615;&#21644;&#24930;&#36895;&#23398;&#20064;&#36807;&#31243;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;DHTM&#20248;&#20110;&#32463;&#20856;&#30340;LSTM&#65292;&#24182;&#19982;&#26356;&#20808;&#36827;&#30340;&#31867;&#20284;RNN&#30340;&#31639;&#27861;&#24615;&#33021;&#30456;&#24403;&#65292;&#22312;&#21464;&#21270;&#30340;&#29615;&#22659;&#20013;&#21152;&#36895;&#20102;&#32487;&#20219;&#32773;&#34920;&#31034;&#30340;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel approach to address the challenge of online hidden representation learning for decision-making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism and a multicomponent neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Representation (SR). Inspired by neurophysiological models of the neocortex, the algorithm utilizes distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning process of traditional temporal memory algorithms like RNN and HMM. Experimental results demonstrate that DHTM outperforms classical LSTM and performs comparably to more advanced RNN-like algorithms, speeding up Temporal Difference learning for SR in changing environments. Additionally, we compare
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#19981;&#21516;&#30340;&#22270;&#25299;&#25169;&#23384;&#22312;&#19979;&#65292;&#22270;&#25193;&#25955;&#26041;&#31243;&#22914;&#20309;&#23545;GNN&#36827;&#34892;&#22806;&#25512;&#21644;&#27010;&#25324;&#65292;&#25581;&#31034;&#20102;&#22522;&#20110;&#23616;&#37096;&#25193;&#25955;&#30340;&#29616;&#26377;&#27169;&#22411;&#22312;&#27010;&#25324;&#33021;&#21147;&#19978;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#38750;&#23616;&#37096;&#25193;&#25955;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.06417</link><description>&lt;p&gt;
&#29992;&#20110;&#22270;&#23398;&#20064;&#20013;&#30340;&#25299;&#25169;&#27010;&#25324;&#30340;&#27969;&#21160;&#25193;&#25955;&#21464;&#21387;&#22120;
&lt;/p&gt;
&lt;p&gt;
Advective Diffusion Transformers for Topological Generalization in Graph Learning. (arXiv:2310.06417v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#19981;&#21516;&#30340;&#22270;&#25299;&#25169;&#23384;&#22312;&#19979;&#65292;&#22270;&#25193;&#25955;&#26041;&#31243;&#22914;&#20309;&#23545;GNN&#36827;&#34892;&#22806;&#25512;&#21644;&#27010;&#25324;&#65292;&#25581;&#31034;&#20102;&#22522;&#20110;&#23616;&#37096;&#25193;&#25955;&#30340;&#29616;&#26377;&#27169;&#22411;&#22312;&#27010;&#25324;&#33021;&#21147;&#19978;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#38750;&#23616;&#37096;&#25193;&#25955;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#25193;&#25955;&#26041;&#31243;&#19982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#23494;&#20999;&#30456;&#20851;&#65292;&#24182;&#19988;&#26368;&#36817;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#20316;&#20026;&#20998;&#26512;GNN&#21160;&#21147;&#23398;&#12289;&#24418;&#24335;&#21270;&#20854;&#34920;&#36798;&#33021;&#21147;&#21644;&#35777;&#26126;&#26550;&#26500;&#36873;&#25321;&#30340;&#26377;&#21407;&#21017;&#30340;&#26694;&#26550;&#12290;&#22270;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;GNN&#30340;&#27010;&#25324;&#33021;&#21147;&#12290;&#24403;&#21069;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#38480;&#21046;&#22312;&#20110;&#20551;&#35774;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20013;&#30340;&#22270;&#25299;&#25169;&#26469;&#33258;&#30456;&#21516;&#30340;&#20998;&#24067;&#12290;&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#22270;&#25193;&#25955;&#26041;&#31243;&#22312;&#19981;&#21516;&#22270;&#25299;&#25169;&#23384;&#22312;&#19979;&#30340;&#22806;&#25512;&#21644;&#27010;&#25324;&#33021;&#21147;&#65292;&#36808;&#20986;&#20102;&#35299;&#26512;GNN&#27010;&#25324;&#24615;&#30340;&#19968;&#27493;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22522;&#20110;&#22270;&#19978;&#23616;&#37096;&#25193;&#25955;&#30340;&#29616;&#26377;&#27169;&#22411;&#22312;&#27010;&#25324;&#33021;&#21147;&#19978;&#30340;&#19981;&#36275;&#65292;&#36825;&#26159;&#30001;&#20110;&#23545;&#25299;&#25169;&#21464;&#21270;&#30340;&#25351;&#25968;&#25935;&#24863;&#24615;&#24341;&#36215;&#30340;&#12290;&#38543;&#21518;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#38750;&#23616;&#37096;&#25193;&#25955;&#30340;&#28508;&#21147;&#65292;&#23427;&#20513;&#23548;&#23545;&#23436;&#20840;&#36830;&#25509;&#30340;&#28508;&#22312;&#22270;&#36827;&#34892;&#29305;&#24449;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph diffusion equations are intimately related to graph neural networks (GNNs) and have recently attracted attention as a principled framework for analyzing GNN dynamics, formalizing their expressive power, and justifying architectural choices. One key open questions in graph learning is the generalization capabilities of GNNs. A major limitation of current approaches hinges on the assumption that the graph topologies in the training and test sets come from the same distribution. In this paper, we make steps towards understanding the generalization of GNNs by exploring how graph diffusion equations extrapolate and generalize in the presence of varying graph topologies. We first show deficiencies in the generalization capability of existing models built upon local diffusion on graphs, stemming from the exponential sensitivity to topology variation. Our subsequent analysis reveals the promise of non-local diffusion, which advocates for feature propagation over fully-connected latent gr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#25214;&#21040;&#26368;&#20248;&#20915;&#31574;&#26641;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#22810;&#20010;&#21487;&#35299;&#37322;&#24615;-&#24615;&#33021;&#26435;&#34913;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#65292;&#20351;&#29992;&#25143;&#21487;&#20197;&#26681;&#25454;&#33258;&#24049;&#30340;&#38656;&#27714;&#36873;&#25321;&#26368;&#36866;&#21512;&#30340;&#26641;&#12290;</title><link>http://arxiv.org/abs/2309.12701</link><description>&lt;p&gt;
&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21457;&#29616;&#20915;&#31574;&#26641;&#30340;&#21487;&#35299;&#37322;&#24615;-&#24615;&#33021;&#24085;&#32047;&#25176;&#21069;&#27839;
&lt;/p&gt;
&lt;p&gt;
Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming. (arXiv:2309.12701v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#25214;&#21040;&#26368;&#20248;&#20915;&#31574;&#26641;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#22810;&#20010;&#21487;&#35299;&#37322;&#24615;-&#24615;&#33021;&#26435;&#34913;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#65292;&#20351;&#29992;&#25143;&#21487;&#20197;&#26681;&#25454;&#33258;&#24049;&#30340;&#38656;&#27714;&#36873;&#25321;&#26368;&#36866;&#21512;&#30340;&#26641;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20915;&#31574;&#26641;&#30001;&#20110;&#21487;&#20197;&#34987;&#20154;&#31867;&#26816;&#26597;&#21644;&#35299;&#37322;&#32780;&#20855;&#26377;&#22266;&#26377;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#27492;&#22806;&#65292;&#26368;&#36817;&#30828;&#20214;&#30340;&#36827;&#27493;&#37325;&#26032;&#24341;&#36215;&#20102;&#23545;&#26368;&#20248;&#20915;&#31574;&#26641;&#31639;&#27861;&#30340;&#20851;&#27880;&#65292;&#36825;&#20123;&#31639;&#27861;&#27604;&#36890;&#24120;&#30340;&#36138;&#23146;&#26041;&#27861;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#26641;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26368;&#20248;&#31639;&#27861;&#36820;&#22238;&#30340;&#26159;&#19968;&#20010;&#20248;&#21270;&#25163;&#21160;&#23450;&#20041;&#30340;&#21487;&#35299;&#37322;&#24615;-&#24615;&#33021;&#26435;&#34913;&#30340;&#21333;&#20010;&#26641;&#65292;&#36890;&#36807;&#25351;&#23450;&#26368;&#22823;&#20915;&#31574;&#33410;&#28857;&#25968;&#37327;&#26469;&#33719;&#24471;&#65292;&#23545;&#20110;&#36825;&#20010;&#26435;&#34913;&#30340;&#36136;&#37327;&#27809;&#26377;&#36827;&#19968;&#27493;&#30340;&#27934;&#23519;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#65288;MDP&#65289;&#24418;&#24335;&#26469;&#25214;&#21040;&#26368;&#20248;&#20915;&#31574;&#26641;&#12290;&#36825;&#31181;&#24418;&#24335;&#30340;&#20027;&#35201;&#20248;&#28857;&#26159;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#21333;&#19968;&#30340;&#21160;&#24577;&#35268;&#21010;&#38382;&#39064;&#35745;&#31639;&#20986;&#22810;&#20010;&#21487;&#35299;&#37322;&#24615;-&#24615;&#33021;&#26435;&#34913;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#65292;&#35753;&#29992;&#25143;&#20107;&#21518;&#36873;&#25321;&#26368;&#36866;&#21512;&#20182;&#20204;&#38656;&#27714;&#30340;&#26641;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#36816;&#34892;&#26102;&#38388;&#26041;&#38754;&#19982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#31454;&#20105;&#21147;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision trees are known to be intrinsically interpretable as they can be inspected and interpreted by humans. Furthermore, recent hardware advances have rekindled an interest for optimal decision tree algorithms, that produce more accurate trees than the usual greedy approaches. However, these optimal algorithms return a single tree optimizing a hand defined interpretability-performance trade-off, obtained by specifying a maximum number of decision nodes, giving no further insights about the quality of this trade-off. In this paper, we propose a new Markov Decision Problem (MDP) formulation for finding optimal decision trees. The main interest of this formulation is that we can compute the optimal decision trees for several interpretability-performance trade-offs by solving a single dynamic program, letting the user choose a posteriori the tree that best suits their needs. Empirically, we show that our method is competitive with state-of-the-art algorithms in terms of accuracy and run
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#27861;&#26469;&#25512;&#26029;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#36890;&#36807;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#65292;&#30456;&#20851;&#31639;&#27861;&#32463;&#36807;&#39564;&#35777;&#20855;&#26377;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.01835</link><description>&lt;p&gt;
&#20998;&#24067;&#26080;&#20851;&#25512;&#26029;&#20108;&#20803;&#20998;&#31867;&#30340;&#22238;&#24402;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Inference for the Regression Function of Binary Classification. (arXiv:2308.01835v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#27861;&#26469;&#25512;&#26029;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#36890;&#36807;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#65292;&#30456;&#20851;&#31639;&#27861;&#32463;&#36807;&#39564;&#35777;&#20855;&#26377;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#20803;&#20998;&#31867;&#30340;&#19968;&#20010;&#20851;&#38190;&#23545;&#35937;&#26159;&#22238;&#24402;&#20989;&#25968;&#65292;&#21363;&#32473;&#23450;&#36755;&#20837;&#30340;&#31867;&#21035;&#26631;&#31614;&#30340;&#26465;&#20214;&#26399;&#26395;&#12290;&#36890;&#36807;&#22238;&#24402;&#20989;&#25968;&#65292;&#19981;&#20165;&#21487;&#20197;&#23450;&#20041;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#65292;&#36824;&#21487;&#20197;&#32534;&#30721;&#23545;&#24212;&#30340;&#38169;&#35823;&#20998;&#31867;&#27010;&#29575;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#37319;&#26679;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#31934;&#30830;&#12289;&#20998;&#24067;&#26080;&#20851;&#19988;&#38750;&#28176;&#36817;&#20445;&#35777;&#30340;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#26681;&#25454;&#29992;&#25143;&#36873;&#25321;&#30340;&#32622;&#20449;&#27700;&#24179;&#12290;&#28982;&#21518;&#65292;&#25552;&#20986;&#20102;&#29305;&#23450;&#30340;&#31639;&#27861;&#26469;&#28436;&#31034;&#35813;&#26694;&#26550;&#12290;&#35777;&#26126;&#20102;&#26500;&#24314;&#30340;&#32622;&#20449;&#21306;&#38388;&#26159;&#24378;&#19968;&#33268;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#20219;&#20309;&#38169;&#35823;&#30340;&#27169;&#22411;&#26368;&#32456;&#34987;&#25490;&#38500;&#30340;&#27010;&#29575;&#20026;1&#12290;&#25490;&#38500;&#30340;&#31243;&#24230;&#20063;&#36890;&#36807;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#31867;&#22411;&#30340;&#30028;&#38480;&#36827;&#34892;&#20102;&#37327;&#21270;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#31639;&#27861;&#65292;&#24182;&#23558;&#26041;&#27861;&#19982;&#36817;&#20284;&#28176;&#36817;&#32622;&#20449;&#26925;&#22278;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the key objects of binary classification is the regression function, i.e., the conditional expectation of the class labels given the inputs. With the regression function not only a Bayes optimal classifier can be defined, but it also encodes the corresponding misclassification probabilities. The paper presents a resampling framework to construct exact, distribution-free and non-asymptotically guaranteed confidence regions for the true regression function for any user-chosen confidence level. Then, specific algorithms are suggested to demonstrate the framework. It is proved that the constructed confidence regions are strongly consistent, that is, any false model is excluded in the long run with probability one. The exclusion is quantified with probably approximately correct type bounds, as well. Finally, the algorithms are validated via numerical experiments, and the methods are compared to approximate asymptotic confidence ellipsoids.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#30456;&#20851;&#32852;&#30340;&#22270;&#20687;&#23545;AI&#29983;&#25104;&#25253;&#21578;&#36827;&#34892;&#20107;&#23454;&#26680;&#26597;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#21306;&#20998;&#25253;&#21578;&#20013;&#30340;&#30495;&#20551;&#21477;&#23376;&#12290;&#36825;&#23545;&#21152;&#24555;&#20020;&#24202;&#24037;&#20316;&#27969;&#31243;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#24182;&#38477;&#20302;&#24635;&#20307;&#25104;&#26412;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2307.14634</link><description>&lt;p&gt;
AI&#29983;&#25104;&#25253;&#21578;&#30340;&#20107;&#23454;&#26680;&#26597;
&lt;/p&gt;
&lt;p&gt;
Fact-Checking of AI-Generated Reports. (arXiv:2307.14634v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14634
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#30456;&#20851;&#32852;&#30340;&#22270;&#20687;&#23545;AI&#29983;&#25104;&#25253;&#21578;&#36827;&#34892;&#20107;&#23454;&#26680;&#26597;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#21306;&#20998;&#25253;&#21578;&#20013;&#30340;&#30495;&#20551;&#21477;&#23376;&#12290;&#36825;&#23545;&#21152;&#24555;&#20020;&#24202;&#24037;&#20316;&#27969;&#31243;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#24182;&#38477;&#20302;&#24635;&#20307;&#25104;&#26412;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#30340;&#36827;&#27493;&#65292;&#29616;&#22312;&#21487;&#20197;&#29983;&#25104;&#36924;&#30495;&#30340;&#33258;&#21160;&#25253;&#21578;&#26469;&#23545;&#25918;&#23556;&#23398;&#22270;&#20687;&#36827;&#34892;&#21021;&#27493;&#38405;&#35835;&#12290;&#36825;&#21487;&#20197;&#21152;&#24555;&#20020;&#24202;&#24037;&#20316;&#27969;&#31243;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#24182;&#38477;&#20302;&#24635;&#20307;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#36825;&#31181;&#27169;&#22411;&#24448;&#24448;&#20250;&#20135;&#29983;&#24187;&#35273;&#65292;&#23548;&#33268;&#29983;&#25104;&#25253;&#21578;&#20013;&#20986;&#29616;&#38169;&#35823;&#30340;&#21457;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#30456;&#20851;&#32852;&#30340;&#22270;&#20687;&#23545;AI&#29983;&#25104;&#25253;&#21578;&#36827;&#34892;&#20107;&#23454;&#26680;&#26597;&#30340;&#26032;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#23398;&#20064;&#22270;&#20687;&#19982;&#25551;&#36848;&#30495;&#23454;&#25110;&#28508;&#22312;&#34394;&#20551;&#21457;&#29616;&#30340;&#21477;&#23376;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#24320;&#21457;&#30340;&#26680;&#26597;&#32773;&#21306;&#20998;&#25253;&#21578;&#20013;&#30340;&#30495;&#20551;&#21477;&#23376;&#12290;&#20026;&#20102;&#35757;&#32451;&#36825;&#26679;&#30340;&#26680;&#26597;&#32773;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#25200;&#21160;&#21407;&#22987;&#19982;&#22270;&#20687;&#30456;&#20851;&#30340;&#25918;&#23556;&#23398;&#25253;&#21578;&#20013;&#30340;&#21457;&#29616;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#20266;&#36896;&#25253;&#21578;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#23558;&#26469;&#33258;&#36825;&#20123;&#25253;&#21578;&#30340;&#30495;&#20551;&#21477;&#23376;&#30340;&#25991;&#26412;&#32534;&#30721;&#19982;&#22270;&#20687;&#32534;&#30721;&#37197;&#23545;&#65292;&#23398;&#20064;&#26144;&#23556;&#21040;&#30495;/&#20551;&#26631;&#31614;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
With advances in generative artificial intelligence (AI), it is now possible to produce realistic-looking automated reports for preliminary reads of radiology images. This can expedite clinical workflows, improve accuracy and reduce overall costs. However, it is also well-known that such models often hallucinate, leading to false findings in the generated reports. In this paper, we propose a new method of fact-checking of AI-generated reports using their associated images. Specifically, the developed examiner differentiates real and fake sentences in reports by learning the association between an image and sentences describing real or potentially fake findings. To train such an examiner, we first created a new dataset of fake reports by perturbing the findings in the original ground truth radiology reports associated with images. Text encodings of real and fake sentences drawn from these reports are then paired with image encodings to learn the mapping to real/fake labels. The utility 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#24212;&#29992;&#20110;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#23454;&#29616;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#20381;&#36182;&#20110;RKHS&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.17329</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#22312;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Kernel $\epsilon$-Greedy for Contextual Bandits. (arXiv:2306.17329v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17329
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#24212;&#29992;&#20110;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#23454;&#29616;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#20381;&#36182;&#20110;RKHS&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#33218;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35748;&#20026;&#24179;&#22343;&#22870;&#21169;&#20989;&#25968;&#20301;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22870;&#21169;&#20989;&#25968;&#30340;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#12290;&#22312;&#23545;&#25506;&#32034;&#27010;&#29575;&#24207;&#21015;$\{\epsilon_t\}_t$&#21644;&#27491;&#21017;&#21270;&#21442;&#25968;$\{\lambda_t\}_t$&#30340;&#19968;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#26680;&#21644;&#30456;&#24212;&#30340;RKHS&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#20381;&#36182;&#20110;RKHS&#20869;&#22312;&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#12290;&#27492;&#22806;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;$\sqrt{T}$&#30340;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a kernelized version of the $\epsilon$-greedy strategy for contextual bandits. More precisely, in a setting with finitely many arms, we consider that the mean reward functions lie in a reproducing kernel Hilbert space (RKHS). We propose an online weighted kernel ridge regression estimator for the reward functions. Under some conditions on the exploration probability sequence, $\{\epsilon_t\}_t$, and choice of the regularization parameter, $\{\lambda_t\}_t$, we show that the proposed estimator is consistent. We also show that for any choice of kernel and the corresponding RKHS, we achieve a sub-linear regret rate depending on the intrinsic dimensionality of the RKHS. Furthermore, we achieve the optimal regret rate of $\sqrt{T}$ under a margin condition for finite-dimensional RKHS.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20351;&#29992;InceptionTime&#21644;ROCKET&#26041;&#27861;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#65292;&#20197;&#30417;&#27979;&#24085;&#37329;&#26862;&#30149;&#24739;&#32773;&#30340;&#25163;&#33109;&#36816;&#21160;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25152;&#26377;&#26041;&#27861;&#37117;&#36866;&#29992;&#20110;&#20272;&#35745;&#38663;&#39076;&#20005;&#37325;&#31243;&#24230;&#21644;&#32908;&#32905;&#24378;&#30452;&#30340;&#23384;&#22312;&#65292;&#20294;&#22312;&#26816;&#27979;&#36816;&#21160;&#38556;&#30861;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20855;&#26377;&#23725;&#20998;&#31867;&#22120;&#30340;InceptionTime&#26041;&#27861;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#20998;&#31867;&#24615;&#33021;&#65292;&#26174;&#31034;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#22312;&#22522;&#20110;&#21487;&#31359;&#25140;&#35774;&#22791;&#30340;PD&#30151;&#29366;&#30417;&#27979;&#20013;&#20855;&#26377;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.11265</link><description>&lt;p&gt;
&#25163;&#33109;&#21160;&#20316;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#29992;&#20110;&#24085;&#37329;&#26862;&#30149;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Time Series Classification for Detecting Parkinson's Disease from Wrist Motions. (arXiv:2304.11265v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11265
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20351;&#29992;InceptionTime&#21644;ROCKET&#26041;&#27861;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#65292;&#20197;&#30417;&#27979;&#24085;&#37329;&#26862;&#30149;&#24739;&#32773;&#30340;&#25163;&#33109;&#36816;&#21160;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25152;&#26377;&#26041;&#27861;&#37117;&#36866;&#29992;&#20110;&#20272;&#35745;&#38663;&#39076;&#20005;&#37325;&#31243;&#24230;&#21644;&#32908;&#32905;&#24378;&#30452;&#30340;&#23384;&#22312;&#65292;&#20294;&#22312;&#26816;&#27979;&#36816;&#21160;&#38556;&#30861;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20855;&#26377;&#23725;&#20998;&#31867;&#22120;&#30340;InceptionTime&#26041;&#27861;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#20998;&#31867;&#24615;&#33021;&#65292;&#26174;&#31034;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#22312;&#22522;&#20110;&#21487;&#31359;&#25140;&#35774;&#22791;&#30340;PD&#30151;&#29366;&#30417;&#27979;&#20013;&#20855;&#26377;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24085;&#37329;&#26862;&#30149;&#26159;&#19968;&#31181;&#31070;&#32463;&#36864;&#34892;&#24615;&#30142;&#30149;&#65292;&#20855;&#26377;&#39057;&#32321;&#21464;&#21270;&#30340;&#36816;&#21160;&#30151;&#29366;&#65292;&#25345;&#32493;&#30340;&#30151;&#29366;&#30417;&#27979;&#21487;&#20197;&#23454;&#29616;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#27835;&#30103;&#12290;&#20256;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20351;&#29992;&#21487;&#31359;&#25140;&#21152;&#36895;&#24230;&#35745;&#25968;&#25454;&#36827;&#34892;PD&#30151;&#29366;&#30417;&#27979;&#26102;&#24615;&#33021;&#26377;&#38480;&#65292;&#22240;&#20026;PD&#36816;&#21160;&#27169;&#24335;&#20855;&#26377;&#22797;&#26434;&#24615;&#65292;&#20294;&#25968;&#25454;&#38598;&#24456;&#23567;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;InceptionTime&#21644;RandOm&#21367;&#31215;&#26680;&#21464;&#25442;&#65288;ROCKET&#65289;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;TSC&#30340;&#26368;&#26032;&#25216;&#26415;&#65292;&#24182;&#19988;&#23545;&#20110;PD&#30151;&#29366;&#30417;&#27979;&#38750;&#24120;&#26377;&#21069;&#26223;&#65306;InceptionTime&#30340;&#39640;&#23398;&#20064;&#33021;&#21147;&#36866;&#29992;&#20110;&#24314;&#27169;&#22797;&#26434;&#36816;&#21160;&#27169;&#24335;&#65292;&#32780;ROCKET&#36866;&#29992;&#20110;&#23567;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#25628;&#32034;&#25214;&#21040;&#20102;&#26368;&#39640;&#24471;&#20998;&#30340;InceptionTime&#32467;&#26500;&#65292;&#24182;&#23558;&#20854;&#19982;&#20855;&#26377;&#23725;&#20998;&#31867;&#22120;&#21644;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#30340;ROCKET&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#29992;&#20110;PD&#24739;&#32773;&#30340;&#25163;&#33109;&#36816;&#21160;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25152;&#26377;&#26041;&#27861;&#37117;&#36866;&#29992;&#20110;&#20272;&#35745;&#38663;&#39076;&#20005;&#37325;&#31243;&#24230;&#21644;&#32908;&#32905;&#24378;&#30452;&#30340;&#23384;&#22312;&#65292;&#20294;&#22312;&#26816;&#27979;&#36816;&#21160;&#38556;&#30861;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20855;&#26377;&#23725;&#20998;&#31867;&#22120;&#30340;InceptionTime&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20998;&#31867;&#24615;&#33021;&#65292;&#23637;&#31034;&#20102;TSC&#22312;&#22522;&#20110;&#21487;&#31359;&#25140;&#35774;&#22791;&#30340;PD&#30151;&#29366;&#30417;&#27979;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parkinson's disease (PD) is a neurodegenerative disease with frequently changing motor symptoms where continuous symptom monitoring enables more targeted treatment. Classical time series classification (TSC) and deep learning techniques have limited performance for PD symptom monitoring using wearable accelerometer data because PD movement patterns are complex, but datasets are small. We investigate InceptionTime and RandOm Convolutional KErnel Transform (ROCKET) because they are state-of-the-art for TSC and promising for PD symptom monitoring: InceptionTime's high learning capacity is suited to modeling complex movement patterns while ROCKET is suited to small datasets. We used a random search to find the highest-scoring InceptionTime architecture and compared it to ROCKET with a ridge classifier and a multi-layer perceptron (MLP) on wrist motions of PD patients. We find that all approaches are suitable for estimating tremor severity and bradykinesia presence but struggle with detecti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#955;&#28436;&#31639;&#27861;&#65292;&#20351;&#29992;&#955;&#35821;&#35328;&#32534;&#31243;&#65292;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#25191;&#34892;&#25972;&#20010;&#31243;&#24207;&#30340;&#33021;&#21147;&#65292;&#26088;&#22312;&#25299;&#23637;&#31070;&#32463;&#32593;&#32476;&#22312;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.09276</link><description>&lt;p&gt;
&#19968;&#31181;&#31070;&#32463;&#955;&#28436;&#31639;&#27861;&#65306;&#31070;&#32463;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#36935;&#35265;&#35745;&#31639;&#21644;&#20989;&#25968;&#24335;&#32534;&#31243;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming. (arXiv:2304.09276v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#955;&#28436;&#31639;&#27861;&#65292;&#20351;&#29992;&#955;&#35821;&#35328;&#32534;&#31243;&#65292;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#25191;&#34892;&#25972;&#20010;&#31243;&#24207;&#30340;&#33021;&#21147;&#65292;&#26088;&#22312;&#25299;&#23637;&#31070;&#32463;&#32593;&#32476;&#22312;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#65292;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#25104;&#20026;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20027;&#23548;&#33539;&#24335;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#35748;&#20026;&#22312;&#31526;&#21495;&#23398;&#20064;&#20013;&#20351;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#26159;&#36234;&#26469;&#36234;&#30456;&#20851;&#30340;&#12290;&#20026;&#20102;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#33021;&#21147;&#65292;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#25506;&#32034;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#25968;&#23398;&#26500;&#36896;&#65288;&#22914;&#21152;&#27861;&#21644;&#20056;&#27861;&#65289;&#12289;&#36923;&#36753;&#25512;&#29702;&#65288;&#22914;&#23450;&#29702;&#35777;&#26126;&#22120;&#65289;&#29978;&#33267;&#25191;&#34892;&#35745;&#31639;&#26426;&#31243;&#24207;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#21518;&#32773;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#26469;&#35828;&#26159;&#22826;&#22797;&#26434;&#30340;&#20219;&#21153;&#65292;&#32467;&#26524;&#24182;&#19981;&#24635;&#26159;&#25104;&#21151;&#30340;&#65292;&#24182;&#19988;&#24448;&#24448;&#38656;&#35201;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#24341;&#20837;&#26377;&#20559;&#35265;&#30340;&#20803;&#32032;&#65292;&#20197;&#38480;&#21046;&#21487;&#33021;&#35201;&#25191;&#34892;&#30340;&#31243;&#24207;&#30340;&#33539;&#22260;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#22914;&#20309;&#25191;&#34892;&#25972;&#20010;&#31243;&#24207;&#30340;&#33021;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#19981;&#20351;&#29992;&#21629;&#20196;&#24335;&#32534;&#31243;&#35821;&#35328;&#65292;&#32780;&#26159;&#37319;&#29992;&#955;&#35821;&#35328;&#36827;&#34892;&#32534;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the last decades, deep neural networks based-models became the dominant paradigm in machine learning. Further, the use of artificial neural networks in symbolic learning has been seen as increasingly relevant recently. To study the capabilities of neural networks in the symbolic AI domain, researchers have explored the ability of deep neural networks to learn mathematical constructions, such as addition and multiplication, logic inference, such as theorem provers, and even the execution of computer programs. The latter is known to be too complex a task for neural networks. Therefore, the results were not always successful, and often required the introduction of biased elements in the learning process, in addition to restricting the scope of possible programs to be executed. In this work, we will analyze the ability of neural networks to learn how to execute programs as a whole. To do so, we propose a different approach. Instead of using an imperative programming language, with com
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17475</link><description>&lt;p&gt;
&#36229;&#36234;&#36127;&#37319;&#26679;&#30340;&#39640;&#25928;&#20998;&#24067;&#24335;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#20063;&#31216;&#20026;&#23884;&#20837;&#65289;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#20010;&#31867;&#20284;&#20110;Word2Vec&#31639;&#27861;&#20013;&#24341;&#20837;&#24182;&#22312;&#22810;&#20010;&#24037;&#20316;&#20013;&#37319;&#29992;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#23454;&#29616;&#12290;&#20248;&#21270;&#35745;&#31639;&#30340;&#29942;&#39048;&#26159;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#35745;&#31639;&#65292;&#36825;&#38656;&#35201;&#19982;&#26679;&#26412;&#22823;&#23567;&#21576;&#20108;&#27425;&#27604;&#20363;&#30340;&#25805;&#20316;&#25968;&#12290;&#36825;&#31181;&#22797;&#26434;&#24230;&#19981;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#25152;&#20197;&#36127;&#37319;&#26679;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19982;&#26679;&#26412;&#22823;&#23567;&#32447;&#24615;&#30456;&#20851;&#30340;&#26102;&#38388;&#20869;&#33719;&#24471;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36127;&#37319;&#26679;&#20250;&#25913;&#21464;&#25439;&#22833;&#20989;&#25968;&#65292;&#22240;&#27492;&#35299;&#20915;&#30340;&#26159;&#19982;&#26368;&#21021;&#25552;&#20986;&#30340;&#19981;&#21516;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#22312;&#20110;&#23637;&#31034;&#22914;&#20309;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#20174;&#32780;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23884;&#20837;&#36136;&#37327;&#21644;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#20248;&#20110;&#36127;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our ap
&lt;/p&gt;</description></item></channel></rss>