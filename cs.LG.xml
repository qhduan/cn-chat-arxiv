<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#23450;&#20041;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#31243;&#24207;&#20844;&#24179;&#24615;&#65292;&#25552;&#20986;&#20102;&#35780;&#20272;&#32676;&#20307;&#31243;&#24207;&#20844;&#24179;&#24615;&#30340;&#26032;&#24230;&#37327;&#26631;&#20934;$GPF_{FAE}$&#65292;&#24182;&#20351;&#29992;&#29305;&#24449;&#24402;&#22240;&#35299;&#37322;&#26469;&#25429;&#25417;&#20915;&#31574;&#36807;&#31243;&#65292;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#31243;&#24207;&#21644;&#20998;&#37197;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35782;&#21035;&#23548;&#33268;&#31243;&#24207;&#24615;&#19981;&#20844;&#24179;&#30340;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2404.01877</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31243;&#24207;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Procedural Fairness in Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23450;&#20041;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#31243;&#24207;&#20844;&#24179;&#24615;&#65292;&#25552;&#20986;&#20102;&#35780;&#20272;&#32676;&#20307;&#31243;&#24207;&#20844;&#24179;&#24615;&#30340;&#26032;&#24230;&#37327;&#26631;&#20934;$GPF_{FAE}$&#65292;&#24182;&#20351;&#29992;&#29305;&#24449;&#24402;&#22240;&#35299;&#37322;&#26469;&#25429;&#25417;&#20915;&#31574;&#36807;&#31243;&#65292;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#31243;&#24207;&#21644;&#20998;&#37197;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35782;&#21035;&#23548;&#33268;&#31243;&#24207;&#24615;&#19981;&#20844;&#24179;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20844;&#24179;&#24615;&#19968;&#30452;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#65292;&#28982;&#32780;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#27169;&#22411;&#30340;&#20998;&#37197;&#20844;&#24179;&#24615;&#19978;&#12290;&#21478;&#19968;&#20010;&#20844;&#24179;&#24615;&#32500;&#24230;&#65292;&#21363;&#31243;&#24207;&#20844;&#24179;&#24615;&#65292;&#21364;&#34987;&#24573;&#35270;&#20102;&#12290;&#26412;&#25991;&#39318;&#20808;&#23450;&#20041;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#31243;&#24207;&#20844;&#24179;&#24615;&#65292;&#28982;&#21518;&#32473;&#20986;&#20102;&#20010;&#20307;&#21644;&#32676;&#20307;&#31243;&#24207;&#20844;&#24179;&#24615;&#30340;&#27491;&#24335;&#23450;&#20041;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#32676;&#20307;&#31243;&#24207;&#20844;&#24179;&#24615;&#65292;&#31216;&#20026;$GPF_{FAE}$&#65292;&#23427;&#21033;&#29992;&#20102;&#19968;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#21363;&#29305;&#24449;&#24402;&#22240;&#35299;&#37322;&#65288;FAE&#65289;&#65292;&#26469;&#25429;&#25417;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20843;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;$GPF_{FAE}$&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#31243;&#24207;&#21644;&#20998;&#37197;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35782;&#21035;&#23548;&#33268;&#31243;&#24207;&#24615;&#19981;&#20844;&#24179;&#38382;&#39064;&#30340;&#29305;&#24449;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01877v1 Announce Type: new  Abstract: Fairness in machine learning (ML) has received much attention. However, existing studies have mainly focused on the distributive fairness of ML models. The other dimension of fairness, i.e., procedural fairness, has been neglected. In this paper, we first define the procedural fairness of ML models, and then give formal definitions of individual and group procedural fairness. We propose a novel metric to evaluate the group procedural fairness of ML models, called $GPF_{FAE}$, which utilizes a widely used explainable artificial intelligence technique, namely feature attribution explanation (FAE), to capture the decision process of the ML models. We validate the effectiveness of $GPF_{FAE}$ on a synthetic dataset and eight real-world datasets. Our experiments reveal the relationship between procedural and distributive fairness of the ML model. Based on our analysis, we propose a method for identifying the features that lead to the procedur
&lt;/p&gt;</description></item></channel></rss>