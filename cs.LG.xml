<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#21452;&#33258;&#21160;&#32534;&#30721;&#22120;&#27169;&#22411;(TAE)&#65292;&#36890;&#36807;&#23558;&#28508;&#22312;&#34920;&#31034;&#36716;&#25442;&#20026;&#21487;&#20998;&#31163;&#34920;&#31034;&#26469;&#35299;&#20915;&#32593;&#32476;&#25915;&#20987;&#26816;&#27979;&#20013;&#28151;&#21512;&#34920;&#31034;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.15509</link><description>&lt;p&gt;
&#21452;&#33258;&#21160;&#32534;&#30721;&#22120;&#27169;&#22411;&#29992;&#20110;&#23398;&#20064;&#32593;&#32476;&#25915;&#20987;&#26816;&#27979;&#20013;&#30340;&#21487;&#20998;&#31163;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Twin Auto-Encoder Model for Learning Separable Representation in Cyberattack Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15509
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#21452;&#33258;&#21160;&#32534;&#30721;&#22120;&#27169;&#22411;(TAE)&#65292;&#36890;&#36807;&#23558;&#28508;&#22312;&#34920;&#31034;&#36716;&#25442;&#20026;&#21487;&#20998;&#31163;&#34920;&#31034;&#26469;&#35299;&#20915;&#32593;&#32476;&#25915;&#20987;&#26816;&#27979;&#20013;&#28151;&#21512;&#34920;&#31034;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#24449;&#23398;&#20064;&#22312;&#32593;&#32476;&#25915;&#20987;&#26816;&#27979;&#31561;&#35768;&#22810;&#38382;&#39064;&#30340;&#25104;&#21151;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#22823;&#22810;&#25968;&#32593;&#32476;&#25915;&#20987;&#26816;&#27979;&#30340;&#34920;&#24449;&#23398;&#20064;&#26041;&#27861;&#22522;&#20110;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;AE&#65289;&#27169;&#22411;&#30340;&#28508;&#22312;&#21521;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;AEs&#34920;&#31034;&#20013;&#28151;&#21512;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21452;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;TAE&#65289;&#30340;&#26032;&#22411;&#27169;&#22411;&#12290;TAE&#23558;&#28508;&#22312;&#34920;&#31034;&#30830;&#23450;&#22320;&#36716;&#25442;&#20026;&#26356;&#26131;&#21306;&#20998;&#30340;&#34920;&#31034;&#65292;&#21363;\textit{&#21487;&#20998;&#31163;&#34920;&#31034;}&#65292;&#24182;&#22312;&#36755;&#20986;&#31471;&#37325;&#24314;&#21487;&#20998;&#31163;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15509v1 Announce Type: cross  Abstract: Representation Learning (RL) plays a pivotal role in the success of many problems including cyberattack detection. Most of the RL methods for cyberattack detection are based on the latent vector of Auto-Encoder (AE) models. An AE transforms raw data into a new latent representation that better exposes the underlying characteristics of the input data. Thus, it is very useful for identifying cyberattacks. However, due to the heterogeneity and sophistication of cyberattacks, the representation of AEs is often entangled/mixed resulting in the difficulty for downstream attack detection models. To tackle this problem, we propose a novel mod called Twin Auto-Encoder (TAE). TAE deterministically transforms the latent representation into a more distinguishable representation namely the \textit{separable representation} and the reconstructsuct the separable representation at the output. The output of TAE called the \textit{reconstruction represe
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;Tennessee Eastman Process&#12290;&#35843;&#30740;&#24635;&#32467;&#20102;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#31639;&#27861;&#30340;&#20248;&#21155;&#21183;&#12290;&#36824;&#35752;&#35770;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#21644;&#26080;&#26631;&#35760;&#26679;&#26412;&#31561;&#25361;&#25112;&#65292;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#24212;&#23545;&#12290;&#27604;&#36739;&#20102;&#19981;&#21516;&#31639;&#27861;&#22312;Tennessee Eastman Process&#19978;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;</title><link>http://arxiv.org/abs/2401.10266</link><description>&lt;p&gt;
&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;: &#26041;&#27861;&#35770;&#21644;&#19981;&#30830;&#23450;&#24615;&#31649;&#29702;&#31574;&#30053;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Intelligent Condition Monitoring of Industrial Plants: An Overview of Methodologies and Uncertainty Management Strategies. (arXiv:2401.10266v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;Tennessee Eastman Process&#12290;&#35843;&#30740;&#24635;&#32467;&#20102;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#31639;&#27861;&#30340;&#20248;&#21155;&#21183;&#12290;&#36824;&#35752;&#35770;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#21644;&#26080;&#26631;&#35760;&#26679;&#26412;&#31561;&#25361;&#25112;&#65292;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#24212;&#23545;&#12290;&#27604;&#36739;&#20102;&#19981;&#21516;&#31639;&#27861;&#22312;Tennessee Eastman Process&#19978;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29366;&#24577;&#30417;&#27979;&#22312;&#29616;&#20195;&#24037;&#19994;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#21644;&#21487;&#38752;&#24615;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#22312;&#24037;&#19994;&#24212;&#29992;&#20013;&#26085;&#30410;&#21463;&#21040;&#23398;&#26415;&#30028;&#21644;&#34892;&#19994;&#20851;&#27880;&#30340;&#22686;&#38271;&#20027;&#39064;&#21644;&#19968;&#31181;&#24378;&#22823;&#30340;&#25925;&#38556;&#35782;&#21035;&#26041;&#24335;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#24320;&#28304;&#22522;&#20934;Tennessee Eastman Process&#65288;TEP&#65289;&#12290;&#22312;&#36825;&#39033;&#35843;&#26597;&#20013;&#65292;&#24635;&#32467;&#20102;&#29992;&#20110;&#24037;&#19994;&#21378;&#25151;&#29366;&#24577;&#30417;&#27979;&#12289;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#30340;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#27599;&#31181;&#31639;&#27861;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#36824;&#28085;&#30422;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#12289;&#26080;&#26631;&#35760;&#26679;&#26412;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#22788;&#29702;&#36825;&#20123;&#25361;&#25112;&#12290;&#26368;&#21518;&#65292;&#27604;&#36739;&#20102;&#21033;&#29992;Tennessee Eastman Process&#30340;&#19981;&#21516;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;
Condition monitoring plays a significant role in the safety and reliability of modern industrial systems. Artificial intelligence (AI) approaches are gaining attention from academia and industry as a growing subject in industrial applications and as a powerful way of identifying faults. This paper provides an overview of intelligent condition monitoring and fault detection and diagnosis methods for industrial plants with a focus on the open-source benchmark Tennessee Eastman Process (TEP). In this survey, the most popular and state-of-the-art deep learning (DL) and machine learning (ML) algorithms for industrial plant condition monitoring, fault detection, and diagnosis are summarized and the advantages and disadvantages of each algorithm are studied. Challenges like imbalanced data, unlabelled samples and how deep learning models can handle them are also covered. Finally, a comparison of the accuracies and specifications of different algorithms utilizing the Tennessee Eastman Process 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#26377;&#38480;&#26102;&#38388;&#19981;&#22343;&#21248;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#20013;&#23454;&#29616;&#26497;&#23567;&#21518;&#24724;&#30340;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.13586</link><description>&lt;p&gt;
&#35299;&#20915;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Settling the Sample Complexity of Online Reinforcement Learning. (arXiv:2307.13586v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#26377;&#38480;&#26102;&#38388;&#19981;&#22343;&#21248;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#20013;&#23454;&#29616;&#26497;&#23567;&#21518;&#24724;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#25968;&#25454;&#25928;&#29575;&#12290;&#34429;&#28982;&#26368;&#36817;&#30340;&#19968;&#20123;&#24037;&#20316;&#22312;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#23454;&#29616;&#20102;&#28176;&#36817;&#26368;&#23567;&#30340;&#21518;&#24724;&#65292;&#20294;&#36825;&#20123;&#32467;&#26524;&#30340;&#26368;&#20248;&#24615;&#20165;&#22312;&#8220;&#22823;&#26679;&#26412;&#8221;&#24773;&#20917;&#19979;&#24471;&#21040;&#20445;&#35777;&#65292;&#20026;&#20102;&#20351;&#20854;&#31639;&#27861;&#36816;&#34892;&#26368;&#20339;&#65292;&#38656;&#35201;&#20184;&#20986;&#24040;&#22823;&#30340;&#39044;&#29123;&#25104;&#26412;&#12290;&#22914;&#20309;&#22312;&#19981;&#20135;&#29983;&#20219;&#20309;&#39044;&#29123;&#25104;&#26412;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26497;&#23567;&#21518;&#24724;&#30340;&#26368;&#20248;&#24615;&#19968;&#30452;&#26159;&#24378;&#21270;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#35299;&#20915;&#20102;&#26377;&#38480;&#26102;&#38388;&#19981;&#22343;&#21248;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#30340;&#36825;&#20010;&#38382;&#39064;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31181;&#20462;&#25913;&#29256;&#30340;&#21333;&#35843;&#20540;&#20256;&#25773;(MVP)&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26159;&#30001;\cite{zhang2020reinforcement}&#25552;&#20986;&#30340;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#20351;&#24471;&#21518;&#24724;&#30340;&#37327;&#32423;&#20026;(&#27169;&#38500;&#23545;&#25968;&#22240;&#23376;)\begin{equation *} \min\biggr\{ \sqrt{SAH^3K}&#65292;\&#65292;HK \biggr\}&#65292;\end{equation *}&#20854;&#20013;$S$&#26159;&#29366;&#24577;&#25968;&#65292;$A$&#26159;&#21160;&#20316;&#25968;&#65292;$H$&#26159;&#35268;&#21010;&#26102;&#22495;&#65292;$K$&#26159;&#24635;&#30340;&#22238;&#21512;&#25968;&#12290;&#36825;&#20010;&#21518;&#24724;&#30340;&#37327;&#32423;&#19982;&#26497;&#23567;&#21270;&#21518;&#24724;&#37327;&#32423;&#26159;&#30456;&#21305;&#37197;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
A central issue lying at the heart of online reinforcement learning (RL) is data efficiency. While a number of recent works achieved asymptotically minimal regret in online RL, the optimality of these results is only guaranteed in a ``large-sample'' regime, imposing enormous burn-in cost in order for their algorithms to operate optimally. How to achieve minimax-optimal regret without incurring any burn-in cost has been an open problem in RL theory.  We settle this problem for the context of finite-horizon inhomogeneous Markov decision processes. Specifically, we prove that a modified version of Monotonic Value Propagation (MVP), a model-based algorithm proposed by \cite{zhang2020reinforcement}, achieves a regret on the order of (modulo log factors) \begin{equation*}  \min\big\{ \sqrt{SAH^3K}, \,HK \big\}, \end{equation*} where $S$ is the number of states, $A$ is the number of actions, $H$ is the planning horizon, and $K$ is the total number of episodes. This regret matches the minimax 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#19982;&#22810;&#38754;&#20307;&#29702;&#35770;&#30340;&#20132;&#21449;&#39046;&#22495;&#12290;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#31561;&#20989;&#25968;&#20351;&#24471;&#19968;&#20123;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#33021;&#22815;&#36890;&#36807;&#22810;&#38754;&#20307;&#29702;&#35770;&#36827;&#34892;&#20998;&#26512;&#65292;&#24212;&#29992;&#32447;&#24615;&#21644;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#26469;&#23454;&#29616;&#32593;&#32476;&#20462;&#21098;&#12289;&#40065;&#26834;&#24615;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#39564;&#35777;&#31561;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.00241</link><description>&lt;p&gt;
&#24403;&#28145;&#24230;&#23398;&#20064;&#36935;&#35265;&#22810;&#38754;&#20307;&#29702;&#35770;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
When Deep Learning Meets Polyhedral Theory: A Survey. (arXiv:2305.00241v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#19982;&#22810;&#38754;&#20307;&#29702;&#35770;&#30340;&#20132;&#21449;&#39046;&#22495;&#12290;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#31561;&#20989;&#25968;&#20351;&#24471;&#19968;&#20123;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#33021;&#22815;&#36890;&#36807;&#22810;&#38754;&#20307;&#29702;&#35770;&#36827;&#34892;&#20998;&#26512;&#65292;&#24212;&#29992;&#32447;&#24615;&#21644;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#26469;&#23454;&#29616;&#32593;&#32476;&#20462;&#21098;&#12289;&#40065;&#26834;&#24615;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#39564;&#35777;&#31561;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#28145;&#24230;&#23398;&#20064;&#25104;&#20026;&#20102;&#39044;&#27979;&#24314;&#27169;&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#24471;&#30410;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#20219;&#21153;&#20013;&#30340;&#26174;&#33879;&#20934;&#30830;&#24615;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26500;&#22238;&#24402;&#21040;&#20102;&#22522;&#20110;&#20998;&#27573;&#24120;&#25968;&#21644;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#30340;&#31616;&#21333;&#34920;&#31034;&#65292;&#20363;&#22914;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#65292;&#36825;&#31181;&#28608;&#27963;&#20989;&#25968;&#25104;&#20026;&#31070;&#32463;&#32593;&#32476;&#20013;&#26368;&#24120;&#29992;&#30340;&#31867;&#22411;&#12290;&#36825;&#20351;&#24471;&#26576;&#20123;&#31867;&#22411;&#30340;&#32593;&#32476;&#32467;&#26500;&#65292;&#22914;&#20856;&#22411;&#30340;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65292;&#33021;&#22815;&#36890;&#36807;&#22810;&#38754;&#20307;&#29702;&#35770;&#36827;&#34892;&#20998;&#26512;&#65292;&#24182;&#24212;&#29992;&#32447;&#24615;&#35268;&#21010;&#65288;LP&#65289;&#21644;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#65288;MILP&#65289;&#31561;&#26041;&#27861;&#29992;&#20110;&#21508;&#31181;&#30446;&#30340;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#36825;&#20010;&#24555;&#36895;&#21457;&#23637;&#39046;&#22495;&#28044;&#29616;&#30340;&#20027;&#35201;&#20027;&#39064;&#65292;&#20026;&#26356;&#35814;&#32454;&#22320;&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20197;&#21450;&#24212;&#29992;&#25968;&#23398;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#22810;&#38754;&#20307;&#29702;&#35770;&#30340;&#22522;&#30784;&#30693;&#35782;&#20197;&#21450;&#23427;&#19982;&#28145;&#24230;&#23398;&#20064;&#30340;&#20851;&#31995;&#65292;&#24182;&#22238;&#39038;&#20102;&#35813;&#20027;&#39064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21253;&#25324;&#22312;&#32593;&#32476;&#20462;&#21098;&#12289;&#40065;&#26834;&#24615;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#39564;&#35777;&#31561;&#20219;&#21153;&#20013;&#20351;&#29992;LP&#21644;MILP&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#24403;&#21069;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the past decade, deep learning became the prevalent methodology for predictive modeling thanks to the remarkable accuracy of deep neural networks in tasks such as computer vision and natural language processing. Meanwhile, the structure of neural networks converged back to simpler representations based on piecewise constant and piecewise linear functions such as the Rectified Linear Unit (ReLU), which became the most commonly used type of activation function in neural networks. That made certain types of network structure $\unicode{x2014}$such as the typical fully-connected feedforward neural network$\unicode{x2014}$ amenable to analysis through polyhedral theory and to the application of methodologies such as Linear Programming (LP) and Mixed-Integer Linear Programming (MILP) for a variety of purposes. In this paper, we survey the main topics emerging from this fast-paced area of work, which bring a fresh perspective to understanding neural networks in more detail as well as to app
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#40065;&#26834;&#30340;&#33258;&#36866;&#24212; $\tau$-Lasso &#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20197;&#38477;&#20302;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#23427;&#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2304.09310</link><description>&lt;p&gt;
&#33258;&#36866;&#24212; $\tau$-Lasso&#65306;&#20854;&#20581;&#22766;&#24615;&#21644;&#26368;&#20248;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Adaptive $\tau$-Lasso: Its Robustness and Oracle Properties. (arXiv:2304.09310v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#40065;&#26834;&#30340;&#33258;&#36866;&#24212; $\tau$-Lasso &#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20197;&#38477;&#20302;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#23427;&#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#26032;&#22411;&#27491;&#21017;&#21270;&#40065;&#26834; $\tau$-&#22238;&#24402;&#20272;&#35745;&#22120;&#65292;&#20197;&#24212;&#23545;&#21709;&#24212;&#21464;&#37327;&#21644;&#21327;&#21464;&#37327;&#30340;&#20005;&#37325;&#27745;&#26579;&#12290;&#25105;&#20204;&#31216;&#36825;&#31181;&#20272;&#35745;&#22120;&#20026;&#33258;&#36866;&#24212; $\tau$-Lasso&#65292;&#23427;&#23545;&#24322;&#24120;&#20540;&#21644;&#39640;&#26464;&#26438;&#28857;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#26469;&#20943;&#23569;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20026;&#27599;&#20010;&#22238;&#24402;&#31995;&#25968;&#20998;&#37197;&#19968;&#20010;&#26435;&#37325;&#12290;&#23545;&#20110;&#22266;&#23450;&#25968;&#37327;&#30340;&#39044;&#27979;&#21464;&#37327; $p$&#65292;&#25105;&#20204;&#26174;&#31034;&#20986;&#33258;&#36866;&#24212; $\tau$-Lasso &#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;&#28982;&#21518;&#25105;&#20204;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#26029;&#28857;&#21644;&#24433;&#21709;&#20989;&#25968;&#26469;&#34920;&#24449;&#20854;&#20581;&#22766;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#26469;&#27604;&#36739;&#19981;&#21516;&#30340;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new regularized version of the robust $\tau$-regression estimator for analyzing high-dimensional data sets subject to gross contamination in the response variables and covariates. We call the resulting estimator adaptive $\tau$-Lasso that is robust to outliers and high-leverage points and simultaneously employs adaptive $\ell_1$-norm penalty term to reduce the bias associated with large true regression coefficients. More specifically, this adaptive $\ell_1$-norm penalty term assigns a weight to each regression coefficient. For a fixed number of predictors $p$, we show that the adaptive $\tau$-Lasso has the oracle property with respect to variable-selection consistency and asymptotic normality for the regression vector corresponding to the true support, assuming knowledge of the true regression vector support. We then characterize its robustness via the finite-sample breakdown point and the influence function. We carry-out extensive simulations to compare the per
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Prophet&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#31572;&#26696;&#21551;&#21457;&#24335;&#26041;&#24335;&#20419;&#20351;GPT-3&#35299;&#20915;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#38382;&#39064;&#12290;&#22312;&#29305;&#23450;&#30340;&#30693;&#35782;&#22411;VQA&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#19968;&#20010;&#32431;VQA&#27169;&#22411;&#65292;&#24182;&#20174;&#20013;&#25552;&#21462;&#20986;&#31572;&#26696;&#21551;&#21457;&#24335;&#65292;&#21487;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.01903</link><description>&lt;p&gt;
&#29992;&#31572;&#26696;&#21551;&#21457;&#24335;&#26041;&#24335;&#20419;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35299;&#20915;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering. (arXiv:2303.01903v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Prophet&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#31572;&#26696;&#21551;&#21457;&#24335;&#26041;&#24335;&#20419;&#20351;GPT-3&#35299;&#20915;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#38382;&#39064;&#12290;&#22312;&#29305;&#23450;&#30340;&#30693;&#35782;&#22411;VQA&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#19968;&#20010;&#32431;VQA&#27169;&#22411;&#65292;&#24182;&#20174;&#20013;&#25552;&#21462;&#20986;&#31572;&#26696;&#21551;&#21457;&#24335;&#65292;&#21487;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#38656;&#35201;&#36229;&#20986;&#22270;&#20687;&#33539;&#22260;&#30340;&#22806;&#37096;&#30693;&#35782;&#26469;&#22238;&#31572;&#38382;&#39064;&#12290;&#26089;&#26399;&#30340;&#30740;&#31350;&#20174;&#26174;&#24335;&#30693;&#35782;&#24211;&#65288;KBs&#65289;&#26816;&#32034;&#25152;&#38656;&#30340;&#30693;&#35782;&#65292;&#36825;&#32463;&#24120;&#20250;&#24341;&#20837;&#19982;&#38382;&#39064;&#26080;&#20851;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#35797;&#22270;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#21363;GPT-3&#65289;&#20316;&#20026;&#38544;&#21547;&#24335;&#30693;&#35782;&#24341;&#25806;&#26469;&#33719;&#21462;&#22238;&#31572;&#25152;&#38656;&#30340;&#24517;&#35201;&#30693;&#35782;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#21462;&#24471;&#20102;&#20196;&#20154;&#40723;&#33310;&#30340;&#32467;&#26524;&#65292;&#20294;&#25105;&#20204;&#35748;&#20026;&#23427;&#20204;&#36824;&#27809;&#26377;&#20805;&#20998;&#21457;&#25381;GPT-3&#30340;&#33021;&#21147;&#65292;&#22240;&#20026;&#25552;&#20379;&#30340;&#36755;&#20837;&#20449;&#24687;&#20173;&#28982;&#19981;&#36275;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Prophet&#8212;&#8212;&#19968;&#20010;&#27010;&#24565;&#19978;&#31616;&#21333;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22238;&#31572;&#21551;&#21457;&#24335;&#26041;&#24335;&#65292;&#20419;&#20351;GPT-3&#35299;&#20915;&#22522;&#20110;&#30693;&#35782;&#30340;VQA&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#22312;&#29305;&#23450;&#30340;&#22522;&#20110;&#30693;&#35782;&#30340;VQA&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#19968;&#20010;&#32431;VQA&#27169;&#22411;&#65292;&#32780;&#19981;&#20351;&#29992;&#22806;&#37096;&#30693;&#35782;&#12290;&#20043;&#21518;&#65292;&#25105;&#20204;&#20174;&#27169;&#22411;&#20013;&#25552;&#21462;&#20102;&#20004;&#31181;&#20114;&#34917;&#30340;&#31572;&#26696;&#21551;&#21457;&#24335;&#65306;&#31572;&#26696;&#20505;&#36873;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge-based visual question answering (VQA) requires external knowledge beyond the image to answer the question. Early studies retrieve required knowledge from explicit knowledge bases (KBs), which often introduces irrelevant information to the question, hence restricting the performance of their models. Recent works have sought to use a large language model (i.e., GPT-3) as an implicit knowledge engine to acquire the necessary knowledge for answering. Despite the encouraging results achieved by these methods, we argue that they have not fully activated the capacity of GPT-3 as the provided input information is insufficient. In this paper, we present Prophet -- a conceptually simple framework designed to prompt GPT-3 with answer heuristics for knowledge-based VQA. Specifically, we first train a vanilla VQA model on a specific knowledge-based VQA dataset without external knowledge. After that, we extract two types of complementary answer heuristics from the model: answer candidates 
&lt;/p&gt;</description></item></channel></rss>