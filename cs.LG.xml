<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#24066;&#22330;&#33829;&#38144;&#21160;&#24577;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#26041;&#31243;&#65292;&#20934;&#30830;&#25429;&#25417;&#20102;&#24191;&#21578;&#25903;&#20986;&#19982;&#28040;&#36153;&#32773;&#21453;&#24212;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.02175</link><description>&lt;p&gt;
&#28040;&#36153;&#32773;&#21453;&#24212;&#30340;&#31038;&#20250;&#21160;&#24577;&#65306;&#34701;&#21512;&#32479;&#35745;&#29289;&#29702;&#23398;&#19982;&#33829;&#38144;&#21160;&#24577;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Social Dynamics of Consumer Response: A Unified Framework Integrating Statistical Physics and Marketing Dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02175
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#24066;&#22330;&#33829;&#38144;&#21160;&#24577;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#26041;&#31243;&#65292;&#20934;&#30830;&#25429;&#25417;&#20102;&#24191;&#21578;&#25903;&#20986;&#19982;&#28040;&#36153;&#32773;&#21453;&#24212;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#28040;&#36153;&#32773;&#23545;&#24191;&#21578;&#36755;&#20837;&#30340;&#21453;&#24212;&#23545;&#20110;&#26088;&#22312;&#20248;&#21270;&#24191;&#21578;&#31574;&#30053;&#24182;&#25552;&#39640;&#24191;&#21578;&#27963;&#21160;&#26377;&#25928;&#24615;&#30340;&#33829;&#38144;&#20154;&#21592;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#24212;&#29992;&#28304;&#33258;&#29289;&#29702;&#23398;&#21644;&#31038;&#20250;&#24515;&#29702;&#23398;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#28040;&#36153;&#32773;&#34892;&#20026;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#26041;&#31243;&#65292;&#25429;&#25417;&#20102;&#24191;&#21578;&#25903;&#20986;&#19982;&#28040;&#36153;&#32773;&#21453;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21033;&#29992;&#20102;&#35832;&#22914;&#23545;&#31216;&#24615;&#12289;&#26631;&#24230;&#24459;&#21644;&#30456;&#21464;&#31561;&#27010;&#24565;&#12290;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;&#26041;&#31243;&#39564;&#35777;&#19982;Michaelis-Menten&#21644;Hill&#26041;&#31243;&#31561;&#33879;&#21517;&#27169;&#22411;&#30456;&#27604;&#36739;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#22312;&#20934;&#30830;&#34920;&#31034;&#28040;&#36153;&#32773;&#21453;&#24212;&#21160;&#24577;&#22797;&#26434;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20998;&#26512;&#24378;&#35843;&#20102;&#20851;&#38190;&#27169;&#22411;&#21442;&#25968;&#65288;&#22914;&#33829;&#38144;&#25928;&#26524;&#12289;&#21453;&#24212;&#25935;&#24863;&#24230;&#21644;&#34892;&#20026;&#25935;&#24863;&#24230;&#65289;&#23545;&#24433;&#21709;&#28040;&#36153;&#32773;&#34892;&#20026;&#30340;&#37325;&#35201;&#24615;&#12290;&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#24191;&#21578;&#21830;&#21644;&#33829;&#38144;&#20154;&#21592;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02175v1 Announce Type: cross  Abstract: Comprehending how consumers react to advertising inputs is essential for marketers aiming to optimize advertising strategies and improve campaign effectiveness. This study examines the complex nature of consumer behaviour by applying theoretical frameworks derived from physics and social psychology. We present an innovative equation that captures the relation between spending on advertising and consumer response, using concepts such as symmetries, scaling laws, and phase transitions. By validating our equation against well-known models such as the Michaelis-Menten and Hill equations, we prove its effectiveness in accurately representing the complexity of consumer response dynamics. The analysis emphasizes the importance of key model parameters, such as marketing effectiveness, response sensitivity, and behavioural sensitivity, in influencing consumer behaviour. The work explores the practical implications for advertisers and marketers,
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CMP&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;LiDAR&#20449;&#21495;&#20316;&#20026;&#36755;&#20837;&#65292;&#36890;&#36807;&#21512;&#20316;&#24863;&#30693;&#21644;&#36816;&#21160;&#39044;&#27979;&#27169;&#22359;&#20849;&#20139;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;&#21512;&#20316;&#36816;&#21160;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.17916</link><description>&lt;p&gt;
CMP&#65306;&#20855;&#26377;&#22810;&#26234;&#33021;&#20307;&#36890;&#20449;&#30340;&#21512;&#20316;&#36816;&#21160;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
CMP: Cooperative Motion Prediction with Multi-Agent Communication
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17916
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CMP&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;LiDAR&#20449;&#21495;&#20316;&#20026;&#36755;&#20837;&#65292;&#36890;&#36807;&#21512;&#20316;&#24863;&#30693;&#21644;&#36816;&#21160;&#39044;&#27979;&#27169;&#22359;&#20849;&#20139;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;&#21512;&#20316;&#36816;&#21160;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#65288;AVs&#65289;&#30340;&#21457;&#23637;&#21644;&#36710;&#32852;&#32593;&#65288;V2X&#65289;&#36890;&#20449;&#30340;&#25104;&#29087;&#65292;&#21512;&#20316;&#36830;&#25509;&#30340;&#33258;&#21160;&#21270;&#36710;&#36742;&#65288;CAVs&#65289;&#30340;&#21151;&#33021;&#21464;&#24471;&#21487;&#33021;&#12290;&#26412;&#25991;&#22522;&#20110;&#21512;&#20316;&#24863;&#30693;&#65292;&#25506;&#35752;&#20102;&#21512;&#20316;&#36816;&#21160;&#39044;&#27979;&#30340;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;CMP&#20197;LiDAR&#20449;&#21495;&#20316;&#20026;&#36755;&#20837;&#65292;&#20197;&#22686;&#24378;&#36319;&#36394;&#21644;&#39044;&#27979;&#33021;&#21147;&#12290;&#19982;&#36807;&#21435;&#19987;&#27880;&#20110;&#21512;&#20316;&#24863;&#30693;&#25110;&#36816;&#21160;&#39044;&#27979;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#26159;&#25105;&#20204;&#25152;&#30693;&#30340;&#31532;&#19968;&#20010;&#35299;&#20915;CAVs&#22312;&#24863;&#30693;&#21644;&#39044;&#27979;&#27169;&#22359;&#20013;&#20849;&#20139;&#20449;&#24687;&#30340;&#32479;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#35774;&#35745;&#20013;&#36824;&#34701;&#20837;&#20102;&#33021;&#22815;&#23481;&#24525;&#29616;&#23454;V2X&#24102;&#23485;&#38480;&#21046;&#21644;&#20256;&#36755;&#24310;&#36831;&#30340;&#29420;&#29305;&#33021;&#21147;&#65292;&#21516;&#26102;&#22788;&#29702;&#24222;&#22823;&#30340;&#24863;&#30693;&#34920;&#31034;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#39044;&#27979;&#32858;&#21512;&#27169;&#22359;&#65292;&#32479;&#19968;&#20102;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17916v1 Announce Type: cross  Abstract: The confluence of the advancement of Autonomous Vehicles (AVs) and the maturity of Vehicle-to-Everything (V2X) communication has enabled the capability of cooperative connected and automated vehicles (CAVs). Building on top of cooperative perception, this paper explores the feasibility and effectiveness of cooperative motion prediction. Our method, CMP, takes LiDAR signals as input to enhance tracking and prediction capabilities. Unlike previous work that focuses separately on either cooperative perception or motion prediction, our framework, to the best of our knowledge, is the first to address the unified problem where CAVs share information in both perception and prediction modules. Incorporated into our design is the unique capability to tolerate realistic V2X bandwidth limitations and transmission delays, while dealing with bulky perception representations. We also propose a prediction aggregation module, which unifies the predict
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#21270;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#26694;&#26550;&#65292;&#21487;&#22312;&#27169;&#22411;&#35757;&#32451;&#26399;&#38388;&#23545;&#29983;&#25104;&#26679;&#26412;&#26045;&#21152;&#32422;&#26463;&#65292;&#20197;&#25913;&#21892;&#26679;&#26412;&#19982;&#32422;&#26463;&#30340;&#23545;&#40784;&#31243;&#24230;&#24182;&#25552;&#20379;&#33258;&#28982;&#30340;&#27491;&#21017;&#21270;&#65292;&#36866;&#29992;&#24615;&#24191;&#27867;&#12290;</title><link>https://arxiv.org/abs/2403.14404</link><description>&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Physics-Informed Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14404
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#21270;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#26694;&#26550;&#65292;&#21487;&#22312;&#27169;&#22411;&#35757;&#32451;&#26399;&#38388;&#23545;&#29983;&#25104;&#26679;&#26412;&#26045;&#21152;&#32422;&#26463;&#65292;&#20197;&#25913;&#21892;&#26679;&#26412;&#19982;&#32422;&#26463;&#30340;&#23545;&#40784;&#31243;&#24230;&#24182;&#25552;&#20379;&#33258;&#28982;&#30340;&#27491;&#21017;&#21270;&#65292;&#36866;&#29992;&#24615;&#24191;&#27867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#22914;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#27491;&#24555;&#36895;&#25552;&#21319;&#20854;&#36924;&#36817;&#39640;&#24230;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#30340;&#33021;&#21147;&#12290;&#23427;&#20204;&#20063;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#36816;&#29992;&#20110;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#39044;&#26399;&#20174;&#38544;&#21547;&#25968;&#25454;&#20998;&#24067;&#20013;&#21462;&#26679;&#30340;&#26679;&#26412;&#23558;&#36981;&#23432;&#29305;&#23450;&#30340;&#25511;&#21046;&#26041;&#31243;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#27169;&#22411;&#35757;&#32451;&#26399;&#38388;&#23545;&#29983;&#25104;&#26679;&#26412;&#30340;&#22522;&#30784;&#32422;&#26463;&#36827;&#34892;&#20449;&#24687;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25913;&#21892;&#20102;&#29983;&#25104;&#26679;&#26412;&#19982;&#26045;&#21152;&#32422;&#26463;&#30340;&#23545;&#40784;&#31243;&#24230;&#65292;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#32780;&#19981;&#24433;&#21709;&#25512;&#29702;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21152;&#20837;&#36825;&#20123;&#32422;&#26463;&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#38450;&#27490;&#36807;&#25311;&#21512;&#30340;&#27491;&#21017;&#21270;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#26131;&#20110;&#23454;&#29616;&#65292;&#36866;&#29992;&#24615;&#24191;&#27867;&#65292;&#21487;&#29992;&#20110;&#26045;&#21152;&#31561;&#24335;&#21644;&#19981;&#31561;&#24335;&#32422;&#26463;&#20197;&#21450;&#36741;&#21161;&#20248;&#21270;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14404v1 Announce Type: new  Abstract: Generative models such as denoising diffusion models are quickly advancing their ability to approximate highly complex data distributions. They are also increasingly leveraged in scientific machine learning, where samples from the implied data distribution are expected to adhere to specific governing equations. We present a framework to inform denoising diffusion models on underlying constraints on such generated samples during model training. Our approach improves the alignment of the generated samples with the imposed constraints and significantly outperforms existing methods without affecting inference speed. Additionally, our findings suggest that incorporating such constraints during training provides a natural regularization against overfitting. Our framework is easy to implement and versatile in its applicability for imposing equality and inequality constraints as well as auxiliary optimization objectives.
&lt;/p&gt;</description></item><item><title>&#35774;&#35745;&#20102;&#19968;&#31181;&#22312;&#26080;&#32447;&#36793;&#32536;&#32593;&#32476;&#20013;&#20026;&#35774;&#22791;&#21160;&#24577;&#36873;&#25321;&#20998;&#35010;&#28857;&#24182;&#20026;&#26381;&#21153;&#22120;&#20998;&#37197;&#35745;&#31639;&#36164;&#28304;&#30340;&#33258;&#36866;&#24212;&#20998;&#35010;&#23398;&#20064;&#26041;&#26696;&#65292;&#20197;&#26368;&#23567;&#21270;&#24179;&#22343;&#35757;&#32451;&#24310;&#36831;&#20026;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;OPEN&#30340;&#22312;&#32447;&#31639;&#27861;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.05158</link><description>&lt;p&gt;
&#33021;&#37327;&#21463;&#38480;&#30340;&#26080;&#32447;&#36793;&#32536;&#32593;&#32476;&#20013;&#30340;&#33258;&#36866;&#24212;&#20998;&#35010;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adaptive Split Learning over Energy-Constrained Wireless Edge Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05158
&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20102;&#19968;&#31181;&#22312;&#26080;&#32447;&#36793;&#32536;&#32593;&#32476;&#20013;&#20026;&#35774;&#22791;&#21160;&#24577;&#36873;&#25321;&#20998;&#35010;&#28857;&#24182;&#20026;&#26381;&#21153;&#22120;&#20998;&#37197;&#35745;&#31639;&#36164;&#28304;&#30340;&#33258;&#36866;&#24212;&#20998;&#35010;&#23398;&#20064;&#26041;&#26696;&#65292;&#20197;&#26368;&#23567;&#21270;&#24179;&#22343;&#35757;&#32451;&#24310;&#36831;&#20026;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;OPEN&#30340;&#22312;&#32447;&#31639;&#27861;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#35010;&#23398;&#20064;&#65288;SL&#65289;&#26159;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#29992;&#20110;&#35757;&#32451;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#35774;&#22791;&#19982;&#26381;&#21153;&#22120;&#21512;&#20316;&#20197;&#20998;&#24067;&#24335;&#26041;&#24335;&#35757;&#32451;AI&#27169;&#22411;&#65292;&#22522;&#20110;&#30456;&#21516;&#30340;&#22266;&#23450;&#20998;&#35010;&#28857;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35774;&#22791;&#30340;&#24322;&#26500;&#24615;&#21644;&#20449;&#36947;&#26465;&#20214;&#30340;&#21464;&#21270;&#65292;&#36825;&#31181;&#26041;&#24335;&#22312;&#35757;&#32451;&#24310;&#36831;&#21644;&#33021;&#37327;&#28040;&#32791;&#26041;&#38754;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#20998;&#35010;&#23398;&#20064;&#65288;ASL&#65289;&#26041;&#26696;&#65292;&#21487;&#20197;&#22312;&#26080;&#32447;&#36793;&#32536;&#32593;&#32476;&#20013;&#20026;&#35774;&#22791;&#21160;&#24577;&#36873;&#25321;&#20998;&#35010;&#28857;&#65292;&#24182;&#20026;&#26381;&#21153;&#22120;&#20998;&#37197;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#22312;&#28385;&#36275;&#38271;&#26399;&#33021;&#37327;&#28040;&#32791;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#26368;&#23567;&#21270;&#24179;&#22343;&#35757;&#32451;&#24310;&#36831;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#22256;&#38590;&#22312;&#20110;&#32570;&#20047;&#26410;&#26469;&#20449;&#24687;&#21644;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;MIP&#65289;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;Lyapunov&#29702;&#35770;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#21517;&#20026;OPEN&#65292;&#23427;&#23558;&#20854;&#20998;&#35299;&#20026;&#19968;&#20010;&#20855;&#26377;&#24403;&#21069;&#30340;&#26032;MIP&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05158v1 Announce Type: cross  Abstract: Split learning (SL) is a promising approach for training artificial intelligence (AI) models, in which devices collaborate with a server to train an AI model in a distributed manner, based on a same fixed split point. However, due to the device heterogeneity and variation of channel conditions, this way is not optimal in training delay and energy consumption. In this paper, we design an adaptive split learning (ASL) scheme which can dynamically select split points for devices and allocate computing resource for the server in wireless edge networks. We formulate an optimization problem to minimize the average training latency subject to long-term energy consumption constraint. The difficulties in solving this problem are the lack of future information and mixed integer programming (MIP). To solve it, we propose an online algorithm leveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP problem only with the curren
&lt;/p&gt;</description></item><item><title>&#29992;&#21344;&#29992;&#24230;&#27979;&#37327;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#38450;&#27490;&#22870;&#21169;&#27450;&#39575;&#65292;&#36890;&#36807;&#32771;&#34385;&#20195;&#29702;&#19982;&#30495;&#23454;&#22870;&#21169;&#20043;&#38388;&#22823;&#30340;&#29366;&#24577;&#21344;&#29992;&#24230;&#20559;&#24046;&#26469;&#36991;&#20813;&#28508;&#22312;&#30340;&#28798;&#38590;&#21518;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.03185</link><description>&lt;p&gt;
&#29992;&#21344;&#29992;&#24230;&#27979;&#37327;&#27491;&#21017;&#21270;&#38450;&#27490;&#22870;&#21169;&#27450;&#39575;
&lt;/p&gt;
&lt;p&gt;
Preventing Reward Hacking with Occupancy Measure Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03185
&lt;/p&gt;
&lt;p&gt;
&#29992;&#21344;&#29992;&#24230;&#27979;&#37327;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#38450;&#27490;&#22870;&#21169;&#27450;&#39575;&#65292;&#36890;&#36807;&#32771;&#34385;&#20195;&#29702;&#19982;&#30495;&#23454;&#22870;&#21169;&#20043;&#38388;&#22823;&#30340;&#29366;&#24577;&#21344;&#29992;&#24230;&#20559;&#24046;&#26469;&#36991;&#20813;&#28508;&#22312;&#30340;&#28798;&#38590;&#21518;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20195;&#29702;&#26681;&#25454;&#19968;&#20010;&#8220;&#20195;&#29702;&#8221;&#22870;&#21169;&#20989;&#25968;&#65288;&#21487;&#33021;&#26159;&#25163;&#21160;&#25351;&#23450;&#25110;&#23398;&#20064;&#30340;&#65289;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#30456;&#23545;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#22870;&#21169;&#21364;&#34920;&#29616;&#31967;&#31957;&#26102;&#65292;&#23601;&#20250;&#21457;&#29983;&#22870;&#21169;&#27450;&#39575;&#12290;&#30001;&#20110;&#30830;&#20445;&#20195;&#29702;&#21644;&#30495;&#23454;&#22870;&#21169;&#20043;&#38388;&#33391;&#22909;&#23545;&#40784;&#26497;&#20026;&#22256;&#38590;&#65292;&#39044;&#38450;&#22870;&#21169;&#27450;&#39575;&#30340;&#19968;&#31181;&#26041;&#27861;&#26159;&#20445;&#23432;&#22320;&#20248;&#21270;&#20195;&#29702;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#29305;&#21035;&#20851;&#27880;&#20110;&#36890;&#36807;&#24809;&#32602;&#20182;&#20204;&#30340;&#34892;&#20026;&#20998;&#24067;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#26469;&#24378;&#21046;&#35753;&#23398;&#20064;&#21040;&#30340;&#31574;&#30053;&#34920;&#29616;&#31867;&#20284;&#20110;&#8220;&#23433;&#20840;&#8221;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#34892;&#20026;&#20998;&#24067;&#30340;&#27491;&#21017;&#21270;&#24182;&#19981;&#24635;&#26159;&#26377;&#25928;&#65292;&#22240;&#20026;&#22312;&#21333;&#20010;&#29366;&#24577;&#19979;&#34892;&#20026;&#20998;&#24067;&#30340;&#24494;&#23567;&#21464;&#21270;&#21487;&#33021;&#23548;&#33268;&#28508;&#22312;&#30340;&#28798;&#38590;&#24615;&#21518;&#26524;&#65292;&#32780;&#36739;&#22823;&#30340;&#21464;&#21270;&#21487;&#33021;&#24182;&#19981;&#20195;&#34920;&#20219;&#20309;&#21361;&#38505;&#27963;&#21160;&#12290;&#25105;&#20204;&#30340;&#35265;&#35299;&#26159;&#65292;&#24403;&#22870;&#21169;&#27450;&#39575;&#26102;&#65292;&#20195;&#29702;&#35775;&#38382;&#30340;&#29366;&#24577;&#19982;&#23433;&#20840;&#31574;&#30053;&#36798;&#21040;&#30340;&#29366;&#24577;&#25130;&#28982;&#19981;&#21516;&#65292;&#23548;&#33268;&#29366;&#24577;&#21344;&#29992;&#24230;&#30340;&#24040;&#22823;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03185v1 Announce Type: cross  Abstract: Reward hacking occurs when an agent performs very well with respect to a "proxy" reward function (which may be hand-specified or learned), but poorly with respect to the unknown true reward. Since ensuring good alignment between the proxy and true reward is extremely difficult, one approach to prevent reward hacking is optimizing the proxy conservatively. Prior work has particularly focused on enforcing the learned policy to behave similarly to a "safe" policy by penalizing the KL divergence between their action distributions (AD). However, AD regularization doesn't always work well since a small change in action distribution at a single state can lead to potentially calamitous outcomes, while large changes might not be indicative of any dangerous activity. Our insight is that when reward hacking, the agent visits drastically different states from those reached by the safe policy, causing large deviations in state occupancy measure (OM
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23454;&#26102;&#36882;&#24402;&#24378;&#21270;&#23398;&#20064;&#65288;RTRRL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20803;-&#24378;&#21270;&#23398;&#20064;RNN&#26550;&#26500;&#12289;&#22806;&#37096;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21644;RFLO&#23616;&#37096;&#22312;&#32447;&#23398;&#20064;&#65292;&#25104;&#21151;&#35299;&#20915;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#25955;&#21644;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#35745;&#31639;&#22797;&#26434;&#24615;&#30456;&#24403;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;BPTT&#25110;RTRL&#26367;&#20195;RTRRL&#20013;&#30340;&#20248;&#21270;&#31639;&#27861;&#24182;&#19981;&#33021;&#25552;&#39640;&#22238;&#25253;&#12290;</title><link>https://arxiv.org/abs/2311.04830</link><description>&lt;p&gt;
&#23454;&#26102;&#36882;&#24402;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Real-Time Recurrent Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04830
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23454;&#26102;&#36882;&#24402;&#24378;&#21270;&#23398;&#20064;&#65288;RTRRL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20803;-&#24378;&#21270;&#23398;&#20064;RNN&#26550;&#26500;&#12289;&#22806;&#37096;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21644;RFLO&#23616;&#37096;&#22312;&#32447;&#23398;&#20064;&#65292;&#25104;&#21151;&#35299;&#20915;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#25955;&#21644;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#35745;&#31639;&#22797;&#26434;&#24615;&#30456;&#24403;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;BPTT&#25110;RTRL&#26367;&#20195;RTRRL&#20013;&#30340;&#20248;&#21270;&#31639;&#27861;&#24182;&#19981;&#33021;&#25552;&#39640;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23454;&#26102;&#36882;&#24402;&#24378;&#21270;&#23398;&#20064;&#65288;RTRRL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#23545;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#20013;&#30340;&#31163;&#25955;&#21644;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#36827;&#34892;&#27714;&#35299;&#30340;&#29983;&#29289;&#23398;&#21512;&#29702;&#26041;&#27861;&#12290;RTRRL&#30001;&#19977;&#37096;&#20998;&#32452;&#25104;&#65306;&#65288;1&#65289;&#19968;&#20010;&#20803;-&#24378;&#21270;&#23398;&#20064;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#26550;&#26500;&#65292;&#29420;&#31435;&#23454;&#29616;&#20102;&#19968;&#20010;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#65307;&#65288;2&#65289;&#19968;&#20010;&#22806;&#37096;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;&#26102;&#24207;&#24046;&#20998;&#23398;&#20064;&#21644;&#33655;&#20848;&#36164;&#26684;&#36861;&#36394;&#26469;&#35757;&#32451;&#20803;-&#24378;&#21270;&#23398;&#20064;&#32593;&#32476;&#65307;&#21644;&#65288;3&#65289;&#38543;&#26426;&#21453;&#39304;&#23616;&#37096;&#22312;&#32447;&#65288;RFLO&#65289;&#23398;&#20064;&#65292;&#19968;&#31181;&#29992;&#20110;&#35745;&#31639;&#32593;&#32476;&#21442;&#25968;&#26799;&#24230;&#30340;&#22312;&#32447;&#33258;&#21160;&#24494;&#20998;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#23558;RTRRL&#20013;&#30340;&#20248;&#21270;&#31639;&#27861;&#26367;&#25442;&#20026;&#29983;&#29289;&#19981;&#21512;&#29702;&#30340;&#26102;&#24310;&#21453;&#21521;&#20256;&#25773;&#65288;BPTT&#65289;&#25110;&#23454;&#26102;&#36882;&#24402;&#23398;&#20064;&#65288;RTRL&#65289;&#65292;&#24182;&#19981;&#33021;&#25913;&#21892;&#22238;&#25253;&#65292;&#21516;&#26102;&#22312;&#21305;&#37197;BPTT&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#29978;&#33267;&#20250;&#22686;&#21152;&#36820;&#22238;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.04830v2 Announce Type: replace  Abstract: In this paper we propose real-time recurrent reinforcement learning (RTRRL), a biologically plausible approach to solving discrete and continuous control tasks in partially-observable markov decision processes (POMDPs). RTRRL consists of three parts: (1) a Meta-RL RNN architecture, implementing on its own an actor-critic algorithm; (2) an outer reinforcement learning algorithm, exploiting temporal difference learning and dutch eligibility traces to train the Meta-RL network; and (3) random-feedback local-online (RFLO) learning, an online automatic differentiation algorithm for computing the gradients with respect to parameters of the network.Our experimental results show that by replacing the optimization algorithm in RTRRL with the biologically implausible back propagation through time (BPTT), or real-time recurrent learning (RTRL), one does not improve returns, while matching the computational complexity for BPTT, and even increasi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#21327;&#35758;&#65292;&#21487;&#23398;&#20064;&#25552;&#31034;&#20316;&#20026;&#20266;&#25554;&#34917;&#65288;PAI&#65289;&#65292;&#36890;&#36807;&#26500;&#24314;&#21487;&#23398;&#20064;&#30340;&#25552;&#31034;&#26469;&#27169;&#25311;&#19979;&#28216;&#27169;&#22411;&#23545;&#32570;&#22833;&#20540;&#30340;&#38544;&#21547;&#20559;&#22909;&#65292;&#26174;&#33879;&#25552;&#21319;&#25152;&#26377;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20998;&#26512;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16796</link><description>&lt;p&gt;
&#21487;&#23398;&#20064;&#25552;&#31034;&#20316;&#20026;&#20266;&#25554;&#34917;&#26041;&#27861;&#65306;&#37325;&#26032;&#35780;&#20272;&#20256;&#32479;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#25554;&#34917;&#22312;&#19979;&#28216;&#20020;&#24202;&#39044;&#27979;&#20013;&#30340;&#24517;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learnable Prompt as Pseudo-Imputation: Reassessing the Necessity of Traditional EHR Data Imputation in Downstream Clinical Prediction. (arXiv:2401.16796v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16796
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#21327;&#35758;&#65292;&#21487;&#23398;&#20064;&#25552;&#31034;&#20316;&#20026;&#20266;&#25554;&#34917;&#65288;PAI&#65289;&#65292;&#36890;&#36807;&#26500;&#24314;&#21487;&#23398;&#20064;&#30340;&#25552;&#31034;&#26469;&#27169;&#25311;&#19979;&#28216;&#27169;&#22411;&#23545;&#32570;&#22833;&#20540;&#30340;&#38544;&#21547;&#20559;&#22909;&#65292;&#26174;&#33879;&#25552;&#21319;&#25152;&#26377;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20998;&#26512;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20998;&#26512;&#24739;&#32773;&#30340;&#20581;&#24247;&#29366;&#20917;&#26159;&#21307;&#23398;&#20449;&#24687;&#23398;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#30740;&#31350;&#38382;&#39064;&#12290;EHR&#20013;&#23384;&#22312;&#22823;&#37327;&#32570;&#22833;&#20540;&#65292;&#36825;&#20351;&#24471;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38590;&#20197;&#30452;&#25509;&#22522;&#20110;EHR&#27169;&#22411;&#21270;&#24739;&#32773;&#30340;&#20581;&#24247;&#29366;&#20917;&#12290;&#29616;&#26377;&#30340;&#28145;&#24230;&#23398;&#20064;&#35757;&#32451;&#21327;&#35758;&#38656;&#35201;&#20351;&#29992;&#32479;&#35745;&#20449;&#24687;&#25110;&#25554;&#34917;&#27169;&#22411;&#26469;&#37325;&#26500;&#32570;&#22833;&#20540;&#65292;&#28982;&#32780;&#65292;&#36825;&#20123;&#21327;&#35758;&#20250;&#23558;&#38750;&#29616;&#23454;&#30340;&#25968;&#25454;&#27880;&#20837;&#21040;&#19979;&#28216;EHR&#20998;&#26512;&#27169;&#22411;&#20013;&#65292;&#26497;&#22823;&#22320;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#21327;&#35758;&#8212;&#8212;&#21487;&#23398;&#20064;&#25552;&#31034;&#20316;&#20026;&#20266;&#25554;&#34917;&#65288;PAI&#65289;&#12290;PAI&#19981;&#20877;&#24341;&#20837;&#20219;&#20309;&#25554;&#34917;&#25968;&#25454;&#65292;&#32780;&#26159;&#26500;&#24314;&#19968;&#20010;&#21487;&#23398;&#20064;&#30340;&#25552;&#31034;&#26469;&#27169;&#25311;&#19979;&#28216;&#27169;&#22411;&#23545;&#32570;&#22833;&#20540;&#30340;&#38544;&#21547;&#20559;&#22909;&#65292;&#20174;&#32780;&#26174;&#33879;&#25552;&#39640;&#20102;&#25152;&#26377;EHR&#20998;&#26512;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#25968;&#25454;&#19981;&#36275;&#21644;&#39640;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;PAI&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Analyzing the health status of patients based on Electronic Health Records (EHR) is a fundamental research problem in medical informatics. The presence of extensive missing values in EHR makes it challenging for deep neural networks to directly model the patient's health status based on EHR. Existing deep learning training protocols require the use of statistical information or imputation models to reconstruct missing values; however, the protocols inject non-realistic data into downstream EHR analysis models, significantly limiting model performance. This paper introduces Learnable Prompt as Pseudo Imputation (PAI) as a new training protocol. PAI no longer introduces any imputed data but constructs a learnable prompt to model the implicit preferences of the downstream model for missing values, resulting in a significant performance improvement for all EHR analysis models. Additionally, our experiments show that PAI exhibits higher robustness in situations of data insufficiency and hig
&lt;/p&gt;</description></item><item><title>MoE-Infinity&#26159;&#19968;&#31181;&#25104;&#26412;&#39640;&#25928;&#30340;MoE&#26381;&#21153;&#31995;&#32479;&#65292;&#36890;&#36807;&#28608;&#27963;&#24863;&#30693;&#30340;&#19987;&#23478;&#21368;&#36733;&#21644;&#32531;&#23384;&#25216;&#26415;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#24310;&#36831;&#65292;&#24182;&#25552;&#39640;&#20102;&#25104;&#26412;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.14361</link><description>&lt;p&gt;
MoE-Infinity&#65306;&#29992;&#20110;&#39640;&#25928;MoE&#26381;&#21153;&#30340;&#28608;&#27963;&#24863;&#30693;&#19987;&#23478;&#21368;&#36733;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
MoE-Infinity: Activation-Aware Expert Offloading for Efficient MoE Serving. (arXiv:2401.14361v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14361
&lt;/p&gt;
&lt;p&gt;
MoE-Infinity&#26159;&#19968;&#31181;&#25104;&#26412;&#39640;&#25928;&#30340;MoE&#26381;&#21153;&#31995;&#32479;&#65292;&#36890;&#36807;&#28608;&#27963;&#24863;&#30693;&#30340;&#19987;&#23478;&#21368;&#36733;&#21644;&#32531;&#23384;&#25216;&#26415;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#24310;&#36831;&#65292;&#24182;&#25552;&#39640;&#20102;&#25104;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;MoE-Infinity&#65292;&#19968;&#31181;&#25104;&#26412;&#39640;&#25928;&#30340;&#19987;&#23478;&#28151;&#21512;(MoE)&#26381;&#21153;&#31995;&#32479;&#65292;&#23454;&#29616;&#20102;&#28608;&#27963;&#24863;&#30693;&#30340;&#19987;&#23478;&#21368;&#36733;&#12290;MoE-Infinity&#20855;&#26377;&#24207;&#21015;&#32423;&#19987;&#23478;&#28608;&#27963;&#36861;&#36394;&#30340;&#29305;&#28857;&#65292;&#36825;&#26159;&#19968;&#31181;&#25797;&#38271;&#35782;&#21035;&#31232;&#30095;&#28608;&#27963;&#24182;&#25429;&#25417;MoE&#25512;&#29702;&#30340;&#26102;&#38388;&#23616;&#37096;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#20998;&#26512;&#36825;&#20123;&#36861;&#36394;&#65292;MoE-Infinity&#25191;&#34892;&#20102;&#26032;&#39062;&#30340;&#28608;&#27963;&#24863;&#30693;&#19987;&#23478;&#39044;&#21462;&#21644;&#32531;&#23384;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#36890;&#24120;&#19982;&#21368;&#36733;&#19987;&#23478;&#30456;&#20851;&#30340;&#24310;&#36831;&#24320;&#38144;&#65292;&#25552;&#39640;&#20102;&#25104;&#26412;&#24615;&#33021;&#12290;&#22312;&#19968;&#20010;&#38598;&#32676;&#20013;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;MoE-Infinity&#20248;&#20110;&#35768;&#22810;&#29616;&#26377;&#30340;&#31995;&#32479;&#21644;&#26041;&#27861;&#65292;&#23545;&#20110;&#21508;&#31181;MoEs&#65292;&#23558;&#24310;&#36831;&#38477;&#20302;&#20102;420&#20493;&#65292;&#23558;&#37096;&#32626;&#25104;&#26412;&#38477;&#20302;&#20102;8&#20493;&#20197;&#19978;&#12290;MoE-Infinity&#30340;&#28304;&#20195;&#30721;&#21487;&#22312;https://github.com/TorchMoE/MoE-Infinity&#20844;&#24320;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents MoE-Infinity, a cost-efficient mixture-of-expert (MoE) serving system that realizes activation-aware expert offloading. MoE-Infinity features sequence-level expert activation tracing, a new approach adept at identifying sparse activations and capturing the temporal locality of MoE inference. By analyzing these traces, MoE-Infinity performs novel activation-aware expert prefetching and caching, substantially reducing the latency overheads usually associated with offloading experts for improved cost performance. Extensive experiments in a cluster show that MoE-Infinity outperforms numerous existing systems and approaches, reducing latency by 4 20X and decreasing deployment costs by over 8X for various MoEs. MoE-Infinity's source code is publicly available at https://github.com/TorchMoE/MoE-Infinity
&lt;/p&gt;</description></item><item><title>MoTCoder&#26159;&#19968;&#20010;&#20351;&#29992;&#24605;&#32500;&#27169;&#22359;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25361;&#25112;&#24615;&#32534;&#31243;&#20219;&#21153;&#20013;&#33021;&#21147;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21019;&#26032;&#30340;&#25351;&#20196;&#35843;&#25972;&#20419;&#36827;&#20219;&#21153;&#30340;&#20998;&#35299;&#21644;&#27169;&#22359;&#21270;&#65292;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#30340;&#20934;&#30830;&#24615;&#21644;&#27169;&#22359;&#21270;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2312.15960</link><description>&lt;p&gt;
MoTCoder: &#20351;&#29992;&#24605;&#32500;&#27169;&#22359;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#32534;&#31243;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
MoTCoder: Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks. (arXiv:2312.15960v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15960
&lt;/p&gt;
&lt;p&gt;
MoTCoder&#26159;&#19968;&#20010;&#20351;&#29992;&#24605;&#32500;&#27169;&#22359;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25361;&#25112;&#24615;&#32534;&#31243;&#20219;&#21153;&#20013;&#33021;&#21147;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21019;&#26032;&#30340;&#25351;&#20196;&#35843;&#25972;&#20419;&#36827;&#20219;&#21153;&#30340;&#20998;&#35299;&#21644;&#27169;&#22359;&#21270;&#65292;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#30340;&#20934;&#30830;&#24615;&#21644;&#27169;&#22359;&#21270;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22788;&#29702;&#31616;&#21333;&#30340;&#32534;&#31243;&#20219;&#21153;&#26041;&#38754;&#23637;&#31034;&#20986;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#32534;&#31243;&#38382;&#39064;&#26102;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#24448;&#24448;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#20256;&#32479;&#27169;&#22411;&#24448;&#24448;&#29983;&#25104;&#20316;&#20026;&#21333;&#19968;&#20195;&#30721;&#22359;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#35299;&#20915;&#22797;&#26434;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Modular-of-Thought Coder (MoTCoder)&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;MoT&#25351;&#20196;&#35843;&#25972;&#26694;&#26550;&#65292;&#26088;&#22312;&#20419;&#36827;&#23558;&#20219;&#21153;&#20998;&#35299;&#20026;&#36923;&#36753;&#23376;&#20219;&#21153;&#21644;&#23376;&#27169;&#22359;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#22521;&#20859;&#21644;&#21033;&#29992;&#23376;&#27169;&#22359;&#65292;MoTCoder&#26174;&#33879;&#25552;&#39640;&#20102;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#30340;&#27169;&#22359;&#21270;&#21644;&#27491;&#30830;&#24615;&#65292;&#23548;&#33268;&#22312;APPS&#19978;&#30456;&#23545;pass@1&#25913;&#36827;&#20102;12.9%&#65292;&#22312;CodeContests&#19978;&#30456;&#23545;pass@1&#25913;&#36827;&#20102;9.43%&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312;https://github.com/dvlab-research/MoTCoder&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have showcased impressive capabilities in handling straightforward programming tasks. However, their performance tends to falter when confronted with more challenging programming problems. We observe that conventional models often generate solutions as monolithic code blocks, restricting their effectiveness in tackling intricate questions. To overcome this limitation, we present Modular-of-Thought Coder (MoTCoder). We introduce a pioneering framework for MoT instruction tuning, designed to promote the decomposition of tasks into logical sub-tasks and sub-modules. Our investigations reveal that, through the cultivation and utilization of sub-modules, MoTCoder significantly improves both the modularity and correctness of the generated solutions, leading to substantial relative pass@1 improvements of 12.9% on APPS and 9.43% on CodeContests. Our codes are available at https://github.com/dvlab-research/MoTCoder.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22686;&#37327;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#36951;&#24536;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32852;&#37030;&#36951;&#24536;&#26041;&#27861;&#22312;&#26102;&#38388;&#25928;&#29575;&#12289;&#25968;&#25454;&#24433;&#21709;&#20272;&#35745;&#19981;&#31934;&#30830;&#21644;&#35745;&#31639;&#36127;&#33655;&#22823;&#31561;&#26041;&#38754;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.03363</link><description>&lt;p&gt;
&#36890;&#36807;&#20027;&#21160;&#36951;&#24536;&#23454;&#29616;&#32852;&#37030;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Federated Unlearning via Active Forgetting. (arXiv:2307.03363v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03363
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22686;&#37327;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#36951;&#24536;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32852;&#37030;&#36951;&#24536;&#26041;&#27861;&#22312;&#26102;&#38388;&#25928;&#29575;&#12289;&#25968;&#25454;&#24433;&#21709;&#20272;&#35745;&#19981;&#31934;&#30830;&#21644;&#35745;&#31639;&#36127;&#33655;&#22823;&#31561;&#26041;&#38754;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38544;&#31169;&#30340;&#20851;&#27880;&#26085;&#30410;&#22686;&#21152;&#65292;&#24341;&#21457;&#20102;&#23545;&#26426;&#22120;&#36951;&#24536;&#30340;&#25506;&#32034;&#65292;&#21363;&#19968;&#31181;&#28040;&#38500;&#35757;&#32451;&#25968;&#25454;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24433;&#21709;&#30340;&#36807;&#31243;&#12290;&#36825;&#31181;&#20851;&#27880;&#20063;&#20986;&#29616;&#22312;&#32852;&#37030;&#23398;&#20064;&#30340;&#39046;&#22495;&#65292;&#20419;&#20351;&#30740;&#31350;&#20154;&#21592;&#35299;&#20915;&#32852;&#37030;&#36951;&#24536;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#32852;&#37030;&#36951;&#24536;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#30340;&#36951;&#24536;&#26041;&#27861;&#21487;&#20197;&#34987;&#24191;&#27867;&#20998;&#20026;&#20004;&#31181;&#26041;&#27861;&#65292;&#21363;&#31934;&#30830;&#36951;&#24536;&#21644;&#36817;&#20284;&#36951;&#24536;&#12290;&#39318;&#20808;&#65292;&#22312;&#20998;&#24067;&#24335;&#24773;&#20917;&#19979;&#23454;&#26045;&#31934;&#30830;&#36951;&#24536;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#20998;&#21306;-&#32858;&#21512;&#26694;&#26550;&#65292;&#29702;&#35770;&#19978;&#19981;&#20250;&#25552;&#39640;&#26102;&#38388;&#25928;&#29575;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#30340;&#32852;&#37030;&#65288;&#36817;&#20284;&#65289;&#36951;&#24536;&#26041;&#27861;&#22312;&#25968;&#25454;&#24433;&#21709;&#20272;&#35745;&#19981;&#31934;&#30830;&#12289;&#35745;&#31639;&#36127;&#33655;&#22823;&#25110;&#20004;&#32773;&#37117;&#23384;&#22312;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22686;&#37327;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#36951;&#24536;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#19981;&#20381;&#36182;&#20110;&#20855;&#20307;&#30340;&#27169;&#22411;&#21644;&#32852;&#37030;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing concerns regarding the privacy of machine learning models have catalyzed the exploration of machine unlearning, i.e., a process that removes the influence of training data on machine learning models. This concern also arises in the realm of federated learning, prompting researchers to address the federated unlearning problem. However, federated unlearning remains challenging. Existing unlearning methods can be broadly categorized into two approaches, i.e., exact unlearning and approximate unlearning. Firstly, implementing exact unlearning, which typically relies on the partition-aggregation framework, in a distributed manner does not improve time efficiency theoretically. Secondly, existing federated (approximate) unlearning methods suffer from imprecise data influence estimation, significant computational burden, or both. To this end, we propose a novel federated unlearning framework based on incremental learning, which is independent of specific models and federated se
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#22270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23884;&#20837;&#33410;&#28857;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26497;&#23567;&#26497;&#22823;&#24418;&#24335;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#39118;&#38505;&#26469;&#25214;&#21040;&#26368;&#20248;&#33410;&#28857;&#23884;&#20837;&#65292;&#20174;&#32780;&#32531;&#35299;&#29616;&#23454;&#19990;&#30028;&#22270;&#20013;&#22122;&#22768;&#27979;&#37327;&#25361;&#25112;&#23545;&#22270;&#25968;&#25454;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.08210</link><description>&lt;p&gt;
&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22122;&#22768;&#22270;&#19978;&#30340;&#40065;&#26834;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Uncertainty-Aware Robust Learning on Noisy Graphs. (arXiv:2306.08210v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08210
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#22270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23884;&#20837;&#33410;&#28857;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26497;&#23567;&#26497;&#22823;&#24418;&#24335;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#39118;&#38505;&#26469;&#25214;&#21040;&#26368;&#20248;&#33410;&#28857;&#23884;&#20837;&#65292;&#20174;&#32780;&#32531;&#35299;&#29616;&#23454;&#19990;&#30028;&#22270;&#20013;&#22122;&#22768;&#27979;&#37327;&#25361;&#25112;&#23545;&#22270;&#25968;&#25454;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#35299;&#20915;&#21508;&#31181;&#22270;&#35745;&#31639;&#20219;&#21153;&#26041;&#38754;&#23637;&#29616;&#20102;&#20986;&#33394;&#30340;&#33021;&#21147;&#65292;&#29305;&#21035;&#26159;&#22312;&#33410;&#28857;&#20998;&#31867;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22270;&#20013;&#65292;&#25299;&#25169;&#25110;&#33410;&#28857;&#20449;&#24687;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#22122;&#22768;&#27979;&#37327;&#25361;&#25112;&#21487;&#33021;&#20250;&#24433;&#21709;&#20854;&#25928;&#26524;&#12290;&#35266;&#27979;&#20013;&#30340;&#36825;&#20123;&#19981;&#20934;&#30830;&#24615;&#21487;&#33021;&#20250;&#30772;&#22351;&#22270;&#25968;&#25454;&#20013;&#30340;&#20851;&#38190;&#27169;&#24335;&#65292;&#26368;&#32456;&#23548;&#33268;&#23454;&#38469;&#24212;&#29992;&#20013;&#19981;&#33391;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#22270;&#23398;&#20064;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#32534;&#30721;&#22120;&#26469;&#23884;&#20837;&#33410;&#28857;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26497;&#23567;&#26497;&#22823;&#24418;&#24335;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#39118;&#38505;&#26469;&#25214;&#21040;&#26368;&#20248;&#33410;&#28857;&#23884;&#20837;&#12290;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#23398;&#20064;&#36807;&#31243;&#23548;&#33268;&#20102;&#25913;&#36827;&#30340;&#33410;&#28857;&#34920;&#31034;&#21644;&#26356;&#24378;&#22766;&#30340;&#22270;&#39044;&#27979;&#27169;&#22411;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#20102;&#22270;&#25968;&#25454;&#20013;&#22122;&#22768;&#27979;&#37327;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks have shown impressive capabilities in solving various graph learning tasks, particularly excelling in node classification. However, their effectiveness can be hindered by the challenges arising from the widespread existence of noisy measurements associated with the topological or nodal information present in real-world graphs. These inaccuracies in observations can corrupt the crucial patterns within the graph data, ultimately resulting in undesirable performance in practical applications. To address these issues, this paper proposes a novel uncertainty-aware graph learning framework motivated by distributionally robust optimization. Specifically, we use a graph neural network-based encoder to embed the node features and find the optimal node embeddings by minimizing the worst-case risk through a minimax formulation. Such an uncertainty-aware learning process leads to improved node representations and a more robust graph predictive model that effectively mitigates
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#24341;&#20837;&#32593;&#32476;&#36890;&#20449;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#39640;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#23398;&#20064;&#25928;&#29575;&#30340;&#26041;&#26696;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#38469;&#23454;&#39564;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.02766</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#30340;&#32593;&#32476;&#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
Networked Communication for Decentralised Agents in Mean-Field Games. (arXiv:2306.02766v2 [cs.MA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#24341;&#20837;&#32593;&#32476;&#36890;&#20449;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#39640;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#23398;&#20064;&#25928;&#29575;&#30340;&#26041;&#26696;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#38469;&#23454;&#39564;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#32593;&#32476;&#36890;&#20449;&#24341;&#20837;&#22343;&#22330;&#21338;&#24328;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#22312;&#26080;oracle&#30340;&#24773;&#20917;&#19979;&#65292;N&#20010;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#27839;&#30528;&#32463;&#36807;&#30340;&#32463;&#39564;&#31995;&#32479;&#30340;&#21333;&#19968;&#38750;&#21608;&#26399;&#28436;&#21270;&#36335;&#24452;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26550;&#26500;&#22312;&#21482;&#26377;&#19968;&#20123;&#20851;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#21512;&#29702;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#26679;&#26412;&#20445;&#35777;&#65292;&#22312;&#38598;&#20013;&#23398;&#20064;&#21644;&#29420;&#31435;&#23398;&#20064;&#24773;&#20917;&#20043;&#38388;&#26377;&#30028;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#19977;&#20010;&#29702;&#35770;&#31639;&#27861;&#30340;&#26679;&#26412;&#20445;&#35777;&#23454;&#38469;&#19978;&#24182;&#19981;&#20250;&#23548;&#33268;&#23454;&#38469;&#25910;&#25947;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#35774;&#32622;&#20013;&#65292;&#24403;&#29702;&#35770;&#21442;&#25968;&#26410;&#34987;&#35266;&#23519;&#21040;&#65288;&#23548;&#33268;Q&#20989;&#25968;&#30340;&#20272;&#35745;&#19981;&#20934;&#30830;&#65289;&#26102;&#65292;&#25105;&#20204;&#30340;&#36890;&#20449;&#26041;&#26696;&#26174;&#33879;&#21152;&#36895;&#20102;&#25910;&#25947;&#36895;&#24230;&#65292;&#32780;&#26080;&#38656;&#20381;&#36182;&#20110;&#19968;&#20010;&#19981;&#21487;&#21462;&#30340;&#38598;&#20013;&#24335;&#25511;&#21046;&#22120;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#23545;&#19977;&#20010;&#29702;&#35770;&#31639;&#27861;&#36827;&#34892;&#20102;&#20960;&#31181;&#23454;&#38469;&#30340;&#25913;&#36827;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23637;&#31034;&#23427;&#20204;&#30340;&#31532;&#19968;&#20010;&#23454;&#35777;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce networked communication to the mean-field game framework, in particular to oracle-free settings where $N$ decentralised agents learn along a single, non-episodic evolution path of the empirical system. We prove that our architecture, with only a few reasonable assumptions about network structure, has sample guarantees bounded between those of the centralised- and independent-learning cases. We discuss how the sample guarantees of the three theoretical algorithms do not actually result in practical convergence. Accordingly, we show that in practical settings where the theoretical parameters are not observed (leading to poor estimation of the Q-function), our communication scheme significantly accelerates convergence over the independent case, without relying on the undesirable assumption of a centralised controller. We contribute several further practical enhancements to all three theoretical algorithms, allowing us to showcase their first empirical demonstrations. Our expe
&lt;/p&gt;</description></item><item><title>&#21487;&#34892;&#24615;&#31574;&#30053;&#36845;&#20195; (FPI) &#26159;&#19968;&#20010;&#38388;&#25509;&#30340;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#19978;&#19968;&#20010;&#31574;&#30053;&#30340;&#21487;&#34892;&#22495;&#26469;&#36845;&#20195;&#22320;&#38480;&#21046;&#24403;&#21069;&#31574;&#30053;&#12290;&#21487;&#34892;&#24615;&#31574;&#30053;&#25913;&#36827;&#26159;&#20854;&#26680;&#24515;&#65292;&#23427;&#22312;&#21487;&#34892;&#22495;&#20869;&#26368;&#22823;&#21270;&#22238;&#25253;&#65292;&#22312;&#21487;&#34892;&#22495;&#22806;&#26368;&#23567;&#21270;&#32422;&#26463;&#34928;&#20943;&#20989;&#25968; (CDF).</title><link>http://arxiv.org/abs/2304.08845</link><description>&lt;p&gt;
&#21487;&#34892;&#24615;&#31574;&#30053;&#36845;&#20195;
&lt;/p&gt;
&lt;p&gt;
Feasible Policy Iteration. (arXiv:2304.08845v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08845
&lt;/p&gt;
&lt;p&gt;
&#21487;&#34892;&#24615;&#31574;&#30053;&#36845;&#20195; (FPI) &#26159;&#19968;&#20010;&#38388;&#25509;&#30340;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#19978;&#19968;&#20010;&#31574;&#30053;&#30340;&#21487;&#34892;&#22495;&#26469;&#36845;&#20195;&#22320;&#38480;&#21046;&#24403;&#21069;&#31574;&#30053;&#12290;&#21487;&#34892;&#24615;&#31574;&#30053;&#25913;&#36827;&#26159;&#20854;&#26680;&#24515;&#65292;&#23427;&#22312;&#21487;&#34892;&#22495;&#20869;&#26368;&#22823;&#21270;&#22238;&#25253;&#65292;&#22312;&#21487;&#34892;&#22495;&#22806;&#26368;&#23567;&#21270;&#32422;&#26463;&#34928;&#20943;&#20989;&#25968; (CDF).
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26088;&#22312;&#22312;&#23433;&#20840;&#32422;&#26463;&#19979;&#35299;&#20915;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340; $\textit{&#30452;&#25509;}$ &#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#20250;&#22312;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20013;&#19968;&#30452;&#20351;&#29992;&#21407;&#22987;&#32422;&#26463;&#12290;&#23427;&#20204;&#25110;&#32773;&#32570;&#20047;&#31574;&#30053;&#36845;&#20195;&#26399;&#38388;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#25110;&#32773;&#36973;&#36935;&#19981;&#21487;&#34892;&#24615;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21483;&#20570;&#21487;&#34892;&#24615;&#31574;&#30053;&#36845;&#20195;&#65288;FPI&#65289;&#30340; $\textit{&#38388;&#25509;}$ &#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#26368;&#21518;&#19968;&#20010;&#31574;&#30053;&#30340;&#21487;&#34892;&#22495;&#26469;&#36845;&#20195;&#22320;&#38480;&#21046;&#24403;&#21069;&#31574;&#30053;&#12290;&#21487;&#34892;&#22495;&#30001;&#19968;&#20010;&#21483;&#20570;&#32422;&#26463;&#34928;&#20943;&#20989;&#25968;&#65288;CDF&#65289;&#30340;&#21487;&#34892;&#24615;&#20989;&#25968;&#34920;&#31034;&#12290;FPI &#30340;&#26680;&#24515;&#26159;&#19968;&#20010;&#21483;&#20570;&#21487;&#34892;&#24615;&#31574;&#30053;&#25913;&#36827;&#30340;&#21306;&#22495;&#24615;&#31574;&#30053;&#26356;&#26032;&#35268;&#21017;&#65292;&#23427;&#22312;&#21487;&#34892;&#22495;&#20869;&#26368;&#22823;&#21270;&#22238;&#25253;&#65292;&#22312;&#21487;&#34892;&#22495;&#22806;&#26368;&#23567;&#21270; CDF&#12290;&#36825;&#20010;&#26356;&#26032;&#35268;&#21017;&#24635;&#26159;&#21487;&#34892;&#30340;&#65292;&#24182;&#30830;&#20445;&#21487;&#34892;&#22495;&#21333;&#35843;&#22320;&#25193;&#23637;&#65292;&#29366;&#24577;&#20540;&#20989;&#25968;&#21333;&#35843;&#22320;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;
Safe reinforcement learning (RL) aims to solve an optimal control problem under safety constraints. Existing $\textit{direct}$ safe RL methods use the original constraint throughout the learning process. They either lack theoretical guarantees of the policy during iteration or suffer from infeasibility problems. To address this issue, we propose an $\textit{indirect}$ safe RL method called feasible policy iteration (FPI) that iteratively uses the feasible region of the last policy to constrain the current policy. The feasible region is represented by a feasibility function called constraint decay function (CDF). The core of FPI is a region-wise policy update rule called feasible policy improvement, which maximizes the return under the constraint of the CDF inside the feasible region and minimizes the CDF outside the feasible region. This update rule is always feasible and ensures that the feasible region monotonically expands and the state-value function monotonically increases inside 
&lt;/p&gt;</description></item></channel></rss>