<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21307;&#23398;&#22270;&#20687;&#21512;&#25104;&#20013;&#38544;&#24335;&#25193;&#25955;&#27169;&#22411;&#30340;&#35760;&#24518;&#38382;&#39064;&#12290;&#36890;&#36807;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#30340;&#35760;&#24518;&#31243;&#24230;&#20197;&#21450;&#25506;&#32034;&#21487;&#33021;&#23548;&#33268;&#35760;&#24518;&#30340;&#22240;&#32032;&#65292;&#25581;&#31034;&#20102;&#36825;&#19968;&#38382;&#39064;&#30340;&#37325;&#35201;&#24615;&#21644;&#28508;&#22312;&#39118;&#38505;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01054</link><description>&lt;p&gt;
&#26080;&#26465;&#20214;&#30340;&#38544;&#24335;&#25193;&#25955;&#27169;&#22411;&#35760;&#24518;&#24739;&#32773;&#24433;&#20687;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Unconditional Latent Diffusion Models Memorize Patient Imaging Data
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21307;&#23398;&#22270;&#20687;&#21512;&#25104;&#20013;&#38544;&#24335;&#25193;&#25955;&#27169;&#22411;&#30340;&#35760;&#24518;&#38382;&#39064;&#12290;&#36890;&#36807;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#30340;&#35760;&#24518;&#31243;&#24230;&#20197;&#21450;&#25506;&#32034;&#21487;&#33021;&#23548;&#33268;&#35760;&#24518;&#30340;&#22240;&#32032;&#65292;&#25581;&#31034;&#20102;&#36825;&#19968;&#38382;&#39064;&#30340;&#37325;&#35201;&#24615;&#21644;&#28508;&#22312;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#30340;&#38544;&#24335;&#25193;&#25955;&#27169;&#22411;&#22312;&#21307;&#23398;&#24433;&#20687;&#39046;&#22495;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#19968;&#20010;&#20540;&#24471;&#27880;&#24847;&#30340;&#24212;&#29992;&#26159;&#36890;&#36807;&#25552;&#20986;&#21512;&#25104;&#25968;&#25454;&#20316;&#20026;&#30495;&#23454;&#24739;&#32773;&#25968;&#25454;&#30340;&#26367;&#20195;&#21697;&#26469;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;&#24320;&#25918;&#25968;&#25454;&#20849;&#20139;&#12290;&#23613;&#31649;&#26377;&#36825;&#20010;&#24212;&#29992;&#30340;&#21069;&#26223;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#23481;&#26131;&#20986;&#29616;&#24739;&#32773;&#25968;&#25454;&#30340;&#35760;&#24518;&#38382;&#39064;&#65292;&#21363;&#27169;&#22411;&#29983;&#25104;&#24739;&#32773;&#25968;&#25454;&#30340;&#21103;&#26412;&#32780;&#19981;&#26159;&#26032;&#30340;&#21512;&#25104;&#26679;&#26412;&#12290;&#36825;&#30772;&#22351;&#20102;&#20445;&#25252;&#24739;&#32773;&#25968;&#25454;&#30340;&#25972;&#20010;&#30446;&#30340;&#65292;&#29978;&#33267;&#21487;&#33021;&#23548;&#33268;&#24739;&#32773;&#34987;&#37325;&#26032;&#35782;&#21035;&#12290;&#32771;&#34385;&#21040;&#36825;&#20010;&#38382;&#39064;&#30340;&#37325;&#35201;&#24615;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#21307;&#23398;&#24433;&#20687;&#30028;&#20013;&#36825;&#20010;&#38382;&#39064;&#24182;&#27809;&#26377;&#24471;&#21040;&#22826;&#22810;&#20851;&#27880;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#21307;&#23398;&#22270;&#20687;&#21512;&#25104;&#20013;&#38544;&#24335;&#25193;&#25955;&#27169;&#22411;&#30340;&#35760;&#24518;&#38382;&#39064;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;2D&#21644;3D&#30340;&#38544;&#24335;&#25193;&#25955;&#27169;&#22411;&#65292;&#20351;&#29992;CT&#12289;MR&#21644;X&#20809;&#25968;&#25454;&#38598;&#36827;&#34892;&#21512;&#25104;&#25968;&#25454;&#30340;&#29983;&#25104;&#12290;&#20043;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#33258;&#30417;&#30563;&#27169;&#22411;&#26469;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#34987;&#35760;&#24518;&#30340;&#31243;&#24230;&#65292;&#24182;&#36827;&#19968;&#27493;&#30740;&#31350;&#21487;&#33021;&#23548;&#33268;&#35760;&#24518;&#30340;&#21508;&#31181;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative latent diffusion models hold a wide range of applications in the medical imaging domain. A noteworthy application is privacy-preserved open-data sharing by proposing synthetic data as surrogates of real patient data. Despite the promise, these models are susceptible to patient data memorization, where models generate patient data copies instead of novel synthetic samples. This undermines the whole purpose of preserving patient data and may even result in patient re-identification. Considering the importance of the problem, surprisingly it has received relatively little attention in the medical imaging community. To this end, we assess memorization in latent diffusion models for medical image synthesis. We train 2D and 3D latent diffusion models on CT, MR, and X-ray datasets for synthetic data generation. Afterwards, we examine the amount of training data memorized utilizing self-supervised models and further investigate various factors that can possibly lead to memorization 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20849;&#36717;&#26799;&#24230;&#26679;&#24335;&#30340;&#26032;&#20248;&#21270;&#31639;&#27861;CG-like-Adam&#65292;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#65292;&#24182;&#22312;&#25910;&#25947;&#20998;&#26512;&#21644;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;</title><link>https://arxiv.org/abs/2404.01714</link><description>&lt;p&gt;
&#22522;&#20110;&#20849;&#36717;&#26799;&#24230;&#30340;&#33258;&#36866;&#24212;&#30697;&#20272;&#35745;&#20248;&#21270;&#31639;&#27861;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Conjugate-Gradient-like Based Adaptive Moment Estimation Optimization Algorithm for Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01714
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20849;&#36717;&#26799;&#24230;&#26679;&#24335;&#30340;&#26032;&#20248;&#21270;&#31639;&#27861;CG-like-Adam&#65292;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#65292;&#24182;&#22312;&#25910;&#25947;&#20998;&#26512;&#21644;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20026;&#21152;&#24555;&#22521;&#35757;&#36895;&#24230;&#24182;&#22686;&#24378;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#23558;&#20256;&#32479;&#30340;&#20849;&#36717;&#26799;&#24230;&#20462;&#27491;&#20026;&#20849;&#36717;&#26799;&#24230;&#26679;&#24335;&#65292;&#24182;&#23558;&#20854;&#24182;&#20837;&#36890;&#29992;Adam&#20013;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CG-like-Adam&#30340;&#26032;&#20248;&#21270;&#31639;&#27861;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#29992;Adam&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#30697;&#20272;&#35745;&#22343;&#30001;&#20849;&#36717;&#26799;&#24230;&#26679;&#24335;&#26367;&#25442;&#12290;&#25910;&#25947;&#20998;&#26512;&#22788;&#29702;&#20102;&#19968;&#38454;&#30697;&#20272;&#35745;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#31995;&#25968;&#20026;&#24120;&#25968;&#19988;&#19968;&#38454;&#30697;&#20272;&#35745;&#26080;&#20559;&#30340;&#24773;&#20917;&#12290;&#25968;&#20540;&#23454;&#39564;&#26174;&#31034;&#20102;&#22522;&#20110;CIFAR10/100&#25968;&#25454;&#38598;&#30340;&#25152;&#25552;&#31639;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01714v1 Announce Type: cross  Abstract: Training deep neural networks is a challenging task. In order to speed up training and enhance the performance of deep neural networks, we rectify the vanilla conjugate gradient as conjugate-gradient-like and incorporate it into the generic Adam, and thus propose a new optimization algorithm named CG-like-Adam for deep learning. Specifically, both the first-order and the second-order moment estimation of generic Adam are replaced by the conjugate-gradient-like. Convergence analysis handles the cases where the exponential moving average coefficient of the first-order moment estimation is constant and the first-order moment estimation is unbiased. Numerical experiments show the superiority of the proposed algorithm based on the CIFAR10/100 dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#22909;&#33719;&#21462;&#26041;&#27861;&#65292;&#36890;&#36807;DOVE&#21327;&#35758;&#23545;&#25351;&#20196;-&#21709;&#24212;&#23545;&#30340;&#32852;&#21512;&#27010;&#29575;&#36827;&#34892;&#20248;&#21270;&#65292;&#20197;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2404.00530</link><description>&lt;p&gt;
&#23558;&#22351;&#33529;&#26524;&#19982;&#22909;&#27224;&#23376;&#36827;&#34892;&#27604;&#36739;&#65306;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#20559;&#22909;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#22909;&#33719;&#21462;&#26041;&#27861;&#65292;&#36890;&#36807;DOVE&#21327;&#35758;&#23545;&#25351;&#20196;-&#21709;&#24212;&#23545;&#30340;&#32852;&#21512;&#27010;&#29575;&#36827;&#34892;&#20248;&#21270;&#65292;&#20197;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#24120;&#35265;&#30340;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25216;&#26415;&#20381;&#36182;&#20110;&#36890;&#36807;&#27604;&#36739;&#22312;&#22266;&#23450;&#19978;&#19979;&#25991;&#20013;&#26465;&#20214;&#29983;&#25104;&#30340;&#22810;&#20010;&#29983;&#25104;&#30340;&#20154;&#31867;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#24403;&#36825;&#20123;&#29983;&#25104;&#25918;&#32622;&#22312;&#30456;&#21516;&#30340;&#19978;&#19979;&#25991;&#20013;&#26102;&#65292;&#36825;&#20165;&#21033;&#29992;&#20102;&#25104;&#23545;&#27604;&#36739;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26465;&#20214;&#25490;&#21517;&#36890;&#24120;&#26080;&#27861;&#25429;&#33719;&#20154;&#31867;&#20559;&#22909;&#30340;&#22797;&#26434;&#21644;&#22810;&#32500;&#26041;&#38754;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20559;&#22909;&#33719;&#21462;&#30340;&#20256;&#32479;&#33539;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22312;&#25351;&#20196;-&#21709;&#24212;&#23545;&#19978;&#32852;&#21512;&#24341;&#21457;&#20559;&#22909;&#30340;&#26032;&#36724;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#20559;&#22909;&#20248;&#21270;&#26159;&#38024;&#23545;&#26465;&#20214;&#25490;&#21517;&#21327;&#35758;&#65288;&#20363;&#22914;&#65292;DPO&#65289;&#35774;&#35745;&#30340;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#30340;&#20559;&#22909;&#33719;&#21462;&#21327;&#35758;&#24341;&#20837;&#20102;DOVE&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#30340;&#20559;&#22909;&#20248;&#21270;&#30446;&#26631;&#65292;&#36890;&#36807;&#25552;&#21319;&#25152;&#36873;&#25351;&#20196;-&#21709;&#24212;&#23545;&#30340;&#32852;&#21512;&#27010;&#29575;&#26469;&#38477;&#20302;&#25152;&#25298;&#32477;&#25351;&#20196;-&#21709;&#24212;&#23545;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00530v1 Announce Type: cross  Abstract: A common technique for aligning large language models (LLMs) relies on acquiring human preferences by comparing multiple generations conditioned on a fixed context. This only leverages the pairwise comparisons when the generations are placed in an identical context. However, such conditional rankings often fail to capture the complex and multidimensional aspects of human preferences. In this work, we revisit the traditional paradigm of preference acquisition and propose a new axis that is based on eliciting preferences jointly over the instruction-response pairs. While prior preference optimizations are designed for conditional ranking protocols (e.g., DPO), our proposed preference acquisition protocol introduces DOVE, a new preference optimization objective that upweights the joint probability of the chosen instruction-response pair over the rejected instruction-response pair. Interestingly, we find that the LLM trained with joint ins
&lt;/p&gt;</description></item><item><title>&#35813;&#25945;&#31243;&#35752;&#35770;&#20102;&#22270;&#20687;&#21644;&#35270;&#35273;&#39046;&#22495;&#20013;&#25193;&#25955;&#27169;&#22411;&#30340;&#22522;&#26412;&#29702;&#24565;&#65292;&#36866;&#21512;&#23545;&#25193;&#25955;&#27169;&#22411;&#30740;&#31350;&#25110;&#24212;&#29992;&#24863;&#20852;&#36259;&#30340;&#26412;&#31185;&#29983;&#21644;&#30740;&#31350;&#29983;&#12290;</title><link>https://arxiv.org/abs/2403.18103</link><description>&lt;p&gt;
&#20851;&#20110;&#22270;&#20687;&#21644;&#35270;&#35273;&#25193;&#25955;&#27169;&#22411;&#30340;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
Tutorial on Diffusion Models for Imaging and Vision
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18103
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25945;&#31243;&#35752;&#35770;&#20102;&#22270;&#20687;&#21644;&#35270;&#35273;&#39046;&#22495;&#20013;&#25193;&#25955;&#27169;&#22411;&#30340;&#22522;&#26412;&#29702;&#24565;&#65292;&#36866;&#21512;&#23545;&#25193;&#25955;&#27169;&#22411;&#30740;&#31350;&#25110;&#24212;&#29992;&#24863;&#20852;&#36259;&#30340;&#26412;&#31185;&#29983;&#21644;&#30740;&#31350;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#29983;&#25104;&#24037;&#20855;&#30340;&#24778;&#20154;&#22686;&#38271;&#20351;&#24471;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#21644;&#25991;&#26412;&#21040;&#35270;&#39057;&#29983;&#25104;&#31561;&#35768;&#22810;&#20196;&#20154;&#20852;&#22859;&#30340;&#24212;&#29992;&#25104;&#20026;&#21487;&#33021;&#12290;&#36825;&#20123;&#29983;&#25104;&#24037;&#20855;&#32972;&#21518;&#30340;&#22522;&#26412;&#21407;&#29702;&#26159;&#25193;&#25955;&#27010;&#24565;&#65292;&#19968;&#31181;&#29305;&#27530;&#30340;&#37319;&#26679;&#26426;&#21046;&#65292;&#20811;&#26381;&#20102;&#20197;&#21069;&#26041;&#27861;&#20013;&#34987;&#35748;&#20026;&#22256;&#38590;&#30340;&#19968;&#20123;&#32570;&#28857;&#12290;&#26412;&#25945;&#31243;&#30340;&#30446;&#26631;&#26159;&#35752;&#35770;&#25193;&#25955;&#27169;&#22411;&#30340;&#22522;&#26412;&#29702;&#24565;&#12290;&#26412;&#25945;&#31243;&#30340;&#30446;&#26631;&#21463;&#20247;&#21253;&#25324;&#23545;&#30740;&#31350;&#25193;&#25955;&#27169;&#22411;&#25110;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#35299;&#20915;&#20854;&#20182;&#38382;&#39064;&#24863;&#20852;&#36259;&#30340;&#26412;&#31185;&#29983;&#21644;&#30740;&#31350;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18103v1 Announce Type: new  Abstract: The astonishing growth of generative tools in recent years has empowered many exciting applications in text-to-image generation and text-to-video generation. The underlying principle behind these generative tools is the concept of diffusion, a particular sampling mechanism that has overcome some shortcomings that were deemed difficult in the previous approaches. The goal of this tutorial is to discuss the essential ideas underlying the diffusion models. The target audience of this tutorial includes undergraduate and graduate students who are interested in doing research on diffusion models or applying these models to solve other problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#21313;&#19968;&#31181;&#39046;&#20808;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28431;&#27934;&#26816;&#27979;&#20013;&#30340;&#33021;&#21147;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#65292;&#20026;&#25506;&#32034;LLMs&#25512;&#29702;&#33021;&#21147;&#30340;&#26497;&#38480;&#25552;&#20379;&#20102;&#37325;&#35201;&#26696;&#20363;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.17218</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28431;&#27934;&#26816;&#27979;&#26041;&#38754;&#30340;&#33021;&#21147;&#32508;&#21512;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#21313;&#19968;&#31181;&#39046;&#20808;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28431;&#27934;&#26816;&#27979;&#20013;&#30340;&#33021;&#21147;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#65292;&#20026;&#25506;&#32034;LLMs&#25512;&#29702;&#33021;&#21147;&#30340;&#26497;&#38480;&#25552;&#20379;&#20102;&#37325;&#35201;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#23637;&#29616;&#20986;&#22312;&#20195;&#30721;&#29983;&#25104;&#21644;&#20854;&#20182;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#26041;&#38754;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#12290;&#28431;&#27934;&#26816;&#27979;&#23545;&#20110;&#32500;&#25252;&#36719;&#20214;&#31995;&#32479;&#30340;&#23433;&#20840;&#12289;&#23436;&#25972;&#24615;&#21644;&#21487;&#20449;&#24230;&#33267;&#20851;&#37325;&#35201;&#12290;&#31934;&#30830;&#30340;&#28431;&#27934;&#26816;&#27979;&#38656;&#35201;&#23545;&#20195;&#30721;&#36827;&#34892;&#25512;&#29702;&#65292;&#36825;&#20351;&#24471;&#23427;&#25104;&#20026;&#25506;&#32034;LLMs&#25512;&#29702;&#33021;&#21147;&#26497;&#38480;&#30340;&#33391;&#22909;&#26696;&#20363;&#30740;&#31350;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;&#30740;&#31350;&#24050;&#32463;&#21033;&#29992;&#36890;&#29992;&#25552;&#31034;&#25216;&#26415;&#23558;LLMs&#24212;&#29992;&#20110;&#28431;&#27934;&#26816;&#27979;&#65292;&#20294;&#23427;&#20204;&#22312;&#36825;&#19968;&#20219;&#21153;&#20013;&#30340;&#23436;&#25972;&#33021;&#21147;&#20197;&#21450;&#22312;&#35299;&#37322;&#30830;&#23450;&#30340;&#28431;&#27934;&#26102;&#25152;&#29359;&#30340;&#38169;&#35823;&#31867;&#22411;&#20173;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#21313;&#19968;&#31181;&#39046;&#20808;&#30340;&#22312;&#20195;&#30721;&#29983;&#25104;&#26041;&#38754;&#22788;&#20110;&#26368;&#21069;&#27839;&#19988;&#36890;&#24120;&#29992;&#20316;&#32534;&#30721;&#21161;&#25163;&#30340;LLMs&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#22312;&#28431;&#27934;&#26816;&#27979;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#31995;&#32479;&#22320;&#25628;&#32034;&#20102;&#25928;&#26524;&#26368;&#20339;&#30340;&#25552;&#31034;&#65292;&#32467;&#21512;&#20102;&#35832;&#22914;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#38142;&#24335;&#23398;&#20064;&#31561;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17218v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated great potential for code generation and other software engineering tasks. Vulnerability detection is of crucial importance to maintaining the security, integrity, and trustworthiness of software systems. Precise vulnerability detection requires reasoning about the code, making it a good case study for exploring the limits of LLMs' reasoning capabilities. Although recent work has applied LLMs to vulnerability detection using generic prompting techniques, their full capabilities for this task and the types of errors they make when explaining identified vulnerabilities remain unclear.   In this paper, we surveyed eleven LLMs that are state-of-the-art in code generation and commonly used as coding assistants, and evaluated their capabilities for vulnerability detection. We systematically searched for the best-performing prompts, incorporating techniques such as in-context learning and chain-of
&lt;/p&gt;</description></item><item><title>&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#25104;&#23545;&#20559;&#22909;&#25628;&#32034;&#26041;&#27861;PAIRS&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;LLMs&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#20248;&#20110;&#30452;&#25509;&#25171;&#20998;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.16950</link><description>&lt;p&gt;
&#19982;&#20154;&#31867;&#21028;&#26029;&#30456;&#19968;&#33268;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#25104;&#23545;&#20559;&#22909;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16950
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#25104;&#23545;&#20559;&#22909;&#25628;&#32034;&#26041;&#27861;PAIRS&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;LLMs&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#20248;&#20110;&#30452;&#25509;&#25171;&#20998;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#33258;&#21160;&#35780;&#20272;&#22120;&#22312;&#35780;&#20272;&#29983;&#25104;&#30340;&#33258;&#28982;&#35821;&#35328;&#36136;&#37327;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;LLMs&#22312;&#35780;&#20272;&#20013;&#20173;&#23384;&#22312;&#20559;&#35265;&#65292;&#24120;&#24120;&#38590;&#20197;&#29983;&#25104;&#19982;&#20154;&#31867;&#35780;&#20272;&#19968;&#33268;&#30340;&#36830;&#36143;&#35780;&#20272;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;LLM&#35780;&#20272;&#22120;&#19982;&#20154;&#31867;&#21028;&#26029;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#36827;&#34892;&#31995;&#32479;&#30740;&#31350;&#65292;&#25581;&#31034;&#29616;&#26377;&#26088;&#22312;&#20943;&#36731;&#20559;&#35265;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#36275;&#20197;&#26377;&#25928;&#23558;LLM&#35780;&#20272;&#22120;&#23545;&#40784;&#12290;&#21463;&#21040;RLHF&#20013;&#23545;&#20559;&#22909;&#25968;&#25454;&#30340;&#20351;&#29992;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#35780;&#20272;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#25490;&#24207;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;Pairwise-preference Search&#65288;PAIRS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20197;LLMs&#36827;&#34892;&#25104;&#23545;&#27604;&#36739;&#24182;&#26377;&#25928;&#23545;&#20505;&#36873;&#25991;&#26412;&#36827;&#34892;&#25490;&#24207;&#30340;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#24341;&#23548;&#30340;&#25628;&#32034;&#26041;&#27861;&#12290;PAIRS&#22312;&#20195;&#34920;&#24615;&#35780;&#20272;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#26174;&#31034;&#20986;&#27604;&#30452;&#25509;&#25171;&#20998;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16950v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated promising capabilities as automatic evaluators in assessing the quality of generated natural language. However, LLMs still exhibit biases in evaluation and often struggle to generate coherent evaluations that align with human assessments. In this work, we first conduct a systematic study of the misalignment between LLM evaluators and human judgement, revealing that existing calibration methods aimed at mitigating biases are insufficient for effectively aligning LLM evaluators. Inspired by the use of preference data in RLHF, we formulate the evaluation as a ranking problem and introduce Pairwise-preference Search (PAIRS), an uncertainty-guided search method that employs LLMs to conduct pairwise comparisons and efficiently ranks candidate texts. PAIRS achieves state-of-the-art performance on representative evaluation tasks and demonstrates significant improvements over direct scoring. Furthe
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#38024;&#23545;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#27969;&#37327;&#20998;&#26512;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#24635;&#32467;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26032;&#29305;&#24449;&#12289;&#26368;&#26032;&#36827;&#23637;&#21644;&#25361;&#25112;&#65292;&#35748;&#20026;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#21487;&#20197;&#25581;&#31034;CIoT&#39046;&#22495;&#20013;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.16149</link><description>&lt;p&gt;
&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#27969;&#37327;&#30340;&#35843;&#26597;&#65306;&#23433;&#20840;&#19982;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
A Survey on Consumer IoT Traffic: Security and Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16149
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#38024;&#23545;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#27969;&#37327;&#20998;&#26512;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#24635;&#32467;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26032;&#29305;&#24449;&#12289;&#26368;&#26032;&#36827;&#23637;&#21644;&#25361;&#25112;&#65292;&#35748;&#20026;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#21487;&#20197;&#25581;&#31034;CIoT&#39046;&#22495;&#20013;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#37324;&#65292;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#24050;&#32463;&#36827;&#20837;&#20102;&#20844;&#20247;&#29983;&#27963;&#12290;&#23613;&#31649;CIoT&#25552;&#39640;&#20102;&#20154;&#20204;&#26085;&#24120;&#29983;&#27963;&#30340;&#20415;&#21033;&#24615;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26032;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;&#25105;&#20204;&#23581;&#35797;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#36825;&#19968;&#23433;&#20840;&#39046;&#22495;&#20013;&#30340;&#27969;&#34892;&#26041;&#27861;&#65292;&#25214;&#20986;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#20174;&#27969;&#37327;&#20998;&#26512;&#20013;&#20102;&#35299;CIoT&#23433;&#20840;&#21644;&#38544;&#31169;&#26041;&#38754;&#30340;&#20869;&#23481;&#12290;&#26412;&#35843;&#26597;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#35282;&#24230;&#25506;&#35752;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#20013;&#30340;&#26032;&#29305;&#24449;&#12289;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26368;&#26032;&#36827;&#23637;&#20197;&#21450;&#23578;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#20174;2018&#24180;1&#26376;&#33267;2023&#24180;12&#26376;&#25910;&#38598;&#20102;310&#31687;&#19982;CIoT&#27969;&#37327;&#20998;&#26512;&#26377;&#20851;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#35282;&#24230;&#30340;&#35770;&#25991;&#65292;&#24635;&#32467;&#20102;&#35782;&#21035;&#20102;CIoT&#26032;&#29305;&#24449;&#30340;CIoT&#27969;&#37327;&#20998;&#26512;&#36807;&#31243;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#20116;&#20010;&#24212;&#29992;&#30446;&#26631;&#35814;&#32454;&#20171;&#32461;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#35774;&#22791;&#25351;&#32441;&#35782;&#21035;&#12289;&#29992;&#25143;&#27963;&#21160;&#25512;&#26029;&#12289;&#24694;&#24847;&#34892;&#20026;&#26816;&#27979;&#12289;&#38544;&#31169;&#27844;&#38706;&#20197;&#21450;&#36890;&#20449;&#27169;&#24335;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16149v1 Announce Type: cross  Abstract: For the past few years, the Consumer Internet of Things (CIoT) has entered public lives. While CIoT has improved the convenience of people's daily lives, it has also brought new security and privacy concerns. In this survey, we try to figure out what researchers can learn about the security and privacy of CIoT by traffic analysis, a popular method in the security community. From the security and privacy perspective, this survey seeks out the new characteristics in CIoT traffic analysis, the state-of-the-art progress in CIoT traffic analysis, and the challenges yet to be solved. We collected 310 papers from January 2018 to December 2023 related to CIoT traffic analysis from the security and privacy perspective and summarized the process of CIoT traffic analysis in which the new characteristics of CIoT are identified. Then, we detail existing works based on five application goals: device fingerprinting, user activity inference, malicious
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#26102;&#38388;&#19968;&#33268;Koopman&#33258;&#32534;&#30721;&#22120;&#65288;tcKAE&#65289;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;&#38271;&#26399;&#39044;&#27979;&#65292;&#22312;&#26377;&#38480;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#19979;&#36890;&#36807;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#39033;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.12335</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#21160;&#24577;&#31995;&#32479;&#30340;&#26102;&#38388;&#19968;&#33268;&#30340;Koopman&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Temporally-Consistent Koopman Autoencoders for Forecasting Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12335
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#26102;&#38388;&#19968;&#33268;Koopman&#33258;&#32534;&#30721;&#22120;&#65288;tcKAE&#65289;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;&#38271;&#26399;&#39044;&#27979;&#65292;&#22312;&#26377;&#38480;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#19979;&#36890;&#36807;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#39033;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#20047;&#36275;&#22815;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#32463;&#24120;&#26159;&#39640;&#32500;&#26102;&#31354;&#21160;&#24577;&#31995;&#32479;&#25968;&#25454;&#39537;&#21160;&#24314;&#27169;&#20013;&#20851;&#38190;&#25361;&#25112;&#12290;Koopman&#33258;&#32534;&#30721;&#22120;&#65288;KAEs&#65289;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#12289;&#33258;&#32534;&#30721;&#22120;&#30340;&#38477;&#32500;&#33021;&#21147;&#20197;&#21450;Koopman&#31639;&#23376;&#30340;&#35889;&#29305;&#24615;&#65292;&#23398;&#20064;&#20855;&#26377;&#26356;&#31616;&#21333;&#32447;&#24615;&#21160;&#24577;&#30340;&#38477;&#38454;&#29305;&#24449;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;KAEs&#30340;&#26377;&#25928;&#24615;&#21463;&#38480;&#20110;&#26377;&#38480;&#32780;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#23548;&#33268;&#27867;&#21270;&#33021;&#21147;&#36739;&#24046;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#26102;&#38388;&#19968;&#33268;Koopman&#33258;&#32534;&#30721;&#22120;&#65288;tcKAE&#65289;&#30340;&#27169;&#22411;&#65292;&#26088;&#22312;&#21363;&#20351;&#22312;&#21463;&#38480;&#19988;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#24773;&#20917;&#19979;&#29983;&#25104;&#20934;&#30830;&#30340;&#38271;&#26399;&#39044;&#27979;&#12290;&#36825;&#26159;&#36890;&#36807;&#24378;&#21046;&#22312;&#19981;&#21516;&#26102;&#38388;&#27493;&#19978;&#20445;&#25345;&#39044;&#27979;&#19968;&#33268;&#24615;&#30340;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#39033;&#23454;&#29616;&#30340;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;tcKAE&#30456;&#23545;&#20110;&#29616;&#26377;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12335v1 Announce Type: new  Abstract: Absence of sufficiently high-quality data often poses a key challenge in data-driven modeling of high-dimensional spatio-temporal dynamical systems. Koopman Autoencoders (KAEs) harness the expressivity of deep neural networks (DNNs), the dimension reduction capabilities of autoencoders, and the spectral properties of the Koopman operator to learn a reduced-order feature space with simpler, linear dynamics. However, the effectiveness of KAEs is hindered by limited and noisy training datasets, leading to poor generalizability. To address this, we introduce the Temporally-Consistent Koopman Autoencoder (tcKAE), designed to generate accurate long-term predictions even with constrained and noisy training data. This is achieved through a consistency regularization term that enforces prediction coherence across different time steps, thus enhancing the robustness and generalizability of tcKAE over existing models. We provide analytical justifica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#29702;&#35770;&#33719;&#21462;&#20989;&#25968;&#65292;&#29992;&#20110;&#24179;&#34913;&#22312;&#36830;&#32493;&#30340;&#20248;&#21270;&#20219;&#21153;&#20013;&#33719;&#24471;&#26368;&#20248;&#20540;&#25110;&#35299;&#20449;&#24687;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2403.09570</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#20445;&#30495;&#24230;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#21450;&#36328;&#20219;&#21153;&#21487;&#36716;&#31227;&#30340;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Multi-Fidelity Bayesian Optimization With Across-Task Transferable Max-Value Entropy Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09570
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#29702;&#35770;&#33719;&#21462;&#20989;&#25968;&#65292;&#29992;&#20110;&#24179;&#34913;&#22312;&#36830;&#32493;&#30340;&#20248;&#21270;&#20219;&#21153;&#20013;&#33719;&#24471;&#26368;&#20248;&#20540;&#25110;&#35299;&#20449;&#24687;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#35774;&#35745;&#32773;&#38754;&#20020;&#19968;&#31995;&#21015;&#20248;&#21270;&#20219;&#21153;&#65292;&#20219;&#21153;&#30340;&#30446;&#26631;&#26159;&#26114;&#36149;&#35780;&#20272;&#30340;&#40657;&#30418;&#20989;&#25968;&#24418;&#24335;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#29702;&#35770;&#33719;&#21462;&#20989;&#25968;&#65292;&#29992;&#20110;&#24179;&#34913;&#38656;&#35201;&#33719;&#21462;&#19981;&#21516;&#20219;&#21153;&#30340;&#26368;&#20248;&#20540;&#25110;&#35299;&#30340;&#20449;&#24687;&#21644;&#36890;&#36807;&#21442;&#25968;&#30340;&#36716;&#31227;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09570v1 Announce Type: new  Abstract: In many applications, ranging from logistics to engineering, a designer is faced with a sequence of optimization tasks for which the objectives are in the form of black-box functions that are costly to evaluate. For example, the designer may need to tune the hyperparameters of neural network models for different learning tasks over time. Rather than evaluating the objective function for each candidate solution, the designer may have access to approximations of the objective functions, for which higher-fidelity evaluations entail a larger cost. Existing multi-fidelity black-box optimization strategies select candidate solutions and fidelity levels with the goal of maximizing the information accrued about the optimal value or solution for the current task. Assuming that successive optimization tasks are related, this paper introduces a novel information-theoretic acquisition function that balances the need to acquire information about the 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#31070;&#32463;PDE&#27714;&#35299;&#22120;&#65288;LNS&#65289;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#28508;&#22312;&#31354;&#38388;&#23398;&#20064;&#31995;&#32479;&#21160;&#24577;&#24182;&#20351;&#29992;&#36739;&#31895;&#31961;&#30340;&#31163;&#25955;&#21270;&#65292;&#21487;&#20197;&#22823;&#22823;&#31616;&#21270;&#31070;&#32463;PDE&#27714;&#35299;&#22120;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.17853</link><description>&lt;p&gt;
&#28508;&#22312;&#31070;&#32463;PDE&#27714;&#35299;&#22120;&#65306;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#38477;&#38454;&#24314;&#27169;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Latent Neural PDE Solver: a reduced-order modelling framework for partial differential equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17853
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#31070;&#32463;PDE&#27714;&#35299;&#22120;&#65288;LNS&#65289;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#28508;&#22312;&#31354;&#38388;&#23398;&#20064;&#31995;&#32479;&#21160;&#24577;&#24182;&#20351;&#29992;&#36739;&#31895;&#31961;&#30340;&#31163;&#25955;&#21270;&#65292;&#21487;&#20197;&#22823;&#22823;&#31616;&#21270;&#31070;&#32463;PDE&#27714;&#35299;&#22120;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#21152;&#36895;&#30001;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#25511;&#21046;&#30340;&#31995;&#32479;&#30340;&#25968;&#20540;&#27169;&#25311;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#24040;&#22823;&#28508;&#21147;&#12290;&#19982;&#35768;&#22810;&#29616;&#26377;&#30340;&#22312;&#39640;&#32500;&#31163;&#25955;&#21270;&#22330;&#19978;&#25805;&#20316;&#30340;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#35758;&#22312;&#28508;&#22312;&#31354;&#38388;&#23398;&#20064;&#31995;&#32479;&#30340;&#21160;&#24577;&#65292;&#20351;&#29992;&#26356;&#31895;&#31961;&#30340;&#31163;&#25955;&#21270;&#12290;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550; - &#28508;&#22312;&#31070;&#32463;PDE&#27714;&#35299;&#22120;&#65288;LNS&#65289;&#20013;&#65292;&#39318;&#20808;&#35757;&#32451;&#19968;&#20010;&#38750;&#32447;&#24615;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#23558;&#31995;&#32479;&#30340;&#20840;&#38454;&#34920;&#31034;&#25237;&#24433;&#21040;&#32593;&#26684;&#20943;&#23569;&#30340;&#31354;&#38388;&#20013;&#65292;&#25509;&#30528;&#35757;&#32451;&#19968;&#20010;&#26102;&#38388;&#27169;&#22411;&#26469;&#39044;&#27979;&#36825;&#20010;&#32593;&#26684;&#20943;&#23569;&#30340;&#31354;&#38388;&#20013;&#30340;&#26410;&#26469;&#29366;&#24577;&#12290;&#36825;&#31181;&#38477;&#38454;&#36807;&#31243;&#36890;&#36807;&#22823;&#22823;&#20943;&#23569;&#20276;&#38543;&#32454;&#31890;&#24230;&#31163;&#25955;&#21270;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#31616;&#21270;&#20102;&#26102;&#38388;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25552;&#20986;&#30340;&#26694;&#26550;&#20197;&#21450;&#20960;&#31181;&#20854;&#20182;&#27969;&#34892;&#30340;&#31070;&#32463;PDE&#27714;&#35299;&#22120;&#22312;&#21508;&#31181;&#31867;&#22411;&#30340;&#31995;&#32479;&#19978;&#30340;&#33021;&#21147;&#65292;&#21253;&#25324;&#21333;&#30456;&#21644;&#22810;&#30456;&#27969;&#20307;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17853v1 Announce Type: cross  Abstract: Neural networks have shown promising potential in accelerating the numerical simulation of systems governed by partial differential equations (PDEs). Different from many existing neural network surrogates operating on high-dimensional discretized fields, we propose to learn the dynamics of the system in the latent space with much coarser discretizations. In our proposed framework - Latent Neural PDE Solver (LNS), a non-linear autoencoder is first trained to project the full-order representation of the system onto the mesh-reduced space, then a temporal model is trained to predict the future state in this mesh-reduced space. This reduction process simplifies the training of the temporal model by greatly reducing the computational cost accompanying a fine discretization. We study the capability of the proposed framework and several other popular neural PDE solvers on various types of systems including single-phase and multi-phase flows a
&lt;/p&gt;</description></item><item><title>&#25506;&#32034;&#22312;&#33021;&#22815;&#36827;&#34892;&#26799;&#24230;&#24179;&#34892;&#35780;&#20272;&#30340;&#26694;&#26550;&#20013;&#30340;&#25277;&#26679;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#24182;&#34892;&#21270;&#30340;&#38543;&#26426;&#20013;&#28857;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#26032;&#25216;&#26415;&#23548;&#20986;&#20102;&#23545;&#25277;&#26679;&#21644;&#30446;&#26631;&#23494;&#24230;&#20043;&#38388;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#37327;&#21270;&#20102;&#24182;&#34892;&#22788;&#29702;&#21333;&#20803;&#24102;&#26469;&#30340;&#36816;&#34892;&#26102;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.14434</link><description>&lt;p&gt;
&#24182;&#34892;&#20013;&#28857;&#38543;&#26426;&#21270;&#30340; Langevin Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Parallelized Midpoint Randomization for Langevin Monte Carlo
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14434
&lt;/p&gt;
&lt;p&gt;
&#25506;&#32034;&#22312;&#33021;&#22815;&#36827;&#34892;&#26799;&#24230;&#24179;&#34892;&#35780;&#20272;&#30340;&#26694;&#26550;&#20013;&#30340;&#25277;&#26679;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#24182;&#34892;&#21270;&#30340;&#38543;&#26426;&#20013;&#28857;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#26032;&#25216;&#26415;&#23548;&#20986;&#20102;&#23545;&#25277;&#26679;&#21644;&#30446;&#26631;&#23494;&#24230;&#20043;&#38388;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#37327;&#21270;&#20102;&#24182;&#34892;&#22788;&#29702;&#21333;&#20803;&#24102;&#26469;&#30340;&#36816;&#34892;&#26102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#21487;&#20197;&#36827;&#34892;&#26799;&#24230;&#30340;&#24179;&#34892;&#35780;&#20272;&#30340;&#26694;&#26550;&#20013;&#30340;&#25277;&#26679;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#37325;&#28857;&#25918;&#22312;&#30001;&#24179;&#28369;&#21644;&#24378;log-&#20985;&#23494;&#24230;&#34920;&#24449;&#30340;&#30446;&#26631;&#20998;&#24067;&#19978;&#12290;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#24182;&#34892;&#21270;&#30340;&#38543;&#26426;&#20013;&#28857;&#26041;&#27861;&#65292;&#24182;&#36816;&#29992;&#26368;&#36817;&#24320;&#21457;&#29992;&#20110;&#20998;&#26512;&#20854;&#32431;&#39034;&#24207;&#29256;&#26412;&#30340;&#35777;&#26126;&#25216;&#26415;&#12290;&#21033;&#29992;&#36825;&#20123;&#25216;&#26415;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#25277;&#26679;&#21644;&#30446;&#26631;&#23494;&#24230;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#30028;&#38480;&#37327;&#21270;&#20102;&#36890;&#36807;&#21033;&#29992;&#24182;&#34892;&#22788;&#29702;&#21333;&#20803;&#25152;&#23454;&#29616;&#30340;&#36816;&#34892;&#26102;&#25913;&#36827;&#65292;&#36825;&#21487;&#33021;&#26159;&#30456;&#24403;&#21487;&#35266;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14434v1 Announce Type: cross  Abstract: We explore the sampling problem within the framework where parallel evaluations of the gradient of the log-density are feasible. Our investigation focuses on target distributions characterized by smooth and strongly log-concave densities. We revisit the parallelized randomized midpoint method and employ proof techniques recently developed for analyzing its purely sequential version. Leveraging these techniques, we derive upper bounds on the Wasserstein distance between the sampling and target densities. These bounds quantify the runtime improvement achieved by utilizing parallel processing units, which can be considerable.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#26410;&#21457;&#24067;&#30740;&#31350;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#30001;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#26500;&#24314;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#32467;&#21512;&#35770;&#25991;&#20869;&#23481;&#21644;&#21382;&#21490;&#24341;&#29992;&#30340;&#20449;&#24687;&#65292;&#39640;&#20934;&#30830;&#24230;&#39044;&#27979;&#26410;&#26469;&#30340;&#28436;&#21270;&#32593;&#32476;&#21160;&#24577;&#21644;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.08640</link><description>&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22312;&#19981;&#26029;&#28436;&#21270;&#30340;&#30693;&#35782;&#22270;&#35889;&#19978;&#39044;&#27979;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#20027;&#39064;
&lt;/p&gt;
&lt;p&gt;
Forecasting high-impact research topics via machine learning on evolving knowledge graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08640
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#26410;&#21457;&#24067;&#30740;&#31350;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#30001;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#26500;&#24314;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#32467;&#21512;&#35770;&#25991;&#20869;&#23481;&#21644;&#21382;&#21490;&#24341;&#29992;&#30340;&#20449;&#24687;&#65292;&#39640;&#20934;&#30830;&#24230;&#39044;&#27979;&#26410;&#26469;&#30340;&#28436;&#21270;&#32593;&#32476;&#21160;&#24577;&#21644;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#20986;&#29256;&#29289;&#30340;&#25351;&#25968;&#22686;&#38271;&#23545;&#20154;&#31867;&#30740;&#31350;&#32773;&#26500;&#25104;&#20102;&#20005;&#23803;&#25361;&#25112;&#12290;&#23427;&#36843;&#20351;&#30740;&#31350;&#32773;&#23558;&#27880;&#24847;&#21147;&#38598;&#20013;&#22312;&#26356;&#29421;&#31364;&#30340;&#23376;&#39046;&#22495;&#19978;&#65292;&#20351;&#24471;&#21457;&#29616;&#20854;&#20182;&#39046;&#22495;&#30340;&#26032;&#39062;&#19988;&#26377;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#24819;&#27861;&#21644;&#21512;&#20316;&#21464;&#24471;&#22256;&#38590;&#12290;&#34429;&#28982;&#26377;&#21150;&#27861;&#39044;&#27979;&#31185;&#23398;&#35770;&#25991;&#26410;&#26469;&#30340;&#24341;&#29992;&#27425;&#25968;&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#31561;&#21040;&#30740;&#31350;&#23436;&#25104;&#24182;&#19988;&#35770;&#25991;&#20889;&#25104;&#21518;&#25165;&#33021;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#26679;&#23601;&#38169;&#36807;&#20102;&#24819;&#27861;&#26500;&#24605;&#30340;&#26089;&#26399;&#38454;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#39044;&#27979;&#20174;&#26410;&#34987;&#30740;&#31350;&#32773;&#21457;&#24067;&#30340;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#20854;&#20013;&#21253;&#21547;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#12290;&#23427;&#32467;&#21512;&#20102;&#20174;&#35770;&#25991;&#20869;&#23481;&#20013;&#21019;&#24314;&#30340;&#35821;&#20041;&#32593;&#32476;&#21644;&#20174;&#21382;&#21490;&#24341;&#29992;&#20013;&#21019;&#24314;&#30340;&#24433;&#21709;&#32593;&#32476;&#12290;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#65292;&#25105;&#20204;&#21487;&#20197;&#39640;&#20934;&#30830;&#24230;&#22320;&#39044;&#27979;&#28436;&#21270;&#32593;&#32476;&#30340;&#21160;&#24577;&#24773;&#20917;&#65292;&#20174;&#32780;&#39044;&#27979;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;&#25105;&#20204;&#39044;&#26399;&#36825;&#31181;&#33021;&#21147;&#23558;&#26377;&#21161;&#20110;&#30740;&#31350;&#32773;&#21457;&#29616;&#20855;&#26377;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#25193;&#23637;&#32447;&#24615;&#21270;&#25910;&#32553;&#21160;&#21147;&#23398;&#65288;ELCD&#65289;&#65292;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#20840;&#23616;&#25910;&#32553;&#24615;&#20445;&#35777;&#30340;&#31070;&#32463;&#32593;&#32476;&#21160;&#21147;&#31995;&#32479;&#65292;&#36890;&#36807;&#21442;&#25968;&#21270;&#38750;&#32447;&#24615;&#21521;&#37327;&#22330;&#30340;&#25193;&#23637;&#32447;&#24615;&#21270;&#23454;&#29616;&#12290;&#36890;&#36807;&#22312;&#25968;&#25454;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#35757;&#32451;&#24494;&#20998;&#21516;&#32986;&#65292;&#24182;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#24378;&#21046;&#25910;&#32553;&#24615;&#65292;ELCD&#33021;&#22312;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#20445;&#25345;&#20840;&#23616;&#31283;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08090</link><description>&lt;p&gt;
&#23398;&#20064;&#31070;&#32463;&#25910;&#32553;&#21160;&#21147;&#23398;&#65306;&#25193;&#23637;&#32447;&#24615;&#21270;&#21644;&#20840;&#23616;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Learning Neural Contracting Dynamics: Extended Linearization and Global Guarantees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#25193;&#23637;&#32447;&#24615;&#21270;&#25910;&#32553;&#21160;&#21147;&#23398;&#65288;ELCD&#65289;&#65292;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#20840;&#23616;&#25910;&#32553;&#24615;&#20445;&#35777;&#30340;&#31070;&#32463;&#32593;&#32476;&#21160;&#21147;&#31995;&#32479;&#65292;&#36890;&#36807;&#21442;&#25968;&#21270;&#38750;&#32447;&#24615;&#21521;&#37327;&#22330;&#30340;&#25193;&#23637;&#32447;&#24615;&#21270;&#23454;&#29616;&#12290;&#36890;&#36807;&#22312;&#25968;&#25454;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#35757;&#32451;&#24494;&#20998;&#21516;&#32986;&#65292;&#24182;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#24378;&#21046;&#25910;&#32553;&#24615;&#65292;ELCD&#33021;&#22312;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#20445;&#25345;&#20840;&#23616;&#31283;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#30340;&#21160;&#24577;&#31995;&#32479;&#20013;&#65292;&#20840;&#23616;&#31283;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#20445;&#35777;&#23545;&#20110;&#30830;&#20445;&#31995;&#32479;&#22312;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#30340;&#33391;&#22909;&#34892;&#20026;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#23637;&#32447;&#24615;&#21270;&#25910;&#32553;&#21160;&#21147;&#23398;&#65288;ELCD&#65289;&#65292;&#35813;&#31995;&#32479;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#20219;&#24847;&#24230;&#37327;&#19979;&#20840;&#23616;&#25910;&#32553;&#24615;&#20445;&#35777;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#21160;&#21147;&#31995;&#32479;&#12290;ELCD&#30340;&#20851;&#38190;&#29305;&#24615;&#26159;&#38750;&#32447;&#24615;&#21521;&#37327;&#22330;&#25193;&#23637;&#32447;&#24615;&#21270;&#30340;&#21442;&#25968;&#21270;&#12290;&#22312;&#20854;&#26368;&#22522;&#26412;&#24418;&#24335;&#19979;&#65292;ELCD&#20445;&#35777;&#20840;&#23616;&#25351;&#25968;&#31283;&#23450;&#12289;&#24179;&#34913;&#25910;&#32553;&#20197;&#21450;&#22312;&#26576;&#20123;&#24230;&#37327;&#19979;&#20840;&#23616;&#25910;&#32553;&#12290;&#20026;&#20102;&#23454;&#29616;&#22312;&#25968;&#25454;&#31354;&#38388;&#20013;&#30456;&#23545;&#20110;&#26356;&#19968;&#33324;&#24230;&#37327;&#30340;&#25910;&#32553;&#65292;&#25105;&#20204;&#35757;&#32451;&#25968;&#25454;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#24494;&#20998;&#21516;&#32986;&#65292;&#24182;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#24378;&#21046;&#25910;&#32553;&#24615;&#65292;&#20174;&#32780;&#30830;&#20445;&#25968;&#25454;&#31354;&#38388;&#30340;&#20840;&#23616;&#25910;&#32553;&#24615;&#12290;&#25105;&#20204;&#22312;2D&#12289;4D&#21644;8D&#30340;LASA&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;ELCD&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Global stability and robustness guarantees in learned dynamical systems are essential to ensure well-behavedness of the systems in the face of uncertainty. We present Extended Linearized Contracting Dynamics (ELCD), the first neural network-based dynamical system with global contractivity guarantees in arbitrary metrics. The key feature of ELCD is a parametrization of the extended linearization of the nonlinear vector field. In its most basic form, ELCD is guaranteed to be (i) globally exponentially stable, (ii) equilibrium contracting, and (iii) globally contracting with respect to some metric. To allow for contraction with respect to more general metrics in the data space, we train diffeomorphisms between the data space and a latent space and enforce contractivity in the latent space, which ensures global contractivity in the data space. We demonstrate the performance of ELCD on the $2$D, $4$D, and $8$D LASA datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#20998;&#25903;&#31574;&#30053;&#20013;&#30340;&#23481;&#37327;&#65292;&#24182;&#21457;&#29616;&#20102;&#28040;&#24687;&#20256;&#36882;GNN (MP-GNN) &#30340;&#34920;&#36798;&#33021;&#21147;&#30340;&#23616;&#38480;&#24615;&#20197;&#21450;&#21478;&#19968;&#31181;GNN&#32467;&#26500; second-order folklore GNN (2-FGNN) &#30340;&#36890;&#29992;&#36924;&#36817;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2402.07099</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#25903;&#31574;&#30053;&#20013;&#30340;&#23481;&#37327;
&lt;/p&gt;
&lt;p&gt;
Rethinking the Capacity of Graph Neural Networks for Branching Strategy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#20998;&#25903;&#31574;&#30053;&#20013;&#30340;&#23481;&#37327;&#65292;&#24182;&#21457;&#29616;&#20102;&#28040;&#24687;&#20256;&#36882;GNN (MP-GNN) &#30340;&#34920;&#36798;&#33021;&#21147;&#30340;&#23616;&#38480;&#24615;&#20197;&#21450;&#21478;&#19968;&#31181;GNN&#32467;&#26500; second-order folklore GNN (2-FGNN) &#30340;&#36890;&#29992;&#36924;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#39044;&#27979;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#65288;MILPs&#65289;&#30340;&#23646;&#24615;&#21644;&#21551;&#21457;&#24335;&#65292;&#24182;&#21152;&#36895;MILP&#27714;&#35299;&#22120;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;GNNs&#22312;&#34920;&#31034;&#25552;&#20379;&#20998;&#25903;&#38480;&#30028;&#31639;&#27861;&#20013;&#39640;&#25928;&#31574;&#30053;&#30340;&#24378;&#20998;&#25903;&#65288;SB&#65289;&#24471;&#20998;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#23613;&#31649;&#29616;&#26377;&#25991;&#29486;&#20013;&#32463;&#24120;&#20351;&#29992;&#26368;&#31616;&#21333;&#30340;&#28040;&#24687;&#20256;&#36882;GNN&#65288;MP-GNN&#65289;&#26469;&#23398;&#20064;SB&#24471;&#20998;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#34920;&#36798;&#33021;&#21147;&#30340;&#19968;&#20010;&#26681;&#26412;&#23616;&#38480;&#24615;--&#23384;&#22312;&#20004;&#20010;&#19981;&#21516;SB&#24471;&#20998;&#30340;MILP&#23454;&#20363;&#65292;&#26080;&#35770;&#21442;&#25968;&#30340;&#25968;&#37327;&#22914;&#20309;&#65292;&#37117;&#26080;&#27861;&#36890;&#36807;&#20219;&#20309;MP-GNN&#21306;&#20998;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#65292;&#29992;&#20110;&#21478;&#19968;&#31181;GNN&#32467;&#26500;&#31216;&#20026;second-order folklore GNN&#65288;2-FGNN&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#20309;MILP&#25968;&#25454;&#20998;&#24067;&#65292;&#24635;&#26159;&#23384;&#22312;&#19968;&#20010;&#21487;&#20197;&#20197;&#20219;&#24847;&#39640;&#31934;&#24230;&#21644;&#20219;&#24847;&#39640;&#27010;&#29575;&#36924;&#36817;SB&#24471;&#20998;&#30340;2-FGNN&#12290;&#19968;&#20010;&#23567;&#35268;&#27169;&#30340;&#25968;&#20540;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have been widely used to predict properties and heuristics of mixed-integer linear programs (MILPs) and hence accelerate MILP solvers. This paper investigates the capacity of GNNs to represent strong branching (SB) scores that provide an efficient strategy in the branch-and-bound algorithm.   Although message-passing GNN (MP-GNN), as the simplest GNN structure, is frequently employed in the existing literature to learn SB scores, we prove a fundamental limitation in its expressive power -- there exist two MILP instances with different SB scores that cannot be distinguished by any MP-GNN, regardless of the number of parameters. In addition, we establish a universal approximation theorem for another GNN structure called the second-order folklore GNN (2-FGNN). We show that for any data distribution over MILPs, there always exists a 2-FGNN that can approximate the SB score with arbitrarily high accuracy and arbitrarily high probability. A small-scale numerical 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29109;&#27491;&#21017;&#21270;&#30340;&#25193;&#25955;&#31574;&#30053;&#19982;Q-&#38598;&#21512;&#30456;&#32467;&#21512;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#19968;&#20010;&#22797;&#26434;&#30340;&#21160;&#20316;&#20998;&#24067;&#36716;&#21270;&#20026;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#65292;&#28982;&#21518;&#20351;&#29992;&#36870;&#26102;&#38388;SDE&#37319;&#26679;&#21160;&#20316;&#65292;&#20197;&#25913;&#21892;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#25506;&#32034;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;Q-&#38598;&#21512;&#30340;&#19979;&#20449;&#24515;&#30028;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#31574;&#30053;&#25913;&#36827;&#12290;&#22312;D4RL&#22522;&#20934;&#20219;&#21153;&#30340;&#22823;&#22810;&#25968;&#20219;&#21153;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04080</link><description>&lt;p&gt;
&#29109;&#27491;&#21017;&#21270;&#25193;&#25955;&#31574;&#30053;&#19982;Q-&#38598;&#21512;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Entropy-regularized Diffusion Policy with Q-Ensembles for Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04080
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29109;&#27491;&#21017;&#21270;&#30340;&#25193;&#25955;&#31574;&#30053;&#19982;Q-&#38598;&#21512;&#30456;&#32467;&#21512;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#19968;&#20010;&#22797;&#26434;&#30340;&#21160;&#20316;&#20998;&#24067;&#36716;&#21270;&#20026;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#65292;&#28982;&#21518;&#20351;&#29992;&#36870;&#26102;&#38388;SDE&#37319;&#26679;&#21160;&#20316;&#65292;&#20197;&#25913;&#21892;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#25506;&#32034;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;Q-&#38598;&#21512;&#30340;&#19979;&#20449;&#24515;&#30028;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#31574;&#30053;&#25913;&#36827;&#12290;&#22312;D4RL&#22522;&#20934;&#20219;&#21153;&#30340;&#22823;&#22810;&#25968;&#20219;&#21153;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#35757;&#32451;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#25193;&#25955;&#31574;&#30053;&#30340;&#20808;&#36827;&#25216;&#26415;&#12290;&#26680;&#24515;&#26159;&#19968;&#20010;&#22343;&#20540;&#22238;&#24402;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#65292;&#23427;&#23558;&#22797;&#26434;&#30340;&#21160;&#20316;&#20998;&#24067;&#36716;&#21270;&#20026;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#65292;&#28982;&#21518;&#22312;&#29615;&#22659;&#29366;&#24577;&#26465;&#20214;&#19979;&#20351;&#29992;&#30456;&#24212;&#30340;&#36870;&#26102;&#38388;SDE&#37319;&#26679;&#21160;&#20316;&#65292;&#31867;&#20284;&#20110;&#20856;&#22411;&#30340;&#25193;&#25955;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#19968;&#20010;SDE&#26377;&#35299;&#65292;&#25105;&#20204;&#21487;&#20197;&#29992;&#23427;&#26469;&#35745;&#31639;&#31574;&#30053;&#30340;&#23545;&#25968;&#27010;&#29575;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#29109;&#27491;&#21017;&#39033;&#65292;&#25913;&#36827;&#20102;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#25506;&#32034;&#33021;&#21147;&#12290;&#20026;&#20102;&#20943;&#36731;&#26469;&#33258;&#20998;&#24067;&#22806;&#25968;&#25454;&#28857;&#30340;&#19981;&#20934;&#30830;&#20540;&#20989;&#25968;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#23398;&#20064;Q-&#38598;&#21512;&#30340;&#19979;&#20449;&#24515;&#30028;&#20197;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#31574;&#30053;&#25913;&#36827;&#12290;&#36890;&#36807;&#23558;&#29109;&#27491;&#21017;&#21270;&#25193;&#25955;&#31574;&#30053;&#19982;Q-&#38598;&#21512;&#32467;&#21512;&#24212;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;D4RL&#22522;&#20934;&#20219;&#21153;&#30340;&#22823;&#22810;&#25968;&#20219;&#21153;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20195;&#30721;&#21487;&#22312;\href{https://github.com/ruoqizzz/Entro}{https://github.com/ruoqizzz/Entro}&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents advanced techniques of training diffusion policies for offline reinforcement learning (RL). At the core is a mean-reverting stochastic differential equation (SDE) that transfers a complex action distribution into a standard Gaussian and then samples actions conditioned on the environment state with a corresponding reverse-time SDE, like a typical diffusion policy. We show that such an SDE has a solution that we can use to calculate the log probability of the policy, yielding an entropy regularizer that improves the exploration of offline datasets. To mitigate the impact of inaccurate value functions from out-of-distribution data points, we further propose to learn the lower confidence bound of Q-ensembles for more robust policy improvement. By combining the entropy-regularized diffusion policy with Q-ensembles in offline RL, our method achieves state-of-the-art performance on most tasks in D4RL benchmarks. Code is available at \href{https://github.com/ruoqizzz/Entro
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#32479;&#35745;&#27169;&#22411;&#30340;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#19988;&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#22788;&#29702;&#22823;&#37327;&#21442;&#25968;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.09184</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#20004;&#23610;&#24230;&#22797;&#26434;&#24230;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
A Two-Scale Complexity Measure for Deep Learning Models. (arXiv:2401.09184v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09184
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#32479;&#35745;&#27169;&#22411;&#30340;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#19988;&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#22788;&#29702;&#22823;&#37327;&#21442;&#25968;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#25928;&#32500;&#24230;&#30340;&#32479;&#35745;&#27169;&#22411;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#12290;&#36825;&#20010;&#26032;&#30340;&#25968;&#37327;&#22312;&#23545;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#26631;&#20934;&#25968;&#25454;&#38598;&#21644;&#27969;&#34892;&#30340;&#27169;&#22411;&#26550;&#26500;&#30340;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;2sED&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#23545;&#20110;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#20174;&#19979;&#26041;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#35299;&#20915;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#36817;&#20284;&#23545;&#19981;&#21516;&#30340;&#31361;&#20986;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#37117;&#24456;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel capacity measure 2sED for statistical models based on the effective dimension. The new quantity provably bounds the generalization error under mild assumptions on the model. Furthermore, simulations on standard data sets and popular model architectures show that 2sED correlates well with the training error. For Markovian models, we show how to efficiently approximate 2sED from below through a layerwise iterative approach, which allows us to tackle deep learning models with a large number of parameters. Simulation results suggest that the approximation is good for different prominent models and data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20154;&#24037;&#26234;&#33021;&#21327;&#20316;&#20013;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#23545;&#20154;&#31867;&#22996;&#25176;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#26174;&#33879;&#25552;&#39640;&#20102;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#22242;&#38431;&#30340;&#34920;&#29616;&#65292;&#24182;&#19988;&#22996;&#25176;&#34892;&#20026;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20449;&#24687;&#19979;&#21457;&#29983;&#26174;&#33879;&#21464;&#21270;&#12290;&#36825;&#39033;&#30740;&#31350;&#25512;&#36827;&#20102;&#23545;&#20154;&#24037;&#26234;&#33021;&#22996;&#25176;&#20013;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20114;&#21160;&#30340;&#29702;&#35299;&#65292;&#24182;&#20026;&#35774;&#35745;&#26356;&#26377;&#25928;&#30340;&#21327;&#20316;&#31995;&#32479;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2401.04729</link><description>&lt;p&gt;
&#20851;&#20110;&#19978;&#19979;&#25991;&#20449;&#24687;&#23545;&#20154;&#31867;&#22312;&#20154;&#24037;&#26234;&#33021;&#21327;&#20316;&#20013;&#30340;&#22996;&#25176;&#34892;&#20026;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the Effect of Contextual Information on Human Delegation Behavior in Human-AI collaboration. (arXiv:2401.04729v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20154;&#24037;&#26234;&#33021;&#21327;&#20316;&#20013;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#23545;&#20154;&#31867;&#22996;&#25176;&#34892;&#20026;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#26174;&#33879;&#25552;&#39640;&#20102;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#22242;&#38431;&#30340;&#34920;&#29616;&#65292;&#24182;&#19988;&#22996;&#25176;&#34892;&#20026;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20449;&#24687;&#19979;&#21457;&#29983;&#26174;&#33879;&#21464;&#21270;&#12290;&#36825;&#39033;&#30740;&#31350;&#25512;&#36827;&#20102;&#23545;&#20154;&#24037;&#26234;&#33021;&#22996;&#25176;&#20013;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20114;&#21160;&#30340;&#29702;&#35299;&#65292;&#24182;&#20026;&#35774;&#35745;&#26356;&#26377;&#25928;&#30340;&#21327;&#20316;&#31995;&#32479;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#30340;&#19981;&#26029;&#22686;&#24378;&#33021;&#21147;&#20026;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#30340;&#21327;&#20316;&#24102;&#26469;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;&#21033;&#29992;&#29616;&#26377;&#30340;&#20114;&#34917;&#33021;&#21147;&#65292;&#35753;&#20154;&#20204;&#23558;&#20010;&#21035;&#23454;&#20363;&#22996;&#25176;&#32473;&#20154;&#24037;&#26234;&#33021;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20351;&#20154;&#20204;&#26377;&#25928;&#22320;&#22996;&#25176;&#23454;&#20363;&#38656;&#35201;&#20182;&#20204;&#35780;&#20272;&#33258;&#24049;&#21644;&#20154;&#24037;&#26234;&#33021;&#22312;&#32473;&#23450;&#20219;&#21153;&#30340;&#32972;&#26223;&#19979;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#20154;&#31867;&#20915;&#23450;&#23558;&#23454;&#20363;&#22996;&#25176;&#32473;&#20154;&#24037;&#26234;&#33021;&#26102;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#26174;&#33879;&#25552;&#39640;&#20102;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#22242;&#38431;&#30340;&#34920;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#24403;&#21442;&#19982;&#32773;&#25509;&#25910;&#21040;&#19981;&#21516;&#31867;&#22411;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#26102;&#65292;&#22996;&#25176;&#34892;&#20026;&#20250;&#21457;&#29983;&#26174;&#33879;&#21464;&#21270;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#36825;&#39033;&#30740;&#31350;&#25512;&#36827;&#20102;&#20154;&#24037;&#26234;&#33021;&#22996;&#25176;&#20013;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20114;&#21160;&#30340;&#29702;&#35299;&#65292;&#24182;&#20026;&#35774;&#35745;&#26356;&#26377;&#25928;&#30340;&#21327;&#20316;&#31995;&#32479;&#25552;&#20379;&#20102;&#21487;&#34892;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The constantly increasing capabilities of artificial intelligence (AI) open new possibilities for human-AI collaboration. One promising approach to leverage existing complementary capabilities is allowing humans to delegate individual instances to the AI. However, enabling humans to delegate instances effectively requires them to assess both their own and the AI's capabilities in the context of the given task. In this work, we explore the effects of providing contextual information on human decisions to delegate instances to an AI. We find that providing participants with contextual information significantly improves the human-AI team performance. Additionally, we show that the delegation behavior changes significantly when participants receive varying types of contextual information. Overall, this research advances the understanding of human-AI interaction in human delegation and provides actionable insights for designing more effective collaborative systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#21547;&#26377;93&#20010;&#20070;&#31821;&#21644;&#23545;&#24212;&#26377;&#22768;&#20070;&#30340;&#25968;&#25454;&#38598;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#27169;&#22411;&#26469;&#39044;&#27979;&#26377;&#22768;&#20070;&#25991;&#26412;&#20013;&#30340;&#38901;&#24459;&#23646;&#24615;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#39044;&#27979;&#38901;&#24459;&#19982;&#20154;&#31867;&#26391;&#35835;&#27604;&#21830;&#19994;&#32423;TTS&#31995;&#32479;&#26356;&#30456;&#20851;&#65292;&#24182;&#19988;&#20154;&#20204;&#26356;&#21916;&#27426;&#38901;&#24459;&#22686;&#24378;&#30340;&#26377;&#22768;&#20070;&#26391;&#35835;&#12290;</title><link>http://arxiv.org/abs/2310.06930</link><description>&lt;p&gt;
&#12298;&#26377;&#22768;&#20070;&#30340;&#38901;&#24459;&#20998;&#26512;&#12299;
&lt;/p&gt;
&lt;p&gt;
Prosody Analysis of Audiobooks. (arXiv:2310.06930v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06930
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#21547;&#26377;93&#20010;&#20070;&#31821;&#21644;&#23545;&#24212;&#26377;&#22768;&#20070;&#30340;&#25968;&#25454;&#38598;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#27169;&#22411;&#26469;&#39044;&#27979;&#26377;&#22768;&#20070;&#25991;&#26412;&#20013;&#30340;&#38901;&#24459;&#23646;&#24615;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#39044;&#27979;&#38901;&#24459;&#19982;&#20154;&#31867;&#26391;&#35835;&#27604;&#21830;&#19994;&#32423;TTS&#31995;&#32479;&#26356;&#30456;&#20851;&#65292;&#24182;&#19988;&#20154;&#20204;&#26356;&#21916;&#27426;&#38901;&#24459;&#22686;&#24378;&#30340;&#26377;&#22768;&#20070;&#26391;&#35835;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#25991;&#26412;&#36716;&#35821;&#38899;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20351;&#24471;&#20174;&#25991;&#26412;&#20013;&#29983;&#25104;&#33258;&#28982;&#38899;&#25928;&#30340;&#38899;&#39057;&#25104;&#20026;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#26377;&#22768;&#20070;&#26391;&#35835;&#28041;&#21450;&#21040;&#35835;&#32773;&#30340;&#25103;&#21095;&#24615;&#22768;&#38899;&#21644;&#35821;&#35843;&#65292;&#26356;&#22810;&#22320;&#20381;&#36182;&#24773;&#24863;&#12289;&#23545;&#35805;&#21644;&#21465;&#36848;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;93&#26412;&#20070;&#19982;&#20854;&#23545;&#24212;&#30340;&#26377;&#22768;&#20070;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#20174;&#21465;&#36848;&#25991;&#26412;&#20013;&#39044;&#27979;&#38901;&#24459;&#23646;&#24615;&#65288;&#38899;&#39640;&#12289;&#38899;&#37327;&#21644;&#35821;&#36895;&#65289;&#65292;&#24182;&#20351;&#29992;&#35821;&#35328;&#24314;&#27169;&#12290;&#25105;&#20204;&#39044;&#27979;&#30340;&#38901;&#24459;&#23646;&#24615;&#19982;&#20154;&#31867;&#26391;&#35835;&#30340;&#30456;&#20851;&#24615;&#35201;&#36828;&#39640;&#20110;&#21830;&#19994;&#32423;TTS&#31995;&#32479;&#30340;&#32467;&#26524;&#65306;&#22312;24&#26412;&#20070;&#20013;&#65292;&#25105;&#20204;&#39044;&#27979;&#30340;&#38899;&#39640;&#23545;22&#26412;&#20070;&#30340;&#20154;&#31867;&#38405;&#35835;&#26356;&#20855;&#30456;&#20851;&#24615;&#65292;&#32780;&#25105;&#20204;&#39044;&#27979;&#30340;&#38899;&#37327;&#23646;&#24615;&#23545;23&#26412;&#20070;&#30340;&#20154;&#31867;&#38405;&#35835;&#26356;&#21152;&#30456;&#20284;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#20154;&#31867;&#35780;&#20272;&#30740;&#31350;&#65292;&#20197;&#37327;&#21270;&#20154;&#20204;&#26356;&#21916;&#27426;&#38901;&#24459;&#22686;&#24378;&#30340;&#26377;&#22768;&#20070;&#26391;&#35835;&#36824;&#26159;&#21830;&#19994;&#32423;&#25991;&#26412;&#36716;&#35821;&#38899;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in text-to-speech have made it possible to generate natural-sounding audio from text. However, audiobook narrations involve dramatic vocalizations and intonations by the reader, with greater reliance on emotions, dialogues, and descriptions in the narrative. Using our dataset of 93 aligned book-audiobook pairs, we present improved models for prosody prediction properties (pitch, volume, and rate of speech) from narrative text using language modeling. Our predicted prosody attributes correlate much better with human audiobook readings than results from a state-of-the-art commercial TTS system: our predicted pitch shows a higher correlation with human reading for 22 out of the 24 books, while our predicted volume attribute proves more similar to human reading for 23 out of the 24 books. Finally, we present a human evaluation study to quantify the extent that people prefer prosody-enhanced audiobook readings over commercial text-to-speech systems.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20174;&#24515;&#33039;MRI&#20013;&#30340;&#30693;&#35782;&#36716;&#31227;&#35299;&#38145;&#24515;&#30005;&#22270;&#30340;&#35786;&#26029;&#28508;&#21147;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;CMR&#22270;&#20687;&#20013;&#30340;&#39046;&#22495;&#29305;&#23450;&#20449;&#24687;&#36716;&#31227;&#21040;ECG&#23884;&#20837;&#20013;&#65292;&#35813;&#26041;&#27861;&#23454;&#29616;&#20102;&#20165;&#26681;&#25454;ECG&#25968;&#25454;&#36827;&#34892;&#20840;&#38754;&#30340;&#24515;&#33039;&#31579;&#26597;&#65292;&#24182;&#33021;&#39044;&#27979;&#24515;&#34880;&#31649;&#30142;&#30149;&#30340;&#20010;&#20307;&#39118;&#38505;&#21644;&#30830;&#23450;&#24515;&#33039;&#34920;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.05764</link><description>&lt;p&gt;
&#36890;&#36807;&#20174;&#24515;&#33039;MRI&#20013;&#30340;&#30693;&#35782;&#36716;&#31227;&#35299;&#38145;&#24515;&#30005;&#22270;&#30340;&#35786;&#26029;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI. (arXiv:2308.05764v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05764
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20174;&#24515;&#33039;MRI&#20013;&#30340;&#30693;&#35782;&#36716;&#31227;&#35299;&#38145;&#24515;&#30005;&#22270;&#30340;&#35786;&#26029;&#28508;&#21147;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;CMR&#22270;&#20687;&#20013;&#30340;&#39046;&#22495;&#29305;&#23450;&#20449;&#24687;&#36716;&#31227;&#21040;ECG&#23884;&#20837;&#20013;&#65292;&#35813;&#26041;&#27861;&#23454;&#29616;&#20102;&#20165;&#26681;&#25454;ECG&#25968;&#25454;&#36827;&#34892;&#20840;&#38754;&#30340;&#24515;&#33039;&#31579;&#26597;&#65292;&#24182;&#33021;&#39044;&#27979;&#24515;&#34880;&#31649;&#30142;&#30149;&#30340;&#20010;&#20307;&#39118;&#38505;&#21644;&#30830;&#23450;&#24515;&#33039;&#34920;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24515;&#30005;&#22270; (ECG) &#26159;&#19968;&#31181;&#24191;&#27867;&#21487;&#29992;&#30340;&#35786;&#26029;&#24037;&#20855;&#65292;&#21487;&#20197;&#24555;&#36895;&#21644;&#32463;&#27982;&#39640;&#25928;&#22320;&#35780;&#20272;&#24515;&#34880;&#31649;&#20581;&#24247;&#29366;&#20917;&#12290;&#28982;&#32780;&#65292;&#22312;&#24515;&#34880;&#31649;&#30142;&#30149;&#30340;&#35786;&#26029;&#20013;&#65292;&#36890;&#24120;&#26356;&#21916;&#27426;&#20351;&#29992;&#26114;&#36149;&#30340;&#24515;&#33039;&#30913;&#20849;&#25391; (CMR) &#25104;&#20687;&#36827;&#34892;&#26356;&#35814;&#32454;&#30340;&#26816;&#26597;&#12290;&#34429;&#28982; CMR &#25104;&#20687;&#21487;&#20197;&#25552;&#20379;&#35814;&#32454;&#30340;&#24515;&#33039;&#35299;&#21078;&#21487;&#35270;&#21270;&#65292;&#20294;&#30001;&#20110;&#38271;&#26102;&#38388;&#25195;&#25551;&#21644;&#39640;&#26114;&#30340;&#36153;&#29992;&#65292;&#23427;&#24182;&#19981;&#24191;&#27867;&#21487;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31532;&#19968;&#31181;&#33258;&#30417;&#30563;&#23545;&#27604;&#26041;&#27861;&#65292;&#23558;CMR&#22270;&#20687;&#20013;&#30340;&#39046;&#22495;&#29305;&#23450;&#20449;&#24687;&#36716;&#31227;&#21040;ECG&#23884;&#20837;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#22810;&#27169;&#24577;&#23545;&#27604;&#23398;&#20064;&#19982;&#23631;&#34109;&#25968;&#25454;&#24314;&#27169;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#20165;&#26681;&#25454;ECG&#25968;&#25454;&#36827;&#34892;&#20840;&#38754;&#30340;&#24515;&#33039;&#31579;&#26597;&#12290;&#22312;&#20351;&#29992;&#26469;&#33258;40044&#21517;UK Biobank&#21463;&#35797;&#32773;&#30340;&#25968;&#25454;&#36827;&#34892;&#30340;&#24191;&#27867;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#21487;&#25512;&#24191;&#24615;&#12290;&#25105;&#20204;&#39044;&#27979;&#20102;&#21508;&#31181;&#24515;&#34880;&#31649;&#30142;&#30149;&#30340;&#20010;&#20307;&#39118;&#38505;&#65292;&#24182;&#20165;&#26681;&#25454;ECG&#25968;&#25454;&#30830;&#23450;&#20102;&#19981;&#21516;&#30340;&#24515;&#33039;&#34920;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The electrocardiogram (ECG) is a widely available diagnostic tool that allows for a cost-effective and fast assessment of the cardiovascular health. However, more detailed examination with expensive cardiac magnetic resonance (CMR) imaging is often preferred for the diagnosis of cardiovascular diseases. While providing detailed visualization of the cardiac anatomy, CMR imaging is not widely available due to long scan times and high costs. To address this issue, we propose the first self-supervised contrastive approach that transfers domain-specific information from CMR images to ECG embeddings. Our approach combines multimodal contrastive learning with masked data modeling to enable holistic cardiac screening solely from ECG data. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalizability of our method. We predict the subject-specific risk of various cardiovascular diseases and determine distinct cardiac phenotypes solely from E
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31867;&#31216;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#30340;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.04056</link><description>&lt;p&gt;
&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Manifold Filter-Combine Networks. (arXiv:2307.04056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04056
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31867;&#31216;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#30340;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;(MNNs)&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#12290;&#36825;&#20010;&#31867;&#21035;&#21253;&#25324;&#20102;Wang&#12289;Ruiz&#21644;Ribeiro&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#32771;&#34385;&#30340;MNNs&#65292;&#27969;&#24418;&#25955;&#23556;&#21464;&#25442;(&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;)&#65292;&#20197;&#21450;&#20854;&#20182;&#26377;&#36259;&#30340;&#20043;&#21069;&#22312;&#25991;&#29486;&#20013;&#26410;&#32771;&#34385;&#30340;&#31034;&#20363;&#65292;&#22914;Kipf&#21644;Welling&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#27969;&#24418;&#31561;&#25928;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27809;&#26377;&#23545;&#27969;&#24418;&#26377;&#20840;&#23616;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;&#32780;&#21482;&#33021;&#35775;&#38382;&#26377;&#38480;&#25968;&#37327;&#30340;&#26679;&#26412;&#28857;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#32593;&#32476;&#22312;&#26679;&#26412;&#28857;&#25968;&#36235;&#20110;&#26080;&#31351;&#22823;&#26102;&#33021;&#22815;&#20445;&#35777;&#25910;&#25947;&#21040;&#20854;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;(&#20027;&#35201;&#20851;&#27880;&#29305;&#23450;&#30340;MNN&#32467;&#26500;&#21644;&#22270;&#26500;&#24314;)&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#25910;&#25947;&#36895;&#24230;&#24182;&#19981;&#20381;&#36182;&#20110;&#20351;&#29992;&#30340;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;&#32780;&#19988;&#65292;&#23427;&#34920;&#29616;&#20986;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a large class of manifold neural networks (MNNs) which we call Manifold Filter-Combine Networks. This class includes as special cases, the MNNs considered in previous work by Wang, Ruiz, and Ribeiro, the manifold scattering transform (a wavelet-based model of neural networks), and other interesting examples not previously considered in the literature such as the manifold equivalent of Kipf and Welling's graph convolutional network. We then consider a method, based on building a data-driven graph, for implementing such networks when one does not have global knowledge of the manifold, but merely has access to finitely many sample points. We provide sufficient conditions for the network to provably converge to its continuum limit as the number of sample points tends to infinity. Unlike previous work (which focused on specific MNN architectures and graph constructions), our rate of convergence does not explicitly depend on the number of filters used. Moreover, it exhibits line
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#22312;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;ODE&#31995;&#32479;&#65292;&#21487;&#20197;&#35299;&#20915;&#26174;&#24335;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#25968;&#25454;&#21644;&#22270;&#20687;&#25968;&#25454;&#20013;&#37117;&#20855;&#26377;&#36890;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.10189</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#23398;&#20064;&#39640;&#32500;&#38750;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning High-Dimensional Nonparametric Differential Equations via Multivariate Occupation Kernel Functions. (arXiv:2306.10189v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#22312;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;ODE&#31995;&#32479;&#65292;&#21487;&#20197;&#35299;&#20915;&#26174;&#24335;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#25968;&#25454;&#21644;&#22270;&#20687;&#25968;&#25454;&#20013;&#37117;&#20855;&#26377;&#36890;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;$d$&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;$n$&#20010;&#36712;&#36857;&#24555;&#29031;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#31995;&#32479;&#38656;&#35201;&#23398;&#20064;$d$&#20010;&#20989;&#25968;&#12290;&#38500;&#38750;&#20855;&#26377;&#39069;&#22806;&#30340;&#31995;&#32479;&#23646;&#24615;&#30693;&#35782;&#65292;&#20363;&#22914;&#31232;&#30095;&#24615;&#21644;&#23545;&#31216;&#24615;&#65292;&#21542;&#21017;&#26174;&#24335;&#30340;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21521;&#37327;&#20540;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#25552;&#20379;&#30340;&#38544;&#24335;&#20844;&#24335;&#23398;&#20064;&#30340;&#32447;&#24615;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;ODE&#37325;&#20889;&#20026;&#26356;&#24369;&#30340;&#31215;&#20998;&#24418;&#24335;&#65292;&#25105;&#20204;&#38543;&#21518;&#36827;&#34892;&#26368;&#23567;&#21270;&#24182;&#25512;&#23548;&#20986;&#25105;&#20204;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#35299;&#21521;&#37327;&#22330;&#20381;&#36182;&#20110;&#19982;&#35299;&#36712;&#36857;&#30456;&#20851;&#30340;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;$d$&#21487;&#33021;&#36229;&#36807;100&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#20174;&#22270;&#20687;&#25968;&#25454;&#23398;&#20064;&#38750;&#21442;&#25968;&#19968;&#38454;&#25311;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning a nonparametric system of ordinary differential equations (ODEs) from $n$ trajectory snapshots in a $d$-dimensional state space requires learning $d$ functions of $d$ variables. Explicit formulations scale quadratically in $d$ unless additional knowledge about system properties, such as sparsity and symmetries, is available. In this work, we propose a linear approach to learning using the implicit formulation provided by vector-valued Reproducing Kernel Hilbert Spaces. By rewriting the ODEs in a weaker integral form, which we subsequently minimize, we derive our learning algorithm. The minimization problem's solution for the vector field relies on multivariate occupation kernel functions associated with the solution trajectories. We validate our approach through experiments on highly nonlinear simulated and real data, where $d$ may exceed 100. We further demonstrate the versatility of the proposed method by learning a nonparametric first order quasilinear partial differential 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31163;&#32447;&#20248;&#20808;&#32463;&#39564;&#37325;&#25918;&#65288;OPER&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#36890;&#36807;&#35774;&#35745;&#19968;&#31867;&#20248;&#20808;&#32423;&#20989;&#25968;&#26469;&#23545;&#39640;&#22238;&#25253;&#30340;&#36716;&#25442;&#36827;&#34892;&#20248;&#20808;&#22788;&#29702;&#65292;&#20174;&#32780;&#25913;&#21892;&#34892;&#20026;&#31574;&#30053;&#65292;&#24182;&#22312;&#27492;&#25913;&#36827;&#30340;&#31574;&#30053;&#32422;&#26463;&#19979;&#20248;&#21270;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;OPER&#26041;&#27861;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.05412</link><description>&lt;p&gt;
&#31163;&#32447;&#20248;&#20808;&#32463;&#39564;&#37325;&#25918;
&lt;/p&gt;
&lt;p&gt;
Offline Prioritized Experience Replay. (arXiv:2306.05412v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31163;&#32447;&#20248;&#20808;&#32463;&#39564;&#37325;&#25918;&#65288;OPER&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#36890;&#36807;&#35774;&#35745;&#19968;&#31867;&#20248;&#20808;&#32423;&#20989;&#25968;&#26469;&#23545;&#39640;&#22238;&#25253;&#30340;&#36716;&#25442;&#36827;&#34892;&#20248;&#20808;&#22788;&#29702;&#65292;&#20174;&#32780;&#25913;&#21892;&#34892;&#20026;&#31574;&#30053;&#65292;&#24182;&#22312;&#27492;&#25913;&#36827;&#30340;&#31574;&#30053;&#32422;&#26463;&#19979;&#20248;&#21270;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;OPER&#26041;&#27861;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38754;&#20020;&#30528;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#35774;&#35745;&#23398;&#20064;&#31574;&#30053;&#21644;&#34892;&#20026;&#31574;&#30053;&#20043;&#38388;&#30340;&#22797;&#26434;&#32422;&#26463;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32422;&#26463;&#36890;&#36807;&#22343;&#21248;&#37319;&#26679;&#31561;&#26041;&#24335;&#34987;&#24212;&#29992;&#21040;&#34920;&#29616;&#33391;&#22909;&#21644;&#34920;&#29616;&#24046;&#30340;&#34892;&#21160;&#19978;&#65292;&#36825;&#21487;&#33021;&#20250;&#23545;&#23398;&#20064;&#31574;&#30053;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31163;&#32447;&#20248;&#20808;&#32463;&#39564;&#37325;&#25918;&#65288;OPER&#65289;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#31867;&#20248;&#20808;&#32423;&#20989;&#25968;&#65292;&#29992;&#20110;&#23558;&#39640;&#22238;&#25253;&#30340;&#36716;&#25442;&#32622;&#20110;&#26356;&#39057;&#32321;&#30340;&#35775;&#38382;&#20013;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31867;&#20248;&#20808;&#32423;&#20989;&#25968;&#33021;&#22815;&#24341;&#36215;&#34892;&#20026;&#31574;&#30053;&#30340;&#25913;&#21892;&#65292;&#24403;&#31574;&#30053;&#32422;&#26463;&#21040;&#36825;&#20010;&#25913;&#36827;&#30340;&#31574;&#30053;&#19978;&#26102;&#65292;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#24456;&#21487;&#33021;&#24471;&#21040;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#31181;&#23454;&#29992;&#31574;&#30053;&#26469;&#33719;&#24471;&#22522;&#20110;&#25311;&#21512;&#20540;&#32593;&#32476;&#30340;&#20248;&#20808;&#26435;&#37325;&#65288;OPER-A&#65289;&#25110;&#32773;u
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL) is challenged by the distributional shift problem. To address this problem, existing works mainly focus on designing sophisticated policy constraints between the learned policy and the behavior policy. However, these constraints are applied equally to well-performing and inferior actions through uniform sampling, which might negatively affect the learned policy. To alleviate this issue, we propose Offline Prioritized Experience Replay (OPER), featuring a class of priority functions designed to prioritize highly-rewarding transitions, making them more frequently visited during training. Through theoretical analysis, we show that this class of priority functions induce an improved behavior policy, and when constrained to this improved policy, a policy-constrained offline RL algorithm is likely to yield a better solution. We develop two practical strategies to obtain priority weights by estimating advantages based on a fitted value network (OPER-A) or u
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22635;&#34917;&#20102;&#22312;&#39640;&#32500;&#29305;&#24449;&#21464;&#37327;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#26412;&#36523;&#36827;&#34892;&#25512;&#26029;&#30340;&#24037;&#20316;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#30340;&#20272;&#35745;&#22120;&#20197;&#25552;&#39640;&#20215;&#20540;&#20989;&#25968;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.12553</link><description>&lt;p&gt;
&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#30340;&#39640;&#32500;&#29305;&#24449;&#28176;&#36817;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Inference for Multi-Stage Stationary Treatment Policy with High Dimensional Features. (arXiv:2301.12553v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22635;&#34917;&#20102;&#22312;&#39640;&#32500;&#29305;&#24449;&#21464;&#37327;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#26412;&#36523;&#36827;&#34892;&#25512;&#26029;&#30340;&#24037;&#20316;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#30340;&#20272;&#35745;&#22120;&#20197;&#25552;&#39640;&#20215;&#20540;&#20989;&#25968;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#27835;&#30103;&#35268;&#21017;&#26159;&#19968;&#31995;&#21015;&#38024;&#23545;&#20010;&#20307;&#29305;&#24449;&#37327;&#36523;&#23450;&#21046;&#30340;&#22810;&#38454;&#27573;&#20915;&#31574;&#20989;&#25968;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#19968;&#31867;&#37325;&#35201;&#30340;&#27835;&#30103;&#31574;&#30053;&#26159;&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#65292;&#20854;&#20351;&#29992;&#30456;&#21516;&#30340;&#20915;&#31574;&#20989;&#25968;&#26469;&#25351;&#23450;&#27835;&#30103;&#20998;&#37197;&#27010;&#29575;&#65292;&#22312;&#20915;&#31574;&#26102;&#22522;&#20110;&#21516;&#26102;&#21253;&#25324;&#22522;&#32447;&#21464;&#37327;&#65288;&#20363;&#22914;&#20154;&#21475;&#32479;&#35745;&#23398;&#65289;&#21644;&#26102;&#21464;&#21464;&#37327;&#65288;&#20363;&#22914;&#24120;&#35268;&#26816;&#27979;&#21040;&#30340;&#30142;&#30149;&#29983;&#29289;&#26631;&#24535;&#29289;&#65289;&#30340;&#19968;&#32452;&#29305;&#24449;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#22823;&#37327;&#25991;&#29486;&#23545;&#19982;&#21160;&#24577;&#27835;&#30103;&#31574;&#30053;&#30456;&#20851;&#30340;&#20215;&#20540;&#20989;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#20294;&#22312;&#39640;&#32500;&#29305;&#24449;&#21464;&#37327;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#27835;&#30103;&#31574;&#30053;&#26412;&#36523;&#30340;&#24037;&#20316;&#36824;&#24456;&#23569;&#12290;&#25105;&#20204;&#26088;&#22312;&#22635;&#34917;&#36825;&#39033;&#24037;&#20316;&#30340;&#31354;&#30333;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#22522;&#20110;&#22686;&#24378;&#30340;&#20498;&#25968;&#26435;&#37325;&#20272;&#35745;&#22120;&#20272;&#35745;&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#65292;&#20197;&#25552;&#39640;&#20215;&#20540;&#20989;&#25968;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic treatment rules or policies are a sequence of decision functions over multiple stages that are tailored to individual features. One important class of treatment policies for practice, namely multi-stage stationary treatment policies, prescribe treatment assignment probabilities using the same decision function over stages, where the decision is based on the same set of features consisting of both baseline variables (e.g., demographics) and time-evolving variables (e.g., routinely collected disease biomarkers). Although there has been extensive literature to construct valid inference for the value function associated with the dynamic treatment policies, little work has been done for the policies themselves, especially in the presence of high dimensional feature variables. We aim to fill in the gap in this work. Specifically, we first estimate the multistage stationary treatment policy based on an augmented inverse probability weighted estimator for the value function to increase
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#20351;&#29992;&#20102;&#30495;&#23454;&#21518;&#39564;&#65292;&#36825;&#31181;&#26041;&#27861;&#20173;&#26080;&#27861;&#38450;&#27490;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#21516;&#26102;&#65292;&#27169;&#22411;&#35823;&#24046;&#21644;&#20219;&#21153;&#25968;&#25454;&#19981;&#24179;&#34913;&#20063;&#20250;&#23548;&#33268;&#36830;&#32493;&#23398;&#20064;&#24615;&#33021;&#30340;&#19979;&#38477;&#12290;</title><link>http://arxiv.org/abs/2301.01828</link><description>&lt;p&gt;
&#20851;&#20110;&#36830;&#32493;&#23398;&#20064;&#30340;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
On Sequential Bayesian Inference for Continual Learning. (arXiv:2301.01828v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.01828
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#20351;&#29992;&#20102;&#30495;&#23454;&#21518;&#39564;&#65292;&#36825;&#31181;&#26041;&#27861;&#20173;&#26080;&#27861;&#38450;&#27490;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#21516;&#26102;&#65292;&#27169;&#22411;&#35823;&#24046;&#21644;&#20219;&#21153;&#25968;&#25454;&#19981;&#24179;&#34913;&#20063;&#20250;&#23548;&#33268;&#36830;&#32493;&#23398;&#20064;&#24615;&#33021;&#30340;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#21487;&#29992;&#20110;&#36830;&#32493;&#23398;&#20064;&#65292;&#20197;&#38450;&#27490;&#36807;&#21435;&#20219;&#21153;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#24182;&#22312;&#23398;&#20064;&#26032;&#20219;&#21153;&#26102;&#25552;&#20379;&#20449;&#24687;&#20016;&#23500;&#30340;&#20808;&#39564;&#12290;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#24182;&#27979;&#35797;&#26159;&#21542;&#26377;&#35775;&#38382;&#30495;&#23454;&#21518;&#39564;&#30340;&#20445;&#35777;&#21487;&#20197;&#38450;&#27490;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#20026;&#20102;&#20570;&#21040;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#20351;&#29992;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#25191;&#34892;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#26679;&#26412;&#25311;&#21512;&#23494;&#24230;&#20272;&#35745;&#22120;&#65292;&#23558;&#21518;&#39564;&#20256;&#25773;&#20026;&#26032;&#20219;&#21153;&#30340;&#20808;&#39564;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#26080;&#27861;&#38450;&#27490;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#35777;&#26126;&#20102;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#25191;&#34892;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#22256;&#38590;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#36830;&#32493;&#23398;&#20064;&#30340;&#31616;&#21333;&#20998;&#26512;&#31034;&#20363;&#65292;&#24182;&#24378;&#35843;&#20102;&#27169;&#22411;&#38169;&#35823;&#35828;&#26126;&#38382;&#39064;&#65292;&#21363;&#20351;&#36827;&#34892;&#20102;&#20934;&#30830;&#30340;&#25512;&#26029;&#65292;&#20063;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#30340;&#36830;&#32493;&#23398;&#20064;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20219;&#21153;&#25968;&#25454;&#19981;&#24179;&#34913;&#21487;&#33021;&#23548;&#33268;&#36951;&#24536;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential Bayesian inference can be used for continual learning to prevent catastrophic forgetting of past tasks and provide an informative prior when learning new tasks. We revisit sequential Bayesian inference and test whether having access to the true posterior is guaranteed to prevent catastrophic forgetting in Bayesian neural networks. To do this we perform sequential Bayesian inference using Hamiltonian Monte Carlo. We propagate the posterior as a prior for new tasks by fitting a density estimator on Hamiltonian Monte Carlo samples. We find that this approach fails to prevent catastrophic forgetting demonstrating the difficulty in performing sequential Bayesian inference in neural networks. From there we study simple analytical examples of sequential Bayesian inference and CL and highlight the issue of model misspecification which can lead to sub-optimal continual learning performance despite exact inference. Furthermore, we discuss how task data imbalances can cause forgetting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32534;&#30721;&#31639;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#29305;&#24449;&#20540;&#30340;&#39057;&#29575;&#21644;&#19978;&#19979;&#25991;&#65292;&#23545;NetFlow&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#65292;&#20197;&#25552;&#39640;&#32593;&#32476;&#24322;&#24120;&#26816;&#27979;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2207.03890</link><description>&lt;p&gt;
ENCODE&#65306;&#29992;&#20110;&#32593;&#32476;&#24322;&#24120;&#26816;&#27979;&#30340;&#32534;&#30721;NetFlows
&lt;/p&gt;
&lt;p&gt;
ENCODE: Encoding NetFlows for Network Anomaly Detection. (arXiv:2207.03890v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.03890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32534;&#30721;&#31639;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#29305;&#24449;&#20540;&#30340;&#39057;&#29575;&#21644;&#19978;&#19979;&#25991;&#65292;&#23545;NetFlow&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#65292;&#20197;&#25552;&#39640;&#32593;&#32476;&#24322;&#24120;&#26816;&#27979;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
NetFlow&#25968;&#25454;&#26159;&#35768;&#22810;&#32593;&#32476;&#20998;&#26512;&#24072;&#21644;&#30740;&#31350;&#20154;&#21592;&#20351;&#29992;&#30340;&#27969;&#34892;&#32593;&#32476;&#26085;&#24535;&#26684;&#24335;&#12290;&#19982;&#28145;&#24230;&#21253;&#26816;&#26597;&#30456;&#27604;&#65292;&#20351;&#29992;NetFlow&#30340;&#20248;&#21183;&#22312;&#20110;&#26356;&#26131;&#20110;&#25910;&#38598;&#21644;&#22788;&#29702;&#65292;&#23545;&#38544;&#31169;&#24615;&#30340;&#20405;&#20837;&#24615;&#26356;&#23567;&#12290;&#35768;&#22810;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26469;&#20351;&#29992;NetFlow&#25968;&#25454;&#26816;&#27979;&#32593;&#32476;&#25915;&#20987;&#12290;&#36825;&#20123;&#26426;&#22120;&#23398;&#20064;&#27969;&#27700;&#32447;&#30340;&#31532;&#19968;&#27493;&#26159;&#22312;&#23558;&#25968;&#25454;&#25552;&#20379;&#32473;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20043;&#21069;&#23545;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#12290;&#23384;&#22312;&#35768;&#22810;&#26041;&#27861;&#26469;&#39044;&#22788;&#29702;NetFlow&#25968;&#25454;&#65307;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#21482;&#26159;&#31616;&#21333;&#22320;&#23558;&#29616;&#26377;&#26041;&#27861;&#24212;&#29992;&#20110;&#25968;&#25454;&#65292;&#32780;&#19981;&#32771;&#34385;&#32593;&#32476;&#25968;&#25454;&#30340;&#29305;&#23450;&#23646;&#24615;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23545;&#20110;&#28304;&#33258;&#36719;&#20214;&#31995;&#32479;&#65288;&#22914;NetFlow&#25110;&#36719;&#20214;&#26085;&#24535;&#65289;&#30340;&#25968;&#25454;&#65292;&#29305;&#24449;&#20540;&#30340;&#39057;&#29575;&#21644;&#19978;&#19979;&#25991;&#30340;&#30456;&#20284;&#24615;&#27604;&#20540;&#26412;&#36523;&#30340;&#30456;&#20284;&#24615;&#26356;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32534;&#30721;&#31639;&#27861;&#65292;&#22312;&#22788;&#29702;&#25968;&#25454;&#26102;&#30452;&#25509;&#32771;&#34385;&#29305;&#24449;&#20540;&#30340;&#39057;&#29575;&#21644;&#19978;&#19979;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;
NetFlow data is a popular network log format used by many network analysts and researchers. The advantages of using NetFlow over deep packet inspection are that it is easier to collect and process, and it is less privacy intrusive. Many works have used machine learning to detect network attacks using NetFlow data. The first step for these machine learning pipelines is to pre-process the data before it is given to the machine learning algorithm. Many approaches exist to pre-process NetFlow data; however, these simply apply existing methods to the data, not considering the specific properties of network data. We argue that for data originating from software systems, such as NetFlow or software logs, similarities in frequency and contexts of feature values are more important than similarities in the value itself. In this work, we propose an encoding algorithm that directly takes the frequency and the context of the feature values into account when the data is being processed. Different ty
&lt;/p&gt;</description></item></channel></rss>