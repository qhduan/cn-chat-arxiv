<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>SVGCraft&#24341;&#20837;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#25991;&#26412;&#25551;&#36848;&#20013;&#29983;&#25104;&#25551;&#32472;&#25972;&#20010;&#22330;&#26223;&#30340;&#30690;&#37327;&#22270;&#65292;&#20854;&#20013;&#21253;&#25324;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLM&#36827;&#34892;&#24067;&#23616;&#29983;&#25104;&#12289;&#20135;&#29983;&#36974;&#32617;&#28508;&#21464;&#37327;&#20197;&#36827;&#34892;&#20934;&#30830;&#23545;&#35937;&#25918;&#32622;&#12289;&#34701;&#21512;&#27880;&#24847;&#21147;&#22270;&#20197;&#21450;&#20351;&#29992;&#25193;&#25955;U-Net&#36827;&#34892;&#21512;&#25104;&#65292;&#21516;&#26102;&#36890;&#36807;&#39044;&#35757;&#32451;&#30340;&#32534;&#30721;&#22120;&#21644;LPIPS&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2404.00412</link><description>&lt;p&gt;
SVGCraft:&#36229;&#36234;&#21333;&#20010;&#30446;&#26631;&#25991;&#23383;&#21040;SVG&#32508;&#21512;&#30011;&#24067;&#24067;&#23616;
&lt;/p&gt;
&lt;p&gt;
SVGCraft: Beyond Single Object Text-to-SVG Synthesis with Comprehensive Canvas Layout
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00412
&lt;/p&gt;
&lt;p&gt;
SVGCraft&#24341;&#20837;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#25991;&#26412;&#25551;&#36848;&#20013;&#29983;&#25104;&#25551;&#32472;&#25972;&#20010;&#22330;&#26223;&#30340;&#30690;&#37327;&#22270;&#65292;&#20854;&#20013;&#21253;&#25324;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLM&#36827;&#34892;&#24067;&#23616;&#29983;&#25104;&#12289;&#20135;&#29983;&#36974;&#32617;&#28508;&#21464;&#37327;&#20197;&#36827;&#34892;&#20934;&#30830;&#23545;&#35937;&#25918;&#32622;&#12289;&#34701;&#21512;&#27880;&#24847;&#21147;&#22270;&#20197;&#21450;&#20351;&#29992;&#25193;&#25955;U-Net&#36827;&#34892;&#21512;&#25104;&#65292;&#21516;&#26102;&#36890;&#36807;&#39044;&#35757;&#32451;&#30340;&#32534;&#30721;&#22120;&#21644;LPIPS&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20174;&#25991;&#26412;&#25552;&#31034;&#21040;&#30690;&#37327;&#22270;&#30340;VectorArt&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#35270;&#35273;&#20219;&#21153;&#65292;&#38656;&#35201;&#23545;&#24050;&#30693;&#21644;&#26410;&#30693;&#23454;&#20307;&#36827;&#34892;&#22810;&#26679;&#21270;&#32780;&#30495;&#23454;&#30340;&#25551;&#36848;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#23616;&#38480;&#20110;&#29983;&#25104;&#21333;&#20010;&#23545;&#35937;&#65292;&#32780;&#19981;&#26159;&#30001;&#22810;&#20010;&#20803;&#32032;&#32452;&#25104;&#30340;&#22330;&#26223;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;SVGCraft&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#31471;&#21040;&#31471;&#26694;&#26550;&#65292;&#29992;&#20110;&#20174;&#25991;&#26412;&#25551;&#36848;&#20013;&#29983;&#25104;&#25551;&#32472;&#25972;&#20010;&#22330;&#26223;&#30340;&#30690;&#37327;&#22270;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLM&#20174;&#25991;&#26412;&#25552;&#31034;&#29983;&#25104;&#24067;&#23616;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#25216;&#26415;&#65292;&#36890;&#36807;&#29983;&#20135;&#29305;&#23450;&#36793;&#30028;&#26694;&#20013;&#30340;&#25513;&#33180;&#28508;&#21464;&#37327;&#23454;&#29616;&#20934;&#30830;&#30340;&#23545;&#35937;&#25918;&#32622;&#12290;&#23427;&#24341;&#20837;&#20102;&#19968;&#20010;&#34701;&#21512;&#26426;&#21046;&#65292;&#29992;&#20110;&#38598;&#25104;&#27880;&#24847;&#21147;&#22270;&#65292;&#24182;&#20351;&#29992;&#25193;&#25955;U-Net&#36827;&#34892;&#36830;&#36143;&#30340;&#21512;&#25104;&#65292;&#21152;&#24555;&#32472;&#22270;&#36807;&#31243;&#12290;&#29983;&#25104;&#30340;SVG&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#32534;&#30721;&#22120;&#21644;LPIPS&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#36879;&#26126;&#24230;&#35843;&#21046;&#26469;&#26368;&#22823;&#31243;&#24230;&#22320;&#22686;&#21152;&#30456;&#20284;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00412v1 Announce Type: cross  Abstract: Generating VectorArt from text prompts is a challenging vision task, requiring diverse yet realistic depictions of the seen as well as unseen entities. However, existing research has been mostly limited to the generation of single objects, rather than comprehensive scenes comprising multiple elements. In response, this work introduces SVGCraft, a novel end-to-end framework for the creation of vector graphics depicting entire scenes from textual descriptions. Utilizing a pre-trained LLM for layout generation from text prompts, this framework introduces a technique for producing masked latents in specified bounding boxes for accurate object placement. It introduces a fusion mechanism for integrating attention maps and employs a diffusion U-Net for coherent composition, speeding up the drawing process. The resulting SVG is optimized using a pre-trained encoder and LPIPS loss with opacity modulation to maximize similarity. Additionally, th
&lt;/p&gt;</description></item><item><title>&#23558;&#31232;&#30095;&#35782;&#21035;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65288;SINDy&#65289;&#19982;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;SINDy-RL&#26694;&#26550;&#65292;&#29992;&#20110;&#21019;&#24314;&#39640;&#25928;&#35299;&#37322;&#24615;&#36824;&#26377;&#22312;&#20302;&#25968;&#25454;&#21046;&#24230;&#19979;&#21019;&#24314;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.09110</link><description>&lt;p&gt;
SINDy-RL: &#21487;&#35299;&#37322;&#21644;&#39640;&#25928;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SINDy-RL: Interpretable and Efficient Model-Based Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09110
&lt;/p&gt;
&lt;p&gt;
&#23558;&#31232;&#30095;&#35782;&#21035;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65288;SINDy&#65289;&#19982;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;SINDy-RL&#26694;&#26550;&#65292;&#29992;&#20110;&#21019;&#24314;&#39640;&#25928;&#35299;&#37322;&#24615;&#36824;&#26377;&#22312;&#20302;&#25968;&#25454;&#21046;&#24230;&#19979;&#21019;&#24314;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#24050;&#26174;&#31034;&#20986;&#22312;&#19982;&#22797;&#26434;&#21160;&#24577;&#29615;&#22659;&#20013;&#30456;&#20114;&#20316;&#29992;&#30340;&#22797;&#26434;&#25511;&#21046;&#31574;&#30053;&#20013;&#20855;&#26377;&#26174;&#33879;&#28508;&#21147;&#65292;&#20363;&#22914;&#31283;&#23450;&#25176;&#21345;&#39532;&#20811;&#32858;&#21464;&#21453;&#24212;&#22534;&#30340;&#30913;&#27969;&#20307;&#21160;&#21147;&#23398;&#25110;&#20351;&#29289;&#20307;&#22312;&#27969;&#20307;&#27969;&#21160;&#20013;&#21463;&#21040;&#30340;&#38459;&#21147;&#26368;&#23567;&#21270;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#38656;&#35201;&#22823;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#65292;&#23545;&#35768;&#22810;&#24212;&#29992;&#32780;&#35328;&#25104;&#26412;&#21487;&#33021;&#36807;&#39640;&#12290;&#21478;&#22806;&#65292;&#20381;&#36182;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24448;&#24448;&#20250;&#23548;&#33268;&#38590;&#20197;&#35299;&#37322;&#30340;&#40657;&#30418;&#31574;&#30053;&#65292;&#21487;&#33021;&#22312;&#26576;&#20123;&#23884;&#20837;&#24335;&#31995;&#32479;&#20013;&#20351;&#29992;&#26102;&#35745;&#31639;&#25104;&#26412;&#36807;&#39640;&#12290;&#26368;&#36817;&#30340;&#31232;&#30095;&#23383;&#20856;&#23398;&#20064;&#26041;&#27861;&#30340;&#36827;&#23637;&#65292;&#22914;&#31232;&#30095;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#31232;&#30095;&#35782;&#21035;&#65288;SINDy&#65289;&#65292;&#26174;&#31034;&#20986;&#22312;&#20302;&#25968;&#25454;&#21046;&#24230;&#19979;&#21019;&#24314;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#30340;&#21069;&#26223;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;SINDy-RL&#65292;&#36825;&#26159;&#19968;&#20010;&#32467;&#21512;SINDy&#21644;DRL&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#21019;&#24314;&#39640;&#25928;&#30340;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09110v1 Announce Type: new  Abstract: Deep reinforcement learning (DRL) has shown significant promise for uncovering sophisticated control policies that interact in environments with complicated dynamics, such as stabilizing the magnetohydrodynamics of a tokamak fusion reactor or minimizing the drag force exerted on an object in a fluid flow. However, these algorithms require an abundance of training examples and may become prohibitively expensive for many applications. In addition, the reliance on deep neural networks often results in an uninterpretable, black-box policy that may be too computationally expensive to use with certain embedded systems. Recent advances in sparse dictionary learning, such as the sparse identification of nonlinear dynamics (SINDy), have shown promise for creating efficient and interpretable data-driven models in the low-data regime. In this work we introduce SINDy-RL, a unifying framework for combining SINDy and DRL to create efficient, interpret
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#26469;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2403.07151</link><description>&lt;p&gt;
&#19981;&#35201;&#24536;&#35760;&#25105;&#20570;&#30340;&#20107;&#65306;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;
Don't Forget What I did?: Assessing Client Contributions in Federated Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07151
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#26469;&#35780;&#20272;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#23458;&#25143;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#21327;&#20316;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#65292;&#22810;&#20010;&#23458;&#25143;&#21442;&#19982;&#35757;&#32451;ML&#27169;&#22411;&#65292;&#32780;&#19981;&#26292;&#38706;&#31169;&#20154;&#25968;&#25454;&#12290;&#20844;&#24179;&#20934;&#30830;&#35780;&#20272;&#23458;&#25143;&#36129;&#29486;&#22312;FL&#20013;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#20197;&#20419;&#36827;&#28608;&#21169;&#20998;&#37197;&#24182;&#40723;&#21169;&#22810;&#26679;&#21270;&#23458;&#25143;&#21442;&#19982;&#32479;&#19968;&#27169;&#22411;&#35757;&#32451;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21382;&#21490;&#24863;&#30693;&#30340;&#21338;&#24328;&#29702;&#35770;&#26694;&#26550;FLContrib&#65292;&#29992;&#20110;&#35780;&#20272;&#22312;&#27599;&#20010;FL&#35757;&#32451;&#26102;&#26399;&#20013;&#30340;&#65288;&#28508;&#22312;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#65289;&#23458;&#25143;&#21442;&#19982;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07151v1 Announce Type: cross  Abstract: Federated Learning (FL) is a collaborative machine learning (ML) approach, where multiple clients participate in training an ML model without exposing the private data. Fair and accurate assessment of client contributions is an important problem in FL to facilitate incentive allocation and encouraging diverse clients to participate in a unified model training. Existing methods for assessing client contribution adopts co-operative game-theoretic concepts, such as Shapley values, but under simplified assumptions. In this paper, we propose a history-aware game-theoretic framework, called FLContrib, to assess client contributions when a subset of (potentially non-i.i.d.) clients participate in each epoch of FL training. By exploiting the FL training process and linearity of Shapley value, we develop FLContrib that yields a historical timeline of client contributions as FL training progresses over epochs. Additionally, to assess client cont
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36229;&#21442;&#25968;&#35843;&#25972;&#20013;&#30340;&#38544;&#31169;&#24615;&#38382;&#39064;&#65292;&#21457;&#29616;&#24403;&#21069;&#30340;&#38544;&#31169;&#20998;&#26512;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#32039;&#23494;&#30340;&#65292;&#20294;&#22312;&#29305;&#23450;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#19978;&#21017;&#19981;&#20877;&#25104;&#31435;&#65292;&#24182;&#36890;&#36807;&#38544;&#31169;&#23457;&#35745;&#25581;&#31034;&#20102;&#24403;&#21069;&#29702;&#35770;&#38544;&#31169;&#30028;&#19982;&#23454;&#35777;&#20043;&#38388;&#30340;&#26174;&#33879;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2402.13087</link><description>&lt;p&gt;
&#36873;&#25321;&#22914;&#20309;&#27844;&#28431;&#38544;&#31169;&#65306;&#37325;&#26032;&#23457;&#35270;&#31169;&#26377;&#36873;&#25321;&#21450;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#25913;&#36827;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
How Does Selection Leak Privacy: Revisiting Private Selection and Improved Results for Hyper-parameter Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36229;&#21442;&#25968;&#35843;&#25972;&#20013;&#30340;&#38544;&#31169;&#24615;&#38382;&#39064;&#65292;&#21457;&#29616;&#24403;&#21069;&#30340;&#38544;&#31169;&#20998;&#26512;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#32039;&#23494;&#30340;&#65292;&#20294;&#22312;&#29305;&#23450;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#19978;&#21017;&#19981;&#20877;&#25104;&#31435;&#65292;&#24182;&#36890;&#36807;&#38544;&#31169;&#23457;&#35745;&#25581;&#31034;&#20102;&#24403;&#21069;&#29702;&#35770;&#38544;&#31169;&#30028;&#19982;&#23454;&#35777;&#20043;&#38388;&#30340;&#26174;&#33879;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#20013;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;(DP)&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#20851;&#38190;&#30340;&#36807;&#31243;&#65292;&#28041;&#21450;&#20174;&#20960;&#20010;&#36816;&#34892;&#20013;&#36873;&#25321;&#26368;&#20339;&#30340;&#36807;&#31243;&#12290;&#19982;&#35768;&#22810;&#31169;&#26377;&#31639;&#27861;&#65288;&#21253;&#25324;&#26222;&#36941;&#23384;&#22312;&#30340;DP-SGD&#65289;&#19981;&#21516;&#65292;&#35843;&#25972;&#30340;&#38544;&#31169;&#24433;&#21709;&#20173;&#28982;&#19981;&#22815;&#20102;&#35299;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#31169;&#26377;&#35299;&#20915;&#26041;&#26696;&#29992;&#20110;&#35843;&#25972;&#36807;&#31243;&#65292;&#28982;&#32780;&#19968;&#20010;&#26681;&#26412;&#30340;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#24403;&#21069;&#35299;&#20915;&#26041;&#26696;&#30340;&#38544;&#31169;&#30028;&#26159;&#21542;&#32039;&#23494;&#65311;&#26412;&#25991;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#20102;&#31215;&#26497;&#21644;&#28040;&#26497;&#30340;&#31572;&#26696;&#12290;&#26368;&#21021;&#65292;&#25105;&#20204;&#25552;&#20379;&#30340;&#30740;&#31350;&#35777;&#23454;&#20102;&#24403;&#21069;&#30340;&#38544;&#31169;&#20998;&#26512;&#22312;&#19968;&#33324;&#24847;&#20041;&#19978;&#30830;&#23454;&#26159;&#32039;&#23494;&#30340;&#12290;&#28982;&#32780;&#65292;&#24403;&#25105;&#20204;&#19987;&#38376;&#30740;&#31350;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#26102;&#65292;&#36825;&#31181;&#32039;&#23494;&#24615;&#21017;&#19981;&#20877;&#25104;&#31435;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#23545;&#35843;&#25972;&#36807;&#31243;&#36827;&#34892;&#38544;&#31169;&#23457;&#35745;&#26469;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#31361;&#26174;&#20102;&#24403;&#21069;&#29702;&#35770;&#38544;&#31169;&#30028;&#19982;&#23454;&#35777;&#20043;&#38388;&#23384;&#22312;&#37325;&#22823;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13087v1 Announce Type: new  Abstract: We study the problem of guaranteeing Differential Privacy (DP) in hyper-parameter tuning, a crucial process in machine learning involving the selection of the best run from several. Unlike many private algorithms, including the prevalent DP-SGD, the privacy implications of tuning remain insufficiently understood. Recent works propose a generic private solution for the tuning process, yet a fundamental question still persists: is the current privacy bound for this solution tight?   This paper contributes both positive and negative answers to this question. Initially, we provide studies affirming the current privacy analysis is indeed tight in a general sense. However, when we specifically study the hyper-parameter tuning problem, such tightness no longer holds. This is first demonstrated by applying privacy audit on the tuning process. Our findings underscore a substantial gap between the current theoretical privacy bound and the empirica
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#31070;&#32463;&#36827;&#21270;&#31639;&#27861;&#20248;&#21270;&#20154;&#24037;&#33008;&#33146;&#27835;&#30103;&#31574;&#30053;&#65292;&#20943;&#23569;&#31958;&#23615;&#30149;&#24739;&#32773;&#30340;&#34880;&#31958;&#20559;&#24046;&#65292;&#24182;&#19988;&#38477;&#20302;&#27880;&#23556;&#27425;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.07949</link><description>&lt;p&gt;
&#20248;&#21270;&#20154;&#24037;&#33008;&#33146;&#35774;&#35745;&#20197;&#25913;&#21892;&#31958;&#23615;&#30149;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Optimizing the Design of an Artificial Pancreas to Improve Diabetes Management
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07949
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#36827;&#21270;&#31639;&#27861;&#20248;&#21270;&#20154;&#24037;&#33008;&#33146;&#27835;&#30103;&#31574;&#30053;&#65292;&#20943;&#23569;&#31958;&#23615;&#30149;&#24739;&#32773;&#30340;&#34880;&#31958;&#20559;&#24046;&#65292;&#24182;&#19988;&#38477;&#20302;&#27880;&#23556;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31958;&#23615;&#30149;&#26159;&#19968;&#31181;&#24930;&#24615;&#30142;&#30149;&#65292;&#24433;&#21709;&#32654;&#22269;&#22659;&#20869;&#26377;3800&#19975;&#20154;&#65292;&#23427;&#20250;&#24433;&#21709;&#36523;&#20307;&#23558;&#39135;&#29289;&#36716;&#21270;&#20026;&#33021;&#37327;&#65288;&#21363;&#34880;&#31958;&#65289;&#30340;&#33021;&#21147;&#12290;&#26631;&#20934;&#30340;&#27835;&#30103;&#26041;&#27861;&#26159;&#36890;&#36807;&#20351;&#29992;&#20154;&#24037;&#33008;&#33146;&#65292;&#21363;&#25345;&#32493;&#33008;&#23707;&#32032;&#27893;&#65288;&#22522;&#30784;&#27880;&#23556;&#65289;&#65292;&#20197;&#21450;&#23450;&#26399;&#27880;&#23556;&#33008;&#23707;&#32032;&#65288;&#31361;&#21457;&#27880;&#23556;&#65289;&#26469;&#34917;&#20805;&#30899;&#27700;&#21270;&#21512;&#29289;&#25668;&#20837;&#37327;&#12290;&#27835;&#30103;&#30446;&#26631;&#26159;&#23558;&#34880;&#31958;&#20445;&#25345;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#30340;&#20013;&#24515;&#20301;&#32622;&#65292;&#36890;&#36807;&#25345;&#32493;&#34880;&#31958;&#27979;&#37327;&#26469;&#36827;&#34892;&#34913;&#37327;&#12290;&#27425;&#35201;&#30446;&#26631;&#26159;&#20943;&#23569;&#27880;&#23556;&#27425;&#25968;&#65292;&#22240;&#20026;&#23545;&#26576;&#20123;&#24739;&#32773;&#26469;&#35828;&#27880;&#23556;&#26159;&#19981;&#24841;&#24555;&#19988;&#38590;&#20197;&#23454;&#26045;&#30340;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#31070;&#32463;&#36827;&#21270;&#26469;&#21457;&#29616;&#27835;&#30103;&#30340;&#26368;&#20339;&#31574;&#30053;&#12290;&#22522;&#20110;30&#22825;&#30340;&#27835;&#30103;&#21644;&#21333;&#20010;&#24739;&#32773;&#30340;&#27979;&#37327;&#25968;&#25454;&#38598;&#65292;&#39318;&#20808;&#35757;&#32451;&#20102;&#38543;&#26426;&#26862;&#26519;&#26469;&#39044;&#27979;&#26410;&#26469;&#30340;&#34880;&#31958;&#27700;&#24179;&#12290;&#28982;&#21518;&#36890;&#36807;&#36827;&#21270;&#20102;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#25351;&#23450;&#30899;&#27700;&#21270;&#21512;&#29289;&#25668;&#20837;&#37327;&#12289;&#22522;&#30784;&#27880;&#23556;&#27700;&#24179;&#21644;&#31361;&#21457;&#27880;&#23556;&#12290;&#36827;&#21270;&#21457;&#29616;&#20102;&#19968;&#20010;&#24085;&#32047;&#25176;&#21069;&#27839;&#65292;&#20943;&#23569;&#20102;&#19982;&#30446;&#26631;&#20540;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diabetes, a chronic condition that impairs how the body turns food into energy, i.e. blood glucose, affects 38 million people in the US alone. The standard treatment is to supplement carbohydrate intake with an artificial pancreas, i.e. a continuous insulin pump (basal shots), as well as occasional insulin injections (bolus shots). The goal of the treatment is to keep blood glucose at the center of an acceptable range, as measured through a continuous glucose meter. A secondary goal is to minimize injections, which are unpleasant and difficult for some patients to implement. In this study, neuroevolution was used to discover an optimal strategy for the treatment. Based on a dataset of 30 days of treatment and measurements of a single patient, a random forest was first trained to predict future glucose levels. A neural network was then evolved to prescribe carbohydrates, basal pumping levels, and bolus injections. Evolution discovered a Pareto front that reduced deviation from the targe
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#23567;&#30340;&#31867;&#20869;&#21464;&#21270;&#19982;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#26377;&#20851;</title><link>https://arxiv.org/abs/2402.03991</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#31867;&#20869;&#21464;&#21270;&#23567;&#20250;&#23548;&#33268;&#20302;&#31209;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Neural Rank Collapse: Weight Decay and Small Within-Class Variability Yield Low-Rank Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03991
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#23567;&#30340;&#31867;&#20869;&#21464;&#21270;&#19982;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#26377;&#20851;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22312;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#30340;&#30740;&#31350;&#26174;&#31034;&#20102;&#19968;&#20010;&#38544;&#21547;&#30340;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#65306;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#30697;&#38453;&#24448;&#24448;&#36817;&#20284;&#20026;&#20302;&#31209;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25110;&#20174;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#20013;&#21435;&#38500;&#30456;&#23545;&#36739;&#23567;&#30340;&#22855;&#24322;&#20540;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#27169;&#22411;&#22823;&#23567;&#65292;&#21516;&#26102;&#20445;&#25345;&#29978;&#33267;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20302;&#31209;&#20559;&#24046;&#30340;&#29702;&#35770;&#30740;&#31350;&#37117;&#28041;&#21450;&#21040;&#31616;&#21270;&#30340;&#32447;&#24615;&#28145;&#24230;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24102;&#26377;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#21644;&#26435;&#37325;&#34928;&#20943;&#21442;&#25968;&#30340;&#36890;&#29992;&#32593;&#32476;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#31070;&#32463;&#31209;&#23849;&#28291;&#29616;&#35937;&#65292;&#23427;&#23558;&#35757;&#32451;&#22909;&#30340;&#32593;&#32476;&#30340;&#20302;&#31209;&#20559;&#24046;&#19982;&#32593;&#32476;&#30340;&#31070;&#32463;&#23849;&#28291;&#29305;&#24615;&#32852;&#31995;&#36215;&#26469;&#65306;&#38543;&#30528;&#26435;&#37325;&#34928;&#20943;&#21442;&#25968;&#30340;&#22686;&#21152;&#65292;&#32593;&#32476;&#20013;&#27599;&#19968;&#23618;&#30340;&#31209;&#21576;&#27604;&#20363;&#36882;&#20943;&#65292;&#19982;&#21069;&#38754;&#23618;&#30340;&#38544;&#34255;&#31354;&#38388;&#23884;&#20837;&#30340;&#31867;&#20869;&#21464;&#21270;&#25104;&#21453;&#27604;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work in deep learning has shown strong empirical and theoretical evidence of an implicit low-rank bias: weight matrices in deep networks tend to be approximately low-rank and removing relatively small singular values during training or from available trained models may significantly reduce model size while maintaining or even improving model performance. However, the majority of the theoretical investigations around low-rank bias in neural networks deal with oversimplified deep linear networks. In this work, we consider general networks with nonlinear activations and the weight decay parameter, and we show the presence of an intriguing neural rank collapse phenomenon, connecting the low-rank bias of trained networks with networks' neural collapse properties: as the weight decay parameter grows, the rank of each layer in the network decreases proportionally to the within-class variability of the hidden-space embeddings of the previous layers. Our theoretical findings are supporte
&lt;/p&gt;</description></item><item><title>&#24120;&#29992;&#30340;&#20855;&#26377;&#26080;&#33618;&#21407;&#35777;&#26126;&#30340;&#27169;&#22411;&#20063;&#21487;&#20197;&#22312;&#36827;&#34892;&#21021;&#22987;&#25968;&#25454;&#37319;&#38598;&#38454;&#27573;&#20174;&#37327;&#23376;&#35774;&#22791;&#20013;&#25910;&#38598;&#19968;&#20123;&#32463;&#20856;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#32463;&#20856;&#27169;&#25311;</title><link>https://arxiv.org/abs/2312.09121</link><description>&lt;p&gt;
&#35777;&#23454;&#26080;&#33618;&#21407;&#23384;&#22312;&#26159;&#21542;&#24847;&#21619;&#30528;&#32463;&#20856;&#27169;&#25311;&#65311;&#25110;&#32773;&#65292;&#20026;&#20160;&#20040;&#25105;&#20204;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#21464;&#20998;&#37327;&#23376;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Does provable absence of barren plateaus imply classical simulability? Or, why we need to rethink variational quantum computing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.09121
&lt;/p&gt;
&lt;p&gt;
&#24120;&#29992;&#30340;&#20855;&#26377;&#26080;&#33618;&#21407;&#35777;&#26126;&#30340;&#27169;&#22411;&#20063;&#21487;&#20197;&#22312;&#36827;&#34892;&#21021;&#22987;&#25968;&#25454;&#37319;&#38598;&#38454;&#27573;&#20174;&#37327;&#23376;&#35774;&#22791;&#20013;&#25910;&#38598;&#19968;&#20123;&#32463;&#20856;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#32463;&#20856;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20154;&#20204;&#23545;&#33618;&#21407;&#29616;&#35937;&#36827;&#34892;&#20102;&#22823;&#37327;&#30740;&#31350;&#12290; &#22312;&#36825;&#31687;&#35266;&#28857;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#38754;&#23545;&#20102;&#36234;&#26469;&#36234;&#26126;&#26174;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35768;&#22810;&#20154;&#26263;&#31034;&#20294;&#23578;&#26410;&#26126;&#30830;&#35299;&#20915;&#30340;&#38382;&#39064;&#65306;&#20801;&#35768;&#36991;&#20813;&#33618;&#21407;&#30340;&#32467;&#26500;&#26159;&#21542;&#20063;&#21487;&#20197;&#34987;&#21033;&#29992;&#26469;&#26377;&#25928;&#22320;&#32463;&#20856;&#27169;&#25311;&#25439;&#22833;&#65311; &#25105;&#20204;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#35777;&#25454;&#65292;&#34920;&#26126;&#24120;&#29992;&#30340;&#20855;&#26377;&#26080;&#33618;&#21407;&#35777;&#26126;&#30340;&#27169;&#22411;&#20063;&#21487;&#20197;&#22312;&#36827;&#34892;&#21021;&#22987;&#25968;&#25454;&#37319;&#38598;&#38454;&#27573;&#20174;&#37327;&#23376;&#35774;&#22791;&#20013;&#25910;&#38598;&#19968;&#20123;&#32463;&#20856;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#32463;&#20856;&#27169;&#25311;&#12290; &#36825;&#26159;&#22240;&#20026;&#33618;&#21407;&#29616;&#35937;&#26159;&#30001;&#32500;&#24230;&#30340;&#35781;&#21650;&#23548;&#33268;&#30340;&#65292;&#32780;&#30446;&#21069;&#35299;&#20915;&#38382;&#39064;&#30340;&#26041;&#27861;&#26368;&#32456;&#23558;&#38382;&#39064;&#32534;&#30721;&#21040;&#19968;&#20123;&#23567;&#30340;&#12289;&#32463;&#20856;&#21487;&#27169;&#25311;&#30340;&#23376;&#31354;&#38388;&#20013;&#12290; &#22240;&#27492;&#65292;&#23613;&#31649;&#24378;&#35843;&#37327;&#23376;&#35745;&#31639;&#21487;&#20197;&#26159;&#25910;&#38598;&#25968;&#25454;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#24341;&#36215;&#20102;&#20005;&#37325;&#30340;&#24605;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.09121v2 Announce Type: replace-cross  Abstract: A large amount of effort has recently been put into understanding the barren plateau phenomenon. In this perspective article, we face the increasingly loud elephant in the room and ask a question that has been hinted at by many but not explicitly addressed: Can the structure that allows one to avoid barren plateaus also be leveraged to efficiently simulate the loss classically? We present strong evidence that commonly used models with provable absence of barren plateaus are also classically simulable, provided that one can collect some classical data from quantum devices during an initial data acquisition phase. This follows from the observation that barren plateaus result from a curse of dimensionality, and that current approaches for solving them end up encoding the problem into some small, classically simulable, subspaces. Thus, while stressing quantum computers can be essential for collecting data, our analysis sheds seriou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#20316;&#20026;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20165;&#38656;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#26469;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2401.10811</link><description>&lt;p&gt;
&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simulation Based Bayesian Optimization. (arXiv:2401.10811v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#20316;&#20026;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20165;&#38656;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#26469;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#23558;&#20808;&#39564;&#30693;&#35782;&#19982;&#25345;&#32493;&#20989;&#25968;&#35780;&#20272;&#30456;&#32467;&#21512;&#30340;&#24378;&#22823;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#26500;&#24314;&#19982;&#21327;&#21464;&#37327;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#27010;&#29575;&#20195;&#29702;&#27169;&#22411;&#26469;&#25351;&#23548;&#26410;&#26469;&#35780;&#20272;&#28857;&#30340;&#36873;&#25321;&#12290;&#23545;&#20110;&#24179;&#28369;&#36830;&#32493;&#30340;&#25628;&#32034;&#31354;&#38388;&#65292;&#39640;&#26031;&#36807;&#31243;&#32463;&#24120;&#34987;&#29992;&#20316;&#20195;&#29702;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20204;&#25552;&#20379;&#23545;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#30340;&#35299;&#26512;&#35775;&#38382;&#65292;&#20174;&#32780;&#20415;&#20110;&#35745;&#31639;&#21644;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#28041;&#21450;&#23545;&#20998;&#31867;&#25110;&#28151;&#21512;&#21327;&#21464;&#37327;&#31354;&#38388;&#36827;&#34892;&#20248;&#21270;&#30340;&#22797;&#26434;&#24773;&#20917;&#19979;&#65292;&#39640;&#26031;&#36807;&#31243;&#21487;&#33021;&#19981;&#26159;&#29702;&#24819;&#30340;&#36873;&#25321;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#23545;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#36827;&#34892;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#65292;&#20197;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) is a powerful method for optimizing black-box functions by combining prior knowledge with ongoing function evaluations. BO constructs a probabilistic surrogate model of the objective function given the covariates, which is in turn used to inform the selection of future evaluation points through an acquisition function. For smooth continuous search spaces, Gaussian Processes (GPs) are commonly used as the surrogate model as they offer analytical access to posterior predictive distributions, thus facilitating the computation and optimization of acquisition functions. However, in complex scenarios involving optimizations over categorical or mixed covariate spaces, GPs may not be ideal.  This paper introduces Simulation Based Bayesian Optimization (SBBO) as a novel approach to optimizing acquisition functions that only requires \emph{sampling-based} access to posterior predictive distributions. SBBO allows the use of surrogate probabilistic models tailored for co
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;Tennessee Eastman Process&#12290;&#35843;&#30740;&#24635;&#32467;&#20102;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#31639;&#27861;&#30340;&#20248;&#21155;&#21183;&#12290;&#36824;&#35752;&#35770;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#21644;&#26080;&#26631;&#35760;&#26679;&#26412;&#31561;&#25361;&#25112;&#65292;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#24212;&#23545;&#12290;&#27604;&#36739;&#20102;&#19981;&#21516;&#31639;&#27861;&#22312;Tennessee Eastman Process&#19978;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;</title><link>http://arxiv.org/abs/2401.10266</link><description>&lt;p&gt;
&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;: &#26041;&#27861;&#35770;&#21644;&#19981;&#30830;&#23450;&#24615;&#31649;&#29702;&#31574;&#30053;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Intelligent Condition Monitoring of Industrial Plants: An Overview of Methodologies and Uncertainty Management Strategies. (arXiv:2401.10266v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;Tennessee Eastman Process&#12290;&#35843;&#30740;&#24635;&#32467;&#20102;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#31639;&#27861;&#30340;&#20248;&#21155;&#21183;&#12290;&#36824;&#35752;&#35770;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#21644;&#26080;&#26631;&#35760;&#26679;&#26412;&#31561;&#25361;&#25112;&#65292;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#24212;&#23545;&#12290;&#27604;&#36739;&#20102;&#19981;&#21516;&#31639;&#27861;&#22312;Tennessee Eastman Process&#19978;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29366;&#24577;&#30417;&#27979;&#22312;&#29616;&#20195;&#24037;&#19994;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#21644;&#21487;&#38752;&#24615;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#22312;&#24037;&#19994;&#24212;&#29992;&#20013;&#26085;&#30410;&#21463;&#21040;&#23398;&#26415;&#30028;&#21644;&#34892;&#19994;&#20851;&#27880;&#30340;&#22686;&#38271;&#20027;&#39064;&#21644;&#19968;&#31181;&#24378;&#22823;&#30340;&#25925;&#38556;&#35782;&#21035;&#26041;&#24335;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#24037;&#19994;&#21378;&#25151;&#26234;&#33021;&#29366;&#24577;&#30417;&#27979;&#21644;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#24320;&#28304;&#22522;&#20934;Tennessee Eastman Process&#65288;TEP&#65289;&#12290;&#22312;&#36825;&#39033;&#35843;&#26597;&#20013;&#65292;&#24635;&#32467;&#20102;&#29992;&#20110;&#24037;&#19994;&#21378;&#25151;&#29366;&#24577;&#30417;&#27979;&#12289;&#25925;&#38556;&#26816;&#27979;&#21644;&#35786;&#26029;&#30340;&#26368;&#27969;&#34892;&#21644;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#27599;&#31181;&#31639;&#27861;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#36824;&#28085;&#30422;&#20102;&#19981;&#24179;&#34913;&#25968;&#25454;&#12289;&#26080;&#26631;&#35760;&#26679;&#26412;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#22788;&#29702;&#36825;&#20123;&#25361;&#25112;&#12290;&#26368;&#21518;&#65292;&#27604;&#36739;&#20102;&#21033;&#29992;Tennessee Eastman Process&#30340;&#19981;&#21516;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#35268;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;
Condition monitoring plays a significant role in the safety and reliability of modern industrial systems. Artificial intelligence (AI) approaches are gaining attention from academia and industry as a growing subject in industrial applications and as a powerful way of identifying faults. This paper provides an overview of intelligent condition monitoring and fault detection and diagnosis methods for industrial plants with a focus on the open-source benchmark Tennessee Eastman Process (TEP). In this survey, the most popular and state-of-the-art deep learning (DL) and machine learning (ML) algorithms for industrial plant condition monitoring, fault detection, and diagnosis are summarized and the advantages and disadvantages of each algorithm are studied. Challenges like imbalanced data, unlabelled samples and how deep learning models can handle them are also covered. Finally, a comparison of the accuracies and specifications of different algorithms utilizing the Tennessee Eastman Process 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#26080;&#30417;&#30563;&#39046;&#22495;&#36716;&#25442;&#20013;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;MPA&#28040;&#38500;&#29702;&#35770;&#65292;&#35299;&#20915;&#20102;CycleGAN&#21450;&#20854;&#21464;&#20307;&#20135;&#29983;&#20869;&#23481;&#19981;&#23545;&#40784;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.09671</link><description>&lt;p&gt;
&#36808;&#21521;&#21487;&#35782;&#21035;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#36716;&#25442;&#65306;&#19968;&#31181;&#22810;&#26679;&#21270;&#20998;&#24067;&#21305;&#37197;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach. (arXiv:2401.09671v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#35299;&#20915;&#26080;&#30417;&#30563;&#39046;&#22495;&#36716;&#25442;&#20013;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;MPA&#28040;&#38500;&#29702;&#35770;&#65292;&#35299;&#20915;&#20102;CycleGAN&#21450;&#20854;&#21464;&#20307;&#20135;&#29983;&#20869;&#23481;&#19981;&#23545;&#40784;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39046;&#22495;&#36716;&#25442;&#65288;UDT&#65289;&#26088;&#22312;&#25214;&#21040;&#23558;&#19968;&#20010;&#39046;&#22495;&#30340;&#26679;&#26412;&#65288;&#20363;&#22914;&#32032;&#25551;&#65289;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#39046;&#22495;&#65288;&#20363;&#22914;&#29031;&#29255;&#65289;&#30340;&#20989;&#25968;&#65292;&#21516;&#26102;&#19981;&#25913;&#21464;&#39640;&#23618;&#35821;&#20041;&#24847;&#20041;&#65288;&#20063;&#31216;&#20026;&#8220;&#20869;&#23481;&#8221;&#65289;&#12290;&#36825;&#20123;&#36716;&#25442;&#20989;&#25968;&#36890;&#24120;&#36890;&#36807;&#36716;&#25442;&#28304;&#39046;&#22495;&#21644;&#30446;&#26631;&#39046;&#22495;&#30340;&#27010;&#29575;&#20998;&#24067;&#26469;&#23547;&#25214;&#12290;CycleGAN&#21487;&#20197;&#35828;&#26159;&#36825;&#19968;&#39046;&#22495;&#20013;&#26368;&#20855;&#20195;&#34920;&#24615;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#20013;&#25351;&#20986;CycleGAN&#21450;&#20854;&#21464;&#20307;&#21487;&#33021;&#26080;&#27861;&#35782;&#21035;&#25152;&#38656;&#30340;&#36716;&#25442;&#20989;&#25968;&#65292;&#24182;&#20135;&#29983;&#20869;&#23481;&#19981;&#23545;&#40784;&#30340;&#36716;&#25442;&#12290;&#36825;&#31181;&#23616;&#38480;&#24615;&#28304;&#20110;&#23398;&#20064;&#20934;&#21017;&#35299;&#31354;&#38388;&#20013;&#23384;&#22312;&#22810;&#20010;&#36716;&#25442;&#20989;&#25968;&#65292;&#31216;&#20026;&#8220;&#20445;&#24230;&#33258;&#21516;&#26500;&#65288;MPA&#65289;&#8221;&#12290;&#23613;&#31649;&#24847;&#35782;&#21040;&#20102;&#36825;&#31181;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#20294;&#35299;&#20915;&#26041;&#26696;&#20173;&#28982;&#38590;&#20197;&#25214;&#21040;&#12290;&#26412;&#30740;&#31350;&#28145;&#20837;&#25506;&#31350;&#20102;&#26680;&#24515;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;MPA&#28040;&#38500;&#29702;&#35770;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;...
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain translation (UDT) aims to find functions that convert samples from one domain (e.g., sketches) to another domain (e.g., photos) without changing the high-level semantic meaning (also referred to as ``content''). The translation functions are often sought by probability distribution matching of the transformed source domain and target domain. CycleGAN stands as arguably the most representative approach among this line of work. However, it was noticed in the literature that CycleGAN and variants could fail to identify the desired translation functions and produce content-misaligned translations. This limitation arises due to the presence of multiple translation functions -- referred to as ``measure-preserving automorphism" (MPA) -- in the solution space of the learning criteria. Despite awareness of such identifiability issues, solutions have remained elusive. This study delves into the core identifiability inquiry and introduces an MPA elimination theory. Our analysi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#36890;&#36807;&#19968;&#20010;&#32508;&#21512;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#20915;&#31574;&#32773;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#21644;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.09018</link><description>&lt;p&gt;
&#20851;&#20110;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
On the Foundation of Distributionally Robust Reinforcement Learning. (arXiv:2311.09018v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.09018
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#36890;&#36807;&#19968;&#20010;&#32508;&#21512;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#20915;&#31574;&#32773;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#21644;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20986;&#20110;&#23545;&#22312;&#35757;&#32451;&#21644;&#37096;&#32626;&#20043;&#38388;&#29615;&#22659;&#21464;&#21270;&#26102;&#40065;&#26834;&#31574;&#30053;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#36890;&#36807;&#19968;&#20010;&#20197;&#20998;&#24067;&#40065;&#26834;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;DRMDPs&#65289;&#20026;&#20013;&#24515;&#30340;&#32508;&#21512;&#24314;&#27169;&#26694;&#26550;&#65292;&#25105;&#20204;&#20351;&#20915;&#31574;&#32773;&#22312;&#19968;&#20010;&#30001;&#23545;&#25163;&#25805;&#32437;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#12290;&#36890;&#36807;&#32479;&#19968;&#21644;&#25193;&#23637;&#29616;&#26377;&#30340;&#34920;&#36848;&#65292;&#25105;&#20204;&#20005;&#26684;&#26500;&#24314;&#20102;&#36866;&#29992;&#20110;&#20915;&#31574;&#32773;&#21644;&#23545;&#25163;&#30340;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#30340;DRMDPs&#65292;&#21253;&#25324;&#36866;&#24212;&#24615;&#31890;&#24230;&#12289;&#25506;&#32034;&#21382;&#21490;&#20381;&#36182;&#24615;&#12289;&#39532;&#23572;&#31185;&#22827;&#21644;&#39532;&#23572;&#31185;&#22827;&#26102;&#38388;&#40784;&#27425;&#30340;&#20915;&#31574;&#32773;&#21644;&#23545;&#25163;&#21160;&#24577;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#20102;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#65292;&#30740;&#31350;&#20102;SA&#21644;S-&#30697;&#24418;&#24615;&#12290;&#22312;&#36825;&#20010;DRMDP&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23454;&#29616;&#40065;&#26834;&#24615;&#25152;&#38656;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the need for a robust policy in the face of environment shifts between training and the deployment, we contribute to the theoretical foundation of distributionally robust reinforcement learning (DRRL). This is accomplished through a comprehensive modeling framework centered around distributionally robust Markov decision processes (DRMDPs). This framework obliges the decision maker to choose an optimal policy under the worst-case distributional shift orchestrated by an adversary. By unifying and extending existing formulations, we rigorously construct DRMDPs that embraces various modeling attributes for both the decision maker and the adversary. These attributes include adaptability granularity, exploring history-dependent, Markov, and Markov time-homogeneous decision maker and adversary dynamics. Additionally, we delve into the flexibility of shifts induced by the adversary, examining SA and S-rectangularity. Within this DRMDP framework, we investigate conditions for the e
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;&#38382;&#39064;&#12290;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#36755;&#20837;&#30340;&#20219;&#24847;&#27169;&#24577;&#65292;&#20351;&#20854;&#23884;&#20837;&#19982;&#20854;&#20182;&#27169;&#24577;&#30340;&#20219;&#24847;&#36755;&#20837;&#25509;&#36817;&#65292;&#20174;&#32780;&#23454;&#29616;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#30340;&#23545;&#40784;&#12290;&#35813;&#38382;&#39064;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#65292;&#23545;&#29983;&#25104;&#21644;&#20998;&#31867;&#20219;&#21153;&#20250;&#20135;&#29983;&#35823;&#23548;&#12290;</title><link>http://arxiv.org/abs/2308.11804</link><description>&lt;p&gt;
&#36825;&#19981;&#26159;&#19968;&#20010;&#33529;&#26524;&#65306;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Ceci n'est pas une pomme: Adversarial Illusions in Multi-Modal Embeddings. (arXiv:2308.11804v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11804
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#20013;&#30340;&#23545;&#25239;&#24187;&#35273;&#38382;&#39064;&#12290;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#36755;&#20837;&#30340;&#20219;&#24847;&#27169;&#24577;&#65292;&#20351;&#20854;&#23884;&#20837;&#19982;&#20854;&#20182;&#27169;&#24577;&#30340;&#20219;&#24847;&#36755;&#20837;&#25509;&#36817;&#65292;&#20174;&#32780;&#23454;&#29616;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#30340;&#23545;&#40784;&#12290;&#35813;&#38382;&#39064;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#65292;&#23545;&#29983;&#25104;&#21644;&#20998;&#31867;&#20219;&#21153;&#20250;&#20135;&#29983;&#35823;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#23558;&#22270;&#20687;&#12289;&#22768;&#38899;&#12289;&#25991;&#26412;&#12289;&#35270;&#39057;&#31561;&#26144;&#23556;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#23545;&#40784;&#19981;&#21516;&#27169;&#24577;&#30340;&#34920;&#31034;&#65288;&#20363;&#22914;&#23558;&#19968;&#24352;&#29399;&#30340;&#22270;&#20687;&#19982;&#19968;&#31181;&#21483;&#22768;&#30456;&#20851;&#32852;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24577;&#23884;&#20837;&#21487;&#20197;&#21463;&#21040;&#19968;&#31181;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#23545;&#25239;&#24187;&#35273;&#8221;&#30340;&#25915;&#20987;&#12290;&#32473;&#23450;&#20219;&#24847;&#27169;&#24577;&#30340;&#36755;&#20837;&#65292;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#23427;&#65292;&#20351;&#20854;&#23884;&#20837;&#25509;&#36817;&#20110;&#21478;&#19968;&#27169;&#24577;&#20013;&#20219;&#24847;&#23545;&#25163;&#36873;&#25321;&#30340;&#36755;&#20837;&#30340;&#23884;&#20837;&#12290;&#24187;&#35273;&#20351;&#23545;&#25163;&#33021;&#22815;&#23558;&#20219;&#24847;&#22270;&#20687;&#19982;&#20219;&#24847;&#25991;&#26412;&#12289;&#20219;&#24847;&#25991;&#26412;&#19982;&#20219;&#24847;&#22768;&#38899;&#31561;&#36827;&#34892;&#23545;&#40784;&#12290;&#23545;&#25239;&#24187;&#35273;&#21033;&#29992;&#20102;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#25509;&#36817;&#24615;&#65292;&#22240;&#27492;&#19982;&#19979;&#28216;&#20219;&#21153;&#26080;&#20851;&#12290;&#20351;&#29992;ImageBind&#23884;&#20837;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#27809;&#26377;&#20855;&#20307;&#19979;&#28216;&#20219;&#21153;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#23545;&#25239;&#24615;&#23545;&#40784;&#30340;&#36755;&#20837;&#22914;&#20309;&#35823;&#23548;&#22270;&#20687;&#29983;&#25104;&#12289;&#25991;&#26412;&#29983;&#25104;&#21644;&#38646;&#26679;&#20363;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-modal encoders map images, sounds, texts, videos, etc. into a single embedding space, aligning representations across modalities (e.g., associate an image of a dog with a barking sound). We show that multi-modal embeddings can be vulnerable to an attack we call "adversarial illusions." Given an input in any modality, an adversary can perturb it so as to make its embedding close to that of an arbitrary, adversary-chosen input in another modality. Illusions thus enable the adversary to align any image with any text, any text with any sound, etc.  Adversarial illusions exploit proximity in the embedding space and are thus agnostic to downstream tasks. Using ImageBind embeddings, we demonstrate how adversarially aligned inputs, generated without knowledge of specific downstream tasks, mislead image generation, text generation, and zero-shot classification.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#20165;&#38656;&#35201;&#36739;&#23569;&#30340;&#26679;&#26412;&#21363;&#21487;&#22312;&#36817;&#32447;&#24615;&#26102;&#38388;&#20869;&#20272;&#35745;&#31232;&#30095;&#22343;&#20540;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15276</link><description>&lt;p&gt;
&#22686;&#37327;&#23398;&#20064;&#19979;&#30340;&#31232;&#30095;&#22343;&#20540;&#40065;&#26834;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Robust Sparse Mean Estimation via Incremental Learning. (arXiv:2305.15276v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#20165;&#38656;&#35201;&#36739;&#23569;&#30340;&#26679;&#26412;&#21363;&#21487;&#22312;&#36817;&#32447;&#24615;&#26102;&#38388;&#20869;&#20272;&#35745;&#31232;&#30095;&#22343;&#20540;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#22343;&#20540;&#30340;&#40065;&#26834;&#24615;&#20272;&#35745;&#38382;&#39064;&#65292;&#26088;&#22312;&#20272;&#35745;&#20174;&#37325;&#23614;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#37096;&#20998;&#25439;&#22351;&#26679;&#26412;&#30340;$k$-&#31232;&#30095;&#22343;&#20540;&#12290;&#29616;&#26377;&#20272;&#35745;&#22120;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#38754;&#20020;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#65306;&#39318;&#20808;&#65292;&#23427;&#20204;&#21463;&#21040;&#19968;&#20010;&#34987;&#25512;&#27979;&#30340;&#35745;&#31639;&#32479;&#35745;&#26435;&#34913;&#30340;&#38480;&#21046;&#65292;&#36825;&#24847;&#21619;&#30528;&#20219;&#20309;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#38656;&#35201;$\tilde\Omega(k^2)$&#20010;&#26679;&#26412;&#65292;&#32780;&#20854;&#22312;&#32479;&#35745;&#19978;&#26368;&#20248;&#30340;&#23545;&#24212;&#29289;&#21482;&#38656;&#35201;$\tilde O(k)$&#20010;&#26679;&#26412;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#30340;&#20272;&#35745;&#22120;&#35268;&#27169;&#38543;&#30528;&#29615;&#22659;&#30340;&#32500;&#24230;&#22686;&#21152;&#32780;&#24613;&#21095;&#19978;&#21319;&#65292;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#22312;&#36866;&#24230;&#30340;&#26465;&#20214;&#19979;&#20811;&#26381;&#20102;&#36825;&#20004;&#20010;&#25361;&#25112;&#65306;&#23427;&#22312;&#20960;&#20046;&#32447;&#24615;&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#20013;&#36816;&#34892;&#65288;&#30456;&#23545;&#20110;&#29615;&#22659;&#32500;&#24230;&#65289;&#65292;&#21516;&#26102;&#21482;&#38656;&#35201;$\tilde O(k)$&#20010;&#26679;&#26412;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#22343;&#20540;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#22686;&#37327;&#23398;&#20064;&#29616;&#35937;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#38750;&#20984;&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#23558;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#36716;&#21270;&#20026;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#22522;&#20110;&#22686;&#37327;&#23398;&#20064;&#30340;&#31639;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of robust sparse mean estimation, where the goal is to estimate a $k$-sparse mean from a collection of partially corrupted samples drawn from a heavy-tailed distribution. Existing estimators face two critical challenges in this setting. First, they are limited by a conjectured computational-statistical tradeoff, implying that any computationally efficient algorithm needs $\tilde\Omega(k^2)$ samples, while its statistically-optimal counterpart only requires $\tilde O(k)$ samples. Second, the existing estimators fall short of practical use as they scale poorly with the ambient dimension. This paper presents a simple mean estimator that overcomes both challenges under moderate conditions: it runs in near-linear time and memory (both with respect to the ambient dimension) while requiring only $\tilde O(k)$ samples to recover the true mean. At the core of our method lies an incremental learning phenomenon: we introduce a simple nonconvex framework that ca
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#20351;&#29992;&#34920;&#26684;&#25968;&#25454;&#33258;&#21160;&#35757;&#32451;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#20197;&#23398;&#20064;&#25968;&#25454;&#22266;&#26377;&#30340;&#32467;&#26500;&#65292;&#26080;&#38656;&#35782;&#21035;&#20803;&#29305;&#24449;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#65292;&#35813;&#26041;&#27861;&#22343;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.09101</link><description>&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#33258;&#21160;&#23398;&#20064;&#31639;&#27861;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Automatic learning algorithm selection for classification via convolutional neural networks. (arXiv:2305.09101v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09101
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#20351;&#29992;&#34920;&#26684;&#25968;&#25454;&#33258;&#21160;&#35757;&#32451;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#20197;&#23398;&#20064;&#25968;&#25454;&#22266;&#26377;&#30340;&#32467;&#26500;&#65292;&#26080;&#38656;&#35782;&#21035;&#20803;&#29305;&#24449;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#65292;&#35813;&#26041;&#27861;&#22343;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20854;&#20182;&#20219;&#21153;&#19968;&#26679;&#65292;&#26500;&#24314;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36807;&#31243;&#21487;&#20197;&#21463;&#30410;&#20110;&#20808;&#21069;&#30340;&#32463;&#39564;&#12290;&#22522;&#20110;&#20803;&#23398;&#20064;&#30340;&#20998;&#31867;&#22120;&#36873;&#25321;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#24615;&#33021;&#65292;&#20197;&#25552;&#39640;&#24403;&#21069;&#24314;&#27169;&#36807;&#31243;&#20013;&#30340;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#23398;&#20064;&#26041;&#26696;&#65292;&#30452;&#25509;&#20351;&#29992;&#34920;&#26684;&#25968;&#25454;&#20026;&#20108;&#36827;&#21046;&#20998;&#31867;&#35757;&#32451;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#23398;&#20064;&#25968;&#25454;&#22266;&#26377;&#30340;&#32467;&#26500;&#32780;&#19981;&#35782;&#21035;&#20803;&#29305;&#24449;&#12290;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#26174;&#31034;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#35782;&#21035;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#27169;&#24335;&#26041;&#38754;&#36798;&#21040;&#20102;&#20960;&#20046;&#23436;&#32654;&#30340;&#24615;&#33021;&#65292;&#20248;&#20110;&#22522;&#20110;&#20803;&#29305;&#24449;&#30340;&#20256;&#32479;&#20004;&#27493;&#26041;&#27861;&#12290;&#25991;&#20013;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#38543;&#21518;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#30340;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As in any other task, the process of building machine learning models can benefit from prior experience. Meta-learning for classifier selection gains knowledge from characteristics of different datasets and/or previous performance of machine learning techniques to make better decisions for the current modeling process. Meta-learning approaches first collect meta-data that describe this prior experience and then use it as input for an algorithm selection model. In this paper, however, we propose an automatic learning scheme in which we train convolutional networks directly with the information of tabular datasets for binary classification. The goal of this study is to learn the inherent structure of the data without identifying meta-features. Experiments with simulated datasets show that the proposed approach achieves nearly perfect performance in identifying linear and nonlinear patterns, outperforming the traditional two-step method based on meta-features. The proposed method is then 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#40065;&#26834;&#27169;&#24577;&#36830;&#25509;&#23548;&#21521;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#65292;&#23454;&#29616;&#31070;&#32463;&#32593;&#32476;&#23545;&#22810;&#26679;&#21270;$\ell_p$&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#22522;&#20110;&#31181;&#32676;&#23398;&#20064;&#30340;&#23398;&#20064;&#38454;&#27573;&#12290;</title><link>http://arxiv.org/abs/2303.10225</link><description>&lt;p&gt;
&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#23545;&#22810;&#26679;&#21270;$\ell_p$&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;:&#40065;&#26834;&#27169;&#24577;&#36830;&#25509;&#23548;&#21521;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Robust Mode Connectivity-Oriented Adversarial Defense: Enhancing Neural Network Robustness Against Diversified $\ell_p$ Attacks. (arXiv:2303.10225v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#40065;&#26834;&#27169;&#24577;&#36830;&#25509;&#23548;&#21521;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#65292;&#23454;&#29616;&#31070;&#32463;&#32593;&#32476;&#23545;&#22810;&#26679;&#21270;$\ell_p$&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#22522;&#20110;&#31181;&#32676;&#23398;&#20064;&#30340;&#23398;&#20064;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#26159;&#34913;&#37327;&#31070;&#32463;&#32593;&#32476;&#22312;&#25512;&#29702;&#38454;&#27573;&#25269;&#24481;&#23545;&#25239;&#24615;&#25915;&#20987;&#33021;&#21147;&#30340;&#20851;&#38190;&#27010;&#24565;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#20351;&#29992;&#30340;&#24378;&#21270;&#40065;&#26834;&#24615;&#35757;&#32451;&#25216;&#26415;&#33021;&#22815;&#25552;&#39640;&#23545;&#19968;&#31181;&#31867;&#22411;&#30340;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#65292;&#20294;&#27169;&#22411;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#22810;&#26679;&#21270;&#30340;$\ell_p$&#25915;&#20987;&#12290;&#20026;&#20102;&#23454;&#29616;&#22810;&#26679;&#21270;&#30340;$\ell_p$&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#40065;&#26834;&#27169;&#24577;&#36830;&#25509; (RMC) &#23548;&#21521;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;&#65292;&#23427;&#21253;&#21547;&#20004;&#20010;&#22522;&#20110;&#31181;&#32676;&#23398;&#20064;&#30340;&#23398;&#20064;&#38454;&#27573;&#12290;&#31532;&#19968;&#20010;&#38454;&#27573;&#65292;RMC&#65292;&#33021;&#22815;&#25628;&#32034;&#20004;&#20010;&#39044;&#20808;&#35757;&#32451;&#27169;&#22411;&#20043;&#38388;&#30340;&#27169;&#22411;&#21442;&#25968;&#31354;&#38388;&#65292;&#24182;&#25214;&#21040;&#21253;&#21547;&#39640;&#40065;&#26834;&#24615;&#28857;&#30340;&#36335;&#24452;&#20197;&#25269;&#24481;&#22810;&#26679;&#21270;&#30340;$\ell_p$&#25915;&#20987;&#12290;&#22522;&#20110;RMC&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#31532;&#20108;&#20010;&#38454;&#27573;&#65292;&#22522;&#20110;RMC&#30340;&#20248;&#21270;&#65292;&#20854;&#20013;RMC&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#22810;&#26679;&#21270;$\ell_p$&#40065;&#26834;&#24615;&#36827;&#19968;&#27493;&#22686;&#24378;&#30340;&#22522;&#26412;&#21333;&#20803;&#12290;&#20026;&#20102;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#25105;&#20204;&#23558;&#23398;&#20064;&#19982;&#20165;&#36873;&#25321;&#23376;&#38598;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30456;&#32467;&#21512;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#32452;&#36739;&#23567;&#30340;&#20195;&#34920;&#24615;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#21487;&#29992;&#20110;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#23545;&#22810;&#26679;&#21270;$\ell_p$&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial robustness is a key concept in measuring the ability of neural networks to defend against adversarial attacks during the inference phase. Recent studies have shown that despite the success of improving adversarial robustness against a single type of attack using robust training techniques, models are still vulnerable to diversified $\ell_p$ attacks. To achieve diversified $\ell_p$ robustness, we propose a novel robust mode connectivity (RMC)-oriented adversarial defense that contains two population-based learning phases. The first phase, RMC, is able to search the model parameter space between two pre-trained models and find a path containing points with high robustness against diversified $\ell_p$ attacks. In light of the effectiveness of RMC, we develop a second phase, RMC-based optimization, with RMC serving as the basic unit for further enhancement of neural network diversified $\ell_p$ robustness. To increase computational efficiency, we incorporate learning with a sel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#24403;&#21069;&#36229;&#36793;&#30028;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25216;&#26415;&#32454;&#33410;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#24635;&#32467;&#20102;&#27599;&#20010;&#32452;&#20214;&#30340;&#21464;&#20307;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#21508;&#31181;&#19982;HGNN&#30456;&#20851;&#30340;&#24212;&#29992;&#21644;&#24403;&#21069;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2202.13852</link><description>&lt;p&gt;
&#36229;&#36793;&#30028;&#22270;&#31070;&#32463;&#32593;&#32476;&#65306;&#26041;&#27861;&#21644;&#24212;&#29992;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Hyperbolic Graph Neural Networks: A Review of Methods and Applications. (arXiv:2202.13852v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.13852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#24403;&#21069;&#36229;&#36793;&#30028;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25216;&#26415;&#32454;&#33410;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#24635;&#32467;&#20102;&#27599;&#20010;&#32452;&#20214;&#30340;&#21464;&#20307;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#21508;&#31181;&#19982;HGNN&#30456;&#20851;&#30340;&#24212;&#29992;&#21644;&#24403;&#21069;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#23558;&#20256;&#32479;&#30340;&#31070;&#32463;&#32593;&#32476;&#25512;&#24191;&#21040;&#20102;&#22270;&#32467;&#26500;&#25968;&#25454;&#65292;&#24182;&#22240;&#20854;&#20986;&#33394;&#30340;&#34920;&#24449;&#33021;&#21147;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#23601;&#65292;&#20294;&#27431;&#20960;&#37324;&#24471;&#27169;&#22411;&#22312;&#19982;&#22270;&#30456;&#20851;&#30340;&#23398;&#20064;&#20013;&#30340;&#24615;&#33021;&#20173;&#28982;&#21463;&#21040;&#27431;&#20960;&#37324;&#24471;&#20960;&#20309;&#30340;&#34920;&#24449;&#33021;&#21147;&#30340;&#38480;&#21046;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20855;&#26377;&#39640;&#24230;&#38750;&#27431;&#20960;&#37324;&#24471;&#28508;&#22312;&#35299;&#21078;&#30340;&#25968;&#25454;&#38598;&#12290;&#26368;&#36817;&#65292;&#36229;&#36793;&#30028;&#31354;&#38388;&#22312;&#22788;&#29702;&#20855;&#26377;&#26641;&#29366;&#32467;&#26500;&#21644;&#24130;&#24459;&#20998;&#24067;&#30340;&#22270;&#25968;&#25454;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#36825;&#24402;&#21151;&#20110;&#20854;&#25351;&#25968;&#32423;&#30340;&#22686;&#38271;&#29305;&#24615;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#20840;&#38754;&#22238;&#39038;&#20102;&#24403;&#21069;&#36229;&#36793;&#30028;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25216;&#26415;&#32454;&#33410;&#65292;&#23558;&#23427;&#20204;&#32479;&#19968;&#20026;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#24635;&#32467;&#20102;&#27599;&#20010;&#32452;&#20214;&#30340;&#21464;&#20307;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#21508;&#31181;&#19982;HGNN&#30456;&#20851;&#30340;&#24212;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#19968;&#20123;&#25361;&#25112;&#65292;&#36825;&#20123;&#25361;&#25112;&#21487;&#33021;&#25104;&#20026;&#36827;&#19968;&#27493;&#21457;&#23637;&#22270;&#31070;&#32463;&#32593;&#32476;&#25104;&#23601;&#30340;&#25351;&#23548;&#26041;&#38024;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks generalize conventional neural networks to graph-structured data and have received widespread attention due to their impressive representation ability. In spite of the remarkable achievements, the performance of Euclidean models in graph-related learning is still bounded and limited by the representation ability of Euclidean geometry, especially for datasets with highly non-Euclidean latent anatomy. Recently, hyperbolic space has gained increasing popularity in processing graph data with tree-like structure and power-law distribution, owing to its exponential growth property. In this survey, we comprehensively revisit the technical details of the current hyperbolic graph neural networks, unifying them into a general framework and summarizing the variants of each component. More importantly, we present various HGNN-related applications. Last, we also identify several challenges, which potentially serve as guidelines for further flourishing the achievements of graph
&lt;/p&gt;</description></item></channel></rss>