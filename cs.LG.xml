<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22270;&#19981;&#21464;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#24615;&#12289;&#36719;&#24615;&#21644;&#21487;&#24494;&#24615;&#21407;&#21017;&#26469;&#25552;&#21462;&#19981;&#21464;&#23376;&#22270;&#65292;&#20174;&#32780;&#25552;&#39640;&#22270;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07191</link><description>&lt;p&gt;
GSINA: &#36890;&#36807;&#22270;Sinkhorn Attention&#25913;&#36827;&#22270;&#19981;&#21464;&#23398;&#20064;&#20013;&#30340;&#23376;&#22270;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
GSINA: Improving Subgraph Extraction for Graph Invariant Learning via Graph Sinkhorn Attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22270;&#19981;&#21464;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#24615;&#12289;&#36719;&#24615;&#21644;&#21487;&#24494;&#24615;&#21407;&#21017;&#26469;&#25552;&#21462;&#19981;&#21464;&#23376;&#22270;&#65292;&#20174;&#32780;&#25552;&#39640;&#22270;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#19981;&#21464;&#23398;&#20064;(GIL)&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#19981;&#21516;&#20998;&#24067;&#21464;&#21270;&#19979;&#21457;&#29616;&#22270;&#25968;&#25454;&#19982;&#20854;&#26631;&#31614;&#20043;&#38388;&#30340;&#19981;&#21464;&#20851;&#31995;&#65292;&#20197;&#35299;&#20915;&#21508;&#31181;&#22270;&#23398;&#20064;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;GIL&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20174;&#36755;&#20837;&#22270;&#20013;&#25552;&#21462;&#19981;&#21464;&#23376;&#22270;&#65292;&#20316;&#20026;&#35268;&#21017;&#21270;&#31574;&#30053;&#26469;&#25552;&#39640;&#22270;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#33719;&#21462;&#19981;&#21464;&#23376;&#22270;&#26041;&#38754;&#20063;&#23384;&#22312;&#21508;&#31181;&#38480;&#21046;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#29616;&#26377;&#24037;&#20316;&#30340;&#32570;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;&#25552;&#21462;&#19981;&#21464;&#23376;&#22270;&#30340;&#30456;&#24212;&#21407;&#21017;&#65306;1&#65289;&#31232;&#30095;&#24615;&#65292;&#20197;&#36807;&#28388;&#25481;&#21464;&#24322;&#29305;&#24449;&#65307;2&#65289;&#36719;&#24615;&#65292;&#20197;&#33719;&#24471;&#26356;&#24191;&#27867;&#30340;&#35299;&#31354;&#38388;&#65307;&#21644;3&#65289;&#21487;&#24494;&#24615;&#65292;&#20197;&#36827;&#34892;&#31471;&#21040;&#31471;&#20248;&#21270;&#12290;&#20026;&#20102;&#22312;&#19968;&#27425;&#25805;&#20316;&#20013;&#28385;&#36275;&#36825;&#20123;&#21407;&#21017;&#65292;&#25105;&#20204;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;(OT)&#29702;&#35770;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#27880;&#24847;&#26426;&#21046;&#65292;&#31216;&#20026;&#22270;Sinkhorn Attention&#65288;G)
&lt;/p&gt;
&lt;p&gt;
Graph invariant learning (GIL) has been an effective approach to discovering the invariant relationships between graph data and its labels for different graph learning tasks under various distribution shifts. Many recent endeavors of GIL focus on extracting the invariant subgraph from the input graph for prediction as a regularization strategy to improve the generalization performance of graph learning. Despite their success, such methods also have various limitations in obtaining their invariant subgraphs. In this paper, we provide in-depth analyses of the drawbacks of existing works and propose corresponding principles of our invariant subgraph extraction: 1) the sparsity, to filter out the variant features, 2) the softness, for a broader solution space, and 3) the differentiability, for a soundly end-to-end optimization. To meet these principles in one shot, we leverage the Optimal Transport (OT) theory and propose a novel graph attention mechanism called Graph Sinkhorn Attention (G
&lt;/p&gt;</description></item><item><title>&#36825;&#20221;&#30333;&#30382;&#20070;&#26159;&#23545;&#32654;&#22269;&#22269;&#23478;&#30005;&#20449;&#21644;&#20449;&#24687;&#31649;&#29702;&#23616;&#30340;&#8220;AI&#38382;&#36131;&#25919;&#31574;&#35780;&#35770;&#35831;&#27714;&#8221;&#30340;&#22238;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#30456;&#20114;&#20851;&#32852;&#30340;AI&#38382;&#36131;&#25919;&#31574;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2307.13658</link><description>&lt;p&gt;
&#20851;&#20110;AI&#38382;&#36131;&#25919;&#31574;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Towards an AI Accountability Policy. (arXiv:2307.13658v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13658
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#30333;&#30382;&#20070;&#26159;&#23545;&#32654;&#22269;&#22269;&#23478;&#30005;&#20449;&#21644;&#20449;&#24687;&#31649;&#29702;&#23616;&#30340;&#8220;AI&#38382;&#36131;&#25919;&#31574;&#35780;&#35770;&#35831;&#27714;&#8221;&#30340;&#22238;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#30456;&#20114;&#20851;&#32852;&#30340;AI&#38382;&#36131;&#25919;&#31574;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#30333;&#30382;&#20070;&#26159;&#23545;&#32654;&#22269;&#22269;&#23478;&#30005;&#20449;&#21644;&#20449;&#24687;&#31649;&#29702;&#23616;&#30340;&#8220;AI&#38382;&#36131;&#25919;&#31574;&#35780;&#35770;&#35831;&#27714;&#8221;&#20316;&#20986;&#30340;&#22238;&#24212;&#12290;&#22312;&#22238;&#31572;&#30456;&#20851;&#38382;&#39064;&#30340;&#20851;&#38190;&#21477;&#23376;&#26411;&#23614;&#65292;&#25552;&#20379;&#20102;&#35201;&#27714;&#35780;&#35770;&#30340;&#38382;&#39064;&#32534;&#21495;&#30340;&#19978;&#26631;&#12290;&#35813;&#30333;&#30382;&#20070;&#25552;&#20986;&#20102;&#19968;&#32452;&#30456;&#20114;&#20851;&#32852;&#30340;AI&#38382;&#36131;&#25919;&#31574;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
This white paper is a response to the "AI Accountability Policy Request for Comments" by the National Telecommunications and Information Administration of the United States. The question numbers for which comments were requested are provided in superscripts at the end of key sentences answering the respective questions. The white paper offers a set of interconnected recommendations for an AI accountability policy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30830;&#23450;&#26368;&#23567;&#21442;&#25968;&#38598;&#65292;&#26377;&#25928;&#25551;&#36848;&#38543;&#26426;&#36807;&#31243;&#21160;&#21147;&#23398;&#65292;&#24182;&#29983;&#25104;&#33021;&#20934;&#30830;&#22797;&#21046;&#39044;&#26399;&#38543;&#26426;&#34892;&#20026;&#30340;&#26032;&#36712;&#36857;&#12290;</title><link>http://arxiv.org/abs/2307.11608</link><description>&lt;p&gt;
&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#23398;&#20064;&#38543;&#26426;&#36807;&#31243;&#30340;&#26368;&#23567;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning minimal representations of stochastic processes with variational autoencoders. (arXiv:2307.11608v1 [cond-mat.soft])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30830;&#23450;&#26368;&#23567;&#21442;&#25968;&#38598;&#65292;&#26377;&#25928;&#25551;&#36848;&#38543;&#26426;&#36807;&#31243;&#21160;&#21147;&#23398;&#65292;&#24182;&#29983;&#25104;&#33021;&#20934;&#30830;&#22797;&#21046;&#39044;&#26399;&#38543;&#26426;&#34892;&#20026;&#30340;&#26032;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#36807;&#31243;&#22312;&#31185;&#23398;&#20013;&#26377;&#35768;&#22810;&#24212;&#29992;&#65292;&#22240;&#20026;&#23427;&#20204;&#24191;&#27867;&#29992;&#20110;&#27169;&#25311;&#21508;&#31181;&#33258;&#28982;&#29616;&#35937;&#12290;&#30001;&#20110;&#20854;&#22266;&#26377;&#30340;&#38543;&#26426;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#23427;&#20204;&#24456;&#38590;&#36827;&#34892;&#34920;&#24449;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#26377;&#25928;&#25551;&#36848;&#38543;&#26426;&#36807;&#31243;&#21160;&#21147;&#23398;&#25152;&#38656;&#30340;&#26368;&#23567;&#21442;&#25968;&#38598;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#22312;&#25193;&#23637;&#30340;&#946;-&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26550;&#26500;&#19978;&#12290;&#36890;&#36807;&#19982;&#20856;&#22411;&#25193;&#25955;&#27169;&#22411;&#30456;&#23545;&#24212;&#30340;&#27169;&#25311;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#25552;&#21462;&#33021;&#20934;&#30830;&#25551;&#36848;&#36825;&#20123;&#21160;&#21147;&#23398;&#30340;&#26368;&#23567;&#30456;&#20851;&#21442;&#25968;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#29983;&#25104;&#24544;&#23454;&#22797;&#21046;&#39044;&#26399;&#38543;&#26426;&#34892;&#20026;&#30340;&#26032;&#36712;&#36857;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;&#33021;&#22815;&#33258;&#21160;&#21457;&#29616;&#25551;&#36848;&#38543;&#26426;&#36807;&#31243;&#30340;&#26410;&#30693;&#21442;&#25968;&#65292;&#20174;&#32780;&#22686;&#36827;&#23545;&#21508;&#20010;&#39046;&#22495;&#20013;&#22797;&#26434;&#29616;&#35937;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic processes have found numerous applications in science, as they are broadly used to model a variety of natural phenomena. Due to their intrinsic randomness and uncertainty, they are however difficult to characterize. Here, we introduce an unsupervised machine learning approach to determine the minimal set of parameters required to effectively describe the dynamics of a stochastic process. Our method builds upon an extended $\beta$-variational autoencoder architecture. By means of simulated datasets corresponding to paradigmatic diffusion models, we showcase its effectiveness in extracting the minimal relevant parameters that accurately describe these dynamics. Furthermore, the method enables the generation of new trajectories that faithfully replicate the expected stochastic behavior. Overall, our approach enables for the autonomous discovery of unknown parameters describing stochastic processes, hence enhancing our comprehension of complex phenomena across various fields.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;Committor&#38382;&#39064;&#30340;&#26377;&#38480;&#34920;&#36798;&#24335;&#26041;&#27861;(FEX)&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#26368;&#20248;&#38750;&#32447;&#24615;&#20989;&#25968;&#21644;&#31995;&#25968;&#20540;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#35745;&#31639;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.12268</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;Committor&#38382;&#39064;&#30340;&#26377;&#38480;&#34920;&#36798;&#24335;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Finite Expression Method for Solving High-Dimensional Committor Problems. (arXiv:2306.12268v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12268
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;Committor&#38382;&#39064;&#30340;&#26377;&#38480;&#34920;&#36798;&#24335;&#26041;&#27861;(FEX)&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#26368;&#20248;&#38750;&#32447;&#24615;&#20989;&#25968;&#21644;&#31995;&#25968;&#20540;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#35745;&#31639;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#31227;&#36335;&#24452;&#29702;&#35770;&#65288;TPT&#65289;&#26159;&#19968;&#31181;&#25968;&#23398;&#26694;&#26550;&#65292;&#29992;&#20110;&#37327;&#21270;&#20174;&#36873;&#23450;&#30340;&#20122;&#31283;&#24577;$A$&#21040;$B$&#20043;&#38388;&#30340;&#31232;&#26377;&#36716;&#31227;&#20107;&#20214;&#12290;TPT&#30340;&#26680;&#24515;&#26159;Committor&#20989;&#25968;&#65292;&#20854;&#25551;&#36848;&#20102;&#20174;&#30456;&#31354;&#38388;&#30340;&#20219;&#20309;&#36215;&#22987;&#28857;&#21040;&#36798;&#20122;&#31283;&#24577;$B$&#20043;&#21069;&#21040;&#36798;$A$&#30340;&#27010;&#29575;&#12290;&#35745;&#31639;&#20986;Committor&#20043;&#21518;&#65292;&#21487;&#20197;&#31435;&#21363;&#25214;&#21040;&#36716;&#25442;&#36890;&#36947;&#21644;&#36716;&#25442;&#36895;&#29575;&#12290;Committor&#26159;&#20855;&#26377;&#36866;&#24403;&#36793;&#30028;&#26465;&#20214;&#30340;&#21453;&#21521;Kolmogorov&#26041;&#31243;&#30340;&#35299;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#30001;&#20110;&#38656;&#35201;&#32593;&#26684;&#21270;&#25972;&#20010;&#29615;&#22659;&#31354;&#38388;&#65292;&#35299;&#20915;Committor&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#26377;&#38480;&#34920;&#36798;&#24335;&#26041;&#27861;&#65288;FEX&#65292;Liang&#21644;Yang&#65288;2022&#65289;&#65289;&#20316;&#20026;&#35745;&#31639;Committor&#30340;&#24037;&#20855;&#12290;FEX&#36890;&#36807;&#28041;&#21450;&#19968;&#23450;&#25968;&#37327;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#21644;&#20108;&#36827;&#21046;&#31639;&#26415;&#36816;&#31639;&#30340;&#22266;&#23450;&#26377;&#38480;&#20195;&#25968;&#34920;&#36798;&#24335;&#26469;&#36924;&#36817;Committor&#12290;&#26368;&#20339;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12289;&#20108;&#36827;&#21046;&#36816;&#31639;&#21644;&#25968;&#20540;&#31995;&#25968;&#20540;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#12290;&#25105;&#20204;&#36890;&#36807;&#35299;&#20915;&#22810;&#20010;&#39640;&#32500;Committor&#38382;&#39064;&#65292;&#20854;&#20013;&#21253;&#25324;&#39640;&#36798;400&#20010;&#32500;&#24230;&#65292;&#23637;&#31034;&#20102;FEX&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19988;&#34920;&#26126;FEX&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#30340;&#25968;&#20540;&#26041;&#27861;&#65292;&#22914;&#26377;&#38480;&#20803;&#26041;&#27861;&#21644;&#26377;&#38480;&#24046;&#20998;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transition path theory (TPT) is a mathematical framework for quantifying rare transition events between a pair of selected metastable states $A$ and $B$. Central to TPT is the committor function, which describes the probability to hit the metastable state $B$ prior to $A$ from any given starting point of the phase space. Once the committor is computed, the transition channels and the transition rate can be readily found. The committor is the solution to the backward Kolmogorov equation with appropriate boundary conditions. However, solving it is a challenging task in high dimensions due to the need to mesh a whole region of the ambient space. In this work, we explore the finite expression method (FEX, Liang and Yang (2022)) as a tool for computing the committor. FEX approximates the committor by an algebraic expression involving a fixed finite number of nonlinear functions and binary arithmetic operations. The optimal nonlinear functions, the binary operations, and the numerical coeffi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;MRI&#20998;&#31867;&#20219;&#21153;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;&#19981;&#21516;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;XAI&#26041;&#27861;&#24182;&#19981;&#19968;&#23450;&#27604;&#31616;&#21333;&#27169;&#22411;&#25552;&#20379;&#26356;&#22909;&#30340;&#35299;&#37322;&#65292;&#19988;CNN&#30340;&#35299;&#37322;&#33021;&#21147;&#21462;&#20915;&#20110;&#24213;&#23618;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#21644;&#26631;&#31614;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.12150</link><description>&lt;p&gt;
&#22522;&#20110;&#39044;&#35757;&#32451;&#30340;&#24433;&#21709;&#22240;&#32032;&#30740;&#31350;&#21307;&#23398;&#22270;&#20687;&#20998;&#31867;&#35299;&#37322;&#24615;&#33021;&#30340;&#22522;&#20934;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Benchmark data to study the influence of pre-training on explanation performance in MR image classification. (arXiv:2306.12150v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12150
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;MRI&#20998;&#31867;&#20219;&#21153;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;&#19981;&#21516;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;XAI&#26041;&#27861;&#24182;&#19981;&#19968;&#23450;&#27604;&#31616;&#21333;&#27169;&#22411;&#25552;&#20379;&#26356;&#22909;&#30340;&#35299;&#37322;&#65292;&#19988;CNN&#30340;&#35299;&#37322;&#33021;&#21147;&#21462;&#20915;&#20110;&#24213;&#23618;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#21644;&#26631;&#31614;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#24120;&#24120;&#22312;&#21307;&#23398;&#39044;&#27979;&#20219;&#21153;&#20013;&#34987;&#25104;&#21151;&#22320;&#24212;&#29992;&#65292;&#36890;&#24120;&#19982;&#36801;&#31227;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#19981;&#36275;&#26102;&#33021;&#22815;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;CNN&#20135;&#29983;&#30340;&#27169;&#22411;&#39640;&#24230;&#22797;&#26434;&#19988;&#36890;&#24120;&#19981;&#25552;&#20379;&#20219;&#20309;&#26377;&#20851;&#20854;&#39044;&#27979;&#26426;&#21046;&#30340;&#20449;&#24687;&#65292;&#36825;&#20419;&#20351;&#20102;&#8220;&#21487;&#35299;&#37322;&#24615;&#8221;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#39046;&#22495;&#30340;&#30740;&#31350;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#22312;MRI&#20998;&#31867;&#20219;&#21153;&#20013;&#23450;&#37327;&#35780;&#20272;&#35299;&#37322;&#24615;&#33021;&#12290;&#36890;&#36807;&#36825;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#21487;&#20197;&#20102;&#35299;&#36801;&#31227;&#23398;&#20064;&#23545;&#35299;&#37322;&#36136;&#37327;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#24212;&#29992;&#20110;&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;CNN&#30340;&#27969;&#34892;XAI&#26041;&#27861;&#24182;&#19981;&#19968;&#23450;&#27604;&#31616;&#21333;&#27169;&#22411;&#25552;&#20379;&#26356;&#22909;&#30340;&#35299;&#37322;&#65292;&#24182;&#19988;CNN&#25552;&#20379;&#26377;&#24847;&#20041;&#35299;&#37322;&#30340;&#33021;&#21147;&#20005;&#37325;&#20381;&#36182;&#20110;&#24213;&#23618;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#21644;&#26631;&#31614;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Convolutional Neural Networks (CNNs) are frequently and successfully used in medical prediction tasks. They are often used in combination with transfer learning, leading to improved performance when training data for the task are scarce. The resulting models are highly complex and typically do not provide any insight into their predictive mechanisms, motivating the field of 'explainable' artificial intelligence (XAI). However, previous studies have rarely quantitatively evaluated the 'explanation performance' of XAI methods against ground-truth data, and transfer learning and its influence on objective measures of explanation performance has not been investigated. Here, we propose a benchmark dataset that allows for quantifying explanation performance in a realistic magnetic resonance imaging (MRI) classification task. We employ this benchmark to understand the influence of transfer learning on the quality of explanations. Experimental results show that popular XAI methods applied to t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;"&#26377;&#38480;&#34920;&#36798;&#27861;" (FEX) &#30340;&#28145;&#24230;&#31526;&#21495;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#21160;&#24577;&#25968;&#25454;&#20013;PDE&#35299;&#30340;&#23548;&#25968;&#65292;&#21457;&#29616;&#25511;&#21046;&#26041;&#31243;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#30456;&#23545;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#65292;FEX&#22312;&#22810;&#31181;&#38382;&#39064;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#65292;&#21253;&#25324;&#26102;&#21464;&#30340;PDE&#38382;&#39064;&#21644;&#20855;&#26377;&#26102;&#21464;&#31995;&#25968;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2305.08342</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;&#29289;&#29702;&#23450;&#24459;&#30340;&#26377;&#38480;&#34920;&#36798;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Finite Expression Methods for Discovering Physical Laws from Data. (arXiv:2305.08342v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;"&#26377;&#38480;&#34920;&#36798;&#27861;" (FEX) &#30340;&#28145;&#24230;&#31526;&#21495;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#21160;&#24577;&#25968;&#25454;&#20013;PDE&#35299;&#30340;&#23548;&#25968;&#65292;&#21457;&#29616;&#25511;&#21046;&#26041;&#31243;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#30456;&#23545;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#65292;FEX&#22312;&#22810;&#31181;&#38382;&#39064;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#65292;&#21253;&#25324;&#26102;&#21464;&#30340;PDE&#38382;&#39064;&#21644;&#20855;&#26377;&#26102;&#21464;&#31995;&#25968;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#26159;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#29616;&#35937;&#12290;&#28982;&#32780;&#65292;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#25512;&#23548;&#20986;&#25551;&#36848;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#23558;&#20171;&#32461;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#31526;&#21495;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;"&#26377;&#38480;&#34920;&#36798;&#27861;" (FEX)&#65292;&#36890;&#36807;&#23398;&#20064;&#21160;&#24577;&#25968;&#25454;&#20013;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#35299;&#30340;&#23548;&#25968;&#65292;&#21033;&#29992;FEX&#22312;&#21253;&#21547;&#26377;&#38480;&#38598;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#30340;&#20989;&#25968;&#31354;&#38388;&#20013;&#21457;&#29616;&#25511;&#21046;&#26041;&#31243;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#23545;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#65288;&#22914;PDE-Net, SINDy, GP &#21644; SPL&#65289;&#65292;&#25105;&#20204;&#30340;FEX&#22312;&#22810;&#31181;&#38382;&#39064;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#65292;&#21253;&#25324;&#26102;&#21464;&#30340;PDE&#38382;&#39064;&#21644;&#20855;&#26377;&#26102;&#21464;&#31995;&#25968;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#12290;&#27492;&#22806;&#65292;&#32467;&#26524;&#31361;&#26174;&#20102;FEX&#30340;&#28789;&#27963;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonlinear dynamics is a pervasive phenomenon observed in scientific and engineering disciplines. However, the task of deriving analytical expressions to describe nonlinear dynamics from limited data remains challenging. In this paper, we shall present a novel deep symbolic learning method called the "finite expression method" (FEX) to discover governing equations within a function space containing a finite set of analytic expressions, based on observed dynamic data. The key concept is to employ FEX to generate analytical expressions of the governing equations by learning the derivatives of partial differential equation (PDE) solutions through convolutions. Our numerical results demonstrate that our FEX surpasses other existing methods (such as PDE-Net, SINDy, GP, and SPL) in terms of numerical performance across a range of problems, including time-dependent PDE problems and nonlinear dynamical systems with time-varying coefficients. Moreover, the results highlight FEX's flexibility and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#21487;&#33021;&#24102;&#26377;&#27495;&#35270;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#19988;&#33021;&#22815;&#22312;&#20844;&#24179;&#30340;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#19988;&#35813;&#26041;&#27861;&#21487;&#22312;&#28040;&#38500;&#27495;&#35270;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#65292;&#24182;&#22312;&#21463;&#20445;&#25252;&#32676;&#20307;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/1912.08189</link><description>&lt;p&gt;
&#20174;&#24102;&#26377;&#27495;&#35270;&#24615;&#36136;&#30340;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning from Discriminatory Training Data. (arXiv:1912.08189v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1912.08189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#21487;&#33021;&#24102;&#26377;&#27495;&#35270;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#19988;&#33021;&#22815;&#22312;&#20844;&#24179;&#30340;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#19988;&#35813;&#26041;&#27861;&#21487;&#22312;&#28040;&#38500;&#27495;&#35270;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#65292;&#24182;&#22312;&#21463;&#20445;&#25252;&#32676;&#20307;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#31995;&#32479;&#26159;&#36890;&#36807;&#21382;&#21490;&#25968;&#25454;&#35757;&#32451;&#30340;&#65292;&#22914;&#26524;&#36825;&#20123;&#25968;&#25454;&#21463;&#21040;&#27495;&#35270;&#24615;&#36136;&#30340;&#24433;&#21709;&#65292;&#37027;&#20040;&#35813;&#31995;&#32479;&#21487;&#33021;&#20250;&#22312;&#20445;&#25252;&#32452;&#20013;&#20135;&#29983;&#27495;&#35270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20844;&#24179;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#28508;&#22312;&#30340;&#27495;&#35270;&#24615;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#65292;&#20063;&#23558;&#22312;&#20844;&#24179;&#30340;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#36716;&#21464;&#20026;&#29305;&#23450;&#20844;&#24179;&#23398;&#20064;&#26041;&#27861;&#30340;&#24212;&#29992;&#26041;&#26696;&#12290;&#20363;&#22914;&#65292;&#28040;&#38500;&#30452;&#25509;&#27495;&#35270;&#21487;&#20197;&#34987;&#34920;&#31034;&#20026;&#29305;&#23450;&#30340;&#25968;&#25454;&#38598;&#36716;&#21464;&#38382;&#39064;&#12290;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#30450;&#30446;&#35757;&#32451;&#21253;&#21547;&#30452;&#25509;&#21152;&#24615;&#27495;&#35270;&#30340;&#25968;&#25454;&#38598;&#30340;&#21516;&#26102;&#65292;&#22312;&#20844;&#24179;&#25968;&#25454;&#38598;&#19978;&#21487;&#20197;&#35777;&#26126;&#26368;&#23567;&#21270;&#27169;&#22411;&#35823;&#24046;&#12290;&#35813;&#26041;&#27861;&#19982;&#29616;&#26377;&#30340;&#27861;&#24459;&#20307;&#31995;&#20860;&#23481;&#65292;&#24182;&#36890;&#36807;&#22312;&#21463;&#20445;&#25252;&#32676;&#20307;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#26469;&#35299;&#20915;&#24191;&#27867;&#35752;&#35770;&#30340;&#21463;&#20445;&#25252;&#32676;&#20307;&#20132;&#21449;&#30340;&#38382;&#39064;&#12290;&#20174;&#25216;&#26415;&#19978;&#35762;&#65292;&#35813;&#26041;&#27861;&#24212;&#29992;&#20102;&#27010;&#29575;&#24178;&#39044;&#65292;&#24182;&#20855;&#26377;&#22240;&#26524;&#21644;&#21453;&#20107;&#23454;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning systems are trained using historical data and, if the data was tainted by discrimination, they may unintentionally learn to discriminate against protected groups. We propose that fair learning methods, despite training on potentially discriminatory datasets, shall perform well on fair test datasets. Such dataset shifts crystallize application scenarios for specific fair learning methods. For instance, the removal of direct discrimination can be represented as a particular dataset shift problem. For this scenario, we propose a learning method that provably minimizes model error on fair datasets, while blindly training on datasets poisoned with direct additive discrimination. The method is compatible with existing legal systems and provides a solution to the widely discussed issue of protected groups' intersectionality by striking a balance between the protected groups. Technically, the method applies probabilistic interventions, has causal and counterfactual formulat
&lt;/p&gt;</description></item></channel></rss>