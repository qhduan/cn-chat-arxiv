<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>TreeDOX&#26159;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#20351;&#29992;&#26102;&#38388;&#24310;&#36831;&#36807;&#24230;&#23884;&#20837;&#21644;&#39069;&#22806;&#26641;&#22238;&#24402;&#22120;&#36827;&#34892;&#29305;&#24449;&#38477;&#32500;&#21644;&#39044;&#27979;&#65292;&#24182;&#22312;&#28145;&#24230;&#39044;&#27979;&#28151;&#27788;&#31995;&#32479;&#20013;&#34920;&#29616;&#20986;state-of-the-art&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13836</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#30340;&#23398;&#20064;&#29992;&#20110;&#28145;&#24230;&#39044;&#27979;&#28151;&#27788;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Tree-based Learning for High-Fidelity Prediction of Chaos
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13836
&lt;/p&gt;
&lt;p&gt;
TreeDOX&#26159;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#20351;&#29992;&#26102;&#38388;&#24310;&#36831;&#36807;&#24230;&#23884;&#20837;&#21644;&#39069;&#22806;&#26641;&#22238;&#24402;&#22120;&#36827;&#34892;&#29305;&#24449;&#38477;&#32500;&#21644;&#39044;&#27979;&#65292;&#24182;&#22312;&#28145;&#24230;&#39044;&#27979;&#28151;&#27788;&#31995;&#32479;&#20013;&#34920;&#29616;&#20986;state-of-the-art&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#39044;&#27979;&#28151;&#27788;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#26159;&#33267;&#20851;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#38656;&#35201;&#36827;&#34892;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#36825;&#20005;&#37325;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65306;TreeDOX&#12290;&#23427;&#20351;&#29992;&#26102;&#38388;&#24310;&#36831;&#36807;&#24230;&#23884;&#20837;&#20316;&#20026;&#26174;&#24335;&#30701;&#26399;&#35760;&#24518;&#65292;&#20197;&#21450;&#39069;&#22806;&#26641;&#22238;&#24402;&#22120;&#26469;&#25191;&#34892;&#29305;&#24449;&#38477;&#32500;&#21644;&#39044;&#27979;&#12290;&#25105;&#20204;&#20351;&#29992;Henon&#26144;&#23556;&#65292;Lorenz&#21644;Kuramoto-Sivashinsky&#31995;&#32479;&#20197;&#21450;&#29616;&#23454;&#19990;&#30028;&#30340;Southern Oscillation Index&#23637;&#31034;&#20102;TreeDOX&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13836v1 Announce Type: new  Abstract: Model-free forecasting of the temporal evolution of chaotic systems is crucial but challenging. Existing solutions require hyperparameter tuning, significantly hindering their wider adoption. In this work, we introduce a tree-based approach not requiring hyperparameter tuning: TreeDOX. It uses time delay overembedding as explicit short-term memory and Extra-Trees Regressors to perform feature reduction and forecasting. We demonstrate the state-of-the-art performance of TreeDOX using the Henon map, Lorenz and Kuramoto-Sivashinsky systems, and the real-world Southern Oscillation Index.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#26102;&#38388;&#19968;&#33268;Koopman&#33258;&#32534;&#30721;&#22120;&#65288;tcKAE&#65289;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;&#38271;&#26399;&#39044;&#27979;&#65292;&#22312;&#26377;&#38480;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#19979;&#36890;&#36807;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#39033;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.12335</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#21160;&#24577;&#31995;&#32479;&#30340;&#26102;&#38388;&#19968;&#33268;&#30340;Koopman&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Temporally-Consistent Koopman Autoencoders for Forecasting Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12335
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#26102;&#38388;&#19968;&#33268;Koopman&#33258;&#32534;&#30721;&#22120;&#65288;tcKAE&#65289;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;&#38271;&#26399;&#39044;&#27979;&#65292;&#22312;&#26377;&#38480;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#19979;&#36890;&#36807;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#39033;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#20047;&#36275;&#22815;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#32463;&#24120;&#26159;&#39640;&#32500;&#26102;&#31354;&#21160;&#24577;&#31995;&#32479;&#25968;&#25454;&#39537;&#21160;&#24314;&#27169;&#20013;&#20851;&#38190;&#25361;&#25112;&#12290;Koopman&#33258;&#32534;&#30721;&#22120;&#65288;KAEs&#65289;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#12289;&#33258;&#32534;&#30721;&#22120;&#30340;&#38477;&#32500;&#33021;&#21147;&#20197;&#21450;Koopman&#31639;&#23376;&#30340;&#35889;&#29305;&#24615;&#65292;&#23398;&#20064;&#20855;&#26377;&#26356;&#31616;&#21333;&#32447;&#24615;&#21160;&#24577;&#30340;&#38477;&#38454;&#29305;&#24449;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;KAEs&#30340;&#26377;&#25928;&#24615;&#21463;&#38480;&#20110;&#26377;&#38480;&#32780;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#23548;&#33268;&#27867;&#21270;&#33021;&#21147;&#36739;&#24046;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#26102;&#38388;&#19968;&#33268;Koopman&#33258;&#32534;&#30721;&#22120;&#65288;tcKAE&#65289;&#30340;&#27169;&#22411;&#65292;&#26088;&#22312;&#21363;&#20351;&#22312;&#21463;&#38480;&#19988;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#24773;&#20917;&#19979;&#29983;&#25104;&#20934;&#30830;&#30340;&#38271;&#26399;&#39044;&#27979;&#12290;&#36825;&#26159;&#36890;&#36807;&#24378;&#21046;&#22312;&#19981;&#21516;&#26102;&#38388;&#27493;&#19978;&#20445;&#25345;&#39044;&#27979;&#19968;&#33268;&#24615;&#30340;&#19968;&#33268;&#24615;&#27491;&#21017;&#21270;&#39033;&#23454;&#29616;&#30340;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;tcKAE&#30456;&#23545;&#20110;&#29616;&#26377;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12335v1 Announce Type: new  Abstract: Absence of sufficiently high-quality data often poses a key challenge in data-driven modeling of high-dimensional spatio-temporal dynamical systems. Koopman Autoencoders (KAEs) harness the expressivity of deep neural networks (DNNs), the dimension reduction capabilities of autoencoders, and the spectral properties of the Koopman operator to learn a reduced-order feature space with simpler, linear dynamics. However, the effectiveness of KAEs is hindered by limited and noisy training datasets, leading to poor generalizability. To address this, we introduce the Temporally-Consistent Koopman Autoencoder (tcKAE), designed to generate accurate long-term predictions even with constrained and noisy training data. This is achieved through a consistency regularization term that enforces prediction coherence across different time steps, thus enhancing the robustness and generalizability of tcKAE over existing models. We provide analytical justifica
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27010;&#29575;&#28508;&#22312;&#31354;&#38388;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#37322;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#30340;&#20248;&#21270;&#32593;&#32476;&#31232;&#30095;&#24230;&#65292;&#24182;&#25506;&#35752;&#20102;&#32593;&#32476;&#23618;&#30340;AP3/AP2&#23646;&#24615;&#19982;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.00155</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#28508;&#22312;&#31354;&#38388;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00155
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#28508;&#22312;&#31354;&#38388;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#37322;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#30340;&#20248;&#21270;&#32593;&#32476;&#31232;&#30095;&#24230;&#65292;&#24182;&#25506;&#35752;&#20102;&#32593;&#32476;&#23618;&#30340;AP3/AP2&#23646;&#24615;&#19982;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#21644;&#23384;&#20648;&#31354;&#38388;&#28040;&#32791;&#23548;&#33268;&#20102;&#32593;&#32476;&#21387;&#32553;&#30340;&#27010;&#24565;&#12290;&#23613;&#31649;&#24050;&#24191;&#27867;&#30740;&#31350;&#20102;&#35832;&#22914;&#20462;&#21098;&#21644;&#20302;&#31209;&#20998;&#35299;&#31561;DNN&#21387;&#32553;&#25216;&#26415;&#65292;&#20294;&#23545;&#23427;&#20204;&#30340;&#29702;&#35770;&#35299;&#37322;&#20173;&#26410;&#21463;&#21040;&#36275;&#22815;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;DNN&#26435;&#37325;&#30340;&#27010;&#29575;&#28508;&#22312;&#31354;&#38388;&#24182;&#21033;&#29992;&#20449;&#24687;&#29702;&#35770;&#20998;&#27495;&#24230;&#37327;&#35299;&#37322;&#26368;&#20339;&#32593;&#32476;&#31232;&#30095;&#24615;&#30340;&#26032;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#20026;DNN&#24341;&#20837;&#20102;&#26032;&#30340;&#31867;&#27604;&#25237;&#24433;&#27169;&#24335;&#65288;AP2&#65289;&#21644;&#27010;&#29575;&#20013;&#30340;&#31867;&#27604;&#25237;&#24433;&#27169;&#24335;&#65288;AP3&#65289;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#32593;&#32476;&#20013;&#23618;&#30340;AP3/AP2&#29305;&#24615;&#19982;&#20854;&#24615;&#33021;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#20998;&#26512;&#65292;&#35299;&#37322;&#20102;&#21387;&#32553;&#32593;&#32476;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#26159;&#20174;&#23454;&#35777;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00155v1 Announce Type: new  Abstract: Despite the impressive performance of deep neural networks (DNNs), their computational complexity and storage space consumption have led to the concept of network compression. While DNN compression techniques such as pruning and low-rank decomposition have been extensively studied, there has been insufficient attention paid to their theoretical explanation. In this paper, we propose a novel theoretical framework that leverages a probabilistic latent space of DNN weights and explains the optimal network sparsity by using the information-theoretic divergence measures. We introduce new analogous projected patterns (AP2) and analogous-in-probability projected patterns (AP3) notions for DNNs and prove that there exists a relationship between AP3/AP2 property of layers in the network and its performance. Further, we provide a theoretical analysis that explains the training process of the compressed network. The theoretical results are empirica
&lt;/p&gt;</description></item><item><title>&#22312;&#36830;&#32493;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#23547;&#27714;&#24110;&#21161;&#26469;&#36991;&#20813;&#28798;&#38590;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#28798;&#38590;&#21457;&#29983;&#30340;&#27010;&#29575;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#36830;&#32493;1D&#29366;&#24577;&#31354;&#38388;&#21644;&#30456;&#23545;&#31616;&#21333;&#30340;&#22238;&#25253;&#20989;&#25968;&#19979;&#65292;&#36951;&#25022;&#21644;&#21521;&#23548;&#24072;&#26597;&#35810;&#29575;&#37117;&#36235;&#36817;&#20110;0&#12290;</title><link>https://arxiv.org/abs/2402.08062</link><description>&lt;p&gt;
&#36991;&#20813;&#36830;&#32493;&#31354;&#38388;&#20013;&#30340;&#28798;&#38590;&#65306;&#36890;&#36807;&#23547;&#27714;&#24110;&#21161;
&lt;/p&gt;
&lt;p&gt;
Avoiding Catastrophe in Continuous Spaces by Asking for Help
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08062
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#31354;&#38388;&#20013;&#65292;&#36890;&#36807;&#23547;&#27714;&#24110;&#21161;&#26469;&#36991;&#20813;&#28798;&#38590;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#28798;&#38590;&#21457;&#29983;&#30340;&#27010;&#29575;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#36830;&#32493;1D&#29366;&#24577;&#31354;&#38388;&#21644;&#30456;&#23545;&#31616;&#21333;&#30340;&#22238;&#25253;&#20989;&#25968;&#19979;&#65292;&#36951;&#25022;&#21644;&#21521;&#23548;&#24072;&#26597;&#35810;&#29575;&#37117;&#36235;&#36817;&#20110;0&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#20855;&#26377;&#27491;&#24335;&#36951;&#25022;&#20445;&#35777;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20551;&#35774;&#25152;&#26377;&#38169;&#35823;&#37117;&#26159;&#21487;&#36870;&#30340;&#65292;&#24182;&#20381;&#36182;&#20110;&#23581;&#35797;&#25152;&#26377;&#21487;&#33021;&#30340;&#36873;&#39033;&#12290;&#24403;&#19968;&#20123;&#38169;&#35823;&#26159;&#26080;&#27861;&#20462;&#22797;&#29978;&#33267;&#26159;&#28798;&#38590;&#24615;&#30340;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#20250;&#23548;&#33268;&#31967;&#31957;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#21457;&#29983;&#28798;&#38590;&#30340;&#27010;&#29575;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20551;&#35774;&#27599;&#36718;&#30340;&#22238;&#25253;&#20195;&#34920;&#20102;&#22312;&#35813;&#36718;&#36991;&#20813;&#28798;&#38590;&#30340;&#27010;&#29575;&#65292;&#24182;&#23581;&#35797;&#26368;&#22823;&#21270;&#22238;&#25253;&#30340;&#20056;&#31215;&#65288;&#24635;&#20307;&#36991;&#20813;&#28798;&#38590;&#30340;&#27010;&#29575;&#65289;&#12290;&#20026;&#20102;&#32473; agent &#19968;&#20123;&#25104;&#21151;&#30340;&#26426;&#20250;&#65292;&#25105;&#20204;&#20801;&#35768;&#26377;&#38480;&#27425;&#21521;&#23548;&#24072;&#25552;&#38382;&#65292;&#24182;&#20551;&#35774;&#22238;&#25253;&#20989;&#25968;&#20026; Lipschitz &#36830;&#32493;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#24403;&#26102;&#38388;&#36328;&#24230;&#22686;&#38271;&#26102;&#65292;&#23427;&#30340;&#36951;&#25022;&#21644;&#21521;&#23548;&#24072;&#26597;&#35810;&#29575;&#37117;&#36235;&#36817;&#20110; 0&#65292;&#20551;&#35774;&#26159;&#19968;&#20010;&#36830;&#32493;&#30340; 1D &#29366;&#24577;&#31354;&#38388;&#21644;&#30456;&#23545;"&#31616;&#21333;"&#30340;&#22238;&#25253;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#21305;&#37197;&#30340;&#19979;&#30028;&#65306;&#22312;&#27809;&#26377;&#31616;&#21333;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20219;&#20309;&#31639;&#27861;&#35201;&#20040;&#19981;&#26029;&#26597;&#35810;&#24322;&#24120;&#30340;&#34892;&#20026;&#65292;&#35201;&#20040;&#27599;&#27425;&#26597;&#35810;&#23436;&#20840;&#30456;&#21516;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most reinforcement learning algorithms with formal regret guarantees assume all mistakes are reversible and rely on essentially trying all possible options. This approach leads to poor outcomes when some mistakes are irreparable or even catastrophic. We propose a variant of the contextual bandit problem where the goal is to minimize the chance of catastrophe. Specifically, we assume that the payoff each round represents the chance of avoiding catastrophe that round, and try to maximize the product of payoffs (the overall chance of avoiding catastrophe). To give the agent some chance of success, we allow a limited number of queries to a mentor and assume a Lipschitz continuous payoff function. We present an algorithm whose regret and rate of querying the mentor both approach 0 as the time horizon grows, assuming a continuous 1D state space and a relatively "simple" payoff function. We also provide a matching lower bound: without the simplicity assumption: any algorithm either constantly
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#22810;&#26679;&#24615;&#31995;&#25968;&#20316;&#20026;LLM&#39044;&#35757;&#32451;&#25968;&#25454;&#36136;&#37327;&#30340;&#25351;&#26631;&#65292;&#30740;&#31350;&#34920;&#26126;&#20844;&#24320;&#21487;&#29992;&#30340;LLM&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#31995;&#25968;&#24456;&#39640;&#12290;</title><link>http://arxiv.org/abs/2306.13840</link><description>&lt;p&gt;
&#36229;&#36234;&#35268;&#27169;&#65306;&#22810;&#26679;&#24615;&#31995;&#25968;&#20316;&#20026;&#25968;&#25454;&#36136;&#37327;&#25351;&#26631;&#35777;&#26126;&#20102;LLMs&#26159;&#22312;&#24418;&#24335;&#22810;&#26679;&#30340;&#25968;&#25454;&#19978;&#39044;&#20808;&#35757;&#32451;&#30340;
&lt;/p&gt;
&lt;p&gt;
Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data. (arXiv:2306.13840v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13840
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#22810;&#26679;&#24615;&#31995;&#25968;&#20316;&#20026;LLM&#39044;&#35757;&#32451;&#25968;&#25454;&#36136;&#37327;&#30340;&#25351;&#26631;&#65292;&#30740;&#31350;&#34920;&#26126;&#20844;&#24320;&#21487;&#29992;&#30340;LLM&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#31995;&#25968;&#24456;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#65292;&#39044;&#20808;&#35757;&#32451;&#24378;&#22823;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#36235;&#21183;&#20027;&#35201;&#38598;&#20013;&#22312;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#35268;&#27169;&#30340;&#25193;&#22823;&#12290;&#28982;&#32780;&#65292;&#39044;&#20808;&#35757;&#32451;&#25968;&#25454;&#30340;&#36136;&#37327;&#23545;&#20110;&#35757;&#32451;&#24378;&#22823;&#30340;LLMs&#26469;&#35828;&#26159;&#19968;&#20010;&#37325;&#35201;&#22240;&#32032;&#65292;&#20294;&#23427;&#26159;&#19968;&#20010;&#27169;&#31946;&#30340;&#27010;&#24565;&#65292;&#23578;&#26410;&#23436;&#20840;&#34920;&#24449;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;Task2Vec&#22810;&#26679;&#24615;&#31995;&#25968;&#26469;&#22522;&#20110;&#25968;&#25454;&#36136;&#37327;&#30340;&#24418;&#24335;&#26041;&#38754;&#65292;&#36229;&#36234;&#35268;&#27169;&#26412;&#36523;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#27979;&#37327;&#20844;&#24320;&#21487;&#29992;&#30340;&#39044;&#20808;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#31995;&#25968;&#65292;&#20197;&#35777;&#26126;&#23427;&#20204;&#30340;&#24418;&#24335;&#22810;&#26679;&#24615;&#39640;&#20110;&#29702;&#35770;&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#24314;&#31435;&#23545;&#22810;&#26679;&#24615;&#31995;&#25968;&#30340;&#20449;&#24515;&#65292;&#25105;&#20204;&#36827;&#34892;&#21487;&#35299;&#37322;&#24615;&#23454;&#39564;&#65292;&#24182;&#21457;&#29616;&#35813;&#31995;&#25968;&#19982;&#22810;&#26679;&#24615;&#30340;&#30452;&#35266;&#23646;&#24615;&#30456;&#21563;&#21512;&#65292;&#20363;&#22914;&#65292;&#38543;&#30528;&#28508;&#22312;&#27010;&#24565;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#23427;&#22686;&#21152;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#22810;&#26679;&#24615;&#31995;&#25968;&#26159;&#21487;&#38752;&#30340;&#65292;&#34920;&#26126;&#20844;&#24320;&#21487;&#29992;&#30340;LLM&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#31995;&#25968;&#24456;&#39640;&#65292;&#24182;&#25512;&#27979;&#23427;&#21487;&#20197;&#20316;&#20026;&#39044;&#35757;&#32451;LLMs&#27169;&#22411;&#30340;&#25968;&#25454;&#36136;&#37327;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current trends to pre-train capable Large Language Models (LLMs) mostly focus on scaling of model and dataset size. However, the quality of pre-training data is an important factor for training powerful LLMs, yet it is a nebulous concept that has not been fully characterized. Therefore, we use the recently proposed Task2Vec diversity coefficient to ground and understand formal aspects of data quality, to go beyond scale alone. Specifically, we measure the diversity coefficient of publicly available pre-training datasets to demonstrate that their formal diversity is high when compared to theoretical lower and upper bounds. In addition, to build confidence in the diversity coefficient, we conduct interpretability experiments and find that the coefficient aligns with intuitive properties of diversity, e.g., it increases as the number of latent concepts increases. We conclude the diversity coefficient is reliable, show it's high for publicly available LLM datasets, and conjecture it can be
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#38544;&#24335;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#65288;ICDA&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#26679;&#26412;&#22686;&#24378;&#31574;&#30053;&#12289;&#26131;&#20110;&#35745;&#31639;&#30340;&#20195;&#29702;&#25439;&#22833;&#21644;&#20855;&#20307;&#26041;&#26696;&#65292;&#28040;&#38500;&#20102;&#34394;&#20551;&#20851;&#32852;&#24182;&#36827;&#34892;&#20102;&#31283;&#20581;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2304.13431</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24335;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Implicit Counterfactual Data Augmentation for Deep Neural Networks. (arXiv:2304.13431v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#38544;&#24335;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#65288;ICDA&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#26679;&#26412;&#22686;&#24378;&#31574;&#30053;&#12289;&#26131;&#20110;&#35745;&#31639;&#30340;&#20195;&#29702;&#25439;&#22833;&#21644;&#20855;&#20307;&#26041;&#26696;&#65292;&#28040;&#38500;&#20102;&#34394;&#20551;&#20851;&#32852;&#24182;&#36827;&#34892;&#20102;&#31283;&#20581;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26131;&#20110;&#25429;&#25417;&#38750;&#22240;&#26524;&#23646;&#24615;&#21644;&#31867;&#21035;&#20043;&#38388;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#65292;&#20351;&#29992;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26159;&#30772;&#38500;&#36825;&#20123;&#34394;&#20551;&#30340;&#32852;&#24819;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#26126;&#30830;&#29983;&#25104;&#21453;&#20107;&#23454;&#25968;&#25454;&#24456;&#20855;&#25361;&#25112;&#24615;&#65292;&#35757;&#32451;&#25928;&#29575;&#20250;&#38477;&#20302;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#24335;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#65288;Implicit Counterfactual Data Augmentation&#65292;ICDA&#65289;&#26041;&#27861;&#26469;&#28040;&#38500;&#34394;&#20551;&#20851;&#32852;&#24182;&#36827;&#34892;&#31283;&#20581;&#39044;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#39318;&#20808;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26679;&#26412;&#22686;&#24378;&#31574;&#30053;&#65292;&#20026;&#27599;&#20010;&#26679;&#26412;&#29983;&#25104;&#22312;&#35821;&#20041;&#21644;&#21453;&#20107;&#23454;&#24847;&#20041;&#19978;&#26377;&#24847;&#20041;&#30340;&#28145;&#24230;&#29305;&#24449;&#65292;&#24182;&#20855;&#26377;&#19981;&#21516;&#30340;&#22686;&#24378;&#24378;&#24230;&#12290;&#20854;&#27425;&#65292;&#24403;&#22686;&#24191;&#26679;&#26412;&#25968;&#21464;&#20026;&#26080;&#31351;&#22823;&#26102;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#23545;&#20110;&#22686;&#24191;&#29305;&#24449;&#38598;&#30340;&#26131;&#20110;&#35745;&#31639;&#30340;&#20195;&#29702;&#25439;&#22833;&#12290;&#31532;&#19977;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#20855;&#20307;&#30340;&#26041;&#26696;&#65292;&#21253;&#25324;&#30452;&#25509;&#37327;&#21270;&#21644;&#20803;&#23398;&#20064;&#65292;&#20197;&#30830;&#23450;&#40065;&#26834;&#24615;&#25439;&#22833;&#30340;&#20851;&#38190;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#20174;&#23454;&#39564;&#30340;&#35282;&#24230;&#35299;&#37322;&#20102;ICDA&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine-learning models are prone to capturing the spurious correlations between non-causal attributes and classes, with counterfactual data augmentation being a promising direction for breaking these spurious associations. However, explicitly generating counterfactual data is challenging, with the training efficiency declining. Therefore, this study proposes an implicit counterfactual data augmentation (ICDA) method to remove spurious correlations and make stable predictions. Specifically, first, a novel sample-wise augmentation strategy is developed that generates semantically and counterfactually meaningful deep features with distinct augmentation strength for each sample. Second, we derive an easy-to-compute surrogate loss on the augmented feature set when the number of augmented samples becomes infinite. Third, two concrete schemes are proposed, including direct quantification and meta-learning, to derive the key parameters for the robust loss. In addition, ICDA is explained from 
&lt;/p&gt;</description></item><item><title>KD-BIRL&#26159;&#19968;&#31181;&#26680;&#23494;&#24230;&#36125;&#21494;&#26031;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#36924;&#36817;&#20284;&#28982;&#20989;&#25968;&#26469;&#23398;&#20064;&#20195;&#29702;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#20811;&#26381;&#20102;&#23398;&#20064;&#28857;&#20272;&#35745;&#30340;&#32570;&#28857;&#65292;&#24182;&#36866;&#29992;&#20110;&#22797;&#26434;&#21644;&#26080;&#38480;&#29615;&#22659;&#12290;</title><link>http://arxiv.org/abs/2303.06827</link><description>&lt;p&gt;
&#26680;&#23494;&#24230;&#36125;&#21494;&#26031;&#36870;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Kernel Density Bayesian Inverse Reinforcement Learning. (arXiv:2303.06827v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06827
&lt;/p&gt;
&lt;p&gt;
KD-BIRL&#26159;&#19968;&#31181;&#26680;&#23494;&#24230;&#36125;&#21494;&#26031;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#36924;&#36817;&#20284;&#28982;&#20989;&#25968;&#26469;&#23398;&#20064;&#20195;&#29702;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#20811;&#26381;&#20102;&#23398;&#20064;&#28857;&#20272;&#35745;&#30340;&#32570;&#28857;&#65292;&#24182;&#36866;&#29992;&#20110;&#22797;&#26434;&#21644;&#26080;&#38480;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#26159;&#19968;&#31181;&#36890;&#36807;&#35266;&#23519;&#20195;&#29702;&#34892;&#20026;&#26469;&#25512;&#26029;&#20854;&#22870;&#21169;&#20989;&#25968;&#30340;&#24378;&#22823;&#26694;&#26550;&#65292;&#20294;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#30340;&#28857;&#20272;&#35745;&#21487;&#33021;&#20250;&#35823;&#23548;&#65292;&#22240;&#20026;&#21487;&#33021;&#26377;&#22810;&#20010;&#20989;&#25968;&#33021;&#22815;&#24456;&#22909;&#22320;&#25551;&#36848;&#20195;&#29702;&#30340;&#34892;&#20026;&#12290;&#36125;&#21494;&#26031;&#36870;&#24378;&#21270;&#23398;&#20064;&#37319;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#27169;&#25311;&#20505;&#36873;&#22870;&#21169;&#20989;&#25968;&#30340;&#20998;&#24067;&#65292;&#20811;&#26381;&#20102;&#23398;&#20064;&#28857;&#20272;&#35745;&#30340;&#32570;&#28857;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#36125;&#21494;&#26031;&#36870;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20351;&#29992;Q&#20540;&#20989;&#25968;&#20195;&#26367;&#20284;&#28982;&#20989;&#25968;&#12290;&#30001;&#27492;&#24471;&#21040;&#30340;&#21518;&#39564;&#35745;&#31639;&#37327;&#22823;&#65292;&#29702;&#35770;&#20445;&#35777;&#23569;&#65292;&#24182;&#19988;Q&#20540;&#20989;&#25968;&#36890;&#24120;&#23545;&#20284;&#28982;&#20989;&#25968;&#30340;&#36924;&#36817;&#25928;&#26524;&#36739;&#24046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26680;&#23494;&#24230;&#36125;&#21494;&#26031;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;KD-BIRL&#65289;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#26465;&#20214;&#26680;&#23494;&#24230;&#20272;&#35745;&#30452;&#25509;&#36924;&#36817;&#20284;&#28982;&#20989;&#25968;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#22312;&#32463;&#36807;&#25913;&#36827;&#30340;&#22870;&#21169;&#20989;&#25968;&#21442;&#25968;&#21270;&#19979;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22797;&#26434;&#21644;&#26080;&#38480;&#30340;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse reinforcement learning~(IRL) is a powerful framework to infer an agent's reward function by observing its behavior, but IRL algorithms that learn point estimates of the reward function can be misleading because there may be several functions that describe an agent's behavior equally well. A Bayesian approach to IRL models a distribution over candidate reward functions, alleviating the shortcomings of learning a point estimate. However, several Bayesian IRL algorithms use a $Q$-value function in place of the likelihood function. The resulting posterior is computationally intensive to calculate, has few theoretical guarantees, and the $Q$-value function is often a poor approximation for the likelihood. We introduce kernel density Bayesian IRL (KD-BIRL), which uses conditional kernel density estimation to directly approximate the likelihood, providing an efficient framework that, with a modified reward function parameterization, is applicable to environments with complex and infin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#27169;&#22411;&#29702;&#35770;&#20013;&#26377;&#20851;&#29702;&#35770;&#31283;&#23450;&#24615;&#21644;&#23398;&#20064;&#20013;&#31639;&#27861;&#31283;&#23450;&#24615;&#30340;&#20132;&#20114;&#65292;&#36890;&#36807;&#31639;&#27861;&#24615;&#36136;&#21462;&#20195;&#20102;&#26080;&#38480;&#65292;&#37325;&#35775;&#20102;Shelah&#38395;&#21517;&#30340;&#19981;&#31283;&#23450;&#20844;&#24335;&#23450;&#29702;&#65292;&#24182;&#24341;&#20837;&#20102;&#21487;&#33021;&#26368;&#32456;&#27491;&#30830;&#23398;&#20064;&#27169;&#22411;&#65292;&#34920;&#24449;&#20102;Littlestone&#65288;&#31283;&#23450;&#65289;&#31867;&#65292;&#36879;&#36807;&#27169;&#22411;&#35770;&#20013;&#31867;&#22411;&#30340;&#21487;&#23450;&#20041;&#24615;&#24418;&#24335;&#21270;&#20102;Littlestone&#31867;&#30340;&#36924;&#36817;&#12290;</title><link>http://arxiv.org/abs/2212.05050</link><description>&lt;p&gt;
&#36890;&#36807;&#31639;&#27861;&#37325;&#35775;&#19981;&#31283;&#23450;&#20844;&#24335;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
The unstable formula theorem revisited via algorithms. (arXiv:2212.05050v2 [math.LO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#27169;&#22411;&#29702;&#35770;&#20013;&#26377;&#20851;&#29702;&#35770;&#31283;&#23450;&#24615;&#21644;&#23398;&#20064;&#20013;&#31639;&#27861;&#31283;&#23450;&#24615;&#30340;&#20132;&#20114;&#65292;&#36890;&#36807;&#31639;&#27861;&#24615;&#36136;&#21462;&#20195;&#20102;&#26080;&#38480;&#65292;&#37325;&#35775;&#20102;Shelah&#38395;&#21517;&#30340;&#19981;&#31283;&#23450;&#20844;&#24335;&#23450;&#29702;&#65292;&#24182;&#24341;&#20837;&#20102;&#21487;&#33021;&#26368;&#32456;&#27491;&#30830;&#23398;&#20064;&#27169;&#22411;&#65292;&#34920;&#24449;&#20102;Littlestone&#65288;&#31283;&#23450;&#65289;&#31867;&#65292;&#36879;&#36807;&#27169;&#22411;&#35770;&#20013;&#31867;&#22411;&#30340;&#21487;&#23450;&#20041;&#24615;&#24418;&#24335;&#21270;&#20102;Littlestone&#31867;&#30340;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#26377;&#20851;&#27169;&#22411;&#29702;&#35770;&#20013;&#20851;&#20110;&#29702;&#35770;&#31283;&#23450;&#24615;&#30340;&#22522;&#30784;&#32467;&#26524;&#19982;&#23398;&#20064;&#20013;&#31639;&#27861;&#31283;&#23450;&#24615;&#20043;&#38388;&#24778;&#20154;&#30340;&#20132;&#20114;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#31639;&#27861;&#24615;&#36136;&#21462;&#20195;&#26080;&#38480;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;Shelah&#38395;&#21517;&#30340;&#19981;&#31283;&#23450;&#20844;&#24335;&#23450;&#29702;&#30340;&#23436;&#25972;&#31639;&#27861;&#31867;&#27604;&#12290;&#36825;&#20854;&#20013;&#28041;&#21450;&#20102;&#20960;&#20010;&#26032;&#23450;&#29702;&#20197;&#21450;&#26368;&#36817;&#30340;&#30740;&#31350;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#8220;&#21487;&#33021;&#26368;&#32456;&#27491;&#30830;&#8221;&#30340;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36825;&#20010;&#27169;&#22411;&#34920;&#24449;&#20102;Littlestone&#65288;&#31283;&#23450;&#65289;&#31867;&#65307;&#24182;&#36890;&#36807;&#27169;&#22411;&#35770;&#20013;&#31867;&#22411;&#30340;&#21487;&#23450;&#20041;&#24615;&#31867;&#27604;&#25551;&#36848;&#20102;Littlestone&#31867;&#30340;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is about the surprising interaction of a foundational result from model theory about stability of theories, which seems to be inherently about the infinite, with algorithmic stability in learning. Specifically, we develop a complete algorithmic analogue of Shelah's celebrated Unstable Formula Theorem, with algorithmic properties taking the place of the infinite. This draws on several new theorems as well as much recent work. In particular we introduce a new ``Probably Eventually Correct'' learning model, of independent interest, and characterize Littlestone (stable) classes in terms of this model; and we describe Littlestone classes via approximations, by analogy to definability of types in model theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#27867;&#21270;&#26102;&#33021;&#22815;&#24456;&#22909;&#24212;&#23545;&#22122;&#22768;&#25968;&#25454;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23558;&#35757;&#32451;&#35823;&#24046;&#38477;&#33267;&#38646;&#24182;&#23436;&#32654;&#22320;&#36866;&#24212;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#65292;&#24182;&#21516;&#26102;&#36798;&#21040;&#26368;&#20248;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2202.05928</link><description>&lt;p&gt;
&#19981;&#38656;&#35201;&#32447;&#24615;&#20851;&#31995;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#65306;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#29992;&#20110;&#22122;&#22768;&#32447;&#24615;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. (arXiv:2202.05928v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#27867;&#21270;&#26102;&#33021;&#22815;&#24456;&#22909;&#24212;&#23545;&#22122;&#22768;&#25968;&#25454;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23558;&#35757;&#32451;&#35823;&#24046;&#38477;&#33267;&#38646;&#24182;&#23436;&#32654;&#22320;&#36866;&#24212;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#65292;&#24182;&#21516;&#26102;&#36798;&#21040;&#26368;&#20248;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33391;&#24615;&#36807;&#25311;&#21512;&#26159;&#25351;&#25554;&#20540;&#27169;&#22411;&#22312;&#23384;&#22312;&#22122;&#22768;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#30340;&#29616;&#35937;&#65292;&#26368;&#26089;&#20986;&#29616;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#23454;&#35777;&#35266;&#23519;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#21518;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#22312;&#36923;&#36753;&#25439;&#22833;&#20989;&#25968;&#19978;&#36827;&#34892;&#25554;&#20540;&#35757;&#32451;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#20551;&#35774;&#25968;&#25454;&#26469;&#33258;&#20110;&#26126;&#26174;&#20998;&#31163;&#30340;&#31867;&#26465;&#20214;&#23545;&#25968;&#20985;&#20998;&#24067;&#65292;&#24182;&#20801;&#35768;&#35757;&#32451;&#26631;&#31614;&#20013;&#30340;&#19968;&#23450;&#27604;&#20363;&#34987;&#23545;&#25163;&#31713;&#25913;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#34920;&#29616;&#20986;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#29305;&#28857;&#65306;&#23427;&#20204;&#21487;&#20197;&#34987;&#39537;&#21160;&#21040;&#38646;&#35757;&#32451;&#35823;&#24046;&#65292;&#23436;&#32654;&#22320;&#25311;&#21512;&#20219;&#20309;&#26377;&#22122;&#22768;&#30340;&#35757;&#32451;&#26631;&#31614;&#65292;&#24182;&#21516;&#26102;&#36798;&#21040;&#26497;&#23567;&#21270;&#26368;&#22823;&#21270;&#26368;&#20248;&#27979;&#35797;&#35823;&#24046;&#12290;&#19982;&#20043;&#21069;&#20851;&#20110;&#33391;&#24615;&#36807;&#25311;&#21512;&#38656;&#35201;&#32447;&#24615;&#25110;&#22522;&#20110;&#26680;&#30340;&#39044;&#27979;&#22120;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#22312;&#27169;&#22411;&#21644;&#23398;&#20064;&#21160;&#24577;&#37117;&#26159;&#22522;&#26412;&#38750;&#32447;&#24615;&#30340;&#24773;&#20917;&#19979;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
Benign overfitting, the phenomenon where interpolating models generalize well in the presence of noisy data, was first observed in neural network models trained with gradient descent. To better understand this empirical observation, we consider the generalization error of two-layer neural networks trained to interpolation by gradient descent on the logistic loss following random initialization. We assume the data comes from well-separated class-conditional log-concave distributions and allow for a constant fraction of the training labels to be corrupted by an adversary. We show that in this setting, neural networks exhibit benign overfitting: they can be driven to zero training error, perfectly fitting any noisy training labels, and simultaneously achieve minimax optimal test error. In contrast to previous work on benign overfitting that require linear or kernel-based predictors, our analysis holds in a setting where both the model and learning dynamics are fundamentally nonlinear.
&lt;/p&gt;</description></item></channel></rss>