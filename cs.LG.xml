<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25237;&#31080;&#30340;&#22312;&#32447;&#20381;&#20174;&#27169;&#22411;&#32858;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#36807;&#21435;&#34920;&#29616;&#35843;&#25972;&#27169;&#22411;&#26435;&#37325;&#12290;</title><link>https://arxiv.org/abs/2403.15527</link><description>&lt;p&gt;
&#20381;&#20174;&#22312;&#32447;&#27169;&#22411;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Conformal online model aggregation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15527
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25237;&#31080;&#30340;&#22312;&#32447;&#20381;&#20174;&#27169;&#22411;&#32858;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#36807;&#21435;&#34920;&#29616;&#35843;&#25972;&#27169;&#22411;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20381;&#20174;&#39044;&#27979;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#31181;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#27010;&#24565;&#65292;&#32780;&#19981;&#38656;&#35201;&#20570;&#20986;&#24378;&#28872;&#30340;&#20998;&#24067;&#20551;&#35774;&#12290;&#23427;&#36866;&#29992;&#20110;&#20219;&#20309;&#40657;&#30418;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#23558;&#28857;&#39044;&#27979;&#36716;&#25442;&#25104;&#20855;&#26377;&#39044;&#23450;&#20041;&#36793;&#38469;&#35206;&#30422;&#20445;&#35777;&#30340;&#38598;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#20381;&#20174;&#39044;&#27979;&#21482;&#22312;&#20107;&#20808;&#30830;&#23450;&#24213;&#23618;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#36215;&#20316;&#29992;&#12290;&#20381;&#20174;&#39044;&#27979;&#20013;&#30456;&#23545;&#36739;&#23569;&#28041;&#21450;&#30340;&#38382;&#39064;&#26159;&#27169;&#22411;&#36873;&#25321;&#21644;/&#25110;&#32858;&#21512;&#65306;&#23545;&#20110;&#32473;&#23450;&#30340;&#38382;&#39064;&#65292;&#24212;&#35813;&#22914;&#20309;&#20381;&#20174;&#21270;&#20247;&#22810;&#39044;&#27979;&#26041;&#27861;&#65288;&#38543;&#26426;&#26862;&#26519;&#12289;&#31070;&#32463;&#32593;&#32476;&#12289;&#27491;&#21017;&#21270;&#32447;&#24615;&#27169;&#22411;&#31561;&#65289;&#65311;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20381;&#20174;&#27169;&#22411;&#32858;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#35774;&#32622;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#23558;&#26469;&#33258;&#22810;&#20010;&#31639;&#27861;&#30340;&#39044;&#27979;&#38598;&#36827;&#34892;&#25237;&#31080;&#65292;&#20854;&#20013;&#26681;&#25454;&#36807;&#21435;&#34920;&#29616;&#35843;&#25972;&#27169;&#22411;&#19978;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15527v1 Announce Type: cross  Abstract: Conformal prediction equips machine learning models with a reasonable notion of uncertainty quantification without making strong distributional assumptions. It wraps around any black-box prediction model and converts point predictions into set predictions that have a predefined marginal coverage guarantee. However, conformal prediction only works if we fix the underlying machine learning model in advance. A relatively unaddressed issue in conformal prediction is that of model selection and/or aggregation: for a given problem, which of the plethora of prediction methods (random forests, neural nets, regularized linear models, etc.) should we conformalize? This paper proposes a new approach towards conformal model aggregation in online settings that is based on combining the prediction sets from several algorithms by voting, where weights on the models are adapted over time based on past performance.
&lt;/p&gt;</description></item><item><title>&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;</title><link>https://arxiv.org/abs/2403.13748</link><description>&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#20013;&#22240;&#23376;&#21270;&#39640;&#26031;&#36817;&#20284;&#30340;&#24046;&#24322;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13748
&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#20013;&#65292;&#32473;&#23450;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#20998;&#24067;$p$&#65292;&#38382;&#39064;&#26159;&#20174;&#19968;&#20123;&#26356;&#26131;&#22788;&#29702;&#30340;&#26063;$\mathcal{Q}$&#20013;&#35745;&#31639;&#26368;&#20339;&#36817;&#20284;$q$&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#36817;&#20284;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;Kullback-Leibler (KL)&#25955;&#24230;&#26469;&#25214;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23384;&#22312;&#20854;&#20182;&#26377;&#25928;&#30340;&#25955;&#24230;&#36873;&#25321;&#65292;&#24403;$\mathcal{Q}$&#19981;&#21253;&#21547;$p$&#26102;&#65292;&#27599;&#20010;&#25955;&#24230;&#37117;&#25903;&#25345;&#19981;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#39640;&#26031;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#34987;&#23545;&#35282;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#36817;&#20284;&#25152;&#24433;&#21709;&#30340;VI&#32467;&#26524;&#20013;&#65292;&#25955;&#24230;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;VI&#32467;&#26524;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#30340;&#25955;&#24230;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#22914;&#26041;&#24046;&#12289;&#31934;&#24230;&#21644;&#29109;&#65292;&#36827;&#34892;\textit{&#25490;&#24207;}&#12290;&#25105;&#20204;&#36824;&#24471;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#23450;&#29702;&#65292;&#34920;&#26126;&#26080;&#27861;&#36890;&#36807;&#22240;&#23376;&#21270;&#36817;&#20284;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;&#65307;&#22240;&#27492;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13748v1 Announce Type: cross  Abstract: Given an intractable distribution $p$, the problem of variational inference (VI) is to compute the best approximation $q$ from some more tractable family $\mathcal{Q}$. Most commonly the approximation is found by minimizing a Kullback-Leibler (KL) divergence. However, there exist other valid choices of divergences, and when $\mathcal{Q}$ does not contain~$p$, each divergence champions a different solution. We analyze how the choice of divergence affects the outcome of VI when a Gaussian with a dense covariance matrix is approximated by a Gaussian with a diagonal covariance matrix. In this setting we show that different divergences can be \textit{ordered} by the amount that their variational approximations misestimate various measures of uncertainty, such as the variance, precision, and entropy. We also derive an impossibility theorem showing that no two of these measures can be simultaneously matched by a factorized approximation; henc
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#22312;&#25968;&#25454;&#27969;&#24418;&#20869;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#22312;&#30446;&#26631;&#20989;&#25968;&#23450;&#20041;&#30340;Boltzmann&#20998;&#24067;&#21644;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#20056;&#31215;&#19978;&#36827;&#34892;&#25277;&#26679;&#26469;&#35299;&#20915;&#20855;&#26377;&#26410;&#30693;&#32422;&#26463;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.18012</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#20855;&#26377;&#26410;&#30693;&#32422;&#26463;&#30340;&#20248;&#21270;&#32422;&#26463;&#25277;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18012
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#22312;&#25968;&#25454;&#27969;&#24418;&#20869;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#22312;&#30446;&#26631;&#20989;&#25968;&#23450;&#20041;&#30340;Boltzmann&#20998;&#24067;&#21644;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#20056;&#31215;&#19978;&#36827;&#34892;&#25277;&#26679;&#26469;&#35299;&#20915;&#20855;&#26377;&#26410;&#30693;&#32422;&#26463;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22788;&#29702;&#29616;&#23454;&#19990;&#30028;&#30340;&#20248;&#21270;&#38382;&#39064;&#22312;&#20998;&#26512;&#23458;&#35266;&#20989;&#25968;&#25110;&#32422;&#26463;&#19981;&#21487;&#29992;&#26102;&#21464;&#24471;&#23588;&#20026;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#35768;&#22810;&#30740;&#31350;&#24050;&#32463;&#35299;&#20915;&#20102;&#26410;&#30693;&#30446;&#26631;&#30340;&#38382;&#39064;&#65292;&#20294;&#26377;&#38480;&#30740;&#31350;&#20851;&#27880;&#20102;&#32422;&#26463;&#26465;&#20214;&#26410;&#26126;&#30830;&#32473;&#20986;&#30340;&#24773;&#20917;&#12290;&#24573;&#30053;&#36825;&#20123;&#32422;&#26463;&#21487;&#33021;&#23548;&#33268;&#22312;&#23454;&#36341;&#20013;&#19981;&#29616;&#23454;&#30340;&#34394;&#20551;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#31181;&#26410;&#30693;&#32422;&#26463;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#22312;&#25968;&#25454;&#27969;&#24418;&#20869;&#36827;&#34892;&#20248;&#21270;&#12290;&#20026;&#20102;&#23558;&#20248;&#21270;&#36807;&#31243;&#38480;&#21046;&#22312;&#25968;&#25454;&#27969;&#24418;&#20869;&#65292;&#25105;&#20204;&#23558;&#21407;&#22987;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#26500;&#36896;&#20026;&#36890;&#36807;&#23458;&#35266;&#20989;&#25968;&#23450;&#20041;&#30340;Boltzmann&#20998;&#24067;&#21644;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#20056;&#31215;&#30340;&#25277;&#26679;&#38382;&#39064;&#12290;&#20026;&#20102;&#22686;&#24378;&#25277;&#26679;&#25928;&#29575;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#26694;&#26550;&#65292;&#20197;&#24341;&#23548;&#25193;&#25955;&#36807;&#31243;&#36827;&#34892;&#39044;&#28909;&#65292;&#28982;&#21518;&#26159;Langevin&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18012v1 Announce Type: cross  Abstract: Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. To enhance sampling efficiency, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dyna
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#36793;&#32536;&#35745;&#31639;&#36801;&#31227;&#30340;&#25925;&#38556;&#33258;&#36866;&#24212;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550; FIRE&#65292;&#24341;&#20837;ImRE&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36793;&#32536;&#35745;&#31639;&#25968;&#23383;&#23402;&#29983;&#29615;&#22659;&#20013;&#35757;&#32451;RL&#31574;&#30053;&#26469;&#36866;&#24212;&#32597;&#35265;&#20107;&#20214;&#65292;&#35299;&#20915;&#20102;RL&#26694;&#26550;&#22312;&#22788;&#29702;&#20598;&#21457;&#26381;&#21153;&#22120;&#25925;&#38556;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2209.14399</link><description>&lt;p&gt;
FIRE&#65306;&#38754;&#21521;&#36793;&#32536;&#35745;&#31639;&#36801;&#31227;&#30340;&#25925;&#38556;&#33258;&#36866;&#24212;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
FIRE: A Failure-Adaptive Reinforcement Learning Framework for Edge Computing Migrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.14399
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#36793;&#32536;&#35745;&#31639;&#36801;&#31227;&#30340;&#25925;&#38556;&#33258;&#36866;&#24212;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550; FIRE&#65292;&#24341;&#20837;ImRE&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36793;&#32536;&#35745;&#31639;&#25968;&#23383;&#23402;&#29983;&#29615;&#22659;&#20013;&#35757;&#32451;RL&#31574;&#30053;&#26469;&#36866;&#24212;&#32597;&#35265;&#20107;&#20214;&#65292;&#35299;&#20915;&#20102;RL&#26694;&#26550;&#22312;&#22788;&#29702;&#20598;&#21457;&#26381;&#21153;&#22120;&#25925;&#38556;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36793;&#32536;&#35745;&#31639;&#20013;&#65292;&#29992;&#25143;&#26381;&#21153;&#37197;&#32622;&#25991;&#20214;&#30001;&#20110;&#29992;&#25143;&#31227;&#21160;&#32780;&#36827;&#34892;&#36801;&#31227;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26694;&#26550;&#26469;&#36827;&#34892;&#36801;&#31227;&#65292;&#36890;&#24120;&#26159;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;RL&#26694;&#26550;&#24573;&#35270;&#20102;&#20598;&#21457;&#30340;&#26381;&#21153;&#22120;&#25925;&#38556;&#65292;&#23613;&#31649;&#32597;&#35265;&#65292;&#20294;&#20250;&#24433;&#21709;&#21040;&#20687;&#33258;&#21160;&#39550;&#39542;&#21644;&#23454;&#26102;&#38556;&#30861;&#26816;&#27979;&#31561;&#23545;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#65288;&#32597;&#35265;&#20107;&#20214;&#65289;&#25925;&#38556;&#34429;&#28982;&#22312;&#21382;&#21490;&#35757;&#32451;&#25968;&#25454;&#20013;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#20195;&#34920;&#65292;&#21364;&#23545;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;RL&#31639;&#27861;&#26500;&#25104;&#25361;&#25112;&#12290;&#30001;&#20110;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#35843;&#25972;&#25925;&#38556;&#39057;&#29575;&#36827;&#34892;&#35757;&#32451;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;FIRE&#65292;&#36825;&#26159;&#19968;&#20010;&#36890;&#36807;&#22312;&#36793;&#32536;&#35745;&#31639;&#25968;&#23383;&#23402;&#29983;&#29615;&#22659;&#20013;&#35757;&#32451;RL&#31574;&#30053;&#26469;&#36866;&#24212;&#32597;&#35265;&#20107;&#20214;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ImRE&#65292;&#19968;&#31181;&#22522;&#20110;&#37325;&#35201;&#24615;&#25277;&#26679;&#30340;Q-learning&#31639;&#27861;&#65292;&#23427;&#26681;&#25454;&#32597;&#35265;&#20107;&#20214;&#23545;&#20540;&#20989;&#25968;&#30340;&#24433;&#21709;&#36827;&#34892;&#27604;&#20363;&#25277;&#26679;&#12290;FIRE&#32771;&#34385;&#20102;&#24310;&#36831;&#12289;&#36801;&#31227;&#12289;&#25925;&#38556;&#21644;&#22791;&#20221;pl
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.14399v2 Announce Type: replace-cross  Abstract: In edge computing, users' service profiles are migrated due to user mobility. Reinforcement learning (RL) frameworks have been proposed to do so, often trained on simulated data. However, existing RL frameworks overlook occasional server failures, which although rare, impact latency-sensitive applications like autonomous driving and real-time obstacle detection. Nevertheless, these failures (rare events), being not adequately represented in historical training data, pose a challenge for data-driven RL algorithms. As it is impractical to adjust failure frequency in real-world applications for training, we introduce FIRE, a framework that adapts to rare events by training a RL policy in an edge computing digital twin environment. We propose ImRE, an importance sampling-based Q-learning algorithm, which samples rare events proportionally to their impact on the value function. FIRE considers delay, migration, failure, and backup pl
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#20020;&#24202;&#21644;RT-PCR&#25968;&#25454;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#26469;&#39044;&#27979;COVID-19&#24739;&#32773;&#24247;&#22797;&#25110;&#27515;&#20129;&#39118;&#38505;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.13925</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#20915;&#31574;&#26862;&#26519;&#65306;&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;COVID-19&#24739;&#32773;&#24247;&#22797;&#25110;&#27515;&#20129;&#30340;&#26032;&#26041;&#27861;&#65292;&#32467;&#21512;&#20020;&#24202;&#21644;RT-PCR&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Decision Forest: A Novel Approach for Predicting Recovery or Decease of COVID-19 Patients with Clinical and RT-PCR. (arXiv:2311.13925v2 [eess.IV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.13925
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#20020;&#24202;&#21644;RT-PCR&#25968;&#25454;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#26469;&#39044;&#27979;COVID-19&#24739;&#32773;&#24247;&#22797;&#25110;&#27515;&#20129;&#39118;&#38505;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#19990;&#30028;&#21355;&#29983;&#32452;&#32455;&#23459;&#24067;&#22823;&#27969;&#34892;&#24050;&#32463;&#32467;&#26463;&#65292;&#20294;COVID-19&#20173;&#28982;&#34987;&#35270;&#20026;&#19968;&#31181;&#22320;&#26041;&#24615;&#30142;&#30149;&#12290;&#36825;&#27425;&#22823;&#27969;&#34892;&#20197;&#21069;&#25152;&#26410;&#26377;&#30340;&#26041;&#24335;&#25171;&#20081;&#20102;&#20154;&#20204;&#30340;&#29983;&#27963;&#24182;&#23548;&#33268;&#24191;&#27867;&#30340;&#21457;&#30149;&#29575;&#21644;&#27515;&#20129;&#29575;&#12290;&#22240;&#27492;&#65292;&#32039;&#24613;&#21307;&#29983;&#26377;&#24517;&#35201;&#30830;&#23450;&#39640;&#39118;&#38505;&#27515;&#20129;&#24739;&#32773;&#65292;&#20197;&#20415;&#20248;&#20808;&#32771;&#34385;&#21307;&#38498;&#35774;&#22791;&#30340;&#20998;&#37197;&#65292;&#23588;&#20854;&#26159;&#22312;&#21307;&#30103;&#36164;&#28304;&#26377;&#38480;&#30340;&#22320;&#21306;&#12290;&#23613;&#31649;&#23384;&#22312;&#21738;&#31181;&#25968;&#25454;&#26368;&#20934;&#30830;&#30340;&#39044;&#27979;&#30340;&#38382;&#39064;&#65292;&#20294;&#24739;&#32773;&#25910;&#38598;&#21040;&#30340;&#25968;&#25454;&#23545;&#20110;&#39044;&#27979;COVID-19&#30149;&#20363;&#30340;&#32467;&#26524;&#26159;&#26377;&#30410;&#30340;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#26088;&#22312;&#23454;&#29616;&#20004;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24819;&#35201;&#26816;&#26597;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#26159;&#21542;&#33021;&#22815;&#39044;&#27979;&#24739;&#32773;&#30340;&#27515;&#20129;&#29575;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20020;&#24202;&#21644;RT-PCR&#23545;&#39044;&#27979;&#30340;&#24433;&#21709;&#65292;&#20197;&#30830;&#23450;&#21738;&#20010;&#26356;&#21487;&#38752;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#22235;&#20010;&#19981;&#21516;&#29305;&#24449;&#38598;&#30340;&#38454;&#27573;&#65292;&#24182;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26500;&#24314;&#20102;&#30456;&#24212;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
COVID-19 continues to be considered an endemic disease in spite of the World Health Organization's declaration that the pandemic is over. This pandemic has disrupted people's lives in unprecedented ways and caused widespread morbidity and mortality. As a result, it is important for emergency physicians to identify patients with a higher mortality risk in order to prioritize hospital equipment, especially in areas with limited medical services. The collected data from patients is beneficial to predict the outcome of COVID-19 cases, although there is a question about which data makes the most accurate predictions. Therefore, this study aims to accomplish two main objectives. First, we want to examine whether deep learning algorithms can predict a patient's morality. Second, we investigated the impact of Clinical and RT-PCR on prediction to determine which one is more reliable. We defined four stages with different feature sets and used interpretable deep learning methods to build appropr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#21033;&#29992;&#22825;&#32447;&#21709;&#24212;&#19968;&#33268;&#24615;&#65288;ARC&#65289;&#26469;&#23450;&#20041;&#36866;&#24403;&#30340;&#23545;&#20934;&#26631;&#20934;&#65292;&#20197;&#35299;&#20915;&#22312;WiFi&#20154;&#20307;&#27963;&#21160;&#35782;&#21035;&#20013;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#22312;CSI&#25968;&#25454;&#19978;&#26080;&#27861;&#36798;&#21040;&#39044;&#26399;&#24615;&#33021;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.06328</link><description>&lt;p&gt;
&#21033;&#29992;&#22825;&#32447;&#21709;&#24212;&#19968;&#33268;&#24615;&#23450;&#20041;CSI&#25968;&#25454;&#30340;&#23545;&#20934;&#26631;&#20934;
&lt;/p&gt;
&lt;p&gt;
Exploit the antenna response consistency to define the alignment criteria for CSI data. (arXiv:2310.06328v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06328
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#21033;&#29992;&#22825;&#32447;&#21709;&#24212;&#19968;&#33268;&#24615;&#65288;ARC&#65289;&#26469;&#23450;&#20041;&#36866;&#24403;&#30340;&#23545;&#20934;&#26631;&#20934;&#65292;&#20197;&#35299;&#20915;&#22312;WiFi&#20154;&#20307;&#27963;&#21160;&#35782;&#21035;&#20013;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#22312;CSI&#25968;&#25454;&#19978;&#26080;&#27861;&#36798;&#21040;&#39044;&#26399;&#24615;&#33021;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#29992;&#20110;&#22522;&#20110;WiFi&#30340;&#20154;&#20307;&#27963;&#21160;&#35782;&#21035;&#65288;HAR&#65289;&#30001;&#20110;&#33021;&#22815;&#35299;&#20915;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#30340;&#25361;&#25112;&#32780;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#23558;&#21407;&#26412;&#35774;&#35745;&#29992;&#20110;&#20854;&#20182;&#39046;&#22495;&#30340;SSL&#31639;&#27861;&#65292;&#29305;&#21035;&#26159;&#23545;&#27604;&#23398;&#20064;&#65292;&#31227;&#26893;&#21040;CSI&#25968;&#25454;&#19978;&#24448;&#24448;&#26080;&#27861;&#36798;&#21040;&#39044;&#26399;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#24402;&#22240;&#20110;&#23545;&#20934;&#26631;&#20934;&#19981;&#24403;&#65292;&#36825;&#30772;&#22351;&#20102;&#29305;&#24449;&#31354;&#38388;&#21644;&#36755;&#20837;&#31354;&#38388;&#20043;&#38388;&#30340;&#35821;&#20041;&#36317;&#31163;&#19968;&#33268;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;``Anetenna Response Consistency (ARC)''&#20316;&#20026;&#23450;&#20041;&#21512;&#36866;&#23545;&#20934;&#26631;&#20934;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;ARC&#30340;&#35774;&#35745;&#22312;&#20445;&#30041;&#36755;&#20837;&#31354;&#38388;&#30340;&#35821;&#20041;&#20449;&#24687;&#30340;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#23545;&#29616;&#23454;&#19990;&#30028;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#20174;CSI&#25968;&#25454;&#32467;&#26500;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;ARC&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#26368;&#20248;&#35299;&#23548;&#33268;&#20102;&#20174;&#36755;&#20837;CSI&#25968;&#25454;&#21040;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#21160;&#20316;&#21521;&#37327;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) for WiFi-based human activity recognition (HAR) holds great promise due to its ability to address the challenge of insufficient labeled data. However, directly transplanting SSL algorithms, especially contrastive learning, originally designed for other domains to CSI data, often fails to achieve the expected performance. We attribute this issue to the inappropriate alignment criteria, which disrupt the semantic distance consistency between the feature space and the input space. To address this challenge, we introduce \textbf{A}netenna \textbf{R}esponse \textbf{C}onsistency (ARC) as a solution to define proper alignment criteria. ARC is designed to retain semantic information from the input space while introducing robustness to real-world noise. We analyze ARC from the perspective of CSI data structure, demonstrating that its optimal solution leads to a direct mapping from input CSI data to action vectors in the feature map. Furthermore, we provide extensi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#35760;&#24518;&#30340;&#21078;&#26512;&#65292;&#25581;&#31034;&#20102;&#23574;&#38160;&#24847;&#35782;&#26368;&#23567;&#21270;&#31639;&#27861;&#22312;&#38750;&#20856;&#22411;&#25968;&#25454;&#28857;&#19978;&#23454;&#29616;&#30340;&#27867;&#21270;&#25910;&#30410;&#12290;&#21516;&#26102;&#65292;&#20063;&#21457;&#29616;&#20102;&#19982;&#27492;&#31639;&#27861;&#30456;&#20851;&#30340;&#26356;&#39640;&#38544;&#31169;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#32531;&#35299;&#31574;&#30053;&#65292;&#20197;&#36798;&#21040;&#26356;&#29702;&#24819;&#30340;&#20934;&#30830;&#24230;&#19982;&#38544;&#31169;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2310.00488</link><description>&lt;p&gt;
&#20851;&#20110;&#23574;&#38160;&#24847;&#35782;&#26368;&#23567;&#21270;&#30340;&#35760;&#24518;&#21644;&#38544;&#31169;&#39118;&#38505;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Memorization and Privacy Risks of Sharpness Aware Minimization. (arXiv:2310.00488v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#35760;&#24518;&#30340;&#21078;&#26512;&#65292;&#25581;&#31034;&#20102;&#23574;&#38160;&#24847;&#35782;&#26368;&#23567;&#21270;&#31639;&#27861;&#22312;&#38750;&#20856;&#22411;&#25968;&#25454;&#28857;&#19978;&#23454;&#29616;&#30340;&#27867;&#21270;&#25910;&#30410;&#12290;&#21516;&#26102;&#65292;&#20063;&#21457;&#29616;&#20102;&#19982;&#27492;&#31639;&#27861;&#30456;&#20851;&#30340;&#26356;&#39640;&#38544;&#31169;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#32531;&#35299;&#31574;&#30053;&#65292;&#20197;&#36798;&#21040;&#26356;&#29702;&#24819;&#30340;&#20934;&#30830;&#24230;&#19982;&#38544;&#31169;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#35774;&#35745;&#23547;&#27714;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#20248;&#21270;&#20013;&#26356;&#24179;&#22374;&#30340;&#26497;&#20540;&#30340;&#31639;&#27861;&#25104;&#20026;&#28966;&#28857;&#65292;&#22240;&#20026;&#26377;&#32463;&#39564;&#35777;&#25454;&#34920;&#26126;&#36825;&#20250;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#19978;&#23548;&#33268;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#35760;&#24518;&#35270;&#35282;&#26469;&#21078;&#26512;&#36825;&#20123;&#24615;&#33021;&#25910;&#30410;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#24110;&#21161;&#25105;&#20204;&#30830;&#23450;&#30456;&#23545;&#20110;&#26222;&#36890;SGD&#65292;&#23547;&#27714;&#26356;&#24179;&#22374;&#26497;&#20540;&#30340;&#31639;&#27861;&#22312;&#21738;&#20123;&#25968;&#25454;&#28857;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23574;&#38160;&#24847;&#35782;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#25152;&#23454;&#29616;&#30340;&#27867;&#21270;&#25910;&#30410;&#22312;&#38750;&#20856;&#22411;&#25968;&#25454;&#28857;&#19978;&#29305;&#21035;&#26174;&#33879;&#65292;&#36825;&#38656;&#35201;&#35760;&#24518;&#12290;&#36825;&#19968;&#35748;&#35782;&#24110;&#21161;&#25105;&#20204;&#25581;&#31034;&#19982;SAM&#30456;&#20851;&#30340;&#26356;&#39640;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#24182;&#36890;&#36807;&#35814;&#23613;&#30340;&#23454;&#35777;&#35780;&#20272;&#36827;&#34892;&#39564;&#35777;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#32531;&#35299;&#31574;&#30053;&#65292;&#20197;&#23454;&#29616;&#26356;&#29702;&#24819;&#30340;&#20934;&#30830;&#24230;&#19982;&#38544;&#31169;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many recent works, there is an increased focus on designing algorithms that seek flatter optima for neural network loss optimization as there is empirical evidence that it leads to better generalization performance in many datasets. In this work, we dissect these performance gains through the lens of data memorization in overparameterized models. We define a new metric that helps us identify which data points specifically do algorithms seeking flatter optima do better when compared to vanilla SGD. We find that the generalization gains achieved by Sharpness Aware Minimization (SAM) are particularly pronounced for atypical data points, which necessitate memorization. This insight helps us unearth higher privacy risks associated with SAM, which we verify through exhaustive empirical evaluations. Finally, we propose mitigation strategies to achieve a more desirable accuracy vs privacy tradeoff.
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#30340;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#23427;&#25552;&#20379;&#20102;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#26159;&#21487;&#34892;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.01449</link><description>&lt;p&gt;
&#23558;&#23454;&#39564;&#25968;&#25454;&#19982;&#35266;&#27979;&#25968;&#25454;&#32467;&#21512;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Double Machine Learning Approach to Combining Experimental and Observational Data. (arXiv:2307.01449v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01449
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#30340;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#23427;&#25552;&#20379;&#20102;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#36890;&#24120;&#30001;&#20110;&#26080;&#27861;&#27979;&#35797;&#30340;&#20551;&#35774;&#32780;&#32570;&#20047;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23558;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#32467;&#21512;&#36215;&#26469;&#65292;&#20351;&#20174;&#19994;&#20154;&#21592;&#33021;&#22815;&#27979;&#35797;&#20551;&#35774;&#36829;&#21453;&#24773;&#20917;&#24182;&#19968;&#33268;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#36739;&#36731;&#30340;&#20551;&#35774;&#19979;&#27979;&#35797;&#22806;&#37096;&#25928;&#24230;&#21644;&#21487;&#24573;&#35270;&#24615;&#30340;&#36829;&#21453;&#24773;&#20917;&#12290;&#24403;&#21482;&#26377;&#19968;&#20010;&#20551;&#35774;&#34987;&#36829;&#21453;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#21322;&#21442;&#25968;&#39640;&#25928;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#24378;&#35843;&#20102;&#20934;&#30830;&#35782;&#21035;&#36829;&#21453;&#30340;&#20551;&#35774;&#23545;&#19968;&#33268;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#30340;&#24517;&#35201;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#19977;&#20010;&#23454;&#38469;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#20854;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Experimental and observational studies often lack validity due to untestable assumptions. We propose a double machine learning approach to combine experimental and observational studies, allowing practitioners to test for assumption violations and estimate treatment effects consistently. Our framework tests for violations of external validity and ignorability under milder assumptions. When only one assumption is violated, we provide semi-parametrically efficient treatment effect estimators. However, our no-free-lunch theorem highlights the necessity of accurately identifying the violated assumption for consistent treatment effect estimation. We demonstrate the applicability of our approach in three real-world case studies, highlighting its relevance for practical settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#22522;&#20110;GNN&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#20248;&#21270;&#26381;&#21153;&#36136;&#37327;&#65292;&#35299;&#20915;ONTS&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.13773</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65306;&#23398;&#20064;&#28151;&#21512;&#25972;&#25968;&#27169;&#22411;&#30340;&#27934;&#35265;
&lt;/p&gt;
&lt;p&gt;
A Graph Neural Network Approach to Nanosatellite Task Scheduling: Insights into Learning Mixed-Integer Models. (arXiv:2303.13773v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13773
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#22522;&#20110;GNN&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#20248;&#21270;&#26381;&#21153;&#36136;&#37327;&#65292;&#35299;&#20915;ONTS&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#22914;&#20309;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26356;&#26377;&#25928;&#22320;&#35843;&#24230;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#12290;&#22312;&#31163;&#32447;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#65288;ONTS&#65289;&#38382;&#39064;&#20013;&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#22312;&#36712;&#36947;&#19978;&#25191;&#34892;&#20219;&#21153;&#30340;&#26368;&#20339;&#23433;&#25490;&#65292;&#21516;&#26102;&#32771;&#34385;&#26381;&#21153;&#36136;&#37327;&#65288;QoS&#65289;&#26041;&#38754;&#30340;&#32771;&#34385;&#22240;&#32032;&#65292;&#22914;&#20248;&#20808;&#32423;&#65292;&#26368;&#23567;&#21644;&#26368;&#22823;&#28608;&#27963;&#20107;&#20214;&#65292;&#25191;&#34892;&#26102;&#38388;&#26694;&#26550;&#65292;&#21608;&#26399;&#21644;&#25191;&#34892;&#31383;&#21475;&#65292;&#20197;&#21450;&#21355;&#26143;&#30005;&#21147;&#36164;&#28304;&#21644;&#33021;&#37327;&#25910;&#38598;&#21644;&#31649;&#29702;&#30340;&#22797;&#26434;&#24615;&#30340;&#32422;&#26463;&#12290;ONTS&#38382;&#39064;&#24050;&#32463;&#20351;&#29992;&#20256;&#32479;&#30340;&#25968;&#23398;&#20844;&#24335;&#21644;&#31934;&#30830;&#26041;&#27861;&#36827;&#34892;&#20102;&#22788;&#29702;&#65292;&#20294;&#26159;&#23427;&#20204;&#22312;&#38382;&#39064;&#30340;&#25361;&#25112;&#24615;&#26696;&#20363;&#20013;&#30340;&#36866;&#29992;&#24615;&#26377;&#38480;&#12290;&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;GNN&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#24050;&#32463;&#25104;&#21151;&#24212;&#29992;&#20110;&#35768;&#22810;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#26053;&#34892;&#21830;&#38382;&#39064;&#65292;&#35843;&#24230;&#38382;&#39064;&#21644;&#35774;&#26045;&#25918;&#32622;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;ONTS&#38382;&#39064;&#30340;MILP&#23454;&#20363;&#23436;&#20840;&#34920;&#31034;&#25104;&#20108;&#20998;&#22270;&#32593;&#32476;&#32467;&#26500;&#26469;&#24212;&#29992;GNN&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates how to schedule nanosatellite tasks more efficiently using Graph Neural Networks (GNN). In the Offline Nanosatellite Task Scheduling (ONTS) problem, the goal is to find the optimal schedule for tasks to be carried out in orbit while taking into account Quality-of-Service (QoS) considerations such as priority, minimum and maximum activation events, execution time-frames, periods, and execution windows, as well as constraints on the satellite's power resources and the complexity of energy harvesting and management. The ONTS problem has been approached using conventional mathematical formulations and precise methods, but their applicability to challenging cases of the problem is limited. This study examines the use of GNNs in this context, which has been effectively applied to many optimization problems, including traveling salesman problems, scheduling problems, and facility placement problems. Here, we fully represent MILP instances of the ONTS problem in biparti
&lt;/p&gt;</description></item><item><title>HUMAP&#26159;&#19968;&#31181;&#26032;&#30340;&#23618;&#27425;&#38477;&#32500;&#25216;&#26415;&#65292;&#33021;&#22815;&#22312;&#23618;&#27425;&#25506;&#32034;&#20013;&#20445;&#30041;&#24515;&#29702;&#22320;&#22270;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#25968;&#25454;&#31867;&#22411;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2106.07718</link><description>&lt;p&gt;
HUMAP&#65306;&#23618;&#27425;&#32479;&#19968;&#27969;&#24418;&#36924;&#36817;&#19982;&#25237;&#24433;
&lt;/p&gt;
&lt;p&gt;
HUMAP: Hierarchical Uniform Manifold Approximation and Projection. (arXiv:2106.07718v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.07718
&lt;/p&gt;
&lt;p&gt;
HUMAP&#26159;&#19968;&#31181;&#26032;&#30340;&#23618;&#27425;&#38477;&#32500;&#25216;&#26415;&#65292;&#33021;&#22815;&#22312;&#23618;&#27425;&#25506;&#32034;&#20013;&#20445;&#30041;&#24515;&#29702;&#22320;&#22270;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#25968;&#25454;&#31867;&#22411;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#38477;&#32500;&#25216;&#26415;&#26377;&#21161;&#20110;&#20998;&#26512;&#20154;&#21592;&#29702;&#35299;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#27169;&#24335;&#12290;&#36825;&#20123;&#25216;&#26415;&#36890;&#24120;&#20197;&#25955;&#28857;&#22270;&#24418;&#24335;&#21576;&#29616;&#65292;&#24212;&#29992;&#20110;&#21508;&#31181;&#31185;&#23398;&#39046;&#22495;&#65292;&#24182;&#20419;&#36827;&#38598;&#32676;&#21644;&#25968;&#25454;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#20998;&#26512;&#12290;&#38024;&#23545;&#21253;&#21547;&#35768;&#22810;&#31890;&#24230;&#25110;&#36981;&#24490;&#20449;&#24687;&#21487;&#35270;&#21270;&#20934;&#21017;&#30340;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#65292;&#23618;&#27425;&#38477;&#32500;&#25216;&#26415;&#26159;&#26368;&#36866;&#21512;&#30340;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#20204;&#20808;&#21069;&#21576;&#29616;&#20102;&#20027;&#35201;&#32467;&#26500;&#24182;&#21487;&#20197;&#25353;&#38656;&#25552;&#20379;&#35814;&#32454;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#23618;&#27425;&#38477;&#32500;&#25216;&#26415;&#24182;&#19981;&#33021;&#23436;&#20840;&#35299;&#20915;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#33021;&#22312;&#23618;&#27425;&#32423;&#21035;&#20043;&#38388;&#20445;&#25345;&#25237;&#24433;&#24515;&#29702;&#22320;&#22270;&#65292;&#20063;&#19981;&#36866;&#29992;&#20110;&#22823;&#22810;&#25968;&#25968;&#25454;&#31867;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#23618;&#27425;&#38477;&#32500;&#25216;&#26415;HUMAP&#65292;&#26088;&#22312;&#28789;&#27963;&#22320;&#20445;&#30041;&#26412;&#22320;&#21644;&#20840;&#23616;&#32467;&#26500;&#20197;&#21450;&#24515;&#29702;&#22320;&#22270;&#65292;&#22312;&#23618;&#27425;&#25506;&#32034;&#20013;&#20855;&#26377;&#20248;&#36234;&#24615;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#25968;&#25454;&#31867;&#22411;&#19978;&#25552;&#20379;&#20102;&#23454;&#35777;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dimensionality reduction (DR) techniques help analysts understand patterns in high-dimensional spaces. These techniques, often represented by scatter plots, are employed in diverse science domains and facilitate similarity analysis among clusters and data samples. For datasets containing many granularities or when analysis follows the information visualization mantra, hierarchical DR techniques are the most suitable approach since they present major structures beforehand and details on demand. However, current hierarchical DR techniques are not fully capable of addressing literature problems because they do not preserve the projection mental map across hierarchical levels or are not suitable for most data types. This work presents HUMAP, a novel hierarchical dimensionality reduction technique designed to be flexible in preserving local and global structures and the mental map throughout hierarchical exploration. We provide empirical evidence of our technique's superiority compared with
&lt;/p&gt;</description></item></channel></rss>