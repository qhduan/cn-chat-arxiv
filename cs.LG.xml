<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23616;&#37096;&#34394;&#21457;&#29616;&#29575;&#25511;&#21046;&#30340;&#36164;&#28304;&#20998;&#37197;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;$O(\sqrt{T})$&#30340;&#21518;&#24724;&#29575;&#65292;&#24182;&#25351;&#20986;&#36825;&#31181;&#21518;&#24724;&#29575;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#25913;&#36827;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.11425</link><description>&lt;p&gt;
&#22312;&#32447;&#23616;&#37096;&#34394;&#21457;&#29616;&#29575;&#25511;&#21046;&#65306;&#19968;&#31181;&#36164;&#28304;&#20998;&#37197;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Local False Discovery Rate Control: A Resource Allocation Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11425
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23616;&#37096;&#34394;&#21457;&#29616;&#29575;&#25511;&#21046;&#30340;&#36164;&#28304;&#20998;&#37197;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;$O(\sqrt{T})$&#30340;&#21518;&#24724;&#29575;&#65292;&#24182;&#25351;&#20986;&#36825;&#31181;&#21518;&#24724;&#29575;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#25913;&#36827;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#23616;&#37096;&#34394;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#25511;&#21046;&#38382;&#39064;&#65292;&#20854;&#20013;&#22810;&#20010;&#27979;&#35797;&#34987;&#39034;&#24207;&#36827;&#34892;&#65292;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#24635;&#26399;&#26395;&#30340;&#21457;&#29616;&#27425;&#25968;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#19968;&#31181;&#22312;&#32447;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#65292;&#28041;&#21450;&#25509;&#21463;/&#25298;&#32477;&#20915;&#31574;&#65292;&#20174;&#39640;&#23618;&#27425;&#26469;&#30475;&#65292;&#36825;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#24102;&#26377;&#39069;&#22806;&#19981;&#30830;&#23450;&#24615;&#30340;&#22312;&#32447;&#32972;&#21253;&#38382;&#39064;&#65292;&#21363;&#38543;&#26426;&#39044;&#31639;&#34917;&#20805;&#12290;&#25105;&#20204;&#20174;&#19968;&#33324;&#30340;&#21040;&#36798;&#20998;&#24067;&#24320;&#22987;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;$O(\sqrt{T})$&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#36825;&#31181;&#21518;&#24724;&#29575;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#25913;&#36827;&#30340;&#26469;&#34917;&#20805;&#36825;&#19968;&#32467;&#26524;&#12290;&#28982;&#21518;&#25105;&#20204;&#23558;&#28966;&#28857;&#36716;&#21521;&#31163;&#25955;&#21040;&#36798;&#20998;&#24067;&#12290;&#25105;&#20204;&#21457;&#29616;&#35768;&#22810;&#29616;&#26377;&#30340;&#22312;&#32447;&#36164;&#28304;&#20998;&#37197;&#25991;&#29486;&#20013;&#30340;&#37325;&#26032;&#35299;&#20915;&#21551;&#21457;&#24335;&#34429;&#28982;&#22312;&#20856;&#22411;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#26377;&#30028;&#30340;&#25439;&#22833;&#65292;&#20294;&#21487;&#33021;&#20250;&#36896;&#25104;$\Omega(\sqrt{T})$&#29978;&#33267;$\Omega(T)$&#30340;&#21518;&#24724;&#12290;&#36890;&#36807;&#35266;&#23519;&#21040;&#20856;&#22411;&#31574;&#30053;&#24448;&#24448;&#22826;&#36807;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11425v1 Announce Type: cross  Abstract: We consider the problem of online local false discovery rate (FDR) control where multiple tests are conducted sequentially, with the goal of maximizing the total expected number of discoveries. We formulate the problem as an online resource allocation problem with accept/reject decisions, which from a high level can be viewed as an online knapsack problem, with the additional uncertainty of random budget replenishment. We start with general arrival distributions and propose a simple policy that achieves a $O(\sqrt{T})$ regret. We complement the result by showing that such regret rate is in general not improvable. We then shift our focus to discrete arrival distributions. We find that many existing re-solving heuristics in the online resource allocation literature, albeit achieve bounded loss in canonical settings, may incur a $\Omega(\sqrt{T})$ or even a $\Omega(T)$ regret. With the observation that canonical policies tend to be too op
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21442;&#25968;&#21270;&#36229;&#22797;&#25968;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#35270;&#22270;&#20083;&#33146;&#30284;&#20998;&#31867;&#26041;&#27861;&#65292;&#33021;&#22815;&#27169;&#25311;&#24182;&#21033;&#29992;&#20083;&#25151;X&#20809;&#26816;&#26597;&#30340;&#19981;&#21516;&#35270;&#22270;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#32959;&#30244;&#35782;&#21035;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2204.05798</link><description>&lt;p&gt;
&#22810;&#35270;&#22270;&#36229;&#22797;&#25968;&#23398;&#20064;&#29992;&#20110;&#20083;&#33146;&#30284;&#31579;&#26597;
&lt;/p&gt;
&lt;p&gt;
Multi-View Hypercomplex Learning for Breast Cancer Screening
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2204.05798
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21442;&#25968;&#21270;&#36229;&#22797;&#25968;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#35270;&#22270;&#20083;&#33146;&#30284;&#20998;&#31867;&#26041;&#27861;&#65292;&#33021;&#22815;&#27169;&#25311;&#24182;&#21033;&#29992;&#20083;&#25151;X&#20809;&#26816;&#26597;&#30340;&#19981;&#21516;&#35270;&#22270;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#32959;&#30244;&#35782;&#21035;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#29992;&#20110;&#20083;&#33146;&#30284;&#20998;&#31867;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#25191;&#34892;&#21333;&#35270;&#22270;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20083;&#33146;X-ray&#22270;&#20687;&#20013;&#21253;&#21547;&#30340;&#30456;&#20851;&#24615;&#65292;&#25918;&#23556;&#31185;&#21307;&#29983;&#21516;&#26102;&#20998;&#26512;&#32452;&#25104;&#20083;&#25151;X&#20809;&#25668;&#24433;&#26816;&#26597;&#30340;&#25152;&#26377;&#22235;&#20010;&#35270;&#22270;&#65292;&#36825;&#20026;&#35782;&#21035;&#32959;&#30244;&#25552;&#20379;&#20102;&#20851;&#38190;&#20449;&#24687;&#12290;&#37492;&#20110;&#27492;&#65292;&#19968;&#20123;&#30740;&#31350;&#24050;&#32463;&#24320;&#22987;&#25552;&#20986;&#22810;&#35270;&#22270;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#26679;&#30340;&#29616;&#26377;&#26550;&#26500;&#20013;&#65292;&#20083;&#25151;X&#20809;&#22270;&#20687;&#34987;&#29420;&#31435;&#30340;&#21367;&#31215;&#20998;&#25903;&#22788;&#29702;&#20026;&#29420;&#31435;&#30340;&#22270;&#20687;&#65292;&#20174;&#32780;&#22833;&#21435;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21442;&#25968;&#21270;&#36229;&#22797;&#25968;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#35270;&#22270;&#20083;&#33146;&#30284;&#20998;&#31867;&#26041;&#27861;&#12290;&#30001;&#20110;&#36229;&#22797;&#25968;&#20195;&#25968;&#29305;&#24615;&#65292;&#25105;&#20204;&#30340;&#32593;&#32476;&#33021;&#22815;&#24314;&#27169;&#24182;&#21033;&#29992;&#32452;&#25104;&#20083;&#25151;X&#20809;&#26816;&#26597;&#30340;&#19981;&#21516;&#35270;&#22270;&#20043;&#38388;&#30340;&#29616;&#26377;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#27169;&#25311;&#38405;&#29255;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2204.05798v3 Announce Type: replace-cross  Abstract: Traditionally, deep learning methods for breast cancer classification perform a single-view analysis. However, radiologists simultaneously analyze all four views that compose a mammography exam, owing to the correlations contained in mammography views, which present crucial information for identifying tumors. In light of this, some studies have started to propose multi-view methods. Nevertheless, in such existing architectures, mammogram views are processed as independent images by separate convolutional branches, thus losing correlations among them. To overcome such limitations, in this paper, we propose a methodological approach for multi-view breast cancer classification based on parameterized hypercomplex neural networks. Thanks to hypercomplex algebra properties, our networks are able to model, and thus leverage, existing correlations between the different views that comprise a mammogram, thus mimicking the reading process
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#39640;&#25928;&#35745;&#31639;&#35757;&#32451;&#38598;$\mathbf{X}^\mathbf{T}\mathbf{X}$&#21644;$\mathbf{X}^\mathbf{T}\mathbf{Y}$&#30340;&#31639;&#27861;&#65292;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#24037;&#20316;&#65292;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#26174;&#33879;&#21152;&#36895;&#20132;&#21449;&#39564;&#35777;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35745;&#31639;&#30697;&#38453;&#20056;&#31215;&#25110;&#32479;&#35745;&#37327;&#12290;</title><link>http://arxiv.org/abs/2401.13185</link><description>&lt;p&gt;
&#31616;&#21270;&#20132;&#21449;&#39564;&#35777;&#65306;&#39640;&#25928;&#22320;&#35745;&#31639;&#19981;&#38656;&#35201;&#20840;&#37327;&#37325;&#26032;&#35745;&#31639;&#30697;&#38453;&#20056;&#31215;&#25110;&#32479;&#35745;&#37327;&#30340;&#21015;&#21521;&#20013;&#24515;&#21270;&#21644;&#26631;&#20934;&#21270;&#35757;&#32451;&#38598;$\mathbf{X}^\mathbf{T}\mathbf{X}$&#21644;$\mathbf{X}^\mathbf{T}\mathbf{Y}$
&lt;/p&gt;
&lt;p&gt;
Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$ Without Full Recomputation of Matrix Products or Statistical Moments. (arXiv:2401.13185v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#39640;&#25928;&#35745;&#31639;&#35757;&#32451;&#38598;$\mathbf{X}^\mathbf{T}\mathbf{X}$&#21644;$\mathbf{X}^\mathbf{T}\mathbf{Y}$&#30340;&#31639;&#27861;&#65292;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#24037;&#20316;&#65292;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#26174;&#33879;&#21152;&#36895;&#20132;&#21449;&#39564;&#35777;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35745;&#31639;&#30697;&#38453;&#20056;&#31215;&#25110;&#32479;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#35780;&#20272;&#39044;&#27979;&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#34920;&#29616;&#30340;&#25216;&#26415;&#12290;&#35768;&#22810;&#39044;&#27979;&#27169;&#22411;&#65292;&#22914;&#22522;&#20110;&#26680;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#27169;&#22411;&#65292;&#38656;&#35201;&#20165;&#20351;&#29992;&#36755;&#20837;&#30697;&#38453;$\mathbf{X}$&#21644;&#36755;&#20986;&#30697;&#38453;$\mathbf{Y}$&#20013;&#30340;&#35757;&#32451;&#38598;&#26679;&#26412;&#26469;&#35745;&#31639;$\mathbf{X}^{\mathbf{T}}\mathbf{X}$&#21644;$\mathbf{X}^{\mathbf{T}}\mathbf{Y}$&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#39640;&#25928;&#35745;&#31639;&#36825;&#20123;&#30697;&#38453;&#30340;&#31639;&#27861;&#12290;&#31532;&#19968;&#31181;&#31639;&#27861;&#19981;&#38656;&#35201;&#21015;&#21521;&#39044;&#22788;&#29702;&#12290;&#31532;&#20108;&#31181;&#31639;&#27861;&#20801;&#35768;&#20197;&#35757;&#32451;&#38598;&#22343;&#20540;&#20026;&#20013;&#24515;&#21270;&#28857;&#36827;&#34892;&#21015;&#21521;&#20013;&#24515;&#21270;&#12290;&#31532;&#19977;&#31181;&#31639;&#27861;&#20801;&#35768;&#20197;&#35757;&#32451;&#38598;&#22343;&#20540;&#21644;&#26631;&#20934;&#24046;&#20026;&#20013;&#24515;&#21270;&#28857;&#21644;&#26631;&#20934;&#21270;&#28857;&#36827;&#34892;&#21015;&#21521;&#20013;&#24515;&#21270;&#21644;&#26631;&#20934;&#21270;&#12290;&#36890;&#36807;&#35777;&#26126;&#27491;&#30830;&#24615;&#21644;&#20248;&#36234;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#23427;&#20204;&#30456;&#27604;&#20110;&#30452;&#25509;&#20132;&#21449;&#39564;&#35777;&#21644;&#20197;&#21069;&#30340;&#24555;&#36895;&#20132;&#21449;&#39564;&#35777;&#24037;&#20316;&#65292;&#25552;&#20379;&#20102;&#26174;&#33879;&#30340;&#20132;&#21449;&#39564;&#35777;&#21152;&#36895;&#65292;&#32780;&#26080;&#38656;&#25968;&#25454;&#27844;&#38706;&#12290;&#23427;&#20204;&#36866;&#21512;&#24182;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-validation is a widely used technique for assessing the performance of predictive models on unseen data. Many predictive models, such as Kernel-Based Partial Least-Squares (PLS) models, require the computation of $\mathbf{X}^{\mathbf{T}}\mathbf{X}$ and $\mathbf{X}^{\mathbf{T}}\mathbf{Y}$ using only training set samples from the input and output matrices, $\mathbf{X}$ and $\mathbf{Y}$, respectively. In this work, we present three algorithms that efficiently compute these matrices. The first one allows no column-wise preprocessing. The second one allows column-wise centering around the training set means. The third one allows column-wise centering and column-wise scaling around the training set means and standard deviations. Demonstrating correctness and superior computational complexity, they offer significant cross-validation speedup compared with straight-forward cross-validation and previous work on fast cross-validation - all without data leakage. Their suitability for paralle
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27169;&#22359;&#21270;&#30340;&#19990;&#30028;&#27169;&#22411;&#65292;&#20943;&#23569;&#20102;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#35757;&#32451;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#25104;&#21151;&#39044;&#27979;&#20102;&#32852;&#21512;&#21160;&#20316;&#20215;&#20540;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.04615</link><description>&lt;p&gt;
&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#20998;&#35299;&#22312;&#22522;&#20110;&#20540;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Leveraging World Model Disentanglement in Value-Based Multi-Agent Reinforcement Learning. (arXiv:2309.04615v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04615
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27169;&#22359;&#21270;&#30340;&#19990;&#30028;&#27169;&#22411;&#65292;&#20943;&#23569;&#20102;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#35757;&#32451;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#25104;&#21151;&#39044;&#27979;&#20102;&#32852;&#21512;&#21160;&#20316;&#20215;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#21517;&#20026;Value Decomposition Framework with Disentangled World Model&#65292;&#26088;&#22312;&#35299;&#20915;&#22312;&#30456;&#21516;&#29615;&#22659;&#20013;&#22810;&#20010;&#26234;&#33021;&#20307;&#36798;&#25104;&#20849;&#21516;&#30446;&#26631;&#26102;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#30001;&#20110;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#38750;&#24179;&#31283;&#24615;&#38382;&#39064;&#65292;&#26080;&#27169;&#22411;&#26041;&#27861;&#20381;&#36182;&#20110;&#22823;&#37327;&#26679;&#26412;&#36827;&#34892;&#35757;&#32451;&#12290;&#30456;&#21453;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#27169;&#22359;&#21270;&#30340;&#19990;&#30028;&#27169;&#22411;&#65292;&#21253;&#25324;&#21160;&#20316;&#26465;&#20214;&#12289;&#26080;&#21160;&#20316;&#21644;&#38745;&#24577;&#20998;&#25903;&#65292;&#26469;&#35299;&#24320;&#29615;&#22659;&#21160;&#24577;&#24182;&#26681;&#25454;&#36807;&#21435;&#30340;&#32463;&#39564;&#20135;&#29983;&#24819;&#35937;&#20013;&#30340;&#32467;&#26524;&#65292;&#32780;&#19981;&#26159;&#30452;&#25509;&#20174;&#30495;&#23454;&#29615;&#22659;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#21464;&#20998;&#22270;&#33258;&#21160;&#32534;&#30721;&#22120;&#26469;&#23398;&#20064;&#19990;&#30028;&#27169;&#22411;&#30340;&#28508;&#22312;&#34920;&#31034;&#65292;&#23558;&#20854;&#19982;&#22522;&#20110;&#20540;&#30340;&#26694;&#26550;&#21512;&#24182;&#65292;&#20197;&#39044;&#27979;&#32852;&#21512;&#21160;&#20316;&#20215;&#20540;&#20989;&#25968;&#24182;&#20248;&#21270;&#25972;&#20307;&#35757;&#32451;&#30446;&#26631;&#12290;&#25105;&#20204;&#25552;&#20379;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel model-based multi-agent reinforcement learning approach named Value Decomposition Framework with Disentangled World Model to address the challenge of achieving a common goal of multiple agents interacting in the same environment with reduced sample complexity. Due to scalability and non-stationarity problems posed by multi-agent systems, model-free methods rely on a considerable number of samples for training. In contrast, we use a modularized world model, composed of action-conditioned, action-free, and static branches, to unravel the environment dynamics and produce imagined outcomes based on past experience, without sampling directly from the real environment. We employ variational auto-encoders and variational graph auto-encoders to learn the latent representations for the world model, which is merged with a value-based framework to predict the joint action-value function and optimize the overall training objective. We present experimental results 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#37197;&#23545;&#36317;&#31163;&#20272;&#35745;&#22120;&#23545;&#38598;&#25104;&#27169;&#22411;&#36827;&#34892;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26032;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#24120;&#29992;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26356;&#24555;&#36895;&#12289;&#26356;&#20934;&#30830;&#22320;&#22312;&#26356;&#22823;&#30340;&#31354;&#38388;&#21644;&#26356;&#39640;&#32500;&#24230;&#19978;&#20272;&#35745;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13498</link><description>&lt;p&gt;
&#36867;&#31163;&#26679;&#26412;&#38519;&#38449;&#65306;&#20351;&#29992;&#37197;&#23545;&#36317;&#31163;&#20272;&#35745;&#22120;&#24555;&#36895;&#20934;&#30830;&#22320;&#20272;&#35745;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Escaping the Sample Trap: Fast and Accurate Epistemic Uncertainty Estimation with Pairwise-Distance Estimators. (arXiv:2308.13498v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#37197;&#23545;&#36317;&#31163;&#20272;&#35745;&#22120;&#23545;&#38598;&#25104;&#27169;&#22411;&#36827;&#34892;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26032;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#24120;&#29992;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26356;&#24555;&#36895;&#12289;&#26356;&#20934;&#30830;&#22320;&#22312;&#26356;&#22823;&#30340;&#31354;&#38388;&#21644;&#26356;&#39640;&#32500;&#24230;&#19978;&#20272;&#35745;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#37197;&#23545;&#36317;&#31163;&#20272;&#35745;&#22120;&#65288;PaiDEs&#65289;&#23545;&#38598;&#25104;&#27169;&#22411;&#36827;&#34892;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#21033;&#29992;&#27169;&#22411;&#32452;&#20214;&#20043;&#38388;&#30340;&#37197;&#23545;&#36317;&#31163;&#26469;&#24314;&#31435;&#29109;&#30340;&#36793;&#30028;&#65292;&#24182;&#23558;&#36825;&#20123;&#36793;&#30028;&#20316;&#20026;&#22522;&#20110;&#20449;&#24687;&#20934;&#21017;&#30340;&#20272;&#35745;&#20540;&#12290;&#19982;&#26368;&#36817;&#22522;&#20110;&#26679;&#26412;&#30340;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#22120;&#29992;&#20110;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#19981;&#21516;&#65292;PaiDEs&#33021;&#22815;&#22312;&#26356;&#22823;&#30340;&#31354;&#38388;&#65288;&#26368;&#22810;100&#20493;&#65289;&#19978;&#20197;&#26356;&#24555;&#30340;&#36895;&#24230;&#65288;&#26368;&#22810;100&#20493;&#65289;&#20272;&#35745;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#22312;&#26356;&#39640;&#32500;&#24230;&#19978;&#20855;&#26377;&#26356;&#20934;&#30830;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#29992;&#20110;&#35780;&#20272;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#23454;&#39564;&#65306;&#19968;&#32500;&#27491;&#24358;&#25968;&#25454;&#65292;&#25670;&#21160;&#29289;&#20307;&#65288;Pendulum-v0&#65289;&#65292;&#36339;&#36291;&#26426;&#22120;&#20154;&#65288;Hopper-v2&#65289;&#65292;&#34434;&#34433;&#26426;&#22120;&#20154;&#65288;Ant-v2&#65289;&#21644;&#20154;&#24418;&#26426;&#22120;&#20154;&#65288;Humanoid-v2&#65289;&#12290;&#23545;&#20110;&#27599;&#20010;&#23454;&#39564;&#35774;&#32622;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#26469;&#23637;&#31034;PaiDEs&#22312;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces a novel approach for epistemic uncertainty estimation for ensemble models using pairwise-distance estimators (PaiDEs). These estimators utilize the pairwise-distance between model components to establish bounds on entropy and uses said bounds as estimates for information-based criterion. Unlike recent deep learning methods for epistemic uncertainty estimation, which rely on sample-based Monte Carlo estimators, PaiDEs are able to estimate epistemic uncertainty up to 100$\times$ faster, over a larger space (up to 100$\times$) and perform more accurately in higher dimensions. To validate our approach, we conducted a series of experiments commonly used to evaluate epistemic uncertainty estimation: 1D sinusoidal data, Pendulum-v0, Hopper-v2, Ant-v2 and Humanoid-v2. For each experimental setting, an Active Learning framework was applied to demonstrate the advantages of PaiDEs for epistemic uncertainty estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#25968;&#20540;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.13646</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#29992;&#20110;&#24102;&#21327;&#21464;&#20449;&#24687;&#30340;&#38543;&#26426;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information. (arXiv:2304.13646v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#25968;&#20540;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24102;&#21327;&#21464;&#20449;&#24687;&#30340;&#38543;&#26426;&#35268;&#21010;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;(PADR)&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#26041;&#27861;&#65292;&#26088;&#22312;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;PADR&#30340;ERM&#27169;&#22411;&#30340;&#38750;&#28176;&#36817;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#21487;&#29992;&#20110;&#26080;&#32422;&#26463;&#38382;&#39064;&#65292;&#20197;&#21450;&#32422;&#26463;&#38382;&#39064;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#38750;&#20984;&#21644;&#38750;&#21487;&#24494;&#30340;ERM&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22686;&#24378;&#30340;&#38543;&#26426;&#20027;&#23548;&#19979;&#38477;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#27839;&#65288;&#22797;&#21512;&#24378;&#65289;&#26041;&#21521;&#31283;&#23450;&#24615;&#30340;&#28176;&#36817;&#25910;&#25947;&#20197;&#21450;&#22797;&#26434;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;PADR-based ERM&#26041;&#27861;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#19968;&#33268;&#24615;&#20445;&#35777;&#21644;&#35745;&#31639;&#21487;&#22788;&#29702;&#24615;&#12290;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#65292;PADR-based ERM&#26041;&#27861;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Focusing on stochastic programming (SP) with covariate information, this paper proposes an empirical risk minimization (ERM) method embedded within a nonconvex piecewise affine decision rule (PADR), which aims to learn the direct mapping from features to optimal decisions. We establish the nonasymptotic consistency result of our PADR-based ERM model for unconstrained problems and asymptotic consistency result for constrained ones. To solve the nonconvex and nondifferentiable ERM problem, we develop an enhanced stochastic majorization-minimization algorithm and establish the asymptotic convergence to (composite strong) directional stationarity along with complexity analysis. We show that the proposed PADR-based ERM method applies to a broad class of nonconvex SP problems with theoretical consistency guarantees and computational tractability. Our numerical study demonstrates the superior performance of PADR-based ERM methods compared to state-of-the-art approaches under various settings,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2210.05102</link><description>&lt;p&gt;
&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Pre-Training Representations of Binary Code Using Contrastive Learning. (arXiv:2210.05102v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05102
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32534;&#35793;&#21518;&#30340;&#36719;&#20214;&#20197;&#21487;&#25191;&#34892;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#24418;&#24335;&#20132;&#20184;&#12290;&#24320;&#21457;&#20154;&#21592;&#32534;&#20889;&#28304;&#20195;&#30721;&#26469;&#34920;&#36798;&#36719;&#20214;&#30340;&#35821;&#20041;&#65292;&#20294;&#32534;&#35793;&#22120;&#23558;&#20854;&#36716;&#25442;&#20026;CPU&#21487;&#20197;&#30452;&#25509;&#25191;&#34892;&#30340;&#20108;&#36827;&#21046;&#26684;&#24335;&#12290;&#22240;&#27492;&#65292;&#20108;&#36827;&#21046;&#20195;&#30721;&#20998;&#26512;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#31561;&#27809;&#26377;&#28304;&#20195;&#30721;&#30340;&#24212;&#29992;&#31243;&#24207;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#19982;&#21253;&#21547;&#20016;&#23500;&#35821;&#20041;&#20449;&#24687;&#30340;&#28304;&#20195;&#30721;&#21644;&#33258;&#28982;&#35821;&#35328;&#19981;&#21516;&#65292;&#20108;&#36827;&#21046;&#20195;&#30721;&#36890;&#24120;&#38590;&#20197;&#29702;&#35299;&#21644;&#20998;&#26512;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#24037;&#20316;&#20351;&#29992;AI&#27169;&#22411;&#36741;&#21161;&#28304;&#20195;&#30721;&#20998;&#26512;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#32771;&#34385;&#20108;&#36827;&#21046;&#20195;&#30721;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#36827;&#34892;&#34920;&#31034;&#23398;&#20064;&#30340;&#23545;&#27604;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;COMBO&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;COMBO&#20013;&#25552;&#20986;&#20102;&#19977;&#20010;&#32452;&#20214;&#65306;&#65288;1&#65289;&#29992;&#20110;&#20919;&#21551;&#21160;&#39044;&#35757;&#32451;&#30340;&#20027;&#35201;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#65288;2&#65289;&#29992;&#20110;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#25554;&#20837;&#21040;&#20108;&#36827;&#21046;&#20195;&#30721;&#20013;&#30340;&#21333;&#32431;&#25554;&#20540;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compiled software is delivered as executable binary code. Developers write source code to express the software semantics, but the compiler converts it to a binary format that the CPU can directly execute. Therefore, binary code analysis is critical to applications in reverse engineering and computer security tasks where source code is not available. However, unlike source code and natural language that contain rich semantic information, binary code is typically difficult for human engineers to understand and analyze. While existing work uses AI models to assist source code analysis, few studies have considered binary code. In this paper, we propose a COntrastive learning Model for Binary cOde Analysis, or COMBO, that incorporates source code and comment information into binary code during representation learning. Specifically, we present three components in COMBO: (1) a primary contrastive learning method for cold-start pre-training, (2) a simplex interpolation method to incorporate so
&lt;/p&gt;</description></item></channel></rss>