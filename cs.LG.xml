<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Brenier&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#38750;&#32447;&#24615;&#28388;&#27874;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#20808;&#39564;&#20998;&#24067;&#21040;&#21518;&#39564;&#20998;&#24067;&#30340;&#26144;&#23556;&#26469;&#36991;&#20813;&#26435;&#37325;&#36864;&#21270;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#22797;&#26434;&#20998;&#24067;&#21644;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2310.13886</link><description>&lt;p&gt;
Brenier&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#19979;&#30340;&#38750;&#32447;&#24615;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Filtering with Brenier Optimal Transport Maps
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2310.13886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Brenier&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#38750;&#32447;&#24615;&#28388;&#27874;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#20808;&#39564;&#20998;&#24067;&#21040;&#21518;&#39564;&#20998;&#24067;&#30340;&#26144;&#23556;&#26469;&#36991;&#20813;&#26435;&#37325;&#36864;&#21270;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#22797;&#26434;&#20998;&#24067;&#21644;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#38750;&#32447;&#24615;&#28388;&#27874;&#38382;&#39064;&#65292;&#21363;&#22312;&#32473;&#23450;&#22122;&#22768;&#37096;&#20998;&#35266;&#27979;&#21382;&#21490;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#38543;&#26426;&#21160;&#24577;&#31995;&#32479;&#29366;&#24577;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#20256;&#32479;&#30340;&#24207;&#21015;&#37325;&#35201;&#37325;&#37319;&#26679;&#65288;SIR&#65289;&#31890;&#23376;&#28388;&#27874;&#30001;&#20110;&#26435;&#37325;&#36864;&#21270;&#38382;&#39064;&#65292;&#22312;&#28041;&#21450;&#36864;&#21270;&#20284;&#28982;&#25110;&#39640;&#32500;&#29366;&#24577;&#30340;&#24773;&#20917;&#19979;&#23384;&#22312;&#22522;&#26412;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#22522;&#20110;&#20272;&#35745;&#20174;&#24403;&#21069;&#20808;&#39564;&#20998;&#24067;&#21040;&#19979;&#19968;&#20010;&#26102;&#38388;&#27493;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;Brenier&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#26144;&#23556;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#19982;SIR&#31890;&#23376;&#28388;&#27874;&#19981;&#21516;&#65292;OT&#26041;&#27861;&#19981;&#38656;&#35201;&#20284;&#28982;&#30340;&#35299;&#26512;&#24418;&#24335;&#12290;&#27492;&#22806;&#65292;&#23427;&#20801;&#35768;&#25105;&#20204;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#26469;&#24314;&#27169;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#26469;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#25968;&#23383;&#23454;&#39564;&#65292;&#27604;&#36739;&#20102;OT&#28388;&#27874;&#22120;&#21644;SIR&#31890;&#23376;&#28388;&#27874;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with the problem of nonlinear filtering, i.e., computing the conditional distribution of the state of a stochastic dynamical system given a history of noisy partial observations. Conventional sequential importance resampling (SIR) particle filters suffer from fundamental limitations, in scenarios involving degenerate likelihoods or high-dimensional states, due to the weight degeneracy issue. In this paper, we explore an alternative method, which is based on estimating the Brenier optimal transport (OT) map from the current prior distribution of the state to the posterior distribution at the next time step. Unlike SIR particle filters, the OT formulation does not require the analytical form of the likelihood. Moreover, it allows us to harness the approximation power of neural networks to model complex and multi-modal distributions and employ stochastic optimization algorithms to enhance scalability. Extensive numerical experiments are presented that compare the O
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23041;&#32961;&#12290;&#36890;&#36807;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#21253;&#25324;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#65292;&#25991;&#31456;&#25581;&#31034;&#20102;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#21333;&#35302;&#21457;&#25915;&#20987;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.15295</link><description>&lt;p&gt;
&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#65306;&#26356;&#22810;&#35302;&#21457;&#22120;&#65292;&#26356;&#22810;&#23041;&#32961;
&lt;/p&gt;
&lt;p&gt;
Multi-Trigger Backdoor Attacks: More Triggers, More Threats. (arXiv:2401.15295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22810;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23041;&#32961;&#12290;&#36890;&#36807;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#21253;&#25324;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#65292;&#25991;&#31456;&#25581;&#31034;&#20102;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#21333;&#35302;&#21457;&#25915;&#20987;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#38376;&#25915;&#20987;&#24050;&#32463;&#25104;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#65288;&#39044;&#65289;&#35757;&#32451;&#21644;&#37096;&#32626;&#30340;&#20027;&#35201;&#23041;&#32961;&#12290;&#23613;&#31649;&#21518;&#38376;&#25915;&#20987;&#22312;&#19968;&#20123;&#30740;&#31350;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#25506;&#35752;&#65292;&#20294;&#20854;&#20013;&#22823;&#37096;&#20998;&#37117;&#38598;&#20013;&#22312;&#20351;&#29992;&#21333;&#20010;&#31867;&#22411;&#30340;&#35302;&#21457;&#22120;&#26469;&#27745;&#26579;&#25968;&#25454;&#38598;&#30340;&#21333;&#35302;&#21457;&#25915;&#20987;&#19978;&#12290;&#21487;&#20197;&#35828;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#21518;&#38376;&#25915;&#20987;&#21487;&#33021;&#26356;&#21152;&#22797;&#26434;&#65292;&#20363;&#22914;&#65292;&#21516;&#19968;&#25968;&#25454;&#38598;&#21487;&#33021;&#23384;&#22312;&#22810;&#20010;&#23545;&#25163;&#65292;&#22914;&#26524;&#35813;&#25968;&#25454;&#38598;&#20855;&#26377;&#36739;&#39640;&#30340;&#20215;&#20540;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#35302;&#21457;&#25915;&#20987;&#35774;&#32622;&#19979;&#21518;&#38376;&#25915;&#20987;&#30340;&#23454;&#38469;&#23041;&#32961;&#65292;&#22810;&#20010;&#23545;&#25163;&#21033;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#35302;&#21457;&#22120;&#26469;&#27745;&#26579;&#21516;&#19968;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#25552;&#20986;&#21644;&#30740;&#31350;&#24182;&#34892;&#12289;&#39034;&#24207;&#21644;&#28151;&#21512;&#25915;&#20987;&#36825;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#35302;&#21457;&#25915;&#20987;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#19981;&#21516;&#35302;&#21457;&#22120;&#23545;&#21516;&#19968;&#25968;&#25454;&#38598;&#30340;&#20849;&#23384;&#12289;&#35206;&#20889;&#21644;&#20132;&#21449;&#28608;&#27963;&#25928;&#26524;&#30340;&#37325;&#35201;&#35748;&#35782;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21333;&#35302;&#21457;&#25915;&#20987;&#24448;&#24448;&#23481;&#26131;&#24341;&#36215;&#35206;&#20889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Backdoor attacks have emerged as a primary threat to (pre-)training and deployment of deep neural networks (DNNs). While backdoor attacks have been extensively studied in a body of works, most of them were focused on single-trigger attacks that poison a dataset using a single type of trigger. Arguably, real-world backdoor attacks can be much more complex, e.g., the existence of multiple adversaries for the same dataset if it is of high value. In this work, we investigate the practical threat of backdoor attacks under the setting of \textbf{multi-trigger attacks} where multiple adversaries leverage different types of triggers to poison the same dataset. By proposing and investigating three types of multi-trigger attacks, including parallel, sequential, and hybrid attacks, we provide a set of important understandings of the coexisting, overwriting, and cross-activating effects between different triggers on the same dataset. Moreover, we show that single-trigger attacks tend to cause over
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#32771;&#34385;&#20102;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12472</link><description>&lt;p&gt;
&#26080;&#27169;&#22411;&#24191;&#20041;&#22522;&#20934;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Model-free generalized fiducial inference. (arXiv:2307.12472v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#32771;&#34385;&#20102;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#30340;&#23433;&#20840;&#21487;&#38752;&#24615;&#30340;&#38656;&#27714;&#65292;&#26412;&#25991;&#25552;&#20986;&#24182;&#21457;&#23637;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#25552;&#20379;&#39044;&#27979;&#38598;&#30340;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#23545;&#31532;&#19968;&#31867;&#38169;&#35823;&#30340;&#26377;&#38480;&#26679;&#26412;&#25511;&#21046;&#65292;&#36825;&#19982;&#19968;&#33268;&#24615;&#39044;&#27979;&#38598;&#20855;&#26377;&#30456;&#21516;&#30340;&#23646;&#24615;&#65292;&#20294;&#36825;&#31181;&#26032;&#26041;&#27861;&#36824;&#25552;&#20379;&#20102;&#26356;&#28789;&#27963;&#30340;&#19981;&#20934;&#30830;&#27010;&#29575;&#25512;&#29702;&#24037;&#20855;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#24182;&#32771;&#34385;&#20102;&#19968;&#31181;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#29305;&#24615;&#12290;&#36890;&#36807;&#23558;&#20449;&#24565;/&#21487;&#20449;&#24230;&#24230;&#37327;&#23545;&#36817;&#20284;&#20026;&#22312;&#21487;&#20449;&#21306;&#38388;&#20013;&#30340;[&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#26368;&#20248;]&#27010;&#29575;&#24230;&#37327;&#65292;&#26159;&#25193;&#22823;&#22312;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#25512;&#24191;&#19981;&#20934;&#30830;&#27010;&#29575;&#25512;&#29702;&#26041;&#27861;&#25152;&#38656;&#30340;&#20851;&#38190;&#35299;&#20915;&#26041;&#26696;&#65292;&#30446;&#21069;&#22312;&#32479;&#35745;&#21644;
&lt;/p&gt;
&lt;p&gt;
Motivated by the need for the development of safe and reliable methods for uncertainty quantification in machine learning, I propose and develop ideas for a model-free statistical framework for imprecise probabilistic prediction inference. This framework facilitates uncertainty quantification in the form of prediction sets that offer finite sample control of type 1 errors, a property shared with conformal prediction sets, but this new approach also offers more versatile tools for imprecise probabilistic reasoning. Furthermore, I propose and consider the theoretical and empirical properties of a precise probabilistic approximation to the model-free imprecise framework. Approximating a belief/plausibility measure pair by an [optimal in some sense] probability measure in the credal set is a critical resolution needed for the broader adoption of imprecise probabilistic approaches to inference in statistical and machine learning communities. It is largely undetermined in the statistical and
&lt;/p&gt;</description></item></channel></rss>