<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#20960;&#20309;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25968;&#25454;&#32467;&#26500;&#12289;&#27169;&#22411;&#21644;&#24212;&#29992;&#65292;&#36890;&#36807;&#25552;&#20986;&#20855;&#22791;&#19981;&#21464;&#24615;/&#31561;&#21464;&#24615;&#23646;&#24615;&#30340;&#20960;&#20309;GNN&#26469;&#26356;&#22909;&#22320;&#34920;&#24449;&#20960;&#20309;&#22270;&#30340;&#20960;&#20309;&#24418;&#29366;&#21644;&#25299;&#25169;&#65292;&#24182;&#25552;&#20379;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;</title><link>https://arxiv.org/abs/2403.00485</link><description>&lt;p&gt;
&#20960;&#20309;&#22270;&#31070;&#32463;&#32593;&#32476;&#32508;&#36848;&#65306;&#25968;&#25454;&#32467;&#26500;&#12289;&#27169;&#22411;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Survey of Geometric Graph Neural Networks: Data Structures, Models and Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00485
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#20960;&#20309;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25968;&#25454;&#32467;&#26500;&#12289;&#27169;&#22411;&#21644;&#24212;&#29992;&#65292;&#36890;&#36807;&#25552;&#20986;&#20855;&#22791;&#19981;&#21464;&#24615;/&#31561;&#21464;&#24615;&#23646;&#24615;&#30340;&#20960;&#20309;GNN&#26469;&#26356;&#22909;&#22320;&#34920;&#24449;&#20960;&#20309;&#22270;&#30340;&#20960;&#20309;&#24418;&#29366;&#21644;&#25299;&#25169;&#65292;&#24182;&#25552;&#20379;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#20309;&#22270;&#26159;&#19968;&#31181;&#20855;&#26377;&#20960;&#20309;&#29305;&#24449;&#30340;&#29305;&#27530;&#22270;&#24418;&#65292;&#23545;&#20110;&#24314;&#27169;&#35768;&#22810;&#31185;&#23398;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#19982;&#19968;&#33324;&#22270;&#19981;&#21516;&#65292;&#20960;&#20309;&#22270;&#36890;&#24120;&#20855;&#26377;&#24179;&#31227;&#12289;&#26059;&#36716;&#21644;&#21453;&#23556;&#31561;&#29289;&#29702;&#23545;&#31216;&#24615;&#65292;&#36825;&#20351;&#23427;&#20204;&#38590;&#20197;&#34987;&#24403;&#21069;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26377;&#25928;&#22788;&#29702;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#21508;&#31181;&#20855;&#22791;&#19981;&#21464;&#24615;/&#31561;&#21464;&#24615;&#23646;&#24615;&#30340;&#20960;&#20309;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#26356;&#22909;&#22320;&#34920;&#24449;&#20960;&#20309;&#22270;&#30340;&#20960;&#20309;&#24418;&#29366;&#21644;&#25299;&#25169;&#12290;&#37492;&#20110;&#35813;&#39046;&#22495;&#30340;&#24403;&#21069;&#36827;&#23637;&#65292;&#26377;&#24517;&#35201;&#23545;&#19982;&#20960;&#20309;GNN&#30456;&#20851;&#30340;&#25968;&#25454;&#32467;&#26500;&#12289;&#27169;&#22411;&#21644;&#24212;&#29992;&#36827;&#34892;&#20840;&#38754;&#35843;&#26597;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#22522;&#20110;&#24517;&#35201;&#20294;&#31616;&#27905;&#30340;&#25968;&#23398;&#22522;&#30784;&#30693;&#35782;&#65292;&#25105;&#20204;&#20174;&#20960;&#20309;&#28040;&#24687;&#20256;&#36882;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#24212;&#29992;&#31243;&#24207;&#20197;&#21450;&#30456;&#20851;&#25968;&#25454;&#38598;&#65292;&#20197;&#20419;&#36827;&#20197;&#21518;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00485v1 Announce Type: new  Abstract: Geometric graph is a special kind of graph with geometric features, which is vital to model many scientific problems. Unlike generic graphs, geometric graphs often exhibit physical symmetries of translations, rotations, and reflections, making them ineffectively processed by current Graph Neural Networks (GNNs). To tackle this issue, researchers proposed a variety of Geometric Graph Neural Networks equipped with invariant/equivariant properties to better characterize the geometry and topology of geometric graphs. Given the current progress in this field, it is imperative to conduct a comprehensive survey of data structures, models, and applications related to geometric GNNs. In this paper, based on the necessary but concise mathematical preliminaries, we provide a unified view of existing models from the geometric message passing perspective. Additionally, we summarize the applications as well as the related datasets to facilitate later 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20174;&#31070;&#32463;&#23849;&#28291;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#26631;&#31614;&#24179;&#28369;&#65292;&#24182;&#21457;&#29616;&#27169;&#22411;&#22312;&#26631;&#31614;&#24179;&#28369;&#35757;&#32451;&#19979;&#26356;&#24555;&#22320;&#25910;&#25947;&#21040;&#31070;&#32463;&#23849;&#28291;&#35299;&#65292;&#24182;&#36798;&#21040;&#26356;&#24378;&#30340;&#31070;&#32463;&#23849;&#28291;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#26631;&#31614;&#24179;&#28369;&#25439;&#22833;&#19979;&#30340;&#27169;&#22411;&#22312;&#30456;&#21516;&#30340;NC1&#27700;&#24179;&#19979;&#34920;&#29616;&#20986;&#21152;&#24378;&#30340;NC2&#65292;&#24182;&#21487;&#22312;&#29702;&#35770;&#19978;&#26356;&#24555;&#22320;&#25910;&#25947;&#12290;</title><link>https://arxiv.org/abs/2402.03979</link><description>&lt;p&gt;
&#20132;&#21449;&#29109;&#19982;&#26631;&#31614;&#24179;&#28369;&#65306;&#31070;&#32463;&#23849;&#28291;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Cross Entropy versus Label Smoothing: A Neural Collapse Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03979
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#31070;&#32463;&#23849;&#28291;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#26631;&#31614;&#24179;&#28369;&#65292;&#24182;&#21457;&#29616;&#27169;&#22411;&#22312;&#26631;&#31614;&#24179;&#28369;&#35757;&#32451;&#19979;&#26356;&#24555;&#22320;&#25910;&#25947;&#21040;&#31070;&#32463;&#23849;&#28291;&#35299;&#65292;&#24182;&#36798;&#21040;&#26356;&#24378;&#30340;&#31070;&#32463;&#23849;&#28291;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#26631;&#31614;&#24179;&#28369;&#25439;&#22833;&#19979;&#30340;&#27169;&#22411;&#22312;&#30456;&#21516;&#30340;NC1&#27700;&#24179;&#19979;&#34920;&#29616;&#20986;&#21152;&#24378;&#30340;NC2&#65292;&#24182;&#21487;&#22312;&#29702;&#35770;&#19978;&#26356;&#24555;&#22320;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#31614;&#24179;&#28369;&#25439;&#22833;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#24191;&#27867;&#37319;&#29992;&#30340;&#19968;&#31181;&#25216;&#26415;&#65292;&#29992;&#20110;&#20943;&#36731;&#36807;&#25311;&#21512;&#12290;&#26412;&#25991;&#20174;&#31070;&#32463;&#23849;&#28291;&#65288;NC&#65289;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#26631;&#31614;&#24179;&#28369;&#65292;&#36825;&#26159;&#19968;&#20010;&#24378;&#22823;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#25551;&#36848;&#35757;&#32451;&#30340;&#26368;&#21518;&#38454;&#27573;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26631;&#31614;&#24179;&#28369;&#35757;&#32451;&#30340;&#27169;&#22411;&#26356;&#24555;&#22320;&#25910;&#25947;&#21040;&#31070;&#32463;&#23849;&#28291;&#35299;&#65292;&#24182;&#36798;&#21040;&#26356;&#24378;&#30340;&#31070;&#32463;&#23849;&#28291;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#22312;&#30456;&#21516;&#30340;NC1&#27700;&#24179;&#19979;&#65292;&#26631;&#31614;&#24179;&#28369;&#25439;&#22833;&#19979;&#30340;&#27169;&#22411;&#26174;&#31034;&#20986;&#21152;&#24378;&#30340;NC2&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#29702;&#35299;&#26631;&#31614;&#24179;&#28369;&#25439;&#22833;&#19979;&#30340;&#24615;&#33021;&#20248;&#21183;&#21644;&#22686;&#24378;&#30340;&#27169;&#22411;&#26657;&#20934;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#25512;&#23548;&#20986;&#20004;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#38381;&#24335;&#35299;&#65292;&#24182;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#26631;&#31614;&#24179;&#28369;&#19979;&#30340;&#27169;&#22411;&#20855;&#26377;&#36739;&#20302;&#30340;&#26465;&#20214;&#25968;&#65292;&#22240;&#27492;&#22312;&#29702;&#35770;&#19978;&#26356;&#24555;&#22320;&#25910;&#25947;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32508;&#21512;&#20102;&#32463;&#39564;&#21644;&#29702;&#35770;&#30340;&#26041;&#27861;&#65292;&#20026;&#29702;&#35299;&#26631;&#31614;&#24179;&#28369;&#30340;&#25928;&#26524;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Label smoothing loss is a widely adopted technique to mitigate overfitting in deep neural networks. This paper studies label smoothing from the perspective of Neural Collapse (NC), a powerful empirical and theoretical framework which characterizes model behavior during the terminal phase of training. We first show empirically that models trained with label smoothing converge faster to neural collapse solutions and attain a stronger level of neural collapse. Additionally, we show that at the same level of NC1, models under label smoothing loss exhibit intensified NC2. These findings provide valuable insights into the performance benefits and enhanced model calibration under label smoothing loss. We then leverage the unconstrained feature model to derive closed-form solutions for the global minimizers for both loss functions and further demonstrate that models under label smoothing have a lower conditioning number and, therefore, theoretically converge faster. Our study, combining empiri
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#22686;&#24378;&#26159;&#19968;&#31181;&#21033;&#29992;dropout&#25110;PCA&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#36716;&#25442;&#30446;&#26631;&#23618;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#25913;&#21892;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#22312;Transformers&#12289;ResNets&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#31561;&#22522;&#30784;&#27169;&#22411;&#19978;&#65292;&#36890;&#36807;&#28145;&#24230;&#22686;&#24378;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#20294;&#22312;&#30417;&#30563;&#38382;&#39064;&#19978;&#25928;&#26524;&#30456;&#21453;&#12290;</title><link>https://arxiv.org/abs/2303.14537</link><description>&lt;p&gt;
&#28145;&#24230;&#22686;&#24378;&#65306;&#22312;&#28608;&#27963;&#31354;&#38388;&#20013;&#20351;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Deep Augmentation: Self-Supervised Learning with Transformations in Activation Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2303.14537
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#22686;&#24378;&#26159;&#19968;&#31181;&#21033;&#29992;dropout&#25110;PCA&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#36716;&#25442;&#30446;&#26631;&#23618;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#25913;&#21892;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#22312;Transformers&#12289;ResNets&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#31561;&#22522;&#30784;&#27169;&#22411;&#19978;&#65292;&#36890;&#36807;&#28145;&#24230;&#22686;&#24378;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#20294;&#22312;&#30417;&#30563;&#38382;&#39064;&#19978;&#25928;&#26524;&#30456;&#21453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#28145;&#24230;&#22686;&#24378;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36749;&#23398;&#25110;PCA&#26469;&#36716;&#25442;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#30446;&#26631;&#23618;&#65292;&#20197;&#25552;&#39640;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#22270;&#23398;&#20064;&#20013;&#30340;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#19978;&#36827;&#34892;&#22823;&#37327;&#23454;&#39564;&#26469;&#23637;&#31034;&#28145;&#24230;&#22686;&#24378;&#12290; &#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#23545;&#27604;&#23398;&#20064;&#30340;&#22522;&#30784;&#27169;&#22411;&#20013;&#65292;&#22914;Transformers&#12289;ResNets&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#19978;&#28145;&#24230;&#22686;&#24378;&#33021;&#22815;&#24102;&#26469;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#20294;&#22312;&#30456;&#24212;&#30340;&#30417;&#30563;&#38382;&#39064;&#19978;&#35266;&#23519;&#21040;&#30456;&#21453;&#30340;&#25928;&#26524;&#12290; &#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#28145;&#24230;&#22686;&#24378;&#20943;&#36731;&#20102;&#23618;&#20043;&#38388;&#30340;&#30456;&#20114;&#36866;&#24212;&#65292;&#21363;"&#23849;&#28291;"&#24418;&#24335;&#30340;&#38382;&#39064;&#12290; &#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#21046;&#23450;&#20102;&#19968;&#31181;&#36873;&#25321;&#30446;&#26631;&#23618;&#30340;&#26041;&#27861;&#65307;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#29992;&#28145;&#24230;&#22686;&#24378;&#23450;&#20301;&#26356;&#28145;&#23618;&#27425;&#30340;&#23618;&#35201;&#20248;&#20110;&#22686;&#24378;&#36755;&#20837;&#25968;&#25454;&#12290; &#36825;&#31181;&#26041;&#27861;&#30340;&#31616;&#21333;&#32593;&#32476;&#21644;&#27169;&#24577;&#26080;&#20851;&#24615;&#20351;&#20854;
&lt;/p&gt;
&lt;p&gt;
arXiv:2303.14537v2 Announce Type: replace-cross  Abstract: We introduce Deep Augmentation, an approach to implicit data augmentation using dropout or PCA to transform a targeted layer within a neural network to improve performance and generalization. We demonstrate Deep Augmentation through extensive experiments on contrastive learning tasks in NLP, computer vision, and graph learning. We observe substantial performance gains with Transformers, ResNets, and Graph Neural Networks as the underlying models in contrastive learning, but observe inverse effects on the corresponding supervised problems. Our analysis suggests that Deep Augmentation alleviates co-adaption between layers, a form of "collapse." We use this observation to formulate a method for selecting which layer to target; in particular, our experimentation reveals that targeting deeper layers with Deep Augmentation outperforms augmenting the input data. The simple network- and modality-agnostic nature of this approach enables
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20855;&#26377;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#25216;&#26415;&#12289;&#22810;&#31181;&#36866;&#24212;&#27169;&#22411;&#21644;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#31561;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2112.14249</link><description>&lt;p&gt;
&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65306;&#38271;&#26399;&#12289;&#20013;&#20171;&#21644;&#26102;&#21464;&#27835;&#30103;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Nested Nonparametric Instrumental Variable Regression: Long Term, Mediated, and Time Varying Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2112.14249
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20855;&#26377;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#25216;&#26415;&#12289;&#22810;&#31181;&#36866;&#24212;&#27169;&#22411;&#21644;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#31561;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#20013;&#30340;&#20960;&#20010;&#22240;&#26524;&#21442;&#25968;&#26159;&#31216;&#20026;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65288;nested NPIV&#65289;&#30340;&#20989;&#25968;&#30340;&#26631;&#37327;&#24635;&#32467;&#12290;&#20363;&#22914;&#65292;&#20351;&#29992;&#20195;&#29702;&#21464;&#37327;&#35782;&#21035;&#20986;&#38271;&#26399;&#12289;&#20013;&#20171;&#21644;&#26102;&#21464;&#27835;&#30103;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#20284;&#20046;&#19981;&#23384;&#22312;&#20851;&#20110;&#23884;&#22871;NPIV&#30340;&#20808;&#21069;&#20272;&#35745;&#37327;&#25110;&#20445;&#35777;&#65292;&#36825;&#26679;&#23601;&#26080;&#27861;&#28789;&#27963;&#22320;&#20272;&#35745;&#21644;&#25512;&#26029;&#36825;&#20123;&#22240;&#26524;&#21442;&#25968;&#12290;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#30001;&#20110;&#23884;&#22871;&#36870;&#38382;&#39064;&#32780;&#23548;&#33268;&#30340;&#22797;&#21512;&#30149;&#24577;&#24615;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#23884;&#22871;NPIV&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#20855;&#26377;&#19977;&#20010;&#26174;&#33879;&#29305;&#24449;&#65306;&#65288;i&#65289;&#24341;&#20837;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#30340;&#25216;&#26415;&#65307;&#65288;ii&#65289;&#36866;&#24212;&#31070;&#32463;&#32593;&#32476;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65307;&#65288;iii&#65289;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#65292;&#20363;&#22914;&#38271;&#26399;&#24322;&#36136;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2112.14249v3 Announce Type: replace-cross  Abstract: Several causal parameters in short panel data models are scalar summaries of a function called a nested nonparametric instrumental variable regression (nested NPIV). Examples include long term, mediated, and time varying treatment effects identified using proxy variables. However, it appears that no prior estimators or guarantees for nested NPIV exist, preventing flexible estimation and inference for these causal parameters. A major challenge is compounding ill posedness due to the nested inverse problems. We analyze adversarial estimators of nested NPIV, and provide sufficient conditions for efficient inference on the causal parameter. Our nonasymptotic analysis has three salient features: (i) introducing techniques that limit how ill posedness compounds; (ii) accommodating neural networks, random forests, and reproducing kernel Hilbert spaces; and (iii) extending to causal functions, e.g. long term heterogeneous treatment eff
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2401.14283</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#39044;&#27979;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;
&lt;/p&gt;
&lt;p&gt;
Information Leakage Detection through Approximate Bayes-optimal Prediction. (arXiv:2401.14283v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20170;&#22825;&#30340;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#19990;&#30028;&#20013;&#65292;&#20844;&#24320;&#21487;&#33719;&#24471;&#30340;&#20449;&#24687;&#30340;&#22686;&#21152;&#21152;&#21095;&#20102;&#20449;&#24687;&#27844;&#28431;&#65288;IL&#65289;&#30340;&#25361;&#25112;&#65292;&#24341;&#21457;&#20102;&#23433;&#20840;&#38382;&#39064;&#12290;IL&#28041;&#21450;&#36890;&#36807;&#31995;&#32479;&#30340;&#21487;&#35266;&#23519;&#20449;&#24687;&#26080;&#24847;&#22320;&#23558;&#31192;&#23494;&#65288;&#25935;&#24863;&#65289;&#20449;&#24687;&#26292;&#38706;&#32473;&#26410;&#32463;&#25480;&#26435;&#30340;&#26041;&#65292;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;&#21487;&#35266;&#23519;&#20449;&#24687;&#21644;&#31192;&#23494;&#20449;&#24687;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#26469;&#26816;&#27979;IL&#65292;&#38754;&#20020;&#32500;&#24230;&#28798;&#38590;&#12289;&#25910;&#25947;&#12289;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;MI&#20272;&#35745;&#38169;&#35823;&#31561;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#26032;&#20852;&#30340;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#22312;&#20108;&#36827;&#21046;&#31995;&#32479;&#25935;&#24863;&#20449;&#24687;&#30340;&#26816;&#27979;&#19978;&#26377;&#25928;&#65292;&#20294;&#32570;&#20047;&#19968;&#20010;&#20840;&#38754;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#24314;&#31435;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;IL&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;MI&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's data-driven world, the proliferation of publicly available information intensifies the challenge of information leakage (IL), raising security concerns. IL involves unintentionally exposing secret (sensitive) information to unauthorized parties via systems' observable information. Conventional statistical approaches, which estimate mutual information (MI) between observable and secret information for detecting IL, face challenges such as the curse of dimensionality, convergence, computational complexity, and MI misestimation. Furthermore, emerging supervised machine learning (ML) methods, though effective, are limited to binary system-sensitive information and lack a comprehensive theoretical framework. To address these limitations, we establish a theoretical framework using statistical learning theory and information theory to accurately quantify and detect IL. We demonstrate that MI can be accurately estimated by approximating the log-loss and accuracy of the Bayes predict
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#30340;&#38598;&#25104;&#21040;&#24494;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20197;&#35299;&#20915;&#20854;&#20135;&#29983;&#19981;&#21487;&#21462;&#20869;&#23481;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#28165;&#27905;&#39046;&#22495;&#20013;&#26377;&#25928;&#20943;&#23569;&#26377;&#23475;&#20869;&#23481;&#29983;&#25104;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.08491</link><description>&lt;p&gt;
&#23545;&#27604;&#22256;&#24785;&#24230;&#22312;&#21463;&#25511;&#29983;&#25104;&#20013;&#30340;&#24212;&#29992;&#65306;&#28165;&#27905;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models. (arXiv:2401.08491v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08491
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#30340;&#38598;&#25104;&#21040;&#24494;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20197;&#35299;&#20915;&#20854;&#20135;&#29983;&#19981;&#21487;&#21462;&#20869;&#23481;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#28165;&#27905;&#39046;&#22495;&#20013;&#26377;&#25928;&#20943;&#23569;&#26377;&#23475;&#20869;&#23481;&#29983;&#25104;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20135;&#29983;&#19981;&#21487;&#21462;&#21644;&#20107;&#23454;&#19981;&#27491;&#30830;&#30340;&#20869;&#23481;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#26159;&#19968;&#20010;&#25361;&#25112;&#21644;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#30340;&#38598;&#25104;&#65292;&#29992;&#20110;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#20197;&#36827;&#34892;&#38544;&#24335;&#30693;&#35782;&#32534;&#36753;&#21644;&#21463;&#25511;&#25991;&#26412;&#29983;&#25104;&#12290;&#36890;&#36807;&#23545;&#27604;&#26041;&#24335;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#21363;&#23545;&#40784;&#25991;&#26412;&#30340;&#22256;&#24785;&#24230;&#12290;&#20026;&#20102;&#20197;&#33258;&#30417;&#30563;&#30340;&#26041;&#24335;&#35757;&#32451;&#27169;&#22411;&#65292;&#25105;&#20204;&#21033;&#29992;&#29616;&#25104;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#28165;&#27905;&#39046;&#22495;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#29983;&#25104;&#26377;&#23475;&#20869;&#23481;&#30340;&#25968;&#37327;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#23545;&#20110;&#24120;&#35782;&#25512;&#29702;&#21644;&#38405;&#35835;&#29702;&#35299;&#31561;&#19979;&#28216;&#20219;&#21153;&#30340;&#23454;&#29992;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#31616;&#21333;&#20294;&#32463;&#39564;&#19978;&#24378;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generation of undesirable and factually incorrect content of large language models poses a significant challenge and remains largely an unsolved issue. This paper studies the integration of a contrastive learning objective for fine-tuning LLMs for implicit knowledge editing and controlled text generation. Optimizing the training objective entails aligning text perplexities in a contrastive fashion. To facilitate training the model in a self-supervised fashion, we leverage an off-the-shelf LLM for training data generation. We showcase applicability in the domain of detoxification. Herein, the proposed approach leads to a significant decrease in the generation of toxic content while preserving general utility for downstream tasks such as commonsense reasoning and reading comprehension. The proposed approach is conceptually simple but empirically powerful.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#12289;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#35758;&#20102;&#19968;&#31181;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#25910;&#25947;&#36895;&#24230;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06738</link><description>&lt;p&gt;
&#22122;&#22768;&#33258;&#36866;&#24212;&#65288;&#21152;&#36895;&#65289;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;
&lt;/p&gt;
&lt;p&gt;
Noise-adaptive (Accelerated) Stochastic Heavy-Ball Momentum. (arXiv:2401.06738v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#12289;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#35758;&#20102;&#19968;&#31181;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#25910;&#25947;&#36895;&#24230;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#65292;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#65288;SHB&#65289;&#30340;&#25910;&#25947;&#24615;&#12290;Kidambi&#31561;&#20154;&#65288;2018&#65289;&#34920;&#26126;&#65292;&#23545;&#20110;&#20108;&#27425;&#20989;&#25968;&#65292;SHB&#65288;&#24102;&#26377;&#23567;&#25209;&#37327;&#65289;&#26080;&#27861;&#36798;&#21040;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#29468;&#24819;SHB&#30340;&#23454;&#38469;&#25910;&#30410;&#26159;&#23567;&#25209;&#37327;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#19968;&#23450;&#38408;&#20540;&#26102;&#65292;SHB&#21487;&#20197;&#33719;&#24471;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35777;&#23454;&#36825;&#19968;&#35266;&#28857;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#26465;&#20214;&#25968;&#20026;$\kappa$&#30340;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#26631;&#20934;&#27493;&#38271;&#21644;&#21160;&#37327;&#21442;&#25968;&#30340;SHB&#20855;&#26377;$O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$T$&#20026;&#36845;&#20195;&#27425;&#25968;&#65292;$\sigma^2$&#20026;&#38543;&#26426;&#26799;&#24230;&#30340;&#26041;&#24046;&#12290;&#20026;&#30830;&#20445;&#25910;&#25947;&#21040;&#26497;&#23567;&#20540;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#32467;&#26524;&#26159;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;$O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$&#36895;&#24230;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#24378;&#20984;&#20989;&#25968;&#65292;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the convergence of stochastic heavy ball (SHB) momentum in the smooth, strongly-convex setting. Kidambi et al. (2018) show that SHB (with small mini-batches) cannot attain an accelerated rate of convergence even for quadratics, and conjecture that the practical gain of SHB is a by-product of mini-batching. We substantiate this claim by showing that SHB can obtain an accelerated rate when the mini-batch size is larger than some threshold. In particular, for strongly-convex quadratics with condition number $\kappa$, we prove that SHB with the standard step-size and momentum parameters results in an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence rate, where $T$ is the number of iterations and $\sigma^2$ is the variance in the stochastic gradients. To ensure convergence to the minimizer, we propose a multi-stage approach that results in a noise-adaptive $O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$ rate. For general strongly-
&lt;/p&gt;</description></item><item><title>CCNETS&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#33041;&#21551;&#21457;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#22823;&#33041;&#30340;&#20449;&#24687;&#22788;&#29702;&#65292;&#36890;&#36807;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#26469;&#22686;&#24378;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#30340;&#27169;&#24335;&#35782;&#21035;&#65292;&#29305;&#21035;&#20851;&#27880;&#22788;&#29702;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.04139</link><description>&lt;p&gt;
CCNETS:&#19968;&#31181;&#26032;&#39062;&#30340;&#33041;&#21551;&#21457;&#26041;&#27861;&#29992;&#20110;&#22686;&#24378;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#30340;&#27169;&#24335;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
CCNETS: A Novel Brain-Inspired Approach for Enhanced Pattern Recognition in Imbalanced Datasets. (arXiv:2401.04139v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04139
&lt;/p&gt;
&lt;p&gt;
CCNETS&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#33041;&#21551;&#21457;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#22823;&#33041;&#30340;&#20449;&#24687;&#22788;&#29702;&#65292;&#36890;&#36807;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#26469;&#22686;&#24378;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#30340;&#27169;&#24335;&#35782;&#21035;&#65292;&#29305;&#21035;&#20851;&#27880;&#22788;&#29702;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;CCNETS&#65288;&#20855;&#26377;&#22240;&#26524;&#21512;&#20316;&#32593;&#32476;&#30340;&#22240;&#26524;&#23398;&#20064;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#20998;&#31867;&#22120;&#65292;&#26088;&#22312;&#35299;&#20915;&#27169;&#24335;&#35782;&#21035;&#20013;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#29983;&#25104;&#30340;&#25361;&#25112;&#12290;CCNETS&#29420;&#29305;&#22320;&#35774;&#35745;&#25104;&#27169;&#25311;&#31867;&#20284;&#20110;&#22823;&#33041;&#30340;&#20449;&#24687;&#22788;&#29702;&#65292;&#24182;&#21253;&#25324;&#19977;&#20010;&#20027;&#35201;&#32452;&#20214;&#65306;&#35299;&#37322;&#22120;&#12289;&#29983;&#25104;&#22120;&#21644;&#25512;&#29702;&#22120;&#12290;&#27599;&#20010;&#32452;&#20214;&#37117;&#34987;&#35774;&#35745;&#25104;&#27169;&#20223;&#29305;&#23450;&#30340;&#22823;&#33041;&#21151;&#33021;&#65292;&#26377;&#21161;&#20110;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#24182;&#22686;&#24378;&#20998;&#31867;&#24615;&#33021;&#12290;&#35813;&#27169;&#22411;&#29305;&#21035;&#20851;&#27880;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#35265;&#21644;&#37325;&#35201;&#25361;&#25112;&#12290;&#36890;&#36807;&#23558;CCNETS&#24212;&#29992;&#20110;&#19968;&#20010;&#8220;&#27450;&#35784;&#25968;&#25454;&#38598;&#8221;&#65292;&#20854;&#20013;&#27491;&#24120;&#20132;&#26131;&#26126;&#26174;&#22810;&#20110;&#27450;&#35784;&#20132;&#26131;&#65288;99.83&#65285; vs. 0.17&#65285;&#65289;&#65292;&#35777;&#26126;&#20102;CCNETS&#30340;&#26377;&#25928;&#24615;&#12290;&#20256;&#32479;&#26041;&#27861;&#24448;&#24448;&#22312;&#22788;&#29702;&#36825;&#31181;&#19981;&#24179;&#34913;&#26102;&#36935;&#21040;&#22256;&#38590;&#65292;&#23548;&#33268;&#24615;&#33021;&#25351;&#26631;&#19981;&#22343;&#34913;&#12290;&#28982;&#32780;&#65292;CCNETS&#23637;&#29616;&#20986;&#20248;&#36234;&#30340;&#20998;&#31867;&#33021;&#21147;&#65292;&#36890;&#36807;&#20854;&#24615;&#33021;&#25351;&#26631;&#30340;&#25913;&#21892;&#26469;&#20307;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study introduces CCNETS (Causal Learning with Causal Cooperative Nets), a novel generative model-based classifier designed to tackle the challenge of generating data for imbalanced datasets in pattern recognition. CCNETS is uniquely crafted to emulate brain-like information processing and comprises three main components: Explainer, Producer, and Reasoner. Each component is designed to mimic specific brain functions, which aids in generating high-quality datasets and enhancing classification performance.  The model is particularly focused on addressing the common and significant challenge of handling imbalanced datasets in machine learning. CCNETS's effectiveness is demonstrated through its application to a "fraud dataset," where normal transactions significantly outnumber fraudulent ones (99.83% vs. 0.17%). Traditional methods often struggle with such imbalances, leading to skewed performance metrics. However, CCNETS exhibits superior classification ability, as evidenced by its pe
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35752;&#35770;&#20102;&#38754;&#20020;&#33021;&#28304;&#12289;&#23545;&#40784;&#21644;&#20174;&#29421;&#20041;&#20154;&#24037;&#26234;&#33021;&#21040;AGI&#30340;&#19977;&#22823;&#25361;&#25112;&#30340;&#31995;&#32479;&#21270;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#22312;&#33021;&#28304;&#28040;&#32791;&#12289;&#31995;&#32479;&#35774;&#35745;&#21644;&#23545;&#40784;&#38382;&#39064;&#19978;&#23384;&#22312;&#19981;&#36275;&#65292;&#32780;&#31995;&#32479;&#35774;&#35745;&#22312;&#35299;&#20915;&#23545;&#40784;&#12289;&#33021;&#28304;&#21644;AGI&#22823;&#25361;&#25112;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.15274</link><description>&lt;p&gt;
&#31995;&#32479;&#21270;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#29992;&#20110;AGI&#65306;&#35299;&#20915;&#23545;&#40784;&#12289;&#33021;&#28304;&#21644;AGI&#22823;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges. (arXiv:2310.15274v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15274
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35752;&#35770;&#20102;&#38754;&#20020;&#33021;&#28304;&#12289;&#23545;&#40784;&#21644;&#20174;&#29421;&#20041;&#20154;&#24037;&#26234;&#33021;&#21040;AGI&#30340;&#19977;&#22823;&#25361;&#25112;&#30340;&#31995;&#32479;&#21270;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#22312;&#33021;&#28304;&#28040;&#32791;&#12289;&#31995;&#32479;&#35774;&#35745;&#21644;&#23545;&#40784;&#38382;&#39064;&#19978;&#23384;&#22312;&#19981;&#36275;&#65292;&#32780;&#31995;&#32479;&#35774;&#35745;&#22312;&#35299;&#20915;&#23545;&#40784;&#12289;&#33021;&#28304;&#21644;AGI&#22823;&#25361;&#25112;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#38754;&#20020;&#30528;&#19977;&#22823;&#25361;&#25112;&#65306;&#33021;&#28304;&#22721;&#22418;&#12289;&#23545;&#40784;&#38382;&#39064;&#21644;&#20174;&#29421;&#20041;&#20154;&#24037;&#26234;&#33021;&#21040;AGI&#30340;&#39134;&#36291;&#12290;&#24403;&#20195;&#20154;&#24037;&#26234;&#33021;&#35299;&#20915;&#26041;&#26696;&#22312;&#27169;&#22411;&#35757;&#32451;&#21644;&#26085;&#24120;&#36816;&#34892;&#36807;&#31243;&#20013;&#28040;&#32791;&#30528;&#19981;&#21487;&#25345;&#32493;&#30340;&#33021;&#28304;&#12290;&#26356;&#31967;&#31957;&#30340;&#26159;&#65292;&#33258;2020&#24180;&#20197;&#26469;&#65292;&#27599;&#20010;&#26032;&#30340;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#25152;&#38656;&#30340;&#35745;&#31639;&#37327;&#27599;&#20004;&#20010;&#26376;&#23601;&#32763;&#20493;&#65292;&#30452;&#25509;&#23548;&#33268;&#33021;&#28304;&#28040;&#32791;&#30340;&#22686;&#21152;&#12290;&#20174;&#20154;&#24037;&#26234;&#33021;&#21040;AGI&#30340;&#39134;&#36291;&#38656;&#35201;&#22810;&#20010;&#21151;&#33021;&#23376;&#31995;&#32479;&#20197;&#24179;&#34913;&#30340;&#26041;&#24335;&#36816;&#20316;&#65292;&#36825;&#38656;&#35201;&#19968;&#20010;&#31995;&#32479;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#32570;&#20047;&#31995;&#32479;&#35774;&#35745;&#65307;&#21363;&#20351;&#31995;&#32479;&#29305;&#24449;&#22312;&#20154;&#33041;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#65292;&#20174;&#23427;&#22788;&#29702;&#20449;&#24687;&#30340;&#26041;&#24335;&#21040;&#23427;&#20570;&#20986;&#20915;&#31574;&#30340;&#26041;&#24335;&#12290;&#21516;&#26679;&#65292;&#24403;&#21069;&#30340;&#23545;&#40784;&#21644;&#20154;&#24037;&#26234;&#33021;&#20262;&#29702;&#26041;&#27861;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#35270;&#20102;&#31995;&#32479;&#35774;&#35745;&#65292;&#28982;&#32780;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#33041;&#30340;&#31995;&#32479;&#26550;&#26500;&#22312;&#20581;&#24247;&#30340;&#36947;&#24503;&#20915;&#31574;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#31995;&#32479;&#35774;&#35745;&#22312;&#35299;&#20915;&#23545;&#40784;&#12289;&#33021;&#28304;&#21644;AGI&#22823;&#25361;&#25112;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
AI faces a trifecta of grand challenges the Energy Wall, the Alignment Problem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume unsustainable amounts of energy during model training and daily operations.Making things worse, the amount of computation required to train each new AI model has been doubling every 2 months since 2020, directly translating to increases in energy consumption.The leap from AI to AGI requires multiple functional subsystems operating in a balanced manner, which requires a system architecture. However, the current approach to artificial intelligence lacks system design; even though system characteristics play a key role in the human brain from the way it processes information to how it makes decisions. Similarly, current alignment and AI ethics approaches largely ignore system design, yet studies show that the brains system architecture plays a critical role in healthy moral decisions.In this paper, we argue that system design is critically im
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.00098</link><description>&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#23398;&#20064;&#36827;&#34892;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Federated Learning with Differential Privacy for End-to-End Speech Recognition. (arXiv:2310.00098v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20294;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#39046;&#22495;&#20165;&#38480;&#20110;&#21021;&#27493;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#32852;&#37030;&#23398;&#20064;&#19981;&#33021;&#26412;&#36136;&#19978;&#20445;&#35777;&#29992;&#25143;&#38544;&#31169;&#65292;&#24182;&#38656;&#35201;&#24046;&#20998;&#38544;&#31169;&#26469;&#25552;&#20379;&#31283;&#20581;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36824;&#19981;&#28165;&#26970;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#20808;&#21069;&#24037;&#20316;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20026;&#32852;&#37030;&#23398;&#20064;&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;&#30340;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#22522;&#20934;&#65292;&#24182;&#24314;&#31435;&#31532;&#19968;&#20010;&#22522;&#32447;&#26469;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#32852;&#37030;&#23398;&#20064;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#30740;&#31350;&#65292;&#25506;&#32034;&#20102;&#26368;&#26032;&#30340;&#22823;&#22411;&#31471;&#21040;&#31471;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65306;&#26550;&#26500;&#35774;&#35745;&#65292;&#31181;&#23376;&#27169;&#22411;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#65292;&#39046;&#22495;&#36716;&#31227;&#65292;&#20197;&#21450;cohort&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#21512;&#29702;&#30340;&#20013;&#22830;&#32858;&#21512;&#25968;&#37327;&#65292;&#25105;&#20204;&#33021;&#22815;&#35757;&#32451;&#20986;&#21363;&#20351;&#22312;&#24322;&#26500;&#25968;&#25454;&#12289;&#26469;&#33258;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#31181;&#23376;&#27169;&#22411;&#25110;&#26080;&#39044;&#20808;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#25509;&#36817;&#26368;&#20248;&#30340;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
While federated learning (FL) has recently emerged as a promising approach to train machine learning models, it is limited to only preliminary explorations in the domain of automatic speech recognition (ASR). Moreover, FL does not inherently guarantee user privacy and requires the use of differential privacy (DP) for robust privacy guarantees. However, we are not aware of prior work on applying DP to FL for ASR. In this paper, we aim to bridge this research gap by formulating an ASR benchmark for FL with DP and establishing the first baselines. First, we extend the existing research on FL for ASR by exploring different aspects of recent $\textit{large end-to-end transformer models}$: architecture design, seed models, data heterogeneity, domain shift, and impact of cohort size. With a $\textit{practical}$ number of central aggregations we are able to train $\textbf{FL models}$ that are \textbf{nearly optimal} even with heterogeneous data, a seed model from another domain, or no pre-trai
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#65292;&#24182;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#32447;&#24615;&#20551;&#35774;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#20379;&#36739;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13135</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#21487;&#21152;&#20540;&#20989;&#25968;&#65306;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#21450;&#20854;&#22312;&#22806;&#31185;&#25163;&#26415;&#24674;&#22797;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Additive Value Functions: Interpretable Reinforcement Learning with an Application to Surgical Recovery. (arXiv:2308.13135v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13135
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#65292;&#24182;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#32447;&#24615;&#20551;&#35774;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#20379;&#36739;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#12290;&#23398;&#20064;&#20381;&#38752;&#25968;&#23383;&#34920;&#22411;&#29305;&#24449;&#30340;&#26377;&#25928;&#33258;&#36866;&#24212;&#20020;&#24202;&#24178;&#39044;&#26159;&#21307;&#21153;&#20154;&#21592;&#37325;&#35270;&#30340;&#38382;&#39064;&#12290;&#22312;&#33034;&#26609;&#25163;&#26415;&#26041;&#38754;&#65292;&#20851;&#20110;&#24739;&#32773;&#36816;&#21160;&#33021;&#21147;&#24674;&#22797;&#30340;&#19981;&#21516;&#26415;&#21518;&#24674;&#22797;&#24314;&#35758;&#21487;&#33021;&#20250;&#23548;&#33268;&#24739;&#32773;&#24674;&#22797;&#31243;&#24230;&#30340;&#26174;&#33879;&#21464;&#21270;&#12290;&#34429;&#28982;&#24378;&#21270;&#23398;&#20064;&#22312;&#28216;&#25103;&#31561;&#39046;&#22495;&#21462;&#24471;&#20102;&#24191;&#27867;&#25104;&#21151;&#65292;&#20294;&#26368;&#36817;&#30340;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#40657;&#30418;&#26041;&#27861;&#65292;&#22914;&#31070;&#32463;&#32593;&#32476;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#38459;&#30861;&#20102;&#32771;&#23519;&#27599;&#20010;&#29305;&#24449;&#23545;&#20110;&#20135;&#29983;&#26368;&#32456;&#24314;&#35758;&#20915;&#31574;&#30340;&#36129;&#29486;&#12290;&#34429;&#28982;&#22312;&#32463;&#20856;&#31639;&#27861;&#65288;&#22914;&#26368;&#23567;&#20108;&#20056;&#31574;&#30053;&#36845;&#20195;&#65289;&#20013;&#21487;&#20197;&#36731;&#26494;&#25552;&#20379;&#36825;&#26679;&#30340;&#35299;&#37322;&#65292;&#20294;&#22522;&#26412;&#30340;&#32447;&#24615;&#20551;&#35774;&#38459;&#27490;&#20102;&#23398;&#20064;&#29305;&#24449;&#20043;&#38388;&#30340;&#39640;&#38454;&#28789;&#27963;&#20132;&#20114;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#25216;&#26415;&#26469;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#24182;&#33021;&#22815;&#24471;&#21040;&#35299;&#37322;&#24615;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a nonparametric additive model for estimating interpretable value functions in reinforcement learning. Learning effective adaptive clinical interventions that rely on digital phenotyping features is a major for concern medical practitioners. With respect to spine surgery, different post-operative recovery recommendations concerning patient mobilization can lead to significant variation in patient recovery. While reinforcement learning has achieved widespread success in domains such as games, recent methods heavily rely on black-box methods, such neural networks. Unfortunately, these methods hinder the ability of examining the contribution each feature makes in producing the final suggested decision. While such interpretations are easily provided in classical algorithms such as Least Squares Policy Iteration, basic linearity assumptions prevent learning higher-order flexible interactions between features. In this paper, we present a novel method that offers a flexible techniq
&lt;/p&gt;</description></item><item><title>RL4CO&#26159;&#19968;&#20010;&#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#30340;&#24191;&#27867;&#24378;&#21270;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;&#65292;&#30528;&#37325;&#20110;&#21487;&#25193;&#23637;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#30340;&#35780;&#20272;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20123;&#26368;&#26032;&#26041;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#30340;&#34920;&#29616;&#30456;&#23545;&#36739;&#24046;&#65292;&#24378;&#35843;&#20102;&#23545;&#31070;&#32463;CO&#27714;&#35299;&#22120;&#24615;&#33021;&#30340;&#24179;&#34913;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.17100</link><description>&lt;p&gt;
RL4CO: &#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#30340;&#24191;&#27867;&#24378;&#21270;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark. (arXiv:2306.17100v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17100
&lt;/p&gt;
&lt;p&gt;
RL4CO&#26159;&#19968;&#20010;&#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#30340;&#24191;&#27867;&#24378;&#21270;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;&#65292;&#30528;&#37325;&#20110;&#21487;&#25193;&#23637;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#30340;&#35780;&#20272;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20123;&#26368;&#26032;&#26041;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#30340;&#34920;&#29616;&#30456;&#23545;&#36739;&#24046;&#65292;&#24378;&#35843;&#20102;&#23545;&#31070;&#32463;CO&#27714;&#35299;&#22120;&#24615;&#33021;&#30340;&#24179;&#34913;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;RL4CO&#65292;&#36825;&#26159;&#19968;&#20010;&#24191;&#27867;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#65288;CO&#65289;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;RL4CO&#37319;&#29992;&#26368;&#20808;&#36827;&#30340;&#36719;&#20214;&#24211;&#21644;&#26368;&#20339;&#23454;&#36341;&#65292;&#22914;&#27169;&#22359;&#21270;&#21644;&#37197;&#32622;&#31649;&#29702;&#65292;&#20197;&#20415;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#36731;&#26494;&#20462;&#25913;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12289;&#29615;&#22659;&#21644;&#31639;&#27861;&#12290;&#19982;&#29616;&#26377;&#30340;&#19987;&#27880;&#20110;&#29305;&#23450;&#20219;&#21153;&#65288;&#22914;&#26053;&#34892;&#25512;&#38144;&#21592;&#38382;&#39064;&#65289;&#36827;&#34892;&#24615;&#33021;&#35780;&#20272;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#24378;&#35843;&#21487;&#25193;&#23637;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#23545;&#20110;&#21508;&#31181;&#20248;&#21270;&#20219;&#21153;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36824;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#21508;&#31181;&#27169;&#22411;&#22312;&#26679;&#26412;&#25928;&#29575;&#12289;&#38646;-shot&#27867;&#21270;&#21644;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19968;&#20123;&#26368;&#26032;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#22312;&#20351;&#29992;&#36825;&#20123;&#26032;&#25351;&#26631;&#36827;&#34892;&#35780;&#20272;&#26102;&#33853;&#21518;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#34920;&#26126;&#26377;&#24517;&#35201;&#26356;&#21152;&#24179;&#34913;&#22320;&#35780;&#20272;&#31070;&#32463;CO&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#24076;&#26395;RL4CO&#33021;&#22815;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#19968;&#20010;&#32508;&#21512;&#24615;&#30340;&#22522;&#20934;&#27979;&#35797;&#24037;&#20855;&#65292;&#20197;&#36827;&#19968;&#27493;&#25512;&#21160;&#24378;&#21270;&#23398;&#20064;&#22312;&#32452;&#21512;&#20248;&#21270;&#39046;&#22495;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark. RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms. Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks. We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models. Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers. We hope RL4CO will 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#20013;&#24213;&#23618;&#38382;&#39064;&#20026;&#24378;&#20984;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21152;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#25509;&#36817;&#26368;&#20248;&#30340;&#36895;&#29575;&#25910;&#25947;&#12290;&#36825;&#31181;&#31639;&#27861;&#36991;&#20813;&#20102;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26080;&#27861;&#33719;&#24471;&#25110;&#20195;&#20215;&#26114;&#36149;&#30340;Hessian-&#21521;&#37327;&#20056;&#31215;&#39044;&#35328;&#26426;&#30340;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.14853</link><description>&lt;p&gt;
&#36817;&#20284;&#26368;&#20248;&#38750;&#20984;-&#24378;&#20984;&#21452;&#23618;&#20248;&#21270;&#19982;&#20840;&#19968;&#38454;&#39044;&#35328;&#26426;
&lt;/p&gt;
&lt;p&gt;
Near-Optimal Nonconvex-Strongly-Convex Bilevel Optimization with Fully First-Order Oracles. (arXiv:2306.14853v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#20013;&#24213;&#23618;&#38382;&#39064;&#20026;&#24378;&#20984;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21152;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#25509;&#36817;&#26368;&#20248;&#30340;&#36895;&#29575;&#25910;&#25947;&#12290;&#36825;&#31181;&#31639;&#27861;&#36991;&#20813;&#20102;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26080;&#27861;&#33719;&#24471;&#25110;&#20195;&#20215;&#26114;&#36149;&#30340;Hessian-&#21521;&#37327;&#20056;&#31215;&#39044;&#35328;&#26426;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#12289;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#21644;&#20803;&#23398;&#20064;&#31561;&#39046;&#22495;&#26377;&#30528;&#24191;&#27867;&#24212;&#29992;&#12290;&#35774;&#35745;&#39640;&#25928;&#30340;&#21452;&#23618;&#20248;&#21270;&#31639;&#27861;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#24213;&#23618;&#38382;&#39064;&#36890;&#36807;&#21478;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#38544;&#24335;&#23450;&#20041;&#20102;&#19968;&#20010;&#21487;&#34892;&#24615;&#38598;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#26131;&#20110;&#22788;&#29702;&#30340;&#24773;&#20917;&#65292;&#21363;&#24213;&#23618;&#38382;&#39064;&#26159;&#24378;&#20984;&#30340;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;Hessian-&#21521;&#37327;&#20056;&#31215;&#39044;&#35328;&#26426;&#65292;&#21487;&#20197;&#22312;$\tilde{\mathcal{O}}(\epsilon^{-2})$&#20010;&#39044;&#35328;&#35843;&#29992;&#20869;&#21487;&#38752;&#22320;&#25214;&#21040;&#19968;&#20010;$\epsilon$-&#19968;&#38454;&#31283;&#23450;&#28857;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;Hessian-&#21521;&#37327;&#20056;&#31215;&#21487;&#33021;&#26080;&#27861;&#33719;&#24471;&#25110;&#20195;&#20215;&#26114;&#36149;&#12290;Kwon&#31561;&#20154;&#65288;ICML 2023&#65289;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#19968;&#38454;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20197;&#36739;&#24930;&#30340;$\tilde{\mathcal{O}}(\epsilon^{-3})$&#30340;&#36895;&#29575;&#23454;&#29616;&#30456;&#21516;&#30340;&#30446;&#26631;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26356;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20197;&#25509;&#36817;&#26368;&#20248;&#30340;$\tilde {\mathcal{O}}(\epsilon^{-2})$&#30340;&#36895;&#29575;&#20687;&#20108;&#38454;&#26041;&#27861;&#19968;&#26679;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization has wide applications such as hyperparameter tuning, neural architecture search, and meta-learning. Designing efficient algorithms for bilevel optimization is challenging because the lower-level problem defines a feasibility set implicitly via another optimization problem. In this work, we consider one tractable case when the lower-level problem is strongly convex. Recent works show that with a Hessian-vector product oracle, one can provably find an $\epsilon$-first-order stationary point within $\tilde{\mathcal{O}}(\epsilon^{-2})$ oracle calls. However, Hessian-vector product may be inaccessible or expensive in practice. Kwon et al. (ICML 2023) addressed this issue by proposing a first-order method that can achieve the same goal at a slower rate of $\tilde{\mathcal{O}}(\epsilon^{-3})$. In this work, we provide a tighter analysis demonstrating that this method can converge at the near-optimal $\tilde {\mathcal{O}}(\epsilon^{-2})$ rate as second-order methods. Our a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65292;&#21363;&#20854;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#65306;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#65292;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#30410;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#12290;</title><link>http://arxiv.org/abs/2306.04542</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65306;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#35774;&#35745;&#22522;&#30784;&#65292;&#21363;&#20854;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#65306;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#65292;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#30410;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36880;&#28176;&#28155;&#21152;&#21644;&#21024;&#38500;&#22122;&#22768;&#26469;&#23398;&#20064;&#35757;&#32451;&#25968;&#25454;&#30340;&#28508;&#22312;&#20998;&#24067;&#20197;&#29983;&#25104;&#25968;&#25454;&#12290;&#25193;&#25955;&#27169;&#22411;&#30340;&#32452;&#25104;&#37096;&#20998;&#24050;&#32463;&#21463;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#65292;&#35768;&#22810;&#35774;&#35745;&#36873;&#25321;&#34987;&#25552;&#20986;&#12290;&#29616;&#26377;&#30340;&#35780;&#35770;&#20027;&#35201;&#20851;&#27880;&#39640;&#23618;&#27425;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23545;&#32452;&#20214;&#30340;&#35774;&#35745;&#22522;&#30784;&#35206;&#30422;&#36739;&#23569;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#20840;&#38754;&#32780;&#36830;&#36143;&#30340;&#32508;&#36848;&#65292;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#32452;&#20214;&#35774;&#35745;&#36873;&#25321;&#36827;&#34892;&#20998;&#26512;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32508;&#36848;&#25353;&#29031;&#19977;&#20010;&#20851;&#38190;&#32452;&#20214;&#36827;&#34892;&#32452;&#32455;&#65292;&#21363;&#27491;&#21521;&#36807;&#31243;&#12289;&#36870;&#21521;&#36807;&#31243;&#21644;&#37319;&#26679;&#36807;&#31243;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#25552;&#20379;&#25193;&#25955;&#27169;&#22411;&#30340;&#32454;&#31890;&#24230;&#36879;&#35270;&#65292;&#26377;&#21161;&#20110;&#26410;&#26469;&#30740;&#31350;&#20998;&#26512;&#20010;&#20307;&#32452;&#20214;&#12289;&#35774;&#35745;&#36873;&#25321;&#30340;&#36866;&#29992;&#24615;&#20197;&#21450;&#25193;&#25955;&#27169;&#22411;&#30340;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are generative models, which gradually add and remove noise to learn the underlying distribution of training data for data generation. The components of diffusion models have gained significant attention with many design choices proposed. Existing reviews have primarily focused on higher-level solutions, thereby covering less on the design fundamentals of components. This study seeks to address this gap by providing a comprehensive and coherent review on component-wise design choices in diffusion models. Specifically, we organize this review according to their three key components, namely the forward process, the reverse process, and the sampling procedure. This allows us to provide a fine-grained perspective of diffusion models, benefiting future studies in the analysis of individual components, the applicability of design choices, and the implementation of diffusion models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#23457;&#31295;&#20154;&#20998;&#37197;&#38382;&#39064;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#31639;&#27861;&#38590;&#20197;&#36827;&#34892;&#21407;&#21017;&#27604;&#36739;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#22522;&#20110;&#27492;&#25968;&#25454;&#38598;&#30340;&#31639;&#27861;&#27604;&#36739;&#32467;&#26524;&#65292;&#20026;&#21033;&#30410;&#30456;&#20851;&#32773;&#22312;&#36873;&#25321;&#31639;&#27861;&#26041;&#38754;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2303.16750</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#23457;&#31295;&#20154;&#20998;&#37197;&#38382;&#39064;&#30340;&#40644;&#37329;&#26631;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
A Gold Standard Dataset for the Reviewer Assignment Problem. (arXiv:2303.16750v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16750
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#23457;&#31295;&#20154;&#20998;&#37197;&#38382;&#39064;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#31639;&#27861;&#38590;&#20197;&#36827;&#34892;&#21407;&#21017;&#27604;&#36739;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#22522;&#20110;&#27492;&#25968;&#25454;&#38598;&#30340;&#31639;&#27861;&#27604;&#36739;&#32467;&#26524;&#65292;&#20026;&#21033;&#30410;&#30456;&#20851;&#32773;&#22312;&#36873;&#25321;&#31639;&#27861;&#26041;&#38754;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#21516;&#34892;&#35780;&#23457;&#26399;&#21002;&#25110;&#20250;&#35758;&#27491;&#22312;&#20351;&#29992;&#25110;&#35797;&#22270;&#20351;&#29992;&#31639;&#27861;&#23558;&#25237;&#31295;&#20998;&#37197;&#32473;&#23457;&#31295;&#20154;&#12290;&#36825;&#20123;&#33258;&#21160;&#21270;&#26041;&#27861;&#30340;&#20851;&#38190;&#26159;&#8220;&#30456;&#20284;&#24230;&#20998;&#25968;&#8221;&#65292;&#21363;&#23545;&#23457;&#31295;&#20154;&#22312;&#23457;&#26597;&#35770;&#25991;&#20013;&#30340;&#19987;&#19994;&#27700;&#24179;&#30340;&#25968;&#20540;&#20272;&#35745;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#31639;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#20998;&#25968;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#23578;&#26410;&#32463;&#36807;&#26377;&#21407;&#21017;&#30340;&#27604;&#36739;&#65292;&#36825;&#20351;&#24471;&#21033;&#30410;&#30456;&#20851;&#32773;&#38590;&#20197;&#20197;&#22522;&#20110;&#35777;&#25454;&#30340;&#26041;&#24335;&#36873;&#25321;&#31639;&#27861;&#12290;&#27604;&#36739;&#29616;&#26377;&#31639;&#27861;&#21644;&#24320;&#21457;&#26356;&#22909;&#31639;&#27861;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#32570;&#20047;&#20844;&#24320;&#21487;&#29992;&#30340;&#40644;&#37329;&#26631;&#20934;&#25968;&#25454;&#65292;&#36825;&#20123;&#25968;&#25454;&#23558;&#29992;&#20110;&#36827;&#34892;&#21487;&#37325;&#22797;&#30740;&#31350;&#12290;&#25105;&#20204;&#36890;&#36807;&#25910;&#38598;&#19968;&#32452;&#26032;&#30340;&#30456;&#20284;&#24230;&#24471;&#20998;&#25968;&#25454;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#21457;&#24067;&#32473;&#30740;&#31350;&#31038;&#21306;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#30001;58&#20301;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#30340;477&#20010;&#33258;&#25105;&#25253;&#21578;&#30340;&#19987;&#19994;&#27700;&#24179;&#20998;&#25968;&#32452;&#25104;&#65292;&#29992;&#20110;&#35780;&#20272;&#20182;&#20204;&#20808;&#21069;&#38405;&#35835;&#30340;&#35770;&#25991;&#30340;&#23457;&#26597;&#32463;&#39564;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#25968;&#25454;&#26469;&#27604;&#36739;&#21508;&#31181;&#31639;&#27861;&#65292;&#24182;&#23545;&#26631;&#20934;&#25968;&#25454;&#38598;&#30340;&#35774;&#35745;&#25552;&#20986;&#20102;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many peer-review venues are either using or looking to use algorithms to assign submissions to reviewers. The crux of such automated approaches is the notion of the "similarity score"--a numerical estimate of the expertise of a reviewer in reviewing a paper--and many algorithms have been proposed to compute these scores. However, these algorithms have not been subjected to a principled comparison, making it difficult for stakeholders to choose the algorithm in an evidence-based manner. The key challenge in comparing existing algorithms and developing better algorithms is the lack of the publicly available gold-standard data that would be needed to perform reproducible research. We address this challenge by collecting a novel dataset of similarity scores that we release to the research community. Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously.  We use this data to compare s
&lt;/p&gt;</description></item></channel></rss>