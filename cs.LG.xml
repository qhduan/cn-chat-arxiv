<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Boosting&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.14890</link><description>&lt;p&gt;
Boosting&#29992;&#20110;&#30028;&#23450;&#26368;&#24046;&#20998;&#31867;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Boosting for Bounding the Worst-class Error. (arXiv:2310.14890v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14890
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Boosting&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#26368;&#24046;&#31867;&#21035;&#35823;&#24046;&#29575;&#30340;&#38382;&#39064;&#65292;&#32780;&#19981;&#26159;&#38024;&#23545;&#25152;&#26377;&#31867;&#21035;&#30340;&#26631;&#20934;&#35823;&#24046;&#29575;&#30340;&#24179;&#22343;&#12290;&#20363;&#22914;&#65292;&#19968;&#20010;&#19977;&#31867;&#21035;&#20998;&#31867;&#20219;&#21153;&#65292;&#20854;&#20013;&#21508;&#31867;&#21035;&#30340;&#35823;&#24046;&#29575;&#20998;&#21035;&#20026;10&#65285;&#65292;10&#65285;&#21644;40&#65285;&#65292;&#20854;&#26368;&#24046;&#31867;&#21035;&#35823;&#24046;&#29575;&#20026;40&#65285;&#65292;&#32780;&#22312;&#31867;&#21035;&#24179;&#34913;&#26465;&#20214;&#19979;&#30340;&#24179;&#22343;&#35823;&#24046;&#29575;&#20026;20&#65285;&#12290;&#26368;&#24046;&#31867;&#21035;&#38169;&#35823;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24456;&#37325;&#35201;&#12290;&#20363;&#22914;&#65292;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#23545;&#20110;&#24694;&#24615;&#32959;&#30244;&#31867;&#21035;&#20855;&#26377;40&#65285;&#30340;&#38169;&#35823;&#29575;&#32780;&#33391;&#24615;&#21644;&#20581;&#24247;&#31867;&#21035;&#20855;&#26377;10&#65285;&#30340;&#38169;&#35823;&#29575;&#26159;&#19981;&#33021;&#34987;&#25509;&#21463;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#35777;&#26368;&#24046;&#31867;&#21035;&#35757;&#32451;&#35823;&#24046;&#19978;&#30028;&#30340;&#25552;&#21319;&#31639;&#27861;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#27867;&#21270;&#30028;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#38477;&#20302;&#20102;&#26368;&#24046;&#31867;&#21035;&#30340;&#27979;&#35797;&#35823;&#24046;&#29575;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#23545;&#35757;&#32451;&#38598;&#30340;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper tackles the problem of the worst-class error rate, instead of the standard error rate averaged over all classes. For example, a three-class classification task with class-wise error rates of 10\%, 10\%, and 40\% has a worst-class error rate of 40\%, whereas the average is 20\% under the class-balanced condition. The worst-class error is important in many applications. For example, in a medical image classification task, it would not be acceptable for the malignant tumor class to have a 40\% error rate, while the benign and healthy classes have 10\% error rates.We propose a boosting algorithm that guarantees an upper bound of the worst-class training error and derive its generalization bound. Experimental results show that the algorithm lowers worst-class test error rates while avoiding overfitting to the training set.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#22238;&#24402;&#22330;&#26223;&#30340;&#39044;&#27979;&#38598;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#21306;&#22495;&#30340;&#32463;&#39564;&#29256;&#26412;&#22312;&#22823;&#26679;&#26412;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08209</link><description>&lt;p&gt;
&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#22238;&#24402;&#30340;&#19968;&#33268;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Conformal inference for regression on Riemannian Manifolds. (arXiv:2310.08209v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#22238;&#24402;&#22330;&#26223;&#30340;&#39044;&#27979;&#38598;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#21306;&#22495;&#30340;&#32463;&#39564;&#29256;&#26412;&#22312;&#22823;&#26679;&#26412;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27969;&#24418;&#19978;&#36827;&#34892;&#22238;&#24402;&#65292;&#20197;&#21450;&#26356;&#24191;&#27867;&#22320;&#35828;&#65292;&#23545;&#27969;&#24418;&#19978;&#30340;&#32479;&#35745;&#23398;&#26377;&#20102;&#37325;&#35201;&#30340;&#20851;&#27880;&#65292;&#22240;&#20026;&#36825;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#26377;&#22823;&#37327;&#30340;&#24212;&#29992;&#12290;&#22278;&#24418;&#25968;&#25454;&#26159;&#19968;&#20010;&#32463;&#20856;&#31034;&#20363;&#65292;&#20294;&#21327;&#26041;&#24046;&#30697;&#38453;&#31354;&#38388;&#19978;&#30340;&#25968;&#25454;&#12289;&#20027;&#25104;&#20998;&#20998;&#26512;&#24471;&#21040;&#30340;Grassmann&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#31561;&#20063;&#26159;&#22914;&#27492;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#21709;&#24212;&#21464;&#37327;$Y$&#20301;&#20110;&#27969;&#24418;&#19978;&#65292;&#32780;&#21327;&#21464;&#37327;$X$&#20301;&#20110;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#26102;&#65292;&#22238;&#24402;&#22330;&#26223;&#30340;&#39044;&#27979;&#38598;&#12290;&#36825;&#25193;&#23637;&#20102;[Lei and Wasserman, 2014]&#20013;&#22312;&#36825;&#19968;&#26032;&#39046;&#22495;&#20013;&#27010;&#36848;&#30340;&#27010;&#24565;&#12290;&#19982;&#19968;&#33268;&#25512;&#26029;&#20013;&#30340;&#20256;&#32479;&#21407;&#21017;&#19968;&#33268;&#65292;&#36825;&#20123;&#39044;&#27979;&#38598;&#26159;&#26080;&#20998;&#24067;&#30340;&#65292;&#34920;&#26126;&#23545;$(X, Y)$&#30340;&#32852;&#21512;&#20998;&#24067;&#27809;&#26377;&#26045;&#21152;&#29305;&#23450;&#30340;&#20551;&#35774;&#65292;&#32780;&#19988;&#23427;&#20204;&#20445;&#25345;&#38750;&#21442;&#25968;&#24615;&#36136;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#21306;&#22495;&#30340;&#32463;&#39564;&#29256;&#26412;&#22312;&#20960;&#20046;&#24517;&#28982;&#25910;&#25947;&#20110;&#26080;&#31351;&#22823;&#26102;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regression on manifolds, and, more broadly, statistics on manifolds, has garnered significant importance in recent years due to the vast number of applications for this type of data. Circular data is a classic example, but so is data in the space of covariance matrices, data on the Grassmannian manifold obtained as a result of principal component analysis, among many others. In this work we investigate prediction sets for regression scenarios when the response variable, denoted by $Y$, resides in a manifold, and the covariable, denoted by X, lies in Euclidean space. This extends the concepts delineated in [Lei and Wasserman, 2014] to this novel context. Aligning with traditional principles in conformal inference, these prediction sets are distribution-free, indicating that no specific assumptions are imposed on the joint distribution of $(X, Y)$, and they maintain a non-parametric character. We prove the asymptotic almost sure convergence of the empirical version of these regions on th
&lt;/p&gt;</description></item><item><title>Boolformer&#26159;&#31532;&#19968;&#20010;&#32463;&#36807;&#35757;&#32451;&#30340;Transformer&#26550;&#26500;&#65292;&#29992;&#20110;&#25191;&#34892;&#31471;&#21040;&#31471;&#30340;&#24067;&#23572;&#20989;&#25968;&#31526;&#21495;&#22238;&#24402;&#12290;&#23427;&#21487;&#20197;&#39044;&#27979;&#22797;&#26434;&#20989;&#25968;&#30340;&#31616;&#27905;&#20844;&#24335;&#65292;&#24182;&#22312;&#25552;&#20379;&#19981;&#23436;&#25972;&#21644;&#26377;&#22122;&#22768;&#35266;&#27979;&#26102;&#25214;&#21040;&#36817;&#20284;&#34920;&#36798;&#24335;&#12290;Boolformer&#22312;&#30495;&#23454;&#20108;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20986;&#28508;&#21147;&#20316;&#20026;&#21487;&#35299;&#37322;&#24615;&#26367;&#20195;&#26041;&#26696;&#65292;&#24182;&#22312;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#21160;&#21147;&#23398;&#24314;&#27169;&#20219;&#21153;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#36951;&#20256;&#31639;&#27861;&#30456;&#27604;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.12207</link><description>&lt;p&gt;
Boolformer: &#29992;Transformer&#36827;&#34892;&#36923;&#36753;&#20989;&#25968;&#30340;&#31526;&#21495;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Boolformer: Symbolic Regression of Logic Functions with Transformers. (arXiv:2309.12207v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12207
&lt;/p&gt;
&lt;p&gt;
Boolformer&#26159;&#31532;&#19968;&#20010;&#32463;&#36807;&#35757;&#32451;&#30340;Transformer&#26550;&#26500;&#65292;&#29992;&#20110;&#25191;&#34892;&#31471;&#21040;&#31471;&#30340;&#24067;&#23572;&#20989;&#25968;&#31526;&#21495;&#22238;&#24402;&#12290;&#23427;&#21487;&#20197;&#39044;&#27979;&#22797;&#26434;&#20989;&#25968;&#30340;&#31616;&#27905;&#20844;&#24335;&#65292;&#24182;&#22312;&#25552;&#20379;&#19981;&#23436;&#25972;&#21644;&#26377;&#22122;&#22768;&#35266;&#27979;&#26102;&#25214;&#21040;&#36817;&#20284;&#34920;&#36798;&#24335;&#12290;Boolformer&#22312;&#30495;&#23454;&#20108;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20986;&#28508;&#21147;&#20316;&#20026;&#21487;&#35299;&#37322;&#24615;&#26367;&#20195;&#26041;&#26696;&#65292;&#24182;&#22312;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#21160;&#21147;&#23398;&#24314;&#27169;&#20219;&#21153;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#36951;&#20256;&#31639;&#27861;&#30456;&#27604;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Boolformer&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#32463;&#36807;&#35757;&#32451;&#30340;Transformer&#26550;&#26500;&#65292;&#29992;&#20110;&#25191;&#34892;&#31471;&#21040;&#31471;&#30340;&#24067;&#23572;&#20989;&#25968;&#31526;&#21495;&#22238;&#24402;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#25552;&#20379;&#24178;&#20928;&#30340;&#30495;&#20540;&#34920;&#26102;&#65292;&#23427;&#21487;&#20197;&#39044;&#27979;&#22797;&#26434;&#20989;&#25968;&#30340;&#31616;&#27905;&#20844;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#25552;&#20379;&#19981;&#23436;&#25972;&#21644;&#26377;&#22122;&#22768;&#35266;&#27979;&#26102;&#25214;&#21040;&#36817;&#20284;&#34920;&#36798;&#24335;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#24191;&#27867;&#30340;&#30495;&#23454;&#20108;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;Boolformer&#65292;&#35777;&#26126;&#20102;&#23427;&#20316;&#20026;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#21487;&#35299;&#37322;&#24615;&#26367;&#20195;&#21697;&#30340;&#28508;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#24314;&#27169;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#21160;&#21147;&#23398;&#30340;&#24120;&#35265;&#20219;&#21153;&#12290;&#20351;&#29992;&#26368;&#36817;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Boolformer&#19982;&#26368;&#20808;&#36827;&#30340;&#36951;&#20256;&#31639;&#27861;&#30456;&#27604;&#65292;&#36895;&#24230;&#25552;&#39640;&#20102;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#27169;&#22411;&#20844;&#24320;&#21487;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce Boolformer, the first Transformer architecture trained to perform end-to-end symbolic regression of Boolean functions. First, we show that it can predict compact formulas for complex functions which were not seen during training, when provided a clean truth table. Then, we demonstrate its ability to find approximate expressions when provided incomplete and noisy observations. We evaluate the Boolformer on a broad set of real-world binary classification datasets, demonstrating its potential as an interpretable alternative to classic machine learning methods. Finally, we apply it to the widespread task of modelling the dynamics of gene regulatory networks. Using a recent benchmark, we show that Boolformer is competitive with state-of-the art genetic algorithms with a speedup of several orders of magnitude. Our code and models are available publicly.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#26469;&#28304;&#22270;&#21644;Transformer&#30340;&#39640;&#32423;&#25345;&#20037;&#24615;&#23041;&#32961;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;Transformer&#30340;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#25552;&#21462;&#31995;&#32479;&#29366;&#24577;&#30340;&#38271;&#26399;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26469;&#28304;&#20998;&#26512;&#23454;&#29616;&#23545;&#38271;&#26399;&#36816;&#34892;&#31995;&#32479;&#30340;&#27010;&#25324;&#65292;&#20197;&#26816;&#27979;&#32531;&#24930;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2304.02838</link><description>&lt;p&gt;
&#22522;&#20110;Transformer&#21644;&#26469;&#28304;&#22270;&#30340;&#39640;&#32423;&#25345;&#20037;&#24615;&#23041;&#32961;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph. (arXiv:2304.02838v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#26469;&#28304;&#22270;&#21644;Transformer&#30340;&#39640;&#32423;&#25345;&#20037;&#24615;&#23041;&#32961;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;Transformer&#30340;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#25552;&#21462;&#31995;&#32479;&#29366;&#24577;&#30340;&#38271;&#26399;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26469;&#28304;&#20998;&#26512;&#23454;&#29616;&#23545;&#38271;&#26399;&#36816;&#34892;&#31995;&#32479;&#30340;&#27010;&#25324;&#65292;&#20197;&#26816;&#27979;&#32531;&#24930;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#39640;&#32423;&#25345;&#20037;&#24615;&#23041;&#32961;&#65288;APT&#65289;&#25915;&#20987;&#30340;&#38271;&#26399;&#28508;&#20239;&#12289;&#38544;&#31192;&#22810;&#38454;&#27573;&#25915;&#20987;&#27169;&#24335;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;APT&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#26469;&#28304;&#22270;&#25552;&#20379;&#30340;&#21382;&#21490;&#20449;&#24687;&#36827;&#34892;APT&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;Transformer&#30340;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#25552;&#21462;&#31995;&#32479;&#29366;&#24577;&#30340;&#38271;&#26399;&#19978;&#19979;&#25991;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#26469;&#28304;&#20998;&#26512;&#23454;&#29616;&#23545;&#38271;&#26399;&#36816;&#34892;&#31995;&#32479;&#30340;&#27010;&#25324;&#65292;&#20197;&#26816;&#27979;&#32531;&#24930;&#25915;&#20987;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#24341;&#20837;&#20102;&#24322;&#24120;&#35780;&#20998;&#65292;&#21487;&#35780;&#20272;&#19981;&#21516;&#31995;&#32479;&#29366;&#24577;&#30340;&#24322;&#24120;&#24615;&#12290;&#27599;&#20010;&#29366;&#24577;&#37117;&#26377;&#30456;&#24212;&#30340;&#30456;&#20284;&#24230;&#21644;&#38548;&#31163;&#24230;&#20998;&#25968;&#30340;&#24322;&#24120;&#20998;&#25968;&#35745;&#31639;&#12290;&#20026;&#20102;&#35780;&#20272;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
APT detection is difficult to detect due to the long-term latency, covert and slow multistage attack patterns of Advanced Persistent Threat (APT). To tackle these issues, we propose TBDetector, a transformer-based advanced persistent threat detection method for APT attack detection. Considering that provenance graphs provide rich historical information and have the powerful attacks historic correlation ability to identify anomalous activities, TBDetector employs provenance analysis for APT detection, which summarizes long-running system execution with space efficiency and utilizes transformer with self-attention based encoder-decoder to extract long-term contextual features of system states to detect slow-acting attacks. Furthermore, we further introduce anomaly scores to investigate the anomaly of different system states, where each state is calculated with an anomaly score corresponding to its similarity score and isolation score. To evaluate the effectiveness of the proposed method,
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;&#29616;&#23454;&#19990;&#30028;&#20013;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#25968;&#25454;&#23548;&#21521;&#26550;&#26500;&#65288;DOA&#65289;&#30340;&#37319;&#29992;&#24773;&#20917;&#65292;&#21457;&#29616;&#23613;&#31649;&#27809;&#26377;&#26126;&#30830;&#25552;&#21450;DOA&#65292;&#20294;&#35768;&#22810;&#35770;&#25991;&#20013;&#30340;&#35774;&#35745;&#20915;&#31574;&#40664;&#40664;&#22320;&#36981;&#24490;&#20102;DOA&#30340;&#21407;&#21017;&#12290;</title><link>http://arxiv.org/abs/2302.04810</link><description>&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#65306;&#22522;&#20110;&#25968;&#25454;&#23548;&#21521;&#26550;&#26500;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Real-world Machine Learning Systems: A survey from a Data-Oriented Architecture Perspective. (arXiv:2302.04810v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;&#29616;&#23454;&#19990;&#30028;&#20013;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#25968;&#25454;&#23548;&#21521;&#26550;&#26500;&#65288;DOA&#65289;&#30340;&#37319;&#29992;&#24773;&#20917;&#65292;&#21457;&#29616;&#23613;&#31649;&#27809;&#26377;&#26126;&#30830;&#25552;&#21450;DOA&#65292;&#20294;&#35768;&#22810;&#35770;&#25991;&#20013;&#30340;&#35774;&#35745;&#20915;&#31574;&#40664;&#40664;&#22320;&#36981;&#24490;&#20102;DOA&#30340;&#21407;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;&#20154;&#24037;&#26234;&#33021;&#30340;&#20852;&#36259;&#19981;&#26029;&#22686;&#38271;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#27491;&#22312;&#20316;&#20026;&#29616;&#23454;&#19990;&#30028;&#31995;&#32479;&#30340;&#19968;&#37096;&#20998;&#37096;&#32626;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#35774;&#35745;&#12289;&#23454;&#29616;&#21644;&#32500;&#25252;&#21463;&#21040;&#29616;&#23454;&#19990;&#30028;&#29615;&#22659;&#30340;&#25361;&#25112;&#65292;&#36825;&#20123;&#29615;&#22659;&#20135;&#29983;&#20102;&#26356;&#22810;&#30340;&#24322;&#26500;&#25968;&#25454;&#65292;&#29992;&#25143;&#38656;&#35201;&#26356;&#24555;&#30340;&#21709;&#24212;&#36895;&#24230;&#21644;&#39640;&#25928;&#30340;&#36164;&#28304;&#28040;&#32791;&#12290;&#36825;&#20123;&#35201;&#27714;&#23558;&#26222;&#36941;&#23384;&#22312;&#30340;&#36719;&#20214;&#26550;&#26500;&#25512;&#21521;&#20102;&#26497;&#38480;&#65292;&#24403;&#37096;&#32626;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#31995;&#32479;&#26102;&#12290;&#25968;&#25454;&#23548;&#21521;&#26550;&#26500;&#65288;DOA&#65289;&#26159;&#19968;&#20010;&#26032;&#20852;&#30340;&#27010;&#24565;&#65292;&#23427;&#33021;&#26356;&#22909;&#22320;&#20026;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#31995;&#32479;&#25552;&#20379;&#25903;&#25345;&#12290;DOA&#25193;&#23637;&#20102;&#24403;&#21069;&#30340;&#26550;&#26500;&#65292;&#21019;&#24314;&#20102;&#25968;&#25454;&#39537;&#21160;&#12289;&#26494;&#32806;&#21512;&#12289;&#21435;&#20013;&#24515;&#21270;&#21644;&#24320;&#25918;&#30340;&#31995;&#32479;&#12290;&#23613;&#31649;&#37096;&#32626;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#35770;&#25991;&#20013;&#27809;&#26377;&#25552;&#21040;DOA&#65292;&#20294;&#23427;&#20204;&#30340;&#20316;&#32773;&#22312;&#35774;&#35745;&#19978;&#38544;&#21547;&#22320;&#36981;&#24490;&#20102;DOA&#12290;&#20026;&#20160;&#20040;&#12289;&#22914;&#20309;&#20197;&#21450;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#37319;&#29992;DOA&#22312;&#36825;&#20123;&#31995;&#32479;&#20013;&#23578;&#19981;&#28165;&#26970;&#12290;&#38544;&#21547;&#30340;&#35774;&#35745;&#20915;&#31574;&#38480;&#21046;&#20102;&#20174;&#19994;&#32773;&#23545;&#20110;&#35774;&#35745;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#31995;&#32479;&#26102;DOA&#30340;&#35748;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning models are being deployed as parts of real-world systems with the upsurge of interest in artificial intelligence. The design, implementation, and maintenance of such systems are challenged by real-world environments that produce larger amounts of heterogeneous data and users requiring increasingly faster responses with efficient resource consumption. These requirements push prevalent software architectures to the limit when deploying ML-based systems. Data-oriented Architecture (DOA) is an emerging concept that equips systems better for integrating ML models. DOA extends current architectures to create data-driven, loosely coupled, decentralised, open systems. Even though papers on deployed ML-based systems do not mention DOA, their authors made design decisions that implicitly follow DOA. The reasons why, how, and the extent to which DOA is adopted in these systems are unclear. Implicit design decisions limit the practitioners' knowledge of DOA to design ML-based syst
&lt;/p&gt;</description></item></channel></rss>