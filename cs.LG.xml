<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;&#65292;&#36890;&#36807;&#32534;&#36753;&#27169;&#22411;&#20869;&#37096;&#28608;&#27963;&#26469;&#25913;&#21892;CodeLLMs&#22312;&#20195;&#30721;&#31867;&#22411;&#39044;&#27979;&#20013;&#23545;&#20110;&#35821;&#27861;&#24178;&#25200;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#65292;&#23558;&#31867;&#22411;&#35823;&#24046;&#29575;&#32416;&#27491;&#39640;&#36798;90%&#12290;</title><link>https://arxiv.org/abs/2404.01903</link><description>&lt;p&gt;
&#22312;CodeLLMs&#20013;&#23454;&#29616;&#31867;&#22411;&#39044;&#27979;&#30340;&#40065;&#26834;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Activation Steering for Robust Type Prediction in CodeLLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01903
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;&#65292;&#36890;&#36807;&#32534;&#36753;&#27169;&#22411;&#20869;&#37096;&#28608;&#27963;&#26469;&#25913;&#21892;CodeLLMs&#22312;&#20195;&#30721;&#31867;&#22411;&#39044;&#27979;&#20013;&#23545;&#20110;&#35821;&#27861;&#24178;&#25200;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#65292;&#23558;&#31867;&#22411;&#35823;&#24046;&#29575;&#32416;&#27491;&#39640;&#36798;90%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#22312;&#20195;&#30721;&#19978;&#30340;&#29616;&#20195;LLMs&#33021;&#22815;&#25104;&#21151;&#22320;&#23436;&#25104;&#21508;&#31181;&#32534;&#31243;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#23545;&#35821;&#27861;&#29305;&#24449;&#38750;&#24120;&#25935;&#24863;&#65292;&#20363;&#22914;&#21464;&#37327;&#21644;&#31867;&#22411;&#30340;&#21517;&#31216;&#12289;&#20195;&#30721;&#32467;&#26500;&#20197;&#21450;&#31867;&#22411;&#25552;&#31034;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25512;&#29702;&#26102;&#25216;&#26415;&#65292;&#20351;CodeLLMs&#26356;&#33021;&#25269;&#24481;&#35821;&#27861;&#24178;&#25200;&#22240;&#32032;&#65292;&#36825;&#20123;&#22240;&#32032;&#19982;&#35821;&#20041;&#26080;&#20851;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#28608;&#27963;&#23548;&#21521;&#65292;&#28041;&#21450;&#32534;&#36753;&#20869;&#37096;&#27169;&#22411;&#28608;&#27963;&#20197;&#23558;&#27169;&#22411;&#24341;&#23548;&#21040;&#27491;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#20174;&#31361;&#21464;&#27979;&#35797;&#20013;&#27762;&#21462;&#28789;&#24863;&#26500;&#24314;&#28608;&#27963;&#21521;&#37327;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26500;&#24314;&#26368;&#23567;&#30340;&#30772;&#22351;&#35821;&#20041;&#30340;&#20195;&#30721;&#32534;&#36753;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#20174;&#20445;&#30041;&#35821;&#20041;&#30340;&#20195;&#30721;&#32534;&#36753;&#20013;&#26500;&#24314;&#28608;&#27963;&#21521;&#37327;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#36880;&#28176;&#31867;&#22411;&#21270;&#35821;&#35328;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#20219;&#21153;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#32416;&#27491;&#39640;&#36798;90%&#30340;&#31867;&#22411;&#38169;&#35823;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01903v1 Announce Type: new  Abstract: Contemporary LLMs pretrained on code are capable of succeeding at a wide variety of programming tasks. However, their performance is very sensitive to syntactic features, such as the names of variables and types, the structure of code, and presence of type hints. We contribute an inference-time technique to make CodeLLMs more robust to syntactic distractors that are semantically irrelevant. Our methodology relies on activation steering, which involves editing internal model activations to steer the model towards the correct prediction. We contribute a novel way to construct steering vectors by taking inspiration from mutation testing, which constructs minimal semantics-breaking code edits. In contrast, we construct steering vectors from semantics-preserving code edits. We apply our approach to the task of type prediction for the gradually typed languages Python and TypeScript. This approach corrects up to 90% of type mispredictions. Fina
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;</title><link>https://arxiv.org/abs/2402.17732</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;
&lt;/p&gt;
&lt;p&gt;
Batched Nonparametric Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17732
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#21160;&#20316;&#30340;&#26399;&#26395;&#22870;&#21169;&#34987;&#24314;&#27169;&#20026;&#21327;&#21464;&#37327;&#30340;&#24179;&#28369;&#20989;&#25968;&#65292;&#24182;&#19988;&#31574;&#30053;&#26356;&#26032;&#26159;&#22312;&#27599;&#20010;Observations&#25209;&#27425;&#32467;&#26463;&#26102;&#36827;&#34892;&#30340;&#12290;&#25105;&#20204;&#20026;&#36825;&#31181;&#35774;&#32622;&#24314;&#31435;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Batched Successive Elimination with Dynamic Binning&#65288;BaSEDB&#65289;&#30340;&#26041;&#26696;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21518;&#24724;&#65288;&#36798;&#21040;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#23454;&#36136;&#19978;&#65292;BaSEDB&#21160;&#24577;&#22320;&#23558;&#21327;&#21464;&#37327;&#31354;&#38388;&#20998;&#21106;&#25104;&#26356;&#23567;&#30340;&#31665;&#23376;&#65292;&#24182;&#20180;&#32454;&#35843;&#25972;&#23427;&#20204;&#30340;&#23485;&#24230;&#20197;&#31526;&#21512;&#25209;&#27425;&#22823;&#23567;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#38745;&#24577;&#20998;&#31665;&#30340;&#38750;&#26368;&#20248;&#24615;&#65292;&#31361;&#20986;&#20102;&#21160;&#24577;&#20998;&#31665;&#30340;&#24517;&#35201;&#24615;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23436;&#20840;&#22312;&#32447;&#35774;&#32622;&#20013;&#65292;&#20960;&#20046;&#24658;&#23450;&#25968;&#37327;&#30340;&#31574;&#30053;&#26356;&#26032;&#21487;&#20197;&#36798;&#21040;&#26368;&#20339;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17732v1 Announce Type: cross  Abstract: We study nonparametric contextual bandits under batch constraints, where the expected reward for each action is modeled as a smooth function of covariates, and the policy updates are made at the end of each batch of observations. We establish a minimax regret lower bound for this setting and propose Batched Successive Elimination with Dynamic Binning (BaSEDB) that achieves optimal regret (up to logarithmic factors). In essence, BaSEDB dynamically splits the covariate space into smaller bins, carefully aligning their widths with the batch size. We also show the suboptimality of static binning under batch constraints, highlighting the necessity of dynamic binning. Additionally, our results suggest that a nearly constant number of policy updates can attain optimal regret in the fully online setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24369;&#26465;&#20214;&#19979;&#33719;&#24471;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23454;&#29616;&#26041;&#24046;&#20943;&#23569;&#30340;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2402.08992</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#26041;&#24046;&#20943;&#23569;&#21644;&#20302;&#26679;&#26412;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Variance Reduction and Low Sample Complexity in Stochastic Optimization via Proximal Point Method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24369;&#26465;&#20214;&#19979;&#33719;&#24471;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23454;&#29616;&#26041;&#24046;&#20943;&#23569;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#36817;&#31471;&#28857;&#27861;&#26469;&#35299;&#20915;&#38543;&#26426;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#39640;&#27010;&#29575;&#32467;&#26524;&#36890;&#24120;&#20381;&#36182;&#20110;&#23545;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#20363;&#22914;&#23376;&#39640;&#26031;&#20998;&#24067;&#12290;&#26412;&#25991;&#21482;&#20551;&#35774;&#20102;&#38543;&#26426;&#26799;&#24230;&#30340;&#26377;&#30028;&#26041;&#24046;&#31561;&#24369;&#26465;&#20214;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#20197;&#33719;&#24471;&#20851;&#20110;&#25152;&#25552;&#26041;&#27861;&#25910;&#25947;&#30340;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#26412;&#24037;&#20316;&#30340;&#19968;&#20010;&#26174;&#33879;&#26041;&#38754;&#26159;&#21457;&#23637;&#20102;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#36817;&#31471;&#23376;&#38382;&#39064;&#30340;&#23376;&#31243;&#24207;&#65292;&#23427;&#21516;&#26102;&#20063;&#26159;&#19968;&#31181;&#29992;&#20110;&#20943;&#23569;&#26041;&#24046;&#30340;&#26032;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08992v1 Announce Type: cross Abstract: This paper proposes a stochastic proximal point method to solve a stochastic convex composite optimization problem. High probability results in stochastic optimization typically hinge on restrictive assumptions on the stochastic gradient noise, for example, sub-Gaussian distributions. Assuming only weak conditions such as bounded variance of the stochastic gradient, this paper establishes a low sample complexity to obtain a high probability guarantee on the convergence of the proposed method. Additionally, a notable aspect of this work is the development of a subroutine to solve the proximal subproblem, which also serves as a novel technique for variance reduction.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#24182;&#20272;&#35745;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2302.08854</link><description>&lt;p&gt;
&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Post-Episodic Reinforcement Learning Inference. (arXiv:2302.08854v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08854
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#24182;&#20272;&#35745;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25910;&#38598;&#30340;&#25968;&#25454;&#36827;&#34892;&#20272;&#35745;&#21644;&#25512;&#26029;&#65307;&#21363;&#22312;&#27599;&#20010;&#26102;&#26399;&#65288;&#20063;&#31216;&#20026;&#24773;&#33410;&#65289;&#20197;&#39034;&#24207;&#26041;&#24335;&#19982;&#21333;&#20010;&#21463;&#35797;&#21333;&#20803;&#22810;&#27425;&#20132;&#20114;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#25910;&#38598;&#25968;&#25454;&#21518;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#65292;&#24182;&#20272;&#35745;&#32467;&#26500;&#21442;&#25968;&#65292;&#22914;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36825;&#21487;&#20197;&#29992;&#20110;&#20449;&#29992;&#20998;&#37197;&#65288;&#20363;&#22914;&#65292;&#31532;&#19968;&#20010;&#26102;&#26399;&#30340;&#34892;&#21160;&#23545;&#26368;&#32456;&#32467;&#26524;&#30340;&#24433;&#21709;&#65289;&#12290;&#36825;&#20123;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#21487;&#20197;&#26500;&#25104;&#30697;&#26041;&#31243;&#30340;&#35299;&#65292;&#20294;&#19981;&#26159;&#24635;&#20307;&#25439;&#22833;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#22120;&#65292;&#22312;&#38745;&#24577;&#25968;&#25454;&#24773;&#20917;&#19979;&#23548;&#33268;&#20102;$Z$-&#20272;&#35745;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#20272;&#35745;&#37327;&#22312;&#33258;&#36866;&#24212;&#25968;&#25454;&#25910;&#38598;&#30340;&#24773;&#20917;&#19979;&#19981;&#33021;&#28176;&#36817;&#27491;&#24577;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#65292;&#20351;&#29992;&#31934;&#24515;&#35774;&#35745;&#30340;&#33258;&#36866;&#24212;&#26435;&#37325;&#26469;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#65292;&#36825;&#26159;&#30001;&#38750;...
&lt;/p&gt;
&lt;p&gt;
We consider estimation and inference with data collected from episodic reinforcement learning (RL) algorithms; i.e. adaptive experimentation algorithms that at each period (aka episode) interact multiple times in a sequential manner with a single treated unit. Our goal is to be able to evaluate counterfactual adaptive policies after data collection and to estimate structural parameters such as dynamic treatment effects, which can be used for credit assignment (e.g. what was the effect of the first period action on the final outcome). Such parameters of interest can be framed as solutions to moment equations, but not minimizers of a population loss function, leading to $Z$-estimation approaches in the case of static data. However, such estimators fail to be asymptotically normal in the case of adaptive data collection. We propose a re-weighted $Z$-estimation approach with carefully designed adaptive weights to stabilize the episode-varying estimation variance, which results from the non
&lt;/p&gt;</description></item></channel></rss>