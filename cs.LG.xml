<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20813;&#20808;&#39564;&#27491;&#26080;&#26631;&#23398;&#20064;&#30340;&#23545;&#27604;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#29305;&#24449;&#31354;&#38388;&#24182;&#21033;&#29992;&#23884;&#20837;&#30340;&#27987;&#24230;&#29305;&#24615;&#23545;&#26410;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#20266;&#26631;&#31614;&#22788;&#29702;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#22810;&#20010;&#26631;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#31867;&#20808;&#39564;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.06038</link><description>&lt;p&gt;
&#20813;&#20808;&#39564;&#27491;&#26080;&#26631;&#65288;Positive Unlabeled&#65289;&#23398;&#20064;&#30340;&#23545;&#27604;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Contrastive Approach to Prior Free Positive Unlabeled Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06038
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20813;&#20808;&#39564;&#27491;&#26080;&#26631;&#23398;&#20064;&#30340;&#23545;&#27604;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#29305;&#24449;&#31354;&#38388;&#24182;&#21033;&#29992;&#23884;&#20837;&#30340;&#27987;&#24230;&#29305;&#24615;&#23545;&#26410;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#20266;&#26631;&#31614;&#22788;&#29702;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#22810;&#20010;&#26631;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#31867;&#20808;&#39564;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#26080;&#26631;&#65288;Positive Unlabeled&#65289;&#23398;&#20064;&#26159;&#25351;&#22312;&#32473;&#23450;&#23569;&#37327;&#26631;&#35760;&#30340;&#27491;&#26679;&#26412;&#21644;&#19968;&#32452;&#26410;&#26631;&#35760;&#26679;&#26412;&#65288;&#21487;&#33021;&#26159;&#27491;&#20363;&#25110;&#36127;&#20363;&#65289;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#19968;&#20010;&#20108;&#20998;&#31867;&#22120;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27491;&#26080;&#26631;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20445;&#35777;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#23398;&#20064;&#29305;&#24449;&#31354;&#38388;&#65292;&#24182;&#21033;&#29992;&#23884;&#20837;&#30340;&#27987;&#24230;&#29305;&#24615;&#23545;&#26410;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#20266;&#26631;&#31614;&#22788;&#29702;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#26631;&#20934;&#27491;&#26080;&#26631;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36731;&#26494;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#27491;&#26080;&#26631;&#23398;&#20064;&#26041;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#31867;&#20808;&#39564;&#30340;&#20272;&#35745;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26631;&#35760;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#65292;&#32780;&#22823;&#22810;&#25968;&#27491;&#26080;&#26631;&#23398;&#20064;&#31639;&#27861;&#21017;&#22833;&#36133;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#31616;&#21333;&#30340;&#29702;&#35770;&#20998;&#26512;&#26469;&#25512;&#21160;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#65292;&#24182;&#20026;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#20102;&#19968;&#33324;&#21270;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Positive Unlabeled (PU) learning refers to the task of learning a binary classifier given a few labeled positive samples, and a set of unlabeled samples (which could be positive or negative). In this paper, we propose a novel PU learning framework, that starts by learning a feature space through pretext-invariant representation learning and then applies pseudo-labeling to the unlabeled examples, leveraging the concentration property of the embeddings. Overall, our proposed approach handily outperforms state-of-the-art PU learning methods across several standard PU benchmark datasets, while not requiring a-priori knowledge or estimate of class prior. Remarkably, our method remains effective even when labeled data is scant, where most PU learning algorithms falter. We also provide simple theoretical analysis motivating our proposed algorithms and establish generalization guarantee for our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#22122;&#22768;&#19987;&#23478;&#27169;&#22411;&#65288;ITEM&#65289;&#26469;&#35299;&#20915;&#26679;&#26412;&#36873;&#25321;&#20013;&#30340;&#35757;&#32451;&#20559;&#24046;&#21644;&#25968;&#25454;&#20559;&#24046;&#38382;&#39064;&#12290;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#40065;&#26834;&#30340;&#32593;&#32476;&#26550;&#26500;&#26469;&#38598;&#25104;&#22810;&#20010;&#19987;&#23478;&#65292;&#21487;&#20197;&#20943;&#23569;&#36873;&#25321;&#38598;&#19981;&#24179;&#34913;&#21644;&#32047;&#31215;&#38169;&#35823;&#65292;&#24182;&#22312;&#20351;&#29992;&#26356;&#23569;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26356;&#22909;&#30340;&#36873;&#25321;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.13360</link><description>&lt;p&gt;
&#23545;&#25239;&#22122;&#22768;&#26631;&#31614;&#30340;&#26080;&#20559;&#26679;&#26412;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Debiased Sample Selection for Combating Noisy Labels. (arXiv:2401.13360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#22122;&#22768;&#19987;&#23478;&#27169;&#22411;&#65288;ITEM&#65289;&#26469;&#35299;&#20915;&#26679;&#26412;&#36873;&#25321;&#20013;&#30340;&#35757;&#32451;&#20559;&#24046;&#21644;&#25968;&#25454;&#20559;&#24046;&#38382;&#39064;&#12290;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#40065;&#26834;&#30340;&#32593;&#32476;&#26550;&#26500;&#26469;&#38598;&#25104;&#22810;&#20010;&#19987;&#23478;&#65292;&#21487;&#20197;&#20943;&#23569;&#36873;&#25321;&#38598;&#19981;&#24179;&#34913;&#21644;&#32047;&#31215;&#38169;&#35823;&#65292;&#24182;&#22312;&#20351;&#29992;&#26356;&#23569;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26356;&#22909;&#30340;&#36873;&#25321;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20351;&#29992;&#22122;&#22768;&#26631;&#31614;&#26088;&#22312;&#30830;&#20445;&#27169;&#22411;&#22312;&#26631;&#31614;&#38169;&#35823;&#30340;&#35757;&#32451;&#38598;&#19978;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#12290;&#26679;&#26412;&#36873;&#25321;&#31574;&#30053;&#36890;&#36807;&#36873;&#25321;&#21487;&#38752;&#30340;&#26631;&#31614;&#23376;&#38598;&#26469;&#23454;&#29616;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#23454;&#35777;&#34920;&#26126;&#65292;&#29616;&#26377;&#30340;&#26679;&#26412;&#36873;&#25321;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#23384;&#22312;&#25968;&#25454;&#21644;&#35757;&#32451;&#20559;&#24046;&#65292;&#20998;&#21035;&#34920;&#31034;&#20026;&#36873;&#25321;&#38598;&#19981;&#24179;&#34913;&#21644;&#32047;&#31215;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#21482;&#22788;&#29702;&#20102;&#35757;&#32451;&#20559;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#26679;&#26412;&#36873;&#25321;&#30340;&#26080;&#22122;&#22768;&#19987;&#23478;&#27169;&#22411;&#65288;ITEM&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20026;&#20102;&#20943;&#36731;&#35757;&#32451;&#20559;&#24046;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#19982;&#22810;&#20010;&#19987;&#23478;&#38598;&#25104;&#12290;&#19982;&#30446;&#21069;&#30340;&#21452;&#20998;&#25903;&#32593;&#32476;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#32593;&#32476;&#22312;&#35757;&#32451;&#26356;&#23569;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#38598;&#25104;&#36825;&#20123;&#19987;&#23478;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#36873;&#25321;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#20026;&#20102;&#20943;&#36731;&#25968;&#25454;&#20559;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#37319;&#26679;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning with noisy labels aims to ensure model generalization given a label-corrupted training set. The sample selection strategy achieves promising performance by selecting a label-reliable subset for model training. In this paper, we empirically reveal that existing sample selection methods suffer from both data and training bias that are represented as imbalanced selected sets and accumulation errors in practice, respectively. However, only the training bias was handled in previous studies. To address this limitation, we propose a noIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection. Specifically, to mitigate the training bias, we design a robust network architecture that integrates with multiple experts. Compared with the prevailing double-branch network, our network exhibits better performance of selection and prediction by ensembling these experts while training with fewer parameters. Meanwhile, to mitigate the data bias, we propose a mixed sampling strat
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#37327;&#21270;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#65292;&#23545;&#20110;&#23494;&#24230;&#32858;&#31867;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.12806</link><description>&lt;p&gt;
DCSI -- &#22522;&#20110;&#20998;&#31163;&#21644;&#36830;&#36890;&#24615;&#30340;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
DCSI -- An improved measure of cluster separability based on separation and connectedness. (arXiv:2310.12806v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12806
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#37327;&#21270;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#65292;&#23545;&#20110;&#23494;&#24230;&#32858;&#31867;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#23450;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#30340;&#31867;&#21035;&#26631;&#31614;&#26159;&#21542;&#23545;&#24212;&#20110;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#23545;&#20110;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#38598;&#35780;&#20272;&#32858;&#31867;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#20010;&#29305;&#24615;&#21487;&#20197;&#36890;&#36807;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26469;&#37327;&#21270;&#12290;&#29616;&#26377;&#25991;&#29486;&#30340;&#32508;&#36848;&#26174;&#31034;&#65292;&#26082;&#26377;&#30340;&#22522;&#20110;&#20998;&#31867;&#30340;&#22797;&#26434;&#24615;&#24230;&#37327;&#26041;&#27861;&#21644;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631; (CVIs) &#37117;&#27809;&#26377;&#20805;&#20998;&#34701;&#20837;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#30340;&#26680;&#24515;&#29305;&#24449;&#65306;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#12290;&#19968;&#31181;&#26032;&#24320;&#21457;&#30340;&#24230;&#37327;&#26041;&#27861; (&#23494;&#24230;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#25351;&#25968;, DCSI) &#26088;&#22312;&#37327;&#21270;&#36825;&#20004;&#20010;&#29305;&#24449;&#65292;&#24182;&#19988;&#20063;&#21487;&#29992;&#20316; CVI&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;DCSI &#19982;&#36890;&#36807;&#35843;&#25972;&#20848;&#24503;&#25351;&#25968; (ARI) &#27979;&#37327;&#30340;DBSCAN&#30340;&#24615;&#33021;&#20043;&#38388;&#26377;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#65292;&#20294;&#22312;&#23545;&#22810;&#31867;&#25968;&#25454;&#38598;&#36827;&#34892;&#23494;&#24230;&#32858;&#31867;&#19981;&#36866;&#24403;&#30340;&#37325;&#21472;&#31867;&#21035;&#26102;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#23545;&#32463;&#24120;&#20351;&#29992;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#35814;&#32454;&#35780;&#20272;&#26174;&#31034;&#65292;DCSI &#33021;&#22815;&#26356;&#22909;&#22320;&#21306;&#20998;&#23494;&#24230;&#32858;&#31867;&#30340;&#21487;&#20998;&#31163;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether class labels in a given data set correspond to meaningful clusters is crucial for the evaluation of clustering algorithms using real-world data sets. This property can be quantified by separability measures. A review of the existing literature shows that neither classification-based complexity measures nor cluster validity indices (CVIs) adequately incorporate the central aspects of separability for density-based clustering: between-class separation and within-class connectedness. A newly developed measure (density cluster separability index, DCSI) aims to quantify these two characteristics and can also be used as a CVI. Extensive experiments on synthetic data indicate that DCSI correlates strongly with the performance of DBSCAN measured via the adjusted rand index (ARI) but lacks robustness when it comes to multi-class data sets with overlapping classes that are ill-suited for density-based hard clustering. Detailed evaluation on frequently used real-world data sets shows that
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#36890;&#36807;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#24341;&#20837;&#19981;&#21516;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#32780;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#21017;&#30001;&#36825;&#20123;&#29305;&#24449;&#25152;&#20915;&#23450;&#12290;</title><link>http://arxiv.org/abs/2310.07891</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks. (arXiv:2310.07891v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07891
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#36890;&#36807;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#24341;&#20837;&#19981;&#21516;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#32780;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#21017;&#30001;&#36825;&#20123;&#29305;&#24449;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#23398;&#20064;&#34987;&#35748;&#20026;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25104;&#21151;&#30340;&#22522;&#26412;&#21407;&#22240;&#20043;&#19968;&#12290;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#24050;&#32463;&#20005;&#26684;&#35777;&#26126;&#65292;&#22312;&#20004;&#23618;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#31532;&#19968;&#23618;&#36827;&#34892;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#65292;&#28982;&#21518;&#22312;&#31532;&#20108;&#23618;&#36827;&#34892;&#23725;&#22238;&#24402;&#21487;&#20197;&#23548;&#33268;&#29305;&#24449;&#23398;&#20064;&#65307;&#29305;&#24449;&#30697;&#38453;&#30340;&#35889;&#20013;&#20250;&#20986;&#29616;&#20998;&#31163;&#30340;&#19968;&#32500;&#32452;&#20214;&#65292;&#31216;&#20026;&#8220;spike&#8221;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#22266;&#23450;&#26799;&#24230;&#19979;&#38477;&#27493;&#38271;&#26102;&#65292;&#36825;&#20010;&#8220;spike&#8221;&#20165;&#25552;&#20379;&#20102;&#30446;&#26631;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#20214;&#30340;&#20449;&#24687;&#65292;&#22240;&#27492;&#23398;&#20064;&#38750;&#32447;&#24615;&#32452;&#20214;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23398;&#20064;&#29575;&#38543;&#26679;&#26412;&#22823;&#23567;&#22686;&#38271;&#26102;&#65292;&#36825;&#26679;&#30340;&#35757;&#32451;&#23454;&#38469;&#19978;&#24341;&#20837;&#20102;&#22810;&#20010;&#19968;&#32500;&#32452;&#20214;&#65292;&#27599;&#20010;&#32452;&#20214;&#23545;&#24212;&#19968;&#20010;&#29305;&#23450;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#26497;&#38480;&#22823;&#32500;&#24230;&#21644;&#22823;&#26679;&#26412;&#35757;&#32451;&#21644;&#27979;&#35797;&#35823;&#24046;&#23436;&#20840;&#30001;&#36825;&#20123;&#8220;spike&#8221;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature learning is thought to be one of the fundamental reasons for the success of deep neural networks. It is rigorously known that in two-layer fully-connected neural networks under certain conditions, one step of gradient descent on the first layer followed by ridge regression on the second layer can lead to feature learning; characterized by the appearance of a separated rank-one component -- spike -- in the spectrum of the feature matrix. However, with a constant gradient descent step size, this spike only carries information from the linear component of the target function and therefore learning non-linear components is impossible. We show that with a learning rate that grows with the sample size, such training in fact introduces multiple rank-one components, each corresponding to a specific polynomial feature. We further prove that the limiting large-dimensional and large sample training and test errors of the updated neural networks are fully characterized by these spikes. By 
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#20316;&#32773;&#23637;&#31034;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#29289;&#29702;&#30452;&#35273;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#23576;&#22467;&#31561;&#31163;&#23376;&#20307;&#23454;&#39564;&#20013;&#30340;&#21147;&#23398;&#35268;&#24459;&#12290;&#36890;&#36807;&#23545;&#31890;&#23376;&#36712;&#36857;&#30340;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#23545;&#31216;&#24615;&#21644;&#38750;&#30456;&#21516;&#31890;&#23376;&#20043;&#38388;&#30340;&#38750;&#20114;&#36870;&#21147;&#65292;&#24182;&#25552;&#21462;&#20102;&#27599;&#20010;&#31890;&#23376;&#30340;&#36136;&#37327;&#21644;&#30005;&#33655;&#12290;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#25351;&#31034;&#20986;&#23576;&#22467;&#31561;&#31163;&#23376;&#20307;&#20013;&#23384;&#22312;&#36229;&#20986;&#24403;&#21069;&#29702;&#35770;&#20998;&#36776;&#29575;&#30340;&#26032;&#29289;&#29702;&#65292;&#24182;&#23637;&#31034;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#24341;&#23548;&#22810;&#20307;&#31995;&#32479;&#31185;&#23398;&#21457;&#29616;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.05273</link><description>&lt;p&gt;
&#22312;&#22810;&#20307;&#31995;&#32479;&#20013;&#23398;&#20064;&#21147;&#23398;&#35268;&#24459;
&lt;/p&gt;
&lt;p&gt;
Learning force laws in many-body systems. (arXiv:2310.05273v1 [physics.plasm-ph] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05273
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#20316;&#32773;&#23637;&#31034;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#29289;&#29702;&#30452;&#35273;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#23576;&#22467;&#31561;&#31163;&#23376;&#20307;&#23454;&#39564;&#20013;&#30340;&#21147;&#23398;&#35268;&#24459;&#12290;&#36890;&#36807;&#23545;&#31890;&#23376;&#36712;&#36857;&#30340;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#23545;&#31216;&#24615;&#21644;&#38750;&#30456;&#21516;&#31890;&#23376;&#20043;&#38388;&#30340;&#38750;&#20114;&#36870;&#21147;&#65292;&#24182;&#25552;&#21462;&#20102;&#27599;&#20010;&#31890;&#23376;&#30340;&#36136;&#37327;&#21644;&#30005;&#33655;&#12290;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#25351;&#31034;&#20986;&#23576;&#22467;&#31561;&#31163;&#23376;&#20307;&#20013;&#23384;&#22312;&#36229;&#20986;&#24403;&#21069;&#29702;&#35770;&#20998;&#36776;&#29575;&#30340;&#26032;&#29289;&#29702;&#65292;&#24182;&#23637;&#31034;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#24341;&#23548;&#22810;&#20307;&#31995;&#32479;&#31185;&#23398;&#21457;&#29616;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25551;&#36848;&#33258;&#28982;&#31995;&#32479;&#30340;&#31185;&#23398;&#35268;&#24459;&#21487;&#33021;&#27604;&#25105;&#20204;&#30340;&#30452;&#35273;&#26356;&#22797;&#26434;&#65292;&#22240;&#27492;&#25105;&#20204;&#21457;&#29616;&#35268;&#24459;&#30340;&#26041;&#27861;&#24517;&#39035;&#25913;&#21464;&#12290;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#21487;&#20197;&#20998;&#26512;&#22823;&#37327;&#25968;&#25454;&#65292;&#20294;&#20854;&#32467;&#26500;&#24212;&#35813;&#31526;&#21512;&#22522;&#26412;&#30340;&#29289;&#29702;&#32422;&#26463;&#26465;&#20214;&#20197;&#25552;&#20379;&#26377;&#29992;&#30340;&#35265;&#35299;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#29289;&#29702;&#30452;&#35273;&#30340;ML&#26041;&#27861;&#65292;&#20197;&#25512;&#26029;&#23576;&#22467;&#31561;&#31163;&#23376;&#20307;&#23454;&#39564;&#20013;&#30340;&#21147;&#23398;&#27861;&#21017;&#12290;&#36890;&#36807;&#23545;3D&#31890;&#23376;&#36712;&#36857;&#36827;&#34892;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#22266;&#26377;&#30340;&#23545;&#31216;&#24615;&#21644;&#38750;&#30456;&#21516;&#31890;&#23376;&#20043;&#38388;&#30340;&#26377;&#25928;&#38750;&#20114;&#36870;&#21147;&#65292;&#24182;&#25552;&#21462;&#20986;&#27599;&#20010;&#31890;&#23376;&#30340;&#36136;&#37327;&#21644;&#30005;&#33655;&#12290;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65288;R^2 &gt; 0.99&#65289;&#25351;&#31034;&#20986;&#23576;&#22467;&#31561;&#31163;&#23376;&#20307;&#20013;&#36229;&#20986;&#24403;&#21069;&#29702;&#35770;&#20998;&#36776;&#29575;&#30340;&#26032;&#29289;&#29702;&#65292;&#24182;&#23637;&#31034;&#20102;&#26426;&#22120;&#23398;&#20064;&#39537;&#21160;&#30340;&#26041;&#27861;&#22914;&#20309;&#24341;&#23548;&#22810;&#20307;&#31995;&#32479;&#20013;&#30340;&#31185;&#23398;&#21457;&#29616;&#30340;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scientific laws describing natural systems may be more complex than our intuition can handle, and thus how we discover laws must change. Machine learning (ML) models can analyze large quantities of data, but their structure should match the underlying physical constraints to provide useful insight. Here we demonstrate a ML approach that incorporates such physical intuition to infer force laws in dusty plasma experiments. Trained on 3D particle trajectories, the model accounts for inherent symmetries and non-identical particles, accurately learns the effective non-reciprocal forces between particles, and extracts each particle's mass and charge. The model's accuracy (R^2 &gt; 0.99) points to new physics in dusty plasma beyond the resolution of current theories and demonstrates how ML-powered approaches can guide new routes of scientific discovery in many-body systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#20840;&#23616;&#26368;&#23567;&#20540;&#38468;&#36817;&#30340;&#32467;&#26500;&#21644;&#26799;&#24230;&#21160;&#21147;&#23398;&#65292;&#25581;&#31034;&#20102;&#20854;&#27867;&#21270;&#33021;&#21147;&#36739;&#24378;&#30340;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2309.00508</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20840;&#23616;&#26368;&#23567;&#20540;&#38468;&#36817;&#30340;&#32467;&#26500;&#21644;&#26799;&#24230;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Structure and Gradient Dynamics Near Global Minima of Two-layer Neural Networks. (arXiv:2309.00508v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#20840;&#23616;&#26368;&#23567;&#20540;&#38468;&#36817;&#30340;&#32467;&#26500;&#21644;&#26799;&#24230;&#21160;&#21147;&#23398;&#65292;&#25581;&#31034;&#20102;&#20854;&#27867;&#21270;&#33021;&#21147;&#36739;&#24378;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#20840;&#23616;&#26368;&#23567;&#20540;&#38468;&#36817;&#30340;&#25439;&#22833;&#20989;&#25968;&#34920;&#38754;&#30340;&#32467;&#26500;&#65292;&#30830;&#23450;&#20102;&#33021;&#22815;&#23454;&#29616;&#23436;&#32654;&#27867;&#21270;&#30340;&#21442;&#25968;&#38598;&#65292;&#24182;&#23436;&#25972;&#25551;&#36848;&#20102;&#20854;&#21608;&#22260;&#30340;&#26799;&#24230;&#27969;&#21160;&#24577;&#12290;&#36890;&#36807;&#26032;&#39062;&#30340;&#25216;&#26415;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#22797;&#26434;&#30340;&#25439;&#22833;&#20989;&#25968;&#34920;&#38754;&#30340;&#19968;&#20123;&#31616;&#21333;&#26041;&#38754;&#65292;&#24182;&#25581;&#31034;&#20102;&#27169;&#22411;&#12289;&#30446;&#26631;&#20989;&#25968;&#12289;&#26679;&#26412;&#21644;&#21021;&#22987;&#21270;&#23545;&#35757;&#32451;&#21160;&#21147;&#23398;&#30340;&#19981;&#21516;&#24433;&#21709;&#12290;&#22522;&#20110;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#65288;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#65289;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Under mild assumptions, we investigate the structure of loss landscape of two-layer neural networks near global minima, determine the set of parameters which give perfect generalization, and fully characterize the gradient flows around it. With novel techniques, our work uncovers some simple aspects of the complicated loss landscape and reveals how model, target function, samples and initialization affect the training dynamics differently. Based on these results, we also explain why (overparametrized) neural networks could generalize well.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#19981;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#21462;&#20998;&#23376;&#30456;&#20114;&#20316;&#29992;&#21644;&#36890;&#36335;&#30693;&#35782;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.08813</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#21462;&#20998;&#23376;&#30456;&#20114;&#20316;&#29992;&#21644;&#36890;&#36335;&#30693;&#35782;&#26041;&#38754;&#30340;&#27604;&#36739;&#24615;&#33021;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Comparative Performance Evaluation of Large Language Models for Extracting Molecular Interactions and Pathway Knowledge. (arXiv:2307.08813v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#19981;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#21462;&#20998;&#23376;&#30456;&#20114;&#20316;&#29992;&#21644;&#36890;&#36335;&#30693;&#35782;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#34507;&#30333;&#36136;&#30456;&#20114;&#20316;&#29992;&#21644;&#36890;&#36335;&#30693;&#35782;&#23545;&#20110;&#25581;&#31034;&#29983;&#29289;&#31995;&#32479;&#30340;&#22797;&#26434;&#24615;&#21644;&#30740;&#31350;&#29983;&#29289;&#21151;&#33021;&#21644;&#22797;&#26434;&#30142;&#30149;&#30340;&#22522;&#26412;&#26426;&#21046;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#29616;&#26377;&#30340;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#26469;&#33258;&#25991;&#29486;&#21644;&#20854;&#20182;&#28304;&#30340;&#31574;&#21010;&#29983;&#29289;&#25968;&#25454;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#19981;&#23436;&#25972;&#19988;&#32500;&#25252;&#24037;&#20316;&#32321;&#37325;&#65292;&#22240;&#27492;&#38656;&#35201;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#33258;&#21160;&#20174;&#30456;&#20851;&#31185;&#23398;&#25991;&#29486;&#20013;&#25552;&#21462;&#36825;&#20123;&#30693;&#35782;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#19981;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35782;&#21035;&#34507;&#30333;&#36136;&#30456;&#20114;&#20316;&#29992;&#12289;&#36890;&#36335;&#21644;&#22522;&#22240;&#35843;&#25511;&#20851;&#31995;&#31561;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#27169;&#22411;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#24443;&#24213;&#35780;&#20272;&#65292;&#31361;&#20986;&#20102;&#37325;&#35201;&#30340;&#21457;&#29616;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#31181;&#26041;&#27861;&#25152;&#38754;&#20020;&#30340;&#26410;&#26469;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#38142;&#25509;&#21487;&#22312;&#35770;&#25991;&#20013;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding protein interactions and pathway knowledge is crucial for unraveling the complexities of living systems and investigating the underlying mechanisms of biological functions and complex diseases. While existing databases provide curated biological data from literature and other sources, they are often incomplete and their maintenance is labor-intensive, necessitating alternative approaches. In this study, we propose to harness the capabilities of large language models to address these issues by automatically extracting such knowledge from the relevant scientific literature. Toward this goal, in this work, we investigate the effectiveness of different large language models in tasks that involve recognizing protein interactions, pathways, and gene regulatory relations. We thoroughly evaluate the performance of various models, highlight the significant findings, and discuss both the future opportunities and the remaining challenges associated with this approach. The code and d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26159;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#30740;&#31350;&#39046;&#22495;&#30340;&#31995;&#32479;&#32508;&#36848;&#65292;&#24635;&#32467;&#20102;&#26368;&#26032;&#26368;&#20808;&#36827;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#26377;&#21161;&#20110;&#20102;&#35299;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#20013;&#30340;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2307.06162</link><description>&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23545;&#29983;&#29702;&#20449;&#21495;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Deep Generative Models for Physiological Signals: A Systematic Literature Review. (arXiv:2307.06162v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#30740;&#31350;&#39046;&#22495;&#30340;&#31995;&#32479;&#32508;&#36848;&#65292;&#24635;&#32467;&#20102;&#26368;&#26032;&#26368;&#20808;&#36827;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#26377;&#21161;&#20110;&#20102;&#35299;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#20013;&#30340;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#29983;&#29702;&#20449;&#21495;&#65292;&#29305;&#21035;&#26159;&#24515;&#30005;&#22270;&#12289;&#33041;&#30005;&#22270;&#12289;&#20809;&#30005;&#23481;&#25239;&#22270;&#21644;&#32908;&#30005;&#22270;&#39046;&#22495;&#30340;&#25991;&#29486;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#12290;&#19982;&#24050;&#26377;&#30340;&#32508;&#36848;&#25991;&#31456;&#30456;&#27604;&#65292;&#26412;&#25991;&#26159;&#31532;&#19968;&#31687;&#24635;&#32467;&#26368;&#26032;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#32508;&#36848;&#12290;&#36890;&#36807;&#20998;&#26512;&#19982;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30456;&#20851;&#30340;&#26368;&#26032;&#30740;&#31350;&#65292;&#20197;&#21450;&#36825;&#20123;&#27169;&#22411;&#30340;&#20027;&#35201;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#26412;&#32508;&#36848;&#20026;&#23545;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#29983;&#29702;&#20449;&#21495;&#30340;&#25972;&#20307;&#29702;&#35299;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24378;&#35843;&#37319;&#29992;&#30340;&#35780;&#20272;&#21327;&#35758;&#21644;&#26368;&#24120;&#29992;&#30340;&#29983;&#29702;&#25968;&#25454;&#24211;&#65292;&#26412;&#32508;&#36848;&#26377;&#21161;&#20110;&#23545;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a systematic literature review on deep generative models for physiological signals, particularly electrocardiogram, electroencephalogram, photoplethysmogram and electromyogram. Compared to the existing review papers, we present the first review that summarizes the recent state-of-the-art deep generative models. By analysing the state-of-the-art research related to deep generative models along with their main applications and challenges, this review contributes to the overall understanding of these models applied to physiological signals. Additionally, by highlighting the employed evaluation protocol and the most used physiological databases, this review facilitates the assessment and benchmarking of deep generative models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#26377;&#38480;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;&#21450;&#20854;&#26222;&#36866;&#24615;&#65292;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26377;&#38480;&#32593;&#32476;&#20013;&#20173;&#28982;&#23384;&#22312;&#30528;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#36807;&#28193;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#20250;&#21453;&#26144;&#22312;&#36807;&#28193;&#30340;&#26222;&#36866;&#31867;&#19978;&#12290;</title><link>http://arxiv.org/abs/2307.02284</link><description>&lt;p&gt;
&#20154;&#24037;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;
&lt;/p&gt;
&lt;p&gt;
Absorbing Phase Transitions in Artificial Deep Neural Networks. (arXiv:2307.02284v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#26377;&#38480;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;&#21450;&#20854;&#26222;&#36866;&#24615;&#65292;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26377;&#38480;&#32593;&#32476;&#20013;&#20173;&#28982;&#23384;&#22312;&#30528;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#36807;&#28193;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#20250;&#21453;&#26144;&#22312;&#36807;&#28193;&#30340;&#26222;&#36866;&#31867;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#33879;&#21517;&#30340;&#24179;&#22343;&#22330;&#29702;&#35770;&#65292;&#23545;&#20110;&#21508;&#31181;&#20307;&#31995;&#30340;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#30340;&#29702;&#35770;&#29702;&#35299;&#24050;&#32463;&#36805;&#36895;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26356;&#23454;&#38469;&#21644;&#29616;&#23454;&#37325;&#35201;&#24615;&#26356;&#24378;&#30340;&#26377;&#38480;&#32593;&#32476;&#65292;&#32570;&#20047;&#28165;&#26224;&#30452;&#35266;&#30340;&#26694;&#26550;&#26469;&#24310;&#20280;&#25105;&#20204;&#30340;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#21487;&#20197;&#29992;&#21560;&#25910;&#30456;&#21464;&#20013;&#30340;&#26222;&#36941;&#20020;&#30028;&#29616;&#35937;&#26469;&#29702;&#35299;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#30456;&#21464;&#65292;&#24182;&#24378;&#35843;&#20102;&#20307;&#31995;&#26550;&#26500;&#30340;&#24046;&#24322;&#19982;&#30456;&#21464;&#30340;&#26222;&#36866;&#31867;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#36824;&#25104;&#21151;&#22320;&#24212;&#29992;&#20102;&#26377;&#38480;&#23610;&#24230;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#36825;&#34920;&#26126;&#20102;&#30452;&#35266;&#30340;&#29616;&#35937;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical understanding of the behavior of infinitely-wide neural networks has been rapidly developed for various architectures due to the celebrated mean-field theory. However, there is a lack of a clear, intuitive framework for extending our understanding to finite networks that are of more practical and realistic importance. In the present contribution, we demonstrate that the behavior of properly initialized neural networks can be understood in terms of universal critical phenomena in absorbing phase transitions. More specifically, we study the order-to-chaos transition in the fully-connected feedforward neural networks and the convolutional ones to show that (i) there is a well-defined transition from the ordered state to the chaotics state even for the finite networks, and (ii) difference in architecture is reflected in that of the universality class of the transition. Remarkably, the finite-size scaling can also be successfully applied, indicating that intuitive phenomenologic
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;&#26412;&#22320;&#22788;&#29702;&#22120;&#27665;&#20027;&#8221;&#30340;&#31639;&#27861;Cooperator&#65292;&#35813;&#31639;&#27861;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#34920;&#29616;&#27604;Transformer&#31639;&#27861;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.10449</link><description>&lt;p&gt;
&#21512;&#20316;&#26159;&#20320;&#25152;&#38656;&#35201;&#30340;&#12290; &#65288;arXiv:2305.10449v1 [cs.LG]&#65289;
&lt;/p&gt;
&lt;p&gt;
Cooperation Is All You Need. (arXiv:2305.10449v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10449
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;&#26412;&#22320;&#22788;&#29702;&#22120;&#27665;&#20027;&#8221;&#30340;&#31639;&#27861;Cooperator&#65292;&#35813;&#31639;&#27861;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#34920;&#29616;&#27604;Transformer&#31639;&#27861;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36229;&#36234;&#8220;&#26641;&#31361;&#27665;&#20027;&#8221;&#20043;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;Cooperator&#30340;&#8220;&#26412;&#22320;&#22788;&#29702;&#22120;&#27665;&#20027;&#8221;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23558;&#23427;&#20204;&#19982;&#22522;&#20110;Transformers&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65288;&#20363;&#22914;ChatGPT&#65289;&#22312;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#30340;&#21151;&#33021;&#36827;&#34892;&#27604;&#36739;&#12290; Transformers&#22522;&#20110;&#38271;&#26399;&#20197;&#26469;&#30340;&#8220;&#31215;&#20998;-&#21457;&#23556;&#8221;&#8220;&#28857;&#8221;&#31070;&#32463;&#20803;&#30340;&#27010;&#24565;&#65292;&#32780;Cooperator&#21017;&#21463;&#21040;&#26368;&#36817;&#31070;&#32463;&#29983;&#29289;&#23398;&#31361;&#30772;&#30340;&#21551;&#31034;&#65292;&#36825;&#20123;&#31361;&#30772;&#34920;&#26126;&#65292;&#31934;&#31070;&#29983;&#27963;&#30340;&#32454;&#32990;&#22522;&#30784;&#21462;&#20915;&#20110;&#26032;&#30382;&#23618;&#20013;&#20855;&#26377;&#20004;&#20010;&#21151;&#33021;&#19978;&#19981;&#21516;&#28857;&#30340;&#19978;&#30382;&#31070;&#32463;&#20803;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#29992;&#20110;RL&#26102;&#65292;&#22522;&#20110;Cooperator&#30340;&#31639;&#27861;&#23398;&#20064;&#36895;&#24230;&#27604;&#22522;&#20110;Transformer&#30340;&#31639;&#27861;&#24555;&#24471;&#22810;&#65292;&#21363;&#20351;&#23427;&#20204;&#20855;&#26377;&#30456;&#21516;&#25968;&#37327;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Going beyond 'dendritic democracy', we introduce a 'democracy of local processors', termed Cooperator. Here we compare their capabilities when used in permutation-invariant neural networks for reinforcement learning (RL), with machine learning algorithms based on Transformers, such as ChatGPT. Transformers are based on the long-standing conception of integrate-and-fire 'point' neurons, whereas Cooperator is inspired by recent neurobiological breakthroughs suggesting that the cellular foundations of mental life depend on context-sensitive pyramidal neurons in the neocortex which have two functionally distinct points. We show that when used for RL, an algorithm based on Cooperator learns far quicker than that based on Transformer, even while having the same number of parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2303.08431</link><description>&lt;p&gt;
&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25910;&#25947;&#20110;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#30340;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Converges to the Globally Optimal Policy for Nearly Linear-Quadratic Regulators. (arXiv:2303.08431v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#21482;&#33719;&#24471;&#20102;&#38750;&#23436;&#25972;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#25511;&#21046;&#31995;&#32479;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#25214;&#21040;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#21160;&#24577;&#31995;&#32479;&#65292;&#32467;&#21512;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#30001;&#30456;&#21516;&#32467;&#26500;&#30340;&#31574;&#30053;&#36827;&#34892;&#31649;&#29702;&#12290;&#22312;&#20551;&#35774;&#38750;&#32447;&#24615;&#32452;&#25104;&#37096;&#20998;&#21253;&#21547;&#20855;&#26377;&#23567;&#22411;Lipschitz&#31995;&#25968;&#30340;&#20869;&#26680;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#25104;&#26412;&#20989;&#25968;&#30340;&#20248;&#21270;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#34429;&#28982;&#25104;&#26412;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#20984;&#30340;&#65292;&#20294;&#25105;&#20204;&#30830;&#31435;&#20102;&#20840;&#23616;&#26368;&#20248;&#35299;&#38468;&#36817;&#23616;&#37096;&#30340;&#24378;&#20984;&#24615;&#21644;&#20809;&#28369;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21021;&#22987;&#21270;&#26426;&#21046;&#65292;&#20197;&#21033;&#29992;&#36825;&#20123;&#23646;&#24615;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonlinear control systems with partial information to the decision maker are prevalent in a variety of applications. As a step toward studying such nonlinear systems, this work explores reinforcement learning methods for finding the optimal policy in the nearly linear-quadratic regulator systems. In particular, we consider a dynamic system that combines linear and nonlinear components, and is governed by a policy with the same structure. Assuming that the nonlinear component comprises kernels with small Lipschitz coefficients, we characterize the optimization landscape of the cost function. Although the cost function is nonconvex in general, we establish the local strong convexity and smoothness in the vicinity of the global optimizer. Additionally, we propose an initialization mechanism to leverage these properties. Building on the developments, we design a policy gradient algorithm that is guaranteed to converge to the globally optimal policy with a linear rate.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#33258;&#31169;&#34892;&#20026;&#19979;&#30340;&#21163;&#21290;&#31038;&#20132;&#23398;&#20064;&#38382;&#39064;&#65292;&#21457;&#29616;&#23384;&#22312;&#19968;&#31181;&#25506;&#32034;&#28608;&#21169;&#26435;&#34913;&#65292;&#21363;&#27494;&#22120;&#25506;&#32034;&#21644;&#31038;&#20132;&#25506;&#32034;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#21463;&#21040;&#20195;&#29702;&#30340;&#30701;&#35270;&#34892;&#20026;&#30340;&#38480;&#21046;&#20250;&#21152;&#21095;&#36825;&#31181;&#26435;&#34913;&#65292;&#24182;&#23548;&#33268;&#36951;&#25022;&#29575;&#19982;&#20195;&#29702;&#25968;&#37327;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.07425</link><description>&lt;p&gt;
&#33258;&#31169;&#34892;&#20026;&#19979;&#30340;&#21163;&#21290;&#31038;&#20132;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bandit Social Learning: Exploration under Myopic Behavior. (arXiv:2302.07425v2 [cs.GT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07425
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#33258;&#31169;&#34892;&#20026;&#19979;&#30340;&#21163;&#21290;&#31038;&#20132;&#23398;&#20064;&#38382;&#39064;&#65292;&#21457;&#29616;&#23384;&#22312;&#19968;&#31181;&#25506;&#32034;&#28608;&#21169;&#26435;&#34913;&#65292;&#21363;&#27494;&#22120;&#25506;&#32034;&#21644;&#31038;&#20132;&#25506;&#32034;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#21463;&#21040;&#20195;&#29702;&#30340;&#30701;&#35270;&#34892;&#20026;&#30340;&#38480;&#21046;&#20250;&#21152;&#21095;&#36825;&#31181;&#26435;&#34913;&#65292;&#24182;&#23548;&#33268;&#36951;&#25022;&#29575;&#19982;&#20195;&#29702;&#25968;&#37327;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31038;&#20132;&#23398;&#20064;&#21160;&#24577;&#65292;&#20854;&#20013;&#20195;&#29702;&#25353;&#29031;&#31616;&#21333;&#30340;&#22810;&#33218;&#21163;&#21290;&#21327;&#35758;&#20849;&#21516;&#34892;&#21160;&#12290;&#20195;&#29702;&#20197;&#39034;&#24207;&#26041;&#24335;&#21040;&#36798;&#65292;&#36873;&#25321;&#27494;&#22120;&#24182;&#25509;&#25910;&#30456;&#20851;&#22870;&#21169;&#12290;&#27599;&#20010;&#20195;&#29702;&#35266;&#23519;&#20808;&#21069;&#20195;&#29702;&#30340;&#23436;&#25972;&#21382;&#21490;&#35760;&#24405;&#65288;&#27494;&#22120;&#21644;&#22870;&#21169;&#65289;&#65292;&#19981;&#23384;&#22312;&#31169;&#26377;&#20449;&#21495;&#12290;&#23613;&#31649;&#20195;&#29702;&#20849;&#21516;&#38754;&#20020;&#24320;&#21457;&#21644;&#21033;&#29992;&#30340;&#25506;&#32034;&#25240;&#34935;&#65292;&#20294;&#27599;&#20010;&#20195;&#29702;&#20154;&#37117;&#26159;&#19968;&#35265;&#38047;&#24773;&#30340;&#65292;&#26080;&#38656;&#32771;&#34385;&#25506;&#32034;&#12290;&#25105;&#20204;&#20801;&#35768;&#19968;&#31995;&#21015;&#19982;&#65288;&#21442;&#25968;&#21270;&#65289;&#32622;&#20449;&#21306;&#38388;&#19968;&#33268;&#30340;&#33258;&#31169;&#34892;&#20026;&#65292;&#21253;&#25324;&#8220;&#26080;&#20559;&#8221;&#34892;&#20026;&#21644;&#21508;&#31181;&#34892;&#20026;&#20559;&#24046;&#12290;&#34429;&#28982;&#36825;&#20123;&#34892;&#20026;&#30340;&#26497;&#31471;&#29256;&#26412;&#23545;&#24212;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#21163;&#21290;&#31639;&#27861;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#20102;&#26356;&#28201;&#21644;&#30340;&#29256;&#26412;&#20250;&#23548;&#33268;&#26126;&#26174;&#30340;&#25506;&#32034;&#22833;&#36133;&#65292;&#22240;&#27492;&#36951;&#25022;&#29575;&#19982;&#20195;&#29702;&#25968;&#37327;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#8220;&#28201;&#21644;&#20048;&#35266;&#8221;&#30340;&#20195;&#29702;&#25552;&#20379;&#21305;&#37197;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#25506;&#32034;&#28608;&#21169;&#20043;&#38388;&#30340;&#22522;&#26412;&#26435;&#34913;&#65306;&#27494;&#22120;&#25506;&#32034;&#26159;&#22266;&#26377;&#20110;&#21163;&#21290;&#38382;&#39064;&#30340;&#65292;&#21482;&#21463;&#24403;&#21069;&#20195;&#29702;&#30340;&#34892;&#21160;&#24433;&#21709;&#65292;&#32780;&#31038;&#20132;&#25506;&#32034;&#26159;&#30001;&#20808;&#21069;&#20195;&#29702;&#34892;&#20026;&#39537;&#21160;&#30340;&#65292;&#22240;&#27492;&#26377;&#21033;&#20110;&#26410;&#26469;&#20195;&#29702;&#12290;&#30001;&#20110;&#20195;&#29702;&#30340;&#30701;&#35270;&#34892;&#20026;&#38480;&#21046;&#20102;&#31038;&#20132;&#25506;&#32034;&#65292;&#36825;&#31181;&#26435;&#34913;&#34987;&#21152;&#21095;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study social learning dynamics where the agents collectively follow a simple multi-armed bandit protocol. Agents arrive sequentially, choose arms and receive associated rewards. Each agent observes the full history (arms and rewards) of the previous agents, and there are no private signals. While collectively the agents face exploration-exploitation tradeoff, each agent acts myopically, without regards to exploration. Motivating scenarios concern reviews and ratings on online platforms.  We allow a wide range of myopic behaviors that are consistent with (parameterized) confidence intervals, including the "unbiased" behavior as well as various behaviorial biases. While extreme versions of these behaviors correspond to well-known bandit algorithms, we prove that more moderate versions lead to stark exploration failures, and consequently to regret rates that are linear in the number of agents. We provide matching upper bounds on regret by analyzing "moderately optimistic" agents.  As a
&lt;/p&gt;</description></item><item><title>&#35774;&#35745;&#20102;&#19968;&#20010;DL&#27169;&#22411;&#26694;&#26550;&#65292;&#21517;&#20026;&#22240;&#26524;&#31070;&#32463;&#31639;&#23376;&#65288;CNO&#65289;&#65292;&#20197;&#36924;&#36817;&#22240;&#26524;&#31639;&#23376;&#65288;CO&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;CNO&#27169;&#22411;&#21487;&#20197;&#22312;&#32039;&#33268;&#38598;&#19978;&#19968;&#33268;&#36924;&#36817;H&#246;lder&#25110;&#24179;&#28369;&#36857;&#31867;&#31639;&#23376;&#12290;</title><link>http://arxiv.org/abs/2210.13300</link><description>&lt;p&gt;
&#35774;&#35745;&#36890;&#29992;&#22240;&#26524;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65306;&#20197;&#38543;&#26426;&#20998;&#26512;&#20013;&#30340;&#26080;&#38480;&#32500;&#21160;&#24577;&#31995;&#32479;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Designing Universal Causal Deep Learning Models: The Case of Infinite-Dimensional Dynamical Systems from Stochastic Analysis. (arXiv:2210.13300v2 [math.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13300
&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20102;&#19968;&#20010;DL&#27169;&#22411;&#26694;&#26550;&#65292;&#21517;&#20026;&#22240;&#26524;&#31070;&#32463;&#31639;&#23376;&#65288;CNO&#65289;&#65292;&#20197;&#36924;&#36817;&#22240;&#26524;&#31639;&#23376;&#65288;CO&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;CNO&#27169;&#22411;&#21487;&#20197;&#22312;&#32039;&#33268;&#38598;&#19978;&#19968;&#33268;&#36924;&#36817;H&#246;lder&#25110;&#24179;&#28369;&#36857;&#31867;&#31639;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#31639;&#23376;&#65288;CO&#65289;&#22312;&#24403;&#20195;&#38543;&#26426;&#20998;&#26512;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#65292;&#20363;&#22914;&#21508;&#31181;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#31639;&#23376;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#19968;&#20010;&#33021;&#22815;&#36924;&#36817;CO&#30340;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#27169;&#22411;&#30340;&#35268;&#33539;&#26694;&#26550;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;DL&#27169;&#22411;&#35774;&#35745;&#26694;&#26550;&#26469;&#25552;&#20986;&#19968;&#20010;&#8220;&#20960;&#20309;&#24863;&#30693;&#8221;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26694;&#26550;&#20197;&#21512;&#36866;&#30340;&#26080;&#38480;&#32500;&#32447;&#24615;&#24230;&#37327;&#31354;&#38388;&#20026;&#36755;&#20837;&#65292;&#24182;&#36820;&#22238;&#36866;&#24212;&#36825;&#20123;&#32447;&#24615;&#20960;&#20309;&#30340;&#36890;&#29992;&#36830;&#32493;&#24207;&#21015;DL&#27169;&#22411;&#12290;&#25105;&#20204;&#31216;&#36825;&#20123;&#27169;&#22411;&#20026;&#22240;&#26524;&#31070;&#32463;&#31639;&#23376;&#65288;CNO&#65289;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#25152;&#20135;&#29983;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#32039;&#33268;&#38598;&#19978;&#21644;&#36328;&#20219;&#24847;&#26377;&#38480;&#26102;&#38388;&#35270;&#37326;&#19978;&#19968;&#33268;&#36924;&#36817;H&#246;lder&#25110;&#24179;&#28369;&#36857;&#31867;&#31639;&#23376;&#65292;&#36825;&#20123;&#31639;&#23376;&#22240;&#26524;&#22320;&#26144;&#23556;&#32473;&#23450;&#32447;&#24615;&#24230;&#37327;&#31354;&#38388;&#20043;&#38388;&#30340;&#24207;&#21015;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#20851;&#20110;CNO&#30340;&#28508;&#22312;&#29366;&#24577;&#31354;&#38388;&#32500;&#24230;&#30340;&#26032;&#23450;&#37327;&#20851;&#31995;&#65292;&#29978;&#33267;&#23545;&#20110;&#65288;&#32463;&#20856;&#30340;&#65289;&#26377;&#38480;&#32500;DL&#27169;&#22411;&#20063;&#26377;&#26032;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal operators (CO), such as various solution operators to stochastic differential equations, play a central role in contemporary stochastic analysis; however, there is still no canonical framework for designing Deep Learning (DL) models capable of approximating COs. This paper proposes a "geometry-aware'" solution to this open problem by introducing a DL model-design framework that takes suitable infinite-dimensional linear metric spaces as inputs and returns a universal sequential DL model adapted to these linear geometries. We call these models Causal Neural Operators (CNOs). Our main result states that the models produced by our framework can uniformly approximate on compact sets and across arbitrarily finite-time horizons H\"older or smooth trace class operators, which causally map sequences between given linear metric spaces. Our analysis uncovers new quantitative relationships on the latent state-space dimension of CNOs which even have new implications for (classical) finite-d
&lt;/p&gt;</description></item></channel></rss>