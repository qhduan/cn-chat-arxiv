<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#38754;&#20020;&#30340;&#19981;&#24179;&#34913;&#12289;&#22122;&#22768;&#12289;&#38544;&#31169;&#21644;OOD&#25361;&#25112;&#65292;&#24182;&#33268;&#21147;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12289;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04468</link><description>&lt;p&gt;
&#20851;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#35843;&#26597;&#65306;&#19981;&#24179;&#34913;&#12289;&#22122;&#22768;&#12289;&#38544;&#31169;&#21644;OOD&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A Survey of Graph Neural Networks in Real world: Imbalance, Noise, Privacy and OOD Challenges
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#38754;&#20020;&#30340;&#19981;&#24179;&#34913;&#12289;&#22122;&#22768;&#12289;&#38544;&#31169;&#21644;OOD&#25361;&#25112;&#65292;&#24182;&#33268;&#21147;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12289;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04468v1 &#21457;&#24067;&#31867;&#22411;: &#36328;&#22495; &#25688;&#35201;: &#22270;&#32467;&#26500;&#21270;&#25968;&#25454;&#34920;&#29616;&#20986;&#26222;&#36866;&#24615;&#21644;&#24191;&#27867;&#36866;&#29992;&#24615;&#65292;&#28085;&#30422;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#12289;&#29983;&#29289;&#21270;&#23398;&#12289;&#37329;&#34701;&#27450;&#35784;&#26816;&#27979;&#21644;&#32593;&#32476;&#23433;&#20840;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;&#22312;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#21462;&#24471;&#26174;&#33879;&#25104;&#21151;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#27169;&#22411;&#30340;&#35757;&#32451;&#29615;&#22659;&#24448;&#24448;&#36828;&#38750;&#29702;&#24819;&#65292;&#30001;&#20110;&#21508;&#31181;&#19981;&#21033;&#22240;&#32032;&#65292;&#21253;&#25324;&#25968;&#25454;&#20998;&#24067;&#19981;&#24179;&#34913;&#12289;&#38169;&#35823;&#25968;&#25454;&#20013;&#23384;&#22312;&#22122;&#22768;&#12289;&#25935;&#24863;&#20449;&#24687;&#30340;&#38544;&#31169;&#20445;&#25252;&#20197;&#21450;&#23545;&#20110;OOD&#22330;&#26223;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#23548;&#33268;GNN&#27169;&#22411;&#30340;&#24615;&#33021;&#22823;&#24133;&#19979;&#38477;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20154;&#20204;&#33268;&#21147;&#20110;&#25913;&#21892;GNN&#27169;&#22411;&#22312;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013;&#30340;&#24615;&#33021;&#65292;&#25552;&#39640;&#20854;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#26412;&#25991;&#20840;&#38754;&#35843;&#26597;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04468v1 Announce Type: cross  Abstract: Graph-structured data exhibits universality and widespread applicability across diverse domains, such as social network analysis, biochemistry, financial fraud detection, and network security. Significant strides have been made in leveraging Graph Neural Networks (GNNs) to achieve remarkable success in these areas. However, in real-world scenarios, the training environment for models is often far from ideal, leading to substantial performance degradation of GNN models due to various unfavorable factors, including imbalance in data distribution, the presence of noise in erroneous data, privacy protection of sensitive information, and generalization capability for out-of-distribution (OOD) scenarios. To tackle these issues, substantial efforts have been devoted to improving the performance of GNN models in practical real-world scenarios, as well as enhancing their reliability and robustness. In this paper, we present a comprehensive surv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;AI&#36719;&#20214;&#21644;&#30828;&#20214;&#24212;&#29992;&#20110;&#25968;&#20540;&#24314;&#27169;&#39046;&#22495;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21033;&#29992;AI&#26041;&#27861;&#65292;&#22914;CNN&#65292;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26631;&#20934;&#25805;&#20316;&#65292;&#24102;&#26469;&#39640;&#24615;&#33021;&#12289;&#26550;&#26500;&#19981;&#21487;&#30693;&#24615;&#21644;&#26131;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.17913</link><description>&lt;p&gt;
&#20351;&#29992;AI&#24211;&#36827;&#34892;&#19981;&#21487;&#21387;&#32553;&#35745;&#31639;&#27969;&#20307;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Using AI libraries for Incompressible Computational Fluid Dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;AI&#36719;&#20214;&#21644;&#30828;&#20214;&#24212;&#29992;&#20110;&#25968;&#20540;&#24314;&#27169;&#39046;&#22495;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21033;&#29992;AI&#26041;&#27861;&#65292;&#22914;CNN&#65292;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26631;&#20934;&#25805;&#20316;&#65292;&#24102;&#26469;&#39640;&#24615;&#33021;&#12289;&#26550;&#26500;&#19981;&#21487;&#30693;&#24615;&#21644;&#26131;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20154;&#20204;&#33268;&#21147;&#20110;&#24320;&#21457;&#39640;&#25928;&#24320;&#28304;&#24211;&#65292;&#20197;&#22312;&#19981;&#21516;&#30340;&#35745;&#31639;&#26426;&#26550;&#26500;&#65288;&#20363;&#22914;CPU&#12289;GPU&#21644;&#26032;&#30340;AI&#22788;&#29702;&#22120;&#65289;&#19978;&#25191;&#34892;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#30456;&#20851;&#30340;&#35745;&#31639;&#12290;&#36825;&#19981;&#20165;&#20351;&#22522;&#20110;&#36825;&#20123;&#24211;&#30340;&#31639;&#27861;&#39640;&#25928;&#32780;&#19988;&#22312;&#19981;&#21516;&#26550;&#26500;&#20043;&#38388;&#21487;&#31227;&#26893;&#65292;&#36824;&#22823;&#22823;&#31616;&#21270;&#20102;&#20351;&#29992;AI&#24320;&#21457;&#26041;&#27861;&#30340;&#38376;&#27099;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#35770;&#65292;&#23558;AI&#36719;&#20214;&#21644;&#30828;&#20214;&#30340;&#24378;&#22823;&#21151;&#33021;&#24102;&#20837;&#25968;&#20540;&#24314;&#27169;&#39046;&#22495;&#65292;&#23558;AI&#26041;&#27861;&#65288;&#22914;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;CNN&#65289;&#37325;&#26032;&#29992;&#20110;&#25968;&#20540;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26631;&#20934;&#25805;&#20316;&#12290;&#26412;&#24037;&#20316;&#30340;&#30446;&#26631;&#26159;&#23558;&#39640;&#24615;&#33021;&#12289;&#26550;&#26500;&#19981;&#21487;&#30693;&#24615;&#21644;&#26131;&#29992;&#24615;&#24341;&#20837;&#25968;&#20540;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#20915;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17913v1 Announce Type: cross  Abstract: Recently, there has been a huge effort focused on developing highly efficient open source libraries to perform Artificial Intelligence (AI) related computations on different computer architectures (for example, CPUs, GPUs and new AI processors). This has not only made the algorithms based on these libraries highly efficient and portable between different architectures, but also has substantially simplified the entry barrier to develop methods using AI. Here, we present a novel methodology to bring the power of both AI software and hardware into the field of numerical modelling by repurposing AI methods, such as Convolutional Neural Networks (CNNs), for the standard operations required in the field of the numerical solution of Partial Differential Equations (PDEs). The aim of this work is to bring the high performance, architecture agnosticism and ease of use into the field of the numerical solution of PDEs. We use the proposed methodol
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#38598;&#27604;&#36739;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#33258;&#21160;&#30456;&#20851;&#24615;&#26816;&#27979;&#26435;&#37325;&#26469;&#22686;&#24378;&#27979;&#35797;&#30340;&#21151;&#25928;&#65292;&#24182;&#24341;&#20837;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#27491;&#21017;&#21270;&#21442;&#25968;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.01537</link><description>&lt;p&gt;
&#22312;&#21487;&#35299;&#37322;&#30340;&#20998;&#24067;&#27604;&#36739;&#20013;&#30340;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Variable Selection in Maximum Mean Discrepancy for Interpretable Distribution Comparison. (arXiv:2311.01537v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01537
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#38598;&#27604;&#36739;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#33258;&#21160;&#30456;&#20851;&#24615;&#26816;&#27979;&#26435;&#37325;&#26469;&#22686;&#24378;&#27979;&#35797;&#30340;&#21151;&#25928;&#65292;&#24182;&#24341;&#20837;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#27491;&#21017;&#21270;&#21442;&#25968;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20004;&#26679;&#26412;&#27979;&#35797;&#26159;&#20026;&#20102;&#21028;&#26029;&#20004;&#20010;&#25968;&#25454;&#38598;&#26159;&#21542;&#26469;&#33258;&#21516;&#19968;&#20998;&#24067;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#26679;&#26412;&#27979;&#35797;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#21363;&#35782;&#21035;&#36896;&#25104;&#20004;&#20010;&#20998;&#24067;&#24046;&#24322;&#30340;&#21464;&#37327;&#65288;&#25110;&#32500;&#24230;&#65289;&#30340;&#20219;&#21153;&#12290;&#36825;&#20010;&#20219;&#21153;&#19982;&#27169;&#24335;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#35768;&#22810;&#38382;&#39064;&#30456;&#20851;&#65292;&#22914;&#25968;&#25454;&#38598;&#28418;&#31227;&#36866;&#24212;&#12289;&#22240;&#26524;&#25512;&#26029;&#21644;&#27169;&#22411;&#39564;&#35777;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;&#12290;&#25105;&#20204;&#20248;&#21270;&#38024;&#23545;&#21508;&#20010;&#21464;&#37327;&#23450;&#20041;&#30340;&#33258;&#21160;&#30456;&#20851;&#24615;&#26816;&#27979;&#65288;ARD&#65289;&#26435;&#37325;&#65292;&#20197;&#26368;&#22823;&#21270;&#22522;&#20110;MMD&#30340;&#26816;&#39564;&#30340;&#21151;&#29575;&#12290;&#23545;&#20110;&#36825;&#31181;&#20248;&#21270;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31232;&#30095;&#27491;&#21017;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36873;&#25321;&#36866;&#24403;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#38382;&#39064;&#12290;&#19968;&#31181;&#26041;&#27861;&#26159;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#30830;&#23450;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#21478;&#19968;&#31181;&#26041;&#27861;&#26159;&#21512;&#24182;&#19981;&#21516;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#30830;&#35748;&#20102;&#36825;&#20010;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two-sample testing decides whether two datasets are generated from the same distribution. This paper studies variable selection for two-sample testing, the task being to identify the variables (or dimensions) responsible for the discrepancies between the two distributions. This task is relevant to many problems of pattern analysis and machine learning, such as dataset shift adaptation, causal inference and model validation. Our approach is based on a two-sample test based on the Maximum Mean Discrepancy (MMD). We optimise the Automatic Relevance Detection (ARD) weights defined for individual variables to maximise the power of the MMD-based test. For this optimisation, we introduce sparse regularisation and propose two methods for dealing with the issue of selecting an appropriate regularisation parameter. One method determines the regularisation parameter in a data-driven way, and the other aggregates the results of different regularisation parameters. We confirm the validity of the pr
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#33021;&#22815;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#23616;&#37096;&#21306;&#22495;&#65292;&#25913;&#21892;&#25972;&#20010;&#31995;&#32479;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2301.11375</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#21306;&#22495;
&lt;/p&gt;
&lt;p&gt;
Neural networks learn to magnify areas near decision boundaries. (arXiv:2301.11375v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11375
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#33021;&#22815;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#23616;&#37096;&#21306;&#22495;&#65292;&#25913;&#21892;&#25972;&#20010;&#31995;&#32479;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#35757;&#32451;&#22914;&#20309;&#22609;&#36896;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#22270;&#35825;&#23548;&#30340;&#40654;&#26364;&#20960;&#20309;&#12290;&#22312;&#23485;&#24230;&#20026;&#26080;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#38543;&#26426;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#36755;&#20837;&#31354;&#38388;&#19978;&#24341;&#23548;&#39640;&#24230;&#23545;&#31216;&#30340;&#24230;&#37327;&#12290;&#35757;&#32451;&#20998;&#31867;&#20219;&#21153;&#30340;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#23398;&#20064;&#25918;&#22823;&#20102;&#27839;&#20915;&#31574;&#36793;&#30028;&#30340;&#23616;&#37096;&#21306;&#22495;&#12290;&#36825;&#20123;&#21464;&#21270;&#19982;&#20808;&#21069;&#25552;&#20986;&#30340;&#29992;&#20110;&#25163;&#21160;&#35843;&#25972;&#26680;&#26041;&#27861;&#20197;&#25913;&#21892;&#27867;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how training molds the Riemannian geometry induced by neural network feature maps. At infinite width, neural networks with random parameters induce highly symmetric metrics on input space. Feature learning in networks trained to perform classification tasks magnifies local areas along decision boundaries. These changes are consistent with previously proposed geometric approaches for hand-tuning of kernel methods to improve generalization.
&lt;/p&gt;</description></item></channel></rss>