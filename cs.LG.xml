<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#21327;&#20316;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DC-DML&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20445;&#25252;&#20998;&#24067;&#24335;&#25968;&#25454;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#65288;CATE&#65289;&#27169;&#22411;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#35813;&#26041;&#27861;&#30340;&#19977;&#20010;&#20027;&#35201;&#36129;&#29486;&#26159;&#65306;&#23454;&#29616;&#20102;&#23545;&#20998;&#24067;&#24335;&#25968;&#25454;&#19978;&#30340;&#38750;&#36845;&#20195;&#36890;&#20449;&#30340;&#21322;&#21442;&#25968;CATE&#27169;&#22411;&#30340;&#20272;&#35745;&#21644;&#27979;&#35797;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02672</link><description>&lt;p&gt;
&#23545;&#20998;&#24067;&#24335;&#25968;&#25454;&#30340;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#65306;&#19968;&#31181;&#20445;&#25252;&#38544;&#31169;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Estimation of conditional average treatment effects on distributed data: A privacy-preserving approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02672
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#21327;&#20316;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DC-DML&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20445;&#25252;&#20998;&#24067;&#24335;&#25968;&#25454;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#65288;CATE&#65289;&#27169;&#22411;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#35813;&#26041;&#27861;&#30340;&#19977;&#20010;&#20027;&#35201;&#36129;&#29486;&#26159;&#65306;&#23454;&#29616;&#20102;&#23545;&#20998;&#24067;&#24335;&#25968;&#25454;&#19978;&#30340;&#38750;&#36845;&#20195;&#36890;&#20449;&#30340;&#21322;&#21442;&#25968;CATE&#27169;&#22411;&#30340;&#20272;&#35745;&#21644;&#27979;&#35797;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#31561;&#21508;&#20010;&#39046;&#22495;&#20013;&#65292;&#23545;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#65288;CATEs&#65289;&#30340;&#20272;&#35745;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#35838;&#39064;&#12290;&#22914;&#26524;&#20998;&#24067;&#22312;&#22810;&#20010;&#21442;&#19982;&#26041;&#20043;&#38388;&#30340;&#25968;&#25454;&#21487;&#20197;&#38598;&#20013;&#65292;&#21487;&#20197;&#23545;CATEs&#36827;&#34892;&#39640;&#31934;&#24230;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22914;&#26524;&#36825;&#20123;&#25968;&#25454;&#21253;&#21547;&#38544;&#31169;&#20449;&#24687;&#65292;&#21017;&#24456;&#38590;&#36827;&#34892;&#25968;&#25454;&#32858;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#25454;&#21327;&#20316;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DC-DML&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20445;&#25252;&#20998;&#24067;&#24335;&#25968;&#25454;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;CATE&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23545;&#35813;&#26041;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#24635;&#32467;&#22914;&#19979;&#19977;&#28857;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#25968;&#25454;&#19978;&#36827;&#34892;&#38750;&#36845;&#20195;&#36890;&#20449;&#30340;&#21322;&#21442;&#25968;CATE&#27169;&#22411;&#30340;&#20272;&#35745;&#21644;&#27979;&#35797;&#12290;&#21322;&#21442;&#25968;&#25110;&#38750;&#21442;&#25968;&#30340;CATE&#27169;&#22411;&#33021;&#22815;&#27604;&#21442;&#25968;&#27169;&#22411;&#26356;&#31283;&#20581;&#22320;&#36827;&#34892;&#20272;&#35745;&#21644;&#27979;&#35797;&#65292;&#23545;&#20110;&#27169;&#22411;&#20559;&#24046;&#30340;&#40065;&#26834;&#24615;&#26356;&#24378;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#25552;&#20986;&#26377;&#25928;&#30340;&#36890;&#20449;&#26041;&#27861;&#26469;&#20272;&#35745;&#21644;&#27979;&#35797;&#36825;&#20123;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimation of conditional average treatment effects (CATEs) is an important topic in various fields such as medical and social sciences. CATEs can be estimated with high accuracy if distributed data across multiple parties can be centralized. However, it is difficult to aggregate such data if they contain privacy information. To address this issue, we proposed data collaboration double machine learning (DC-DML), a method that can estimate CATE models with privacy preservation of distributed data, and evaluated the method through numerical experiments. Our contributions are summarized in the following three points. First, our method enables estimation and testing of semi-parametric CATE models without iterative communication on distributed data. Semi-parametric or non-parametric CATE models enable estimation and testing that is more robust to model mis-specification than parametric models. However, to our knowledge, no communication-efficient method has been proposed for estimating and 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#20302;&#36164;&#28304;&#23433;&#20840;&#25915;&#20987;&#27169;&#24335;&#35782;&#21035;&#21305;&#37197;&#26694;&#26550;&#65292;&#36890;&#36807;&#30452;&#25509;&#35821;&#20041;&#30456;&#20284;&#24230;&#20915;&#23450;&#25991;&#26412;&#19982;&#25915;&#20987;&#27169;&#24335;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#20197;&#38477;&#20302;&#22823;&#37327;&#31867;&#21035;&#12289;&#26631;&#31614;&#20998;&#24067;&#19981;&#22343;&#21644;&#26631;&#31614;&#31354;&#38388;&#22797;&#26434;&#24615;&#24102;&#26469;&#30340;&#23398;&#20064;&#38590;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.10337</link><description>&lt;p&gt;
&#22522;&#20110;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#20302;&#36164;&#28304;&#23433;&#20840;&#25915;&#20987;&#27169;&#24335;&#35782;&#21035;&#21305;&#37197;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10337
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#20302;&#36164;&#28304;&#23433;&#20840;&#25915;&#20987;&#27169;&#24335;&#35782;&#21035;&#21305;&#37197;&#26694;&#26550;&#65292;&#36890;&#36807;&#30452;&#25509;&#35821;&#20041;&#30456;&#20284;&#24230;&#20915;&#23450;&#25991;&#26412;&#19982;&#25915;&#20987;&#27169;&#24335;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#20197;&#38477;&#20302;&#22823;&#37327;&#31867;&#21035;&#12289;&#26631;&#31614;&#20998;&#24067;&#19981;&#22343;&#21644;&#26631;&#31614;&#31354;&#38388;&#22797;&#26434;&#24615;&#24102;&#26469;&#30340;&#23398;&#20064;&#38590;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25112;&#26415;&#12289;&#25216;&#26415;&#21644;&#31243;&#24207;&#65288;TTPs&#65289;&#26159;&#32593;&#32476;&#23433;&#20840;&#39046;&#22495;&#20013;&#22797;&#26434;&#30340;&#25915;&#20987;&#27169;&#24335;&#65292;&#22312;&#25991;&#26412;&#30693;&#35782;&#24211;&#20013;&#26377;&#35814;&#32454;&#30340;&#25551;&#36848;&#12290;&#22312;&#32593;&#32476;&#23433;&#20840;&#20889;&#20316;&#20013;&#35782;&#21035;TTPs&#65292;&#36890;&#24120;&#31216;&#20026;TTP&#26144;&#23556;&#65292;&#26159;&#19968;&#20010;&#37325;&#35201;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20256;&#32479;&#30340;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#20197;&#32463;&#20856;&#30340;&#22810;&#31867;&#25110;&#22810;&#26631;&#31614;&#20998;&#31867;&#35774;&#32622;&#20026;&#30446;&#26631;&#12290;&#30001;&#20110;&#23384;&#22312;&#22823;&#37327;&#30340;&#31867;&#21035;&#65288;&#21363;TTPs&#65289;&#65292;&#26631;&#31614;&#20998;&#24067;&#30340;&#19981;&#22343;&#34913;&#21644;&#26631;&#31614;&#31354;&#38388;&#30340;&#22797;&#26434;&#23618;&#27425;&#32467;&#26500;&#65292;&#36825;&#31181;&#35774;&#32622;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#23398;&#20064;&#33539;&#24335;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#23558;&#25991;&#26412;&#19982;TTP&#26631;&#31614;&#20043;&#38388;&#30340;&#30452;&#25509;&#35821;&#20041;&#30456;&#20284;&#24230;&#20915;&#23450;&#20026;&#25991;&#26412;&#20998;&#37197;&#32473;TTP&#26631;&#31614;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#20165;&#20165;&#22312;&#22823;&#22411;&#26631;&#31614;&#31354;&#38388;&#19978;&#31454;&#20105;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26377;&#25928;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#23398;&#20064;&#27604;&#36739;&#26426;&#21046;&#30340;&#31070;&#32463;&#21305;&#37197;&#26550;&#26500;&#65292;&#20419;&#36827;&#23398;&#20064;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tactics, Techniques and Procedures (TTPs) represent sophisticated attack patterns in the cybersecurity domain, described encyclopedically in textual knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP mapping, is an important and challenging task. Conventional learning approaches often target the problem in the classical multi-class or multilabel classification setting. This setting hinders the learning ability of the model due to a large number of classes (i.e., TTPs), the inevitable skewness of the label distribution and the complex hierarchical structure of the label space. We formulate the problem in a different learning paradigm, where the assignment of a text to a TTP label is decided by the direct semantic similarity between the two, thus reducing the complexity of competing solely over the large labeling space. To that end, we propose a neural matching architecture with an effective sampling-based learn-to-compare mechanism, facilitating the learning pr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#32806;&#36807;&#31243;&#26469;&#21457;&#29616;&#21487;&#20197;&#19982;&#20027;&#20219;&#21153;&#19968;&#36215;&#21033;&#29992;&#30340;&#19981;&#30456;&#20851;&#30340;&#20998;&#31867;&#20219;&#21153;&#21644;&#30456;&#20851;&#26631;&#31614;&#65292;&#20174;&#32780;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20419;&#36827;&#36741;&#21161;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.09278</link><description>&lt;p&gt;
&#35299;&#32806;&#28508;&#22312;&#31354;&#38388;&#20419;&#36827;&#25968;&#25454;&#39537;&#21160;&#30340;&#36741;&#21161;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning. (arXiv:2310.09278v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#32806;&#36807;&#31243;&#26469;&#21457;&#29616;&#21487;&#20197;&#19982;&#20027;&#20219;&#21153;&#19968;&#36215;&#21033;&#29992;&#30340;&#19981;&#30456;&#20851;&#30340;&#20998;&#31867;&#20219;&#21153;&#21644;&#30456;&#20851;&#26631;&#31614;&#65292;&#20174;&#32780;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20419;&#36827;&#36741;&#21161;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#36741;&#21161;&#30446;&#26631;&#24120;&#24120;&#34987;&#29992;&#26469;&#22312;&#25968;&#25454;&#31232;&#32570;&#25110;&#32773;&#20027;&#35201;&#20219;&#21153;&#38750;&#24120;&#22797;&#26434;&#30340;&#24773;&#20917;&#19979;&#20419;&#36827;&#23398;&#20064;&#12290;&#36825;&#20010;&#24819;&#27861;&#20027;&#35201;&#21463;&#21040;&#21516;&#26102;&#35299;&#20915;&#22810;&#20010;&#20219;&#21153;&#24102;&#26469;&#30340;&#25913;&#36827;&#27867;&#21270;&#33021;&#21147;&#30340;&#21551;&#21457;&#65292;&#20174;&#32780;&#20135;&#29983;&#26356;&#24378;&#22823;&#30340;&#20849;&#20139;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#25214;&#21040;&#33021;&#20135;&#29983;&#26399;&#26395;&#25913;&#36827;&#30340;&#26368;&#20248;&#36741;&#21161;&#20219;&#21153;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#36890;&#24120;&#38656;&#35201;&#25163;&#21160;&#35774;&#35745;&#30340;&#25216;&#24039;&#25110;&#32773;&#26114;&#36149;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;Detaux&#65292;&#36890;&#36807;&#24369;&#30417;&#30563;&#30340;&#35299;&#32806;&#36807;&#31243;&#22312;&#20219;&#20309;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#27169;&#22411;&#20013;&#21457;&#29616;&#21487;&#20197;&#19982;&#20027;&#35201;&#20219;&#21153;&#19968;&#36215;&#21033;&#29992;&#30340;&#19981;&#30456;&#20851;&#30340;&#20998;&#31867;&#20219;&#21153;&#21644;&#30456;&#20851;&#26631;&#31614;&#12290;&#35299;&#32806;&#36807;&#31243;&#22312;&#34920;&#31034;&#23618;&#38754;&#24037;&#20316;&#65292;&#23558;&#19982;&#20027;&#35201;&#20219;&#21153;&#30456;&#20851;&#30340;&#19968;&#20010;&#23376;&#31354;&#38388;&#19982;&#20219;&#24847;&#25968;&#37327;&#30340;&#27491;&#20132;&#23376;&#31354;&#38388;&#20998;&#31163;&#24320;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
In deep learning, auxiliary objectives are often used to facilitate learning in situations where data is scarce, or the principal task is extremely complex. This idea is primarily inspired by the improved generalization capability induced by solving multiple tasks simultaneously, which leads to a more robust shared representation. Nevertheless, finding optimal auxiliary tasks that give rise to the desired improvement is a crucial problem that often requires hand-crafted solutions or expensive meta-learning approaches. In this paper, we propose a novel framework, dubbed Detaux, whereby a weakly supervised disentanglement procedure is used to discover new unrelated classification tasks and the associated labels that can be exploited with the principal task in any Multi-Task Learning (MTL) model. The disentanglement procedure works at a representation level, isolating a subspace related to the principal task, plus an arbitrary number of orthogonal subspaces. In the most disentangled subsp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#36870;&#26144;&#23556;B-KRnet&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#25968;&#25454;&#25110;PDE&#30340;&#23494;&#24230;&#20272;&#35745;/&#36817;&#20284;&#65292;&#30001;&#20110;&#20854;&#23450;&#20041;&#22312;&#26377;&#30028;&#22495;&#19978;&#65292;&#22240;&#27492;&#27604;KRnet&#26356;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2305.09063</link><description>&lt;p&gt;
&#26377;&#30028;KRnet&#21450;&#20854;&#22312;&#23494;&#24230;&#20272;&#35745;&#21644;&#36817;&#20284;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Bounded KRnet and its applications to density estimation and approximation. (arXiv:2305.09063v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09063
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#36870;&#26144;&#23556;B-KRnet&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#25968;&#25454;&#25110;PDE&#30340;&#23494;&#24230;&#20272;&#35745;/&#36817;&#20284;&#65292;&#30001;&#20110;&#20854;&#23450;&#20041;&#22312;&#26377;&#30028;&#22495;&#19978;&#65292;&#22240;&#27492;&#27604;KRnet&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#26377;&#30028;&#22495;&#19978;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#36870;&#26144;&#23556;&#65292;&#31216;&#20026;B-KRnet&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#25968;&#25454;&#25110;PDE&#65288;&#20363;&#22914;&#31119;&#20811;-&#26222;&#26391;&#20811;&#26041;&#31243;&#21644;Keller-Segel&#26041;&#31243;&#65289;&#30340;&#23494;&#24230;&#20272;&#35745;/&#36817;&#20284;&#12290;&#19982;KRnet&#31867;&#20284;&#65292;B-KRnet&#30340;&#32467;&#26500;&#23558;Knothe-Rosenblatt&#37325;&#25490;&#30340;&#19977;&#35282;&#24418;&#24418;&#24335;&#36716;&#21270;&#20026;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#12290;B-KRnet&#21644;KRnet&#20043;&#38388;&#30340;&#20027;&#35201;&#21306;&#21035;&#26159;B-KRnet&#23450;&#20041;&#22312;&#36229;&#31435;&#26041;&#20307;&#19978;&#65292;&#32780;KRnet&#23450;&#20041;&#22312;&#25972;&#20010;&#31354;&#38388;&#19978;&#65292;&#25442;&#21477;&#35805;&#35828;&#65292;&#25105;&#20204;&#22312;B-KRnet&#20013;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#21046;&#26469;&#20445;&#25345;&#31934;&#30830;&#30340;&#21487;&#36870;&#24615;&#12290;&#23558;B-KRnet&#29992;&#20316;&#20256;&#36755;&#26144;&#23556;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;PDF&#65289;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23545;&#24212;&#20110;&#20808;&#39564;&#65288;&#22343;&#21248;&#65289;&#20998;&#24067;&#22312;&#36229;&#31435;&#26041;&#20307;&#19978;&#30340;&#25512;&#31227;&#12290;&#20026;&#20102;&#36817;&#20284;&#35745;&#31639;&#22495;&#19978;&#23450;&#20041;&#30340;PDF&#65292;B-KRnet&#27604;KRnet&#26356;&#26377;&#25928;&#12290;&#36890;&#36807;&#32806;&#21512;KRnet&#21644;B-KRnet&#65292;&#25105;&#20204;&#36824;&#21487;&#20197;&#22312;&#39640;&#32500;&#22495;&#19978;&#23450;&#20041;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop an invertible mapping, called B-KRnet, on a bounded domain and apply it to density estimation/approximation for data or the solutions of PDEs such as the Fokker-Planck equation and the Keller-Segel equation. Similar to KRnet, the structure of B-KRnet adapts the triangular form of the Knothe-Rosenblatt rearrangement into a normalizing flow model. The main difference between B-KRnet and KRnet is that B-KRnet is defined on a hypercube while KRnet is defined on the whole space, in other words, we introduce a new mechanism in B-KRnet to maintain the exact invertibility. Using B-KRnet as a transport map, we obtain an explicit probability density function (PDF) model that corresponds to the pushforward of a prior (uniform) distribution on the hypercube. To approximate PDFs defined on a bounded computational domain, B-KRnet is more effective than KRnet. By coupling KRnet and B-KRnet, we can also define a deep generative model on a high-dimensional domain where some di
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#27491;&#21017;&#21270;&#29109;Wasserstein&#37325;&#24515;&#20844;&#24335;&#65292;&#20855;&#26377;&#22909;&#30340;&#27491;&#21017;&#21270;&#12289;&#36924;&#36817;&#12289;&#31283;&#23450;&#24615;&#21644;&#65288;&#26080;&#32593;&#26684;&#65289;&#20248;&#21270;&#29305;&#24615;; &#20854;&#20013;&#65292;&#21482;&#26377;&#22312;$\tau=\lambda/2$&#30340;&#24773;&#20917;&#19979;&#26159;&#26080;&#20559;&#24046;&#30340;&#12290;</title><link>http://arxiv.org/abs/2303.11844</link><description>&lt;p&gt;
&#21452;&#37325;&#27491;&#21017;&#21270;&#29109; Wasserstein &#37325;&#24515;
&lt;/p&gt;
&lt;p&gt;
Doubly Regularized Entropic Wasserstein Barycenters. (arXiv:2303.11844v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11844
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#27491;&#21017;&#21270;&#29109;Wasserstein&#37325;&#24515;&#20844;&#24335;&#65292;&#20855;&#26377;&#22909;&#30340;&#27491;&#21017;&#21270;&#12289;&#36924;&#36817;&#12289;&#31283;&#23450;&#24615;&#21644;&#65288;&#26080;&#32593;&#26684;&#65289;&#20248;&#21270;&#29305;&#24615;; &#20854;&#20013;&#65292;&#21482;&#26377;&#22312;$\tau=\lambda/2$&#30340;&#24773;&#20917;&#19979;&#26159;&#26080;&#20559;&#24046;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#24120;&#35268;&#30340;&#27491;&#21017;&#21270;Wasserstein&#37325;&#24515;&#30340;&#20844;&#24335;&#65292;&#36825;&#20010;&#20844;&#24335;&#20855;&#26377;&#33391;&#22909;&#30340;&#27491;&#21017;&#21270;&#12289;&#36924;&#36817;&#12289;&#31283;&#23450;&#24615;&#21644;&#65288;&#26080;&#32593;&#26684;&#65289;&#20248;&#21270;&#29305;&#24615;&#12290;&#36825;&#20010;&#37325;&#24515;&#34987;&#23450;&#20041;&#20026;&#21807;&#19968;&#19968;&#31181;&#26368;&#23567;&#21270;&#20851;&#20110;&#19968;&#26063;&#32473;&#23450;&#27010;&#29575;&#27979;&#24230;&#30340;&#29109;&#26368;&#20248;&#36755;&#36816;&#65288;EOT&#65289;&#25104;&#26412;&#20043;&#21644;&#21450;&#29109;&#39033;&#30340;&#27010;&#29575;&#27979;&#24230;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;$(\lambda,\tau)$-&#37325;&#24515;&#65292;&#20854;&#20013;&#65292;$\lambda$ &#26159;&#20869;&#37096;&#27491;&#21017;&#21270;&#24378;&#24230;&#65292;$\tau$ &#26159;&#22806;&#37096;&#27491;&#21017;&#21270;&#24378;&#24230;&#12290;&#36825;&#31181;&#20844;&#24335;&#24674;&#22797;&#20102;&#24050;&#32463;&#25552;&#20986;&#30340;&#22810;&#31181;EOT&#37325;&#24515;&#65292;&#36866;&#21512;&#20110;&#19981;&#21516;&#30340; $\lambda, \tau \geq 0$ &#36873;&#25321;&#65292;&#24182;&#23545;&#23427;&#20204;&#36827;&#34892;&#20102;&#27867;&#21270;&#12290;&#39318;&#20808;&#65292;&#23613;&#31649;&#20855;&#26377;&#21452;&#37325;&#27491;&#21017;&#21270;&#65292;&#20294;&#22312;$\tau=\lambda/2$ &#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20844;&#24335;&#26159;&#26080;&#20559;&#30340;: &#23545;&#20110;&#20809;&#28369;&#23494;&#24230;&#65292;&#65288;&#26410;&#27491;&#21017;&#21270;&#30340;&#65289;Wasserstein &#37325;&#24515;&#30446;&#26631;&#20989;&#25968;&#20013;&#30340;&#27425;&#20248;&#24615;&#26159;&#29109;&#27491;&#21017;&#21270;&#24378;&#24230;$\lambda^2$&#30340;&#65292;&#32780;&#19981;&#26159;&#19968;&#33324;&#24773;&#20917;&#19979;&#30340;$\max \{\lambda, \tau\}$&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a general formulation of regularized Wasserstein barycenters that enjoys favorable regularity, approximation, stability and (grid-free) optimization properties. This barycenter is defined as the unique probability measure that minimizes the sum of entropic optimal transport (EOT) costs with respect to a family of given probability measures, plus an entropy term. We denote it $(\lambda,\tau)$-barycenter, where $\lambda$ is the inner regularization strength and $\tau$ the outer one. This formulation recovers several previously proposed EOT barycenters for various choices of $\lambda,\tau \geq 0$ and generalizes them. First, in spite of -- and in fact owing to -- being \emph{doubly} regularized, we show that our formulation is debiased for $\tau=\lambda/2$: the suboptimality in the (unregularized) Wasserstein barycenter objective is, for smooth densities, of the order of the strength $\lambda^2$ of entropic regularization, instead of $\max\{\lambda,\tau\}$ in general. We discuss 
&lt;/p&gt;</description></item></channel></rss>