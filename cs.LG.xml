<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#20010;&#26377;&#37325;&#35201;&#24847;&#20041;&#30340;&#39046;&#22495;&#12290;&#26412;&#32508;&#36848;&#20998;&#31867;&#21644;&#20998;&#26512;&#20102;&#24050;&#26377;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#26500;&#24314;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;GNNs&#30340;&#26126;&#30830;&#25351;&#23548;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01138</link><description>&lt;p&gt;
&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#20010;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks in EEG-based Emotion Recognition: A Survey
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01138
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#20010;&#26377;&#37325;&#35201;&#24847;&#20041;&#30340;&#39046;&#22495;&#12290;&#26412;&#32508;&#36848;&#20998;&#31867;&#21644;&#20998;&#26512;&#20102;&#24050;&#26377;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#26500;&#24314;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;GNNs&#30340;&#26126;&#30830;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#23545;&#20110;&#20854;&#20182;&#27169;&#24335;&#65292;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#21487;&#20197;&#30452;&#35266;&#22320;&#21709;&#24212;&#20154;&#33041;&#20013;&#30340;&#24773;&#32490;&#27169;&#24335;&#65292;&#22240;&#27492;&#25104;&#20026;&#33041;-&#35745;&#31639;&#26426;&#25509;&#21475;&#39046;&#22495;&#26368;&#20851;&#27880;&#30340;&#20219;&#21153;&#20043;&#19968;&#12290;&#30001;&#20110;&#22823;&#33041;&#21306;&#22495;&#20043;&#38388;&#30340;&#20381;&#36182;&#19982;&#24773;&#32490;&#23494;&#20999;&#30456;&#20851;&#65292;&#22240;&#27492;&#21457;&#23637;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#36827;&#34892;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#36235;&#21183;&#12290;&#28982;&#32780;&#65292;&#24773;&#32490;&#24615;&#33041;&#30005;&#22270;&#20013;&#30340;&#22823;&#33041;&#21306;&#22495;&#20381;&#36182;&#20855;&#26377;&#29983;&#29702;&#22522;&#30784;&#65292;&#20351;&#24471;&#22312;&#36825;&#19968;&#39046;&#22495;&#20013;&#30340;GNNs&#19982;&#20854;&#20182;&#26102;&#38388;&#24207;&#21015;&#39046;&#22495;&#30340;GNNs&#26377;&#25152;&#21306;&#21035;&#12290;&#27492;&#22806;&#65292;&#22312;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;&#24773;&#32490;&#35782;&#21035;&#20013;&#26082;&#27809;&#26377;&#20840;&#38754;&#30340;&#32508;&#36848;&#65292;&#20063;&#27809;&#26377;&#26500;&#24314;GNNs&#30340;&#25351;&#23548;&#12290;&#22312;&#36825;&#39033;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#23545;&#24050;&#26377;&#26041;&#27861;&#22312;&#22270;&#26500;&#36896;&#30340;&#32479;&#19968;&#26694;&#26550;&#19979;&#36827;&#34892;&#20102;&#20998;&#31867;&#65292;&#25581;&#31034;&#20986;&#20854;&#20849;&#21516;&#28857;&#21644;&#24046;&#24322;&#12290;&#25105;&#20204;&#20174;&#26694;&#26550;&#30340;&#19977;&#20010;&#38454;&#27573;&#20998;&#26512;&#21644;&#20998;&#31867;&#26041;&#27861;&#65292;&#20026;&#26500;&#24314;&#22522;&#20110;&#33041;&#30005;&#22270;&#30340;GNNs&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#25351;&#23548;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#19968;&#20123;...
&lt;/p&gt;
&lt;p&gt;
Compared to other modalities, EEG-based emotion recognition can intuitively respond to the emotional patterns in the human brain and, therefore, has become one of the most concerning tasks in the brain-computer interfaces field. Since dependencies within brain regions are closely related to emotion, a significant trend is to develop Graph Neural Networks (GNNs) for EEG-based emotion recognition. However, brain region dependencies in emotional EEG have physiological bases that distinguish GNNs in this field from those in other time series fields. Besides, there is neither a comprehensive review nor guidance for constructing GNNs in EEG-based emotion recognition. In the survey, our categorization reveals the commonalities and differences of existing approaches under a unified framework of graph construction. We analyze and categorize methods from three stages in the framework to provide clear guidance on constructing GNNs in EEG-based emotion recognition. In addition, we discuss several 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#65292;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#21644;&#29420;&#31435;&#27714;&#35299;&#33021;&#21147;&#12290;</title><link>https://rss.arxiv.org/abs/2212.00133</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#21021;&#22987;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Learning of Sinkhorn Algorithm Initializations
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2212.00133
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#65292;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#21644;&#29420;&#31435;&#27714;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sinkhorn&#31639;&#27861;&#26159;&#36817;&#20284;&#27714;&#35299;&#31163;&#25955;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#29109;&#27491;&#21017;&#36755;&#36816;&#65288;OT&#65289;&#36317;&#31163;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;&#31639;&#27861;&#21021;&#22987;&#21270;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;Sinkhorn&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#24335;&#20351;&#29992;&#31532;&#20108;&#20010;&#29983;&#25104;&#32593;&#32476;&#21644;&#33258;&#30417;&#30563;&#24341;&#23548;&#25439;&#22833;&#26469;&#35757;&#32451;&#25105;&#20204;&#30340;&#39044;&#27979;&#32593;&#32476;&#12290;&#39044;&#27979;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#33021;&#22815;&#25512;&#24191;&#21040;&#20219;&#24847;&#22266;&#23450;&#32500;&#24230;&#21644;&#25104;&#26412;&#30340;&#27010;&#29575;&#20998;&#24067;&#23545;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#29983;&#25104;&#32593;&#32476;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20135;&#29983;&#20219;&#24847;&#27010;&#29575;&#20998;&#24067;&#23545;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32593;&#32476;&#21487;&#20197;&#20316;&#20026;&#29420;&#31435;&#30340;OT&#27714;&#35299;&#22120;&#26469;&#36817;&#20284;&#27491;&#21017;&#21270;&#36755;&#36816;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sinkhorn algorithm is the state-of-the-art to approximate solutions of entropic optimal transport (OT) distances between discrete probability distributions. We show that meticulously training a neural network to learn initializations to the algorithm via the entropic OT dual problem can significantly speed up convergence, while maintaining desirable properties of the Sinkhorn algorithm, such as differentiability and parallelizability. We train our predictive network in an adversarial fashion using a second, generating network and a self-supervised bootstrapping loss. The predictive network is universal in the sense that it is able to generalize to any pair of distributions of fixed dimension and cost at inference, and we prove that we can make the generating network universal in the sense that it is capable of producing any pair of distributions during training. Furthermore, we show that our network can even be used as a standalone OT solver to approximate regularized transport dis
&lt;/p&gt;</description></item><item><title>TranSDDP&#26159;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#21019;&#26032;&#20998;&#38454;&#20998;&#35299;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;Transformer&#27169;&#22411;&#30340;&#32467;&#26500;&#20248;&#21183;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#24207;&#36143;&#26041;&#27861;&#26469;&#36924;&#36817;&#20540;&#20989;&#25968;&#65292;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.02583</link><description>&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#20998;&#38454;&#20998;&#35299;&#29992;&#20110;&#22823;&#35268;&#27169;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Transformer-based Stagewise Decomposition for Large-Scale Multistage Stochastic Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02583
&lt;/p&gt;
&lt;p&gt;
TranSDDP&#26159;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#21019;&#26032;&#20998;&#38454;&#20998;&#35299;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;Transformer&#27169;&#22411;&#30340;&#32467;&#26500;&#20248;&#21183;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#24207;&#36143;&#26041;&#27861;&#26469;&#36924;&#36817;&#20540;&#20989;&#25968;&#65292;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#22823;&#35268;&#27169;&#22810;&#38454;&#27573;&#38543;&#26426;&#35268;&#21010;&#65288;MSP&#65289;&#38382;&#39064;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#24120;&#29992;&#30340;&#20998;&#38454;&#20998;&#35299;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;&#23545;&#20598;&#21160;&#24577;&#35268;&#21010;&#65288;SDDP&#65289;&#65292;&#38543;&#30528;&#23376;&#38382;&#39064;&#35268;&#27169;&#21644;&#38382;&#39064;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#26102;&#38388;&#22797;&#26434;&#24230;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#20256;&#32479;&#26041;&#27861;&#36890;&#36807;&#36880;&#27493;&#32047;&#31215;&#26469;&#33258;&#20998;&#38454;&#23376;&#38382;&#39064;&#21407;&#22987;&#21644;&#23545;&#20598;&#35299;&#30340;&#27425;&#26799;&#24230;&#20999;&#21106;&#24179;&#38754;&#65292;&#23558;&#20540;&#20989;&#25968;&#36817;&#20284;&#20026;&#20998;&#27573;&#32447;&#24615;&#20984;&#20989;&#25968;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;Transformer&#30340;&#20998;&#38454;&#20998;&#35299;&#31639;&#27861;TranSDDP&#12290;&#36825;&#31181;&#21019;&#26032;&#26041;&#27861;&#21033;&#29992;Transformer&#27169;&#22411;&#30340;&#32467;&#26500;&#20248;&#21183;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#24207;&#36143;&#26041;&#27861;&#65292;&#29992;&#20110;&#25972;&#21512;&#27425;&#26799;&#24230;&#20999;&#21106;&#24179;&#38754;&#20197;&#36924;&#36817;&#20540;&#20989;&#25968;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#30830;&#35748;&#20102;TranSDDP&#22312;&#22788;&#29702;MSP&#38382;&#39064;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#23427;&#33021;&#22815;&#39640;&#25928;&#29983;&#25104;&#20998;&#27573;&#32447;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02583v1 Announce Type: new  Abstract: Solving large-scale multistage stochastic programming (MSP) problems poses a significant challenge as commonly used stagewise decomposition algorithms, including stochastic dual dynamic programming (SDDP), face growing time complexity as the subproblem size and problem count increase. Traditional approaches approximate the value functions as piecewise linear convex functions by incrementally accumulating subgradient cutting planes from the primal and dual solutions of stagewise subproblems. Recognizing these limitations, we introduce TranSDDP, a novel Transformer-based stagewise decomposition algorithm. This innovative approach leverages the structural advantages of the Transformer model, implementing a sequential method for integrating subgradient cutting planes to approximate the value function. Through our numerical experiments, we affirm TranSDDP's effectiveness in addressing MSP problems. It efficiently generates a piecewise linear 
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.10763</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#26356;&#24555;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#30340;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Primal-Dual Algorithm for Faster Distributionally Robust Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10763
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24102;&#26377;&#38381;&#21512;&#12289;&#20984;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#24809;&#32602;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#65292;&#36825;&#20010;&#35774;&#32622;&#21253;&#25324;&#20102;&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;$f$-DRO&#12289;Wasserstein-DRO&#21644;&#35889;/$L$-&#39118;&#38505;&#20844;&#24335;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Drago&#65292;&#19968;&#31181;&#38543;&#26426;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#65292;&#22312;&#24378;&#20984;-&#24378;&#20985;DRO&#38382;&#39064;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;&#35813;&#26041;&#27861;&#23558;&#38543;&#26426;&#21270;&#21644;&#24490;&#29615;&#32452;&#20214;&#19982;&#23567;&#25209;&#37327;&#32467;&#21512;&#65292;&#26377;&#25928;&#22788;&#29702;&#20102;DRO&#20013;&#21407;&#22987;&#21644;&#23545;&#20598;&#38382;&#39064;&#30340;&#29420;&#29305;&#19981;&#23545;&#31216;&#24615;&#36136;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#31867;&#21644;&#22238;&#24402;&#20013;&#30340;&#25968;&#20540;&#22522;&#20934;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10763v1 Announce Type: cross  Abstract: We consider the penalized distributionally robust optimization (DRO) problem with a closed, convex uncertainty set, a setting that encompasses the $f$-DRO, Wasserstein-DRO, and spectral/$L$-risk formulations used in practice. We present Drago, a stochastic primal-dual algorithm that achieves a state-of-the-art linear convergence rate on strongly convex-strongly concave DRO problems. The method combines both randomized and cyclic components with mini-batching, which effectively handles the unique asymmetric nature of the primal and dual problems in DRO. We support our theoretical results with numerical benchmarks in classification and regression.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#36890;&#36807;&#20840;&#38754;&#30740;&#31350;&#20219;&#21153;&#38590;&#24230;&#65292;&#21457;&#29616;&#36739;&#26089;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#20219;&#21153;&#26356;&#20855;&#25361;&#25112;&#24615;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#21435;&#22122;&#20219;&#21153;&#38590;&#24230;&#30340;&#28176;&#36827;&#24335;&#35838;&#31243;&#35757;&#32451;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.10348</link><description>&lt;p&gt;
&#22522;&#20110;&#21435;&#22122;&#20219;&#21153;&#38590;&#24230;&#30340;&#28176;&#36827;&#24335;&#35838;&#31243;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Denoising Task Difficulty-based Curriculum for Training Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10348
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#36890;&#36807;&#20840;&#38754;&#30740;&#31350;&#20219;&#21153;&#38590;&#24230;&#65292;&#21457;&#29616;&#36739;&#26089;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#20219;&#21153;&#26356;&#20855;&#25361;&#25112;&#24615;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#21435;&#22122;&#20219;&#21153;&#38590;&#24230;&#30340;&#28176;&#36827;&#24335;&#35838;&#31243;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#24050;&#25104;&#20026;&#29983;&#25104;&#24314;&#27169;&#39046;&#22495;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;&#23613;&#31649;&#23545;&#21508;&#20010;&#26102;&#38388;&#27493;&#38271;&#21644;&#22122;&#22768;&#27700;&#24179;&#20043;&#38388;&#30340;&#21435;&#22122;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#20851;&#20110;&#21435;&#22122;&#20219;&#21153;&#30340;&#30456;&#23545;&#38590;&#24230;&#20173;&#23384;&#22312;&#20105;&#35758;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#23545;&#20219;&#21153;&#38590;&#24230;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#37325;&#28857;&#20851;&#27880;&#25910;&#25947;&#34892;&#20026;&#21644;&#26102;&#38388;&#27493;&#38271;&#38388;&#36830;&#32493;&#27010;&#29575;&#20998;&#24067;&#30340;&#30456;&#23545;&#29109;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#35266;&#23519;&#26174;&#31034;&#65292;&#36739;&#26089;&#26102;&#38388;&#27493;&#38271;&#30340;&#21435;&#22122;&#23384;&#22312;&#25910;&#25947;&#32531;&#24930;&#21644;&#36739;&#39640;&#30340;&#30456;&#23545;&#29109;&#65292;&#34920;&#26126;&#22312;&#36825;&#20123;&#36739;&#20302;&#26102;&#38388;&#27493;&#38271;&#19978;&#20219;&#21153;&#38590;&#24230;&#22686;&#21152;&#12290;&#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#30001;&#26131;&#21040;&#38590;&#30340;&#23398;&#20064;&#26041;&#26696;&#65292;&#20511;&#37492;&#28176;&#36827;&#24335;&#23398;&#20064;&#30340;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10348v1 Announce Type: cross  Abstract: Diffusion-based generative models have emerged as powerful tools in the realm of generative modeling. Despite extensive research on denoising across various timesteps and noise levels, a conflict persists regarding the relative difficulties of the denoising tasks. While various studies argue that lower timesteps present more challenging tasks, others contend that higher timesteps are more difficult. To address this conflict, our study undertakes a comprehensive examination of task difficulties, focusing on convergence behavior and changes in relative entropy between consecutive probability distributions across timesteps. Our observational study reveals that denoising at earlier timesteps poses challenges characterized by slower convergence and higher relative entropy, indicating increased task difficulty at these lower timesteps. Building on these observations, we introduce an easy-to-hard learning scheme, drawing from curriculum learn
&lt;/p&gt;</description></item><item><title>&#19981;&#21516;iable pruning&#19982;&#32452;&#21512;&#20248;&#21270;&#30456;&#32467;&#21512;&#65292;&#20135;&#29983;&#20102;&#19968;&#20010;&#29992;&#20110;&#32467;&#26500;&#21270;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#30340;&#19968;&#33268;&#26694;&#26550;&#65292;&#20197;&#21487;&#24494;&#21098;&#26525;&#24341;&#23548;&#32452;&#21512;&#20248;&#21270;&#31639;&#27861;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#31232;&#30095;&#21442;&#25968;&#38598;&#12290;</title><link>https://arxiv.org/abs/2402.17902</link><description>&lt;p&gt;
SequentialAttention++&#29992;&#20110;&#22359;&#31232;&#30095;&#21270;&#65306;&#21487;&#24494;&#21098;&#26525;&#36935;&#19978;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
SequentialAttention++ for Block Sparsification: Differentiable Pruning Meets Combinatorial Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17902
&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;iable pruning&#19982;&#32452;&#21512;&#20248;&#21270;&#30456;&#32467;&#21512;&#65292;&#20135;&#29983;&#20102;&#19968;&#20010;&#29992;&#20110;&#32467;&#26500;&#21270;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#30340;&#19968;&#33268;&#26694;&#26550;&#65292;&#20197;&#21487;&#24494;&#21098;&#26525;&#24341;&#23548;&#32452;&#21512;&#20248;&#21270;&#31639;&#27861;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#31232;&#30095;&#21442;&#25968;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#26159;&#19968;&#31181;&#20851;&#38190;&#25216;&#26415;&#65292;&#21487;&#29992;&#20110;&#26500;&#24314;&#22823;&#22411;&#19988;&#21487;&#25193;&#23637;&#12289;&#21487;&#35299;&#37322;&#21644;&#21487;&#27867;&#21270;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#23558;&#20004;&#31181;&#26041;&#27861;&#32479;&#19968;&#36215;&#26469;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#21270;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#30340;&#19968;&#33268;&#26694;&#26550;&#65292;&#20854;&#20013;&#21487;&#24494;&#21098;&#26525;&#24341;&#23548;&#32452;&#21512;&#20248;&#21270;&#31639;&#27861;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#31232;&#30095;&#21442;&#25968;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17902v1 Announce Type: new  Abstract: Neural network pruning is a key technique towards engineering large yet scalable, interpretable, and generalizable models. Prior work on the subject has developed largely along two orthogonal directions: (1) differentiable pruning for efficiently and accurately scoring the importance of parameters, and (2) combinatorial optimization for efficiently searching over the space of sparse models. We unite the two approaches, both theoretically and empirically, to produce a coherent framework for structured neural network pruning in which differentiable pruning guides combinatorial optimization algorithms to select the most important sparse set of parameters. Theoretically, we show how many existing differentiable pruning techniques can be understood as nonconvex regularization for group sparse optimization, and prove that for a wide class of nonconvex regularizers, the global optimum is unique, group-sparse, and provably yields an approximate 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;RAGFormer&#30340;&#26032;&#26694;&#26550;&#65292;&#21516;&#26102;&#23558;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#23884;&#20837;&#30446;&#26631;&#33410;&#28857;&#65292;&#20197;&#25913;&#36827;&#27450;&#35784;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.17472</link><description>&lt;p&gt;
&#36890;&#36807;&#34701;&#21512;&#20840;&#23616;&#21644;&#23616;&#37096;&#20851;&#31995;&#20132;&#20114;&#36827;&#34892;&#27450;&#35784;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Fraud Detection with Binding Global and Local Relational Interaction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17472
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;RAGFormer&#30340;&#26032;&#26694;&#26550;&#65292;&#21516;&#26102;&#23558;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#23884;&#20837;&#30446;&#26631;&#33410;&#28857;&#65292;&#20197;&#25913;&#36827;&#27450;&#35784;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#23545;&#20110;&#27450;&#35784;&#26816;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#22312;&#25972;&#20307;&#35270;&#35282;&#20013;&#32534;&#30721;&#33410;&#28857;&#20132;&#20114;&#21644;&#32858;&#21512;&#29305;&#24449;&#12290;&#26368;&#36817;&#65292;&#20855;&#26377;&#20986;&#33394;&#24207;&#21015;&#32534;&#30721;&#33021;&#21147;&#30340;Transformer&#32593;&#32476;&#22312;&#25991;&#29486;&#20013;&#20063;&#34920;&#29616;&#20986;&#20248;&#20110;&#20854;&#20182;&#22522;&#20110;GNN&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;GNN&#21644;&#22522;&#20110;Transformer&#30340;&#32593;&#32476;&#21482;&#32534;&#30721;&#25972;&#20010;&#22270;&#30340;&#19968;&#20010;&#35270;&#35282;&#65292;&#32780;GNN&#32534;&#30721;&#20840;&#23616;&#29305;&#24449;&#65292;Transformer&#32593;&#32476;&#32534;&#30721;&#23616;&#37096;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#24573;&#35270;&#20102;&#20351;&#29992;&#21333;&#29420;&#32593;&#32476;&#32534;&#30721;&#24322;&#26500;&#22270;&#30340;&#20840;&#23616;&#20132;&#20114;&#29305;&#24449;&#65292;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;Relation-Aware GNN with transFormer&#65288;RAGFormer&#65289;&#30340;&#26032;&#39062;&#26694;&#26550;&#65292;&#23558;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#21516;&#26102;&#23884;&#20837;&#30446;&#26631;&#33410;&#28857;&#20013;&#12290;&#36825;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#32593;&#32476;&#24212;&#29992;&#20102;&#19968;&#20010;&#20462;&#25913;&#21518;&#30340;GAGA&#27169;&#22359;&#65292;&#20854;&#20013;&#27599;&#20010;Transformer&#23618;&#21518;&#38754;&#37117;&#36319;&#30528;&#19968;&#20010;&#36328;&#20851;&#31995;&#32858;&#21512;&#23618;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17472v1 Announce Type: cross  Abstract: Graph Neural Network has been proved to be effective for fraud detection for its capability to encode node interaction and aggregate features in a holistic view. Recently, Transformer network with great sequence encoding ability, has also outperformed other GNN-based methods in literatures. However, both GNN-based and Transformer-based networks only encode one perspective of the whole graph, while GNN encodes global features and Transformer network encodes local ones. Furthermore, previous works ignored encoding global interaction features of the heterogeneous graph with separate networks, thus leading to suboptimal performance. In this work, we present a novel framework called Relation-Aware GNN with transFormer (RAGFormer) which simultaneously embeds local and global features into a target node. The simple yet effective network applies a modified GAGA module where each transformer layer is followed by a cross-relation aggregation lay
&lt;/p&gt;</description></item><item><title>&#23558;&#34920;&#24449;&#31354;&#38388;&#30340;&#21453;&#20107;&#23454;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#65292;&#20197;&#20998;&#26512;&#21644;&#35299;&#37322;&#27169;&#22411;&#24178;&#39044;&#25152;&#24341;&#36215;&#30340;&#35821;&#35328;&#21464;&#21270;&#65292;&#24182;&#20943;&#36731;&#20998;&#31867;&#20013;&#30340;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2402.11355</link><description>&lt;p&gt;
&#25913;&#21464;&#20102;&#20160;&#20040;&#65311;&#23558;&#34920;&#24449;&#24178;&#39044;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;
&lt;/p&gt;
&lt;p&gt;
What Changed? Converting Representational Interventions to Natural Language
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11355
&lt;/p&gt;
&lt;p&gt;
&#23558;&#34920;&#24449;&#31354;&#38388;&#30340;&#21453;&#20107;&#23454;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#65292;&#20197;&#20998;&#26512;&#21644;&#35299;&#37322;&#27169;&#22411;&#24178;&#39044;&#25152;&#24341;&#36215;&#30340;&#35821;&#35328;&#21464;&#21270;&#65292;&#24182;&#20943;&#36731;&#20998;&#31867;&#20013;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#34920;&#24449;&#31354;&#38388;&#30340;&#24178;&#39044;&#26041;&#27861;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#24433;&#21709;&#27169;&#22411;&#34892;&#20026;&#30340;&#26377;&#25928;&#25163;&#27573;&#12290;&#36825;&#20123;&#26041;&#27861;&#34987;&#29992;&#26469;&#28040;&#38500;&#25110;&#25913;&#21464;&#27169;&#22411;&#34920;&#31034;&#20013;&#30340;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#65288;&#22914;&#24615;&#21035;&#65289;&#30340;&#32534;&#30721;&#65292;&#21019;&#24314;&#19968;&#20010;&#21453;&#20107;&#23454;&#30340;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#24178;&#39044;&#25805;&#20316;&#22312;&#34920;&#31034;&#31354;&#38388;&#20869;&#65292;&#20934;&#30830;&#29702;&#35299;&#23427;&#20462;&#25913;&#20102;&#21738;&#20123;&#29305;&#24449;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#34920;&#24449;&#31354;&#38388;&#30340;&#21453;&#20107;&#23454;&#21487;&#20197;&#36716;&#21270;&#20026;&#33258;&#28982;&#35821;&#35328;&#30340;&#21453;&#20107;&#23454;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#20998;&#26512;&#23545;&#24212;&#20110;&#32473;&#23450;&#34920;&#31034;&#31354;&#38388;&#24178;&#39044;&#30340;&#35821;&#35328;&#21464;&#21270;&#65292;&#24182;&#35299;&#37322;&#29992;&#20110;&#32534;&#30721;&#29305;&#23450;&#27010;&#24565;&#30340;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#30001;&#27492;&#20135;&#29983;&#30340;&#21453;&#20107;&#23454;&#21487;&#20197;&#29992;&#20110;&#20943;&#36731;&#20998;&#31867;&#20013;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11355v1 Announce Type: new  Abstract: Interventions targeting the representation space of language models (LMs) have emerged as effective means to influence model behavior. These methods are employed, for example, to eliminate or alter the encoding of demographic information such as gender within the model's representations, creating a counterfactual representation. However, since the intervention operates within the representation space, understanding precisely which features it modifies poses a challenge. We show that representation-space counterfactuals can be converted into natural language counterfactuals. We demonstrate that this approach enables us to analyze the linguistic alterations corresponding to a given representation-space intervention and to interpret the features utilized for encoding a specific concept. Moreover, the resulting counterfactuals can be used to mitigate bias in classification.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#20013;&#20943;&#23569;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#20195;&#20215;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09401</link><description>&lt;p&gt;
&#20351;&#29992;&#20027;&#21160;&#26597;&#35810;&#30340;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback with Active Queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#20013;&#20943;&#23569;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#20195;&#20215;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#23545;&#40784;&#65292;&#22312;&#26500;&#24314;&#29616;&#20195;&#29983;&#25104;&#27169;&#22411;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#24403;&#21069;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#20294;&#24448;&#24448;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#65292;&#32780;&#36825;&#31181;&#25968;&#25454;&#25910;&#38598;&#36153;&#26102;&#36153;&#21147;&#12290;&#26412;&#25991;&#21463;&#21040;&#20027;&#21160;&#23398;&#20064;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#36890;&#36807;&#25552;&#20986;&#26597;&#35810;&#25928;&#29575;&#39640;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#23545;&#40784;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#19978;&#19979;&#25991;&#31454;&#20105;&#20108;&#33218;&#24378;&#30423;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;APPO&#65289;&#31639;&#27861;&#65292;&#20855;&#26377;$\tilde{O}(d^2/\Delta)$&#30340;&#36951;&#25022;&#30028;&#21644;$\tilde{O}(d^2/\Delta^2)$&#30340;&#26597;&#35810;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;$d$&#26159;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#24230;&#65292;$\Delta$&#26159;&#25152;&#26377;&#19978;&#19979;&#25991;&#20013;&#30340;&#27425;&#20248;&#24046;&#36317;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ADPO&#65292;&#36825;&#26159;&#25105;&#20204;&#31639;&#27861;&#30340;&#23454;&#38469;&#29256;&#26412;&#65292;&#22522;&#20110;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09401v1 Announce Type: cross Abstract: Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32467;&#21512;&#20102;PAC-Bayes&#24037;&#20855;&#31665;&#21644;Poincar&#233;&#19982;Log-Sobolev&#19981;&#31561;&#24335;&#65292;&#25552;&#20379;&#20102;&#26032;&#30340;&#26799;&#24230;&#39033;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#31361;&#20986;&#20102;&#24179;&#22374;&#26368;&#23567;&#20540;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.08508</link><description>&lt;p&gt;
&#24191;&#20041;&#21644;&#24179;&#22343;&#23481;&#37327;&#20043;&#38388;&#30340;PAC-Bayes&#32852;&#32467;
&lt;/p&gt;
&lt;p&gt;
A PAC-Bayesian Link Between Generalisation and Flat Minima
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32467;&#21512;&#20102;PAC-Bayes&#24037;&#20855;&#31665;&#21644;Poincar&#233;&#19982;Log-Sobolev&#19981;&#31561;&#24335;&#65292;&#25552;&#20379;&#20102;&#26032;&#30340;&#26799;&#24230;&#39033;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#31361;&#20986;&#20102;&#24179;&#22374;&#26368;&#23567;&#20540;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#36890;&#24120;&#20351;&#29992;&#36229;&#21442;&#25968;&#35774;&#32622;&#65288;&#35757;&#32451;&#21442;&#25968;&#25968;&#37327;&#22823;&#20110;&#25968;&#25454;&#38598;&#22823;&#23567;&#65289;&#20013;&#30340;&#39044;&#27979;&#22120;&#65292;&#23427;&#20204;&#30340;&#35757;&#32451;&#19981;&#20165;&#20135;&#29983;&#33391;&#22909;&#30340;&#35757;&#32451;&#25968;&#25454;&#24615;&#33021;&#65292;&#32780;&#19988;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#36825;&#19968;&#29616;&#35937;&#25361;&#25112;&#20102;&#35768;&#22810;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#19988;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#28041;&#21450;&#26799;&#24230;&#39033;&#30340;&#26032;&#22411;&#27867;&#21270;&#30028;&#38480;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;PAC-Bayes&#24037;&#20855;&#31665;&#19982;Poincar&#233;&#21644;Log-Sobolev&#19981;&#31561;&#24335;&#30456;&#32467;&#21512;&#65292;&#36991;&#20813;&#20102;&#23545;&#39044;&#27979;&#22120;&#31354;&#38388;&#32500;&#25968;&#30340;&#26174;&#24335;&#20381;&#36182;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31361;&#20986;&#20102;&#8220;&#24179;&#22374;&#26368;&#23567;&#20540;&#8221;&#65288;&#20960;&#20046;&#33021;&#22815;&#26368;&#23567;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37051;&#36817;&#26368;&#23567;&#20540;&#65289;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#65292;&#30452;&#25509;&#28041;&#21450;&#21040;&#20248;&#21270;&#38454;&#27573;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning usually involves predictors in the overparametrised setting (number of trained parameters greater than dataset size), and their training yield not only good performances on training data, but also good generalisation capacity. This phenomenon challenges many theoretical results, and remains an open problem. To reach a better understanding, we provide novel generalisation bounds involving gradient terms. To do so, we combine the PAC-Bayes toolbox with Poincar\'e and Log-Sobolev inequalities, avoiding an explicit dependency on dimension of the predictor space. Our results highlight the positive influence of \emph{flat minima} (being minima with a neighbourhood nearly minimising the learning problem as well) on generalisation performances, involving directly the benefits of the optimisation phase.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#37319;&#26679;&#26041;&#26696;"mix-cd"&#65292;&#36890;&#36807;&#35782;&#21035;&#21644;&#20248;&#20808;&#22788;&#29702;&#23454;&#38469;&#38754;&#20020;&#36951;&#24536;&#30340;&#26679;&#26412;&#65292;&#20197;&#32531;&#35299;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#30693;&#35782;&#36951;&#24536;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#31616;&#21333;&#12289;&#26131;&#20110;&#23454;&#29616;&#65292;&#24182;&#33021;&#22312;&#29616;&#26377;&#27169;&#22411;&#20013;&#26080;&#32541;&#36816;&#29992;&#65292;&#26377;&#25928;&#22320;&#20445;&#25345;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08096</link><description>&lt;p&gt;
&#22312;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#26102;&#37325;&#26032;&#32451;&#20064;&#21738;&#20123;&#39044;&#35757;&#32451;&#26679;&#26412;&#26356;&#22909;&#65311;
&lt;/p&gt;
&lt;p&gt;
Which Pretrain Samples to Rehearse when Finetuning Pretrained Models?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#37319;&#26679;&#26041;&#26696;"mix-cd"&#65292;&#36890;&#36807;&#35782;&#21035;&#21644;&#20248;&#20808;&#22788;&#29702;&#23454;&#38469;&#38754;&#20020;&#36951;&#24536;&#30340;&#26679;&#26412;&#65292;&#20197;&#32531;&#35299;&#24494;&#35843;&#36807;&#31243;&#20013;&#30340;&#30693;&#35782;&#36951;&#24536;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#31616;&#21333;&#12289;&#26131;&#20110;&#23454;&#29616;&#65292;&#24182;&#33021;&#22312;&#29616;&#26377;&#27169;&#22411;&#20013;&#26080;&#32541;&#36816;&#29992;&#65292;&#26377;&#25928;&#22320;&#20445;&#25345;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25991;&#26412;&#21644;&#35270;&#35273;&#20219;&#21153;&#20013;&#65292;&#24494;&#35843;&#39044;&#35757;&#32451;&#22522;&#30784;&#27169;&#22411;&#24050;&#25104;&#20026;&#20107;&#23454;&#19978;&#30340;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#24050;&#30693;&#38382;&#39064;&#26159;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#20250;&#36951;&#24536;&#39044;&#35757;&#32451;&#30693;&#35782;&#12290;&#20174;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#38543;&#26426;&#36873;&#25321;&#26679;&#26412;&#26469;&#36827;&#34892;&#37325;&#26032;&#32451;&#20064;&#26159;&#32531;&#35299;&#36951;&#24536;&#30340;&#24120;&#35265;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#38543;&#26426;&#28151;&#21512;&#19981;&#32463;&#24847;&#22320;&#21253;&#25324;&#20102;&#27169;&#22411;&#23578;&#26410;&#36951;&#24536;&#25110;&#26080;&#27861;&#23398;&#20064;&#30340;&#26679;&#26412;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#26696;"mix-cd"&#65292;&#29992;&#20110;&#35782;&#21035;&#21644;&#20248;&#20808;&#22788;&#29702;&#23454;&#38469;&#38754;&#20020;&#36951;&#24536;&#30340;&#26679;&#26412;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;"collateral damage"&#12290;&#30001;&#20110;&#30452;&#25509;&#35782;&#21035;"collateral damage"&#26679;&#26412;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36319;&#36394;&#24494;&#35843;&#26679;&#26412;&#30340;&#32479;&#35745;&#20449;&#24687;&#26469;&#20272;&#35745;&#36825;&#31867;&#26679;&#26412;&#20998;&#24067;&#30340;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#31616;&#27905;&#36731;&#37327;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#24182;&#21487;&#20197;&#26080;&#32541;&#38598;&#25104;&#21040;&#29616;&#26377;&#27169;&#22411;&#20013;&#65292;&#20855;&#26377;&#26377;&#25928;&#22320;&#20445;&#25345;&#39044;&#35757;&#32451;&#24615;&#33021;&#32780;&#26080;&#38656;&#39069;&#22806;&#35745;&#31639;&#24320;&#38144;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning pretrained foundational models on specific tasks is now the de facto approach for text and vision tasks. A known pitfall of this approach is the forgetting of pretraining knowledge that happens during finetuning. Rehearsing samples randomly from the pretrain dataset is a common approach to alleviate such forgetting. However, we find that random mixing unintentionally includes samples which are not (yet) forgotten or unlearnable by the model. We propose a novel sampling scheme, mix-cd, that identifies and prioritizes samples that actually face forgetting, which we call collateral damage. Since directly identifying collateral damage samples is computationally expensive, we propose a procedure to estimate the distribution of such samples by tracking the statistics of finetuned samples. Our approach is lightweight, easy to implement, and can be seamlessly integrated into existing models, offering an effective means to retain pretrain performance without additional computational
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20869;&#30465;&#35268;&#21010;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#24341;&#23548;&#35821;&#35328;&#39537;&#21160;&#30340;&#20195;&#29702;&#26426;&#22120;&#20154;&#25913;&#36827;&#33258;&#36523;&#19981;&#30830;&#23450;&#24615;&#30340;&#31995;&#32479;&#26041;&#27861;&#12290;&#36890;&#36807;&#35782;&#21035;&#20219;&#21153;&#19981;&#30830;&#23450;&#24615;&#24182;&#20027;&#21160;&#23547;&#27714;&#28548;&#28165;&#65292;&#20869;&#30465;&#26174;&#33879;&#25552;&#39640;&#20102;&#26426;&#22120;&#20154;&#20219;&#21153;&#35268;&#21010;&#30340;&#25104;&#21151;&#29575;&#21644;&#23433;&#20840;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06529</link><description>&lt;p&gt;
&#20869;&#30465;&#35268;&#21010;&#65306;&#24341;&#23548;&#35821;&#35328;&#39537;&#21160;&#30340;&#20195;&#29702;&#26426;&#22120;&#20154;&#25913;&#36827;&#33258;&#36523;&#30340;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06529
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20869;&#30465;&#35268;&#21010;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#24341;&#23548;&#35821;&#35328;&#39537;&#21160;&#30340;&#20195;&#29702;&#26426;&#22120;&#20154;&#25913;&#36827;&#33258;&#36523;&#19981;&#30830;&#23450;&#24615;&#30340;&#31995;&#32479;&#26041;&#27861;&#12290;&#36890;&#36807;&#35782;&#21035;&#20219;&#21153;&#19981;&#30830;&#23450;&#24615;&#24182;&#20027;&#21160;&#23547;&#27714;&#28548;&#28165;&#65292;&#20869;&#30465;&#26174;&#33879;&#25552;&#39640;&#20102;&#26426;&#22120;&#20154;&#20219;&#21153;&#35268;&#21010;&#30340;&#25104;&#21151;&#29575;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23637;&#31034;&#20102;&#20808;&#36827;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20351;&#24471;&#26426;&#22120;&#20154;&#33021;&#22815;&#29702;&#35299;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#65292;&#24182;&#36890;&#36807;&#36866;&#24403;&#30340;&#22522;&#30784;&#22609;&#36896;&#26469;&#31574;&#30053;&#24615;&#22320;&#36827;&#34892;&#39640;&#32423;&#34892;&#21160;&#35268;&#21010;&#12290;&#28982;&#32780;&#65292;LLM&#20135;&#29983;&#30340;&#24187;&#35273;&#21487;&#33021;&#23548;&#33268;&#26426;&#22120;&#20154;&#33258;&#20449;&#22320;&#25191;&#34892;&#19982;&#29992;&#25143;&#30446;&#26631;&#19981;&#31526;&#25110;&#22312;&#26497;&#31471;&#24773;&#20917;&#19979;&#19981;&#23433;&#20840;&#30340;&#35745;&#21010;&#12290;&#27492;&#22806;&#65292;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#20013;&#30340;&#22266;&#26377;&#27495;&#20041;&#21487;&#33021;&#24341;&#21457;&#20219;&#21153;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#22810;&#20010;&#26377;&#25928;&#36873;&#39033;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;LLMs&#24517;&#39035;&#35782;&#21035;&#27492;&#31867;&#19981;&#30830;&#23450;&#24615;&#24182;&#20027;&#21160;&#23547;&#27714;&#28548;&#28165;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#20869;&#30465;&#35268;&#21010;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#31995;&#32479;&#26041;&#27861;&#65292;&#24341;&#23548;LLMs&#22312;&#26080;&#38656;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#24418;&#25104;&#24847;&#35782;&#21040;&#19981;&#30830;&#23450;&#24615;&#30340;&#26426;&#22120;&#20154;&#20219;&#21153;&#25191;&#34892;&#35745;&#21010;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20219;&#21153;&#32423;&#26426;&#22120;&#20154;&#35268;&#21010;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#35777;&#26126;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;LLM&#30340;&#35268;&#21010;&#26041;&#27861;&#30456;&#27604;&#65292;&#20869;&#30465;&#26174;&#33879;&#25552;&#39640;&#20102;&#25104;&#21151;&#29575;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) exhibit advanced reasoning skills, enabling robots to comprehend natural language instructions and strategically plan high-level actions through proper grounding. However, LLM hallucination may result in robots confidently executing plans that are misaligned with user goals or, in extreme cases, unsafe. Additionally, inherent ambiguity in natural language instructions can induce task uncertainty, particularly in situations where multiple valid options exist. To address this issue, LLMs must identify such uncertainty and proactively seek clarification. This paper explores the concept of introspective planning as a systematic method for guiding LLMs in forming uncertainty--aware plans for robotic task execution without the need for fine-tuning. We investigate uncertainty quantification in task-level robot planning and demonstrate that introspection significantly improves both success rates and safety compared to state-of-the-art LLM-based planning approaches.
&lt;/p&gt;</description></item><item><title>CataractBot&#26159;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#30333;&#20869;&#38556;&#24739;&#32773;&#19987;&#23478;&#36741;&#21161;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#36890;&#36807;&#26597;&#35810;&#30693;&#35782;&#24211;&#25552;&#20379;&#21363;&#26102;&#30340;&#31572;&#26696;&#21644;&#19987;&#23478;&#39564;&#35777;&#30340;&#22238;&#22797;&#12290;&#22312;&#23454;&#22320;&#37096;&#32626;&#30740;&#31350;&#20013;&#35777;&#26126;&#20102;&#20854;&#20215;&#20540;&#25152;&#22312;&#12290;</title><link>https://arxiv.org/abs/2402.04620</link><description>&lt;p&gt;
CataractBot&#65306;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#30333;&#20869;&#38556;&#24739;&#32773;&#19987;&#23478;&#36741;&#21161;&#32842;&#22825;&#26426;&#22120;&#20154;
&lt;/p&gt;
&lt;p&gt;
CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract Patients
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04620
&lt;/p&gt;
&lt;p&gt;
CataractBot&#26159;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#30333;&#20869;&#38556;&#24739;&#32773;&#19987;&#23478;&#36741;&#21161;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#36890;&#36807;&#26597;&#35810;&#30693;&#35782;&#24211;&#25552;&#20379;&#21363;&#26102;&#30340;&#31572;&#26696;&#21644;&#19987;&#23478;&#39564;&#35777;&#30340;&#22238;&#22797;&#12290;&#22312;&#23454;&#22320;&#37096;&#32626;&#30740;&#31350;&#20013;&#35777;&#26126;&#20102;&#20854;&#20215;&#20540;&#25152;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21307;&#30103;&#34892;&#19994;&#30340;&#21457;&#23637;&#65292;&#24739;&#32773;&#36234;&#26469;&#36234;&#36861;&#27714;&#26356;&#21487;&#38752;&#30340;&#20581;&#24247;&#20449;&#24687;&#65292;&#21253;&#25324;&#20182;&#20204;&#30340;&#20581;&#24247;&#29366;&#20917;&#12289;&#27835;&#30103;&#36873;&#25321;&#21644;&#28508;&#22312;&#39118;&#38505;&#12290;&#34429;&#28982;&#26377;&#24456;&#22810;&#20449;&#24687;&#26469;&#28304;&#65292;&#20294;&#25968;&#23383;&#26102;&#20195;&#21364;&#32473;&#20154;&#20204;&#24102;&#26469;&#20102;&#36807;&#22810;&#19988;&#38169;&#35823;&#30340;&#20449;&#24687;&#12290;&#24739;&#32773;&#20027;&#35201;&#20449;&#20219;&#21307;&#29983;&#21644;&#21307;&#38498;&#24037;&#20316;&#20154;&#21592;&#65292;&#31361;&#26174;&#20102;&#19987;&#23478;&#35748;&#21487;&#30340;&#20581;&#24247;&#20449;&#24687;&#30340;&#24517;&#35201;&#24615;&#12290;&#20294;&#26159;&#65292;&#19987;&#23478;&#38754;&#20020;&#30340;&#21387;&#21147;&#23548;&#33268;&#20102;&#27807;&#36890;&#26102;&#38388;&#30340;&#20943;&#23569;&#65292;&#24433;&#21709;&#20102;&#20449;&#24687;&#30340;&#20849;&#20139;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CataractBot&#65292;&#19968;&#31181;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39537;&#21160;&#30340;&#19987;&#23478;&#36741;&#21161;&#32842;&#22825;&#26426;&#22120;&#20154;&#12290;&#19982;&#21360;&#24230;&#19968;&#23478;&#19977;&#32423;&#30524;&#31185;&#21307;&#38498;&#21512;&#20316;&#24320;&#21457;&#30340;CataractBot&#36890;&#36807;&#26597;&#35810;&#31574;&#21010;&#30340;&#30693;&#35782;&#24211;&#65292;&#21363;&#26102;&#22238;&#31572;&#30333;&#20869;&#38556;&#25163;&#26415;&#30456;&#20851;&#30340;&#38382;&#39064;&#65292;&#24182;&#24322;&#27493;&#25552;&#20379;&#19987;&#23478;&#39564;&#35777;&#30340;&#31572;&#22797;&#12290;CataractBot&#20855;&#22791;&#22810;&#27169;&#24335;&#25903;&#25345;&#21644;&#22810;&#35821;&#35328;&#33021;&#21147;&#12290;&#22312;&#19982;49&#21517;&#21442;&#19982;&#32773;&#30340;&#23454;&#22320;&#37096;&#32626;&#30740;&#31350;&#20013;&#65292;CataractBot&#35777;&#26126;&#20102;&#20854;&#20215;&#20540;&#25152;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
The healthcare landscape is evolving, with patients seeking more reliable information about their health conditions, treatment options, and potential risks. Despite the abundance of information sources, the digital age overwhelms individuals with excess, often inaccurate information. Patients primarily trust doctors and hospital staff, highlighting the need for expert-endorsed health information. However, the pressure on experts has led to reduced communication time, impacting information sharing. To address this gap, we propose CataractBot, an experts-in-the-loop chatbot powered by large language models (LLMs). Developed in collaboration with a tertiary eye hospital in India, CataractBot answers cataract surgery related questions instantly by querying a curated knowledge base, and provides expert-verified responses asynchronously. CataractBot features multimodal support and multilingual capabilities. In an in-the-wild deployment study with 49 participants, CataractBot proved valuable,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#21452;&#20869;&#28857;&#20248;&#21270;&#23398;&#20064;&#21644;&#21452;&#36229;&#26799;&#24230;&#23398;&#20064;&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#24102;&#26377;&#26377;&#30028;&#21464;&#37327;&#30340;&#21442;&#25968;&#32447;&#24615;&#35268;&#21010;&#30340;&#23545;&#20598;&#21487;&#34892;&#35299;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#36807;&#39044;&#27979;&#32422;&#26463;&#23545;&#24212;&#30340;&#23545;&#20598;&#21464;&#37327;&#65292;&#30830;&#20445;&#23545;&#20598;&#21487;&#34892;&#24615;&#65292;&#24182;&#19988;&#33021;&#22815;&#25552;&#20379;&#39640;&#20445;&#30495;&#24230;&#30340;&#23545;&#20598;&#21487;&#34892;&#35299;&#21644;&#26377;&#25928;&#30340;&#23545;&#20598;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.02596</link><description>&lt;p&gt;
&#21452;&#20869;&#28857;&#20248;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Dual Interior-Point Optimization Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02596
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#21452;&#20869;&#28857;&#20248;&#21270;&#23398;&#20064;&#21644;&#21452;&#36229;&#26799;&#24230;&#23398;&#20064;&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#24102;&#26377;&#26377;&#30028;&#21464;&#37327;&#30340;&#21442;&#25968;&#32447;&#24615;&#35268;&#21010;&#30340;&#23545;&#20598;&#21487;&#34892;&#35299;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#36807;&#39044;&#27979;&#32422;&#26463;&#23545;&#24212;&#30340;&#23545;&#20598;&#21464;&#37327;&#65292;&#30830;&#20445;&#23545;&#20598;&#21487;&#34892;&#24615;&#65292;&#24182;&#19988;&#33021;&#22815;&#25552;&#20379;&#39640;&#20445;&#30495;&#24230;&#30340;&#23545;&#20598;&#21487;&#34892;&#35299;&#21644;&#26377;&#25928;&#30340;&#23545;&#20598;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#21452;&#20869;&#28857;&#23398;&#20064;&#65288;DIPL&#65289;&#21644;&#21452;&#36229;&#26799;&#24230;&#23398;&#20064;&#65288;DSL&#65289;&#65292;&#20197;&#23398;&#20064;&#24102;&#26377;&#26377;&#30028;&#21464;&#37327;&#30340;&#21442;&#25968;&#32447;&#24615;&#35268;&#21010;&#30340;&#23545;&#20598;&#21487;&#34892;&#35299;&#65292;&#36825;&#22312;&#35768;&#22810;&#34892;&#19994;&#20013;&#37117;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#12290;DIPL&#27169;&#25311;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#20598;&#20869;&#28857;&#31639;&#27861;&#65292;&#32780;DSL&#21017;&#27169;&#25311;&#20102;&#32463;&#20856;&#30340;&#23545;&#20598;&#36229;&#26799;&#24230;&#19978;&#21319;&#31639;&#27861;&#12290;&#36890;&#36807;&#39044;&#27979;&#19982;&#32422;&#26463;&#20851;&#32852;&#30340;&#23545;&#20598;&#21464;&#37327;&#65292;DIPL&#21644;DSL&#20445;&#35777;&#23545;&#20598;&#21487;&#34892;&#24615;&#65292;&#28982;&#21518;&#21033;&#29992;&#23545;&#20110;&#32422;&#26463;&#30028;&#38480;&#30340;&#23545;&#20598;&#30340;&#28789;&#27963;&#24615;&#12290;DIPL&#21644;DSL&#36890;&#36807;&#25552;&#20379;&#36136;&#37327;&#35777;&#26126;&#26469;&#34917;&#20805;&#29616;&#26377;&#30340;&#21407;&#22987;&#23398;&#20064;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#23427;&#20204;&#33021;&#22815;&#20026;&#22823;&#35268;&#27169;&#26368;&#20248;&#21151;&#29575;&#27969;&#38382;&#39064;&#20135;&#29983;&#39640;&#20445;&#30495;&#24230;&#30340;&#23545;&#20598;&#21487;&#34892;&#35299;&#65292;&#24182;&#22312;0.5%&#30340;&#20248;&#21270;&#24046;&#36317;&#19979;&#25552;&#20379;&#26377;&#25928;&#30340;&#23545;&#20598;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces Dual Interior Point Learning (DIPL) and Dual Supergradient Learning (DSL) to learn dual feasible solutions to parametric linear programs with bounded variables, which are pervasive across many industries. DIPL mimics a novel dual interior point algorithm while DSL mimics classical dual supergradient ascent. DIPL and DSL ensure dual feasibility by predicting dual variables associated with the constraints then exploiting the flexibility of the duals of the bound constraints. DIPL and DSL complement existing primal learning methods by providing a certificate of quality. They are shown to produce high-fidelity dual-feasible solutions to large-scale optimal power flow problems providing valid dual bounds under 0.5% optimality gap.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35843;&#26597;&#20102;&#20154;&#24037;&#26234;&#33021;&#20013;&#29702;&#24615;&#19982;&#38750;&#29702;&#24615;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#26410;&#35299;&#38382;&#39064;&#12290;&#37325;&#28857;&#35752;&#35770;&#20102;&#34892;&#20026;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#38750;&#29702;&#24615;&#34892;&#20026;&#21487;&#33021;&#26159;&#26368;&#20248;&#30340;&#24773;&#20917;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#26469;&#22788;&#29702;&#38750;&#29702;&#24615;&#20195;&#29702;&#65292;&#20294;&#20173;&#23384;&#22312;&#25361;&#25112;&#21644;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.17165</link><description>&lt;p&gt;
(&#38750;)&#29702;&#24615;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#24212;&#29992;&#65306;&#29616;&#29366;&#12289;&#30740;&#31350;&#25361;&#25112;&#21644;&#26410;&#35299;&#20043;&#38382;
&lt;/p&gt;
&lt;p&gt;
(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17165
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35843;&#26597;&#20102;&#20154;&#24037;&#26234;&#33021;&#20013;&#29702;&#24615;&#19982;&#38750;&#29702;&#24615;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#26410;&#35299;&#38382;&#39064;&#12290;&#37325;&#28857;&#35752;&#35770;&#20102;&#34892;&#20026;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#38750;&#29702;&#24615;&#34892;&#20026;&#21487;&#33021;&#26159;&#26368;&#20248;&#30340;&#24773;&#20917;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#26469;&#22788;&#29702;&#38750;&#29702;&#24615;&#20195;&#29702;&#65292;&#20294;&#20173;&#23384;&#22312;&#25361;&#25112;&#21644;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#24615;&#27010;&#24565;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20013;&#21344;&#25454;&#30528;&#37325;&#35201;&#22320;&#20301;&#12290;&#26080;&#35770;&#26159;&#27169;&#25311;&#20154;&#31867;&#25512;&#29702;&#36824;&#26159;&#36861;&#27714;&#26377;&#38480;&#26368;&#20248;&#24615;&#65292;&#25105;&#20204;&#36890;&#24120;&#24076;&#26395;&#20351;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#23613;&#21487;&#33021;&#29702;&#24615;&#12290;&#23613;&#31649;&#36825;&#20010;&#27010;&#24565;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#38750;&#24120;&#26680;&#24515;&#65292;&#20294;&#23545;&#20110;&#20160;&#20040;&#26500;&#25104;&#29702;&#24615;&#20195;&#29702;&#24182;&#27809;&#26377;&#32479;&#19968;&#30340;&#23450;&#20041;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#29702;&#24615;&#19982;&#38750;&#29702;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36825;&#20010;&#39046;&#22495;&#30340;&#26410;&#35299;&#38382;&#39064;&#12290;&#22312;&#20854;&#20182;&#39046;&#22495;&#23545;&#29702;&#24615;&#30340;&#29702;&#35299;&#23545;&#20854;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#27010;&#24565;&#20135;&#29983;&#20102;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#32463;&#27982;&#23398;&#12289;&#21746;&#23398;&#21644;&#24515;&#29702;&#23398;&#26041;&#38754;&#30340;&#30740;&#31350;&#12290;&#30528;&#37325;&#32771;&#34385;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#30340;&#34892;&#20026;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#26576;&#20123;&#24773;&#22659;&#20013;&#38750;&#29702;&#24615;&#34892;&#20026;&#21487;&#33021;&#26159;&#26368;&#20248;&#30340;&#24773;&#20917;&#12290;&#20851;&#20110;&#22788;&#29702;&#38750;&#29702;&#24615;&#20195;&#29702;&#30340;&#26041;&#27861;&#24050;&#32463;&#24471;&#21040;&#20102;&#19968;&#20123;&#21457;&#23637;&#65292;&#21253;&#25324;&#35782;&#21035;&#21644;&#20132;&#20114;&#31561;&#26041;&#38754;&#30340;&#30740;&#31350;&#65292;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#39046;&#22495;&#30340;&#24037;&#20316;&#20173;&#28982;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#21644;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.17165v2 Announce Type: replace Abstract: The concept of rationality is central to the field of artificial intelligence. Whether we are seeking to simulate human reasoning, or the goal is to achieve bounded optimality, we generally seek to make artificial agents as rational as possible. Despite the centrality of the concept within AI, there is no unified definition of what constitutes a rational agent. This article provides a survey of rationality and irrationality in artificial intelligence, and sets out the open questions in this area. The understanding of rationality in other fields has influenced its conception within artificial intelligence, in particular work in economics, philosophy and psychology. Focusing on the behaviour of artificial agents, we consider irrational behaviours that can prove to be optimal in certain scenarios. Some methods have been developed to deal with irrational agents, both in terms of identification and interaction, however work in this area re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BASS&#30340;&#22522;&#20110;&#24191;&#25773;&#30340;&#23376;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#21152;&#36895;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#20943;&#23569;&#36890;&#20449;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2401.13779</link><description>&lt;p&gt;
&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#23569;&#30340;&#36890;&#20449;&#25104;&#26412;&#65306;&#29992;&#20110;&#26080;&#32447;&#32593;&#32476;&#30340;&#22522;&#20110;&#24191;&#25773;&#30340;&#23376;&#22270;&#37319;&#26679;&#30340;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Faster Convergence with Less Communication: Broadcast-Based Subgraph Sampling for Decentralized Learning over Wireless Networks. (arXiv:2401.13779v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BASS&#30340;&#22522;&#20110;&#24191;&#25773;&#30340;&#23376;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#21152;&#36895;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#20943;&#23569;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20849;&#35782;&#30340;&#21435;&#20013;&#24515;&#21270;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(D-SGD)&#26159;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#32593;&#32476;&#20195;&#29702;&#20043;&#38388;&#30340;&#21435;&#20013;&#24515;&#21270;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12290;D-SGD&#30340;&#19968;&#20010;&#20851;&#38190;&#37096;&#20998;&#26159;&#22522;&#20110;&#20849;&#35782;&#30340;&#27169;&#22411;&#24179;&#22343;&#65292;&#23427;&#20005;&#37325;&#20381;&#36182;&#20110;&#33410;&#28857;&#20043;&#38388;&#30340;&#20449;&#24687;&#20132;&#25442;&#21644;&#34701;&#21512;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#22312;&#26080;&#32447;&#32593;&#32476;&#19978;&#30340;&#20849;&#35782;&#24179;&#22343;&#65292;&#36890;&#20449;&#21327;&#35843;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#30830;&#23450;&#33410;&#28857;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#35775;&#38382;&#20449;&#36947;&#65292;&#24182;&#23558;&#20449;&#24687;&#20256;&#36755;&#65288;&#25110;&#25509;&#25910;&#65289;&#32473;&#65288;&#25110;&#20174;&#65289;&#37051;&#23621;&#33410;&#28857;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BASS&#30340;&#22522;&#20110;&#24191;&#25773;&#30340;&#23376;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#26088;&#22312;&#21152;&#24555;D-SGD&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#32771;&#34385;&#27599;&#36718;&#36845;&#20195;&#30340;&#23454;&#38469;&#36890;&#20449;&#25104;&#26412;&#12290;BASS&#21019;&#24314;&#19968;&#32452;&#28151;&#21512;&#30697;&#38453;&#20505;&#36873;&#39033;&#65292;&#34920;&#31034;&#22522;&#30784;&#25299;&#25169;&#30340;&#31232;&#30095;&#23376;&#22270;&#12290;&#22312;&#27599;&#20010;&#20849;&#35782;&#36845;&#20195;&#20013;&#65292;&#23558;&#37319;&#26679;&#19968;&#20010;&#28151;&#21512;&#30697;&#38453;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#20010;&#29305;&#23450;&#30340;&#35843;&#24230;&#20915;&#31574;&#65292;&#28608;&#27963;&#22810;&#20010;&#26080;&#30896;&#25758;&#30340;&#33410;&#28857;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consensus-based decentralized stochastic gradient descent (D-SGD) is a widely adopted algorithm for decentralized training of machine learning models across networked agents. A crucial part of D-SGD is the consensus-based model averaging, which heavily relies on information exchange and fusion among the nodes. Specifically, for consensus averaging over wireless networks, communication coordination is necessary to determine when and how a node can access the channel and transmit (or receive) information to (or from) its neighbors. In this work, we propose $\texttt{BASS}$, a broadcast-based subgraph sampling method designed to accelerate the convergence of D-SGD while considering the actual communication cost per iteration. $\texttt{BASS}$ creates a set of mixing matrix candidates that represent sparser subgraphs of the base topology. In each consensus iteration, one mixing matrix is sampled, leading to a specific scheduling decision that activates multiple collision-free subsets of node
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#20998;&#25955;&#32593;&#32476;&#30340;&#36890;&#20449;&#39640;&#25928;&#31639;&#27861;PISCO, &#36890;&#36807;&#27010;&#29575;&#24615;&#30340;&#20195;&#29702;&#38388;&#21644;&#20195;&#29702;&#19982;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#36890;&#20449;&#65292;&#23454;&#29616;&#20102;&#36890;&#20449;&#25928;&#29575;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#25240;&#34935;&#12290;</title><link>http://arxiv.org/abs/2311.18787</link><description>&lt;p&gt;
&#36890;&#20449;&#39640;&#25928;&#30340;&#21322;&#20998;&#25955;&#32593;&#32476;&#32852;&#37030;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Federated Optimization over Semi-Decentralized Networks. (arXiv:2311.18787v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.18787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#20998;&#25955;&#32593;&#32476;&#30340;&#36890;&#20449;&#39640;&#25928;&#31639;&#27861;PISCO, &#36890;&#36807;&#27010;&#29575;&#24615;&#30340;&#20195;&#29702;&#38388;&#21644;&#20195;&#29702;&#19982;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#36890;&#20449;&#65292;&#23454;&#29616;&#20102;&#36890;&#20449;&#25928;&#29575;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#25240;&#34935;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#30340;&#32852;&#37030;&#21644;&#20998;&#25955;&#24335;&#23398;&#20064;&#20013;&#65292;&#36890;&#20449;&#25928;&#29575;&#26159;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#29942;&#39048;&#20043;&#19968;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#20998;&#25955;&#36890;&#20449;&#21327;&#35758;&#19979;&#30340;&#36890;&#20449;&#39640;&#25928;&#31639;&#27861;PISCO&#65292;&#36890;&#36807;&#27010;&#29575;&#24615;&#30340;&#20195;&#29702;&#38388;&#21644;&#20195;&#29702;&#19982;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#36890;&#20449;&#65292;&#23454;&#29616;&#20102;&#36890;&#20449;&#25928;&#29575;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#25240;&#34935;&#12290;PISCO&#31639;&#27861;&#36890;&#36807;&#26799;&#24230;&#36861;&#36394;&#21644;&#22810;&#20010;&#26412;&#22320;&#26356;&#26032;&#20445;&#35777;&#20102;&#23545;&#25968;&#25454;&#24322;&#36136;&#24615;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;PISCO&#31639;&#27861;&#22312;&#38750;&#20984;&#38382;&#39064;&#19978;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#25968;&#37327;&#26041;&#38754;&#65292;PISCO&#31639;&#27861;&#20855;&#26377;&#32447;&#24615;&#21152;&#36895;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
In large-scale federated and decentralized learning, communication efficiency is one of the most challenging bottlenecks. While gossip communication -- where agents can exchange information with their connected neighbors -- is more cost-effective than communicating with the remote server, it often requires a greater number of communication rounds, especially for large and sparse networks. To tackle the trade-off, we examine the communication efficiency under a semi-decentralized communication protocol, in which agents can perform both agent-to-agent and agent-to-server communication in a probabilistic manner. We design a tailored communication-efficient algorithm over semi-decentralized networks, referred to as PISCO, which inherits the robustness to data heterogeneity thanks to gradient tracking and allows multiple local updates for saving communication. We establish the convergence rate of PISCO for nonconvex problems and show that PISCO enjoys a linear speedup in terms of the number
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26435;&#37325;&#21098;&#35009;&#30340;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20844;&#20849;&#20449;&#24687;&#23545;&#20840;&#23616;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#65292;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#28789;&#25935;&#24230;&#30028;&#38480;&#21644;&#22122;&#22768;&#27700;&#24179;&#35843;&#25972;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.18001</link><description>&lt;p&gt;
&#24102;&#26435;&#37325;&#21098;&#35009;&#30340;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DP-SGD with weight clipping. (arXiv:2310.18001v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26435;&#37325;&#21098;&#35009;&#30340;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20844;&#20849;&#20449;&#24687;&#23545;&#20840;&#23616;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#65292;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#28789;&#25935;&#24230;&#30028;&#38480;&#21644;&#22122;&#22768;&#27700;&#24179;&#35843;&#25972;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#20854;&#20182;&#20381;&#36182;&#20110;&#30446;&#26631;&#20989;&#25968;&#20248;&#21270;&#30340;&#26041;&#27861;&#30340;&#39640;&#24230;&#27969;&#34892;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#38544;&#31169;&#30340;&#20851;&#27880;&#65292;&#24046;&#20998;&#38544;&#31169;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;&#20026;&#20102;&#22312;&#25552;&#20379;&#26368;&#23567;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#65292;&#33021;&#22815;&#20934;&#30830;&#22320;&#38480;&#21046;&#21442;&#19982;&#32773;&#23558;&#35266;&#23519;&#21040;&#30340;&#20449;&#24687;&#30340;&#28789;&#25935;&#24230;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#24357;&#34917;&#20102;&#20256;&#32479;&#26799;&#24230;&#21098;&#35009;&#20135;&#29983;&#30340;&#20559;&#24046;&#12290;&#36890;&#36807;&#21033;&#29992;&#20851;&#20110;&#24403;&#21069;&#20840;&#23616;&#27169;&#22411;&#21450;&#20854;&#22312;&#25628;&#32034;&#39046;&#22495;&#20013;&#20301;&#32622;&#30340;&#20844;&#20849;&#20449;&#24687;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#25913;&#36827;&#30340;&#26799;&#24230;&#30028;&#38480;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#28789;&#25935;&#24230;&#30830;&#23450;&#21644;&#22122;&#22768;&#27700;&#24179;&#35843;&#25972;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#65292;&#38656;&#35201;&#26356;&#23569;&#30340;&#22122;&#22768;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, due to the popularity of deep neural networks and other methods whose training typically relies on the optimization of an objective function, and due to concerns for data privacy, there is a lot of interest in differentially private gradient descent methods. To achieve differential privacy guarantees with a minimum amount of noise, it is important to be able to bound precisely the sensitivity of the information which the participants will observe. In this study, we present a novel approach that mitigates the bias arising from traditional gradient clipping. By leveraging public information concerning the current global model and its location within the search domain, we can achieve improved gradient bounds, leading to enhanced sensitivity determinations and refined noise level adjustments. We extend the state of the art algorithms, present improved differential privacy guarantees requiring less noise and present an empirical evaluation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#65292;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#12290;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.08731</link><description>&lt;p&gt;
&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#22312;&#19990;&#30028;&#27169;&#22411;&#20013;&#23454;&#29616;&#26032;&#39062;&#24615;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Simple Way to Incorporate Novelty Detection in World Models. (arXiv:2310.08731v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#65292;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#12290;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#19990;&#30028;&#27169;&#22411;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#24403;&#19990;&#30028;&#26426;&#21046;&#25110;&#23646;&#24615;&#21457;&#29983;&#31361;&#28982;&#21464;&#21270;&#26102;&#65292;&#20195;&#29702;&#30340;&#24615;&#33021;&#21644;&#21487;&#38752;&#24615;&#21487;&#33021;&#20250;&#26174;&#33879;&#19979;&#38477;&#12290;&#25105;&#20204;&#23558;&#35270;&#35273;&#23646;&#24615;&#25110;&#29366;&#24577;&#36716;&#25442;&#30340;&#31361;&#21464;&#31216;&#20026;&#8220;&#26032;&#39062;&#24615;&#8221;&#12290;&#22312;&#29983;&#25104;&#30340;&#19990;&#30028;&#27169;&#22411;&#26694;&#26550;&#20013;&#23454;&#26045;&#26032;&#39062;&#24615;&#26816;&#27979;&#26159;&#20445;&#25252;&#37096;&#32626;&#26102;&#20195;&#29702;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36793;&#30028;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#26032;&#39062;&#24615;&#26816;&#27979;&#32435;&#20837;&#19990;&#30028;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20013;&#65292;&#36890;&#36807;&#21033;&#29992;&#19990;&#30028;&#27169;&#22411;&#24187;&#35273;&#29366;&#24577;&#21644;&#30495;&#23454;&#35266;&#23519;&#29366;&#24577;&#30340;&#19981;&#21305;&#37197;&#24615;&#20316;&#20026;&#24322;&#24120;&#20998;&#25968;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19982;&#24207;&#21015;&#20915;&#31574;&#30456;&#20851;&#30340;&#26032;&#39062;&#24615;&#26816;&#27979;&#26412;&#20307;&#35770;&#65292;&#28982;&#21518;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#20195;&#29702;&#22312;&#19990;&#30028;&#27169;&#22411;&#20013;&#23398;&#20064;&#30340;&#36716;&#25442;&#20998;&#24067;&#20013;&#26816;&#27979;&#26032;&#39062;&#24615;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#26032;&#29615;&#22659;&#20013;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as {\em novelties}. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We first provide an ontology of novelty detection relevant to sequential decision making, then we provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional ma
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;EMR&#25968;&#25454;&#38598;&#20043;&#38388;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#30340;&#39044;&#21518;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#36807;&#28193;&#27169;&#22411;&#35299;&#20915;&#20102;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.07799</link><description>&lt;p&gt;
&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;EMR&#25968;&#25454;&#38598;&#20043;&#38388;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#30340;&#39044;&#21518;&#39044;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Transfer-Learning-Based Prognosis Prediction Paradigm that Bridges Data Distribution Shift across EMR Datasets. (arXiv:2310.07799v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07799
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;EMR&#25968;&#25454;&#38598;&#20043;&#38388;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#30340;&#39044;&#21518;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#36807;&#28193;&#27169;&#22411;&#35299;&#20915;&#20102;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#23545;&#26032;&#20852;&#30142;&#30149;&#30340;&#20449;&#24687;&#26377;&#38480;&#65292;&#30151;&#29366;&#24456;&#38590;&#34987;&#23519;&#35273;&#21644;&#35748;&#35782;&#21040;&#65292;&#22240;&#27492;&#21487;&#33021;&#24573;&#35270;&#20020;&#24202;&#24178;&#39044;&#30340;&#31383;&#21475;&#12290;&#26399;&#26395;&#33021;&#22815;&#24314;&#31435;&#19968;&#20010;&#26377;&#25928;&#30340;&#39044;&#21518;&#27169;&#22411;&#65292;&#36741;&#21161;&#21307;&#29983;&#36827;&#34892;&#27491;&#30830;&#35786;&#26029;&#21644;&#21046;&#23450;&#20010;&#24615;&#21270;&#27835;&#30103;&#26041;&#26696;&#65292;&#20174;&#32780;&#21450;&#26102;&#39044;&#38450;&#19981;&#21033;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#30142;&#30149;&#26089;&#26399;&#38454;&#27573;&#65292;&#30001;&#20110;&#25968;&#25454;&#25910;&#38598;&#21644;&#20020;&#24202;&#32463;&#39564;&#26377;&#38480;&#65292;&#20877;&#21152;&#19978;&#23545;&#38544;&#31169;&#21644;&#20262;&#29702;&#30340;&#32771;&#34385;&#65292;&#23548;&#33268;&#21487;&#20379;&#21442;&#32771;&#30340;&#25968;&#25454;&#21463;&#38480;&#65292;&#29978;&#33267;&#38590;&#20197;&#27491;&#30830;&#26631;&#35760;&#25968;&#25454;&#26631;&#31614;&#12290;&#27492;&#22806;&#65292;&#19981;&#21516;&#30142;&#30149;&#25110;&#21516;&#19968;&#30142;&#30149;&#19981;&#21516;&#26469;&#28304;&#30340;&#30005;&#23376;&#21307;&#30103;&#35760;&#24405;&#65288;EMR&#65289;&#25968;&#25454;&#21487;&#33021;&#23384;&#22312;&#20005;&#37325;&#30340;&#36328;&#25968;&#25454;&#38598;&#29305;&#24449;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#20005;&#37325;&#24433;&#21709;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#29575;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#24314;&#31435;&#19968;&#20010;&#20174;&#28304;&#25968;&#25454;&#38598;&#21040;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#36807;&#28193;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#29305;&#24449;&#36827;&#34892;&#32422;&#26463;&#65292;&#26469;&#35299;&#20915;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the limited information about emerging diseases, symptoms are hard to be noticed and recognized, so that the window for clinical intervention could be ignored. An effective prognostic model is expected to assist doctors in making right diagnosis and designing personalized treatment plan, so to promptly prevent unfavorable outcomes. However, in the early stage of a disease, limited data collection and clinical experiences, plus the concern out of privacy and ethics, may result in restricted data availability for reference, to the extent that even data labels are difficult to mark correctly. In addition, Electronic Medical Record (EMR) data of different diseases or of different sources of the same disease can prove to be having serious cross-dataset feature misalignment problems, greatly mutilating the efficiency of deep learning models. This article introduces a transfer learning method to build a transition model from source dataset to target dataset. By way of constraining the 
&lt;/p&gt;</description></item><item><title>AdaRec&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#39034;&#24207;&#25512;&#33616;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#36317;&#31163;&#30340;&#34920;&#31034;&#25439;&#22833;&#26469;&#25552;&#21462;&#28508;&#22312;&#20449;&#24687;&#65292;&#20197;&#36866;&#24212;&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#30340;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.03984</link><description>&lt;p&gt;
AdaRec&#65306;&#29992;&#20110;&#22686;&#24378;&#29992;&#25143;&#38271;&#26399;&#21442;&#19982;&#24230;&#30340;&#33258;&#36866;&#24212;&#39034;&#24207;&#25512;&#33616;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
AdaRec: Adaptive Sequential Recommendation for Reinforcing Long-term User Engagement. (arXiv:2310.03984v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03984
&lt;/p&gt;
&lt;p&gt;
AdaRec&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#39034;&#24207;&#25512;&#33616;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#36317;&#31163;&#30340;&#34920;&#31034;&#25439;&#22833;&#26469;&#25552;&#21462;&#28508;&#22312;&#20449;&#24687;&#65292;&#20197;&#36866;&#24212;&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39034;&#24207;&#25512;&#33616;&#20219;&#21153;&#20013;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#20248;&#21270;&#29992;&#25143;&#30340;&#38271;&#26399;&#21442;&#19982;&#24230;&#12290;&#22823;&#35268;&#27169;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#65288;&#22914;&#20114;&#21160;&#39057;&#29575;&#21644;&#20445;&#30041;&#20542;&#21521;&#65289;&#30340;&#19981;&#26029;&#22797;&#26434;&#21464;&#21270;&#12290;&#24403;&#23558;&#38382;&#39064;&#24314;&#27169;&#20026;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#26102;&#65292;&#25512;&#33616;&#31995;&#32479;&#30340;&#21160;&#24577;&#21644;&#22870;&#21169;&#20989;&#25968;&#20250;&#19981;&#26029;&#21463;&#21040;&#36825;&#20123;&#21464;&#21270;&#30340;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#25512;&#33616;&#31995;&#32479;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20250;&#21463;&#21040;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#30340;&#22256;&#25200;&#65292;&#24182;&#38590;&#20197;&#36866;&#24212;&#36825;&#31181;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#24335;&#65292;&#31216;&#20026;&#33258;&#36866;&#24212;&#39034;&#24207;&#25512;&#33616;&#65288;AdaRec&#65289;&#65292;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;AdaRec&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#34920;&#31034;&#25439;&#22833;&#65292;&#20174;&#29992;&#25143;&#30340;&#20114;&#21160;&#36712;&#36857;&#20013;&#25552;&#21462;&#28508;&#22312;&#20449;&#24687;&#12290;&#36825;&#20123;&#20449;&#24687;&#21453;&#26144;&#20102;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#19982;&#24403;&#21069;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#30340;&#21305;&#37197;&#31243;&#24230;&#65292;&#24182;&#24110;&#21161;&#31574;&#30053;&#35782;&#21035;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#32454;&#24494;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Growing attention has been paid to Reinforcement Learning (RL) algorithms when optimizing long-term user engagement in sequential recommendation tasks. One challenge in large-scale online recommendation systems is the constant and complicated changes in users' behavior patterns, such as interaction rates and retention tendencies. When formulated as a Markov Decision Process (MDP), the dynamics and reward functions of the recommendation system are continuously affected by these changes. Existing RL algorithms for recommendation systems will suffer from distribution shift and struggle to adapt in such an MDP. In this paper, we introduce a novel paradigm called Adaptive Sequential Recommendation (AdaRec) to address this issue. AdaRec proposes a new distance-based representation loss to extract latent information from users' interaction trajectories. Such information reflects how RL policy fits to current user behavior patterns, and helps the policy to identify subtle changes in the recomm
&lt;/p&gt;</description></item><item><title>FairDP&#26159;&#19968;&#31181;&#21516;&#26102;&#30830;&#20445;&#24046;&#20998;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30340;&#26032;&#22411;&#26426;&#21046;&#65292;&#36890;&#36807;&#29420;&#31435;&#20026;&#19981;&#21516;&#30340;&#20010;&#20307;&#32676;&#20307;&#35757;&#32451;&#27169;&#22411;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#27493;&#25972;&#21512;&#26469;&#33258;&#32676;&#20307;&#27169;&#22411;&#30340;&#30693;&#35782;&#65292;&#21046;&#23450;&#32508;&#21512;&#27169;&#22411;&#20197;&#24179;&#34913;&#38544;&#31169;&#12289;&#25928;&#29992;&#21644;&#20844;&#24179;&#24615;&#30340;&#19979;&#28216;&#20219;&#21153;&#12290;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;FairDP&#23637;&#31034;&#20102;&#26356;&#22909;&#30340;&#27169;&#22411;&#25928;&#30410;&#12289;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.16474</link><description>&lt;p&gt;
FairDP: &#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#35748;&#35777;&#30340;&#20844;&#24179;&#24615;&#20445;&#38556;
&lt;/p&gt;
&lt;p&gt;
FairDP: Certified Fairness with Differential Privacy. (arXiv:2305.16474v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16474
&lt;/p&gt;
&lt;p&gt;
FairDP&#26159;&#19968;&#31181;&#21516;&#26102;&#30830;&#20445;&#24046;&#20998;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30340;&#26032;&#22411;&#26426;&#21046;&#65292;&#36890;&#36807;&#29420;&#31435;&#20026;&#19981;&#21516;&#30340;&#20010;&#20307;&#32676;&#20307;&#35757;&#32451;&#27169;&#22411;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#27493;&#25972;&#21512;&#26469;&#33258;&#32676;&#20307;&#27169;&#22411;&#30340;&#30693;&#35782;&#65292;&#21046;&#23450;&#32508;&#21512;&#27169;&#22411;&#20197;&#24179;&#34913;&#38544;&#31169;&#12289;&#25928;&#29992;&#21644;&#20844;&#24179;&#24615;&#30340;&#19979;&#28216;&#20219;&#21153;&#12290;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;FairDP&#23637;&#31034;&#20102;&#26356;&#22909;&#30340;&#27169;&#22411;&#25928;&#30410;&#12289;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;FairDP&#30340;&#26032;&#22411;&#26426;&#21046;&#65292;&#26088;&#22312;&#21516;&#26102;&#30830;&#20445;&#24046;&#20998;&#38544;&#31169;(DP)&#21644;&#20844;&#24179;&#24615;&#12290;FairDP&#36890;&#36807;&#29420;&#31435;&#20026;&#19981;&#21516;&#30340;&#20010;&#20307;&#32676;&#20307;&#35757;&#32451;&#27169;&#22411;&#65292;&#22312;&#20351;&#29992;&#32452;&#29305;&#23450;&#30340;&#21098;&#35009;&#39033;&#26469;&#35780;&#20272;&#21644;&#38480;&#21046;DP&#30340;&#24046;&#24322;&#24433;&#21709;&#30340;&#21516;&#26102;&#25805;&#20316;&#12290;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#35813;&#26426;&#21046;&#36880;&#27493;&#25972;&#21512;&#26469;&#33258;&#32676;&#20307;&#27169;&#22411;&#30340;&#30693;&#35782;&#65292;&#21046;&#23450;&#32508;&#21512;&#27169;&#22411;&#20197;&#24179;&#34913;&#38544;&#31169;&#12289;&#25928;&#29992;&#21644;&#20844;&#24179;&#24615;&#30340;&#19979;&#28216;&#20219;&#21153;&#12290;&#24191;&#27867;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#39564;&#35777;&#20102;FairDP&#30340;&#21151;&#25928;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#23637;&#31034;&#20102;&#26356;&#22909;&#30340;&#27169;&#22411;&#25928;&#30410;&#12289;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces FairDP, a novel mechanism designed to simultaneously ensure differential privacy (DP) and fairness. FairDP operates by independently training models for distinct individual groups, using group-specific clipping terms to assess and bound the disparate impacts of DP. Throughout the training process, the mechanism progressively integrates knowledge from group models to formulate a comprehensive model that balances privacy, utility, and fairness in downstream tasks. Extensive theoretical and empirical analyses validate the efficacy of FairDP, demonstrating improved trade-offs between model utility, privacy, and fairness compared with existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.05642</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A duality framework for generalization analysis of random feature models and two-layer neural networks. (arXiv:2305.05642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#39640;&#32500;&#20998;&#26512;&#20013;&#20986;&#29616;&#30340;&#33258;&#28982;&#20989;&#25968;&#31354;&#38388; $\mathcal{F}_{p,\pi}$ &#21644; Barron &#31354;&#38388;&#20013;&#23398;&#20064;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23545;&#20598;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20123;&#31354;&#38388;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#21487;&#20197;&#22312;&#26576;&#31181;&#24847;&#20041;&#19979;&#34987;&#35270;&#20026;&#31561;&#20215;&#30340;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#22312;&#30740;&#31350;&#36825;&#20004;&#31181;&#27169;&#22411;&#30340;&#27867;&#21270;&#26102;&#26356;&#19987;&#27880;&#20110;&#26356;&#23481;&#26131;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#30340;&#22797;&#26434;&#24230;&#26469;&#26377;&#25928;&#22320;&#25511;&#21046;&#20272;&#35745;&#35823;&#24046;&#65292;&#24314;&#31435;&#20102;&#23545;&#20598;&#31561;&#20215;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#20004;&#20010;&#20855;&#20307;&#24212;&#29992;&#36827;&#34892;&#32508;&#21512;&#20998;&#26512;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#12290;&#31532;&#19968;&#20010;&#24212;&#29992;&#26159;&#30740;&#31350;&#20351;&#29992; RFMs &#23398;&#20064; $\mathcal{F}_{p,\pi}$ &#20013;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#21482;&#35201; $p&gt;1$&#65292;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#36825;&#24847;&#21619;&#30528; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning functions in the $\mathcal{F}_{p,\pi}$ and Barron spaces, which are natural function spaces that arise in the high-dimensional analysis of random feature models (RFMs) and two-layer neural networks. Through a duality analysis, we reveal that the approximation and estimation of these spaces can be considered equivalent in a certain sense. This enables us to focus on the easier problem of approximation and estimation when studying the generalization of both models. The dual equivalence is established by defining an information-based complexity that can effectively control estimation errors. Additionally, we demonstrate the flexibility of our duality framework through comprehensive analyses of two concrete applications.  The first application is to study learning functions in $\mathcal{F}_{p,\pi}$ with RFMs. We prove that the learning does not suffer from the curse of dimensionality as long as $p&gt;1$, implying RFMs can work beyond the kernel regime. Our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#30340;&#20445;&#24207;&#26426;&#21046;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#25351;&#25968;&#26063;&#20998;&#24067;&#20197;&#25552;&#39640;&#21516;&#34892;&#35780;&#23457;&#30340;&#36136;&#37327;&#65292;&#24182;&#21457;&#29616;&#20316;&#32773;&#30340;&#21516;&#34892;&#35780;&#20998;&#21487;&#20197;&#36739;&#20934;&#30830;&#22320;&#22312;&#19981;&#38656;&#35201;&#30693;&#36947;&#20855;&#20307;&#20998;&#24067;&#24773;&#20917;&#19979;&#36827;&#34892;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2304.11160</link><description>&lt;p&gt;
&#21033;&#29992;&#20445;&#24207;&#26426;&#21046;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20250;&#35758;&#30340;&#21516;&#34892;&#35780;&#23457;
&lt;/p&gt;
&lt;p&gt;
The Isotonic Mechanism for Exponential Family Estimation. (arXiv:2304.11160v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11160
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#30340;&#20445;&#24207;&#26426;&#21046;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#25351;&#25968;&#26063;&#20998;&#24067;&#20197;&#25552;&#39640;&#21516;&#34892;&#35780;&#23457;&#30340;&#36136;&#37327;&#65292;&#24182;&#21457;&#29616;&#20316;&#32773;&#30340;&#21516;&#34892;&#35780;&#20998;&#21487;&#20197;&#36739;&#20934;&#30830;&#22320;&#22312;&#19981;&#38656;&#35201;&#30693;&#36947;&#20855;&#20307;&#20998;&#24067;&#24773;&#20917;&#19979;&#36827;&#34892;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#25193;&#23637;&#20445;&#24207;&#26426;&#21046;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#25351;&#25968;&#26063;&#20998;&#24067;&#20197;&#25552;&#39640;&#21516;&#34892;&#35780;&#23457;&#30340;&#36136;&#37327;&#12290;&#35813;&#26426;&#21046;&#21487;&#29983;&#25104;&#19982;&#21407;&#22987;&#35780;&#20998;&#25509;&#36817;&#30340;&#35843;&#25972;&#20998;&#25968;&#65292;&#24182;&#31526;&#21512;&#20316;&#32773;&#25351;&#23450;&#30340;&#25490;&#21517;&#35201;&#27714;&#65292;&#24471;&#21040;&#24191;&#27867;&#30340;&#25351;&#25968;&#26063;&#20998;&#24067;&#24212;&#29992;&#65292;&#32780;&#19988;&#19981;&#38656;&#35201;&#30693;&#36947;&#20855;&#20307;&#30340;&#20998;&#24067;&#24418;&#24335;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#19968;&#23450;&#30340;&#25351;&#25968;&#26063;&#20998;&#24067;&#19979;&#65292;&#22914;&#26524;&#20316;&#32773;&#30340;&#25928;&#29992;&#20989;&#25968;&#37319;&#29992;&#31616;&#21333;&#30340;&#20984;&#21487;&#21152;&#20989;&#25968;&#65292;&#21017;&#28608;&#21169;&#20316;&#32773;&#25552;&#20379;&#20934;&#30830;&#30340;&#25490;&#21517;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 2023, the International Conference on Machine Learning (ICML) required authors with multiple submissions to rank their submissions based on perceived quality. In this paper, we aim to employ these author-specified rankings to enhance peer review in machine learning and artificial intelligence conferences by extending the Isotonic Mechanism (Su, 2021, 2022) to exponential family distributions. This mechanism generates adjusted scores closely align with the original scores while adhering to author-specified rankings. Despite its applicability to a broad spectrum of exponential family distributions, this mechanism's implementation does not necessitate knowledge of the specific distribution form. We demonstrate that an author is incentivized to provide accurate rankings when her utility takes the form of a convex additive function of the adjusted review scores. For a certain subclass of exponential family distributions, we prove that the author reports truthfully only if the question in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#19988;&#26080;&#38656;&#38543;&#26426;&#21270;&#12290;</title><link>http://arxiv.org/abs/2209.02525</link><description>&lt;p&gt;
&#22522;&#20110;&#30830;&#23450;&#24615;PAC-Bayes&#30340;&#26799;&#24230;&#19979;&#38477;&#19979;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalisation under gradient descent via deterministic PAC-Bayes. (arXiv:2209.02525v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02525
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#19988;&#26080;&#38656;&#38543;&#26426;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#24314;&#31435;&#20102;&#32454;&#20998;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#12290;&#19982;PAC-Bayes&#35774;&#23450;&#20013;&#30340;&#26631;&#20934;&#20570;&#27861;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#30830;&#23450;&#24615;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#21435;&#38543;&#26426;&#21270;&#30340;&#27493;&#39588;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#23436;&#20840;&#21487;&#35745;&#31639;&#30340;&#65292;&#21462;&#20915;&#20110;&#21021;&#22987;&#20998;&#24067;&#30340;&#23494;&#24230;&#21644;&#36712;&#36857;&#19978;&#35757;&#32451;&#30446;&#26631;&#30340;&#28023;&#26862;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#12289;&#21160;&#37327;&#31639;&#27861;&#21644;&#38459;&#23612;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish disintegrated PAC-Bayesian generalisation bounds for models trained with gradient descent methods or continuous gradient flows. Contrary to standard practice in the PAC-Bayesian setting, our result applies to optimisation algorithms that are deterministic, without requiring any de-randomisation step. Our bounds are fully computable, depending on the density of the initial distribution and the Hessian of the training objective over the trajectory. We show that our framework can be applied to a variety of iterative optimisation algorithms, including stochastic gradient descent (SGD), momentum-based schemes, and damped Hamiltonian dynamics.
&lt;/p&gt;</description></item></channel></rss>