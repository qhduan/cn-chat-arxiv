<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>StreamingT2V&#26159;&#19968;&#31181;&#33258;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#38271;&#35270;&#39057;&#65292;&#21487;&#20197;&#20135;&#29983;80&#12289;240&#12289;600&#12289;1200&#24103;&#29978;&#33267;&#26356;&#22810;&#24103;&#30340;&#35270;&#39057;&#65292;&#24182;&#20855;&#26377;&#24179;&#28369;&#30340;&#36807;&#28193;&#12290;</title><link>https://arxiv.org/abs/2403.14773</link><description>&lt;p&gt;
StreamingT2V: &#19968;&#31181;&#19968;&#33268;&#12289;&#21160;&#24577;&#21644;&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#25991;&#26412;&#30340;&#38271;&#35270;&#39057;&#29983;&#25104;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14773
&lt;/p&gt;
&lt;p&gt;
StreamingT2V&#26159;&#19968;&#31181;&#33258;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#38271;&#35270;&#39057;&#65292;&#21487;&#20197;&#20135;&#29983;80&#12289;240&#12289;600&#12289;1200&#24103;&#29978;&#33267;&#26356;&#22810;&#24103;&#30340;&#35270;&#39057;&#65292;&#24182;&#20855;&#26377;&#24179;&#28369;&#30340;&#36807;&#28193;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14773v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449; &#25688;&#35201;: &#25991;&#26412;&#21040;&#35270;&#39057;&#30340;&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#36981;&#24490;&#25991;&#26412;&#25351;&#20196;&#30340;&#39640;&#36136;&#37327;&#35270;&#39057;&#65292;&#20351;&#24471;&#21019;&#24314;&#22810;&#26679;&#21270;&#21644;&#20010;&#24615;&#21270;&#20869;&#23481;&#21464;&#24471;&#26356;&#21152;&#23481;&#26131;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22823;&#22810;&#38598;&#20013;&#22312;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#30701;&#35270;&#39057;&#65288;&#36890;&#24120;&#20026;16&#25110;24&#24103;&#65289;&#65292;&#24403;&#22825;&#30495;&#22320;&#25193;&#23637;&#21040;&#38271;&#35270;&#39057;&#21512;&#25104;&#30340;&#24773;&#20917;&#26102;&#65292;&#36890;&#24120;&#20250;&#20986;&#29616;&#30828;&#35009;&#21098;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;StreamingT2V&#65292;&#36825;&#26159;&#19968;&#31181;&#33258;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;80&#12289;240&#12289;600&#12289;1200&#25110;&#26356;&#22810;&#24103;&#30340;&#38271;&#35270;&#39057;&#65292;&#20855;&#26377;&#24179;&#28369;&#30340;&#36807;&#28193;&#12290;&#20027;&#35201;&#32452;&#20214;&#21253;&#25324;&#65306;&#65288;i&#65289;&#19968;&#31181;&#21517;&#20026;&#26465;&#20214;&#27880;&#24847;&#21147;&#27169;&#22359;&#65288;CAM&#65289;&#30340;&#30701;&#26399;&#35760;&#24518;&#22359;&#65292;&#36890;&#36807;&#27880;&#24847;&#26426;&#21046;&#23558;&#24403;&#21069;&#29983;&#25104;&#26465;&#20214;&#35774;&#32622;&#20026;&#20808;&#21069;&#22359;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#23454;&#29616;&#19968;&#33268;&#30340;&#22359;&#36807;&#28193;&#65292;&#65288;ii&#65289;&#19968;&#31181;&#21517;&#20026;&#22806;&#35266;&#20445;&#23384;&#27169;&#22359;&#30340;&#38271;&#26399;&#35760;&#24518;&#22359;&#65292;&#20174;&#31532;&#19968;&#20010;&#35270;&#39057;&#22359;&#20013;&#25552;&#21462;&#39640;&#32423;&#22330;&#26223;&#21644;&#23545;&#35937;&#29305;&#24449;&#65292;&#20197;&#38450;&#27490;th
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14773v1 Announce Type: cross  Abstract: Text-to-video diffusion models enable the generation of high-quality videos that follow text instructions, making it easy to create diverse and individual content. However, existing approaches mostly focus on high-quality short video generation (typically 16 or 24 frames), ending up with hard-cuts when naively extended to the case of long video synthesis. To overcome these limitations, we introduce StreamingT2V, an autoregressive approach for long video generation of 80, 240, 600, 1200 or more frames with smooth transitions. The key components are:(i) a short-term memory block called conditional attention module (CAM), which conditions the current generation on the features extracted from the previous chunk via an attentional mechanism, leading to consistent chunk transitions, (ii) a long-term memory block called appearance preservation module, which extracts high-level scene and object features from the first video chunk to prevent th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#21644;&#24211;&#26222;&#26364;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#35782;&#21035;&#8220;&#20004;&#20307;&#38382;&#39064;&#8221;&#21644;&#8220;&#22278;&#38480;&#21046;&#19977;&#20307;&#38382;&#39064;&#8221;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#23558;&#20854;&#20840;&#23616;&#32447;&#24615;&#21270;&#25104;&#32447;&#24615;&#26102;&#19981;&#21464;&#31995;&#32479;&#12290;</title><link>https://arxiv.org/abs/2403.08965</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#24211;&#26222;&#26364;&#29702;&#35770;&#30340;&#36712;&#36947;&#38382;&#39064;&#21160;&#21147;&#23398;&#35782;&#21035;&#19982;&#32447;&#24615;&#21270;
&lt;/p&gt;
&lt;p&gt;
Deep Learning Based Dynamics Identification and Linearization of Orbital Problems using Koopman Theory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08965
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#21644;&#24211;&#26222;&#26364;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#35782;&#21035;&#8220;&#20004;&#20307;&#38382;&#39064;&#8221;&#21644;&#8220;&#22278;&#38480;&#21046;&#19977;&#20307;&#38382;&#39064;&#8221;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#23558;&#20854;&#20840;&#23616;&#32447;&#24615;&#21270;&#25104;&#32447;&#24615;&#26102;&#19981;&#21464;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33322;&#31354;&#33322;&#22825;&#24037;&#31243;&#21644;&#31185;&#23398;&#39046;&#22495;&#20013;&#23545;&#8220;&#20004;&#20307;&#38382;&#39064;&#8221;&#21644;&#8220;&#22278;&#38480;&#21046;&#19977;&#20307;&#38382;&#39064;&#8221;&#30340;&#30740;&#31350;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#20204;&#26377;&#21161;&#20110;&#25551;&#36848;&#22825;&#20307;&#21644;&#20154;&#36896;&#21355;&#26143;&#30340;&#36816;&#21160;&#12290;&#38543;&#30528;&#23545;&#21355;&#26143;&#21644;&#21355;&#26143;&#32534;&#38431;&#39134;&#34892;&#30340;&#38656;&#27714;&#26085;&#30410;&#22686;&#38271;&#65292;&#23545;&#36825;&#20123;&#31995;&#32479;&#36827;&#34892;&#24555;&#36895;&#26377;&#25928;&#30340;&#25511;&#21046;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#26694;&#26550;&#65292;&#36890;&#36807;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#24211;&#26222;&#26364;&#29702;&#35770;&#23454;&#29616;&#8220;&#20004;&#20307;&#38382;&#39064;&#8221;&#21644;&#8220;&#22278;&#38480;&#21046;&#19977;&#20307;&#38382;&#39064;&#8221;&#30340;&#21516;&#26102;&#31995;&#32479;&#35782;&#21035;&#21644;&#20840;&#23616;&#32447;&#24615;&#21270;&#65292;&#21363;&#36890;&#36807;&#32431;&#25968;&#25454;&#39537;&#21160;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#21457;&#29616;&#32447;&#24615;&#24211;&#26222;&#26364;&#31639;&#23376;&#65292;&#24182;&#23558;&#20854;&#20840;&#23616;&#32447;&#24615;&#21270;&#20026;&#32447;&#24615;&#26102;&#19981;&#21464;&#31995;&#32479;&#65288;LTI&#65289;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08965v1 Announce Type: cross  Abstract: The study of the Two-Body and Circular Restricted Three-Body Problems in the field of aerospace engineering and sciences is deeply important because they help describe the motion of both celestial and artificial satellites. With the growing demand for satellites and satellite formation flying, fast and efficient control of these systems is becoming ever more important. Global linearization of these systems allows engineers to employ methods of control in order to achieve these desired results. We propose a data-driven framework for simultaneous system identification and global linearization of both the Two-Body Problem and Circular Restricted Three-Body Problem via deep learning-based Koopman Theory, i.e., a framework that can identify the underlying dynamics and globally linearize it into a linear time-invariant (LTI) system. The linear Koopman operator is discovered through purely data-driven training of a Deep Neural Network with a 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26550;&#26500;&#26080;&#20851;&#30340;&#26816;&#27979;&#25104;&#26412;&#20989;&#25968;&#65288;a-DCF&#65289;&#65292;&#36866;&#29992;&#20110;&#35780;&#20272;&#25269;&#24481;&#27450;&#39575;&#25915;&#20987;&#30340;&#33258;&#21160;&#35828;&#35805;&#20154;&#39564;&#35777;&#65288;ASV&#65289;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2403.01355</link><description>&lt;p&gt;
a-DCF&#65306;&#19968;&#31181;&#19982;&#26550;&#26500;&#26080;&#20851;&#30340;&#24230;&#37327;&#65292;&#36866;&#29992;&#20110;&#25269;&#24481;&#27450;&#39575;&#25915;&#20987;&#30340;&#35828;&#35805;&#20154;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
a-DCF: an architecture agnostic metric with application to spoofing-robust speaker verification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01355
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26550;&#26500;&#26080;&#20851;&#30340;&#26816;&#27979;&#25104;&#26412;&#20989;&#25968;&#65288;a-DCF&#65289;&#65292;&#36866;&#29992;&#20110;&#35780;&#20272;&#25269;&#24481;&#27450;&#39575;&#25915;&#20987;&#30340;&#33258;&#21160;&#35828;&#35805;&#20154;&#39564;&#35777;&#65288;ASV&#65289;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27450;&#39575;&#26816;&#27979;&#30446;&#21069;&#26159;&#19968;&#20010;&#20027;&#27969;&#30740;&#31350;&#35838;&#39064;&#12290;&#26631;&#20934;&#24230;&#37327;&#21487;&#20197;&#29992;&#26469;&#35780;&#20272;&#23396;&#31435;&#27450;&#39575;&#26816;&#27979;&#35299;&#20915;&#26041;&#26696;&#30340;&#24615;&#33021;&#65292;&#20063;&#26377;&#19968;&#20123;&#25552;&#20986;&#26469;&#25903;&#25345;&#23427;&#20204;&#22312;&#19982;&#35828;&#35805;&#20154;&#26816;&#27979;&#32467;&#21512;&#26102;&#30340;&#35780;&#20272;&#65292;&#20294;&#23384;&#22312;&#24050;&#30693;&#30340;&#32570;&#38519;&#25110;&#32773;&#38480;&#21046;&#20102;&#32467;&#21512;&#35828;&#35805;&#20154;&#21644;&#27450;&#39575;&#26816;&#27979;&#22120;&#30340;&#26550;&#26500;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26550;&#26500;&#26080;&#20851;&#30340;&#26816;&#27979;&#25104;&#26412;&#20989;&#25968;&#65288;a-DCF&#65289;&#12290;&#20316;&#20026;&#24191;&#27867;&#29992;&#20110;&#35780;&#20272;&#33258;&#21160;&#35828;&#35805;&#20154;&#39564;&#35777;&#65288;ASV&#65289;&#24615;&#33021;&#30340;&#21407;&#22987;DCF&#30340;&#25512;&#24191;&#65292;a-DCF&#26088;&#22312;&#29992;&#20110;&#35780;&#20272;&#25269;&#24481;&#27450;&#39575;&#25915;&#20987;&#30340;ASV&#12290;&#19982;DCF&#31867;&#20284;&#65292;a-DCF&#20174;Bayes&#39118;&#38505;&#30340;&#35282;&#24230;&#21453;&#26144;&#20102;&#20915;&#31574;&#30340;&#20195;&#20215;&#65292;&#20854;&#20013;&#26126;&#30830;&#23450;&#20041;&#20102;&#31867;&#20808;&#39564;&#21644;&#26816;&#27979;&#25104;&#26412;&#27169;&#22411;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#26550;&#26500;&#24322;&#26500;&#30340;&#25269;&#24481;&#27450;&#39575;&#25915;&#20987;&#30340;ASV&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#22522;&#20934;&#35780;&#20272;&#65292;&#23637;&#31034;&#20102;a-DCF&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01355v1 Announce Type: cross  Abstract: Spoofing detection is today a mainstream research topic. Standard metrics can be applied to evaluate the performance of isolated spoofing detection solutions and others have been proposed to support their evaluation when they are combined with speaker detection. These either have well-known deficiencies or restrict the architectural approach to combine speaker and spoof detectors. In this paper, we propose an architecture-agnostic detection cost function (a-DCF). A generalisation of the original DCF used widely for the assessment of automatic speaker verification (ASV), the a-DCF is designed for the evaluation of spoofing-robust ASV. Like the DCF, the a-DCF reflects the cost of decisions in a Bayes risk sense, with explicitly defined class priors and detection cost model. We demonstrate the merit of the a-DCF through the benchmarking evaluation of architecturally-heterogeneous spoofing-robust ASV solutions.
&lt;/p&gt;</description></item><item><title>&#38543;&#26426;&#26862;&#26519;&#30456;&#23545;&#20110;&#35013;&#34955;&#27861;&#20855;&#26377;&#20943;&#23569;&#20559;&#24046;&#30340;&#33021;&#21147;&#65292;&#22312;&#25581;&#31034;&#25968;&#25454;&#27169;&#24335;&#21644;&#39640;&#20449;&#22122;&#27604;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#30340;&#29305;&#28857;&#65292;&#20026;&#38543;&#26426;&#26862;&#26519;&#22312;&#19981;&#21516;&#20449;&#22122;&#27604;&#29615;&#22659;&#19979;&#30340;&#25104;&#21151;&#25552;&#20379;&#20102;&#35299;&#37322;&#21644;&#23454;&#29992;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.12668</link><description>&lt;p&gt;
&#38543;&#26426;&#21270;&#26082;&#21487;&#20197;&#20943;&#23569;&#20559;&#24046;&#21448;&#21487;&#20197;&#20943;&#23569;&#26041;&#24046;&#65306;&#38543;&#26426;&#26862;&#26519;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12668
&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#30456;&#23545;&#20110;&#35013;&#34955;&#27861;&#20855;&#26377;&#20943;&#23569;&#20559;&#24046;&#30340;&#33021;&#21147;&#65292;&#22312;&#25581;&#31034;&#25968;&#25454;&#27169;&#24335;&#21644;&#39640;&#20449;&#22122;&#27604;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#30340;&#29305;&#28857;&#65292;&#20026;&#38543;&#26426;&#26862;&#26519;&#22312;&#19981;&#21516;&#20449;&#22122;&#27604;&#29615;&#22659;&#19979;&#30340;&#25104;&#21151;&#25552;&#20379;&#20102;&#35299;&#37322;&#21644;&#23454;&#29992;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24448;&#24448;&#34987;&#24573;&#35270;&#30340;&#29616;&#35937;&#65292;&#39318;&#27425;&#22312;\cite{breiman2001random}&#20013;&#25351;&#20986;&#65292;&#21363;&#38543;&#26426;&#26862;&#26519;&#20284;&#20046;&#27604;&#35013;&#34955;&#27861;&#20943;&#23569;&#20102;&#20559;&#24046;&#12290;&#21463;\cite{mentch2020randomization}&#19968;&#31687;&#26377;&#36259;&#30340;&#35770;&#25991;&#30340;&#21551;&#21457;&#65292;&#20854;&#20013;&#20316;&#32773;&#35748;&#20026;&#38543;&#26426;&#26862;&#26519;&#20943;&#23569;&#20102;&#26377;&#25928;&#33258;&#30001;&#24230;&#65292;&#24182;&#19988;&#21482;&#26377;&#22312;&#20302;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#29615;&#22659;&#19979;&#25165;&#33021;&#32988;&#36807;&#35013;&#34955;&#38598;&#25104;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#38543;&#26426;&#26862;&#26519;&#22914;&#20309;&#33021;&#22815;&#25581;&#31034;&#34987;&#35013;&#34955;&#27861;&#24573;&#35270;&#30340;&#25968;&#25454;&#27169;&#24335;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#20013;&#35777;&#26126;&#65292;&#22312;&#23384;&#22312;&#36825;&#31181;&#27169;&#24335;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#26862;&#26519;&#19981;&#20165;&#21487;&#20197;&#20943;&#23567;&#20559;&#24046;&#36824;&#33021;&#20943;&#23567;&#26041;&#24046;&#65292;&#24182;&#19988;&#24403;&#20449;&#22122;&#27604;&#39640;&#26102;&#38543;&#26426;&#26862;&#26519;&#30340;&#34920;&#29616;&#24840;&#21457;&#22909;&#20110;&#35013;&#34955;&#38598;&#25104;&#12290;&#25105;&#20204;&#30340;&#35266;&#23519;&#20026;&#35299;&#37322;&#38543;&#26426;&#26862;&#26519;&#22312;&#21508;&#31181;&#20449;&#22122;&#27604;&#24773;&#20917;&#19979;&#30340;&#30495;&#23454;&#19990;&#30028;&#25104;&#21151;&#25552;&#20379;&#20102;&#35265;&#35299;&#65292;&#24182;&#22686;&#36827;&#20102;&#25105;&#20204;&#23545;&#38543;&#26426;&#26862;&#26519;&#19982;&#35013;&#34955;&#38598;&#25104;&#22312;&#27599;&#27425;&#20998;&#21106;&#27880;&#20837;&#30340;&#38543;&#26426;&#21270;&#26041;&#38754;&#30340;&#24046;&#24322;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#32467;&#26524;&#36824;&#25552;&#20379;&#20102;&#23454;&#29992;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12668v1 Announce Type: cross  Abstract: We study the often overlooked phenomenon, first noted in \cite{breiman2001random}, that random forests appear to reduce bias compared to bagging. Motivated by an interesting paper by \cite{mentch2020randomization}, where the authors argue that random forests reduce effective degrees of freedom and only outperform bagging ensembles in low signal-to-noise ratio (SNR) settings, we explore how random forests can uncover patterns in the data missed by bagging. We empirically demonstrate that in the presence of such patterns, random forests reduce bias along with variance and increasingly outperform bagging ensembles when SNR is high. Our observations offer insights into the real-world success of random forests across a range of SNRs and enhance our understanding of the difference between random forests and bagging ensembles with respect to the randomization injected into each split. Our investigations also yield practical insights into the 
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#65292;&#20272;&#35745;&#20102;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#30340;&#19979;&#38480;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.10504</link><description>&lt;p&gt;
&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#24377;&#24615;
&lt;/p&gt;
&lt;p&gt;
Resilience of the quadratic Littlewood-Offord problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10504
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#65292;&#20272;&#35745;&#20102;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#30340;&#19979;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#25968;&#25454;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;$\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi}$&#21453;&#38598;&#20013;&#29305;&#24615;&#30340;&#24433;&#21709;&#30340;&#20272;&#35745;&#65292;&#20854;&#20013;$M$&#26159;&#19968;&#20010;&#22266;&#23450;&#30340;&#65288;&#39640;&#32500;&#65289;&#30697;&#38453;&#65292;$\boldsymbol{\xi}$&#26159;&#19968;&#20010;&#20849;&#24418;Rademacher&#21521;&#37327;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;$\boldsymbol{\xi}$&#33021;&#22815;&#25215;&#21463;&#22810;&#23569;&#23545;&#25239;&#24615;&#31526;&#21495;&#32763;&#36716;&#32780;&#19981;&#8220;&#33192;&#32960;&#8221;$\sup_{x\in \mathbb{R}} \mathbb{P} \left\{\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi} = x\right\}$&#65292;&#20174;&#32780;&#8220;&#21435;&#38500;&#8221;&#21407;&#22987;&#20998;&#24067;&#23548;&#33268;&#26356;&#8220;&#26377;&#31890;&#24230;&#8221;&#21644;&#23545;&#25239;&#24615;&#20559;&#20506;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#19979;&#38480;&#20272;&#35745;&#65307;&#36825;&#20123;&#32467;&#26524;&#22312;&#20851;&#38190;&#21306;&#22495;&#34987;&#35777;&#26126;&#26159;&#28176;&#36817;&#32039;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10504v1 Announce Type: cross  Abstract: We study the statistical resilience of high-dimensional data. Our results provide estimates as to the effects of adversarial noise over the anti-concentration properties of the quadratic Radamecher chaos $\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi}$, where $M$ is a fixed (high-dimensional) matrix and $\boldsymbol{\xi}$ is a conformal Rademacher vector. Specifically, we pursue the question of how many adversarial sign-flips can $\boldsymbol{\xi}$ sustain without "inflating" $\sup_{x\in \mathbb{R}} \mathbb{P} \left\{\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi} = x\right\}$ and thus "de-smooth" the original distribution resulting in a more "grainy" and adversarially biased distribution. Our results provide lower bound estimations for the statistical resilience of the quadratic and bilinear Rademacher chaos; these are shown to be asymptotically tight across key regimes.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23884;&#20837;&#31354;&#38388;&#25915;&#20987;&#26041;&#27861;&#65292;&#38024;&#23545;&#24320;&#28304;LLMs&#36827;&#34892;&#25915;&#20987;&#65292;&#32469;&#36807;&#27169;&#22411;&#23545;&#40784;&#24182;&#22312;&#36951;&#24536;&#30340;&#24773;&#20917;&#19979;&#25552;&#21462;&#20449;&#24687;&#65292;&#27604;&#20256;&#32479;&#30340;&#31163;&#25955;&#25915;&#20987;&#26356;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.09063</link><description>&lt;p&gt;
&#36719;&#25552;&#31034;&#23041;&#32961;&#65306;&#36890;&#36807;&#23884;&#20837;&#31354;&#38388;&#23545;&#24320;&#28304;LLMs&#36827;&#34892;&#23433;&#20840;&#23545;&#40784;&#25915;&#20987;&#21644;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09063
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23884;&#20837;&#31354;&#38388;&#25915;&#20987;&#26041;&#27861;&#65292;&#38024;&#23545;&#24320;&#28304;LLMs&#36827;&#34892;&#25915;&#20987;&#65292;&#32469;&#36807;&#27169;&#22411;&#23545;&#40784;&#24182;&#22312;&#36951;&#24536;&#30340;&#24773;&#20917;&#19979;&#25552;&#21462;&#20449;&#24687;&#65292;&#27604;&#20256;&#32479;&#30340;&#31163;&#25955;&#25915;&#20987;&#26356;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#23545;LLMs&#30340;&#25932;&#23545;&#40065;&#26834;&#24615;&#30740;&#31350;&#19987;&#27880;&#20110;&#33258;&#28982;&#35821;&#35328;&#31354;&#38388;&#20013;&#30340;&#31163;&#25955;&#36755;&#20837;&#25805;&#32437;&#65292;&#36825;&#20123;&#25805;&#32437;&#21487;&#20197;&#30452;&#25509;&#36716;&#31227;&#21040;&#38381;&#28304;&#27169;&#22411;&#20013;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24573;&#35270;&#20102;&#24320;&#28304;&#27169;&#22411;&#30340;&#25345;&#32493;&#36827;&#23637;&#12290;&#38543;&#30528;&#24320;&#28304;&#27169;&#22411;&#33021;&#21147;&#30340;&#25552;&#21319;&#65292;&#30830;&#20445;&#20854;&#23433;&#20840;&#24615;&#20063;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#38024;&#23545;&#24320;&#28304;LLMs&#30340;&#25915;&#20987;&#65292;&#21033;&#29992;&#23436;&#20840;&#27169;&#22411;&#35775;&#38382;&#26435;&#38480;&#30340;&#26041;&#24335;&#20173;&#28982;&#24456;&#23569;&#34987;&#25506;&#32034;&#12290;&#25105;&#20204;&#22635;&#34917;&#20102;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#20102;&#23884;&#20837;&#31354;&#38388;&#25915;&#20987;&#65292;&#30452;&#25509;&#25915;&#20987;&#36755;&#20837;&#20196;&#29260;&#30340;&#36830;&#32493;&#23884;&#20837;&#34920;&#31034;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23884;&#20837;&#31354;&#38388;&#25915;&#20987;&#27604;&#31163;&#25955;&#25915;&#20987;&#25110;&#27169;&#22411;&#24494;&#35843;&#26356;&#26377;&#25928;&#22320;&#32469;&#36807;&#27169;&#22411;&#23545;&#40784;&#24182;&#35302;&#21457;&#26377;&#23475;&#34892;&#20026;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#36951;&#24536;&#30340;&#32972;&#26223;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23041;&#32961;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#23884;&#20837;&#31354;&#38388;&#25915;&#20987;&#22312;&#20174;&#26410;&#32463;&#23398;&#20064;&#30340;LLMs&#20013;&#25552;&#21462;&#24212;&#35813;&#21024;&#38500;&#30340;&#20449;&#24687;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09063v1 Announce Type: new Abstract: Current research in adversarial robustness of LLMs focuses on discrete input manipulations in the natural language space, which can be directly transferred to closed-source models. However, this approach neglects the steady progression of open-source models. As open-source models advance in capability, ensuring their safety also becomes increasingly imperative. Yet, attacks tailored to open-source LLMs that exploit full model access remain largely unexplored. We address this research gap and propose the embedding space attack, which directly attacks the continuous embedding representation of input tokens. We find that embedding space attacks circumvent model alignments and trigger harmful behaviors more efficiently than discrete attacks or model fine-tuning. Furthermore, we present a novel threat model in the context of unlearning and show that embedding space attacks can extract supposedly deleted information from unlearned LLMs across m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;(GFlowNets)&#30340;&#19968;&#20123;&#27867;&#21270;&#26426;&#21046;&#20551;&#35774;&#65292;&#21457;&#29616;&#23427;&#20204;&#23398;&#20064;&#36924;&#36817;&#30340;&#20989;&#25968;&#20855;&#26377;&#38544;&#21547;&#30340;&#22522;&#30784;&#32467;&#26500;&#65292;&#26377;&#21161;&#20110;&#27867;&#21270;&#12290;&#21516;&#26102;&#65292;GFlowNets&#23545;&#20110;&#31163;&#32447;&#21644;&#31163;&#31574;&#30053;&#35757;&#32451;&#25935;&#24863;&#65292;&#20294;&#38544;&#21547;&#23398;&#20064;&#30340;&#22870;&#21169;&#23545;&#35757;&#32451;&#20998;&#24067;&#30340;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05309</link><description>&lt;p&gt;
&#30740;&#31350;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#27867;&#21270;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Investigating Generalization Behaviours of Generative Flow Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;(GFlowNets)&#30340;&#19968;&#20123;&#27867;&#21270;&#26426;&#21046;&#20551;&#35774;&#65292;&#21457;&#29616;&#23427;&#20204;&#23398;&#20064;&#36924;&#36817;&#30340;&#20989;&#25968;&#20855;&#26377;&#38544;&#21547;&#30340;&#22522;&#30784;&#32467;&#26500;&#65292;&#26377;&#21161;&#20110;&#27867;&#21270;&#12290;&#21516;&#26102;&#65292;GFlowNets&#23545;&#20110;&#31163;&#32447;&#21644;&#31163;&#31574;&#30053;&#35757;&#32451;&#25935;&#24863;&#65292;&#20294;&#38544;&#21547;&#23398;&#20064;&#30340;&#22870;&#21169;&#23545;&#35757;&#32451;&#20998;&#24067;&#30340;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65292;GFNs&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#31163;&#25955;&#31354;&#38388;&#19978;&#38750;&#24402;&#19968;&#21270;&#27010;&#29575;&#36136;&#37327;&#20989;&#25968;&#30340;&#29983;&#25104;&#26694;&#26550;&#12290;&#33258;&#20174;&#23427;&#20204;&#38382;&#19990;&#20197;&#26469;&#65292;GFlowNets&#22312;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35757;&#32451;&#26399;&#38388;&#22823;&#37096;&#20998;&#31163;&#25955;&#31354;&#38388;&#26410;&#34987;&#35775;&#38382;&#30340;&#24212;&#29992;&#12290;&#36825;&#20351;&#19968;&#20123;&#20154;&#20551;&#35774;&#24403;GFlowNets&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#37197;&#23545;&#26102;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#26412;&#25991;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#20102;GFlowNets&#30340;&#19968;&#20123;&#27867;&#21270;&#26426;&#21046;&#20551;&#35774;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21457;&#29616;GFlowNets&#23398;&#20064;&#36924;&#36817;&#30340;&#20989;&#25968;&#20855;&#26377;&#38544;&#21547;&#30340;&#22522;&#30784;&#32467;&#26500;&#65292;&#26377;&#21161;&#20110;&#27867;&#21270;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;GFlowNets&#23545;&#20110;&#31163;&#32447;&#21644;&#31163;&#31574;&#30053;&#35757;&#32451;&#24456;&#25935;&#24863;&#65292;&#28982;&#32780;&#65292;GFlowNets&#38544;&#21547;&#23398;&#20064;&#30340;&#22870;&#21169;&#23545;&#35757;&#32451;&#20998;&#24067;&#30340;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets, GFNs) are a generative framework for learning unnormalized probability mass functions over discrete spaces. Since their inception, GFlowNets have proven to be useful for learning generative models in applications where the majority of the discrete space is unvisited during training. This has inspired some to hypothesize that GFlowNets, when paired with deep neural networks (DNNs), have favourable generalization properties. In this work, we empirically verify some of the hypothesized mechanisms of generalization of GFlowNets. In particular, we find that the functions that GFlowNets learn to approximate have an implicit underlying structure which facilitate generalization. We also find that GFlowNets are sensitive to being trained offline and off-policy; however, the reward implicitly learned by GFlowNets is robust to changes in the training distribution.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22806;&#25512;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#26041;&#27861;&#65288;BMMe&#65289;&#26469;&#35299;&#20915;&#22810;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;$\beta$-NMF&#12290;&#36890;&#36807;&#20351;&#29992;&#29420;&#29305;&#30340;&#33258;&#36866;&#24212;&#26356;&#26032;&#35268;&#21017;&#26469;&#26356;&#26032;&#22806;&#25512;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#23637;&#29616;&#20986;&#26174;&#33879;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.06646</link><description>&lt;p&gt;
&#20351;&#29992;&#22806;&#25512;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#26041;&#27861;&#21644;&#24212;&#29992;&#20110;$\beta$-NMF
&lt;/p&gt;
&lt;p&gt;
Block Majorization Minimization with Extrapolation and Application to $\beta$-NMF. (arXiv:2401.06646v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22806;&#25512;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#26041;&#27861;&#65288;BMMe&#65289;&#26469;&#35299;&#20915;&#22810;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;$\beta$-NMF&#12290;&#36890;&#36807;&#20351;&#29992;&#29420;&#29305;&#30340;&#33258;&#36866;&#24212;&#26356;&#26032;&#35268;&#21017;&#26469;&#26356;&#26032;&#22806;&#25512;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#23637;&#29616;&#20986;&#26174;&#33879;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22806;&#25512;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#26041;&#27861;&#65288;BMMe&#65289;&#26469;&#35299;&#20915;&#19968;&#31867;&#22810;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;BMMe&#30340;&#22806;&#25512;&#21442;&#25968;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#26356;&#26032;&#35268;&#21017;&#26469;&#26356;&#26032;&#12290;&#36890;&#36807;&#23558;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#37325;&#26032;&#34920;&#36848;&#20026;&#22359;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#65292;&#24182;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#33258;&#36866;&#24212;&#26356;&#26032;Bregman&#25955;&#24230;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;BMMe&#30340;&#23376;&#24207;&#21015;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#35774;&#35745;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#22788;&#29702;$\beta$-NMF&#20013;&#30340;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;&#65292;&#20854;&#20013;$\beta\in [1,2]$&#12290;&#36825;&#20123;&#31639;&#27861;&#26159;&#20351;&#29992;&#22806;&#25512;&#30340;&#20056;&#27861;&#26356;&#26032;&#65292;&#24182;&#20174;&#25105;&#20204;&#30340;&#26032;&#32467;&#26524;&#20013;&#33719;&#24471;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#23454;&#35777;&#20102;BMMe&#22312;$\beta$-NMF&#20013;&#30340;&#26174;&#33879;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a Block Majorization Minimization method with Extrapolation (BMMe) for solving a class of multi-convex optimization problems. The extrapolation parameters of BMMe are updated using a novel adaptive update rule. By showing that block majorization minimization can be reformulated as a block mirror descent method, with the Bregman divergence adaptively updated at each iteration, we establish subsequential convergence for BMMe. We use this method to design efficient algorithms to tackle nonnegative matrix factorization problems with the $\beta$-divergences ($\beta$-NMF) for $\beta\in [1,2]$. These algorithms, which are multiplicative updates with extrapolation, benefit from our novel results that offer convergence guarantees. We also empirically illustrate the significant acceleration of BMMe for $\beta$-NMF through extensive experiments.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#31354;&#24179;&#21488;&#31449;&#65288;HAPS&#65289;&#20351;&#33021;&#30340;&#22402;&#30452;&#24322;&#26500;&#32593;&#32476;&#20013;&#25968;&#25454;&#20998;&#24067;&#19981;&#22343;&#38382;&#39064;&#30340;&#25112;&#30053;&#23458;&#25143;&#36873;&#25321;&#31574;&#30053;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#30340;&#32593;&#32476;&#27969;&#37327;&#34892;&#20026;&#39044;&#27979;&#21644;&#20998;&#31867;&#65292;&#20248;&#20808;&#36873;&#25321;&#25968;&#25454;&#21576;&#29616;&#30456;&#20284;&#27169;&#24335;&#30340;&#23458;&#25143;&#21442;&#19982;&#65292;&#20197;&#25552;&#39640;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.05308</link><description>&lt;p&gt;
&#38754;&#23545;HAPS&#20351;&#33021;&#30340;FL&#32593;&#32476;&#20013;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#38382;&#39064;&#65292;&#25112;&#30053;&#23458;&#25143;&#36873;&#25321;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL Networks. (arXiv:2401.05308v1 [cs.NI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05308
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#31354;&#24179;&#21488;&#31449;&#65288;HAPS&#65289;&#20351;&#33021;&#30340;&#22402;&#30452;&#24322;&#26500;&#32593;&#32476;&#20013;&#25968;&#25454;&#20998;&#24067;&#19981;&#22343;&#38382;&#39064;&#30340;&#25112;&#30053;&#23458;&#25143;&#36873;&#25321;&#31574;&#30053;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#30340;&#32593;&#32476;&#27969;&#37327;&#34892;&#20026;&#39044;&#27979;&#21644;&#20998;&#31867;&#65292;&#20248;&#20808;&#36873;&#25321;&#25968;&#25454;&#21576;&#29616;&#30456;&#20284;&#27169;&#24335;&#30340;&#23458;&#25143;&#21442;&#19982;&#65292;&#20197;&#25552;&#39640;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30001;&#39640;&#31354;&#24179;&#21488;&#31449;&#65288;HAPS&#65289;&#20351;&#33021;&#30340;&#22402;&#30452;&#24322;&#26500;&#32593;&#32476;&#20013;&#37096;&#32626;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#20026;&#21508;&#31181;&#19981;&#21516;&#36890;&#20449;&#21644;&#35745;&#31639;&#33021;&#21147;&#30340;&#23458;&#25143;&#25552;&#20379;&#20102;&#21442;&#19982;&#30340;&#26426;&#20250;&#12290;&#36825;&#31181;&#22810;&#26679;&#24615;&#19981;&#20165;&#25552;&#39640;&#20102;FL&#27169;&#22411;&#30340;&#35757;&#32451;&#31934;&#24230;&#65292;&#36824;&#21152;&#24555;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20123;&#24191;&#38420;&#30340;&#32593;&#32476;&#20013;&#24212;&#29992;FL&#23384;&#22312;&#26174;&#33879;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#38382;&#39064;&#12290;&#36825;&#31181;&#25968;&#25454;&#24322;&#36136;&#24615;&#24448;&#24448;&#23548;&#33268;&#25910;&#25947;&#36895;&#24230;&#36739;&#24930;&#21644;&#27169;&#22411;&#35757;&#32451;&#24615;&#33021;&#30340;&#38477;&#20302;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#38024;&#23545;&#27492;&#38382;&#39064;&#30340;&#23458;&#25143;&#36873;&#25321;&#31574;&#30053;&#65292;&#21033;&#29992;&#29992;&#25143;&#32593;&#32476;&#27969;&#37327;&#34892;&#20026;&#36827;&#34892;&#39044;&#27979;&#21644;&#20998;&#31867;&#12290;&#35813;&#31574;&#30053;&#36890;&#36807;&#25112;&#30053;&#24615;&#36873;&#25321;&#25968;&#25454;&#21576;&#29616;&#30456;&#20284;&#27169;&#24335;&#30340;&#23458;&#25143;&#21442;&#19982;&#65292;&#21516;&#26102;&#20248;&#20808;&#32771;&#34385;&#29992;&#25143;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
The deployment of federated learning (FL) within vertical heterogeneous networks, such as those enabled by high-altitude platform station (HAPS), offers the opportunity to engage a wide array of clients, each endowed with distinct communication and computational capabilities. This diversity not only enhances the training accuracy of FL models but also hastens their convergence. Yet, applying FL in these expansive networks presents notable challenges, particularly the significant non-IIDness in client data distributions. Such data heterogeneity often results in slower convergence rates and reduced effectiveness in model training performance. Our study introduces a client selection strategy tailored to address this issue, leveraging user network traffic behaviour. This strategy involves the prediction and classification of clients based on their network usage patterns while prioritizing user privacy. By strategically selecting clients whose data exhibit similar patterns for participation
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#30340;&#32479;&#19968;&#21407;&#29702;&#65292;&#29992;&#20110;&#37325;&#26032;&#25512;&#23548;&#21644;&#25512;&#24191;&#29616;&#26377;&#30340;&#21464;&#20998;&#38477;&#32500;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#26032;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#22810;&#21464;&#37327;&#20449;&#24687;&#29942;&#39048;&#35299;&#37322;&#20026;&#20004;&#20010;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26435;&#34913;&#65292;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#21387;&#32553;&#25968;&#25454;&#21644;&#20445;&#30041;&#20449;&#24687;&#20043;&#38388;&#30340;&#26435;&#34913;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.03311</link><description>&lt;p&gt;
&#28145;&#24230;&#21464;&#20998;&#22810;&#21464;&#37327;&#20449;&#24687;&#29942;&#39048;--&#19968;&#31181;&#21464;&#20998;&#25439;&#22833;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses. (arXiv:2310.03311v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03311
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#30340;&#32479;&#19968;&#21407;&#29702;&#65292;&#29992;&#20110;&#37325;&#26032;&#25512;&#23548;&#21644;&#25512;&#24191;&#29616;&#26377;&#30340;&#21464;&#20998;&#38477;&#32500;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#26032;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#22810;&#21464;&#37327;&#20449;&#24687;&#29942;&#39048;&#35299;&#37322;&#20026;&#20004;&#20010;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26435;&#34913;&#65292;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#21387;&#32553;&#25968;&#25454;&#21644;&#20445;&#30041;&#20449;&#24687;&#20043;&#38388;&#30340;&#26435;&#34913;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#38477;&#32500;&#26041;&#27861;&#20197;&#20854;&#39640;&#31934;&#24230;&#12289;&#29983;&#25104;&#33021;&#21147;&#21644;&#40065;&#26834;&#24615;&#32780;&#38395;&#21517;&#12290;&#36825;&#20123;&#26041;&#27861;&#26377;&#24456;&#22810;&#29702;&#35770;&#19978;&#30340;&#35777;&#26126;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#30340;&#32479;&#19968;&#21407;&#29702;&#65292;&#37325;&#26032;&#25512;&#23548;&#21644;&#25512;&#24191;&#20102;&#29616;&#26377;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#22810;&#21464;&#37327;&#20449;&#24687;&#29942;&#39048;&#30340;&#35299;&#37322;&#65292;&#20854;&#20013;&#20004;&#20010;&#36125;&#21494;&#26031;&#32593;&#32476;&#30456;&#20114;&#26435;&#34913;&#12290;&#25105;&#20204;&#23558;&#31532;&#19968;&#20010;&#32593;&#32476;&#35299;&#37322;&#20026;&#32534;&#30721;&#22120;&#22270;&#65292;&#23427;&#25351;&#23450;&#20102;&#22312;&#21387;&#32553;&#25968;&#25454;&#26102;&#35201;&#20445;&#30041;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;&#31532;&#20108;&#20010;&#32593;&#32476;&#35299;&#37322;&#20026;&#35299;&#30721;&#22120;&#22270;&#65292;&#23427;&#20026;&#25968;&#25454;&#25351;&#23450;&#20102;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#12290;&#20351;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#37325;&#26032;&#25512;&#23548;&#20102;&#29616;&#26377;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#22914;&#28145;&#24230;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;(DVIB)&#12289;beta&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(beta-VAE)&#21644;&#28145;&#24230;&#21464;&#20998;&#35268;&#33539;&#30456;&#20851;&#20998;&#26512;(DVCCA)&#12290;&#35813;&#26694;&#26550;&#33258;&#28982;&#22320;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#21387;&#32553;&#25968;&#25454;&#21644;&#20445;&#30041;&#20449;&#24687;&#20043;&#38388;&#30340;&#26435;&#34913;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational dimensionality reduction methods are known for their high accuracy, generative abilities, and robustness. These methods have many theoretical justifications. Here we introduce a unifying principle rooted in information theory to rederive and generalize existing variational methods and design new ones. We base our framework on an interpretation of the multivariate information bottleneck, in which two Bayesian networks are traded off against one another. We interpret the first network as an encoder graph, which specifies what information to keep when compressing the data. We interpret the second network as a decoder graph, which specifies a generative model for the data. Using this framework, we rederive existing dimensionality reduction methods such as the deep variational information bottleneck (DVIB), beta variational auto-encoders (beta-VAE), and deep variational canonical correlation analysis (DVCCA). The framework naturally introduces a trade-off parameter between compr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2309.14073</link><description>&lt;p&gt;
&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65306;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35745;&#31639;&#36825;&#20010;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models.
&lt;/p&gt;</description></item><item><title>H2O+&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#28151;&#21512;&#31163;&#32447;&#21644;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#32771;&#34385;&#30495;&#23454;&#21644;&#27169;&#25311;&#29615;&#22659;&#30340;&#21160;&#21147;&#23398;&#24046;&#36317;&#65292;&#21516;&#26102;&#21033;&#29992;&#26377;&#38480;&#30340;&#31163;&#32447;&#25968;&#25454;&#21644;&#19981;&#23436;&#32654;&#30340;&#27169;&#25311;&#22120;&#36827;&#34892;&#31574;&#30053;&#23398;&#20064;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#20223;&#30495;&#21644;&#23454;&#38469;&#26426;&#22120;&#20154;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.12716</link><description>&lt;p&gt;
H2O+: &#19968;&#31181;&#25913;&#36827;&#30340;&#28151;&#21512;&#31163;&#32447;&#21644;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#21160;&#21147;&#23398;&#24046;&#36317;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
H2O+: An Improved Framework for Hybrid Offline-and-Online RL with Dynamics Gaps. (arXiv:2309.12716v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12716
&lt;/p&gt;
&lt;p&gt;
H2O+&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#28151;&#21512;&#31163;&#32447;&#21644;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#32771;&#34385;&#30495;&#23454;&#21644;&#27169;&#25311;&#29615;&#22659;&#30340;&#21160;&#21147;&#23398;&#24046;&#36317;&#65292;&#21516;&#26102;&#21033;&#29992;&#26377;&#38480;&#30340;&#31163;&#32447;&#25968;&#25454;&#21644;&#19981;&#23436;&#32654;&#30340;&#27169;&#25311;&#22120;&#36827;&#34892;&#31574;&#30053;&#23398;&#20064;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#20223;&#30495;&#21644;&#23454;&#38469;&#26426;&#22120;&#20154;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27809;&#26377;&#39640;&#31934;&#24230;&#27169;&#25311;&#29615;&#22659;&#25110;&#22823;&#37327;&#31163;&#32447;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#35299;&#20915;&#23454;&#38469;&#22797;&#26434;&#20219;&#21153;&#21487;&#33021;&#30456;&#24403;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#38750;&#23436;&#32654;&#27169;&#25311;&#29615;&#22659;&#20013;&#35757;&#32451;&#30340;&#22312;&#32447;RL&#20195;&#29702;&#21487;&#33021;&#20250;&#21463;&#21040;&#20005;&#37325;&#30340;&#27169;&#25311;&#19982;&#29616;&#23454;&#38382;&#39064;&#12290;&#34429;&#28982;&#31163;&#32447;RL&#26041;&#27861;&#21487;&#20197;&#32469;&#36807;&#23545;&#27169;&#25311;&#22120;&#30340;&#38656;&#27714;&#65292;&#20294;&#24448;&#24448;&#23545;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#21644;&#36136;&#37327;&#25552;&#20986;&#20102;&#33499;&#21051;&#30340;&#35201;&#27714;&#12290;&#26368;&#36817;&#20986;&#29616;&#30340;&#28151;&#21512;&#31163;&#32447;&#21644;&#22312;&#32447;RL&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21560;&#24341;&#21147;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#20351;&#29992;&#26377;&#38480;&#30340;&#31163;&#32447;&#25968;&#25454;&#21644;&#19981;&#23436;&#32654;&#30340;&#27169;&#25311;&#22120;&#36827;&#34892;&#21487;&#36716;&#31227;&#31574;&#30053;&#23398;&#20064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;H2O+&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#26725;&#25509;&#19981;&#21516;&#30340;&#31163;&#32447;&#21644;&#22312;&#32447;&#23398;&#20064;&#26041;&#27861;&#30340;&#21516;&#26102;&#65292;&#20063;&#32771;&#34385;&#20102;&#30495;&#23454;&#21644;&#27169;&#25311;&#29615;&#22659;&#20043;&#38388;&#30340;&#21160;&#21147;&#23398;&#24046;&#36317;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#20223;&#30495;&#21644;&#23454;&#38469;&#26426;&#22120;&#20154;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;H2O+&#22312;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#19978;&#20248;&#20110;&#20808;&#36827;&#30340;&#36328;&#22495;&#22312;&#32447;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Solving real-world complex tasks using reinforcement learning (RL) without high-fidelity simulation environments or large amounts of offline data can be quite challenging. Online RL agents trained in imperfect simulation environments can suffer from severe sim-to-real issues. Offline RL approaches although bypass the need for simulators, often pose demanding requirements on the size and quality of the offline datasets. The recently emerged hybrid offline-and-online RL provides an attractive framework that enables joint use of limited offline data and imperfect simulator for transferable policy learning. In this paper, we develop a new algorithm, called H2O+, which offers great flexibility to bridge various choices of offline and online learning methods, while also accounting for dynamics gaps between the real and simulation environment. Through extensive simulation and real-world robotics experiments, we demonstrate superior performance and flexibility over advanced cross-domain online
&lt;/p&gt;</description></item></channel></rss>