<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#35745;&#31639;&#39640;&#38454;&#23548;&#25968;&#65292;&#23558;&#29275;&#39039;&#27861;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#21508;&#31181;&#26550;&#26500;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2312.03885</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#38454;&#23548;&#25968;&#24635;&#32467;&#65292;&#23558;&#29275;&#39039;&#27861;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Adapting Newton's Method to Neural Networks through a Summary of Higher-Order Derivatives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03885
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#35745;&#31639;&#39640;&#38454;&#23548;&#25968;&#65292;&#23558;&#29275;&#39039;&#27861;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#21508;&#31181;&#26550;&#26500;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#21521;&#37327;&#21464;&#37327;$\boldsymbol{\theta}$&#19978;&#30340;&#20989;&#25968;$\mathcal{L}$&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;$\boldsymbol{\theta}$&#34987;&#34920;&#31034;&#20026;&#20803;&#32452;$(\mathbf{T}_1, \cdots, \mathbf{T}_S)$&#30340;&#24352;&#37327;&#12290;&#35813;&#26694;&#26550;&#21253;&#25324;&#35768;&#22810;&#24120;&#35265;&#30340;&#29992;&#20363;&#65292;&#20363;&#22914;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#26469;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25104;&#26412;&#20302;&#24265;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#33258;&#21160;&#24494;&#20998;&#21644;&#35745;&#31639;&#25216;&#24039;&#65292;&#25552;&#20379;&#20851;&#20110;$\mathcal{L}$&#21450;&#20854;&#24352;&#37327;$\mathbf{T}_s$&#20043;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#39640;&#38454;&#20449;&#24687;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#25216;&#26415;&#26469;&#24314;&#31435;&#19968;&#20010;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#35757;&#32451;&#21508;&#31181;&#26550;&#26500;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20010;&#20108;&#38454;&#26041;&#27861;&#21033;&#29992;&#20102;$\boldsymbol{\theta}$&#34987;&#20998;&#21106;&#20026;&#24352;&#37327;$(\mathbf{T}_1, \cdots, \mathbf{T}_S)$&#30340;&#20998;&#21306;&#32467;&#26500;&#65292;&#22240;&#27492;&#19981;&#38656;&#35201;&#35745;&#31639;$\mathcal{L}$&#30340;Hessian&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a gradient-based optimization method applied to a function $\mathcal{L}$ of a vector of variables $\boldsymbol{\theta}$, in the case where $\boldsymbol{\theta}$ is represented as a tuple of tensors $(\mathbf{T}_1, \cdots, \mathbf{T}_S)$. This framework encompasses many common use-cases, such as training neural networks by gradient descent. First, we propose a computationally inexpensive technique providing higher-order information on $\mathcal{L}$, especially about the interactions between the tensors $\mathbf{T}_s$, based on automatic differentiation and computational tricks. Second, we use this technique at order 2 to build a second-order optimization method which is suitable, among other things, for training deep neural networks of various architectures. This second-order method leverages the partition structure of $\boldsymbol{\theta}$ into tensors $(\mathbf{T}_1, \cdots, \mathbf{T}_S)$, in such a way that it requires neither the computation of the Hessian of $\mathcal{
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22343;&#21248;&#22320;&#26631;&#25277;&#26679;&#21644;&#32422;&#26463;&#23616;&#37096;&#32447;&#24615;&#23884;&#20837;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20280;&#32553;&#30340;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#22823;&#35268;&#27169;&#21644;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#20840;&#23616;&#32467;&#26500;&#22833;&#30495;&#21644;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.01100</link><description>&lt;p&gt;
&#36890;&#36807;&#22343;&#21248;&#22320;&#26631;&#25277;&#26679;&#21644;&#32422;&#26463;&#23616;&#37096;&#32447;&#24615;&#23884;&#20837;&#23454;&#29616;&#21487;&#20280;&#32553;&#30340;&#27969;&#24418;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Scalable manifold learning by uniform landmark sampling and constrained locally linear embedding. (arXiv:2401.01100v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01100
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22343;&#21248;&#22320;&#26631;&#25277;&#26679;&#21644;&#32422;&#26463;&#23616;&#37096;&#32447;&#24615;&#23884;&#20837;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20280;&#32553;&#30340;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#22823;&#35268;&#27169;&#21644;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#20840;&#23616;&#32467;&#26500;&#22833;&#30495;&#21644;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#31185;&#23398;&#20013;&#30340;&#20851;&#38190;&#26041;&#27861;&#65292;&#26088;&#22312;&#25581;&#31034;&#39640;&#32500;&#31354;&#38388;&#20013;&#22797;&#26434;&#38750;&#32447;&#24615;&#27969;&#24418;&#20869;&#22312;&#30340;&#20302;&#32500;&#32467;&#26500;&#12290;&#36890;&#36807;&#21033;&#29992;&#27969;&#24418;&#20551;&#35774;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#21508;&#31181;&#38750;&#32447;&#24615;&#38477;&#32500;&#25216;&#26415;&#26469;&#20419;&#36827;&#21487;&#35270;&#21270;&#12289;&#20998;&#31867;&#12289;&#32858;&#31867;&#21644;&#33719;&#24471;&#20851;&#38190;&#27934;&#23519;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#20173;&#28982;&#23384;&#22312;&#20840;&#23616;&#32467;&#26500;&#20013;&#30340;&#22823;&#37327;&#22833;&#30495;&#38382;&#39064;&#65292;&#36825;&#38459;&#30861;&#20102;&#23545;&#24213;&#23618;&#27169;&#24335;&#30340;&#29702;&#35299;&#12290;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#20063;&#38480;&#21046;&#20102;&#23427;&#20204;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20280;&#32553;&#30340;&#27969;&#24418;&#23398;&#20064;(scML)&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#26377;&#25928;&#30340;&#26041;&#24335;&#22788;&#29702;&#22823;&#35268;&#27169;&#21644;&#39640;&#32500;&#25968;&#25454;&#12290;&#23427;&#36890;&#36807;&#23547;&#25214;&#19968;&#32452;&#22320;&#26631;&#26469;&#26500;&#24314;&#25972;&#20010;&#25968;&#25454;&#30340;&#20302;&#32500;&#39592;&#26550;&#65292;&#28982;&#21518;&#23558;&#38750;&#22320;&#26631;&#24341;&#20837;&#22320;&#26631;&#31354;&#38388;&#20013;
&lt;/p&gt;
&lt;p&gt;
As a pivotal approach in machine learning and data science, manifold learning aims to uncover the intrinsic low-dimensional structure within complex nonlinear manifolds in high-dimensional space. By exploiting the manifold hypothesis, various techniques for nonlinear dimension reduction have been developed to facilitate visualization, classification, clustering, and gaining key insights. Although existing manifold learning methods have achieved remarkable successes, they still suffer from extensive distortions incurred in the global structure, which hinders the understanding of underlying patterns. Scalability issues also limit their applicability for handling large-scale data. Here, we propose a scalable manifold learning (scML) method that can manipulate large-scale and high-dimensional data in an efficient manner. It starts by seeking a set of landmarks to construct the low-dimensional skeleton of the entire data and then incorporates the non-landmarks into the landmark space based 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#32534;&#30721;&#22120;&#33258;&#32534;&#30721;&#22120;&#21644;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#30450;&#28304;&#20998;&#31163;&#38382;&#39064;&#12290;&#36890;&#36807;&#35757;&#32451;&#32593;&#32476;&#36827;&#34892;&#36755;&#20837;&#35299;&#30721;&#21644;&#37325;&#26500;&#65292;&#28982;&#21518;&#21033;&#29992;&#32534;&#30721;&#25513;&#34109;&#25216;&#26415;&#36827;&#34892;&#28304;&#25512;&#26029;&#65292;&#21516;&#26102;&#24341;&#20837;&#36335;&#24452;&#20998;&#31163;&#25439;&#22833;&#20197;&#20419;&#36827;&#31232;&#30095;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.07138</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#32534;&#30721;&#22120;&#33258;&#32534;&#30721;&#22120;&#30340;&#33258;&#30417;&#30563;&#30450;&#28304;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders. (arXiv:2309.07138v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07138
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#32534;&#30721;&#22120;&#33258;&#32534;&#30721;&#22120;&#21644;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#30450;&#28304;&#20998;&#31163;&#38382;&#39064;&#12290;&#36890;&#36807;&#35757;&#32451;&#32593;&#32476;&#36827;&#34892;&#36755;&#20837;&#35299;&#30721;&#21644;&#37325;&#26500;&#65292;&#28982;&#21518;&#21033;&#29992;&#32534;&#30721;&#25513;&#34109;&#25216;&#26415;&#36827;&#34892;&#28304;&#25512;&#26029;&#65292;&#21516;&#26102;&#24341;&#20837;&#36335;&#24452;&#20998;&#31163;&#25439;&#22833;&#20197;&#20419;&#36827;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30450;&#28304;&#20998;&#31163;&#65288;BSS&#65289;&#30340;&#20219;&#21153;&#26159;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#20174;&#28151;&#21512;&#20449;&#21495;&#20013;&#20998;&#31163;&#20986;&#28304;&#20449;&#21495;&#21644;&#28151;&#21512;&#31995;&#32479;&#12290;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#36890;&#24120;&#38656;&#35201;&#23545;&#28151;&#21512;&#31995;&#32479;&#21644;&#28304;&#20449;&#21495;&#20570;&#20986;&#38480;&#21046;&#24615;&#30340;&#20551;&#35774;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38750;&#32447;&#24615;&#28151;&#21512;&#30340;BSS&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#22810;&#32534;&#30721;&#22120;&#33258;&#32534;&#30721;&#22120;&#30340;&#33258;&#28982;&#29305;&#24449;&#23376;&#31354;&#38388;&#19987;&#38376;&#21270;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#23436;&#20840;&#33258;&#30417;&#30563;&#23398;&#20064;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;&#19981;&#38656;&#35201;&#24378;&#20808;&#39564;&#30693;&#35782;&#12290;&#22312;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#36755;&#20837;&#35299;&#30721;&#25104;&#22810;&#32534;&#30721;&#22120;&#32593;&#32476;&#30340;&#21333;&#29420;&#32534;&#30721;&#31354;&#38388;&#65292;&#28982;&#21518;&#22312;&#35299;&#30721;&#22120;&#20869;&#37325;&#26032;&#28151;&#21512;&#36825;&#20123;&#34920;&#31034;&#20197;&#37325;&#26500;&#36755;&#20837;&#12290;&#28982;&#21518;&#65292;&#20026;&#20102;&#36827;&#34892;&#28304;&#25512;&#26029;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32534;&#30721;&#25513;&#34109;&#25216;&#26415;&#65292;&#21363;&#23631;&#34109;&#38500;&#19968;&#20010;&#32534;&#30721;&#22806;&#30340;&#25152;&#26377;&#32534;&#30721;&#65292;&#20351;&#24471;&#35299;&#30721;&#22120;&#33021;&#22815;&#20272;&#35745;&#28304;&#20449;&#21495;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#36335;&#24452;&#20998;&#31163;&#25439;&#22833;&#30340;&#26041;&#27861;&#65292;&#20197;&#20419;&#36827;&#32534;&#30721;&#20043;&#38388;&#30340;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of blind source separation (BSS) involves separating sources from a mixture without prior knowledge of the sources or the mixing system. This is a challenging problem that often requires making restrictive assumptions about both the mixing system and the sources. In this paper, we propose a novel method for addressing BSS of non-linear mixtures by leveraging the natural feature subspace specialization ability of multi-encoder autoencoders with fully self-supervised learning without strong priors. During the training phase, our method unmixes the input into the separate encoding spaces of the multi-encoder network and then remixes these representations within the decoder for a reconstruction of the input. Then to perform source inference, we introduce a novel encoding masking technique whereby masking out all but one of the encodings enables the decoder to estimate a source signal. To this end, we also introduce a so-called pathway separation loss that encourages sparsity betwe
&lt;/p&gt;</description></item><item><title>ResidualPlanner&#26159;&#19968;&#31181;&#29992;&#20110;&#24102;&#26377;&#39640;&#26031;&#22122;&#22768;&#30340;&#36793;&#32536;&#30340;&#30697;&#38453;&#26426;&#21046;&#65292;&#26082;&#20248;&#21270;&#21448;&#21487;&#25193;&#23637;&#65292;&#21487;&#20197;&#20248;&#21270;&#35768;&#22810;&#21487;&#20197;&#20889;&#25104;&#36793;&#38469;&#26041;&#24046;&#30340;&#20984;&#20989;&#25968;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.08175</link><description>&lt;p&gt;
&#19968;&#31181;&#20248;&#21270;&#19988;&#21487;&#25193;&#23637;&#30340;&#30697;&#38453;&#26426;&#21046;&#29992;&#20110;&#25200;&#21160;&#36793;&#32536;&#25968;&#25454;&#19979;&#20984;&#25439;&#22833;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
An Optimal and Scalable Matrix Mechanism for Noisy Marginals under Convex Loss Functions. (arXiv:2305.08175v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08175
&lt;/p&gt;
&lt;p&gt;
ResidualPlanner&#26159;&#19968;&#31181;&#29992;&#20110;&#24102;&#26377;&#39640;&#26031;&#22122;&#22768;&#30340;&#36793;&#32536;&#30340;&#30697;&#38453;&#26426;&#21046;&#65292;&#26082;&#20248;&#21270;&#21448;&#21487;&#25193;&#23637;&#65292;&#21487;&#20197;&#20248;&#21270;&#35768;&#22810;&#21487;&#20197;&#20889;&#25104;&#36793;&#38469;&#26041;&#24046;&#30340;&#20984;&#20989;&#25968;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25200;&#21160;&#30340;&#36793;&#32536;&#25968;&#25454;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#24418;&#24335;&#65292;&#21487;&#29992;&#20110;&#35832;&#22914;&#21015;&#32852;&#34920;&#20998;&#26512;&#12289;&#36125;&#21494;&#26031;&#32593;&#32476;&#26500;&#24314;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31561;&#19979;&#28216;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ResidualPlanner&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#24102;&#26377;&#39640;&#26031;&#22122;&#22768;&#30340;&#36793;&#32536;&#30340;&#30697;&#38453;&#26426;&#21046;&#65292;&#26082;&#20248;&#21270;&#21448;&#21487;&#25193;&#23637;&#12290;ResidualPlanner&#21487;&#20197;&#20248;&#21270;&#35768;&#22810;&#21487;&#20197;&#20889;&#25104;&#36793;&#38469;&#26041;&#24046;&#30340;&#20984;&#20989;&#25968;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;ResidualPlanner&#21487;&#20197;&#22312;&#20960;&#31186;&#38047;&#20869;&#20248;&#21270;&#22823;&#35268;&#27169;&#35774;&#32622;&#20013;&#30340;&#36793;&#32536;&#20934;&#30830;&#24615;&#65292;&#21363;&#20351;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#65288;HDMM&#65289;&#20063;&#20250;&#21344;&#29992;&#36807;&#22810;&#30340;&#20869;&#23384;&#12290;&#29978;&#33267;&#22312;&#20855;&#26377;100&#20010;&#23646;&#24615;&#30340;&#25968;&#25454;&#38598;&#19978;&#20063;&#21487;&#20197;&#22312;&#20960;&#20998;&#38047;&#20869;&#36816;&#34892;&#12290;&#27492;&#22806;&#65292;ResidualPlanner&#36824;&#21487;&#20197;&#26377;&#25928;&#22320;&#35745;&#31639;&#27599;&#20010;&#36793;&#32536;&#30340;&#26041;&#24046;/&#21327;&#26041;&#24046;&#20540;&#65288;&#20043;&#21069;&#30340;&#26041;&#27861;&#20250;&#24456;&#24555;&#22833;&#36133;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Noisy marginals are a common form of confidentiality-protecting data release and are useful for many downstream tasks such as contingency table analysis, construction of Bayesian networks, and even synthetic data generation. Privacy mechanisms that provide unbiased noisy answers to linear queries (such as marginals) are known as matrix mechanisms.  We propose ResidualPlanner, a matrix mechanism for marginals with Gaussian noise that is both optimal and scalable. ResidualPlanner can optimize for many loss functions that can be written as a convex function of marginal variances (prior work was restricted to just one predefined objective function). ResidualPlanner can optimize the accuracy of marginals in large scale settings in seconds, even when the previous state of the art (HDMM) runs out of memory. It even runs on datasets with 100 attributes in a couple of minutes. Furthermore ResidualPlanner can efficiently compute variance/covariance values for each marginal (prior methods quickly
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#36741;&#21161;&#26694;&#26550;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#32479;&#19968;&#30340;&#35270;&#35282;&#65292;&#25552;&#20379;&#20102;&#20855;&#26377;&#20840;&#23616;&#22797;&#26434;&#24615;&#20445;&#35777;&#30340;&#38543;&#26426;&#21644;&#26041;&#24046;&#20943;&#23569;&#30340;&#20108;&#38454;&#31639;&#27861;&#12290;&#35813;&#26694;&#26550;&#22312;&#26500;&#24314;&#21644;&#20998;&#26512;&#38543;&#26426;&#19977;&#27425;&#29275;&#39039;&#26041;&#27861;&#26102;&#20855;&#26377;&#39640;&#24230;&#28789;&#27963;&#24615;&#65292;&#20351;&#29992;&#20102;&#20219;&#24847;&#22823;&#23567;&#30340;&#25209;&#37327;&#65292;&#20197;&#21450;&#26377;&#22122;&#22768;&#21644;&#21487;&#33021;&#26377;&#20559;&#24046;&#30340;&#26799;&#24230;&#21644;Hessian&#30340;&#20272;&#35745;&#65292;&#32467;&#21512;&#20102;&#26041;&#24046;&#20943;&#23569;&#21644;&#24816;&#24615;Hessian&#26356;&#26032;&#12290;&#22312;&#22122;&#22768;&#30340;&#24369;&#20551;&#35774;&#19979;&#65292;&#24674;&#22797;&#20102;&#24050;&#30693;&#30340;&#38543;&#26426;&#21644;&#26041;&#24046;&#20943;&#23569;&#30340;&#19977;&#27425;&#29275;&#39039;&#30340;&#26368;&#20339;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.11962</link><description>&lt;p&gt;
&#38543;&#26426;&#21644;&#26041;&#24046;&#20943;&#23569;&#30340;&#19977;&#27425;&#29275;&#39039;&#26041;&#27861;&#30340;&#32479;&#19968;&#25910;&#25947;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods. (arXiv:2302.11962v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11962
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#36741;&#21161;&#26694;&#26550;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#32479;&#19968;&#30340;&#35270;&#35282;&#65292;&#25552;&#20379;&#20102;&#20855;&#26377;&#20840;&#23616;&#22797;&#26434;&#24615;&#20445;&#35777;&#30340;&#38543;&#26426;&#21644;&#26041;&#24046;&#20943;&#23569;&#30340;&#20108;&#38454;&#31639;&#27861;&#12290;&#35813;&#26694;&#26550;&#22312;&#26500;&#24314;&#21644;&#20998;&#26512;&#38543;&#26426;&#19977;&#27425;&#29275;&#39039;&#26041;&#27861;&#26102;&#20855;&#26377;&#39640;&#24230;&#28789;&#27963;&#24615;&#65292;&#20351;&#29992;&#20102;&#20219;&#24847;&#22823;&#23567;&#30340;&#25209;&#37327;&#65292;&#20197;&#21450;&#26377;&#22122;&#22768;&#21644;&#21487;&#33021;&#26377;&#20559;&#24046;&#30340;&#26799;&#24230;&#21644;Hessian&#30340;&#20272;&#35745;&#65292;&#32467;&#21512;&#20102;&#26041;&#24046;&#20943;&#23569;&#21644;&#24816;&#24615;Hessian&#26356;&#26032;&#12290;&#22312;&#22122;&#22768;&#30340;&#24369;&#20551;&#35774;&#19979;&#65292;&#24674;&#22797;&#20102;&#24050;&#30693;&#30340;&#38543;&#26426;&#21644;&#26041;&#24046;&#20943;&#23569;&#30340;&#19977;&#27425;&#29275;&#39039;&#30340;&#26368;&#20339;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#29992;&#20110;&#35299;&#20915;&#19968;&#33324;&#21487;&#33021;&#38750;&#20984;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#38543;&#26426;&#19977;&#27425;&#29275;&#39039;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20043;&#20026;&#36741;&#21161;&#26694;&#26550;&#65292;&#23427;&#25552;&#20379;&#20102;&#20855;&#26377;&#20840;&#23616;&#22797;&#26434;&#24615;&#20445;&#35777;&#30340;&#38543;&#26426;&#21644;&#26041;&#24046;&#20943;&#23569;&#30340;&#20108;&#38454;&#31639;&#27861;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;&#23427;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#24102;&#26377;&#36741;&#21161;&#20449;&#24687;&#30340;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#36741;&#21161;&#26694;&#26550;&#20026;&#31639;&#27861;&#35774;&#35745;&#32773;&#25552;&#20379;&#20102;&#26500;&#24314;&#21644;&#20998;&#26512;&#38543;&#26426;&#19977;&#27425;&#29275;&#39039;&#26041;&#27861;&#30340;&#39640;&#24230;&#28789;&#27963;&#24615;&#65292;&#20801;&#35768;&#20219;&#24847;&#22823;&#23567;&#30340;&#25209;&#37327;&#65292;&#24182;&#19988;&#20351;&#29992;&#26377;&#22122;&#22768;&#21644;&#21487;&#33021;&#26377;&#20559;&#24046;&#30340;&#26799;&#24230;&#21644;Hessian&#30340;&#20272;&#35745;&#65292;&#23558;&#26041;&#24046;&#20943;&#23569;&#21644;&#24816;&#24615;Hessian&#26356;&#26032;&#32467;&#21512;&#36215;&#26469;&#12290;&#22312;&#22122;&#22768;&#30340;&#24369;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#24050;&#30693;&#30340;&#38543;&#26426;&#21644;&#26041;&#24046;&#20943;&#23569;&#30340;&#19977;&#27425;&#29275;&#39039;&#30340;&#26368;&#20339;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#29702;&#35770;&#30340;&#19968;&#20010;&#30452;&#25509;&#32467;&#26524;&#26159;&#26032;&#30340;&#24816;&#24615;&#38543;&#26426;&#20108;&#38454;&#26041;&#27861;&#65292;&#23427;&#26174;&#33879;&#25913;&#36827;&#20102;&#22823;&#32500;&#38382;&#39064;&#30340;&#31639;&#26415;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study stochastic Cubic Newton methods for solving general possibly non-convex minimization problems. We propose a new framework, which we call the helper framework, that provides a unified view of the stochastic and variance-reduced second-order algorithms equipped with global complexity guarantees. It can also be applied to learning with auxiliary information. Our helper framework offers the algorithm designer high flexibility for constructing and analyzing the stochastic Cubic Newton methods, allowing arbitrary size batches, and the use of noisy and possibly biased estimates of the gradients and Hessians, incorporating both the variance reduction and the lazy Hessian updates. We recover the best-known complexities for the stochastic and variance-reduced Cubic Newton, under weak assumptions on the noise. A direct consequence of our theory is the new lazy stochastic second-order method, which significantly improves the arithmetic complexity for large dimension problems. We also esta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23454;&#39564;&#30740;&#31350;&#21457;&#29616;&#65292;&#28145;&#24230;&#32593;&#32476;&#30340;&#21033;&#26222;&#24076;&#33576;&#24120;&#25968;&#36235;&#21183;&#19982;&#27979;&#35797;&#35823;&#24046;&#23494;&#20999;&#30456;&#20851;&#65292;&#36890;&#36807;&#24314;&#31435;&#21442;&#25968;&#31354;&#38388;&#21644;&#36755;&#20837;&#31354;&#38388;&#26799;&#24230;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#30830;&#23450;&#20102;&#25439;&#22833;&#20989;&#25968;&#26354;&#29575;&#21644;&#36317;&#31163;&#21021;&#22987;&#21270;&#21442;&#25968;&#30340;&#36317;&#31163;&#23545;&#20110;&#28145;&#24230;&#32593;&#32476;&#30340;&#20248;&#21270;&#21644;&#27169;&#22411;&#20989;&#25968;&#22797;&#26434;&#24230;&#38480;&#21046;&#26159;&#20851;&#38190;&#22240;&#32032;&#65292;&#35813;&#30740;&#31350;&#23545;&#38544;&#24335;&#27491;&#21017;&#21270;&#21644;&#32593;&#32476;&#30340;&#26377;&#25928;&#27169;&#22411;&#22797;&#26434;&#24230;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2301.12309</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#32593;&#32476;&#21644;&#21452;&#37325;&#19979;&#38477;&#30340;&#21033;&#26222;&#24076;&#33576;&#24120;&#25968;
&lt;/p&gt;
&lt;p&gt;
On the Lipschitz Constant of Deep Networks and Double Descent. (arXiv:2301.12309v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23454;&#39564;&#30740;&#31350;&#21457;&#29616;&#65292;&#28145;&#24230;&#32593;&#32476;&#30340;&#21033;&#26222;&#24076;&#33576;&#24120;&#25968;&#36235;&#21183;&#19982;&#27979;&#35797;&#35823;&#24046;&#23494;&#20999;&#30456;&#20851;&#65292;&#36890;&#36807;&#24314;&#31435;&#21442;&#25968;&#31354;&#38388;&#21644;&#36755;&#20837;&#31354;&#38388;&#26799;&#24230;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#30830;&#23450;&#20102;&#25439;&#22833;&#20989;&#25968;&#26354;&#29575;&#21644;&#36317;&#31163;&#21021;&#22987;&#21270;&#21442;&#25968;&#30340;&#36317;&#31163;&#23545;&#20110;&#28145;&#24230;&#32593;&#32476;&#30340;&#20248;&#21270;&#21644;&#27169;&#22411;&#20989;&#25968;&#22797;&#26434;&#24230;&#38480;&#21046;&#26159;&#20851;&#38190;&#22240;&#32032;&#65292;&#35813;&#30740;&#31350;&#23545;&#38544;&#24335;&#27491;&#21017;&#21270;&#21644;&#32593;&#32476;&#30340;&#26377;&#25928;&#27169;&#22411;&#22797;&#26434;&#24230;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#20851;&#20110;&#28145;&#24230;&#32593;&#32476;&#27867;&#21270;&#35823;&#24046;&#30340;&#30028;&#38480;&#37117;&#26159;&#22522;&#20110;&#36755;&#20837;&#21464;&#37327;&#30340;&#24179;&#28369;&#25110;&#26377;&#30028;&#20381;&#36182;&#24615;&#65292;&#27809;&#26377;&#30740;&#31350;&#25506;&#31350;&#23454;&#36341;&#20013;&#25511;&#21046;&#36825;&#20123;&#22240;&#32032;&#30340;&#26426;&#21046;&#12290;&#26412;&#25991;&#23545;&#32463;&#21382;&#21452;&#37325;&#34928;&#20943;&#30340;&#28145;&#24230;&#32593;&#32476;&#30340;&#23454;&#39564;&#21033;&#26222;&#24076;&#33576;&#24120;&#25968;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#30740;&#31350;&#65292;&#24182;&#24378;&#35843;&#20102;&#38750;&#21333;&#35843;&#30340;&#36235;&#21183;&#65292;&#19982;&#27979;&#35797;&#35823;&#24046;&#23494;&#20999;&#30456;&#20851;&#12290;&#36890;&#36807;&#24314;&#31435;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21442;&#25968;&#31354;&#38388;&#21644;&#36755;&#20837;&#31354;&#38388;&#26799;&#24230;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25105;&#20204;&#20998;&#31163;&#20986;&#20004;&#20010;&#37325;&#35201;&#22240;&#32032;&#65292;&#21363;&#25439;&#22833;&#20989;&#25968;&#26354;&#29575;&#21644;&#36317;&#31163;&#21021;&#22987;&#21270;&#21442;&#25968;&#30340;&#36317;&#31163;&#65292;&#20998;&#21035;&#25511;&#21046;&#20851;&#38190;&#28857;&#21608;&#22260;&#30340;&#20248;&#21270;&#21160;&#24577;&#65292;&#24182;&#38480;&#21046;&#27169;&#22411;&#20989;&#25968;&#30340;&#22797;&#26434;&#24230;&#65292;&#21363;&#20351;&#22312;&#35757;&#32451;&#25968;&#25454;&#20043;&#22806;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#36229;&#21442;&#25968;&#21270;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#21644;&#23454;&#36341;&#20013;&#32593;&#32476;&#30340;&#26377;&#25928;&#27169;&#22411;&#22797;&#26434;&#24230;&#30340;&#26032;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing bounds on the generalization error of deep networks assume some form of smooth or bounded dependence on the input variable, falling short of investigating the mechanisms controlling such factors in practice. In this work, we present an extensive experimental study of the empirical Lipschitz constant of deep networks undergoing double descent, and highlight non-monotonic trends strongly correlating with the test error. Building a connection between parameter-space and input-space gradients for SGD around a critical point, we isolate two important factors -- namely loss landscape curvature and distance of parameters from initialization -- respectively controlling optimization dynamics around a critical point and bounding model function complexity, even beyond the training data. Our study presents novels insights on implicit regularization via overparameterization, and effective model complexity for networks trained in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ACMP&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#20855;&#26377;&#21560;&#24341;&#21147;&#21644;&#25490;&#26021;&#21147;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#36827;&#34892;&#28040;&#24687;&#20256;&#36882;&#20256;&#25773;&#65292;&#20811;&#26381;&#20102;GNN&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#23558;&#32593;&#32476;&#28145;&#24230;&#25512;&#21040;100&#23618;&#65292;&#24182;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#33410;&#28857;&#20998;&#31867;&#21644;&#22270;&#21305;&#37197;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2206.05437</link><description>&lt;p&gt;
ACMP: Allen-Cahn&#20449;&#24687;&#20256;&#36882;&#29992;&#20110;&#24102;&#26377;&#29289;&#36136;&#30456;&#21464;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle Phase Transition. (arXiv:2206.05437v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05437
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ACMP&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#20855;&#26377;&#21560;&#24341;&#21147;&#21644;&#25490;&#26021;&#21147;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#36827;&#34892;&#28040;&#24687;&#20256;&#36882;&#20256;&#25773;&#65292;&#20811;&#26381;&#20102;GNN&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#23558;&#32593;&#32476;&#28145;&#24230;&#25512;&#21040;100&#23618;&#65292;&#24182;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#33410;&#28857;&#20998;&#31867;&#21644;&#22270;&#21305;&#37197;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#28040;&#24687;&#20256;&#36882;&#26159;&#22522;&#20110;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#29305;&#24449;&#25552;&#21462;&#21333;&#20803;&#65292;&#32771;&#34385;&#20174;&#19968;&#23618;&#21040;&#19979;&#19968;&#23618;&#30340;&#32593;&#32476;&#20256;&#25773;&#20013;&#30340;&#30456;&#37051;&#33410;&#28857;&#29305;&#24449;&#12290;&#25105;&#20204;&#36890;&#36807;&#20855;&#26377;&#21560;&#24341;&#21147;&#21644;&#25490;&#26021;&#21147;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#26469;&#24314;&#27169;&#36825;&#31181;&#36807;&#31243;&#65292;&#24182;&#22312;&#30456;&#21464;&#24314;&#27169;&#20013;&#24341;&#20837;Allen-Cahn&#21147;&#12290;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#26159;&#19968;&#31181;&#21453;&#24212;&#25193;&#25955;&#36807;&#31243;&#65292;&#21487;&#20197;&#23558;&#31890;&#23376;&#20998;&#31163;&#32780;&#19981;&#20250;&#25193;&#25955;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#31181;Allen-Cahn&#20449;&#24687;&#20256;&#36882;(ACMP)&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#20013;&#31890;&#23376;&#31995;&#32479;&#35299;&#30340;&#25968;&#20540;&#36845;&#20195;&#26500;&#25104;&#20102;&#28040;&#24687;&#20256;&#36882;&#20256;&#25773;&#12290;ACMP&#20855;&#26377;&#31616;&#21333;&#30340;&#23454;&#29616;&#21644;&#31070;&#32463;ODE&#27714;&#35299;&#22120;&#65292;&#21487;&#20197;&#23558;&#32593;&#32476;&#28145;&#24230;&#25512;&#21040;100&#23618;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#19978;&#35777;&#26126;&#30340;Dirichlet&#33021;&#37327;&#20005;&#26684;&#27491;&#19979;&#30028;&#12290;&#22240;&#27492;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#28145;&#24230;&#27169;&#22411;&#30340;GNN&#65292;&#36991;&#20813;&#20102;&#24120;&#35265;&#30340;GNN&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#12290;&#20351;&#29992;ACMP&#30340;GNN&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#23454;&#38469;&#33410;&#28857;&#20998;&#31867;&#21644;&#22270;&#21305;&#37197;&#20219;&#21153;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural message passing is a basic feature extraction unit for graph-structured data considering neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising in the modeling of phase transition. The dynamics of the system is a reaction-diffusion process which can separate particles without blowing up. This induces an Allen-Cahn message passing (ACMP) for graph neural networks where the numerical iteration for the particle system solution constitutes the message passing propagation. ACMP which has a simple implementation with a neural ODE solver can propel the network depth up to one hundred of layers with theoretically proven strictly positive lower bound of the Dirichlet energy. It thus provides a deep model of GNNs circumventing the common GNN problem of oversmoothing. GNNs with ACMP achieve state of the art performance for real-world node class
&lt;/p&gt;</description></item></channel></rss>