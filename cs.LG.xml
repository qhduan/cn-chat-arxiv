<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36825;&#31181;&#29420;&#29305;&#30340;Transformer&#27169;&#22411;&#22312;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#65292;&#20026;&#21487;&#38752;&#21644;&#21487;&#25345;&#32493;&#30340;&#30005;&#21147;&#31995;&#32479;&#36816;&#34892;&#25552;&#20379;&#20102;&#26377;&#21069;&#26223;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2403.16108</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#30340;Transformer&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Transformer approach for Electricity Price Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16108
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#29420;&#29305;&#30340;Transformer&#27169;&#22411;&#22312;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#65292;&#20026;&#21487;&#38752;&#21644;&#21487;&#25345;&#32493;&#30340;&#30005;&#21147;&#31995;&#32479;&#36816;&#34892;&#25552;&#20379;&#20102;&#26377;&#21069;&#26223;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32431;Transformer&#27169;&#22411;&#36827;&#34892;&#30005;&#21147;&#20215;&#26684;&#39044;&#27979;&#65288;EPF&#65289;&#30340;&#26032;&#26041;&#27861;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;&#27809;&#26377;&#20351;&#29992;&#20854;&#20182;&#36882;&#24402;&#32593;&#32476;&#32467;&#21512;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;&#22240;&#27492;&#65292;&#34920;&#26126;&#27880;&#24847;&#21147;&#23618;&#36275;&#20197;&#25429;&#25417;&#26102;&#38388;&#27169;&#24335;&#12290;&#35813;&#35770;&#25991;&#36824;&#36890;&#36807;&#20351;&#29992;&#24320;&#28304;EPF&#24037;&#20855;&#36827;&#34892;&#20102;&#23545;&#27169;&#22411;&#30340;&#20844;&#24179;&#27604;&#36739;&#65292;&#24182;&#25552;&#20379;&#20102;&#20195;&#30721;&#20197;&#22686;&#24378;EPF&#30740;&#31350;&#30340;&#21487;&#20877;&#29616;&#24615;&#21644;&#36879;&#26126;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;Transformer&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#20026;&#21487;&#38752;&#21644;&#21487;&#25345;&#32493;&#30340;&#30005;&#21147;&#31995;&#32479;&#36816;&#34892;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16108v1 Announce Type: cross  Abstract: This paper presents a novel approach to electricity price forecasting (EPF) using a pure Transformer model. As opposed to other alternatives, no other recurrent network is used in combination to the attention mechanism. Hence, showing that the attention layer is enough for capturing the temporal patterns. The paper also provides fair comparison of the models using the open-source EPF toolbox and provide the code to enhance reproducibility and transparency in EPF research. The results show that the Transformer model outperforms traditional methods, offering a promising solution for reliable and sustainable power system operation.
&lt;/p&gt;</description></item><item><title>FedComLoc&#21033;&#29992;Scaffnew&#31639;&#27861;&#30340;&#22522;&#30784;&#65292;&#24341;&#20837;&#20102;&#21387;&#32553;&#21644;&#26412;&#22320;&#35757;&#32451;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;</title><link>https://arxiv.org/abs/2403.09904</link><description>&lt;p&gt;
FedComLoc: &#31232;&#30095;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#36890;&#20449;&#39640;&#25928;&#20998;&#24067;&#24335;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
FedComLoc: Communication-Efficient Distributed Training of Sparse and Quantized Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09904
&lt;/p&gt;
&lt;p&gt;
FedComLoc&#21033;&#29992;Scaffnew&#31639;&#27861;&#30340;&#22522;&#30784;&#65292;&#24341;&#20837;&#20102;&#21387;&#32553;&#21644;&#26412;&#22320;&#35757;&#32451;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30001;&#20110;&#20854;&#20801;&#35768;&#24322;&#26500;&#23458;&#25143;&#31471;&#22312;&#26412;&#22320;&#22788;&#29702;&#20854;&#31169;&#26377;&#25968;&#25454;&#24182;&#19982;&#20013;&#22830;&#26381;&#21153;&#22120;&#20114;&#21160;&#65292;&#21516;&#26102;&#23562;&#37325;&#38544;&#31169;&#30340;&#29420;&#29305;&#29305;&#28857;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21463;&#21040;&#20102;&#21019;&#26032;&#30340;Scaffnew&#31639;&#27861;&#30340;&#21551;&#21457;&#65292;&#35813;&#31639;&#27861;&#22312;FL&#20013;&#22823;&#22823;&#25512;&#21160;&#20102;&#36890;&#20449;&#22797;&#26434;&#24615;&#30340;&#38477;&#20302;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;FedComLoc&#65288;&#32852;&#37030;&#21387;&#32553;&#21644;&#26412;&#22320;&#35757;&#32451;&#65289;&#65292;&#23558;&#23454;&#29992;&#19988;&#26377;&#25928;&#30340;&#21387;&#32553;&#38598;&#25104;&#21040;Scaffnew&#20013;&#65292;&#20197;&#36827;&#19968;&#27493;&#22686;&#24378;&#36890;&#20449;&#25928;&#29575;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#20351;&#29992;&#27969;&#34892;&#30340;TopK&#21387;&#32553;&#22120;&#21644;&#37327;&#21270;&#65292;&#23427;&#22312;&#22823;&#24133;&#20943;&#23569;&#24322;&#26500;&#20013;&#30340;&#36890;&#20449;&#24320;&#38144;&#26041;&#38754;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09904v1 Announce Type: cross  Abstract: Federated Learning (FL) has garnered increasing attention due to its unique characteristic of allowing heterogeneous clients to process their private data locally and interact with a central server, while being respectful of privacy. A critical bottleneck in FL is the communication cost. A pivotal strategy to mitigate this burden is \emph{Local Training}, which involves running multiple local stochastic gradient descent iterations between communication phases. Our work is inspired by the innovative \emph{Scaffnew} algorithm, which has considerably advanced the reduction of communication complexity in FL. We introduce FedComLoc (Federated Compressed and Local Training), integrating practical and effective compression into \emph{Scaffnew} to further enhance communication efficiency. Extensive experiments, using the popular TopK compressor and quantization, demonstrate its prowess in substantially reducing communication overheads in heter
&lt;/p&gt;</description></item><item><title>PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.04355</link><description>&lt;p&gt;
PQMass: &#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#30340;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#27010;&#29575;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04355
&lt;/p&gt;
&lt;p&gt;
PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#22522;&#20110;&#26679;&#26412;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#20272;&#35745;&#20004;&#20010;&#26679;&#26412;&#38598;&#21512;&#26469;&#33258;&#21516;&#19968;&#20998;&#24067;&#30340;&#27010;&#29575;&#65292;&#20026;&#35780;&#20272;&#21333;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#25110;&#27604;&#36739;&#22312;&#21516;&#19968;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#22810;&#20010;&#31454;&#20105;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#35745;&#19978;&#20005;&#26684;&#30340;&#26041;&#27861;&#12290;&#35813;&#27604;&#36739;&#21487;&#20197;&#36890;&#36807;&#23558;&#31354;&#38388;&#21010;&#20998;&#20026;&#38750;&#37325;&#21472;&#30340;&#21306;&#22495;&#24182;&#27604;&#36739;&#27599;&#20010;&#21306;&#22495;&#20013;&#30340;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#26469;&#36827;&#34892;&#12290;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#29983;&#25104;&#27169;&#22411;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#26679;&#26412;&#12290;&#23427;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#26080;&#38656;&#38477;&#32500;&#12290;&#26174;&#33879;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#20851;&#20110;&#30495;&#23454;&#20998;&#24067;&#23494;&#24230;&#30340;&#20551;&#35774;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#35757;&#32451;&#25110;&#25311;&#21512;&#20219;&#20309;&#36741;&#21161;&#27169;&#22411;&#12290;&#30456;&#21453;&#65292;&#23427;&#30528;&#37325;&#20110;&#36817;&#20284;&#35745;&#31639;&#23494;&#24230;&#30340;&#31215;&#20998;&#65288;&#27010;&#29575;&#36136;&#37327;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a comprehensive sample-based method for assessing the quality of generative models. The proposed approach enables the estimation of the probability that two sets of samples are drawn from the same distribution, providing a statistically rigorous method for assessing the performance of a single generative model or the comparison of multiple competing models trained on the same dataset. This comparison can be conducted by dividing the space into non-overlapping regions and comparing the number of data samples in each region. The method only requires samples from the generative model and the test data. It is capable of functioning directly on high-dimensional data, obviating the need for dimensionality reduction. Significantly, the proposed method does not depend on assumptions regarding the density of the true distribution, and it does not rely on training or fitting any auxiliary models. Instead, it focuses on approximating the integral of the density (probability mass) acros
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BA-SGCL&#30340;&#40065;&#26834;SGNN&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#22270;&#23545;&#27604;&#23398;&#20064;&#21407;&#21017;&#21644;&#24179;&#34913;&#22686;&#24378;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#24102;&#31526;&#21495;&#22270;&#23545;&#25239;&#24615;&#25915;&#20987;&#20013;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#19981;&#21487;&#36870;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.10590</link><description>&lt;p&gt;
Adversarially Robust Signed Graph Contrastive Learning from Balance Augmentation&#65288;&#20174;&#24179;&#34913;&#22686;&#24378;&#20013;&#25552;&#21462;&#23545;&#25239;&#24615;&#40065;&#26834;&#30340;&#24102;&#31526;&#21495;&#22270;&#23545;&#27604;&#23398;&#20064;&#65289;
&lt;/p&gt;
&lt;p&gt;
Adversarially Robust Signed Graph Contrastive Learning from Balance Augmentation. (arXiv:2401.10590v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BA-SGCL&#30340;&#40065;&#26834;SGNN&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#22270;&#23545;&#27604;&#23398;&#20064;&#21407;&#21017;&#21644;&#24179;&#34913;&#22686;&#24378;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#24102;&#31526;&#21495;&#22270;&#23545;&#25239;&#24615;&#25915;&#20987;&#20013;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#19981;&#21487;&#36870;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#31526;&#21495;&#22270;&#30001;&#36793;&#21644;&#31526;&#21495;&#32452;&#25104;&#65292;&#21487;&#20197;&#20998;&#20026;&#32467;&#26500;&#20449;&#24687;&#21644;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#12290;&#29616;&#26377;&#30340;&#24102;&#31526;&#21495;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;SGNN&#65289;&#36890;&#24120;&#20381;&#36182;&#20110;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#26469;&#29983;&#25104;&#23884;&#20837;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#23545;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#20135;&#29983;&#20102;&#19981;&#21033;&#24433;&#21709;&#12290;&#31867;&#20284;&#20110;&#32467;&#26500;&#23398;&#20064;&#21487;&#20197;&#24674;&#22797;&#26080;&#31526;&#21495;&#22270;&#65292;&#36890;&#36807;&#25913;&#36827;&#34987;&#27745;&#26579;&#22270;&#30340;&#24179;&#34913;&#24230;&#65292;&#21487;&#20197;&#23558;&#24179;&#34913;&#23398;&#20064;&#24212;&#29992;&#20110;&#24102;&#31526;&#21495;&#22270;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#38754;&#20020;&#30528;&#8220;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#30340;&#19981;&#21487;&#36870;&#24615;&#8221;&#25361;&#25112;-&#23613;&#31649;&#24179;&#34913;&#24230;&#24471;&#21040;&#25913;&#21892;&#65292;&#20294;&#24674;&#22797;&#30340;&#36793;&#21487;&#33021;&#19981;&#26159;&#26368;&#21021;&#21463;&#21040;&#25915;&#20987;&#24433;&#21709;&#30340;&#36793;&#65292;&#23548;&#33268;&#38450;&#24481;&#25928;&#26524;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;SGNN&#26694;&#26550;&#65292;&#31216;&#20026;&#24179;&#34913;&#22686;&#24378;&#24102;&#31526;&#21495;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;BA-SGCL&#65289;&#65292;&#23427;&#23558;&#22270;&#23545;&#27604;&#23398;&#20064;&#21407;&#21017;&#19982;&#24179;&#34913;&#22686;&#24378;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signed graphs consist of edges and signs, which can be separated into structural information and balance-related information, respectively. Existing signed graph neural networks (SGNNs) typically rely on balance-related information to generate embeddings. Nevertheless, the emergence of recent adversarial attacks has had a detrimental impact on the balance-related information. Similar to how structure learning can restore unsigned graphs, balance learning can be applied to signed graphs by improving the balance degree of the poisoned graph. However, this approach encounters the challenge "Irreversibility of Balance-related Information" - while the balance degree improves, the restored edges may not be the ones originally affected by attacks, resulting in poor defense effectiveness. To address this challenge, we propose a robust SGNN framework called Balance Augmented-Signed Graph Contrastive Learning (BA-SGCL), which combines Graph Contrastive Learning principles with balance augmentati
&lt;/p&gt;</description></item><item><title>&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#21487;&#20197;&#26497;&#20854;&#20887;&#20313;&#65292;&#20165;&#20351;&#29992;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#32500;&#24230;&#30340;1%&#23601;&#33021;&#22815;&#36798;&#21040;&#20351;&#29992;&#23436;&#25972;&#34920;&#31034;&#26102;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.03843</link><description>&lt;p&gt;
Less is More: &#20851;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20219;&#21153;&#20013;&#29305;&#24449;&#20887;&#20313;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Less is More: On the Feature Redundancy of Pretrained Models When Transferring to Few-shot Tasks. (arXiv:2310.03843v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03843
&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#21487;&#20197;&#26497;&#20854;&#20887;&#20313;&#65292;&#20165;&#20351;&#29992;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#32500;&#24230;&#30340;1%&#23601;&#33021;&#22815;&#36798;&#21040;&#20351;&#29992;&#23436;&#25972;&#34920;&#31034;&#26102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#24212;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#30446;&#26631;&#25968;&#25454;&#36827;&#34892;&#32447;&#24615;&#25506;&#27979;&#26469;&#23454;&#29616;&#65292;&#21363;&#23545;&#20174;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#25552;&#21462;&#30340;&#20923;&#32467;&#29305;&#24449;&#36827;&#34892;&#35757;&#32451;&#32447;&#24615;&#20998;&#31867;&#22120;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#21644;&#19979;&#28216;&#25968;&#25454;&#38598;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#25105;&#20204;&#21487;&#20197;&#35810;&#38382;&#26159;&#21542;&#25152;&#26377;&#39044;&#35757;&#32451;&#29305;&#24449;&#30340;&#32500;&#24230;&#23545;&#20110;&#32473;&#23450;&#30340;&#19979;&#28216;&#20219;&#21153;&#37117;&#26159;&#26377;&#29992;&#30340;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#32447;&#24615;&#25506;&#27979;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#19979;&#28216;&#25968;&#25454;&#31232;&#32570;&#25110;&#23569;&#26679;&#26412;&#26102;&#65292;&#39044;&#35757;&#32451;&#29305;&#24449;&#21487;&#33021;&#26497;&#20854;&#20887;&#20313;&#12290;&#23545;&#20110;&#19968;&#20123;&#24773;&#20917;&#65292;&#27604;&#22914;5&#31867;1&#26679;&#26412;&#20219;&#21153;&#65292;&#21482;&#20351;&#29992;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#32500;&#24230;&#30340;1%&#23601;&#33021;&#22815;&#36798;&#21040;&#20351;&#29992;&#23436;&#25972;&#34920;&#31034;&#26102;&#30340;&#24615;&#33021;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22823;&#37096;&#20998;&#29305;&#24449;&#21482;&#22312;&#23569;&#26679;&#26412;&#35774;&#32622;&#19979;&#26159;&#20887;&#20313;&#30340;&#65292;&#22312;&#26679;&#26412;&#25968;&#22686;&#21152;&#26102;&#36880;&#28176;&#21464;&#24471;&#26377;&#29992;&#65292;&#36825;&#34920;&#26126;&#29305;&#24449;&#20887;&#20313;&#21487;&#33021;&#26159;&#34920;&#24449;&#23569;&#26679;&#26412;&#36716;&#31227;&#38382;&#39064;&#30340;&#20851;&#38190;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#29702;&#35770;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Transferring a pretrained model to a downstream task can be as easy as conducting linear probing with target data, that is, training a linear classifier upon frozen features extracted from the pretrained model. As there may exist significant gaps between pretraining and downstream datasets, one may ask whether all dimensions of the pretrained features are useful for a given downstream task. We show that, for linear probing, the pretrained features can be extremely redundant when the downstream data is scarce, or few-shot. For some cases such as 5-way 1-shot tasks, using only 1\% of the most important feature dimensions is able to recover the performance achieved by using the full representation. Interestingly, most dimensions are redundant only under few-shot settings and gradually become useful when the number of shots increases, suggesting that feature redundancy may be the key to characterizing the "few-shot" nature of few-shot transfer problems. We give a theoretical understanding 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Sparse Gaussian Process attention (SGPA)&#26469;&#26657;&#20934;Transformer&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;SGPA-based Transformers&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.02444</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#26657;&#20934;Transformer
&lt;/p&gt;
&lt;p&gt;
Calibrating Transformers via Sparse Gaussian Processes. (arXiv:2303.02444v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02444
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Sparse Gaussian Process attention (SGPA)&#26469;&#26657;&#20934;Transformer&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;SGPA-based Transformers&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#27169;&#22411;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#35821;&#38899;&#35782;&#21035;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#24191;&#27867;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#23558;Transformer&#30340;&#25104;&#21151;&#25193;&#23637;&#21040;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#38656;&#35201;&#20934;&#30830;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#36739;&#23569;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#27880;&#24847;&#21147;&#65288;SGPA&#65289;&#65292;&#23427;&#30452;&#25509;&#22312;Transformer&#30340;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#22359;&#65288;MHA&#65289;&#30340;&#36755;&#20986;&#31354;&#38388;&#20013;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20197;&#26657;&#20934;&#20854;&#19981;&#30830;&#23450;&#24615;&#12290;&#23427;&#29992;&#19968;&#20010;&#26377;&#25928;&#30340;&#23545;&#31216;&#26680;&#26367;&#20195;&#20102;&#32553;&#25918;&#28857;&#31215;&#25805;&#20316;&#65292;&#24182;&#20351;&#29992;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#65288;SGP&#65289;&#25216;&#26415;&#26469;&#36817;&#20284;MHA&#36755;&#20986;&#30340;&#21518;&#39564;&#36807;&#31243;&#12290;&#32463;&#39564;&#19978;&#65292;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#19968;&#31995;&#21015;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;SGPA&#30340;Transformer&#27169;&#22411;&#23454;&#29616;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer models have achieved profound success in prediction tasks in a wide range of applications in natural language processing, speech recognition and computer vision. Extending Transformer's success to safety-critical domains requires calibrated uncertainty estimation which remains under-explored. To address this, we propose Sparse Gaussian Process attention (SGPA), which performs Bayesian inference directly in the output space of multi-head attention blocks (MHAs) in transformer to calibrate its uncertainty. It replaces the scaled dot-product operation with a valid symmetric kernel and uses sparse Gaussian processes (SGP) techniques to approximate the posterior processes of MHA outputs. Empirically, on a suite of prediction tasks on text, images and graphs, SGPA-based Transformers achieve competitive predictive accuracy, while noticeably improving both in-distribution calibration and out-of-distribution robustness and detection.
&lt;/p&gt;</description></item><item><title>FlexFringe&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#27010;&#29575;&#26377;&#38480;&#33258;&#21160;&#26426;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#24314;&#27169;&#36719;&#20214;&#34892;&#20026;&#12290;&#35813;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#36890;&#36807;&#23454;&#29616;&#25913;&#36827;&#30340;&#29366;&#24577;&#21512;&#24182;&#31574;&#30053;&#23454;&#29616;&#20102;&#26174;&#33879;&#24615;&#33021;&#25552;&#21319;&#65292;&#24182;&#19988;&#33021;&#22815;&#20174;&#36719;&#20214;&#26085;&#24535;&#20013;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35299;&#20915;&#26041;&#26696;&#30456;&#27604;&#65292;&#23398;&#20064;&#26356;&#23567;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#33021;&#22815;&#25552;&#39640;FlexFringe&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2203.16331</link><description>&lt;p&gt;
FlexFringe:&#36890;&#36807;&#23398;&#20064;&#27010;&#29575;&#26377;&#38480;&#33258;&#21160;&#26426;&#26469;&#24314;&#27169;&#36719;&#20214;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
FlexFringe: Modeling Software Behavior by Learning Probabilistic Automata. (arXiv:2203.16331v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.16331
&lt;/p&gt;
&lt;p&gt;
FlexFringe&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#27010;&#29575;&#26377;&#38480;&#33258;&#21160;&#26426;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#24314;&#27169;&#36719;&#20214;&#34892;&#20026;&#12290;&#35813;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#36890;&#36807;&#23454;&#29616;&#25913;&#36827;&#30340;&#29366;&#24577;&#21512;&#24182;&#31574;&#30053;&#23454;&#29616;&#20102;&#26174;&#33879;&#24615;&#33021;&#25552;&#21319;&#65292;&#24182;&#19988;&#33021;&#22815;&#20174;&#36719;&#20214;&#26085;&#24535;&#20013;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35299;&#20915;&#26041;&#26696;&#30456;&#27604;&#65292;&#23398;&#20064;&#26356;&#23567;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#33021;&#22815;&#25552;&#39640;FlexFringe&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;FlexFringe&#20013;&#21487;&#29992;&#30340;&#27010;&#29575;&#30830;&#23450;&#24615;&#26377;&#38480;&#33258;&#21160;&#26426;&#23398;&#20064;&#26041;&#27861;&#30340;&#39640;&#25928;&#23454;&#29616;&#12290;&#36825;&#20123;&#23454;&#29616;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;&#29366;&#24577;&#21512;&#24182;&#31574;&#30053;&#65292;&#21253;&#25324;&#20960;&#31181;&#20462;&#25913;&#20197;&#25552;&#39640;&#23427;&#20204;&#22312;&#23454;&#36341;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#33719;&#24471;&#26377;&#31454;&#20105;&#21147;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#40664;&#35748;&#23454;&#29616;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;FlexFringe&#20174;&#36719;&#20214;&#26085;&#24535;&#20013;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#36739;&#38590;&#35299;&#37322;&#65292;&#20294;&#25105;&#20204;&#23637;&#31034;&#20102;&#23398;&#20064;&#26356;&#23567;&#12289;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#22914;&#20309;&#25552;&#39640;FlexFringe&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#20248;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the efficient implementations of probabilistic deterministic finite automaton learning methods available in FlexFringe. These implement well-known strategies for state-merging including several modifications to improve their performance in practice. We show experimentally that these algorithms obtain competitive results and significant improvements over a default implementation. We also demonstrate how to use FlexFringe to learn interpretable models from software logs and use these for anomaly detection. Although less interpretable, we show that learning smaller more convoluted models improves the performance of FlexFringe on anomaly detection, outperforming an existing solution based on neural nets.
&lt;/p&gt;</description></item></channel></rss>