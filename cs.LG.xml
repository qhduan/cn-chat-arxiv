<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#22312;&#26377;&#38480;&#35282;&#24230;&#23618;&#26512;&#25104;&#20687;&#20013;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#33021;&#26356;&#31283;&#23450;&#22320;&#37325;&#26500;&#26356;&#22810;&#20449;&#24687;</title><link>https://arxiv.org/abs/2403.11350</link><description>&lt;p&gt;
&#26377;&#38480;&#35282;&#24230;&#23618;&#26512;&#25104;&#20687;&#20013;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Robustness of the data-driven approach in limited angle tomography
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11350
&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#22312;&#26377;&#38480;&#35282;&#24230;&#23618;&#26512;&#25104;&#20687;&#20013;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#33021;&#26356;&#31283;&#23450;&#22320;&#37325;&#26500;&#26356;&#22810;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#38480;&#35282;&#24230;Radon&#21464;&#25442;&#30001;&#20110;&#20854;&#19981;&#36870;&#38382;&#39064;&#32780;&#38395;&#21517;&#20110;&#19990;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#35299;&#37322;&#65292;&#21363;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#21487;&#20197;&#20197;&#26356;&#31283;&#23450;&#30340;&#26041;&#24335;&#37325;&#26500;&#26356;&#22810;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11350v1 Announce Type: cross  Abstract: The limited angle Radon transform is notoriously difficult to invert due to the ill-posedness. In this work, we give a mathematical explanation that the data-driven approach based on deep neural networks can reconstruct more information in a stable way compared to traditional methods.
&lt;/p&gt;</description></item><item><title>&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#30340;&#27169;&#22411;&#39044;&#27979;&#26041;&#27861;&#26377;&#21161;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#30340;&#31574;&#30053;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.13213</link><description>&lt;p&gt;
&#36719;&#26368;&#22823;&#27010;&#29575;&#65288;&#22823;&#37096;&#20998;&#26102;&#20505;&#65289;&#22312;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#39044;&#27979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27491;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Softmax Probabilities (Mostly) Predict Large Language Model Correctness on Multiple-Choice Q&amp;A
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13213
&lt;/p&gt;
&lt;p&gt;
&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#30340;&#27169;&#22411;&#39044;&#27979;&#26041;&#27861;&#26377;&#21161;&#20110;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#30340;&#31574;&#30053;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#36807;&#24230;&#33258;&#20449;&#20173;&#28982;&#26159;&#19968;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#35774;&#22312;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#38169;&#35823;&#31572;&#26696;&#23558;&#19982;&#26368;&#22823;softmax&#27010;&#29575;&#65288;MSPs&#65289;&#36739;&#23567;&#30456;&#20851;&#65292;&#30456;&#27604;&#20043;&#19979;&#27491;&#30830;&#31572;&#26696;&#36739;&#22823;&#12290;&#25105;&#20204;&#22312;&#21313;&#20010;&#24320;&#28304;LLMs&#21644;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#20840;&#38754;&#35780;&#20272;&#20102;&#36825;&#19968;&#20551;&#35774;&#65292;&#22312;&#34920;&#29616;&#33391;&#22909;&#30340;&#21407;&#22987;&#38382;&#31572;&#20219;&#21153;&#20013;&#21457;&#29616;&#20102;&#23545;&#25105;&#20204;&#20551;&#35774;&#30340;&#24378;&#26377;&#21147;&#35777;&#25454;&#12290;&#23545;&#20110;&#34920;&#29616;&#26368;&#20339;&#30340;&#20845;&#20010;LLMs&#65292;&#20174;MSP&#23548;&#20986;&#30340;AUROC&#22312;59/60&#20010;&#23454;&#20363;&#20013;&#37117;&#20248;&#20110;&#38543;&#26426;&#26426;&#20250;&#65292;p &lt; 10^{-4}&#12290;&#22312;&#36825;&#20845;&#20010;LLMs&#20013;&#65292;&#24179;&#22343;AUROC&#33539;&#22260;&#22312;60%&#33267;69%&#20043;&#38388;&#12290;&#21033;&#29992;&#36825;&#20123;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#24323;&#26435;&#36873;&#39033;&#30340;&#22810;&#39033;&#36873;&#25321;&#38382;&#31572;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#36890;&#36807;&#26681;&#25454;&#21021;&#22987;&#27169;&#22411;&#21709;&#24212;&#30340;MSP&#26377;&#36873;&#25321;&#22320;&#24323;&#26435;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#29992;&#39044;softmax logits&#32780;&#19981;&#26159;softmax&#36827;&#34892;&#20102;&#30456;&#21516;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13213v1 Announce Type: cross  Abstract: Although large language models (LLMs) perform impressively on many tasks, overconfidence remains a problem. We hypothesized that on multiple-choice Q&amp;A tasks, wrong answers would be associated with smaller maximum softmax probabilities (MSPs) compared to correct answers. We comprehensively evaluate this hypothesis on ten open-source LLMs and five datasets, and find strong evidence for our hypothesis among models which perform well on the original Q&amp;A task. For the six LLMs with the best Q&amp;A performance, the AUROC derived from the MSP was better than random chance with p &lt; 10^{-4} in 59/60 instances. Among those six LLMs, the average AUROC ranged from 60% to 69%. Leveraging these findings, we propose a multiple-choice Q&amp;A task with an option to abstain and show that performance can be improved by selectively abstaining based on the MSP of the initial model response. We also run the same experiments with pre-softmax logits instead of sof
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#35813;&#31574;&#30053;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#19968;&#33324;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.00539</link><description>&lt;p&gt;
&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#19979;&#30340;Thompson&#25506;&#32034;&#22312;&#26368;&#20339;&#33218;&#35782;&#21035;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Thompson Exploration with Best Challenger Rule in Best Arm Identification. (arXiv:2310.00539v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#35813;&#31574;&#30053;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#19968;&#33324;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32463;&#20856;&#21333;&#21442;&#25968;&#25351;&#25968;&#27169;&#22411;&#19979;&#65292;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#30446;&#21069;&#24050;&#26377;&#24456;&#22810;&#31574;&#30053;&#34987;&#25552;&#20986;&#65292;&#20294;&#22823;&#22810;&#25968;&#38656;&#35201;&#22312;&#27599;&#19968;&#36718;&#35299;&#20915;&#19968;&#20010;&#26368;&#20248;&#21270;&#38382;&#39064;&#21644;/&#25110;&#32773;&#38656;&#35201;&#25506;&#32034;&#19968;&#20010;&#33218;&#33267;&#23569;&#19968;&#23450;&#27425;&#25968;&#65292;&#38500;&#38750;&#26159;&#38024;&#23545;&#39640;&#26031;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#8212;&#8212;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#12290;&#34429;&#28982;Thompson&#37319;&#26679;&#26368;&#21021;&#34987;&#32771;&#34385;&#29992;&#20110;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#23427;&#20063;&#21487;&#20197;&#33258;&#28982;&#22320;&#29992;&#20110;&#22312;BAI&#20013;&#25506;&#32034;&#33218;&#32780;&#19981;&#24378;&#36843;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31574;&#30053;&#22312;&#20219;&#24847;&#20004;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#26159;&#28176;&#36817;&#26368;&#20248;&#30340;&#65292;&#24182;&#19988;&#22312;&#19968;&#33324;&#30340;$K$&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#65288;$K\geq 3$&#65289;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31574;&#30053;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#34920;&#29616;&#20986;&#20102;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the fixed-confidence best arm identification (BAI) problem in the bandit framework in the canonical single-parameter exponential models. For this problem, many policies have been proposed, but most of them require solving an optimization problem at every round and/or are forced to explore an arm at least a certain number of times except those restricted to the Gaussian model. To address these limitations, we propose a novel policy that combines Thompson sampling with a computationally efficient approach known as the best challenger rule. While Thompson sampling was originally considered for maximizing the cumulative reward, we demonstrate that it can be used to naturally explore arms in BAI without forcing it. We show that our policy is asymptotically optimal for any two-armed bandit problems and achieves near optimality for general $K$-armed bandit problems for $K\geq 3$. Nevertheless, in numerical experiments, our policy shows competitive performance compared to as
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#26080;&#30417;&#30563;&#22270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25552;&#20986;&#20102;&#38598;&#25104;&#22478;&#24066;&#27946;&#27700;&#39118;&#38505;&#35780;&#32423;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#21306;&#22495;&#20043;&#38388;&#30340;&#31354;&#38388;&#20381;&#36182;&#20851;&#31995;&#21644;&#27946;&#27700;&#21361;&#38505;&#19982;&#22478;&#24066;&#35201;&#32032;&#20043;&#38388;&#30340;&#22797;&#26434;&#30456;&#20114;&#20316;&#29992;&#65292;&#25581;&#31034;&#20102;&#22478;&#24066;&#22320;&#21306;&#30340;&#31361;&#21457;&#27946;&#27700;&#39118;&#38505;&#27010;&#20917;</title><link>http://arxiv.org/abs/2309.14610</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#22270;&#28145;&#24230;&#23398;&#20064;&#25581;&#31034;&#20102;&#22478;&#24066;&#22320;&#21306;&#31361;&#21457;&#27946;&#27700;&#39118;&#38505;&#27010;&#20917;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas. (arXiv:2309.14610v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14610
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#26080;&#30417;&#30563;&#22270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25552;&#20986;&#20102;&#38598;&#25104;&#22478;&#24066;&#27946;&#27700;&#39118;&#38505;&#35780;&#32423;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#21306;&#22495;&#20043;&#38388;&#30340;&#31354;&#38388;&#20381;&#36182;&#20851;&#31995;&#21644;&#27946;&#27700;&#21361;&#38505;&#19982;&#22478;&#24066;&#35201;&#32032;&#20043;&#38388;&#30340;&#22797;&#26434;&#30456;&#20114;&#20316;&#29992;&#65292;&#25581;&#31034;&#20102;&#22478;&#24066;&#22320;&#21306;&#30340;&#31361;&#21457;&#27946;&#27700;&#39118;&#38505;&#27010;&#20917;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22478;&#24066;&#27946;&#27700;&#39118;&#38505;&#28304;&#20110;&#19982;&#27946;&#27700;&#21361;&#38505;&#12289;&#27946;&#27700;&#26292;&#38706;&#20197;&#21450;&#31038;&#20250;&#21644;&#29289;&#29702;&#33030;&#24369;&#24615;&#30456;&#20851;&#30340;&#22810;&#20010;&#35201;&#32032;&#20043;&#38388;&#30340;&#22797;&#26434;&#21644;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#20197;&#21450;&#22797;&#26434;&#30340;&#31354;&#38388;&#27946;&#27700;&#20381;&#36182;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29992;&#20110;&#34920;&#24449;&#22478;&#24066;&#27946;&#27700;&#39118;&#38505;&#30340;&#26041;&#27861;&#20027;&#35201;&#26159;&#22522;&#20110;&#27946;&#27700;&#24179;&#21407;&#22320;&#22270;&#65292;&#20391;&#37325;&#20110;&#26377;&#38480;&#25968;&#37327;&#30340;&#35201;&#32032;&#65292;&#20027;&#35201;&#26159;&#21361;&#38505;&#21644;&#26292;&#38706;&#35201;&#32032;&#65292;&#27809;&#26377;&#32771;&#34385;&#35201;&#32032;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#25110;&#31354;&#38388;&#21306;&#22495;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#22270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65288;&#31216;&#20026;FloodRisk-Net&#65289;&#30340;&#38598;&#25104;&#22478;&#24066;&#27946;&#27700;&#39118;&#38505;&#35780;&#32423;&#27169;&#22411;&#12290;FloodRisk-Net&#33021;&#22815;&#25429;&#25417;&#21306;&#22495;&#20043;&#38388;&#30340;&#31354;&#38388;&#20381;&#36182;&#20851;&#31995;&#20197;&#21450;&#27946;&#27700;&#21361;&#38505;&#21644;&#22478;&#24066;&#35201;&#32032;&#20043;&#38388;&#30340;&#22797;&#26434;&#21644;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#30830;&#23450;&#31361;&#21457;&#27946;&#27700;&#39118;&#38505;&#12290;&#21033;&#29992;&#32654;&#22269;&#22810;&#20010;&#37117;&#24066;&#32479;&#35745;&#21306;&#65288;MSAs&#65289;&#30340;&#25968;&#25454;&#65292;&#35813;&#27169;&#22411;&#23558;&#23427;&#20204;&#30340;&#27946;&#27700;&#39118;&#38505;&#29305;&#24449;&#21270;&#20026;
&lt;/p&gt;
&lt;p&gt;
Urban flood risk emerges from complex and nonlinear interactions among multiple features related to flood hazard, flood exposure, and social and physical vulnerabilities, along with the complex spatial flood dependence relationships. Existing approaches for characterizing urban flood risk, however, are primarily based on flood plain maps, focusing on a limited number of features, primarily hazard and exposure features, without consideration of feature interactions or the dependence relationships among spatial areas. To address this gap, this study presents an integrated urban flood-risk rating model based on a novel unsupervised graph deep learning model (called FloodRisk-Net). FloodRisk-Net is capable of capturing spatial dependence among areas and complex and nonlinear interactions among flood hazards and urban features for specifying emergent flood risk. Using data from multiple metropolitan statistical areas (MSAs) in the United States, the model characterizes their flood risk into
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#29256;&#30340;&#8220;&#36923;&#36753;&#36879;&#38236;&#8221;&#25216;&#26415;&#8212;&#8212;&#8220;&#35843;&#35856;&#36879;&#38236;&#8221;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#20223;&#23556;&#25506;&#38024;&#65292;&#21487;&#20197;&#23558;&#27599;&#20010;&#38544;&#34255;&#29366;&#24577;&#35299;&#30721;&#25104;&#35789;&#27719;&#20998;&#24067;&#12290;&#36825;&#20010;&#26041;&#27861;&#34987;&#24212;&#29992;&#20110;&#21508;&#31181;&#33258;&#22238;&#24402;&#35821;&#35328;&#27169;&#22411;&#19978;&#65292;&#27604;&#36923;&#36753;&#36879;&#38236;&#26356;&#20855;&#26377;&#39044;&#27979;&#24615;&#12289;&#21487;&#38752;&#24615;&#21644;&#26080;&#20559;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#22240;&#26524;&#23454;&#39564;&#39564;&#35777;&#20351;&#29992;&#30340;&#29305;&#24449;&#19982;&#27169;&#22411;&#26412;&#36523;&#31867;&#20284;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#21457;&#29616;&#28508;&#22312;&#39044;&#27979;&#30340;&#36712;&#36857;&#21487;&#20197;&#29992;&#20110;&#39640;&#31934;&#24230;&#22320;&#26816;&#27979;&#24694;&#24847;&#36755;&#20837;&#12290;</title><link>http://arxiv.org/abs/2303.08112</link><description>&lt;p&gt;
&#29992;&#35843;&#35856;&#36879;&#38236;&#20174;Transformer&#20013;&#33719;&#21462;&#28508;&#22312;&#30340;&#39044;&#27979;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Eliciting Latent Predictions from Transformers with the Tuned Lens. (arXiv:2303.08112v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#29256;&#30340;&#8220;&#36923;&#36753;&#36879;&#38236;&#8221;&#25216;&#26415;&#8212;&#8212;&#8220;&#35843;&#35856;&#36879;&#38236;&#8221;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#20010;&#20223;&#23556;&#25506;&#38024;&#65292;&#21487;&#20197;&#23558;&#27599;&#20010;&#38544;&#34255;&#29366;&#24577;&#35299;&#30721;&#25104;&#35789;&#27719;&#20998;&#24067;&#12290;&#36825;&#20010;&#26041;&#27861;&#34987;&#24212;&#29992;&#20110;&#21508;&#31181;&#33258;&#22238;&#24402;&#35821;&#35328;&#27169;&#22411;&#19978;&#65292;&#27604;&#36923;&#36753;&#36879;&#38236;&#26356;&#20855;&#26377;&#39044;&#27979;&#24615;&#12289;&#21487;&#38752;&#24615;&#21644;&#26080;&#20559;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#22240;&#26524;&#23454;&#39564;&#39564;&#35777;&#20351;&#29992;&#30340;&#29305;&#24449;&#19982;&#27169;&#22411;&#26412;&#36523;&#31867;&#20284;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#21457;&#29616;&#28508;&#22312;&#39044;&#27979;&#30340;&#36712;&#36857;&#21487;&#20197;&#29992;&#20110;&#39640;&#31934;&#24230;&#22320;&#26816;&#27979;&#24694;&#24847;&#36755;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#36845;&#20195;&#25512;&#29702;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;transformers&#27169;&#22411;&#65292;&#26088;&#22312;&#20102;&#35299;&#27169;&#22411;&#39044;&#27979;&#26159;&#22914;&#20309;&#36880;&#23618;&#36827;&#34892;&#31934;&#21270;&#30340;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#30340;&#65292;&#25105;&#20204;&#20026;&#20923;&#32467;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#30340;&#27599;&#20010;&#22359;&#35757;&#32451;&#19968;&#20010;&#20223;&#23556;&#25506;&#38024;&#65292;&#20351;&#24471;&#21487;&#20197;&#23558;&#27599;&#20010;&#38544;&#34255;&#29366;&#24577;&#35299;&#30721;&#25104;&#35789;&#27719;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#8220;&#35843;&#35856;&#36879;&#38236;&#8221;&#65292;&#26159;&#8220;&#36923;&#36753;&#36879;&#38236;&#8221;&#25216;&#26415;&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;&#21069;&#32773;&#32473;&#20986;&#20102;&#26377;&#29992;&#30340;&#35265;&#35299;&#65292;&#20294;&#24120;&#24120;&#26131;&#30862;&#12290;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#20855;&#26377;&#22810;&#36798;20B&#21442;&#25968;&#30340;&#33258;&#22238;&#24402;&#35821;&#35328;&#27169;&#22411;&#65292;&#34920;&#26126;&#20854;&#27604;&#36923;&#36753;&#36879;&#38236;&#26356;&#20855;&#26377;&#39044;&#27979;&#24615;&#12289;&#21487;&#38752;&#24615;&#21644;&#26080;&#20559;&#24615;&#12290;&#36890;&#36807;&#22240;&#26524;&#23454;&#39564;&#26174;&#31034;&#65292;&#35843;&#35856;&#36879;&#38236;&#20351;&#29992;&#30340;&#29305;&#24449;&#19982;&#27169;&#22411;&#26412;&#36523;&#31867;&#20284;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#28508;&#22312;&#39044;&#27979;&#30340;&#36712;&#36857;&#21487;&#20197;&#29992;&#20110;&#39640;&#31934;&#24230;&#22320;&#26816;&#27979;&#24694;&#24847;&#36755;&#20837;&#12290;&#25105;&#20204;&#30340;&#25152;&#26377;&#20195;&#30721;&#37117;&#21487;&#20197;&#22312;https://github.com/AlignmentResearch/tuned-lens &#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze transformers from the perspective of iterative inference, seeking to understand how model predictions are refined layer by layer. To do so, we train an affine probe for each block in a frozen pretrained model, making it possible to decode every hidden state into a distribution over the vocabulary. Our method, the \emph{tuned lens}, is a refinement of the earlier ``logit lens'' technique, which yielded useful insights but is often brittle.  We test our method on various autoregressive language models with up to 20B parameters, showing it to be more predictive, reliable and unbiased than the logit lens. With causal experiments, we show the tuned lens uses similar features to the model itself. We also find the trajectory of latent predictions can be used to detect malicious inputs with high accuracy. All code needed to reproduce our results can be found at https://github.com/AlignmentResearch/tuned-lens.
&lt;/p&gt;</description></item></channel></rss>