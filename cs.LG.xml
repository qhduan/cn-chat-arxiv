<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35780;&#35770;&#20102;&#21478;&#19968;&#31687;&#20851;&#20110;&#20174;&#24494;&#20998;&#26041;&#31243;&#20013;&#23398;&#20064;&#23432;&#24658;&#23450;&#24459;&#30340;&#25991;&#31456;&#20013;&#23384;&#22312;&#30340;&#20005;&#37325;&#25512;&#23548;&#38169;&#35823;</title><link>https://arxiv.org/abs/2404.02896</link><description>&lt;p&gt;
&#23545;&#8220;&#20174;&#24494;&#20998;&#26041;&#31243;&#20013;&#23398;&#20064;&#23432;&#24658;&#23450;&#24459;&#8221;&#19968;&#25991;&#30340;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Comment on "Machine learning conservation laws from differential equations"
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02896
&lt;/p&gt;
&lt;p&gt;
&#35780;&#35770;&#20102;&#21478;&#19968;&#31687;&#20851;&#20110;&#20174;&#24494;&#20998;&#26041;&#31243;&#20013;&#23398;&#20064;&#23432;&#24658;&#23450;&#24459;&#30340;&#25991;&#31456;&#20013;&#23384;&#22312;&#30340;&#20005;&#37325;&#25512;&#23548;&#38169;&#35823;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27492;&#35780;&#35770;&#20013;&#65292;&#20316;&#32773;&#22238;&#39038;&#20102;&#21016;, &#39532;&#24503;&#21704;&#19975;&#21644;&#27888;&#26684;&#39532;&#20811;&#25552;&#20986;&#30340;&#19982;&#20316;&#32773;&#25552;&#20986;&#30340;&#19968;&#32500;&#38459;&#23612;&#35856;&#25391;&#23376;&#30340;&#23432;&#24658;&#37327;&#30456;&#31867;&#20284;&#30340;&#32467;&#26524;&#65292;&#25351;&#20986;&#20182;&#20204;&#25512;&#23548;&#20013;&#23384;&#22312;&#20845;&#20010;&#20005;&#37325;&#38169;&#35823;&#65292;&#23548;&#33268;&#20182;&#20204;&#30340;&#26041;&#27861;&#21644;&#32467;&#26524;&#22343;&#19981;&#27491;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02896v1 Announce Type: new  Abstract: In lieu of abstract, first paragraph reads: Six months after the author derived a constant of motion for a 1D damped harmonic oscillator [1], a similar result appeared by Liu, Madhavan, and Tegmark [2, 3], without citing the author. However, their derivation contained six serious errors, causing both their method and result to be incorrect. In this Comment, those errors are reviewed.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#27979;&#35797;&#26102;&#38388;&#21407;&#22411;&#36716;&#31227;&#65288;TPS&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21160;&#24577;&#23398;&#20064;&#27599;&#20010;&#21407;&#22411;&#30340;&#36716;&#31227;&#21521;&#37327;&#65292;&#26377;&#25928;&#22320;&#24357;&#21512;&#20102;&#39046;&#22495;&#24046;&#36317;&#24182;&#22686;&#24378;&#20102;&#31867;</title><link>https://arxiv.org/abs/2403.12952</link><description>&lt;p&gt;
&#21482;&#38656;&#36716;&#31227;&#23427;&#65306;&#27979;&#35797;&#26102;&#38388;&#21407;&#22411;&#36716;&#31227;&#29992;&#20110;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Just Shift It: Test-Time Prototype Shifting for Zero-Shot Generalization with Vision-Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12952
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#27979;&#35797;&#26102;&#38388;&#21407;&#22411;&#36716;&#31227;&#65288;TPS&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21160;&#24577;&#23398;&#20064;&#27599;&#20010;&#21407;&#22411;&#30340;&#36716;&#31227;&#21521;&#37327;&#65292;&#26377;&#25928;&#22320;&#24357;&#21512;&#20102;&#39046;&#22495;&#24046;&#36317;&#24182;&#22686;&#24378;&#20102;&#31867;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#30340;&#36827;&#23637;&#25512;&#21160;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#22312;&#38646;&#26679;&#26412;&#23398;&#20064;&#35774;&#32622;&#20013;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#26377;&#21069;&#26223;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#22312;&#27979;&#35797;&#29615;&#22659;&#20013;&#24448;&#24448;&#20250;&#22240;&#20026;&#39046;&#22495;&#36716;&#31227;&#32780;&#38477;&#20302;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#27979;&#35797;&#26102;&#38388;&#21407;&#22411;&#36716;&#31227;&#65288;TPS&#65289;&#26694;&#26550;&#65292;&#36825;&#26159;&#19968;&#31181;&#26088;&#22312;&#20351;&#29992;&#26631;&#35760;&#27979;&#35797;&#36755;&#20837;&#26469;&#20351;VLM&#36866;&#24212;&#27979;&#35797;&#25968;&#25454;&#38598;&#30340;&#24320;&#21019;&#24615;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22312;&#20849;&#20139;&#23884;&#20837;&#31354;&#38388;&#20013;&#35843;&#33410;&#27599;&#20010;&#31867;&#21035;&#30340;&#21407;&#22411;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#20351;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;&#25991;&#26412;&#32534;&#30721;&#22120;&#29983;&#25104;&#24182;&#32531;&#23384;&#21407;&#22411;&#65292;TPS&#19981;&#20165;&#20419;&#36827;&#20102;&#26080;&#38656;&#20248;&#21270;&#30340;&#21407;&#22411;&#37325;&#29992;&#36827;&#34892;&#21518;&#32493;&#39044;&#27979;&#65292;&#36824;&#35753;&#20854;&#33021;&#22815;&#26080;&#32541;&#38598;&#25104;&#24403;&#21069;&#36827;&#23637;&#30340;&#25552;&#31034;&#24037;&#31243;&#25216;&#26415;&#12290;&#22312;&#27979;&#35797;&#26102;&#38388;&#65292;TPS&#20165;&#22522;&#20110;&#32473;&#23450;&#30340;&#27979;&#35797;&#26679;&#26412;&#21160;&#24577;&#23398;&#20064;&#27599;&#20010;&#21407;&#22411;&#30340;&#36716;&#31227;&#21521;&#37327;&#65292;&#26377;&#25928;&#22320;&#24357;&#21512;&#39046;&#22495;&#24046;&#36317;&#24182;&#22686;&#24378;&#31867;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12952v1 Announce Type: cross  Abstract: Advancements in vision-language models (VLMs) have propelled the field of computer vision, particularly in the zero-shot learning setting. Despite their promise, the effectiveness of these models often diminishes due to domain shifts in test environments. To address this, we introduce the Test-Time Prototype Shifting (TPS) framework, a pioneering approach designed to adapt VLMs to test datasets using unlabeled test inputs. Our method is based on the notion of modulating per-class prototypes in the shared embedding space. By pre-computing and caching prototypes generated with the pre-trained text encoder, TPS not only facilitates optimization-free prototype reuse for subsequent predictions but also enables seamless integration with current advancements in prompt engineering. At test-time, TPS dynamically learns shift vectors for each prototype based solely on the given test sample, effectively bridging the domain gap and enhancing class
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#22270;&#35889;&#32467;&#21512;&#65292;&#25552;&#39640;&#38646;&#26679;&#26412;&#23545;&#35937;&#29366;&#24577;&#20998;&#31867;&#24615;&#33021;</title><link>https://arxiv.org/abs/2403.12151</link><description>&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#39046;&#22495;&#29305;&#23450;&#20869;&#23481;&#34701;&#20837;&#30693;&#35782;&#22270;&#35889;&#65292;&#20197;&#22686;&#24378;&#38646;&#26679;&#26412;&#23545;&#35937;&#29366;&#24577;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Fusing Domain-Specific Content from Large Language Models into Knowledge Graphs for Enhanced Zero Shot Object State Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12151
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#22270;&#35889;&#32467;&#21512;&#65292;&#25552;&#39640;&#38646;&#26679;&#26412;&#23545;&#35937;&#29366;&#24577;&#20998;&#31867;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#21487;&#20197;&#26174;&#33879;&#26377;&#21161;&#20110;&#35299;&#20915;&#21508;&#31181;&#35270;&#35273;&#20219;&#21153;&#65292;&#20294;&#29983;&#25104;&#36825;&#31181;&#30693;&#35782;&#38656;&#35201;&#22823;&#37327;&#20154;&#21147;&#21644;&#26102;&#38388;&#25104;&#26412;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#36890;&#36807;&#35821;&#20041;&#23884;&#20837;&#29983;&#25104;&#21644;&#25552;&#20379;&#39046;&#22495;&#29305;&#23450;&#20449;&#24687;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#23558;LLM&#38598;&#25104;&#21040;&#19968;&#20010;&#27969;&#31243;&#20013;&#65292;&#35813;&#27969;&#31243;&#22312;&#35270;&#35273;&#22522;&#30784;&#38646;&#26679;&#26412;&#23545;&#35937;&#29366;&#24577;&#20998;&#31867;&#20219;&#21153;&#30340;&#32972;&#26223;&#19979;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#21644;&#39044;&#35757;&#32451;&#30340;&#35821;&#20041;&#21521;&#37327;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#28040;&#34701;&#30740;&#31350;&#24443;&#24213;&#30740;&#31350;&#20102;LLM&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#22522;&#20110;LLM&#30340;&#23884;&#20837;&#19982;&#36890;&#29992;&#30340;&#39044;&#35757;&#32451;&#23884;&#20837;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;&#20511;&#37492;&#36825;&#19968;&#28040;&#34701;&#30740;&#31350;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#23545;&#31454;&#20105;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#65292;&#20174;&#32780;&#31361;&#20986;&#20102;&#26368;&#26032;&#30340;&#34920;&#29616;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12151v1 Announce Type: new  Abstract: Domain-specific knowledge can significantly contribute to addressing a wide variety of vision tasks. However, the generation of such knowledge entails considerable human labor and time costs. This study investigates the potential of Large Language Models (LLMs) in generating and providing domain-specific information through semantic embeddings. To achieve this, an LLM is integrated into a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors in the context of the Vision-based Zero-shot Object State Classification task. We thoroughly examine the behavior of the LLM through an extensive ablation study. Our findings reveal that the integration of LLM-based embeddings, in combination with general-purpose pre-trained embeddings, leads to substantial performance improvements. Drawing insights from this ablation study, we conduct a comparative analysis against competing models, thereby highlighting the state-of-the-art perfor
&lt;/p&gt;</description></item><item><title>&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#26469;&#22312;&#35745;&#31639;&#39044;&#31639;&#20869;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;MeRino&#27169;&#22411;&#65292;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23637;&#29616;&#20986;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#31454;&#20105;&#24615;&#33021;&#30340;&#29305;&#28857;</title><link>https://arxiv.org/abs/2403.07921</link><description>&lt;p&gt;
Merino&#65306;&#22522;&#20110;&#29109;&#39537;&#21160;&#30340;IoT&#35774;&#22791;&#19978;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Merino: Entropy-driven Design for Generative Language Models on IoT Devices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07921
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#26469;&#22312;&#35745;&#31639;&#39044;&#31639;&#20869;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;MeRino&#27169;&#22411;&#65292;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23637;&#29616;&#20986;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#31454;&#20105;&#24615;&#33021;&#30340;&#29305;&#28857;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#20154;&#24037;&#26234;&#33021;&#29616;&#20195;&#26102;&#20195;&#30340;&#38761;&#21629;&#24615;&#36827;&#27493;&#65292;&#28982;&#32780;&#65292;&#30452;&#25509;&#37096;&#32626;LLMs&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#30828;&#20214;&#19978;&#65292;&#27604;&#22914;&#29289;&#32852;&#32593;&#65288;IoT&#65289;&#35774;&#22791;&#65292;&#30001;&#20110;&#20854;&#39640;&#35745;&#31639;&#25104;&#26412;&#32780;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35774;&#35745;&#33539;&#24335;&#26159;&#22312;&#32473;&#23450;&#30340;&#35745;&#31639;&#39044;&#31639;&#20869;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#12290;&#25972;&#20010;&#35774;&#35745;&#36807;&#31243;&#28041;&#21450;&#35299;&#20915;&#19968;&#20010;&#25968;&#23398;&#35268;&#21010;&#65288;MP&#65289;&#38382;&#39064;&#65292;&#21487;&#20197;&#22312;&#20960;&#20998;&#38047;&#20869;&#22312;CPU&#19978;&#23436;&#25104;&#65292;&#20351;&#20854;&#20960;&#20046;&#26159;&#38646;&#25104;&#26412;&#30340;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#35774;&#35745;&#30340;&#27169;&#22411;MeRino&#65292;&#22312;&#20061;&#20010;NLP&#19979;&#28216;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23545;&#25239;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#30340;&#31454;&#20105;&#24615;&#34920;&#29616;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;MeRino&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#33719;&#24471;&#20102;&#31867;&#20284;&#25110;&#26356;&#22909;&#30340;&#38646;&#24615;&#33021;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07921v1 Announce Type: cross  Abstract: Generative Large Language Models (LLMs) stand as a revolutionary advancement in the modern era of artificial intelligence (AI). However, directly deploying LLMs in resource-constrained hardware, such as Internet-of-Things (IoT) devices, is difficult due to their high computational cost. In this paper, we propose a novel information-entropy framework for designing mobile-friendly generative language models. Our key design paradigm is to maximize the entropy of transformer decoders within the given computational budgets. The whole design procedure involves solving a mathematical programming (MP) problem, which can be done on the CPU within minutes, making it nearly zero-cost. We evaluate our designed models, termed MeRino, across nine NLP downstream tasks, showing their competitive performance against the state-of-the-art autoregressive transformer models under the mobile setting. Notably, MeRino achieves similar or better zero performan
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#25239;&#24615;&#35757;&#32451;&#26469;&#25913;&#36827;DRL&#23545;&#26465;&#20214;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#65292;&#30740;&#31350;&#32773;&#31995;&#32479;&#20998;&#26512;&#20102;&#24403;&#20195;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#35814;&#32454;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.00420</link><description>&lt;p&gt;
&#32463;&#30001;&#23545;&#25239;&#25915;&#20987;&#21644;&#35757;&#32451;&#30340;&#31283;&#20581;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00420
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#25239;&#24615;&#35757;&#32451;&#26469;&#25913;&#36827;DRL&#23545;&#26465;&#20214;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#65292;&#30740;&#31350;&#32773;&#31995;&#32479;&#20998;&#26512;&#20102;&#24403;&#20195;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#35814;&#32454;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#26159;&#19968;&#31181;&#35757;&#32451;&#33258;&#20027;&#20195;&#29702;&#22312;&#21508;&#31181;&#22797;&#26434;&#29615;&#22659;&#20013;&#30340;&#26041;&#27861;&#12290;&#23613;&#31649;&#22312;&#20247;&#25152;&#21608;&#30693;&#30340;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#36731;&#24494;&#26465;&#20214;&#21464;&#21270;&#30340;&#24433;&#21709;&#65292;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#20854;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#21487;&#38752;&#24615;&#30340;&#25285;&#24551;&#12290;&#20026;&#20102;&#25552;&#39640;&#21487;&#29992;&#24615;&#65292;DRL&#24517;&#39035;&#23637;&#31034;&#20986;&#21487;&#20449;&#24230;&#21644;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#23545;&#25239;&#24615;&#35757;&#32451;&#25552;&#39640;DRL&#23545;&#26465;&#20214;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#26159;&#19968;&#31181;&#25913;&#36827;&#26041;&#24335;&#65292;&#36890;&#36807;&#35757;&#32451;&#20195;&#29702;&#38024;&#23545;&#29615;&#22659;&#21160;&#24577;&#30340;&#36866;&#24403;&#23545;&#25239;&#24615;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#33268;&#21147;&#20110;&#35299;&#20915;&#36825;&#19968;&#20851;&#38190;&#38382;&#39064;&#65292;&#23545;&#24403;&#20195;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#31995;&#32479;&#22320;&#23545;&#20854;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#27604;&#36739;&#23427;&#20204;&#30340;&#30446;&#26631;&#21644;&#25805;&#20316;&#26426;&#21046;&#12290;&#36825;&#31181;&#20998;&#31867;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#23545;&#25239;&#24615;&#25915;&#20987;&#22914;&#20309;&#26377;&#25928;&#35780;&#20272;DRL&#20195;&#29702;&#30340;&#24674;&#22797;&#21147;&#30340;&#35814;&#32454;&#35265;&#35299;&#65292;&#20174;&#32780;&#20026;&#24320;&#36767;DRL&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#36947;&#36335;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00420v1 Announce Type: cross  Abstract: Deep Reinforcement Learning (DRL) is an approach for training autonomous agents across various complex environments. Despite its significant performance in well known environments, it remains susceptible to minor conditions variations, raising concerns about its reliability in real-world applications. To improve usability, DRL must demonstrate trustworthiness and robustness. A way to improve robustness of DRL to unknown changes in the conditions is through Adversarial Training, by training the agent against well suited adversarial attacks on the dynamics of the environment. Addressing this critical issue, our work presents an in-depth analysis of contemporary adversarial attack methodologies, systematically categorizing them and comparing their objectives and operational mechanisms. This classification offers a detailed insight into how adversarial attacks effectively act for evaluating the resilience of DRL agents, thereby paving the 
&lt;/p&gt;</description></item><item><title>Rainbow Teaming&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#25918;&#24335;&#25628;&#32034;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#23545;&#25239;&#24615;&#25552;&#31034;&#65292;&#21487;&#20197;&#24110;&#21161;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#65292;&#25552;&#39640;&#23433;&#20840;&#24615;&#65292;&#38382;&#31572;&#21644;&#32593;&#32476;&#23433;&#20840;&#31561;&#39046;&#22495;&#30340;&#27169;&#22411;&#28431;&#27934;&#12290;</title><link>https://arxiv.org/abs/2402.16822</link><description>&lt;p&gt;
&#24425;&#34425;&#22242;&#38431;&#65306;&#22810;&#26679;&#21270;&#23545;&#25239;&#24615;&#25552;&#31034;&#30340;&#24320;&#25918;&#24335;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16822
&lt;/p&gt;
&lt;p&gt;
Rainbow Teaming&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#25918;&#24335;&#25628;&#32034;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#23545;&#25239;&#24615;&#25552;&#31034;&#65292;&#21487;&#20197;&#24110;&#21161;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#65292;&#25552;&#39640;&#23433;&#20840;&#24615;&#65292;&#38382;&#31572;&#21644;&#32593;&#32476;&#23433;&#20840;&#31561;&#39046;&#22495;&#30340;&#27169;&#22411;&#28431;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#26222;&#36941;&#65292;&#29702;&#35299;&#21644;&#22686;&#24378;&#23427;&#20204;&#23545;&#29992;&#25143;&#36755;&#20837;&#30340;&#31283;&#20581;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#29992;&#20110;&#35782;&#21035;&#25932;&#23545;&#25552;&#31034;&#30340;&#26041;&#27861;&#24448;&#24448;&#19987;&#27880;&#20110;&#29305;&#23450;&#39046;&#22495;&#65292;&#32570;&#20047;&#22810;&#26679;&#24615;&#65292;&#25110;&#38656;&#35201;&#22823;&#37327;&#20154;&#24037;&#27880;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24425;&#34425;&#22242;&#38431;&#65292;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#22810;&#26679;&#21270;&#23545;&#25239;&#24615;&#25552;&#31034;&#30340;&#26032;&#26041;&#27861;&#12290;&#24425;&#34425;&#22242;&#38431;&#23558;&#23545;&#25239;&#24615;&#25552;&#31034;&#29983;&#25104;&#35270;&#20026;&#19968;&#20010;&#36136;&#37327; - &#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#24320;&#25918;&#24335;&#25628;&#32034;&#26469;&#29983;&#25104;&#26082;&#26377;&#25928;&#21448;&#22810;&#26679;&#30340;&#25552;&#31034;&#12290;&#23427;&#21487;&#20197;&#25581;&#31034;&#27169;&#22411;&#22312;&#24191;&#27867;&#39046;&#22495;&#20869;&#30340;&#33030;&#24369;&#24615;&#65292;&#21253;&#25324;&#26412;&#25991;&#20013;&#30340;&#23433;&#20840;&#24615;&#12289;&#38382;&#31572;&#21644;&#32593;&#32476;&#23433;&#20840;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#23545;&#30001;&#24425;&#34425;&#22242;&#38431;&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#21487;&#20197;&#25552;&#39640;&#26368;&#20808;&#36827;&#30340;LLMs&#30340;&#23433;&#20840;&#24615;&#65292;&#32780;&#19981;&#25439;&#23475;&#23427;&#20204;&#30340;&#19968;&#33324;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16822v1 Announce Type: new  Abstract: As large language models (LLMs) become increasingly prevalent across many real-world applications, understanding and enhancing their robustness to user inputs is of paramount importance. Existing methods for identifying adversarial prompts tend to focus on specific domains, lack diversity, or require extensive human annotations. To address these limitations, we present Rainbow Teaming, a novel approach for producing a diverse collection of adversarial prompts. Rainbow Teaming casts adversarial prompt generation as a quality-diversity problem, and uses open-ended search to generate prompts that are both effective and diverse. It can uncover a model's vulnerabilities across a broad range of domains including, in this paper, safety, question answering, and cybersecurity. We also demonstrate that fine-tuning on synthetic data generated by Rainbow Teaming improves the safety of state-of-the-art LLMs without hurting their general capabilities 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#22312;&#32447;&#20984;&#20248;&#21270;&#65292;&#24320;&#21457;&#20102;&#26032;&#30340;&#31639;&#27861;&#26469;&#20998;&#21035;&#38477;&#20302;&#20984;&#20989;&#25968;&#21644;&#24378;&#20984;&#20989;&#25968;&#30340;&#21518;&#24724;&#36793;&#30028;&#65292;&#24182;&#22635;&#34917;&#20102;&#29616;&#26377;&#19979;&#30028;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2402.09173</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#24335;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#36817;&#20284;&#26368;&#20248;&#21518;&#24724;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Nearly Optimal Regret for Decentralized Online Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#22312;&#32447;&#20984;&#20248;&#21270;&#65292;&#24320;&#21457;&#20102;&#26032;&#30340;&#31639;&#27861;&#26469;&#20998;&#21035;&#38477;&#20302;&#20984;&#20989;&#25968;&#21644;&#24378;&#20984;&#20989;&#25968;&#30340;&#21518;&#24724;&#36793;&#30028;&#65292;&#24182;&#22635;&#34917;&#20102;&#29616;&#26377;&#19979;&#30028;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#22312;&#32447;&#20984;&#20248;&#21270;(D-OCO)&#65292;&#20854;&#20013;&#19968;&#32452;&#26412;&#22320;&#23398;&#20064;&#22120;&#38656;&#35201;&#20351;&#29992;&#20165;&#38480;&#20110;&#26412;&#22320;&#35745;&#31639;&#21644;&#36890;&#20449;&#30340;&#26041;&#27861;&#26469;&#26368;&#23567;&#21270;&#19968;&#31995;&#21015;&#20840;&#23616;&#25439;&#22833;&#20989;&#25968;&#12290;&#20197;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#30830;&#23450;&#20102;&#38024;&#23545;&#20984;&#20989;&#25968;&#21644;&#24378;&#20984;&#20989;&#25968;&#30340;&#21518;&#24724;&#30028;&#38480;&#20998;&#21035;&#20026;$O(n^{5/4}\rho^{-1/2}\sqrt{T})$&#21644;${O}(n^{3/2}\rho^{-1}\log T)$&#65292;&#20854;&#20013;$n$&#26159;&#26412;&#22320;&#23398;&#20064;&#22120;&#30340;&#25968;&#37327;&#65292;$\rho&lt;1$&#26159;&#36890;&#20449;&#30697;&#38453;&#30340;&#35889;&#38388;&#38553;&#65292;$T$&#26159;&#26102;&#38388;&#27573;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20984;&#20989;&#25968;&#23384;&#22312;&#30528;&#36739;&#22823;&#30340;&#38388;&#38553;&#65292;&#21363;&#20984;&#20989;&#25968;&#30340;&#19979;&#30028;&#20026;$\Omega(n\sqrt{T})$&#65292;&#24378;&#20984;&#20989;&#25968;&#30340;&#19979;&#30028;&#20026;$\Omega(n)$&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20123;&#38388;&#38553;&#65292;&#26412;&#25991;&#39318;&#20808;&#24320;&#21457;&#20102;&#26032;&#30340;D-OCO&#31639;&#27861;&#65292;&#23558;&#20984;&#20989;&#25968;&#21644;&#24378;&#20984;&#20989;&#25968;&#30340;&#21518;&#24724;&#36793;&#30028;&#20998;&#21035;&#38477;&#20302;&#21040;$\tilde{O}(n\rho^{-1/4}\sqrt{T})$&#21644;$\tilde{O}(n\rho^{-1/2}\log T)$&#12290;&#20027;&#35201;&#25216;&#26415;&#26159;&#35774;&#35745;&#19968;&#31181;&#22312;&#32447;&#21487;&#36827;&#21462;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09173v1 Announce Type: new Abstract: We investigate decentralized online convex optimization (D-OCO), in which a set of local learners are required to minimize a sequence of global loss functions using only local computations and communications. Previous studies have established $O(n^{5/4}\rho^{-1/2}\sqrt{T})$ and ${O}(n^{3/2}\rho^{-1}\log T)$ regret bounds for convex and strongly convex functions respectively, where $n$ is the number of local learners, $\rho&lt;1$ is the spectral gap of the communication matrix, and $T$ is the time horizon. However, there exist large gaps from the existing lower bounds, i.e., $\Omega(n\sqrt{T})$ for convex functions and $\Omega(n)$ for strongly convex functions. To fill these gaps, in this paper, we first develop novel D-OCO algorithms that can respectively reduce the regret bounds for convex and strongly convex functions to $\tilde{O}(n\rho^{-1/4}\sqrt{T})$ and $\tilde{O}(n\rho^{-1/2}\log T)$. The primary technique is to design an online acce
&lt;/p&gt;</description></item><item><title>&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;&#26159;&#20851;&#20110;&#23558;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#36807;&#31243;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23545;&#35937;&#38598;&#19981;&#26029;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#21644;&#32467;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.04436</link><description>&lt;p&gt;
&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;
&lt;/p&gt;
&lt;p&gt;
Continuous Multidimensional Scaling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04436
&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;&#26159;&#20851;&#20110;&#23558;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#36807;&#31243;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23545;&#35937;&#38598;&#19981;&#26029;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#21644;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#32500;&#26631;&#24230;(MDS)&#26159;&#23558;&#20851;&#20110;&#19968;&#32452;$n$&#20010;&#23545;&#35937;&#30340;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#21040;$d$&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#36807;&#31243;&#12290;&#26368;&#21021;&#30001;&#24515;&#29702;&#27979;&#37327;&#23398;&#30028;&#26500;&#24605;&#65292;MDS&#20851;&#27880;&#30340;&#26159;&#23884;&#20837;&#21040;&#19968;&#32452;&#22266;&#23450;&#23545;&#35937;&#19978;&#30340;&#19968;&#32452;&#22266;&#23450;&#36317;&#31163;&#12290;&#29616;&#20195;&#20851;&#27880;&#30340;&#38382;&#39064;&#26356;&#24120;&#28041;&#21450;&#21040;&#30740;&#31350;&#19982;&#19968;&#32452;&#19981;&#26029;&#22686;&#21152;&#30340;&#23545;&#35937;&#30456;&#20851;&#32852;&#30340;&#19968;&#31995;&#21015;&#36317;&#31163;&#30340;&#26497;&#38480;&#34892;&#20026;&#65292;&#22914;&#22312;&#38543;&#26426;&#22270;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#28176;&#36817;&#29702;&#35770;&#20013;&#20986;&#29616;&#30340;&#38382;&#39064;&#12290;&#28857;&#21040;&#38598;&#21512;&#26144;&#23556;&#29702;&#35770;&#20013;&#30340;&#26631;&#20934;&#32467;&#26524;&#34920;&#26126;&#65292;&#33509;$n$&#22266;&#23450;&#65292;&#21017;&#23884;&#20837;&#32467;&#26500;&#30340;&#26497;&#38480;&#26159;&#26497;&#38480;&#36317;&#31163;&#30340;&#23884;&#20837;&#32467;&#26500;&#12290;&#20294;&#22914;&#26524;$n$&#22686;&#21152;&#24590;&#20040;&#21150;&#21602;&#65311;&#37027;&#20040;&#23601;&#38656;&#35201;&#37325;&#26032;&#21046;&#23450;MDS&#65292;&#20197;&#20415;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#26679;&#19968;&#31181;&#37325;&#26032;&#21046;&#23450;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20123;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multidimensional scaling (MDS) is the act of embedding proximity information about a set of $n$ objects in $d$-dimensional Euclidean space. As originally conceived by the psychometric community, MDS was concerned with embedding a fixed set of proximities associated with a fixed set of objects. Modern concerns, e.g., that arise in developing asymptotic theories for statistical inference on random graphs, more typically involve studying the limiting behavior of a sequence of proximities associated with an increasing set of objects. Standard results from the theory of point-to-set maps imply that, if $n$ is fixed, then the limit of the embedded structures is the embedded structure of the limiting proximities. But what if $n$ increases? It then becomes necessary to reformulate MDS so that the entire sequence of embedding problems can be viewed as a sequence of optimization problems in a fixed space. We present such a reformulation and derive some consequences.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CoPreFL&#30340;&#21327;&#20316;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#21487;&#36866;&#24212;&#20219;&#20309;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#26469;&#25552;&#39640;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#26041;&#27861;&#22312;&#25552;&#20379;&#21487;&#38752;&#30340;&#21021;&#22987;&#21270;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02225</link><description>&lt;p&gt;
&#37325;&#24605;&#20986;&#21457;&#28857;&#65306;&#36890;&#36807;&#21327;&#20316;&#39044;&#35757;&#32451;&#22686;&#24378;&#32852;&#37030;&#23398;&#20064;&#30340;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rethinking the Starting Point: Enhancing Performance and Fairness of Federated Learning via Collaborative Pre-Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CoPreFL&#30340;&#21327;&#20316;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#21487;&#36866;&#24212;&#20219;&#20309;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#26469;&#25552;&#39640;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#26041;&#27861;&#22312;&#25552;&#20379;&#21487;&#38752;&#30340;&#21021;&#22987;&#21270;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#20551;&#35774;&#35757;&#32451;&#20174;&#19968;&#20010;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#27169;&#22411;&#24320;&#22987;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#23454;&#35777;&#20102;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#20026;&#32852;&#37030;&#23398;&#20064;&#25552;&#20379;&#26377;&#30410;&#30340;&#21021;&#22987;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#20316;&#39044;&#35757;&#32451;&#26041;&#27861;CoPreFL&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#31574;&#30053;&#24615;&#22320;&#35774;&#35745;&#19968;&#20010;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#20026;&#20219;&#20309;&#19979;&#28216;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#25552;&#20379;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#30340;&#39044;&#35757;&#32451;&#31639;&#27861;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#27169;&#20223;&#19979;&#28216;&#20998;&#24067;&#24335;&#22330;&#26223;&#30340;&#20803;&#23398;&#20064;&#36807;&#31243;&#65292;&#20351;&#20854;&#33021;&#22815;&#36866;&#24212;&#20219;&#20309;&#26410;&#30693;&#30340;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#12290;CoPreFL&#30340;&#39044;&#35757;&#32451;&#20248;&#21270;&#36807;&#31243;&#20063;&#22312;&#24179;&#22343;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#24179;&#34913;&#65292;&#26088;&#22312;&#36890;&#36807;&#26234;&#33021;&#21021;&#22987;&#21270;&#26469;&#35299;&#20915;&#19979;&#28216;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#31454;&#20105;&#25361;&#25112;&#12290;&#22823;&#37327;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#20026;&#20219;&#20309;&#26410;&#30693;&#30340;&#19979;&#28216;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#25552;&#20379;&#20102;&#21487;&#38752;&#30340;&#21021;&#22987;&#21270;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#24179;&#22343;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most existing federated learning (FL) methodologies have assumed training begins from a randomly initialized model. Recently, several studies have empirically demonstrated that leveraging a pre-trained model can offer advantageous initializations for FL. In this paper, we propose a collaborative pre-training approach, CoPreFL, which strategically designs a pre-trained model to serve as a good initialization for any downstream FL task. The key idea of our pre-training algorithm is a meta-learning procedure which mimics downstream distributed scenarios, enabling it to adapt to any unforeseen FL task. CoPreFL's pre-training optimization procedure also strikes a balance between average performance and fairness, with the aim of addressing these competing challenges in downstream FL tasks through intelligent initializations. Extensive experimental results validate that our pre-training method provides a robust initialization for any unseen downstream FL task, resulting in enhanced average pe
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21152;&#26435;&#38598;&#25104;&#27169;&#22411;&#23454;&#29616;&#20102;&#39640;&#20934;&#30830;&#24615;&#30340;&#25345;&#32493;&#23398;&#20064;&#65292;&#20860;&#39038;&#21487;&#22609;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2312.08977</link><description>&lt;p&gt;
&#21152;&#26435;&#38598;&#25104;&#27169;&#22411;&#26159;&#24378;&#22823;&#30340;&#25345;&#32493;&#23398;&#20064;&#32773;
&lt;/p&gt;
&lt;p&gt;
Weighted Ensemble Models Are Strong Continual Learners
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.08977
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21152;&#26435;&#38598;&#25104;&#27169;&#22411;&#23454;&#29616;&#20102;&#39640;&#20934;&#30830;&#24615;&#30340;&#25345;&#32493;&#23398;&#20064;&#65292;&#20860;&#39038;&#21487;&#22609;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#25345;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#30446;&#26631;&#26159;&#20174;&#19968;&#31995;&#21015;&#20219;&#21153;&#20013;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#24471;&#20197;&#21069;&#20219;&#21153;&#30340;&#25968;&#25454;&#22312;&#23398;&#20064;&#24403;&#21069;&#20219;&#21153;&#25968;&#25454;&#26102;&#19981;&#21487;&#29992;&#12290;CL&#26412;&#36136;&#19978;&#26159;&#22312;&#33021;&#22815;&#23398;&#20064;&#26032;&#20219;&#21153;&#65288;&#21363;&#21487;&#22609;&#24615;&#65289;&#21644;&#20445;&#25345;&#20808;&#21069;&#23398;&#20064;&#27010;&#24565;&#30340;&#24615;&#33021;&#65288;&#21363;&#31283;&#23450;&#24615;&#65289;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#30340;&#36807;&#31243;&#12290;&#20026;&#20102;&#35299;&#20915;&#31283;&#23450;&#24615;-&#21487;&#22609;&#24615;&#30340;&#26435;&#34913;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#35758;&#23545;&#20808;&#21069;&#21644;&#24403;&#21069;&#20219;&#21153;&#30340;&#27169;&#22411;&#21442;&#25968;&#36827;&#34892;&#21152;&#26435;&#38598;&#25104;&#12290;&#36825;&#31181;&#21152;&#26435;&#38598;&#25104;&#27169;&#22411;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#25345;&#32493;&#27169;&#22411;&#24179;&#22343;&#65288;&#25110;CoMA&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#22609;&#24615;&#22312;&#24403;&#21069;&#20219;&#21153;&#19978;&#33719;&#24471;&#39640;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#19981;&#20250;&#20559;&#31163;&#22826;&#36828;&#30340;&#20808;&#21069;&#26435;&#37325;&#37197;&#32622;&#65292;&#20174;&#32780;&#30830;&#20445;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;CoMA&#30340;&#25913;&#36827;&#22411;&#21464;&#20307;&#65292;&#21517;&#20026;&#25345;&#32493;&#36153;&#33293;&#23572;&#21152;&#26435;&#27169;&#22411;&#24179;&#22343;&#65288;&#25110;CoFiMA&#65289;&#65292;&#35813;&#27169;&#22411;&#23545;&#27599;&#19968;&#20010;&#21442;&#25968;&#36827;&#34892;&#36873;&#25321;&#24615;&#21152;&#26435;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.08977v2 Announce Type: replace-cross  Abstract: In this work, we study the problem of continual learning (CL) where the goal is to learn a model on a sequence of tasks, such that the data from the previous tasks becomes unavailable while learning on the current task data. CL is essentially a balancing act between being able to learn on the new task (i.e., plasticity) and maintaining the performance on the previously learned concepts (i.e., stability). Intending to address the stability-plasticity trade-off, we propose to perform weight-ensembling of the model parameters of the previous and current tasks. This weighted-ensembled model, which we call Continual Model Averaging (or CoMA), attains high accuracy on the current task by leveraging plasticity, while not deviating too far from the previous weight configuration, ensuring stability. We also propose an improved variant of CoMA, named Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively weighs each para
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#24212;&#29992;&#20110;1D&#24515;&#38899;&#22270;&#26679;&#26412;&#20013;&#24322;&#24120;&#26816;&#27979;&#65292;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#38899;&#39057;&#22686;&#24378;&#26041;&#27861;&#27604;&#36739;&#35780;&#20272;&#21644;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2312.00502</link><description>&lt;p&gt;
&#23545;&#31283;&#20581;&#30340;OOD&#33258;&#30417;&#30563;&#23545;&#27604;&#24515;&#38899;&#22270;&#34920;&#31034;&#23398;&#20064;&#22686;&#24378;&#26041;&#27861;&#30340;&#20840;&#38754;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Evaluation of Augmentations for Robust OOD Self-Supervised Contrastive Phonocardiogram Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.00502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#24212;&#29992;&#20110;1D&#24515;&#38899;&#22270;&#26679;&#26412;&#20013;&#24322;&#24120;&#26816;&#27979;&#65292;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#38899;&#39057;&#22686;&#24378;&#26041;&#27861;&#27604;&#36739;&#35780;&#20272;&#21644;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36817;&#24180;&#26469;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#30740;&#31350;&#27963;&#21160;&#26377;&#25152;&#22686;&#21152;&#65292;&#20294;&#22312;&#21307;&#23398;&#31561;&#22810;&#20010;&#29616;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#65292;&#36825;&#20123;&#27169;&#22411;&#23578;&#26410;&#34987;&#24191;&#27867;&#25509;&#21463;&#12290;&#39640;&#36136;&#37327;&#26631;&#35760;&#25968;&#25454;&#30340;&#30701;&#32570;&#32463;&#24120;&#38459;&#30861;&#20102;&#24320;&#21457;&#31283;&#20581;&#19988;&#20855;&#26377;&#19968;&#33324;&#24615;&#30340;&#27169;&#22411;&#65292;&#24403;&#38754;&#20020;&#26032;&#25910;&#38598;&#30340;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#25968;&#25454;&#38598;&#26102;&#65292;&#36825;&#20123;&#27169;&#22411;&#19981;&#20250;&#22240;&#25928;&#26524;&#19979;&#38477;&#32780;&#21463;&#25439;&#12290;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#20026;&#26631;&#35760;&#25968;&#25454;&#31232;&#32570;&#24615;&#25552;&#20379;&#20102;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#22686;&#21152;&#27169;&#22411;&#30340;&#25928;&#33021;&#21644;&#31283;&#20581;&#24615;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#23545;&#27604;SSL&#24212;&#29992;&#20110;&#26816;&#27979;1D&#24515;&#38899;&#22270;&#65288;PCG&#65289;&#26679;&#26412;&#20013;&#30340;&#24322;&#24120;&#65292;&#36890;&#36807;&#23398;&#20064;&#20449;&#21495;&#30340;&#24191;&#20041;&#34920;&#31034;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#24191;&#27867;&#30340;&#27604;&#36739;&#35780;&#20272;&#65292;&#28041;&#21450;&#22810;&#31181;&#22522;&#20110;&#38899;&#39057;&#30340;&#22686;&#24378;&#26041;&#27861;&#65292;&#35780;&#20272;&#20102;&#22312;&#19981;&#21516;&#19979;&#28216;&#20219;&#21153;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#65292;&#26368;&#32456;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.00502v2 Announce Type: replace  Abstract: Despite the recent increase in research activity, deep-learning models have not yet been widely accepted in several real-world settings, such as medicine. The shortage of high-quality annotated data often hinders the development of robust and generalizable models, which do not suffer from degraded effectiveness when presented with newly-collected, out-of-distribution (OOD) datasets. Contrastive Self-Supervised Learning (SSL) offers a potential solution to labeled data scarcity, as it takes advantage of unlabeled data to increase model effectiveness and robustness. In this research, we propose applying contrastive SSL for detecting abnormalities in 1D phonocardiogram (PCG) samples by learning a generalized representation of the signal. Specifically, we perform an extensive comparative evaluation of a wide range of audio-based augmentations, evaluate trained classifiers on multiple datasets across different downstream tasks, and finall
&lt;/p&gt;</description></item><item><title>&#35757;&#32451;&#21160;&#24577;&#21487;&#22312;&#19981;&#21516;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#26041;&#27861;&#20043;&#38388;&#36827;&#34892;&#36716;&#31227;&#65292;&#36890;&#36807;&#36873;&#23450;&#30340;&#35757;&#32451;&#23454;&#20363;&#24494;&#35843;&#20027;&#27169;&#22411;&#23454;&#29616;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26356;&#39640;&#30340;&#35757;&#32451;&#25928;&#29575;</title><link>https://arxiv.org/abs/2310.06588</link><description>&lt;p&gt;
FTFT:&#36890;&#36807;&#36716;&#31227;&#35757;&#32451;&#21160;&#24577;&#23454;&#29616;&#39640;&#25928;&#19988;&#31283;&#20581;&#30340;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.06588
&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#21160;&#24577;&#21487;&#22312;&#19981;&#21516;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#26041;&#27861;&#20043;&#38388;&#36827;&#34892;&#36716;&#31227;&#65292;&#36890;&#36807;&#36873;&#23450;&#30340;&#35757;&#32451;&#23454;&#20363;&#24494;&#35843;&#20027;&#27169;&#22411;&#23454;&#29616;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26356;&#39640;&#30340;&#35757;&#32451;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#20998;&#24067;&#22806;&#36755;&#20837;&#30340;&#24433;&#21709;&#12290; &#25968;&#25454;&#38598;&#21046;&#22270;&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#21452;&#27169;&#22411;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#39640;&#24494;&#35843;PLMs&#30340;&#40065;&#26834;&#24615;&#12290; &#23427;&#28041;&#21450;&#22312;&#21407;&#22987;&#35757;&#32451;&#38598;&#19978;&#24494;&#35843;&#27169;&#22411;&#65288;&#21363;&#21442;&#32771;&#27169;&#22411;&#65289;&#65292;&#26681;&#25454;&#35757;&#32451;&#21160;&#24577;&#36873;&#25321;&#19968;&#20123;&#37325;&#35201;&#30340;&#35757;&#32451;&#23454;&#20363;&#65292;&#24182;&#20165;&#23545;&#36825;&#20123;&#36873;&#23450;&#30340;&#31034;&#20363;&#20877;&#27425;&#36827;&#34892;&#24494;&#35843;&#65288;&#21363;&#20027;&#27169;&#22411;&#65289;&#12290; &#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#38656;&#35201;&#23545;&#21516;&#19968;&#27169;&#22411;&#36827;&#34892;&#20004;&#27425;&#24494;&#35843;&#65292;&#36825;&#23545;&#20110;&#22823;&#22411;PLMs&#32780;&#35328;&#22312;&#35745;&#31639;&#19978;&#26159;&#26114;&#36149;&#30340;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#65288;1&#65289;&#35757;&#32451;&#21160;&#24577;&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#26041;&#27861;&#20043;&#38388;&#20855;&#26377;&#39640;&#24230;&#21487;&#20256;&#36882;&#24615;&#65292;&#20197;&#21450;&#65288;2&#65289;&#20351;&#29992;&#36825;&#20123;&#36873;&#23450;&#30340;&#35757;&#32451;&#23454;&#20363;&#23545;&#20027;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#21487;&#20197;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#23454;&#29616;&#26356;&#39640;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290; &#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24494;&#35843;&#26041;&#27861;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.06588v2 Announce Type: replace  Abstract: Despite the massive success of fine-tuning Pre-trained Language Models (PLMs), they remain susceptible to out-of-distribution input. Dataset cartography is a simple yet effective dual-model approach that improves the robustness of fine-tuned PLMs. It involves fine-tuning a model on the original training set (i.e. reference model), selecting a subset of important training instances based on the training dynamics, and fine-tuning again only on these selected examples (i.e. main model). However, this approach requires fine-tuning the same model twice, which is computationally expensive for large PLMs. In this paper, we show that (1) training dynamics are highly transferable across model sizes and pre-training methods, and that (2) fine-tuning main models using these selected training instances achieves higher training efficiency than empirical risk minimization (ERM). Building on these observations, we propose a novel fine-tuning approa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21487;&#35299;&#27010;&#29575;&#27169;&#22411;&#31934;&#30830;&#35745;&#31639;&#32422;&#26463;&#21518;&#39564;&#30340;&#26041;&#27861;&#65292;&#28982;&#21518;&#21033;&#29992;&#36825;&#19968;&#20449;&#21495;&#26469;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#21435;&#22122;&#36807;&#31243;&#65292;&#20174;&#32780;&#25913;&#36827;&#22270;&#20687;&#20462;&#22797;&#30340;&#36136;&#37327;&#21644;&#35821;&#20041;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03349</link><description>&lt;p&gt;
&#22270;&#20687;&#20462;&#22797;&#36890;&#36807;&#21487;&#25511;&#25193;&#25955;&#27169;&#22411;&#30340;&#23548;&#33322;
&lt;/p&gt;
&lt;p&gt;
Image Inpainting via Tractable Steering of Diffusion Models. (arXiv:2401.03349v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21487;&#35299;&#27010;&#29575;&#27169;&#22411;&#31934;&#30830;&#35745;&#31639;&#32422;&#26463;&#21518;&#39564;&#30340;&#26041;&#27861;&#65292;&#28982;&#21518;&#21033;&#29992;&#36825;&#19968;&#20449;&#21495;&#26469;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#21435;&#22122;&#36807;&#31243;&#65292;&#20174;&#32780;&#25913;&#36827;&#22270;&#20687;&#20462;&#22797;&#30340;&#36136;&#37327;&#21644;&#35821;&#20041;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#29983;&#25104;&#36924;&#30495;&#22270;&#20687;&#30340;&#24403;&#21069;&#26368;&#20808;&#36827;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26377;&#32422;&#26463;&#30340;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#65292;&#22914;&#20462;&#22797;&#65292;&#25511;&#21046;&#25277;&#26679;&#36807;&#31243;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#23545;&#36825;&#20123;&#32422;&#26463;&#30340;&#31934;&#30830;&#26465;&#20214;&#35774;&#23450;&#26159;&#19981;&#21487;&#35299;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#21487;&#35299;&#30340;&#27010;&#29575;&#27169;&#22411;(TPMs)&#30340;&#33021;&#21147;&#26469;&#31934;&#30830;&#19988;&#26377;&#25928;&#22320;&#35745;&#31639;&#21463;&#32422;&#26463;&#30340;&#21518;&#39564;&#65292;&#24182;&#21033;&#29992;&#35813;&#20449;&#21495;&#26469;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#21435;&#22122;&#36807;&#31243;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26412;&#25991;&#37319;&#29992;&#20102;&#19968;&#31867;&#34920;&#36798;&#21147;&#36739;&#24378;&#30340;TPMs&#65292;&#31216;&#20026;&#27010;&#29575;&#30005;&#36335;(PCs)&#12290;&#22522;&#20110;&#20808;&#21069;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25193;&#22823;&#20102;PCs&#30340;&#35268;&#27169;&#65292;&#24182;&#20351;&#20854;&#33021;&#22815;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#22270;&#20687;&#29983;&#25104;&#36807;&#31243;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#19977;&#20010;&#33258;&#28982;&#22270;&#20687;&#25968;&#25454;&#38598;&#65288;&#21363;CelebA-H&#65289;&#20013;&#25345;&#32493;&#25913;&#36827;&#20462;&#22797;&#22270;&#20687;&#30340;&#25972;&#20307;&#36136;&#37327;&#21644;&#35821;&#20041;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are the current state of the art for generating photorealistic images. Controlling the sampling process for constrained image generation tasks such as inpainting, however, remains challenging since exact conditioning on such constraints is intractable. While existing methods use various techniques to approximate the constrained posterior, this paper proposes to exploit the ability of Tractable Probabilistic Models (TPMs) to exactly and efficiently compute the constrained posterior, and to leverage this signal to steer the denoising process of diffusion models. Specifically, this paper adopts a class of expressive TPMs termed Probabilistic Circuits (PCs). Building upon prior advances, we further scale up PCs and make them capable of guiding the image generation process of diffusion models. Empirical results suggest that our approach can consistently improve the overall quality and semantic coherence of inpainted images across three natural image datasets (i.e., CelebA-H
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27880;&#24847;&#21147;&#21644;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#34920;&#31034;&#23398;&#20064;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#29983;&#25104;&#30340;&#20449;&#21495;&#19982;&#31034;&#20363;&#25968;&#25454;&#38598;&#30340;&#30456;&#20284;&#24615;&#36739;&#39640;&#12290;</title><link>http://arxiv.org/abs/2401.01987</link><description>&lt;p&gt;
&#20351;&#29992;&#27880;&#24847;&#21147;&#21644;&#23545;&#25239;&#35757;&#32451;&#23545;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Representation Learning of Multivariate Time Series using Attention and Adversarial Training. (arXiv:2401.01987v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27880;&#24847;&#21147;&#21644;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#34920;&#31034;&#23398;&#20064;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#29983;&#25104;&#30340;&#20449;&#21495;&#19982;&#31034;&#20363;&#25968;&#25454;&#38598;&#30340;&#30456;&#20284;&#24615;&#36739;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20449;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#26159;&#24320;&#21457;&#20986;&#23545;&#35757;&#32451;&#25968;&#25454;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#34920;&#31034;&#26041;&#27861;&#12290;&#21482;&#26377;&#22312;&#27492;&#20445;&#35777;&#19979;&#65292;&#26041;&#27861;&#25165;&#33021;&#21512;&#27861;&#22320;&#20154;&#24037;&#29983;&#25104;&#25968;&#25454;&#65292;&#20363;&#22914;&#65292;&#23545;&#25239;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#25110;&#20026;&#40657;&#30418;&#20915;&#31574;&#31995;&#32479;&#25552;&#20379;&#21453;&#20107;&#23454;&#35299;&#37322;&#12290;&#36817;&#24180;&#26469;&#65292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#22312;&#24418;&#25104;&#31283;&#23450;&#30340;&#34920;&#31034;&#21644;&#29983;&#25104;&#36924;&#30495;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#25104;&#26524;&#12290;&#34429;&#28982;&#35768;&#22810;&#24212;&#29992;&#38598;&#20013;&#20110;&#29983;&#25104;&#22270;&#20687;&#25968;&#25454;&#65292;&#20294;&#22312;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#22810;&#21464;&#37327;&#20449;&#21495;&#26041;&#38754;&#65292;&#20184;&#20986;&#30340;&#21162;&#21147;&#36739;&#23569;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#33258;&#32534;&#30721;&#22120;&#65292;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#26041;&#26696;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#20197;&#29983;&#25104;&#20154;&#24037;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20449;&#21495;&#12290;&#36890;&#36807;t-SNE&#21487;&#35270;&#21270;&#12289;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#65288;DTW&#65289;&#21644;&#29109;&#24471;&#20998;&#23545;&#34920;&#31034;&#36827;&#34892;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#29983;&#25104;&#30340;&#20449;&#21495;&#19982;&#31034;&#20363;&#25968;&#25454;&#38598;&#30340;&#30456;&#20284;&#24615;&#36739;&#39640;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#24120;&#35268;&#30340;&#33258;&#32534;&#30721;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
A critical factor in trustworthy machine learning is to develop robust representations of the training data. Only under this guarantee methods are legitimate to artificially generate data, for example, to counteract imbalanced datasets or provide counterfactual explanations for blackbox decision-making systems. In recent years, Generative Adversarial Networks (GANs) have shown considerable results in forming stable representations and generating realistic data. While many applications focus on generating image data, less effort has been made in generating time series data, especially multivariate signals. In this work, a Transformer-based autoencoder is proposed that is regularized using an adversarial training scheme to generate artificial multivariate time series signals. The representation is evaluated using t-SNE visualizations, Dynamic Time Warping (DTW) and Entropy scores. Our results indicate that the generated signals exhibit higher similarity to an exemplary dataset than using
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65292;&#33021;&#22815;&#36991;&#20813;&#32452;&#21512;&#32467;&#26500;&#30340;&#22797;&#26434;&#24615;&#65292;&#23454;&#29616;&#39640;&#25928;&#32431;&#25506;&#32034;&#65292;&#20174;&#32780;&#20934;&#30830;&#22238;&#31572;&#26597;&#35810;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.19319</link><description>&lt;p&gt;
&#39640;&#25928;&#32431;&#25506;&#32034;&#30340;&#21452;&#21521;&#31639;&#27861;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Dual-Directed Algorithm Design for Efficient Pure Exploration. (arXiv:2310.19319v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19319
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65292;&#33021;&#22815;&#36991;&#20813;&#32452;&#21512;&#32467;&#26500;&#30340;&#22797;&#26434;&#24615;&#65292;&#23454;&#29616;&#39640;&#25928;&#32431;&#25506;&#32034;&#65292;&#20174;&#32780;&#20934;&#30830;&#22238;&#31572;&#26597;&#35810;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#26377;&#38480;&#30340;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#38543;&#26426;&#39034;&#24207;&#33258;&#36866;&#24212;&#23454;&#39564;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#20915;&#31574;&#32773;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#26368;&#23567;&#30340;&#27979;&#37327;&#24037;&#20316;&#20197;&#39640;&#32622;&#20449;&#24230;&#20934;&#30830;&#22238;&#31572;&#19982;&#22791;&#36873;&#26041;&#26696;&#30456;&#20851;&#30340;&#26597;&#35810;&#38382;&#39064;&#12290;&#19968;&#20010;&#20856;&#22411;&#30340;&#26597;&#35810;&#38382;&#39064;&#26159;&#30830;&#23450;&#34920;&#29616;&#26368;&#20339;&#30340;&#22791;&#36873;&#26041;&#26696;&#65292;&#36825;&#22312;&#25490;&#21517;&#21644;&#36873;&#25321;&#38382;&#39064;&#20197;&#21450;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#31216;&#20026;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#22266;&#23450;&#31934;&#24230;&#30340;&#35774;&#23450;&#65292;&#24182;&#23548;&#20986;&#20102;&#19968;&#20010;&#19982;&#26679;&#26412;&#26368;&#20248;&#20998;&#37197;&#26377;&#24378;&#25910;&#25947;&#24615;&#27010;&#24565;&#30456;&#20851;&#30340;&#20248;&#21270;&#26465;&#20214;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25105;&#20204;&#21051;&#30011;&#20102;&#19968;&#20010;&#20998;&#37197;&#26159;&#21542;&#26368;&#20248;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#23545;&#20598;&#21464;&#37327;&#30340;&#20351;&#29992;&#20351;&#25105;&#20204;&#33021;&#22815;&#32469;&#36807;&#23436;&#20840;&#20381;&#36182;&#20110;&#21407;&#22987;&#21464;&#37327;&#30340;&#26368;&#20248;&#26465;&#20214;&#30340;&#32452;&#21512;&#32467;&#26500;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#26368;&#20248;&#26465;&#20214;&#20351;&#24471;&#21452;&#21521;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#30340;&#25193;&#23637;&#25104;&#20026;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider pure-exploration problems in the context of stochastic sequential adaptive experiments with a finite set of alternative options. The goal of the decision-maker is to accurately answer a query question regarding the alternatives with high confidence with minimal measurement efforts. A typical query question is to identify the alternative with the best performance, leading to ranking and selection problems, or best-arm identification in the machine learning literature. We focus on the fixed-precision setting and derive a sufficient condition for optimality in terms of a notion of strong convergence to the optimal allocation of samples. Using dual variables, we characterize the necessary and sufficient conditions for an allocation to be optimal. The use of dual variables allow us to bypass the combinatorial structure of the optimality conditions that relies solely on primal variables. Remarkably, these optimality conditions enable an extension of top-two algorithm design princ
&lt;/p&gt;</description></item><item><title>&#22810;&#29289;&#29702;&#23398;&#39044;&#35757;&#32451;&#26159;&#19968;&#31181;&#29992;&#20110;&#29289;&#29702;&#20195;&#29702;&#24314;&#27169;&#30340;&#33258;&#22238;&#24402;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#22823;&#22411;&#20195;&#29702;&#27169;&#22411;&#21516;&#26102;&#39044;&#27979;&#22810;&#20010;&#24322;&#26500;&#29289;&#29702;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#23398;&#20064;&#22312;&#19981;&#21516;&#29289;&#29702;&#20219;&#21153;&#20013;&#24191;&#27867;&#36866;&#29992;&#30340;&#29305;&#24449;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#21333;&#20010;MPP&#39044;&#35757;&#32451;&#30340;&#21464;&#25442;&#22120;&#21487;&#20197;&#22312;&#25152;&#26377;&#39044;&#35757;&#32451;&#23376;&#20219;&#21153;&#19978;&#19982;&#25110;&#36229;&#36807;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#20934;&#32467;&#26524;&#65292;&#26080;&#38656;&#24494;&#35843;&#65292;&#24182;&#19988;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#65292;&#24494;&#35843;MPP&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#20174;&#22836;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#23545;&#26032;&#29289;&#29702;&#30340;&#39044;&#27979;&#32467;&#26524;&#26356;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2310.02994</link><description>&lt;p&gt;
&#22810;&#29289;&#29702;&#23398;&#39044;&#35757;&#32451;&#29992;&#20110;&#29289;&#29702;&#20195;&#29702;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Multiple Physics Pretraining for Physical Surrogate Models. (arXiv:2310.02994v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02994
&lt;/p&gt;
&lt;p&gt;
&#22810;&#29289;&#29702;&#23398;&#39044;&#35757;&#32451;&#26159;&#19968;&#31181;&#29992;&#20110;&#29289;&#29702;&#20195;&#29702;&#24314;&#27169;&#30340;&#33258;&#22238;&#24402;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#22823;&#22411;&#20195;&#29702;&#27169;&#22411;&#21516;&#26102;&#39044;&#27979;&#22810;&#20010;&#24322;&#26500;&#29289;&#29702;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#23398;&#20064;&#22312;&#19981;&#21516;&#29289;&#29702;&#20219;&#21153;&#20013;&#24191;&#27867;&#36866;&#29992;&#30340;&#29305;&#24449;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#21333;&#20010;MPP&#39044;&#35757;&#32451;&#30340;&#21464;&#25442;&#22120;&#21487;&#20197;&#22312;&#25152;&#26377;&#39044;&#35757;&#32451;&#23376;&#20219;&#21153;&#19978;&#19982;&#25110;&#36229;&#36807;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#20934;&#32467;&#26524;&#65292;&#26080;&#38656;&#24494;&#35843;&#65292;&#24182;&#19988;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#65292;&#24494;&#35843;MPP&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#20174;&#22836;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#23545;&#26032;&#29289;&#29702;&#30340;&#39044;&#27979;&#32467;&#26524;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#29289;&#29702;&#23398;&#39044;&#35757;&#32451;&#65288;MPP&#65289;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#33258;&#22238;&#24402;&#20219;&#21153;&#19981;&#21487;&#30693;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#29289;&#29702;&#20195;&#29702;&#24314;&#27169;&#12290;MPP&#36890;&#36807;&#35757;&#32451;&#22823;&#22411;&#20195;&#29702;&#27169;&#22411;&#21516;&#26102;&#39044;&#27979;&#22810;&#20010;&#24322;&#26500;&#29289;&#29702;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#23398;&#20064;&#22312;&#19981;&#21516;&#29289;&#29702;&#20219;&#21153;&#20013;&#24191;&#27867;&#36866;&#29992;&#30340;&#29305;&#24449;&#12290;&#20026;&#20102;&#26377;&#25928;&#23398;&#20064;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20849;&#20139;&#23884;&#20837;&#21644;&#24402;&#19968;&#21270;&#31574;&#30053;&#65292;&#23558;&#22810;&#20010;&#31995;&#32479;&#30340;&#23383;&#27573;&#25237;&#24433;&#21040;&#19968;&#20010;&#20849;&#20139;&#23884;&#20837;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#28041;&#21450;&#27969;&#20307;&#21147;&#23398;&#30340;&#24191;&#27867;&#22522;&#20934;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21333;&#20010;MPP&#39044;&#35757;&#32451;&#30340;&#21464;&#25442;&#22120;&#33021;&#22815;&#22312;&#25152;&#26377;&#39044;&#35757;&#32451;&#23376;&#20219;&#21153;&#19978;&#19982;&#25110;&#36229;&#36807;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#20934;&#32467;&#26524;&#65292;&#32780;&#26080;&#38656;&#24494;&#35843;&#12290;&#23545;&#20110;&#19979;&#28216;&#20219;&#21153;&#65292;&#25105;&#20204;&#35777;&#26126;&#24494;&#35843;MPP&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#20174;&#22836;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#22312;&#22810;&#20010;&#26102;&#38388;&#27493;&#39588;&#19978;&#23545;&#26032;&#29289;&#29702;&#30340;&#39044;&#27979;&#32467;&#26524;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce multiple physics pretraining (MPP), an autoregressive task-agnostic pretraining approach for physical surrogate modeling. MPP involves training large surrogate models to predict the dynamics of multiple heterogeneous physical systems simultaneously by learning features that are broadly useful across diverse physical tasks. In order to learn effectively in this setting, we introduce a shared embedding and normalization strategy that projects the fields of multiple systems into a single shared embedding space. We validate the efficacy of our approach on both pretraining and downstream tasks over a broad fluid mechanics-oriented benchmark. We show that a single MPP-pretrained transformer is able to match or outperform task-specific baselines on all pretraining sub-tasks without the need for finetuning. For downstream tasks, we demonstrate that finetuning MPP-trained models results in more accurate predictions across multiple time-steps on new physics compared to training from
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27714;&#35299;&#22120;&#22312;&#27169;&#25311;&#28237;&#27969;&#27969;&#22330;&#26102;&#22914;&#20309;&#23454;&#29616;&#26102;&#38388;&#31283;&#23450;&#24615;&#65292;&#24182;&#21457;&#29616;&#22522;&#20110;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#28436;&#21270;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#21487;&#20197;&#36229;&#36234;&#20854;&#20182;&#27969;&#22330;&#39044;&#27979;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.01745</link><description>&lt;p&gt;
&#29992;&#20110;&#28237;&#27969;&#27969;&#22330;&#27169;&#25311;&#30340;&#33258;&#22238;&#24402;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Autoregressive Conditional Diffusion Models for Turbulent Flow Simulation. (arXiv:2309.01745v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01745
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27714;&#35299;&#22120;&#22312;&#27169;&#25311;&#28237;&#27969;&#27969;&#22330;&#26102;&#22914;&#20309;&#23454;&#29616;&#26102;&#38388;&#31283;&#23450;&#24615;&#65292;&#24182;&#21457;&#29616;&#22522;&#20110;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#28436;&#21270;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#21487;&#20197;&#36229;&#36234;&#20854;&#20182;&#27969;&#22330;&#39044;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#25311;&#28237;&#27969;&#27969;&#22330;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27714;&#35299;&#22120;&#26085;&#30410;&#21463;&#21040;&#37325;&#35270;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#23398;&#20064;&#30340;PDE&#27714;&#35299;&#22120;&#26469;&#35828;&#65292;&#22312;&#25512;&#24191;&#21040;&#26356;&#38271;&#30340;&#28436;&#21270;&#26102;&#38388;&#20013;&#23454;&#29616;&#26102;&#38388;&#31283;&#23450;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#25345;&#20037;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#30340;&#27969;&#20307;&#27714;&#35299;&#22120;&#26159;&#21542;&#21033;&#29992;&#22522;&#20110;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#28436;&#21270;&#26159;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#21487;&#34892;&#36873;&#25321;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20934;&#30830;&#24615;&#12289;&#21518;&#39564;&#37319;&#26679;&#12289;&#35889;&#29305;&#24615;&#21644;&#26102;&#38388;&#31283;&#23450;&#24615;&#65292;&#24182;&#35201;&#27714;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#25512;&#24191;&#21040;&#36229;&#20986;&#35757;&#32451;&#33539;&#22260;&#30340;&#27969;&#21160;&#21442;&#25968;&#12290;&#20026;&#20102;&#23450;&#37327;&#21644;&#23450;&#24615;&#22320;&#23545;&#19968;&#31995;&#21015;&#27969;&#22330;&#39044;&#27979;&#26041;&#27861;&#30340;&#24615;&#33021;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19977;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#65292;&#21253;&#25324;&#19981;&#21487;&#21387;&#32553;&#27969;&#21160;&#12289;&#36328;&#38899;&#36895;&#27969;&#21160;&#21644;&#21508;&#21521;&#21516;&#24615;&#28237;&#27969;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21363;&#20351;&#26159;&#31616;&#21333;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;...
&lt;/p&gt;
&lt;p&gt;
Simulating turbulent flows is crucial for a wide range of applications, and machine learning-based solvers are gaining increasing relevance. However, achieving temporal stability when generalizing to longer rollout horizons remains a persistent challenge for learned PDE solvers. In this work, we analyze if fully data-driven fluid solvers that utilize an autoregressive rollout based on conditional diffusion models are a viable option to address this challenge. We investigate accuracy, posterior sampling, spectral behavior, and temporal stability, while requiring that methods generalize to flow parameters beyond the training regime. To quantitatively and qualitatively benchmark the performance of a range of flow prediction approaches, three challenging scenarios including incompressible and transonic flows, as well as isotropic turbulence are employed. We find that even simple diffusion-based approaches can outperform multiple established flow prediction methods in terms of accuracy and 
&lt;/p&gt;</description></item><item><title>Matbench Discovery&#26159;&#19968;&#20010;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#26230;&#20307;&#31283;&#23450;&#24615;&#39044;&#27979;&#30340;&#26694;&#26550;&#65292;&#22312;&#28909;&#21147;&#23398;&#31283;&#23450;&#24615;&#39044;&#27979;&#26041;&#38754;&#30340;&#27979;&#35797;&#20013;&#65292;CHGNet&#34920;&#29616;&#26368;&#20339;&#12290;</title><link>http://arxiv.org/abs/2308.14920</link><description>&lt;p&gt;
Matbench Discovery - &#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#26230;&#20307;&#31283;&#23450;&#24615;&#39044;&#27979;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Matbench Discovery -- An evaluation framework for machine learning crystal stability prediction. (arXiv:2308.14920v1 [cond-mat.mtrl-sci])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14920
&lt;/p&gt;
&lt;p&gt;
Matbench Discovery&#26159;&#19968;&#20010;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#26230;&#20307;&#31283;&#23450;&#24615;&#39044;&#27979;&#30340;&#26694;&#26550;&#65292;&#22312;&#28909;&#21147;&#23398;&#31283;&#23450;&#24615;&#39044;&#27979;&#26041;&#38754;&#30340;&#27979;&#35797;&#20013;&#65292;CHGNet&#34920;&#29616;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Matbench Discovery&#36890;&#36807;&#27169;&#25311;&#26426;&#22120;&#23398;&#20064;&#33021;&#28304;&#27169;&#22411;&#22312;&#39640;&#36890;&#37327;&#25628;&#32034;&#31283;&#23450;&#26080;&#26426;&#26230;&#20307;&#26041;&#38754;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#28909;&#21147;&#23398;&#31283;&#23450;&#24615;&#21644;&#24418;&#25104;&#33021;&#20043;&#38388;&#30340;&#24046;&#24322;&#20197;&#21450;&#22495;&#20869;&#19982;&#22495;&#22806;&#24615;&#33021;&#20043;&#38388;&#30340;&#33073;&#33410;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#24067;&#20102;&#19968;&#20010;Python&#21253;&#65292;&#20197;&#20415;&#20110;&#26410;&#26469;&#27169;&#22411;&#30340;&#25552;&#20132;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#32447;&#25490;&#34892;&#27036;&#65292;&#36827;&#19968;&#27493;&#27934;&#23519;&#21508;&#31181;&#24615;&#33021;&#25351;&#26631;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#36890;&#36807;&#23545;&#28909;&#21147;&#23398;&#31283;&#23450;&#24615;&#39044;&#27979;&#30340;&#27979;&#35797;&#38598;F1&#24471;&#20998;&#36827;&#34892;&#25490;&#21517;&#65292;&#25105;&#20204;&#21457;&#29616;CHGNet &gt; M3GNet &gt; MACE &gt; ALIGNN &gt; MEGNet &gt; CGCNN &gt; CGCNN+P &gt; Wrenformer &gt; BOWSR &gt; Voronoi tessellation fingerprints with random forest&#12290;
&lt;/p&gt;
&lt;p&gt;
Matbench Discovery simulates the deployment of machine learning (ML) energy models in a high-throughput search for stable inorganic crystals. We address the disconnect between (i) thermodynamic stability and formation energy and (ii) in-domain vs out-of-distribution performance. Alongside this paper, we publish a Python package to aid with future model submissions and a growing online leaderboard with further insights into trade-offs between various performance metrics. To answer the question which ML methodology performs best at materials discovery, our initial release explores a variety of models including random forests, graph neural networks (GNN), one-shot predictors, iterative Bayesian optimizers and universal interatomic potentials (UIP). Ranked best-to-worst by their test set F1 score on thermodynamic stability prediction, we find CHGNet &gt; M3GNet &gt; MACE &gt; ALIGNN &gt; MEGNet &gt; CGCNN &gt; CGCNN+P &gt; Wrenformer &gt; BOWSR &gt; Voronoi tessellation fingerprints with random forest. The top 3 mod
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#21453;&#23556;&#33108;&#20013;&#30340;&#22810;&#27425;&#25955;&#23556;&#36890;&#36807;&#34987;&#21160;&#35825;&#23548;&#20809;&#23398;&#38750;&#32447;&#24615;&#26144;&#23556;&#30340;&#35774;&#35745;&#65292;&#23454;&#29616;&#20102;&#20809;&#23398;&#25968;&#25454;&#21387;&#32553;&#21644;&#39640;&#25928;&#22788;&#29702;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.08558</link><description>&lt;p&gt;
&#20855;&#26377;&#34987;&#21160;&#20809;&#23398;&#38750;&#32447;&#24615;&#26144;&#23556;&#30340;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Deep Learning with Passive Optical Nonlinear Mapping. (arXiv:2307.08558v2 [physics.optics] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08558
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#21453;&#23556;&#33108;&#20013;&#30340;&#22810;&#27425;&#25955;&#23556;&#36890;&#36807;&#34987;&#21160;&#35825;&#23548;&#20809;&#23398;&#38750;&#32447;&#24615;&#26144;&#23556;&#30340;&#35774;&#35745;&#65292;&#23454;&#29616;&#20102;&#20809;&#23398;&#25968;&#25454;&#21387;&#32553;&#21644;&#39640;&#25928;&#22788;&#29702;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#24050;&#32463;&#20174;&#26681;&#26412;&#19978;&#25913;&#21464;&#20102;&#20154;&#24037;&#26234;&#33021;&#65292;&#20294;&#26159;&#26085;&#30410;&#22797;&#26434;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#19987;&#38376;&#30340;&#30828;&#20214;&#21152;&#36895;&#22120;&#12290;&#20809;&#23398;&#21152;&#36895;&#22120;&#21487;&#20197;&#25552;&#20379;&#22686;&#24378;&#30340;&#24615;&#33021;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#33021;&#37327;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#23454;&#29616;&#20809;&#23398;&#20013;&#30340;&#38750;&#32447;&#24615;&#26144;&#23556;&#65292;&#36825;&#26159;&#31070;&#32463;&#32593;&#32476;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#35774;&#35745;&#65292;&#21033;&#29992;&#19968;&#20010;&#21453;&#23556;&#33108;&#20013;&#30340;&#22810;&#27425;&#25955;&#23556;&#26469;&#34987;&#21160;&#35825;&#23548;&#20809;&#23398;&#38750;&#32447;&#24615;&#38543;&#26426;&#26144;&#23556;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#28608;&#20809;&#21151;&#29575;&#12290;&#25105;&#20204;&#24037;&#20316;&#30340;&#19968;&#20010;&#37325;&#35201;&#20248;&#21183;&#26159;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#21453;&#23556;&#33108;&#20013;&#30340;&#22810;&#27425;&#25955;&#23556;&#26469;&#36827;&#34892;&#20809;&#23398;&#25968;&#25454;&#21387;&#32553;&#65292;&#20197;&#39640;&#25928;&#22320;&#21387;&#32553;&#21644;&#20445;&#30041;&#37325;&#35201;&#20449;&#24687;&#65292;&#21516;&#26102;&#38477;&#20302;&#25968;&#25454;&#30340;&#32500;&#24230;&#12290;&#36825;&#20351;&#24471;&#24555;&#36895;&#30340;&#20809;&#23398;&#20449;&#24687;&#22788;&#29702;&#21644;&#29983;&#25104;&#39640;&#24230;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#20302;&#32500;&#28151;&#21512;&#25104;&#20998;&#25104;&#20026;&#21487;&#33021;&#12290;&#36825;&#23545;&#20110;&#38656;&#35201;&#39640;&#25928;&#22788;&#29702;&#30340;&#24212;&#29992;&#29305;&#21035;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has fundamentally transformed artificial intelligence, but the ever-increasing complexity in deep learning models calls for specialized hardware accelerators. Optical accelerators can potentially offer enhanced performance, scalability, and energy efficiency. However, achieving nonlinear mapping, a critical component of neural networks, remains challenging optically. Here, we introduce a design that leverages multiple scattering in a reverberating cavity to passively induce optical nonlinear random mapping, without the need for additional laser power. A key advantage emerging from our work is that we show we can perform optical data compression, facilitated by multiple scattering in the cavity, to efficiently compress and retain vital information while also decreasing data dimensionality. This allows rapid optical information processing and generation of low dimensional mixtures of highly nonlinear features. These are particularly useful for applications demanding high-sp
&lt;/p&gt;</description></item><item><title>&#26368;&#22823;&#29109;&#24322;&#36136;&#20195;&#29702;&#38236;&#20687;&#23398;&#20064;(MEHAML)&#26159;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#26368;&#22823;&#29109;&#21407;&#29702;&#35774;&#35745;&#20102;&#26368;&#22823;&#29109;MARL&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#65292;&#20855;&#26377;&#32852;&#21512;&#26368;&#22823;&#29109;&#30446;&#26631;&#30340;&#21333;&#35843;&#25913;&#36827;&#21644;&#25910;&#25947;&#33267;&#20013;&#20301;&#21709;&#24212;&#22343;&#34913;(QRE)&#30340;&#26399;&#26395;&#29305;&#24615;&#65292;&#24182;&#36890;&#36807;&#25193;&#23637;&#24120;&#29992;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;HASAC&#26469;&#39564;&#35777;&#20854;&#23454;&#29992;&#24615;&#21644;&#22312;&#25506;&#32034;&#21644;&#31283;&#20581;&#24615;&#26041;&#38754;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2306.10715</link><description>&lt;p&gt;
&#26368;&#22823;&#29109;&#24322;&#36136;&#20195;&#29702;&#38236;&#20687;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Maximum Entropy Heterogeneous-Agent Mirror Learning. (arXiv:2306.10715v2 [cs.MA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10715
&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#29109;&#24322;&#36136;&#20195;&#29702;&#38236;&#20687;&#23398;&#20064;(MEHAML)&#26159;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#26368;&#22823;&#29109;&#21407;&#29702;&#35774;&#35745;&#20102;&#26368;&#22823;&#29109;MARL&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#65292;&#20855;&#26377;&#32852;&#21512;&#26368;&#22823;&#29109;&#30446;&#26631;&#30340;&#21333;&#35843;&#25913;&#36827;&#21644;&#25910;&#25947;&#33267;&#20013;&#20301;&#21709;&#24212;&#22343;&#34913;(QRE)&#30340;&#26399;&#26395;&#29305;&#24615;&#65292;&#24182;&#36890;&#36807;&#25193;&#23637;&#24120;&#29992;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;HASAC&#26469;&#39564;&#35777;&#20854;&#23454;&#29992;&#24615;&#21644;&#22312;&#25506;&#32034;&#21644;&#31283;&#20581;&#24615;&#26041;&#38754;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;(MARL)&#22312;&#21512;&#20316;&#21338;&#24328;&#20013;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#38754;&#20020;&#26679;&#26412;&#25928;&#29575;&#20302;&#12289;&#36229;&#21442;&#25968;&#33030;&#24369;&#24615;&#21644;&#25910;&#25947;&#20110;&#27425;&#20248;&#32435;&#20160;&#22343;&#34913;&#30340;&#39118;&#38505;&#31561;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#21629;&#21517;&#20026;&#26368;&#22823;&#29109;&#24322;&#36136;&#20195;&#29702;&#38236;&#20687;&#23398;&#20064;(MEHAML)&#65292;&#21033;&#29992;&#26368;&#22823;&#29109;&#21407;&#29702;&#35774;&#35745;&#20102;&#26368;&#22823;&#29109;MARL&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20174;MEHAML&#26694;&#26550;&#23548;&#20986;&#30340;&#31639;&#27861;&#20855;&#26377;&#32852;&#21512;&#26368;&#22823;&#29109;&#30446;&#26631;&#30340;&#21333;&#35843;&#25913;&#36827;&#21644;&#25910;&#25947;&#33267;&#20013;&#20301;&#21709;&#24212;&#22343;&#34913;(QRE)&#30340;&#26399;&#26395;&#29305;&#24615;&#12290;MEHAML&#30340;&#23454;&#29992;&#24615;&#36890;&#36807;&#24320;&#21457;&#24191;&#27867;&#20351;&#29992;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;HASAC&#30340;MEHAML&#25193;&#23637;&#26469;&#23637;&#31034;&#65292;&#22312;&#19977;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22522;&#20934;&#27979;&#35797;&#19978;&#23637;&#31034;&#20986;&#20102;&#25506;&#32034;&#21644;&#31283;&#20581;&#24615;&#30340;&#26174;&#33879;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-agent reinforcement learning (MARL) has been shown effective for cooperative games in recent years. However, existing state-of-the-art methods face challenges related to sample inefficiency, brittleness regarding hyperparameters, and the risk of converging to a suboptimal Nash Equilibrium. To resolve these issues, in this paper, we propose a novel theoretical framework, named Maximum Entropy Heterogeneous-Agent Mirror Learning (MEHAML), that leverages the maximum entropy principle to design maximum entropy MARL actor-critic algorithms. We prove that algorithms derived from the MEHAML framework enjoy the desired properties of the monotonic improvement of the joint maximum entropy objective and the convergence to quantal response equilibrium (QRE). The practicality of MEHAML is demonstrated by developing a MEHAML extension of the widely used RL algorithm, HASAC (for soft actor-critic), which shows significant improvements in exploration and robustness on three challenging benchmark
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29305;&#27931;&#20234;&#27169;&#22411;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#28608;&#27963;&#20248;&#21270;&#20026;&#27169;&#22411;&#21019;&#24314;&#31614;&#21517;&#65292;&#28982;&#21518;&#35757;&#32451;&#20998;&#31867;&#22120;&#26469;&#26816;&#27979;&#29305;&#27931;&#20234;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#22312;&#20004;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.04877</link><description>&lt;p&gt;
&#20351;&#29992;&#28608;&#27963;&#20248;&#21270;&#36827;&#34892;&#29305;&#27931;&#20234;&#27169;&#22411;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Trojan Model Detection Using Activation Optimization. (arXiv:2306.04877v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29305;&#27931;&#20234;&#27169;&#22411;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#28608;&#27963;&#20248;&#21270;&#20026;&#27169;&#22411;&#21019;&#24314;&#31614;&#21517;&#65292;&#28982;&#21518;&#35757;&#32451;&#20998;&#31867;&#22120;&#26469;&#26816;&#27979;&#29305;&#27931;&#20234;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#22312;&#20004;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#25968;&#25454;&#30340;&#19981;&#21487;&#29992;&#24615;&#25110;&#22823;&#35268;&#27169;&#65292;&#20197;&#21450;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39640;&#35745;&#31639;&#21644;&#20154;&#21147;&#25104;&#26412;&#65292;&#36890;&#24120;&#20250;&#22312;&#21487;&#33021;&#30340;&#24773;&#20917;&#19979;&#20381;&#36182;&#20110;&#24320;&#28304;&#39044;&#35757;&#32451;&#27169;&#22411;&#12290;&#20294;&#26159;&#65292;&#20174;&#23433;&#20840;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#20570;&#27861;&#38750;&#24120;&#20196;&#20154;&#25285;&#24551;&#12290;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#33021;&#20250;&#34987;&#24863;&#26579;&#29305;&#27931;&#20234;&#25915;&#20987;&#65292;&#22312;&#36825;&#31181;&#25915;&#20987;&#20013;&#65292;&#25915;&#20987;&#32773;&#23884;&#20837;&#19968;&#20010;&#35302;&#21457;&#22120;&#22312;&#27169;&#22411;&#20013;&#65292;&#20351;&#24471;&#24403;&#35302;&#21457;&#22120;&#23384;&#22312;&#20110;&#36755;&#20837;&#20013;&#26102;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#25511;&#21046;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29305;&#27931;&#20234;&#27169;&#22411;&#26816;&#27979;&#26041;&#27861;&#30340;&#21021;&#27493;&#24037;&#20316;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26681;&#25454;&#28608;&#27963;&#20248;&#21270;&#20026;&#27169;&#22411;&#21019;&#24314;&#31614;&#21517;&#12290;&#28982;&#21518;&#35757;&#32451;&#20998;&#31867;&#22120;&#26469;&#26816;&#27979;&#29305;&#27931;&#20234;&#27169;&#22411;&#24182;&#32473;&#20986;&#20854;&#31614;&#21517;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20004;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to data's unavailability or large size, and the high computational and human labor costs of training machine learning models, it is a common practice to rely on open source pre-trained models whenever possible. However, this practice is worry some from the security perspective. Pre-trained models can be infected with Trojan attacks, in which the attacker embeds a trigger in the model such that the model's behavior can be controlled by the attacker when the trigger is present in the input. In this paper, we present our preliminary work on a novel method for Trojan model detection. Our method creates a signature for a model based on activation optimization. A classifier is then trained to detect a Trojan model given its signature. Our method achieves state of the art performance on two public datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20445;&#25252;&#20010;&#20154;&#25935;&#24863;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#29983;&#25104;&#39640;&#25928;&#20302;&#32500;&#21512;&#25104;&#25968;&#25454;&#30340;&#31639;&#27861;&#65292;&#24182;&#22312;Wasserstein&#36317;&#31163;&#26041;&#38754;&#20855;&#26377;&#25928;&#29992;&#20445;&#35777;&#65307;&#19982;&#26631;&#20934;&#25200;&#21160;&#20998;&#26512;&#19981;&#21516;&#65292;&#20351;&#29992;&#31169;&#26377;&#20027;&#25104;&#20998;&#20998;&#26512;&#36807;&#31243;&#36991;&#20813;&#20102;&#32500;&#24230;&#35781;&#21650;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.17148</link><description>&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#30340;&#24046;&#20998;&#38544;&#31169;&#20302;&#32500;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Differentially private low-dimensional representation of high-dimensional data. (arXiv:2305.17148v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17148
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20445;&#25252;&#20010;&#20154;&#25935;&#24863;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#29983;&#25104;&#39640;&#25928;&#20302;&#32500;&#21512;&#25104;&#25968;&#25454;&#30340;&#31639;&#27861;&#65292;&#24182;&#22312;Wasserstein&#36317;&#31163;&#26041;&#38754;&#20855;&#26377;&#25928;&#29992;&#20445;&#35777;&#65307;&#19982;&#26631;&#20934;&#25200;&#21160;&#20998;&#26512;&#19981;&#21516;&#65292;&#20351;&#29992;&#31169;&#26377;&#20027;&#25104;&#20998;&#20998;&#26512;&#36807;&#31243;&#36991;&#20813;&#20102;&#32500;&#24230;&#35781;&#21650;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26426;&#21046;&#65292;&#21487;&#20197;&#22312;&#20445;&#25252;&#20010;&#20154;&#25935;&#24863;&#20449;&#24687;&#30340;&#21516;&#26102;&#36827;&#34892;&#25968;&#25454;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#22788;&#20110;&#39640;&#32500;&#31354;&#38388;&#20013;&#26102;&#65292;&#21512;&#25104;&#25968;&#25454;&#30340;&#20934;&#30830;&#24615;&#20250;&#21463;&#21040;&#32500;&#24230;&#35781;&#21650;&#30340;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#21487;&#20197;&#20174;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#39640;&#25928;&#22320;&#29983;&#25104;&#20302;&#32500;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#22312;Wasserstein&#36317;&#31163;&#26041;&#38754;&#20855;&#26377;&#25928;&#29992;&#20445;&#35777;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#27493;&#39588;&#26159;&#20351;&#29992;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#31934;&#24230;&#30028;&#38480;&#30340;&#31169;&#26377;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#36807;&#31243;&#65292;&#20174;&#32780;&#35268;&#36991;&#20102;&#32500;&#24230;&#35781;&#21650;&#30340;&#24433;&#21709;&#12290;&#19982;&#20351;&#29992;Davis-Kahan&#23450;&#29702;&#36827;&#34892;&#26631;&#20934;&#25200;&#21160;&#20998;&#26512;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31169;&#26377;PCA&#20998;&#26512;&#19981;&#38656;&#35201;&#20551;&#35774;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#35889;&#38388;&#38553;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private synthetic data provide a powerful mechanism to enable data analysis while protecting sensitive information about individuals. However, when the data lie in a high-dimensional space, the accuracy of the synthetic data suffers from the curse of dimensionality. In this paper, we propose a differentially private algorithm to generate low-dimensional synthetic data efficiently from a high-dimensional dataset with a utility guarantee with respect to the Wasserstein distance. A key step of our algorithm is a private principal component analysis (PCA) procedure with a near-optimal accuracy bound that circumvents the curse of dimensionality. Different from the standard perturbation analysis using the Davis-Kahan theorem, our analysis of private PCA works without assuming the spectral gap for the sample covariance matrix.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#33258;&#36866;&#24212;&#23398;&#20064;&#26368;&#20248;&#23450;&#20215;&#21644;&#24191;&#21578;&#31574;&#30053;&#65292;&#36798;&#21040;&#27425;&#32447;&#24615;&#21518;&#24724;&#12290;</title><link>http://arxiv.org/abs/2304.14385</link><description>&lt;p&gt;
&#24102;&#26377;&#36125;&#21494;&#26031;&#35828;&#26381;&#30340;&#21160;&#24577;&#23450;&#20215;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Dynamic Pricing and Learning with Bayesian Persuasion. (arXiv:2304.14385v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14385
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#33258;&#36866;&#24212;&#23398;&#20064;&#26368;&#20248;&#23450;&#20215;&#21644;&#24191;&#21578;&#31574;&#30053;&#65292;&#36798;&#21040;&#27425;&#32447;&#24615;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#21160;&#24577;&#23450;&#20215;&#21644;&#23398;&#20064;&#35774;&#32622;&#65292;&#22312;&#25353;&#39034;&#24207;&#35774;&#32622;&#20135;&#21697;&#20215;&#26684;&#30340;&#21516;&#26102;&#65292;&#21334;&#23478;&#36824;&#39044;&#20808;&#25215;&#35834;&#8220;&#24191;&#21578;&#26041;&#26696;&#8221;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22312;&#27599;&#36718;&#24320;&#22987;&#26102;&#65292;&#21334;&#23478;&#21487;&#20197;&#20915;&#23450;&#25552;&#20379;&#20160;&#20040;&#26679;&#30340;&#20449;&#21495;&#26469;&#21578;&#30693;&#20080;&#23478;&#20135;&#21697;&#23454;&#38469;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#26694;&#26550;&#26469;&#27169;&#25311;&#36825;&#20123;&#20449;&#21495;&#23545;&#20080;&#23478;&#30340;&#35780;&#20272;&#21644;&#36141;&#20080;&#21453;&#24212;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#22312;&#26368;&#22823;&#21270;&#21334;&#26041;&#39044;&#26399;&#25910;&#20837;&#30340;&#21516;&#26102;&#25214;&#21040;&#24191;&#21578;&#26041;&#26696;&#21644;&#23450;&#20215;&#26041;&#26696;&#30340;&#26368;&#20248;&#35774;&#35745;&#38382;&#39064;&#12290;&#22312;&#27809;&#26377;&#20219;&#20309;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#22312;&#32447;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#36807;&#21435;&#30340;&#36141;&#20080;&#21453;&#24212;&#26469;&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#26368;&#20248;&#23450;&#20215;&#21644;&#24191;&#21578;&#31574;&#30053;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#31639;&#27861;&#30340;&#21518;&#24724;&#65292;&#19982;&#26368;&#20248;&#30340;&#21315;&#37324;&#20043;&#22564;&#20215;&#26684;&#21644;&#24191;&#21578;&#35745;&#21010;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#21363;&#20351;&#21334;&#23478;&#27809;&#26377;&#20080;&#23478;&#38656;&#27714;&#20989;&#25968;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#20063;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20339;&#22266;&#23450;&#20215;&#26684;&#21644;&#24191;&#21578;&#26041;&#26696;&#30456;&#20851;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a novel dynamic pricing and learning setting where in addition to setting prices of products in sequential rounds, the seller also ex-ante commits to 'advertising schemes'. That is, in the beginning of each round the seller can decide what kind of signal they will provide to the buyer about the product's quality upon realization. Using the popular Bayesian persuasion framework to model the effect of these signals on the buyers' valuation and purchase responses, we formulate the problem of finding an optimal design of the advertising scheme along with a pricing scheme that maximizes the seller's expected revenue. Without any apriori knowledge of the buyers' demand function, our goal is to design an online algorithm that can use past purchase responses to adaptively learn the optimal pricing and advertising strategy. We study the regret of the algorithm when compared to the optimal clairvoyant price and advertising scheme.  Our main result is a computationally efficient onlin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#27573;&#20223;&#23556;&#20195;&#29702;&#26500;&#24314;&#30340;&#20840;&#23616;&#21644;&#22522;&#20110;&#20559;&#22909;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#35299;&#20915;&#32447;&#24615;&#32422;&#26463;&#30340;&#28151;&#21512;&#21464;&#37327;&#38382;&#39064;&#65292;&#31639;&#27861;&#36890;&#36807;&#20004;&#31181;&#25506;&#32034;&#20989;&#25968;&#21487;&#26377;&#25928;&#25628;&#32034;&#21487;&#34892;&#22495;</title><link>http://arxiv.org/abs/2302.04686</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#27573;&#20223;&#23556;&#20195;&#29702;&#23454;&#29616;&#28151;&#21512;&#21464;&#37327;&#30340;&#20840;&#23616;&#21644;&#20248;&#20808;&#32423;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Global and Preference-based Optimization with Mixed Variables using Piecewise Affine Surrogates. (arXiv:2302.04686v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04686
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#27573;&#20223;&#23556;&#20195;&#29702;&#26500;&#24314;&#30340;&#20840;&#23616;&#21644;&#22522;&#20110;&#20559;&#22909;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#35299;&#20915;&#32447;&#24615;&#32422;&#26463;&#30340;&#28151;&#21512;&#21464;&#37327;&#38382;&#39064;&#65292;&#31639;&#27861;&#36890;&#36807;&#20004;&#31181;&#25506;&#32034;&#20989;&#25968;&#21487;&#26377;&#25928;&#25628;&#32034;&#21487;&#34892;&#22495;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#22797;&#26434;&#38480;&#21046;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#28041;&#21450;&#28151;&#21512;&#21464;&#37327;&#65288;&#21363;&#25968;&#20540;&#21644;&#20998;&#31867;&#24615;&#30340;&#21464;&#37327;&#65289;&#30340;&#20248;&#21270;&#38382;&#39064;&#21487;&#33021;&#38590;&#20197;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#26159;&#22797;&#26434;&#27169;&#25311;&#25110;&#23454;&#39564;&#30340;&#32467;&#26524;&#26102;&#65292;&#35780;&#20272;&#20195;&#20215;&#21487;&#33021;&#24456;&#39640;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20195;&#29702;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#65292;&#22522;&#20110;&#23545;&#21487;&#34892;&#26679;&#26412;&#19978;&#30446;&#26631;&#20989;&#25968;&#30340;&#20998;&#27573;&#20223;&#23556;&#20195;&#29702;&#26500;&#24314;&#26469;&#35299;&#20915;&#32447;&#24615;&#32422;&#26463;&#30340;&#28151;&#21512;&#21464;&#37327;&#38382;&#39064;&#65292;&#21487;&#35299;&#20915;&#20013;&#21040;&#22823;&#35268;&#27169;&#38382;&#39064;&#65288;&#32534;&#30721;&#21518;&#32422;100&#20010;&#21464;&#37327;&#21644;20&#20010;&#32422;&#26463;&#65289;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#31181;&#25506;&#32034;&#20989;&#25968;&#26469;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#27714;&#35299;&#22120;&#26377;&#25928;&#22320;&#25628;&#32034;&#21487;&#34892;&#22495;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#20559;&#22909;&#30340;&#31639;&#27861;&#29256;&#26412;&#65292;&#24403;&#21482;&#33021;&#33719;&#24471;&#26679;&#26412;&#38388;&#30340;&#25104;&#23545;&#27604;&#36739;&#32780;&#26410;&#37327;&#21270;&#24213;&#23618;&#35201;&#26368;&#23567;&#21270;&#30340;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#21487;&#20351;&#29992;&#35813;&#31639;&#27861;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimization problems involving mixed variables, i.e., variables of numerical and categorical nature, can be challenging to solve, especially in the presence of complex constraints. Moreover, when the objective function is the result of a complicated simulation or experiment, it may be expensive to evaluate. This paper proposes a novel surrogate-based global optimization algorithm to solve linearly constrained mixed-variable problems up to medium-large size (around 100 variables after encoding and 20 constraints) based on constructing a piecewise affine surrogate of the objective function over feasible samples. We introduce two types of exploration functions to efficiently search the feasible domain via mixed-integer linear programming solvers. We also provide a preference-based version of the algorithm, which can be used when only pairwise comparisons between samples can be acquired while the underlying objective function to minimize remains unquantified. The two algorithms are tested
&lt;/p&gt;</description></item></channel></rss>