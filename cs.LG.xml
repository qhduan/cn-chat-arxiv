<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19968;&#33324;&#21644;&#29616;&#23454;&#35774;&#32622;&#19979;&#30340;&#31283;&#20581;&#25928;&#29992;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#33021;&#22312;&#27809;&#26377;&#24050;&#30693;&#26368;&#20339;&#31574;&#30053;&#30340;&#24773;&#20917;&#19979;&#32988;&#36807;&#25152;&#26377;&#20854;&#20182;&#21442;&#32771;&#31574;&#30053;</title><link>https://arxiv.org/abs/2403.15243</link><description>&lt;p&gt;
&#36890;&#36807;GAN&#26041;&#27861;&#23454;&#29616;&#31283;&#20581;&#25928;&#29992;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robust Utility Optimization via a GAN Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15243
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19968;&#33324;&#21644;&#29616;&#23454;&#35774;&#32622;&#19979;&#30340;&#31283;&#20581;&#25928;&#29992;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#33021;&#22312;&#27809;&#26377;&#24050;&#30693;&#26368;&#20339;&#31574;&#30053;&#30340;&#24773;&#20917;&#19979;&#32988;&#36807;&#25152;&#26377;&#20854;&#20182;&#21442;&#32771;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31283;&#20581;&#25928;&#29992;&#20248;&#21270;&#20351;&#25237;&#36164;&#32773;&#33021;&#22815;&#20197;&#32467;&#26500;&#21270;&#26041;&#24335;&#22788;&#29702;&#24066;&#22330;&#19981;&#30830;&#23450;&#24615;&#65292;&#26088;&#22312;&#26368;&#22823;&#21270;&#26368;&#22351;&#24773;&#20917;&#30340;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#26041;&#27861;&#65292;&#65288;&#36817;&#20284;&#22320;&#65289;&#35299;&#20915;&#19968;&#33324;&#21644;&#29616;&#23454;&#35774;&#32622;&#19979;&#30340;&#31283;&#20581;&#25928;&#29992;&#20248;&#21270;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#23545;&#25237;&#36164;&#32773;&#21644;&#24066;&#22330;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#22312;&#26497;&#23567;&#26497;&#22823;&#38646;&#21644;&#21338;&#24328;&#20013;&#35757;&#32451;&#23427;&#20204;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#36830;&#32493;&#25928;&#29992;&#20989;&#25968;&#65292;&#24182;&#22312;&#20855;&#26377;&#20132;&#26131;&#25104;&#26412;&#30340;&#29616;&#23454;&#24066;&#22330;&#35774;&#32622;&#20013;&#65292;&#21482;&#33021;&#20351;&#29992;&#24066;&#22330;&#30340;&#21487;&#35266;&#23519;&#20449;&#24687;&#12290;&#22823;&#37327;&#23454;&#35777;&#30740;&#31350;&#26174;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#22810;&#21151;&#33021;&#24615;&#12290;&#27599;&#24403;&#23384;&#22312;&#26368;&#20339;&#21442;&#32771;&#31574;&#30053;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#37117;&#33021;&#19982;&#20043;&#23218;&#32654;&#65292;&#22312;&#27809;&#26377;&#24050;&#30693;&#26368;&#20339;&#31574;&#30053;&#30340;&#65288;&#35768;&#22810;&#65289;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#32988;&#36807;&#25152;&#26377;&#20854;&#20182;&#21442;&#32771;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21487;&#20197;&#20174;&#30740;&#31350;&#20013;&#24471;&#20986;&#32467;&#35770;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15243v1 Announce Type: cross  Abstract: Robust utility optimization enables an investor to deal with market uncertainty in a structured way, with the goal of maximizing the worst-case outcome. In this work, we propose a generative adversarial network (GAN) approach to (approximately) solve robust utility optimization problems in general and realistic settings. In particular, we model both the investor and the market by neural networks (NN) and train them in a mini-max zero-sum game. This approach is applicable for any continuous utility function and in realistic market settings with trading costs, where only observable information of the market can be used. A large empirical study shows the versatile usability of our method. Whenever an optimal reference strategy is available, our method performs on par with it and in the (many) settings without known optimal strategy, our method outperforms all other reference strategies. Moreover, we can conclude from our study that the tr
&lt;/p&gt;</description></item><item><title>&#24046;&#20998;&#31169;&#26377;&#22810;&#21464;&#37327;&#20013;&#20301;&#25968;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#20445;&#35777;&#20026;&#24120;&#29992;&#28145;&#24230;&#20989;&#25968;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#37325;&#23614;&#20301;&#32622;&#20272;&#35745;&#30340;&#25104;&#26412;&#36229;&#36807;&#20102;&#38544;&#31169;&#20445;&#25252;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2210.06459</link><description>&lt;p&gt;
&#24046;&#20998;&#31169;&#26377;&#22810;&#21464;&#37327;&#20013;&#20301;&#25968;
&lt;/p&gt;
&lt;p&gt;
Differentially private multivariate medians
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.06459
&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#31169;&#26377;&#22810;&#21464;&#37327;&#20013;&#20301;&#25968;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#20445;&#35777;&#20026;&#24120;&#29992;&#28145;&#24230;&#20989;&#25968;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#37325;&#23614;&#20301;&#32622;&#20272;&#35745;&#30340;&#25104;&#26412;&#36229;&#36807;&#20102;&#38544;&#31169;&#20445;&#25252;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#38656;&#35201;&#28385;&#36275;&#20005;&#26684;&#38544;&#31169;&#20445;&#35777;&#30340;&#32479;&#35745;&#24037;&#20855;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#23545;&#27745;&#26579;&#30340;&#40065;&#26834;&#24615;&#19982;&#24046;&#20998;&#38544;&#31169;&#26377;&#20851;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#20351;&#29992;&#22810;&#20803;&#20013;&#20301;&#25968;&#36827;&#34892;&#24046;&#20998;&#31169;&#26377;&#21644;&#40065;&#26834;&#30340;&#22810;&#20803;&#20301;&#32622;&#20272;&#35745;&#23578;&#26410;&#24471;&#21040;&#31995;&#32479;&#30740;&#31350;&#12290;&#25105;&#20204;&#20026;&#24046;&#20998;&#31169;&#26377;&#22810;&#20803;&#28145;&#24230;&#20013;&#20301;&#25968;&#24320;&#21457;&#20102;&#26032;&#39062;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#22522;&#26412;&#19978;&#26159;&#23574;&#38160;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#28085;&#30422;&#20102;&#24120;&#29992;&#30340;&#28145;&#24230;&#20989;&#25968;&#65292;&#22914;&#21322;&#24179;&#38754;&#65288;&#25110;Tukey&#65289;&#28145;&#24230;&#65292;&#31354;&#38388;&#28145;&#24230;&#21644;&#38598;&#25104;&#21452;&#28145;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26607;&#35199;&#36793;&#38469;&#19979;&#65292;&#37325;&#23614;&#20301;&#32622;&#20272;&#35745;&#30340;&#20195;&#20215;&#36229;&#36807;&#20102;&#38544;&#31169;&#30340;&#20195;&#20215;&#12290;&#25105;&#20204;&#22312;&#39640;&#36798;d = 100&#30340;&#32500;&#24230;&#19978;&#20351;&#29992;&#39640;&#26031;&#27745;&#26579;&#27169;&#22411;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#65292;&#24182;&#23558;&#20854;&#19982;&#26368;&#20808;&#36827;&#30340;&#31169;&#26377;&#22343;&#20540;&#20272;&#35745;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#20316;&#20026;&#25105;&#20204;&#30740;&#31350;&#30340;&#19968;&#20010;&#21103;&#20135;&#21697;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.06459v2 Announce Type: replace-cross  Abstract: Statistical tools which satisfy rigorous privacy guarantees are necessary for modern data analysis. It is well-known that robustness against contamination is linked to differential privacy. Despite this fact, using multivariate medians for differentially private and robust multivariate location estimation has not been systematically studied. We develop novel finite-sample performance guarantees for differentially private multivariate depth-based medians, which are essentially sharp. Our results cover commonly used depth functions, such as the halfspace (or Tukey) depth, spatial depth, and the integrated dual depth. We show that under Cauchy marginals, the cost of heavy-tailed location estimation outweighs the cost of privacy. We demonstrate our results numerically using a Gaussian contamination model in dimensions up to d = 100, and compare them to a state-of-the-art private mean estimation algorithm. As a by-product of our inv
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#30340;&#26032;&#22411;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23427;&#20351;&#29992;&#20998;&#27835;&#31574;&#30053;&#23558;&#27880;&#24847;&#21147;&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#20174;O(n^2)&#38477;&#20302;&#21040;O(n log n)&#25110;O(n)&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#20840;&#23616;&#24863;&#30693;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2310.11960</link><description>&lt;p&gt;
&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#65306;&#19968;&#31181;&#29992;&#20110;&#38271;&#24207;&#21015;&#30340;&#20998;&#27835;&#27880;&#24847;&#21147;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for Long Sequences. (arXiv:2310.11960v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11960
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#30340;&#26032;&#22411;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23427;&#20351;&#29992;&#20998;&#27835;&#31574;&#30053;&#23558;&#27880;&#24847;&#21147;&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#20174;O(n^2)&#38477;&#20302;&#21040;O(n log n)&#25110;O(n)&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#20840;&#23616;&#24863;&#30693;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#24050;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#33258;&#27880;&#24847;&#21147;&#23545;&#20110;&#36755;&#20837;&#38271;&#24230;&#30340;&#20108;&#27425;&#22797;&#26434;&#24230;&#38480;&#21046;&#20102;Transformer&#27169;&#22411;&#22312;&#38271;&#24207;&#21015;&#19978;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#65292;&#19968;&#31181;&#20351;&#29992;&#20998;&#27835;&#31574;&#30053;&#26469;&#20943;&#23569;&#27880;&#24847;&#21147;&#26102;&#38388;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#30340;&#26032;&#22411;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23558;&#38271;&#24230;&#20026;n&#30340;&#24207;&#21015;&#30340;&#27880;&#24847;&#21147;&#22797;&#26434;&#24230;&#20174;O(n^2)&#38477;&#20302;&#21040;O(n log n)&#25110;O(n)&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#20840;&#23616;&#24863;&#30693;&#33539;&#22260;&#12290;&#36825;&#31181;&#20998;&#23618;&#26041;&#27861;&#23558;&#26597;&#35810;&#12289;&#38190;&#21644;&#20540;&#20998;&#20026;O(log n)&#32423;&#30340;&#20998;&#36776;&#29575;&#65292;&#36739;&#36828;&#36317;&#31163;&#30340;&#32452;&#32676;&#36234;&#26469;&#36234;&#22823;&#65292;&#24182;&#23398;&#20064;&#35745;&#31639;&#32452;&#32676;&#25968;&#37327;&#30340;&#26435;&#37325;&#12290;&#22240;&#27492;&#65292;&#20197;&#39640;&#25928;&#20998;&#23618;&#30340;&#26041;&#24335;&#22312;&#36739;&#20302;&#30340;&#20998;&#36776;&#29575;&#20013;&#32771;&#34385;&#36828;&#31163;&#24444;&#27492;&#30340;&#26631;&#35760;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#24555;&#36895;&#22810;&#26497;&#21270;&#27880;&#24847;&#21147;&#30340;&#24635;&#20307;&#22797;&#26434;&#24230;&#20026;O(n)&#25110;O(n log n)&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer-based models have achieved state-of-the-art performance in many areas. However, the quadratic complexity of self-attention with respect to the input length hinders the applicability of Transformer-based models to long sequences. To address this, we present Fast Multipole Attention, a new attention mechanism that uses a divide-and-conquer strategy to reduce the time and memory complexity of attention for sequences of length $n$ from $\mathcal{O}(n^2)$ to $\mathcal{O}(n \log n)$ or $O(n)$, while retaining a global receptive field. The hierarchical approach groups queries, keys, and values into $\mathcal{O}( \log n)$ levels of resolution, where groups at greater distances are increasingly larger in size and the weights to compute group quantities are learned. As such, the interaction between tokens far from each other is considered in lower resolution in an efficient hierarchical manner. The overall complexity of Fast Multipole Attention is $\mathcal{O}(n)$ or $\mathcal{O}(n \
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#24322;&#26500;&#26377;&#21521;&#36229;&#22270;&#34920;&#31034;AST&#65292;&#24182;&#20351;&#29992;&#24322;&#26500;&#26377;&#21521;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#22270;&#24418;&#36827;&#34892;&#20195;&#30721;&#20998;&#31867;&#65292;&#36229;&#36807;&#20102;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.04228</link><description>&lt;p&gt;
&#22522;&#20110;&#25277;&#35937;&#35821;&#27861;&#26641;&#30340;&#24322;&#26500;&#26377;&#21521;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#20195;&#30721;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous Directed Hypergraph Neural Network over abstract syntax tree (AST) for Code Classification. (arXiv:2305.04228v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04228
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#24322;&#26500;&#26377;&#21521;&#36229;&#22270;&#34920;&#31034;AST&#65292;&#24182;&#20351;&#29992;&#24322;&#26500;&#26377;&#21521;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#22270;&#24418;&#36827;&#34892;&#20195;&#30721;&#20998;&#31867;&#65292;&#36229;&#36807;&#20102;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#30721;&#20998;&#31867;&#26159;&#31243;&#24207;&#29702;&#35299;&#21644;&#33258;&#21160;&#32534;&#30721;&#20013;&#30340;&#19968;&#20010;&#38590;&#39064;&#12290;&#30001;&#20110;&#31243;&#24207;&#30340;&#27169;&#31946;&#35821;&#27861;&#21644;&#22797;&#26434;&#35821;&#20041;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#20351;&#29992;&#22522;&#20110;&#25277;&#35937;&#35821;&#27861;&#26641;&#65288;AST&#65289;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#25216;&#26415;&#21019;&#24314;&#20195;&#30721;&#34920;&#31034;&#29992;&#20110;&#20195;&#30721;&#20998;&#31867;&#12290;&#36825;&#20123;&#25216;&#26415;&#21033;&#29992;&#20195;&#30721;&#30340;&#32467;&#26500;&#21644;&#35821;&#20041;&#20449;&#24687;&#65292;&#20294;&#21482;&#32771;&#34385;&#33410;&#28857;&#20043;&#38388;&#30340;&#25104;&#23545;&#20851;&#31995;&#65292;&#24573;&#30053;&#20102;AST&#20013;&#33410;&#28857;&#20043;&#38388;&#24050;&#32463;&#23384;&#22312;&#30340;&#39640;&#38454;&#30456;&#20851;&#24615;&#65292;&#21487;&#33021;&#23548;&#33268;&#20195;&#30721;&#32467;&#26500;&#20449;&#24687;&#30340;&#20002;&#22833;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#24322;&#26500;&#26377;&#21521;&#36229;&#22270;&#65288;HDHG&#65289;&#34920;&#31034;AST&#65292;&#24182;&#20351;&#29992;&#24322;&#26500;&#26377;&#21521;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;HDHGN&#65289;&#22788;&#29702;&#22270;&#24418;&#12290;HDHG&#20445;&#30041;&#20102;&#33410;&#28857;&#20043;&#38388;&#30340;&#39640;&#38454;&#30456;&#20851;&#24615;&#65292;&#24182;&#26356;&#20840;&#38754;&#22320;&#32534;&#30721;&#20102;AST&#30340;&#35821;&#20041;&#21644;&#32467;&#26500;&#20449;&#24687;&#12290;HDHGN&#36890;&#36807;&#32858;&#21512;&#19981;&#21516;&#33410;&#28857;&#30340;&#29305;&#24449;&#24182;&#20351;&#29992;&#19981;&#21516;&#30340;&#20989;&#25968;&#23545;&#20854;&#36827;&#34892;&#22788;&#29702;&#26469;&#23545;AST&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#22235;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;HDHG&#21644;HDHGN&#22312;&#20195;&#30721;&#20998;&#31867;&#20219;&#21153;&#20013;&#36229;&#36234;&#20102;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Code classification is a difficult issue in program understanding and automatic coding. Due to the elusive syntax and complicated semantics in programs, most existing studies use techniques based on abstract syntax tree (AST) and graph neural network (GNN) to create code representations for code classification. These techniques utilize the structure and semantic information of the code, but they only take into account pairwise associations and neglect the high-order correlations that already exist between nodes in the AST, which may result in the loss of code structural information. On the other hand, while a general hypergraph can encode high-order data correlations, it is homogeneous and undirected which will result in a lack of semantic and structural information such as node types, edge types, and directions between child nodes and parent nodes when modeling AST. In this study, we propose to represent AST as a heterogeneous directed hypergraph (HDHG) and process the graph by hetero
&lt;/p&gt;</description></item></channel></rss>