<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#21487;&#24494;&#30340;&#25289;&#26684;&#26391;&#26085;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#29289;&#29702;&#20449;&#24687;&#19982;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#22312;&#38477;&#27700;&#39044;&#25253;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#20026;&#20854;&#20182;&#25289;&#26684;&#26391;&#26085;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#26032;&#24605;&#36335;&#12290;</title><link>https://arxiv.org/abs/2402.10747</link><description>&lt;p&gt;
&#23436;&#20840;&#21487;&#24494;&#30340;&#25289;&#26684;&#26391;&#26085;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#36830;&#32493;&#19968;&#33268;&#29289;&#29702;&#20449;&#24687;&#38477;&#27700;&#39044;&#25253;
&lt;/p&gt;
&lt;p&gt;
Fully Differentiable Lagrangian Convolutional Neural Network for Continuity-Consistent Physics-Informed Precipitation Nowcasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10747
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#21487;&#24494;&#30340;&#25289;&#26684;&#26391;&#26085;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#29289;&#29702;&#20449;&#24687;&#19982;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#22312;&#38477;&#27700;&#39044;&#25253;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#20026;&#20854;&#20182;&#25289;&#26684;&#26391;&#26085;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#26032;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#38477;&#27700;&#39044;&#25253;&#65292;&#32467;&#21512;&#20102;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#39046;&#22495;&#30693;&#35782;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;LUPIN&#65292;&#21363;&#29992;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#25289;&#26684;&#26391;&#26085;&#21452;U-Net&#30340;&#29616;&#22312;&#39044;&#25253;&#65292;&#20511;&#37492;&#20102;&#29616;&#26377;&#30340;&#22522;&#20110;&#22806;&#25512;&#30340;&#39044;&#25253;&#26041;&#27861;&#65292;&#24182;&#20197;&#23436;&#20840;&#21487;&#24494;&#19988;GPU&#21152;&#36895;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#25968;&#25454;&#30340;&#25289;&#26684;&#26391;&#26085;&#22352;&#26631;&#31995;&#36716;&#25442;&#65292;&#20197;&#20801;&#35768;&#23454;&#26102;&#31471;&#21040;&#31471;&#35757;&#32451;&#21644;&#25512;&#26029;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#35780;&#20272;&#65292;LUPIN&#19982;&#24182;&#36229;&#36807;&#20102;&#25152;&#36873;&#25321;&#22522;&#20934;&#30340;&#24615;&#33021;&#65292;&#20026;&#20854;&#20182;&#25289;&#26684;&#26391;&#26085;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25950;&#24320;&#20102;&#22823;&#38376;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10747v1 Announce Type: cross  Abstract: This paper presents a convolutional neural network model for precipitation nowcasting that combines data-driven learning with physics-informed domain knowledge. We propose LUPIN, a Lagrangian Double U-Net for Physics-Informed Nowcasting, that draws from existing extrapolation-based nowcasting methods and implements the Lagrangian coordinate system transformation of the data in a fully differentiable and GPU-accelerated manner to allow for real-time end-to-end training and inference. Based on our evaluation, LUPIN matches and exceeds the performance of the chosen benchmark, opening the door for other Lagrangian machine learning models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20302;&#36164;&#28304;&#29615;&#22659;&#20013;&#35821;&#20041;&#20998;&#21106;&#30340;&#36873;&#25321;&#24615;&#39044;&#27979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#35821;&#20041;&#20998;&#21106;&#37327;&#36523;&#23450;&#21046;&#30340;&#26032;&#22411;&#22270;&#20687;&#32423;&#32622;&#20449;&#24230;&#27979;&#37327;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;</title><link>https://arxiv.org/abs/2402.10665</link><description>&lt;p&gt;
&#20351;&#29992;&#20107;&#21518;&#32622;&#20449;&#24230;&#20272;&#35745;&#30340;&#36873;&#25321;&#24615;&#39044;&#27979;&#22312;&#35821;&#20041;&#20998;&#21106;&#20013;&#30340;&#24615;&#33021;&#21450;&#20854;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Selective Prediction for Semantic Segmentation using Post-Hoc Confidence Estimation and Its Performance under Distribution Shift
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20302;&#36164;&#28304;&#29615;&#22659;&#20013;&#35821;&#20041;&#20998;&#21106;&#30340;&#36873;&#25321;&#24615;&#39044;&#27979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#35821;&#20041;&#20998;&#21106;&#37327;&#36523;&#23450;&#21046;&#30340;&#26032;&#22411;&#22270;&#20687;&#32423;&#32622;&#20449;&#24230;&#27979;&#37327;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#20041;&#20998;&#21106;&#22312;&#21508;&#31181;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#65292;&#28982;&#32780;&#20854;&#26377;&#25928;&#24615;&#24120;&#24120;&#21463;&#21040;&#39640;&#36136;&#37327;&#26631;&#35760;&#25968;&#25454;&#30340;&#32570;&#20047;&#25152;&#38480;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#19968;&#20010;&#24120;&#35265;&#31574;&#30053;&#26159;&#21033;&#29992;&#22312;&#19981;&#21516;&#31181;&#32676;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#22914;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#23548;&#33268;&#20102;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#22312;&#20852;&#36259;&#31181;&#32676;&#19978;&#34920;&#29616;&#20986;&#38477;&#20302;&#30340;&#24615;&#33021;&#12290;&#22312;&#27169;&#22411;&#38169;&#35823;&#21487;&#33021;&#24102;&#26469;&#37325;&#22823;&#21518;&#26524;&#30340;&#24773;&#20917;&#19979;&#65292;&#36873;&#25321;&#24615;&#39044;&#27979;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#20943;&#36731;&#39118;&#38505;&#12289;&#20943;&#23569;&#23545;&#19987;&#23478;&#30417;&#30563;&#20381;&#36182;&#30340;&#25163;&#27573;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36164;&#28304;&#21294;&#20047;&#29615;&#22659;&#19979;&#35821;&#20041;&#20998;&#21106;&#30340;&#36873;&#25321;&#24615;&#39044;&#27979;&#65292;&#30528;&#37325;&#20110;&#24212;&#29992;&#20110;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#36816;&#34892;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#20107;&#21518;&#32622;&#20449;&#24230;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#35821;&#20041;&#20998;&#21106;&#37327;&#36523;&#23450;&#21046;&#30340;&#26032;&#22411;&#22270;&#20687;&#32423;&#32622;&#20449;&#24230;&#27979;&#37327;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10665v1 Announce Type: new  Abstract: Semantic segmentation plays a crucial role in various computer vision applications, yet its efficacy is often hindered by the lack of high-quality labeled data. To address this challenge, a common strategy is to leverage models trained on data from different populations, such as publicly available datasets. This approach, however, leads to the distribution shift problem, presenting a reduced performance on the population of interest. In scenarios where model errors can have significant consequences, selective prediction methods offer a means to mitigate risks and reduce reliance on expert supervision. This paper investigates selective prediction for semantic segmentation in low-resource settings, thus focusing on post-hoc confidence estimators applied to pre-trained models operating under distribution shift. We propose a novel image-level confidence measure tailored for semantic segmentation and demonstrate its effectiveness through expe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;LLMs&#20013;&#30340;&#28608;&#27963;&#24322;&#24120;&#20540;&#19982;&#32593;&#32476;&#23618;&#31232;&#30095;&#24230;&#30340;&#38750;&#22343;&#21248;&#24615;&#30456;&#20851;&#65292;&#24182;&#25552;&#20986;&#20102;Outlier Weighed Layerwise Sparsity&#65288;OWL&#65289;&#20316;&#20026;&#21098;&#26525;LLMs&#21040;&#39640;&#31232;&#30095;&#24230;&#30340;&#31192;&#23494;&#35843;&#21619;&#26009;&#12290;</title><link>https://arxiv.org/abs/2310.05175</link><description>&lt;p&gt;
Outlier Weighed Layerwise Sparsity (OWL): &#20026;&#21098;&#26525;LLMs&#36798;&#21040;&#39640;&#31232;&#30095;&#24230;&#25552;&#20379;&#32570;&#22833;&#30340;&#31192;&#23494;&#35843;&#21619;&#26009;
&lt;/p&gt;
&lt;p&gt;
Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.05175
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;LLMs&#20013;&#30340;&#28608;&#27963;&#24322;&#24120;&#20540;&#19982;&#32593;&#32476;&#23618;&#31232;&#30095;&#24230;&#30340;&#38750;&#22343;&#21248;&#24615;&#30456;&#20851;&#65292;&#24182;&#25552;&#20986;&#20102;Outlier Weighed Layerwise Sparsity&#65288;OWL&#65289;&#20316;&#20026;&#21098;&#26525;LLMs&#21040;&#39640;&#31232;&#30095;&#24230;&#30340;&#31192;&#23494;&#35843;&#21619;&#26009;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20197;&#22312;&#21508;&#20010;&#39046;&#22495;&#23637;&#29616;&#20986;&#30340;&#21331;&#36234;&#24615;&#33021;&#32780;&#38395;&#21517;&#65292;&#22312;&#23454;&#38469;&#37096;&#32626;&#26102;&#30001;&#20110;&#27169;&#22411;&#24222;&#22823;&#32780;&#38754;&#20020;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#20154;&#20204;&#21162;&#21147;&#23558;&#20256;&#32479;&#30340;&#32593;&#32476;&#21098;&#26525;&#25216;&#26415;&#24212;&#29992;&#20110;LLMs&#65292;&#21457;&#29616;&#21487;&#20197;&#22312;&#19981;&#24433;&#21709;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#19968;&#27425;&#24615;&#21098;&#25481;&#22823;&#37327;&#21442;&#25968;&#12290;&#29616;&#26377;&#30340;LLM&#21098;&#26525;&#31574;&#30053;&#19968;&#30452;&#22362;&#25345;&#20197;&#31561;&#20215;&#31232;&#30095;&#24230;&#22343;&#21248;&#21098;&#35009;&#25152;&#26377;&#23618;&#30340;&#20570;&#27861;&#65292;&#32467;&#26524;&#34920;&#29616;&#24378;&#21170;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#35266;&#23519;&#32467;&#26524;&#19982;&#22312;&#35270;&#35273;&#27169;&#22411;&#39046;&#22495;&#35266;&#23519;&#21040;&#30340;&#38750;&#22343;&#21248;&#36880;&#23618;&#31232;&#30095;&#30340;&#20027;&#27969;&#36235;&#21183;&#30456;&#30683;&#30462;&#65292;&#21518;&#32773;&#36890;&#24120;&#20250;&#20135;&#29983;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#20102;&#35299;&#36825;&#31181;&#24046;&#24322;&#32972;&#21518;&#30340;&#21407;&#22240;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#65292;&#24182;&#21457;&#29616;&#19982;LLMs&#20013;&#24322;&#24120;&#20540;&#30340;&#20986;&#29616;&#24378;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.05175v2 Announce Type: replace  Abstract: Large Language Models (LLMs), renowned for their remarkable performance across diverse domains, present a challenge when it comes to practical deployment due to their colossal model size. In response to this challenge, efforts have been directed toward the application of traditional network pruning techniques to LLMs, uncovering a massive number of parameters that can be pruned in one-shot without hurting performance. Prevailing LLM pruning strategies have consistently adhered to the practice of uniformly pruning all layers at equivalent sparsity, resulting in robust performance. However, this observation stands in contrast to the prevailing trends observed in the field of vision models, where non-uniform layerwise sparsity typically yields stronger results. To understand the underlying reasons for this disparity, we conduct a comprehensive study and discover a strong correlation with the emergence of activation outliers in LLMs. Ins
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#35299;&#20915;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#20013;&#30340;&#23884;&#22871;&#26399;&#26395;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2401.16776</link><description>&lt;p&gt;
&#21033;&#29992;&#23884;&#22871;MLMC&#23545;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#36827;&#34892;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Leveraging Nested MLMC for Sequential Neural Posterior Estimation with Intractable Likelihoods. (arXiv:2401.16776v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#35299;&#20915;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#20013;&#30340;&#23884;&#22871;&#26399;&#26395;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#20102;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;SNPE&#65289;&#25216;&#26415;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#27169;&#22411;&#12290;&#23427;&#20204;&#33268;&#21147;&#20110;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#33258;&#36866;&#24212;&#22320;&#29983;&#25104;&#30340;&#27169;&#25311;&#26469;&#23398;&#20064;&#21518;&#39564;&#12290;&#20316;&#20026;&#19968;&#31181;SNPE&#25216;&#26415;&#65292;Greenberg&#31561;&#20154;&#65288;2019&#65289;&#25552;&#20986;&#30340;&#33258;&#21160;&#21518;&#39564;&#21464;&#25442;&#65288;APT&#65289;&#26041;&#27861;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;APT&#26041;&#27861;&#21253;&#21547;&#35745;&#31639;&#38590;&#20197;&#22788;&#29702;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#23545;&#25968;&#30340;&#26399;&#26395;&#65292;&#21363;&#23884;&#22871;&#26399;&#26395;&#12290;&#23613;&#31649;&#21407;&#23376;APT&#36890;&#36807;&#31163;&#25955;&#21270;&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#20998;&#26512;&#23398;&#20064;&#30340;&#25910;&#25947;&#24615;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#20272;&#35745;&#30456;&#20851;&#30340;&#23884;&#22871;&#26399;&#26395;&#12290;&#36825;&#26377;&#21161;&#20110;&#24314;&#31435;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#30001;&#20110;&#25439;&#22833;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#30340;&#23884;&#22871;&#20272;&#35745;&#26159;&#26377;&#20559;&#30340;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;
&lt;/p&gt;
&lt;p&gt;
Sequential neural posterior estimation (SNPE) techniques have been recently proposed for dealing with simulation-based models with intractable likelihoods. They are devoted to learning the posterior from adaptively proposed simulations using neural network-based conditional density estimators. As a SNPE technique, the automatic posterior transformation (APT) method proposed by Greenberg et al. (2019) performs notably and scales to high dimensional data. However, the APT method bears the computation of an expectation of the logarithm of an intractable normalizing constant, i.e., a nested expectation. Although atomic APT was proposed to solve this by discretizing the normalizing constant, it remains challenging to analyze the convergence of learning. In this paper, we propose a nested APT method to estimate the involved nested expectation instead. This facilitates establishing the convergence analysis. Since the nested estimators for the loss function and its gradient are biased, we make
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32597;&#35265;&#24773;&#20917;&#19979;&#30340;&#32959;&#30244;&#26816;&#27979;&#38382;&#39064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20462;&#25913;&#26679;&#26412;&#25968;&#37327;&#21644;&#24739;&#32773;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#24212;&#23545;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.03302</link><description>&lt;p&gt;
&#34892;&#21160;&#20013;&#30340;&#29616;&#23454;&#20027;&#20041;&#65306;&#20351;&#29992;YOLOv8&#21644;DeiT&#20174;&#21307;&#23398;&#22270;&#20687;&#20013;&#35786;&#26029;&#33041;&#32959;&#30244;&#30340;&#24322;&#24120;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT. (arXiv:2401.03302v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32597;&#35265;&#24773;&#20917;&#19979;&#30340;&#32959;&#30244;&#26816;&#27979;&#38382;&#39064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20462;&#25913;&#26679;&#26412;&#25968;&#37327;&#21644;&#24739;&#32773;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#24212;&#23545;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#31185;&#23398;&#39046;&#22495;&#65292;&#30001;&#20110;&#33041;&#32959;&#30244;&#22312;&#24739;&#32773;&#20013;&#30340;&#32597;&#35265;&#31243;&#24230;&#65292;&#21487;&#38752;&#22320;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#20173;&#28982;&#26159;&#19968;&#20010;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#22312;&#24322;&#24120;&#24773;&#20917;&#19979;&#26816;&#27979;&#32959;&#30244;&#30340;&#33021;&#21147;&#23545;&#20110;&#30830;&#20445;&#21450;&#26102;&#24178;&#39044;&#21644;&#25913;&#21892;&#24739;&#32773;&#32467;&#26524;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#12290;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#65288;NBML&#65289;&#30340;&#31934;&#36873;&#25968;&#25454;&#38598;&#21253;&#25324;81&#21517;&#24739;&#32773;&#65292;&#20854;&#20013;&#21253;&#25324;30&#20363;&#32959;&#30244;&#30149;&#20363;&#21644;51&#20363;&#27491;&#24120;&#30149;&#20363;&#12290;&#26816;&#27979;&#21644;&#20998;&#31867;&#27969;&#31243;&#34987;&#20998;&#20026;&#20004;&#20010;&#36830;&#32493;&#30340;&#20219;&#21153;&#12290;&#26816;&#27979;&#38454;&#27573;&#21253;&#25324;&#20840;&#38754;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#39044;&#22788;&#29702;&#65292;&#20197;&#20462;&#25913;&#22270;&#20687;&#26679;&#26412;&#21644;&#27599;&#20010;&#31867;&#21035;&#30340;&#24739;&#32773;&#25968;&#37327;&#65292;&#20197;&#31526;&#21512;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#20998;&#24067;&#65288;9&#20010;&#27491;&#24120;&#26679;&#26412;&#23545;&#24212;1&#20010;&#32959;&#30244;&#26679;&#26412;&#65289;&#12290;&#27492;&#22806;&#65292;&#22312;&#27979;&#35797;&#20013;&#38500;&#20102;&#24120;&#35265;&#30340;&#35780;&#20272;&#25351;&#26631;&#22806;&#65292;&#25105;&#20204;&#36824;&#37319;&#29992;&#20102;... [&#25688;&#35201;&#38271;&#24230;&#24050;&#36798;&#21040;&#19978;&#38480;]
&lt;/p&gt;
&lt;p&gt;
In the field of medical sciences, reliable detection and classification of brain tumors from images remains a formidable challenge due to the rarity of tumors within the population of patients. Therefore, the ability to detect tumors in anomaly scenarios is paramount for ensuring timely interventions and improved patient outcomes. This study addresses the issue by leveraging deep learning (DL) techniques to detect and classify brain tumors in challenging situations. The curated data set from the National Brain Mapping Lab (NBML) comprises 81 patients, including 30 Tumor cases and 51 Normal cases. The detection and classification pipelines are separated into two consecutive tasks. The detection phase involved comprehensive data analysis and pre-processing to modify the number of image samples and the number of patients of each class to anomaly distribution (9 Normal per 1 Tumor) to comply with real world scenarios. Next, in addition to common evaluation metrics for the testing, we emplo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#31232;&#30095;&#24615;&#20998;&#26512;LLM&#39044;&#35757;&#32451;&#26435;&#37325;&#30340;&#20219;&#21153;&#20013;&#24515;&#35282;&#24230;&#65292;&#25361;&#25112;&#20102;&#20256;&#32479;&#23545;&#20110;&#26435;&#37325;&#20013;&#20887;&#20313;&#24615;&#30340;&#35266;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;"&#22403;&#22334;DNA&#20551;&#35774;"&#12290;</title><link>http://arxiv.org/abs/2310.02277</link><description>&lt;p&gt;
"&#22403;&#22334;DNA&#20551;&#35774;&#65306;&#36890;&#36807;&#31232;&#30095;&#24615;&#23545;LLM&#39044;&#35757;&#32451;&#26435;&#37325;&#36827;&#34892;&#20219;&#21153;&#20013;&#24515;&#35282;&#24230;&#20998;&#26512;"
&lt;/p&gt;
&lt;p&gt;
Junk DNA Hypothesis: A Task-Centric Angle of LLM Pre-trained Weights through Sparsity. (arXiv:2310.02277v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#31232;&#30095;&#24615;&#20998;&#26512;LLM&#39044;&#35757;&#32451;&#26435;&#37325;&#30340;&#20219;&#21153;&#20013;&#24515;&#35282;&#24230;&#65292;&#25361;&#25112;&#20102;&#20256;&#32479;&#23545;&#20110;&#26435;&#37325;&#20013;&#20887;&#20313;&#24615;&#30340;&#35266;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;"&#22403;&#22334;DNA&#20551;&#35774;"&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#23545;"&#22403;&#22334;DNA"&#30340;&#27010;&#24565;&#38271;&#26399;&#20197;&#26469;&#19982;&#20154;&#31867;&#22522;&#22240;&#32452;&#20013;&#30340;&#38750;&#32534;&#30721;&#29255;&#27573;&#30456;&#20851;&#32852;&#65292;&#21344;&#20854;&#32452;&#25104;&#30340;&#22823;&#32422;98%&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#19968;&#20123;&#36825;&#20123;&#30475;&#20284;&#26080;&#21151;&#33021;&#30340;DNA&#24207;&#21015;&#22312;&#32454;&#32990;&#36807;&#31243;&#20013;&#36215;&#21040;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#19982;&#20154;&#31867;&#22522;&#22240;&#20013;&#35266;&#23519;&#21040;&#30340;&#20887;&#20313;&#24615;&#26377;&#30528;&#26174;&#33879;&#30340;&#30456;&#20284;&#24615;&#12290;&#20154;&#20204;&#35748;&#20026;&#65292;&#24222;&#22823;&#27169;&#22411;&#20013;&#30340;&#26435;&#37325;&#21253;&#21547;&#20102;&#36807;&#22810;&#30340;&#20887;&#20313;&#65292;&#21487;&#20197;&#22312;&#19981;&#24433;&#21709;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#21435;&#38500;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#20196;&#20154;&#20449;&#26381;&#30340;&#21453;&#35770;&#26469;&#25361;&#25112;&#36825;&#20010;&#20256;&#32479;&#35266;&#28857;&#12290;&#25105;&#20204;&#20351;&#29992;&#31232;&#30095;&#24615;&#20316;&#20026;&#19968;&#31181;&#24037;&#20855;&#65292;&#26469;&#29420;&#31435;&#32780;&#20934;&#30830;&#22320;&#37327;&#21270;&#39044;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#20013;&#20302;&#24133;&#24230;&#26435;&#37325;&#30340;&#32454;&#24494;&#37325;&#35201;&#24615;&#65292;&#20174;&#19979;&#28216;&#20219;&#21153;&#20013;&#24515;&#30340;&#35282;&#24230;&#29702;&#35299;&#23427;&#20204;&#21253;&#21547;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25903;&#25345;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#30340;"&#22403;&#22334;DNA&#20551;&#35774;"&#12290;
&lt;/p&gt;
&lt;p&gt;
The traditional notion of "Junk DNA" has long been linked to non-coding segments within the human genome, constituting roughly 98% of its composition. However, recent research has unveiled the critical roles some of these seemingly non-functional DNA sequences play in cellular processes. Intriguingly, the weights within deep neural networks exhibit a remarkable similarity to the redundancy observed in human genes. It was believed that weights in gigantic models contained excessive redundancy, and could be removed without compromising performance. This paper challenges this conventional wisdom by presenting a compelling counter-argument. We employ sparsity as a tool to isolate and quantify the nuanced significance of low-magnitude weights in pre-trained large language models (LLMs). Our study demonstrates a strong correlation between these weight magnitudes and the knowledge they encapsulate, from a downstream task-centric angle. we raise the "Junk DNA Hypothesis" backed by our in-depth
&lt;/p&gt;</description></item></channel></rss>