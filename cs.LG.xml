<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#21644;&#22522;&#30784;&#35774;&#26045;&#36830;&#32493;&#27979;&#37327;&#25968;&#25454;&#65292;&#20197;&#21450;&#22312;&#20869;&#37096;&#27979;&#35797;&#21488;&#19978;&#36827;&#34892;&#25915;&#20987;&#27169;&#25311;&#65292;&#23454;&#29616;&#20102;IT&#22522;&#30784;&#35774;&#26045;&#20013;&#30340;&#33258;&#21160;&#20837;&#20405;&#26816;&#27979;&#12290;</title><link>https://arxiv.org/abs/2402.13081</link><description>&lt;p&gt;
&#20351;&#29992;&#32479;&#35745;&#23398;&#20064;&#21644;&#27979;&#35797;&#21488;&#27979;&#37327;&#36827;&#34892;IT&#20837;&#20405;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
IT Intrusion Detection Using Statistical Learning and Testbed Measurements
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13081
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#21644;&#22522;&#30784;&#35774;&#26045;&#36830;&#32493;&#27979;&#37327;&#25968;&#25454;&#65292;&#20197;&#21450;&#22312;&#20869;&#37096;&#27979;&#35797;&#21488;&#19978;&#36827;&#34892;&#25915;&#20987;&#27169;&#25311;&#65292;&#23454;&#29616;&#20102;IT&#22522;&#30784;&#35774;&#26045;&#20013;&#30340;&#33258;&#21160;&#20837;&#20405;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;IT&#22522;&#30784;&#35774;&#26045;&#20013;&#30340;&#33258;&#21160;&#20837;&#20405;&#26816;&#27979;&#65292;&#29305;&#21035;&#26159;&#35782;&#21035;&#25915;&#20987;&#24320;&#22987;&#12289;&#25915;&#20987;&#31867;&#22411;&#20197;&#21450;&#25915;&#20987;&#32773;&#37319;&#21462;&#30340;&#21160;&#20316;&#39034;&#24207;&#30340;&#38382;&#39064;&#65292;&#22522;&#20110;&#22522;&#30784;&#35774;&#26045;&#30340;&#36830;&#32493;&#27979;&#37327;&#12290;&#25105;&#20204;&#24212;&#29992;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#21253;&#25324;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#12289;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#38543;&#26426;&#26862;&#26519;&#20998;&#31867;&#22120;&#65288;RFC&#65289;&#65292;&#23558;&#35266;&#27979;&#24207;&#21015;&#26144;&#23556;&#21040;&#39044;&#27979;&#25915;&#20987;&#21160;&#20316;&#24207;&#21015;&#12290;&#19982;&#22823;&#22810;&#25968;&#30456;&#20851;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#25317;&#26377;&#20016;&#23500;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#27169;&#22411;&#24182;&#35780;&#20272;&#20854;&#39044;&#27979;&#33021;&#21147;&#12290;&#25968;&#25454;&#26469;&#33258;&#25105;&#20204;&#22312;&#20869;&#37096;&#27979;&#35797;&#21488;&#19978;&#29983;&#25104;&#30340;&#36319;&#36394;&#25968;&#25454;&#65292;&#22312;&#36825;&#37324;&#25105;&#20204;&#23545;&#27169;&#25311;&#30340;IT&#22522;&#30784;&#35774;&#26045;&#36827;&#34892;&#25915;&#20987;&#12290;&#25105;&#20204;&#24037;&#20316;&#30340;&#26680;&#24515;&#26159;&#19968;&#20010;&#26426;&#22120;&#23398;&#20064;&#31649;&#36947;&#65292;&#23558;&#26469;&#33258;&#39640;&#32500;&#35266;&#27979;&#31354;&#38388;&#30340;&#27979;&#37327;&#26144;&#23556;&#21040;&#20302;&#32500;&#31354;&#38388;&#25110;&#23569;&#37327;&#35266;&#27979;&#31526;&#21495;&#30340;&#31354;&#38388;&#12290;&#25105;&#20204;&#30740;&#31350;&#31163;&#32447;&#21644;&#22312;&#32447;&#20837;&#20405;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13081v1 Announce Type: new  Abstract: We study automated intrusion detection in an IT infrastructure, specifically the problem of identifying the start of an attack, the type of attack, and the sequence of actions an attacker takes, based on continuous measurements from the infrastructure. We apply statistical learning methods, including Hidden Markov Model (HMM), Long Short-Term Memory (LSTM), and Random Forest Classifier (RFC) to map sequences of observations to sequences of predicted attack actions. In contrast to most related research, we have abundant data to train the models and evaluate their predictive power. The data comes from traces we generate on an in-house testbed where we run attacks against an emulated IT infrastructure. Central to our work is a machine-learning pipeline that maps measurements from a high-dimensional observation space to a space of low dimensionality or to a small set of observation symbols. Investigating intrusions in offline as well as onli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24369;&#26465;&#20214;&#19979;&#33719;&#24471;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23454;&#29616;&#26041;&#24046;&#20943;&#23569;&#30340;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2402.08992</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#26041;&#24046;&#20943;&#23569;&#21644;&#20302;&#26679;&#26412;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Variance Reduction and Low Sample Complexity in Stochastic Optimization via Proximal Point Method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24369;&#26465;&#20214;&#19979;&#33719;&#24471;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23454;&#29616;&#26041;&#24046;&#20943;&#23569;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#36817;&#31471;&#28857;&#27861;&#26469;&#35299;&#20915;&#38543;&#26426;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#39640;&#27010;&#29575;&#32467;&#26524;&#36890;&#24120;&#20381;&#36182;&#20110;&#23545;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#20363;&#22914;&#23376;&#39640;&#26031;&#20998;&#24067;&#12290;&#26412;&#25991;&#21482;&#20551;&#35774;&#20102;&#38543;&#26426;&#26799;&#24230;&#30340;&#26377;&#30028;&#26041;&#24046;&#31561;&#24369;&#26465;&#20214;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#20197;&#33719;&#24471;&#20851;&#20110;&#25152;&#25552;&#26041;&#27861;&#25910;&#25947;&#30340;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#26412;&#24037;&#20316;&#30340;&#19968;&#20010;&#26174;&#33879;&#26041;&#38754;&#26159;&#21457;&#23637;&#20102;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#36817;&#31471;&#23376;&#38382;&#39064;&#30340;&#23376;&#31243;&#24207;&#65292;&#23427;&#21516;&#26102;&#20063;&#26159;&#19968;&#31181;&#29992;&#20110;&#20943;&#23569;&#26041;&#24046;&#30340;&#26032;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08992v1 Announce Type: cross Abstract: This paper proposes a stochastic proximal point method to solve a stochastic convex composite optimization problem. High probability results in stochastic optimization typically hinge on restrictive assumptions on the stochastic gradient noise, for example, sub-Gaussian distributions. Assuming only weak conditions such as bounded variance of the stochastic gradient, this paper establishes a low sample complexity to obtain a high probability guarantee on the convergence of the proposed method. Additionally, a notable aspect of this work is the development of a subroutine to solve the proximal subproblem, which also serves as a novel technique for variance reduction.
&lt;/p&gt;</description></item><item><title>&#22797;&#21512;&#22238;&#25253;&#26159;&#19968;&#31181;&#26032;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#38477;&#20302;&#26041;&#24046;&#21644;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#30340;&#36129;&#29486;&#21644;&#21019;&#26032;&#12290;</title><link>https://arxiv.org/abs/2402.03903</link><description>&lt;p&gt;
&#22797;&#21512;&#22238;&#25253;&#38477;&#20302;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26041;&#24046;
&lt;/p&gt;
&lt;p&gt;
Compound Returns Reduce Variance in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03903
&lt;/p&gt;
&lt;p&gt;
&#22797;&#21512;&#22238;&#25253;&#26159;&#19968;&#31181;&#26032;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#38477;&#20302;&#26041;&#24046;&#21644;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#30340;&#36129;&#29486;&#21644;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27493;&#22238;&#25253;&#65292;&#20363;&#22914;$n$&#27493;&#22238;&#25253;&#21644;$\lambda$&#22238;&#25253;&#65292;&#36890;&#24120;&#29992;&#20110;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;&#22810;&#27493;&#22238;&#25253;&#30340;&#26041;&#24046;&#25104;&#20026;&#20854;&#38271;&#24230;&#30340;&#38480;&#21046;&#22240;&#32032;&#65292;&#36807;&#24230;&#36828;&#26395;&#26410;&#26469;&#20250;&#22686;&#21152;&#26041;&#24046;&#24182;&#36870;&#36716;&#22810;&#27493;&#23398;&#20064;&#30340;&#22909;&#22788;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22797;&#21512;&#22238;&#25253;&#65288;$n$&#27493;&#22238;&#25253;&#30340;&#21152;&#26435;&#24179;&#22343;&#65289;&#38477;&#20302;&#26041;&#24046;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#27425;&#35777;&#26126;&#20102;&#20219;&#20309;&#19982;&#32473;&#23450;$n$&#27493;&#22238;&#25253;&#20855;&#26377;&#30456;&#21516;&#25910;&#32553;&#27169;&#25968;&#30340;&#22797;&#21512;&#22238;&#25253;&#30340;&#26041;&#24046;&#20005;&#26684;&#36739;&#20302;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36825;&#31181;&#38477;&#20302;&#26041;&#24046;&#30340;&#29305;&#24615;&#25913;&#21892;&#20102;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#26102;&#24207;&#24046;&#20998;&#23398;&#20064;&#30340;&#26377;&#38480;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#30001;&#20110;&#19968;&#33324;&#22797;&#21512;&#22238;&#25253;&#30340;&#23454;&#26045;&#21487;&#33021;&#20195;&#20215;&#39640;&#26114;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#33258;&#21161;&#22238;&#25253;&#65292;&#23427;&#20204;&#22312;&#20445;&#25345;&#39640;&#25928;&#24615;&#30340;&#21516;&#26102;&#38477;&#20302;&#20102;&#26041;&#24046;&#65292;&#21363;&#20351;&#22312;&#20351;&#29992;&#23567;&#25209;&#37327;&#32463;&#39564;&#22238;&#25918;&#26102;&#20063;&#26159;&#22914;&#27492;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#26174;&#31034;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
Multistep returns, such as $n$-step returns and $\lambda$-returns, are commonly used to improve the sample efficiency of reinforcement learning (RL) methods. The variance of the multistep returns becomes the limiting factor in their length; looking too far into the future increases variance and reverses the benefits of multistep learning. In our work, we demonstrate the ability of compound returns -- weighted averages of $n$-step returns -- to reduce variance. We prove for the first time that any compound return with the same contraction modulus as a given $n$-step return has strictly lower variance. We additionally prove that this variance-reduction property improves the finite-sample complexity of temporal-difference learning under linear function approximation. Because general compound returns can be expensive to implement, we introduce two-bootstrap returns which reduce variance while remaining efficient, even when using minibatched experience replay. We conduct experiments showing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2212.04382</link><description>&lt;p&gt;
&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#65306;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.04382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#35770;&#22522;&#20110;&#27169;&#22411;&#12289;&#35757;&#32451;&#25968;&#25454;&#36824;&#26159;&#20108;&#32773;&#32452;&#21512;&#65292;&#20998;&#31867;&#22120;&#23558;&#65288;&#21487;&#33021;&#22797;&#26434;&#30340;&#65289;&#36755;&#20837;&#25968;&#25454;&#24402;&#20837;&#30456;&#23545;&#36739;&#23569;&#30340;&#36755;&#20986;&#31867;&#21035;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#22312;&#36755;&#20837;&#31354;&#38388;&#20026;&#22270;&#30340;&#24773;&#20917;&#19979;&#65292;&#36793;&#30028;&#30340;&#32467;&#26500;&#8212;&#8212;&#37027;&#20123;&#34987;&#20998;&#31867;&#20026;&#19981;&#21516;&#31867;&#21035;&#30340;&#37051;&#36817;&#28857;&#8212;&#8212;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#30340;&#31185;&#23398;&#32972;&#26223;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#30001;&#19979;&#19968;&#20195;&#27979;&#24207;&#20202;&#29983;&#25104;&#30340;DNA&#35835;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36793;&#30028;&#26082;&#26159;&#24040;&#22823;&#30340;&#65292;&#21448;&#20855;&#26377;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#23427;&#23558;&#19968;&#20010;&#28857;&#30340;&#32467;&#26524;&#19982;&#20854;&#37051;&#23621;&#30340;&#32467;&#26524;&#20998;&#24067;&#36827;&#34892;&#27604;&#36739;&#12290;&#36825;&#20010;&#24230;&#37327;&#19981;&#20165;&#36861;&#36394;&#20102;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#20004;&#20010;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#36824;&#21487;&#20197;&#22312;&#27809;&#26377;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#30340;&#20998;&#31867;&#22120;&#19978;&#23454;&#29616;&#65292;&#20294;&#38656;&#35201;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether based on models, training data or a combination, classifiers place (possibly complex) input data into one of a relatively small number of output categories. In this paper, we study the structure of the boundary--those points for which a neighbor is classified differently--in the context of an input space that is a graph, so that there is a concept of neighboring inputs, The scientific setting is a model-based naive Bayes classifier for DNA reads produced by Next Generation Sequencers. We show that the boundary is both large and complicated in structure. We create a new measure of uncertainty, called Neighbor Similarity, that compares the result for a point to the distribution of results for its neighbors. This measure not only tracks two inherent uncertainty measures for the Bayes classifier, but also can be implemented, at a computational cost, for classifiers without inherent measures of uncertainty.
&lt;/p&gt;</description></item><item><title>HUTFormer&#26159;&#19968;&#31181;&#29992;&#20110;&#38271;&#26399;&#20132;&#36890;&#39044;&#27979;&#30340;&#20998;&#23618;U-Net Transformer&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#23610;&#24230;&#34920;&#31034;&#26469;&#35299;&#20915;&#38271;&#26399;&#39044;&#27979;&#20013;&#30340;&#25361;&#25112;&#21644;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.14596</link><description>&lt;p&gt;
HUTFormer&#65306;&#29992;&#20110;&#38271;&#26399;&#20132;&#36890;&#39044;&#27979;&#30340;&#20998;&#23618;U-Net Transformer
&lt;/p&gt;
&lt;p&gt;
HUTFormer: Hierarchical U-Net Transformer for Long-Term Traffic Forecasting. (arXiv:2307.14596v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14596
&lt;/p&gt;
&lt;p&gt;
HUTFormer&#26159;&#19968;&#31181;&#29992;&#20110;&#38271;&#26399;&#20132;&#36890;&#39044;&#27979;&#30340;&#20998;&#23618;U-Net Transformer&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#23610;&#24230;&#34920;&#31034;&#26469;&#35299;&#20915;&#38271;&#26399;&#39044;&#27979;&#20013;&#30340;&#25361;&#25112;&#21644;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#39044;&#27979;&#26088;&#22312;&#22522;&#20110;&#21382;&#21490;&#35266;&#27979;&#25968;&#25454;&#39044;&#27979;&#20132;&#36890;&#29366;&#20917;&#65292;&#26159;&#26234;&#33021;&#20132;&#36890;&#39046;&#22495;&#20013;&#30340;&#37325;&#35201;&#30740;&#31350;&#35838;&#39064;&#12290;&#26368;&#36817;&#30340;&#31354;&#38388;-&#26102;&#38388;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;STGNNs&#65289;&#36890;&#36807;&#23558;&#39034;&#24207;&#27169;&#22411;&#19982;&#22270;&#21367;&#31215;&#32593;&#32476;&#30456;&#32467;&#21512;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;STGNNs&#20165;&#32858;&#28966;&#20110;&#30701;&#26399;&#20132;&#36890;&#39044;&#27979;&#65292;&#22914;1&#23567;&#26102;&#39044;&#27979;&#65292;&#32780;&#24573;&#35270;&#20102;&#26356;&#23454;&#38469;&#30340;&#38271;&#26399;&#39044;&#27979;&#12290;&#26412;&#25991;&#39318;&#27425;&#23581;&#35797;&#25506;&#32034;&#38271;&#26399;&#20132;&#36890;&#39044;&#27979;&#65292;&#20363;&#22914;1&#22825;&#30340;&#39044;&#27979;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#25581;&#31034;&#20102;&#22312;&#21033;&#29992;&#22810;&#23610;&#24230;&#34920;&#31034;&#26041;&#38754;&#30340;&#29420;&#29305;&#25361;&#25112;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23618;U-Net TransFormer&#65288;HUTFormer&#65289;&#26469;&#35299;&#20915;&#38271;&#26399;&#20132;&#36890;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;HUTFormer&#30001;&#20998;&#23618;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#32452;&#25104;&#65292;&#20849;&#21516;&#29983;&#25104;&#21644;&#21033;&#29992;&#20132;&#36890;&#30340;&#22810;&#23610;&#24230;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traffic forecasting, which aims to predict traffic conditions based on historical observations, has been an enduring research topic and is widely recognized as an essential component of intelligent transportation. Recent proposals on Spatial-Temporal Graph Neural Networks (STGNNs) have made significant progress by combining sequential models with graph convolution networks. However, due to high complexity issues, STGNNs only focus on short-term traffic forecasting, e.g., 1-hour forecasting, while ignoring more practical long-term forecasting. In this paper, we make the first attempt to explore long-term traffic forecasting, e.g., 1-day forecasting. To this end, we first reveal its unique challenges in exploiting multi-scale representations. Then, we propose a novel Hierarchical U-net TransFormer (HUTFormer) to address the issues of long-term traffic forecasting. HUTFormer consists of a hierarchical encoder and decoder to jointly generate and utilize multi-scale representations of traff
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25361;&#25112;&#20102;&#22312;&#26102;&#38388;&#19978;&#26159;&#19981;&#30456;&#20851;&#30340;&#20551;&#35774;&#65292;&#24182;&#24378;&#35843;&#20102;epoch-based&#22122;&#22768;&#30456;&#20851;&#24615;&#23545;&#31163;&#25955;&#26102;&#38388;&#24102;&#21160;&#37327;&#30340;SGD&#30340;&#26435;&#37325;&#26041;&#24046;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.05300</link><description>&lt;p&gt;
&#22522;&#20110;Epoch&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30456;&#20851;&#22122;&#22768;&#65306;&#26435;&#37325;&#26041;&#24046;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Correlated Noise in Epoch-Based Stochastic Gradient Descent: Implications for Weight Variances. (arXiv:2306.05300v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05300
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25361;&#25112;&#20102;&#22312;&#26102;&#38388;&#19978;&#26159;&#19981;&#30456;&#20851;&#30340;&#20551;&#35774;&#65292;&#24182;&#24378;&#35843;&#20102;epoch-based&#22122;&#22768;&#30456;&#20851;&#24615;&#23545;&#31163;&#25955;&#26102;&#38388;&#24102;&#21160;&#37327;&#30340;SGD&#30340;&#26435;&#37325;&#26041;&#24046;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#24050;&#25104;&#20026;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#30340;&#22522;&#30707;&#65292;&#20294;&#35748;&#20026;SGD&#24341;&#20837;&#30340;&#22122;&#22768;&#22312;&#26102;&#38388;&#19978;&#26159;&#19981;&#30456;&#20851;&#30340;&#65292;&#23613;&#31649;epoch-based&#35757;&#32451;&#26159;&#26080;&#22788;&#19981;&#22312;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#27492;&#36827;&#34892;&#20102;&#25361;&#25112;&#65292;&#24182;&#35843;&#26597;&#20102;epoch-based&#22122;&#22768;&#30456;&#20851;&#24615;&#23545;&#31163;&#25955;&#26102;&#38388;&#24102;&#21160;&#37327;&#30340;SGD&#30340;&#31283;&#24577;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#38480;&#20110;&#20108;&#27425;&#25439;&#22833;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26377;&#20004;&#20010;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#35745;&#31639;&#35757;&#32451;epoch&#26102;&#22122;&#22768;&#30340;&#31934;&#30830;&#33258;&#30456;&#20851;&#24615;&#65292;&#20551;&#35774;&#35813;&#22122;&#22768;&#29420;&#31435;&#20110;&#26435;&#37325;&#21521;&#37327;&#20013;&#30340;&#23567;&#27874;&#21160;;&#20854;&#27425;&#65292;&#25105;&#20204;&#25506;&#32034;epoch-based&#23398;&#20064;&#26041;&#26696;&#24341;&#20837;&#30340;&#30456;&#20851;&#24615;&#23545;SGD&#21160;&#24577;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#26354;&#29575;&#22823;&#20110;&#19968;&#20010;&#36229;&#21442;&#25968;&#30456;&#20851;&#20540;&#30340;&#26041;&#21521;&#19978;&#65292;&#36824;&#21407;&#20102;&#19981;&#30456;&#20851;&#22122;&#22768;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#30456;&#23545;&#24179;&#22374;&#30340;&#26041;&#21521;&#19978;&#65292;&#26435;&#37325;&#26041;&#24046;&#26174;&#30528;&#20943;&#23567;&#12290;&#25105;&#20204;&#20351;&#29992;&#31616;&#21333;&#30340;&#20108;&#32500;&#22270;&#20363;&#23545;&#36825;&#20123;&#32467;&#26524;&#36827;&#34892;&#20102;&#30452;&#35266;&#35299;&#37322;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20379;&#20102;&#20851;&#20110;epoch-based SGD&#20013;&#30456;&#20851;&#22122;&#22768;&#24433;&#21709;&#30340;&#35265;&#35299;&#65292;&#21487;&#20197;&#25351;&#23548;&#35774;&#35745;&#26356;&#26377;&#25928;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient descent (SGD) has become a cornerstone of neural network optimization, yet the noise introduced by SGD is often assumed to be uncorrelated over time, despite the ubiquity of epoch-based training. In this work, we challenge this assumption and investigate the effects of epoch-based noise correlations on the stationary distribution of discrete-time SGD with momentum, limited to a quadratic loss. Our main contributions are twofold: first, we calculate the exact autocorrelation of the noise for training in epochs under the assumption that the noise is independent of small fluctuations in the weight vector; second, we explore the influence of correlations introduced by the epoch-based learning scheme on SGD dynamics. We find that for directions with a curvature greater than a hyperparameter-dependent crossover value, the results for uncorrelated noise are recovered. However, for relatively flat directions, the weight variance is significantly reduced. We provide an intui
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#31574;&#30053;"EE-Net"&#65292;&#23427;&#29992;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#21033;&#29992;&#21644;&#25506;&#32034;&#65292;&#22312;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#30340;&#21516;&#26102;&#20063;&#36866;&#24212;&#24615;&#22320;&#23398;&#20064;&#28508;&#22312;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2305.03784</link><description>&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#19978;&#19979;&#25991;&#21033;&#29992;&#19982;&#25506;&#32034;&#30340;&#31070;&#32463;&#32593;&#32476;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Neural Exploitation and Exploration of Contextual Bandits. (arXiv:2305.03784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#31574;&#30053;"EE-Net"&#65292;&#23427;&#29992;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#21033;&#29992;&#21644;&#25506;&#32034;&#65292;&#22312;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#30340;&#21516;&#26102;&#20063;&#36866;&#24212;&#24615;&#22320;&#23398;&#20064;&#28508;&#22312;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#21033;&#29992;&#21644;&#25506;&#32034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"EE-Net"&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#21033;&#29992;&#21644;&#25506;&#32034;&#31574;&#30053;&#65292;&#23427;&#20351;&#29992;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65288;&#21033;&#29992;&#32593;&#32476;&#65289;&#26469;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#65292;&#21478;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65288;&#25506;&#32034;&#32593;&#32476;&#65289;&#26469;&#36866;&#24212;&#24615;&#22320;&#23398;&#20064;&#30456;&#23545;&#20110;&#24403;&#21069;&#20272;&#35745;&#22870;&#21169;&#30340;&#28508;&#22312;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study utilizing neural networks for the exploitation and exploration of contextual multi-armed bandits. Contextual multi-armed bandits have been studied for decades with various applications. To solve the exploitation-exploration trade-off in bandits, there are three main techniques: epsilon-greedy, Thompson Sampling (TS), and Upper Confidence Bound (UCB). In recent literature, a series of neural bandit algorithms have been proposed to adapt to the non-linear reward function, combined with TS or UCB strategies for exploration. In this paper, instead of calculating a large-deviation based statistical bound for exploration like previous methods, we propose, ``EE-Net,'' a novel neural-based exploitation and exploration strategy. In addition to using a neural network (Exploitation network) to learn the reward function, EE-Net uses another neural network (Exploration network) to adaptively learn the potential gains compared to the currently estimated reward for exploration
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#36712;&#36857;&#24863;&#30693;&#30340;&#36164;&#26684;&#36861;&#36394;&#22810;&#27493;&#36816;&#31639;&#31526;&#65292;&#21487;&#20197;&#21516;&#26102;&#34920;&#36798;&#27599;&#20010;&#20915;&#31574;&#21644;&#36712;&#36857;&#24863;&#30693;&#30340;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#34987;&#23436;&#20840;&#35009;&#21098;&#30340;&#36164;&#26684;&#36861;&#36394;&#26080;&#27861;&#36870;&#36716;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.11321</link><description>&lt;p&gt;
&#36712;&#36857;&#24863;&#30693;&#30340;&#36164;&#26684;&#36861;&#36394;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning. (arXiv:2301.11321v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11321
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#36712;&#36857;&#24863;&#30693;&#30340;&#36164;&#26684;&#36861;&#36394;&#22810;&#27493;&#36816;&#31639;&#31526;&#65292;&#21487;&#20197;&#21516;&#26102;&#34920;&#36798;&#27599;&#20010;&#20915;&#31574;&#21644;&#36712;&#36857;&#24863;&#30693;&#30340;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#34987;&#23436;&#20840;&#35009;&#21098;&#30340;&#36164;&#26684;&#36861;&#36394;&#26080;&#27861;&#36870;&#36716;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#22810;&#27493;&#36820;&#22238;&#30340;&#38750;&#25919;&#31574;&#23398;&#20064;&#23545;&#20110;&#33410;&#32422;&#26679;&#26412;&#30340;&#24378;&#21270;&#23398;&#20064;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#25269;&#28040;&#20559;&#24046;&#30340;&#21516;&#26102;&#19981;&#21152;&#21095;&#26041;&#24046;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#38750;&#25919;&#31574;&#20559;&#24046;&#26159;&#36890;&#36807;&#36164;&#26684;&#36861;&#36394;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#20462;&#27491;&#30340;&#65292;&#36164;&#26684;&#36861;&#36394;&#36890;&#36807;&#36890;&#21507;&#22240;&#23376;(Impotance Sampling)&#27604;&#20363;&#23545;&#36807;&#21435;&#30340;&#26102;&#38388;&#24046;&#20998;&#35823;&#24046;&#36827;&#34892;&#37325;&#26032;&#21152;&#26435;&#20197;&#32416;&#27491;&#12290;&#35768;&#22810;&#31163;&#32447;&#31639;&#27861;&#37117;&#20381;&#36182;&#36825;&#31181;&#26426;&#21046;&#65292;&#19981;&#21516;&#30340;&#26159;&#38024;&#23545;IS&#30340;&#32479;&#35745;&#20272;&#35745;&#26041;&#27861;&#25152;&#37319;&#29992;&#30340;&#8220;&#35009;&#21098;IS&#27604;&#20363;&#8221;&#21327;&#35758;&#30340;&#19981;&#21516;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#19968;&#26086;&#36164;&#26684;&#36861;&#36394;&#34987;&#23436;&#20840;&#35009;&#21098;&#65292;&#20854;&#24433;&#21709;&#23601;&#26080;&#27861;&#36870;&#36716;&#12290;&#36825;&#24050;&#32463;&#23548;&#33268;&#20102;&#23558;&#22810;&#20010;&#36807;&#21435;&#32463;&#21382;&#21516;&#26102;&#32771;&#34385;&#22312;&#20869;&#30340;&#20449;&#29992;&#20998;&#37197;&#31574;&#30053;&#30340;&#20986;&#29616;&#12290;&#36825;&#20123;&#36712;&#36857;&#24863;&#30693;&#30340;&#26041;&#27861;&#23578;&#26410;&#24471;&#21040;&#24191;&#27867;&#30340;&#20998;&#26512;&#65292;&#23427;&#20204;&#30340;&#29702;&#35770;&#20381;&#25454;&#20173;&#28982;&#19981;&#30830;&#23450;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#27493;&#36816;&#31639;&#31526;&#65292;&#21487;&#20197;&#21516;&#26102;&#34920;&#36798;&#27599;&#20010;&#20915;&#31574;&#21644;&#36712;&#36857;&#24863;&#30693;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#30340;&#25910;&#25947;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Off-policy learning from multistep returns is crucial for sample-efficient reinforcement learning, but counteracting off-policy bias without exacerbating variance is challenging. Classically, off-policy bias is corrected in a per-decision manner: past temporal-difference errors are re-weighted by the instantaneous Importance Sampling (IS) ratio after each action via eligibility traces. Many off-policy algorithms rely on this mechanism, along with differing protocols for cutting the IS ratios to combat the variance of the IS estimator. Unfortunately, once a trace has been fully cut, the effect cannot be reversed. This has led to the development of credit-assignment strategies that account for multiple past experiences at a time. These trajectory-aware methods have not been extensively analyzed, and their theoretical justification remains uncertain. In this paper, we propose a multistep operator that can express both per-decision and trajectory-aware methods. We prove convergence conditi
&lt;/p&gt;</description></item></channel></rss>