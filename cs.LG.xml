<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#20851;&#20110;&#26368;&#23567;&#28145;&#24230;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#26368;&#23567;&#28145;&#24230;&#19982;CPWL&#20989;&#25968;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.15315</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26368;&#23567;&#28145;&#24230;
&lt;/p&gt;
&lt;p&gt;
On Minimal Depth in Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15315
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#20851;&#20110;&#26368;&#23567;&#28145;&#24230;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#26368;&#23567;&#28145;&#24230;&#19982;CPWL&#20989;&#25968;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;ReLU&#31070;&#32463;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#20197;&#21450;&#19982;&#34920;&#31034;&#20219;&#20309;&#36830;&#32493;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#65288;CPWL&#65289;&#25152;&#38656;&#30340;&#26368;&#23567;&#28145;&#24230;&#30456;&#20851;&#30340;&#29468;&#24819;&#30340;&#20851;&#31995;&#36827;&#34892;&#30740;&#31350;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#29305;&#24615;&#12290;&#30740;&#31350;&#37325;&#28857;&#21253;&#25324;&#23545;&#27714;&#21644;&#21644;&#26368;&#22823;&#36816;&#31639;&#30340;&#26368;&#23567;&#28145;&#24230;&#34920;&#31034;&#65292;&#20197;&#21450;&#23545;&#22810;&#38754;&#20307;&#31070;&#32463;&#32593;&#32476;&#30340;&#25506;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#27714;&#21644;&#36816;&#31639;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20851;&#20110;&#25805;&#20316;&#25968;&#26368;&#23567;&#28145;&#24230;&#30340;&#20805;&#20998;&#26465;&#20214;&#20197;&#25214;&#21040;&#36816;&#31639;&#30340;&#26368;&#23567;&#28145;&#24230;&#12290;&#30456;&#21453;&#65292;&#20851;&#20110;&#26368;&#22823;&#36816;&#31639;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#20363;&#23376;&#65292;&#35777;&#26126;&#20165;&#20381;&#36182;&#20110;&#25805;&#20316;&#25968;&#28145;&#24230;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#19981;&#20250;&#26263;&#31034;&#36816;&#31639;&#30340;&#26368;&#23567;&#28145;&#24230;&#12290;&#30740;&#31350;&#36824;&#32771;&#23519;&#20102;&#20984;CPWL&#20989;&#25968;&#20043;&#38388;&#30340;&#26368;&#23567;&#28145;&#24230;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15315v1 Announce Type: new  Abstract: A characterization of the representability of neural networks is relevant to comprehend their success in artificial intelligence. This study investigate two topics on ReLU neural network expressivity and their connection with a conjecture related to the minimum depth required for representing any continuous piecewise linear function (CPWL). The topics are the minimal depth representation of the sum and max operations, as well as the exploration of polytope neural networks. For the sum operation, we establish a sufficient condition on the minimal depth of the operands to find the minimal depth of the operation. In contrast, regarding the max operation, a comprehensive set of examples is presented, demonstrating that no sufficient conditions, depending solely on the depth of the operands, would imply a minimal depth for the operation. The study also examine the minimal depth relationship between convex CPWL functions. On polytope neural ne
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#22312;&#32447;&#39118;&#38505;&#36866;&#24212;&#24615;&#35843;&#25972;&#26469;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#21160;&#24577;&#36873;&#25321;&#35748;&#30693;&#39118;&#38505;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2310.05179</link><description>&lt;p&gt;
&#20855;&#26377;&#22312;&#32447;&#39118;&#38505;&#24863;&#30693;&#36866;&#24212;&#24615;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributional Reinforcement Learning with Online Risk-awareness Adaption
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.05179
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#22312;&#32447;&#39118;&#38505;&#36866;&#24212;&#24615;&#35843;&#25972;&#26469;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#21160;&#24577;&#36873;&#25321;&#35748;&#30693;&#39118;&#38505;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#38656;&#35201;&#32771;&#34385;&#27425;&#20248;&#32467;&#26524;&#65292;&#36825;&#21462;&#20915;&#20110;&#20195;&#29702;&#20154;&#23545;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#29087;&#24713;&#31243;&#24230;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;Distributional RL with Online Risk Adaption&#65288;DRL-ORA&#65289;&#65292;&#21487;&#20197;&#32508;&#21512;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#24182;&#21160;&#24577;&#36873;&#25321;&#35748;&#30693;&#39118;&#38505;&#27700;&#24179;&#65292;&#36890;&#36807;&#22312;&#32447;&#35299;&#20915;&#24635;&#21464;&#24046;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#39118;&#38505;&#27700;&#24179;&#36873;&#25321;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;Follow-The-Leader&#31867;&#22411;&#31639;&#27861;&#36827;&#34892;&#32593;&#26684;&#25628;&#32034;&#26469;&#26377;&#25928;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.05179v2 Announce Type: replace  Abstract: The use of reinforcement learning (RL) in practical applications requires considering sub-optimal outcomes, which depend on the agent's familiarity with the uncertain environment. Dynamically adjusting the level of epistemic risk over the course of learning can tactically achieve reliable optimal policy in safety-critical environments and tackle the sub-optimality of a static risk level. In this work, we introduce a novel framework, Distributional RL with Online Risk Adaption (DRL-ORA), which can quantify the aleatory and epistemic uncertainties compositely and dynamically select the epistemic risk levels via solving a total variation minimization problem online. The risk level selection can be efficiently achieved through grid search using a Follow-The-Leader type algorithm, and its offline oracle is related to "satisficing measure" (in the decision analysis community) under a special modification of the loss function. We show multi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#35299;&#37322;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;${\mathcal L}^2$&#20195;&#20215;&#26368;&#23567;&#21270;&#30340;&#26500;&#36896;&#26041;&#27861;&#33719;&#24471;&#20102;&#19968;&#20010;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#30340;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2309.10370</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#21644;&#22522;&#20110;${\mathcal L}^2$&#20195;&#20215;&#26368;&#23567;&#21270;&#30340;&#26500;&#36896;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Geometric structure of shallow neural networks and constructive ${\mathcal L}^2$ cost minimization. (arXiv:2309.10370v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#35299;&#37322;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;${\mathcal L}^2$&#20195;&#20215;&#26368;&#23567;&#21270;&#30340;&#26500;&#36896;&#26041;&#27861;&#33719;&#24471;&#20102;&#19968;&#20010;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32473;&#20986;&#20102;&#19968;&#20010;&#20960;&#20309;&#35299;&#37322;&#65306;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26500;&#30001;&#19968;&#20010;&#38544;&#34255;&#23618;&#12289;&#19968;&#20010;&#26012;&#22369;&#28608;&#27963;&#20989;&#25968;&#12289;&#19968;&#20010;${\mathcal L}^2$&#35889;&#33539;&#31867;&#65288;&#25110;&#32773;Hilbert-Schmidt&#65289;&#30340;&#20195;&#20215;&#20989;&#25968;&#12289;&#36755;&#20837;&#31354;&#38388;${\mathbb R}^M$&#12289;&#36755;&#20986;&#31354;&#38388;${\mathbb R}^Q$&#65288;&#20854;&#20013;$Q\leq M$&#65289;&#65292;&#20197;&#21450;&#35757;&#32451;&#36755;&#20837;&#26679;&#26412;&#25968;&#37327;$N&gt;QM$&#25152;&#29305;&#24449;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20195;&#20215;&#20989;&#25968;&#30340;&#26368;&#23567;&#20540;&#20855;&#26377;$O(\delta_P)$&#30340;&#19978;&#30028;&#65292;&#20854;&#20013;$\delta_P$&#34913;&#37327;&#20102;&#35757;&#32451;&#36755;&#20837;&#30340;&#20449;&#22122;&#27604;&#12290;&#25105;&#20204;&#20351;&#29992;&#36866;&#24212;&#20110;&#23646;&#20110;&#21516;&#19968;&#36755;&#20986;&#21521;&#37327;$y_j$&#30340;&#35757;&#32451;&#36755;&#20837;&#21521;&#37327;$\overline{x_{0,j}}$&#30340;&#25237;&#24433;&#26469;&#33719;&#24471;&#36817;&#20284;&#30340;&#20248;&#21270;&#22120;&#65292;&#20854;&#20013;$j=1,\dots,Q$&#12290;&#22312;&#29305;&#27530;&#24773;&#20917;$M=Q$&#19979;&#65292;&#25105;&#20204;&#26126;&#30830;&#30830;&#23450;&#20102;&#20195;&#20215;&#20989;&#25968;&#30340;&#19968;&#20010;&#30830;&#20999;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#65307;&#36825;&#20010;&#23574;&#38160;&#30340;&#20540;&#19982;&#23545;&#20110;$Q\leq M$&#25152;&#33719;&#24471;&#30340;&#19978;&#30028;&#20043;&#38388;&#26377;&#19968;&#20010;&#30456;&#23545;&#35823;&#24046;$O(\delta_P^2)$&#12290;&#19978;&#30028;&#35777;&#26126;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#26500;&#36896;&#24615;&#35757;&#32451;&#30340;&#32593;&#32476;&#65307;&#25105;&#20204;&#35777;&#26126;&#23427;&#27979;&#24230;&#20102;$Q$&#32500;&#31354;&#38388;&#20013;&#30340;&#32473;&#23450;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a geometric interpretation of the structure of shallow neural networks characterized by one hidden layer, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, input space ${\mathbb R}^M$, output space ${\mathbb R}^Q$ with $Q\leq M$, and training input sample size $N&gt;QM$. We prove an upper bound on the minimum of the cost function of order $O(\delta_P$ where $\delta_P$ measures the signal to noise ratio of training inputs. We obtain an approximate optimizer using projections adapted to the averages $\overline{x_{0,j}}$ of training input vectors belonging to the same output vector $y_j$, $j=1,\dots,Q$. In the special case $M=Q$, we explicitly determine an exact degenerate local minimum of the cost function; the sharp value differs from the upper bound obtained for $Q\leq M$ by a relative error $O(\delta_P^2)$. The proof of the upper bound yields a constructively trained network; we show that it metrizes the $Q$-dimen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#23376;&#26080;&#23548;&#25968;&#20248;&#21270;&#26041;&#27861;&#35299;&#37322;&#20026;&#26799;&#24230;&#19979;&#38477;&#30340;&#38543;&#26426;&#26494;&#24347;&#26041;&#27861;&#12290;&#27492;&#20248;&#21270;&#26041;&#27861;&#35777;&#26126;&#20102;&#38646;&#38454;&#26041;&#27861;&#24182;&#19981;&#19968;&#23450;&#20302;&#25928;&#25110;&#19981;&#20855;&#22791;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#20016;&#23500;&#31867;&#21035;&#30340;&#38750;&#20809;&#28369;&#21644;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#19979;&#20840;&#23616;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.09778</link><description>&lt;p&gt;
&#26799;&#24230;&#30495;&#30340;&#26159;&#20320;&#25152;&#38656;&#35201;&#30340;&#19968;&#20999;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Gradient is All You Need?. (arXiv:2306.09778v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#23376;&#26080;&#23548;&#25968;&#20248;&#21270;&#26041;&#27861;&#35299;&#37322;&#20026;&#26799;&#24230;&#19979;&#38477;&#30340;&#38543;&#26426;&#26494;&#24347;&#26041;&#27861;&#12290;&#27492;&#20248;&#21270;&#26041;&#27861;&#35777;&#26126;&#20102;&#38646;&#38454;&#26041;&#27861;&#24182;&#19981;&#19968;&#23450;&#20302;&#25928;&#25110;&#19981;&#20855;&#22791;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#20016;&#23500;&#31867;&#21035;&#30340;&#38750;&#20809;&#28369;&#21644;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#19979;&#20840;&#23616;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#19968;&#31181;&#26032;&#30340;&#22810;&#31890;&#23376;&#26080;&#23548;&#25968;&#20248;&#21270;&#26041;&#27861;&#32467;&#21512;&#26799;&#24230;&#19979;&#38477;&#30475;&#20316;&#38543;&#26426;&#26494;&#24347;&#26041;&#27861;&#65292;&#26469;&#35299;&#37322;&#22522;&#20110;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#36890;&#36807;&#31890;&#23376;&#20043;&#38388;&#30340;&#36890;&#35759;&#65292;&#36825;&#31181;&#20248;&#21270;&#26041;&#27861;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#34892;&#20026;&#65292;&#35777;&#26126;&#20102;&#38646;&#38454;&#26041;&#27861;&#24182;&#19981;&#19968;&#23450;&#20302;&#25928;&#25110;&#19981;&#20855;&#22791;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#38750;&#20809;&#28369;&#21644;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#20016;&#23500;&#31867;&#21035;&#19979;&#20840;&#23616;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we provide a novel analytical perspective on the theoretical understanding of gradient-based learning algorithms by interpreting consensus-based optimization (CBO), a recently proposed multi-particle derivative-free optimization method, as a stochastic relaxation of gradient descent. Remarkably, we observe that through communication of the particles, CBO exhibits a stochastic gradient descent (SGD)-like behavior despite solely relying on evaluations of the objective function. The fundamental value of such link between CBO and SGD lies in the fact that CBO is provably globally convergent to global minimizers for ample classes of nonsmooth and nonconvex objective functions, hence, on the one side, offering a novel explanation for the success of stochastic relaxations of gradient descent. On the other side, contrary to the conventional wisdom for which zero-order methods ought to be inefficient or not to possess generalization abilities, our results unveil an intrinsic gradi
&lt;/p&gt;</description></item><item><title>TimeMAE&#26159;&#19968;&#31181;&#26032;&#22411;&#33258;&#30417;&#30563;&#27169;&#22411;&#65292;&#21033;&#29992;transformer&#32593;&#32476;&#23558;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#22788;&#29702;&#25104;&#19968;&#31995;&#21015;&#19981;&#37325;&#21472;&#30340;&#23376;&#24207;&#21015;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#25513;&#30721;&#31574;&#30053;&#35206;&#30422;&#26412;&#22320;&#21270;&#23376;&#24207;&#21015;&#30340;&#35821;&#20041;&#21333;&#20803;&#65292;&#20197;&#23398;&#20064;&#21040;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#21487;&#20256;&#36882;&#30340;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2303.00320</link><description>&lt;p&gt;
TimeMAE: &#22522;&#20110;&#35299;&#32806;&#25513;&#30721;&#33258;&#32534;&#30721;&#22120;&#30340;&#33258;&#30417;&#30563;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
TimeMAE: Self-Supervised Representations of Time Series with Decoupled Masked Autoencoders. (arXiv:2303.00320v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00320
&lt;/p&gt;
&lt;p&gt;
TimeMAE&#26159;&#19968;&#31181;&#26032;&#22411;&#33258;&#30417;&#30563;&#27169;&#22411;&#65292;&#21033;&#29992;transformer&#32593;&#32476;&#23558;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#22788;&#29702;&#25104;&#19968;&#31995;&#21015;&#19981;&#37325;&#21472;&#30340;&#23376;&#24207;&#21015;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#25513;&#30721;&#31574;&#30053;&#35206;&#30422;&#26412;&#22320;&#21270;&#23376;&#24207;&#21015;&#30340;&#35821;&#20041;&#21333;&#20803;&#65292;&#20197;&#23398;&#20064;&#21040;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#21487;&#20256;&#36882;&#30340;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#20013;&#65292;&#21033;&#29992;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#27491;&#22312;&#21464;&#24471;&#36234;&#26469;&#36234;&#26222;&#36941;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#24456;&#22810;&#24037;&#20316;&#33268;&#21147;&#20110;&#24320;&#21457;&#38754;&#21521;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#33258;&#30417;&#30563;&#27169;&#22411;&#65292;&#20294;&#30001;&#20110;&#20165;&#22312;&#31232;&#30095;&#36880;&#28857;&#36755;&#20837;&#21333;&#20803;&#19978;&#36827;&#34892;&#21333;&#21521;&#32534;&#30721;&#65292;&#24403;&#21069;&#26041;&#27861;&#19981;&#33021;&#23398;&#20064;&#21040;&#26368;&#20248;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TimeMAE&#65292;&#19968;&#31181;&#22522;&#20110;transformer&#32593;&#32476;&#30340;&#23398;&#20064;&#21487;&#20256;&#36882;&#26102;&#38388;&#24207;&#21015;&#34920;&#31034;&#30340;&#26032;&#22411;&#33258;&#30417;&#30563;&#33539;&#24335;&#12290;TimeMAE&#30340;&#29420;&#29305;&#29305;&#28857;&#22312;&#20110;&#23558;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#36890;&#36807;&#31383;&#21475;&#20999;&#29255;&#20998;&#21306;&#22788;&#29702;&#25104;&#19968;&#31995;&#21015;&#19981;&#37325;&#21472;&#30340;&#23376;&#24207;&#21015;&#65292;&#28982;&#21518;&#36890;&#36807;&#38543;&#26426;&#25513;&#30721;&#31574;&#30053;&#35206;&#30422;&#26412;&#22320;&#21270;&#23376;&#24207;&#21015;&#30340;&#35821;&#20041;&#21333;&#20803;&#12290;&#36825;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35774;&#32622;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#36798;&#21040;&#19968;&#20030;&#19977;&#24471;&#30340;&#30446;&#26631;&#65292;&#21363;&#65288;1&#65289;&#23398;&#20064;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65307;
&lt;/p&gt;
&lt;p&gt;
Enhancing the expressive capacity of deep learning-based time series models with self-supervised pre-training has become ever-increasingly prevalent in time series classification. Even though numerous efforts have been devoted to developing self-supervised models for time series data, we argue that the current methods are not sufficient to learn optimal time series representations due to solely unidirectional encoding over sparse point-wise input units. In this work, we propose TimeMAE, a novel self-supervised paradigm for learning transferrable time series representations based on transformer networks. The distinct characteristics of the TimeMAE lie in processing each time series into a sequence of non-overlapping sub-series via window-slicing partitioning, followed by random masking strategies over the semantic units of localized sub-series. Such a simple yet effective setting can help us achieve the goal of killing three birds with one stone, i.e., (1) learning enriched contextual r
&lt;/p&gt;</description></item></channel></rss>