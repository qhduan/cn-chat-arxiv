<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35770;&#25991;&#25581;&#31034;&#20102;&#22312;&#26576;&#20123;&#20219;&#21153;&#31867;&#21035;&#20013;&#65292;&#25945;&#24072;&#24378;&#21046;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#22312;&#31532;&#19968;&#26102;&#38388;&#23398;&#20064;&#21040;&#20934;&#30830;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#65292;&#36827;&#32780;&#23548;&#33268;&#27169;&#22411;&#22833;&#36133;&#30340;&#19968;&#33324;&#26426;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.06963</link><description>&lt;p&gt;
&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30340;&#38519;&#38449;
&lt;/p&gt;
&lt;p&gt;
The pitfalls of next-token prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06963
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25581;&#31034;&#20102;&#22312;&#26576;&#20123;&#20219;&#21153;&#31867;&#21035;&#20013;&#65292;&#25945;&#24072;&#24378;&#21046;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#22312;&#31532;&#19968;&#26102;&#38388;&#23398;&#20064;&#21040;&#20934;&#30830;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#65292;&#36827;&#32780;&#23548;&#33268;&#27169;&#22411;&#22833;&#36133;&#30340;&#19968;&#33324;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#31687;&#20851;&#20110;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30340;&#35770;&#25991;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#30452;&#35266;&#30340;&#25285;&#24551;&#65306;&#19968;&#20010;&#20165;&#20165;&#22522;&#20110;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30340;&#27169;&#22411;&#26159;&#21542;&#33021;&#24544;&#23454;&#22320;&#27169;&#25311;&#20154;&#31867;&#26234;&#33021;&#12290;&#25105;&#20204;&#35748;&#20026;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#20013;&#32463;&#24120;&#28151;&#28102;&#30340;&#20004;&#20010;&#38454;&#27573; -- &#33258;&#22238;&#24402;&#25512;&#26029;&#21644;&#25945;&#24072;&#24378;&#21046;&#35757;&#32451; -- &#24517;&#39035;&#34987;&#21306;&#21035;&#23545;&#24453;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#19968;&#33324;&#26426;&#21046;&#65292;&#23637;&#31034;&#20102;&#25945;&#24072;&#24378;&#21046;&#22914;&#20309;&#22833;&#36133;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#35745;&#21010;&#20219;&#21153;&#65292;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;Transformer&#21644;Mamba&#26550;&#26500;&#22312;&#23454;&#36341;&#20013;&#20197;&#36825;&#31181;&#26041;&#24335;&#22833;&#36133; -- &#23613;&#31649;&#20219;&#21153;&#26412;&#36523;&#24456;&#23481;&#26131;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06963v1 Announce Type: cross  Abstract: Can a mere next-token predictor faithfully model human intelligence? We crystallize this intuitive concern, which is fragmented in the literature. As a starting point, we argue that the two often-conflated phases of next-token prediction -- autoregressive inference and teacher-forced training -- must be treated distinctly. The popular criticism that errors can compound during autoregressive inference, crucially assumes that teacher-forcing has learned an accurate next-token predictor. This assumption sidesteps a more deep-rooted problem we expose: in certain classes of tasks, teacher-forcing can simply fail to learn an accurate next-token predictor in the first place. We describe a general mechanism of how teacher-forcing can fail, and design a minimal planning task where both the Transformer and the Mamba architecture empirically fail in that manner -- remarkably, despite the task being straightforward to learn. We provide preliminary
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24635;&#32467;&#20102;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;&#38450;&#24481;&#22312;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#30740;&#31350;&#12290;&#21015;&#20986;&#20102;&#29616;&#26377;&#30340;&#19981;&#23433;&#20840;&#22240;&#32032;&#65292;&#24182;&#34920;&#26126;&#20102;&#26412;&#39046;&#22495;&#30340;&#26032;&#20852;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2306.06123</link><description>&lt;p&gt;
&#12298;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;&#38450;&#24481;&#65306;&#35843;&#26597;&#25253;&#21578;&#12299;
&lt;/p&gt;
&lt;p&gt;
Adversarial Attacks and Defenses in Explainable Artificial Intelligence: A Survey. (arXiv:2306.06123v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24635;&#32467;&#20102;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;&#38450;&#24481;&#22312;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#30740;&#31350;&#12290;&#21015;&#20986;&#20102;&#29616;&#26377;&#30340;&#19981;&#23433;&#20840;&#22240;&#32032;&#65292;&#24182;&#34920;&#26126;&#20102;&#26412;&#39046;&#22495;&#30340;&#26032;&#20852;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#34987;&#25551;&#32472;&#20026;&#35843;&#35797;&#21644;&#20449;&#20219;&#32479;&#35745;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#27835;&#30103;&#26041;&#24335;&#65292;&#20197;&#21450;&#35299;&#37322;&#23427;&#20204;&#30340;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#23545;&#25239;&#26426;&#22120;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#31361;&#20986;&#20102;&#26368;&#26032;&#35299;&#37322;&#30340;&#23616;&#38480;&#24615;&#21644;&#28431;&#27934;&#65292;&#36825;&#20123;&#36827;&#23637;&#20196;&#20154;&#23545;&#20854;&#23433;&#20840;&#24615;&#21644;&#21487;&#20449;&#24230;&#20135;&#29983;&#36136;&#30097;&#12290;&#25805;&#32437;&#12289;&#27450;&#39575;&#25110;&#27927;&#30333;&#27169;&#22411;&#25512;&#29702;&#35777;&#25454;&#30340;&#21487;&#33021;&#24615;&#22312;&#39640;&#39118;&#38505;&#20915;&#31574;&#21644;&#30693;&#35782;&#21457;&#29616;&#20013;&#20135;&#29983;&#19981;&#21033;&#21518;&#26524;&#12290;&#26412;&#25991;&#24635;&#32467;&#20102;50&#22810;&#31687;&#35770;&#25991;&#30340;&#30740;&#31350;&#65292;&#27010;&#36848;&#20102;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35299;&#37322;&#30340;&#23545;&#25239;&#25915;&#20987;&#20197;&#21450;&#20844;&#24179;&#24230;&#37327;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#22914;&#20309;&#38450;&#24481;&#25915;&#20987;&#24182;&#35774;&#35745;&#40065;&#26834;&#30340;&#35299;&#37322;&#26041;&#27861;&#12290;&#25105;&#20204;&#21015;&#20986;XAI&#20013;&#29616;&#26377;&#30340;&#19981;&#23433;&#20840;&#22240;&#32032;&#65292;&#24182;&#27010;&#36848;&#20102;&#23545;&#25239;&#24615;XAI&#65288;AdvXAI&#65289;&#30340;&#26032;&#20852;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable artificial intelligence (XAI) methods are portrayed as a remedy for debugging and trusting statistical and deep learning models, as well as interpreting their predictions. However, recent advances in adversarial machine learning highlight the limitations and vulnerabilities of state-of-the-art explanations, putting their security and trustworthiness into question. The possibility of manipulating, fooling or fairwashing evidence of the model's reasoning has detrimental consequences when applied in high-stakes decision-making and knowledge discovery. This concise survey of over 50 papers summarizes research concerning adversarial attacks on explanations of machine learning models, as well as fairness metrics. We discuss how to defend against attacks and design robust interpretation methods. We contribute a list of existing insecurities in XAI and outline the emerging research directions in adversarial XAI (AdvXAI).
&lt;/p&gt;</description></item><item><title>Global-QSGD&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#20840;&#23616;&#32553;&#25918;&#37327;&#21270;&#26426;&#21046;&#65292;&#21487;&#20197;&#25552;&#39640;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#25928;&#29575;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#26114;&#36149;&#30340;&#35823;&#24046;&#21453;&#39304;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#36798;$O(\ sqrt{n})$&#30340;&#39069;&#22806;&#21387;&#32553;&#27604;&#12290;</title><link>http://arxiv.org/abs/2305.18627</link><description>&lt;p&gt;
&#20840;&#23616;&#32553;&#25918;&#37327;&#21270;&#65306;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#23454;&#29992;&#30340;&#26080;&#28014;&#28857;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Global-QSGD: Practical Floatless Quantization for Distributed Learning with Theoretical Guarantees. (arXiv:2305.18627v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18627
&lt;/p&gt;
&lt;p&gt;
Global-QSGD&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#20840;&#23616;&#32553;&#25918;&#37327;&#21270;&#26426;&#21046;&#65292;&#21487;&#20197;&#25552;&#39640;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#25928;&#29575;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#26114;&#36149;&#30340;&#35823;&#24046;&#21453;&#39304;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#36798;$O(\ sqrt{n})$&#30340;&#39069;&#22806;&#21387;&#32553;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;&#26159;&#25512;&#21160;&#28145;&#24230;&#23398;&#20064;&#36817;&#26399;&#36827;&#23637;&#30340;&#20027;&#35201;&#39537;&#21160;&#21147;&#12290;&#28982;&#32780;&#65292;&#36890;&#20449;&#24120;&#24120;&#26159;&#31995;&#32479;&#30340;&#20027;&#35201;&#29942;&#39048;&#24182;&#20855;&#26377;&#39640;&#26114;&#30340;&#20195;&#20215;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#35774;&#35745;&#39640;&#25928;&#30340;&#36890;&#20449;&#26426;&#21046;&#65292;&#26082;&#33021;&#22312;&#32463;&#39564;&#19978;&#25552;&#39640;&#21534;&#21520;&#37327;&#65292;&#21448;&#33021;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20840;&#23616;-QSGD&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#37327;&#21270;&#36816;&#31639;&#31526;&#65292;&#36890;&#36807;&#20840;&#23616;&#32553;&#25918;&#35774;&#35745;&#26469;&#21152;&#36895;&#22522;&#20110;&#20998;&#24067;&#24335;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;Global-QSGD&#26159;&#31532;&#19968;&#20010;&#29702;&#35770;&#19978;&#20005;&#26684;&#30340;Allreduce&#20860;&#23481;&#21387;&#32553;&#26426;&#21046;&#65292;&#36890;&#36807;&#22312;&#21387;&#32553;&#35823;&#24046;&#21644;&#36890;&#20449;&#33410;&#30465;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#26469;&#23454;&#29616;&#21487;&#35777;&#26126;&#30340;&#21152;&#36895;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#30001;&#20110;&#20854;&#22266;&#26377;&#30340;&#26080;&#20559;&#24615;&#65292;Global-QSGD&#19981;&#20381;&#36182;&#26114;&#36149;&#30340;&#35823;&#24046;&#21453;&#39304;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#27969;&#34892;&#30340;QSGD&#37327;&#21270;&#33021;&#25552;&#20379;&#39640;&#36798;$O(\sqrt{n})$ &#30340;&#39069;&#22806;&#21387;&#32553;&#27604;&#65288;&#20854;&#20013;$n$&#34920;&#31034;&#24037;&#20316;&#32773;&#30340;&#25968;&#37327;&#65289;&#12290;&#20026;&#20102;&#33719;&#24471;&#29702;&#35770;&#20445;&#35777;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#20449;&#24687;&#35770;&#21644;&#20984;&#20998;&#26512;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient distributed training is a principal driver of recent advances in deep learning. However, communication often proves costly and becomes the primary bottleneck in these systems. As a result, there is a demand for the design of efficient communication mechanisms that can empirically boost throughput while providing theoretical guarantees. In this work, we introduce Global-QSGD, a novel family of quantization operators, engineered to accelerate distributed training based on global scaling. We demonstrate that Global-QSGD is the first theoretically rigorous Allreduce-compatible compression mechanism that achieves a provable speed-up by striking a balance between compression error and communication savings. Importantly, Global-QSGD does not rely on costly error feedback due to its inherent unbiasedness and offers up to $O(\sqrt{n})$ additional compression ratio compared to the popular QSGD quantization ($n$ represents the number of workers). To obtain theoretical guarantees, we gen
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#25991;&#31456;&#25581;&#31034;&#20102;&#20851;&#20110;&#31038;&#20132;&#26426;&#22120;&#20154;&#30740;&#31350;&#30340;&#26222;&#36941;&#35823;&#35299;&#65292;&#24378;&#35843;&#38656;&#35201;&#20197;&#20005;&#35880;&#12289;&#20844;&#27491;&#21644;&#36127;&#36131;&#20219;&#30340;&#26041;&#24335;&#35752;&#35770;&#34394;&#20551;&#20449;&#24687;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2303.17251</link><description>&lt;p&gt;
&#25581;&#24320;&#23545;&#31038;&#20132;&#26426;&#22120;&#20154;&#30740;&#31350;&#30340;&#35823;&#35299;
&lt;/p&gt;
&lt;p&gt;
Demystifying Misconceptions in Social Bots Research. (arXiv:2303.17251v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17251
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#25991;&#31456;&#25581;&#31034;&#20102;&#20851;&#20110;&#31038;&#20132;&#26426;&#22120;&#20154;&#30740;&#31350;&#30340;&#26222;&#36941;&#35823;&#35299;&#65292;&#24378;&#35843;&#38656;&#35201;&#20197;&#20005;&#35880;&#12289;&#20844;&#27491;&#21644;&#36127;&#36131;&#20219;&#30340;&#26041;&#24335;&#35752;&#35770;&#34394;&#20551;&#20449;&#24687;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#26426;&#22120;&#20154;&#31185;&#23398;&#23547;&#27714;&#35299;&#20915;&#32593;&#32476;&#34394;&#20551;&#20449;&#24687;&#26368;&#21463;&#20105;&#35758;&#30340;&#24418;&#24335;&#20043;&#19968;&#30340;&#30693;&#35782;&#21644;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#31038;&#20132;&#26426;&#22120;&#20154;&#30740;&#31350;&#21463;&#21040;&#26222;&#36941;&#30340;&#20559;&#35265;&#12289;&#22840;&#22823;&#30340;&#32467;&#26524;&#21644;&#35823;&#35299;&#30340;&#22256;&#25200;&#65292;&#36825;&#20123;&#37117;&#20026;&#27495;&#20041;&#12289;&#19981;&#20999;&#23454;&#38469;&#30340;&#26399;&#26395;&#21644;&#30475;&#20284;&#26080;&#27861;&#35843;&#21644;&#30340;&#21457;&#29616;&#25171;&#19979;&#20102;&#22522;&#30784;&#12290;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#23545;&#20110;&#30830;&#20445;&#21487;&#38752;&#30340;&#35299;&#20915;&#26041;&#26696;&#21644;&#37325;&#30003;&#31185;&#23398;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#20462;&#35746;&#20102;&#31038;&#20132;&#26426;&#22120;&#20154;&#30740;&#31350;&#20013;&#30340;&#19968;&#20123;&#26368;&#26032;&#32467;&#26524;&#65292;&#24378;&#35843;&#21644;&#32416;&#27491;&#20102;&#20107;&#23454;&#38169;&#35823;&#20197;&#21450;&#26041;&#27861;&#35770;&#21644;&#27010;&#24565;&#38382;&#39064;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25581;&#24320;&#20102;&#26222;&#36941;&#30340;&#35823;&#35299;&#65292;&#35299;&#20915;&#20102;&#26377;&#20851;&#22914;&#20309;&#35752;&#35770;&#31038;&#20132;&#26426;&#22120;&#20154;&#30740;&#31350;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#20197;&#20005;&#35880;&#12289;&#20844;&#27491;&#21644;&#36127;&#36131;&#20219;&#30340;&#26041;&#24335;&#35752;&#35770;&#34394;&#20551;&#20449;&#24687;&#30740;&#31350;&#30340;&#24517;&#35201;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#30830;&#23450;&#24182;&#39539;&#26021;&#31038;&#20132;&#26426;&#22120;&#20154;&#30740;&#31350;&#30340;&#25903;&#25345;&#32773;&#21644;&#21453;&#23545;&#32773;&#24120;&#29992;&#30340;&#35884;&#35823;&#35770;&#35777;&#65292;&#25903;&#25345;&#36825;&#31181;&#21162;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The science of social bots seeks knowledge and solutions to one of the most debated forms of online misinformation. Yet, social bots research is plagued by widespread biases, hyped results, and misconceptions that set the stage for ambiguities, unrealistic expectations, and seemingly irreconcilable findings. Overcoming such issues is instrumental towards ensuring reliable solutions and reaffirming the validity of the scientific method. In this contribution we revise some recent results in social bots research, highlighting and correcting factual errors as well as methodological and conceptual issues. More importantly, we demystify common misconceptions, addressing fundamental points on how social bots research is discussed. Our analysis surfaces the need to discuss misinformation research in a rigorous, unbiased, and responsible way. This article bolsters such effort by identifying and refuting common fallacious arguments used by both proponents and opponents of social bots research as
&lt;/p&gt;</description></item></channel></rss>