<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#24066;&#22330;&#33829;&#38144;&#21160;&#24577;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#26041;&#31243;&#65292;&#20934;&#30830;&#25429;&#25417;&#20102;&#24191;&#21578;&#25903;&#20986;&#19982;&#28040;&#36153;&#32773;&#21453;&#24212;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.02175</link><description>&lt;p&gt;
&#28040;&#36153;&#32773;&#21453;&#24212;&#30340;&#31038;&#20250;&#21160;&#24577;&#65306;&#34701;&#21512;&#32479;&#35745;&#29289;&#29702;&#23398;&#19982;&#33829;&#38144;&#21160;&#24577;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Social Dynamics of Consumer Response: A Unified Framework Integrating Statistical Physics and Marketing Dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02175
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#24066;&#22330;&#33829;&#38144;&#21160;&#24577;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#26041;&#31243;&#65292;&#20934;&#30830;&#25429;&#25417;&#20102;&#24191;&#21578;&#25903;&#20986;&#19982;&#28040;&#36153;&#32773;&#21453;&#24212;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#28040;&#36153;&#32773;&#23545;&#24191;&#21578;&#36755;&#20837;&#30340;&#21453;&#24212;&#23545;&#20110;&#26088;&#22312;&#20248;&#21270;&#24191;&#21578;&#31574;&#30053;&#24182;&#25552;&#39640;&#24191;&#21578;&#27963;&#21160;&#26377;&#25928;&#24615;&#30340;&#33829;&#38144;&#20154;&#21592;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#24212;&#29992;&#28304;&#33258;&#29289;&#29702;&#23398;&#21644;&#31038;&#20250;&#24515;&#29702;&#23398;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#28040;&#36153;&#32773;&#34892;&#20026;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21019;&#26032;&#30340;&#26041;&#31243;&#65292;&#25429;&#25417;&#20102;&#24191;&#21578;&#25903;&#20986;&#19982;&#28040;&#36153;&#32773;&#21453;&#24212;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21033;&#29992;&#20102;&#35832;&#22914;&#23545;&#31216;&#24615;&#12289;&#26631;&#24230;&#24459;&#21644;&#30456;&#21464;&#31561;&#27010;&#24565;&#12290;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;&#26041;&#31243;&#39564;&#35777;&#19982;Michaelis-Menten&#21644;Hill&#26041;&#31243;&#31561;&#33879;&#21517;&#27169;&#22411;&#30456;&#27604;&#36739;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#22312;&#20934;&#30830;&#34920;&#31034;&#28040;&#36153;&#32773;&#21453;&#24212;&#21160;&#24577;&#22797;&#26434;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20998;&#26512;&#24378;&#35843;&#20102;&#20851;&#38190;&#27169;&#22411;&#21442;&#25968;&#65288;&#22914;&#33829;&#38144;&#25928;&#26524;&#12289;&#21453;&#24212;&#25935;&#24863;&#24230;&#21644;&#34892;&#20026;&#25935;&#24863;&#24230;&#65289;&#23545;&#24433;&#21709;&#28040;&#36153;&#32773;&#34892;&#20026;&#30340;&#37325;&#35201;&#24615;&#12290;&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#24191;&#21578;&#21830;&#21644;&#33829;&#38144;&#20154;&#21592;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02175v1 Announce Type: cross  Abstract: Comprehending how consumers react to advertising inputs is essential for marketers aiming to optimize advertising strategies and improve campaign effectiveness. This study examines the complex nature of consumer behaviour by applying theoretical frameworks derived from physics and social psychology. We present an innovative equation that captures the relation between spending on advertising and consumer response, using concepts such as symmetries, scaling laws, and phase transitions. By validating our equation against well-known models such as the Michaelis-Menten and Hill equations, we prove its effectiveness in accurately representing the complexity of consumer response dynamics. The analysis emphasizes the importance of key model parameters, such as marketing effectiveness, response sensitivity, and behavioural sensitivity, in influencing consumer behaviour. The work explores the practical implications for advertisers and marketers,
&lt;/p&gt;</description></item><item><title>QUCE&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#20943;&#23569;&#36335;&#24452;&#19981;&#30830;&#23450;&#24615;&#26469;&#37327;&#21270;&#21644;&#32531;&#35299;&#22522;&#20110;&#36335;&#24452;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#23545;&#25239;&#24615;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.17516</link><description>&lt;p&gt;
QUCE: &#20943;&#23569;&#21644;&#37327;&#21270;&#22522;&#20110;&#36335;&#24452;&#30340;&#19981;&#30830;&#23450;&#24615;&#20197;&#29983;&#25104;&#23545;&#25239;&#24615;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17516
&lt;/p&gt;
&lt;p&gt;
QUCE&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#20943;&#23569;&#36335;&#24452;&#19981;&#30830;&#23450;&#24615;&#26469;&#37327;&#21270;&#21644;&#32531;&#35299;&#22522;&#20110;&#36335;&#24452;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#23545;&#25239;&#24615;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17516v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#23398;&#31185; &#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#26368;&#31361;&#20986;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;DNNs&#30340;&#26377;&#25928;&#24615;&#38543;&#30528;&#26368;&#36817;&#35745;&#31639;&#33021;&#21147;&#30340;&#22686;&#21152;&#32780;&#28608;&#22686;&#65292;&#20351;&#24471;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#25193;&#23637;&#21040;&#22788;&#29702;&#22823;&#25968;&#25454;&#20013;&#30340;&#37325;&#35201;&#22797;&#26434;&#24615;&#20197;&#24212;&#23545;&#39044;&#27979;&#25361;&#25112;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;DNN&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#25552;&#39640;&#65292;&#21487;&#35299;&#37322;&#24615;&#38477;&#20302;&#12290;&#38024;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#35832;&#22914;&#23545;&#25239;&#26799;&#24230;&#25972;&#21512;&#65288;AGI&#65289;&#36825;&#26679;&#30340;&#21487;&#35299;&#37322;&#27169;&#22411;&#21033;&#29992;DNN&#25552;&#20379;&#30340;&#22522;&#20110;&#36335;&#24452;&#30340;&#26799;&#24230;&#26469;&#38416;&#26126;&#23427;&#20204;&#30340;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#24403;&#26799;&#24230;&#22312;&#36234;&#30028;&#36335;&#24452;&#36941;&#21382;&#26399;&#38388;&#34920;&#29616;&#20986;&#19981;&#35268;&#21017;&#24615;&#26102;&#65292;&#22522;&#20110;&#36335;&#24452;&#30340;&#35299;&#37322;&#22120;&#30340;&#24615;&#33021;&#21487;&#33021;&#20250;&#21463;&#21040;&#25439;&#23475;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Quantified Uncertainty Counterfactual Explanations&#65288;QUCE&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26088;&#22312;&#20943;&#23569;&#36335;&#24452;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#20197;&#32531;&#35299;&#36234;&#30028;&#36941;&#21382;&#12290; QUCE&#19981;&#20165;&#22312;&#25552;&#20986;&#35299;&#37322;&#26102;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17516v1 Announce Type: cross  Abstract: Deep Neural Networks (DNNs) stand out as one of the most prominent approaches within the Machine Learning (ML) domain. The efficacy of DNNs has surged alongside recent increases in computational capacity, allowing these approaches to scale to significant complexities for addressing predictive challenges in big data. However, as the complexity of DNN models rises, interpretability diminishes. In response to this challenge, explainable models such as Adversarial Gradient Integration (AGI) leverage path-based gradients provided by DNNs to elucidate their decisions. Yet the performance of path-based explainers can be compromised when gradients exhibit irregularities during out-of-distribution path traversal. In this context, we introduce Quantified Uncertainty Counterfactual Explanations (QUCE), a method designed to mitigate out-of-distribution traversal by minimizing path uncertainty. QUCE not only quantifies uncertainty when presenting e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#32422;&#26463;&#31639;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#32465;&#23450;&#26368;&#23567;&#21644;&#26368;&#22823;&#25928;&#29992;&#20540;&#26469;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#28857;&#24182;&#20002;&#24323;&#19981;&#37325;&#35201;&#30340;&#28857;&#12290;</title><link>https://arxiv.org/abs/2402.16442</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#37197;&#23545;&#27425;&#27169;&#27169;&#20989;&#25968;&#30340;&#20998;&#24067;&#24335;&#22823;&#20110;&#20869;&#23384;&#30340;&#23376;&#38598;&#36873;&#25321;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#32422;&#26463;&#31639;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#32465;&#23450;&#26368;&#23567;&#21644;&#26368;&#22823;&#25928;&#29992;&#20540;&#26469;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#28857;&#24182;&#20002;&#24323;&#19981;&#37325;&#35201;&#30340;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#23398;&#20064;&#38382;&#39064;&#21462;&#20915;&#20110;&#23376;&#38598;&#36873;&#25321;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#30830;&#23450;&#19968;&#32452;&#37325;&#35201;&#21644;&#20195;&#34920;&#24615;&#30340;&#28857;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#21487;&#35777;&#20272;&#35745;&#36817;&#20284;&#20445;&#35777;&#30340;&#26032;&#39062;&#20998;&#24067;&#24335;&#32422;&#26463;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#36845;&#20195;&#32465;&#23450;&#26368;&#23567;&#21644;&#26368;&#22823;&#25928;&#29992;&#20540;&#26469;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#28857;&#24182;&#20002;&#24323;&#19981;&#37325;&#35201;&#30340;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16442v1 Announce Type: cross  Abstract: Many learning problems hinge on the fundamental problem of subset selection, i.e., identifying a subset of important and representative points. For example, selecting the most significant samples in ML training cannot only reduce training costs but also enhance model quality. Submodularity, a discrete analogue of convexity, is commonly used for solving subset selection problems. However, existing algorithms for optimizing submodular functions are sequential, and the prior distributed methods require at least one central machine to fit the target subset. In this paper, we relax the requirement of having a central machine for the target subset by proposing a novel distributed bounding algorithm with provable approximation guarantees. The algorithm iteratively bounds the minimum and maximum utility values to select high quality points and discard the unimportant ones. When bounding does not find the complete subset, we use a multi-round, 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#65292;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.01900</link><description>&lt;p&gt;
&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Distributional Off-policy Evaluation with Bellman Residual Minimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01900
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#65292;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#30340;&#38382;&#39064;&#65292;&#23427;&#26159;&#35768;&#22810;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#31639;&#27861;&#30340;&#22522;&#30784;&#12290;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26041;&#27861;&#65288;&#20381;&#36182;&#20110;&#26368;&#22823;&#20540;-&#25193;&#23637;&#30340;&#32479;&#35745;&#36317;&#31163;&#65292;&#22914;&#26368;&#22823;&#20540;Wasserstein&#36317;&#31163;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30740;&#31350;&#29992;&#20110;&#37327;&#21270;&#20998;&#24067;&#24335;Bellman&#27531;&#24046;&#30340;&#26399;&#26395;-&#25193;&#23637;&#30340;&#32479;&#35745;&#36317;&#31163;&#65292;&#24182;&#19988;&#35777;&#26126;&#23427;&#21487;&#20197;&#19978;&#30028;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#30340;&#26399;&#26395;&#35823;&#24046;&#12290;&#22522;&#20110;&#36825;&#20010;&#26377;&#21560;&#24341;&#21147;&#30340;&#24615;&#36136;&#65292;&#36890;&#36807;&#23558;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#26694;&#26550;&#25512;&#24191;&#21040;DRL&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#27493;&#24341;&#23548;&#36807;&#31243;&#30340;&#26041;&#27861;&#30340;&#21464;&#20307;&#65292;&#20197;&#23454;&#29616;&#22810;&#27493;&#25193;&#23637;&#12290;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#27493;&#38271;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of distributional off-policy evaluation which serves as the foundation of many distributional reinforcement learning (DRL) algorithms. In contrast to most existing works (that rely on supremum-extended statistical distances such as supremum-Wasserstein distance), we study the expectation-extended statistical distance for quantifying the distributional Bellman residuals and show that it can upper bound the expected error of estimating the return distribution. Based on this appealing property, by extending the framework of Bellman residual minimization to DRL, we propose a method called Energy Bellman Residual Minimizer (EBRM) to estimate the return distribution. We establish a finite-sample error bound for the EBRM estimator under the realizability assumption. Furthermore, we introduce a variant of our method based on a multi-step bootstrapping procedure to enable multi-step extension. By selecting an appropriate step level, we obtain a better error bound for thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#24182;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;&#36827;&#19968;&#27493;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#12290;</title><link>http://arxiv.org/abs/2311.01797</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#24182;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;&#36827;&#19968;&#27493;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#24314;&#31435;&#19968;&#20010;&#38543;&#26426;&#20256;&#36755;&#26144;&#23556;&#65292;&#23558;&#32463;&#39564;&#35266;&#27979;&#21040;&#30340;&#20294;&#26410;&#30693;&#30340;&#30446;&#26631;&#20998;&#24067;&#19982;&#24050;&#30693;&#30340;&#20808;&#39564;&#20998;&#24067;&#32852;&#31995;&#36215;&#26469;&#12290;&#23613;&#31649;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23545;&#20854;&#27867;&#21270;&#33021;&#21147;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#26410;&#20805;&#20998;&#21457;&#23637;&#12290;&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#34920;&#26126;&#22312;&#26679;&#26412;&#22823;&#23567;$n$&#21644;&#27169;&#22411;&#23481;&#37327;$m$&#19978;&#37117;&#23384;&#22312;&#22810;&#39033;&#24335;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;($O(n^{-2/5}+m^{-4/5})$)&#65292;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#65288;&#21363;&#25968;&#25454;&#32500;&#24230;&#19981;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#19968;&#20010;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#65292;&#20854;&#20013;&#30446;&#26631;&#20998;&#24067;&#34987;&#25551;&#32472;&#20026;&#19968;&#31995;&#21015;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a class of generative models that serve to establish a stochastic transport map between an empirically observed, yet unknown, target distribution and a known prior. Despite their remarkable success in real-world applications, a theoretical understanding of their generalization capabilities remains underdeveloped. This work embarks on a comprehensive theoretical exploration of the generalization attributes of diffusion models. We establish theoretical estimates of the generalization gap that evolves in tandem with the training dynamics of score-based diffusion models, suggesting a polynomially small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$ and the model capacity $m$, evading the curse of dimensionality (i.e., not exponentially large in the data dimension) when early-stopped. Furthermore, we extend our quantitative analysis to a data-dependent scenario, wherein target distributions are portrayed as a succession of densities with progr
&lt;/p&gt;</description></item><item><title>RelationMatch&#26159;&#19968;&#31181;&#21033;&#29992;&#30697;&#38453;&#20132;&#21449;&#29109;&#65288;MCE&#65289;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21305;&#37197;&#25209;&#20869;&#20851;&#31995;&#65292;&#26377;&#25928;&#25552;&#39640;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#30417;&#30563;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.10397</link><description>&lt;p&gt;
RelationMatch&#65306;&#29992;&#20110;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#25209;&#20869;&#20851;&#31995;&#21305;&#37197;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
RelationMatch: Matching In-batch Relationships for Semi-supervised Learning. (arXiv:2305.10397v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10397
&lt;/p&gt;
&lt;p&gt;
RelationMatch&#26159;&#19968;&#31181;&#21033;&#29992;&#30697;&#38453;&#20132;&#21449;&#29109;&#65288;MCE&#65289;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21305;&#37197;&#25209;&#20869;&#20851;&#31995;&#65292;&#26377;&#25928;&#25552;&#39640;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#30417;&#30563;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#36890;&#36807;&#21033;&#29992;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#21644;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#30340;&#20449;&#24687;&#65292;&#24050;&#32463;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#31639;&#27861;&#36890;&#24120;&#38598;&#20013;&#22312;&#26469;&#33258;&#30456;&#21516;&#26469;&#28304;&#30340;&#25104;&#23545;&#25968;&#25454;&#28857;&#30340;&#39044;&#27979;&#23545;&#20934;&#19978;&#65292;&#24182;&#24573;&#30053;&#20102;&#27599;&#20010;&#25209;&#27425;&#20869;&#30340;&#28857;&#38388;&#20851;&#31995;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;RelationMatch&#65292;&#23427;&#21033;&#29992;&#19968;&#31181;&#30697;&#38453;&#20132;&#21449;&#29109;&#65288;MCE&#65289;&#25439;&#22833;&#20989;&#25968;&#26469;&#21457;&#25496;&#25209;&#20869;&#20851;&#31995;&#12290;&#36890;&#36807;&#24212;&#29992;MCE&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#35270;&#35273;&#25968;&#25454;&#38598;&#20013;&#22987;&#32456;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#22914;FixMatch&#21644;FlexMatch&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#20165;&#20351;&#29992;40&#20010;&#26631;&#31614;&#30340;STL-10&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#30456;&#23545;&#20110;FlexMatch&#26377;15.21&#65285;&#30340;&#26174;&#33879;&#25552;&#39640;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;MCE&#24212;&#29992;&#20110;&#30417;&#30563;&#23398;&#20064;&#22330;&#26223;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#19968;&#33268;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning has achieved notable success by leveraging very few labeled data and exploiting the wealth of information derived from unlabeled data. However, existing algorithms usually focus on aligning predictions on paired data points augmented from an identical source, and overlook the inter-point relationships within each batch. This paper introduces a novel method, RelationMatch, which exploits in-batch relationships with a matrix cross-entropy (MCE) loss function. Through the application of MCE, our proposed method consistently surpasses the performance of established state-of-the-art methods, such as FixMatch and FlexMatch, across a variety of vision datasets. Notably, we observed a substantial enhancement of 15.21% in accuracy over FlexMatch on the STL-10 dataset using only 40 labels. Moreover, we apply MCE to supervised learning scenarios, and observe consistent improvements as well.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedLGD&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26412;&#22320;&#21644;&#20840;&#23616;&#25968;&#25454;&#38598;&#30340;&#33976;&#39311;&#32452;&#21512;&#26469;&#21019;&#24314;&#19968;&#20010;&#26356;&#23567;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20197;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#22788;&#29702;&#24322;&#26500;&#25968;&#25454;&#26102;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#21516;&#26102;&#20351;&#29992;&#36845;&#20195;&#20998;&#24067;&#21305;&#37197;&#26469;&#22788;&#29702;&#21516;&#27493;&#21644;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.02278</link><description>&lt;p&gt;
&#22522;&#20110;&#26412;&#22320;&#20840;&#23616;&#33976;&#39311;&#30340;&#24322;&#26500;&#25968;&#25454;&#32852;&#37030;&#34394;&#25311;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Virtual Learning on Heterogeneous Data with Local-global Distillation. (arXiv:2303.02278v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02278
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedLGD&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26412;&#22320;&#21644;&#20840;&#23616;&#25968;&#25454;&#38598;&#30340;&#33976;&#39311;&#32452;&#21512;&#26469;&#21019;&#24314;&#19968;&#20010;&#26356;&#23567;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20197;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#22788;&#29702;&#24322;&#26500;&#25968;&#25454;&#26102;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#21516;&#26102;&#20351;&#29992;&#36845;&#20195;&#20998;&#24067;&#21305;&#37197;&#26469;&#22788;&#29702;&#21516;&#27493;&#21644;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#32852;&#37030;&#23398;&#20064;&#24050;&#25104;&#20026;&#20998;&#24067;&#24335;&#23398;&#20064;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36235;&#21183;&#65292;&#20294;&#22312;&#22788;&#29702;&#24322;&#26500;&#25968;&#25454;&#26102;&#65292;&#20854;&#24615;&#33021;&#23481;&#26131;&#20986;&#29616;&#19979;&#38477;&#12290;&#27492;&#22806;&#65292;&#32852;&#37030;&#23398;&#20064;&#19981;&#21487;&#36991;&#20813;&#22320;&#38754;&#20020;&#21516;&#27493;&#12289;&#25928;&#29575;&#21644;&#38544;&#31169;&#31561;&#25361;&#25112;&#12290;&#36817;&#26469;&#65292;&#25968;&#25454;&#38598;&#33976;&#39311;&#24050;&#34987;&#30740;&#31350;&#65292;&#20197;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#20445;&#30041;&#26412;&#22320;&#31169;&#26377;&#25968;&#25454;&#38598;&#35757;&#32451;&#27169;&#22411;&#24615;&#33021;&#30340;&#36739;&#23567;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#26469;&#25552;&#39640;FL&#30340;&#25928;&#29575;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#20063;&#21457;&#29616;&#20351;&#29992;&#33976;&#39311;&#30340;&#26412;&#22320;&#25968;&#25454;&#38598;&#20250;&#25918;&#22823;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24322;&#26500;&#24615;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#26412;&#22320;&#20840;&#23616;&#33976;&#39311;&#30340;&#24322;&#26500;&#25968;&#25454;&#32852;&#37030;&#34394;&#25311;&#23398;&#20064;&#65288;FedLGD&#65289;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#19968;&#20010;&#36739;&#23567;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65288;&#31216;&#20026;&#34394;&#25311;&#25968;&#25454;&#65289;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#36890;&#36807;&#26412;&#22320;&#21644;&#20840;&#23616;&#25968;&#25454;&#38598;&#33976;&#39311;&#30340;&#32452;&#21512;&#21019;&#24314;&#30340;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20026;&#20102;&#22788;&#29702;&#21516;&#27493;&#21644;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36845;&#20195;&#20998;&#24067;&#21305;&#37197;&#65292;&#20801;&#35768;&#23458;&#25143;&#31471;&#20174;&#20840;&#23616;&#27169;&#22411;&#20013;&#33719;&#21462;&#30693;&#35782;&#24182;&#36890;&#36807;&#27169;&#22411;&#21453;&#39304;&#26469;&#20849;&#21516;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite Federated Learning (FL)'s trend for learning machine learning models in a distributed manner, it is susceptible to performance drops when training on heterogeneous data. In addition, FL inevitability faces the challenges of synchronization, efficiency, and privacy. Recently, dataset distillation has been explored in order to improve the efficiency and scalability of FL by creating a smaller, synthetic dataset that retains the performance of a model trained on the local private datasets. We discover that using distilled local datasets can amplify the heterogeneity issue in FL. To address this, we propose a new method, called Federated Virtual Learning on Heterogeneous Data with Local-Global Distillation (FedLGD), which trains FL using a smaller synthetic dataset (referred as virtual data) created through a combination of local and global dataset distillation. Specifically, to handle synchronization and class imbalance, we propose iterative distribution matching to allow clients 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#21487;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2211.15072</link><description>&lt;p&gt;
FaiREE&#65306;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#20445;&#35777;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
FaiREE: Fair Classification with Finite-Sample and Distribution-Free Guarantee. (arXiv:2211.15072v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15072
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#21487;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#20844;&#24179;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#21457;&#25381;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#32676;&#20307;&#20844;&#24179;&#24615;&#27010;&#24565;&#21644;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#30340;&#20844;&#24179;&#20445;&#35777;&#20027;&#35201;&#20381;&#36182;&#20110;&#29305;&#23450;&#30340;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#65292;&#36890;&#24120;&#38656;&#35201;&#22823;&#26679;&#26412;&#37327;&#65292;&#24182;&#19988;&#22312;&#26679;&#26412;&#37327;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#36829;&#21453;&#20844;&#24179;&#24615;&#65292;&#32780;&#36825;&#22312;&#23454;&#36341;&#20013;&#32463;&#24120;&#21457;&#29983;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#19979;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;FaiREE&#21487;&#20197;&#36866;&#24212;&#21508;&#31181;&#32676;&#20307;&#20844;&#24179;&#24615;&#27010;&#24565;&#65288;&#20363;&#22914;&#65292;&#26426;&#20250;&#24179;&#31561;&#65292;&#24179;&#34913;&#20960;&#29575;&#65292;&#20154;&#21475;&#32479;&#35745;&#23398;&#24179;&#34913;&#31561;&#65289;&#24182;&#23454;&#29616;&#26368;&#20339;&#20934;&#30830;&#24615;&#12290;&#36825;&#20123;&#29702;&#35770;&#20445;&#35777;&#36827;&#19968;&#27493;&#24471;&#21040;&#20102;&#23545;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#25903;&#25345;&#12290;FaiREE&#34920;&#29616;&#20986;&#27604;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic fairness plays an increasingly critical role in machine learning research. Several group fairness notions and algorithms have been proposed. However, the fairness guarantee of existing fair classification methods mainly depends on specific data distributional assumptions, often requiring large sample sizes, and fairness could be violated when there is a modest number of samples, which is often the case in practice. In this paper, we propose FaiREE, a fair classification algorithm that can satisfy group fairness constraints with finite-sample and distribution-free theoretical guarantees. FaiREE can be adapted to satisfy various group fairness notions (e.g., Equality of Opportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal accuracy. These theoretical guarantees are further supported by experiments on both synthetic and real data. FaiREE is shown to have favorable performance over state-of-the-art algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#22823;&#25968;&#25454;&#35282;&#24230;&#32508;&#36848;&#20102;&#20225;&#19994;&#36130;&#21153;&#39118;&#38505;&#20998;&#26512;&#30340;&#30740;&#31350;&#29616;&#29366;&#65292;&#22238;&#39038;&#20102;250&#22810;&#31687;&#20195;&#34920;&#24615;&#25991;&#31456;&#12290;</title><link>http://arxiv.org/abs/2211.14997</link><description>&lt;p&gt;
&#20174;&#22823;&#25968;&#25454;&#35282;&#24230;&#30475;&#20225;&#19994;&#36130;&#21153;&#39118;&#38505;&#20998;&#26512;&#30340;&#32508;&#36848;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Survey on Enterprise Financial Risk Analysis from Big Data Perspective. (arXiv:2211.14997v3 [q-fin.RM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#22823;&#25968;&#25454;&#35282;&#24230;&#32508;&#36848;&#20102;&#20225;&#19994;&#36130;&#21153;&#39118;&#38505;&#20998;&#26512;&#30340;&#30740;&#31350;&#29616;&#29366;&#65292;&#22238;&#39038;&#20102;250&#22810;&#31687;&#20195;&#34920;&#24615;&#25991;&#31456;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20225;&#19994;&#36130;&#21153;&#39118;&#38505;&#20998;&#26512;&#26088;&#22312;&#39044;&#27979;&#20225;&#19994;&#26410;&#26469;&#30340;&#36130;&#21153;&#39118;&#38505;&#12290;&#30001;&#20110;&#20854;&#24191;&#27867;&#32780;&#37325;&#35201;&#30340;&#24212;&#29992;&#65292;&#20225;&#19994;&#36130;&#21153;&#39118;&#38505;&#20998;&#26512;&#19968;&#30452;&#26159;&#37329;&#34701;&#21644;&#31649;&#29702;&#39046;&#22495;&#30340;&#26680;&#24515;&#30740;&#31350;&#20027;&#39064;&#12290;&#22522;&#20110;&#20808;&#36827;&#30340;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#20225;&#19994;&#39118;&#38505;&#20998;&#26512;&#30740;&#31350;&#27491;&#22312;&#32463;&#21382;&#24555;&#36895;&#21457;&#23637;&#24182;&#21462;&#24471;&#37325;&#35201;&#36827;&#23637;&#12290;&#22240;&#27492;&#65292;&#20840;&#38754;&#35780;&#20272;&#30456;&#20851;&#30740;&#31350;&#26082;&#26377;&#24517;&#35201;&#24615;&#21448;&#20855;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#23384;&#22312;&#19968;&#20123;&#26377;&#20215;&#20540;&#21644;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#20851;&#20110;&#20225;&#19994;&#39118;&#38505;&#20998;&#26512;&#30340;&#32508;&#36848;&#65292;&#20294;&#36825;&#20123;&#32508;&#36848;&#21333;&#29420;&#20171;&#32461;&#20102;&#26041;&#27861;&#65292;&#32570;&#20047;&#20225;&#19994;&#36130;&#21153;&#39118;&#38505;&#20998;&#26512;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#30456;&#21453;&#65292;&#26412;&#25991;&#23581;&#35797;&#20174;&#22823;&#25968;&#25454;&#30340;&#35282;&#24230;&#25552;&#20379;&#20225;&#19994;&#39118;&#38505;&#20998;&#26512;&#26041;&#27861;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#22238;&#39038;&#20102;&#36229;&#36807;250&#31687;&#20195;&#34920;&#24615;&#25991;&#31456;&#12290;
&lt;/p&gt;
&lt;p&gt;
Enterprise financial risk analysis aims at predicting the future financial risk of enterprises. Due to its wide and significant application, enterprise financial risk analysis has always been the core research topic in the fields of Finance and Management. Based on advanced computer science and artificial intelligence technologies, enterprise risk analysis research is experiencing rapid developments and making significant progress. Therefore, it is both necessary and challenging to comprehensively review the relevant studies. Although there are already some valuable and impressive surveys on enterprise risk analysis from the perspective of Finance and Management, these surveys introduce approaches in a relatively isolated way and lack recent advances in enterprise financial risk analysis. In contrast, this paper attempts to provide a systematic literature survey of enterprise risk analysis approaches from Big Data perspective, which reviews more than 250 representative articles in the 
&lt;/p&gt;</description></item></channel></rss>