<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36825;&#31181;&#25216;&#26415;&#21487;&#20197;&#31616;&#21270;&#20998;&#26512;&#20381;&#36182;&#36731;&#23614;&#38543;&#26426;&#28304;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#36739;&#31616;&#21333;&#30340;&#31639;&#27861;&#21464;&#20307;&#36827;&#34892;&#20998;&#26512;&#65292;&#36991;&#20813;&#20351;&#29992;&#19987;&#38376;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#25351;&#25968;&#12289;&#20122;&#39640;&#26031;&#21644;&#26356;&#19968;&#33324;&#30340;&#24555;&#36895;&#34928;&#20943;&#20998;&#24067;&#12290;</title><link>https://arxiv.org/abs/2403.02873</link><description>&lt;p&gt;
&#20851;&#20110;&#20855;&#26377;&#25351;&#25968;&#12289;&#20122;&#39640;&#26031;&#21644;&#19968;&#33324;&#36731;&#23614;&#30340;&#39640;&#27010;&#29575;&#20998;&#26512;&#31639;&#27861;&#30340;&#27880;&#35299;
&lt;/p&gt;
&lt;p&gt;
A Note on High-Probability Analysis of Algorithms with Exponential, Sub-Gaussian, and General Light Tails
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02873
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#25216;&#26415;&#21487;&#20197;&#31616;&#21270;&#20998;&#26512;&#20381;&#36182;&#36731;&#23614;&#38543;&#26426;&#28304;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#36739;&#31616;&#21333;&#30340;&#31639;&#27861;&#21464;&#20307;&#36827;&#34892;&#20998;&#26512;&#65292;&#36991;&#20813;&#20351;&#29992;&#19987;&#38376;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#25351;&#25968;&#12289;&#20122;&#39640;&#26031;&#21644;&#26356;&#19968;&#33324;&#30340;&#24555;&#36895;&#34928;&#20943;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#31616;&#30701;&#30340;&#27880;&#35299;&#25551;&#36848;&#20102;&#19968;&#31181;&#20998;&#26512;&#27010;&#29575;&#31639;&#27861;&#30340;&#31616;&#21333;&#25216;&#26415;&#65292;&#35813;&#31639;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#36731;&#23614;&#65288;&#20294;&#19981;&#19968;&#23450;&#26377;&#30028;&#65289;&#30340;&#38543;&#26426;&#21270;&#26469;&#28304;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#19968;&#20010;&#31639;&#27861;&#30340;&#20998;&#26512;&#21487;&#20197;&#36890;&#36807;&#40657;&#30418;&#26041;&#24335;&#20943;&#23569;&#65292;&#21482;&#22312;&#23545;&#25968;&#22240;&#23376;&#20013;&#26377;&#23567;&#37327;&#25439;&#22833;&#65292;&#36716;&#21270;&#20026;&#20998;&#26512;&#21516;&#19968;&#31639;&#27861;&#30340;&#19968;&#20010;&#26356;&#31616;&#21333;&#21464;&#20307;&#65292;&#35813;&#21464;&#20307;&#20351;&#29992;&#26377;&#30028;&#38543;&#26426;&#21464;&#37327;&#65292;&#36890;&#24120;&#26356;&#23481;&#26131;&#20998;&#26512;&#12290;&#36825;&#31181;&#26041;&#27861;&#21516;&#26102;&#36866;&#29992;&#20110;&#20219;&#20309;&#36731;&#23614;&#38543;&#26426;&#21270;&#65292;&#21253;&#25324;&#25351;&#25968;&#12289;&#20122;&#39640;&#26031;&#21644;&#26356;&#19968;&#33324;&#30340;&#24555;&#36895;&#34928;&#20943;&#20998;&#24067;&#65292;&#32780;&#19981;&#38656;&#35201;&#35843;&#29992;&#19987;&#38376;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;&#12290;&#25552;&#20379;&#20102;&#23545;&#19968;&#33324;&#21270;Azuma&#19981;&#31561;&#24335;&#21644;&#20855;&#26377;&#19968;&#33324;&#36731;&#23614;&#22122;&#22768;&#30340;&#38543;&#26426;&#20248;&#21270;&#30340;&#20998;&#26512;&#65292;&#20197;&#35828;&#26126;&#35813;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02873v1 Announce Type: new  Abstract: This short note describes a simple technique for analyzing probabilistic algorithms that rely on a light-tailed (but not necessarily bounded) source of randomization. We show that the analysis of such an algorithm can be reduced, in a black-box manner and with only a small loss in logarithmic factors, to an analysis of a simpler variant of the same algorithm that uses bounded random variables and often easier to analyze. This approach simultaneously applies to any light-tailed randomization, including exponential, sub-Gaussian, and more general fast-decaying distributions, without needing to appeal to specialized concentration inequalities. Analyses of a generalized Azuma inequality and stochastic optimization with general light-tailed noise are provided to illustrate the technique.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27010;&#29575;&#28508;&#22312;&#31354;&#38388;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#37322;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#30340;&#20248;&#21270;&#32593;&#32476;&#31232;&#30095;&#24230;&#65292;&#24182;&#25506;&#35752;&#20102;&#32593;&#32476;&#23618;&#30340;AP3/AP2&#23646;&#24615;&#19982;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.00155</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#28508;&#22312;&#31354;&#38388;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00155
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#28508;&#22312;&#31354;&#38388;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#37322;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#30340;&#20248;&#21270;&#32593;&#32476;&#31232;&#30095;&#24230;&#65292;&#24182;&#25506;&#35752;&#20102;&#32593;&#32476;&#23618;&#30340;AP3/AP2&#23646;&#24615;&#19982;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#21644;&#23384;&#20648;&#31354;&#38388;&#28040;&#32791;&#23548;&#33268;&#20102;&#32593;&#32476;&#21387;&#32553;&#30340;&#27010;&#24565;&#12290;&#23613;&#31649;&#24050;&#24191;&#27867;&#30740;&#31350;&#20102;&#35832;&#22914;&#20462;&#21098;&#21644;&#20302;&#31209;&#20998;&#35299;&#31561;DNN&#21387;&#32553;&#25216;&#26415;&#65292;&#20294;&#23545;&#23427;&#20204;&#30340;&#29702;&#35770;&#35299;&#37322;&#20173;&#26410;&#21463;&#21040;&#36275;&#22815;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;DNN&#26435;&#37325;&#30340;&#27010;&#29575;&#28508;&#22312;&#31354;&#38388;&#24182;&#21033;&#29992;&#20449;&#24687;&#29702;&#35770;&#20998;&#27495;&#24230;&#37327;&#35299;&#37322;&#26368;&#20339;&#32593;&#32476;&#31232;&#30095;&#24615;&#30340;&#26032;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#20026;DNN&#24341;&#20837;&#20102;&#26032;&#30340;&#31867;&#27604;&#25237;&#24433;&#27169;&#24335;&#65288;AP2&#65289;&#21644;&#27010;&#29575;&#20013;&#30340;&#31867;&#27604;&#25237;&#24433;&#27169;&#24335;&#65288;AP3&#65289;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#32593;&#32476;&#20013;&#23618;&#30340;AP3/AP2&#29305;&#24615;&#19982;&#20854;&#24615;&#33021;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#20998;&#26512;&#65292;&#35299;&#37322;&#20102;&#21387;&#32553;&#32593;&#32476;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#26159;&#20174;&#23454;&#35777;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00155v1 Announce Type: new  Abstract: Despite the impressive performance of deep neural networks (DNNs), their computational complexity and storage space consumption have led to the concept of network compression. While DNN compression techniques such as pruning and low-rank decomposition have been extensively studied, there has been insufficient attention paid to their theoretical explanation. In this paper, we propose a novel theoretical framework that leverages a probabilistic latent space of DNN weights and explains the optimal network sparsity by using the information-theoretic divergence measures. We introduce new analogous projected patterns (AP2) and analogous-in-probability projected patterns (AP3) notions for DNNs and prove that there exists a relationship between AP3/AP2 property of layers in the network and its performance. Further, we provide a theoretical analysis that explains the training process of the compressed network. The theoretical results are empirica
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22810;&#35270;&#22270;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26032;&#39062;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#35268;&#33539;&#30456;&#20851;&#24615;&#30446;&#26631;&#23398;&#20064;&#34701;&#21512;&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#22810;&#20010;&#35270;&#22270;&#30340;&#19968;&#33268;&#20266;&#26631;&#31614;&#26469;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#27169;&#22411;&#26377;&#25928;&#24615;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#36924;&#36817;&#30417;&#30563;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#34920;&#31034;&#65292;&#25552;&#20379;&#20102;&#30001;&#38169;&#35823;&#20266;&#26631;&#31614;&#27880;&#37322;&#24341;&#36215;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.16383</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#22810;&#35270;&#22270;&#32858;&#31867;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Self Supervised Correlation-based Permutations for Multi-View Clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16383
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22810;&#35270;&#22270;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26032;&#39062;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#35268;&#33539;&#30456;&#20851;&#24615;&#30446;&#26631;&#23398;&#20064;&#34701;&#21512;&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#22810;&#20010;&#35270;&#22270;&#30340;&#19968;&#33268;&#20266;&#26631;&#31614;&#26469;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#27169;&#22411;&#26377;&#25928;&#24615;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#36924;&#36817;&#30417;&#30563;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#34920;&#31034;&#65292;&#25552;&#20379;&#20102;&#30001;&#38169;&#35823;&#20266;&#26631;&#31614;&#27880;&#37322;&#24341;&#36215;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34701;&#21512;&#26469;&#33258;&#19981;&#21516;&#27169;&#24577;&#30340;&#20449;&#24687;&#21487;&#20197;&#22686;&#24378;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#65292;&#21253;&#25324;&#32858;&#31867;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22810;&#35270;&#22270;&#32858;&#31867;&#65288;MVC&#65289;&#35299;&#20915;&#26041;&#26696;&#20165;&#38480;&#20110;&#29305;&#23450;&#39046;&#22495;&#65292;&#25110;&#32773;&#20381;&#36182;&#20110;&#27425;&#20248;&#30340;&#19988;&#35745;&#31639;&#38656;&#27714;&#39640;&#30340;&#34920;&#31034;&#21644;&#32858;&#31867;&#20004;&#38454;&#27573;&#31243;&#24207;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#31471;&#21040;&#31471;&#28145;&#24230;&#23398;&#20064;&#30340;&#36890;&#29992;&#25968;&#25454;&#65288;&#22270;&#20687;&#12289;&#34920;&#26684;&#31561;&#65289;&#30340;MVC&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#22522;&#20110;&#26032;&#39062;&#32622;&#25442;&#30340;&#35268;&#33539;&#30456;&#20851;&#24615;&#30446;&#26631;&#26469;&#23398;&#20064;&#26377;&#24847;&#20041;&#30340;&#34701;&#21512;&#25968;&#25454;&#34920;&#31034;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36890;&#36807;&#35782;&#21035;&#36328;&#22810;&#20010;&#35270;&#22270;&#30340;&#19968;&#33268;&#20266;&#26631;&#31614;&#26469;&#23398;&#20064;&#32858;&#31867;&#20998;&#37197;&#12290;&#25105;&#20204;&#20351;&#29992;&#21313;&#20010;MVC&#22522;&#20934;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#36924;&#36817;&#20102;&#30417;&#30563;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#34920;&#31034;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30001;&#38169;&#35823;&#20266;&#26631;&#31614;&#27880;&#37322;&#24341;&#36215;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16383v1 Announce Type: new  Abstract: Fusing information from different modalities can enhance data analysis tasks, including clustering. However, existing multi-view clustering (MVC) solutions are limited to specific domains or rely on a suboptimal and computationally demanding two-stage procedure of representation and clustering. We propose an end-to-end deep learning-based MVC framework for general data (image, tabular, etc.). Our approach involves learning meaningful fused data representations with a novel permutation-based canonical correlation objective. Concurrently, we learn cluster assignments by identifying consistent pseudo-labels across multiple views. We demonstrate the effectiveness of our model using ten MVC benchmark datasets. Theoretically, we show that our model approximates the supervised linear discrimination analysis (LDA) representation. Additionally, we provide an error bound induced by false-pseudo label annotations.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.04906</link><description>&lt;p&gt;
&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35748;&#35782;&#24178;&#39044;&#25928;&#26524;&#65292;&#21363;&#27835;&#30103;&#25928;&#26524;&#65292;&#23545;&#20110;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#29992;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524; (CATE) &#20272;&#35745;&#31561;&#26041;&#27861;&#36890;&#24120;&#21482;&#25552;&#20379;&#27835;&#30103;&#25928;&#26524;&#30340;&#28857;&#20272;&#35745;&#65292;&#32780;&#24120;&#24120;&#38656;&#35201;&#39069;&#22806;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931; (CMC) &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644; CATE &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#26469;&#20135;&#29983;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32467;&#26524;&#22122;&#22768;&#20998;&#24067;&#30340;&#29305;&#23450;&#20551;&#35774;&#22914;&#20309;&#20005;&#37325;&#24433;&#21709;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;CMC&#26694;&#26550;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21516;&#26102;&#20445;&#25345;&#36739;&#23567;&#30340;&#21306;&#38388;&#23485;&#24230;&#65292;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge of the effect of interventions, called the treatment effect, is paramount for decision-making. Approaches to estimating this treatment effect, e.g. by using Conditional Average Treatment Effect (CATE) estimators, often only provide a point estimate of this treatment effect, while additional uncertainty quantification is frequently desired instead. Therefore, we present a novel method, the Conformal Monte Carlo (CMC) meta-learners, leveraging conformal predictive systems, Monte Carlo sampling, and CATE meta-learners, to instead produce a predictive distribution usable in individualized decision-making. Furthermore, we show how specific assumptions on the noise distribution of the outcome heavily affect these uncertainty predictions. Nonetheless, the CMC framework shows strong experimental coverage while retaining small interval widths to provide estimates of the true individual treatment effect.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#32508;&#36848;&#19981;&#21516;&#30340;&#26041;&#27861;&#20197;&#21450;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#25913;&#36827;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.04059</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Deep Learning for Multivariate Time Series Imputation: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#32508;&#36848;&#19981;&#21516;&#30340;&#26041;&#27861;&#20197;&#21450;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#30340;&#25913;&#36827;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26222;&#36941;&#23384;&#22312;&#30340;&#32570;&#22833;&#20540;&#23548;&#33268;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#37096;&#20998;&#35266;&#27979;&#65292;&#30772;&#22351;&#20102;&#26102;&#38388;&#24207;&#21015;&#30340;&#23436;&#25972;&#24615;&#65292;&#38459;&#30861;&#20102;&#26377;&#25928;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#12290;&#26368;&#36817;&#65292;&#28145;&#24230;&#23398;&#20064;&#25554;&#34917;&#26041;&#27861;&#22312;&#25552;&#39640;&#25439;&#22351;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36136;&#37327;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#36827;&#32780;&#25552;&#39640;&#20102;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#23545;&#26368;&#36817;&#25552;&#20986;&#30340;&#28145;&#24230;&#23398;&#20064;&#25554;&#34917;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24378;&#35843;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#38480;&#21046;&#26469;&#36827;&#34892;&#20102;&#32467;&#26500;&#21270;&#30340;&#32508;&#36848;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#23454;&#35777;&#23454;&#39564;&#65292;&#30740;&#31350;&#20102;&#19981;&#21516;&#26041;&#27861;&#65292;&#24182;&#27604;&#36739;&#20102;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#25913;&#36827;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;&#20102;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#26410;&#26469;&#30740;&#31350;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#26412;&#25991;&#30340;&#25152;&#26377;&#20195;&#30721;&#21644;&#37197;&#32622;&#65292;&#21253;&#25324;&#23450;&#26399;&#32500;&#25252;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#35770;&#25991;&#21015;&#34920;&#65292;&#21487;&#20197;&#22312;&#20197;&#19979;&#20301;&#32622;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ubiquitous missing values cause the multivariate time series data to be partially observed, destroying the integrity of time series and hindering the effective time series data analysis. Recently deep learning imputation methods have demonstrated remarkable success in elevating the quality of corrupted time series data, subsequently enhancing performance in downstream tasks. In this paper, we conduct a comprehensive survey on the recently proposed deep learning imputation methods. First, we propose a taxonomy for the reviewed methods, and then provide a structured review of these methods by highlighting their strengths and limitations. We also conduct empirical experiments to study different methods and compare their enhancement for downstream tasks. Finally, the open issues for future research on multivariate time series imputation are pointed out. All code and configurations of this work, including a regularly maintained multivariate time series imputation paper list, can be foun
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35752;&#35770;&#20102;&#22810;&#26679;&#24615;&#24863;&#30693;&#32858;&#31867;&#38382;&#39064;&#65292;&#22312;&#36873;&#25321;&#32858;&#31867;&#20013;&#24515;&#26102;&#35201;&#32771;&#34385;&#22810;&#20010;&#23646;&#24615;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#32858;&#31867;&#30446;&#26631;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#19981;&#21516;&#32858;&#31867;&#30446;&#26631;&#30340;&#21442;&#25968;&#21270;&#36817;&#20284;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#20445;&#35777;&#32858;&#31867;&#36136;&#37327;&#30340;&#21516;&#26102;&#65292;&#20855;&#26377;&#32039;&#30830;&#30340;&#36817;&#20284;&#27604;&#12290;</title><link>http://arxiv.org/abs/2401.05502</link><description>&lt;p&gt;
&#22810;&#26679;&#24615;&#24863;&#30693;&#32858;&#31867;&#65306;&#35745;&#31639;&#22797;&#26434;&#24615;&#21644;&#36817;&#20284;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Diversity-aware clustering: Computational Complexity and Approximation Algorithms. (arXiv:2401.05502v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35752;&#35770;&#20102;&#22810;&#26679;&#24615;&#24863;&#30693;&#32858;&#31867;&#38382;&#39064;&#65292;&#22312;&#36873;&#25321;&#32858;&#31867;&#20013;&#24515;&#26102;&#35201;&#32771;&#34385;&#22810;&#20010;&#23646;&#24615;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#32858;&#31867;&#30446;&#26631;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#19981;&#21516;&#32858;&#31867;&#30446;&#26631;&#30340;&#21442;&#25968;&#21270;&#36817;&#20284;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#20445;&#35777;&#32858;&#31867;&#36136;&#37327;&#30340;&#21516;&#26102;&#65292;&#20855;&#26377;&#32039;&#30830;&#30340;&#36817;&#20284;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#26679;&#24615;&#24863;&#30693;&#32858;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#28857;&#19982;&#22810;&#20010;&#23646;&#24615;&#30456;&#20851;&#32852;&#65292;&#24418;&#25104;&#20132;&#21449;&#30340;&#32452;&#12290;&#32858;&#31867;&#35299;&#20915;&#26041;&#26696;&#38656;&#35201;&#30830;&#20445;&#20174;&#27599;&#20010;&#32452;&#20013;&#36873;&#25321;&#26368;&#23569;&#25968;&#37327;&#30340;&#32858;&#31867;&#20013;&#24515;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#32858;&#31867;&#30446;&#26631;&#65292;&#21487;&#20197;&#26159;$k$-&#20013;&#20301;&#25968;&#65292;$k$-&#22343;&#20540;&#25110;$k$-&#20379;&#24212;&#21830;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21442;&#25968;&#21270;&#36817;&#20284;&#31639;&#27861;&#65292;&#36817;&#20284;&#27604;&#20998;&#21035;&#20026;$1+\frac{2}{e}$&#65292;$1+\frac{8}{e}$&#21644;$3$&#65292;&#29992;&#20110;&#22810;&#26679;&#24615;&#24863;&#30693;$k$-&#20013;&#20301;&#25968;&#65292;&#22810;&#26679;&#24615;&#24863;&#30693;$k$-&#22343;&#20540;&#21644;&#22810;&#26679;&#24615;&#24863;&#30693;$k$-&#20379;&#24212;&#21830;&#12290;&#36825;&#20123;&#36817;&#20284;&#27604;&#22312;&#20551;&#35774;Gap-ETH&#21644;FPT $\neq$ W[2]&#30340;&#24773;&#20917;&#19979;&#26159;&#32039;&#30830;&#30340;&#12290;&#23545;&#20110;&#20844;&#24179;$k$-&#20013;&#20301;&#25968;&#21644;&#20844;&#24179;$k$-&#22343;&#20540;&#30340;&#19981;&#30456;&#20132;&#24037;&#21378;&#32452;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21442;&#25968;&#21270;&#36817;&#20284;&#31639;&#27861;&#65292;&#36817;&#20284;&#27604;&#20998;&#21035;&#20026;$1+\frac{2}{e}$&#21644;$1+\frac{8}{e}$&#12290;&#23545;&#20110;&#20855;&#26377;&#19981;&#30456;&#20132;&#24037;&#21378;&#32452;&#30340;&#20844;&#24179;$k$-&#20379;&#24212;&#21830;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#36817;&#20284;&#31639;&#27861;&#65292;&#22240;&#23376;&#20026;$3$&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study diversity-aware clustering problems where the data points are associated with multiple attributes resulting in intersecting groups. A clustering solution need to ensure that a minimum number of cluster centers are chosen from each group while simultaneously minimizing the clustering objective, which can be either $k$-median, $k$-means or $k$-supplier. We present parameterized approximation algorithms with approximation ratios $1+ \frac{2}{e}$, $1+\frac{8}{e}$ and $3$ for diversity-aware $k$-median, diversity-aware $k$-means and diversity-aware $k$-supplier, respectively. The approximation ratios are tight assuming Gap-ETH and FPT $\neq$ W[2]. For fair $k$-median and fair $k$-means with disjoint faicility groups, we present parameterized approximation algorithm with approximation ratios $1+\frac{2}{e}$ and $1+\frac{8}{e}$, respectively. For fair $k$-supplier with disjoint facility groups, we present a polynomial-time approximation algorithm with factor $3$, improv
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23545;&#20849;&#24773;&#26816;&#27979;&#39046;&#22495;&#30340;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#36827;&#34892;&#20102;&#32508;&#36848;&#21644;&#20998;&#26512;&#65292;&#21253;&#25324;&#25991;&#26412;&#12289;&#35270;&#21548;&#12289;&#38899;&#39057;&#21644;&#29983;&#29702;&#20449;&#21495;&#22235;&#31181;&#36755;&#20837;&#27169;&#24577;&#30340;&#22788;&#29702;&#21644;&#32593;&#32476;&#35774;&#35745;&#65292;&#20197;&#21450;&#35780;&#20272;&#21327;&#35758;&#21644;&#25968;&#25454;&#38598;&#30340;&#25551;&#36848;&#12290;</title><link>http://arxiv.org/abs/2311.00721</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#22312;&#25991;&#26412;&#12289;&#35270;&#21548;&#12289;&#38899;&#39057;&#25110;&#29983;&#29702;&#20449;&#21495;&#19978;&#36827;&#34892;&#20849;&#24773;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Empathy Detection Using Machine Learning on Text, Audiovisual, Audio or Physiological Signals. (arXiv:2311.00721v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23545;&#20849;&#24773;&#26816;&#27979;&#39046;&#22495;&#30340;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#36827;&#34892;&#20102;&#32508;&#36848;&#21644;&#20998;&#26512;&#65292;&#21253;&#25324;&#25991;&#26412;&#12289;&#35270;&#21548;&#12289;&#38899;&#39057;&#21644;&#29983;&#29702;&#20449;&#21495;&#22235;&#31181;&#36755;&#20837;&#27169;&#24577;&#30340;&#22788;&#29702;&#21644;&#32593;&#32476;&#35774;&#35745;&#65292;&#20197;&#21450;&#35780;&#20272;&#21327;&#35758;&#21644;&#25968;&#25454;&#38598;&#30340;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20849;&#24773;&#26159;&#19968;&#20010;&#31038;&#20132;&#25216;&#33021;&#65292;&#34920;&#26126;&#19968;&#20010;&#20010;&#20307;&#29702;&#35299;&#20182;&#20154;&#30340;&#33021;&#21147;&#12290;&#36817;&#24180;&#26469;&#65292;&#20849;&#24773;&#24341;&#36215;&#20102;&#21253;&#25324;&#24773;&#24863;&#35745;&#31639;&#12289;&#35748;&#30693;&#31185;&#23398;&#21644;&#24515;&#29702;&#23398;&#22312;&#20869;&#30340;&#21508;&#20010;&#23398;&#31185;&#30340;&#20851;&#27880;&#12290;&#20849;&#24773;&#26159;&#19968;&#20010;&#20381;&#36182;&#20110;&#19978;&#19979;&#25991;&#30340;&#26415;&#35821;&#65292;&#22240;&#27492;&#26816;&#27979;&#25110;&#35782;&#21035;&#20849;&#24773;&#22312;&#31038;&#20250;&#12289;&#21307;&#30103;&#21644;&#25945;&#32946;&#31561;&#39046;&#22495;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#12290;&#23613;&#31649;&#20849;&#24773;&#26816;&#27979;&#39046;&#22495;&#28041;&#21450;&#33539;&#22260;&#24191;&#27867;&#19988;&#26377;&#37325;&#21472;&#65292;&#20294;&#20174;&#25972;&#20307;&#25991;&#29486;&#35282;&#24230;&#26469;&#30475;&#65292;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#20849;&#24773;&#26816;&#27979;&#30740;&#31350;&#20173;&#28982;&#30456;&#23545;&#36739;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#31995;&#32479;&#25910;&#38598;&#21644;&#31579;&#36873;&#20102;&#26469;&#33258;10&#20010;&#30693;&#21517;&#25968;&#25454;&#24211;&#30340;801&#31687;&#35770;&#25991;&#65292;&#24182;&#20998;&#26512;&#20102;&#36873;&#23450;&#30340;54&#31687;&#35770;&#25991;&#12290;&#25105;&#20204;&#26681;&#25454;&#20849;&#24773;&#26816;&#27979;&#31995;&#32479;&#30340;&#36755;&#20837;&#27169;&#24577;&#65292;&#21363;&#25991;&#26412;&#12289;&#35270;&#21548;&#12289;&#38899;&#39057;&#21644;&#29983;&#29702;&#20449;&#21495;&#65292;&#23545;&#35770;&#25991;&#36827;&#34892;&#20998;&#32452;&#12290;&#25105;&#20204;&#20998;&#21035;&#30740;&#31350;&#20102;&#29305;&#23450;&#27169;&#24577;&#30340;&#39044;&#22788;&#29702;&#21644;&#32593;&#32476;&#26550;&#26500;&#35774;&#35745;&#21327;&#35758;&#12289;&#24120;&#35265;&#25968;&#25454;&#38598;&#30340;&#25551;&#36848;&#21644;&#21487;&#29992;&#24615;&#35814;&#24773;&#65292;&#20197;&#21450;&#35780;&#20272;&#21327;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empathy is a social skill that indicates an individual's ability to understand others. Over the past few years, empathy has drawn attention from various disciplines, including but not limited to Affective Computing, Cognitive Science and Psychology. Empathy is a context-dependent term; thus, detecting or recognising empathy has potential applications in society, healthcare and education. Despite being a broad and overlapping topic, the avenue of empathy detection studies leveraging Machine Learning remains underexplored from a holistic literature perspective. To this end, we systematically collect and screen 801 papers from 10 well-known databases and analyse the selected 54 papers. We group the papers based on input modalities of empathy detection systems, i.e., text, audiovisual, audio and physiological signals. We examine modality-specific pre-processing and network architecture design protocols, popular dataset descriptions and availability details, and evaluation protocols. We fur
&lt;/p&gt;</description></item><item><title>&#34920;&#28436;&#24615;&#39044;&#27979;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#26032;&#20852;&#39046;&#22495;&#65292;&#36890;&#36807;&#23450;&#20041;&#21644;&#30740;&#31350;&#39044;&#27979;&#23545;&#30446;&#26631;&#30340;&#24433;&#21709;&#65292;&#25552;&#20379;&#20102;&#23545;&#20110;&#20998;&#24067;&#21464;&#21270;&#21644;&#20248;&#21270;&#25361;&#25112;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.16608</link><description>&lt;p&gt;
&#34920;&#28436;&#24615;&#39044;&#27979;&#65306;&#36807;&#21435;&#19982;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
Performative Prediction: Past and Future. (arXiv:2310.16608v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16608
&lt;/p&gt;
&lt;p&gt;
&#34920;&#28436;&#24615;&#39044;&#27979;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#26032;&#20852;&#39046;&#22495;&#65292;&#36890;&#36807;&#23450;&#20041;&#21644;&#30740;&#31350;&#39044;&#27979;&#23545;&#30446;&#26631;&#30340;&#24433;&#21709;&#65292;&#25552;&#20379;&#20102;&#23545;&#20110;&#20998;&#24067;&#21464;&#21270;&#21644;&#20248;&#21270;&#25361;&#25112;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20250;&#19990;&#30028;&#20013;&#65292;&#39044;&#27979;&#36890;&#24120;&#20250;&#24433;&#21709;&#39044;&#27979;&#30340;&#30446;&#26631;&#65292;&#36825;&#19968;&#29616;&#35937;&#34987;&#31216;&#20026;&#34920;&#28436;&#24615;&#12290;&#33258;&#25105;&#23454;&#29616;&#21644;&#33258;&#25105;&#21542;&#23450;&#30340;&#39044;&#27979;&#26159;&#34920;&#28436;&#24615;&#30340;&#20363;&#23376;&#12290;&#23545;&#32463;&#27982;&#23398;&#12289;&#37329;&#34701;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#33267;&#20851;&#37325;&#35201;&#30340;&#27010;&#24565;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#21457;&#23637;&#20013;&#19968;&#30452;&#32570;&#22833;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#34920;&#28436;&#24615;&#36890;&#24120;&#34920;&#29616;&#20026;&#20998;&#24067;&#21464;&#21270;&#12290;&#20363;&#22914;&#65292;&#22312;&#25968;&#23383;&#24179;&#21488;&#19978;&#37096;&#32626;&#30340;&#39044;&#27979;&#27169;&#22411;&#20250;&#24433;&#21709;&#28040;&#36153;&#65292;&#20174;&#32780;&#25913;&#21464;&#25968;&#25454;&#29983;&#25104;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;&#26368;&#36817;&#25104;&#31435;&#30340;&#34920;&#28436;&#24615;&#39044;&#27979;&#39046;&#22495;&#65292;&#35813;&#39046;&#22495;&#25552;&#20379;&#20102;&#19968;&#20010;&#23450;&#20041;&#21644;&#27010;&#24565;&#26694;&#26550;&#26469;&#30740;&#31350;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#34920;&#28436;&#24615;&#12290;&#34920;&#28436;&#24615;&#39044;&#27979;&#30340;&#19968;&#20010;&#32467;&#26524;&#26159;&#33258;&#28982;&#22343;&#34913;&#27010;&#24565;&#30340;&#20135;&#29983;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#26032;&#30340;&#20248;&#21270;&#25361;&#25112;&#12290;&#21478;&#19968;&#20010;&#32467;&#26524;&#26159;&#23398;&#20064;&#21644;&#25805;&#25511;&#20043;&#38388;&#30340;&#21306;&#21035;&#65292;&#36825;&#26159;&#34920;&#28436;&#24615;&#39044;&#27979;&#20013;&#30340;&#20004;&#31181;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictions in the social world generally influence the target of prediction, a phenomenon known as performativity. Self-fulfilling and self-negating predictions are examples of performativity. Of fundamental importance to economics, finance, and the social sciences, the notion has been absent from the development of machine learning. In machine learning applications, performativity often surfaces as distribution shift. A predictive model deployed on a digital platform, for example, influences consumption and thereby changes the data-generating distribution. We survey the recently founded area of performative prediction that provides a definition and conceptual framework to study performativity in machine learning. A consequence of performative prediction is a natural equilibrium notion that gives rise to new optimization challenges. Another consequence is a distinction between learning and steering, two mechanisms at play in performative prediction. The notion of steering is in turn i
&lt;/p&gt;</description></item><item><title>&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.10870</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10870
&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#20851;&#20110;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#30456;&#20284;&#34920;&#31034;&#32467;&#26500;&#26469;&#31616;&#21270;&#30446;&#26631;&#20219;&#21153;&#65292;&#24182;&#23454;&#29616;&#25910;&#25947;&#36895;&#29575;&#30340;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#34920;&#31034;&#24448;&#24448;&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#65292;&#24341;&#20837;&#20102;&#27599;&#20010;&#20219;&#21153;&#20013;&#19981;&#21487;&#31616;&#21333;&#24179;&#22343;&#30340;&#38750;&#24179;&#20961;&#20559;&#24046;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#38750;&#32447;&#24615;&#34920;&#31034;&#25512;&#23548;&#20986;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent theoretical works on \emph{meta-learning} aim to achieve guarantees in leveraging similar representational structures from related tasks towards simplifying a target task. Importantly, the main aim in theory works on the subject is to understand the extent to which convergence rates -- in learning a common representation -- \emph{may scale with the number $N$ of tasks} (as well as the number of samples per task). First steps in this setting demonstrate this property when both the shared representation amongst tasks, and task-specific regression functions, are linear. This linear setting readily reveals the benefits of aggregating tasks, e.g., via averaging arguments. In practice, however, the representation is often highly nonlinear, introducing nontrivial biases in each task that cannot easily be averaged out as in the linear case. In the present work, we derive theoretical guarantees for meta-learning with nonlinear representations. In particular, assuming the shared nonl
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#65292;&#24182;&#21487;&#30830;&#20445;&#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.04095</link><description>&lt;p&gt;
&#22522;&#20110;&#23494;&#38053;&#38145;&#27169;&#22359;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Gradient Leakage Defense with Key-Lock Module for Federated Learning. (arXiv:2305.04095v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#37030;&#23398;&#20064;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#65292;&#24182;&#21487;&#30830;&#20445;&#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#38544;&#31169;&#20445;&#25252;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20854;&#20013;&#31169;&#26377;&#25968;&#25454;&#20445;&#25345;&#26412;&#22320;&#65292;&#20801;&#35768;&#23433;&#20840;&#35745;&#31639;&#21644;&#26412;&#22320;&#27169;&#22411;&#26799;&#24230;&#19982;&#31532;&#19977;&#26041;&#21442;&#25968;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#20132;&#25442;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#20849;&#20139;&#30340;&#26799;&#24230;&#21487;&#33021;&#20250;&#21361;&#21450;&#38544;&#31169;&#24182;&#24674;&#22797;&#25935;&#24863;&#20449;&#24687;&#12290;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#20998;&#26512;&#21644;&#23545;&#26799;&#24230;&#27844;&#28431;&#38382;&#39064;&#30340;&#26032;&#35270;&#35282;&#12290;&#36825;&#20123;&#29702;&#35770;&#24037;&#20316;&#23548;&#33268;&#20102;&#19968;&#31181;&#26032;&#30340;&#26799;&#24230;&#27844;&#38706;&#38450;&#24481;&#25216;&#26415;&#65292;&#20351;&#29992;&#31169;&#38053;&#38145;&#27169;&#22359;&#20445;&#25252;&#20219;&#24847;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#12290;&#21482;&#26377;&#38145;&#23450;&#30340;&#26799;&#24230;&#34987;&#20256;&#36755;&#21040;&#21442;&#25968;&#26381;&#21153;&#22120;&#36827;&#34892;&#20840;&#23616;&#27169;&#22411;&#32858;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#23398;&#20064;&#26041;&#27861;&#23545;&#26799;&#24230;&#27844;&#38706;&#25915;&#20987;&#20855;&#26377;&#25269;&#25239;&#21147;&#65292;&#24182;&#19988;&#25152;&#35774;&#35745;&#21644;&#35757;&#32451;&#30340;&#23494;&#38053;&#38145;&#27169;&#22359;&#21487;&#20197;&#30830;&#20445;&#65292;&#27809;&#26377;&#23494;&#38053;&#38145;&#27169;&#22359;&#30340;&#31169;&#26377;&#20449;&#24687;&#65306;a) &#26080;&#27861;&#20174;&#20849;&#20139;&#30340;&#26799;&#24230;&#20013;&#37325;&#24314;&#31169;&#26377;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a widely adopted privacy-preserving machine learning approach where private data remains local, enabling secure computations and the exchange of local model gradients between local clients and third-party parameter servers. However, recent findings reveal that privacy may be compromised and sensitive information potentially recovered from shared gradients. In this study, we offer detailed analysis and a novel perspective on understanding the gradient leakage problem. These theoretical works lead to a new gradient leakage defense technique that secures arbitrary model architectures using a private key-lock module. Only the locked gradient is transmitted to the parameter server for global model aggregation. Our proposed learning method is resistant to gradient leakage attacks, and the key-lock module is designed and trained to ensure that, without the private information of the key-lock module: a) reconstructing private training data from the shared gradient is
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32593;&#32476;&#29615;&#22659;&#20013;&#22810;&#31181;&#25968;&#25454;&#21644;&#27169;&#22411;&#30340;&#27169;&#22411;&#26080;&#20851;&#20851;&#32852;&#23398;&#20064;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#32593;&#32476;&#32467;&#26500;&#21453;&#26144;&#26412;&#22320;&#25968;&#25454;&#38598;&#30340;&#30456;&#20284;&#24615;&#24182;&#20445;&#35777;&#26412;&#22320;&#27169;&#22411;&#20135;&#29983;&#19968;&#33268;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.04363</link><description>&lt;p&gt;
&#25506;&#32034;&#32593;&#32476;&#19978;&#30340;&#27169;&#22411;&#26080;&#20851;&#32852;&#21512;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Model-Agnostic Federated Learning over Networks. (arXiv:2302.04363v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04363
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32593;&#32476;&#29615;&#22659;&#20013;&#22810;&#31181;&#25968;&#25454;&#21644;&#27169;&#22411;&#30340;&#27169;&#22411;&#26080;&#20851;&#20851;&#32852;&#23398;&#20064;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#32593;&#32476;&#32467;&#26500;&#21453;&#26144;&#26412;&#22320;&#25968;&#25454;&#38598;&#30340;&#30456;&#20284;&#24615;&#24182;&#20445;&#35777;&#26412;&#22320;&#27169;&#22411;&#20135;&#29983;&#19968;&#33268;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24322;&#26500;&#25968;&#25454;&#21644;&#27169;&#22411;&#32593;&#32476;&#30340;&#27169;&#22411;&#26080;&#20851;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;&#12290;&#32593;&#32476;&#32467;&#26500;&#21453;&#26144;&#20102;&#26412;&#22320;&#25968;&#25454;&#38598;&#65288;&#32479;&#35745;&#25968;&#25454;&#65289;&#21644;&#23427;&#20204;&#30456;&#20851;&#30340;&#26412;&#22320;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#19968;&#31181;&#23454;&#20363;&#65292;&#20854;&#20013;&#27491;&#21017;&#21270;&#39033;&#26159;&#20174;&#25968;&#25454;&#30340;&#32593;&#32476;&#32467;&#26500;&#23548;&#20986;&#30340;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35201;&#27714;&#33391;&#22909;&#36830;&#25509;&#30340;&#26412;&#22320;&#27169;&#22411;&#24418;&#25104;&#32858;&#31867;&#65292;&#22312;&#19968;&#20010;&#20844;&#20849;&#27979;&#35797;&#38598;&#19978;&#20135;&#29983;&#30456;&#20284;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20801;&#35768;&#20351;&#29992;&#21508;&#31181;&#21508;&#26679;&#30340;&#26412;&#22320;&#27169;&#22411;&#12290; &#23545;&#36825;&#20123;&#26412;&#22320;&#27169;&#22411;&#21807;&#19968;&#30340;&#38480;&#21046;&#26159;&#23427;&#20204;&#20801;&#35768;&#26377;&#25928;&#23454;&#29616;&#27491;&#21017;&#21270;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;&#35757;&#32451;&#65289;&#12290;&#23545;&#20110;&#21508;&#31181;&#27169;&#22411;&#65292;&#36825;&#26679;&#30340;&#23454;&#29616;&#37117;&#21487;&#20197;&#22312;&#39640;&#32423;&#32534;&#31243;&#24211;&#65288;&#21253;&#25324;scikit-learn&#12289;Keras&#25110;PyTorch&#65289;&#20013;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a model-agnostic federated learning method for networks of heterogeneous data and models. The network structure reflects similarities between the (statistics of) local datasets and, in turn, their associated local("personal") models. Our method is an instance of empirical risk minimization, with the regularization term derived from the network structure of data. In particular, we require well-connected local models, forming clusters, to yield similar predictions on a common test set. The proposed method allows for a wide range of local models. The only restriction on these local models is that they allow for efficient implementation of regularized empirical risk minimization (training). For a wide range of models, such implementations are available in high-level programming libraries including scikit-learn, Keras or PyTorch.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25209;&#37327;&#27979;&#35797;&#22312;&#27969;&#25968;&#25454;&#19978;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26681;&#25454;&#20219;&#21153;&#22797;&#26434;&#24615;&#33258;&#36866;&#24212;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#21518;&#25345;&#32493;&#30417;&#27979;&#21644;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;</title><link>http://arxiv.org/abs/2212.07383</link><description>&lt;p&gt;
&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Sequential Kernelized Independence Testing. (arXiv:2212.07383v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07383
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25209;&#37327;&#27979;&#35797;&#22312;&#27969;&#25968;&#25454;&#19978;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26681;&#25454;&#20219;&#21153;&#22797;&#26434;&#24615;&#33258;&#36866;&#24212;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#21518;&#25345;&#32493;&#30417;&#27979;&#21644;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29420;&#31435;&#24615;&#27979;&#35797;&#26159;&#19968;&#20010;&#32463;&#20856;&#30340;&#32479;&#35745;&#38382;&#39064;&#65292;&#22312;&#22266;&#23450;&#37319;&#38598;&#25968;&#25454;&#20043;&#21069;&#30340;&#25209;&#37327;&#35774;&#32622;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#23454;&#36341;&#32773;&#20204;&#24448;&#24448;&#26356;&#21916;&#27426;&#33021;&#22815;&#26681;&#25454;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#36827;&#34892;&#33258;&#36866;&#24212;&#30340;&#31243;&#24207;&#65292;&#32780;&#19981;&#26159;&#20107;&#20808;&#35774;&#23450;&#26679;&#26412;&#22823;&#23567;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#36825;&#26679;&#30340;&#31243;&#24207;&#24212;&#35813;&#65288;a&#65289;&#22312;&#31616;&#21333;&#20219;&#21153;&#19978;&#23613;&#26089;&#20572;&#27490;&#65288;&#22312;&#22256;&#38590;&#20219;&#21153;&#19978;&#31245;&#21518;&#20572;&#27490;&#65289;&#65292;&#22240;&#27492;&#26356;&#22909;&#22320;&#21033;&#29992;&#21487;&#29992;&#36164;&#28304;&#65292;&#20197;&#21450;&#65288;b&#65289;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#20043;&#21518;&#65292;&#25345;&#32493;&#30417;&#27979;&#25968;&#25454;&#24182;&#39640;&#25928;&#22320;&#25972;&#21512;&#32479;&#35745;&#35777;&#25454;&#65292;&#21516;&#26102;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;&#32463;&#20856;&#30340;&#25209;&#37327;&#27979;&#35797;&#19981;&#36866;&#29992;&#20110;&#27969;&#25968;&#25454;&#65306;&#22312;&#25968;&#25454;&#35266;&#23519;&#21518;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#38656;&#35201;&#23545;&#22810;&#37325;&#27979;&#35797;&#36827;&#34892;&#26657;&#27491;&#65292;&#36825;&#23548;&#33268;&#20102;&#20302;&#21151;&#29575;&#12290;&#36981;&#24490;&#36890;&#36807;&#25237;&#27880;&#36827;&#34892;&#27979;&#35797;&#30340;&#21407;&#21017;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#20811;&#26381;&#20102;&#36825;&#20123;&#32570;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#30001;&#26680;&#30456;&#20851;&#24615;&#27979;&#24230;&#65288;&#22914;Hilbert-&#65289;&#21551;&#21457;&#30340;&#25237;&#27880;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#24191;&#27867;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Independence testing is a classical statistical problem that has been extensively studied in the batch setting when one fixes the sample size before collecting data. However, practitioners often prefer procedures that adapt to the complexity of a problem at hand instead of setting sample size in advance. Ideally, such procedures should (a) stop earlier on easy tasks (and later on harder tasks), hence making better use of available resources, and (b) continuously monitor the data and efficiently incorporate statistical evidence after collecting new data, while controlling the false alarm rate. Classical batch tests are not tailored for streaming data: valid inference after data peeking requires correcting for multiple testing which results in low power. Following the principle of testing by betting, we design sequential kernelized independence tests that overcome such shortcomings. We exemplify our broad framework using bets inspired by kernelized dependence measures, e.g., the Hilbert-
&lt;/p&gt;</description></item></channel></rss>