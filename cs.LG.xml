<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20026;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#24102;&#26469;&#26032;&#39062;&#35270;&#35282;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#26631;&#20934;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#20989;&#25968;&#36924;&#36817;&#30340;&#21306;&#21035;&#12290;</title><link>https://arxiv.org/abs/2403.09621</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#20998;&#24067;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09621
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20026;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#24102;&#26469;&#26032;&#39062;&#35270;&#35282;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#26631;&#20934;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#20989;&#25968;&#36924;&#36817;&#30340;&#21306;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#23547;&#27714;&#38024;&#23545;&#29615;&#22659;&#25200;&#21160;&#30340;&#40065;&#26834;&#31574;&#30053;&#35757;&#32451;&#65292;&#36890;&#36807;&#24314;&#27169;&#21160;&#24577;&#19981;&#30830;&#23450;&#24615;&#26469;&#35843;&#29992;&#20989;&#25968;&#36924;&#36817;&#65292;&#24403;&#38754;&#23545;&#24222;&#22823;&#30340;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#26102;&#65292;&#36825;&#31181;RL&#38656;&#35201;&#32771;&#34385;&#21040;&#21160;&#24577;&#19981;&#30830;&#23450;&#24615;&#65292;&#24341;&#20837;&#20102;&#22522;&#26412;&#30340;&#38750;&#32447;&#24615;&#21644;&#35745;&#31639;&#36127;&#25285;&#65292;&#36825;&#32473;&#20998;&#26512;&#21644;&#23454;&#38469;&#24212;&#29992;&#20989;&#25968;&#36924;&#36817;&#25552;&#20986;&#20102;&#29420;&#29305;&#25361;&#25112;&#12290;&#22312;&#22522;&#26412;&#35774;&#32622;&#19979;&#65292;&#25552;&#35758;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20989;&#25968;&#36924;&#36817;&#65292;&#24182;&#22312;&#40065;&#26834;&#31163;&#32447;RL&#30340;&#32972;&#26223;&#19979;&#21551;&#21160;&#23545;&#23454;&#20363;&#30456;&#20851;&#27425;&#20248;&#24615;&#20998;&#26512;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#40065;&#26834;&#31163;&#32447;RL&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#26412;&#36136;&#19978;&#19982;&#26631;&#20934;&#31163;&#32447;RL&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#26377;&#26126;&#26174;&#21306;&#21035;&#65292;&#21487;&#33021;&#26356;&#21152;&#22256;&#38590;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#29702;&#35770;&#32467;&#26524;&#33267;&#20851;&#37325;&#35201;&#22320;&#20381;&#36182;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09621v1 Announce Type: cross  Abstract: Distributionally robust offline reinforcement learning (RL), which seeks robust policy training against environment perturbation by modeling dynamics uncertainty, calls for function approximations when facing large state-action spaces. However, the consideration of dynamics uncertainty introduces essential nonlinearity and computational burden, posing unique challenges for analyzing and practically employing function approximation. Focusing on a basic setting where the nominal model and perturbed models are linearly parameterized, we propose minimax optimal and computationally efficient algorithms realizing function approximation and initiate the study on instance-dependent suboptimality analysis in the context of robust offline RL. Our results uncover that function approximation in robust offline RL is essentially distinct from and probably harder than that in standard offline RL. Our algorithms and theoretical results crucially depen
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#35889;&#20998;&#35299;&#21644;&#25193;&#25955;&#36807;&#31243;&#30340;&#26032;&#39062;&#22270;&#29983;&#25104;&#27169;&#22411;GRASP&#65292;&#33021;&#22815;&#36890;&#36807;&#25130;&#26029;&#25289;&#26222;&#25289;&#26031;&#39057;&#35889;&#24555;&#36895;&#20934;&#30830;&#22320;&#25429;&#25417;&#22270;&#30340;&#32467;&#26500;&#29305;&#24449;&#65292;&#21516;&#26102;&#22788;&#29702;&#33410;&#28857;&#29305;&#24449;&#65292;&#36991;&#20813;&#20102;&#20108;&#27425;&#22797;&#26434;&#24615;&#29942;&#39048;&#12290;</title><link>https://arxiv.org/abs/2402.18974</link><description>&lt;p&gt;
&#36890;&#36807;&#35889;&#25193;&#25955;&#29983;&#25104;&#22270;&#24418;
&lt;/p&gt;
&lt;p&gt;
Graph Generation via Spectral Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18974
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#35889;&#20998;&#35299;&#21644;&#25193;&#25955;&#36807;&#31243;&#30340;&#26032;&#39062;&#22270;&#29983;&#25104;&#27169;&#22411;GRASP&#65292;&#33021;&#22815;&#36890;&#36807;&#25130;&#26029;&#25289;&#26222;&#25289;&#26031;&#39057;&#35889;&#24555;&#36895;&#20934;&#30830;&#22320;&#25429;&#25417;&#22270;&#30340;&#32467;&#26500;&#29305;&#24449;&#65292;&#21516;&#26102;&#22788;&#29702;&#33410;&#28857;&#29305;&#24449;&#65292;&#36991;&#20813;&#20102;&#20108;&#27425;&#22797;&#26434;&#24615;&#29942;&#39048;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;GRASP&#65292;&#19968;&#31181;&#22522;&#20110;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#30340;&#35889;&#20998;&#35299;&#21644;&#25193;&#25955;&#36807;&#31243;&#30340;&#26032;&#39062;&#22270;&#29983;&#25104;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21435;&#22122;&#27169;&#22411;&#20174;&#20013;&#37319;&#26679;&#29305;&#24449;&#21521;&#37327;&#21644;&#29305;&#24449;&#20540;&#65292;&#20174;&#32780;&#21487;&#20197;&#37325;&#24314;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#21644;&#37051;&#25509;&#30697;&#38453;&#12290;&#25105;&#20204;&#30340;&#32622;&#25442;&#19981;&#21464;&#27169;&#22411;&#36824;&#21487;&#20197;&#36890;&#36807;&#23558;&#33410;&#28857;&#29305;&#24449;&#36830;&#25509;&#21040;&#27599;&#20010;&#33410;&#28857;&#30340;&#29305;&#24449;&#21521;&#37327;&#26469;&#22788;&#29702;&#33410;&#28857;&#29305;&#24449;&#12290;&#20351;&#29992;&#25289;&#26222;&#25289;&#26031;&#39057;&#35889;&#20351;&#25105;&#20204;&#33021;&#22815;&#33258;&#28982;&#25429;&#33719;&#22270;&#30340;&#32467;&#26500;&#29305;&#24449;&#65292;&#24182;&#30452;&#25509;&#22312;&#33410;&#28857;&#31354;&#38388;&#20013;&#24037;&#20316;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#38480;&#21046;&#20854;&#20182;&#26041;&#27861;&#36866;&#29992;&#24615;&#30340;&#20108;&#27425;&#22797;&#26434;&#24615;&#29942;&#39048;&#12290;&#36890;&#36807;&#25130;&#26029;&#35889;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#26356;&#24555;&#20294;&#20934;&#30830;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#36825;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;&#23545;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#22270;&#24418;&#30340;&#22823;&#37327;&#23454;&#39564;&#26174;&#31034;&#20102;&#25105;&#20204;&#27169;&#22411;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18974v1 Announce Type: new  Abstract: In this paper, we present GRASP, a novel graph generative model based on 1) the spectral decomposition of the graph Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian and adjacency matrix. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the graph and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other methods. This is achieved by truncating the spectrum, which as we show in our experiments results in a faster yet accurate generative process. An extensive set of experiments on both synthetic and real world graphs demonstrates the strengths of our model against state-of-the-art a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22312;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#22788;&#29702;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#30340;&#26041;&#27861;&#65292;&#23454;&#26045;&#20102;&#20351;&#29992;&#29109;&#20998;&#25968;&#21644;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#26469;&#25351;&#23548;&#27169;&#22411;&#30340;&#31574;&#30053;&#65292;&#24182;&#22312;&#23454;&#35777;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30456;&#23545;&#20110;&#25932;&#23545;&#29702;&#30001;&#30340;&#31283;&#20581;&#24615;&#33021;&#20248;&#21183;</title><link>https://arxiv.org/abs/2402.14337</link><description>&lt;p&gt;
AURA&#65306;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#30340;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
AURA: Natural Language Reasoning for Aleatoric Uncertainty in Rationales
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14337
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22312;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#22788;&#29702;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#30340;&#26041;&#27861;&#65292;&#23454;&#26045;&#20102;&#20351;&#29992;&#29109;&#20998;&#25968;&#21644;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#26469;&#25351;&#23548;&#27169;&#22411;&#30340;&#31574;&#30053;&#65292;&#24182;&#22312;&#23454;&#35777;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30456;&#23545;&#20110;&#25932;&#23545;&#29702;&#30001;&#30340;&#31283;&#20581;&#24615;&#33021;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#31574;&#32972;&#21518;&#30340;&#29702;&#30001;&#19981;&#20165;&#35299;&#37322;&#20102;&#27169;&#22411;&#20915;&#31574;&#65292;&#32780;&#19988;&#25552;&#21319;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#33719;&#24471;&#26080;&#25032;&#21487;&#20987;&#30340;&#29702;&#30001;&#36890;&#24120;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#27492;&#22806;&#65292;&#20272;&#35745;&#29702;&#30001;&#36275;&#22815;&#24544;&#23454;&#20197;&#40723;&#21169;&#27169;&#22411;&#34920;&#29616;&#30340;&#31243;&#24230;&#24182;&#19981;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#25512;&#29702;&#20219;&#21153;&#36890;&#24120;&#36843;&#20351;&#27169;&#22411;&#22312;&#19981;&#29702;&#24819;&#30340;&#29702;&#30001;&#19979;&#36755;&#20986;&#27491;&#30830;&#31572;&#26696;&#65292;&#24182;&#19988;&#19982;&#27169;&#22411;&#23436;&#20840;&#26377;&#33021;&#21147;&#30340;&#24773;&#20917;&#30456;&#27604;&#26159;&#27425;&#20248;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22914;&#20309;&#24212;&#23545;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#12290;&#25105;&#20204;&#39318;&#20808;&#29992;&#32473;&#23450;&#29702;&#30001;&#30340;&#29109;&#20998;&#25968;&#26469;&#23450;&#20041;&#27169;&#31946;&#30340;&#29702;&#30001;&#65292;&#20351;&#29992;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#20316;&#20026;&#20449;&#24687;&#37327;&#12290;&#28982;&#21518;&#26681;&#25454;&#29702;&#30001;&#30340;&#27169;&#31946;&#24615;&#26469;&#24341;&#23548;&#27169;&#22411;&#36873;&#25321;&#20004;&#31181;&#19981;&#21516;&#30340;&#25512;&#29702;&#27169;&#22411;&#20013;&#30340;&#19968;&#31181;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#19978;&#35770;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#29702;&#30001;&#30340;&#25932;&#23545;&#36136;&#37327;&#20135;&#29983;&#20102;&#31283;&#20581;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14337v1 Announce Type: new  Abstract: Rationales behind answers not only explain model decisions but boost language models to reason well on complex reasoning tasks. However, obtaining impeccable rationales is often impossible. Besides, it is non-trivial to estimate the degree to which the rationales are faithful enough to encourage model performance. Thus, such reasoning tasks often compel models to output correct answers under undesirable rationales and are sub-optimal compared to what the models are fully capable of. In this work, we propose how to deal with imperfect rationales causing aleatoric uncertainty. We first define the ambiguous rationales with entropy scores of given rationales, using model prior beliefs as informativeness. We then guide models to select one of two different reasoning models according to the ambiguity of rationales. We empirically argue that our proposed method produces robust performance superiority against the adversarial quality of rationale
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;ReLU-like&#28608;&#27963;&#20989;&#25968;&#20197;&#32463;&#39564;&#24179;&#26041;&#25439;&#22833;&#35757;&#32451;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#25552;&#20986;&#20102;&#31283;&#23450;&#28857;&#26465;&#20214;&#21644;&#36867;&#36920;&#31070;&#32463;&#20803;&#30340;&#23450;&#20041;&#65292;&#24182;&#23558;&#38797;&#28857;&#36867;&#36920;&#19982;&#36867;&#36920;&#31070;&#32463;&#20803;&#30340;&#21442;&#25968;&#21464;&#21270;&#32852;&#31995;&#36215;&#26469;&#12290;</title><link>https://arxiv.org/abs/2402.05626</link><description>&lt;p&gt;
&#27973;&#23618;ReLU-like&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#26223;&#35266;&#65306;&#31283;&#23450;&#28857;&#12289;&#38797;&#28857;&#36867;&#36920;&#21644;&#32593;&#32476;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
The Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle Escaping, and Network Embedding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;ReLU-like&#28608;&#27963;&#20989;&#25968;&#20197;&#32463;&#39564;&#24179;&#26041;&#25439;&#22833;&#35757;&#32451;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#25552;&#20986;&#20102;&#31283;&#23450;&#28857;&#26465;&#20214;&#21644;&#36867;&#36920;&#31070;&#32463;&#20803;&#30340;&#23450;&#20041;&#65292;&#24182;&#23558;&#38797;&#28857;&#36867;&#36920;&#19982;&#36867;&#36920;&#31070;&#32463;&#20803;&#30340;&#21442;&#25968;&#21464;&#21270;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;ReLU-like&#28608;&#27963;&#20989;&#25968;&#20197;&#32463;&#39564;&#24179;&#26041;&#25439;&#22833;&#35757;&#32451;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#26223;&#35266;&#12290;&#30001;&#20110;&#28608;&#27963;&#20989;&#25968;&#26159;&#19981;&#21487;&#24494;&#30340;&#65292;&#30446;&#21069;&#36824;&#19981;&#28165;&#26970;&#22914;&#20309;&#23436;&#20840;&#25551;&#36848;&#31283;&#23450;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#38750;&#21487;&#24494;&#21644;&#21487;&#24494;&#24773;&#20917;&#30340;&#31283;&#23450;&#28857;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#26524;&#19968;&#20010;&#31283;&#23450;&#28857;&#19981;&#21253;&#21547;&#8220;&#36867;&#36920;&#31070;&#32463;&#20803;&#8221;&#65288;&#36890;&#36807;&#19968;&#38454;&#26465;&#20214;&#23450;&#20041;&#65289;&#65292;&#37027;&#20040;&#23427;&#24517;&#23450;&#26159;&#19968;&#20010;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#27492;&#22806;&#65292;&#22312;&#26631;&#37327;&#36755;&#20986;&#24773;&#20917;&#19979;&#65292;&#36867;&#36920;&#31070;&#32463;&#20803;&#30340;&#23384;&#22312;&#20445;&#35777;&#20102;&#31283;&#23450;&#28857;&#19981;&#26159;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36827;&#19968;&#27493;&#25551;&#36848;&#20102;&#20174;&#26080;&#31351;&#23567;&#65288;&#28040;&#22833;&#65289;&#21021;&#22987;&#21270;&#24320;&#22987;&#30340;&#27973;&#23618;ReLU-like&#32593;&#32476;&#30340;&#38797;&#28857;&#21040;&#38797;&#28857;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#30452;&#25509;&#23558;&#38797;&#28857;&#36867;&#36920;&#19982;&#36867;&#36920;&#31070;&#32463;&#20803;&#30340;&#21442;&#25968;&#21464;&#21270;&#32852;&#31995;&#36215;&#26469;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23436;&#20840;&#35752;&#35770;&#20102;&#32593;&#32476;&#23884;&#20837;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the loss landscape of one-hidden-layer neural networks with ReLU-like activation functions trained with the empirical squared loss. As the activation function is non-differentiable, it is so far unclear how to completely characterize the stationary points. We propose the conditions for stationarity that apply to both non-differentiable and differentiable cases. Additionally, we show that, if a stationary point does not contain "escape neurons", which are defined with first-order conditions, then it must be a local minimum. Moreover, for the scalar-output case, the presence of an escape neuron guarantees that the stationary point is not a local minimum. Our results refine the description of the saddle-to-saddle training process starting from infinitesimally small (vanishing) initialization for shallow ReLU-like networks, linking saddle escaping directly with the parameter changes of escape neurons. Moreover, we are also able to fully discuss how network emb
&lt;/p&gt;</description></item><item><title>DiffTOP&#20351;&#29992;&#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#20316;&#20026;&#31574;&#30053;&#34920;&#31034;&#26469;&#29983;&#25104;&#21160;&#20316;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#8220;&#30446;&#26631;&#19981;&#21305;&#37197;&#8221;&#38382;&#39064;&#65292;&#24182;&#22312;&#27169;&#20223;&#23398;&#20064;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>https://arxiv.org/abs/2402.05421</link><description>&lt;p&gt;
DiffTOP: &#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#22312;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
DiffTOP: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05421
&lt;/p&gt;
&lt;p&gt;
DiffTOP&#20351;&#29992;&#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#20316;&#20026;&#31574;&#30053;&#34920;&#31034;&#26469;&#29983;&#25104;&#21160;&#20316;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#8220;&#30446;&#26631;&#19981;&#21305;&#37197;&#8221;&#38382;&#39064;&#65292;&#24182;&#22312;&#27169;&#20223;&#23398;&#20064;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;DiffTOP&#65292;&#23427;&#21033;&#29992;&#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#20316;&#20026;&#31574;&#30053;&#34920;&#31034;&#65292;&#20026;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#29983;&#25104;&#21160;&#20316;&#12290;&#36712;&#36857;&#20248;&#21270;&#26159;&#19968;&#31181;&#22312;&#25511;&#21046;&#39046;&#22495;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#65292;&#30001;&#25104;&#26412;&#21644;&#21160;&#21147;&#23398;&#20989;&#25968;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20851;&#38190;&#26159;&#21033;&#29992;&#20102;&#26368;&#36817;&#22312;&#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#20351;&#24471;&#21487;&#20197;&#35745;&#31639;&#25439;&#22833;&#23545;&#20110;&#36712;&#36857;&#20248;&#21270;&#30340;&#21442;&#25968;&#30340;&#26799;&#24230;&#12290;&#22240;&#27492;&#65292;&#36712;&#36857;&#20248;&#21270;&#30340;&#25104;&#26412;&#21644;&#21160;&#21147;&#23398;&#20989;&#25968;&#21487;&#20197;&#31471;&#21040;&#31471;&#22320;&#23398;&#20064;&#12290;DiffTOP&#35299;&#20915;&#20102;&#20043;&#21069;&#27169;&#22411;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#8220;&#30446;&#26631;&#19981;&#21305;&#37197;&#8221;&#38382;&#39064;&#65292;&#22240;&#20026;DiffTOP&#20013;&#30340;&#21160;&#21147;&#23398;&#27169;&#22411;&#36890;&#36807;&#36712;&#36857;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#31574;&#30053;&#26799;&#24230;&#25439;&#22833;&#30452;&#25509;&#26368;&#22823;&#21270;&#20219;&#21153;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23545;DiffTOP&#22312;&#26631;&#20934;&#26426;&#22120;&#20154;&#25805;&#32437;&#20219;&#21153;&#22871;&#20214;&#20013;&#36827;&#34892;&#20102;&#27169;&#20223;&#23398;&#20064;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces DiffTOP, which utilizes Differentiable Trajectory OPtimization as the policy representation to generate actions for deep reinforcement and imitation learning. Trajectory optimization is a powerful and widely used algorithm in control, parameterized by a cost and a dynamics function. The key to our approach is to leverage the recent progress in differentiable trajectory optimization, which enables computing the gradients of the loss with respect to the parameters of trajectory optimization. As a result, the cost and dynamics functions of trajectory optimization can be learned end-to-end. DiffTOP addresses the ``objective mismatch'' issue of prior model-based RL algorithms, as the dynamics model in DiffTOP is learned to directly maximize task performance by differentiating the policy gradient loss through the trajectory optimization process. We further benchmark DiffTOP for imitation learning on standard robotic manipulation task suites with high-dimensional sensory
&lt;/p&gt;</description></item><item><title>EAGLE&#26159;&#19968;&#20010;&#26080;&#25439;&#21152;&#36895;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#27425;&#39030;&#23618;&#29305;&#24449;&#23618;&#38754;&#19978;&#33258;&#22238;&#24402;&#25512;&#29702;&#65292;&#24182;&#35299;&#20915;&#37319;&#26679;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#24555;3&#20493;&#30340;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.15077</link><description>&lt;p&gt;
EAGLE: &#25512;&#27979;&#37319;&#26679;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#29305;&#24449;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty. (arXiv:2401.15077v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15077
&lt;/p&gt;
&lt;p&gt;
EAGLE&#26159;&#19968;&#20010;&#26080;&#25439;&#21152;&#36895;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#27425;&#39030;&#23618;&#29305;&#24449;&#23618;&#38754;&#19978;&#33258;&#22238;&#24402;&#25512;&#29702;&#65292;&#24182;&#35299;&#20915;&#37319;&#26679;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#24555;3&#20493;&#30340;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#22238;&#24402;&#35299;&#30721;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#21464;&#24471;&#32791;&#26102;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26694;&#26550;&#65292;EAGLE&#65288;&#29992;&#20110;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#25928;&#29575;&#30340;&#22806;&#25512;&#31639;&#27861;&#65289;&#65292;&#23454;&#29616;&#20102;&#26080;&#25439;&#21152;&#36895;&#12290;&#19982;&#20256;&#32479;&#30340;&#25512;&#27979;&#37319;&#26679;&#26041;&#27861;&#19981;&#21516;&#65292;EAGLE&#22312;&#26356;&#35268;&#24459;&#30340;&#65288;&#27425;&#39030;&#23618;&#65289;&#29305;&#24449;&#23618;&#38754;&#19978;&#33258;&#22238;&#24402;&#36827;&#34892;&#32534;&#20889;&#65292;&#24182;&#36890;&#36807;&#25972;&#21512;&#25552;&#21069;&#19968;&#20010;&#26102;&#38388;&#27493;&#30340;&#26631;&#35760;&#26469;&#35299;&#20915;&#19979;&#19968;&#20010;&#29305;&#24449;&#39044;&#27979;&#38382;&#39064;&#20013;&#30340;&#37319;&#26679;&#19981;&#30830;&#23450;&#24615;&#12290;EAGLE&#25152;&#25552;&#20379;&#30340;&#21152;&#36895;&#26159;&#26080;&#25439;&#30340;&#65306;&#23427;&#19981;&#38656;&#35201;&#24494;&#35843;&#30446;&#26631;LLM&#65292;&#24182;&#19988;&#29983;&#25104;&#30340;&#25991;&#26412;&#19982;&#21407;&#22987;&#30340;&#33258;&#22238;&#24402;&#35299;&#30721;&#30340;&#20998;&#24067;&#30456;&#21516;&#12290;&#25130;&#33267;&#26412;&#25991;&#25552;&#20132;&#26102;&#65292;EAGLE&#26159;&#24050;&#30693;&#25512;&#27979;&#37319;&#26679;&#23478;&#26063;&#20013;&#36895;&#24230;&#26368;&#24555;&#30340;&#26694;&#26550;&#12290;&#22312;MT-bench&#19978;&#65292;EAGLE&#27604;&#21407;&#22987;&#35299;&#30721;&#24555;3&#20493;&#65292;&#27604;Lookahead&#24555;2&#20493;&#65292;&#27604;Medusa&#24555;1.6&#20493;&#12290;&#20351;&#29992;gpt-fast&#65292;EAGLE&#24179;&#22343;&#27599;&#31186;&#36798;&#21040;160&#20010;&#26631;&#35760;&#19982;LLaMA2-Chat&#25645;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Auto-regressive decoding makes the inference of Large Language Models (LLMs) time-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm for Greater Language-model Efficiency), for lossless acceleration. Unlike traditional speculative sampling methods, EAGLE operates the drafting process auto-regressively at the more regular (second-top-layer) feature level and addresses the sampling uncertainty issues in the next-feature prediction problems by integrating tokens from one time step ahead. The acceleration provided by EAGLE is lossless: it involves no fine-tuning of the target LLM, and the generated text maintains the same distribution as that of vanilla auto-regressive decoding. As of the submission of this paper, EAGLE is the fastest known framework within the speculative sampling family. On MT-bench, EAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x faster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with LLaMA2-Chat 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#36951;&#25022;&#21305;&#37197;&#30340;&#31639;&#27861;&#22312;&#28216;&#25103;&#20013;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#36136;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#21457;&#29616;&#22810;&#20010;&#23454;&#38469;&#21464;&#20307;&#22312;&#31616;&#21333;&#30340;&#28216;&#25103;&#20013;&#32570;&#20047;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#20445;&#35777;&#65292;&#32780;&#22522;&#20110;&#24179;&#28369;&#25216;&#26415;&#30340;&#26368;&#36817;&#21464;&#20307;&#21017;&#20855;&#26377;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.00676</link><description>&lt;p&gt;
Regret-Matching&#31639;&#27861;&#22312;&#28216;&#25103;&#20013;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games. (arXiv:2311.00676v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00676
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#36951;&#25022;&#21305;&#37197;&#30340;&#31639;&#27861;&#22312;&#28216;&#25103;&#20013;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#36136;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#21457;&#29616;&#22810;&#20010;&#23454;&#38469;&#21464;&#20307;&#22312;&#31616;&#21333;&#30340;&#28216;&#25103;&#20013;&#32570;&#20047;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#20445;&#35777;&#65292;&#32780;&#22522;&#20110;&#24179;&#28369;&#25216;&#26415;&#30340;&#26368;&#36817;&#21464;&#20307;&#21017;&#20855;&#26377;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#36951;&#25022;&#21305;&#37197;&#30340;&#31639;&#27861;&#65292;&#29305;&#21035;&#26159;&#36951;&#25022;&#21305;&#37197;+ (RM+)&#21450;&#20854;&#21464;&#31181;&#65292;&#26159;&#35299;&#20915;&#22823;&#35268;&#27169;&#21452;&#20154;&#38646;&#21644;&#28216;&#25103;&#30340;&#26368;&#27969;&#34892;&#26041;&#27861;&#12290;&#19982;&#20855;&#26377;&#38646;&#21644;&#28216;&#25103;&#30340;&#24378;&#26368;&#32456;&#36845;&#20195;&#21644;&#36941;&#21382;&#25910;&#25947;&#24615;&#36136;&#30340;&#31639;&#27861;&#65288;&#22914;&#20048;&#35266;&#26799;&#24230;&#19978;&#21319;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#23545;&#20110;&#36951;&#25022;&#21305;&#37197;&#31639;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#24615;&#36136;&#20960;&#20046;&#19968;&#26080;&#25152;&#30693;&#12290;&#37492;&#20110;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#23545;&#20110;&#25968;&#20540;&#20248;&#21270;&#21644;&#27169;&#25311;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#28216;&#25103;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#21508;&#31181;&#27969;&#34892;&#30340;RM+&#21464;&#20307;&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#36136;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#65292;&#21253;&#25324;&#21516;&#26102;RM+&#12289;&#20132;&#26367;RM+&#21644;&#21516;&#26102;&#39044;&#27979;RM+&#22312;&#20869;&#30340;&#20960;&#20010;&#23454;&#38469;&#21464;&#20307;&#65292;&#29978;&#33267;&#22312;&#31616;&#21333;&#30340;3x3&#28216;&#25103;&#20013;&#20063;&#32570;&#20047;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#20445;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#26368;&#36817;&#21464;&#20307;&#65292;&#22522;&#20110;&#24179;&#28369;&#25216;&#26415;&#24471;&#21040;&#20102;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms based on regret matching, specifically regret matching$^+$ (RM$^+$), and its variants are the most popular approaches for solving large-scale two-player zero-sum games in practice. Unlike algorithms such as optimistic gradient descent ascent, which have strong last-iterate and ergodic convergence properties for zero-sum games, virtually nothing is known about the last-iterate properties of regret-matching algorithms. Given the importance of last-iterate convergence for numerical optimization reasons and relevance as modeling real-word learning in games, in this paper, we study the last-iterate convergence properties of various popular variants of RM$^+$. First, we show numerically that several practical variants such as simultaneous RM$^+$, alternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate convergence guarantees even on a simple $3\times 3$ game. We then prove that recent variants of these algorithms based on a smoothing technique do enjoy last-it
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#38382;&#39064;&#65292;&#22312;&#28176;&#36817;&#21644;&#38750;&#28176;&#36817;&#35774;&#32622;&#20013;&#25552;&#20986;&#20102;Tri-BBAI&#21644;Opt-BBAI&#31639;&#27861;&#65292;&#20998;&#21035;&#23454;&#29616;&#20102;&#26368;&#20248;&#21644;&#20960;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.14129</link><description>&lt;p&gt;
&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#30340;&#26368;&#20339;&#25209;&#22788;&#29702;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Batched Best Arm Identification. (arXiv:2310.14129v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#38382;&#39064;&#65292;&#22312;&#28176;&#36817;&#21644;&#38750;&#28176;&#36817;&#35774;&#32622;&#20013;&#25552;&#20986;&#20102;Tri-BBAI&#21644;Opt-BBAI&#31639;&#27861;&#65292;&#20998;&#21035;&#23454;&#29616;&#20102;&#26368;&#20248;&#21644;&#20960;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#65288;BBAI&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#22312;&#23613;&#37327;&#23569;&#22320;&#26356;&#25442;&#31574;&#30053;&#30340;&#21516;&#26102;&#35782;&#21035;&#20986;&#26368;&#20339;&#27494;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20197;&#27010;&#29575;$1-\delta$&#25214;&#21040;&#26368;&#20339;&#27494;&#22120;&#65292;&#20854;&#20013;$\delta&gt;0$&#26159;&#19968;&#20010;&#23567;&#24120;&#25968;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#26679;&#26412;&#22797;&#26434;&#24230;&#65288;&#27494;&#22120;&#25289;&#21462;&#30340;&#24635;&#25968;&#65289;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#65288;&#25209;&#22788;&#29702;&#30340;&#24635;&#25968;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#25209;&#27425;&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#65288;Tri-BBAI&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#28176;&#36817;&#35774;&#32622;&#65288;&#21363;$\delta\rightarrow0$&#65289;&#20013;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#19988;&#20165;&#22312;&#26368;&#22810;&#19977;&#20010;&#25209;&#27425;&#20013;&#36816;&#34892;&#30340;&#25209;&#22788;&#29702;&#31639;&#27861;&#12290;&#22522;&#20110;Tri-BBAI&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#20960;&#20046;&#26368;&#20248;&#30340;&#25209;&#22788;&#29702;&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#65288;Opt-BBAI&#65289;&#31639;&#27861;&#65292;&#22312;&#38750;&#28176;&#36817;&#35774;&#32622;&#65288;&#21363;$\delta&gt;0$&#26159;&#20219;&#24847;&#22266;&#23450;&#30340;&#65289;&#20013;&#23454;&#29616;&#36817;&#20284;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#65292;&#21516;&#26102;&#22312;$\delta$&#36235;&#20110;&#38646;&#26102;&#20139;&#21463;&#19982;Tri-BBAI&#30456;&#21516;&#30340;&#25209;&#22788;&#29702;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the batched best arm identification (BBAI) problem, where the learner's goal is to identify the best arm while switching the policy as less as possible. In particular, we aim to find the best arm with probability $1-\delta$ for some small constant $\delta&gt;0$ while minimizing both the sample complexity (total number of arm pulls) and the batch complexity (total number of batches). We propose the three-batch best arm identification (Tri-BBAI) algorithm, which is the first batched algorithm that achieves the optimal sample complexity in the asymptotic setting (i.e., $\delta\rightarrow 0$) and runs only in at most $3$ batches. Based on Tri-BBAI, we further propose the almost optimal batched best arm identification (Opt-BBAI) algorithm, which is the first algorithm that achieves the near-optimal sample and batch complexity in the non-asymptotic setting (i.e., $\delta&gt;0$ is arbitrarily fixed), while enjoying the same batch and sample complexity as Tri-BBAI when $\delta$ tends to zer
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#23398;&#20064;&#35770;&#35777;&#35821;&#20041;&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#35770;&#35777;&#27714;&#35299;&#22120;&#65292;&#24182;&#22312;&#24418;&#24335;&#35770;&#35777;&#21644;&#20154;&#26426;&#23545;&#35805;&#39046;&#22495;&#24320;&#36767;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2310.12309</link><description>&lt;p&gt;
&#19968;&#31181;&#32479;&#19968;&#30340;&#23398;&#20064;&#35770;&#35777;&#35821;&#20041;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unifying Framework for Learning Argumentation Semantics. (arXiv:2310.12309v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#23398;&#20064;&#35770;&#35777;&#35821;&#20041;&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#35770;&#35777;&#27714;&#35299;&#22120;&#65292;&#24182;&#22312;&#24418;&#24335;&#35770;&#35777;&#21644;&#20154;&#26426;&#23545;&#35805;&#39046;&#22495;&#24320;&#36767;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#35777;&#26159;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#19968;&#20010;&#38750;&#24120;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#28041;&#21450;&#21040;&#22312;&#20154;&#19982;&#20154;&#25110;&#20154;&#19982;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#20043;&#38388;&#30340;&#23545;&#35805;&#20013;&#25152;&#20351;&#29992;&#30340;&#35770;&#35777;&#30340;&#34920;&#31034;&#21644;&#35780;&#20272;&#12290;&#27491;&#24335;&#35770;&#35777;&#31995;&#32479;&#30340;&#21487;&#25509;&#21463;&#24615;&#35821;&#20041;&#23450;&#20041;&#20102;&#35770;&#35777;&#30340;&#25509;&#21463;&#25110;&#25298;&#32477;&#30340;&#26631;&#20934;&#12290;&#24050;&#32463;&#24320;&#21457;&#20102;&#19968;&#20123;&#31216;&#20026;&#35770;&#35777;&#27714;&#35299;&#22120;&#30340;&#36719;&#20214;&#31995;&#32479;&#65292;&#29992;&#20110;&#20351;&#29992;&#36825;&#20123;&#26631;&#20934;&#35745;&#31639;&#34987;&#25509;&#21463;/&#34987;&#25298;&#32477;&#30340;&#35770;&#35777;&#12290;&#20854;&#20013;&#19968;&#20123;&#31995;&#32479;&#36890;&#36807;&#20351;&#29992;&#19981;&#21487;&#35299;&#37322;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#35782;&#21035;&#25509;&#21463;&#30340;&#35770;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#37319;&#29992;&#24402;&#32435;&#36923;&#36753;&#32534;&#31243;&#26041;&#27861;&#20197;&#21487;&#35299;&#37322;&#30340;&#26041;&#24335;&#26469;&#23398;&#20064;&#22810;&#20010;&#25277;&#35937;&#21644;&#32467;&#26500;&#21270;&#35770;&#35777;&#26694;&#26550;&#30340;&#21487;&#25509;&#21463;&#24615;&#35821;&#20041;&#12290;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#20248;&#20110;&#29616;&#26377;&#30340;&#35770;&#35777;&#27714;&#35299;&#22120;&#65292;&#20174;&#32780;&#24320;&#36767;&#20102;&#24418;&#24335;&#35770;&#35777;&#21644;&#20154;&#26426;&#23545;&#35805;&#39046;&#22495;&#30340;&#26032;&#30340;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Argumentation is a very active research field of Artificial Intelligence concerned with the representation and evaluation of arguments used in dialogues between humans and/or artificial agents. Acceptability semantics of formal argumentation systems define the criteria for the acceptance or rejection of arguments. Several software systems, known as argumentation solvers, have been developed to compute the accepted/rejected arguments using such criteria. These include systems that learn to identify the accepted arguments using non-interpretable methods. In this paper we present a novel framework, which uses an Inductive Logic Programming approach to learn the acceptability semantics for several abstract and structured argumentation frameworks in an interpretable way. Through an empirical evaluation we show that our framework outperforms existing argumentation solvers, thus opening up new future research directions in the area of formal argumentation and human-machine dialogues.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#26694;&#26550;&#65288;ScoreAG&#65289;&#65292;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#24182;&#36890;&#36807;&#22270;&#20687;&#36716;&#25442;&#25110;&#26032;&#22270;&#20687;&#21512;&#25104;&#30340;&#26041;&#27861;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.04285</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#22270;&#20687;&#29983;&#25104;&#35780;&#20272;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing Robustness via Score-Based Adversarial Image Generation. (arXiv:2310.04285v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#26694;&#26550;&#65288;ScoreAG&#65289;&#65292;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#24182;&#36890;&#36807;&#22270;&#20687;&#36716;&#25442;&#25110;&#26032;&#22270;&#20687;&#21512;&#25104;&#30340;&#26041;&#27861;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#23545;&#25239;&#25915;&#20987;&#21644;&#38450;&#24481;&#37117;&#38598;&#20013;&#22312;&#23567;&#30340;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#20869;&#30340;&#25200;&#21160;&#19978;&#12290;&#28982;&#32780;&#65292;$\ell_p$&#23041;&#32961;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#21040;&#25152;&#26377;&#30456;&#20851;&#30340;&#20445;&#30041;&#35821;&#20041;&#30340;&#25200;&#21160;&#65292;&#22240;&#27492;&#65292;&#40065;&#26834;&#24615;&#35780;&#20272;&#30340;&#33539;&#22260;&#26159;&#26377;&#38480;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#65288;ScoreAG&#65289;&#65292;&#19968;&#31181;&#21033;&#29992;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#36827;&#23637;&#26469;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#26080;&#38480;&#21046;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#20811;&#26381;&#20102;&#23427;&#20204;&#30340;&#23616;&#38480;&#24615;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;ScoreAG&#22312;&#29983;&#25104;&#36924;&#30495;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#26102;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#21487;&#20197;&#36890;&#36807;&#36716;&#25442;&#29616;&#26377;&#22270;&#20687;&#25110;&#23436;&#20840;&#20174;&#38646;&#24320;&#22987;&#21512;&#25104;&#26032;&#22270;&#20687;&#30340;&#26041;&#24335;&#23454;&#29616;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21033;&#29992;ScoreAG&#30340;&#29983;&#25104;&#33021;&#21147;&#26469;&#20928;&#21270;&#22270;&#20687;&#65292;&#20174;&#32463;&#39564;&#19978;&#22686;&#24378;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;ScoreAG&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#30340;&#24615;&#33021;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most adversarial attacks and defenses focus on perturbations within small $\ell_p$-norm constraints. However, $\ell_p$ threat models cannot capture all relevant semantic-preserving perturbations, and hence, the scope of robustness evaluations is limited. In this work, we introduce Score-Based Adversarial Generation (ScoreAG), a novel framework that leverages the advancements in score-based generative models to generate adversarial examples beyond $\ell_p$-norm constraints, so-called unrestricted adversarial examples, overcoming their limitations. Unlike traditional methods, ScoreAG maintains the core semantics of images while generating realistic adversarial examples, either by transforming existing images or synthesizing new ones entirely from scratch. We further exploit the generative capability of ScoreAG to purify images, empirically enhancing the robustness of classifiers. Our extensive empirical evaluation demonstrates that ScoreAG matches the performance of state-of-the-art atta
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#33258;&#20027;&#37327;&#23376;&#28909;&#26426;&#23454;&#29616;&#20102;&#28909;&#21147;&#23398;&#35745;&#31639;&#27169;&#22411;&#12290;&#36890;&#36807;&#28909;&#27969;&#36827;&#34892;&#35745;&#31639;&#65292;&#21487;&#23454;&#29616;&#20219;&#20309;&#32447;&#24615;&#21487;&#20998;&#31163;&#20989;&#25968;&#65292;&#24182;&#21487;&#25193;&#23637;&#21040;&#31070;&#32463;&#20803;&#32593;&#32476;&#25191;&#34892;&#20219;&#20309; needed&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.15905</link><description>&lt;p&gt;
&#36890;&#36807;&#33258;&#20027;&#37327;&#23376;&#28909;&#26426;&#23454;&#29616;&#28909;&#21147;&#23398;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Thermodynamic Computing via Autonomous Quantum Thermal Machines. (arXiv:2308.15905v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15905
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#33258;&#20027;&#37327;&#23376;&#28909;&#26426;&#23454;&#29616;&#20102;&#28909;&#21147;&#23398;&#35745;&#31639;&#27169;&#22411;&#12290;&#36890;&#36807;&#28909;&#27969;&#36827;&#34892;&#35745;&#31639;&#65292;&#21487;&#23454;&#29616;&#20219;&#20309;&#32447;&#24615;&#21487;&#20998;&#31163;&#20989;&#25968;&#65292;&#24182;&#21487;&#25193;&#23637;&#21040;&#31070;&#32463;&#20803;&#32593;&#32476;&#25191;&#34892;&#20219;&#20309; needed&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22522;&#20110;&#33258;&#20027;&#37327;&#23376;&#28909;&#26426;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#32463;&#20856;&#35745;&#31639;&#12290;&#36825;&#20123;&#26426;&#22120;&#30001;&#23569;&#25968;&#30456;&#20114;&#20316;&#29992;&#30340;&#37327;&#23376;&#20301;&#65288;qubits&#65289;&#19982;&#19981;&#21516;&#28201;&#24230;&#30340;&#20960;&#20010;&#29615;&#22659;&#30456;&#36830;&#12290;&#36890;&#36807;&#26426;&#22120;&#30340;&#28909;&#27969;&#36827;&#34892;&#35745;&#31639;&#12290;&#36807;&#31243;&#20174;&#26681;&#25454;&#36923;&#36753;&#36755;&#20837;&#35774;&#23450;&#29615;&#22659;&#28201;&#24230;&#24320;&#22987;&#12290;&#26426;&#22120;&#28436;&#21270;&#65292;&#26368;&#32456;&#36798;&#21040;&#38750;&#24179;&#34913;&#31283;&#24577;&#65292;&#36890;&#36807;&#36741;&#21161;&#26377;&#38480;&#23610;&#23544;&#20648;&#23384;&#27744;&#30340;&#28201;&#24230;&#21487;&#20197;&#30830;&#23450;&#35745;&#31639;&#32467;&#26524;&#12290;&#36825;&#26679;&#30340;&#26426;&#22120;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#28909;&#21147;&#23398;&#31070;&#32463;&#20803;&#8221;&#65292;&#21487;&#20197;&#23454;&#29616;&#20219;&#20309;&#32447;&#24615;&#21487;&#20998;&#31163;&#20989;&#25968;&#65292;&#25105;&#20204;&#26126;&#30830;&#35752;&#35770;&#20102;NOT&#65292;3-majority&#21644;NOR&#38376;&#30340;&#24773;&#20917;&#12290;&#21453;&#36807;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#28909;&#21147;&#23398;&#31070;&#32463;&#20803;&#32593;&#32476;&#21487;&#20197;&#25191;&#34892;&#20219;&#20309;&#38656;&#35201;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#19982;&#20154;&#24037;&#31070;&#32463;&#20803;&#65288;&#24863;&#30693;&#22120;&#65289;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#65292;&#24182;&#35748;&#20026;&#25105;&#20204;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a physics-based model for classical computation based on autonomous quantum thermal machines. These machines consist of few interacting quantum bits (qubits) connected to several environments at different temperatures. Heat flows through the machine are here exploited for computing. The process starts by setting the temperatures of the environments according to the logical input. The machine evolves, eventually reaching a non-equilibrium steady state, from which the output of the computation can be determined via the temperature of an auxilliary finite-size reservoir. Such a machine, which we term a "thermodynamic neuron", can implement any linearly-separable function, and we discuss explicitly the cases of NOT, 3-majority and NOR gates. In turn, we show that a network of thermodynamic neurons can perform any desired function. We discuss the close connection between our model and artificial neurons (perceptrons), and argue that our model provides an alternative physics-based
&lt;/p&gt;</description></item><item><title>HoSNN&#26159;&#19968;&#31181;&#23545;&#25239;&#24615;&#31283;&#24577;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#37319;&#29992;&#33258;&#36866;&#24212;&#21457;&#25918;&#38408;&#20540;&#30340;&#28183;&#28431;&#25972;&#21512;&#19982;&#21457;&#25918;&#65288;TA-LIF&#65289;&#31070;&#32463;&#20803;&#27169;&#22411;&#26469;&#25269;&#24481;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#22312;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#19979;&#20445;&#25252;&#20854;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.10373</link><description>&lt;p&gt;
HoSNN: &#20855;&#26377;&#33258;&#36866;&#24212;&#21457;&#25918;&#38408;&#20540;&#30340;&#23545;&#25239;&#24615;&#31283;&#24577;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds. (arXiv:2308.10373v2 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10373
&lt;/p&gt;
&lt;p&gt;
HoSNN&#26159;&#19968;&#31181;&#23545;&#25239;&#24615;&#31283;&#24577;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#37319;&#29992;&#33258;&#36866;&#24212;&#21457;&#25918;&#38408;&#20540;&#30340;&#28183;&#28431;&#25972;&#21512;&#19982;&#21457;&#25918;&#65288;TA-LIF&#65289;&#31070;&#32463;&#20803;&#27169;&#22411;&#26469;&#25269;&#24481;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#22312;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#19979;&#20445;&#25252;&#20854;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNNs&#65289;&#22312;&#39640;&#25928;&#21644;&#24378;&#22823;&#30340;&#31070;&#32463;&#21551;&#21457;&#24335;&#35745;&#31639;&#26041;&#38754;&#20855;&#26377;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#19982;&#20854;&#20182;&#31867;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#19968;&#26679;&#65292;SNNs&#38754;&#20020;&#30528;&#23545;&#25239;&#25915;&#20987;&#30340;&#20005;&#37325;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20174;&#31070;&#32463;&#24658;&#31283;&#24615;&#20013;&#27762;&#21462;&#28789;&#24863;&#30340;&#30740;&#31350;&#65292;&#20197;&#24320;&#21457;&#19968;&#31181;&#20223;&#29983;&#35299;&#20915;&#26041;&#26696;&#65292;&#26469;&#24212;&#23545;SNNs&#23545;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#21457;&#25918;&#38408;&#20540;&#30340;&#28183;&#28431;&#25972;&#21512;&#19982;&#21457;&#25918;&#65288;TA-LIF&#65289;&#31070;&#32463;&#20803;&#27169;&#22411;&#65292;&#25105;&#20204;&#37319;&#29992;&#23427;&#26469;&#26500;&#24314;&#25152;&#25552;&#20986;&#30340;&#23545;&#25239;&#24615;&#31283;&#24577;SNN&#65288;HoSNN&#65289;&#12290;&#19982;&#20256;&#32479;&#30340;LIF&#27169;&#22411;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;TA-LIF&#27169;&#22411;&#34701;&#20837;&#20102;&#33258;&#31283;&#23450;&#21160;&#24577;&#38408;&#20540;&#26426;&#21046;&#65292;&#38480;&#21046;&#23545;&#25239;&#24615;&#22122;&#22768;&#30340;&#20256;&#25773;&#65292;&#24182;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#20445;&#25252;HoSNN&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#20197;&#38416;&#26126;TA-LIF&#31070;&#32463;&#20803;&#30340;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#24615;&#65292;&#24378;&#35843;&#23427;&#20204;&#22312;&#36755;&#20837;&#22810;&#26679;&#24615;&#26041;&#38754;&#30340;&#21331;&#36234;&#21160;&#24577;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spiking neural networks (SNNs) offer promise for efficient and powerful neurally inspired computation. Common to other types of neural networks, however, SNNs face the severe issue of vulnerability to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to develop a bio-inspired solution that counters the susceptibilities of SNNs to adversarial onslaughts. At the heart of our approach is a novel threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model, which we adopt to construct the proposed adversarially robust homeostatic SNN (HoSNN). Distinct from traditional LIF models, our TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, curtailing adversarial noise propagation and safeguarding the robustness of HoSNNs in an unsupervised manner. Theoretical analysis is presented to shed light on the stability and convergence properties of the TA-LIF neurons, underscoring their superior dynamic robustness under input di
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#26041;&#27861;&#65288;MCF&#65289;&#65292;&#29992;&#20110;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#19979;&#30340;&#25968;&#25454;&#32858;&#31867;&#65292;&#20854;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;&#21487;&#27979;&#37327;&#20998;&#21306;&#24207;&#21015;&#30340;&#23618;&#27425;&#20851;&#31995;&#21644;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2305.04281</link><description>&lt;p&gt;
&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;
&lt;/p&gt;
&lt;p&gt;
Persistent Homology of the Multiscale Clustering Filtration. (arXiv:2305.04281v2 [math.AT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04281
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#26041;&#27861;&#65288;MCF&#65289;&#65292;&#29992;&#20110;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#19979;&#30340;&#25968;&#25454;&#32858;&#31867;&#65292;&#20854;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;&#21487;&#27979;&#37327;&#20998;&#21306;&#24207;&#21015;&#30340;&#23618;&#27425;&#20851;&#31995;&#21644;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#25968;&#25454;&#32858;&#31867;&#24212;&#29992;&#20013;&#65292;&#19981;&#20165;&#24076;&#26395;&#25214;&#21040;&#19968;&#31181;&#21333;&#19968;&#30340;&#20998;&#21306;&#26041;&#24335;&#65292;&#36824;&#24076;&#26395;&#25214;&#21040;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#25110;&#31895;&#31961;&#23618;&#27425;&#19979;&#30340;&#25968;&#25454;&#30340;&#19968;&#31995;&#21015;&#20998;&#21306;&#26041;&#24335;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#26159;&#20998;&#26512;&#21644;&#27604;&#36739;&#25903;&#25745;&#36825;&#31181;&#22810;&#23610;&#24230;&#25968;&#25454;&#25551;&#36848;&#30340;&#65288;&#19981;&#19968;&#23450;&#26159;&#23618;&#27425;&#24615;&#30340;&#65289;&#20998;&#21306;&#24207;&#21015;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#25277;&#35937;&#21333;&#32431;&#22797;&#24418;&#30340;&#36807;&#28388;&#65292;&#31216;&#20026;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#65288;MCF&#65289;&#65292;&#23427;&#32534;&#30721;&#20102;&#36328;&#23610;&#24230;&#30340;&#20219;&#24847;&#27169;&#24335;&#30340;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#35777;&#26126;&#20102;MCF&#20135;&#29983;&#31283;&#23450;&#30340;&#25345;&#20037;&#22270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MCF&#30340;&#38646;&#32500;&#25345;&#20037;&#21516;&#35843;&#27979;&#37327;&#20102;&#20998;&#21306;&#24207;&#21015;&#20013;&#30340;&#23618;&#27425;&#20851;&#31995;&#31243;&#24230;&#65292;&#32780;&#39640;&#32500;&#25345;&#20037;&#21516;&#35843;&#21017;&#36319;&#36394;&#20102;&#20998;&#21306;&#24207;&#21015;&#20013;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;&#20026;&#20102;&#25299;&#23485;MCF&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#31561;&#20215;&#30340;&#26500;&#36896;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many applications in data clustering, it is desirable to find not just a single partition into clusters but a sequence of partitions describing the data at different scales, or levels of coarseness. A natural problem then is to analyse and compare the (not necessarily hierarchical) sequences of partitions that underpin such multiscale descriptions of data. Here, we introduce a filtration of abstract simplicial complexes, denoted the Multiscale Clustering Filtration (MCF), which encodes arbitrary patterns of cluster assignments across scales, and we prove that the MCF produces stable persistence diagrams. We then show that the zero-dimensional persistent homology of the MCF measures the degree of hierarchy in the sequence of partitions, and that the higher-dimensional persistent homology tracks the emergence and resolution of conflicts between cluster assignments across the sequence of partitions. To broaden the theoretical foundations of the MCF, we also provide an equivalent constr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#19978;&#30340;&#21435;&#20013;&#24515;&#21270;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#21033;&#29992;&#25193;&#25955;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#23545;&#25239;&#24615;&#35757;&#32451;&#26694;&#26550;&#65292;&#22686;&#24378;&#20102;&#22810;&#20010;&#20195;&#29702;&#30340;&#40065;&#26834;&#24615;&#20197;&#23545;&#25239;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2303.13326</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#21435;&#20013;&#24515;&#21270;&#23545;&#25239;&#24615;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Decentralized Adversarial Training over Graphs. (arXiv:2303.13326v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#19978;&#30340;&#21435;&#20013;&#24515;&#21270;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#21033;&#29992;&#25193;&#25955;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#23545;&#25239;&#24615;&#35757;&#32451;&#26694;&#26550;&#65292;&#22686;&#24378;&#20102;&#22810;&#20010;&#20195;&#29702;&#30340;&#40065;&#26834;&#24615;&#20197;&#23545;&#25239;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#25915;&#20987;&#30340;&#28431;&#27934;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#29420;&#31435;&#21333;&#19968;&#20195;&#29702;&#23398;&#20064;&#32773;&#30340;&#34892;&#20026;&#19978;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#19978;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#20854;&#20013;&#21508;&#20010;&#21333;&#29420;&#30340;&#20195;&#29702;&#20250;&#21463;&#21040;&#31354;&#38388;&#20013;&#19981;&#21516;&#24378;&#24230;&#30340;&#25200;&#21160;&#12290;&#39044;&#26399;&#36890;&#36807;&#38142;&#25509;&#20195;&#29702;&#21644;&#21487;&#33021;&#22312;&#22270;&#19978;&#23454;&#29616;&#30340;&#25915;&#20987;&#27169;&#22411;&#30340;&#24322;&#36136;&#24615;&#65292;&#21327;&#35843;&#25972;&#20010;&#22242;&#38431;&#30340;&#24378;&#22823;&#21327;&#21516;&#20316;&#29992;&#21487;&#20197;&#24110;&#21161;&#22686;&#24378;&#40065;&#26834;&#24615;&#12290;&#26412;&#25991;&#20351;&#29992;&#25193;&#25955;&#23398;&#20064;&#30340;&#26497;&#23567;-&#26497;&#22823;&#20844;&#24335;&#65292;&#20026;&#22810;&#20195;&#29702;&#31995;&#32479;&#24320;&#21457;&#20102;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26694;&#26550;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#35813;&#26041;&#26696;&#22312;&#20984;&#21644;&#38750;&#20984;&#29615;&#22659;&#19979;&#30340;&#25910;&#25947;&#29305;&#24615;&#65292;&#24182;&#35828;&#26126;&#20102;&#22686;&#24378;&#30340;&#40065;&#26834;&#24615;&#23545;&#25239;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
The vulnerability of machine learning models to adversarial attacks has been attracting considerable attention in recent years. Most existing studies focus on the behavior of stand-alone single-agent learners. In comparison, this work studies adversarial training over graphs, where individual agents are subjected to perturbations of varied strength levels across space. It is expected that interactions by linked agents, and the heterogeneity of the attack models that are possible over the graph, can help enhance robustness in view of the coordination power of the group. Using a min-max formulation of diffusion learning, we develop a decentralized adversarial training framework for multi-agent systems. We analyze the convergence properties of the proposed scheme for both convex and non-convex environments, and illustrate the enhanced robustness to adversarial attacks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26597;&#35810;&#23884;&#20837;&#26041;&#27861;RoConE&#65292;&#23427;&#20801;&#35768;&#23398;&#20064;&#20851;&#31995;&#27169;&#24335;&#24182;&#25552;&#39640;&#20102;&#36923;&#36753;&#26597;&#35810;&#25512;&#29702;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.11858</link><description>&lt;p&gt;
&#23545;&#30693;&#35782;&#22270;&#35889;&#36827;&#34892;&#36923;&#36753;&#26597;&#35810;&#24212;&#31572;&#30340;&#20851;&#31995;&#27169;&#24335;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Modeling Relational Patterns for Logical Query Answering over Knowledge Graphs. (arXiv:2303.11858v1 [cs.DB])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26597;&#35810;&#23884;&#20837;&#26041;&#27861;RoConE&#65292;&#23427;&#20801;&#35768;&#23398;&#20064;&#20851;&#31995;&#27169;&#24335;&#24182;&#25552;&#39640;&#20102;&#36923;&#36753;&#26597;&#35810;&#25512;&#29702;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#36827;&#34892;&#19968;&#38454;&#36923;&#36753;&#65288;FOL&#65289;&#26597;&#35810;&#30340;&#22238;&#31572;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;KG&#19981;&#23436;&#25972;&#24615;&#32780;&#23548;&#33268;&#30340;&#12290;&#26597;&#35810;&#23884;&#20837;&#26041;&#27861;&#36890;&#36807;&#35745;&#31639;&#23454;&#20307;&#12289;&#20851;&#31995;&#21644;&#36923;&#36753;&#26597;&#35810;&#30340;&#20302;&#32500;&#24230;&#21521;&#37327;&#34920;&#31034;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;KG&#34920;&#29616;&#20986;&#23545;&#31216;&#24615;&#21644;&#32452;&#21512;&#24615;&#31561;&#20851;&#31995;&#27169;&#24335;&#65292;&#24314;&#27169;&#36825;&#20123;&#27169;&#24335;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26597;&#35810;&#23884;&#20837;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#24335;&#22312;&#26597;&#35810;&#23884;&#20837;&#27169;&#22411;&#20013;&#30340;&#20316;&#29992;&#23578;&#26410;&#22312;&#25991;&#29486;&#20013;&#36827;&#34892;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#20801;&#35768;&#23398;&#20064;&#20851;&#31995;&#27169;&#24335;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#21152;&#24378;FOL&#26597;&#35810;&#25512;&#29702;&#30340;&#27169;&#24335;&#25512;&#29702;&#33021;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26597;&#35810;&#23884;&#20837;&#26041;&#27861;RoConE&#65292;&#23427;&#23558;&#26597;&#35810;&#21306;&#22495;&#23450;&#20041;&#20026;&#20960;&#20309;&#38181;&#20307;&#65292;&#24182;&#36890;&#36807;&#22312;&#22797;&#26434;&#31354;&#38388;&#20013;&#26059;&#36716;&#20195;&#25968;&#26597;&#35810;&#31639;&#23376;&#12290;RoConE&#32467;&#21512;&#20102;&#20960;&#20309;&#38181;&#20307;&#20316;&#20026;&#21487;&#20197;&#26126;&#30830;&#23450;&#20041;&#26597;&#35810;&#34920;&#31034;&#30340;&#20960;&#20309;&#34920;&#31034;&#21644;&#26059;&#36716;&#20195;&#25968;&#26597;&#35810;&#31639;&#23376;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Answering first-order logical (FOL) queries over knowledge graphs (KG) remains a challenging task mainly due to KG incompleteness. Query embedding approaches this problem by computing the low-dimensional vector representations of entities, relations, and logical queries. KGs exhibit relational patterns such as symmetry and composition and modeling the patterns can further enhance the performance of query embedding models. However, the role of such patterns in answering FOL queries by query embedding models has not been yet studied in the literature. In this paper, we fill in this research gap and empower FOL queries reasoning with pattern inference by introducing an inductive bias that allows for learning relation patterns. To this end, we develop a novel query embedding method, RoConE, that defines query regions as geometric cones and algebraic query operators by rotations in complex space. RoConE combines the advantages of Cone as a well-specified geometric representation for query e
&lt;/p&gt;</description></item><item><title>MIXRTs&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26550;&#26500;&#65292;&#36890;&#36807;&#28151;&#21512;&#24490;&#29615;&#36719;&#20915;&#31574;&#26641;&#30340;&#26041;&#24335;&#65292;&#33021;&#22815;&#34920;&#36798;&#26126;&#30830;&#30340;&#20915;&#31574;&#36807;&#31243;&#24182;&#23637;&#31034;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2209.07225</link><description>&lt;p&gt;
MIXRTs:&#36890;&#36807;&#28151;&#21512;&#24490;&#29615;&#36719;&#20915;&#31574;&#26641;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees. (arXiv:2209.07225v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07225
&lt;/p&gt;
&lt;p&gt;
MIXRTs&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26550;&#26500;&#65292;&#36890;&#36807;&#28151;&#21512;&#24490;&#29615;&#36719;&#20915;&#31574;&#26641;&#30340;&#26041;&#24335;&#65292;&#33021;&#22815;&#34920;&#36798;&#26126;&#30830;&#30340;&#20915;&#31574;&#36807;&#31243;&#24182;&#23637;&#31034;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#24040;&#22823;&#25104;&#21151;&#30340;&#21516;&#26102;&#65292;&#29616;&#26377;&#30340;&#20855;&#26377;&#40657;&#30418;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#20197;&#19981;&#36879;&#26126;&#30340;&#26041;&#24335;&#20570;&#20986;&#20915;&#31574;&#65292;&#38459;&#30861;&#20102;&#20154;&#20204;&#29702;&#35299;&#23398;&#20064;&#21040;&#30340;&#30693;&#35782;&#20197;&#21450;&#36755;&#20837;&#35266;&#27979;&#22914;&#20309;&#24433;&#21709;&#20915;&#31574;&#12290;&#19982;&#27492;&#30456;&#21453;&#65292;&#29616;&#26377;&#30340;&#21487;&#35299;&#37322;&#26041;&#27861;&#65292;&#22914;&#20256;&#32479;&#30340;&#32447;&#24615;&#27169;&#22411;&#21644;&#20915;&#31574;&#26641;&#65292;&#24448;&#24448;&#22312;&#34920;&#36798;&#33021;&#21147;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#24615;&#33021;&#21644;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#26126;&#26174;&#20108;&#20803;&#23545;&#31435;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#32467;&#26500;&#8212;&#8212;&#28151;&#21512;&#24490;&#29615;&#36719;&#20915;&#31574;&#26641;&#65288;MIXRTs&#65289;&#65292;&#23427;&#33021;&#22815;&#36890;&#36807;&#20174;&#26681;&#33410;&#28857;&#21040;&#21494;&#33410;&#28857;&#30340;&#36335;&#24452;&#34920;&#31034;&#26126;&#30830;&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#21453;&#26144;&#27599;&#20010;&#26234;&#33021;&#20307;&#23545;&#22242;&#38431;&#30340;&#36129;&#29486;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36719;&#20915;&#31574;&#26641;&#26469;&#35299;&#20915;&#23616;&#37096;&#21487;&#35266;&#23519;&#24615;&#38382;&#39064;&#65292;&#21033;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#36827;&#23637;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#23637;&#31034;&#21738;&#20123;&#29305;&#24449;&#24433;&#21709;&#20915;&#31574;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
While achieving tremendous success in various fields, existing multi-agent reinforcement learning (MARL) with a black-box neural network architecture makes decisions in an opaque manner that hinders humans from understanding the learned knowledge and how input observations influence decisions. Instead, existing interpretable approaches, such as traditional linear models and decision trees, usually suffer from weak expressivity and low accuracy. To address this apparent dichotomy between performance and interpretability, our solution, MIXing Recurrent soft decision Trees (MIXRTs), is a novel interpretable architecture that can represent explicit decision processes via the root-to-leaf path and reflect each agent's contribution to the team. Specifically, we construct a novel soft decision tree to address partial observability by leveraging the advances in recurrent neural networks, and demonstrate which features influence the decision-making process through the tree-based model. Then, ba
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;24&#31181;&#19981;&#21516;&#37327;&#21270;&#26041;&#27861;&#22312;&#36229;&#36807;40&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20840;&#38754;&#23454;&#35777;&#27604;&#36739;&#65292;&#22635;&#34917;&#20102;&#37327;&#21270;&#26041;&#27861;&#27604;&#36739;&#30740;&#31350;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#20108;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;&#22522;&#20110;&#38408;&#20540;&#36873;&#25321;&#30340;Median Sweep&#21644;TSMax&#26041;&#27861;&#12289;DyS&#26694;&#26550;&#21644;&#24343;&#37324;&#24503;&#26364;&#30340;&#26041;&#27861;&#34920;&#29616;&#26368;&#20339;&#65307;&#32780;&#22312;&#22810;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;Generaliz&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2103.03223</link><description>&lt;p&gt;
&#37327;&#21270;&#26041;&#27861;&#30340;&#27604;&#36739;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A Comparative Evaluation of Quantification Methods. (arXiv:2103.03223v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.03223
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;24&#31181;&#19981;&#21516;&#37327;&#21270;&#26041;&#27861;&#22312;&#36229;&#36807;40&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20840;&#38754;&#23454;&#35777;&#27604;&#36739;&#65292;&#22635;&#34917;&#20102;&#37327;&#21270;&#26041;&#27861;&#27604;&#36739;&#30740;&#31350;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#20108;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;&#22522;&#20110;&#38408;&#20540;&#36873;&#25321;&#30340;Median Sweep&#21644;TSMax&#26041;&#27861;&#12289;DyS&#26694;&#26550;&#21644;&#24343;&#37324;&#24503;&#26364;&#30340;&#26041;&#27861;&#34920;&#29616;&#26368;&#20339;&#65307;&#32780;&#22312;&#22810;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;Generaliz&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#26159;&#25351;&#22312;&#25968;&#25454;&#38598;&#20013;&#39044;&#27979;&#31867;&#21035;&#20998;&#24067;&#30340;&#38382;&#39064;&#12290;&#23427;&#20063;&#20195;&#34920;&#30528;&#19968;&#20010;&#22312;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#26029;&#21457;&#23637;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#36817;&#24180;&#26469;&#25552;&#20986;&#20102;&#22823;&#37327;&#19981;&#21516;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#19968;&#20221;&#20840;&#38754;&#30340;&#23454;&#35777;&#27604;&#36739;&#37327;&#21270;&#26041;&#27861;&#30340;&#30740;&#31350;&#65292;&#20197;&#25903;&#25345;&#31639;&#27861;&#36873;&#25321;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#36229;&#36807;40&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;24&#31181;&#19981;&#21516;&#37327;&#21270;&#26041;&#27861;&#30340;&#24443;&#24213;&#23454;&#35777;&#24615;&#24615;&#33021;&#27604;&#36739;&#65292;&#21253;&#25324;&#20108;&#20998;&#31867;&#21644;&#22810;&#20998;&#31867;&#37327;&#21270;&#35774;&#32622;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#27809;&#26377;&#21333;&#19968;&#31639;&#27861;&#33021;&#22815;&#22312;&#25152;&#26377;&#31454;&#20105;&#23545;&#25163;&#20013;&#22987;&#32456;&#34920;&#29616;&#26368;&#20339;&#65292;&#20294;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#32452;&#22312;&#20108;&#20998;&#31867;&#35774;&#32622;&#20013;&#34920;&#29616;&#26368;&#20339;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#38408;&#20540;&#36873;&#25321;&#30340;Median Sweep&#21644;TSMax&#26041;&#27861;&#12289;DyS&#26694;&#26550;&#21644;&#24343;&#37324;&#24503;&#26364;&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#22810;&#20998;&#31867;&#35774;&#32622;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#21478;&#19968;&#32452;&#31639;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#21253;&#25324;Generaliz&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantification represents the problem of predicting class distributions in a dataset. It also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. However, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. In this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on overall more than 40 data sets, considering binary as well as multiclass quantification settings. We observe that no single algorithm generally outperforms all competitors, but identify a group of methods including the threshold selection-based Median Sweep and TSMax methods, the DyS framework, and Friedman's method that performs best in the binary setting. For the multiclass setting, we observe that a different group of algorithms yields good performance, including the Generaliz
&lt;/p&gt;</description></item></channel></rss>