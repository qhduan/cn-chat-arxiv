<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>Effector&#26159;&#19968;&#20010;&#19987;&#27880;&#20110;&#21306;&#22495;&#29305;&#24449;&#25928;&#26524;&#30340;Python&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#24341;&#20837;&#21306;&#22495;&#25928;&#26524;&#26469;&#38477;&#20302;&#20840;&#23616;&#29305;&#24449;&#25928;&#26524;&#26041;&#27861;&#20013;&#21487;&#33021;&#30340;&#24322;&#36136;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.02629</link><description>&lt;p&gt;
Effector: &#19968;&#20010;&#29992;&#20110;&#21306;&#22495;&#35299;&#37322;&#30340;Python&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
Effector: A Python package for regional explanations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02629
&lt;/p&gt;
&lt;p&gt;
Effector&#26159;&#19968;&#20010;&#19987;&#27880;&#20110;&#21306;&#22495;&#29305;&#24449;&#25928;&#26524;&#30340;Python&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#24341;&#20837;&#21306;&#22495;&#25928;&#26524;&#26469;&#38477;&#20302;&#20840;&#23616;&#29305;&#24449;&#25928;&#26524;&#26041;&#27861;&#20013;&#21487;&#33021;&#30340;&#24322;&#36136;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#23616;&#29305;&#24449;&#25928;&#26524;&#26041;&#27861;&#35299;&#37322;&#19968;&#20010;&#36755;&#20986;&#27169;&#22411;&#65292;&#27599;&#20010;&#29305;&#24449;&#23545;&#24212;&#19968;&#20010;&#22270;&#12290;&#35813;&#22270;&#26174;&#31034;&#29305;&#24449;&#23545;&#36755;&#20986;&#30340;&#24179;&#22343;&#25928;&#26524;&#65292;&#20363;&#22914;&#24180;&#40836;&#23545;&#24180;&#25910;&#20837;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#24403;&#30001;&#24322;&#36136;&#23616;&#37096;&#25928;&#26524;&#25512;&#23548;&#20986;&#24179;&#22343;&#25928;&#26524;&#26102;&#65292;&#24179;&#22343;&#25928;&#26524;&#21487;&#33021;&#20855;&#26377;&#35823;&#23548;&#24615;&#65292;&#21363;&#26126;&#26174;&#20559;&#31163;&#24179;&#22343;&#20540;&#12290;&#20026;&#20102;&#20943;&#23569;&#24322;&#36136;&#24615;&#65292;&#21306;&#22495;&#25928;&#26524;&#20026;&#27599;&#20010;&#29305;&#24449;&#25552;&#20379;&#22810;&#20010;&#22270;&#65292;&#27599;&#20010;&#22270;&#20195;&#34920;&#29305;&#23450;&#23376;&#31354;&#38388;&#20869;&#30340;&#24179;&#22343;&#25928;&#26524;&#12290;&#20026;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#23376;&#31354;&#38388;&#34987;&#23450;&#20041;&#20026;&#30001;&#36923;&#36753;&#35268;&#21017;&#38142;&#23450;&#20041;&#30340;&#36229;&#30697;&#24418;&#65292;&#20363;&#22914;&#24180;&#40836;&#23545;&#30007;&#24615;&#21644;&#22899;&#24615;&#30340;&#24180;&#25910;&#20837;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#19981;&#21516;&#19987;&#19994;&#32463;&#39564;&#27700;&#24179;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;Effector&#65292;&#19968;&#20010;&#33268;&#21147;&#20110;&#21306;&#22495;&#29305;&#24449;&#25928;&#26524;&#30340;Python&#24211;&#12290;Effector&#23454;&#29616;&#20102;&#19968;&#20123;&#25104;&#29087;&#30340;&#20840;&#23616;&#25928;&#26524;&#26041;&#27861;&#65292;&#35780;&#20272;&#27599;&#31181;&#26041;&#27861;&#30340;&#24322;&#36136;&#24615;&#65292;&#24182;&#22522;&#20110;&#27492;&#25552;&#20379;&#21306;&#22495;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02629v1 Announce Type: new  Abstract: Global feature effect methods explain a model outputting one plot per feature. The plot shows the average effect of the feature on the output, like the effect of age on the annual income. However, average effects may be misleading when derived from local effects that are heterogeneous, i.e., they significantly deviate from the average. To decrease the heterogeneity, regional effects provide multiple plots per feature, each representing the average effect within a specific subspace. For interpretability, subspaces are defined as hyperrectangles defined by a chain of logical rules, like age's effect on annual income separately for males and females and different levels of professional experience. We introduce Effector, a Python library dedicated to regional feature effects. Effector implements well-established global effect methods, assesses the heterogeneity of each method and, based on that, provides regional effects. Effector automatica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#31070;&#32463;&#31215;&#20998;&#26041;&#31243;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#35889;&#22495;&#20013;&#23398;&#20064;&#31639;&#23376;&#65292;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#20445;&#35777;&#20102;&#39640;&#25554;&#20540;&#31934;&#24230;&#12290;</title><link>https://arxiv.org/abs/2312.05654</link><description>&lt;p&gt;
&#31070;&#32463;&#31215;&#20998;&#26041;&#31243;&#30340;&#35889;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Spectral methods for Neural Integral Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.05654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#31070;&#32463;&#31215;&#20998;&#26041;&#31243;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#35889;&#22495;&#20013;&#23398;&#20064;&#31639;&#23376;&#65292;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#20445;&#35777;&#20102;&#39640;&#25554;&#20540;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2312.05654v3 &#20844;&#21578;&#31867;&#22411;&#65306;&#26367;&#25442;-&#36328;&#20132;&#25688;&#35201;&#65306;&#31070;&#32463;&#31215;&#20998;&#26041;&#31243;&#26159;&#22522;&#20110;&#31215;&#20998;&#26041;&#31243;&#29702;&#35770;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#20854;&#20013;&#27169;&#22411;&#30001;&#31215;&#20998;&#31639;&#23376;&#21644;&#36890;&#36807;&#20248;&#21270;&#36807;&#31243;&#23398;&#20064;&#30340;&#30456;&#24212;&#26041;&#31243;&#65288;&#31532;&#20108;&#31181;&#65289;&#32452;&#25104;&#12290;&#36825;&#31181;&#26041;&#27861;&#20801;&#35768;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#20013;&#31215;&#20998;&#31639;&#23376;&#30340;&#38750;&#23616;&#37096;&#29305;&#24615;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#31070;&#32463;&#31215;&#20998;&#26041;&#31243;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#35889;&#22495;&#20013;&#23398;&#20064;&#19968;&#20010;&#31639;&#23376;&#65292;&#20174;&#32780;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#65292;&#21516;&#26102;&#20445;&#35777;&#39640;&#25554;&#20540;&#31934;&#24230;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102;&#20851;&#20110;&#27169;&#22411;&#36817;&#20284;&#33021;&#21147;&#21644;&#25910;&#25947;&#21040;&#25968;&#20540;&#26041;&#27861;&#35299;&#30340;&#21508;&#31181;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#39564;&#26469;&#23637;&#31034;&#25152;&#24471;&#27169;&#22411;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.05654v3 Announce Type: replace-cross  Abstract: Neural integral equations are deep learning models based on the theory of integral equations, where the model consists of an integral operator and the corresponding equation (of the second kind) which is learned through an optimization procedure. This approach allows to leverage the nonlocal properties of integral operators in machine learning, but it is computationally expensive. In this article, we introduce a framework for neural integral equations based on spectral methods that allows us to learn an operator in the spectral domain, resulting in a cheaper computational cost, as well as in high interpolation accuracy. We study the properties of our methods and show various theoretical guarantees regarding the approximation capabilities of the model, and convergence to solutions of the numerical methods. We provide numerical experiments to demonstrate the practical effectiveness of the resulting model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23454;&#29616;&#21644;&#35780;&#20272;&#20102;18&#20010;&#20195;&#34920;&#24615;&#30340;&#36807;&#21435;&#30740;&#31350;&#65292;&#24182;&#22312;&#21253;&#21547;124,000&#20010;&#24212;&#29992;&#31243;&#24207;&#30340;&#24179;&#34913;&#12289;&#30456;&#20851;&#21644;&#26368;&#26032;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#26032;&#23454;&#39564;&#65292;&#21457;&#29616;&#20165;&#36890;&#36807;&#38745;&#24577;&#20998;&#26512;&#25552;&#21462;&#30340;&#29305;&#24449;&#23601;&#33021;&#23454;&#29616;&#39640;&#36798;96.8%&#30340;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2301.12778</link><description>&lt;p&gt;
&#25506;&#31350;&#23433;&#21331;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#20013;&#30340;&#29305;&#24449;&#21644;&#27169;&#22411;&#37325;&#35201;&#24615;&#65306;&#19968;&#39033;&#23454;&#26045;&#35843;&#26597;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#39564;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Investigating Feature and Model Importance in Android Malware Detection: An Implemented Survey and Experimental Comparison of ML-Based Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.12778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23454;&#29616;&#21644;&#35780;&#20272;&#20102;18&#20010;&#20195;&#34920;&#24615;&#30340;&#36807;&#21435;&#30740;&#31350;&#65292;&#24182;&#22312;&#21253;&#21547;124,000&#20010;&#24212;&#29992;&#31243;&#24207;&#30340;&#24179;&#34913;&#12289;&#30456;&#20851;&#21644;&#26368;&#26032;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#26032;&#23454;&#39564;&#65292;&#21457;&#29616;&#20165;&#36890;&#36807;&#38745;&#24577;&#20998;&#26512;&#25552;&#21462;&#30340;&#29305;&#24449;&#23601;&#33021;&#23454;&#29616;&#39640;&#36798;96.8%&#30340;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Android&#30340;&#26222;&#21450;&#24847;&#21619;&#30528;&#23427;&#25104;&#20026;&#24694;&#24847;&#36719;&#20214;&#30340;&#24120;&#35265;&#30446;&#26631;&#12290;&#22810;&#24180;&#26469;&#65292;&#21508;&#31181;&#30740;&#31350;&#21457;&#29616;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#21306;&#20998;&#24694;&#24847;&#36719;&#20214;&#21644;&#33391;&#24615;&#24212;&#29992;&#31243;&#24207;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#25805;&#20316;&#31995;&#32479;&#30340;&#28436;&#36827;&#65292;&#24694;&#24847;&#36719;&#20214;&#20063;&#22312;&#19981;&#26029;&#21457;&#23637;&#65292;&#23545;&#20808;&#21069;&#30740;&#31350;&#30340;&#21457;&#29616;&#25552;&#20986;&#20102;&#36136;&#30097;&#65292;&#20854;&#20013;&#35768;&#22810;&#25253;&#21578;&#31216;&#20351;&#29992;&#23567;&#22411;&#12289;&#36807;&#26102;&#19988;&#32463;&#24120;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#33021;&#22815;&#33719;&#24471;&#38750;&#24120;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23454;&#29616;&#20102;18&#39033;&#20855;&#20195;&#34920;&#24615;&#30340;&#36807;&#21435;&#30740;&#31350;&#24182;&#20351;&#29992;&#21253;&#25324;124,000&#20010;&#24212;&#29992;&#31243;&#24207;&#30340;&#24179;&#34913;&#12289;&#30456;&#20851;&#19988;&#26368;&#26032;&#30340;&#25968;&#25454;&#38598;&#23545;&#23427;&#20204;&#36827;&#34892;&#37325;&#26032;&#35780;&#20272;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#26032;&#30340;&#23454;&#39564;&#65292;&#20197;&#22635;&#34917;&#29616;&#26377;&#30693;&#35782;&#20013;&#30340;&#31354;&#30333;&#65292;&#24182;&#21033;&#29992;&#30740;&#31350;&#32467;&#26524;&#30830;&#23450;&#22312;&#24403;&#20195;&#29615;&#22659;&#20013;&#29992;&#20110;&#23433;&#21331;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#30340;&#26368;&#26377;&#25928;&#29305;&#24449;&#21644;&#27169;&#22411;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20165;&#36890;&#36807;&#38745;&#24577;&#20998;&#26512;&#25552;&#21462;&#30340;&#29305;&#24449;&#21363;&#21487;&#23454;&#29616;&#39640;&#36798;96.8%&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.12778v2 Announce Type: replace  Abstract: The popularity of Android means it is a common target for malware. Over the years, various studies have found that machine learning models can effectively discriminate malware from benign applications. However, as the operating system evolves, so does malware, bringing into question the findings of these previous studies, many of which report very high accuracies using small, outdated, and often imbalanced datasets. In this paper, we reimplement 18 representative past works and reevaluate them using a balanced, relevant, and up-to-date dataset comprising 124,000 applications. We also carry out new experiments designed to fill holes in existing knowledge, and use our findings to identify the most effective features and models to use for Android malware detection within a contemporary environment. We show that high detection accuracies (up to 96.8%) can be achieved using features extracted through static analysis alone, yielding a mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#21487;&#20197;&#22312;&#36845;&#20195;&#22797;&#26434;&#24615;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2401.10989</link><description>&lt;p&gt;
&#20855;&#26377;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#30340;&#21487;&#35777;&#20280;&#32553;&#24615;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Provably Scalable Black-Box Variational Inference with Structured Variational Families. (arXiv:2401.10989v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#21487;&#20197;&#22312;&#36845;&#20195;&#22797;&#26434;&#24615;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#30693;&#20855;&#26377;&#28385;&#31209;&#21327;&#26041;&#24046;&#36924;&#36817;&#30340;&#21464;&#20998;&#26063;&#22312;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#20013;&#34920;&#29616;&#19981;&#20339;&#65292;&#26080;&#35770;&#26159;&#20174;&#23454;&#35777;&#19978;&#36824;&#26159;&#29702;&#35770;&#19978;&#12290;&#20107;&#23454;&#19978;&#65292;&#26368;&#36817;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#30456;&#27604;&#65292;&#28385;&#31209;&#21464;&#20998;&#26063;&#22312;&#38382;&#39064;&#30340;&#32500;&#24230;&#19978;&#25193;&#23637;&#24471;&#24456;&#24046;&#12290;&#36825;&#23545;&#20855;&#26377;&#26412;&#22320;&#21464;&#37327;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#23588;&#20026;&#20851;&#38190;&#65292;&#23427;&#20204;&#30340;&#32500;&#24230;&#38543;&#30528;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#32780;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#36845;&#20195;&#22797;&#26434;&#24615;&#23545;&#25968;&#25454;&#38598;&#22823;&#23567;N&#23384;&#22312;&#26126;&#30830;&#30340;O(N^2)&#20381;&#36182;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#12290;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126;&#20102;&#26576;&#20123;&#23610;&#24230;&#30697;&#38453;&#32467;&#26500;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#36845;&#20195;&#22797;&#26434;&#24615;O(N)&#65292;&#20174;&#32780;&#19982;N&#30340;&#32553;&#25918;&#26356;&#22909;&#22320;&#21305;&#37197;&#12290;&#25105;&#20204;&#22312;&#29616;&#23454;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Variational families with full-rank covariance approximations are known not to work well in black-box variational inference (BBVI), both empirically and theoretically. In fact, recent computational complexity results for BBVI have established that full-rank variational families scale poorly with the dimensionality of the problem compared to e.g. mean field families. This is particularly critical to hierarchical Bayesian models with local variables; their dimensionality increases with the size of the datasets. Consequently, one gets an iteration complexity with an explicit $\mathcal{O}(N^2)$ dependence on the dataset size $N$. In this paper, we explore a theoretical middle ground between mean-field variational families and full-rank families: structured variational families. We rigorously prove that certain scale matrix structures can achieve a better iteration complexity of $\mathcal{O}(N)$, implying better scaling with respect to $N$. We empirically verify our theoretical results on l
&lt;/p&gt;</description></item></channel></rss>