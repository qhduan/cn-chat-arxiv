<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>Synapse&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#20174;&#26377;&#38480;&#28436;&#31034;&#20013;&#39640;&#25928;&#23398;&#20064;&#20559;&#22909;&#27010;&#24565;&#65292;&#36890;&#36807;&#23558;&#20559;&#22909;&#34920;&#31034;&#20026;&#31070;&#32463;&#31526;&#21495;&#31243;&#24207;&#24182;&#21033;&#29992;&#35270;&#35273;&#35299;&#26512;&#12289;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#31243;&#24207;&#21512;&#25104;&#30456;&#32467;&#21512;&#30340;&#26041;&#24335;&#26469;&#23398;&#20064;&#20010;&#20154;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2403.16689</link><description>&lt;p&gt;
Synapse: &#20174;&#35270;&#35273;&#28436;&#31034;&#20013;&#23398;&#20064;&#20248;&#20808;&#27010;&#24565;
&lt;/p&gt;
&lt;p&gt;
Synapse: Learning Preferential Concepts from Visual Demonstrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16689
&lt;/p&gt;
&lt;p&gt;
Synapse&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#20174;&#26377;&#38480;&#28436;&#31034;&#20013;&#39640;&#25928;&#23398;&#20064;&#20559;&#22909;&#27010;&#24565;&#65292;&#36890;&#36807;&#23558;&#20559;&#22909;&#34920;&#31034;&#20026;&#31070;&#32463;&#31526;&#21495;&#31243;&#24207;&#24182;&#21033;&#29992;&#35270;&#35273;&#35299;&#26512;&#12289;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#31243;&#24207;&#21512;&#25104;&#30456;&#32467;&#21512;&#30340;&#26041;&#24335;&#26469;&#23398;&#20064;&#20010;&#20154;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20559;&#22909;&#23398;&#20064;&#38382;&#39064;&#65292;&#26088;&#22312;&#20174;&#35270;&#35273;&#36755;&#20837;&#20013;&#23398;&#20064;&#29992;&#25143;&#29305;&#23450;&#20559;&#22909;&#65288;&#20363;&#22914;&#65292;&#8220;&#22909;&#20572;&#36710;&#20301;&#8221;&#65292;&#8220;&#26041;&#20415;&#30340;&#19979;&#36710;&#20301;&#32622;&#8221;&#65289;&#12290;&#23613;&#31649;&#19982;&#23398;&#20064;&#20107;&#23454;&#27010;&#24565;&#65288;&#20363;&#22914;&#65292;&#8220;&#32418;&#33394;&#31435;&#26041;&#20307;&#8221;&#65289;&#30456;&#20284;&#65292;&#20294;&#20559;&#22909;&#23398;&#20064;&#26159;&#19968;&#20010;&#22522;&#26412;&#26356;&#21152;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#28041;&#21450;&#20027;&#35266;&#24615;&#36136;&#21644;&#20010;&#20154;&#29305;&#23450;&#35757;&#32451;&#25968;&#25454;&#30340;&#32570;&#20047;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#21517;&#20026;Synapse&#30340;&#26032;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#26159;&#19968;&#31181;&#31070;&#32463;&#31526;&#21495;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#26377;&#25928;&#22320;&#20174;&#26377;&#38480;&#28436;&#31034;&#20013;&#23398;&#20064;&#20559;&#22909;&#27010;&#24565;&#12290;Synapse&#23558;&#20559;&#22909;&#34920;&#31034;&#20026;&#22312;&#22270;&#20687;&#19978;&#36816;&#20316;&#30340;&#39046;&#22495;&#29305;&#23450;&#35821;&#35328;&#65288;DSL&#65289;&#20013;&#30340;&#31070;&#32463;&#31526;&#21495;&#31243;&#24207;&#65292;&#24182;&#21033;&#29992;&#35270;&#35273;&#35299;&#26512;&#12289;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#31243;&#24207;&#21512;&#25104;&#30340;&#26032;&#32452;&#21512;&#26469;&#23398;&#20064;&#20195;&#34920;&#20010;&#20154;&#20559;&#22909;&#30340;&#31243;&#24207;&#12290;&#25105;&#20204;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#35780;&#20272;&#20102;Synapse&#65292;&#21253;&#25324;&#19968;&#20010;&#20851;&#27880;&#19982;&#31227;&#21160;&#30456;&#20851;&#30340;&#29992;&#25143;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16689v1 Announce Type: cross  Abstract: This paper addresses the problem of preference learning, which aims to learn user-specific preferences (e.g., "good parking spot", "convenient drop-off location") from visual input. Despite its similarity to learning factual concepts (e.g., "red cube"), preference learning is a fundamentally harder problem due to its subjective nature and the paucity of person-specific training data. We address this problem using a new framework called Synapse, which is a neuro-symbolic approach designed to efficiently learn preferential concepts from limited demonstrations. Synapse represents preferences as neuro-symbolic programs in a domain-specific language (DSL) that operates over images, and leverages a novel combination of visual parsing, large language models, and program synthesis to learn programs representing individual preferences. We evaluate Synapse through extensive experimentation including a user case study focusing on mobility-related
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#25439;&#22833;&#35282;&#24230;&#37325;&#26032;&#23450;&#20041;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#29616;&#33021;&#21147;&#65292;&#21457;&#29616;&#20855;&#26377;&#30456;&#21516;&#39044;&#35757;&#32451;&#25439;&#22833;&#30340;&#27169;&#22411;&#22312;&#19981;&#21516;&#20219;&#21153;&#19978;&#34920;&#29616;&#30456;&#20284;&#65292;&#32780;&#24403;&#39044;&#35757;&#32451;&#25439;&#22833;&#20302;&#20110;&#29305;&#23450;&#38408;&#20540;&#26102;&#65292;&#27169;&#22411;&#23558;&#23637;&#29616;&#20986;&#31361;&#29616;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.15796</link><description>&lt;p&gt;
&#20174;&#25439;&#22833;&#35282;&#24230;&#29702;&#35299;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#29616;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Understanding Emergent Abilities of Language Models from the Loss Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15796
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#25439;&#22833;&#35282;&#24230;&#37325;&#26032;&#23450;&#20041;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#29616;&#33021;&#21147;&#65292;&#21457;&#29616;&#20855;&#26377;&#30456;&#21516;&#39044;&#35757;&#32451;&#25439;&#22833;&#30340;&#27169;&#22411;&#22312;&#19981;&#21516;&#20219;&#21153;&#19978;&#34920;&#29616;&#30456;&#20284;&#65292;&#32780;&#24403;&#39044;&#35757;&#32451;&#25439;&#22833;&#20302;&#20110;&#29305;&#23450;&#38408;&#20540;&#26102;&#65292;&#27169;&#22411;&#23558;&#23637;&#29616;&#20986;&#31361;&#29616;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30740;&#31350;&#36136;&#30097;&#20102;&#20256;&#32479;&#35748;&#20026;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#29616;&#33021;&#21147;&#20165;&#23384;&#22312;&#20110;&#22823;&#27169;&#22411;&#20013;&#30340;&#35266;&#28857;&#12290;&#36825;&#31181;&#24576;&#30097;&#28304;&#33258;&#20004;&#28857;&#35266;&#23519;&#65306;1&#65289;&#36739;&#23567;&#30340;&#27169;&#22411;&#20063;&#33021;&#23637;&#29616;&#20986;&#23545;&#31361;&#29616;&#33021;&#21147;&#30340;&#39640;&#24615;&#33021;&#65307;2&#65289;&#36136;&#30097;&#29992;&#20110;&#27979;&#37327;&#36825;&#20123;&#33021;&#21147;&#30340;&#19981;&#36830;&#32493;&#24615;&#25351;&#26631;&#12290;&#26412;&#25991;&#25552;&#35758;&#20174;&#39044;&#35757;&#32451;&#25439;&#22833;&#30340;&#35282;&#24230;&#30740;&#31350;&#31361;&#29616;&#33021;&#21147;&#65292;&#32780;&#38750;&#27169;&#22411;&#22823;&#23567;&#25110;&#35757;&#32451;&#35745;&#31639;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20855;&#26377;&#30456;&#21516;&#39044;&#35757;&#32451;&#25439;&#22833;&#20294;&#19981;&#21516;&#27169;&#22411;&#21644;&#25968;&#25454;&#22823;&#23567;&#30340;&#27169;&#22411;&#65292;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#19978;&#34920;&#29616;&#30456;&#21516;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#24403;&#26576;&#19968;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#25439;&#22833;&#20302;&#20110;&#29305;&#23450;&#38408;&#20540;&#26102;&#65292;&#22312;&#26576;&#20123;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#31361;&#29616;&#33021;&#21147;&#65292;&#32780;&#19981;&#35770;&#25351;&#26631;&#30340;&#36830;&#32493;&#24615;&#22914;&#20309;&#65307;&#32780;&#22312;&#36798;&#21040;&#35813;&#38408;&#20540;&#20043;&#21069;&#65292;&#20854;&#24615;&#33021;&#20173;&#20445;&#25345;&#22312;&#38543;&#26426;&#29468;&#27979;&#27700;&#24179;&#12290;&#36825;&#21551;&#21457;&#25105;&#20204;&#37325;&#26032;&#23450;&#20041;&#31361;&#29616;&#33021;&#21147;&#20026;&#37027;&#20123;......
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15796v1 Announce Type: cross  Abstract: Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) there is doubt on the discontinuous metrics used to measure these abilities. In this paper, we propose to study emergent abilities in the lens of pre-training loss, instead of model size or training compute. We demonstrate that the models with the same pre-training loss, but different model and data sizes, generate the same performance on various downstream tasks. We also discover that a model exhibits emergent abilities on certain tasks -- regardless of the continuity of metrics -- when its pre-training loss falls below a specific threshold. Before reaching this threshold, its performance remains at the level of random guessing. This inspires us to redefine emergent abilities as those that
&lt;/p&gt;</description></item><item><title>SelectIT&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#30340;&#33021;&#21147;&#21644;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#39069;&#22806;&#36164;&#28304;&#30340;&#39640;&#25928;&#36873;&#25321;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#36827;&#32780;&#25552;&#21319;&#20102;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.16705</link><description>&lt;p&gt;
SelectIT: &#36890;&#36807;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#33258;&#25105;&#21453;&#24605;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25351;&#23548;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
SelectIT: Selective Instruction Tuning for Large Language Models via Uncertainty-Aware Self-Reflection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16705
&lt;/p&gt;
&lt;p&gt;
SelectIT&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#30340;&#33021;&#21147;&#21644;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#39069;&#22806;&#36164;&#28304;&#30340;&#39640;&#25928;&#36873;&#25321;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#36827;&#32780;&#25552;&#21319;&#20102;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#23548;&#35843;&#25972;&#65288;IT&#65289;&#23545;&#20110;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20197;&#36866;&#24212;&#20154;&#31867;&#20013;&#24515;&#20132;&#20114;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#30340;&#36827;&#23637;&#34920;&#26126;&#65292;&#31934;&#24515;&#36873;&#25321;&#19968;&#23567;&#37096;&#20998;&#39640;&#36136;&#37327;&#30340;IT&#25968;&#25454;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;LLMs&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#24120;&#35265;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#39069;&#22806;&#30340;&#27169;&#22411;&#25110;&#25968;&#25454;&#38598;&#65292;&#36825;&#22686;&#21152;&#20102;&#25104;&#26412;&#24182;&#38480;&#21046;&#20102;&#24191;&#27867;&#37319;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;SelectIT&#65292;&#23427;&#21033;&#29992;LLM&#26412;&#36523;&#30340;&#22522;&#26412;&#33021;&#21147;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;LLMs&#20013;&#22266;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#26356;&#26377;&#25928;&#22320;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;IT&#25968;&#25454;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#36164;&#28304;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;IT&#25968;&#25454;&#38598;&#65292;&#21517;&#20026;&#36873;&#25321;&#24615;&#32650;&#39548;&#65288;Selective Alpaca&#65289;&#65292;&#36890;&#36807;&#23558;SelectIT&#24212;&#29992;&#20110;Alpaca-GPT4&#25968;&#25454;&#38598;&#32780;&#21019;&#24314;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#36873;&#25321;&#24615;&#32650;&#39548;&#36827;&#34892;IT&#21487;&#20197;&#26497;&#22823;&#22320;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;SelectIT&#30340;&#31283;&#20581;&#24615;&#20063;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16705v1 Announce Type: new  Abstract: Instruction tuning (IT) is crucial to tailoring large language models (LLMs) towards human-centric interactions. Recent advancements have shown that the careful selection of a small, high-quality subset of IT data can significantly enhance the performance of LLMs. Despite this, common approaches often rely on additional models or data sets, which increases costs and limits widespread adoption. In this work, we propose a novel approach, termed SelectIT, that capitalizes on the foundational capabilities of the LLM itself. Specifically, we exploit the intrinsic uncertainty present in LLMs to more effectively select high-quality IT data, without the need for extra resources. Furthermore, we introduce a novel IT dataset, the Selective Alpaca, created by applying SelectIT to the Alpaca-GPT4 dataset. Empirical results demonstrate that IT using Selective Alpaca leads to substantial model ability enhancement. The robustness of SelectIT has also b
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#33268;&#21147;&#20110;&#23398;&#20064;&#22914;&#20309;&#35774;&#35745;&#26368;&#20248;&#31246;&#25910;&#65292;&#20197;&#22312;&#38750;&#21407;&#23376;&#25317;&#22581;&#21338;&#24328;&#20013;&#25552;&#39640;&#25928;&#29575;&#12290;&#20026;&#20102;&#35299;&#20915;&#25351;&#25968;&#32423;&#30340;&#31246;&#25910;&#20989;&#25968;&#31354;&#38388;&#12289;&#26799;&#24230;&#19981;&#23384;&#22312;&#21644;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#20984;&#24615;&#31561;&#25361;&#25112;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;&#20998;&#27573;&#32447;&#24615;&#31246;&#25910;&#12289;&#39069;&#22806;&#30340;&#32447;&#24615;&#39033;&#21644;&#26377;&#25928;&#30340;&#23376;&#20363;&#31243;&#30340;&#26032;&#39062;&#32452;&#25104;&#37096;&#20998;&#12290;</title><link>https://arxiv.org/abs/2402.07437</link><description>&lt;p&gt;
&#38750;&#21407;&#23376;&#25317;&#22581;&#21338;&#24328;&#20013;&#23398;&#20064;&#26368;&#20248;&#31246;&#25910;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Learning Optimal Tax Design in Nonatomic Congestion Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07437
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#33268;&#21147;&#20110;&#23398;&#20064;&#22914;&#20309;&#35774;&#35745;&#26368;&#20248;&#31246;&#25910;&#65292;&#20197;&#22312;&#38750;&#21407;&#23376;&#25317;&#22581;&#21338;&#24328;&#20013;&#25552;&#39640;&#25928;&#29575;&#12290;&#20026;&#20102;&#35299;&#20915;&#25351;&#25968;&#32423;&#30340;&#31246;&#25910;&#20989;&#25968;&#31354;&#38388;&#12289;&#26799;&#24230;&#19981;&#23384;&#22312;&#21644;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#20984;&#24615;&#31561;&#25361;&#25112;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;&#20998;&#27573;&#32447;&#24615;&#31246;&#25910;&#12289;&#39069;&#22806;&#30340;&#32447;&#24615;&#39033;&#21644;&#26377;&#25928;&#30340;&#23376;&#20363;&#31243;&#30340;&#26032;&#39062;&#32452;&#25104;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#23398;&#20064;&#26368;&#20248;&#31246;&#25910;&#35774;&#35745;&#65292;&#20197;&#22312;&#38750;&#21407;&#23376;&#25317;&#22581;&#21338;&#24328;&#20013;&#26368;&#22823;&#21270;&#25928;&#29575;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#29609;&#23478;&#20043;&#38388;&#30340;&#33258;&#21033;&#34892;&#20026;&#21487;&#33021;&#20250;&#30772;&#22351;&#31995;&#32479;&#30340;&#25928;&#29575;&#12290;&#31246;&#21153;&#26426;&#21046;&#26159;&#32531;&#35299;&#27492;&#38382;&#39064;&#24182;&#24341;&#23548;&#31038;&#20250;&#26368;&#20248;&#34892;&#20026;&#30340;&#24120;&#35265;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#37319;&#21462;&#20102;&#23398;&#20064;&#26368;&#20248;&#31246;&#25910;&#30340;&#21021;&#22987;&#27493;&#39588;&#65292;&#35813;&#26368;&#20248;&#31246;&#25910;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#21453;&#39304;&#26469;&#26368;&#23567;&#21270;&#31038;&#20250;&#25104;&#26412;&#65292;&#21363;&#31246;&#21153;&#35774;&#35745;&#32773;&#21482;&#33021;&#35266;&#23519;&#21040;&#24378;&#21046;&#31246;&#25910;&#19979;&#30340;&#22343;&#34913;&#29366;&#24577;&#12290;&#30001;&#20110;&#25351;&#25968;&#32423;&#30340;&#31246;&#25910;&#20989;&#25968;&#31354;&#38388;&#65292;&#26799;&#24230;&#19981;&#23384;&#22312;&#21644;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#20984;&#24615;&#65292;&#29616;&#26377;&#31639;&#27861;&#19981;&#36866;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21033;&#29992;&#20102;&#20960;&#20010;&#26032;&#39062;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#65288;1&#65289;&#20998;&#27573;&#32447;&#24615;&#31246;&#25910;&#26469;&#36817;&#20284;&#26368;&#20248;&#31246;&#25910;&#65307;&#65288;2&#65289;&#39069;&#22806;&#30340;&#32447;&#24615;&#39033;&#26469;&#20445;&#35777;&#24378;&#20984;&#28508;&#21147;&#20989;&#25968;&#65307;&#65288;3&#65289;&#26377;&#25928;&#30340;&#23376;&#20363;&#31243;&#26469;&#25214;&#21040;&#8220;&#36793;&#30028;&#8221;&#31246;&#25910;&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#25214;&#21040;&#19968;&#20010;$\epsilon$-&#26368;&#20248;&#31246;&#25910;&#65292;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;$O(\bet
&lt;/p&gt;
&lt;p&gt;
We study how to learn the optimal tax design to maximize the efficiency in nonatomic congestion games. It is known that self-interested behavior among the players can damage the system's efficiency. Tax mechanisms is a common method to alleviate this issue and induce socially optimal behavior. In this work, we take the initial step for learning the optimal tax that can minimize the social cost with \emph{equilibrium feedback}, i.e., the tax designer can only observe the equilibrium state under the enforced tax. Existing algorithms are not applicable due to the exponentially large tax function space, nonexistence of the gradient, and nonconvexity of the objective. To tackle these challenges, our algorithm leverages several novel components: (1) piece-wise linear tax to approximate the optimal tax; (2) an extra linear term to guarantee a strongly convex potential function; (3) efficient subroutine to find the ``boundary'' tax. The algorithm can find an $\epsilon$-optimal tax with $O(\bet
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#21487;&#31283;&#23450;&#35745;&#31639;&#65292;&#33021;&#22815;&#36827;&#34892;&#22810;&#23610;&#24230;&#27604;&#36739;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2311.16054</link><description>&lt;p&gt;
&#29992;&#20110;&#35780;&#20272;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#30340;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;
&lt;/p&gt;
&lt;p&gt;
Metric Space Magnitude for Evaluating the Diversity of Latent Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16054
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#21487;&#31283;&#23450;&#35745;&#31639;&#65292;&#33021;&#22815;&#36827;&#34892;&#22810;&#23610;&#24230;&#27604;&#36739;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24230;&#37327;&#31354;&#38388;&#30340;&#22823;&#23567;&#26159;&#19968;&#31181;&#36817;&#26399;&#24314;&#31435;&#30340;&#19981;&#21464;&#24615;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#25552;&#20379;&#31354;&#38388;&#30340;&#8220;&#26377;&#25928;&#22823;&#23567;&#8221;&#30340;&#34913;&#37327;&#65292;&#24182;&#25429;&#25417;&#21040;&#35768;&#22810;&#20960;&#20309;&#23646;&#24615;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#20869;&#22312;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#24418;&#24335;&#21270;&#20102;&#26377;&#38480;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#20989;&#25968;&#20043;&#38388;&#30340;&#26032;&#39062;&#19981;&#30456;&#20284;&#24615;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;&#25968;&#25454;&#25200;&#21160;&#19979;&#20445;&#35777;&#31283;&#23450;&#65292;&#21487;&#20197;&#39640;&#25928;&#35745;&#31639;&#65292;&#24182;&#19988;&#33021;&#22815;&#23545;&#28508;&#22312;&#34920;&#31034;&#36827;&#34892;&#20005;&#26684;&#30340;&#22810;&#23610;&#24230;&#27604;&#36739;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;&#23454;&#39564;&#22871;&#20214;&#20013;&#30340;&#23454;&#29992;&#24615;&#21644;&#21331;&#36234;&#24615;&#33021;&#65292;&#21253;&#25324;&#19981;&#21516;&#39046;&#22495;&#21644;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#12289;&#27169;&#24335;&#23849;&#28291;&#26816;&#27979;&#20197;&#21450;&#29992;&#20110;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The magnitude of a metric space is a recently-established invariant, providing a measure of the 'effective size' of a space across multiple scales while also capturing numerous geometrical properties. We develop a family of magnitude-based measures of the intrinsic diversity of latent representations, formalising a novel notion of dissimilarity between magnitude functions of finite metric spaces. Our measures are provably stable under perturbations of the data, can be efficiently calculated, and enable a rigorous multi-scale comparison of latent representations. We show the utility and superior performance of our measures in an experimental suite that comprises different domains and tasks, including the evaluation of diversity, the detection of mode collapse, and the evaluation of generative models for text, image, and graph data.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23545;&#38543;&#26426;&#32447;&#24615;&#36172;&#33218;&#29615;&#22659;&#20013;&#30340;&#38598;&#25104;&#25277;&#26679;&#36827;&#34892;&#20102;&#39318;&#27425;&#23454;&#29992;&#21644;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#37319;&#29992;&#35268;&#27169;&#20026;$d \log T$&#30340;&#38598;&#25104;&#25277;&#26679;&#21487;&#20197;&#33719;&#24471;&#25509;&#36817;$\sqrt{T}$&#38454;&#30340;&#21518;&#24724;&#65292;&#32780;&#19981;&#38656;&#35201;&#38598;&#25104;&#22823;&#23567;&#19982;$T$&#32447;&#24615;&#25193;&#23637;&#12290;</title><link>https://arxiv.org/abs/2311.08376</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#33218;&#30340;&#38598;&#25104;&#25277;&#26679;&#65306;&#23567;&#38598;&#25104;&#36275;&#30691;
&lt;/p&gt;
&lt;p&gt;
Ensemble sampling for linear bandits: small ensembles suffice
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08376
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23545;&#38543;&#26426;&#32447;&#24615;&#36172;&#33218;&#29615;&#22659;&#20013;&#30340;&#38598;&#25104;&#25277;&#26679;&#36827;&#34892;&#20102;&#39318;&#27425;&#23454;&#29992;&#21644;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#37319;&#29992;&#35268;&#27169;&#20026;$d \log T$&#30340;&#38598;&#25104;&#25277;&#26679;&#21487;&#20197;&#33719;&#24471;&#25509;&#36817;$\sqrt{T}$&#38454;&#30340;&#21518;&#24724;&#65292;&#32780;&#19981;&#38656;&#35201;&#38598;&#25104;&#22823;&#23567;&#19982;$T$&#32447;&#24615;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#23545;&#38543;&#26426;&#32447;&#24615;&#36172;&#33218;&#35774;&#23450;&#19979;&#30340;&#38598;&#25104;&#25277;&#26679;&#36827;&#34892;&#20102;&#26377;&#29992;&#19988;&#20005;&#35880;&#30340;&#20998;&#26512;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#23545;&#20110;&#19968;&#20010;&#20855;&#26377;&#20132;&#20114;&#20316;&#29992;&#26102;&#38388;&#36328;&#24230;$T$&#30340;$d$&#32500;&#38543;&#26426;&#32447;&#24615;&#36172;&#33218;&#65292;&#37319;&#29992;&#38598;&#25104;&#22823;&#23567;&#20026;$\smash{d \log T}$&#30340;&#38598;&#25104;&#25277;&#26679;&#65292;&#36973;&#21463;&#30340;&#21518;&#24724;&#26368;&#22810;&#20026;$\smash{(d \log T)^{5/2} \sqrt{T}}$&#38454;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#22312;&#20219;&#20309;&#32467;&#26500;&#21270;&#29615;&#22659;&#20013;&#31532;&#19968;&#20010;&#19981;&#35201;&#27714;&#38598;&#25104;&#22823;&#23567;&#19982;$T$&#32447;&#24615;&#25193;&#23637;&#30340;&#32467;&#26524;&#65292;&#36825;&#20351;&#24471;&#38598;&#25104;&#25277;&#26679;&#22833;&#21435;&#24847;&#20041;&#65292;&#21516;&#26102;&#33719;&#24471;&#20102;&#25509;&#36817;$\smash{\sqrt{T}}$&#38454;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20063;&#26159;&#31532;&#19968;&#20010;&#20801;&#35768;&#26080;&#38480;&#21160;&#20316;&#38598;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08376v2 Announce Type: replace-cross  Abstract: We provide the first useful and rigorous analysis of ensemble sampling for the stochastic linear bandit setting. In particular, we show that, under standard assumptions, for a $d$-dimensional stochastic linear bandit with an interaction horizon $T$, ensemble sampling with an ensemble of size of order $\smash{d \log T}$ incurs regret at most of the order $\smash{(d \log T)^{5/2} \sqrt{T}}$. Ours is the first result in any structured setting not to require the size of the ensemble to scale linearly with $T$ -- which defeats the purpose of ensemble sampling -- while obtaining near $\smash{\sqrt{T}}$ order regret. Ours is also the first result that allows infinite action sets.
&lt;/p&gt;</description></item><item><title>SupplyGraph&#26159;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20379;&#24212;&#38142;&#35268;&#21010;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#26469;&#33258;&#23391;&#21152;&#25289;&#22269;&#19968;&#23478;&#39046;&#20808;&#24555;&#36895;&#28040;&#36153;&#21697;&#20844;&#21496;&#30340;&#23454;&#38469;&#25968;&#25454;&#65292;&#29992;&#20110;&#20248;&#21270;&#12289;&#39044;&#27979;&#21644;&#35299;&#20915;&#20379;&#24212;&#38142;&#38382;&#39064;&#12290;&#25968;&#25454;&#38598;&#20013;&#30340;&#26102;&#38388;&#25968;&#25454;&#20316;&#20026;&#33410;&#28857;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#38144;&#21806;&#39044;&#27979;&#12289;&#29983;&#20135;&#35745;&#21010;&#21644;&#25925;&#38556;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2401.15299</link><description>&lt;p&gt;
SupplyGraph: &#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20379;&#24212;&#38142;&#35268;&#21010;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
SupplyGraph: A Benchmark Dataset for Supply Chain Planning using Graph Neural Networks. (arXiv:2401.15299v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15299
&lt;/p&gt;
&lt;p&gt;
SupplyGraph&#26159;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20379;&#24212;&#38142;&#35268;&#21010;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#26469;&#33258;&#23391;&#21152;&#25289;&#22269;&#19968;&#23478;&#39046;&#20808;&#24555;&#36895;&#28040;&#36153;&#21697;&#20844;&#21496;&#30340;&#23454;&#38469;&#25968;&#25454;&#65292;&#29992;&#20110;&#20248;&#21270;&#12289;&#39044;&#27979;&#21644;&#35299;&#20915;&#20379;&#24212;&#38142;&#38382;&#39064;&#12290;&#25968;&#25454;&#38598;&#20013;&#30340;&#26102;&#38388;&#25968;&#25454;&#20316;&#20026;&#33410;&#28857;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#38144;&#21806;&#39044;&#27979;&#12289;&#29983;&#20135;&#35745;&#21010;&#21644;&#25925;&#38556;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#19981;&#21516;&#39046;&#22495;&#22914;&#36816;&#36755;&#12289;&#29983;&#29289;&#20449;&#24687;&#23398;&#12289;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#22312;&#23558;GNNs&#24212;&#29992;&#20110;&#20379;&#24212;&#38142;&#32593;&#32476;&#26041;&#38754;&#65292;&#30446;&#21069;&#23578;&#32570;&#20047;&#30740;&#31350;&#12290;&#20379;&#24212;&#38142;&#32593;&#32476;&#22312;&#32467;&#26500;&#19978;&#31867;&#20284;&#20110;&#22270;&#24418;&#65292;&#20351;&#20854;&#25104;&#20026;&#24212;&#29992;GNN&#26041;&#27861;&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;&#36825;&#20026;&#20248;&#21270;&#12289;&#39044;&#27979;&#21644;&#35299;&#20915;&#20379;&#24212;&#38142;&#38382;&#39064;&#24320;&#36767;&#20102;&#26080;&#38480;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#27492;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#38556;&#30861;&#22312;&#20110;&#32570;&#20047;&#30495;&#23454;&#19990;&#30028;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#20197;&#20419;&#36827;&#20351;&#29992;GNN&#26469;&#30740;&#31350;&#21644;&#35299;&#20915;&#20379;&#24212;&#38142;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26469;&#33258;&#23391;&#21152;&#25289;&#22269;&#19968;&#23478;&#39046;&#20808;&#30340;&#24555;&#36895;&#28040;&#36153;&#21697;&#20844;&#21496;&#30340;&#23454;&#38469;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#20391;&#37325;&#20110;&#29992;&#20110;&#29983;&#20135;&#30446;&#30340;&#30340;&#20379;&#24212;&#38142;&#35268;&#21010;&#30340;&#26102;&#38388;&#20219;&#21153;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#25324;&#26102;&#38388;&#25968;&#25454;&#20316;&#20026;&#33410;&#28857;&#29305;&#24449;&#65292;&#20197;&#23454;&#29616;&#38144;&#21806;&#39044;&#27979;&#12289;&#29983;&#20135;&#35745;&#21010;&#21644;&#25925;&#38556;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have gained traction across different domains such as transportation, bio-informatics, language processing, and computer vision. However, there is a noticeable absence of research on applying GNNs to supply chain networks. Supply chain networks are inherently graph-like in structure, making them prime candidates for applying GNN methodologies. This opens up a world of possibilities for optimizing, predicting, and solving even the most complex supply chain problems. A major setback in this approach lies in the absence of real-world benchmark datasets to facilitate the research and resolution of supply chain problems using GNNs. To address the issue, we present a real-world benchmark dataset for temporal tasks, obtained from one of the leading FMCG companies in Bangladesh, focusing on supply chain planning for production purposes. The dataset includes temporal data as node features to enable sales predictions, production planning, and the identification of fa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28508;&#22312;&#34920;&#31034;&#30340;&#31561;&#21464;&#24615;&#20197;&#21450;&#22312;&#20351;&#29992;&#20013;&#32771;&#34385;&#31561;&#21464;&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36873;&#25321;&#19981;&#21464;&#25237;&#24433;&#30340;&#21407;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20004;&#20010;&#23454;&#20363;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.12588</link><description>&lt;p&gt;
&#35299;&#35835;&#31561;&#21464;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Interpreting Equivariant Representations. (arXiv:2401.12588v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12588
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28508;&#22312;&#34920;&#31034;&#30340;&#31561;&#21464;&#24615;&#20197;&#21450;&#22312;&#20351;&#29992;&#20013;&#32771;&#34385;&#31561;&#21464;&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36873;&#25321;&#19981;&#21464;&#25237;&#24433;&#30340;&#21407;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20004;&#20010;&#23454;&#20363;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35270;&#21270;&#12289;&#25554;&#20540;&#25110;&#29305;&#24449;&#25552;&#21462;&#31561;&#19979;&#28216;&#20219;&#21153;&#65292;&#28508;&#22312;&#34920;&#31034;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#19981;&#21464;&#21644;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#26159;&#29992;&#20110;&#24378;&#21046;&#25191;&#34892;&#24402;&#32435;&#20559;&#24046;&#30340;&#24378;&#22823;&#19988;&#24050;&#24314;&#31435;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#22312;&#20351;&#29992;&#28508;&#22312;&#34920;&#31034;&#26102;&#65292;&#24517;&#39035;&#21516;&#26102;&#32771;&#34385;&#31561;&#21464;&#27169;&#22411;&#26045;&#21152;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#32771;&#34385;&#24402;&#32435;&#20559;&#24046;&#20250;&#23548;&#33268;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#19979;&#38477;&#65292;&#30456;&#21453;&#65292;&#36890;&#36807;&#20351;&#29992;&#28508;&#22312;&#34920;&#31034;&#30340;&#19981;&#21464;&#25237;&#24433;&#21487;&#20197;&#26377;&#25928;&#22320;&#32771;&#34385;&#24402;&#32435;&#20559;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36873;&#25321;&#36825;&#26679;&#19968;&#20010;&#25237;&#24433;&#30340;&#21407;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20004;&#20010;&#24120;&#35265;&#20363;&#23376;&#20013;&#20351;&#29992;&#36825;&#20123;&#21407;&#21017;&#30340;&#24433;&#21709;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#23376;&#22270;&#29983;&#25104;&#30340;&#32622;&#25442;&#31561;&#21464;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65307;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#35774;&#35745;&#20986;&#19981;&#20135;&#29983;&#20449;&#24687;&#25439;&#22833;&#30340;&#19981;&#21464;&#25237;&#24433;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent representations are used extensively for downstream tasks, such as visualization, interpolation or feature extraction of deep learning models. Invariant and equivariant neural networks are powerful and well-established models for enforcing inductive biases. In this paper, we demonstrate that the inductive bias imposed on the by an equivariant model must also be taken into account when using latent representations. We show how not accounting for the inductive biases leads to decreased performance on downstream tasks, and vice versa, how accounting for inductive biases can be done effectively by using an invariant projection of the latent representations. We propose principles for how to choose such a projection, and show the impact of using these principles in two common examples: First, we study a permutation equivariant variational auto-encoder trained for molecule graph generation; here we show that invariant projections can be designed that incur no loss of information in the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31934;&#32454;&#30340;&#26426;&#22120;&#21435;&#23398;&#20064;&#31574;&#30053;&#65292;&#36890;&#36807;&#32454;&#31890;&#24230;&#27169;&#22411;&#21442;&#25968;&#30340;&#25200;&#21160;&#26469;&#23454;&#29616;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#25511;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#37319;&#29992;&#36951;&#24536;&#29575;&#21644;&#35760;&#24518;&#20445;&#30041;&#29575;&#31561;&#26032;&#30340;&#25351;&#26631;&#26469;&#35780;&#20272;&#21435;&#23398;&#20064;&#25928;&#26524;&#21644;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.04385</link><description>&lt;p&gt;
&#36890;&#36807;&#32454;&#31890;&#24230;&#27169;&#22411;&#21442;&#25968;&#25200;&#21160;&#23454;&#29616;&#26426;&#22120;&#21435;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Machine unlearning through fine-grained model parameters perturbation. (arXiv:2401.04385v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04385
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31934;&#32454;&#30340;&#26426;&#22120;&#21435;&#23398;&#20064;&#31574;&#30053;&#65292;&#36890;&#36807;&#32454;&#31890;&#24230;&#27169;&#22411;&#21442;&#25968;&#30340;&#25200;&#21160;&#26469;&#23454;&#29616;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#25511;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#37319;&#29992;&#36951;&#24536;&#29575;&#21644;&#35760;&#24518;&#20445;&#30041;&#29575;&#31561;&#26032;&#30340;&#25351;&#26631;&#26469;&#35780;&#20272;&#21435;&#23398;&#20064;&#25928;&#26524;&#21644;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#21435;&#23398;&#20064;&#25216;&#26415;&#28041;&#21450;&#21040;&#25764;&#38144;&#25968;&#25454;&#35760;&#24405;&#21644;&#20943;&#23567;&#35813;&#25968;&#25454;&#23545;&#35757;&#32451;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#24110;&#21161;&#23454;&#29616;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#30446;&#26631;&#65292;&#20294;&#20250;&#24102;&#26469;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22522;&#20110;&#21442;&#25968;&#25200;&#21160;&#30340;&#26435;&#37325;&#21435;&#23398;&#20064;&#26159;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#65292;&#20294;&#36890;&#24120;&#28041;&#21450;&#21040;&#20840;&#23616;&#20462;&#25913;&#21442;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31934;&#32454;&#30340;Top-K&#21644;Random-k&#21442;&#25968;&#25200;&#21160;&#19981;&#31934;&#30830;&#26426;&#22120;&#21435;&#23398;&#20064;&#31574;&#30053;&#65292;&#20197;&#28385;&#36275;&#38544;&#31169;&#38656;&#27714;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#25104;&#26412;&#21487;&#25511;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;&#35780;&#20272;&#26426;&#22120;&#21435;&#23398;&#20064;&#25928;&#26524;&#30340;&#25361;&#25112;&#65292;&#32771;&#34385;&#20102;&#27169;&#22411;&#22312;&#21435;&#23398;&#20064;&#21644;&#21097;&#20313;&#25968;&#25454;&#19978;&#30340;&#24191;&#20041;&#24615;&#33021;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#35780;&#20272;&#21435;&#23398;&#20064;&#25928;&#26524;&#21644;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#25351;&#26631;&#65292;&#21363;&#36951;&#24536;&#29575;&#21644;&#35760;&#24518;&#20445;&#30041;&#29575;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#19981;&#31934;&#30830;&#30340;&#26426;&#22120;&#21435;&#23398;&#20064;&#65292;&#29616;&#26377;&#30340;&#25351;&#26631;&#26080;&#27861;&#23545;&#21435;&#23398;&#20064;&#31243;&#24230;&#36827;&#34892;&#20934;&#30830;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine unlearning techniques, which involve retracting data records and reducing influence of said data on trained models, help with the user privacy protection objective but incur significant computational costs. Weight perturbation-based unlearning is a general approach, but it typically involves globally modifying the parameters. We propose fine-grained Top-K and Random-k parameters perturbed inexact machine unlearning strategies that address the privacy needs while keeping the computational costs tractable.  In order to demonstrate the efficacy of our strategies we also tackle the challenge of evaluating the effectiveness of machine unlearning by considering the model's generalization performance across both unlearning and remaining data. To better assess the unlearning effect and model generalization, we propose novel metrics, namely, the forgetting rate and memory retention rate. However, for inexact machine unlearning, current metrics are inadequate in quantifying the degree of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;Volterra&#24378;&#35843;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#21487;&#36890;&#37327;&#24615; (VANYA) &#27169;&#22411;&#26469;&#27169;&#25311;&#26862;&#26519;&#30733;&#20240;&#65292;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;&#25429;&#39135;&#32773;-&#34987;&#25429;&#39135;&#32773;&#21160;&#21147;&#23398;&#65292;&#24182;&#22312;&#23545;&#20122;&#39532;&#36874;&#38632;&#26519;&#25968;&#25454;&#36827;&#34892;&#20102;&#39044;&#27979;&#65292;&#24182;&#19982;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2308.06471</link><description>&lt;p&gt;
Volterra&#24378;&#35843;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#21487;&#36890;&#37327;&#24615; (VANYA) &#22312;&#26862;&#26519;&#30733;&#20240;&#27169;&#25311;&#20013;&#30340;&#24212;&#29992;&#65306;&#20197;&#20122;&#39532;&#36874;&#38632;&#26519;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Volterra Accentuated Non-Linear Dynamical Admittance (VANYA) to model Deforestation: An Exemplification from the Amazon Rainforest. (arXiv:2308.06471v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;Volterra&#24378;&#35843;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#21487;&#36890;&#37327;&#24615; (VANYA) &#27169;&#22411;&#26469;&#27169;&#25311;&#26862;&#26519;&#30733;&#20240;&#65292;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;&#25429;&#39135;&#32773;-&#34987;&#25429;&#39135;&#32773;&#21160;&#21147;&#23398;&#65292;&#24182;&#22312;&#23545;&#20122;&#39532;&#36874;&#38632;&#26519;&#25968;&#25454;&#36827;&#34892;&#20102;&#39044;&#27979;&#65292;&#24182;&#19982;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26234;&#33021;&#33258;&#21160;&#21270;&#25216;&#26415;&#36890;&#36807;&#20854;&#26368;&#26032;&#30340;&#25216;&#26415;&#36827;&#23637;&#65292;&#22312;&#25269;&#24481;&#39123;&#39118;&#12289;&#24178;&#26097;&#21644;&#22320;&#38663;&#31561;&#26041;&#38754;&#32473;&#20104;&#20102;&#25105;&#20204;&#25903;&#25345;&#12290;&#31639;&#27861;&#23398;&#20064;&#24050;&#32463;&#25512;&#21160;&#20102;&#31070;&#32463;&#31185;&#23398;&#12289;&#36951;&#20256;&#23398;&#21644;&#20154;&#26426;&#20132;&#20114;&#31561;&#39046;&#22495;&#30340;&#21457;&#23637;&#12290;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#23545;&#36827;&#23637;&#36215;&#21040;&#20102;&#20419;&#36827;&#20316;&#29992;&#12290;&#22312;&#20256;&#32479;&#39046;&#22495;&#20013;&#37319;&#29992;&#36825;&#20123;&#26041;&#27861;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;&#31070;&#32463;&#32593;&#32476;&#38754;&#20020;&#29702;&#35299;&#21644;&#20559;&#35265;&#38382;&#39064;&#12290;&#20154;&#24037;&#26234;&#33021;&#22312;&#31185;&#23398;&#39046;&#22495;&#30340;&#25193;&#23637;&#26159;&#30001;&#20110;&#20854;&#21487;&#36866;&#24212;&#30340;&#31616;&#21333;&#25551;&#36848;&#31526;&#21644;&#32452;&#21512;&#35770;&#35777;&#12290;&#26412;&#25991;&#20391;&#37325;&#20110;&#21033;&#29992;VANYA&#27169;&#22411;&#39044;&#27979;&#26519;&#22320;&#25439;&#22833;&#65292;&#24182;&#32467;&#21512;&#25429;&#39135;&#32773;-&#34987;&#25429;&#39135;&#32773;&#21160;&#21147;&#23398;&#12290;VANYA&#27169;&#22411;&#23545;&#20122;&#39532;&#36874;&#38632;&#26519;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#39044;&#27979;&#65292;&#24182;&#19982;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#65288;&#22914;&#38271;&#30701;&#26399;&#35760;&#24518;&#12289;N-BEATS&#21644;RCN&#65289;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intelligent automation supports us against cyclones, droughts, and seismic events with recent technology advancements. Algorithmic learning has advanced fields like neuroscience, genetics, and human-computer interaction. Time-series data boosts progress. Challenges persist in adopting these approaches in traditional fields. Neural networks face comprehension and bias issues. AI's expansion across scientific areas is due to adaptable descriptors and combinatorial argumentation. This article focuses on modeling Forest loss using the VANYA Model, incorporating Prey Predator Dynamics. VANYA predicts forest cover, demonstrated on Amazon Rainforest data against other forecasters like Long Short-Term Memory, N-BEATS, RCN.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#37051;&#22495;&#28151;&#28102;&#24230;&#37327;&#26469;&#20998;&#31163;&#23398;&#20064;&#35299;&#20915;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#28151;&#28102;&#33410;&#28857;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26356;&#21487;&#38752;&#22320;&#21306;&#20998;&#24322;&#36136;&#33410;&#28857;&#21644;&#21516;&#36136;&#33410;&#28857;&#65292;&#24182;&#25913;&#21892;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02285</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#31163;&#23398;&#20064;&#35299;&#20915;&#28151;&#28102;&#33410;&#28857;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Clarify Confused Nodes Through Separated Learning. (arXiv:2306.02285v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#37051;&#22495;&#28151;&#28102;&#24230;&#37327;&#26469;&#20998;&#31163;&#23398;&#20064;&#35299;&#20915;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#28151;&#28102;&#33410;&#28857;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26356;&#21487;&#38752;&#22320;&#21306;&#20998;&#24322;&#36136;&#33410;&#28857;&#21644;&#21516;&#36136;&#33410;&#28857;&#65292;&#24182;&#25913;&#21892;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22312;&#22270;&#23548;&#21521;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#22270;&#20013;&#19981;&#21487;&#36991;&#20813;&#22320;&#21253;&#21547;&#19968;&#23450;&#27604;&#20363;&#30340;&#24322;&#36136;&#33410;&#28857;&#65292;&#36825;&#25361;&#25112;&#20102;&#32463;&#20856;GNN&#30340;&#21516;&#36136;&#24615;&#20551;&#35774;&#65292;&#24182;&#38459;&#30861;&#20102;&#20854;&#24615;&#33021;&#12290;&#29616;&#26377;&#30740;&#31350;&#22823;&#22810;&#25968;&#20173;&#35774;&#35745;&#20102;&#20855;&#26377;&#24322;&#36136;&#33410;&#28857;&#21644;&#21516;&#36136;&#33410;&#28857;&#38388;&#20849;&#20139;&#26435;&#37325;&#30340;&#36890;&#29992;&#27169;&#22411;&#12290;&#23613;&#31649;&#36825;&#20123;&#21162;&#21147;&#20013;&#21253;&#21547;&#20102;&#39640;&#38454;&#20449;&#24687;&#21644;&#22810;&#36890;&#36947;&#26550;&#26500;&#65292;&#20294;&#24448;&#24448;&#25928;&#26524;&#19981;&#20339;&#12290;&#23569;&#25968;&#30740;&#31350;&#23581;&#35797;&#35757;&#32451;&#19981;&#21516;&#33410;&#28857;&#32452;&#30340;&#20998;&#31163;&#23398;&#20064;&#65292;&#20294;&#21463;&#21040;&#20102;&#19981;&#21512;&#36866;&#30340;&#20998;&#31163;&#24230;&#37327;&#21644;&#20302;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#31216;&#20026;&#37051;&#22495;&#28151;&#28102;&#65288;NC&#65289;&#65292;&#20197;&#20415;&#26356;&#21487;&#38752;&#22320;&#20998;&#31163;&#33410;&#28857;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#20855;&#26377;&#19981;&#21516;NC&#20540;&#30340;&#33410;&#28857;&#32452;&#22312;&#32452;&#20869;&#20934;&#30830;&#24230;&#21644;&#21487;&#35270;&#21270;&#23884;&#20837;&#19978;&#23384;&#22312;&#19968;&#23450;&#24046;&#24322;&#12290;&#36825;&#20026;&#22522;&#20110;&#37051;&#22495;&#28151;&#28102;&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;NC-GCN&#65289;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have achieved remarkable advances in graph-oriented tasks. However, real-world graphs invariably contain a certain proportion of heterophilous nodes, challenging the homophily assumption of classical GNNs and hindering their performance. Most existing studies continue to design generic models with shared weights between heterophilous and homophilous nodes. Despite the incorporation of high-order messages or multi-channel architectures, these efforts often fall short. A minority of studies attempt to train different node groups separately but suffer from inappropriate separation metrics and low efficiency. In this paper, we first propose a new metric, termed Neighborhood Confusion (NC), to facilitate a more reliable separation of nodes. We observe that node groups with different levels of NC values exhibit certain differences in intra-group accuracy and visualized embeddings. These pave the way for Neighborhood Confusion-guided Graph Convolutional Network (N
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#29992;&#20110;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#31639;&#27861;&#20805;&#24403;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#24674;&#22797;&#29992;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#32780;&#26469;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.09123</link><description>&lt;p&gt;
&#20351;&#29992;&#34987;&#21160; Langevin &#21160;&#21147;&#23398;&#30340;&#33258;&#36866;&#24212;&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#26377;&#38480;&#26679;&#26412;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Finite-Sample Bounds for Adaptive Inverse Reinforcement Learning using Passive Langevin Dynamics. (arXiv:2304.09123v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#29992;&#20110;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#31639;&#27861;&#20805;&#24403;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#24674;&#22797;&#29992;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#32780;&#26469;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398; (SGLD) &#26159;&#20174;&#27010;&#29575;&#20998;&#24067;&#37319;&#26679;&#30340;&#26377;&#29992;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861; (PSGLD) &#30340;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#65292;&#26088;&#22312;&#23454;&#29616;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#27492;&#22788;&#30340;&#8220;&#34987;&#21160;&#8221;&#26159;&#25351; PSGLD &#31639;&#27861;(&#36870;&#23398;&#20064;&#36807;&#31243;)&#21487;&#29992;&#30340;&#22122;&#22768;&#28176;&#21464;&#26159;&#30001;&#22806;&#37096;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;(&#27491;&#21521;&#23398;&#20064;&#22120;)&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#28857;&#19978;&#35780;&#20272;&#30340;&#12290;PSGLD &#31639;&#27861;&#22240;&#27492;&#20805;&#24403;&#19968;&#20010;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#21487;&#24674;&#22797;&#27491;&#22312;&#34987;&#27492;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#20351;&#29992;&#38543;&#26426;&#36924;&#36817;&#25216;&#26415;&#20998;&#26512;&#20102;&#36825;&#20010;&#34987;&#21160;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#33021;&#65307;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#23427;&#30340;&#26377;&#38480;&#26102;&#38388;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#34987;&#21160;&#31639;&#27861;&#21644;&#20854;&#31283;&#23450;&#27979;&#24230;&#20043;&#38388;&#30340; 2-Wasserstein &#36317;&#31163;&#19978;&#30340;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#20174;&#20013;&#21487;&#20197;&#33719;&#24471;&#37325;&#24314;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient Langevin dynamics (SGLD) are a useful methodology for sampling from probability distributions. This paper provides a finite sample analysis of a passive stochastic gradient Langevin dynamics algorithm (PSGLD) designed to achieve inverse reinforcement learning. By "passive", we mean that the noisy gradients available to the PSGLD algorithm (inverse learning process) are evaluated at randomly chosen points by an external stochastic gradient algorithm (forward learner). The PSGLD algorithm thus acts as a randomized sampler which recovers the cost function being optimized by this external process. Previous work has analyzed the asymptotic performance of this passive algorithm using stochastic approximation techniques; in this work we analyze the non-asymptotic performance. Specifically, we provide finite-time bounds on the 2-Wasserstein distance between the passive algorithm and its stationary measure, from which the reconstructed cost function is obtained.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23500;&#25991;&#26412;&#32534;&#36753;&#22120;&#29983;&#25104;&#34920;&#36798;&#24615;&#25991;&#26412;&#22270;&#20687;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#23616;&#37096;&#26679;&#24335;&#25511;&#21046;&#12289;&#26126;&#30830;&#30340;&#26631;&#35760;&#37325;&#26032;&#21152;&#26435;&#12289;&#31934;&#30830;&#30340;&#39068;&#33394;&#28210;&#26579;&#21644;&#35814;&#32454;&#30340;&#21306;&#22495;&#21512;&#25104;&#65292;&#29983;&#25104;&#39640;&#36136;&#37327;&#19988;&#22810;&#26679;&#21270;&#30340;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2304.06720</link><description>&lt;p&gt;
&#23500;&#25991;&#26412;&#29983;&#25104;&#34920;&#36798;&#24615;&#25991;&#26412;&#22270;&#20687;
&lt;/p&gt;
&lt;p&gt;
Expressive Text-to-Image Generation with Rich Text. (arXiv:2304.06720v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23500;&#25991;&#26412;&#32534;&#36753;&#22120;&#29983;&#25104;&#34920;&#36798;&#24615;&#25991;&#26412;&#22270;&#20687;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#23616;&#37096;&#26679;&#24335;&#25511;&#21046;&#12289;&#26126;&#30830;&#30340;&#26631;&#35760;&#37325;&#26032;&#21152;&#26435;&#12289;&#31934;&#30830;&#30340;&#39068;&#33394;&#28210;&#26579;&#21644;&#35814;&#32454;&#30340;&#21306;&#22495;&#21512;&#25104;&#65292;&#29983;&#25104;&#39640;&#36136;&#37327;&#19988;&#22810;&#26679;&#21270;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32431;&#25991;&#26412;&#24050;&#32463;&#25104;&#20026;&#25991;&#23383;&#21040;&#22270;&#20687;&#21512;&#25104;&#30340;&#27969;&#34892;&#30028;&#38754;&#12290;&#20294;&#26159;&#65292;&#23427;&#30340;&#23450;&#21046;&#36873;&#39033;&#26377;&#38480;&#65292;&#38459;&#30861;&#20102;&#29992;&#25143;&#31934;&#30830;&#25551;&#36848;&#25152;&#38656;&#30340;&#36755;&#20986;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#25903;&#25345;&#23383;&#20307;&#26679;&#24335;&#12289;&#22823;&#23567;&#12289;&#39068;&#33394;&#21644;&#33050;&#27880;&#31561;&#26684;&#24335;&#30340;&#23500;&#25991;&#26412;&#32534;&#36753;&#22120;&#12290;&#25105;&#20204;&#20174;&#23500;&#25991;&#26412;&#20013;&#25552;&#21462;&#27599;&#20010;&#23383;&#30340;&#23646;&#24615;&#65292;&#20197;&#21551;&#29992;&#23616;&#37096;&#26679;&#24335;&#25511;&#21046;&#12289;&#26126;&#30830;&#30340;&#26631;&#35760;&#37325;&#26032;&#21152;&#26435;&#12289;&#31934;&#30830;&#30340;&#39068;&#33394;&#28210;&#26579;&#21644;&#35814;&#32454;&#30340;&#21306;&#22495;&#21512;&#25104;&#12290;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#30340;&#25193;&#25955;&#36807;&#31243;&#23454;&#29616;&#20102;&#36825;&#20123;&#21151;&#33021;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#27604;&#29616;&#26377;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#26041;&#27861;&#26356;&#22909;&#22320;&#29983;&#25104;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#21270;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Plain text has become a prevalent interface for text-to-image synthesis. However, its limited customization options hinder users from accurately describing desired outputs. For example, plain text makes it hard to specify continuous quantities, such as the precise RGB color value or importance of each word. Furthermore, creating detailed text prompts for complex scenes is tedious for humans to write and challenging for text encoders to interpret. To address these challenges, we propose using a rich-text editor supporting formats such as font style, size, color, and footnote. We extract each word's attributes from rich text to enable local style control, explicit token reweighting, precise color rendering, and detailed region synthesis. We achieve these capabilities through a region-based diffusion process. We first obtain each word's region based on cross-attention maps of a vanilla diffusion process using plain text. For each region, we enforce its text attributes by creating region-s
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25581;&#31034;&#20197;&#21450;&#25552;&#20986;&#20102;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#24040;&#22823;&#27700;&#36275;&#36857;&#30340;&#26041;&#27861;&#65292;&#22240;&#20026;&#20854;&#28129;&#27700;&#28040;&#32791;&#24050;&#32463;&#24341;&#36215;&#22269;&#38469;&#31038;&#20250;&#30340;&#37325;&#35270;&#65292;&#24182;&#19988;AI&#27169;&#22411;&#24212;&#35813;&#25215;&#25285;&#31038;&#20250;&#36131;&#20219;&#65292;&#20570;&#20986;&#38754;&#23545;&#27700;&#21361;&#26426;&#30340;&#34920;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.03271</link><description>&lt;p&gt;
&#20351;AI&#8220;&#21475;&#28212;&#8221;&#20943;&#23569;&#30340;&#26041;&#27861;&#65306;&#25581;&#31034;&#21644;&#35299;&#20915;AI&#27169;&#22411;&#30340;&#31192;&#23494;&#27700;&#28040;&#32791;
&lt;/p&gt;
&lt;p&gt;
Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models. (arXiv:2304.03271v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03271
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25581;&#31034;&#20197;&#21450;&#25552;&#20986;&#20102;&#35299;&#20915;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#24040;&#22823;&#27700;&#36275;&#36857;&#30340;&#26041;&#27861;&#65292;&#22240;&#20026;&#20854;&#28129;&#27700;&#28040;&#32791;&#24050;&#32463;&#24341;&#36215;&#22269;&#38469;&#31038;&#20250;&#30340;&#37325;&#35270;&#65292;&#24182;&#19988;AI&#27169;&#22411;&#24212;&#35813;&#25215;&#25285;&#31038;&#20250;&#36131;&#20219;&#65292;&#20570;&#20986;&#38754;&#23545;&#27700;&#21361;&#26426;&#30340;&#34920;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#27169;&#22411;&#30340;&#30899;&#36275;&#36857;&#19981;&#26029;&#22686;&#38271;&#65292;&#29305;&#21035;&#26159;&#20687;GPT-3&#21644;GPT-4&#36825;&#26679;&#30340;&#22823;&#22411;&#27169;&#22411;&#65292;&#24050;&#32463;&#21463;&#21040;&#20844;&#20247;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#21516;&#31561;&#37325;&#35201;&#19988;&#24040;&#22823;&#30340;AI&#27169;&#22411;&#27700;&#21360;&#23578;&#26410;&#24341;&#36215;&#20154;&#20204;&#30340;&#27880;&#24847;&#12290;&#20363;&#22914;&#65292;&#22312;&#24494;&#36719;&#26368;&#20808;&#36827;&#30340;&#32654;&#22269;&#25968;&#25454;&#20013;&#24515;&#20013;&#35757;&#32451;GPT-3&#21487;&#20197;&#30452;&#25509;&#28040;&#32791;70&#19975;&#21319;&#28165;&#27905;&#28129;&#27700;&#65288;&#30456;&#24403;&#20110;&#29983;&#20135;370&#36742;&#23453;&#39532;&#27773;&#36710;&#25110;320&#36742;&#29305;&#26031;&#25289;&#30005;&#21160;&#27773;&#36710;&#65289;&#65292;&#22914;&#26524;&#22312;&#24494;&#36719;&#30340;&#20122;&#27954;&#25968;&#25454;&#20013;&#24515;&#36827;&#34892;&#35757;&#32451;&#65292;&#36825;&#20010;&#27700;&#28040;&#32791;&#37327;&#23558;&#22686;&#21152;&#19977;&#20493;&#65292;&#20294;&#36825;&#26679;&#30340;&#20449;&#24687;&#19968;&#30452;&#34987;&#20445;&#23494;&#12290;&#36825;&#26497;&#20854;&#20196;&#20154;&#25285;&#24551;&#65292;&#22240;&#20026;&#28129;&#27700;&#30701;&#32570;&#24050;&#25104;&#20026;&#22312;&#20154;&#21475;&#36805;&#36895;&#22686;&#38271;&#12289;&#27700;&#36164;&#28304;&#20943;&#23569;&#21644;&#32769;&#21270;&#30340;&#27700;&#22522;&#30784;&#35774;&#26045;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25152;&#26377;&#20154;&#38754;&#20020;&#30340;&#26368;&#32039;&#36843;&#30340;&#25361;&#25112;&#20043;&#19968;&#12290;&#20026;&#20102;&#24212;&#23545;&#20840;&#29699;&#27700;&#36164;&#28304;&#30340;&#25361;&#25112;&#65292;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#21487;&#20197;&#65292;&#32780;&#19988;&#24212;&#35813;&#65292;&#25215;&#25285;&#31038;&#20250;&#36131;&#20219;&#65292;&#20197;&#36523;&#20316;&#21017;&#35299;&#20915;&#33258;&#24049;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The growing carbon footprint of artificial intelligence (AI) models, especially large ones such as GPT-3 and GPT-4, has been undergoing public scrutiny. Unfortunately, however, the equally important and enormous water footprint of AI models has remained under the radar. For example, training GPT-3 in Microsoft's state-of-the-art U.S. data centers can directly consume 700,000 liters of clean freshwater (enough for producing 370 BMW cars or 320 Tesla electric vehicles) and the water consumption would have been tripled if training were done in Microsoft's Asian data centers, but such information has been kept as a secret. This is extremely concerning, as freshwater scarcity has become one of the most pressing challenges shared by all of us in the wake of the rapidly growing population, depleting water resources, and aging water infrastructures. To respond to the global water challenges, AI models can, and also should, take social responsibility and lead by example by addressing their own 
&lt;/p&gt;</description></item></channel></rss>