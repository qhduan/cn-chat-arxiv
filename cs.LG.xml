<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25932;&#23545;&#36755;&#20837;&#25200;&#21160;&#30340;&#25935;&#24863;&#24615;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#23450;&#20041;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#25932;&#23545;&#25915;&#20987;&#26041;&#27861;&#21644;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2404.01356</link><description>&lt;p&gt;
&#36755;&#20837;&#25200;&#21160;&#23545;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#30340;&#21452;&#20995;&#21073;
&lt;/p&gt;
&lt;p&gt;
The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01356
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25932;&#23545;&#36755;&#20837;&#25200;&#21160;&#30340;&#25935;&#24863;&#24615;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#23450;&#20041;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#25932;&#23545;&#25915;&#20987;&#26041;&#27861;&#21644;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#34987;&#35748;&#20026;&#23545;&#25932;&#23545;&#36755;&#20837;&#25200;&#21160;&#25935;&#24863;&#65292;&#23548;&#33268;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#25110;&#20010;&#20307;&#20844;&#24179;&#24615;&#38477;&#20302;&#12290;&#20026;&#20102;&#20849;&#21516;&#34920;&#24449;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#20010;&#20307;&#20844;&#24179;&#24615;&#23545;&#25932;&#23545;&#25200;&#21160;&#30340;&#25935;&#24863;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#30340;&#26032;&#23450;&#20041;&#12290;&#40065;&#26834;&#20934;&#30830;&#20844;&#24179;&#24615;&#35201;&#27714;&#24403;&#23454;&#20363;&#21450;&#20854;&#30456;&#20284;&#23545;&#24212;&#29289;&#21463;&#21040;&#36755;&#20837;&#25200;&#21160;&#26102;&#65292;&#39044;&#27979;&#19982;&#22320;&#38754;&#20107;&#23454;&#19968;&#33268;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#25932;&#23545;&#25915;&#20987;&#26041;&#27861;RAFair&#65292;&#20197;&#26292;&#38706;DNN&#20013;&#30340;&#34394;&#20551;&#25110;&#20559;&#35265;&#25932;&#23545;&#32570;&#38519;&#65292;&#36825;&#20123;&#32570;&#38519;&#20250;&#27450;&#39575;&#20934;&#30830;&#24615;&#25110;&#25439;&#23475;&#20010;&#20307;&#20844;&#24179;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#36825;&#26679;&#30340;&#25932;&#23545;&#23454;&#20363;&#21487;&#20197;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#33391;&#24615;&#25200;&#21160;&#26377;&#25928;&#22320;&#35299;&#20915;&#65292;&#20174;&#32780;&#20351;&#23427;&#20204;&#30340;&#39044;&#27979;&#20934;&#30830;&#32780;&#20844;&#24179;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25506;&#35752;&#20102;&#36755;&#20837;&#23545;&#20934;&#30830;&#20844;&#24179;&#24615;&#30340;&#21452;&#20995;&#21073;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01356v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) are known to be sensitive to adversarial input perturbations, leading to a reduction in either prediction accuracy or individual fairness. To jointly characterize the susceptibility of prediction accuracy and individual fairness to adversarial perturbations, we introduce a novel robustness definition termed robust accurate fairness. Informally, robust accurate fairness requires that predictions for an instance and its similar counterparts consistently align with the ground truth when subjected to input perturbations. We propose an adversarial attack approach dubbed RAFair to expose false or biased adversarial defects in DNN, which either deceive accuracy or compromise individual fairness. Then, we show that such adversarial instances can be effectively addressed by carefully designed benign perturbations, correcting their predictions to be accurate and fair. Our work explores the double-edged sword of input 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#31181;&#29305;&#24449;&#21644;&#27880;&#24847;&#26426;&#21046;&#26469;&#20272;&#35745;&#22768;&#28304;&#30340;&#20301;&#32622;&#21644;&#31867;&#21035;&#65292;&#21253;&#25324;&#24341;&#20837;"&#22768;&#38899;&#22320;&#22270;"&#29305;&#24449;&#12289;&#20351;&#29992;Gammatone&#28388;&#27874;&#22120;&#29983;&#25104;&#26356;&#36866;&#21512;&#23460;&#22806;&#29615;&#22659;&#30340;&#22768;&#23398;&#29305;&#24449;&#65292;&#20197;&#21450;&#38598;&#25104;&#27880;&#24847;&#26426;&#21046;&#26469;&#23398;&#20064;&#36890;&#36947;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.20130</link><description>&lt;p&gt;
&#22312;&#23460;&#22806;&#29615;&#22659;&#20013;&#20351;&#29992;WASN&#36827;&#34892;&#22768;&#20107;&#20214;&#23450;&#20301;&#21644;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Sound event localization and classification using WASN in Outdoor Environment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20130
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#31181;&#29305;&#24449;&#21644;&#27880;&#24847;&#26426;&#21046;&#26469;&#20272;&#35745;&#22768;&#28304;&#30340;&#20301;&#32622;&#21644;&#31867;&#21035;&#65292;&#21253;&#25324;&#24341;&#20837;"&#22768;&#38899;&#22320;&#22270;"&#29305;&#24449;&#12289;&#20351;&#29992;Gammatone&#28388;&#27874;&#22120;&#29983;&#25104;&#26356;&#36866;&#21512;&#23460;&#22806;&#29615;&#22659;&#30340;&#22768;&#23398;&#29305;&#24449;&#65292;&#20197;&#21450;&#38598;&#25104;&#27880;&#24847;&#26426;&#21046;&#26469;&#23398;&#20064;&#36890;&#36947;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22768;&#20107;&#20214;&#23450;&#20301;&#21644;&#20998;&#31867;&#26159;&#26080;&#32447;&#22768;&#23398;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#30340;&#26032;&#20852;&#30740;&#31350;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#22768;&#20107;&#20214;&#23450;&#20301;&#21644;&#20998;&#31867;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#21333;&#20010;&#40614;&#20811;&#39118;&#38453;&#21015;&#65292;&#23481;&#26131;&#21463;&#21040;&#20449;&#21495;&#34928;&#20943;&#21644;&#29615;&#22659;&#22122;&#38899;&#30340;&#24433;&#21709;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#30417;&#27979;&#33539;&#22260;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#22810;&#20010;&#40614;&#20811;&#39118;&#38453;&#21015;&#30340;&#26041;&#27861;&#36890;&#24120;&#21482;&#20851;&#27880;&#28304;&#23450;&#20301;&#65292;&#24573;&#30053;&#20102;&#22768;&#20107;&#20214;&#20998;&#31867;&#26041;&#38754;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#31181;&#29305;&#24449;&#21644;&#27880;&#24847;&#26426;&#21046;&#26469;&#20272;&#35745;&#22768;&#28304;&#30340;&#20301;&#32622;&#21644;&#31867;&#21035;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;"&#22768;&#38899;&#22320;&#22270;"&#29305;&#24449;&#65292;&#20197;&#25429;&#33719;&#22810;&#20010;&#39057;&#27573;&#30340;&#31354;&#38388;&#20449;&#24687;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;Gammatone&#28388;&#27874;&#22120;&#29983;&#25104;&#26356;&#36866;&#21512;&#23460;&#22806;&#29615;&#22659;&#30340;&#22768;&#23398;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38598;&#25104;&#20102;&#27880;&#24847;&#26426;&#21046;&#26469;&#23398;&#20064;&#36890;&#36947;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20130v1 Announce Type: cross  Abstract: Deep learning-based sound event localization and classification is an emerging research area within wireless acoustic sensor networks. However, current methods for sound event localization and classification typically rely on a single microphone array, making them susceptible to signal attenuation and environmental noise, which limits their monitoring range. Moreover, methods using multiple microphone arrays often focus solely on source localization, neglecting the aspect of sound event classification. In this paper, we propose a deep learning-based method that employs multiple features and attention mechanisms to estimate the location and class of sound source. We introduce a Soundmap feature to capture spatial information across multiple frequency bands. We also use the Gammatone filter to generate acoustic features more suitable for outdoor environments. Furthermore, we integrate attention mechanisms to learn channel-wise relationsh
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#37096;&#20998;&#22312;&#32447;&#29366;&#24577;&#20449;&#24687;&#30340;POMDP&#38382;&#39064;&#30340;&#29702;&#35770;&#22256;&#38590;&#24615;&#21644;&#21487;&#35745;&#31639;&#24615;&#12290;&#20316;&#32773;&#36890;&#36807;&#24314;&#31435;&#19979;&#30028;&#24471;&#20986;&#19968;&#20010;&#24778;&#20154;&#30340;&#38590;&#24230;&#32467;&#26524;&#65306;&#38500;&#38750;&#20855;&#26377;&#23436;&#25972;&#30340;&#22312;&#32447;&#29366;&#24577;&#20449;&#24687;&#65292;&#21542;&#21017;&#38656;&#35201;&#25351;&#25968;&#32423;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25165;&#33021;&#24471;&#21040;POMDP&#30340;&#26368;&#20248;&#31574;&#30053;&#35299;&#12290;&#28982;&#32780;&#65292;&#20316;&#32773;&#36824;&#21457;&#29616;&#20102;&#20855;&#26377;&#37096;&#20998;&#22312;&#32447;&#29366;&#24577;&#20449;&#24687;&#19979;&#30340;&#21487;&#35745;&#31639;POMDP&#31867;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#26469;&#35777;&#26126;&#20854;&#25509;&#36817;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.08762</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#37096;&#20998;&#22312;&#32447;&#29366;&#24577;&#20449;&#24687;&#30340;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;POMDP&#30340;&#29702;&#35770;&#38590;&#24230;&#21644;&#21487;&#35745;&#31639;&#24615;
&lt;/p&gt;
&lt;p&gt;
Theoretical Hardness and Tractability of POMDPs in RL with Partial Online State Information. (arXiv:2306.08762v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#37096;&#20998;&#22312;&#32447;&#29366;&#24577;&#20449;&#24687;&#30340;POMDP&#38382;&#39064;&#30340;&#29702;&#35770;&#22256;&#38590;&#24615;&#21644;&#21487;&#35745;&#31639;&#24615;&#12290;&#20316;&#32773;&#36890;&#36807;&#24314;&#31435;&#19979;&#30028;&#24471;&#20986;&#19968;&#20010;&#24778;&#20154;&#30340;&#38590;&#24230;&#32467;&#26524;&#65306;&#38500;&#38750;&#20855;&#26377;&#23436;&#25972;&#30340;&#22312;&#32447;&#29366;&#24577;&#20449;&#24687;&#65292;&#21542;&#21017;&#38656;&#35201;&#25351;&#25968;&#32423;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25165;&#33021;&#24471;&#21040;POMDP&#30340;&#26368;&#20248;&#31574;&#30053;&#35299;&#12290;&#28982;&#32780;&#65292;&#20316;&#32773;&#36824;&#21457;&#29616;&#20102;&#20855;&#26377;&#37096;&#20998;&#22312;&#32447;&#29366;&#24577;&#20449;&#24687;&#19979;&#30340;&#21487;&#35745;&#31639;POMDP&#31867;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#26469;&#35777;&#26126;&#20854;&#25509;&#36817;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37096;&#20998;&#21487;&#35266;&#23519;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25429;&#25417;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29702;&#35770;&#32467;&#26524;&#24050;&#32463;&#34920;&#26126;&#65292;&#22312;&#19968;&#33324;&#30340;POMDP&#20013;&#23398;&#20064;&#21487;&#33021;&#26159;&#19981;&#21487;&#35745;&#31639;&#30340;&#65292;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#32570;&#20047;&#28508;&#22312;&#30340;&#29366;&#24577;&#20449;&#24687;&#12290;&#19968;&#20010;&#20851;&#38190;&#30340;&#22522;&#26412;&#38382;&#39064;&#26159;&#26377;&#22810;&#23569;&#22312;&#32447;&#29366;&#24577;&#20449;&#24687;&#65288;OSI&#65289;&#36275;&#20197;&#23454;&#29616;&#21487;&#35745;&#31639;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#25581;&#31034;&#20102;&#19968;&#20010;&#24778;&#20154;&#30340;&#38590;&#24230;&#32467;&#26524;&#65306;&#38500;&#38750;&#25105;&#20204;&#20855;&#26377;&#23436;&#25972;&#30340;OSI&#65292;&#21542;&#21017;&#25105;&#20204;&#38656;&#35201;&#25351;&#25968;&#32423;&#30340;&#37319;&#26679;&#22797;&#26434;&#24230;&#25165;&#33021;&#33719;&#24471;POMDP&#30340;$\epsilon$-&#26368;&#20248;&#31574;&#30053;&#35299;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#21463;&#21040;&#25105;&#20204;&#19979;&#30028;&#35774;&#35745;&#30340;&#20851;&#38190;&#35265;&#35299;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#21457;&#29616;&#21363;&#20351;&#21482;&#26377;&#37096;&#20998;OSI&#65292;&#20063;&#23384;&#22312;&#37325;&#35201;&#30340;&#21487;&#35745;&#31639;&#30340;POMDP&#31867;&#21035;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#20855;&#26377;&#37096;&#20998;OSI&#30340;&#20004;&#20010;&#26032;&#39062;&#30340;POMDP&#31867;&#21035;&#65292;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#26032;&#30340;&#36951;&#25022;&#19978;&#19979;&#30028;&#35777;&#26126;&#20102;&#26032;&#30340;&#31639;&#27861;&#26159;&#25509;&#36817;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partially observable Markov decision processes (POMDPs) have been widely applied to capture many real-world applications. However, existing theoretical results have shown that learning in general POMDPs could be intractable, where the main challenge lies in the lack of latent state information. A key fundamental question here is how much online state information (OSI) is sufficient to achieve tractability. In this paper, we establish a lower bound that reveals a surprising hardness result: unless we have full OSI, we need an exponentially scaling sample complexity to obtain an $\epsilon$-optimal policy solution for POMDPs. Nonetheless, inspired by the key insights in our lower bound design, we find that there exist important tractable classes of POMDPs even with only partial OSI. In particular, for two novel classes of POMDPs with partial OSI, we provide new algorithms that are proved to be near-optimal by establishing new regret upper and lower bounds.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#38024;&#23545;&#20855;&#26377; Kronecker &#32467;&#26500;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#24322;&#27493;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#23436;&#25104;&#27599;&#27425;&#36845;&#20195;&#12290;</title><link>http://arxiv.org/abs/2305.08001</link><description>&lt;p&gt;
&#20855;&#26377;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#39640;&#25928;&#24322;&#27493;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Asynchronize Stochastic Gradient Algorithm with Structured Data. (arXiv:2305.08001v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#20855;&#26377; Kronecker &#32467;&#26500;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#24322;&#27493;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#23436;&#25104;&#27599;&#27425;&#36845;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22240;&#20854;&#33391;&#22909;&#30340;&#27867;&#21270;&#32780;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;&#24555;&#36895;&#35757;&#32451;&#20855;&#26377;&#22823;&#37327;&#23618;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#19968;&#30452;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#21033;&#29992;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#25216;&#26415;&#25110;&#26576;&#20123;&#25968;&#25454;&#32467;&#26500;&#30340;&#31354;&#38388;&#21010;&#20998;&#26469;&#20943;&#36731;&#27599;&#27425;&#36845;&#20195;&#30340;&#35757;&#32451;&#25104;&#26412;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23581;&#35797;&#20174;&#36755;&#20837;&#25968;&#25454;&#28857;&#30340;&#35282;&#24230;&#21152;&#36895;&#27599;&#27425;&#36845;&#20195;&#20013;&#30340;&#35745;&#31639;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#38024;&#23545;&#19968;&#20010;&#20004;&#23618;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#24403;&#35757;&#32451;&#25968;&#25454;&#20855;&#26377;&#19968;&#20123;&#29305;&#27530;&#23646;&#24615;&#65292;&#20363;&#22914; Kronecker &#32467;&#26500;&#26102;&#65292;&#27599;&#27425;&#36845;&#20195;&#21487;&#20197;&#22312;&#25968;&#25454;&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#23436;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has achieved impressive success in a variety of fields because of its good generalization. However, it has been a challenging problem to quickly train a neural network with a large number of layers. The existing works utilize the locality-sensitive hashing technique or some data structures on space partitioning to alleviate the training cost in each iteration. In this work, we try accelerating the computations in each iteration from the perspective of input data points. Specifically, for a two-layer fully connected neural network, when the training data have some special properties, e.g., Kronecker structure, each iteration can be completed in sublinear time in the data dimension.
&lt;/p&gt;</description></item><item><title>GFlowNets&#26159;&#19968;&#31181;&#29983;&#25104;&#27969;&#32593;&#32476;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#12290;&#23427;&#20204;&#20855;&#26377;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#36793;&#38469;&#20998;&#24067;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#65292;GFlowNets&#20998;&#25674;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#30340;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2111.09266</link><description>&lt;p&gt;
GFlowNet&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
GFlowNet Foundations. (arXiv:2111.09266v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.09266
&lt;/p&gt;
&lt;p&gt;
GFlowNets&#26159;&#19968;&#31181;&#29983;&#25104;&#27969;&#32593;&#32476;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#12290;&#23427;&#20204;&#20855;&#26377;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#36793;&#38469;&#20998;&#24067;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#65292;GFlowNets&#20998;&#25674;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#34987;&#24341;&#20837;&#20026;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#30340;&#26041;&#27861;&#65292;&#20854;&#35757;&#32451;&#30446;&#26631;&#20351;&#20854;&#36817;&#20284;&#25353;&#29031;&#32473;&#23450;&#30340;&#22870;&#21169;&#20989;&#25968;&#36827;&#34892;&#37319;&#26679;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;GFlowNets&#30340;&#19968;&#20123;&#39069;&#22806;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#23427;&#20204;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#30456;&#24212;&#30340;&#36793;&#38469;&#20998;&#24067;&#65292;&#20854;&#20013;&#19968;&#20123;&#21464;&#37327;&#26410;&#25351;&#23450;&#65292;&#29305;&#21035;&#26159;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;GFlowNets&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#26469;&#20998;&#25674;&#36890;&#24120;&#30001;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#23436;&#25104;&#30340;&#24037;&#20316;&#12290;&#23427;&#20204;&#36824;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#20998;&#21306;&#20989;&#25968;&#21644;&#33258;&#30001;&#33021;&#65292;&#32473;&#23450;&#19968;&#20010;&#23376;&#38598;&#65288;&#23376;&#22270;&#65289;&#30340;&#36229;&#38598;&#65288;&#36229;&#22270;&#65289;&#30340;&#26465;&#20214;&#27010;&#29575;&#65292;&#20197;&#21450;&#32473;&#23450;&#19968;&#20010;&#38598;&#21512;&#65288;&#22270;&#65289;&#30340;&#25152;&#26377;&#36229;&#38598;&#65288;&#36229;&#22270;&#65289;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20123;&#21464;&#20307;&#65292;&#20351;&#24471;&#21487;&#20197;&#20272;&#35745;&#29109;&#30340;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets. They can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entro
&lt;/p&gt;</description></item></channel></rss>