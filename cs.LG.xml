<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;</title><link>https://arxiv.org/abs/2403.05652</link><description>&lt;p&gt;
&#36825;&#37324;&#26159;&#32763;&#35793;&#36807;&#30340;&#35770;&#25991;&#26631;&#39064;
&lt;/p&gt;
&lt;p&gt;
What is different between these datasets?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05652
&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#32763;&#35793;&#36807;&#30340;&#35770;&#25991;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05652v1 Announce Type: cross  Abstract: The performance of machine learning models heavily depends on the quality of input data, yet real-world applications often encounter various data-related challenges. One such challenge could arise when curating training data or deploying the model in the real world - two comparable datasets in the same domain may have different distributions. While numerous techniques exist for detecting distribution shifts, the literature lacks comprehensive approaches for explaining dataset differences in a human-understandable manner. To address this gap, we propose a suite of interpretable methods (toolbox) for comparing two datasets. We demonstrate the versatility of our approach across diverse data modalities, including tabular data, language, images, and signals in both low and high-dimensional settings. Our methods not only outperform comparable and related approaches in terms of explanation quality and correctness, but also provide actionable,
&lt;/p&gt;</description></item><item><title>&#22312;&#26080;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DANSE&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#38750;&#32447;&#24615;&#29366;&#24577;&#20272;&#35745;&#26041;&#27861;&#65292;&#21033;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#25429;&#25417;&#27169;&#22411;&#26080;&#20851;&#36807;&#31243;&#20013;&#30340;&#28508;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#12290;</title><link>https://arxiv.org/abs/2306.03897</link><description>&lt;p&gt;
DANSE: &#26080;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#20013;&#27169;&#22411;&#26080;&#20851;&#36807;&#31243;&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#38750;&#32447;&#24615;&#29366;&#24577;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
DANSE: Data-driven Non-linear State Estimation of Model-free Process in Unsupervised Learning Setup
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2306.03897
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DANSE&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#38750;&#32447;&#24615;&#29366;&#24577;&#20272;&#35745;&#26041;&#27861;&#65292;&#21033;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#25429;&#25417;&#27169;&#22411;&#26080;&#20851;&#36807;&#31243;&#20013;&#30340;&#28508;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#26080;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#20013;&#38024;&#23545;&#27169;&#22411;&#26080;&#20851;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#29366;&#24577;&#20272;&#35745;&#21644;&#39044;&#27979;&#20219;&#21153;&#12290;&#23545;&#20110;&#27169;&#22411;&#26080;&#20851;&#36807;&#31243;&#65292;&#25105;&#20204;&#27809;&#26377;&#20219;&#20309;&#20851;&#20110;&#36807;&#31243;&#21160;&#24577;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#22312;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DANSE&#8212;&#8212;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#38750;&#32447;&#24615;&#29366;&#24577;&#20272;&#35745;&#26041;&#27861;&#12290;DANSE&#25552;&#20379;&#20102;&#32473;&#23450;&#29366;&#24577;&#30340;&#32447;&#24615;&#27979;&#37327;&#30340;&#23553;&#38381;&#24418;&#24335;&#21518;&#39564;&#27010;&#29575;&#12290;&#27492;&#22806;&#65292;&#23427;&#36824;&#25552;&#20379;&#20102;&#39044;&#27979;&#30340;&#23553;&#38381;&#24418;&#24335;&#21518;&#39564;&#27010;&#29575;&#12290;DANSE&#20013;&#20351;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#26469;&#25552;&#20379;&#29366;&#24577;&#20808;&#39564;&#30340;&#21442;&#25968;&#12290;&#20808;&#39564;&#20381;&#36182;&#20110;&#36807;&#21435;&#30340;&#27979;&#37327;&#20316;&#20026;&#36755;&#20837;&#65292;&#28982;&#21518;&#20351;&#29992;&#24403;&#21069;&#27979;&#37327;&#20316;&#20026;&#36755;&#20837;&#25214;&#21040;&#29366;&#24577;&#30340;&#23553;&#38381;&#24418;&#24335;&#21518;&#39564;&#27010;&#29575;&#12290;&#25968;&#25454;&#39537;&#21160;&#30340;RNN&#25429;&#25417;&#27169;&#22411;&#26080;&#20851;&#36807;&#31243;&#30340;&#28508;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#12290;DANSE&#30340;&#35757;&#32451;&#65292;&#20027;&#35201;&#26159;&#23398;&#20064;RNN&#30340;&#21442;&#25968;&#65292;&#26159;&#20351;&#29992;&#26080;&#30417;&#30563;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2306.03897v2 Announce Type: replace-cross  Abstract: We address the tasks of Bayesian state estimation and forecasting for a model-free process in an unsupervised learning setup. For a model-free process, we do not have any a-priori knowledge of the process dynamics. In the article, we propose DANSE -- a Data-driven Nonlinear State Estimation method. DANSE provides a closed-form posterior of the state of the model-free process, given linear measurements of the state. In addition, it provides a closed-form posterior for forecasting. A data-driven recurrent neural network (RNN) is used in DANSE to provide the parameters of a prior of the state. The prior depends on the past measurements as input, and then we find the closed-form posterior of the state using the current measurement as input. The data-driven RNN captures the underlying non-linear dynamics of the model-free process. The training of DANSE, mainly learning the parameters of the RNN, is executed using an unsupervised lea
&lt;/p&gt;</description></item><item><title>&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20013;&#65292;&#24403;&#25968;&#25454;&#38598;&#30340;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#20302;&#26102;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;PT&#65289;&#32988;&#36807;&#27169;&#22411;&#26080;&#20851;&#20803;&#23398;&#20064;&#65288;MAML&#65289;&#12290;&#24403;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#39640;&#26102;&#65292;MAML&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2306.13841</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;&#30495;&#30340;&#27604;&#20803;&#23398;&#20064;&#26356;&#22909;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Pre-training Truly Better Than Meta-Learning?. (arXiv:2306.13841v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13841
&lt;/p&gt;
&lt;p&gt;
&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20013;&#65292;&#24403;&#25968;&#25454;&#38598;&#30340;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#20302;&#26102;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;PT&#65289;&#32988;&#36807;&#27169;&#22411;&#26080;&#20851;&#20803;&#23398;&#20064;&#65288;MAML&#65289;&#12290;&#24403;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#39640;&#26102;&#65292;MAML&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#32972;&#26223;&#19979;&#65292;&#30446;&#21069;&#26222;&#36941;&#35748;&#20026;&#22266;&#23450;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;PT&#65289;&#21152;&#19978;&#22312;&#35780;&#20215;&#26102;&#24494;&#35843;&#26368;&#21518;&#19968;&#23618;&#65292;&#32988;&#36807;&#26631;&#20934;&#30340;&#20803;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#28145;&#20837;&#30340;&#23454;&#35777;&#30740;&#31350;&#21644;&#24191;&#27867;&#30340;&#25968;&#25454;&#38598;&#27604;&#36739;PT&#21644;&#27169;&#22411;&#26080;&#20851;&#20803;&#23398;&#20064;&#65288;MAML&#65289;&#36825;&#20123;&#35828;&#27861;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#24378;&#35843;&#20351;&#29992;&#30456;&#21516;&#30340;&#20307;&#31995;&#32467;&#26500;&#12289;&#30456;&#21516;&#30340;&#20248;&#21270;&#22120;&#65292;&#20197;&#21450;&#25152;&#26377;&#27169;&#22411;&#37117;&#35757;&#32451;&#21040;&#25910;&#25947;&#12290;&#20851;&#38190;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#26356;&#20005;&#26684;&#30340;&#32479;&#35745;&#24037;&#20855;&#8212;&#8212;&#25928;&#24212;&#37327;&#65288;Cohen's d&#65289;&#8212;&#8212;&#26469;&#30830;&#23450;&#20351;&#29992;PT&#19982;&#20351;&#29992;MAML&#20043;&#38388;&#30340;&#27169;&#22411;&#24046;&#24322;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;&#28982;&#21518;&#20351;&#29992;&#19968;&#20010;&#39044;&#20808;&#25552;&#20986;&#30340;&#24230;&#37327;&#8212;&#8212;&#22810;&#26679;&#24615;&#31995;&#25968;&#8212;&#8212;&#26469;&#35745;&#31639;&#25968;&#25454;&#38598;&#30340;&#24179;&#22343;&#27491;&#24335;&#22810;&#26679;&#24615;&#12290;&#20351;&#29992;&#36825;&#31181;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20197;&#19979;&#20107;&#23454;&#65306;1. &#24403;&#25968;&#25454;&#38598;&#30340;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#20302;&#26102;&#65292;PT&#22312;&#24179;&#22343;&#24847;&#20041;&#19978;&#32988;&#36807;MAML&#65307;2. &#24403;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#39640;&#26102;&#65292;MAML&#32988;&#36807;PT&#12290;
&lt;/p&gt;
&lt;p&gt;
In the context of few-shot learning, it is currently believed that a fixed pre-trained (PT) model, along with fine-tuning the final layer during evaluation, outperforms standard meta-learning algorithms. We re-evaluate these claims under an in-depth empirical examination of an extensive set of formally diverse datasets and compare PT to Model Agnostic Meta-Learning (MAML). Unlike previous work, we emphasize a fair comparison by using: the same architecture, the same optimizer, and all models trained to convergence. Crucially, we use a more rigorous statistical tool -- the effect size (Cohen's d) -- to determine the practical significance of the difference between a model trained with PT vs. a MAML. We then use a previously proposed metric -- the diversity coefficient -- to compute the average formal diversity of a dataset. Using this analysis, we demonstrate the following: 1. when the formal diversity of a data set is low, PT beats MAML on average and 2. when the formal diversity is hi
&lt;/p&gt;</description></item><item><title>Packed-Ensembles&#26159;&#19968;&#31181;&#33021;&#22815;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#20869;&#36816;&#34892;&#30340;&#36731;&#37327;&#32423;&#32467;&#26500;&#21270;&#38598;&#21512;&#65292;&#23427;&#36890;&#36807;&#31934;&#24515;&#35843;&#33410;&#32534;&#30721;&#31354;&#38388;&#30340;&#32500;&#24230;&#26469;&#35774;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#19981;&#25439;&#22833;&#25928;&#26524;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2210.09184</link><description>&lt;p&gt;
&#32039;&#20945;&#38598;&#25104;&#29992;&#20110;&#39640;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Packed-Ensembles for Efficient Uncertainty Estimation. (arXiv:2210.09184v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09184
&lt;/p&gt;
&lt;p&gt;
Packed-Ensembles&#26159;&#19968;&#31181;&#33021;&#22815;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#20869;&#36816;&#34892;&#30340;&#36731;&#37327;&#32423;&#32467;&#26500;&#21270;&#38598;&#21512;&#65292;&#23427;&#36890;&#36807;&#31934;&#24515;&#35843;&#33410;&#32534;&#30721;&#31354;&#38388;&#30340;&#32500;&#24230;&#26469;&#35774;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#19981;&#25439;&#22833;&#25928;&#26524;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#38598;&#25104;&#26159;&#23454;&#29616;&#20851;&#38190;&#25351;&#26631;&#65288;&#22914;&#20934;&#30830;&#24615;&#12289;&#26657;&#20934;&#12289;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#65289;&#21331;&#36234;&#24615;&#33021;&#30340;&#31361;&#20986;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#29616;&#23454;&#31995;&#32479;&#30340;&#30828;&#20214;&#38480;&#21046;&#38480;&#21046;&#20102;&#26356;&#23567;&#30340;&#38598;&#21512;&#21644;&#36739;&#20302;&#23481;&#37327;&#30340;&#32593;&#32476;&#65292;&#20005;&#37325;&#25439;&#23475;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#21644;&#23646;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Packed-Ensembles&#65288;PE&#65289;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#31934;&#24515;&#35843;&#33410;&#20854;&#32534;&#30721;&#31354;&#38388;&#30340;&#32500;&#24230;&#26469;&#35774;&#35745;&#21644;&#35757;&#32451;&#36731;&#37327;&#32423;&#32467;&#26500;&#21270;&#38598;&#21512;&#12290;&#25105;&#20204;&#21033;&#29992;&#32452;&#21367;&#31215;&#23558;&#38598;&#21512;&#24182;&#34892;&#21270;&#20026;&#21333;&#20010;&#20849;&#20139;&#39592;&#24178;&#65292;&#24182;&#36827;&#34892;&#21069;&#21521;&#20256;&#36882;&#20197;&#25552;&#39640;&#35757;&#32451;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;PE&#26088;&#22312;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#23384;&#38480;&#21046;&#20869;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our c
&lt;/p&gt;</description></item></channel></rss>