<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#27010;&#29575;&#33258;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#65288;Prob-PSENN&#65289;&#65292;&#36890;&#36807;&#27010;&#29575;&#20998;&#24067;&#21462;&#20195;&#28857;&#20272;&#35745;&#65292;&#23454;&#29616;&#20102;&#26356;&#28789;&#27963;&#30340;&#21407;&#22411;&#23398;&#20064;&#65292;&#25552;&#20379;&#20102;&#23454;&#29992;&#30340;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2403.13740</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#33258;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#35748;&#30693;
&lt;/p&gt;
&lt;p&gt;
Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13740
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#27010;&#29575;&#33258;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#65288;Prob-PSENN&#65289;&#65292;&#36890;&#36807;&#27010;&#29575;&#20998;&#24067;&#21462;&#20195;&#28857;&#20272;&#35745;&#65292;&#23454;&#29616;&#20102;&#26356;&#28789;&#27963;&#30340;&#21407;&#22411;&#23398;&#20064;&#65292;&#25552;&#20379;&#20102;&#23454;&#29992;&#30340;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#36879;&#26126;&#24615;&#25345;&#32493;&#38480;&#21046;&#20854;&#21487;&#38752;&#24615;&#21644;&#22312;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#30340;&#20351;&#29992;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#27010;&#29575;&#33258;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#65288;Prob-PSENN&#65289;&#65292;&#37319;&#29992;&#27010;&#29575;&#20998;&#24067;&#20195;&#26367;&#21407;&#22411;&#30340;&#28857;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#21407;&#22411;&#31471;&#21040;&#31471;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13740v1 Announce Type: new  Abstract: The lack of transparency of Deep Neural Networks continues to be a limitation that severely undermines their reliability and usage in high-stakes applications. Promising approaches to overcome such limitations are Prototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions rely on the similarity between the input at hand and a set of prototypical representations of the output classes, offering therefore a deep, yet transparent-by-design, architecture. So far, such models have been designed by considering pointwise estimates for the prototypes, which remain fixed after the learning phase of the model. In this paper, we introduce a probabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point estimates for the prototypes with probability distributions over their values. This provides not only a more flexible framework for an end-to-end learning of prototypes, but can also capture the explanatory uncertaint
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#36824;&#27604;&#36739;&#20102;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#21644;&#20256;&#32479;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19982;&#27531;&#24046;&#36830;&#25509;&#30340;&#26550;&#26500;&#12290;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#20915;&#31574;&#26641;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#32780;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#22312;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#24182;&#27809;&#26377;&#36229;&#36807;&#20256;&#32479;MLP&#26550;&#26500;&#30340;&#31616;&#21270;&#21464;&#20307;&#12290;</title><link>https://arxiv.org/abs/2402.03970</link><description>&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#65306;&#27880;&#24847;&#21147;&#26159;&#21807;&#19968;&#38656;&#35201;&#30340;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Tabular Data: Is Attention All You Need?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#36824;&#27604;&#36739;&#20102;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#21644;&#20256;&#32479;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19982;&#27531;&#24046;&#36830;&#25509;&#30340;&#26550;&#26500;&#12290;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#20915;&#31574;&#26641;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#32780;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#22312;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#24182;&#27809;&#26377;&#36229;&#36807;&#20256;&#32479;MLP&#26550;&#26500;&#30340;&#31616;&#21270;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#24443;&#24213;&#25913;&#21464;&#20102;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#24182;&#22312;&#28041;&#21450;&#22270;&#20687;&#21644;&#25991;&#26412;&#25968;&#25454;&#30340;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#23601;&#12290;&#36951;&#25022;&#30340;&#26159;&#65292;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#22312;&#32467;&#26500;&#21270;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#20248;&#21183;&#23384;&#22312;&#30528;&#19981;&#19968;&#33268;&#30340;&#35777;&#25454;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#22312;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#65292;&#36824;&#27604;&#36739;&#20102;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#21644;&#20256;&#32479;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19982;&#27531;&#24046;&#36830;&#25509;&#30340;&#26550;&#26500;&#12290;&#19982;&#20043;&#21069;&#30340;&#30740;&#31350;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#23454;&#35777;&#21457;&#29616;&#34920;&#26126;&#31070;&#32463;&#32593;&#32476;&#22312;&#20915;&#31574;&#26641;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;&#22522;&#20110;Transformer&#30340;&#26550;&#26500;&#22312;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#24182;&#27809;&#26377;&#36229;&#36807;&#20256;&#32479;MLP&#26550;&#26500;&#30340;&#31616;&#21270;&#21464;&#20307;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#24110;&#21161;&#30740;&#31350;&#21644;&#23454;&#36341;&#31038;&#21306;&#22312;&#26410;&#26469;&#30340;&#34920;&#26684;&#25968;&#25454;&#24212;&#29992;&#20013;&#20570;&#20986;&#26126;&#26234;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning has revolutionized the field of AI and led to remarkable achievements in applications involving image and text data. Unfortunately, there is inconclusive evidence on the merits of neural networks for structured tabular data. In this paper, we introduce a large-scale empirical study comparing neural networks against gradient-boosted decision trees on tabular data, but also transformer-based architectures against traditional multi-layer perceptrons (MLP) with residual connections. In contrast to prior work, our empirical findings indicate that neural networks are competitive against decision trees. Furthermore, we assess that transformer-based architectures do not outperform simpler variants of traditional MLP architectures on tabular datasets. As a result, this paper helps the research and practitioner communities make informed choices on deploying neural networks on future tabular data applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#38160;&#24230;&#21160;&#21147;&#23398;&#65292;&#25581;&#31034;&#20986;&#26089;&#26399;&#38160;&#24230;&#38477;&#20302;&#12289;&#36880;&#28176;&#22686;&#21152;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#30028;&#30340;&#26426;&#21046;&#65292;&#24182;&#21457;&#29616;&#22686;&#22823;&#23398;&#20064;&#29575;&#26102;&#65292;&#31283;&#23450;&#36793;&#30028;&#27969;&#24418;&#19978;&#21457;&#29983;&#20493;&#22686;&#28151;&#27788;&#36335;&#24452;&#12290;</title><link>http://arxiv.org/abs/2311.02076</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#26222;&#36866;&#38160;&#24230;&#21160;&#21147;&#23398;&#65306;&#22266;&#23450;&#28857;&#20998;&#26512;&#12289;&#31283;&#23450;&#36793;&#30028;&#21644;&#28151;&#27788;&#36335;&#24452;
&lt;/p&gt;
&lt;p&gt;
Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos. (arXiv:2311.02076v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#38160;&#24230;&#21160;&#21147;&#23398;&#65292;&#25581;&#31034;&#20986;&#26089;&#26399;&#38160;&#24230;&#38477;&#20302;&#12289;&#36880;&#28176;&#22686;&#21152;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#30028;&#30340;&#26426;&#21046;&#65292;&#24182;&#21457;&#29616;&#22686;&#22823;&#23398;&#20064;&#29575;&#26102;&#65292;&#31283;&#23450;&#36793;&#30028;&#27969;&#24418;&#19978;&#21457;&#29983;&#20493;&#22686;&#28151;&#27788;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#21160;&#21147;&#23398;&#20013;&#65292;&#25439;&#22833;&#20989;&#25968;&#28023;&#26862;&#30697;&#38453;&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#65288;&#38160;&#24230;&#65289;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23637;&#31034;&#20986;&#21508;&#31181;&#31283;&#20581;&#30340;&#29616;&#35937;&#12290;&#36825;&#21253;&#25324;&#26089;&#26399;&#26102;&#38388;&#38454;&#27573;&#65292;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#38160;&#24230;&#21487;&#33021;&#20943;&#23567;&#65288;&#38477;&#20302;&#38160;&#24230;&#65289;&#65292;&#20197;&#21450;&#21518;&#26399;&#34892;&#20026;&#65292;&#22914;&#36880;&#28176;&#22686;&#21152;&#30340;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#30028;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;2&#23618;&#32447;&#24615;&#32593;&#32476;&#65288;UV&#27169;&#22411;&#65289;&#65292;&#22312;&#21333;&#20010;&#35757;&#32451;&#26679;&#26412;&#19978;&#35757;&#32451;&#65292;&#23637;&#31034;&#20102;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#35266;&#23519;&#21040;&#30340;&#25152;&#26377;&#20851;&#38190;&#38160;&#24230;&#29616;&#35937;&#12290;&#36890;&#36807;&#20998;&#26512;&#20989;&#25968;&#31354;&#38388;&#20013;&#21160;&#21147;&#23398;&#22266;&#23450;&#28857;&#30340;&#32467;&#26500;&#21644;&#20989;&#25968;&#26356;&#26032;&#30340;&#21521;&#37327;&#22330;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20123;&#38160;&#24230;&#36235;&#21183;&#32972;&#21518;&#30340;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#65306;(i)&#26089;&#26399;&#38160;&#24230;&#38477;&#20302;&#21644;&#36880;&#28176;&#22686;&#21152;&#38160;&#21270;&#30340;&#26426;&#21046;&#65292;(ii)&#31283;&#23450;&#36793;&#30028;&#25152;&#38656;&#30340;&#26465;&#20214;&#65292;&#20197;&#21450; (iii)&#24403;&#23398;&#20064;&#29575;&#22686;&#21152;&#26102;&#65292;&#31283;&#23450;&#36793;&#30028;&#27969;&#24418;&#19978;&#30340;&#20493;&#22686;&#28151;&#27788;&#36335;&#24452;.
&lt;/p&gt;
&lt;p&gt;
In gradient descent dynamics of neural networks, the top eigenvalue of the Hessian of the loss (sharpness) displays a variety of robust phenomena throughout training. This includes early time regimes where the sharpness may decrease during early periods of training (sharpness reduction), and later time behavior such as progressive sharpening and edge of stability. We demonstrate that a simple $2$-layer linear network (UV model) trained on a single training example exhibits all of the essential sharpness phenomenology observed in real-world scenarios. By analyzing the structure of dynamical fixed points in function space and the vector field of function updates, we uncover the underlying mechanisms behind these sharpness trends. Our analysis reveals (i) the mechanism behind early sharpness reduction and progressive sharpening, (ii) the required conditions for edge of stability, and (iii) a period-doubling route to chaos on the edge of stability manifold as learning rate is increased. Fi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#26816;&#27979;&#21040;&#39640;&#23494;&#24230;&#21306;&#22495;&#20013;&#30340;&#32467;&#26500;&#65292;&#20855;&#26377;&#20808;&#21069;&#31639;&#27861;&#25152;&#19981;&#20855;&#22791;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.00677</link><description>&lt;p&gt;
SDC-HSDD-NDSA: &#20351;&#29992;&#23618;&#27425;&#27425;&#32423;&#23548;&#21521;&#24046;&#24322;&#21644;&#24402;&#19968;&#21270;&#23494;&#24230;&#33258;&#36866;&#24212;&#30340;&#32467;&#26500;&#26816;&#27979;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption. (arXiv:2307.00677v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00677
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#26816;&#27979;&#21040;&#39640;&#23494;&#24230;&#21306;&#22495;&#20013;&#30340;&#32467;&#26500;&#65292;&#20855;&#26377;&#20808;&#21069;&#31639;&#27861;&#25152;&#19981;&#20855;&#22791;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#31639;&#27861;&#26159;&#26368;&#21463;&#27426;&#36814;&#30340;&#32858;&#31867;&#31639;&#27861;&#20043;&#19968;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#35782;&#21035;&#20219;&#24847;&#24418;&#29366;&#30340;&#32858;&#31867;&#65292;&#21482;&#35201;&#19981;&#21516;&#30340;&#39640;&#23494;&#24230;&#32858;&#31867;&#20043;&#38388;&#26377;&#20302;&#23494;&#24230;&#21306;&#22495;&#20998;&#38548;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#20302;&#23494;&#24230;&#21306;&#22495;&#23558;&#32858;&#31867;&#20998;&#38548;&#24320;&#30340;&#35201;&#27714;&#24182;&#19981;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#65292;&#22240;&#20026;&#39640;&#23494;&#24230;&#21306;&#22495;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#30340;&#32467;&#26500;&#65292;&#24212;&#35813;&#34987;&#32858;&#31867;&#21040;&#19981;&#21516;&#30340;&#32452;&#20013;&#12290;&#36825;&#31181;&#24773;&#20917;&#35828;&#26126;&#20102;&#25105;&#20204;&#24050;&#30693;&#30340;&#25152;&#26377;&#20808;&#21069;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#31639;&#27861;&#30340;&#20027;&#35201;&#32570;&#38519;--&#26080;&#27861;&#26816;&#27979;&#39640;&#23494;&#24230;&#32858;&#31867;&#20013;&#30340;&#32467;&#26500;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#26041;&#26696;&#65292;&#26082;&#20855;&#26377;&#20808;&#21069;&#26041;&#27861;&#30340;&#33021;&#21147;&#65292;&#21448;&#33021;&#22815;&#26816;&#27979;&#21040;&#39640;&#23494;&#24230;&#21306;&#22495;&#20013;&#26410;&#34987;&#20302;&#23494;&#24230;&#21306;&#20998;&#24320;&#30340;&#32467;&#26500;&#12290;&#35813;&#31639;&#27861;&#37319;&#29992;&#23618;&#27425;&#27425;&#32423;&#23548;&#21521;&#24046;&#24322;&#12289;&#23618;&#27425;&#21270;&#12289;&#24402;&#19968;&#21270;&#23494;&#24230;&#20197;&#21450;&#33258;&#36866;&#24212;&#31995;&#25968;&#65292;&#22240;&#27492;&#34987;&#31216;&#20026;&#32467;&#26500;&#26816;&#27979;&#32858;&#31867;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Density-based clustering could be the most popular clustering algorithm since it can identify clusters of arbitrary shape as long as different (high-density) clusters are separated by low-density regions. However, the requirement of the separateness of clusters by low-density regions is not trivial since a high-density region might have different structures which should be clustered into different groups. Such a situation demonstrates the main flaw of all previous density-based clustering algorithms we have known--structures in a high-density cluster could not be detected. Therefore, this paper aims to provide a density-based clustering scheme that not only has the ability previous ones have but could also detect structures in a high-density region not separated by low-density ones. The algorithm employs secondary directed differential, hierarchy, normalized density, as well as the self-adaption coefficient, and thus is called Structure Detecting Cluster by Hierarchical Secondary Direc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Task Aware Dreamer&#65288;TAD&#65289;&#30340;&#26041;&#27861;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#27867;&#21270;&#12290;&#36890;&#36807;&#37327;&#21270;&#20219;&#21153;&#20998;&#24067;&#30340;&#30456;&#20851;&#24615;&#65292;TAD&#33021;&#22815;&#23558;&#21382;&#21490;&#20449;&#24687;&#32534;&#30721;&#21040;&#31574;&#30053;&#20013;&#65292;&#20197;&#20415;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#65292;&#24182;&#22312;&#27867;&#21270;&#21040;&#26410;&#35265;&#20219;&#21153;&#26102;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.05092</link><description>&lt;p&gt;
Task Aware Dreamer&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Task Aware Dreamer for Task Generalization in Reinforcement Learning. (arXiv:2303.05092v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Task Aware Dreamer&#65288;TAD&#65289;&#30340;&#26041;&#27861;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#27867;&#21270;&#12290;&#36890;&#36807;&#37327;&#21270;&#20219;&#21153;&#20998;&#24067;&#30340;&#30456;&#20851;&#24615;&#65292;TAD&#33021;&#22815;&#23558;&#21382;&#21490;&#20449;&#24687;&#32534;&#30721;&#21040;&#31574;&#30053;&#20013;&#65292;&#20197;&#20415;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#65292;&#24182;&#22312;&#27867;&#21270;&#21040;&#26410;&#35265;&#20219;&#21153;&#26102;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#30340;&#19968;&#20010;&#38271;&#26399;&#30446;&#26631;&#26159;&#33719;&#24471;&#33021;&#22815;&#22312;&#35757;&#32451;&#20219;&#21153;&#19978;&#23398;&#20064;&#24182;&#19988;&#22312;&#19981;&#21516;&#22870;&#21169;&#20989;&#25968;&#19979;&#21487;&#20197;&#24456;&#22909;&#22320;&#27867;&#21270;&#21040;&#26410;&#35265;&#20219;&#21153;&#30340;&#20195;&#29702;&#12290;&#19968;&#20010;&#36890;&#29992;&#30340;&#25361;&#25112;&#26159;&#23450;&#37327;&#22320;&#34913;&#37327;&#36825;&#20123;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#36825;&#23545;&#20110;&#20998;&#26512;&#20219;&#21153;&#20998;&#24067;&#24182;&#36827;&#19968;&#27493;&#35774;&#35745;&#20855;&#26377;&#26356;&#24378;&#27867;&#21270;&#33021;&#21147;&#30340;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#21517;&#20026;&#20219;&#21153;&#20998;&#24067;&#30456;&#20851;&#24615;&#65288;TDR&#65289;&#65292;&#36890;&#36807;&#19981;&#21516;&#20219;&#21153;&#30340;&#26368;&#20248;Q&#20989;&#25968;&#26469;&#37327;&#21270;&#20219;&#21153;&#20998;&#24067;&#30340;&#30456;&#20851;&#24615;&#12290;&#22312;&#20855;&#26377;&#39640;TDR&#30340;&#20219;&#21153;&#24773;&#20917;&#19979;&#65292;&#21363;&#20219;&#21153;&#20043;&#38388;&#26174;&#33879;&#19981;&#21516;&#65292;&#25105;&#20204;&#21457;&#29616;&#39532;&#23572;&#21487;&#22827;&#31574;&#30053;&#26080;&#27861;&#21306;&#20998;&#23427;&#20204;&#65292;&#23548;&#33268;&#24615;&#33021;&#36739;&#24046;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#23558;&#25152;&#26377;&#21382;&#21490;&#20449;&#24687;&#32534;&#30721;&#21040;&#31574;&#30053;&#20013;&#20197;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;Task Aware Dreamer&#65288;TAD&#65289;&#65292;&#23427;&#23558;&#19990;&#30028;&#27169;&#22411;&#25193;&#23637;&#20026;&#25105;&#20204;&#30340;&#22870;&#21169;&#24863;&#30693;&#19990;&#30028;&#27169;&#22411;&#20197;&#25429;&#25417;&#20219;&#21153;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A long-standing goal of reinforcement learning is to acquire agents that can learn on training tasks and generalize well on unseen tasks that may share a similar dynamic but with different reward functions. A general challenge is to quantitatively measure the similarities between these different tasks, which is vital for analyzing the task distribution and further designing algorithms with stronger generalization. To address this, we present a novel metric named Task Distribution Relevance (TDR) via optimal Q functions of different tasks to capture the relevance of the task distribution quantitatively. In the case of tasks with a high TDR, i.e., the tasks differ significantly, we show that the Markovian policies cannot differentiate them, leading to poor performance. Based on this insight, we encode all historical information into policies for distinguishing different tasks and propose Task Aware Dreamer (TAD), which extends world models into our reward-informed world models to capture
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;Auto.gov&#8221;&#26694;&#26550;&#65292;&#21487;&#22686;&#24378;&#21435;&#20013;&#24515;&#21270;&#37329;&#34701;&#65288;DeFi&#65289;&#30340;&#23433;&#20840;&#24615;&#21644;&#38477;&#20302;&#21463;&#25915;&#20987;&#30340;&#39118;&#38505;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#28145;&#24230;Q-&#32593;&#32476;&#65288;DQN&#65289;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#21322;&#33258;&#21160;&#30340;&#12289;&#30452;&#35266;&#30340;&#27835;&#29702;&#25552;&#26696;&#65292;&#24182;&#37327;&#21270;&#20102;&#20854;&#29702;&#30001;&#65292;&#20351;&#31995;&#32479;&#33021;&#22815;&#26377;&#25928;&#22320;&#24212;&#23545;&#24694;&#24847;&#34892;&#20026;&#21644;&#24847;&#22806;&#30340;&#24066;&#22330;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2302.09551</link><description>&lt;p&gt;
Auto.gov&#65306;&#38754;&#21521;DeFi&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#38142;&#19978;&#27835;&#29702;
&lt;/p&gt;
&lt;p&gt;
Auto.gov: Learning-based On-chain Governance for Decentralized Finance (DeFi). (arXiv:2302.09551v2 [q-fin.RM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09551
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;Auto.gov&#8221;&#26694;&#26550;&#65292;&#21487;&#22686;&#24378;&#21435;&#20013;&#24515;&#21270;&#37329;&#34701;&#65288;DeFi&#65289;&#30340;&#23433;&#20840;&#24615;&#21644;&#38477;&#20302;&#21463;&#25915;&#20987;&#30340;&#39118;&#38505;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#28145;&#24230;Q-&#32593;&#32476;&#65288;DQN&#65289;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#21322;&#33258;&#21160;&#30340;&#12289;&#30452;&#35266;&#30340;&#27835;&#29702;&#25552;&#26696;&#65292;&#24182;&#37327;&#21270;&#20102;&#20854;&#29702;&#30001;&#65292;&#20351;&#31995;&#32479;&#33021;&#22815;&#26377;&#25928;&#22320;&#24212;&#23545;&#24694;&#24847;&#34892;&#20026;&#21644;&#24847;&#22806;&#30340;&#24066;&#22330;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21435;&#20013;&#24515;&#21270;&#37329;&#34701;&#65288;DeFi&#65289;&#32463;&#21382;&#20102;&#26174;&#33879;&#22686;&#38271;&#65292;&#28044;&#29616;&#20986;&#20102;&#21508;&#31181;&#21327;&#35758;&#65292;&#20363;&#22914;&#20511;&#36151;&#21327;&#35758;&#21644;&#33258;&#21160;&#21270;&#20570;&#24066;&#21830;&#65288;AMM&#65289;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20123;&#21327;&#35758;&#37319;&#29992;&#38142;&#19979;&#27835;&#29702;&#65292;&#20854;&#20013;&#20195;&#24065;&#25345;&#26377;&#32773;&#25237;&#31080;&#20462;&#25913;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#30001;&#21327;&#35758;&#26680;&#24515;&#22242;&#38431;&#36827;&#34892;&#30340;&#25163;&#21160;&#21442;&#25968;&#35843;&#25972;&#23481;&#26131;&#36973;&#21463;&#21246;&#32467;&#25915;&#20987;&#65292;&#21361;&#21450;&#31995;&#32479;&#30340;&#23436;&#25972;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;&#27492;&#22806;&#65292;&#32431;&#31929;&#30340;&#30830;&#23450;&#24615;&#31639;&#27861;&#26041;&#27861;&#21487;&#33021;&#20250;&#20351;&#21327;&#35758;&#21463;&#21040;&#26032;&#30340;&#21033;&#29992;&#21644;&#25915;&#20987;&#30340;&#23041;&#32961;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;Auto.gov&#8221;&#65292;&#36825;&#26159;&#19968;&#20010;&#38754;&#21521;DeFi&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#38142;&#19978;&#27835;&#29702;&#26694;&#26550;&#65292;&#21487;&#22686;&#24378;&#23433;&#20840;&#24615;&#24182;&#38477;&#20302;&#21463;&#25915;&#20987;&#30340;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21033;&#29992;&#20102;&#28145;&#24230;Q-&#32593;&#32476;&#65288;DQN&#65289;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#21322;&#33258;&#21160;&#21270;&#30340;&#12289;&#30452;&#35266;&#30340;&#27835;&#29702;&#25552;&#26696;&#19982;&#37327;&#21270;&#30340;&#29702;&#30001;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#31995;&#32479;&#33021;&#22815;&#26377;&#25928;&#22320;&#36866;&#24212;&#21644;&#32531;&#35299;&#24694;&#24847;&#34892;&#20026;&#21644;&#24847;&#22806;&#30340;&#24066;&#22330;&#24773;&#20917;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, decentralized finance (DeFi) has experienced remarkable growth, with various protocols such as lending protocols and automated market makers (AMMs) emerging. Traditionally, these protocols employ off-chain governance, where token holders vote to modify parameters. However, manual parameter adjustment, often conducted by the protocol's core team, is vulnerable to collusion, compromising the integrity and security of the system. Furthermore, purely deterministic, algorithm-based approaches may expose the protocol to novel exploits and attacks.  In this paper, we present "Auto.gov", a learning-based on-chain governance framework for DeFi that enhances security and reduces susceptibility to attacks. Our model leverages a deep Q- network (DQN) reinforcement learning approach to propose semi-automated, intuitive governance proposals with quantitative justifications. This methodology enables the system to efficiently adapt to and mitigate the negative impact of malicious beha
&lt;/p&gt;</description></item></channel></rss>