<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#35843;&#26597;&#38024;&#23545;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#27969;&#37327;&#20998;&#26512;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#24635;&#32467;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26032;&#29305;&#24449;&#12289;&#26368;&#26032;&#36827;&#23637;&#21644;&#25361;&#25112;&#65292;&#35748;&#20026;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#21487;&#20197;&#25581;&#31034;CIoT&#39046;&#22495;&#20013;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.16149</link><description>&lt;p&gt;
&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#27969;&#37327;&#30340;&#35843;&#26597;&#65306;&#23433;&#20840;&#19982;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
A Survey on Consumer IoT Traffic: Security and Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16149
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#38024;&#23545;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#27969;&#37327;&#20998;&#26512;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#24635;&#32467;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26032;&#29305;&#24449;&#12289;&#26368;&#26032;&#36827;&#23637;&#21644;&#25361;&#25112;&#65292;&#35748;&#20026;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#21487;&#20197;&#25581;&#31034;CIoT&#39046;&#22495;&#20013;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#37324;&#65292;&#28040;&#36153;&#32773;&#29289;&#32852;&#32593;&#65288;CIoT&#65289;&#24050;&#32463;&#36827;&#20837;&#20102;&#20844;&#20247;&#29983;&#27963;&#12290;&#23613;&#31649;CIoT&#25552;&#39640;&#20102;&#20154;&#20204;&#26085;&#24120;&#29983;&#27963;&#30340;&#20415;&#21033;&#24615;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26032;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;&#25105;&#20204;&#23581;&#35797;&#36890;&#36807;&#27969;&#37327;&#20998;&#26512;&#36825;&#19968;&#23433;&#20840;&#39046;&#22495;&#20013;&#30340;&#27969;&#34892;&#26041;&#27861;&#65292;&#25214;&#20986;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#20174;&#27969;&#37327;&#20998;&#26512;&#20013;&#20102;&#35299;CIoT&#23433;&#20840;&#21644;&#38544;&#31169;&#26041;&#38754;&#30340;&#20869;&#23481;&#12290;&#26412;&#35843;&#26597;&#20174;&#23433;&#20840;&#21644;&#38544;&#31169;&#35282;&#24230;&#25506;&#35752;&#20102;CIoT&#27969;&#37327;&#20998;&#26512;&#20013;&#30340;&#26032;&#29305;&#24449;&#12289;CIoT&#27969;&#37327;&#20998;&#26512;&#30340;&#26368;&#26032;&#36827;&#23637;&#20197;&#21450;&#23578;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#20174;2018&#24180;1&#26376;&#33267;2023&#24180;12&#26376;&#25910;&#38598;&#20102;310&#31687;&#19982;CIoT&#27969;&#37327;&#20998;&#26512;&#26377;&#20851;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#35282;&#24230;&#30340;&#35770;&#25991;&#65292;&#24635;&#32467;&#20102;&#35782;&#21035;&#20102;CIoT&#26032;&#29305;&#24449;&#30340;CIoT&#27969;&#37327;&#20998;&#26512;&#36807;&#31243;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#20116;&#20010;&#24212;&#29992;&#30446;&#26631;&#35814;&#32454;&#20171;&#32461;&#20102;&#29616;&#26377;&#30340;&#30740;&#31350;&#24037;&#20316;&#65306;&#35774;&#22791;&#25351;&#32441;&#35782;&#21035;&#12289;&#29992;&#25143;&#27963;&#21160;&#25512;&#26029;&#12289;&#24694;&#24847;&#34892;&#20026;&#26816;&#27979;&#12289;&#38544;&#31169;&#27844;&#38706;&#20197;&#21450;&#36890;&#20449;&#27169;&#24335;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16149v1 Announce Type: cross  Abstract: For the past few years, the Consumer Internet of Things (CIoT) has entered public lives. While CIoT has improved the convenience of people's daily lives, it has also brought new security and privacy concerns. In this survey, we try to figure out what researchers can learn about the security and privacy of CIoT by traffic analysis, a popular method in the security community. From the security and privacy perspective, this survey seeks out the new characteristics in CIoT traffic analysis, the state-of-the-art progress in CIoT traffic analysis, and the challenges yet to be solved. We collected 310 papers from January 2018 to December 2023 related to CIoT traffic analysis from the security and privacy perspective and summarized the process of CIoT traffic analysis in which the new characteristics of CIoT are identified. Then, we detail existing works based on five application goals: device fingerprinting, user activity inference, malicious
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Spectral Motion Alignment&#65288;SMA&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20613;&#31435;&#21494;&#21644;&#23567;&#27874;&#21464;&#25442;&#26469;&#20248;&#21270;&#21644;&#23545;&#40784;&#36816;&#21160;&#21521;&#37327;&#65292;&#23398;&#20064;&#25972;&#24103;&#20840;&#23616;&#36816;&#21160;&#21160;&#24577;&#65292;&#20943;&#36731;&#31354;&#38388;&#20266;&#24433;&#65292;&#26377;&#25928;&#25913;&#21892;&#36816;&#21160;&#36716;&#31227;&#12290;</title><link>https://arxiv.org/abs/2403.15249</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#35270;&#39057;&#36816;&#21160;&#36716;&#31227;&#30340;&#20809;&#35889;&#36816;&#21160;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Spectral Motion Alignment for Video Motion Transfer using Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15249
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Spectral Motion Alignment&#65288;SMA&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20613;&#31435;&#21494;&#21644;&#23567;&#27874;&#21464;&#25442;&#26469;&#20248;&#21270;&#21644;&#23545;&#40784;&#36816;&#21160;&#21521;&#37327;&#65292;&#23398;&#20064;&#25972;&#24103;&#20840;&#23616;&#36816;&#21160;&#21160;&#24577;&#65292;&#20943;&#36731;&#31354;&#38388;&#20266;&#24433;&#65292;&#26377;&#25928;&#25913;&#21892;&#36816;&#21160;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#30340;&#21457;&#23637;&#22312;&#35270;&#39057;&#29983;&#25104;&#21644;&#29702;&#35299;&#26041;&#38754;&#20135;&#29983;&#20102;&#24040;&#22823;&#24433;&#21709;&#12290;&#29305;&#21035;&#26159;&#65292;&#25991;&#26412;&#21040;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;&#65288;VDMs&#65289;&#26174;&#33879;&#20419;&#36827;&#20102;&#23558;&#36755;&#20837;&#35270;&#39057;&#23450;&#21046;&#20026;&#30446;&#26631;&#22806;&#35266;&#12289;&#36816;&#21160;&#31561;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#20934;&#30830;&#25552;&#21462;&#35270;&#39057;&#24103;&#30340;&#36816;&#21160;&#20449;&#24687;&#20173;&#28982;&#23384;&#22312;&#25361;&#25112;&#12290;&#29616;&#26377;&#20316;&#21697;&#21033;&#29992;&#36830;&#32493;&#24103;&#27531;&#24046;&#20316;&#20026;&#30446;&#26631;&#36816;&#21160;&#21521;&#37327;&#65292;&#20294;&#23427;&#20204;&#22266;&#26377;&#22320;&#32570;&#20047;&#20840;&#23616;&#36816;&#21160;&#32972;&#26223;&#65292;&#24182;&#23481;&#26131;&#21463;&#21040;&#36880;&#24103;&#22833;&#30495;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20809;&#35889;&#36816;&#21160;&#23545;&#40784;&#65288;SMA&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#36890;&#36807;&#20613;&#31435;&#21494;&#21644;&#23567;&#27874;&#21464;&#25442;&#26469;&#20248;&#21270;&#21644;&#23545;&#40784;&#36816;&#21160;&#21521;&#37327;&#30340;&#26032;&#26694;&#26550;&#12290;SMA&#36890;&#36807;&#25972;&#21512;&#39057;&#22495;&#27491;&#21017;&#21270;&#26469;&#23398;&#20064;&#36816;&#21160;&#27169;&#24335;&#65292;&#20419;&#36827;&#25972;&#24103;&#20840;&#23616;&#36816;&#21160;&#21160;&#24577;&#30340;&#23398;&#20064;&#65292;&#24182;&#20943;&#36731;&#31354;&#38388;&#20266;&#24433;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;SMA&#22312;&#25913;&#21892;&#36816;&#21160;&#36716;&#31227;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15249v1 Announce Type: cross  Abstract: The evolution of diffusion models has greatly impacted video generation and understanding. Particularly, text-to-video diffusion models (VDMs) have significantly facilitated the customization of input video with target appearance, motion, etc. Despite these advances, challenges persist in accurately distilling motion information from video frames. While existing works leverage the consecutive frame residual as the target motion vector, they inherently lack global motion context and are vulnerable to frame-wise distortions. To address this, we present Spectral Motion Alignment (SMA), a novel framework that refines and aligns motion vectors using Fourier and wavelet transforms. SMA learns motion patterns by incorporating frequency-domain regularization, facilitating the learning of whole-frame global motion dynamics, and mitigating spatial artifacts. Extensive experiments demonstrate SMA's efficacy in improving motion transfer while main
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26059;&#36716;&#19981;&#21464;&#21464;&#20998;&#37327;&#23376;&#30005;&#36335;&#36827;&#34892;&#22270;&#20687;&#20998;&#31867;&#30340;&#31561;&#21464;&#26550;&#26500;&#65292;&#36890;&#36807;&#24341;&#20837;&#20960;&#20309;&#24402;&#32435;&#20559;&#24046;&#65292;&#25104;&#21151;&#25552;&#21319;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.15031</link><description>&lt;p&gt;
&#20351;&#29992;&#26059;&#36716;&#19981;&#21464;&#21464;&#20998;&#37327;&#23376;&#30005;&#36335;&#36827;&#34892;&#22270;&#20687;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Image Classification with Rotation-Invariant Variational Quantum Circuits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15031
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26059;&#36716;&#19981;&#21464;&#21464;&#20998;&#37327;&#23376;&#30005;&#36335;&#36827;&#34892;&#22270;&#20687;&#20998;&#31867;&#30340;&#31561;&#21464;&#26550;&#26500;&#65292;&#36890;&#36807;&#24341;&#20837;&#20960;&#20309;&#24402;&#32435;&#20559;&#24046;&#65292;&#25104;&#21151;&#25552;&#21319;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#37327;&#23376;&#31639;&#27861;&#20316;&#20026;&#22024;&#26434;&#20013;&#31561;&#35268;&#27169;&#37327;&#23376;&#65288;NISQ&#65289;&#35774;&#22791;&#30340;&#26089;&#26399;&#24212;&#29992;&#27491;&#21463;&#21040;&#20851;&#27880;&#12290;&#21464;&#20998;&#26041;&#27861;&#30340;&#20027;&#35201;&#38382;&#39064;&#20043;&#19968;&#22312;&#20110;Barren Plateaus&#29616;&#35937;&#65292;&#22312;&#21464;&#20998;&#21442;&#25968;&#20248;&#21270;&#36807;&#31243;&#20013;&#23384;&#22312;&#12290;&#25552;&#20986;&#23558;&#20960;&#20309;&#24402;&#32435;&#20559;&#24046;&#28155;&#21152;&#21040;&#37327;&#23376;&#27169;&#22411;&#20316;&#20026;&#32531;&#35299;&#36825;&#19968;&#38382;&#39064;&#30340;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#19968;&#20010;&#31216;&#20026;&#20960;&#20309;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#39046;&#22495;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#31561;&#21464;&#32467;&#26500;&#30340;&#21464;&#20998;&#37327;&#23376;&#20998;&#31867;&#22120;&#65292;&#20197;&#21019;&#24314;&#20855;&#26377;$C_4$&#26059;&#36716;&#26631;&#31614;&#23545;&#31216;&#24615;&#30340;&#22270;&#20687;&#20998;&#31867;&#30340;&#26631;&#31614;&#19981;&#21464;&#27169;&#22411;&#12290;&#31561;&#21464;&#30005;&#36335;&#19982;&#20004;&#31181;&#19981;&#21516;&#30340;&#32467;&#26500;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#23454;&#39564;&#35777;&#26126;&#20960;&#20309;&#26041;&#27861;&#25552;&#21319;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25552;&#20986;&#20102;&#32463;&#20856;&#31561;&#21464;&#21367;&#31215;&#25805;&#20316;&#65292;&#20197;&#25193;&#23637;&#37327;&#23376;&#27169;&#22411;&#22788;&#29702;&#26356;&#22823;&#22270;&#20687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15031v1 Announce Type: cross  Abstract: Variational quantum algorithms are gaining attention as an early application of Noisy Intermediate-Scale Quantum (NISQ) devices. One of the main problems of variational methods lies in the phenomenon of Barren Plateaus, present in the optimization of variational parameters. Adding geometric inductive bias to the quantum models has been proposed as a potential solution to mitigate this problem, leading to a new field called Geometric Quantum Machine Learning. In this work, an equivariant architecture for variational quantum classifiers is introduced to create a label-invariant model for image classification with $C_4$ rotational label symmetry. The equivariant circuit is benchmarked against two different architectures, and it is experimentally observed that the geometric approach boosts the model's performance. Finally, a classical equivariant convolution operation is proposed to extend the quantum model for the processing of larger ima
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#26469;&#36873;&#25321;&#38656;&#35201;&#36827;&#19968;&#27493;&#36866;&#24212;&#30340;&#23618;&#65292;&#20174;&#32780;&#20811;&#26381;&#20102;&#25345;&#32493;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#26041;&#27861;&#20013;&#30001;&#20110;&#20266;&#26631;&#31614;&#24341;&#36215;&#30340;&#19981;&#20934;&#30830;&#24615;&#22256;&#25200;&#12290;</title><link>https://arxiv.org/abs/2403.10650</link><description>&lt;p&gt;
PALM&#65306;&#25512;&#36827;&#29992;&#20110;&#25345;&#32493;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
PALM: Pushing Adaptive Learning Rate Mechanisms for Continual Test-Time Adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#26469;&#36873;&#25321;&#38656;&#35201;&#36827;&#19968;&#27493;&#36866;&#24212;&#30340;&#23618;&#65292;&#20174;&#32780;&#20811;&#26381;&#20102;&#25345;&#32493;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#26041;&#27861;&#20013;&#30001;&#20110;&#20266;&#26631;&#31614;&#24341;&#36215;&#30340;&#19981;&#20934;&#30830;&#24615;&#22256;&#25200;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#29615;&#22659;&#20013;&#30340;&#35270;&#35273;&#27169;&#22411;&#38754;&#20020;&#39046;&#22495;&#20998;&#24067;&#30340;&#24555;&#36895;&#36716;&#21464;&#65292;&#23548;&#33268;&#35782;&#21035;&#24615;&#33021;&#19979;&#38477;&#12290;&#25345;&#32493;&#27979;&#35797;&#26102;&#38388;&#33258;&#36866;&#24212;&#65288;CTTA&#65289;&#30452;&#25509;&#26681;&#25454;&#27979;&#35797;&#25968;&#25454;&#35843;&#25972;&#39044;&#35757;&#32451;&#30340;&#28304;&#21028;&#21035;&#27169;&#22411;&#20197;&#36866;&#24212;&#36825;&#20123;&#19981;&#26029;&#21464;&#21270;&#30340;&#39046;&#22495;&#12290;&#19968;&#31181;&#39640;&#24230;&#26377;&#25928;&#30340;CTTA&#26041;&#27861;&#28041;&#21450;&#24212;&#29992;&#36880;&#23618;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#24182;&#36873;&#25321;&#24615;&#22320;&#35843;&#25972;&#39044;&#35757;&#32451;&#23618;&#12290;&#28982;&#32780;&#65292;&#23427;&#21463;&#21040;&#39046;&#22495;&#36716;&#31227;&#20272;&#35745;&#19981;&#20934;&#30830;&#21644;&#30001;&#20266;&#26631;&#31614;&#24341;&#36215;&#30340;&#19981;&#20934;&#30830;&#24615;&#25152;&#22256;&#25200;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#35782;&#21035;&#23618;&#26469;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#36890;&#36807;&#23545;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#26469;&#36873;&#25321;&#23618;&#65292;&#32780;&#26080;&#39035;&#20381;&#36182;&#20266;&#26631;&#31614;&#12290;&#25105;&#20204;&#21033;&#29992;&#26799;&#24230;&#30340;&#22823;&#23567;&#20316;&#20026;&#19968;&#20010;&#24230;&#37327;&#26631;&#20934;&#65292;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;softmax&#36755;&#20986;&#19982;&#22343;&#21248;&#20998;&#24067;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#26469;&#35745;&#31639;&#65292;&#20197;&#36873;&#25321;&#38656;&#35201;&#36827;&#19968;&#27493;&#36866;&#24212;&#30340;&#23618;&#12290;&#38543;&#21518;&#65292;&#20165;&#23646;&#20110;&#36825;&#20123;&#23618;&#30340;&#21442;&#25968;&#23558;&#34987;&#36827;&#19968;&#27493;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10650v1 Announce Type: cross  Abstract: Real-world vision models in dynamic environments face rapid shifts in domain distributions, leading to decreased recognition performance. Continual test-time adaptation (CTTA) directly adjusts a pre-trained source discriminative model to these changing domains using test data. A highly effective CTTA method involves applying layer-wise adaptive learning rates, and selectively adapting pre-trained layers. However, it suffers from the poor estimation of domain shift and the inaccuracies arising from the pseudo-labels. In this work, we aim to overcome these limitations by identifying layers through the quantification of model prediction uncertainty without relying on pseudo-labels. We utilize the magnitude of gradients as a metric, calculated by backpropagating the KL divergence between the softmax output and a uniform distribution, to select layers for further adaptation. Subsequently, for the parameters exclusively belonging to these se
&lt;/p&gt;</description></item><item><title>CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;</title><link>https://arxiv.org/abs/2403.07728</link><description>&lt;p&gt;
CAS: &#19968;&#31181;&#20855;&#26377;FCR&#25511;&#21046;&#30340;&#22312;&#32447;&#36873;&#25321;&#24615;&#31526;&#21512;&#39044;&#27979;&#30340;&#36890;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
CAS: A General Algorithm for Online Selective Conformal Prediction with FCR Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07728
&lt;/p&gt;
&lt;p&gt;
CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#26041;&#24335;&#19979;&#21518;&#36873;&#25321;&#39044;&#27979;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#23558;&#36164;&#28304;&#32791;&#36153;&#22312;&#19981;&#37325;&#35201;&#30340;&#21333;&#20301;&#19978;&#65292;&#22312;&#25253;&#21578;&#20854;&#39044;&#27979;&#21306;&#38388;&#20043;&#21069;&#23545;&#24403;&#21069;&#20010;&#20307;&#36827;&#34892;&#21021;&#27493;&#36873;&#25321;&#22312;&#22312;&#32447;&#39044;&#27979;&#20219;&#21153;&#20013;&#26159;&#24120;&#35265;&#19988;&#26377;&#24847;&#20041;&#30340;&#12290;&#30001;&#20110;&#22312;&#32447;&#36873;&#25321;&#23548;&#33268;&#25152;&#36873;&#39044;&#27979;&#21306;&#38388;&#20013;&#23384;&#22312;&#26102;&#38388;&#22810;&#37325;&#24615;&#65292;&#22240;&#27492;&#25511;&#21046;&#23454;&#26102;&#35823;&#35206;&#30422;&#38472;&#36848;&#29575;&#65288;FCR&#65289;&#26469;&#27979;&#37327;&#24179;&#22343;&#35823;&#35206;&#30422;&#35823;&#24046;&#26159;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;CAS&#65288;&#36866;&#24212;&#24615;&#36873;&#25321;&#21518;&#26657;&#20934;&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#21253;&#35065;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#21644;&#22312;&#32447;&#36873;&#25321;&#35268;&#21017;&#65292;&#20197;&#36755;&#20986;&#21518;&#36873;&#25321;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#22914;&#26524;&#36873;&#25321;&#20102;&#24403;&#21069;&#20010;&#20307;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#21382;&#21490;&#25968;&#25454;&#36827;&#34892;&#33258;&#36866;&#24212;&#36873;&#25321;&#26469;&#26500;&#24314;&#26657;&#20934;&#38598;&#65292;&#28982;&#21518;&#20026;&#26410;&#35266;&#23519;&#21040;&#30340;&#26631;&#31614;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#20026;&#26657;&#20934;&#38598;&#25552;&#20379;&#20102;&#21487;&#34892;&#30340;&#26500;&#36896;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07728v1 Announce Type: cross  Abstract: We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) to measure the averaged miscoverage error. We develop a general framework named CAS (Calibration after Adaptive Selection) that can wrap around any prediction model and online selection rule to output post-selection prediction intervals. If the current individual is selected, we first perform an adaptive selection on historical data to construct a calibration set, then output a conformal prediction interval for the unobserved label. We provide tractable constructions for the calibration set for 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#26500;&#24314;&#19968;&#31181;&#23618;&#27425;&#32467;&#26500;&#30340;&#21487;&#39640;&#25928;&#35757;&#32451;&#30340;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#22312;&#32463;&#20856;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#20013;&#20855;&#26377;&#20219;&#24847;&#24120;&#25968;&#27425;&#25968;&#30340;&#22810;&#39033;&#24335;&#20869;&#23384;&#20998;&#31163;&#12290;&#27599;&#20010;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#21333;&#20803;&#37117;&#21487;&#20197;&#22312;&#24120;&#25968;&#26102;&#38388;&#20869;&#22312;&#37327;&#23376;&#35774;&#22791;&#19978;&#36827;&#34892;&#35745;&#31639;&#12290;</title><link>https://arxiv.org/abs/2402.08606</link><description>&lt;p&gt;
&#21487;&#35757;&#32451;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#20219;&#24847;&#22810;&#39033;&#24335;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Arbitrary Polynomial Separations in Trainable Quantum Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08606
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#26500;&#24314;&#19968;&#31181;&#23618;&#27425;&#32467;&#26500;&#30340;&#21487;&#39640;&#25928;&#35757;&#32451;&#30340;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#22312;&#32463;&#20856;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#20013;&#20855;&#26377;&#20219;&#24847;&#24120;&#25968;&#27425;&#25968;&#30340;&#22810;&#39033;&#24335;&#20869;&#23384;&#20998;&#31163;&#12290;&#27599;&#20010;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#21333;&#20803;&#37117;&#21487;&#20197;&#22312;&#24120;&#25968;&#26102;&#38388;&#20869;&#22312;&#37327;&#23376;&#35774;&#22791;&#19978;&#36827;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#29702;&#35770;&#30740;&#31350;&#34920;&#26126;&#65292;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNNs&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#21487;&#35757;&#32451;&#24615;&#20043;&#38388;&#23384;&#22312;&#19968;&#31181;&#26222;&#36941;&#30340;&#26435;&#34913;&#65307;&#20316;&#20026;&#36825;&#20123;&#32467;&#26524;&#30340;&#25512;&#35770;&#65292;&#23454;&#38469;&#19978;&#22312;&#34920;&#36798;&#33021;&#21147;&#19978;&#23454;&#29616;&#25351;&#25968;&#32423;&#30340;&#36229;&#36234;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20998;&#31163;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#22240;&#20026;&#36825;&#26679;&#30340;QNN&#35757;&#32451;&#26102;&#38388;&#22312;&#27169;&#22411;&#35268;&#27169;&#19978;&#26159;&#25351;&#25968;&#32423;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#31181;&#23618;&#27425;&#32467;&#26500;&#30340;&#21487;&#39640;&#25928;&#35757;&#32451;&#30340;QNNs&#26469;&#32469;&#24320;&#36825;&#20123;&#36127;&#38754;&#32467;&#26524;&#65292;&#22312;&#25191;&#34892;&#32463;&#20856;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#26102;&#65292;&#36825;&#20123;QNNs&#21487;&#20197;&#23637;&#31034;&#20986;&#20219;&#24847;&#24120;&#25968;&#27425;&#25968;&#30340;&#22810;&#39033;&#24335;&#20869;&#23384;&#20998;&#31163;&#65292;&#19988;&#22312;&#37327;&#23376;&#35774;&#22791;&#19978;&#27599;&#20010;&#21333;&#20803;&#26684;&#37117;&#21487;&#20197;&#22312;&#24120;&#25968;&#26102;&#38388;&#20869;&#36827;&#34892;&#35745;&#31639;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#20998;&#31163;&#36866;&#29992;&#20110;&#21253;&#25324;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#20869;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#32463;&#20856;&#32593;&#32476;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#37327;&#23376;&#19978;&#19979;&#25991;&#30456;&#20851;&#24615;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent theoretical results in quantum machine learning have demonstrated a general trade-off between the expressive power of quantum neural networks (QNNs) and their trainability; as a corollary of these results, practical exponential separations in expressive power over classical machine learning models are believed to be infeasible as such QNNs take a time to train that is exponential in the model size. We here circumvent these negative results by constructing a hierarchy of efficiently trainable QNNs that exhibit unconditionally provable, polynomial memory separations of arbitrary constant degree over classical neural networks in performing a classical sequence modeling task. Furthermore, each unit cell of the introduced class of QNNs is computationally efficient, implementable in constant time on a quantum device. The classical networks we prove a separation over include well-known examples such as recurrent neural networks and Transformers. We show that quantum contextuality is th
&lt;/p&gt;</description></item><item><title>XTSFormer&#26159;&#19968;&#20010;&#29992;&#20110;&#19981;&#35268;&#21017;&#26102;&#38388;&#20107;&#20214;&#39044;&#27979;&#30340;&#36328;&#26102;&#31354;&#23610;&#24230;&#30340;Transformer&#27169;&#22411;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#24490;&#29615;&#24863;&#30693;&#26102;&#38388;&#20301;&#32622;&#32534;&#30721;&#21644;&#20998;&#23618;&#30340;&#22810;&#23610;&#24230;&#26102;&#38388;&#27880;&#24847;&#26426;&#21046;&#26469;&#35299;&#20915;&#19981;&#35268;&#21017;&#26102;&#38388;&#38388;&#38548;&#12289;&#24490;&#29615;&#12289;&#21608;&#26399;&#24615;&#21644;&#22810;&#23610;&#24230;&#20107;&#20214;&#20132;&#20114;&#31561;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.02258</link><description>&lt;p&gt;
XTSFormer: &#36328;&#26102;&#31354;&#23610;&#24230;&#30340;Transformer&#29992;&#20110;&#19981;&#35268;&#21017;&#26102;&#38388;&#20107;&#20214;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02258
&lt;/p&gt;
&lt;p&gt;
XTSFormer&#26159;&#19968;&#20010;&#29992;&#20110;&#19981;&#35268;&#21017;&#26102;&#38388;&#20107;&#20214;&#39044;&#27979;&#30340;&#36328;&#26102;&#31354;&#23610;&#24230;&#30340;Transformer&#27169;&#22411;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#24490;&#29615;&#24863;&#30693;&#26102;&#38388;&#20301;&#32622;&#32534;&#30721;&#21644;&#20998;&#23618;&#30340;&#22810;&#23610;&#24230;&#26102;&#38388;&#27880;&#24847;&#26426;&#21046;&#26469;&#35299;&#20915;&#19981;&#35268;&#21017;&#26102;&#38388;&#38388;&#38548;&#12289;&#24490;&#29615;&#12289;&#21608;&#26399;&#24615;&#21644;&#22810;&#23610;&#24230;&#20107;&#20214;&#20132;&#20114;&#31561;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20107;&#20214;&#39044;&#27979;&#26088;&#22312;&#22522;&#20110;&#21382;&#21490;&#20107;&#20214;&#24207;&#21015;&#39044;&#27979;&#26410;&#26469;&#20107;&#20214;&#30340;&#26102;&#38388;&#21644;&#31867;&#22411;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#20294;&#23384;&#22312;&#20960;&#20010;&#25361;&#25112;&#65292;&#21253;&#25324;&#36830;&#32493;&#20107;&#20214;&#20043;&#38388;&#26102;&#38388;&#38388;&#38548;&#30340;&#19981;&#35268;&#21017;&#24615;&#12289;&#24490;&#29615;&#12289;&#21608;&#26399;&#24615;&#21644;&#22810;&#23610;&#24230;&#20107;&#20214;&#20132;&#20114;&#65292;&#20197;&#21450;&#38271;&#20107;&#20214;&#24207;&#21015;&#30340;&#39640;&#35745;&#31639;&#25104;&#26412;&#12290;&#29616;&#26377;&#30340;&#31070;&#32463;&#26102;&#38388;&#28857;&#36807;&#31243;&#65288;TPP&#65289;&#26041;&#27861;&#19981;&#33021;&#25429;&#25417;&#20107;&#20214;&#20132;&#20114;&#30340;&#22810;&#23610;&#24230;&#29305;&#24615;&#65292;&#32780;&#36825;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65288;&#22914;&#20020;&#24202;&#20107;&#20214;&#25968;&#25454;&#65289;&#24456;&#24120;&#35265;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36328;&#26102;&#31354;&#23610;&#24230;&#30340;Transformer&#65288;XTSFormer&#65289;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#19981;&#35268;&#21017;&#26102;&#38388;&#20107;&#20214;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21253;&#21547;&#20004;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#29305;&#24449;&#30340;&#24490;&#29615;&#24863;&#30693;&#26102;&#38388;&#20301;&#32622;&#32534;&#30721;&#65288;FCPE&#65289;&#65292;&#33021;&#22815;&#28789;&#27963;&#25429;&#25417;&#26102;&#38388;&#30340;&#24490;&#29615;&#24615;&#36136;&#65292;&#20197;&#21450;&#19968;&#20010;&#20998;&#23618;&#30340;&#22810;&#23610;&#24230;&#26102;&#38388;&#27880;&#24847;&#26426;&#21046;&#12290;&#36825;&#20123;&#23610;&#24230;&#30001;&#33258;&#24213;&#21521;&#19978;&#30340;&#32858;&#31867;&#31639;&#27861;&#30830;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
Event prediction aims to forecast the time and type of a future event based on a historical event sequence. Despite its significance, several challenges exist, including the irregularity of time intervals between consecutive events, the existence of cycles, periodicity, and multi-scale event interactions, as well as the high computational costs for long event sequences. Existing neural temporal point processes (TPPs) methods do not capture the multi-scale nature of event interactions, which is common in many real-world applications such as clinical event data. To address these issues, we propose the cross-temporal-scale transformer (XTSFormer), designed specifically for irregularly timed event data. Our model comprises two vital components: a novel Feature-based Cycle-aware Time Positional Encoding (FCPE) that adeptly captures the cyclical nature of time, and a hierarchical multi-scale temporal attention mechanism. These scales are determined by a bottom-up clustering algorithm. Extens
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#36873;&#25321;&#24615;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#33258;&#36866;&#24212;&#30340;&#26041;&#24335;&#24314;&#31435;&#32622;&#20449;&#21306;&#38388;&#65292;&#26377;&#25928;&#22320;&#22788;&#29702;&#20102;&#23454;&#38469;&#38382;&#39064;&#20013;&#31574;&#30053;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2302.00284</link><description>&lt;p&gt;
&#36873;&#25321;&#24615;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Selective Uncertainty Propagation in Offline RL
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.00284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#36873;&#25321;&#24615;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#33258;&#36866;&#24212;&#30340;&#26041;&#24335;&#24314;&#31435;&#32622;&#20449;&#21306;&#38388;&#65292;&#26377;&#25928;&#22320;&#22788;&#29702;&#20102;&#23454;&#38469;&#38382;&#39064;&#20013;&#31574;&#30053;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#26377;&#38480;&#26102;&#38388;&#27573;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#24773;&#26223;&#65292;&#30446;&#26631;&#22312;&#20110;&#24212;&#23545;&#21160;&#24577;&#35268;&#21010;&#31639;&#27861;&#20013;&#27599;&#19968;&#27493;&#31574;&#30053;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#35780;&#20272;&#31163;&#24320;&#34892;&#20026;&#31574;&#30053;&#22312;&#31532;h&#27493;&#26102;&#30340;&#22788;&#29702;&#25928;&#26524;&#65292;&#23601;&#21487;&#20197;&#23398;&#20064;&#21040;&#36825;&#19968;&#27493;&#30340;&#31574;&#30053;&#12290;&#30001;&#20110;&#27599;&#19968;&#27493;&#31574;&#30053;&#37117;&#20250;&#24433;&#21709;&#19979;&#19968;&#29366;&#24577;&#30340;&#20998;&#24067;&#65292;&#30456;&#20851;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#20351;&#24471;&#36825;&#19968;&#38382;&#39064;&#22312;&#32479;&#35745;&#23398;&#19978;&#27604;&#38543;&#26426;&#24773;&#22659;&#25361;&#25112;&#19979;&#30340;&#22788;&#29702;&#25928;&#26524;&#20272;&#35745;&#26356;&#21152;&#22256;&#38590;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#23454;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#38590;&#24230;&#20171;&#20110;&#36825;&#20004;&#31181;&#24773;&#22659;&#20043;&#38388;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#28789;&#27963;&#19988;&#36890;&#29992;&#30340;&#26041;&#27861;&#65292;&#21517;&#20026;&#36873;&#25321;&#24615;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#65292;&#29992;&#20110;&#24314;&#31435;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#26681;&#25454;&#30456;&#20851;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#30340;&#38590;&#24230;&#36827;&#34892;&#33258;&#36866;&#24212;&#12290;&#22312;&#29609;&#20855;&#29615;&#22659;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#25216;&#26415;&#22312;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#20013;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the finite-horizon offline reinforcement learning (RL) setting, and are motivated by the challenge of learning the policy at any step h in dynamic programming (DP) algorithms. To learn this, it is sufficient to evaluate the treatment effect of deviating from the behavioral policy at step h after having optimized the policy for all future steps. Since the policy at any step can affect next-state distributions, the related distributional shift challenges can make this problem far more statistically hard than estimating such treatment effects in the stochastic contextual bandit setting. However, the hardness of many real-world RL instances lies between the two regimes. We develop a flexible and general method called selective uncertainty propagation for confidence interval construction that adapts to the hardness of the associated distribution shift challenges. We show benefits of our approach on toy environments and demonstrate the benefits of these techniques for offline pol
&lt;/p&gt;</description></item><item><title>TurboSVM-FL&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#32852;&#37030;&#32858;&#21512;&#31574;&#30053;&#65292;&#36890;&#36807;SVM&#32858;&#21512;&#20026;&#25042;&#24816;&#23458;&#25143;&#31471;&#22686;&#24378;&#32852;&#37030;&#23398;&#20064;&#12290;&#36825;&#31181;&#31574;&#30053;&#22312;&#19981;&#22686;&#21152;&#23458;&#25143;&#31471;&#35745;&#31639;&#36127;&#25285;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.12012</link><description>&lt;p&gt;
TurboSVM-FL: &#36890;&#36807;SVM&#32858;&#21512;&#20026;&#25042;&#24816;&#23458;&#25143;&#31471;&#22686;&#24378;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients. (arXiv:2401.12012v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12012
&lt;/p&gt;
&lt;p&gt;
TurboSVM-FL&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#32852;&#37030;&#32858;&#21512;&#31574;&#30053;&#65292;&#36890;&#36807;SVM&#32858;&#21512;&#20026;&#25042;&#24816;&#23458;&#25143;&#31471;&#22686;&#24378;&#32852;&#37030;&#23398;&#20064;&#12290;&#36825;&#31181;&#31574;&#30053;&#22312;&#19981;&#22686;&#21152;&#23458;&#25143;&#31471;&#35745;&#31639;&#36127;&#25285;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#20998;&#24067;&#24335;&#21327;&#20316;&#26426;&#22120;&#23398;&#20064;&#33539;&#20363;&#65292;&#22312;&#36817;&#24180;&#26469;&#33719;&#24471;&#20102;&#24378;&#28872;&#30340;&#25512;&#21160;&#21147;&#12290;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#20013;&#22830;&#26381;&#21153;&#22120;&#23450;&#26399;&#36890;&#36807;&#23458;&#25143;&#31471;&#21327;&#35843;&#27169;&#22411;&#65292;&#24182;&#32858;&#21512;&#30001;&#23458;&#25143;&#31471;&#22312;&#26412;&#22320;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#35775;&#38382;&#26412;&#22320;&#25968;&#25454;&#12290;&#23613;&#31649;&#20855;&#26377;&#28508;&#21147;&#65292;&#20294;&#32852;&#37030;&#23398;&#20064;&#30340;&#23454;&#26045;&#20173;&#28982;&#38754;&#20020;&#19968;&#20123;&#25361;&#25112;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#25968;&#25454;&#24322;&#36136;&#24615;&#23548;&#33268;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#12290;&#25910;&#25947;&#36895;&#24230;&#24930;&#22312;&#36328;&#35774;&#22791;&#32852;&#37030;&#23398;&#20064;&#22330;&#26223;&#20013;&#23588;&#20026;&#38382;&#39064;&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#21487;&#33021;&#21463;&#21040;&#35745;&#31639;&#33021;&#21147;&#21644;&#23384;&#20648;&#31354;&#38388;&#30340;&#20005;&#37325;&#38480;&#21046;&#65292;&#22240;&#27492;&#23545;&#23458;&#25143;&#31471;&#20135;&#29983;&#39069;&#22806;&#35745;&#31639;&#25110;&#20869;&#23384;&#36127;&#25285;&#30340;&#26041;&#27861;&#65292;&#22914;&#36741;&#21161;&#30446;&#26631;&#39033;&#21644;&#26356;&#22823;&#30340;&#35757;&#32451;&#36845;&#20195;&#27425;&#25968;&#65292;&#21487;&#33021;&#19981;&#23454;&#38469;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32852;&#37030;&#32858;&#21512;&#31574;&#30053;TurboSVM-FL&#65292;&#23427;&#19981;&#20250;&#32473;&#23458;&#25143;&#31471;&#22686;&#21152;&#39069;&#22806;&#30340;&#35745;&#31639;&#36127;&#25285;
&lt;/p&gt;
&lt;p&gt;
Federated learning is a distributed collaborative machine learning paradigm that has gained strong momentum in recent years. In federated learning, a central server periodically coordinates models with clients and aggregates the models trained locally by clients without necessitating access to local data. Despite its potential, the implementation of federated learning continues to encounter several challenges, predominantly the slow convergence that is largely due to data heterogeneity. The slow convergence becomes particularly problematic in cross-device federated learning scenarios where clients may be strongly limited by computing power and storage space, and hence counteracting methods that induce additional computation or memory cost on the client side such as auxiliary objective terms and larger training iterations can be impractical. In this paper, we propose a novel federated aggregation strategy, TurboSVM-FL, that poses no additional computation burden on the client side and c
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#36870;&#35299;&#20915;&#38750;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#31070;&#32463;&#27969;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26082;&#20445;&#35777;&#20102;&#21487;&#36870;&#24615;&#21448;&#38477;&#20302;&#20102;&#35745;&#31639;&#36127;&#25285;&#65292;&#24182;&#19988;&#22312;&#20998;&#31867;&#21644;&#25554;&#20540;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.04979</link><description>&lt;p&gt;
&#21487;&#36870;&#35299;&#20915;&#38750;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series. (arXiv:2401.04979v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04979
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#36870;&#35299;&#20915;&#38750;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#31070;&#32463;&#27969;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26082;&#20445;&#35777;&#20102;&#21487;&#36870;&#24615;&#21448;&#38477;&#20302;&#20102;&#35745;&#31639;&#36127;&#25285;&#65292;&#24182;&#19988;&#22312;&#20998;&#31867;&#21644;&#25554;&#20540;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22788;&#29702;&#38750;&#35268;&#21017;&#21644;&#19981;&#23436;&#25972;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#65288;NDE&#65289;&#30340;&#21487;&#36870;&#35299;&#20915;&#26041;&#26696;&#12290;&#34429;&#28982;&#22522;&#20110;NDE&#30340;&#26041;&#27861;&#26159;&#20998;&#26512;&#38750;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#19968;&#31181;&#24378;&#22823;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#19981;&#33021;&#20445;&#35777;&#22312;&#20854;&#26631;&#20934;&#24418;&#24335;&#19979;&#36827;&#34892;&#21487;&#36870;&#21464;&#25442;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#35758;&#20351;&#29992;&#20855;&#26377;&#31070;&#32463;&#27969;&#30340;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#65288;Neural CDEs&#65289;&#30340;&#21464;&#31181;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#20302;&#30340;&#35745;&#31639;&#36127;&#25285;&#30340;&#21516;&#26102;&#30830;&#20445;&#20102;&#21487;&#36870;&#24615;&#12290;&#27492;&#22806;&#65292;&#23427;&#36824;&#21487;&#20197;&#35757;&#32451;&#21452;&#37325;&#28508;&#22312;&#31354;&#38388;&#65292;&#22686;&#24378;&#20102;&#23545;&#21160;&#24577;&#26102;&#38388;&#21160;&#21147;&#23398;&#30340;&#24314;&#27169;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#20808;&#36827;&#30340;&#26694;&#26550;&#65292;&#22312;&#20998;&#31867;&#21644;&#25554;&#20540;&#20219;&#21153;&#20013;&#37117;&#34920;&#29616;&#20986;&#33394;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#20010;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#22686;&#24378;&#22411;&#21452;&#37325;&#28508;&#22312;&#29366;&#24577;&#26550;&#26500;&#65292;&#29992;&#20110;&#22312;&#21508;&#31181;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#20013;&#25552;&#39640;&#31934;&#24230;&#12290;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
To handle the complexities of irregular and incomplete time series data, we propose an invertible solution of Neural Differential Equations (NDE)-based method. While NDE-based methods are a powerful method for analyzing irregularly-sampled time series, they typically do not guarantee reversible transformations in their standard form. Our method suggests the variation of Neural Controlled Differential Equations (Neural CDEs) with Neural Flow, which ensures invertibility while maintaining a lower computational burden. Additionally, it enables the training of a dual latent space, enhancing the modeling of dynamic temporal dynamics. Our research presents an advanced framework that excels in both classification and interpolation tasks. At the core of our approach is an enhanced dual latent states architecture, carefully designed for high precision across various time series tasks. Empirical analysis demonstrates that our method significantly outperforms existing models. This work significan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;LoBaSS&#65292;&#21033;&#29992;&#25968;&#25454;&#30340;&#21487;&#23398;&#20064;&#24615;&#20316;&#20026;&#36873;&#25321;&#30417;&#30563;&#24494;&#35843;&#25968;&#25454;&#30340;&#20027;&#35201;&#26631;&#20934;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26681;&#25454;&#27169;&#22411;&#30340;&#33021;&#21147;&#23558;&#25968;&#25454;&#36873;&#25321;&#19982;&#27169;&#22411;&#23545;&#40784;&#65292;&#30830;&#20445;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.13008</link><description>&lt;p&gt;
LoBaSS&#65306;&#22312;&#30417;&#30563;&#24494;&#35843;&#25968;&#25454;&#20013;&#27979;&#37327;&#21487;&#23398;&#20064;&#24615;
&lt;/p&gt;
&lt;p&gt;
LoBaSS: Gauging Learnability in Supervised Fine-tuning Data. (arXiv:2310.13008v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;LoBaSS&#65292;&#21033;&#29992;&#25968;&#25454;&#30340;&#21487;&#23398;&#20064;&#24615;&#20316;&#20026;&#36873;&#25321;&#30417;&#30563;&#24494;&#35843;&#25968;&#25454;&#30340;&#20027;&#35201;&#26631;&#20934;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26681;&#25454;&#27169;&#22411;&#30340;&#33021;&#21147;&#23558;&#25968;&#25454;&#36873;&#25321;&#19982;&#27169;&#22411;&#23545;&#40784;&#65292;&#30830;&#20445;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#26159;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#29305;&#23450;&#20219;&#21153;&#30340;&#20808;&#20915;&#26465;&#20214;&#23545;&#40784;&#30340;&#20851;&#38190;&#38454;&#27573;&#12290;&#24494;&#35843;&#25968;&#25454;&#30340;&#36873;&#25321;&#28145;&#21051;&#24433;&#21709;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#20256;&#32479;&#19978;&#20197;&#25968;&#25454;&#36136;&#37327;&#21644;&#20998;&#24067;&#20026;&#22522;&#30784;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SFT&#25968;&#25454;&#36873;&#25321;&#30340;&#19968;&#20010;&#26032;&#32500;&#24230;&#65306;&#21487;&#23398;&#20064;&#24615;&#12290;&#36825;&#20010;&#26032;&#32500;&#24230;&#30340;&#21160;&#26426;&#26159;&#30001;LLM&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#33719;&#24471;&#30340;&#33021;&#21147;&#12290;&#37492;&#20110;&#19981;&#21516;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#20855;&#26377;&#19981;&#21516;&#30340;&#33021;&#21147;&#65292;&#36866;&#21512;&#19968;&#20010;&#27169;&#22411;&#30340;SFT&#25968;&#25454;&#21487;&#33021;&#19981;&#36866;&#21512;&#21478;&#19968;&#20010;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23398;&#20064;&#33021;&#21147;&#36825;&#20010;&#26415;&#35821;&#26469;&#23450;&#20041;&#25968;&#25454;&#23545;&#27169;&#22411;&#36827;&#34892;&#26377;&#25928;&#23398;&#20064;&#30340;&#36866;&#21512;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25439;&#22833;&#30340;SFT&#25968;&#25454;&#36873;&#25321;&#65288;LoBaSS&#65289;&#26041;&#27861;&#65292;&#21033;&#29992;&#25968;&#25454;&#30340;&#21487;&#23398;&#20064;&#24615;&#20316;&#20026;&#36873;&#25321;SFT&#25968;&#25454;&#30340;&#20027;&#35201;&#26631;&#20934;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#32454;&#33268;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#23558;&#25968;&#25454;&#36873;&#25321;&#19982;&#22266;&#26377;&#30340;&#27169;&#22411;&#33021;&#21147;&#23545;&#40784;&#65292;&#30830;&#20445;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites. The selection of fine-tuning data profoundly influences the model's performance, whose principle is traditionally grounded in data quality and distribution. In this paper, we introduce a new dimension in SFT data selection: learnability. This new dimension is motivated by the intuition that SFT unlocks capabilities acquired by a LLM during the pretraining phase. Given that different pretrained models have disparate capabilities, the SFT data appropriate for one may not suit another. Thus, we introduce the term learnability to define the suitability of data for effective learning by the model. We present the Loss Based SFT Data Selection (LoBaSS) method, utilizing data learnability as the principal criterion for the selection SFT data. This method provides a nuanced approach, allowing the alignment of data selection with inherent model capabilities, ensuring op
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#31867;&#30340;&#26080;&#23548;&#25968;&#20248;&#21270;&#31639;&#27861;&#30340;&#21152;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21306;&#22495;&#25910;&#32553;&#27493;&#39588;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;RACE-CARS&#8221;&#30340;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#21306;&#22495;&#25910;&#32553;&#30340;&#21152;&#36895;&#24615;&#36136;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;"RACE-CARS"&#30340;&#39640;&#25928;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#32463;&#39564;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.11036</link><description>&lt;p&gt;
&#22522;&#20110;&#21306;&#22495;&#25910;&#32553;&#30340;&#20998;&#31867;&#20248;&#21270;&#31639;&#27861;&#30340;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
A Region-Shrinking-Based Acceleration for Classification-Based Derivative-Free Optimization. (arXiv:2309.11036v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#31867;&#30340;&#26080;&#23548;&#25968;&#20248;&#21270;&#31639;&#27861;&#30340;&#21152;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21306;&#22495;&#25910;&#32553;&#27493;&#39588;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;RACE-CARS&#8221;&#30340;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#21306;&#22495;&#25910;&#32553;&#30340;&#21152;&#36895;&#24615;&#36136;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;"RACE-CARS"&#30340;&#39640;&#25928;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#32463;&#39564;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#23548;&#25968;&#20248;&#21270;&#31639;&#27861;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#35774;&#35745;&#20248;&#21270;&#38382;&#39064;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#29305;&#21035;&#26159;&#24403;&#26080;&#27861;&#33719;&#21462;&#23548;&#25968;&#20449;&#24687;&#26102;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#31867;&#30340;&#26080;&#23548;&#25968;&#20248;&#21270;&#31639;&#27861;&#30340;&#26694;&#26550;&#12290;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#31216;&#20026;&#20551;&#35774;-&#30446;&#26631;&#30772;&#35010;&#29575;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#35813;&#31867;&#22411;&#31639;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#19978;&#30028;&#12290;&#21463;&#37325;&#26032;&#23457;&#35270;&#30340;&#19978;&#30028;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;RACE-CARS&#8221;&#30340;&#31639;&#27861;&#65292;&#19982;&#8220;SRACOS&#8221;&#65288;Hu et al., 2017&#65289;&#30456;&#27604;&#65292;&#35813;&#31639;&#27861;&#28155;&#21152;&#20102;&#19968;&#20010;&#38543;&#26426;&#21306;&#22495;&#25910;&#32553;&#27493;&#39588;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#21306;&#22495;&#25910;&#32553;&#30340;&#21152;&#36895;&#24615;&#36136;&#12290;&#38024;&#23545;&#21512;&#25104;&#20989;&#25968;&#20197;&#21450;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#40657;&#30418;&#35843;&#20248;&#30340;&#23454;&#39564;&#22312;&#32463;&#39564;&#35777;&#26126;&#20102;&#8220;RACE-CARS&#8221;&#30340;&#25928;&#29575;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#20851;&#20110;&#24341;&#20837;&#36229;&#21442;&#25968;&#30340;&#28040;&#34701;&#23454;&#39564;&#65292;&#25581;&#31034;&#20102;&#8220;RACE-CARS&#8221;&#30340;&#24037;&#20316;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#32463;&#39564;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Derivative-free optimization algorithms play an important role in scientific and engineering design optimization problems, especially when derivative information is not accessible. In this paper, we study the framework of classification-based derivative-free optimization algorithms. By introducing a concept called hypothesis-target shattering rate, we revisit the computational complexity upper bound of this type of algorithms. Inspired by the revisited upper bound, we propose an algorithm named "RACE-CARS", which adds a random region-shrinking step compared with "SRACOS" (Hu et al., 2017).. We further establish a theorem showing the acceleration of region-shrinking. Experiments on the synthetic functions as well as black-box tuning for language-model-as-a-service demonstrate empirically the efficiency of "RACE-CARS". An ablation experiment on the introduced hyperparameters is also conducted, revealing the mechanism of "RACE-CARS" and putting forward an empirical hyperparameter-tuning g
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DTW+S&#30340;&#26032;&#22411;&#27979;&#37327;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#21019;&#24314;&#23616;&#37096;&#36235;&#21183;&#30340;&#30697;&#38453;&#34920;&#31034;&#65292;&#24182;&#24212;&#29992;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#26469;&#35745;&#31639;&#36317;&#31163;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#25429;&#25417;&#23616;&#37096;&#36235;&#21183;&#30456;&#20284;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.03579</link><description>&lt;p&gt;
DTW+S: &#20351;&#29992;&#26377;&#24207;&#23616;&#37096;&#36235;&#21183;&#36827;&#34892;&#22522;&#20110;&#24418;&#29366;&#30340;&#26102;&#38388;&#24207;&#21015;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend. (arXiv:2309.03579v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03579
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DTW+S&#30340;&#26032;&#22411;&#27979;&#37327;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#21019;&#24314;&#23616;&#37096;&#36235;&#21183;&#30340;&#30697;&#38453;&#34920;&#31034;&#65292;&#24182;&#24212;&#29992;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#26469;&#35745;&#31639;&#36317;&#31163;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#25429;&#25417;&#23616;&#37096;&#36235;&#21183;&#30456;&#20284;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#36317;&#31163;&#25110;&#30456;&#20284;&#24230;&#30340;&#27979;&#37327;&#26159;&#35768;&#22810;&#24212;&#29992;&#21253;&#25324;&#20998;&#31867;&#21644;&#32858;&#31867;&#30340;&#22522;&#26412;&#26041;&#38754;&#12290;&#29616;&#26377;&#30340;&#27979;&#37327;&#26041;&#27861;&#21487;&#33021;&#30001;&#20110;&#23616;&#37096;&#36235;&#21183;&#65288;&#24418;&#29366;&#65289;&#32780;&#26080;&#27861;&#25429;&#25417;&#21040;&#30456;&#20284;&#20043;&#22788;&#65292;&#29978;&#33267;&#21487;&#33021;&#20135;&#29983;&#35823;&#23548;&#24615;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24320;&#21457;&#19968;&#31181;&#33021;&#22815;&#23547;&#25214;&#22312;&#30456;&#20284;&#26102;&#38388;&#21608;&#22260;&#21457;&#29983;&#30340;&#30456;&#20284;&#36235;&#21183;&#30340;&#27979;&#37327;&#26041;&#27861;&#65292;&#24182;&#19988;&#23545;&#24212;&#29992;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#26131;&#20110;&#35299;&#37322;&#30340;&#26041;&#27861;&#12290;&#36825;&#23545;&#20110;&#26102;&#38388;&#24207;&#21015;&#20855;&#26377;&#26377;&#24207;&#30340;&#26377;&#24847;&#20041;&#30340;&#23616;&#37096;&#36235;&#21183;&#24207;&#21015;&#30340;&#24212;&#29992;&#29305;&#21035;&#26377;&#29992;&#65292;&#20363;&#22914;&#22312;&#27969;&#34892;&#30149;&#20013;&#65288;&#20174;&#22686;&#38271;&#21040;&#23792;&#20540;&#20877;&#21040;&#20943;&#23569;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27979;&#37327;&#26041;&#27861;&#65292;DTW+S&#65292;&#23427;&#21019;&#24314;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#8220;&#20445;&#25345;&#25509;&#36817;&#24615;&#8221;&#30340;&#30697;&#38453;&#34920;&#31034;&#26102;&#38388;&#24207;&#21015;&#65292;&#20854;&#20013;&#27599;&#19968;&#21015;&#20195;&#34920;&#23616;&#37096;&#36235;&#21183;&#65292;&#28982;&#21518;&#24212;&#29992;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#26469;&#35745;&#31639;&#36825;&#20123;&#30697;&#38453;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25903;&#25345;&#36825;&#31181;&#34920;&#31034;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;DTW+S&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measuring distance or similarity between time-series data is a fundamental aspect of many applications including classification and clustering. Existing measures may fail to capture similarities due to local trends (shapes) and may even produce misleading results. Our goal is to develop a measure that looks for similar trends occurring around similar times and is easily interpretable for researchers in applied domains. This is particularly useful for applications where time-series have a sequence of meaningful local trends that are ordered, such as in epidemics (a surge to an increase to a peak to a decrease). We propose a novel measure, DTW+S, which creates an interpretable "closeness-preserving" matrix representation of the time-series, where each column represents local trends, and then it applies Dynamic Time Warping to compute distances between these matrices. We present a theoretical analysis that supports the choice of this representation. We demonstrate the utility of DTW+S in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;NetHack&#28216;&#25103;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#65292;&#21457;&#29616;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#21487;&#20197;&#25913;&#36827;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#24182;&#24314;&#31435;&#20102;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;IL&#20195;&#29702;&#20154;&#30340;&#24130;&#24459;&#12290;</title><link>http://arxiv.org/abs/2307.09423</link><description>&lt;p&gt;
&#22312;NetHack&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#30340;&#35268;&#27169;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;NetHack&#28216;&#25103;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#65292;&#21457;&#29616;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#21487;&#20197;&#25913;&#36827;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#24182;&#24314;&#31435;&#20102;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;IL&#20195;&#29702;&#20154;&#30340;&#24130;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#20223;&#23398;&#20064; (IL) &#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#24378;&#22823;&#65292;&#20294;&#35768;&#22810;&#30740;&#31350;&#21457;&#29616;&#23427;&#24448;&#24448;&#19981;&#33021;&#23436;&#20840;&#24674;&#22797;&#20986;&#28508;&#22312;&#30340;&#19987;&#23478;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#27809;&#26377;&#28145;&#20837;&#25506;&#31350;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#30340;&#25193;&#22823;&#22312;&#20854;&#20013;&#30340;&#20316;&#29992;&#12290;&#21463;&#26368;&#36817;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702; (NLP) &#39046;&#22495;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#22312;&#37027;&#37324;&#8220;&#25193;&#22823;&#35268;&#27169;&#8221;&#24050;&#32463;&#23548;&#33268;&#20102;&#36234;&#26469;&#36234;&#26377;&#33021;&#21147;&#30340;&#39046;&#22495;&#29305;&#23450;&#35821;&#35328;&#27169;&#22411; (LLMs)&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20180;&#32454;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#26159;&#21542;&#21487;&#20197;&#22312;&#27169;&#20223;&#23398;&#20064;&#30340;&#35774;&#32622;&#20013;&#24102;&#26469;&#31867;&#20284;&#30340;&#25913;&#36827;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312; NetHack &#28216;&#25103;&#19978;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#31243;&#24207;&#29983;&#25104;&#12289;&#38543;&#26426;&#24615;&#12289;&#38271;&#26399;&#20381;&#36182;&#24615;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29615;&#22659;&#12290;&#25105;&#20204;&#21457;&#29616; IL &#30340;&#25439;&#22833;&#21644;&#24179;&#22343;&#22238;&#25253;&#38543;&#30528;&#35745;&#31639;&#39044;&#31639;&#30340;&#21464;&#21270;&#32780;&#24179;&#28369;&#21464;&#21270;&#19988;&#24378;&#30456;&#20851;&#65292;&#20174;&#32780;&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#26679;&#26412;&#25968;&#37327;&#26041;&#38754;&#20026;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;&#30340; IL &#20195;&#29702;&#20154;&#30340;&#35745;&#31639;&#39044;&#31639;&#24314;&#31435;&#20102;&#24130;&#24459;&#12290;&#25105;&#20204;&#39044;&#27979;&#24182;&#35757;&#32451;&#20102;&#20960;&#20010;&#20855;&#26377; IL &#30340;NetHack&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where "scaling up" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#22522;&#32447;&#30340;&#26032;&#22411;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#39564;&#35777;&#22240;&#26524;&#22270;&#30340;&#27491;&#30830;&#24615;&#24182;&#25351;&#23548;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.09565</link><description>&lt;p&gt;
&#22522;&#20110;&#32622;&#25442;&#26816;&#39564;&#30340;&#22240;&#26524;&#22270;&#20551;&#35774;&#39564;&#35777;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Toward Falsifying Causal Graphs Using a Permutation-Based Test. (arXiv:2305.09565v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#22522;&#32447;&#30340;&#26032;&#22411;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#39564;&#35777;&#22240;&#26524;&#22270;&#30340;&#27491;&#30830;&#24615;&#24182;&#25351;&#23548;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31995;&#32479;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#23545;&#20110;&#35299;&#37322;&#21644;&#25511;&#21046;&#20854;&#34892;&#20026;&#33267;&#20851;&#37325;&#35201;&#12290;&#20294;&#26159;&#65292;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#22270;&#38656;&#35201;&#24456;&#22810;&#19981;&#24635;&#26159;&#29616;&#23454;&#30340;&#24378;&#20551;&#35774;&#12290;&#23545;&#20110;&#39046;&#22495;&#19987;&#23478;&#26469;&#35828;&#65292;&#24456;&#38590;&#34920;&#36798;&#22240;&#26524;&#22270;&#12290;&#22240;&#27492;&#65292;&#22312;&#23558;&#22240;&#26524;&#22270;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#20043;&#21069;&#65292;&#23450;&#37327;&#35780;&#20272;&#22240;&#26524;&#22270;&#30340;&#20248;&#21155;&#30340;&#24230;&#37327;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#26816;&#26597;&#12290;&#29616;&#26377;&#30340;&#24230;&#37327;&#25552;&#20379;&#20102;&#19968;&#20010;&#32477;&#23545;&#25968;&#37327;&#30340;&#22240;&#26524;&#22270;&#19982;&#35266;&#23519;&#25968;&#25454;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#32780;&#27809;&#26377;&#22522;&#30784;&#32447;&#65292;&#20174;&#19994;&#20154;&#21592;&#38656;&#35201;&#22238;&#31572;&#26377;&#22810;&#23569;&#36825;&#26679;&#30340;&#19981;&#19968;&#33268;&#24615;&#26159;&#21487;&#25509;&#21463;&#25110;&#39044;&#26399;&#30340;&#36825;&#19968;&#38590;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#30340;&#26367;&#20195;&#22522;&#32447;&#12290;&#36890;&#36807;&#23558;&#19981;&#19968;&#33268;&#24615;&#30340;&#25968;&#37327;&#19982;&#26367;&#20195;&#22522;&#32447;&#19978;&#30340;&#25968;&#37327;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#35299;&#37322;&#30340;&#24230;&#37327;&#65292;&#25429;&#25417;&#26377;&#21521;&#26080;&#29615;&#22270;&#26159;&#21542;&#26174;&#33879;&#36866;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the causal relationships among the variables of a system is paramount to explain and control its behaviour. Inferring the causal graph from observational data without interventions, however, requires a lot of strong assumptions that are not always realistic. Even for domain experts it can be challenging to express the causal graph. Therefore, metrics that quantitatively assess the goodness of a causal graph provide helpful checks before using it in downstream tasks. Existing metrics provide an absolute number of inconsistencies between the graph and the observed data, and without a baseline, practitioners are left to answer the hard question of how many such inconsistencies are acceptable or expected. Here, we propose a novel consistency metric by constructing a surrogate baseline through node permutations. By comparing the number of inconsistencies with those on the surrogate baseline, we derive an interpretable metric that captures whether the DAG fits significantly bet
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#25345;&#32493;&#21516;&#35843;&#25216;&#26415;&#22312;&#25429;&#25417;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#38271;&#31243;&#22270;&#24615;&#36136;&#26041;&#38754;&#34920;&#29616;&#20986;&#30340;&#39640;&#34920;&#36798;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.09826</link><description>&lt;p&gt;
&#25345;&#32493;&#21516;&#35843;&#22312;&#22270;&#23398;&#20064;&#20013;&#30340;&#34920;&#36798;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Expressivity of Persistent Homology in Graph Learning. (arXiv:2302.09826v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#25345;&#32493;&#21516;&#35843;&#25216;&#26415;&#22312;&#25429;&#25417;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#38271;&#31243;&#22270;&#24615;&#36136;&#26041;&#38754;&#34920;&#29616;&#20986;&#30340;&#39640;&#34920;&#36798;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#35745;&#31639;&#25299;&#25169;&#23398;&#20013;&#30340;&#19968;&#39033;&#25216;&#26415;&#65292;&#25345;&#32493;&#21516;&#35843;&#23637;&#29616;&#20986;&#22312;&#22270;&#20998;&#31867;&#26041;&#38754;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#23427;&#33021;&#22815;&#36890;&#36807;&#39640;&#38454;&#25299;&#25169;&#29305;&#24449;&#8212;&#8212;&#22914;&#20219;&#24847;&#38271;&#24230;&#30340;&#29615;&#8212;&#8212;&#20197;&#21450;&#22810;&#23610;&#24230;&#25299;&#25169;&#25551;&#36848;&#31526;&#25429;&#25417;&#38271;&#31243;&#22270;&#24615;&#36136;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#8212;&#8212;&#22914;&#20998;&#23376;&#8212;&#8212;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25345;&#32493;&#21516;&#35843;&#30340;&#29702;&#35770;&#24615;&#36136;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#23578;&#26410;&#24471;&#21040;&#27491;&#24335;&#35780;&#20272;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#25552;&#20379;&#25345;&#32493;&#21516;&#35843;&#22312;&#22270;&#20013;&#30340;&#31616;&#35201;&#20171;&#32461;&#20197;&#21450;&#23545;&#20854;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34920;&#36798;&#24615;&#36827;&#34892;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#24357;&#21512;&#35745;&#31639;&#25299;&#25169;&#23398;&#21644;&#22270;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology, a technique from computational topology, has recently shown strong empirical performance in the context of graph classification. Being able to capture long range graph properties via higher-order topological features, such as cycles of arbitrary length, in combination with multi-scale topological descriptors, has improved predictive performance for data sets with prominent topological structures, such as molecules. At the same time, the theoretical properties of persistent homology have not been formally assessed in this context. This paper intends to bridge the gap between computational topology and graph machine learning by providing a brief introduction to persistent homology in the context of graphs, as well as a theoretical discussion and empirical analysis of its expressivity for graph learning tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#20449;&#24687;&#20960;&#20309;&#26500;&#36896;&#20102;&#32447;&#24615;&#20960;&#20046;&#27431;&#20960;&#37324;&#24471;&#27969;&#24418;&#65292;&#36890;&#36807;&#24341;&#20837;&#20559;&#24494;&#20998;&#26041;&#31243;Ricci&#27969;&#65292;&#35299;&#20915;&#20102;&#31163;&#25955;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#26799;&#24230;&#26080;&#31351;&#25110;&#38646;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.03390</link><description>&lt;p&gt;
&#22312;Ricci&#27969;&#19979;&#23398;&#20064;&#31163;&#25955;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Discretized Neural Networks under Ricci Flow. (arXiv:2302.03390v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03390
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#20449;&#24687;&#20960;&#20309;&#26500;&#36896;&#20102;&#32447;&#24615;&#20960;&#20046;&#27431;&#20960;&#37324;&#24471;&#27969;&#24418;&#65292;&#36890;&#36807;&#24341;&#20837;&#20559;&#24494;&#20998;&#26041;&#31243;Ricci&#27969;&#65292;&#35299;&#20915;&#20102;&#31163;&#25955;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#26799;&#24230;&#26080;&#31351;&#25110;&#38646;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#30001;&#20302;&#31934;&#24230;&#26435;&#37325;&#21644;&#28608;&#27963;&#20989;&#25968;&#26500;&#25104;&#30340;&#31163;&#25955;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30001;&#20110;&#38750;&#21487;&#24494;&#20998;&#31163;&#25955;&#20989;&#25968;&#32780;&#36973;&#21463;&#26080;&#31351;&#25110;&#38646;&#26799;&#24230;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#38024;&#23545;&#27492;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#25226; STE&#36817;&#20284;&#26799;&#24230;&#30475;&#20316;&#25972;&#20307;&#20559;&#24046;&#30340;&#24230;&#37327;&#25200;&#21160;&#65292;&#36890;&#36807;&#23545;&#20598;&#29702;&#35770;&#23558;&#20854;&#30475;&#20316;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#24230;&#37327;&#25200;&#21160;&#65292;&#24182;&#22312;&#20449;&#24687;&#20960;&#20309;&#30340;&#22522;&#30784;&#19978;&#20026; DNN&#26500;&#36896;&#20102;&#32447;&#24615;&#20960;&#20046;&#27431;&#20960;&#37324;&#24471;&#65288;LNE&#65289;&#27969;&#24418;&#20197;&#22788;&#29702;&#25200;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider Discretized Neural Networks (DNNs) consisting of low-precision weights and activations, which suffer from either infinite or zero gradients due to the non-differentiable discrete function in the training process. In this case, most training-based DNNs employ the standard Straight-Through Estimator (STE) to approximate the gradient w.r.t. discrete values. However, the STE gives rise to the problem of gradient mismatch, due to the perturbations of the approximated gradient. To address this problem, this paper reveals that this mismatch can be viewed as a metric perturbation in a Riemannian manifold through the lens of duality theory. Further, on the basis of the information geometry, we construct the Linearly Nearly Euclidean (LNE) manifold for DNNs as a background to deal with perturbations. By introducing a partial differential equation on metrics, i.e., the Ricci flow, we prove the dynamical stability and convergence of the LNE metric with the $L^2$-norm per
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#22914;&#20309;&#26356;&#26032;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#26469;&#25351;&#23548;&#24178;&#39044;&#12290;&#20316;&#32773;&#25552;&#20986;&#20351;&#29992;&#30041;&#32622;&#38598;&#30340;&#26041;&#24335;&#36827;&#34892;&#26356;&#26032;&#65292;&#36890;&#36807;&#25214;&#21040;&#30041;&#32622;&#38598;&#30340;&#21512;&#36866;&#22823;&#23567;&#21487;&#20197;&#20445;&#35777;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#25968;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#24635;&#25104;&#26412;&#22686;&#38271;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2202.06374</link><description>&lt;p&gt;
&#38024;&#23545;&#39044;&#27979;&#27169;&#22411;&#26356;&#26032;&#30340;&#30041;&#32622;&#38598;
&lt;/p&gt;
&lt;p&gt;
Holdouts set for predictive model updating. (arXiv:2202.06374v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06374
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#22914;&#20309;&#26356;&#26032;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#26469;&#25351;&#23548;&#24178;&#39044;&#12290;&#20316;&#32773;&#25552;&#20986;&#20351;&#29992;&#30041;&#32622;&#38598;&#30340;&#26041;&#24335;&#36827;&#34892;&#26356;&#26032;&#65292;&#36890;&#36807;&#25214;&#21040;&#30041;&#32622;&#38598;&#30340;&#21512;&#36866;&#22823;&#23567;&#21487;&#20197;&#20445;&#35777;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#25968;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#24635;&#25104;&#26412;&#22686;&#38271;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22797;&#26434;&#30340;&#29615;&#22659;&#20013;&#65292;&#22914;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#65292;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#22312;&#25351;&#23548;&#24178;&#39044;&#26041;&#38754;&#36215;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#26356;&#26032;&#29992;&#20110;&#25351;&#23548;&#24178;&#39044;&#30340;&#39118;&#38505;&#35780;&#20998;&#21487;&#33021;&#23548;&#33268;&#20559;&#24046;&#39118;&#38505;&#20272;&#35745;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#8220;&#30041;&#32622;&#38598;&#8221;&#26469;&#36827;&#34892;&#26356;&#26032;-&#30041;&#32622;&#38598;&#26159;&#19968;&#20010;&#19981;&#25509;&#21463;&#39118;&#38505;&#35780;&#20998;&#25351;&#23548;&#24178;&#39044;&#30340;&#20154;&#32676;&#30340;&#23376;&#38598;&#12290;&#22312;&#30041;&#32622;&#38598;&#30340;&#22823;&#23567;&#19978;&#21462;&#24471;&#24179;&#34913;&#26159;&#20851;&#38190;&#65292;&#20197;&#30830;&#20445;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#26368;&#22823;&#38480;&#24230;&#22320;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#20351;&#24471;&#24635;&#25104;&#26412;&#21487;&#20197;&#20197;$O\left(N^{2/3}\right)$&#30340;&#36895;&#24230;&#22686;&#38271;&#65292;&#20854;&#20013;$N$&#26159;&#20154;&#21475;&#35268;&#27169;&#65292;&#24182;&#19988;&#35748;&#20026;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#27809;&#26377;&#31454;&#20105;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#36890;&#36807;&#23450;&#20041;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20123;&#26465;&#20214;&#65292;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#30830;&#23450;&#26368;&#20339;&#30041;&#32622;&#38598;&#22823;&#23567;&#65288;OHS&#65289;&#65292;&#24182;&#24341;&#20837;&#21442;&#25968;&#21270;&#21644;&#21322;&#21442;&#25968;&#21270;&#31639;&#27861;&#26469;&#20272;&#35745;OHS&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#26368;&#26032;&#39118;&#38505;&#35780;&#20998;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In complex settings, such as healthcare, predictive risk scores play an increasingly crucial role in guiding interventions. However, directly updating risk scores used to guide intervention can lead to biased risk estimates. To address this, we propose updating using a `holdout set' - a subset of the population that does not receive interventions guided by the risk score. Striking a balance in the size of the holdout set is essential, to ensure good performance of the updated risk score whilst minimising the number of held out samples. We prove that this approach enables total costs to grow at a rate $O\left(N^{2/3}\right)$ for a population of size $N$, and argue that in general circumstances there is no competitive alternative. By defining an appropriate loss function, we describe conditions under which an optimal holdout size (OHS) can be readily identified, and introduce parametric and semi-parametric algorithms for OHS estimation, demonstrating their use on a recent risk score for 
&lt;/p&gt;</description></item></channel></rss>