<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#34987;&#24402;&#32435;&#21040;&#20998;&#31867;&#25511;&#21046;&#21407;&#29702;&#26694;&#26550;&#20013;&#65292;&#36890;&#36807;&#21442;&#25968;&#21270;&#30340;&#20809;&#23398;&#30456;&#20114;&#20316;&#29992;&#65292;&#23637;&#31034;&#20102;&#26032;&#30340;&#26500;&#36896;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.02688</link><description>&lt;p&gt;
&#22312;&#20998;&#31867;&#25511;&#21046;&#21407;&#29702;&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning in Categorical Cybernetics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02688
&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#34987;&#24402;&#32435;&#21040;&#20998;&#31867;&#25511;&#21046;&#21407;&#29702;&#26694;&#26550;&#20013;&#65292;&#36890;&#36807;&#21442;&#25968;&#21270;&#30340;&#20809;&#23398;&#30456;&#20114;&#20316;&#29992;&#65292;&#23637;&#31034;&#20102;&#26032;&#30340;&#26500;&#36896;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#31181;&#20027;&#35201;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#31639;&#27861;&#36866;&#29992;&#20110;&#20998;&#31867;&#25511;&#21046;&#21407;&#29702;&#26694;&#26550;&#65292;&#21363;&#21442;&#25968;&#21270;&#30340;&#21452;&#21521;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#27492;&#21069;&#30340;&#24037;&#20316;&#22522;&#30784;&#19978;&#23637;&#24320;&#65292;&#20854;&#20013;&#25105;&#20204;&#23637;&#31034;&#20102;&#20215;&#20540;&#36845;&#20195;&#21487;&#20197;&#36890;&#36807;&#39044;&#21512;&#25104;&#29305;&#23450;&#30340;&#20809;&#23398;&#34920;&#31034;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#26500;&#36896;&#27010;&#36848;&#22914;&#19979;&#65306;&#65288;1&#65289;&#25105;&#20204;&#23558;Bellman&#31639;&#23376;&#25193;&#23637;&#21040;&#36866;&#29992;&#20110;&#21160;&#20316;&#20540;&#20989;&#25968;&#24182;&#20381;&#36182;&#20110;&#26679;&#26412;&#30340;&#21442;&#25968;&#21270;&#20809;&#23398;&#12290; &#65288;2&#65289;&#25105;&#20204;&#24212;&#29992;&#19968;&#20010;&#21487;&#34920;&#31034;&#30340;&#36870;&#21464;&#23376;&#20989;&#23376;&#65292;&#24471;&#21040;&#19968;&#20010;&#24212;&#29992;Bellman&#36845;&#20195;&#30340;&#21442;&#25968;&#21270;&#20989;&#25968;&#12290;&#65288;3&#65289;&#35813;&#21442;&#25968;&#21270;&#20989;&#25968;&#25104;&#20026;&#21478;&#19968;&#20010;&#20195;&#34920;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#20809;&#23398;&#30340;&#21453;&#21521;&#20256;&#36882;&#65292;&#36890;&#36807;&#20195;&#29702;&#19982;&#29615;&#22659;&#36827;&#34892;&#20132;&#20114;&#12290;&#22240;&#27492;&#65292;&#22312;&#25105;&#20204;&#30340;&#26500;&#36896;&#20013;&#65292;&#21442;&#25968;&#21270;&#20809;&#23398;&#20197;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#24335;&#20986;&#29616;&#65292;&#20854;&#20013;&#19968;&#31181;&#25104;&#20026;&#21478;&#19968;&#31181;&#30340;&#19968;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02688v1 Announce Type: new  Abstract: We show that several major algorithms of reinforcement learning (RL) fit into the framework of categorical cybernetics, that is to say, parametrised bidirectional processes. We build on our previous work in which we show that value iteration can be represented by precomposition with a certain optic. The outline of the main construction in this paper is: (1) We extend the Bellman operators to parametrised optics that apply to action-value functions and depend on a sample. (2) We apply a representable contravariant functor, obtaining a parametrised function that applies the Bellman iteration. (3) This parametrised function becomes the backward pass of another parametrised optic that represents the model, which interacts with an environment via an agent. Thus, parametrised optics appear in two different ways in our construction, with one becoming part of the other. As we show, many of the major classes of algorithms in RL can be seen as dif
&lt;/p&gt;</description></item><item><title>&#24191;&#20041;&#26799;&#24230;&#19979;&#38477;&#30456;&#23545;&#20110;Cartesian reverse derivative categories (CRDCs)&#30340;&#36890;&#29992;&#23458;&#35266;&#20989;&#25968;&#35825;&#23548;&#20986;&#19968;&#20010;&#36229;&#22270;&#20989;&#23376;&#65292;&#23558;&#20248;&#21270;&#38382;&#39064;&#26144;&#23556;&#21040;&#21160;&#21147;&#31995;&#32479;&#65292;&#20026;&#20998;&#24067;&#24335;&#20248;&#21270;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#36884;&#24452;&#12290;</title><link>https://arxiv.org/abs/2403.19845</link><description>&lt;p&gt;
&#24191;&#20041;&#26799;&#24230;&#19979;&#38477;&#26159;&#19968;&#20010;&#36229;&#22270;&#20989;&#23376;
&lt;/p&gt;
&lt;p&gt;
Generalized Gradient Descent is a Hypergraph Functor
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19845
&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#26799;&#24230;&#19979;&#38477;&#30456;&#23545;&#20110;Cartesian reverse derivative categories (CRDCs)&#30340;&#36890;&#29992;&#23458;&#35266;&#20989;&#25968;&#35825;&#23548;&#20986;&#19968;&#20010;&#36229;&#22270;&#20989;&#23376;&#65292;&#23558;&#20248;&#21270;&#38382;&#39064;&#26144;&#23556;&#21040;&#21160;&#21147;&#31995;&#32479;&#65292;&#20026;&#20998;&#24067;&#24335;&#20248;&#21270;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Cartesian reverse derivative categories (CRDCs)&#25552;&#20379;&#20102;&#23545;&#21453;&#21521;&#23548;&#25968;&#30340;&#20844;&#29702;&#21270;&#27867;&#21270;&#65292;&#36825;&#20351;&#24471;&#21487;&#20197;&#23558;&#30456;&#23545;&#20110;&#24191;&#27867;&#31867;&#38382;&#39064;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#24191;&#20041;&#31867;&#27604;&#24212;&#29992;&#20110;&#32463;&#20856;&#20248;&#21270;&#31639;&#27861;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#30456;&#23545;&#20110;&#32473;&#23450;CRDC&#30340;&#24191;&#20041;&#26799;&#24230;&#19979;&#38477;&#35825;&#23548;&#20986;&#19968;&#20010;&#20174;&#20248;&#21270;&#38382;&#39064;&#30340;&#36229;&#22270;&#33539;&#30068;&#21040;&#21160;&#21147;&#31995;&#32479;&#30340;&#36229;&#22270;&#20989;&#23376;&#12290;&#35813;&#20989;&#23376;&#30340;&#23450;&#20041;&#22495;&#30001;&#23458;&#35266;&#20989;&#25968;&#32452;&#25104;&#65292;&#36825;&#20123;&#23458;&#35266;&#20989;&#25968;&#22312;&#20219;&#24847;CRDC&#19979;&#37117;&#26159;&#36890;&#29992;&#30340;&#65292;&#24182;&#19988;&#26159;&#24320;&#25918;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#21464;&#37327;&#20849;&#20139;&#19982;&#20854;&#20182;&#36825;&#26679;&#30340;&#23458;&#35266;&#20989;&#25968;&#32452;&#21512;&#12290;&#23545;&#26144;&#22495;&#31867;&#20284;&#22320;&#34987;&#25351;&#23450;&#20026;&#22522;&#30784;CRDC&#30340;&#36890;&#29992;&#21644;&#24320;&#25918;&#21160;&#24577;&#31995;&#32479;&#31867;&#21035;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#36229;&#22270;&#20989;&#23376;&#22914;&#20309;&#35825;&#23548;&#20986;&#19968;&#20010;&#38024;&#23545;&#20219;&#24847;&#38382;&#39064;&#30340;&#20998;&#24067;&#24335;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19845v1 Announce Type: cross  Abstract: Cartesian reverse derivative categories (CRDCs) provide an axiomatic generalization of the reverse derivative, which allows generalized analogues of classic optimization algorithms such as gradient descent to be applied to a broad class of problems. In this paper, we show that generalized gradient descent with respect to a given CRDC induces a hypergraph functor from a hypergraph category of optimization problems to a hypergraph category of dynamical systems. The domain of this functor consists of objective functions that are 1) general in the sense that they are defined with respect to an arbitrary CRDC, and 2) open in that they are decorated spans that can be composed with other such objective functions via variable sharing. The codomain is specified analogously as a category of general and open dynamical systems for the underlying CRDC. We describe how the hypergraph functor induces a distributed optimization algorithm for arbitrary
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#26159;&#20855;&#26377;&#19968;&#23450;&#28508;&#21147;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.16851</link><description>&lt;p&gt;
ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can ChatGPT predict article retraction based on Twitter mentions?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#26159;&#20855;&#26377;&#19968;&#23450;&#28508;&#21147;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#26377;&#38382;&#39064;&#30340;&#30740;&#31350;&#25991;&#31456;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26681;&#25454;&#34987;&#25764;&#22238;&#25991;&#31456;&#22312;Twitter&#19978;&#30340;&#25552;&#21450;&#26159;&#21542;&#33021;&#22815;&#22312;&#25991;&#31456;&#34987;&#25764;&#22238;&#21069;&#21457;&#20986;&#20449;&#21495;&#65292;&#20174;&#32780;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;&#20998;&#26512;&#20102;&#21253;&#25324;3,505&#31687;&#24050;&#25764;&#22238;&#25991;&#31456;&#21450;&#20854;&#30456;&#20851;Twitter&#25552;&#21450;&#22312;&#20869;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#20351;&#29992;&#31895;&#31961;&#31934;&#30830;&#21305;&#37197;&#26041;&#27861;&#33719;&#21462;&#30340;&#20855;&#26377;&#31867;&#20284;&#29305;&#24449;&#30340;3,505&#31687;&#26410;&#25764;&#22238;&#25991;&#31456;&#12290;&#36890;&#36807;&#22235;&#31181;&#39044;&#27979;&#26041;&#27861;&#35780;&#20272;&#20102;Twitter&#25552;&#21450;&#22312;&#39044;&#27979;&#25991;&#31456;&#25764;&#22238;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#25163;&#21160;&#26631;&#27880;&#12289;&#20851;&#38190;&#35789;&#35782;&#21035;&#12289;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;ChatGPT&#12290;&#25163;&#21160;&#26631;&#27880;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#30340;&#30830;&#26377;&#34987;&#25764;&#22238;&#30340;&#25991;&#31456;&#65292;&#20854;Twitter&#25552;&#21450;&#21253;&#21547;&#22312;&#25764;&#22238;&#21069;&#21457;&#20986;&#20449;&#21495;&#30340;&#21487;&#35782;&#21035;&#35777;&#25454;&#65292;&#23613;&#31649;&#23427;&#20204;&#21482;&#21344;&#25152;&#26377;&#34987;&#25764;&#22238;&#25991;&#31456;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16851v1 Announce Type: cross  Abstract: Detecting problematic research articles timely is a vital task. This study explores whether Twitter mentions of retracted articles can signal potential problems with the articles prior to retraction, thereby playing a role in predicting future retraction of problematic articles. A dataset comprising 3,505 retracted articles and their associated Twitter mentions is analyzed, alongside 3,505 non-retracted articles with similar characteristics obtained using the Coarsened Exact Matching method. The effectiveness of Twitter mentions in predicting article retraction is evaluated by four prediction methods, including manual labelling, keyword identification, machine learning models, and ChatGPT. Manual labelling results indicate that there are indeed retracted articles with their Twitter mentions containing recognizable evidence signaling problems before retraction, although they represent only a limited share of all retracted articles with 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#26159;&#20851;&#20110;&#22312;&#23391;&#21152;&#25289;&#22269;&#32972;&#26223;&#19979;&#23545;&#30007;&#24615;&#23478;&#24237;&#26292;&#21147;&#36827;&#34892;&#24320;&#21019;&#24615;&#25506;&#32034;&#65292;&#25581;&#31034;&#20102;&#30007;&#24615;&#21463;&#23475;&#32773;&#30340;&#23384;&#22312;&#12289;&#27169;&#24335;&#21644;&#28508;&#22312;&#22240;&#32032;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#25991;&#29486;&#23545;&#30007;&#24615;&#21463;&#23475;&#32773;&#30740;&#31350;&#31354;&#30333;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.15594</link><description>&lt;p&gt;
&#36890;&#36807;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#21644;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#27934;&#35265;&#20998;&#26512;&#30007;&#24615;&#23478;&#24237;&#26292;&#21147;
&lt;/p&gt;
&lt;p&gt;
Analyzing Male Domestic Violence through Exploratory Data Analysis and Explainable Machine Learning Insights
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15594
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#26159;&#20851;&#20110;&#22312;&#23391;&#21152;&#25289;&#22269;&#32972;&#26223;&#19979;&#23545;&#30007;&#24615;&#23478;&#24237;&#26292;&#21147;&#36827;&#34892;&#24320;&#21019;&#24615;&#25506;&#32034;&#65292;&#25581;&#31034;&#20102;&#30007;&#24615;&#21463;&#23475;&#32773;&#30340;&#23384;&#22312;&#12289;&#27169;&#24335;&#21644;&#28508;&#22312;&#22240;&#32032;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#25991;&#29486;&#23545;&#30007;&#24615;&#21463;&#23475;&#32773;&#30740;&#31350;&#31354;&#30333;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23478;&#24237;&#26292;&#21147;&#36890;&#24120;&#34987;&#35270;&#20026;&#19968;&#20010;&#20851;&#20110;&#22899;&#24615;&#21463;&#23475;&#32773;&#30340;&#24615;&#21035;&#38382;&#39064;&#65292;&#22312;&#36817;&#24180;&#26469;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#23613;&#31649;&#26377;&#36825;&#31181;&#20851;&#27880;&#65292;&#23391;&#21152;&#25289;&#22269;&#29305;&#21035;&#26159;&#30007;&#24615;&#21463;&#23475;&#32773;&#20173;&#28982;&#20027;&#35201;&#34987;&#24573;&#35270;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20195;&#34920;&#20102;&#22312;&#23391;&#21152;&#25289;&#22269;&#32972;&#26223;&#19979;&#23545;&#30007;&#24615;&#23478;&#24237;&#26292;&#21147;&#65288;MDV&#65289;&#36825;&#19968;&#26410;&#34987;&#20805;&#20998;&#25506;&#35752;&#39046;&#22495;&#30340;&#24320;&#21019;&#24615;&#25506;&#32034;&#65292;&#25581;&#31034;&#20102;&#20854;&#26222;&#36941;&#24615;&#12289;&#27169;&#24335;&#21644;&#28508;&#22312;&#22240;&#32032;&#12290;&#29616;&#26377;&#25991;&#29486;&#20027;&#35201;&#24378;&#35843;&#23478;&#24237;&#26292;&#21147;&#24773;&#22659;&#20013;&#22899;&#24615;&#30340;&#21463;&#23475;&#65292;&#23548;&#33268;&#23545;&#30007;&#24615;&#21463;&#23475;&#32773;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#20174;&#23391;&#21152;&#25289;&#22269;&#20027;&#35201;&#22478;&#24066;&#25910;&#38598;&#20102;&#25968;&#25454;&#65292;&#24182;&#36827;&#34892;&#20102;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#20197;&#20102;&#35299;&#28508;&#22312;&#21160;&#24577;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;11&#31181;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65288;&#21253;&#25324;&#40664;&#35748;&#21644;&#20248;&#21270;&#30340;&#36229;&#21442;&#25968;&#65289;&#12289;2&#31181;&#28145;&#24230;&#23398;&#20064;&#21644;4&#31181;&#38598;&#25104;&#27169;&#22411;&#12290;&#23613;&#31649;&#37319;&#29992;&#20102;&#21508;&#31181;&#26041;&#27861;&#65292;CatBoost&#30001;&#20110;&#20854;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15594v1 Announce Type: cross  Abstract: Domestic violence, which is often perceived as a gendered issue among female victims, has gained increasing attention in recent years. Despite this focus, male victims of domestic abuse remain primarily overlooked, particularly in Bangladesh. Our study represents a pioneering exploration of the underexplored realm of male domestic violence (MDV) within the Bangladeshi context, shedding light on its prevalence, patterns, and underlying factors. Existing literature predominantly emphasizes female victimization in domestic violence scenarios, leading to an absence of research on male victims. We collected data from the major cities of Bangladesh and conducted exploratory data analysis to understand the underlying dynamics. We implemented 11 traditional machine learning models with default and optimized hyperparameters, 2 deep learning, and 4 ensemble models. Despite various approaches, CatBoost has emerged as the top performer due to its 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.02080</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#29992;&#20110;&#39640;&#25928;&#37319;&#26679;Boltzmann&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Energy based diffusion generator for efficient sampling of Boltzmann distributions. (arXiv:2401.02080v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02080
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#37319;&#26679;&#27169;&#22411;&#37319;&#29992;&#31867;&#20284;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#65292;&#21033;&#29992;&#35299;&#30721;&#22120;&#23558;&#26469;&#33258;&#31616;&#21333;&#20998;&#24067;&#30340;&#28508;&#22312;&#21464;&#37327;&#36716;&#25442;&#20026;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#38543;&#26426;&#21464;&#37327;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#32534;&#30721;&#22120;&#12290;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#23545;&#22797;&#26434;&#20998;&#24067;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#29983;&#25104;&#26679;&#26412;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#20934;&#30830;&#21464;&#20998;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#30340;&#35299;&#30721;&#22120;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel sampler called the energy based diffusion generator for generating samples from arbitrary target distributions. The sampling model employs a structure similar to a variational autoencoder, utilizing a decoder to transform latent variables from a simple distribution into random variables approximating the target distribution, and we design an encoder based on the diffusion model. Leveraging the powerful modeling capacity of the diffusion model for complex distributions, we can obtain an accurate variational estimate of the Kullback-Leibler divergence between the distributions of the generated samples and the target. Moreover, we propose a decoder based on generalized Hamiltonian dynamics to further enhance sampling performance. Through empirical evaluation, we demonstrate the effectiveness of our method across various complex distribution functions, showcasing its superiority compared to existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#27169;&#22411;&#26550;&#26500;&#21644;&#35757;&#32451;&#29615;&#22659;&#23545;&#35757;&#32451;&#26356;&#29615;&#20445;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#25214;&#20986;&#20102;&#33021;&#28304;&#25928;&#29575;&#21644;&#27169;&#22411;&#27491;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.05520</link><description>&lt;p&gt;
DL&#27169;&#22411;&#21644;&#35757;&#32451;&#29615;&#22659;&#23545;&#33021;&#28304;&#28040;&#32791;&#26377;&#24433;&#21709;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do DL models and training environments have an impact on energy consumption?. (arXiv:2307.05520v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#27169;&#22411;&#26550;&#26500;&#21644;&#35757;&#32451;&#29615;&#22659;&#23545;&#35757;&#32451;&#26356;&#29615;&#20445;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#25214;&#20986;&#20102;&#33021;&#28304;&#25928;&#29575;&#21644;&#27169;&#22411;&#27491;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#30340;&#27491;&#30830;&#24615;&#21644;&#25512;&#29702;&#26102;&#38388;&#24615;&#33021;&#19978;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#24456;&#23569;&#26377;&#20851;&#20110;&#35757;&#32451;DL&#27169;&#22411;&#24102;&#26469;&#24040;&#22823;&#30899;&#36275;&#36857;&#30340;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#20998;&#26512;&#27169;&#22411;&#26550;&#26500;&#21644;&#35757;&#32451;&#29615;&#22659;&#23545;&#35757;&#32451;&#26356;&#29615;&#20445;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#30446;&#26631;&#20998;&#20026;&#20004;&#20010;&#30740;&#31350;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20998;&#26512;&#27169;&#22411;&#26550;&#26500;&#23545;&#23454;&#29616;&#26356;&#29615;&#20445;&#27169;&#22411;&#21516;&#26102;&#20445;&#25345;&#27491;&#30830;&#24615;&#22312;&#26368;&#20339;&#27700;&#24179;&#30340;&#24433;&#21709;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30740;&#31350;&#35757;&#32451;&#29615;&#22659;&#23545;&#29983;&#25104;&#26356;&#29615;&#20445;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35843;&#26597;&#36825;&#20123;&#20851;&#31995;&#65292;&#25105;&#20204;&#22312;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#25910;&#38598;&#20102;&#19982;&#33021;&#28304;&#25928;&#29575;&#21644;&#27169;&#22411;&#27491;&#30830;&#24615;&#30456;&#20851;&#30340;&#22810;&#20010;&#25351;&#26631;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#27169;&#22411;&#26550;&#26500;&#22312;&#27979;&#37327;&#33021;&#28304;&#25928;&#29575;&#21644;&#27169;&#22411;&#27491;&#30830;&#24615;&#26041;&#38754;&#30340;&#26435;&#34913;&#65292;&#20197;&#21450;&#23427;&#20204;&#19982;&#35757;&#32451;&#29615;&#22659;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#23454;&#39564;&#24179;&#21488;&#19978;&#36827;&#34892;&#20102;&#36825;&#39033;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current research in the computer vision field mainly focuses on improving Deep Learning (DL) correctness and inference time performance. However, there is still little work on the huge carbon footprint that has training DL models. This study aims to analyze the impact of the model architecture and training environment when training greener computer vision models. We divide this goal into two research questions. First, we analyze the effects of model architecture on achieving greener models while keeping correctness at optimal levels. Second, we study the influence of the training environment on producing greener models. To investigate these relationships, we collect multiple metrics related to energy efficiency and model correctness during the models' training. Then, we outline the trade-offs between the measured energy efficiency and the models' correctness regarding model architecture, and their relationship with the training environment. We conduct this research in the context of a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#30740;&#31350;&#20102;&#22312;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#36807;&#31243;&#20013;&#22914;&#20309;&#35782;&#21035;&#20986;&#24178;&#20928;&#26631;&#31614;&#26679;&#26412;&#65292;&#21457;&#29616;&#27599;&#20010;&#23454;&#20363;&#26377;&#33267;&#23569; $2C-1$ &#20010;&#26377;&#22122;&#22768;&#26631;&#31614;&#26102;&#65292;&#35813;&#38382;&#39064;&#25165;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#20010;&#35201;&#27714;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#22122;&#22768;&#26631;&#31614;&#20998;&#24067;&#33258;&#21160;&#29983;&#25104;&#39069;&#22806;&#30340;&#22122;&#22768;&#26631;&#31614;&#20197;&#25552;&#39640;&#21487;&#35782;&#21035;&#24615;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2301.01405</link><description>&lt;p&gt;
&#38754;&#21521;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#30340;&#21487;&#35782;&#21035;&#24615;&#65306;&#22810;&#39033;&#24335;&#28151;&#21512;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards the Identifiability in Noisy Label Learning: A Multinomial Mixture Approach. (arXiv:2301.01405v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.01405
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#30740;&#31350;&#20102;&#22312;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#36807;&#31243;&#20013;&#22914;&#20309;&#35782;&#21035;&#20986;&#24178;&#20928;&#26631;&#31614;&#26679;&#26412;&#65292;&#21457;&#29616;&#27599;&#20010;&#23454;&#20363;&#26377;&#33267;&#23569; $2C-1$ &#20010;&#26377;&#22122;&#22768;&#26631;&#31614;&#26102;&#65292;&#35813;&#38382;&#39064;&#25165;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#20010;&#35201;&#27714;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#22122;&#22768;&#26631;&#31614;&#20998;&#24067;&#33258;&#21160;&#29983;&#25104;&#39069;&#22806;&#30340;&#22122;&#22768;&#26631;&#31614;&#20197;&#25552;&#39640;&#21487;&#35782;&#21035;&#24615;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26377;&#22122;&#22768;&#26631;&#31614;&#20013;&#36827;&#34892;&#23398;&#20064;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#25198;&#28436;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#35282;&#33394;&#12290;&#26368;&#26377;&#21069;&#36884;&#30340;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#26041;&#27861;&#20381;&#36182;&#20110;&#20174;&#24102;&#26377;&#22122;&#22768;&#27880;&#37322;&#30340;&#25968;&#25454;&#38598;&#20013;&#35782;&#21035;&#20986;&#24178;&#20928;&#26631;&#31614;&#26679;&#26412;&#12290;&#36825;&#31181;&#35782;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#20256;&#32479;&#30340;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#38382;&#39064;&#20551;&#23450;&#27599;&#20010;&#23454;&#20363;&#21482;&#26377;&#19968;&#20010;&#26377;&#22122;&#22768;&#26631;&#31614;&#65292;&#26159;&#19981;&#21487;&#35782;&#21035;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#27809;&#26377;&#38468;&#21152;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#29702;&#35770;&#19978;&#26080;&#27861;&#20272;&#35745;&#20986;&#24178;&#20928;&#26631;&#31614;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20351;&#29992;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#27491;&#24335;&#35843;&#26597;&#36825;&#20010;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#65292;&#20197;&#30830;&#23450;&#20351;&#38382;&#39064;&#21487;&#35782;&#21035;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#22914;&#26524;&#27599;&#20010;&#23454;&#20363;&#26377;&#33267;&#23569; $2C-1$ &#20010;&#26377;&#22122;&#22768;&#26631;&#31614;&#65292;&#20854;&#20013; C &#26159;&#31867;&#30340;&#25968;&#37327;&#65292;&#21017;&#35813;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#38382;&#39064;&#23601;&#21464;&#24471;&#21487;&#35782;&#21035;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#20010;&#35201;&#27714;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#27599;&#20010;&#23454;&#20363;&#39069;&#22806;&#30340; $2C-2$ &#25163;&#21160;&#27880;&#37322;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#22122;&#22768;&#26631;&#31614;&#20998;&#24067;&#26469;&#33258;&#21160;&#29983;&#25104;&#39069;&#22806;&#30340;&#22122;&#22768;&#26631;&#31614;&#12290;&#36825;&#20123;&#39069;&#22806;&#30340;&#22122;&#22768;&#26631;&#31614;&#25552;&#39640;&#20102;&#21487;&#35782;&#21035;&#24615;&#65292;&#20351;&#24471;&#21487;&#20197;&#26080;&#38656;&#20219;&#20309;&#20854;&#20182;&#20551;&#35774;&#26469;&#20272;&#35745;&#24178;&#20928;&#26631;&#31614;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#22522;&#20934;&#21644;&#24212;&#29992;&#31243;&#24207;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning from noisy labels (LNL) plays a crucial role in deep learning. The most promising LNL methods rely on identifying clean-label samples from a dataset with noisy annotations. Such an identification is challenging because the conventional LNL problem, which assumes a single noisy label per instance, is non-identifiable, i.e., clean labels cannot be estimated theoretically without additional heuristics. In this paper, we aim to formally investigate this identifiability issue using multinomial mixture models to determine the constraints that make the problem identifiable. Specifically, we discover that the LNL problem becomes identifiable if there are at least $2C - 1$ noisy labels per instance, where $C$ is the number of classes. To meet this requirement without relying on additional $2C - 2$ manual annotations per instance, we propose a method that automatically generates additional noisy labels by estimating the noisy label distribution based on nearest neighbours. These additio
&lt;/p&gt;</description></item></channel></rss>