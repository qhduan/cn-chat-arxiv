<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#32479;&#19968;&#31070;&#32463;&#20869;&#26680;(UNK)&#65292;&#21487;&#20197;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#24182;&#22312;&#26377;&#38480;&#30340;&#23398;&#20064;&#27493;&#39588;&#19979;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;NTK&#30340;&#34892;&#20026;&#65292;&#24403;&#23398;&#20064;&#27493;&#39588;&#36924;&#36817;&#26080;&#31351;&#22823;&#26102;&#25910;&#25947;&#21040;NNGP&#12290;</title><link>https://arxiv.org/abs/2403.17467</link><description>&lt;p&gt;
&#19968;&#20010;&#32479;&#19968;&#30340;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20869;&#26680;
&lt;/p&gt;
&lt;p&gt;
A Unified Kernel for Neural Network Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#32479;&#19968;&#31070;&#32463;&#20869;&#26680;(UNK)&#65292;&#21487;&#20197;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#24182;&#22312;&#26377;&#38480;&#30340;&#23398;&#20064;&#27493;&#39588;&#19979;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;NTK&#30340;&#34892;&#20026;&#65292;&#24403;&#23398;&#20064;&#27493;&#39588;&#36924;&#36817;&#26080;&#31351;&#22823;&#26102;&#25910;&#25947;&#21040;NNGP&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#21313;&#24180;&#26469;&#65292;&#20154;&#20204;&#23545;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21644;&#20869;&#26680;&#23398;&#20064;&#20043;&#38388;&#30340;&#21306;&#21035;&#21644;&#32852;&#31995;&#34920;&#29616;&#20986;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;&#26368;&#36817;&#30340;&#36827;&#23637;&#22312;&#36830;&#25509;&#26080;&#38480;&#23485;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#26041;&#38754;&#21462;&#24471;&#20102;&#29702;&#35770;&#19978;&#30340;&#36827;&#23637;&#12290;&#20986;&#29616;&#20102;&#20004;&#31181;&#20027;&#27969;&#26041;&#27861;&#65306;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;(NNGP)&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;(NTK)&#12290;&#21069;&#32773;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20195;&#34920;&#20102;&#38646;&#38454;&#26680;&#65292;&#32780;&#21518;&#32773;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#20999;&#21521;&#31354;&#38388;&#65292;&#26159;&#31532;&#19968;&#38454;&#26680;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32479;&#19968;&#31070;&#32463;&#20869;&#26680;(UNK)&#65292;&#35813;&#20869;&#26680;&#34920;&#24449;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#26799;&#24230;&#19979;&#38477;&#21644;&#21442;&#25968;&#21021;&#22987;&#21270;&#20013;&#30340;&#23398;&#20064;&#21160;&#24577;&#12290;&#25152;&#25552;&#20986;&#30340;UNK&#20869;&#26680;&#20445;&#25345;&#20102;NNGP&#21644;NTK&#30340;&#26497;&#38480;&#29305;&#24615;&#65292;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;NTK&#30340;&#34892;&#20026;&#65292;&#20294;&#26377;&#26377;&#38480;&#30340;&#23398;&#20064;&#27493;&#39588;&#65292;&#24182;&#19988;&#24403;&#23398;&#20064;&#27493;&#39588;&#25509;&#36817;&#26080;&#31351;&#22823;&#26102;&#25910;&#25947;&#21040;NNGP&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20174;&#29702;&#35770;&#19978;&#23545;UNK&#20869;&#26680;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17467v1 Announce Type: cross  Abstract: Past decades have witnessed a great interest in the distinction and connection between neural network learning and kernel learning. Recent advancements have made theoretical progress in connecting infinite-wide neural networks and Gaussian processes. Two predominant approaches have emerged: the Neural Network Gaussian Process (NNGP) and the Neural Tangent Kernel (NTK). The former, rooted in Bayesian inference, represents a zero-order kernel, while the latter, grounded in the tangent space of gradient descents, is a first-order kernel. In this paper, we present the Unified Neural Kernel (UNK), which characterizes the learning dynamics of neural networks with gradient descents and parameter initialization. The proposed UNK kernel maintains the limiting properties of both NNGP and NTK, exhibiting behaviors akin to NTK with a finite learning step and converging to NNGP as the learning step approaches infinity. Besides, we also theoreticall
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.04022</link><description>&lt;p&gt;
&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A General Theory for Kernel Packets: from state space model to compactly supported basis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04022
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#29366;&#24577;&#31354;&#38388;&#65288;SS&#65289;&#27169;&#22411;&#20844;&#24335;&#21487;&#20197;&#23558;&#20854;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#38477;&#20302;&#21040;O&#65288;n&#65289;&#65288;n&#20026;&#25968;&#25454;&#28857;&#20010;&#25968;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;m&#32500;&#30340;GP&#30340;SS&#27169;&#22411;&#20844;&#24335;&#31561;&#20215;&#20110;&#25105;&#20204;&#24341;&#20837;&#30340;&#19968;&#20010;&#27010;&#24565;&#65292;&#31216;&#20026;&#36890;&#29992;&#21491;&#26680;&#20998;&#32452;&#65288;KP&#65289;&#65306;&#19968;&#31181;&#29992;&#20110;GP&#21327;&#26041;&#24046;&#20989;&#25968;K&#30340;&#21464;&#25442;&#65292;&#20351;&#24471;&#23545;&#20110;&#20219;&#24847;$t \leq t_1$&#65292;$0 \leq j \leq m-1$&#21644;$m+1$&#20010;&#36830;&#32493;&#28857;$t_i$&#65292;&#37117;&#28385;&#36275;$\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$&#65292;&#20854;&#20013;${D}_t^{(j)}f(t)$&#34920;&#31034;&#22312;$t$&#19978;&#20316;&#29992;&#30340;&#31532;j&#38454;&#23548;&#25968;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;GP&#30340;&#21521;&#21518;SS&#27169;&#22411;&#20844;&#24335;&#65292;&#24471;&#21040;&#20102;&#19979;&#19968;&#20010;$m$&#20010;&#36830;&#32493;&#28857;&#30340;&#24038;&#26680;&#20998;&#32452;&#30340;&#27010;&#24565;&#65306;$\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$&#65292;&#23545;&#20110;&#20219;&#24847;$t\geq t_{2m}$&#12290;&#36890;&#36807;&#32467;&#21512;&#24038;&#21491;&#26680;&#20998;&#32452;&#65292;&#21487;&#20197;&#35777;&#26126;&#36825;&#20123;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#36866;&#24403;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#65306;&#23545;&#20110;&#20219;&#24847;$t\not\in(t_0,t_{2m})$&#21644;$j=0,\cdots,m-1$&#65292;$\phi^{(j)}(t)=0$&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to O(n) for n data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance function $K$ such that $\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \leq t_1$, 0 $\leq j \leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th order derivative acting on $t$. We extend this idea to the backward SS model formulation of the GP, leading to the concept of the left KP for next $m$ consecutive points: $\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ compactly supported KP functions: $\phi^{(j)}(t)=0$ for any $t\not\in(t_0,t_{2m})$ and $j=0,\cdots,m-1$
&lt;/p&gt;</description></item><item><title>EERO &#26159;&#19968;&#31181;&#26089;&#26399;&#36864;&#20986;&#19982;&#25298;&#32477;&#36873;&#39033;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#20010;&#20998;&#31867;&#22120;&#26469;&#36873;&#25321;&#27599;&#20010;&#23454;&#20363;&#30340;&#36864;&#20986;&#22836;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#20998;&#31867;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#21487;&#20197;&#26377;&#25928;&#31649;&#29702;&#39044;&#31639;&#20998;&#37197;&#24182;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03779</link><description>&lt;p&gt;
EERO: &#26089;&#26399;&#36864;&#20986;&#19982;&#25298;&#32477;&#36873;&#39033;&#29992;&#20110;&#26377;&#38480;&#39044;&#31639;&#19979;&#30340;&#39640;&#25928;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
EERO: Early Exit with Reject Option for Efficient Classification with limited budget
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03779
&lt;/p&gt;
&lt;p&gt;
EERO &#26159;&#19968;&#31181;&#26089;&#26399;&#36864;&#20986;&#19982;&#25298;&#32477;&#36873;&#39033;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#20010;&#20998;&#31867;&#22120;&#26469;&#36873;&#25321;&#27599;&#20010;&#23454;&#20363;&#30340;&#36864;&#20986;&#22836;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#20998;&#31867;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#21487;&#20197;&#26377;&#25928;&#31649;&#29702;&#39044;&#31639;&#20998;&#37197;&#24182;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#19981;&#26029;&#22797;&#26434;&#21270;&#35201;&#27714;&#21019;&#26032;&#30340;&#26041;&#27861;&#26469;&#26377;&#25928;&#31649;&#29702;&#35745;&#31639;&#36164;&#28304;&#12290;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#26159;&#26089;&#26399;&#36864;&#20986;&#31574;&#30053;&#65292;&#36890;&#36807;&#25552;&#20379;&#32553;&#30701;&#31616;&#21333;&#25968;&#25454;&#23454;&#20363;&#22788;&#29702;&#36335;&#24452;&#30340;&#26426;&#21046;&#65292;&#23454;&#29616;&#33258;&#36866;&#24212;&#35745;&#31639;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EERO&#65292;&#19968;&#31181;&#23558;&#26089;&#26399;&#36864;&#20986;&#38382;&#39064;&#36716;&#21270;&#20026;&#20351;&#29992;&#20855;&#26377;&#25298;&#32477;&#36873;&#39033;&#30340;&#22810;&#20010;&#20998;&#31867;&#22120;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#20415;&#26356;&#22909;&#22320;&#36873;&#25321;&#27599;&#20010;&#23454;&#20363;&#30340;&#36864;&#20986;&#22836;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26435;&#37325;&#32858;&#21512;&#26469;&#26657;&#20934;&#19981;&#21516;&#22836;&#37096;&#36864;&#20986;&#30340;&#27010;&#29575;&#65292;&#20197;&#20445;&#35777;&#19968;&#20010;&#22266;&#23450;&#30340;&#39044;&#31639;&#12290;&#25105;&#20204;&#32771;&#34385;&#36125;&#21494;&#26031;&#39118;&#38505;&#12289;&#39044;&#31639;&#32422;&#26463;&#21644;&#22836;&#37096;&#29305;&#23450;&#39044;&#31639;&#28040;&#32791;&#31561;&#22240;&#32032;&#12290;&#36890;&#36807;&#22312;Cifar&#21644;ImageNet&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;ResNet-18&#27169;&#22411;&#21644;ConvNext&#26550;&#26500;&#36827;&#34892;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#33021;&#26377;&#25928;&#31649;&#29702;&#39044;&#31639;&#20998;&#37197;&#65292;&#36824;&#33021;&#25552;&#39640;&#36807;&#24230;&#32771;&#34385;&#22330;&#26223;&#20013;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing complexity of advanced machine learning models requires innovative approaches to manage computational resources effectively. One such method is the Early Exit strategy, which allows for adaptive computation by providing a mechanism to shorten the processing path for simpler data instances. In this paper, we propose EERO, a new methodology to translate the problem of early exiting to a problem of using multiple classifiers with reject option in order to better select the exiting head for each instance. We calibrate the probabilities of exiting at the different heads using aggregation with exponential weights to guarantee a fixed budget .We consider factors such as Bayesian risk, budget constraints, and head-specific budget consumption. Experimental results, conducted using a ResNet-18 model and a ConvNext architecture on Cifar and ImageNet datasets, demonstrate that our method not only effectively manages budget allocation but also enhances accuracy in overthinking scenar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#26041;&#27861;&#65292;&#30452;&#25509;&#20851;&#32852;&#25968;&#25454;&#21644;&#24178;&#20928;&#26631;&#31614;&#65292;&#36890;&#36807;&#20351;&#29992;&#21028;&#21035;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#38544;&#24335;&#20272;&#35745;&#29983;&#25104;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22797;&#26434;&#20844;&#24335;&#12289;&#38590;&#20197;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#26080;&#20449;&#24687;&#20808;&#39564;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.01184</link><description>&lt;p&gt;
&#36890;&#36807;&#37096;&#20998;&#26631;&#31614;&#20808;&#39564;&#30340;&#38544;&#24335;&#21028;&#21035;&#36924;&#36817;&#36827;&#34892;&#29983;&#25104;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior. (arXiv:2308.01184v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01184
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#26041;&#27861;&#65292;&#30452;&#25509;&#20851;&#32852;&#25968;&#25454;&#21644;&#24178;&#20928;&#26631;&#31614;&#65292;&#36890;&#36807;&#20351;&#29992;&#21028;&#21035;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#38544;&#24335;&#20272;&#35745;&#29983;&#25104;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22797;&#26434;&#20844;&#24335;&#12289;&#38590;&#20197;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#26080;&#20449;&#24687;&#20808;&#39564;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#24050;&#32463;&#20351;&#29992;&#20102;&#21028;&#21035;&#27169;&#22411;&#21644;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#30740;&#31350;&#12290;&#23613;&#31649;&#21028;&#21035;&#27169;&#22411;&#30001;&#20110;&#20854;&#31616;&#21333;&#30340;&#24314;&#27169;&#21644;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#35757;&#32451;&#36807;&#31243;&#32780;&#22312;&#35813;&#39046;&#22495;&#21344;&#20027;&#23548;&#22320;&#20301;&#65292;&#20294;&#29983;&#25104;&#27169;&#22411;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#20998;&#35299;&#24178;&#20928;&#21644;&#22122;&#22768;&#26631;&#31614;&#65292;&#24182;&#25913;&#21892;&#26631;&#31614;&#36716;&#25442;&#30697;&#38453;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#26041;&#27861;&#20351;&#29992;&#20102;&#22797;&#26434;&#30340;&#20844;&#24335;&#26469;&#26368;&#22823;&#21270;&#22122;&#22768;&#26631;&#31614;&#21644;&#25968;&#25454;&#30340;&#32852;&#21512;&#20284;&#28982;&#65292;&#36825;&#21482;&#38388;&#25509;&#20248;&#21270;&#20102;&#19982;&#25968;&#25454;&#21644;&#24178;&#20928;&#26631;&#31614;&#30456;&#20851;&#30340;&#24863;&#20852;&#36259;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#24456;&#38590;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#20542;&#21521;&#20110;&#20351;&#29992;&#26080;&#20449;&#24687;&#30340;&#24178;&#20928;&#26631;&#31614;&#20808;&#39564;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29983;&#25104;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#19977;&#20010;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#20248;&#21270;&#26041;&#27861;&#65292;&#30452;&#25509;&#20851;&#32852;&#25968;&#25454;&#21644;&#24178;&#20928;&#26631;&#31614;&#12290;&#20854;&#27425;&#65292;&#36890;&#36807;&#20351;&#29992;&#21028;&#21035;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#38544;&#24335;&#20272;&#35745;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The learning with noisy labels has been addressed with both discriminative and generative models. Although discriminative models have dominated the field due to their simpler modeling and more efficient computational training processes, generative models offer a more effective means of disentangling clean and noisy labels and improving the estimation of the label transition matrix. However, generative approaches maximize the joint likelihood of noisy labels and data using a complex formulation that only indirectly optimizes the model of interest associating data and clean labels. Additionally, these approaches rely on generative models that are challenging to train and tend to use uninformative clean label priors. In this paper, we propose a new generative noisy-label learning approach that addresses these three issues. First, we propose a new model optimisation that directly associates data and clean labels. Second, the generative model is implicitly estimated using a discriminative m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Weisfeiler-Leman (WL)&#31639;&#27861;&#30340;&#23616;&#37096;&#29256;&#26412;&#65292;&#29992;&#20110;&#35299;&#20915;&#23376;&#22270;&#35745;&#25968;&#38382;&#39064;&#24182;&#25552;&#39640;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#21516;&#26102;&#65292;&#20063;&#32473;&#20986;&#20102;&#19968;&#20123;&#26102;&#38388;&#21644;&#31354;&#38388;&#25928;&#29575;&#26356;&#39640;&#30340;$k-$WL&#21464;&#20307;&#21644;&#20998;&#35010;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2305.19659</link><description>&lt;p&gt;
&#21033;&#29992;&#23616;&#37096;&#21270;&#25552;&#39640;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Improving Expressivity of Graph Neural Networks using Localization. (arXiv:2305.19659v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Weisfeiler-Leman (WL)&#31639;&#27861;&#30340;&#23616;&#37096;&#29256;&#26412;&#65292;&#29992;&#20110;&#35299;&#20915;&#23376;&#22270;&#35745;&#25968;&#38382;&#39064;&#24182;&#25552;&#39640;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#21516;&#26102;&#65292;&#20063;&#32473;&#20986;&#20102;&#19968;&#20123;&#26102;&#38388;&#21644;&#31354;&#38388;&#25928;&#29575;&#26356;&#39640;&#30340;$k-$WL&#21464;&#20307;&#21644;&#20998;&#35010;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Weisfeiler-Leman (WL)&#31639;&#27861;&#30340;&#23616;&#37096;&#29256;&#26412;&#65292;&#26088;&#22312;&#22686;&#21152;&#34920;&#36798;&#33021;&#21147;&#24182;&#20943;&#23569;&#35745;&#31639;&#36127;&#25285;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#23376;&#22270;&#35745;&#25968;&#38382;&#39064;&#65292;&#24182;&#20026;&#20219;&#24847;$k$&#32473;&#20986;$k-$WL&#30340;&#23616;&#37096;&#29256;&#26412;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;Local $k-$WL&#30340;&#20316;&#29992;&#65292;&#24182;&#35777;&#26126;&#20854;&#27604;$k-$WL&#26356;&#20855;&#34920;&#29616;&#21147;&#65292;&#24182;&#19988;&#33267;&#22810;&#19982;$(k+1)-$WL&#19968;&#26679;&#20855;&#26377;&#34920;&#29616;&#21147;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20123;&#27169;&#24335;&#30340;&#29305;&#24449;&#65292;&#22914;&#26524;&#20004;&#20010;&#22270;&#26159;Local $k-$WL&#31561;&#20215;&#30340;&#65292;&#21017;&#23427;&#20204;&#30340;&#23376;&#22270;&#21644;&#35825;&#23548;&#23376;&#22270;&#30340;&#35745;&#25968;&#26159;&#19981;&#21464;&#30340;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;$k-$WL&#30340;&#20004;&#20010;&#21464;&#20307;&#65306;&#23618;$k-$WL&#21644;&#36882;&#24402;$k-$WL&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#25928;&#29575;&#27604;&#22312;&#25972;&#20010;&#22270;&#19978;&#24212;&#29992;$k-$WL&#26356;&#39640;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#35010;&#25216;&#26415;&#65292;&#20351;&#29992;$1-$WL&#21363;&#21487;&#20445;&#35777;&#25152;&#26377;&#22823;&#23567;&#19981;&#36229;&#36807;4&#30340;&#35825;&#23548;&#23376;&#22270;&#30340;&#20934;&#30830;&#35745;&#25968;&#12290;&#30456;&#21516;&#30340;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;$k&gt;1$&#36827;&#19968;&#27493;&#25193;&#23637;&#21040;&#26356;&#22823;&#30340;&#27169;&#24335;&#12290;&#25105;&#20204;&#36824;&#23558;Local $k-$WL&#30340;&#34920;&#29616;&#21147;&#19982;&#20854;&#20182;GNN&#23618;&#27425;&#32467;&#26500;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose localized versions of Weisfeiler-Leman (WL) algorithms in an effort to both increase the expressivity, as well as decrease the computational overhead. We focus on the specific problem of subgraph counting and give localized versions of $k-$WL for any $k$. We analyze the power of Local $k-$WL and prove that it is more expressive than $k-$WL and at most as expressive as $(k+1)-$WL. We give a characterization of patterns whose count as a subgraph and induced subgraph are invariant if two graphs are Local $k-$WL equivalent. We also introduce two variants of $k-$WL: Layer $k-$WL and recursive $k-$WL. These methods are more time and space efficient than applying $k-$WL on the whole graph. We also propose a fragmentation technique that guarantees the exact count of all induced subgraphs of size at most 4 using just $1-$WL. The same idea can be extended further for larger patterns using $k&gt;1$. We also compare the expressive power of Local $k-$WL with other GNN hierarc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;(NNs)&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#30340;&#36817;&#20284;&#26041;&#27861;&#65292;&#31216;&#20026;&#23433;&#20840;&#22686;&#24378;&#65292;&#21487;&#20197;&#20351;&#35299;&#20915;&#26041;&#26696;&#22312;&#32447;&#21487;&#34892;&#24182;&#20855;&#26377;&#25910;&#25947;&#21644;&#32422;&#26463;&#26465;&#20214;&#30340;&#30830;&#23450;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.09575</link><description>&lt;p&gt;
&#22522;&#20110;&#23433;&#20840;&#22686;&#24378;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#32447;&#24615;&#36817;&#20284;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Approximate non-linear model predictive control with safety-augmented neural networks. (arXiv:2304.09575v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;(NNs)&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#30340;&#36817;&#20284;&#26041;&#27861;&#65292;&#31216;&#20026;&#23433;&#20840;&#22686;&#24378;&#65292;&#21487;&#20197;&#20351;&#35299;&#20915;&#26041;&#26696;&#22312;&#32447;&#21487;&#34892;&#24182;&#20855;&#26377;&#25910;&#25947;&#21644;&#32422;&#26463;&#26465;&#20214;&#30340;&#30830;&#23450;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#21487;&#20197;&#23454;&#29616;&#23545;&#20110;&#19968;&#33324;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#31283;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#30340;&#28385;&#36275;&#65292;&#20294;&#38656;&#35201;&#36827;&#34892;&#35745;&#31639;&#24320;&#38144;&#24456;&#22823;&#30340;&#22312;&#32447;&#20248;&#21270;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;(NNs)&#23545;&#36825;&#31181;MPC&#25511;&#21046;&#22120;&#30340;&#36817;&#20284;&#65292;&#20197;&#23454;&#29616;&#24555;&#36895;&#30340;&#22312;&#32447;&#35780;&#20272;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23433;&#20840;&#22686;&#24378;&#65292;&#23613;&#31649;&#23384;&#22312;&#36817;&#20284;&#19981;&#20934;&#30830;&#24615;&#65292;&#20294;&#21487;&#20197;&#33719;&#24471;&#25910;&#25947;&#21644;&#32422;&#26463;&#26465;&#20214;&#30340;&#30830;&#23450;&#20445;&#35777;&#12290;&#25105;&#20204;&#20351;&#29992;NN&#36817;&#20284;MPC&#30340;&#25972;&#20010;&#36755;&#20837;&#24207;&#21015;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#22312;&#32447;&#39564;&#35777;&#23427;&#26159;&#21542;&#26159;MPC&#38382;&#39064;&#30340;&#21487;&#34892;&#35299;&#12290;&#24403;&#35813;&#35299;&#20915;&#26041;&#26696;&#19981;&#21487;&#34892;&#25110;&#25104;&#26412;&#26356;&#39640;&#26102;&#65292;&#25105;&#20204;&#22522;&#20110;&#26631;&#20934;MPC&#25216;&#26415;&#23558;NN&#35299;&#20915;&#26041;&#26696;&#26367;&#25442;&#20026;&#23433;&#20840;&#20505;&#36873;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20165;&#38656;&#35201;&#23545;NN&#36827;&#34892;&#19968;&#27425;&#35780;&#20272;&#21644;&#23545;&#36755;&#20837;&#24207;&#21015;&#36827;&#34892;&#22312;&#32447;&#21069;&#21521;&#31215;&#20998;&#65292;&#36825;&#22312;&#36164;&#28304;&#21463;&#38480;&#31995;&#32479;&#19978;&#30340;&#35745;&#31639;&#36895;&#24230;&#24456;&#24555;&#12290;&#25152;&#25552;&#20986;&#30340;&#25511;&#21046;&#26694;&#26550;&#22312;&#19977;&#20010;&#19981;&#21516;&#22797;&#26434;&#24230;&#30340;&#38750;&#32447;&#24615;MPC&#22522;&#20934;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#23637;&#31034;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model predictive control (MPC) achieves stability and constraint satisfaction for general nonlinear systems, but requires computationally expensive online optimization. This paper studies approximations of such MPC controllers via neural networks (NNs) to achieve fast online evaluation. We propose safety augmentation that yields deterministic guarantees for convergence and constraint satisfaction despite approximation inaccuracies. We approximate the entire input sequence of the MPC with NNs, which allows us to verify online if it is a feasible solution to the MPC problem. We replace the NN solution by a safe candidate based on standard MPC techniques whenever it is infeasible or has worse cost. Our method requires a single evaluation of the NN and forward integration of the input sequence online, which is fast to compute on resource-constrained systems. The proposed control framework is illustrated on three non-linear MPC benchmarks of different complexity, demonstrating computational
&lt;/p&gt;</description></item></channel></rss>