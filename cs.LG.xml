<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#24418;&#36716;&#25442;&#27169;&#22411;&#26500;&#24314;&#26041;&#27861;&#65292;&#32467;&#21512;&#29983;&#25104;&#21644;&#21160;&#24577;&#35266;&#28857;&#65292;&#23454;&#29616;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#25512;&#29702;&#65292;&#36890;&#36807;&#21387;&#32553;&#19968;&#32452;&#36716;&#25442;&#25104;&#19968;&#32452;&#35268;&#21017;&#65292;&#20801;&#35768;&#27169;&#22411;&#23637;&#31034;&#36229;&#20986;&#36755;&#20837;&#33539;&#22260;&#30340;&#34892;&#20026;&#12290;</title><link>https://arxiv.org/abs/2404.02692</link><description>&lt;p&gt;
&#22270;&#24418;&#36716;&#25442;&#35268;&#21017;&#30340;&#33258;&#21160;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Automated Inference of Graph Transformation Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02692
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#24418;&#36716;&#25442;&#27169;&#22411;&#26500;&#24314;&#26041;&#27861;&#65292;&#32467;&#21512;&#29983;&#25104;&#21644;&#21160;&#24577;&#35266;&#28857;&#65292;&#23454;&#29616;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#25512;&#29702;&#65292;&#36890;&#36807;&#21387;&#32553;&#19968;&#32452;&#36716;&#25442;&#25104;&#19968;&#32452;&#35268;&#21017;&#65292;&#20801;&#35768;&#27169;&#22411;&#23637;&#31034;&#36229;&#20986;&#36755;&#20837;&#33539;&#22260;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#21629;&#31185;&#23398;&#39046;&#22495;&#21487;&#29992;&#25968;&#25454;&#30340;&#29190;&#28856;&#24615;&#22686;&#38271;&#25512;&#21160;&#20102;&#23545;&#23500;&#26377;&#34920;&#29616;&#21147;&#27169;&#22411;&#21644;&#35745;&#31639;&#26041;&#27861;&#26085;&#30410;&#22686;&#38271;&#30340;&#38656;&#27714;&#12290;&#22270;&#24418;&#36716;&#25442;&#26159;&#19968;&#31181;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#21160;&#24577;&#31995;&#32479;&#27169;&#22411;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22270;&#24418;&#36716;&#25442;&#27169;&#22411;&#26500;&#24314;&#26041;&#27861;&#65292;&#23558;&#29983;&#25104;&#21644;&#21160;&#24577;&#35266;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#25552;&#20379;&#19968;&#20010;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#25512;&#29702;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#25509;&#21463;&#20316;&#20026;&#21160;&#24577;&#23646;&#24615;&#30340;&#36755;&#20837;&#65292;&#32473;&#23450;&#20026;&#30001;&#26174;&#24335;&#36716;&#25442;&#32534;&#30721;&#30340;&#21160;&#24577;&#30340;&#8220;&#24555;&#29031;&#8221;&#65292;&#24182;&#26500;&#24314;&#19968;&#20010;&#20860;&#23481;&#30340;&#27169;&#22411;&#12290;&#33719;&#24471;&#30340;&#27169;&#22411;&#34987;&#20445;&#35777;&#26159;&#26368;&#23567;&#30340;&#65292;&#22240;&#27492;&#23558;&#35813;&#26041;&#27861;&#35268;&#33539;&#20026;&#27169;&#22411;&#21387;&#32553;&#65288;&#23558;&#19968;&#32452;&#36716;&#25442;&#21387;&#32553;&#20026;&#19968;&#32452;&#35268;&#21017;&#65289;&#30340;&#26041;&#27861;&#12290;&#21387;&#32553;&#23545;&#26377;&#25439;&#24773;&#20917;&#24456;&#23485;&#23481;&#65292;&#21363;&#20801;&#35768;&#26500;&#24314;&#30340;&#27169;&#22411;&#23637;&#31034;&#36229;&#20986;&#36755;&#20837;&#36716;&#25442;&#33539;&#22260;&#30340;&#34892;&#20026;&#65292;&#20174;&#32780;&#24314;&#35758;&#23436;&#25104;&#36755;&#20837;&#21160;&#24577;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02692v1 Announce Type: cross  Abstract: The explosion of data available in life sciences is fueling an increasing demand for expressive models and computational methods. Graph transformation is a model for dynamic systems with a large variety of applications. We introduce a novel method of the graph transformation model construction, combining generative and dynamical viewpoints to give a fully automated data-driven model inference method.   The method takes the input dynamical properties, given as a "snapshot" of the dynamics encoded by explicit transitions, and constructs a compatible model. The obtained model is guaranteed to be minimal, thus framing the approach as model compression (from a set of transitions into a set of rules). The compression is permissive to a lossy case, where the constructed model is allowed to exhibit behavior outside of the input transitions, thus suggesting a completion of the input dynamics.   The task of graph transformation model inference i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;&#28151;&#21512;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;HUDS&#65292;&#32467;&#21512;&#20102;&#19981;&#30830;&#23450;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#29992;&#20110;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#21477;&#23376;&#36873;&#25321;&#12290;</title><link>https://arxiv.org/abs/2403.09259</link><description>&lt;p&gt;
&#26159;&#21542;&#32473;&#25968;&#25454;&#36148;&#26631;&#31614;&#65306;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;&#28151;&#21512;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
To Label or Not to Label: Hybrid Active Learning for Neural Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09259
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;&#28151;&#21512;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;HUDS&#65292;&#32467;&#21512;&#20102;&#19981;&#30830;&#23450;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#29992;&#20110;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#21477;&#23376;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#25216;&#26415;&#36890;&#36807;&#20174;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#36873;&#25321;&#26356;&#23567;&#30340;&#20195;&#34920;&#24615;&#23376;&#38598;&#36827;&#34892;&#27880;&#37322;&#65292;&#38477;&#20302;&#20102;&#35757;&#32451;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#65288;NMT&#65289;&#27169;&#22411;&#30340;&#26631;&#35760;&#25104;&#26412;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;HUDS&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;NMT&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#28151;&#21512;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#65292;&#23558;&#19981;&#30830;&#23450;&#24615;&#21644;&#22810;&#26679;&#24615;&#30456;&#32467;&#21512;&#65292;&#20197;&#36827;&#34892;&#21477;&#23376;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09259v1 Announce Type: new  Abstract: Active learning (AL) techniques reduce labeling costs for training neural machine translation (NMT) models by selecting smaller representative subsets from unlabeled data for annotation. Diversity sampling techniques select heterogeneous instances, while uncertainty sampling methods select instances with the highest model uncertainty. Both approaches have limitations - diversity methods may extract varied but trivial examples, while uncertainty sampling can yield repetitive, uninformative instances. To bridge this gap, we propose HUDS, a hybrid AL strategy for domain adaptation in NMT that combines uncertainty and diversity for sentence selection. HUDS computes uncertainty scores for unlabeled sentences and subsequently stratifies them. It then clusters sentence embeddings within each stratum using k-MEANS and computes diversity scores by distance to the centroid. A weighted hybrid score that combines uncertainty and diversity is then us
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#36866;&#24212;&#24615;CNC&#65288;ACNC&#65289;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#33258;&#20027;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#36741;&#21161;&#26426;&#21046;&#65292;&#26088;&#22312;&#32852;&#21512;&#32534;&#25490;&#35745;&#31639;&#21644;&#32593;&#32476;&#36164;&#28304;&#65292;&#28385;&#36275;&#23545;&#21160;&#24577;&#21644;&#22823;&#37327;&#29992;&#25143;&#35831;&#27714;&#30340;&#20005;&#26684;&#35201;&#27714;&#12290;</title><link>https://arxiv.org/abs/2403.07573</link><description>&lt;p&gt;
&#36808;&#21521;&#20855;&#26377;&#21487;&#36866;&#24212;&#24615;&#35745;&#31639;&#21644;&#32593;&#32476;&#34701;&#21512;&#30340;&#21160;&#24577;&#26410;&#26469;&#65288;ACNC&#65289;
&lt;/p&gt;
&lt;p&gt;
Towards a Dynamic Future with Adaptable Computing and Network Convergence (ACNC)
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07573
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#36866;&#24212;&#24615;CNC&#65288;ACNC&#65289;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#33258;&#20027;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#36741;&#21161;&#26426;&#21046;&#65292;&#26088;&#22312;&#32852;&#21512;&#32534;&#25490;&#35745;&#31639;&#21644;&#32593;&#32476;&#36164;&#28304;&#65292;&#28385;&#36275;&#23545;&#21160;&#24577;&#21644;&#22823;&#37327;&#29992;&#25143;&#35831;&#27714;&#30340;&#20005;&#26684;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#36827;6G&#30340;&#32972;&#26223;&#19979;&#65292;&#39044;&#35745;&#20250;&#20986;&#29616;&#23454;&#36136;&#24615;&#30340;&#33539;&#24335;&#36716;&#21464;&#65292;&#31361;&#20986;&#20102;&#30001;&#22823;&#37327;&#36830;&#25509;&#21644;&#20005;&#26684;&#36981;&#23432;&#26381;&#21153;&#36136;&#37327;/&#20307;&#39564;&#65288;QoS/E&#65289;&#20808;&#20915;&#26465;&#20214;&#25152;&#29305;&#24449;&#21270;&#30340;&#20840;&#38754;&#30340;&#19968;&#20999;&#23545;&#19968;&#20999;&#20132;&#20114;&#12290;&#21363;&#23558;&#38754;&#20020;&#30340;&#25361;&#25112;&#28304;&#20110;&#36164;&#28304;&#31232;&#32570;&#65292;&#20419;&#20351;&#26377;&#24847;&#35782;&#22320;&#21521;&#35745;&#31639;-&#32593;&#32476;&#34701;&#21512;&#65288;CNC&#65289;&#36807;&#28193;&#65292;&#20316;&#20026;&#32852;&#21512;&#36164;&#28304;&#32534;&#25490;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#34429;&#28982;&#22522;&#20110;CNC&#30340;&#26426;&#21046;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#20294;&#23427;&#20204;&#22312;&#23454;&#29616;&#26410;&#26469;&#26381;&#21153;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#31867;&#20284;Metaverse&#30340;&#20351;&#29992;&#24773;&#26223;&#20013;&#65292;&#21487;&#33021;&#20250;&#30001;&#20110;&#29992;&#25143;&#12289;&#26381;&#21153;&#21644;&#36164;&#28304;&#19981;&#26029;&#21464;&#21270;&#30340;&#29305;&#24615;&#32780;&#21463;&#21040;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#36866;&#24212;&#24615;CNC&#65288;ACNC&#65289;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#33258;&#20027;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#36741;&#21161;&#26426;&#21046;&#65292;&#26088;&#22312;&#32852;&#21512;&#32534;&#25490;&#35745;&#31639;&#21644;&#32593;&#32476;&#36164;&#28304;&#65292;&#28385;&#36275;&#23545;&#21160;&#24577;&#21644;&#22823;&#37327;&#29992;&#25143;&#35831;&#27714;&#30340;&#20005;&#26684;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07573v1 Announce Type: cross  Abstract: In the context of advancing 6G, a substantial paradigm shift is anticipated, highlighting comprehensive everything-to-everything interactions characterized by numerous connections and stringent adherence to Quality of Service/Experience (QoS/E) prerequisites. The imminent challenge stems from resource scarcity, prompting a deliberate transition to Computing-Network Convergence (CNC) as an auspicious approach for joint resource orchestration. While CNC-based mechanisms have garnered attention, their effectiveness in realizing future services, particularly in use cases like the Metaverse, may encounter limitations due to the continually changing nature of users, services, and resources. Hence, this paper presents the concept of Adaptable CNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for the joint orchestration of computing and network resources, catering to dynamic and voluminous user requests with stringent r
&lt;/p&gt;</description></item><item><title>&#29992;&#21344;&#29992;&#24230;&#27979;&#37327;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#38450;&#27490;&#22870;&#21169;&#27450;&#39575;&#65292;&#36890;&#36807;&#32771;&#34385;&#20195;&#29702;&#19982;&#30495;&#23454;&#22870;&#21169;&#20043;&#38388;&#22823;&#30340;&#29366;&#24577;&#21344;&#29992;&#24230;&#20559;&#24046;&#26469;&#36991;&#20813;&#28508;&#22312;&#30340;&#28798;&#38590;&#21518;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.03185</link><description>&lt;p&gt;
&#29992;&#21344;&#29992;&#24230;&#27979;&#37327;&#27491;&#21017;&#21270;&#38450;&#27490;&#22870;&#21169;&#27450;&#39575;
&lt;/p&gt;
&lt;p&gt;
Preventing Reward Hacking with Occupancy Measure Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03185
&lt;/p&gt;
&lt;p&gt;
&#29992;&#21344;&#29992;&#24230;&#27979;&#37327;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#38450;&#27490;&#22870;&#21169;&#27450;&#39575;&#65292;&#36890;&#36807;&#32771;&#34385;&#20195;&#29702;&#19982;&#30495;&#23454;&#22870;&#21169;&#20043;&#38388;&#22823;&#30340;&#29366;&#24577;&#21344;&#29992;&#24230;&#20559;&#24046;&#26469;&#36991;&#20813;&#28508;&#22312;&#30340;&#28798;&#38590;&#21518;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20195;&#29702;&#26681;&#25454;&#19968;&#20010;&#8220;&#20195;&#29702;&#8221;&#22870;&#21169;&#20989;&#25968;&#65288;&#21487;&#33021;&#26159;&#25163;&#21160;&#25351;&#23450;&#25110;&#23398;&#20064;&#30340;&#65289;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#30456;&#23545;&#20110;&#26410;&#30693;&#30340;&#30495;&#23454;&#22870;&#21169;&#21364;&#34920;&#29616;&#31967;&#31957;&#26102;&#65292;&#23601;&#20250;&#21457;&#29983;&#22870;&#21169;&#27450;&#39575;&#12290;&#30001;&#20110;&#30830;&#20445;&#20195;&#29702;&#21644;&#30495;&#23454;&#22870;&#21169;&#20043;&#38388;&#33391;&#22909;&#23545;&#40784;&#26497;&#20026;&#22256;&#38590;&#65292;&#39044;&#38450;&#22870;&#21169;&#27450;&#39575;&#30340;&#19968;&#31181;&#26041;&#27861;&#26159;&#20445;&#23432;&#22320;&#20248;&#21270;&#20195;&#29702;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#29305;&#21035;&#20851;&#27880;&#20110;&#36890;&#36807;&#24809;&#32602;&#20182;&#20204;&#30340;&#34892;&#20026;&#20998;&#24067;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#26469;&#24378;&#21046;&#35753;&#23398;&#20064;&#21040;&#30340;&#31574;&#30053;&#34920;&#29616;&#31867;&#20284;&#20110;&#8220;&#23433;&#20840;&#8221;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#34892;&#20026;&#20998;&#24067;&#30340;&#27491;&#21017;&#21270;&#24182;&#19981;&#24635;&#26159;&#26377;&#25928;&#65292;&#22240;&#20026;&#22312;&#21333;&#20010;&#29366;&#24577;&#19979;&#34892;&#20026;&#20998;&#24067;&#30340;&#24494;&#23567;&#21464;&#21270;&#21487;&#33021;&#23548;&#33268;&#28508;&#22312;&#30340;&#28798;&#38590;&#24615;&#21518;&#26524;&#65292;&#32780;&#36739;&#22823;&#30340;&#21464;&#21270;&#21487;&#33021;&#24182;&#19981;&#20195;&#34920;&#20219;&#20309;&#21361;&#38505;&#27963;&#21160;&#12290;&#25105;&#20204;&#30340;&#35265;&#35299;&#26159;&#65292;&#24403;&#22870;&#21169;&#27450;&#39575;&#26102;&#65292;&#20195;&#29702;&#35775;&#38382;&#30340;&#29366;&#24577;&#19982;&#23433;&#20840;&#31574;&#30053;&#36798;&#21040;&#30340;&#29366;&#24577;&#25130;&#28982;&#19981;&#21516;&#65292;&#23548;&#33268;&#29366;&#24577;&#21344;&#29992;&#24230;&#30340;&#24040;&#22823;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03185v1 Announce Type: cross  Abstract: Reward hacking occurs when an agent performs very well with respect to a "proxy" reward function (which may be hand-specified or learned), but poorly with respect to the unknown true reward. Since ensuring good alignment between the proxy and true reward is extremely difficult, one approach to prevent reward hacking is optimizing the proxy conservatively. Prior work has particularly focused on enforcing the learned policy to behave similarly to a "safe" policy by penalizing the KL divergence between their action distributions (AD). However, AD regularization doesn't always work well since a small change in action distribution at a single state can lead to potentially calamitous outcomes, while large changes might not be indicative of any dangerous activity. Our insight is that when reward hacking, the agent visits drastically different states from those reached by the safe policy, causing large deviations in state occupancy measure (OM
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#23398;&#20064;&#30446;&#26631;&#33539;&#24335;&#65292;&#36890;&#36807;Y-mapping&#26469;&#25918;&#26494;&#32422;&#26463;&#24182;&#35774;&#35745;&#26032;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#21253;&#25324;&#23398;&#20064;&#22495;&#26080;&#20851;&#30340;&#26465;&#20214;&#29305;&#24449;&#21644;&#26368;&#22823;&#21270;&#21518;&#39564;&#27010;&#29575;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#39033;&#35299;&#20915;&#25918;&#26494;&#32422;&#26463;&#24341;&#36215;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2402.18853</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#24102;&#26377;&#36890;&#29992;&#23398;&#20064;&#30446;&#26631;&#30340;&#22810;&#39046;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Rethinking Multi-domain Generalization with A General Learning Objective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18853
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#23398;&#20064;&#30446;&#26631;&#33539;&#24335;&#65292;&#36890;&#36807;Y-mapping&#26469;&#25918;&#26494;&#32422;&#26463;&#24182;&#35774;&#35745;&#26032;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#21253;&#25324;&#23398;&#20064;&#22495;&#26080;&#20851;&#30340;&#26465;&#20214;&#29305;&#24449;&#21644;&#26368;&#22823;&#21270;&#21518;&#39564;&#27010;&#29575;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#39033;&#35299;&#20915;&#25918;&#26494;&#32422;&#26463;&#24341;&#36215;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#39046;&#22495;&#27867;&#21270;&#65288;mDG&#65289;&#30340;&#26222;&#36941;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#20197;&#22686;&#24378;&#36793;&#38469;&#21040;&#26631;&#31614;&#20998;&#24067;&#26144;&#23556;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;mDG&#25991;&#29486;&#32570;&#20047;&#19968;&#20010;&#36890;&#29992;&#30340;&#23398;&#20064;&#30446;&#26631;&#33539;&#24335;&#65292;&#36890;&#24120;&#23545;&#38745;&#24577;&#30446;&#26631;&#36793;&#38469;&#20998;&#24067;&#26045;&#21152;&#32422;&#26463;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#35758;&#21033;&#29992;&#19968;&#20010;$Y$-mapping&#26469;&#25918;&#26494;&#32422;&#26463;&#12290;&#25105;&#20204;&#37325;&#26032;&#24605;&#32771;&#20102;mDG&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#36890;&#29992;&#23398;&#20064;&#30446;&#26631;&#26469;&#35299;&#37322;&#21644;&#20998;&#26512;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;mDG&#26234;&#24935;&#12290;&#36825;&#20010;&#36890;&#29992;&#30446;&#26631;&#20998;&#20026;&#20004;&#20010;&#21327;&#21516;&#30340;&#30446;&#26631;&#65306;&#23398;&#20064;&#19982;&#22495;&#26080;&#20851;&#30340;&#26465;&#20214;&#29305;&#24449;&#21644;&#26368;&#22823;&#21270;&#19968;&#20010;&#21518;&#39564;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#20004;&#20010;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#39033;&#65292;&#36825;&#20123;&#39033;&#32467;&#21512;&#20102;&#20808;&#39564;&#20449;&#24687;&#24182;&#25233;&#21046;&#20102;&#26080;&#25928;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20943;&#36731;&#20102;&#25918;&#26494;&#32422;&#26463;&#25152;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#20026;&#22495;&#23545;&#40784;&#25552;&#20379;&#20102;&#19968;&#20010;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18853v1 Announce Type: cross  Abstract: Multi-domain generalization (mDG) is universally aimed to minimize the discrepancy between training and testing distributions to enhance marginal-to-label distribution mapping. However, existing mDG literature lacks a general learning objective paradigm and often imposes constraints on static target marginal distributions. In this paper, we propose to leverage a $Y$-mapping to relax the constraint. We rethink the learning objective for mDG and design a new \textbf{general learning objective} to interpret and analyze most existing mDG wisdom. This general objective is bifurcated into two synergistic amis: learning domain-independent conditional features and maximizing a posterior. Explorations also extend to two effective regularization terms that incorporate prior information and suppress invalid causality, alleviating the issues that come with relaxed constraints. We theoretically contribute an upper bound for the domain alignment of 
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#31532;&#19977;&#32500;&#24230;&#65292;&#23558;ROC&#26354;&#32447;&#25552;&#21319;&#20026;ROC&#26354;&#38754;&#65292;&#25552;&#20986;VOROS&#20316;&#20026;2D ROC&#26354;&#32447;&#19979;&#38754;&#31215;&#30340;3D&#27867;&#21270;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#19981;&#21516;&#20998;&#31867;&#22120;&#30340;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.18689</link><description>&lt;p&gt;
VOROS&#65306;&#23558;ROC&#26354;&#32447;&#25552;&#21319;&#21040;3D
&lt;/p&gt;
&lt;p&gt;
The VOROS: Lifting ROC curves to 3D
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18689
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#31532;&#19977;&#32500;&#24230;&#65292;&#23558;ROC&#26354;&#32447;&#25552;&#21319;&#20026;ROC&#26354;&#38754;&#65292;&#25552;&#20986;VOROS&#20316;&#20026;2D ROC&#26354;&#32447;&#19979;&#38754;&#31215;&#30340;3D&#27867;&#21270;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#19981;&#21516;&#20998;&#31867;&#22120;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ROC&#26354;&#32447;&#19979;&#38754;&#31215;&#26159;&#19968;&#20010;&#24120;&#29992;&#30340;&#24230;&#37327;&#65292;&#36890;&#24120;&#29992;&#20110;&#25490;&#21015;&#19981;&#21516;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#30456;&#23545;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#20197;&#21069;&#25152;&#25351;&#20986;&#30340;&#65292;&#24403;&#30495;&#23454;&#31867;&#20540;&#25110;&#35823;&#20998;&#31867;&#25104;&#26412;&#22312;&#20004;&#20010;&#31867;&#21035;&#20043;&#38388;&#39640;&#24230;&#19981;&#24179;&#34913;&#26102;&#65292;&#23427;&#21487;&#33021;&#26080;&#27861;&#20934;&#30830;&#25429;&#25417;&#19981;&#21516;&#20998;&#31867;&#22120;&#30340;&#25928;&#30410;&#12290;&#25105;&#20204;&#24341;&#20837;&#31532;&#19977;&#32500;&#26469;&#25429;&#33719;&#36825;&#20123;&#25104;&#26412;&#65292;&#24182;&#20197;&#19968;&#31181;&#33258;&#28982;&#30340;&#26041;&#24335;&#23558;ROC&#26354;&#32447;&#25552;&#21319;&#20026;ROC&#26354;&#38754;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#26354;&#38754;&#65292;&#24182;&#24341;&#20837;&#20102;VOROS&#65292;&#21363;ROC&#26354;&#38754;&#19978;&#26041;&#30340;&#20307;&#31215;&#65292;&#20316;&#20026;2D ROC&#26354;&#32447;&#19979;&#38754;&#31215;&#30340;3D&#27867;&#21270;&#12290;&#23545;&#20110;&#23384;&#22312;&#39044;&#26399;&#25104;&#26412;&#25110;&#31867;&#21035;&#19981;&#24179;&#34913;&#36793;&#30028;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#38480;&#21046;&#32771;&#34385;&#36866;&#24403;&#23376;&#21306;&#22495;&#30340;ROC&#26354;&#38754;&#30340;&#20307;&#31215;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;VOROS&#22914;&#20309;&#22312;&#32463;&#20856;&#21644;&#29616;&#20195;&#31034;&#20363;&#25968;&#25454;&#38598;&#19978;&#26356;&#22909;&#22320;&#25429;&#25417;&#19981;&#21516;&#20998;&#31867;&#22120;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18689v1 Announce Type: new  Abstract: The area under the ROC curve is a common measure that is often used to rank the relative performance of different binary classifiers. However, as has been also previously noted, it can be a measure that ill-captures the benefits of different classifiers when either the true class values or misclassification costs are highly unbalanced between the two classes. We introduce a third dimension to capture these costs, and lift the ROC curve to a ROC surface in a natural way. We study both this surface and introduce the VOROS, the volume over this ROC surface, as a 3D generalization of the 2D area under the ROC curve. For problems where there are only bounds on the expected costs or class imbalances, we restrict consideration to the volume of the appropriate subregion of the ROC surface. We show how the VOROS can better capture the costs of different classifiers on both a classical and a modern example dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#20027;&#21160;&#25512;&#29702;&#35745;&#31639;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#23618;&#28151;&#21512;&#27169;&#22411;&#65292;&#36890;&#36807;&#32452;&#21512;&#31163;&#25955;&#21644;&#36830;&#32493;&#27169;&#22411;&#20197;&#23454;&#29616;&#28789;&#27963;&#24037;&#20855;&#20351;&#29992;&#65292;&#25511;&#21046;&#21644;&#35268;&#21010;&#12290;&#22312;&#38750;&#24179;&#20961;&#20219;&#21153;&#20013;&#39564;&#35777;&#20102;&#35813;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.10088</link><description>&lt;p&gt;
&#20998;&#23618;&#28151;&#21512;&#24314;&#27169;&#29992;&#20110;&#28789;&#27963;&#24037;&#20855;&#20351;&#29992;
&lt;/p&gt;
&lt;p&gt;
Hierarchical hybrid modeling for flexible tool use
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#20027;&#21160;&#25512;&#29702;&#35745;&#31639;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#23618;&#28151;&#21512;&#27169;&#22411;&#65292;&#36890;&#36807;&#32452;&#21512;&#31163;&#25955;&#21644;&#36830;&#32493;&#27169;&#22411;&#20197;&#23454;&#29616;&#28789;&#27963;&#24037;&#20855;&#20351;&#29992;&#65292;&#25511;&#21046;&#21644;&#35268;&#21010;&#12290;&#22312;&#38750;&#24179;&#20961;&#20219;&#21153;&#20013;&#39564;&#35777;&#20102;&#35813;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#25552;&#20986;&#30340;&#20027;&#21160;&#25512;&#29702;&#35745;&#31639;&#26694;&#26550;&#20013;&#65292;&#31163;&#25955;&#27169;&#22411;&#21487;&#20197;&#19982;&#36830;&#32493;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#20197;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#20915;&#31574;&#12290;&#20174;&#21478;&#19968;&#20010;&#35282;&#24230;&#26469;&#30475;&#65292;&#31616;&#21333;&#30340;&#20195;&#29702;&#21487;&#20197;&#32452;&#21512;&#22312;&#19968;&#36215;&#65292;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#19990;&#30028;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#25105;&#20204;&#22914;&#20309;&#23558;&#36825;&#20004;&#20010;&#29305;&#28857;&#32467;&#21512;&#36215;&#26469;&#23454;&#29616;&#39640;&#25928;&#30340;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26550;&#26500;&#65292;&#30001;&#22810;&#20010;&#28151;&#21512; - &#36830;&#32493;&#21644;&#31163;&#25955; - &#21333;&#20803;&#32452;&#25104;&#65292;&#22797;&#21046;&#20195;&#29702;&#30340;&#37197;&#32622;&#65292;&#30001;&#39640;&#32423;&#31163;&#25955;&#27169;&#22411;&#25511;&#21046;&#65292;&#23454;&#29616;&#21160;&#24577;&#35268;&#21010;&#21644;&#21516;&#27493;&#34892;&#20026;&#12290;&#27599;&#20010;&#23618;&#27425;&#20869;&#37096;&#30340;&#36827;&#19968;&#27493;&#20998;&#35299;&#21487;&#20197;&#20197;&#20998;&#23618;&#26041;&#24335;&#34920;&#31034;&#19982;self&#30456;&#20851;&#30340;&#20854;&#20182;&#20195;&#29702;&#21644;&#23545;&#35937;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#36825;&#31181;&#20998;&#23618;&#28151;&#21512;&#27169;&#22411;&#65306;&#22312;&#25342;&#21462;&#19968;&#20010;&#31227;&#21160;&#24037;&#20855;&#21518;&#21040;&#36798;&#19968;&#20010;&#31227;&#21160;&#29289;&#20307;&#12290;&#36825;&#39033;&#30740;&#31350;&#25193;&#23637;&#20102;&#20197;&#25512;&#29702;&#20026;&#25511;&#21046;&#30340;&#20808;&#21069;&#24037;&#20316;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10088v1 Announce Type: cross  Abstract: In a recent computational framework called active inference, discrete models can be linked to their continuous counterparts to perform decision-making in changing environments. From another perspective, simple agents can be combined to better capture the causal relationships of the world. How can we use these two features together to achieve efficient goal-directed behavior? We present an architecture composed of several hybrid -- continuous and discrete -- units replicating the agent's configuration, controlled by a high-level discrete model that achieves dynamic planning and synchronized behavior. Additional factorizations within each level allow to represent hierarchically other agents and objects in relation to the self. We evaluate this hierarchical hybrid model on a non-trivial task: reaching a moving object after having picked a moving tool. This study extends past work on control as inference and proposes an alternative directi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23558;&#26080;&#22870;&#21169;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#24341;&#20837;&#21040;&#22312;&#32447;&#26426;&#21046;&#35774;&#35745;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#23398;&#20064;&#21160;&#24577;VCG&#26426;&#21046;&#19988;&#20855;&#26377;&#19978;&#30028;&#20026;$\tilde{\mathcal{O}}(T^{2/3})$&#30340;&#36951;&#25022;&#20445;&#35777;&#30340;&#26032;&#39062;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2202.12797</link><description>&lt;p&gt;
&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#23398;&#20064;&#21160;&#24577;&#26426;&#21046;&#65306;&#19968;&#31181;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning Dynamic Mechanisms in Unknown Environments: A Reinforcement Learning Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.12797
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#26080;&#22870;&#21169;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#24341;&#20837;&#21040;&#22312;&#32447;&#26426;&#21046;&#35774;&#35745;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#23398;&#20064;&#21160;&#24577;VCG&#26426;&#21046;&#19988;&#20855;&#26377;&#19978;&#30028;&#20026;$\tilde{\mathcal{O}}(T^{2/3})$&#30340;&#36951;&#25022;&#20445;&#35777;&#30340;&#26032;&#39062;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#26426;&#21046;&#35774;&#35745;&#30740;&#31350;&#20102;&#26426;&#21046;&#35774;&#35745;&#32773;&#22312;&#26102;&#21464;&#29615;&#22659;&#20013;&#24212;&#35813;&#22914;&#20309;&#22312;&#20195;&#29702;&#20043;&#38388;&#20998;&#37197;&#36164;&#28304;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#38382;&#39064;&#65292;&#21363;&#20195;&#29702;&#26681;&#25454;&#26410;&#30693;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#19982;&#26426;&#21046;&#35774;&#35745;&#32773;&#20114;&#21160;&#65292;&#22312;&#36825;&#20010;&#36807;&#31243;&#20013;&#20195;&#29702;&#30340;&#22870;&#21169;&#21644;&#26426;&#21046;&#35774;&#35745;&#32773;&#30340;&#29366;&#24577;&#26681;&#25454;&#19968;&#20010;&#24102;&#26377;&#26410;&#30693;&#22870;&#21169;&#20989;&#25968;&#21644;&#36716;&#31227;&#26680;&#30340;&#24773;&#33410;MDP&#28436;&#21270;&#12290;&#25105;&#20204;&#20851;&#27880;&#22312;&#32447;&#35774;&#32622;&#19979;&#30340;&#32447;&#24615;&#20989;&#25968;&#36817;&#20284;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#22810;&#36718;&#20114;&#21160;&#20013;&#24674;&#22797;&#21160;&#24577;Vickrey-Clarke-Grove(VCG)&#26426;&#21046;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#23558;&#26080;&#22870;&#21169;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;(RL)&#32467;&#21512;&#36827;&#26469;&#65292;&#20197;&#24110;&#21161;&#22312;&#20016;&#23500;&#30340;&#31574;&#30053;&#31354;&#38388;&#20013;&#36827;&#34892;&#25506;&#32034;&#65292;&#20174;&#32780;&#20272;&#35745;&#21160;&#24577;VCG&#26426;&#21046;&#20013;&#30340;&#20215;&#26684;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#36951;&#25022;&#19978;&#30028;&#20026;$\tilde{\mathcal{O}}(T^{2/3})$&#65292;&#24182;&#36827;&#19968;&#27493;&#35774;&#35745;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#20197;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.12797v2 Announce Type: replace  Abstract: Dynamic mechanism design studies how mechanism designers should allocate resources among agents in a time-varying environment. We consider the problem where the agents interact with the mechanism designer according to an unknown Markov Decision Process (MDP), where agent rewards and the mechanism designer's state evolve according to an episodic MDP with unknown reward functions and transition kernels. We focus on the online setting with linear function approximation and propose novel learning algorithms to recover the dynamic Vickrey-Clarke-Grove (VCG) mechanism over multiple rounds of interaction. A key contribution of our approach is incorporating reward-free online Reinforcement Learning (RL) to aid exploration over a rich policy space to estimate prices in the dynamic VCG mechanism. We show that the regret of our proposed method is upper bounded by $\tilde{\mathcal{O}}(T^{2/3})$ and further devise a lower bound to show that our a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BA-SGCL&#30340;&#40065;&#26834;SGNN&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#22270;&#23545;&#27604;&#23398;&#20064;&#21407;&#21017;&#21644;&#24179;&#34913;&#22686;&#24378;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#24102;&#31526;&#21495;&#22270;&#23545;&#25239;&#24615;&#25915;&#20987;&#20013;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#19981;&#21487;&#36870;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.10590</link><description>&lt;p&gt;
Adversarially Robust Signed Graph Contrastive Learning from Balance Augmentation&#65288;&#20174;&#24179;&#34913;&#22686;&#24378;&#20013;&#25552;&#21462;&#23545;&#25239;&#24615;&#40065;&#26834;&#30340;&#24102;&#31526;&#21495;&#22270;&#23545;&#27604;&#23398;&#20064;&#65289;
&lt;/p&gt;
&lt;p&gt;
Adversarially Robust Signed Graph Contrastive Learning from Balance Augmentation. (arXiv:2401.10590v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BA-SGCL&#30340;&#40065;&#26834;SGNN&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#22270;&#23545;&#27604;&#23398;&#20064;&#21407;&#21017;&#21644;&#24179;&#34913;&#22686;&#24378;&#25216;&#26415;&#65292;&#35299;&#20915;&#20102;&#24102;&#31526;&#21495;&#22270;&#23545;&#25239;&#24615;&#25915;&#20987;&#20013;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#19981;&#21487;&#36870;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#31526;&#21495;&#22270;&#30001;&#36793;&#21644;&#31526;&#21495;&#32452;&#25104;&#65292;&#21487;&#20197;&#20998;&#20026;&#32467;&#26500;&#20449;&#24687;&#21644;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#12290;&#29616;&#26377;&#30340;&#24102;&#31526;&#21495;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;SGNN&#65289;&#36890;&#24120;&#20381;&#36182;&#20110;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#26469;&#29983;&#25104;&#23884;&#20837;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#23545;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#20135;&#29983;&#20102;&#19981;&#21033;&#24433;&#21709;&#12290;&#31867;&#20284;&#20110;&#32467;&#26500;&#23398;&#20064;&#21487;&#20197;&#24674;&#22797;&#26080;&#31526;&#21495;&#22270;&#65292;&#36890;&#36807;&#25913;&#36827;&#34987;&#27745;&#26579;&#22270;&#30340;&#24179;&#34913;&#24230;&#65292;&#21487;&#20197;&#23558;&#24179;&#34913;&#23398;&#20064;&#24212;&#29992;&#20110;&#24102;&#31526;&#21495;&#22270;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#38754;&#20020;&#30528;&#8220;&#24179;&#34913;&#30456;&#20851;&#20449;&#24687;&#30340;&#19981;&#21487;&#36870;&#24615;&#8221;&#25361;&#25112;-&#23613;&#31649;&#24179;&#34913;&#24230;&#24471;&#21040;&#25913;&#21892;&#65292;&#20294;&#24674;&#22797;&#30340;&#36793;&#21487;&#33021;&#19981;&#26159;&#26368;&#21021;&#21463;&#21040;&#25915;&#20987;&#24433;&#21709;&#30340;&#36793;&#65292;&#23548;&#33268;&#38450;&#24481;&#25928;&#26524;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;SGNN&#26694;&#26550;&#65292;&#31216;&#20026;&#24179;&#34913;&#22686;&#24378;&#24102;&#31526;&#21495;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;BA-SGCL&#65289;&#65292;&#23427;&#23558;&#22270;&#23545;&#27604;&#23398;&#20064;&#21407;&#21017;&#19982;&#24179;&#34913;&#22686;&#24378;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signed graphs consist of edges and signs, which can be separated into structural information and balance-related information, respectively. Existing signed graph neural networks (SGNNs) typically rely on balance-related information to generate embeddings. Nevertheless, the emergence of recent adversarial attacks has had a detrimental impact on the balance-related information. Similar to how structure learning can restore unsigned graphs, balance learning can be applied to signed graphs by improving the balance degree of the poisoned graph. However, this approach encounters the challenge "Irreversibility of Balance-related Information" - while the balance degree improves, the restored edges may not be the ones originally affected by attacks, resulting in poor defense effectiveness. To address this challenge, we propose a robust SGNN framework called Balance Augmented-Signed Graph Contrastive Learning (BA-SGCL), which combines Graph Contrastive Learning principles with balance augmentati
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22810;&#21345;&#36710;&#22810;&#20998;&#27573;&#38656;&#27714;&#36335;&#24452;&#30340;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#29616;&#26377;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27880;&#24847;&#21147;&#27169;&#22411;&#36827;&#34892;&#25193;&#23637;&#65292;&#23454;&#29616;&#20102;&#22312;&#24037;&#19994;&#20379;&#24212;&#38142;&#29289;&#27969;&#20013;&#20351;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#26377;&#25928;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2401.08669</link><description>&lt;p&gt;
&#22810;&#21345;&#36710;&#22810;&#20998;&#27573;&#38656;&#27714;&#36335;&#24452;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Reinforcement Learning for Multi-Truck Vehicle Routing Problems with Multi-Leg Demand Routes. (arXiv:2401.08669v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22810;&#21345;&#36710;&#22810;&#20998;&#27573;&#38656;&#27714;&#36335;&#24452;&#30340;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#29616;&#26377;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27880;&#24847;&#21147;&#27169;&#22411;&#36827;&#34892;&#25193;&#23637;&#65292;&#23454;&#29616;&#20102;&#22312;&#24037;&#19994;&#20379;&#24212;&#38142;&#29289;&#27969;&#20013;&#20351;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#26377;&#25928;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24050;&#34987;&#35777;&#26126;&#22312;&#35299;&#20915;&#19968;&#20123;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#26102;&#38750;&#24120;&#26377;&#25928;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27880;&#24847;&#21147;&#26426;&#21046;&#29983;&#25104;&#30340;&#31574;&#30053;&#26102;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#19968;&#20123;&#30456;&#23545;&#31616;&#21333;&#30340;&#38382;&#39064;&#23454;&#20363;&#65292;&#36825;&#20123;&#25216;&#26415;&#24050;&#32463;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#23545;&#20110;&#19968;&#20123;&#20173;&#26410;&#24471;&#21040;&#30740;&#31350;&#21644;&#38750;&#24120;&#22797;&#26434;&#30340;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#21464;&#20307;&#65292;&#23578;&#26410;&#35777;&#26126;&#26377;&#26377;&#25928;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#21487;&#29992;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#19968;&#31181;&#36825;&#26679;&#30340;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#21464;&#20307;&#65292;&#20854;&#20013;&#21253;&#21547;&#22810;&#36742;&#21345;&#36710;&#21644;&#22810;&#20998;&#27573;&#36335;&#24452;&#35201;&#27714;&#12290;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#65292;&#38656;&#27714;&#38656;&#35201;&#27839;&#30528;&#33410;&#28857;&#24207;&#21015;&#31227;&#21160;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#20174;&#36215;&#28857;&#21040;&#32456;&#28857;&#12290;&#20026;&#20102;&#20351;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#25104;&#20026;&#36866;&#29992;&#20110;&#23454;&#38469;&#24037;&#19994;&#35268;&#27169;&#30340;&#20379;&#24212;&#38142;&#29289;&#27969;&#30340;&#26377;&#25928;&#31574;&#30053;&#65292;&#25105;&#20204;&#23545;&#29616;&#26377;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27880;&#24847;&#21147;&#27169;&#22411;&#36827;&#34892;&#20102;&#26032;&#25193;&#23637;&#65292;&#20351;&#20854;&#33021;&#22788;&#29702;&#22810;&#21345;&#36710;&#21644;&#22810;&#20998;&#27573;&#36335;&#24452;&#35201;&#27714;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#36825;&#26679;&#30340;&#20248;&#21183;&#65292;&#21487;&#20197;&#22312;&#23567;&#35268;&#27169;&#25968;&#25454;&#35757;&#32451;&#19979;&#36827;&#34892;&#65292;&#24182;&#33021;&#22312;&#24037;&#19994;&#20379;&#24212;&#38142;&#29289;&#27969;&#20013;&#36827;&#34892;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning (RL) has been shown to be effective in producing approximate solutions to some vehicle routing problems (VRPs), especially when using policies generated by encoder-decoder attention mechanisms. While these techniques have been quite successful for relatively simple problem instances, there are still under-researched and highly complex VRP variants for which no effective RL method has been demonstrated. In this work we focus on one such VRP variant, which contains multiple trucks and multi-leg routing requirements. In these problems, demand is required to move along sequences of nodes, instead of just from a start node to an end node. With the goal of making deep RL a viable strategy for real-world industrial-scale supply chain logistics, we develop new extensions to existing encoder-decoder attention models which allow them to handle multiple trucks and multi-leg routing requirements. Our models have the advantage that they can be trained for a small number 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#20998;&#24067;&#24335;&#22870;&#21169;&#35780;&#35770;&#23478;&#26550;&#26500;&#65292;&#33021;&#22815;&#22312;&#26410;&#30693;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#24674;&#22797;&#30495;&#23454;&#22870;&#21169;&#65292;&#24182;&#22312;&#22810;&#20010;&#25511;&#21046;&#20219;&#21153;&#20013;&#21462;&#24471;&#36739;&#39640;&#30340;&#22238;&#25253;&#12290;</title><link>http://arxiv.org/abs/2401.05710</link><description>&lt;p&gt;
&#23545;&#25200;&#21160;&#22870;&#21169;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#24067;&#24335;&#22870;&#21169;&#35780;&#35770;&#23478;&#26550;&#26500;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Distributional Reward Critic Architecture for Perturbed-Reward Reinforcement Learning. (arXiv:2401.05710v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05710
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#20998;&#24067;&#24335;&#22870;&#21169;&#35780;&#35770;&#23478;&#26550;&#26500;&#65292;&#33021;&#22815;&#22312;&#26410;&#30693;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#24674;&#22797;&#30495;&#23454;&#22870;&#21169;&#65292;&#24182;&#22312;&#22810;&#20010;&#25511;&#21046;&#20219;&#21153;&#20013;&#21462;&#24471;&#36739;&#39640;&#30340;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#22870;&#21169;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#23545;&#36825;&#20010;&#38382;&#39064;&#20570;&#20986;&#20102;&#24378;&#22823;&#30340;&#20551;&#35774;&#65292;&#21253;&#25324;&#22870;&#21169;&#24179;&#28369;&#24615;&#12289;&#24050;&#30693;&#25200;&#21160;&#21644;/&#25110;&#19981;&#20250;&#25913;&#21464;&#26368;&#20248;&#31574;&#30053;&#30340;&#25200;&#21160;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#26410;&#30693;&#20219;&#24847;&#25200;&#21160;&#30340;&#24773;&#20917;&#65292;&#36825;&#20123;&#25200;&#21160;&#23545;&#22870;&#21169;&#31354;&#38388;&#36827;&#34892;&#20102;&#31163;&#25955;&#21270;&#21644;&#27927;&#29260;&#65292;&#20294;&#22312;&#25200;&#21160;&#21518;&#65292;&#30495;&#23454;&#22870;&#21169;&#23646;&#20110;&#26368;&#39057;&#32321;&#35266;&#23519;&#21040;&#30340;&#31867;&#21035;&#12290;&#36825;&#31867;&#25200;&#21160;&#27867;&#21270;&#20102;&#29616;&#26377;&#30340;&#31867;&#21035;&#65288;&#24182;&#22312;&#26497;&#38480;&#24773;&#20917;&#19979;&#27867;&#21270;&#20102;&#25152;&#26377;&#36830;&#32493;&#26377;&#30028;&#25200;&#21160;&#65289;&#65292;&#24182;&#25112;&#32988;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#20998;&#24067;&#24335;&#22870;&#21169;&#35780;&#35770;&#23478;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#22312;&#25216;&#26415;&#26465;&#20214;&#19979;&#23427;&#21487;&#20197;&#24674;&#22797;&#30495;&#23454;&#22870;&#21169;&#12290;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#20013;&#30340;&#30446;&#26631;&#25200;&#21160;&#19979;&#65292;&#25105;&#20204;&#22312;40/57&#20010;&#29615;&#22659;&#20013;&#36194;&#21033;/&#24179;&#23616;&#65288;&#30456;&#23545;&#20110;&#26368;&#20339;&#22522;&#32447;&#30340;16/57&#65289;&#12290;&#21363;&#20351;&#22312;&#38750;&#30446;&#26631;&#25200;&#21160;&#19979;&#65292;&#25105;&#20204;&#20173;&#28982;&#32988;&#36807;&#35774;&#35745;&#20026;&#24102;&#26377;&#30446;&#26631;&#25200;&#21160;&#30340;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study reinforcement learning in the presence of an unknown reward perturbation. Existing methodologies for this problem make strong assumptions including reward smoothness, known perturbations, and/or perturbations that do not modify the optimal policy. We study the case of unknown arbitrary perturbations that discretize and shuffle reward space, but have the property that the true reward belongs to the most frequently observed class after perturbation. This class of perturbations generalizes existing classes (and, in the limit, all continuous bounded perturbations) and defeats existing methods. We introduce an adaptive distributional reward critic and show theoretically that it can recover the true rewards under technical conditions. Under the targeted perturbation in discrete and continuous control tasks, we win/tie the highest return in 40/57 settings (compared to 16/57 for the best baseline). Even under the untargeted perturbation, we still win an edge over the baseline designed
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#29289;&#29702;-&#26426;&#22120;&#23398;&#20064;&#27668;&#20505;&#27169;&#25311;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#22823;&#35268;&#27169;&#22312;&#32447;&#24314;&#27169;&#38169;&#35823;&#37319;&#26679;&#21644;&#35780;&#20272;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#21442;&#25968;&#21270;&#35774;&#35745;&#20013;&#21457;&#29616;&#20102;&#25913;&#36827;&#24615;&#33021;&#30340;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.16177</link><description>&lt;p&gt;
&#31995;&#32479;&#21270;&#37319;&#26679;&#21644;&#26426;&#22120;&#23398;&#20064;&#21442;&#25968;&#21270;&#22312;&#27668;&#20505;&#27169;&#22411;&#20013;&#30340;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Systematic Sampling and Validation of Machine Learning-Parameterizations in Climate Models. (arXiv:2309.16177v1 [physics.ao-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#29289;&#29702;-&#26426;&#22120;&#23398;&#20064;&#27668;&#20505;&#27169;&#25311;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#22823;&#35268;&#27169;&#22312;&#32447;&#24314;&#27169;&#38169;&#35823;&#37319;&#26679;&#21644;&#35780;&#20272;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#21442;&#25968;&#21270;&#35774;&#35745;&#20013;&#21457;&#29616;&#20102;&#25913;&#36827;&#24615;&#33021;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#29289;&#29702;-&#26426;&#22120;&#23398;&#20064;&#27668;&#20505;&#27169;&#25311;&#30340;&#36827;&#23637;&#21463;&#21040;&#33719;&#21462;&#39640;&#24615;&#33021;&#32806;&#21512;&#65288;&#21363;&#22312;&#32447;&#65289;&#27169;&#25311;&#30340;&#22256;&#38590;&#30340;&#38480;&#21046;&#12290;&#34429;&#28982;&#22312;&#33073;&#26426;&#29615;&#22659;&#20013;&#35780;&#20272;&#25968;&#30334;&#20010;&#26426;&#22120;&#23398;&#20064;&#21442;&#25968;&#21270;&#23376;&#32593;&#26684;&#38381;&#21512;&#65288;&#22914;&#23545;&#27969;&#21644;&#36752;&#23556;&#65289;&#26159;&#30452;&#25509;&#30340;&#65292;&#20294;&#22312;&#30456;&#21516;&#35268;&#27169;&#19978;&#30340;&#22312;&#32447;&#35780;&#20272;&#22312;&#25216;&#26415;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#30340;&#36719;&#20214;&#33258;&#21160;&#21270;&#23454;&#29616;&#20102;&#27604;&#20197;&#24448;&#20219;&#20309;&#26102;&#20505;&#37117;&#22810;&#19968;&#20010;&#25968;&#37327;&#32423;&#30340;&#22312;&#32447;&#24314;&#27169;&#38169;&#35823;&#37319;&#26679;&#12290;&#21033;&#29992;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#35780;&#20272;&#28151;&#21512;&#27668;&#20505;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#21046;&#23450;&#25913;&#36827;&#31574;&#30053;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#21253;&#21547;&#35760;&#24518;&#12289;&#30456;&#23545;&#28287;&#24230;&#36755;&#20837;&#29305;&#24449;&#36716;&#25442;&#21644;&#39069;&#22806;&#36755;&#20837;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#22411;&#30340;&#22312;&#32447;&#24615;&#33021;&#26377;&#25152;&#25552;&#39640;&#12290;&#25105;&#20204;&#36824;&#25581;&#31034;&#20102;&#22312;&#32447;&#38169;&#35823;&#30340;&#26174;&#33879;&#24046;&#24322;&#20197;&#21450;&#33073;&#26426;&#19982;&#22312;&#32447;&#38169;&#35823;&#32479;&#35745;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;&#36825;&#24847;&#21619;&#30528;&#38656;&#35201;&#22312;&#32447;&#35780;&#20272;&#25968;&#30334;&#20010;&#20505;&#36873;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20197;&#26816;&#27979;&#21442;&#25968;&#21270;&#35774;&#35745;&#36873;&#25321;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Progress in hybrid physics-machine learning (ML) climate simulations has been limited by the difficulty of obtaining performant coupled (i.e. online) simulations. While evaluating hundreds of ML parameterizations of subgrid closures (here of convection and radiation) offline is straightforward, online evaluation at the same scale is technically challenging. Our software automation achieves an order-of-magnitude larger sampling of online modeling errors than has previously been examined. Using this, we evaluate the hybrid climate model performance and define strategies to improve it. We show that model online performance improves when incorporating memory, a relative humidity input feature transformation, and additional input variables. We also reveal substantial variation in online error and inconsistencies between offline vs. online error statistics. The implication is that hundreds of candidate ML models should be evaluated online to detect the effects of parameterization design choi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#20013;&#65292;&#21487;&#20197;&#28789;&#27963;&#12289;&#39640;&#25928;&#22320;&#27169;&#25311;&#20855;&#26377;&#38750;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#26497;&#31471;&#20107;&#20214;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26102;&#38388;&#25928;&#29575;&#21644;&#24615;&#33021;&#19978;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#35768;&#22810;&#20855;&#26377;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2307.08079</link><description>&lt;p&gt;
&#36890;&#36807;&#21464;&#20998;&#33258;&#21160; &#32534;&#30721;&#22120;&#23454;&#29616;&#28789;&#27963;&#39640;&#25928;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#20013;&#65292;&#21487;&#20197;&#28789;&#27963;&#12289;&#39640;&#25928;&#22320;&#27169;&#25311;&#20855;&#26377;&#38750;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#26497;&#31471;&#20107;&#20214;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26102;&#38388;&#25928;&#29575;&#21644;&#24615;&#33021;&#19978;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#35768;&#22810;&#20855;&#26377;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#36807;&#31243;&#20855;&#26377;&#22797;&#26434;&#30340;&#23614;&#20381;&#36182;&#32467;&#26500;&#65292;&#36825;&#31181;&#32467;&#26500;&#26080;&#27861;&#20351;&#29992;&#20256;&#32479;&#30340;&#39640;&#26031;&#36807;&#31243;&#26469;&#25551;&#36848;&#12290;&#26356;&#28789;&#27963;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292; &#22914;&#39640;&#26031;&#23610;&#24230;&#28151;&#21512;&#27169;&#22411;&#21644;&#21333;&#31449;&#28857;&#35843;&#33410;&#27169;&#22411;&#65292;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#26497;&#31471;&#20381;&#36182;&#24615;&#36136;&#65292;&#20294;&#24448;&#24448;&#38590;&#20197;&#25311;&#21512;&#21644;&#27169;&#25311;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#20855;&#26377;&#28789;&#27963;&#21644;&#38750;&#24179;&#31283;&#30340;&#30456;&#20851;&#24615;&#23646;&#24615;&#65292;&#24182;&#23558;&#20854;&#38598;&#25104;&#21040;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120; (extVAE) &#30340;&#32534;&#30721;-&#35299;&#30721;&#32467;&#26500;&#20013;&#12290; extVAE &#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#26102;&#31354;&#27169;&#25311;&#22120;&#65292;&#23545;&#28508;&#22312;&#30340;&#26426;&#21046;&#27169;&#22411;&#36755;&#20986;&#29366;&#24577;&#30340;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#20135;&#29983;&#20855;&#26377;&#19982;&#36755;&#20837;&#30456;&#21516;&#23646;&#24615;&#30340;&#36755;&#20986;&#65292;&#23588;&#20854;&#26159;&#22312;&#23614;&#37096;&#21306;&#22495;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;extVAE&#27604;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26356;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377; &#24179;&#31283;&#30456;&#20851;&#24615;&#32467;&#26500;&#30340;&#35768;&#22810;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#20013;&#34920;&#29616; &#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world processes have complex tail dependence structures that cannot be characterized using classical Gaussian processes. More flexible spatial extremes models such as Gaussian scale mixtures and single-station conditioning models exhibit appealing extremal dependence properties but are often exceedingly prohibitive to fit and simulate from. In this paper, we develop a new spatial extremes model that has flexible and non-stationary dependence properties, and we integrate it in the encoding-decoding structure of a variational autoencoder (extVAE). The extVAE can be used as a spatio-temporal emulator that characterizes the distribution of potential mechanistic model output states and produces outputs that have the same properties as the inputs, especially in the tail. Through extensive simulation studies, we show that our extVAE is vastly more time-efficient than traditional Bayesian inference while also outperforming many spatial extremes models with a stationary dependence str
&lt;/p&gt;</description></item><item><title>Awesome-META+&#26159;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#38598;&#25104;&#21644;&#23398;&#20064;&#24179;&#21488;&#65292;&#26088;&#22312;&#25552;&#20379;&#23436;&#25972;&#21487;&#38752;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#24212;&#29992;&#21644;&#38754;&#21521;&#21021;&#23398;&#32773;&#30340;&#23398;&#20064;&#26448;&#26009;&#65292;&#36827;&#32780;&#20419;&#36827;&#20803;&#23398;&#20064;&#30340;&#21457;&#23637;&#24182;&#23558;&#20854;&#20174;&#23567;&#20247;&#39046;&#22495;&#36716;&#21270;&#20026;&#20027;&#27969;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2304.12921</link><description>&lt;p&gt;
Awesome-META+: &#20803;&#23398;&#20064;&#30740;&#31350;&#19982;&#23398;&#20064;&#24179;&#21488;
&lt;/p&gt;
&lt;p&gt;
Awesome-META+: Meta-Learning Research and Learning Platform. (arXiv:2304.12921v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12921
&lt;/p&gt;
&lt;p&gt;
Awesome-META+&#26159;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#38598;&#25104;&#21644;&#23398;&#20064;&#24179;&#21488;&#65292;&#26088;&#22312;&#25552;&#20379;&#23436;&#25972;&#21487;&#38752;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#24212;&#29992;&#21644;&#38754;&#21521;&#21021;&#23398;&#32773;&#30340;&#23398;&#20064;&#26448;&#26009;&#65292;&#36827;&#32780;&#20419;&#36827;&#20803;&#23398;&#20064;&#30340;&#21457;&#23637;&#24182;&#23558;&#20854;&#20174;&#23567;&#20247;&#39046;&#22495;&#36716;&#21270;&#20026;&#20027;&#27969;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#24050;&#32463;&#22312;&#32463;&#27982;&#12289;&#20135;&#19994;&#12289;&#25945;&#32946;&#31561;&#21508;&#20010;&#39046;&#22495;&#20135;&#29983;&#20102;&#28145;&#36828;&#30340;&#24433;&#21709;&#65292;&#20294;&#36824;&#23384;&#22312;&#35832;&#22810;&#38480;&#21046;&#12290;&#20803;&#23398;&#20064;&#65292;&#20063;&#31216;&#20026;&#8220;&#23398;&#20064;&#22914;&#20309;&#23398;&#20064;&#8221;&#65292;&#20026;&#36890;&#29992;&#20154;&#24037;&#26234;&#33021;&#25552;&#20379;&#20102;&#31361;&#30772;&#30446;&#21069;&#29942;&#39048;&#30340;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#20803;&#23398;&#20064;&#36215;&#27493;&#36739;&#26202;&#65292;&#30456;&#27604;CV&#12289;NLP&#31561;&#39046;&#22495;&#65292;&#39033;&#30446;&#25968;&#37327;&#36739;&#23569;&#12290;&#27599;&#27425;&#37096;&#32626;&#37117;&#38656;&#35201;&#22823;&#37327;&#30340;&#32463;&#39564;&#21435;&#37197;&#32622;&#29615;&#22659;&#12289;&#35843;&#35797;&#20195;&#30721;&#29978;&#33267;&#37325;&#20889;&#65292;&#32780;&#19988;&#26694;&#26550;&#20043;&#38388;&#30456;&#23545;&#23396;&#31435;&#12290;&#27492;&#22806;&#65292;&#30446;&#21069;&#38024;&#23545;&#20803;&#23398;&#20064;&#30340;&#19987;&#38376;&#24179;&#21488;&#21644;&#38754;&#21521;&#21021;&#23398;&#32773;&#30340;&#23398;&#20064;&#26448;&#26009;&#30456;&#23545;&#36739;&#23569;&#65292;&#38376;&#27099;&#30456;&#23545;&#36739;&#39640;&#12290;&#22522;&#20110;&#27492;&#65292;Awesome-META+&#25552;&#20986;&#20102;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#38598;&#25104;&#21644;&#23398;&#20064;&#24179;&#21488;&#65292;&#26088;&#22312;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#24182;&#25552;&#20379;&#23436;&#25972;&#21487;&#38752;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#24212;&#29992;&#21644;&#23398;&#20064;&#24179;&#21488;&#12290;&#35813;&#39033;&#30446;&#26088;&#22312;&#20419;&#36827;&#20803;&#23398;&#20064;&#30340;&#21457;&#23637;&#65292;&#24182;&#23558;&#20854;&#20174;&#19968;&#20010;&#23567;&#20247;&#39046;&#22495;&#36716;&#21270;&#20026;&#19968;&#20010;&#20027;&#27969;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence technology has already had a profound impact in various fields such as economy, industry, and education, but still limited. Meta-learning, also known as "learning to learn", provides an opportunity for general artificial intelligence, which can break through the current AI bottleneck. However, meta learning started late and there are fewer projects compare with CV, NLP etc. Each deployment requires a lot of experience to configure the environment, debug code or even rewrite, and the frameworks are isolated. Moreover, there are currently few platforms that focus exclusively on meta-learning, or provide learning materials for novices, for which the threshold is relatively high. Based on this, Awesome-META+, a meta-learning framework integration and learning platform is proposed to solve the above problems and provide a complete and reliable meta-learning framework application and learning platform. The project aims to promote the development of meta-learning and t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#21487;&#20197;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;&#24314;&#27169;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#21253;&#21547;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.00200</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#30340;&#31890;&#23376;&#31995;&#32479;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion map particle systems for generative modeling. (arXiv:2304.00200v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#21487;&#20197;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;&#24314;&#27169;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#21253;&#21547;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#21644;Laplacian&#35843;&#25972;&#30340;Wasserstein&#26799;&#24230;&#19979;&#38477;&#65288;LAWGD&#65289;&#12290;&#25193;&#25955;&#26144;&#23556;&#34987;&#29992;&#26469;&#20174;&#26679;&#26412;&#20013;&#36817;&#20284;Langevin&#25193;&#25955;&#36807;&#31243;&#30340;&#29983;&#25104;&#22120;&#65292;&#20174;&#32780;&#23398;&#20064;&#28508;&#22312;&#30340;&#25968;&#25454;&#29983;&#25104;&#27969;&#24418;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;LAWGD&#33021;&#22815;&#22312;&#21512;&#36866;&#30340;&#26680;&#20989;&#25968;&#36873;&#25321;&#19979;&#39640;&#25928;&#22320;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#25277;&#26679;&#65292;&#25105;&#20204;&#22312;&#36825;&#37324;&#36890;&#36807;&#25193;&#25955;&#26144;&#23556;&#35745;&#31639;&#29983;&#25104;&#22120;&#30340;&#35889;&#36924;&#36817;&#26469;&#26500;&#36896;&#26680;&#20989;&#25968;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21253;&#25324;&#20855;&#26377;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel diffusion map particle system (DMPS) for generative modeling, based on diffusion maps and Laplacian-adjusted Wasserstein gradient descent (LAWGD). Diffusion maps are used to approximate the generator of the Langevin diffusion process from samples, and hence to learn the underlying data-generating manifold. On the other hand, LAWGD enables efficient sampling from the target distribution given a suitable choice of kernel, which we construct here via a spectral approximation of the generator, computed with diffusion maps. Numerical experiments show that our method outperforms others on synthetic datasets, including examples with manifold structure.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#35775;&#38382;&#30446;&#26631;DNN&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;3D&#28857;&#20113;&#20013;&#30340;&#23545;&#25239;&#28857;&#65292;&#25552;&#20379;&#20102;&#26080;&#30418;&#23376;&#25915;&#20987;&#30340;&#26032;&#35270;&#35282;&#12290;</title><link>http://arxiv.org/abs/2210.14164</link><description>&lt;p&gt;
3D&#28857;&#20113;&#20998;&#31867;&#30340;&#26080;&#30418;&#23376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
No-Box Attacks on 3D Point Cloud Classification. (arXiv:2210.14164v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14164
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#35775;&#38382;&#30446;&#26631;DNN&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;3D&#28857;&#20113;&#20013;&#30340;&#23545;&#25239;&#28857;&#65292;&#25552;&#20379;&#20102;&#26080;&#30418;&#23376;&#25915;&#20987;&#30340;&#26032;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#21508;&#31181;&#36755;&#20837;&#20449;&#21495;&#30340;&#20998;&#26512;&#65292;&#23545;&#25239;&#25915;&#20987;&#26500;&#25104;&#20102;&#20005;&#37325;&#25361;&#25112;&#12290;&#22312;3D&#28857;&#20113;&#30340;&#24773;&#20917;&#19979;&#65292;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#26469;&#35782;&#21035;&#22312;&#32593;&#32476;&#20915;&#31574;&#20013;&#36215;&#20851;&#38190;&#20316;&#29992;&#30340;&#28857;&#65292;&#32780;&#36825;&#20123;&#26041;&#27861;&#22312;&#29983;&#25104;&#29616;&#26377;&#30340;&#23545;&#25239;&#25915;&#20987;&#20013;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#20363;&#22914;&#65292;&#26174;&#33879;&#24615;&#22270;&#26041;&#27861;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#23545;&#25239;&#25915;&#20987;&#20250;&#26174;&#33879;&#24433;&#21709;&#32593;&#32476;&#20915;&#31574;&#30340;&#28857;&#12290;&#36890;&#24120;&#65292;&#35782;&#21035;&#23545;&#25239;&#28857;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#23545;&#30446;&#26631;DNN&#27169;&#22411;&#30340;&#35775;&#38382;&#65292;&#20197;&#30830;&#23450;&#21738;&#20123;&#28857;&#23545;&#27169;&#22411;&#30340;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#26088;&#22312;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20379;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65292;&#22312;&#19981;&#35775;&#38382;&#30446;&#26631;DNN&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#23545;&#25239;&#28857;&#65292;&#36825;&#34987;&#31216;&#20026;&#8220;&#26080;&#30418;&#23376;&#8221;&#25915;&#20987;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;14&#20010;&#28857;&#20113;&#29305;&#24449;&#65292;&#24182;&#20351;&#29992;&#22810;&#20803;&#32447;&#24615;&#22238;&#24402;&#26469;&#26816;&#26597;&#36825;&#20123;&#29305;&#24449;&#26159;&#21542;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#23545;&#25239;&#28857;&#65292;&#20197;&#21450;&#21738;&#20123;&#29305;&#24449;&#23545;&#39044;&#27979;&#26368;&#20026;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial attacks pose serious challenges for deep neural network (DNN)-based analysis of various input signals. In the case of 3D point clouds, methods have been developed to identify points that play a key role in network decision, and these become crucial in generating existing adversarial attacks. For example, a saliency map approach is a popular method for identifying adversarial drop points, whose removal would significantly impact the network decision. Generally, methods for identifying adversarial points rely on the access to the DNN model itself to determine which points are critically important for the model's decision. This paper aims to provide a novel viewpoint on this problem, where adversarial points can be predicted without access to the target DNN model, which is referred to as a ``no-box'' attack. To this end, we define 14 point cloud features and use multiple linear regression to examine whether these features can be used for adversarial point prediction, and which
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#31354;&#20154;&#32676;&#27969;&#37327;&#39044;&#27979;&#20013;&#30340;&#19978;&#19979;&#25991;&#27867;&#21270;&#24615;&#65292;&#24314;&#31435;&#20102;&#22522;&#20934;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#20998;&#31867;&#27861;&#65292;&#20026;&#19978;&#19979;&#25991;&#36873;&#25321;&#21644;&#24314;&#27169;&#25552;&#20379;&#20102;&#25351;&#21335;&#12290;</title><link>http://arxiv.org/abs/2106.16046</link><description>&lt;p&gt;
&#25506;&#32034;&#26102;&#31354;&#20154;&#32676;&#27969;&#37327;&#39044;&#27979;&#20013;&#30340;&#19978;&#19979;&#25991;&#27867;&#21270;&#24615;&#65306;&#22522;&#20934;&#21644;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
Exploring the Context Generalizability in Spatiotemporal Crowd Flow Prediction: Benchmark and Guideline. (arXiv:2106.16046v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.16046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#31354;&#20154;&#32676;&#27969;&#37327;&#39044;&#27979;&#20013;&#30340;&#19978;&#19979;&#25991;&#27867;&#21270;&#24615;&#65292;&#24314;&#31435;&#20102;&#22522;&#20934;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#20998;&#31867;&#27861;&#65292;&#20026;&#19978;&#19979;&#25991;&#36873;&#25321;&#21644;&#24314;&#27169;&#25552;&#20379;&#20102;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#29305;&#24449;&#26159;&#26500;&#24314;&#26102;&#31354;&#20154;&#32676;&#27969;&#37327;&#39044;&#27979;&#65288;STCFP&#65289;&#27169;&#22411;&#30340;&#37325;&#35201;&#25968;&#25454;&#26469;&#28304;&#12290;&#28982;&#32780;&#65292;&#24212;&#29992;&#19978;&#19979;&#25991;&#30340;&#22256;&#38590;&#22312;&#20110;&#19981;&#21516;&#22330;&#26223;&#20013;&#19978;&#19979;&#25991;&#29305;&#24449;&#65288;&#20363;&#22914;&#22825;&#27668;&#12289;&#20551;&#26085;&#21644;&#20852;&#36259;&#28857;&#65289;&#21644;&#19978;&#19979;&#25991;&#24314;&#27169;&#25216;&#26415;&#30340;&#26410;&#30693;&#27867;&#21270;&#24615;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#22522;&#20934;&#65292;&#30001;&#22823;&#35268;&#27169;&#26102;&#31354;&#20154;&#32676;&#27969;&#37327;&#25968;&#25454;&#12289;&#19978;&#19979;&#25991;&#25968;&#25454;&#21644;&#26368;&#20808;&#36827;&#30340;&#26102;&#31354;&#39044;&#27979;&#27169;&#22411;&#32452;&#25104;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22478;&#24066;&#20154;&#32676;&#27969;&#37327;&#39044;&#27979;&#22330;&#26223;&#20013;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#30740;&#31350;&#65292;&#20197;&#23450;&#37327;&#30740;&#31350;&#19981;&#21516;&#19978;&#19979;&#25991;&#29305;&#24449;&#21644;&#24314;&#27169;&#25216;&#26415;&#30340;&#27867;&#21270;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22522;&#20110;&#23545;&#27969;&#34892;&#30740;&#31350;&#30340;&#24191;&#27867;&#35843;&#26597;&#65292;&#24320;&#21457;&#20102;&#19978;&#19979;&#25991;&#24314;&#27169;&#25216;&#26415;&#30340;&#36890;&#29992;&#20998;&#31867;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#25968;&#30334;&#19975;&#26465;&#35760;&#24405;&#21644;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#25968;&#25454;&#65292;&#35757;&#32451;&#21644;&#27979;&#35797;&#20102;&#25968;&#30334;&#31181;&#27169;&#22411;&#20197;&#25429;&#25417;&#19978;&#19979;&#25991;&#27867;&#21270;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;STCFP&#20013;&#30340;&#19978;&#19979;&#25991;&#36873;&#25321;&#21644;&#24314;&#27169;&#25552;&#20379;&#20102;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contextual features are important data sources for building spatiotemporal crowd flow prediction (STCFP) models. However, the difficulty of applying context lies in the unknown generalizability of both contextual features (e.g., weather, holiday, and points of interests) and context modeling techniques across different scenarios. In this paper, we build a benchmark composed of large-scale spatiotemporal crowd flow data, contextual data, and state-of-the-art spatiotemporal prediction models. We conduct a comprehensive experimental study to quantitatively investigate the generalizability of different contextual features and modeling techniques in several urban crowd flow prediction scenarios (including bike flow, metro passenger flow, electric vehicle charging demand and so on). In particular, we develop a general taxonomy of context modeling techniques based on extensive investigations in prevailing research. With millions of records and rich context data, we have trained and tested hun
&lt;/p&gt;</description></item></channel></rss>