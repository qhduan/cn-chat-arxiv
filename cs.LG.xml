<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#38750;&#32908;&#23618;&#20405;&#34989;&#24615;&#33152;&#33009;&#30284;&#22797;&#21457;&#39044;&#27979;&#20013;&#20855;&#26377;&#28508;&#22312;&#20316;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#38477;&#20302;&#27835;&#30103;&#25104;&#26412;&#65292;&#24182;&#26377;&#25928;&#35268;&#21010;&#27835;&#30103;&#26041;&#26696;</title><link>https://arxiv.org/abs/2403.10586</link><description>&lt;p&gt;
&#20174;&#31639;&#27861;&#21040;&#32467;&#26524;&#65306;&#23457;&#35270;&#20154;&#24037;&#26234;&#33021;&#22312;&#38750;&#32908;&#23618;&#20405;&#34989;&#24615;&#33152;&#33009;&#30284;&#22797;&#21457;&#39044;&#27979;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
From Algorithms to Outcomes: Reviewing AI's Role in Non-Muscle-Invasive Bladder Cancer Recurrence Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10586
&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#38750;&#32908;&#23618;&#20405;&#34989;&#24615;&#33152;&#33009;&#30284;&#22797;&#21457;&#39044;&#27979;&#20013;&#20855;&#26377;&#28508;&#22312;&#20316;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#38477;&#20302;&#27835;&#30103;&#25104;&#26412;&#65292;&#24182;&#26377;&#25928;&#35268;&#21010;&#27835;&#30103;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33152;&#33009;&#30284;&#26159;&#33521;&#22269;&#27599;&#22825;&#36896;&#25104;15&#20154;&#27515;&#20129;&#30340;&#39046;&#20808;&#27852;&#23615;&#36947;&#30284;&#30151;&#12290;&#36825;&#31181;&#30284;&#30151;&#20027;&#35201;&#34920;&#29616;&#20026;&#38750;&#32908;&#23618;&#20405;&#34989;&#24615;&#33152;&#33009;&#30284;&#65288;NMIBC&#65289;&#65292;&#20854;&#29305;&#28857;&#26159;&#32959;&#30244;&#36824;&#26410;&#28183;&#36879;&#21040;&#33152;&#33009;&#22721;&#30340;&#32908;&#32905;&#23618;&#12290; NMIBC&#30340;&#22797;&#21457;&#29575;&#38750;&#24120;&#39640;&#65292;&#36798;&#21040;70-80&#65285;&#65292;&#22240;&#27492;&#27835;&#30103;&#25104;&#26412;&#26368;&#39640;&#12290;&#30446;&#21069;&#29992;&#20110;&#39044;&#27979;&#22797;&#21457;&#30340;&#24037;&#20855;&#20351;&#29992;&#35780;&#20998;&#31995;&#32479;&#26469;&#39640;&#20272;&#39118;&#38505;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20934;&#30830;&#24615;&#12290;&#23545;&#22797;&#21457;&#30340;&#19981;&#20934;&#30830;&#21644;&#24310;&#36831;&#39044;&#27979;&#26174;&#33879;&#25552;&#39640;&#20102;&#27515;&#20129;&#30340;&#21487;&#33021;&#24615;&#12290;&#22240;&#27492;&#65292;&#20934;&#30830;&#39044;&#27979;&#22797;&#21457;&#23545;&#20110;&#25104;&#26412;&#25928;&#30410;&#30340;&#31649;&#29702;&#21644;&#27835;&#30103;&#35745;&#21010;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#23601;&#26159;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#25216;&#26415;&#20986;&#29616;&#30340;&#22320;&#26041;&#65292;&#36890;&#36807;&#21033;&#29992;&#20998;&#23376;&#21644;&#20020;&#24202;&#25968;&#25454;&#39044;&#27979;NMIBC&#22797;&#21457;&#65292;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#26412;&#27425;&#23457;&#26597;&#23545;&#39044;&#27979;NMIBC&#22797;&#21457;&#30340;ML&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#35780;&#20272;&#20351;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10586v1 Announce Type: cross  Abstract: Bladder cancer, the leading urinary tract cancer, is responsible for 15 deaths daily in the UK. This cancer predominantly manifests as non-muscle-invasive bladder cancer (NMIBC), characterised by tumours not yet penetrating the muscle layer of the bladder wall. NMIBC is plagued by a very high recurrence rate of 70-80% and hence the costliest treatments. Current tools for predicting recurrence use scoring systems that overestimate risk and have poor accuracy. Inaccurate and delayed prediction of recurrence significantly elevates the likelihood of mortality. Accurate prediction of recurrence is hence vital for cost-effective management and treatment planning. This is where Machine learning (ML) techniques have emerged as a promising approach for predicting NMIBC recurrence by leveraging molecular and clinical data. This review provides a comprehensive analysis of ML approaches for predicting NMIBC recurrence. Our systematic evaluation de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20445;&#25345;&#27169;&#22411;&#39640;&#20934;&#30830;&#24615;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10045</link><description>&lt;p&gt;
&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#23454;&#29616;&#23545;&#25239;&#40065;&#26834;&#24615;&#25968;&#25454;&#38598;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
Towards Adversarially Robust Dataset Distillation by Curvature Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#26354;&#29575;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20445;&#25345;&#27169;&#22411;&#39640;&#20934;&#30830;&#24615;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#38598;&#31934;&#28860;&#65288;DD&#65289;&#20801;&#35768;&#23558;&#25968;&#25454;&#38598;&#31934;&#28860;&#20026;&#21407;&#22987;&#22823;&#23567;&#30340;&#20998;&#25968;&#65292;&#21516;&#26102;&#20445;&#30041;&#20016;&#23500;&#30340;&#20998;&#24067;&#20449;&#24687;&#65292;&#20351;&#24471;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#33410;&#30465;&#26174;&#33879;&#35745;&#31639;&#36127;&#36733;&#30340;&#21516;&#26102;&#36798;&#21040;&#21487;&#27604;&#30340;&#20934;&#30830;&#24615;&#12290;&#26368;&#36817;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#25552;&#39640;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25506;&#32034;DD&#30340;&#19968;&#31181;&#26032;&#35270;&#35282;&#12290;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#22312;&#31934;&#28860;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20197;&#20351;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#20445;&#25345;&#39640;&#31934;&#24230;&#30340;&#21516;&#26102;&#33719;&#24471;&#26356;&#22909;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23558;&#26354;&#29575;&#27491;&#21017;&#21270;&#32435;&#20837;&#21040;&#31934;&#28860;&#36807;&#31243;&#20013;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#26032;&#26041;&#27861;&#65292;&#32780;&#36825;&#31181;&#26041;&#27861;&#30340;&#35745;&#31639;&#24320;&#38144;&#27604;&#26631;&#20934;&#30340;&#23545;&#25239;&#35757;&#32451;&#35201;&#23569;&#24471;&#22810;&#12290;&#22823;&#37327;&#30340;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#22312;&#20934;&#30830;&#24615;&#19978;&#20248;&#20110;&#26631;&#20934;&#23545;&#25239;&#35757;&#32451;&#65292;&#21516;&#26102;&#22312;&#23545;&#25239;&#24615;&#33021;&#26041;&#38754;&#20063;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10045v1 Announce Type: new  Abstract: Dataset distillation (DD) allows datasets to be distilled to fractions of their original size while preserving the rich distributional information so that models trained on the distilled datasets can achieve a comparable accuracy while saving significant computational loads. Recent research in this area has been focusing on improving the accuracy of models trained on distilled datasets. In this paper, we aim to explore a new perspective of DD. We study how to embed adversarial robustness in distilled datasets, so that models trained on these datasets maintain the high accuracy and meanwhile acquire better adversarial robustness. We propose a new method that achieves this goal by incorporating curvature regularization into the distillation process with much less computational overhead than standard adversarial training. Extensive empirical experiments suggest that our method not only outperforms standard adversarial training on both accur
&lt;/p&gt;</description></item><item><title>&#23558;&#21435;&#22122;&#26041;&#27861;&#25512;&#24191;&#21040;&#38750;&#24179;&#34913;&#32467;&#26500;&#65292;&#20174;&#32780;&#25913;&#36827;&#31561;&#21464;&#21147;&#22330;&#30340;&#24615;&#33021;&#65292;&#25552;&#39640;&#20102;&#23545;&#21407;&#23376;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#29702;&#35299;&#20197;&#21450;&#22312;&#20998;&#23376;&#21160;&#21147;&#23398;&#21644;&#20652;&#21270;&#21058;&#35774;&#35745;&#31561;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.09549</link><description>&lt;p&gt;
&#23558;&#21435;&#22122;&#25512;&#24191;&#21040;&#38750;&#24179;&#34913;&#32467;&#26500;&#20197;&#25913;&#36827;&#31561;&#21464;&#21147;&#22330;
&lt;/p&gt;
&lt;p&gt;
Generalizing Denoising to Non-Equilibrium Structures Improves Equivariant Force Fields
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09549
&lt;/p&gt;
&lt;p&gt;
&#23558;&#21435;&#22122;&#26041;&#27861;&#25512;&#24191;&#21040;&#38750;&#24179;&#34913;&#32467;&#26500;&#65292;&#20174;&#32780;&#25913;&#36827;&#31561;&#21464;&#21147;&#22330;&#30340;&#24615;&#33021;&#65292;&#25552;&#39640;&#20102;&#23545;&#21407;&#23376;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#29702;&#35299;&#20197;&#21450;&#22312;&#20998;&#23376;&#21160;&#21147;&#23398;&#21644;&#20652;&#21270;&#21058;&#35774;&#35745;&#31561;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#21407;&#23376;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#22914;3D&#21407;&#23376;&#20307;&#31995;&#20013;&#30340;&#21147;&#65292;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#22914;&#20998;&#23376;&#21160;&#21147;&#23398;&#21644;&#20652;&#21270;&#21058;&#35774;&#35745;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#27169;&#25311;&#36825;&#20123;&#30456;&#20114;&#20316;&#29992;&#38656;&#35201;&#35745;&#31639;&#23494;&#38598;&#30340;&#20174;&#22836;&#31639;&#35745;&#31639;&#65292;&#22240;&#27492;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#25968;&#25454;&#26377;&#38480;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#21435;&#22122;&#38750;&#24179;&#34913;&#32467;&#26500;&#65288;DeNS&#65289;&#20316;&#20026;&#36741;&#21161;&#20219;&#21153;&#65292;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#35757;&#32451;&#25968;&#25454;&#24182;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;&#20351;&#29992;DeNS&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#21521;&#20854;3D&#22352;&#26631;&#28155;&#21152;&#22122;&#22768;&#26469;&#30772;&#22351;3D&#32467;&#26500;&#65292;&#28982;&#21518;&#39044;&#27979;&#22122;&#22768;&#12290;&#19981;&#21516;&#20110;&#20197;&#24448;&#20165;&#38480;&#20110;&#24179;&#34913;&#32467;&#26500;&#30340;&#21435;&#22122;&#24037;&#20316;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23558;&#21435;&#22122;&#27867;&#21270;&#21040;&#26356;&#22823;&#33539;&#22260;&#30340;&#38750;&#24179;&#34913;&#32467;&#26500;&#12290;&#20027;&#35201;&#21306;&#21035;&#22312;&#20110;&#38750;&#24179;&#34913;&#32467;&#26500;&#19981;&#23545;&#24212;&#20110;&#23616;&#37096;&#33021;&#37327;&#26368;&#23567;&#20540;&#65292;&#20855;&#26377;&#38750;&#38646;&#21147;&#65292;&#22240;&#27492;&#21487;&#33021;&#20855;&#26377;&#35768;&#22810;&#21487;&#33021;&#30340;&#21407;&#23376;&#20301;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09549v1 Announce Type: cross  Abstract: Understanding the interactions of atoms such as forces in 3D atomistic systems is fundamental to many applications like molecular dynamics and catalyst design. However, simulating these interactions requires compute-intensive ab initio calculations and thus results in limited data for training neural networks. In this paper, we propose to use denoising non-equilibrium structures (DeNS) as an auxiliary task to better leverage training data and improve performance. For training with DeNS, we first corrupt a 3D structure by adding noise to its 3D coordinates and then predict the noise. Different from previous works on denoising, which are limited to equilibrium structures, the proposed method generalizes denoising to a much larger set of non-equilibrium structures. The main difference is that a non-equilibrium structure does not correspond to local energy minima and has non-zero forces, and therefore it can have many possible atomic posit
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25552;&#21319;&#31639;&#27861;&#26469;&#35299;&#20915;&#20256;&#32479;&#25552;&#21319;&#31639;&#27861;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#23558;&#26679;&#26412;&#21387;&#32553;&#26041;&#27861;&#25193;&#23637;&#21040;&#25903;&#25345;&#38543;&#26426;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#26679;&#26412;&#22823;&#23567;&#19978;&#20855;&#26377;&#21333;&#23545;&#25968;&#20381;&#36182;&#30340;&#27867;&#21270;&#38169;&#35823;&#12290;</title><link>https://arxiv.org/abs/2402.02976</link><description>&lt;p&gt;
&#25552;&#21319;&#65292;&#25237;&#31080;&#20998;&#31867;&#22120;&#21644;&#38543;&#26426;&#37319;&#26679;&#21387;&#32553;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Boosting, Voting Classifiers and Randomized Sample Compression Schemes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02976
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25552;&#21319;&#31639;&#27861;&#26469;&#35299;&#20915;&#20256;&#32479;&#25552;&#21319;&#31639;&#27861;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#23558;&#26679;&#26412;&#21387;&#32553;&#26041;&#27861;&#25193;&#23637;&#21040;&#25903;&#25345;&#38543;&#26426;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#26679;&#26412;&#22823;&#23567;&#19978;&#20855;&#26377;&#21333;&#23545;&#25968;&#20381;&#36182;&#30340;&#27867;&#21270;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25552;&#21319;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#21033;&#29992;&#22810;&#20010;&#24369;&#23398;&#20064;&#22120;&#26469;&#20135;&#29983;&#19968;&#20010;&#24378;&#23398;&#20064;&#22120;&#12290;&#36825;&#20010;&#33539;&#24335;&#30340;&#26680;&#24515;&#26159;&#23558;&#24378;&#23398;&#20064;&#22120;&#24314;&#27169;&#20026;&#19968;&#20010;&#25237;&#31080;&#20998;&#31867;&#22120;&#65292;&#23427;&#36755;&#20986;&#24369;&#23398;&#20064;&#22120;&#30340;&#21152;&#26435;&#22810;&#25968;&#25237;&#31080;&#12290;&#23613;&#31649;&#35768;&#22810;&#25104;&#21151;&#30340;&#25552;&#21319;&#31639;&#27861;&#65292;&#22914;&#26631;&#24535;&#24615;&#30340;AdaBoost&#65292;&#20135;&#29983;&#25237;&#31080;&#20998;&#31867;&#22120;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#24615;&#33021;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#19981;&#22815;&#20248;&#21270;&#65306;&#36804;&#20170;&#20026;&#27490;&#65292;&#24050;&#30693;&#30340;&#20351;&#25237;&#31080;&#20998;&#31867;&#22120;&#36798;&#21040;&#32473;&#23450;&#20934;&#30830;&#24615;&#25152;&#38656;&#30340;&#35757;&#32451;&#26679;&#26412;&#25968;&#30340;&#26368;&#20339;&#30028;&#38480;&#24635;&#26159;&#33267;&#23569;&#21253;&#21547;&#33267;&#22810;&#20004;&#20010;&#23545;&#25968;&#22240;&#23376;&#65292;&#32780;&#36825;&#24050;&#32463;&#36229;&#36807;&#20102;&#19968;&#33324;&#30340;&#24369;&#21040;&#24378;&#23398;&#20064;&#22120;&#25152;&#33021;&#23454;&#29616;&#30340;&#33539;&#22260;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#38543;&#26426;&#25552;&#21319;&#31639;&#27861;&#25171;&#30772;&#36825;&#19968;&#38556;&#30861;&#65292;&#35813;&#31639;&#27861;&#36755;&#20986;&#30340;&#25237;&#31080;&#20998;&#31867;&#22120;&#22312;&#26679;&#26412;&#22823;&#23567;&#19978;&#21253;&#21547;&#21333;&#23545;&#25968;&#20381;&#36182;&#30340;&#27867;&#21270;&#38169;&#35823;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#23558;&#26679;&#26412;&#21387;&#32553;&#26041;&#27861;&#25193;&#23637;&#21040;&#25903;&#25345;&#38543;&#26426;&#23398;&#20064;&#31639;&#27861;&#26469;&#33719;&#24471;&#36825;&#20010;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In boosting, we aim to leverage multiple weak learners to produce a strong learner. At the center of this paradigm lies the concept of building the strong learner as a voting classifier, which outputs a weighted majority vote of the weak learners. While many successful boosting algorithms, such as the iconic AdaBoost, produce voting classifiers, their theoretical performance has long remained sub-optimal: the best known bounds on the number of training examples necessary for a voting classifier to obtain a given accuracy has so far always contained at least two logarithmic factors above what is known to be achievable by general weak-to-strong learners. In this work, we break this barrier by proposing a randomized boosting algorithm that outputs voting classifiers whose generalization error contains a single logarithmic dependency on the sample size. We obtain this result by building a general framework that extends sample compression methods to support randomized learning algorithms ba
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#20248;&#21270;&#28909;&#39044;&#35686;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#39062;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#21644;&#32508;&#21512;&#25968;&#25454;&#38598;&#65292;&#35299;&#20915;&#20102;&#27668;&#20505;&#21644;&#20581;&#24247;&#29615;&#22659;&#20013;&#30340;&#20302;&#20449;&#21495;&#25928;&#24212;&#21644;&#31354;&#38388;&#24322;&#36136;&#24615;&#12290;</title><link>https://arxiv.org/abs/2312.14196</link><description>&lt;p&gt;
&#29992;&#24378;&#21270;&#23398;&#20064;&#20248;&#21270;&#28909;&#39044;&#35686;&#30340;&#21457;&#24067;
&lt;/p&gt;
&lt;p&gt;
Optimizing Heat Alert Issuance with Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14196
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#20248;&#21270;&#28909;&#39044;&#35686;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#39062;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#21644;&#32508;&#21512;&#25968;&#25454;&#38598;&#65292;&#35299;&#20915;&#20102;&#27668;&#20505;&#21644;&#20581;&#24247;&#29615;&#22659;&#20013;&#30340;&#20302;&#20449;&#21495;&#25928;&#24212;&#21644;&#31354;&#38388;&#24322;&#36136;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20250;&#36866;&#24212;&#27668;&#20505;&#21464;&#21270;&#30340;&#20851;&#38190;&#25112;&#30053;&#20043;&#19968;&#26159;&#21033;&#29992;&#39044;&#35686;&#31995;&#32479;&#20943;&#23569;&#26497;&#31471;&#39640;&#28201;&#20107;&#20214;&#30340;&#19981;&#21033;&#20581;&#24247;&#24433;&#21709;&#65292;&#20197;&#20419;&#20351;&#39044;&#38450;&#24615;&#34892;&#21160;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20316;&#20026;&#20248;&#21270;&#27492;&#31867;&#31995;&#32479;&#25928;&#26524;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26377;&#19977;&#20010;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#65292;&#35780;&#20272;&#28909;&#39044;&#35686;&#25919;&#31574;&#30340;&#26377;&#25928;&#24615;&#65292;&#20197;&#20943;&#23569;&#19982;&#39640;&#28201;&#26377;&#20851;&#30340;&#20303;&#38498;&#20154;&#25968;&#12290;&#22870;&#21169;&#27169;&#22411;&#22522;&#20110;&#21382;&#21490;&#22825;&#27668;&#12289;&#21307;&#30103;&#20445;&#38505;&#20581;&#24247;&#35760;&#24405;&#20197;&#21450;&#31038;&#20250;&#32463;&#27982;/&#22320;&#29702;&#29305;&#24449;&#30340;&#20840;&#38754;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#20351;&#29992;&#21464;&#20998;&#36125;&#21494;&#26031;&#25216;&#26415;&#35299;&#20915;&#20102;&#22312;&#27668;&#20505;&#21644;&#20581;&#24247;&#29615;&#22659;&#20013;&#24120;&#35265;&#30340;&#20302;&#20449;&#21495;&#25928;&#24212;&#21644;&#31354;&#38388;&#24322;&#36136;&#24615;&#12290;&#36716;&#25442;&#27169;&#22411;&#32467;&#21512;&#20102;&#30495;&#23454;&#30340;&#21382;&#21490;&#22825;&#27668;&#27169;&#24335;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#27668;&#20505;&#21306;&#22495;&#30456;&#20284;&#24615;&#30340;&#25968;&#25454;&#22686;&#24378;&#26426;&#21046;&#36827;&#34892;&#22686;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14196v2 Announce Type: replace  Abstract: A key strategy in societal adaptation to climate change is the use of alert systems to reduce the adverse health impacts of extreme heat events by prompting preventative action. In this work, we investigate reinforcement learning (RL) as a tool to optimize the effectiveness of such systems. Our contributions are threefold. First, we introduce a novel RL environment enabling the evaluation of the effectiveness of heat alert policies to reduce heat-related hospitalizations. The rewards model is trained from a comprehensive dataset of historical weather, Medicare health records, and socioeconomic/geographic features. We use variational Bayesian techniques to address low-signal effects and spatial heterogeneity, which are commonly encountered in climate &amp; health settings. The transition model incorporates real historical weather patterns enriched by a data augmentation mechanism based on climate region similarity. Second, we use this env
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20351;&#29992;&#32852;&#21512;&#21327;&#21516;&#35757;&#32451;&#26041;&#27861;&#26469;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;&#65292;&#36890;&#36807;&#22312;&#20844;&#20849;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#19978;&#20849;&#20139;&#30828;&#26631;&#31614;&#20195;&#26367;&#27169;&#22411;&#21442;&#25968;&#65292;&#24418;&#25104;&#20266;&#26631;&#31614;&#20197;&#32467;&#21512;&#31169;&#26377;&#25968;&#25454;&#35757;&#32451;&#26412;&#22320;&#27169;&#22411;&#65292;&#25552;&#39640;&#38544;&#31169;&#20445;&#25252;&#25928;&#26524;&#24182;&#33719;&#24471;&#19982;&#32852;&#37030;&#23398;&#20064;&#30456;&#23218;&#32654;&#30340;&#27169;&#22411;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2310.05696</link><description>&lt;p&gt;
&#36890;&#36807;&#32852;&#21512;&#21327;&#21516;&#35757;&#32451;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Protecting Sensitive Data through Federated Co-Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.05696
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20351;&#29992;&#32852;&#21512;&#21327;&#21516;&#35757;&#32451;&#26041;&#27861;&#26469;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;&#65292;&#36890;&#36807;&#22312;&#20844;&#20849;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#19978;&#20849;&#20139;&#30828;&#26631;&#31614;&#20195;&#26367;&#27169;&#22411;&#21442;&#25968;&#65292;&#24418;&#25104;&#20266;&#26631;&#31614;&#20197;&#32467;&#21512;&#31169;&#26377;&#25968;&#25454;&#35757;&#32451;&#26412;&#22320;&#27169;&#22411;&#65292;&#25552;&#39640;&#38544;&#31169;&#20445;&#25252;&#25928;&#26524;&#24182;&#33719;&#24471;&#19982;&#32852;&#37030;&#23398;&#20064;&#30456;&#23218;&#32654;&#30340;&#27169;&#22411;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#25935;&#24863;&#25968;&#25454;&#26412;&#36136;&#19978;&#26159;&#20998;&#24067;&#30340;&#65292;&#30001;&#20110;&#38544;&#31169;&#38382;&#39064;&#21487;&#33021;&#26080;&#27861;&#27719;&#24635;&#12290;&#32852;&#37030;&#23398;&#20064;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#36845;&#20195;&#22320;&#32858;&#21512;&#26412;&#22320;&#27169;&#22411;&#30340;&#21442;&#25968;&#26469;&#21327;&#20316;&#35757;&#32451;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#21512;&#24182;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#21487;&#20197;&#36890;&#36807;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#25512;&#26029;&#20986;&#25935;&#24863;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#32852;&#21512;&#21327;&#21516;&#35757;&#32451;&#26041;&#27861;&#65292;&#22312;&#20854;&#20013;&#23458;&#25143;&#31471;&#20998;&#20139;&#20844;&#20849;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#19978;&#30340;&#30828;&#26631;&#31614;&#65292;&#32780;&#19981;&#26159;&#27169;&#22411;&#21442;&#25968;&#12290;&#23545;&#20849;&#20139;&#26631;&#31614;&#30340;&#19968;&#33268;&#24615;&#24418;&#25104;&#20102;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#30340;&#20266;&#26631;&#31614;&#65292;&#23458;&#25143;&#31471;&#23558;&#20854;&#19982;&#31169;&#26377;&#25968;&#25454;&#32467;&#21512;&#20351;&#29992;&#26469;&#35757;&#32451;&#26412;&#22320;&#27169;&#22411;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20849;&#20139;&#30828;&#26631;&#31614;&#22823;&#22823;&#25552;&#39640;&#20102;&#19982;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#30456;&#27604;&#30340;&#38544;&#31169;&#20445;&#25252;&#12290;&#21516;&#26102;&#65292;&#32852;&#21512;&#21327;&#21516;&#35757;&#32451;&#23454;&#29616;&#20102;&#19982;&#32852;&#37030;&#23398;&#20064;&#30456;&#23218;&#32654;&#30340;&#27169;&#22411;&#36136;&#37327;&#12290;&#27492;&#22806;&#65292;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;&#20687;(&#26799;&#24230;&#25552;&#21319;)&#20915;&#31574;&#26641;&#12289;&#35268;&#21017;&#38598;&#21512;&#31561;&#26412;&#22320;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.05696v2 Announce Type: replace  Abstract: In many applications, sensitive data is inherently distributed and may not be pooled due to privacy concerns. Federated learning allows us to collaboratively train a model without pooling the data by iteratively aggregating the parameters of local models. It is possible, though, to infer upon the sensitive data from the shared model parameters. We propose to use a federated co-training approach where clients share hard labels on a public unlabeled dataset instead of model parameters. A consensus on the shared labels forms a pseudo labeling for the unlabeled dataset that clients use in combination with their private data to train local models. We show that sharing hard labels substantially improves privacy over sharing model parameters. At the same time, federated co-training achieves a model quality comparable to federated learning. Moreover, it allows us to use local models such as (gradient boosted) decision trees, rule ensembles, 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35843;&#26597;&#20102;&#26368;&#36817;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#30740;&#31350;&#36827;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#19981;&#21516;&#31639;&#27861;&#24615;&#33021;&#30340;&#28145;&#24230;&#27604;&#36739;&#65292;&#36824;&#25506;&#35752;&#20102;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#26041;&#27861;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.10825</link><description>&lt;p&gt;
&#26368;&#26032;&#36827;&#23637;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A survey on recent advances in named entity recognition. (arXiv:2401.10825v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10825
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35843;&#26597;&#20102;&#26368;&#36817;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#30740;&#31350;&#36827;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#19981;&#21516;&#31639;&#27861;&#24615;&#33021;&#30340;&#28145;&#24230;&#27604;&#36739;&#65292;&#36824;&#25506;&#35752;&#20102;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#26041;&#27861;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#26088;&#22312;&#20174;&#25991;&#26412;&#20013;&#25552;&#21462;&#20986;&#21629;&#21517;&#30495;&#23454;&#19990;&#30028;&#23545;&#35937;&#30340;&#23376;&#23383;&#31526;&#20018;&#65292;&#24182;&#30830;&#23450;&#20854;&#31867;&#22411;&#65288;&#20363;&#22914;&#65292;&#26159;&#21542;&#25351;&#20154;&#29289;&#25110;&#32452;&#32455;&#65289;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#27010;&#36848;&#20102;&#26368;&#36817;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#20851;&#27880;&#20102;&#22522;&#20110;&#22270;&#21644;&#21464;&#25442;&#22120;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#24456;&#23569;&#22312;&#20854;&#20182;&#32508;&#36848;&#20013;&#28041;&#21450;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#38024;&#23545;&#31232;&#32570;&#27880;&#37322;&#25968;&#25454;&#38598;&#35774;&#35745;&#30340;&#26041;&#27861;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#20027;&#35201;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#23454;&#29616;&#22312;&#21508;&#31181;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#65288;&#39046;&#22495;&#12289;&#35268;&#27169;&#21644;&#31867;&#21035;&#25968;&#65289;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20174;&#26410;&#21516;&#26102;&#32771;&#34385;&#30340;&#31639;&#27861;&#30340;&#28145;&#24230;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#25968;&#25454;&#38598;&#29305;&#24449;&#22914;&#20309;&#24433;&#21709;&#25105;&#20204;&#27604;&#36739;&#30340;&#26041;&#27861;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Named Entity Recognition seeks to extract substrings within a text that name real-world objects and to determine their type (for example, whether they refer to persons or organizations). In this survey, we first present an overview of recent popular approaches, but we also look at graph- and transformer- based methods including Large Language Models (LLMs) that have not had much coverage in other surveys. Second, we focus on methods designed for datasets with scarce annotations. Third, we evaluate the performance of the main NER implementations on a variety of datasets with differing characteristics (as regards their domain, their size, and their number of classes). We thus provide a deep comparison of algorithms that are never considered together. Our experiments shed some light on how the characteristics of datasets affect the behavior of the methods that we compare.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27979;&#37327;&#30340;&#21464;&#20998;&#37327;&#23376;&#35745;&#31639;&#31639;&#27861;&#65292;&#23558;&#37327;&#23376;&#27979;&#37327;&#30340;&#38543;&#26426;&#24615;&#35270;&#20026;&#35745;&#31639;&#36164;&#28304;&#65292;&#24182;&#24212;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.13524</link><description>&lt;p&gt;
&#22522;&#20110;&#27979;&#37327;&#30340;&#21464;&#20998;&#37327;&#23376;&#35745;&#31639;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Variational measurement-based quantum computation for generative modeling. (arXiv:2310.13524v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13524
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27979;&#37327;&#30340;&#21464;&#20998;&#37327;&#23376;&#35745;&#31639;&#31639;&#27861;&#65292;&#23558;&#37327;&#23376;&#27979;&#37327;&#30340;&#38543;&#26426;&#24615;&#35270;&#20026;&#35745;&#31639;&#36164;&#28304;&#65292;&#24182;&#24212;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27979;&#37327;&#30340;&#37327;&#23376;&#35745;&#31639;&#65288;MBQC&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#26412;&#29420;&#29305;&#30340;&#33539;&#20363;&#26469;&#35774;&#35745;&#37327;&#23376;&#31639;&#27861;&#12290;&#22312;MBQC&#20013;&#65292;&#30001;&#20110;&#37327;&#23376;&#27979;&#37327;&#30340;&#22266;&#26377;&#38543;&#26426;&#24615;&#65292;&#33258;&#28982;&#30340;&#25805;&#20316;&#19981;&#26159;&#30830;&#23450;&#24615;&#21644;&#24186;&#27491;&#30340;&#65292;&#32780;&#26159;&#36890;&#36807;&#27010;&#29575;&#38468;&#24102;&#30340;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;MBQC&#30340;&#20027;&#35201;&#31639;&#27861;&#24212;&#29992;&#26159;&#23436;&#20840;&#25269;&#28040;&#36825;&#31181;&#27010;&#29575;&#24615;&#36136;&#65292;&#20197;&#27169;&#25311;&#34920;&#36798;&#22312;&#30005;&#36335;&#27169;&#22411;&#20013;&#30340;&#24186;&#27491;&#35745;&#31639;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35774;&#35745;MBQC&#31639;&#27861;&#30340;&#24605;&#36335;&#65292;&#35813;&#31639;&#27861;&#25509;&#21463;&#36825;&#31181;&#22266;&#26377;&#38543;&#26426;&#24615;&#65292;&#24182;&#23558;MBQC&#20013;&#30340;&#38543;&#26426;&#38468;&#24102;&#35270;&#20026;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#38543;&#26426;&#24615;&#26377;&#30410;&#30340;&#33258;&#28982;&#24212;&#29992;&#65292;&#21363;&#29983;&#25104;&#24314;&#27169;&#65292;&#36825;&#26159;&#19968;&#20010;&#20197;&#29983;&#25104;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#20026;&#20013;&#24515;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#25511;&#21046;&#21442;&#25968;&#30340;&#21464;&#20998;MBQC&#31639;&#27861;&#65292;&#21487;&#20197;&#30452;&#25509;&#35843;&#25972;&#20801;&#35768;&#22312;&#35745;&#31639;&#20013;&#24341;&#20837;&#30340;&#38543;&#26426;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measurement-based quantum computation (MBQC) offers a fundamentally unique paradigm to design quantum algorithms. Indeed, due to the inherent randomness of quantum measurements, the natural operations in MBQC are not deterministic and unitary, but are rather augmented with probabilistic byproducts. Yet, the main algorithmic use of MBQC so far has been to completely counteract this probabilistic nature in order to simulate unitary computations expressed in the circuit model. In this work, we propose designing MBQC algorithms that embrace this inherent randomness and treat the random byproducts in MBQC as a resource for computation. As a natural application where randomness can be beneficial, we consider generative modeling, a task in machine learning centered around generating complex probability distributions. To address this task, we propose a variational MBQC algorithm equipped with control parameters that allow to directly adjust the degree of randomness to be admitted in the comput
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27531;&#24046;&#22810;&#20445;&#30495;&#35745;&#31639;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#20445;&#30495;&#20449;&#24687;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20302;&#20445;&#30495;&#21644;&#39640;&#20445;&#30495;&#35745;&#31639;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#24314;&#27169;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#35757;&#32451;&#20102;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#27531;&#24046;&#20989;&#25968;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#65292;&#26368;&#32456;&#24471;&#21040;&#20102;&#39640;&#20445;&#30495;&#26367;&#20195;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.03572</link><description>&lt;p&gt;
&#22810;&#20445;&#30495;&#31070;&#32463;&#32593;&#32476;&#35745;&#31639;&#30340;&#27531;&#24046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Residual Multi-Fidelity Neural Network Computing. (arXiv:2310.03572v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27531;&#24046;&#22810;&#20445;&#30495;&#35745;&#31639;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#20445;&#30495;&#20449;&#24687;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20302;&#20445;&#30495;&#21644;&#39640;&#20445;&#30495;&#35745;&#31639;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#24314;&#27169;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#35757;&#32451;&#20102;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#27531;&#24046;&#20989;&#25968;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#65292;&#26368;&#32456;&#24471;&#21040;&#20102;&#39640;&#20445;&#30495;&#26367;&#20195;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#22810;&#20445;&#30495;&#20449;&#24687;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#30340;&#19968;&#33324;&#38382;&#39064;&#12290;&#32473;&#23450;&#19968;&#20010;&#24265;&#20215;&#30340;&#20302;&#20445;&#30495;&#21644;&#19968;&#20010;&#26114;&#36149;&#30340;&#39640;&#20445;&#30495;&#35745;&#31639;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27531;&#24046;&#22810;&#20445;&#30495;&#35745;&#31639;&#26694;&#26550;&#65292;&#23558;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#24314;&#27169;&#20026;&#19968;&#20010;&#27531;&#24046;&#20989;&#25968;&#65292;&#36825;&#26159;&#19968;&#20010;&#21487;&#33021;&#38750;&#32447;&#24615;&#30340;1&#65289;&#27169;&#22411;&#20849;&#20139;&#30340;&#36755;&#20837;&#31354;&#38388;&#21644;&#20302;&#20445;&#30495;&#27169;&#22411;&#36755;&#20986;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#20197;&#21450;2&#65289;&#20004;&#20010;&#27169;&#22411;&#36755;&#20986;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#21327;&#21516;&#24037;&#20316;&#12290;&#31532;&#19968;&#20010;&#32593;&#32476;&#22312;&#23569;&#37327;&#30340;&#39640;&#20445;&#30495;&#21644;&#20302;&#20445;&#30495;&#25968;&#25454;&#19978;&#23398;&#20064;&#27531;&#24046;&#20989;&#25968;&#12290;&#19968;&#26086;&#35757;&#32451;&#23436;&#25104;&#65292;&#36825;&#20010;&#32593;&#32476;&#34987;&#29992;&#26469;&#29983;&#25104;&#39069;&#22806;&#30340;&#21512;&#25104;&#39640;&#20445;&#30495;&#25968;&#25454;&#65292;&#29992;&#20110;&#35757;&#32451;&#31532;&#20108;&#20010;&#32593;&#32476;&#12290;&#19968;&#26086;&#35757;&#32451;&#23436;&#25104;&#65292;&#31532;&#20108;&#20010;&#32593;&#32476;&#20316;&#20026;&#25105;&#20204;&#23545;&#39640;&#20445;&#30495;&#24863;&#20852;&#36259;&#30340;&#37327;&#30340;&#26367;&#20195;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19977;&#20010;&#25968;&#20540;&#20363;&#23376;&#26469;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we consider the general problem of constructing a neural network surrogate model using multi-fidelity information. Given an inexpensive low-fidelity and an expensive high-fidelity computational model, we present a residual multi-fidelity computational framework that formulates the correlation between models as a residual function, a possibly non-linear mapping between 1) the shared input space of the models together with the low-fidelity model output and 2) the discrepancy between the two model outputs. To accomplish this, we train two neural networks to work in concert. The first network learns the residual function on a small set of high-fidelity and low-fidelity data. Once trained, this network is used to generate additional synthetic high-fidelity data, which is used in the training of a second network. This second network, once trained, acts as our surrogate for the high-fidelity quantity of interest. We present three numerical examples to demonstrate the power of th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20174;&#35821;&#38899;&#35760;&#24405;&#20013;&#26816;&#27979;&#21897;&#30284;&#30340;&#25991;&#29486;&#36827;&#34892;&#20102;&#32508;&#36848;&#65292;&#21457;&#29616;&#20102;22&#31687;&#30456;&#20851;&#35770;&#25991;&#65292;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#26041;&#27861;&#21644;&#32467;&#26524;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#26757;&#23572;&#39057;&#29575;&#20498;&#35889;&#31995;&#25968;&#25552;&#21462;&#38899;&#39057;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#20102;&#20998;&#31867;&#65292;&#21462;&#24471;&#20102;&#19968;&#23450;&#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.09230</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20174;&#35821;&#38899;&#20449;&#21495;&#20013;&#26816;&#27979;&#21897;&#30284;&#65306;&#21487;&#22797;&#29616;&#30340;&#25991;&#29486;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Detecting Throat Cancer from Speech Signals Using Machine Learning: A Reproducible Literature Review. (arXiv:2307.09230v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20174;&#35821;&#38899;&#35760;&#24405;&#20013;&#26816;&#27979;&#21897;&#30284;&#30340;&#25991;&#29486;&#36827;&#34892;&#20102;&#32508;&#36848;&#65292;&#21457;&#29616;&#20102;22&#31687;&#30456;&#20851;&#35770;&#25991;&#65292;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#26041;&#27861;&#21644;&#32467;&#26524;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#26757;&#23572;&#39057;&#29575;&#20498;&#35889;&#31995;&#25968;&#25552;&#21462;&#38899;&#39057;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#20102;&#20998;&#31867;&#65292;&#21462;&#24471;&#20102;&#19968;&#23450;&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20174;&#35821;&#38899;&#35760;&#24405;&#20013;&#26816;&#27979;&#21897;&#30284;&#30340;&#24403;&#21069;&#25991;&#29486;&#36827;&#34892;&#20102;&#33539;&#22260;&#35780;&#20272;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;22&#31687;&#30456;&#20851;&#35770;&#25991;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#26041;&#27861;&#21644;&#32467;&#26524;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#35770;&#25991;&#20998;&#20026;&#20004;&#32452; - &#20061;&#31687;&#36827;&#34892;&#20108;&#20998;&#31867;&#65292;13&#31687;&#36827;&#34892;&#22810;&#31867;&#21035;&#20998;&#31867;&#12290;&#36825;&#20123;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26041;&#27861;&#65292;&#20854;&#20013;&#26368;&#24120;&#35265;&#30340;&#26159;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#20998;&#31867;&#20043;&#21069;&#36824;&#20174;&#38899;&#39057;&#20013;&#25552;&#21462;&#20102;&#35768;&#22810;&#29305;&#24449;&#65292;&#20854;&#20013;&#26368;&#24120;&#35265;&#30340;&#26159;&#26757;&#23572;&#39057;&#29575;&#20498;&#35889;&#31995;&#25968;&#12290;&#22312;&#36825;&#27425;&#25628;&#32034;&#20013;&#26410;&#25214;&#21040;&#20219;&#20309;&#24102;&#26377;&#20195;&#30721;&#24211;&#30340;&#35770;&#25991;&#65292;&#22240;&#27492;&#26080;&#27861;&#22797;&#29616;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#20195;&#30721;&#24211;&#26469;&#35757;&#32451;&#33258;&#24049;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#22810;&#31867;&#21035;&#38382;&#39064;&#19978;&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#65292;&#23558;&#19977;&#31181;&#30149;&#29702;&#21644;&#20581;&#24247;&#23545;&#29031;&#36827;&#34892;&#20998;&#31867;&#12290;&#20351;&#29992;&#36825;&#31181;&#25216;&#26415;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;53.54%&#30340;&#21152;&#26435;&#24179;&#22343;&#21484;&#22238;&#29575;&#12289;83.14%&#30340;&#25935;&#24863;&#24615;&#21644;&#29305;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we perform a scoping review of the current literature on the detection of throat cancer from speech recordings using machine learning and artificial intelligence. We find 22 papers within this area and discuss their methods and results. We split these papers into two groups - nine performing binary classification, and 13 performing multi-class classification. The papers present a range of methods with neural networks being most commonly implemented. Many features are also extracted from the audio before classification, with the most common bring mel-frequency cepstral coefficients. None of the papers found in this search have associated code repositories and as such are not reproducible. Therefore, we create a publicly available code repository of our own classifiers. We use transfer learning on a multi-class problem, classifying three pathologies and healthy controls. Using this technique we achieve an unweighted average recall of 53.54%, sensitivity of 83.14%, and specif
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#30340;&#26032;&#26041;&#27861;&#65292;&#20381;&#38752;&#29702;&#35770;&#29289;&#29702;&#30340;&#24605;&#24819;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#26500;&#24314;&#32039;&#20945;&#30340;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25429;&#25417;&#25968;&#25454;&#30340;&#22522;&#26412;&#32467;&#26500;&#21644;&#20219;&#21153;&#29305;&#23450;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#30452;&#35266;&#12289;&#21487;&#35299;&#37322;&#21644;&#21487;&#39564;&#35777;&#24615;&#65292;&#24182;&#21487;&#20197;&#22312;&#24191;&#20041;&#35774;&#32622;&#20013;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.01930</link><description>&lt;p&gt;
&#23398;&#20064;ECG&#20449;&#21495;&#29305;&#24449;&#30340;&#38750;&#21453;&#21521;&#20256;&#25773;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning ECG signal features without backpropagation. (arXiv:2307.01930v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01930
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#30340;&#26032;&#26041;&#27861;&#65292;&#20381;&#38752;&#29702;&#35770;&#29289;&#29702;&#30340;&#24605;&#24819;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#26500;&#24314;&#32039;&#20945;&#30340;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25429;&#25417;&#25968;&#25454;&#30340;&#22522;&#26412;&#32467;&#26500;&#21644;&#20219;&#21153;&#29305;&#23450;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#30452;&#35266;&#12289;&#21487;&#35299;&#37322;&#21644;&#21487;&#39564;&#35777;&#24615;&#65292;&#24182;&#21487;&#20197;&#22312;&#24191;&#20041;&#35774;&#32622;&#20013;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#19968;&#20010;&#20851;&#38190;&#30740;&#31350;&#39046;&#22495;&#65292;&#23427;&#26088;&#22312;&#21457;&#29616;&#29992;&#20110;&#25552;&#39640;&#20998;&#31867;&#21644;&#39044;&#27979;&#31561;&#19979;&#28216;&#20219;&#21153;&#30340;&#21407;&#22987;&#25968;&#25454;&#30340;&#26377;&#25928;&#29305;&#24449;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#31867;&#22411;&#25968;&#25454;&#34920;&#31034;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#20381;&#38752;&#29702;&#35770;&#29289;&#29702;&#30340;&#24605;&#24819;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#26500;&#24314;&#32039;&#20945;&#30340;&#34920;&#31034;&#65292;&#24182;&#21487;&#20197;&#25429;&#25417;&#21040;&#25968;&#25454;&#30340;&#22522;&#26412;&#32467;&#26500;&#21644;&#20219;&#21153;&#29305;&#23450;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#30452;&#35266;&#12289;&#21487;&#35299;&#37322;&#21644;&#21487;&#39564;&#35777;&#24615;&#12290;&#36825;&#20010;&#26032;&#26041;&#27861;&#26088;&#22312;&#35782;&#21035;&#33021;&#22815;&#26377;&#25928;&#25429;&#25417;&#23646;&#20110;&#29305;&#23450;&#31867;&#21035;&#30340;&#26679;&#26412;&#20043;&#38388;&#20849;&#20139;&#29305;&#24449;&#30340;&#32447;&#24615;&#35268;&#24459;&#12290;&#36890;&#36807;&#38543;&#21518;&#21033;&#29992;&#36825;&#20123;&#35268;&#24459;&#22312;&#21069;&#21521;&#26041;&#24335;&#19979;&#29983;&#25104;&#19968;&#20010;&#19982;&#20998;&#31867;&#22120;&#26080;&#20851;&#30340;&#34920;&#31034;&#65292;&#23427;&#20204;&#21487;&#20197;&#22312;&#24191;&#20041;&#35774;&#32622;&#20013;&#24212;&#29992;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation learning has become a crucial area of research in machine learning, as it aims to discover efficient ways of representing raw data with useful features to increase the effectiveness, scope and applicability of downstream tasks such as classification and prediction. In this paper, we propose a novel method to generate representations for time series-type data. This method relies on ideas from theoretical physics to construct a compact representation in a data-driven way, and it can capture both the underlying structure of the data and task-specific information while still remaining intuitive, interpretable and verifiable. This novel methodology aims to identify linear laws that can effectively capture a shared characteristic among samples belonging to a specific class. By subsequently utilizing these laws to generate a classifier-agnostic representation in a forward manner, they become applicable in a generalized setting. We demonstrate the effectiveness of our approach o
&lt;/p&gt;</description></item><item><title>&#21435;&#22122;&#22768;&#26356;&#22909;&#65292;&#34920;&#29616;&#26356;&#22909;&#30340;&#20998;&#23618;&#32423;&#21035;&#28608;&#27963;&#26426;&#21046;</title><link>http://arxiv.org/abs/2306.04940</link><description>&lt;p&gt;
&#20998;&#23618;&#32423;&#21035;&#28608;&#27963;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Layer-level activation mechanism. (arXiv:2306.04940v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04940
&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#22768;&#26356;&#22909;&#65292;&#34920;&#29616;&#26356;&#22909;&#30340;&#20998;&#23618;&#32423;&#21035;&#28608;&#27963;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28608;&#27963;&#26426;&#21046;&#65292;&#26088;&#22312;&#24314;&#31435;&#20998;&#23618;&#32423;&#21035;&#28608;&#27963;&#21151;&#33021;&#65288;LayerAct&#65289;&#12290;&#36825;&#20123;&#21151;&#33021;&#26088;&#22312;&#36890;&#36807;&#20943;&#23569;&#36755;&#20837;&#20559;&#31227;&#25152;&#23548;&#33268;&#30340;&#28608;&#27963;&#36755;&#20986;&#30340;&#20998;&#23618;&#32423;&#27874;&#21160;&#26469;&#38477;&#20302;&#20256;&#32479;&#20803;&#32032;&#32423;&#28608;&#27963;&#21151;&#33021;&#30340;&#22122;&#38899;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;LayerAct&#21151;&#33021;&#23454;&#29616;&#20102;&#31867;&#20284;&#20110;&#38646;&#30340;&#24179;&#22343;&#28608;&#27963;&#36755;&#20986;&#65292;&#32780;&#19981;&#38480;&#21046;&#28608;&#27963;&#36755;&#20986;&#31354;&#38388;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20998;&#26512;&#21644;&#23454;&#39564;&#65292;&#35777;&#26126;LayerAct&#21151;&#33021;&#22312;&#22122;&#22768;&#40065;&#26834;&#24615;&#26041;&#38754;&#20248;&#20110;&#20803;&#32032;&#32423;&#28608;&#27963;&#21151;&#33021;&#65292;&#24182;&#19988;&#32463;&#39564;&#35777;&#26126;&#36825;&#20123;&#21151;&#33021;&#30340;&#24179;&#22343;&#28608;&#27963;&#32467;&#26524;&#31867;&#20284;&#20110;&#38646;&#12290;&#22312;&#19977;&#20010;&#22522;&#20934;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22788;&#29702;&#22024;&#26434;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#26102;&#65292;LayerAct&#21151;&#33021;&#27604;&#20803;&#32032;&#32423;&#28608;&#27963;&#21151;&#33021;&#34920;&#29616;&#26356;&#22909;&#65292;&#32780;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#28165;&#27905;&#25968;&#25454;&#38598;&#30340;&#34920;&#29616;&#20063;&#26159;&#20248;&#36234;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a novel activation mechanism aimed at establishing layer-level activation (LayerAct) functions. These functions are designed to be more noise-robust compared to traditional element-level activation functions by reducing the layer-level fluctuation of the activation outputs due to shift in inputs. Moreover, the LayerAct functions achieve a zero-like mean activation output without restricting the activation output space. We present an analysis and experiments demonstrating that LayerAct functions exhibit superior noise-robustness compared to element-level activation functions, and empirically show that these functions have a zero-like mean activation. Experimental results on three benchmark image classification tasks show that LayerAct functions excel in handling noisy image datasets, outperforming element-level activation functions, while the performance on clean datasets is also superior in most cases.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#24863;&#30693;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#20849;&#20139;&#27773;&#36710;&#31449;&#28857;&#30340;&#24179;&#22343;&#26376;&#24230;&#38656;&#27714;&#65292;&#21033;&#29992;&#20102;&#20016;&#23500;&#30340;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#65292;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.14421</link><description>&lt;p&gt;
&#31354;&#38388;&#24863;&#30693;&#30340;&#20849;&#20139;&#27773;&#36710;&#38656;&#27714;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Spatially-Aware Car-Sharing Demand Prediction. (arXiv:2303.14421v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#24863;&#30693;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#20849;&#20139;&#27773;&#36710;&#31449;&#28857;&#30340;&#24179;&#22343;&#26376;&#24230;&#38656;&#27714;&#65292;&#21033;&#29992;&#20102;&#20016;&#23500;&#30340;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#65292;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20849;&#20139;&#27773;&#36710;&#26381;&#21153;&#20316;&#20026;&#31169;&#20154;&#20010;&#20154;&#20986;&#34892;&#30340;&#21487;&#34892;&#26367;&#20195;&#21697;&#20986;&#29616;&#65292;&#25215;&#35834;&#26356;&#21487;&#25345;&#32493;&#12289;&#36164;&#28304;&#21033;&#29992;&#25928;&#29575;&#26356;&#39640;&#65292;&#20294;&#20173;&#28982;&#31561;&#21516;&#20110;&#31169;&#20154;&#20986;&#34892;&#12290;&#20851;&#20110;&#30701;&#26399;&#39044;&#27979;&#21644;&#20248;&#21270;&#26041;&#27861;&#30340;&#30740;&#31350;&#24050;&#32463;&#25913;&#21892;&#20102;&#20849;&#20139;&#27773;&#36710;&#26381;&#21153;&#30340;&#36816;&#33829;&#21644;&#36710;&#38431;&#25511;&#21046;;&#28982;&#32780;&#65292;&#22312;&#25991;&#29486;&#20013;&#38271;&#26399;&#39044;&#27979;&#21644;&#31354;&#38388;&#20998;&#26512;&#26159;&#32570;&#20047;&#30340;&#12290;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#20855;&#26377;&#31354;&#38388;&#24863;&#30693;&#23398;&#20064;&#31639;&#27861;&#30340;&#24179;&#22343;&#26376;&#24230;&#38656;&#27714;&#26469;&#20998;&#26512;&#22522;&#20110;&#31449;&#28857;&#30340;&#20849;&#20139;&#27773;&#36710;&#26381;&#21153;&#65292;&#36825;&#31181;&#31639;&#27861;&#26082;&#20855;&#26377;&#39640;&#39044;&#27979;&#24615;&#33021;&#65292;&#21448;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20840;&#29699;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#19982;&#31354;&#38388;&#24863;&#30693;&#26041;&#27861;&#26469;&#39044;&#27979;&#24179;&#22343;&#27599;&#20010;&#31449;&#28857;&#30340;&#26376;&#24230;&#38656;&#27714;&#12290;&#35813;&#30740;&#31350;&#21033;&#29992;&#20102;&#20016;&#23500;&#30340;&#31038;&#20250;-&#20154;&#21475;&#23398;&#12289;&#22522;&#20110;&#20301;&#32622;&#30340;(&#20363;&#22914;POI)&#21644;&#20849;&#20139;&#27773;&#36710;&#29305;&#23450;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#65292;&#36825;&#20123;&#29305;&#24449;&#26469;&#33258;&#19968;&#20010;&#22823;&#22411;&#30340;&#19987;&#26377;&#20849;&#20139;&#27773;&#36710;&#25968;&#25454;&#38598;&#21644;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20840;&#29699;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#36890;&#24120;&#34920;&#29616;&#26368;&#22909;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#31354;&#38388;&#24863;&#30693;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, car-sharing services have emerged as viable alternatives to private individual mobility, promising more sustainable and resource-efficient, but still comfortable transportation. Research on short-term prediction and optimization methods has improved operations and fleet control of car-sharing services; however, long-term projections and spatial analysis are sparse in the literature. We propose to analyze the average monthly demand in a station-based car-sharing service with spatially-aware learning algorithms that offer high predictive performance as well as interpretability. In particular, we compare the spatially-implicit Random Forest model with spatially-aware methods for predicting average monthly per-station demand. The study utilizes a rich set of socio-demographic, location-based (e.g., POIs), and car-sharing-specific features as input, extracted from a large proprietary car-sharing dataset and publicly available datasets. We show that the global Random Forest 
&lt;/p&gt;</description></item></channel></rss>