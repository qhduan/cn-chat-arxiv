<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#30740;&#31350;&#21457;&#29616;&#20102;&#25968;&#25454;&#28151;&#21512;&#35268;&#24459;&#65292;&#21487;&#20197;&#37327;&#21270;&#22320;&#39044;&#27979;&#27169;&#22411;&#24615;&#33021;&#19982;&#25968;&#25454;&#28151;&#21512;&#27604;&#20363;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#36890;&#36807;&#25311;&#21512;&#20989;&#25968;&#24418;&#24335;&#26469;&#24341;&#23548;&#29702;&#24819;&#30340;&#25968;&#25454;&#28151;&#21512;&#36873;&#25321;&#65292;&#20174;&#32780;&#20248;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35757;&#32451;&#28151;&#21512;&#12290;</title><link>https://arxiv.org/abs/2403.16952</link><description>&lt;p&gt;
&#25968;&#25454;&#28151;&#21512;&#35268;&#24459;&#65306;&#36890;&#36807;&#39044;&#27979;&#35821;&#35328;&#24314;&#27169;&#24615;&#33021;&#26469;&#20248;&#21270;&#25968;&#25454;&#28151;&#21512;
&lt;/p&gt;
&lt;p&gt;
Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16952
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21457;&#29616;&#20102;&#25968;&#25454;&#28151;&#21512;&#35268;&#24459;&#65292;&#21487;&#20197;&#37327;&#21270;&#22320;&#39044;&#27979;&#27169;&#22411;&#24615;&#33021;&#19982;&#25968;&#25454;&#28151;&#21512;&#27604;&#20363;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#36890;&#36807;&#25311;&#21512;&#20989;&#25968;&#24418;&#24335;&#26469;&#24341;&#23548;&#29702;&#24819;&#30340;&#25968;&#25454;&#28151;&#21512;&#36873;&#25321;&#65292;&#20174;&#32780;&#20248;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35757;&#32451;&#28151;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#25968;&#25454;&#21253;&#25324;&#22810;&#20010;&#39046;&#22495;&#65288;&#20363;&#22914;&#32593;&#32476;&#25991;&#26412;&#12289;&#23398;&#26415;&#35770;&#25991;&#12289;&#20195;&#30721;&#65289;&#65292;&#20854;&#28151;&#21512;&#27604;&#20363;&#23545;&#32467;&#26524;&#27169;&#22411;&#30340;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#36890;&#24120;&#20381;&#36182;&#20110;&#21551;&#21457;&#24335;&#26041;&#27861;&#25110;&#23450;&#24615;&#31574;&#30053;&#26469;&#35843;&#25972;&#27604;&#20363;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#27169;&#22411;&#24615;&#33021;&#19982;&#28151;&#21512;&#27604;&#20363;&#20043;&#38388;&#30340;&#20989;&#25968;&#24418;&#24335;&#30340;&#23450;&#37327;&#21487;&#39044;&#27979;&#24615;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#25968;&#25454;&#28151;&#21512;&#35268;&#24459;&#12290;&#22312;&#26679;&#26412;&#28151;&#21512;&#19978;&#25311;&#21512;&#36825;&#31181;&#20989;&#25968;&#25581;&#31034;&#20102;&#26410;&#35265;&#28151;&#21512;&#30340;&#27169;&#22411;&#24615;&#33021;&#65292;&#20174;&#32780;&#24341;&#23548;&#36873;&#25321;&#29702;&#24819;&#30340;&#25968;&#25454;&#28151;&#21512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35757;&#32451;&#27493;&#39588;&#12289;&#27169;&#22411;&#22823;&#23567;&#21644;&#25105;&#20204;&#30340;&#25968;&#25454;&#28151;&#21512;&#35268;&#24459;&#30340;&#32553;&#25918;&#35268;&#24459;&#30340;&#23884;&#22871;&#20351;&#29992;&#65292;&#20197;&#20351;&#24471;&#20165;&#36890;&#36807;&#23567;&#35268;&#27169;&#35757;&#32451;&#23601;&#33021;&#22815;&#39044;&#27979;&#22312;&#21508;&#31181;&#28151;&#21512;&#25968;&#25454;&#19979;&#35757;&#32451;&#30340;&#22823;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#20248;&#21270;&#20102;&#35757;&#32451;&#28151;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16952v1 Announce Type: cross  Abstract: Pretraining data of large language models composes multiple domains (e.g., web texts, academic papers, codes), whose mixture proportions crucially impact the competence of outcome models. While existing endeavors rely on heuristics or qualitative strategies to tune the proportions, we discover the quantitative predictability of model performance regarding the mixture proportions in function forms, which we refer to as the data mixing laws. Fitting such functions on sample mixtures unveils model performance on unseen mixtures before actual runs, thus guiding the selection of an ideal data mixture. Furthermore, we propose nested use of the scaling laws of training steps, model sizes, and our data mixing law to enable predicting the performance of large models trained on massive data under various mixtures with only small-scale training. Moreover, experimental results verify that our method effectively optimizes the training mixture of a 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25345;&#32493;&#30340;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#20998;&#25955;&#30340;&#23398;&#20064;&#26550;&#26500;&#65292;&#26469;&#35299;&#20915;&#20132;&#36890;&#36335;&#21475;&#31359;&#36234;&#21644;&#33258;&#20027;&#36187;&#36710;&#31561;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.10996</link><description>&lt;p&gt;
&#19968;&#20010;&#21487;&#25193;&#23637;&#19988;&#21487;&#24182;&#34892;&#21270;&#30340;&#25968;&#23383;&#23402;&#29983;&#26694;&#26550;&#65292;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#21487;&#25345;&#32493;Sim2Real&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
A Scalable and Parallelizable Digital Twin Framework for Sustainable Sim2Real Transition of Multi-Agent Reinforcement Learning Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10996
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25345;&#32493;&#30340;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#20998;&#25955;&#30340;&#23398;&#20064;&#26550;&#26500;&#65292;&#26469;&#35299;&#20915;&#20132;&#36890;&#36335;&#21475;&#31359;&#36234;&#21644;&#33258;&#20027;&#36187;&#36710;&#31561;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25345;&#32493;&#30340;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#36873;&#25321;&#24615;&#22320;&#25353;&#38656;&#25193;&#23637;&#24182;&#34892;&#21270;&#35757;&#32451;&#24037;&#20316;&#36127;&#36733;&#65292;&#24182;&#21033;&#29992;&#26368;&#23569;&#30340;&#30828;&#20214;&#36164;&#28304;&#23558;&#35757;&#32451;&#22909;&#30340;&#31574;&#30053;&#20174;&#27169;&#25311;&#29615;&#22659;&#36716;&#31227;&#21040;&#29616;&#23454;&#19990;&#30028;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;AutoDRIVE&#29983;&#24577;&#31995;&#32479;&#20316;&#20026;&#19968;&#20010;&#21551;&#21160;&#25968;&#23383;&#23402;&#29983;&#26694;&#26550;&#65292;&#29992;&#20110;&#35757;&#32451;&#12289;&#37096;&#32626;&#21644;&#36716;&#31227;&#21512;&#20316;&#21644;&#31454;&#20105;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20174;&#27169;&#25311;&#29615;&#22659;&#21040;&#29616;&#23454;&#19990;&#30028;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25506;&#31350;&#20102;4&#21488;&#21512;&#20316;&#36710;&#36742;(Nigel)&#22312;&#21333;&#26234;&#33021;&#20307;&#21644;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;&#29615;&#22659;&#20013;&#20849;&#20139;&#26377;&#38480;&#29366;&#24577;&#20449;&#24687;&#30340;&#20132;&#21449;&#36941;&#21382;&#38382;&#39064;&#65292;&#37319;&#29992;&#20102;&#19968;&#31181;&#36890;&#29992;&#31574;&#30053;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#20010;&#20307;&#31574;&#30053;&#26041;&#27861;&#30740;&#31350;&#20102;2&#36742;&#36710;(F1TENTH)&#30340;&#23545;&#25239;&#24615;&#33258;&#20027;&#36187;&#36710;&#38382;&#39064;&#12290;&#22312;&#20219;&#20309;&#19968;&#32452;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#26550;&#26500;&#65292;&#36825;&#20801;&#35768;&#23545;&#31574;&#30053;&#36827;&#34892;&#26377;&#21147;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10996v1 Announce Type: cross  Abstract: This work presents a sustainable multi-agent deep reinforcement learning framework capable of selectively scaling parallelized training workloads on-demand, and transferring the trained policies from simulation to reality using minimal hardware resources. We introduce AutoDRIVE Ecosystem as an enabling digital twin framework to train, deploy, and transfer cooperative as well as competitive multi-agent reinforcement learning policies from simulation to reality. Particularly, we first investigate an intersection traversal problem of 4 cooperative vehicles (Nigel) that share limited state information in single as well as multi-agent learning settings using a common policy approach. We then investigate an adversarial autonomous racing problem of 2 vehicles (F1TENTH) using an individual policy approach. In either set of experiments, a decentralized learning architecture was adopted, which allowed robust training and testing of the policies 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#32852;&#32593;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#26234;&#33021;&#20892;&#19994;&#28201;&#23460;&#25511;&#21046;&#31995;&#32479;&#65292;&#36890;&#36807;&#30417;&#27979;&#21644;&#35843;&#25511;&#28201;&#23460;&#20869;&#29615;&#22659;&#26465;&#20214;&#65292;&#25552;&#39640;&#20316;&#29289;&#29983;&#38271;&#25928;&#29575;&#21644;&#20135;&#37327;&#65292;&#20943;&#23569;&#36164;&#28304;&#28010;&#36153;&#12290;</title><link>https://arxiv.org/abs/2402.09488</link><description>&lt;p&gt;
&#22522;&#20110;&#29289;&#32852;&#32593;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#26234;&#33021;&#20892;&#19994;&#28201;&#23460;&#25511;&#21046;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Intelligent Agricultural Greenhouse Control System Based on Internet of Things and Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09488
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#32852;&#32593;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#26234;&#33021;&#20892;&#19994;&#28201;&#23460;&#25511;&#21046;&#31995;&#32479;&#65292;&#36890;&#36807;&#30417;&#27979;&#21644;&#35843;&#25511;&#28201;&#23460;&#20869;&#29615;&#22659;&#26465;&#20214;&#65292;&#25552;&#39640;&#20316;&#29289;&#29983;&#38271;&#25928;&#29575;&#21644;&#20135;&#37327;&#65292;&#20943;&#23569;&#36164;&#28304;&#28010;&#36153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35797;&#22270;&#23558;&#29289;&#32852;&#32593;&#21644;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#26500;&#24314;&#19968;&#20010;&#20808;&#36827;&#30340;&#20892;&#19994;&#28201;&#23460;&#25511;&#21046;&#31995;&#32479;&#12290;&#36890;&#36807;&#23545;&#28201;&#23460;&#20869;&#22266;&#26377;&#29615;&#22659;&#21442;&#25968;&#30340;&#32454;&#33268;&#30417;&#27979;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#25972;&#21512;&#65292;&#33021;&#22815;&#36866;&#24403;&#35843;&#25511;&#28201;&#23460;&#20869;&#30340;&#26465;&#20214;&#12290;&#39044;&#26399;&#30340;&#32467;&#26524;&#26159;&#22686;&#21152;&#20316;&#29289;&#29983;&#38271;&#25928;&#29575;&#21644;&#20135;&#37327;&#65292;&#21516;&#26102;&#20943;&#23569;&#36164;&#28304;&#28010;&#36153;&#12290;&#22312;&#20840;&#29699;&#20154;&#21475;&#25345;&#32493;&#22686;&#38271;&#21644;&#27668;&#20505;&#21464;&#21270;&#19981;&#26029;&#21152;&#21095;&#30340;&#32972;&#26223;&#19979;&#65292;&#20892;&#19994;&#38754;&#20020;&#21069;&#25152;&#26410;&#26377;&#30340;&#25361;&#25112;&#12290;&#20256;&#32479;&#20892;&#19994;&#33539;&#24335;&#24050;&#32463;&#34987;&#35777;&#26126;&#26080;&#27861;&#28385;&#36275;&#39135;&#21697;&#23433;&#20840;&#21644;&#29983;&#20135;&#25928;&#29575;&#30340;&#35201;&#27714;&#12290;&#22312;&#36825;&#31181;&#32972;&#26223;&#19979;&#65292;&#28201;&#23460;&#20892;&#19994;&#25104;&#20026;&#19968;&#31181;&#21487;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20026;&#20316;&#29289;&#31181;&#26893;&#25552;&#20379;&#20102;&#19968;&#20010;&#21463;&#25511;&#30340;&#29615;&#22659;&#26469;&#22686;&#21152;&#20135;&#37327;&#65292;&#25913;&#21892;&#21697;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09488v1 Announce Type: cross  Abstract: This study endeavors to conceptualize and execute a sophisticated agricultural greenhouse control system grounded in the amalgamation of the Internet of Things (IoT) and machine learning. Through meticulous monitoring of intrinsic environmental parameters within the greenhouse and the integration of machine learning algorithms, the conditions within the greenhouse are aptly modulated. The envisaged outcome is an enhancement in crop growth efficiency and yield, accompanied by a reduction in resource wastage. In the backdrop of escalating global population figures and the escalating exigencies of climate change, agriculture confronts unprecedented challenges. Conventional agricultural paradigms have proven inadequate in addressing the imperatives of food safety and production efficiency. Against this backdrop, greenhouse agriculture emerges as a viable solution, proffering a controlled milieu for crop cultivation to augment yields, refin
&lt;/p&gt;</description></item><item><title>GenEFT&#26159;&#19968;&#20010;&#26377;&#25928;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#30740;&#31350;&#27867;&#21270;&#30456;&#21464;&#21644;&#34920;&#31034;&#23398;&#20064;&#21160;&#24577;&#65292;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#38745;&#24577;&#21644;&#21160;&#24577;&#29305;&#24615;&#65292;&#36825;&#24357;&#21512;&#20102;&#26426;&#22120;&#23398;&#20064;&#29702;&#35770;&#39044;&#27979;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2402.05916</link><description>&lt;p&gt;
GenEFT: &#36890;&#36807;&#26377;&#25928;&#29702;&#35770;&#29702;&#35299;&#27169;&#22411;&#27867;&#21270;&#30340;&#38745;&#24577;&#21644;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
GenEFT: Understanding Statics and Dynamics of Model Generalization via Effective Theory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05916
&lt;/p&gt;
&lt;p&gt;
GenEFT&#26159;&#19968;&#20010;&#26377;&#25928;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#30740;&#31350;&#27867;&#21270;&#30456;&#21464;&#21644;&#34920;&#31034;&#23398;&#20064;&#21160;&#24577;&#65292;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#38745;&#24577;&#21644;&#21160;&#24577;&#29305;&#24615;&#65292;&#36825;&#24357;&#21512;&#20102;&#26426;&#22120;&#23398;&#20064;&#29702;&#35770;&#39044;&#27979;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;GenEFT&#65306;&#19968;&#20010;&#26377;&#25928;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#25581;&#31034;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#38745;&#24577;&#21644;&#21160;&#24577;&#65292;&#20197;&#22270;&#23398;&#20064;&#20026;&#20363;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#35268;&#27169;&#22686;&#21152;&#26102;&#30340;&#27867;&#21270;&#30456;&#21464;&#65292;&#23558;&#23454;&#39564;&#32467;&#26524;&#19982;&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#30340;&#36817;&#20284;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#35299;&#30721;&#22120;&#26082;&#19981;&#22826;&#24369;&#20063;&#19981;&#22826;&#24378;&#30340;&#8220;&#23567;&#29066;&#23453;&#36125;&#21306;&#22495;&#8221;&#20013;&#23384;&#22312;&#30528;&#27867;&#21270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#21160;&#24577;&#30340;&#26377;&#25928;&#29702;&#35770;&#65292;&#23558;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;&#24314;&#27169;&#20026;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#65288;repons&#65289;&#65292;&#21457;&#29616;&#23427;&#35299;&#37322;&#20102;&#25105;&#20204;&#22312;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#23398;&#20064;&#36895;&#29575;&#25195;&#25551;&#26102;&#35266;&#23519;&#21040;&#30340;&#27867;&#21270;&#21644;&#36807;&#25311;&#21512;&#20043;&#38388;&#30340;&#30456;&#21464;&#12290;&#36825;&#31361;&#20986;&#20102;&#21463;&#29289;&#29702;&#21551;&#21457;&#30340;&#26377;&#25928;&#29702;&#35770;&#22312;&#24357;&#21512;&#26426;&#22120;&#23398;&#20064;&#20013;&#29702;&#35770;&#39044;&#27979;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#26041;&#38754;&#30340;&#21147;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present GenEFT: an effective theory framework for shedding light on the statics and dynamics of neural network generalization, and illustrate it with graph learning examples. We first investigate the generalization phase transition as data size increases, comparing experimental results with information-theory-based approximations. We find generalization in a Goldilocks zone where the decoder is neither too weak nor too powerful. We then introduce an effective theory for the dynamics of representation learning, where latent-space representations are modeled as interacting particles (repons), and find that it explains our experimentally observed phase transition between generalization and overfitting as encoder and decoder learning rates are scanned. This highlights the power of physics-inspired effective theories for bridging the gap between theoretical predictions and practice in machine learning.
&lt;/p&gt;</description></item><item><title>Crowd-PrefRL&#26159;&#19968;&#31181;&#22522;&#20110;&#20247;&#21253;&#30340;&#20559;&#22909;&#21453;&#39304;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#20174;&#26469;&#33258;&#32676;&#20307;&#30340;&#21453;&#39304;&#20013;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#65292;&#24182;&#19988;&#33021;&#22815;&#24378;&#22823;&#22320;&#32858;&#21512;&#32676;&#20307;&#20559;&#22909;&#21453;&#39304;&#24182;&#20272;&#35745;&#29992;&#25143;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.10941</link><description>&lt;p&gt;
Crowd-PrefRL: &#22522;&#20110;&#20247;&#21253;&#30340;&#20559;&#22909;&#21453;&#39304;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Crowd-PrefRL: Preference-Based Reward Learning from Crowds. (arXiv:2401.10941v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10941
&lt;/p&gt;
&lt;p&gt;
Crowd-PrefRL&#26159;&#19968;&#31181;&#22522;&#20110;&#20247;&#21253;&#30340;&#20559;&#22909;&#21453;&#39304;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#20174;&#26469;&#33258;&#32676;&#20307;&#30340;&#21453;&#39304;&#20013;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#65292;&#24182;&#19988;&#33021;&#22815;&#24378;&#22823;&#22320;&#32858;&#21512;&#32676;&#20307;&#20559;&#22909;&#21453;&#39304;&#24182;&#20272;&#35745;&#29992;&#25143;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20559;&#22909;&#30340;&#24378;&#21270;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#34892;&#20026;&#23545;&#30340;&#20559;&#22909;&#36827;&#34892;&#20154;&#31867;&#21453;&#39304;&#26469;&#35757;&#32451;&#26234;&#33021;&#20307;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#38590;&#20197;&#25351;&#23450;&#25968;&#20540;&#22870;&#21169;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#26399;&#26395;&#30340;&#34892;&#20026;&#12290;&#23613;&#31649;&#36825;&#20010;&#33539;&#24335;&#21033;&#29992;&#20102;&#20154;&#31867;&#30340;&#21453;&#39304;&#65292;&#20294;&#30446;&#21069;&#23558;&#21453;&#39304;&#35270;&#20026;&#21333;&#20010;&#20154;&#31867;&#29992;&#25143;&#25152;&#32473;&#20986;&#30340;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#20197;&#24378;&#22823;&#30340;&#26041;&#24335;&#21512;&#24182;&#26469;&#33258;&#32676;&#20307;&#65288;&#21363;&#29992;&#25143;&#38598;&#21512;&#65289;&#30340;&#20559;&#22909;&#21453;&#39304;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#32780;&#20351;&#29992;&#26469;&#33258;&#22810;&#20010;&#29992;&#25143;&#30340;&#21453;&#39304;&#26469;&#35757;&#32451;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#30340;&#38382;&#39064;&#20173;&#28982;&#34987;&#30740;&#31350;&#19981;&#36275;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Crowd-PrefRL&#65292;&#19968;&#20010;&#21033;&#29992;&#26469;&#33258;&#32676;&#20307;&#30340;&#21453;&#39304;&#36827;&#34892;&#22522;&#20110;&#20559;&#22909;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#26694;&#26550;&#12290;&#36825;&#39033;&#24037;&#20316;&#23637;&#31034;&#20102;&#21033;&#29992;&#26410;&#30693;&#19987;&#19994;&#27700;&#24179;&#21644;&#21487;&#38752;&#24615;&#30340;&#32676;&#20307;&#20559;&#22909;&#21453;&#39304;&#26469;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#30340;&#21487;&#34892;&#24615;&#12290;Crowd-PrefRL&#19981;&#20165;&#33021;&#22815;&#24378;&#22823;&#22320;&#32858;&#21512;&#32676;&#20307;&#20559;&#22909;&#21453;&#39304;&#65292;&#36824;&#33021;&#22815;&#20272;&#35745;&#27599;&#20010;&#29992;&#25143;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Preference-based reinforcement learning (RL) provides a framework to train agents using human feedback through pairwise preferences over pairs of behaviors, enabling agents to learn desired behaviors when it is difficult to specify a numerical reward function. While this paradigm leverages human feedback, it currently treats the feedback as given by a single human user. Meanwhile, incorporating preference feedback from crowds (i.e. ensembles of users) in a robust manner remains a challenge, and the problem of training RL agents using feedback from multiple human users remains understudied. In this work, we introduce Crowd-PrefRL, a framework for performing preference-based RL leveraging feedback from crowds. This work demonstrates the viability of learning reward functions from preference feedback provided by crowds of unknown expertise and reliability. Crowd-PrefRL not only robustly aggregates the crowd preference feedback, but also estimates the reliability of each user within the cr
&lt;/p&gt;</description></item><item><title>CLAN&#26159;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26032;&#39062;&#24615;&#26816;&#27979;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20154;&#20307;&#27963;&#21160;&#35782;&#21035;&#20013;&#30340;&#25361;&#25112;&#65292;&#24182;&#26500;&#24314;&#23545;&#25361;&#25112;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#24050;&#30693;&#27963;&#21160;&#30340;&#34920;&#31034;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.10288</link><description>&lt;p&gt;
CLAN:&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#29992;&#20110;&#20154;&#20307;&#27963;&#21160;&#35782;&#21035;&#30340;&#26032;&#39062;&#24615;&#26816;&#27979;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
CLAN: A Contrastive Learning based Novelty Detection Framework for Human Activity Recognition. (arXiv:2401.10288v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10288
&lt;/p&gt;
&lt;p&gt;
CLAN&#26159;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26032;&#39062;&#24615;&#26816;&#27979;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20154;&#20307;&#27963;&#21160;&#35782;&#21035;&#20013;&#30340;&#25361;&#25112;&#65292;&#24182;&#26500;&#24314;&#23545;&#25361;&#25112;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#24050;&#30693;&#27963;&#21160;&#30340;&#34920;&#31034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29615;&#22659;&#36741;&#21161;&#29983;&#27963;&#20013;&#65292;&#20174;&#26102;&#38388;&#24207;&#21015;&#20256;&#24863;&#22120;&#25968;&#25454;&#36827;&#34892;&#20154;&#20307;&#27963;&#21160;&#35782;&#21035;&#20027;&#35201;&#38598;&#20013;&#20110;&#39044;&#23450;&#20041;&#30340;&#27963;&#21160;&#65292;&#24448;&#24448;&#24573;&#30053;&#20102;&#26032;&#30340;&#27963;&#21160;&#27169;&#24335;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;CLAN&#65292;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#26032;&#39062;&#24615;&#26816;&#27979;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#36127;&#26679;&#26412;&#23545;&#20110;&#20154;&#20307;&#27963;&#21160;&#35782;&#21035;&#12290;&#35813;&#26694;&#26550;&#38024;&#23545;&#20154;&#20307;&#27963;&#21160;&#29305;&#24449;&#30340;&#25361;&#25112;&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#21253;&#25324;&#26102;&#38388;&#21644;&#39057;&#29575;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#12289;&#22797;&#26434;&#30340;&#27963;&#21160;&#21160;&#24577;&#12289;&#27963;&#21160;&#20043;&#38388;&#20849;&#20139;&#30340;&#29305;&#24449;&#65292;&#20197;&#21450;&#20256;&#24863;&#22120;&#27169;&#24577;&#30340;&#21464;&#21270;&#12290;&#35813;&#26694;&#26550;&#26088;&#22312;&#26500;&#24314;&#23545;&#25361;&#25112;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#24050;&#30693;&#27963;&#21160;&#30340;&#34920;&#31034;&#26041;&#27861;&#12290;&#20026;&#20102;&#29983;&#25104;&#21512;&#36866;&#30340;&#36127;&#26679;&#26412;&#23545;&#65292;&#23427;&#26681;&#25454;&#27599;&#20010;&#25968;&#25454;&#38598;&#30340;&#26102;&#38388;&#21644;&#39057;&#29575;&#29305;&#24449;&#36873;&#25321;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#12290;&#23427;&#36890;&#36807;&#23545;&#27604;&#21644;&#20998;&#31867;&#25439;&#22833;&#30340;&#34920;&#31034;&#23398;&#20064;&#20197;&#21450;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#30340;&#26032;&#39062;&#24615;&#26816;&#27979;&#65292;&#20174;&#20013;&#23548;&#20986;&#38024;&#23545;&#26080;&#24847;&#20041;&#21160;&#24577;&#30340;&#20851;&#38190;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
In ambient assisted living, human activity recognition from time series sensor data mainly focuses on predefined activities, often overlooking new activity patterns. We propose CLAN, a two-tower contrastive learning-based novelty detection framework with diverse types of negative pairs for human activity recognition. It is tailored to challenges with human activity characteristics, including the significance of temporal and frequency features, complex activity dynamics, shared features across activities, and sensor modality variations. The framework aims to construct invariant representations of known activity robust to the challenges. To generate suitable negative pairs, it selects data augmentation methods according to the temporal and frequency characteristics of each dataset. It derives the key representations against meaningless dynamics by contrastive and classification losses-based representation learning and score function-based novelty detection that accommodate dynamic number
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#30340;&#35282;&#24230;&#28145;&#20837;&#30740;&#31350;&#20102;&#32500;&#24230;&#35781;&#21650;&#30340;&#20004;&#20010;&#20027;&#35201;&#21407;&#22240;&#8212;&#8212;&#36317;&#31163;&#38598;&#20013;&#21644;&#27969;&#24418;&#25928;&#24212;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20351;&#29992;Minkowski&#36317;&#31163;&#36827;&#34892;&#26368;&#36817;&#37051;&#25628;&#32034;&#65288;NNS&#65289;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#21462;&#24471;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.00422</link><description>&lt;p&gt;
&#20174;&#36317;&#31163;&#38598;&#20013;&#21644;&#27969;&#24418;&#25928;&#24212;&#35299;&#35835;&#32500;&#24230;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
Interpreting the Curse of Dimensionality from Distance Concentration and Manifold Effect. (arXiv:2401.00422v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00422
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#30340;&#35282;&#24230;&#28145;&#20837;&#30740;&#31350;&#20102;&#32500;&#24230;&#35781;&#21650;&#30340;&#20004;&#20010;&#20027;&#35201;&#21407;&#22240;&#8212;&#8212;&#36317;&#31163;&#38598;&#20013;&#21644;&#27969;&#24418;&#25928;&#24212;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20351;&#29992;Minkowski&#36317;&#31163;&#36827;&#34892;&#26368;&#36817;&#37051;&#25628;&#32034;&#65288;NNS&#65289;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#21462;&#24471;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#25968;&#25454;&#30340;&#29305;&#24449;&#22914;&#20998;&#24067;&#21644;&#24322;&#36136;&#24615;&#21464;&#24471;&#36234;&#26469;&#36234;&#22797;&#26434;&#21644;&#36829;&#21453;&#30452;&#35273;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#32500;&#24230;&#35781;&#21650;&#65292;&#20302;&#32500;&#31354;&#38388;&#20013;&#25104;&#31435;&#30340;&#24120;&#35265;&#27169;&#24335;&#21644;&#20851;&#31995;&#65288;&#20363;&#22914;&#20869;&#37096;&#21644;&#36793;&#30028;&#27169;&#24335;&#65289;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#21487;&#33021;&#26080;&#25928;&#12290;&#36825;&#23548;&#33268;&#22238;&#24402;&#12289;&#20998;&#31867;&#25110;&#32858;&#31867;&#27169;&#22411;&#25110;&#31639;&#27861;&#30340;&#24615;&#33021;&#38477;&#20302;&#12290;&#32500;&#24230;&#35781;&#21650;&#21487;&#20197;&#24402;&#22240;&#20110;&#35768;&#22810;&#21407;&#22240;&#12290;&#26412;&#25991;&#39318;&#20808;&#24635;&#32467;&#20102;&#19982;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#30456;&#20851;&#30340;&#20116;&#20010;&#25361;&#25112;&#65292;&#24182;&#35299;&#37322;&#20102;&#22238;&#24402;&#12289;&#20998;&#31867;&#25110;&#32858;&#31867;&#20219;&#21153;&#22833;&#36133;&#30340;&#28508;&#22312;&#21407;&#22240;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#28145;&#20837;&#30740;&#31350;&#20102;&#32500;&#24230;&#35781;&#21650;&#30340;&#20004;&#20010;&#20027;&#35201;&#21407;&#22240;&#65292;&#21363;&#36317;&#31163;&#38598;&#20013;&#21644;&#27969;&#24418;&#25928;&#24212;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#19977;&#31181;&#20856;&#22411;&#30340;&#36317;&#31163;&#27979;&#37327;&#36827;&#34892;&#26368;&#36817;&#37051;&#25628;&#32034;&#65288;NNS&#65289;&#26102;&#65292;Minkowski&#36317;&#31163;&#30340;&#24615;&#33021;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;
The characteristics of data like distribution and heterogeneity, become more complex and counterintuitive as the dimensionality increases. This phenomenon is known as curse of dimensionality, where common patterns and relationships (e.g., internal and boundary pattern) that hold in low-dimensional space may be invalid in higher-dimensional space. It leads to a decreasing performance for the regression, classification or clustering models or algorithms. Curse of dimensionality can be attributed to many causes. In this paper, we first summarize five challenges associated with manipulating high-dimensional data, and explains the potential causes for the failure of regression, classification or clustering tasks. Subsequently, we delve into two major causes of the curse of dimensionality, distance concentration and manifold effect, by performing theoretical and empirical analyses. The results demonstrate that nearest neighbor search (NNS) using three typical distance measurements, Minkowski
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#28436;&#21592;-&#35780;&#35770;&#23478;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#32467;&#21512;&#36215;&#26469;&#65292;&#21033;&#29992;&#35299;&#32806;&#30340;&#23545;&#35937;&#34920;&#31034;&#26377;&#25928;&#22320;&#23398;&#20064;&#31574;&#30053;&#12290;&#35813;&#26041;&#27861;&#22635;&#34917;&#20102;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#39640;&#25928;&#19988;&#36866;&#29992;&#20110;&#31163;&#25955;&#25110;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#30340;&#19990;&#30028;&#27169;&#22411;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2310.17178</link><description>&lt;p&gt;
&#22270;&#24418;&#21270;&#30340;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;Actor-Critic&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Graphical Object-Centric Actor-Critic. (arXiv:2310.17178v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17178
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#28436;&#21592;-&#35780;&#35770;&#23478;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#32467;&#21512;&#36215;&#26469;&#65292;&#21033;&#29992;&#35299;&#32806;&#30340;&#23545;&#35937;&#34920;&#31034;&#26377;&#25928;&#22320;&#23398;&#20064;&#31574;&#30053;&#12290;&#35813;&#26041;&#27861;&#22635;&#34917;&#20102;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#39640;&#25928;&#19988;&#36866;&#29992;&#20110;&#31163;&#25955;&#25110;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#30340;&#19990;&#30028;&#27169;&#22411;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#26080;&#30417;&#30563;&#30340;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#34920;&#31034;&#23398;&#20064;&#21450;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#26368;&#26032;&#30340;&#30740;&#31350;&#25903;&#25345;&#36825;&#26679;&#19968;&#20010;&#35266;&#28857;&#65292;&#21363;&#22312;&#22522;&#20110;&#22270;&#20687;&#30340;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#37319;&#29992;&#35299;&#32806;&#30340;&#23545;&#35937;&#34920;&#31034;&#33021;&#22815;&#20419;&#36827;&#31574;&#30053;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#26377;&#25928;&#21033;&#29992;&#36825;&#20123;&#34920;&#31034;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21464;&#25442;&#22120;&#32534;&#30721;&#22120;&#26469;&#25552;&#21462;&#23545;&#35937;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#29615;&#22659;&#30340;&#21160;&#21147;&#23398;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22635;&#34917;&#20102;&#24320;&#21457;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#21487;&#20197;&#29992;&#20110;&#31163;&#25955;&#25110;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#30340;&#39640;&#25928;&#20197;&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#19990;&#30028;&#27169;&#22411;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#20010;&#20855;&#26377;&#22797;&#26434;&#35270;&#35273;3D&#26426;&#22120;&#20154;&#29615;&#22659;&#21644;&#19968;&#20010;&#20855;&#26377;&#32452;&#21512;&#32467;&#26500;&#30340;2D&#29615;&#22659;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
There have recently been significant advances in the problem of unsupervised object-centric representation learning and its application to downstream tasks. The latest works support the argument that employing disentangled object representations in image-based object-centric reinforcement learning tasks facilitates policy learning. We propose a novel object-centric reinforcement learning algorithm combining actor-critic and model-based approaches to utilize these representations effectively. In our approach, we use a transformer encoder to extract object representations and graph neural networks to approximate the dynamics of an environment. The proposed method fills a research gap in developing efficient object-centric world models for reinforcement learning settings that can be used for environments with discrete or continuous action spaces. Our algorithm performs better in a visually complex 3D robotic environment and a 2D environment with compositional structure than the state-of-t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.02211</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Machine Learning with Multi-source Data. (arXiv:2309.02211v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#30446;&#26631;&#20998;&#24067;&#19982;&#28304;&#25968;&#25454;&#38598;&#19981;&#21516;&#26102;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#36739;&#24046;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26412;&#25991;&#21033;&#29992;&#22810;&#20010;&#25968;&#25454;&#28304;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#20248;&#21270;&#20851;&#20110;&#30446;&#26631;&#20998;&#24067;&#31867;&#30340;&#21487;&#35299;&#37322;&#26041;&#24046;&#30340;&#23545;&#25239;&#24615;&#22870;&#21169;&#12290;&#19982;&#20256;&#32479;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#25913;&#21892;&#20102;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26159;&#28304;&#25968;&#25454;&#38598;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340;&#21152;&#26435;&#24179;&#22343;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#20851;&#38190;&#37492;&#21035;&#32467;&#26524;&#26469;&#25552;&#39640;&#20219;&#24847;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#21644;&#31070;&#32463;&#32593;&#32476;&#31561;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#22120;&#26469;&#20272;&#35745;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;c&#26041;&#38754;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal aggregation weight for general machine-learning algorithms and demonstrate its improvement in the c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#24615;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#20107;&#21518;&#26041;&#27861;BELLA&#65292;&#29992;&#20110;&#35299;&#37322;&#22238;&#24402;&#40657;&#30418;&#27169;&#22411;&#30340;&#20010;&#21035;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#29305;&#24449;&#31354;&#38388;&#20013;&#35757;&#32451;&#30340;&#32447;&#24615;&#27169;&#22411;&#25552;&#20379;&#35299;&#37322;&#65292;&#20351;&#24471;&#35813;&#27169;&#22411;&#30340;&#31995;&#25968;&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#35745;&#31639;&#29305;&#24449;&#20540;&#30340;&#39044;&#27979;&#20540;&#12290;&#27492;&#22806;&#65292;BELLA&#26368;&#22823;&#21270;&#20102;&#32447;&#24615;&#27169;&#22411;&#36866;&#29992;&#30340;&#39046;&#22495;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2305.11311</link><description>&lt;p&gt;
BELLA: &#36890;&#36807;&#26412;&#22320;&#32447;&#24615;&#36924;&#36817;&#36827;&#34892;&#40657;&#30418;&#27169;&#22411;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
BELLA: Black box model Explanations by Local Linear Approximations. (arXiv:2305.11311v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#24615;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#20107;&#21518;&#26041;&#27861;BELLA&#65292;&#29992;&#20110;&#35299;&#37322;&#22238;&#24402;&#40657;&#30418;&#27169;&#22411;&#30340;&#20010;&#21035;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#29305;&#24449;&#31354;&#38388;&#20013;&#35757;&#32451;&#30340;&#32447;&#24615;&#27169;&#22411;&#25552;&#20379;&#35299;&#37322;&#65292;&#20351;&#24471;&#35813;&#27169;&#22411;&#30340;&#31995;&#25968;&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#35745;&#31639;&#29305;&#24449;&#20540;&#30340;&#39044;&#27979;&#20540;&#12290;&#27492;&#22806;&#65292;BELLA&#26368;&#22823;&#21270;&#20102;&#32447;&#24615;&#27169;&#22411;&#36866;&#29992;&#30340;&#39046;&#22495;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29702;&#35299;&#40657;&#30418;&#27169;&#22411;&#30340;&#20915;&#31574;&#36807;&#31243;&#19981;&#20165;&#25104;&#20026;&#27861;&#24459;&#35201;&#27714;&#65292;&#20063;&#25104;&#20026;&#35780;&#20272;&#20854;&#24615;&#33021;&#30340;&#21478;&#19968;&#31181;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#20381;&#36182;&#20110;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#65292;&#36825;&#24341;&#20837;&#20102;&#19981;&#30830;&#23450;&#24615;&#24182;&#21487;&#33021;&#25439;&#23475;&#35299;&#37322;&#30340;&#21487;&#38752;&#24615;&#65292;&#24182;&#19988;&#23427;&#20204; tend to produce explanations that apply to only very few data points. This makes the explanations brittle and limited in scope. Finally, they provide scores that have no direct verifiable meaning. In this paper, we present BELLA, a deterministic model-agnostic post-hoc approach for explaining the individual predictions of regression black-box models. BELLA provides explanations in the form of a linear model trained in the feature space. Thus, its coefficients can be used directly to compute the predicted value from the feature values. Furthermore, BELLA maximizes the size of the neighborhood to which the linear model a
&lt;/p&gt;
&lt;p&gt;
In recent years, understanding the decision-making process of black-box models has become not only a legal requirement but also an additional way to assess their performance. However, the state of the art post-hoc interpretation approaches rely on synthetic data generation. This introduces uncertainty and can hurt the reliability of the interpretations. Furthermore, they tend to produce explanations that apply to only very few data points. This makes the explanations brittle and limited in scope. Finally, they provide scores that have no direct verifiable meaning. In this paper, we present BELLA, a deterministic model-agnostic post-hoc approach for explaining the individual predictions of regression black-box models. BELLA provides explanations in the form of a linear model trained in the feature space. Thus, its coefficients can be used directly to compute the predicted value from the feature values. Furthermore, BELLA maximizes the size of the neighborhood to which the linear model a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#28216;&#25103;&#20013;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#30495;&#23454;&#21644;&#27169;&#25311;&#25968;&#25454;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.10361</link><description>&lt;p&gt;
&#38750;&#21512;&#20316;&#21338;&#24328;&#20013;&#30340;&#20154;&#31867;&#36873;&#25321;&#39044;&#27979;&#65306;&#22522;&#20110;&#27169;&#25311;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Human Choice Prediction in Non-Cooperative Games: Simulation-based Off-Policy Evaluation. (arXiv:2305.10361v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#28216;&#25103;&#20013;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#30495;&#23454;&#21644;&#27169;&#25311;&#25968;&#25454;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35828;&#26381;&#28216;&#25103;&#22312;&#32463;&#27982;&#21644;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#24182;&#20855;&#26377;&#37325;&#35201;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#22522;&#20110;&#35821;&#35328;&#30340;&#35828;&#26381;&#28216;&#25103;&#20013;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#30340;&#25361;&#25112;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#30495;&#23454;&#21644;&#27169;&#25311;&#20154;&#31867; - &#26426;&#22120;&#20154;&#20132;&#20114;&#25968;&#25454;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#35757;&#32451;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26377;&#25928;&#22320;&#25972;&#21512;&#20102;&#30495;&#23454;&#20132;&#20114;&#21644;&#27169;&#25311;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persuasion games have been fundamental in economics and AI research, and have significant practical applications. Recent works in this area have started to incorporate natural language, moving beyond the traditional stylized message setting. However, previous research has focused on on-policy prediction, where the train and test data have the same distribution, which is not representative of real-life scenarios. In this paper, we tackle the challenging problem of off-policy evaluation (OPE) in language-based persuasion games. To address the inherent difficulty of human data collection in this setup, we propose a novel approach which combines real and simulated human-bot interaction data. Our simulated data is created by an exogenous model assuming decision makers (DMs) start with a mixture of random and decision-theoretic based behaviors and improve over time. We present a deep learning training algorithm that effectively integrates real interaction and simulated data, substantially im
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#22522;&#20110;GNN&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#20248;&#21270;&#26381;&#21153;&#36136;&#37327;&#65292;&#35299;&#20915;ONTS&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.13773</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65306;&#23398;&#20064;&#28151;&#21512;&#25972;&#25968;&#27169;&#22411;&#30340;&#27934;&#35265;
&lt;/p&gt;
&lt;p&gt;
A Graph Neural Network Approach to Nanosatellite Task Scheduling: Insights into Learning Mixed-Integer Models. (arXiv:2303.13773v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13773
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#22522;&#20110;GNN&#30340;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#20248;&#21270;&#26381;&#21153;&#36136;&#37327;&#65292;&#35299;&#20915;ONTS&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#22914;&#20309;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26356;&#26377;&#25928;&#22320;&#35843;&#24230;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#12290;&#22312;&#31163;&#32447;&#32435;&#31859;&#21355;&#26143;&#20219;&#21153;&#35843;&#24230;&#65288;ONTS&#65289;&#38382;&#39064;&#20013;&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#22312;&#36712;&#36947;&#19978;&#25191;&#34892;&#20219;&#21153;&#30340;&#26368;&#20339;&#23433;&#25490;&#65292;&#21516;&#26102;&#32771;&#34385;&#26381;&#21153;&#36136;&#37327;&#65288;QoS&#65289;&#26041;&#38754;&#30340;&#32771;&#34385;&#22240;&#32032;&#65292;&#22914;&#20248;&#20808;&#32423;&#65292;&#26368;&#23567;&#21644;&#26368;&#22823;&#28608;&#27963;&#20107;&#20214;&#65292;&#25191;&#34892;&#26102;&#38388;&#26694;&#26550;&#65292;&#21608;&#26399;&#21644;&#25191;&#34892;&#31383;&#21475;&#65292;&#20197;&#21450;&#21355;&#26143;&#30005;&#21147;&#36164;&#28304;&#21644;&#33021;&#37327;&#25910;&#38598;&#21644;&#31649;&#29702;&#30340;&#22797;&#26434;&#24615;&#30340;&#32422;&#26463;&#12290;ONTS&#38382;&#39064;&#24050;&#32463;&#20351;&#29992;&#20256;&#32479;&#30340;&#25968;&#23398;&#20844;&#24335;&#21644;&#31934;&#30830;&#26041;&#27861;&#36827;&#34892;&#20102;&#22788;&#29702;&#65292;&#20294;&#26159;&#23427;&#20204;&#22312;&#38382;&#39064;&#30340;&#25361;&#25112;&#24615;&#26696;&#20363;&#20013;&#30340;&#36866;&#29992;&#24615;&#26377;&#38480;&#12290;&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;GNN&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#24050;&#32463;&#25104;&#21151;&#24212;&#29992;&#20110;&#35768;&#22810;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#26053;&#34892;&#21830;&#38382;&#39064;&#65292;&#35843;&#24230;&#38382;&#39064;&#21644;&#35774;&#26045;&#25918;&#32622;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;ONTS&#38382;&#39064;&#30340;MILP&#23454;&#20363;&#23436;&#20840;&#34920;&#31034;&#25104;&#20108;&#20998;&#22270;&#32593;&#32476;&#32467;&#26500;&#26469;&#24212;&#29992;GNN&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates how to schedule nanosatellite tasks more efficiently using Graph Neural Networks (GNN). In the Offline Nanosatellite Task Scheduling (ONTS) problem, the goal is to find the optimal schedule for tasks to be carried out in orbit while taking into account Quality-of-Service (QoS) considerations such as priority, minimum and maximum activation events, execution time-frames, periods, and execution windows, as well as constraints on the satellite's power resources and the complexity of energy harvesting and management. The ONTS problem has been approached using conventional mathematical formulations and precise methods, but their applicability to challenging cases of the problem is limited. This study examines the use of GNNs in this context, which has been effectively applied to many optimization problems, including traveling salesman problems, scheduling problems, and facility placement problems. Here, we fully represent MILP instances of the ONTS problem in biparti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#31934;&#20934;&#32959;&#30244;&#23398;&#20013;&#30340;&#26579;&#33394;&#20307;&#20998;&#26512;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;Fred Hutchinson&#30284;&#30151;&#30740;&#31350;&#20013;&#24515;&#30340;&#22823;&#37327;&#25968;&#25454;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#25299;&#25169;&#35270;&#35273;&#36716;&#25442;&#22120;(TopViTs)&#65292;&#25104;&#21151;&#24320;&#21457;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#35782;&#21035;&#26579;&#33394;&#20307;&#24322;&#24120;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.14312</link><description>&lt;p&gt;
&#31934;&#20934;&#32959;&#30244;&#23398;&#30340;&#26579;&#33394;&#20307;AI
&lt;/p&gt;
&lt;p&gt;
Karyotype AI for Precision Oncology. (arXiv:2211.14312v3 [q-bio.QM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#31934;&#20934;&#32959;&#30244;&#23398;&#20013;&#30340;&#26579;&#33394;&#20307;&#20998;&#26512;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;Fred Hutchinson&#30284;&#30151;&#30740;&#31350;&#20013;&#24515;&#30340;&#22823;&#37327;&#25968;&#25454;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#25299;&#25169;&#35270;&#35273;&#36716;&#25442;&#22120;(TopViTs)&#65292;&#25104;&#21151;&#24320;&#21457;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#35782;&#21035;&#26579;&#33394;&#20307;&#24322;&#24120;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26579;&#33394;&#20307;&#20998;&#26512;&#23545;&#20110;&#35786;&#26029;&#36951;&#20256;&#30142;&#30149;&#33267;&#20851;&#37325;&#35201;&#12290;&#23545;&#20110;&#34880;&#28082;&#31995;&#32479;&#24694;&#24615;&#32959;&#30244;&#65292;&#36890;&#36807;&#26579;&#33394;&#20307;&#32452;&#22411;&#20998;&#26512;&#26469;&#21457;&#29616;&#20307;&#32454;&#32990;&#31361;&#21464;&#26159;&#26631;&#20934;&#30340;&#25252;&#29702;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#26579;&#33394;&#20307;&#32452;&#22411;&#20998;&#26512;&#22240;&#20026;&#22823;&#37096;&#20998;&#26159;&#25163;&#21160;&#25805;&#20316;&#65292;&#19988;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#26469;&#35782;&#21035;&#21644;&#27880;&#37322;&#31361;&#21464;&#65292;&#25152;&#20197;&#26114;&#36149;&#19988;&#32791;&#26102;&#12290;&#20197;Fred Hutchinson&#30284;&#30151;&#30740;&#31350;&#20013;&#24515;&#36807;&#21435;&#20116;&#24180;&#30340;&#32422;10,000&#20010;&#24739;&#32773;&#26631;&#26412;&#21644;&#32422;50,000&#20010;&#26579;&#33394;&#20307;&#32452;&#22411;&#22270;&#29255;&#20316;&#20026;&#35757;&#32451;&#38598;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#32452;&#20195;&#34920;&#21333;&#20010;&#26579;&#33394;&#20307;&#30340;&#26631;&#35760;&#22270;&#29255;&#12290;&#36825;&#20123;&#21333;&#20010;&#26579;&#33394;&#20307;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#20197;&#20998;&#31867;&#20154;&#31867;&#30340;24&#26465;&#26579;&#33394;&#20307;&#21644;&#35782;&#21035;&#26579;&#33394;&#20307;&#24322;&#24120;&#12290;&#20855;&#26377;&#26368;&#39640;&#20934;&#30830;&#24615;&#30340;&#27169;&#22411;&#20351;&#29992;&#20102;&#26368;&#36817;&#24341;&#20837;&#30340;&#25299;&#25169;&#35270;&#35273;&#36716;&#25442;&#22120;(TopViTs)&#21644;&#20108;&#32423;&#22359;-&#25176;&#26222;&#21033;&#33576;&#33945;&#29256;&#65292;&#20197;&#34701;&#20837;&#32467;&#26500;&#24615;&#24402;&#32435;&#20559;&#32622;&#12290;TopViT&#30340;&#24615;&#33021;&#20248;&#20110;CNN(Inc)
&lt;/p&gt;
&lt;p&gt;
Chromosome analysis is essential for diagnosing genetic disorders. For hematologic malignancies, identification of somatic clonal aberrations by karyotype analysis remains the standard of care. However, karyotyping is costly and time-consuming because of the largely manual process and the expertise required in identifying and annotating aberrations. Efforts to automate karyotype analysis to date fell short in aberration detection. Using a training set of ~10k patient specimens and ~50k karyograms from over 5 years from the Fred Hutchinson Cancer Center, we created a labeled set of images representing individual chromosomes. These individual chromosomes were used to train and assess deep learning models for classifying the 24 human chromosomes and identifying chromosomal aberrations. The top-accuracy models utilized the recently introduced Topological Vision Transformers (TopViTs) with 2-level-block-Toeplitz masking, to incorporate structural inductive bias. TopViT outperformed CNN (Inc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26377;&#38480;&#26102;&#22495;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22266;&#23450;&#26102;&#38388;&#21518;&#32456;&#27490;&#65292;&#36890;&#36807;&#20989;&#25968;&#36924;&#36817;&#21644;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2210.04527</link><description>&lt;p&gt;
&#26377;&#38480;&#26102;&#22495;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A policy gradient approach for Finite Horizon Constrained Markov Decision Processes. (arXiv:2210.04527v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26377;&#38480;&#26102;&#22495;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22266;&#23450;&#26102;&#38388;&#21518;&#32456;&#27490;&#65292;&#36890;&#36807;&#20989;&#25968;&#36924;&#36817;&#21644;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#38480;&#26102;&#22495;&#35774;&#32622;&#36890;&#24120;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#23548;&#33268;&#20135;&#29983;&#26368;&#20248;&#30340;&#22266;&#23450;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#26377;&#38480;&#26102;&#22495;&#25511;&#21046;&#38382;&#39064;&#26356;&#20855;&#26377;&#23454;&#38469;&#24847;&#20041;&#65292;&#24182;&#19988;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#36890;&#24120;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#26368;&#36817;&#65292;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#30340;&#35774;&#32622;&#20063;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#65292;&#20854;&#20013;&#20195;&#29702;&#21516;&#26102;&#22312;&#26368;&#22823;&#21270;&#22870;&#21169;&#30340;&#21516;&#26102;&#28385;&#36275;&#26576;&#20123;&#32473;&#23450;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#35774;&#32622;&#20165;&#22312;&#26080;&#38480;&#26102;&#22495;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#32972;&#26223;&#19979;&#24471;&#21040;&#20102;&#30740;&#31350;&#65292;&#20854;&#20013;&#22266;&#23450;&#31574;&#30053;&#26159;&#26368;&#20248;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26377;&#38480;&#26102;&#22495;&#35774;&#32622;&#19979;&#36827;&#34892;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#22312;&#19968;&#20010;&#22266;&#23450;&#30340;&#26102;&#38388;&#21518;&#32456;&#27490;&#12290;&#25105;&#20204;&#22312;&#31639;&#27861;&#20013;&#20351;&#29992;&#20989;&#25968;&#36924;&#36817;&#65292;&#36825;&#22312;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#36739;&#22823;&#25110;&#36830;&#32493;&#30340;&#24773;&#20917;&#19979;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#65292;&#24182;&#20351;&#29992;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#26469;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#24471;&#21040;&#30340;&#26368;&#20248;&#31574;&#30053;&#21462;&#20915;&#20110;&#26102;&#38388;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
The infinite horizon setting is widely adopted for problems of reinforcement learning (RL). These invariably result in stationary policies that are optimal. In many situations, finite horizon control problems are of interest and for such problems, the optimal policies are time-varying in general. Another setting that has become popular in recent times is of Constrained Reinforcement Learning, where the agent maximizes its rewards while it also aims to satisfy some given constraint criteria. However, this setting has only been studied in the context of infinite horizon MDPs where stationary policies are optimal. We present an algorithm for constrained RL in the Finite Horizon Setting where the horizon terminates after a fixed (finite) time. We use function approximation in our algorithm which is essential when the state and action spaces are large or continuous and use the policy gradient method to find the optimal policy. The optimal policy that we obtain depends on the stage and so is
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23545;&#25237;&#24433;&#31995;&#25968;&#36827;&#34892;&#26816;&#27979;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2110.01729</link><description>&lt;p&gt;
&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#21450;&#20854;&#22312;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic coordinate transformations with applications to robust machine learning. (arXiv:2110.01729v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.01729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23545;&#25237;&#24433;&#31995;&#25968;&#36827;&#34892;&#26816;&#27979;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#32452;&#26032;&#30340;&#29305;&#24449;&#65292;&#21033;&#29992;Karhunen-Loeve&#23637;&#24320;&#27861;&#26469;&#35782;&#21035;&#36755;&#20837;&#25968;&#25454;&#30340;&#28508;&#22312;&#38543;&#26426;&#34892;&#20026;&#12290;&#36825;&#20123;&#26032;&#29305;&#24449;&#26159;&#36890;&#36807;&#22522;&#20110;&#26368;&#36817;&#30340;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#29702;&#35770;&#36827;&#34892;&#30340;&#22352;&#26631;&#21464;&#25442;&#26500;&#24314;&#30340;&#65292;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#30456;&#20851;&#30340;&#20449;&#21495;&#20998;&#35299;&#26159;&#29992;&#24050;&#30693;&#20248;&#21270;&#23646;&#24615;&#30340;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#20855;&#26377;&#26377;&#38480;&#21151;&#33021;&#31354;&#38388;&#30340;&#38543;&#26426;&#36807;&#31243;&#65288;&#38543;&#26426;&#22330;&#65289;&#12290;&#21407;&#21017;&#19978;&#65292;&#36825;&#20123;&#20302;&#32500;&#31354;&#38388;&#21487;&#20197;&#25429;&#25417;&#32473;&#23450;&#21517;&#20041;&#31867;&#21035;&#30340;'&#24213;&#23618;&#20449;&#21495;'&#30340;&#22823;&#37096;&#20998;&#38543;&#26426;&#21464;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#23558;&#26469;&#33258;&#20854;&#23427;&#31867;&#21035;&#30340;&#20449;&#21495;&#25298;&#32477;&#20026;&#38543;&#26426;&#24322;&#24120;&#12290;&#36890;&#36807;&#21517;&#20041;&#31867;&#21035;&#30340;&#23618;&#32423;&#26377;&#38480;&#32500;&#23637;&#24320;&#65292;&#26500;&#24314;&#20102;&#19968;&#31995;&#21015;&#29992;&#20110;&#26816;&#27979;&#24322;&#24120;&#20449;&#21495;&#32452;&#20214;&#30340;&#27491;&#20132;&#23884;&#22871;&#23376;&#31354;&#38388;&#12290;&#28982;&#21518;&#20351;&#29992;&#36825;&#20123;&#23376;&#31354;&#38388;&#20013;&#30340;&#25237;&#24433;&#31995;&#25968;&#26469;&#35757;&#32451;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#32467;&#26524;&#34920;&#26126;&#20854;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we introduce a set of novel features for identifying underlying stochastic behavior of input data using the Karhunen-Loeve expansion. These novel features are constructed by applying a coordinate transformation based on the recent Functional Data Analysis theory for anomaly detection. The associated signal decomposition is an exact hierarchical tensor product expansion with known optimality properties for approximating stochastic processes (random fields) with finite dimensional function spaces. In principle these low dimensional spaces can capture most of the stochastic behavior of `underlying signals' in a given nominal class, and can reject signals in alternative classes as stochastic anomalies. Using a hierarchical finite dimensional expansion of the nominal class, a series of orthogonal nested subspaces is constructed for detecting anomalous signal components. Projection coefficients of input data in these subspaces are then used to train a Machine Learning (ML) clas
&lt;/p&gt;</description></item></channel></rss>