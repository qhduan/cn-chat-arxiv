<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20026;&#20102;&#35299;&#20915;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#20013;"&#37325;&#21472;"&#20551;&#35774;&#30340;&#38382;&#39064;&#30340;&#28608;&#21169;&#24863;&#30693;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#28608;&#21169;&#21333;&#20301;&#37319;&#21462;&#36890;&#24120;&#19981;&#20250;&#32771;&#34385;&#30340;&#24178;&#39044;&#25514;&#26045;&#65292;&#25552;&#20379;&#19982;&#28608;&#21169;&#30456;&#23481;&#30340;&#24178;&#39044;&#24314;&#35758;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#38754;&#26495;&#25968;&#25454;&#29615;&#22659;&#20013;&#20934;&#30830;&#20272;&#35745;&#21453;&#20107;&#23454;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2312.16307</link><description>&lt;p&gt;
&#28608;&#21169;&#24863;&#30693;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#65306;&#36890;&#36807;&#28608;&#21169;&#25506;&#32034;&#36827;&#34892;&#20934;&#30830;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Incentive-Aware Synthetic Control: Accurate Counterfactual Estimation via Incentivized Exploration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16307
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20026;&#20102;&#35299;&#20915;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#20013;"&#37325;&#21472;"&#20551;&#35774;&#30340;&#38382;&#39064;&#30340;&#28608;&#21169;&#24863;&#30693;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#28608;&#21169;&#21333;&#20301;&#37319;&#21462;&#36890;&#24120;&#19981;&#20250;&#32771;&#34385;&#30340;&#24178;&#39044;&#25514;&#26045;&#65292;&#25552;&#20379;&#19982;&#28608;&#21169;&#30456;&#23481;&#30340;&#24178;&#39044;&#24314;&#35758;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#38754;&#26495;&#25968;&#25454;&#29615;&#22659;&#20013;&#20934;&#30830;&#20272;&#35745;&#21453;&#20107;&#23454;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#21512;&#25104;&#23545;&#29031;&#26041;&#27861;&#65288;SCMs&#65289;&#30340;&#35774;&#23450;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#38754;&#26495;&#25968;&#25454;&#29615;&#22659;&#20013;&#20272;&#35745;&#34987;&#27835;&#30103;&#23545;&#35937;&#30340;&#27835;&#30103;&#25928;&#24212;&#30340;&#32463;&#20856;&#26041;&#27861;&#12290;&#25105;&#20204;&#25581;&#31034;&#20102;SCMs&#20013;&#32463;&#24120;&#34987;&#24573;&#35270;&#20294;&#26222;&#36941;&#23384;&#22312;&#30340;&#8220;&#37325;&#21472;&#8221;&#20551;&#35774;&#65306;&#19968;&#20010;&#34987;&#27835;&#30103;&#30340;&#21333;&#20301;&#21487;&#20197;&#34987;&#20889;&#25104;&#20445;&#25345;&#25511;&#21046;&#30340;&#21333;&#20301;&#30340;&#26576;&#31181;&#32452;&#21512;&#65288;&#36890;&#24120;&#26159;&#20984;&#25110;&#32447;&#24615;&#32452;&#21512;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#26524;&#21333;&#20301;&#36873;&#25321;&#33258;&#24049;&#30340;&#24178;&#39044;&#25514;&#26045;&#65292;&#24182;&#19988;&#21333;&#20301;&#20043;&#38388;&#30340;&#24322;&#36136;&#24615;&#36275;&#22815;&#22823;&#65292;&#20197;&#33267;&#20110;&#20182;&#20204;&#20559;&#22909;&#19981;&#21516;&#30340;&#24178;&#39044;&#25514;&#26045;&#65292;&#37325;&#21472;&#23558;&#19981;&#25104;&#31435;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#28608;&#21169;&#20855;&#26377;&#19981;&#21516;&#20559;&#22909;&#30340;&#21333;&#20301;&#26469;&#37319;&#21462;&#20182;&#20204;&#36890;&#24120;&#19981;&#20250;&#32771;&#34385;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#20449;&#24687;&#35774;&#35745;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#24037;&#20855;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;SCM&#65292;&#36890;&#36807;&#20026;&#21333;&#20301;&#25552;&#20379;&#19982;&#28608;&#21169;&#30456;&#23481;&#30340;&#24178;&#39044;&#24314;&#35758;&#65292;&#22312;&#38754;&#26495;&#25968;&#25454;&#29615;&#22659;&#20013;&#28608;&#21169;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.16307v2 Announce Type: replace-cross Abstract: We consider the setting of synthetic control methods (SCMs), a canonical approach used to estimate the treatment effect on the treated in a panel data setting. We shed light on a frequently overlooked but ubiquitous assumption made in SCMs of "overlap": a treated unit can be written as some combination -- typically, convex or linear combination -- of the units that remain under control. We show that if units select their own interventions, and there is sufficiently large heterogeneity between units that prefer different interventions, overlap will not hold. We address this issue by proposing a framework which incentivizes units with different preferences to take interventions they would not normally consider. Specifically, leveraging tools from information design and online learning, we propose a SCM that incentivizes exploration in panel data settings by providing incentive-compatible intervention recommendations to units. We e
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38598;&#20013;&#35757;&#32451;&#21644;&#20998;&#25955;&#25191;&#34892;&#30340;&#22810;Agent&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#31649;&#29702;&#20132;&#36890;&#22522;&#30784;&#35774;&#26045;&#31995;&#32479;&#30340;&#25972;&#20010;&#29983;&#21629;&#21608;&#26399;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#24230;&#31354;&#38388;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#26102;&#33021;&#22815;&#38477;&#20302;&#38271;&#26399;&#39118;&#38505;&#21644;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2401.12455</link><description>&lt;p&gt;
&#22522;&#20110;&#38598;&#20013;&#35757;&#32451;&#21644;&#20998;&#25955;&#25191;&#34892;&#30340;&#22810;Agent&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#20132;&#36890;&#22522;&#30784;&#35774;&#26045;&#31649;&#29702;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multi-agent deep reinforcement learning with centralized training and decentralized execution for transportation infrastructure management. (arXiv:2401.12455v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12455
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38598;&#20013;&#35757;&#32451;&#21644;&#20998;&#25955;&#25191;&#34892;&#30340;&#22810;Agent&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#31649;&#29702;&#20132;&#36890;&#22522;&#30784;&#35774;&#26045;&#31995;&#32479;&#30340;&#25972;&#20010;&#29983;&#21629;&#21608;&#26399;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#24230;&#31354;&#38388;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#26102;&#33021;&#22815;&#38477;&#20302;&#38271;&#26399;&#39118;&#38505;&#21644;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;Agent&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#20132;&#36890;&#22522;&#30784;&#35774;&#26045;&#30340;&#25972;&#20010;&#29983;&#21629;&#21608;&#26399;&#20869;&#36827;&#34892;&#31649;&#29702;&#12290;&#36825;&#31181;&#24037;&#31243;&#31995;&#32479;&#30340;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#26159;&#19968;&#20010;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#30340;&#20219;&#21153;&#65292;&#38656;&#35201;&#36866;&#24403;&#30340;&#39034;&#24207;&#26816;&#26597;&#21644;&#32500;&#25252;&#20915;&#31574;&#65292;&#33021;&#22815;&#22312;&#22788;&#29702;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#26102;&#38477;&#20302;&#38271;&#26399;&#39118;&#38505;&#21644;&#25104;&#26412;&#65292;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#23384;&#22312;&#20110;&#39640;&#32500;&#31354;&#38388;&#20013;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#38745;&#24577;&#30340;&#22522;&#20110;&#24180;&#40836;&#25110;&#26465;&#20214;&#30340;&#32500;&#25252;&#26041;&#27861;&#21644;&#22522;&#20110;&#39118;&#38505;&#25110;&#23450;&#26399;&#26816;&#26597;&#35745;&#21010;&#20027;&#35201;&#35299;&#20915;&#20102;&#36825;&#31867;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20123;&#26041;&#27861;&#19979;&#65292;&#20248;&#21270;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#38480;&#21046;&#32463;&#24120;&#26174;&#29616;&#20986;&#26469;&#12290;&#26412;&#24037;&#20316;&#20013;&#30340;&#20248;&#21270;&#38382;&#39064;&#20197;&#32422;&#26463;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(POMDPs)&#26694;&#26550;&#20026;&#22522;&#30784;&#65292;&#20026;&#20855;&#26377;&#35266;&#23519;&#19981;&#30830;&#23450;&#24615;&#12289;&#39118;&#38505;&#32771;&#34385;&#21644;&#38543;&#26426;&#39034;&#24207;&#20915;&#31574;&#30340;&#38382;&#39064;&#25552;&#20379;&#20102;&#32508;&#21512;&#30340;&#25968;&#23398;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a multi-agent Deep Reinforcement Learning (DRL) framework for managing large transportation infrastructure systems over their life-cycle. Life-cycle management of such engineering systems is a computationally intensive task, requiring appropriate sequential inspection and maintenance decisions able to reduce long-term risks and costs, while dealing with different uncertainties and constraints that lie in high-dimensional spaces. To date, static age- or condition-based maintenance methods and risk-based or periodic inspection plans have mostly addressed this class of optimization problems. However, optimality, scalability, and uncertainty limitations are often manifested under such approaches. The optimization problem in this work is cast in the framework of constrained Partially Observable Markov Decision Processes (POMDPs), which provides a comprehensive mathematical basis for stochastic sequential decision settings with observation uncertainties, risk considerations, and l
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#25193;&#25955;&#36807;&#31243;&#24182;&#30452;&#25509;&#20272;&#35745;&#22270;&#20687;&#21644;&#22122;&#22768;&#65292;&#26412;&#25991;&#25913;&#36827;&#20102;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#22270;&#20687;&#29983;&#25104;&#30340;&#36895;&#24230;&#21644;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.17167</link><description>&lt;p&gt;
&#36890;&#36807;&#21516;&#26102;&#20272;&#35745;&#22270;&#20687;&#21644;&#22122;&#22768;&#25913;&#36827;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Improving Denoising Diffusion Models via Simultaneous Estimation of Image and Noise. (arXiv:2310.17167v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17167
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#25193;&#25955;&#36807;&#31243;&#24182;&#30452;&#25509;&#20272;&#35745;&#22270;&#20687;&#21644;&#22122;&#22768;&#65292;&#26412;&#25991;&#25913;&#36827;&#20102;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#22270;&#20687;&#29983;&#25104;&#30340;&#36895;&#24230;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#20010;&#20851;&#38190;&#30340;&#36129;&#29486;&#65292;&#26088;&#22312;&#36890;&#36807;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#29983;&#25104;&#30340;&#22270;&#20687;&#30340;&#36895;&#24230;&#21644;&#36136;&#37327;&#12290;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#36890;&#36807;&#20197;&#22270;&#20687;&#21644;&#22122;&#22768;&#20043;&#38388;&#30340;&#22235;&#20998;&#20043;&#19968;&#22278;&#24359;&#19978;&#30340;&#35282;&#24230;&#37325;&#26032;&#21442;&#25968;&#21270;&#25193;&#25955;&#36807;&#31243;&#65292;&#29305;&#21035;&#26159;&#35774;&#32622;&#20256;&#32479;&#30340; $\displaystyle \sqrt{\bar{\alpha}}=\cos(\eta)$&#12290;&#36825;&#31181;&#37325;&#26032;&#21442;&#25968;&#21270;&#28040;&#38500;&#20102;&#20004;&#20010;&#22855;&#24322;&#28857;&#65292;&#24182;&#20801;&#35768;&#23558;&#25193;&#25955;&#28436;&#21270;&#34920;&#36798;&#20026;&#19968;&#20010;&#33391;&#22909;&#34892;&#20026;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#12290;&#20174;&#32780;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20351;&#29992;&#26356;&#39640;&#38454;&#30340;ODE&#27714;&#35299;&#22120;&#65292;&#22914;Runge-Kutta&#26041;&#27861;&#12290;&#31532;&#20108;&#20010;&#36129;&#29486;&#26159;&#30452;&#25509;&#20351;&#29992;&#25105;&#20204;&#30340;&#32593;&#32476;&#20272;&#35745;&#22270;&#20687;&#65288;$\mathbf{x}_0$&#65289;&#21644;&#22122;&#22768;&#65288;$\mathbf{\epsilon}$&#65289;&#65292;&#36825;&#20351;&#24471;&#36870;&#21521;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#26356;&#26032;&#27493;&#39588;&#35745;&#31639;&#26356;&#21152;&#31283;&#23450;&#65292;&#22240;&#20026;&#22312;&#36807;&#31243;&#30340;&#19981;&#21516;&#38454;&#27573;&#20934;&#30830;&#20272;&#35745;&#22270;&#20687;&#21644;&#22122;&#22768;&#37117;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22312;&#36825;&#20123;&#21464;&#21270;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23454;&#29616;&#20102;...
&lt;/p&gt;
&lt;p&gt;
This paper introduces two key contributions aimed at improving the speed and quality of images generated through inverse diffusion processes. The first contribution involves reparameterizing the diffusion process in terms of the angle on a quarter-circular arc between the image and noise, specifically setting the conventional $\displaystyle \sqrt{\bar{\alpha}}=\cos(\eta)$. This reparameterization eliminates two singularities and allows for the expression of diffusion evolution as a well-behaved ordinary differential equation (ODE). In turn, this allows higher order ODE solvers such as Runge-Kutta methods to be used effectively. The second contribution is to directly estimate both the image ($\mathbf{x}_0$) and noise ($\mathbf{\epsilon}$) using our network, which enables more stable calculations of the update step in the inverse diffusion steps, as accurate estimation of both the image and noise are crucial at different stages of the process. Together with these changes, our model achie
&lt;/p&gt;</description></item><item><title>ChatGPT&#24102;&#26469;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;(LLMs)&#34429;&#28982;&#26377;&#24456;&#22810;&#20248;&#21183;&#65292;&#20294;&#26159;&#38543;&#26426;&#40550;&#40521;&#21644;&#24187;&#35273;&#31561;&#26032;&#30340;&#27861;&#24459;&#21644;&#20262;&#29702;&#39118;&#38505;&#20063;&#38543;&#20043;&#32780;&#26469;&#12290;&#27431;&#27954;AI&#30417;&#31649;&#33539;&#24335;&#38656;&#35201;&#36827;&#19968;&#27493;&#21457;&#23637;&#20197;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2304.14347</link><description>&lt;p&gt;
ChatGPT&#30340;&#40657;&#26263;&#38754;&#65306;&#26469;&#33258;&#38543;&#26426;&#40550;&#40521;&#21644;&#24187;&#35273;&#30340;&#27861;&#24459;&#21644;&#20262;&#29702;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
The Dark Side of ChatGPT: Legal and Ethical Challenges from Stochastic Parrots and Hallucination. (arXiv:2304.14347v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14347
&lt;/p&gt;
&lt;p&gt;
ChatGPT&#24102;&#26469;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;(LLMs)&#34429;&#28982;&#26377;&#24456;&#22810;&#20248;&#21183;&#65292;&#20294;&#26159;&#38543;&#26426;&#40550;&#40521;&#21644;&#24187;&#35273;&#31561;&#26032;&#30340;&#27861;&#24459;&#21644;&#20262;&#29702;&#39118;&#38505;&#20063;&#38543;&#20043;&#32780;&#26469;&#12290;&#27431;&#27954;AI&#30417;&#31649;&#33539;&#24335;&#38656;&#35201;&#36827;&#19968;&#27493;&#21457;&#23637;&#20197;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;ChatGPT&#30340;&#25512;&#20986;&#65292;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#27491;&#22312;&#21160;&#25671;&#25105;&#20204;&#25972;&#20010;&#31038;&#20250;&#65292;&#24555;&#36895;&#25913;&#21464;&#25105;&#20204;&#30340;&#24605;&#32500;&#12289;&#21019;&#36896;&#21644;&#29983;&#27963;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#38543;&#26426;&#40550;&#40521;&#21644;&#24187;&#35273;&#31561;&#26032;&#30340;&#27861;&#24459;&#21644;&#20262;&#29702;&#39118;&#38505;&#20986;&#29616;&#65292;&#26032;&#20852;LLMs&#20063;&#24102;&#26469;&#20102;&#35768;&#22810;&#25361;&#25112;&#12290;&#27431;&#30431;&#26159;&#31532;&#19968;&#20010;&#23558;&#37325;&#28857;&#25918;&#22312;AI&#27169;&#22411;&#30417;&#31649;&#19978;&#30340;&#21496;&#27861;&#31649;&#36758;&#21306;&#12290;&#28982;&#32780;&#65292;&#26032;LLMs&#24102;&#26469;&#30340;&#39118;&#38505;&#21487;&#33021;&#20250;&#34987;&#26032;&#20852;&#30340;&#27431;&#30431;&#30417;&#31649;&#33539;&#24335;&#25152;&#20302;&#20272;&#12290;&#22240;&#27492;&#65292;&#26412;&#20989;&#21578;&#35686;&#31034;&#27431;&#27954;AI&#30417;&#31649;&#33539;&#24335;&#24517;&#39035;&#36827;&#19968;&#27493;&#21457;&#23637;&#20197;&#20943;&#36731;&#36825;&#20123;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the launch of ChatGPT, Large Language Models (LLMs) are shaking up our whole society, rapidly altering the way we think, create and live. For instance, the GPT integration in Bing has altered our approach to online searching. While nascent LLMs have many advantages, new legal and ethical risks are also emerging, stemming in particular from stochastic parrots and hallucination. The EU is the first and foremost jurisdiction that has focused on the regulation of AI models. However, the risks posed by the new LLMs are likely to be underestimated by the emerging EU regulatory paradigm. Therefore, this correspondence warns that the European AI regulatory paradigm must evolve further to mitigate such risks.
&lt;/p&gt;</description></item></channel></rss>