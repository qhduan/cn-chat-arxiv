<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>ChatDBG&#26159;&#31532;&#19968;&#20010;AI-Powered&#35843;&#35797;&#21161;&#25163;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21040;&#20256;&#32479;&#35843;&#35797;&#22120;&#20013;&#65292;&#23454;&#29616;&#20102;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#23545;&#35805;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#12289;&#25191;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;</title><link>https://arxiv.org/abs/2403.16354</link><description>&lt;p&gt;
ChatDBG: &#19968;&#31181;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35843;&#35797;&#21161;&#25163;
&lt;/p&gt;
&lt;p&gt;
ChatDBG: An AI-Powered Debugging Assistant
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16354
&lt;/p&gt;
&lt;p&gt;
ChatDBG&#26159;&#31532;&#19968;&#20010;AI-Powered&#35843;&#35797;&#21161;&#25163;&#65292;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#21040;&#20256;&#32479;&#35843;&#35797;&#22120;&#20013;&#65292;&#23454;&#29616;&#20102;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#23545;&#35805;&#65292;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#12289;&#25191;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;ChatDBG&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35843;&#35797;&#21161;&#25163;&#12290;ChatDBG&#38598;&#25104;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#65292;&#26174;&#33879;&#22686;&#24378;&#20102;&#20256;&#32479;&#35843;&#35797;&#22120;&#30340;&#21151;&#33021;&#21644;&#29992;&#25143;&#21451;&#22909;&#24615;&#12290;ChatDBG&#20801;&#35768;&#31243;&#24207;&#21592;&#19982;&#35843;&#35797;&#22120;&#36827;&#34892;&#21327;&#20316;&#23545;&#35805;&#65292;&#20351;&#20182;&#20204;&#33021;&#22815;&#25552;&#20986;&#20851;&#20110;&#31243;&#24207;&#29366;&#24577;&#30340;&#22797;&#26434;&#38382;&#39064;&#65292;&#23545;&#23849;&#28291;&#25110;&#26029;&#35328;&#22833;&#36133;&#36827;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#65292;&#24182;&#25506;&#32034;&#35832;&#22914;&#8220;&#20026;&#20160;&#20040;x&#20026;&#31354;&#65311;&#8221;&#20043;&#31867;&#30340;&#24320;&#25918;&#24615;&#26597;&#35810;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#26597;&#35810;&#65292;ChatDBG&#25480;&#20104;LLM&#33258;&#20027;&#26435;&#65292;&#36890;&#36807;&#21457;&#20986;&#21629;&#20196;&#26469;&#27983;&#35272;&#22534;&#26632;&#21644;&#26816;&#26597;&#31243;&#24207;&#29366;&#24577;&#36827;&#34892;&#35843;&#35797;&#65307;&#28982;&#21518;&#25253;&#21578;&#20854;&#21457;&#29616;&#24182;&#23558;&#25511;&#21046;&#26435;&#20132;&#36824;&#32473;&#31243;&#24207;&#21592;&#12290;&#25105;&#20204;&#30340;ChatDBG&#21407;&#22411;&#19982;&#26631;&#20934;&#35843;&#35797;&#22120;&#38598;&#25104;&#65292;&#21253;&#25324;LLDB&#12289;GDB&#21644;WinDBG&#29992;&#20110;&#26412;&#22320;&#20195;&#30721;&#20197;&#21450;&#29992;&#20110;Python&#30340;Pdb&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#20195;&#30721;&#38598;&#21512;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#20855;&#26377;&#24050;&#30693;&#38169;&#35823;&#30340;C/C++&#20195;&#30721;&#21644;&#19968;&#22871;Python&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#20581;&#24247;&#20445;&#20581;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;</title><link>https://arxiv.org/abs/2403.05720</link><description>&lt;p&gt;
&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05720
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#20581;&#24247;&#20445;&#20581;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#65288;BHC&#65289;&#25688;&#35201;&#26159;&#36890;&#36807;&#24635;&#32467;&#20020;&#24202;&#35760;&#24405;&#32780;&#29983;&#25104;&#30340;&#24120;&#35265;&#20020;&#24202;&#25991;&#20214;&#12290;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#21160;&#21270;&#23454;&#38469;&#20219;&#21153;&#26041;&#38754;&#23637;&#29616;&#20986;&#26174;&#33879;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;&#21307;&#30103;&#24212;&#29992;&#65288;&#22914;BHC&#21512;&#25104;&#65289;&#20013;&#30340;&#33021;&#21147;&#23578;&#26410;&#24471;&#21040;&#23637;&#31034;&#12290;&#20026;&#20102;&#20351;LLMs&#33021;&#22815;&#36866;&#24212;BHC&#21512;&#25104;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#21547;&#20174;MIMIC-IV&#35760;&#24405;&#20013;&#25552;&#21462;&#30340;&#32463;&#36807;&#39044;&#22788;&#29702;&#30340;&#25968;&#25454;&#38598;&#65292;&#23553;&#35013;&#20102;&#20020;&#24202;&#35760;&#24405;&#21644;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#65288;BHC&#65289;&#23545;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20004;&#20010;&#36890;&#29992;LLMs&#21644;&#19977;&#20010;&#21307;&#30103;&#39046;&#22495;&#36866;&#24212;&#30340;LLMs&#30340;&#24615;&#33021;&#65292;&#20197;&#25913;&#36827;&#20174;&#20020;&#24202;&#35760;&#24405;&#29983;&#25104;BHC&#12290;&#25105;&#20204;&#20351;&#29992;&#20020;&#24202;&#35760;&#24405;&#20316;&#20026;&#36755;&#20837;&#26469;&#29983;&#25104;BHC&#65292;&#37319;&#29992;&#22522;&#20110;&#25552;&#31034;&#30340;&#65288;&#20351;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#65289;&#21644;&#22522;&#20110;&#24494;&#35843;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#26469;&#24212;&#29992;&#20110;&#19977;&#20010;&#24320;&#28304;LLMs&#65288;Clinical-T5-Large&#65292;Llama2-13B&#65292;FLAN-UL2&#65289;&#21644;&#20004;&#20010;&#19987;&#26377;LLMs&#65288;GPT-3.5&#65292;GPT-4&#65289;&#12290;&#25105;&#20204;&#23450;&#37327;&#35780;&#20272;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05720v1 Announce Type: cross  Abstract: Brief hospital course (BHC) summaries are common clinical documents generated by summarizing clinical notes. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as BHC synthesis have not been shown. To enable the adaptation of LLMs for BHC synthesis, we introduce a novel benchmark consisting of a pre-processed dataset extracted from MIMIC-IV notes, encapsulating clinical note, and brief hospital course (BHC) pairs. We assess the performance of two general-purpose LLMs and three healthcare-adapted LLMs to improve BHC synthesis from clinical notes. Using clinical notes as input for generating BHCs, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to three open-source LLMs (Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5, GPT-4). We quantitatively evaluate the performa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#22686;&#24378;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26368;&#23567;&#21270;&#20256;&#36755;&#21644;&#38472;&#26087;&#25104;&#26412;&#30340;&#24635;&#21644;&#65292;&#22312;&#20445;&#35777;&#26368;&#22351;&#24773;&#20917;&#19979;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#20860;&#39038;&#20856;&#22411;&#24773;&#20917;&#19979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.02573</link><description>&lt;p&gt;
&#23398;&#20064;&#22686;&#24378;&#30340;&#22312;&#32447;&#26368;&#23567;&#21270;&#20449;&#24687;&#26102;&#20195;&#21644;&#20256;&#36755;&#25104;&#26412;
&lt;/p&gt;
&lt;p&gt;
Learning-augmented Online Minimization of Age of Information and Transmission Costs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02573
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#22686;&#24378;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26368;&#23567;&#21270;&#20256;&#36755;&#21644;&#38472;&#26087;&#25104;&#26412;&#30340;&#24635;&#21644;&#65292;&#22312;&#20445;&#35777;&#26368;&#22351;&#24773;&#20917;&#19979;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#20860;&#39038;&#20856;&#22411;&#24773;&#20917;&#19979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#31163;&#25955;&#26102;&#38388;&#31995;&#32479;&#65292;&#19968;&#20010;&#36164;&#28304;&#21463;&#38480;&#30340;&#26469;&#28304;&#65288;&#20363;&#22914;&#65292;&#19968;&#20010;&#23567;&#22411;&#20256;&#24863;&#22120;&#65289;&#36890;&#36807;&#19968;&#20010;&#26102;&#21464;&#26080;&#32447;&#20449;&#36947;&#23558;&#20854;&#21450;&#26102;&#25968;&#25454;&#20256;&#36755;&#32473;&#30446;&#30340;&#22320;&#12290;&#27599;&#27425;&#20256;&#36755;&#20250;&#20135;&#29983;&#22266;&#23450;&#30340;&#20256;&#36755;&#25104;&#26412;&#65288;&#20363;&#22914;&#65292;&#33021;&#37327;&#25104;&#26412;&#65289;&#65292;&#32780;&#27809;&#26377;&#20256;&#36755;&#20250;&#23548;&#33268;&#19968;&#20010;&#20197;&#20449;&#24687;&#26102;&#20195;&#34920;&#31034;&#30340;&#38472;&#26087;&#25104;&#26412;&#12290;&#26469;&#28304;&#24517;&#39035;&#22312;&#20256;&#36755;&#25104;&#26412;&#21644;&#38472;&#26087;&#25104;&#26412;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;&#20256;&#36755;&#21644;&#38472;&#26087;&#25104;&#26412;&#30340;&#24635;&#21644;&#65292;&#30830;&#20445;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;&#23613;&#31649;&#22312;&#32447;&#31639;&#27861;&#26159;&#31283;&#20581;&#30340;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#36807;&#20110;&#20445;&#23432;&#65292;&#22312;&#20856;&#22411;&#24773;&#20917;&#19979;&#21487;&#33021;&#34920;&#29616;&#19981;&#20339;&#12290;&#30456;&#21453;&#65292;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#21644;&#39044;&#27979;&#27169;&#22411;&#65292;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#22312;&#24179;&#22343;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#36890;&#24120;&#32570;&#20047;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;&#20026;&#20102;&#23454;&#29616;&#26368;&#22909;&#30340;&#20004;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#22686;&#24378;&#30340;&#22312;&#32447;&#26368;&#23567;&#21270;&#20449;&#24687;&#26102;&#20195;&#21644;&#20256;&#36755;&#25104;&#26412;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02573v1 Announce Type: new  Abstract: We consider a discrete-time system where a resource-constrained source (e.g., a small sensor) transmits its time-sensitive data to a destination over a time-varying wireless channel. Each transmission incurs a fixed transmission cost (e.g., energy cost), and no transmission results in a staleness cost represented by the Age-of-Information. The source must balance the tradeoff between transmission and staleness costs. To address this challenge, we develop a robust online algorithm to minimize the sum of transmission and staleness costs, ensuring a worst-case performance guarantee. While online algorithms are robust, they are usually overly conservative and may have a poor average performance in typical scenarios. In contrast, by leveraging historical data and prediction models, machine learning (ML) algorithms perform well in average cases. However, they typically lack worst-case performance guarantees. To achieve the best of both worlds,
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;Synergy&#65292;&#19968;&#20010;&#36890;&#36807;&#21160;&#24577;&#32452;&#21512;&#24494;&#22411;AI&#21152;&#36895;&#22120;&#26469;&#36827;&#34892;&#21327;&#20316;&#25512;&#26029;&#30340;&#31995;&#32479;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#22312;&#35774;&#22791;&#19978;AI&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#26102;tinyML&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;Synergy&#36890;&#36807;&#25552;&#20379;&#34394;&#25311;&#35745;&#31639;&#31354;&#38388;&#21644;&#36816;&#34892;&#26102;&#32534;&#25490;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#36164;&#28304;&#30340;&#32479;&#19968;&#34394;&#25311;&#21270;&#35270;&#22270;&#21644;&#36328;&#21160;&#24577;/&#24322;&#26500;&#21152;&#36895;&#22120;&#30340;&#26368;&#20339;&#25512;&#26029;&#65292;&#20854;&#21534;&#21520;&#37327;&#24179;&#22343;&#25552;&#21319;&#20102;8.0&#20493;&#12290;</title><link>http://arxiv.org/abs/2401.08637</link><description>&lt;p&gt;
&#36890;&#36807;MCU&#19978;&#24494;&#22411;AI&#21152;&#36895;&#22120;&#30340;&#21160;&#24577;&#32452;&#21512;&#23454;&#29616;&#21327;&#20316;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Collaborative Inference via Dynamic Composition of Tiny AI Accelerators on MCUs. (arXiv:2401.08637v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08637
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;Synergy&#65292;&#19968;&#20010;&#36890;&#36807;&#21160;&#24577;&#32452;&#21512;&#24494;&#22411;AI&#21152;&#36895;&#22120;&#26469;&#36827;&#34892;&#21327;&#20316;&#25512;&#26029;&#30340;&#31995;&#32479;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#22312;&#35774;&#22791;&#19978;AI&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#26102;tinyML&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;Synergy&#36890;&#36807;&#25552;&#20379;&#34394;&#25311;&#35745;&#31639;&#31354;&#38388;&#21644;&#36816;&#34892;&#26102;&#32534;&#25490;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#36164;&#28304;&#30340;&#32479;&#19968;&#34394;&#25311;&#21270;&#35270;&#22270;&#21644;&#36328;&#21160;&#24577;/&#24322;&#26500;&#21152;&#36895;&#22120;&#30340;&#26368;&#20339;&#25512;&#26029;&#65292;&#20854;&#21534;&#21520;&#37327;&#24179;&#22343;&#25552;&#21319;&#20102;8.0&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#22411;AI&#21152;&#36895;&#22120;&#30340;&#20986;&#29616;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26497;&#38480;&#36793;&#32536;&#19978;&#30340;&#37096;&#32626;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#25552;&#20379;&#20102;&#36739;&#20302;&#30340;&#24310;&#36831;&#12289;&#36739;&#20302;&#30340;&#21151;&#32791;&#25104;&#26412;&#21644;&#25913;&#36827;&#30340;&#38544;&#31169;&#20445;&#25252;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#36825;&#20123;&#21152;&#36895;&#22120;&#30340;&#22266;&#26377;&#38480;&#21046;&#65292;&#22914;&#26377;&#38480;&#30340;&#20869;&#23384;&#21644;&#21333;&#35774;&#22791;&#28966;&#28857;&#65292;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Synergy&#65292;&#19968;&#20010;&#33021;&#22815;&#20026;&#22810;&#31199;&#25143;&#27169;&#22411;&#21160;&#24577;&#32452;&#21512;&#24494;&#22411;AI&#21152;&#36895;&#22120;&#30340;&#31995;&#32479;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#23545;&#20110;&#35774;&#22791;&#19978;AI&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#26102;tinyML&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;Synergy&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#26159;&#20854;&#25552;&#20379;&#20102;&#34394;&#25311;&#35745;&#31639;&#31354;&#38388;&#65292;&#20026;&#36164;&#28304;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#34394;&#25311;&#21270;&#35270;&#22270;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#29289;&#29702;&#35774;&#22791;&#30340;&#39640;&#25928;&#20219;&#21153;&#26144;&#23556;&#12290;Synergy&#30340;&#36816;&#34892;&#26102;&#32534;&#25490;&#27169;&#22359;&#30830;&#20445;&#20102;&#36328;&#21160;&#24577;&#21644;&#24322;&#26500;&#21152;&#36895;&#22120;&#30340;&#26368;&#20339;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;&#19982;&#22522;&#20934;&#30456;&#27604;&#65292;Synergy&#30340;&#21534;&#21520;&#37327;&#24179;&#22343;&#25552;&#21319;&#20102;8.0&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of tiny AI accelerators opens opportunities for deep neural network deployment at the extreme edge, offering reduced latency, lower power cost, and improved privacy in on-device ML inference. Despite these advancements, challenges persist due to inherent limitations of these accelerators, such as restricted onboard memory and single-device focus. This paper introduces Synergy, a system that dynamically composes tiny AI accelerators for multi-tenant models, effectively addressing tinyML's critical challenges for the increasing demand for on-device AI. A key feature of Synergy is its virtual computing space, providing a unified, virtualized view of resources and enabling efficient task mapping to physical devices. Synergy's runtime orchestration module ensures optimal inference across dynamic and heterogeneous accelerators. Our evaluations with 7 baselines and 8 models demonstrate that Synergy improves throughput by an average of 8.0X compared to baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;</title><link>http://arxiv.org/abs/2310.16705</link><description>&lt;p&gt;
&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#27969;&#22312;&#21464;&#20998;&#25512;&#26029;&#30340;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gradient Flow over Variational Parameter Space for Variational Inference. (arXiv:2310.16705v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#21464;&#20998;&#21442;&#25968;&#34987;&#35843;&#25972;&#20197;&#20351;&#21464;&#20998;&#20998;&#24067;&#19982;&#30495;&#23454;&#21518;&#39564;&#23613;&#21487;&#33021;&#25509;&#36817;&#12290;&#21487;&#20197;&#36890;&#36807;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#26222;&#36890;&#26799;&#24230;&#19979;&#38477;&#25110;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#26469;&#35299;&#20915;&#20248;&#21270;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#19968;&#20010;&#8220;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#8221;&#20013;&#23450;&#20041;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#20248;&#21270;&#25216;&#26415;&#65292;&#21363;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#21644;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#65292;&#21487;&#20197;&#37325;&#26032;&#35299;&#37322;&#20026;&#25152;&#25552;&#20986;&#30340;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#30340;&#29305;&#23450;&#23454;&#20363;&#12290;&#20026;&#20102;&#25552;&#39640;&#20248;&#21270;&#25928;&#29575;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#23454;&#29992;&#30340;&#26041;&#27861;&#26469;&#25968;&#20540;&#27714;&#35299;&#31163;&#25955;&#26799;&#24230;&#27969;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference (VI) can be cast as an optimization problem in which the variational parameters are tuned to closely align a variational distribution with the true posterior. The optimization task can be approached through vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient VI. In this work, we reframe VI as the optimization of an objective that concerns probability distributions defined over a \textit{variational parameter space}. Subsequently, we propose Wasserstein gradient descent for tackling this optimization problem. Notably, the optimization techniques, namely black-box VI and natural-gradient VI, can be reinterpreted as specific instances of the proposed Wasserstein gradient descent. To enhance the efficiency of optimization, we develop practical methods for numerically solving the discrete gradient flows. We validate the effectiveness of the proposed methods through empirical experiments on a synthetic dataset, supplemented by theore
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#22312;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2307.14530</link><description>&lt;p&gt;
&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimation in Mixed-Membership Stochastic Block Models. (arXiv:2307.14530v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#22312;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#29616;&#20195;&#32593;&#32476;&#31185;&#23398;&#20013;&#26368;&#20851;&#38190;&#30340;&#38382;&#39064;&#20043;&#19968;&#12290;&#20854;&#24212;&#29992;&#21487;&#20197;&#22312;&#21508;&#20010;&#39046;&#22495;&#25214;&#21040;&#65292;&#20174;&#34507;&#30333;&#36136;&#24314;&#27169;&#21040;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#12290;&#26368;&#36817;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#35770;&#25991;&#30740;&#31350;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#21363;&#32593;&#32476;&#20013;&#30340;&#27599;&#20010;&#33410;&#28857;&#21487;&#33021;&#23646;&#20110;&#22810;&#20010;&#31038;&#21306;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#30001;Airoldi&#31561;&#20154;&#65288;2008&#65289;&#39318;&#27425;&#25552;&#20986;&#30340;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;MMSB&#65289;&#12290;MMSB&#22312;&#22270;&#20013;&#23545;&#37325;&#21472;&#31038;&#21306;&#32467;&#26500;&#25552;&#20379;&#20102;&#30456;&#24403;&#19968;&#33324;&#30340;&#35774;&#32622;&#12290;&#26412;&#25991;&#30340;&#26680;&#24515;&#38382;&#39064;&#26159;&#22312;&#35266;&#23519;&#21040;&#30340;&#32593;&#32476;&#20013;&#37325;&#24314;&#31038;&#21306;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#36825;&#20010;&#19979;&#30028;&#21305;&#37197;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#32467;&#26524;&#22312;&#23545;&#25152;&#32771;&#34385;&#30340;&#27169;&#22411;&#30340;&#30456;&#24403;&#26222;&#36941;&#26465;&#20214;&#19979;&#24471;&#21040;&#35777;&#26126;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#26469;&#35828;&#26126;&#36825;&#20010;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community detection is one of the most critical problems in modern network science. Its applications can be found in various fields, from protein modeling to social network analysis. Recently, many papers appeared studying the problem of overlapping community detection, where each node of a network may belong to several communities. In this work, we consider Mixed-Membership Stochastic Block Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite a general setting for modeling overlapping community structure in graphs. The central question of this paper is to reconstruct relations between communities given an observed network. We compare different approaches and establish the minimax lower bound on the estimation error. Then, we propose a new estimator that matches this lower bound. Theoretical results are proved under fairly general conditions on the considered model. Finally, we illustrate the theory in a series of experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#19981;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#21462;&#20998;&#23376;&#30456;&#20114;&#20316;&#29992;&#21644;&#36890;&#36335;&#30693;&#35782;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.08813</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#21462;&#20998;&#23376;&#30456;&#20114;&#20316;&#29992;&#21644;&#36890;&#36335;&#30693;&#35782;&#26041;&#38754;&#30340;&#27604;&#36739;&#24615;&#33021;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Comparative Performance Evaluation of Large Language Models for Extracting Molecular Interactions and Pathway Knowledge. (arXiv:2307.08813v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#19981;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#21462;&#20998;&#23376;&#30456;&#20114;&#20316;&#29992;&#21644;&#36890;&#36335;&#30693;&#35782;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#34507;&#30333;&#36136;&#30456;&#20114;&#20316;&#29992;&#21644;&#36890;&#36335;&#30693;&#35782;&#23545;&#20110;&#25581;&#31034;&#29983;&#29289;&#31995;&#32479;&#30340;&#22797;&#26434;&#24615;&#21644;&#30740;&#31350;&#29983;&#29289;&#21151;&#33021;&#21644;&#22797;&#26434;&#30142;&#30149;&#30340;&#22522;&#26412;&#26426;&#21046;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#29616;&#26377;&#30340;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#26469;&#33258;&#25991;&#29486;&#21644;&#20854;&#20182;&#28304;&#30340;&#31574;&#21010;&#29983;&#29289;&#25968;&#25454;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#19981;&#23436;&#25972;&#19988;&#32500;&#25252;&#24037;&#20316;&#32321;&#37325;&#65292;&#22240;&#27492;&#38656;&#35201;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#33258;&#21160;&#20174;&#30456;&#20851;&#31185;&#23398;&#25991;&#29486;&#20013;&#25552;&#21462;&#36825;&#20123;&#30693;&#35782;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#19981;&#21516;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35782;&#21035;&#34507;&#30333;&#36136;&#30456;&#20114;&#20316;&#29992;&#12289;&#36890;&#36335;&#21644;&#22522;&#22240;&#35843;&#25511;&#20851;&#31995;&#31561;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#27169;&#22411;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#24443;&#24213;&#35780;&#20272;&#65292;&#31361;&#20986;&#20102;&#37325;&#35201;&#30340;&#21457;&#29616;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#31181;&#26041;&#27861;&#25152;&#38754;&#20020;&#30340;&#26410;&#26469;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#38142;&#25509;&#21487;&#22312;&#35770;&#25991;&#20013;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding protein interactions and pathway knowledge is crucial for unraveling the complexities of living systems and investigating the underlying mechanisms of biological functions and complex diseases. While existing databases provide curated biological data from literature and other sources, they are often incomplete and their maintenance is labor-intensive, necessitating alternative approaches. In this study, we propose to harness the capabilities of large language models to address these issues by automatically extracting such knowledge from the relevant scientific literature. Toward this goal, in this work, we investigate the effectiveness of different large language models in tasks that involve recognizing protein interactions, pathways, and gene regulatory relations. We thoroughly evaluate the performance of various models, highlight the significant findings, and discuss both the future opportunities and the remaining challenges associated with this approach. The code and d
&lt;/p&gt;</description></item></channel></rss>