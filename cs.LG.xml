<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#24863;&#30693;-&#34892;&#21160;-&#36890;&#20449;(LPAC)&#26550;&#26500;&#65292;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#29615;&#22659;&#24863;&#30693;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#26426;&#22120;&#20154;&#20043;&#38388;&#30340;&#20449;&#24687;&#20132;&#27969;&#65292;&#27973;&#23618;&#22810;&#23618;&#24863;&#30693;&#26426;&#35745;&#31639;&#26426;&#22120;&#20154;&#30340;&#21160;&#20316;&#12290;&#20351;&#29992;&#38598;&#20013;&#24335;&#26174;&#24494;&#31639;&#27861;&#35757;&#32451;&#27169;&#22411;&#65292;&#23454;&#29616;&#26426;&#22120;&#20154;&#32676;&#20307;&#30340;&#21327;&#20316;&#12290;</title><link>http://arxiv.org/abs/2401.04855</link><description>&lt;p&gt;
LPAC: &#21487;&#23398;&#20064;&#30340;&#24863;&#30693;-&#34892;&#21160;-&#36890;&#20449;&#24490;&#29615;&#21450;&#20854;&#22312;&#35206;&#30422;&#25511;&#21046;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
LPAC: Learnable Perception-Action-Communication Loops with Applications to Coverage Control. (arXiv:2401.04855v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04855
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#24863;&#30693;-&#34892;&#21160;-&#36890;&#20449;(LPAC)&#26550;&#26500;&#65292;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#29615;&#22659;&#24863;&#30693;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#26426;&#22120;&#20154;&#20043;&#38388;&#30340;&#20449;&#24687;&#20132;&#27969;&#65292;&#27973;&#23618;&#22810;&#23618;&#24863;&#30693;&#26426;&#35745;&#31639;&#26426;&#22120;&#20154;&#30340;&#21160;&#20316;&#12290;&#20351;&#29992;&#38598;&#20013;&#24335;&#26174;&#24494;&#31639;&#27861;&#35757;&#32451;&#27169;&#22411;&#65292;&#23454;&#29616;&#26426;&#22120;&#20154;&#32676;&#20307;&#30340;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35206;&#30422;&#25511;&#21046;&#26159;&#25351;&#23548;&#26426;&#22120;&#20154;&#32676;&#20307;&#21327;&#21516;&#30417;&#27979;&#26410;&#30693;&#30340;&#24863;&#20852;&#36259;&#29305;&#24449;&#25110;&#29616;&#35937;&#30340;&#38382;&#39064;&#12290;&#22312;&#26377;&#38480;&#30340;&#36890;&#20449;&#21644;&#24863;&#30693;&#33021;&#21147;&#30340;&#20998;&#25955;&#35774;&#32622;&#20013;&#65292;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#24863;&#30693;-&#34892;&#21160;-&#36890;&#20449;(LPAC)&#26550;&#26500;&#26469;&#35299;&#20915;&#35206;&#30422;&#25511;&#21046;&#38382;&#39064;&#12290;&#22312;&#35813;&#35299;&#20915;&#26041;&#26696;&#20013;&#65292;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#22788;&#29702;&#20102;&#29615;&#22659;&#30340;&#23616;&#37096;&#24863;&#30693;&#65307;&#22270;&#31070;&#32463;&#32593;&#32476;(GNN)&#23454;&#29616;&#20102;&#37051;&#36817;&#26426;&#22120;&#20154;&#20043;&#38388;&#30340;&#30456;&#20851;&#20449;&#24687;&#36890;&#20449;&#65307;&#26368;&#21518;&#65292;&#27973;&#23618;&#22810;&#23618;&#24863;&#30693;&#26426;(MLP)&#35745;&#31639;&#26426;&#22120;&#20154;&#30340;&#21160;&#20316;&#12290;&#36890;&#20449;&#27169;&#22359;&#20013;&#30340;GNN&#36890;&#36807;&#35745;&#31639;&#24212;&#35813;&#19982;&#37051;&#23621;&#36890;&#20449;&#21738;&#20123;&#20449;&#24687;&#20197;&#21450;&#22914;&#20309;&#21033;&#29992;&#25509;&#25910;&#21040;&#30340;&#20449;&#24687;&#37319;&#21462;&#36866;&#24403;&#30340;&#34892;&#21160;&#26469;&#23454;&#29616;&#26426;&#22120;&#20154;&#32676;&#20307;&#30340;&#21327;&#20316;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#30693;&#26195;&#25972;&#20010;&#29615;&#22659;&#30340;&#38598;&#20013;&#24335;&#26174;&#24494;&#31639;&#27861;&#26469;&#36827;&#34892;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Coverage control is the problem of navigating a robot swarm to collaboratively monitor features or a phenomenon of interest not known a priori. The problem is challenging in decentralized settings with robots that have limited communication and sensing capabilities. This paper proposes a learnable Perception-Action-Communication (LPAC) architecture for the coverage control problem. In the proposed solution, a convolution neural network (CNN) processes localized perception of the environment; a graph neural network (GNN) enables communication of relevant information between neighboring robots; finally, a shallow multi-layer perceptron (MLP) computes robot actions. The GNN in the communication module enables collaboration in the robot swarm by computing what information to communicate with neighbors and how to use received information to take appropriate actions. We train models using imitation learning with a centralized clairvoyant algorithm that is aware of the entire environment. Eva
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#39038;&#20102;&#36817;&#26399;&#22312;&#25913;&#36827;&#23494;&#24230;&#27867;&#20989;&#21450;&#30456;&#20851;&#36817;&#20284;&#26041;&#27861;&#20013;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#36827;&#23637;&#65292;&#35752;&#35770;&#20102;&#22312;&#19981;&#21516;&#21270;&#23398;&#21644;&#26448;&#26009;&#31867;&#21035;&#20043;&#38388;&#35774;&#35745;&#21487;&#36801;&#31227;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26102;&#21487;&#33021;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#24076;&#26395;&#12290;</title><link>http://arxiv.org/abs/2311.00196</link><description>&lt;p&gt;
&#29992;&#20110;&#25552;&#39640;&#23494;&#24230;&#27867;&#20989;&#36817;&#20284;&#31934;&#30830;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Machine learning for accuracy in density functional approximations. (arXiv:2311.00196v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00196
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#36817;&#26399;&#22312;&#25913;&#36827;&#23494;&#24230;&#27867;&#20989;&#21450;&#30456;&#20851;&#36817;&#20284;&#26041;&#27861;&#20013;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#36827;&#23637;&#65292;&#35752;&#35770;&#20102;&#22312;&#19981;&#21516;&#21270;&#23398;&#21644;&#26448;&#26009;&#31867;&#21035;&#20043;&#38388;&#35774;&#35745;&#21487;&#36801;&#31227;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26102;&#21487;&#33021;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#24076;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#24050;&#32463;&#25104;&#20026;&#35745;&#31639;&#21270;&#23398;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#21152;&#36895;&#21407;&#23376;&#27169;&#25311;&#21644;&#26448;&#26009;&#35774;&#35745;&#12290;&#27492;&#22806;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26377;&#21487;&#33021;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#30005;&#23376;&#32467;&#26500;&#29702;&#35770;&#65288;&#22914;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65289;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#32416;&#27491;&#23494;&#24230;&#27867;&#20989;&#26041;&#27861;&#20013;&#30340;&#22522;&#26412;&#38169;&#35823;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#26368;&#36817;&#22312;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#25913;&#36827;&#23494;&#24230;&#27867;&#20989;&#21644;&#30456;&#20851;&#36817;&#20284;&#26041;&#27861;&#30340;&#36827;&#23637;&#12290;&#36890;&#36807;&#31034;&#20363;&#24212;&#29992;&#26377;&#24076;&#26395;&#30340;&#27169;&#22411;&#20110;&#35757;&#32451;&#38598;&#20043;&#22806;&#30340;&#31995;&#32479;&#65292;&#35752;&#35770;&#20102;&#22312;&#19981;&#21516;&#21270;&#23398;&#21644;&#26448;&#26009;&#31867;&#21035;&#20043;&#38388;&#35774;&#35745;&#21487;&#36801;&#31227;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26102;&#21487;&#33021;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#24076;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning techniques have found their way into computational chemistry as indispensable tools to accelerate atomistic simulations and materials design. In addition, machine learning approaches hold the potential to boost the predictive power of computationally efficient electronic structure methods, such as density functional theory, to chemical accuracy and to correct for fundamental errors in density functional approaches. Here, recent progress in applying machine learning to improve the accuracy of density functional and related approximations is reviewed. Promises and challenges in devising machine learning models transferable between different chemistries and materials classes are discussed with the help of examples applying promising models to systems far outside their training sets.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#23454;&#29616;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#25935;&#24863;&#23646;&#24615;&#30340;&#21518;&#20195;&#30340;&#23545;&#29031;&#20998;&#24067;&#26469;&#30830;&#20445;&#20844;&#24179;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2310.17687</link><description>&lt;p&gt;
&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36827;&#34892;&#39044;&#27979;&#30340;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Fairness for Predictions using Generative Adversarial Networks. (arXiv:2310.17687v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17687
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#23454;&#29616;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#25935;&#24863;&#23646;&#24615;&#30340;&#21518;&#20195;&#30340;&#23545;&#29031;&#20998;&#24067;&#26469;&#30830;&#20445;&#20844;&#24179;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#27861;&#24459;&#12289;&#20262;&#29702;&#21644;&#31038;&#20250;&#21407;&#22240;&#65292;&#39044;&#27979;&#20013;&#30340;&#20844;&#24179;&#24615;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#36890;&#24120;&#36890;&#36807;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#26469;&#23454;&#29616;&#65292;&#35813;&#20844;&#24179;&#24615;&#30830;&#20445;&#20010;&#20307;&#30340;&#39044;&#27979;&#19982;&#22312;&#19981;&#21516;&#25935;&#24863;&#23646;&#24615;&#19979;&#30340;&#23545;&#29031;&#19990;&#30028;&#20013;&#30340;&#39044;&#27979;&#30456;&#21516;&#12290;&#28982;&#32780;&#65292;&#35201;&#23454;&#29616;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#23545;&#29031;&#26159;&#19981;&#21487;&#35266;&#23519;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#31216;&#20026;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GCFN&#65289;&#65292;&#29992;&#20110;&#22312;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#19979;&#36827;&#34892;&#39044;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;&#19968;&#20010;&#37327;&#36523;&#23450;&#21046;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30452;&#25509;&#23398;&#20064;&#25935;&#24863;&#23646;&#24615;&#30340;&#21518;&#20195;&#30340;&#23545;&#29031;&#20998;&#24067;&#65292;&#28982;&#21518;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#29031;&#23186;&#20171;&#27491;&#21017;&#21270;&#26469;&#23454;&#26045;&#20844;&#24179;&#39044;&#27979;&#12290;&#22914;&#26524;&#23545;&#29031;&#20998;&#24067;&#23398;&#20064;&#24471;&#36275;&#22815;&#22909;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25968;&#23398;&#19978;&#30830;&#20445;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#30340;&#27010;&#24565;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;GCFN&#35299;&#20915;&#20102;&#23545;&#29031;&#22240;&#26524;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fairness in predictions is of direct importance in practice due to legal, ethical, and societal reasons. It is often achieved through counterfactual fairness, which ensures that the prediction for an individual is the same as that in a counterfactual world under a different sensitive attribute. However, achieving counterfactual fairness is challenging as counterfactuals are unobservable. In this paper, we develop a novel deep neural network called Generative Counterfactual Fairness Network (GCFN) for making predictions under counterfactual fairness. Specifically, we leverage a tailored generative adversarial network to directly learn the counterfactual distribution of the descendants of the sensitive attribute, which we then use to enforce fair predictions through a novel counterfactual mediator regularization. If the counterfactual distribution is learned sufficiently well, our method is mathematically guaranteed to ensure the notion of counterfactual fairness. Thereby, our GCFN addre
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2309.14073</link><description>&lt;p&gt;
&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65306;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35745;&#31639;&#36825;&#20010;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#38024;&#23545;$k$-means&#21644;$k$-median&#32858;&#31867;&#30340;&#24046;&#20998;&#38544;&#31169;&#27969;&#31639;&#27861;&#65292;&#22312;&#27969;&#27169;&#22411;&#20013;&#23454;&#29616;&#23545;&#25968;&#25454;&#38544;&#31169;&#30340;&#20445;&#25252;&#65292;&#24182;&#20351;&#29992;&#23613;&#21487;&#33021;&#23569;&#30340;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2307.07449</link><description>&lt;p&gt;
&#25968;&#25454;&#27969;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Clustering in Data Streams. (arXiv:2307.07449v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07449
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#38024;&#23545;$k$-means&#21644;$k$-median&#32858;&#31867;&#30340;&#24046;&#20998;&#38544;&#31169;&#27969;&#31639;&#27861;&#65292;&#22312;&#27969;&#27169;&#22411;&#20013;&#23454;&#29616;&#23545;&#25968;&#25454;&#38544;&#31169;&#30340;&#20445;&#25252;&#65292;&#24182;&#20351;&#29992;&#23613;&#21487;&#33021;&#23569;&#30340;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#27169;&#22411;&#26159;&#22788;&#29702;&#22823;&#35268;&#27169;&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#30340;&#19968;&#31181;&#24120;&#35265;&#26041;&#27861;&#12290;&#22312;&#27969;&#27169;&#22411;&#20013;&#65292;&#25968;&#25454;&#28857;&#20381;&#27425;&#27969;&#20837;&#65292;&#31639;&#27861;&#21482;&#33021;&#23545;&#25968;&#25454;&#27969;&#36827;&#34892;&#19968;&#27425;&#36941;&#21382;&#65292;&#30446;&#26631;&#26159;&#22312;&#20351;&#29992;&#23613;&#21487;&#33021;&#23569;&#30340;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#22312;&#27969;&#20013;&#36827;&#34892;&#19968;&#20123;&#20998;&#26512;&#12290;&#32858;&#31867;&#38382;&#39064;&#26159;&#22522;&#26412;&#30340;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21407;&#35821;&#65292;&#36807;&#21435;&#24050;&#32463;&#23545;&#27969;&#32858;&#31867;&#31639;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#38544;&#31169;&#24050;&#25104;&#20026;&#19968;&#20010;&#26680;&#24515;&#20851;&#27880;&#28857;&#65292;&#38750;&#31169;&#26377;&#32858;&#31867;&#31639;&#27861;&#22312;&#35768;&#22810;&#22330;&#26223;&#19979;&#19981;&#36866;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#38024;&#23545;$k$-means&#21644;$k$-median&#32858;&#31867;&#30340;&#24046;&#20998;&#31169;&#26377;&#27969;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#38271;&#24230;&#26368;&#22810;&#20026;$T$&#30340;&#27969;&#19978;&#20351;&#29992;$poly(k,d,\log(T))$&#30340;&#31354;&#38388;&#26469;&#23454;&#29616;&#19968;&#20010;&#8220;&#24120;&#25968;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
The streaming model is an abstraction of computing over massive data streams, which is a popular way of dealing with large-scale modern data analysis. In this model, there is a stream of data points, one after the other. A streaming algorithm is only allowed one pass over the data stream, and the goal is to perform some analysis during the stream while using as small space as possible.  Clustering problems (such as $k$-means and $k$-median) are fundamental unsupervised machine learning primitives, and streaming clustering algorithms have been extensively studied in the past. However, since data privacy becomes a central concern in many real-world applications, non-private clustering algorithms are not applicable in many scenarios.  In this work, we provide the first differentially private streaming algorithms for $k$-means and $k$-median clustering of $d$-dimensional Euclidean data points over a stream with length at most $T$ using $poly(k,d,\log(T))$ space to achieve a {\it constant} 
&lt;/p&gt;</description></item><item><title>BOF-UCB&#26159;&#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;&#65292;&#20854;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#65292;&#25552;&#39640;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#23427;&#21033;&#29992;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#20197;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#26159;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#39034;&#24207;&#20915;&#31574;&#30340;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.03587</link><description>&lt;p&gt;
BOF-UCB: &#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#19978;&#19979;&#30028;&#20449;&#24515;&#31639;&#27861;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
BOF-UCB: A Bayesian-Optimistic Frequentist Algorithm for Non-Stationary Contextual Bandits. (arXiv:2307.03587v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03587
&lt;/p&gt;
&lt;p&gt;
BOF-UCB&#26159;&#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;&#65292;&#20854;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#65292;&#25552;&#39640;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#23427;&#21033;&#29992;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#20197;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#26159;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#39034;&#24207;&#20915;&#31574;&#30340;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#19978;&#19979;&#30028;&#20449;&#24515;&#31639;&#27861;&#65288;BOF-UCB&#65289;&#65292;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#38543;&#26426;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#12290;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#30340;&#29420;&#29305;&#32467;&#21512;&#22686;&#24378;&#20102;&#31639;&#27861;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#36866;&#24212;&#24615;&#21644;&#24615;&#33021;&#12290;BOF-UCB&#31639;&#27861;&#21033;&#29992;&#39034;&#24207;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#26410;&#30693;&#22238;&#24402;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#38543;&#21518;&#37319;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#36890;&#36807;&#26368;&#22823;&#21270;&#21518;&#39564;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#25910;&#30410;&#26469;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#65288;UCB&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;BOF-UCB&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel Bayesian-Optimistic Frequentist Upper Confidence Bound (BOF-UCB) algorithm for stochastic contextual linear bandits in non-stationary environments. This unique combination of Bayesian and frequentist principles enhances adaptability and performance in dynamic settings. The BOF-UCB algorithm utilizes sequential Bayesian updates to infer the posterior distribution of the unknown regression parameter, and subsequently employs a frequentist approach to compute the Upper Confidence Bound (UCB) by maximizing the expected reward over the posterior distribution. We provide theoretical guarantees of BOF-UCB's performance and demonstrate its effectiveness in balancing exploration and exploitation on synthetic datasets and classical control tasks in a reinforcement learning setting. Our results show that BOF-UCB outperforms existing methods, making it a promising solution for sequential decision-making in non-stationary environments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;Q&#32593;&#32476;&#23398;&#20064;&#21551;&#21457;&#24335;&#20989;&#25968;&#65292;&#36890;&#36807;&#21482;&#36827;&#34892;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#35745;&#31639;&#30456;&#37051;&#33410;&#28857;&#30340;&#36716;&#31227;&#25104;&#26412;&#21644;&#21551;&#21457;&#24335;&#20540;&#20043;&#21644;&#65292;&#24182;&#22312;&#19981;&#26174;&#24335;&#29983;&#25104;&#36825;&#20123;&#23376;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#25351;&#23548;&#25628;&#32034;&#30340;Q*&#25628;&#32034;&#31639;&#27861;&#65292;&#20197;&#22823;&#24133;&#20943;&#23569;&#35745;&#31639;&#26102;&#38388;&#12290;&#22312;&#39764;&#26041;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#35299;&#20915;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2102.04518</link><description>&lt;p&gt;
&#19981;&#25193;&#23637;&#30340;A*&#25628;&#32034;&#65306;&#29992;&#28145;&#24230;Q&#32593;&#32476;&#23398;&#20064;&#21551;&#21457;&#24335;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks. (arXiv:2102.04518v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.04518
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;Q&#32593;&#32476;&#23398;&#20064;&#21551;&#21457;&#24335;&#20989;&#25968;&#65292;&#36890;&#36807;&#21482;&#36827;&#34892;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#35745;&#31639;&#30456;&#37051;&#33410;&#28857;&#30340;&#36716;&#31227;&#25104;&#26412;&#21644;&#21551;&#21457;&#24335;&#20540;&#20043;&#21644;&#65292;&#24182;&#22312;&#19981;&#26174;&#24335;&#29983;&#25104;&#36825;&#20123;&#23376;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#25351;&#23548;&#25628;&#32034;&#30340;Q*&#25628;&#32034;&#31639;&#27861;&#65292;&#20197;&#22823;&#24133;&#20943;&#23569;&#35745;&#31639;&#26102;&#38388;&#12290;&#22312;&#39764;&#26041;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#35299;&#20915;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#22320;&#20351;&#29992; A* &#25628;&#32034;&#35299;&#20915;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#38382;&#39064;&#23545;&#20110;&#20154;&#24037;&#26234;&#33021;&#31038;&#21306;&#20960;&#21313;&#24180;&#26469;&#19968;&#30452;&#38750;&#24120;&#37325;&#35201;&#12290;&#36825;&#26159;&#22240;&#20026; A* &#25628;&#32034;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#38656;&#27714;&#38543;&#30528;&#21160;&#20316;&#31354;&#38388;&#30340;&#22823;&#23567;&#21576;&#32447;&#24615;&#22686;&#38271;&#12290;&#24403; A* &#25628;&#32034;&#20351;&#29992;&#35745;&#31639;&#20195;&#20215;&#39640;&#26114;&#30340;&#20989;&#25968;&#36924;&#36817;&#22120;&#65288;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#23398;&#20064;&#21551;&#21457;&#24335;&#20989;&#25968;&#26102;&#65292;&#36825;&#31181;&#36127;&#25285;&#21464;&#24471;&#26356;&#21152;&#26126;&#26174;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102; Q* &#25628;&#32034;&#65292;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230; Q &#32593;&#32476;&#24341;&#23548;&#25628;&#32034;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#20197;&#21033;&#29992;&#19968;&#20010;&#20107;&#23454;&#65292;&#21363;&#22312;&#19981;&#26174;&#24335;&#29983;&#25104;&#36825;&#20123;&#23376;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#33410;&#28857;&#30340;&#23376;&#33410;&#28857;&#30340;&#36716;&#31227;&#25104;&#26412;&#21644;&#21551;&#21457;&#24335;&#20540;&#20043;&#21644;&#21487;&#20197;&#36890;&#36807;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#35745;&#31639;&#12290;&#36825;&#26174;&#30528;&#38477;&#20302;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#19988;&#27599;&#27425;&#36845;&#20195;&#21482;&#38656;&#35201;&#29983;&#25104;&#19968;&#20010;&#33410;&#28857;&#12290;&#25105;&#20204;&#20351;&#29992; Q* &#25628;&#32034;&#26469;&#35299;&#20915;&#39764;&#26041;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#20204;&#34920;&#31034;&#20026;&#19968;&#20010;&#21253;&#21547; 1872 &#20010;&#20803;&#21160;&#20316;&#30340;&#22823;&#21160;&#20316;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficiently solving problems with large action spaces using A* search has been of importance to the artificial intelligence community for decades. This is because the computation and memory requirements of A* search grow linearly with the size of the action space. This burden becomes even more apparent when A* search uses a heuristic function learned by computationally expensive function approximators, such as deep neural networks. To address this problem, we introduce Q* search, a search algorithm that uses deep Q-networks to guide search in order to take advantage of the fact that the sum of the transition costs and heuristic values of the children of a node can be computed with a single forward pass through a deep Q-network without explicitly generating those children. This significantly reduces computation time and requires only one node to be generated per iteration. We use Q* search to solve the Rubik's cube when formulated with a large action space that includes 1872 meta-action
&lt;/p&gt;</description></item></channel></rss>