<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36890;&#36807;&#23545;ICP&#31639;&#27861;&#36827;&#34892;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#25915;&#20987;&#65292;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#35780;&#20272;&#20854;&#40065;&#26834;&#24615;&#65292;&#37325;&#28857;&#22312;&#20110;&#25214;&#21040;&#21487;&#33021;&#30340;&#26368;&#22823;ICP&#23039;&#21183;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.05666</link><description>&lt;p&gt;
&#38754;&#23545;&#26368;&#22351;&#24773;&#20917;&#65306;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#23545;ICP&#31639;&#27861;&#40065;&#26834;&#24615;&#20998;&#26512;&#30340;&#23545;&#25239;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Prepared for the Worst: A Learning-Based Adversarial Attack for Resilience Analysis of the ICP Algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05666
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;ICP&#31639;&#27861;&#36827;&#34892;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#25915;&#20987;&#65292;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#35780;&#20272;&#20854;&#40065;&#26834;&#24615;&#65292;&#37325;&#28857;&#22312;&#20110;&#25214;&#21040;&#21487;&#33021;&#30340;&#26368;&#22823;ICP&#23039;&#21183;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#25915;&#20987;&#28608;&#20809;&#38647;&#36798;&#28857;&#20113;&#26469;&#35780;&#20272;&#36845;&#20195;&#26368;&#36817;&#28857;&#65288;ICP&#65289;&#31639;&#27861;&#40065;&#26834;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#23545;&#20110;&#20687;&#33258;&#20027;&#23548;&#33322;&#36825;&#26679;&#30340;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#65292;&#30830;&#20445;&#31639;&#27861;&#22312;&#37096;&#32626;&#21069;&#30340;&#40065;&#26834;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;ICP&#31639;&#27861;&#24050;&#25104;&#20026;&#22522;&#20110;&#28608;&#20809;&#38647;&#36798;&#30340;&#23450;&#20301;&#30340;&#26631;&#20934;&#12290;&#28982;&#32780;&#65292;&#23427;&#20135;&#29983;&#30340;&#23039;&#21183;&#20272;&#35745;&#21487;&#33021;&#20250;&#21463;&#21040;&#27979;&#37327;&#25968;&#25454;&#30340;&#24433;&#21709;&#12290;&#25968;&#25454;&#30340;&#27745;&#26579;&#21487;&#33021;&#26469;&#33258;&#21508;&#31181;&#22330;&#26223;&#65292;&#22914;&#36974;&#25377;&#12289;&#24694;&#21155;&#22825;&#27668;&#25110;&#20256;&#24863;&#22120;&#30340;&#26426;&#26800;&#38382;&#39064;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;ICP&#30340;&#22797;&#26434;&#21644;&#36845;&#20195;&#29305;&#24615;&#20351;&#24471;&#35780;&#20272;&#20854;&#23545;&#27745;&#26579;&#30340;&#40065;&#26834;&#24615;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#20154;&#21162;&#21147;&#21019;&#24314;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#21644;&#24320;&#21457;&#20223;&#30495;&#26469;&#32463;&#39564;&#24615;&#22320;&#35780;&#20272;ICP&#30340;&#40065;&#26834;&#24615;&#65292;&#20294;&#25105;&#20204;&#30340;&#26041;&#27861;&#20391;&#37325;&#20110;&#36890;&#36807;&#22522;&#20110;&#25200;&#21160;&#30340;&#23545;&#25239;&#25915;&#20987;&#25214;&#21040;&#26368;&#22823;&#21487;&#33021;&#30340;ICP&#23039;&#21183;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05666v1 Announce Type: cross  Abstract: This paper presents a novel method to assess the resilience of the Iterative Closest Point (ICP) algorithm via deep-learning-based attacks on lidar point clouds. For safety-critical applications such as autonomous navigation, ensuring the resilience of algorithms prior to deployments is of utmost importance. The ICP algorithm has become the standard for lidar-based localization. However, the pose estimate it produces can be greatly affected by corruption in the measurements. Corruption can arise from a variety of scenarios such as occlusions, adverse weather, or mechanical issues in the sensor. Unfortunately, the complex and iterative nature of ICP makes assessing its resilience to corruption challenging. While there have been efforts to create challenging datasets and develop simulations to evaluate the resilience of ICP empirically, our method focuses on finding the maximum possible ICP pose error using perturbation-based adversarial
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38381;&#29615;&#26080;&#30417;&#30563;&#34920;&#31034;&#35299;&#32544;&#26041;&#27861;CL-Dis&#65292;&#20351;&#29992;&#25193;&#25955;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;Diff-AE&#65289;&#21644;&#946;-VAE&#20849;&#21516;&#25552;&#21462;&#35821;&#20041;&#35299;&#32544;&#34920;&#31034;&#65292;&#20197;&#35299;&#20915;&#34920;&#31034;&#35299;&#32544;&#38754;&#20020;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.02346</link><description>&lt;p&gt;
&#38381;&#29615;&#26080;&#30417;&#30563;&#34920;&#31034;&#35299;&#32544;&#30340;&#946;-VAE&#33976;&#39311;&#19982;&#25193;&#25955;&#27010;&#29575;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Closed-Loop Unsupervised Representation Disentanglement with $\beta$-VAE Distillation and Diffusion Probabilistic Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02346
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38381;&#29615;&#26080;&#30417;&#30563;&#34920;&#31034;&#35299;&#32544;&#26041;&#27861;CL-Dis&#65292;&#20351;&#29992;&#25193;&#25955;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;Diff-AE&#65289;&#21644;&#946;-VAE&#20849;&#21516;&#25552;&#21462;&#35821;&#20041;&#35299;&#32544;&#34920;&#31034;&#65292;&#20197;&#35299;&#20915;&#34920;&#31034;&#35299;&#32544;&#38754;&#20020;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#35299;&#32544;&#21487;&#33021;&#26377;&#21161;&#20110;AI&#26681;&#26412;&#19978;&#29702;&#35299;&#29616;&#23454;&#19990;&#30028;&#65292;&#20174;&#32780;&#20351;&#21028;&#21035;&#21644;&#29983;&#25104;&#20219;&#21153;&#21463;&#30410;&#12290;&#30446;&#21069;&#33267;&#23569;&#26377;&#19977;&#20010;&#26410;&#35299;&#20915;&#30340;&#26680;&#24515;&#38382;&#39064;&#65306;&#65288;i&#65289;&#36807;&#20110;&#20381;&#36182;&#26631;&#31614;&#27880;&#37322;&#21644;&#21512;&#25104;&#25968;&#25454;-&#23548;&#33268;&#22312;&#33258;&#28982;&#24773;&#26223;&#19979;&#27867;&#21270;&#33021;&#21147;&#36739;&#24046;&#65307;&#65288;ii&#65289;&#21551;&#21457;&#24335;/&#25163;&#24037;&#21046;&#20316;&#30340;&#35299;&#32544;&#32422;&#26463;&#20351;&#24471;&#38590;&#20197;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#26368;&#20339;&#35757;&#32451;&#26435;&#34913;&#65307;&#65288;iii&#65289;&#32570;&#20047;&#21512;&#29702;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#30495;&#23454;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#34987;&#31216;&#20026;CL-Dis&#30340;&#38381;&#29615;&#26080;&#30417;&#30563;&#34920;&#31034;&#35299;&#32544;&#26041;&#27861;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#25193;&#25955;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;Diff-AE&#65289;&#20316;&#20026;&#39592;&#24178;&#65292;&#24182;&#20351;&#29992;&#946;-VAE&#20316;&#20026;&#21103;&#39550;&#39542;&#21592;&#26469;&#25552;&#21462;&#35821;&#20041;&#35299;&#32544;&#30340;&#34920;&#31034;&#12290;&#25193;&#25955;&#27169;&#22411;&#30340;&#24378;&#22823;&#29983;&#25104;&#33021;&#21147;&#21644;VAE&#27169;&#22411;&#30340;&#33391;&#22909;&#35299;&#32544;&#33021;&#21147;&#26159;&#20114;&#34917;&#30340;&#12290;&#20026;&#20102;&#21152;&#24378;&#35299;&#32544;&#65292;&#20351;&#29992;VAE&#28508;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation disentanglement may help AI fundamentally understand the real world and thus benefit both discrimination and generation tasks. It currently has at least three unresolved core issues: (i) heavy reliance on label annotation and synthetic data -- causing poor generalization on natural scenarios; (ii) heuristic/hand-craft disentangling constraints make it hard to adaptively achieve an optimal training trade-off; (iii) lacking reasonable evaluation metric, especially for the real label-free data. To address these challenges, we propose a \textbf{C}losed-\textbf{L}oop unsupervised representation \textbf{Dis}entanglement approach dubbed \textbf{CL-Dis}. Specifically, we use diffusion-based autoencoder (Diff-AE) as a backbone while resorting to $\beta$-VAE as a co-pilot to extract semantically disentangled representations. The strong generation ability of diffusion model and the good disentanglement ability of VAE model are complementary. To strengthen disentangling, VAE-latent 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#26469;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#23398;&#20064;&#20844;&#20849;&#25968;&#25454;&#20013;&#30340;&#20849;&#20139;&#34920;&#31034;&#65292;&#21487;&#20197;&#22312;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#20013;&#23454;&#29616;&#26368;&#20248;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#22312;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#20010;&#24615;&#21270;&#22330;&#26223;&#20013;&#65292;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#21487;&#20197;&#28040;&#38500;&#31169;&#26377;&#21327;&#35843;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#32431;&#23616;&#37096;&#23398;&#20064;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;</title><link>http://arxiv.org/abs/2312.15551</link><description>&lt;p&gt;
&#21033;&#29992;&#20844;&#20849;&#34920;&#31034;&#26469;&#36827;&#34892;&#31169;&#26377;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Leveraging Public Representations for Private Transfer Learning. (arXiv:2312.15551v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15551
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#26469;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#23398;&#20064;&#20844;&#20849;&#25968;&#25454;&#20013;&#30340;&#20849;&#20139;&#34920;&#31034;&#65292;&#21487;&#20197;&#22312;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#20013;&#23454;&#29616;&#26368;&#20248;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#22312;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#20010;&#24615;&#21270;&#22330;&#26223;&#20013;&#65292;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#21487;&#20197;&#28040;&#38500;&#31169;&#26377;&#21327;&#35843;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#32431;&#23616;&#37096;&#23398;&#20064;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#23558;&#20844;&#20849;&#25968;&#25454;&#32435;&#20837;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#30340;&#26368;&#26032;&#23454;&#35777;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#20174;&#20844;&#20849;&#25968;&#25454;&#20013;&#23398;&#21040;&#30340;&#20849;&#20139;&#34920;&#31034;&#22914;&#20309;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#32447;&#24615;&#22238;&#24402;&#30340;&#20004;&#31181;&#24120;&#35265;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#65292;&#20004;&#32773;&#37117;&#20551;&#35774;&#20844;&#20849;&#20219;&#21153;&#21644;&#31169;&#26377;&#20219;&#21153;&#65288;&#22238;&#24402;&#21521;&#37327;&#65289;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20849;&#20139;&#19968;&#20010;&#20302;&#31209;&#23376;&#31354;&#38388;&#12290;&#22312;&#31532;&#19968;&#31181;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#22312;&#25152;&#26377;&#29992;&#25143;&#20043;&#38388;&#20849;&#20139;&#30340;&#21333;&#19968;&#27169;&#22411;&#65292;&#27599;&#20010;&#29992;&#25143;&#23545;&#24212;&#25968;&#25454;&#38598;&#20013;&#30340;&#19968;&#34892;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#21305;&#37197;&#30340;&#19978;&#19979;&#30028;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#20272;&#35745;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#30340;&#31639;&#27861;&#31867;&#20013;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#27169;&#22411;&#20010;&#24615;&#21270;&#30340;&#31532;&#20108;&#31181;&#24773;&#26223;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#22312;&#26377;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#29992;&#25143;&#21487;&#20197;&#36991;&#20813;&#31169;&#26377;&#21327;&#35843;&#65292;&#22240;&#20026;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#20869;&#32431;&#31929;&#30340;&#23616;&#37096;&#23398;&#20064;&#21487;&#20197;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the recent empirical success of incorporating public data into differentially private learning, we theoretically investigate how a shared representation learned from public data can improve private learning. We explore two common scenarios of transfer learning for linear regression, both of which assume the public and private tasks (regression vectors) share a low-rank subspace in a high-dimensional space. In the first single-task transfer scenario, the goal is to learn a single model shared across all users, each corresponding to a row in a dataset. We provide matching upper and lower bounds showing that our algorithm achieves the optimal excess risk within a natural class of algorithms that search for the linear model within the given subspace estimate. In the second scenario of multitask model personalization, we show that with sufficient public data, users can avoid private coordination, as purely local learning within the given subspace achieves the same utility. Take
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#33258;&#21160;&#32570;&#38519;&#29983;&#25104;&#38382;&#39064;&#65292;&#38024;&#23545;&#38590;&#20197;&#26816;&#27979;&#21644;&#38590;&#20197;&#20462;&#22797;&#30340;&#32570;&#38519;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#20998;&#26512;&#20102;&#22522;&#20110;&#23398;&#20064;&#30340;&#25216;&#26415;&#20013;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#20914;&#31361;&#12290;</title><link>http://arxiv.org/abs/2310.02407</link><description>&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#33258;&#21160;&#32570;&#38519;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Automated Bug Generation in the era of Large Language Models. (arXiv:2310.02407v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#33258;&#21160;&#32570;&#38519;&#29983;&#25104;&#38382;&#39064;&#65292;&#38024;&#23545;&#38590;&#20197;&#26816;&#27979;&#21644;&#38590;&#20197;&#20462;&#22797;&#30340;&#32570;&#38519;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#20998;&#26512;&#20102;&#22522;&#20110;&#23398;&#20064;&#30340;&#25216;&#26415;&#20013;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#20914;&#31361;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#38519;&#22312;&#36719;&#20214;&#24037;&#31243;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65307;&#36807;&#21435;&#20960;&#21313;&#24180;&#30340;&#35768;&#22810;&#30740;&#31350;&#24050;&#32463;&#25552;&#20986;&#20102;&#26816;&#27979;&#12289;&#23450;&#20301;&#21644;&#20462;&#22797;&#36719;&#20214;&#31995;&#32479;&#20013;&#30340;&#32570;&#38519;&#30340;&#26041;&#27861;&#12290;&#35780;&#20272;&#36825;&#20123;&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#38656;&#35201;&#22797;&#26434;&#30340;&#32570;&#38519;&#65292;&#21363;&#37027;&#20123;&#24456;&#38590;&#36890;&#36807;&#27979;&#35797;&#21644;&#35843;&#35797;&#26469;&#26816;&#27979;&#21644;&#20462;&#22797;&#30340;&#32570;&#38519;&#12290;&#20174;&#20256;&#32479;&#36719;&#20214;&#24037;&#31243;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#38590;&#20197;&#20462;&#22797;&#30340;&#32570;&#38519;&#19982;&#27491;&#30830;&#30340;&#20195;&#30721;&#22312;&#22810;&#20010;&#20301;&#32622;&#19978;&#26377;&#25152;&#24046;&#24322;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#38590;&#20197;&#23450;&#20301;&#21644;&#20462;&#22797;&#12290;&#32780;&#38590;&#20197;&#26816;&#27979;&#30340;&#32570;&#38519;&#21017;&#22312;&#29305;&#23450;&#30340;&#27979;&#35797;&#36755;&#20837;&#21644;&#21487;&#36798;&#26465;&#20214;&#19979;&#23637;&#29616;&#20986;&#26469;&#12290;&#36825;&#20004;&#20010;&#30446;&#26631;&#65292;&#21363;&#29983;&#25104;&#38590;&#20197;&#26816;&#27979;&#21644;&#38590;&#20197;&#20462;&#22797;&#30340;&#32570;&#38519;&#65292;&#22823;&#22810;&#25968;&#26159;&#19968;&#33268;&#30340;&#65307;&#32570;&#38519;&#29983;&#25104;&#25216;&#26415;&#21487;&#20197;&#23558;&#22810;&#20010;&#35821;&#21477;&#26356;&#25913;&#20026;&#20165;&#22312;&#29305;&#23450;&#36755;&#20837;&#38598;&#21512;&#19979;&#34987;&#35206;&#30422;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22522;&#20110;&#23398;&#20064;&#30340;&#25216;&#26415;&#26469;&#35828;&#65292;&#36825;&#20004;&#20010;&#30446;&#26631;&#26159;&#30456;&#20114;&#20914;&#31361;&#30340;&#65306;&#19968;&#20010;&#32570;&#38519;&#24212;&#35813;&#26377;&#19982;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#27491;&#30830;&#20195;&#30721;&#30456;&#20284;&#30340;&#20195;&#30721;&#34920;&#31034;&#65292;&#20197;&#25361;&#25112;&#32570;&#38519;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bugs are essential in software engineering; many research studies in the past decades have been proposed to detect, localize, and repair bugs in software systems. Effectiveness evaluation of such techniques requires complex bugs, i.e., those that are hard to detect through testing and hard to repair through debugging. From the classic software engineering point of view, a hard-to-repair bug differs from the correct code in multiple locations, making it hard to localize and repair. Hard-to-detect bugs, on the other hand, manifest themselves under specific test inputs and reachability conditions. These two objectives, i.e., generating hard-to-detect and hard-to-repair bugs, are mostly aligned; a bug generation technique can change multiple statements to be covered only under a specific set of inputs. However, these two objectives are conflicting for learning-based techniques: A bug should have a similar code representation to the correct code in the training data to challenge a bug predi
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#27599;&#36718;&#25237;&#24433;&#30340;&#25968;&#37327;&#26469;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08911</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Methods for Non-stationary Online Learning. (arXiv:2309.08911v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08911
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#27599;&#36718;&#25237;&#24433;&#30340;&#25968;&#37327;&#26469;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#29305;&#21035;&#26159;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#65292;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#34987;&#25552;&#20986;&#20316;&#20026;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#20004;&#20010;&#21407;&#21017;&#24615;&#24615;&#33021;&#24230;&#37327;&#12290;&#20026;&#20102;&#20248;&#21270;&#23427;&#20204;&#65292;&#36890;&#24120;&#37319;&#29992;&#20004;&#23618;&#22312;&#32447;&#38598;&#25104;&#65292;&#30001;&#20110;&#38750;&#24179;&#31283;&#24615;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#65292;&#20854;&#20013;&#32500;&#25252;&#19968;&#32452;&#22522;&#23398;&#20064;&#22120;&#65292;&#24182;&#37319;&#29992;&#20803;&#31639;&#27861;&#22312;&#36816;&#34892;&#36807;&#31243;&#20013;&#36319;&#36394;&#26368;&#20339;&#23398;&#20064;&#22120;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20004;&#23618;&#32467;&#26500;&#24341;&#21457;&#20102;&#20851;&#20110;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#25285;&#24551; -&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#21516;&#26102;&#32500;&#25252;$\mathcal{O}(\log T)$&#20010;&#22522;&#23398;&#20064;&#22120;&#65292;&#23545;&#20110;&#19968;&#20010;$T$&#36718;&#22312;&#32447;&#28216;&#25103;&#65292;&#22240;&#27492;&#27599;&#36718;&#25191;&#34892;&#22810;&#27425;&#25237;&#24433;&#21040;&#21487;&#34892;&#22495;&#19978;&#65292;&#24403;&#22495;&#24456;&#22797;&#26434;&#26102;&#65292;&#36825;&#25104;&#20026;&#35745;&#31639;&#29942;&#39048;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#23558;&#27599;&#36718;&#30340;&#25237;&#24433;&#27425;&#25968;&#20174;$\mathcal{O}(\log T)$&#38477;&#20302;&#21040;...
&lt;/p&gt;
&lt;p&gt;
Non-stationary online learning has drawn much attention in recent years. In particular, dynamic regret and adaptive regret are proposed as two principled performance measures for online convex optimization in non-stationary environments. To optimize them, a two-layer online ensemble is usually deployed due to the inherent uncertainty of the non-stationarity, in which a group of base-learners are maintained and a meta-algorithm is employed to track the best one on the fly. However, the two-layer structure raises the concern about the computational complexity -- those methods typically maintain $\mathcal{O}(\log T)$ base-learners simultaneously for a $T$-round online game and thus perform multiple projections onto the feasible domain per round, which becomes the computational bottleneck when the domain is complicated. In this paper, we present efficient methods for optimizing dynamic regret and adaptive regret, which reduce the number of projections per round from $\mathcal{O}(\log T)$ t
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25968;&#25454;&#23457;&#35745;&#21644;&#35302;&#21457;&#22120;&#22270;&#20687;&#36807;&#28388;&#31561;&#26426;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#25968;&#25454;&#29983;&#25104;&#35302;&#21457;&#22120;&#30340;&#38450;&#24481;&#26041;&#27861;&#26469;&#20445;&#25252;&#32852;&#37030;&#23398;&#20064;&#20813;&#21463;&#21518;&#38376;&#25915;&#20987;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#21518;&#38376;&#25915;&#20987;&#29305;&#24449;&#26469;&#23398;&#20064;&#35302;&#21457;&#22120;&#65292;&#24182;&#29983;&#25104;&#20855;&#26377;&#26032;&#23398;&#20064;&#30693;&#35782;&#30340;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2308.11333</link><description>&lt;p&gt;
&#26080;&#25968;&#25454;&#29983;&#25104;&#35302;&#21457;&#22120;&#20445;&#25252;&#32852;&#37030;&#23398;&#20064;&#20813;&#21463;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation. (arXiv:2308.11333v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11333
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25968;&#25454;&#23457;&#35745;&#21644;&#35302;&#21457;&#22120;&#22270;&#20687;&#36807;&#28388;&#31561;&#26426;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#25968;&#25454;&#29983;&#25104;&#35302;&#21457;&#22120;&#30340;&#38450;&#24481;&#26041;&#27861;&#26469;&#20445;&#25252;&#32852;&#37030;&#23398;&#20064;&#20813;&#21463;&#21518;&#38376;&#25915;&#20987;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#21518;&#38376;&#25915;&#20987;&#29305;&#24449;&#26469;&#23398;&#20064;&#35302;&#21457;&#22120;&#65292;&#24182;&#29983;&#25104;&#20855;&#26377;&#26032;&#23398;&#20064;&#30693;&#35782;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#33539; paradigm&#65292;&#32852;&#37030;&#23398;&#20064; (FL) &#21487;&#20197;&#20351;&#22823;&#35268;&#27169;&#23458;&#25143;&#31471;&#22312;&#19981;&#20849;&#20139;&#21407;&#22987;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21327;&#21516;&#35757;&#32451;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23545;&#19981;&#21487;&#20449;&#23458;&#25143;&#31471;&#30340;&#25968;&#25454;&#23457;&#35745;&#32570;&#22833;&#65292;FL &#26131;&#21463;&#27745;&#26579;&#25915;&#20987;&#65292;&#29305;&#21035;&#26159;&#21518;&#38376;&#25915;&#20987;&#12290;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#27745;&#26579;&#25968;&#25454;&#36827;&#34892;&#26412;&#22320;&#35757;&#32451;&#25110;&#30452;&#25509;&#26356;&#25913;&#27169;&#22411;&#21442;&#25968;&#65292;&#36731;&#32780;&#26131;&#20030;&#22320;&#23558;&#21518;&#38376;&#27880;&#20837;&#27169;&#22411;&#65292;&#20174;&#32780;&#35302;&#21457;&#27169;&#22411;&#23545;&#22270;&#20687;&#20013;&#30340;&#30446;&#26631;&#27169;&#24335;&#36827;&#34892;&#38169;&#35823;&#20998;&#31867;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20004;&#20010;&#21518;&#38376;&#25915;&#20987;&#29305;&#24449;&#30340;&#26032;&#22411;&#26080;&#25968;&#25454;&#29983;&#25104;&#35302;&#21457;&#22120;&#38450;&#24481;&#26041;&#27861;&#65306;i) &#35302;&#21457;&#22120;&#23398;&#20064;&#36895;&#24230;&#27604;&#26222;&#36890;&#30693;&#35782;&#26356;&#24555;&#65292;ii) &#35302;&#21457;&#22120;&#27169;&#24335;&#23545;&#22270;&#20687;&#20998;&#31867;&#30340;&#24433;&#21709;&#22823;&#20110;&#26222;&#36890;&#31867;&#21035;&#27169;&#24335;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#35782;&#21035;&#26087;&#21644;&#26032;&#20840;&#23616;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#29983;&#25104;&#20855;&#26377;&#26032;&#23398;&#20064;&#30693;&#35782;&#30340;&#22270;&#20687;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;&#26041;&#27861;&#36807;&#28388;&#35302;&#21457;&#22120;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a distributed machine learning paradigm, Federated Learning (FL) enables large-scale clients to collaboratively train a model without sharing their raw data. However, due to the lack of data auditing for untrusted clients, FL is vulnerable to poisoning attacks, especially backdoor attacks. By using poisoned data for local training or directly changing the model parameters, attackers can easily inject backdoors into the model, which can trigger the model to make misclassification of targeted patterns in images. To address these issues, we propose a novel data-free trigger-generation-based defense approach based on the two characteristics of backdoor attacks: i) triggers are learned faster than normal knowledge, and ii) trigger patterns have a greater effect on image classification than normal class patterns. Our approach generates the images with newly learned knowledge by identifying the differences between the old and new global models, and filters trigger images by evaluating the 
&lt;/p&gt;</description></item></channel></rss>