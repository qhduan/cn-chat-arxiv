<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;FedDG&#26550;&#26500;&#26041;&#27861;gPerXAN&#65292;&#36890;&#36807;&#35268;&#33539;&#21270;&#26041;&#26696;&#21644;&#24341;&#23548;&#27491;&#21017;&#21270;&#22120;&#37197;&#21512;&#24037;&#20316;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#26174;&#24335;&#32452;&#35013;&#35268;&#33539;&#21270;&#65292;&#26377;&#21161;&#20110;&#23458;&#25143;&#31471;&#27169;&#22411;&#23545;&#39046;&#22495;&#29305;&#24449;&#36827;&#34892;&#26377;&#36873;&#25321;&#24615;&#36807;&#28388;&#12290;</title><link>https://arxiv.org/abs/2403.15605</link><description>&lt;p&gt;
&#20026;&#32852;&#37030;&#39046;&#22495;&#27867;&#21270;&#39640;&#25928;&#32452;&#21512;&#35268;&#33539;&#21270;&#23618;&#19982;&#27491;&#21017;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficiently Assemble Normalization Layers and Regularization for Federated Domain Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15605
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;FedDG&#26550;&#26500;&#26041;&#27861;gPerXAN&#65292;&#36890;&#36807;&#35268;&#33539;&#21270;&#26041;&#26696;&#21644;&#24341;&#23548;&#27491;&#21017;&#21270;&#22120;&#37197;&#21512;&#24037;&#20316;&#65292;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#26174;&#24335;&#32452;&#35013;&#35268;&#33539;&#21270;&#65292;&#26377;&#21161;&#20110;&#23458;&#25143;&#31471;&#27169;&#22411;&#23545;&#39046;&#22495;&#29305;&#24449;&#36827;&#34892;&#26377;&#36873;&#25321;&#24615;&#36807;&#28388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#36716;&#31227;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#20005;&#23803;&#30340;&#38382;&#39064;&#65292;&#20250;&#23548;&#33268;&#27169;&#22411;&#22312;&#26410;&#30693;&#39046;&#22495;&#27979;&#35797;&#26102;&#24615;&#33021;&#19979;&#38477;&#12290;&#32852;&#37030;&#39046;&#22495;&#27867;&#21270;&#65288;FedDG&#65289;&#26088;&#22312;&#20197;&#38544;&#31169;&#20445;&#25252;&#30340;&#26041;&#24335;&#20351;&#29992;&#21327;&#20316;&#23458;&#25143;&#31471;&#35757;&#32451;&#20840;&#23616;&#27169;&#22411;&#65292;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#21040;&#21487;&#33021;&#23384;&#22312;&#39046;&#22495;&#36716;&#31227;&#30340;&#26410;&#30693;&#23458;&#25143;&#31471;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;FedDG&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#39069;&#22806;&#30340;&#25968;&#25454;&#27844;&#38706;&#38544;&#31169;&#39118;&#38505;&#65292;&#25110;&#32773;&#22312;&#23458;&#25143;&#31471;&#36890;&#20449;&#21644;&#35745;&#31639;&#25104;&#26412;&#26041;&#38754;&#20135;&#29983;&#26174;&#33879;&#24320;&#38144;&#65292;&#36825;&#22312;&#32852;&#37030;&#23398;&#20064;&#33539;&#24335;&#20013;&#26159;&#20027;&#35201;&#20851;&#27880;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;FedDG&#26550;&#26500;&#26041;&#27861;&#65292;&#21363;gPerXAN&#65292;&#23427;&#20381;&#36182;&#20110;&#19968;&#20010;&#35268;&#33539;&#21270;&#26041;&#26696;&#19982;&#24341;&#23548;&#27491;&#21017;&#21270;&#22120;&#37197;&#21512;&#24037;&#20316;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#31934;&#24515;&#35774;&#35745;&#20102;&#20010;&#24615;&#21270;&#26174;&#24335;&#32452;&#35013;&#35268;&#33539;&#21270;&#65292;&#20197;&#24378;&#21046;&#23458;&#25143;&#31471;&#27169;&#22411;&#26377;&#36873;&#25321;&#22320;&#36807;&#28388;&#23545;&#26412;&#22320;&#25968;&#25454;&#26377;&#20559;&#21521;&#30340;&#29305;&#23450;&#39046;&#22495;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15605v1 Announce Type: cross  Abstract: Domain shift is a formidable issue in Machine Learning that causes a model to suffer from performance degradation when tested on unseen domains. Federated Domain Generalization (FedDG) attempts to train a global model using collaborative clients in a privacy-preserving manner that can generalize well to unseen clients possibly with domain shift. However, most existing FedDG methods either cause additional privacy risks of data leakage or induce significant costs in client communication and computation, which are major concerns in the Federated Learning paradigm. To circumvent these challenges, here we introduce a novel architectural method for FedDG, namely gPerXAN, which relies on a normalization scheme working with a guiding regularizer. In particular, we carefully design Personalized eXplicitly Assembled Normalization to enforce client models selectively filtering domain-specific features that are biased towards local data while ret
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;MeZO&#26041;&#27861;&#65292;&#36890;&#36807;&#20165;&#23545;&#31934;&#24515;&#36873;&#25321;&#30340;&#21442;&#25968;&#23376;&#38598;&#24212;&#29992;&#38646;&#38454;&#20248;&#21270;&#65292;&#23454;&#29616;&#20102;&#22312;&#38646;&#38454;LLM&#24494;&#35843;&#20013;&#20943;&#23569;&#21442;&#25968;&#20197;&#33719;&#24471;&#26356;&#22909;&#24615;&#33021;&#30340;&#30446;&#26631;</title><link>https://arxiv.org/abs/2402.15751</link><description>&lt;p&gt;
&#31232;&#30095;MeZO&#65306;&#22312;&#38646;&#38454;LLM&#24494;&#35843;&#20013;&#20943;&#23569;&#21442;&#25968;&#20197;&#33719;&#24471;&#26356;&#22909;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15751
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;MeZO&#26041;&#27861;&#65292;&#36890;&#36807;&#20165;&#23545;&#31934;&#24515;&#36873;&#25321;&#30340;&#21442;&#25968;&#23376;&#38598;&#24212;&#29992;&#38646;&#38454;&#20248;&#21270;&#65292;&#23454;&#29616;&#20102;&#22312;&#38646;&#38454;LLM&#24494;&#35843;&#20013;&#20943;&#23569;&#21442;&#25968;&#20197;&#33719;&#24471;&#26356;&#22909;&#24615;&#33021;&#30340;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38024;&#23545;&#29305;&#23450;&#20219;&#21153;&#36827;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24494;&#35843;&#36890;&#24120;&#20250;&#20135;&#29983;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#20294;&#30001;&#20110;&#22522;&#20110;&#26799;&#24230;&#30340;&#35757;&#32451;&#20013;&#30340;&#21453;&#21521;&#20256;&#25773;&#32780;&#23548;&#33268;&#20869;&#23384;&#25928;&#29575;&#20302;&#19979;&#12290;&#26368;&#36817;&#25552;&#20986;&#30340;&#39640;&#25928;&#21033;&#29992;&#23384;&#20648;&#22120;&#30340;&#38646;&#38454;&#65288;MeZO&#65289;&#20248;&#21270;&#22120;&#26088;&#22312;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21482;&#38656;&#35201;&#21069;&#21521;&#20256;&#36882;&#65292;&#20351;&#20854;&#26356;&#31526;&#21512;&#20869;&#23384;&#21451;&#22909;&#24615;&#12290;&#28982;&#32780;&#65292;&#38646;&#38454;&#20248;&#21270;&#20013;&#26799;&#24230;&#20272;&#35745;&#30340;&#36136;&#37327;&#24448;&#24448;&#21462;&#20915;&#20110;&#25968;&#25454;&#30340;&#32500;&#25968;&#65292;&#36825;&#21487;&#33021;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19982;&#21508;&#31181;&#20219;&#21153;&#20013;&#30340;&#26631;&#20934;&#24494;&#35843;&#30456;&#27604;&#65292;MeZO&#20173;&#28982;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#21463;&#21040;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#65288;PEFT&#65289;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#31232;&#30095;MeZO&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#20869;&#23384;&#39640;&#25928;&#30340;&#38646;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#20165;&#23558;ZO&#24212;&#29992;&#20110;&#31934;&#24515;&#36873;&#25321;&#30340;&#21442;&#25968;&#23376;&#38598;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#21442;&#25968;&#36873;&#25321;&#26041;&#26696;&#65292;&#33719;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15751v1 Announce Type: cross  Abstract: While fine-tuning large language models (LLMs) for specific tasks often yields impressive results, it comes at the cost of memory inefficiency due to back-propagation in gradient-based training. Memory-efficient Zeroth-order (MeZO) optimizers, recently proposed to address this issue, only require forward passes during training, making them more memory-friendly. However, the quality of gradient estimates in zeroth order optimization often depends on the data dimensionality, potentially explaining why MeZO still exhibits significant performance drops compared to standard fine-tuning across various tasks. Inspired by the success of Parameter-Efficient Fine-Tuning (PEFT), this paper introduces Sparse MeZO, a novel memory-efficient zeroth-order optimization approach that applies ZO only to a carefully chosen subset of parameters. We propose a simple yet effective parameter selection scheme that yields significant performance gains with Spar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#35777;&#26126;&#19968;&#20010;&#36275;&#22815;&#23485;&#32780;&#20219;&#24847;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20986;&#26469;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#27169;&#22411;&#19982;&#22823;&#22411;&#22240;&#23376;&#27169;&#22411;&#31561;&#25928;&#65292;&#25171;&#24320;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#27492;&#39046;&#22495;&#20013;&#30340;&#40657;&#30418;&#23376;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#23553;&#38381;&#24418;&#24335;&#30340;&#25512;&#23548;&#26041;&#27861;&#12290;&#30740;&#31350;&#23454;&#35777;&#20102;&#19981;&#21516;&#26550;&#26500;&#36873;&#25321;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#38543;&#30528;&#28145;&#24230;&#22686;&#21152;&#65292;&#27169;&#22411;&#22312;&#36275;&#22815;&#22810;&#25968;&#25454;&#19979;&#30340;&#34920;&#29616;&#36880;&#28176;&#25552;&#21319;&#65292;&#30452;&#33267;&#36798;&#21040;&#39281;&#21644;&#12290;</title><link>https://arxiv.org/abs/2402.06635</link><description>&lt;p&gt;
&#22823;&#22411;&#65288;&#21644;&#28145;&#24230;&#65289;&#22240;&#23376;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large (and Deep) Factor Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06635
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#35777;&#26126;&#19968;&#20010;&#36275;&#22815;&#23485;&#32780;&#20219;&#24847;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20986;&#26469;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#27169;&#22411;&#19982;&#22823;&#22411;&#22240;&#23376;&#27169;&#22411;&#31561;&#25928;&#65292;&#25171;&#24320;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#27492;&#39046;&#22495;&#20013;&#30340;&#40657;&#30418;&#23376;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#23553;&#38381;&#24418;&#24335;&#30340;&#25512;&#23548;&#26041;&#27861;&#12290;&#30740;&#31350;&#23454;&#35777;&#20102;&#19981;&#21516;&#26550;&#26500;&#36873;&#25321;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#38543;&#30528;&#28145;&#24230;&#22686;&#21152;&#65292;&#27169;&#22411;&#22312;&#36275;&#22815;&#22810;&#25968;&#25454;&#19979;&#30340;&#34920;&#29616;&#36880;&#28176;&#25552;&#21319;&#65292;&#30452;&#33267;&#36798;&#21040;&#39281;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25171;&#24320;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#20013;&#30340;&#40657;&#30418;&#23376;&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#20010;&#36275;&#22815;&#23485;&#32780;&#20219;&#24847;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;(DNN)&#34987;&#35757;&#32451;&#29992;&#26469;&#26368;&#22823;&#21270;&#38543;&#26426;&#36148;&#29616;&#22240;&#23376;(SDF)&#30340;&#22799;&#26222;&#27604;&#29575;&#31561;&#25928;&#20110;&#19968;&#20010;&#22823;&#22411;&#22240;&#23376;&#27169;&#22411;(LFM)&#65306;&#19968;&#20010;&#20351;&#29992;&#35768;&#22810;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#32447;&#24615;&#22240;&#23376;&#23450;&#20215;&#27169;&#22411;&#12290;&#36825;&#20123;&#29305;&#24449;&#30340;&#24615;&#36136;&#21462;&#20915;&#20110;DNN&#30340;&#20307;&#31995;&#32467;&#26500;&#65292;&#22312;&#19968;&#31181;&#26126;&#30830;&#21487;&#36861;&#36394;&#30340;&#26041;&#24335;&#19979;&#12290;&#36825;&#20351;&#24471;&#39318;&#27425;&#21487;&#20197;&#25512;&#23548;&#20986;&#23553;&#38381;&#24418;&#24335;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#30340;&#22522;&#20110;DNN&#30340;SDF&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#20102;LFMs&#65292;&#24182;&#23637;&#31034;&#20102;&#21508;&#31181;&#26550;&#26500;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;SDF&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#28145;&#24230;&#22797;&#26434;&#24615;&#30340;&#20248;&#28857;&#65306;&#38543;&#30528;&#36275;&#22815;&#22810;&#30340;&#25968;&#25454;&#65292;DNN-SDF&#30340;&#22806;&#26679;&#24635;&#20307;&#34920;&#29616;&#20250;&#38543;&#30528;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#32780;&#22686;&#21152;&#65292;&#24403;&#38544;&#34255;&#23618;&#36798;&#21040;&#32422;100&#23618;&#26102;&#36798;&#21040;&#39281;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
We open up the black box behind Deep Learning for portfolio optimization and prove that a sufficiently wide and arbitrarily deep neural network (DNN) trained to maximize the Sharpe ratio of the Stochastic Discount Factor (SDF) is equivalent to a large factor model (LFM): A linear factor pricing model that uses many non-linear characteristics. The nature of these characteristics depends on the architecture of the DNN in an explicit, tractable fashion. This makes it possible to derive end-to-end trained DNN-based SDFs in closed form for the first time. We evaluate LFMs empirically and show how various architectural choices impact SDF performance. We document the virtue of depth complexity: With enough data, the out-of-sample performance of DNN-SDF is increasing in the NN depth, saturating at huge depths of around 100 hidden layers.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;&#30340;&#26041;&#27861;&#21487;&#20197;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#65292;&#20174;&#32780;&#22312;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#26041;&#38754;&#21462;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02644</link><description>&lt;p&gt;
&#36890;&#36807;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#30340;&#26041;&#27861;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Variational DAG Estimation via State Augmentation With Stochastic Permutations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02644
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#29366;&#24577;&#25193;&#23637;&#21644;&#38543;&#26426;&#25490;&#21015;&#36827;&#34892;&#21464;&#20998;DAG&#20272;&#35745;&#30340;&#26041;&#27861;&#21487;&#20197;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#65292;&#20174;&#32780;&#22312;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#26041;&#38754;&#21462;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#65292;&#21363;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#65292;&#26159;&#19968;&#20010;&#22312;&#32479;&#35745;&#21644;&#35745;&#31639;&#19978;&#37117;&#24456;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#22312;&#22240;&#26524;&#21457;&#29616;&#31561;&#39046;&#22495;&#26377;&#30528;&#37325;&#35201;&#24212;&#29992;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#22312;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#26041;&#38754;&#26159;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#22788;&#29702;&#20247;&#25152;&#21608;&#30693;&#30340;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#12290;&#20174;&#27010;&#29575;&#25512;&#26029;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#20027;&#35201;&#30340;&#25361;&#25112;&#26159;&#65288;i&#65289;&#34920;&#31034;&#28385;&#36275;DAG&#32422;&#26463;&#30340;&#22270;&#30340;&#20998;&#24067;&#21644;&#65288;ii&#65289;&#20272;&#35745;&#24213;&#23618;&#32452;&#21512;&#31354;&#38388;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;DAG&#21644;&#25490;&#21015;&#30340;&#25193;&#23637;&#31354;&#38388;&#19978;&#26500;&#24314;&#32852;&#21512;&#20998;&#24067;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#21518;&#39564;&#20272;&#35745;&#65292;&#22312;&#20854;&#20013;&#21033;&#29992;&#20102;&#31163;&#25955;&#20998;&#24067;&#30340;&#36830;&#32493;&#26494;&#24347;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#33021;&#22815;&#36229;&#36234;&#31454;&#20105;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the structure of a Bayesian network, in the form of a directed acyclic graph (DAG), from observational data is a statistically and computationally hard problem with essential applications in areas such as causal discovery. Bayesian approaches are a promising direction for solving this task, as they allow for uncertainty quantification and deal with well-known identifiability issues. From a probabilistic inference perspective, the main challenges are (i) representing distributions over graphs that satisfy the DAG constraint and (ii) estimating a posterior over the underlying combinatorial space. We propose an approach that addresses these challenges by formulating a joint distribution on an augmented space of DAGs and permutations. We carry out posterior estimation via variational inference, where we exploit continuous relaxations of discrete distributions. We show that our approach can outperform competitive Bayesian and non-Bayesian benchmarks on a range of synthetic and re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#20219;&#21153;&#21644;&#26041;&#27861;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2307.14397</link><description>&lt;p&gt;
&#20851;&#20110;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#29983;&#25104;&#24314;&#27169;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot. (arXiv:2307.14397v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#20219;&#21153;&#21644;&#26041;&#27861;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#29983;&#25104;&#24314;&#27169;&#26088;&#22312;&#23398;&#20064;&#29983;&#25104;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#32479;&#35745;&#30456;&#20284;&#30340;&#26032;&#25968;&#25454;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#12289;&#23569;&#26679;&#26412;&#21644;&#38646;&#26679;&#26412;&#26465;&#20214;&#19979;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#31216;&#20026;&#25968;&#25454;&#32422;&#26463;&#19979;&#30340;&#29983;&#25104;&#24314;&#27169;&#65288;GM-DC&#65289;&#12290;&#36825;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20027;&#39064;&#65292;&#24403;&#25968;&#25454;&#33719;&#21462;&#20855;&#26377;&#25361;&#25112;&#24615;&#26102;&#65292;&#20363;&#22914;&#21307;&#30103;&#24212;&#29992;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#32972;&#26223;&#12289;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#20998;&#31867;&#20307;&#31995;&#65306;&#19968;&#20010;&#26159;GM-DC&#20219;&#21153;&#20998;&#31867;&#65292;&#21478;&#19968;&#20010;&#26159;GM-DC&#26041;&#27861;&#20998;&#31867;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;GM-DC&#20219;&#21153;&#21644;&#26041;&#27861;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#30740;&#31350;&#31354;&#30333;&#12289;&#30740;&#31350;&#36235;&#21183;&#21644;&#26410;&#26469;&#25506;&#32034;&#30340;&#28508;&#22312;&#36884;&#24452;&#12290;&#39033;&#30446;&#32593;&#31449;&#65306;https://gmdc-survey.github.io&#12290;
&lt;/p&gt;
&lt;p&gt;
In machine learning, generative modeling aims to learn to generate new data statistically similar to the training data distribution. In this paper, we survey learning generative models under limited data, few shots and zero shot, referred to as Generative Modeling under Data Constraint (GM-DC). This is an important topic when data acquisition is challenging, e.g. healthcare applications. We discuss background, challenges, and propose two taxonomies: one on GM-DC tasks and another on GM-DC approaches. Importantly, we study interactions between different GM-DC tasks and approaches. Furthermore, we highlight research gaps, research trends, and potential avenues for future exploration. Project website: https://gmdc-survey.github.io.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22238;&#24402;&#31639;&#27861;LESS&#65292;&#36890;&#36807;&#29983;&#25104;&#20197;&#38543;&#26426;&#28857;&#20026;&#20013;&#24515;&#30340;&#23376;&#38598;&#24182;&#35757;&#32451;&#23616;&#37096;&#39044;&#27979;&#22120;&#65292;&#28982;&#21518;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#32452;&#21512;&#39044;&#27979;&#22120;&#24471;&#21040;&#25972;&#20307;&#39044;&#27979;&#22120;&#12290;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#34920;&#26126;&#65292;LESS&#26159;&#19968;&#31181;&#26377;&#31454;&#20105;&#21147;&#19988;&#39640;&#25928;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2112.06251</link><description>&lt;p&gt;
&#23398;&#20064;&#19982;&#23376;&#38598;&#21472;&#21152;
&lt;/p&gt;
&lt;p&gt;
Learning with Subset Stacking. (arXiv:2112.06251v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.06251
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22238;&#24402;&#31639;&#27861;LESS&#65292;&#36890;&#36807;&#29983;&#25104;&#20197;&#38543;&#26426;&#28857;&#20026;&#20013;&#24515;&#30340;&#23376;&#38598;&#24182;&#35757;&#32451;&#23616;&#37096;&#39044;&#27979;&#22120;&#65292;&#28982;&#21518;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#32452;&#21512;&#39044;&#27979;&#22120;&#24471;&#21040;&#25972;&#20307;&#39044;&#27979;&#22120;&#12290;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#34920;&#26126;&#65292;LESS&#26159;&#19968;&#31181;&#26377;&#31454;&#20105;&#21147;&#19988;&#39640;&#25928;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22238;&#24402;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20174;&#19968;&#32452;&#36755;&#20837;-&#36755;&#20986;&#23545;&#20013;&#36827;&#34892;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36866;&#29992;&#20110;&#36755;&#20837;&#21464;&#37327;&#19982;&#36755;&#20986;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#34920;&#29616;&#20986;&#24322;&#36136;&#34892;&#20026;&#30340;&#32676;&#20307;&#12290;&#35813;&#31639;&#27861;&#39318;&#20808;&#29983;&#25104;&#20197;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#38543;&#26426;&#28857;&#20026;&#20013;&#24515;&#30340;&#23376;&#38598;&#65292;&#28982;&#21518;&#20026;&#27599;&#20010;&#23376;&#38598;&#35757;&#32451;&#19968;&#20010;&#23616;&#37096;&#39044;&#27979;&#22120;&#12290;&#28982;&#21518;&#36825;&#20123;&#39044;&#27979;&#22120;&#20197;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24335;&#32452;&#21512;&#22312;&#19968;&#36215;&#65292;&#24418;&#25104;&#19968;&#20010;&#25972;&#20307;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#23558;&#27492;&#31639;&#27861;&#31216;&#20026;&#8220;&#23398;&#20064;&#19982;&#23376;&#38598;&#21472;&#21152;&#8221;&#25110;LESS&#65292;&#22240;&#20026;&#23427;&#31867;&#20284;&#20110;&#21472;&#21152;&#22238;&#24402;&#22120;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;LESS&#19982;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#36827;&#34892;&#27979;&#35797;&#24615;&#33021;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#27604;&#36739;&#32467;&#26524;&#34920;&#26126;&#65292;LESS&#26159;&#19968;&#31181;&#26377;&#31454;&#20105;&#21147;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;LESS&#22312;&#35745;&#31639;&#26102;&#38388;&#19978;&#20063;&#38750;&#24120;&#39640;&#25928;&#65292;&#24182;&#19988;&#21487;&#20197;&#30452;&#25509;&#36827;&#34892;&#24182;&#34892;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new regression algorithm that learns from a set of input-output pairs. Our algorithm is designed for populations where the relation between the input variables and the output variable exhibits a heterogeneous behavior across the predictor space. The algorithm starts with generating subsets that are concentrated around random points in the input space. This is followed by training a local predictor for each subset. Those predictors are then combined in a novel way to yield an overall predictor. We call this algorithm ``LEarning with Subset Stacking'' or LESS, due to its resemblance to the method of stacking regressors. We compare the testing performance of LESS with state-of-the-art methods on several datasets. Our comparison shows that LESS is a competitive supervised learning method. Moreover, we observe that LESS is also efficient in terms of computation time and it allows a straightforward parallel implementation.
&lt;/p&gt;</description></item></channel></rss>