<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#24341;&#20837;&#20102;&#20934;&#26102;&#21040;&#20301;&#65288;RioT&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#27169;&#22411;&#35299;&#37322;&#22312;&#26102;&#38388;&#21644;&#39057;&#29575;&#22495;&#20043;&#38388;&#20132;&#20114;&#65292;&#24182;&#21033;&#29992;&#21453;&#39304;&#26469;&#32422;&#26463;&#27169;&#22411;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#28151;&#26434;&#22240;&#32032;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.12921</link><description>&lt;p&gt;
&#20934;&#26102;&#21040;&#20301;&#65306;&#36890;&#36807;&#38480;&#21046;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#35299;&#37322;&#26469;&#20462;&#35746;&#23427;&#20204;
&lt;/p&gt;
&lt;p&gt;
Right on Time: Revising Time Series Models by Constraining their Explanations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12921
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#20934;&#26102;&#21040;&#20301;&#65288;RioT&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#27169;&#22411;&#35299;&#37322;&#22312;&#26102;&#38388;&#21644;&#39057;&#29575;&#22495;&#20043;&#38388;&#20132;&#20114;&#65292;&#24182;&#21033;&#29992;&#21453;&#39304;&#26469;&#32422;&#26463;&#27169;&#22411;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#28151;&#26434;&#22240;&#32032;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#32463;&#24120;&#20250;&#21463;&#21040;&#20854;&#20381;&#36182;&#28151;&#26434;&#22240;&#32032;&#30340;&#20542;&#21521;&#30340;&#25439;&#23475;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#35823;&#23548;&#24615;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#26032;&#35760;&#24405;&#30340;&#12289;&#33258;&#28982;&#28151;&#26434;&#30340;&#25968;&#25454;&#38598;P2S&#26469;&#33258;&#30495;&#23454;&#30340;&#26426;&#26800;&#29983;&#20135;&#32447;&#65292;&#24378;&#35843;&#20102;&#36825;&#19968;&#28857;&#12290;&#20026;&#20102;&#35299;&#20915;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#28151;&#26434;&#22240;&#32032;&#30340;&#25361;&#25112;&#24615;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20934;&#26102;&#21040;&#20301;&#65288;RioT&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#27169;&#22411;&#35299;&#37322;&#22312;&#26102;&#38388;&#21644;&#39057;&#29575;&#22495;&#20043;&#38388;&#36827;&#34892;&#20132;&#20114;&#12290;&#28982;&#21518;&#21033;&#29992;&#20004;&#20010;&#22495;&#20869;&#30340;&#35299;&#37322;&#21453;&#39304;&#26469;&#32422;&#26463;&#27169;&#22411;&#65292;&#20351;&#20854;&#36828;&#31163;&#26631;&#27880;&#30340;&#28151;&#26434;&#22240;&#32032;&#12290;&#22312;&#22788;&#29702;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#20013;&#28151;&#26434;&#22240;&#32032;&#26041;&#38754;&#65292;&#21452;&#22495;&#20132;&#20114;&#31574;&#30053;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#20973;&#32463;&#39564;&#35777;&#26126;&#65292;RioT&#33021;&#22815;&#26377;&#25928;&#22320;&#24341;&#23548;&#27169;&#22411;&#36828;&#31163;P2S&#20197;&#21450;&#27969;&#34892;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#39044;&#27979;&#25968;&#25454;&#38598;&#20013;&#30340;&#38169;&#35823;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12921v1 Announce Type: new  Abstract: The reliability of deep time series models is often compromised by their tendency to rely on confounding factors, which may lead to misleading results. Our newly recorded, naturally confounded dataset named P2S from a real mechanical production line emphasizes this. To tackle the challenging problem of mitigating confounders in time series data, we introduce Right on Time (RioT). Our method enables interactions with model explanations across both the time and frequency domain. Feedback on explanations in both domains is then used to constrain the model, steering it away from the annotated confounding factors. The dual-domain interaction strategy is crucial for effectively addressing confounders in time series datasets. We empirically demonstrate that RioT can effectively guide models away from the wrong reasons in P2S as well as popular time series classification and forecasting datasets.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#29615;&#22659;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06434</link><description>&lt;p&gt;
&#30495;&#30456;&#22312;&#21738;&#37324;&#65311;&#22312;&#36830;&#32493;&#30340;&#19990;&#30028;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Where is the Truth? The Risk of Getting Confounded in a Continual World
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06434
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#29615;&#22659;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#19968;&#20010;&#25968;&#25454;&#38598;&#36890;&#36807;&#19968;&#20010;&#34394;&#20551;&#30456;&#20851;&#24615;&#26469;&#35299;&#20915;&#65292;&#32780;&#36825;&#31181;&#30456;&#20851;&#24615;&#26080;&#27861;&#27867;&#21270;&#21040;&#26032;&#25968;&#25454;&#65292;&#35813;&#25968;&#25454;&#38598;&#23601;&#26159;&#28151;&#28102;&#30340;&#12290;&#25105;&#20204;&#23558;&#23637;&#31034;&#65292;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#30340;&#29615;&#22659;&#20013;&#65292;&#28151;&#28102;&#22240;&#32032;&#21487;&#33021;&#38543;&#30528;&#20219;&#21153;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#65292;&#23548;&#33268;&#30340;&#25361;&#25112;&#36828;&#36828;&#36229;&#36807;&#36890;&#24120;&#32771;&#34385;&#30340;&#36951;&#24536;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20174;&#25968;&#23398;&#19978;&#25512;&#23548;&#20102;&#36825;&#31181;&#28151;&#28102;&#22240;&#32032;&#23545;&#19968;&#32452;&#28151;&#28102;&#20219;&#21153;&#30340;&#26377;&#25928;&#32852;&#21512;&#35299;&#31354;&#38388;&#30340;&#24433;&#21709;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#39044;&#27979;&#65292;&#22312;&#35768;&#22810;&#36825;&#26679;&#30340;&#36830;&#32493;&#25968;&#25454;&#38598;&#20013;&#65292;&#24403;&#20219;&#21153;&#36827;&#34892;&#32852;&#21512;&#35757;&#32451;&#26102;&#65292;&#34394;&#20551;&#30456;&#20851;&#24615;&#24456;&#23481;&#26131;&#34987;&#24573;&#30053;&#65292;&#20294;&#26159;&#22312;&#39034;&#24207;&#32771;&#34385;&#20219;&#21153;&#26102;&#65292;&#36991;&#20813;&#28151;&#28102;&#35201;&#22256;&#38590;&#24471;&#22810;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#36825;&#26679;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#26631;&#20934;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#32780;&#21516;&#26102;&#23545;&#25152;&#26377;&#20219;&#21153;&#36827;&#34892;&#32852;&#21512;&#35757;&#32451;&#21017;&#26159;&#25104;&#21151;&#30340;&#12290;&#25105;&#20204;&#30340;&#36830;&#32493;&#28151;&#28102;&#25968;&#25454;&#38598;ConCon&#22522;&#20110;CLEVR&#22270;&#20687;&#65292;&#35777;&#26126;&#20102;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26469;&#22788;&#29702;&#28151;&#28102;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. We will show that, in a continual learning setting where confounders may vary in time across tasks, the resulting challenge far exceeds the standard forgetting problem normally considered. In particular, we derive mathematically the effect of such confounders on the space of valid joint solutions to sets of confounded tasks. Interestingly, our theory predicts that for many such continual datasets, spurious correlations are easily ignored when the tasks are trained on jointly, but it is far harder to avoid confounding when they are considered sequentially. We construct such a dataset and demonstrate empirically that standard continual learning methods fail to ignore confounders, while training jointly on all tasks is successful. Our continually confounded dataset, ConCon, is based on CLEVR images and demonstrates the need for continual learning methods with more robust b
&lt;/p&gt;</description></item><item><title>DiffTOP&#20351;&#29992;&#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#20316;&#20026;&#31574;&#30053;&#34920;&#31034;&#26469;&#29983;&#25104;&#21160;&#20316;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#8220;&#30446;&#26631;&#19981;&#21305;&#37197;&#8221;&#38382;&#39064;&#65292;&#24182;&#22312;&#27169;&#20223;&#23398;&#20064;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>https://arxiv.org/abs/2402.05421</link><description>&lt;p&gt;
DiffTOP: &#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#22312;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
DiffTOP: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05421
&lt;/p&gt;
&lt;p&gt;
DiffTOP&#20351;&#29992;&#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#20316;&#20026;&#31574;&#30053;&#34920;&#31034;&#26469;&#29983;&#25104;&#21160;&#20316;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#8220;&#30446;&#26631;&#19981;&#21305;&#37197;&#8221;&#38382;&#39064;&#65292;&#24182;&#22312;&#27169;&#20223;&#23398;&#20064;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;DiffTOP&#65292;&#23427;&#21033;&#29992;&#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#20316;&#20026;&#31574;&#30053;&#34920;&#31034;&#65292;&#20026;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#29983;&#25104;&#21160;&#20316;&#12290;&#36712;&#36857;&#20248;&#21270;&#26159;&#19968;&#31181;&#22312;&#25511;&#21046;&#39046;&#22495;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#65292;&#30001;&#25104;&#26412;&#21644;&#21160;&#21147;&#23398;&#20989;&#25968;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20851;&#38190;&#26159;&#21033;&#29992;&#20102;&#26368;&#36817;&#22312;&#21487;&#24494;&#20998;&#36712;&#36857;&#20248;&#21270;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#20351;&#24471;&#21487;&#20197;&#35745;&#31639;&#25439;&#22833;&#23545;&#20110;&#36712;&#36857;&#20248;&#21270;&#30340;&#21442;&#25968;&#30340;&#26799;&#24230;&#12290;&#22240;&#27492;&#65292;&#36712;&#36857;&#20248;&#21270;&#30340;&#25104;&#26412;&#21644;&#21160;&#21147;&#23398;&#20989;&#25968;&#21487;&#20197;&#31471;&#21040;&#31471;&#22320;&#23398;&#20064;&#12290;DiffTOP&#35299;&#20915;&#20102;&#20043;&#21069;&#27169;&#22411;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#8220;&#30446;&#26631;&#19981;&#21305;&#37197;&#8221;&#38382;&#39064;&#65292;&#22240;&#20026;DiffTOP&#20013;&#30340;&#21160;&#21147;&#23398;&#27169;&#22411;&#36890;&#36807;&#36712;&#36857;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#31574;&#30053;&#26799;&#24230;&#25439;&#22833;&#30452;&#25509;&#26368;&#22823;&#21270;&#20219;&#21153;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23545;DiffTOP&#22312;&#26631;&#20934;&#26426;&#22120;&#20154;&#25805;&#32437;&#20219;&#21153;&#22871;&#20214;&#20013;&#36827;&#34892;&#20102;&#27169;&#20223;&#23398;&#20064;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces DiffTOP, which utilizes Differentiable Trajectory OPtimization as the policy representation to generate actions for deep reinforcement and imitation learning. Trajectory optimization is a powerful and widely used algorithm in control, parameterized by a cost and a dynamics function. The key to our approach is to leverage the recent progress in differentiable trajectory optimization, which enables computing the gradients of the loss with respect to the parameters of trajectory optimization. As a result, the cost and dynamics functions of trajectory optimization can be learned end-to-end. DiffTOP addresses the ``objective mismatch'' issue of prior model-based RL algorithms, as the dynamics model in DiffTOP is learned to directly maximize task performance by differentiating the policy gradient loss through the trajectory optimization process. We further benchmark DiffTOP for imitation learning on standard robotic manipulation task suites with high-dimensional sensory
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36827;&#21270;&#24341;&#23548;&#30340;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;EGFN&#65289;&#65292;&#29992;&#20110;&#22788;&#29702;&#38271;&#26102;&#38388;&#36328;&#24230;&#21644;&#31232;&#30095;&#22870;&#21169;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#20351;&#29992;&#36827;&#21270;&#31639;&#27861;&#35757;&#32451;&#19968;&#32452;&#20195;&#29702;&#21442;&#25968;&#65292;&#24182;&#23558;&#32467;&#26524;&#36712;&#36857;&#23384;&#20648;&#22312;&#20248;&#20808;&#22238;&#25918;&#32531;&#20914;&#21306;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;GFlowNets&#20195;&#29702;&#26102;&#23637;&#29616;&#20986;&#20102;&#24456;&#39640;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.02186</link><description>&lt;p&gt;
&#36827;&#21270;&#24341;&#23548;&#30340;&#29983;&#25104;&#27969;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Evolution Guided Generative Flow Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36827;&#21270;&#24341;&#23548;&#30340;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;EGFN&#65289;&#65292;&#29992;&#20110;&#22788;&#29702;&#38271;&#26102;&#38388;&#36328;&#24230;&#21644;&#31232;&#30095;&#22870;&#21169;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#20351;&#29992;&#36827;&#21270;&#31639;&#27861;&#35757;&#32451;&#19968;&#32452;&#20195;&#29702;&#21442;&#25968;&#65292;&#24182;&#23558;&#32467;&#26524;&#36712;&#36857;&#23384;&#20648;&#22312;&#20248;&#20808;&#22238;&#25918;&#32531;&#20914;&#21306;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;GFlowNets&#20195;&#29702;&#26102;&#23637;&#29616;&#20986;&#20102;&#24456;&#39640;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#26159;&#19968;&#31867;&#27010;&#29575;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#23398;&#20064;&#25353;&#29031;&#22870;&#21169;&#27604;&#20363;&#23545;&#32452;&#21512;&#23545;&#35937;&#36827;&#34892;&#37319;&#26679;&#12290;GFlowNets&#30340;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#26159;&#22312;&#22788;&#29702;&#38271;&#26102;&#38388;&#36328;&#24230;&#21644;&#31232;&#30095;&#22870;&#21169;&#26102;&#26377;&#25928;&#35757;&#32451;&#23427;&#20204;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36827;&#21270;&#24341;&#23548;&#30340;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;EGFN&#65289;&#65292;&#36825;&#26159;&#23545;GFlowNets&#35757;&#32451;&#30340;&#19968;&#31181;&#31616;&#21333;&#20294;&#24378;&#22823;&#30340;&#22686;&#24378;&#26041;&#27861;&#65292;&#20351;&#29992;&#36827;&#21270;&#31639;&#27861;&#65288;EA&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#20219;&#20309;GFlowNets&#35757;&#32451;&#30446;&#26631;&#30340;&#22522;&#30784;&#19978;&#24037;&#20316;&#65292;&#36890;&#36807;&#20351;&#29992;EA&#35757;&#32451;&#19968;&#32452;&#20195;&#29702;&#21442;&#25968;&#65292;&#23558;&#32467;&#26524;&#36712;&#36857;&#23384;&#20648;&#22312;&#20248;&#20808;&#22238;&#25918;&#32531;&#20914;&#21306;&#20013;&#65292;&#24182;&#20351;&#29992;&#23384;&#20648;&#30340;&#36712;&#36857;&#35757;&#32451;GFlowNets&#20195;&#29702;&#12290;&#25105;&#20204;&#22312;&#24191;&#27867;&#30340;&#29609;&#20855;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#22788;&#29702;&#38271;&#36712;&#36857;&#21644;&#31232;&#30095;&#22870;&#21169;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets) are a family of probabilistic generative models that learn to sample compositional objects proportional to their rewards. One big challenge of GFlowNets is training them effectively when dealing with long time horizons and sparse rewards. To address this, we propose Evolution guided generative flow networks (EGFN), a simple but powerful augmentation to the GFlowNets training using Evolutionary algorithms (EA). Our method can work on top of any GFlowNets training objective, by training a set of agent parameters using EA, storing the resulting trajectories in the prioritized replay buffer, and training the GFlowNets agent using the stored trajectories. We present a thorough investigation over a wide range of toy and real-world benchmark tasks showing the effectiveness of our method in handling long trajectories and sparse rewards.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#19979;&#30340;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20173;&#28982;&#21463;&#30410;&#12290;</title><link>https://arxiv.org/abs/2311.17539</link><description>&lt;p&gt;
&#22312;&#36807;&#21442;&#25968;&#21270;&#19979;&#20998;&#26512;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Analyzing Sharpness-aware Minimization under Overparameterization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#19979;&#30340;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20173;&#28982;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#23613;&#31649;&#35757;&#32451;&#25439;&#22833;&#30456;&#21516;&#65292;&#20294;&#21487;&#20197;&#24471;&#21040;&#20855;&#26377;&#19981;&#21516;&#27867;&#21270;&#33021;&#21147;&#30340;&#26497;&#23567;&#20540;&#12290;&#26377;&#35777;&#25454;&#34920;&#26126;&#65292;&#26497;&#23567;&#20540;&#30340;&#38160;&#24230;&#19982;&#20854;&#27867;&#21270;&#35823;&#24046;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#22240;&#27492;&#24050;&#32463;&#20570;&#20986;&#20102;&#26356;&#22810;&#21162;&#21147;&#24320;&#21457;&#19968;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#20197;&#26174;&#24335;&#22320;&#25214;&#21040;&#25153;&#24179;&#26497;&#23567;&#20540;&#20316;&#20026;&#26356;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#30340;&#35299;&#12290;&#28982;&#32780;&#65292;&#33267;&#20170;&#20026;&#27490;&#65292;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#31574;&#30053;&#30340;&#24433;&#21709;&#30340;&#30740;&#31350;&#36824;&#19981;&#22810;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#19981;&#21516;&#31243;&#24230;&#30340;&#36807;&#21442;&#25968;&#21270;&#19979;&#30340;SAM&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#34920;&#26126;&#36807;&#21442;&#25968;&#21270;&#23545;SAM&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#28085;&#30422;&#20102;&#21508;&#20010;&#39046;&#22495;&#65292;&#24182;&#34920;&#26126;&#23384;&#22312;&#19968;&#31181;&#19968;&#33268;&#30340;&#36235;&#21183;&#65292;&#21363;SAM&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#21463;&#30410;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#19968;&#20123;&#20196;&#20154;&#20449;&#26381;&#30340;&#26696;&#20363;&#65292;&#35828;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training an overparameterized neural network can yield minimizers of different generalization capabilities despite the same level of training loss. With evidence that suggests a correlation between sharpness of minima and their generalization errors, increasing efforts have been made to develop an optimization method to explicitly find flat minima as more generalizable solutions. However, this sharpness-aware minimization (SAM) strategy has not been studied much yet as to whether and how it is affected by overparameterization.   In this work, we analyze SAM under overparameterization of varying degrees and present both empirical and theoretical results that indicate a critical influence of overparameterization on SAM. Specifically, we conduct extensive numerical experiments across various domains, and show that there exists a consistent trend that SAM continues to benefit from increasing overparameterization. We also discover compelling cases where the effect of overparameterization is
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#28608;&#27963;&#26368;&#22823;&#21270;&#26041;&#27861;&#22312;&#23545;&#25239;&#27169;&#22411;&#25805;&#20316;&#20013;&#30340;&#33030;&#24369;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#25805;&#32437;&#29305;&#24449;&#21487;&#35270;&#21270;&#65292;&#20197;&#38544;&#34255;&#29305;&#23450;&#31070;&#32463;&#20803;&#30340;&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.06122</link><description>&lt;p&gt;
&#29992;&#26799;&#24230;&#24377;&#23556;&#25805;&#32437;&#29305;&#24449;&#21487;&#35270;&#21270;
&lt;/p&gt;
&lt;p&gt;
Manipulating Feature Visualizations with Gradient Slingshots. (arXiv:2401.06122v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#28608;&#27963;&#26368;&#22823;&#21270;&#26041;&#27861;&#22312;&#23545;&#25239;&#27169;&#22411;&#25805;&#20316;&#20013;&#30340;&#33030;&#24369;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#25805;&#32437;&#29305;&#24449;&#21487;&#35270;&#21270;&#65292;&#20197;&#38544;&#34255;&#29305;&#23450;&#31070;&#32463;&#20803;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#33021;&#22815;&#23398;&#20064;&#22797;&#26434;&#32780;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#65292;&#28982;&#32780;&#65292;&#23398;&#20064;&#21040;&#30340;&#27010;&#24565;&#30340;&#35821;&#20041;&#24615;&#36136;&#20173;&#28982;&#26410;&#30693;&#12290;&#35299;&#37322;DNNs&#23398;&#20064;&#21040;&#30340;&#27010;&#24565;&#30340;&#24120;&#29992;&#26041;&#27861;&#26159;&#28608;&#27963;&#26368;&#22823;&#21270;(AM)&#65292;&#23427;&#29983;&#25104;&#19968;&#20010;&#21512;&#25104;&#30340;&#36755;&#20837;&#20449;&#21495;&#65292;&#26368;&#22823;&#21270;&#28608;&#27963;&#32593;&#32476;&#20013;&#30340;&#29305;&#23450;&#31070;&#32463;&#20803;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#23545;&#25239;&#27169;&#22411;&#25805;&#20316;&#30340;&#33030;&#24369;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#25805;&#32437;&#29305;&#24449;&#21487;&#35270;&#21270;&#65292;&#32780;&#19981;&#25913;&#21464;&#27169;&#22411;&#32467;&#26500;&#25110;&#23545;&#27169;&#22411;&#30340;&#20915;&#31574;&#36807;&#31243;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20960;&#20010;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#25928;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#38544;&#34255;&#29305;&#23450;&#31070;&#32463;&#20803;&#21151;&#33021;&#30340;&#33021;&#21147;&#65292;&#22312;&#27169;&#22411;&#23457;&#26680;&#36807;&#31243;&#20013;&#20351;&#29992;&#36873;&#25321;&#30340;&#30446;&#26631;&#35299;&#37322;&#23631;&#34109;&#20102;&#21407;&#22987;&#35299;&#37322;&#12290;&#20316;&#20026;&#19968;&#31181;&#34917;&#25937;&#25514;&#26045;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38450;&#27490;&#36825;&#31181;&#25805;&#32437;&#30340;&#38450;&#25252;&#25514;&#26045;&#65292;&#24182;&#25552;&#20379;&#20102;&#23450;&#37327;&#35777;&#25454;&#65292;&#35777;&#26126;&#20102;&#23427;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks (DNNs) are capable of learning complex and versatile representations, however, the semantic nature of the learned concepts remains unknown. A common method used to explain the concepts learned by DNNs is Activation Maximization (AM), which generates a synthetic input signal that maximally activates a particular neuron in the network. In this paper, we investigate the vulnerability of this approach to adversarial model manipulations and introduce a novel method for manipulating feature visualization without altering the model architecture or significantly impacting the model's decision-making process. We evaluate the effectiveness of our method on several neural network models and demonstrate its capabilities to hide the functionality of specific neurons by masking the original explanations of neurons with chosen target explanations during model auditing. As a remedy, we propose a protective measure against such manipulations and provide quantitative evidence which 
&lt;/p&gt;</description></item><item><title>&#29992;&#26426;&#22120;&#23398;&#20064;&#21457;&#29616;&#24102;&#29366;&#29289;&#65292;&#21453;&#39539;&#22235;&#32500;&#24179;&#20961; Poincar&#233; &#29468;&#24819;&#12290;</title><link>http://arxiv.org/abs/2304.09304</link><description>&lt;p&gt;
&#29992;&#26426;&#22120;&#23398;&#20064;&#25628;&#32034;&#24102;&#29366;&#29289;
&lt;/p&gt;
&lt;p&gt;
Searching for ribbons with machine learning. (arXiv:2304.09304v1 [math.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09304
&lt;/p&gt;
&lt;p&gt;
&#29992;&#26426;&#22120;&#23398;&#20064;&#21457;&#29616;&#24102;&#29366;&#29289;&#65292;&#21453;&#39539;&#22235;&#32500;&#24179;&#20961; Poincar&#233; &#29468;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20110;&#25299;&#25169;&#23398;&#20013;&#30340;&#19968;&#20010;&#38382;&#39064;&#65306;&#22914;&#20309;&#30830;&#23450;&#19968;&#20010;&#32467;&#19981;&#33021;&#38480;&#23450;&#19968;&#20010;&#24102;&#29366;&#29289;&#12290;&#35813;&#38382;&#39064;&#22312;&#21453;&#39539;&#22235;&#32500;&#24179;&#20961; Poincar&#233; &#29468;&#24819;&#30340;&#26041;&#27861;&#20013;&#26159;&#30456;&#20851;&#30340;&#65307;&#21033;&#29992;&#25105;&#20204;&#30340;&#31243;&#24207;&#65292;&#25105;&#20204;&#25490;&#38500;&#20102;&#35768;&#22810;&#29468;&#24819;&#30340;&#21453;&#20363;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36825;&#20123;&#31243;&#24207;&#25104;&#21151;&#26816;&#27979;&#20102;&#33539;&#22260;&#22312;70&#33410;&#28857;&#20869;&#30340;&#35768;&#22810;&#24102;&#29366;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We apply Bayesian optimization and reinforcement learning to a problem in topology: the question of when a knot bounds a ribbon disk. This question is relevant in an approach to disproving the four-dimensional smooth Poincar\'e conjecture; using our programs, we rule out many potential counterexamples to the conjecture. We also show that the programs are successful in detecting many ribbon knots in the range of up to 70 crossings.
&lt;/p&gt;</description></item></channel></rss>