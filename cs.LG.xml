<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#20998;&#26512;&#20102;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#21508;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#38899;&#27169;&#22411;&#20013;&#30340;&#26032;&#39062;&#29616;&#35937;&#65292;&#24182;&#23637;&#31034;&#20102;&#29305;&#24449;&#20132;&#20114;&#22914;&#20309;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.13106</link><description>&lt;p&gt;
&#35748;&#35782;&#20320;&#30340;&#38750;&#32447;&#24615;&#65306;Shapley&#20114;&#21160;&#25581;&#31034;&#25968;&#25454;&#30340;&#28508;&#22312;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Knowing Your Nonlinearities: Shapley Interactions Reveal the Underlying Structure of Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#20998;&#26512;&#20102;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#21508;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#38899;&#27169;&#22411;&#20013;&#30340;&#26032;&#39062;&#29616;&#35937;&#65292;&#24182;&#23637;&#31034;&#20102;&#29305;&#24449;&#20132;&#20114;&#22914;&#20309;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#37327;&#38750;&#32447;&#24615;&#29305;&#24449;&#20132;&#20114;&#26159;&#29702;&#35299;&#35768;&#22810;&#27169;&#22411;&#20013;&#22797;&#26434;&#24402;&#22240;&#27169;&#24335;&#30340;&#19968;&#31181;&#24050;&#24314;&#31435;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#26469;&#20998;&#26512;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#22810;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#12290;&#22312;&#32771;&#34385;&#25513;&#30721;&#21644;&#33258;&#22238;&#24402;&#35821;&#35328;&#27169;&#22411;&#65288;MLMs&#21644;ALMs&#65289;&#20013;&#30340;&#35821;&#35328;&#32467;&#26500;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;STII&#22312;&#24815;&#29992;&#34920;&#36798;&#20013;&#22686;&#21152;&#65292;MLMs&#38543;&#21477;&#27861;&#36317;&#31163;&#25193;&#23637;STII&#65292;&#26356;&#22810;&#22320;&#20381;&#36182;&#35821;&#27861;&#22312;&#20854;&#38750;&#32447;&#24615;&#32467;&#26500;&#20013;&#30456;&#27604;ALMs&#12290;&#25105;&#20204;&#30340;&#35821;&#38899;&#27169;&#22411;&#30740;&#31350;&#21453;&#26144;&#20102;&#21475;&#33108;&#24352;&#24320;&#31243;&#24230;&#20915;&#23450;&#38899;&#32032;&#26681;&#25454;&#19978;&#19979;&#25991;&#21464;&#21270;&#30340;&#25968;&#37327;&#30340;&#21407;&#21017;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#22270;&#20687;&#20998;&#31867;&#22120;&#24182;&#35828;&#26126;&#29305;&#24449;&#20132;&#20114;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#36328;&#23398;&#31185;&#24037;&#20316;&#21644;&#39046;&#22495;&#20043;&#38388;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13106v1 Announce Type: cross  Abstract: Measuring nonlinear feature interaction is an established approach to understanding complex patterns of attribution in many models. In this paper, we use Shapley Taylor interaction indices (STII) to analyze the impact of underlying data structure on model representations in a variety of modalities, tasks, and architectures. Considering linguistic structure in masked and auto-regressive language models (MLMs and ALMs), we find that STII increases within idiomatic expressions and that MLMs scale STII with syntactic distance, relying more on syntax in their nonlinear structure than ALMs do. Our speech model findings reflect the phonetic principal that the openness of the oral cavity determines how much a phoneme varies based on its context. Finally, we study image classifiers and illustrate that feature interactions intuitively reflect object boundaries. Our wide range of results illustrates the benefits of interdisciplinary work and doma
&lt;/p&gt;</description></item><item><title>&#27604;&#36739;&#20256;&#32479;EEG&#19982;&#19977;&#26497;EEG&#22312;&#39640;&#24615;&#33021;&#21040;&#39076;&#25235;&#25569;BCI&#31995;&#32479;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#20449;&#22122;&#27604;&#12289;&#31354;&#38388;&#20998;&#36776;&#29575;&#12289;ERPs&#21644;&#23567;&#27874;&#26102;&#39057;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.09448</link><description>&lt;p&gt;
&#26222;&#36890;EEG&#19982;&#19977;&#26497;EEG&#22312;&#39640;&#24615;&#33021;&#21040;&#39076;&#25235;&#25569;BCI&#31995;&#32479;&#20013;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comparative Study of Conventional and Tripolar EEG for High-Performance Reach-to-Grasp BCI Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09448
&lt;/p&gt;
&lt;p&gt;
&#27604;&#36739;&#20256;&#32479;EEG&#19982;&#19977;&#26497;EEG&#22312;&#39640;&#24615;&#33021;&#21040;&#39076;&#25235;&#25569;BCI&#31995;&#32479;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#20449;&#22122;&#27604;&#12289;&#31354;&#38388;&#20998;&#36776;&#29575;&#12289;ERPs&#21644;&#23567;&#27874;&#26102;&#39057;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#27604;&#36739;&#20256;&#32479;EEG&#19982;&#19977;&#26497;EEG&#22312;&#25552;&#21319;&#36816;&#21160;&#38556;&#30861;&#20010;&#20307;&#30340;BCI&#24212;&#29992;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#37325;&#28857;&#26159;&#35299;&#35835;&#21644;&#35299;&#30721;&#21508;&#31181;&#25235;&#25569;&#21160;&#20316;&#65292;&#22914;&#21147;&#25569;&#21644;&#31934;&#30830;&#25569;&#25345;&#12290;&#30446;&#26631;&#26159;&#30830;&#23450;&#21738;&#31181;EEG&#25216;&#26415;&#22312;&#22788;&#29702;&#21644;&#32763;&#35793;&#19982;&#25235;&#25569;&#30456;&#20851;&#30340;&#33041;&#30005;&#20449;&#21495;&#26041;&#38754;&#26356;&#20026;&#26377;&#25928;&#12290;&#30740;&#31350;&#28041;&#21450;&#23545;&#21313;&#21517;&#20581;&#24247;&#21442;&#19982;&#32773;&#36827;&#34892;&#23454;&#39564;&#65292;&#21442;&#19982;&#32773;&#36827;&#34892;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#25569;&#25345;&#36816;&#21160;&#65306;&#21147;&#25569;&#21644;&#31934;&#30830;&#25569;&#25345;&#65292;&#26080;&#36816;&#21160;&#26465;&#20214;&#20316;&#20026;&#22522;&#32447;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#22312;&#35299;&#30721;&#25235;&#25569;&#21160;&#20316;&#26041;&#38754;&#23545;EEG&#21644;&#19977;&#26497;EEG&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#12290;&#35813;&#27604;&#36739;&#28085;&#30422;&#20102;&#20960;&#20010;&#20851;&#38190;&#21442;&#25968;&#65292;&#21253;&#25324;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#12289;&#36890;&#36807;&#21151;&#33021;&#36830;&#25509;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12289;ERPs&#21644;&#23567;&#27874;&#26102;&#39057;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#36824;&#28041;&#21450;&#20174;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09448v1 Announce Type: cross  Abstract: This study aims to enhance BCI applications for individuals with motor impairments by comparing the effectiveness of tripolar EEG (tEEG) with conventional EEG. The focus is on interpreting and decoding various grasping movements, such as power grasp and precision grasp. The goal is to determine which EEG technology is more effective in processing and translating grasp related neural signals. The approach involved experimenting on ten healthy participants who performed two distinct grasp movements: power grasp and precision grasp, with a no movement condition serving as the baseline. Our research presents a thorough comparison between EEG and tEEG in decoding grasping movements. This comparison spans several key parameters, including signal to noise ratio (SNR), spatial resolution via functional connectivity, ERPs, and wavelet time frequency analysis. Additionally, our study involved extracting and analyzing statistical features from th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#26410;&#21457;&#24067;&#30740;&#31350;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#30001;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#26500;&#24314;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#32467;&#21512;&#35770;&#25991;&#20869;&#23481;&#21644;&#21382;&#21490;&#24341;&#29992;&#30340;&#20449;&#24687;&#65292;&#39640;&#20934;&#30830;&#24230;&#39044;&#27979;&#26410;&#26469;&#30340;&#28436;&#21270;&#32593;&#32476;&#21160;&#24577;&#21644;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.08640</link><description>&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22312;&#19981;&#26029;&#28436;&#21270;&#30340;&#30693;&#35782;&#22270;&#35889;&#19978;&#39044;&#27979;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#20027;&#39064;
&lt;/p&gt;
&lt;p&gt;
Forecasting high-impact research topics via machine learning on evolving knowledge graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08640
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#26410;&#21457;&#24067;&#30740;&#31350;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#30001;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#26500;&#24314;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#32467;&#21512;&#35770;&#25991;&#20869;&#23481;&#21644;&#21382;&#21490;&#24341;&#29992;&#30340;&#20449;&#24687;&#65292;&#39640;&#20934;&#30830;&#24230;&#39044;&#27979;&#26410;&#26469;&#30340;&#28436;&#21270;&#32593;&#32476;&#21160;&#24577;&#21644;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#20986;&#29256;&#29289;&#30340;&#25351;&#25968;&#22686;&#38271;&#23545;&#20154;&#31867;&#30740;&#31350;&#32773;&#26500;&#25104;&#20102;&#20005;&#23803;&#25361;&#25112;&#12290;&#23427;&#36843;&#20351;&#30740;&#31350;&#32773;&#23558;&#27880;&#24847;&#21147;&#38598;&#20013;&#22312;&#26356;&#29421;&#31364;&#30340;&#23376;&#39046;&#22495;&#19978;&#65292;&#20351;&#24471;&#21457;&#29616;&#20854;&#20182;&#39046;&#22495;&#30340;&#26032;&#39062;&#19988;&#26377;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#24819;&#27861;&#21644;&#21512;&#20316;&#21464;&#24471;&#22256;&#38590;&#12290;&#34429;&#28982;&#26377;&#21150;&#27861;&#39044;&#27979;&#31185;&#23398;&#35770;&#25991;&#26410;&#26469;&#30340;&#24341;&#29992;&#27425;&#25968;&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#31561;&#21040;&#30740;&#31350;&#23436;&#25104;&#24182;&#19988;&#35770;&#25991;&#20889;&#25104;&#21518;&#25165;&#33021;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#26679;&#23601;&#38169;&#36807;&#20102;&#24819;&#27861;&#26500;&#24605;&#30340;&#26089;&#26399;&#38454;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#39044;&#27979;&#20174;&#26410;&#34987;&#30740;&#31350;&#32773;&#21457;&#24067;&#30340;&#24819;&#27861;&#30340;&#24433;&#21709;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#28436;&#21270;&#30693;&#35782;&#22270;&#35889;&#65292;&#20854;&#20013;&#21253;&#21547;&#36229;&#36807;2100&#19975;&#31687;&#31185;&#23398;&#35770;&#25991;&#12290;&#23427;&#32467;&#21512;&#20102;&#20174;&#35770;&#25991;&#20869;&#23481;&#20013;&#21019;&#24314;&#30340;&#35821;&#20041;&#32593;&#32476;&#21644;&#20174;&#21382;&#21490;&#24341;&#29992;&#20013;&#21019;&#24314;&#30340;&#24433;&#21709;&#32593;&#32476;&#12290;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#65292;&#25105;&#20204;&#21487;&#20197;&#39640;&#20934;&#30830;&#24230;&#22320;&#39044;&#27979;&#28436;&#21270;&#32593;&#32476;&#30340;&#21160;&#24577;&#24773;&#20917;&#65292;&#20174;&#32780;&#39044;&#27979;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#30340;&#24433;&#21709;&#21147;&#12290;&#25105;&#20204;&#39044;&#26399;&#36825;&#31181;&#33021;&#21147;&#23558;&#26377;&#21161;&#20110;&#30740;&#31350;&#32773;&#21457;&#29616;&#20855;&#26377;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21363;&#25554;&#21363;&#29992;&#22270;&#20687;&#24674;&#22797;&#26694;&#26550;&#65292;&#31216;&#20026;&#38543;&#26426;&#21435;&#22122;&#27491;&#21017;&#21270;&#65288;SNORE&#65289;&#12290;&#35813;&#26694;&#26550;&#22312;&#24688;&#24403;&#22122;&#22768;&#27700;&#24179;&#30340;&#22270;&#20687;&#19978;&#24212;&#29992;&#21435;&#22122;&#22120;&#65292;&#24182;&#22522;&#20110;&#38543;&#26426;&#27491;&#21017;&#21270;&#25552;&#20379;&#20102;&#35299;&#20915;&#30149;&#24577;&#36870;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SNORE&#22312;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.01779</link><description>&lt;p&gt;
&#24102;&#26377;&#38543;&#26426;&#21435;&#22122;&#27491;&#21017;&#21270;&#30340;&#21363;&#25554;&#21363;&#29992;&#22270;&#20687;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play image restoration with Stochastic deNOising REgularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21363;&#25554;&#21363;&#29992;&#22270;&#20687;&#24674;&#22797;&#26694;&#26550;&#65292;&#31216;&#20026;&#38543;&#26426;&#21435;&#22122;&#27491;&#21017;&#21270;&#65288;SNORE&#65289;&#12290;&#35813;&#26694;&#26550;&#22312;&#24688;&#24403;&#22122;&#22768;&#27700;&#24179;&#30340;&#22270;&#20687;&#19978;&#24212;&#29992;&#21435;&#22122;&#22120;&#65292;&#24182;&#22522;&#20110;&#38543;&#26426;&#27491;&#21017;&#21270;&#25552;&#20379;&#20102;&#35299;&#20915;&#30149;&#24577;&#36870;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SNORE&#22312;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21363;&#25554;&#21363;&#29992;&#65288;PnP&#65289;&#31639;&#27861;&#26159;&#19968;&#31867;&#36845;&#20195;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#29289;&#29702;&#27169;&#22411;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27491;&#21017;&#21270;&#26469;&#35299;&#20915;&#22270;&#20687;&#21453;&#28436;&#38382;&#39064;&#12290;&#23613;&#31649;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#20135;&#29983;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#22270;&#20687;&#24674;&#22797;&#32467;&#26524;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#22312;&#36845;&#20195;&#36807;&#31243;&#20013;&#36234;&#26469;&#36234;&#23569;&#22122;&#38899;&#30340;&#22270;&#20687;&#19978;&#30340;&#19968;&#31181;&#38750;&#26631;&#20934;&#30340;&#21435;&#22122;&#22120;&#20351;&#29992;&#26041;&#27861;&#65292;&#36825;&#19982;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#65288;DM&#65289;&#30340;&#26368;&#26032;&#31639;&#27861;&#30456;&#30683;&#30462;&#65292;&#22312;&#36825;&#20123;&#31639;&#27861;&#20013;&#65292;&#21435;&#22122;&#22120;&#20165;&#24212;&#29992;&#20110;&#37325;&#26032;&#21152;&#22122;&#30340;&#22270;&#20687;&#19978;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PnP&#26694;&#26550;&#65292;&#31216;&#20026;&#38543;&#26426;&#21435;&#22122;&#27491;&#21017;&#21270;&#65288;SNORE&#65289;&#65292;&#23427;&#20165;&#22312;&#22122;&#22768;&#27700;&#24179;&#36866;&#24403;&#30340;&#22270;&#20687;&#19978;&#24212;&#29992;&#21435;&#22122;&#22120;&#12290;&#23427;&#22522;&#20110;&#26174;&#24335;&#30340;&#38543;&#26426;&#27491;&#21017;&#21270;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#19968;&#31181;&#35299;&#20915;&#30149;&#24577;&#36870;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#31639;&#27861;&#21450;&#20854;&#36864;&#28779;&#25193;&#23637;&#30340;&#25910;&#25947;&#20998;&#26512;&#12290;&#22312;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;SNORE&#22312;&#21435;&#27169;&#31946;&#21644;&#20462;&#22797;&#20219;&#21153;&#19978;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play (PnP) algorithms are a class of iterative algorithms that address image inverse problems by combining a physical model and a deep neural network for regularization. Even if they produce impressive image restoration results, these algorithms rely on a non-standard use of a denoiser on images that are less and less noisy along the iterations, which contrasts with recent algorithms based on Diffusion Models (DM), where the denoiser is applied only on re-noised images. We propose a new PnP framework, called Stochastic deNOising REgularization (SNORE), which applies the denoiser only on images with noise of the adequate level. It is based on an explicit stochastic regularization, which leads to a stochastic gradient descent algorithm to solve ill-posed inverse problems. A convergence analysis of this algorithm and its annealing extension is provided. Experimentally, we prove that SNORE is competitive with respect to state-of-the-art methods on deblurring and inpainting tasks, 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23558;&#19968;&#38454;&#36923;&#36753;&#19982;&#35745;&#25968;&#31526;&#21495;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#22312;&#22810;&#23545;&#25968;&#24230;&#32467;&#26500;&#19979;&#20197;&#27425;&#32447;&#24615;&#26102;&#38388;&#19968;&#33268;&#23398;&#20064;&#21487;&#23450;&#20041;&#30340;&#20998;&#31867;&#22120;&#65292;&#20026;&#21253;&#21547;&#25968;&#20540;&#26041;&#38754;&#30340;&#26426;&#22120;&#23398;&#20064;&#25193;&#23637;&#23398;&#20064;&#26694;&#26550;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;</title><link>https://arxiv.org/abs/1909.03820</link><description>&lt;p&gt;
&#29992;&#35745;&#25968;&#31526;&#21495;&#30340;&#19968;&#38454;&#36923;&#36753;&#23450;&#20041;&#30340;&#27010;&#24565;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning Concepts Definable in First-Order Logic with Counting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1909.03820
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23558;&#19968;&#38454;&#36923;&#36753;&#19982;&#35745;&#25968;&#31526;&#21495;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#22312;&#22810;&#23545;&#25968;&#24230;&#32467;&#26500;&#19979;&#20197;&#27425;&#32447;&#24615;&#26102;&#38388;&#19968;&#33268;&#23398;&#20064;&#21487;&#23450;&#20041;&#30340;&#20998;&#31867;&#22120;&#65292;&#20026;&#21253;&#21547;&#25968;&#20540;&#26041;&#38754;&#30340;&#26426;&#22120;&#23398;&#20064;&#25193;&#23637;&#23398;&#20064;&#26694;&#26550;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Grohe&#21644;Tur\'an&#24341;&#20837;&#30340;&#36923;&#36753;&#26694;&#26550;&#19979;&#30340;&#20851;&#31995;&#32972;&#26223;&#32467;&#26500;&#19978;&#30340;&#24067;&#23572;&#20998;&#31867;&#38382;&#39064;&#12290;&#20247;&#25152;&#21608;&#30693;(Grohe&#21644;Ritzert, LICS 2017)&#65292;&#22312;&#22810;&#23545;&#25968;&#24230;&#32467;&#26500;&#19978;&#30340;&#19968;&#38454;&#36923;&#36753;&#21487;&#23450;&#20041;&#30340;&#20998;&#31867;&#22120;&#21487;&#20197;&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#23398;&#20064;&#65292;&#20854;&#20013;&#32467;&#26500;&#30340;&#24230;&#21644;&#36816;&#34892;&#26102;&#38388;&#26159;&#20197;&#32467;&#26500;&#30340;&#22823;&#23567;&#20026;&#21333;&#20301;&#26469;&#34913;&#37327;&#30340;&#12290;&#25105;&#20204;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#30001;Kuske&#21644;Schweikardt(LICS 2017)&#24341;&#20837;&#30340;&#24102;&#35745;&#25968;&#30340;&#19968;&#38454;&#36923;&#36753;FOCN&#65292;&#23427;&#20316;&#20026;&#19968;&#20010;&#24191;&#27867;&#25512;&#24191;&#21508;&#31181;&#35745;&#25968;&#36923;&#36753;&#30340;&#34920;&#29616;&#36923;&#36753;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#22312;&#22810;&#23545;&#25968;&#24230;&#32467;&#26500;&#31867;&#19978;&#23450;&#20041;&#30340;FOCN&#20013;&#30340;&#20998;&#31867;&#22120;&#21487;&#20197;&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#19968;&#33268;&#22320;&#23398;&#20064;&#12290;&#36825;&#21487;&#20197;&#30475;&#20316;&#26159;&#23558;&#23398;&#20064;&#26694;&#26550;&#25193;&#23637;&#20197;&#21253;&#21547;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#20540;&#26041;&#38754;&#30340;&#31532;&#19968;&#27493;&#12290;&#25105;&#20204;&#23558;&#36825;&#19968;&#32467;&#26524;&#25193;&#23637;&#21040;&#20102;&#26080;&#35270;&#30340;&#27010;&#29575;
&lt;/p&gt;
&lt;p&gt;
arXiv:1909.03820v2 Announce Type: replace-cross  Abstract: We study Boolean classification problems over relational background structures in the logical framework introduced by Grohe and Tur\'an (TOCS 2004). It is known (Grohe and Ritzert, LICS 2017) that classifiers definable in first-order logic over structures of polylogarithmic degree can be learned in sublinear time, where the degree of the structure and the running time are measured in terms of the size of the structure. We generalise the results to the first-order logic with counting FOCN, which was introduced by Kuske and Schweikardt (LICS 2017) as an expressive logic generalising various other counting logics. Specifically, we prove that classifiers definable in FOCN over classes of structures of polylogarithmic degree can be consistently learned in sublinear time. This can be seen as a first step towards extending the learning framework to include numerical aspects of machine learning. We extend the result to agnostic probabl
&lt;/p&gt;</description></item><item><title>&#30001;&#20110;&#29992;&#25143;&#38656;&#27714;&#21644;&#26368;&#36817;&#30340;&#27861;&#35268;&#35201;&#27714;&#65292;&#38656;&#35201;&#23545;AI&#31995;&#32479;&#25152;&#20570;&#20986;&#30340;&#20915;&#31574;&#36827;&#34892;&#35299;&#37322;&#12290;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Sum-Product Networks&#27169;&#25311;&#23547;&#25214;&#39640;&#21487;&#33021;&#24615;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#25552;&#20379;&#28385;&#36275;&#22810;&#20010;&#24120;&#35265;&#35201;&#27714;&#30340;&#26368;&#20339;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2401.14086</link><description>&lt;p&gt;
&#20351;&#29992;Sum-Product Networks&#29983;&#25104;&#21487;&#33021;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Generating Likely Counterfactuals Using Sum-Product Networks. (arXiv:2401.14086v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14086
&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#29992;&#25143;&#38656;&#27714;&#21644;&#26368;&#36817;&#30340;&#27861;&#35268;&#35201;&#27714;&#65292;&#38656;&#35201;&#23545;AI&#31995;&#32479;&#25152;&#20570;&#20986;&#30340;&#20915;&#31574;&#36827;&#34892;&#35299;&#37322;&#12290;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Sum-Product Networks&#27169;&#25311;&#23547;&#25214;&#39640;&#21487;&#33021;&#24615;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#25552;&#20379;&#28385;&#36275;&#22810;&#20010;&#24120;&#35265;&#35201;&#27714;&#30340;&#26368;&#20339;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#29992;&#25143;&#38656;&#27714;&#21644;&#26368;&#36817;&#30340;&#27861;&#35268;&#65288;GDPR&#12289;AI&#27861;&#26696;&#65289;&#65292;&#38656;&#35201;&#35299;&#37322;AI&#31995;&#32479;&#25152;&#20570;&#20986;&#30340;&#20915;&#31574;&#12290;&#36825;&#20123;&#20915;&#31574;&#24448;&#24448;&#21482;&#33021;&#22312;&#20107;&#21518;&#35299;&#37322;&#65292;&#21453;&#20107;&#23454;&#25512;&#29702;&#25104;&#20026;&#24120;&#35265;&#30340;&#35299;&#37322;&#26041;&#24335;&#12290;&#20160;&#20040;&#26500;&#25104;&#20102;&#26368;&#20339;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#24517;&#39035;&#32771;&#34385;&#22810;&#20010;&#26041;&#38754;&#65292;&#20854;&#20013;&#8220;&#26679;&#26412;&#36317;&#31163;&#8221;&#26159;&#26368;&#24120;&#35265;&#30340;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#19968;&#35201;&#27714;&#32463;&#24120;&#20250;&#23548;&#33268;&#19981;&#22826;&#21487;&#33021;&#19988;&#22240;&#27492;&#20215;&#20540;&#26377;&#38480;&#30340;&#35299;&#37322;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#25552;&#20379;&#39640;&#21487;&#33021;&#24615;&#35299;&#37322;&#30340;&#31995;&#32479;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#65288;MIO&#65289;&#27169;&#25311;&#23547;&#25214;&#28385;&#36275;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#35768;&#22810;&#24120;&#35265;&#35201;&#27714;&#30340;&#26368;&#26377;&#21487;&#33021;&#35299;&#37322;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Sum-Product Network&#65288;SPN&#65289;&#30340;MIO&#34920;&#36798;&#65292;&#24182;&#20351;&#29992;SPN&#20272;&#35745;&#21453;&#20107;&#23454;&#30340;&#21487;&#33021;&#24615;&#65292;&#36825;&#23545;&#29420;&#31435;&#30340;&#20852;&#36259;&#20063;&#26377;&#29992;&#12290;&#19982;&#29983;&#25104;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#20960;&#31181;&#26041;&#27861;&#36827;&#34892;&#25968;&#20540;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to user demand and recent regulation (GDPR, AI Act), decisions made by AI systems need to be explained. These decisions are often explainable only post hoc, where counterfactual explanations are popular. The question of what constitutes the best counterfactual explanation must consider multiple aspects, where "distance from the sample" is the most common. We argue that this requirement frequently leads to explanations that are unlikely and, therefore, of limited value. Here, we present a system that provides high-likelihood explanations. We show that the search for the most likely explanations satisfying many common desiderata for counterfactual explanations can be modeled using mixed-integer optimization (MIO). In the process, we propose an MIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate the likelihood of a counterfactual, which can be of independent interest. A numerical comparison against several methods for generating counterfactual explanations is pr
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25308;&#21344;&#24237;&#23481;&#38169;&#30340;&#20998;&#25955;&#24335;&#22810;&#33218;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#36890;&#36807;&#20449;&#24687;&#28151;&#21512;&#21644;&#20540;&#30340;&#25130;&#26029;&#23454;&#29616;&#20102;&#23545;&#25308;&#21344;&#24237;&#20195;&#29702;&#30340;&#24674;&#22797;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.07320</link><description>&lt;p&gt;
&#25308;&#21344;&#24237;&#23481;&#38169;&#30340;&#20998;&#25955;&#24335;&#22810;&#33218;&#36172;&#21338;&#26426;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Byzantine-Resilient Decentralized Multi-Armed Bandits. (arXiv:2310.07320v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07320
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25308;&#21344;&#24237;&#23481;&#38169;&#30340;&#20998;&#25955;&#24335;&#22810;&#33218;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#36890;&#36807;&#20449;&#24687;&#28151;&#21512;&#21644;&#20540;&#30340;&#25130;&#26029;&#23454;&#29616;&#20102;&#23545;&#25308;&#21344;&#24237;&#20195;&#29702;&#30340;&#24674;&#22797;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#25955;&#24335;&#21512;&#20316;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#27599;&#20010;&#20195;&#29702;&#35266;&#23519;&#21040;&#19981;&#21516;&#30340;&#22870;&#21169;&#27969;&#65292;&#35797;&#22270;&#19982;&#20854;&#20182;&#20195;&#29702;&#20132;&#25442;&#20449;&#24687;&#20197;&#36873;&#25321;&#19968;&#31995;&#21015;&#25163;&#33218;&#20197;&#26368;&#23567;&#21270;&#36951;&#25022;&#12290;&#19982;&#29420;&#31435;&#36816;&#34892;&#19978;&#30028;&#32622;&#20449;&#24230;&#65288;UCB&#65289;&#31561;&#22810;&#33218;&#36172;&#21338;&#26426;&#26041;&#27861;&#30456;&#27604;&#65292;&#21327;&#20316;&#22330;&#26223;&#20013;&#30340;&#20195;&#29702;&#21487;&#20197;&#34920;&#29616;&#24471;&#26356;&#22909;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#26410;&#30693;&#27604;&#20363;&#30340;&#20195;&#29702;&#21487;&#33021;&#26159;&#25308;&#21344;&#24237;&#65288;&#21363;&#65292;&#20197;&#22870;&#21169;&#22343;&#20540;&#20272;&#35745;&#25110;&#32622;&#20449;&#24230;&#38598;&#30340;&#24418;&#24335;&#20256;&#36882;&#20219;&#24847;&#38169;&#35823;&#20449;&#24687;&#65289;&#26102;&#24674;&#22797;&#27492;&#31867;&#31361;&#20986;&#34892;&#20026;&#12290;&#35813;&#26694;&#26550;&#21487;&#29992;&#20110;&#27169;&#25311;&#35745;&#31639;&#26426;&#32593;&#32476;&#20013;&#30340;&#25915;&#20987;&#32773;&#65292;&#21521;&#25512;&#33616;&#31995;&#32479;&#20013;&#25554;&#20837;&#25915;&#20987;&#24615;&#20869;&#23481;&#30340;&#31574;&#21010;&#32773;&#65292;&#25110;&#32773;&#37329;&#34701;&#24066;&#22330;&#30340;&#25805;&#32437;&#32773;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24320;&#21457;&#20102;&#19968;&#31181;&#23436;&#20840;&#20998;&#25955;&#30340;&#20855;&#26377;&#23481;&#38169;&#19978;&#30028;&#32622;&#20449;&#24230;&#65288;UCB&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#20195;&#29702;&#38388;&#30340;&#20449;&#24687;&#28151;&#21512;&#27493;&#39588;&#19982;&#19981;&#19968;&#33268;&#21644;&#26497;&#31471;&#20540;&#30340;&#25130;&#26029;&#30456;&#32467;&#21512;&#12290;&#36825;&#20010;&#25130;&#26029;&#27493;&#39588;&#20351;&#25105;&#20204;&#33021;&#22815;&#24314;&#31435;
&lt;/p&gt;
&lt;p&gt;
In decentralized cooperative multi-armed bandits (MAB), each agent observes a distinct stream of rewards, and seeks to exchange information with others to select a sequence of arms so as to minimize its regret. Agents in the cooperative setting can outperform a single agent running a MAB method such as Upper-Confidence Bound (UCB) independently. In this work, we study how to recover such salient behavior when an unknown fraction of the agents can be Byzantine, that is, communicate arbitrarily wrong information in the form of reward mean-estimates or confidence sets. This framework can be used to model attackers in computer networks, instigators of offensive content into recommender systems, or manipulators of financial markets. Our key contribution is the development of a fully decentralized resilient upper confidence bound (UCB) algorithm that fuses an information mixing step among agents with a truncation of inconsistent and extreme values. This truncation step enables us to establis
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#21160;&#21147;&#23849;&#28291;&#38382;&#39064;&#65292;&#21457;&#29616;&#29305;&#24449;&#24402;&#19968;&#21270;&#21487;&#20197;&#38450;&#27490;&#27492;&#38382;&#39064;&#30340;&#20986;&#29616;&#65292;&#20026;&#35299;&#20915;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#35745;&#31639;&#25928;&#29575;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2309.16109</link><description>&lt;p&gt;
&#29305;&#24449;&#24402;&#19968;&#21270;&#38450;&#27490;&#38750;&#23545;&#27604;&#23398;&#20064;&#21160;&#21147;&#30340;&#23849;&#28291;
&lt;/p&gt;
&lt;p&gt;
Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#21160;&#21147;&#23849;&#28291;&#38382;&#39064;&#65292;&#21457;&#29616;&#29305;&#24449;&#24402;&#19968;&#21270;&#21487;&#20197;&#38450;&#27490;&#27492;&#38382;&#39064;&#30340;&#20986;&#29616;&#65292;&#20026;&#35299;&#20915;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#35745;&#31639;&#25928;&#29575;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#26159;&#19968;&#31181;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#22686;&#24378;&#29983;&#25104;&#30340;&#20004;&#20010;&#27491;&#35270;&#22270;&#22312;&#25968;&#25454;&#34920;&#31034;&#31354;&#38388;&#20013;&#36890;&#36807;&#21560;&#24341;&#21147;&#20351;&#23427;&#20204;&#30456;&#20284;&#65292;&#32780;&#36890;&#36807;&#25490;&#26021;&#21147;&#20351;&#23427;&#20204;&#36828;&#31163;&#36127;&#26679;&#26412;&#12290;&#38750;&#23545;&#27604;&#23398;&#20064;&#36890;&#36807;BYOL&#21644;SimSiam&#31561;&#25163;&#27573;&#21435;&#38500;&#20102;&#36127;&#26679;&#26412;&#65292;&#24182;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;&#34429;&#28982;&#30001;&#20110;&#32570;&#20047;&#25490;&#26021;&#21147;&#65292;&#23398;&#21040;&#30340;&#34920;&#31034;&#21487;&#33021;&#20250;&#23849;&#28291;&#25104;&#19968;&#20010;&#21333;&#28857;&#65292;&#20294;&#30000;&#31561;&#20154;&#65288;2021&#65289;&#36890;&#36807;&#23398;&#20064;&#21160;&#21147;&#20998;&#26512;&#25581;&#31034;&#65292;&#22914;&#26524;&#25968;&#25454;&#22686;&#24378;&#36275;&#22815;&#24378;&#20110;&#27491;&#21017;&#21270;&#65292;&#21017;&#34920;&#31034;&#21487;&#20197;&#36991;&#20813;&#23849;&#28291;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#20998;&#26512;&#27809;&#26377;&#32771;&#34385;&#24120;&#29992;&#30340;&#29305;&#24449;&#24402;&#19968;&#21270;&#65292;&#21363;&#22312;&#34913;&#37327;&#34920;&#31034;&#30456;&#20284;&#24615;&#20043;&#21069;&#36827;&#34892;&#30340;&#24402;&#19968;&#21270;&#25805;&#20316;&#65292;&#22240;&#27492;&#36807;&#24378;&#30340;&#27491;&#21017;&#21270;&#21487;&#33021;&#20250;&#23548;&#33268;&#21160;&#21147;&#23849;&#28291;&#65292;&#36825;&#22312;&#29305;&#24449;&#24402;&#19968;&#21270;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26159;&#19981;&#33258;&#28982;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning is a self-supervised representation learning framework, where two positive views generated through data augmentation are made similar by an attraction force in a data representation space, while a repulsive force makes them far from negative examples. Non-contrastive learning, represented by BYOL and SimSiam, further gets rid of negative examples and improves computational efficiency. While learned representations may collapse into a single point due to the lack of the repulsive force at first sight, Tian et al. (2021) revealed through the learning dynamics analysis that the representations can avoid collapse if data augmentation is sufficiently stronger than regularization. However, their analysis does not take into account commonly-used feature normalization, a normalizer before measuring the similarity of representations, and hence excessively strong regularization may collapse the dynamics, which is an unnatural behavior under the presence of feature normalizat
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#65288;SSNL&#65289;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#27169;&#25311;&#22120;&#29983;&#25104;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;SSNL&#36890;&#36807;&#25311;&#21512;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.01054</link><description>&lt;p&gt;
&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference using surjective sequential neural likelihood estimation. (arXiv:2308.01054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01054
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#65288;SSNL&#65289;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#27169;&#25311;&#22120;&#29983;&#25104;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;SSNL&#36890;&#36807;&#25311;&#21512;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#65288;SSNL&#65289;&#20272;&#35745;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#21487;&#20197;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#30340;&#27169;&#25311;&#22120;&#26102;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#12290;SSNL&#25311;&#21512;&#19968;&#20010;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#20174;&#32780;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#21253;&#25324;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#25110;&#21464;&#20998;&#25512;&#26029;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#20302;&#32500;&#31354;&#38388;&#20013;&#65292;SSNL&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#24212;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#26102;&#36935;&#21040;&#30340;&#20960;&#20010;&#38382;&#39064;&#65292;&#20363;&#22914;&#21253;&#21547;&#26080;&#20449;&#24687;&#25968;&#25454;&#32500;&#24230;&#25110;&#20301;&#20110;&#36739;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#23545;SSNL&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#34920;&#26126;&#23427;&#36890;&#24120;&#20248;&#20110;&#22312;&#22522;&#20110;&#20223;&#30495;&#25512;&#26029;&#20013;&#20351;&#29992;&#30340;&#29616;&#20195;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;&#19968;&#39033;&#26469;&#33258;&#22825;&#20307;&#29289;&#29702;&#23398;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#19990;&#30028;&#20363;&#23376;&#19978;&#23545;&#30913;&#22330;&#27169;&#22411;&#30340;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Surjective Sequential Neural Likelihood (SSNL) estimation, a novel method for simulation-based inference in models where the evaluation of the likelihood function is not tractable and only a simulator that can generate synthetic data is available. SSNL fits a dimensionality-reducing surjective normalizing flow model and uses it as a surrogate likelihood function which allows for conventional Bayesian inference using either Markov chain Monte Carlo methods or variational inference. By embedding the data in a low-dimensional space, SSNL solves several issues previous likelihood-based methods had when applied to high-dimensional data sets that, for instance, contain non-informative data dimensions or lie along a lower-dimensional manifold. We evaluate SSNL on a wide variety of experiments and show that it generally outperforms contemporary methods used in simulation-based inference, for instance, on a challenging real-world example from astrophysics which models the magnetic fi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#22312;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2307.14530</link><description>&lt;p&gt;
&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimation in Mixed-Membership Stochastic Block Models. (arXiv:2307.14530v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#22312;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#29616;&#20195;&#32593;&#32476;&#31185;&#23398;&#20013;&#26368;&#20851;&#38190;&#30340;&#38382;&#39064;&#20043;&#19968;&#12290;&#20854;&#24212;&#29992;&#21487;&#20197;&#22312;&#21508;&#20010;&#39046;&#22495;&#25214;&#21040;&#65292;&#20174;&#34507;&#30333;&#36136;&#24314;&#27169;&#21040;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#12290;&#26368;&#36817;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#35770;&#25991;&#30740;&#31350;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#21363;&#32593;&#32476;&#20013;&#30340;&#27599;&#20010;&#33410;&#28857;&#21487;&#33021;&#23646;&#20110;&#22810;&#20010;&#31038;&#21306;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#30001;Airoldi&#31561;&#20154;&#65288;2008&#65289;&#39318;&#27425;&#25552;&#20986;&#30340;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;MMSB&#65289;&#12290;MMSB&#22312;&#22270;&#20013;&#23545;&#37325;&#21472;&#31038;&#21306;&#32467;&#26500;&#25552;&#20379;&#20102;&#30456;&#24403;&#19968;&#33324;&#30340;&#35774;&#32622;&#12290;&#26412;&#25991;&#30340;&#26680;&#24515;&#38382;&#39064;&#26159;&#22312;&#35266;&#23519;&#21040;&#30340;&#32593;&#32476;&#20013;&#37325;&#24314;&#31038;&#21306;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#36825;&#20010;&#19979;&#30028;&#21305;&#37197;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#32467;&#26524;&#22312;&#23545;&#25152;&#32771;&#34385;&#30340;&#27169;&#22411;&#30340;&#30456;&#24403;&#26222;&#36941;&#26465;&#20214;&#19979;&#24471;&#21040;&#35777;&#26126;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#26469;&#35828;&#26126;&#36825;&#20010;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community detection is one of the most critical problems in modern network science. Its applications can be found in various fields, from protein modeling to social network analysis. Recently, many papers appeared studying the problem of overlapping community detection, where each node of a network may belong to several communities. In this work, we consider Mixed-Membership Stochastic Block Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite a general setting for modeling overlapping community structure in graphs. The central question of this paper is to reconstruct relations between communities given an observed network. We compare different approaches and establish the minimax lower bound on the estimation error. Then, we propose a new estimator that matches this lower bound. Theoretical results are proved under fairly general conditions on the considered model. Finally, we illustrate the theory in a series of experiments.
&lt;/p&gt;</description></item></channel></rss>