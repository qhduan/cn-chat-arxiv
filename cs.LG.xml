<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#26391;&#20043;&#19975;&#26041;&#31243;&#30340;&#32508;&#21512;&#26694;&#26550;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#32447;&#24615;&#21644;&#39640;&#32500;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#39044;&#27979;&#30340;&#20998;&#24067;&#20174;&#32780;&#35780;&#20272;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01338</link><description>&lt;p&gt;
&#36890;&#36807;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#26391;&#20043;&#19975;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Inferring the Langevin Equation with Uncertainty via Bayesian Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01338
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#26391;&#20043;&#19975;&#26041;&#31243;&#30340;&#32508;&#21512;&#26694;&#26550;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#32447;&#24615;&#21644;&#39640;&#32500;&#31995;&#32479;&#65292;&#36890;&#36807;&#25552;&#20379;&#39044;&#27979;&#30340;&#20998;&#24067;&#20174;&#32780;&#35780;&#20272;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#26222;&#36941;&#23384;&#22312;&#30340;&#38543;&#26426;&#31995;&#32479;&#34920;&#29616;&#20986;&#20174;&#20998;&#23376;&#21160;&#21147;&#23398;&#21040;&#27668;&#20505;&#29616;&#35937;&#30340;&#36807;&#31243;&#20013;&#30340;&#27874;&#21160;&#12290;&#26391;&#20043;&#19975;&#26041;&#31243;&#20316;&#20026;&#19968;&#31181;&#24120;&#35265;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#34987;&#29992;&#20110;&#30740;&#31350;&#36825;&#31181;&#31995;&#32479;&#65292;&#21487;&#20197;&#39044;&#27979;&#23427;&#20204;&#30340;&#26102;&#38388;&#28436;&#21270;&#20197;&#21450;&#20998;&#26512;&#28909;&#21147;&#23398;&#37327;&#65292;&#21253;&#25324;&#21560;&#25910;&#28909;&#37327;&#12289;&#23545;&#31995;&#32479;&#20570;&#30340;&#21151;&#20197;&#21450;&#29109;&#30340;&#20135;&#29983;&#12290;&#28982;&#32780;&#65292;&#20174;&#35266;&#27979;&#36712;&#36857;&#20013;&#25512;&#26029;&#26391;&#20043;&#19975;&#26041;&#31243;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#38750;&#32447;&#24615;&#21644;&#39640;&#32500;&#31995;&#32479;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#25512;&#26029;&#36807;&#38459;&#23612;&#21644;&#27424;&#38459;&#23612;&#24773;&#20917;&#19979;&#30340;&#26391;&#20043;&#19975;&#26041;&#31243;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#39318;&#20808;&#20998;&#21035;&#25552;&#20379;&#28418;&#31227;&#21147;&#21644;&#25193;&#25955;&#30697;&#38453;&#65292;&#28982;&#21518;&#23558;&#23427;&#20204;&#32452;&#21512;&#36215;&#26469;&#26500;&#24314;&#26391;&#20043;&#19975;&#26041;&#31243;&#12290;&#36890;&#36807;&#25552;&#20379;&#39044;&#27979;&#30340;&#20998;&#24067;&#32780;&#19981;&#20165;&#20165;&#26159;&#19968;&#20010;&#21333;&#19968;&#30340;&#20540;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#35780;&#20272;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#21487;&#20197;&#38450;&#27490;&#28508;&#22312;&#30340;&#8230;
&lt;/p&gt;
&lt;p&gt;
Pervasive across diverse domains, stochastic systems exhibit fluctuations in processes ranging from molecular dynamics to climate phenomena. The Langevin equation has served as a common mathematical model for studying such systems, enabling predictions of their temporal evolution and analyses of thermodynamic quantities, including absorbed heat, work done on the system, and entropy production. However, inferring the Langevin equation from observed trajectories remains challenging, particularly for nonlinear and high-dimensional systems. In this study, we present a comprehensive framework that employs Bayesian neural networks for inferring Langevin equations in both overdamped and underdamped regimes. Our framework first provides the drift force and diffusion matrix separately and then combines them to construct the Langevin equation. By providing a distribution of predictions instead of a single value, our approach allows us to assess prediction uncertainties, which can prevent potenti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26410;&#32463;&#35757;&#32451;&#30340;&#38543;&#26426;&#26435;&#37325;&#32593;&#32476;&#65292;&#21457;&#29616;&#21363;&#20351;&#31616;&#21333;&#30340;MLPs&#20063;&#20855;&#26377;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#35265;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#35266;&#28857;&#30340;&#26159;&#65292;NNs&#24182;&#19981;&#20855;&#26377;&#22266;&#26377;&#30340;&#8220;&#31616;&#21333;&#20559;&#35265;&#8221;&#65292;&#32780;&#26159;&#20381;&#36182;&#20110;&#32452;&#20214;&#30340;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.02241</link><description>&lt;p&gt;
&#31070;&#32463;&#32418;&#31227;&#65306;&#38543;&#26426;&#32593;&#32476;&#24182;&#38750;&#38543;&#26426;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Neural Redshift: Random Networks are not Random Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26410;&#32463;&#35757;&#32451;&#30340;&#38543;&#26426;&#26435;&#37325;&#32593;&#32476;&#65292;&#21457;&#29616;&#21363;&#20351;&#31616;&#21333;&#30340;MLPs&#20063;&#20855;&#26377;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#35265;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#35266;&#28857;&#30340;&#26159;&#65292;NNs&#24182;&#19981;&#20855;&#26377;&#22266;&#26377;&#30340;&#8220;&#31616;&#21333;&#20559;&#35265;&#8221;&#65292;&#32780;&#26159;&#20381;&#36182;&#20110;&#32452;&#20214;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#31070;&#32463;&#32593;&#32476;&#65288;NNs&#65289;&#30340;&#27867;&#21270;&#33021;&#21147;&#30340;&#29702;&#35299;&#20173;&#19981;&#23436;&#25972;&#12290;&#30446;&#21069;&#30340;&#35299;&#37322;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#38544;&#21547;&#20559;&#35265;&#65292;&#20294;&#26080;&#27861;&#35299;&#37322;&#26799;&#24230;&#33258;&#30001;&#26041;&#27861;&#20013;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#20063;&#26080;&#27861;&#35299;&#37322;&#26368;&#36817;&#35266;&#23519;&#21040;&#30340;&#26410;&#32463;&#35757;&#32451;&#32593;&#32476;&#30340;&#31616;&#21333;&#20559;&#35265;&#12290;&#26412;&#25991;&#23547;&#25214;NNs&#20013;&#30340;&#20854;&#20182;&#27867;&#21270;&#28304;&#12290;&#20026;&#20102;&#29420;&#31435;&#20110;GD&#29702;&#35299;&#20307;&#31995;&#32467;&#26500;&#25552;&#20379;&#30340;&#24402;&#32435;&#20559;&#35265;&#65292;&#25105;&#20204;&#30740;&#31350;&#26410;&#32463;&#35757;&#32451;&#30340;&#38543;&#26426;&#26435;&#37325;&#32593;&#32476;&#12290;&#21363;&#20351;&#26159;&#31616;&#21333;&#30340;MLPs&#20063;&#34920;&#29616;&#20986;&#24378;&#28872;&#30340;&#24402;&#32435;&#20559;&#35265;&#65306;&#22312;&#26435;&#37325;&#31354;&#38388;&#20013;&#36827;&#34892;&#22343;&#21248;&#25277;&#26679;&#20250;&#20135;&#29983;&#19968;&#20010;&#38750;&#24120;&#20559;&#21521;&#20110;&#22797;&#26434;&#24615;&#30340;&#20989;&#25968;&#20998;&#24067;&#12290;&#20294;&#19982;&#24120;&#35268;&#26234;&#24935;&#19981;&#21516;&#65292;NNs&#24182;&#19981;&#20855;&#26377;&#22266;&#26377;&#30340;&#8220;&#31616;&#21333;&#20559;&#35265;&#8221;&#12290;&#36825;&#19968;&#29305;&#24615;&#21462;&#20915;&#20110;&#32452;&#20214;&#65292;&#22914;ReLU&#12289;&#27531;&#24046;&#36830;&#25509;&#21644;&#23618;&#24402;&#19968;&#21270;&#12290;&#21487;&#21033;&#29992;&#26367;&#20195;&#20307;&#31995;&#32467;&#26500;&#26500;&#24314;&#20559;&#21521;&#20110;&#20219;&#20309;&#22797;&#26434;&#24615;&#27700;&#24179;&#30340;&#20559;&#35265;&#12290;Transformers&#20063;&#20855;&#26377;&#36825;&#19968;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02241v1 Announce Type: cross  Abstract: Our understanding of the generalization capabilities of neural networks (NNs) is still incomplete. Prevailing explanations are based on implicit biases of gradient descent (GD) but they cannot account for the capabilities of models from gradient-free methods nor the simplicity bias recently observed in untrained networks. This paper seeks other sources of generalization in NNs.   Findings. To understand the inductive biases provided by architectures independently from GD, we examine untrained, random-weight networks. Even simple MLPs show strong inductive biases: uniform sampling in weight space yields a very biased distribution of functions in terms of complexity. But unlike common wisdom, NNs do not have an inherent "simplicity bias". This property depends on components such as ReLUs, residual connections, and layer normalizations. Alternative architectures can be built with a bias for any level of complexity. Transformers also inher
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#39640;&#25928;&#35745;&#31639;&#35757;&#32451;&#38598;$\mathbf{X}^\mathbf{T}\mathbf{X}$&#21644;$\mathbf{X}^\mathbf{T}\mathbf{Y}$&#30340;&#31639;&#27861;&#65292;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#24037;&#20316;&#65292;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#26174;&#33879;&#21152;&#36895;&#20132;&#21449;&#39564;&#35777;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35745;&#31639;&#30697;&#38453;&#20056;&#31215;&#25110;&#32479;&#35745;&#37327;&#12290;</title><link>http://arxiv.org/abs/2401.13185</link><description>&lt;p&gt;
&#31616;&#21270;&#20132;&#21449;&#39564;&#35777;&#65306;&#39640;&#25928;&#22320;&#35745;&#31639;&#19981;&#38656;&#35201;&#20840;&#37327;&#37325;&#26032;&#35745;&#31639;&#30697;&#38453;&#20056;&#31215;&#25110;&#32479;&#35745;&#37327;&#30340;&#21015;&#21521;&#20013;&#24515;&#21270;&#21644;&#26631;&#20934;&#21270;&#35757;&#32451;&#38598;$\mathbf{X}^\mathbf{T}\mathbf{X}$&#21644;$\mathbf{X}^\mathbf{T}\mathbf{Y}$
&lt;/p&gt;
&lt;p&gt;
Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$ Without Full Recomputation of Matrix Products or Statistical Moments. (arXiv:2401.13185v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#39640;&#25928;&#35745;&#31639;&#35757;&#32451;&#38598;$\mathbf{X}^\mathbf{T}\mathbf{X}$&#21644;$\mathbf{X}^\mathbf{T}\mathbf{Y}$&#30340;&#31639;&#27861;&#65292;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#24037;&#20316;&#65292;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#26174;&#33879;&#21152;&#36895;&#20132;&#21449;&#39564;&#35777;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35745;&#31639;&#30697;&#38453;&#20056;&#31215;&#25110;&#32479;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#35780;&#20272;&#39044;&#27979;&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#34920;&#29616;&#30340;&#25216;&#26415;&#12290;&#35768;&#22810;&#39044;&#27979;&#27169;&#22411;&#65292;&#22914;&#22522;&#20110;&#26680;&#30340;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#27169;&#22411;&#65292;&#38656;&#35201;&#20165;&#20351;&#29992;&#36755;&#20837;&#30697;&#38453;$\mathbf{X}$&#21644;&#36755;&#20986;&#30697;&#38453;$\mathbf{Y}$&#20013;&#30340;&#35757;&#32451;&#38598;&#26679;&#26412;&#26469;&#35745;&#31639;$\mathbf{X}^{\mathbf{T}}\mathbf{X}$&#21644;$\mathbf{X}^{\mathbf{T}}\mathbf{Y}$&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#39640;&#25928;&#35745;&#31639;&#36825;&#20123;&#30697;&#38453;&#30340;&#31639;&#27861;&#12290;&#31532;&#19968;&#31181;&#31639;&#27861;&#19981;&#38656;&#35201;&#21015;&#21521;&#39044;&#22788;&#29702;&#12290;&#31532;&#20108;&#31181;&#31639;&#27861;&#20801;&#35768;&#20197;&#35757;&#32451;&#38598;&#22343;&#20540;&#20026;&#20013;&#24515;&#21270;&#28857;&#36827;&#34892;&#21015;&#21521;&#20013;&#24515;&#21270;&#12290;&#31532;&#19977;&#31181;&#31639;&#27861;&#20801;&#35768;&#20197;&#35757;&#32451;&#38598;&#22343;&#20540;&#21644;&#26631;&#20934;&#24046;&#20026;&#20013;&#24515;&#21270;&#28857;&#21644;&#26631;&#20934;&#21270;&#28857;&#36827;&#34892;&#21015;&#21521;&#20013;&#24515;&#21270;&#21644;&#26631;&#20934;&#21270;&#12290;&#36890;&#36807;&#35777;&#26126;&#27491;&#30830;&#24615;&#21644;&#20248;&#36234;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#23427;&#20204;&#30456;&#27604;&#20110;&#30452;&#25509;&#20132;&#21449;&#39564;&#35777;&#21644;&#20197;&#21069;&#30340;&#24555;&#36895;&#20132;&#21449;&#39564;&#35777;&#24037;&#20316;&#65292;&#25552;&#20379;&#20102;&#26174;&#33879;&#30340;&#20132;&#21449;&#39564;&#35777;&#21152;&#36895;&#65292;&#32780;&#26080;&#38656;&#25968;&#25454;&#27844;&#38706;&#12290;&#23427;&#20204;&#36866;&#21512;&#24182;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-validation is a widely used technique for assessing the performance of predictive models on unseen data. Many predictive models, such as Kernel-Based Partial Least-Squares (PLS) models, require the computation of $\mathbf{X}^{\mathbf{T}}\mathbf{X}$ and $\mathbf{X}^{\mathbf{T}}\mathbf{Y}$ using only training set samples from the input and output matrices, $\mathbf{X}$ and $\mathbf{Y}$, respectively. In this work, we present three algorithms that efficiently compute these matrices. The first one allows no column-wise preprocessing. The second one allows column-wise centering around the training set means. The third one allows column-wise centering and column-wise scaling around the training set means and standard deviations. Demonstrating correctness and superior computational complexity, they offer significant cross-validation speedup compared with straight-forward cross-validation and previous work on fast cross-validation - all without data leakage. Their suitability for paralle
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#30340;&#12289;&#20445;&#25345;&#36523;&#20221;&#30340;&#12289;&#30643;&#23380;&#23610;&#23544;&#21464;&#21270;&#30340;&#34425;&#33180;&#22270;&#20687;&#21512;&#25104;&#26041;&#27861;&#65292;&#33021;&#22815;&#21512;&#25104;&#19981;&#21516;&#30643;&#23380;&#23610;&#23544;&#30340;&#34425;&#33180;&#22270;&#20687;&#65292;&#20195;&#34920;&#19981;&#23384;&#22312;&#30340;&#36523;&#20221;&#65292;&#24182;&#33021;&#22815;&#22312;&#20445;&#25345;&#36523;&#20221;&#30340;&#21516;&#26102;&#36827;&#34892;&#38750;&#32447;&#24615;&#32441;&#29702;&#21464;&#24418;&#12290;</title><link>http://arxiv.org/abs/2312.12028</link><description>&lt;p&gt;
EyePreserve: &#20445;&#25345;&#36523;&#20221;&#30340;&#34425;&#33180;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
EyePreserve: Identity-Preserving Iris Synthesis. (arXiv:2312.12028v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.12028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#30340;&#12289;&#20445;&#25345;&#36523;&#20221;&#30340;&#12289;&#30643;&#23380;&#23610;&#23544;&#21464;&#21270;&#30340;&#34425;&#33180;&#22270;&#20687;&#21512;&#25104;&#26041;&#27861;&#65292;&#33021;&#22815;&#21512;&#25104;&#19981;&#21516;&#30643;&#23380;&#23610;&#23544;&#30340;&#34425;&#33180;&#22270;&#20687;&#65292;&#20195;&#34920;&#19981;&#23384;&#22312;&#30340;&#36523;&#20221;&#65292;&#24182;&#33021;&#22815;&#22312;&#20445;&#25345;&#36523;&#20221;&#30340;&#21516;&#26102;&#36827;&#34892;&#38750;&#32447;&#24615;&#32441;&#29702;&#21464;&#24418;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#30340;&#30643;&#23380;&#23610;&#23544;&#33539;&#22260;&#20869;&#20445;&#25345;&#36523;&#20221;&#30340;&#21516;&#36523;&#20221;&#29983;&#29289;&#29305;&#24449;&#34425;&#33180;&#22270;&#20687;&#30340;&#21512;&#25104;&#26159;&#22797;&#26434;&#30340;&#65292;&#22240;&#20026;&#23427;&#28041;&#21450;&#21040;&#34425;&#33180;&#32908;&#32905;&#25910;&#32553;&#26426;&#21046;&#65292;&#38656;&#35201;&#23558;&#34425;&#33180;&#38750;&#32447;&#24615;&#32441;&#29702;&#21464;&#24418;&#27169;&#22411;&#23884;&#20837;&#21040;&#21512;&#25104;&#27969;&#31243;&#20013;&#12290;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#30340;&#12289;&#20445;&#25345;&#36523;&#20221;&#30340;&#12289;&#30643;&#23380;&#23610;&#23544;&#21464;&#21270;&#30340;&#34425;&#33180;&#22270;&#20687;&#21512;&#25104;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#21512;&#25104;&#20855;&#26377;&#19981;&#21516;&#30643;&#23380;&#23610;&#23544;&#30340;&#34425;&#33180;&#22270;&#20687;&#65292;&#20195;&#34920;&#19981;&#23384;&#22312;&#30340;&#36523;&#20221;&#65292;&#24182;&#33021;&#22815;&#22312;&#32473;&#23450;&#30446;&#26631;&#34425;&#33180;&#22270;&#20687;&#30340;&#20998;&#21106;&#25513;&#33180;&#19979;&#38750;&#32447;&#24615;&#22320;&#21464;&#24418;&#29616;&#26377;&#20027;&#20307;&#30340;&#34425;&#33180;&#22270;&#20687;&#32441;&#29702;&#12290;&#34425;&#33180;&#35782;&#21035;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#21464;&#24418;&#27169;&#22411;&#19981;&#20165;&#22312;&#25913;&#21464;&#30643;&#23380;&#23610;&#23544;&#26102;&#20445;&#25345;&#36523;&#20221;&#65292;&#32780;&#19988;&#22312;&#30643;&#23380;&#23610;&#23544;&#26377;&#26174;&#33879;&#24046;&#24322;&#30340;&#21516;&#36523;&#20221;&#34425;&#33180;&#26679;&#26412;&#20043;&#38388;&#25552;&#20379;&#26356;&#22909;&#30340;&#30456;&#20284;&#24230;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#26041;&#27861;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthesis of same-identity biometric iris images, both for existing and non-existing identities while preserving the identity across a wide range of pupil sizes, is complex due to intricate iris muscle constriction mechanism, requiring a precise model of iris non-linear texture deformations to be embedded into the synthesis pipeline. This paper presents the first method of fully data-driven, identity-preserving, pupil size-varying s ynthesis of iris images. This approach is capable of synthesizing images of irises with different pupil sizes representing non-existing identities as well as non-linearly deforming the texture of iris images of existing subjects given the segmentation mask of the target iris image. Iris recognition experiments suggest that the proposed deformation model not only preserves the identity when changing the pupil size but offers better similarity between same-identity iris samples with significant differences in pupil size, compared to state-of-the-art linear an
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#35299;&#20915;&#20102;&#22810;&#37325;&#20849;&#32447;&#24615;&#38382;&#39064;&#65292;&#38024;&#23545;&#22235;&#24029;&#30465;&#30340;&#30899;&#25490;&#25918;&#24773;&#20917;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#30830;&#23450;&#20102;&#34892;&#19994;&#20998;&#32452;&#65292;&#35780;&#20272;&#20102;&#25490;&#25918;&#39537;&#21160;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#31185;&#23398;&#30340;&#20943;&#25490;&#31574;&#30053;&#65292;&#20197;&#25913;&#21892;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2309.01115</link><description>&lt;p&gt;
&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#22810;&#37325;&#20849;&#32447;&#24615;&#35299;&#20915;&#26041;&#26696;&#65306;&#22235;&#24029;&#30465;&#30899;&#25490;&#25918;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multicollinearity Resolution Based on Machine Learning: A Case Study of Carbon Emissions in Sichuan Province. (arXiv:2309.01115v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#35299;&#20915;&#20102;&#22810;&#37325;&#20849;&#32447;&#24615;&#38382;&#39064;&#65292;&#38024;&#23545;&#22235;&#24029;&#30465;&#30340;&#30899;&#25490;&#25918;&#24773;&#20917;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#30830;&#23450;&#20102;&#34892;&#19994;&#20998;&#32452;&#65292;&#35780;&#20272;&#20102;&#25490;&#25918;&#39537;&#21160;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#31185;&#23398;&#30340;&#20943;&#25490;&#31574;&#30053;&#65292;&#20197;&#25913;&#21892;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#30697;&#38453;&#24402;&#19968;&#21270;&#23545;&#22235;&#24029;&#30465;46&#20010;&#20851;&#38190;&#20135;&#19994;2000-2019&#24180;&#30340;&#33021;&#28304;&#28040;&#32791;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#12290;DBSCAN&#32858;&#31867;&#35782;&#21035;&#20102;16&#20010;&#29305;&#24449;&#31867;&#21035;&#20197;&#23458;&#35266;&#22320;&#20998;&#32452;&#34892;&#19994;&#12290;&#25509;&#19979;&#26469;&#65292;&#37319;&#29992;&#32602;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20197;&#24212;&#23545;&#36807;&#25311;&#21512;&#25511;&#21046;&#12289;&#39640;&#32500;&#25968;&#25454;&#22788;&#29702;&#21644;&#29305;&#24449;&#36873;&#25321;&#31561;&#22797;&#26434;&#33021;&#28304;&#25968;&#25454;&#22788;&#29702;&#30340;&#20248;&#21183;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#29028;&#28845;&#21608;&#22260;&#30340;&#31532;&#20108;&#20010;&#32858;&#31867;&#22240;&#29983;&#20135;&#38656;&#27714;&#32780;&#20135;&#29983;&#30340;&#25490;&#25918;&#37327;&#26368;&#39640;&#12290;&#20197;&#27773;&#27833;&#21644;&#28966;&#28845;&#20026;&#20013;&#24515;&#30340;&#32858;&#31867;&#30340;&#25490;&#25918;&#37327;&#20063;&#24456;&#26174;&#33879;&#12290;&#22522;&#20110;&#27492;&#65292;&#20943;&#25490;&#24314;&#35758;&#21253;&#25324;&#28165;&#27905;&#29028;&#25216;&#26415;&#12289;&#20132;&#36890;&#31649;&#29702;&#12289;&#38050;&#38081;&#20013;&#30340;&#29028;&#30005;&#26367;&#20195;&#21644;&#34892;&#19994;&#26631;&#20934;&#21270;&#12290;&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#23458;&#35266;&#36873;&#25321;&#22240;&#32032;&#65292;&#24182;&#26088;&#22312;&#25506;&#32034;&#26032;&#30340;&#20943;&#25490;&#36884;&#24452;&#12290;&#24635;&#32780;&#35328;&#20043;&#65292;&#26412;&#30740;&#31350;&#30830;&#23450;&#20102;&#34892;&#19994;&#20998;&#32452;&#65292;&#35780;&#20272;&#20102;&#25490;&#25918;&#39537;&#21160;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#31185;&#23398;&#30340;&#20943;&#25490;&#31574;&#30053;&#20197;&#36827;&#19968;&#27493;&#25913;&#21892;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study preprocessed 2000-2019 energy consumption data for 46 key Sichuan industries using matrix normalization. DBSCAN clustering identified 16 feature classes to objectively group industries. Penalized regression models were then applied for their advantages in overfitting control, high-dimensional data processing, and feature selection - well-suited for the complex energy data. Results showed the second cluster around coal had highest emissions due to production needs. Emissions from gasoline-focused and coke-focused clusters were also significant. Based on this, emission reduction suggestions included clean coal technologies, transportation management, coal-electricity replacement in steel, and industry standardization. The research introduced unsupervised learning to objectively select factors and aimed to explore new emission reduction avenues. In summary, the study identified industry groupings, assessed emissions drivers, and proposed scientific reduction strategies to bette
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35821;&#20041;&#27491;&#21521;&#23545;&#38598;&#21512;&#65288;SPPS&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#34920;&#31034;&#23398;&#20064;&#36807;&#31243;&#20013;&#35782;&#21035;&#20855;&#26377;&#30456;&#20284;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#65292;&#24182;&#23558;&#23427;&#20204;&#35270;&#20026;&#27491;&#21521;&#23454;&#20363;&#65292;&#20174;&#32780;&#20943;&#23569;&#20002;&#24323;&#37325;&#35201;&#29305;&#24449;&#30340;&#39118;&#38505;&#12290;&#22312;&#22810;&#20010;&#23454;&#39564;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16122</link><description>&lt;p&gt;
&#22686;&#24378;&#23545;&#27604;&#23454;&#20363;&#21306;&#20998;&#30340;&#35821;&#20041;&#27491;&#21521;&#23545;
&lt;/p&gt;
&lt;p&gt;
Semantic Positive Pairs for Enhancing Contrastive Instance Discrimination. (arXiv:2306.16122v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16122
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35821;&#20041;&#27491;&#21521;&#23545;&#38598;&#21512;&#65288;SPPS&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#34920;&#31034;&#23398;&#20064;&#36807;&#31243;&#20013;&#35782;&#21035;&#20855;&#26377;&#30456;&#20284;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#65292;&#24182;&#23558;&#23427;&#20204;&#35270;&#20026;&#27491;&#21521;&#23454;&#20363;&#65292;&#20174;&#32780;&#20943;&#23569;&#20002;&#24323;&#37325;&#35201;&#29305;&#24449;&#30340;&#39118;&#38505;&#12290;&#22312;&#22810;&#20010;&#23454;&#39564;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#23454;&#20363;&#21306;&#20998;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#26377;&#25928;&#22320;&#38450;&#27490;&#34920;&#31034;&#22349;&#32553;&#65292;&#24182;&#22312;&#34920;&#31034;&#23398;&#20064;&#20013;&#20135;&#29983;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#23884;&#20837;&#31354;&#38388;&#20013;&#21560;&#24341;&#27491;&#21521;&#23545;&#65288;&#21363;&#30456;&#21516;&#23454;&#20363;&#30340;&#20004;&#20010;&#35270;&#22270;&#65289;&#24182;&#25490;&#26021;&#25152;&#26377;&#20854;&#20182;&#23454;&#20363;&#65288;&#21363;&#36127;&#21521;&#23545;&#65289;&#65292;&#26080;&#35770;&#23427;&#20204;&#30340;&#31867;&#21035;&#65292;&#21487;&#33021;&#23548;&#33268;&#20002;&#24323;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35782;&#21035;&#20855;&#26377;&#30456;&#20284;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#65292;&#24182;&#23558;&#23427;&#20204;&#35270;&#20026;&#27491;&#21521;&#23454;&#20363;&#65292;&#21629;&#21517;&#20026;&#35821;&#20041;&#27491;&#21521;&#23545;&#38598;&#21512;&#65288;SPPS&#65289;&#65292;&#20174;&#32780;&#22312;&#34920;&#31034;&#23398;&#20064;&#20013;&#20943;&#23569;&#20102;&#20002;&#24323;&#37325;&#35201;&#29305;&#24449;&#30340;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#19982;&#20219;&#20309;&#23545;&#27604;&#23454;&#20363;&#21306;&#20998;&#26694;&#26550;&#65288;&#22914;SimCLR&#25110;MOCO&#65289;&#19968;&#36215;&#20351;&#29992;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#65288;ImageNet&#12289;STL-10&#21644;CIFAR-10&#65289;&#19978;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;&#22522;&#32447;&#26041;&#27861;vanilla&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning algorithms based on instance discrimination effectively prevent representation collapse and produce promising results in representation learning. However, the process of attracting positive pairs (i.e., two views of the same instance) in the embedding space and repelling all other instances (i.e., negative pairs) irrespective of their categories could result in discarding important features. To address this issue, we propose an approach to identifying those images with similar semantic content and treating them as positive instances, named semantic positive pairs set (SPPS), thereby reducing the risk of discarding important features during representation learning. Our approach could work with any contrastive instance discrimination framework such as SimCLR or MOCO. We conduct experiments on three datasets: ImageNet, STL-10 and CIFAR-10 to evaluate our approach. The experimental results show that our approach consistently outperforms the baseline method vanilla 
&lt;/p&gt;</description></item></channel></rss>