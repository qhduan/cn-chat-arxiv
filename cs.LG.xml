<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#32570;&#20047;&#36890;&#29992;&#34892;&#20026;&#65292;&#38656;&#35201;&#21033;&#29992;&#32467;&#26500;&#21270;&#30693;&#35782;&#34920;&#31034;&#12290;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#35748;&#30693;&#27867;&#21270;&#26694;&#26550;KIX&#65292;&#36890;&#36807;&#19982;&#23545;&#35937;&#30340;&#20132;&#20114;&#23398;&#20064;&#21487;&#36801;&#31227;&#30340;&#20132;&#20114;&#27010;&#24565;&#21644;&#27867;&#21270;&#33021;&#21147;&#65292;&#20419;&#36827;&#20102;&#30693;&#35782;&#19982;&#24378;&#21270;&#23398;&#20064;&#30340;&#34701;&#21512;&#65292;&#20026;&#23454;&#29616;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#33258;&#20027;&#21644;&#36890;&#29992;&#34892;&#20026;&#25552;&#20379;&#20102;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.05346</link><description>&lt;p&gt;
KIX: &#19968;&#31181;&#20803;&#35748;&#30693;&#27867;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
KIX: A Metacognitive Generalization Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05346
&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#32570;&#20047;&#36890;&#29992;&#34892;&#20026;&#65292;&#38656;&#35201;&#21033;&#29992;&#32467;&#26500;&#21270;&#30693;&#35782;&#34920;&#31034;&#12290;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#35748;&#30693;&#27867;&#21270;&#26694;&#26550;KIX&#65292;&#36890;&#36807;&#19982;&#23545;&#35937;&#30340;&#20132;&#20114;&#23398;&#20064;&#21487;&#36801;&#31227;&#30340;&#20132;&#20114;&#27010;&#24565;&#21644;&#27867;&#21270;&#33021;&#21147;&#65292;&#20419;&#36827;&#20102;&#30693;&#35782;&#19982;&#24378;&#21270;&#23398;&#20064;&#30340;&#34701;&#21512;&#65292;&#20026;&#23454;&#29616;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#33258;&#20027;&#21644;&#36890;&#29992;&#34892;&#20026;&#25552;&#20379;&#20102;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#21644;&#20854;&#20182;&#21160;&#29289;&#33021;&#22815;&#28789;&#27963;&#35299;&#20915;&#21508;&#31181;&#20219;&#21153;&#65292;&#24182;&#19988;&#33021;&#22815;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#21644;&#24212;&#29992;&#38271;&#26399;&#31215;&#32047;&#30340;&#39640;&#32423;&#30693;&#35782;&#26469;&#36866;&#24212;&#26032;&#39062;&#24773;&#22659;&#65292;&#36825;&#34920;&#29616;&#20102;&#19968;&#31181;&#27867;&#21270;&#26234;&#33021;&#34892;&#20026;&#12290;&#20294;&#26159;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#26356;&#22810;&#22320;&#26159;&#19987;&#23478;&#65292;&#32570;&#20047;&#36825;&#31181;&#36890;&#29992;&#34892;&#20026;&#12290;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#38656;&#35201;&#29702;&#35299;&#21644;&#21033;&#29992;&#20851;&#38190;&#30340;&#32467;&#26500;&#21270;&#30693;&#35782;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#35748;&#30693;&#27867;&#21270;&#26694;&#26550;&#65292;&#31216;&#20026;Knowledge-Interaction-eXecution (KIX)&#65292;&#24182;&#19988;&#35748;&#20026;&#36890;&#36807;&#19982;&#23545;&#35937;&#30340;&#20132;&#20114;&#26469;&#21033;&#29992;&#31867;&#22411;&#31354;&#38388;&#21487;&#20197;&#20419;&#36827;&#23398;&#20064;&#21487;&#36801;&#31227;&#30340;&#20132;&#20114;&#27010;&#24565;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#36825;&#26159;&#23558;&#30693;&#35782;&#34701;&#20837;&#21040;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#33258;&#28982;&#26041;&#24335;&#65292;&#24182;&#26377;&#26395;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#20013;&#23454;&#29616;&#33258;&#20027;&#21644;&#36890;&#29992;&#34892;&#20026;&#30340;&#25512;&#24191;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;
Humans and other animals aptly exhibit general intelligence behaviors in solving a variety of tasks with flexibility and ability to adapt to novel situations by reusing and applying high level knowledge acquired over time. But artificial agents are more of a specialist, lacking such generalist behaviors. Artificial agents will require understanding and exploiting critical structured knowledge representations. We present a metacognitive generalization framework, Knowledge-Interaction-eXecution (KIX), and argue that interactions with objects leveraging type space facilitate the learning of transferable interaction concepts and generalization. It is a natural way of integrating knowledge into reinforcement learning and promising to act as an enabler for autonomous and generalist behaviors in artificial intelligence systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20110;TD&#23398;&#20064;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.15719</link><description>&lt;p&gt;
&#20851;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#21450;&#20854;&#22312;TD&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Rates of Convergence in the Central Limit Theorem for Markov Chains, with an Application to TD Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20110;TD&#23398;&#20064;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;Stein&#26041;&#27861;&#35777;&#26126;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#30340;&#12289;&#30690;&#37327;&#20540;&#38789;&#24046;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#21033;&#29992;&#27850;&#26494;&#26041;&#31243;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#20989;&#25968;&#12290;&#28982;&#21518;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#24212;&#29992;&#20110;&#24314;&#31435;&#22522;&#20110;&#24179;&#22343;&#30340;&#38750;&#28176;&#36817;&#30340;TD&#23398;&#20064;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a non-asymptotic central limit theorem for vector-valued martingale differences using Stein's method, and use Poisson's equation to extend the result to functions of Markov Chains. We then show that these results can be applied to establish a non-asymptotic central limit theorem for Temporal Difference (TD) learning with averaging.
&lt;/p&gt;</description></item><item><title>YaRN&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#26377;&#25928;&#21033;&#29992;&#21644;&#25512;&#26029;&#27604;&#21407;&#22987;&#39044;&#35757;&#32451;&#20801;&#35768;&#30340;&#19978;&#19979;&#25991;&#38271;&#24230;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#65292;&#21516;&#26102;&#36229;&#36234;&#20102;&#20043;&#21069;&#30340;&#26368;&#26032;&#30740;&#31350;&#25104;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.00071</link><description>&lt;p&gt;
YaRN: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39640;&#25928;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
YaRN: Efficient Context Window Extension of Large Language Models. (arXiv:2309.00071v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00071
&lt;/p&gt;
&lt;p&gt;
YaRN&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#26377;&#25928;&#21033;&#29992;&#21644;&#25512;&#26029;&#27604;&#21407;&#22987;&#39044;&#35757;&#32451;&#20801;&#35768;&#30340;&#19978;&#19979;&#25991;&#38271;&#24230;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#65292;&#21516;&#26102;&#36229;&#36234;&#20102;&#20043;&#21069;&#30340;&#26368;&#26032;&#30740;&#31350;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26059;&#36716;&#20301;&#32622;&#23884;&#20837;&#65288;RoPE&#65289;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#26377;&#25928;&#22320;&#32534;&#30721;transformer-based&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20301;&#32622;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#36229;&#36807;&#23427;&#20204;&#35757;&#32451;&#30340;&#24207;&#21015;&#38271;&#24230;&#26102;&#26080;&#27861;&#27867;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;YaRN&#65288;Yet another RoPE extensioN method&#65289;&#65292;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#26041;&#27861;&#26469;&#25193;&#23637;&#36825;&#20123;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#65292;&#38656;&#35201;&#30340;tokens&#25968;&#37327;&#21644;&#35757;&#32451;&#27493;&#39588;&#23569;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#30340;10&#20493;&#21644;2.5&#20493;&#12290;&#20351;&#29992;YaRN&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;LLaMA&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#21644;&#25512;&#26029;&#27604;&#21407;&#22987;&#39044;&#35757;&#32451;&#20801;&#35768;&#30340;&#19978;&#19979;&#25991;&#38271;&#24230;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#65292;&#24182;&#19988;&#22312;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#26041;&#38754;&#36229;&#36807;&#20102;&#20043;&#21069;&#30340;&#26368;&#26032;&#30740;&#31350;&#25104;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;YaRN&#20855;&#26377;&#36229;&#36234;&#24494;&#35843;&#25968;&#25454;&#38598;&#26377;&#38480;&#19978;&#19979;&#25991;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;https://github.com/jquesnelle/yarn&#19978;&#21457;&#24067;&#20102;&#20351;&#29992;64k&#21644;128k&#19978;&#19979;&#25991;&#31383;&#21475;&#36827;&#34892;Fine-tuning&#30340;Llama 2 7B/13B&#30340;&#26816;&#26597;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models. However, these models fail to generalize past the sequence length they were trained on. We present YaRN (Yet another RoPE extensioN method), a compute-efficient method to extend the context window of such models, requiring 10x less tokens and 2.5x less training steps than previous methods. Using YaRN, we show that LLaMA models can effectively utilize and extrapolate to context lengths much longer than their original pre-training would allow, while also surpassing previous the state-of-the-art at context window extension. In addition, we demonstrate that YaRN exhibits the capability to extrapolate beyond the limited context of a fine-tuning dataset. We publish the checkpoints of Llama 2 7B/13B fine-tuned using YaRN with 64k and 128k context windows at https://github.com/jquesnelle/yarn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#65292;&#29992;&#20110;&#20272;&#31639;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;</title><link>http://arxiv.org/abs/2306.13681</link><description>&lt;p&gt;
&#20272;&#31639;&#22522;&#20110;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
Estimating the Value of Evidence-Based Decision Making. (arXiv:2306.13681v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13681
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#65292;&#29992;&#20110;&#20272;&#31639;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21830;&#19994;/&#25919;&#31574;&#20915;&#31574;&#36890;&#24120;&#22522;&#20110;&#38543;&#26426;&#23454;&#39564;&#21644;&#35266;&#23519;&#24615;&#30740;&#31350;&#30340;&#35777;&#25454;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#26469;&#20272;&#31639;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#65288;EBDM&#65289;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;
Business/policy decisions are often based on evidence from randomized experiments and observational studies. In this article we propose an empirical framework to estimate the value of evidence-based decision making (EBDM) and the return on the investment in statistical precision.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#37325;&#24230;&#19981;&#24179;&#34913;&#33410;&#28857;&#20998;&#31867;&#30340;&#36845;&#20195;&#36807;&#37319;&#26679;&#26041;&#27861;UNREAL&#65292;&#36890;&#36807;&#28155;&#21152;&#26410;&#26631;&#35760;&#33410;&#28857;&#32780;&#19981;&#26159;&#21512;&#25104;&#33410;&#28857;&#65292;&#35299;&#20915;&#20102;&#29305;&#24449;&#21644;&#37051;&#22495;&#29983;&#25104;&#30340;&#38590;&#39064;&#65292;&#24182;&#21033;&#29992;&#33410;&#28857;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#36827;&#34892;&#20960;&#20309;&#25490;&#21517;&#26469;&#26377;&#25928;&#22320;&#26657;&#20934;&#20266;&#26631;&#31614;&#20998;&#37197;&#12290;</title><link>http://arxiv.org/abs/2303.10371</link><description>&lt;p&gt;
UNREAL: &#29992;&#20110;&#37325;&#24230;&#19981;&#24179;&#34913;&#33410;&#28857;&#20998;&#31867;&#30340;&#26410;&#26631;&#35760;&#33410;&#28857;&#26816;&#32034;&#21644;&#26631;&#35760;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
UNREAL:Unlabeled Nodes Retrieval and Labeling for Heavily-imbalanced Node Classification. (arXiv:2303.10371v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10371
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#37325;&#24230;&#19981;&#24179;&#34913;&#33410;&#28857;&#20998;&#31867;&#30340;&#36845;&#20195;&#36807;&#37319;&#26679;&#26041;&#27861;UNREAL&#65292;&#36890;&#36807;&#28155;&#21152;&#26410;&#26631;&#35760;&#33410;&#28857;&#32780;&#19981;&#26159;&#21512;&#25104;&#33410;&#28857;&#65292;&#35299;&#20915;&#20102;&#29305;&#24449;&#21644;&#37051;&#22495;&#29983;&#25104;&#30340;&#38590;&#39064;&#65292;&#24182;&#21033;&#29992;&#33410;&#28857;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#36827;&#34892;&#20960;&#20309;&#25490;&#21517;&#26469;&#26377;&#25928;&#22320;&#26657;&#20934;&#20266;&#26631;&#31614;&#20998;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#26497;&#24230;&#20542;&#26012;&#30340;&#26631;&#31614;&#20998;&#24067;&#24456;&#24120;&#35265;&#12290;&#22914;&#26524;&#19981;&#21512;&#36866;&#22320;&#22788;&#29702;&#65292;&#36825;&#23545;&#23569;&#25968;&#31867;&#21035;&#30340;GNNs&#24615;&#33021;&#20250;&#26377;&#26497;&#22823;&#30340;&#24433;&#21709;&#12290;&#30001;&#20110;&#20854;&#23454;&#29992;&#24615;&#65292;&#26368;&#36817;&#19968;&#31995;&#21015;&#30340;&#30740;&#31350;&#37117;&#33268;&#21147;&#20110;&#35299;&#20915;&#36825;&#20010;&#38590;&#39064;&#12290;&#29616;&#26377;&#30340;&#36807;&#37319;&#26679;&#26041;&#27861;&#36890;&#36807;&#20135;&#29983;&#8220;&#20551;&#8221;&#30340;&#23569;&#25968;&#33410;&#28857;&#21644;&#21512;&#25104;&#20854;&#29305;&#24449;&#21644;&#23616;&#37096;&#25299;&#25169;&#26469;&#24179;&#28369;&#26631;&#31614;&#20998;&#24067;&#65292;&#36825;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#30053;&#20102;&#22270;&#19978;&#26410;&#26631;&#35760;&#33410;&#28857;&#30340;&#20016;&#23500;&#20449;&#24687;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;UNREAL&#65292;&#19968;&#31181;&#36845;&#20195;&#36807;&#37319;&#26679;&#26041;&#27861;&#12290;&#31532;&#19968;&#20010;&#20851;&#38190;&#21306;&#21035;&#22312;&#20110;&#65292;&#25105;&#20204;&#21482;&#28155;&#21152;&#26410;&#26631;&#35760;&#33410;&#28857;&#32780;&#19981;&#26159;&#21512;&#25104;&#33410;&#28857;&#65292;&#36825;&#28040;&#38500;&#20102;&#29305;&#24449;&#21644;&#37051;&#22495;&#29983;&#25104;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#36873;&#25321;&#35201;&#28155;&#21152;&#30340;&#26410;&#26631;&#35760;&#33410;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20309;&#25490;&#21517;&#26469;&#23545;&#26410;&#26631;&#35760;&#33410;&#28857;&#36827;&#34892;&#25490;&#21517;&#12290;&#20960;&#20309;&#25490;&#21517;&#21033;&#29992;&#33410;&#28857;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#26469;&#26377;&#25928;&#22320;&#26657;&#20934;&#20266;&#26631;&#31614;&#20998;&#37197;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extremely skewed label distributions are common in real-world node classification tasks. If not dealt with appropriately, it significantly hurts the performance of GNNs in minority classes. Due to its practical importance, there have been a series of recent research devoted to this challenge. Existing over-sampling techniques smooth the label distribution by generating ``fake'' minority nodes and synthesizing their features and local topology, which largely ignore the rich information of unlabeled nodes on graphs. In this paper, we propose UNREAL, an iterative over-sampling method. The first key difference is that we only add unlabeled nodes instead of synthetic nodes, which eliminates the challenge of feature and neighborhood generation. To select which unlabeled nodes to add, we propose geometric ranking to rank unlabeled nodes. Geometric ranking exploits unsupervised learning in the node embedding space to effectively calibrates pseudo-label assignment. Finally, we identify the issu
&lt;/p&gt;</description></item></channel></rss>