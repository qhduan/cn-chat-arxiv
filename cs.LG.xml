<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36890;&#36807;&#24341;&#20837;&#36716;&#23548;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;PARMESAN&#65292;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#21644;&#36716;&#23548;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#26080;&#38656;&#36830;&#32493;&#35757;&#32451;&#30340;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.11743</link><description>&lt;p&gt;
PARMESAN: &#29992;&#20110;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#19982;&#36716;&#23548;
&lt;/p&gt;
&lt;p&gt;
PARMESAN: Parameter-Free Memory Search and Transduction for Dense Prediction Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11743
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#36716;&#23548;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;PARMESAN&#65292;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#21644;&#36716;&#23548;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#26080;&#38656;&#36830;&#32493;&#35757;&#32451;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#36716;&#23548;&#25512;&#29702;&#26469;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#28789;&#27963;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;PARMESAN&#65288;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#19982;&#36716;&#23548;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36716;&#23548;&#26041;&#27861;&#65292;&#21033;&#29992;&#20869;&#23384;&#27169;&#22359;&#26469;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#12290;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#65292;&#20869;&#23384;&#20013;&#30340;&#38544;&#34255;&#34920;&#31034;&#34987;&#25628;&#32034;&#20197;&#25214;&#21040;&#30456;&#24212;&#30340;&#31034;&#20363;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;PARMESAN&#36890;&#36807;&#20462;&#25913;&#20869;&#23384;&#20869;&#23481;&#23398;&#20064;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20219;&#20309;&#36830;&#32493;&#35757;&#32451;&#25110;&#24494;&#35843;&#21487;&#23398;&#20064;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#24120;&#29992;&#30340;&#31070;&#32463;&#32467;&#26500;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11743v1 Announce Type: new  Abstract: In this work we address flexibility in deep learning by means of transductive reasoning. For adaptation to new tasks or new data, existing methods typically involve tuning of learnable parameters or even complete re-training from scratch, rendering such approaches unflexible in practice. We argue that the notion of separating computation from memory by the means of transduction can act as a stepping stone for solving these issues. We therefore propose PARMESAN (parameter-free memory search and transduction), a scalable transduction method which leverages a memory module for solving dense prediction tasks. At inference, hidden representations in memory are being searched to find corresponding examples. In contrast to other methods, PARMESAN learns without the requirement for any continuous training or fine-tuning of learnable parameters simply by modifying the memory content. Our method is compatible with commonly used neural architecture
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;Hessian&#35745;&#31639;&#21644;&#27714;&#36870;&#30340;Hessian-Free Laplace&#36817;&#20284;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#25968;&#21518;&#39564;&#21644;&#32593;&#32476;&#39044;&#27979;&#30340;&#26354;&#29575;&#26469;&#20272;&#35745;&#21518;&#39564;&#30340;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.10671</link><description>&lt;p&gt;
Bayesian&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#26080;Hessian-Laplace
&lt;/p&gt;
&lt;p&gt;
Hessian-Free Laplace in Bayesian Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10671
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;Hessian&#35745;&#31639;&#21644;&#27714;&#36870;&#30340;Hessian-Free Laplace&#36817;&#20284;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#25968;&#21518;&#39564;&#21644;&#32593;&#32476;&#39044;&#27979;&#30340;&#26354;&#29575;&#26469;&#20272;&#35745;&#21518;&#39564;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;Laplace&#36817;&#20284;&#65288;LA&#65289;&#26159;&#20197;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#20026;&#20013;&#24515;&#30340;&#39640;&#26031;&#20998;&#24067;&#12290;&#23427;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#21560;&#24341;&#21147;&#28304;&#20110;&#33021;&#22815;&#22312;&#26631;&#20934;&#32593;&#32476;&#21442;&#25968;&#20248;&#21270;&#20043;&#21518;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65288;&#21363;&#20107;&#21518;&#65289;&#65292;&#20174;&#36817;&#20284;&#21518;&#39564;&#20013;&#25277;&#26679;&#30340;&#20415;&#21033;&#24615;&#20197;&#21450;&#27169;&#22411;&#35777;&#25454;&#30340;&#35299;&#26512;&#24418;&#24335;&#12290;&#28982;&#32780;&#65292;LA&#30340;&#19968;&#20010;&#37325;&#35201;&#35745;&#31639;&#29942;&#39048;&#26159;&#24517;&#39035;&#35745;&#31639;&#21644;&#27714;&#36870;&#23545;&#25968;&#21518;&#39564;&#30340;Hessian&#30697;&#38453;&#12290;Hessian&#21487;&#20197;&#20197;&#22810;&#31181;&#26041;&#24335;&#36817;&#20284;&#65292;&#36136;&#37327;&#19982;&#32593;&#32476;&#12289;&#25968;&#25454;&#38598;&#21644;&#25512;&#26029;&#20219;&#21153;&#31561;&#22810;&#20010;&#22240;&#32032;&#26377;&#20851;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32469;&#36807;Hessian&#35745;&#31639;&#21644;&#27714;&#36870;&#30340;&#26367;&#20195;&#26694;&#26550;&#12290;&#26080;Hessian-Laplace&#65288;HFL&#65289;&#36817;&#20284;&#20351;&#29992;&#23545;&#25968;&#21518;&#39564;&#21644;&#32593;&#32476;&#39044;&#27979;&#30340;&#26354;&#29575;&#26469;&#20272;&#35745;&#20854;&#26041;&#24046;&#12290;&#21482;&#38656;&#35201;&#20004;&#20010;&#28857;&#20272;&#35745;&#65306;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#21644;&#31561;&#20215;&#30340;&#26354;&#29575;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10671v1 Announce Type: cross  Abstract: The Laplace approximation (LA) of the Bayesian posterior is a Gaussian distribution centered at the maximum a posteriori estimate. Its appeal in Bayesian deep learning stems from the ability to quantify uncertainty post-hoc (i.e., after standard network parameter optimization), the ease of sampling from the approximate posterior, and the analytic form of model evidence. However, an important computational bottleneck of LA is the necessary step of calculating and inverting the Hessian matrix of the log posterior. The Hessian may be approximated in a variety of ways, with quality varying with a number of factors including the network, dataset, and inference task. In this paper, we propose an alternative framework that sidesteps Hessian calculation and inversion. The Hessian-free Laplace (HFL) approximation uses curvature of both the log posterior and network prediction to estimate its variance. Only two point estimates are needed: the st
&lt;/p&gt;</description></item><item><title>&#21457;&#23637;&#20102;&#19968;&#20010;&#20351;&#29992;&#31354;&#38388;&#38598;&#21512;&#26694;&#26550;&#30340;&#20998;&#31867;&#22120;&#65292;&#21487;&#20197;&#26681;&#25454;&#28857;&#30340;&#25490;&#21015;&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#21306;&#20998;&#20004;&#20010;&#31867;&#21035;&#65292;&#23545;&#20110;&#32959;&#30244;&#23398;&#31561;&#24212;&#29992;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;</title><link>https://arxiv.org/abs/2402.14974</link><description>&lt;p&gt;
&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#23454;&#29616;&#31354;&#38388;&#36879;&#26126;&#30340;AI&#20998;&#31867;&#65306;MxIF&#32959;&#30244;&#25968;&#25454;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14974
&lt;/p&gt;
&lt;p&gt;
&#21457;&#23637;&#20102;&#19968;&#20010;&#20351;&#29992;&#31354;&#38388;&#38598;&#21512;&#26694;&#26550;&#30340;&#20998;&#31867;&#22120;&#65292;&#21487;&#20197;&#26681;&#25454;&#28857;&#30340;&#25490;&#21015;&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#21306;&#20998;&#20004;&#20010;&#31867;&#21035;&#65292;&#23545;&#20110;&#32959;&#30244;&#23398;&#31561;&#24212;&#29992;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#26469;&#33258;&#19981;&#21516;&#22320;&#28857;&#31867;&#22411;&#30340;&#22810;&#31867;&#21035;&#28857;&#38598;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24320;&#21457;&#19968;&#20010;&#31354;&#38388;&#36879;&#26126;&#30340;&#20998;&#31867;&#22120;&#65292;&#21487;&#20197;&#26681;&#25454;&#28857;&#30340;&#25490;&#21015;&#21306;&#20998;&#20004;&#20010;&#31867;&#21035;&#12290;&#36825;&#20010;&#38382;&#39064;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#65292;&#27604;&#22914;&#32959;&#30244;&#23398;&#65292;&#29992;&#20110;&#20998;&#26512;&#20813;&#30123;-&#32959;&#30244;&#20851;&#31995;&#21644;&#35774;&#35745;&#26032;&#30340;&#20813;&#30123;&#27835;&#30103;&#26041;&#27861;&#12290;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#38656;&#35201;&#32771;&#34385;&#31354;&#38388;&#21464;&#21270;&#21644;&#21487;&#35299;&#37322;&#24615;&#38656;&#27714;&#12290;&#20197;&#21069;&#25552;&#20986;&#30340;&#25216;&#26415;&#35201;&#27714;&#23494;&#38598;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#25110;&#32773;&#22312;&#22788;&#29702;&#21333;&#20010;&#22320;&#28857;&#31867;&#22411;&#20869;&#30340;&#26174;&#33879;&#31354;&#38388;&#21464;&#24322;&#24615;&#26041;&#38754;&#33021;&#21147;&#26377;&#38480;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20123;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#26041;&#27861;&#27809;&#26377;&#35774;&#35745;&#29992;&#20110;&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#24037;&#20316;&#65292;&#29305;&#21035;&#26159;&#28857;&#38598;&#12290;&#29616;&#26377;&#30340;&#38750;&#27431;&#20960;&#37324;&#24471;DNN&#26041;&#27861;&#23616;&#38480;&#20110;&#19968;&#20992;&#20999;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#31354;&#38388;&#38598;&#21512;&#26694;&#26550;&#65292;&#26126;&#30830;&#20351;&#29992;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#21253;&#25324;&#21152;&#26435;&#36317;&#31163;&#23398;&#20064;&#29575;&#21644;&#31354;&#38388;&#22495;&#33258;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14974v1 Announce Type: cross  Abstract: Given multi-category point sets from different place-types, our goal is to develop a spatially-lucid classifier that can distinguish between two classes based on the arrangements of their points. This problem is important for many applications, such as oncology, for analyzing immune-tumor relationships and designing new immunotherapies. It is challenging due to spatial variability and interpretability needs. Previously proposed techniques require dense training data or have limited ability to handle significant spatial variability within a single place-type. Most importantly, these deep neural network (DNN) approaches are not designed to work in non-Euclidean space, particularly point sets. Existing non-Euclidean DNN methods are limited to one-size-fits-all approaches. We explore a spatial ensemble framework that explicitly uses different training strategies, including weighted-distance learning rate and spatial domain adaptation, on v
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32467;&#21512;&#39034;&#24207;&#21270;&#30340;MCMC&#32467;&#26500;&#23398;&#20064;&#25216;&#26415;&#21644;&#26799;&#24230;&#22270;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#23558;&#22240;&#26524;&#32467;&#26500;&#25512;&#26029;&#38382;&#39064;&#20998;&#35299;&#20026;&#21464;&#37327;&#25299;&#25169;&#39034;&#24207;&#25512;&#26029;&#21644;&#21464;&#37327;&#29238;&#33410;&#28857;&#38598;&#21512;&#25512;&#26029;&#65292;&#21516;&#26102;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#22240;&#26524;&#26426;&#21046;&#24314;&#27169;&#23454;&#29616;&#31934;&#30830;&#36793;&#32536;&#21270;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;Rao-Blackwell&#21270;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.14781</link><description>&lt;p&gt;
Rao-Blackwellising Bayesian Causal Inference
&lt;/p&gt;
&lt;p&gt;
Rao-Blackwellising Bayesian Causal Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32467;&#21512;&#39034;&#24207;&#21270;&#30340;MCMC&#32467;&#26500;&#23398;&#20064;&#25216;&#26415;&#21644;&#26799;&#24230;&#22270;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#23558;&#22240;&#26524;&#32467;&#26500;&#25512;&#26029;&#38382;&#39064;&#20998;&#35299;&#20026;&#21464;&#37327;&#25299;&#25169;&#39034;&#24207;&#25512;&#26029;&#21644;&#21464;&#37327;&#29238;&#33410;&#28857;&#38598;&#21512;&#25512;&#26029;&#65292;&#21516;&#26102;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#22240;&#26524;&#26426;&#21046;&#24314;&#27169;&#23454;&#29616;&#31934;&#30830;&#36793;&#32536;&#21270;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;Rao-Blackwell&#21270;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#65292;&#21363;&#25512;&#26029;&#29992;&#20110;&#19979;&#28216;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#22240;&#26524;&#27169;&#22411;&#30340;&#21518;&#39564;&#27010;&#29575;&#65292;&#26500;&#25104;&#20102;&#19968;&#20010;&#22312;&#25991;&#29486;&#20013;&#40092;&#26377;&#25506;&#35752;&#30340;&#38590;&#35299;&#30340;&#35745;&#31639;&#25512;&#26029;&#38382;&#39064;&#12290;&#26412;&#25991;&#23558;&#22522;&#20110;&#39034;&#24207;&#30340;MCMC&#32467;&#26500;&#23398;&#20064;&#25216;&#26415;&#19982;&#26368;&#36817;&#26799;&#24230;&#22270;&#23398;&#20064;&#30340;&#36827;&#23637;&#30456;&#32467;&#21512;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#30340;&#38382;&#39064;&#20998;&#35299;&#20026;(i)&#25512;&#26029;&#21464;&#37327;&#20043;&#38388;&#30340;&#25299;&#25169;&#39034;&#24207;&#20197;&#21450;(ii)&#25512;&#26029;&#27599;&#20010;&#21464;&#37327;&#30340;&#29238;&#33410;&#28857;&#38598;&#21512;&#12290;&#24403;&#38480;&#21046;&#27599;&#20010;&#21464;&#37327;&#30340;&#29238;&#33410;&#28857;&#25968;&#37327;&#26102;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#23436;&#20840;&#36793;&#32536;&#21270;&#29238;&#33410;&#28857;&#38598;&#21512;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#24314;&#27169;&#26410;&#30693;&#30340;&#22240;&#26524;&#26426;&#21046;&#65292;&#20174;&#32780;&#20801;&#35768;&#20854;&#31934;&#30830;&#36793;&#32536;&#21270;&#12290;&#36825;&#24341;&#20837;&#20102;&#19968;&#20010;Rao-Blackwell&#21270;&#26041;&#26696;&#65292;&#20854;&#20013;&#38500;&#20102;&#22240;&#26524;&#39034;&#24207;&#20043;&#22806;&#65292;&#27169;&#22411;&#20013;&#30340;&#25152;&#26377;&#32452;&#20214;&#37117;&#34987;&#28040;&#38500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14781v1 Announce Type: cross  Abstract: Bayesian causal inference, i.e., inferring a posterior over causal models for the use in downstream causal reasoning tasks, poses a hard computational inference problem that is little explored in literature. In this work, we combine techniques from order-based MCMC structure learning with recent advances in gradient-based graph learning into an effective Bayesian causal inference framework. Specifically, we decompose the problem of inferring the causal structure into (i) inferring a topological order over variables and (ii) inferring the parent sets for each variable. When limiting the number of parents per variable, we can exactly marginalise over the parent sets in polynomial time. We further use Gaussian processes to model the unknown causal mechanisms, which also allows their exact marginalisation. This introduces a Rao-Blackwellization scheme, where all components are eliminated from the model, except for the causal order, for whi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#32447;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#20854;&#20013;&#36890;&#36807;&#26126;&#30830;&#24314;&#27169;&#29366;&#24577;&#30340;&#29983;&#25104;&#36807;&#31243;&#21644;&#20351;&#29992;&#22240;&#26524;&#32467;&#26500;&#36827;&#34892;&#31574;&#30053;&#24341;&#23548;&#65292;&#20197;&#24110;&#21161;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#30340;&#20915;&#31574;&#21487;&#35299;&#37322;&#24615;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#22312;&#25506;&#32034;&#21644;&#24320;&#21457;&#36807;&#31243;&#20013;&#20351;&#29992;&#24178;&#39044;&#36827;&#34892;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.04869</link><description>&lt;p&gt;
&#23398;&#20064;&#36890;&#36807;&#23454;&#36341;&#65306;&#20855;&#26377;&#22240;&#26524;&#24863;&#30693;&#30340;&#22312;&#32447;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Learning by Doing: An Online Causal Reinforcement Learning Framework with Causal-Aware Policy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04869
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#32447;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#20854;&#20013;&#36890;&#36807;&#26126;&#30830;&#24314;&#27169;&#29366;&#24577;&#30340;&#29983;&#25104;&#36807;&#31243;&#21644;&#20351;&#29992;&#22240;&#26524;&#32467;&#26500;&#36827;&#34892;&#31574;&#30053;&#24341;&#23548;&#65292;&#20197;&#24110;&#21161;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#30340;&#20915;&#31574;&#21487;&#35299;&#37322;&#24615;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#22312;&#25506;&#32034;&#21644;&#24320;&#21457;&#36807;&#31243;&#20013;&#20351;&#29992;&#24178;&#39044;&#36827;&#34892;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#30693;&#35782;&#20316;&#20026;&#20154;&#31867;&#26234;&#33021;&#20013;&#30452;&#35266;&#35748;&#30693;&#21644;&#25512;&#29702;&#35299;&#20915;&#26041;&#26696;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#20026;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20195;&#29702;&#30340;&#21487;&#35299;&#37322;&#24615;&#20915;&#31574;&#25552;&#20379;&#20102;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;&#24110;&#21161;&#20943;&#23569;&#25628;&#32034;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#21457;&#29616;&#21644;&#25972;&#21512;&#22240;&#26524;&#20851;&#31995;&#36827;&#20837;RL&#20173;&#23384;&#22312;&#30456;&#24403;&#22823;&#30340;&#24046;&#36317;&#65292;&#36825;&#38459;&#30861;&#20102;&#22240;&#26524;&#20851;&#31995;RL&#30340;&#24555;&#36895;&#21457;&#23637;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#22240;&#26524;&#22270;&#27169;&#22411;&#26126;&#30830;&#22320;&#24314;&#27169;&#29366;&#24577;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#22686;&#24378;&#31574;&#30053;&#12290;&#25105;&#20204;&#23558;&#22240;&#26524;&#32467;&#26500;&#26356;&#26032;&#24418;&#24335;&#21270;&#20026;&#20855;&#26377;&#20027;&#21160;&#29615;&#22659;&#24178;&#39044;&#23398;&#20064;&#30340;RL&#20132;&#20114;&#36807;&#31243;&#12290;&#20026;&#20102;&#20248;&#21270;&#34893;&#29983;&#30340;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#30340;&#26694;&#26550;&#65292;&#20004;&#20010;&#27493;&#39588;&#20132;&#26367;&#36827;&#34892;&#65306;&#22312;&#25506;&#32034;&#36807;&#31243;&#20013;&#20351;&#29992;&#24178;&#39044;&#36827;&#34892;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#65292;&#22312;&#24320;&#21457;&#36807;&#31243;&#20013;&#20351;&#29992;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#32467;&#26500;&#36827;&#34892;&#31574;&#30053;&#24341;&#23548;&#12290;&#30001;&#20110;&#32570;&#23569;&#20844;&#20849;&#22522;&#20934;&#65292;&#29992;&#20110;&#23545;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a key component to intuitive cognition and reasoning solutions in human intelligence, causal knowledge provides great potential for reinforcement learning (RL) agents' interpretability towards decision-making by helping reduce the searching space. However, there is still a considerable gap in discovering and incorporating causality into RL, which hinders the rapid development of causal RL. In this paper, we consider explicitly modeling the generation process of states with the causal graphical model, based on which we augment the policy. We formulate the causal structure updating into the RL interaction process with active intervention learning of the environment. To optimize the derived objective, we propose a framework with theoretical performance guarantees that alternates between two steps: using interventions for causal structure learning during exploration and using the learned causal structure for policy guidance during exploitation. Due to the lack of public benchmarks that 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26469;&#36924;&#36817;&#38745;&#24577;&#21644;&#21160;&#24577;&#26465;&#20214;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#35299;&#65292;&#23454;&#29616;&#20102;&#23545;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#31639;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#20256;&#36755;&#26144;&#23556;&#20197;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16975</link><description>&lt;p&gt;
&#26465;&#20214;&#26368;&#20248;&#20256;&#36755;&#30340;&#39640;&#25928;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#21450;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference. (arXiv:2310.16975v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16975
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26469;&#36924;&#36817;&#38745;&#24577;&#21644;&#21160;&#24577;&#26465;&#20214;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#35299;&#65292;&#23454;&#29616;&#20102;&#23545;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#31639;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#20256;&#36755;&#26144;&#23556;&#20197;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#20998;&#21035;&#36924;&#36817;&#38745;&#24577;&#21644;&#21160;&#24577;&#26465;&#20214;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#35299;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#20197;&#23545;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#65292;&#36825;&#26159;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#30446;&#26631;&#26465;&#20214;&#20998;&#24067;&#34920;&#31034;&#20026;&#21487;&#22788;&#29702;&#30340;&#21442;&#32771;&#20998;&#24067;&#30340;&#36716;&#25442;&#65292;&#22240;&#27492;&#23646;&#20110;&#27979;&#24230;&#20256;&#36755;&#30340;&#26694;&#26550;&#12290;&#22312;&#35813;&#26694;&#26550;&#20013;&#65292;COT&#26144;&#23556;&#26159;&#19968;&#20010;&#20856;&#22411;&#30340;&#36873;&#25321;&#65292;&#20855;&#26377;&#21807;&#19968;&#24615;&#21644;&#21333;&#35843;&#24615;&#31561;&#21487;&#21462;&#30340;&#23646;&#24615;&#12290;&#28982;&#32780;&#65292;&#30456;&#20851;&#30340;COT&#38382;&#39064;&#22312;&#20013;&#31561;&#32500;&#24230;&#19979;&#35745;&#31639;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#30340;&#25968;&#20540;&#31639;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;COT&#26144;&#23556;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20805;&#20998;&#21033;&#29992;&#20102;COT&#38382;&#39064;&#30340;&#38745;&#24577;&#21644;&#21160;&#24577;&#34920;&#36798;&#24418;&#24335;&#30340;&#32467;&#26500;&#12290;PCP-Map&#23558;&#26465;&#20214;&#20256;&#36755;&#26144;&#23556;&#24314;&#27169;&#20026;&#37096;&#20998;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#65288;PICNN&#65289;&#30340;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present two neural network approaches that approximate the solutions of static and dynamic conditional optimal transport (COT) problems, respectively. Both approaches enable sampling and density estimation of conditional probability distributions, which are core tasks in Bayesian inference. Our methods represent the target conditional distributions as transformations of a tractable reference distribution and, therefore, fall into the framework of measure transport. COT maps are a canonical choice within this framework, with desirable properties such as uniqueness and monotonicity. However, the associated COT problems are computationally challenging, even in moderate dimensions. To improve the scalability, our numerical algorithms leverage neural networks to parameterize COT maps. Our methods exploit the structure of the static and dynamic formulations of the COT problem. PCP-Map models conditional transport maps as the gradient of a partially input convex neural network (PICNN) and 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#26041;&#27861;&#65288;MCF&#65289;&#65292;&#29992;&#20110;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#19979;&#30340;&#25968;&#25454;&#32858;&#31867;&#65292;&#20854;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;&#21487;&#27979;&#37327;&#20998;&#21306;&#24207;&#21015;&#30340;&#23618;&#27425;&#20851;&#31995;&#21644;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2305.04281</link><description>&lt;p&gt;
&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;
&lt;/p&gt;
&lt;p&gt;
Persistent Homology of the Multiscale Clustering Filtration. (arXiv:2305.04281v2 [math.AT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04281
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#26041;&#27861;&#65288;MCF&#65289;&#65292;&#29992;&#20110;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#19979;&#30340;&#25968;&#25454;&#32858;&#31867;&#65292;&#20854;&#20013;&#30340;&#25345;&#20037;&#21516;&#35843;&#21487;&#27979;&#37327;&#20998;&#21306;&#24207;&#21015;&#30340;&#23618;&#27425;&#20851;&#31995;&#21644;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#25968;&#25454;&#32858;&#31867;&#24212;&#29992;&#20013;&#65292;&#19981;&#20165;&#24076;&#26395;&#25214;&#21040;&#19968;&#31181;&#21333;&#19968;&#30340;&#20998;&#21306;&#26041;&#24335;&#65292;&#36824;&#24076;&#26395;&#25214;&#21040;&#25551;&#36848;&#19981;&#21516;&#23610;&#24230;&#25110;&#31895;&#31961;&#23618;&#27425;&#19979;&#30340;&#25968;&#25454;&#30340;&#19968;&#31995;&#21015;&#20998;&#21306;&#26041;&#24335;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#26159;&#20998;&#26512;&#21644;&#27604;&#36739;&#25903;&#25745;&#36825;&#31181;&#22810;&#23610;&#24230;&#25968;&#25454;&#25551;&#36848;&#30340;&#65288;&#19981;&#19968;&#23450;&#26159;&#23618;&#27425;&#24615;&#30340;&#65289;&#20998;&#21306;&#24207;&#21015;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#25277;&#35937;&#21333;&#32431;&#22797;&#24418;&#30340;&#36807;&#28388;&#65292;&#31216;&#20026;&#22810;&#23610;&#24230;&#32858;&#31867;&#36807;&#28388;&#65288;MCF&#65289;&#65292;&#23427;&#32534;&#30721;&#20102;&#36328;&#23610;&#24230;&#30340;&#20219;&#24847;&#27169;&#24335;&#30340;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#35777;&#26126;&#20102;MCF&#20135;&#29983;&#31283;&#23450;&#30340;&#25345;&#20037;&#22270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MCF&#30340;&#38646;&#32500;&#25345;&#20037;&#21516;&#35843;&#27979;&#37327;&#20102;&#20998;&#21306;&#24207;&#21015;&#20013;&#30340;&#23618;&#27425;&#20851;&#31995;&#31243;&#24230;&#65292;&#32780;&#39640;&#32500;&#25345;&#20037;&#21516;&#35843;&#21017;&#36319;&#36394;&#20102;&#20998;&#21306;&#24207;&#21015;&#20013;&#32858;&#31867;&#20998;&#37197;&#20914;&#31361;&#30340;&#20986;&#29616;&#21644;&#35299;&#20915;&#12290;&#20026;&#20102;&#25299;&#23485;MCF&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#31561;&#20215;&#30340;&#26500;&#36896;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many applications in data clustering, it is desirable to find not just a single partition into clusters but a sequence of partitions describing the data at different scales, or levels of coarseness. A natural problem then is to analyse and compare the (not necessarily hierarchical) sequences of partitions that underpin such multiscale descriptions of data. Here, we introduce a filtration of abstract simplicial complexes, denoted the Multiscale Clustering Filtration (MCF), which encodes arbitrary patterns of cluster assignments across scales, and we prove that the MCF produces stable persistence diagrams. We then show that the zero-dimensional persistent homology of the MCF measures the degree of hierarchy in the sequence of partitions, and that the higher-dimensional persistent homology tracks the emergence and resolution of conflicts between cluster assignments across the sequence of partitions. To broaden the theoretical foundations of the MCF, we also provide an equivalent constr
&lt;/p&gt;</description></item></channel></rss>