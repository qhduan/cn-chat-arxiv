<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934; ELITR-Bench&#65292;&#19987;&#27880;&#20110;&#38271;&#19978;&#19979;&#25991;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#38469;&#20250;&#35758;&#21161;&#29702;&#22330;&#26223;&#65292;&#36890;&#36807;&#22312;&#29616;&#26377; ELITR &#35821;&#26009;&#24211;&#30340;&#36716;&#24405;&#20013;&#28155;&#21152;&#25163;&#24037;&#21046;&#20316;&#30340;&#38382;&#39064;&#21644;&#30495;&#23454;&#31572;&#26696;&#65292;&#25581;&#31034;&#20102;&#24320;&#28304;&#27169;&#22411;&#21644;&#19987;&#26377;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.20262</link><description>&lt;p&gt;
ELITR-Bench: &#38754;&#21521;&#38271;&#19978;&#19979;&#25991;&#35821;&#35328;&#27169;&#22411;&#30340;&#20250;&#35758;&#21161;&#29702;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20262
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934; ELITR-Bench&#65292;&#19987;&#27880;&#20110;&#38271;&#19978;&#19979;&#25991;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#38469;&#20250;&#35758;&#21161;&#29702;&#22330;&#26223;&#65292;&#36890;&#36807;&#22312;&#29616;&#26377; ELITR &#35821;&#26009;&#24211;&#30340;&#36716;&#24405;&#20013;&#28155;&#21152;&#25163;&#24037;&#21046;&#20316;&#30340;&#38382;&#39064;&#21644;&#30495;&#23454;&#31572;&#26696;&#65292;&#25581;&#31034;&#20102;&#24320;&#28304;&#27169;&#22411;&#21644;&#19987;&#26377;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#30740;&#31350;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#65292;&#20027;&#35201;&#33268;&#21147;&#20110;&#25193;&#23637;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#22823;&#23567;&#65292;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#38271;&#25991;&#26723;&#20869;&#37096;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272;&#38271;&#36317;&#31163;&#33021;&#21147;&#30340;&#22522;&#20934;&#65292;&#20294;&#29616;&#26377;&#30340;&#21162;&#21147;&#20027;&#35201;&#32771;&#34385;&#30340;&#26159;&#19981;&#19968;&#23450;&#19982;&#29616;&#23454;&#24212;&#29992;&#30456;&#20851;&#30340;&#36890;&#29992;&#20219;&#21153;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#23454;&#38469;&#20250;&#35758;&#21161;&#29702;&#22330;&#26223;&#30340;&#38271;&#19978;&#19979;&#25991;LLMs&#30340;&#26032;&#22522;&#20934;&#12290;&#22312;&#36825;&#31181;&#24773;&#26223;&#19979;&#65292;&#38271;&#19978;&#19979;&#25991;&#30001;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#33719;&#24471;&#30340;&#36716;&#24405;&#32452;&#25104;&#65292;&#30001;&#20110;&#36825;&#20123;&#25968;&#25454;&#30340;&#22266;&#26377;&#22024;&#26434;&#24615;&#21644;&#21475;&#35821;&#29305;&#24615;&#65292;&#36825;&#20026;LLMs&#25552;&#20986;&#20102;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#65292;&#21517;&#20026;ELITR-Bench&#65292;&#36890;&#36807;271&#20010;&#25163;&#24037;&#21046;&#20316;&#30340;&#38382;&#39064;&#21450;&#20854;&#30495;&#23454;&#31572;&#26696;&#26469;&#22686;&#24378;&#29616;&#26377;&#30340;ELITR&#35821;&#26009;&#24211;&#30340;&#36716;&#24405;&#12290;&#25105;&#20204;&#22312;ELITR-Bench&#19978;&#23545;&#26368;&#26032;&#30340;&#38271;&#19978;&#19979;&#25991;LLMs&#36827;&#34892;&#30340;&#23454;&#39564;&#20984;&#26174;&#20102;&#24320;&#28304;&#27169;&#22411;&#21644;&#19987;&#26377;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20262v1 Announce Type: cross  Abstract: Research on Large Language Models (LLMs) has recently witnessed an increasing interest in extending models' context size to better capture dependencies within long documents. While benchmarks have been proposed to assess long-range abilities, existing efforts primarily considered generic tasks that are not necessarily aligned with real-world applications. In contrast, our work proposes a new benchmark for long-context LLMs focused on a practical meeting assistant scenario. In this scenario, the long contexts consist of transcripts obtained by automatic speech recognition, presenting unique challenges for LLMs due to the inherent noisiness and oral nature of such data. Our benchmark, named ELITR-Bench, augments the existing ELITR corpus' transcripts with 271 manually crafted questions and their ground-truth answers. Our experiments with recent long-context LLMs on ELITR-Bench highlight a gap between open-source and proprietary models, e
&lt;/p&gt;</description></item><item><title>&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#25104;&#23545;&#20559;&#22909;&#25628;&#32034;&#26041;&#27861;PAIRS&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;LLMs&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#20248;&#20110;&#30452;&#25509;&#25171;&#20998;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.16950</link><description>&lt;p&gt;
&#19982;&#20154;&#31867;&#21028;&#26029;&#30456;&#19968;&#33268;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#25104;&#23545;&#20559;&#22909;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16950
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#25104;&#23545;&#20559;&#22909;&#25628;&#32034;&#26041;&#27861;PAIRS&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;LLMs&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#20248;&#20110;&#30452;&#25509;&#25171;&#20998;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#33258;&#21160;&#35780;&#20272;&#22120;&#22312;&#35780;&#20272;&#29983;&#25104;&#30340;&#33258;&#28982;&#35821;&#35328;&#36136;&#37327;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;LLMs&#22312;&#35780;&#20272;&#20013;&#20173;&#23384;&#22312;&#20559;&#35265;&#65292;&#24120;&#24120;&#38590;&#20197;&#29983;&#25104;&#19982;&#20154;&#31867;&#35780;&#20272;&#19968;&#33268;&#30340;&#36830;&#36143;&#35780;&#20272;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;LLM&#35780;&#20272;&#22120;&#19982;&#20154;&#31867;&#21028;&#26029;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#36827;&#34892;&#31995;&#32479;&#30740;&#31350;&#65292;&#25581;&#31034;&#29616;&#26377;&#26088;&#22312;&#20943;&#36731;&#20559;&#35265;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#36275;&#20197;&#26377;&#25928;&#23558;LLM&#35780;&#20272;&#22120;&#23545;&#40784;&#12290;&#21463;&#21040;RLHF&#20013;&#23545;&#20559;&#22909;&#25968;&#25454;&#30340;&#20351;&#29992;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#35780;&#20272;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#25490;&#24207;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;Pairwise-preference Search&#65288;PAIRS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20197;LLMs&#36827;&#34892;&#25104;&#23545;&#27604;&#36739;&#24182;&#26377;&#25928;&#23545;&#20505;&#36873;&#25991;&#26412;&#36827;&#34892;&#25490;&#24207;&#30340;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#24341;&#23548;&#30340;&#25628;&#32034;&#26041;&#27861;&#12290;PAIRS&#22312;&#20195;&#34920;&#24615;&#35780;&#20272;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#26174;&#31034;&#20986;&#27604;&#30452;&#25509;&#25171;&#20998;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16950v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated promising capabilities as automatic evaluators in assessing the quality of generated natural language. However, LLMs still exhibit biases in evaluation and often struggle to generate coherent evaluations that align with human assessments. In this work, we first conduct a systematic study of the misalignment between LLM evaluators and human judgement, revealing that existing calibration methods aimed at mitigating biases are insufficient for effectively aligning LLM evaluators. Inspired by the use of preference data in RLHF, we formulate the evaluation as a ranking problem and introduce Pairwise-preference Search (PAIRS), an uncertainty-guided search method that employs LLMs to conduct pairwise comparisons and efficiently ranks candidate texts. PAIRS achieves state-of-the-art performance on representative evaluation tasks and demonstrates significant improvements over direct scoring. Furthe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#20849;&#20139;&#24494;&#31227;&#21160;&#26381;&#21153;&#36816;&#33829;&#19982;&#25511;&#21046;&#20013;&#23454;&#29616;&#24615;&#33021;&#20248;&#21270;&#21644;&#31639;&#27861;&#20844;&#24179;&#24615;&#24179;&#34913;&#30340;&#21069;&#27839;&#35843;&#26597;&#65292;&#21033;&#29992;Q-Learning&#31639;&#27861;&#30830;&#20445;&#26041;&#27861;&#31283;&#20581;&#65292;&#33021;&#22815;&#23454;&#29616;&#21508;&#31181;&#31449;&#28857;&#31867;&#21035;&#20043;&#38388;&#30340;&#20844;&#24179;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.15780</link><description>&lt;p&gt;
&#38754;&#21521;&#20844;&#24179;&#24615;&#30340;&#20849;&#20139;&#24494;&#31227;&#21160;&#26381;&#21153;&#36816;&#33829;&#19982;&#25511;&#21046;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Fairness-Oriented Reinforcement Learning Approach for the Operation and Control of Shared Micromobility Services
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#20849;&#20139;&#24494;&#31227;&#21160;&#26381;&#21153;&#36816;&#33829;&#19982;&#25511;&#21046;&#20013;&#23454;&#29616;&#24615;&#33021;&#20248;&#21270;&#21644;&#31639;&#27861;&#20844;&#24179;&#24615;&#24179;&#34913;&#30340;&#21069;&#27839;&#35843;&#26597;&#65292;&#21033;&#29992;Q-Learning&#31639;&#27861;&#30830;&#20445;&#26041;&#27861;&#31283;&#20581;&#65292;&#33021;&#22815;&#23454;&#29616;&#21508;&#31181;&#31449;&#28857;&#31867;&#21035;&#20043;&#38388;&#30340;&#20844;&#24179;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#22312;&#21508;&#31181;&#24212;&#29992;&#39046;&#22495;&#21464;&#24471;&#26085;&#30410;&#26222;&#36941;&#65292;&#21253;&#25324;&#37027;&#20123;&#30452;&#25509;&#28041;&#21450;&#20154;&#31867;&#30340;&#39046;&#22495;&#65292;&#24179;&#31561;&#21644;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24517;&#35201;&#24615;&#22312;&#20154;&#24037;&#26234;&#33021;&#30028;&#24840;&#21457;&#31361;&#20986;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22312;&#20849;&#20139;&#24494;&#31227;&#21160;&#31995;&#32479;&#30340;&#32972;&#26223;&#19979;&#65292;&#20844;&#24179;&#24615;&#23548;&#21521;&#26041;&#27861;&#30340;&#25506;&#32034;&#20173;&#28982;&#26377;&#38480;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#39033;&#25506;&#35752;&#24615;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#20849;&#20139;&#24494;&#31227;&#21160;&#26381;&#21153;&#36816;&#33829;&#19982;&#25511;&#21046;&#20013;&#24615;&#33021;&#20248;&#21270;&#19982;&#31639;&#27861;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#36816;&#29992;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;Q-Learning&#31639;&#27861;&#65292;&#21033;&#29992;&#20854;&#25910;&#25947;&#20445;&#35777;&#26469;&#30830;&#20445;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#31283;&#20581;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#21516;&#31449;&#28857;&#31867;&#21035;&#65288;&#20013;&#24515;&#12289;&#36793;&#32536;&#21644;&#36828;&#31243;&#65289;&#20043;&#38388;&#33021;&#22815;&#23454;&#29616;&#20844;&#24179;&#30340;&#32467;&#26524;&#65292;&#36825;&#26159;&#36890;&#36807;&#22522;&#23612;&#31995;&#25968;&#26469;&#34913;&#37327;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15780v1 Announce Type: cross  Abstract: As Machine Learning systems become increasingly popular across diverse application domains, including those with direct human implications, the imperative of equity and algorithmic fairness has risen to prominence in the Artificial Intelligence community. On the other hand, in the context of Shared Micromobility Systems, the exploration of fairness-oriented approaches remains limited. Addressing this gap, we introduce a pioneering investigation into the balance between performance optimization and algorithmic fairness in the operation and control of Shared Micromobility Services. Our study leverages the Q-Learning algorithm in Reinforcement Learning, benefiting from its convergence guarantees to ensure the robustness of our proposed approach. Notably, our methodology stands out for its ability to achieve equitable outcomes, as measured by the Gini index, across different station categories--central, peripheral, and remote. Through stra
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;TCM&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#22312;&#20027;&#21160;&#23398;&#20064;&#20013;&#25104;&#21151;&#32467;&#21512;&#20102;&#22810;&#26679;&#24615;&#37319;&#26679;&#21644;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20919;&#21551;&#21160;&#38382;&#39064;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#27700;&#24179;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>https://arxiv.org/abs/2403.03728</link><description>&lt;p&gt;
&#36890;&#36807;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#22312;&#20027;&#21160;&#23398;&#20064;&#20013;&#24357;&#21512;&#22810;&#26679;&#24615;&#19982;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Bridging Diversity and Uncertainty in Active learning with Self-Supervised Pre-Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03728
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;TCM&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#22312;&#20027;&#21160;&#23398;&#20064;&#20013;&#25104;&#21151;&#32467;&#21512;&#20102;&#22810;&#26679;&#24615;&#37319;&#26679;&#21644;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20919;&#21551;&#21160;&#38382;&#39064;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#27700;&#24179;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20027;&#21160;&#23398;&#20064;&#20013;&#38598;&#25104;&#22522;&#20110;&#22810;&#26679;&#24615;&#21644;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#37319;&#26679;&#31574;&#30053;&#65292;&#29305;&#21035;&#26159;&#22312;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31216;&#20026;TCM&#30340;&#31616;&#21333;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#21487;&#20197;&#32531;&#35299;&#20919;&#21551;&#21160;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#21508;&#31181;&#25968;&#25454;&#27700;&#24179;&#19978;&#20445;&#25345;&#24378;&#22823;&#24615;&#33021;&#12290;&#36890;&#36807;&#39318;&#20808;&#24212;&#29992;TypiClust&#36827;&#34892;&#22810;&#26679;&#24615;&#37319;&#26679;&#65292;&#38543;&#21518;&#36807;&#28193;&#21040;&#20351;&#29992;Margin&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#32467;&#21512;&#20102;&#20004;&#31181;&#31574;&#30053;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;TCM&#22312;&#20302;&#25968;&#25454;&#21644;&#39640;&#25968;&#25454;&#24773;&#20917;&#19979;&#22987;&#32456;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03728v1 Announce Type: cross  Abstract: This study addresses the integration of diversity-based and uncertainty-based sampling strategies in active learning, particularly within the context of self-supervised pre-trained models. We introduce a straightforward heuristic called TCM that mitigates the cold start problem while maintaining strong performance across various data levels. By initially applying TypiClust for diversity sampling and subsequently transitioning to uncertainty sampling with Margin, our approach effectively combines the strengths of both strategies. Our experiments demonstrate that TCM consistently outperforms existing methods across various datasets in both low and high data regimes.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20855;&#26377;&#26032;&#39062;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#39318;&#27425;&#22312;&#27969;&#24335;&#35774;&#32622;&#20013;&#20026;&#40065;&#26834;ReLU&#22238;&#24402;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.01204</link><description>&lt;p&gt;
&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#27969;&#24335;&#32447;&#24615;&#21644;&#20462;&#27491;&#32447;&#24615;&#31995;&#32479;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient descent for streaming linear and rectified linear systems with Massart noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01204
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20855;&#26377;&#26032;&#39062;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#39318;&#27425;&#22312;&#27969;&#24335;&#35774;&#32622;&#20013;&#20026;&#40065;&#26834;ReLU&#22238;&#24402;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;SGD-exp&#65292;&#19968;&#31181;&#29992;&#20110;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#22312;Massart&#22122;&#22768;&#65288;&#23545;&#25239;&#24615;&#21322;&#38543;&#26426;&#30772;&#22351;&#27169;&#22411;&#65289;&#19979;&#65292;&#23436;&#20840;&#27969;&#24335;&#35774;&#32622;&#19979;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;SGD-exp&#23545;&#30495;&#23454;&#21442;&#25968;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#26368;&#39640;&#21487;&#36798;50%&#30340;Massart&#30772;&#22351;&#29575;&#65292;&#22312;&#23545;&#31216;&#26080;&#24551;&#30772;&#22351;&#24773;&#20917;&#19979;&#65292;&#20219;&#24847;&#30772;&#22351;&#29575;&#20063;&#26377;&#20445;&#35777;&#12290;&#36825;&#26159;&#27969;&#24335;&#35774;&#32622;&#20013;&#40065;&#26834;ReLU&#22238;&#24402;&#30340;&#31532;&#19968;&#20010;&#25910;&#25947;&#20445;&#35777;&#32467;&#26524;&#65292;&#23427;&#26174;&#31034;&#20102;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#40065;&#26834;&#26041;&#27861;&#23545;&#20110;L1&#32447;&#24615;&#22238;&#24402;&#20855;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#36825;&#26159;&#30001;&#20110;&#36873;&#25321;&#20102;&#25351;&#25968;&#34928;&#20943;&#27493;&#38271;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#30340;&#28418;&#31227;&#20998;&#26512;&#65292;&#36825;&#26412;&#36523;&#20063;&#21487;&#33021;&#26159;&#26377;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01204v1 Announce Type: new  Abstract: We propose SGD-exp, a stochastic gradient descent approach for linear and ReLU regressions under Massart noise (adversarial semi-random corruption model) for the fully streaming setting. We show novel nearly linear convergence guarantees of SGD-exp to the true parameter with up to $50\%$ Massart corruption rate, and with any corruption rate in the case of symmetric oblivious corruptions. This is the first convergence guarantee result for robust ReLU regression in the streaming setting, and it shows the improved convergence rate over previous robust methods for $L_1$ linear regression due to a choice of an exponentially decaying step size, known for its efficiency in practice. Our analysis is based on the drift analysis of a discrete stochastic process, which could also be interesting on its own.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#8220;&#32431;&#31929;&#35843;&#20248;&#65292;&#23433;&#20840;&#27979;&#35797;&#8221;&#65288;PTST&#65289;&#21407;&#21017;&#65292;&#21363;&#22312;&#24494;&#35843;&#26102;&#19981;&#21253;&#21547;&#23433;&#20840;&#25552;&#31034;&#65292;&#20294;&#22312;&#27979;&#35797;&#26102;&#21152;&#20837;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;LLMs&#20013;&#19981;&#23433;&#20840;&#34892;&#20026;&#30340;&#20986;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.18540</link><description>&lt;p&gt;
&#22312;&#24494;&#35843;&#21518;&#20445;&#25345;LLMs&#30340;&#23545;&#40784;&#24615;:&#25552;&#31034;&#27169;&#26495;&#30340;&#20851;&#38190;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18540
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#8220;&#32431;&#31929;&#35843;&#20248;&#65292;&#23433;&#20840;&#27979;&#35797;&#8221;&#65288;PTST&#65289;&#21407;&#21017;&#65292;&#21363;&#22312;&#24494;&#35843;&#26102;&#19981;&#21253;&#21547;&#23433;&#20840;&#25552;&#31034;&#65292;&#20294;&#22312;&#27979;&#35797;&#26102;&#21152;&#20837;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;LLMs&#20013;&#19981;&#23433;&#20840;&#34892;&#20026;&#30340;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#20849;LLMs&#65292;&#22914;Llama 2-Chat&#65292;&#25512;&#21160;&#20102;LLM&#30740;&#31350;&#30340;&#24040;&#22823;&#27963;&#21160;&#12290;&#36825;&#20123;&#27169;&#22411;&#32463;&#21382;&#20102;&#23545;&#40784;&#24615;&#35757;&#32451;&#65292;&#34987;&#35748;&#20026;&#26159;&#23433;&#20840;&#30340;&#12290;&#26368;&#36817;&#65292;&#40784;&#31561;&#20154;&#65288;2023&#24180;&#65289;&#25253;&#21578;&#31216;&#65292;&#21363;&#20351;&#26159;&#33391;&#24615;&#30340;&#24494;&#35843;&#65288;&#20363;&#22914;&#65292;&#22312;&#30475;&#20284;&#23433;&#20840;&#30340;&#25968;&#25454;&#38598;&#19978;&#65289;&#20063;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#20135;&#29983;&#19981;&#23433;&#20840;&#30340;&#34892;&#20026;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20943;&#36731;&#36825;&#31181;&#23545;&#40784;&#24615;&#20002;&#22833;&#30340;&#26041;&#27861;&#21644;&#26368;&#20339;&#23454;&#36341;&#12290;&#36890;&#36807;&#23545;&#20960;&#20010;&#32842;&#22825;&#27169;&#22411;&#65288;Meta&#30340;Llama 2-Chat&#65292;Mistral AI&#30340;Mistral 7B Instruct v0.2&#21644;OpenAI&#30340;GPT-3.5 Turbo&#65289;&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#26412;&#25991;&#21457;&#29616;&#24494;&#35843;&#21644;&#25512;&#29702;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;&#25552;&#31034;&#27169;&#26495;&#22312;&#20445;&#25345;&#23433;&#20840;&#23545;&#40784;&#24615;&#26041;&#38754;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#8220;&#32431;&#31929;&#35843;&#20248;&#65292;&#23433;&#20840;&#27979;&#35797;&#8221;&#65288;PTST&#65289;&#21407;&#21017; - &#22312;&#27979;&#35797;&#26102;&#19981;&#20351;&#29992;&#23433;&#20840;&#25552;&#31034;&#36827;&#34892;&#27169;&#22411;&#24494;&#35843;&#65292;&#20294;&#22312;&#27979;&#35797;&#26102;&#21253;&#21547;&#23427;&#12290;&#23545;GSM8K&#65292;ChatDoctor&#21644;OpenOrca&#36827;&#34892;&#30340;&#24494;&#35843;&#23454;&#39564;&#34920;&#26126;&#65292;PTST&#26174;&#30528;&#20943;&#23569;&#20102;&#19981;&#23433;&#20840;&#34892;&#20026;&#30340;&#22686;&#21152;&#65292;&#29978;&#33267;&#20960;&#20046;&#28040;&#38500;&#20102;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18540v1 Announce Type: cross  Abstract: Public LLMs such as the Llama 2-Chat have driven huge activity in LLM research. These models underwent alignment training and were considered safe. Recently Qi et al. (2023) reported that even benign fine-tuning (e.g., on seemingly safe datasets) can give rise to unsafe behaviors in the models. The current paper is about methods and best practices to mitigate such loss of alignment. Through extensive experiments on several chat models (Meta's Llama 2-Chat, Mistral AI's Mistral 7B Instruct v0.2, and OpenAI's GPT-3.5 Turbo), this paper uncovers that the prompt templates used during fine-tuning and inference play a crucial role in preserving safety alignment, and proposes the "Pure Tuning, Safe Testing" (PTST) principle -- fine-tune models without a safety prompt, but include it at test time. Fine-tuning experiments on GSM8K, ChatDoctor, and OpenOrca show that PTST significantly reduces the rise of unsafe behaviors, and even almost elimin
&lt;/p&gt;</description></item><item><title>Anfinsen Goes Neural (AGN) is a graphical model for conditional antibody design that combines a pre-trained protein language model with a graph neural network. It outperforms existing methods and addresses the limitation of generating unrealistic sequences.</title><link>https://arxiv.org/abs/2402.05982</link><description>&lt;p&gt;
Anfinsen Goes Neural: &#19968;&#31181;&#29992;&#20110;&#26465;&#20214;&#25239;&#20307;&#35774;&#35745;&#30340;&#22270;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Anfinsen Goes Neural: a Graphical Model for Conditional Antibody Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05982
&lt;/p&gt;
&lt;p&gt;
Anfinsen Goes Neural (AGN) is a graphical model for conditional antibody design that combines a pre-trained protein language model with a graph neural network. It outperforms existing methods and addresses the limitation of generating unrealistic sequences.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25239;&#20307;&#35774;&#35745;&#22312;&#25512;&#21160;&#27835;&#30103;&#23398;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#22312;&#36825;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#24555;&#36895;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#23545;&#19968;&#33324;&#34507;&#30333;&#36136;&#30693;&#35782;&#30340;&#21033;&#29992;&#26377;&#38480;&#65292;&#24182;&#20551;&#35774;&#22270;&#27169;&#22411;&#36829;&#21453;&#34507;&#30333;&#36136;&#30340;&#32463;&#39564;&#21457;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Anfinsen Goes Neural (AGN)&#65292;&#36825;&#26159;&#19968;&#20010;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#34507;&#30333;&#36136;&#35821;&#35328;&#27169;&#22411;(pLM)&#24182;&#32534;&#30721;&#20102;&#19968;&#31181;&#20851;&#20110;&#34507;&#30333;&#36136;&#30340;&#37325;&#35201;&#21457;&#29616;&#65292;&#21363;Anfinsen's dogma&#30340;&#22270;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36981;&#24490;&#24207;&#21015;&#29983;&#25104;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;(GNN)&#36827;&#34892;&#32467;&#26500;&#39044;&#27979;&#30340;&#20004;&#27493;&#36807;&#31243;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22522;&#20934;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;&#38750;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#19968;&#20010;&#20851;&#38190;&#38480;&#21046;&#65292;&#21363;&#23427;&#20204;&#20542;&#21521;&#20110;&#29983;&#25104;&#20855;&#26377;&#36807;&#22810;&#37325;&#22797;&#26631;&#35760;&#30340;&#19981;&#29616;&#23454;&#24207;&#21015;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#32452;&#21512;&#30340;&#27491;&#21017;&#21270;&#39033;&#21040;&#20132;&#21449;&#29109;&#30446;&#26631;&#20013;&#65292;&#21487;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Antibody design plays a pivotal role in advancing therapeutics. Although deep learning has made rapid progress in this field, existing methods make limited use of general protein knowledge and assume a graphical model (GM) that violates empirical findings on proteins. To address these limitations, we present Anfinsen Goes Neural (AGN), a graphical model that uses a pre-trained protein language model (pLM) and encodes a seminal finding on proteins called Anfinsen's dogma. Our framework follows a two-step process of sequence generation with pLM and structure prediction with graph neural network (GNN). Experiments show that our approach outperforms state-of-the-art results on benchmark experiments. We also address a critical limitation of non-autoregressive models -- namely, that they tend to generate unrealistic sequences with overly repeating tokens. To resolve this, we introduce a composition-based regularization term to the cross-entropy objective that allows an efficient trade-off be
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#27604;&#20102;&#20256;&#32479;&#30340;&#8220;&#20915;&#23450;&#24615;AI x-risk&#20551;&#35774;&#8221;&#19982;&#8220;&#32047;&#31215;&#24615;AI x-risk&#20551;&#35774;&#8221;&#65292;&#25351;&#20986;&#20154;&#24037;&#26234;&#33021;&#21487;&#33021;&#24102;&#26469;&#30340;&#28781;&#32477;&#24615;&#28798;&#38590;&#26377;&#20004;&#31181;&#21487;&#33021;&#36335;&#24452;&#65306;&#19968;&#31181;&#26159;&#31361;&#28982;&#21457;&#29983;&#30340;AI&#25509;&#31649;&#65292;&#21478;&#19968;&#31181;&#26159;&#36880;&#28176;&#31215;&#32047;&#30340;&#23041;&#32961;&#12290;</title><link>https://arxiv.org/abs/2401.07836</link><description>&lt;p&gt;
&#20004;&#31181;&#31867;&#22411;&#30340;&#20154;&#24037;&#26234;&#33021;&#23384;&#22312;&#39118;&#38505;&#65306;&#20915;&#23450;&#24615;&#21644;&#32047;&#31215;&#24615;
&lt;/p&gt;
&lt;p&gt;
Two Types of AI Existential Risk: Decisive and Accumulative
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.07836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#27604;&#20102;&#20256;&#32479;&#30340;&#8220;&#20915;&#23450;&#24615;AI x-risk&#20551;&#35774;&#8221;&#19982;&#8220;&#32047;&#31215;&#24615;AI x-risk&#20551;&#35774;&#8221;&#65292;&#25351;&#20986;&#20154;&#24037;&#26234;&#33021;&#21487;&#33021;&#24102;&#26469;&#30340;&#28781;&#32477;&#24615;&#28798;&#38590;&#26377;&#20004;&#31181;&#21487;&#33021;&#36335;&#24452;&#65306;&#19968;&#31181;&#26159;&#31361;&#28982;&#21457;&#29983;&#30340;AI&#25509;&#31649;&#65292;&#21478;&#19968;&#31181;&#26159;&#36880;&#28176;&#31215;&#32047;&#30340;&#23041;&#32961;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#23545;&#20154;&#24037;&#26234;&#33021;(AI)&#24341;&#36215;&#30340;&#23384;&#22312;&#39118;&#38505;(x-risks)&#30340;&#35752;&#35770;&#36890;&#24120;&#38598;&#20013;&#22312;&#30001;&#20808;&#36827;&#30340;AI&#31995;&#32479;&#24341;&#36215;&#30340;&#31361;&#28982;&#12289;&#20005;&#37325;&#20107;&#20214;&#19978;&#65292;&#23588;&#20854;&#26159;&#37027;&#20123;&#21487;&#33021;&#36798;&#21040;&#25110;&#36229;&#36807;&#20154;&#31867;&#27700;&#24179;&#26234;&#33021;&#30340;&#31995;&#32479;&#12290;&#36825;&#20123;&#20107;&#20214;&#23558;&#24102;&#26469;&#20005;&#37325;&#21518;&#26524;&#65292;&#35201;&#20040;&#23548;&#33268;&#20154;&#31867;&#28781;&#32477;&#65292;&#35201;&#20040;&#26080;&#27861;&#36870;&#36716;&#22320;&#20351;&#20154;&#31867;&#25991;&#26126;&#38519;&#20837;&#26080;&#27861;&#24674;&#22797;&#30340;&#29366;&#24577;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35752;&#35770;&#32463;&#24120;&#24573;&#35270;AI x-risk&#36880;&#28176;&#36890;&#36807;&#19968;&#31995;&#21015;&#36739;&#23567;&#20294;&#30456;&#20114;&#20851;&#32852;&#30340;&#20013;&#26029;&#36880;&#28176;&#26174;&#29616;&#20986;&#26469;&#30340;&#20005;&#37325;&#21487;&#33021;&#24615;&#65292;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#36880;&#28176;&#36328;&#36234;&#20851;&#38190;&#38408;&#20540;&#12290;&#35813;&#35770;&#25991;&#23558;&#20256;&#32479;&#30340;&#8220;&#20915;&#23450;&#24615;AI x-risk&#20551;&#35774;&#8221;&#19982;&#8220;&#32047;&#31215;&#24615;AI x-risk&#20551;&#35774;&#8221;&#36827;&#34892;&#23545;&#27604;&#12290;&#21069;&#32773;&#25551;&#32472;&#20102;&#19968;&#31181;&#26126;&#26174;&#30340;AI&#25509;&#31649;&#36335;&#24452;&#65292;&#20854;&#29305;&#24449;&#26159;&#26080;&#27861;&#25511;&#21046;&#30340;&#36229;&#32423;&#26234;&#33021;&#31561;&#24773;&#26223;&#65292;&#32780;&#21518;&#32773;&#21017;&#25552;&#20986;&#20102;&#21478;&#19968;&#31181;&#23548;&#33268;&#28781;&#32477;&#24615;&#28798;&#38590;&#30340;&#22240;&#26524;&#36335;&#24452;&#12290;&#36825;&#28041;&#21450;&#21040;&#30001;AI&#24341;&#36215;&#30340;&#20005;&#37325;&#23041;&#32961;&#30340;&#36880;&#28176;&#32047;&#31215;&#65292;&#20363;&#22914;&#20005;&#37325;&#30340;&#28431;&#27934;&#21644;&#31995;&#32479;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
The conventional discourse on existential risks (x-risks) from AI typically focuses on abrupt, dire events caused by advanced AI systems, particularly those that might achieve or surpass human-level intelligence. These events have severe consequences that either lead to human extinction or irreversibly cripple human civilization to a point beyond recovery. This discourse, however, often neglects the serious possibility of AI x-risks manifesting incrementally through a series of smaller yet interconnected disruptions, gradually crossing critical thresholds over time. This paper contrasts the conventional "decisive AI x-risk hypothesis" with an "accumulative AI x-risk hypothesis." While the former envisions an overt AI takeover pathway, characterized by scenarios like uncontrollable superintelligence, the latter suggests a different causal pathway to existential catastrophes. This involves a gradual accumulation of critical AI-induced threats such as severe vulnerabilities and systemic e
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#23545;&#39057;&#29575;-&#20005;&#37325;&#24615;&#20445;&#38505;&#23450;&#20215;&#36827;&#34892;&#20102;&#22522;&#20934;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#19981;&#21516;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;(CANN)&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.12671</link><description>&lt;p&gt;
&#21033;&#29992;&#39057;&#29575;&#21644;&#20005;&#37325;&#24615;&#25968;&#25454;&#36827;&#34892;&#20445;&#38505;&#23450;&#20215;&#30340;&#31070;&#32463;&#32593;&#32476;&#65306;&#20174;&#25968;&#25454;&#39044;&#22788;&#29702;&#21040;&#25216;&#26415;&#23450;&#20215;&#30340;&#22522;&#20934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Neural networks for insurance pricing with frequency and severity data: a benchmark study from data preprocessing to technical tariff. (arXiv:2310.12671v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#23545;&#39057;&#29575;-&#20005;&#37325;&#24615;&#20445;&#38505;&#23450;&#20215;&#36827;&#34892;&#20102;&#22522;&#20934;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#19981;&#21516;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;(CANN)&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20445;&#38505;&#20844;&#21496;&#36890;&#24120;&#20351;&#29992;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#26469;&#24314;&#27169;&#32034;&#36180;&#30340;&#39057;&#29575;&#21644;&#20005;&#37325;&#24615;&#25968;&#25454;&#12290;&#30001;&#20110;&#20854;&#22312;&#20854;&#20182;&#39046;&#22495;&#30340;&#25104;&#21151;&#65292;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#22312;&#31934;&#31639;&#24037;&#20855;&#31665;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#26412;&#25991;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#20026;&#39057;&#29575;-&#20005;&#37325;&#24615;&#20445;&#38505;&#23450;&#20215;&#19982;&#26426;&#22120;&#23398;&#20064;&#30456;&#20851;&#30340;&#25991;&#29486;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#20445;&#38505;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22522;&#20934;&#30740;&#31350;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#21253;&#21547;&#26377;&#22810;&#31181;&#31867;&#22411;&#30340;&#36755;&#20837;&#29305;&#24449;&#21644;&#39057;&#29575;-&#20005;&#37325;&#24615;&#30446;&#26631;&#12290;&#25105;&#20204;&#35814;&#32454;&#27604;&#36739;&#20102;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#22312;&#20998;&#31665;&#36755;&#20837;&#25968;&#25454;&#12289;&#26799;&#24230;&#25552;&#21319;&#26641;&#27169;&#22411;&#12289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFNN&#65289;&#21644;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;&#65288;CANN&#65289;&#19978;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;CANN&#23558;&#36890;&#36807;GLM&#21644;GBM&#20998;&#21035;&#24314;&#31435;&#30340;&#22522;&#32447;&#39044;&#27979;&#19982;&#31070;&#32463;&#32593;&#32476;&#26657;&#27491;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#25968;&#25454;&#39044;&#22788;&#29702;&#27493;&#39588;&#65292;&#29305;&#21035;&#20851;&#27880;&#36890;&#24120;&#23384;&#22312;&#20110;&#34920;&#26684;&#20445;&#38505;&#25968;&#25454;&#38598;&#20013;&#30340;&#22810;&#31181;&#31867;&#22411;&#30340;&#36755;&#20837;&#29305;&#24449;&#65292;&#27604;&#22914;&#37038;&#32534;&#21644;&#25968;&#23383;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Insurers usually turn to generalized linear models for modelling claim frequency and severity data. Due to their success in other fields, machine learning techniques are gaining popularity within the actuarial toolbox. Our paper contributes to the literature on frequency-severity insurance pricing with machine learning via deep learning structures. We present a benchmark study on four insurance data sets with frequency and severity targets in the presence of multiple types of input features. We compare in detail the performance of: a generalized linear model on binned input data, a gradient-boosted tree model, a feed-forward neural network (FFNN), and the combined actuarial neural network (CANN). Our CANNs combine a baseline prediction established with a GLM and GBM, respectively, with a neural network correction. We explain the data preprocessing steps with specific focus on the multiple types of input features typically present in tabular insurance data sets, such as postal codes, nu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#24335;&#35745;&#31639;&#20013;&#65292;&#20801;&#35768;&#20449;&#24687;&#27844;&#28431;&#21644;&#36817;&#20284;&#20056;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#35802;&#23454;&#33410;&#28857;&#25968;&#37327;&#20026;&#23569;&#25968;&#26102;&#65292;&#24046;&#20998;&#38544;&#31169;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2309.16105</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#23433;&#20840;&#20056;&#27861;&#65306;&#22312;&#22122;&#22768;&#20013;&#38544;&#34255;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Secure Multiplication: Hiding Information in the Rubble of Noise. (arXiv:2309.16105v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#24335;&#35745;&#31639;&#20013;&#65292;&#20801;&#35768;&#20449;&#24687;&#27844;&#28431;&#21644;&#36817;&#20284;&#20056;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#35802;&#23454;&#33410;&#28857;&#25968;&#37327;&#20026;&#23569;&#25968;&#26102;&#65292;&#24046;&#20998;&#38544;&#31169;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#31169;&#23494;&#20998;&#24067;&#24335;&#22810;&#26041;&#20056;&#27861;&#30340;&#38382;&#39064;&#12290;&#24050;&#32463;&#30830;&#35748;&#65292;Shamir&#31192;&#23494;&#20849;&#20139;&#32534;&#30721;&#31574;&#30053;&#21487;&#20197;&#36890;&#36807;Ben Or&#65292;Goldwasser&#65292;Wigderson&#31639;&#27861;&#65288;&#8220;BGW&#31639;&#27861;&#8221;&#65289;&#22312;&#20998;&#24067;&#24335;&#35745;&#31639;&#20013;&#23454;&#29616;&#23436;&#32654;&#30340;&#20449;&#24687;&#29702;&#35770;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#23436;&#32654;&#30340;&#38544;&#31169;&#21644;&#20934;&#30830;&#24615;&#38656;&#35201;&#19968;&#20010;&#35802;&#23454;&#30340;&#22810;&#25968;&#65292;&#21363;&#38656;&#35201;$N \geq 2t+1$&#20010;&#35745;&#31639;&#33410;&#28857;&#20197;&#30830;&#20445;&#23545;&#25239;&#24615;&#33410;&#28857;&#30340;&#38544;&#31169;&#12290;&#25105;&#20204;&#36890;&#36807;&#20801;&#35768;&#19968;&#23450;&#37327;&#30340;&#20449;&#24687;&#27844;&#28431;&#21644;&#36817;&#20284;&#20056;&#27861;&#26469;&#30740;&#31350;&#22312;&#35802;&#23454;&#33410;&#28857;&#25968;&#37327;&#20026;&#23569;&#25968;&#26102;&#30340;&#32534;&#30721;&#26041;&#26696;&#65292;&#21363;$N&lt; 2t+1$&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#32780;&#19981;&#26159;&#23436;&#32654;&#38544;&#31169;&#26469;&#27979;&#37327;&#20449;&#24687;&#27844;&#28431;&#65292;&#24182;&#20351;&#29992;&#22343;&#26041;&#35823;&#24046;&#24230;&#37327;&#20934;&#30830;&#24615;&#65292;&#23545;$N &lt; 2t+1$&#30340;&#24773;&#20917;&#19979;&#30340;&#38544;&#31169;-&#20934;&#30830;&#24615;&#26435;&#34913;&#36827;&#34892;&#20102;&#32039;&#23494;&#30340;&#21051;&#30011;&#12290;&#19968;&#20010;&#26032;&#39062;&#30340;&#25216;&#26415;&#26041;&#38754;&#26159;&#22797;&#26434;&#22320;&#25511;&#21046;&#20449;&#24687;&#27844;&#28431;&#30340;&#32454;&#33410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of private distributed multi-party multiplication. It is well-established that Shamir secret-sharing coding strategies can enable perfect information-theoretic privacy in distributed computation via the celebrated algorithm of Ben Or, Goldwasser and Wigderson (the "BGW algorithm"). However, perfect privacy and accuracy require an honest majority, that is, $N \geq 2t+1$ compute nodes are required to ensure privacy against any $t$ colluding adversarial nodes. By allowing for some controlled amount of information leakage and approximate multiplication instead of exact multiplication, we study coding schemes for the setting where the number of honest nodes can be a minority, that is $N&lt; 2t+1.$ We develop a tight characterization privacy-accuracy trade-off for cases where $N &lt; 2t+1$ by measuring information leakage using {differential} privacy instead of perfect privacy, and using the mean squared error metric for accuracy. A novel technical aspect is an intricately 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#38454;&#27573;&#28145;&#24230;&#23398;&#20064;&#20266;&#24433;&#20943;&#23569;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#30340;&#22270;&#20687;&#36136;&#37327;&#12290;&#20256;&#32479;&#26041;&#27861;&#36890;&#24120;&#22312;&#37325;&#24314;&#20043;&#21518;&#36827;&#34892;&#22788;&#29702;&#65292;&#32780;&#26412;&#26041;&#27861;&#33021;&#22815;&#26681;&#25454;&#19981;&#21516;&#30340;&#22270;&#20687;&#22495;&#36827;&#34892;&#22810;&#27493;&#39588;&#21435;&#20266;&#24433;&#65292;&#20351;&#24471;&#30456;&#23545;&#22256;&#38590;&#21435;&#38500;&#30340;&#20266;&#24433;&#20063;&#33021;&#22815;&#26377;&#25928;&#28040;&#38500;&#12290;</title><link>http://arxiv.org/abs/2309.00494</link><description>&lt;p&gt;
&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#30340;&#22810;&#38454;&#27573;&#28145;&#24230;&#23398;&#20064;&#20266;&#24433;&#20943;&#23569;
&lt;/p&gt;
&lt;p&gt;
Multi-stage Deep Learning Artifact Reduction for Computed Tomography. (arXiv:2309.00494v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#38454;&#27573;&#28145;&#24230;&#23398;&#20064;&#20266;&#24433;&#20943;&#23569;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#30340;&#22270;&#20687;&#36136;&#37327;&#12290;&#20256;&#32479;&#26041;&#27861;&#36890;&#24120;&#22312;&#37325;&#24314;&#20043;&#21518;&#36827;&#34892;&#22788;&#29702;&#65292;&#32780;&#26412;&#26041;&#27861;&#33021;&#22815;&#26681;&#25454;&#19981;&#21516;&#30340;&#22270;&#20687;&#22495;&#36827;&#34892;&#22810;&#27493;&#39588;&#21435;&#20266;&#24433;&#65292;&#20351;&#24471;&#30456;&#23545;&#22256;&#38590;&#21435;&#38500;&#30340;&#20266;&#24433;&#20063;&#33021;&#22815;&#26377;&#25928;&#28040;&#38500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#20013;&#65292;&#36890;&#36807;&#19968;&#31995;&#21015;&#33719;&#21462;&#30340;&#25237;&#24433;&#22270;&#20687;&#35745;&#31639;&#20986;&#29289;&#20307;&#20869;&#37096;&#32467;&#26500;&#30340;&#22270;&#20687;&#12290;&#36825;&#20123;&#37325;&#24314;&#22270;&#20687;&#30340;&#36136;&#37327;&#23545;&#20110;&#20934;&#30830;&#20998;&#26512;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#26159;&#36825;&#31181;&#36136;&#37327;&#21487;&#33021;&#20250;&#34987;&#21508;&#31181;&#25104;&#20687;&#20266;&#24433;&#38477;&#20302;&#12290;&#20026;&#20102;&#25552;&#39640;&#37325;&#24314;&#36136;&#37327;&#65292;&#33719;&#21462;&#30340;&#25237;&#24433;&#22270;&#20687;&#36890;&#24120;&#36890;&#36807;&#30001;&#22810;&#20010;&#21435;&#20266;&#24433;&#27493;&#39588;&#32452;&#25104;&#30340;&#27969;&#31243;&#36827;&#34892;&#22788;&#29702;&#65292;&#36825;&#20123;&#27493;&#39588;&#24212;&#29992;&#20110;&#19981;&#21516;&#30340;&#22270;&#20687;&#22495;&#65288;&#20363;&#22914;&#65292;&#25237;&#24433;&#22270;&#20687;&#30340;&#24322;&#24120;&#20540;&#21435;&#38500;&#21644;&#37325;&#24314;&#22270;&#20687;&#30340;&#21435;&#22122;&#65289;&#12290;&#36825;&#20123;&#20266;&#24433;&#21435;&#38500;&#26041;&#27861;&#21033;&#29992;&#20102;&#26576;&#20123;&#20266;&#24433;&#22312;&#29305;&#23450;&#22495;&#30456;&#23545;&#20110;&#20854;&#20182;&#22495;&#26356;&#23481;&#26131;&#21435;&#38500;&#30340;&#20107;&#23454;&#12290;&#26368;&#36817;&#65292;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#20266;&#24433;&#21435;&#38500;&#26041;&#38754;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#37117;&#26159;&#22312;&#37325;&#24314;&#20043;&#21518;&#20316;&#20026;&#21518;&#22788;&#29702;&#26041;&#27861;&#24212;&#29992;&#30340;&#12290;&#22240;&#27492;&#65292;&#22312;&#37325;&#24314;&#22495;&#30456;&#23545;&#22256;&#38590;&#21435;&#38500;&#30340;&#20266;&#24433;&#21487;&#33021;&#26080;&#27861;&#26377;&#25928;&#21435;&#38500;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Computed Tomography (CT), an image of the interior structure of an object is computed from a set of acquired projection images. The quality of these reconstructed images is essential for accurate analysis, but this quality can be degraded by a variety of imaging artifacts. To improve reconstruction quality, the acquired projection images are often processed by a pipeline consisting of multiple artifact-removal steps applied in various image domains (e.g., outlier removal on projection images and denoising of reconstruction images). These artifact-removal methods exploit the fact that certain artifacts are easier to remove in a certain domain compared with other domains.  Recently, deep learning methods have shown promising results for artifact removal for CT images. However, most existing deep learning methods for CT are applied as a post-processing method after reconstruction. Therefore, artifacts that are relatively difficult to remove in the reconstruction domain may not be effec
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#21517;&#20026;AutoRUL&#65292;&#29992;&#20110;&#33258;&#21160;&#39044;&#27979;&#24037;&#31243;&#31995;&#32479;&#30340;&#21097;&#20313;&#20351;&#29992;&#23551;&#21629;&#65288;RUL&#65289;&#12290;&#35813;&#26041;&#27861;&#23558;&#24494;&#35843;&#30340;&#26631;&#20934;&#22238;&#24402;&#26041;&#27861;&#19982;&#39640;&#39044;&#27979;&#33021;&#21147;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#65292;&#24182;&#36890;&#36807;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#65292;&#35777;&#26126;AutoML&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2306.12215</link><description>&lt;p&gt;
&#38754;&#21521;&#21097;&#20313;&#20351;&#29992;&#23551;&#21629;&#39044;&#27979;&#30340;&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Automated Machine Learning for Remaining Useful Life Predictions. (arXiv:2306.12215v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12215
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#21517;&#20026;AutoRUL&#65292;&#29992;&#20110;&#33258;&#21160;&#39044;&#27979;&#24037;&#31243;&#31995;&#32479;&#30340;&#21097;&#20313;&#20351;&#29992;&#23551;&#21629;&#65288;RUL&#65289;&#12290;&#35813;&#26041;&#27861;&#23558;&#24494;&#35843;&#30340;&#26631;&#20934;&#22238;&#24402;&#26041;&#27861;&#19982;&#39640;&#39044;&#27979;&#33021;&#21147;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#65292;&#24182;&#36890;&#36807;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#65292;&#35777;&#26126;AutoML&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#24037;&#31243;&#31995;&#32479;&#30340;&#21097;&#20313;&#20351;&#29992;&#23551;&#21629;&#65288;RUL&#65289;&#26159;&#39044;&#27979;&#19982;&#20581;&#24247;&#31649;&#29702;&#20013;&#30340;&#37325;&#35201;&#20219;&#21153;&#12290;&#26368;&#36817;&#65292;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#22312;RUL&#39044;&#27979;&#20013;&#26222;&#21450;&#65292;&#30456;&#27604;&#27169;&#22411;&#39537;&#21160;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#24037;&#31243;&#31995;&#32479;&#30340;&#29289;&#29702;&#30693;&#35782;&#12290;&#20294;&#26159;&#65292;&#36825;&#21482;&#26159;&#23558;&#38656;&#35201;&#30340;&#29289;&#29702;&#19987;&#19994;&#30693;&#35782;&#26367;&#25442;&#25104;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#19987;&#19994;&#30693;&#35782;&#65292;&#32780;&#36825;&#31181;&#19987;&#19994;&#30693;&#35782;&#36890;&#24120;&#20063;&#19981;&#21487;&#24471;&#12290;&#33258;&#21160;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;AutoML&#65289;&#25215;&#35834;&#33258;&#21160;&#26500;&#24314;&#31471;&#21040;&#31471;&#30340;ML&#31649;&#36947;&#65292;&#20351;&#39046;&#22495;&#19987;&#23478;&#32780;&#38750;ML&#19987;&#23478;&#33021;&#22815;&#21019;&#24314;&#33258;&#24049;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;AutoRUL&#65292;&#19968;&#31181;AutoML&#39537;&#21160;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;RUL&#39044;&#27979;&#12290;AutoRUL&#23558;&#24494;&#35843;&#30340;&#26631;&#20934;&#22238;&#24402;&#26041;&#27861;&#19982;&#39640;&#39044;&#27979;&#33021;&#21147;&#30340;&#38598;&#25104;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#29992;&#20110;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#25163;&#24037;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#34920;&#26126;AutoML&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Being able to predict the remaining useful life (RUL) of an engineering system is an important task in prognostics and health management. Recently, data-driven approaches to RUL predictions are becoming prevalent over model-based approaches since no underlying physical knowledge of the engineering system is required. Yet, this just replaces required expertise of the underlying physics with machine learning (ML) expertise, which is often also not available. Automated machine learning (AutoML) promises to build end-to-end ML pipelines automatically enabling domain experts without ML expertise to create their own models. This paper introduces AutoRUL, an AutoML-driven end-to-end approach for automatic RUL predictions. AutoRUL combines fine-tuned standard regression methods to an ensemble with high predictive power. By evaluating the proposed method on eight real-world and synthetic datasets against state-of-the-art hand-crafted models, we show that AutoML provides a viable alternative to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;BERT&#30340;&#28966;&#28857;&#29228;&#34411;ThreatCrawl&#65292;&#20351;&#29992;&#20027;&#39064;&#24314;&#27169;&#21644;&#20851;&#38190;&#35789;&#25552;&#21462;&#25216;&#26415;&#26469;&#31579;&#36873;&#20986;&#26368;&#21487;&#33021;&#21253;&#21547;&#26377;&#20215;&#20540;CTI&#20449;&#24687;&#30340;&#32593;&#39029;&#12290;</title><link>http://arxiv.org/abs/2304.11960</link><description>&lt;p&gt;
ThreatCrawl&#65306;&#22522;&#20110;BERT&#30340;&#32593;&#32476;&#23433;&#20840;&#28966;&#28857;&#29228;&#34411;
&lt;/p&gt;
&lt;p&gt;
ThreatCrawl: A BERT-based Focused Crawler for the Cybersecurity Domain. (arXiv:2304.11960v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11960
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;BERT&#30340;&#28966;&#28857;&#29228;&#34411;ThreatCrawl&#65292;&#20351;&#29992;&#20027;&#39064;&#24314;&#27169;&#21644;&#20851;&#38190;&#35789;&#25552;&#21462;&#25216;&#26415;&#26469;&#31579;&#36873;&#20986;&#26368;&#21487;&#33021;&#21253;&#21547;&#26377;&#20215;&#20540;CTI&#20449;&#24687;&#30340;&#32593;&#39029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20844;&#24320;&#33719;&#21462;&#30340;&#20449;&#24687;&#23545;&#20110;&#32593;&#32476;&#23041;&#32961;&#24773;&#25253;&#65288;CTI&#65289;&#26469;&#35828;&#21253;&#21547;&#26377;&#20215;&#20540;&#30340;&#20449;&#24687;&#12290;&#36825;&#21487;&#20197;&#29992;&#20110;&#39044;&#38450;&#24050;&#32463;&#22312;&#20854;&#20182;&#31995;&#32479;&#19978;&#21457;&#29983;&#30340;&#25915;&#20987;&#12290;&#20294;&#26159;&#65292;&#34429;&#28982;&#26377;&#19981;&#21516;&#30340;&#26631;&#20934;&#26469;&#20132;&#27969;&#36825;&#20123;&#20449;&#24687;&#65292;&#20294;&#24456;&#22810;&#20449;&#24687;&#26159;&#20197;&#38750;&#26631;&#20934;&#21270;&#30340;&#26041;&#24335;&#22312;&#25991;&#31456;&#25110;&#21338;&#23458;&#24086;&#23376;&#20013;&#20849;&#20139;&#30340;&#12290;&#25163;&#21160;&#27983;&#35272;&#22810;&#20010;&#22312;&#32447;&#38376;&#25143;&#21644;&#26032;&#38395;&#39029;&#38754;&#20197;&#21457;&#29616;&#26032;&#23041;&#32961;&#24182;&#25552;&#21462;&#23427;&#20204;&#26159;&#19968;&#39033;&#32791;&#26102;&#30340;&#20219;&#21153;&#12290;&#20026;&#20102;&#33258;&#21160;&#21270;&#36825;&#20010;&#25195;&#25551;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#22810;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20174;&#25991;&#26723;&#20013;&#25552;&#21462;&#23041;&#32961;&#25351;&#31034;&#22120;&#65288;IOCs&#65289;&#30340;&#25552;&#21462;&#22120;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#36825;&#24050;&#32463;&#35299;&#20915;&#20102;&#20174;&#25991;&#26723;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#38382;&#39064;&#65292;&#20294;&#24456;&#23569;&#32771;&#34385;&#25628;&#32034;&#36825;&#20123;&#25991;&#26723;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28966;&#28857;&#29228;&#34411;ThreatCrawl&#65292;&#23427;&#20351;&#29992;&#21452;&#21521;&#32534;&#30721;&#22120;&#34920;&#31034;&#65288;BERT&#65289;&#25628;&#32034;&#32593;&#32476;&#23433;&#20840;&#39046;&#22495;&#20013;&#30340;&#30456;&#20851;&#25991;&#26723;&#12290;ThreatCrawl&#20351;&#29992;&#20027;&#39064;&#24314;&#27169;&#21644;&#20851;&#38190;&#35789;&#25552;&#21462;&#25216;&#26415;&#26469;&#35782;&#21035;&#30456;&#20851;&#32593;&#31449;&#21644;&#32593;&#39029;&#65292;&#28982;&#21518;&#24212;&#29992;&#22522;&#20110;BERT&#30340;&#20998;&#31867;&#22120;&#26469;&#20248;&#20808;&#32771;&#34385;&#26368;&#21487;&#33021;&#21253;&#21547;&#26377;&#20215;&#20540;CTI&#20449;&#24687;&#30340;&#32593;&#39029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Publicly available information contains valuable information for Cyber Threat Intelligence (CTI). This can be used to prevent attacks that have already taken place on other systems. Ideally, only the initial attack succeeds and all subsequent ones are detected and stopped. But while there are different standards to exchange this information, a lot of it is shared in articles or blog posts in non-standardized ways. Manually scanning through multiple online portals and news pages to discover new threats and extracting them is a time-consuming task. To automize parts of this scanning process, multiple papers propose extractors that use Natural Language Processing (NLP) to extract Indicators of Compromise (IOCs) from documents. However, while this already solves the problem of extracting the information out of documents, the search for these documents is rarely considered. In this paper, a new focused crawler is proposed called ThreatCrawl, which uses Bidirectional Encoder Representations 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#20960;&#31181;AI&#25991;&#26412;&#26816;&#27979;&#22120;&#19981;&#21487;&#38752;&#12290;&#25913;&#20889;&#25915;&#20987;&#21487;&#20197;&#30772;&#35299;&#22810;&#31181;&#26816;&#27979;&#22120;&#65292;&#21253;&#25324;&#27700;&#21360;&#26041;&#26696;&#12289;&#31070;&#32463;&#32593;&#32476;&#26816;&#27979;&#22120;&#21644;&#38646;&#26679;&#26412;&#20998;&#31867;&#22120;&#12290;&#21363;&#20351;&#26159;&#26368;&#22909;&#30340;&#26816;&#27979;&#22120;&#65292;&#38543;&#30528;&#35821;&#35328;&#27169;&#22411;&#30340;&#36827;&#19968;&#27493;&#25552;&#21319;&#65292;&#24615;&#33021;&#20063;&#20250;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;AI&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#21487;&#38752;&#26816;&#27979;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2303.11156</link><description>&lt;p&gt;
AI&#29983;&#25104;&#30340;&#25991;&#26412;&#26159;&#21542;&#21487;&#38752;&#22320;&#26816;&#27979;&#20986;&#26469;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can AI-Generated Text be Reliably Detected?. (arXiv:2303.11156v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11156
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#20960;&#31181;AI&#25991;&#26412;&#26816;&#27979;&#22120;&#19981;&#21487;&#38752;&#12290;&#25913;&#20889;&#25915;&#20987;&#21487;&#20197;&#30772;&#35299;&#22810;&#31181;&#26816;&#27979;&#22120;&#65292;&#21253;&#25324;&#27700;&#21360;&#26041;&#26696;&#12289;&#31070;&#32463;&#32593;&#32476;&#26816;&#27979;&#22120;&#21644;&#38646;&#26679;&#26412;&#20998;&#31867;&#22120;&#12290;&#21363;&#20351;&#26159;&#26368;&#22909;&#30340;&#26816;&#27979;&#22120;&#65292;&#38543;&#30528;&#35821;&#35328;&#27169;&#22411;&#30340;&#36827;&#19968;&#27493;&#25552;&#21319;&#65292;&#24615;&#33021;&#20063;&#20250;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;AI&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#21487;&#38752;&#26816;&#27979;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#23454;&#35777;&#21644;&#29702;&#35770;&#20004;&#20010;&#26041;&#38754;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#20960;&#31181;AI&#25991;&#26412;&#26816;&#27979;&#22120;&#24182;&#19981;&#21487;&#38752;&#12290;&#20174;&#23454;&#36341;&#19978;&#26469;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36731;&#37327;&#32423;&#30340;&#25913;&#20889;&#22120;&#24212;&#29992;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19978;&#21487;&#20197;&#30772;&#35299;&#19968;&#31995;&#21015;&#30340;&#26816;&#27979;&#22120;&#65292;&#21253;&#25324;&#20351;&#29992;&#27700;&#21360;&#26041;&#26696;&#12289;&#31070;&#32463;&#32593;&#32476;&#26816;&#27979;&#22120;&#21644;&#38646;&#26679;&#26412;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#26088;&#22312;&#36530;&#36991;&#25913;&#20889;&#25915;&#20987;&#30340;&#22522;&#20110;&#26816;&#32034;&#30340;&#26816;&#27979;&#22120;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#36882;&#24402;&#25913;&#20889;&#30340;&#25915;&#20987;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#30340;&#19981;&#21487;&#33021;&#32467;&#26524;&#65292;&#25351;&#20986;&#38543;&#30528;&#35821;&#35328;&#27169;&#22411;&#21464;&#24471;&#36234;&#26469;&#36234;&#22797;&#26434;&#21644;&#26356;&#25797;&#38271;&#27169;&#20223;&#20154;&#31867;&#25991;&#26412;&#65292;&#22312;&#26368;&#22909;&#30340;&#26816;&#27979;&#22120;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#23545;&#20110;&#19968;&#20010;&#36275;&#22815;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#27169;&#20223;&#20154;&#31867;&#25991;&#26412;&#65292;&#21363;&#20351;&#26368;&#20339;&#30340;&#26816;&#27979;&#22120;&#30340;&#34920;&#29616;&#21482;&#27604;&#38543;&#26426;&#20998;&#31867;&#22120;&#22909;&#19978;&#19968;&#28857;&#28857;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36275;&#22815;&#27010;&#25324;&#29305;&#23450;&#30340;&#22330;&#26223;&#65292;&#22914;&#25913;&#20889;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, both empirically and theoretically, we show that several AI-text detectors are not reliable in practical scenarios. Empirically, we show that paraphrasing attacks, where a light paraphraser is applied on top of a large language model (LLM), can break a whole range of detectors, including ones using watermarking schemes as well as neural network-based detectors and zero-shot classifiers. Our experiments demonstrate that retrieval-based detectors, designed to evade paraphrasing attacks, are still vulnerable to recursive paraphrasing. We then provide a theoretical impossibility result indicating that as language models become more sophisticated and better at emulating human text, the performance of even the best-possible detector decreases. For a sufficiently advanced language model seeking to imitate human text, even the best-possible detector may only perform marginally better than a random classifier. Our result is general enough to capture specific scenarios such as par
&lt;/p&gt;</description></item></channel></rss>