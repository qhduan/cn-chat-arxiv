<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#20174;&#22522;&#20110;&#30693;&#35782;&#30340;&#35282;&#24230;&#20840;&#38754;&#35843;&#26597;&#21644;&#20998;&#26512;&#20102;&#22270;&#22522;&#30784;&#27169;&#22411;&#30340;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#28041;&#21450;&#24494;&#35266;&#21644;&#23439;&#35266;&#30693;&#35782;&#65292;&#21253;&#25324;9&#20010;&#30693;&#35782;&#31867;&#21035;&#12289;25&#20010;&#39044;&#35757;&#32451;&#20219;&#21153;&#20197;&#21450;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#36866;&#24212;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.16137</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#22270;&#22522;&#30784;&#27169;&#22411;&#30340;&#35843;&#26597;&#65306;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Survey on Self-Supervised Pre-Training of Graph Foundation Models: A Knowledge-Based Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16137
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20174;&#22522;&#20110;&#30693;&#35782;&#30340;&#35282;&#24230;&#20840;&#38754;&#35843;&#26597;&#21644;&#20998;&#26512;&#20102;&#22270;&#22522;&#30784;&#27169;&#22411;&#30340;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#28041;&#21450;&#24494;&#35266;&#21644;&#23439;&#35266;&#30693;&#35782;&#65292;&#21253;&#25324;9&#20010;&#30693;&#35782;&#31867;&#21035;&#12289;25&#20010;&#39044;&#35757;&#32451;&#20219;&#21153;&#20197;&#21450;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#36866;&#24212;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#33258;&#30417;&#30563;&#23398;&#20064;&#29616;&#22312;&#26159;&#39044;&#35757;&#32451;&#22270;&#22522;&#30784;&#27169;&#22411;&#30340;&#39318;&#36873;&#26041;&#27861;&#65292;&#21253;&#25324;&#22270;&#31070;&#32463;&#32593;&#32476;&#12289;&#22270;&#21464;&#25442;&#22120;&#65292;&#20197;&#21450;&#26356;&#36817;&#26399;&#30340;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#22270;&#27169;&#22411;&#12290;&#25991;&#31456;&#20840;&#38754;&#35843;&#26597;&#21644;&#20998;&#26512;&#20102;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35282;&#19979;&#30340;&#22270;&#22522;&#30784;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#21253;&#25324;&#24494;&#35266;&#65288;&#33410;&#28857;&#12289;&#38142;&#25509;&#31561;&#65289;&#21644;&#23439;&#35266;&#30693;&#35782;&#65288;&#31751;&#12289;&#20840;&#23616;&#32467;&#26500;&#31561;&#65289;&#12290;&#28085;&#30422;&#20102;&#20849;&#35745;9&#20010;&#30693;&#35782;&#31867;&#21035;&#21644;25&#20010;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#20197;&#21450;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#36866;&#24212;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16137v1 Announce Type: new  Abstract: Graph self-supervised learning is now a go-to method for pre-training graph foundation models, including graph neural networks, graph transformers, and more recent large language model (LLM)-based graph models. There is a wide variety of knowledge patterns embedded in the structure and properties of graphs which may be used for pre-training, but we lack a systematic overview of self-supervised pre-training tasks from the perspective of graph knowledge. In this paper, we comprehensively survey and analyze the pre-training tasks of graph foundation models from a knowledge-based perspective, consisting of microscopic (nodes, links, etc) and macroscopic knowledge (clusters, global structure, etc). It covers a total of 9 knowledge categories and 25 pre-training tasks, as well as various downstream task adaptation strategies. Furthermore, an extensive list of the related papers with detailed metadata is provided at https://github.com/Newiz430/
&lt;/p&gt;</description></item><item><title>&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;</title><link>https://arxiv.org/abs/2403.13748</link><description>&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#20013;&#22240;&#23376;&#21270;&#39640;&#26031;&#36817;&#20284;&#30340;&#24046;&#24322;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13748
&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#20013;&#65292;&#32473;&#23450;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#20998;&#24067;$p$&#65292;&#38382;&#39064;&#26159;&#20174;&#19968;&#20123;&#26356;&#26131;&#22788;&#29702;&#30340;&#26063;$\mathcal{Q}$&#20013;&#35745;&#31639;&#26368;&#20339;&#36817;&#20284;$q$&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#36817;&#20284;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;Kullback-Leibler (KL)&#25955;&#24230;&#26469;&#25214;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23384;&#22312;&#20854;&#20182;&#26377;&#25928;&#30340;&#25955;&#24230;&#36873;&#25321;&#65292;&#24403;$\mathcal{Q}$&#19981;&#21253;&#21547;$p$&#26102;&#65292;&#27599;&#20010;&#25955;&#24230;&#37117;&#25903;&#25345;&#19981;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#39640;&#26031;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#34987;&#23545;&#35282;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#36817;&#20284;&#25152;&#24433;&#21709;&#30340;VI&#32467;&#26524;&#20013;&#65292;&#25955;&#24230;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;VI&#32467;&#26524;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#30340;&#25955;&#24230;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#22914;&#26041;&#24046;&#12289;&#31934;&#24230;&#21644;&#29109;&#65292;&#36827;&#34892;\textit{&#25490;&#24207;}&#12290;&#25105;&#20204;&#36824;&#24471;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#23450;&#29702;&#65292;&#34920;&#26126;&#26080;&#27861;&#36890;&#36807;&#22240;&#23376;&#21270;&#36817;&#20284;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;&#65307;&#22240;&#27492;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13748v1 Announce Type: cross  Abstract: Given an intractable distribution $p$, the problem of variational inference (VI) is to compute the best approximation $q$ from some more tractable family $\mathcal{Q}$. Most commonly the approximation is found by minimizing a Kullback-Leibler (KL) divergence. However, there exist other valid choices of divergences, and when $\mathcal{Q}$ does not contain~$p$, each divergence champions a different solution. We analyze how the choice of divergence affects the outcome of VI when a Gaussian with a dense covariance matrix is approximated by a Gaussian with a diagonal covariance matrix. In this setting we show that different divergences can be \textit{ordered} by the amount that their variational approximations misestimate various measures of uncertainty, such as the variance, precision, and entropy. We also derive an impossibility theorem showing that no two of these measures can be simultaneously matched by a factorized approximation; henc
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#27169;&#20223;&#27491;&#21017;&#21270;&#30340;&#26368;&#20248;&#36755;&#36816;&#65288;I-OT&#65289;&#65292;&#36890;&#36807;&#27169;&#20223;&#20808;&#39564;&#20998;&#24067;&#26469;&#25552;&#39640;&#32593;&#32476;&#31995;&#32479;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.17967</link><description>&lt;p&gt;
&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#27169;&#20223;&#27491;&#21017;&#21270;&#30340;&#26368;&#20248;&#36755;&#36816;&#65306;&#21487;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;&#21450;&#20854;&#22312;&#29289;&#27969;&#35268;&#21010;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Imitation-regularized Optimal Transport on Networks: Provable Robustness and Application to Logistics Planning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17967
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#27169;&#20223;&#27491;&#21017;&#21270;&#30340;&#26368;&#20248;&#36755;&#36816;&#65288;I-OT&#65289;&#65292;&#36890;&#36807;&#27169;&#20223;&#20808;&#39564;&#20998;&#24067;&#26469;&#25552;&#39640;&#32593;&#32476;&#31995;&#32479;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#31995;&#32479;&#26500;&#25104;&#20102;&#29616;&#20195;&#31038;&#20250;&#30340;&#22522;&#30784;&#65292;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#38754;&#20020;&#30528;&#30001;&#28798;&#38590;&#31561;&#19981;&#21487;&#39044;&#35265;&#24773;&#20917;&#24102;&#26469;&#30340;&#37325;&#22823;&#39118;&#38505;&#12290;&#37492;&#20110;&#27492;&#65292;&#36843;&#20999;&#38656;&#35201;&#30740;&#31350;&#21152;&#24378;&#32593;&#32476;&#31995;&#32479;&#30340;&#40065;&#26834;&#24615;&#12290;&#26368;&#36817;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#24050;&#32463;&#30830;&#23450;&#20102;&#33719;&#21462;&#40065;&#26834;&#24615;&#21644;&#27491;&#21017;&#21270;&#29109;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#22312;&#36825;&#19968;&#26694;&#26550;&#20869;&#20351;&#29992;&#20102;&#27169;&#20223;&#23398;&#20064;&#26469;&#21453;&#26144;&#19987;&#23478;&#30340;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#22312;&#32593;&#32476;&#19978;&#30340;&#26368;&#20248;&#36755;&#36816;&#20013;&#20351;&#29992;&#31867;&#20284;&#27169;&#20223;&#26694;&#26550;&#30340;&#20840;&#38754;&#30740;&#31350;&#36824;&#27809;&#26377;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#19978;&#36827;&#34892;&#30340;&#27169;&#20223;&#27491;&#21017;&#21270;&#30340;&#26368;&#20248;&#36755;&#36816;&#65288;I-OT&#65289;&#12290;&#23427;&#36890;&#36807;&#27169;&#20223;&#32473;&#23450;&#30340;&#20808;&#39564;&#20998;&#24067;&#23545;&#32593;&#32476;&#30340;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#32534;&#30721;&#12290;I-OT&#35299;&#20915;&#26041;&#26696;&#22312;&#32593;&#32476;&#19978;&#23450;&#20041;&#30340;&#25104;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17967v1 Announce Type: new  Abstract: Network systems form the foundation of modern society, playing a critical role in various applications. However, these systems are at significant risk of being adversely affected by unforeseen circumstances, such as disasters. Considering this, there is a pressing need for research to enhance the robustness of network systems. Recently, in reinforcement learning, the relationship between acquiring robustness and regularizing entropy has been identified. Additionally, imitation learning is used within this framework to reflect experts' behavior. However, there are no comprehensive studies on the use of a similar imitation framework for optimal transport on networks. Therefore, in this study, imitation-regularized optimal transport (I-OT) on networks was investigated. It encodes prior knowledge on the network by imitating a given prior distribution. The I-OT solution demonstrated robustness in terms of the cost defined on the network. More
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#36870;&#20613;&#31435;&#21494;&#31070;&#32463;&#31639;&#23376;(iFNO)&#65292;&#36890;&#36807;&#35774;&#35745;&#21487;&#36870;&#20613;&#31435;&#21494;&#22359;&#21644;&#38598;&#25104;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#23454;&#29616;&#21516;&#26102;&#22788;&#29702;&#21069;&#21521;&#19982;&#21453;&#21521;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#20026;&#21452;&#21521;&#20219;&#21153;&#30340;&#23398;&#20064;&#25552;&#20379;&#26377;&#25928;&#30340;&#21442;&#25968;&#20849;&#20139;&#21644;&#20449;&#24687;&#20132;&#25442;&#65292;&#20811;&#26381;&#20102;&#19981;&#36866;&#23450;&#24615;&#12289;&#25968;&#25454;&#30701;&#32570;&#21644;&#22122;&#22768;&#31561;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.11722</link><description>&lt;p&gt;
&#21487;&#36870;&#20613;&#31435;&#21494;&#31070;&#32463;&#31639;&#23376;&#22788;&#29702;&#21069;&#21521;&#21644;&#21453;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Invertible Fourier Neural Operators for Tackling Both Forward and Inverse Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#36870;&#20613;&#31435;&#21494;&#31070;&#32463;&#31639;&#23376;(iFNO)&#65292;&#36890;&#36807;&#35774;&#35745;&#21487;&#36870;&#20613;&#31435;&#21494;&#22359;&#21644;&#38598;&#25104;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#23454;&#29616;&#21516;&#26102;&#22788;&#29702;&#21069;&#21521;&#19982;&#21453;&#21521;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#20026;&#21452;&#21521;&#20219;&#21153;&#30340;&#23398;&#20064;&#25552;&#20379;&#26377;&#25928;&#30340;&#21442;&#25968;&#20849;&#20139;&#21644;&#20449;&#24687;&#20132;&#25442;&#65292;&#20811;&#26381;&#20102;&#19981;&#36866;&#23450;&#24615;&#12289;&#25968;&#25454;&#30701;&#32570;&#21644;&#22122;&#22768;&#31561;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20613;&#31435;&#21494;&#31070;&#32463;&#31639;&#23376;&#65288;FNO&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#31639;&#23376;&#23398;&#20064;&#26041;&#27861;&#65292;&#24050;&#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;FNO&#20027;&#35201;&#29992;&#20110;&#21069;&#21521;&#39044;&#27979;&#65292;&#32780;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20381;&#36182;&#20110;&#35299;&#20915;&#21453;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#36870;&#20613;&#31435;&#21494;&#31070;&#32463;&#31639;&#23376;&#65288;iFNO&#65289;&#65292;&#26088;&#22312;&#35299;&#20915;&#21069;&#21521;&#21644;&#21453;&#21521;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#28508;&#22312;&#36890;&#36947;&#31354;&#38388;&#20013;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#21487;&#36870;&#20613;&#31435;&#21494;&#22359;&#65292;&#20197;&#20998;&#20139;&#27169;&#22411;&#21442;&#25968;&#65292;&#26377;&#25928;&#20132;&#25442;&#20449;&#24687;&#65292;&#24182;&#30456;&#20114;&#27491;&#35268;&#21270;&#21452;&#21521;&#20219;&#21153;&#30340;&#23398;&#20064;&#12290;&#25105;&#20204;&#38598;&#25104;&#20102;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#20197;&#25429;&#33719;&#36755;&#20837;&#31354;&#38388;&#20869;&#22312;&#32467;&#26500;&#65292;&#24182;&#23454;&#29616;&#21518;&#39564;&#25512;&#26029;&#65292;&#20197;&#20811;&#26381;&#19981;&#36866;&#23450;&#24615;&#12289;&#25968;&#25454;&#30701;&#32570;&#12289;&#22122;&#22768;&#31561;&#25361;&#25112;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#19977;&#27493;&#36807;&#31243;&#65292;&#29992;&#20110;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#20197;&#23454;&#29616;&#39640;&#25928;&#35757;&#32451;&#12290;&#23545;&#20116;&#20010;&#22522;&#20934;&#38382;&#39064;&#30340;&#35780;&#20272;&#24050;&#32463;&#35777;&#26126;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11722v1 Announce Type: new  Abstract: Fourier Neural Operator (FNO) is a popular operator learning method, which has demonstrated state-of-the-art performance across many tasks. However, FNO is mainly used in forward prediction, yet a large family of applications rely on solving inverse problems. In this paper, we propose an invertible Fourier Neural Operator (iFNO) that tackles both the forward and inverse problems. We designed a series of invertible Fourier blocks in the latent channel space to share the model parameters, efficiently exchange the information, and mutually regularize the learning for the bi-directional tasks. We integrated a variational auto-encoder to capture the intrinsic structures within the input space and to enable posterior inference so as to overcome challenges of illposedness, data shortage, noises, etc. We developed a three-step process for pre-training and fine tuning for efficient training. The evaluations on five benchmark problems have demonst
&lt;/p&gt;</description></item><item><title>TinyCL&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#20027;&#31995;&#32479;&#25345;&#32493;&#23398;&#20064;&#30340;&#39640;&#25928;&#30828;&#20214;&#26550;&#26500;&#65292;&#22312;CL&#20013;&#25903;&#25345;&#21069;&#21521;&#21644;&#21453;&#21521;&#20256;&#25773;&#65292;&#24182;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#30340;&#36830;&#32493;&#23398;&#20064;&#31574;&#30053;&#26469;&#20943;&#23569;&#20869;&#23384;&#35775;&#38382;&#12290;</title><link>https://arxiv.org/abs/2402.09780</link><description>&lt;p&gt;
TinyCL:&#19968;&#31181;&#29992;&#20110;&#33258;&#20027;&#31995;&#32479;&#25345;&#32493;&#23398;&#20064;&#30340;&#39640;&#25928;&#30828;&#20214;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
TinyCL: An Efficient Hardware Architecture for Continual Learning on Autonomous Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09780
&lt;/p&gt;
&lt;p&gt;
TinyCL&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#20027;&#31995;&#32479;&#25345;&#32493;&#23398;&#20064;&#30340;&#39640;&#25928;&#30828;&#20214;&#26550;&#26500;&#65292;&#22312;CL&#20013;&#25903;&#25345;&#21069;&#21521;&#21644;&#21453;&#21521;&#20256;&#25773;&#65292;&#24182;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#30340;&#36830;&#32493;&#23398;&#20064;&#31574;&#30053;&#26469;&#20943;&#23569;&#20869;&#23384;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#33539;&#24335;&#21253;&#25324;&#19981;&#26029;&#28436;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;&#20197;&#36880;&#27493;&#23398;&#20064;&#25191;&#34892;&#26032;&#20219;&#21153;&#65292;&#32780;&#19981;&#38477;&#20302;&#20808;&#21069;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#21363;&#36991;&#20813;&#25152;&#35859;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#28982;&#32780;&#65292;&#22312;&#22522;&#20110;CL&#30340;&#33258;&#20027;&#31995;&#32479;&#20013;&#65292;DNN&#21442;&#25968;&#26356;&#26032;&#23545;&#36164;&#28304;&#35201;&#27714;&#26497;&#39640;&#12290;&#29616;&#26377;&#30340;DNN&#21152;&#36895;&#22120;&#19981;&#33021;&#30452;&#25509;&#29992;&#20110;CL&#65292;&#22240;&#20026;&#23427;&#20204;&#21482;&#25903;&#25345;&#21069;&#21521;&#20256;&#25773;&#30340;&#25191;&#34892;&#12290;&#21482;&#26377;&#23569;&#25968;&#20808;&#21069;&#30340;&#26550;&#26500;&#25191;&#34892;&#21453;&#21521;&#20256;&#25773;&#21644;&#26435;&#37325;&#26356;&#26032;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#23545;CL&#30340;&#25511;&#21046;&#21644;&#31649;&#29702;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#30828;&#20214;&#26550;&#26500;TinyCL&#65292;&#29992;&#20110;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#33258;&#20027;&#31995;&#32479;&#19978;&#36827;&#34892;&#25345;&#32493;&#23398;&#20064;&#12290;&#23427;&#21253;&#25324;&#19968;&#20010;&#25191;&#34892;&#21069;&#21521;&#21644;&#21453;&#21521;&#20256;&#25773;&#30340;&#22788;&#29702;&#21333;&#20803;&#65292;&#20197;&#21450;&#19968;&#20010;&#31649;&#29702;&#22522;&#20110;&#20869;&#23384;&#30340;CL&#24037;&#20316;&#36127;&#36733;&#30340;&#25511;&#21046;&#21333;&#20803;&#12290;&#20026;&#20102;&#26368;&#23567;&#21270;&#20869;&#23384;&#35775;&#38382;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#28369;&#21160;&#31383;&#21475;&#30340;&#36830;&#32493;&#23398;&#20064;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09780v1 Announce Type: new  Abstract: The Continuous Learning (CL) paradigm consists of continuously evolving the parameters of the Deep Neural Network (DNN) model to progressively learn to perform new tasks without reducing the performance on previous tasks, i.e., avoiding the so-called catastrophic forgetting. However, the DNN parameter update in CL-based autonomous systems is extremely resource-hungry. The existing DNN accelerators cannot be directly employed in CL because they only support the execution of the forward propagation. Only a few prior architectures execute the backpropagation and weight update, but they lack the control and management for CL. Towards this, we design a hardware architecture, TinyCL, to perform CL on resource-constrained autonomous systems. It consists of a processing unit that executes both forward and backward propagation, and a control unit that manages memory-based CL workload. To minimize the memory accesses, the sliding window of the con
&lt;/p&gt;</description></item><item><title>FreDF&#26159;&#19968;&#31181;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#26631;&#31614;&#24207;&#21015;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;</title><link>https://arxiv.org/abs/2402.02399</link><description>&lt;p&gt;
FreDF: &#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
FreDF: Learning to Forecast in Frequency Domain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02399
&lt;/p&gt;
&lt;p&gt;
FreDF&#26159;&#19968;&#31181;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#26631;&#31614;&#24207;&#21015;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#22312;&#21382;&#21490;&#24207;&#21015;&#21644;&#26631;&#31614;&#24207;&#21015;&#20013;&#37117;&#38754;&#20020;&#33258;&#30456;&#20851;&#30340;&#25361;&#25112;&#12290;&#24403;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22788;&#29702;&#21382;&#21490;&#24207;&#21015;&#20013;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#20294;&#24448;&#24448;&#24573;&#35270;&#20102;&#26631;&#31614;&#24207;&#21015;&#20013;&#30340;&#33258;&#30456;&#20851;&#23384;&#22312;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#26032;&#20852;&#30340;&#39044;&#27979;&#27169;&#22411;&#20027;&#35201;&#36981;&#24490;&#30452;&#25509;&#39044;&#27979;&#65288;DF&#65289;&#33539;&#24335;&#65292;&#22312;&#26631;&#31614;&#24207;&#21015;&#20013;&#20551;&#35774;&#26465;&#20214;&#29420;&#31435;&#24615;&#19979;&#29983;&#25104;&#22810;&#27493;&#39044;&#27979;&#12290;&#36825;&#31181;&#20551;&#35774;&#24573;&#35270;&#20102;&#26631;&#31614;&#24207;&#21015;&#20013;&#22266;&#26377;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#22522;&#20110;DF&#30340;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#38024;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#39057;&#22495;&#22686;&#24378;&#30452;&#25509;&#39044;&#27979;&#65288;FreDF&#65289;&#65292;&#36890;&#36807;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#26469;&#36991;&#20813;&#26631;&#31614;&#33258;&#30456;&#20851;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;FreDF&#22312;&#24615;&#33021;&#19978;&#22823;&#22823;&#36229;&#36807;&#20102;&#21253;&#25324;iTransformer&#22312;&#20869;&#30340;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series modeling is uniquely challenged by the presence of autocorrelation in both historical and label sequences. Current research predominantly focuses on handling autocorrelation within the historical sequence but often neglects its presence in the label sequence. Specifically, emerging forecast models mainly conform to the direct forecast (DF) paradigm, generating multi-step forecasts under the assumption of conditional independence within the label sequence. This assumption disregards the inherent autocorrelation in the label sequence, thereby limiting the performance of DF-based models. In response to this gap, we introduce the Frequency-enhanced Direct Forecast (FreDF), which bypasses the complexity of label autocorrelation by learning to forecast in the frequency domain. Our experiments demonstrate that FreDF substantially outperforms existing state-of-the-art methods including iTransformer and is compatible with a variety of forecast models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38024;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;&#65292;&#21457;&#29616;GNN&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#21518;&#38376;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#35813;&#20219;&#21153;&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.02663</link><description>&lt;p&gt;
&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#30340;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
A backdoor attack against link prediction tasks with graph neural networks. (arXiv:2401.02663v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02663
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38024;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;&#65292;&#21457;&#29616;GNN&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#21518;&#38376;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#35813;&#20219;&#21153;&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26159;&#19968;&#31867;&#33021;&#22815;&#22788;&#29702;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;GNN&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#21518;&#38376;&#25915;&#20987;&#12290;&#24403;&#20855;&#20307;&#30340;&#27169;&#24335;&#65288;&#31216;&#20026;&#21518;&#38376;&#35302;&#21457;&#22120;&#65292;&#20363;&#22914;&#23376;&#22270;&#12289;&#33410;&#28857;&#31561;&#65289;&#20986;&#29616;&#22312;&#36755;&#20837;&#25968;&#25454;&#20013;&#26102;&#65292;&#23884;&#20837;&#22312;GNN&#27169;&#22411;&#20013;&#30340;&#21518;&#38376;&#20250;&#34987;&#28608;&#27963;&#65292;&#23558;&#36755;&#20837;&#25968;&#25454;&#35823;&#20998;&#31867;&#20026;&#25915;&#20987;&#32773;&#25351;&#23450;&#30340;&#30446;&#26631;&#31867;&#26631;&#31614;&#65292;&#32780;&#24403;&#36755;&#20837;&#20013;&#27809;&#26377;&#21518;&#38376;&#35302;&#21457;&#22120;&#26102;&#65292;&#23884;&#20837;&#22312;GNN&#27169;&#22411;&#20013;&#30340;&#21518;&#38376;&#19981;&#20250;&#34987;&#28608;&#27963;&#65292;&#27169;&#22411;&#27491;&#24120;&#24037;&#20316;&#12290;&#21518;&#38376;&#25915;&#20987;&#20855;&#26377;&#26497;&#39640;&#30340;&#38544;&#34109;&#24615;&#65292;&#32473;GNN&#27169;&#22411;&#24102;&#26469;&#20005;&#37325;&#30340;&#23433;&#20840;&#39118;&#38505;&#12290;&#30446;&#21069;&#65292;&#23545;GNN&#30340;&#21518;&#38376;&#25915;&#20987;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22270;&#20998;&#31867;&#21644;&#33410;&#28857;&#20998;&#31867;&#31561;&#20219;&#21153;&#19978;&#65292;&#23545;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#30340;&#21518;&#38376;&#25915;&#20987;&#30740;&#31350;&#36739;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are a class of deep learning models capable of processing graph-structured data, and they have demonstrated significant performance in a variety of real-world applications. Recent studies have found that GNN models are vulnerable to backdoor attacks. When specific patterns (called backdoor triggers, e.g., subgraphs, nodes, etc.) appear in the input data, the backdoor embedded in the GNN models is activated, which misclassifies the input data into the target class label specified by the attacker, whereas when there are no backdoor triggers in the input, the backdoor embedded in the GNN models is not activated, and the models work normally. Backdoor attacks are highly stealthy and expose GNN models to serious security risks. Currently, research on backdoor attacks against GNNs mainly focus on tasks such as graph classification and node classification, and backdoor attacks against link prediction tasks are rarely studied. In this paper, we propose a backdoor a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#35780;&#20272;&#25968;&#25454;&#27969;&#21152;&#36895;&#22120;&#19978;&#30340;&#20391;&#20449;&#36947;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25915;&#20987;&#26041;&#27861;&#26469;&#24674;&#22797;CNN&#27169;&#22411;&#30340;&#26550;&#26500;&#12290;&#35813;&#25915;&#20987;&#21033;&#29992;&#20102;&#25968;&#25454;&#27969;&#26144;&#23556;&#30340;&#25968;&#25454;&#37325;&#29992;&#20197;&#21450;&#26550;&#26500;&#32447;&#32034;&#65292;&#25104;&#21151;&#24674;&#22797;&#20102;&#27969;&#34892;&#30340;CNN&#27169;&#22411;Lenet&#65292;Alexnet&#21644;VGGnet16&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2311.00579</link><description>&lt;p&gt;
&#36890;&#36807;&#25968;&#25454;&#27969;&#25512;&#29702;&#21152;&#36895;&#22120;&#20013;&#30340;&#20391;&#20449;&#36947;&#20998;&#26512;&#25581;&#31034;CNN&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based Inference Accelerators. (arXiv:2311.00579v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#35780;&#20272;&#25968;&#25454;&#27969;&#21152;&#36895;&#22120;&#19978;&#30340;&#20391;&#20449;&#36947;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25915;&#20987;&#26041;&#27861;&#26469;&#24674;&#22797;CNN&#27169;&#22411;&#30340;&#26550;&#26500;&#12290;&#35813;&#25915;&#20987;&#21033;&#29992;&#20102;&#25968;&#25454;&#27969;&#26144;&#23556;&#30340;&#25968;&#25454;&#37325;&#29992;&#20197;&#21450;&#26550;&#26500;&#32447;&#32034;&#65292;&#25104;&#21151;&#24674;&#22797;&#20102;&#27969;&#34892;&#30340;CNN&#27169;&#22411;Lenet&#65292;Alexnet&#21644;VGGnet16&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#26368;&#36817;&#22312;&#22522;&#20110;&#25968;&#25454;&#27969;&#30340;CNN&#21152;&#36895;&#22120;&#30340;&#36827;&#23637;&#20351;&#24471;CNN&#25512;&#29702;&#21487;&#20197;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#36793;&#32536;&#35774;&#22791;&#19978;&#36827;&#34892;&#12290;&#36825;&#20123;&#25968;&#25454;&#27969;&#21152;&#36895;&#22120;&#21033;&#29992;&#21367;&#31215;&#23618;&#30340;&#22266;&#26377;&#25968;&#25454;&#37325;&#29992;&#26469;&#39640;&#25928;&#22788;&#29702;CNN&#27169;&#22411;&#12290;&#38544;&#34255;CNN&#27169;&#22411;&#30340;&#26550;&#26500;&#23545;&#20110;&#38544;&#31169;&#21644;&#23433;&#20840;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#20869;&#23384;&#30340;&#20391;&#20449;&#36947;&#20449;&#24687;&#65292;&#20197;&#20174;&#25968;&#25454;&#27969;&#21152;&#36895;&#22120;&#20013;&#24674;&#22797;CNN&#26550;&#26500;&#12290;&#25152;&#25552;&#20986;&#30340;&#25915;&#20987;&#21033;&#29992;&#20102;CNN&#21152;&#36895;&#22120;&#19978;&#25968;&#25454;&#27969;&#26144;&#23556;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#25968;&#25454;&#37325;&#29992;&#20197;&#21450;&#26550;&#26500;&#32447;&#32034;&#26469;&#24674;&#22797;CNN&#27169;&#22411;&#30340;&#32467;&#26500;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#20391;&#20449;&#36947;&#25915;&#20987;&#21487;&#20197;&#24674;&#22797;&#27969;&#34892;&#30340;CNN&#27169;&#22411;Lenet&#65292;Alexnet&#21644;VGGnet16&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Convolution Neural Networks (CNNs) are widely used in various domains. Recent advances in dataflow-based CNN accelerators have enabled CNN inference in resource-constrained edge devices. These dataflow accelerators utilize inherent data reuse of convolution layers to process CNN models efficiently. Concealing the architecture of CNN models is critical for privacy and security. This paper evaluates memory-based side-channel information to recover CNN architectures from dataflow-based CNN inference accelerators. The proposed attack exploits spatial and temporal data reuse of the dataflow mapping on CNN accelerators and architectural hints to recover the structure of CNN models. Experimental results demonstrate that our proposed side-channel attack can recover the structures of popular CNN models, namely Lenet, Alexnet, and VGGnet16.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#20989;&#25968;&#26469;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#26080;&#38656;&#35757;&#32451;&#65292;&#19988;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#33021;&#22815;&#23454;&#29616;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.12395</link><description>&lt;p&gt;
&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Closed-Form Diffusion Models. (arXiv:2310.12395v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#20989;&#25968;&#26469;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#26080;&#38656;&#35757;&#32451;&#65292;&#19988;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#33021;&#22815;&#23454;&#29616;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;(SGMs)&#36890;&#36807;&#36845;&#20195;&#22320;&#20351;&#29992;&#25200;&#21160;&#30446;&#26631;&#20989;&#25968;&#30340;&#24471;&#20998;&#20989;&#25968;&#26469;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#23545;&#20110;&#20219;&#20309;&#26377;&#38480;&#30340;&#35757;&#32451;&#38598;&#65292;&#21487;&#20197;&#38381;&#24335;&#22320;&#35780;&#20272;&#36825;&#20010;&#24471;&#20998;&#20989;&#25968;&#65292;&#20294;&#30001;&#27492;&#24471;&#21040;&#30340;SGMs&#20250;&#35760;&#24518;&#20854;&#35757;&#32451;&#25968;&#25454;&#65292;&#19981;&#33021;&#29983;&#25104;&#26032;&#26679;&#26412;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#24471;&#20998;&#20989;&#25968;&#65292;&#20294;&#36825;&#31181;&#36817;&#20284;&#30340;&#35823;&#24046;&#26377;&#21161;&#20110;&#25512;&#24191;&#65292;&#28982;&#32780;&#31070;&#32463;SGMs&#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#20195;&#20215;&#39640;&#65292;&#32780;&#19988;&#23545;&#20110;&#36825;&#31181;&#35823;&#24046;&#25552;&#20379;&#30340;&#26377;&#25928;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#23578;&#19981;&#28165;&#26970;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#26469;&#33719;&#24471;&#19968;&#20010;&#29983;&#25104;&#26032;&#26679;&#26412;&#30340;SGMs&#65292;&#32780;&#26080;&#38656;&#35757;&#32451;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#39640;&#25928;&#24471;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#12290;&#21033;&#29992;&#36825;&#20010;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#36816;&#34892;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models (SGMs) sample from a target distribution by iteratively transforming noise using the score function of the perturbed target. For any finite training set, this score function can be evaluated in closed form, but the resulting SGM memorizes its training data and does not generate novel samples. In practice, one approximates the score by training a neural network via score-matching. The error in this approximation promotes generalization, but neural SGMs are costly to train and sample, and the effective regularization this error provides is not well-understood theoretically. In this work, we instead explicitly smooth the closed-form score to obtain an SGM that generates novel samples without training. We analyze our model and propose an efficient nearest-neighbor-based estimator of its score function. Using this estimator, our method achieves sampling times competitive with neural SGMs while running on consumer-grade CPUs.
&lt;/p&gt;</description></item><item><title>ParFam&#26159;&#19968;&#31181;&#26032;&#30340;&#31526;&#21495;&#22238;&#24402;&#26041;&#27861;&#65292;&#21033;&#29992;&#21442;&#25968;&#21270;&#30340;&#31526;&#21495;&#20989;&#25968;&#26063;&#23558;&#31163;&#25955;&#38382;&#39064;&#36716;&#21270;&#20026;&#36830;&#32493;&#38382;&#39064;&#65292;&#24182;&#32467;&#21512;&#20840;&#23616;&#20248;&#21270;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#31526;&#21495;&#22238;&#24402;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05537</link><description>&lt;p&gt;
ParFam - &#22522;&#20110;&#36830;&#32493;&#20840;&#23616;&#20248;&#21270;&#30340;&#31526;&#21495;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
ParFam -- Symbolic Regression Based on Continuous Global Optimization. (arXiv:2310.05537v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05537
&lt;/p&gt;
&lt;p&gt;
ParFam&#26159;&#19968;&#31181;&#26032;&#30340;&#31526;&#21495;&#22238;&#24402;&#26041;&#27861;&#65292;&#21033;&#29992;&#21442;&#25968;&#21270;&#30340;&#31526;&#21495;&#20989;&#25968;&#26063;&#23558;&#31163;&#25955;&#38382;&#39064;&#36716;&#21270;&#20026;&#36830;&#32493;&#38382;&#39064;&#65292;&#24182;&#32467;&#21512;&#20840;&#23616;&#20248;&#21270;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#31526;&#21495;&#22238;&#24402;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21495;&#22238;&#24402;&#65288;SR&#65289;&#38382;&#39064;&#22312;&#35768;&#22810;&#19981;&#21516;&#30340;&#24212;&#29992;&#20013;&#20986;&#29616;&#65292;&#27604;&#22914;&#20174;&#32473;&#23450;&#25968;&#25454;&#20013;&#35782;&#21035;&#29289;&#29702;&#23450;&#24459;&#25110;&#25512;&#23548;&#25551;&#36848;&#37329;&#34701;&#24066;&#22330;&#34892;&#20026;&#30340;&#25968;&#23398;&#26041;&#31243;&#12290;&#30446;&#21069;&#23384;&#22312;&#22810;&#31181;&#35299;&#20915;SR&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#24120;&#22522;&#20110;&#36951;&#20256;&#32534;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#38750;&#24120;&#22797;&#26434;&#65292;&#38656;&#35201;&#22823;&#37327;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#35745;&#31639;&#36164;&#28304;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26032;&#26041;&#27861;ParFam&#65292;&#23427;&#21033;&#29992;&#36866;&#21512;&#30340;&#31526;&#21495;&#20989;&#25968;&#30340;&#21442;&#25968;&#21270;&#26063;&#23558;&#31163;&#25955;&#30340;&#31526;&#21495;&#22238;&#24402;&#38382;&#39064;&#36716;&#21270;&#20026;&#36830;&#32493;&#38382;&#39064;&#65292;&#30456;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#35774;&#32622;&#26356;&#21152;&#30452;&#35266;&#12290;&#32467;&#21512;&#24378;&#22823;&#30340;&#20840;&#23616;&#20248;&#21270;&#22120;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;SR&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#23427;&#21487;&#20197;&#36731;&#26494;&#25193;&#23637;&#21040;&#26356;&#39640;&#32423;&#30340;&#31639;&#27861;&#65292;&#20363;&#22914;&#28155;&#21152;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20197;&#25214;&#21040;&#36866;&#21512;&#30340;&#21442;&#25968;&#21270;&#26063;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of symbolic regression (SR) arises in many different applications, such as identifying physical laws or deriving mathematical equations describing the behavior of financial markets from given data. Various methods exist to address the problem of SR, often based on genetic programming. However, these methods are usually quite complicated and require a lot of hyperparameter tuning and computational resources. In this paper, we present our new method ParFam that utilizes parametric families of suitable symbolic functions to translate the discrete symbolic regression problem into a continuous one, resulting in a more straightforward setup compared to current state-of-the-art methods. In combination with a powerful global optimizer, this approach results in an effective method to tackle the problem of SR. Furthermore, it can be easily extended to more advanced algorithms, e.g., by adding a deep neural network to find good-fitting parametric families. We prove the performance of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;NoC&#26550;&#26500;&#20013;&#29616;&#26377;&#21311;&#21517;&#36335;&#30001;&#21327;&#35758;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#21311;&#21517;&#36335;&#30001;&#23545;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#26131;&#21463;&#25915;&#20987;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#21311;&#21517;&#36335;&#30001;&#65292;&#20351;&#29992;&#27969;&#37327;&#28151;&#28102;&#25216;&#26415;&#65292;&#21487;&#20197;&#25269;&#24481;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2309.15687</link><description>&lt;p&gt;
&#25171;&#30772;NoC&#21311;&#21517;&#24615;&#20351;&#29992;&#27969;&#30456;&#20851;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Breaking NoC Anonymity using Flow Correlation Attack. (arXiv:2309.15687v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;NoC&#26550;&#26500;&#20013;&#29616;&#26377;&#21311;&#21517;&#36335;&#30001;&#21327;&#35758;&#30340;&#23433;&#20840;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#21311;&#21517;&#36335;&#30001;&#23545;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#26131;&#21463;&#25915;&#20987;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#21311;&#21517;&#36335;&#30001;&#65292;&#20351;&#29992;&#27969;&#37327;&#28151;&#28102;&#25216;&#26415;&#65292;&#21487;&#20197;&#25269;&#24481;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#29255;&#19978;&#20114;&#36830;&#65288;NoC&#65289;&#24191;&#27867;&#29992;&#20316;&#24403;&#20170;&#22810;&#26680;&#29255;&#19978;&#31995;&#32479;&#65288;SoC&#65289;&#35774;&#35745;&#20013;&#30340;&#20869;&#37096;&#36890;&#20449;&#32467;&#26500;&#12290;&#29255;&#19978;&#36890;&#20449;&#30340;&#23433;&#20840;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#21033;&#29992;&#20849;&#20139;&#30340;NoC&#20013;&#30340;&#20219;&#20309;&#28431;&#27934;&#23545;&#25915;&#20987;&#32773;&#26469;&#35828;&#37117;&#26159;&#19968;&#20010;&#23500;&#30719;&#12290;NoC&#23433;&#20840;&#20381;&#36182;&#20110;&#23545;&#21508;&#31181;&#25915;&#20987;&#30340;&#26377;&#25928;&#38450;&#33539;&#25514;&#26045;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;NoC&#26550;&#26500;&#20013;&#29616;&#26377;&#21311;&#21517;&#36335;&#30001;&#21327;&#35758;&#30340;&#23433;&#20840;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26412;&#25991;&#20316;&#20986;&#20102;&#20004;&#20010;&#37325;&#35201;&#36129;&#29486;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#21311;&#21517;&#36335;&#30001;&#23545;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#26159;&#26131;&#21463;&#25915;&#20987;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#21311;&#21517;&#36335;&#30001;&#65292;&#20351;&#29992;&#27969;&#37327;&#28151;&#28102;&#25216;&#26415;&#65292;&#21487;&#20197;&#25269;&#24481;&#22522;&#20110;ML&#30340;&#27969;&#30456;&#20851;&#25915;&#20987;&#12290;&#20351;&#29992;&#23454;&#38469;&#21644;&#21512;&#25104;&#27969;&#37327;&#36827;&#34892;&#30340;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#25915;&#20987;&#33021;&#22815;&#25104;&#21151;&#22320;&#23545;&#25239;NoC&#26550;&#26500;&#20013;&#26368;&#20808;&#36827;&#30340;&#21311;&#21517;&#36335;&#30001;&#65292;&#23545;&#20110;&#22810;&#31181;&#27969;&#37327;&#27169;&#24335;&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#39640;&#36798;99&#65285;&#65292;&#21516;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network-on-Chip (NoC) is widely used as the internal communication fabric in today's multicore System-on-Chip (SoC) designs. Security of the on-chip communication is crucial because exploiting any vulnerability in shared NoC would be a goldmine for an attacker. NoC security relies on effective countermeasures against diverse attacks. We investigate the security strength of existing anonymous routing protocols in NoC architectures. Specifically, this paper makes two important contributions. We show that the existing anonymous routing is vulnerable to machine learning (ML) based flow correlation attacks on NoCs. We propose a lightweight anonymous routing that use traffic obfuscation techniques which can defend against ML-based flow correlation attacks. Experimental studies using both real and synthetic traffic reveal that our proposed attack is successful against state-of-the-art anonymous routing in NoC architectures with a high accuracy (up to 99%) for diverse traffic patterns, while o
&lt;/p&gt;</description></item><item><title>META-CODE&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#23398;&#20064;&#21644;&#26131;&#20110;&#25910;&#38598;&#30340;&#33410;&#28857;&#20803;&#25968;&#25454;&#65292;&#22312;&#26410;&#30693;&#25299;&#25169;&#32593;&#32476;&#20013;&#26816;&#27979;&#37325;&#21472;&#31038;&#21306;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;META-CODE&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.04497</link><description>&lt;p&gt;
&#26410;&#30693;&#25299;&#25169;&#32593;&#32476;&#20013;&#30340;&#25506;&#32034;&#23398;&#20064;&#36741;&#21161;&#31038;&#21306;&#26816;&#27979;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unified Framework for Exploratory Learning-Aided Community Detection in Networks with Unknown Topology. (arXiv:2304.04497v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04497
&lt;/p&gt;
&lt;p&gt;
META-CODE&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#23398;&#20064;&#21644;&#26131;&#20110;&#25910;&#38598;&#30340;&#33410;&#28857;&#20803;&#25968;&#25454;&#65292;&#22312;&#26410;&#30693;&#25299;&#25169;&#32593;&#32476;&#20013;&#26816;&#27979;&#37325;&#21472;&#31038;&#21306;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;META-CODE&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#65292;&#21457;&#29616;&#31038;&#21306;&#32467;&#26500;&#20316;&#20026;&#21508;&#31181;&#32593;&#32476;&#20998;&#26512;&#20219;&#21153;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38544;&#31169;&#38382;&#39064;&#25110;&#35775;&#38382;&#38480;&#21046;&#65292;&#32593;&#32476;&#32467;&#26500;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#65292;&#36825;&#20351;&#24471;&#29616;&#26377;&#30340;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#22312;&#27809;&#26377;&#26114;&#36149;&#30340;&#32593;&#32476;&#25299;&#25169;&#33719;&#21462;&#30340;&#24773;&#20917;&#19979;&#26080;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; META-CODE&#65292;&#36825;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#23398;&#20064;&#36741;&#21161;&#26131;&#20110;&#25910;&#38598;&#30340;&#33410;&#28857;&#20803;&#25968;&#25454;&#65292;&#22312;&#26410;&#30693;&#25299;&#25169;&#32593;&#32476;&#20013;&#26816;&#27979;&#37325;&#21472;&#31038;&#21306;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;META-CODE &#38500;&#20102;&#21021;&#22987;&#30340;&#32593;&#32476;&#25512;&#29702;&#27493;&#39588;&#22806;&#65292;&#36824;&#21253;&#25324;&#19977;&#20010;&#36845;&#20195;&#27493;&#39588;&#65306;1) &#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#33410;&#28857;&#32423;&#31038;&#21306;&#24402;&#23646;&#23884;&#20837;&#65292;&#36890;&#36807;&#25105;&#20204;&#30340;&#26032;&#37325;&#26500;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#65292;2) &#22522;&#20110;&#31038;&#21306;&#24402;&#23646;&#30340;&#33410;&#28857;&#26597;&#35810;&#36827;&#34892;&#32593;&#32476;&#25506;&#32034;&#65292;3) &#20351;&#29992;&#25506;&#32034;&#32593;&#32476;&#20013;&#30340;&#22522;&#20110;&#36793;&#36830;&#25509;&#30340;&#36830;&#20307;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#32593;&#32476;&#25512;&#29702;&#12290;&#36890;&#36807;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102; META-CODE &#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In social networks, the discovery of community structures has received considerable attention as a fundamental problem in various network analysis tasks. However, due to privacy concerns or access restrictions, the network structure is often unknown, thereby rendering established community detection approaches ineffective without costly network topology acquisition. To tackle this challenge, we present META-CODE, a unified framework for detecting overlapping communities in networks with unknown topology via exploratory learning aided by easy-to-collect node metadata. Specifically, META-CODE consists of three iterative steps in addition to the initial network inference step: 1) node-level community-affiliation embeddings based on graph neural networks (GNNs) trained by our new reconstruction loss, 2) network exploration via community-affiliation-based node queries, and 3) network inference using an edge connectivity-based Siamese neural network model from the explored network. Through e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#26102;&#38388;&#19979;&#30340;q-Learning&#65292;&#36890;&#36807;&#24341;&#20837;&#23567;q&#20989;&#25968;&#20316;&#20026;&#19968;&#38454;&#36817;&#20284;&#65292;&#30740;&#31350;&#20102;q-learning&#29702;&#35770;&#65292;&#24212;&#29992;&#20110;&#35774;&#35745;&#19981;&#21516;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2207.00713</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#19979;&#30340;q-Learning
&lt;/p&gt;
&lt;p&gt;
q-Learning in Continuous Time. (arXiv:2207.00713v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.00713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#26102;&#38388;&#19979;&#30340;q-Learning&#65292;&#36890;&#36807;&#24341;&#20837;&#23567;q&#20989;&#25968;&#20316;&#20026;&#19968;&#38454;&#36817;&#20284;&#65292;&#30740;&#31350;&#20102;q-learning&#29702;&#35770;&#65292;&#24212;&#29992;&#20110;&#35774;&#35745;&#19981;&#21516;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#29109;&#27491;&#21017;&#21270;&#30340;&#25506;&#32034;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;Q-learning&#22312;&#36830;&#32493;&#26102;&#38388;&#19979;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#23567;q&#20989;&#25968;&#8221;&#20316;&#20026;&#22823;Q&#20989;&#25968;&#30340;&#19968;&#38454;&#36817;&#20284;&#65292;&#30740;&#31350;&#20102;q&#20989;&#25968;&#30340;q-learning&#29702;&#35770;&#65292;&#24182;&#24212;&#29992;&#20110;&#35774;&#35745;&#19981;&#21516;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the continuous-time counterpart of Q-learning for reinforcement learning (RL) under the entropy-regularized, exploratory diffusion process formulation introduced by Wang et al. (2020). As the conventional (big) Q-function collapses in continuous time, we consider its first-order approximation and coin the term ``(little) q-function". This function is related to the instantaneous advantage rate function as well as the Hamiltonian. We develop a ``q-learning" theory around the q-function that is independent of time discretization. Given a stochastic policy, we jointly characterize the associated q-function and value function by martingale conditions of certain stochastic processes, in both on-policy and off-policy settings. We then apply the theory to devise different actor-critic algorithms for solving underlying RL problems, depending on whether or not the density function of the Gibbs measure generated from the q-function can be computed explicitly. One of our algorithms inter
&lt;/p&gt;</description></item></channel></rss>