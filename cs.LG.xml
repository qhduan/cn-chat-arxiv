<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;RMSProp&#21644;Adam&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#32039;&#33268;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#23637;&#31034;&#20102;&#22312;&#26368;&#23485;&#26494;&#30340;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RMSProp&#21644;Adam&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;</title><link>https://arxiv.org/abs/2404.01436</link><description>&lt;p&gt;
RMSProp&#21644;Adam&#22312;&#20855;&#26377;&#20223;&#23556;&#22122;&#22768;&#26041;&#24046;&#30340;&#24191;&#20041;&#20809;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;RMSProp&#21644;Adam&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#32039;&#33268;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#23637;&#31034;&#20102;&#22312;&#26368;&#23485;&#26494;&#30340;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RMSProp&#21644;Adam&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22352;&#26631;&#32423;&#21035;&#24191;&#20041;&#20809;&#28369;&#24615;&#21644;&#20223;&#23556;&#22122;&#22768;&#26041;&#24046;&#30340;&#26368;&#23485;&#26494;&#20551;&#35774;&#19979;&#65292;&#20026;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;RMSProp&#21644;Adam&#25552;&#20379;&#20102;&#39318;&#20010;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#39318;&#20808;&#20998;&#26512;&#20102;RMSProp&#65292;&#23427;&#26159;&#19968;&#31181;&#20855;&#26377;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#20294;&#27809;&#26377;&#19968;&#38454;&#21160;&#37327;&#30340;Adam&#30340;&#29305;&#20363;&#12290;&#20855;&#20307;&#22320;&#65292;&#20026;&#20102;&#35299;&#20915;&#33258;&#36866;&#24212;&#26356;&#26032;&#12289;&#26080;&#30028;&#26799;&#24230;&#20272;&#35745;&#21644;Lipschitz&#24120;&#25968;&#20043;&#38388;&#30340;&#20381;&#36182;&#25361;&#25112;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19979;&#38477;&#24341;&#29702;&#20013;&#30340;&#19968;&#38454;&#39033;&#25910;&#25947;&#65292;&#24182;&#19988;&#20854;&#20998;&#27597;&#30001;&#26799;&#24230;&#33539;&#25968;&#30340;&#20989;&#25968;&#19978;&#30028;&#38480;&#21046;&#12290;&#22522;&#20110;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#36866;&#24403;&#30340;&#36229;&#21442;&#25968;&#30340;RMSProp&#25910;&#25947;&#21040;&#19968;&#20010;$\epsilon$-&#31283;&#23450;&#28857;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;&#28982;&#21518;&#65292;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25512;&#24191;&#21040;Adam&#65292;&#39069;&#22806;&#30340;&#25361;&#25112;&#26159;&#30001;&#20110;&#26799;&#24230;&#19982;&#19968;&#38454;&#21160;&#37327;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01436v1 Announce Type: cross  Abstract: This paper provides the first tight convergence analyses for RMSProp and Adam in non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. We first analyze RMSProp, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and first-order momentum. We develop a new upper bound on
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#22768;&#26126;&#24615;&#12289;&#32479;&#19968;API&#30340;Python&#24211;&#65292;&#36890;&#36807;&#31616;&#27905;&#30340;API&#35843;&#29992;&#31616;&#21270;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#27969;&#31243;</title><link>https://arxiv.org/abs/2403.08291</link><description>&lt;p&gt;
CleanAgent&#65306;&#22522;&#20110;LLM&#20195;&#29702;&#33258;&#21160;&#21270;&#25968;&#25454;&#26631;&#20934;&#21270;
&lt;/p&gt;
&lt;p&gt;
CleanAgent: Automating Data Standardization with LLM-based Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08291
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#22768;&#26126;&#24615;&#12289;&#32479;&#19968;API&#30340;Python&#24211;&#65292;&#36890;&#36807;&#31616;&#27905;&#30340;API&#35843;&#29992;&#31616;&#21270;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#27969;&#31243;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#26631;&#20934;&#21270;&#26159;&#25968;&#25454;&#31185;&#23398;&#29983;&#21629;&#21608;&#26399;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#19968;&#37096;&#20998;&#12290;&#34429;&#28982;&#35832;&#22914;Pandas&#20043;&#31867;&#30340;&#24037;&#20855;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21151;&#33021;&#65292;&#20294;&#23427;&#20204;&#30340;&#22797;&#26434;&#24615;&#20197;&#21450;&#38656;&#35201;&#23450;&#21046;&#20195;&#30721;&#20197;&#36866;&#24212;&#19981;&#21516;&#21015;&#31867;&#22411;&#30340;&#25163;&#21160;&#25805;&#20316;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;ChatGPT&#24050;&#32463;&#23637;&#29616;&#20986;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#20195;&#30721;&#29983;&#25104;&#33258;&#21160;&#21270;&#27492;&#36807;&#31243;&#30340;&#28508;&#21147;&#65292;&#20294;&#20173;&#38656;&#35201;&#19987;&#19994;&#31243;&#24230;&#30340;&#32534;&#31243;&#30693;&#35782;&#21644;&#25345;&#32493;&#20114;&#21160;&#20197;&#36827;&#34892;&#21450;&#26102;&#30340;&#23436;&#21892;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#30340;&#20851;&#38190;&#24819;&#27861;&#26159;&#25552;&#20986;&#19968;&#20010;&#20855;&#26377;&#22768;&#26126;&#24615;&#12289;&#32479;&#19968;API&#30340;Python&#24211;&#65292;&#29992;&#20110;&#26631;&#20934;&#21270;&#21015;&#31867;&#22411;&#65292;&#36890;&#36807;&#31616;&#27905;&#30340;API&#35843;&#29992;&#31616;&#21270;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#27969;&#31243;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;Dataprep.Clean&#65292;&#20316;&#20026;Dataprep&#24211;&#30340;&#19968;&#20010;&#32452;&#20214;&#65292;&#36890;&#36807;&#19968;&#34892;&#20195;&#30721;&#23454;&#29616;&#29305;&#23450;&#21015;&#31867;&#22411;&#30340;&#26631;&#20934;&#21270;&#65292;&#26497;&#22823;&#38477;&#20302;&#20102;&#22797;&#26434;&#24615;&#12290;&#28982;&#21518;&#25105;&#20204;&#20171;&#32461;&#20102;CleanAgen
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08291v1 Announce Type: cross  Abstract: Data standardization is a crucial part in data science life cycle. While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges. Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement. To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing column types, simplifying the code generation of LLM with concise API calls. We first propose Dataprep.Clean which is written as a component of the Dataprep Library, offers a significant reduction in complexity by enabling the standardization of specific column types with a single line of code. Then we introduce the CleanAgen
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#37325;&#24314;&#25915;&#20987;&#65292;&#20316;&#32773;&#21457;&#29616;&#22312;DP-SGD&#19979;&#65292;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20808;&#39564;&#23545;&#20110;&#37325;&#24314;&#25104;&#21151;&#20855;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.07588</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#35270;&#35273;&#38544;&#31169;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Visual Privacy Auditing with Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07588
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#37325;&#24314;&#25915;&#20987;&#65292;&#20316;&#32773;&#21457;&#29616;&#22312;DP-SGD&#19979;&#65292;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20808;&#39564;&#23545;&#20110;&#37325;&#24314;&#25104;&#21151;&#20855;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07588v1 &#22768;&#26126;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22270;&#20687;&#37325;&#24314;&#25915;&#20987;&#21487;&#33021;&#20250;&#23548;&#33268;&#27844;&#38706;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23545;&#38544;&#31169;&#26500;&#25104;&#37325;&#22823;&#39118;&#38505;&#12290;&#34429;&#28982;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;(DP)&#26469;&#25269;&#24481;&#27492;&#31867;&#25915;&#20987;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#30830;&#23450;&#36866;&#24403;&#30340;DP&#21442;&#25968;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#24403;&#21069;&#23545;&#25968;&#25454;&#37325;&#24314;&#25104;&#21151;&#30340;&#24418;&#24335;&#21270;&#20445;&#35777;&#21463;&#21040;&#20102;&#20851;&#20110;&#23545;&#25163;&#23545;&#30446;&#26631;&#25968;&#25454;&#30340;&#20102;&#35299;&#30340;&#36807;&#20110;&#29702;&#35770;&#21270;&#30340;&#20551;&#35774;&#30340;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#22312;&#22270;&#20687;&#39046;&#22495;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#35843;&#26597;&#36825;&#19968;&#24046;&#24322;&#65292;&#24182;&#21457;&#29616;&#36825;&#20123;&#20551;&#35774;&#30340;&#23454;&#38469;&#24615;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#25968;&#25454;&#20808;&#39564;&#21644;&#37325;&#24314;&#30446;&#26631;&#20043;&#38388;&#30340;&#22495;&#36716;&#31227;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;(DMs)&#30340;&#37325;&#24314;&#25915;&#20987;&#65292;&#20551;&#35774;&#23545;&#25163;&#21487;&#20197;&#35775;&#38382;&#30495;&#23454;&#19990;&#30028;&#30340;&#22270;&#20687;&#20808;&#39564;&#65292;&#24182;&#35780;&#20272;&#20854;&#23545;&#22312;DP-SGD&#19979;&#30340;&#38544;&#31169;&#27844;&#38706;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;(1)&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20808;&#39564;&#26174;&#33879;&#24433;&#21709;&#37325;&#24314;&#25104;&#21151;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07588v1 Announce Type: new  Abstract: Image reconstruction attacks on machine learning models pose a significant risk to privacy by potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) has proven effective, determining appropriate DP parameters remains challenging. Current formal guarantees on data reconstruction success suffer from overly theoretical assumptions regarding adversary knowledge about the target data, particularly in the image domain. In this work, we empirically investigate this discrepancy and find that the practicality of these assumptions strongly depends on the domain shift between the data prior and the reconstruction target. We propose a reconstruction attack based on diffusion models (DMs) that assumes adversary access to real-world image priors and assess its implications on privacy leakage under DP-SGD. We show that (1) real-world data priors significantly influence reconstruction success, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#26088;&#22312;&#20840;&#38754;&#27010;&#36848;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#22914;&#20309;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#26469;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644; GNN &#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#35266;&#28857;&#12290;</title><link>https://arxiv.org/abs/2403.07185</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Uncertainty in Graph Neural Networks: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#26088;&#22312;&#20840;&#38754;&#27010;&#36848;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#22914;&#20309;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#26469;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644; GNN &#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#12290;&#28982;&#32780;&#65292;GNNs&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#28304;&#33258;&#25968;&#25454;&#20013;&#30340;&#22266;&#26377;&#38543;&#26426;&#24615;&#21644;&#27169;&#22411;&#35757;&#32451;&#35823;&#24046;&#31561;&#22810;&#31181;&#22240;&#32032;&#65292;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#21644;&#38169;&#35823;&#30340;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644;GNN&#39044;&#27979;&#30340;&#21487;&#38752;&#24615;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#26412;&#35843;&#26597;&#26088;&#22312;&#20174;&#19981;&#30830;&#23450;&#24615;&#30340;&#35282;&#24230;&#20840;&#38754;&#27010;&#36848;GNNs&#65292;&#24182;&#24378;&#35843;&#20854;&#22312;&#22270;&#23398;&#20064;&#20013;&#30340;&#25972;&#21512;&#12290;&#25105;&#20204;&#27604;&#36739;&#21644;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#22270;&#19981;&#30830;&#23450;&#24615;&#29702;&#35770;&#21644;&#26041;&#27861;&#65292;&#20197;&#21450;&#30456;&#24212;&#30340;&#19979;&#28216;&#20219;&#21153;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#24357;&#21512;&#20102;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#21516;&#26102;&#36830;&#25509;&#19981;&#21516;&#30340;GNN&#31038;&#21306;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#36825;&#19968;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07185v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have been extensively used in various real-world applications. However, the predictive uncertainty of GNNs stemming from diverse sources such as inherent randomness in data and model training errors can lead to unstable and erroneous predictions. Therefore, identifying, quantifying, and utilizing uncertainty are essential to enhance the performance of the model for the downstream tasks as well as the reliability of the GNN predictions. This survey aims to provide a comprehensive overview of the GNNs from the perspective of uncertainty with an emphasis on its integration in graph learning. We compare and summarize existing graph uncertainty theory and methods, alongside the corresponding downstream tasks. Thereby, we bridge the gap between theory and practice, meanwhile connecting different GNN communities. Moreover, our work provides valuable insights into promising directions in this field.
&lt;/p&gt;</description></item><item><title>&#24322;&#36136;&#24615;&#23545;&#20110;&#22238;&#24402;&#20219;&#21153;&#20013;&#20986;&#29616;&#22240;&#26524;&#24615;&#30340;&#36129;&#29486;&#35299;&#37322;&#20102;&#20026;&#20309;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#20174;&#20851;&#32852;&#24615;&#35757;&#32451;&#20013;&#25581;&#31034;&#22240;&#26524;&#20851;&#32852;&#12290;</title><link>https://arxiv.org/abs/2403.01420</link><description>&lt;p&gt;
&#24322;&#36136;&#24615;&#23545;&#19981;&#21464;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#30340;&#38544;&#24615;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
The Implicit Bias of Heterogeneity towards Invariance and Causality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01420
&lt;/p&gt;
&lt;p&gt;
&#24322;&#36136;&#24615;&#23545;&#20110;&#22238;&#24402;&#20219;&#21153;&#20013;&#20986;&#29616;&#22240;&#26524;&#24615;&#30340;&#36129;&#29486;&#35299;&#37322;&#20102;&#20026;&#20309;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#20174;&#20851;&#32852;&#24615;&#35757;&#32451;&#20013;&#25581;&#31034;&#22240;&#26524;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#32463;&#39564;&#19978;&#35266;&#23519;&#21040;&#65292;&#20351;&#29992;&#26469;&#33258;&#20114;&#32852;&#32593;&#30340;&#22823;&#37327;&#35821;&#26009;&#24211;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#20351;&#29992;&#19968;&#31181;&#21464;&#20307;&#22238;&#24402;&#25439;&#22833;&#65292;&#21487;&#20197;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#25581;&#31034;&#22240;&#26524;&#20851;&#32852;&#12290;&#36825;&#19982;&#20256;&#32479;&#26234;&#24935;&#8220;&#20851;&#32852;&#19981;&#26159;&#22240;&#26524;&#8221;&#20197;&#21450;&#20256;&#32479;&#22240;&#26524;&#25512;&#26029;&#33539;&#24335;&#30456;&#21453;&#65292;&#20256;&#32479;&#22240;&#26524;&#25512;&#26029;&#33539;&#24335;&#35748;&#20026;&#20808;&#21069;&#30340;&#22240;&#26524;&#30693;&#35782;&#24212;&#35880;&#24910;&#22320;&#32435;&#20837;&#21040;&#26041;&#27861;&#35774;&#35745;&#20013;&#12290;&#20196;&#20154;&#22256;&#24785;&#30340;&#26159;&#65292;&#20026;&#20309;&#22312;&#36861;&#27714;&#20851;&#32852;&#30340;&#22238;&#24402;&#20219;&#21153;&#20013;&#33021;&#22815;&#20174;&#26356;&#39640;&#23618;&#27425;&#30340;&#29702;&#35299;&#20013;&#20986;&#29616;&#22240;&#26524;&#24615;&#12290;&#26412;&#25991;&#22768;&#31216;&#20174;&#38754;&#21521;&#20851;&#32852;&#30340;&#35757;&#32451;&#20013;&#20986;&#29616;&#22240;&#26524;&#24615;&#21487;&#20197;&#24402;&#22240;&#20110;&#28304;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#12289;&#35757;&#32451;&#31639;&#27861;&#30340;&#38543;&#26426;&#24615;&#21644;&#23398;&#20064;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#21270;&#30340;&#32806;&#21512;&#25928;&#24212;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#31616;&#21333;&#20294;&#26377;&#35265;&#22320;&#30340;&#27169;&#22411;&#26469;&#38416;&#37322;&#36825;&#26679;&#30340;&#30452;&#35273;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#22238;&#24402;&#25439;&#22833;&#23398;&#20064;&#19981;&#21464;&#24615;&#65292;&#19968;&#31181;&#20934;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01420v1 Announce Type: new  Abstract: It is observed empirically that the large language models (LLM), trained with a variant of regression loss using numerous corpus from the Internet, can unveil causal associations to some extent. This is contrary to the traditional wisdom that ``association is not causation'' and the paradigm of traditional causal inference in which prior causal knowledge should be carefully incorporated into the design of methods. It is a mystery why causality, in a higher layer of understanding, can emerge from the regression task that pursues associations. In this paper, we claim the emergence of causality from association-oriented training can be attributed to the coupling effects from the heterogeneity of the source data, stochasticity of training algorithms, and over-parameterization of the learning models. We illustrate such an intuition using a simple but insightful model that learns invariance, a quasi-causality, using regression loss. To be spec
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GraphEdit&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23398;&#20064;&#22797;&#26434;&#30340;&#22270;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#30340;&#33410;&#28857;&#20851;&#31995;&#65292;&#36890;&#36807;&#22312;&#22270;&#32467;&#26500;&#19978;&#36827;&#34892;&#25351;&#23548;&#35843;&#25972;&#65292;&#22686;&#24378;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20174;&#32780;&#25552;&#39640;&#22270;&#32467;&#26500;&#23398;&#20064;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.15183</link><description>&lt;p&gt;
GraphEdit&#65306;&#29992;&#20110;&#22270;&#32467;&#26500;&#23398;&#20064;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
GraphEdit: Large Language Models for Graph Structure Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15183
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GraphEdit&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23398;&#20064;&#22797;&#26434;&#30340;&#22270;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#30340;&#33410;&#28857;&#20851;&#31995;&#65292;&#36890;&#36807;&#22312;&#22270;&#32467;&#26500;&#19978;&#36827;&#34892;&#25351;&#23548;&#35843;&#25972;&#65292;&#22686;&#24378;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20174;&#32780;&#25552;&#39640;&#22270;&#32467;&#26500;&#23398;&#20064;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#32467;&#26500;&#23398;&#20064;&#65288;GSL&#65289;&#33268;&#21147;&#20110;&#36890;&#36807;&#29983;&#25104;&#26032;&#39062;&#30340;&#22270;&#32467;&#26500;&#26469;&#25429;&#25417;&#22270;&#32467;&#26500;&#25968;&#25454;&#20013;&#33410;&#28857;&#20043;&#38388;&#30340;&#22266;&#26377;&#20381;&#36182;&#24615;&#21644;&#30456;&#20114;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GraphEdit&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23398;&#20064;&#22270;&#32467;&#26500;&#21270;&#25968;&#25454;&#20013;&#22797;&#26434;&#30340;&#33410;&#28857;&#20851;&#31995;&#12290;&#36890;&#36807;&#22312;&#22270;&#32467;&#26500;&#19978;&#36827;&#34892;&#25351;&#23548;&#35843;&#25972;&#65292;&#22686;&#24378;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#25105;&#20204;&#26088;&#22312;&#20811;&#26381;&#26174;&#24335;&#22270;&#32467;&#26500;&#20449;&#24687;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#39640;&#22270;&#32467;&#26500;&#23398;&#20064;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15183v1 Announce Type: cross  Abstract: Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks (GNNs) have emerged as promising GSL solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing GSL methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of LLMs through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy co
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IDEA&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#29366;&#24577;&#26816;&#27979;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#21464;&#36801;&#65292;&#24182;&#36827;&#19968;&#27493;&#20998;&#31163;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#30340;&#28508;&#22312;&#29366;&#24577;&#12290;</title><link>https://arxiv.org/abs/2402.12767</link><description>&lt;p&gt;
&#22312;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#65306;&#23398;&#20064;&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#29366;&#24577;&#36827;&#34892;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
When and How: Learning Identifiable Latent States for Nonstationary Time Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12767
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IDEA&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#29366;&#24577;&#26816;&#27979;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#21464;&#36801;&#65292;&#24182;&#36827;&#19968;&#27493;&#20998;&#31163;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#30340;&#28508;&#22312;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#20998;&#24067;&#30340;&#36716;&#31227;&#22312;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#12290;&#20854;&#20013;&#19968;&#31181;&#26368;&#27969;&#34892;&#30340;&#26041;&#27861;&#20551;&#23450;&#26102;&#38388;&#20998;&#24067;&#30340;&#36716;&#31227;&#26159;&#22343;&#21248;&#21457;&#29983;&#30340;&#65292;&#20197;&#21306;&#20998;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#20551;&#35774;&#24456;&#38590;&#28385;&#36275;&#65292;&#22240;&#20026;&#25105;&#20204;&#19981;&#30693;&#36947;&#20998;&#24067;&#20309;&#26102;&#21457;&#29983;&#36716;&#31227;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#29366;&#24577;&#65288;IDEA&#65289;&#26469;&#26816;&#27979;&#20998;&#24067;&#20309;&#26102;&#21457;&#29983;&#36716;&#31227;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#20805;&#20998;&#35266;&#23519;&#20551;&#35774;&#26469;&#20998;&#31163;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#30340;&#28508;&#22312;&#29366;&#24577;&#65292;&#23398;&#20064;&#28508;&#22312;&#29366;&#24577;&#30340;&#21464;&#21270;&#26041;&#24335;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;&#22240;&#26524;&#36807;&#31243;&#24418;&#24335;&#21270;&#20026;&#19982;&#29615;&#22659;&#19981;&#30456;&#20851;&#30340;&#31283;&#23450;&#21464;&#37327;&#21644;&#19982;&#29615;&#22659;&#30456;&#20851;&#30340;&#38750;&#24179;&#31283;&#21464;&#37327;&#12290;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#28508;&#22312;&#29615;&#22659;&#21644;&#31283;&#23450;/&#38750;&#31283;&#23450;&#21464;&#37327;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#22522;&#20110;&#36825;&#20123;&#29702;&#35770;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;IDEA&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;&#33258;&#22238;&#24402;&#38544;&#39532;&#23572;&#31185;&#22827;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12767v1 Announce Type: new  Abstract: Temporal distribution shifts are ubiquitous in time series data. One of the most popular methods assumes that the temporal distribution shift occurs uniformly to disentangle the stationary and nonstationary dependencies. But this assumption is difficult to meet, as we do not know when the distribution shifts occur. To solve this problem, we propose to learn IDentifiable latEnt stAtes (IDEA) to detect when the distribution shifts occur. Beyond that, we further disentangle the stationary and nonstationary latent states via sufficient observation assumption to learn how the latent states change. Specifically, we formalize the causal process with environment-irrelated station- ary and environment-related nonstationary variables. Under mild conditions, we show that latent environments and stationary/nonstationary variables are identifiable. Based on these theories, we devise the IDEA model, which incorporates an autoregressive hidden Markov m
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#23558;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#35270;&#20026;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#25104;&#21151;&#35843;&#25972; EI &#24182;&#23637;&#31034;&#20854;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11345</link><description>&lt;p&gt;
&#21464;&#20998;&#29109;&#25628;&#32034;&#29992;&#20110;&#35843;&#25972;&#26399;&#26395;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Variational Entropy Search for Adjusting Expected Improvement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#23558;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#35270;&#20026;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#25104;&#21151;&#35843;&#25972; EI &#24182;&#23637;&#31034;&#20854;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bayesian optimization &#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#30340;&#25216;&#26415;&#65292;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#26159;&#35813;&#39046;&#22495;&#20013;&#26368;&#24120;&#29992;&#30340;&#33719;&#21462;&#20989;&#25968;&#12290;&#34429;&#28982; EI &#36890;&#24120;&#34987;&#35270;&#20026;&#19982;&#20854;&#20182;&#20449;&#24687;&#29702;&#35770;&#33719;&#21462;&#20989;&#25968;&#65288;&#22914;&#29109;&#25628;&#32034;&#65288;ES&#65289;&#21644;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#65289;&#19981;&#21516;&#65292;&#20294;&#25105;&#20204;&#30340;&#24037;&#20316;&#25581;&#31034;&#20102;&#65292;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#26041;&#27861;&#65292;EI &#21487;&#20197;&#34987;&#35270;&#20026; MES &#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#22312;&#36825;&#19968;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#20449;&#24687;&#29702;&#35770;&#27010;&#24565;&#30340;&#21407;&#21017;&#25972;&#21512;&#21040; EI &#20013;&#26469;&#35843;&#25972; EI&#12290;VES-Gamma &#30340;&#26377;&#25928;&#24615;&#22312;&#21508;&#31181;&#27979;&#35797;&#20989;&#25968;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;&#31361;&#20986;&#20102;&#23427;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#22330;&#26223;&#20013;&#30340;&#29702;&#35770;&#21644;&#23454;&#38469;&#29992;&#36884;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11345v1 Announce Type: cross  Abstract: Bayesian optimization is a widely used technique for optimizing black-box functions, with Expected Improvement (EI) being the most commonly utilized acquisition function in this domain. While EI is often viewed as distinct from other information-theoretic acquisition functions, such as entropy search (ES) and max-value entropy search (MES), our work reveals that EI can be considered a special case of MES when approached through variational inference (VI). In this context, we have developed the Variational Entropy Search (VES) methodology and the VES-Gamma algorithm, which adapts EI by incorporating principles from information-theoretic concepts. The efficacy of VES-Gamma is demonstrated across a variety of test functions and read datasets, highlighting its theoretical and practical utilities in Bayesian optimization scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.09469</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20613;&#31435;&#21494;&#30005;&#36335;&#65306;&#35299;&#38145;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Fourier Circuits in Neural Networks: Unlocking the Potential of Large Language Models in Mathematical Reasoning and Modular Arithmetic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#19981;&#26029;&#21457;&#23637;&#30340;&#32972;&#26223;&#19979;&#65292;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#25152;&#21033;&#29992;&#30340;&#20869;&#37096;&#34920;&#31034;&#26159;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#22312;&#36817;&#26399;&#30340;&#30740;&#31350;&#22522;&#30784;&#19978;&#65292;&#23545;&#32593;&#32476;&#37319;&#29992;&#29305;&#23450;&#35745;&#31639;&#31574;&#30053;&#32972;&#21518;&#30340;&#21407;&#22240;&#36827;&#34892;&#20102;&#25506;&#32034;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#28041;&#21450;k&#20010;&#36755;&#20837;&#30340;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#65292;&#21363;&#27169;&#36816;&#31639;&#30340;&#21152;&#27861;&#12290;&#25105;&#20204;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#36825;&#19968;&#20219;&#21153;&#20013;&#23398;&#21040;&#30340;&#29305;&#24449;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#29702;&#35770;&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#26159;&#38416;&#26126;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#30340;&#29305;&#24449;&#30340;&#24433;&#21709;&#12290;&#20854;&#20013;&#65292;p&#34920;&#31034;&#27169;&#25968;&#65292;Dp&#34920;&#31034;k&#20010;&#36755;&#20837;&#30340;&#27169;&#36816;&#31639;&#25968;&#25454;&#38598;&#65292;m&#34920;&#31034;&#32593;&#32476;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09469v1 Announce Type: new  Abstract: In the evolving landscape of machine learning, a pivotal challenge lies in deciphering the internal representations harnessed by neural networks and Transformers. Building on recent progress toward comprehending how networks execute distinct target functions, our study embarks on an exploration of the underlying reasons behind networks adopting specific computational strategies. We direct our focus to the complex algebraic learning task of modular addition involving $k$ inputs. Our research presents a thorough analytical characterization of the features learned by stylized one-hidden layer neural networks and one-layer Transformers in addressing this task.   A cornerstone of our theoretical framework is the elucidation of how the principle of margin maximization shapes the features adopted by one-hidden layer neural networks. Let $p$ denote the modulus, $D_p$ denote the dataset of modular arithmetic with $k$ inputs and $m$ denote the net
&lt;/p&gt;</description></item><item><title>&#26410;&#26469;&#39044;&#27979;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#23398;&#20064; History Representation &#20855;&#26377;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07102</link><description>&lt;p&gt;
&#26410;&#26469;&#39044;&#27979;&#21487;&#20197;&#25104;&#20026;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#33391;&#22909;&#21382;&#21490;&#34920;&#36798;&#30340;&#26377;&#21147;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
Future Prediction Can be a Strong Evidence of Good History Representation in Partially Observable Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07102
&lt;/p&gt;
&lt;p&gt;
&#26410;&#26469;&#39044;&#27979;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#23398;&#20064; History Representation &#20855;&#26377;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#33391;&#22909;&#30340;&#21382;&#21490;&#34920;&#36798;&#26159;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#24378;&#21270;&#23398;&#20064;&#30340;&#26680;&#24515;&#25361;&#25112;&#20043;&#19968;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21508;&#31181;&#36741;&#21161;&#20219;&#21153;&#23545;&#20419;&#36827;&#34920;&#36798;&#23398;&#20064;&#20855;&#26377;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36741;&#21161;&#20219;&#21153;&#30340;&#26377;&#25928;&#24615;&#23578;&#26410;&#23436;&#20840;&#20351;&#20154;&#20449;&#26381;&#65292;&#29305;&#21035;&#26159;&#22312;&#38656;&#35201;&#38271;&#26399;&#35760;&#24518;&#21644;&#25512;&#29702;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#12290;&#22312;&#36825;&#20010;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#26410;&#26469;&#39044;&#27979;&#22312;&#23398;&#20064;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#21382;&#21490;&#34920;&#36798;&#26102;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26410;&#26469;&#39044;&#27979;&#23558;&#23398;&#20064;&#21382;&#21490;&#34920;&#36798;&#19982;&#31574;&#30053;&#20248;&#21270;&#20998;&#31163;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26377;&#20004;&#20010;&#26041;&#38754;&#65306;&#65288;a&#65289;&#25105;&#20204;&#35777;&#26126;&#20102;&#24378;&#21270;&#23398;&#20064;&#30340;&#24615;&#33021;&#19982;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#26410;&#26469;&#35266;&#27979;&#30340;&#39044;&#27979;&#31934;&#24230;&#24378;&#30456;&#20851;&#65292;&#65288;b&#65289;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#38271;&#26102;&#38388;&#21382;&#21490;&#30340;&#34920;&#36798;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning a good history representation is one of the core challenges of reinforcement learning (RL) in partially observable environments. Recent works have shown the advantages of various auxiliary tasks for facilitating representation learning. However, the effectiveness of such auxiliary tasks has not been fully convincing, especially in partially observable environments that require long-term memorization and inference. In this empirical study, we investigate the effectiveness of future prediction for learning the representations of histories, possibly of extensive length, in partially observable environments. We first introduce an approach that decouples the task of learning history representations from policy optimization via future prediction. Then, our main contributions are two-fold: (a) we demonstrate that the performance of reinforcement learning is strongly correlated with the prediction accuracy of future observations in partially observable environments, and (b) our approa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21457;&#29616;&#65292;&#22312;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#26410;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#21462;&#20915;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36951;&#20256;&#31639;&#27861;&#65292;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.05835</link><description>&lt;p&gt;
&#19981;&#21487;&#35265;&#25968;&#25454;&#21462;&#20915;&#20110;&#24050;&#30693;&#20449;&#24687;&#30340;&#22810;&#23569;
&lt;/p&gt;
&lt;p&gt;
How Much is Unseen Depends Chiefly on Information About the Seen
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05835
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21457;&#29616;&#65292;&#22312;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#26410;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#21462;&#20915;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36951;&#20256;&#31639;&#27861;&#65292;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20045;&#19968;&#30475;&#21487;&#33021;&#26377;&#20123;&#36829;&#21453;&#30452;&#35273;&#65306;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#39044;&#26399;&#20013;&#65292;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#27809;&#26377;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#30001;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;$f_k$&#30830;&#23450;&#12290;&#34429;&#28982;&#22312;&#29702;&#35770;&#19978;&#25105;&#20204;&#35777;&#26126;&#20102;&#30001;&#35813;&#20272;&#35745;&#37327;&#24341;&#36215;&#30340;&#20559;&#24046;&#22312;&#26679;&#26412;&#22823;&#23567;&#25351;&#25968;&#32423;&#34928;&#20943;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#39640;&#26041;&#24046;&#38459;&#27490;&#25105;&#20204;&#30452;&#25509;&#20351;&#29992;&#23427;&#20316;&#20026;&#26679;&#26412;&#35206;&#30422;&#20272;&#35745;&#37327;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#23545;$f_k$&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#36827;&#34892;&#20102;&#31934;&#30830;&#30340;&#25551;&#36848;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#22810;&#20010;&#19981;&#21516;&#26399;&#26395;&#20540;&#34920;&#31034;&#30340;&#25628;&#32034;&#31354;&#38388;&#65292;&#21487;&#20197;&#30830;&#23450;&#22320;&#23454;&#20363;&#21270;&#20026;&#20272;&#35745;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36716;&#21521;&#20248;&#21270;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#36951;&#20256;&#31639;&#27861;&#65292;&#20165;&#26681;&#25454;&#26679;&#26412;&#25628;&#32034;&#24179;&#22343;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#26368;&#23567;&#30340;&#20272;&#35745;&#37327;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#36951;&#20256;&#31639;&#27861;&#21457;&#29616;&#20102;&#20855;&#26377;&#26126;&#26174;&#36739;&#23567;&#26041;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
It might seem counter-intuitive at first: We find that, in expectation, the proportion of data points in an unknown population-that belong to classes that do not appear in the training data-is almost entirely determined by the number $f_k$ of classes that do appear in the training data the same number of times. While in theory we show that the difference of the induced estimator decays exponentially in the size of the sample, in practice the high variance prevents us from using it directly for an estimator of the sample coverage. However, our precise characterization of the dependency between $f_k$'s induces a large search space of different representations of the expected value, which can be deterministically instantiated as estimators. Hence, we turn to optimization and develop a genetic algorithm that, given only the sample, searches for an estimator with minimal mean-squared error (MSE). In our experiments, our genetic algorithm discovers estimators that have a substantially smalle
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#21644;&#23545;&#35805;&#20195;&#29702;&#22120;ChatGPT&#30456;&#32467;&#21512;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36890;&#36807;&#31038;&#20132;&#23186;&#20307;&#26816;&#27979;&#25233;&#37057;&#30151;&#30340;&#21487;&#35299;&#37322;&#24615;&#25361;&#25112;&#12290;&#36890;&#36807;&#23558;Twitter&#29305;&#23450;&#21464;&#20307;BERTweet&#19982;&#33258;&#35299;&#37322;&#27169;&#22411;BERT-XDD&#30456;&#32467;&#21512;&#65292;&#24182;&#20511;&#21161;ChatGPT&#23558;&#25216;&#26415;&#35299;&#37322;&#36716;&#21270;&#20026;&#20154;&#31867;&#21487;&#35835;&#30340;&#35780;&#35770;&#65292;&#23454;&#29616;&#20102;&#35299;&#37322;&#33021;&#21147;&#30340;&#21516;&#26102;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20026;&#21457;&#23637;&#31038;&#20250;&#36127;&#36131;&#20219;&#30340;&#25968;&#23383;&#24179;&#21488;&#65292;&#20419;&#36827;&#26089;&#26399;&#24178;&#39044;&#20570;&#20986;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2401.17477</link><description>&lt;p&gt;
&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#26816;&#27979;&#24515;&#29702;&#38556;&#30861;&#65306;&#22522;&#20110;ChatGPT&#30340;&#21487;&#35299;&#37322;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Detecting mental disorder on social media: a ChatGPT-augmented explainable approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17477
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#21644;&#23545;&#35805;&#20195;&#29702;&#22120;ChatGPT&#30456;&#32467;&#21512;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36890;&#36807;&#31038;&#20132;&#23186;&#20307;&#26816;&#27979;&#25233;&#37057;&#30151;&#30340;&#21487;&#35299;&#37322;&#24615;&#25361;&#25112;&#12290;&#36890;&#36807;&#23558;Twitter&#29305;&#23450;&#21464;&#20307;BERTweet&#19982;&#33258;&#35299;&#37322;&#27169;&#22411;BERT-XDD&#30456;&#32467;&#21512;&#65292;&#24182;&#20511;&#21161;ChatGPT&#23558;&#25216;&#26415;&#35299;&#37322;&#36716;&#21270;&#20026;&#20154;&#31867;&#21487;&#35835;&#30340;&#35780;&#35770;&#65292;&#23454;&#29616;&#20102;&#35299;&#37322;&#33021;&#21147;&#30340;&#21516;&#26102;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20026;&#21457;&#23637;&#31038;&#20250;&#36127;&#36131;&#20219;&#30340;&#25968;&#23383;&#24179;&#21488;&#65292;&#20419;&#36827;&#26089;&#26399;&#24178;&#39044;&#20570;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#26102;&#20195;&#65292;&#31038;&#20132;&#23186;&#20307;&#19978;&#34920;&#36798;&#30340;&#25233;&#37057;&#30151;&#29366;&#30340;&#39057;&#29575;&#24341;&#36215;&#20102;&#20005;&#37325;&#20851;&#27880;&#65292;&#36843;&#20999;&#38656;&#35201;&#20808;&#36827;&#30340;&#26041;&#27861;&#26469;&#21450;&#26102;&#26816;&#27979;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#21644;ChatGPT&#31561;&#23545;&#35805;&#20195;&#29702;&#22120;&#26377;&#25928;&#22320;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#24212;&#23545;&#21487;&#35299;&#37322;&#24615;&#25233;&#37057;&#30151;&#26816;&#27979;&#30340;&#25361;&#25112;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#36890;&#36807;&#23558;Twitter&#29305;&#23450;&#21464;&#20307;BERTweet&#19982;&#19968;&#31181;&#26032;&#22411;&#30340;&#33258;&#35299;&#37322;&#27169;&#22411;BERT-XDD&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#35299;&#37322;&#33021;&#21147;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#36890;&#36807;&#25513;&#30721;&#27880;&#24847;&#21147;&#25552;&#20379;&#20998;&#31867;&#21644;&#35299;&#37322;&#12290;&#20351;&#29992;ChatGPT&#23558;&#25216;&#26415;&#35299;&#37322;&#36716;&#21270;&#20026;&#21487;&#35835;&#24615;&#24378;&#30340;&#35780;&#35770;&#65292;&#36827;&#19968;&#27493;&#22686;&#24378;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26377;&#25928;&#19988;&#27169;&#22359;&#21270;&#30340;&#21487;&#35299;&#37322;&#25233;&#37057;&#30151;&#26816;&#27979;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20026;&#21457;&#23637;&#31038;&#20250;&#36127;&#36131;&#20219;&#30340;&#25968;&#23383;&#24179;&#21488;&#20570;&#20986;&#36129;&#29486;&#65292;&#20419;&#36827;&#26089;&#26399;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the digital era, the prevalence of depressive symptoms expressed on social media has raised serious concerns, necessitating advanced methodologies for timely detection. This paper addresses the challenge of interpretable depression detection by proposing a novel methodology that effectively combines Large Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and conversational agents like ChatGPT. In our methodology, explanations are achieved by integrating BERTweet, a Twitter-specific variant of BERT, into a novel self-explanatory model, namely BERT-XDD, capable of providing both classification and explanations via masked attention. The interpretability is further enhanced using ChatGPT to transform technical explanations into human-readable commentaries. By introducing an effective and modular approach for interpretable depression detection, our methodology can contribute to the development of socially responsible digital platforms, fostering early intervention and
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2312.09481</link><description>&lt;p&gt;
&#25345;&#32493;&#19981;&#26029;&#30340;&#23545;&#25239;&#24615;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Continual Adversarial Defense
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.09481
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#27599;&#26376;&#38024;&#23545;&#35270;&#35273;&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#24555;&#36895;&#28436;&#21464;&#30340;&#29305;&#24615;&#65292;&#20154;&#20204;&#25552;&#20986;&#20102;&#35768;&#22810;&#38450;&#24481;&#26041;&#27861;&#65292;&#26088;&#22312;&#23613;&#21487;&#33021;&#36890;&#29992;&#21270;&#20197;&#25269;&#24481;&#23613;&#21487;&#33021;&#22810;&#30340;&#24050;&#30693;&#25915;&#20987;&#12290;&#28982;&#32780;&#65292;&#35774;&#35745;&#19968;&#20010;&#33021;&#22815;&#23545;&#25239;&#25152;&#26377;&#31867;&#22411;&#25915;&#20987;&#30340;&#38450;&#24481;&#26041;&#27861;&#24182;&#19981;&#29616;&#23454;&#65292;&#22240;&#20026;&#38450;&#24481;&#31995;&#32479;&#36816;&#34892;&#30340;&#29615;&#22659;&#26159;&#21160;&#24577;&#30340;&#65292;&#21253;&#21547;&#38543;&#30528;&#26102;&#38388;&#20986;&#29616;&#30340;&#21508;&#31181;&#29420;&#29305;&#25915;&#20987;&#12290;&#38450;&#24481;&#31995;&#32479;&#24517;&#39035;&#25910;&#38598;&#22312;&#32447;&#23569;&#26679;&#26412;&#23545;&#25239;&#21453;&#39304;&#20197;&#36805;&#36895;&#22686;&#24378;&#33258;&#36523;&#65292;&#20805;&#20998;&#21033;&#29992;&#20869;&#23384;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#21160;&#24577;&#36866;&#24212;&#20219;&#20309;&#25915;&#20987;&#30340;&#25345;&#32493;&#23545;&#25239;&#24615;&#38450;&#24481;&#65288;CAD&#65289;&#26694;&#26550;&#65292;&#20854;&#20013;&#21508;&#31181;&#25915;&#20987;&#36880;&#20010;&#38454;&#27573;&#20986;&#29616;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;CAD&#22522;&#20110;&#22235;&#39033;&#21407;&#21017;&#36827;&#34892;&#24314;&#27169;&#65306;(1) &#25345;&#32493;&#36866;&#24212;&#26032;&#25915;&#20987;&#32780;&#26080;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;(2) &#23569;&#26679;&#26412;&#36866;&#24212;&#65292;(3) &#20869;&#23384;&#39640;&#25928;&#36866;&#24212;&#65292;&#20197;&#21450;(4) &#39640;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.09481v2 Announce Type: replace-cross  Abstract: In response to the rapidly evolving nature of adversarial attacks against visual classifiers on a monthly basis, numerous defenses have been proposed to generalize against as many known attacks as possible. However, designing a defense method that generalizes to all types of attacks is not realistic because the environment in which defense systems operate is dynamic and comprises various unique attacks that emerge as time goes on. The defense system must gather online few-shot defense feedback to promptly enhance itself, leveraging efficient memory utilization. Therefore, we propose the first continual adversarial defense (CAD) framework that adapts to any attacks in a dynamic scenario, where various attacks emerge stage by stage. In practice, CAD is modeled under four principles: (1) continual adaptation to new attacks without catastrophic forgetting, (2) few-shot adaptation, (3) memory-efficient adaptation, and (4) high accur
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25913;&#36827;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#20923;&#32467;&#30340;&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#39592;&#24178;&#65292;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#34920;&#29616;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#39044;&#35757;&#32451;&#25216;&#26415;&#12289;&#25439;&#22833;&#20989;&#25968;&#21644;&#21407;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2311.17093</link><description>&lt;p&gt;
&#29992;&#21407;&#22411;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#22522;&#30784;&#27169;&#22411;&#23454;&#29616;&#39640;&#25928;&#30340;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Efficient Out-of-Distribution Detection with Prototypical Semi-Supervised Learning and Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25913;&#36827;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#20923;&#32467;&#30340;&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#39592;&#24178;&#65292;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#34920;&#29616;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#39044;&#35757;&#32451;&#25216;&#26415;&#12289;&#25439;&#22833;&#20989;&#25968;&#21644;&#21407;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;PAWS-VMK&#65292;&#19968;&#31181;&#25913;&#36827;&#30340;&#21407;&#22411;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#21033;&#29992;&#20923;&#32467;&#30340;&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#39592;&#24178;&#65292;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#20013;&#20248;&#20110;&#20197;&#24448;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#32467;&#26524;&#65292;&#25913;&#36827;&#20102;Predicting View-Assignments With Support Samples&#65288;PAWS&#65289;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;(1) &#21442;&#25968;&#21270;von-Mises Fisher&#38543;&#26426;&#37051;&#22495;&#23884;&#20837;&#65288;vMF-SNE&#65289;&#26469;&#39044;&#35757;&#32451;&#25237;&#24433;&#22836;&#65292;&#20351;&#29992;&#22522;&#30784;&#27169;&#22411;&#30340;&#39640;&#36136;&#37327;&#23884;&#20837;;(2) &#21463;MixMatch&#21551;&#21457;&#30340;&#25439;&#22833;&#65292;&#36890;&#36807;&#23545;&#22810;&#35270;&#22270;&#30340;&#39044;&#27979;&#36827;&#34892;&#24179;&#22343;&#65292;&#25552;&#20379;&#27604;PAWS&#20013;&#20351;&#29992;&#30340;&#19968;&#33268;&#24615;&#25439;&#22833;&#26356;&#21487;&#38752;&#30340;&#30417;&#30563;&#20449;&#21495;;&#21644;(3) &#31616;&#21333;k-Means&#21407;&#22411;&#36873;&#25321;&#65288;SKMPS&#65289;&#65292;&#19968;&#31181;&#27604;&#20854;&#20182;&#26080;&#30417;&#30563;&#26631;&#31614;&#36873;&#25321;&#26041;&#27861;&#25552;&#20379;&#26356;&#20248;&#36234;&#24615;&#33021;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.17093v2 Announce Type: replace-cross  Abstract: This paper describes PAWS-VMK, an improved approach to prototypical semi-supervised learning in the field of computer vision, specifically designed to utilize a frozen foundation model as the neural network backbone. This method outperforms previous results in semi-supervised learning and out-of-distribution (OOD) detection, improving upon the Predicting View-Assignments With Support Samples (PAWS) semi-supervised learning method. We introduce (1) parametric von-Mises Fisher Stochastic Neighbour Embedding (vMF-SNE) to pretrain the projection head using the high-quality embeddings of the foundation model; (2) a MixMatch inspired loss, where predictions across multiple views are averaged to provide a more reliable supervision signal compared to the consistency loss used in PAWS and (3) simple $k$-Means prototype selection (SKMPS), a technique that provides superior performance to other unsupervised label selection approaches in t
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#37327;&#23376;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#65288;QLD&#65289;&#26469;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#20984;&#26223;&#35266;&#20013; QLD &#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#33021;&#37327;&#32791;&#25955;&#33021;&#21147;&#21644;&#20302;&#28201;&#26497;&#38480;&#19979;&#25351;&#25968;&#34928;&#20943;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2311.15587</link><description>&lt;p&gt;
&#37327;&#23376;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#29992;&#20110;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Quantum Langevin Dynamics for Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15587
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#37327;&#23376;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#65288;QLD&#65289;&#26469;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#20984;&#26223;&#35266;&#20013; QLD &#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#33021;&#37327;&#32791;&#25955;&#33021;&#21147;&#21644;&#20302;&#28201;&#26497;&#38480;&#19979;&#25351;&#25968;&#34928;&#20943;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#21033;&#29992;&#37327;&#23376;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#65288;QLD&#65289;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#23545;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20135;&#29983;&#37325;&#22823;&#38556;&#30861;&#30340;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19982;&#26080;&#38480;&#28909;&#28020;&#32806;&#21512;&#30340;&#31995;&#32479;&#21160;&#21147;&#23398;&#12290;&#35813;&#30456;&#20114;&#20316;&#29992;&#26082;&#24341;&#36215;&#20102;&#38543;&#26426;&#37327;&#23376;&#22122;&#22768;&#65292;&#21448;&#24341;&#36215;&#20102;&#23545;&#31995;&#32479;&#30340;&#30830;&#23450;&#24615;&#38459;&#23612;&#25928;&#24212;&#65292;&#20174;&#32780;&#23558;&#31995;&#32479;&#25512;&#21521;&#25509;&#36817;&#30446;&#26631;&#20989;&#25968;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#31283;&#23450;&#29366;&#24577;&#12290;&#25105;&#20204;&#22312;&#20984;&#26223;&#35266;&#20013;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102; QLD &#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#31995;&#32479;&#30340;&#24179;&#22343;&#33021;&#37327;&#21487;&#20197;&#22312;&#20302;&#28201;&#26497;&#38480;&#19979;&#25509;&#36817;&#38646;&#65292;&#24182;&#19988;&#20855;&#26377;&#19982;&#28436;&#21270;&#26102;&#38388;&#30456;&#20851;&#30340;&#25351;&#25968;&#34928;&#20943;&#36895;&#29575;&#12290;&#22312;&#25968;&#20540;&#19978;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#23558;&#20854;&#36215;&#28304;&#36861;&#28335;&#21040;&#33258;&#21457;&#36752;&#23556;&#26469;&#23637;&#31034; QLD &#30340;&#33021;&#37327;&#32791;&#25955;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#27599;&#20010; p &#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#35814;&#32454;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.15587v2 Announce Type: replace-cross  Abstract: We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve optimization problems, particularly those non-convex objective functions that present substantial obstacles for traditional gradient descent algorithms. Specifically, we examine the dynamics of a system coupled with an infinite heat bath. This interaction induces both random quantum noise and a deterministic damping effect to the system, which nudge the system towards a steady state that hovers near the global minimum of objective functions. We theoretically prove the convergence of QLD in convex landscapes, demonstrating that the average energy of the system can approach zero in the low temperature limit with an exponential decay rate correlated with the evolution time. Numerically, we first show the energy dissipation capability of QLD by retracing its origins to spontaneous emission. Furthermore, we conduct detailed discussion of the impact of each p
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26469;&#33258;SCANIA&#20844;&#21496;&#30340;&#30495;&#23454;&#19990;&#30028;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#39044;&#27979;&#24615;&#32500;&#25252;&#22330;&#26223;&#12290;&#23427;&#20855;&#26377;&#24222;&#22823;&#30340;&#26679;&#26412;&#25968;&#37327;&#21644;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#65292;&#20197;&#21450;&#26102;&#38388;&#20449;&#24687;&#65292;&#20026;&#30740;&#31350;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#26631;&#20934;&#22522;&#20934;&#12290;</title><link>http://arxiv.org/abs/2401.15199</link><description>&lt;p&gt;
SCANIA&#32452;&#20214;X&#25968;&#25454;&#38598;&#65306;&#29992;&#20110;&#39044;&#27979;&#24615;&#32500;&#25252;&#30340;&#30495;&#23454;&#19990;&#30028;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
SCANIA Component X Dataset: A Real-World Multivariate Time Series Dataset for Predictive Maintenance. (arXiv:2401.15199v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15199
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26469;&#33258;SCANIA&#20844;&#21496;&#30340;&#30495;&#23454;&#19990;&#30028;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#39044;&#27979;&#24615;&#32500;&#25252;&#22330;&#26223;&#12290;&#23427;&#20855;&#26377;&#24222;&#22823;&#30340;&#26679;&#26412;&#25968;&#37327;&#21644;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#65292;&#20197;&#21450;&#26102;&#38388;&#20449;&#24687;&#65292;&#20026;&#30740;&#31350;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#26631;&#20934;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26469;&#33258;SCANIA&#29790;&#20856;&#20844;&#21496;&#30340;&#21345;&#36710;&#36710;&#38431;&#20013;&#21311;&#21517;&#21457;&#21160;&#26426;&#37096;&#20214;&#65288;&#31216;&#20026;Component X&#65289;&#30340;&#30495;&#23454;&#19990;&#30028;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#25324;&#22810;&#31181;&#21464;&#37327;&#65292;&#25429;&#25417;&#20102;&#35814;&#32454;&#30340;&#25805;&#20316;&#25968;&#25454;&#12289;&#32500;&#20462;&#35760;&#24405;&#21644;&#21345;&#36710;&#35268;&#26684;&#65292;&#21516;&#26102;&#36890;&#36807;&#21311;&#21517;&#22788;&#29702;&#20445;&#25345;&#26426;&#23494;&#24615;&#12290;&#23427;&#38750;&#24120;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#65292;&#22914;&#20998;&#31867;&#12289;&#22238;&#24402;&#12289;&#29983;&#23384;&#20998;&#26512;&#21644;&#24322;&#24120;&#26816;&#27979;&#65292;&#29305;&#21035;&#26159;&#22312;&#39044;&#27979;&#24615;&#32500;&#25252;&#22330;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;&#24222;&#22823;&#30340;&#26679;&#26412;&#25968;&#37327;&#21644;&#20197;&#30452;&#26041;&#22270;&#21644;&#35745;&#25968;&#22120;&#24418;&#24335;&#30340;&#22810;&#26679;&#21270;&#29305;&#24449;&#65292;&#20197;&#21450;&#21253;&#21547;&#26102;&#38388;&#20449;&#24687;&#65292;&#20351;&#24471;&#36825;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#22312;&#35813;&#39046;&#22495;&#20013;&#29420;&#29305;&#12290;&#21457;&#24067;&#36825;&#20010;&#25968;&#25454;&#38598;&#30340;&#30446;&#26631;&#26159;&#35753;&#24191;&#22823;&#30740;&#31350;&#20154;&#21592;&#26377;&#21487;&#33021;&#20351;&#29992;&#26469;&#33258;&#19968;&#23478;&#22269;&#38469;&#30693;&#21517;&#20844;&#21496;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#65292;&#24182;&#24341;&#20837;&#19968;&#20010;&#26631;&#20934;&#22522;&#20934;&#29992;&#20110;&#39044;&#27979;&#24615;&#32500;&#25252;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a description of a real-world, multivariate time series dataset collected from an anonymized engine component (called Component X) of a fleet of trucks from SCANIA, Sweden. This dataset includes diverse variables capturing detailed operational data, repair records, and specifications of trucks while maintaining confidentiality by anonymization. It is well-suited for a range of machine learning applications, such as classification, regression, survival analysis, and anomaly detection, particularly when applied to predictive maintenance scenarios. The large population size and variety of features in the format of histograms and numerical counters, along with the inclusion of temporal information, make this real-world dataset unique in the field. The objective of releasing this dataset is to give a broad range of researchers the possibility of working with real-world data from an internationally well-known company and introduce a standard benchmark to the predictive ma
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#32479;&#19968;&#33258;&#30417;&#30563;&#32858;&#31867;&#21644;&#33021;&#37327;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#21270;&#30340;&#25512;&#23548;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#21487;&#38752;&#22320;&#24809;&#32602;&#22833;&#36133;&#27169;&#24335;&#30340;&#19979;&#30028;&#12290;&#36825;&#20010;&#19979;&#30028;&#20351;&#24471;&#33021;&#22815;&#35757;&#32451;&#19968;&#20010;&#26631;&#20934;&#30340;&#39592;&#26550;&#26550;&#26500;&#65292;&#32780;&#26080;&#38656;&#20351;&#29992;&#38750;&#23545;&#31216;&#20803;&#32032;&#12290;</title><link>http://arxiv.org/abs/2401.00873</link><description>&lt;p&gt;
&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#32479;&#19968;&#33258;&#30417;&#30563;&#32858;&#31867;&#21644;&#33021;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Unification of Self-Supervised Clustering and Energy-Based Models. (arXiv:2401.00873v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00873
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#32479;&#19968;&#33258;&#30417;&#30563;&#32858;&#31867;&#21644;&#33021;&#37327;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#21270;&#30340;&#25512;&#23548;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#21487;&#38752;&#22320;&#24809;&#32602;&#22833;&#36133;&#27169;&#24335;&#30340;&#19979;&#30028;&#12290;&#36825;&#20010;&#19979;&#30028;&#20351;&#24471;&#33021;&#22815;&#35757;&#32451;&#19968;&#20010;&#26631;&#20934;&#30340;&#39592;&#26550;&#26550;&#26500;&#65292;&#32780;&#26080;&#38656;&#20351;&#29992;&#38750;&#23545;&#31216;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#26159;&#19968;&#31181;&#21033;&#29992;&#22823;&#37327;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#27969;&#34892;&#19988;&#24378;&#22823;&#30340;&#26041;&#27861;&#65292;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#21508;&#31181;&#35757;&#32451;&#30446;&#26631;&#12290;&#26412;&#30740;&#31350;&#23545;&#26368;&#20808;&#36827;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#30446;&#26631;&#36827;&#34892;&#36125;&#21494;&#26031;&#20998;&#26512;&#65292;&#38416;&#26126;&#20102;&#27599;&#20010;&#31867;&#21035;&#20013;&#28508;&#22312;&#30340;&#27010;&#29575;&#22270;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22522;&#26412;&#21407;&#29702;&#20986;&#21457;&#25512;&#23548;&#36825;&#20123;&#27169;&#22411;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#20998;&#26512;&#36824;&#34920;&#26126;&#20102;&#23558;&#33258;&#30417;&#30563;&#23398;&#20064;&#19982;&#22522;&#20110;&#20284;&#28982;&#30340;&#29983;&#25104;&#27169;&#22411;&#33258;&#28982;&#25972;&#21512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#22522;&#20110;&#32858;&#31867;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#21644;&#33021;&#37327;&#27169;&#22411;&#39046;&#22495;&#20013;&#23454;&#29616;&#20102;&#36825;&#20010;&#27010;&#24565;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#19979;&#30028;&#65292;&#32463;&#35777;&#26126;&#33021;&#21487;&#38752;&#22320;&#24809;&#32602;&#26368;&#37325;&#35201;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#26032;&#25552;&#20986;&#30340;&#19979;&#30028;&#20351;&#24471;&#33021;&#22815;&#35757;&#32451;&#19968;&#20010;&#26631;&#20934;&#30340;&#39592;&#24178;&#26550;&#26500;&#65292;&#32780;&#26080;&#38656;&#20351;&#29992;&#35832;&#22914;&#20572;&#27490;&#26799;&#24230;&#12289;&#21160;&#37327;&#32534;&#30721;&#22120;&#25110;&#19987;&#38376;&#30340;&#32858;&#31867;&#31561;&#38750;&#23545;&#31216;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning is a popular and powerful method for utilizing large amounts of unlabeled data, for which a wide variety of training objectives have been proposed in the literature. In this study, we perform a Bayesian analysis of state-of-the-art self-supervised learning objectives, elucidating the underlying probabilistic graphical models in each class and presenting a standardized methodology for their derivation from first principles. The analysis also indicates a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a novel lower bound which is proven to reliably penalize the most important failure modes. Furthermore, this newly proposed lower bound enables the training of a standard backbone architecture without the necessity for asymmetric elements such as stop gradients, momentum encoders, or specialized clusteri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22270;&#22522;&#30784;&#27169;&#22411;&#65288;GFMs&#65289;&#30340;&#27010;&#24565;&#65292;&#24182;&#23545;&#20854;&#20851;&#38190;&#29305;&#24449;&#21644;&#25216;&#26415;&#36827;&#34892;&#20102;&#20840;&#38754;&#38416;&#36848;&#12290;&#21516;&#26102;&#65292;&#23558;&#29616;&#26377;GFMs&#24037;&#20316;&#20998;&#20026;&#19977;&#20010;&#31867;&#21035;&#65292;&#20026;&#36827;&#19968;&#27493;&#30740;&#31350;&#21644;&#24320;&#21457;&#22270;&#23398;&#20064;&#33539;&#24335;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2310.11829</link><description>&lt;p&gt;
&#36208;&#21521;&#22270;&#22522;&#30784;&#27169;&#22411;&#65306;&#19968;&#39033;&#35843;&#26597;&#19982;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Towards Graph Foundation Models: A Survey and Beyond. (arXiv:2310.11829v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11829
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22270;&#22522;&#30784;&#27169;&#22411;&#65288;GFMs&#65289;&#30340;&#27010;&#24565;&#65292;&#24182;&#23545;&#20854;&#20851;&#38190;&#29305;&#24449;&#21644;&#25216;&#26415;&#36827;&#34892;&#20102;&#20840;&#38754;&#38416;&#36848;&#12290;&#21516;&#26102;&#65292;&#23558;&#29616;&#26377;GFMs&#24037;&#20316;&#20998;&#20026;&#19977;&#20010;&#31867;&#21035;&#65292;&#20026;&#36827;&#19968;&#27493;&#30740;&#31350;&#21644;&#24320;&#21457;&#22270;&#23398;&#20064;&#33539;&#24335;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20854;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#20854;&#20182;&#39046;&#22495;&#20013;&#30340;&#26174;&#33879;&#25104;&#21151;&#65292;&#22522;&#30784;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#30340;&#22522;&#26412;&#26500;&#24314;&#27169;&#22359;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#22270;&#26426;&#22120;&#23398;&#20064;&#32463;&#21382;&#20102;&#30001;&#27973;&#23618;&#26041;&#27861;&#21521;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#36716;&#21464;&#12290;&#22522;&#30784;&#27169;&#22411;&#30340;&#20986;&#29616;&#21644;&#21516;&#21270;&#33021;&#21147;&#24341;&#36215;&#20102;&#22270;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#32773;&#30340;&#20852;&#36259;&#65292;&#24341;&#21457;&#20102;&#20851;&#20110;&#24320;&#21457;&#19979;&#19968;&#20010;&#39044;&#35757;&#32451;&#20110;&#24191;&#27867;&#22270;&#25968;&#25454;&#24182;&#21487;&#36866;&#24212;&#21508;&#31181;&#19979;&#28216;&#22270;&#20219;&#21153;&#30340;&#22270;&#23398;&#20064;&#33539;&#24335;&#30340;&#35752;&#35770;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#36825;&#31867;&#24037;&#20316;&#23578;&#26080;&#26126;&#30830;&#30340;&#23450;&#20041;&#21644;&#31995;&#32479;&#30340;&#20998;&#26512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22270;&#22522;&#30784;&#27169;&#22411;(GFMs)&#30340;&#27010;&#24565;&#65292;&#24182;&#39318;&#27425;&#23545;&#20854;&#20851;&#38190;&#29305;&#24449;&#21644;&#25216;&#26415;&#36827;&#34892;&#20840;&#38754;&#38416;&#36848;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#26681;&#25454;&#20854;&#21487;&#38752;&#24615;&#23558;&#29616;&#26377;GFMs&#24037;&#20316;&#20998;&#20026;&#19977;&#20010;&#31867;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emerging as fundamental building blocks for diverse artificial intelligence applications, foundation models have achieved notable success across natural language processing and many other domains. Parallelly, graph machine learning has witnessed a transformative shift, with shallow methods giving way to deep learning approaches. The emergence and homogenization capabilities of foundation models have piqued the interest of graph machine learning researchers, sparking discussions about developing the next graph learning paradigm that is pre-trained on broad graph data and can be adapted to a wide range of downstream graph tasks. However, there is currently no clear definition and systematic analysis for this type of work. In this article, we propose the concept of graph foundation models (GFMs), and provide the first comprehensive elucidation on their key characteristics and technologies. Following that, we categorize existing works towards GFMs into three categories based on their relia
&lt;/p&gt;</description></item><item><title>LGL-BCI&#26159;&#19968;&#31181;&#36731;&#37327;&#32423;&#20960;&#20309;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#22788;&#29702;EEG&#25968;&#25454;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#24230;&#37327;&#31354;&#38388;&#20013;&#25429;&#25417;&#36816;&#21160;&#24819;&#35937;&#20219;&#21153;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#24182;&#36890;&#36807;&#29305;&#24449;&#20998;&#35299;&#31639;&#27861;&#36827;&#34892;EEG&#36890;&#36947;&#36873;&#25321;&#20197;&#25552;&#39640;&#25512;&#26029;&#36895;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;LGL-BCI&#30456;&#27604;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#20855;&#26377;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.08051</link><description>&lt;p&gt;
LGL-BCI&#65306;&#19968;&#31181;&#36731;&#37327;&#32423;&#20960;&#20309;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#22522;&#20110;&#36816;&#21160;&#24819;&#35937;&#30340;&#33041;&#26426;&#25509;&#21475;
&lt;/p&gt;
&lt;p&gt;
LGL-BCI: A Lightweight Geometric Learning Framework for Motor Imagery-Based Brain-Computer Interfaces. (arXiv:2310.08051v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08051
&lt;/p&gt;
&lt;p&gt;
LGL-BCI&#26159;&#19968;&#31181;&#36731;&#37327;&#32423;&#20960;&#20309;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#22788;&#29702;EEG&#25968;&#25454;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#24230;&#37327;&#31354;&#38388;&#20013;&#25429;&#25417;&#36816;&#21160;&#24819;&#35937;&#20219;&#21153;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#24182;&#36890;&#36807;&#29305;&#24449;&#20998;&#35299;&#31639;&#27861;&#36827;&#34892;EEG&#36890;&#36947;&#36873;&#25321;&#20197;&#25552;&#39640;&#25512;&#26029;&#36895;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;LGL-BCI&#30456;&#27604;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#20855;&#26377;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33041;&#26426;&#25509;&#21475;&#26159;&#19968;&#31181;&#20351;&#29992;&#33041;&#20449;&#21495;&#19982;&#22806;&#37096;&#35774;&#22791;&#36827;&#34892;&#20132;&#20114;&#30340;&#24320;&#21019;&#24615;&#25216;&#26415;&#12290;&#23613;&#31649;&#26377;&#25152;&#36827;&#23637;&#65292;&#22522;&#20110;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#30340;&#36816;&#21160;&#24819;&#35937;&#20219;&#21153;&#38754;&#20020;&#25361;&#25112;&#65292;&#22914;&#24133;&#24230;&#21644;&#30456;&#20301;&#21464;&#24322;&#65292;&#20197;&#21450;&#22797;&#26434;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#38656;&#35201;&#26356;&#23567;&#30340;&#27169;&#22411;&#22823;&#23567;&#21644;&#26356;&#24555;&#30340;&#25512;&#26029;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;LGL-BCI&#26694;&#26550;&#65292;&#37319;&#29992;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24503;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;EEG&#65292;&#29305;&#21035;&#26159;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#27969;&#24418;&#31354;&#38388;&#12290;LGL-BCI&#25552;&#20379;&#20102;&#31283;&#20581;&#30340;EEG&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#25429;&#25417;&#20102;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29305;&#24449;&#20998;&#35299;&#31639;&#27861;&#36827;&#34892;EEG&#36890;&#36947;&#36873;&#25321;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#20943;&#23569;SPD&#30697;&#38453;&#30340;&#32500;&#24230;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#25512;&#26029;&#36895;&#24230;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#26174;&#31034;&#65292;&#19982;&#24403;&#21069;&#35299;&#20915;&#26041;&#26696;&#30456;&#27604;&#65292;LGL-BCI&#20855;&#26377;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#31361;&#20986;&#20102;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#22312;&#36816;&#21160;&#24819;&#35937;-&#33041;&#26426;&#25509;&#21475;&#24212;&#29992;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Brain-Computer Interfaces (BCIs) are a groundbreaking technology for interacting with external devices using brain signals. Despite advancements, electroencephalogram (EEG)-based Motor Imagery (MI) tasks face challenges like amplitude and phase variability, and complex spatial correlations, with a need for smaller model size and faster inference. This study introduces the LGL-BCI framework, employing a Geometric Deep Learning Framework for EEG processing in non-Euclidean metric spaces, particularly the Symmetric Positive Definite (SPD) Manifold space. LGL-BCI offers robust EEG data representation and captures spatial correlations. We propose an EEG channel selection solution via a feature decomposition algorithm to reduce SPD matrix dimensionality, with a lossless transformation boosting inference speed. Extensive experiments show LGL-BCI's superior accuracy and efficiency compared to current solutions, highlighting geometric deep learning's potential in MI-BCI applications. The effici
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#65292;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#39564;&#35777;&#65292;&#37327;&#21270;&#20102;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#32467;&#26524;&#34920;&#26126;PnP-ULA&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#12290;</title><link>http://arxiv.org/abs/2310.03546</link><description>&lt;p&gt;
&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#22312;&#19981;&#21305;&#37197;&#27979;&#37327;&#21644;&#20808;&#39564;&#27169;&#22411;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03546
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#65292;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#39564;&#35777;&#65292;&#37327;&#21270;&#20102;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#32467;&#26524;&#34920;&#26126;PnP-ULA&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#24050;&#34987;&#35777;&#26126;&#26159;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#24378;&#22823;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#26368;&#36817;&#21457;&#23637;&#36215;&#26469;&#30340;&#25554;&#25300;&#24335;&#26410;&#35843;&#25972;&#26391;&#20043;&#19975;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#20351;&#29992;&#22270;&#20687;&#21435;&#22122;&#22120;&#25351;&#23450;&#30340;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#65288;MMSE&#65289;&#20272;&#35745;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;PnP-ULA&#30340;&#37319;&#26679;&#20998;&#24067;&#19982;&#19981;&#21305;&#37197;&#30340;&#25968;&#25454;&#20445;&#30495;&#24230;&#21644;&#21435;&#22122;&#22120;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#23578;&#26410;&#32463;&#36807;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#21518;&#39564;-L2&#25311;&#24230;&#37327;&#24182;&#21033;&#29992;&#23427;&#26469;&#37327;&#21270;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#30340;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#36870;&#38382;&#39064;&#19978;&#23545;&#25105;&#20204;&#30340;&#29702;&#35770;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#65292;&#22914;&#20174;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#22270;&#20687;&#21435;&#27169;&#31946;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;PnP-ULA&#30340;&#37319;&#26679;&#20998;&#24067;&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#65292;&#24182;&#21487;&#20197;&#31934;&#30830;&#22320;&#25551;&#36848;&#20854;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Posterior sampling has been shown to be a powerful Bayesian approach for solving imaging inverse problems. The recent plug-and-play unadjusted Langevin algorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling and minimum mean squared error (MMSE) estimation by combining physical measurement models with deep-learning priors specified using image denoisers. However, the intricate relationship between the sampling distribution of PnP-ULA and the mismatched data-fidelity and denoiser has not been theoretically analyzed. We address this gap by proposing a posterior-L2 pseudometric and using it to quantify an explicit error bound for PnP-ULA under mismatched posterior distribution. We numerically validate our theory on several inverse problems such as sampling from Gaussian mixture models and image deblurring. Our results suggest that the sensitivity of the sampling distribution of PnP-ULA to a mismatch in the measurement model and the denoiser can be precisely characte
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SupReMix&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#26679;&#26412;&#65292;&#29305;&#21035;&#26159;&#28151;&#21512;&#36127;&#26679;&#26412;&#21644;&#28151;&#21512;&#27491;&#26679;&#26412;&#65292;&#26469;&#35299;&#20915;&#22238;&#24402;&#38382;&#39064;&#20013;&#34920;&#31034;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#20934;&#30830;&#30340;&#22238;&#24402;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.16633</link><description>&lt;p&gt;
&#28151;&#21512;&#20320;&#33258;&#24049;&#30340;&#23545;&#27604;&#23545;
&lt;/p&gt;
&lt;p&gt;
Mixup Your Own Pairs. (arXiv:2309.16633v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16633
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SupReMix&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#26679;&#26412;&#65292;&#29305;&#21035;&#26159;&#28151;&#21512;&#36127;&#26679;&#26412;&#21644;&#28151;&#21512;&#27491;&#26679;&#26412;&#65292;&#26469;&#35299;&#20915;&#22238;&#24402;&#38382;&#39064;&#20013;&#34920;&#31034;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#20934;&#30830;&#30340;&#22238;&#24402;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#22238;&#24402;&#38382;&#39064;&#20256;&#32479;&#19978;&#27604;&#20998;&#31867;&#38382;&#39064;&#21463;&#21040;&#30340;&#20851;&#27880;&#36739;&#23569;&#12290;&#30452;&#25509;&#24212;&#29992;&#20026;&#20998;&#31867;&#35774;&#35745;&#30340;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#21040;&#22238;&#24402;&#38382;&#39064;&#24448;&#24448;&#20250;&#23548;&#33268;&#28508;&#31354;&#38388;&#20013;&#30862;&#29255;&#21270;&#30340;&#34920;&#31034;&#65292;&#20174;&#32780;&#20135;&#29983;&#27425;&#20248;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#30001;&#20110;&#24573;&#35270;&#20102;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;&#65306;&#24207;&#24207;&#24863;&#30693;&#21644;&#38590;&#24230;&#65292;&#23545;&#20110;&#22238;&#24402;&#38382;&#39064;&#32780;&#35328;&#65292;&#23545;&#27604;&#23398;&#20064;&#30340;&#28508;&#33021;&#34987;&#24573;&#35270;&#20102;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20513;&#8220;&#28151;&#21512;&#33258;&#24049;&#30340;&#23545;&#27604;&#23545;&#36827;&#34892;&#30417;&#30563;&#24615;&#23545;&#27604;&#22238;&#24402;&#8221;&#65292;&#32780;&#19981;&#20165;&#20165;&#20381;&#38752;&#30495;&#23454;/&#22686;&#24378;&#26679;&#26412;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#28151;&#21512;&#24335;&#30417;&#30563;&#23545;&#27604;&#22238;&#24402;&#23398;&#20064;&#65288;SupReMix&#65289;&#12290;&#23427;&#22312;&#23884;&#20837;&#32423;&#21035;&#19978;&#20197;&#38170;&#28857;&#21253;&#21547;&#30340;&#28151;&#21512;&#65288;&#38170;&#28857;&#21644;&#19968;&#20010;&#19981;&#21516;&#30340;&#36127;&#26679;&#26412;&#30340;&#28151;&#21512;&#65289;&#20316;&#20026;&#22256;&#38590;&#36127;&#23545;&#65292;&#20197;&#38170;&#28857;&#25490;&#38500;&#30340;&#28151;&#21512;&#65288;&#20004;&#20010;&#19981;&#21516;&#30340;&#36127;&#26679;&#26412;&#30340;&#28151;&#21512;&#65289;&#20316;&#20026;&#22256;&#38590;&#27491;&#23545;&#12290;&#36825;&#19968;&#31574;&#30053;&#24418;&#25104;&#20102;&#22256;&#38590;&#26679;&#26412;&#23545;&#23398;&#20064;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
In representation learning, regression has traditionally received less attention than classification. Directly applying representation learning techniques designed for classification to regression often results in fragmented representations in the latent space, yielding sub-optimal performance. In this paper, we argue that the potential of contrastive learning for regression has been overshadowed due to the neglect of two crucial aspects: ordinality-awareness and hardness. To address these challenges, we advocate "mixup your own contrastive pairs for supervised contrastive regression", instead of relying solely on real/augmented samples. Specifically, we propose Supervised Contrastive Learning for Regression with Mixup (SupReMix). It takes anchor-inclusive mixtures (mixup of the anchor and a distinct negative sample) as hard negative pairs and anchor-exclusive mixtures (mixup of two distinct negative samples) as hard positive pairs at the embedding level. This strategy formulates harde
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;PILOT&#30340;&#22522;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;&#24037;&#20855;&#31665;&#65292;&#20026;&#22312;&#22788;&#29702;&#27969;&#24335;&#25968;&#25454;&#24182;&#36866;&#24212;&#26032;&#25968;&#25454;&#21040;&#26469;&#30340;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#22686;&#37327;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.07117</link><description>&lt;p&gt;
PILOT&#65306;&#19968;&#20010;&#22522;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;&#24037;&#20855;&#31665;
&lt;/p&gt;
&lt;p&gt;
PILOT: A Pre-Trained Model-Based Continual Learning Toolbox. (arXiv:2309.07117v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07117
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;PILOT&#30340;&#22522;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;&#24037;&#20855;&#31665;&#65292;&#20026;&#22312;&#22788;&#29702;&#27969;&#24335;&#25968;&#25454;&#24182;&#36866;&#24212;&#26032;&#25968;&#25454;&#21040;&#26469;&#30340;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#22686;&#37327;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#21508;&#31181;&#38382;&#39064;&#65292;&#20294;&#20027;&#35201;&#22312;&#23553;&#38381;&#29615;&#22659;&#20013;&#36816;&#20316;&#65292;&#22788;&#29702;&#27969;&#24335;&#25968;&#25454;&#26102;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#65292;&#22686;&#37327;&#23398;&#20064;&#24212;&#36816;&#32780;&#29983;&#65292;&#29992;&#20110;&#22788;&#29702;&#28041;&#21450;&#26032;&#25968;&#25454;&#21040;&#26469;&#30340;&#29616;&#23454;&#22330;&#26223;&#12290;&#26368;&#36817;&#65292;&#39044;&#35757;&#32451;&#22312;&#19981;&#26029;&#21462;&#24471;&#37325;&#35201;&#36827;&#23637;&#65292;&#24182;&#24341;&#36215;&#20102;&#20247;&#22810;&#30740;&#31350;&#20154;&#21592;&#30340;&#20851;&#27880;&#12290;&#36825;&#20123;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;PTMs&#65289;&#30340;&#24378;&#22823;&#24615;&#33021;&#20026;&#24320;&#21457;&#33021;&#22815;&#26377;&#25928;&#36866;&#24212;&#29616;&#23454;&#22330;&#26223;&#30340;&#25345;&#32493;&#23398;&#20064;&#31639;&#27861;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;&#22240;&#27492;&#65292;&#25506;&#32034;&#22312;&#22686;&#37327;&#23398;&#20064;&#20013;&#21033;&#29992;PTMs&#24050;&#32463;&#25104;&#20026;&#24517;&#38656;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;PILOT&#30340;&#22522;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;&#24037;&#20855;&#31665;&#12290;&#19968;&#26041;&#38754;&#65292;PILOT&#23454;&#26045;&#20102;&#19968;&#20123;&#22522;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#26368;&#26032;&#29677;&#32423;&#22686;&#37327;&#23398;&#20064;&#31639;&#27861;&#65292;&#22914;L2P&#12289;DualPrompt&#21644;CODA-Prompt&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;PILOT&#20063;&#36866;&#24212;&#20102;&#20856;&#22411;&#30340;&#29677;&#32423;&#22686;&#37327;&#23398;&#20064;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
While traditional machine learning can effectively tackle a wide range of problems, it primarily operates within a closed-world setting, which presents limitations when dealing with streaming data. As a solution, incremental learning emerges to address real-world scenarios involving new data's arrival. Recently, pre-training has made significant advancements and garnered the attention of numerous researchers. The strong performance of these pre-trained models (PTMs) presents a promising avenue for developing continual learning algorithms that can effectively adapt to real-world scenarios. Consequently, exploring the utilization of PTMs in incremental learning has become essential. This paper introduces a pre-trained model-based continual learning toolbox known as PILOT. On the one hand, PILOT implements some state-of-the-art class-incremental learning algorithms based on pre-trained models, such as L2P, DualPrompt, and CODA-Prompt. On the other hand, PILOT also fits typical class-incre
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#19981;&#31934;&#30830;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#40065;&#26834;&#32479;&#35745;&#39564;&#35777;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20027;&#21160;&#23398;&#20064;&#12289;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#31070;&#32463;&#32593;&#32476;&#39564;&#35777;&#65292;&#21487;&#20197;&#22312;&#22823;&#37327;&#30340;&#20998;&#24067;&#19978;&#25552;&#20379;&#23545;&#40657;&#30418;&#31995;&#32479;&#34892;&#20026;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2308.14815</link><description>&lt;p&gt;
&#20351;&#29992;&#19981;&#31934;&#30830;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#40065;&#26834;&#32479;&#35745;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Statistical Verification with Imprecise Neural Networks. (arXiv:2308.14815v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#19981;&#31934;&#30830;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#40065;&#26834;&#32479;&#35745;&#39564;&#35777;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20027;&#21160;&#23398;&#20064;&#12289;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#31070;&#32463;&#32593;&#32476;&#39564;&#35777;&#65292;&#21487;&#20197;&#22312;&#22823;&#37327;&#30340;&#20998;&#24067;&#19978;&#25552;&#20379;&#23545;&#40657;&#30418;&#31995;&#32479;&#34892;&#20026;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;AI&#23433;&#20840;&#39046;&#22495;&#65292;&#19968;&#20010;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#26159;&#22312;&#39640;&#32500;&#33258;&#20027;&#31995;&#32479;&#30340;&#34892;&#20026;&#19978;&#25552;&#20379;&#20445;&#35777;&#12290;&#20197;&#21487;&#36798;&#24615;&#20998;&#26512;&#20026;&#20013;&#24515;&#30340;&#39564;&#35777;&#26041;&#27861;&#26080;&#27861;&#25193;&#23637;&#65292;&#32780;&#32431;&#31929;&#30340;&#32479;&#35745;&#26041;&#27861;&#21463;&#21040;&#23545;&#37319;&#26679;&#36807;&#31243;&#30340;&#20998;&#24067;&#20551;&#35774;&#30340;&#38480;&#21046;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#40657;&#30418;&#31995;&#32479;&#30340;&#20998;&#24067;&#40065;&#26834;&#29256;&#26412;&#30340;&#32479;&#35745;&#39564;&#35777;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#30340;&#24615;&#33021;&#20445;&#35777;&#36866;&#29992;&#20110;&#22823;&#37327;&#30340;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#23398;&#20064;&#12289;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#31070;&#32463;&#32593;&#32476;&#39564;&#35777;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#26680;&#24515;&#37096;&#20998;&#26159;&#19968;&#31181;&#31216;&#20026;&#19981;&#31934;&#30830;&#31070;&#32463;&#32593;&#32476;&#30340;&#38598;&#25104;&#25216;&#26415;&#65292;&#23427;&#25552;&#20379;&#20102;&#19981;&#30830;&#23450;&#24615;&#20197;&#25351;&#23548;&#20027;&#21160;&#23398;&#20064;&#12290;&#20027;&#21160;&#23398;&#20064;&#20351;&#29992;&#20102;&#19968;&#31181;&#31216;&#20026;Sherlock&#30340;&#20840;&#38754;&#31070;&#32463;&#32593;&#32476;&#39564;&#35777;&#24037;&#20855;&#26469;&#25910;&#38598;&#26679;&#26412;&#12290;&#22312;openAI gym Mujoco&#29615;&#22659;&#20013;&#20351;&#29992;&#22810;&#20010;&#29289;&#29702;&#27169;&#25311;&#22120;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
A particularly challenging problem in AI safety is providing guarantees on the behavior of high-dimensional autonomous systems. Verification approaches centered around reachability analysis fail to scale, and purely statistical approaches are constrained by the distributional assumptions about the sampling process. Instead, we pose a distributionally robust version of the statistical verification problem for black-box systems, where our performance guarantees hold over a large family of distributions. This paper proposes a novel approach based on a combination of active learning, uncertainty quantification, and neural network verification. A central piece of our approach is an ensemble technique called Imprecise Neural Networks, which provides the uncertainty to guide active learning. The active learning uses an exhaustive neural-network verification tool Sherlock to collect samples. An evaluation on multiple physical simulators in the openAI gym Mujoco environments with reinforcement-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#22312;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#65292;&#22312;&#24418;&#24335;&#35821;&#35328;&#29702;&#35770;&#32972;&#26223;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20026;&#20160;&#20040;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#21040;&#32452;&#21512;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#24182;&#22312;&#19968;&#20010;&#29616;&#23454;&#19990;&#30028;&#30340;&#33521;&#35821;&#21477;&#23376;&#31034;&#20363;&#20013;&#25552;&#20379;&#20102;&#38646;&#38169;&#35823;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2306.17184</link><description>&lt;p&gt;
&#20026;&#20160;&#20040;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#35299;&#20915;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#38382;&#39064;&#65311;&#25968;&#23398;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Why can neural language models solve next-word prediction? A mathematical perspective. (arXiv:2306.17184v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17184
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#22312;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#65292;&#22312;&#24418;&#24335;&#35821;&#35328;&#29702;&#35770;&#32972;&#26223;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20026;&#20160;&#20040;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#21040;&#32452;&#21512;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#24182;&#22312;&#19968;&#20010;&#29616;&#23454;&#19990;&#30028;&#30340;&#33521;&#35821;&#21477;&#23376;&#31034;&#20363;&#20013;&#25552;&#20379;&#20102;&#38646;&#38169;&#35823;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28145;&#24230;&#23398;&#20064;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#24341;&#36215;&#20102;&#38761;&#21629;&#65292;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#22312;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#26041;&#38754;&#35777;&#26126;&#20102;&#38750;&#24120;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#22312;&#24418;&#24335;&#35821;&#35328;&#29702;&#35770;&#30340;&#32972;&#26223;&#19979;&#65292;&#20851;&#20110;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#22312;&#27492;&#20219;&#21153;&#20013;&#21487;&#20197;&#23398;&#20064;&#21040;&#32452;&#21512;&#35268;&#21017;&#30340;&#25104;&#21151;&#30340;&#20005;&#26684;&#29702;&#35770;&#35299;&#37322;&#23578;&#26410;&#34987;&#25552;&#20986;&#65292;&#22240;&#20026;&#23578;&#19981;&#28165;&#26970;&#20026;&#20160;&#20040;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#23398;&#20064;&#21040;&#25511;&#21046;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#20219;&#21153;&#30340;&#32452;&#21512;&#35268;&#21017;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#21487;&#20197;&#29992;&#26469;&#27169;&#25311;&#33521;&#35821;&#21477;&#23376;&#30340;&#29616;&#23454;&#19990;&#30028;&#31034;&#20363;&#30340;&#24418;&#24335;&#35821;&#35328;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#19979;&#19968;&#20010;&#35789;&#39044;&#27979;&#20219;&#21153;&#65292;&#19988;&#38169;&#35823;&#29575;&#20026;&#38646;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#31361;&#20986;&#20102;&#23884;&#20837;&#23618;&#21644;&#20840;&#36830;&#25509;&#32452;&#20214;&#22312;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#19981;&#21516;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, deep learning has revolutionized the field of natural language processing, with neural language models proving to be very effective for next-word prediction. However, a rigorous theoretical explanation for their success in the context of formal language theory has not yet been developed, as it is unclear why neural language models can learn the combinatorial rules that govern the next-word prediction task. In this paper, we study a class of formal languages that can be used to model real-world examples of English sentences. We construct neural language models can solve the next-word prediction task in this context with zero error. Our proof highlights the different roles of the embedding layer and the fully connected component within the neural language model.
&lt;/p&gt;</description></item><item><title>&#31639;&#23376;&#23398;&#20064;&#20013;&#23384;&#22312;&#32500;&#24230;&#35781;&#21650;&#65292;&#20294;&#23545;&#20110;&#30001;Hamilton-Jacobi&#26041;&#31243;&#23450;&#20041;&#30340;&#35299;&#31639;&#23376;&#21487;&#20197;&#20811;&#26381;&#32500;&#24230;&#35781;&#21650;&#12290;</title><link>http://arxiv.org/abs/2306.15924</link><description>&lt;p&gt;
&#36816;&#31639;&#23398;&#20064;&#20013;&#30340;&#32500;&#24230;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
The curse of dimensionality in operator learning. (arXiv:2306.15924v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15924
&lt;/p&gt;
&lt;p&gt;
&#31639;&#23376;&#23398;&#20064;&#20013;&#23384;&#22312;&#32500;&#24230;&#35781;&#21650;&#65292;&#20294;&#23545;&#20110;&#30001;Hamilton-Jacobi&#26041;&#31243;&#23450;&#20041;&#30340;&#35299;&#31639;&#23376;&#21487;&#20197;&#20811;&#26381;&#32500;&#24230;&#35781;&#21650;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#26144;&#23556;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#31639;&#23376;&#65292;&#21487;&#20197;&#29992;&#20110;&#36890;&#36807;&#27169;&#25311;&#21152;&#36895;&#27169;&#22411;&#35780;&#20272;&#65292;&#25110;&#32773;&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#36817;&#24180;&#26469;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#24341;&#21457;&#20102;&#31639;&#23376;&#23398;&#20064;&#39046;&#22495;&#30340;&#24555;&#36895;&#21457;&#23637;&#12290;&#26412;&#25991;&#30340;&#31532;&#19968;&#39033;&#36129;&#29486;&#26159;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#33324;&#30340;&#21482;&#30001;&#20854; $C^r$ &#25110; Lipschitz &#27491;&#21017;&#24615;&#29305;&#24449;&#21270;&#30340;&#31639;&#23376;&#31867;&#65292;&#31639;&#23376;&#23398;&#20064;&#36973;&#21463;&#20102;&#32500;&#24230;&#35781;&#21650;&#65292;&#36825;&#37324;&#36890;&#36807;&#26080;&#31351;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#20989;&#25968;&#31354;&#38388;&#30340;&#34920;&#24449;&#26469;&#31934;&#30830;&#23450;&#20041;&#32500;&#24230;&#35781;&#21650;&#12290;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#21253;&#25324; PCA-Net&#12289;DeepONet &#21644; FNO &#22312;&#20869;&#30340;&#22810;&#31181;&#29616;&#26377;&#31070;&#32463;&#31639;&#23376;&#12290;&#26412;&#25991;&#30340;&#31532;&#20108;&#39033;&#36129;&#29486;&#26159;&#35777;&#26126;&#20102;&#23545;&#20110;&#30001;Hamilton-Jacobi&#26041;&#31243;&#23450;&#20041;&#30340;&#35299;&#31639;&#23376;&#65292;&#21487;&#20197;&#20811;&#26381;&#19968;&#33324;&#30340;&#32500;&#24230;&#35781;&#21650;&#65307;&#36825;&#26159;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#34920;&#31034;&#26041;&#27861;&#26469;&#23454;&#29616;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural operator architectures employ neural networks to approximate operators mapping between Banach spaces of functions; they may be used to accelerate model evaluations via emulation, or to discover models from data. Consequently, the methodology has received increasing attention over recent years, giving rise to the rapidly growing field of operator learning. The first contribution of this paper is to prove that for general classes of operators which are characterized only by their $C^r$- or Lipschitz-regularity, operator learning suffers from a curse of dimensionality, defined precisely here in terms of representations of the infinite-dimensional input and output function spaces. The result is applicable to a wide variety of existing neural operators, including PCA-Net, DeepONet and the FNO. The second contribution of the paper is to prove that the general curse of dimensionality can be overcome for solution operators defined by the Hamilton-Jacobi equation; this is achieved by lev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;</title><link>http://arxiv.org/abs/2305.05792</link><description>&lt;p&gt;
&#36807;&#25311;&#21512;&#30340;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Testing for Overfitting. (arXiv:2305.05792v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05792
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#39640;&#22797;&#26434;&#24230;&#30340;&#27169;&#22411;&#24120;&#35265;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#21363;&#27169;&#22411;&#33021;&#22815;&#24456;&#22909;&#22320;&#20195;&#34920;&#25968;&#25454;&#65292;&#20294;&#26080;&#27861;&#25512;&#24191;&#21040;&#22522;&#30784;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#12290;&#35299;&#20915;&#36807;&#25311;&#21512;&#30340;&#20856;&#22411;&#26041;&#27861;&#26159;&#22312;&#30041;&#32622;&#38598;&#19978;&#35745;&#31639;&#32463;&#39564;&#39118;&#38505;&#65292;&#19968;&#26086;&#39118;&#38505;&#24320;&#22987;&#22686;&#21152;&#65292;&#23601;&#20572;&#27490;&#65288;&#25110;&#26631;&#35760;&#20309;&#26102;&#20572;&#27490;&#65289;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#36755;&#20986;&#20102;&#33391;&#22909;&#27867;&#21270;&#30340;&#27169;&#22411;&#65292;&#20294;&#20854;&#23454;&#29616;&#21407;&#29702;&#20027;&#35201;&#26159;&#21551;&#21457;&#24335;&#30340;&#12290;&#26412;&#25991;&#35752;&#35770;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;&#26631;&#20934;&#28176;&#36817;&#21644;&#27987;&#24230;&#32467;&#26524;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20986;&#24182;&#38416;&#36848;&#20102;&#19968;&#20010;&#20551;&#35774;&#26816;&#39564;&#65292;&#36890;&#36807;&#35813;&#26816;&#39564;&#21487;&#20197;&#23545;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#37327;&#21270;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;&#25105;&#20204;&#20381;&#38752;&#30830;&#20445;&#32463;&#39564;&#22343;&#20540;&#24212;&#35813;&#39640;&#27010;&#29575;&#22320;&#36817;&#20284;&#20854;&#30495;&#23454;&#22343;&#20540;&#30340;&#27987;&#24230;&#30028;&#38480;&#65292;&#20197;&#24471;&#20986;&#20182;&#20204;&#24212;&#35813;&#30456;&#20114;&#25509;&#36817;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
High complexity models are notorious in machine learning for overfitting, a phenomenon in which models well represent data but fail to generalize an underlying data generating process. A typical procedure for circumventing overfitting computes empirical risk on a holdout set and halts once (or flags that/when) it begins to increase. Such practice often helps in outputting a well-generalizing model, but justification for why it works is primarily heuristic.  We discuss the overfitting problem and explain why standard asymptotic and concentration results do not hold for evaluation with training data. We then proceed to introduce and argue for a hypothesis test by means of which both model performance may be evaluated using training data, and overfitting quantitatively defined and detected. We rely on said concentration bounds which guarantee that empirical means should, with high probability, approximate their true mean to conclude that they should approximate each other. We stipulate co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#31614;&#25216;&#24039;&#65292;&#29992;&#20110;&#22312;&#22810;&#33410;&#28857;&#20219;&#21153;&#19978;&#25552;&#39640;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#31034;&#23398;&#20064;&#33021;&#21147;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21306;&#20998;&#30446;&#26631;&#33410;&#28857;&#21644;&#20854;&#20182;&#33410;&#28857;&#30340;&#26041;&#24335;&#25913;&#36827;&#20102;&#20197;&#24448;&#30452;&#25509;&#32858;&#21512;&#21508;&#33410;&#28857;&#34920;&#31034;&#30340;&#32570;&#38519;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#33410;&#28857;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2304.10074</link><description>&lt;p&gt;
&#21033;&#29992;&#26631;&#31614;&#25216;&#24039;&#22312;&#22810;&#33410;&#28857;&#20219;&#21153;&#19978;&#25913;&#36827;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Improving Graph Neural Networks on Multi-node Tasks with Labeling Tricks. (arXiv:2304.10074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#31614;&#25216;&#24039;&#65292;&#29992;&#20110;&#22312;&#22810;&#33410;&#28857;&#20219;&#21153;&#19978;&#25552;&#39640;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#31034;&#23398;&#20064;&#33021;&#21147;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21306;&#20998;&#30446;&#26631;&#33410;&#28857;&#21644;&#20854;&#20182;&#33410;&#28857;&#30340;&#26041;&#24335;&#25913;&#36827;&#20102;&#20197;&#24448;&#30452;&#25509;&#32858;&#21512;&#21508;&#33410;&#28857;&#34920;&#31034;&#30340;&#32570;&#38519;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#33410;&#28857;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#36827;&#34892;&#22810;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#30340;&#29702;&#35770;&#65292;&#20854;&#20013;&#25105;&#20204;&#26377;&#20852;&#36259;&#23398;&#20064;&#30001;&#22810;&#20010;&#33410;&#28857;&#32452;&#25104;&#30340;&#33410;&#28857;&#38598;&#30340;&#34920;&#31034;&#65292;&#22914;&#19968;&#20010;&#38142;&#25509;&#12290;&#29616;&#26377;&#30340;GNN&#20027;&#35201;&#35774;&#35745;&#29992;&#20110;&#23398;&#20064;&#21333;&#20010;&#33410;&#28857;&#34920;&#31034;&#12290;&#24403;&#25105;&#20204;&#24819;&#35201;&#23398;&#20064;&#28041;&#21450;&#22810;&#20010;&#33410;&#28857;&#30340;&#33410;&#28857;&#38598;&#34920;&#31034;&#26102;&#65292;&#20197;&#21069;&#30340;&#24037;&#20316;&#20013;&#24120;&#35265;&#30340;&#20570;&#27861;&#26159;&#30452;&#25509;&#32858;&#21512;GNN&#33719;&#24471;&#30340;&#21333;&#33410;&#28857;&#34920;&#31034;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#22522;&#26412;&#23616;&#38480;&#24615;&#65292;&#21363;&#19981;&#33021;&#25429;&#25417;&#33410;&#28857;&#38598;&#20013;&#22810;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#21516;&#26102;&#20063;&#35748;&#20026;&#30452;&#25509;&#32858;&#21512;&#21508;&#20010;&#33410;&#28857;&#30340;&#34920;&#31034;&#26080;&#27861;&#20026;&#22810;&#20010;&#33410;&#28857;&#20135;&#29983;&#26377;&#25928;&#30340;&#32852;&#21512;&#34920;&#31034;&#12290;&#19968;&#20010;&#30452;&#25509;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#21306;&#20998;&#30446;&#26631;&#33410;&#28857;&#21644;&#20854;&#20182;&#33410;&#28857;&#12290;&#22522;&#20110;&#36825;&#20010;&#24819;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#26631;&#31614;&#25216;&#24039;&#8221;&#65292;&#23427;&#39318;&#20808;&#26681;&#25454;&#19982;&#30446;&#26631;&#33410;&#28857;&#38598;&#30340;&#20851;&#31995;&#26631;&#35760;&#22270;&#20013;&#30340;&#33410;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a theory of using graph neural networks (GNNs) for \textit{multi-node representation learning}, where we are interested in learning a representation for a set of more than one node such as a link. Existing GNNs are mainly designed to learn single-node representations. When we want to learn a node-set representation involving multiple nodes, a common practice in previous works is to directly aggregate the single-node representations obtained by a GNN. In this paper, we show a fundamental limitation of such an approach, namely the inability to capture the dependence among multiple nodes in a node set, and argue that directly aggregating individual node representations fails to produce an effective joint representation for multiple nodes. A straightforward solution is to distinguish target nodes from others. Formalizing this idea, we propose \text{labeling trick}, which first labels nodes in the graph according to their relationships with the target node set befo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#21457;&#29616;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#22312;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2303.00055</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#26102;&#38388;&#23610;&#24230;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Learning time-scales in two-layers neural networks. (arXiv:2303.00055v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#21457;&#29616;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#22312;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20855;&#26377;&#22810;&#20010;&#24341;&#20154;&#27880;&#24847;&#30340;&#29305;&#28857;&#12290;&#23588;&#20854;&#26159;&#65292;&#22312;&#22823;&#25209;&#37327;&#25968;&#25454;&#24179;&#22343;&#21518;&#65292;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#20960;&#20046;&#27809;&#26377;&#36827;&#23637;&#30340;&#38271;&#21608;&#26399;&#21644;&#24555;&#36895;&#19979;&#38477;&#30340;&#38388;&#38548;&#20132;&#26367;&#20986;&#29616;&#12290;&#36825;&#20123;&#36830;&#32493;&#30340;&#23398;&#20064;&#38454;&#27573;&#24448;&#24448;&#22312;&#38750;&#24120;&#19981;&#21516;&#30340;&#26102;&#38388;&#23610;&#24230;&#19978;&#36827;&#34892;&#12290;&#26368;&#21518;&#65292;&#22312;&#26089;&#26399;&#38454;&#27573;&#23398;&#20064;&#30340;&#27169;&#22411;&#36890;&#24120;&#26159;&#8220;&#31616;&#21333;&#30340;&#8221;&#25110;&#8220;&#26131;&#20110;&#23398;&#20064;&#30340;&#8221;&#65292;&#23613;&#31649;&#20197;&#38590;&#20197;&#24418;&#24335;&#21270;&#30340;&#26041;&#24335;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#65292;&#22312;&#19968;&#31995;&#21015;&#26032;&#30340;&#20005;&#23494;&#32467;&#26524;&#12289;&#38750;&#20005;&#23494;&#25968;&#23398;&#25512;&#23548;&#21644;&#25968;&#20540;&#23454;&#39564;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#29305;&#21035;&#25351;&#20986;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#19982;&#38271;&#21608;&#26399;&#30340;&#20986;&#29616;&#21644;&#28040;&#22833;&#26377;&#20851;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#21487;&#20197;&#29992;&#20110;&#35268;&#33539;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-based learning in multi-layer neural networks displays a number of striking features. In particular, the decrease rate of empirical risk is non-monotone even after averaging over large batches. Long plateaus in which one observes barely any progress alternate with intervals of rapid decrease. These successive phases of learning often take place on very different time scales. Finally, models learnt in an early phase are typically `simpler' or `easier to learn' although in a way that is difficult to formalize.  Although theoretical explanations of these phenomena have been put forward, each of them captures at best certain specific regimes. In this paper, we study the gradient flow dynamics of a wide two-layer neural network in high-dimension, when data are distributed according to a single-index model (i.e., the target function depends on a one-dimensional projection of the covariates). Based on a mixture of new rigorous results, non-rigorous mathematical derivations, and numer
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#36873;&#25321;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#30340;&#21160;&#26426;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#22522;&#20110;&#20010;&#20154;&#30446;&#26631;&#21644;&#32972;&#26223;&#22240;&#32032;&#65292;&#35843;&#26597;&#36824;&#32473;&#20986;&#20102;&#20248;&#21270;&#27169;&#22411;&#30340;&#20845;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2203.01717</link><description>&lt;p&gt;
&#36873;&#25321;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#30340;&#20174;&#19994;&#32773;&#21160;&#26426;
&lt;/p&gt;
&lt;p&gt;
Practitioner Motives to Select Hyperparameter Optimization Methods. (arXiv:2203.01717v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.01717
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#36873;&#25321;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#30340;&#21160;&#26426;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#22522;&#20110;&#20010;&#20154;&#30446;&#26631;&#21644;&#32972;&#26223;&#22240;&#32032;&#65292;&#35843;&#26597;&#36824;&#32473;&#20986;&#20102;&#20248;&#21270;&#27169;&#22411;&#30340;&#20845;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#36827;&#30340;&#32534;&#31243;&#36229;&#21442;&#25968;&#20248;&#21270;&#26041;&#27861;&#65292;&#22914;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#20855;&#26377;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#33021;&#22815;&#21487;&#38752;&#22320;&#25214;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#20540;&#12290;&#28982;&#32780;&#65292;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#32463;&#24120;&#24212;&#29992;&#26679;&#26412;&#25928;&#29575;&#36739;&#20302;&#30340;HPO&#26041;&#27861;&#65292;&#22914;&#32593;&#26684;&#25628;&#32034;&#65292;&#36825;&#36890;&#24120;&#23548;&#33268;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26410;&#32463;&#20248;&#21270;&#12290;&#25105;&#20204;&#24576;&#30097;&#65292;&#20174;&#19994;&#32773;&#36873;&#25321;HPO&#26041;&#27861;&#30340;&#21407;&#22240;&#22522;&#20110;&#20010;&#20154;&#21160;&#26426;&#65292;&#21253;&#25324;&#32972;&#26223;&#22240;&#32032;&#21644;&#20010;&#20154;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#20174;&#19994;&#32773;&#30340;&#21160;&#26426;&#20173;&#28982;&#38656;&#35201;&#28548;&#28165;&#65292;&#36825;&#22952;&#30861;&#20102;&#35780;&#20272;HPO&#26041;&#27861;&#20197;&#23454;&#29616;&#29305;&#23450;&#30446;&#26631;&#21644;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;HPO&#24037;&#20855;&#30340;&#24320;&#21457;&#12290;&#20026;&#20102;&#20102;&#35299;&#20174;&#19994;&#32773;&#20351;&#29992;&#29305;&#23450;HPO&#26041;&#27861;&#30340;&#21160;&#26426;&#65292;&#25105;&#20204;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#21253;&#25324;20&#20010;&#21322;&#32467;&#26500;&#21270;&#35775;&#35848;&#21644;&#19968;&#39033;&#35843;&#26597;&#30740;&#31350;&#65292;&#20849;&#26377;71&#21517;&#26426;&#22120;&#23398;&#20064;&#19987;&#23478;&#21442;&#19982;&#65292;&#20197;&#25910;&#38598;&#35775;&#35848;&#32467;&#26524;&#30340;&#22806;&#37096;&#26377;&#25928;&#24615;&#30340;&#35777;&#25454;&#12290;&#36890;&#36807;&#35774;&#32622;&#20845;&#20010;&#20027;&#35201;&#30446;&#26631;&#65288;&#20363;&#22914;&#65292;&#25913;&#36827;&#27169;&#22411;&#29702;&#35299;&#65289;&#65292;
&lt;/p&gt;
&lt;p&gt;
Advanced programmatic hyperparameter optimization (HPO) methods, such as Bayesian optimization, have high sample efficiency in reproducibly finding optimal hyperparameter values of machine learning (ML) models. Yet, ML practitioners often apply less sample-efficient HPO methods, such as grid search, which often results in under-optimized ML models. As a reason for this behavior, we suspect practitioners choose HPO methods based on individual motives, consisting of contextual factors and individual goals. However, practitioners' motives still need to be clarified, hindering the evaluation of HPO methods for achieving specific goals and the user-centered development of HPO tools. To understand practitioners' motives for using specific HPO methods, we used a mixed-methods approach involving 20 semi-structured interviews and a survey study with 71 ML experts to gather evidence of the external validity of the interview results. By presenting six main goals (e.g., improving model understandi
&lt;/p&gt;</description></item></channel></rss>