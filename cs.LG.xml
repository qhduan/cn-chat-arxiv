<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;TSAP&#26041;&#27861;&#26469;&#33258;&#21160;&#35843;&#25972;&#25968;&#25454;&#22686;&#24378;&#65292;&#20026;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#24102;&#26469;&#20102;&#31471;&#21040;&#31471;&#30340;&#33258;&#35843;&#33410;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.02865</link><description>&lt;p&gt;
&#31471;&#21040;&#31471;&#33258;&#35843;&#33410;&#33258;&#30417;&#30563;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
End-To-End Self-tuning Self-supervised Time Series Anomaly Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02865
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;TSAP&#26041;&#27861;&#26469;&#33258;&#21160;&#35843;&#25972;&#25968;&#25454;&#22686;&#24378;&#65292;&#20026;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#24102;&#26469;&#20102;&#31471;&#21040;&#31471;&#30340;&#33258;&#35843;&#33410;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#65288;TSAD&#65289;&#22312;&#30417;&#25511;&#29615;&#22659;&#20256;&#24863;&#22120;&#12289;&#34892;&#19994;KPI&#12289;&#24739;&#32773;&#29983;&#29289;&#26631;&#24535;&#29289;&#31561;&#26041;&#38754;&#26377;&#35768;&#22810;&#24212;&#29992;&#12290;TSAD&#30340;&#19968;&#20010;&#21452;&#37325;&#25361;&#25112;&#26159;&#38656;&#35201;&#19968;&#31181;&#22810;&#21151;&#33021;&#19988;&#26080;&#30417;&#30563;&#27169;&#22411;&#65292;&#33021;&#22815;&#26816;&#27979;&#21508;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#65288;&#23574;&#23792;&#12289;&#19981;&#36830;&#32493;&#12289;&#36235;&#21183;&#21464;&#21270;&#31561;&#65289;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#26631;&#35760;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;TSAP&#26469;&#25191;&#34892;TSA&#8220;&#33258;&#21160;&#39550;&#39542;&#8221;&#65292;&#21487;&#20197;&#31471;&#21040;&#31471;&#33258;&#21160;&#35843;&#25972;&#25968;&#25454;&#22686;&#24378;&#30340;&#36229;&#21442;&#25968;&#65292;&#33258;&#36866;&#24212;&#36873;&#25321;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02865v1 Announce Type: new  Abstract: Time series anomaly detection (TSAD) finds many applications such as monitoring environmental sensors, industry KPIs, patient biomarkers, etc. A two-fold challenge for TSAD is a versatile and unsupervised model that can detect various different types of time series anomalies (spikes, discontinuities, trend shifts, etc.) without any labeled data. Modern neural networks have outstanding ability in modeling complex time series. Self-supervised models in particular tackle unsupervised TSAD by transforming the input via various augmentations to create pseudo anomalies for training. However, their performance is sensitive to the choice of augmentation, which is hard to choose in practice, while there exists no effort in the literature on data augmentation tuning for TSAD without labels. Our work aims to fill this gap. We introduce TSAP for TSA "on autoPilot", which can (self-)tune augmentation hyperparameters end-to-end. It stands on two key c
&lt;/p&gt;</description></item><item><title>&#23558;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#19982;&#25511;&#21046;&#29702;&#35770;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35774;&#23450;&#28857;&#26356;&#26032;&#31639;&#27861;&#65292;&#20197;&#30830;&#20445;&#23433;&#20840;&#26465;&#20214;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#20219;&#21153;&#30446;&#26631;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.01551</link><description>&lt;p&gt;
&#20855;&#26377;&#25511;&#21046;&#29702;&#35770;&#23433;&#20840;&#20445;&#35777;&#30340;&#21160;&#24577;&#32593;&#32476;&#26725;&#25509;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Reinforcement Learning with Control-Theoretic Safety Guarantees for Dynamic Network Bridging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01551
&lt;/p&gt;
&lt;p&gt;
&#23558;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#19982;&#25511;&#21046;&#29702;&#35770;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35774;&#23450;&#28857;&#26356;&#26032;&#31639;&#27861;&#65292;&#20197;&#30830;&#20445;&#23433;&#20840;&#26465;&#20214;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#20219;&#21153;&#30446;&#26631;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23433;&#20840;&#20851;&#38190;&#29615;&#22659;&#19979;&#35299;&#20915;&#22797;&#26434;&#30340;&#21512;&#20316;&#20219;&#21153;&#23545;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#25552;&#20986;&#20102;&#37325;&#22823;&#25361;&#25112;&#65292;&#23588;&#20854;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#26465;&#20214;&#19979;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#65292;&#23558;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#19982;&#25511;&#21046;&#29702;&#35770;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#30830;&#20445;&#23433;&#20840;&#21644;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#19968;&#31181;&#26032;&#39062;&#30340;&#35774;&#23450;&#28857;&#26356;&#26032;&#31639;&#27861;&#65292;&#21160;&#24577;&#35843;&#25972;&#26234;&#33021;&#20307;&#20301;&#32622;&#65292;&#20197;&#20445;&#25345;&#23433;&#20840;&#26465;&#20214;&#32780;&#19981;&#24433;&#21709;&#20219;&#21153;&#30446;&#26631;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#25105;&#20204;&#35777;&#26126;&#30456;&#27604;&#20256;&#32479;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#21183;&#65292;&#23454;&#29616;&#20102;&#19982;&#38646;&#23433;&#20840;&#36829;&#35268;&#30456;&#27604;&#21487;&#27604;&#30340;&#20219;&#21153;&#24615;&#33021;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#23433;&#20840;&#25511;&#21046;&#19982;&#23398;&#20064;&#26041;&#27861;&#30456;&#32467;&#21512;&#19981;&#20165;&#22686;&#24378;&#20102;&#23433;&#20840;&#21512;&#35268;&#24615;&#65292;&#36824;&#23454;&#29616;&#20102;&#33391;&#22909;&#30340;&#20219;&#21153;&#30446;&#26631;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01551v1 Announce Type: cross  Abstract: Addressing complex cooperative tasks in safety-critical environments poses significant challenges for Multi-Agent Systems, especially under conditions of partial observability. This work introduces a hybrid approach that integrates Multi-Agent Reinforcement Learning with control-theoretic methods to ensure safe and efficient distributed strategies. Our contributions include a novel setpoint update algorithm that dynamically adjusts agents' positions to preserve safety conditions without compromising the mission's objectives. Through experimental validation, we demonstrate significant advantages over conventional MARL strategies, achieving comparable task performance with zero safety violations. Our findings indicate that integrating safe control with learning approaches not only enhances safety compliance but also achieves good performance in mission objectives.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#22312;&#32447;&#23398;&#20064;&#21644;&#21338;&#24328;&#35770;&#20013;&#30340;&#22522;&#20934;&#20915;&#31574;&#35774;&#32622;&#65292;&#35780;&#20272;LLM&#20195;&#29702;&#30340;&#20132;&#20114;&#34892;&#20026;&#21644;&#24615;&#33021;&#65292;&#20197;&#20102;&#35299;&#23427;&#20204;&#22312;&#22810;&#20195;&#29702;&#29615;&#22659;&#20013;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.16843</link><description>&lt;p&gt;
LLM&#20195;&#29702;&#26159;&#21542;&#20250;&#24863;&#21040;&#21518;&#24724;&#65311;&#22312;&#32447;&#23398;&#20064;&#21644;&#28216;&#25103;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Do LLM Agents Have Regret? A Case Study in Online Learning and Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16843
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#22312;&#32447;&#23398;&#20064;&#21644;&#21338;&#24328;&#35770;&#20013;&#30340;&#22522;&#20934;&#20915;&#31574;&#35774;&#32622;&#65292;&#35780;&#20272;LLM&#20195;&#29702;&#30340;&#20132;&#20114;&#34892;&#20026;&#21644;&#24615;&#33021;&#65292;&#20197;&#20102;&#35299;&#23427;&#20204;&#22312;&#22810;&#20195;&#29702;&#29615;&#22659;&#20013;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#29992;&#20110;(&#20132;&#20114;&#24335;)&#20915;&#31574;&#21046;&#23450;&#65292;&#36890;&#36807;&#24320;&#21457;&#22522;&#20110;LLM&#30340;&#33258;&#20027;&#20195;&#29702;&#12290;&#23613;&#31649;&#23427;&#20204;&#21462;&#24471;&#20102;&#19981;&#26029;&#30340;&#25104;&#21151;&#65292;&#20294;LLM&#20195;&#29702;&#22312;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#34920;&#29616;&#23578;&#26410;&#36890;&#36807;&#23450;&#37327;&#25351;&#26631;&#36827;&#34892;&#20805;&#20998;&#35843;&#26597;&#65292;&#29305;&#21035;&#26159;&#22312;&#23427;&#20204;&#30456;&#20114;&#20316;&#29992;&#26102;&#30340;&#22810;&#20195;&#29702;&#35774;&#32622;&#20013;&#65292;&#36825;&#26159;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#20856;&#22411;&#22330;&#26223;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;LLM&#20195;&#29702;&#22312;&#36825;&#20123;&#20132;&#20114;&#29615;&#22659;&#20013;&#30340;&#38480;&#21046;&#65292;&#25105;&#20204;&#24314;&#35758;&#30740;&#31350;&#23427;&#20204;&#22312;&#22312;&#32447;&#23398;&#20064;&#21644;&#21338;&#24328;&#35770;&#30340;&#22522;&#20934;&#20915;&#31574;&#35774;&#32622;&#20013;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#36890;&#36807;\emph{&#21518;&#24724;}&#24615;&#33021;&#25351;&#26631;&#36827;&#34892;&#35780;&#20272;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#32463;&#20856;(&#38750;&#24179;&#31283;)&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#20013;&#32463;&#39564;&#24615;&#22320;&#30740;&#31350;LLMs&#30340;&#26080;&#21518;&#24724;&#34892;&#20026;&#65292;&#20197;&#21450;&#24403;LLM&#20195;&#29702;&#36890;&#36807;&#36827;&#34892;&#37325;&#22797;&#28216;&#25103;&#36827;&#34892;&#20132;&#20114;&#26102;&#22343;&#34913;&#30340;&#20986;&#29616;&#12290;&#28982;&#21518;&#25105;&#20204;&#23545;&#26080;&#21518;&#24724;&#34892;&#20026;&#25552;&#20379;&#19968;&#20123;&#29702;&#35770;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16843v1 Announce Type: cross  Abstract: Large language models (LLMs) have been increasingly employed for (interactive) decision-making, via the development of LLM-based autonomous agents. Despite their emerging successes, the performance of LLM agents in decision-making has not been fully investigated through quantitative metrics, especially in the multi-agent setting when they interact with each other, a typical scenario in real-world LLM-agent applications. To better understand the limits of LLM agents in these interactive environments, we propose to study their interactions in benchmark decision-making settings in online learning and game theory, through the performance metric of \emph{regret}. We first empirically study the {no-regret} behaviors of LLMs in canonical (non-stationary) online learning problems, as well as the emergence of equilibria when LLM agents interact through playing repeated games. We then provide some theoretical insights into the no-regret behavior
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36870;&#25209;&#22788;&#29702;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#65288;IBCB&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#26681;&#25454;&#19987;&#23478;&#30340;&#34892;&#20026;&#28436;&#21464;&#21382;&#21490;&#23545;&#29615;&#22659;&#22870;&#21169;&#21442;&#25968;&#21644;&#23398;&#20064;&#31574;&#30053;&#36827;&#34892;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.16075</link><description>&lt;p&gt;
IBCB: &#39640;&#25928;&#30340;&#36870;&#25209;&#22788;&#29702;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#34892;&#20026;&#28436;&#21464;&#21382;&#21490;
&lt;/p&gt;
&lt;p&gt;
IBCB: Efficient Inverse Batched Contextual Bandit for Behavioral Evolution History
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16075
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36870;&#25209;&#22788;&#29702;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#65288;IBCB&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#26681;&#25454;&#19987;&#23478;&#30340;&#34892;&#20026;&#28436;&#21464;&#21382;&#21490;&#23545;&#29615;&#22659;&#22870;&#21169;&#21442;&#25968;&#21644;&#23398;&#20064;&#31574;&#30053;&#36827;&#34892;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#27169;&#20223;&#23398;&#20064;&#20851;&#27880;&#19987;&#23478;&#30340;&#34892;&#20026;&#26426;&#21046;&#24314;&#27169;&#65292;&#38656;&#35201;&#22823;&#37327;&#30001;&#26576;&#20010;&#22266;&#23450;&#19987;&#23478;&#29983;&#25104;&#30340;&#20132;&#20114;&#21382;&#21490;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#27969;&#24335;&#24212;&#29992;&#20013;&#65292;&#22914;&#27969;&#24335;&#25512;&#33616;&#31995;&#32479;&#65292;&#22312;&#32447;&#20915;&#31574;&#32773;&#36890;&#24120;&#22312;&#20915;&#31574;&#36807;&#31243;&#20013;&#36827;&#34892;&#22312;&#32447;&#23398;&#20064;&#65292;&#36825;&#24847;&#21619;&#30528;&#22312;&#32447;&#20915;&#31574;&#32773;&#29983;&#25104;&#30340;&#20132;&#20114;&#21382;&#21490;&#21253;&#25324;&#20182;&#20204;&#20174;&#26032;&#25163;&#19987;&#23478;&#21040;&#26377;&#32463;&#39564;&#19987;&#23478;&#30340;&#34892;&#20026;&#28436;&#21464;&#12290;&#36825;&#32473;&#29616;&#26377;&#30340;&#21482;&#33021;&#21033;&#29992;&#26377;&#32463;&#39564;&#19987;&#23478;&#25968;&#25454;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#24102;&#26469;&#20102;&#26032;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36870;&#25209;&#22788;&#29702;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#65288;IBCB&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#22522;&#20110;&#19987;&#23478;&#34892;&#20026;&#28436;&#21464;&#21382;&#21490;&#30340;&#29615;&#22659;&#22870;&#21169;&#21442;&#25968;&#21644;&#23398;&#20064;&#31574;&#30053;&#30340;&#20272;&#35745;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;IBCB&#23558;&#36870;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#31616;&#21333;&#30340;&#20108;&#27425;&#35268;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16075v1 Announce Type: new  Abstract: Traditional imitation learning focuses on modeling the behavioral mechanisms of experts, which requires a large amount of interaction history generated by some fixed expert. However, in many streaming applications, such as streaming recommender systems, online decision-makers typically engage in online learning during the decision-making process, meaning that the interaction history generated by online decision-makers includes their behavioral evolution from novice expert to experienced expert. This poses a new challenge for existing imitation learning approaches that can only utilize data from experienced experts. To address this issue, this paper proposes an inverse batched contextual bandit (IBCB) framework that can efficiently perform estimations of environment reward parameters and learned policy based on the expert's behavioral evolution history. Specifically, IBCB formulates the inverse problem into a simple quadratic programming 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#27493;&#36827;&#28145;&#24230;&#26799;&#24230;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#65288;&#31895;&#31961;&#65289;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#26399;&#26435;&#23450;&#20215;&#38382;&#39064;&#65292;&#20445;&#35777;&#20102;&#23545;&#22823;&#37329;&#39069;&#27700;&#24179;&#19979;&#26399;&#26435;&#20215;&#26684;&#30340;&#28176;&#36817;&#34892;&#20026;&#21644;&#20808;&#39564;&#19978;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.00746</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#65288;&#31895;&#31961;&#65289;&#25193;&#25955;&#27169;&#22411;&#20013;&#26399;&#26435;&#23450;&#20215;&#30340;&#26102;&#38388;&#27493;&#36827;&#28145;&#24230;&#26799;&#24230;&#27969;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A time-stepping deep gradient flow method for option pricing in (rough) diffusion models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00746
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#27493;&#36827;&#28145;&#24230;&#26799;&#24230;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#65288;&#31895;&#31961;&#65289;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#26399;&#26435;&#23450;&#20215;&#38382;&#39064;&#65292;&#20445;&#35777;&#20102;&#23545;&#22823;&#37329;&#39069;&#27700;&#24179;&#19979;&#26399;&#26435;&#20215;&#26684;&#30340;&#28176;&#36817;&#34892;&#20026;&#21644;&#20808;&#39564;&#19978;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#25193;&#25955;&#27169;&#22411;&#20013;&#23450;&#20215;&#27431;&#24335;&#26399;&#26435;&#65292;&#21487;&#20197;&#39640;&#25928;&#22788;&#29702;&#30001;&#20110;&#31895;&#31961;&#27874;&#21160;&#29575;&#27169;&#22411;&#30340;&#39532;&#23572;&#21487;&#22827;&#36924;&#36817;&#32780;&#23548;&#33268;&#30340;&#39640;&#32500;&#38382;&#39064;&#12290;&#26399;&#26435;&#23450;&#20215;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#34987;&#37325;&#26032;&#34920;&#36848;&#20026;&#33021;&#37327;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#36890;&#36807;&#28145;&#24230;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20197;&#26102;&#38388;&#27493;&#36827;&#30340;&#26041;&#24335;&#36827;&#34892;&#36817;&#20284;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#26696;&#31526;&#21512;&#26399;&#26435;&#20215;&#26684;&#22312;&#22823;&#37329;&#39069;&#27700;&#24179;&#19978;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#36981;&#23432;&#26399;&#26435;&#20215;&#26684;&#30340;&#20808;&#39564;&#24050;&#30693;&#19978;&#19979;&#30028;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#25968;&#20540;&#31034;&#20363;&#35780;&#20272;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;&#25552;&#21319;Heston&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00746v1 Announce Type: cross  Abstract: We develop a novel deep learning approach for pricing European options in diffusion models, that can efficiently handle high-dimensional problems resulting from Markovian approximations of rough volatility models. The option pricing partial differential equation is reformulated as an energy minimization problem, which is approximated in a time-stepping fashion by deep artificial neural networks. The proposed scheme respects the asymptotic behavior of option prices for large levels of moneyness, and adheres to a priori known bounds for option prices. The accuracy and efficiency of the proposed method is assessed in a series of numerical examples, with particular focus in the lifted Heston model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#32422;&#26463;&#31639;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#32465;&#23450;&#26368;&#23567;&#21644;&#26368;&#22823;&#25928;&#29992;&#20540;&#26469;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#28857;&#24182;&#20002;&#24323;&#19981;&#37325;&#35201;&#30340;&#28857;&#12290;</title><link>https://arxiv.org/abs/2402.16442</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#37197;&#23545;&#27425;&#27169;&#27169;&#20989;&#25968;&#30340;&#20998;&#24067;&#24335;&#22823;&#20110;&#20869;&#23384;&#30340;&#23376;&#38598;&#36873;&#25321;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#32422;&#26463;&#31639;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#32465;&#23450;&#26368;&#23567;&#21644;&#26368;&#22823;&#25928;&#29992;&#20540;&#26469;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#28857;&#24182;&#20002;&#24323;&#19981;&#37325;&#35201;&#30340;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#23398;&#20064;&#38382;&#39064;&#21462;&#20915;&#20110;&#23376;&#38598;&#36873;&#25321;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#30830;&#23450;&#19968;&#32452;&#37325;&#35201;&#21644;&#20195;&#34920;&#24615;&#30340;&#28857;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#21487;&#35777;&#20272;&#35745;&#36817;&#20284;&#20445;&#35777;&#30340;&#26032;&#39062;&#20998;&#24067;&#24335;&#32422;&#26463;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#36845;&#20195;&#32465;&#23450;&#26368;&#23567;&#21644;&#26368;&#22823;&#25928;&#29992;&#20540;&#26469;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#28857;&#24182;&#20002;&#24323;&#19981;&#37325;&#35201;&#30340;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16442v1 Announce Type: cross  Abstract: Many learning problems hinge on the fundamental problem of subset selection, i.e., identifying a subset of important and representative points. For example, selecting the most significant samples in ML training cannot only reduce training costs but also enhance model quality. Submodularity, a discrete analogue of convexity, is commonly used for solving subset selection problems. However, existing algorithms for optimizing submodular functions are sequential, and the prior distributed methods require at least one central machine to fit the target subset. In this paper, we relax the requirement of having a central machine for the target subset by proposing a novel distributed bounding algorithm with provable approximation guarantees. The algorithm iteratively bounds the minimum and maximum utility values to select high quality points and discard the unimportant ones. When bounding does not find the complete subset, we use a multi-round, 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37325;&#26032;&#24605;&#32771;&#20102;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#21644;&#26550;&#26500;&#65292;&#36890;&#36807;&#32463;&#39564;&#30740;&#31350;&#21457;&#29616;&#20102;&#22312;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#29305;&#21035;&#26377;&#25928;&#30340;&#35774;&#35745;&#20844;&#24335;&#65292;&#24182;&#22312;&#22810;&#35821;&#31181;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#39640;&#24615;&#33021;&#30340;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.02791</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#21644;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Rethinking Optimization and Architecture for Tiny Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#26032;&#24605;&#32771;&#20102;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#21644;&#26550;&#26500;&#65292;&#36890;&#36807;&#32463;&#39564;&#30740;&#31350;&#21457;&#29616;&#20102;&#22312;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#29305;&#21035;&#26377;&#25928;&#30340;&#35774;&#35745;&#20844;&#24335;&#65292;&#24182;&#22312;&#22810;&#35821;&#31181;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#39640;&#24615;&#33021;&#30340;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23041;&#21147;&#36890;&#36807;&#22823;&#37327;&#30340;&#25968;&#25454;&#21644;&#35745;&#31639;&#36164;&#28304;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#28982;&#32780;&#65292;&#22312;&#31227;&#21160;&#35774;&#22791;&#19978;&#24212;&#29992;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30528;&#35745;&#31639;&#21644;&#20869;&#23384;&#25104;&#26412;&#30340;&#24040;&#22823;&#25361;&#25112;&#65292;&#36843;&#20999;&#38656;&#35201;&#39640;&#24615;&#33021;&#30340;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#21463;&#22797;&#26434;&#35757;&#32451;&#36807;&#31243;&#30340;&#38480;&#21046;&#65292;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#35768;&#22810;&#32454;&#33410;&#24456;&#23569;&#24471;&#21040;&#20180;&#32454;&#30740;&#31350;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#22522;&#20110;&#19968;&#20010;&#20855;&#26377;10&#20159;&#21442;&#25968;&#30340;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#20180;&#32454;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#32463;&#39564;&#30740;&#31350;&#26469;&#20998;&#26512;&#27599;&#20010;&#32452;&#20214;&#30340;&#24433;&#21709;&#12290;&#20027;&#35201;&#35752;&#35770;&#20102;&#19977;&#20010;&#26041;&#38754;&#65292;&#21363;&#31070;&#32463;&#26550;&#26500;&#12289;&#21442;&#25968;&#21021;&#22987;&#21270;&#21644;&#20248;&#21270;&#31574;&#30053;&#12290;&#22810;&#20010;&#35774;&#35745;&#20844;&#24335;&#22312;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32463;&#39564;&#24615;&#22320;&#34987;&#35777;&#26126;&#29305;&#21035;&#26377;&#25928;&#65292;&#21253;&#25324;&#20998;&#35789;&#22120;&#21387;&#32553;&#12289;&#26550;&#26500;&#35843;&#25972;&#12289;&#21442;&#25968;&#32487;&#25215;&#21644;&#22810;&#36718;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;1.6T&#22810;&#35821;&#31181;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;PanGu-$\pi$-1B Pro&#21644;PanGu-$\pi$-1.5B Pro&#12290;
&lt;/p&gt;
&lt;p&gt;
The power of large language models (LLMs) has been demonstrated through numerous data and computing resources. However, the application of language models on mobile devices is facing huge challenge on the computation and memory costs, that is, tiny language models with high performance are urgently required. Limited by the highly complex training process, there are many details for optimizing language models that are seldom studied carefully. In this study, based on a tiny language model with 1B parameters, we carefully design a series of empirical study to analyze the effect of each component. Three perspectives are mainly discussed, i.e., neural architecture, parameter initialization, and optimization strategy. Several design formulas are empirically proved especially effective for tiny language models, including tokenizer compression, architecture tweaking, parameter inheritance and multiple-round training. Then we train PanGu-$\pi$-1B Pro and PanGu-$\pi$-1.5B Pro on 1.6T multilingu
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPMs&#65289;&#29983;&#25104;&#26032;&#29305;&#24449;&#32452;&#21512;&#30340;&#22270;&#20687;&#65292;&#21487;&#20197;&#22312;&#38598;&#25104;&#27169;&#22411;&#20013;&#22686;&#21152;&#27169;&#22411;&#22810;&#26679;&#24615;&#65292;&#24182;&#20943;&#36731;&#25463;&#24452;&#20559;&#35265;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30417;&#30563;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2311.16176</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#26679;&#21270;&#21512;&#25104;&#21644;&#25193;&#25955;&#27169;&#22411;&#20943;&#36731;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Mitigating Biases with Diverse Ensembles and Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16176
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPMs&#65289;&#29983;&#25104;&#26032;&#29305;&#24449;&#32452;&#21512;&#30340;&#22270;&#20687;&#65292;&#21487;&#20197;&#22312;&#38598;&#25104;&#27169;&#22411;&#20013;&#22686;&#21152;&#27169;&#22411;&#22810;&#26679;&#24615;&#65292;&#24182;&#20943;&#36731;&#25463;&#24452;&#20559;&#35265;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30417;&#30563;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#65292;&#21363;&#22810;&#20010;&#32447;&#32034;&#21487;&#20197;&#39044;&#27979;&#30446;&#26631;&#26631;&#31614;&#65292;&#24120;&#24120;&#23548;&#33268;&#19968;&#31181;&#31216;&#20026;&#25463;&#24452;&#20559;&#35265;&#30340;&#29616;&#35937;&#65292;&#21363;&#27169;&#22411;&#20381;&#36182;&#20110;&#38169;&#35823;&#30340;&#12289;&#26131;&#23398;&#30340;&#32447;&#32034;&#65292;&#32780;&#24573;&#30053;&#21487;&#38752;&#30340;&#32447;&#32034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPMs&#65289;&#30340;&#38598;&#25104;&#22810;&#26679;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#20943;&#36731;&#25463;&#24452;&#20559;&#35265;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#29305;&#23450;&#30340;&#35757;&#32451;&#38388;&#38548;&#20013;&#65292;DPMs&#21487;&#20197;&#29983;&#25104;&#20855;&#26377;&#26032;&#29305;&#24449;&#32452;&#21512;&#30340;&#22270;&#20687;&#65292;&#21363;&#20351;&#22312;&#26174;&#31034;&#30456;&#20851;&#36755;&#20837;&#29305;&#24449;&#30340;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#20851;&#38190;&#23646;&#24615;&#36890;&#36807;&#38598;&#25104;&#19981;&#19968;&#33268;&#24615;&#29983;&#25104;&#21512;&#25104;&#21453;&#20107;&#23454;&#26469;&#22686;&#21152;&#27169;&#22411;&#30340;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;DPM&#24341;&#23548;&#30340;&#22810;&#26679;&#21270;&#36275;&#20197;&#28040;&#38500;&#23545;&#20027;&#35201;&#25463;&#24452;&#32447;&#32034;&#30340;&#20381;&#36182;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#30417;&#30563;&#20449;&#21495;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#22312;&#20960;&#20010;&#22810;&#26679;&#21270;&#30446;&#26631;&#19978;&#22312;&#23454;&#35777;&#19978;&#37327;&#21270;&#20854;&#26377;&#25928;&#24615;&#65292;&#24182;&#26368;&#32456;&#23637;&#31034;&#20102;&#25913;&#36827;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.16176v2 Announce Type: replace-cross  Abstract: Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to a phenomenon known as shortcut bias, where a model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting Diffusion Probabilistic Models (DPMs) for shortcut bias mitigation. We show that at particular training intervals, DPMs can generate images with novel feature combinations, even when trained on samples displaying correlated input features. We leverage this crucial property to generate synthetic counterfactuals to increase model diversity via ensemble disagreement. We show that DPM-guided diversification is sufficient to remove dependence on primary shortcut cues, without a need for additional supervised signals. We further empirically quantify its efficacy on several diversification objectives, and finally show improved generalizati
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#20294;&#20855;&#26377;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#20960;&#20046;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#22312;&#25311;&#21512;&#36807;&#31243;&#20013;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#37327;&#26469;&#32553;&#25918;&#27169;&#22411;&#31995;&#25968;&#65292;&#24182;&#26368;&#23567;&#21270;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2401.15610</link><description>&lt;p&gt;
&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#26159;&#39640;&#32500;&#25968;&#25454;&#20013;&#36923;&#36753;&#22238;&#24402;&#30340;&#39640;&#25928;&#26367;&#20195;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prevalidated ridge regression is a highly-efficient drop-in replacement for logistic regression for high-dimensional data. (arXiv:2401.15610v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15610
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#20294;&#20855;&#26377;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#20960;&#20046;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#22312;&#25311;&#21512;&#36807;&#31243;&#20013;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#37327;&#26469;&#32553;&#25918;&#27169;&#22411;&#31995;&#25968;&#65292;&#24182;&#26368;&#23567;&#21270;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#27010;&#29575;&#20998;&#31867;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36923;&#36753;&#22238;&#24402;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#20180;&#32454;&#19988;&#30456;&#23545;&#35745;&#31639;&#23494;&#38598;&#30340;&#35843;&#20248;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#65292;&#24182;&#19988;&#23588;&#20854;&#22312;&#39640;&#32500;&#25968;&#25454;&#30340;&#32972;&#26223;&#19979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#20998;&#31867;&#38169;&#35823;&#21644;&#23545;&#25968;&#25439;&#22833;&#26041;&#38754;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#65292;&#21516;&#26102;&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#26126;&#26174;&#26356;&#39640;&#65292;&#24182;&#19988;&#38500;&#20102;&#27491;&#21017;&#21270;&#20043;&#22806;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#32553;&#25918;&#27169;&#22411;&#30340;&#31995;&#25968;&#26469;&#26368;&#23567;&#21270;&#30001;&#20272;&#35745;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#35823;&#24046;&#25512;&#23548;&#20986;&#30340;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;&#36825;&#21033;&#29992;&#20102;&#22312;&#25311;&#21512;&#23725;&#22238;&#24402;&#27169;&#22411;&#36807;&#31243;&#20013;&#24050;&#32463;&#35745;&#31639;&#30340;&#25968;&#37327;&#65292;&#20197;&#25214;&#21040;&#20855;&#26377;&#21517;&#20041;&#38468;&#21152;&#35745;&#31639;&#24320;&#38144;&#30340;&#32553;&#25918;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Logistic regression is a ubiquitous method for probabilistic classification. However, the effectiveness of logistic regression depends upon careful and relatively computationally expensive tuning, especially for the regularisation hyperparameter, and especially in the context of high-dimensional data. We present a prevalidated ridge regression model that closely matches logistic regression in terms of classification error and log-loss, particularly for high-dimensional data, while being significantly more computationally efficient and having effectively no hyperparameters beyond regularisation. We scale the coefficients of the model so as to minimise log-loss for a set of prevalidated predictions derived from the estimated leave-one-out cross-validation error. This exploits quantities already computed in the course of fitting the ridge regression model in order to find the scaling parameter with nominal additional computational expense.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#24378;&#21270;&#30340;&#31070;&#32463;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#28789;&#27963;&#22320;&#32531;&#35299;&#37327;&#23376;&#36807;&#31243;&#20013;&#30340;&#21508;&#31181;&#22122;&#22768;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#19981;&#21516;&#31867;&#22411;&#37327;&#23376;&#36807;&#31243;&#20013;&#19982;&#20808;&#21069;&#26041;&#27861;&#30456;&#27604;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.01727</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#24378;&#21270;&#30340;&#31070;&#32463;&#27169;&#22411;&#23545;&#37327;&#23376;&#36807;&#31243;&#36827;&#34892;&#28789;&#27963;&#30340;&#35823;&#24046;&#32531;&#35299;
&lt;/p&gt;
&lt;p&gt;
Flexible Error Mitigation of Quantum Processes with Data Augmentation Empowered Neural Model. (arXiv:2311.01727v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01727
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#24378;&#21270;&#30340;&#31070;&#32463;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#28789;&#27963;&#22320;&#32531;&#35299;&#37327;&#23376;&#36807;&#31243;&#20013;&#30340;&#21508;&#31181;&#22122;&#22768;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#19981;&#21516;&#31867;&#22411;&#37327;&#23376;&#36807;&#31243;&#20013;&#19982;&#20808;&#21069;&#26041;&#27861;&#30456;&#27604;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#37327;&#23376;&#35745;&#31639;&#30340;&#21508;&#31181;&#20219;&#21153;&#20013;&#26174;&#31034;&#20986;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#37327;&#23376;&#35823;&#24046;&#32531;&#35299;&#20013;&#30340;&#24212;&#29992;&#21463;&#21040;&#23545;&#26080;&#22122;&#22768;&#32479;&#35745;&#30340;&#20381;&#36182;&#38480;&#21046;&#65292;&#36825;&#26159;&#23454;&#29616;&#23454;&#38469;&#37327;&#23376;&#36827;&#23637;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#20851;&#38190;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#24378;&#21270;&#30340;&#31070;&#32463;&#27169;&#22411;&#29992;&#20110;&#35823;&#24046;&#32531;&#35299;&#65288;DAEM&#65289;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#19981;&#38656;&#35201;&#20219;&#20309;&#20851;&#20110;&#29305;&#23450;&#22122;&#22768;&#31867;&#22411;&#21644;&#27979;&#37327;&#35774;&#32622;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#19988;&#21487;&#20197;&#20165;&#26681;&#25454;&#30446;&#26631;&#37327;&#23376;&#36807;&#31243;&#30340;&#22122;&#22768;&#27979;&#37327;&#32467;&#26524;&#20272;&#35745;&#26080;&#22122;&#22768;&#32479;&#35745;&#20540;&#65292;&#20351;&#20854;&#38750;&#24120;&#36866;&#21512;&#23454;&#38469;&#23454;&#26045;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#27169;&#22411;&#22312;&#32531;&#35299;&#21508;&#31181;&#31867;&#22411;&#30340;&#22122;&#22768;&#65288;&#21253;&#25324;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#21644;&#38750;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#65289;&#26041;&#38754;&#19982;&#20808;&#21069;&#30340;&#35823;&#24046;&#32531;&#35299;&#26041;&#27861;&#30456;&#27604;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#21033;&#29992;&#35813;&#27169;&#22411;&#26469;&#32531;&#35299;&#22810;&#31181;&#31867;&#22411;&#30340;&#37327;&#23376;&#36807;&#31243;&#20013;&#30340;&#38169;&#35823;&#26469;&#23637;&#31034;&#20854;&#22810;&#21151;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks have shown their effectiveness in various tasks in the realm of quantum computing. However, their application in quantum error mitigation, a crucial step towards realizing practical quantum advancements, has been restricted by reliance on noise-free statistics. To tackle this critical challenge, we propose a data augmentation empowered neural model for error mitigation (DAEM). Our model does not require any prior knowledge about the specific noise type and measurement settings and can estimate noise-free statistics solely from the noisy measurement results of the target quantum process, rendering it highly suitable for practical implementation. In numerical experiments, we show the model's superior performance in mitigating various types of noise, including Markovian noise and Non-Markovian noise, compared with previous error mitigation methods. We further demonstrate its versatility by employing the model to mitigate errors in diverse types of quantum processes, includ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38381;&#21512;&#24418;&#24335;&#30340;&#26041;&#27861;LEACE&#65292;&#21487;&#22312;&#21024;&#38500;&#25351;&#23450;&#29305;&#24449;&#30340;&#21516;&#26102;&#23613;&#21487;&#33021;&#23569;&#22320;&#25913;&#21464;&#34920;&#31034;&#65292;&#24182;&#21487;&#35777;&#26126;&#38450;&#27490;&#25152;&#26377;&#32447;&#24615;&#20998;&#31867;&#22120;&#26816;&#27979;&#21040;&#27010;&#24565;&#12290;&#20316;&#32773;&#29992;&#8220;&#27010;&#24565;&#25830;&#38500;&#8221;&#36825;&#19968;&#26032;&#26041;&#27861;&#23558;&#20854;&#24212;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#27979;&#37327;&#35821;&#35328;&#27169;&#22411;&#23545;&#35789;&#24615;&#30340;&#20381;&#36182;&#24615;&#21644;&#20943;&#23569;BERT&#23884;&#20837;&#20013;&#30340;&#24615;&#21035;&#20559;&#24046;&#20219;&#21153;&#20013;&#24471;&#20986;&#33391;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.03819</link><description>&lt;p&gt;
LEACE&#65306;&#38381;&#21512;&#24418;&#24335;&#20013;&#30340;&#23436;&#32654;&#32447;&#24615;&#27010;&#24565;&#25830;&#38500;
&lt;/p&gt;
&lt;p&gt;
LEACE: Perfect linear concept erasure in closed form. (arXiv:2306.03819v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38381;&#21512;&#24418;&#24335;&#30340;&#26041;&#27861;LEACE&#65292;&#21487;&#22312;&#21024;&#38500;&#25351;&#23450;&#29305;&#24449;&#30340;&#21516;&#26102;&#23613;&#21487;&#33021;&#23569;&#22320;&#25913;&#21464;&#34920;&#31034;&#65292;&#24182;&#21487;&#35777;&#26126;&#38450;&#27490;&#25152;&#26377;&#32447;&#24615;&#20998;&#31867;&#22120;&#26816;&#27979;&#21040;&#27010;&#24565;&#12290;&#20316;&#32773;&#29992;&#8220;&#27010;&#24565;&#25830;&#38500;&#8221;&#36825;&#19968;&#26032;&#26041;&#27861;&#23558;&#20854;&#24212;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22312;&#27979;&#37327;&#35821;&#35328;&#27169;&#22411;&#23545;&#35789;&#24615;&#30340;&#20381;&#36182;&#24615;&#21644;&#20943;&#23569;BERT&#23884;&#20837;&#20013;&#30340;&#24615;&#21035;&#20559;&#24046;&#20219;&#21153;&#20013;&#24471;&#20986;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#24565;&#25830;&#38500;&#26088;&#22312;&#20174;&#34920;&#24449;&#20013;&#21024;&#38500;&#25351;&#23450;&#30340;&#29305;&#24449;&#12290;&#23427;&#21487;&#20197;&#25552;&#39640;&#20844;&#24179;&#24615;&#65288;&#20363;&#22914;&#65292;&#38450;&#27490;&#20998;&#31867;&#22120;&#20351;&#29992;&#24615;&#21035;&#25110;&#31181;&#26063;&#65289;&#21644;&#21487;&#35299;&#37322;&#24615;&#65288;&#20363;&#22914;&#65292;&#21024;&#38500;&#27010;&#24565;&#20197;&#35266;&#23519;&#27169;&#22411;&#34892;&#20026;&#30340;&#21464;&#21270;&#65289;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;LEAst-squares&#27010;&#24565;&#25830;&#38500;&#65288;LEACE&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#38381;&#21512;&#24418;&#24335;&#30340;&#26041;&#27861;&#65292;&#21487;&#35777;&#26126;&#38450;&#27490;&#25152;&#26377;&#32447;&#24615;&#20998;&#31867;&#22120;&#26816;&#27979;&#21040;&#27010;&#24565;&#65292;&#21516;&#26102;&#23613;&#21487;&#33021;&#22320;&#25913;&#21464;&#34920;&#31034;&#65292;&#22914;&#24191;&#27867;&#31867;&#21035;&#30340;&#33539;&#25968;&#25152;&#27979;&#37327;&#30340;&#37027;&#26679;&#12290;&#25105;&#20204;&#20351;&#29992;&#21517;&#20026;&#8220;&#27010;&#24565;&#25830;&#38500;&#8221;&#30340;&#26032;&#26041;&#27861;&#23558;LEACE&#24212;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25830;&#38500;&#27599;&#20010;&#23618;&#20013;&#30340;&#30446;&#26631;&#27010;&#24565;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65306;&#27979;&#37327;&#35821;&#35328;&#27169;&#22411;&#23545;&#35789;&#24615;&#20449;&#24687;&#30340;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#20943;&#23569;BERT&#23884;&#20837;&#20013;&#30340;&#24615;&#21035;&#20559;&#24046;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/EleutherAI/concept-erasure&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Concept erasure aims to remove specified features from a representation. It can improve fairness (e.g. preventing a classifier from using gender or race) and interpretability (e.g. removing a concept to observe changes in model behavior). We introduce LEAst-squares Concept Erasure (LEACE), a closed-form method which provably prevents all linear classifiers from detecting a concept while changing the representation as little as possible, as measured by a broad class of norms. We apply LEACE to large language models with a novel procedure called "concept scrubbing," which erases target concept information from every layer in the network. We demonstrate our method on two tasks: measuring the reliance of language models on part-of-speech information, and reducing gender bias in BERT embeddings. Code is available at https://github.com/EleutherAI/concept-erasure.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2305.10015</link><description>&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#25928;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Utility Theory of Synthetic Data Generation. (arXiv:2305.10015v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#30340;&#25928;&#29992;&#23545;&#20110;&#34913;&#37327;&#21512;&#25104;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#32467;&#26524;&#20391;&#37325;&#20110;&#23545;&#21512;&#25104;&#25968;&#25454;&#25928;&#29992;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#32780;&#38024;&#23545;&#21512;&#25104;&#25968;&#25454;&#31639;&#27861;&#22914;&#20309;&#24433;&#21709;&#25928;&#29992;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#12290;&#35813;&#25351;&#26631;&#23450;&#20041;&#20026;&#22312;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#20043;&#38388;&#27867;&#21270;&#30340;&#32477;&#23545;&#24046;&#24322;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35813;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#26469;&#30740;&#31350;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#12290;&#19968;&#20010;&#26377;&#36259;&#30340;&#32467;&#26524;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#21017;&#35813;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;&#21478;&#19968;&#20010;&#37325;&#35201;&#30340;&#25928;&#29992;&#25351;&#26631;&#22522;&#20110;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#20043;&#38388;&#28508;&#22312;&#30340;&#22240;&#26524;&#26426;&#21046;&#19968;&#33268;&#24615;&#12290;&#35813;&#29702;&#35770;&#20351;&#29992;&#20960;&#31181;&#21512;&#25104;&#31639;&#27861;&#36827;&#34892;&#35828;&#26126;&#65292;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#25928;&#29992;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating the utility of synthetic data is critical for measuring the effectiveness and efficiency of synthetic algorithms. Existing results focus on empirical evaluations of the utility of synthetic data, whereas the theoretical understanding of how utility is affected by synthetic data algorithms remains largely unexplored. This paper establishes utility theory from a statistical perspective, aiming to quantitatively assess the utility of synthetic algorithms based on a general metric. The metric is defined as the absolute difference in generalization between models trained on synthetic and original datasets. We establish analytical bounds for this utility metric to investigate critical conditions for the metric to converge. An intriguing result is that the synthetic feature distribution is not necessarily identical to the original one for the convergence of the utility metric as long as the model specification in downstream learning tasks is correct. Another important utility metri
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#65292;&#29992;&#20110;&#27714;&#35299;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#36895;&#24230;&#24555;&#19988;&#31616;&#21333;&#26131;&#34892;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.09046</link><description>&lt;p&gt;
&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Convex optimization over a probability simplex. (arXiv:2305.09046v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09046
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#65292;&#29992;&#20110;&#27714;&#35299;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#36895;&#24230;&#24555;&#19988;&#31616;&#21333;&#26131;&#34892;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#8212;&#8212;&#26607;&#35199;&#21333;&#32431;&#24418;&#26469;&#20248;&#21270;&#20984;&#38382;&#39064;&#65292;&#20351;&#20854;&#28385;&#36275;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#38480;&#21046;&#26465;&#20214;&#65292;&#21363;$w\in\mathbb{R}^n$&#20013;$\sum_i w_i=1$&#65292;$w_i\geq0$&#12290;&#25105;&#20204;&#23558;&#21333;&#32431;&#24418;&#26144;&#23556;&#21040;&#21333;&#20301;&#29699;&#30340;&#27491;&#22235;&#38754;&#20307;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#33719;&#24471;&#38544;&#21464;&#37327;&#30340;&#35299;&#65292;&#24182;&#23558;&#32467;&#26524;&#26144;&#23556;&#22238;&#21407;&#22987;&#21464;&#37327;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#39640;&#32500;&#38382;&#39064;&#65292;&#27599;&#27425;&#36845;&#20195;&#30001;&#31616;&#21333;&#30340;&#25805;&#20316;&#32452;&#25104;&#65292;&#19988;&#38024;&#23545;&#20984;&#20989;&#25968;&#35777;&#26126;&#20102;&#25910;&#25947;&#36895;&#24230;&#20026;${O}(1/T)$&#12290;&#21516;&#26102;&#26412;&#25991;&#20851;&#27880;&#20102;&#20449;&#24687;&#29702;&#35770;&#65288;&#22914;&#20132;&#21449;&#29109;&#21644;KL&#25955;&#24230;&#65289;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new iteration scheme, the Cauchy-Simplex, to optimize convex problems over the probability simplex $\{w\in\mathbb{R}^n\ |\ \sum_i w_i=1\ \textrm{and}\ w_i\geq0\}$. Other works have taken steps to enforce positivity or unit normalization automatically but never simultaneously within a unified setting. This paper presents a natural framework for manifestly requiring the probability condition. Specifically, we map the simplex to the positive quadrant of a unit sphere, envisage gradient descent in latent variables, and map the result back in a way that only depends on the simplex variable. Moreover, proving rigorous convergence results in this formulation leads inherently to tools from information theory (e.g. cross entropy and KL divergence). Each iteration of the Cauchy-Simplex consists of simple operations, making it well-suited for high-dimensional problems. We prove that it has a convergence rate of ${O}(1/T)$ for convex functions, and numerical experiments of projection 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#36890;&#29992;&#39640;&#25928;&#35757;&#32451;&#33539;&#24335;&#65292;&#29992;&#20110;&#22810;&#20219;&#21153;&#31070;&#32463;&#27714;&#35299;&#22120;&#30340;&#35757;&#32451;&#65292;&#36890;&#36807;&#20219;&#21153;&#24433;&#21709;&#30697;&#38453;&#36827;&#34892;&#26356;&#39640;&#25928;&#30340;&#35757;&#32451;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#35745;&#21010;&#65292;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#39044;&#31639;&#25110;&#30456;&#21516;&#30340;&#35757;&#32451;&#26102;&#38271;&#20869;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#25972;&#20307;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.06361</link><description>&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#26426;&#29992;&#20110;&#22810;&#20219;&#21153;&#31070;&#32463;&#27714;&#35299;&#22120;&#30340;&#39640;&#25928;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Efficient Training of Multi-task Neural Solver with Multi-armed Bandits. (arXiv:2305.06361v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#36890;&#29992;&#39640;&#25928;&#35757;&#32451;&#33539;&#24335;&#65292;&#29992;&#20110;&#22810;&#20219;&#21153;&#31070;&#32463;&#27714;&#35299;&#22120;&#30340;&#35757;&#32451;&#65292;&#36890;&#36807;&#20219;&#21153;&#24433;&#21709;&#30697;&#38453;&#36827;&#34892;&#26356;&#39640;&#25928;&#30340;&#35757;&#32451;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#35745;&#21010;&#65292;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#39044;&#31639;&#25110;&#30456;&#21516;&#30340;&#35757;&#32451;&#26102;&#38271;&#20869;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#25972;&#20307;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#22914;&#20309;&#39640;&#25928;&#22320;&#20026;&#21508;&#31181;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064; (COP) &#35757;&#32451;&#22810;&#20219;&#21153;&#31070;&#32463;&#27714;&#35299;&#22120;&#65292;&#30446;&#21069;&#30340;&#30740;&#31350;&#30456;&#23545;&#36739;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#36890;&#29992;&#39640;&#25928;&#35757;&#32451;&#33539;&#24335;&#65292;&#20197;&#25552;&#20379;&#19968;&#20010;&#32479;&#19968;&#30340;&#22810;&#20219;&#21153;&#31070;&#32463;&#27714;&#35299;&#22120;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#21033;&#29992;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#26694;&#26550;&#19979;&#30340;&#22810;&#20219;&#21153;&#29702;&#35770;&#25439;&#22833;&#20998;&#35299;&#65292;&#36890;&#36807;&#19968;&#20010;&#20219;&#21153;&#24433;&#21709;&#30697;&#38453;&#36890;&#36807;&#27491;&#30830;&#30340;&#36172;&#21338;&#31639;&#27861;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#35757;&#32451;&#12290;&#30456;&#27604;&#26631;&#20934;&#30340;&#35757;&#32451;&#35745;&#21010;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#39044;&#31639;&#25110;&#30456;&#21516;&#30340;&#35757;&#32451;&#26102;&#27573;&#20869;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#25972;&#20307;&#24615;&#33021;&#65292;&#36825;&#21487;&#20197;&#20026;&#20854;&#20182;&#22810;&#20219;&#21153;&#22823;&#27169;&#22411;&#30340;&#39640;&#25928;&#35757;&#32451;&#25552;&#20379;&#25351;&#23548;&#65292;&#27492;&#22806;&#65292;&#24433;&#21709;&#30697;&#38453;&#21487;&#20197;&#25552;&#20379;&#23398;&#20064;&#20248;&#21270;&#39046;&#22495;&#20013;&#24120;&#35265;&#23454;&#36341;&#30340;&#32463;&#39564;&#35777;&#25454;&#65292;&#20174;&#32780;&#25903;&#25345;&#25105;&#20204;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficiently training a multi-task neural solver for various combinatorial optimization problems (COPs) has been less studied so far. In this paper, we propose a general and efficient training paradigm based on multi-armed bandits to deliver a unified multi-task neural solver. To this end, we resort to the theoretical loss decomposition for multiple tasks under an encoder-decoder framework, which enables more efficient training via proper bandit task-sampling algorithms through an intra-task influence matrix. Our method achieves much higher overall performance with either limited training budgets or the same training epochs, compared to standard training schedules, which can be promising for advising efficient training of other multi-task large models. Additionally, the influence matrix can provide empirical evidence of some common practices in the area of learning to optimize, which in turn supports the validity of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#26041;&#27861;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#21487;&#20197;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.03069</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#19982;&#26041;&#27861;&#30697;&#31227;&#21160;&#20272;&#35745;&#22120;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series. (arXiv:2304.03069v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#26041;&#27861;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#21487;&#20197;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#30340;&#26102;&#38388;&#24207;&#21015;&#36890;&#24120;&#26159;&#38750;&#24179;&#31283;&#30340;&#65292;&#36825;&#24102;&#26469;&#20102;&#27169;&#22411;&#36866;&#24212;&#30340;&#38590;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;GARCH&#20551;&#23450;&#20219;&#24847;&#31867;&#22411;&#30340;&#20381;&#36182;&#24615;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#20559;&#24046;&#65292;&#25105;&#20204;&#23558;&#30528;&#30524;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#19981;&#21487;&#30693;&#30340;&#31227;&#21160;&#20272;&#35745;&#22120;&#21746;&#23398;&#65306;&#22312;&#26102;&#38388;$t$&#25214;&#21040;&#20248;&#21270;$F_t=\sum_{\tau&lt;t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$&#31227;&#21160;&#23545;&#25968;&#20284;&#28982;&#30340;&#21442;&#25968;&#65292;&#38543;&#26102;&#38388;&#28436;&#21270;&#12290;&#20363;&#22914;&#65292;&#23427;&#20801;&#35768;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#65292;&#20363;&#22914;&#32477;&#23545;&#20013;&#24515;&#30697;$E[|x-\mu|^p]$&#38543;$p\in\mathbb{R}^+$&#30340;&#21464;&#21270;&#32780;&#28436;&#21270;$m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$&#12290;&#36825;&#31181;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#30340;&#24212;&#29992;&#23558;&#21576;&#29616;&#22312;&#23398;&#29983;t&#20998;&#24067;&#19978;&#65292;&#23588;&#20854;&#26159;&#22312;&#32463;&#27982;&#24212;&#29992;&#20013;&#27969;&#34892;&#65292;&#36825;&#37324;&#24212;&#29992;&#20110;DJIA&#20844;&#21496;&#30340;&#23545;&#25968;&#25910;&#30410;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The real life time series are usually nonstationary, bringing a difficult question of model adaptation. Classical approaches like GARCH assume arbitrary type of dependence. To prevent such bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $F_t=\sum_{\tau&lt;t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$ moving log-likelihood, evolving in time. It allows for example to estimate parameters using inexpensive exponential moving averages (EMA), like absolute central moments $E[|x-\mu|^p]$ evolving with $m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$ for one or multiple powers $p\in\mathbb{R}^+$. Application of such general adaptive methods of moments will be presented on Student's t-distribution, popular especially in economical applications, here applied to log-returns of DJIA companies.
&lt;/p&gt;</description></item></channel></rss>