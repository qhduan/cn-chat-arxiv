<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#21644;&#39640;&#25928;&#22320;&#20272;&#35745;&#30452;&#25509;&#21644;&#21516;&#34892;&#25928;&#24212;&#65292;&#22788;&#29702;&#32593;&#32476;&#28151;&#26434;&#22240;&#32032;&#65292;&#24182;&#19968;&#33268;&#22320;&#20272;&#35745;&#25152;&#38656;&#30340;&#22240;&#26524;&#25928;&#24212;</title><link>https://arxiv.org/abs/2403.11332</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#32593;&#32476;&#22240;&#26524;&#25928;&#24212;&#21452;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Network based Double Machine Learning Estimator of Network Causal Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11332
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#20934;&#30830;&#21644;&#39640;&#25928;&#22320;&#20272;&#35745;&#30452;&#25509;&#21644;&#21516;&#34892;&#25928;&#24212;&#65292;&#22788;&#29702;&#32593;&#32476;&#28151;&#26434;&#22240;&#32032;&#65292;&#24182;&#19968;&#33268;&#22320;&#20272;&#35745;&#25152;&#38656;&#30340;&#22240;&#26524;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#35770;&#25991;&#35299;&#20915;&#20102;&#22312;&#31038;&#20132;&#32593;&#32476;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#25928;&#24212;&#30340;&#25361;&#25112;&#65292;&#36825;&#20123;&#25968;&#25454;&#20855;&#26377;&#20010;&#20307;&#20043;&#38388;&#22797;&#26434;&#30340;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#65292;&#23548;&#33268;&#21333;&#20301;&#20043;&#38388;&#19981;&#29420;&#31435;&#12289;&#24178;&#25200;&#65288;&#21333;&#20301;&#30340;&#32467;&#26524;&#21463;&#37051;&#23621;&#30340;&#22788;&#29702;&#24433;&#21709;&#65289;&#20197;&#21450;&#24341;&#20837;&#26469;&#33258;&#37051;&#36817;&#21333;&#20301;&#30340;&#39069;&#22806;&#28151;&#26434;&#22240;&#32032;&#31561;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#20351;&#29992;&#21333;&#20010;&#35266;&#27979;&#31038;&#20132;&#32593;&#32476;&#20934;&#30830;&#39640;&#25928;&#22320;&#20272;&#35745;&#30452;&#25509;&#21644;&#21516;&#20276;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22270;&#21516;&#26500;&#32593;&#32476;&#19982;&#21452;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#26377;&#25928;&#35843;&#25972;&#32593;&#32476;&#28151;&#26434;&#22240;&#32032;&#24182;&#19968;&#33268;&#22320;&#20272;&#35745;&#25152;&#38656;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#26082;&#20855;&#26377;&#28176;&#36817;&#27491;&#24577;&#24615;&#21448;&#21322;&#21442;&#25968;&#39640;&#25928;&#12290;&#25105;&#20204;&#23545;&#19977;&#20010;&#21322;&#21512;&#25104;&#29366;&#24577;&#19979;&#30340;&#22235;&#31181;&#26368;&#20808;&#36827;&#22522;&#32447;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11332v1 Announce Type: new  Abstract: Our paper addresses the challenge of inferring causal effects in social network data, characterized by complex interdependencies among individuals resulting in challenges such as non-independence of units, interference (where a unit's outcome is affected by neighbors' treatments), and introduction of additional confounding factors from neighboring units. We propose a novel methodology combining graph neural networks and double machine learning, enabling accurate and efficient estimation of direct and peer effects using a single observational social network. Our approach utilizes graph isomorphism networks in conjunction with double machine learning to effectively adjust for network confounders and consistently estimate the desired causal effects. We demonstrate that our estimator is both asymptotically normal and semiparametrically efficient. A comprehensive evaluation against four state-of-the-art baseline methods using three semi-synth
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20809;&#35889;&#21487;&#21152;&#24615;&#30340;&#26041;&#27861;&#65292;&#20174;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#29983;&#25104;&#20855;&#26377;&#32479;&#35745;&#29420;&#31435;&#26631;&#31614;&#30340;&#39069;&#22806;&#25968;&#25454;&#28857;&#65292;&#29992;&#20110;&#35757;&#32451;&#33021;&#22815;&#22788;&#29702;&#38750;&#39640;&#26031;&#22122;&#22768;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>https://arxiv.org/abs/2402.00851</link><description>&lt;p&gt;
&#20855;&#26377;&#39640;&#24230;&#30456;&#20851;&#27880;&#37322;&#30340;&#25289;&#26364;&#20809;&#35889;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Data Augmentation Scheme for Raman Spectra with Highly Correlated Annotations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00851
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20809;&#35889;&#21487;&#21152;&#24615;&#30340;&#26041;&#27861;&#65292;&#20174;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#29983;&#25104;&#20855;&#26377;&#32479;&#35745;&#29420;&#31435;&#26631;&#31614;&#30340;&#39069;&#22806;&#25968;&#25454;&#28857;&#65292;&#29992;&#20110;&#35757;&#32451;&#33021;&#22815;&#22788;&#29702;&#38750;&#39640;&#26031;&#22122;&#22768;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#29289;&#25216;&#26415;&#20013;&#65292;&#25289;&#26364;&#20809;&#35889;&#27861;&#20316;&#20026;&#19968;&#31181;&#36807;&#31243;&#20998;&#26512;&#25216;&#26415;&#65288;PAT&#65289;&#24555;&#36895;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#65292;&#23427;&#21487;&#20197;&#27979;&#37327;&#32454;&#32990;&#23494;&#24230;&#12289;&#24213;&#29289;&#21644;&#20135;&#29289;&#27987;&#24230;&#12290;&#30001;&#20110;&#25289;&#26364;&#20809;&#35889;&#35760;&#24405;&#20102;&#20998;&#23376;&#30340;&#25391;&#21160;&#27169;&#24335;&#65292;&#22240;&#27492;&#21487;&#20197;&#38750;&#20405;&#20837;&#24615;&#22320;&#22312;&#19968;&#20010;&#20809;&#35889;&#20013;&#25552;&#20379;&#30456;&#20851;&#20449;&#24687;&#12290;&#36890;&#24120;&#65292;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#26159;&#20174;&#20809;&#35889;&#20013;&#25512;&#26029;&#24863;&#20852;&#36259;&#21464;&#37327;&#20449;&#24687;&#30340;&#27169;&#22411;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#29983;&#29289;&#36807;&#31243;&#20197;&#20854;&#22797;&#26434;&#24615;&#32780;&#38395;&#21517;&#65292;&#20854;&#20013;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#26159;&#19968;&#20010;&#24378;&#22823;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#23427;&#20204;&#21487;&#20197;&#22788;&#29702;&#38750;&#39640;&#26031;&#22122;&#22768;&#65292;&#24182;&#32771;&#34385;&#20809;&#26463;&#38169;&#20301;&#12289;&#20687;&#32032;&#25925;&#38556;&#25110;&#20854;&#20182;&#29289;&#36136;&#30340;&#23384;&#22312;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#38656;&#35201;&#22823;&#37327;&#25968;&#25454;&#65292;&#24182;&#19988;&#33021;&#22815;&#25429;&#25417;&#21040;&#36807;&#31243;&#21464;&#37327;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20809;&#35889;&#30340;&#21487;&#21152;&#24615;&#26469;&#29983;&#25104;&#20174;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#30340;&#20855;&#26377;&#32479;&#35745;&#29420;&#31435;&#26631;&#31614;&#30340;&#39069;&#22806;&#25968;&#25454;&#28857;&#65292;&#20197;&#20415;&#35757;&#32451;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
In biotechnology Raman Spectroscopy is rapidly gaining popularity as a process analytical technology (PAT) that measures cell densities, substrate- and product concentrations. As it records vibrational modes of molecules it provides that information non-invasively in a single spectrum. Typically, partial least squares (PLS) is the model of choice to infer information about variables of interest from the spectra. However, biological processes are known for their complexity where convolutional neural networks (CNN) present a powerful alternative. They can handle non-Gaussian noise and account for beam misalignment, pixel malfunctions or the presence of additional substances. However, they require a lot of data during model training, and they pick up non-linear dependencies in the process variables. In this work, we exploit the additive nature of spectra in order to generate additional data points from a given dataset that have statistically independent labels so that a network trained on
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26080;&#38656;&#39044;&#35774;&#21442;&#25968;&#30340;ART&#25299;&#25169;&#32858;&#31867;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#23454;&#29616;&#25345;&#32493;&#23398;&#20064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20854;&#27604;&#29616;&#26377;&#32858;&#31867;&#31639;&#27861;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2305.01507</link><description>&lt;p&gt;
&#19968;&#31181;&#26080;&#38656;&#39044;&#35774;&#21442;&#25968;&#30340;&#33258;&#36866;&#24212;&#20849;&#25391;&#29702;&#35770;&#25299;&#25169;&#32858;&#31867;&#31639;&#27861;&#65292;&#23454;&#29616;&#25345;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
A Parameter-free Adaptive Resonance Theory-based Topological Clustering Algorithm Capable of Continual Learning. (arXiv:2305.01507v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01507
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26080;&#38656;&#39044;&#35774;&#21442;&#25968;&#30340;ART&#25299;&#25169;&#32858;&#31867;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#23454;&#29616;&#25345;&#32493;&#23398;&#20064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20854;&#27604;&#29616;&#26377;&#32858;&#31867;&#31639;&#27861;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33324;&#26469;&#35828;&#65292;&#22312;&#33258;&#36866;&#24212;&#20849;&#25391;&#29702;&#35770;&#65288;ART&#65289;&#31639;&#27861;&#20013;&#65292;&#33410;&#28857;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#30456;&#20284;&#24230;&#38408;&#20540;&#65288;&#21363;&#35686;&#35273;&#21442;&#25968;&#65289;&#23545;&#32858;&#31867;&#24615;&#33021;&#26377;&#37325;&#22823;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25299;&#25169;&#32858;&#31867;&#31639;&#27861;&#20013;&#30340;&#36793;&#32536;&#21024;&#38500;&#38408;&#20540;&#22312;&#33258;&#32452;&#32455;&#36807;&#31243;&#20013;&#29983;&#25104;&#20114;&#30456;&#20998;&#31163;&#30340;&#32858;&#31867;&#20013;&#36215;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#38656;&#39044;&#35774;&#21442;&#25968;&#30340;ART&#25299;&#25169;&#32858;&#31867;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#23454;&#29616;&#25345;&#32493;&#23398;&#20064;&#12290;&#38024;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#31639;&#27861;&#22312;&#26080;&#39044;&#35774;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#27604;&#29616;&#26377;&#32858;&#31867;&#31639;&#27861;&#26356;&#20248;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In general, a similarity threshold (i.e., a vigilance parameter) for a node learning process in Adaptive Resonance Theory (ART)-based algorithms has a significant impact on clustering performance. In addition, an edge deletion threshold in a topological clustering algorithm plays an important role in adaptively generating well-separated clusters during a self-organizing process. In this paper, we propose a new parameter-free ART-based topological clustering algorithm capable of continual learning by introducing parameter estimation methods. Experimental results with synthetic and real-world datasets show that the proposed algorithm has superior clustering performance to the state-of-the-art clustering algorithms without any parameter pre-specifications.
&lt;/p&gt;</description></item></channel></rss>