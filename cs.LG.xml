<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#20013;&#39118;&#20998;&#21106;&#30340;&#21512;&#25104;&#26694;&#26550;&#65292;&#20351;&#29992;&#30149;&#21464;&#29305;&#23450;&#22686;&#24378;&#31574;&#30053;&#25193;&#23637;&#20102;SynthSeg&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23454;&#29616;&#23545;&#20581;&#24247;&#32452;&#32455;&#21644;&#30149;&#29702;&#30149;&#21464;&#30340;&#20998;&#21106;&#65292;&#26080;&#38656;&#29305;&#23450;&#24207;&#21015;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#22312;&#39046;&#22495;&#20869;&#21644;&#39046;&#22495;&#22806;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#40065;&#26834;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.01946</link><description>&lt;p&gt;
&#29992;&#20110;&#40065;&#26834;&#24615;&#20013;&#39118;&#20998;&#21106;&#30340;&#21512;&#25104;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Synthetic Data for Robust Stroke Segmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01946
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#20013;&#39118;&#20998;&#21106;&#30340;&#21512;&#25104;&#26694;&#26550;&#65292;&#20351;&#29992;&#30149;&#21464;&#29305;&#23450;&#22686;&#24378;&#31574;&#30053;&#25193;&#23637;&#20102;SynthSeg&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23454;&#29616;&#23545;&#20581;&#24247;&#32452;&#32455;&#21644;&#30149;&#29702;&#30149;&#21464;&#30340;&#20998;&#21106;&#65292;&#26080;&#38656;&#29305;&#23450;&#24207;&#21015;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#22312;&#39046;&#22495;&#20869;&#21644;&#39046;&#22495;&#22806;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#40065;&#26834;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01946v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#20132;&#21449; &#25688;&#35201;&#65306;&#30446;&#21069;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31070;&#32463;&#24433;&#20687;&#35821;&#20041;&#20998;&#21106;&#38656;&#35201;&#39640;&#20998;&#36776;&#29575;&#25195;&#25551;&#21644;&#22823;&#37327;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#36825;&#32473;&#20020;&#24202;&#36866;&#29992;&#24615;&#24102;&#26469;&#20102;&#26174;&#33879;&#38556;&#30861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21512;&#25104;&#26694;&#26550;&#65292;&#29992;&#20110;&#30149;&#21464;&#20998;&#21106;&#20219;&#21153;&#65292;&#25193;&#23637;&#20102;&#24050;&#24314;&#31435;&#30340;SynthSeg&#26041;&#27861;&#30340;&#33021;&#21147;&#65292;&#20197;&#36866;&#24212;&#20855;&#26377;&#30149;&#21464;&#29305;&#23450;&#22686;&#24378;&#31574;&#30053;&#30340;&#22823;&#22411;&#24322;&#36136;&#30149;&#21464;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#20174;&#20581;&#24247;&#21644;&#20013;&#39118;&#25968;&#25454;&#38598;&#27966;&#29983;&#30340;&#26631;&#31614;&#26144;&#23556;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#36825;&#37324;&#28436;&#31034;&#20102;UNet&#26550;&#26500;&#65292;&#20419;&#36827;&#20102;&#20581;&#24247;&#32452;&#32455;&#21644;&#30149;&#29702;&#30149;&#21464;&#30340;&#20998;&#21106;&#65292;&#32780;&#26080;&#38656;&#29305;&#23450;&#20110;&#24207;&#21015;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#38024;&#23545;&#39046;&#22495;&#20869;&#21644;&#39046;&#22495;&#22806;&#65288;OOD&#65289;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#34920;&#29616;&#20986;&#40065;&#26834;&#24615;&#33021;&#65292;&#19982;&#35757;&#32451;&#39046;&#22495;&#20869;&#30340;&#24403;&#21069;&#26041;&#27861;&#30456;&#23218;&#32654;&#65292;&#24182;&#22312;OOD&#25968;&#25454;&#19978;&#26174;&#30528;&#20248;&#20110;&#23427;&#20204;&#12290;&#36825;&#19968;&#36129;&#29486;&#26377;&#26395;&#25512;&#21160;&#21307;&#23398;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01946v1 Announce Type: cross  Abstract: Deep learning-based semantic segmentation in neuroimaging currently requires high-resolution scans and extensive annotated datasets, posing significant barriers to clinical applicability. We present a novel synthetic framework for the task of lesion segmentation, extending the capabilities of the established SynthSeg approach to accommodate large heterogeneous pathologies with lesion-specific augmentation strategies. Our method trains deep learning models, demonstrated here with the UNet architecture, using label maps derived from healthy and stroke datasets, facilitating the segmentation of both healthy tissue and pathological lesions without sequence-specific training data. Evaluated against in-domain and out-of-domain (OOD) datasets, our framework demonstrates robust performance, rivaling current methods within the training domain and significantly outperforming them on OOD data. This contribution holds promise for advancing medical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#19981;&#21464;&#37051;&#22495;&#27169;&#24335;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#37051;&#22495;&#20256;&#25773;&#27169;&#22359;&#21644;&#19981;&#21464;&#38750;&#21516;&#28304;&#22270;&#23398;&#20064;&#27169;&#22359;&#65292;&#35299;&#20915;&#20102;&#38750;&#21516;&#28304;&#22270;&#19978;&#37051;&#22495;&#27169;&#24335;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.10572</link><description>&lt;p&gt;
&#21457;&#29616;&#24322;&#24615;&#22270;&#30340;&#19981;&#21464;&#37051;&#22495;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
Discovering Invariant Neighborhood Patterns for Heterophilic Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#19981;&#21464;&#37051;&#22495;&#27169;&#24335;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#37051;&#22495;&#20256;&#25773;&#27169;&#22359;&#21644;&#19981;&#21464;&#38750;&#21516;&#28304;&#22270;&#23398;&#20064;&#27169;&#22359;&#65292;&#35299;&#20915;&#20102;&#38750;&#21516;&#28304;&#22270;&#19978;&#37051;&#22495;&#27169;&#24335;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#21516;&#28304;&#22270;&#19978;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#20381;&#36182;&#20110;&#21516;&#28304;&#20551;&#35774;&#65292;&#21363;&#21516;&#19968;&#31867;&#21035;&#30340;&#33410;&#28857;&#26356;&#26377;&#21487;&#33021;&#34987;&#36830;&#25509;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22270;&#20013;&#65292;&#36825;&#31181;&#21516;&#28304;&#24615;&#20551;&#35774;&#24182;&#19981;&#24635;&#26159;&#25104;&#31435;&#65292;&#36825;&#23548;&#33268;&#20102;&#22312;&#20808;&#21069;&#30340;&#26041;&#27861;&#20013;&#26410;&#33021;&#35299;&#37322;&#30340;&#26356;&#22797;&#26434;&#30340;&#20998;&#24067;&#20559;&#31227;&#12290;&#22312;&#38750;&#21516;&#28304;&#22270;&#19978;&#65292;&#37051;&#22495;&#27169;&#24335;&#30340;&#20998;&#24067;&#20559;&#31227;&#26356;&#21152;&#22810;&#26679;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#19981;&#21464;&#37051;&#22495;&#27169;&#24335;&#23398;&#20064;&#65288;INPL&#65289;&#26041;&#27861;&#65292;&#20197;&#32531;&#35299;&#38750;&#21516;&#28304;&#22270;&#19978;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#37051;&#22495;&#20256;&#25773;&#65288;ANP&#65289;&#27169;&#22359;&#26469;&#25429;&#33719;&#33258;&#36866;&#24212;&#30340;&#37051;&#22495;&#20449;&#24687;&#65292;&#36825;&#21487;&#20197;&#32531;&#35299;&#38750;&#21516;&#28304;&#22270;&#19978;&#30340;&#37051;&#22495;&#27169;&#24335;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#21464;&#38750;&#21516;&#28304;&#22270;&#23398;&#20064;&#65288;INHGL&#65289;&#27169;&#22359;&#65292;&#20854;&#32422;&#26463;&#20102;ANP&#24182;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10572v1 Announce Type: new  Abstract: This paper studies the problem of distribution shifts on non-homophilous graphs Mosting existing graph neural network methods rely on the homophilous assumption that nodes from the same class are more likely to be linked. However, such assumptions of homophily do not always hold in real-world graphs, which leads to more complex distribution shifts unaccounted for in previous methods. The distribution shifts of neighborhood patterns are much more diverse on non-homophilous graphs. We propose a novel Invariant Neighborhood Pattern Learning (INPL) to alleviate the distribution shifts problem on non-homophilous graphs. Specifically, we propose the Adaptive Neighborhood Propagation (ANP) module to capture the adaptive neighborhood information, which could alleviate the neighborhood pattern distribution shifts problem on non-homophilous graphs. We propose Invariant Non-Homophilous Graph Learning (INHGL) module to constrain the ANP and learn in
&lt;/p&gt;</description></item><item><title>JMA&#26159;&#19968;&#31181;&#36890;&#29992;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#20960;&#20046;&#26368;&#20248;&#30340;&#23450;&#21521;&#23545;&#25239;&#26679;&#26412;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;Jacobian&#24341;&#36215;&#30340;&#39532;&#27663;&#36317;&#31163;&#65292;&#32771;&#34385;&#20102;&#23558;&#36755;&#20837;&#26679;&#26412;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;&#22312;&#32473;&#23450;&#26041;&#21521;&#19978;&#31227;&#21160;&#25152;&#38656;&#30340;&#25237;&#20837;&#12290;&#35813;&#31639;&#27861;&#22312;&#35299;&#20915;&#23545;&#25239;&#26679;&#26412;&#38382;&#39064;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2401.01199</link><description>&lt;p&gt;
JMA:&#19968;&#31181;&#24555;&#36895;&#29983;&#25104;&#20960;&#20046;&#26368;&#20248;&#23450;&#21521;&#23545;&#25239;&#26679;&#26412;&#30340;&#36890;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example. (arXiv:2401.01199v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01199
&lt;/p&gt;
&lt;p&gt;
JMA&#26159;&#19968;&#31181;&#36890;&#29992;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#20960;&#20046;&#26368;&#20248;&#30340;&#23450;&#21521;&#23545;&#25239;&#26679;&#26412;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;Jacobian&#24341;&#36215;&#30340;&#39532;&#27663;&#36317;&#31163;&#65292;&#32771;&#34385;&#20102;&#23558;&#36755;&#20837;&#26679;&#26412;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;&#22312;&#32473;&#23450;&#26041;&#21521;&#19978;&#31227;&#21160;&#25152;&#38656;&#30340;&#25237;&#20837;&#12290;&#35813;&#31639;&#27861;&#22312;&#35299;&#20915;&#23545;&#25239;&#26679;&#26412;&#38382;&#39064;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#20026;&#27490;&#65292;&#22823;&#22810;&#25968;&#29992;&#20110;&#29983;&#25104;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#23450;&#21521;&#23545;&#25239;&#26679;&#26412;&#30340;&#26041;&#27861;&#37117;&#26159;&#39640;&#24230;&#27425;&#20248;&#30340;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#22686;&#21152;&#30446;&#26631;&#31867;&#21035;&#30340;&#21487;&#33021;&#24615;&#65292;&#22240;&#27492;&#38544;&#21547;&#22320;&#19987;&#27880;&#20110;&#19968;&#28909;&#32534;&#30721;&#35774;&#32622;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21152;&#36890;&#29992;&#30340;&#12289;&#29702;&#35770;&#19978;&#21487;&#38752;&#30340;&#23450;&#21521;&#25915;&#20987;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#26368;&#23567;&#21270;&#38597;&#21487;&#27604;&#24341;&#36215;&#30340;&#39532;&#27663;&#36317;&#31163;&#65288;JMA&#65289;&#39033;&#65292;&#32771;&#34385;&#23558;&#36755;&#20837;&#26679;&#26412;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;&#22312;&#32473;&#23450;&#26041;&#21521;&#19978;&#31227;&#21160;&#25152;&#38656;&#30340;&#25237;&#20837;&#65288;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#65289;&#12290;&#36890;&#36807;&#21033;&#29992;&#27779;&#23572;&#22827;&#20108;&#37325;&#24615;&#23450;&#29702;&#27714;&#35299;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#23558;&#38382;&#39064;&#31616;&#21270;&#20026;&#35299;&#38750;&#36127;&#26368;&#23567;&#20108;&#20056;&#65288;NNLS&#65289;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20026;Szegedy&#31561;&#20154;&#26368;&#21021;&#24341;&#20837;&#30340;&#23545;&#25239;&#26679;&#26412;&#38382;&#39064;&#30340;&#32447;&#24615;&#21270;&#29256;&#26412;&#25552;&#20379;&#20102;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#30340;&#25915;&#20987;&#30340;&#24191;&#27867;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most of the approaches proposed so far to craft targeted adversarial examples against Deep Learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings. In this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a Jacobian-induced MAhalanobis distance (JMA) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction. The minimization is solved by exploiting the Wolfe duality theorem, reducing the problem to the solution of a Non-Negative Least Square (NNLS) problem. The proposed algorithm provides an optimal solution to a linearized version of the adversarial example problem originally introduced by Szegedy et al. \cite{szegedy2013intriguing}. The experiments we carried out confirm the generality of the proposed attack which is proven to be 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.00098</link><description>&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#23398;&#20064;&#36827;&#34892;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Federated Learning with Differential Privacy for End-to-End Speech Recognition. (arXiv:2310.00098v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20294;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#39046;&#22495;&#20165;&#38480;&#20110;&#21021;&#27493;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#32852;&#37030;&#23398;&#20064;&#19981;&#33021;&#26412;&#36136;&#19978;&#20445;&#35777;&#29992;&#25143;&#38544;&#31169;&#65292;&#24182;&#38656;&#35201;&#24046;&#20998;&#38544;&#31169;&#26469;&#25552;&#20379;&#31283;&#20581;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36824;&#19981;&#28165;&#26970;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#20808;&#21069;&#24037;&#20316;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20026;&#32852;&#37030;&#23398;&#20064;&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;&#30340;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#22522;&#20934;&#65292;&#24182;&#24314;&#31435;&#31532;&#19968;&#20010;&#22522;&#32447;&#26469;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#32852;&#37030;&#23398;&#20064;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#30740;&#31350;&#65292;&#25506;&#32034;&#20102;&#26368;&#26032;&#30340;&#22823;&#22411;&#31471;&#21040;&#31471;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65306;&#26550;&#26500;&#35774;&#35745;&#65292;&#31181;&#23376;&#27169;&#22411;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#65292;&#39046;&#22495;&#36716;&#31227;&#65292;&#20197;&#21450;cohort&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#21512;&#29702;&#30340;&#20013;&#22830;&#32858;&#21512;&#25968;&#37327;&#65292;&#25105;&#20204;&#33021;&#22815;&#35757;&#32451;&#20986;&#21363;&#20351;&#22312;&#24322;&#26500;&#25968;&#25454;&#12289;&#26469;&#33258;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#31181;&#23376;&#27169;&#22411;&#25110;&#26080;&#39044;&#20808;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#25509;&#36817;&#26368;&#20248;&#30340;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
While federated learning (FL) has recently emerged as a promising approach to train machine learning models, it is limited to only preliminary explorations in the domain of automatic speech recognition (ASR). Moreover, FL does not inherently guarantee user privacy and requires the use of differential privacy (DP) for robust privacy guarantees. However, we are not aware of prior work on applying DP to FL for ASR. In this paper, we aim to bridge this research gap by formulating an ASR benchmark for FL with DP and establishing the first baselines. First, we extend the existing research on FL for ASR by exploring different aspects of recent $\textit{large end-to-end transformer models}$: architecture design, seed models, data heterogeneity, domain shift, and impact of cohort size. With a $\textit{practical}$ number of central aggregations we are able to train $\textbf{FL models}$ that are \textbf{nearly optimal} even with heterogeneous data, a seed model from another domain, or no pre-trai
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;SI SL&#65292;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#21644;&#27169;&#22411;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#35268;&#21010;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#19982;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#26041;&#26696;&#30340;&#27604;&#36739;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.08029</link><description>&lt;p&gt;
&#35268;&#21010;&#23398;&#20064;&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Planning to Learn: A Novel Algorithm for Active Learning during Model-Based Planning. (arXiv:2308.08029v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08029
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;SI SL&#65292;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#21644;&#27169;&#22411;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#35268;&#21010;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#19982;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#26041;&#26696;&#30340;&#27604;&#36739;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#25512;&#29702;&#26159;&#19968;&#31181;&#36817;&#26399;&#30340;&#23545;&#19981;&#30830;&#23450;&#24615;&#24773;&#22659;&#19979;&#35268;&#21010;&#24314;&#27169;&#30340;&#26694;&#26550;&#12290;&#29616;&#22312;&#20154;&#20204;&#24050;&#32463;&#24320;&#22987;&#35780;&#20272;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#20197;&#21450;&#22914;&#20309;&#25913;&#36827;&#23427;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#25299;&#23637;-&#22797;&#26434;&#27169;&#22411;&#20248;&#21270;&#31639;&#27861;&#36890;&#36807;&#36882;&#24402;&#20915;&#31574;&#26641;&#25628;&#32034;&#22312;&#22810;&#27493;&#35268;&#21010;&#38382;&#39064;&#19978;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#24456;&#23569;&#26377;&#24037;&#20316;&#23545;&#27604;SI&#19982;&#20854;&#20182;&#24050;&#24314;&#31435;&#30340;&#35268;&#21010;&#31639;&#27861;&#12290;SI&#31639;&#27861;&#20063;&#20027;&#35201;&#20851;&#27880;&#25512;&#29702;&#32780;&#19981;&#26159;&#23398;&#20064;&#12290;&#26412;&#25991;&#26377;&#20004;&#20010;&#30446;&#26631;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#27604;&#36739;SI&#19982;&#26088;&#22312;&#35299;&#20915;&#30456;&#20284;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26041;&#26696;&#30340;&#24615;&#33021;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SI&#22797;&#26434;&#23398;&#20064;&#65288;SL&#65289;&#30340;&#25299;&#23637;&#65292;&#35813;&#25299;&#23637;&#22312;&#35268;&#21010;&#36807;&#31243;&#20013;&#26356;&#21152;&#20805;&#20998;&#22320;&#24341;&#20837;&#20102;&#20027;&#21160;&#23398;&#20064;&#12290;SL&#32500;&#25345;&#23545;&#26410;&#26469;&#35266;&#27979;&#19979;&#27599;&#20010;&#31574;&#30053;&#19979;&#27169;&#22411;&#21442;&#25968;&#22914;&#20309;&#21464;&#21270;&#30340;&#20449;&#24565;&#12290;&#36825;&#20801;&#35768;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#30340;&#22238;&#39038;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Active Inference is a recent framework for modeling planning under uncertainty. Empirical and theoretical work have now begun to evaluate the strengths and weaknesses of this approach and how it might be improved. A recent extension - the sophisticated inference (SI) algorithm - improves performance on multi-step planning problems through recursive decision tree search. However, little work to date has been done to compare SI to other established planning algorithms. SI was also developed with a focus on inference as opposed to learning. The present paper has two aims. First, we compare performance of SI to Bayesian reinforcement learning (RL) schemes designed to solve similar problems. Second, we present an extension of SI sophisticated learning (SL) - that more fully incorporates active learning during planning. SL maintains beliefs about how model parameters would change under the future observations expected under each policy. This allows a form of counterfactual retrospective in
&lt;/p&gt;</description></item></channel></rss>