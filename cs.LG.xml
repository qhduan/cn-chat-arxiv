<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#19987;&#38376;&#27169;&#22411;&#36890;&#24120;&#21482;&#38656;&#23569;&#37327;&#26631;&#35760;&#26679;&#26412;&#65288;100-1000&#20010;&#65289;&#23601;&#33021;&#19982;&#36890;&#29992;&#27169;&#22411;&#25345;&#24179;&#29978;&#33267;&#26356;&#22909;&#65292;&#21462;&#20915;&#20110;&#20219;&#21153;&#30340;&#22797;&#26434;&#24615;&#21644;&#32467;&#26524;&#30340;&#21464;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.12819</link><description>&lt;p&gt;
&#24494;&#35843;&#12289;&#25552;&#31034;&#12289;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#25351;&#23548;&#24494;&#35843;&#65306;&#25105;&#20204;&#38656;&#35201;&#22810;&#23569;&#26631;&#35760;&#26679;&#26412;&#65311;
&lt;/p&gt;
&lt;p&gt;
Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12819
&lt;/p&gt;
&lt;p&gt;
&#19987;&#38376;&#27169;&#22411;&#36890;&#24120;&#21482;&#38656;&#23569;&#37327;&#26631;&#35760;&#26679;&#26412;&#65288;100-1000&#20010;&#65289;&#23601;&#33021;&#19982;&#36890;&#29992;&#27169;&#22411;&#25345;&#24179;&#29978;&#33267;&#26356;&#22909;&#65292;&#21462;&#20915;&#20110;&#20219;&#21153;&#30340;&#22797;&#26434;&#24615;&#21644;&#32467;&#26524;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#35299;&#20915;&#20855;&#26377;&#26377;&#38480;&#26631;&#35760;&#25968;&#25454;&#30340;&#20219;&#21153;&#26102;&#65292;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#36873;&#25321;&#20351;&#29992;&#36890;&#29992;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32780;&#19981;&#36827;&#34892;&#36827;&#19968;&#27493;&#26356;&#26032;&#65292;&#25110;&#32773;&#20351;&#29992;&#23569;&#37327;&#31034;&#20363;&#26469;&#35843;&#25972;&#19987;&#38376;&#30340;&#36739;&#23567;&#27169;&#22411;&#12290; &#24403;&#26377;&#36275;&#22815;&#30340;&#26631;&#35760;&#21487;&#29992;&#26102;&#65292;&#19987;&#38376;&#30340;&#27169;&#22411;&#22312;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#20110;&#36890;&#29992;&#27169;&#22411;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#35843;&#26597;&#19987;&#38376;&#27169;&#22411;&#38656;&#35201;&#22810;&#23569;&#26631;&#35760;&#26679;&#26412;&#25165;&#33021;&#23454;&#29616;&#36825;&#31181;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#32771;&#34385;&#32467;&#26524;&#30340;&#21464;&#21270;&#12290;&#35266;&#23519;&#25552;&#31034;&#12289;&#19978;&#19979;&#25991;&#23398;&#20064;&#12289;&#24494;&#35843;&#21644;&#25351;&#23548;&#24494;&#35843;&#30340;&#34892;&#20026;&#65292;&#35782;&#21035;&#23427;&#20204;&#22312;&#22686;&#21152;&#19981;&#21516;&#22797;&#26434;&#24615;&#20219;&#21153;&#30340;&#26631;&#35760;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#26102;&#30340;&#25910;&#25903;&#24179;&#34913;&#28857;&#65292;&#25105;&#20204;&#21457;&#29616;&#19987;&#38376;&#27169;&#22411;&#36890;&#24120;&#21482;&#38656;&#23569;&#37327;&#26679;&#26412;&#65288;100-1000&#20010;&#65289;&#23601;&#33021;&#19982;&#36890;&#29992;&#27169;&#22411;&#25345;&#24179;&#29978;&#33267;&#26356;&#22909;&#12290; &#21516;&#26102;&#65292;&#25152;&#38656;&#30340;&#26631;&#35760;&#25968;&#25454;&#37327;&#24378;&#28872;&#20381;&#36182;&#20110;&#20219;&#21153;&#30340;&#22797;&#26434;&#24615;&#21644;&#32467;&#26524;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12819v1 Announce Type: cross  Abstract: When solving a task with limited labelled data, researchers can either use a general large language model without further update, or use the few examples to tune a specialised smaller model. When enough labels are available, the specialised models outperform the general ones on many NLP tasks. In this work, we aim to investigate how many labelled samples are required for the specialised models to achieve this superior performance, while taking the results variance into consideration. Observing the behaviour of prompting, in-context learning, fine-tuning and instruction-tuning, identifying their break-even points when increasing number of labelled training samples across three tasks of varying complexity, we find that the specialised models often need only few samples ($100-1000$) to be on par or better than the general ones. At the same time, the amount of required labelled data strongly depends on the task complexity and results varia
&lt;/p&gt;</description></item><item><title>&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#26041;&#27861;ECUP&#26088;&#22312;&#35299;&#20915;&#38142;&#36335;&#20559;&#24046;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#65292;&#22312;&#32447;&#33829;&#38144;&#20013;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2402.03379</link><description>&lt;p&gt;
&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#19982;&#19978;&#19979;&#25991;&#22686;&#24378;&#23398;&#20064;&#29992;&#20110;&#26234;&#33021;&#33829;&#38144;
&lt;/p&gt;
&lt;p&gt;
Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03379
&lt;/p&gt;
&lt;p&gt;
&#20840;&#38142;&#36335;&#19978;&#21319;&#24314;&#27169;&#26041;&#27861;ECUP&#26088;&#22312;&#35299;&#20915;&#38142;&#36335;&#20559;&#24046;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#65292;&#22312;&#32447;&#33829;&#38144;&#20013;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#21319;&#24314;&#27169;&#22312;&#22312;&#32447;&#33829;&#38144;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#23427;&#26088;&#22312;&#36890;&#36807;&#39044;&#27979;&#20010;&#20307;&#22788;&#29702;&#25928;&#26524;&#65288;ITE&#65289;&#26469;&#20934;&#30830;&#34913;&#37327;&#19981;&#21516;&#31574;&#30053;&#65288;&#22914;&#20248;&#24800;&#21048;&#25110;&#25240;&#25187;&#65289;&#23545;&#19981;&#21516;&#29992;&#25143;&#30340;&#24433;&#21709;&#12290;&#22312;&#30005;&#23376;&#21830;&#21153;&#29615;&#22659;&#20013;&#65292;&#29992;&#25143;&#34892;&#20026;&#36981;&#24490;&#30830;&#23450;&#30340;&#39034;&#24207;&#38142;&#36335;&#65292;&#21253;&#25324;&#23637;&#31034;&#12289;&#28857;&#20987;&#21644;&#36716;&#21270;&#12290;&#33829;&#38144;&#31574;&#30053;&#22312;&#36825;&#20010;&#38142;&#36335;&#20013;&#30340;&#27599;&#20010;&#38454;&#27573;&#37117;&#20250;&#20135;&#29983;&#19981;&#21516;&#30340;&#19978;&#21319;&#25928;&#24212;&#65292;&#24433;&#21709;&#30528;&#28857;&#20987;&#29575;&#21644;&#36716;&#21270;&#29575;&#31561;&#25351;&#26631;&#12290;&#23613;&#31649;&#20854;&#23454;&#29992;&#24615;&#65292;&#29616;&#26377;&#30740;&#31350;&#24573;&#35270;&#20102;&#29305;&#23450;&#22788;&#29702;&#20013;&#25152;&#26377;&#38454;&#27573;&#30340;&#30456;&#20114;&#24433;&#21709;&#65292;&#24182;&#26410;&#20805;&#20998;&#21033;&#29992;&#22788;&#29702;&#20449;&#24687;&#65292;&#21487;&#33021;&#32473;&#21518;&#32493;&#30340;&#33829;&#38144;&#20915;&#31574;&#24341;&#20837;&#20102;&#37325;&#22823;&#20559;&#24046;&#12290;&#26412;&#25991;&#23558;&#36825;&#20004;&#20010;&#38382;&#39064;&#31216;&#20026;&#38142;&#36335;&#20559;&#24046;&#38382;&#39064;&#21644;&#22788;&#29702;&#19981;&#36866;&#24212;&#38382;&#39064;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#20855;&#26377;&#19978;&#19979;&#25991;&#22686;&#24378;&#23398;&#20064;&#30340;&#20840;&#38142;&#36335;&#19978;&#21319;&#26041;&#27861;&#65288;ECUP&#65289;&#12290;ECUP&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#65306;
&lt;/p&gt;
&lt;p&gt;
Uplift modeling, vital in online marketing, seeks to accurately measure the impact of various strategies, such as coupons or discounts, on different users by predicting the Individual Treatment Effect (ITE). In an e-commerce setting, user behavior follows a defined sequential chain, including impression, click, and conversion. Marketing strategies exert varied uplift effects at each stage within this chain, impacting metrics like click-through and conversion rate. Despite its utility, existing research has neglected to consider the inter-task across all stages impacts within a specific treatment and has insufficiently utilized the treatment information, potentially introducing substantial bias into subsequent marketing decisions. We identify these two issues as the chain-bias problem and the treatment-unadaptive problem. This paper introduces the Entire Chain UPlift method with context-enhanced learning (ECUP), devised to tackle these issues. ECUP consists of two primary components: 1)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Task Aware Dreamer&#65288;TAD&#65289;&#30340;&#26041;&#27861;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#27867;&#21270;&#12290;&#36890;&#36807;&#37327;&#21270;&#20219;&#21153;&#20998;&#24067;&#30340;&#30456;&#20851;&#24615;&#65292;TAD&#33021;&#22815;&#23558;&#21382;&#21490;&#20449;&#24687;&#32534;&#30721;&#21040;&#31574;&#30053;&#20013;&#65292;&#20197;&#20415;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#65292;&#24182;&#22312;&#27867;&#21270;&#21040;&#26410;&#35265;&#20219;&#21153;&#26102;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.05092</link><description>&lt;p&gt;
Task Aware Dreamer&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Task Aware Dreamer for Task Generalization in Reinforcement Learning. (arXiv:2303.05092v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Task Aware Dreamer&#65288;TAD&#65289;&#30340;&#26041;&#27861;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20219;&#21153;&#27867;&#21270;&#12290;&#36890;&#36807;&#37327;&#21270;&#20219;&#21153;&#20998;&#24067;&#30340;&#30456;&#20851;&#24615;&#65292;TAD&#33021;&#22815;&#23558;&#21382;&#21490;&#20449;&#24687;&#32534;&#30721;&#21040;&#31574;&#30053;&#20013;&#65292;&#20197;&#20415;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#65292;&#24182;&#22312;&#27867;&#21270;&#21040;&#26410;&#35265;&#20219;&#21153;&#26102;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#30340;&#19968;&#20010;&#38271;&#26399;&#30446;&#26631;&#26159;&#33719;&#24471;&#33021;&#22815;&#22312;&#35757;&#32451;&#20219;&#21153;&#19978;&#23398;&#20064;&#24182;&#19988;&#22312;&#19981;&#21516;&#22870;&#21169;&#20989;&#25968;&#19979;&#21487;&#20197;&#24456;&#22909;&#22320;&#27867;&#21270;&#21040;&#26410;&#35265;&#20219;&#21153;&#30340;&#20195;&#29702;&#12290;&#19968;&#20010;&#36890;&#29992;&#30340;&#25361;&#25112;&#26159;&#23450;&#37327;&#22320;&#34913;&#37327;&#36825;&#20123;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#36825;&#23545;&#20110;&#20998;&#26512;&#20219;&#21153;&#20998;&#24067;&#24182;&#36827;&#19968;&#27493;&#35774;&#35745;&#20855;&#26377;&#26356;&#24378;&#27867;&#21270;&#33021;&#21147;&#30340;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#21517;&#20026;&#20219;&#21153;&#20998;&#24067;&#30456;&#20851;&#24615;&#65288;TDR&#65289;&#65292;&#36890;&#36807;&#19981;&#21516;&#20219;&#21153;&#30340;&#26368;&#20248;Q&#20989;&#25968;&#26469;&#37327;&#21270;&#20219;&#21153;&#20998;&#24067;&#30340;&#30456;&#20851;&#24615;&#12290;&#22312;&#20855;&#26377;&#39640;TDR&#30340;&#20219;&#21153;&#24773;&#20917;&#19979;&#65292;&#21363;&#20219;&#21153;&#20043;&#38388;&#26174;&#33879;&#19981;&#21516;&#65292;&#25105;&#20204;&#21457;&#29616;&#39532;&#23572;&#21487;&#22827;&#31574;&#30053;&#26080;&#27861;&#21306;&#20998;&#23427;&#20204;&#65292;&#23548;&#33268;&#24615;&#33021;&#36739;&#24046;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#23558;&#25152;&#26377;&#21382;&#21490;&#20449;&#24687;&#32534;&#30721;&#21040;&#31574;&#30053;&#20013;&#20197;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;Task Aware Dreamer&#65288;TAD&#65289;&#65292;&#23427;&#23558;&#19990;&#30028;&#27169;&#22411;&#25193;&#23637;&#20026;&#25105;&#20204;&#30340;&#22870;&#21169;&#24863;&#30693;&#19990;&#30028;&#27169;&#22411;&#20197;&#25429;&#25417;&#20219;&#21153;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A long-standing goal of reinforcement learning is to acquire agents that can learn on training tasks and generalize well on unseen tasks that may share a similar dynamic but with different reward functions. A general challenge is to quantitatively measure the similarities between these different tasks, which is vital for analyzing the task distribution and further designing algorithms with stronger generalization. To address this, we present a novel metric named Task Distribution Relevance (TDR) via optimal Q functions of different tasks to capture the relevance of the task distribution quantitatively. In the case of tasks with a high TDR, i.e., the tasks differ significantly, we show that the Markovian policies cannot differentiate them, leading to poor performance. Based on this insight, we encode all historical information into policies for distinguishing different tasks and propose Task Aware Dreamer (TAD), which extends world models into our reward-informed world models to capture
&lt;/p&gt;</description></item><item><title>&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#20026;&#22312;&#32447;&#24191;&#21578;&#39046;&#22495;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#20197;&#24212;&#23545;&#20256;&#32479;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2209.15635</link><description>&lt;p&gt;
&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#29992;&#20110;&#39640;&#25928;&#22312;&#32447;&#24191;&#21578;
&lt;/p&gt;
&lt;p&gt;
Vertical Semi-Federated Learning for Efficient Online Advertising. (arXiv:2209.15635v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15635
&lt;/p&gt;
&lt;p&gt;
&#22402;&#30452;&#21322;&#32852;&#21512;&#23398;&#20064;&#20026;&#22312;&#32447;&#24191;&#21578;&#39046;&#22495;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#20197;&#24212;&#23545;&#20256;&#32479;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26550;&#26500;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;1&#65289;&#36866;&#29992;&#33539;&#22260;&#21463;&#38480;&#20110;&#37325;&#21472;&#26679;&#26412;&#65307;2&#65289;&#23454;&#26102;&#32852;&#21512;&#26381;&#21153;&#30340;&#31995;&#32479;&#25361;&#25112;&#36739;&#39640;&#65292;&#36825;&#38480;&#21046;&#20102;&#20854;&#22312;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#35774;&#32622;&#8212;&#8212;&#21322;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;(Semi-VFL)&#65292;&#20197;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#12290;&#21322;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#26088;&#22312;&#23454;&#29616;&#22402;&#30452;&#32852;&#21512;&#23398;&#20064;&#30340;&#23454;&#38469;&#24037;&#19994;&#24212;&#29992;&#26041;&#24335;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#32852;&#21512;&#24863;&#30693;&#30340;&#23616;&#37096;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#34920;&#29616;&#20248;&#20110;&#21333;&#26041;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#23616;&#37096;&#26381;&#21153;&#30340;&#20415;&#21033;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31934;&#24515;&#35774;&#35745;&#30340;&#32852;&#21512;&#29305;&#26435;&#23398;&#20064;&#26694;&#26550;(JPL)&#65292;&#26469;&#35299;&#20915;&#34987;&#21160;&#26041;&#29305;&#24449;&#32570;&#22833;&#21644;&#36866;&#24212;&#25972;&#20010;&#26679;&#26412;&#31354;&#38388;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#25512;&#29702;&#39640;&#25928;&#30340;&#36866;&#29992;&#20110;&#25972;&#20010;&#26679;&#26412;&#31354;&#38388;&#30340;&#21333;&#26041;&#23398;&#29983;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#32852;&#21512;&#29305;&#24449;&#25193;&#23637;&#30340;&#20248;&#21183;&#12290;&#26032;&#30340;&#34920;&#31034;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
The traditional vertical federated learning schema suffers from two main issues: 1) restricted applicable scope to overlapped samples and 2) high system challenge of real-time federated serving, which limits its application to advertising systems. To this end, we advocate a new learning setting Semi-VFL (Vertical Semi-Federated Learning) to tackle these challenge. Semi-VFL is proposed to achieve a practical industry application fashion for VFL, by learning a federation-aware local model which performs better than single-party models and meanwhile maintain the convenience of local-serving. For this purpose, we propose the carefully designed Joint Privileged Learning framework (JPL) to i) alleviate the absence of the passive party's feature and ii) adapt to the whole sample space. Specifically, we build an inference-efficient single-party student model applicable to the whole sample space and meanwhile maintain the advantage of the federated feature extension. New representation distilla
&lt;/p&gt;</description></item></channel></rss>