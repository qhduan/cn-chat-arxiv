<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#24102;&#26377;&#29978;&#33267;&#31435;&#26041;&#38750;&#32447;&#24615;&#30340;&#31616;&#21333;&#23454;&#29616;&#28608;&#27963;&#20989;&#25968;&#65292;&#36890;&#36807;&#24341;&#20837;&#21487;&#20248;&#21270;&#21442;&#25968;&#20351;&#24471;&#28608;&#27963;&#20989;&#25968;&#20855;&#26377;&#26356;&#22823;&#30340;&#33258;&#30001;&#24230;&#65292;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#22826;&#22810;&#39069;&#22806;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;</title><link>https://arxiv.org/abs/2403.19896</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#22686;&#24378;&#33258;&#36866;&#24212;&#28608;&#27963;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Nonlinearity Enhanced Adaptive Activation Function
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19896
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#24102;&#26377;&#29978;&#33267;&#31435;&#26041;&#38750;&#32447;&#24615;&#30340;&#31616;&#21333;&#23454;&#29616;&#28608;&#27963;&#20989;&#25968;&#65292;&#36890;&#36807;&#24341;&#20837;&#21487;&#20248;&#21270;&#21442;&#25968;&#20351;&#24471;&#28608;&#27963;&#20989;&#25968;&#20855;&#26377;&#26356;&#22823;&#30340;&#33258;&#30001;&#24230;&#65292;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#22826;&#22810;&#39069;&#22806;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#19968;&#31181;&#31616;&#21333;&#23454;&#29616;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#20855;&#26377;&#29978;&#33267;&#31435;&#26041;&#38750;&#32447;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#20934;&#30830;&#24615;&#65292;&#32780;&#19981;&#38656;&#35201;&#22826;&#22810;&#39069;&#22806;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#36890;&#36807;&#19968;&#31181;&#26126;&#26174;&#30340;&#25910;&#25947;&#19982;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#26469;&#23454;&#29616;&#12290;&#35813;&#28608;&#27963;&#20989;&#25968;&#36890;&#36807;&#24341;&#20837;&#21487;&#20248;&#21270;&#21442;&#25968;&#26469;&#27867;&#21270;&#26631;&#20934;RELU&#20989;&#25968;&#65292;&#20174;&#32780;&#22686;&#21152;&#20102;&#39069;&#22806;&#30340;&#33258;&#30001;&#24230;&#65292;&#20351;&#24471;&#38750;&#32447;&#24615;&#31243;&#24230;&#21487;&#20197;&#34987;&#35843;&#25972;&#12290;&#36890;&#36807;&#19982;&#26631;&#20934;&#25216;&#26415;&#36827;&#34892;&#27604;&#36739;&#65292;&#23558;&#22312;MNIST&#25968;&#23383;&#25968;&#25454;&#38598;&#30340;&#32972;&#26223;&#19979;&#37327;&#21270;&#30456;&#20851;&#20934;&#30830;&#24615;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19896v1 Announce Type: new  Abstract: A simply implemented activation function with even cubic nonlinearity is introduced that increases the accuracy of neural networks without substantial additional computational resources. This is partially enabled through an apparent tradeoff between convergence and accuracy. The activation function generalizes the standard RELU function by introducing additional degrees of freedom through optimizable parameters that enable the degree of nonlinearity to be adjusted. The associated accuracy enhancement is quantified in the context of the MNIST digit data set through a comparison with standard techniques.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#21183;&#22312;&#33258;&#30001;&#33021;&#35745;&#31639;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#20351;&#29992;&#31561;&#21464;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;MLPs&#26469;&#20934;&#30830;&#39044;&#27979;&#33258;&#30001;&#33021;&#21644;&#36807;&#28193;&#24577;&#65292;&#32771;&#34385;&#21040;&#20998;&#23376;&#26500;&#22411;&#30340;&#33021;&#37327;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.13952</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#30456;&#20114;&#20316;&#29992;&#21183;&#22312;&#33258;&#30001;&#33021;&#35745;&#31639;&#20013;&#30340;&#24212;&#29992;&#32771;&#34385;
&lt;/p&gt;
&lt;p&gt;
Considerations in the use of ML interaction potentials for free energy calculations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13952
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#21183;&#22312;&#33258;&#30001;&#33021;&#35745;&#31639;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#20351;&#29992;&#31561;&#21464;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;MLPs&#26469;&#20934;&#30830;&#39044;&#27979;&#33258;&#30001;&#33021;&#21644;&#36807;&#28193;&#24577;&#65292;&#32771;&#34385;&#21040;&#20998;&#23376;&#26500;&#22411;&#30340;&#33021;&#37327;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21183;&#65288;MLPs&#65289;&#20855;&#26377;&#20934;&#30830;&#24314;&#27169;&#20998;&#23376;&#33021;&#37327;&#21644;&#33258;&#30001;&#33021;&#26223;&#35266;&#30340;&#28508;&#21147;&#65292;&#35813;&#20934;&#30830;&#24615;&#21487;&#23218;&#32654;&#37327;&#23376;&#21147;&#23398;&#65292;&#24182;&#20855;&#26377;&#31867;&#20284;&#32463;&#20856;&#27169;&#25311;&#30340;&#25928;&#29575;&#12290;&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#20351;&#29992;&#31561;&#21464;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;MLPs&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#24314;&#27169;&#24179;&#34913;&#20998;&#23376;&#36712;&#36857;&#20013;&#24050;&#34987;&#35777;&#26126;&#26377;&#25928;&#12290;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;MLPs&#33021;&#21542;&#20934;&#30830;&#39044;&#27979;&#33258;&#30001;&#33021;&#21644;&#36807;&#28193;&#24577;&#65292;&#35201;&#32771;&#34385;&#20998;&#23376;&#26500;&#22411;&#30340;&#33021;&#37327;&#21644;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#26816;&#26597;&#20102;&#35757;&#32451;&#25968;&#25454;&#20013;&#38598;&#20307;&#21464;&#37327;&#65288;CVs&#65289;&#30340;&#20998;&#24067;&#22914;&#20309;&#24433;&#21709;MLP&#22312;&#30830;&#23450;&#31995;&#32479;&#33258;&#30001;&#33021;&#38754;&#65288;FES&#65289;&#26102;&#30340;&#20934;&#30830;&#24615;&#65292;&#20351;&#29992;Metadynamics&#27169;&#25311;&#23545;&#19969;&#28919;&#21644;&#19993;&#27688;&#37240;&#20108;&#32957;&#65288;ADP&#65289;&#36827;&#34892;&#23454;&#39564;&#12290;&#35813;&#30740;&#31350;&#28041;&#21450;&#23545;&#22235;&#21313;&#19977;&#20010;MLP&#36827;&#34892;&#35757;&#32451;&#65292;&#20854;&#20013;&#19968;&#21322;&#22522;&#20110;&#32463;&#20856;&#20998;&#23376;&#21160;&#21147;&#23398;&#25968;&#25454;&#65292;&#20854;&#20313;&#30340;&#22522;&#20110;&#20174;&#22836;&#35745;&#31639;&#30340;&#33021;&#37327;&#12290;&#36825;&#20123;MLPs&#36827;&#34892;&#20102;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13952v1 Announce Type: cross  Abstract: Machine learning potentials (MLPs) offer the potential to accurately model the energy and free energy landscapes of molecules with the precision of quantum mechanics and an efficiency similar to classical simulations. This research focuses on using equivariant graph neural networks MLPs due to their proven effectiveness in modeling equilibrium molecular trajectories. A key issue addressed is the capability of MLPs to accurately predict free energies and transition states by considering both the energy and the diversity of molecular configurations. We examined how the distribution of collective variables (CVs) in the training data affects MLP accuracy in determining the free energy surface (FES) of systems, using Metadynamics simulations for butane and alanine dipeptide (ADP). The study involved training forty-three MLPs, half based on classical molecular dynamics data and the rest on ab initio computed energies. The MLPs were trained u
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20449;&#24687;&#35770;&#26694;&#26550;&#20998;&#26512;&#20102;&#26368;&#20808;&#36827;&#30340;&#20284;&#28982;&#27604;&#25915;&#20987;&#23545;&#19981;&#30830;&#23450;&#24615;&#12289;&#26657;&#20934;&#27700;&#24179;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#20102;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#20013;&#38544;&#21547;&#30340;&#39118;&#38505;</title><link>https://arxiv.org/abs/2402.10686</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#12289;&#26657;&#20934;&#21644;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#65306;&#20449;&#24687;&#35770;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Uncertainty, Calibration, and Membership Inference Attacks: An Information-Theoretic Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10686
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20449;&#24687;&#35770;&#26694;&#26550;&#20998;&#26512;&#20102;&#26368;&#20808;&#36827;&#30340;&#20284;&#28982;&#27604;&#25915;&#20987;&#23545;&#19981;&#30830;&#23450;&#24615;&#12289;&#26657;&#20934;&#27700;&#24179;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#20102;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#20013;&#38544;&#21547;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#65288;MIA&#65289;&#20013;&#65292;&#25915;&#20987;&#32773;&#21033;&#29992;&#20856;&#22411;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#20986;&#30340;&#36807;&#24230;&#33258;&#20449;&#26469;&#30830;&#23450;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#34987;&#29992;&#20110;&#35757;&#32451;&#30446;&#26631;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#20449;&#24687;&#29702;&#35770;&#26694;&#26550;&#20869;&#20998;&#26512;&#20102;&#26368;&#20808;&#36827;&#30340;&#20284;&#28982;&#27604;&#25915;&#20987;&#65288;LiRA&#65289;&#30340;&#24615;&#33021;&#65292;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#20801;&#35768;&#30740;&#31350;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#30001;&#26377;&#38480;&#35757;&#32451;&#25968;&#25454;&#38598;&#24341;&#36215;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#20197;&#21450;&#30446;&#26631;&#27169;&#22411;&#30340;&#26657;&#20934;&#27700;&#24179;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#25915;&#20987;&#32773;&#20174;&#30446;&#26631;&#27169;&#22411;&#25509;&#25910;&#21040;&#30340;&#20449;&#24687;&#36880;&#28176;&#20943;&#23569;&#65306;&#32622;&#20449;&#21521;&#37327;&#65288;CV&#65289;&#25259;&#38706;&#65292;&#20854;&#20013;&#36755;&#20986;&#27010;&#29575;&#21521;&#37327;&#34987;&#21457;&#24067;&#65307;&#30495;&#23454;&#26631;&#31614;&#32622;&#20449;&#24230;&#65288;TLC&#65289;&#25259;&#38706;&#65292;&#20854;&#20013;&#21482;&#26377;&#27169;&#22411;&#20998;&#37197;&#32473;&#30495;&#23454;&#26631;&#31614;&#30340;&#27010;&#29575;&#26159;&#21487;&#29992;&#30340;&#65307;&#20197;&#21450;&#20915;&#31574;&#38598;&#65288;DS&#65289;&#25259;&#38706;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10686v1 Announce Type: cross  Abstract: In a membership inference attack (MIA), an attacker exploits the overconfidence exhibited by typical machine learning models to determine whether a specific data point was used to train a target model. In this paper, we analyze the performance of the state-of-the-art likelihood ratio attack (LiRA) within an information-theoretical framework that allows the investigation of the impact of the aleatoric uncertainty in the true data generation process, of the epistemic uncertainty caused by a limited training data set, and of the calibration level of the target model. We compare three different settings, in which the attacker receives decreasingly informative feedback from the target model: confidence vector (CV) disclosure, in which the output probability vector is released; true label confidence (TLC) disclosure, in which only the probability assigned to the true label is made available by the model; and decision set (DS) disclosure, in 
&lt;/p&gt;</description></item><item><title>GenSTL&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#31232;&#30095;&#36712;&#36857;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#22238;&#24402;&#29983;&#25104;&#29305;&#24449;&#22495;&#26469;&#23454;&#29616;&#31232;&#30095;&#36712;&#36857;&#19982;&#23494;&#38598;&#36712;&#36857;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#20174;&#32780;&#28040;&#38500;&#20102;&#23545;&#22823;&#35268;&#27169;&#23494;&#38598;&#36712;&#36857;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;</title><link>https://arxiv.org/abs/2402.07232</link><description>&lt;p&gt;
GenSTL: &#36890;&#36807;&#29305;&#24449;&#22495;&#30340;&#33258;&#22238;&#24402;&#29983;&#25104;&#23454;&#29616;&#36890;&#29992;&#31232;&#30095;&#36712;&#36857;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
GenSTL: General Sparse Trajectory Learning via Auto-regressive Generation of Feature Domains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07232
&lt;/p&gt;
&lt;p&gt;
GenSTL&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#31232;&#30095;&#36712;&#36857;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#22238;&#24402;&#29983;&#25104;&#29305;&#24449;&#22495;&#26469;&#23454;&#29616;&#31232;&#30095;&#36712;&#36857;&#19982;&#23494;&#38598;&#36712;&#36857;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#20174;&#32780;&#28040;&#38500;&#20102;&#23545;&#22823;&#35268;&#27169;&#23494;&#38598;&#36712;&#36857;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36712;&#36857;&#26159;&#26102;&#38388;&#25139;&#20301;&#32622;&#26679;&#26412;&#30340;&#24207;&#21015;&#12290;&#22312;&#31232;&#30095;&#36712;&#36857;&#20013;&#65292;&#20301;&#32622;&#26679;&#26412;&#30340;&#37319;&#26679;&#26159;&#19981;&#39057;&#32321;&#30340;&#65307;&#23613;&#31649;&#36825;&#31181;&#36712;&#36857;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#24456;&#24120;&#35265;&#65292;&#20294;&#35201;&#20351;&#29992;&#23427;&#20204;&#26469;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#19982;&#20132;&#36890;&#30456;&#20851;&#30340;&#24212;&#29992;&#31243;&#24207;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#35201;&#20040;&#20551;&#35774;&#36712;&#36857;&#26159;&#23494;&#38598;&#37319;&#26679;&#30340;&#24182;&#19988;&#32463;&#36807;&#20934;&#30830;&#30340;&#22320;&#22270;&#21305;&#37197;&#65292;&#35201;&#20040;&#20381;&#36182;&#20110;&#20004;&#38454;&#27573;&#26041;&#26696;&#65292;&#20174;&#32780;&#20135;&#29983;&#27425;&#20248;&#30340;&#24212;&#29992;&#31243;&#24207;&#12290;&#20026;&#20102;&#25193;&#23637;&#31232;&#30095;&#36712;&#36857;&#30340;&#25928;&#29992;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31232;&#30095;&#36712;&#36857;&#23398;&#20064;&#26694;&#26550;GenSTL&#12290;&#35813;&#26694;&#26550;&#32463;&#36807;&#39044;&#35757;&#32451;&#20197;&#20351;&#29992;&#29305;&#24449;&#22495;&#30340;&#33258;&#22238;&#24402;&#29983;&#25104;&#24418;&#25104;&#31232;&#30095;&#36712;&#36857;&#19982;&#23494;&#38598;&#36712;&#36857;&#20043;&#38388;&#30340;&#36830;&#25509;&#12290;GenSTL&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#65292;&#25110;&#32773;&#21487;&#20197;&#20808;&#36827;&#34892;&#24494;&#35843;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;GenSTL&#28040;&#38500;&#20102;&#23545;&#22823;&#35268;&#27169;&#23494;&#38598;&#21644;&#22320;&#22270;&#21305;&#37197;&#36712;&#36857;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;&#20854;&#20013;&#21253;&#25324;&#31934;&#24515;&#35774;&#35745;&#30340;&#29305;&#24449;&#22495;&#32534;&#30721;&#23618;&#21644;&#20998;&#23618;&#30340;...
&lt;/p&gt;
&lt;p&gt;
Trajectories are sequences of timestamped location samples. In sparse trajectories, the locations are sampled infrequently; and while such trajectories are prevalent in real-world settings, they are challenging to use to enable high-quality transportation-related applications. Current methodologies either assume densely sampled and accurately map-matched trajectories, or they rely on two-stage schemes, yielding sub-optimal applications.   To extend the utility of sparse trajectories, we propose a novel sparse trajectory learning framework, GenSTL. The framework is pre-trained to form connections between sparse trajectories and dense counterparts using auto-regressive generation of feature domains. GenSTL can subsequently be applied directly in downstream tasks, or it can be fine-tuned first. This way, GenSTL eliminates the reliance on the availability of large-scale dense and map-matched trajectory data. The inclusion of a well-crafted feature domain encoding layer and a hierarchical m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#35299;&#20915;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.17772</link><description>&lt;p&gt;
&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;
&lt;/p&gt;
&lt;p&gt;
Learning Optimal Classification Trees Robust to Distribution Shifts. (arXiv:2310.17772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#35299;&#20915;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;/&#37096;&#32626;&#25968;&#25454;&#20043;&#38388;&#30340;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#26641;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#32463;&#24120;&#22312;&#39640;&#39118;&#38505;&#29615;&#22659;&#20013;&#20986;&#29616;&#65292;&#20363;&#22914;&#20844;&#20849;&#21355;&#29983;&#21644;&#31038;&#20250;&#24037;&#20316;&#65292;&#20854;&#20013;&#25968;&#25454;&#36890;&#24120;&#26159;&#36890;&#36807;&#33258;&#25105;&#25253;&#21578;&#30340;&#35843;&#26597;&#25910;&#38598;&#30340;&#65292;&#36825;&#20123;&#35843;&#26597;&#23545;&#38382;&#39064;&#30340;&#34920;&#36848;&#26041;&#24335;&#12289;&#35843;&#26597;&#36827;&#34892;&#30340;&#26102;&#38388;&#21644;&#22320;&#28857;&#12289;&#20197;&#21450;&#21463;&#35775;&#32773;&#19982;&#35843;&#26597;&#21592;&#20998;&#20139;&#20449;&#24687;&#30340;&#33298;&#36866;&#31243;&#24230;&#38750;&#24120;&#25935;&#24863;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#30340;&#23398;&#20064;&#26368;&#20248;&#40065;&#26834;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#23398;&#20064;&#26368;&#20248;&#40065;&#26834;&#26641;&#30340;&#38382;&#39064;&#21487;&#20197;&#31561;&#20215;&#22320;&#34920;&#36798;&#20026;&#19968;&#20010;&#20855;&#26377;&#39640;&#24230;&#38750;&#32447;&#24615;&#21644;&#19981;&#36830;&#32493;&#30446;&#26631;&#30340;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31561;&#20215;&#22320;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#20004;&#38454;&#27573;&#32447;&#24615;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#20026;&#27492;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#23450;&#21046;&#35299;&#20915;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning classification trees that are robust to distribution shifts between training and testing/deployment data. This problem arises frequently in high stakes settings such as public health and social work where data is often collected using self-reported surveys which are highly sensitive to e.g., the framing of the questions, the time when and place where the survey is conducted, and the level of comfort the interviewee has in sharing information with the interviewer. We propose a method for learning optimal robust classification trees based on mixed-integer robust optimization technology. In particular, we demonstrate that the problem of learning an optimal robust tree can be cast as a single-stage mixed-integer robust optimization problem with a highly nonlinear and discontinuous objective. We reformulate this problem equivalently as a two-stage linear robust optimization problem for which we devise a tailored solution procedure based on constraint gene
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02293</link><description>&lt;p&gt;
&#29992;&#27491;&#21017;&#21270;&#39640;&#38454;&#24635;&#21464;&#24046;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02293
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#39640;&#24230;&#34920;&#36798;&#30340;&#21442;&#25968;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#24314;&#27169;&#22797;&#26434;&#27010;&#24565;&#65292;&#20294;&#35757;&#32451;&#36825;&#31181;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#24050;&#30693;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#19968;&#31181;k&#38454;&#24635;&#21464;&#24046;&#65288;k-TV&#65289;&#27491;&#21017;&#21270;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#35201;&#35757;&#32451;&#30340;&#21442;&#25968;&#27169;&#22411;&#30340;k&#38454;&#23548;&#25968;&#30340;&#24179;&#26041;&#31215;&#20998;&#65292;&#36890;&#36807;&#24809;&#32602;k-TV&#26469;&#20135;&#29983;&#19968;&#20010;&#26356;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;&#23613;&#31649;&#23558;k-TV&#39033;&#24212;&#29992;&#20110;&#19968;&#33324;&#30340;&#21442;&#25968;&#27169;&#22411;&#30001;&#20110;&#31215;&#20998;&#32780;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#65292;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#24102;&#26377;k-TV&#27491;&#21017;&#21270;&#30340;&#19968;&#33324;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#26174;&#24335;&#30340;&#25968;&#20540;&#31215;&#20998;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#32467;&#26500;&#20219;&#24847;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#36827;&#34892;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#20248;&#21270;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
&lt;/p&gt;</description></item></channel></rss>