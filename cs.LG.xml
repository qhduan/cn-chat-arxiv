<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#21644;&#35299;&#37322;&#26041;&#27861;&#26469;&#30830;&#23450;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#30340;&#27969;&#31243;&#65292;&#36890;&#36807;&#35745;&#31639;&#35299;&#37322;&#20998;&#24067;&#30340;&#21464;&#24322;&#31995;&#25968;&#65292;&#35780;&#20272;&#20102;&#35299;&#37322;&#30340;&#32622;&#20449;&#24230;&#24182;&#30830;&#23450;Guided Backpropagation&#26041;&#27861;&#29983;&#25104;&#30340;&#35299;&#37322;&#20855;&#26377;&#36739;&#20302;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17224</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#22522;&#20110;&#26799;&#24230;&#30340;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification for Gradient-based Explanations in Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#21644;&#35299;&#37322;&#26041;&#27861;&#26469;&#30830;&#23450;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#30340;&#27969;&#31243;&#65292;&#36890;&#36807;&#35745;&#31639;&#35299;&#37322;&#20998;&#24067;&#30340;&#21464;&#24322;&#31995;&#25968;&#65292;&#35780;&#20272;&#20102;&#35299;&#37322;&#30340;&#32622;&#20449;&#24230;&#24182;&#30830;&#23450;Guided Backpropagation&#26041;&#27861;&#29983;&#25104;&#30340;&#35299;&#37322;&#20855;&#26377;&#36739;&#20302;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#26041;&#27861;&#26377;&#21161;&#20110;&#29702;&#35299;&#27169;&#22411;&#39044;&#27979;&#30340;&#21407;&#22240;&#12290;&#36825;&#20123;&#26041;&#27861;&#36234;&#26469;&#36234;&#22810;&#22320;&#21442;&#19982;&#27169;&#22411;&#35843;&#35797;&#12289;&#24615;&#33021;&#20248;&#21270;&#65292;&#24182;&#33719;&#24471;&#23545;&#27169;&#22411;&#24037;&#20316;&#21407;&#29702;&#30340;&#27934;&#35265;&#12290;&#37492;&#20110;&#36825;&#20123;&#26041;&#27861;&#30340;&#20851;&#38190;&#24212;&#29992;&#65292;&#34913;&#37327;&#36825;&#20123;&#26041;&#27861;&#29983;&#25104;&#30340;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#21644;&#35299;&#37322;&#26041;&#27861;&#26469;&#30830;&#23450;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#30340;&#27969;&#31243;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#27969;&#31243;&#20026;CIFAR-10&#12289;FER+&#21644;California Housing&#25968;&#25454;&#38598;&#29983;&#25104;&#35299;&#37322;&#20998;&#24067;&#12290;&#36890;&#36807;&#35745;&#31639;&#36825;&#20123;&#20998;&#24067;&#30340;&#21464;&#24322;&#31995;&#25968;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#35299;&#37322;&#30340;&#32622;&#20449;&#24230;&#65292;&#24182;&#30830;&#23450;&#20351;&#29992;&#24341;&#23548;&#21453;&#21521;&#20256;&#25773;&#29983;&#25104;&#30340;&#35299;&#37322;&#19982;&#20302;&#19981;&#30830;&#23450;&#24615;&#30456;&#20851;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35745;&#31639;&#20102;&#20462;&#25913;&#30340;&#20687;&#32032;&#25554;&#20837;/&#21024;&#38500;&#24230;&#37327;&#26469;&#35780;&#20215;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17224v1 Announce Type: cross  Abstract: Explanation methods help understand the reasons for a model's prediction. These methods are increasingly involved in model debugging, performance optimization, and gaining insights into the workings of a model. With such critical applications of these methods, it is imperative to measure the uncertainty associated with the explanations generated by these methods. In this paper, we propose a pipeline to ascertain the explanation uncertainty of neural networks by combining uncertainty estimation methods and explanation methods. We use this pipeline to produce explanation distributions for the CIFAR-10, FER+, and California Housing datasets. By computing the coefficient of variation of these distributions, we evaluate the confidence in the explanation and determine that the explanations generated using Guided Backpropagation have low uncertainty associated with them. Additionally, we compute modified pixel insertion/deletion metrics to ev
&lt;/p&gt;</description></item><item><title>Cram&#26041;&#27861;&#26159;&#19968;&#31181;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21033;&#29992;&#25972;&#20010;&#26679;&#26412;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#65292;&#27604;&#20256;&#32479;&#30340;&#26679;&#26412;&#20998;&#21106;&#31574;&#30053;&#26356;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2403.07031</link><description>&lt;p&gt;
&#29992;&#20110;&#39640;&#25928;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#30340;Cram&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
The Cram Method for Efficient Simultaneous Learning and Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07031
&lt;/p&gt;
&lt;p&gt;
Cram&#26041;&#27861;&#26159;&#19968;&#31181;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21033;&#29992;&#25972;&#20010;&#26679;&#26412;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#65292;&#27604;&#20256;&#32479;&#30340;&#26679;&#26412;&#20998;&#21106;&#31574;&#30053;&#26356;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#8220;Cram&#8221;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#29992;&#19988;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#36827;&#34892;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#12290;&#22312;&#25209;&#22788;&#29702;&#25968;&#25454;&#30340;&#21333;&#27425;&#20256;&#36882;&#20013;&#65292;&#35813;&#26041;&#27861;&#21453;&#22797;&#35757;&#32451;ML&#31639;&#27861;&#24182;&#27979;&#35797;&#20854;&#32463;&#39564;&#24615;&#33021;&#12290;&#30001;&#20110;&#23427;&#21516;&#26102;&#21033;&#29992;&#20102;&#25972;&#20010;&#26679;&#26412;&#36827;&#34892;&#23398;&#20064;&#21644;&#35780;&#20272;&#65292;&#25152;&#20197;Cram&#26041;&#27861;&#27604;&#26679;&#26412;&#20998;&#21106;&#35201;&#39640;&#25928;&#24471;&#22810;&#12290;Cram&#26041;&#27861;&#36824;&#33258;&#28982;&#22320;&#36866;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20351;&#20854;&#23454;&#26045;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#12290;&#20026;&#20102;&#23637;&#31034;Cram&#26041;&#27861;&#30340;&#24378;&#22823;&#20043;&#22788;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#26631;&#20934;&#31574;&#30053;&#23398;&#20064;&#35774;&#32622;&#65292;&#20854;&#20013;&#23558;Cram&#24212;&#29992;&#20110;&#30456;&#21516;&#25968;&#25454;&#20197;&#24320;&#21457;&#20010;&#24615;&#21270;&#27835;&#30103;&#35268;&#21017;&#65288;ITR&#65289;&#24182;&#20272;&#35745;&#22914;&#26524;&#23398;&#20064;&#30340;ITR&#34987;&#37096;&#32626;&#23558;&#20250;&#20135;&#29983;&#30340;&#24179;&#22343;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26368;&#23567;&#19968;&#32452;&#20551;&#35774;&#19979;&#65292;&#30001;&#27492;&#20135;&#29983;&#30340;Cram&#35780;&#20272;&#20272;&#35745;&#22120;&#26159;&#19968;&#33268;&#19988;&#28176;&#36817;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07031v1 Announce Type: new  Abstract: We introduce the "cram" method, a general and efficient approach to simultaneous learning and evaluation using a generic machine learning (ML) algorithm. In a single pass of batched data, the proposed method repeatedly trains an ML algorithm and tests its empirical performance. Because it utilizes the entire sample for both learning and evaluation, cramming is significantly more data-efficient than sample-splitting. The cram method also naturally accommodates online learning algorithms, making its implementation computationally efficient. To demonstrate the power of the cram method, we consider the standard policy learning setting where cramming is applied to the same data to both develop an individualized treatment rule (ITR) and estimate the average outcome that would result if the learned ITR were to be deployed. We show that under a minimal set of assumptions, the resulting crammed evaluation estimator is consistent and asymptoticall
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20351;&#29992;&#21069;&#21521;&#20256;&#36882;&#30340;LLM&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#65292;&#36890;&#36807;Bonsai&#29983;&#25104;&#30340;&#20462;&#21098;&#27169;&#22411;&#22312;&#24615;&#33021;&#19978;&#20248;&#20110;&#26799;&#24230;-based&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#65292;&#24182;&#19988;&#36895;&#24230;&#26159;&#21322;&#32467;&#26500;&#21270;&#20462;&#21098;&#27169;&#22411;&#30340;&#20004;&#20493;&#12290;</title><link>https://arxiv.org/abs/2402.05406</link><description>&lt;p&gt;
&#29616;&#22312;&#25152;&#26377;&#20154;&#37117;&#20462;&#21098;&#65306;&#20165;&#20351;&#29992;&#21069;&#21521;&#20256;&#36882;&#30340;LLM&#32467;&#26500;&#21270;&#20462;&#21098;
&lt;/p&gt;
&lt;p&gt;
Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20351;&#29992;&#21069;&#21521;&#20256;&#36882;&#30340;LLM&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#65292;&#36890;&#36807;Bonsai&#29983;&#25104;&#30340;&#20462;&#21098;&#27169;&#22411;&#22312;&#24615;&#33021;&#19978;&#20248;&#20110;&#26799;&#24230;-based&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#65292;&#24182;&#19988;&#36895;&#24230;&#26159;&#21322;&#32467;&#26500;&#21270;&#20462;&#21098;&#27169;&#22411;&#30340;&#20004;&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#38750;&#19987;&#19994;&#20174;&#19994;&#32773;&#21644;&#26368;&#23500;&#26377;&#36164;&#28304;&#30340;&#26426;&#26500;&#20043;&#38388;&#30340;&#30828;&#20214;&#24046;&#36317;&#65292;&#23610;&#23544;&#19981;&#26029;&#22686;&#38271;&#30340;LLM&#21464;&#24471;&#36234;&#26469;&#36234;&#38590;&#20197;&#20351;&#29992;&#12290;&#34429;&#28982;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#26469;&#21387;&#32553;LLM&#65292;&#20197;&#20351;&#20854;&#36164;&#28304;&#28040;&#32791;&#21487;&#31649;&#29702;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#26412;&#36523;&#24448;&#24448;&#32791;&#36153;&#36164;&#28304;&#65292;&#20351;&#20854;&#30446;&#26631;&#29992;&#25143;&#32676;&#26080;&#27861;&#25509;&#35302;&#21040;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#20165;&#20351;&#29992;&#21069;&#21521;&#20256;&#36882;&#30340;LLM&#32467;&#26500;&#21270;&#20462;&#21098;&#38382;&#39064;&#12290;&#25105;&#20204;&#24076;&#26395;&#35753;&#20174;&#19994;&#32773;&#33021;&#22815;&#20462;&#21098;&#27169;&#22411;&#65292;&#20351;&#20854;&#35268;&#27169;&#22823;&#21040;&#30828;&#20214;&#20165;&#26377;&#36275;&#22815;&#30340;&#20869;&#23384;&#26469;&#36816;&#34892;&#25512;&#29702;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;Bonsai&#65292;&#36825;&#26159;&#19968;&#31181;&#26080;&#26799;&#24230;&#12289;&#25200;&#21160;&#20462;&#21098;&#26041;&#27861;&#65292;&#33021;&#22815;&#29983;&#25104;&#23567;&#12289;&#24555;&#21644;&#20934;&#30830;&#30340;&#20462;&#21098;&#27169;&#22411;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;Bonsai&#29983;&#25104;&#30340;&#20462;&#21098;&#27169;&#22411;&#65288;i&#65289;&#20248;&#20110;&#26356;&#26114;&#36149;&#30340;&#26799;&#24230;-based&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#29983;&#25104;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#65288;ii&#65289;&#19982;&#21322;&#32467;&#26500;&#21270;&#20462;&#21098;&#27169;&#22411;&#30456;&#27604;&#65292;&#36895;&#24230;&#24555;&#19968;&#20493;&#19988;&#20934;&#30830;&#24615;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given the generational gap in available hardware between lay practitioners and the most endowed institutions, LLMs are becoming increasingly inaccessible as they grow in size. Whilst many approaches have been proposed to compress LLMs to make their resource consumption manageable, these methods themselves tend to be resource intensive, putting them out of the reach of the very user groups they target. In this work, we explore the problem of structured pruning of LLMs using only forward passes. We seek to empower practitioners to prune models so large that their available hardware has just enough memory to run inference. We develop Bonsai, a gradient-free, perturbative pruning method capable of delivering small, fast, and accurate pruned models.   We observe that Bonsai outputs pruned models that (i) outperform those generated by more expensive gradient-based structured pruning methods, and (ii) are twice as fast (with comparable accuracy) as those generated by semi-structured pruning m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#38024;&#23545;&#19968;&#31181;&#26032;&#22411;&#38544;&#31169;&#25915;&#20987;&#8212;&#8212;&#31038;&#21306;&#26816;&#27979;&#25915;&#20987;&#65288;CDA&#65289;&#30340;&#38887;&#24615;&#12290;</title><link>https://arxiv.org/abs/2306.08929</link><description>&lt;p&gt;
&#20851;&#20110;&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#38024;&#23545;&#31038;&#21306;&#26816;&#27979;&#25915;&#20987;&#30340;&#38887;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the resilience of Collaborative Learning-based Recommender Systems Against Community Detection Attack
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2306.08929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#38024;&#23545;&#19968;&#31181;&#26032;&#22411;&#38544;&#31169;&#25915;&#20987;&#8212;&#8212;&#31038;&#21306;&#26816;&#27979;&#25915;&#20987;&#65288;CDA&#65289;&#30340;&#38887;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#28304;&#20110;&#21327;&#20316;&#23398;&#20064;&#25216;&#26415;&#65288;&#22914;&#32852;&#37030;&#23398;&#20064;&#21644;&#20843;&#21350;&#23398;&#20064;&#65289;&#30340;&#25104;&#21151;&#12290;&#22312;&#36825;&#20123;&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#21442;&#19982;&#25512;&#33616;&#31995;&#32479;&#30340;&#35757;&#32451;&#21516;&#26102;&#22312;&#20854;&#35774;&#22791;&#19978;&#20445;&#30041;&#24050;&#28040;&#36153;&#39033;&#30446;&#30340;&#21382;&#21490;&#35760;&#24405;&#12290;&#34429;&#28982;&#36825;&#20123;&#35299;&#20915;&#26041;&#26696;&#20045;&#19968;&#30475;&#20284;&#20046;&#26377;&#21033;&#20110;&#20445;&#25252;&#21442;&#19982;&#32773;&#30340;&#38544;&#31169;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21327;&#20316;&#23398;&#20064;&#21487;&#33021;&#23481;&#26131;&#21463;&#21040;&#21508;&#31181;&#38544;&#31169;&#25915;&#20987;&#30340;&#23041;&#32961;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#21327;&#20316;&#23398;&#20064;&#25512;&#33616;&#31995;&#32479;&#38024;&#23545;&#19968;&#31181;&#31216;&#20026;&#31038;&#21306;&#26816;&#27979;&#25915;&#20987;&#65288;CDA&#65289;&#30340;&#26032;&#22411;&#38544;&#31169;&#25915;&#20987;&#30340;&#38887;&#24615;&#12290;&#36825;&#31181;&#25915;&#20987;&#20351;&#24471;&#23545;&#25163;&#33021;&#22815;&#22522;&#20110;&#19968;&#20010;&#36873;&#25321;&#30340;&#39033;&#30446;&#38598;&#65288;&#22914;&#35782;&#21035;&#23545;&#29305;&#23450;&#20852;&#36259;&#28857;&#24863;&#20852;&#36259;&#30340;&#29992;&#25143;&#65289;&#26469;&#35782;&#21035;&#31038;&#21306;&#25104;&#21592;&#12290;&#36890;&#36807;&#22312;&#19977;&#20010;&#30495;&#23454;&#25512;&#33616;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#20351;&#29992;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
arXiv:2306.08929v2 Announce Type: replace-cross  Abstract: Collaborative-learning-based recommender systems emerged following the success of collaborative learning techniques such as Federated Learning (FL) and Gossip Learning (GL). In these systems, users participate in the training of a recommender system while maintaining their history of consumed items on their devices. While these solutions seemed appealing for preserving the privacy of the participants at first glance, recent studies have revealed that collaborative learning can be vulnerable to various privacy attacks. In this paper, we study the resilience of collaborative learning-based recommender systems against a novel privacy attack called Community Detection Attack (CDA). This attack enables an adversary to identify community members based on a chosen set of items (eg., identifying users interested in specific points-of-interest). Through experiments on three real recommendation datasets using two state-of-the-art recomme
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#22797;&#26434;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#30340;&#20915;&#31574;&#32452;&#20214;&#65292;&#36890;&#36807;&#35748;&#30693;&#36335;&#24452;&#21644;&#31639;&#27861;&#26469;&#23454;&#29616;&#20840;&#38754;&#25512;&#29702;&#21644;&#21487;&#25191;&#34892;&#39550;&#39542;&#25351;&#20196;&#30340;&#36716;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LLMs&#33021;&#22815;&#22312;&#21333;&#36710;&#20219;&#21153;&#21644;&#22797;&#26434;&#39550;&#39542;&#34892;&#20026;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#36825;&#26159;&#22240;&#20026;&#20854;&#20855;&#26377;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.03026</link><description>&lt;p&gt;
LanguageMPC&#65306;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#21160;&#39550;&#39542;&#20915;&#31574;&#32773;
&lt;/p&gt;
&lt;p&gt;
LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving. (arXiv:2310.03026v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03026
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#22797;&#26434;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#30340;&#20915;&#31574;&#32452;&#20214;&#65292;&#36890;&#36807;&#35748;&#30693;&#36335;&#24452;&#21644;&#31639;&#27861;&#26469;&#23454;&#29616;&#20840;&#38754;&#25512;&#29702;&#21644;&#21487;&#25191;&#34892;&#39550;&#39542;&#25351;&#20196;&#30340;&#36716;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LLMs&#33021;&#22815;&#22312;&#21333;&#36710;&#20219;&#21153;&#21644;&#22797;&#26434;&#39550;&#39542;&#34892;&#20026;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#36825;&#26159;&#22240;&#20026;&#20854;&#20855;&#26377;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#22522;&#20110;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#22312;&#29702;&#35299;&#39640;&#32423;&#20449;&#24687;&#12289;&#25512;&#24191;&#32597;&#35265;&#20107;&#20214;&#21644;&#25552;&#20379;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#22797;&#26434;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#30340;&#20915;&#31574;&#32452;&#20214;&#65292;&#38656;&#35201;&#20154;&#31867;&#24120;&#35782;&#29702;&#35299;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#35748;&#30693;&#36335;&#24452;&#65292;&#20351;LLMs&#33021;&#22815;&#36827;&#34892;&#20840;&#38754;&#25512;&#29702;&#65292;&#24182;&#24320;&#21457;&#20102;&#23558;LLM&#20915;&#31574;&#36716;&#21270;&#20026;&#21487;&#25191;&#34892;&#39550;&#39542;&#25351;&#20196;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;LLM&#20915;&#31574;&#36890;&#36807;&#24341;&#23548;&#21442;&#25968;&#30697;&#38453;&#36866;&#24212;&#19982;&#20302;&#32423;&#25511;&#21046;&#22120;&#26080;&#32541;&#38598;&#25104;&#12290;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19981;&#20165;&#22312;&#21333;&#36710;&#20219;&#21153;&#20013;&#22987;&#32456;&#36229;&#36234;&#22522;&#32447;&#26041;&#27861;&#65292;&#32780;&#19988;&#36824;&#33021;&#22788;&#29702;&#22797;&#26434;&#30340;&#39550;&#39542;&#34892;&#20026;&#65292;&#29978;&#33267;&#22810;&#36710;&#21327;&#35843;&#65292;&#36825;&#35201;&#24402;&#21151;&#20110;LLMs&#30340;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;LLMs&#20316;&#20026;&#26377;&#25928;&#20915;&#31574;&#32773;&#30340;&#21021;&#27493;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing learning-based autonomous driving (AD) systems face challenges in comprehending high-level information, generalizing to rare events, and providing interpretability. To address these problems, this work employs Large Language Models (LLMs) as a decision-making component for complex AD scenarios that require human commonsense understanding. We devise cognitive pathways to enable comprehensive reasoning with LLMs, and develop algorithms for translating LLM decisions into actionable driving commands. Through this approach, LLM decisions are seamlessly integrated with low-level controllers by guided parameter matrix adaptation. Extensive experiments demonstrate that our proposed method not only consistently surpasses baseline approaches in single-vehicle tasks, but also helps handle complex driving behaviors even multi-vehicle coordination, thanks to the commonsense reasoning capabilities of LLMs. This paper presents an initial step toward leveraging LLMs as effective decision-make
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25581;&#31034;&#20102;&#22522;&#20110;Hinge Loss&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#20108;&#20998;&#31867;&#22120;&#30340;&#22522;&#26412;&#27979;&#35797;&#24615;&#33021;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.06774</link><description>&lt;p&gt;
&#22522;&#20110;Hinge Loss&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#20108;&#20998;&#31867;&#22120;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fundamental Limits of Deep Learning-Based Binary Classifiers Trained with Hinge Loss. (arXiv:2309.06774v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#22522;&#20110;Hinge Loss&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#20108;&#20998;&#31867;&#22120;&#30340;&#22522;&#26412;&#27979;&#35797;&#24615;&#33021;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#21270;&#23398;&#12289;&#35745;&#31639;&#26426;&#31185;&#23398;&#12289;&#30005;&#23376;&#24037;&#31243;&#12289;&#25968;&#23398;&#12289;&#21307;&#23398;&#12289;&#31070;&#32463;&#31185;&#23398;&#21644;&#29289;&#29702;&#23398;&#31561;&#22810;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#22823;&#31361;&#30772;&#65292;&#20294;&#23545;&#20110;&#20026;&#20160;&#20040;&#21644;&#22914;&#20309;&#33719;&#24471;&#32463;&#39564;&#25104;&#21151;&#30340;&#20840;&#38754;&#29702;&#35299;&#20173;&#28982;&#22522;&#26412;&#38590;&#20197;&#25226;&#25569;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#26681;&#26412;&#38382;&#39064;&#24182;&#25581;&#31034;&#28145;&#24230;&#23398;&#20064;&#32972;&#21518;&#30340;&#22885;&#31192;&#65292;&#24050;&#32463;&#22312;&#24314;&#31435;&#32479;&#19968;&#29702;&#35770;&#30340;&#26041;&#21521;&#19978;&#21462;&#24471;&#20102;&#37325;&#22823;&#21019;&#26032;&#12290;&#36825;&#20123;&#21019;&#26032;&#21253;&#25324;&#20248;&#21270;&#12289;&#27867;&#21270;&#21644;&#36817;&#20284;&#31561;&#22522;&#30784;&#24615;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#36824;&#27809;&#26377;&#19968;&#20010;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#37327;&#21270;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#22312;&#35299;&#20915;&#27169;&#24335;&#20998;&#31867;&#38382;&#39064;&#26102;&#30340;&#27979;&#35797;&#24615;&#33021;&#12290;&#20026;&#20102;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#20811;&#26381;&#36825;&#20010;&#22522;&#26412;&#25361;&#25112;&#65292;&#26412;&#25991;&#25581;&#31034;&#20102;&#22522;&#20110;Hinge Loss&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#20108;&#20998;&#31867;&#22120;&#30340;&#22522;&#26412;&#27979;&#35797;&#24615;&#33021;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although deep learning (DL) has led to several breakthroughs in many disciplines as diverse as chemistry, computer science, electrical engineering, mathematics, medicine, neuroscience, and physics, a comprehensive understanding of why and how DL is empirically successful remains fundamentally elusive. To attack this fundamental problem and unravel the mysteries behind DL's empirical successes, significant innovations toward a unified theory of DL have been made. These innovations encompass nearly fundamental advances in optimization, generalization, and approximation. Despite these advances, however, no work to date has offered a way to quantify the testing performance of a DL-based algorithm employed to solve a pattern classification problem. To overcome this fundamental challenge in part, this paper exposes the fundamental testing performance limits of DL-based binary classifiers trained with hinge loss. For binary classifiers that are based on deep rectified linear unit (ReLU) feedf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20855;&#26377;&#32463;&#39564;&#22238;&#25918;&#30340;TD&#23398;&#20064;&#65292;&#22312;&#39532;&#23572;&#31185;&#22827;&#35266;&#27979;&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#23545;&#22122;&#22768;&#39033;&#30340;&#20998;&#35299;&#65292;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#35823;&#24046;&#30028;&#38480;&#65292;&#21487;&#20197;&#36890;&#36807;&#35843;&#25972;&#22238;&#25918;&#32531;&#20914;&#21306;&#21644;&#23567;&#25209;&#37327;&#30340;&#22823;&#23567;&#26469;&#25511;&#21046;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.09746</link><description>&lt;p&gt;
&#12298;&#20855;&#26377;&#32463;&#39564;&#22238;&#25918;&#30340;&#26102;&#24207;&#24046;&#20998;&#23398;&#20064;&#12299;
&lt;/p&gt;
&lt;p&gt;
Temporal Difference Learning with Experience Replay. (arXiv:2306.09746v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09746
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20855;&#26377;&#32463;&#39564;&#22238;&#25918;&#30340;TD&#23398;&#20064;&#65292;&#22312;&#39532;&#23572;&#31185;&#22827;&#35266;&#27979;&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#23545;&#22122;&#22768;&#39033;&#30340;&#20998;&#35299;&#65292;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#35823;&#24046;&#30028;&#38480;&#65292;&#21487;&#20197;&#36890;&#36807;&#35843;&#25972;&#22238;&#25918;&#32531;&#20914;&#21306;&#21644;&#23567;&#25209;&#37327;&#30340;&#22823;&#23567;&#26469;&#25511;&#21046;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#24207;&#24046;&#20998;&#23398;&#20064;&#34987;&#26222;&#36941;&#35748;&#20026;&#26159;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#31639;&#27861;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20854;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#65292;&#21253;&#25324;&#22343;&#26041;&#35823;&#24046;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#12290;&#22312;&#32463;&#39564;&#26041;&#38754;&#65292;&#32463;&#39564;&#22238;&#25918;&#26159;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25104;&#21151;&#30340;&#20851;&#38190;&#22240;&#32032;&#20043;&#19968;&#65292;&#20294;&#20854;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#29702;&#35770;&#25928;&#24212;&#23578;&#26410;&#34987;&#23436;&#20840;&#29702;&#35299;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#39532;&#23572;&#31185;&#22827;&#22122;&#22768;&#39033;&#30340;&#31616;&#21333;&#20998;&#35299;&#65292;&#24182;&#20026;&#20855;&#26377;&#32463;&#39564;&#22238;&#25918;&#30340;TD&#23398;&#20064;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#35823;&#24046;&#30028;&#38480;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#39532;&#23572;&#31185;&#22827;&#35266;&#27979;&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#24179;&#22343;&#36845;&#20195;&#21644;&#26368;&#32456;&#36845;&#20195;&#24773;&#20917;&#19979;&#65292;&#24120;&#25968;&#27493;&#38271;&#24341;&#36215;&#30340;&#35823;&#24046;&#26415;&#35821;&#21487;&#20197;&#36890;&#36807;&#22238;&#25918;&#32531;&#20914;&#21306;&#30340;&#22823;&#23567;&#21644;&#20174;&#32463;&#39564;&#22238;&#25918;&#32531;&#20914;&#21306;&#20013;&#25277;&#26679;&#30340;&#23567;&#25209;&#37327;&#26469;&#26377;&#25928;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal-difference (TD) learning is widely regarded as one of the most popular algorithms in reinforcement learning (RL). Despite its widespread use, it has only been recently that researchers have begun to actively study its finite time behavior, including the finite time bound on mean squared error and sample complexity. On the empirical side, experience replay has been a key ingredient in the success of deep RL algorithms, but its theoretical effects on RL have yet to be fully understood. In this paper, we present a simple decomposition of the Markovian noise terms and provide finite-time error bounds for TD-learning with experience replay. Specifically, under the Markovian observation model, we demonstrate that for both the averaged iterate and final iterate cases, the error term induced by a constant step-size can be effectively controlled by the size of the replay buffer and the mini-batch sampled from the experience replay buffer.
&lt;/p&gt;</description></item><item><title>Awesome-META+&#26159;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#38598;&#25104;&#21644;&#23398;&#20064;&#24179;&#21488;&#65292;&#26088;&#22312;&#25552;&#20379;&#23436;&#25972;&#21487;&#38752;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#24212;&#29992;&#21644;&#38754;&#21521;&#21021;&#23398;&#32773;&#30340;&#23398;&#20064;&#26448;&#26009;&#65292;&#36827;&#32780;&#20419;&#36827;&#20803;&#23398;&#20064;&#30340;&#21457;&#23637;&#24182;&#23558;&#20854;&#20174;&#23567;&#20247;&#39046;&#22495;&#36716;&#21270;&#20026;&#20027;&#27969;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2304.12921</link><description>&lt;p&gt;
Awesome-META+: &#20803;&#23398;&#20064;&#30740;&#31350;&#19982;&#23398;&#20064;&#24179;&#21488;
&lt;/p&gt;
&lt;p&gt;
Awesome-META+: Meta-Learning Research and Learning Platform. (arXiv:2304.12921v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12921
&lt;/p&gt;
&lt;p&gt;
Awesome-META+&#26159;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#38598;&#25104;&#21644;&#23398;&#20064;&#24179;&#21488;&#65292;&#26088;&#22312;&#25552;&#20379;&#23436;&#25972;&#21487;&#38752;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#24212;&#29992;&#21644;&#38754;&#21521;&#21021;&#23398;&#32773;&#30340;&#23398;&#20064;&#26448;&#26009;&#65292;&#36827;&#32780;&#20419;&#36827;&#20803;&#23398;&#20064;&#30340;&#21457;&#23637;&#24182;&#23558;&#20854;&#20174;&#23567;&#20247;&#39046;&#22495;&#36716;&#21270;&#20026;&#20027;&#27969;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#24050;&#32463;&#22312;&#32463;&#27982;&#12289;&#20135;&#19994;&#12289;&#25945;&#32946;&#31561;&#21508;&#20010;&#39046;&#22495;&#20135;&#29983;&#20102;&#28145;&#36828;&#30340;&#24433;&#21709;&#65292;&#20294;&#36824;&#23384;&#22312;&#35832;&#22810;&#38480;&#21046;&#12290;&#20803;&#23398;&#20064;&#65292;&#20063;&#31216;&#20026;&#8220;&#23398;&#20064;&#22914;&#20309;&#23398;&#20064;&#8221;&#65292;&#20026;&#36890;&#29992;&#20154;&#24037;&#26234;&#33021;&#25552;&#20379;&#20102;&#31361;&#30772;&#30446;&#21069;&#29942;&#39048;&#30340;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#20803;&#23398;&#20064;&#36215;&#27493;&#36739;&#26202;&#65292;&#30456;&#27604;CV&#12289;NLP&#31561;&#39046;&#22495;&#65292;&#39033;&#30446;&#25968;&#37327;&#36739;&#23569;&#12290;&#27599;&#27425;&#37096;&#32626;&#37117;&#38656;&#35201;&#22823;&#37327;&#30340;&#32463;&#39564;&#21435;&#37197;&#32622;&#29615;&#22659;&#12289;&#35843;&#35797;&#20195;&#30721;&#29978;&#33267;&#37325;&#20889;&#65292;&#32780;&#19988;&#26694;&#26550;&#20043;&#38388;&#30456;&#23545;&#23396;&#31435;&#12290;&#27492;&#22806;&#65292;&#30446;&#21069;&#38024;&#23545;&#20803;&#23398;&#20064;&#30340;&#19987;&#38376;&#24179;&#21488;&#21644;&#38754;&#21521;&#21021;&#23398;&#32773;&#30340;&#23398;&#20064;&#26448;&#26009;&#30456;&#23545;&#36739;&#23569;&#65292;&#38376;&#27099;&#30456;&#23545;&#36739;&#39640;&#12290;&#22522;&#20110;&#27492;&#65292;Awesome-META+&#25552;&#20986;&#20102;&#19968;&#20010;&#20803;&#23398;&#20064;&#26694;&#26550;&#38598;&#25104;&#21644;&#23398;&#20064;&#24179;&#21488;&#65292;&#26088;&#22312;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#24182;&#25552;&#20379;&#23436;&#25972;&#21487;&#38752;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#24212;&#29992;&#21644;&#23398;&#20064;&#24179;&#21488;&#12290;&#35813;&#39033;&#30446;&#26088;&#22312;&#20419;&#36827;&#20803;&#23398;&#20064;&#30340;&#21457;&#23637;&#65292;&#24182;&#23558;&#20854;&#20174;&#19968;&#20010;&#23567;&#20247;&#39046;&#22495;&#36716;&#21270;&#20026;&#19968;&#20010;&#20027;&#27969;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence technology has already had a profound impact in various fields such as economy, industry, and education, but still limited. Meta-learning, also known as "learning to learn", provides an opportunity for general artificial intelligence, which can break through the current AI bottleneck. However, meta learning started late and there are fewer projects compare with CV, NLP etc. Each deployment requires a lot of experience to configure the environment, debug code or even rewrite, and the frameworks are isolated. Moreover, there are currently few platforms that focus exclusively on meta-learning, or provide learning materials for novices, for which the threshold is relatively high. Based on this, Awesome-META+, a meta-learning framework integration and learning platform is proposed to solve the above problems and provide a complete and reliable meta-learning framework application and learning platform. The project aims to promote the development of meta-learning and t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#19979;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#36716;&#25442;&#24605;&#24819;&#21644;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.03807</link><description>&lt;p&gt;
&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving CNN Training with Transfer Learning. (arXiv:2304.03807v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36801;&#31227;&#23398;&#20064;&#23454;&#29616;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#19979;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#36716;&#25442;&#24605;&#24819;&#21644;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#31169;&#20445;&#25252;&#30340;&#31070;&#32463;&#32593;&#32476;&#25512;&#29702;&#24050;&#32463;&#24471;&#21040;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#20445;&#25345;&#21516;&#24577;CNN&#35757;&#32451;&#20173;&#28982;&#26159;&#19968;&#39033;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#23454;&#29616;&#22522;&#20110;&#21516;&#24577;&#21152;&#23494;&#25216;&#26415;&#30340;&#38544;&#31169;&#20445;&#25252;CNN&#35757;&#32451;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#27425;&#25104;&#21151;&#31361;&#30772;&#36825;&#20010;&#38590;&#39064;&#65292;&#20197;&#21069;&#27809;&#26377;&#20219;&#20309;&#24037;&#20316;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#12290;&#37319;&#29992;&#20102;&#20960;&#31181;&#25216;&#26415;&#65306;&#65288;1&#65289;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#65292;&#21487;&#20197;&#23558;&#38544;&#31169;&#20445;&#25252;&#30340;CNN&#35757;&#32451;&#31616;&#21270;&#20026;&#21516;&#24577;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#65292;&#29978;&#33267;&#26159;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#65288;MLR&#65289;&#35757;&#32451;&#65307;&#65288;2&#65289;&#36890;&#36807;&#26356;&#24555;&#30340;&#26799;&#24230;&#21464;&#20307;$\texttt{Quadratic Gradient}$&#65292;&#24212;&#29992;&#20110;MLR&#30340;&#22686;&#24378;&#26799;&#24230;&#26041;&#27861;&#65292;&#22312;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65307;&#65288;3&#65289;&#25105;&#20204;&#37319;&#29992;&#25968;&#23398;&#20013;&#30340;&#21464;&#25442;&#24605;&#24819;&#65292;&#23558;&#21152;&#23494;&#22495;&#20013;&#30340;&#36817;&#20284;Softmax&#20989;&#25968;&#36716;&#25442;&#25104;&#24050;&#32463;&#30740;&#31350;&#36807;&#30340;&#36924;&#36817;&#26041;&#27861;&#65292;&#20174;&#32780;&#24471;&#21040;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Privacy-preserving nerual network inference has been well studied while homomorphic CNN training still remains an open challenging task. In this paper, we present a practical solution to implement privacy-preserving CNN training based on mere Homomorphic Encryption (HE) technique. To our best knowledge, this is the first attempt successfully to crack this nut and no work ever before has achieved this goal. Several techniques combine to make it done: (1) with transfer learning, privacy-preserving CNN training can be reduced to homomorphic neural network training, or even multiclass logistic regression (MLR) training; (2) via a faster gradient variant called $\texttt{Quadratic Gradient}$, an enhanced gradient method for MLR with a state-of-the-art performance in converge speed is applied in this work to achieve high performance; (3) we employ the thought of transformation in mathematics to transform approximating Softmax function in encryption domain to the well-studied approximation of 
&lt;/p&gt;</description></item></channel></rss>