<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#22240;&#32452;&#23398;&#25110;&#36716;&#24405;&#32452;&#25968;&#25454;&#19978;&#30340;&#32852;&#37030;&#23398;&#20064;&#65292;&#20351;&#29992; TensorFlow Federated &#21644; Flower &#26694;&#26550;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#22521;&#35757;&#30142;&#30149;&#39044;&#21518;&#21644;&#32454;&#32990;&#31867;&#22411;&#20998;&#31867;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.14527</link><description>&lt;p&gt;
&#22522;&#22240;&#32452;&#23398;&#25110;&#36716;&#24405;&#32452;&#25968;&#25454;&#19978;&#30340;&#32852;&#37030;&#23398;&#20064;&#65306;&#27169;&#22411;&#36136;&#37327;&#21644;&#24615;&#33021;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Federated Learning on Transcriptomic Data: Model Quality and Performance Trade-Offs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#22240;&#32452;&#23398;&#25110;&#36716;&#24405;&#32452;&#25968;&#25454;&#19978;&#30340;&#32852;&#37030;&#23398;&#20064;&#65292;&#20351;&#29992; TensorFlow Federated &#21644; Flower &#26694;&#26550;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#22521;&#35757;&#30142;&#30149;&#39044;&#21518;&#21644;&#32454;&#32990;&#31867;&#22411;&#20998;&#31867;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#22522;&#22240;&#32452;&#23398;&#25110;&#36716;&#24405;&#32452;&#25968;&#25454;&#19978;&#36827;&#34892;&#26426;&#22120;&#23398;&#20064;&#23545;&#35768;&#22810;&#26032;&#39062;&#30340;&#20581;&#24247;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#20363;&#22914;&#65292;&#31934;&#20934;&#21307;&#23398;&#21487;&#20197;&#26681;&#25454;&#20010;&#20307;&#29983;&#29289;&#26631;&#24535;&#29289;&#12289;&#32454;&#32990;&#21644;&#20998;&#23376;&#29366;&#24577;&#31561;&#20010;&#20307;&#20449;&#24687;&#26469;&#37327;&#36523;&#23450;&#21046;&#21307;&#23398;&#27835;&#30103;&#12290;&#28982;&#32780;&#65292;&#25152;&#38656;&#25968;&#25454;&#25935;&#24863;&#12289;&#24222;&#22823;&#12289;&#24322;&#36136;&#65292;&#24182;&#19988;&#36890;&#24120;&#20998;&#24067;&#22312;&#26080;&#27861;&#20351;&#29992;&#19987;&#38376;&#30340;&#26426;&#22120;&#23398;&#20064;&#30828;&#20214;&#30340;&#22320;&#28857;&#12290;&#30001;&#20110;&#38544;&#31169;&#21644;&#30417;&#31649;&#21407;&#22240;&#65292;&#22312;&#21487;&#20449;&#20219;&#30340;&#31532;&#19977;&#26041;&#22788;&#32858;&#21512;&#25152;&#26377;&#25968;&#25454;&#20063;&#23384;&#22312;&#38382;&#39064;&#12290;&#32852;&#37030;&#23398;&#20064;&#26159;&#36825;&#19968;&#22256;&#22659;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#23454;&#29616;&#20102;&#22312;&#19981;&#20132;&#25442;&#21407;&#22987;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20998;&#25955;&#12289;&#21327;&#20316;&#30340;&#26426;&#22120;&#23398;&#20064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550; TensorFlow Federated &#21644; Flower &#36827;&#34892;&#27604;&#36739;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#26696;&#20363;&#26159;&#22521;&#35757;&#30142;&#30149;&#39044;&#21518;&#21644;&#32454;&#32990;&#31867;&#22411;&#20998;&#31867;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#20998;&#24067;&#24335;&#36716;&#24405;&#32452;&#23545;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14527v1 Announce Type: new  Abstract: Machine learning on large-scale genomic or transcriptomic data is important for many novel health applications. For example, precision medicine tailors medical treatments to patients on the basis of individual biomarkers, cellular and molecular states, etc. However, the data required is sensitive, voluminous, heterogeneous, and typically distributed across locations where dedicated machine learning hardware is not available. Due to privacy and regulatory reasons, it is also problematic to aggregate all data at a trusted third party.Federated learning is a promising solution to this dilemma, because it enables decentralized, collaborative machine learning without exchanging raw data. In this paper, we perform comparative experiments with the federated learning frameworks TensorFlow Federated and Flower. Our test case is the training of disease prognosis and cell type classification models. We train the models with distributed transcriptom
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11789</link><description>&lt;p&gt;
&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#20551;&#35774;&#30340;&#32479;&#35745;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Generated Hypotheses by Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#30340;&#22686;&#24378;&#24615;&#33021;&#21152;&#36895;&#20102;&#20854;&#34701;&#20837;&#31185;&#23398;&#30740;&#31350;&#12290;&#29305;&#21035;&#26159;&#65292;&#21033;&#29992;&#29983;&#25104;&#24335;AI&#21019;&#24314;&#31185;&#23398;&#20551;&#35774;&#26159;&#24456;&#26377;&#21069;&#36884;&#30340;&#65292;&#24182;&#19988;&#27491;&#22312;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#24403;&#20351;&#29992;AI&#29983;&#25104;&#30340;&#20551;&#35774;&#36827;&#34892;&#20851;&#38190;&#20915;&#31574;&#65288;&#22914;&#21307;&#23398;&#35786;&#26029;&#65289;&#26102;&#65292;&#39564;&#35777;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#36827;&#34892;&#21307;&#23398;&#35786;&#26029;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26469;&#37327;&#21270;&#20854;&#21487;&#38752;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#20351;&#29992;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#29983;&#25104;&#30340;&#22270;&#20687;&#26159;&#30001;&#32463;&#36807;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#36825;&#19968;&#20107;&#23454;&#26465;&#20214;&#19979;&#30340;&#32479;&#35745;&#26816;&#39564;&#12290;&#21033;&#29992;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#32479;&#35745;&#21487;&#38752;&#24615;&#21487;&#20197;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25511;&#21046;&#38169;&#35823;&#29575;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11789v1 Announce Type: cross  Abstract: The enhanced performance of AI has accelerated its integration into scientific research. In particular, the use of generative AI to create scientific hypotheses is promising and is increasingly being applied across various fields. However, when employing AI-generated hypotheses for critical decisions, such as medical diagnoses, verifying their reliability is crucial. In this study, we consider a medical diagnostic task using generated images by diffusion models, and propose a statistical test to quantify its reliability. The basic idea behind the proposed statistical test is to employ a selective inference framework, where we consider a statistical test conditional on the fact that the generated images are produced by a trained diffusion model. Using the proposed method, the statistical reliability of medical image diagnostic results can be quantified in the form of a p-value, allowing for decision-making with a controlled error rate. 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26354;&#29575;&#24863;&#30693;&#23545;&#35282;&#39044;&#22788;&#29702;&#22120;&#65292;&#22312;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#21152;&#36895;&#20102;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#20449;&#21495;&#27169;&#24577;&#12290;</title><link>https://arxiv.org/abs/2402.08784</link><description>&lt;p&gt;
&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#38543;&#26426;&#35757;&#32451;&#30340;&#39044;&#22788;&#29702;&#22120;
&lt;/p&gt;
&lt;p&gt;
Preconditioners for the Stochastic Training of Implicit Neural Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26354;&#29575;&#24863;&#30693;&#23545;&#35282;&#39044;&#22788;&#29702;&#22120;&#65292;&#22312;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#21152;&#36895;&#20102;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#20449;&#21495;&#27169;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#23558;&#22797;&#26434;&#36830;&#32493;&#22810;&#32500;&#20449;&#21495;&#32534;&#30721;&#20026;&#31070;&#32463;&#32593;&#32476;&#65292;&#20174;&#32780;&#23454;&#29616;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#26426;&#22120;&#20154;&#23398;&#21644;&#20960;&#20309;&#23398;&#31561;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;Adam&#30001;&#20110;&#20854;&#38543;&#26426;&#30340;&#39640;&#25928;&#24615;&#32780;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35757;&#32451;&#20013;&#65292;&#20294;&#20854;&#35757;&#32451;&#26102;&#38388;&#24448;&#24448;&#36739;&#38271;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22312;&#21152;&#36895;&#35757;&#32451;&#30340;&#21516;&#26102;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#30340;&#26367;&#20195;&#20248;&#21270;&#25216;&#26415;&#12290;&#20256;&#32479;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#22914;L-BFGS&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#25928;&#26524;&#19981;&#20339;&#65292;&#22240;&#27492;&#19981;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#26354;&#29575;&#24863;&#30693;&#23545;&#35282;&#39044;&#22788;&#29702;&#22120;&#36827;&#34892;&#38543;&#26426;&#35757;&#32451;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#22270;&#20687;&#12289;&#24418;&#29366;&#37325;&#24314;&#21644;&#31070;&#32463;&#36752;&#23556;&#22330;&#31561;&#21508;&#31181;&#20449;&#21495;&#27169;&#24577;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08784v1 Announce Type: cross Abstract: Implicit neural representations have emerged as a powerful technique for encoding complex continuous multidimensional signals as neural networks, enabling a wide range of applications in computer vision, robotics, and geometry. While Adam is commonly used for training due to its stochastic proficiency, it entails lengthy training durations. To address this, we explore alternative optimization techniques for accelerated training without sacrificing accuracy. Traditional second-order optimizers like L-BFGS are suboptimal in stochastic settings, making them unsuitable for large-scale data sets. Instead, we propose stochastic training using curvature-aware diagonal preconditioners, showcasing their effectiveness across various signal modalities such as images, shape reconstruction, and Neural Radiance Fields (NeRF).
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#26041;&#27861;&#31995;&#32479;&#22320;&#27979;&#35797;&#20102;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#20197;&#21450;&#35757;&#32451;&#32467;&#26463;&#26102;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#20851;&#32852;&#12290;</title><link>https://arxiv.org/abs/2402.06674</link><description>&lt;p&gt;
&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#30340;&#23454;&#38469;&#25104;&#21592;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Understanding Practical Membership Privacy of Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06674
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#26041;&#27861;&#31995;&#32479;&#22320;&#27979;&#35797;&#20102;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#20197;&#21450;&#35757;&#32451;&#32467;&#26463;&#26102;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24212;&#29992;&#26368;&#20808;&#36827;&#30340;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#65288;MIA&#65289;&#26469;&#31995;&#32479;&#22320;&#27979;&#35797;&#32454;&#35843;&#22823;&#22411;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23454;&#38469;&#38544;&#31169;&#28431;&#27934;&#12290;&#25105;&#20204;&#30340;&#37325;&#28857;&#26159;&#29702;&#35299;&#20351;&#25968;&#25454;&#38598;&#21644;&#26679;&#26412;&#23481;&#26131;&#21463;&#21040;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#29305;&#24615;&#12290;&#22312;&#25968;&#25454;&#38598;&#29305;&#24615;&#26041;&#38754;&#65292;&#25105;&#20204;&#21457;&#29616;&#25968;&#25454;&#20013;&#27599;&#20010;&#31867;&#21035;&#30340;&#31034;&#20363;&#25968;&#37327;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#24378;&#28872;&#30340;&#24130;&#24459;&#20381;&#36182;&#20851;&#31995;&#65292;&#36825;&#26159;&#20197;&#25915;&#20987;&#30340;&#30495;&#38451;&#24615;&#29575;&#65288;&#22312;&#20302;&#20551;&#38451;&#24615;&#29575;&#19979;&#27979;&#37327;&#65289;&#26469;&#34913;&#37327;&#30340;&#12290;&#23545;&#20110;&#20010;&#21035;&#26679;&#26412;&#32780;&#35328;&#65292;&#22312;&#35757;&#32451;&#32467;&#26463;&#26102;&#20135;&#29983;&#30340;&#22823;&#26799;&#24230;&#19982;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#28431;&#27934;&#20043;&#38388;&#23384;&#22312;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We apply a state-of-the-art membership inference attack (MIA) to systematically test the practical privacy vulnerability of fine-tuning large image classification models.We focus on understanding the properties of data sets and samples that make them vulnerable to membership inference. In terms of data set properties, we find a strong power law dependence between the number of examples per class in the data and the MIA vulnerability, as measured by true positive rate of the attack at a low false positive rate. For an individual sample, large gradients at the end of training are strongly correlated with MIA vulnerability.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAR&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06104</link><description>&lt;p&gt;
&#21151;&#33021;&#23545;&#40784;&#22238;&#24402;&#65306;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#26126;&#30830;&#23398;&#20064;&#20989;&#25968;&#23548;&#25968;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06104
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAR&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#22320;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20843;&#20010;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#24402;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#20219;&#21153;&#65292;&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20256;&#32479;&#30340;&#22238;&#24402;&#26041;&#27861;&#20027;&#35201;&#36890;&#36807;&#20351;&#29992;&#25439;&#22833;&#20989;&#25968;&#26469;&#23558;&#27169;&#22411;&#39044;&#27979;&#19982;&#27599;&#20010;&#20010;&#20307;&#25968;&#25454;&#26679;&#26412;&#30340;&#30495;&#23454;&#20540;&#23545;&#40784;&#65292;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#22312;&#19981;&#21516;&#26679;&#26412;&#20043;&#38388;&#20851;&#31995;&#30340;&#39044;&#27979;&#19981;&#22815;&#20248;&#21270;&#12290;&#36817;&#26399;&#30340;&#30740;&#31350;&#24037;&#20316;&#24341;&#20837;&#20102;&#26631;&#31614;&#30456;&#20284;&#24615;&#20449;&#24687;&#26469;&#25913;&#36827;&#22238;&#24402;&#26041;&#27861;&#65292;&#20294;&#22312;&#23436;&#20840;&#25429;&#25417;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#26041;&#38754;&#20173;&#23384;&#22312;&#26126;&#26174;&#30340;&#24046;&#36317;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FAR&#65288;&#21151;&#33021;&#23545;&#40784;&#22238;&#24402;&#65289;&#20316;&#20026;&#19968;&#31181;&#26356;&#22909;&#12289;&#26356;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#25429;&#25417;&#20989;&#25968;&#23548;&#25968;&#26469;&#25311;&#21512;&#24213;&#23618;&#30495;&#23454;&#20989;&#25968;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20845;&#20010;&#39046;&#22495;&#30340;&#20843;&#20010;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample, which, as we show, can result in sub-optimal prediction of the relationships between the different samples. Recent research endeavors have introduced novel perspectives by incorporating label similarity information to regression. However, a notable gap persists in these approaches when it comes to fully capturing the intricacies of the underlying ground truth function. In this work, we propose FAR (Function Aligned Regression) as a arguably better and more efficient solution to fit the underlying function of ground truth by capturing functional derivatives. We demonstrate the effectiveness of the proposed method practically on 2 synthetic datasets and on 8 extensive real-world tasks from 6 b
&lt;/p&gt;</description></item><item><title>RandCom&#26159;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#30340;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#20013;&#36890;&#36807;&#27010;&#29575;&#24615;&#26412;&#22320;&#26356;&#26032;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#65292;&#24182;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2310.07983</link><description>&lt;p&gt;
RandCom&#65306;&#21435;&#20013;&#24515;&#21270;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#29992;&#20110;&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization. (arXiv:2310.07983v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07983
&lt;/p&gt;
&lt;p&gt;
RandCom&#26159;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#30340;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#20013;&#36890;&#36807;&#27010;&#29575;&#24615;&#26412;&#22320;&#26356;&#26032;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#65292;&#24182;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#38543;&#26426;&#36890;&#20449;&#36339;&#36807;&#30340;&#20998;&#24067;&#24335;&#20248;&#21270;&#26041;&#27861;&#22240;&#20854;&#22312;&#21152;&#36895;&#36890;&#20449;&#22797;&#26434;&#24615;&#26041;&#38754;&#20855;&#26377;&#30340;&#20248;&#21183;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24378;&#20984;&#30830;&#23450;&#24615;&#35774;&#32622;&#30340;&#38598;&#20013;&#24335;&#36890;&#20449;&#21327;&#35758;&#19978;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RandCom&#30340;&#20998;&#24067;&#24335;&#20248;&#21270;&#26041;&#27861;&#65292;&#23427;&#37319;&#29992;&#20102;&#27010;&#29575;&#24615;&#30340;&#26412;&#22320;&#26356;&#26032;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;RandCom&#22312;&#38543;&#26426;&#38750;&#20984;&#12289;&#20984;&#21644;&#24378;&#20984;&#35774;&#32622;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#33021;&#22815;&#36890;&#36807;&#36890;&#20449;&#27010;&#29575;&#26469;&#28176;&#36817;&#22320;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#24403;&#33410;&#28857;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;RandCom&#33021;&#22815;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;&#22312;&#38543;&#26426;&#24378;&#20984;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;RandCom&#21487;&#20197;&#36890;&#36807;&#29420;&#31435;&#20110;&#32593;&#32476;&#30340;&#27493;&#38271;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;RandCom&#24212;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#30340;&#28508;&#21147;&#30340;&#31215;&#26497;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed optimization methods with random communication skips are gaining increasing attention due to their proven benefits in accelerating communication complexity. Nevertheless, existing research mainly focuses on centralized communication protocols for strongly convex deterministic settings. In this work, we provide a decentralized optimization method called RandCom, which incorporates probabilistic local updates. We analyze the performance of RandCom in stochastic non-convex, convex, and strongly convex settings and demonstrate its ability to asymptotically reduce communication overhead by the probability of communication. Additionally, we prove that RandCom achieves linear speedup as the number of nodes increases. In stochastic strongly convex settings, we further prove that RandCom can achieve linear speedup with network-independent stepsizes. Moreover, we apply RandCom to federated learning and provide positive results concerning the potential for achieving linear speedup and
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;QFT&#26694;&#26550;&#65292;&#21487;&#20197;&#23545;LLMs&#36827;&#34892;&#20869;&#23384;&#39640;&#25928;&#30340;&#20840;&#21442;&#25968;&#24494;&#35843;&#65292;&#32780;&#19981;&#25439;&#23475;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.07147</link><description>&lt;p&gt;
QFT: &#20351;&#29992;&#21487;&#25215;&#25285;&#36164;&#28304;&#23545;LLMs&#36827;&#34892;&#37327;&#21270;&#20840;&#21442;&#25968;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources. (arXiv:2310.07147v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07147
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;QFT&#26694;&#26550;&#65292;&#21487;&#20197;&#23545;LLMs&#36827;&#34892;&#20869;&#23384;&#39640;&#25928;&#30340;&#20840;&#21442;&#25968;&#24494;&#35843;&#65292;&#32780;&#19981;&#25439;&#23475;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#24433;&#21709;&#12290;&#23545;&#36825;&#20123;&#39044;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#65292;&#20294;&#30001;&#20110;&#20854;&#24040;&#22823;&#30340;&#36164;&#28304;&#38656;&#27714;&#65292;&#36825;&#19968;&#36807;&#31243;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#27492;&#65292;&#29616;&#26377;&#30340;&#21162;&#21147;&#37117;&#38598;&#20013;&#22312;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#19978;&#65292;&#19981;&#24184;&#30340;&#26159;&#65292;&#23427;&#20204;&#27809;&#26377;&#20805;&#20998;&#21457;&#25381;&#20840;&#21442;&#25968;&#24494;&#35843;&#30340;&#28508;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;QFT&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;LLMs&#30340;&#37327;&#21270;&#20840;&#21442;&#25968;&#35843;&#25972;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#19981;&#25439;&#23475;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#39640;&#25928;&#30340;&#20869;&#23384;&#24494;&#35843;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#20004;&#20010;&#26032;&#39062;&#30340;&#24605;&#24819;&#65306;&#65288;i&#65289;&#25105;&#20204;&#37319;&#29992;&#39640;&#25928;&#30340;Lion&#20248;&#21270;&#22120;&#65292;&#20165;&#36319;&#36394;&#21160;&#37327;&#24182;&#20855;&#26377;&#27599;&#20010;&#21442;&#25968;&#19968;&#33268;&#30340;&#26356;&#26032;&#24133;&#24230;&#65292;&#36825;&#23545;&#20110;&#31283;&#20581;&#30340;&#37327;&#21270;&#26159;&#19968;&#31181;&#20869;&#22312;&#20248;&#21183;&#65307;&#65288;ii&#65289;&#25105;&#20204;&#23558;&#25152;&#26377;&#27169;&#22411;&#29366;&#24577;&#36827;&#34892;&#37327;&#21270;&#65292;&#24182;&#20197;&#25972;&#25968;&#20540;&#23384;&#20648;&#65292;&#21516;&#26102;&#25552;&#20379;&#26799;&#24230;&#27969;&#21644;&#21442;&#25968;&#26356;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have showcased remarkable impacts across a wide spectrum of natural language processing tasks. Fine-tuning these pre-trained models on downstream datasets provides further significant performance gains, but this process has been challenging due to its extraordinary resource requirements. To this end, existing efforts focus on parameter-efficient fine-tuning, which, unfortunately, fail to capitalize on the powerful potential of full-parameter fine-tuning. In this work, we propose QFT, a novel Quantized Full-parameter Tuning framework for LLMs that enables memory-efficient fine-tuning without harming performance. Our framework incorporates two novel ideas: (i) we adopt the efficient Lion optimizer, which only keeps track of the momentum and has consistent update magnitudes for each parameter, an inherent advantage for robust quantization; and (ii) we quantize all model states and store them as integer values, and present a gradient flow and parameter update s
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32508;&#21512;&#35780;&#20272;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#23427;&#20204;&#32570;&#20047;&#31283;&#23450;&#24615;&#21644;&#21487;&#38752;&#24615;&#65292;&#24182;&#24314;&#35758;&#37319;&#29992;&#24191;&#27867;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#32479;&#19968;&#30340;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2308.04137</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#24615;&#33021;&#30340;&#32508;&#21512;&#35780;&#20272;&#25581;&#31034;&#20986;&#24778;&#20154;&#30340;&#32570;&#20047;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness. (arXiv:2308.04137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04137
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32508;&#21512;&#35780;&#20272;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#23427;&#20204;&#32570;&#20047;&#31283;&#23450;&#24615;&#21644;&#21487;&#38752;&#24615;&#65292;&#24182;&#24314;&#35758;&#37319;&#29992;&#24191;&#27867;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#32479;&#19968;&#30340;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#32780;&#31283;&#20581;&#30340;&#35780;&#20272;&#26041;&#27861;&#26159;&#24320;&#21457;&#26412;&#36523;&#31283;&#20581;&#21487;&#38752;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24517;&#35201;&#31532;&#19968;&#27493;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#29992;&#20110;&#35780;&#20272;&#20998;&#31867;&#22120;&#30340;&#24120;&#35268;&#35780;&#20272;&#21327;&#35758;&#22312;&#32508;&#21512;&#35780;&#20272;&#24615;&#33021;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#22240;&#20026;&#23427;&#20204;&#24448;&#24448;&#20381;&#36182;&#20110;&#26377;&#38480;&#31867;&#22411;&#30340;&#27979;&#35797;&#25968;&#25454;&#65292;&#24573;&#35270;&#20854;&#20182;&#31867;&#22411;&#30340;&#25968;&#25454;&#12290;&#20363;&#22914;&#65292;&#20351;&#29992;&#26631;&#20934;&#27979;&#35797;&#25968;&#25454;&#26080;&#27861;&#35780;&#20272;&#20998;&#31867;&#22120;&#23545;&#20110;&#26410;&#32463;&#35757;&#32451;&#30340;&#31867;&#21035;&#26679;&#26412;&#30340;&#39044;&#27979;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20351;&#29992;&#21253;&#21547;&#26410;&#30693;&#31867;&#21035;&#26679;&#26412;&#30340;&#25968;&#25454;&#36827;&#34892;&#27979;&#35797;&#26080;&#27861;&#35780;&#20272;&#20998;&#31867;&#22120;&#23545;&#20110;&#24050;&#30693;&#31867;&#21035;&#26631;&#31614;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20513;&#20351;&#29992;&#21508;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#36827;&#34892;&#24615;&#33021;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#21487;&#24212;&#29992;&#20110;&#25152;&#26377;&#36825;&#20123;&#25968;&#25454;&#31867;&#22411;&#30340;&#21333;&#19968;&#25351;&#26631;&#65292;&#20197;&#20135;&#29983;&#19968;&#33268;&#30340;&#24615;&#33021;&#35780;&#20272;&#32467;&#26524;&#12290;&#36890;&#36807;&#36825;&#26679;&#30340;&#22522;&#20934;&#27979;&#35797;&#21457;&#29616;&#65292;&#30446;&#21069;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21253;&#25324;&#20351;&#29992;&#35748;&#20026;&#26159;&#20840;&#38754;&#30340;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#30340;&#32593;&#32476;&#65292;&#20063;&#23384;&#22312;&#32570;&#20047;&#31283;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliable and robust evaluation methods are a necessary first step towards developing machine learning models that are themselves robust and reliable. Unfortunately, current evaluation protocols typically used to assess classifiers fail to comprehensively evaluate performance as they tend to rely on limited types of test data, and ignore others. For example, using the standard test data fails to evaluate the predictions made by the classifier to samples from classes it was not trained on. On the other hand, testing with data containing samples from unknown classes fails to evaluate how well the classifier can predict the labels for known classes. This article advocates bench-marking performance using a wide range of different types of data and using a single metric that can be applied to all such data types to produce a consistent evaluation of performance. Using such a benchmark it is found that current deep neural networks, including those trained with methods that are believed to pro
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35831;&#27714;&#25104;&#21592;&#26631;&#31614;&#21644;&#25104;&#23545;&#20559;&#22909;&#26469;&#25193;&#23637;&#20027;&#21160;&#35268;&#33539;&#23398;&#20064;&#65292;&#25552;&#39640;&#23398;&#20064;&#24418;&#24335;&#35268;&#33539;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#23454;&#39564;&#20013;&#65292;&#32467;&#26524;&#34920;&#26126;&#36890;&#36807;&#23398;&#20064;&#25104;&#21592;&#21644;&#20559;&#22909;&#30340;&#32452;&#21512;&#21487;&#20197;&#31283;&#23450;&#21644;&#26041;&#20415;&#22320;&#35782;&#21035;&#35268;&#33539;&#12290;</title><link>http://arxiv.org/abs/2307.10434</link><description>&lt;p&gt;
&#20174;&#25104;&#21592;&#21644;&#20559;&#22909;&#26597;&#35810;&#20013;&#23398;&#20064;&#24418;&#24335;&#35268;&#33539;
&lt;/p&gt;
&lt;p&gt;
Learning Formal Specifications from Membership and Preference Queries. (arXiv:2307.10434v1 [cs.FL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10434
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35831;&#27714;&#25104;&#21592;&#26631;&#31614;&#21644;&#25104;&#23545;&#20559;&#22909;&#26469;&#25193;&#23637;&#20027;&#21160;&#35268;&#33539;&#23398;&#20064;&#65292;&#25552;&#39640;&#23398;&#20064;&#24418;&#24335;&#35268;&#33539;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#23454;&#39564;&#20013;&#65292;&#32467;&#26524;&#34920;&#26126;&#36890;&#36807;&#23398;&#20064;&#25104;&#21592;&#21644;&#20559;&#22909;&#30340;&#32452;&#21512;&#21487;&#20197;&#31283;&#23450;&#21644;&#26041;&#20415;&#22320;&#35782;&#21035;&#35268;&#33539;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#30740;&#31350;&#24191;&#27867;&#30340;&#23398;&#20064;&#24418;&#24335;&#35268;&#33539;&#30340;&#26041;&#27861;&#65292;&#20363;&#22914;&#33258;&#21160;&#26426;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#23558;&#20027;&#21160;&#35268;&#33539;&#23398;&#20064;&#25193;&#23637;&#21040;&#35831;&#27714;&#32452;&#21512;&#25104;&#21592;&#26631;&#31614;&#21644;&#25104;&#23545;&#20559;&#22909;&#65288;&#23545;&#25104;&#21592;&#26631;&#31614;&#30340;&#19968;&#31181;&#27969;&#34892;&#26367;&#20195;&#26041;&#24335;&#65289;&#12290;&#25104;&#23545;&#20559;&#22909;&#21644;&#25104;&#21592;&#26631;&#31614;&#30340;&#32452;&#21512;&#20801;&#35768;&#26356;&#28789;&#27963;&#30340;&#20027;&#21160;&#35268;&#33539;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#20808;&#21069;&#20165;&#20381;&#36182;&#25104;&#21592;&#26631;&#31614;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;&#20004;&#20010;&#19981;&#21516;&#30340;&#39046;&#22495;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24191;&#27867;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20174;&#20004;&#31181;&#27169;&#24335;&#23398;&#20064;&#21487;&#20197;&#36890;&#36807;&#25104;&#21592;&#21644;&#20559;&#22909;&#26469;&#31283;&#20581;&#21644;&#26041;&#20415;&#22320;&#35782;&#21035;&#35268;&#33539;&#12290;
&lt;/p&gt;
&lt;p&gt;
Active learning is a well-studied approach to learning formal specifications, such as automata. In this work, we extend active specification learning by proposing a novel framework that strategically requests a combination of membership labels and pair-wise preferences, a popular alternative to membership labels. The combination of pair-wise preferences and membership labels allows for a more flexible approach to active specification learning, which previously relied on membership labels only. We instantiate our framework in two different domains, demonstrating the generality of our approach. Our results suggest that learning from both modalities allows us to robustly and conveniently identify specifications via membership and preferences.
&lt;/p&gt;</description></item><item><title>MDI+&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#26367;&#25442;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;&#24230;&#37327;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#26356;&#36866;&#21512;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2307.01932</link><description>&lt;p&gt;
MDI+:&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MDI+: A Flexible Random Forest-Based Feature Importance Framework. (arXiv:2307.01932v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01932
&lt;/p&gt;
&lt;p&gt;
MDI+&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#26367;&#25442;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;&#24230;&#37327;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#26356;&#36866;&#21512;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#19981;&#32431;&#24230;&#20943;&#23569;&#30340;&#24179;&#22343;&#20540;(MDI)&#26159;&#38543;&#26426;&#26862;&#26519;(RF)&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20272;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;RF&#20013;&#27599;&#20010;&#26641;&#30340;&#29305;&#24449;$X_k$&#30340;MDI&#31561;&#20215;&#20110;&#21709;&#24212;&#21464;&#37327;&#22312;&#20915;&#31574;&#26641;&#38598;&#21512;&#19978;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#26410;&#24402;&#19968;&#21270;$R^2$&#20540;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#35299;&#37322;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;MDI+&#65292;MDI+&#36890;&#36807;&#20801;&#35768;&#20998;&#26512;&#20154;&#21592;&#23558;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;$R^2$&#24230;&#37327;&#26367;&#25442;&#20026;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;(GLM)&#21644;&#26356;&#36866;&#21512;&#32473;&#23450;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#22522;&#20110;&#21487;&#39044;&#27979;&#24615;&#12289;&#21487;&#35745;&#31639;&#24615;&#21644;&#31283;&#23450;&#24615;&#26694;&#26550;&#36873;&#25321;&#36866;&#24403;&#30340;GLM&#21644;&#24230;&#37327;&#30340;&#25351;&#23548;&#65292;&#20197;&#36827;&#34892;&#30495;&#23454;&#25968;&#25454;&#31185;&#23398;&#30740;&#31350;&#12290;&#22823;&#37327;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#25311;&#32467;&#26524;&#26174;&#31034;&#65292;MDI+&#22312;&#24615;&#33021;&#19978;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#30340;MDI&#12290;
&lt;/p&gt;
&lt;p&gt;
Mean decrease in impurity (MDI) is a popular feature importance measure for random forests (RFs). We show that the MDI for a feature $X_k$ in each tree in an RF is equivalent to the unnormalized $R^2$ value in a linear regression of the response on the collection of decision stumps that split on $X_k$. We use this interpretation to propose a flexible feature importance framework called MDI+. Specifically, MDI+ generalizes MDI by allowing the analyst to replace the linear regression model and $R^2$ metric with regularized generalized linear models (GLMs) and metrics better suited for the given data structure. Moreover, MDI+ incorporates additional features to mitigate known biases of decision trees against additive or smooth models. We further provide guidance on how practitioners can choose an appropriate GLM and metric based upon the Predictability, Computability, Stability framework for veridical data science. Extensive data-inspired simulations show that MDI+ significantly outperfor
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#65292;&#21487;&#20197;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20294;&#38656;&#35201;&#27491;&#30830;&#20351;&#29992;&#27491;&#21017;&#21270;&#25216;&#26415;&#20197;&#36991;&#20813;&#27425;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2211.13723</link><description>&lt;p&gt;
&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#26469;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improving Multi-task Learning via Seeking Task-based Flat Regions. (arXiv:2211.13723v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13723
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23547;&#25214;&#22522;&#20110;&#20219;&#21153;&#30340;&#24179;&#22374;&#21306;&#22495;&#65292;&#21487;&#20197;&#25913;&#36827;&#22810;&#20219;&#21153;&#23398;&#20064;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20294;&#38656;&#35201;&#27491;&#30830;&#20351;&#29992;&#27491;&#21017;&#21270;&#25216;&#26415;&#20197;&#36991;&#20813;&#27425;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#19988;&#24378;&#22823;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#29992;&#20110;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#36890;&#36807;&#21333;&#20010;&#39592;&#24178;&#23398;&#20064;&#22810;&#20010;&#30446;&#26631;&#12290;&#19982;&#21333;&#29420;&#35757;&#32451;&#20219;&#21153;&#30456;&#27604;&#65292;MTL&#26174;&#30528;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#26469;&#28508;&#22312;&#22320;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#23427;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#39046;&#22495;&#65292;&#20174;&#35745;&#31639;&#26426;&#35270;&#35273;&#21040;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35821;&#38899;&#35782;&#21035;&#12290;&#20854;&#20013;&#65292;MTL&#30340;&#19968;&#20010;&#26032;&#20852;&#30740;&#31350;&#26041;&#21521;&#38598;&#20013;&#22312;&#25805;&#32437;&#20219;&#21153;&#26799;&#24230;&#20197;&#25512;&#23548;&#20986;&#23545;&#25152;&#26377;&#20219;&#21153;&#26377;&#30410;&#30340;&#26368;&#32456;&#26799;&#24230;&#19979;&#38477;&#26041;&#21521;&#12290;&#23613;&#31649;&#22312;&#35768;&#22810;&#22522;&#20934;&#27979;&#35797;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#20294;&#26159;&#22312;&#23454;&#38469;&#38382;&#39064;&#19978;&#30452;&#25509;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;&#32780;&#19981;&#20351;&#29992;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#35299;&#12290;&#29305;&#21035;&#26159;&#65292;&#26631;&#20934;&#35757;&#32451;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#26368;&#23567;&#21270;&#32463;&#39564;&#25439;&#22833;&#65292;&#24456;&#23481;&#26131;&#36973;&#21463;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-Task Learning (MTL) is a widely-used and powerful learning paradigm for training deep neural networks that allows learning more than one objective by a single backbone. Compared to training tasks separately, MTL significantly reduces computational costs, improves data efficiency, and potentially enhances model performance by leveraging knowledge across tasks. Hence, it has been adopted in a variety of applications, ranging from computer vision to natural language processing and speech recognition. Among them, there is an emerging line of work in MTL that focuses on manipulating the task gradient to derive an ultimate gradient descent direction to benefit all tasks. Despite achieving impressive results on many benchmarks, directly applying these approaches without using appropriate regularization techniques might lead to suboptimal solutions on real-world problems. In particular, standard training that minimizes the empirical loss on the training data can easily suffer from overfi
&lt;/p&gt;</description></item></channel></rss>