<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>SARI&#26159;&#19968;&#20010;&#31616;&#32422;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22024;&#26434;&#37096;&#20998;&#26631;&#31614;&#65292;&#32467;&#21512;&#24179;&#22343;&#31574;&#30053;&#21644;&#35782;&#21035;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#20013;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#35757;&#32451;&#65292;&#24182;&#26174;&#33879;&#25552;&#21319;&#20102;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04835</link><description>&lt;p&gt;
SARI: &#31616;&#27905;&#24179;&#22343;&#19982;&#40065;&#26834;&#24615;&#22522;&#20110;&#22024;&#26434;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SARI: Simplistic Average and Robust Identification based Noisy Partial Label Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04835
&lt;/p&gt;
&lt;p&gt;
SARI&#26159;&#19968;&#20010;&#31616;&#32422;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22024;&#26434;&#37096;&#20998;&#26631;&#31614;&#65292;&#32467;&#21512;&#24179;&#22343;&#31574;&#30053;&#21644;&#35782;&#21035;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#20013;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#35757;&#32451;&#65292;&#24182;&#26174;&#33879;&#25552;&#21319;&#20102;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37096;&#20998;&#26631;&#31614;&#23398;&#20064; (PLL) &#26159;&#19968;&#31181;&#24369;&#30417;&#30563;&#23398;&#20064;&#33539;&#24335;&#65292;&#20854;&#20013;&#27599;&#20010;&#35757;&#32451;&#23454;&#20363;&#37117;&#19982;&#19968;&#32452;&#20505;&#36873;&#26631;&#31614; (&#37096;&#20998;&#26631;&#31614;) &#25104;&#23545;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;&#30495;&#27491;&#30340;&#26631;&#31614;&#12290;&#22024;&#26434;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064; (NPLL) &#25918;&#23485;&#20102;&#36825;&#20010;&#32422;&#26463;&#65292;&#20801;&#35768;&#19968;&#20123;&#37096;&#20998;&#26631;&#31614;&#19981;&#21253;&#21547;&#30495;&#27491;&#30340;&#26631;&#31614;&#65292;&#22686;&#21152;&#20102;&#38382;&#39064;&#30340;&#23454;&#29992;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#38598;&#20013;&#22312; NPLL &#19978;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#32422;&#30340;&#26694;&#26550; SARI&#65292;&#36890;&#36807;&#21033;&#29992;&#21152;&#26435;&#26368;&#36817;&#37051;&#31639;&#27861;&#23558;&#20266;&#26631;&#31614;&#20998;&#37197;&#32473;&#22270;&#20687;&#12290;&#28982;&#21518;&#65292;&#36825;&#20123;&#20266;&#26631;&#31614;&#19982;&#22270;&#20687;&#37197;&#23545;&#29992;&#20110;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#65292;&#37319;&#29992;&#26631;&#31614;&#24179;&#28369;&#21644;&#26631;&#20934;&#27491;&#21017;&#21270;&#25216;&#26415;&#12290;&#38543;&#21518;&#65292;&#21033;&#29992;&#20998;&#31867;&#22120;&#30340;&#29305;&#24449;&#21644;&#39044;&#27979;&#32467;&#26524;&#26469;&#25913;&#36827;&#21644;&#25552;&#39640;&#20266;&#26631;&#31614;&#30340;&#20934;&#30830;&#24615;&#12290;SARI&#32467;&#21512;&#20102;&#25991;&#29486;&#20013;&#22522;&#20110;&#24179;&#22343;&#31574;&#30053; (&#20266;&#26631;&#31614;) &#21644;&#22522;&#20110;&#35782;&#21035;&#31574;&#30053; (&#20998;&#31867;&#22120;&#35757;&#32451;)&#30340;&#20248;&#28857;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#35814;&#23613;&#30340;&#23454;&#39564;&#35780;&#20272;&#65292;&#39564;&#35777;&#20102;SARI&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partial label learning (PLL) is a weakly-supervised learning paradigm where each training instance is paired with a set of candidate labels (partial label), one of which is the true label. Noisy PLL (NPLL) relaxes this constraint by allowing some partial labels to not contain the true label, enhancing the practicality of the problem. Our work centers on NPLL and presents a minimalistic framework called SARI that initially assigns pseudo-labels to images by exploiting the noisy partial labels through a weighted nearest neighbour algorithm. These pseudo-label and image pairs are then used to train a deep neural network classifier with label smoothing and standard regularization techniques. The classifier's features and predictions are subsequently employed to refine and enhance the accuracy of pseudo-labels. SARI combines the strengths of Average Based Strategies (in pseudo labelling) and Identification Based Strategies (in classifier training) from the literature. We perform thorough ex
&lt;/p&gt;</description></item><item><title>SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.03819</link><description>&lt;p&gt;
SMOTE&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#30740;&#31350;&#65306;&#20851;&#20110;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#30340;&#38480;&#21046;&#21644;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03819
&lt;/p&gt;
&lt;p&gt;
SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
SMOTE&#65288;Synthetic Minority Oversampling Technique&#65289;&#26159;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#24120;&#29992;&#30340;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;SMOTE&#65288;&#40664;&#35748;&#21442;&#25968;&#65289;&#36890;&#36807;&#31616;&#21333;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#25903;&#25345;&#36793;&#30028;&#38468;&#36817;&#65292;SMOTE&#30340;&#23494;&#24230;&#20250;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;&#24120;&#35265;&#30340;BorderLine SMOTE&#31574;&#30053;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#29616;&#26377;&#30340;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21482;&#26377;&#24403;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#26102;&#25165;&#38656;&#35201;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#23545;&#20110;&#36825;&#31181;&#25968;&#25454;&#38598;&#65292;SMOTE&#12289;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced data sets. Asymptotically, we prove that SMOTE (with default parameter) regenerates the original distribution by simply copying the original minority samples. We also prove that SMOTE density vanishes near the boundary of the support of the minority distribution, therefore justifying the common BorderLine SMOTE strategy. Then we introduce two new SMOTE-related strategies, and compare them with state-of-the-art rebalancing procedures. We show that rebalancing strategies are only required when the data set is highly imbalanced. For such data sets, SMOTE, our proposals, or undersampling procedures are the best strategies.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;Polish&#31354;&#38388;&#20013;&#30340;&#29109;&#27491;&#21017;&#21270;Markov&#20915;&#31574;&#36807;&#31243;&#19978;&#30340;Fisher-Rao&#31574;&#30053;&#26799;&#24230;&#27969;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#22312;&#26799;&#24230;&#35780;&#20272;&#26041;&#38754;&#30340;&#31283;&#23450;&#24615;&#65292;&#20026;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#27969;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#27934;&#35265;&#12290;</title><link>http://arxiv.org/abs/2310.02951</link><description>&lt;p&gt;
Fisher-Rao&#26799;&#24230;&#27969;&#22312;Polish&#31354;&#38388;&#20013;&#23545;&#29109;&#27491;&#21017;&#21270;Markov&#20915;&#31574;&#36807;&#31243;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Fisher-Rao gradient flow for entropy-regularised Markov decision processes in Polish spaces. (arXiv:2310.02951v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02951
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;Polish&#31354;&#38388;&#20013;&#30340;&#29109;&#27491;&#21017;&#21270;Markov&#20915;&#31574;&#36807;&#31243;&#19978;&#30340;Fisher-Rao&#31574;&#30053;&#26799;&#24230;&#27969;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#22312;&#26799;&#24230;&#35780;&#20272;&#26041;&#38754;&#30340;&#31283;&#23450;&#24615;&#65292;&#20026;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#27969;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Polish&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#20013;&#26080;&#38480;&#26102;&#22495;&#30340;&#29109;&#27491;&#21017;&#21270;&#30340;Markov&#20915;&#31574;&#36807;&#31243;&#30340;Fisher-Rao&#31574;&#30053;&#26799;&#24230;&#27969;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#36825;&#20010;&#27969;&#26159;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#30340;&#36830;&#32493;&#26102;&#38388;&#31867;&#27604;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#30340;&#20840;&#23616;&#33391;&#23450;&#20041;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#22312;&#26799;&#24230;&#35780;&#20272;&#26041;&#38754;&#30340;&#31283;&#23450;&#24615;&#65292;&#20026;&#23545;&#25968;&#32447;&#24615;&#31574;&#30053;&#21442;&#25968;&#21270;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#27969;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#27934;&#35265;&#12290;&#20026;&#20102;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#38750;&#20984;&#24615;&#21644;&#29109;&#27491;&#21017;&#21270;&#24341;&#36215;&#30340;&#19981;&#36830;&#32493;&#24615;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#21033;&#29992;&#24615;&#33021;&#24046;&#21035;&#24341;&#29702;&#21644;&#26799;&#24230;&#19982;&#38236;&#20687;&#19979;&#38477;&#27969;&#20043;&#38388;&#30340;&#23545;&#20598;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the global convergence of a Fisher-Rao policy gradient flow for infinite-horizon entropy-regularised Markov decision processes with Polish state and action space. The flow is a continuous-time analogue of a policy mirror descent method. We establish the global well-posedness of the gradient flow and demonstrate its exponential convergence to the optimal policy. Moreover, we prove the flow is stable with respect to gradient evaluation, offering insights into the performance of a natural policy gradient flow with log-linear policy parameterisation. To overcome challenges stemming from the lack of the convexity of the objective function and the discontinuity arising from the entropy regulariser, we leverage the performance difference lemma and the duality relationship between the gradient and mirror descent flows.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#20854;&#33021;&#22815;&#19982;&#21508;&#31181;MCMC&#26041;&#27861;&#32467;&#21512;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#32452;&#21512;&#21644;&#36827;&#34892;&#26356;&#22909;&#30340;&#37319;&#26679;&#12290;</title><link>http://arxiv.org/abs/2307.14012</link><description>&lt;p&gt;
MCMC-&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#29992;&#20110;&#27169;&#22411;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
MCMC-Correction of Score-Based Diffusion Models for Model Composition. (arXiv:2307.14012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#20854;&#33021;&#22815;&#19982;&#21508;&#31181;MCMC&#26041;&#27861;&#32467;&#21512;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#32452;&#21512;&#21644;&#36827;&#34892;&#26356;&#22909;&#30340;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#29992;&#24471;&#20998;&#25110;&#33021;&#37327;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#12290;&#33021;&#37327;&#21442;&#25968;&#21270;&#20855;&#26377;&#26356;&#22909;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#20027;&#35201;&#26159;&#23427;&#21487;&#20197;&#36890;&#36807;&#22312;&#25552;&#35758;&#26679;&#26412;&#20013;&#24635;&#33021;&#37327;&#30340;&#21464;&#21270;&#22522;&#20110;Metropolis-Hastings&#20462;&#27491;&#27493;&#39588;&#26469;&#36827;&#34892;&#25193;&#23637;&#37319;&#26679;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#23427;&#20284;&#20046;&#20135;&#29983;&#20102;&#31245;&#24494;&#36739;&#24046;&#30340;&#24615;&#33021;&#65292;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#30001;&#20110;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26222;&#36941;&#27969;&#34892;&#65292;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#33021;&#37327;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#21487;&#29992;&#24615;&#21463;&#21040;&#38480;&#21046;&#12290;&#36825;&#31181;&#38480;&#21046;&#21066;&#24369;&#20102;&#27169;&#22411;&#32452;&#21512;&#30340;&#30446;&#30340;&#65292;&#21363;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#32452;&#21512;&#36215;&#26469;&#20174;&#26032;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#25552;&#35758;&#24314;&#35758;&#20445;&#30041;&#24471;&#20998;&#21442;&#25968;&#21270;&#65292;&#32780;&#26159;&#36890;&#36807;&#23545;&#24471;&#20998;&#20989;&#25968;&#36827;&#34892;&#32447;&#31215;&#20998;&#26469;&#35745;&#31639;&#22522;&#20110;&#33021;&#37327;&#30340;&#25509;&#21463;&#27010;&#29575;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#37325;&#29992;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#23558;&#21453;&#21521;&#36807;&#31243;&#19982;&#21508;&#31181;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#26041;&#27861;&#32452;&#21512;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models can be parameterised in terms of either a score or an energy function. The energy parameterisation has better theoretical properties, mainly that it enables an extended sampling procedure with a Metropolis--Hastings correction step, based on the change in total energy in the proposed samples. However, it seems to yield slightly worse performance, and more importantly, due to the widespread popularity of score-based diffusion, there are limited availability of off-the-shelf pre-trained energy-based ones. This limitation undermines the purpose of model composition, which aims to combine pre-trained models to sample from new distributions. Our proposal, however, suggests retaining the score parameterization and instead computing the energy-based acceptance probability through line integration of the score function. This allows us to re-use existing diffusion models and still combine the reverse process with various Markov-Chain Monte Carlo (MCMC) methods. We evaluate our 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#29366;&#24577;&#37325;&#26500;&#25193;&#25955;&#31574;&#30053; (SRDP) &#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#26368;&#26032;&#30340;&#25193;&#25955;&#31574;&#30053;&#31867;&#20013;&#24341;&#20837;&#20102;&#29366;&#24577;&#37325;&#26500;&#29305;&#24449;&#23398;&#20064;&#65292;&#20197;&#35299;&#20915;&#33073;&#26426;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#21644;&#26377;&#25928;&#34920;&#31034;&#31574;&#30053;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.04726</link><description>&lt;p&gt;
&#33073;&#26426;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31163;&#25955;&#31574;&#30053;&#30340;&#25193;&#25955;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Diffusion Policies for Out-of-Distribution Generalization in Offline Reinforcement Learning. (arXiv:2307.04726v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04726
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#29366;&#24577;&#37325;&#26500;&#25193;&#25955;&#31574;&#30053; (SRDP) &#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#26368;&#26032;&#30340;&#25193;&#25955;&#31574;&#30053;&#31867;&#20013;&#24341;&#20837;&#20102;&#29366;&#24577;&#37325;&#26500;&#29305;&#24449;&#23398;&#20064;&#65292;&#20197;&#35299;&#20915;&#33073;&#26426;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#21644;&#26377;&#25928;&#34920;&#31034;&#31574;&#30053;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33073;&#26426;&#24378;&#21270;&#23398;&#20064; (RL) &#26041;&#27861;&#21033;&#29992;&#20197;&#21069;&#30340;&#32463;&#39564;&#26469;&#23398;&#20064;&#27604;&#29992;&#20110;&#25968;&#25454;&#25910;&#38598;&#30340;&#34892;&#20026;&#31574;&#30053;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#19982;&#34892;&#20026;&#20811;&#38534;&#30456;&#21453;&#65292;&#34892;&#20026;&#20811;&#38534;&#20551;&#35774;&#25968;&#25454;&#26159;&#20174;&#19987;&#23478;&#28436;&#31034;&#20013;&#25910;&#38598;&#30340;&#65292;&#32780;&#33073;&#26426; RL &#21487;&#20197;&#20351;&#29992;&#38750;&#19987;&#23478;&#25968;&#25454;&#21644;&#22810;&#27169;&#24577;&#34892;&#20026;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#33073;&#26426; RL &#31639;&#27861;&#22312;&#22788;&#29702;&#20998;&#24067;&#20559;&#31227;&#21644;&#26377;&#25928;&#34920;&#31034;&#31574;&#30053;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#22240;&#20026;&#35757;&#32451;&#36807;&#31243;&#20013;&#32570;&#20047;&#22312;&#32447;&#20132;&#20114;&#12290;&#20808;&#21069;&#20851;&#20110;&#33073;&#26426; RL &#30340;&#24037;&#20316;&#20351;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#26469;&#34920;&#31034;&#25968;&#25454;&#38598;&#20013;&#30340;&#22810;&#27169;&#24577;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24182;&#27809;&#26377;&#38024;&#23545;&#32531;&#35299;&#33073;&#26426;&#20998;&#24067;&#29366;&#24577;&#27867;&#21270;&#32780;&#21046;&#23450;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21517;&#20026;&#29366;&#24577;&#37325;&#26500;&#25193;&#25955;&#31574;&#30053; (SRDP)&#65292;&#23558;&#29366;&#24577;&#37325;&#26500;&#29305;&#24449;&#23398;&#20064;&#32435;&#20837;&#21040;&#26368;&#26032;&#30340;&#25193;&#25955;&#31574;&#30053;&#31867;&#20013;&#65292;&#20197;&#35299;&#20915;&#33073;&#26426;&#20998;&#24067;&#36890;&#29992;&#21270;&#38382;&#39064;&#12290;&#29366;&#24577;&#37325;&#26500;&#25439;&#22833;&#20419;&#36827;&#20102;&#26356;&#35814;&#32454;&#30340;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline Reinforcement Learning (RL) methods leverage previous experiences to learn better policies than the behavior policy used for data collection. In contrast to behavior cloning, which assumes the data is collected from expert demonstrations, offline RL can work with non-expert data and multimodal behavior policies. However, offline RL algorithms face challenges in handling distribution shifts and effectively representing policies due to the lack of online interaction during training. Prior work on offline RL uses conditional diffusion models to represent multimodal behavior in the dataset. Nevertheless, these methods are not tailored toward alleviating the out-of-distribution state generalization. We introduce a novel method, named State Reconstruction for Diffusion Policies (SRDP), incorporating state reconstruction feature learning in the recent class of diffusion policies to address the out-of-distribution generalization problem. State reconstruction loss promotes more descript
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#20316;&#29992;&#12290; &#21457;&#29616;&#22270;&#21367;&#31215;&#32593;&#32476;&#26174;&#33879;&#22686;&#24378;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#21306;&#22495;&#65292;&#22312;&#36825;&#20010;&#21306;&#22495;&#20869;&#20449;&#21495;&#23398;&#20064;&#36229;&#36234;&#20102;&#22122;&#22768;&#35760;&#24518;&#12290;</title><link>http://arxiv.org/abs/2306.13926</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20174;&#32467;&#26500;&#20449;&#24687;&#20013;&#33719;&#30410;&#30340;&#35777;&#26126;&#65306;&#19968;&#20010;&#29305;&#24449;&#23398;&#20064;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks Provably Benefit from Structural Information: A Feature Learning Perspective. (arXiv:2306.13926v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#20316;&#29992;&#12290; &#21457;&#29616;&#22270;&#21367;&#31215;&#32593;&#32476;&#26174;&#33879;&#22686;&#24378;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#21306;&#22495;&#65292;&#22312;&#36825;&#20010;&#21306;&#22495;&#20869;&#20449;&#21495;&#23398;&#20064;&#36229;&#36234;&#20102;&#22122;&#22768;&#35760;&#24518;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#22312;&#22270;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#21462;&#24471;&#20102;&#20808;&#39537;&#24615;&#36827;&#23637;&#65292;&#22312;&#22788;&#29702;&#22270;&#36755;&#20837;&#26102;&#34920;&#29616;&#20986;&#27604;&#22810;&#23618;&#24863;&#30693;&#22120;(MLPs)&#26356;&#20248;&#36234;&#30340;&#29305;&#24449;&#23398;&#20064;&#21644;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#29702;&#35299;GNN&#30340;&#29305;&#24449;&#23398;&#20064;&#26041;&#38754;&#20173;&#22788;&#20110;&#21021;&#22987;&#38454;&#27573;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30740;&#31350;&#22270;&#21367;&#31215;&#22312;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#20316;&#29992;&#26469;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20004;&#23618;&#22270;&#21367;&#31215;&#32593;&#32476;(GCNs)&#20013;&#20449;&#21495;&#23398;&#20064;&#21644;&#22122;&#22768;&#35760;&#24518;&#30340;&#19981;&#21516;&#21051;&#30011;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#20004;&#23618;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#36827;&#34892;&#23545;&#27604;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#23545;&#24212;&#30340;CNNs&#30456;&#27604;&#65292;&#22270;&#21367;&#31215;&#32593;&#32476;&#26174;&#33879;&#22686;&#24378;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#21306;&#22495;&#65292;&#22312;&#36825;&#20010;&#21306;&#22495;&#20869;&#20449;&#21495;&#23398;&#20064;&#36229;&#36234;&#20102;&#22122;&#22768;&#35760;&#24518;&#65292;&#24182;&#19988;&#36817;&#20284;&#20110;&#22240;&#23376;$\sqrt{D}^{q-2}$&#65292;&#20854;&#20013;$D$&#34920;&#31034;&#33410;&#28857;&#30340;&#26399;&#26395;&#24230;&#25968;&#65292;$q$&#34920;&#31034;ReLU&#28608;&#27963;&#21151;&#33021;&#30340;&#24130;&#27425;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have pioneered advancements in graph representation learning, exhibiting superior feature learning and performance over multilayer perceptrons (MLPs) when handling graph inputs. However, understanding the feature learning aspect of GNNs is still in its initial stage. This study aims to bridge this gap by investigating the role of graph convolution within the context of feature learning theory in neural networks using gradient descent training. We provide a distinct characterization of signal learning and noise memorization in two-layer graph convolutional networks (GCNs), contrasting them with two-layer convolutional neural networks (CNNs). Our findings reveal that graph convolution significantly augments the benign overfitting regime over the counterpart CNNs, where signal learning surpasses noise memorization, by approximately factor $\sqrt{D}^{q-2}$, with $D$ denoting a node's expected degree and $q$ being the power of the ReLU activation function where 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#30452;&#25509;&#21046;&#23450;&#25193;&#25955;&#22522;&#20110;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#20808;&#31163;&#25955;&#21270;&#20877;&#24212;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#36991;&#20813;&#21442;&#25968;&#32454;&#21270;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#65292;&#20026;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#25552;&#20379;&#20102;&#20934;&#21017;&#12290;</title><link>http://arxiv.org/abs/2302.10130</link><description>&lt;p&gt;
&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Infinite-Dimensional Diffusion Models. (arXiv:2302.10130v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10130
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#30452;&#25509;&#21046;&#23450;&#25193;&#25955;&#22522;&#20110;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#20808;&#31163;&#25955;&#21270;&#20877;&#24212;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#36991;&#20813;&#21442;&#25968;&#32454;&#21270;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#65292;&#20026;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#25552;&#20379;&#20102;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#37117;&#20135;&#29983;&#20102;&#28145;&#36828;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#37027;&#20123;&#25968;&#25454;&#26412;&#36136;&#19978;&#26159;&#26080;&#38480;&#32500;&#30340;&#39046;&#22495;&#65292;&#22914;&#22270;&#20687;&#25110;&#26102;&#38388;&#24207;&#21015;&#12290;&#26631;&#20934;&#26041;&#27861;&#26159;&#39318;&#20808;&#31163;&#25955;&#21270;&#25968;&#25454;&#65292;&#28982;&#21518;&#23558;&#25193;&#25955;&#27169;&#22411;&#24212;&#29992;&#20110;&#31163;&#25955;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#32454;&#21270;&#31163;&#25955;&#21270;&#21442;&#25968;&#26102;&#36890;&#24120;&#20250;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30452;&#25509;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#21046;&#23450;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#20989;&#25968;&#30340;&#29983;&#25104;&#24314;&#27169;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20844;&#24335;&#22312;&#26080;&#38480;&#32500;&#24230;&#29615;&#22659;&#20013;&#26159;&#33391;&#22909;&#23450;&#20041;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;&#20174;&#26679;&#26412;&#21040;&#30446;&#26631;&#27979;&#24230;&#30340;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#36824;&#21046;&#23450;&#20102;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#30340;&#20934;&#21017;&#12290;&#23545;&#20110;&#22270;&#20687;&#20998;&#24067;&#65292;&#36825;&#20123;&#20934;&#21017;&#19982;&#24403;&#21069;&#29992;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#32463;&#20856;&#36873;&#25321;&#19968;&#33268;&#12290;&#23545;&#20110;&#20854;&#20182;&#20998;&#24067;...
&lt;/p&gt;
&lt;p&gt;
Diffusion models have had a profound impact on many application areas, including those where data are intrinsically infinite-dimensional, such as images or time series. The standard approach is first to discretize and then to apply diffusion models to the discretized data. While such approaches are practically appealing, the performance of the resulting algorithms typically deteriorates as discretization parameters are refined. In this paper, we instead directly formulate diffusion-based generative models in infinite dimensions and apply them to the generative modeling of functions. We prove that our formulations are well posed in the infinite-dimensional setting and provide dimension-independent distance bounds from the sample to the target measure. Using our theory, we also develop guidelines for the design of infinite-dimensional diffusion models. For image distributions, these guidelines are in line with the canonical choices currently made for diffusion models. For other distribut
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32534;&#30721;&#35745;&#31639;&#21644;&#21521;&#37327;&#25215;&#35834;&#30340;&#25308;&#21344;&#24237;&#25269;&#25239;&#23433;&#20840;&#32858;&#21512;&#26041;&#26696;&#65292;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#12290;&#35813;&#26041;&#26696;&#36890;&#36807;RAM&#31192;&#23494;&#20849;&#20139;&#23558;&#26412;&#22320;&#26356;&#26032;&#20998;&#21106;&#25104;&#36739;&#23567;&#23376;&#21521;&#37327;&#65292;&#24182;&#20351;&#29992;&#21452;&#37325;RAMP&#20849;&#20139;&#25216;&#26415;&#23454;&#29616;&#25104;&#23545;&#36317;&#31163;&#30340;&#23433;&#20840;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2302.09913</link><description>&lt;p&gt;
&#22522;&#20110;&#32534;&#30721;&#35745;&#31639;&#21644;&#21521;&#37327;&#25215;&#35834;&#30340;&#25308;&#21344;&#24237;&#25269;&#25239;&#23433;&#20840;&#32858;&#21512;&#26041;&#26696;&#65292;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064; (arXiv:2302.09913v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
ByzSecAgg: A Byzantine-Resistant Secure Aggregation Scheme for Federated Learning Based on Coded Computing and Vector Commitment. (arXiv:2302.09913v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32534;&#30721;&#35745;&#31639;&#21644;&#21521;&#37327;&#25215;&#35834;&#30340;&#25308;&#21344;&#24237;&#25269;&#25239;&#23433;&#20840;&#32858;&#21512;&#26041;&#26696;&#65292;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#12290;&#35813;&#26041;&#26696;&#36890;&#36807;RAM&#31192;&#23494;&#20849;&#20139;&#23558;&#26412;&#22320;&#26356;&#26032;&#20998;&#21106;&#25104;&#36739;&#23567;&#23376;&#21521;&#37327;&#65292;&#24182;&#20351;&#29992;&#21452;&#37325;RAMP&#20849;&#20139;&#25216;&#26415;&#23454;&#29616;&#25104;&#23545;&#36317;&#31163;&#30340;&#23433;&#20840;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#32852;&#37030;&#23398;&#20064;&#20445;&#25252;&#26041;&#26696;&#65292;&#21487;&#20197;&#25269;&#24481;&#25308;&#21344;&#24237;&#25915;&#20987;&#21644;&#38544;&#31169;&#27844;&#38706;&#12290;&#36825;&#31181;&#26041;&#26696;&#36890;&#36807;&#22788;&#29702;&#21333;&#20010;&#26356;&#26032;&#26469;&#31649;&#29702;&#23545;&#25239;&#34892;&#20026;&#65292;&#24182;&#22312;&#25269;&#24481;&#20018;&#36890;&#33410;&#28857;&#30340;&#21516;&#26102;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#23545;&#26356;&#26032;&#21521;&#37327;&#36827;&#34892;&#23433;&#20840;&#31192;&#23494;&#20849;&#20139;&#30340;&#36890;&#20449;&#36127;&#36733;&#21487;&#33021;&#38750;&#24120;&#39640;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#26412;&#22320;&#26356;&#26032;&#20998;&#21106;&#25104;&#36739;&#23567;&#23376;&#21521;&#37327;&#24182;&#20351;&#29992;RAM&#31192;&#23494;&#20849;&#20139;&#30340;&#26041;&#26696;&#12290;&#20294;&#26159;&#65292;&#36825;&#31181;&#20849;&#20139;&#26041;&#27861;&#26080;&#27861;&#36827;&#34892;&#21452;&#32447;&#24615;&#35745;&#31639;&#65292;&#20363;&#22914;&#38656;&#35201;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#30340;&#25104;&#23545;&#36317;&#31163;&#35745;&#31639;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#27599;&#20010;&#29992;&#25143;&#37117;&#20250;&#36816;&#34892;&#21478;&#19968;&#36718;RAMP&#20849;&#20139;&#65292;&#35813;&#20849;&#20139;&#20855;&#26377;&#19981;&#21516;&#30340;&#25968;&#25454;&#23884;&#20837;&#20854;&#20013;&#12290;&#36825;&#31181;&#21463;&#32534;&#30721;&#35745;&#31639;&#24605;&#24819;&#21551;&#21457;&#30340;&#25216;&#26415;&#23454;&#29616;&#20102;&#25104;&#23545;&#36317;&#31163;&#30340;&#23433;&#20840;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose an efficient secure aggregation scheme for federated learning that is protected against Byzantine attacks and privacy leakages. Processing individual updates to manage adversarial behavior, while preserving privacy of data against colluding nodes, requires some sort of secure secret sharing. However, communication load for secret sharing of long vectors of updates can be very high. To resolve this issue, in the proposed scheme, local updates are partitioned into smaller sub-vectors and shared using ramp secret sharing. However, this sharing method does not admit bi-linear computations, such as pairwise distance calculations, needed by outlier-detection algorithms. To overcome this issue, each user runs another round of ramp sharing, with different embedding of data in the sharing polynomial. This technique, motivated by ideas from coded computing, enables secure computation of pairwise distance. In addition, to maintain the integrity and privacy of the local u
&lt;/p&gt;</description></item></channel></rss>