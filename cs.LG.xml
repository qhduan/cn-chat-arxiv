<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#36755;&#20837;&#33258;&#21160;&#32534;&#30721;&#22120;(MIAE)&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#36890;&#36807;&#35757;&#32451;MIAE&#27169;&#22411;&#65292;&#22312;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#24335;&#19979;&#23558;&#24322;&#26500;&#36755;&#20837;&#36716;&#25442;&#20026;&#36739;&#20302;&#32500;&#34920;&#31034;&#65292;&#26377;&#21161;&#20110;&#20998;&#31867;&#22120;&#21306;&#20998;&#27491;&#24120;&#34892;&#20026;&#21644;&#19981;&#21516;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2403.15511</link><description>&lt;p&gt;
IoT&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;&#20013;&#30340;&#22810;&#36755;&#20837;&#33258;&#21160;&#32534;&#30721;&#22120;&#24341;&#23548;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Multiple-Input Auto-Encoder Guided Feature Selection for IoT Intrusion Detection Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15511
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#36755;&#20837;&#33258;&#21160;&#32534;&#30721;&#22120;(MIAE)&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#36890;&#36807;&#35757;&#32451;MIAE&#27169;&#22411;&#65292;&#22312;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#24335;&#19979;&#23558;&#24322;&#26500;&#36755;&#20837;&#36716;&#25442;&#20026;&#36739;&#20302;&#32500;&#34920;&#31034;&#65292;&#26377;&#21161;&#20110;&#20998;&#31867;&#22120;&#21306;&#20998;&#27491;&#24120;&#34892;&#20026;&#21644;&#19981;&#21516;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;(IDSs)&#21463;&#30410;&#20110;IoT&#25968;&#25454;&#29305;&#24449;&#30340;&#22810;&#26679;&#24615;&#21644;&#27867;&#21270;&#65292;&#25968;&#25454;&#30340;&#22810;&#26679;&#24615;&#20351;&#24471;&#22312;IoT IDSs&#20013;&#35757;&#32451;&#26377;&#25928;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21464;&#24471;&#22256;&#38590;&#12290;&#26412;&#25991;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#36755;&#20837;&#33258;&#21160;&#32534;&#30721;&#22120;(MIAE)&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;MIAE&#30001;&#22810;&#20010;&#23376;&#32534;&#30721;&#22120;&#32452;&#25104;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#30340;&#19981;&#21516;&#26469;&#28304;&#30340;&#36755;&#20837;&#12290; MIAE&#27169;&#22411;&#20197;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#24335;&#36827;&#34892;&#35757;&#32451;&#65292;&#23558;&#24322;&#26500;&#36755;&#20837;&#36716;&#25442;&#20026;&#36739;&#20302;&#32500;&#34920;&#31034;&#65292;&#26377;&#21161;&#20110;&#20998;&#31867;&#22120;&#21306;&#20998;&#27491;&#24120;&#34892;&#20026;&#21644;&#19981;&#21516;&#31867;&#22411;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15511v1 Announce Type: cross  Abstract: While intrusion detection systems (IDSs) benefit from the diversity and generalization of IoT data features, the data diversity (e.g., the heterogeneity and high dimensions of data) also makes it difficult to train effective machine learning models in IoT IDSs. This also leads to potentially redundant/noisy features that may decrease the accuracy of the detection engine in IDSs. This paper first introduces a novel neural network architecture called Multiple-Input Auto-Encoder (MIAE). MIAE consists of multiple sub-encoders that can process inputs from different sources with different characteristics. The MIAE model is trained in an unsupervised learning mode to transform the heterogeneous inputs into lower-dimensional representation, which helps classifiers distinguish between normal behaviour and different types of attacks. To distil and retain more relevant features but remove less important/redundant ones during the training process,
&lt;/p&gt;</description></item><item><title>MGAS&#26159;&#19968;&#20010;&#22810;&#31890;&#24230;&#26550;&#26500;&#25628;&#32034;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#36890;&#36807;&#23398;&#20064;&#29305;&#23450;&#31890;&#24230;&#32423;&#21035;&#30340;&#31163;&#25955;&#21270;&#20989;&#25968;&#65292;&#33258;&#36866;&#24212;&#22320;&#30830;&#23450;&#21097;&#20313;&#27604;&#20363;&#65292;&#20174;&#32780;&#23454;&#29616;&#21516;&#26102;&#20248;&#21270;&#27169;&#22411;&#22823;&#23567;&#21644;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.15074</link><description>&lt;p&gt;
MGAS: &#22810;&#31890;&#24230;&#26550;&#26500;&#25628;&#32034;&#20197;&#23454;&#29616;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
MGAS: Multi-Granularity Architecture Search for Effective and Efficient Neural Networks. (arXiv:2310.15074v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15074
&lt;/p&gt;
&lt;p&gt;
MGAS&#26159;&#19968;&#20010;&#22810;&#31890;&#24230;&#26550;&#26500;&#25628;&#32034;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#36890;&#36807;&#23398;&#20064;&#29305;&#23450;&#31890;&#24230;&#32423;&#21035;&#30340;&#31163;&#25955;&#21270;&#20989;&#25968;&#65292;&#33258;&#36866;&#24212;&#22320;&#30830;&#23450;&#21097;&#20313;&#27604;&#20363;&#65292;&#20174;&#32780;&#23454;&#29616;&#21516;&#26102;&#20248;&#21270;&#27169;&#22411;&#22823;&#23567;&#21644;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#24494;&#20998;&#26550;&#26500;&#25628;&#32034;(DAS)&#36890;&#36807;&#26102;&#38388;&#39640;&#25928;&#30340;&#33258;&#21160;&#21270;&#25913;&#21464;&#20102;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#25628;&#32034;(NAS)&#30340;&#26041;&#24335;&#65292;&#20174;&#31163;&#25955;&#20505;&#36873;&#37319;&#26679;&#21644;&#35780;&#20272;&#36716;&#21464;&#20026;&#21487;&#24494;&#20998;&#36229;&#32593;&#32476;&#20248;&#21270;&#21644;&#31163;&#25955;&#21270;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;DAS&#26041;&#27861;&#35201;&#20040;&#21482;&#36827;&#34892;&#31895;&#31890;&#24230;&#30340;&#25805;&#20316;&#32423;&#25628;&#32034;&#65292;&#35201;&#20040;&#25163;&#21160;&#23450;&#20041;&#21097;&#20313;&#30340;&#32454;&#31890;&#24230;&#30340;&#26680;&#32423;&#21644;&#26435;&#37325;&#32423;&#21333;&#20301;&#30340;&#27604;&#20363;&#65292;&#20174;&#32780;&#26080;&#27861;&#21516;&#26102;&#20248;&#21270;&#27169;&#22411;&#22823;&#23567;&#21644;&#27169;&#22411;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#20026;&#20102;&#20943;&#23569;&#20869;&#23384;&#28040;&#32791;&#32780;&#29306;&#29298;&#20102;&#25628;&#32034;&#36136;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22810;&#31890;&#24230;&#26550;&#26500;&#25628;&#32034;(MGAS)&#65292;&#36825;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#20840;&#38754;&#32780;&#20869;&#23384;&#39640;&#25928;&#22320;&#25506;&#32034;&#22810;&#31890;&#24230;&#25628;&#32034;&#31354;&#38388;&#65292;&#21457;&#29616;&#26082;&#26377;&#25928;&#21448;&#39640;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23398;&#20064;&#20102;&#38024;&#23545;&#27599;&#20010;&#31890;&#24230;&#32423;&#21035;&#30340;&#31163;&#25955;&#21270;&#20989;&#25968;&#65292;&#26681;&#25454;&#19981;&#26029;&#28436;&#21270;&#30340;&#26550;&#26500;&#33258;&#36866;&#24212;&#22320;&#30830;&#23450;&#21097;&#20313;&#30340;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentiable architecture search (DAS) revolutionizes neural architecture search (NAS) with time-efficient automation, transitioning from discrete candidate sampling and evaluation to differentiable super-net optimization and discretization. However, existing DAS methods either only conduct coarse-grained operation-level search or manually define the remaining ratios for fine-grained kernel-level and weight-level units, which fail to simultaneously optimize model size and model performance. Furthermore, these methods compromise search quality to reduce memory consumption. To tackle these issues, we introduce multi-granularity architecture search (MGAS), a unified framework which aims to comprehensively and memory-efficiently explore the multi-granularity search space to discover both effective and efficient neural networks. Specifically, we learn discretization functions specific to each granularity level to adaptively determine the remaining ratios according to the evolving architec
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#24046;&#20998;&#31169;&#26377;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#39640;&#32500;&#21327;&#26041;&#24046;&#24863;&#30693;&#22343;&#20540;&#20272;&#35745;&#12290;&#22312;Mahalanobis&#35823;&#24046;&#24230;&#37327;&#20013;&#65292;&#20063;&#23601;&#26159;&#30456;&#23545;&#20110;&#21327;&#26041;&#24046;&#30340;&#24179;&#22343;&#35823;&#24046;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#24471;$\hat \mu$&#26356;&#25509;&#36817;$\mu$&#12290;</title><link>http://arxiv.org/abs/2301.12250</link><description>&lt;p&gt;
&#39640;&#32500;&#27425;&#39640;&#26031;&#20998;&#24067;&#30340;&#24555;&#36895;&#65292;&#26679;&#26412;&#26377;&#25928;&#65292;&#20223;&#23556;&#19981;&#21464;&#31169;&#26377;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Fast, Sample-Efficient, Affine-Invariant Private Mean and Covariance Estimation for Subgaussian Distributions. (arXiv:2301.12250v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#24046;&#20998;&#31169;&#26377;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#39640;&#32500;&#21327;&#26041;&#24046;&#24863;&#30693;&#22343;&#20540;&#20272;&#35745;&#12290;&#22312;Mahalanobis&#35823;&#24046;&#24230;&#37327;&#20013;&#65292;&#20063;&#23601;&#26159;&#30456;&#23545;&#20110;&#21327;&#26041;&#24046;&#30340;&#24179;&#22343;&#35823;&#24046;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#24471;$\hat \mu$&#26356;&#25509;&#36817;$\mu$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#24046;&#20998;&#31169;&#26377;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#39640;&#32500;&#21327;&#26041;&#24046;&#24863;&#30693;&#22343;&#20540;&#20272;&#35745;&#12290;&#20197;&#21069;&#24050;&#30693;&#21482;&#26377;&#25351;&#25968;&#26102;&#38388;&#20272;&#35745;&#22120;&#25165;&#33021;&#23454;&#29616;&#27492;&#20445;&#35777;&#12290;&#32473;&#23450;&#20174;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540; $&#956;$ &#21644;&#21327;&#26041;&#24046; $&#931;$ &#30340;&#65288;&#20122;&#65289;&#39640;&#26031;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;$n$&#20010;&#26679;&#26412;&#65292;&#25105;&#20204;&#30340; $(\varepsilon,\delta)$-&#24046;&#20998;&#24335;&#31169;&#26377;&#20272;&#35745;&#22120;&#29983;&#25104;$\tilde{\mu}$&#65292;&#20351;&#24471;&#21482;&#35201; $n \gtrsim \tfrac d {\alpha^2} + \tfrac{d \sqrt{\log 1/\delta}}{\alpha \varepsilon}+\frac{d\log 1/\delta}{\varepsilon}$&#65292;&#23601;&#28385;&#36275; $\|\mu - \tilde{\mu}\|_{\Sigma} \leq \alpha$&#12290;Mahalanobis&#35823;&#24046;&#24230;&#37327; $\|\mu - \hat{\mu}\|_{\Sigma}$ &#34913;&#37327;&#20102;$\hat \mu$&#19982;$\mu$&#22312;$\Sigma$&#30456;&#23545;&#36317;&#31163;; &#23427;&#34920;&#24449;&#20102;&#26679;&#26412;&#24179;&#22343;&#20540;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36816;&#34892;&#26102;&#38388;&#20026;$\tilde{O}(nd^{\omega - 1} + nd/\varepsilon)$&#65292;&#20854;&#20013;$\omega &lt; 2.38$&#26159;&#30697;&#38453;&#20056;&#27861;&#25351;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992; Brown&#12289;Gaboardi&#12289;Smith&#12289;Ullman &#21644; Zakynthiadaki[BGSUZ18] &#30340;&#25351;&#25968;&#26102;&#38388;&#26041;&#27861;&#26469;&#35745;&#31639;&#38382;&#39064;&#30340;&#26368;&#20248;&#20272;&#35745;&#30340;&#36275;&#22815;&#32479;&#35745;&#37327;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#36890;&#36807;&#38543;&#26426;&#32447;&#24615;&#20195;&#25968;&#26500;&#36896;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a fast, differentially private algorithm for high-dimensional covariance-aware mean estimation with nearly optimal sample complexity. Only exponential-time estimators were previously known to achieve this guarantee. Given $n$ samples from a (sub-)Gaussian distribution with unknown mean $\mu$ and covariance $\Sigma$, our $(\varepsilon,\delta)$-differentially private estimator produces $\tilde{\mu}$ such that $\|\mu - \tilde{\mu}\|_{\Sigma} \leq \alpha$ as long as $n \gtrsim \tfrac d {\alpha^2} + \tfrac{d \sqrt{\log 1/\delta}}{\alpha \varepsilon}+\frac{d\log 1/\delta}{\varepsilon}$. The Mahalanobis error metric $\|\mu - \hat{\mu}\|_{\Sigma}$ measures the distance between $\hat \mu$ and $\mu$ relative to $\Sigma$; it characterizes the error of the sample mean. Our algorithm runs in time $\tilde{O}(nd^{\omega - 1} + nd/\varepsilon)$, where $\omega &lt; 2.38$ is the matrix multiplication exponent.  We adapt an exponential-time approach of Brown, Gaboardi, Smith, Ullman, and Zakynthi
&lt;/p&gt;</description></item></channel></rss>