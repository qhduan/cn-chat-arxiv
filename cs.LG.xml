<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Hamiltonian&#30340;&#26412;&#22320;&#24615;&#27979;&#35797;&#20316;&#20026;&#23646;&#24615;&#27979;&#35797;&#38382;&#39064;&#65292;&#37325;&#28857;&#22312;&#20110;&#30830;&#23450;&#26410;&#30693;&#30340;$n$&#27604;&#29305;Hamiltonian&#26159;&#21542;&#26159;$k$&#23616;&#37096;&#30340;&#65292;&#36890;&#36807;&#23545;$H$&#30340;&#26102;&#38388;&#28436;&#21270;&#36827;&#34892;&#35775;&#38382;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.02968</link><description>&lt;p&gt;
Hamiltonian&#24615;&#36136;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Hamiltonian Property Testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Hamiltonian&#30340;&#26412;&#22320;&#24615;&#27979;&#35797;&#20316;&#20026;&#23646;&#24615;&#27979;&#35797;&#38382;&#39064;&#65292;&#37325;&#28857;&#22312;&#20110;&#30830;&#23450;&#26410;&#30693;&#30340;$n$&#27604;&#29305;Hamiltonian&#26159;&#21542;&#26159;$k$&#23616;&#37096;&#30340;&#65292;&#36890;&#36807;&#23545;$H$&#30340;&#26102;&#38388;&#28436;&#21270;&#36827;&#34892;&#35775;&#38382;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Hamiltonian&#26412;&#22320;&#24615;&#27979;&#35797;&#20316;&#20026;&#19968;&#20010;&#23646;&#24615;&#27979;&#35797;&#38382;&#39064;&#65292;&#21363;&#30830;&#23450;&#19968;&#20010;&#26410;&#30693;&#30340;$n$&#27604;&#29305;Hamiltonian $H$&#26159;&#21542;&#26159;$k$&#23616;&#37096;&#30340;&#65292;&#25110;&#32773;&#19982;&#25152;&#26377;$k$&#23616;&#37096;Hamiltonian&#37117;&#30456;&#36317;$\varepsilon$&#65292;&#24182;&#36890;&#36807;&#23545;$H$&#30340;&#26102;&#38388;&#28436;&#21270;&#36827;&#34892;&#35775;&#38382;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02968v1 Announce Type: cross  Abstract: Locality is a fundamental feature of many physical time evolutions. Assumptions on locality and related structural properties also underlie recently proposed procedures for learning an unknown Hamiltonian from access to the induced time evolution. However, no protocols to rigorously test whether an unknown Hamiltonian is local were known. We investigate Hamiltonian locality testing as a property testing problem, where the task is to determine whether an unknown $n$-qubit Hamiltonian $H$ is $k$-local or $\varepsilon$-far from all $k$-local Hamiltonians, given access to the time evolution along $H$. First, we emphasize the importance of the chosen distance measure: With respect to the operator norm, a worst-case distance measure, incoherent quantum locality testers require $\tilde{\Omega}(2^n)$ many time evolution queries and an expected total evolution time of $\tilde{\Omega}(2^n / \varepsilon)$, and even coherent testers need $\Omega(2
&lt;/p&gt;</description></item><item><title>"Lens"&#26159;&#19968;&#20010;&#22522;&#20110;T5&#26550;&#26500;&#30340;&#22522;&#30784;&#32593;&#32476;&#27969;&#37327;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#22823;&#35268;&#27169;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#39044;&#35757;&#32451;&#34920;&#31034;&#65292;&#33021;&#22815;&#22312;&#27969;&#37327;&#29702;&#35299;&#21644;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#31934;&#30830;&#30340;&#39044;&#27979;&#21644;&#29983;&#25104;&#12290;</title><link>https://arxiv.org/abs/2402.03646</link><description>&lt;p&gt;
Lens: &#32593;&#32476;&#27969;&#37327;&#30340;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Lens: A Foundation Model for Network Traffic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03646
&lt;/p&gt;
&lt;p&gt;
"Lens"&#26159;&#19968;&#20010;&#22522;&#20110;T5&#26550;&#26500;&#30340;&#22522;&#30784;&#32593;&#32476;&#27969;&#37327;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#22823;&#35268;&#27169;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#39044;&#35757;&#32451;&#34920;&#31034;&#65292;&#33021;&#22815;&#22312;&#27969;&#37327;&#29702;&#35299;&#21644;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#31934;&#30830;&#30340;&#39044;&#27979;&#21644;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#27969;&#37327;&#26159;&#25351;&#36890;&#36807;&#20114;&#32852;&#32593;&#25110;&#36830;&#25509;&#35745;&#31639;&#26426;&#30340;&#20219;&#20309;&#31995;&#32479;&#21457;&#36865;&#21644;&#25509;&#25910;&#30340;&#20449;&#24687;&#37327;&#12290;&#20998;&#26512;&#21644;&#29702;&#35299;&#32593;&#32476;&#27969;&#37327;&#23545;&#20110;&#25552;&#39640;&#32593;&#32476;&#23433;&#20840;&#21644;&#31649;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#21253;&#30340;&#29305;&#27530;&#29305;&#24615;&#65292;&#22914;&#24322;&#26500;&#26631;&#22836;&#21644;&#32570;&#20047;&#35821;&#20041;&#30340;&#21152;&#23494;&#36127;&#36733;&#65292;&#32593;&#32476;&#27969;&#37327;&#30340;&#20998;&#26512;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#25429;&#25417;&#27969;&#37327;&#30340;&#28508;&#22312;&#35821;&#20041;&#65292;&#19968;&#20123;&#30740;&#31350;&#37319;&#29992;&#20102;&#22522;&#20110;Transformer&#32534;&#30721;&#22120;&#25110;&#35299;&#30721;&#22120;&#30340;&#39044;&#35757;&#32451;&#25216;&#26415;&#65292;&#20174;&#22823;&#35268;&#27169;&#30340;&#27969;&#37327;&#25968;&#25454;&#20013;&#23398;&#20064;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#21482;&#22312;&#27969;&#37327;&#29702;&#35299;&#65288;&#20998;&#31867;&#65289;&#25110;&#27969;&#37327;&#29983;&#25104;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;Lens&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#30784;&#30340;&#32593;&#32476;&#27969;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;T5&#26550;&#26500;&#20174;&#22823;&#35268;&#27169;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#20013;&#23398;&#20064;&#39044;&#35757;&#32451;&#34920;&#31034;&#12290;&#20511;&#21161;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#26694;&#26550;&#30340;&#20248;&#21183;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#25429;&#25417;&#20840;&#23616;&#21644;&#23616;&#37096;&#29305;&#24449;&#65292;&#23454;&#29616;&#31934;&#30830;&#30340;&#27969;&#37327;&#39044;&#27979;&#21644;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network traffic refers to the amount of information being sent and received over the internet or any system that connects computers. Analyzing and understanding network traffic is vital for improving network security and management. However, the analysis of network traffic poses great challenges due to the unique characteristics of data packets, such as heterogeneous headers and encrypted payload lacking semantics. To capture the latent semantics of traffic, a few studies have adopted pre-training techniques based on the Transformer encoder or decoder to learn the representations from large-scale traffic data. However, these methods typically excel only in traffic understanding (classification) or traffic generation tasks. To address this issue, we develop Lens, a foundational network traffic model that leverages the T5 architecture to learn the pre-trained representations from large-scale unlabeled data. Harnessing the strength of the encoder-decoder framework, which captures the glob
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SoftCLT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#23454;&#20363;&#32423;&#21644;&#26102;&#38388;&#32423;&#36719;&#23545;&#27604;&#25439;&#22833;&#65292;&#35299;&#20915;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#20013;&#24573;&#30053;&#22266;&#26377;&#30456;&#20851;&#24615;&#25152;&#23548;&#33268;&#30340;&#23398;&#20064;&#34920;&#31034;&#36136;&#37327;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2312.16424</link><description>&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#30340;&#36719;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Soft Contrastive Learning for Time Series
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16424
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SoftCLT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#23454;&#20363;&#32423;&#21644;&#26102;&#38388;&#32423;&#36719;&#23545;&#27604;&#25439;&#22833;&#65292;&#35299;&#20915;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#20013;&#24573;&#30053;&#22266;&#26377;&#30456;&#20851;&#24615;&#25152;&#23548;&#33268;&#30340;&#23398;&#20064;&#34920;&#31034;&#36136;&#37327;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#24050;&#32463;&#34987;&#35777;&#26126;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#23545;&#20110;&#20174;&#26102;&#38388;&#24207;&#21015;&#20013;&#23398;&#20064;&#34920;&#31034;&#26159;&#26377;&#25928;&#30340;&#12290;&#28982;&#32780;&#65292;&#23558;&#26102;&#38388;&#24207;&#21015;&#20013;&#30456;&#20284;&#30340;&#23454;&#20363;&#25110;&#30456;&#37051;&#26102;&#38388;&#25139;&#30340;&#20540;&#36827;&#34892;&#23545;&#27604;&#20250;&#24573;&#30053;&#23427;&#20204;&#22266;&#26377;&#30340;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#23548;&#33268;&#23398;&#20064;&#34920;&#31034;&#30340;&#36136;&#37327;&#19979;&#38477;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SoftCLT&#65292;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26102;&#38388;&#24207;&#21015;&#36719;&#23545;&#27604;&#23398;&#20064;&#31574;&#30053;&#12290;&#36825;&#26159;&#36890;&#36807;&#24341;&#20837;&#20174;&#38646;&#21040;&#19968;&#30340;&#36719;&#36171;&#20540;&#30340;&#23454;&#20363;&#32423;&#21644;&#26102;&#38388;&#32423;&#23545;&#27604;&#25439;&#22833;&#26469;&#23454;&#29616;&#30340;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20026;1)&#22522;&#20110;&#25968;&#25454;&#31354;&#38388;&#19978;&#30340;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#36317;&#31163;&#23450;&#20041;&#20102;&#23454;&#20363;&#32423;&#23545;&#27604;&#25439;&#22833;&#30340;&#36719;&#36171;&#20540;&#65292;&#24182;&#20026;2)&#22522;&#20110;&#26102;&#38388;&#25139;&#20043;&#38388;&#30340;&#24046;&#24322;&#23450;&#20041;&#20102;&#26102;&#38388;&#32423;&#23545;&#27604;&#25439;&#22833;&#12290;SoftCLT&#26159;&#19968;&#31181;&#21363;&#25554;&#21363;&#29992;&#30340;&#26102;&#38388;&#24207;&#21015;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#39640;&#23398;&#20064;&#34920;&#31034;&#30340;&#36136;&#37327;&#65292;&#27809;&#26377;&#36807;&#22810;&#22797;&#26434;&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.16424v2 Announce Type: replace-cross  Abstract: Contrastive learning has shown to be effective to learn representations from time series in a self-supervised way. However, contrasting similar time series instances or values from adjacent timestamps within a time series leads to ignore their inherent correlations, which results in deteriorating the quality of learned representations. To address this issue, we propose SoftCLT, a simple yet effective soft contrastive learning strategy for time series. This is achieved by introducing instance-wise and temporal contrastive loss with soft assignments ranging from zero to one. Specifically, we define soft assignments for 1) instance-wise contrastive loss by the distance between time series on the data space, and 2) temporal contrastive loss by the difference of timestamps. SoftCLT is a plug-and-play method for time series contrastive learning that improves the quality of learned representations without bells and whistles. In experi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#26102;&#30340;&#26680;&#26497;&#38480;&#65292;&#21033;&#29992;&#25968;&#23398;&#26041;&#27861;&#23545;&#20854;&#28176;&#36817;&#29305;&#24615;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;&#24182;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#36825;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#36827;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2308.14555</link><description>&lt;p&gt;
&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#30340;&#26680;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data Sequences. (arXiv:2308.14555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#36941;&#21382;&#25968;&#25454;&#24207;&#21015;&#19978;&#35757;&#32451;&#26102;&#30340;&#26680;&#26497;&#38480;&#65292;&#21033;&#29992;&#25968;&#23398;&#26041;&#27861;&#23545;&#20854;&#28176;&#36817;&#29305;&#24615;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;&#24182;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#36825;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#36827;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#25968;&#23398;&#26041;&#27861;&#26469;&#25551;&#36848;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#30340;&#28176;&#36817;&#29305;&#24615;&#65292;&#20854;&#20013;&#38544;&#34255;&#21333;&#20803;&#30340;&#25968;&#37327;&#12289;&#24207;&#21015;&#20013;&#30340;&#25968;&#25454;&#26679;&#26412;&#12289;&#38544;&#34255;&#29366;&#24577;&#30340;&#26356;&#26032;&#21644;&#35757;&#32451;&#27493;&#39588;&#21516;&#26102;&#36235;&#20110;&#26080;&#31351;&#22823;&#12290;&#23545;&#20110;&#20855;&#26377;&#31616;&#21270;&#26435;&#37325;&#30697;&#38453;&#30340;RNN&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RNN&#25910;&#25947;&#21040;&#19982;&#38543;&#26426;&#20195;&#25968;&#26041;&#31243;&#30340;&#19981;&#21160;&#28857;&#32806;&#21512;&#30340;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;&#20998;&#26512;&#38656;&#35201;&#35299;&#20915;RNN&#25152;&#29305;&#26377;&#30340;&#20960;&#20010;&#25361;&#25112;&#12290;&#22312;&#20856;&#22411;&#30340;&#22343;&#22330;&#24212;&#29992;&#20013;&#65288;&#20363;&#22914;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65289;&#65292;&#31163;&#25955;&#30340;&#26356;&#26032;&#37327;&#20026;$\mathcal{O}(\frac{1}{N})$&#65292;&#26356;&#26032;&#30340;&#27425;&#25968;&#20026;$\mathcal{O}(N)$&#12290;&#22240;&#27492;&#65292;&#31995;&#32479;&#21487;&#20197;&#34920;&#31034;&#20026;&#36866;&#24403;ODE/PDE&#30340;Euler&#36924;&#36817;&#65292;&#24403;$N \rightarrow \infty$&#26102;&#25910;&#25947;&#21040;&#35813;ODE/PDE&#12290;&#28982;&#32780;&#65292;RNN&#30340;&#38544;&#34255;&#23618;&#26356;&#26032;&#20026;$\mathcal{O}(1)$&#12290;&#22240;&#27492;&#65292;RNN&#19981;&#33021;&#34920;&#31034;&#20026;ODE/PDE&#30340;&#31163;&#25955;&#21270;&#21644;&#26631;&#20934;&#22343;&#22330;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mathematical methods are developed to characterize the asymptotics of recurrent neural networks (RNN) as the number of hidden units, data samples in the sequence, hidden state updates, and training steps simultaneously grow to infinity. In the case of an RNN with a simplified weight matrix, we prove the convergence of the RNN to the solution of an infinite-dimensional ODE coupled with the fixed point of a random algebraic equation. The analysis requires addressing several challenges which are unique to RNNs. In typical mean-field applications (e.g., feedforward neural networks), discrete updates are of magnitude $\mathcal{O}(\frac{1}{N})$ and the number of updates is $\mathcal{O}(N)$. Therefore, the system can be represented as an Euler approximation of an appropriate ODE/PDE, which it will converge to as $N \rightarrow \infty$. However, the RNN hidden layer updates are $\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization of an ODE/PDE and standard mean-field tec
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24490;&#29615;&#31070;&#32463;&#31639;&#23376;&#23398;&#20064;&#38750;&#24179;&#31283;&#21160;&#21147;&#31995;&#32479;&#28436;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#26816;&#27979;&#26410;&#26469;&#30340;&#32763;&#36710;&#28857;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#30417;&#27979;&#19982;&#29289;&#29702;&#32422;&#26463;&#30340;&#20559;&#31163;&#26469;&#39044;&#27979;&#32763;&#36710;&#28857;&#65292;&#20174;&#32780;&#20351;&#24471;&#39044;&#27979;&#32467;&#26524;&#20855;&#26377;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.08794</link><description>&lt;p&gt;
&#21151;&#33021;&#31354;&#38388;&#20013;&#38750;&#24179;&#31283;&#21160;&#21147;&#23398;&#20013;&#30340;&#32763;&#36710;&#28857;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces. (arXiv:2308.08794v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08794
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24490;&#29615;&#31070;&#32463;&#31639;&#23376;&#23398;&#20064;&#38750;&#24179;&#31283;&#21160;&#21147;&#31995;&#32479;&#28436;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#26816;&#27979;&#26410;&#26469;&#30340;&#32763;&#36710;&#28857;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#30417;&#27979;&#19982;&#29289;&#29702;&#32422;&#26463;&#30340;&#20559;&#31163;&#26469;&#39044;&#27979;&#32763;&#36710;&#28857;&#65292;&#20174;&#32780;&#20351;&#24471;&#39044;&#27979;&#32467;&#26524;&#20855;&#26377;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32763;&#36710;&#28857;&#26159;&#38750;&#24179;&#31283;&#21644;&#28151;&#27788;&#21160;&#21147;&#31995;&#32479;&#28436;&#21270;&#20013;&#30340;&#31361;&#21464;&#12289;&#21095;&#28872;&#19988;&#24120;&#24120;&#19981;&#21487;&#36870;&#30340;&#21464;&#21270;&#12290;&#20363;&#22914;&#65292;&#39044;&#35745;&#28201;&#23460;&#27668;&#20307;&#27987;&#24230;&#30340;&#22686;&#21152;&#20250;&#23548;&#33268;&#20302;&#20113;&#35206;&#30422;&#30340;&#24613;&#21095;&#20943;&#23569;&#65292;&#34987;&#31216;&#20026;&#27668;&#20505;&#23398;&#30340;&#32763;&#36710;&#28857;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24490;&#29615;&#31070;&#32463;&#31639;&#23376;&#65288;RNO&#65289;&#23398;&#20064;&#36825;&#31181;&#38750;&#24179;&#31283;&#21160;&#21147;&#31995;&#32479;&#30340;&#28436;&#21270;&#65292;RNO&#21487;&#20197;&#23398;&#20064;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;&#22312;&#20165;&#35757;&#32451;RNO&#22312;&#32763;&#36710;&#28857;&#20043;&#21069;&#30340;&#21160;&#21147;&#23398;&#25968;&#25454;&#20043;&#21518;&#65292;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#26410;&#26469;&#30340;&#32763;&#36710;&#28857;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#30417;&#27979;&#19982;&#29289;&#29702;&#32422;&#26463;&#65288;&#22914;&#23432;&#24658;&#37327;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#65289;&#20559;&#31163;&#26469;&#39044;&#27979;&#32763;&#36710;&#28857;&#65292;&#20174;&#32780;&#20351;&#24471;&#23545;&#36825;&#20123;&#31361;&#21464;&#30340;&#39044;&#27979;&#20276;&#38543;&#30528;&#19968;&#31181;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#38750;&#24179;&#31283;&#24120;&#24494;&#20998;&#26041;&#31243;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tipping points are abrupt, drastic, and often irreversible changes in the evolution of non-stationary and chaotic dynamical systems. For instance, increased greenhouse gas concentrations are predicted to lead to drastic decreases in low cloud cover, referred to as a climatological tipping point. In this paper, we learn the evolution of such non-stationary dynamical systems using a novel recurrent neural operator (RNO), which learns mappings between function spaces. After training RNO on only the pre-tipping dynamics, we employ it to detect future tipping points using an uncertainty-based approach. In particular, we propose a conformal prediction framework to forecast tipping points by monitoring deviations from physics constraints (such as conserved quantities and partial differential equations), enabling forecasting of these abrupt changes along with a rigorous measure of uncertainty. We illustrate our proposed methodology on non-stationary ordinary and partial differential equations,
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#35843;&#26597;&#20102;&#24773;&#24863;&#35745;&#31639;&#20013;&#30340;&#20010;&#24615;&#21270;&#26041;&#27861;&#65292;&#23558;&#20854;&#20998;&#20026;&#19971;&#31867;&#65292;&#24182;&#32473;&#20986;&#20102;&#35843;&#26597;&#25991;&#29486;&#30340;&#32479;&#35745;&#20803;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2304.00377</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#24773;&#24863;&#35745;&#31639;&#22312;&#20154;&#26426;&#20132;&#20114;&#20013;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Personalized Affective Computing in Human-Machine Interaction. (arXiv:2304.00377v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00377
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35843;&#26597;&#20102;&#24773;&#24863;&#35745;&#31639;&#20013;&#30340;&#20010;&#24615;&#21270;&#26041;&#27861;&#65292;&#23558;&#20854;&#20998;&#20026;&#19971;&#31867;&#65292;&#24182;&#32473;&#20986;&#20102;&#35843;&#26597;&#25991;&#29486;&#30340;&#32479;&#35745;&#20803;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#26426;&#39046;&#22495;&#20013;&#65292;&#20010;&#24615;&#21270;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#25110;&#22810;&#20010;&#24615;&#33021;&#25351;&#26631;&#24182;&#36981;&#23432;&#29305;&#23450;&#32422;&#26463;&#26465;&#20214;&#26469;&#35757;&#32451;&#36814;&#21512;&#29305;&#23450;&#20010;&#20154;&#25110;&#20154;&#32676;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#24773;&#24863;&#21644;&#20154;&#26684;&#35745;&#31639;&#65288;&#20197;&#19979;&#31616;&#31216;&#24773;&#24863;&#35745;&#31639;&#65289;&#20013;&#20010;&#24615;&#21270;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#23545;&#24773;&#24863;&#35745;&#31639;&#20013;&#20010;&#24615;&#21270;&#30340;&#26368;&#26032;&#26041;&#27861;&#36827;&#34892;&#20102;&#35843;&#26597;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#28085;&#30422;&#20102;&#35757;&#32451;&#25216;&#26415;&#21644;&#30446;&#26631;&#65292;&#20197;&#23454;&#29616;&#24773;&#24863;&#35745;&#31639;&#27169;&#22411;&#30340;&#20010;&#24615;&#21270;&#23450;&#21046;&#12290;&#25105;&#20204;&#23558;&#29616;&#26377;&#30340;&#26041;&#27861;&#20998;&#20026;&#19971;&#31867;&#65306;&#65288;1&#65289;&#38754;&#21521;&#29305;&#23450;&#30446;&#26631;&#30340;&#27169;&#22411;&#65292;&#65288;2&#65289;&#38754;&#21521;&#29305;&#23450;&#32676;&#20307;&#30340;&#27169;&#22411;&#65292;&#65288;3&#65289;&#22522;&#20110;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#65288;4&#65289;&#24494;&#35843;&#26041;&#27861;&#65292;&#65288;5&#65289;&#22810;&#20219;&#21153;&#23398;&#20064;&#65292;&#65288;6&#65289;&#29983;&#25104;&#24335;&#27169;&#22411;&#21644;&#65288;7&#65289;&#29305;&#24449;&#22686;&#24378;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#35843;&#26597;&#25991;&#29486;&#30340;&#32479;&#35745;&#20803;&#20998;&#26512;&#65292;&#20998;&#26512;&#20102;&#19981;&#21516;&#24773;&#24863;&#35745;&#31639;&#20219;&#21153;&#12289;&#20132;&#20114;&#27169;&#24335;&#12289;&#20132;&#20114;&#19978;&#19979;&#25991;&#20197;&#21450;&#25152;&#28041;&#21450;&#39046;&#22495;&#30340;&#26222;&#36941;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In computing, the aim of personalization is to train a model that caters to a specific individual or group of people by optimizing one or more performance metrics and adhering to specific constraints. In this paper, we discuss the need for personalization in affective and personality computing (hereinafter referred to as affective computing). We present a survey of state-of-the-art approaches for personalization in affective computing. Our review spans training techniques and objectives towards the personalization of affective computing models. We group existing approaches into seven categories: (1) Target-specific Models, (2) Group-specific Models, (3) Weighting-based Approaches, (4) Fine-tuning Approaches, (5) Multitask Learning, (6) Generative-based Models, and (7) Feature Augmentation. Additionally, we provide a statistical meta-analysis of the surveyed literature, analyzing the prevalence of different affective computing tasks, interaction modes, interaction contexts, and the leve
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;MDP&#20998;&#35299;&#20026;&#22806;&#29983;&#21644;&#20869;&#29983;&#20004;&#20010;&#37096;&#20998;&#65292;&#20248;&#21270;&#20869;&#29983;&#22870;&#21169;&#65292;&#22312;&#29366;&#24577;&#31354;&#38388;&#30340;&#20869;&#29983;&#21644;&#22806;&#29983;&#29366;&#24577;&#31354;&#38388;&#27809;&#26377;&#20107;&#20808;&#32473;&#20986;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#27491;&#30830;&#30340;&#31639;&#27861;&#36827;&#34892;&#33258;&#21160;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.12957</link><description>&lt;p&gt;
&#20855;&#26377;&#22806;&#37096;&#29366;&#24577;&#21644;&#22870;&#21169;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with Exogenous States and Rewards. (arXiv:2303.12957v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12957
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;MDP&#20998;&#35299;&#20026;&#22806;&#29983;&#21644;&#20869;&#29983;&#20004;&#20010;&#37096;&#20998;&#65292;&#20248;&#21270;&#20869;&#29983;&#22870;&#21169;&#65292;&#22312;&#29366;&#24577;&#31354;&#38388;&#30340;&#20869;&#29983;&#21644;&#22806;&#29983;&#29366;&#24577;&#31354;&#38388;&#27809;&#26377;&#20107;&#20808;&#32473;&#20986;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#27491;&#30830;&#30340;&#31639;&#27861;&#36827;&#34892;&#33258;&#21160;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22806;&#37096;&#29366;&#24577;&#21464;&#37327;&#21644;&#22870;&#21169;&#20250;&#36890;&#36807;&#21521;&#22870;&#21169;&#20449;&#21495;&#27880;&#20837;&#19981;&#21487;&#25511;&#30340;&#21464;&#21270;&#32780;&#20943;&#24930;&#24378;&#21270;&#23398;&#20064;&#30340;&#36895;&#24230;&#12290;&#26412;&#25991;&#23545;&#22806;&#37096;&#29366;&#24577;&#21464;&#37327;&#21644;&#22870;&#21169;&#36827;&#34892;&#20102;&#27491;&#24335;&#21270;&#65292;&#24182;&#34920;&#26126;&#22914;&#26524;&#22870;&#21169;&#20989;&#25968;&#21152;&#27861;&#20998;&#35299;&#25104;&#20869;&#29983;&#21644;&#22806;&#29983;&#20004;&#20010;&#37096;&#20998;&#65292;MDP&#21487;&#20197;&#20998;&#35299;&#20026;&#19968;&#20010;&#22806;&#29983;&#39532;&#23572;&#21487;&#22827;&#22870;&#21169;&#36807;&#31243;&#65288;&#22522;&#20110;&#22806;&#37096;&#22870;&#21169;&#65289;&#21644;&#19968;&#20010;&#20869;&#29983;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;&#20248;&#21270;&#20869;&#29983;&#22870;&#21169;&#65289;&#12290;&#20869;&#29983;MDP&#30340;&#20219;&#20309;&#26368;&#20248;&#31574;&#30053;&#20063;&#26159;&#21407;&#22987;MDP&#30340;&#26368;&#20248;&#31574;&#30053;&#65292;&#20294;&#30001;&#20110;&#20869;&#29983;&#22870;&#21169;&#36890;&#24120;&#20855;&#26377;&#38477;&#20302;&#30340;&#26041;&#24046;&#65292;&#22240;&#27492;&#20869;&#29983;MDP&#26356;&#23481;&#26131;&#27714;&#35299;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29366;&#24577;&#31354;&#38388;&#20998;&#35299;&#20026;&#20869;&#22806;&#29983;&#29366;&#24577;&#31354;&#38388;&#30340;&#24773;&#20917;&#65292;&#32780;&#36825;&#31181;&#29366;&#24577;&#31354;&#38388;&#20998;&#35299;&#24182;&#27809;&#26377;&#32473;&#20986;&#65292;&#32780;&#26159;&#24517;&#39035;&#21457;&#29616;&#12290;&#26412;&#25991;&#20171;&#32461;&#24182;&#35777;&#26126;&#20102;&#22312;&#32447;&#24615;&#32452;&#21512;&#19979;&#21457;&#29616;&#20869;&#29983;&#21644;&#22806;&#29983;&#29366;&#24577;&#31354;&#38388;&#30340;&#31639;&#27861;&#30340;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exogenous state variables and rewards can slow reinforcement learning by injecting uncontrolled variation into the reward signal. This paper formalizes exogenous state variables and rewards and shows that if the reward function decomposes additively into endogenous and exogenous components, the MDP can be decomposed into an exogenous Markov Reward Process (based on the exogenous reward) and an endogenous Markov Decision Process (optimizing the endogenous reward). Any optimal policy for the endogenous MDP is also an optimal policy for the original MDP, but because the endogenous reward typically has reduced variance, the endogenous MDP is easier to solve. We study settings where the decomposition of the state space into exogenous and endogenous state spaces is not given but must be discovered. The paper introduces and proves correctness of algorithms for discovering the exogenous and endogenous subspaces of the state space when they are mixed through linear combination. These algorithms
&lt;/p&gt;</description></item></channel></rss>