<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24471;&#20986;&#20102;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#35774;&#32622;&#20013;&#30340;&#20108;&#36827;&#21046;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#21453;&#38169;&#35823;&#27010;&#29575;&#30340;&#23545;&#25968;&#21644;&#20445;&#30495;&#24230;&#30340;&#36127;&#23545;&#25968;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.17868</link><description>&lt;p&gt;
&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sample complexity of quantum hypothesis testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24471;&#20986;&#20102;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#35774;&#32622;&#20013;&#30340;&#20108;&#36827;&#21046;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#21453;&#38169;&#35823;&#27010;&#29575;&#30340;&#23545;&#25968;&#21644;&#20445;&#30495;&#24230;&#30340;&#36127;&#23545;&#25968;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#20154;&#20204;&#20174;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#30740;&#31350;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20154;&#20204;&#23545;&#38169;&#35823;&#27010;&#29575;&#30340;&#26368;&#20248;&#34928;&#20943;&#36895;&#29575;&#24863;&#20852;&#36259;&#65292;&#36825;&#20010;&#36895;&#29575;&#26159;&#26410;&#30693;&#29366;&#24577;&#30340;&#26679;&#26412;&#25968;&#37327;&#20989;&#25968;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#26088;&#22312;&#30830;&#23450;&#36798;&#21040;&#25152;&#38656;&#38169;&#35823;&#27010;&#29575;&#25152;&#38656;&#30340;&#26368;&#23569;&#26679;&#26412;&#25968;&#37327;&#12290;&#36890;&#36807;&#21033;&#29992;&#24050;&#26377;&#25991;&#29486;&#20013;&#20851;&#20110;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#20016;&#23500;&#30693;&#35782;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#35774;&#32622;&#20013;&#30340;&#20108;&#36827;&#21046;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#20010;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#30028;&#38480;&#12290;&#26356;&#35814;&#32454;&#22320;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#31216;&#20108;&#36827;&#21046;&#37327;&#23376;&#20551;&#35774;&#26816;&#39564;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#23545;&#21453;&#38169;&#35823;&#27010;&#29575;&#30340;&#23545;&#25968;&#21644;&#20445;&#30495;&#24230;&#30340;&#36127;&#23545;&#25968;&#30340;&#23545;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17868v1 Announce Type: cross  Abstract: Quantum hypothesis testing has been traditionally studied from the information-theoretic perspective, wherein one is interested in the optimal decay rate of error probabilities as a function of the number of samples of an unknown state. In this paper, we study the sample complexity of quantum hypothesis testing, wherein the goal is to determine the minimum number of samples needed to reach a desired error probability. By making use of the wealth of knowledge that already exists in the literature on quantum hypothesis testing, we characterize the sample complexity of binary quantum hypothesis testing in the symmetric and asymmetric settings, and we provide bounds on the sample complexity of multiple quantum hypothesis testing. In more detail, we prove that the sample complexity of symmetric binary quantum hypothesis testing depends logarithmically on the inverse error probability and inversely on the negative logarithm of the fidelity. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22522;&#32447;&#27169;&#22411;GraphMLP&#65292;&#22522;&#20110;&#22270;&#32467;&#26500;&#21644;MLP&#32593;&#32476;&#65292;&#22312;&#36710;&#36947;&#32423;&#20132;&#36890;&#39044;&#27979;&#20013;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#31354;&#38388;&#25299;&#25169;&#32467;&#26500;&#21644;&#39044;&#27979;&#20219;&#21153;&#65292;&#24110;&#21161;&#31361;&#30772;&#20102;&#29616;&#26377;&#35780;&#20272;&#26631;&#20934;&#21644;&#25968;&#25454;&#20844;&#24320;&#24615;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.14941</link><description>&lt;p&gt;
&#20174;&#22270;&#32467;&#26500;&#35282;&#24230;&#32479;&#19968;&#36710;&#36947;&#32423;&#20132;&#36890;&#39044;&#27979;&#65306;&#22522;&#20934;&#21644;&#22522;&#32447;
&lt;/p&gt;
&lt;p&gt;
Unifying Lane-Level Traffic Prediction from a Graph Structural Perspective: Benchmark and Baseline
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14941
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22522;&#32447;&#27169;&#22411;GraphMLP&#65292;&#22522;&#20110;&#22270;&#32467;&#26500;&#21644;MLP&#32593;&#32476;&#65292;&#22312;&#36710;&#36947;&#32423;&#20132;&#36890;&#39044;&#27979;&#20013;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#31354;&#38388;&#25299;&#25169;&#32467;&#26500;&#21644;&#39044;&#27979;&#20219;&#21153;&#65292;&#24110;&#21161;&#31361;&#30772;&#20102;&#29616;&#26377;&#35780;&#20272;&#26631;&#20934;&#21644;&#25968;&#25454;&#20844;&#24320;&#24615;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#39044;&#27979;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#26159;&#30740;&#31350;&#20013;&#30340;&#19968;&#20010;&#28966;&#28857;&#21644;&#20851;&#38190;&#39046;&#22495;&#65292;&#22312;&#36807;&#21435;&#20960;&#24180;&#37324;&#65292;&#26082;&#35265;&#35777;&#20102;&#20174;&#22478;&#24066;&#32423;&#21040;&#36947;&#36335;&#32423;&#39044;&#27979;&#21462;&#24471;&#30340;&#37325;&#22823;&#36827;&#23637;&#12290;&#38543;&#30528;&#36710;&#36742;&#23545;&#19968;&#20999;&#65288;V2X&#65289;&#25216;&#26415;&#12289;&#33258;&#21160;&#39550;&#39542;&#21644;&#20132;&#36890;&#39046;&#22495;&#30340;&#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#36827;&#27493;&#65292;&#36947;&#36335;&#32423;&#20132;&#36890;&#39044;&#27979;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#19981;&#21487;&#25110;&#32570;&#30340;&#26041;&#21521;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#39046;&#22495;&#30340;&#36827;&#19968;&#27493;&#36827;&#23637;&#21463;&#21040;&#20102;&#20840;&#38754;&#21644;&#32479;&#19968;&#30340;&#35780;&#20272;&#26631;&#20934;&#30340;&#32570;&#20047;&#20197;&#21450;&#26377;&#38480;&#30340;&#20844;&#24320;&#25968;&#25454;&#21644;&#20195;&#30721;&#30340;&#38459;&#30861;&#12290;&#26412;&#25991;&#23545;&#36710;&#36947;&#32423;&#20132;&#36890;&#39044;&#27979;&#20013;&#29616;&#26377;&#30740;&#31350;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#20998;&#26512;&#21644;&#20998;&#31867;&#65292;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#31354;&#38388;&#25299;&#25169;&#32467;&#26500;&#21644;&#39044;&#27979;&#20219;&#21153;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;&#32467;&#26500;&#21644;MLP&#32593;&#32476;&#30340;&#31616;&#21333;&#22522;&#32447;&#27169;&#22411;GraphMLP&#12290;&#25105;&#20204;&#22797;&#21046;&#20102;&#29616;&#26377;&#30740;&#31350;&#20013;&#23578;&#19981;&#20844;&#24320;&#30340;&#20195;&#30721;&#65292;&#24182;&#22522;&#20110;&#27492;&#20805;&#20998;&#32780;&#20844;&#27491;&#22320;&#35780;&#20272;&#20102;&#21508;&#31181;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14941v1 Announce Type: cross  Abstract: Traffic prediction has long been a focal and pivotal area in research, witnessing both significant strides from city-level to road-level predictions in recent years. With the advancement of Vehicle-to-Everything (V2X) technologies, autonomous driving, and large-scale models in the traffic domain, lane-level traffic prediction has emerged as an indispensable direction. However, further progress in this field is hindered by the absence of comprehensive and unified evaluation standards, coupled with limited public availability of data and code. This paper extensively analyzes and categorizes existing research in lane-level traffic prediction, establishes a unified spatial topology structure and prediction tasks, and introduces a simple baseline model, GraphMLP, based on graph structure and MLP networks. We have replicated codes not publicly available in existing studies and, based on this, thoroughly and fairly assessed various models in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#31639;&#27861;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#25512;&#29702;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#33268;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#36827;&#34892;&#20102;&#19968;&#20123;&#26816;&#39564;&#20551;&#35774;&#30340;&#25512;&#29702;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#26469;&#35745;&#31639;&#19968;&#20010;&#32473;&#23450;&#31639;&#27861;&#19982;&#21069;&#27839;&#19978;&#26368;&#20844;&#24179;&#28857;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#25551;&#36848;&#20102;&#23427;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2402.08879</link><description>&lt;p&gt;
&#19968;&#20010;&#31639;&#27861;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Inference for an Algorithmic Fairness-Accuracy Frontier
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#31639;&#27861;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#25512;&#29702;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#33268;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#36827;&#34892;&#20102;&#19968;&#20123;&#26816;&#39564;&#20551;&#35774;&#30340;&#25512;&#29702;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#26469;&#35745;&#31639;&#19968;&#20010;&#32473;&#23450;&#31639;&#27861;&#19982;&#21069;&#27839;&#19978;&#26368;&#20844;&#24179;&#28857;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#25551;&#36848;&#20102;&#23427;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#36807;&#31243;&#36234;&#26469;&#36234;&#20381;&#36182;&#20110;&#31639;&#27861;&#30340;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#31639;&#27861;&#30340;&#39044;&#27979;&#33021;&#21147;&#22312;&#20154;&#21475;&#30340;&#19981;&#21516;&#23376;&#32676;&#20307;&#20013;&#32463;&#24120;&#20986;&#29616;&#31995;&#32479;&#24615;&#21464;&#21270;&#12290;&#34429;&#28982;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#37117;&#26159;&#31639;&#27861;&#30340;&#26399;&#26395;&#29305;&#24615;&#65292;&#20294;&#23427;&#20204;&#24120;&#24120;&#26159;&#30456;&#20114;&#29306;&#29298;&#30340;&#12290;&#37027;&#20040;&#65292;&#24403;&#38754;&#23545;&#26377;&#38480;&#30340;&#25968;&#25454;&#26102;&#65292;&#19968;&#20010;&#27880;&#37325;&#20844;&#24179;&#24615;&#30340;&#20915;&#31574;&#32773;&#24212;&#35813;&#24590;&#20040;&#20570;&#21602;?&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;Liang&#65292;Lu&#21644;Mu&#65288;2023&#65289;&#25552;&#20986;&#30340;&#19968;&#20010;&#29702;&#35770;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#21069;&#27839;&#25552;&#20379;&#20102;&#19968;&#33268;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20986;&#20102;&#26816;&#39564;&#20551;&#35774;&#30340;&#25512;&#29702;&#26041;&#27861;&#12290;&#36825;&#20123;&#20551;&#35774;&#22312;&#20844;&#24179;&#24615;&#25991;&#29486;&#20013;&#24341;&#36215;&#20102;&#24456;&#22810;&#20851;&#27880;&#65292;&#20363;&#22914;(i)&#20840;&#38754;&#25490;&#38500;&#22312;&#31639;&#27861;&#35757;&#32451;&#20013;&#20351;&#29992;&#19968;&#20010;&#21327;&#21464;&#37327;&#26159;&#21542;&#26159;&#26368;&#20248;&#30340;&#65292;(ii)&#26159;&#21542;&#23384;&#22312;&#23545;&#29616;&#26377;&#31639;&#27861;&#26356;&#23569;&#27495;&#35270;&#24615;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#25105;&#20204;&#36824;&#20026;&#32473;&#23450;&#31639;&#27861;&#19982;&#21069;&#27839;&#19978;&#26368;&#20844;&#24179;&#28857;&#20043;&#38388;&#30340;&#36317;&#31163;&#25552;&#20379;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#65292;&#24182;&#25551;&#36848;&#20102;&#23427;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08879v1 Announce Type: cross Abstract: Decision-making processes increasingly rely on the use of algorithms. Yet, algorithms' predictive ability frequently exhibit systematic variation across subgroups of the population. While both fairness and accuracy are desirable properties of an algorithm, they often come at the cost of one another. What should a fairness-minded policymaker do then, when confronted with finite data? In this paper, we provide a consistent estimator for a theoretical fairness-accuracy frontier put forward by Liang, Lu and Mu (2023) and propose inference methods to test hypotheses that have received much attention in the fairness literature, such as (i) whether fully excluding a covariate from use in training the algorithm is optimal and (ii) whether there are less discriminatory alternatives to an existing algorithm. We also provide an estimator for the distance between a given algorithm and the fairest point on the frontier, and characterize its asymptot
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#38598;&#20013;&#20110;&#19981;&#21464;&#27169;&#22411;&#30340;&#29702;&#35770;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#24341;&#20837;&#23436;&#22791;&#30340;&#35774;&#35745;GeoNGNN&#65292;&#24182;&#21033;&#29992;&#20854;&#20316;&#20026;&#29702;&#35770;&#24037;&#20855;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;E(3)-&#23436;&#22791;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04836</link><description>&lt;p&gt;
&#20851;&#20110;&#19981;&#21464;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23436;&#22791;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Completeness of Invariant Geometric Deep Learning Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04836
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#38598;&#20013;&#20110;&#19981;&#21464;&#27169;&#22411;&#30340;&#29702;&#35770;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#24341;&#20837;&#23436;&#22791;&#30340;&#35774;&#35745;GeoNGNN&#65292;&#24182;&#21033;&#29992;&#20854;&#20316;&#20026;&#29702;&#35770;&#24037;&#20855;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;E(3)-&#23436;&#22791;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21464;&#27169;&#22411;&#26159;&#19968;&#31867;&#37325;&#35201;&#30340;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#20449;&#24687;&#20016;&#23500;&#30340;&#20960;&#20309;&#29305;&#24449;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#20960;&#20309;&#34920;&#31034;&#12290;&#36825;&#20123;&#27169;&#22411;&#20197;&#20854;&#31616;&#21333;&#24615;&#12289;&#33391;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#21644;&#35745;&#31639;&#25928;&#29575;&#32780;&#38395;&#21517;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#29702;&#35770;&#34920;&#36798;&#33021;&#21147;&#20173;&#28982;&#19981;&#28165;&#26970;&#65292;&#38480;&#21046;&#20102;&#23545;&#36825;&#31181;&#27169;&#22411;&#28508;&#21147;&#30340;&#28145;&#20837;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38598;&#20013;&#35752;&#35770;&#19981;&#21464;&#27169;&#22411;&#30340;&#29702;&#35770;&#34920;&#36798;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#20005;&#26684;&#38480;&#21046;&#20102;&#26368;&#32463;&#20856;&#30340;&#19981;&#21464;&#27169;&#22411;Vanilla DisGNN&#65288;&#32467;&#21512;&#36317;&#31163;&#30340;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23558;&#20854;&#19981;&#21487;&#35782;&#21035;&#30340;&#24773;&#20917;&#20165;&#38480;&#20110;&#39640;&#24230;&#23545;&#31216;&#30340;&#20960;&#20309;&#22270;&#24418;&#12290;&#20026;&#20102;&#25171;&#30772;&#36825;&#20123;&#29305;&#27530;&#24773;&#20917;&#30340;&#23545;&#31216;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#23436;&#22791;&#30340;&#19981;&#21464;&#35774;&#35745;&#65292;&#21363;&#23884;&#22871;Vanilla DisGNN&#30340;GeoNGNN&#12290;&#21033;&#29992;GeoNGNN&#20316;&#20026;&#29702;&#35770;&#24037;&#20855;&#65292;&#25105;&#20204;&#39318;&#27425;&#35777;&#26126;&#20102;E(3)-&#23436;&#22791;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Invariant models, one important class of geometric deep learning models, are capable of generating meaningful geometric representations by leveraging informative geometric features. These models are characterized by their simplicity, good experimental results and computational efficiency. However, their theoretical expressive power still remains unclear, restricting a deeper understanding of the potential of such models. In this work, we concentrate on characterizing the theoretical expressiveness of invariant models. We first rigorously bound the expressiveness of the most classical invariant model, Vanilla DisGNN (message passing neural networks incorporating distance), restricting its unidentifiable cases to be only those highly symmetric geometric graphs. To break these corner cases' symmetry, we introduce a simple yet E(3)-complete invariant design by nesting Vanilla DisGNN, named GeoNGNN. Leveraging GeoNGNN as a theoretical tool, we for the first time prove the E(3)-completeness 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#29992;&#20110;&#27714;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#21644;O(&#949;^(-4))&#12290;</title><link>https://arxiv.org/abs/2402.03352</link><description>&lt;p&gt;
&#38754;&#21521;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#21407;&#22987;&#23545;&#20598;&#20132;&#26367;&#25237;&#24433;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Zeroth-Order primal-dual Alternating Projection Gradient Algorithms for Nonconvex Minimax Problems with Coupled linear Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#29992;&#20110;&#27714;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#21644;O(&#949;^(-4))&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#35774;&#32622;&#19979;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#36825;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#21644;&#20854;&#20182;&#39046;&#22495;&#20013;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20363;&#22914;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#21644;&#32593;&#32476;&#27969;&#38382;&#39064;&#20013;&#30340;&#23545;&#25239;&#25915;&#20987;&#31561;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#20998;&#21035;&#26159;&#38646;&#38454;&#21407;&#22987;&#23545;&#20598;&#20132;&#26367;&#25237;&#24433;&#26799;&#24230;&#65288;ZO-PDAPG&#65289;&#31639;&#27861;&#21644;&#38646;&#38454;&#27491;&#21017;&#21160;&#37327;&#21407;&#22987;&#23545;&#20598;&#25237;&#24433;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-RMPDPG&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#38750;&#20984;-(&#24378;)&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;&#31639;&#27861;&#33719;&#24471;&#19968;&#20010;&#949;-&#31283;&#23450;&#28857;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#65288;&#23545;&#20110;&#27714;&#35299;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65289;&#21644;O(&#949;^(-4))&#65288;&#23545;&#20110;&#27714;&#35299;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study zeroth-order algorithms for nonconvex minimax problems with coupled linear constraints under the deterministic and stochastic settings, which have attracted wide attention in machine learning, signal processing and many other fields in recent years, e.g., adversarial attacks in resource allocation problems and network flow problems etc. We propose two single-loop algorithms, namely the zero-order primal-dual alternating projected gradient (ZO-PDAPG) algorithm and the zero-order regularized momentum primal-dual projected gradient algorithm (ZO-RMPDPG), for solving deterministic and stochastic nonconvex-(strongly) concave minimax problems with coupled linear constraints. The iteration complexity of the two proposed algorithms to obtain an $\varepsilon$-stationary point are proved to be $\mathcal{O}(\varepsilon ^{-2})$ (resp. $\mathcal{O}(\varepsilon ^{-4})$) for solving nonconvex-strongly concave (resp. nonconvex-concave) minimax problems with coupled linear const
&lt;/p&gt;</description></item><item><title>&#35299;&#37322;&#31639;&#27861;&#24448;&#24448;&#25968;&#23398;&#19978;&#22797;&#26434;&#19988;&#38590;&#20197;&#35299;&#37322;&#65292;&#36825;&#23548;&#33268;&#35299;&#37322;&#38169;&#35823;&#12290;&#20026;&#20102;&#21521;&#21069;&#25512;&#36827;&#65292;&#35299;&#37322;&#31639;&#27861;&#38656;&#35201;&#26126;&#30830;&#20854;&#36755;&#20986;&#30340;&#35299;&#37322;&#26041;&#24335;&#65292;&#24182;&#28548;&#28165;&#21487;&#20197;&#21644;&#19981;&#33021;&#22238;&#31572;&#30340;&#38382;&#39064;&#12290;&#36825;&#19968;&#35770;&#28857;&#22522;&#20110;&#32479;&#35745;&#23398;&#21644;&#35299;&#37322;&#20043;&#38388;&#30340;&#21306;&#21035;&#65292;&#20197;&#21450;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#21644;&#24212;&#29992;&#32479;&#35745;&#23398;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02870</link><description>&lt;p&gt;
&#27809;&#26377;&#35299;&#37322;&#30340;&#32479;&#35745;&#23398;&#65306;&#23545;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#30340;&#20919;&#38745;&#35266;&#23519;
&lt;/p&gt;
&lt;p&gt;
Statistics without Interpretation: A Sober Look at Explainable Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02870
&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#31639;&#27861;&#24448;&#24448;&#25968;&#23398;&#19978;&#22797;&#26434;&#19988;&#38590;&#20197;&#35299;&#37322;&#65292;&#36825;&#23548;&#33268;&#35299;&#37322;&#38169;&#35823;&#12290;&#20026;&#20102;&#21521;&#21069;&#25512;&#36827;&#65292;&#35299;&#37322;&#31639;&#27861;&#38656;&#35201;&#26126;&#30830;&#20854;&#36755;&#20986;&#30340;&#35299;&#37322;&#26041;&#24335;&#65292;&#24182;&#28548;&#28165;&#21487;&#20197;&#21644;&#19981;&#33021;&#22238;&#31572;&#30340;&#38382;&#39064;&#12290;&#36825;&#19968;&#35770;&#28857;&#22522;&#20110;&#32479;&#35745;&#23398;&#21644;&#35299;&#37322;&#20043;&#38388;&#30340;&#21306;&#21035;&#65292;&#20197;&#21450;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#21644;&#24212;&#29992;&#32479;&#35745;&#23398;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20851;&#20110;&#35299;&#37322;&#31639;&#27861;&#30340;&#24555;&#36895;&#21457;&#23637;&#30340;&#25991;&#29486;&#20013;&#65292;&#36825;&#20123;&#31639;&#27861;&#24448;&#24448;&#19981;&#28165;&#26970;&#25152;&#29992;&#20110;&#20309;&#22788;&#21450;&#20854;&#20351;&#29992;&#26041;&#24335;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#26159;&#22240;&#20026;&#35299;&#37322;&#31639;&#27861;&#24448;&#24448;&#22312;&#25968;&#23398;&#19978;&#22797;&#26434;&#19988;&#38590;&#20197;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#27809;&#26377;&#28165;&#26224;&#35299;&#37322;&#30340;&#22797;&#26434;&#32479;&#35745;&#26041;&#27861;&#24456;&#21487;&#33021;&#23548;&#33268;&#35299;&#37322;&#30340;&#38169;&#35823;&#65292;&#36825;&#19968;&#20107;&#23454;&#22312;&#25991;&#29486;&#20013;&#36234;&#26469;&#36234;&#26126;&#26174;&#12290;&#20026;&#20102;&#21521;&#21069;&#25512;&#36827;&#65292;&#20851;&#20110;&#35299;&#37322;&#31639;&#27861;&#30340;&#35770;&#25991;&#24212;&#26126;&#30830;&#35299;&#37322;&#31639;&#27861;&#30340;&#36755;&#20986;&#22914;&#20309;&#35299;&#37322;&#12290;&#20182;&#20204;&#36824;&#24212;&#28548;&#28165;&#22312;&#32473;&#20986;&#35299;&#37322;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#22238;&#31572;&#21738;&#20123;&#20851;&#20110;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;&#21738;&#20123;&#38382;&#39064;&#26080;&#27861;&#22238;&#31572;&#12290;&#25105;&#20204;&#30340;&#35770;&#28857;&#22522;&#20110;&#32479;&#35745;&#23398;&#21644;&#23427;&#20204;&#30340;&#35299;&#37322;&#20043;&#38388;&#30340;&#21306;&#21035;&#12290;&#23427;&#36824;&#20381;&#36182;&#20110;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#21644;&#24212;&#29992;&#32479;&#35745;&#23398;&#20043;&#38388;&#30340;&#30456;&#20284;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the rapidly growing literature on explanation algorithms, it often remains unclear what precisely these algorithms are for and how they should be used. We argue that this is because explanation algorithms are often mathematically complex but don't admit a clear interpretation. Unfortunately, complex statistical methods that don't have a clear interpretation are bound to lead to errors in interpretation, a fact that has become increasingly apparent in the literature. In order to move forward, papers on explanation algorithms should make clear how precisely the output of the algorithms should be interpreted. They should also clarify what questions about the function can and cannot be answered given the explanations. Our argument is based on the distinction between statistics and their interpretation. It also relies on parallels between explainable machine learning and applied statistics.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#19981;&#24179;&#34913;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#24179;&#22374;&#24230;&#37327;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25512;&#24191;&#21040;&#20998;&#24067;&#24635;&#36136;&#37327;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#19981;&#24179;&#34913;&#26368;&#20248;&#36755;&#36816;&#21644;&#25968;&#25454;&#20998;&#24067;&#20998;&#26512;&#12290;&#35770;&#25991;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#35745;&#31639;&#20986;&#20004;&#20010;&#32473;&#23450;&#27979;&#24230;&#20043;&#38388;&#36317;&#31163;&#30340;&#26368;&#20339;&#27979;&#35797;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#23454;&#39564;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.01039</link><description>&lt;p&gt;
&#35745;&#31639;&#19981;&#24179;&#34913;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163; - &#24179;&#22374;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Computing the Distance between unbalanced Distributions -- The flat Metric. (arXiv:2308.01039v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01039
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#19981;&#24179;&#34913;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#24179;&#22374;&#24230;&#37327;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25512;&#24191;&#21040;&#20998;&#24067;&#24635;&#36136;&#37327;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#19981;&#24179;&#34913;&#26368;&#20248;&#36755;&#36816;&#21644;&#25968;&#25454;&#20998;&#24067;&#20998;&#26512;&#12290;&#35770;&#25991;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#35745;&#31639;&#20986;&#20004;&#20010;&#32473;&#23450;&#27979;&#24230;&#20043;&#38388;&#36317;&#31163;&#30340;&#26368;&#20339;&#27979;&#35797;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#23454;&#39564;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#20219;&#24847;&#32500;&#24230;&#35745;&#31639;&#24179;&#22374;&#24230;&#37327;&#30340;&#23454;&#29616;&#12290;&#24179;&#22374;&#24230;&#37327;&#65292;&#20063;&#31216;&#20026;&#21452;&#36793;&#30028;Lipschitz&#36317;&#31163;&#65292;&#23558;&#20247;&#25152;&#21608;&#30693;&#30340;Wasserstein&#36317;&#31163;W1&#25512;&#24191;&#21040;&#20102;&#20998;&#24067;&#24635;&#36136;&#37327;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#12290;&#36825;&#23545;&#20110;&#19981;&#24179;&#34913;&#26368;&#20248;&#36755;&#36816;&#20219;&#21153;&#21644;&#25968;&#25454;&#20998;&#24067;&#20998;&#26512;&#20013;&#65292;&#26679;&#26412;&#22823;&#23567;&#37325;&#35201;&#25110;&#32773;&#24402;&#19968;&#21270;&#19981;&#21487;&#33021;&#30340;&#24773;&#20917;&#20855;&#26377;&#29305;&#27530;&#30340;&#24847;&#20041;&#12290;&#35813;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#26469;&#30830;&#23450;&#23454;&#29616;&#20004;&#20010;&#32473;&#23450;&#27979;&#24230;&#20043;&#38388;&#36317;&#31163;&#30340;&#26368;&#20339;&#27979;&#35797;&#20989;&#25968;&#12290;&#25105;&#20204;&#29305;&#21035;&#27880;&#37325;&#23454;&#29616;&#20102;&#20174;&#29420;&#31435;&#35757;&#32451;&#30340;&#32593;&#32476;&#35745;&#31639;&#20986;&#30340;&#25104;&#23545;&#36317;&#31163;&#30340;&#21487;&#27604;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#23454;&#39564;&#35777;&#26126;&#20102;&#36755;&#20986;&#30340;&#36136;&#37327;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#19968;&#20123;&#26377;&#23454;&#38469;&#30495;&#20540;&#30340;&#23454;&#39564;&#20197;&#21450;&#20351;&#29992;&#27169;&#25311;&#25968;&#25454;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide an implementation to compute the flat metric in any dimension. The flat metric, also called dual bounded Lipschitz distance, generalizes the well-known Wasserstein distance W1 to the case that the distributions are of unequal total mass. This is of particular interest for unbalanced optimal transport tasks and for the analysis of data distributions where the sample size is important or normalization is not possible. The core of the method is based on a neural network to determine on optimal test function realizing the distance between two given measures. Special focus was put on achieving comparability of pairwise computed distances from independently trained networks. We tested the quality of the output in several experiments where ground truth was available as well as with simulated data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.05857</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#21487;&#20197;&#34987;&#21098;&#26525;&#21040;&#22810;&#20040;&#31232;&#30095;&#65306;&#20960;&#20309;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Sparse Can We Prune A Deep Network: A Geometric Viewpoint. (arXiv:2306.05857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#20043;&#19968;&#12290;&#34429;&#28982;&#23427;&#21487;&#20197;&#25552;&#20379;&#20986;&#33394;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20294;&#21516;&#26102;&#20063;&#24378;&#21152;&#20102;&#37325;&#22823;&#30340;&#23384;&#20648;&#36127;&#25285;&#65292;&#22240;&#27492;&#26377;&#24517;&#35201;&#30740;&#31350;&#32593;&#32476;&#21098;&#26525;&#12290;&#19968;&#20010;&#33258;&#28982;&#32780;&#22522;&#26412;&#30340;&#38382;&#39064;&#26159;&#65306;&#25105;&#20204;&#33021;&#21098;&#26525;&#19968;&#20010;&#28145;&#24230;&#32593;&#32476;&#21040;&#22810;&#20040;&#31232;&#30095;&#65288;&#20960;&#20046;&#19981;&#24433;&#21709;&#24615;&#33021;&#65289;&#65311;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#37319;&#29992;&#20102;&#31532;&#19968;&#21407;&#29702;&#26041;&#27861;&#65292;&#20855;&#20307;&#22320;&#65292;&#21482;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25105;&#20204;&#33021;&#22815;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#25551;&#36848;&#21098;&#26525;&#27604;&#29575;&#30340;&#23574;&#38160;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#23545;&#24212;&#20110;&#21487;&#34892;&#21644;&#19981;&#21487;&#34892;&#20043;&#38388;&#30340;&#36793;&#30028;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#65292;&#36825;&#20123;&#20984;&#20307;&#26159;&#30001;$l_1$-&#35268;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#24471;&#20986;&#30340;&#65292;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21098;&#26525;&#36807;&#31243;&#20013;&#21442;&#25968;&#30340;&#20998;&#24067;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparameterization constitutes one of the most significant hallmarks of deep neural networks. Though it can offer the advantage of outstanding generalization performance, it meanwhile imposes substantial storage burden, thus necessitating the study of network pruning. A natural and fundamental question is: How sparse can we prune a deep network (with almost no hurt on the performance)? To address this problem, in this work we take a first principles approach, specifically, by merely enforcing the sparsity constraint on the original loss function, we're able to characterize the sharp phase transition point of pruning ratio, which corresponds to the boundary between the feasible and the infeasible, from the perspective of high-dimensional geometry. It turns out that the phase transition point of pruning ratio equals the squared Gaussian width of some convex body resulting from the $l_1$-regularized loss function, normalized by the original dimension of parameters. As a byproduct, we pr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#30001;&#20154;&#31867;&#26631;&#27880;&#30340;&#20114;&#34917;&#26631;&#31614;&#65292;&#21019;&#36896;&#20102;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;CLL&#25968;&#25454;&#38598;&#65292;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#29616;&#23454;&#34920;&#29616;&#19979;CLL&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#20026;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26356;&#23454;&#38469;&#30340;&#35780;&#20272;&#26631;&#20934;&#12290;</title><link>http://arxiv.org/abs/2305.08295</link><description>&lt;p&gt;
CLCIFAR&#65306;&#24102;&#20154;&#31867;&#26631;&#27880;&#20114;&#34917;&#26631;&#31614;&#30340;CIFAR&#27966;&#29983;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CLCIFAR: CIFAR-Derived Benchmark Datasets with Human Annotated Complementary Labels. (arXiv:2305.08295v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#30001;&#20154;&#31867;&#26631;&#27880;&#30340;&#20114;&#34917;&#26631;&#31614;&#65292;&#21019;&#36896;&#20102;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;CLL&#25968;&#25454;&#38598;&#65292;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#29616;&#23454;&#34920;&#29616;&#19979;CLL&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#20026;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26356;&#23454;&#38469;&#30340;&#35780;&#20272;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#34917;&#26631;&#31614;&#23398;&#20064;&#65288;CLL&#65289;&#26159;&#19968;&#31181;&#24369;&#30417;&#30563;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#20165;&#20351;&#29992;&#20114;&#34917;&#26631;&#31614;&#65288;&#26631;&#31034;&#23454;&#20363;&#19981;&#23646;&#20110;&#21738;&#20123;&#31867;&#21035;&#65289;&#26469;&#35757;&#32451;&#22810;&#31867;&#20998;&#31867;&#22120;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#22810;&#31181;CLL&#31639;&#27861;&#65292;&#20294;&#30001;&#20110;&#20004;&#20010;&#21407;&#22240;&#65292;&#23427;&#20204;&#30340;&#23454;&#38469;&#34920;&#29616;&#20173;&#19981;&#28165;&#26970;&#12290;&#39318;&#20808;&#65292;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#23545;&#20114;&#34917;&#26631;&#31614;&#29983;&#25104;&#30340;&#20551;&#35774;&#12290;&#20854;&#27425;&#65292;&#23427;&#20204;&#30340;&#35780;&#20272;&#20165;&#38480;&#20110;&#21512;&#25104;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#33719;&#21462;&#26377;&#20851;CLL&#31639;&#27861;&#30340;&#30495;&#23454;&#19990;&#30028;&#34920;&#29616;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21327;&#35758;&#26469;&#25910;&#38598;&#30001;&#20154;&#31867;&#27880;&#37322;&#32773;&#27880;&#37322;&#30340;&#20114;&#34917;&#26631;&#31614;&#12290;&#36825;&#19968;&#21162;&#21147;&#23548;&#33268;&#21019;&#24314;&#20102;&#20004;&#20010;&#25968;&#25454;&#38598;&#65292;CLCIFAR10&#21644;CLCIFAR20&#65292;&#20998;&#21035;&#30001;CIFAR10&#21644;CIFAR100&#27966;&#29983;&#32780;&#26469;&#12290;&#36825;&#20123;&#25968;&#25454;&#38598;&#22312;https://github.com/ntucllab/complementary_cifar&#19978;&#20844;&#24320;&#21457;&#24067;&#65292;&#20195;&#34920;&#20102;&#31532;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;CLL&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#22522;&#20934;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;&#30456;&#36739;&#20110;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#24403;&#20351;&#29992;&#20154;&#31867;&#27880;&#37322;&#30340;&#20114;&#34917;&#26631;&#31614;&#26102;&#65292;&#24615;&#33021;&#26377;&#26126;&#26174;&#19979;&#38477;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#20063;&#35266;&#23519;&#21040;&#65292;&#30495;&#23454;&#19990;&#30028;&#30340;CLL&#25968;&#25454;&#38598;&#20351;&#24471;&#22312;&#26356;&#25509;&#36817;&#23454;&#38469;&#24212;&#29992;&#26465;&#20214;&#19979;&#35780;&#20272;&#31639;&#27861;&#25104;&#20026;&#21487;&#33021;&#65292;&#20174;&#32780;&#26356;&#30495;&#23454;&#22320;&#35780;&#20272;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Complementary-label learning (CLL) is a weakly-supervised learning paradigm that aims to train a multi-class classifier using only complementary labels, which indicate classes to which an instance does not belong. Despite numerous algorithmic proposals for CLL, their practical performance remains unclear for two reasons. Firstly, these algorithms often rely on assumptions about the generation of complementary labels. Secondly, their evaluation has been limited to synthetic datasets. To gain insights into the real-world performance of CLL algorithms, we developed a protocol to collect complementary labels annotated by human annotators. This effort resulted in the creation of two datasets, CLCIFAR10 and CLCIFAR20, derived from CIFAR10 and CIFAR100, respectively. These datasets, publicly released at https://github.com/ntucllab/complementary_cifar, represent the very first real-world CLL datasets. Through extensive benchmark experiments, we discovered a notable decline in performance when 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20960;&#20309;&#24605;&#24819;&#30340;&#28508;&#22312;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#24314;&#27169;Barrett&#39135;&#31649;&#30142;&#30149;&#36827;&#31243;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#37325;&#24314;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2303.12711</link><description>&lt;p&gt;
&#22522;&#20110;&#20960;&#20309;&#24863;&#30693;&#30340;&#28508;&#22312;&#34920;&#31034;&#23398;&#20064;&#29992;&#20110;&#24314;&#27169;Barrett&#39135;&#31649;&#30142;&#30149;&#36827;&#31243;
&lt;/p&gt;
&lt;p&gt;
Geometry-Aware Latent Representation Learning for Modeling Disease Progression of Barrett's Esophagus. (arXiv:2303.12711v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20960;&#20309;&#24605;&#24819;&#30340;&#28508;&#22312;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#24314;&#27169;Barrett&#39135;&#31649;&#30142;&#30149;&#36827;&#31243;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#37325;&#24314;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Barrett&#39135;&#31649;&#26159;&#39135;&#31649;&#33146;&#30284;&#30340;&#21807;&#19968;&#20808;&#39537;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#35786;&#26029;&#26102;&#39044;&#21518;&#19981;&#33391;&#30340;&#39135;&#31649;&#30284;&#30151;&#12290;&#22240;&#27492;&#65292;&#35786;&#26029;Barrett&#39135;&#31649;&#23545;&#20110;&#39044;&#38450;&#21644;&#27835;&#30103;&#39135;&#31649;&#30284;&#33267;&#20851;&#37325;&#35201;&#12290;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#25903;&#25345;Barrett&#39135;&#31649;&#35786;&#26029;&#65292;&#20294;&#32452;&#32455;&#30149;&#29702;&#23398;&#35757;&#32451;&#25968;&#25454;&#30340;&#39640;&#35266;&#23519;&#32773;&#21464;&#24322;&#38480;&#21046;&#20102;&#36825;&#20123;&#26041;&#27861;&#12290;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;(VAEs)&#36827;&#34892;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#26174;&#31034;&#20986;&#28508;&#22312;&#20248;&#21183;&#65292;&#22240;&#20026;&#23427;&#20204;&#23558;&#36755;&#20837;&#25968;&#25454;&#26144;&#23556;&#21040;&#20855;&#26377;&#20165;&#26377;&#29992;&#29305;&#24449;&#30340;&#20302;&#32500;&#27969;&#24418;&#65292;&#20026;&#25913;&#36827;&#19979;&#28216;&#20219;&#21153;&#21644;&#35265;&#35299;&#23558;Barrett&#39135;&#31649;&#30149;&#31243;&#34920;&#24449;&#12290;&#28982;&#32780;&#65292;VAE&#30340;&#27431;&#20960;&#37324;&#24471;&#28508;&#22312;&#31354;&#38388;&#25197;&#26354;&#20102;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#30142;&#30149;&#36827;&#23637;&#24314;&#27169;&#12290;&#20960;&#20309;VAEs&#20026;&#28508;&#22312;&#31354;&#38388;&#25552;&#20379;&#38468;&#21152;&#20960;&#20309;&#32467;&#26500;&#65292;RHVAE&#20551;&#35774;&#20026;&#40654;&#26364;&#27969;&#24418;&#65292;$\mathcal{S}$-VAE&#20551;&#35774;&#20026;&#36229;&#29699;&#38754;&#27969;&#24418;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;$\mathcal{S}$-VAE&#20248;&#20110;&#24120;&#35268;VAE&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#37325;&#24314;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
Barrett's Esophagus (BE) is the only precursor known to Esophageal Adenocarcinoma (EAC), a type of esophageal cancer with poor prognosis upon diagnosis. Therefore, diagnosing BE is crucial in preventing and treating esophageal cancer. While supervised machine learning supports BE diagnosis, high interobserver variability in histopathological training data limits these methods. Unsupervised representation learning via Variational Autoencoders (VAEs) shows promise, as they map input data to a lower-dimensional manifold with only useful features, characterizing BE progression for improved downstream tasks and insights. However, the VAE's Euclidean latent space distorts point relationships, hindering disease progression modeling. Geometric VAEs provide additional geometric structure to the latent space, with RHVAE assuming a Riemannian manifold and $\mathcal{S}$-VAE a hyperspherical manifold. Our study shows that $\mathcal{S}$-VAE outperforms vanilla VAE with better reconstruction losses, 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19981;&#23436;&#20840;&#20449;&#24687;&#30340;&#24066;&#22330;&#20013;&#20351;&#29992;&#22312;&#32447;&#23398;&#20064;&#36827;&#34892;&#24179;&#34913;&#23450;&#20215;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#35299;&#20915;&#36873;&#25321;&#24615;&#35854;&#35328;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.11522</link><description>&lt;p&gt;
&#22312;&#19981;&#23436;&#20840;&#20449;&#24687;&#30340;&#24066;&#22330;&#20013;&#20351;&#29992;&#22312;&#32447;&#23398;&#20064;&#36827;&#34892;&#24179;&#34913;&#23450;&#20215;
&lt;/p&gt;
&lt;p&gt;
Online Learning for Equilibrium Pricing in Markets under Incomplete Information. (arXiv:2303.11522v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11522
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19981;&#23436;&#20840;&#20449;&#24687;&#30340;&#24066;&#22330;&#20013;&#20351;&#29992;&#22312;&#32447;&#23398;&#20064;&#36827;&#34892;&#24179;&#34913;&#23450;&#20215;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#35299;&#20915;&#36873;&#25321;&#24615;&#35854;&#35328;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24066;&#22330;&#24179;&#34913;&#30340;&#30740;&#31350;&#26159;&#32463;&#27982;&#29702;&#35770;&#30340;&#26680;&#24515;&#65292;&#29305;&#21035;&#26159;&#22312;&#26377;&#25928;&#37197;&#32622;&#31232;&#32570;&#36164;&#28304;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#23450;&#20215;&#22343;&#34913;&#30340;&#35745;&#31639;&#36890;&#24120;&#20381;&#36182;&#20110;&#23436;&#25972;&#30340;&#20010;&#20307;&#23646;&#24615;&#20449;&#24687;&#65292;&#22914;&#20379;&#24212;&#21830;&#30340;&#25104;&#26412;&#20989;&#25968;&#31561;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#24448;&#24448;&#19981;&#21487;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#19981;&#23436;&#20840;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#23450;&#20215;&#22343;&#34913;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24066;&#22330;&#32463;&#33829;&#32773;&#23547;&#27714;&#36890;&#36807;&#20174;&#25104;&#26412;&#20989;&#25968;&#26410;&#30693;&#30340;&#31454;&#20105;&#20379;&#24212;&#21830;&#36141;&#20080;&#25152;&#38656;&#25968;&#37327;&#26469;&#28385;&#36275;&#23458;&#25143;&#38656;&#27714;&#12290;&#22312;&#36825;&#31181;&#19981;&#23436;&#25972;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#21363;&#23398;&#20064;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#24179;&#34913;&#20215;&#26684;&#65292;&#21516;&#26102;&#32852;&#21512;&#20248;&#21270;&#19977;&#20010;&#24615;&#33021;&#25351;&#26631;&#8212;&#8212;&#26410;&#28385;&#36275;&#30340;&#38656;&#27714;&#12289;&#25104;&#26412;&#22833;&#35823;&#21644;&#20184;&#27454;&#22833;&#35823;&#8212;&#8212;&#36825;&#26159;&#22312;&#23450;&#20215;&#22343;&#34913;&#30340;&#24773;&#20917;&#19979;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The study of market equilibria is central to economic theory, particularly in efficiently allocating scarce resources. However, the computation of equilibrium prices at which the supply of goods matches their demand typically relies on having access to complete information on private attributes of agents, e.g., suppliers' cost functions, which are often unavailable in practice. Motivated by this practical consideration, we consider the problem of setting equilibrium prices in the incomplete information setting wherein a market operator seeks to satisfy the customer demand for a commodity by purchasing the required amount from competing suppliers with privately known cost functions unknown to the market operator. In this incomplete information setting, we consider the online learning problem of learning equilibrium prices over time while jointly optimizing three performance metrics -- unmet demand, cost regret, and payment regret -- pertinent in the context of equilibrium pricing over a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#22522;&#20110;Transformer&#30340;&#33258;&#30417;&#30563;&#27169;&#22411;&#36827;&#34892;&#21387;&#32553;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#26435;&#37325;&#20462;&#21098;&#12289;&#22836;&#37096;&#20462;&#21098;&#12289;&#20302;&#31209;&#36924;&#36817;&#21644;&#30693;&#35782;&#33976;&#39311;&#12290;&#32467;&#26524;&#21457;&#29616;&#65292;&#22522;&#26412;&#30340;&#21387;&#32553;&#25216;&#26415;&#26159;&#24378;&#22823;&#30340;&#22522;&#20934;&#65292;&#21487;&#20197;&#25913;&#21892;&#27169;&#22411;&#30340;&#21387;&#32553;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.09949</link><description>&lt;p&gt;
&#23545;&#22522;&#20110;Transformer&#30340;&#33258;&#30417;&#30563;&#27169;&#22411;&#22312;&#35821;&#38899;&#22788;&#29702;&#20013;&#36827;&#34892;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Compressing Transformer-based self-supervised models for speech processing. (arXiv:2211.09949v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#22522;&#20110;Transformer&#30340;&#33258;&#30417;&#30563;&#27169;&#22411;&#36827;&#34892;&#21387;&#32553;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#26435;&#37325;&#20462;&#21098;&#12289;&#22836;&#37096;&#20462;&#21098;&#12289;&#20302;&#31209;&#36924;&#36817;&#21644;&#30693;&#35782;&#33976;&#39311;&#12290;&#32467;&#26524;&#21457;&#29616;&#65292;&#22522;&#26412;&#30340;&#21387;&#32553;&#25216;&#26415;&#26159;&#24378;&#22823;&#30340;&#22522;&#20934;&#65292;&#21487;&#20197;&#25913;&#21892;&#27169;&#22411;&#30340;&#21387;&#32553;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;Transformer&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#24182;&#24212;&#29992;&#20110;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#20294;&#26159;&#35757;&#32451;&#21644;&#25512;&#26029;&#30340;&#35745;&#31639;&#25104;&#26412;&#20173;&#28982;&#26159;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#21508;&#31181;&#35774;&#22791;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;&#30446;&#21069;&#24050;&#26377;&#19968;&#20123;&#23396;&#31435;&#30340;&#23581;&#35797;&#26469;&#21387;&#32553;Transformer&#65292;&#20294;&#30740;&#31350;&#20013;&#30340;&#35774;&#32622;&#21644;&#25351;&#26631;&#21508;&#19981;&#30456;&#21516;&#12290;&#27492;&#21069;&#30340;&#24037;&#20316;&#24456;&#23569;&#28041;&#21450;&#19981;&#21516;&#21387;&#32553;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#36825;&#20351;&#24471;&#27604;&#36739;&#21387;&#32553;&#25216;&#26415;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20026;&#36825;&#20123;&#23396;&#31435;&#32467;&#26524;&#25552;&#20379;&#32972;&#26223;&#65292;&#30740;&#31350;&#20960;&#31181;&#24120;&#29992;&#30340;&#21387;&#32553;&#25216;&#26415;&#65292;&#21253;&#25324;&#26435;&#37325;&#20462;&#21098;&#12289;&#22836;&#37096;&#20462;&#21098;&#12289;&#20302;&#31209;&#36924;&#36817;&#21644;&#30693;&#35782;&#33976;&#39311;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#22312;&#19981;&#21516;&#21387;&#32553;&#29575;&#19979;&#30340;&#26435;&#34913;&#65292;&#21253;&#25324;&#22681;&#38047;&#26102;&#38388;&#12289;&#21442;&#25968;&#25968;&#37327;&#21644;&#20056;&#21152;&#25805;&#20316;&#25968;&#37327;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#26368;&#36817;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#22522;&#26412;&#30340;&#21387;&#32553;&#25216;&#26415;&#26159;&#24378;&#22823;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#20960;&#31181;&#21387;&#32553;&#26041;&#27861;&#26469;&#25913;&#36827;&#27169;&#22411;&#30340;&#21387;&#32553;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the success of Transformers in self- supervised learning with applications to various downstream tasks, the computational cost of training and inference remains a major challenge for applying these models to a wide spectrum of devices. Several isolated attempts have been made to compress Transformers, but the settings and metrics are different across studies. Trade-off at various compression rates are also largely missing in prior work, making it difficult to compare compression techniques. In this work, we aim to provide context for the isolated results, studying several commonly used compression techniques, including weight pruning, head pruning, low-rank approximation, and knowledge distillation. We report trade- off at various compression rate, including wall-clock time, the number of parameters, and the number of multiply-accumulate operations. Our results show that compared to recent approaches, basic compression techniques are strong baselines. We further present several
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#65292;&#31034;&#20363;&#35777;&#26126;&#20854;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20855;&#26377;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2208.02814</link><description>&lt;p&gt;
&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal Risk Control. (arXiv:2208.02814v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.02814
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#65292;&#31034;&#20363;&#35777;&#26126;&#20854;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20855;&#26377;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#25512;&#24191;&#33267;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;&#35813;&#31639;&#27861;&#23558;&#20998;&#35010;&#31526;&#21512;&#24615;&#39044;&#27979;&#21450;&#20854;&#35206;&#30422;&#20445;&#35777;&#36827;&#34892;&#20102;&#27867;&#21270;&#12290;&#31867;&#20284;&#20110;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#22312;$\mathcal{O}(1/n)$&#22240;&#23376;&#20869;&#20445;&#25345;&#32039;&#23494;&#24615;&#12290;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#31034;&#20363;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#22312;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\mathcal{O}(1/n)$ factor. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.
&lt;/p&gt;</description></item></channel></rss>