<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23618;&#32423;&#26550;&#26500;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;&#20132;&#20114;&#39044;&#27979;&#21644;&#31934;&#31616;&#30340;MPC&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#65292;&#22312;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#20132;&#36890;&#22330;&#26223;&#20013;&#23637;&#31034;&#20102;12&#20493;&#30340;&#36895;&#24230;&#25552;&#21319;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01116</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#22810;&#27169;&#22411;MPC&#30340;&#22522;&#20110;&#23545;&#20598;&#20132;&#20114;&#39044;&#27979;&#30340;&#23618;&#32423;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Scalable Multi-modal Model Predictive Control via Duality-based Interaction Predictions
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01116
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23618;&#32423;&#26550;&#26500;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;&#20132;&#20114;&#39044;&#27979;&#21644;&#31934;&#31616;&#30340;MPC&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#65292;&#22312;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#20132;&#36890;&#22330;&#26223;&#20013;&#23637;&#31034;&#20102;12&#20493;&#30340;&#36895;&#24230;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23618;&#32423;&#26550;&#26500;&#65292;&#29992;&#20110;&#22312;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#20132;&#36890;&#22330;&#26223;&#20013;&#23454;&#29616;&#21487;&#25193;&#23637;&#30340;&#23454;&#26102;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;(MPC)&#12290;&#35813;&#26550;&#26500;&#30001;&#20004;&#20010;&#20851;&#38190;&#32452;&#20214;&#32452;&#25104;&#65306;1) RAID-Net&#65292;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26032;&#39062;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65292;&#20351;&#29992;&#25289;&#26684;&#26391;&#26085;&#23545;&#20598;&#24615;&#39044;&#27979;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#19982;&#21608;&#22260;&#36710;&#36742;&#20043;&#38388;&#22312;MPC&#39044;&#27979;&#33539;&#22260;&#20869;&#30340;&#30456;&#20851;&#20132;&#20114;&#65307;2) &#19968;&#20010;&#31616;&#21270;&#30340;&#38543;&#26426;MPC&#38382;&#39064;&#65292;&#28040;&#38500;&#19981;&#30456;&#20851;&#30340;&#36991;&#30896;&#32422;&#26463;&#65292;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#20010;&#27169;&#25311;&#20132;&#36890;&#36335;&#21475;&#20013;&#28436;&#31034;&#65292;&#23637;&#31034;&#20102;&#35299;&#20915;&#36816;&#21160;&#35268;&#21010;&#38382;&#39064;&#30340;12&#20493;&#36895;&#25552;&#21319;&#12290;&#24744;&#21487;&#20197;&#22312;&#36825;&#37324;&#25214;&#21040;&#23637;&#31034;&#35813;&#26550;&#26500;&#22312;&#22810;&#20010;&#22797;&#26434;&#20132;&#36890;&#22330;&#26223;&#20013;&#30340;&#35270;&#39057;&#65306;https://youtu.be/-TcMeolCLWc
&lt;/p&gt;
&lt;p&gt;
We propose a hierarchical architecture designed for scalable real-time Model Predictive Control (MPC) in complex, multi-modal traffic scenarios. This architecture comprises two key components: 1) RAID-Net, a novel attention-based Recurrent Neural Network that predicts relevant interactions along the MPC prediction horizon between the autonomous vehicle and the surrounding vehicles using Lagrangian duality, and 2) a reduced Stochastic MPC problem that eliminates irrelevant collision avoidance constraints, enhancing computational efficiency. Our approach is demonstrated in a simulated traffic intersection with interactive surrounding vehicles, showcasing a 12x speed-up in solving the motion planning problem. A video demonstrating the proposed architecture in multiple complex traffic scenarios can be found here: https://youtu.be/-TcMeolCLWc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#26367;&#20195;&#20102;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#23637;&#31034;&#20102;&#20854;&#22312;&#36817;&#20284;&#24179;&#28369;&#20998;&#31867;&#22120;&#26041;&#38754;&#30340;&#31934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07498</link><description>&lt;p&gt;
&#21152;&#36895;&#24179;&#28369;&#65306;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Accelerated Smoothing: A Scalable Approach to Randomized Smoothing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#26367;&#20195;&#20102;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#23637;&#31034;&#20102;&#20854;&#22312;&#36817;&#20284;&#24179;&#28369;&#20998;&#31867;&#22120;&#26041;&#38754;&#30340;&#31934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#24179;&#28369;&#20197;&#20854;&#20351;&#29992;&#29305;&#23450;&#20998;&#24067;&#30340;&#24179;&#28369;&#22122;&#22768;&#30830;&#20445;&#24179;&#28369;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#32780;&#25104;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#21487;&#35777;&#26126;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#38450;&#24481;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#36807;&#31243;&#20013;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#30340;&#20351;&#29992;&#24341;&#20837;&#20102;&#19968;&#20010;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#22240;&#32032;&#65292;&#38480;&#21046;&#20102;&#22312;&#36739;&#22823;&#35268;&#27169;&#19978;&#23454;&#36341;&#38543;&#26426;&#24179;&#28369;&#30340;&#21487;&#34892;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#23616;&#38480;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#35757;&#32451;&#26367;&#20195;&#20102;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#12290;&#36890;&#36807;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#36817;&#20284;&#24179;&#28369;&#20998;&#31867;&#22120;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#30340;&#31934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#21152;&#36895;&#20102;&#40065;&#26834;&#21322;&#24452;&#35748;&#35777;&#36807;&#31243;&#65292;&#22312;&#35745;&#31639;&#26102;&#38388;&#19978;&#25552;&#20379;&#20102;&#36817;600&#20493;&#30340;&#25913;&#36827;&#65292;&#20811;&#26381;&#20102;&#20256;&#32479;&#38543;&#26426;&#24179;&#28369;&#20013;&#30340;&#35745;&#31639;&#29942;&#39048;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized smoothing has emerged as a potent certifiable defense against adversarial attacks by employing smoothing noises from specific distributions to ensure the robustness of a smoothed classifier. However, the utilization of Monte Carlo sampling in this process introduces a compute-intensive element, which constrains the practicality of randomized smoothing on a larger scale. To address this limitation, we propose a novel approach that replaces Monte Carlo sampling with the training of a surrogate neural network. Through extensive experimentation in various settings, we demonstrate the efficacy of our approach in approximating the smoothed classifier with remarkable precision. Furthermore, we demonstrate that our approach significantly accelerates the robust radius certification process, providing nearly $600$X improvement in computation time, overcoming the computational bottlenecks associated with traditional randomized smoothing.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;LoGoNet&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#37319;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#24212;&#23545;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#20013;&#30340;&#25361;&#25112;&#12290;LoGoNet&#36890;&#36807;&#37319;&#29992;&#22823;&#20869;&#26680;&#27880;&#24847;&#21147;&#21644;&#21452;&#37325;&#32534;&#30721;&#31574;&#30053;&#65292;&#28789;&#27963;&#25429;&#25417;&#38271;&#12289;&#30701;&#36317;&#31163;&#29305;&#24449;&#30456;&#20851;&#24615;&#12290;&#36825;&#31181;&#21019;&#26032;&#30340;&#32452;&#21512;&#25216;&#26415;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#21106;&#20013;&#29305;&#21035;&#26377;&#30410;&#12290;</title><link>https://arxiv.org/abs/2402.06190</link><description>&lt;p&gt;
Masked LoGoNet&#65306;&#29992;&#20110;&#21307;&#23398;&#39046;&#22495;&#30340;&#24555;&#36895;&#20934;&#30830;3D&#22270;&#20687;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06190
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;LoGoNet&#30340;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#37319;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#24212;&#23545;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#20013;&#30340;&#25361;&#25112;&#12290;LoGoNet&#36890;&#36807;&#37319;&#29992;&#22823;&#20869;&#26680;&#27880;&#24847;&#21147;&#21644;&#21452;&#37325;&#32534;&#30721;&#31574;&#30053;&#65292;&#28789;&#27963;&#25429;&#25417;&#38271;&#12289;&#30701;&#36317;&#31163;&#29305;&#24449;&#30456;&#20851;&#24615;&#12290;&#36825;&#31181;&#21019;&#26032;&#30340;&#32452;&#21512;&#25216;&#26415;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#21106;&#20013;&#29305;&#21035;&#26377;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#22270;&#20687;&#26041;&#27861;&#22312;&#21307;&#23398;&#24212;&#29992;&#20013;&#38754;&#20020;&#25361;&#25112;&#65292;&#22240;&#20026;&#25968;&#25454;&#38598;&#26500;&#24314;&#30340;&#39640;&#25104;&#26412;&#21644;&#26377;&#38480;&#30340;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#37096;&#32626;&#26102;&#36890;&#24120;&#29992;&#20110;&#27599;&#22825;&#22788;&#29702;&#22823;&#37327;&#25968;&#25454;&#65292;&#32473;&#21307;&#30103;&#35774;&#26045;&#24102;&#26469;&#39640;&#32500;&#25252;&#25104;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;LoGoNet&#65292;&#37319;&#29992;&#23450;&#21046;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#26041;&#27861;&#26469;&#32531;&#35299;&#36825;&#20123;&#25361;&#25112;&#12290;LoGoNet&#22312;U&#24418;&#26550;&#26500;&#20869;&#25972;&#21512;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#21033;&#29992;&#22823;&#20869;&#26680;&#27880;&#24847;&#21147;&#65288;LKA&#65289;&#21644;&#21452;&#37325;&#32534;&#30721;&#31574;&#30053;&#65292;&#28789;&#27963;&#22320;&#25429;&#25417;&#38271;&#12289;&#30701;&#36317;&#31163;&#29305;&#24449;&#30456;&#20851;&#24615;&#12290;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#22686;&#21152;&#32593;&#32476;&#23481;&#37327;&#20197;&#22686;&#24378;&#29305;&#24449;&#25552;&#21462;&#30340;&#26041;&#24335;&#24418;&#25104;&#23545;&#27604;&#12290;&#25105;&#20204;&#27169;&#22411;&#20013;&#36825;&#20123;&#26032;&#25216;&#26415;&#30340;&#32452;&#21512;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#21106;&#20013;&#29305;&#21035;&#26377;&#30410;&#65292;&#32771;&#34385;&#21040;&#20854;&#22256;&#38590;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard modern machine-learning-based imaging methods have faced challenges in medical applications due to the high cost of dataset construction and, thereby, the limited labeled training data available. Additionally, upon deployment, these methods are usually used to process a large volume of data on a daily basis, imposing a high maintenance cost on medical facilities. In this paper, we introduce a new neural network architecture, termed LoGoNet, with a tailored self-supervised learning (SSL) method to mitigate such challenges. LoGoNet integrates a novel feature extractor within a U-shaped architecture, leveraging Large Kernel Attention (LKA) and a dual encoding strategy to capture both long-range and short-range feature dependencies adeptly. This is in contrast to existing methods that rely on increasing network capacity to enhance feature extraction. This combination of novel techniques in our model is especially beneficial in medical image segmentation, given the difficulty of le
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#20013;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38544;&#24615;&#20559;&#24046;&#20197;&#21450;&#20854;&#25910;&#25947;&#36895;&#29575;&#65292;&#36890;&#36807;&#35777;&#26126;&#22312;&#29305;&#23450;&#25968;&#25454;&#35774;&#32622;&#19979;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.05738</link><description>&lt;p&gt;
&#38544;&#24615;&#20559;&#24046;&#19982;&#33258;&#27880;&#24847;&#21147;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias and Fast Convergence Rates for Self-attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05738
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#20013;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38544;&#24615;&#20559;&#24046;&#20197;&#21450;&#20854;&#25910;&#25947;&#36895;&#29575;&#65292;&#36890;&#36807;&#35777;&#26126;&#22312;&#29305;&#23450;&#25968;&#25454;&#35774;&#32622;&#19979;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#26159;transformer&#30340;&#26680;&#24515;&#26426;&#21046;&#65292;&#23427;&#20351;&#20854;&#19982;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#26377;&#25152;&#21306;&#21035;&#65292;&#24182;&#39537;&#21160;&#20854;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#24320;&#21457;&#33258;&#27880;&#24847;&#21147;&#30340;&#22522;&#26412;&#20248;&#21270;&#21407;&#21017;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#35757;&#32451;&#20855;&#26377;&#22266;&#23450;&#32447;&#24615;&#35299;&#30721;&#22120;&#30340;&#33258;&#27880;&#24847;&#21147;&#23618;&#22312;&#20108;&#20803;&#20998;&#31867;&#20013;&#30340;&#38544;&#24615;&#20559;&#24046;&#12290;&#21463;&#21040;&#22312;&#21487;&#20998;&#31163;&#25968;&#25454;&#19978;&#32447;&#24615;&#36923;&#36753;&#22238;&#24402;&#20013;GD&#30340;&#30740;&#31350;&#21551;&#21457;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#38543;&#30528;&#36845;&#20195;&#27425;&#25968;t&#26080;&#38480;&#25509;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38190;-&#26597;&#35810;&#30697;&#38453;W_t&#22312;&#23616;&#37096;&#19978;&#65288;&#30456;&#23545;&#20110;&#21021;&#22987;&#21270;&#26041;&#21521;&#65289;&#25910;&#25947;&#21040;&#19968;&#20010;&#30828;&#36793;&#30028;&#25903;&#25345;&#21521;&#37327;&#26426;&#35299;W_mm&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#22235;&#20010;&#26041;&#38754;&#22686;&#24378;&#20102;&#36825;&#20010;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#38750;&#24179;&#20961;&#30340;&#25968;&#25454;&#35774;&#32622;&#65292;&#23545;&#20110;&#36825;&#20123;&#35774;&#32622;&#65292;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25581;&#31034;&#20102;&#20248;&#21270;&#31354;&#38388;&#30340;&#29305;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#65292;&#24182;&#37327;&#21270;&#20102;&#31232;&#30095;&#21270;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-attention, the core mechanism of transformers, distinguishes them from traditional neural networks and drives their outstanding performance. Towards developing the fundamental optimization principles of self-attention, we investigate the implicit bias of gradient descent (GD) in training a self-attention layer with fixed linear decoder in binary classification. Drawing inspiration from the study of GD in linear logistic regression over separable data, recent work demonstrates that as the number of iterations $t$ approaches infinity, the key-query matrix $W_t$ converges locally (with respect to the initialization direction) to a hard-margin SVM solution $W_{mm}$. Our work enhances this result in four aspects. Firstly, we identify non-trivial data settings for which convergence is provably global, thus shedding light on the optimization landscape. Secondly, we provide the first finite-time convergence rate for $W_t$ to $W_{mm}$, along with quantifying the rate of sparsification in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;&#31639;&#27861;&#65288;D-SOBA&#65289;&#65292;&#39318;&#27425;&#38416;&#26126;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#22312;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2402.03167</link><description>&lt;p&gt;
&#22270;&#19978;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;: &#26080;&#29615;&#31639;&#27861;&#26356;&#26032;&#21644;&#30636;&#24577;&#36845;&#20195;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Decentralized Bilevel Optimization over Graphs: Loopless Algorithmic Update and Transient Iteration Complexity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03167
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;&#31639;&#27861;&#65288;D-SOBA&#65289;&#65292;&#39318;&#27425;&#38416;&#26126;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#22312;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21452;&#32423;&#20248;&#21270;&#65288;SBO&#65289;&#22312;&#22788;&#29702;&#23884;&#22871;&#32467;&#26500;&#26041;&#38754;&#30340;&#22810;&#26679;&#24615;&#20351;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#22823;&#35268;&#27169;SBO&#65292;&#21435;&#20013;&#24515;&#21270;&#26041;&#27861;&#20316;&#20026;&#26377;&#25928;&#30340;&#33539;&#20363;&#20986;&#29616;&#65292;&#20854;&#20013;&#33410;&#28857;&#19982;&#30452;&#25509;&#30456;&#37051;&#33410;&#28857;&#36827;&#34892;&#36890;&#20449;&#65292;&#26080;&#38656;&#20013;&#22830;&#26381;&#21153;&#22120;&#65292;&#20174;&#32780;&#25552;&#39640;&#36890;&#20449;&#25928;&#29575;&#21644;&#22686;&#24378;&#31639;&#27861;&#30340;&#31283;&#20581;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#21435;&#20013;&#24515;&#21270;SBO&#31639;&#27861;&#38754;&#20020;&#25361;&#25112;&#65292;&#21253;&#25324;&#26114;&#36149;&#30340;&#20869;&#37096;&#24490;&#29615;&#26356;&#26032;&#21644;&#23545;&#32593;&#32476;&#25299;&#25169;&#12289;&#25968;&#25454;&#24322;&#26500;&#24615;&#21644;&#23884;&#22871;&#21452;&#32423;&#31639;&#27861;&#32467;&#26500;&#30340;&#24433;&#21709;&#19981;&#26126;&#30830;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;SBO&#65288;D-SOBA&#65289;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#20854;&#30636;&#24577;&#36845;&#20195;&#22797;&#26434;&#24615;&#65292;&#39318;&#27425;&#28548;&#28165;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic bilevel optimization (SBO) is becoming increasingly essential in machine learning due to its versatility in handling nested structures. To address large-scale SBO, decentralized approaches have emerged as effective paradigms in which nodes communicate with immediate neighbors without a central server, thereby improving communication efficiency and enhancing algorithmic robustness. However, current decentralized SBO algorithms face challenges, including expensive inner-loop updates and unclear understanding of the influence of network topology, data heterogeneity, and the nested bilevel algorithmic structures. In this paper, we introduce a single-loop decentralized SBO (D-SOBA) algorithm and establish its transient iteration complexity, which, for the first time, clarifies the joint influence of network topology and data heterogeneity on decentralized bilevel algorithms. D-SOBA achieves the state-of-the-art asymptotic rate, asymptotic gradient/Hessian complexity, and transien
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37325;&#26032;&#24605;&#32771;&#20102;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#21644;&#26550;&#26500;&#65292;&#36890;&#36807;&#32463;&#39564;&#30740;&#31350;&#21457;&#29616;&#20102;&#22312;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#29305;&#21035;&#26377;&#25928;&#30340;&#35774;&#35745;&#20844;&#24335;&#65292;&#24182;&#22312;&#22810;&#35821;&#31181;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#39640;&#24615;&#33021;&#30340;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.02791</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#21644;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Rethinking Optimization and Architecture for Tiny Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#26032;&#24605;&#32771;&#20102;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#21644;&#26550;&#26500;&#65292;&#36890;&#36807;&#32463;&#39564;&#30740;&#31350;&#21457;&#29616;&#20102;&#22312;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#29305;&#21035;&#26377;&#25928;&#30340;&#35774;&#35745;&#20844;&#24335;&#65292;&#24182;&#22312;&#22810;&#35821;&#31181;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#39640;&#24615;&#33021;&#30340;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23041;&#21147;&#36890;&#36807;&#22823;&#37327;&#30340;&#25968;&#25454;&#21644;&#35745;&#31639;&#36164;&#28304;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#28982;&#32780;&#65292;&#22312;&#31227;&#21160;&#35774;&#22791;&#19978;&#24212;&#29992;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30528;&#35745;&#31639;&#21644;&#20869;&#23384;&#25104;&#26412;&#30340;&#24040;&#22823;&#25361;&#25112;&#65292;&#36843;&#20999;&#38656;&#35201;&#39640;&#24615;&#33021;&#30340;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#21463;&#22797;&#26434;&#35757;&#32451;&#36807;&#31243;&#30340;&#38480;&#21046;&#65292;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#35768;&#22810;&#32454;&#33410;&#24456;&#23569;&#24471;&#21040;&#20180;&#32454;&#30740;&#31350;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#22522;&#20110;&#19968;&#20010;&#20855;&#26377;10&#20159;&#21442;&#25968;&#30340;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#20180;&#32454;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#32463;&#39564;&#30740;&#31350;&#26469;&#20998;&#26512;&#27599;&#20010;&#32452;&#20214;&#30340;&#24433;&#21709;&#12290;&#20027;&#35201;&#35752;&#35770;&#20102;&#19977;&#20010;&#26041;&#38754;&#65292;&#21363;&#31070;&#32463;&#26550;&#26500;&#12289;&#21442;&#25968;&#21021;&#22987;&#21270;&#21644;&#20248;&#21270;&#31574;&#30053;&#12290;&#22810;&#20010;&#35774;&#35745;&#20844;&#24335;&#22312;&#24494;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32463;&#39564;&#24615;&#22320;&#34987;&#35777;&#26126;&#29305;&#21035;&#26377;&#25928;&#65292;&#21253;&#25324;&#20998;&#35789;&#22120;&#21387;&#32553;&#12289;&#26550;&#26500;&#35843;&#25972;&#12289;&#21442;&#25968;&#32487;&#25215;&#21644;&#22810;&#36718;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;1.6T&#22810;&#35821;&#31181;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;PanGu-$\pi$-1B Pro&#21644;PanGu-$\pi$-1.5B Pro&#12290;
&lt;/p&gt;
&lt;p&gt;
The power of large language models (LLMs) has been demonstrated through numerous data and computing resources. However, the application of language models on mobile devices is facing huge challenge on the computation and memory costs, that is, tiny language models with high performance are urgently required. Limited by the highly complex training process, there are many details for optimizing language models that are seldom studied carefully. In this study, based on a tiny language model with 1B parameters, we carefully design a series of empirical study to analyze the effect of each component. Three perspectives are mainly discussed, i.e., neural architecture, parameter initialization, and optimization strategy. Several design formulas are empirically proved especially effective for tiny language models, including tokenizer compression, architecture tweaking, parameter inheritance and multiple-round training. Then we train PanGu-$\pi$-1B Pro and PanGu-$\pi$-1.5B Pro on 1.6T multilingu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22240;&#26524;&#21457;&#29616;&#26694;&#26550;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#39044;&#35757;&#32451;&#19982;&#32463;&#20856;&#21457;&#29616;&#31639;&#27861;&#30340;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#12289;&#20934;&#30830;&#22320;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#26356;&#22909;&#30340;&#34920;&#29616;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.01929</link><description>&lt;p&gt;
&#26679;&#26412;&#12289;&#20272;&#35745;&#12289;&#32858;&#21512;&#65306;&#22240;&#26524;&#21457;&#29616;&#22522;&#30784;&#27169;&#22411;&#30340;&#19968;&#31181;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample, estimate, aggregate: A recipe for causal discovery foundation models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22240;&#26524;&#21457;&#29616;&#26694;&#26550;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#39044;&#35757;&#32451;&#19982;&#32463;&#20856;&#21457;&#29616;&#31639;&#27861;&#30340;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#12289;&#20934;&#30830;&#22320;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#26356;&#22909;&#30340;&#34920;&#29616;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#26159;&#20174;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#30340;&#20219;&#21153;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;&#31185;&#23398;&#30740;&#31350;&#12289;&#25351;&#23548;&#20915;&#31574;&#31561;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#30340;&#27599;&#20010;&#25968;&#25454;&#38598;&#30340;&#29305;&#24615;&#20351;&#23427;&#20204;&#21464;&#24471;&#32531;&#24930;&#12289;&#38656;&#35201;&#22823;&#37327;&#25968;&#25454;&#24182;&#19988;&#33030;&#24369;&#12290;&#21463;&#22522;&#30784;&#27169;&#22411;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21457;&#29616;&#26694;&#26550;&#65292;&#20854;&#20013;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#39044;&#35757;&#32451;&#29992;&#20110;&#22788;&#29702;&#22312;&#36739;&#23567;&#30340;&#21464;&#37327;&#23376;&#38598;&#19978;&#36816;&#34892;&#30340;&#32463;&#20856;&#21457;&#29616;&#31639;&#27861;&#30340;&#39044;&#27979;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#21033;&#29992;&#20197;&#19979;&#35266;&#23519;&#32467;&#26524;&#65306;&#32463;&#20856;&#31639;&#27861;&#30340;&#36755;&#20986;&#22312;&#23567;&#38382;&#39064;&#19978;&#35745;&#31639;&#36895;&#24230;&#24555;&#65292;&#23545;&#65288;&#36793;&#38469;&#65289;&#25968;&#25454;&#32467;&#26500;&#20855;&#26377;&#20449;&#24687;&#37327;&#65292;&#19988;&#23427;&#20204;&#30340;&#36755;&#20986;&#32467;&#26500;&#20316;&#20026;&#23545;&#35937;&#22312;&#25968;&#25454;&#38598;&#20043;&#38388;&#21487;&#20197;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21487;&#20197;&#25512;&#24191;&#21040;&#35757;&#32451;&#26399;&#38388;&#26410;&#35265;&#36807;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#65292;&#24182;&#19988;&#25552;&#20379;&#27604;&#29616;&#26377;&#27169;&#22411;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#25512;&#29702;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery, the task of inferring causal structure from data, promises to accelerate scientific research, inform policy making, and more. However, the per-dataset nature of existing causal discovery algorithms renders them slow, data hungry, and brittle. Inspired by foundation models, we propose a causal discovery framework where a deep learning model is pretrained to resolve predictions from classical discovery algorithms run over smaller subsets of variables. This method is enabled by the observations that the outputs from classical algorithms are fast to compute for small problems, informative of (marginal) data structure, and their structure outputs as objects remain comparable across datasets. Our method achieves state-of-the-art performance on synthetic and realistic datasets, generalizes to data generating mechanisms not seen during training, and offers inference speeds that are orders of magnitude faster than existing models.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LCPO&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20248;&#21270;&#24403;&#21069;&#32463;&#39564;&#22238;&#25253;&#30340;&#21516;&#26102;&#23558;&#31574;&#30053;&#23545;&#26087;&#32463;&#39564;&#36827;&#34892;&#38170;&#23450;&#26469;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2302.02182</link><description>&lt;p&gt;
&#22312;&#38750;&#38745;&#24577;&#19978;&#19979;&#25991;&#39537;&#21160;&#29615;&#22659;&#20013;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Reinforcement Learning in Non-Stationary Context-Driven Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.02182
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LCPO&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20248;&#21270;&#24403;&#21069;&#32463;&#39564;&#22238;&#25253;&#30340;&#21516;&#26102;&#23558;&#31574;&#30053;&#23545;&#26087;&#32463;&#39564;&#36827;&#34892;&#38170;&#23450;&#26469;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#20013;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#20854;&#20013;&#19968;&#20010;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#22806;&#29983;&#19978;&#19979;&#25991;&#36807;&#31243;&#24433;&#21709;&#30528;&#29615;&#22659;&#21160;&#24577;&#12290;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#22312;&#36825;&#26679;&#30340;&#29615;&#22659;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#23384;&#22312;&#8220;&#28798;&#38590;&#24615;&#36951;&#24536;&#8221;&#29616;&#35937;&#12290;&#38543;&#30528;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#26032;&#32463;&#39564;&#22686;&#21152;&#65292;&#20195;&#29702; tend to forget &#20808;&#21069;&#30340;&#30693;&#35782;&#12290;&#20197;&#24448;&#30340;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#20219;&#21153;&#26631;&#31614;&#65288;&#36825;&#22312;&#23454;&#36341;&#20013;&#24448;&#24448;&#26159;&#19981;&#23384;&#22312;&#30340;&#65289;&#25110;&#32773;&#20351;&#29992;&#33073;&#26426;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#23384;&#22312;&#19981;&#31283;&#23450;&#24615;&#21644;&#24615;&#33021;&#24046;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; Locally Constrained Policy Optimization (LCPO) &#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20248;&#21270;&#24403;&#21069;&#32463;&#39564;&#22238;&#25253;&#30340;&#21516;&#26102;&#23558;&#31574;&#30053;&#23545;&#26087;&#30340;&#32463;&#39564;&#36827;&#34892;&#38170;&#23450;&#26469;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#38382;&#39064;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#31181;&#38170;&#23450;&#65292;LCPO&#20351;&#29992;&#26469;&#33258;&#24403;&#21069;&#19978;&#19979;&#25991;&#20998;&#24067;&#20043;&#22806;&#30340;&#32463;&#39564;&#26679;&#26412;&#26469;&#23616;&#37096;&#32422;&#26463;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#22312;Mujoco&#12289;&#32463;&#20856;&#25511;&#21046;&#21644;&#35745;&#31639;&#26426;&#31995;&#32479;&#29615;&#22659;&#20013;&#20351;&#29992;&#22810;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19978;&#19979;&#25991;&#36319;&#36394;&#65292;&#35780;&#20272;&#20102;LCPO&#30340;&#24615;&#33021;&#65292;&#24182;&#21457;&#29616;&#23427;&#33021;&#22815;&#21462;&#24471;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study online reinforcement learning (RL) in non-stationary environments, where a time-varying exogenous context process affects the environment dynamics. Online RL is challenging in such environments due to "catastrophic forgetting" (CF). The agent tends to forget prior knowledge as it trains on new experiences. Prior approaches to mitigate this issue assume task labels (which are often not available in practice) or use off-policy methods that suffer from instability and poor performance.   We present Locally Constrained Policy Optimization (LCPO), an online RL approach that combats CF by anchoring policy outputs on old experiences while optimizing the return on current experiences. To perform this anchoring, LCPO locally constrains policy optimization using samples from experiences that lie outside of the current context distribution. We evaluate LCPO in Mujoco, classic control and computer systems environments with a variety of synthetic and real context traces, and find that it o
&lt;/p&gt;</description></item><item><title>&#36825;&#20221;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#19979;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;&#20197;&#21450;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65292;&#24182;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#21644;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#26469;&#31163;&#25955;&#21270;&#31215;&#20998;&#36816;&#31639;&#31526;&#12290;</title><link>http://arxiv.org/abs/2401.06740</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#26399;&#26435;&#23450;&#20215;&#30340;&#28145;&#24230;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models. (arXiv:2401.06740v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06740
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#19979;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;&#20197;&#21450;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65292;&#24182;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#21644;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#26469;&#31163;&#25955;&#21270;&#31215;&#20998;&#36816;&#31639;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#21160;&#24577;&#19979;&#30340;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#12290;&#23558;&#26399;&#26435;&#23450;&#20215;&#38382;&#39064;&#34920;&#36848;&#20026;&#19968;&#20010;&#20559;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26102;&#38388;&#27493;&#27861;&#36827;&#34892;&#36817;&#20284;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#28145;&#24230;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#36880;&#27493;&#36924;&#36817;&#12290;&#31215;&#20998;&#36816;&#31639;&#31526;&#36890;&#36807;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#31163;&#25955;&#21270;&#65306;a&#65289;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#65292;&#37319;&#29992;&#22855;&#24322;&#20540;&#20998;&#35299;&#20135;&#29983;&#30340;&#23616;&#37096;&#22352;&#26631;&#36724;&#65292;&#24182;&#19988;b&#65289;&#36890;&#36807;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#12290;&#20851;&#38190;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;ANN&#30340;&#26500;&#36896;&#30830;&#20445;&#20102;&#35299;&#20915;&#26041;&#26696;&#22312;&#26631;&#30340;&#36164;&#20135;&#36739;&#22823;&#20540;&#26102;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#19988;&#19982;&#35299;&#20915;&#26041;&#26696;&#20808;&#39564;&#24050;&#30693;&#30340;&#23450;&#24615;&#29305;&#24615;&#30456;&#19968;&#33268;&#36755;&#20986;&#12290;&#23545;&#26041;&#27861;&#32500;&#24230;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assesse
&lt;/p&gt;</description></item><item><title>MoTCoder&#26159;&#19968;&#20010;&#20351;&#29992;&#24605;&#32500;&#27169;&#22359;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25361;&#25112;&#24615;&#32534;&#31243;&#20219;&#21153;&#20013;&#33021;&#21147;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21019;&#26032;&#30340;&#25351;&#20196;&#35843;&#25972;&#20419;&#36827;&#20219;&#21153;&#30340;&#20998;&#35299;&#21644;&#27169;&#22359;&#21270;&#65292;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#30340;&#20934;&#30830;&#24615;&#21644;&#27169;&#22359;&#21270;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2312.15960</link><description>&lt;p&gt;
MoTCoder: &#20351;&#29992;&#24605;&#32500;&#27169;&#22359;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#32534;&#31243;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
MoTCoder: Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks. (arXiv:2312.15960v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15960
&lt;/p&gt;
&lt;p&gt;
MoTCoder&#26159;&#19968;&#20010;&#20351;&#29992;&#24605;&#32500;&#27169;&#22359;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25361;&#25112;&#24615;&#32534;&#31243;&#20219;&#21153;&#20013;&#33021;&#21147;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21019;&#26032;&#30340;&#25351;&#20196;&#35843;&#25972;&#20419;&#36827;&#20219;&#21153;&#30340;&#20998;&#35299;&#21644;&#27169;&#22359;&#21270;&#65292;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#30340;&#20934;&#30830;&#24615;&#21644;&#27169;&#22359;&#21270;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22788;&#29702;&#31616;&#21333;&#30340;&#32534;&#31243;&#20219;&#21153;&#26041;&#38754;&#23637;&#31034;&#20986;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#32534;&#31243;&#38382;&#39064;&#26102;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#24448;&#24448;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#20256;&#32479;&#27169;&#22411;&#24448;&#24448;&#29983;&#25104;&#20316;&#20026;&#21333;&#19968;&#20195;&#30721;&#22359;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#35299;&#20915;&#22797;&#26434;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Modular-of-Thought Coder (MoTCoder)&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;MoT&#25351;&#20196;&#35843;&#25972;&#26694;&#26550;&#65292;&#26088;&#22312;&#20419;&#36827;&#23558;&#20219;&#21153;&#20998;&#35299;&#20026;&#36923;&#36753;&#23376;&#20219;&#21153;&#21644;&#23376;&#27169;&#22359;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#22521;&#20859;&#21644;&#21033;&#29992;&#23376;&#27169;&#22359;&#65292;MoTCoder&#26174;&#33879;&#25552;&#39640;&#20102;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#30340;&#27169;&#22359;&#21270;&#21644;&#27491;&#30830;&#24615;&#65292;&#23548;&#33268;&#22312;APPS&#19978;&#30456;&#23545;pass@1&#25913;&#36827;&#20102;12.9%&#65292;&#22312;CodeContests&#19978;&#30456;&#23545;pass@1&#25913;&#36827;&#20102;9.43%&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312;https://github.com/dvlab-research/MoTCoder&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have showcased impressive capabilities in handling straightforward programming tasks. However, their performance tends to falter when confronted with more challenging programming problems. We observe that conventional models often generate solutions as monolithic code blocks, restricting their effectiveness in tackling intricate questions. To overcome this limitation, we present Modular-of-Thought Coder (MoTCoder). We introduce a pioneering framework for MoT instruction tuning, designed to promote the decomposition of tasks into logical sub-tasks and sub-modules. Our investigations reveal that, through the cultivation and utilization of sub-modules, MoTCoder significantly improves both the modularity and correctness of the generated solutions, leading to substantial relative pass@1 improvements of 12.9% on APPS and 9.43% on CodeContests. Our codes are available at https://github.com/dvlab-research/MoTCoder.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#24207;&#21015;&#21644;&#24182;&#34892;&#30340;ADMM&#31639;&#27861;&#35299;&#20915;&#27531;&#24046;&#32593;&#32476;&#35757;&#32451;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#24182;&#34892;&#23454;&#29616;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#28040;&#32791;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.15334</link><description>&lt;p&gt;
ADMM&#35757;&#32451;&#31639;&#27861;&#29992;&#20110;&#27531;&#24046;&#32593;&#32476;&#65306;&#25910;&#25947;&#24615;&#65292;&#22797;&#26434;&#24230;&#21644;&#24182;&#34892;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
ADMM Training Algorithms for Residual Networks: Convergence, Complexity and Parallel Training. (arXiv:2310.15334v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15334
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#24207;&#21015;&#21644;&#24182;&#34892;&#30340;ADMM&#31639;&#27861;&#35299;&#20915;&#27531;&#24046;&#32593;&#32476;&#35757;&#32451;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#24182;&#34892;&#23454;&#29616;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#28040;&#32791;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#36741;&#21161;&#21464;&#37327;&#65292;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#24207;&#21015;&#21644;&#24182;&#34892;&#30340;&#36817;&#31471;&#28857;&#65288;&#26799;&#24230;&#65289;ADMM&#31639;&#27861;&#26469;&#35299;&#20915;&#23436;&#20840;&#36830;&#25509;&#30340;&#27531;&#24046;&#32593;&#32476;&#65288;FCResNets&#65289;&#35757;&#32451;&#38382;&#39064;&#12290;&#36890;&#36807;&#22522;&#20110;Kurdyka-Lojasiewicz&#65288;KL&#65289;&#23646;&#24615;&#20998;&#26512;&#26694;&#26550;&#30340;&#35777;&#26126;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36817;&#31471;&#28857;&#29256;&#26412;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#30830;&#20445;&#22312;&#19981;&#21516;&#30340;Kurdyka-Lojasiewicz&#65288;KL&#65289;&#25351;&#25968;&#33539;&#22260;&#20869;&#65292;&#23454;&#29616;&#23616;&#37096;R-&#32447;&#24615;&#25110;&#20122;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#24182;&#34892;&#23454;&#29616;&#22312;&#26102;&#38388;&#22797;&#26434;&#24615;&#21644;&#65288;&#27599;&#20010;&#33410;&#28857;&#30340;&#65289;&#20869;&#23384;&#28040;&#32791;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#24212;&#29992;&#20110;FCResNets&#35757;&#32451;&#38382;&#39064;&#30340;ADMM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#25910;&#25947;&#36895;&#24230;&#65292;&#26102;&#38388;&#22797;&#26434;&#24615;&#21644;&#65288;&#27599;&#20010;&#33410;&#28857;&#30340;&#65289;&#20869;&#23384;&#38656;&#27714;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#23454;&#39564;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#39640;&#36895;&#24230;&#65292;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#40065;&#26834;&#24615;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We design a series of serial and parallel proximal point (gradient) ADMMs for the fully connected residual networks (FCResNets) training problem by introducing auxiliary variables. Convergence of the proximal point version is proven based on a Kurdyka-Lojasiewicz (KL) property analysis framework, and we can ensure a locally R-linear or sublinear convergence rate depending on the different ranges of the Kurdyka-Lojasiewicz (KL) exponent, in which a necessary auxiliary function is constructed to realize our goal. Moreover, the advantages of the parallel implementation in terms of lower time complexity and less (per-node) memory consumption are analyzed theoretically. To the best of our knowledge, this is the first work analyzing the convergence, convergence rate, time complexity and (per-node) runtime memory requirement of the ADMM applied in the FCResNets training problem theoretically. Experiments are reported to show the high speed, better performance, robustness and potential in the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12781</link><description>&lt;p&gt;
&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#20195;&#32479;&#35745;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#38656;&#35201;&#22312;&#25935;&#24863;&#29992;&#25143;&#25968;&#25454;&#19978;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#12290;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#19968;&#31181;&#27491;&#24335;&#30340;&#20445;&#35777;&#65292;&#21363;&#20010;&#20307;&#29992;&#25143;&#20449;&#24687;&#19981;&#20250;&#27844;&#38706;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21521;&#20445;&#23494;&#25968;&#25454;&#27880;&#20837;&#26657;&#20934;&#30340;&#22122;&#22768;&#65292;&#20174;&#32780;&#20135;&#29983;&#38544;&#31169;&#20445;&#25252;&#30340;&#25968;&#25454;&#38598;&#25110;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#20250;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#65292;&#38590;&#20197;&#23545;&#22522;&#30784;&#26426;&#23494;&#25968;&#25454;&#30340;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#30340;&#25512;&#29702;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#38598;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#20316;&#20026;&#19968;&#32452;&#28789;&#27963;&#30340;&#20998;&#24067;&#26469;&#36817;&#20284;&#32473;&#23450;&#35266;&#27979;&#21040;&#30340;&#31169;&#26377;&#26597;&#35810;&#32467;&#26524;&#30340;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#20256;&#26579;&#30149;&#27169;&#22411;&#19979;&#30340;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20197;&#21450;&#26222;&#36890;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#19978;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many modern statistical analysis and machine learning applications require training models on sensitive user data. Differential privacy provides a formal guarantee that individual-level information about users does not leak. In this framework, randomized algorithms inject calibrated noise into the confidential data, resulting in privacy-protected datasets or queries. However, restricting access to only the privatized data during statistical analysis makes it computationally challenging to perform valid inferences on parameters underlying the confidential data. In this work, we propose simulation-based inference methods from privacy-protected datasets. Specifically, we use neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and on ordinary linear regression models. Illustra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10545</link><description>&lt;p&gt;
&#20248;&#21270;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#19982;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;
&lt;/p&gt;
&lt;p&gt;
Optimal vintage factor analysis with deflation varimax. (arXiv:2310.10545v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#26088;&#22312;&#39318;&#20808;&#25214;&#21040;&#21407;&#22987;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#23547;&#27714;&#26059;&#36716;&#65292;&#20351;&#26059;&#36716;&#21518;&#30340;&#20302;&#32500;&#34920;&#31034;&#20855;&#26377;&#31185;&#23398;&#24847;&#20041;&#12290;&#23613;&#31649;Principal Component Analysis (PCA) followed by the varimax rotation&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#65292;&#20294;&#30001;&#20110;varimax rotation&#38656;&#35201;&#22312;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#19978;&#35299;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22240;&#27492;&#24456;&#38590;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#34892;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#30340;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#36807;&#31243;&#12290;&#38500;&#20102;&#22312;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#21644;&#28789;&#27963;&#24615;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#33021;&#22312;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#23545;&#25152;&#25552;&#20986;&#30340;&#36807;&#31243;&#36827;&#34892;&#23436;&#20840;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;PCA&#20043;&#21518;&#37319;&#29992;&#36825;&#31181;&#26032;&#30340;varimax&#26041;&#27861;&#20316;&#20026;&#31532;&#20108;&#27493;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#36825;&#20010;&#20004;&#27493;&#36807;&#31243;&#22312;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#22240;&#23376;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vintage factor analysis is one important type of factor analysis that aims to first find a low-dimensional representation of the original data, and then to seek a rotation such that the rotated low-dimensional representation is scientifically meaningful. Perhaps the most widely used vintage factor analysis is the Principal Component Analysis (PCA) followed by the varimax rotation. Despite its popularity, little theoretical guarantee can be provided mainly because varimax rotation requires to solve a non-convex optimization over the set of orthogonal matrices.  In this paper, we propose a deflation varimax procedure that solves each row of an orthogonal matrix sequentially. In addition to its net computational gain and flexibility, we are able to fully establish theoretical guarantees for the proposed procedure in a broad context.  Adopting this new varimax approach as the second step after PCA, we further analyze this two step procedure under a general class of factor models. Our resul
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;ARMOR_D&#26469;&#21152;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#36827;&#34892;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;ARMOR_D&#26041;&#27861;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#20013;&#33021;&#22815;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.03791</link><description>&lt;p&gt;
&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#26469;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences. (arXiv:2309.03791v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;ARMOR_D&#26469;&#21152;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#36827;&#34892;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;ARMOR_D&#26041;&#27861;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#20013;&#33021;&#22815;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;ARMOR_D&#26041;&#27861;&#20316;&#20026;&#22686;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#31867;&#65292;&#36890;&#36807;&#20449;&#24687;&#24046;&#24322;&#21644;&#26368;&#20248;&#20256;&#36755;&#25104;&#26412;&#20043;&#38388;&#30340;infimal&#21367;&#31215;&#26500;&#24314;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#22686;&#24378;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#65292;&#36825;&#34987;&#31216;&#20026;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#12290;&#20316;&#20026;&#26500;&#24314;&#23545;&#25239;&#26679;&#26412;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#26679;&#26412;&#26681;&#25454;&#26368;&#20248;&#20256;&#36755;&#25104;&#26412;&#36827;&#34892;&#20256;&#36755;&#65292;&#24182;&#26681;&#25454;&#20449;&#24687;&#24046;&#24322;&#36827;&#34892;&#37325;&#26032;&#21152;&#26435;&#12290;&#25105;&#20204;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#21457;&#29616;&#22312;&#22686;&#24378;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#26041;&#38754;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;ARMOR_D&#22312;FGSM&#25915;&#20987;&#19979;&#30340;robustified&#20934;&#30830;&#29575;&#36798;&#21040;98.29%&#65292;&#22312;&#20854;&#20182;&#25915;&#20987;&#19979;&#36798;&#21040;98.18%&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\%$ against $FGSM$ and $98.18\%$ aga
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#22312;&#22823;&#35268;&#27169;&#30005;&#21830;&#25968;&#25454;&#38598;&#19978;&#36890;&#36807;&#38598;&#25104;&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.14906</link><description>&lt;p&gt;
&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions. (arXiv:2307.14906v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#21644;&#25439;&#22833;&#20989;&#25968;&#25193;&#23637;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#22312;&#22823;&#35268;&#27169;&#30005;&#21830;&#25968;&#25454;&#38598;&#19978;&#36890;&#36807;&#38598;&#25104;&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#25512;&#33616;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;TRON&#65292;&#19968;&#31181;&#20351;&#29992;&#20248;&#21270;&#30340;&#36127;&#37319;&#26679;&#30340;&#21487;&#25193;&#23637;&#30340;&#22522;&#20110;&#20250;&#35805;&#30340;Transformer&#25512;&#33616;&#31995;&#32479;&#12290;&#21463;&#21040;SASRec&#21644;GRU4Rec+&#31561;&#29616;&#26377;&#27169;&#22411;&#22312;&#21487;&#25193;&#23637;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#38480;&#21046;&#65292;TRON&#38598;&#25104;&#20102;top-k&#36127;&#37319;&#26679;&#21644;&#21015;&#34920;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#25552;&#39640;&#20854;&#25512;&#33616;&#20934;&#30830;&#24615;&#12290;&#22312;&#30456;&#20851;&#30340;&#22823;&#35268;&#27169;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;TRON&#22312;&#20445;&#25345;&#19982;SASRec&#31867;&#20284;&#30340;&#35757;&#32451;&#36895;&#24230;&#30340;&#21516;&#26102;&#65292;&#25913;&#36827;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#25512;&#33616;&#36136;&#37327;&#12290;&#19968;&#39033;&#23454;&#26102;&#30340;A/B&#27979;&#35797;&#26174;&#31034;&#65292;&#30456;&#23545;&#20110;SASRec&#65292;TRON&#30340;&#28857;&#20987;&#29575;&#22686;&#21152;&#20102;18.14%&#65292;&#31361;&#26174;&#20102;&#20854;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces TRON, a scalable session-based Transformer Recommender using Optimized Negative-sampling. Motivated by the scalability and performance limitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates top-k negative sampling and listwise loss functions to enhance its recommendation accuracy. Evaluations on relevant large-scale e-commerce datasets show that TRON improves upon the recommendation quality of current methods while maintaining training speeds similar to SASRec. A live A/B test yielded an 18.14% increase in click-through rate over SASRec, highlighting the potential of TRON in practical settings. For further research, we provide access to our source code at https://github.com/otto-de/TRON and an anonymized dataset at https://github.com/otto-de/recsys-dataset.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#20855;&#26377;&#39640;&#31232;&#30095;&#24230;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#36825;&#19982;&#29983;&#29289;&#23398;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#30456;&#20284;&#12290;</title><link>http://arxiv.org/abs/2305.18353</link><description>&lt;p&gt;
Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20013;&#30340;&#31361;&#29616;&#34920;&#24449;
&lt;/p&gt;
&lt;p&gt;
Emergent representations in networks trained with the Forward-Forward algorithm. (arXiv:2305.18353v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18353
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#35757;&#32451;&#30340;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#20855;&#26377;&#39640;&#31232;&#30095;&#24230;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#36825;&#19982;&#29983;&#29289;&#23398;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#30456;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Backpropagation&#31639;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#20294;&#20854;&#32570;&#20047;&#29983;&#29289;&#23398;&#19978;&#30340;&#29616;&#23454;&#24615;&#12290;&#20026;&#20102;&#23547;&#25214;&#19968;&#31181;&#26356;&#20855;&#29983;&#29289;&#23398;&#21487;&#34892;&#24615;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#24182;&#36991;&#20813;&#21453;&#21521;&#20256;&#25773;&#26799;&#24230;&#65292;&#32780;&#26159;&#20351;&#29992;&#26412;&#22320;&#23398;&#20064;&#35268;&#21017;&#65292;&#26368;&#36817;&#20171;&#32461;&#30340;Forward-Forward&#31639;&#27861;&#23558;Backpropagation&#30340;&#20256;&#36882;&#26367;&#25442;&#20026;&#20004;&#20010;&#21069;&#21521;&#20256;&#36882;&#12290;&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;Forward-Forward&#31639;&#27861;&#33719;&#24471;&#30340;&#20869;&#37096;&#34920;&#24449;&#32452;&#32455;&#20026;&#31283;&#20581;&#30340;&#65292;&#31867;&#21035;&#29305;&#23450;&#30340;&#38598;&#21512;&#65292;&#30001;&#26497;&#23569;&#37327;&#30340;&#26377;&#25928;&#21333;&#20803;(&#39640;&#31232;&#30095;&#24230;)&#32452;&#25104;&#12290;&#36825;&#19982;&#24863;&#35273;&#22788;&#29702;&#36807;&#31243;&#20013;&#35266;&#23519;&#21040;&#30340;&#30382;&#23618;&#34920;&#24449;&#38750;&#24120;&#30456;&#20284;&#12290;&#34429;&#28982;&#22312;&#20351;&#29992;&#26631;&#20934;Backpropagation&#36827;&#34892;&#35757;&#32451;&#30340;&#27169;&#22411;&#20013;&#27809;&#26377;&#21457;&#29616;&#65292;&#20294;&#26159;&#22312;&#20351;&#29992;&#19982;Forward-Forward&#30456;&#21516;&#30340;&#35757;&#32451;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#30340;&#32593;&#32476;&#20013;&#20063;&#20986;&#29616;&#20102;&#31232;&#30095;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;Forward-Forward&#25552;&#35758;&#30340;&#23398;&#20064;&#36807;&#31243;&#21487;&#33021;&#26356;&#25509;&#36817;&#29983;&#29289;&#23398;&#23398;&#20064;&#30340;&#29616;&#23454;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Backpropagation algorithm, widely used to train neural networks, has often been criticised for its lack of biological realism. In an attempt to find a more biologically plausible alternative, and avoid to back-propagate gradients in favour of using local learning rules, the recently introduced Forward-Forward algorithm replaces the traditional forward and backward passes of Backpropagation with two forward passes. In this work, we show that internal representations obtained with the Forward-Forward algorithm organize into robust, category-specific ensembles, composed by an extremely low number of active units (high sparsity). This is remarkably similar to what is observed in cortical representations during sensory processing. While not found in models trained with standard Backpropagation, sparsity emerges also in networks optimized by Backpropagation, on the same training objective of Forward-Forward. These results suggest that the learning procedure proposed by Forward-Forward ma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29609;&#25991;&#23383;&#28216;&#25103;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#20854;&#34920;&#29616;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;&#20173;&#28982;&#32570;&#20047;&#26234;&#33021;&#65292;&#26377;&#24453;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2304.02868</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#33021;&#22815;&#24456;&#22909;&#22320;&#29609;&#25991;&#23383;&#28216;&#25103;&#65311;&#29616;&#29366;&#21644;&#26410;&#26469;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions. (arXiv:2304.02868v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29609;&#25991;&#23383;&#28216;&#25103;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#20854;&#34920;&#29616;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;&#20173;&#28982;&#32570;&#20047;&#26234;&#33021;&#65292;&#26377;&#24453;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#35832;&#22914;ChatGPT&#21644;GPT-4&#20043;&#31867;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#23427;&#20204;&#19982;&#20154;&#31867;&#29992;&#25143;&#36890;&#20449;&#30340;&#21331;&#36234;&#33021;&#21147;&#12290;&#26412;&#25216;&#26415;&#25253;&#21578;&#26088;&#22312;&#35843;&#26597;&#23427;&#20204;&#22312;&#29609;&#25991;&#23383;&#28216;&#25103;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#36825;&#35201;&#27714;&#29609;&#23478;&#36890;&#36807;&#19982;&#28216;&#25103;&#19990;&#30028;&#30340;&#23545;&#35805;&#26469;&#29702;&#35299;&#29615;&#22659;&#24182;&#23545;&#24773;&#20917;&#20570;&#20986;&#21453;&#24212;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#25152;&#26377;&#29616;&#26377;&#31995;&#32479;&#30456;&#27604;&#65292;ChatGPT&#34920;&#29616;&#20986;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;&#20173;&#28982;&#34920;&#29616;&#20986;&#36739;&#20302;&#30340;&#26234;&#33021;&#27700;&#24179;&#12290;&#30830;&#20999;&#22320;&#35828;&#65292;ChatGPT&#26080;&#27861;&#36890;&#36807;&#29609;&#28216;&#25103;&#25110;&#38405;&#35835;&#28216;&#25103;&#25163;&#20876;&#26469;&#26500;&#24314;&#19990;&#30028;&#27169;&#22411;&#65307;&#23427;&#21487;&#33021;&#26080;&#27861;&#21033;&#29992;&#23427;&#24050;&#32463;&#25317;&#26377;&#30340;&#19990;&#30028;&#30693;&#35782;&#65307;&#23427;&#26080;&#27861;&#25512;&#26029;&#20986;&#38543;&#30528;&#28216;&#25103;&#36827;&#23637;&#30340;&#27599;&#19968;&#27493;&#30340;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#20154;&#24037;&#26234;&#33021;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20132;&#21449;&#39046;&#22495;&#24320;&#21551;&#20102;&#26032;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users. In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world. Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence. Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses. Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#35299;&#20915;&#37327;&#23376;&#35745;&#31639;&#20013;&#30340;&#20445;&#30495;&#24230;&#38382;&#39064;&#65292;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#39044;&#27979;&#37327;&#23376;&#30005;&#36335;&#30340;&#20445;&#30495;&#24230;&#12290;</title><link>http://arxiv.org/abs/2303.17523</link><description>&lt;p&gt;
&#21033;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#25552;&#39640;&#37327;&#23376;&#30005;&#36335;&#20445;&#30495;&#24230;
&lt;/p&gt;
&lt;p&gt;
Quantum Circuit Fidelity Improvement with Long Short-Term Memory Networks. (arXiv:2303.17523v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17523
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#35299;&#20915;&#37327;&#23376;&#35745;&#31639;&#20013;&#30340;&#20445;&#30495;&#24230;&#38382;&#39064;&#65292;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#39044;&#27979;&#37327;&#23376;&#30005;&#36335;&#30340;&#20445;&#30495;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#35745;&#31639;&#24050;&#36827;&#20837;&#22122;&#22768;&#20013;&#38388;&#35268;&#27169;&#37327;&#23376;&#65288;NISQ&#65289;&#26102;&#20195;&#65292;&#30446;&#21069;&#25105;&#20204;&#25317;&#26377;&#30340;&#37327;&#23376;&#22788;&#29702;&#22120;&#23545;&#36752;&#23556;&#21644;&#28201;&#24230;&#31561;&#29615;&#22659;&#21464;&#37327;&#25935;&#24863;&#65292;&#22240;&#27492;&#20250;&#20135;&#29983;&#22024;&#26434;&#30340;&#36755;&#20986;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#35768;&#22810;&#31639;&#27861;&#21644;&#24212;&#29992;&#31243;&#24207;&#29992;&#20110;NISQ&#22788;&#29702;&#22120;&#65292;&#20294;&#25105;&#20204;&#20173;&#38754;&#20020;&#30528;&#35299;&#37322;&#20854;&#22024;&#26434;&#32467;&#26524;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23545;&#25152;&#36873;&#25321;&#30340;&#37327;&#23376;&#24577;&#26377;&#22810;&#23569;&#20449;&#24515;&#65311;&#36825;&#31181;&#20449;&#24515;&#24456;&#37325;&#35201;&#65292;&#22240;&#20026;NISQ&#35745;&#31639;&#26426;&#23558;&#36755;&#20986;&#20854;&#37327;&#23376;&#20301;&#27979;&#37327;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#26377;&#26102;&#24456;&#38590;&#21306;&#20998;&#20998;&#24067;&#26159;&#21542;&#34920;&#31034;&#26377;&#24847;&#20041;&#30340;&#35745;&#31639;&#25110;&#21482;&#26159;&#38543;&#26426;&#22122;&#22768;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#37327;&#23376;&#30005;&#36335;&#20445;&#30495;&#24230;&#39044;&#27979;&#26694;&#26550;&#20026;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#38382;&#39064;&#65292;&#22240;&#27492;&#21487;&#20197;&#21033;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#31070;&#32463;&#32593;&#32476;&#30340;&#24378;&#22823;&#33021;&#21147;&#12290;&#19968;&#20010;&#23436;&#25972;&#30340;&#24037;&#20316;&#27969;&#31243;&#26469;&#26500;&#24314;&#35757;&#32451;&#30005;&#36335;
&lt;/p&gt;
&lt;p&gt;
Quantum computing has entered the Noisy Intermediate-Scale Quantum (NISQ) era. Currently, the quantum processors we have are sensitive to environmental variables like radiation and temperature, thus producing noisy outputs. Although many proposed algorithms and applications exist for NISQ processors, we still face uncertainties when interpreting their noisy results. Specifically, how much confidence do we have in the quantum states we are picking as the output? This confidence is important since a NISQ computer will output a probability distribution of its qubit measurements, and it is sometimes hard to distinguish whether the distribution represents meaningful computation or just random noise. This paper presents a novel approach to attack this problem by framing quantum circuit fidelity prediction as a Time Series Forecasting problem, therefore making it possible to utilize the power of Long Short-Term Memory (LSTM) neural networks. A complete workflow to build the training circuit d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23646;&#24615;&#36873;&#25321;&#26426;&#21046;&#30340;&#22825;&#28982;&#21487;&#35299;&#37322;&#27169;&#22411;&#26469;&#22788;&#29702;&#23567;&#26679;&#26412;&#23398;&#20064;&#65292;&#36890;&#36807;&#20943;&#23569;&#27599;&#20010;episode&#20013;&#28041;&#21450;&#30340;&#23646;&#24615;&#25968;&#37327;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#33258;&#21160;&#26816;&#27979;&#24182;&#34917;&#20607;&#20154;&#24037;&#26234;&#33021;&#23646;&#24615;&#27744;&#19981;&#36275;&#30340;episode&#12290;</title><link>http://arxiv.org/abs/2211.09107</link><description>&lt;p&gt;
&#22312;&#32447;&#23646;&#24615;&#36873;&#25321;&#30340;&#21487;&#35299;&#37322;&#30340;&#23567;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Interpretable Few-shot Learning with Online Attribute Selection. (arXiv:2211.09107v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23646;&#24615;&#36873;&#25321;&#26426;&#21046;&#30340;&#22825;&#28982;&#21487;&#35299;&#37322;&#27169;&#22411;&#26469;&#22788;&#29702;&#23567;&#26679;&#26412;&#23398;&#20064;&#65292;&#36890;&#36807;&#20943;&#23569;&#27599;&#20010;episode&#20013;&#28041;&#21450;&#30340;&#23646;&#24615;&#25968;&#37327;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#33258;&#21160;&#26816;&#27979;&#24182;&#34917;&#20607;&#20154;&#24037;&#26234;&#33021;&#23646;&#24615;&#27744;&#19981;&#36275;&#30340;episode&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23567;&#26679;&#26412;&#23398;&#20064;(few-shot learning, FSL)&#26159;&#19968;&#31181;&#25361;&#25112;&#24615;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#27599;&#20010;&#31867;&#21035;&#21482;&#26377;&#24456;&#23569;&#30340;&#26679;&#26412;&#21487;&#29992;&#12290;&#22312;FSL&#20013;&#20915;&#31574;&#30340;&#35299;&#37322;&#27604;&#20256;&#32479;&#20998;&#31867;&#26356;&#21152;&#37325;&#35201;&#65292;&#22240;&#20026;&#38169;&#35823;&#30340;&#20960;&#29575;&#26356;&#22823;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20197;&#21069;&#30340;FSL&#26041;&#27861;&#37117;&#26159;&#40657;&#21283;&#23376;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26131;&#20110;&#29702;&#35299;&#30340;&#23646;&#24615;&#30340;&#22825;&#28982;&#21487;&#35299;&#37322;&#27169;&#22411;&#26469;&#22788;&#29702;FSL&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23646;&#24615;&#36873;&#25321;&#26426;&#21046;&#65292;&#20197;&#26377;&#25928;&#36807;&#28388;&#27599;&#20010;episode&#20013;&#19981;&#30456;&#20851;&#30340;&#23646;&#24615;&#12290;&#35813;&#23646;&#24615;&#36873;&#25321;&#26426;&#21046;&#36890;&#36807;&#20943;&#23569;&#27599;&#20010;episode&#20013;&#28041;&#21450;&#30340;&#23646;&#24615;&#25968;&#37327;&#26469;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#21046;&#65292;&#33258;&#21160;&#26816;&#27979;&#20154;&#24037;&#26234;&#33021;&#23646;&#24615;&#27744;&#19981;&#36275;&#30340;episode&#65292;&#24182;&#36890;&#36807;&#28041;&#21450;&#23398;&#20064;&#30340;&#26410;&#30693;&#23646;&#24615;&#26469;&#34917;&#20607;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#19982;&#40657;&#21283;&#23376;&#23567;&#26679;&#26412;&#23398;&#20064;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Few-shot learning (FSL) is a challenging learning problem in which only a few samples are available for each class. Decision interpretation is more important in few-shot classification since there is a greater chance of error than in traditional classification. However, most of the previous FSL methods are black-box models. In this paper, we propose an inherently interpretable model for FSL based on human-friendly attributes. Moreover, we propose an online attribute selection mechanism that can effectively filter out irrelevant attributes in each episode. The attribute selection mechanism improves the accuracy and helps with interpretability by reducing the number of participated attributes in each episode. We propose a mechanism that automatically detects the episodes where the pool of human-friendly attributes are not adequate, and compensates by engaging learned unknown attributes. We demonstrate that the proposed method achieves results on par with black-box few-shot-learning model
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24182;&#19988;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24314;&#27169;&#20102;&#38543;&#26426;&#23545;&#35937;&#65292;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#24180;&#40836;&#20998;&#24067;&#21644;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2207.05442</link><description>&lt;p&gt;
Wasserstein&#22810;&#20803;&#33258;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#24314;&#27169;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#21450;&#20854;&#22312;&#22270;&#24418;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning. (arXiv:2207.05442v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.05442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24182;&#19988;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24314;&#27169;&#20102;&#38543;&#26426;&#23545;&#35937;&#65292;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#24180;&#40836;&#20998;&#24067;&#21644;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#32479;&#35745;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#21253;&#25324;&#19968;&#32452;&#22312;&#23454;&#32447;&#26377;&#30028;&#38388;&#38548;&#19978;&#25903;&#25345;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#22810;&#20010;&#31995;&#21015;&#65292;&#24182;&#19988;&#34987;&#19981;&#21516;&#26102;&#38388;&#30636;&#38388;&#25152;&#32034;&#24341;&#12290;&#27010;&#29575;&#27979;&#24230;&#34987;&#24314;&#27169;&#20026;Wasserstein&#31354;&#38388;&#20013;&#30340;&#38543;&#26426;&#23545;&#35937;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;Lebesgue&#27979;&#24230;&#30340;&#20999;&#31354;&#38388;&#20013;&#24314;&#31435;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#39318;&#20808;&#23545;&#25152;&#26377;&#21407;&#22987;&#27979;&#24230;&#36827;&#34892;&#23621;&#20013;&#22788;&#29702;&#65292;&#20197;&#20415;&#23427;&#20204;&#30340;Fr&#233;chet&#24179;&#22343;&#20540;&#25104;&#20026;Lebesgue&#27979;&#24230;&#12290;&#21033;&#29992;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#31995;&#32479;&#30340;&#29702;&#35770;&#65292;&#25552;&#20379;&#20102;&#36825;&#26679;&#19968;&#20010;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#24179;&#31283;&#24615;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#27169;&#22411;&#31995;&#25968;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#38500;&#20102;&#23545;&#27169;&#25311;&#25968;&#25454;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#36824;&#20351;&#29992;&#20004;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#27169;&#22411;&#28436;&#31034;&#65306;&#19968;&#20010;&#26159;&#19981;&#21516;&#22269;&#23478;&#24180;&#40836;&#20998;&#24067;&#30340;&#35266;&#23519;&#25968;&#25454;&#38598;&#65292;&#21478;&#19968;&#20010;&#26159;&#24052;&#40654;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new auto-regressive model for the statistical analysis of multivariate distributional time series. The data of interest consist of a collection of multiple series of probability measures supported over a bounded interval of the real line, and that are indexed by distinct time instants. The probability measures are modelled as random objects in the Wasserstein space. We establish the auto-regressive model in the tangent space at the Lebesgue measure by first centering all the raw measures so that their Fr\'echet means turn to be the Lebesgue measure. Using the theory of iterated random function systems, results on the existence, uniqueness and stationarity of the solution of such a model are provided. We also propose a consistent estimator for the model coefficient. In addition to the analysis of simulated data, the proposed model is illustrated with two real data sets made of observations from age distribution in different countries and bike sharing network in Paris. Final
&lt;/p&gt;</description></item></channel></rss>