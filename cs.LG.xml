<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#22270;&#20687;&#22788;&#29702;&#26465;&#20214;&#35774;&#32622;&#22312;EHR&#30340;&#20540;&#21644;&#27979;&#37327;&#19978;&#65292;&#20197;&#25972;&#21512;&#20020;&#24202;&#25104;&#20687;&#21644;&#34920;&#26684;&#25968;&#25454;&#65292;&#26088;&#22312;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#20013;&#30340;&#20114;&#34917;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2403.13319</link><description>&lt;p&gt;
HyperFusion&#65306;&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#24314;&#27169;&#30340;&#22810;&#27169;&#24577;&#25972;&#21512;&#34920;&#26684;&#21644;&#21307;&#23398;&#25104;&#20687;&#25968;&#25454;&#30340;&#36229;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
HyperFusion: A Hypernetwork Approach to Multimodal Integration of Tabular and Medical Imaging Data for Predictive Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13319
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#22270;&#20687;&#22788;&#29702;&#26465;&#20214;&#35774;&#32622;&#22312;EHR&#30340;&#20540;&#21644;&#27979;&#37327;&#19978;&#65292;&#20197;&#25972;&#21512;&#20020;&#24202;&#25104;&#20687;&#21644;&#34920;&#26684;&#25968;&#25454;&#65292;&#26088;&#22312;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#20013;&#30340;&#20114;&#34917;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ARXIV: 2403.13319v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449;&#25688;&#35201;: &#25972;&#21512;&#21508;&#31181;&#20020;&#24202;&#27169;&#24335;&#65292;&#22914;&#21307;&#23398;&#25104;&#20687;&#21644;&#24739;&#32773;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#33719;&#24471;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#26159;&#29616;&#20195;&#21307;&#30103;&#20445;&#20581;&#30340;&#20851;&#38190;&#26041;&#38754;&#12290;&#22810;&#28304;&#25968;&#25454;&#30340;&#32508;&#21512;&#20998;&#26512;&#21487;&#20197;&#20840;&#38754;&#20102;&#35299;&#24739;&#32773;&#30340;&#29366;&#20917;&#65292;&#24182;&#21487;&#20197;&#22686;&#24378;&#35786;&#26029;&#21644;&#27835;&#30103;&#20915;&#31574;&#12290;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#21307;&#23398;&#39046;&#22495;&#30340;&#22810;&#27169;&#24577;&#20219;&#21153;&#20013;&#19968;&#30452;&#23637;&#31034;&#20986;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#26377;&#25928;&#22320;&#23558;&#21307;&#23398;&#25104;&#20687;&#19982;&#20197;&#25968;&#23383;&#34920;&#26684;&#25968;&#25454;&#34920;&#31034;&#30340;&#20020;&#24202;&#12289;&#20154;&#21475;&#32479;&#35745;&#21644;&#36951;&#20256;&#20449;&#24687;&#36827;&#34892;&#34701;&#21512;&#30340;&#22797;&#26434;&#21162;&#21147;&#20173;&#28982;&#26159;&#19968;&#20010;&#39640;&#24230;&#27963;&#36291;&#30340;&#25345;&#32493;&#30740;&#31350;&#36861;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13319v1 Announce Type: cross  Abstract: The integration of diverse clinical modalities such as medical imaging and the tabular data obtained by the patients' Electronic Health Records (EHRs) is a crucial aspect of modern healthcare. The integrative analysis of multiple sources can provide a comprehensive understanding of a patient's condition and can enhance diagnoses and treatment decisions. Deep Neural Networks (DNNs) consistently showcase outstanding performance in a wide range of multimodal tasks in the medical domain. However, the complex endeavor of effectively merging medical imaging with clinical, demographic and genetic information represented as numerical tabular data remains a highly active and ongoing research pursuit.   We present a novel framework based on hypernetworks to fuse clinical imaging and tabular data by conditioning the image processing on the EHR's values and measurements. This approach aims to leverage the complementary information present in these
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#32771;&#34385;&#38544;&#31169;&#32422;&#26463;&#12290;</title><link>https://arxiv.org/abs/2403.11343</link><description>&lt;p&gt;
&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Transfer Learning with Differential Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#32771;&#34385;&#38544;&#31169;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#36234;&#26469;&#36234;&#21463;&#21040;&#27426;&#36814;&#65292;&#25968;&#25454;&#24322;&#26500;&#24615;&#21644;&#38544;&#31169;&#24615;&#26159;&#20004;&#20010;&#31361;&#20986;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#20869;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#26088;&#22312;&#36890;&#36807;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#36981;&#23432;&#38544;&#31169;&#32422;&#26463;&#12290;&#25105;&#20204;&#20005;&#26684;&#21046;&#23450;&#20102;\textit{&#32852;&#37030;&#24046;&#20998;&#38544;&#31169;}&#30340;&#27010;&#24565;&#65292;&#20026;&#27599;&#20010;&#25968;&#25454;&#38598;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65292;&#32780;&#26080;&#38656;&#20551;&#35774;&#26377;&#19968;&#20010;&#21463;&#20449;&#20219;&#30340;&#20013;&#22830;&#26381;&#21153;&#22120;&#12290;&#22312;&#36825;&#20010;&#38544;&#31169;&#32422;&#26463;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#20010;&#32463;&#20856;&#30340;&#32479;&#35745;&#38382;&#39064;&#65292;&#21363;&#21333;&#21464;&#37327;&#22343;&#20540;&#20272;&#35745;&#12289;&#20302;&#32500;&#32447;&#24615;&#22238;&#24402;&#21644;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#12290;&#36890;&#36807;&#30740;&#31350;&#26497;&#23567;&#20540;&#29575;&#24182;&#30830;&#23450;&#36825;&#20123;&#38382;&#39064;&#30340;&#38544;&#31169;&#25104;&#26412;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32852;&#37030;&#24046;&#20998;&#38544;&#31169;&#26159;&#24050;&#24314;&#31435;&#30340;&#23616;&#37096;&#21644;&#20013;&#22830;&#27169;&#22411;&#20043;&#38388;&#30340;&#19968;&#31181;&#20013;&#38388;&#38544;&#31169;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11343v1 Announce Type: new  Abstract: Federated learning is gaining increasing popularity, with data heterogeneity and privacy being two prominent challenges. In this paper, we address both issues within a federated transfer learning framework, aiming to enhance learning on a target data set by leveraging information from multiple heterogeneous source data sets while adhering to privacy constraints. We rigorously formulate the notion of \textit{federated differential privacy}, which offers privacy guarantees for each data set without assuming a trusted central server. Under this privacy constraint, we study three classical statistical problems, namely univariate mean estimation, low-dimensional linear regression, and high-dimensional linear regression. By investigating the minimax rates and identifying the costs of privacy for these problems, we show that federated differential privacy is an intermediate privacy model between the well-established local and central models of 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#27010;&#24565;&#65292;$(\varepsilon, \Phi(\delta))$-&#23616;&#37096;&#22343;&#34913;&#65292;&#20197;&#35299;&#20915;&#22312;&#38750;&#20985;&#28216;&#25103;&#20013;&#23616;&#37096;&#22343;&#34913;&#23384;&#22312;&#20294;&#38590;&#20197;&#22788;&#29702;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.08171</link><description>&lt;p&gt;
&#22312;&#38750;&#20985;&#28216;&#25103;&#20013;&#21487;&#22788;&#29702;&#30340;&#23616;&#37096;&#22343;&#34913;
&lt;/p&gt;
&lt;p&gt;
Tractable Local Equilibria in Non-Concave Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08171
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#27010;&#24565;&#65292;$(\varepsilon, \Phi(\delta))$-&#23616;&#37096;&#22343;&#34913;&#65292;&#20197;&#35299;&#20915;&#22312;&#38750;&#20985;&#28216;&#25103;&#20013;&#23616;&#37096;&#22343;&#34913;&#23384;&#22312;&#20294;&#38590;&#20197;&#22788;&#29702;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20247;&#25152;&#21608;&#30693;&#22312;&#32447;&#26799;&#24230;&#19979;&#38477;&#21644;&#20854;&#20182;&#26080;&#24724;&#23398;&#20064;&#31243;&#24207;&#21487;&#20197;&#26377;&#25928;&#22320;&#25910;&#25947;&#21040;&#21327;&#35843;&#22343;&#34913;&#65292;&#22312;&#27599;&#20010;Agent&#30340;&#25928;&#29992;&#23545;&#20110;&#20854;&#33258;&#36523;&#31574;&#30053;&#21576;&#20985;&#24418;&#30340;&#24773;&#20917;&#19979;&#65292;&#20294;&#24403;&#25928;&#29992;&#26159;&#38750;&#20985;&#30340;&#26102;&#65292;&#36825;&#31181;&#24773;&#20917;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#65292;&#20854;&#20013;Agent&#30340;&#31574;&#30053;&#30001;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#65292;&#25110;&#32773;Agent&#30340;&#25928;&#29992;&#30001;&#31070;&#32463;&#32593;&#32476;&#35745;&#31639;&#65292;&#25110;&#20004;&#32773;&#20860;&#32780;&#26377;&#20043;&#12290;&#23454;&#38469;&#19978;&#65292;&#38750;&#20985;&#28216;&#25103;&#23384;&#22312;&#19968;&#31995;&#21015;&#21338;&#24328;&#35770;&#21644;&#20248;&#21270;&#25361;&#25112;&#65306;(i) Nash&#22343;&#34913;&#21487;&#33021;&#19981;&#23384;&#22312;&#65307;(ii) &#23616;&#37096;Nash&#22343;&#34913;&#23384;&#22312;&#20294;&#26159;&#19981;&#21487;&#22788;&#29702;&#65307;(iii) &#28151;&#21512;Nash&#12289;&#21327;&#35843;&#21644;&#31895;&#31961;&#21327;&#35843;&#22343;&#34913;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#20855;&#26377;&#26080;&#38480;&#25903;&#25345;&#65292;&#24182;&#19988;&#26159;&#19981;&#21487;&#22788;&#29702;&#30340;&#12290;&#20026;&#20102;&#36991;&#24320;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#27010;&#24565;&#65292;&#31216;&#20026;$(\varepsilon, \Phi(\delta))$-&#23616;&#37096;&#22343;&#34913;&#65292;&#35813;&#27010;&#24565;&#22312;&#38750;&#20985;&#28216;&#25103;&#20013;&#27010;&#25324;&#20102;&#23616;&#37096;Nash&#22343;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08171v1 Announce Type: cross  Abstract: While Online Gradient Descent and other no-regret learning procedures are known to efficiently converge to coarse correlated equilibrium in games where each agent's utility is concave in their own strategy, this is not the case when the utilities are non-concave, a situation that is common in machine learning applications where the agents' strategies are parameterized by deep neural networks, or the agents' utilities are computed by a neural network, or both. Indeed, non-concave games present a host of game-theoretic and optimization challenges: (i) Nash equilibria may fail to exist; (ii) local Nash equilibria exist but are intractable; and (iii) mixed Nash, correlated, and coarse correlated equilibria have infinite support in general, and are intractable. To sidestep these challenges we propose a new solution concept, termed $(\varepsilon, \Phi(\delta))$-local equilibrium, which generalizes local Nash equilibrium in non-concave games,
&lt;/p&gt;</description></item><item><title>CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;</title><link>https://arxiv.org/abs/2403.07728</link><description>&lt;p&gt;
CAS: &#19968;&#31181;&#20855;&#26377;FCR&#25511;&#21046;&#30340;&#22312;&#32447;&#36873;&#25321;&#24615;&#31526;&#21512;&#39044;&#27979;&#30340;&#36890;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
CAS: A General Algorithm for Online Selective Conformal Prediction with FCR Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07728
&lt;/p&gt;
&lt;p&gt;
CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#26041;&#24335;&#19979;&#21518;&#36873;&#25321;&#39044;&#27979;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#23558;&#36164;&#28304;&#32791;&#36153;&#22312;&#19981;&#37325;&#35201;&#30340;&#21333;&#20301;&#19978;&#65292;&#22312;&#25253;&#21578;&#20854;&#39044;&#27979;&#21306;&#38388;&#20043;&#21069;&#23545;&#24403;&#21069;&#20010;&#20307;&#36827;&#34892;&#21021;&#27493;&#36873;&#25321;&#22312;&#22312;&#32447;&#39044;&#27979;&#20219;&#21153;&#20013;&#26159;&#24120;&#35265;&#19988;&#26377;&#24847;&#20041;&#30340;&#12290;&#30001;&#20110;&#22312;&#32447;&#36873;&#25321;&#23548;&#33268;&#25152;&#36873;&#39044;&#27979;&#21306;&#38388;&#20013;&#23384;&#22312;&#26102;&#38388;&#22810;&#37325;&#24615;&#65292;&#22240;&#27492;&#25511;&#21046;&#23454;&#26102;&#35823;&#35206;&#30422;&#38472;&#36848;&#29575;&#65288;FCR&#65289;&#26469;&#27979;&#37327;&#24179;&#22343;&#35823;&#35206;&#30422;&#35823;&#24046;&#26159;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;CAS&#65288;&#36866;&#24212;&#24615;&#36873;&#25321;&#21518;&#26657;&#20934;&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#21253;&#35065;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#21644;&#22312;&#32447;&#36873;&#25321;&#35268;&#21017;&#65292;&#20197;&#36755;&#20986;&#21518;&#36873;&#25321;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#22914;&#26524;&#36873;&#25321;&#20102;&#24403;&#21069;&#20010;&#20307;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#21382;&#21490;&#25968;&#25454;&#36827;&#34892;&#33258;&#36866;&#24212;&#36873;&#25321;&#26469;&#26500;&#24314;&#26657;&#20934;&#38598;&#65292;&#28982;&#21518;&#20026;&#26410;&#35266;&#23519;&#21040;&#30340;&#26631;&#31614;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#20026;&#26657;&#20934;&#38598;&#25552;&#20379;&#20102;&#21487;&#34892;&#30340;&#26500;&#36896;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07728v1 Announce Type: cross  Abstract: We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) to measure the averaged miscoverage error. We develop a general framework named CAS (Calibration after Adaptive Selection) that can wrap around any prediction model and online selection rule to output post-selection prediction intervals. If the current individual is selected, we first perform an adaptive selection on historical data to construct a calibration set, then output a conformal prediction interval for the unobserved label. We provide tractable constructions for the calibration set for 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22312;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#39030;&#28857;&#19978;&#23884;&#20837;&#32467;&#26524;&#65292;&#24182;&#25506;&#31350;&#21333;&#32431;&#24418;&#20013;&#30340;&#19968;&#33268;&#24615;&#21306;&#22495;&#65292;&#26435;&#34913;&#20102;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.10818</link><description>&lt;p&gt;
&#22312;&#27169;&#22411;&#30340;&#20984;&#26367;&#20195;&#21697;&#30340;&#19968;&#33268;&#24615;&#21644;&#32500;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Trading off Consistency and Dimensionality of Convex Surrogates for the Mode
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10818
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#39030;&#28857;&#19978;&#23884;&#20837;&#32467;&#26524;&#65292;&#24182;&#25506;&#31350;&#21333;&#32431;&#24418;&#20013;&#30340;&#19968;&#33268;&#24615;&#21306;&#22495;&#65292;&#26435;&#34913;&#20102;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#31867;&#20998;&#31867;&#20013;&#65292;&#24517;&#39035;&#23558;&#32467;&#26524;&#23884;&#20837;&#21040;&#33267;&#23569;&#26377;$n-1$&#32500;&#30340;&#23454;&#25968;&#31354;&#38388;&#20013;&#65292;&#20197;&#35774;&#35745;&#19968;&#31181;&#19968;&#33268;&#30340;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#65292;&#36825;&#20250;&#23548;&#33268;"&#27491;&#30830;"&#30340;&#20998;&#31867;&#65292;&#32780;&#19981;&#21463;&#25968;&#25454;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#22312;&#20449;&#24687;&#26816;&#32034;&#21644;&#32467;&#26500;&#21270;&#39044;&#27979;&#20219;&#21153;&#31561;&#38656;&#35201;&#22823;&#37327;n&#26102;&#65292;&#20248;&#21270;n-1&#32500;&#26367;&#20195;&#24120;&#24120;&#26159;&#26840;&#25163;&#30340;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#31867;&#20998;&#31867;&#20013;&#22914;&#20309;&#26435;&#34913;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#20197;&#21450;&#22312;&#21333;&#32431;&#24418;&#19978;&#32422;&#26463;&#19968;&#33268;&#24615;&#21306;&#22495;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36319;&#38543;&#36807;&#21435;&#30340;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#23884;&#20837;&#36807;&#31243;&#65292;&#23558;&#32467;&#26524;&#26144;&#23556;&#21040;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#30340;&#39030;&#28857;&#19978;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#27599;&#20010;&#28857;&#36136;&#37327;&#20998;&#24067;&#21608;&#22260;&#23384;&#22312;&#21333;&#32431;&#24418;&#30340;&#20840;&#32500;&#23376;&#38598;&#65292;&#20854;&#20013;&#19968;&#33268;&#24615;&#25104;&#31435;&#65292;&#20294;&#26159;&#65292;&#23569;&#20110;n-1&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#19968;&#20123;&#20998;&#24067;&#65292;&#23545;&#20110;&#36825;&#20123;&#20998;&#24067;&#65292;&#19968;&#31181;&#29616;&#35937;&#24615;&#26159;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10818v1 Announce Type: new  Abstract: In multiclass classification over $n$ outcomes, the outcomes must be embedded into the reals with dimension at least $n-1$ in order to design a consistent surrogate loss that leads to the "correct" classification, regardless of the data distribution. For large $n$, such as in information retrieval and structured prediction tasks, optimizing a surrogate in $n-1$ dimensions is often intractable. We investigate ways to trade off surrogate loss dimension, the number of problem instances, and restricting the region of consistency in the simplex for multiclass classification. Following past work, we examine an intuitive embedding procedure that maps outcomes into the vertices of convex polytopes in a low-dimensional surrogate space. We show that full-dimensional subsets of the simplex exist around each point mass distribution for which consistency holds, but also, with less than $n-1$ dimensions, there exist distributions for which a phenomeno
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#23545;&#31216;&#30772;&#32570;&#22686;&#24378;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#35757;&#32451;&#38431;&#21451;&#30340;&#34892;&#20026;&#22810;&#26679;&#24615;&#26469;&#25552;&#39640;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#19982;&#26032;&#38431;&#21451;&#21512;&#20316;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09984</link><description>&lt;p&gt;
&#23545;&#20110;&#20020;&#26102;&#22242;&#38431;&#21512;&#20316;&#30340;&#23545;&#31216;&#30772;&#32570;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Symmetry-Breaking Augmentations for Ad Hoc Teamwork
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#23545;&#31216;&#30772;&#32570;&#22686;&#24378;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#35757;&#32451;&#38431;&#21451;&#30340;&#34892;&#20026;&#22810;&#26679;&#24615;&#26469;&#25552;&#39640;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#19982;&#26032;&#38431;&#21451;&#21512;&#20316;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#21327;&#20316;&#29615;&#22659;&#20013;&#65292;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#20195;&#29702;&#24517;&#39035;&#33021;&#22815;&#36866;&#24212;&#20351;&#29992;&#26410;&#30693;&#25110;&#20808;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#31574;&#30053;&#30340;&#26032;&#38431;&#21451;&#12290;&#23545;&#20110;AI&#20195;&#29702;&#26469;&#35828;&#65292;&#36825;&#36890;&#24120;&#23545;&#20154;&#31867;&#26469;&#35828;&#24456;&#31616;&#21333;&#65292;&#20294;&#21364;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20363;&#22914;&#65292;&#22914;&#26524;&#19968;&#20010;AI&#20195;&#29702;&#22312;&#35757;&#32451;&#38598;&#20013;&#23398;&#20250;&#20102;&#19982;&#21482;&#22312;&#19968;&#20391;&#36947;&#36335;&#19978;&#34892;&#39542;&#30340;&#20854;&#20182;&#36710;&#36742;&#24182;&#34892;&#39542;&#65292;&#37027;&#20040;&#21363;&#20351;&#36825;&#20123;&#36710;&#36742;&#30340;&#34892;&#20026;&#21482;&#26159;&#22312;&#24038;&#21491;&#23545;&#31216;&#19978;&#36827;&#34892;&#20102;&#32763;&#36716;&#65292;&#23427;&#20063;&#21487;&#33021;&#38590;&#20197;&#36866;&#24212;&#19982;&#30456;&#21453;&#26041;&#21521;&#19978;&#34892;&#39542;&#30340;&#39550;&#39542;&#21592;&#36827;&#34892;&#21327;&#35843;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#31216;&#30772;&#32570;&#22686;&#24378;&#65288;SBA&#65289;&#65292;&#36890;&#36807;&#24212;&#29992;&#23545;&#31216;&#32763;&#36716;&#25805;&#20316;&#26469;&#22686;&#21152;&#35757;&#32451;&#38431;&#21451;&#30340;&#34892;&#20026;&#22810;&#26679;&#24615;&#12290;&#36890;&#36807;&#23398;&#20064;&#23545;&#22686;&#24378;&#21518;&#30340;&#38431;&#21451;&#30340;&#26368;&#20339;&#21709;&#24212;&#65292;&#25105;&#20204;&#30340;&#20195;&#29702;&#33021;&#22815;&#25509;&#35302;&#21040;&#26356;&#24191;&#27867;&#30340;&#34892;&#20026;&#32422;&#23450;&#65292;&#20174;&#32780;&#25552;&#39640;&#19982;&#26032;&#38431;&#21451;&#21512;&#20316;&#26102;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#35774;&#32622;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09984v1 Announce Type: cross  Abstract: In many collaborative settings, artificial intelligence (AI) agents must be able to adapt to new teammates that use unknown or previously unobserved strategies. While often simple for humans, this can be challenging for AI agents. For example, if an AI agent learns to drive alongside others (a training set) that only drive on one side of the road, it may struggle to adapt this experience to coordinate with drivers on the opposite side, even if their behaviours are simply flipped along the left-right symmetry. To address this we introduce symmetry-breaking augmentations (SBA), which increases diversity in the behaviour of training teammates by applying a symmetry-flipping operation. By learning a best-response to the augmented set of teammates, our agent is exposed to a wider range of behavioural conventions, improving performance when deployed with novel teammates. We demonstrate this experimentally in two settings, and show that our a
&lt;/p&gt;</description></item><item><title>Centaur&#25552;&#20986;&#20102;&#38754;&#21521;&#21463;&#38480;&#36793;&#32536;&#35774;&#22791;&#30340;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#36873;&#25321;&#26041;&#26696;&#21644;&#22522;&#20110;&#20998;&#21306;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#36229;&#38480;&#21046;&#35774;&#22791;&#22312;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#21442;&#19982;&#65292;&#30456;&#27604;&#26412;&#22320;&#35757;&#32451;&#33021;&#33719;&#24471;&#26356;&#39640;&#20934;&#30830;&#24615;&#21644;&#33410;&#32422;&#33021;&#37327;&#12290;</title><link>https://arxiv.org/abs/2211.04175</link><description>&lt;p&gt;
Centaur: &#38754;&#21521;&#21463;&#38480;&#36793;&#32536;&#35774;&#22791;&#30340;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Centaur: Federated Learning for Constrained Edge Devices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.04175
&lt;/p&gt;
&lt;p&gt;
Centaur&#25552;&#20986;&#20102;&#38754;&#21521;&#21463;&#38480;&#36793;&#32536;&#35774;&#22791;&#30340;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#36873;&#25321;&#26041;&#26696;&#21644;&#22522;&#20110;&#20998;&#21306;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#36229;&#38480;&#21046;&#35774;&#22791;&#22312;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#21442;&#19982;&#65292;&#30456;&#27604;&#26412;&#22320;&#35757;&#32451;&#33021;&#33719;&#24471;&#26356;&#39640;&#20934;&#30830;&#24615;&#21644;&#33410;&#32422;&#33021;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20419;&#36827;&#20102;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#30340;&#26032;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#21487;&#31359;&#25140;&#21644;&#29289;&#32852;&#32593;&#35774;&#22791;&#12290;&#36825;&#20123;&#35774;&#22791;&#25429;&#33719;&#22823;&#37327;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#65292;&#20294;&#23427;&#20204;&#21463;&#21040;&#20869;&#23384;&#12289;&#35745;&#31639;&#12289;&#21151;&#32791;&#21644;&#36830;&#25509;&#24615;&#32422;&#26463;&#65292;&#36825;&#20123;&#32422;&#26463;&#38459;&#30861;&#20102;&#23427;&#20204;&#21442;&#19982;FL&#12290;&#25105;&#20204;&#25552;&#20986;Centaur&#65292;&#19968;&#20010;&#22810;&#23618;FL&#26694;&#26550;&#65292;&#20351;&#36229;&#38480;&#21046;&#30340;&#35774;&#22791;&#33021;&#22815;&#39640;&#25928;&#22320;&#21442;&#19982;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;FL&#12290;Centaur&#32467;&#21512;&#20102;&#20004;&#20010;&#20027;&#35201;&#30340;&#24819;&#27861;&#65306;&#65288;i&#65289;&#25968;&#25454;&#36873;&#25321;&#26041;&#26696;&#36873;&#25321;&#19968;&#37096;&#20998;&#26679;&#26412;&#21152;&#36895;&#23398;&#20064;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#19968;&#20010;&#22522;&#20110;&#20998;&#21306;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#25972;&#21512;&#21516;&#19968;&#29992;&#25143;&#25317;&#26377;&#30340;&#21463;&#38480;&#21644;&#24378;&#22823;&#35774;&#22791;&#12290;&#22312;&#22235;&#20010;&#22522;&#20934;&#31070;&#32463;&#32593;&#32476;&#21644;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#26174;&#31034;&#65292;Centaur&#30456;&#27604;&#20110;&#22312;&#21463;&#38480;&#35774;&#22791;&#19978;&#30340;&#26412;&#22320;&#35757;&#32451;&#65292;&#33021;&#22815;&#33719;&#24471;&#32422;10\%&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#24179;&#22343;&#33021;&#33410;&#32422;&#32422;58\%&#30340;&#33021;&#37327;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#20063;&#34920;&#26126;&#20102;Centaur&#22312;&#22788;&#29702;&#26102;&#30340;&#21331;&#36234;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.04175v3 Announce Type: replace  Abstract: Federated learning (FL) facilitates new applications at the edge, especially for wearable and Internet-of-Thing devices. Such devices capture a large and diverse amount of data, but they have memory, compute, power, and connectivity constraints which hinder their participation in FL. We propose Centaur, a multitier FL framework, enabling ultra-constrained devices to efficiently participate in FL on large neural nets. Centaur combines two major ideas: (i) a data selection scheme to choose a portion of samples that accelerates the learning, and (ii) a partition-based training algorithm that integrates both constrained and powerful devices owned by the same user. Evaluations, on four benchmark neural nets and three datasets, show that Centaur gains ~10\% higher accuracy than local training on constrained devices with ~58\% energy saving on average. Our experimental results also demonstrate the superior efficiency of Centaur when dealing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#38598;&#25104;&#30340;&#32852;&#37030;&#23398;&#20064;&#22312;&#25932;&#23545;&#23041;&#32961;&#19979;&#30340;&#28431;&#27934;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#25581;&#31034;&#20102;&#35813;&#27169;&#22411;&#22312;&#19981;&#21516;&#37197;&#32622;&#30340;&#32852;&#37030;&#23398;&#20064;&#19979;&#23545;&#25932;&#23545;&#23041;&#32961;&#30340;&#39640;&#25935;&#24863;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.10375</link><description>&lt;p&gt;
&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#38598;&#25104;&#30340;&#32852;&#37030;&#23398;&#20064;&#22312;&#25932;&#23545;&#23041;&#32961;&#19979;&#30340;&#28431;&#27934;
&lt;/p&gt;
&lt;p&gt;
Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats. (arXiv:2401.10375v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10375
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#38598;&#25104;&#30340;&#32852;&#37030;&#23398;&#20064;&#22312;&#25932;&#23545;&#23041;&#32961;&#19979;&#30340;&#28431;&#27934;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#25581;&#31034;&#20102;&#35813;&#27169;&#22411;&#22312;&#19981;&#21516;&#37197;&#32622;&#30340;&#32852;&#37030;&#23398;&#20064;&#19979;&#23545;&#25932;&#23545;&#23041;&#32961;&#30340;&#39640;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#35299;&#20915;&#19982;&#25968;&#25454;&#38544;&#31169;&#21644;&#23433;&#20840;&#30456;&#20851;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#35201;&#38382;&#39064;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#23384;&#22312;&#25968;&#25454;&#19981;&#36275;&#21644;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;&#22522;&#30784;&#27169;&#22411;&#30340;&#20986;&#29616;&#20026;&#29616;&#26377;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#30340;&#23616;&#38480;&#24615;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20363;&#22914;&#36890;&#36807;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#27169;&#22411;&#21021;&#22987;&#21270;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#20869;&#22312;&#23433;&#20840;&#24615;&#38382;&#39064;&#65292;&#23558;&#22522;&#30784;&#27169;&#22411;&#38598;&#25104;&#21040;&#32852;&#37030;&#23398;&#20064;&#20013;&#21487;&#33021;&#24341;&#20837;&#26032;&#30340;&#39118;&#38505;&#65292;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#23578;&#23646;&#26410;&#24320;&#21457;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#38598;&#25104;&#30340;&#32852;&#37030;&#23398;&#20064;&#22312;&#25932;&#23545;&#23041;&#32961;&#19979;&#30340;&#28431;&#27934;&#12290;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#38598;&#25104;&#30340;&#32852;&#37030;&#23398;&#20064;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#21033;&#29992;&#22522;&#30784;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#38382;&#39064;&#26469;&#30772;&#22351;&#32852;&#37030;&#23398;&#20064;&#23458;&#25143;&#31471;&#27169;&#22411;&#12290;&#36890;&#36807;&#22312;&#22270;&#20687;&#21644;&#25991;&#26412;&#39046;&#22495;&#20013;&#20351;&#29992;&#30693;&#21517;&#27169;&#22411;&#21644;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#38598;&#25104;&#30340;&#32852;&#37030;&#23398;&#20064;&#22312;&#19981;&#21516;&#37197;&#32622;&#30340;&#32852;&#37030;&#23398;&#20064;&#19979;&#23545;&#36825;&#31181;&#26032;&#23041;&#32961;&#30340;&#39640;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) addresses critical issues in machine learning related to data privacy and security, yet suffering from data insufficiency and imbalance under certain circumstances. The emergence of foundation models (FMs) offers potential solutions to the limitations of existing FL frameworks, e.g., by generating synthetic data for model initialization. However, due to the inherent safety concerns of FMs, integrating FMs into FL could introduce new risks, which remains largely unexplored. To address this gap, we conduct the first investigation on the vulnerability of FM integrated FL (FM-FL) under adversarial threats. Based on a unified framework of FM-FL, we introduce a novel attack strategy that exploits safety issues of FM to compromise FL client models. Through extensive experiments with well-known models and benchmark datasets in both image and text domains, we reveal the high susceptibility of the FM-FL to this new threat under various FL configurations. Furthermore, we f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#24515;&#29702;&#23398;&#24212;&#29992;&#20013;&#30340;&#21069;&#27839;&#65292;&#21253;&#25324;&#22914;&#20309;&#27169;&#25311;&#20154;&#31867;&#35748;&#30693;&#21644;&#34892;&#20026;&#12289;&#25552;&#20379;&#21019;&#26032;&#24037;&#20855;&#36827;&#34892;&#25991;&#29486;&#22238;&#39038;&#12289;&#20551;&#35774;&#29983;&#25104;&#12289;&#23454;&#39564;&#35774;&#35745;&#31561;&#12290;</title><link>http://arxiv.org/abs/2401.01519</link><description>&lt;p&gt;
&#25506;&#32034;LLMs&#22312;&#24515;&#29702;&#23398;&#24212;&#29992;&#20013;&#30340;&#21069;&#27839;&#65306;&#19968;&#20221;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review. (arXiv:2401.01519v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01519
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#24515;&#29702;&#23398;&#24212;&#29992;&#20013;&#30340;&#21069;&#27839;&#65292;&#21253;&#25324;&#22914;&#20309;&#27169;&#25311;&#20154;&#31867;&#35748;&#30693;&#21644;&#34892;&#20026;&#12289;&#25552;&#20379;&#21019;&#26032;&#24037;&#20855;&#36827;&#34892;&#25991;&#29486;&#22238;&#39038;&#12289;&#20551;&#35774;&#29983;&#25104;&#12289;&#23454;&#39564;&#35774;&#35745;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#24515;&#29702;&#23398;&#24212;&#29992;&#20013;&#30340;&#21069;&#27839;&#12290;&#24515;&#29702;&#23398;&#32463;&#21382;&#20102;&#20960;&#27425;&#29702;&#35770;&#21464;&#38761;&#65292;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65292;&#29305;&#21035;&#26159;LLMs&#30340;&#20351;&#29992;&#26377;&#26395;&#24320;&#21551;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#25105;&#20204;&#35814;&#32454;&#25506;&#35752;&#20102;LLMs&#22914;ChatGPT&#22312;&#24515;&#29702;&#23398;&#30740;&#31350;&#20013;&#30340;&#36716;&#21464;&#12290;&#25991;&#31456;&#35752;&#35770;&#20102;LLMs&#22312;&#35748;&#30693;&#19982;&#34892;&#20026;&#24515;&#29702;&#23398;&#12289;&#20020;&#24202;&#19982;&#21672;&#35810;&#24515;&#29702;&#23398;&#12289;&#25945;&#32946;&#19982;&#21457;&#23637;&#24515;&#29702;&#23398;&#20197;&#21450;&#31038;&#20250;&#19982;&#25991;&#21270;&#24515;&#29702;&#23398;&#31561;&#24515;&#29702;&#23398;&#20998;&#25903;&#20013;&#30340;&#24433;&#21709;&#65292;&#24378;&#35843;&#20102;&#23427;&#20204;&#27169;&#25311;&#20154;&#31867;&#35748;&#30693;&#21644;&#34892;&#20026;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#20123;&#27169;&#22411;&#27169;&#25311;&#20154;&#31867;&#25991;&#26412;&#29983;&#25104;&#30340;&#33021;&#21147;&#65292;&#20026;&#24515;&#29702;&#23398;&#20013;&#30340;&#25991;&#29486;&#22238;&#39038;&#12289;&#20551;&#35774;&#29983;&#25104;&#12289;&#23454;&#39564;&#35774;&#35745;&#12289;&#23454;&#39564;&#23545;&#35937;&#12289;&#25968;&#25454;&#20998;&#26512;&#12289;&#23398;&#26415;&#20889;&#20316;&#21644;&#21516;&#34892;&#35780;&#23457;&#31561;&#25552;&#20379;&#21019;&#26032;&#24037;&#20855;&#12290;&#34429;&#28982;LLMs&#22312;&#25512;&#21160;&#30740;&#31350;&#26041;&#27861;&#23398;&#26041;&#38754;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;
&lt;/p&gt;
&lt;p&gt;
This paper explores the frontiers of large language models (LLMs) in psychology applications. Psychology has undergone several theoretical changes, and the current use of Artificial Intelligence (AI) and Machine Learning, particularly LLMs, promises to open up new research directions. We provide a detailed exploration of how LLMs like ChatGPT are transforming psychological research. It discusses the impact of LLMs across various branches of psychology, including cognitive and behavioral, clinical and counseling, educational and developmental, and social and cultural psychology, highlighting their potential to simulate aspects of human cognition and behavior. The paper delves into the capabilities of these models to emulate human-like text generation, offering innovative tools for literature review, hypothesis generation, experimental design, experimental subjects, data analysis, academic writing, and peer review in psychology. While LLMs are essential in advancing research methodologie
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#35299;&#37322;&#24615;&#27880;&#24847;&#21147;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#35782;&#21035;&#36755;&#20837;&#25968;&#25454;&#30340;&#20851;&#38190;&#37096;&#20998;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.07800</link><description>&lt;p&gt;
&#35299;&#37322;&#24615;&#27880;&#24847;&#21147;&#29992;&#20110;&#23569;&#26679;&#26412;&#23398;&#20064;&#21450;&#20854;&#23427;&#39046;&#22495;
&lt;/p&gt;
&lt;p&gt;
Explainable Attention for Few-shot Learning and Beyond. (arXiv:2310.07800v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07800
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#35299;&#37322;&#24615;&#27880;&#24847;&#21147;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#35782;&#21035;&#36755;&#20837;&#25968;&#25454;&#30340;&#20851;&#38190;&#37096;&#20998;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#22686;&#24378;&#23398;&#20064;&#27169;&#22411;&#20013;&#26174;&#31034;&#20986;&#20102;&#26377;&#24076;&#26395;&#30340;&#28508;&#21147;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#35782;&#21035;&#36755;&#20837;&#25968;&#25454;&#20013;&#26174;&#33879;&#30340;&#37096;&#20998;&#26469;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#36825;&#22312;&#25968;&#25454;&#25910;&#38598;&#21644;&#26631;&#35760;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#65292;&#23548;&#33268;&#35757;&#32451;&#26679;&#26412;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#23588;&#20854;&#26377;&#20215;&#20540;&#12290;&#21463;&#20154;&#31867;&#35748;&#30693;&#36807;&#31243;&#21551;&#21457;&#65292;&#25105;&#20204;&#35748;&#20026;&#65292;&#22914;&#26524;&#23558;AI&#22522;&#32447;&#26292;&#38706;&#20110;&#21407;&#22987;&#25968;&#25454;&#30340;&#20851;&#38190;&#37096;&#20998;&#32780;&#19981;&#26159;&#25972;&#20010;&#36755;&#20837;&#25968;&#25454;&#38598;&#65292;&#31867;&#20284;&#20110;&#20154;&#31867;&#30340;&#24863;&#30693;&#65292;&#37027;&#20040;&#23427;&#30340;&#24615;&#33021;&#21487;&#33021;&#20250;&#26356;&#20934;&#30830;&#12289;&#26356;&#21487;&#38752;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#36825;&#20123;&#20449;&#24687;&#24615;&#25968;&#25454;&#37096;&#20998;&#30340;&#20219;&#21153;&#65292;&#21363;&#30828;&#27880;&#24847;&#21147;&#23547;&#25214;&#65292;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#22312;&#23569;&#37327;&#35757;&#32451;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#30340;&#30740;&#31350;&#24456;&#38590;&#25214;&#21040;&#36825;&#20123;&#20449;&#24687;&#24615;&#21306;&#22495;&#65292;&#21407;&#22240;&#26159;&#22823;&#37327;&#30340;&#35757;&#32451;&#21442;&#25968;&#26080;&#27861;&#20174;&#26377;&#38480;&#30340;&#26679;&#26412;&#20013;&#26377;&#25928;&#23398;&#20064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#30828;&#27880;&#24847;&#21147;&#23547;&#25214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention mechanisms have exhibited promising potential in enhancing learning models by identifying salient portions of input data. This is particularly valuable in scenarios where limited training samples are accessible due to challenges in data collection and labeling. Drawing inspiration from human recognition processes, we posit that an AI baseline's performance could be more accurate and dependable if it is exposed to essential segments of raw data rather than the entire input dataset, akin to human perception. However, the task of selecting these informative data segments, referred to as hard attention finding, presents a formidable challenge. In situations with few training samples, existing studies struggle to locate such informative regions due to the large number of training parameters that cannot be effectively learned from the available limited samples. In this study, we introduce a novel and practical framework for achieving explainable hard attention finding, specifically
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;WL&#27979;&#35797;&#22312;&#28857;&#20113;&#20013;&#30340;&#24212;&#29992;&#65292;&#32467;&#26524;&#21457;&#29616;&#19977;&#27425;&#36845;&#20195;&#30340;$(d-1)$-WL&#27979;&#35797;&#21487;&#20197;&#21306;&#20998;$d$&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#28857;&#20113;&#65292;&#19988;&#21482;&#38656;&#35201;&#19968;&#27425;&#36845;&#20195;&#30340;$d$-WL&#27979;&#35797;&#23601;&#21487;&#20197;&#36798;&#21040;&#23436;&#25972;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.12853</link><description>&lt;p&gt;
&#19977;&#27425;&#36845;&#20195;&#30340;$(1-d)$-WL&#27979;&#35797;&#21487;&#20197;&#21306;&#20998;$d$&#32500;&#28857;&#20113;&#30340;&#38750;&#31561;&#36317;&#21464;&#25442;. (arXiv:2303.12853v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Three iterations of $(1-d)$-WL test distinguish non isometric clouds of $d$-dimensional points. (arXiv:2303.12853v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;WL&#27979;&#35797;&#22312;&#28857;&#20113;&#20013;&#30340;&#24212;&#29992;&#65292;&#32467;&#26524;&#21457;&#29616;&#19977;&#27425;&#36845;&#20195;&#30340;$(d-1)$-WL&#27979;&#35797;&#21487;&#20197;&#21306;&#20998;$d$&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#28857;&#20113;&#65292;&#19988;&#21482;&#38656;&#35201;&#19968;&#27425;&#36845;&#20195;&#30340;$d$-WL&#27979;&#35797;&#23601;&#21487;&#20197;&#36798;&#21040;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Weisfeiler-Lehman (WL)&#27979;&#35797;&#26159;&#19968;&#20010;&#26816;&#26597;&#22270;&#21516;&#26500;&#30340;&#22522;&#26412;&#36845;&#20195;&#31639;&#27861;&#12290;&#23427;&#34987;&#35266;&#23519;&#21040;&#26159;&#20960;&#31181;&#22270;&#31070;&#32463;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#35774;&#35745;&#30340;&#22522;&#30784;&#65292;&#36825;&#20123;&#32593;&#32476;&#30340;&#33021;&#21147;&#21644;&#24615;&#33021;&#21487;&#20197;&#29992;&#36825;&#20010;&#27979;&#35797;&#30340;&#34920;&#31034;&#33021;&#21147;&#26469;&#29702;&#35299;&#12290;&#21463;&#26368;&#36817;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#28041;&#21450;&#19977;&#32500;&#29289;&#20307;&#30340;&#25968;&#25454;&#38598;&#30340;&#21457;&#23637;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;WL&#27979;&#35797;&#23545;&#23436;&#25972;&#30340;&#36317;&#31163;&#22270;&#34920;&#31034;&#30340;&#27431;&#20960;&#37324;&#24471;&#28857;&#20113;&#26159;&#8220;&#23436;&#25972;&#30340;&#8221;&#26102;&#65292;&#23427;&#20309;&#26102;&#33021;&#22815;&#35782;&#21035;&#20986;&#20219;&#24847;&#19968;&#20010;&#20219;&#24847;&#28857;&#20113;.&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#65292;$(d-1)$-&#32500;WL&#27979;&#35797;&#21487;&#20197;&#21306;&#20998;$d$&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#28857;&#20113;&#65292;&#20219;&#20309;$d\ge 2$&#37117;&#21487;&#20197;&#65292;&#32780;&#19988;&#21482;&#38656;&#35201;&#36827;&#34892;&#19977;&#27425;&#27979;&#35797;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;&#20110;$d=2,3$&#26159;&#32039;&#30340;&#12290;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;$d$&#32500;WL&#27979;&#35797;&#21482;&#38656;&#35201;&#36827;&#34892;&#19968;&#27425;&#36845;&#20195;&#23601;&#21487;&#20197;&#36798;&#21040;&#23436;&#25972;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Weisfeiler--Lehman (WL) test is a fundamental iterative algorithm for checking isomorphism of graphs. It has also been observed that it underlies the design of several graph neural network architectures, whose capabilities and performance can be understood in terms of the expressive power of this test. Motivated by recent developments in machine learning applications to datasets involving three-dimensional objects, we study when the WL test is {\em complete} for clouds of euclidean points represented by complete distance graphs, i.e., when it can distinguish, up to isometry, any arbitrary such cloud.  Our main result states that the $(d-1)$-dimensional WL test is complete for point clouds in $d$-dimensional Euclidean space, for any $d\ge 2$, and that only three iterations of the test suffice. Our result is tight for $d = 2, 3$. We also observe that the $d$-dimensional WL test only requires one iteration to achieve completeness.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22686;&#24378;&#30340;&#22522;&#20110;&#21160;&#37327;&#30340;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#26041;&#27861;&#65288;&#21363;MSGDA&#21644;AdaMSGDA&#65289;&#26469;&#35299;&#20915;&#38750;&#20984;-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#20013;AdaMSGDA&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#26469;&#26356;&#26032;&#21464;&#37327;$x$&#21644;$y$&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20840;&#23616;&#21644;&#22352;&#26631;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;MSGDA&#21644;AdaMSGDA&#26041;&#27861;&#22312;&#25214;&#21040;$\epsilon$-&#31283;&#23450;&#35299;&#26102;&#65292;&#21482;&#38656;&#35201;&#22312;&#27599;&#20010;&#24490;&#29615;&#20013;&#36827;&#34892;&#19968;&#27425;&#37319;&#26679;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#24050;&#30693;&#30340;&#26368;&#20339;&#26679;&#26412;&#65288;&#26799;&#24230;&#65289;&#22797;&#26434;&#24230;$O(\epsilon^{-3})$&#12290;</title><link>http://arxiv.org/abs/2303.03984</link><description>&lt;p&gt;
&#38750;&#20984;-PL&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#30340;&#22686;&#24378;&#33258;&#36866;&#24212;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Enhanced Adaptive Gradient Algorithms for Nonconvex-PL Minimax Optimization. (arXiv:2303.03984v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22686;&#24378;&#30340;&#22522;&#20110;&#21160;&#37327;&#30340;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#26041;&#27861;&#65288;&#21363;MSGDA&#21644;AdaMSGDA&#65289;&#26469;&#35299;&#20915;&#38750;&#20984;-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#20013;AdaMSGDA&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#26469;&#26356;&#26032;&#21464;&#37327;$x$&#21644;$y$&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20840;&#23616;&#21644;&#22352;&#26631;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;MSGDA&#21644;AdaMSGDA&#26041;&#27861;&#22312;&#25214;&#21040;$\epsilon$-&#31283;&#23450;&#35299;&#26102;&#65292;&#21482;&#38656;&#35201;&#22312;&#27599;&#20010;&#24490;&#29615;&#20013;&#36827;&#34892;&#19968;&#27425;&#37319;&#26679;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#24050;&#30693;&#30340;&#26368;&#20339;&#26679;&#26412;&#65288;&#26799;&#24230;&#65289;&#22797;&#26434;&#24230;$O(\epsilon^{-3})$&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a class of enhanced momentum-based gradient descent ascent methods (MSGDA and AdaMSGDA) to solve nonconvex-PL minimax problems, where the AdaMSGDA algorithm can use various adaptive learning rates to update variables x and y without relying on any global and coordinate-wise adaptive learning rates. Theoretical analysis shows that MSGDA and AdaMSGDA methods have the best known sample (gradient) complexity of O(&#949;&#8722;3) in finding an &#949;-stationary solution.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#38750;&#20984;&#38750;&#20985;&#30340;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#65288;&#21363;$\min_x\max_y f(x,y)$&#65289;&#65292;&#20854;&#20013;$f(x,y)$&#22312;$x$&#19978;&#21487;&#33021;&#26159;&#38750;&#20984;&#30340;&#65292;&#22312;$y$&#19978;&#26159;&#38750;&#20985;&#30340;&#65292;&#24182;&#28385;&#36275;Polyak-Lojasiewicz&#65288;PL&#65289;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#22686;&#24378;&#30340;&#22522;&#20110;&#21160;&#37327;&#30340;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#26041;&#27861;&#65288;&#21363;MSGDA&#21644;AdaMSGDA&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38543;&#26426;&#38750;&#20984;-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;AdaMSGDA&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#26469;&#26356;&#26032;&#21464;&#37327;$x$&#21644;$y$&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20840;&#23616;&#21644;&#22352;&#26631;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#25910;&#25947;&#20998;&#26512;&#26694;&#26550;&#26469;&#35299;&#20915;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;MSGDA&#21644;AdaMSGDA&#26041;&#27861;&#22312;&#25214;&#21040;$\epsilon$-&#31283;&#23450;&#35299;&#65288;&#21363;$\mathbb{E}\|\nabla F(x)\|\leq \epsilon$&#65292;&#20854;&#20013;$F(x)=\max_y f(x,y)$&#65289;&#26102;&#65292;&#21482;&#38656;&#35201;&#22312;&#27599;&#20010;&#24490;&#29615;&#20013;&#36827;&#34892;&#19968;&#27425;&#37319;&#26679;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#24050;&#30693;&#30340;&#26368;&#20339;&#26679;&#26412;&#65288;&#26799;&#24230;&#65289;&#22797;&#26434;&#24230;$O(\epsilon^{-3})$&#12290;
&lt;/p&gt;
&lt;p&gt;
In the paper, we study a class of nonconvex nonconcave minimax optimization problems (i.e., $\min_x\max_y f(x,y)$), where $f(x,y)$ is possible nonconvex in $x$, and it is nonconcave and satisfies the Polyak-Lojasiewicz (PL) condition in $y$. Moreover, we propose a class of enhanced momentum-based gradient descent ascent methods (i.e., MSGDA and AdaMSGDA) to solve these stochastic Nonconvex-PL minimax problems. In particular, our AdaMSGDA algorithm can use various adaptive learning rates in updating the variables $x$ and $y$ without relying on any global and coordinate-wise adaptive learning rates. Theoretically, we present an effective convergence analysis framework for our methods. Specifically, we prove that our MSGDA and AdaMSGDA methods have the best known sample (gradient) complexity of $O(\epsilon^{-3})$ only requiring one sample at each loop in finding an $\epsilon$-stationary solution (i.e., $\mathbb{E}\|\nabla F(x)\|\leq \epsilon$, where $F(x)=\max_y f(x,y)$). This manuscript 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20351;&#24471;&#36229;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#24674;&#22797;&#21040;&#32447;&#24615;&#65292;&#24182;&#22312;&#20445;&#35777;&#20840;&#23616;&#26368;&#20248;&#24615;&#35777;&#26126;&#26377;&#25928;&#30340;&#21516;&#26102;&#20445;&#25345;&#20302;&#24265;&#30340;&#35745;&#31639;&#20195;&#20215;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#24378;&#20984;&#30340;&#20195;&#20215;&#20989;&#25968; $\phi$&#12290;</title><link>http://arxiv.org/abs/2206.03345</link><description>&lt;p&gt;
&#38024;&#23545;&#36229;&#21442;&#25968;&#21270;&#30340;&#38750;&#20984;Burer-Monteiro&#20998;&#35299;&#30340;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#19982;&#20840;&#23616;&#26368;&#20248;&#24615;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification. (arXiv:2206.03345v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20351;&#24471;&#36229;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#24674;&#22797;&#21040;&#32447;&#24615;&#65292;&#24182;&#22312;&#20445;&#35777;&#20840;&#23616;&#26368;&#20248;&#24615;&#35777;&#26126;&#26377;&#25928;&#30340;&#21516;&#26102;&#20445;&#25345;&#20302;&#24265;&#30340;&#35745;&#31639;&#20195;&#20215;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#24378;&#20984;&#30340;&#20195;&#20215;&#20989;&#25968; $\phi$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#38750;&#20984;&#20989;&#25968;$f(X)=\phi(XX^{T})$&#30340;&#26041;&#27861;&#65292;&#20854;&#20013; $\phi$&#26159;&#19968;&#20010;&#24179;&#28369;&#20984;&#30340;$n\times n$&#30697;&#38453;&#19978;&#19979;&#25991;&#30340;&#20195;&#20215;&#20989;&#25968;&#12290;&#34429;&#28982;&#20165;&#26377;&#20108;&#38454;&#20572;&#30041;&#28857;&#21487;&#20197;&#22312;&#21512;&#29702;&#26102;&#38388;&#20869;&#34987;&#35777;&#26126;&#25214;&#21040;&#65292;&#20294;&#22914;&#26524; $X$ &#30340;&#31209;&#32570;&#22833;&#65292;&#37027;&#20040;&#23427;&#30340;&#31209;&#32570;&#22833;&#23558;&#35777;&#26126;&#23427;&#26159;&#20840;&#23616;&#26368;&#20248;&#30340;&#12290;&#36825;&#31181;&#35748;&#35777;&#20840;&#23616;&#26368;&#20248;&#24615;&#30340;&#26041;&#27861;&#24517;&#28982;&#38656;&#35201;&#24403;&#21069;&#36845;&#20195;$X$&#30340;&#25628;&#32034;&#31209; $r$ &#36229;&#36807;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;$X^{\star}$ &#30340;&#31209;$r^{\star}$&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36229;&#21442;&#25968;&#21270;&#26174;&#33879;&#20943;&#24930;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20174; $r=r^{\star}$ &#26102;&#30340;&#32447;&#24615;&#36895;&#24230;&#38477;&#20026; $r&gt;r^{\star}$ &#26102;&#30340;&#20122;&#32447;&#24615;&#36895;&#24230;&#65292;&#21363;&#20351; $\phi$ &#26159;&#24378;&#20984;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24265;&#20215;&#30340;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23558;&#36229;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#24674;&#22797;&#21040;&#32447;&#24615;&#65292;&#21516;&#26102;&#20445;&#35777;&#20840;&#23616;&#26368;&#20248;&#24615;&#35777;&#26126;&#20381;&#26087;&#26377;&#25928;&#12290;&#36825;&#31181;&#26041;&#27861;&#21482;&#38656;&#35201;&#36827;&#34892;&#31616;&#21333;&#30340;&#30697;&#38453;&#20056;&#27861;&#21644;&#27714;&#36870;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#24378;&#20984;&#30340;$&#966;$&#12290;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#23454;&#39564;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#29616;&#23454;&#24212;&#29992;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider using gradient descent to minimize the nonconvex function $f(X)=\phi(XX^{T})$ over an $n\times r$ factor matrix $X$, in which $\phi$ is an underlying smooth convex cost function defined over $n\times n$ matrices. While only a second-order stationary point $X$ can be provably found in reasonable time, if $X$ is additionally rank deficient, then its rank deficiency certifies it as being globally optimal. This way of certifying global optimality necessarily requires the search rank $r$ of the current iterate $X$ to be overparameterized with respect to the rank $r^{\star}$ of the global minimizer $X^{\star}$. Unfortunately, overparameterization significantly slows down the convergence of gradient descent, from a linear rate with $r=r^{\star}$ to a sublinear rate when $r&gt;r^{\star}$, even when $\phi$ is strongly convex. In this paper, we propose an inexpensive preconditioner that restores the convergence rate of gradient descent back to linear in the overparameterized case, while
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2111.10275</link><description>&lt;p&gt;
&#24102;&#26377;&#26680;&#30340;&#22797;&#21512;&#36866;&#21512;&#24615;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Composite Goodness-of-fit Tests with Kernels. (arXiv:2111.10275v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.10275
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#38169;&#35823;&#35828;&#26126;&#21487;&#33021;&#20250;&#23545;&#27010;&#29575;&#27169;&#22411;&#30340;&#23454;&#29616;&#36896;&#25104;&#37325;&#22823;&#25361;&#25112;&#65292;&#36825;&#20419;&#20351;&#24320;&#21457;&#20986;&#19968;&#20123;&#30452;&#25509;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#40065;&#26834;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#26356;&#20026;&#22797;&#26434;&#30340;&#26041;&#27861;&#26159;&#21542;&#38656;&#35201;&#21462;&#20915;&#20110;&#27169;&#22411;&#26159;&#21542;&#30495;&#30340;&#38169;&#35823;&#65292;&#30446;&#21069;&#32570;&#20047;&#36890;&#29992;&#30340;&#26041;&#27861;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#21363;&#25105;&#20204;&#26159;&#21542;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#26469;&#33258;&#26576;&#20123;&#21442;&#25968;&#27169;&#22411;&#26063;&#20013;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#21033;&#29992;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#21644;&#26680;Stein&#24046;&#24322;&#30340;&#26368;&#23567;&#36317;&#31163;&#20272;&#35745;&#22120;&#12290;&#23427;&#20204;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#21253;&#25324;&#24403;&#21442;&#25968;&#27169;&#22411;&#30340;&#23494;&#24230;&#24050;&#30693;&#38500;&#26631;&#20934;&#21270;&#24120;&#25968;&#22806;&#65292;&#25110;&#32773;&#22914;&#26524;&#27169;&#22411;&#37319;&#29992;&#27169;&#25311;&#22120;&#24418;&#24335;&#12290;&#20316;&#20026;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#33021;&#22815;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24314;&#31435;&#25105;&#20204;&#26041;&#27861;&#26377;&#25928;&#24615;&#30340;&#29702;&#35770;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#21644;&#24322;&#24120;&#26816;&#27979;&#24212;&#29992;&#26696;&#20363;&#28436;&#31034;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model misspecification can create significant challenges for the implementation of probabilistic models, and this has led to development of a range of robust methods which directly account for this issue. However, whether these more involved methods are required will depend on whether the model is really misspecified, and there is a lack of generally applicable methods to answer this question. In this paper, we propose one such method. More precisely, we propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on the maximum mean discrepancy and the kernel Stein discrepancy. They are widely applicable, including whenever the density of the parametric model is known up to normalisation constant, or if the model takes the form of a simulator. As our main result, we show that we are able to estimate the param
&lt;/p&gt;</description></item></channel></rss>