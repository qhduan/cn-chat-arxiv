<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#25105;&#20204;&#35777;&#26126;&#20102;&#21518;&#39564;&#25277;&#26679;&#22312;&#35745;&#31639;&#19978;&#26159;&#38590;&#20197;&#35299;&#20915;&#30340;&#65306;&#22312;&#21152;&#23494;&#23398;&#20013;&#26368;&#22522;&#26412;&#30340;&#20551;&#35774;&#19979;&#8212;&#8212;&#21333;&#21521;&#20989;&#25968;&#23384;&#22312;&#30340;&#20551;&#35774;&#19979;&#65292;&#23384;&#22312;&#19968;&#20123;&#23454;&#20363;&#65292;&#23545;&#20110;&#36825;&#20123;&#23454;&#20363;&#65292;&#27599;&#20010;&#31639;&#27861;&#37117;&#38656;&#35201;&#36229;&#22810;&#39033;&#24335;&#26102;&#38388;&#65292;&#21363;&#20351;&#26080;&#26465;&#20214;&#25277;&#26679;&#21487;&#20197;&#35777;&#26126;&#26159;&#24555;&#36895;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.12727</link><description>&lt;p&gt;
&#25193;&#25955;&#21518;&#39564;&#25277;&#26679;&#22312;&#35745;&#31639;&#19978;&#26159;&#38590;&#20197;&#35299;&#20915;&#30340;
&lt;/p&gt;
&lt;p&gt;
Diffusion Posterior Sampling is Computationally Intractable
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12727
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#21518;&#39564;&#25277;&#26679;&#22312;&#35745;&#31639;&#19978;&#26159;&#38590;&#20197;&#35299;&#20915;&#30340;&#65306;&#22312;&#21152;&#23494;&#23398;&#20013;&#26368;&#22522;&#26412;&#30340;&#20551;&#35774;&#19979;&#8212;&#8212;&#21333;&#21521;&#20989;&#25968;&#23384;&#22312;&#30340;&#20551;&#35774;&#19979;&#65292;&#23384;&#22312;&#19968;&#20123;&#23454;&#20363;&#65292;&#23545;&#20110;&#36825;&#20123;&#23454;&#20363;&#65292;&#27599;&#20010;&#31639;&#27861;&#37117;&#38656;&#35201;&#36229;&#22810;&#39033;&#24335;&#26102;&#38388;&#65292;&#21363;&#20351;&#26080;&#26465;&#20214;&#25277;&#26679;&#21487;&#20197;&#35777;&#26126;&#26159;&#24555;&#36895;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#23398;&#20064;&#21644;&#20174;&#20998;&#24067;$p(x)$&#20013;&#25277;&#26679;&#30340;&#19968;&#31181;&#38750;&#24120;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;&#22312;&#21518;&#39564;&#25277;&#26679;&#20013;&#65292;&#20154;&#20204;&#36824;&#20250;&#32473;&#20986;&#19968;&#20010;&#27979;&#37327;&#27169;&#22411;$p(y \mid x)$&#21644;&#19968;&#20010;&#27979;&#37327;$y$&#65292;&#24076;&#26395;&#20174;$p(x \mid y)$&#20013;&#25277;&#26679;&#12290;&#21518;&#39564;&#25277;&#26679;&#23545;&#20110;&#35832;&#22914;&#20462;&#34917;&#12289;&#36229;&#20998;&#36776;&#29575;&#21644;MRI&#37325;&#24314;&#31561;&#20219;&#21153;&#38750;&#24120;&#26377;&#29992;&#65292;&#22240;&#27492;&#19968;&#20123;&#26368;&#36817;&#30340;&#24037;&#20316;&#24050;&#32463;&#32473;&#20986;&#20102;&#21551;&#21457;&#24335;&#36817;&#20284;&#31639;&#27861;&#65307;&#20294;&#27809;&#26377;&#19968;&#20010;&#24050;&#30693;&#33021;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#25910;&#25947;&#21040;&#27491;&#30830;&#30340;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12727v1 Announce Type: cross  Abstract: Diffusion models are a remarkably effective way of learning and sampling from a distribution $p(x)$. In posterior sampling, one is also given a measurement model $p(y \mid x)$ and a measurement $y$, and would like to sample from $p(x \mid y)$. Posterior sampling is useful for tasks such as inpainting, super-resolution, and MRI reconstruction, so a number of recent works have given algorithms to heuristically approximate it; but none are known to converge to the correct distribution in polynomial time.   In this paper we show that posterior sampling is \emph{computationally intractable}: under the most basic assumption in cryptography -- that one-way functions exist -- there are instances for which \emph{every} algorithm takes superpolynomial time, even though \emph{unconditional} sampling is provably fast. We also show that the exponential-time rejection sampling algorithm is essentially optimal under the stronger plausible assumption 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24182;&#34892;&#22823;&#35268;&#27169;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#30340;&#32858;&#31867;&#21450;&#24449;&#26381;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#30456;&#20851;&#20449;&#24687;&#36827;&#34892;&#32858;&#31867;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#22312;&#22823;&#35268;&#27169;AI&#24212;&#29992;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.02196</link><description>&lt;p&gt;
&#24182;&#34892;&#22823;&#35268;&#27169;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#30340;&#26679;&#26412;&#39640;&#25928;&#32858;&#31867;&#21450;&#24449;&#26381;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample-Efficient Clustering and Conquer Procedures for Parallel Large-Scale Ranking and Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02196
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24182;&#34892;&#22823;&#35268;&#27169;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#30340;&#32858;&#31867;&#21450;&#24449;&#26381;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#30456;&#20851;&#20449;&#24687;&#36827;&#34892;&#32858;&#31867;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#22312;&#22823;&#35268;&#27169;AI&#24212;&#29992;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;"&#32858;&#31867;&#21644;&#24449;&#26381;"&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24182;&#34892;&#22823;&#35268;&#27169;&#25490;&#24207;&#21644;&#36873;&#25321;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#30456;&#20851;&#20449;&#24687;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#25171;&#30772;&#26679;&#26412;&#25928;&#29575;&#30340;&#29942;&#39048;&#12290;&#22312;&#24182;&#34892;&#35745;&#31639;&#29615;&#22659;&#20013;&#65292;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#32858;&#31867;&#21487;&#20197;&#23454;&#29616;O(p)&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20943;&#23569;&#36895;&#24230;&#65292;&#36825;&#26159;&#29702;&#35770;&#19978;&#21487;&#36798;&#21040;&#30340;&#26368;&#20339;&#20943;&#23569;&#36895;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#26159;&#36890;&#29992;&#30340;&#65292;&#22312;&#22266;&#23450;&#39044;&#31639;&#21644;&#22266;&#23450;&#31934;&#24230;&#30340;&#33539;&#24335;&#19979;&#65292;&#21487;&#20197;&#26080;&#32541;&#38598;&#25104;&#21508;&#31181;&#24120;&#35265;&#30340;&#25490;&#24207;&#21644;&#36873;&#25321;&#26041;&#27861;&#12290;&#23427;&#21487;&#20197;&#22312;&#26080;&#38656;&#39640;&#31934;&#30830;&#24230;&#30456;&#20851;&#20272;&#35745;&#21644;&#31934;&#30830;&#32858;&#31867;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#25913;&#36827;&#12290;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#20013;&#65292;&#22914;&#31070;&#32463;&#32467;&#26500;&#25628;&#32034;&#65292;&#25105;&#20204;&#30340;&#26080;&#31579;&#36873;&#29256;&#26412;&#30340;&#26041;&#27861;&#24778;&#20154;&#22320;&#36229;&#36807;&#20102;&#23436;&#20840;&#39034;&#24207;&#21270;&#30340;&#22522;&#20934;&#65292;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;&#36825;&#34920;&#26126;&#21033;&#29992;&#26377;&#20215;&#20540;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#22914;&#30456;&#20851;&#24615;&#65292;&#26159;&#32469;&#36807;&#20256;&#32479;&#26041;&#27861;&#30340;&#19968;&#26465;&#21487;&#34892;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose novel "clustering and conquer" procedures for the parallel large-scale ranking and selection (R&amp;S) problem, which leverage correlation information for clustering to break the bottleneck of sample efficiency. In parallel computing environments, correlation-based clustering can achieve an $\mathcal{O}(p)$ sample complexity reduction rate, which is the optimal reduction rate theoretically attainable. Our proposed framework is versatile, allowing for seamless integration of various prevalent R&amp;S methods under both fixed-budget and fixed-precision paradigms. It can achieve improvements without the necessity of highly accurate correlation estimation and precise clustering. In large-scale AI applications such as neural architecture search, a screening-free version of our procedure surprisingly surpasses fully-sequential benchmarks in terms of sample efficiency. This suggests that leveraging valuable structural information, such as correlation, is a viable path to bypassing the trad
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#30740;&#31350;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21463;&#22810;&#31181;&#22240;&#32032;&#24433;&#21709;&#65292;&#21442;&#25968;&#25968;&#37327;&#26356;&#22810;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#23485;&#30340;&#32593;&#32476;&#65292;&#32780;&#26679;&#26412;&#28857;&#25968;&#37327;&#21644;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#26356;&#39640;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#28145;&#30340;&#32593;&#32476;&#12290;</title><link>https://arxiv.org/abs/2402.00152</link><description>&lt;p&gt;
&#26356;&#28145;&#36824;&#26159;&#26356;&#23485;: &#20174;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#35282;&#24230;&#30475;
&lt;/p&gt;
&lt;p&gt;
Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00152
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#30740;&#31350;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21463;&#22810;&#31181;&#22240;&#32032;&#24433;&#21709;&#65292;&#21442;&#25968;&#25968;&#37327;&#26356;&#22810;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#23485;&#30340;&#32593;&#32476;&#65292;&#32780;&#26679;&#26412;&#28857;&#25968;&#37327;&#21644;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#26356;&#39640;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#28145;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#26159;&#26426;&#22120;&#23398;&#20064;&#30028;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#36861;&#27714;&#65292;&#21040;&#24213;&#26159;&#26356;&#28145;&#36824;&#26159;&#26356;&#23485;&#19968;&#30452;&#26159;&#19968;&#20010;&#25345;&#32493;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;DeNNs&#65289;&#21644;&#20855;&#26377;&#26377;&#38480;&#38544;&#34255;&#23618;&#30340;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;WeNNs&#65289;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#27604;&#36739;&#12290;&#36890;&#36807;&#20998;&#26512;&#30740;&#31350;&#21457;&#29616;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21487;&#20197;&#21463;&#21040;&#22810;&#31181;&#22240;&#32032;&#30340;&#26174;&#33879;&#24433;&#21709;&#65292;&#21253;&#25324;&#26679;&#26412;&#28857;&#30340;&#25968;&#37327;&#65292;&#31070;&#32463;&#32593;&#32476;&#20869;&#30340;&#21442;&#25968;&#20197;&#21450;&#25439;&#22833;&#20989;&#25968;&#30340;&#35268;&#21017;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26356;&#22810;&#30340;&#21442;&#25968;&#20542;&#21521;&#20110;&#36873;&#25321;WeNNs&#65292;&#32780;&#26356;&#22810;&#30340;&#26679;&#26412;&#28857;&#21644;&#26356;&#39640;&#30340;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#20542;&#21521;&#20110;&#36873;&#25321;DeNNs&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#29702;&#35770;&#24212;&#29992;&#20110;&#20351;&#29992;&#28145;&#24230;Ritz&#21644;&#29289;&#29702;&#24863;&#30693;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#26041;&#27861;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constructing the architecture of a neural network is a challenging pursuit for the machine learning community, and the dilemma of whether to go deeper or wider remains a persistent question. This paper explores a comparison between deeper neural networks (DeNNs) with a flexible number of layers and wider neural networks (WeNNs) with limited hidden layers, focusing on their optimal generalization error in Sobolev losses. Analytical investigations reveal that the architecture of a neural network can be significantly influenced by various factors, including the number of sample points, parameters within the neural networks, and the regularity of the loss function. Specifically, a higher number of parameters tends to favor WeNNs, while an increased number of sample points and greater regularity in the loss function lean towards the adoption of DeNNs. We ultimately apply this theory to address partial differential equations using deep Ritz and physics-informed neural network (PINN) methods,
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;GPU&#38598;&#32676;&#35843;&#24230;&#22120;&#65292;&#29992;&#20110;&#20998;&#24067;&#24335;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#65292;&#26681;&#25454;&#20219;&#21153;&#23545;&#36890;&#20449;&#32593;&#32476;&#24310;&#36831;&#30340;&#25935;&#24863;&#24615;&#36827;&#34892;GPU&#36164;&#28304;&#30340;&#37051;&#36817;&#22522;&#30784;&#19968;&#33268;&#24615;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#35843;&#24230;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#35843;&#24230;&#22120;&#21487;&#20197;&#25552;&#20379;&#39640;&#36798;69&#65285;&#30340;&#31471;&#21040;&#31471;Makespan&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2401.16492</link><description>&lt;p&gt;
GPU&#38598;&#32676;&#35843;&#24230;&#23545;&#32593;&#32476;&#25935;&#24863;&#30340;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
GPU Cluster Scheduling for Network-Sensitive Deep Learning. (arXiv:2401.16492v1 [cs.PF])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16492
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;GPU&#38598;&#32676;&#35843;&#24230;&#22120;&#65292;&#29992;&#20110;&#20998;&#24067;&#24335;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#65292;&#26681;&#25454;&#20219;&#21153;&#23545;&#36890;&#20449;&#32593;&#32476;&#24310;&#36831;&#30340;&#25935;&#24863;&#24615;&#36827;&#34892;GPU&#36164;&#28304;&#30340;&#37051;&#36817;&#22522;&#30784;&#19968;&#33268;&#24615;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#35843;&#24230;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#35843;&#24230;&#22120;&#21487;&#20197;&#25552;&#20379;&#39640;&#36798;69&#65285;&#30340;&#31471;&#21040;&#31471;Makespan&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;GPU&#38598;&#32676;&#35843;&#24230;&#22120;&#65292;&#29992;&#20110;&#20998;&#24067;&#24335;DL&#65288;DDL&#65289;&#24037;&#20316;&#36127;&#36733;&#65292;&#20197;&#22522;&#20110;DDL&#20316;&#19994;&#23545;&#39044;&#26399;&#36890;&#20449;&#32593;&#32476;&#24310;&#36831;&#30340;&#25935;&#24863;&#24615;&#36827;&#34892;GPU&#36164;&#28304;&#30340;&#37051;&#36817;&#22522;&#30784;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30340;&#35843;&#24230;&#22120;&#30001;&#19977;&#20010;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#32452;&#25104;&#65306;&#65288;i&#65289;&#19968;&#20010;&#32463;&#20856;&#30340;&#24310;&#36831;&#35843;&#24230;&#31639;&#27861;&#65292;&#29992;&#20110;&#20419;&#36827;&#20316;&#19994;&#25918;&#32622;&#21644;&#19968;&#33268;&#24615;&#65307;&#65288;ii&#65289;&#19968;&#20010;&#23545;&#32593;&#32476;&#25935;&#24863;&#30340;&#20316;&#19994;&#25250;&#21344;&#31574;&#30053;&#65307;&#21644;&#65288;iii&#65289;&#19968;&#31181;&#8220;&#33258;&#21160;&#35843;&#25972;&#22120;&#8221;&#26426;&#21046;&#65292;&#29992;&#20110;&#20248;&#21270;&#24310;&#36831;&#35745;&#26102;&#22120;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#24310;&#36831;&#35843;&#24230;&#12290;&#21478;&#22806;&#65292;&#20026;&#20102;&#23454;&#29616;&#22823;&#35268;&#27169;&#23454;&#39564;&#30340;&#25104;&#26412;&#25928;&#30410;&#26041;&#27861;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;DDL&#38598;&#32676;&#20223;&#30495;&#24179;&#21488;&#12290;&#36890;&#36807;&#20351;&#29992;&#20223;&#30495;&#24179;&#21488;&#65292;&#25105;&#20204;&#22312;&#23454;&#38469;&#24037;&#20316;&#36127;&#36733;&#36319;&#36394;&#20013;&#19982;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#26367;&#20195;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#20197;&#23637;&#31034;&#25105;&#20204;&#35774;&#35745;&#30340;&#20248;&#21183;&#12290;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#19968;&#33268;&#24615;&#35843;&#24230;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#35843;&#24230;&#22120;&#21487;&#20197;&#25552;&#20379;&#39640;&#36798;69&#65285;&#30340;&#31471;&#21040;&#31471;Makespan&#25552;&#21319;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#24179;&#22343;j
&lt;/p&gt;
&lt;p&gt;
We propose a novel GPU-cluster scheduler for distributed DL (DDL) workloads that enables proximity based consolidation of GPU resources based on the DDL jobs' sensitivities to the anticipated communication-network delays. Our scheduler consists of three major components: (i) a classical delay scheduling algorithm to facilitate job placement and consolidation; (ii) a network-sensitive job preemption strategy; and (iii) an "auto-tuner" mechanism to optimize delay timers for effective delay scheduling. Additionally, to enable a cost-effective methodology for large-scale experiments, we develop a data-driven DDL cluster simulation platform. Employing the simulation platform we compare against several state-of-the-art alternatives on real-world workload traces to demonstrate the benefits of our design. Our scheduler can provide improvement of up to 69% in end-to-end Makespan for training all jobs compared to the prevailing consolidation-based scheduling methods, while reducing the average j
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;CDVAE&#65289;&#26469;&#35299;&#20915;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#21644;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#26469;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;</title><link>http://arxiv.org/abs/2310.10559</link><description>&lt;p&gt;
&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Causal Dynamic Variational Autoencoder for Counterfactual Regression in Longitudinal Data. (arXiv:2310.10559v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10559
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;CDVAE&#65289;&#26469;&#35299;&#20915;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#21644;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#26469;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24456;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#22914;&#31934;&#20934;&#21307;&#23398;&#12289;&#27969;&#34892;&#30149;&#23398;&#12289;&#32463;&#27982;&#21644;&#24066;&#22330;&#33829;&#38144;&#20013;&#65292;&#20272;&#35745;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#26159;&#30456;&#20851;&#30340;&#12290;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#35201;&#20040;&#20551;&#35774;&#20102;&#25152;&#26377;&#28151;&#26434;&#21464;&#37327;&#30340;&#35266;&#27979;&#32467;&#26524;&#65292;&#35201;&#20040;&#35797;&#22270;&#25512;&#26029;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21464;&#37327;&#12290;&#25105;&#20204;&#37319;&#21462;&#20102;&#19981;&#21516;&#30340;&#35266;&#28857;&#65292;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#21363;&#20165;&#24433;&#21709;&#32467;&#26524;&#24207;&#21015;&#30340;&#35843;&#25972;&#21464;&#37327;&#12290;&#22312;&#26080;&#28151;&#26434;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20197;&#26410;&#35266;&#27979;&#21040;&#30340;&#39118;&#38505;&#22240;&#32032;&#23548;&#33268;&#30340;&#27835;&#30103;&#21453;&#24212;&#20013;&#30340;&#26410;&#30693;&#24322;&#36136;&#24615;&#20026;&#30446;&#26631;&#65292;&#20272;&#35745;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE&#65289;&#12290;&#25105;&#20204;&#24212;&#23545;&#20102;&#26102;&#21464;&#25928;&#24212;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;&#22312;&#23398;&#20064;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#30340;&#26377;&#25928;&#24615;&#21644;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33324;&#21270;&#30028;&#38480;&#30340;&#29702;&#35770;&#32467;&#26524;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22240;&#26524;DVAE&#65288;CDVAE&#65289;&#12290;&#35813;&#27169;&#22411;&#23558;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#19982;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating treatment effects over time is relevant in many real-world applications, such as precision medicine, epidemiology, economy, and marketing. Many state-of-the-art methods either assume the observations of all confounders or seek to infer the unobserved ones. We take a different perspective by assuming unobserved risk factors, i.e., adjustment variables that affect only the sequence of outcomes. Under unconfoundedness, we target the Individual Treatment Effect (ITE) estimation with unobserved heterogeneity in the treatment response due to missing risk factors. We address the challenges posed by time-varying effects and unobserved adjustment variables. Led by theoretical results over the validity of the learned adjustment variables and generalization bounds over the treatment effect, we devise Causal DVAE (CDVAE). This model combines a Dynamic Variational Autoencoder (DVAE) framework with a weighting strategy using propensity scores to estimate counterfactual responses. The CDVA
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#22312;&#20998;&#24067;&#23618;&#38754;&#19978;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#27745;&#26579;&#27169;&#22411;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#20998;&#26512;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#36125;&#21494;&#26031;&#39118;&#38505;&#30340;&#21464;&#21270;&#23637;&#31034;&#20102;&#36825;&#20123;&#27745;&#26579;&#23545;&#26631;&#20934;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#36827;&#19968;&#27493;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#21521;&#21644;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2307.08643</link><description>&lt;p&gt;
&#19968;&#20010;&#23398;&#20064;&#21463;&#21040;&#27745;&#26579;&#30340;&#36890;&#29992;&#26694;&#26550;&#65306;&#26631;&#31614;&#22122;&#22768;&#12289;&#23646;&#24615;&#22122;&#22768;&#31561;&#31561;
&lt;/p&gt;
&lt;p&gt;
A General Framework for Learning under Corruption: Label Noise, Attribute Noise, and Beyond. (arXiv:2307.08643v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08643
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#22312;&#20998;&#24067;&#23618;&#38754;&#19978;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#27745;&#26579;&#27169;&#22411;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#20998;&#26512;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#36125;&#21494;&#26031;&#39118;&#38505;&#30340;&#21464;&#21270;&#23637;&#31034;&#20102;&#36825;&#20123;&#27745;&#26579;&#23545;&#26631;&#20934;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#36827;&#19968;&#27493;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#21521;&#21644;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#30340;&#27745;&#26579;&#29616;&#35937;&#24456;&#24120;&#35265;&#65292;&#24182;&#19988;&#24050;&#32463;&#22312;&#19981;&#21516;&#30340;&#27745;&#26579;&#27169;&#22411;&#19979;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#28982;&#20102;&#35299;&#26377;&#38480;&#65292;&#32570;&#20047;&#23545;&#27745;&#26579;&#21450;&#20854;&#23545;&#23398;&#20064;&#30340;&#24433;&#21709;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#26680;&#30340;&#19968;&#33324;&#24615;&#21644;&#35814;&#23613;&#30340;&#26694;&#26550;&#65292;&#22312;&#20998;&#24067;&#23618;&#38754;&#19978;&#27491;&#24335;&#20998;&#26512;&#20102;&#27745;&#26579;&#27169;&#22411;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#26631;&#31614;&#21644;&#23646;&#24615;&#19978;&#23384;&#22312;&#30340;&#22797;&#26434;&#32852;&#21512;&#21644;&#20381;&#36182;&#24615;&#27745;&#26579;&#65292;&#36825;&#22312;&#29616;&#26377;&#30740;&#31350;&#20013;&#24456;&#23569;&#35302;&#21450;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#36125;&#21494;&#26031;&#39118;&#38505;&#21464;&#21270;&#26469;&#23637;&#31034;&#36825;&#20123;&#27745;&#26579;&#22914;&#20309;&#24433;&#21709;&#26631;&#20934;&#30340;&#30417;&#30563;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25552;&#20379;&#20102;&#23545;&#20110;&#8220;&#26356;&#22797;&#26434;&#8221;&#27745;&#26579;&#23545;&#23398;&#20064;&#38382;&#39064;&#24433;&#21709;&#30340;&#23450;&#24615;&#27934;&#23519;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#23450;&#37327;&#27604;&#36739;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;&#35813;&#26694;&#26550;&#30340;&#24212;&#29992;&#21253;&#25324;&#27745;&#26579;&#26657;&#27491;&#23398;&#20064;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#20010;&#23376;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Corruption is frequently observed in collected data and has been extensively studied in machine learning under different corruption models. Despite this, there remains a limited understanding of how these models relate such that a unified view of corruptions and their consequences on learning is still lacking. In this work, we formally analyze corruption models at the distribution level through a general, exhaustive framework based on Markov kernels. We highlight the existence of intricate joint and dependent corruptions on both labels and attributes, which are rarely touched by existing research. Further, we show how these corruptions affect standard supervised learning by analyzing the resulting changes in Bayes Risk. Our findings offer qualitative insights into the consequences of "more complex" corruptions on the learning problem, and provide a foundation for future quantitative comparisons. Applications of the framework include corruption-corrected learning, a subcase of which we 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23545;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#22312;&#27979;&#22320;&#32447;&#24378;&#21333;&#35843;&#35774;&#32622;&#19979;&#65292;&#20855;&#26377;&#23545;&#26354;&#29575;&#19981;&#25935;&#24863;&#30340;&#22266;&#23450;&#27493;&#38271;&#30340;RGD&#26041;&#26696;&#21487;&#20197;&#23454;&#29616;&#26354;&#29575;&#26080;&#20851;&#21644;&#32447;&#24615;&#30340;&#26368;&#21518;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.16617</link><description>&lt;p&gt;
&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#28216;&#25103;&#20013;&#26080;&#20851;&#26354;&#29575;&#30340;&#26368;&#21518;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Curvature-Independent Last-Iterate Convergence for Games on Riemannian Manifolds. (arXiv:2306.16617v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16617
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23545;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#22312;&#27979;&#22320;&#32447;&#24378;&#21333;&#35843;&#35774;&#32622;&#19979;&#65292;&#20855;&#26377;&#23545;&#26354;&#29575;&#19981;&#25935;&#24863;&#30340;&#22266;&#23450;&#27493;&#38271;&#30340;RGD&#26041;&#26696;&#21487;&#20197;&#23454;&#29616;&#26354;&#29575;&#26080;&#20851;&#21644;&#32447;&#24615;&#30340;&#26368;&#21518;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#35768;&#22810;&#24212;&#29992;&#21487;&#20197;&#20197;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#22343;&#34913;&#35745;&#31639;&#24418;&#24335;&#21270;&#12290;&#23613;&#31649;&#23545;&#23427;&#20204;&#30340;&#27431;&#20960;&#37324;&#24503;&#23545;&#24212;&#29289;&#36827;&#34892;&#20102;&#22823;&#37327;&#30740;&#31350;&#65292;&#20294;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#24615;&#33021;&#20173;&#28982;&#19981;&#36879;&#26126;&#19988;&#38590;&#20197;&#29702;&#35299;&#12290;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#65288;RGD&#65289;&#30340;&#21407;&#22987;&#26041;&#26696;&#65292;&#24182;&#22312;&#23545;&#27979;&#22320;&#32447;&#21333;&#35843;&#24615;&#20551;&#35774;&#36827;&#34892;&#20998;&#26512;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#30740;&#31350;&#20805;&#20998;&#30340;&#27979;&#22320;&#32447;&#20984;&#20985;&#26497;&#20540;&#20248;&#21270;&#38382;&#39064;&#20316;&#20026;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#34920;&#26126;&#65292;&#23613;&#31649;&#23384;&#22312;&#36317;&#31163;&#22833;&#30495;&#29616;&#35937;&#65292;&#20294;&#20855;&#26377;&#23545;&#26354;&#29575;&#19981;&#25935;&#24863;&#30340;&#22266;&#23450;&#27493;&#38271;&#30340;RGD&#26041;&#26696;&#22312;&#27979;&#22320;&#32447;&#24378;&#21333;&#35843;&#35774;&#32622;&#19979;&#21487;&#20197;&#23454;&#29616;&#26354;&#29575;&#26080;&#20851;&#21644;&#32447;&#24615;&#30340;&#26368;&#21518;&#25910;&#25947;&#36895;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#20197;&#21069;&#20174;&#26410;&#32771;&#34385;&#36807;&#22312;&#40654;&#26364;&#35774;&#32622;&#20013;&#23384;&#22312;&#26354;&#29575;&#26080;&#20851;&#36895;&#29575;&#21644;/&#25110;&#26368;&#21518;&#25910;&#25947;&#24615;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerous applications in machine learning and data analytics can be formulated as equilibrium computation over Riemannian manifolds. Despite the extensive investigation of their Euclidean counterparts, the performance of Riemannian gradient-based algorithms remain opaque and poorly understood. We revisit the original scheme of Riemannian gradient descent (RGD) and analyze it under a geodesic monotonicity assumption, which includes the well-studied geodesically convex-concave min-max optimization problem as a special case. Our main contribution is to show that, despite the phenomenon of distance distortion, the RGD scheme, with a step size that is agnostic to the manifold's curvature, achieves a curvature-independent and linear last-iterate convergence rate in the geodesically strongly monotone setting. To the best of our knowledge, the possibility of curvature-independent rates and/or last-iterate convergence in the Riemannian setting has not been considered before.
&lt;/p&gt;</description></item></channel></rss>