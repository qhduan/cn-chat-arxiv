<rss version="2.0"><channel><title>Chat Arxiv cs.LG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.LG</description><item><title>&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;</title><link>https://arxiv.org/abs/2403.15740</link><description>&lt;p&gt;
Ghost Sentence&#65306;&#19968;&#31181;&#20379;&#26222;&#36890;&#29992;&#25143;&#20351;&#29992;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#36827;&#34892;&#29256;&#26435;&#20445;&#25252;
&lt;/p&gt;
&lt;p&gt;
Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15740
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Web&#29992;&#25143;&#25968;&#25454;&#22312;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21450;&#20854;&#24494;&#35843;&#21464;&#31181;&#30340;&#29983;&#24577;&#31995;&#32479;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#24314;&#35758;&#29992;&#25143;&#22312;&#20854;&#25991;&#26723;&#20013;&#21453;&#22797;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#65292;&#20351;LLMs&#33021;&#22815;&#35760;&#24518;&#36825;&#20123;&#23494;&#30721;&#12290;&#36825;&#20123;&#29992;&#25143;&#25991;&#26723;&#20013;&#38544;&#34255;&#30340;&#23494;&#30721;&#65292;&#34987;&#31216;&#20026;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#19968;&#26086;&#23427;&#20204;&#20986;&#29616;&#22312;LLMs&#29983;&#25104;&#30340;&#20869;&#23481;&#20013;&#65292;&#29992;&#25143;&#23601;&#21487;&#20197;&#30830;&#20449;&#20182;&#20204;&#30340;&#25968;&#25454;&#34987;&#29992;&#20110;&#35757;&#32451;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#31181;&#29256;&#26435;&#24037;&#20855;&#30340;&#26377;&#25928;&#24615;&#21644;&#29992;&#27861;&#65292;&#25105;&#20204;&#21033;&#29992;&#24189;&#28789;&#21477;&#23376;&#23450;&#20041;&#20102;&#8220;&#29992;&#25143;&#35757;&#32451;&#25968;&#25454;&#35782;&#21035;&#8221;&#20219;&#21153;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#26469;&#33258;&#19981;&#21516;&#26469;&#28304;&#12289;&#19981;&#21516;&#35268;&#27169;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#19981;&#21516;&#35268;&#27169;&#30340;LLMs&#36827;&#34892;&#27979;&#35797;&#12290;&#20026;&#20102;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26368;&#21518;$k$&#20010;&#21333;&#35789;&#39564;&#35777;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15740v1 Announce Type: new  Abstract: Web user data plays a central role in the ecosystem of pre-trained large language models (LLMs) and their fine-tuned variants. Billions of data are crawled from the web and fed to LLMs. How can \textit{\textbf{everyday web users}} confirm if LLMs misuse their data without permission? In this work, we suggest that users repeatedly insert personal passphrases into their documents, enabling LLMs to memorize them. These concealed passphrases in user documents, referred to as \textit{ghost sentences}, once they are identified in the generated content of LLMs, users can be sure that their data is used for training. To explore the effectiveness and usage of this copyrighting tool, we define the \textit{user training data identification} task with ghost sentences. Multiple datasets from various sources at different scales are created and tested with LLMs of different sizes. For evaluation, we introduce a last $k$ words verification manner along 
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#22635;&#34917;&#20102;&#26377;&#20851;&#20225;&#19994;&#20013;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;GenAI&#65289;&#27835;&#29702;&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#26088;&#22312;&#21033;&#29992;&#19994;&#21153;&#26426;&#20250;&#24182;&#20943;&#36731;&#19982;GenAI&#25972;&#21512;&#30456;&#20851;&#39118;&#38505;&#12290;</title><link>https://arxiv.org/abs/2403.08802</link><description>&lt;p&gt;
&#20225;&#19994;&#20013;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#27835;&#29702;
&lt;/p&gt;
&lt;p&gt;
Governance of Generative Artificial Intelligence for Companies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#22635;&#34917;&#20102;&#26377;&#20851;&#20225;&#19994;&#20013;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;GenAI&#65289;&#27835;&#29702;&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#26088;&#22312;&#21033;&#29992;&#19994;&#21153;&#26426;&#20250;&#24182;&#20943;&#36731;&#19982;GenAI&#25972;&#21512;&#30456;&#20851;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;GenAI&#65289;&#65292;&#29305;&#21035;&#26159;&#20687;ChatGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24050;&#36805;&#36895;&#36827;&#20837;&#20225;&#19994;&#65292;&#20294;&#32570;&#20047;&#20805;&#20998;&#30340;&#27835;&#29702;&#65292;&#24102;&#26469;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;&#23613;&#31649;&#23545;GenAI&#20855;&#26377;&#21464;&#38761;&#24615;&#36136;&#21644;&#30417;&#31649;&#25514;&#26045;&#30340;&#24191;&#27867;&#35752;&#35770;&#65292;&#20294;&#26377;&#38480;&#30340;&#30740;&#31350;&#28041;&#21450;&#32452;&#32455;&#27835;&#29702;&#65292;&#21253;&#25324;&#25216;&#26415;&#21644;&#19994;&#21153;&#35270;&#35282;&#12290;&#26412;&#32508;&#36848;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#35843;&#26597;&#20102;&#26368;&#36817;&#30340;&#30740;&#31350;&#12290;&#23427;&#19981;&#20165;&#20165;&#26159;&#24635;&#32467;&#65292;&#36824;&#36890;&#36807;&#21046;&#23450;&#36866;&#29992;&#20110;&#20225;&#19994;&#20869;&#30340;GenAI&#27835;&#29702;&#26694;&#26550;&#26469;&#36827;&#34892;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#35814;&#32454;&#25551;&#36848;&#20102;&#33539;&#22260;&#12289;&#30446;&#26631;&#21644;&#27835;&#29702;&#26426;&#21046;&#65292;&#26088;&#22312;&#21033;&#29992;&#19994;&#21153;&#26426;&#20250;&#24182;&#20943;&#36731;&#19982;GenAI&#25972;&#21512;&#30456;&#20851;&#39118;&#38505;&#12290;&#35813;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#19987;&#27880;&#20110;GenAI&#27835;&#29702;&#30340;&#26041;&#27861;&#65292;&#20026;&#20225;&#19994;&#22312;&#36127;&#36131;&#20219;&#30340;AI&#37319;&#29992;&#25361;&#25112;&#20013;&#25552;&#20379;&#20102;&#23454;&#29992;&#35265;&#35299;&#12290;&#23545;&#20110;&#25216;&#26415;&#20154;&#21592;&#26469;&#35828;&#65292;&#20063;&#26377;&#21161;&#20110;&#25299;&#23485;&#20182;&#20204;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08802v1 Announce Type: new  Abstract: Generative Artificial Intelligence (GenAI), specifically large language models like ChatGPT, has swiftly entered organizations without adequate governance, posing both opportunities and risks. Despite extensive debates on GenAI's transformative nature and regulatory measures, limited research addresses organizational governance, encompassing technical and business perspectives. This review paper fills this gap by surveying recent works. It goes beyond mere summarization by developing a framework for GenAI governance within companies. Our framework outlines the scope, objectives, and governance mechanisms tailored to harness business opportunities and mitigate risks associated with GenAI integration. This research contributes a focused approach to GenAI governance, offering practical insights for companies navigating the challenges of responsible AI adoption. It is also valuable for a technical audience to broaden their perspective as inc
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#23545;&#20110;&#19968;&#33324;&#21270;&#30340;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20197;&#21450;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.02004</link><description>&lt;p&gt;
&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#20197;&#21450;log-Sobolev&#21644;Talagrand&#19981;&#31561;&#24335;&#30340;&#25512;&#24191;
&lt;/p&gt;
&lt;p&gt;
Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02004
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#23545;&#20110;&#19968;&#33324;&#21270;&#30340;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20197;&#21450;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;(PGD)~(Kuntz&#31561;&#20154;&#65292;2023)&#30340;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#31163;&#25955;&#21270;&#33258;&#30001;&#33021;&#26799;&#24230;&#27969;&#33719;&#24471;&#30340;&#22823;&#22411;&#28508;&#21464;&#37327;&#27169;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#23545;&#20110;&#28385;&#36275;&#19968;&#33324;&#21270;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#65288;LSI&#21644;PLI&#65289;&#30340;&#27169;&#22411;&#65292;&#27969;&#20197;&#25351;&#25968;&#36895;&#24230;&#25910;&#25947;&#21040;&#33258;&#30001;&#33021;&#30340;&#26497;&#23567;&#21270;&#38598;&#21512;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#26368;&#20248;&#36755;&#36816;&#25991;&#29486;&#20013;&#20247;&#25152;&#21608;&#30693;&#30340;&#32467;&#26524;&#65288;LSI&#24847;&#21619;&#30528;Talagrand&#19981;&#31561;&#24335;&#65289;&#21450;&#20854;&#22312;&#20248;&#21270;&#25991;&#29486;&#20013;&#30340;&#23545;&#24212;&#29289;&#65288;PLI&#24847;&#21619;&#30528;&#25152;&#35859;&#30340;&#20108;&#27425;&#22686;&#38271;&#26465;&#20214;&#65289;&#25193;&#23637;&#24182;&#24212;&#29992;&#21040;&#25105;&#20204;&#30340;&#26032;&#35774;&#32622;&#65292;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#36824;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#65292;&#24182;&#23637;&#31034;&#20102;&#23545;&#20110;&#20855;&#26377;&#24378;&#20985;&#23545;&#25968;&#20284;&#28982;&#30340;&#27169;&#22411;&#65292;LSI/PLI&#30340;&#27010;&#25324;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02004v1 Announce Type: new  Abstract: We prove non-asymptotic error bounds for particle gradient descent (PGD)~(Kuntz et al., 2023), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy. We begin by showing that, for models satisfying a condition generalizing both the log-Sobolev and the Polyak--{\L}ojasiewicz inequalities (LSI and P{\L}I, respectively), the flow converges exponentially fast to the set of minimizers of the free energy. We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the P{\L}I implies the so-called quadratic growth condition), and applying it to our new setting. We also generalize the Bakry--\'Emery Theorem and show that the LSI/P{\L}I generalization holds for models with strongly concave log-likelihoods. For such m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#26680;&#23398;&#20064;&#65288;DKL&#65289;&#30340;&#27963;&#36291;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#20256;&#32479;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#23545;&#27604;&#20998;&#26512;&#65292;&#21019;&#36896;&#20102;&#20248;&#20808;&#32771;&#34385;&#20998;&#23376;&#21151;&#33021;&#24615;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36845;&#20195;&#37325;&#26032;&#35745;&#31639;&#23884;&#20837;&#21521;&#37327;&#23454;&#29616;&#20102;&#26356;&#22909;&#32452;&#32455;&#30340;&#28508;&#22312;&#31354;&#38388;&#12290;</title><link>https://arxiv.org/abs/2403.01234</link><description>&lt;p&gt;
&#27963;&#36291;&#28145;&#24230;&#26680;&#23398;&#20064;&#20998;&#23376;&#21151;&#33021;&#24615;&#65306;&#23454;&#29616;&#21160;&#24577;&#32467;&#26500;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Active Deep Kernel Learning of Molecular Functionalities: Realizing Dynamic Structural Embeddings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#26680;&#23398;&#20064;&#65288;DKL&#65289;&#30340;&#27963;&#36291;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#20256;&#32479;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#23545;&#27604;&#20998;&#26512;&#65292;&#21019;&#36896;&#20102;&#20248;&#20808;&#32771;&#34385;&#20998;&#23376;&#21151;&#33021;&#24615;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36845;&#20195;&#37325;&#26032;&#35745;&#31639;&#23884;&#20837;&#21521;&#37327;&#23454;&#29616;&#20102;&#26356;&#22909;&#32452;&#32455;&#30340;&#28508;&#22312;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25506;&#32034;&#20998;&#23376;&#31354;&#38388;&#23545;&#20110;&#25512;&#36827;&#25105;&#20204;&#23545;&#21270;&#23398;&#24615;&#36136;&#21644;&#21453;&#24212;&#30340;&#29702;&#35299;&#33267;&#20851;&#37325;&#35201;&#65292;&#20174;&#32780;&#22312;&#26448;&#26009;&#31185;&#23398;&#12289;&#21307;&#23398;&#21644;&#33021;&#28304;&#39046;&#22495;&#21462;&#24471;&#31361;&#30772;&#24615;&#21019;&#26032;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#26680;&#23398;&#20064;&#65288;DKL&#65289;&#36827;&#34892;&#20998;&#23376;&#21457;&#29616;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#36229;&#36234;&#20256;&#32479;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#38480;&#21046;&#30340;&#26032;&#26041;&#27861;&#12290;&#20351;&#29992;QM9&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23558;DKL&#19982;&#20256;&#32479;VAEs&#36827;&#34892;&#23545;&#27604;&#65292;&#21518;&#32773;&#22522;&#20110;&#30456;&#20284;&#24615;&#20998;&#26512;&#20998;&#23376;&#32467;&#26500;&#65292;&#25581;&#31034;&#20102;&#30001;&#20110;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#31232;&#30095;&#35268;&#24459;&#24615;&#32780;&#23384;&#22312;&#30340;&#23616;&#38480;&#24615;&#12290;&#28982;&#32780;&#65292;DKL&#36890;&#36807;&#23558;&#32467;&#26500;&#19982;&#24615;&#36136;&#30456;&#20851;&#32852;&#65292;&#21019;&#36896;&#20102;&#20248;&#20808;&#32771;&#34385;&#20998;&#23376;&#21151;&#33021;&#24615;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#25552;&#20379;&#20102;&#26356;&#20840;&#38754;&#30340;&#35270;&#35282;&#12290;&#36825;&#26159;&#36890;&#36807;&#36845;&#20195;&#37325;&#26032;&#35745;&#31639;&#23884;&#20837;&#21521;&#37327;&#26469;&#23454;&#29616;&#30340;&#65292;&#19982;&#30446;&#26631;&#24615;&#36136;&#30340;&#23454;&#39564;&#21487;&#29992;&#24615;&#20445;&#25345;&#19968;&#33268;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#28508;&#22312;&#31354;&#38388;&#19981;&#20165;&#32452;&#32455;&#26356;&#22909;&#65292;&#32780;&#19988;&#20855;&#26377;&#29420;&#29305;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01234v1 Announce Type: new  Abstract: Exploring molecular spaces is crucial for advancing our understanding of chemical properties and reactions, leading to groundbreaking innovations in materials science, medicine, and energy. This paper explores an approach for active learning in molecular discovery using Deep Kernel Learning (DKL), a novel approach surpassing the limits of classical Variational Autoencoders (VAEs). Employing the QM9 dataset, we contrast DKL with traditional VAEs, which analyze molecular structures based on similarity, revealing limitations due to sparse regularities in latent spaces. DKL, however, offers a more holistic perspective by correlating structure with properties, creating latent spaces that prioritize molecular functionality. This is achieved by recalculating embedding vectors iteratively, aligning with the experimental availability of target properties. The resulting latent spaces are not only better organized but also exhibit unique characteri
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#28041;&#21450;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#32467;&#26524;&#19982;&#30446;&#26631;&#30340;&#26399;&#26395;Wasserstein-1&#36317;&#31163;&#30340;&#32553;&#25918;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.15801</link><description>&lt;p&gt;
&#20851;&#20110;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension. (arXiv:2401.15801v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15801
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#28041;&#21450;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#32467;&#26524;&#19982;&#30446;&#26631;&#30340;&#26399;&#26395;Wasserstein-1&#36317;&#31163;&#30340;&#32553;&#25918;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#20854;&#32479;&#35745;&#20934;&#30830;&#24615;&#30340;&#29702;&#35770;&#20445;&#35777;&#20173;&#28982;&#30456;&#23545;&#24754;&#35266;&#12290;&#29305;&#21035;&#26159;&#22312;&#24212;&#29992;GANs&#30340;&#25968;&#25454;&#20998;&#24067;&#65288;&#22914;&#33258;&#28982;&#22270;&#20687;&#65289;&#20013;&#65292;&#36890;&#24120;&#20551;&#35774;&#20854;&#22312;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#20013;&#20855;&#26377;&#22266;&#26377;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#20294;&#36825;&#22312;&#29616;&#26377;&#20998;&#26512;&#20013;&#24448;&#24448;&#27809;&#26377;&#24471;&#21040;&#21453;&#26144;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#36890;&#36807;&#25512;&#23548;&#20851;&#20110;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#26469;&#24357;&#21512;GANs&#21450;&#20854;&#21452;&#21521;&#21464;&#20307;BiGANs&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#20998;&#26512;&#22320;&#35777;&#26126;&#65292;&#22914;&#26524;&#25105;&#20204;&#26377;&#26469;&#33258;&#26410;&#30693;&#30446;&#26631;&#20998;&#24067;&#30340; n &#20010;&#26679;&#26412;&#65292;&#24182;&#19988;&#36873;&#25321;&#20102;&#36866;&#24403;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#37027;&#20040;&#20174;&#30446;&#26631;&#20013;&#20272;&#35745;&#24471;&#20986;&#30340;&#26399;&#26395; Wasserstein-1 &#36317;&#31163;&#20250;&#25353;&#29031; $O(n^{-1/d_\mu })$ &#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\left( n^{-1/d_\mu } \right)$
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2310.20360</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#25968;&#23398;&#20171;&#32461;&#65306;&#26041;&#27861;&#12289;&#23454;&#29616;&#21644;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory. (arXiv:2310.20360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23398;&#20171;&#32461;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#24076;&#26395;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#26088;&#22312;&#20171;&#32461;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20027;&#39064;&#12290;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65288;&#22914;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#12289;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12289;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#12289;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#21644;&#24102;&#26377;&#25209;&#24402;&#19968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65289;&#20197;&#21450;&#19981;&#21516;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;&#22522;&#26412;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#12289;&#21152;&#36895;&#26041;&#27861;&#21644;&#33258;&#36866;&#24212;&#26041;&#27861;&#65289;&#12290;&#25105;&#20204;&#36824;&#28085;&#30422;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#20960;&#20010;&#29702;&#35770;&#26041;&#38754;&#65292;&#22914;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#33021;&#21147;&#65288;&#21253;&#25324;&#31070;&#32463;&#32593;&#32476;&#30340;&#24494;&#31215;&#20998;&#65289;&#12289;&#20248;&#21270;&#29702;&#35770;&#65288;&#21253;&#25324;Kurdyka-Lojasiewicz&#19981;&#31561;&#24335;&#65289;&#21644;&#27867;&#21270;&#35823;&#24046;&#12290;&#22312;&#26412;&#20070;&#30340;&#26368;&#21518;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#36824;&#22238;&#39038;&#20102;&#19968;&#20123;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#26041;&#27861;&#65292;&#21253;&#25324;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#21644;&#28145;&#24230;Galerkin&#26041;&#27861;&#12290;&#24076;&#26395;&#26412;&#20070;&#33021;&#23545;&#23398;&#29983;&#21644;&#31185;&#23398;&#23478;&#20204;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;
This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#24191;&#20041;&#36870;&#29702;&#35770;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20840;&#33394;&#22686;&#24378;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#31616;&#21333;&#30697;&#38453;&#26041;&#31243;&#25551;&#36848;&#20840;&#33394;&#22686;&#24378;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#35299;&#30340;&#26465;&#20214;&#21644;&#20809;&#35889;&#12289;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#33719;&#21462;&#12290;&#36890;&#36807;&#24341;&#20837;&#38477;&#37319;&#26679;&#22686;&#24378;&#26041;&#27861;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19982;&#20998;&#37327;&#26367;&#20195;&#21644;&#22810;&#20998;&#36776;&#29575;&#20998;&#26512;&#26041;&#27861;&#30456;&#23545;&#24212;&#30340;&#24191;&#20041;&#36870;&#30697;&#38453;&#34920;&#36798;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#27169;&#22411;&#20808;&#39564;&#26469;&#35299;&#20915;&#20840;&#33394;&#22686;&#24378;&#20013;&#30340;&#29702;&#35770;&#35823;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.02718</link><description>&lt;p&gt;
&#36890;&#36807;&#24191;&#20041;&#36870;&#29702;&#35299;&#20840;&#33394;&#22686;&#24378;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Understanding Pan-Sharpening via Generalized Inverse. (arXiv:2310.02718v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02718
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#24191;&#20041;&#36870;&#29702;&#35770;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20840;&#33394;&#22686;&#24378;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#31616;&#21333;&#30697;&#38453;&#26041;&#31243;&#25551;&#36848;&#20840;&#33394;&#22686;&#24378;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#35299;&#30340;&#26465;&#20214;&#21644;&#20809;&#35889;&#12289;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#33719;&#21462;&#12290;&#36890;&#36807;&#24341;&#20837;&#38477;&#37319;&#26679;&#22686;&#24378;&#26041;&#27861;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19982;&#20998;&#37327;&#26367;&#20195;&#21644;&#22810;&#20998;&#36776;&#29575;&#20998;&#26512;&#26041;&#27861;&#30456;&#23545;&#24212;&#30340;&#24191;&#20041;&#36870;&#30697;&#38453;&#34920;&#36798;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#27169;&#22411;&#20808;&#39564;&#26469;&#35299;&#20915;&#20840;&#33394;&#22686;&#24378;&#20013;&#30340;&#29702;&#35770;&#35823;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#33394;&#22686;&#24378;&#31639;&#27861;&#21033;&#29992;&#20840;&#33394;&#22270;&#20687;&#21644;&#22810;&#20809;&#35889;&#22270;&#20687;&#33719;&#21462;&#20855;&#26377;&#39640;&#31354;&#38388;&#21644;&#39640;&#20809;&#35889;&#30340;&#22270;&#20687;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#30340;&#20248;&#21270;&#26159;&#26681;&#25454;&#19981;&#21516;&#30340;&#26631;&#20934;&#35774;&#35745;&#30340;&#12290;&#25105;&#20204;&#37319;&#29992;&#31616;&#21333;&#30340;&#30697;&#38453;&#26041;&#31243;&#26469;&#25551;&#36848;&#20840;&#33394;&#22686;&#24378;&#38382;&#39064;&#65292;&#24182;&#35752;&#35770;&#35299;&#30340;&#23384;&#22312;&#26465;&#20214;&#20197;&#21450;&#20809;&#35889;&#21644;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#33719;&#21462;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#38477;&#37319;&#26679;&#22686;&#24378;&#26041;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#33719;&#21462;&#31354;&#38388;&#21644;&#20809;&#35889;&#38477;&#37319;&#26679;&#30697;&#38453;&#12290;&#36890;&#36807;&#24191;&#20041;&#36870;&#29702;&#35770;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20004;&#31181;&#24418;&#24335;&#30340;&#24191;&#20041;&#36870;&#30697;&#38453;&#34920;&#36798;&#24335;&#65292;&#21487;&#20197;&#23545;&#24212;&#20110;&#20004;&#20010;&#20027;&#35201;&#30340;&#20840;&#33394;&#22686;&#24378;&#26041;&#27861;&#65306;&#20998;&#37327;&#26367;&#20195;&#21644;&#22810;&#20998;&#36776;&#29575;&#20998;&#26512;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;Gram Schmidt&#33258;&#36866;&#24212;(GSA)&#26041;&#27861;&#36981;&#24490;&#20998;&#37327;&#26367;&#20195;&#30340;&#24191;&#20041;&#36870;&#30697;&#38453;&#34920;&#36798;&#24335;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#20809;&#35889;&#20989;&#25968;&#30340;&#24191;&#20041;&#36870;&#30697;&#38453;&#20043;&#21069;&#30340;&#27169;&#22411;&#20808;&#39564;&#12290;&#25105;&#20204;&#23545;&#29702;&#35770;&#35823;&#24046;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pan-sharpening algorithm utilizes panchromatic image and multispectral image to obtain a high spatial and high spectral image. However, the optimizations of the algorithms are designed with different standards. We adopt the simple matrix equation to describe the Pan-sharpening problem. The solution existence condition and the acquirement of spectral and spatial resolution are discussed. A down-sampling enhancement method was introduced for better acquiring the spatial and spectral down-sample matrices. By the generalized inverse theory, we derived two forms of general inverse matrix formulations that can correspond to the two prominent classes of Pan-sharpening methods, that is, component substitution and multi-resolution analysis methods. Specifically, the Gram Schmidt Adaptive(GSA) was proved to follow the general inverse matrix formulation of component substitution. A model prior to the general inverse matrix of the spectral function was rendered. The theoretical errors are analyzed
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#26465;&#20214;&#19981;&#21464;&#32452;&#20214;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#19981;&#21464;&#24809;&#32602;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#30446;&#26631;&#39118;&#38505;&#20445;&#35777;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2309.10301</link><description>&lt;p&gt;
&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#26465;&#20214;&#19981;&#21464;&#32452;&#20214;&#30340;&#31361;&#20986;&#20316;&#29992;&#65306;&#29702;&#35770;&#21644;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms. (arXiv:2309.10301v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10301
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#26465;&#20214;&#19981;&#21464;&#32452;&#20214;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#19981;&#21464;&#24809;&#32602;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#30446;&#26631;&#39118;&#38505;&#20445;&#35777;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#33258;&#36866;&#24212;&#26159;&#19968;&#20010;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#65292;&#24403;&#29992;&#20110;&#35757;&#32451;&#27169;&#22411;&#30340;&#28304;&#25968;&#25454;&#20998;&#24067;&#19982;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#30340;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#26102;&#20986;&#29616;&#12290;&#34429;&#28982;&#35768;&#22810;&#39046;&#22495;&#33258;&#36866;&#24212;&#31639;&#27861;&#24050;&#32463;&#35777;&#26126;&#20102;&#30456;&#24403;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#26159;&#30450;&#30446;&#24212;&#29992;&#36825;&#20123;&#31639;&#27861;&#24448;&#24448;&#20250;&#23548;&#33268;&#22312;&#26032;&#30340;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#26356;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#37325;&#35201;&#30340;&#26159;&#28548;&#28165;&#39046;&#22495;&#33258;&#36866;&#24212;&#31639;&#27861;&#22312;&#20855;&#22791;&#33391;&#22909;&#30446;&#26631;&#24615;&#33021;&#30340;&#20551;&#35774;&#19979;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#22312;&#39044;&#27979;&#20013;&#20855;&#22791;&#26465;&#20214;&#19981;&#21464;&#30340;&#32452;&#20214;&#65288;CICs&#65289;&#30340;&#23384;&#22312;&#20551;&#35774;&#65292;&#36825;&#20123;&#32452;&#20214;&#22312;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#20043;&#38388;&#20445;&#25345;&#26465;&#20214;&#19981;&#21464;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;CICs&#65292;&#36890;&#36807;&#26465;&#20214;&#19981;&#21464;&#24809;&#32602;&#65288;CIP&#65289;&#21487;&#20197;&#20272;&#35745;&#65292;&#20855;&#22791;&#22312;&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#25552;&#20379;&#30446;&#26631;&#39118;&#38505;&#20445;&#35777;&#30340;&#19977;&#20010;&#31361;&#20986;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;CICs&#30340;&#26032;&#31639;&#27861;&#65292;&#21363;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#26465;&#20214;&#19981;&#21464;&#24809;&#32602;&#65288;IW-CIP&#65289;&#65292;&#23427;&#22312;&#30446;&#26631;&#39118;&#38505;&#20445;&#35777;&#26041;&#38754;&#36229;&#36234;&#20102;&#31616;&#21333;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain adaptation (DA) is a statistical learning problem that arises when the distribution of the source data used to train a model differs from that of the target data used to evaluate the model. While many DA algorithms have demonstrated considerable empirical success, blindly applying these algorithms can often lead to worse performance on new datasets. To address this, it is crucial to clarify the assumptions under which a DA algorithm has good target performance. In this work, we focus on the assumption of the presence of conditionally invariant components (CICs), which are relevant for prediction and remain conditionally invariant across the source and target data. We demonstrate that CICs, which can be estimated through conditional invariant penalty (CIP), play three prominent roles in providing target risk guarantees in DA. First, we propose a new algorithm based on CICs, importance-weighted conditional invariant penalty (IW-CIP), which has target risk guarantees beyond simple 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#22810;&#26679;&#24615;&#30340;&#20020;&#24202;&#21644;&#34394;&#25311;&#29983;&#25104;&#30340;&#21307;&#23398;&#22270;&#20687;&#24320;&#21457;&#21644;&#35780;&#20272;&#20102;COVID-19&#35786;&#26029;&#30340;AI&#27169;&#22411;&#65292;&#21457;&#29616;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#20110;AI&#24615;&#33021;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#23481;&#26131;&#23548;&#33268;&#27867;&#21270;&#33021;&#21147;&#36739;&#24046;&#65292;&#26368;&#39640;&#19979;&#38477;20&#65285;&#12290;</title><link>http://arxiv.org/abs/2308.09730</link><description>&lt;p&gt;
&#22522;&#20110;COVID-19&#30340;&#25968;&#25454;&#22810;&#26679;&#24615;&#21644;&#34394;&#25311;&#25104;&#20687;&#30340;AI&#35786;&#26029;&#65306;&#20197;&#30149;&#20363;&#30740;&#31350;&#20026;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Data diversity and virtual imaging in AI-based diagnosis: A case study based on COVID-19. (arXiv:2308.09730v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09730
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#22810;&#26679;&#24615;&#30340;&#20020;&#24202;&#21644;&#34394;&#25311;&#29983;&#25104;&#30340;&#21307;&#23398;&#22270;&#20687;&#24320;&#21457;&#21644;&#35780;&#20272;&#20102;COVID-19&#35786;&#26029;&#30340;AI&#27169;&#22411;&#65292;&#21457;&#29616;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#20110;AI&#24615;&#33021;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#23481;&#26131;&#23548;&#33268;&#27867;&#21270;&#33021;&#21147;&#36739;&#24046;&#65292;&#26368;&#39640;&#19979;&#38477;20&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#30740;&#31350;&#24050;&#32463;&#35843;&#26597;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#27169;&#22411;&#22312;&#26032;&#22411;&#20896;&#29366;&#30149;&#27602;&#65288;COVID-19&#65289;&#30340;&#21307;&#23398;&#24433;&#20687;&#35786;&#26029;&#20013;&#30340;&#24212;&#29992;&#65292;&#35768;&#22810;&#25253;&#36947;&#31216;&#20854;&#24615;&#33021;&#20960;&#20046;&#23436;&#32654;&#12290;&#28982;&#32780;&#65292;&#24615;&#33021;&#30340;&#21464;&#24322;&#24615;&#21644;&#28508;&#22312;&#30340;&#25968;&#25454;&#20559;&#24046;&#24341;&#21457;&#20102;&#23545;&#20020;&#24202;&#36866;&#29992;&#24615;&#30340;&#25285;&#24551;&#12290;&#26412;&#22238;&#39038;&#24615;&#30740;&#31350;&#28041;&#21450;&#20351;&#29992;&#20020;&#24202;&#22810;&#26679;&#24615;&#21644;&#34394;&#25311;&#29983;&#25104;&#30340;&#21307;&#23398;&#22270;&#20687;&#24320;&#21457;&#21644;&#35780;&#20272;COVID-19&#35786;&#26029;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#27425;&#34394;&#25311;&#25104;&#20687;&#35797;&#39564;&#65292;&#20197;&#35780;&#20272;AI&#24615;&#33021;&#21463;&#30142;&#30149;&#33539;&#22260;&#12289;&#36752;&#23556;&#21058;&#37327;&#21644;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#65288;CT&#65289;&#21644;&#33016;&#37096;&#25918;&#23556;&#25668;&#24433;&#65288;CXR&#65289;&#25104;&#20687;&#27169;&#24577;&#31561;&#20960;&#20010;&#24739;&#32773;&#21644;&#29289;&#29702;&#24615;&#22240;&#32032;&#30340;&#24433;&#21709;&#12290;&#25968;&#25454;&#38598;&#29305;&#24449;&#65288;&#21253;&#25324;&#25968;&#37327;&#12289;&#22810;&#26679;&#24615;&#21644;&#24739;&#30149;&#29575;&#65289;&#24378;&#28872;&#24433;&#21709;&#20102;AI&#30340;&#24615;&#33021;&#65292;&#23548;&#33268;&#25509;&#25910;&#32773;&#25805;&#20316;&#29305;&#24449;&#26354;&#32447;&#19979;&#38754;&#31215;&#19979;&#38477;&#20102;&#39640;&#36798;20&#65285;&#65292;&#19988;&#27867;&#21270;&#33021;&#21147;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many studies have investigated deep-learning-based artificial intelligence (AI) models for medical imaging diagnosis of the novel coronavirus (COVID-19), with many reports of near-perfect performance. However, variability in performance and underlying data biases raise concerns about clinical generalizability. This retrospective study involved the development and evaluation of artificial intelligence (AI) models for COVID-19 diagnosis using both diverse clinical and virtually generated medical images. In addition, we conducted a virtual imaging trial to assess how AI performance is affected by several patient- and physics-based factors, including the extent of disease, radiation dose, and imaging modality of computed tomography (CT) and chest radiography (CXR). AI performance was strongly influenced by dataset characteristics including quantity, diversity, and prevalence, leading to poor generalization with up to 20% drop in receiver operating characteristic area under the curve. Model
&lt;/p&gt;</description></item></channel></rss>