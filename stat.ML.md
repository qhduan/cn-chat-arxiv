# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Trading off Consistency and Dimensionality of Convex Surrogates for the Mode](https://arxiv.org/abs/2402.10818) | 通过在低维替代空间中的凸多面体顶点上嵌入结果，并探究单纯形中的一致性区域，权衡了替代损失维度、问题实例数量。 |
| [^2] | [Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss](https://arxiv.org/abs/2402.00152) | 本文比较了更深的神经网络和更宽的神经网络在Sobolev损失的最优泛化误差方面的表现，研究发现神经网络的架构受多种因素影响，参数数量更多倾向于选择更宽的网络，而样本点数量和损失函数规则性更高倾向于选择更深的网络。 |
| [^3] | [Hidden Minima in Two-Layer ReLU Networks](https://arxiv.org/abs/2312.16819) | 本文研究了两层ReLU网络中的隐藏极小值现象，并提出方法来研究这些隐藏极小值的独特解析性质。 |
| [^4] | [On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Measures.](http://arxiv.org/abs/2301.10932) | 本论文研究了具有期望条件风险度量的风险厌恶策略梯度方法，提出了策略梯度更新，证明了其在约束和无约束情况下的全局收敛性和迭代复杂度，并测试了REINFORCE和actor-critic算法的风险厌恶变体来展示方法的实用价值和风险控制的重要性。 |

# 详细

[^1]: 在模型的凸替代品的一致性和维度之间进行权衡

    Trading off Consistency and Dimensionality of Convex Surrogates for the Mode

    [https://arxiv.org/abs/2402.10818](https://arxiv.org/abs/2402.10818)

    通过在低维替代空间中的凸多面体顶点上嵌入结果，并探究单纯形中的一致性区域，权衡了替代损失维度、问题实例数量。

    

    在多类分类中，必须将结果嵌入到至少有$n-1$维的实数空间中，以设计一种一致的替代损失函数，这会导致"正确"的分类，而不受数据分布的影响。在信息检索和结构化预测任务等需要大量n时，优化n-1维替代常常是棘手的。我们研究了在多类分类中如何权衡替代损失维度、问题实例数量以及在单纯形上约束一致性区域的方法。我们跟随过去的研究，探讨了一种直观的嵌入过程，将结果映射到低维替代空间中的凸多面体的顶点上。我们展示了在每个点质量分布周围存在单纯形的全维子集，其中一致性成立，但是，少于n-1维度的情况下，存在一些分布，对于这些分布，一种现象性是

    arXiv:2402.10818v1 Announce Type: new  Abstract: In multiclass classification over $n$ outcomes, the outcomes must be embedded into the reals with dimension at least $n-1$ in order to design a consistent surrogate loss that leads to the "correct" classification, regardless of the data distribution. For large $n$, such as in information retrieval and structured prediction tasks, optimizing a surrogate in $n-1$ dimensions is often intractable. We investigate ways to trade off surrogate loss dimension, the number of problem instances, and restricting the region of consistency in the simplex for multiclass classification. Following past work, we examine an intuitive embedding procedure that maps outcomes into the vertices of convex polytopes in a low-dimensional surrogate space. We show that full-dimensional subsets of the simplex exist around each point mass distribution for which consistency holds, but also, with less than $n-1$ dimensions, there exist distributions for which a phenomeno
    
[^2]: 更深还是更宽: 从Sobolev损失的最优泛化误差角度看

    Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss

    [https://arxiv.org/abs/2402.00152](https://arxiv.org/abs/2402.00152)

    本文比较了更深的神经网络和更宽的神经网络在Sobolev损失的最优泛化误差方面的表现，研究发现神经网络的架构受多种因素影响，参数数量更多倾向于选择更宽的网络，而样本点数量和损失函数规则性更高倾向于选择更深的网络。

    

    构建神经网络的架构是机器学习界一个具有挑战性的追求，到底是更深还是更宽一直是一个持续的问题。本文探索了更深的神经网络（DeNNs）和具有有限隐藏层的更宽的神经网络（WeNNs）在Sobolev损失的最优泛化误差方面的比较。通过分析研究发现，神经网络的架构可以受到多种因素的显著影响，包括样本点的数量，神经网络内的参数以及损失函数的规则性。具体而言，更多的参数倾向于选择WeNNs，而更多的样本点和更高的损失函数规则性倾向于选择DeNNs。最后，我们将这个理论应用于使用深度Ritz和物理感知神经网络（PINN）方法解决偏微分方程的问题。

    Constructing the architecture of a neural network is a challenging pursuit for the machine learning community, and the dilemma of whether to go deeper or wider remains a persistent question. This paper explores a comparison between deeper neural networks (DeNNs) with a flexible number of layers and wider neural networks (WeNNs) with limited hidden layers, focusing on their optimal generalization error in Sobolev losses. Analytical investigations reveal that the architecture of a neural network can be significantly influenced by various factors, including the number of sample points, parameters within the neural networks, and the regularity of the loss function. Specifically, a higher number of parameters tends to favor WeNNs, while an increased number of sample points and greater regularity in the loss function lean towards the adoption of DeNNs. We ultimately apply this theory to address partial differential equations using deep Ritz and physics-informed neural network (PINN) methods,
    
[^3]: 两层ReLU网络中的隐藏极小值

    Hidden Minima in Two-Layer ReLU Networks

    [https://arxiv.org/abs/2312.16819](https://arxiv.org/abs/2312.16819)

    本文研究了两层ReLU网络中的隐藏极小值现象，并提出方法来研究这些隐藏极小值的独特解析性质。

    

    本文考虑拟合具有$d$个输入、$k$个神经元以及由目标网络生成的标签的两层ReLU网络所涉及的优化问题。最近发现了两种无穷族的虚假极小值，每个$d$对应一个极小值。属于第一类的极小值的损失在$d$增加时收敛于零。在第二类中，损失保持远离于零。那么，如何避免属于后一类的极小值呢？幸运的是，这样的极小值从不会被标准优化方法检测到。受到此现象性质的问题的启发，我们开发了研究隐藏极小值独特解析性质的方法。根据现有的分析，两种类型的Hessian谱在$O(d^{-1/2})$项模意义下一致 -- 不太乐观。因此，我们的研究通过研究损失被最小化或最大化的曲线进行，通常称为切线。

    arXiv:2312.16819v2 Announce Type: replace  Abstract: The optimization problem associated to fitting two-layer ReLU networks having $d$~inputs, $k$~neurons, and labels generated by a target network, is considered. Two types of infinite families of spurious minima, giving one minimum per $d$, were recently found. The loss at minima belonging to the first type converges to zero as $d$ increases. In the second type, the loss remains bounded away from zero. That being so, how may one avoid minima belonging to the latter type? Fortunately, such minima are never detected by standard optimization methods. Motivated by questions concerning the nature of this phenomenon, we develop methods to study distinctive analytic properties of hidden minima.   By existing analyses, the Hessian spectrum of both types agree modulo $O(d^{-1/2})$-terms -- not promising. Thus, rather, our investigation proceeds by studying curves along which the loss is minimized or maximized, generally referred to as tangency 
    
[^4]: 关于具有期望条件风险度量的风险厌恶策略梯度方法的全局收敛性

    On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Measures. (arXiv:2301.10932v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10932](http://arxiv.org/abs/2301.10932)

    本论文研究了具有期望条件风险度量的风险厌恶策略梯度方法，提出了策略梯度更新，证明了其在约束和无约束情况下的全局收敛性和迭代复杂度，并测试了REINFORCE和actor-critic算法的风险厌恶变体来展示方法的实用价值和风险控制的重要性。

    

    风险敏感的强化学习已经成为控制不确定结果和确保各种顺序决策问题的可靠性能的流行工具。虽然针对风险敏感的强化学习已经开发出了策略梯度方法，但这些方法是否具有与风险中性情况下相同的全局收敛保证还不清楚。本文考虑了一类动态时间一致风险度量，称为期望条件风险度量（ECRM），并为基于ECRM的目标函数推导出策略梯度更新。在约束直接参数化和无约束softmax参数化下，我们提供了相应的风险厌恶策略梯度算法的全局收敛性和迭代复杂度。我们进一步测试了REINFORCE和actor-critic算法的风险厌恶变体，以展示我们的方法的有效性和风险控制的重要性。

    Risk-sensitive reinforcement learning (RL) has become a popular tool to control the risk of uncertain outcomes and ensure reliable performance in various sequential decision-making problems. While policy gradient methods have been developed for risk-sensitive RL, it remains unclear if these methods enjoy the same global convergence guarantees as in the risk-neutral case. In this paper, we consider a class of dynamic time-consistent risk measures, called Expected Conditional Risk Measures (ECRMs), and derive policy gradient updates for ECRM-based objective functions. Under both constrained direct parameterization and unconstrained softmax parameterization, we provide global convergence and iteration complexities of the corresponding risk-averse policy gradient algorithms. We further test risk-averse variants of REINFORCE and actor-critic algorithms to demonstrate the efficacy of our method and the importance of risk control.
    

