# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Tired of Plugins? Large Language Models Can Be End-To-End Recommenders](https://arxiv.org/abs/2404.00702) | 大型语言模型UniLLMRec将多阶段任务整合为端到端推荐框架，以解决推荐系统中对大规模物品集合的挑战 |

# 详细

[^1]: 厌倦了插件？大型语言模型可以成为端到端推荐系统

    Tired of Plugins? Large Language Models Can Be End-To-End Recommenders

    [https://arxiv.org/abs/2404.00702](https://arxiv.org/abs/2404.00702)

    大型语言模型UniLLMRec将多阶段任务整合为端到端推荐框架，以解决推荐系统中对大规模物品集合的挑战

    

    推荐系统旨在基于历史行为数据预测用户兴趣。它们主要设计为顺序流水线，需要大量数据来训练不同子系统，并且难以扩展到新域。最近，大型语言模型（LLMs）展示了出色的通用能力，使一个模型能够处理各种场景中的多样化推荐任务。然而，现有基于LLM的推荐系统纯粹利用LLM来处理推荐流水线的单个任务。此外，这些系统面临着以自然语言格式向LLM呈现大规模物品集合的挑战，由于输入长度的限制。为解决这些挑战，我们引入了一种基于LLM的端到端推荐框架：UniLLMRec。具体而言，UniLLMRec通过推荐链集成多阶段任务（例如召回、排序、重新排序）。为了处理大规模物品，我们提出

    arXiv:2404.00702v1 Announce Type: new  Abstract: Recommender systems aim to predict user interest based on historical behavioral data. They are mainly designed in sequential pipelines, requiring lots of data to train different sub-systems, and are hard to scale to new domains. Recently, Large Language Models (LLMs) have demonstrated remarkable generalized capabilities, enabling a singular model to tackle diverse recommendation tasks across various scenarios. Nonetheless, existing LLM-based recommendation systems utilize LLM purely for a single task of the recommendation pipeline. Besides, these systems face challenges in presenting large-scale item sets to LLMs in natural language format, due to the constraint of input length. To address these challenges, we introduce an LLM-based end-to-end recommendation framework: UniLLMRec. Specifically, UniLLMRec integrates multi-stage tasks (e.g. recall, ranking, re-ranking) via chain-of-recommendations. To deal with large-scale items, we propose
    

