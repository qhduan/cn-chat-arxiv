<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#22270;&#35889;&#32467;&#21512;&#65292;&#25552;&#39640;&#38646;&#26679;&#26412;&#23545;&#35937;&#29366;&#24577;&#20998;&#31867;&#24615;&#33021;</title><link>https://arxiv.org/abs/2403.12151</link><description>&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#39046;&#22495;&#29305;&#23450;&#20869;&#23481;&#34701;&#20837;&#30693;&#35782;&#22270;&#35889;&#65292;&#20197;&#22686;&#24378;&#38646;&#26679;&#26412;&#23545;&#35937;&#29366;&#24577;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Fusing Domain-Specific Content from Large Language Models into Knowledge Graphs for Enhanced Zero Shot Object State Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12151
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#22270;&#35889;&#32467;&#21512;&#65292;&#25552;&#39640;&#38646;&#26679;&#26412;&#23545;&#35937;&#29366;&#24577;&#20998;&#31867;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#21487;&#20197;&#26174;&#33879;&#26377;&#21161;&#20110;&#35299;&#20915;&#21508;&#31181;&#35270;&#35273;&#20219;&#21153;&#65292;&#20294;&#29983;&#25104;&#36825;&#31181;&#30693;&#35782;&#38656;&#35201;&#22823;&#37327;&#20154;&#21147;&#21644;&#26102;&#38388;&#25104;&#26412;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#36890;&#36807;&#35821;&#20041;&#23884;&#20837;&#29983;&#25104;&#21644;&#25552;&#20379;&#39046;&#22495;&#29305;&#23450;&#20449;&#24687;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#23558;LLM&#38598;&#25104;&#21040;&#19968;&#20010;&#27969;&#31243;&#20013;&#65292;&#35813;&#27969;&#31243;&#22312;&#35270;&#35273;&#22522;&#30784;&#38646;&#26679;&#26412;&#23545;&#35937;&#29366;&#24577;&#20998;&#31867;&#20219;&#21153;&#30340;&#32972;&#26223;&#19979;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#21644;&#39044;&#35757;&#32451;&#30340;&#35821;&#20041;&#21521;&#37327;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#28040;&#34701;&#30740;&#31350;&#24443;&#24213;&#30740;&#31350;&#20102;LLM&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#22522;&#20110;LLM&#30340;&#23884;&#20837;&#19982;&#36890;&#29992;&#30340;&#39044;&#35757;&#32451;&#23884;&#20837;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;&#20511;&#37492;&#36825;&#19968;&#28040;&#34701;&#30740;&#31350;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#23545;&#31454;&#20105;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#65292;&#20174;&#32780;&#31361;&#20986;&#20102;&#26368;&#26032;&#30340;&#34920;&#29616;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12151v1 Announce Type: new  Abstract: Domain-specific knowledge can significantly contribute to addressing a wide variety of vision tasks. However, the generation of such knowledge entails considerable human labor and time costs. This study investigates the potential of Large Language Models (LLMs) in generating and providing domain-specific information through semantic embeddings. To achieve this, an LLM is integrated into a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors in the context of the Vision-based Zero-shot Object State Classification task. We thoroughly examine the behavior of the LLM through an extensive ablation study. Our findings reveal that the integration of LLM-based embeddings, in combination with general-purpose pre-trained embeddings, leads to substantial performance improvements. Drawing insights from this ablation study, we conduct a comparative analysis against competing models, thereby highlighting the state-of-the-art perfor
&lt;/p&gt;</description></item><item><title>&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#26469;&#22312;&#35745;&#31639;&#39044;&#31639;&#20869;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;MeRino&#27169;&#22411;&#65292;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23637;&#29616;&#20986;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#31454;&#20105;&#24615;&#33021;&#30340;&#29305;&#28857;</title><link>https://arxiv.org/abs/2403.07921</link><description>&lt;p&gt;
Merino&#65306;&#22522;&#20110;&#29109;&#39537;&#21160;&#30340;IoT&#35774;&#22791;&#19978;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Merino: Entropy-driven Design for Generative Language Models on IoT Devices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07921
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#26469;&#22312;&#35745;&#31639;&#39044;&#31639;&#20869;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;MeRino&#27169;&#22411;&#65292;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23637;&#29616;&#20986;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#31454;&#20105;&#24615;&#33021;&#30340;&#29305;&#28857;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#20154;&#24037;&#26234;&#33021;&#29616;&#20195;&#26102;&#20195;&#30340;&#38761;&#21629;&#24615;&#36827;&#27493;&#65292;&#28982;&#32780;&#65292;&#30452;&#25509;&#37096;&#32626;LLMs&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#30828;&#20214;&#19978;&#65292;&#27604;&#22914;&#29289;&#32852;&#32593;&#65288;IoT&#65289;&#35774;&#22791;&#65292;&#30001;&#20110;&#20854;&#39640;&#35745;&#31639;&#25104;&#26412;&#32780;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35774;&#35745;&#33539;&#24335;&#26159;&#22312;&#32473;&#23450;&#30340;&#35745;&#31639;&#39044;&#31639;&#20869;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#12290;&#25972;&#20010;&#35774;&#35745;&#36807;&#31243;&#28041;&#21450;&#35299;&#20915;&#19968;&#20010;&#25968;&#23398;&#35268;&#21010;&#65288;MP&#65289;&#38382;&#39064;&#65292;&#21487;&#20197;&#22312;&#20960;&#20998;&#38047;&#20869;&#22312;CPU&#19978;&#23436;&#25104;&#65292;&#20351;&#20854;&#20960;&#20046;&#26159;&#38646;&#25104;&#26412;&#30340;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#35774;&#35745;&#30340;&#27169;&#22411;MeRino&#65292;&#22312;&#20061;&#20010;NLP&#19979;&#28216;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23545;&#25239;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#30340;&#31454;&#20105;&#24615;&#34920;&#29616;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;MeRino&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#33719;&#24471;&#20102;&#31867;&#20284;&#25110;&#26356;&#22909;&#30340;&#38646;&#24615;&#33021;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07921v1 Announce Type: cross  Abstract: Generative Large Language Models (LLMs) stand as a revolutionary advancement in the modern era of artificial intelligence (AI). However, directly deploying LLMs in resource-constrained hardware, such as Internet-of-Things (IoT) devices, is difficult due to their high computational cost. In this paper, we propose a novel information-entropy framework for designing mobile-friendly generative language models. Our key design paradigm is to maximize the entropy of transformer decoders within the given computational budgets. The whole design procedure involves solving a mathematical programming (MP) problem, which can be done on the CPU within minutes, making it nearly zero-cost. We evaluate our designed models, termed MeRino, across nine NLP downstream tasks, showing their competitive performance against the state-of-the-art autoregressive transformer models under the mobile setting. Notably, MeRino achieves similar or better zero performan
&lt;/p&gt;</description></item><item><title>Rainbow Teaming&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#25918;&#24335;&#25628;&#32034;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#23545;&#25239;&#24615;&#25552;&#31034;&#65292;&#21487;&#20197;&#24110;&#21161;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#65292;&#25552;&#39640;&#23433;&#20840;&#24615;&#65292;&#38382;&#31572;&#21644;&#32593;&#32476;&#23433;&#20840;&#31561;&#39046;&#22495;&#30340;&#27169;&#22411;&#28431;&#27934;&#12290;</title><link>https://arxiv.org/abs/2402.16822</link><description>&lt;p&gt;
&#24425;&#34425;&#22242;&#38431;&#65306;&#22810;&#26679;&#21270;&#23545;&#25239;&#24615;&#25552;&#31034;&#30340;&#24320;&#25918;&#24335;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16822
&lt;/p&gt;
&lt;p&gt;
Rainbow Teaming&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#25918;&#24335;&#25628;&#32034;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#23545;&#25239;&#24615;&#25552;&#31034;&#65292;&#21487;&#20197;&#24110;&#21161;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#65292;&#25552;&#39640;&#23433;&#20840;&#24615;&#65292;&#38382;&#31572;&#21644;&#32593;&#32476;&#23433;&#20840;&#31561;&#39046;&#22495;&#30340;&#27169;&#22411;&#28431;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#26222;&#36941;&#65292;&#29702;&#35299;&#21644;&#22686;&#24378;&#23427;&#20204;&#23545;&#29992;&#25143;&#36755;&#20837;&#30340;&#31283;&#20581;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#29992;&#20110;&#35782;&#21035;&#25932;&#23545;&#25552;&#31034;&#30340;&#26041;&#27861;&#24448;&#24448;&#19987;&#27880;&#20110;&#29305;&#23450;&#39046;&#22495;&#65292;&#32570;&#20047;&#22810;&#26679;&#24615;&#65292;&#25110;&#38656;&#35201;&#22823;&#37327;&#20154;&#24037;&#27880;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24425;&#34425;&#22242;&#38431;&#65292;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#22810;&#26679;&#21270;&#23545;&#25239;&#24615;&#25552;&#31034;&#30340;&#26032;&#26041;&#27861;&#12290;&#24425;&#34425;&#22242;&#38431;&#23558;&#23545;&#25239;&#24615;&#25552;&#31034;&#29983;&#25104;&#35270;&#20026;&#19968;&#20010;&#36136;&#37327; - &#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#24320;&#25918;&#24335;&#25628;&#32034;&#26469;&#29983;&#25104;&#26082;&#26377;&#25928;&#21448;&#22810;&#26679;&#30340;&#25552;&#31034;&#12290;&#23427;&#21487;&#20197;&#25581;&#31034;&#27169;&#22411;&#22312;&#24191;&#27867;&#39046;&#22495;&#20869;&#30340;&#33030;&#24369;&#24615;&#65292;&#21253;&#25324;&#26412;&#25991;&#20013;&#30340;&#23433;&#20840;&#24615;&#12289;&#38382;&#31572;&#21644;&#32593;&#32476;&#23433;&#20840;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#23545;&#30001;&#24425;&#34425;&#22242;&#38431;&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#21487;&#20197;&#25552;&#39640;&#26368;&#20808;&#36827;&#30340;LLMs&#30340;&#23433;&#20840;&#24615;&#65292;&#32780;&#19981;&#25439;&#23475;&#23427;&#20204;&#30340;&#19968;&#33324;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16822v1 Announce Type: new  Abstract: As large language models (LLMs) become increasingly prevalent across many real-world applications, understanding and enhancing their robustness to user inputs is of paramount importance. Existing methods for identifying adversarial prompts tend to focus on specific domains, lack diversity, or require extensive human annotations. To address these limitations, we present Rainbow Teaming, a novel approach for producing a diverse collection of adversarial prompts. Rainbow Teaming casts adversarial prompt generation as a quality-diversity problem, and uses open-ended search to generate prompts that are both effective and diverse. It can uncover a model's vulnerabilities across a broad range of domains including, in this paper, safety, question answering, and cybersecurity. We also demonstrate that fine-tuning on synthetic data generated by Rainbow Teaming improves the safety of state-of-the-art LLMs without hurting their general capabilities 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;BiMediX&#65292;&#19968;&#20010;&#26088;&#22312;&#23454;&#29616;&#33521;&#35821;&#21644;&#38463;&#25289;&#20271;&#35821;&#20043;&#38388;&#26080;&#32541;&#21307;&#23398;&#20132;&#20114;&#30340;&#21452;&#35821;&#21307;&#23398;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;LLM&#65292;&#24341;&#20837;&#20102;&#21322;&#33258;&#21160;&#21270;&#30340;&#32763;&#35793;&#27969;&#27700;&#32447;&#21644;&#20840;&#38754;&#30340;&#35780;&#20272;&#22522;&#20934;&#65292;&#21516;&#26102;&#25512;&#20986;&#20102;&#21253;&#21547;130&#19975;&#22810;&#26679;&#21270;&#21307;&#23398;&#20132;&#20114;&#30340;BiMed1.3M&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2402.13253</link><description>&lt;p&gt;
BiMediX: &#21452;&#35821;&#21307;&#23398;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;LLM
&lt;/p&gt;
&lt;p&gt;
BiMediX: Bilingual Medical Mixture of Experts LLM
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13253
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;BiMediX&#65292;&#19968;&#20010;&#26088;&#22312;&#23454;&#29616;&#33521;&#35821;&#21644;&#38463;&#25289;&#20271;&#35821;&#20043;&#38388;&#26080;&#32541;&#21307;&#23398;&#20132;&#20114;&#30340;&#21452;&#35821;&#21307;&#23398;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;LLM&#65292;&#24341;&#20837;&#20102;&#21322;&#33258;&#21160;&#21270;&#30340;&#32763;&#35793;&#27969;&#27700;&#32447;&#21644;&#20840;&#38754;&#30340;&#35780;&#20272;&#22522;&#20934;&#65292;&#21516;&#26102;&#25512;&#20986;&#20102;&#21253;&#21547;130&#19975;&#22810;&#26679;&#21270;&#21307;&#23398;&#20132;&#20114;&#30340;BiMed1.3M&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;BiMediX&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#26088;&#22312;&#23454;&#29616;&#22312;&#33521;&#35821;&#21644;&#38463;&#25289;&#20271;&#35821;&#20043;&#38388;&#26080;&#32541;&#20114;&#21160;&#30340;&#21452;&#35821;&#21307;&#23398;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;LLM&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#33521;&#35821;&#21644;&#38463;&#25289;&#20271;&#35821;&#20043;&#38388;&#20419;&#36827;&#20102;&#24191;&#27867;&#33539;&#22260;&#30340;&#21307;&#23398;&#20132;&#20114;&#65292;&#21253;&#25324;&#22810;&#36718;&#23545;&#35805;&#20197;&#35810;&#38382;&#20851;&#20110;&#24739;&#32773;&#30151;&#29366;&#21644;&#30149;&#21490;&#31561;&#39069;&#22806;&#32454;&#33410;&#12289;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20197;&#21450;&#24320;&#25918;&#24335;&#38382;&#39064;&#22238;&#31572;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21322;&#33258;&#21160;&#21270;&#30340;&#33521;&#35821;&#21040;&#38463;&#25289;&#20271;&#35821;&#32763;&#35793;&#27969;&#27700;&#32447;&#65292;&#32467;&#21512;&#20154;&#24037;&#20248;&#21270;&#20197;&#30830;&#20445;&#39640;&#36136;&#37327;&#30340;&#32763;&#35793;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#20010;&#29992;&#20110;&#38463;&#25289;&#20271;&#35821;&#21307;&#23398;LLMs&#30340;&#20840;&#38754;&#35780;&#20272;&#22522;&#20934;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#20986;&#20102;BiMed1.3M&#65292;&#19968;&#20010;&#28085;&#30422;130&#19975;&#21508;&#31181;&#21307;&#23398;&#20132;&#20114;&#30340;&#24191;&#27867;&#30340;&#38463;&#25289;&#20271;&#35821;-&#33521;&#35821;&#21452;&#35821;&#25351;&#20196;&#38598;&#65292;&#20135;&#29983;&#20102;&#36229;&#36807;6.32&#20159;&#20010;&#21307;&#30103;&#19987;&#19994;token&#20197;&#36827;&#34892;&#25351;&#20196;&#35843;&#25972;&#12290;&#25105;&#20204;&#30340;BiMed1.3M&#25968;&#25454;&#38598;&#21253;&#25324;25&#19975;&#20010;&#21512;&#25104;&#30340;&#21307;&#29983;-&#24739;&#32773;&#22810;&#36718;&#23545;&#35805;&#65292;&#24182;&#20445;&#25345;1:2&#30340;&#38463;&#25289;&#20271;&#35821;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13253v1 Announce Type: new  Abstract: In this paper, we introduce BiMediX, the first bilingual medical mixture of experts LLM designed for seamless interaction in both English and Arabic. Our model facilitates a wide range of medical interactions in English and Arabic, including multi-turn chats to inquire about additional details such as patient symptoms and medical history, multiple-choice question answering, and open-ended question answering. We propose a semi-automated English-to-Arabic translation pipeline with human refinement to ensure high-quality translations. We also introduce a comprehensive evaluation benchmark for Arabic medical LLMs. Furthermore, we introduce BiMed1.3M, an extensive Arabic-English bilingual instruction set covering 1.3 Million diverse medical interactions, resulting in over 632 million healthcare specialized tokens for instruction tuning. Our BiMed1.3M dataset includes 250k synthesized multi-turn doctor-patient chats and maintains a 1:2 Arabic-
&lt;/p&gt;</description></item><item><title>&#35757;&#32451;&#21160;&#24577;&#21487;&#22312;&#19981;&#21516;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#26041;&#27861;&#20043;&#38388;&#36827;&#34892;&#36716;&#31227;&#65292;&#36890;&#36807;&#36873;&#23450;&#30340;&#35757;&#32451;&#23454;&#20363;&#24494;&#35843;&#20027;&#27169;&#22411;&#23454;&#29616;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26356;&#39640;&#30340;&#35757;&#32451;&#25928;&#29575;</title><link>https://arxiv.org/abs/2310.06588</link><description>&lt;p&gt;
FTFT:&#36890;&#36807;&#36716;&#31227;&#35757;&#32451;&#21160;&#24577;&#23454;&#29616;&#39640;&#25928;&#19988;&#31283;&#20581;&#30340;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.06588
&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#21160;&#24577;&#21487;&#22312;&#19981;&#21516;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#26041;&#27861;&#20043;&#38388;&#36827;&#34892;&#36716;&#31227;&#65292;&#36890;&#36807;&#36873;&#23450;&#30340;&#35757;&#32451;&#23454;&#20363;&#24494;&#35843;&#20027;&#27169;&#22411;&#23454;&#29616;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26356;&#39640;&#30340;&#35757;&#32451;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#20998;&#24067;&#22806;&#36755;&#20837;&#30340;&#24433;&#21709;&#12290; &#25968;&#25454;&#38598;&#21046;&#22270;&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#21452;&#27169;&#22411;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#39640;&#24494;&#35843;PLMs&#30340;&#40065;&#26834;&#24615;&#12290; &#23427;&#28041;&#21450;&#22312;&#21407;&#22987;&#35757;&#32451;&#38598;&#19978;&#24494;&#35843;&#27169;&#22411;&#65288;&#21363;&#21442;&#32771;&#27169;&#22411;&#65289;&#65292;&#26681;&#25454;&#35757;&#32451;&#21160;&#24577;&#36873;&#25321;&#19968;&#20123;&#37325;&#35201;&#30340;&#35757;&#32451;&#23454;&#20363;&#65292;&#24182;&#20165;&#23545;&#36825;&#20123;&#36873;&#23450;&#30340;&#31034;&#20363;&#20877;&#27425;&#36827;&#34892;&#24494;&#35843;&#65288;&#21363;&#20027;&#27169;&#22411;&#65289;&#12290; &#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#38656;&#35201;&#23545;&#21516;&#19968;&#27169;&#22411;&#36827;&#34892;&#20004;&#27425;&#24494;&#35843;&#65292;&#36825;&#23545;&#20110;&#22823;&#22411;PLMs&#32780;&#35328;&#22312;&#35745;&#31639;&#19978;&#26159;&#26114;&#36149;&#30340;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#65288;1&#65289;&#35757;&#32451;&#21160;&#24577;&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#39044;&#35757;&#32451;&#26041;&#27861;&#20043;&#38388;&#20855;&#26377;&#39640;&#24230;&#21487;&#20256;&#36882;&#24615;&#65292;&#20197;&#21450;&#65288;2&#65289;&#20351;&#29992;&#36825;&#20123;&#36873;&#23450;&#30340;&#35757;&#32451;&#23454;&#20363;&#23545;&#20027;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#21487;&#20197;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#23454;&#29616;&#26356;&#39640;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290; &#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24494;&#35843;&#26041;&#27861;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.06588v2 Announce Type: replace  Abstract: Despite the massive success of fine-tuning Pre-trained Language Models (PLMs), they remain susceptible to out-of-distribution input. Dataset cartography is a simple yet effective dual-model approach that improves the robustness of fine-tuned PLMs. It involves fine-tuning a model on the original training set (i.e. reference model), selecting a subset of important training instances based on the training dynamics, and fine-tuning again only on these selected examples (i.e. main model). However, this approach requires fine-tuning the same model twice, which is computationally expensive for large PLMs. In this paper, we show that (1) training dynamics are highly transferable across model sizes and pre-training methods, and that (2) fine-tuning main models using these selected training instances achieves higher training efficiency than empirical risk minimization (ERM). Building on these observations, we propose a novel fine-tuning approa
&lt;/p&gt;</description></item></channel></rss>