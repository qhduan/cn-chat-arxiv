<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26080;&#30417;&#30563;&#24314;&#31435;&#20010;&#24615;&#21270;&#35789;&#20856;&#65292;&#26469;&#23450;&#21046;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20010;&#24615;&#29305;&#24449;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#20197;&#21487;&#25554;&#25300;&#30340;&#26041;&#24335;&#32467;&#21512;&#20116;&#20010;&#22823;&#31867;&#22240;&#32032;&#65292;&#23454;&#29616;&#23545;&#20010;&#24615;&#29305;&#24449;&#30340;&#31934;&#30830;&#25805;&#32437;&#12290;</title><link>http://arxiv.org/abs/2310.16582</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#24314;&#31435;&#20010;&#24615;&#21270;&#35789;&#20856;&#26469;&#23450;&#21046;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20010;&#24615;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons. (arXiv:2310.16582v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26080;&#30417;&#30563;&#24314;&#31435;&#20010;&#24615;&#21270;&#35789;&#20856;&#65292;&#26469;&#23450;&#21046;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20010;&#24615;&#29305;&#24449;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#20197;&#21487;&#25554;&#25300;&#30340;&#26041;&#24335;&#32467;&#21512;&#20116;&#20010;&#22823;&#31867;&#22240;&#32032;&#65292;&#23454;&#29616;&#23545;&#20010;&#24615;&#29305;&#24449;&#30340;&#31934;&#30830;&#25805;&#32437;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#22312;&#22609;&#36896;&#20154;&#31867;&#34920;&#36798;&#27169;&#24335;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36171;&#20104;&#21644;&#25805;&#32437;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20010;&#24615;&#29305;&#24449;&#22312;&#25552;&#21319;&#29992;&#25143;&#20307;&#39564;&#26041;&#38754;&#20855;&#26377;&#37325;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#26041;&#27861;&#35201;&#20040;&#20381;&#36182;&#20110;&#22312;&#23500;&#21547;&#20010;&#24615;&#34920;&#36798;&#30340;&#35821;&#26009;&#24211;&#19978;&#23545;LLM&#36827;&#34892;&#24494;&#35843;&#65292;&#35201;&#20040;&#38656;&#35201;&#25163;&#21160;&#21046;&#20316;&#25552;&#31034;&#26469;&#35825;&#23548;LLM&#20135;&#29983;&#20010;&#24615;&#21270;&#22238;&#24212;&#12290;&#21069;&#32773;&#38656;&#35201;&#22823;&#37327;&#26102;&#38388;&#21644;&#36164;&#28304;&#26469;&#25910;&#38598;&#36275;&#22815;&#30340;&#35757;&#32451;&#26679;&#26412;&#65292;&#32780;&#21518;&#32773;&#21487;&#33021;&#26080;&#27861;&#31934;&#30830;&#25805;&#32437;&#20010;&#24615;&#29305;&#24449;&#20197;&#36798;&#21040;&#32454;&#31890;&#24230;&#30340;&#27700;&#24179;&#65288;&#20363;&#22914;&#65292;&#22312;&#20943;&#23569;&#24320;&#25918;&#24615;&#30340;&#21516;&#26102;&#25552;&#39640;&#23452;&#20154;&#24615;&#65289;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#23450;&#21046;LLM&#20013;&#30340;&#20010;&#24615;&#29305;&#24449;&#65292;&#20801;&#35768;&#20197;&#21487;&#25554;&#25300;&#30340;&#26041;&#24335;&#32467;&#21512;&#20116;&#20010;&#22823;&#31867;&#22240;&#32032;&#65288;&#21363;&#24320;&#25918;&#24615;&#12289;&#36131;&#20219;&#24515;&#12289;&#22806;&#21521;&#24615;&#12289;&#23452;&#20154;&#24615;&#21644;&#31070;&#32463;&#36136;&#65289;&#30340;&#20219;&#24847;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personality plays a pivotal role in shaping human expression patterns, and empowering and manipulating large language models (LLMs) with personality traits holds significant promise in enhancing the user experience of LLMs. However, prior approaches either rely on fine-tuning LLMs on a corpus enriched with personalized expressions or necessitate the manual crafting of prompts to induce LLMs to produce personalized responses. The former approaches demand substantial time and resources for collecting sufficient training examples while the latter might fail in enabling the precise manipulation of the personality traits at a fine-grained level (e.g., achieving high agreeableness while reducing openness). In this study, we introduce a novel approach for tailoring personality traits within LLMs, allowing for the incorporation of any combination of the Big Five factors (i.e., openness, conscientiousness, extraversion, agreeableness, and neuroticism) in a pluggable manner. This is achieved by 
&lt;/p&gt;</description></item></channel></rss>