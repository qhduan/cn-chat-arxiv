<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>Aurora-M &#26159;&#31532;&#19968;&#20010;&#26681;&#25454;&#32654;&#22269;&#34892;&#25919;&#21629;&#20196;&#36827;&#34892;&#32418;&#38431;&#27979;&#35797;&#30340;&#24320;&#28304;&#22810;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#33521;&#35821;&#12289;&#33452;&#20848;&#35821;&#12289;&#21360;&#22320;&#35821;&#12289;&#26085;&#35821;&#12289;&#36234;&#21335;&#35821;&#21644;&#20195;&#30721;&#19978;&#35757;&#32451;&#65292;&#19981;&#26029;&#39044;&#35757;&#32451;&#65292;&#21253;&#25324;&#20102;&#20154;&#24037;&#23457;&#26680;&#30340;&#23433;&#20840;&#35828;&#26126;&#65292;&#24635;&#35757;&#32451; token &#25968;&#36229;&#36807; 2 &#19975;&#20159;&#20010;</title><link>https://arxiv.org/abs/2404.00399</link><description>&lt;p&gt;
Aurora-M: &#26681;&#25454;&#32654;&#22269;&#34892;&#25919;&#21629;&#20196;&#65292;&#31532;&#19968;&#20010;&#24320;&#28304;&#30340;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#32418;&#38431;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00399
&lt;/p&gt;
&lt;p&gt;
Aurora-M &#26159;&#31532;&#19968;&#20010;&#26681;&#25454;&#32654;&#22269;&#34892;&#25919;&#21629;&#20196;&#36827;&#34892;&#32418;&#38431;&#27979;&#35797;&#30340;&#24320;&#28304;&#22810;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#33521;&#35821;&#12289;&#33452;&#20848;&#35821;&#12289;&#21360;&#22320;&#35821;&#12289;&#26085;&#35821;&#12289;&#36234;&#21335;&#35821;&#21644;&#20195;&#30721;&#19978;&#35757;&#32451;&#65292;&#19981;&#26029;&#39044;&#35757;&#32451;&#65292;&#21253;&#25324;&#20102;&#20154;&#24037;&#23457;&#26680;&#30340;&#23433;&#20840;&#35828;&#26126;&#65292;&#24635;&#35757;&#32451; token &#25968;&#36229;&#36807; 2 &#19975;&#20159;&#20010;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#25903;&#25345;&#22810;&#31181;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#65292;&#20294;&#26159;&#23427;&#20204;&#22312;&#35757;&#32451;&#26102;&#39640;&#26114;&#30340;&#35745;&#31639;&#25104;&#26412;&#38480;&#21046;&#20102;&#21487;&#35775;&#38382;&#24615;&#12290;BLOOM &#21644; StarCoder &#31561;&#20513;&#35758;&#26088;&#22312;&#20351;&#39044;&#35757;&#32451;&#27169;&#22411;&#23545;&#20110;&#21327;&#20316;&#31038;&#21306;&#24320;&#21457;&#26356;&#20855;&#27665;&#20027;&#24615;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23384;&#22312;&#30340;&#27169;&#22411;&#38754;&#20020;&#19968;&#20123;&#25361;&#25112;&#65306;&#22810;&#35821;&#35328;&#33021;&#21147;&#26377;&#38480;&#65292;&#25345;&#32493;&#30340;&#39044;&#35757;&#32451;&#20250;&#23548;&#33268;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#32780;&#20174;&#22836;&#24320;&#22987;&#39044;&#35757;&#32451;&#21448;&#20855;&#26377;&#39640;&#26114;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#19988;&#38656;&#35201;&#36981;&#23432;&#20154;&#24037;&#26234;&#33021;&#23433;&#20840;&#21644;&#21457;&#23637;&#27861;&#24459;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102; Aurora-M&#65292;&#19968;&#20010;&#21253;&#21547; 15B &#21442;&#25968;&#30340;&#22810;&#35821;&#35328;&#24320;&#28304;&#27169;&#22411;&#65292;&#35757;&#32451;&#35821;&#35328;&#21253;&#25324;&#33521;&#35821;&#12289;&#33452;&#20848;&#35821;&#12289;&#21360;&#22320;&#35821;&#12289;&#26085;&#35821;&#12289;&#36234;&#21335;&#35821;&#21644;&#20195;&#30721;&#12290;Aurora-M &#19981;&#26029;&#20174; StarCoderPlus &#19978;&#39044;&#35757;&#32451;&#65292;&#39069;&#22806;&#35757;&#32451;&#20102; 4350 &#20159;&#20010; token&#65292;&#24635;&#35757;&#32451; token &#25968;&#36229;&#36807;&#20102; 2 &#19975;&#20159;&#20010;&#12290;&#23427;&#26159;&#31532;&#19968;&#20010;&#22312;&#20154;&#24037;&#23457;&#26680;&#30340;&#23433;&#20840;&#35828;&#26126;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#24320;&#28304;&#22810;&#35821;&#35328;&#27169;&#22411;&#65292;&#20351;&#20854;&#24320;&#21457;&#19982;&#20256;&#32479;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00399v1 Announce Type: cross  Abstract: Pretrained language models underpin several AI applications, but their high computational cost for training limits accessibility. Initiatives such as BLOOM and StarCoder aim to democratize access to pretrained models for collaborative community development. However, such existing models face challenges: limited multilingual capabilities, continual pretraining causing catastrophic forgetting, whereas pretraining from scratch is computationally expensive, and compliance with AI safety and development laws. This paper presents Aurora-M, a 15B parameter multilingual open-source model trained on English, Finnish, Hindi, Japanese, Vietnamese, and code. Continually pretrained from StarCoderPlus on 435 billion additional tokens, Aurora-M surpasses 2 trillion tokens in total training token count. It is the first open-source multilingual model fine-tuned on human-reviewed safety instructions, thus aligning its development not only with conventio
&lt;/p&gt;</description></item><item><title>&#36880;&#23618;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#26032;&#26041;&#27861;LISA&#22312;&#24494;&#35843;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#35760;&#24518;&#25104;&#26412;&#20302;&#19988;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.17919</link><description>&lt;p&gt;
LISA&#65306;&#29992;&#20110;&#39640;&#25928;&#20869;&#23384;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#30340;&#36880;&#23618;&#37325;&#35201;&#24615;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17919
&lt;/p&gt;
&lt;p&gt;
&#36880;&#23618;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#26032;&#26041;&#27861;LISA&#22312;&#24494;&#35843;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#35760;&#24518;&#25104;&#26412;&#20302;&#19988;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#33258;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39318;&#27425;&#20986;&#29616;&#20197;&#26469;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#36827;&#23637;&#65292;&#28982;&#32780;&#23427;&#20204;&#24040;&#22823;&#30340;&#20869;&#23384;&#28040;&#32791;&#24050;&#25104;&#20026;&#22823;&#35268;&#27169;&#35757;&#32451;&#30340;&#20027;&#35201;&#38556;&#30861;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#35832;&#22914;&#20302;&#31209;&#35843;&#25972;&#65288;LoRA&#65289;&#20043;&#31867;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#25216;&#26415;&#26469;&#32531;&#35299;&#36825;&#19968;&#38382;&#39064;&#65292;&#20294;&#22312;&#22823;&#22810;&#25968;&#22823;&#35268;&#27169;&#24494;&#35843;&#35774;&#32622;&#20013;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#20173;&#26080;&#27861;&#19982;&#23436;&#25972;&#21442;&#25968;&#35757;&#32451;&#30456;&#21305;&#37197;&#12290;&#20026;&#24357;&#34917;&#36825;&#19968;&#19981;&#36275;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LoRA&#22312;&#24494;&#35843;&#20219;&#21153;&#20013;&#30340;&#36880;&#23618;&#29305;&#24615;&#65292;&#24182;&#35266;&#23519;&#21040;&#19981;&#21516;&#23618;&#20043;&#38388;&#26435;&#37325;&#33539;&#25968;&#30340;&#24322;&#24120;&#20559;&#26012;&#12290;&#21033;&#29992;&#36825;&#19968;&#20851;&#38190;&#35266;&#23519;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#31616;&#21333;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#22312;&#35760;&#24518;&#25104;&#26412;&#20302;&#20110;LoRA&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#24191;&#27867;&#30340;&#35774;&#32622;&#20013;&#20248;&#20110;LoRA&#21644;&#23436;&#25972;&#21442;&#25968;&#35757;&#32451;&#12290;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;Layerwise Importance Sampled AdamW&#65288;LISA&#65289;&#65292;&#36825;&#26159;LoRA&#30340;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#24212;&#29992;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17919v1 Announce Type: cross  Abstract: The machine learning community has witnessed impressive advancements since the first appearance of large language models (LLMs), yet their huge memory consumption has become a major roadblock to large-scale training. Parameter Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been proposed to alleviate this problem, but their performance still fails to match full parameter training in most large-scale fine-tuning settings. Attempting to complement this deficiency, we investigate layerwise properties of LoRA on fine-tuning tasks and observe an uncommon skewness of weight norms across different layers. Utilizing this key observation, a surprisingly simple training strategy is discovered, which outperforms both LoRA and full parameter training in a wide range of settings with memory costs as low as LoRA. We name it Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA, which applies the idea of
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20013;&#25991;&#25991;&#26412;&#30340;&#21019;&#26032;&#22411;OIE&#27169;&#22411;APRCOIE&#65292;&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#25277;&#21462;&#27169;&#24335;&#12289;&#23450;&#20041;&#26032;&#30340;&#27169;&#24335;&#24418;&#24335;&#20197;&#21450;&#35774;&#35745;&#24352;&#37327;&#35745;&#31639;&#36807;&#28388;&#22120;&#31561;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#22810;&#26679;&#22797;&#26434;&#20013;&#25991;&#35821;&#27861;&#29616;&#35937;&#30340;&#22788;&#29702;&#65292;&#24182;&#22312;&#35780;&#20272;&#20013;&#34920;&#29616;&#20248;&#36234;&#65292;&#25299;&#23637;&#20102;OIE&#24615;&#33021;&#36793;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.10758</link><description>&lt;p&gt;
&#35268;&#21017;&#20173;&#28982;&#36866;&#29992;&#20110;&#24320;&#25918;&#20449;&#24687;&#25277;&#21462;
&lt;/p&gt;
&lt;p&gt;
Rules still work for Open Information Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10758
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20013;&#25991;&#25991;&#26412;&#30340;&#21019;&#26032;&#22411;OIE&#27169;&#22411;APRCOIE&#65292;&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#25277;&#21462;&#27169;&#24335;&#12289;&#23450;&#20041;&#26032;&#30340;&#27169;&#24335;&#24418;&#24335;&#20197;&#21450;&#35774;&#35745;&#24352;&#37327;&#35745;&#31639;&#36807;&#28388;&#22120;&#31561;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#22810;&#26679;&#22797;&#26434;&#20013;&#25991;&#35821;&#27861;&#29616;&#35937;&#30340;&#22788;&#29702;&#65292;&#24182;&#22312;&#35780;&#20272;&#20013;&#34920;&#29616;&#20248;&#36234;&#65292;&#25299;&#23637;&#20102;OIE&#24615;&#33021;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#25918;&#20449;&#24687;&#25277;&#21462;&#65288;OIE&#65289;&#26088;&#22312;&#20174;&#33258;&#28982;&#35821;&#35328;&#25991;&#26412;&#20013;&#25552;&#21462;&#34920;&#38754;&#20851;&#31995;&#21450;&#20854;&#23545;&#24212;&#30340;&#21442;&#25968;&#65292;&#32780;&#19981;&#32771;&#34385;&#39046;&#22495;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20013;&#25991;&#25991;&#26412;&#30340;&#21019;&#26032;&#22411;OIE&#27169;&#22411;APRCOIE&#12290;&#19982;&#20808;&#21069;&#30340;&#27169;&#22411;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#33258;&#20027;&#29983;&#25104;&#25277;&#21462;&#27169;&#24335;&#12290;&#35813;&#27169;&#22411;&#20026;&#20013;&#25991;OIE&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#24335;&#24418;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#33258;&#21160;&#21270;&#30340;&#27169;&#24335;&#29983;&#25104;&#26041;&#27861;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#22810;&#26679;&#22797;&#26434;&#30340;&#20013;&#25991;&#35821;&#27861;&#29616;&#35937;&#12290;&#25105;&#20204;&#22522;&#20110;&#24352;&#37327;&#35745;&#31639;&#35774;&#35745;&#20102;&#19968;&#20010;&#21021;&#27493;&#36807;&#28388;&#22120;&#65292;&#20197;&#20415;&#39640;&#25928;&#22320;&#36827;&#34892;&#25277;&#21462;&#36807;&#31243;&#12290;&#20026;&#20102;&#35757;&#32451;&#27169;&#22411;&#65292;&#25105;&#20204;&#25163;&#21160;&#26631;&#27880;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20013;&#25991;OIE&#25968;&#25454;&#38598;&#12290;&#22312;&#27604;&#36739;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;APRCOIE&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#20013;&#25991;OIE&#27169;&#22411;&#65292;&#24182;&#26174;&#33879;&#25299;&#23637;&#20102;&#21487;&#23454;&#29616;&#30340;OIE&#24615;&#33021;&#36793;&#30028;&#12290;APRCOIE&#30340;&#20195;&#30721;&#21644;&#26631;&#27880;&#25968;&#25454;&#38598;&#24050;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10758v1 Announce Type: new  Abstract: Open information extraction (OIE) aims to extract surface relations and their corresponding arguments from natural language text, irrespective of domain. This paper presents an innovative OIE model, APRCOIE, tailored for Chinese text. Diverging from previous models, our model generates extraction patterns autonomously. The model defines a new pattern form for Chinese OIE and proposes an automated pattern generation methodology. In that way, the model can handle a wide array of complex and diverse Chinese grammatical phenomena. We design a preliminary filter based on tensor computing to conduct the extraction procedure efficiently. To train the model, we manually annotated a large-scale Chinese OIE dataset. In the comparative evaluation, we demonstrate that APRCOIE outperforms state-of-the-art Chinese OIE models and significantly expands the boundaries of achievable OIE performance. The code of APRCOIE and the annotated dataset are releas
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102; CodeUltraFeedback &#25968;&#25454;&#38598;&#65292;&#36890;&#36807; AI &#21453;&#39304;&#20351; 14 &#31181;&#19981;&#21516;&#30340; LLMs &#23545; 10,000 &#20010;&#22797;&#26434;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#20351;&#29992; LLM-as-a-Judge &#26041;&#27861;&#35780;&#20272;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272; LLM &#23545;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934; CODAL-Bench&#12290;</title><link>https://arxiv.org/abs/2403.09032</link><description>&lt;p&gt;
CodeUltraFeedback&#65306;&#19968;&#31181;&#29992;&#20110;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;LLM&#20316;&#20026;&#27861;&#23448;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09032
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102; CodeUltraFeedback &#25968;&#25454;&#38598;&#65292;&#36890;&#36807; AI &#21453;&#39304;&#20351; 14 &#31181;&#19981;&#21516;&#30340; LLMs &#23545; 10,000 &#20010;&#22797;&#26434;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#20351;&#29992; LLM-as-a-Judge &#26041;&#27861;&#35780;&#20272;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272; LLM &#23545;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934; CODAL-Bench&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24615;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24037;&#20316;&#65292;&#38656;&#35201;&#35780;&#20272;&#22797;&#26434;&#25991;&#26412;LLMs&#30340;&#36755;&#20986;&#12290;&#29616;&#26377;&#22522;&#20934;&#20208;&#36182;&#33258;&#21160;&#21270;&#25351;&#26631;&#21644;&#38745;&#24577;&#20998;&#26512;&#24037;&#20855;&#65292;&#26410;&#33021;&#35780;&#20272;&#29992;&#25143;&#25351;&#20196;&#21644;LLM&#36755;&#20986;&#20013;&#30340;&#24494;&#22937;&#20043;&#22788;&#65292;&#31361;&#26174;&#20102;&#23545;LLM&#20559;&#22909;&#23545;&#40784;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#30340;&#38656;&#27714;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;CodeUltraFeedback&#65292;&#19968;&#20010;&#21253;&#21547;10,000&#20010;&#22797;&#26434;&#25351;&#20196;&#30340;&#20559;&#22909;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;AI&#21453;&#39304;&#26469;&#35843;&#25972;&#21644;&#23545;&#40784;LLMs&#19982;&#32534;&#31243;&#20559;&#22909;&#12290;&#25105;&#20204;&#20351;&#29992;14&#31181;&#19981;&#21516;&#30340;LLMs&#23545;&#36825;&#20123;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#28982;&#21518;&#26681;&#25454;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#36827;&#34892;&#27880;&#37322;&#65292;&#20351;&#29992;GPT-3.5&#30340;LLM&#20316;&#20026;&#27861;&#23448;&#26041;&#27861;&#20135;&#29983;&#25968;&#23383;&#21644;&#25991;&#26412;&#21453;&#39304;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;CODAL-Bench&#65292;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLM&#19982;&#36825;&#20123;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;C
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09032v1 Announce Type: cross  Abstract: Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavour that requires assessing intricate textual LLMs' outputs. By relying on automated metrics and static analysis tools, existing benchmarks fail to assess nuances in user instructions and LLM outputs, highlighting the need for large-scale datasets and benchmarks for LLM preference alignment. In this paper, we introduce CodeUltraFeedback, a preference dataset of 10,000 complex instructions to tune and align LLMs to coding preferences through AI feedback. We generate responses to the instructions using a pool of 14 diverse LLMs, which we then annotate according to their alignment with five coding preferences using the LLM-as-a-Judge approach with GPT-3.5, producing both numerical and textual feedback. We also present CODAL-Bench, a benchmark for assessing LLM alignment with these coding preferences. Our results show that C
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;OmniPred&#26694;&#26550;&#65292;&#29992;&#20110;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#30340;&#31471;&#21040;&#31471;&#22238;&#24402;&#22120;&#65292;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#35757;&#32451;&#26102;&#65292;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#22238;&#24402;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.14547</link><description>&lt;p&gt;
OmniPred&#65306;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#22238;&#24402;&#22120;
&lt;/p&gt;
&lt;p&gt;
OmniPred: Language Models as Universal Regressors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14547
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;OmniPred&#26694;&#26550;&#65292;&#29992;&#20110;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#30340;&#31471;&#21040;&#31471;&#22238;&#24402;&#22120;&#65292;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#35757;&#32451;&#26102;&#65292;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#22238;&#24402;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#39564;&#35774;&#35745;&#30340;&#24191;&#38420;&#39046;&#22495;&#20013;&#65292;&#22238;&#24402;&#19968;&#30452;&#26159;&#19968;&#20010;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#20934;&#30830;&#39044;&#27979;&#31995;&#32479;&#25110;&#27169;&#22411;&#22312;&#32473;&#23450;&#19968;&#32452;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#25351;&#26631;&#65292;&#20294;&#20256;&#32479;&#19978;&#21482;&#38480;&#20110;&#36866;&#29992;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;OmniPred&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#31471;&#21040;&#31471;&#22238;&#24402;&#22120;&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#26469;&#33258;&#22810;&#26679;&#30495;&#23454;&#19990;&#30028;&#23454;&#39564;&#30340;$(x,y)$&#35780;&#20272;&#25968;&#25454;&#12290;&#36890;&#36807;&#20351;&#29992;&#28304;&#33258;Google Vizier&#30340;&#25968;&#25454;&#65292;&#36825;&#26159;&#19990;&#30028;&#19978;&#26368;&#22823;&#30340;&#40657;&#30418;&#20248;&#21270;&#25968;&#25454;&#24211;&#20043;&#19968;&#65292;&#25105;&#20204;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;&#20165;&#36890;&#36807;&#25968;&#23398;&#21442;&#25968;&#21644;&#20540;&#30340;&#25991;&#26412;&#34920;&#31034;&#65292;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#36827;&#34892;&#38750;&#24120;&#31934;&#30830;&#30340;&#25968;&#20540;&#22238;&#24402;&#65292;&#22914;&#26524;&#26377;&#26426;&#20250;&#35757;&#32451;&#22810;&#20010;&#20219;&#21153;&#65292;&#21017;&#21487;&#20197;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#30340;&#22238;&#24402;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14547v1 Announce Type: cross  Abstract: Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27010;&#29575;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#38480;&#21046;&#65292;&#24341;&#20837;&#20102;&#36125;&#21494;&#26031;&#35821;&#35328;&#25512;&#29702;&#25968;&#25454;&#38598;&#65288;BLInD&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#31181;&#35299;&#20915;&#31574;&#30053;&#65292;&#21253;&#25324;Python&#20195;&#30721;&#21644;&#27010;&#29575;&#25512;&#29702;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09614</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#27010;&#29575;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Reasoning in Generative Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27010;&#29575;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#38480;&#21046;&#65292;&#24341;&#20837;&#20102;&#36125;&#21494;&#26031;&#35821;&#35328;&#25512;&#29702;&#25968;&#25454;&#38598;&#65288;BLInD&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#31181;&#35299;&#20915;&#31574;&#30053;&#65292;&#21253;&#25324;Python&#20195;&#30721;&#21644;&#27010;&#29575;&#25512;&#29702;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22788;&#29702;&#28041;&#21450;&#27010;&#29575;&#20540;&#26126;&#30830;&#37327;&#21270;&#30340;&#25991;&#26412;&#25512;&#29702;&#38382;&#39064;&#26102;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#27010;&#29575;&#25512;&#29702;&#23545;&#20110;&#20174;&#26085;&#24120;&#23545;&#35805;&#21040;&#21307;&#23398;&#20915;&#31574;&#31561;&#21508;&#31181;&#24773;&#22659;&#37117;&#24456;&#37325;&#35201;&#12290;&#23613;&#31649;LLMs&#22312;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#26377;&#25152;&#25913;&#36827;&#65292;&#20294;&#22312;&#27010;&#29575;&#25512;&#29702;&#26041;&#38754;&#20173;&#28982;&#23384;&#22312;&#26174;&#33879;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#36125;&#21494;&#26031;&#35821;&#35328;&#25512;&#29702;&#25968;&#25454;&#38598;&#65288;BLInD&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#27979;&#35797;LLMs&#27010;&#29575;&#25512;&#29702;&#33021;&#21147;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#26032;&#25968;&#25454;&#38598;&#26469;&#35814;&#32454;&#35828;&#26126;LLMs&#22312;&#28041;&#21450;&#27010;&#29575;&#25512;&#29702;&#30340;&#20219;&#21153;&#20013;&#30340;&#29305;&#23450;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#31181;&#23558;&#38382;&#39064;&#26144;&#23556;&#21040;&#19981;&#21516;&#24418;&#24335;&#34920;&#31034;&#30340;&#31574;&#30053;&#65292;&#21253;&#25324;Python&#20195;&#30721;&#21644;&#27010;&#29575;&#25512;&#29702;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09614v1 Announce Type: cross  Abstract: This paper considers the challenges that Large Language Models (LLMs) face when reasoning over text that includes information involving uncertainty explicitly quantified via probability values. This type of reasoning is relevant to a variety of contexts ranging from everyday conversations to medical decision-making. Despite improvements in the mathematical reasoning capabilities of LLMs, they still exhibit significant difficulties when it comes to probabilistic reasoning. To deal with this problem, we first introduce the Bayesian Linguistic Inference Dataset (BLInD), a new dataset specifically designed to test the probabilistic reasoning capabilities of LLMs. We then leverage this new dataset to thoroughly illustrate the specific limitations of LLMs for tasks involving probabilistic reasoning and present several strategies that map the problem to different formal representations, including Python code, probabilistic inference algorithm
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#22810;&#26679;&#30340;&#20154;&#31867;&#20559;&#22909;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#28151;&#21512;&#20559;&#22909;&#20998;&#24067;&#24182;&#20351;&#29992;MaxMin&#23545;&#40784;&#30446;&#26631;&#26469;&#26356;&#22909;&#22320;&#34920;&#31034;&#20154;&#31867;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.08925</link><description>&lt;p&gt;
MaxMin-RLHF:&#38754;&#21521;&#20855;&#26377;&#22810;&#26679;&#30340;&#20154;&#31867;&#20559;&#22909;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20844;&#24179;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
MaxMin-RLHF: Towards Equitable Alignment of Large Language Models with Diverse Human Preferences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08925
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#22810;&#26679;&#30340;&#20154;&#31867;&#20559;&#22909;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#28151;&#21512;&#20559;&#22909;&#20998;&#24067;&#24182;&#20351;&#29992;MaxMin&#23545;&#40784;&#30446;&#26631;&#26469;&#26356;&#22909;&#22320;&#34920;&#31034;&#20154;&#31867;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#23398;&#20064;(RLHF)&#36890;&#36807;&#20351;&#29992;&#20174;&#20559;&#22909;&#25968;&#25454;&#20013;&#27966;&#29983;&#30340;&#21333;&#19968;&#22870;&#21169;&#27169;&#22411;&#26469;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#19982;&#20154;&#31867;&#20559;&#22909;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24573;&#35270;&#20102;&#20174;&#22810;&#20010;&#29992;&#25143;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#20154;&#31867;&#20559;&#22909;&#30340;&#20016;&#23500;&#22810;&#26679;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20986;&#20102;&#20351;&#29992;&#21333;&#19968;&#22870;&#21169;RLHF&#36827;&#34892;&#23545;&#40784;&#30340;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#65292;&#20174;&#32780;&#20984;&#26174;&#20102;&#20854;&#26080;&#27861;&#34920;&#31034;&#22810;&#26679;&#30340;&#20154;&#31867;&#20559;&#22909;&#12290;&#20026;&#20102;&#25552;&#20379;&#19968;&#20010;&#20844;&#24179;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#36890;&#36807;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#23398;&#20064;&#20102;&#19968;&#31181;&#28151;&#21512;&#20559;&#22909;&#20998;&#24067;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#31038;&#20250;&#36873;&#25321;&#29702;&#35770;&#20013;&#30340;&#24179;&#31561;&#21407;&#21017;&#21551;&#21457;&#30340;MaxMin&#23545;&#40784;&#30446;&#26631;&#26469;&#26356;&#22909;&#22320;&#34920;&#31034;&#22810;&#26679;&#30340;&#20154;&#31867;&#20559;&#22909;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#20998;&#24067;&#31283;&#20581;&#20248;&#21270;&#21644;&#36890;&#29992;&#25928;&#29992;RL&#30340;&#32852;&#31995;&#65292;&#20174;&#32780;&#31361;&#26174;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26222;&#36866;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08925v1 Announce Type: cross Abstract: Reinforcement Learning from Human Feedback (RLHF) aligns language models to human preferences by employing a singular reward model derived from preference data. However, such an approach overlooks the rich diversity of human preferences inherent in data collected from multiple users. In this work, we first derive an impossibility result of alignment with single reward RLHF, thereby highlighting its insufficiency in representing diverse human preferences. To provide an equitable solution to the problem, we learn a mixture of preference distributions via an expectation-maximization algorithm and propose a MaxMin alignment objective for policy learning inspired by the Egalitarian principle in social choice theory to better represent diverse human preferences. We elucidate the connection of our proposed approach to distributionally robust optimization and general utility RL, thereby highlighting the generality and robustness of our proposed
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20840;&#38754;&#35780;&#20272;&#20102;LLMs&#22312;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#21644;&#25512;&#29702;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;GPT-4&#26356;&#36866;&#21512;&#20316;&#20026;&#25512;&#29702;&#21161;&#25163;&#65292;&#24182;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#20102;&#31934;&#35843;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2305.13168</link><description>&lt;p&gt;
LLMs&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#21644;&#25512;&#29702;&#65306;&#26368;&#26032;&#21151;&#33021;&#19982;&#26410;&#26469;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2305.13168
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20840;&#38754;&#35780;&#20272;&#20102;LLMs&#22312;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#21644;&#25512;&#29702;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;GPT-4&#26356;&#36866;&#21512;&#20316;&#20026;&#25512;&#29702;&#21161;&#25163;&#65292;&#24182;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#20102;&#31934;&#35843;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#26500;&#24314;&#21644;&#25512;&#29702;&#20013;&#30340;&#25968;&#37327;&#21270;&#21644;&#36136;&#21270;&#35780;&#20272;&#36827;&#34892;&#20102;&#35814;&#23613;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#22312;&#20843;&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#37325;&#28857;&#20851;&#27880;&#28085;&#30422;&#23454;&#20307;&#21644;&#20851;&#31995;&#25552;&#21462;&#12289;&#20107;&#20214;&#25552;&#21462;&#12289;&#38142;&#25509;&#39044;&#27979;&#21644;&#38382;&#31572;&#22235;&#20010;&#20856;&#22411;&#20219;&#21153;&#65292;&#20174;&#32780;&#20840;&#38754;&#25506;&#32034;&#20102;LLMs&#22312;&#26500;&#24314;&#21644;&#25512;&#29702;&#39046;&#22495;&#30340;&#34920;&#29616;&#12290;&#32463;&#39564;&#24615;&#30740;&#31350;&#21457;&#29616;&#65292;&#20197;GPT-4&#20026;&#20195;&#34920;&#30340;LLMs&#26356;&#36866;&#21512;&#20316;&#20026;&#25512;&#29702;&#21161;&#25163;&#65292;&#32780;&#19981;&#26159;&#23569;&#26679;&#26412;&#20449;&#24687;&#25552;&#21462;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#34429;&#28982;GPT-4&#22312;&#19982;KG&#26500;&#24314;&#30456;&#20851;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#25512;&#29702;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#20986;&#33394;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#20102;&#31934;&#35843;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#35843;&#26597;&#36824;&#25193;&#23637;&#21040;LLMs&#22312;&#20449;&#24687;&#25552;&#21462;&#26041;&#38754;&#30340;&#28508;&#22312;&#27867;&#21270;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#34394;&#25311;&#30693;&#35782;&#25552;&#21462;&#30340;&#26500;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2305.13168v2 Announce Type: replace-cross  Abstract: This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We engage in experiments across eight diverse datasets, focusing on four representative tasks encompassing entity and relation extraction, event extraction, link prediction, and question-answering, thereby thoroughly exploring LLMs' performance in the domain of construction and inference. Empirically, our findings suggest that LLMs, represented by GPT-4, are more suited as inference assistants rather than few-shot information extractors. Specifically, while GPT-4 exhibits good performance in tasks related to KG construction, it excels further in reasoning tasks, surpassing fine-tuned models in certain cases. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, leading to the proposition of a Virtual Knowledge Extr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#29615;&#22659;&#19979;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#21512;&#29702;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#65292;&#39640;&#25928;&#22320;&#23558;&#35821;&#35328;&#27169;&#22411;&#19987;&#38376;&#29992;&#20110;&#20219;&#21153;&#29305;&#23450;&#30340;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2308.10462</link><description>&lt;p&gt;
&#25506;&#32034;&#22823;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models. (arXiv:2308.10462v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#29615;&#22659;&#19979;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#21512;&#29702;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#65292;&#39640;&#25928;&#22320;&#23558;&#35821;&#35328;&#27169;&#22411;&#19987;&#38376;&#29992;&#20110;&#20219;&#21153;&#29305;&#23450;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23637;&#31034;&#20102;&#22312;&#27809;&#26377;&#29305;&#23450;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#21487;&#26681;&#25454;&#33258;&#28982;&#35821;&#35328;&#24847;&#22270;&#29983;&#25104;&#20934;&#30830;&#30340;&#20195;&#30721;&#29255;&#27573;&#30340;&#21360;&#35937;&#33021;&#21147;&#12290;&#23613;&#31649;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#31361;&#20986;&#20102;&#24494;&#35843;LLMs&#30340;&#20248;&#21183;&#65292;&#20294;&#36825;&#20010;&#36807;&#31243;&#20195;&#20215;&#39640;&#65292;&#23545;&#20110;&#25317;&#26377;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#30340;&#27169;&#22411;&#26469;&#35828;&#65292;&#22312;&#36164;&#28304;&#31232;&#32570;&#30340;&#29615;&#22659;&#19979;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#20197;&#21069;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#20316;&#20026;&#19968;&#31181;&#31574;&#30053;&#65292;&#29992;&#20219;&#21153;&#29305;&#23450;&#30340;&#25552;&#31034;&#31034;&#20363;&#25351;&#23548;LLM&#29983;&#25104;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;ICL&#24341;&#20837;&#20102;&#19968;&#20123;&#19981;&#20415;&#20043;&#22788;&#65292;&#27604;&#22914;&#38656;&#35201;&#35774;&#35745;&#19978;&#19979;&#25991;&#30456;&#20851;&#30340;&#25552;&#31034;&#21644;&#27809;&#26377;&#23398;&#20064;&#20219;&#21153;&#29305;&#23450;&#30340;&#21442;&#25968;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#39044;&#35265;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#65288;PEFT&#65289;&#25216;&#26415;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#21512;&#29702;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#65292;&#39640;&#25928;&#22320;&#23558;LLM&#19987;&#38376;&#29992;&#20110;&#20219;&#21153;&#29305;&#23450;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) demonstrate impressive capabilities to generate accurate code snippets given natural language intents in zero-shot, i.e., without the need for specific fine-tuning. While prior studies have highlighted the advantages of fine-tuning LLMs, this process incurs high computational costs, making it impractical in resource-scarce environments, particularly for models with billions of parameters. To address these challenges, previous research explored In-Context Learning (ICL) as a strategy to guide the LLM generative process with task-specific prompt examples. However, ICL introduces inconveniences, such as the need for designing contextually relevant prompts and the absence of learning task-specific parameters, thereby limiting downstream task performance. In this context, we foresee Parameter-Efficient Fine-Tuning (PEFT) techniques as a promising approach to efficiently specialize LLMs to task-specific data while maintaining reasonable resource consumption. In t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#22823;&#35268;&#27169;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#38899;&#20048;&#29702;&#35299;&#27169;&#22411;MERT&#65292;&#21033;&#29992;&#20102;&#25945;&#24072;&#27169;&#22411;&#24182;&#37319;&#29992;&#20102;&#19968;&#31181;&#20248;&#20110;&#20256;&#32479;&#30340;&#35821;&#38899;&#21644;&#38899;&#39057;&#26041;&#27861;&#30340;&#32452;&#21512;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2306.00107</link><description>&lt;p&gt;
MERT:&#24102;&#26377;&#22823;&#35268;&#27169;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#22768;&#23398;&#38899;&#20048;&#29702;&#35299;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training. (arXiv:2306.00107v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00107
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#22823;&#35268;&#27169;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#38899;&#20048;&#29702;&#35299;&#27169;&#22411;MERT&#65292;&#21033;&#29992;&#20102;&#25945;&#24072;&#27169;&#22411;&#24182;&#37319;&#29992;&#20102;&#19968;&#31181;&#20248;&#20110;&#20256;&#32479;&#30340;&#35821;&#38899;&#21644;&#38899;&#39057;&#26041;&#27861;&#30340;&#32452;&#21512;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#26368;&#36817;&#22312;&#35270;&#35273;&#12289;&#25991;&#26412;&#21644;&#35821;&#38899;&#39046;&#22495;&#20013;&#24050;&#34987;&#35777;&#26126;&#26159;&#35757;&#32451;&#36890;&#29992;&#27169;&#22411;&#30340;&#19968;&#31181;&#24456;&#26377;&#21069;&#26223;&#30340;&#33539;&#20363;&#65292;&#23545;&#20110;&#36328;&#36234;&#38899;&#20048;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#35843;&#24615;&#21644;&#38899;&#39640;&#36825;&#26679;&#30340;&#29305;&#27530;&#38899;&#20048;&#30693;&#35782;&#30340;&#24314;&#27169;&#39047;&#20855;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22823;&#35268;&#27169;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#22768;&#23398;&#38899;&#20048;&#29702;&#35299;&#27169;&#22411;&#65292;&#21363;MERT&#12290;&#22312;&#25105;&#20204;&#30340;&#25506;&#32034;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26356;&#20248;&#31168;&#30340;&#25945;&#24072;&#27169;&#22411;&#32452;&#21512;&#65292;&#36825;&#31181;&#32452;&#21512;&#26041;&#27861;&#22312;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#30340;&#35821;&#38899;&#21644;&#38899;&#39057;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. Although SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is primarily due to the distinctive challenges associated with modelling musical knowledge, particularly its tonal and pitched characteristics of music. To address this research gap, we propose an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training. In our exploration, we identified a superior combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. This combination includes an acoustic teacher based on Residual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a m
&lt;/p&gt;</description></item></channel></rss>