<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20351;&#29992;&#21069;&#21521;&#20256;&#36882;&#30340;LLM&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#65292;&#36890;&#36807;Bonsai&#29983;&#25104;&#30340;&#20462;&#21098;&#27169;&#22411;&#22312;&#24615;&#33021;&#19978;&#20248;&#20110;&#26799;&#24230;-based&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#65292;&#24182;&#19988;&#36895;&#24230;&#26159;&#21322;&#32467;&#26500;&#21270;&#20462;&#21098;&#27169;&#22411;&#30340;&#20004;&#20493;&#12290;</title><link>https://arxiv.org/abs/2402.05406</link><description>&lt;p&gt;
&#29616;&#22312;&#25152;&#26377;&#20154;&#37117;&#20462;&#21098;&#65306;&#20165;&#20351;&#29992;&#21069;&#21521;&#20256;&#36882;&#30340;LLM&#32467;&#26500;&#21270;&#20462;&#21098;
&lt;/p&gt;
&lt;p&gt;
Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20351;&#29992;&#21069;&#21521;&#20256;&#36882;&#30340;LLM&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#65292;&#36890;&#36807;Bonsai&#29983;&#25104;&#30340;&#20462;&#21098;&#27169;&#22411;&#22312;&#24615;&#33021;&#19978;&#20248;&#20110;&#26799;&#24230;-based&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#65292;&#24182;&#19988;&#36895;&#24230;&#26159;&#21322;&#32467;&#26500;&#21270;&#20462;&#21098;&#27169;&#22411;&#30340;&#20004;&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#38750;&#19987;&#19994;&#20174;&#19994;&#32773;&#21644;&#26368;&#23500;&#26377;&#36164;&#28304;&#30340;&#26426;&#26500;&#20043;&#38388;&#30340;&#30828;&#20214;&#24046;&#36317;&#65292;&#23610;&#23544;&#19981;&#26029;&#22686;&#38271;&#30340;LLM&#21464;&#24471;&#36234;&#26469;&#36234;&#38590;&#20197;&#20351;&#29992;&#12290;&#34429;&#28982;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#26469;&#21387;&#32553;LLM&#65292;&#20197;&#20351;&#20854;&#36164;&#28304;&#28040;&#32791;&#21487;&#31649;&#29702;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#26412;&#36523;&#24448;&#24448;&#32791;&#36153;&#36164;&#28304;&#65292;&#20351;&#20854;&#30446;&#26631;&#29992;&#25143;&#32676;&#26080;&#27861;&#25509;&#35302;&#21040;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#20165;&#20351;&#29992;&#21069;&#21521;&#20256;&#36882;&#30340;LLM&#32467;&#26500;&#21270;&#20462;&#21098;&#38382;&#39064;&#12290;&#25105;&#20204;&#24076;&#26395;&#35753;&#20174;&#19994;&#32773;&#33021;&#22815;&#20462;&#21098;&#27169;&#22411;&#65292;&#20351;&#20854;&#35268;&#27169;&#22823;&#21040;&#30828;&#20214;&#20165;&#26377;&#36275;&#22815;&#30340;&#20869;&#23384;&#26469;&#36816;&#34892;&#25512;&#29702;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;Bonsai&#65292;&#36825;&#26159;&#19968;&#31181;&#26080;&#26799;&#24230;&#12289;&#25200;&#21160;&#20462;&#21098;&#26041;&#27861;&#65292;&#33021;&#22815;&#29983;&#25104;&#23567;&#12289;&#24555;&#21644;&#20934;&#30830;&#30340;&#20462;&#21098;&#27169;&#22411;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;Bonsai&#29983;&#25104;&#30340;&#20462;&#21098;&#27169;&#22411;&#65288;i&#65289;&#20248;&#20110;&#26356;&#26114;&#36149;&#30340;&#26799;&#24230;-based&#32467;&#26500;&#21270;&#20462;&#21098;&#26041;&#27861;&#29983;&#25104;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#65288;ii&#65289;&#19982;&#21322;&#32467;&#26500;&#21270;&#20462;&#21098;&#27169;&#22411;&#30456;&#27604;&#65292;&#36895;&#24230;&#24555;&#19968;&#20493;&#19988;&#20934;&#30830;&#24615;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given the generational gap in available hardware between lay practitioners and the most endowed institutions, LLMs are becoming increasingly inaccessible as they grow in size. Whilst many approaches have been proposed to compress LLMs to make their resource consumption manageable, these methods themselves tend to be resource intensive, putting them out of the reach of the very user groups they target. In this work, we explore the problem of structured pruning of LLMs using only forward passes. We seek to empower practitioners to prune models so large that their available hardware has just enough memory to run inference. We develop Bonsai, a gradient-free, perturbative pruning method capable of delivering small, fast, and accurate pruned models.   We observe that Bonsai outputs pruned models that (i) outperform those generated by more expensive gradient-based structured pruning methods, and (ii) are twice as fast (with comparable accuracy) as those generated by semi-structured pruning m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22823;&#35268;&#27169;&#32452;&#32455;&#29615;&#22659;&#20013;&#23454;&#29616;&#27178;&#21521;&#32593;&#32476;&#38035;&#40060;&#30340;&#24773;&#20917;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21453;&#38035;&#40060;&#22522;&#30784;&#35774;&#26045;&#26080;&#27861;&#38450;&#27490;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#38035;&#40060;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2401.09727</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27178;&#21521;&#32593;&#32476;&#38035;&#40060;&#65306;&#22823;&#35268;&#27169;&#32452;&#32455;&#29615;&#22659;&#20013;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large Language Model Lateral Spear Phishing: A Comparative Study in Large-Scale Organizational Settings. (arXiv:2401.09727v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09727
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22823;&#35268;&#27169;&#32452;&#32455;&#29615;&#22659;&#20013;&#23454;&#29616;&#27178;&#21521;&#32593;&#32476;&#38035;&#40060;&#30340;&#24773;&#20917;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21453;&#38035;&#40060;&#22522;&#30784;&#35774;&#26045;&#26080;&#27861;&#38450;&#27490;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#38035;&#40060;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38035;&#40060;&#30005;&#23376;&#37038;&#20214;&#30340;&#20005;&#37325;&#23041;&#32961;&#34987;LLMs&#29983;&#25104;&#39640;&#24230;&#23450;&#21521;&#12289;&#20010;&#24615;&#21270;&#21644;&#33258;&#21160;&#21270;&#30340;&#40060;&#21449;&#24335;&#32593;&#32476;&#38035;&#40060;&#25915;&#20987;&#30340;&#28508;&#21147;&#36827;&#19968;&#27493;&#24694;&#21270;&#12290;&#20851;&#20110;LLM&#20419;&#25104;&#30340;&#38035;&#40060;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;&#65306;1&#65289;&#29616;&#26377;&#30340;&#27178;&#21521;&#32593;&#32476;&#38035;&#40060;&#30740;&#31350;&#32570;&#20047;&#38024;&#23545;&#25972;&#20010;&#32452;&#32455;&#36827;&#34892;&#22823;&#35268;&#27169;&#25915;&#20987;&#30340;LLM&#25972;&#21512;&#30340;&#20855;&#20307;&#23457;&#26597;&#65307;2&#65289;&#23613;&#31649;&#21453;&#38035;&#40060;&#22522;&#30784;&#35774;&#26045;&#32463;&#36807;&#24191;&#27867;&#24320;&#21457;&#65292;&#20294;&#20173;&#26080;&#27861;&#38450;&#27490;LLM&#29983;&#25104;&#30340;&#25915;&#20987;&#65292;&#21487;&#33021;&#24433;&#21709;&#21592;&#24037;&#21644;IT&#23433;&#20840;&#20107;&#20214;&#31649;&#29702;&#12290;&#28982;&#32780;&#65292;&#36827;&#34892;&#36825;&#26679;&#30340;&#35843;&#26597;&#30740;&#31350;&#38656;&#35201;&#22312;&#29616;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#36827;&#34892;&#65292;&#35813;&#29615;&#22659;&#22312;&#27491;&#24120;&#19994;&#21153;&#36816;&#20316;&#26399;&#38388;&#24037;&#20316;&#65292;&#24182;&#21453;&#26144;&#20986;&#22823;&#22411;&#32452;&#32455;&#22522;&#30784;&#35774;&#26045;&#30340;&#22797;&#26434;&#24615;&#12290;&#27492;&#35774;&#32622;&#36824;&#24517;&#39035;&#25552;&#20379;&#25152;&#38656;&#30340;&#28789;&#27963;&#24615;&#65292;&#20197;&#20419;&#36827;&#21508;&#31181;&#23454;&#39564;&#26465;&#20214;&#30340;&#23454;&#26045;&#65292;&#29305;&#21035;&#26159;&#38035;&#40060;&#30005;&#23376;&#37038;&#20214;&#30340;&#21046;&#20316;&#21644;&#32452;&#32455;&#33539;&#22260;&#30340;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
The critical threat of phishing emails has been further exacerbated by the potential of LLMs to generate highly targeted, personalized, and automated spear phishing attacks. Two critical problems concerning LLM-facilitated phishing require further investigation: 1) Existing studies on lateral phishing lack specific examination of LLM integration for large-scale attacks targeting the entire organization, and 2) Current anti-phishing infrastructure, despite its extensive development, lacks the capability to prevent LLM-generated attacks, potentially impacting both employees and IT security incident management. However, the execution of such investigative studies necessitates a real-world environment, one that functions during regular business operations and mirrors the complexity of a large organizational infrastructure. This setting must also offer the flexibility required to facilitate a diverse array of experimental conditions, particularly the incorporation of phishing emails crafted
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#22797;&#26434;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#30340;&#20915;&#31574;&#32452;&#20214;&#65292;&#36890;&#36807;&#35748;&#30693;&#36335;&#24452;&#21644;&#31639;&#27861;&#26469;&#23454;&#29616;&#20840;&#38754;&#25512;&#29702;&#21644;&#21487;&#25191;&#34892;&#39550;&#39542;&#25351;&#20196;&#30340;&#36716;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LLMs&#33021;&#22815;&#22312;&#21333;&#36710;&#20219;&#21153;&#21644;&#22797;&#26434;&#39550;&#39542;&#34892;&#20026;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#36825;&#26159;&#22240;&#20026;&#20854;&#20855;&#26377;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.03026</link><description>&lt;p&gt;
LanguageMPC&#65306;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#21160;&#39550;&#39542;&#20915;&#31574;&#32773;
&lt;/p&gt;
&lt;p&gt;
LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving. (arXiv:2310.03026v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03026
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#22797;&#26434;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#30340;&#20915;&#31574;&#32452;&#20214;&#65292;&#36890;&#36807;&#35748;&#30693;&#36335;&#24452;&#21644;&#31639;&#27861;&#26469;&#23454;&#29616;&#20840;&#38754;&#25512;&#29702;&#21644;&#21487;&#25191;&#34892;&#39550;&#39542;&#25351;&#20196;&#30340;&#36716;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LLMs&#33021;&#22815;&#22312;&#21333;&#36710;&#20219;&#21153;&#21644;&#22797;&#26434;&#39550;&#39542;&#34892;&#20026;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#36825;&#26159;&#22240;&#20026;&#20854;&#20855;&#26377;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#22522;&#20110;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#22312;&#29702;&#35299;&#39640;&#32423;&#20449;&#24687;&#12289;&#25512;&#24191;&#32597;&#35265;&#20107;&#20214;&#21644;&#25552;&#20379;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#22797;&#26434;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#30340;&#20915;&#31574;&#32452;&#20214;&#65292;&#38656;&#35201;&#20154;&#31867;&#24120;&#35782;&#29702;&#35299;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#35748;&#30693;&#36335;&#24452;&#65292;&#20351;LLMs&#33021;&#22815;&#36827;&#34892;&#20840;&#38754;&#25512;&#29702;&#65292;&#24182;&#24320;&#21457;&#20102;&#23558;LLM&#20915;&#31574;&#36716;&#21270;&#20026;&#21487;&#25191;&#34892;&#39550;&#39542;&#25351;&#20196;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;LLM&#20915;&#31574;&#36890;&#36807;&#24341;&#23548;&#21442;&#25968;&#30697;&#38453;&#36866;&#24212;&#19982;&#20302;&#32423;&#25511;&#21046;&#22120;&#26080;&#32541;&#38598;&#25104;&#12290;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19981;&#20165;&#22312;&#21333;&#36710;&#20219;&#21153;&#20013;&#22987;&#32456;&#36229;&#36234;&#22522;&#32447;&#26041;&#27861;&#65292;&#32780;&#19988;&#36824;&#33021;&#22788;&#29702;&#22797;&#26434;&#30340;&#39550;&#39542;&#34892;&#20026;&#65292;&#29978;&#33267;&#22810;&#36710;&#21327;&#35843;&#65292;&#36825;&#35201;&#24402;&#21151;&#20110;LLMs&#30340;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;LLMs&#20316;&#20026;&#26377;&#25928;&#20915;&#31574;&#32773;&#30340;&#21021;&#27493;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing learning-based autonomous driving (AD) systems face challenges in comprehending high-level information, generalizing to rare events, and providing interpretability. To address these problems, this work employs Large Language Models (LLMs) as a decision-making component for complex AD scenarios that require human commonsense understanding. We devise cognitive pathways to enable comprehensive reasoning with LLMs, and develop algorithms for translating LLM decisions into actionable driving commands. Through this approach, LLM decisions are seamlessly integrated with low-level controllers by guided parameter matrix adaptation. Extensive experiments demonstrate that our proposed method not only consistently surpasses baseline approaches in single-vehicle tasks, but also helps handle complex driving behaviors even multi-vehicle coordination, thanks to the commonsense reasoning capabilities of LLMs. This paper presents an initial step toward leveraging LLMs as effective decision-make
&lt;/p&gt;</description></item></channel></rss>