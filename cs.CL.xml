<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>LoRA&#20316;&#20026;&#25915;&#20987;&#32773;&#28183;&#36879;LLM&#23433;&#20840;&#65292;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20849;&#20139;&#19982;&#29609;&#32781;&#22330;&#26223;&#19979;&#21487;&#33021;&#23454;&#29616;&#30340;&#25915;&#20987;&#26426;&#20250;&#12290;</title><link>https://arxiv.org/abs/2403.00108</link><description>&lt;p&gt;
&#23558;LoRA&#20316;&#20026;&#25915;&#20987;&#65281;&#22312;Share-and-Play&#22330;&#26223;&#19979;&#31359;&#36879;LLM&#23433;&#20840;
&lt;/p&gt;
&lt;p&gt;
LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00108
&lt;/p&gt;
&lt;p&gt;
LoRA&#20316;&#20026;&#25915;&#20987;&#32773;&#28183;&#36879;LLM&#23433;&#20840;&#65292;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20849;&#20139;&#19982;&#29609;&#32781;&#22330;&#26223;&#19979;&#21487;&#33021;&#23454;&#29616;&#30340;&#25915;&#20987;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;LLMs&#36827;&#34892;&#24494;&#35843;&#23545;&#20110;&#22686;&#24378;&#20854;&#29305;&#23450;&#20219;&#21153;&#30340;&#24615;&#33021;&#24182;&#30830;&#20445;&#27169;&#22411;&#34892;&#20026;&#19982;&#20154;&#31867;&#20559;&#22909;&#20445;&#25345;&#19968;&#33268;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#21508;&#31181;&#24494;&#35843;&#26041;&#27861;&#20013;&#65292;LoRA&#22240;&#20854;&#25928;&#29575;&#21644;&#26131;&#29992;&#24615;&#32780;&#22791;&#21463;&#25512;&#23815;&#65292;&#20801;&#35768;&#26368;&#32456;&#29992;&#25143;&#36731;&#26494;&#22312;&#24320;&#28304;&#24179;&#21488;&#19978;&#21457;&#24067;&#21644;&#37319;&#29992;&#36731;&#37327;&#30340;LoRA&#27169;&#22359;&#65292;&#20197;&#23450;&#21046;&#20854;&#27169;&#22411;&#20197;&#36866;&#24212;&#19981;&#21516;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#20415;&#30340;&#20849;&#20139;&#19982;&#29609;&#32781;&#35774;&#32622;&#25171;&#24320;&#20102;&#26032;&#30340;&#25915;&#20987;&#38754;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#23558;LoRA&#20316;&#20026;&#25915;&#20987;&#32773;&#65292;&#20363;&#22914;&#32972;&#38376;&#27880;&#20837;&#65292;&#24182;&#24191;&#27867;&#20998;&#21457;&#23545;&#25239;&#24615;LoRA&#32473;&#31038;&#21306;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#19981;&#21033;&#30340;&#21518;&#26524;&#12290;&#23613;&#31649;&#20849;&#20139;LoRA&#27169;&#22359;&#23384;&#22312;&#24040;&#22823;&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#20294;&#36825;&#19968;&#26041;&#38754;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#22312;&#19981;&#26029;&#22686;&#38271;&#30340;&#20849;&#20139;&#19982;&#29609;&#32781;&#22330;&#26223;&#20013;&#21487;&#33021;&#20570;&#20986;&#30340;&#25915;&#20987;&#26426;&#20250;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#23558;&#21518;&#38376;&#27880;&#20837;LoRA&#27169;&#22359;&#24182;&#28145;&#20837;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00108v1 Announce Type: cross  Abstract: Fine-tuning LLMs is crucial to enhancing their task-specific performance and ensuring model behaviors are aligned with human preferences. Among various fine-tuning methods, LoRA is popular for its efficiency and ease to use, allowing end-users to easily post and adopt lightweight LoRA modules on open-source platforms to tailor their model for different customization. However, such a handy share-and-play setting opens up new attack surfaces, that the attacker can render LoRA as an attacker, such as backdoor injection, and widely distribute the adversarial LoRA to the community easily. This can result in detrimental outcomes. Despite the huge potential risks of sharing LoRA modules, this aspect however has not been fully explored. To fill the gap, in this study we thoroughly investigate the attack opportunities enabled in the growing share-and-play scenario. Specifically, we study how to inject backdoor into the LoRA module and dive deep
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#35777;&#25454;&#21644;&#39118;&#26684;&#30340;&#21453;&#39539;&#65292;&#35813;&#25968;&#25454;&#38598;&#22522;&#20110;Reddit ChangeMyView&#25968;&#25454;&#38598;&#20013;&#30340;&#24086;&#23376;&#65292;&#24182;&#21487;&#29992;&#20110;&#35770;&#35777;&#30340;&#25913;&#36827;&#21644;&#35780;&#20272;&#12290;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;GPT-3.5 turbo&#27169;&#22411;&#22312;&#35770;&#35777;&#36136;&#37327;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#20855;&#26377;&#24456;&#39640;&#30340;&#39118;&#26684;&#34701;&#21512;&#33021;&#21147;&#12290;&#20114;&#24800;&#24335;&#21453;&#39539;&#30340;&#25928;&#26524;&#26368;&#20339;&#12290;</title><link>https://arxiv.org/abs/2402.08498</link><description>&lt;p&gt;
&#23457;&#35745;&#21453;&#28779;&#65306;&#35780;&#20272;&#20855;&#26377;&#35777;&#25454;&#21644;&#39118;&#26684;&#30340;&#20808;&#36827;&#21453;&#39539;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Auditing Counterfire: Evaluating Advanced Counterargument Generation with Evidence and Style
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08498
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#35777;&#25454;&#21644;&#39118;&#26684;&#30340;&#21453;&#39539;&#65292;&#35813;&#25968;&#25454;&#38598;&#22522;&#20110;Reddit ChangeMyView&#25968;&#25454;&#38598;&#20013;&#30340;&#24086;&#23376;&#65292;&#24182;&#21487;&#29992;&#20110;&#35770;&#35777;&#30340;&#25913;&#36827;&#21644;&#35780;&#20272;&#12290;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;GPT-3.5 turbo&#27169;&#22411;&#22312;&#35770;&#35777;&#36136;&#37327;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#20855;&#26377;&#24456;&#39640;&#30340;&#39118;&#26684;&#34701;&#21512;&#33021;&#21147;&#12290;&#20114;&#24800;&#24335;&#21453;&#39539;&#30340;&#25928;&#26524;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#25511;&#21046;&#24615;&#21453;&#39539;&#30340;&#21512;&#25104;&#65292;&#26088;&#22312;&#36827;&#19968;&#27493;&#24212;&#29992;&#20110;&#35770;&#35777;&#30340;&#25913;&#36827;&#12289;&#25366;&#25496;&#21644;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#21253;&#21547;&#19982;Reddit ChangeMyView&#25968;&#25454;&#38598;&#20013;&#30340;&#24086;&#23376;&#30456;&#32467;&#21512;&#30340;&#20016;&#23500;&#30340;&#21453;&#39539;&#65292;&#36825;&#20123;&#21453;&#39539;&#34701;&#20837;&#20102;&#20174;&#39640;&#36136;&#37327;&#26469;&#28304;&#20013;&#26816;&#32034;&#21040;&#30340;&#35777;&#25454;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#20559;&#22909;&#29983;&#25104;&#65292;&#35843;&#25972;&#20102;&#35777;&#25454;&#21644;&#35770;&#35777;&#39118;&#26684;&#30340;&#20851;&#38190;&#23646;&#24615;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;Counterfire&#35821;&#26009;&#24211;&#21253;&#25324;&#20174;GPT-3.5 turbo&#12289;Koala&#21644;PaLM 2&#27169;&#22411;&#20197;&#21450;&#23427;&#20204;&#30340;&#20004;&#20010;&#24494;&#35843;&#21464;&#20307;&#29983;&#25104;&#30340;&#35770;&#35777;&#65288;N = 32,000&#65289;&#12290;&#27169;&#22411;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#35777;&#25454;&#26041;&#38754;&#20855;&#26377;&#24378;&#22823;&#30340;&#25913;&#20889;&#33021;&#21147;&#65292;&#23613;&#31649;&#35789;&#27719;&#37325;&#21472;&#26377;&#38480;&#65292;&#21516;&#26102;&#34920;&#29616;&#20986;&#39640;&#24230;&#30340;&#39118;&#26684;&#34701;&#21512;&#65288;&#23545;&#20110;&#8220;&#20114;&#24800;&#8221;&#30340;&#24471;&#20998;&#20026;0.9682&#65289;&#65292;&#26174;&#31034;&#20102;LLM&#34701;&#21512;&#22810;&#26679;&#39118;&#26684;&#30340;&#33021;&#21147;&#12290;&#22312;&#25152;&#26377;&#27169;&#22411;&#20013;&#65292;GPT-3.5 turbo&#22312;&#35770;&#35777;&#36136;&#37327;&#35780;&#20272;&#20013;&#26174;&#31034;&#20986;&#26368;&#39640;&#20998;&#25968;&#65292;&#34920;&#29616;&#20986;&#19968;&#33268;&#20934;&#30830;&#24615;&#65288;&#24471;&#20998; &gt;0.8&#65289;&#12290;&#22312;&#36827;&#19968;&#27493;&#30340;&#20998;&#26512;&#20013;&#65292;&#20114;&#24800;&#24335;&#21453;&#39539;&#35777;&#26126;&#25928;&#26524;&#26368;&#20339;&#65292;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#35770;&#35777;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel dataset for the controlled composition of counterarguments designed for further applications in argument refining, mining, and evaluation. Our dataset constitutes enriched counter-arguments to posts in the Reddit ChangeMyView dataset that are integrated with evidence retrieved from high-quality sources and generated based on user preferences, adjusting the critical attributes of evidence and argument style. The resultant Counterfire corpus comprises arguments generated from GPT-3.5 turbo, Koala, and PaLM 2 models and two of their finetuned variants (N = 32,000). Model evaluation indicates strong paraphrasing abilities with evidence, albeit limited word overlap, while demonstrating high style integration (0.9682 for 'reciprocity'), showing the ability of LLM to assimilate diverse styles. Of all models, GPT-3.5 turbo showed the highest scores in argument quality evaluation, showing consistent accuracy (score &gt;0.8). In further analyses, reciprocity-style counterargument
&lt;/p&gt;</description></item><item><title>LegalDuet&#26159;&#19968;&#31181;&#36890;&#36807;&#21452;&#35270;&#35282;&#27861;&#24459;&#32447;&#32034;&#25512;&#29702;&#27169;&#22411;&#65292;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#23450;&#21046;&#23884;&#20837;&#31354;&#38388;&#26469;&#36827;&#34892;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#27861;&#24459;&#26696;&#20363;&#25512;&#29702;&#21644;&#27861;&#24459;&#22522;&#30784;&#25512;&#29702;&#20004;&#20010;&#25512;&#29702;&#38142;&#36827;&#34892;&#21028;&#20915;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;LegalDuet&#22312;CAIL2018&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#36229;&#36807;&#20102;&#22522;&#32447;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2401.15371</link><description>&lt;p&gt;
LegalDuet: &#36890;&#36807;&#21452;&#35270;&#35282;&#27861;&#24459;&#32447;&#32034;&#25512;&#29702;&#23398;&#20064;&#26377;&#25928;&#30340;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
LegalDuet: Learning Effective Representations for Legal Judgment Prediction through a Dual-View Legal Clue Reasoning. (arXiv:2401.15371v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15371
&lt;/p&gt;
&lt;p&gt;
LegalDuet&#26159;&#19968;&#31181;&#36890;&#36807;&#21452;&#35270;&#35282;&#27861;&#24459;&#32447;&#32034;&#25512;&#29702;&#27169;&#22411;&#65292;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#23450;&#21046;&#23884;&#20837;&#31354;&#38388;&#26469;&#36827;&#34892;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#27861;&#24459;&#26696;&#20363;&#25512;&#29702;&#21644;&#27861;&#24459;&#22522;&#30784;&#25512;&#29702;&#20004;&#20010;&#25512;&#29702;&#38142;&#36827;&#34892;&#21028;&#20915;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;LegalDuet&#22312;CAIL2018&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#36229;&#36807;&#20102;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#65288;LJP&#65289;&#27169;&#22411;&#20391;&#37325;&#20110;&#21457;&#29616;&#21009;&#20107;&#20107;&#23454;&#25551;&#36848;&#20013;&#30340;&#27861;&#24459;&#32447;&#32034;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#19987;&#19994;&#27861;&#23448;&#19981;&#20165;&#38656;&#35201;&#21560;&#25910;&#36807;&#21435;&#21028;&#20915;&#30340;&#27861;&#24459;&#26696;&#20363;&#32463;&#39564;&#65292;&#36824;&#20381;&#36182;&#20110;&#20174;&#19987;&#19994;&#27861;&#24459;&#30693;&#35782;&#20013;&#23398;&#21040;&#30340;&#19987;&#19994;&#27861;&#24459;&#22522;&#30784;&#25512;&#29702;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LegalDuet&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20197;&#23398;&#20064;&#29992;&#20110;&#36827;&#34892;&#27861;&#24459;&#21028;&#20915;&#30340;&#23450;&#21046;&#23884;&#20837;&#31354;&#38388;&#12290;&#23427;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#35270;&#35282;&#27861;&#24459;&#32447;&#32034;&#25512;&#29702;&#26426;&#21046;&#65292;&#30001;&#20004;&#20010;&#25512;&#29702;&#38142;&#32452;&#25104;&#65306;1&#65289;&#27861;&#24459;&#26696;&#20363;&#25512;&#29702;&#65292;&#26681;&#25454;&#20174;&#31867;&#27604;/&#28151;&#28102;&#30340;&#27861;&#24459;&#26696;&#20363;&#20013;&#23398;&#21040;&#30340;&#21028;&#20915;&#32463;&#39564;&#36827;&#34892;&#27861;&#24459;&#21028;&#20915;&#65307;2&#65289;&#27861;&#24459;&#22522;&#30784;&#25512;&#29702;&#65292;&#36890;&#36807;&#21305;&#37197;&#21009;&#20107;&#26696;&#20214;&#21644;&#27861;&#24459;&#20915;&#23450;&#20043;&#38388;&#30340;&#27861;&#24459;&#32447;&#32034;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LegalDuet&#22312;CAIL2018&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#36229;&#36807;&#20102;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most existing Legal Judgment Prediction (LJP) models focus on discovering the legal triggers in the criminal fact description. However, in real-world scenarios, a professional judge not only needs to assimilate the law case experience that thrives on past sentenced legal judgments but also depends on the professional legal grounded reasoning that learned from professional legal knowledge. In this paper, we propose a LegalDuet model, which pretrains language models to learn a tailored embedding space for making legal judgments. It proposes a dual-view legal clue reasoning mechanism, which derives from two reasoning chains of judges: 1) Law Case Reasoning, which makes legal judgments according to the judgment experiences learned from analogy/confusing legal cases; 2) Legal Ground Reasoning, which lies in matching the legal clues between criminal cases and legal decisions. Our experiments show that LegalDuet achieves state-of-the-art performance on the CAIL2018 dataset and outperforms bas
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36830;&#25509;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#36827;&#21270;&#31639;&#27861;&#36827;&#34892;&#25552;&#31034;&#20248;&#21270;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;EvoPrompt&#12290;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#35328;&#22788;&#29702;&#33021;&#21147;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#20248;&#21270;&#24615;&#33021;&#65292;EvoPrompt&#21487;&#20197;&#33258;&#21160;&#21270;&#22788;&#29702;&#38656;&#35201;&#36830;&#36143;&#21644;&#21487;&#35835;&#24615;&#33391;&#22909;&#30340;&#25552;&#31034;&#65292;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.08532</link><description>&lt;p&gt;
&#36890;&#36807;&#36827;&#21270;&#31639;&#27861;&#36830;&#25509;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#24378;&#22823;&#30340;&#25552;&#31034;&#20248;&#21270;&#22120;
&lt;/p&gt;
&lt;p&gt;
Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers. (arXiv:2309.08532v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36830;&#25509;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#36827;&#21270;&#31639;&#27861;&#36827;&#34892;&#25552;&#31034;&#20248;&#21270;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;EvoPrompt&#12290;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#35328;&#22788;&#29702;&#33021;&#21147;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#20248;&#21270;&#24615;&#33021;&#65292;EvoPrompt&#21487;&#20197;&#33258;&#21160;&#21270;&#22788;&#29702;&#38656;&#35201;&#36830;&#36143;&#21644;&#21487;&#35835;&#24615;&#33391;&#22909;&#30340;&#25552;&#31034;&#65292;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#31934;&#24515;&#35774;&#35745;&#30340;&#25552;&#31034;&#65292;&#36825;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#21147;&#21162;&#21147;&#12290;&#20026;&#20102;&#33258;&#21160;&#21270;&#36825;&#20010;&#36807;&#31243;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#25955;&#25552;&#31034;&#20248;&#21270;&#26694;&#26550;&#65292;&#31216;&#20026;EvoPrompt&#65292;&#23427;&#20511;&#37492;&#20102;&#36827;&#21270;&#31639;&#27861;&#30340;&#24605;&#24819;&#65292;&#22240;&#20026;&#23427;&#20204;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#21644;&#24555;&#36895;&#30340;&#25910;&#25947;&#24615;&#12290;&#20026;&#20102;&#20351;&#36827;&#21270;&#31639;&#27861;&#33021;&#22815;&#22788;&#29702;&#38656;&#35201;&#36830;&#36143;&#24182;&#19988;&#21487;&#35835;&#24615;&#33391;&#22909;&#30340;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#31163;&#25955;&#25552;&#31034;&#65292;&#25105;&#20204;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#36827;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#36830;&#25509;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#21487;&#20197;&#21516;&#26102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24378;&#22823;&#35821;&#35328;&#22788;&#29702;&#33021;&#21147;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#39640;&#25928;&#20248;&#21270;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;EvoPrompt&#22312;&#19981;&#20351;&#29992;&#20219;&#20309;&#26799;&#24230;&#25110;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#19968;&#32452;&#25552;&#31034;&#20013;&#24320;&#22987;&#65292;&#24182;&#22522;&#20110;&#36827;&#21270;&#31639;&#23376;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#26032;&#30340;&#25552;&#31034;&#65292;&#26681;&#25454;&#24320;&#21457;&#38598;&#25913;&#36827;&#25552;&#31034;&#30340;&#31181;&#32676;&#12290;&#25105;&#20204;&#23545;&#38381;&#28304;&#21644;&#24320;&#28304;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#21253;&#25324;GPT-3&#36827;&#34892;&#25552;&#31034;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) excel in various tasks, but they rely on carefully crafted prompts that often demand substantial human effort. To automate this process, in this paper, we propose a novel framework for discrete prompt optimization, called EvoPrompt, which borrows the idea of evolutionary algorithms (EAs) as they exhibit good performance and fast convergence. To enable EAs to work on discrete prompts, which are natural language expressions that need to be coherent and human-readable, we connect LLMs with EAs. This approach allows us to simultaneously leverage the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs. Specifically, abstaining from any gradients or parameters, EvoPrompt starts from a population of prompts and iteratively generates new prompts with LLMs based on the evolutionary operators, improving the population based on the development set. We optimize prompts for both closed- and open-source LLMs including GPT-3
&lt;/p&gt;</description></item></channel></rss>