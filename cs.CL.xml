<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#21644;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#21644;&#20943;&#36731;&#36807;&#24230;&#25311;&#21512;&#12290;</title><link>https://arxiv.org/abs/2403.10056</link><description>&lt;p&gt;
&#19981;&#35201;&#21322;&#24515;&#21322;&#24847;&#65306;&#25429;&#25417;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#20013;&#30340;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10056
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#21644;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#21644;&#20943;&#36731;&#36807;&#24230;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10056v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25351;&#23548;&#35843;&#25972;&#21487;&#20197;&#39537;&#20351;&#23427;&#20204;&#22312;&#29305;&#23450;&#19979;&#28216;&#20219;&#21153;&#20013;&#20135;&#29983;&#31526;&#21512;&#20154;&#31867;&#30446;&#26631;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;LLMs&#30340;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#65288;CIT&#65289;&#36807;&#31243;&#21487;&#33021;&#20250;&#24102;&#26469;&#28798;&#38590;&#24615;&#36951;&#24536;&#65288;CF&#65289;&#38382;&#39064;&#65292;&#23548;&#33268;&#20808;&#21069;&#23398;&#21040;&#30340;&#33021;&#21147;&#36864;&#21270;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#23581;&#35797;&#36890;&#36807;&#20462;&#25913;&#27169;&#22411;&#25110;&#37325;&#25918;&#25968;&#25454;&#26469;&#32531;&#35299;CF&#38382;&#39064;&#65292;&#20294;&#36825;&#21487;&#33021;&#21482;&#35760;&#20303;&#25351;&#20196;&#30340;&#34920;&#38754;&#27169;&#24335;&#24182;&#22312;&#30041;&#23384;&#20219;&#21153;&#19978;&#24863;&#21040;&#22256;&#24785;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#65288;KPIG&#65289;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35745;&#31639;&#25513;&#30422;&#37096;&#20998;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#24182;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20174;&#32780;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#19982;&#27491;&#30830;&#21709;&#24212;&#30456;&#20851;&#30340;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#65292;&#24182;&#20943;&#36731;&#23545;&#25351;&#23548;&#20013;&#36890;&#29992;&#25551;&#36848;&#30340;&#36807;&#24230;&#25311;&#21512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#25351;&#26631;&#65292;P&#20998;&#21644;V&#20998;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10056v1 Announce Type: cross  Abstract: Instruction tuning for large language models (LLMs) can drive them to produce results consistent with human goals in specific downstream tasks. However, the process of continual instruction tuning (CIT) for LLMs may bring about the catastrophic forgetting (CF) problem, where previously learned abilities are degraded. Recent methods try to alleviate the CF problem by modifying models or replaying data, which may only remember the surface-level pattern of instructions and get confused on held-out tasks. In this paper, we propose a novel continual instruction tuning method based on Key-part Information Gain (KPIG). Our method computes the information gain on masked parts to dynamically replay data and refine the training objective, which enables LLMs to capture task-aware information relevant to the correct response and alleviate overfitting to general descriptions in instructions. In addition, we propose two metrics, P-score and V-score,
&lt;/p&gt;</description></item><item><title>CodeMind&#26159;&#19968;&#20010;&#29992;&#20110;&#25361;&#25112;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20195;&#30721;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35780;&#20272;LLMs&#30340;&#20195;&#30721;&#25512;&#29702;&#33021;&#21147;&#26469;&#26367;&#20195;&#20165;&#20165;&#20381;&#38752;&#27979;&#35797;&#36890;&#36807;&#26469;&#35780;&#20272;&#65292;&#23545;&#19977;&#31181;&#20195;&#30721;&#25512;&#29702;&#20219;&#21153;&#36827;&#34892;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;LLMs&#33021;&#22815;&#20844;&#27491;&#22320;&#29702;&#35299;&#25511;&#21046;&#27969;&#32467;&#26500;&#65292;&#24182;&#19988;&#23545;&#20110;&#31616;&#21333;&#31243;&#24207;&#21644;&#22797;&#26434;&#31243;&#24207;&#65292;&#23427;&#20204;&#36890;&#24120;&#33021;&#22815;&#25512;&#29702;&#20986;&#36755;&#20837;&#22914;&#20309;&#28436;&#21464;&#20026;&#36755;&#20986;&#12290;</title><link>https://arxiv.org/abs/2402.09664</link><description>&lt;p&gt;
CodeMind:&#19968;&#20010;&#29992;&#20110;&#25361;&#25112;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20195;&#30721;&#25512;&#29702;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
CodeMind: A Framework to Challenge Large Language Models for Code Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09664
&lt;/p&gt;
&lt;p&gt;
CodeMind&#26159;&#19968;&#20010;&#29992;&#20110;&#25361;&#25112;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20195;&#30721;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#35780;&#20272;LLMs&#30340;&#20195;&#30721;&#25512;&#29702;&#33021;&#21147;&#26469;&#26367;&#20195;&#20165;&#20165;&#20381;&#38752;&#27979;&#35797;&#36890;&#36807;&#26469;&#35780;&#20272;&#65292;&#23545;&#19977;&#31181;&#20195;&#30721;&#25512;&#29702;&#20219;&#21153;&#36827;&#34892;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;LLMs&#33021;&#22815;&#20844;&#27491;&#22320;&#29702;&#35299;&#25511;&#21046;&#27969;&#32467;&#26500;&#65292;&#24182;&#19988;&#23545;&#20110;&#31616;&#21333;&#31243;&#24207;&#21644;&#22797;&#26434;&#31243;&#24207;&#65292;&#23427;&#20204;&#36890;&#24120;&#33021;&#22815;&#25512;&#29702;&#20986;&#36755;&#20837;&#22914;&#20309;&#28436;&#21464;&#20026;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20165;&#38752;&#27979;&#35797;&#36890;&#36807;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20195;&#30721;&#21512;&#25104;&#33021;&#21147;&#21487;&#33021;&#20250;&#23548;&#33268;&#19981;&#20844;&#27491;&#30340;&#35780;&#20272;&#25110;&#20419;&#36827;&#20855;&#26377;&#25968;&#25454;&#27844;&#28431;&#30340;&#27169;&#22411;&#65292;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;CodeMind&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#35780;&#20272;LLMs&#30340;&#20195;&#30721;&#25512;&#29702;&#33021;&#21147;&#30340;&#26694;&#26550;&#12290;CodeMind&#30446;&#21069;&#25903;&#25345;&#19977;&#31181;&#20195;&#30721;&#25512;&#29702;&#20219;&#21153;&#65306;&#29420;&#31435;&#25191;&#34892;&#25512;&#29702;&#65288;IER&#65289;&#12289;&#20381;&#36182;&#25191;&#34892;&#25512;&#29702;&#65288;DER&#65289;&#21644;&#35268;&#33539;&#25512;&#29702;&#65288;SR&#65289;&#12290;&#21069;&#20004;&#32773;&#35780;&#20272;&#27169;&#22411;&#20197;&#39044;&#27979;&#20219;&#24847;&#20195;&#30721;&#30340;&#25191;&#34892;&#36755;&#20986;&#65292;&#25110;&#32773;&#27169;&#22411;&#33021;&#22815;&#27491;&#30830;&#21512;&#25104;&#30340;&#20195;&#30721;&#12290;&#31532;&#19977;&#20010;&#20219;&#21153;&#35780;&#20272;LLMs&#23454;&#29616;&#25351;&#23450;&#39044;&#26399;&#34892;&#20026;&#30340;&#31243;&#24230;&#12290;&#25105;&#20204;&#20351;&#29992;CodeMind&#23545;&#20004;&#31181;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#20013;&#30340;&#20116;&#20010;&#22522;&#20934;&#19979;&#30340;&#20061;&#20010;LLMs&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;LLMs&#33021;&#22815;&#20844;&#27491;&#22320;&#29702;&#35299;&#25511;&#21046;&#27969;&#32467;&#26500;&#65292;&#24182;&#19988;&#23545;&#20110;&#31616;&#21333;&#31243;&#24207;&#21644;&#22797;&#26434;&#31243;&#24207;&#65292;&#23427;&#20204;&#36890;&#24120;&#33021;&#22815;&#25512;&#29702;&#20986;&#36755;&#20837;&#22914;&#20309;&#28436;&#21464;&#20026;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09664v1 Announce Type: cross  Abstract: Solely relying on test passing to evaluate Large Language Models (LLMs) for code synthesis may result in unfair assessment or promoting models with data leakage. As an alternative, we introduce CodeMind, a framework designed to gauge the code reasoning abilities of LLMs. CodeMind currently supports three code reasoning tasks: Independent Execution Reasoning (IER), Dependent Execution Reasoning (DER), and Specification Reasoning (SR). The first two evaluate models to predict the execution output of an arbitrary code or code the model could correctly synthesize. The third one evaluates the extent to which LLMs implement the specified expected behavior. Our extensive evaluation of nine LLMs across five benchmarks in two different programming languages using CodeMind shows that LLMs fairly understand control flow constructs and, in general, are capable of reasoning how inputs evolve to output, specifically for simple programs and the ones 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;EntGPT&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;Entity Disambiguation&#65288;ED&#65289;&#20219;&#21153;&#65292;&#36830;&#25509;&#20102;&#29983;&#25104;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#24211;&#12290;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#21644;&#25351;&#20196;&#35843;&#25972;&#65292;&#35813;&#27169;&#22411;&#22312;&#27809;&#26377;&#26377;&#30417;&#30563;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;LLMs&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#23454;&#20307;&#28040;&#27495;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06738</link><description>&lt;p&gt;
EntGPT: &#23558;&#29983;&#25104;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#24211;&#30456;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
EntGPT: Linking Generative Large Language Models with Knowledge Bases
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;EntGPT&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;Entity Disambiguation&#65288;ED&#65289;&#20219;&#21153;&#65292;&#36830;&#25509;&#20102;&#29983;&#25104;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#24211;&#12290;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#21644;&#25351;&#20196;&#35843;&#25972;&#65292;&#35813;&#27169;&#22411;&#22312;&#27809;&#26377;&#26377;&#30417;&#30563;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;LLMs&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#23454;&#20307;&#28040;&#27495;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#35757;&#32451;&#21644;&#25512;&#29702;&#36807;&#31243;&#20013;&#32570;&#20047;&#20107;&#23454;&#26680;&#23454;&#21644;&#30693;&#35782;&#22522;&#30784;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#29983;&#25104;&#30340;&#20107;&#23454;&#27491;&#30830;&#36755;&#20986;&#30340;&#33021;&#21147;&#30456;&#23545;&#36739;&#23569;&#34987;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;Entity Disambiguation&#65288;ED&#65289;&#20219;&#21153;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;&#25552;&#31034;&#24037;&#31243;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#19977;&#27493;&#30828;&#25552;&#31034;&#26041;&#27861;&#65292;&#20197;&#22312;&#27809;&#26377;&#26377;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#30340;&#24773;&#20917;&#19979;&#25506;&#27979;LLM&#30340;ED&#24615;&#33021;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#35813;&#25552;&#31034;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#21407;&#22987;&#22522;&#20934;&#27169;&#22411;&#30340;&#24494;F_1&#24471;&#20998;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;36%&#29978;&#33267;&#26356;&#39640;&#65292;&#24182;&#22312;10&#20010;&#25968;&#25454;&#38598;&#19978;&#19982;&#29616;&#26377;&#30340;SFT&#26041;&#27861;&#30456;&#27604;&#65292;&#33719;&#24471;&#20102;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#31867;&#20284;&#30340;&#25552;&#31034;&#21644;&#21709;&#24212;&#36827;&#34892;&#25351;&#20196;&#35843;&#25972;&#65288;IT&#65289;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#30693;&#35782;&#22522;&#30784;&#12290;&#25351;&#20196;&#35843;&#25972;&#30340;&#27169;&#22411;&#22312;&#21463;&#30417;&#30563;&#23454;&#20307;&#28040;&#27495;&#20219;&#21153;&#19978;&#19981;&#20165;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#24494;F1&#24471;&#20998;&#24615;&#33021;&#65292;&#32780;&#19988;&#24179;&#22343;&#24494;F_1&#25552;&#39640;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability of Large Language Models (LLMs) to generate factually correct output remains relatively unexplored due to the lack of fact-checking and knowledge grounding during training and inference. In this work, we aim to address this challenge through the Entity Disambiguation (ED) task. We first consider prompt engineering, and design a three-step hard-prompting method to probe LLMs' ED performance without supervised fine-tuning (SFT). Overall, the prompting method improves the micro-F_1 score of the original vanilla models by a large margin, on some cases up to 36% and higher, and obtains comparable performance across 10 datasets when compared to existing methods with SFT. We further improve the knowledge grounding ability through instruction tuning (IT) with similar prompts and responses. The instruction-tuned model not only achieves higher micro-F1 score performance as compared to several baseline methods on supervised entity disambiguation tasks with an average micro-F_1 improve
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#30340;Transformer&#35299;&#30721;&#22120;&#22312;&#26377;&#38480;&#33521;&#25991;&#25968;&#25454;&#24494;&#35843;&#21518;&#33021;&#22815;&#36890;&#29992;&#22320;&#36827;&#34892;&#23884;&#20837;&#65292;&#23454;&#29616;&#20102;&#32479;&#19968;&#23884;&#20837;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.08232</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#26159;&#36890;&#29992;&#30340;&#23884;&#20837;&#22120;
&lt;/p&gt;
&lt;p&gt;
Language Models are Universal Embedders. (arXiv:2310.08232v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08232
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#30340;Transformer&#35299;&#30721;&#22120;&#22312;&#26377;&#38480;&#33521;&#25991;&#25968;&#25454;&#24494;&#35843;&#21518;&#33021;&#22815;&#36890;&#29992;&#22320;&#36827;&#34892;&#23884;&#20837;&#65292;&#23454;&#29616;&#20102;&#32479;&#19968;&#23884;&#20837;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#38761;&#21629;&#20013;&#65292;&#23884;&#20837;&#26159;&#21508;&#31181;&#31995;&#32479;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#20363;&#22914;&#65292;&#23427;&#34987;&#29992;&#20110;&#20026;LLMs&#26816;&#32034;&#30693;&#35782;&#25110;&#35760;&#24518;&#65292;&#26500;&#24314;&#20869;&#23481;&#36807;&#28388;&#22120;&#31561;&#12290;&#30001;&#20110;&#36825;&#20123;&#24773;&#20917;&#28041;&#21450;&#20174;&#33521;&#35821;&#21040;&#20854;&#20182;&#33258;&#28982;&#25110;&#32534;&#31243;&#35821;&#35328;&#65292;&#20174;&#26816;&#32034;&#21040;&#20998;&#31867;&#31561;&#21508;&#31181;&#24773;&#20917;&#65292;&#22240;&#27492;&#24314;&#31435;&#19968;&#20010;&#32479;&#19968;&#30340;&#23884;&#20837;&#27169;&#22411;&#32780;&#19981;&#26159;&#20026;&#27599;&#20010;&#22330;&#26223;&#19987;&#38376;&#24314;&#31435;&#19968;&#20010;&#26159;&#21487;&#21462;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36808;&#20986;&#20102;&#26397;&#36825;&#20010;&#30446;&#26631;&#36808;&#20986;&#20102;&#21021;&#22987;&#30340;&#19968;&#27493;&#65292;&#35777;&#26126;&#20102;&#22810;&#35821;&#35328;&#65288;&#33258;&#28982;&#35821;&#35328;&#21644;&#32534;&#31243;&#35821;&#35328;&#65289;&#39044;&#35757;&#32451;&#30340;Transformer&#35299;&#30721;&#22120;&#22312;&#26377;&#38480;&#30340;&#33521;&#25991;&#25968;&#25454;&#24494;&#35843;&#21518;&#33021;&#22815;&#36890;&#29992;&#22320;&#36827;&#34892;&#23884;&#20837;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#23454;&#36341;&#65292;&#24182;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#35780;&#20272;&#12290;&#22312;&#33521;&#25991;MTEB&#19978;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#19981;&#20351;&#29992;&#22823;&#37327;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#22312;&#19981;&#21516;&#30340;&#23884;&#20837;&#20219;&#21153;&#19978;&#36798;&#21040;&#20102;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#12290;&#22312;&#20854;&#20182;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#20363;&#22914;&#22810;&#35821;&#35328;&#20998;&#31867;&#21644;&#20195;&#30721;&#25628;&#32034;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#65288;&#27809;&#26377;&#20219;&#20309;&#30417;&#30563;&#65289;&#34920;&#29616;&#20986;&#19982;&#25110;&#29978;&#33267;&#36229;&#36807;&#22823;&#37327;&#30417;&#30563;&#22522;&#32447;&#30340;&#21487;&#27604;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the large language model (LLM) revolution, embedding is a key component of various systems. For example, it is used to retrieve knowledge or memories for LLMs, to build content moderation filters, etc. As such cases span from English to other natural or programming languages, from retrieval to classification and beyond, it is desirable to build a unified embedding model rather than dedicated ones for each scenario. In this work, we make an initial step towards this goal, demonstrating that multiple languages (both natural and programming) pre-trained transformer decoders can embed universally when finetuned on limited English data. We provide a comprehensive practice with thorough evaluations. On English MTEB, our models achieve competitive performance on different embedding tasks by minimal training data. On other benchmarks, such as multilingual classification and code search, our models (without any supervision) perform comparably to, or even surpass heavily supervised baselines 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26631;&#31614;&#27491;&#21017;&#21270;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#25324;&#20256;&#32479;&#30340;LS&#65292;&#20294;&#20063;&#21487;&#20197;&#24314;&#27169;&#23454;&#20363;&#29305;&#23450;&#30340;&#21464;&#20307;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#20248;&#21270;&#30340;&#26041;&#27861;&#65288;LABO&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#26631;&#31614;&#27491;&#21017;&#21270;&#65292;&#24182;&#24471;&#21040;&#20102;&#21487;&#35299;&#37322;&#30340;&#26368;&#20248;&#26631;&#31614;&#24179;&#28369;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.04971</link><description>&lt;p&gt;
LABO: &#36890;&#36807;&#21452;&#23618;&#20248;&#21270;&#23454;&#29616;&#26368;&#20339;&#26631;&#31614;&#27491;&#21017;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LABO: Towards Learning Optimal Label Regularization via Bi-level Optimization. (arXiv:2305.04971v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26631;&#31614;&#27491;&#21017;&#21270;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#25324;&#20256;&#32479;&#30340;LS&#65292;&#20294;&#20063;&#21487;&#20197;&#24314;&#27169;&#23454;&#20363;&#29305;&#23450;&#30340;&#21464;&#20307;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#20248;&#21270;&#30340;&#26041;&#27861;&#65288;LABO&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#26631;&#31614;&#27491;&#21017;&#21270;&#65292;&#24182;&#24471;&#21040;&#20102;&#21487;&#35299;&#37322;&#30340;&#26368;&#20248;&#26631;&#31614;&#24179;&#28369;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#25216;&#26415;&#23545;&#20110;&#25913;&#21892;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#21644;&#35757;&#32451;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#35768;&#22810;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#20381;&#36182;&#20110;&#26435;&#37325;&#34928;&#20943;&#12289;&#20002;&#24323;&#12289;&#25209;/&#23618;&#24402;&#19968;&#21270;&#31561;&#25216;&#26415;&#26469;&#26356;&#24555;&#22320;&#25910;&#25947;&#21644;&#27867;&#21270;&#12290;&#26631;&#31614;&#24179;&#28369;&#65288;LS&#65289;&#26159;&#21478;&#19968;&#31181;&#31616;&#21333;&#12289;&#36890;&#29992;&#19988;&#39640;&#25928;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#21508;&#31181;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;LS&#20551;&#35774;&#27599;&#20010;&#38750;&#30446;&#26631;&#31867;&#21035;&#20986;&#29616;&#30340;&#27010;&#29575;&#30456;&#31561;&#65292;&#19981;&#33021;&#26681;&#25454;&#23454;&#20363;&#23545;&#26631;&#31614;&#36827;&#34892;&#20248;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26631;&#31614;&#27491;&#21017;&#21270;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21253;&#25324;&#20256;&#32479;&#30340;LS&#20294;&#20063;&#21487;&#20197;&#24314;&#27169;&#23454;&#20363;&#29305;&#23450;&#30340;&#21464;&#20307;&#12290;&#22522;&#20110;&#35813;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35774;&#35745;&#21452;&#23618;&#20248;&#21270;&#65288;LABO&#65289;&#38382;&#39064;&#26469;&#23398;&#20064;&#26631;&#31614;&#27491;&#21017;&#21270;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#20869;&#29615;&#33410;&#30340;&#30830;&#23450;&#24615;&#21644;&#21487;&#35299;&#37322;&#35299;&#65292;&#32780;&#26080;&#38656;&#23384;&#20648;&#32463;&#36807;&#35757;&#32451;&#27169;&#22411;&#30340;&#21442;&#25968;&#25110;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularization techniques are crucial to improving the generalization performance and training efficiency of deep neural networks. Many deep learning algorithms rely on weight decay, dropout, batch/layer normalization to converge faster and generalize. Label Smoothing (LS) is another simple, versatile and efficient regularization which can be applied to various supervised classification tasks. Conventional LS, however, regardless of the training instance assumes that each non-target class is equally likely. In this work, we present a general framework for training with label regularization, which includes conventional LS but can also model instance-specific variants. Based on this formulation, we propose an efficient way of learning LAbel regularization by devising a Bi-level Optimization (LABO) problem. We derive a deterministic and interpretable solution of the inner loop as the optimal label smoothing without the need to store the parameters or the output of a trained model. Finally
&lt;/p&gt;</description></item></channel></rss>