<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25361;&#25112;&#24615;&#25968;&#25454;&#38598;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#23454;&#20307;&#38142;&#25509;&#20219;&#21153;&#30340;&#26032;&#38382;&#39064;&#65306;&#21333;&#20803;&#26684;&#20869;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#26694;&#26550;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36825;&#19968;&#26032;&#20219;&#21153;&#19978;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.04577</link><description>&lt;p&gt;
Wiki-TabNER:&#36890;&#36807;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#25512;&#36827;&#34920;&#26684;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25361;&#25112;&#24615;&#25968;&#25454;&#38598;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#23454;&#20307;&#38142;&#25509;&#20219;&#21153;&#30340;&#26032;&#38382;&#39064;&#65306;&#21333;&#20803;&#26684;&#20869;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#26694;&#26550;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36825;&#19968;&#26032;&#20219;&#21153;&#19978;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04577v1 &#21457;&#24067;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#32593;&#32476;&#34920;&#26684;&#21253;&#21547;&#22823;&#37327;&#23453;&#36149;&#30693;&#35782;&#65292;&#28608;&#21457;&#20102;&#26088;&#22312;&#35299;&#20915;&#34920;&#26684;&#35299;&#37322;&#65288;TI&#65289;&#20219;&#21153;&#30340;&#34920;&#26684;&#35821;&#35328;&#27169;&#22411;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#29992;&#20110;&#35780;&#20272;TI&#20219;&#21153;&#30340;&#24191;&#27867;&#20351;&#29992;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29305;&#21035;&#20851;&#27880;&#23454;&#20307;&#38142;&#25509;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26174;&#31034;&#65292;&#35813;&#25968;&#25454;&#38598;&#36807;&#20110;&#31616;&#21270;&#65292;&#21487;&#33021;&#38477;&#20302;&#20854;&#29992;&#20110;&#20840;&#38754;&#35780;&#20272;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#26410;&#20934;&#30830;&#20195;&#34920;&#34920;&#26684;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#22806;&#35266;&#12290;&#20026;&#20811;&#26381;&#36825;&#19968;&#32570;&#28857;&#65292;&#25105;&#20204;&#26500;&#24314;&#24182;&#27880;&#37322;&#20102;&#19968;&#20010;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;&#38500;&#20102;&#20171;&#32461;&#26032;&#25968;&#25454;&#38598;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#23454;&#20307;&#38142;&#25509;&#20219;&#21153;&#30340;&#26032;&#38382;&#39064;&#65306;&#21333;&#20803;&#26684;&#20869;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#26032;&#24320;&#21457;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#36825;&#19968;&#26032;&#30340;TI&#20219;&#21153;&#19978;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#23545;&#25552;&#31034;LLMs&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#65292;&#20854;&#20013;&#25105;&#20204;&#21516;&#26102;&#20351;&#29992;&#20102;&#38543;&#26426;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04577v1 Announce Type: new  Abstract: Web tables contain a large amount of valuable knowledge and have inspired tabular language models aimed at tackling table interpretation (TI) tasks. In this paper, we analyse a widely used benchmark dataset for evaluation of TI tasks, particularly focusing on the entity linking task. Our analysis reveals that this dataset is overly simplified, potentially reducing its effectiveness for thorough evaluation and failing to accurately represent tables as they appear in the real-world. To overcome this drawback, we construct and annotate a new more challenging dataset. In addition to introducing the new dataset, we also introduce a novel problem aimed at addressing the entity linking task: named entity recognition within cells. Finally, we propose a prompting framework for evaluating the newly developed large language models (LLMs) on this novel TI task. We conduct experiments on prompting LLMs under various settings, where we use both random
&lt;/p&gt;</description></item><item><title>FlexLLM&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#22312;&#21516;&#19968;&#36845;&#20195;&#20013;&#20849;&#21516;&#25552;&#20379;&#25512;&#29702;&#21644;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#35831;&#27714;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#26631;&#35760;&#32423;&#24494;&#35843;&#26426;&#21046;&#23454;&#29616;&#20849;&#20139;GPU&#36164;&#28304;&#30340;&#39640;&#25928;&#21033;&#29992;</title><link>https://arxiv.org/abs/2402.18789</link><description>&lt;p&gt;
FlexLLM&#65306;&#19968;&#31181;&#29992;&#20110;&#20849;&#21516;&#25552;&#20379;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#21644;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#30340;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18789
&lt;/p&gt;
&lt;p&gt;
FlexLLM&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#22312;&#21516;&#19968;&#36845;&#20195;&#20013;&#20849;&#21516;&#25552;&#20379;&#25512;&#29702;&#21644;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#35831;&#27714;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#26631;&#35760;&#32423;&#24494;&#35843;&#26426;&#21046;&#23454;&#29616;&#20849;&#20139;GPU&#36164;&#28304;&#30340;&#39640;&#25928;&#21033;&#29992;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Parameter-efficient finetuning&#65288;PEFT&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#20026;&#19981;&#21516;&#20219;&#21153;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#36890;&#24120;&#65292;&#26381;&#21153;&#25552;&#20379;&#21830;&#20250;&#20026;&#29992;&#25143;&#21019;&#24314;&#21333;&#29420;&#30340;&#31995;&#32479;&#65292;&#20197;&#25191;&#34892;PEFT&#27169;&#22411;&#24494;&#35843;&#21644;&#25512;&#29702;&#20219;&#21153;&#12290;&#36825;&#26159;&#22240;&#20026;&#29616;&#26377;&#31995;&#32479;&#26080;&#27861;&#22788;&#29702;&#21253;&#21547;&#25512;&#29702;&#21644;PEFT&#24494;&#35843;&#35831;&#27714;&#28151;&#21512;&#30340;&#24037;&#20316;&#36127;&#36733;&#12290;&#22240;&#27492;&#65292;&#20849;&#20139;&#30340;GPU&#36164;&#28304;&#21033;&#29992;&#19981;&#36275;&#65292;&#23548;&#33268;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FlexLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#22312;&#21516;&#19968;&#36845;&#20195;&#20013;&#20026;&#25512;&#29702;&#21644;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#35831;&#27714;&#25552;&#20379;&#26381;&#21153;&#30340;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#21033;&#29992;&#36825;&#20004;&#20010;&#20219;&#21153;&#30340;&#20114;&#34917;&#24615;&#36136;&#65292;&#24182;&#21033;&#29992;&#20849;&#20139;&#30340;GPU&#36164;&#28304;&#26469;&#20849;&#21516;&#36816;&#34892;&#23427;&#20204;&#65292;&#20351;&#29992;&#19968;&#31181;&#31216;&#20026;&#20849;&#21516;&#25552;&#20379;&#30340;&#26041;&#27861;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;FlexLLM&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26631;&#35760;&#32423;&#24494;&#35843;&#26426;&#21046;&#65292;&#23558;&#24207;&#21015;&#30340;&#24494;&#35843;&#35745;&#31639;&#20998;&#35299;&#20026;&#26356;&#23567;&#30340;&#26631;&#35760;&#32423;&#35745;&#31639;&#65292;&#24182;&#20351;&#29992;&#20381;&#36182;&#24182;&#34892;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18789v1 Announce Type: cross  Abstract: Parameter-efficient finetuning (PEFT) is a widely used technique to adapt large language models for different tasks. Service providers typically create separate systems for users to perform PEFT model finetuning and inference tasks. This is because existing systems cannot handle workloads that include a mix of inference and PEFT finetuning requests. As a result, shared GPU resources are underutilized, leading to inefficiencies. To address this problem, we present FlexLLM, the first system that can serve inference and parameter-efficient finetuning requests in the same iteration. Our system leverages the complementary nature of these two tasks and utilizes shared GPU resources to run them jointly, using a method called co-serving. To achieve this, FlexLLM introduces a novel token-level finetuning mechanism, which breaks down the finetuning computation of a sequence into smaller token-level computations and uses dependent parallelization
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26041;&#38754;&#24863;&#30693;&#30340;&#35780;&#20272;&#25351;&#26631;&#65288;FM&#65289;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#25688;&#35201;&#36827;&#34892;&#39640;&#32423;&#35821;&#20041;&#21305;&#37197;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#20840;&#38754;&#35780;&#20272;&#31185;&#23398;&#25688;&#35201;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.14359</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#31185;&#23398;&#25688;&#35201;&#35780;&#20272;&#65306;&#22522;&#20110;&#26041;&#38754;&#24863;&#30693;&#22522;&#20934;&#30340;&#21487;&#35299;&#37322;&#24230;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Rethinking Scientific Summarization Evaluation: Grounding Explainable Metrics on Facet-aware Benchmark
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14359
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26041;&#38754;&#24863;&#30693;&#30340;&#35780;&#20272;&#25351;&#26631;&#65288;FM&#65289;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#25688;&#35201;&#36827;&#34892;&#39640;&#32423;&#35821;&#20041;&#21305;&#37197;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#20840;&#38754;&#35780;&#20272;&#31185;&#23398;&#25688;&#35201;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25688;&#35201;&#33021;&#21147;&#22312;&#19968;&#33324;&#39046;&#22495;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#39564;&#35777;&#65292;&#20294;&#23427;&#20204;&#22312;&#28041;&#21450;&#22797;&#26434;&#21477;&#23376;&#21644;&#19987;&#19994;&#30693;&#35782;&#30340;&#31185;&#23398;&#35821;&#26009;&#24211;&#20013;&#30340;&#20351;&#29992;&#36739;&#23569;&#34987;&#35780;&#20272;&#12290;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#31185;&#23398;&#25688;&#35201;&#30340;&#27010;&#24565;&#21644;&#23454;&#39564;&#20998;&#26512;&#65292;&#31361;&#20986;&#20102;&#20256;&#32479;&#35780;&#20272;&#26041;&#27861;&#65288;&#22914;$n$-gram&#12289;&#23884;&#20837;&#27604;&#36739;&#21644;&#38382;&#31572;&#65289;&#22312;&#25552;&#20379;&#35299;&#37322;&#12289;&#25226;&#25569;&#31185;&#23398;&#27010;&#24565;&#25110;&#35782;&#21035;&#20851;&#38190;&#20869;&#23481;&#26041;&#38754;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Facet-aware Metric&#65288;FM&#65289;&#65292;&#21033;&#29992;LLMs&#36827;&#34892;&#39640;&#32423;&#35821;&#20041;&#21305;&#37197;&#65292;&#26681;&#25454;&#19981;&#21516;&#26041;&#38754;&#35780;&#20272;&#25688;&#35201;&#12290;&#36825;&#31181;&#38754;&#21521;&#26041;&#38754;&#30340;&#26041;&#27861;&#36890;&#36807;&#23558;&#35780;&#20272;&#20219;&#21153;&#20998;&#35299;&#20026;&#26356;&#31616;&#21333;&#30340;&#23376;&#20219;&#21153;&#65292;&#20026;&#25688;&#35201;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#35780;&#20272;&#12290;&#37492;&#20110;&#35813;&#39046;&#22495;&#32570;&#20047;&#35780;&#20272;&#22522;&#20934;&#65292;&#25105;&#20204;&#31934;&#24515;&#31574;&#21010;&#20102;&#19968;&#20010;&#22522;&#20110;&#26041;&#38754;&#30340;&#31185;&#23398;&#25688;&#35201;&#25968;&#25454;&#38598;&#65288;FD&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14359v1 Announce Type: new  Abstract: The summarization capabilities of pretrained and large language models (LLMs) have been widely validated in general areas, but their use in scientific corpus, which involves complex sentences and specialized knowledge, has been less assessed. This paper presents conceptual and experimental analyses of scientific summarization, highlighting the inadequacies of traditional evaluation methods, such as $n$-gram, embedding comparison, and QA, particularly in providing explanations, grasping scientific concepts, or identifying key content. Subsequently, we introduce the Facet-aware Metric (FM), employing LLMs for advanced semantic matching to evaluate summaries based on different aspects. This facet-aware approach offers a thorough evaluation of abstracts by decomposing the evaluation task into simpler subtasks.Recognizing the absence of an evaluation benchmark in this domain, we curate a Facet-based scientific summarization Dataset (FD) with 
&lt;/p&gt;</description></item><item><title>AutoPlanBench&#26159;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#36716;&#25442;PDDL&#35268;&#21010;&#22522;&#20934;&#27979;&#35797;&#20026;&#25991;&#26412;&#25551;&#36848;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#21069;&#26368;&#22909;&#30340;LLM&#35268;&#21010;&#22120;&#22312;&#26576;&#20123;&#35268;&#21010;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#31168;&#65292;&#20294;&#23545;&#20110;&#20854;&#20182;&#20219;&#21153;&#26469;&#35828;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2311.09830</link><description>&lt;p&gt;
AutoPlanBench: &#20174;PDDL&#33258;&#21160;&#29983;&#25104;LLM&#35268;&#21010;&#22120;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
AutoPlanBench: Automatically generating benchmarks for LLM planners from PDDL
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09830
&lt;/p&gt;
&lt;p&gt;
AutoPlanBench&#26159;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#36716;&#25442;PDDL&#35268;&#21010;&#22522;&#20934;&#27979;&#35797;&#20026;&#25991;&#26412;&#25551;&#36848;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#21069;&#26368;&#22909;&#30340;LLM&#35268;&#21010;&#22120;&#22312;&#26576;&#20123;&#35268;&#21010;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#31168;&#65292;&#20294;&#23545;&#20110;&#20854;&#20182;&#20219;&#21153;&#26469;&#35828;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#65288;&#36923;&#36753;-&#27010;&#29575;&#27169;&#22411;&#65289;&#22312;&#35268;&#21010;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#65292;&#20294;&#26159;&#23427;&#20204;&#22312;&#35268;&#21010;&#21644;&#25512;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#23578;&#19981;&#26126;&#30830;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;AutoPlanBench&#65292;&#19968;&#31181;&#23558;PDDL&#20013;&#30340;&#35268;&#21010;&#22522;&#20934;&#27979;&#35797;&#33258;&#21160;&#36716;&#25442;&#20026;&#25991;&#26412;&#25551;&#36848;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#25105;&#20204;&#26041;&#27861;&#21019;&#24314;&#30340;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#22909;&#30340;LLM&#35268;&#21010;&#22120;&#22312;&#26576;&#20123;&#35268;&#21010;&#20219;&#21153;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#20854;&#20182;&#20219;&#21153;&#20173;&#28982;&#36229;&#20986;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#33021;&#21147;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
LLMs are being increasingly used for planning-style tasks, but their capabilities for planning and reasoning are poorly understood. We present AutoPlanBench, a novel method for automatically converting planning benchmarks written in PDDL into textual descriptions and offer a benchmark dataset created with our method. We show that while the best LLM planners do well on some planning tasks, others remain out of reach of current methods.
&lt;/p&gt;</description></item></channel></rss>