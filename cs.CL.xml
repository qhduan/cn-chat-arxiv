<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22312;&#22238;&#31572;&#21307;&#23398;&#38382;&#39064;&#26041;&#38754;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#23454;&#38469;&#20020;&#24202;&#26696;&#20363;&#19978;&#30340;&#34920;&#29616;&#26159;&#20851;&#38190;&#65292;&#22240;&#27492;&#26500;&#24314;&#20102;&#20004;&#20010;&#32467;&#26500;&#21270;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2402.18060</link><description>&lt;p&gt;
&#22312;&#22238;&#31572;&#21644;&#35299;&#37322;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#21307;&#23398;&#38382;&#39064;&#19978;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Large Language Models on Answering and Explaining Challenging Medical Questions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18060
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22238;&#31572;&#21307;&#23398;&#38382;&#39064;&#26041;&#38754;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#23454;&#38469;&#20020;&#24202;&#26696;&#20363;&#19978;&#30340;&#34920;&#29616;&#26159;&#20851;&#38190;&#65292;&#22240;&#27492;&#26500;&#24314;&#20102;&#20004;&#20010;&#32467;&#26500;&#21270;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#22312;&#22238;&#31572;&#21307;&#23398;&#38382;&#39064;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20363;&#22914;&#36890;&#36807;&#21307;&#23398;&#25191;&#29031;&#32771;&#35797;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#20381;&#36182;&#20110;&#22996;&#21592;&#20250;&#32771;&#35797;&#38382;&#39064;&#25110;&#19968;&#33324;&#21307;&#23398;&#38382;&#39064;&#65292;&#26080;&#27861;&#25429;&#25417;&#30495;&#23454;&#20020;&#24202;&#26696;&#20363;&#30340;&#22797;&#26434;&#24615;&#12290;&#27492;&#22806;&#65292;&#32570;&#20047;&#31572;&#26696;&#30340;&#21442;&#32771;&#35299;&#37322;&#38459;&#30861;&#20102;&#23545;&#27169;&#22411;&#35299;&#37322;&#30340;&#35780;&#20272;&#65292;&#36825;&#23545;&#25903;&#25345;&#21307;&#29983;&#20570;&#20986;&#22797;&#26434;&#30340;&#21307;&#30103;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#20004;&#20010;&#26032;&#25968;&#25454;&#38598;&#65306;JAMA&#20020;&#24202;&#25361;&#25112;&#21644;Medbullets&#12290;JAMA&#20020;&#24202;&#25361;&#25112;&#21253;&#21547;&#22522;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20020;&#24202;&#26696;&#20363;&#30340;&#38382;&#39064;&#65292;&#32780;Medbullets&#21253;&#21547;&#31867;&#20284;USMLE Step 2&amp;3&#39118;&#26684;&#30340;&#20020;&#24202;&#38382;&#39064;&#12290;&#20004;&#20010;&#25968;&#25454;&#38598;&#22343;&#20197;&#22810;&#39033;&#36873;&#25321;&#38382;&#39064;-&#22238;&#31572;&#20219;&#21153;&#30340;&#32467;&#26500;&#21270;&#24418;&#24335;&#21576;&#29616;&#65292;&#27599;&#20010;&#38382;&#39064;&#37117;&#38468;&#26377;&#19987;&#23478;&#25776;&#20889;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#22312;&#36825;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#22235;&#20010;LLMs&#12290;&#23454;&#39564;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18060v1 Announce Type: new  Abstract: LLMs have demonstrated impressive performance in answering medical questions, such as passing medical licensing examinations. However, most existing benchmarks rely on board exam questions or general medical questions, falling short in capturing the complexity of realistic clinical cases. Moreover, the lack of reference explanations for answers hampers the evaluation of model explanations, which are crucial to supporting doctors in making complex medical decisions. To address these challenges, we construct two new datasets: JAMA Clinical Challenge and Medbullets. JAMA Clinical Challenge consists of questions based on challenging clinical cases, while Medbullets comprises USMLE Step 2&amp;3 style clinical questions. Both datasets are structured as multiple-choice question-answering tasks, where each question is accompanied by an expert-written explanation. We evaluate four LLMs on the two datasets using various prompts. Experiments demonstrat
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20445;&#25252;&#20010;&#20154;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25239;&#24615;LLM&#25512;&#26029;&#30340;&#21311;&#21517;&#21270;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2402.13846</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#20808;&#36827;&#30340;&#21311;&#21517;&#21270;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Advanced Anonymizers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13846
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20445;&#25252;&#20010;&#20154;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25239;&#24615;LLM&#25512;&#26029;&#30340;&#21311;&#21517;&#21270;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#38544;&#31169;&#30740;&#31350;&#39046;&#22495;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23427;&#20204;&#22312;&#25512;&#26029;&#30495;&#23454;&#19990;&#30028;&#22312;&#32447;&#25991;&#26412;&#20013;&#30340;&#20010;&#20154;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#25509;&#36817;&#20154;&#31867;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;&#38543;&#30528;&#27169;&#22411;&#33021;&#21147;&#30340;&#19981;&#26029;&#22686;&#24378;&#65292;&#29616;&#26377;&#30340;&#25991;&#26412;&#21311;&#21517;&#21270;&#26041;&#27861;&#24403;&#21069;&#24050;&#32463;&#33853;&#21518;&#20110;&#30417;&#31649;&#35201;&#27714;&#21644;&#23545;&#25239;&#23041;&#32961;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#20010;&#20154;&#22914;&#20309;&#26377;&#25928;&#22320;&#20445;&#25252;&#20182;&#20204;&#22312;&#20998;&#20139;&#22312;&#32447;&#25991;&#26412;&#26102;&#30340;&#20010;&#20154;&#25968;&#25454;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#20004;&#27493;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35774;&#32622;&#65292;&#29992;&#20110;&#35780;&#20272;&#38754;&#23545;&#23545;&#25239;&#24615;LLM&#30340;&#25512;&#26029;&#26102;&#30340;&#21311;&#21517;&#21270;&#25928;&#26524;&#65292;&#20174;&#32780;&#20801;&#35768;&#33258;&#28982;&#22320;&#27979;&#37327;&#21311;&#21517;&#21270;&#24615;&#33021;&#65292;&#21516;&#26102;&#32416;&#27491;&#20102;&#20197;&#21069;&#25351;&#26631;&#30340;&#19968;&#20123;&#32570;&#38519;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;LLM&#30340;&#23545;&#25239;&#24615;&#21311;&#21517;&#21270;&#26694;&#26550;&#65292;&#21033;&#29992;LLM&#30340;&#24378;&#22823;&#25512;&#26029;&#33021;&#21147;&#26469;&#25351;&#23548;&#25105;&#20204;&#30340;&#21311;&#21517;&#21270;&#36807;&#31243;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#30340;&#21311;&#21517;&#21270;&#23454;&#36341;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13846v1 Announce Type: cross  Abstract: Recent work in privacy research on large language models has shown that they achieve near human-level performance at inferring personal data from real-world online texts. With consistently increasing model capabilities, existing text anonymization methods are currently lacking behind regulatory requirements and adversarial threats. This raises the question of how individuals can effectively protect their personal data in sharing online texts. In this work, we take two steps to answer this question: We first present a new setting for evaluating anonymizations in the face of adversarial LLMs inferences, allowing for a natural measurement of anonymization performance while remedying some of the shortcomings of previous metrics. We then present our LLM-based adversarial anonymization framework leveraging the strong inferential capabilities of LLMs to inform our anonymization procedure. In our experimental evaluation, we show on real-world 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102; Persona-DB&#65292;&#19968;&#20010;&#31616;&#21333;&#21364;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23618;&#32423;&#26500;&#24314;&#36807;&#31243;&#21644;&#21327;&#21516;&#20248;&#21270;&#65292;&#25913;&#21892;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#20013;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#26816;&#32034;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.11060</link><description>&lt;p&gt;
Persona-DB&#65306;&#29992;&#20110;&#21709;&#24212;&#39044;&#27979;&#30340;&#39640;&#25928;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#19982;&#21327;&#21516;&#25968;&#25454;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11060
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102; Persona-DB&#65292;&#19968;&#20010;&#31616;&#21333;&#21364;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23618;&#32423;&#26500;&#24314;&#36807;&#31243;&#21644;&#21327;&#21516;&#20248;&#21270;&#65292;&#25913;&#21892;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20010;&#24615;&#21270;&#20013;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#26816;&#32034;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20010;&#24615;&#21270;&#20132;&#20114;&#38656;&#27714;&#30340;&#22686;&#21152;&#65292;&#38656;&#35201;&#24320;&#21457;&#33021;&#22815;&#20934;&#30830;&#24555;&#36895;&#35782;&#21035;&#29992;&#25143;&#24847;&#35265;&#21644;&#20559;&#22909;&#30340;&#26041;&#27861;&#12290;&#26816;&#32034;&#22686;&#24378;&#20316;&#20026;&#19968;&#31181;&#26377;&#25928;&#31574;&#30053;&#20986;&#29616;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#36866;&#24212;&#22823;&#37327;&#29992;&#25143;&#32780;&#26080;&#38656;&#36827;&#34892;&#24494;&#35843;&#30340;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22686;&#24378;&#26816;&#32034;&#38454;&#27573;&#65292;&#24182;&#23545;&#25968;&#25454;&#24211;&#34920;&#31034;&#30340;&#20248;&#21270;&#36827;&#34892;&#20102;&#26377;&#38480;&#30340;&#25506;&#32034;&#65292;&#36825;&#26159;&#20010;&#24615;&#21270;&#31561;&#20219;&#21153;&#30340;&#20851;&#38190;&#26041;&#38754;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#19968;&#20010;&#26032;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#30528;&#37325;&#20110;&#22914;&#20309;&#26356;&#26377;&#25928;&#22320;&#34920;&#31034;&#25968;&#25454;&#65292;&#20197;&#20415;&#22312;LLM&#23450;&#21046;&#30340;&#24773;&#22659;&#19979;&#26356;&#26377;&#25928;&#22320;&#36827;&#34892;&#26816;&#32034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Persona-DB&#65292;&#36825;&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#19968;&#20010;&#20998;&#23618;&#26500;&#24314;&#36807;&#31243;&#65292;&#20197;&#25913;&#21892;&#36328;&#20219;&#21153;&#32972;&#26223;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#36827;&#34892;&#21327;&#21516;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11060v1 Announce Type: cross  Abstract: The increasing demand for personalized interactions with large language models (LLMs) calls for the development of methodologies capable of accurately and efficiently identifying user opinions and preferences. Retrieval augmentation emerges as an effective strategy, as it can accommodate a vast number of users without the costs from fine-tuning. Existing research, however, has largely focused on enhancing the retrieval stage and devoted limited exploration toward optimizing the representation of the database, a crucial aspect for tasks such as personalization. In this work, we examine the problem from a novel angle, focusing on how data can be better represented for more efficient retrieval in the context of LLM customization. To tackle this challenge, we introduce Persona-DB, a simple yet effective framework consisting of a hierarchical construction process to improve generalization across task contexts and collaborative refinement to
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#23613;&#31649;&#23427;&#20204;&#33021;&#22815;&#34701;&#20837;&#21644;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#12290;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#38656;&#35201;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.06049</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Limits of Large Language Models in Debating Humans
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06049
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#20154;&#31867;&#36777;&#35770;&#20013;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#23613;&#31649;&#23427;&#20204;&#33021;&#22815;&#34701;&#20837;&#21644;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#12290;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#38656;&#35201;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#19982;&#20154;&#31867;&#30340;&#20114;&#21160;&#20013;&#23637;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#28508;&#21147;&#12290;&#38543;&#21518;&#65292;&#23558;&#23427;&#20204;&#20316;&#20026;&#20154;&#24037;&#20195;&#34920;&#21644;&#26367;&#20195;&#21697;&#36827;&#34892;&#31038;&#20250;&#23398;&#23454;&#39564;&#30340;&#28508;&#22312;&#24212;&#29992;&#26159;&#19968;&#20010;&#20196;&#20154;&#28608;&#21160;&#30340;&#21069;&#26223;&#12290;&#20294;&#26159;&#36825;&#20010;&#24819;&#27861;&#26377;&#22810;&#21487;&#34892;&#21602;&#65311;&#26412;&#25991;&#35797;&#22270;&#36890;&#36807;&#19968;&#39033;&#39044;&#20808;&#27880;&#20876;&#30340;&#30740;&#31350;&#26469;&#27979;&#35797;&#29616;&#38454;&#27573;LLMs&#30340;&#23616;&#38480;&#24615;&#65292;&#35813;&#30740;&#31350;&#23558;&#30495;&#23454;&#30340;&#20154;&#31867;&#19982;&#25198;&#28436;&#20154;&#31867;&#30340;LLM&#20195;&#29702;&#32467;&#21512;&#36215;&#26469;&#12290;&#26412;&#30740;&#31350;&#30528;&#37325;&#25506;&#35752;&#36777;&#35770;&#20026;&#22522;&#30784;&#30340;&#24847;&#35265;&#20849;&#35782;&#24418;&#25104;&#22312;&#19977;&#31181;&#29615;&#22659;&#19979;&#30340;&#24773;&#20917;&#65306;&#20165;&#20154;&#31867;&#12289;&#20195;&#29702;&#21644;&#20154;&#31867;&#12289;&#20165;&#20195;&#29702;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#29702;&#35299;LLM&#20195;&#29702;&#23545;&#20154;&#31867;&#30340;&#24433;&#21709;&#65292;&#24182;&#35780;&#20272;&#23427;&#20204;&#22312;&#36777;&#35770;&#26041;&#38754;&#30340;&#33021;&#21147;&#26159;&#21542;&#19982;&#20154;&#31867;&#30456;&#20284;&#12290;&#25105;&#20204;&#21457;&#29616;LLMs&#33021;&#22815;&#34701;&#20837;&#24182;&#20419;&#36827;&#20154;&#31867;&#30340;&#24037;&#20316;&#25928;&#29575;&#65292;&#20294;&#22312;&#36777;&#35770;&#20013;&#30340;&#35828;&#26381;&#21147;&#36739;&#24369;&#65292;&#26368;&#32456;&#34892;&#20026;&#19982;&#20154;&#31867;&#26377;&#25152;&#20559;&#31163;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#36825;&#20123;&#20027;&#35201;&#32570;&#38519;&#65292;&#24182;&#39044;&#35745;&#22312;&#25104;&#20026;&#21487;&#34892;&#30340;&#36777;&#25163;&#20043;&#21069;&#65292;LLMs&#24517;&#39035;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown remarkable promise in their ability to interact proficiently with humans. Subsequently, their potential use as artificial confederates and surrogates in sociological experiments involving conversation is an exciting prospect. But how viable is this idea? This paper endeavors to test the limits of current-day LLMs with a pre-registered study integrating real people with LLM agents acting as people. The study focuses on debate-based opinion consensus formation in three environments: humans only, agents and humans, and agents only. Our goal is to understand how LLM agents influence humans, and how capable they are in debating like humans. We find that LLMs can blend in and facilitate human productivity but are less convincing in debate, with their behavior ultimately deviating from human's. We elucidate these primary failings and anticipate that LLMs must evolve further before being viable debaters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#29992;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#21542;&#35760;&#24518;&#20102;&#24050;&#30693;&#26412;&#20307;&#35770;&#30340;&#20449;&#24687;&#20197;&#21450;&#35760;&#24518;&#30340;&#31243;&#24230;&#65292;&#32467;&#26524;&#26174;&#31034;LLMs&#37096;&#20998;&#22320;&#20102;&#35299;&#26412;&#20307;&#35770;&#30340;&#27010;&#24565;&#65292;&#35760;&#24518;&#31243;&#24230;&#19982;&#20854;&#22312;Web&#19978;&#30340;&#27969;&#34892;&#31243;&#24230;&#25104;&#27491;&#27604;&#12290;</title><link>http://arxiv.org/abs/2401.14931</link><description>&lt;p&gt;
LLM&#26159;&#21542;&#33021;&#35760;&#24518;&#26412;&#20307;&#35770;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do LLMs Dream of Ontologies?. (arXiv:2401.14931v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#29992;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#21542;&#35760;&#24518;&#20102;&#24050;&#30693;&#26412;&#20307;&#35770;&#30340;&#20449;&#24687;&#20197;&#21450;&#35760;&#24518;&#30340;&#31243;&#24230;&#65292;&#32467;&#26524;&#26174;&#31034;LLMs&#37096;&#20998;&#22320;&#20102;&#35299;&#26412;&#20307;&#35770;&#30340;&#27010;&#24565;&#65292;&#35760;&#24518;&#31243;&#24230;&#19982;&#20854;&#22312;Web&#19978;&#30340;&#27969;&#34892;&#31243;&#24230;&#25104;&#27491;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26368;&#36817;&#22312;&#33258;&#21160;&#25991;&#26412;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#12290;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#20381;&#36182;&#20110;&#24213;&#23618;&#31070;&#32463;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#30340;&#21442;&#25968;&#25968;&#37327;&#65292;&#36825;&#20351;&#24471;LLMs&#33021;&#22815;&#35760;&#24518;&#35757;&#32451;&#36807;&#31243;&#20013;&#25509;&#35302;&#21040;&#30340;&#22823;&#37327;&#25968;&#25454;&#30340;&#19968;&#37096;&#20998;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#29992;&#39044;&#35757;&#32451;LLMs&#26159;&#21542;&#35760;&#24518;&#20102;&#24050;&#30693;&#26412;&#20307;&#35770;&#30340;&#20449;&#24687;&#20197;&#21450;&#35760;&#24518;&#30340;&#31243;&#24230;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#37096;&#20998;&#22320;&#20102;&#35299;&#26412;&#20307;&#35770;&#65306;&#23427;&#20204;&#21487;&#20197;&#35760;&#24518;&#25991;&#26412;&#20013;&#25552;&#21040;&#30340;&#26412;&#20307;&#35770;&#27010;&#24565;&#65292;&#20294;&#20854;&#23545;&#27010;&#24565;&#30340;&#35760;&#24518;&#31243;&#24230;&#20284;&#20046;&#19982;&#20854;&#22312;Web&#19978;&#30340;&#27969;&#34892;&#31243;&#24230;&#25104;&#27604;&#20363;&#21464;&#21270;&#65292;&#22240;&#20026;Web&#26159;&#23427;&#20204;&#35757;&#32451;&#26448;&#26009;&#30340;&#20027;&#35201;&#26469;&#28304;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#36890;&#36807;&#27979;&#37327;&#19981;&#21516;&#25552;&#31034;&#37325;&#22797;&#12289;&#26597;&#35810;&#35821;&#35328;&#21644;&#30830;&#23450;&#24230;&#30340;&#36755;&#20986;&#19968;&#33268;&#24615;&#26469;&#20272;&#35745;LLMs&#23545;&#26412;&#20307;&#35770;&#20449;&#24687;&#30340;&#35760;&#24518;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have recently revolutionized automated text understanding and generation. The performance of these models relies on the high number of parameters of the underlying neural architectures, which allows LLMs to memorize part of the vast quantity of data seen during the training. This paper investigates whether and to what extent general-purpose pre-trained LLMs have memorized information from known ontologies. Our results show that LLMs partially know ontologies: they can, and do indeed, memorize concepts from ontologies mentioned in the text, but the level of memorization of their concepts seems to vary proportionally to their popularity on the Web, the primary source of their training material. We additionally propose new metrics to estimate the degree of memorization of ontological information in LLMs by measuring the consistency of the output produced across different prompt repetitions, query languages, and degrees of determinism.
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#22312;&#29983;&#29289;&#20449;&#24687;&#23398;&#20013;&#20351;&#29992;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22914;BERT&#21644;GPT&#65292;&#24182;&#37325;&#28857;&#25506;&#35752;&#20102;&#23427;&#20204;&#22312;&#22522;&#22240;&#32452;&#23398;&#12289;&#36716;&#24405;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#12289;&#33647;&#29289;&#21457;&#29616;&#21644;&#21333;&#32454;&#32990;&#20998;&#26512;&#31561;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#29983;&#29289;&#20449;&#24687;&#23398;&#38382;&#39064;&#26041;&#38754;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#21644;&#21069;&#26223;&#12290;</title><link>http://arxiv.org/abs/2401.04155</link><description>&lt;p&gt;
&#29983;&#29289;&#20449;&#24687;&#23398;&#20013;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#24212;&#29992;&#19982;&#23637;&#26395;
&lt;/p&gt;
&lt;p&gt;
Large language models in bioinformatics: applications and perspectives. (arXiv:2401.04155v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04155
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#20171;&#32461;&#20102;&#22312;&#29983;&#29289;&#20449;&#24687;&#23398;&#20013;&#20351;&#29992;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22914;BERT&#21644;GPT&#65292;&#24182;&#37325;&#28857;&#25506;&#35752;&#20102;&#23427;&#20204;&#22312;&#22522;&#22240;&#32452;&#23398;&#12289;&#36716;&#24405;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#12289;&#33647;&#29289;&#21457;&#29616;&#21644;&#21333;&#32454;&#32990;&#20998;&#26512;&#31561;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#29983;&#29289;&#20449;&#24687;&#23398;&#38382;&#39064;&#26041;&#38754;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#21644;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#19968;&#31867;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#23588;&#20854;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#24120;&#30001;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#32452;&#25104;&#65292;&#36890;&#36807;&#33258;&#30417;&#30563;&#25110;&#21322;&#30417;&#30563;&#23398;&#20064;&#65292;&#22312;&#22823;&#37327;&#26080;&#26631;&#31614;&#36755;&#20837;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#35299;&#20915;&#29983;&#29289;&#20449;&#24687;&#23398;&#38382;&#39064;&#26041;&#38754;&#30340;&#28508;&#21147;&#29978;&#33267;&#36229;&#36807;&#20102;&#22312;&#27169;&#25311;&#20154;&#31867;&#35821;&#35328;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#31687;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#23558;&#20171;&#32461;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#20351;&#29992;&#30340;&#20960;&#20010;&#37325;&#35201;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#22914;BERT&#21644;GPT&#65292;&#24182;&#37325;&#28857;&#25506;&#35752;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#29289;&#20449;&#24687;&#23398;&#20013;&#19981;&#21516;&#32452;&#23398;&#27700;&#24179;&#30340;&#24212;&#29992;&#65292;&#20027;&#35201;&#21253;&#25324;&#22522;&#22240;&#32452;&#23398;&#12289;&#36716;&#24405;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#12289;&#33647;&#29289;&#21457;&#29616;&#21644;&#21333;&#32454;&#32990;&#20998;&#26512;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;&#26368;&#21518;&#65292;&#26412;&#32508;&#36848;&#24635;&#32467;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#29983;&#29289;&#20449;&#24687;&#23398;&#38382;&#39064;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are a class of artificial intelligence models based on deep learning, which have great performance in various tasks, especially in natural language processing (NLP). Large language models typically consist of artificial neural networks with numerous parameters, trained on large amounts of unlabeled input using self-supervised or semi-supervised learning. However, their potential for solving bioinformatics problems may even exceed their proficiency in modeling human language. In this review, we will present a summary of the prominent large language models used in natural language processing, such as BERT and GPT, and focus on exploring the applications of large language models at different omics levels in bioinformatics, mainly including applications of large language models in genomics, transcriptomics, proteomics, drug discovery and single cell analysis. Finally, this review summarizes the potential and prospects of large language models in solving bioinfo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#30340;&#26500;&#24314;&#27969;&#31243;&#12289;&#20851;&#38190;&#25216;&#26415;&#21644;&#21033;&#29992;&#26041;&#27861;&#20197;&#21450;&#29616;&#26377;&#36164;&#28304;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.04802</link><description>&lt;p&gt;
&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;&#32508;&#36848;&#65306;&#36164;&#28304;&#12289;&#24212;&#29992;&#21644;&#21069;&#26223;
&lt;/p&gt;
&lt;p&gt;
A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#30340;&#26500;&#24314;&#27969;&#31243;&#12289;&#20851;&#38190;&#25216;&#26415;&#21644;&#21033;&#29992;&#26041;&#27861;&#20197;&#21450;&#29616;&#26377;&#36164;&#28304;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#24050;&#25104;&#20026;&#32452;&#32455;&#21307;&#23398;&#30693;&#35782;&#30340;&#26377;&#32467;&#26500;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#20026;&#24037;&#20855;&#65292;&#25552;&#20379;&#20102;&#21307;&#23398;&#27010;&#24565;&#21450;&#20854;&#20851;&#31995;&#30340;&#20840;&#38754;&#35270;&#22270;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#35206;&#30422;&#33539;&#22260;&#26377;&#38480;&#31561;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#65292;&#24378;&#35843;&#20102;&#22312;HKG&#39046;&#22495;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24517;&#35201;&#24615;&#12290;&#26412;&#32508;&#36848;&#26159;HKG&#30340;&#31532;&#19968;&#20221;&#32508;&#21512;&#27010;&#36848;&#12290;&#25105;&#20204;&#24635;&#32467;&#20102;HKG&#26500;&#24314;&#30340;&#27969;&#31243;&#21644;&#20851;&#38190;&#25216;&#26415;&#65288;&#21363;&#20174;&#22836;&#24320;&#22987;&#21644;&#36890;&#36807;&#38598;&#25104;&#65289;&#65292;&#20197;&#21450;&#24120;&#35265;&#30340;&#21033;&#29992;&#26041;&#27861;&#65288;&#21363;&#22522;&#20110;&#27169;&#22411;&#21644;&#38750;&#22522;&#20110;&#27169;&#22411;&#65289;&#12290;&#20026;&#20102;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#36164;&#28304;&#65292;&#25105;&#20204;&#26681;&#25454;&#23427;&#20204;&#25429;&#33719;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#24212;&#29992;&#39046;&#22495;&#65288;&#35813;&#36164;&#28304;&#23384;&#20648;&#20110;https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase&#65289;&#32452;&#32455;&#20102;&#29616;&#26377;&#30340;HKG&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;&#22312;&#24212;&#29992;&#37096;&#20998;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
&lt;/p&gt;</description></item></channel></rss>