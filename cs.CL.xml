<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>Dataverse&#26159;&#19968;&#20010;&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#28304;ETL&#31649;&#36947;&#65292;&#25552;&#20379;&#20102;&#29992;&#25143;&#21451;&#22909;&#30340;&#35774;&#35745;&#21644;&#26131;&#20110;&#23450;&#21046;&#30340;&#22788;&#29702;&#22120;&#28155;&#21152;&#21151;&#33021;&#65292;&#26088;&#22312;&#25104;&#20026;LLM&#24320;&#21457;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#24182;&#24320;&#28304;&#25972;&#20010;&#24211;&#20197;&#20419;&#36827;&#31038;&#21306;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2403.19340</link><description>&lt;p&gt;
Dataverse&#65306;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#28304;ETL&#65288;&#25277;&#21462;&#12289;&#36716;&#25442;&#12289;&#21152;&#36733;&#65289;&#31649;&#36947;
&lt;/p&gt;
&lt;p&gt;
Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19340
&lt;/p&gt;
&lt;p&gt;
Dataverse&#26159;&#19968;&#20010;&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#28304;ETL&#31649;&#36947;&#65292;&#25552;&#20379;&#20102;&#29992;&#25143;&#21451;&#22909;&#30340;&#35774;&#35745;&#21644;&#26131;&#20110;&#23450;&#21046;&#30340;&#22788;&#29702;&#22120;&#28155;&#21152;&#21151;&#33021;&#65292;&#26088;&#22312;&#25104;&#20026;LLM&#24320;&#21457;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#24182;&#24320;&#28304;&#25972;&#20010;&#24211;&#20197;&#20419;&#36827;&#31038;&#21306;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;&#35268;&#27169;&#21270;&#25968;&#25454;&#22788;&#29702;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Dataverse&#65292;&#19968;&#20010;&#32479;&#19968;&#30340;&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24320;&#28304;&#25277;&#21462;-&#36716;&#25442;-&#21152;&#36733;&#65288;ETL&#65289;&#31649;&#36947;&#65292;&#20854;&#26680;&#24515;&#20855;&#26377;&#29992;&#25143;&#21451;&#22909;&#30340;&#35774;&#35745;&#12290;&#22312;Dataverse&#20013;&#65292;&#36890;&#36807;&#22522;&#20110;&#22359;&#30340;&#30028;&#38754;&#36731;&#26494;&#28155;&#21152;&#33258;&#23450;&#20041;&#22788;&#29702;&#22120;&#65292;&#20351;&#29992;&#25143;&#21487;&#20197;&#26041;&#20415;&#39640;&#25928;&#22320;&#20351;&#29992;Dataverse&#26500;&#24314;&#33258;&#24049;&#30340;ETL&#31649;&#36947;&#12290;&#25105;&#20204;&#24076;&#26395;Dataverse&#23558;&#25104;&#20026;LLM&#24320;&#21457;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#24182;&#24320;&#25918;&#25972;&#20010;&#24211;&#20197;&#27426;&#36814;&#31038;&#21306;&#36129;&#29486;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#27905;&#30340;&#12289;&#20004;&#20998;&#38047;&#30340;&#31995;&#32479;&#28436;&#31034;&#35270;&#39057;&#65292;&#23637;&#31034;&#20854;&#21151;&#33021;&#21644;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19340v1 Announce Type: cross  Abstract: To address the challenges associated with data processing at scale, we propose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipeline for large language models (LLMs) with a user-friendly design at its core. Easy addition of custom processors with block-based interface in Dataverse allows users to readily and efficiently use Dataverse to build their own ETL pipeline. We hope that Dataverse will serve as a vital tool for LLM development and open source the entire library to welcome community contribution. Additionally, we provide a concise, two-minute video demonstration of our system, illustrating its capabilities and implementation.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22312;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#22788;&#29702;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#30340;&#26041;&#27861;&#65292;&#23454;&#26045;&#20102;&#20351;&#29992;&#29109;&#20998;&#25968;&#21644;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#26469;&#25351;&#23548;&#27169;&#22411;&#30340;&#31574;&#30053;&#65292;&#24182;&#22312;&#23454;&#35777;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30456;&#23545;&#20110;&#25932;&#23545;&#29702;&#30001;&#30340;&#31283;&#20581;&#24615;&#33021;&#20248;&#21183;</title><link>https://arxiv.org/abs/2402.14337</link><description>&lt;p&gt;
AURA&#65306;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#30340;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
AURA: Natural Language Reasoning for Aleatoric Uncertainty in Rationales
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14337
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22312;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#20013;&#22788;&#29702;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#30340;&#26041;&#27861;&#65292;&#23454;&#26045;&#20102;&#20351;&#29992;&#29109;&#20998;&#25968;&#21644;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#26469;&#25351;&#23548;&#27169;&#22411;&#30340;&#31574;&#30053;&#65292;&#24182;&#22312;&#23454;&#35777;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30456;&#23545;&#20110;&#25932;&#23545;&#29702;&#30001;&#30340;&#31283;&#20581;&#24615;&#33021;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#31574;&#32972;&#21518;&#30340;&#29702;&#30001;&#19981;&#20165;&#35299;&#37322;&#20102;&#27169;&#22411;&#20915;&#31574;&#65292;&#32780;&#19988;&#25552;&#21319;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#33719;&#24471;&#26080;&#25032;&#21487;&#20987;&#30340;&#29702;&#30001;&#36890;&#24120;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#27492;&#22806;&#65292;&#20272;&#35745;&#29702;&#30001;&#36275;&#22815;&#24544;&#23454;&#20197;&#40723;&#21169;&#27169;&#22411;&#34920;&#29616;&#30340;&#31243;&#24230;&#24182;&#19981;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#25512;&#29702;&#20219;&#21153;&#36890;&#24120;&#36843;&#20351;&#27169;&#22411;&#22312;&#19981;&#29702;&#24819;&#30340;&#29702;&#30001;&#19979;&#36755;&#20986;&#27491;&#30830;&#31572;&#26696;&#65292;&#24182;&#19988;&#19982;&#27169;&#22411;&#23436;&#20840;&#26377;&#33021;&#21147;&#30340;&#24773;&#20917;&#30456;&#27604;&#26159;&#27425;&#20248;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22914;&#20309;&#24212;&#23545;&#24341;&#21457;&#27169;&#24335;&#21512;&#29702;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#23436;&#32654;&#29702;&#30001;&#12290;&#25105;&#20204;&#39318;&#20808;&#29992;&#32473;&#23450;&#29702;&#30001;&#30340;&#29109;&#20998;&#25968;&#26469;&#23450;&#20041;&#27169;&#31946;&#30340;&#29702;&#30001;&#65292;&#20351;&#29992;&#27169;&#22411;&#20808;&#39564;&#20449;&#24565;&#20316;&#20026;&#20449;&#24687;&#37327;&#12290;&#28982;&#21518;&#26681;&#25454;&#29702;&#30001;&#30340;&#27169;&#31946;&#24615;&#26469;&#24341;&#23548;&#27169;&#22411;&#36873;&#25321;&#20004;&#31181;&#19981;&#21516;&#30340;&#25512;&#29702;&#27169;&#22411;&#20013;&#30340;&#19968;&#31181;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#19978;&#35770;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#29702;&#30001;&#30340;&#25932;&#23545;&#36136;&#37327;&#20135;&#29983;&#20102;&#31283;&#20581;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14337v1 Announce Type: new  Abstract: Rationales behind answers not only explain model decisions but boost language models to reason well on complex reasoning tasks. However, obtaining impeccable rationales is often impossible. Besides, it is non-trivial to estimate the degree to which the rationales are faithful enough to encourage model performance. Thus, such reasoning tasks often compel models to output correct answers under undesirable rationales and are sub-optimal compared to what the models are fully capable of. In this work, we propose how to deal with imperfect rationales causing aleatoric uncertainty. We first define the ambiguous rationales with entropy scores of given rationales, using model prior beliefs as informativeness. We then guide models to select one of two different reasoning models according to the ambiguity of rationales. We empirically argue that our proposed method produces robust performance superiority against the adversarial quality of rationale
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#34920;&#26126;&#65292;&#20165;&#20165;&#36827;&#34892;&#21435;&#35782;&#21035;&#25805;&#20316;&#24182;&#19981;&#33021;&#26377;&#25928;&#20445;&#25252;&#38544;&#31169;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#20020;&#24202;&#31508;&#35760;&#30340;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#20102;&#20854;&#22312;&#20020;&#24202;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#36824;&#21457;&#29616;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#20250;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#25104;&#21151;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.00179</link><description>&lt;p&gt;
&#19981;&#20165;&#20165;&#21435;&#35782;&#21035;&#21487;&#33021;&#26159;&#19981;&#22815;&#30340;
&lt;/p&gt;
&lt;p&gt;
De-identification is not always enough
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00179
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#65292;&#20165;&#20165;&#36827;&#34892;&#21435;&#35782;&#21035;&#25805;&#20316;&#24182;&#19981;&#33021;&#26377;&#25928;&#20445;&#25252;&#38544;&#31169;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#20020;&#24202;&#31508;&#35760;&#30340;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#20102;&#20854;&#22312;&#20020;&#24202;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#36824;&#21457;&#29616;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#20250;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20849;&#20139;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#65292;&#24120;&#24120;&#23558;&#21435;&#35782;&#21035;&#35270;&#20026;&#36275;&#22815;&#20445;&#25252;&#38544;&#31169;&#30340;&#25514;&#26045;&#12290;&#21512;&#25104;&#25968;&#25454;&#20063;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#20445;&#25252;&#38544;&#31169;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#26368;&#36817;&#22312;&#29983;&#25104;&#25968;&#20540;&#21644;&#34920;&#26684;&#25968;&#25454;&#27169;&#22411;&#26041;&#38754;&#21462;&#24471;&#30340;&#25104;&#21151;&#20197;&#21450;&#22823;&#22411;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24341;&#21457;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#21512;&#25104;&#30340;&#20020;&#24202;&#31508;&#35760;&#26159;&#21542;&#21487;&#20197;&#20316;&#20026;&#30740;&#31350;&#30446;&#30340;&#30340;&#30495;&#23454;&#31508;&#35760;&#30340;&#21487;&#34892;&#26367;&#20195;&#21697;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65306;&#65288;i&#65289;&#23545;&#30495;&#23454;&#20020;&#24202;&#31508;&#35760;&#30340;&#21435;&#35782;&#21035;&#24182;&#19981;&#33021;&#20445;&#25252;&#35760;&#24405;&#20813;&#36973;&#20250;&#21592;&#25512;&#29702;&#25915;&#20987;&#65307;&#65288;ii&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#20020;&#24202;&#31508;&#35760;&#30340;&#26032;&#26041;&#27861;&#65307;&#65288;iii&#65289;&#22312;&#20020;&#24202;&#39046;&#22495;&#20219;&#21153;&#20013;&#35780;&#20272;&#20102;&#21512;&#25104;&#29983;&#25104;&#31508;&#35760;&#30340;&#24615;&#33021;&#65307;&#65288;iv&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#35757;&#32451;&#30446;&#26631;&#27169;&#22411;&#30340;&#20250;&#21592;&#25512;&#29702;&#25915;&#20987;&#26041;&#27861;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#24403;&#21512;&#25104;&#29983;&#25104;&#30340;&#31508;&#35760;&#19982;&#30495;&#23454;&#31508;&#35760;&#30456;&#20284;&#26102;&#65292;&#36825;&#31181;&#25915;&#20987;&#30340;&#25104;&#21151;&#29575;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
For sharing privacy-sensitive data, de-identification is commonly regarded as adequate for safeguarding privacy. Synthetic data is also being considered as a privacy-preserving alternative. Recent successes with numerical and tabular data generative models and the breakthroughs in large generative language models raise the question of whether synthetically generated clinical notes could be a viable alternative to real notes for research purposes. In this work, we demonstrated that (i) de-identification of real clinical notes does not protect records against a membership inference attack, (ii) proposed a novel approach to generate synthetic clinical notes using the current state-of-the-art large language models, (iii) evaluated the performance of the synthetically generated notes in a clinical domain task, and (iv) proposed a way to mount a membership inference attack where the target model is trained with synthetic data. We observed that when synthetically generated notes closely match
&lt;/p&gt;</description></item><item><title>EAGLE&#26159;&#19968;&#20010;&#26080;&#25439;&#21152;&#36895;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#27425;&#39030;&#23618;&#29305;&#24449;&#23618;&#38754;&#19978;&#33258;&#22238;&#24402;&#25512;&#29702;&#65292;&#24182;&#35299;&#20915;&#37319;&#26679;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#24555;3&#20493;&#30340;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.15077</link><description>&lt;p&gt;
EAGLE: &#25512;&#27979;&#37319;&#26679;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#29305;&#24449;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty. (arXiv:2401.15077v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15077
&lt;/p&gt;
&lt;p&gt;
EAGLE&#26159;&#19968;&#20010;&#26080;&#25439;&#21152;&#36895;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#27425;&#39030;&#23618;&#29305;&#24449;&#23618;&#38754;&#19978;&#33258;&#22238;&#24402;&#25512;&#29702;&#65292;&#24182;&#35299;&#20915;&#37319;&#26679;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#24555;3&#20493;&#30340;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#22238;&#24402;&#35299;&#30721;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#21464;&#24471;&#32791;&#26102;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#26694;&#26550;&#65292;EAGLE&#65288;&#29992;&#20110;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#25928;&#29575;&#30340;&#22806;&#25512;&#31639;&#27861;&#65289;&#65292;&#23454;&#29616;&#20102;&#26080;&#25439;&#21152;&#36895;&#12290;&#19982;&#20256;&#32479;&#30340;&#25512;&#27979;&#37319;&#26679;&#26041;&#27861;&#19981;&#21516;&#65292;EAGLE&#22312;&#26356;&#35268;&#24459;&#30340;&#65288;&#27425;&#39030;&#23618;&#65289;&#29305;&#24449;&#23618;&#38754;&#19978;&#33258;&#22238;&#24402;&#36827;&#34892;&#32534;&#20889;&#65292;&#24182;&#36890;&#36807;&#25972;&#21512;&#25552;&#21069;&#19968;&#20010;&#26102;&#38388;&#27493;&#30340;&#26631;&#35760;&#26469;&#35299;&#20915;&#19979;&#19968;&#20010;&#29305;&#24449;&#39044;&#27979;&#38382;&#39064;&#20013;&#30340;&#37319;&#26679;&#19981;&#30830;&#23450;&#24615;&#12290;EAGLE&#25152;&#25552;&#20379;&#30340;&#21152;&#36895;&#26159;&#26080;&#25439;&#30340;&#65306;&#23427;&#19981;&#38656;&#35201;&#24494;&#35843;&#30446;&#26631;LLM&#65292;&#24182;&#19988;&#29983;&#25104;&#30340;&#25991;&#26412;&#19982;&#21407;&#22987;&#30340;&#33258;&#22238;&#24402;&#35299;&#30721;&#30340;&#20998;&#24067;&#30456;&#21516;&#12290;&#25130;&#33267;&#26412;&#25991;&#25552;&#20132;&#26102;&#65292;EAGLE&#26159;&#24050;&#30693;&#25512;&#27979;&#37319;&#26679;&#23478;&#26063;&#20013;&#36895;&#24230;&#26368;&#24555;&#30340;&#26694;&#26550;&#12290;&#22312;MT-bench&#19978;&#65292;EAGLE&#27604;&#21407;&#22987;&#35299;&#30721;&#24555;3&#20493;&#65292;&#27604;Lookahead&#24555;2&#20493;&#65292;&#27604;Medusa&#24555;1.6&#20493;&#12290;&#20351;&#29992;gpt-fast&#65292;EAGLE&#24179;&#22343;&#27599;&#31186;&#36798;&#21040;160&#20010;&#26631;&#35760;&#19982;LLaMA2-Chat&#25645;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Auto-regressive decoding makes the inference of Large Language Models (LLMs) time-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm for Greater Language-model Efficiency), for lossless acceleration. Unlike traditional speculative sampling methods, EAGLE operates the drafting process auto-regressively at the more regular (second-top-layer) feature level and addresses the sampling uncertainty issues in the next-feature prediction problems by integrating tokens from one time step ahead. The acceleration provided by EAGLE is lossless: it involves no fine-tuning of the target LLM, and the generated text maintains the same distribution as that of vanilla auto-regressive decoding. As of the submission of this paper, EAGLE is the fastest known framework within the speculative sampling family. On MT-bench, EAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x faster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with LLaMA2-Chat 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#25351;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22806;&#37096;&#33258;&#28982;&#38382;&#39064;&#22312;&#30693;&#35782;&#24211;&#19978;&#36827;&#34892;&#22810;&#26679;&#21270;&#38382;&#39064;&#29983;&#25104;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21452;&#27169;&#22411;&#26694;&#26550;&#26469;&#35299;&#20915;&#22914;&#20309;&#22686;&#24378;&#22810;&#26679;&#21270;&#38382;&#39064;&#29983;&#25104;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.14362</link><description>&lt;p&gt;
&#36890;&#36807;&#22806;&#37096;&#33258;&#28982;&#38382;&#39064;&#22312;&#30693;&#35782;&#24211;&#19978;&#36827;&#34892;&#22810;&#26679;&#21270;&#38382;&#39064;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Diversifying Question Generation over Knowledge Base via External Natural Questions. (arXiv:2309.14362v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14362
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#25351;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22806;&#37096;&#33258;&#28982;&#38382;&#39064;&#22312;&#30693;&#35782;&#24211;&#19978;&#36827;&#34892;&#22810;&#26679;&#21270;&#38382;&#39064;&#29983;&#25104;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21452;&#27169;&#22411;&#26694;&#26550;&#26469;&#35299;&#20915;&#22914;&#20309;&#22686;&#24378;&#22810;&#26679;&#21270;&#38382;&#39064;&#29983;&#25104;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30693;&#35782;&#24211;&#38382;&#39064;&#29983;&#25104;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#25552;&#39640;&#21333;&#20010;&#29983;&#25104;&#38382;&#39064;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#20154;&#31867;&#20986;&#33394;&#30340;&#25913;&#20889;&#33021;&#21147;&#34920;&#26126;&#30456;&#21516;&#30340;&#35821;&#20041;&#21487;&#20197;&#36890;&#36807;&#19981;&#21516;&#30340;&#34920;&#36798;&#26469;&#20256;&#36798;&#12290;&#20197;&#19978;&#35266;&#28857;&#20351;&#24471;&#22810;&#26679;&#21270;&#38382;&#39064;&#29983;&#25104;&#25104;&#20026;&#19968;&#20010;&#26377;&#36259;&#30340;&#20219;&#21153;&#65292;&#20854;&#20013;&#31532;&#19968;&#20010;&#25361;&#25112;&#26159;&#22810;&#26679;&#24615;&#35780;&#20272;&#25351;&#26631;&#12290;&#24403;&#21069;&#30340;&#25351;&#26631;&#19981;&#36275;&#20197;&#35780;&#20272;&#22810;&#26679;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#20165;&#35745;&#31639;&#29983;&#25104;&#38382;&#39064;&#20013;&#21807;&#19968;n-gram&#30340;&#27604;&#20363;&#65292;&#26356;&#20542;&#21521;&#20110;&#34913;&#37327;&#37325;&#22797;&#32780;&#38750;&#30495;&#27491;&#30340;&#22810;&#26679;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#25351;&#26631;&#65292;&#23427;&#34913;&#37327;&#27599;&#20010;&#23454;&#20363;&#30340;&#21069;k&#20010;&#29983;&#25104;&#38382;&#39064;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#65292;&#21516;&#26102;&#30830;&#20445;&#23427;&#20204;&#19982;&#22522;&#20934;&#38382;&#39064;&#30456;&#20851;&#12290;&#26174;&#28982;&#65292;&#31532;&#20108;&#20010;&#25361;&#25112;&#26159;&#22914;&#20309;&#22686;&#24378;&#22810;&#26679;&#21270;&#38382;&#39064;&#29983;&#25104;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#30001;&#20004;&#20010;&#36873;&#25321;&#27169;&#22411;&#20132;&#32455;&#32780;&#25104;&#30340;&#21452;&#27169;&#22411;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previous methods on knowledge base question generation (KBQG) primarily focus on enhancing the quality of a single generated question. Recognizing the remarkable paraphrasing ability of humans, we contend that diverse texts should convey the same semantics through varied expressions. The above insights make diversifying question generation an intriguing task, where the first challenge is evaluation metrics for diversity. Current metrics inadequately assess the above diversity since they calculate the ratio of unique n-grams in the generated question itself, which leans more towards measuring duplication rather than true diversity. Accordingly, we devise a new diversity evaluation metric, which measures the diversity among top-k generated questions for each instance while ensuring their relevance to the ground truth. Clearly, the second challenge is how to enhance diversifying question generation. To address this challenge, we introduce a dual model framework interwoven by two selection
&lt;/p&gt;</description></item></channel></rss>