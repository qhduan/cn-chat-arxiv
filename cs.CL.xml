<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;</title><link>https://arxiv.org/abs/2403.15740</link><description>&lt;p&gt;
Ghost Sentence&#65306;&#19968;&#31181;&#20379;&#26222;&#36890;&#29992;&#25143;&#20351;&#29992;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#36827;&#34892;&#29256;&#26435;&#20445;&#25252;
&lt;/p&gt;
&lt;p&gt;
Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15740
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Web&#29992;&#25143;&#25968;&#25454;&#22312;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21450;&#20854;&#24494;&#35843;&#21464;&#31181;&#30340;&#29983;&#24577;&#31995;&#32479;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#24314;&#35758;&#29992;&#25143;&#22312;&#20854;&#25991;&#26723;&#20013;&#21453;&#22797;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#65292;&#20351;LLMs&#33021;&#22815;&#35760;&#24518;&#36825;&#20123;&#23494;&#30721;&#12290;&#36825;&#20123;&#29992;&#25143;&#25991;&#26723;&#20013;&#38544;&#34255;&#30340;&#23494;&#30721;&#65292;&#34987;&#31216;&#20026;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#19968;&#26086;&#23427;&#20204;&#20986;&#29616;&#22312;LLMs&#29983;&#25104;&#30340;&#20869;&#23481;&#20013;&#65292;&#29992;&#25143;&#23601;&#21487;&#20197;&#30830;&#20449;&#20182;&#20204;&#30340;&#25968;&#25454;&#34987;&#29992;&#20110;&#35757;&#32451;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#31181;&#29256;&#26435;&#24037;&#20855;&#30340;&#26377;&#25928;&#24615;&#21644;&#29992;&#27861;&#65292;&#25105;&#20204;&#21033;&#29992;&#24189;&#28789;&#21477;&#23376;&#23450;&#20041;&#20102;&#8220;&#29992;&#25143;&#35757;&#32451;&#25968;&#25454;&#35782;&#21035;&#8221;&#20219;&#21153;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#26469;&#33258;&#19981;&#21516;&#26469;&#28304;&#12289;&#19981;&#21516;&#35268;&#27169;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#19981;&#21516;&#35268;&#27169;&#30340;LLMs&#36827;&#34892;&#27979;&#35797;&#12290;&#20026;&#20102;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26368;&#21518;$k$&#20010;&#21333;&#35789;&#39564;&#35777;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15740v1 Announce Type: new  Abstract: Web user data plays a central role in the ecosystem of pre-trained large language models (LLMs) and their fine-tuned variants. Billions of data are crawled from the web and fed to LLMs. How can \textit{\textbf{everyday web users}} confirm if LLMs misuse their data without permission? In this work, we suggest that users repeatedly insert personal passphrases into their documents, enabling LLMs to memorize them. These concealed passphrases in user documents, referred to as \textit{ghost sentences}, once they are identified in the generated content of LLMs, users can be sure that their data is used for training. To explore the effectiveness and usage of this copyrighting tool, we define the \textit{user training data identification} task with ghost sentences. Multiple datasets from various sources at different scales are created and tested with LLMs of different sizes. For evaluation, we introduce a last $k$ words verification manner along 
&lt;/p&gt;</description></item><item><title>RAGGED&#26694;&#26550;&#20998;&#26512;&#21644;&#20248;&#21270;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#36866;&#21512;&#19981;&#21516;RAG&#35774;&#32622;&#30340;&#20107;&#23454;&#65292;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#38543;&#25991;&#26723;&#25968;&#37327;&#22686;&#21152;&#32780;&#25913;&#21892;&#65292;&#32780;&#20165;&#35299;&#30721;&#22120;&#27169;&#22411;&#21482;&#33021;&#26377;&#25928;&#21033;&#29992;&#23569;&#37327;&#25991;&#26723;&#12290;</title><link>https://arxiv.org/abs/2403.09040</link><description>&lt;p&gt;
RAGGED:&#26397;&#30528;&#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#30340;&#30693;&#24773;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09040
&lt;/p&gt;
&lt;p&gt;
RAGGED&#26694;&#26550;&#20998;&#26512;&#21644;&#20248;&#21270;&#20102;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#31995;&#32479;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#36866;&#21512;&#19981;&#21516;RAG&#35774;&#32622;&#30340;&#20107;&#23454;&#65292;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#38543;&#25991;&#26723;&#25968;&#37327;&#22686;&#21152;&#32780;&#25913;&#21892;&#65292;&#32780;&#20165;&#35299;&#30721;&#22120;&#27169;&#22411;&#21482;&#33021;&#26377;&#25928;&#21033;&#29992;&#23569;&#37327;&#25991;&#26723;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09040v1 &#22768;&#26126;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#36890;&#36807;&#20026;&#25991;&#26723;&#22411;&#38382;&#31572;&#31561;&#20219;&#21153;&#25552;&#20379;&#38468;&#21152;&#19978;&#19979;&#25991;&#65292;&#26497;&#22823;&#22320;&#25552;&#21319;&#20102;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#20855;&#26377;&#28508;&#21147;&#65292;&#20294;RAG&#30340;&#25928;&#21147;&#39640;&#24230;&#20381;&#36182;&#20110;&#20854;&#37197;&#32622;&#65292;&#20174;&#32780;&#24341;&#21457;&#19968;&#20010;&#38382;&#39064;&#65306;&#20160;&#20040;&#26159;&#26368;&#20339;RAG&#37197;&#32622;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;RAGGED&#26694;&#26550;&#26469;&#20998;&#26512;&#21644;&#20248;&#21270;RAG&#31995;&#32479;&#12290;&#22312;&#19968;&#32452;&#20195;&#34920;&#24615;&#30340;&#25991;&#26723;&#22411;&#38382;&#31572;&#20219;&#21153;&#19978;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#32463;&#20856;&#30340;&#31232;&#30095;&#21644;&#23494;&#38598;&#26816;&#32034;&#22120;&#65292;&#20197;&#21450;&#22235;&#31181;&#22312;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#21644;&#20165;&#35299;&#30721;&#22120;&#32467;&#26500;&#20013;&#34920;&#29616;&#20248;&#24322;&#30340;LMs&#12290;&#36890;&#36807;RAGGED&#65292;&#25105;&#20204;&#21457;&#29616;&#19981;&#21516;&#27169;&#22411;&#36866;&#21512;&#23436;&#20840;&#19981;&#21516;&#30340;RAG&#35774;&#32622;&#12290;&#34429;&#28982;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#38543;&#30528;&#26356;&#22810;&#25991;&#26723;&#30340;&#22686;&#21152;&#32780;&#21333;&#35843;&#25552;&#21319;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#20165;&#35299;&#30721;&#22120;&#27169;&#22411;&#21482;&#33021;&#26377;&#25928;&#22320;&#20351;&#29992;&lt;5&#20010;&#25991;&#26723;&#65292;&#23613;&#31649;&#36890;&#24120;&#20855;&#26377;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#12290;RAGGED&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;LMs&#30340;&#19978;&#19979;&#25991;&#21033;&#29992;&#20064;&#24815;&#65292;&#25105;&#20204;&#21457;&#29616;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09040v1 Announce Type: new  Abstract: Retrieval-augmented generation (RAG) greatly benefits language models (LMs) by providing additional context for tasks such as document-based question answering (DBQA). Despite its potential, the power of RAG is highly dependent on its configuration, raising the question: What is the optimal RAG configuration? To answer this, we introduce the RAGGED framework to analyze and optimize RAG systems. On a set of representative DBQA tasks, we study two classic sparse and dense retrievers, and four top-performing LMs in encoder-decoder and decoder-only architectures. Through RAGGED, we uncover that different models suit substantially varied RAG setups. While encoder-decoder models monotonically improve with more documents, we find decoder-only models can only effectively use &lt; 5 documents, despite often having a longer context window. RAGGED offers further insights into LMs' context utilization habits, where we find that encoder-decoder models r
&lt;/p&gt;</description></item></channel></rss>