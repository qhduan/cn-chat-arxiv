<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#20559;&#35265;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#30740;&#31350;&#20102;"&#25216;&#24039;&#27979;&#35797;"&#19982;&#26356;&#29616;&#23454;&#19990;&#30028;&#20013;&#34920;&#29616;&#30340;RUTEd&#35780;&#20272;&#20043;&#38388;&#30340;&#20851;&#32852;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#24615;&#21035;-&#32844;&#19994;&#20559;&#35265;&#65292;&#24182;&#36827;&#34892;&#20102;&#22810;&#39033;&#35780;&#20272;&#27604;&#36739;&#12290;</title><link>https://arxiv.org/abs/2402.12649</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#65306;&#36229;&#36234;&#25216;&#24039;&#27979;&#35797;&#65292;&#36208;&#21521;RUTEd&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12649
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#20559;&#35265;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#30740;&#31350;&#20102;"&#25216;&#24039;&#27979;&#35797;"&#19982;&#26356;&#29616;&#23454;&#19990;&#30028;&#20013;&#34920;&#29616;&#30340;RUTEd&#35780;&#20272;&#20043;&#38388;&#30340;&#20851;&#32852;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#24615;&#21035;-&#32844;&#19994;&#20559;&#35265;&#65292;&#24182;&#36827;&#34892;&#20102;&#22810;&#39033;&#35780;&#20272;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bias benchmarks are a popular method for studying the negative impacts of bias in LLMs, yet there has been little empirical investigation of whether these benchmarks are actually indicative of how real world harm may manifest in the real world. In this work, we study the correspondence between such decontextualized "trick tests" and evaluations that are more grounded in Realistic Use and Tangible {Effects (i.e. RUTEd evaluations). We explore this correlation in the context of gender-occupation bias--a popular genre of bias evaluation. We compare three de-contextualized evaluations adapted from the current literature to three analogous RUTEd evaluations applied to long-form content generation. We conduct each evaluation for seven instruction-tuned LLMs. For the RUTEd evaluations, we conduct repeated trials of three text generation tasks: children's bedtime stories, user personas, and English language learning exercises. We found no corres
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12649v1 Announce Type: new  Abstract: Bias benchmarks are a popular method for studying the negative impacts of bias in LLMs, yet there has been little empirical investigation of whether these benchmarks are actually indicative of how real world harm may manifest in the real world. In this work, we study the correspondence between such decontextualized "trick tests" and evaluations that are more grounded in Realistic Use and Tangible {Effects (i.e. RUTEd evaluations). We explore this correlation in the context of gender-occupation bias--a popular genre of bias evaluation. We compare three de-contextualized evaluations adapted from the current literature to three analogous RUTEd evaluations applied to long-form content generation. We conduct each evaluation for seven instruction-tuned LLMs. For the RUTEd evaluations, we conduct repeated trials of three text generation tasks: children's bedtime stories, user personas, and English language learning exercises. We found no corres
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#21521;&#37327;&#25509;&#22320;&#38382;&#39064;&#65292;&#36890;&#36807;&#21306;&#20998;&#20869;&#37096;&#34920;&#31034;&#25509;&#22320;&#30340;&#19981;&#21516;&#26041;&#24335;&#65292;&#24635;&#32467;&#20986;&#20116;&#20010;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2304.01481</link><description>&lt;p&gt;
&#21521;&#37327;&#25509;&#22320;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
The Vector Grounding Problem. (arXiv:2304.01481v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#21521;&#37327;&#25509;&#22320;&#38382;&#39064;&#65292;&#36890;&#36807;&#21306;&#20998;&#20869;&#37096;&#34920;&#31034;&#25509;&#22320;&#30340;&#19981;&#21516;&#26041;&#24335;&#65292;&#24635;&#32467;&#20986;&#20116;&#20010;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22788;&#29702;&#22797;&#26434;&#30340;&#35821;&#35328;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#24341;&#21457;&#20102;&#23545;&#23427;&#20204;&#33021;&#21147;&#26412;&#36136;&#30340;&#28608;&#28872;&#36777;&#35770;&#12290;&#19981;&#21516;&#20110;&#20154;&#31867;&#65292;&#36825;&#20123;&#27169;&#22411;&#21482;&#33021;&#20174;&#25991;&#26412;&#25968;&#25454;&#20013;&#23398;&#20064;&#35821;&#35328;&#65292;&#27809;&#26377;&#19982;&#30495;&#23454;&#19990;&#30028;&#30340;&#30452;&#25509;&#20132;&#20114;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#23427;&#20204;&#33021;&#22815;&#29983;&#25104;&#20851;&#20110;&#21508;&#31181;&#35805;&#39064;&#20284;&#20046;&#26377;&#24847;&#20041;&#30340;&#25991;&#26412;&#12290;&#36825;&#19968;&#21360;&#35937;&#28145;&#21051;&#30340;&#25104;&#23601;&#37325;&#26032;&#24341;&#36215;&#20102;&#23545;&#32463;&#20856;&#8220;&#31526;&#21495;&#25509;&#22320;&#38382;&#39064;&#8221;&#30340;&#20851;&#27880;&#65292;&#36825;&#20010;&#38382;&#39064;&#36136;&#30097;&#20102;&#32463;&#20856;&#31526;&#21495;AI&#31995;&#32479;&#30340;&#20869;&#37096;&#34920;&#31034;&#21644;&#36755;&#20986;&#33021;&#21542;&#20855;&#26377;&#20869;&#22312;&#24847;&#20041;&#12290;&#19982;&#36825;&#20123;&#31995;&#32479;&#19981;&#21516;&#65292;&#29616;&#20195;LLMs&#26159;&#35745;&#31639;&#21521;&#37327;&#32780;&#19981;&#26159;&#31526;&#21495;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#31995;&#32479;&#20063;&#26377;&#31867;&#20284;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#21521;&#37327;&#25509;&#22320;&#38382;&#39064;&#12290;&#26412;&#25991;&#26377;&#20004;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21306;&#20998;&#20102;&#29983;&#29289;&#25110;&#20154;&#24037;&#31995;&#32479;&#20013;&#20869;&#37096;&#34920;&#31034;&#21487;&#20197;&#25509;&#22320;&#30340;&#21508;&#31181;&#26041;&#24335;&#65292;&#30830;&#23450;&#20102;&#20116;&#20010;&#19981;&#21516;&#30340;&#27010;&#24565;
&lt;/p&gt;
&lt;p&gt;
The remarkable performance of large language models (LLMs) on complex linguistic tasks has sparked a lively debate on the nature of their capabilities. Unlike humans, these models learn language exclusively from textual data, without direct interaction with the real world. Nevertheless, they can generate seemingly meaningful text about a wide range of topics. This impressive accomplishment has rekindled interest in the classical 'Symbol Grounding Problem,' which questioned whether the internal representations and outputs of classical symbolic AI systems could possess intrinsic meaning. Unlike these systems, modern LLMs are artificial neural networks that compute over vectors rather than symbols. However, an analogous problem arises for such systems, which we dub the Vector Grounding Problem. This paper has two primary objectives. First, we differentiate various ways in which internal representations can be grounded in biological or artificial systems, identifying five distinct notions 
&lt;/p&gt;</description></item></channel></rss>