<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#36880;&#27493;&#21487;&#25512;&#24191;&#30340;&#20934;&#21017;&#65292;&#29992;&#20110;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#35782;&#21035;&#21644;&#20998;&#31867;&#19981;&#21516;&#24418;&#24335;&#30340;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#12290;&#36890;&#36807;&#23545;&#31181;&#26063;&#20027;&#20041;&#30340;&#27010;&#24565;&#21270;&#21644;&#19978;&#19979;&#25991;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;XLM-R&#21644;XLM-R-Racismo&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#31181;&#26063;&#20027;&#20041;&#20998;&#31867;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.09333</link><description>&lt;p&gt;
&#26426;&#22120;&#33021;&#22815;&#30475;&#21040;&#39068;&#33394;&#65306;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#20998;&#31867;&#19981;&#21516;&#24418;&#24335;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#30340;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Machines Do See Color: A Guideline to Classify Different Forms of Racist Discourse in Large Corpora. (arXiv:2401.09333v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09333
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#36880;&#27493;&#21487;&#25512;&#24191;&#30340;&#20934;&#21017;&#65292;&#29992;&#20110;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#35782;&#21035;&#21644;&#20998;&#31867;&#19981;&#21516;&#24418;&#24335;&#30340;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#12290;&#36890;&#36807;&#23545;&#31181;&#26063;&#20027;&#20041;&#30340;&#27010;&#24565;&#21270;&#21644;&#19978;&#19979;&#25991;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;XLM-R&#21644;XLM-R-Racismo&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#31181;&#26063;&#20027;&#20041;&#20998;&#31867;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#35782;&#21035;&#21644;&#20998;&#31867;&#25991;&#26412;&#20013;&#30340;&#31181;&#26063;&#20027;&#20041;&#35821;&#35328;&#30340;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#23567;&#35268;&#27169;&#30340;&#36136;&#24615;&#26041;&#27861;&#25110;&#22823;&#35268;&#27169;&#30340;&#26041;&#27861;&#65292;&#19987;&#27880;&#20110;&#26126;&#26174;&#30340;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#36880;&#27493;&#21487;&#25512;&#24191;&#30340;&#20934;&#21017;&#65292;&#29992;&#20110;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#35782;&#21035;&#21644;&#20998;&#31867;&#19981;&#21516;&#24418;&#24335;&#30340;&#31181;&#26063;&#20027;&#20041;&#35328;&#35770;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#31181;&#26063;&#20027;&#20041;&#21450;&#20854;&#19981;&#21516;&#34920;&#29616;&#24418;&#24335;&#36827;&#34892;&#27010;&#24565;&#21270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#31181;&#26063;&#20027;&#20041;&#34920;&#29616;&#24418;&#24335;&#32622;&#20110;&#24863;&#20852;&#36259;&#30340;&#26102;&#38388;&#21644;&#22320;&#28857;&#32972;&#26223;&#19979;&#65292;&#20197;&#20415;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#35782;&#21035;&#23427;&#20204;&#30340;&#35805;&#35821;&#24418;&#24335;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;XLM-RoBERTa&#65288;XLM-R&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#20808;&#36827;&#19978;&#19979;&#25991;&#29702;&#35299;&#33021;&#21147;&#30340;&#36328;&#35821;&#35328;&#30417;&#30563;&#25991;&#26412;&#20998;&#31867;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;XLM-R&#21644;XLM-R-Racismo&#65288;&#25105;&#20204;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#65289;&#22312;&#22823;&#35268;&#27169;&#35821;&#26009;&#24211;&#20013;&#23545;&#31181;&#26063;&#20027;&#20041;&#36827;&#34892;&#20998;&#31867;&#30340;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#28041;&#21450;2018&#24180;&#33267;2021&#24180;&#21380;&#29916;&#22810;&#23572;&#26412;&#22303;&#32676;&#20307;&#30340;&#25512;&#25991;&#35821;&#26009;&#24211;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current methods to identify and classify racist language in text rely on small-n qualitative approaches or large-n approaches focusing exclusively on overt forms of racist discourse. This article provides a step-by-step generalizable guideline to identify and classify different forms of racist discourse in large corpora. In our approach, we start by conceptualizing racism and its different manifestations. We then contextualize these racist manifestations to the time and place of interest, which allows researchers to identify their discursive form. Finally, we apply XLM-RoBERTa (XLM-R), a cross-lingual model for supervised text classification with a cutting-edge contextual understanding of text. We show that XLM-R and XLM-R-Racismo, our pretrained model, outperform other state-of-the-art approaches in classifying racism in large corpora. We illustrate our approach using a corpus of tweets relating to the Ecuadorian ind\'igena community between 2018 and 2021.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#35758;&#23558;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;&#37325;&#26500;&#20026;&#30001;&#20363;&#23376;&#24341;&#23548;&#30340;&#31890;&#24230;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#65292;&#20197;&#26368;&#23567;&#21270;&#26381;&#21153;&#20043;&#38388;&#30340;&#20219;&#21153;&#36716;&#31227;&#65292;&#33719;&#24471;&#25345;&#32493;&#30340;&#23398;&#20064;&#25928;&#30410;&#12290;&#36890;&#36807;&#32467;&#21512;&#31616;&#21333;&#30340;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#65292;&#21487;&#20197;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.13721</link><description>&lt;p&gt;
&#22522;&#20110;&#31034;&#20363;&#24341;&#23548;&#38382;&#31572;&#30340;&#25345;&#32493;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;
&lt;/p&gt;
&lt;p&gt;
Continual Dialogue State Tracking via Example-Guided Question Answering. (arXiv:2305.13721v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#35758;&#23558;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;&#37325;&#26500;&#20026;&#30001;&#20363;&#23376;&#24341;&#23548;&#30340;&#31890;&#24230;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#65292;&#20197;&#26368;&#23567;&#21270;&#26381;&#21153;&#20043;&#38388;&#30340;&#20219;&#21153;&#36716;&#31227;&#65292;&#33719;&#24471;&#25345;&#32493;&#30340;&#23398;&#20064;&#25928;&#30410;&#12290;&#36890;&#36807;&#32467;&#21512;&#31616;&#21333;&#30340;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#65292;&#21487;&#20197;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#31995;&#32479;&#38656;&#35201;&#19981;&#26029;&#26356;&#26032;&#20197;&#36866;&#24212;&#26032;&#26381;&#21153;&#65292;&#20294;&#26159;&#31616;&#21333;&#22320;&#20351;&#29992;&#26032;&#26381;&#21153;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#20250;&#38477;&#20302;&#20808;&#21069;&#23398;&#20064;&#30340;&#26381;&#21153;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#21457;&#29616;&#65292;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;(DST)&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#20219;&#21153;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#20854;&#37325;&#26500;&#20026;&#19968;&#32452;&#30001;&#20363;&#23376;&#24341;&#23548;&#30340;&#31890;&#24230;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#65292;&#20197;&#26368;&#23567;&#21270;&#26381;&#21153;&#20043;&#38388;&#30340;&#20219;&#21153;&#36716;&#31227;&#65292;&#20174;&#32780;&#33719;&#24471;&#25345;&#32493;&#30340;&#23398;&#20064;&#25928;&#30410;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20943;&#36731;&#29305;&#23450;&#26381;&#21153;&#30340;&#35760;&#24518;&#36127;&#25285;&#65292;&#24182;&#25945;&#20250;&#27169;&#22411;&#23558;&#25152;&#32473;&#38382;&#39064;&#21644;&#31034;&#20363;&#29992;&#20110;&#20174;&#23545;&#35805;&#20013;&#25552;&#21462;&#24517;&#35201;&#20449;&#24687;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#19968;&#20010;&#21482;&#26377;6000&#19975;&#20010;&#21442;&#25968;&#30340;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#20174;&#26816;&#32034;&#22120;&#33719;&#21462;&#30340;&#19978;&#19979;&#25991;&#31034;&#20363;&#33719;&#24471;&#24040;&#22823;&#30340;&#25552;&#21319;&#12290;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#31616;&#21333;&#30340;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dialogue systems are frequently updated to accommodate new services, but naively updating them by continually training with data for new services in diminishing performance on previously learnt services. Motivated by the insight that dialogue state tracking (DST), a crucial component of dialogue systems that estimates the user's goal as a conversation proceeds, is a simple natural language understanding task, we propose reformulating it as a bundle of granular example-guided question answering tasks to minimize the task shift between services and thus benefit continual learning. Our approach alleviates service-specific memorization and teaches a model to contextualize the given question and example to extract the necessary information from the conversation. We find that a model with just 60M parameters can achieve a significant boost by learning to learn from in-context examples retrieved by a retriever trained to identify turns with similar dialogue state changes. Combining our method
&lt;/p&gt;</description></item></channel></rss>