<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>LLM&#21463;&#21040;&#27745;&#26579;&#21487;&#33021;&#23548;&#33268;&#20854;&#24615;&#33021;&#19981;&#21487;&#38752;&#65292;&#25361;&#25112;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#12290;</title><link>https://arxiv.org/abs/2404.00699</link><description>&lt;p&gt;
LLM&#21463;&#21040;&#22810;&#23569;&#27745;&#26579;&#65311;&#19968;&#39033;&#20840;&#38754;&#35843;&#26597;&#21644;LLMSanitize&#24211;
&lt;/p&gt;
&lt;p&gt;
How Much are LLMs Contaminated? A Comprehensive Survey and the LLMSanitize Library
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00699
&lt;/p&gt;
&lt;p&gt;
LLM&#21463;&#21040;&#27745;&#26579;&#21487;&#33021;&#23548;&#33268;&#20854;&#24615;&#33021;&#19981;&#21487;&#38752;&#65292;&#25361;&#25112;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#36817;&#24180;&#26469;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23835;&#36215;&#65292;&#26032;&#30340;&#26426;&#20250;&#27491;&#22312;&#20986;&#29616;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#27745;&#26579;&#38382;&#39064;&#36805;&#36895;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#20225;&#19994;&#24212;&#29992;&#21644;&#20154;&#24037;&#26234;&#33021;&#31609;&#27454;&#24050;&#32463;&#36798;&#21040;&#19968;&#23450;&#35268;&#27169;&#65292;&#27969;&#34892;&#30340;&#38382;&#31572;&#22522;&#20934;&#25552;&#39640;&#20960;&#20010;&#30334;&#20998;&#28857;&#21487;&#33021;&#24847;&#21619;&#30528;&#25968;&#30334;&#19975;&#32654;&#20803;&#65292;&#23545;&#27169;&#22411;&#30340;&#23436;&#25972;&#24615;&#26045;&#21152;&#20102;&#24040;&#22823;&#21387;&#21147;&#12290;&#21516;&#26102;&#65292;&#36861;&#36394;LLMs&#35265;&#36807;&#30340;&#25968;&#25454;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#65307;&#23545;&#20110;&#20687;GPT-4&#21644;Claude-3&#36825;&#26679;&#30340;&#38381;&#28304;&#27169;&#22411;&#65292;&#20182;&#20204;&#19981;&#36879;&#38706;&#20219;&#20309;&#26377;&#20851;&#35757;&#32451;&#38598;&#30340;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#27745;&#26579;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;LLMs&#30340;&#24615;&#33021;&#21487;&#33021;&#19981;&#20877;&#21487;&#38752;&#65292;&#22240;&#20026;&#20854;&#39640;&#24615;&#33021;&#33267;&#23569;&#37096;&#20998;&#24402;&#22240;&#20110;&#20854;&#20808;&#21069;&#25509;&#35302;&#21040;&#30340;&#25968;&#25454;&#12290;&#36825;&#31181;&#23616;&#38480;&#24615;&#21361;&#21450;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#25972;&#20307;&#36827;&#23637;&#65292;&#28982;&#32780;&#65292;&#22914;&#20309;&#26377;&#25928;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#20173;&#28982;&#32570;&#20047;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00699v1 Announce Type: new  Abstract: With the rise of Large Language Models (LLMs) in recent years, new opportunities are emerging, but also new challenges, and contamination is quickly becoming critical. Business applications and fundraising in AI have reached a scale at which a few percentage points gained on popular question-answering benchmarks could translate into dozens of millions of dollars, placing high pressure on model integrity. At the same time, it is becoming harder and harder to keep track of the data that LLMs have seen; if not impossible with closed-source models like GPT-4 and Claude-3 not divulging any information on the training set. As a result, contamination becomes a critical issue: LLMs' performance may not be reliable anymore, as the high performance may be at least partly due to their previous exposure to the data. This limitation jeopardizes the entire progress in the field of NLP, yet, there remains a lack of methods on how to efficiently address
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#30721;&#20999;&#25442;&#30340;&#20132;&#26367;&#36328;&#35821;&#35328;PTM&#65292;&#39318;&#27425;&#23558;&#20195;&#30721;&#20999;&#25442;&#26041;&#27861;&#24212;&#29992;&#20110;&#36328;&#35821;&#35328;&#35821;&#20041;&#26816;&#32034;&#12290;</title><link>https://arxiv.org/abs/2403.01364</link><description>&lt;p&gt;
&#36890;&#36807;&#20195;&#30721;&#20999;&#25442;&#25913;&#36827;&#35821;&#20041;&#26816;&#32034;&#30340;&#36328;&#35821;&#35328;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Improving Cross-lingual Representation for Semantic Retrieval with Code-switching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01364
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#30721;&#20999;&#25442;&#30340;&#20132;&#26367;&#36328;&#35821;&#35328;PTM&#65292;&#39318;&#27425;&#23558;&#20195;&#30721;&#20999;&#25442;&#26041;&#27861;&#24212;&#29992;&#20110;&#36328;&#35821;&#35328;&#35821;&#20041;&#26816;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01364v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032; &#25552;&#35201;&#65306;&#35821;&#20041;&#26816;&#32034;&#65288;SR&#65289;&#24050;&#25104;&#20026;&#20219;&#21153;&#23548;&#21521;&#38382;&#31572;&#65288;QA&#65289;&#23545;&#35805;&#22330;&#26223;&#20013;FAQ&#31995;&#32479;&#20013;&#19981;&#21487;&#25110;&#32570;&#30340;&#37096;&#20998;&#12290;&#26368;&#36817;&#65292;&#23545;&#20110;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#25110;&#26576;&#20123;&#29305;&#23450;&#19994;&#21153;&#29615;&#22659;&#30340;&#36328;&#35821;&#35328;&#26234;&#33021;&#23458;&#25143;&#26381;&#21153;&#31995;&#32479;&#30340;&#38656;&#27714;&#26085;&#30410;&#22686;&#21152;&#12290;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#30740;&#31350;&#30452;&#25509;&#21033;&#29992;&#36328;&#35821;&#35328;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;PTMs&#65289;&#29992;&#20110;&#22810;&#35821;&#35328;&#30693;&#35782;&#26816;&#32034;&#65292;&#32780;&#20854;&#20182;&#19968;&#20123;&#30740;&#31350;&#20063;&#21033;&#29992;&#25345;&#32493;&#39044;&#35757;&#32451;&#22312;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;PTMs&#36827;&#34892;&#24494;&#35843;&#20043;&#21069;&#12290;&#28982;&#32780;&#65292;&#26080;&#35770;&#20351;&#29992;&#21738;&#31181;&#27169;&#24335;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#37117;&#24573;&#30053;&#20102;&#21521;PTMs&#21578;&#30693;&#19982;SR&#30456;&#20851;&#30340;&#19968;&#20123;&#29305;&#24449;&#65292;&#21363;&#22312;&#19981;&#25552;&#20379;&#19982;SR&#30456;&#20851;&#30340;&#20219;&#20309;&#20449;&#21495;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#20182;&#20204;&#30340;PTMs&#12290;&#20026;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#30721;&#20999;&#25442;&#30340;&#20132;&#26367;&#36328;&#35821;&#35328;PTM&#29992;&#20110;SR&#12290;&#25105;&#20204;&#26159;&#31532;&#19968;&#20010;&#20026;&#36328;&#35821;&#35328;SR&#20351;&#29992;&#20195;&#30721;&#20999;&#25442;&#26041;&#27861;&#30340;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#26032;&#39062;&#30340;&#20195;&#30721;&#20999;&#25442;&#25345;&#32493;&#39044;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01364v1 Announce Type: new  Abstract: Semantic Retrieval (SR) has become an indispensable part of the FAQ system in the task-oriented question-answering (QA) dialogue scenario. The demands for a cross-lingual smart-customer-service system for an e-commerce platform or some particular business conditions have been increasing recently. Most previous studies exploit cross-lingual pre-trained models (PTMs) for multi-lingual knowledge retrieval directly, while some others also leverage the continual pre-training before fine-tuning PTMs on the downstream tasks. However, no matter which schema is used, the previous work ignores to inform PTMs of some features of the downstream task, i.e. train their PTMs without providing any signals related to SR. To this end, in this work, we propose an Alternative Cross-lingual PTM for SR via code-switching. We are the first to utilize the code-switching approach for cross-lingual SR. Besides, we introduce the novel code-switched continual pre-t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;NLP&#27169;&#22411;&#22312;&#35782;&#21035;&#36140;&#20302;&#24615;&#35821;&#35328;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#23427;&#20204;&#33021;&#22815;&#20197;70%&#30340;&#20934;&#30830;&#29575;&#21306;&#20998;&#36140;&#20302;&#24615;&#35821;&#35328;&#21644;&#26356;&#24191;&#27867;&#30340;&#20167;&#24680;&#35328;&#35770;&#65292;&#20294;&#20063;&#23384;&#22312;&#30528;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2402.13818</link><description>&lt;p&gt;
&#36229;&#36234;&#20167;&#24680;&#35328;&#35770;: &#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22312;&#21457;&#29616;&#36140;&#20302;&#24615;&#35821;&#35328;&#20013;&#30340;&#25361;&#25112;&#19982;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Beyond Hate Speech: NLP's Challenges and Opportunities in Uncovering Dehumanizing Language
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;NLP&#27169;&#22411;&#22312;&#35782;&#21035;&#36140;&#20302;&#24615;&#35821;&#35328;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#23427;&#20204;&#33021;&#22815;&#20197;70%&#30340;&#20934;&#30830;&#29575;&#21306;&#20998;&#36140;&#20302;&#24615;&#35821;&#35328;&#21644;&#26356;&#24191;&#27867;&#30340;&#20167;&#24680;&#35328;&#35770;&#65292;&#20294;&#20063;&#23384;&#22312;&#30528;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#36523;&#20855;&#35937;&#21270;&#34987;&#23450;&#20041;&#20026;&#20167;&#24680;&#35328;&#35770;&#30340;&#19968;&#31181;&#24494;&#22937;&#20294;&#26377;&#23475;&#30340;&#34920;&#29616;&#24418;&#24335;&#65292;&#28041;&#21450;&#21542;&#35748;&#20010;&#20154;&#30340;&#20154;&#31867;&#29305;&#36136;&#65292;&#36890;&#24120;&#23548;&#33268;&#23545;&#36793;&#32536;&#32676;&#20307;&#30340;&#26292;&#21147;&#34892;&#20026;&#12290;&#23613;&#31649;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#20854;&#22312;&#26816;&#27979;&#36140;&#20302;&#24615;&#35328;&#35821;&#26041;&#38754;&#30340;&#24212;&#29992;&#26377;&#38480;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#36825;&#19968;&#39046;&#22495;&#20844;&#24320;&#21487;&#29992;&#30340;&#24102;&#26631;&#31614;&#25968;&#25454;&#31232;&#32570;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#26368;&#20808;&#36827;&#30340;NLP&#27169;&#22411;&#65288;&#21253;&#25324;GPT-4&#12289;GPT-3.5&#21644;LLAMA-2&#65289;&#22312;&#35782;&#21035;&#36140;&#20302;&#24615;&#35821;&#35328;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26174;&#31034;&#65292;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#34920;&#29616;&#20986;&#28508;&#21147;&#65292;&#36798;&#21040;&#20102;70%&#30340;&#20934;&#30830;&#29575;&#26469;&#21306;&#20998;&#36140;&#20302;&#24615;&#35328;&#35821;&#21644;&#26356;&#24191;&#27867;&#30340;&#20167;&#24680;&#35328;&#35770;&#65292;&#20294;&#23427;&#20204;&#20063;&#26174;&#31034;&#20986;&#20559;&#35265;&#12290;&#23427;&#20204;&#22312;&#23545;&#20854;&#20182;&#24418;&#24335;&#30340;&#20167;&#24680;&#35328;&#35770;&#36827;&#34892;&#20998;&#31867;&#26102;&#36807;&#20110;&#25935;&#24863;&#65292;&#23558;&#20854;&#35823;&#21028;&#20026;&#29305;&#23450;&#30446;&#26631;&#32676;&#20307;&#30340;&#20154;&#36523;&#20855;&#35937;&#21270;&#65292;&#21516;&#26102;&#26356;&#39057;&#32321;&#22320;&#26410;&#33021;&#35782;&#21035;&#26126;&#26174;&#30340;&#20154;&#36523;&#20855;&#35937;&#21270;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13818v1 Announce Type: new  Abstract: Dehumanization, characterized as a subtle yet harmful manifestation of hate speech, involves denying individuals of their human qualities and often results in violence against marginalized groups. Despite significant progress in Natural Language Processing across various domains, its application in detecting dehumanizing language is limited, largely due to the scarcity of publicly available annotated data for this domain. This paper evaluates the performance of cutting-edge NLP models, including GPT-4, GPT-3.5, and LLAMA-2, in identifying dehumanizing language. Our findings reveal that while these models demonstrate potential, achieving a 70\% accuracy rate in distinguishing dehumanizing language from broader hate speech, they also display biases. They are over-sensitive in classifying other forms of hate speech as dehumanization for a specific subset of target groups, while more frequently failing to identify clear cases of dehumanizati
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#32467;&#26500;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#24341;&#23548;&#30340;SQL&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;SQL&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#25191;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13284</link><description>&lt;p&gt;
&#32467;&#26500;&#24341;&#23548;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;SQL&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Structure Guided Large Language Model for SQL Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13284
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#32467;&#26500;&#20449;&#24687;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#24341;&#23548;&#30340;SQL&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;SQL&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#25191;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20934;&#30830;&#30340;&#32467;&#26500;&#21270;&#26597;&#35810;&#35821;&#35328;&#65288;SQL&#65289;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#23558;&#29992;&#25143;&#30340;&#35821;&#20041;&#26597;&#35810;&#19982;&#32467;&#26500;&#21270;&#25968;&#25454;&#24211;&#21305;&#37197;&#65292;&#28982;&#21518;&#29983;&#25104;&#32467;&#26500;&#21270;SQL&#26041;&#38754;&#12290;&#29616;&#26377;&#27169;&#22411;&#36890;&#24120;&#23558;&#26597;&#35810;&#21644;&#25968;&#25454;&#24211;&#27169;&#24335;&#36755;&#20837;&#21040;LLM&#20013;&#65292;&#24182;&#20381;&#36182;LLM&#25191;&#34892;&#35821;&#20041;-&#32467;&#26500;&#21305;&#37197;&#24182;&#29983;&#25104;&#32467;&#26500;&#21270;SQL&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35299;&#20915;&#26041;&#26696;&#24573;&#30053;&#20102;&#29992;&#25143;&#26597;&#35810;&#21644;&#25968;&#25454;&#24211;&#20013;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#32780;&#36825;&#20123;&#20449;&#24687;&#21487;&#20197;&#29992;&#26469;&#22686;&#24378;&#32467;&#26500;&#21270;SQL&#30340;&#29983;&#25104;&#12290;&#36825;&#19968;&#30095;&#24573;&#21487;&#33021;&#23548;&#33268;&#19981;&#20934;&#30830;&#25110;&#26080;&#27861;&#25191;&#34892;&#30340;SQL&#29983;&#25104;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#21040;SQL&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#22266;&#26377;&#30340;&#32467;&#26500;&#20449;&#24687;&#26469;&#25913;&#21892;LLM&#30340;SQL&#29983;&#25104;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#30340;&#32467;&#26500;&#24341;&#23548;SQL&#65288;SGU-SQL&#65289;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13284v1 Announce Type: cross  Abstract: Generating accurate Structured Querying Language (SQL) is a long-standing problem, especially in matching users' semantic queries with structured databases and then generating structured SQL. Existing models typically input queries and database schemas into the LLM and rely on the LLM to perform semantic-structure matching and generate structured SQL. However, such solutions overlook the structural information within user queries and databases, which can be utilized to enhance the generation of structured SQL. This oversight can lead to inaccurate or unexecutable SQL generation. To fully exploit the structure, we propose a structure-to-SQL framework, which leverages the inherent structure information to improve the SQL generation of LLMs. Specifically, we introduce our Structure Guided SQL~(SGU-SQL) generation model. SGU-SQL first links user queries and databases in a structure-enhanced manner. It then decomposes complicated linked str
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#32473;&#20986;&#21709;&#24212;&#26102;&#23384;&#22312;&#19968;&#20010;&#20215;&#20540;&#20559;&#22909;&#30340;&#26426;&#21046;&#65292;&#20542;&#21521;&#20110;&#20559;&#21521;&#29702;&#24819;&#29366;&#24577;&#65292;&#36825;&#31181;&#20559;&#24046;&#20250;&#23545;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.11005</link><description>&lt;p&gt;
&#25506;&#31350;&#20215;&#20540;&#20559;&#22909;&#65306;LLMs&#20559;&#21521;&#29702;&#24819;&#29366;&#24577;&#30340;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Exploring Value Biases: How LLMs Deviate Towards the Ideal
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11005
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#32473;&#20986;&#21709;&#24212;&#26102;&#23384;&#22312;&#19968;&#20010;&#20215;&#20540;&#20559;&#22909;&#30340;&#26426;&#21046;&#65292;&#20542;&#21521;&#20110;&#20559;&#21521;&#29702;&#24819;&#29366;&#24577;&#65292;&#36825;&#31181;&#20559;&#24046;&#20250;&#23545;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#34987;&#37096;&#32626;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#21709;&#24212;&#23545;&#31038;&#20250;&#20135;&#29983;&#30528;&#36234;&#26469;&#36234;&#22823;&#30340;&#24433;&#21709;&#12290;&#29702;&#35299;LLMs&#22312;&#32473;&#20986;&#21709;&#24212;&#26102;&#30340;&#38750;&#25925;&#24847;&#26426;&#21046;&#23545;&#20110;&#35299;&#37322;&#23427;&#20204;&#30340;&#24615;&#33021;&#24182;&#36776;&#21035;&#23427;&#20204;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;&#20559;&#24046;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#31867;&#20284;&#20110;&#20154;&#31867;&#30740;&#31350;&#20013;&#65292;&#36825;&#31181;&#26080;&#24847;&#35782;&#30340;&#21709;&#24212;&#34987;&#31216;&#20026;&#25277;&#26679;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#30340;&#36825;&#31181;&#25277;&#26679;&#29616;&#35937;&#65292;&#21457;&#29616;LLMs&#30340;&#25277;&#26679;&#20542;&#21521;&#20110;&#20559;&#29233;&#39640;&#20215;&#20540;&#36873;&#39033;&#12290;&#20215;&#20540;&#20559;&#22909;&#23545;&#24212;&#20110;&#20174;&#26368;&#21487;&#33021;&#30340;&#21709;&#24212;&#21521;LLM&#20013;&#20195;&#34920;&#30340;&#29702;&#24819;&#20215;&#20540;&#30340;&#36716;&#21464;&#12290;&#23454;&#38469;&#19978;&#65292;&#21363;&#20415;&#26159;&#36890;&#36807;&#19978;&#19979;&#25991;&#25552;&#31034;&#23398;&#20064;&#21040;&#30340;&#26032;&#23454;&#20307;&#65292;&#36825;&#31181;&#25928;&#26524;&#20063;&#33021;&#22815;&#20877;&#29616;&#12290;&#25105;&#20204;&#34920;&#26126;&#36825;&#31181;&#20559;&#24046;&#34920;&#29616;&#22312;&#24847;&#24819;&#19981;&#21040;&#30340;&#22320;&#26041;&#65292;&#24182;&#23545;&#36873;&#25321;&#20856;&#22411;&#23454;&#20363;&#31561;&#30456;&#20851;&#24212;&#29992;&#22330;&#26223;&#20135;&#29983;&#24433;&#21709;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#20215;&#20540;&#20559;&#22909;&#22312;&#19981;&#21516;&#20998;&#31867;&#30340;LLMs&#20013;&#37117;&#24456;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11005v1 Announce Type: cross  Abstract: Large-Language-Models (LLMs) are deployed in a wide range of applications, and their response has an increasing social impact. Understanding the non-deliberate(ive) mechanism of LLMs in giving responses is essential in explaining their performance and discerning their biases in real-world applications. This is analogous to human studies, where such inadvertent responses are referred to as sampling. We study this sampling of LLMs in light of value bias and show that the sampling of LLMs tends to favour high-value options. Value bias corresponds to this shift of response from the most likely towards an ideal value represented in the LLM. In fact, this effect can be reproduced even with new entities learnt via in-context prompting. We show that this bias manifests in unexpected places and has implications on relevant application scenarios, like choosing exemplars. The results show that value bias is strong in LLMs across different categor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#22320;&#29702;&#26631;&#35760;&#30340;&#25512;&#29305;&#25968;&#25454;&#21644;&#35745;&#31639;&#26041;&#27861;&#65292;&#22312;&#33521;&#26684;&#20848;&#21644;&#23041;&#23572;&#22763;&#30340;&#19971;&#21315;&#20010;&#34892;&#25919;&#21306;&#22495;&#19978;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#26144;&#23556;&#65292;&#21457;&#29616;&#31038;&#20250;&#32463;&#27982;&#20132;&#21449;&#24433;&#21709;&#20102;&#35821;&#35328;&#20351;&#29992;&#65292;&#28151;&#21512;&#19981;&#21516;&#31038;&#20250;&#32463;&#27982;&#38454;&#23618;&#30340;&#20154;&#32676;&#39057;&#29575;&#20559;&#31163;&#26631;&#20934;&#35821;&#27861;&#30340;&#31243;&#24230;&#36234;&#39640;&#65292;&#20854;&#25910;&#20837;&#20851;&#32852;&#36234;&#24369;&#12290;</title><link>http://arxiv.org/abs/2307.10016</link><description>&lt;p&gt;
&#26041;&#35328;&#30340;&#30896;&#25758;&#65306;&#31038;&#20250;&#32463;&#27982;&#20132;&#21449;&#23545;&#35821;&#35328;&#20351;&#29992;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
When Dialects Collide: How Socioeconomic Mixing Affects Language Use. (arXiv:2307.10016v1 [physics.soc-ph] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10016
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#22320;&#29702;&#26631;&#35760;&#30340;&#25512;&#29305;&#25968;&#25454;&#21644;&#35745;&#31639;&#26041;&#27861;&#65292;&#22312;&#33521;&#26684;&#20848;&#21644;&#23041;&#23572;&#22763;&#30340;&#19971;&#21315;&#20010;&#34892;&#25919;&#21306;&#22495;&#19978;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#26144;&#23556;&#65292;&#21457;&#29616;&#31038;&#20250;&#32463;&#27982;&#20132;&#21449;&#24433;&#21709;&#20102;&#35821;&#35328;&#20351;&#29992;&#65292;&#28151;&#21512;&#19981;&#21516;&#31038;&#20250;&#32463;&#27982;&#38454;&#23618;&#30340;&#20154;&#32676;&#39057;&#29575;&#20559;&#31163;&#26631;&#20934;&#35821;&#27861;&#30340;&#31243;&#24230;&#36234;&#39640;&#65292;&#20854;&#25910;&#20837;&#20851;&#32852;&#36234;&#24369;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#20204;&#30340;&#31038;&#20250;&#32463;&#27982;&#32972;&#26223;&#19982;&#20182;&#20204;&#20351;&#29992;&#26631;&#20934;&#35821;&#35328;&#30340;&#26041;&#24335;&#24182;&#19981;&#29420;&#31435;&#65292;&#36825;&#22312;&#21508;&#31181;&#31038;&#20250;&#35821;&#35328;&#23398;&#30740;&#31350;&#20013;&#24050;&#32463;&#24471;&#21040;&#35777;&#26126;&#12290;&#28982;&#32780;&#65292;&#19981;&#21516;&#31038;&#20250;&#32463;&#27982;&#38454;&#23618;&#30340;&#20154;&#20204;&#20132;&#21449;&#28151;&#21512;&#21487;&#33021;&#23545;&#36825;&#20123;&#30456;&#20851;&#24615;&#36896;&#25104;&#20309;&#31181;&#24433;&#21709;&#65292;&#22312;&#23450;&#37327;&#35282;&#24230;&#19978;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#24102;&#22320;&#29702;&#26631;&#35760;&#30340;&#25512;&#29305;&#21644;&#21487;&#36716;&#31227;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#22312;&#33521;&#26684;&#20848;&#21644;&#23041;&#23572;&#22763;&#30340;&#19971;&#21315;&#20010;&#34892;&#25919;&#21306;&#22495;&#19978;&#23545;&#19982;&#26631;&#20934;&#33521;&#35821;&#20559;&#31163;&#30340;&#24773;&#20917;&#36827;&#34892;&#22823;&#35268;&#27169;&#26144;&#23556;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#25968;&#25454;&#19982;&#39640;&#20998;&#36776;&#29575;&#30340;&#25910;&#20837;&#22320;&#22270;&#32467;&#21512;&#36215;&#26469;&#65292;&#20026;&#23621;&#20303;&#22320;&#29992;&#25143;&#20998;&#37197;&#19968;&#20010;&#20195;&#29702;&#31038;&#20250;&#32463;&#27982;&#25351;&#26631;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#20843;&#20010;&#22823;&#37117;&#24066;&#21306;&#22495;&#65292;&#25105;&#20204;&#21457;&#29616;&#19968;&#31181;&#19968;&#33268;&#30340;&#27169;&#24335;&#65292;&#34920;&#26126;&#19981;&#21516;&#31038;&#20250;&#32463;&#27982;&#38454;&#23618;&#30340;&#20154;&#20204;&#28151;&#21512;&#24471;&#36234;&#22810;&#65292;&#20854;&#20559;&#31163;&#26631;&#20934;&#35821;&#27861;&#21644;&#25910;&#20837;&#30340;&#39057;&#29575;&#23601;&#36234;&#19981;&#30456;&#20114;&#20381;&#23384;&#12290;
&lt;/p&gt;
&lt;p&gt;
The socioeconomic background of people and how they use standard forms of language are not independent, as demonstrated in various sociolinguistic studies. However, the extent to which these correlations may be influenced by the mixing of people from different socioeconomic classes remains relatively unexplored from a quantitative perspective. In this work we leverage geotagged tweets and transferable computational methods to map deviations from standard English on a large scale, in seven thousand administrative areas of England and Wales. We combine these data with high-resolution income maps to assign a proxy socioeconomic indicator to home-located users. Strikingly, across eight metropolitan areas we find a consistent pattern suggesting that the more different socioeconomic classes mix, the less interdependent the frequency of their departures from standard grammar and their income become. Further, we propose an agent-based model of linguistic variety adoption that sheds light on th
&lt;/p&gt;</description></item></channel></rss>