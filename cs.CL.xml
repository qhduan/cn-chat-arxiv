<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LawInstruct&#30340;&#22823;&#22411;&#27861;&#24459;&#25351;&#23548;&#25968;&#25454;&#38598;&#65292;&#35777;&#26126;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451;&#21644;&#25351;&#23548;&#35843;&#25972;&#21487;&#20197;&#25913;&#21892;&#22312;LegalBench&#19978;&#30340;&#24615;&#33021;&#65292;&#20026;&#22312;&#27861;&#24459;&#39046;&#22495;&#24320;&#21457;&#20855;&#26377;&#26356;&#24378;&#20449;&#24687;&#22788;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#36164;&#28304;&#12290;</title><link>https://arxiv.org/abs/2404.02127</link><description>&lt;p&gt;
FLawN-T5: &#26377;&#25928;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#28151;&#21512;&#22312;&#27861;&#24459;&#25512;&#29702;&#20013;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LawInstruct&#30340;&#22823;&#22411;&#27861;&#24459;&#25351;&#23548;&#25968;&#25454;&#38598;&#65292;&#35777;&#26126;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451;&#21644;&#25351;&#23548;&#35843;&#25972;&#21487;&#20197;&#25913;&#21892;&#22312;LegalBench&#19978;&#30340;&#24615;&#33021;&#65292;&#20026;&#22312;&#27861;&#24459;&#39046;&#22495;&#24320;&#21457;&#20855;&#26377;&#26356;&#24378;&#20449;&#24687;&#22788;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02127v1  &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495;  &#25688;&#35201;: &#25351;&#23548;&#35843;&#25972;&#26159;&#20351;&#35821;&#35328;&#27169;&#22411;&#23545;&#30452;&#25509;&#29992;&#25143;&#20132;&#20114;&#26377;&#25928;&#30340;&#37325;&#35201;&#27493;&#39588;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#27861;&#24459;&#20219;&#21153;&#20173;&#28982;&#36229;&#20986;&#20102;&#22823;&#22810;&#25968;&#24320;&#25918;&#24335;LLMs&#30340;&#33539;&#22260;&#65292;&#32780;&#19988;&#30446;&#21069;&#35813;&#39046;&#22495;&#36824;&#27809;&#26377;&#20219;&#20309;&#22823;&#35268;&#27169;&#30340;&#25968;&#25454;&#38598;&#12290;&#36825;&#20005;&#37325;&#38480;&#21046;&#20102;&#35813;&#24212;&#29992;&#39046;&#22495;&#30340;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#31574;&#21010;&#20102;&#19968;&#20010;&#21517;&#20026;LawInstruct&#30340;&#22823;&#22411;&#27861;&#24459;&#25351;&#23548;&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20102;17&#20010;&#21496;&#27861;&#31649;&#36758;&#21306;&#12289;24&#31181;&#35821;&#35328;&#65292;&#24635;&#35745;1200&#19975;&#20010;&#31034;&#20363;&#12290;&#25105;&#20204;&#21576;&#29616;&#35777;&#25454;&#34920;&#26126;&#65292;&#39046;&#22495;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451;&#21644;&#25351;&#23548;&#35843;&#25972;&#33021;&#22815;&#25913;&#21892;&#22312;LegalBench&#19978;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#23558;Flan-T5 XL&#22312;&#22522;&#20934;&#32447;&#19978;&#25552;&#39640;8&#20010;&#28857;&#25110;16%&#12290;&#28982;&#32780;&#65292;&#35813;&#25928;&#24212;&#24182;&#19981;&#36866;&#29992;&#20110;&#25152;&#26377;&#20219;&#21153;&#12289;&#35757;&#32451;&#27169;&#24335;&#12289;&#27169;&#22411;&#22823;&#23567;&#21644;&#20854;&#20182;&#22240;&#32032;&#12290;LawInstruct&#26159;&#19968;&#20010;&#36164;&#28304;&#65292;&#21487;&#20197;&#21152;&#36895;&#22312;&#27861;&#24459;&#39046;&#22495;&#24320;&#21457;&#20855;&#26377;&#26356;&#24378;&#20449;&#24687;&#22788;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02127v1 Announce Type: cross  Abstract: Instruction tuning is an important step in making language models useful for direct user interaction. However, many legal tasks remain out of reach for most open LLMs and there do not yet exist any large scale instruction datasets for the domain. This critically limits research in this application area. In this work, we curate LawInstruct, a large legal instruction dataset, covering 17 jurisdictions, 24 languages and a total of 12M examples. We present evidence that domain-specific pretraining and instruction tuning improve performance on LegalBench, including improving Flan-T5 XL by 8 points or 16\% over the baseline. However, the effect does not generalize across all tasks, training regimes, model sizes, and other factors. LawInstruct is a resource for accelerating the development of models with stronger information processing and decision making capabilities in the legal domain.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;KG&#30693;&#35782;&#27880;&#20837;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#27604;&#36739;&#65292;&#25506;&#32034;&#20026;LLMs&#25552;&#20379;&#30693;&#35782;&#22270;&#35889;&#30693;&#35782;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#23427;&#20204;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.11541</link><description>&lt;p&gt;
&#36870;&#21521;&#35748;&#30693;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27604;&#25105;&#20204;&#24819;&#35937;&#30340;&#26356;&#25797;&#38271;&#29702;&#35299;&#30693;&#35782;&#22270;&#35889;
&lt;/p&gt;
&lt;p&gt;
Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;KG&#30693;&#35782;&#27880;&#20837;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#27604;&#36739;&#65292;&#25506;&#32034;&#20026;LLMs&#25552;&#20379;&#30693;&#35782;&#22270;&#35889;&#30693;&#35782;&#30340;&#26368;&#20339;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#23427;&#20204;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#36890;&#36807;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#65288;KGs&#65289;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#24182;&#20943;&#23569;&#23427;&#20204;&#30340;&#24187;&#35273;&#30340;&#26041;&#27861;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#30446;&#21069;&#23545;&#22914;&#20309;&#20351;LLMs&#33021;&#22815;&#21363;&#26102;&#25972;&#21512;KGs&#20013;&#30340;&#32467;&#26500;&#21270;&#30693;&#35782;&#30340;&#25506;&#32034;&#36824;&#19981;&#36275;&#12290;&#26412;&#25991;&#37319;&#29992;&#22797;&#26434;&#38382;&#39064;&#22238;&#31572;&#65288;CQA&#65289;&#20316;&#20026;&#19968;&#39033;&#20219;&#21153;&#65292;&#35780;&#20272;LLM&#29702;&#35299;KG&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#23545;KG&#30693;&#35782;&#27880;&#20837;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#65288;&#20174;&#19977;&#20803;&#32452;&#21040;&#33258;&#28982;&#35821;&#35328;&#25991;&#26412;&#65289;&#65292;&#26088;&#22312;&#25506;&#32034;&#20026;LLMs&#25552;&#20379;KG&#30693;&#35782;&#30340;&#26368;&#20339;&#25552;&#31034;&#26041;&#27861;&#65292;&#20174;&#32780;&#22686;&#24378;&#23427;&#20204;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11541v1 Announce Type: cross  Abstract: Although the method of enhancing large language models' (LLMs') reasoning ability and reducing their hallucinations through the use of knowledge graphs (KGs) has received widespread attention, the exploration of how to enable LLMs to integrate the structured knowledge in KGs on-the-fly remains inadequate. Researchers often co-train KG embeddings and LLM parameters to equip LLMs with the ability of comprehending KG knowledge. However, this resource-hungry training paradigm significantly increases the model learning cost and is also unsuitable for non-open-source, black-box LLMs. In this paper, we employ complex question answering (CQA) as a task to assess the LLM's ability of comprehending KG knowledge. We conducted a comprehensive comparison of KG knowledge injection methods (from triples to natural language text), aiming to explore the optimal prompting method for supplying KG knowledge to LLMs, thereby enhancing their comprehension o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#22522;&#20110;&#26080;&#30417;&#30563;&#26041;&#27861;&#30340;&#32763;&#35793;&#26041;&#21521;&#26816;&#27979;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20854;&#22312;&#39640;&#36127;&#36733;&#35821;&#35328;&#23545;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;&#35770;&#25991;&#26631;&#39064;&#20026;&#8220;Machine Translation Models are Zero-Shot Detectors of Translation Direction&#8221;&#12290;</title><link>http://arxiv.org/abs/2401.06769</link><description>&lt;p&gt;
&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#26159;&#38646;&#23556;&#20987;&#30340;&#32763;&#35793;&#26041;&#21521;&#26816;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Translation Models are Zero-Shot Detectors of Translation Direction. (arXiv:2401.06769v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#22522;&#20110;&#26080;&#30417;&#30563;&#26041;&#27861;&#30340;&#32763;&#35793;&#26041;&#21521;&#26816;&#27979;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20854;&#22312;&#39640;&#36127;&#36733;&#35821;&#35328;&#23545;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;&#35770;&#25991;&#26631;&#39064;&#20026;&#8220;Machine Translation Models are Zero-Shot Detectors of Translation Direction&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#24182;&#34892;&#25991;&#26412;&#30340;&#32763;&#35793;&#26041;&#21521;&#23545;&#20110;&#26426;&#22120;&#32763;&#35793;&#30340;&#35757;&#32451;&#21644;&#35780;&#20272;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#65292;&#20294;&#20063;&#20855;&#26377;&#27861;&#21307;&#24212;&#29992;&#65292;&#20363;&#22914;&#35299;&#20915;&#21117;&#31363;&#25110;&#20266;&#36896;&#25351;&#25511;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26681;&#25454;&#19968;&#20010;&#31616;&#21333;&#30340;&#20551;&#35774;&#65292;&#21363;$p(\text{translation}|\text{original})&gt;p(\text{original}|\text{translation})$&#65292;&#20197;&#20256;&#32479;&#19978;&#34987;&#31216;&#20026;&#32763;&#35793;&#35821;&#25110;&#26426;&#22120;&#32763;&#35793;&#35821;&#20013;&#30340;&#31616;&#21270;&#25928;&#24212;&#20026;&#21160;&#26426;&#65292;&#25506;&#32034;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#32763;&#35793;&#26041;&#21521;&#26816;&#27979;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;20&#20010;&#32763;&#35793;&#26041;&#21521;&#36827;&#34892;&#22823;&#35268;&#27169;&#22810;&#35821;&#31181;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#22312;&#36164;&#28304;&#20016;&#23500;&#30340;&#35821;&#35328;&#23545;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#23545;&#20110;NMT&#29983;&#25104;&#30340;&#32763;&#35793;&#65292;&#23454;&#29616;&#20102;&#25991;&#26723;&#32423;&#20934;&#30830;&#29575;&#20026;82-96&#65285;&#65292;&#23545;&#20110;&#20154;&#24037;&#32763;&#35793;&#65292;&#26681;&#25454;&#25152;&#20351;&#29992;&#30340;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;60-81&#65285;&#30340;&#20934;&#30830;&#29575;&#12290;&#20195;&#30721;&#21644;&#28436;&#31034;&#21487;&#22312;https://github.com/ZurichNLP/translation-direction-detection&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting the translation direction of parallel text has applications for machine translation training and evaluation, but also has forensic applications such as resolving plagiarism or forgery allegations. In this work, we explore an unsupervised approach to translation direction detection based on the simple hypothesis that $p(\text{translation}|\text{original})&gt;p(\text{original}|\text{translation})$, motivated by the well-known simplification effect in translationese or machine-translationese. In experiments with massively multilingual machine translation models across 20 translation directions, we confirm the effectiveness of the approach for high-resource language pairs, achieving document-level accuracies of 82-96% for NMT-produced translations, and 60-81% for human translations, depending on the model used. Code and demo are available at https://github.com/ZurichNLP/translation-direction-detection
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#38463;&#25289;&#20271;&#35789;&#20998;&#21106;&#26041;&#27861;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20998;&#26512;&#21382;&#21490;&#21644;&#23447;&#25945;&#25991;&#26412;&#65292;&#24110;&#21161;&#29702;&#35299;&#25991;&#26412;&#20013;&#30340;&#24847;&#20041;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#22312;&#35789;&#27719;&#37327;&#21644;&#31181;&#31867;&#19978;&#37117;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#25968;&#25454;&#38598;&#65292;&#24182;&#19988;&#22312;&#38463;&#25289;&#20271;&#21704;&#36842;&#26031;&#39046;&#22495;&#26159;&#39318;&#20010;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#22810;&#31181;&#26041;&#27861;&#23545;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#35780;&#20272;&#24182;&#25253;&#21578;&#20102;&#27880;&#37322;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.09630</link><description>&lt;p&gt;
Noor-Ghateh: &#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#21704;&#36842;&#26031;&#39046;&#22495;&#38463;&#25289;&#20271;&#35789;&#20998;&#21106;&#22120;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
Noor-Ghateh: A Benchmark Dataset for Evaluating Arabic Word Segmenters in Hadith Domain. (arXiv:2307.09630v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09630
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#38463;&#25289;&#20271;&#35789;&#20998;&#21106;&#26041;&#27861;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20998;&#26512;&#21382;&#21490;&#21644;&#23447;&#25945;&#25991;&#26412;&#65292;&#24110;&#21161;&#29702;&#35299;&#25991;&#26412;&#20013;&#30340;&#24847;&#20041;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#22312;&#35789;&#27719;&#37327;&#21644;&#31181;&#31867;&#19978;&#37117;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#25968;&#25454;&#38598;&#65292;&#24182;&#19988;&#22312;&#38463;&#25289;&#20271;&#21704;&#36842;&#26031;&#39046;&#22495;&#26159;&#39318;&#20010;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#22810;&#31181;&#26041;&#27861;&#23545;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#35780;&#20272;&#24182;&#25253;&#21578;&#20102;&#27880;&#37322;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38463;&#25289;&#20271;&#35821;&#20855;&#26377;&#35768;&#22810;&#22797;&#26434;&#32780;&#20016;&#23500;&#30340;&#24418;&#24577;&#23398;&#32454;&#24494;&#24046;&#21035;&#65292;&#36825;&#22312;&#20998;&#26512;&#20256;&#32479;&#30340;&#38463;&#25289;&#20271;&#25991;&#26412;&#65292;&#29305;&#21035;&#26159;&#22312;&#21382;&#21490;&#21644;&#23447;&#25945;&#35821;&#22659;&#20013;&#65292;&#23545;&#20110;&#29702;&#35299;&#25991;&#26412;&#30340;&#21547;&#20041;&#38750;&#24120;&#26377;&#29992;&#12290;&#35789;&#27719;&#20998;&#31163;&#24847;&#21619;&#30528;&#23558;&#35789;&#35821;&#20998;&#35299;&#20026;&#35832;&#22914;&#35789;&#26681;&#21644;&#35789;&#32512;&#31561;&#19981;&#21516;&#37096;&#20998;&#12290;&#22312;&#24418;&#24577;&#23398;&#25968;&#25454;&#38598;&#20013;&#65292;&#26631;&#31614;&#30340;&#22810;&#26679;&#24615;&#21644;&#25968;&#25454;&#26679;&#26412;&#30340;&#25968;&#37327;&#26377;&#21161;&#20110;&#35780;&#20272;&#24418;&#24577;&#23398;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;&#20998;&#31163;&#38463;&#25289;&#20271;&#35789;&#27719;&#30340;&#26041;&#27861;&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#26469;&#33258;&#12298;&#20234;&#26031;&#20848;&#25945;&#27861;&#12299;&#30340;&#32422;223,690&#20010;&#35789;&#27719;&#65292;&#24050;&#30001;&#19987;&#23478;&#36827;&#34892;&#26631;&#35760;&#12290;&#23601;&#35789;&#27719;&#37327;&#21644;&#31181;&#31867;&#32780;&#35328;&#65292;&#35813;&#25968;&#25454;&#38598;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#25968;&#25454;&#38598;&#65292;&#24182;&#19988;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#19981;&#23384;&#22312;&#38463;&#25289;&#20271;&#21704;&#36842;&#26031;&#39046;&#22495;&#30340;&#25991;&#26412;&#12290;&#20026;&#20102;&#35780;&#20272;&#35813;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23545;&#25968;&#25454;&#38598;&#24212;&#29992;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#22914;Farasa&#12289;Camel&#12289;Madamira&#21644;ALP&#65292;&#24182;&#36890;&#36807;&#22235;&#20010;&#21442;&#25968;&#25253;&#21578;&#20102;&#27880;&#37322;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
There are many complex and rich morphological subtleties in the Arabic language, which are very useful when analyzing traditional Arabic texts, especially in the historical and religious contexts, and help in understanding the meaning of the texts. Vocabulary separation means separating the word into different parts such as root and affix. In the morphological datasets, the variety of labels and the number of data samples helps to evaluate the morphological methods. In this paper, we present a benchmark data set for evaluating the methods of separating Arabic words which include about 223,690 words from the book of Sharia alIslam, which have been labeled by experts. In terms of the volume and variety of words, this dataset is superior to other existing data sets, and as far as we know, there are no Arabic Hadith Domain texts. To evaluate the dataset, we applied different methods such as Farasa, Camel, Madamira, and ALP to the dataset and we reported the annotation quality through four 
&lt;/p&gt;</description></item></channel></rss>