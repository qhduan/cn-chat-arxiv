<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#23558;&#32463;&#20856;&#35268;&#21010;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#36817;&#20284;&#20154;&#31867;&#30452;&#35273;&#65292;&#20197;&#23454;&#29616;&#22810;&#26234;&#33021;&#20307;&#20219;&#21153;&#35268;&#21010;&#12290;</title><link>https://arxiv.org/abs/2403.17246</link><description>&lt;p&gt;
TwoStep: &#20351;&#29992;&#32463;&#20856;&#35268;&#21010;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#22810;&#26234;&#33021;&#20307;&#20219;&#21153;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17246
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23558;&#32463;&#20856;&#35268;&#21010;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#36817;&#20284;&#20154;&#31867;&#30452;&#35273;&#65292;&#20197;&#23454;&#29616;&#22810;&#26234;&#33021;&#20307;&#20219;&#21153;&#35268;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31867;&#20284;&#35268;&#21010;&#39046;&#22495;&#23450;&#20041;&#35821;&#35328;&#65288;PDDL&#65289;&#20043;&#31867;&#30340;&#32463;&#20856;&#35268;&#21010;&#20844;&#24335;&#20801;&#35768;&#30830;&#23450;&#21487;&#23454;&#29616;&#30446;&#26631;&#29366;&#24577;&#30340;&#21160;&#20316;&#24207;&#21015;&#65292;&#21482;&#35201;&#23384;&#22312;&#20219;&#20309;&#21487;&#33021;&#30340;&#21021;&#22987;&#29366;&#24577;&#12290;&#28982;&#32780;&#65292;PDDL&#20013;&#23450;&#20041;&#30340;&#25512;&#29702;&#38382;&#39064;&#24182;&#26410;&#25429;&#33719;&#34892;&#21160;&#36827;&#34892;&#30340;&#26102;&#38388;&#26041;&#38754;&#65292;&#20363;&#22914;&#39046;&#22495;&#20013;&#30340;&#20004;&#20010;&#26234;&#33021;&#20307;&#22914;&#26524;&#24444;&#27492;&#30340;&#21518;&#20917;&#19981;&#24178;&#25200;&#21069;&#25552;&#26465;&#20214;&#65292;&#21017;&#21487;&#20197;&#21516;&#26102;&#25191;&#34892;&#19968;&#20010;&#21160;&#20316;&#12290;&#20154;&#31867;&#19987;&#23478;&#21487;&#20197;&#23558;&#30446;&#26631;&#20998;&#35299;&#20026;&#22823;&#37096;&#20998;&#29420;&#31435;&#30340;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#23558;&#27599;&#20010;&#26234;&#33021;&#20307;&#20998;&#37197;&#32473;&#20854;&#20013;&#19968;&#20010;&#23376;&#30446;&#26631;&#65292;&#20197;&#21033;&#29992;&#21516;&#26102;&#36827;&#34892;&#21160;&#20316;&#26469;&#21152;&#24555;&#35745;&#21010;&#27493;&#39588;&#30340;&#25191;&#34892;&#65292;&#27599;&#20010;&#37096;&#20998;&#20165;&#20351;&#29992;&#21333;&#20010;&#26234;&#33021;&#20307;&#35268;&#21010;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#30452;&#25509;&#25512;&#26029;&#35745;&#21010;&#27493;&#39588;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24182;&#19981;&#20445;&#35777;&#25191;&#34892;&#25104;&#21151;&#65292;&#20294;&#21033;&#29992;&#24120;&#35782;&#25512;&#29702;&#26469;&#32452;&#35013;&#21160;&#20316;&#24207;&#21015;&#12290;&#25105;&#20204;&#36890;&#36807;&#36817;&#20284;&#20154;&#31867;&#30452;&#35273;&#65292;&#32467;&#21512;&#20102;&#32463;&#20856;&#35268;&#21010;&#21644;LLMs&#30340;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17246v1 Announce Type: new  Abstract: Classical planning formulations like the Planning Domain Definition Language (PDDL) admit action sequences guaranteed to achieve a goal state given an initial state if any are possible. However, reasoning problems defined in PDDL do not capture temporal aspects of action taking, for example that two agents in the domain can execute an action simultaneously if postconditions of each do not interfere with preconditions of the other. A human expert can decompose a goal into largely independent constituent parts and assign each agent to one of these subgoals to take advantage of simultaneous actions for faster execution of plan steps, each using only single agent planning. By contrast, large language models (LLMs) used for directly inferring plan steps do not guarantee execution success, but do leverage commonsense reasoning to assemble action sequences. We combine the strengths of classical planning and LLMs by approximating human intuition
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#35299;&#37322;&#26694;&#26550;&#65292;&#20174;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#20013;&#25552;&#21462;&#39118;&#26684;&#24046;&#24322;&#24182;&#27604;&#36739;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#30340;&#39118;&#26684;&#65292;&#21019;&#24314;&#20102;&#20840;&#38754;&#30340;&#22810;&#35821;&#35328;&#31036;&#35980;&#25968;&#25454;&#38598;&#65292;&#25506;&#32034;&#20102;&#31036;&#35980;&#22312;&#22235;&#31181;&#35821;&#35328;&#20013;&#30340;&#21464;&#21270;&#65292;&#20026;&#35780;&#20272;&#35821;&#35328;&#31867;&#21035;&#23545;&#39118;&#26684;&#21464;&#21270;&#30340;&#36129;&#29486;&#21644;&#20102;&#35299;&#19990;&#30028;&#21508;&#22320;&#20154;&#20204;&#30340;&#19981;&#21516;&#27807;&#36890;&#26041;&#24335;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#26041;&#27861;&#21644;&#35299;&#37322;&#27934;&#23519;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.07135</link><description>&lt;p&gt;
&#36328;&#35821;&#35328;&#39118;&#26684;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Comparing Styles across Languages. (arXiv:2310.07135v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07135
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#35299;&#37322;&#26694;&#26550;&#65292;&#20174;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#20013;&#25552;&#21462;&#39118;&#26684;&#24046;&#24322;&#24182;&#27604;&#36739;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#30340;&#39118;&#26684;&#65292;&#21019;&#24314;&#20102;&#20840;&#38754;&#30340;&#22810;&#35821;&#35328;&#31036;&#35980;&#25968;&#25454;&#38598;&#65292;&#25506;&#32034;&#20102;&#31036;&#35980;&#22312;&#22235;&#31181;&#35821;&#35328;&#20013;&#30340;&#21464;&#21270;&#65292;&#20026;&#35780;&#20272;&#35821;&#35328;&#31867;&#21035;&#23545;&#39118;&#26684;&#21464;&#21270;&#30340;&#36129;&#29486;&#21644;&#20102;&#35299;&#19990;&#30028;&#21508;&#22320;&#20154;&#20204;&#30340;&#19981;&#21516;&#27807;&#36890;&#26041;&#24335;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#26041;&#27861;&#21644;&#35299;&#37322;&#27934;&#23519;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#36328;&#35821;&#35328;&#39118;&#26684;&#30340;&#24046;&#24322;&#26377;&#21161;&#20110;&#35757;&#32451;&#20154;&#31867;&#21644;&#35745;&#31639;&#26426;&#29983;&#25104;&#31526;&#21512;&#25991;&#21270;&#32972;&#26223;&#30340;&#25991;&#26412;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#35299;&#37322;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#20013;&#25552;&#21462;&#39118;&#26684;&#24046;&#24322;&#65292;&#24182;&#27604;&#36739;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#30340;&#39118;&#26684;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;(1)&#21487;&#20197;&#29983;&#25104;&#20219;&#20309;&#35821;&#35328;&#30340;&#20840;&#38754;&#39118;&#26684;&#35789;&#20856;&#65292;(2)&#23558;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#32479;&#19968;&#20026;&#21487;&#27604;&#36739;&#30340;&#35789;&#27719;&#31867;&#21035;&#12290;&#25105;&#20204;&#24212;&#29992;&#35813;&#26694;&#26550;&#27604;&#36739;&#20102;&#31036;&#35980;&#35821;&#35328;&#65292;&#21019;&#24314;&#20102;&#31532;&#19968;&#20010;&#20840;&#38754;&#30340;&#22810;&#35821;&#35328;&#31036;&#35980;&#25968;&#25454;&#38598;&#65292;&#24182;&#25506;&#32034;&#20102;&#31036;&#35980;&#22312;&#22235;&#31181;&#35821;&#35328;&#20013;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;&#19981;&#21516;&#35821;&#35328;&#31867;&#21035;&#23545;&#39118;&#26684;&#21464;&#21270;&#30340;&#36129;&#29486;&#65292;&#24182;&#25552;&#20379;&#21487;&#35299;&#37322;&#30340;&#27934;&#23519;&#21147;&#65292;&#20102;&#35299;&#19990;&#30028;&#21508;&#22320;&#20154;&#20204;&#30340;&#19981;&#21516;&#27807;&#36890;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding how styles differ across languages is advantageous for training both humans and computers to generate culturally appropriate text. We introduce an explanation framework to extract stylistic differences from multilingual LMs and compare styles across languages. Our framework (1) generates comprehensive style lexica in any language and (2) consolidates feature importances from LMs into comparable lexical categories. We apply this framework to compare politeness, creating the first holistic multilingual politeness dataset and exploring how politeness varies across four languages. Our approach enables an effective evaluation of how distinct linguistic categories contribute to stylistic variations and provides interpretable insights into how people communicate differently around the world.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20960;&#20309;&#35266;&#24565;&#30340;&#22240;&#26524;&#25506;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35821;&#35328;&#27169;&#22411;&#34920;&#31034;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#19978;&#36827;&#34892;&#21453;&#20107;&#23454;&#24178;&#39044;&#65292;&#20248;&#21270;&#20102;&#22240;&#26524;&#27010;&#24565;&#23376;&#31354;&#38388;&#65292;&#20197;&#23454;&#29616;&#27010;&#24565;&#25511;&#21046;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2307.15054</link><description>&lt;p&gt;
&#19968;&#31181;&#20960;&#20309;&#35266;&#24565;&#30340;&#22240;&#26524;&#25506;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Geometric Notion of Causal Probing. (arXiv:2307.15054v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20960;&#20309;&#35266;&#24565;&#30340;&#22240;&#26524;&#25506;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35821;&#35328;&#27169;&#22411;&#34920;&#31034;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#19978;&#36827;&#34892;&#21453;&#20107;&#23454;&#24178;&#39044;&#65292;&#20248;&#21270;&#20102;&#22240;&#26524;&#27010;&#24565;&#23376;&#31354;&#38388;&#65292;&#20197;&#23454;&#29616;&#27010;&#24565;&#25511;&#21046;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20381;&#36182;&#20110;&#25991;&#26412;&#30340;&#23454;&#20540;&#34920;&#31034;&#26469;&#36827;&#34892;&#39044;&#27979;&#12290;&#36825;&#20123;&#34920;&#31034;&#21253;&#21547;&#20102;&#27169;&#22411;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#23398;&#21040;&#30340;&#20449;&#24687;&#65292;&#21253;&#25324;&#35821;&#35328;&#23646;&#24615;&#21644;&#22522;&#20110;&#24615;&#21035;&#30340;&#20154;&#21475;&#20559;&#35265;&#31561;&#12290;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#36890;&#36807;&#22312;&#34920;&#31034;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#19978;&#36827;&#34892;&#27491;&#20132;&#25237;&#24433;&#26469;&#33719;&#24471;&#20851;&#20110;&#36825;&#20123;&#27010;&#24565;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#35821;&#35328;&#27169;&#22411;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#20449;&#24687;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#20026;&#36825;&#39033;&#30740;&#31350;&#36129;&#29486;&#20102;&#26032;&#30340;&#20869;&#23481;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#26041;&#27861;&#26469;&#36991;&#20813;&#34394;&#20551;&#30456;&#20851;&#30340;&#22833;&#25928;&#27169;&#24335;&#65292;&#36890;&#36807;&#29420;&#31435;&#22788;&#29702;&#23376;&#31354;&#38388;&#20013;&#30340;&#20998;&#37327;&#21644;&#20854;&#27491;&#20132;&#34917;&#31354;&#38388;&#20013;&#30340;&#20998;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23376;&#31354;&#38388;&#20013;&#30340;&#21453;&#20107;&#23454;&#20449;&#24687;&#27010;&#24565;&#26159;&#30001;&#19968;&#20010;&#22240;&#26524;&#27010;&#24565;&#23376;&#31354;&#38388;&#36827;&#34892;&#20248;&#21270;&#30340;&#12290;&#27492;&#22806;&#65292;&#36825;&#31181;&#24178;&#39044;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#25805;&#20316;&#26469;&#23581;&#35797;&#27010;&#24565;&#25511;&#21046;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models rely on real-valued representations of text to make their predictions. These representations contain information learned from the data that the model has trained on, including knowledge of linguistic properties and forms of demographic bias, e.g., based on gender. A growing body of work has considered information about concepts such as these using orthogonal projections onto subspaces of the representation space. We contribute to this body of work by proposing a formal definition of intrinsic information in a subspace of a language model's representation space. We propose a counterfactual approach that avoids the failure mode of spurious correlations (Kumar et al., 2022) by treating components in the subspace and its orthogonal complement independently. We show that our counterfactual notion of information in a subspace is optimizing by an causal concept subspace. Furthermore, this intervention allows us to attempt concept controlled generation by manipulating the
&lt;/p&gt;</description></item></channel></rss>