<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#23545;GPT-3.5&#12289;GPT-4&#21644;Bard&#29983;&#25104;&#30340;&#25991;&#26412;&#36827;&#34892;&#35821;&#35328;&#20998;&#26512;&#27604;&#36739;&#65292;&#21457;&#29616;&#19981;&#21516;&#30340;LLM&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#35821;&#35328;&#21464;&#21270;&#65292;&#21487;&#20197;&#20197;88%&#30340;&#20934;&#30830;&#29575;&#36890;&#36807;&#31616;&#21333;&#30340;&#20998;&#31867;&#27169;&#22411;&#23558;&#25991;&#26412;&#24402;&#22240;&#20110;&#30456;&#24212;&#30340;LLM&#26469;&#28304;&#12290;</title><link>https://arxiv.org/abs/2402.14533</link><description>&lt;p&gt;
&#12298;&#23427;&#21040;&#24213;&#26159;&#35841;&#30340;LLM&#65311;GPT-3.5&#12289;GPT-4&#21644;Bard&#30340;&#35821;&#35328;&#27604;&#36739;&#21644;LLM&#23646;&#24615;&#24402;&#22240;&#12299;
&lt;/p&gt;
&lt;p&gt;
Whose LLM is it Anyway? Linguistic Comparison and LLM Attribution for GPT-3.5, GPT-4 and Bard
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14533
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;GPT-3.5&#12289;GPT-4&#21644;Bard&#29983;&#25104;&#30340;&#25991;&#26412;&#36827;&#34892;&#35821;&#35328;&#20998;&#26512;&#27604;&#36739;&#65292;&#21457;&#29616;&#19981;&#21516;&#30340;LLM&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#35821;&#35328;&#21464;&#21270;&#65292;&#21487;&#20197;&#20197;88%&#30340;&#20934;&#30830;&#29575;&#36890;&#36807;&#31616;&#21333;&#30340;&#20998;&#31867;&#27169;&#22411;&#23558;&#25991;&#26412;&#24402;&#22240;&#20110;&#30456;&#24212;&#30340;LLM&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#22815;&#29983;&#25104;&#19982;&#25110;&#36229;&#36234;&#20154;&#31867;&#36136;&#37327;&#30456;&#20284;&#30340;&#25991;&#26412;&#12290;&#28982;&#32780;&#65292;LLMs&#26159;&#21542;&#20542;&#21521;&#20110;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;&#20154;&#31867;&#20316;&#32773;&#30340;&#29420;&#29305;&#35821;&#35328;&#39118;&#26684;&#23578;&#19981;&#28165;&#26970;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#35821;&#35328;&#20998;&#26512;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#30001;&#24403;&#20170;&#26368;&#27969;&#34892;&#30340;&#19977;&#31181;LLMs&#65288;GPT-3.5&#12289;GPT-4&#21644;Bard&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#35789;&#27719;&#12289;&#35789;&#24615;&#20998;&#24067;&#12289;&#20381;&#36182;&#20998;&#24067;&#21644;&#24773;&#24863;&#19982;&#22810;&#26679;&#36755;&#20837;&#12290;&#32467;&#26524;&#26174;&#31034;&#20986;&#26174;&#33879;&#30340;&#35821;&#35328;&#21464;&#21270;&#65292;&#36827;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;&#31616;&#21333;&#30340;&#29616;&#25104;&#20998;&#31867;&#27169;&#22411;&#20197;88%&#30340;&#20934;&#30830;&#29575;&#23558;&#32473;&#23450;&#25991;&#26412;&#24402;&#22240;&#20110;&#20854;LLM&#26469;&#28304;&#12290;&#35752;&#35770;&#20102;&#36825;&#19968;&#26377;&#36259;&#21457;&#29616;&#30340;&#29702;&#35770;&#21644;&#23454;&#36341;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14533v1 Announce Type: new  Abstract: Large Language Models (LLMs) are capable of generating text that is similar to or surpasses human quality. However, it is unclear whether LLMs tend to exhibit distinctive linguistic styles akin to how human authors do. Through a comprehensive linguistic analysis, we compare the vocabulary, Part-Of-Speech (POS) distribution, dependency distribution, and sentiment of texts generated by three of the most popular LLMS today (GPT-3.5, GPT-4, and Bard) to diverse inputs. The results point to significant linguistic variations which, in turn, enable us to attribute a given text to its LLM origin with a favorable 88\% accuracy using a simple off-the-shelf classification model. Theoretical and practical implications of this intriguing finding are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20174;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#20013;&#30417;&#27979;&#26538;&#25903;&#26292;&#21147;&#20107;&#20214;&#30340;&#21487;&#34892;&#24615;&#12290;&#30740;&#31350;&#22242;&#38431;&#20351;&#29992;&#32463;&#36807;&#24494;&#35843;&#30340;BERT&#27169;&#22411;&#35782;&#21035;&#24052;&#35199;&#30340;&#26538;&#25903;&#26292;&#21147;&#25253;&#21578;&#24182;&#21462;&#24471;&#20102;&#39640;&#20934;&#30830;&#24230;&#12290;&#30740;&#31350;&#32467;&#26524;&#26377;&#21161;&#20110;&#20154;&#26435;&#32452;&#32455;&#25910;&#38598;&#21253;&#21547;&#25152;&#38656;&#25968;&#25454;&#30340;&#20840;&#38754;&#25968;&#25454;&#24211;&#12290;</title><link>http://arxiv.org/abs/2401.12989</link><description>&lt;p&gt;
&#22312;&#20132;&#28779;&#20013;&#65306;&#35780;&#20272;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20247;&#21253;&#26538;&#25903;&#26292;&#21147;&#25253;&#21578;&#30340;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports. (arXiv:2401.12989v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20174;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#20013;&#30417;&#27979;&#26538;&#25903;&#26292;&#21147;&#20107;&#20214;&#30340;&#21487;&#34892;&#24615;&#12290;&#30740;&#31350;&#22242;&#38431;&#20351;&#29992;&#32463;&#36807;&#24494;&#35843;&#30340;BERT&#27169;&#22411;&#35782;&#21035;&#24052;&#35199;&#30340;&#26538;&#25903;&#26292;&#21147;&#25253;&#21578;&#24182;&#21462;&#24471;&#20102;&#39640;&#20934;&#30830;&#24230;&#12290;&#30740;&#31350;&#32467;&#26524;&#26377;&#21161;&#20110;&#20154;&#26435;&#32452;&#32455;&#25910;&#38598;&#21253;&#21547;&#25152;&#38656;&#25968;&#25454;&#30340;&#20840;&#38754;&#25968;&#25454;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26538;&#25903;&#26292;&#21147;&#26159;&#19968;&#20010;&#32039;&#36843;&#19988;&#19981;&#26029;&#22686;&#38271;&#30340;&#20154;&#26435;&#38382;&#39064;&#65292;&#24433;&#21709;&#30528;&#31038;&#20250;&#30340;&#26041;&#26041;&#38754;&#38754;&#65292;&#20174;&#21307;&#30103;&#20445;&#20581;&#21644;&#25945;&#32946;&#21040;&#24515;&#29702;&#23398;&#21644;&#32463;&#27982;&#23398;&#12290;&#21487;&#38752;&#30340;&#26538;&#25903;&#20107;&#20214;&#25968;&#25454;&#23545;&#20110;&#21046;&#23450;&#26356;&#26377;&#25928;&#30340;&#20844;&#20849;&#25919;&#31574;&#21644;&#24212;&#24613;&#21709;&#24212;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#20840;&#38754;&#30340;&#25968;&#25454;&#24211;&#21644;&#38754;&#23545;&#38754;&#35843;&#26597;&#30340;&#39118;&#38505;&#38459;&#27490;&#20102;&#20154;&#26435;&#32452;&#32455;&#22312;&#22823;&#22810;&#25968;&#22269;&#23478;&#25910;&#38598;&#25152;&#38656;&#30340;&#25968;&#25454;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#19982;&#19968;&#23478;&#24052;&#35199;&#20154;&#26435;&#32452;&#32455;&#21512;&#20316;&#65292;&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31995;&#32479;&#35780;&#20272;&#65292;&#20197;&#24110;&#21161;&#30417;&#27979;&#26469;&#33258;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#29616;&#23454;&#19990;&#30028;&#26538;&#25903;&#20107;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;Twitter&#19978;&#32463;&#36807;&#24494;&#35843;&#30340;&#22522;&#20110;BERT&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#21306;&#20998;&#26538;&#25903;&#26292;&#21147;&#25253;&#21578;&#21644;&#26222;&#36890;&#33889;&#33796;&#29273;&#35821;&#25991;&#26412;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#36798;&#21040;&#20102;&#39640;&#36798;0.97&#30340;AUC&#20998;&#25968;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#25972;&#21512;&#21040;&#19968;&#20010;Web&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#24182;&#22312;&#23454;&#26102;&#24178;&#39044;&#20013;&#23545;&#20854;&#36827;&#34892;&#27979;&#35797;&#12290;&#25105;&#20204;&#30740;&#31350;&#24182;&#37319;&#35775;&#24052;&#35199;&#20998;&#26512;&#24072;&#65292;&#20182;&#20204;&#22312;&#25345;&#32493;&#36827;&#34892;&#31038;&#20132;&#23186;&#20307;&#20107;&#23454;&#26680;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gun violence is a pressing and growing human rights issue that affects nearly every dimension of the social fabric, from healthcare and education to psychology and the economy. Reliable data on firearm events is paramount to developing more effective public policy and emergency responses. However, the lack of comprehensive databases and the risks of in-person surveys prevent human rights organizations from collecting needed data in most countries. Here, we partner with a Brazilian human rights organization to conduct a systematic evaluation of language models to assist with monitoring real-world firearm events from social media data. We propose a fine-tuned BERT-based model trained on Twitter (now X) texts to distinguish gun violence reports from ordinary Portuguese texts. Our model achieves a high AUC score of 0.97. We then incorporate our model into a web application and test it in a live intervention. We study and interview Brazilian analysts who continuously fact-check social media
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#21040;&#27573;&#26144;&#23556;&#26469;&#23454;&#29616;&#38382;&#39064;&#22238;&#31572;&#30693;&#35782;&#22270;&#35889;&#12290;&#35813;&#26041;&#27861;&#20391;&#37325;&#20110;&#35821;&#20041;&#35299;&#26512;&#65292;&#35299;&#20915;&#20102;&#29702;&#35299;&#38382;&#39064;&#20013;&#30340;&#38544;&#21547;&#23454;&#20307;&#12289;&#20851;&#31995;&#21644;&#22797;&#26434;&#32422;&#26463;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#32467;&#21512;&#35268;&#21017;&#21644;&#31070;&#32463;&#32593;&#32476;&#25216;&#26415;&#65292;&#26500;&#24314;&#20102;&#39640;&#31934;&#24230;&#21644;&#20840;&#38754;&#30340;&#35821;&#20041;&#27573;&#24207;&#21015;&#65292;&#23454;&#29616;&#20102;&#38382;&#39064;&#38472;&#36848;&#30340;&#26377;&#25928;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2401.06772</link><description>&lt;p&gt;
&#38382;&#39064;&#22238;&#31572;&#30693;&#35782;&#22270;&#35889;&#30340;&#35821;&#20041;&#35299;&#26512;
&lt;/p&gt;
&lt;p&gt;
Semantic Parsing for Question Answering over Knowledge Graphs. (arXiv:2401.06772v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#21040;&#27573;&#26144;&#23556;&#26469;&#23454;&#29616;&#38382;&#39064;&#22238;&#31572;&#30693;&#35782;&#22270;&#35889;&#12290;&#35813;&#26041;&#27861;&#20391;&#37325;&#20110;&#35821;&#20041;&#35299;&#26512;&#65292;&#35299;&#20915;&#20102;&#29702;&#35299;&#38382;&#39064;&#20013;&#30340;&#38544;&#21547;&#23454;&#20307;&#12289;&#20851;&#31995;&#21644;&#22797;&#26434;&#32422;&#26463;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#32467;&#21512;&#35268;&#21017;&#21644;&#31070;&#32463;&#32593;&#32476;&#25216;&#26415;&#65292;&#26500;&#24314;&#20102;&#39640;&#31934;&#24230;&#21644;&#20840;&#38754;&#30340;&#35821;&#20041;&#27573;&#24207;&#21015;&#65292;&#23454;&#29616;&#20102;&#38382;&#39064;&#38472;&#36848;&#30340;&#26377;&#25928;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#21040;&#27573;&#26144;&#23556;&#26469;&#23454;&#29616;&#38382;&#39064;&#22238;&#31572;&#30693;&#35782;&#22270;&#35889;&#12290;&#35813;&#26041;&#27861;&#20391;&#37325;&#20110;&#35821;&#20041;&#35299;&#26512;&#65292;&#36825;&#26159;&#35299;&#37322;&#38382;&#39064;&#38472;&#36848;&#30340;&#20851;&#38190;&#26041;&#27861;&#12290;&#25361;&#25112;&#22312;&#20110;&#29702;&#35299;&#38382;&#39064;&#20013;&#30340;&#38544;&#21547;&#23454;&#20307;&#12289;&#20851;&#31995;&#20197;&#21450;&#26102;&#38388;&#12289;&#25490;&#24207;&#21644;&#32858;&#21512;&#31561;&#22797;&#26434;&#32422;&#26463;&#65292;&#36825;&#20123;&#32422;&#26463;&#22312;&#30693;&#35782;&#22270;&#35889;&#30340;&#32972;&#26223;&#19979;&#36827;&#34892;&#19978;&#19979;&#25991;&#22788;&#29702;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#37319;&#29992;&#20102;&#22522;&#20110;&#35268;&#21017;&#21644;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25216;&#26415;&#30340;&#32452;&#21512;&#65292;&#35299;&#26512;&#24182;&#26500;&#24314;&#20102;&#39640;&#31934;&#24230;&#21644;&#20840;&#38754;&#30340;&#35821;&#20041;&#27573;&#24207;&#21015;&#12290;&#36825;&#20123;&#24207;&#21015;&#24418;&#25104;&#35821;&#20041;&#26597;&#35810;&#22270;&#65292;&#26377;&#25928;&#22320;&#34920;&#31034;&#38382;&#39064;&#38472;&#36848;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#35821;&#20041;&#35299;&#26512;&#20316;&#20026;&#19968;&#20010;&#24207;&#21015;&#29983;&#25104;&#20219;&#21153;&#65292;&#21033;&#29992;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#23558;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#36716;&#21270;&#20026;&#35821;&#20041;&#27573;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22686;&#24378;&#23545;&#38544;&#21547;&#23454;&#20307;&#21644;&#20851;&#31995;&#30340;&#35299;&#26512;&#65292;&#25105;&#20204;&#32467;&#21512;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel method with graph-to-segment mapping for question answering over knowledge graphs, which helps understanding question utterances. This method centers on semantic parsing, a key approach for interpreting these utterances. The challenges lie in comprehending implicit entities, relationships, and complex constraints like time, ordinality, and aggregation within questions, contextualized by the knowledge graph. Our framework employs a combination of rule-based and neural-based techniques to parse and construct highly accurate and comprehensive semantic segment sequences. These sequences form semantic query graphs, effectively representing question utterances. We approach question semantic parsing as a sequence generation task, utilizing an encoder-decoder neural network to transform natural language questions into semantic segments. Moreover, to enhance the parsing of implicit entities and relations, we incorporate a graph neural network that leverages t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#19978;&#19979;&#25991;&#21644;&#23383;&#38754;&#20449;&#24687;&#23481;&#32435;&#21040;&#23454;&#20307;&#21644;&#20851;&#31995;&#30340;&#23884;&#20837;&#20013;&#65292;&#21033;&#29992;&#22270;&#21367;&#31215;&#32593;&#32476;&#65292;&#24182;&#36890;&#36807;&#35268;&#21017;&#21644;&#23383;&#38754;&#20449;&#24687;&#30340;&#34920;&#31034;&#35745;&#31639;&#32622;&#20449;&#24230;&#21644;&#30456;&#20851;&#24615;&#25351;&#26631;&#65292;&#20197;&#25552;&#39640;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.02968</link><description>&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#30340;&#35268;&#21017;&#24341;&#23548;&#32852;&#21512;&#23884;&#20837;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Rule-Guided Joint Embedding Learning of Knowledge Graphs. (arXiv:2401.02968v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#19978;&#19979;&#25991;&#21644;&#23383;&#38754;&#20449;&#24687;&#23481;&#32435;&#21040;&#23454;&#20307;&#21644;&#20851;&#31995;&#30340;&#23884;&#20837;&#20013;&#65292;&#21033;&#29992;&#22270;&#21367;&#31215;&#32593;&#32476;&#65292;&#24182;&#36890;&#36807;&#35268;&#21017;&#21644;&#23383;&#38754;&#20449;&#24687;&#30340;&#34920;&#31034;&#35745;&#31639;&#32622;&#20449;&#24230;&#21644;&#30456;&#20851;&#24615;&#25351;&#26631;&#65292;&#20197;&#25552;&#39640;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#20851;&#27880;&#28857;&#20027;&#35201;&#38598;&#20013;&#22312;&#22686;&#24378;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#23398;&#20064;&#19978;&#65292;&#35813;&#23398;&#20064;&#23558;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#23454;&#20307;&#21644;&#20851;&#31995;&#32534;&#30721;&#20026;&#20302;&#32500;&#21521;&#37327;&#31354;&#38388;&#12290;&#23613;&#31649;&#24403;&#21069;&#27169;&#22411;&#20027;&#35201;&#32771;&#34385;&#36825;&#20123;&#22270;&#35889;&#30340;&#32467;&#26500;&#26041;&#38754;&#65292;&#20294;&#22312;&#30693;&#35782;&#22270;&#35889;&#20013;&#23384;&#22312;&#30528;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#21644;&#23383;&#38754;&#20449;&#24687;&#65292;&#21487;&#20197;&#29992;&#20110;&#26356;&#26377;&#25928;&#30340;&#23884;&#20837;&#23398;&#20064;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#22411;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#19978;&#19979;&#25991;&#21644;&#23383;&#38754;&#20449;&#24687;&#23481;&#32435;&#21040;&#23454;&#20307;&#21644;&#20851;&#31995;&#30340;&#23884;&#20837;&#20013;&#65292;&#21033;&#29992;&#22270;&#21367;&#31215;&#32593;&#32476;&#12290;&#20855;&#20307;&#22320;&#65292;&#23545;&#20110;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#25105;&#20204;&#36890;&#36807;&#32622;&#20449;&#24230;&#21644;&#30456;&#20851;&#24615;&#25351;&#26631;&#35780;&#20272;&#20854;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#26469;&#35745;&#31639;&#32622;&#20449;&#24230;&#25351;&#26631;&#65292;&#24182;&#20174;&#23383;&#38754;&#20449;&#24687;&#30340;&#34920;&#31034;&#20013;&#24471;&#20986;&#30456;&#20851;&#24615;&#25351;&#26631;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#20004;&#20010;&#24050;&#24314;&#31435;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#35814;&#23613;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent studies, the focus has been on enhancing knowledge graph embedding learning, which encodes entities and relations in knowledge graphs into low-dimensional vector spaces. While current models mainly consider the structural aspects of these graphs, there's a wealth of contextual and literal information in knowledge graphs that can be utilized for more effective embeddings. This paper introduces a novel model that incorporates both contextual and literal information into entity and relation embeddings, utilizing graph convolutional networks. Specifically, for contextual information, we assess its significance through confidence and relatedness metrics. A unique rule-based method is developed to calculate the confidence metric, and the relatedness metric is derived from the literal information's representations. We validated our model's performance with thorough experiments on two established benchmark datasets.
&lt;/p&gt;</description></item></channel></rss>