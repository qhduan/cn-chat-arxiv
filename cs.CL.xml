<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#23558;Thinker&#19982;&#28418;&#31227;&#25193;&#25955;&#27169;&#22411;&#38598;&#25104;&#65292;&#37325;&#26032;&#23450;&#20041;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#20197;&#27169;&#25311;&#20154;&#31867;&#32763;&#35793;&#32773;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#23454;&#39564;&#35777;&#26126;&#22312;&#26426;&#22120;&#32763;&#35793;&#20013;&#21462;&#24471;&#20102;&#20248;&#24322;&#25104;&#32489;&#12290;</title><link>https://arxiv.org/abs/2402.10699</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#31867;&#20154;&#32763;&#35793;&#31574;&#30053;&#65306;&#23558;&#28418;&#31227;&#25193;&#25955;&#27169;&#22411;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Rethinking Human-like Translation Strategy: Integrating Drift-Diffusion Model with Large Language Models for Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10699
&lt;/p&gt;
&lt;p&gt;
&#23558;Thinker&#19982;&#28418;&#31227;&#25193;&#25955;&#27169;&#22411;&#38598;&#25104;&#65292;&#37325;&#26032;&#23450;&#20041;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#20197;&#27169;&#25311;&#20154;&#31867;&#32763;&#35793;&#32773;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#23454;&#39564;&#35777;&#26126;&#22312;&#26426;&#22120;&#32763;&#35793;&#20013;&#21462;&#24471;&#20102;&#20248;&#24322;&#25104;&#32489;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21253;&#25324;&#26426;&#22120;&#32763;&#35793;&#22312;&#20869;&#30340;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20102;&#24040;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;LLM&#30340;&#26426;&#22120;&#32763;&#35793;&#20808;&#21069;&#30340;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#26356;&#22909;&#22320;&#21033;&#29992;&#35757;&#32451;&#25968;&#25454;&#12289;&#28436;&#31034;&#29256;&#26412;&#25110;&#39044;&#23450;&#20041;&#30340;&#26222;&#36941;&#30693;&#35782;&#26469;&#25552;&#39640;&#24615;&#33021;&#65292;&#32570;&#20047;&#23545;&#31867;&#20284;&#20154;&#31867;&#32763;&#35793;&#32773;&#30340;&#20915;&#31574;&#21046;&#23450;&#30340;&#32771;&#34385;&#12290;&#26412;&#25991;&#23558;&#8220;Thinker&#8221;&#19982;&#28418;&#31227;&#25193;&#25955;&#27169;&#22411;&#65288;Thinker-DDM&#65289;&#30456;&#32467;&#21512;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#37325;&#26032;&#23450;&#20041;&#20102;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#65292;&#20197;&#27169;&#25311;&#21463;&#38480;&#36164;&#28304;&#24773;&#20917;&#19979;&#31867;&#20154;&#32763;&#35793;&#32773;&#30340;&#21160;&#24577;&#20915;&#31574;&#21046;&#23450;&#12290;&#25105;&#20204;&#22312;&#39640;&#36164;&#28304;&#12289;&#20302;&#36164;&#28304;&#21644;&#24120;&#35782;&#32763;&#35793;&#35774;&#32622;&#19979;&#65292;&#20351;&#29992;WMT22&#21644;CommonMT&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#22312;&#21069;&#20004;&#31181;&#22330;&#26223;&#20013;&#65292;Thinker-DDM&#30340;&#34920;&#29616;&#20248;&#20110;&#22522;&#20934;&#12290;&#25105;&#20204;&#36824;&#23545;&#24120;&#35782;&#32763;&#35793;&#36827;&#34892;&#20102;&#39069;&#22806;&#30340;&#20998;&#26512;&#21644;&#35780;&#20272;&#65292;&#20197;&#35828;&#26126;&#20854;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10699v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated promising potential in various downstream tasks, including machine translation. However, prior work on LLM-based machine translation has mainly focused on better utilizing training data, demonstrations, or pre-defined and universal knowledge to improve performance, with a lack of consideration of decision-making like human translators. In this paper, we incorporate Thinker with the Drift-Diffusion Model (Thinker-DDM) to address this issue. We then redefine the Drift-Diffusion process to emulate human translators' dynamic decision-making under constrained resources. We conduct extensive experiments under the high-resource, low-resource, and commonsense translation settings using the WMT22 and CommonMT datasets, in which Thinker-DDM outperforms baselines in the first two scenarios. We also perform additional analysis and evaluation on commonsense translation to illustrate the high effectivenes
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#27493;&#39588;&#29983;&#25104;&#12289;&#39564;&#35777;&#21644;&#32416;&#27491;&#30340;&#25968;&#25454;&#29983;&#25104;&#25991;&#26412;&#26041;&#27861;&#65292;&#36890;&#36807;&#19987;&#38376;&#30340;&#38169;&#35823;&#25351;&#31034;&#25552;&#31034;&#26469;&#25913;&#21892;&#36755;&#20986;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.15933</link><description>&lt;p&gt;
&#36890;&#36807;&#39564;&#35777;&#21644;&#32416;&#27491;&#25552;&#31034;&#36827;&#34892;&#25968;&#25454;&#29983;&#25104;&#25991;&#26412;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
You Can Generate It Again: Data-to-text Generation with Verification and Correction Prompting. (arXiv:2306.15933v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#27493;&#39588;&#29983;&#25104;&#12289;&#39564;&#35777;&#21644;&#32416;&#27491;&#30340;&#25968;&#25454;&#29983;&#25104;&#25991;&#26412;&#26041;&#27861;&#65292;&#36890;&#36807;&#19987;&#38376;&#30340;&#38169;&#35823;&#25351;&#31034;&#25552;&#31034;&#26469;&#25913;&#21892;&#36755;&#20986;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#29616;&#26377;&#27169;&#22411;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20174;&#32467;&#26500;&#21270;&#25968;&#25454;&#36755;&#20837;&#29983;&#25104;&#25991;&#26412;&#25551;&#36848;&#65288;&#31216;&#20026;&#25968;&#25454;&#29983;&#25104;&#25991;&#26412;&#65289;&#20173;&#28982;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21253;&#25324;&#29983;&#25104;&#12289;&#39564;&#35777;&#21644;&#32416;&#27491;&#38454;&#27573;&#30340;&#22810;&#27493;&#39588;&#36807;&#31243;&#65292;&#36229;&#36234;&#20102;&#20256;&#32479;&#30340;&#19968;&#27425;&#24615;&#29983;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;VCP&#65288;&#39564;&#35777;&#21644;&#32416;&#27491;&#25552;&#31034;&#65289;&#65292;&#20174;&#27169;&#22411;&#29983;&#25104;&#21021;&#22987;&#36755;&#20986;&#24320;&#22987;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32487;&#32493;&#39564;&#35777;&#25152;&#29983;&#25104;&#25991;&#26412;&#30340;&#19981;&#21516;&#26041;&#38754;&#30340;&#27491;&#30830;&#24615;&#12290;&#39564;&#35777;&#27493;&#39588;&#30340;&#35266;&#23519;&#32467;&#26524;&#34987;&#36716;&#21270;&#20026;&#19987;&#38376;&#30340;&#38169;&#35823;&#25351;&#31034;&#25552;&#31034;&#65292;&#35813;&#25552;&#31034;&#25351;&#31034;&#27169;&#22411;&#22312;&#37325;&#26032;&#29983;&#25104;&#36755;&#20986;&#26102;&#32771;&#34385;&#24050;&#35782;&#21035;&#30340;&#38169;&#35823;&#12290;&#20026;&#20102;&#22686;&#24378;&#27169;&#22411;&#30340;&#32416;&#27491;&#33021;&#21147;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#22521;&#35757;&#36807;&#31243;&#12290;&#35813;&#36807;&#31243;&#20351;&#27169;&#22411;&#33021;&#22815;&#34701;&#20837;&#38169;&#35823;&#25351;&#31034;&#25552;&#31034;&#30340;&#21453;&#39304;&#65292;&#20174;&#32780;&#25913;&#21892;&#36755;&#20986;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite significant advancements in existing models, generating text descriptions from structured data input, known as data-to-text generation, remains a challenging task. In this paper, we propose a novel approach that goes beyond traditional one-shot generation methods by introducing a multi-step process consisting of generation, verification, and correction stages. Our approach, VCP(Verification and Correction Prompting), begins with the model generating an initial output. We then proceed to verify the correctness of different aspects of the generated text. The observations from the verification step are converted into a specialized error-indication prompt, which instructs the model to regenerate the output while considering the identified errors. To enhance the model's correction ability, we have developed a carefully designed training procedure. This procedure enables the model to incorporate feedback from the error-indication prompt, resulting in improved output generation. Throu
&lt;/p&gt;</description></item></channel></rss>