<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#29992;&#20110;&#27491;&#24335;&#35748;&#35777;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#33021;&#21147;&#65292;&#35777;&#20070;&#23450;&#37327;&#21270;&#19988;&#21253;&#21547;&#39640;&#32622;&#20449;&#24230;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#30740;&#31350;&#21457;&#29616;&#65292;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#25552;&#39640;&#65292;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.15929</link><description>&lt;p&gt;
QuaCer-C&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#23450;&#37327;&#35748;&#35777;
&lt;/p&gt;
&lt;p&gt;
QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#29992;&#20110;&#27491;&#24335;&#35748;&#35777;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30693;&#35782;&#29702;&#35299;&#30340;&#33021;&#21147;&#65292;&#35777;&#20070;&#23450;&#37327;&#21270;&#19988;&#21253;&#21547;&#39640;&#32622;&#20449;&#24230;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#30740;&#31350;&#21457;&#29616;&#65292;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#25552;&#39640;&#65292;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30740;&#31350;&#24182;&#26410;&#23545;LLMs&#30340;&#34920;&#29616;&#25552;&#20379;&#27491;&#24335;&#30340;&#20445;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;LLM&#35748;&#35777;&#26694;&#26550;QuaCer-C&#65292;&#25105;&#20204;&#22312;&#27492;&#23545;&#30693;&#21517;LLMs&#30340;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#36827;&#34892;&#27491;&#24335;&#35748;&#35777;&#12290;&#25105;&#20204;&#30340;&#35777;&#20070;&#26159;&#23450;&#37327;&#30340; - &#23427;&#20204;&#21253;&#25324;&#23545;&#30446;&#26631;LLM&#22312;&#20219;&#20309;&#30456;&#20851;&#30693;&#35782;&#29702;&#35299;&#25552;&#31034;&#19978;&#32473;&#20986;&#27491;&#30830;&#31572;&#26696;&#30340;&#27010;&#29575;&#30340;&#39640;&#32622;&#20449;&#24230;&#32039;&#23494;&#30028;&#38480;&#12290;&#25105;&#20204;&#38024;&#23545;Llama&#12289;Vicuna&#21644;Mistral LLMs&#30340;&#35777;&#20070;&#34920;&#26126;&#65292;&#30693;&#35782;&#29702;&#35299;&#33021;&#21147;&#38543;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#25552;&#39640;&#65292;&#24182;&#19988;Mistral&#27169;&#22411;&#22312;&#36825;&#19968;&#35780;&#20272;&#20013;&#34920;&#29616;&#19981;&#22914;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15929v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive performance on several benchmarks. However, traditional studies do not provide formal guarantees on the performance of LLMs. In this work, we propose a novel certification framework for LLM, QuaCer-C, wherein we formally certify the knowledge-comprehension capabilities of popular LLMs. Our certificates are quantitative - they consist of high-confidence, tight bounds on the probability that the target LLM gives the correct answer on any relevant knowledge comprehension prompt. Our certificates for the Llama, Vicuna, and Mistral LLMs indicate that the knowledge comprehension capability improves with an increase in the number of parameters and that the Mistral model is less performant than the rest in this evaluation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#32858;&#21512;&#22810;&#20010;&#35270;&#22270;&#30340;&#20247;&#21253;&#27880;&#37322;&#26469;&#33719;&#21462;&#36719;&#26631;&#31614;&#65292;&#20174;&#32780;&#36827;&#34892;&#36328;&#39046;&#22495;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2212.09409</link><description>&lt;p&gt;
&#20174;&#20247;&#21253;&#27880;&#37322;&#20013;&#36827;&#34892;&#22810;&#35270;&#35282;&#30693;&#35782;&#33976;&#39311;&#20197;&#23454;&#29616;&#36328;&#39046;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multi-View Knowledge Distillation from Crowd Annotations for Out-of-Domain Generalization. (arXiv:2212.09409v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#32858;&#21512;&#22810;&#20010;&#35270;&#22270;&#30340;&#20247;&#21253;&#27880;&#37322;&#26469;&#33719;&#21462;&#36719;&#26631;&#31614;&#65292;&#20174;&#32780;&#36827;&#34892;&#36328;&#39046;&#22495;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#36873;&#25321;&#26377;&#25928;&#30340;&#35757;&#32451;&#20449;&#21495;&#24456;&#22256;&#38590;&#65306;&#19987;&#23478;&#27880;&#37322;&#24456;&#26114;&#36149;&#65292;&#32780;&#20247;&#21253;&#27880;&#37322;&#21487;&#33021;&#19981;&#21487;&#38752;&#12290;&#26368;&#36817;&#30340;NLP&#30740;&#31350;&#34920;&#26126;&#65292;&#20174;&#20247;&#21253;&#27880;&#37322;&#20013;&#33719;&#21462;&#26631;&#31614;&#20998;&#24067;&#30340;&#23398;&#20064;&#21487;&#20197;&#26159;&#26377;&#25928;&#30340;&#12290;&#28982;&#32780;&#65292;&#26377;&#24456;&#22810;&#33719;&#21462;&#36825;&#31181;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20219;&#20309;&#19968;&#31181;&#26041;&#27861;&#30340;&#24615;&#33021;&#37117;&#21487;&#33021;&#22240;&#20219;&#21153;&#21644;&#21487;&#29992;&#20247;&#21253;&#27880;&#37322;&#37327;&#32780;&#27874;&#21160;&#65292;&#36825;&#20351;&#24471;&#20107;&#20808;&#19981;&#30693;&#36947;&#21738;&#31181;&#20998;&#24067;&#26368;&#22909;&#12290;&#26412;&#25991;&#22312;&#39046;&#22495;&#22806;&#31995;&#32479;&#22320;&#20998;&#26512;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#36890;&#36807;&#32858;&#21512;&#29616;&#26377;&#26041;&#27861;&#20135;&#29983;&#30340;&#20998;&#24067;&#26469;&#33719;&#21462;&#26469;&#33258;&#20247;&#21253;&#27880;&#37322;&#30340;&#36719;&#26631;&#31614;&#30340;&#26032;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#28201;&#24230;&#32553;&#25918;&#21644;&#25214;&#21040;&#23427;&#20204;&#30340;Jensen-Shannon&#20013;&#24515;&#26469;&#32858;&#21512;&#20247;&#21253;&#27880;&#37322;&#30340;&#22810;&#20010;&#35270;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selecting an effective training signal for tasks in natural language processing is difficult: expert annotations are expensive, and crowd-sourced annotations may not be reliable. At the same time, recent work in NLP has demonstrated that learning from a distribution over labels acquired from crowd annotations can be effective. However, there are many ways to acquire such a distribution, and the performance allotted by any one method can fluctuate based on the task and the amount of available crowd annotations, making it difficult to know a priori which distribution is best. This paper systematically analyzes this in the out-of-domain setting, adding to the NLP literature which has focused on in-domain evaluation, and proposes new methods for acquiring soft-labels from crowd-annotations by aggregating the distributions produced by existing methods. In particular, we propose to aggregate multiple-views of crowd annotations via temperature scaling and finding their Jensen-Shannon centroid
&lt;/p&gt;</description></item></channel></rss>