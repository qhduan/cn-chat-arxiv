<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MExGen&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#26631;&#37327;&#21270;&#27010;&#24565;&#21644;&#22810;&#32423;&#26041;&#27861;&#22788;&#29702;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#30340;&#25361;&#25112;&#65292;&#35777;&#26126;&#21487;&#20197;&#25552;&#20379;&#26356;&#36148;&#36817;&#26412;&#22320;&#30340;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2403.14459</link><description>&lt;p&gt;
&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#32423;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Multi-Level Explanations for Generative Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14459
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MExGen&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#26631;&#37327;&#21270;&#27010;&#24565;&#21644;&#22810;&#32423;&#26041;&#27861;&#22788;&#29702;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#30340;&#25361;&#25112;&#65292;&#35777;&#26126;&#21487;&#20197;&#25552;&#20379;&#26356;&#36148;&#36817;&#26412;&#22320;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25200;&#21160;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#22914;LIME&#21644;SHAP&#65292;&#36890;&#24120;&#24212;&#29992;&#20110;&#25991;&#26412;&#20998;&#31867;&#12290;&#26412;&#25991;&#20851;&#27880;&#23427;&#20204;&#22914;&#20309;&#25193;&#23637;&#21040;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#25991;&#26412;&#20316;&#20026;&#36755;&#20986;&#21644;&#38271;&#25991;&#26412;&#36755;&#20837;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MExGen&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#19981;&#21516;&#30340;&#24402;&#22240;&#31639;&#27861;&#23454;&#20363;&#21270;&#12290;&#20026;&#20102;&#22788;&#29702;&#25991;&#26412;&#36755;&#20986;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23558;&#25991;&#26412;&#26144;&#23556;&#21040;&#23454;&#25968;&#30340;&#26631;&#37327;&#21270;&#27010;&#24565;&#65292;&#24182;&#25506;&#35752;&#20102;&#22810;&#31181;&#21487;&#33021;&#24615;&#12290;&#20026;&#20102;&#22788;&#29702;&#38271;&#36755;&#20837;&#65292;&#25105;&#20204;&#37319;&#29992;&#22810;&#32423;&#26041;&#27861;&#65292;&#20174;&#31895;&#31890;&#24230;&#21040;&#32454;&#31890;&#24230;&#65292;&#37325;&#28857;&#20851;&#27880;&#20855;&#26377;&#27169;&#22411;&#26597;&#35810;&#32447;&#24615;&#32553;&#25918;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#23545;&#22522;&#20110;&#25200;&#21160;&#30340;&#24402;&#22240;&#26041;&#27861;&#36827;&#34892;&#20102;&#31995;&#32479;&#35780;&#20272;&#65292;&#21253;&#25324;&#33258;&#21160;&#21270;&#21644;&#20154;&#24037;&#35780;&#20272;&#65292;&#29992;&#20110;&#25688;&#35201;&#21644;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#38382;&#31572;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#25552;&#20379;&#26356;&#21152;&#36148;&#36817;&#26412;&#22320;&#30340;&#29983;&#25104;&#24335;&#36755;&#20986;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14459v1 Announce Type: cross  Abstract: Perturbation-based explanation methods such as LIME and SHAP are commonly applied to text classification. This work focuses on their extension to generative language models. To address the challenges of text as output and long text inputs, we propose a general framework called MExGen that can be instantiated with different attribution algorithms. To handle text output, we introduce the notion of scalarizers for mapping text to real numbers and investigate multiple possibilities. To handle long inputs, we take a multi-level approach, proceeding from coarser levels of granularity to finer ones, and focus on algorithms with linear scaling in model queries. We conduct a systematic evaluation, both automated and human, of perturbation-based attribution methods for summarization and context-grounded question answering. The results show that our framework can provide more locally faithful explanations of generated outputs.
&lt;/p&gt;</description></item></channel></rss>