<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>GPT-4&#22312;&#26631;&#20934;&#21270;&#35821;&#31687;&#29702;&#35299;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#19982;&#20154;&#31867;&#30456;&#24403;&#30340;&#33021;&#21147;&#65292;&#23588;&#20854;&#22312;&#25512;&#26029;&#26410;&#26126;&#30830;&#38472;&#36848;&#20449;&#24687;&#26041;&#38754;&#26174;&#31034;&#20986;&#26174;&#33879;&#23454;&#21147;</title><link>https://arxiv.org/abs/2403.17196</link><description>&lt;p&gt;
GPT-4&#33267;&#23569;&#33021;&#22815;&#20687;&#20154;&#31867;&#19968;&#26679;&#29702;&#35299;&#35821;&#31687;
&lt;/p&gt;
&lt;p&gt;
GPT-4 Understands Discourse at Least as Well as Humans Do
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17196
&lt;/p&gt;
&lt;p&gt;
GPT-4&#22312;&#26631;&#20934;&#21270;&#35821;&#31687;&#29702;&#35299;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#19982;&#20154;&#31867;&#30456;&#24403;&#30340;&#33021;&#21147;&#65292;&#23588;&#20854;&#22312;&#25512;&#26029;&#26410;&#26126;&#30830;&#38472;&#36848;&#20449;&#24687;&#26041;&#38754;&#26174;&#31034;&#20986;&#26174;&#33879;&#23454;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#27979;&#35797;&#20102;&#19968;&#31181;&#39046;&#20808;&#30340;AI&#31995;&#32479;GPT-4&#26159;&#21542;&#20687;&#20154;&#31867;&#19968;&#26679;&#29702;&#35299;&#35821;&#31687;&#65292;&#20351;&#29992;&#20102;&#19968;&#39033;&#26631;&#20934;&#21270;&#30340;&#35821;&#31687;&#29702;&#35299;&#27979;&#35797;&#12290;&#21442;&#19982;&#32773;&#20250;&#34987;&#21576;&#29616;&#31616;&#30701;&#30340;&#25925;&#20107;&#65292;&#28982;&#21518;&#22238;&#31572;&#20843;&#20010;&#26159;/&#21542;&#38382;&#39064;&#65292;&#25506;&#31350;&#20182;&#20204;&#23545;&#25925;&#20107;&#30340;&#29702;&#35299;&#12290;&#36825;&#20123;&#38382;&#39064;&#30340;&#26684;&#24335;&#26088;&#22312;&#35780;&#20272;&#30452;&#25509;&#24615;&#65288;&#38472;&#36848; vs. &#26263;&#31034;&#65289;&#21644;&#26174;&#33879;&#24615;&#65288;&#20027;&#35201;&#35266;&#28857; vs. &#32454;&#33410;&#65289;&#30340;&#29420;&#31435;&#24433;&#21709;&#12290;&#37492;&#20110;&#20154;&#31867;&#34920;&#29616;&#27700;&#24179;&#38750;&#24120;&#39640;&#65292;GPT-4&#30340;&#34920;&#29616;&#30053;&#22909;&#20110;&#20154;&#31867;&#65292;&#20294;&#24182;&#26080;&#32479;&#35745;&#23398;&#26174;&#33879;&#24046;&#24322;&#12290;GPT-4&#21644;&#20154;&#31867;&#37117;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#33021;&#21147;&#65292;&#33021;&#22815;&#25512;&#26029;&#25925;&#20107;&#20013;&#26410;&#26126;&#30830;&#38472;&#36848;&#30340;&#20449;&#24687;&#65292;&#36825;&#26159;&#23545;&#29702;&#35299;&#21147;&#30340;&#37325;&#35201;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17196v1 Announce Type: new  Abstract: We test whether a leading AI system GPT-4 understands discourse as well as humans do, using a standardized test of discourse comprehension. Participants are presented with brief stories and then answer eight yes/no questions probing their comprehension of the story. The questions are formatted to assess the separate impacts of directness (stated vs. implied) and salience (main idea vs. details). GPT-4 performs slightly, but not statistically significantly, better than humans given the very high level of human performance. Both GPT-4 and humans exhibit a strong ability to make inferences about information that is not explicitly stated in a story, a critical test of understanding.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;AICL&#65289;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#31034;&#20363;&#25968;&#37327;&#26469;&#25552;&#39640;&#25991;&#26412;&#20998;&#31867;&#30340;&#24615;&#33021;&#65292;&#31867;&#20284;&#20110;k&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#20013;&#30340;&#21487;&#21464;&#22823;&#23567;&#37051;&#22495;&#12290;</title><link>https://arxiv.org/abs/2403.06402</link><description>&lt;p&gt;
&#19968;&#20992;&#20999;&#19981;&#36866;&#29992;&#65306;&#23398;&#20064;&#22312;&#25991;&#26412;&#20998;&#31867;&#20013;&#20351;&#29992;&#22810;&#23569;&#20363;&#20026;&#20102;&#25913;&#36827;&#19978;&#19979;&#25991;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
'One size doesn't fit all': Learning how many Examples to use for In-Context Learning for Improved Text Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;AICL&#65289;&#30340;&#24037;&#20316;&#27969;&#31243;&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#31034;&#20363;&#25968;&#37327;&#26469;&#25552;&#39640;&#25991;&#26412;&#20998;&#31867;&#30340;&#24615;&#33021;&#65292;&#31867;&#20284;&#20110;k&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#20013;&#30340;&#21487;&#21464;&#22823;&#23567;&#37051;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06402v1 &#21457;&#34920;&#31867;&#22411;&#65306;&#26032; Abstract: &#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#30340;&#39044;&#27979;&#27169;&#22411;&#24050;&#32463;&#20174;&#20174;&#22836;&#35757;&#32451;&#27169;&#22411;&#21457;&#23637;&#21040;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#12290;&#36825;&#31181;&#24494;&#35843;&#30340;&#26497;&#31471;&#24418;&#24335;&#28041;&#21450;&#21040;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#65292;&#20854;&#20013;&#19968;&#20010;&#39044;&#20808;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#36755;&#20986;&#65288;&#20923;&#32467;&#30340;&#35299;&#30721;&#22120;&#21442;&#25968;&#65289;&#21482;&#21463;&#21040;&#36755;&#20837;&#23383;&#31526;&#20018;&#30340;&#21464;&#21270;&#65288;&#31216;&#20026;&#25351;&#20196;&#25110;&#25552;&#31034;&#65289;&#30340;&#25511;&#21046;&#12290;ICL&#30340;&#19968;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#26159;&#22312;&#25552;&#31034;&#20013;&#20351;&#29992;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#23454;&#20363;&#20316;&#20026;&#31034;&#20363;&#12290;&#23613;&#31649;&#29616;&#26377;&#24037;&#20316;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20026;&#27599;&#20010;&#25968;&#25454;&#23454;&#20363;&#20351;&#29992;&#38745;&#24577;&#25968;&#37327;&#30340;&#31034;&#20363;&#65292;&#20294;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#35843;&#25972;&#31034;&#20363;&#25968;&#37327;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31867;&#20284;&#20110;k&#26368;&#36817;&#37051;&#65288;k-NN&#65289;&#20998;&#31867;&#22120;&#20013;&#20351;&#29992;&#21487;&#21464;&#22823;&#23567;&#37051;&#22495;&#30340;&#26041;&#27861;&#12290;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#33258;&#36866;&#24212;ICL&#65288;AICL&#65289;&#30340;&#24037;&#20316;&#27969;&#31243;&#20013;&#65292;&#23545;&#20110;&#29305;&#23450;&#25968;&#25454;&#23454;&#20363;&#36827;&#34892;&#25512;&#29702;&#26102;&#20351;&#29992;&#30340;&#28436;&#31034;&#25968;&#37327;&#26159;&#21160;&#24577;&#35843;&#25972;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06402v1 Announce Type: new  Abstract: Predictive models in natural language processing (NLP) have evolved from training models from scratch to fine-tuning pre-trained models with labelled data. An extreme form of this fine-tuning involves in-context learning (ICL), where the output of a pre-trained generative model (frozen decoder parameters) is controlled only with variations in the input strings (called instructions or prompts). An important component of ICL is the use of a small number of labelled data instances as examples in the prompt. While existing work uses a static number of examples during inference for each data instance, in this paper we propose a novel methodology of dynamically adapting the number of examples as per the data. This is analogous to the use of a variable-sized neighborhood in k-nearest neighbors (k-NN) classifier. In our proposed workflow of adaptive ICL (AICL), the number of demonstrations to employ during the inference on a particular data inst
&lt;/p&gt;</description></item><item><title>Yi&#27169;&#22411;&#31995;&#21015;&#22522;&#20110;&#24378;&#22823;&#30340;&#22810;&#32500;&#33021;&#21147;&#65292;&#36890;&#36807;&#22522;&#20110;6B&#21644;34B&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#25193;&#23637;&#65292;&#21253;&#25324;&#32842;&#22825;&#27169;&#22411;&#12289;&#38271;&#19978;&#19979;&#25991;&#27169;&#22411;&#12289;&#28145;&#24230;&#25918;&#22823;&#27169;&#22411;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65292;&#21462;&#24471;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.04652</link><description>&lt;p&gt;
Yi: &#30001; 01.AI &#25512;&#20986;&#30340;&#24320;&#25918;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Yi: Open Foundation Models by 01.AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04652
&lt;/p&gt;
&lt;p&gt;
Yi&#27169;&#22411;&#31995;&#21015;&#22522;&#20110;&#24378;&#22823;&#30340;&#22810;&#32500;&#33021;&#21147;&#65292;&#36890;&#36807;&#22522;&#20110;6B&#21644;34B&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#25193;&#23637;&#65292;&#21253;&#25324;&#32842;&#22825;&#27169;&#22411;&#12289;&#38271;&#19978;&#19979;&#25991;&#27169;&#22411;&#12289;&#28145;&#24230;&#25918;&#22823;&#27169;&#22411;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65292;&#21462;&#24471;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;Yi&#27169;&#22411;&#31995;&#21015;&#65292;&#36825;&#26159;&#19968;&#31995;&#21015;&#20855;&#26377;&#24378;&#22823;&#22810;&#32500;&#33021;&#21147;&#30340;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#27169;&#22411;&#12290;Yi&#27169;&#22411;&#31995;&#21015;&#22522;&#20110;6B&#21644;34B&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#28982;&#21518;&#25105;&#20204;&#23558;&#23427;&#20204;&#25193;&#23637;&#20026;&#32842;&#22825;&#27169;&#22411;&#12289;200K&#38271;&#19978;&#19979;&#25991;&#27169;&#22411;&#12289;&#28145;&#24230;&#25918;&#22823;&#27169;&#22411;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#22522;&#30784;&#27169;&#22411;&#22312;&#35832;&#22914;MMLU&#20043;&#31867;&#30340;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;&#25105;&#20204;&#24494;&#35843;&#36807;&#30340;&#32842;&#22825;&#27169;&#22411;&#22312;AlpacaEval&#21644;Chatbot Arena&#31561;&#20027;&#35201;&#35780;&#20272;&#24179;&#21488;&#19978;&#20855;&#26377;&#36739;&#39640;&#30340;&#20154;&#31867;&#20559;&#22909;&#29575;&#12290;&#36890;&#36807;&#20381;&#36182;&#20110;&#25105;&#20204;&#30340;&#21487;&#25193;&#23637;&#36229;&#32423;&#35745;&#31639;&#22522;&#30784;&#35774;&#26045;&#21644;&#32463;&#20856;&#30340;Transformer&#26550;&#26500;&#65292;&#25105;&#20204;&#35748;&#20026;Yi&#27169;&#22411;&#30340;&#24615;&#33021;&#20027;&#35201;&#24402;&#22240;&#20110;&#20854;&#25968;&#25454;&#36136;&#37327;&#65292;&#36825;&#26159;&#30001;&#25105;&#20204;&#30340;&#25968;&#25454;&#24037;&#31243;&#24037;&#20316;&#25152;&#24102;&#26469;&#30340;&#12290;&#23545;&#20110;&#39044;&#35757;&#32451;&#65292;&#25105;&#20204;&#20351;&#29992;&#32423;&#32852;&#30340;&#25968;&#25454;&#21435;&#37325;&#21644;&#36136;&#37327;&#36807;&#28388;&#27969;&#27700;&#32447;&#26500;&#24314;&#20102;3100&#20159;&#20010;&#33521;&#25991;&#21644;&#20013;&#25991;&#35821;&#26009;&#24211;&#30340;&#26631;&#35760;&#12290;&#23545;&#20110;&#24494;&#35843;&#65292;&#25105;&#20204;&#23545;&#23567;&#35268;&#27169;&#27169;&#22411;&#36827;&#34892;&#20102;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04652v1 Announce Type: cross  Abstract: We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities. The Yi model family is based on 6B and 34B pretrained language models, then we extend them to chat models, 200K long context models, depth-upscaled models, and vision-language models. Our base models achieve strong performance on a wide range of benchmarks like MMLU, and our finetuned chat models deliver strong human preference rate on major evaluation platforms like AlpacaEval and Chatbot Arena. Building upon our scalable super-computing infrastructure and the classical transformer architecture, we attribute the performance of Yi models primarily to its data quality resulting from our data-engineering efforts. For pretraining, we construct 3.1 trillion tokens of English and Chinese corpora using a cascaded data deduplication and quality filtering pipeline. For finetuning, we polish a small scale (less th
&lt;/p&gt;</description></item><item><title>GenAudit&#26159;&#19968;&#20010;&#24037;&#20855;&#65292;&#36890;&#36807;&#20462;&#35746;&#25110;&#21024;&#38500;&#26410;&#34987;&#21442;&#32771;&#25991;&#29486;&#25903;&#25345;&#30340;&#22768;&#26126;&#65292;&#24182;&#25552;&#20379;&#26469;&#33258;&#21442;&#32771;&#25991;&#29486;&#30340;&#35777;&#25454;&#65292;&#24110;&#21161;&#20462;&#22797;&#35821;&#35328;&#27169;&#22411;&#36755;&#20986;&#20013;&#30340;&#20107;&#23454;&#38169;&#35823;&#12290;</title><link>https://arxiv.org/abs/2402.12566</link><description>&lt;p&gt;
GenAudit&#65306;&#21033;&#29992;&#35777;&#25454;&#20462;&#22797;&#35821;&#35328;&#27169;&#22411;&#36755;&#20986;&#20013;&#30340;&#20107;&#23454;&#38169;&#35823;
&lt;/p&gt;
&lt;p&gt;
GenAudit: Fixing Factual Errors in Language Model Outputs with Evidence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12566
&lt;/p&gt;
&lt;p&gt;
GenAudit&#26159;&#19968;&#20010;&#24037;&#20855;&#65292;&#36890;&#36807;&#20462;&#35746;&#25110;&#21024;&#38500;&#26410;&#34987;&#21442;&#32771;&#25991;&#29486;&#25903;&#25345;&#30340;&#22768;&#26126;&#65292;&#24182;&#25552;&#20379;&#26469;&#33258;&#21442;&#32771;&#25991;&#29486;&#30340;&#35777;&#25454;&#65292;&#24110;&#21161;&#20462;&#22797;&#35821;&#35328;&#27169;&#22411;&#36755;&#20986;&#20013;&#30340;&#20107;&#23454;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#21363;&#20351;&#21487;&#20197;&#35775;&#38382;&#21442;&#32771;&#25991;&#26723;&#65292;&#20063;&#21487;&#33021;&#29983;&#25104;&#20107;&#23454;&#19981;&#20934;&#30830;&#30340;&#38472;&#36848;&#12290;&#22312;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#65288;&#20363;&#22914;&#22522;&#20110;&#25991;&#26723;&#30340;&#21307;&#30103;&#20445;&#20581;&#25110;&#37329;&#34701;&#38382;&#31572;&#65289;&#65292;&#36825;&#26679;&#30340;&#38169;&#35823;&#21487;&#33021;&#20855;&#26377;&#21361;&#38505;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GenAudit -- &#19968;&#20010;&#26088;&#22312;&#24110;&#21161;&#26816;&#26597;&#22522;&#20110;&#25991;&#26723;&#20219;&#21153;&#35821;&#35328;&#27169;&#22411;&#21709;&#24212;&#30340;&#24037;&#20855;&#12290;GenAudit&#36890;&#36807;&#20462;&#35746;&#25110;&#21024;&#38500;&#26410;&#34987;&#21442;&#32771;&#25991;&#26723;&#25903;&#25345;&#30340;&#22768;&#26126;&#65292;&#21516;&#26102;&#20026;&#30475;&#20284;&#34987;&#35777;&#25454;&#25903;&#25345;&#30340;&#20107;&#23454;&#25552;&#20379;&#26469;&#33258;&#21442;&#32771;&#25991;&#29486;&#30340;&#35777;&#25454;&#65292;&#26469;&#24314;&#35758;&#20462;&#25913;LLM&#21709;&#24212;&#12290;&#25105;&#20204;&#35757;&#32451;&#27169;&#22411;&#26469;&#25191;&#34892;&#36825;&#20123;&#20219;&#21153;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#20132;&#20114;&#30028;&#38754;&#65292;&#21521;&#29992;&#25143;&#21576;&#29616;&#24314;&#35758;&#30340;&#20462;&#25913;&#21644;&#35777;&#25454;&#12290;&#36890;&#36807;&#20154;&#24037;&#35780;&#20998;&#21592;&#30340;&#20840;&#38754;&#35780;&#20272;&#26174;&#31034;&#65292;GenAudit&#22312;&#24635;&#32467;&#19981;&#21516;&#39046;&#22495;&#25991;&#26723;&#26102;&#33021;&#22815;&#26816;&#27979;&#20986;8&#31181;&#19981;&#21516;&#30340;LLM&#36755;&#20986;&#20013;&#30340;&#38169;&#35823;&#12290;&#20026;&#30830;&#20445;&#31995;&#32479;&#33021;&#22815;&#26631;&#35760;&#22823;&#22810;&#25968;&#38169;&#35823;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#39640;&#38169;&#35823;&#21484;&#22238;&#29575;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#23545;&#39044;&#22788;&#29702;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12566v1 Announce Type: new  Abstract: LLMs can generate factually incorrect statements even when provided access to reference documents. Such errors can be dangerous in high-stakes applications (e.g., document-grounded QA for healthcare or finance). We present GenAudit -- a tool intended to assist fact-checking LLM responses for document-grounded tasks. GenAudit suggests edits to the LLM response by revising or removing claims that are not supported by the reference document, and also presents evidence from the reference for facts that do appear to have support. We train models to execute these tasks, and design an interactive interface to present suggested edits and evidence to users. Comprehensive evaluation by human raters shows that GenAudit can detect errors in 8 different LLM outputs when summarizing documents from diverse domains. To ensure that most errors are flagged by the system, we propose a method that can increase the error recall while minimizing impact on pre
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#20219;&#21153;&#20998;&#35299;&#21644;&#20195;&#29702;&#29983;&#25104;&#30340;&#22810;&#20195;&#29702;&#26694;&#26550;(TDAG)&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#22312;&#35299;&#20915;&#22797;&#26434;&#30340;&#23454;&#38469;&#38382;&#39064;&#26102;&#25552;&#39640;&#20195;&#29702;&#30340;&#36866;&#24212;&#24615;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;ItineraryBench&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;&#26053;&#34892;&#35268;&#21010;&#20013;&#20855;&#26377;&#31934;&#32454;&#35780;&#20272;&#31995;&#32479;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>https://arxiv.org/abs/2402.10178</link><description>&lt;p&gt;
TDAG:&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#20219;&#21153;&#20998;&#35299;&#21644;&#20195;&#29702;&#29983;&#25104;&#30340;&#22810;&#20195;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
TDAG: A Multi-Agent Framework based on Dynamic Task Decomposition and Agent Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10178
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#20219;&#21153;&#20998;&#35299;&#21644;&#20195;&#29702;&#29983;&#25104;&#30340;&#22810;&#20195;&#29702;&#26694;&#26550;(TDAG)&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#22312;&#35299;&#20915;&#22797;&#26434;&#30340;&#23454;&#38469;&#38382;&#39064;&#26102;&#25552;&#39640;&#20195;&#29702;&#30340;&#36866;&#24212;&#24615;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;ItineraryBench&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;&#26053;&#34892;&#35268;&#21010;&#20013;&#20855;&#26377;&#31934;&#32454;&#35780;&#20272;&#31995;&#32479;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs)&#22914;ChatGPT&#30340;&#20986;&#29616;&#65292;&#21551;&#21457;&#20102;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#30340;&#24320;&#21457;&#65292;&#33021;&#22815;&#35299;&#20915;&#22797;&#26434;&#30340;&#23454;&#38469;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20195;&#29702;&#22312;&#25191;&#34892;&#20219;&#21153;&#26102;&#24120;&#24120;&#30001;&#20110;&#26041;&#27861;&#35770;&#32422;&#26463;&#65288;&#22914;&#38169;&#35823;&#20256;&#25773;&#21644;&#36866;&#24212;&#24615;&#21463;&#38480;&#65289;&#32780;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#20219;&#21153;&#20998;&#35299;&#21644;&#20195;&#29702;&#29983;&#25104;&#30340;&#22810;&#20195;&#29702;&#26694;&#26550;(TDAG)&#12290;&#35813;&#26694;&#26550;&#21160;&#24577;&#22320;&#23558;&#22797;&#26434;&#20219;&#21153;&#20998;&#35299;&#20026;&#26356;&#23567;&#30340;&#23376;&#20219;&#21153;&#65292;&#24182;&#23558;&#27599;&#20010;&#23376;&#20219;&#21153;&#20998;&#37197;&#32473;&#19968;&#20010;&#29305;&#21035;&#29983;&#25104;&#30340;&#23376;&#20195;&#29702;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22312;&#22810;&#26679;&#21270;&#21644;&#19981;&#21487;&#39044;&#27979;&#30340;&#23454;&#38469;&#20219;&#21153;&#20013;&#30340;&#36866;&#24212;&#24615;&#12290;&#21516;&#26102;&#65292;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#24448;&#24448;&#32570;&#20047;&#35780;&#20272;&#22797;&#26434;&#12289;&#22810;&#27493;&#39588;&#20219;&#21153;&#20013;&#36882;&#22686;&#36827;&#23637;&#25152;&#38656;&#30340;&#32454;&#31890;&#24230;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#26053;&#34892;&#35268;&#21010;&#30340;&#32972;&#26223;&#19979;&#24341;&#20837;&#20102;ItineraryBench&#65292;&#23427;&#20855;&#26377;&#20114;&#36830;&#12289;&#36880;&#28176;&#22797;&#26434;&#30340;&#20219;&#21153;&#21644;&#32454;&#31890;&#24230;&#30340;&#35780;&#20272;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10178v1 Announce Type: new  Abstract: The emergence of Large Language Models (LLMs) like ChatGPT has inspired the development of LLM-based agents capable of addressing complex, real-world tasks. However, these agents often struggle during task execution due to methodological constraints, such as error propagation and limited adaptability. To address this issue, we propose a multi-agent framework based on dynamic Task Decomposition and Agent Generation (TDAG). This framework dynamically decomposes complex tasks into smaller subtasks and assigns each to a specifically generated subagent, thereby enhancing adaptability in diverse and unpredictable real-world tasks. Simultaneously, existing benchmarks often lack the granularity needed to evaluate incremental progress in complex, multi-step tasks. In response, we introduce ItineraryBench in the context of travel planning, featuring interconnected, progressively complex tasks with a fine-grained evaluation system. ItineraryBench i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#25968;&#36824;&#26159;&#23569;&#25968;&#65288;MoM&#65289;&#23398;&#20064;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#23398;&#20064;&#26041;&#27861;&#65292;&#38024;&#23545;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#20013;&#30340;&#22810;&#25968;&#31867;&#21035;&#21644;&#23569;&#25968;&#31867;&#21035;&#20043;&#38388;&#30340;&#25361;&#25112;&#65292;&#33021;&#22815;&#25552;&#39640;&#23569;&#25968;&#31867;&#21035;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#19981;&#24433;&#21709;&#22810;&#25968;&#31867;&#21035;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.11431</link><description>&lt;p&gt;
&#22810;&#25968;&#36824;&#26159;&#23569;&#25968;&#65306;&#29992;&#20110;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Majority or Minority: Data Imbalance Learning Method for Named Entity Recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.11431
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#25968;&#36824;&#26159;&#23569;&#25968;&#65288;MoM&#65289;&#23398;&#20064;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#23398;&#20064;&#26041;&#27861;&#65292;&#38024;&#23545;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#20013;&#30340;&#22810;&#25968;&#31867;&#21035;&#21644;&#23569;&#25968;&#31867;&#21035;&#20043;&#38388;&#30340;&#25361;&#25112;&#65292;&#33021;&#22815;&#25552;&#39640;&#23569;&#25968;&#31867;&#21035;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#19981;&#24433;&#21709;&#22810;&#25968;&#31867;&#21035;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#19981;&#24179;&#34913;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20219;&#21153;&#20013;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#20219;&#21153;&#12290;NER&#34920;&#29616;&#20986;&#19968;&#31181;&#38271;&#23614;&#20998;&#24067;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#65292;&#20854;&#20013;&#26377;&#35768;&#22810;&#23569;&#25968;&#31867;&#21035;&#65288;&#21363;&#23454;&#20307;&#31867;&#21035;&#65289;&#21644;&#19968;&#20010;&#21333;&#19968;&#30340;&#22810;&#25968;&#31867;&#21035;&#65288;&#21363;O&#31867;&#21035;&#65289;&#12290;&#36825;&#31181;&#19981;&#24179;&#34913;&#23548;&#33268;&#23558;&#23454;&#20307;&#31867;&#21035;&#35823;&#20998;&#31867;&#20026;O&#31867;&#21035;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#26377;&#25928;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#21629;&#21517;&#20026;&#22810;&#25968;&#36824;&#26159;&#23569;&#25968;&#65288;MoM&#65289;&#23398;&#20064;&#12290;MoM&#23398;&#20064;&#23558;&#21482;&#26377;&#22320;&#38754;&#20107;&#23454;&#20026;&#22810;&#25968;&#31867;&#21035;&#30340;&#26679;&#26412;&#25152;&#35745;&#31639;&#30340;&#25439;&#22833;&#34701;&#20837;&#21040;&#20256;&#32479;ML&#27169;&#22411;&#30340;&#25439;&#22833;&#20013;&#12290;&#23545;&#22235;&#20010;NER&#25968;&#25454;&#38598;&#65288;&#26085;&#35821;&#21644;&#33521;&#35821;&#65289;&#30340;&#35780;&#20272;&#23454;&#39564;&#34920;&#26126;&#65292;MoM&#23398;&#20064;&#25552;&#39640;&#20102;&#23569;&#25968;&#31867;&#21035;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#19981;&#29306;&#29298;&#22810;&#25968;&#31867;&#21035;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#27604;&#24191;&#20026;&#20154;&#30693;&#30340;&#26368;&#26032;&#25216;&#26415;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.11431v2 Announce Type: replace  Abstract: Data imbalance presents a significant challenge in various machine learning (ML) tasks, particularly named entity recognition (NER) within natural language processing (NLP). NER exhibits a data imbalance with a long-tail distribution, featuring numerous minority classes (i.e., entity classes) and a single majority class (i.e., O-class). This imbalance leads to misclassifications of the entity classes as the O-class. To tackle this issue, we propose a simple and effective learning method named majority or minority (MoM) learning. MoM learning incorporates the loss computed only for samples whose ground truth is the majority class into the loss of the conventional ML model. Evaluation experiments on four NER datasets (Japanese and English) showed that MoM learning improves prediction performance of the minority classes without sacrificing the performance of the majority class and is more effective than widely known and state-of-the-art
&lt;/p&gt;</description></item><item><title>AutoMix&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#36873;&#25321;&#26356;&#22823;&#35821;&#35328;&#27169;&#22411;&#22788;&#29702;&#26597;&#35810;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23569;&#37327;&#26679;&#26412;&#33258;&#25105;&#39564;&#35777;&#21644;&#20803;&#39564;&#35777;&#22120;&#25552;&#39640;&#20102;&#36755;&#20986;&#30340;&#21487;&#38752;&#24615;&#65292;&#21487;&#26174;&#33879;&#25552;&#39640;&#35745;&#31639;&#25104;&#26412;&#21644;&#24615;&#33021;&#30340;&#20248;&#21270;&#65292;&#23454;&#39564;&#35777;&#26126;&#24615;&#33021;&#20248;&#20110;&#22522;&#32447;&#26368;&#22810;86%.</title><link>https://arxiv.org/abs/2310.12963</link><description>&lt;p&gt;
AutoMix: &#33258;&#21160;&#28151;&#21512;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
AutoMix: Automatically Mixing Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.12963
&lt;/p&gt;
&lt;p&gt;
AutoMix&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#36873;&#25321;&#26356;&#22823;&#35821;&#35328;&#27169;&#22411;&#22788;&#29702;&#26597;&#35810;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23569;&#37327;&#26679;&#26412;&#33258;&#25105;&#39564;&#35777;&#21644;&#20803;&#39564;&#35777;&#22120;&#25552;&#39640;&#20102;&#36755;&#20986;&#30340;&#21487;&#38752;&#24615;&#65292;&#21487;&#26174;&#33879;&#25552;&#39640;&#35745;&#31639;&#25104;&#26412;&#21644;&#24615;&#33021;&#30340;&#20248;&#21270;&#65292;&#23454;&#39564;&#35777;&#26126;&#24615;&#33021;&#20248;&#20110;&#22522;&#32447;&#26368;&#22810;86%.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#29616;&#22312;&#21487;&#20197;&#36890;&#36807;&#21508;&#31181;&#23610;&#23544;&#21644;&#37197;&#32622;&#30340;&#20113;API&#25552;&#20379;&#21830;&#33719;&#24471;&#12290;&#34429;&#28982;&#36825;&#31181;&#22810;&#26679;&#24615;&#25552;&#20379;&#20102;&#24191;&#27867;&#30340;&#36873;&#25321;&#65292;&#20294;&#26377;&#25928;&#21033;&#29992;&#36825;&#20123;&#36873;&#39033;&#20197;&#20248;&#21270;&#35745;&#31639;&#25104;&#26412;&#21644;&#24615;&#33021;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AutoMix&#65292;&#19968;&#31181;&#26681;&#25454;&#36739;&#23567;LM&#30340;&#36755;&#20986;&#30340;&#36817;&#20284;&#27491;&#30830;&#24615;&#26469;&#31574;&#30053;&#24615;&#22320;&#23558;&#26597;&#35810;&#36335;&#30001;&#21040;&#26356;&#22823;LM&#30340;&#26041;&#27861;&#12290;AutoMix&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#23569;&#37327;&#26679;&#26412;&#30340;&#33258;&#25105;&#39564;&#35777;&#26426;&#21046;&#65292;&#23427;&#21487;&#20197;&#20272;&#35745;&#36755;&#20986;&#30340;&#21487;&#38752;&#24615;&#32780;&#26080;&#38656;&#35757;&#32451;&#12290;&#37492;&#20110;&#39564;&#35777;&#21487;&#33021;&#23384;&#22312;&#22122;&#22768;&#65292;&#25105;&#20204;&#22312;AutoMix&#20013;&#20351;&#29992;&#20102;&#20803;&#39564;&#35777;&#22120;&#26469;&#25552;&#39640;&#36825;&#20123;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#22312;&#20116;&#20010;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#25512;&#29702;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;LLAMA2-13B&#21644;GPT-4&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;AutoMix&#36229;&#36234;&#20102;&#24050;&#24314;&#31435;&#30340;&#22522;&#32447;&#65292;&#27599;&#21333;&#20301;&#25104;&#26412;&#30340;&#22686;&#37327;&#25928;&#30410;&#25552;&#39640;&#20102;&#26368;&#22810;86%&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#21487;&#22312;https://github.c&#25214;&#21040;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.12963v3 Announce Type: replace  Abstract: Large language models (LLMs) are now available from cloud API providers in various sizes and configurations. While this diversity offers a broad spectrum of choices, effectively leveraging the options to optimize computational cost and performance remains challenging. In this work, we present AutoMix, an approach that strategically routes queries to larger LMs, based on the approximate correctness of outputs from a smaller LM. Central to AutoMix is a few-shot self-verification mechanism, which estimates the reliability of its own outputs without requiring training. Given that verifications can be noisy, we employ a meta-verifier in AutoMix to refine the accuracy of these assessments. Our experiments using LLAMA2-13B and GPT-4, on five context-grounded reasoning datasets demonstrate that AutoMix surpasses established baselines, improving the incremental benefit per cost by up to 86%. Our code and data are available at https://github.c
&lt;/p&gt;</description></item><item><title>LegalDuet&#26159;&#19968;&#31181;&#36890;&#36807;&#21452;&#35270;&#35282;&#27861;&#24459;&#32447;&#32034;&#25512;&#29702;&#27169;&#22411;&#65292;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#23450;&#21046;&#23884;&#20837;&#31354;&#38388;&#26469;&#36827;&#34892;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#27861;&#24459;&#26696;&#20363;&#25512;&#29702;&#21644;&#27861;&#24459;&#22522;&#30784;&#25512;&#29702;&#20004;&#20010;&#25512;&#29702;&#38142;&#36827;&#34892;&#21028;&#20915;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;LegalDuet&#22312;CAIL2018&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#36229;&#36807;&#20102;&#22522;&#32447;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2401.15371</link><description>&lt;p&gt;
LegalDuet: &#36890;&#36807;&#21452;&#35270;&#35282;&#27861;&#24459;&#32447;&#32034;&#25512;&#29702;&#23398;&#20064;&#26377;&#25928;&#30340;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
LegalDuet: Learning Effective Representations for Legal Judgment Prediction through a Dual-View Legal Clue Reasoning. (arXiv:2401.15371v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15371
&lt;/p&gt;
&lt;p&gt;
LegalDuet&#26159;&#19968;&#31181;&#36890;&#36807;&#21452;&#35270;&#35282;&#27861;&#24459;&#32447;&#32034;&#25512;&#29702;&#27169;&#22411;&#65292;&#20351;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#23450;&#21046;&#23884;&#20837;&#31354;&#38388;&#26469;&#36827;&#34892;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#27861;&#24459;&#26696;&#20363;&#25512;&#29702;&#21644;&#27861;&#24459;&#22522;&#30784;&#25512;&#29702;&#20004;&#20010;&#25512;&#29702;&#38142;&#36827;&#34892;&#21028;&#20915;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;LegalDuet&#22312;CAIL2018&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#36229;&#36807;&#20102;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#27861;&#24459;&#21028;&#20915;&#39044;&#27979;&#65288;LJP&#65289;&#27169;&#22411;&#20391;&#37325;&#20110;&#21457;&#29616;&#21009;&#20107;&#20107;&#23454;&#25551;&#36848;&#20013;&#30340;&#27861;&#24459;&#32447;&#32034;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#19987;&#19994;&#27861;&#23448;&#19981;&#20165;&#38656;&#35201;&#21560;&#25910;&#36807;&#21435;&#21028;&#20915;&#30340;&#27861;&#24459;&#26696;&#20363;&#32463;&#39564;&#65292;&#36824;&#20381;&#36182;&#20110;&#20174;&#19987;&#19994;&#27861;&#24459;&#30693;&#35782;&#20013;&#23398;&#21040;&#30340;&#19987;&#19994;&#27861;&#24459;&#22522;&#30784;&#25512;&#29702;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LegalDuet&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20197;&#23398;&#20064;&#29992;&#20110;&#36827;&#34892;&#27861;&#24459;&#21028;&#20915;&#30340;&#23450;&#21046;&#23884;&#20837;&#31354;&#38388;&#12290;&#23427;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#35270;&#35282;&#27861;&#24459;&#32447;&#32034;&#25512;&#29702;&#26426;&#21046;&#65292;&#30001;&#20004;&#20010;&#25512;&#29702;&#38142;&#32452;&#25104;&#65306;1&#65289;&#27861;&#24459;&#26696;&#20363;&#25512;&#29702;&#65292;&#26681;&#25454;&#20174;&#31867;&#27604;/&#28151;&#28102;&#30340;&#27861;&#24459;&#26696;&#20363;&#20013;&#23398;&#21040;&#30340;&#21028;&#20915;&#32463;&#39564;&#36827;&#34892;&#27861;&#24459;&#21028;&#20915;&#65307;2&#65289;&#27861;&#24459;&#22522;&#30784;&#25512;&#29702;&#65292;&#36890;&#36807;&#21305;&#37197;&#21009;&#20107;&#26696;&#20214;&#21644;&#27861;&#24459;&#20915;&#23450;&#20043;&#38388;&#30340;&#27861;&#24459;&#32447;&#32034;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LegalDuet&#22312;CAIL2018&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#36229;&#36807;&#20102;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most existing Legal Judgment Prediction (LJP) models focus on discovering the legal triggers in the criminal fact description. However, in real-world scenarios, a professional judge not only needs to assimilate the law case experience that thrives on past sentenced legal judgments but also depends on the professional legal grounded reasoning that learned from professional legal knowledge. In this paper, we propose a LegalDuet model, which pretrains language models to learn a tailored embedding space for making legal judgments. It proposes a dual-view legal clue reasoning mechanism, which derives from two reasoning chains of judges: 1) Law Case Reasoning, which makes legal judgments according to the judgment experiences learned from analogy/confusing legal cases; 2) Legal Ground Reasoning, which lies in matching the legal clues between criminal cases and legal decisions. Our experiments show that LegalDuet achieves state-of-the-art performance on the CAIL2018 dataset and outperforms bas
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#20449;&#39640;&#25928;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#36731;&#37327;&#32423;&#30340;LoRA&#27169;&#22359;&#36827;&#34892;&#23458;&#25143;&#31471;&#35843;&#25972;&#21644;&#19982;&#26381;&#21153;&#22120;&#30340;&#20132;&#20114;&#65292;&#20197;&#26368;&#23567;&#21270;&#36890;&#20449;&#24320;&#38144;&#65292;&#20197;&#21450;&#20351;&#29992;K&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#20840;&#23616;&#27169;&#22411;&#26469;&#23454;&#29616;&#20010;&#24615;&#21270;&#24182;&#20811;&#26381;&#25968;&#25454;&#24322;&#26500;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.10070</link><description>&lt;p&gt;
&#36890;&#20449;&#39640;&#25928;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#22312;&#35821;&#38899;&#36716;&#25991;&#26412;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Personalized Federated Learning for Speech-to-Text Tasks. (arXiv:2401.10070v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10070
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#20449;&#39640;&#25928;&#30340;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#36731;&#37327;&#32423;&#30340;LoRA&#27169;&#22359;&#36827;&#34892;&#23458;&#25143;&#31471;&#35843;&#25972;&#21644;&#19982;&#26381;&#21153;&#22120;&#30340;&#20132;&#20114;&#65292;&#20197;&#26368;&#23567;&#21270;&#36890;&#20449;&#24320;&#38144;&#65292;&#20197;&#21450;&#20351;&#29992;K&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#20840;&#23616;&#27169;&#22411;&#26469;&#23454;&#29616;&#20010;&#24615;&#21270;&#24182;&#20811;&#26381;&#25968;&#25454;&#24322;&#26500;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20445;&#25252;&#38544;&#31169;&#24182;&#28385;&#36275;&#27861;&#35268;&#35201;&#27714;&#65292;&#32852;&#37030;&#23398;&#20064;&#22312;&#35757;&#32451;&#35821;&#38899;&#36716;&#25991;&#26412;&#31995;&#32479;&#65288;&#21253;&#25324;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#21644;&#35821;&#38899;&#32763;&#35793;&#65289;&#26041;&#38754;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#35821;&#38899;&#36716;&#25991;&#26412;&#20219;&#21153;&#20013;&#24120;&#29992;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65288;&#21363;FedAvg&#65289;&#36890;&#24120;&#38754;&#20020;&#30528;&#22823;&#37327;&#30340;&#36890;&#20449;&#24320;&#38144;&#21644;&#25968;&#25454;&#24322;&#26500;&#23548;&#33268;&#30340;&#24615;&#33021;&#19979;&#38477;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20010;&#24615;&#21270;&#30340;&#32852;&#37030;&#35821;&#38899;&#36716;&#25991;&#26412;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;&#36731;&#37327;&#32423;&#30340;LoRA&#27169;&#22359;&#65288;FedLoRA&#65289;&#29992;&#20110;&#23458;&#25143;&#31471;&#35843;&#25972;&#21644;&#19982;&#26381;&#21153;&#22120;&#36827;&#34892;&#20132;&#20114;&#20197;&#26368;&#23567;&#21270;&#36890;&#20449;&#24320;&#38144;&#65292;&#20197;&#21450;&#20840;&#23616;&#27169;&#22411;&#65288;FedMem&#65289;&#37197;&#22791;&#20102;K&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#65292;&#20197;&#25429;&#25417;&#23458;&#25143;&#29305;&#23450;&#30340;&#20998;&#24067;&#21464;&#21270;&#20197;&#23454;&#29616;&#20010;&#24615;&#21270;&#24182;&#20811;&#26381;&#25968;&#25454;&#24322;&#26500;&#12290;&#22312;CoVoST&#21644;GigaSp&#25968;&#25454;&#38598;&#19978;&#22522;&#20110;Conformer&#21644;Whisper&#20027;&#24178;&#27169;&#22411;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
To protect privacy and meet legal regulations, federated learning (FL) has gained significant attention for training speech-to-text (S2T) systems, including automatic speech recognition (ASR) and speech translation (ST). However, the commonly used FL approach (i.e., \textsc{FedAvg}) in S2T tasks typically suffers from extensive communication overhead due to multi-round interactions based on the whole model and performance degradation caused by data heterogeneity among clients.To address these issues, we propose a personalized federated S2T framework that introduces \textsc{FedLoRA}, a lightweight LoRA module for client-side tuning and interaction with the server to minimize communication overhead, and \textsc{FedMem}, a global model equipped with a $k$-nearest-neighbor ($k$NN) classifier that captures client-specific distributional shifts to achieve personalization and overcome data heterogeneity. Extensive experiments based on Conformer and Whisper backbone models on CoVoST and GigaSp
&lt;/p&gt;</description></item><item><title>&#22235;&#27493;&#25512;&#29702;&#65288;QLFR&#65289;&#26694;&#26550;&#26159;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#21477;&#27861;&#21644;&#35821;&#20041;&#20016;&#23500;&#30340;CoT&#26469;&#25552;&#21319;&#30701;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.03158</link><description>&lt;p&gt;
&#22235;&#27493;&#25512;&#29702;&#65288;QLFR&#65289;&#26694;&#26550;&#65306;&#25512;&#36827;&#30701;&#25991;&#26412;&#20998;&#31867;&#30340;&#22235;&#27493;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification. (arXiv:2401.03158v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03158
&lt;/p&gt;
&lt;p&gt;
&#22235;&#27493;&#25512;&#29702;&#65288;QLFR&#65289;&#26694;&#26550;&#26159;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#21477;&#27861;&#21644;&#35821;&#20041;&#20016;&#23500;&#30340;CoT&#26469;&#25552;&#21319;&#30701;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#25991;&#26412;&#20998;&#31867;&#65288;STC&#65289;&#23545;&#20110;&#22788;&#29702;&#21644;&#29702;&#35299;&#24403;&#20195;&#25968;&#23383;&#24179;&#21488;&#19978;&#27969;&#34892;&#30340;&#31616;&#27905;&#32780;&#37325;&#35201;&#30340;&#20869;&#23481;&#33267;&#20851;&#37325;&#35201;&#12290;STC&#22312;&#25235;&#20303;&#35821;&#20041;&#21644;&#21477;&#27861;&#22797;&#26434;&#24615;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#65292;&#36825;&#20010;&#38382;&#39064;&#22312;&#20256;&#32479;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#24456;&#26126;&#26174;&#12290;&#23613;&#31649;&#22270;&#21367;&#31215;&#32593;&#32476;&#36890;&#36807;&#25972;&#21512;&#22806;&#37096;&#30693;&#35782;&#24211;&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#21463;&#21040;&#24212;&#29992;&#30693;&#35782;&#36136;&#37327;&#21644;&#33539;&#22260;&#30340;&#38480;&#21046;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#30340;&#20986;&#29616;&#26174;&#33879;&#25552;&#39640;&#20102;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#30740;&#31350;&#25351;&#20986;&#20102;&#23427;&#20204;&#22312;&#22522;&#30784;NLP&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#26088;&#22312;&#36816;&#29992;CoT&#26469;&#30740;&#31350;LLMs&#22312;STC&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#22235;&#27493;&#25512;&#29702;&#65288;QLFR&#65289;&#26694;&#26550;&#12290;&#36825;&#20010;&#26694;&#26550;&#20027;&#35201;&#21253;&#25324;&#21477;&#27861;&#21644;&#35821;&#20041;&#20016;&#23500;&#30340;CoT&#65292;&#26377;&#25928;&#21033;&#29992;&#20102;LLMs&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Short Text Classification (STC) is crucial for processing and comprehending the brief but substantial content prevalent on contemporary digital platforms. The STC encounters difficulties in grasping semantic and syntactic intricacies, an issue that is apparent in traditional pre-trained language models. Although Graph Convolutional Networks enhance performance by integrating external knowledge bases, these methods are limited by the quality and extent of the knowledge applied. Recently, the emergence of Large Language Models (LLMs) and Chain-of-Thought (CoT) has significantly improved the performance of complex reasoning tasks. However, some studies have highlighted the limitations of their application in fundamental NLP tasks. Consequently, this study sought to employ CoT to investigate the capabilities of LLMs in STC tasks. This study introduces Quartet Logic: A Four-Step Reasoning (QLFR) framework. This framework primarily incorporates Syntactic and Semantic Enrichment CoT, effectiv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#30340;&#19968;&#33268;&#24615;&#23547;&#27714;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#27809;&#26377;&#26126;&#30830;&#25351;&#23548;&#30340;&#24773;&#20917;&#19979;&#65292;&#26234;&#33021;&#20307;&#20027;&#35201;&#20351;&#29992;&#24179;&#22343;&#31574;&#30053;&#36827;&#34892;&#19968;&#33268;&#24615;&#23547;&#27714;&#65292;&#21516;&#26102;&#36824;&#20998;&#26512;&#20102;&#26234;&#33021;&#20307;&#25968;&#37327;&#12289;&#26234;&#33021;&#20307;&#20010;&#24615;&#21644;&#32593;&#32476;&#25299;&#25169;&#23545;&#21327;&#21830;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.20151</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#19968;&#33268;&#24615;&#23547;&#27714;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Consensus Seeking via Large Language Models. (arXiv:2310.20151v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#30340;&#19968;&#33268;&#24615;&#23547;&#27714;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#27809;&#26377;&#26126;&#30830;&#25351;&#23548;&#30340;&#24773;&#20917;&#19979;&#65292;&#26234;&#33021;&#20307;&#20027;&#35201;&#20351;&#29992;&#24179;&#22343;&#31574;&#30053;&#36827;&#34892;&#19968;&#33268;&#24615;&#23547;&#27714;&#65292;&#21516;&#26102;&#36824;&#20998;&#26512;&#20102;&#26234;&#33021;&#20307;&#25968;&#37327;&#12289;&#26234;&#33021;&#20307;&#20010;&#24615;&#21644;&#32593;&#32476;&#25299;&#25169;&#23545;&#21327;&#21830;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#39537;&#21160;&#30340;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#22312;&#21327;&#20316;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#26041;&#38754;&#23637;&#29616;&#20986;&#20102;&#20196;&#20154;&#26399;&#24453;&#30340;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;&#19968;&#33268;&#24615;&#23547;&#27714;&#12290;&#24403;&#22810;&#20010;&#26234;&#33021;&#20307;&#19968;&#36215;&#24037;&#20316;&#26102;&#65292;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#23427;&#20204;&#22914;&#20309;&#36890;&#36807;&#26234;&#33021;&#20307;&#38388;&#30340;&#21327;&#21830;&#36798;&#25104;&#19968;&#33268;&#12290;&#20026;&#27492;&#65292;&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#19968;&#20010;&#19968;&#33268;&#24615;&#23547;&#27714;&#20219;&#21153;&#65292;&#20854;&#20013;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#29366;&#24577;&#26159;&#19968;&#20010;&#25968;&#20540;&#65292;&#24182;&#19988;&#23427;&#20204;&#36890;&#36807;&#30456;&#20114;&#21327;&#21830;&#26469;&#36798;&#25104;&#19968;&#33268;&#20540;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#27809;&#26377;&#26126;&#30830;&#25351;&#23548;&#24212;&#37319;&#29992;&#21738;&#31181;&#31574;&#30053;&#26102;&#65292;LLM&#39537;&#21160;&#30340;&#26234;&#33021;&#20307;&#20027;&#35201;&#20351;&#29992;&#24179;&#22343;&#31574;&#30053;&#36827;&#34892;&#19968;&#33268;&#24615;&#23547;&#27714;&#65292;&#23613;&#31649;&#23427;&#20204;&#21487;&#33021;&#20598;&#23572;&#20250;&#20351;&#29992;&#20854;&#20182;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#20998;&#26512;&#20102;&#26234;&#33021;&#20307;&#25968;&#37327;&#12289;&#26234;&#33021;&#20307;&#20010;&#24615;&#21644;&#32593;&#32476;&#25299;&#25169;&#23545;&#21327;&#21830;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;&#26412;&#30740;&#31350;&#30340;&#21457;&#29616;&#26377;&#26395;&#20026;&#29702;&#35299;LLM&#39537;&#21160;&#30340;&#22810;&#26234;&#33021;&#20307;&#34892;&#20026;&#22880;&#23450;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-agent systems driven by large language models (LLMs) have shown promising abilities for solving complex tasks in a collaborative manner. This work considers a fundamental problem in multi-agent collaboration: consensus seeking. When multiple agents work together, we are interested in how they can reach a consensus through inter-agent negotiation. To that end, this work studies a consensus-seeking task where the state of each agent is a numerical value and they negotiate with each other to reach a consensus value. It is revealed that when not explicitly directed on which strategy should be adopted, the LLM-driven agents primarily use the average strategy for consensus seeking although they may occasionally use some other strategies. Moreover, this work analyzes the impact of the agent number, agent personality, and network topology on the negotiation process. The findings reported in this work can potentially lay the foundations for understanding the behaviors of LLM-driven multi-
&lt;/p&gt;</description></item><item><title>JsonTuning&#26159;&#19968;&#31181;&#38754;&#21521;&#36890;&#29992;&#12289;&#24378;&#22823;&#21644;&#21487;&#25511;&#30340;&#25351;&#20196;&#35843;&#20248;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;JSON&#30340;&#32467;&#26500;&#21270;&#29305;&#24615;&#65292;&#24110;&#21161;&#27169;&#22411;&#29702;&#35299;&#20219;&#21153;&#35201;&#32032;&#21450;&#20854;&#20851;&#31995;&#65292;&#20174;&#32780;&#25193;&#23637;&#20102;&#36890;&#29992;&#24615;&#12289;&#25552;&#39640;&#20102;&#31283;&#20581;&#24615;&#65292;&#24182;&#22686;&#24378;&#20102;&#23545;&#36755;&#20986;&#30340;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.02953</link><description>&lt;p&gt;
JsonTuning&#65306;&#38754;&#21521;&#36890;&#29992;&#12289;&#24378;&#22823;&#21644;&#21487;&#25511;&#30340;&#25351;&#20196;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning. (arXiv:2310.02953v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02953
&lt;/p&gt;
&lt;p&gt;
JsonTuning&#26159;&#19968;&#31181;&#38754;&#21521;&#36890;&#29992;&#12289;&#24378;&#22823;&#21644;&#21487;&#25511;&#30340;&#25351;&#20196;&#35843;&#20248;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;JSON&#30340;&#32467;&#26500;&#21270;&#29305;&#24615;&#65292;&#24110;&#21161;&#27169;&#22411;&#29702;&#35299;&#20219;&#21153;&#35201;&#32032;&#21450;&#20854;&#20851;&#31995;&#65292;&#20174;&#32780;&#25193;&#23637;&#20102;&#36890;&#29992;&#24615;&#12289;&#25552;&#39640;&#20102;&#31283;&#20581;&#24615;&#65292;&#24182;&#22686;&#24378;&#20102;&#23545;&#36755;&#20986;&#30340;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#20196;&#35843;&#20248;&#24050;&#25104;&#20026;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#33021;&#21147;&#30340;&#20851;&#38190;&#36807;&#31243;&#65292;&#36890;&#36807;&#25552;&#20379;&#26126;&#30830;&#30340;&#20219;&#21153;&#25351;&#20196;&#65292;&#20174;&#32780;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#25991;&#26412;-&#25991;&#26412;&#25351;&#20196;&#35843;&#20248;&#65288;TextTuning&#65289;&#26041;&#27861;&#30001;&#20110;&#20219;&#21153;&#30340;&#27169;&#31946;&#24615;&#21644;&#32570;&#20047;&#26126;&#30830;&#30340;&#32467;&#26500;&#32780;&#23384;&#22312;&#36890;&#29992;&#24615;&#12289;&#31283;&#20581;&#24615;&#21644;&#21487;&#25511;&#24615;&#30340;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;JsonTuning&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21040;&#32467;&#26500;&#30340;&#25351;&#20196;&#35843;&#20248;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;JSON&#30340;&#22810;&#21151;&#33021;&#21644;&#32467;&#26500;&#21270;&#29305;&#24615;&#26469;&#34920;&#31034;&#20219;&#21153;&#65292;JsonTuning&#36890;&#36807;&#24110;&#21161;&#27169;&#22411;&#29702;&#35299;&#20851;&#38190;&#20219;&#21153;&#35201;&#32032;&#21450;&#20854;&#20851;&#31995;&#65292;&#25193;&#23637;&#20102;&#36890;&#29992;&#24615;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#27495;&#20041;&#24615;&#25552;&#39640;&#20102;&#31283;&#20581;&#24615;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#23545;&#36755;&#20986;&#30340;&#26174;&#24335;&#25511;&#21046;&#22686;&#24378;&#20102;&#21487;&#25511;&#24615;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#30340;&#35821;&#35328;&#27169;&#22411;&#21644;&#35780;&#20272;&#22522;&#20934;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#27604;&#36739;&#30740;&#31350;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;JsonTuning&#22312;&#24615;&#33021;&#19978;&#20248;&#20110;TextTuning&#12290;
&lt;/p&gt;
&lt;p&gt;
Instruction tuning has emerged as a crucial process for harnessing the capabilities of large language models (LLMs) by providing explicit task instructions, leading to improved performance in various tasks. However, prevalent text-to-text instruction tuning (TextTuning) methods suffer from limitations in generalization, robustness, and controllability due to the ambiguity and lack of explicit structure in tasks. In this paper, we propose JsonTuning, a novel structure-to-structure approach for instruction tuning. By leveraging the versatility and structured nature of JSON to represent tasks, JsonTuning enhances generalization by helping the model understand essential task elements and their relations, improves robustness by minimizing ambiguity, and increases controllability by providing explicit control over the output. We conduct a comprehensive comparative study with diverse language models and evaluation benchmarks. Experimental results show that JsonTuning outperforms TextTuning in
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26234;&#33021;&#22810;&#20219;&#21153;&#36866;&#24212;&#28151;&#21512;&#25552;&#31034;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;LLM&#22312;&#22788;&#29702;&#24322;&#36136;&#20219;&#21153;&#21644;&#25968;&#25454;&#20998;&#24067;&#26102;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#35774;&#35745;&#20102;&#26234;&#33021;&#38376;&#25511;&#21151;&#33021;&#65292;&#29992;&#20110;&#35782;&#21035;&#23884;&#20837;&#22312;&#19981;&#21516;&#25552;&#31034;&#32452;&#20013;&#30340;&#30456;&#20851;&#25216;&#33021;&#65292;&#24182;&#26681;&#25454;&#30446;&#26631;&#20219;&#21153;&#30340;&#38656;&#27714;&#21160;&#24577;&#20998;&#37197;&#32452;&#21512;&#19987;&#23478;&#12290;&#35813;&#26041;&#27861;&#23545;&#20219;&#20309;&#27169;&#22411;&#21387;&#32553;&#25216;&#26415;&#37117;&#19981;&#21463;&#38480;&#21046;&#65292;&#25552;&#39640;&#20102;&#20219;&#21153;&#22788;&#29702;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.02842</link><description>&lt;p&gt;
&#29992;&#26234;&#33021;&#22810;&#20219;&#21153;&#36866;&#24212;&#28151;&#21512;&#25552;&#31034;&#25195;&#25551;&#24322;&#36136;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation. (arXiv:2310.02842v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26234;&#33021;&#22810;&#20219;&#21153;&#36866;&#24212;&#28151;&#21512;&#25552;&#31034;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;LLM&#22312;&#22788;&#29702;&#24322;&#36136;&#20219;&#21153;&#21644;&#25968;&#25454;&#20998;&#24067;&#26102;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#35774;&#35745;&#20102;&#26234;&#33021;&#38376;&#25511;&#21151;&#33021;&#65292;&#29992;&#20110;&#35782;&#21035;&#23884;&#20837;&#22312;&#19981;&#21516;&#25552;&#31034;&#32452;&#20013;&#30340;&#30456;&#20851;&#25216;&#33021;&#65292;&#24182;&#26681;&#25454;&#30446;&#26631;&#20219;&#21153;&#30340;&#38656;&#27714;&#21160;&#24577;&#20998;&#37197;&#32452;&#21512;&#19987;&#23478;&#12290;&#35813;&#26041;&#27861;&#23545;&#20219;&#20309;&#27169;&#22411;&#21387;&#32553;&#25216;&#26415;&#37117;&#19981;&#21463;&#38480;&#21046;&#65292;&#25552;&#39640;&#20102;&#20219;&#21153;&#22788;&#29702;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#26377;&#33021;&#21147;&#35299;&#20915;&#21508;&#31181;&#20219;&#21153;&#65292;&#22914;&#25991;&#26412;&#25688;&#35201;&#21644;&#25968;&#23398;&#38382;&#39064;&#65292;&#20294;&#36890;&#24120;&#26159;&#38024;&#23545;&#21333;&#19968;&#20219;&#21153;&#36827;&#34892;&#35757;&#32451;&#12290;&#30001;&#20110;&#39640;&#35745;&#31639;&#25104;&#26412;&#65292;&#24403;&#21069;&#36235;&#21183;&#26159;&#20351;&#29992;&#25552;&#31034;&#25351;&#23548;&#35843;&#33410;&#39044;&#20808;&#35757;&#32451;&#30340;LLM&#20197;&#36866;&#24212;&#26032;&#30340;&#19979;&#28216;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#22914;&#20309;&#25193;&#23637;&#25552;&#31034;&#35843;&#33410;&#20197;&#21516;&#26102;&#22788;&#29702;&#24322;&#36136;&#20219;&#21153;&#21644;&#25968;&#25454;&#20998;&#24067;&#26159;&#19968;&#20010;&#24191;&#27867;&#24320;&#25918;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;"&#28151;&#21512;&#25552;&#31034;"&#25110;MoPs&#65292;&#24182;&#32467;&#21512;&#26234;&#33021;&#38376;&#25511;&#21151;&#33021;&#65306;&#21518;&#32773;&#30340;&#35774;&#35745;&#26159;&#26412;&#25991;&#30340;&#36129;&#29486;&#20043;&#19968;&#65292;&#23427;&#21487;&#20197;&#35782;&#21035;&#23884;&#20837;&#22312;&#19981;&#21516;&#25552;&#31034;&#32452;&#20013;&#30340;&#30456;&#20851;&#25216;&#33021;&#65292;&#24182;&#26681;&#25454;&#30446;&#26631;&#20219;&#21153;&#21160;&#24577;&#20998;&#37197;&#32452;&#21512;&#19987;&#23478;(&#21363;&#19968;&#32452;&#25552;&#31034;)&#12290;&#27492;&#22806;&#65292;MoPs&#22312;&#24212;&#29992;&#20219;&#20309;&#27169;&#22411;&#21387;&#32553;&#25216;&#26415;&#26102;&#37117;&#19981;&#21463;&#24433;&#21709;&#8212;&#8212;&#20197;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have the ability to solve a variety of tasks, such as text summarization and mathematical questions, just out of the box, but they are often trained with a single task in mind. Due to high computational costs, the current trend is to use prompt instruction tuning to better adjust monolithic, pretrained LLMs for new -- but often individual -- downstream tasks. Thus, how one would expand prompt tuning to handle -- concomitantly -heterogeneous tasks and data distributions is a widely open question. To address this gap, we suggest the use of \emph{Mixture of Prompts}, or MoPs, associated with smart gating functionality: the latter -- whose design is one of the contributions of this paper -- can identify relevant skills embedded in different groups of prompts and dynamically assign combined experts (i.e., collection of prompts), based on the target task. Additionally, MoPs are empirically agnostic to any model compression technique applied -- for efficiency re
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;NLP&#20998;&#26512;&#20102;ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65292;&#36890;&#36807;&#26500;&#24314;&#24341;&#29992;&#32593;&#32476;&#21644;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#25991;&#29486;&#32508;&#36848;&#12290;</title><link>http://arxiv.org/abs/2308.12420</link><description>&lt;p&gt;
ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65306;&#23545;&#25991;&#29486;&#36827;&#34892;NLP&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature. (arXiv:2308.12420v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;NLP&#20998;&#26512;&#20102;ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65292;&#36890;&#36807;&#26500;&#24314;&#24341;&#29992;&#32593;&#32476;&#21644;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#25991;&#29486;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#36134;&#26412;&#25216;&#26415;(DLT)&#36805;&#36895;&#21457;&#23637;&#65292;&#38656;&#35201;&#20840;&#38754;&#20102;&#35299;&#20854;&#21508;&#20010;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#38024;&#23545;DLT&#30340;&#29615;&#22659;&#12289;&#21487;&#25345;&#32493;&#24615;&#21644;&#27835;&#29702;(ESG)&#32452;&#25104;&#37096;&#20998;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#36824;&#19981;&#36275;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;107&#31687;&#31181;&#23376;&#25991;&#29486;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;63,083&#20010;&#21442;&#32771;&#25991;&#29486;&#30340;&#24341;&#29992;&#32593;&#32476;&#65292;&#24182;&#23558;&#20854;&#31934;&#28860;&#20026;24,539&#31687;&#25991;&#29486;&#30340;&#35821;&#26009;&#24211;&#36827;&#34892;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#19968;&#20010;&#24050;&#24314;&#31435;&#30340;&#25216;&#26415;&#20998;&#31867;&#27861;&#20174;46&#31687;&#35770;&#25991;&#20013;&#26631;&#35760;&#20102;&#21629;&#21517;&#23454;&#20307;&#65292;&#24182;&#36890;&#36807;&#25214;&#20986;DLT&#30340;ESG&#35201;&#32032;&#26469;&#23436;&#21892;&#36825;&#20010;&#20998;&#31867;&#27861;&#12290;&#21033;&#29992;&#22522;&#20110;transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#23545;&#19968;&#20010;&#39044;&#20808;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#32454;&#21270;&#35843;&#25972;&#65292;&#29992;&#20110;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#20351;&#29992;&#25105;&#20204;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#35843;&#25972;&#21518;&#30340;&#35821;&#35328;&#27169;&#22411;&#23545;&#35821;&#26009;&#24211;&#36827;&#34892;&#20102;&#31934;&#31616;&#65292;&#24471;&#21040;&#20102;505&#31687;&#20851;&#38190;&#35770;&#25991;&#65292;&#36890;&#36807;&#21629;&#21517;&#23454;&#20307;&#21644;&#26102;&#38388;&#22270;&#20998;&#26512;&#65292;&#20419;&#36827;&#20102;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#28436;&#21270;&#30340;&#25991;&#29486;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed Ledger Technologies (DLTs) have rapidly evolved, necessitating comprehensive insights into their diverse components. However, a systematic literature review that emphasizes the Environmental, Sustainability, and Governance (ESG) components of DLT remains lacking. To bridge this gap, we selected 107 seed papers to build a citation network of 63,083 references and refined it to a corpus of 24,539 publications for analysis. Then, we labeled the named entities in 46 papers according to twelve top-level categories derived from an established technology taxonomy and enhanced the taxonomy by pinpointing DLT's ESG elements. Leveraging transformer-based language models, we fine-tuned a pre-trained language model for a Named Entity Recognition (NER) task using our labeled dataset. We used our fine-tuned language model to distill the corpus to 505 key papers, facilitating a literature review via named entities and temporal graph analysis on DLT evolution in the context of ESG. Our con
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09254</link><description>&lt;p&gt;
&#29992;&#20110;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#22686;&#24378;&#27169;&#22411;&#21487;&#20449;&#24230;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#30001;&#20110;&#23545;&#29983;&#25104;&#34394;&#26500;&#20107;&#23454;&#30340;&#25285;&#24551;&#65292;&#26368;&#36817;&#20852;&#36215;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;GLM&#65289;&#29305;&#21035;&#24378;&#35843;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31070;&#32463;&#39044;&#27979;&#38598;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;&#30340;&#26041;&#24335;&#37327;&#21270;GLM&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#39044;&#27979;&#38598;&#27169;&#22411;&#36890;&#36807;&#26631;&#37327;&#20540;&#21442;&#25968;&#21270;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#39044;&#27979;&#38598;&#65292;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#20173;&#28385;&#36275;PAC&#20445;&#35777;&#12290;&#36890;&#36807;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#20845;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
&lt;/p&gt;</description></item></channel></rss>