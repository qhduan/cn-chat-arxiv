<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>ActiveRAG&#26159;&#19968;&#20010;&#21019;&#26032;&#30340;RAG&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#20027;&#21160;&#23398;&#20064;&#26426;&#21046;&#65292;&#21033;&#29992;&#30693;&#35782;&#26500;&#24314;&#21644;&#35748;&#30693;&#32852;&#32467;&#26426;&#21046;&#26469;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20869;&#22312;&#35748;&#30693;&#65292;&#23454;&#29616;&#20102;&#26126;&#26174;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.13547</link><description>&lt;p&gt;
ActiveRAG: &#36890;&#36807;&#20027;&#21160;&#23398;&#20064;&#25581;&#31034;&#30693;&#35782;&#30340;&#23453;&#34255;
&lt;/p&gt;
&lt;p&gt;
ActiveRAG: Revealing the Treasures of Knowledge via Active Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13547
&lt;/p&gt;
&lt;p&gt;
ActiveRAG&#26159;&#19968;&#20010;&#21019;&#26032;&#30340;RAG&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#20027;&#21160;&#23398;&#20064;&#26426;&#21046;&#65292;&#21033;&#29992;&#30693;&#35782;&#26500;&#24314;&#21644;&#35748;&#30693;&#32852;&#32467;&#26426;&#21046;&#26469;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20869;&#22312;&#35748;&#30693;&#65292;&#23454;&#29616;&#20102;&#26126;&#26174;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13547v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#33539;&#20363;&#65292;&#26377;&#21161;&#20110;&#35299;&#20915;&#30693;&#35782;&#23494;&#38598;&#22411;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;RAG&#27169;&#22411;&#23558;LLMs&#23450;&#20301;&#20026;&#34987;&#21160;&#30340;&#30693;&#35782;&#25509;&#25910;&#22120;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#23398;&#20064;&#21644;&#29702;&#35299;&#22806;&#37096;&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;ActiveRAG&#65292;&#23427;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;RAG&#26694;&#26550;&#65292;&#20174;&#34987;&#21160;&#30693;&#35782;&#33719;&#21462;&#36716;&#21464;&#20026;&#20027;&#21160;&#23398;&#20064;&#26426;&#21046;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#30693;&#35782;&#26500;&#24314;&#26426;&#21046;&#36890;&#36807;&#23558;&#22806;&#37096;&#30693;&#35782;&#19982;&#20808;&#21069;&#33719;&#21462;&#25110;&#35760;&#24518;&#30340;&#30693;&#35782;&#30456;&#20851;&#32852;&#26469;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#22806;&#37096;&#30693;&#35782;&#12290;&#38543;&#21518;&#65292;&#23427;&#35774;&#35745;&#20102;&#35748;&#30693;&#32852;&#32467;&#26426;&#21046;&#20197;&#21512;&#24182;&#26469;&#33258;&#24605;&#32500;&#21644;&#30693;&#35782;&#26500;&#24314;&#38142;&#30340;&#25104;&#26524;&#65292;&#20174;&#32780;&#26657;&#20934;LLMs&#30340;&#20869;&#22312;&#35748;&#30693;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ActiveRAG&#36229;&#36234;&#20102;&#20808;&#21069;&#30340;RAG&#27169;&#22411;&#65292;&#22312;&#38382;&#39064;&#22238;&#31572;&#19978;&#23454;&#29616;&#20102;5%&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13547v1 Announce Type: new  Abstract: Retrieval Augmented Generation (RAG) has introduced a new paradigm for Large Language Models (LLMs), aiding in the resolution of knowledge-intensive tasks. However, current RAG models position LLMs as passive knowledge receptors, thereby restricting their capacity for learning and comprehending external knowledge. In this paper, we present ActiveRAG, an innovative RAG framework that shifts from passive knowledge acquisition to an active learning mechanism. This approach utilizes the Knowledge Construction mechanism to develop a deeper understanding of external knowledge by associating it with previously acquired or memorized knowledge. Subsequently, it designs the Cognitive Nexus mechanism to incorporate the outcomes from both chains of thought and knowledge construction, thereby calibrating the intrinsic cognition of LLMs. Our experimental results demonstrate that ActiveRAG surpasses previous RAG models, achieving a 5% improvement on qu
&lt;/p&gt;</description></item></channel></rss>