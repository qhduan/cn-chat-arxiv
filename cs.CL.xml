<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#39034;&#24207;&#24314;&#27169;&#33021;&#21147;&#65292;&#29702;&#35770;&#19978;&#21051;&#30011;&#20102;&#21333;&#23618;Transformer&#30340;&#25439;&#22833;&#26223;&#35266;&#24182;&#21457;&#29616;&#20102;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#22351;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#23384;&#22312;&#12290;</title><link>https://arxiv.org/abs/2402.04161</link><description>&lt;p&gt;
&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#35268;&#33539;&#20998;&#26512;&#26694;&#26550;&#65306;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#30740;&#31350;Transformer&#30340;&#39034;&#24207;&#24314;&#27169;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04161
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#39034;&#24207;&#24314;&#27169;&#33021;&#21147;&#65292;&#29702;&#35770;&#19978;&#21051;&#30011;&#20102;&#21333;&#23618;Transformer&#30340;&#25439;&#22833;&#26223;&#35266;&#24182;&#21457;&#29616;&#20102;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#22351;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;Transformer&#22312;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#22312;&#20869;&#30340;&#22810;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#26159;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#36807;&#31243;&#65292;&#27169;&#22411;&#22312;&#27492;&#36807;&#31243;&#20013;&#36890;&#36807;&#33258;&#22238;&#24402;&#30340;&#26041;&#24335;&#22312;&#22823;&#22411;&#25991;&#26412;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#20026;&#20102;&#25581;&#31034;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#35270;&#35282;&#65292;&#20801;&#35768;&#29702;&#35770;&#21644;&#31995;&#32479;&#23454;&#39564;&#26469;&#30740;&#31350;Transformer&#30340;&#39034;&#24207;&#24314;&#27169;&#33021;&#21147;&#12290;&#21463;&#21040;&#33258;&#28982;&#35821;&#35328;&#30340;&#39532;&#23572;&#21487;&#22827;&#24615;&#36136;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#25968;&#25454;&#24314;&#27169;&#20026;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#28304;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#31995;&#32479;&#22320;&#30740;&#31350;&#25968;&#25454;&#20998;&#24067;&#29305;&#24615;&#12289;Transformer&#26550;&#26500;&#12289;&#23398;&#21040;&#30340;&#20998;&#24067;&#21644;&#26368;&#32456;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#21051;&#30011;&#20102;&#21333;&#23618;Transformer&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#24182;&#23637;&#31034;&#20102;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#22351;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#23384;&#22312;&#65292;&#36825;&#21462;&#20915;&#20110;&#20855;&#20307;&#30340;&#25968;&#25454;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. A key ingredient behind their success is the generative pretraining procedure, during which these models are trained on a large text corpus in an auto-regressive manner. To shed light on this phenomenon, we propose a new framework that allows both theory and systematic experiments to study the sequential modeling capabilities of transformers through the lens of Markov chains. Inspired by the Markovianity of natural languages, we model the data as a Markovian source and utilize this framework to systematically study the interplay between the data-distributional properties, the transformer architecture, the learnt distribution, and the final model performance. In particular, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima and bad local minima contingent upon the specific data chara
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;VlogQA&#65306;&#36234;&#21335;&#21475;&#35821;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#12289;&#25968;&#25454;&#38598;&#21644;&#22522;&#32447;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#20219;&#21153;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#30340;&#35265;&#35299;&#12290;VlogQA&#26159;&#19968;&#20010;&#22522;&#20110;&#26469;&#33258;YouTube&#30340;&#21095;&#26412;&#25991;&#26723;&#30340;&#38382;&#31572;&#23545;&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20102;&#39135;&#29289;&#21644;&#26053;&#34892;&#31561;&#20027;&#39064;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#27979;&#35797;&#38598;&#21462;&#24471;&#20102;75.34%&#30340;&#26368;&#39640;F1&#20998;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.02655</link><description>&lt;p&gt;
VlogQA: &#36234;&#21335;&#21475;&#35821;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#12289;&#25968;&#25454;&#38598;&#21644;&#22522;&#32447;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
VlogQA: Task, Dataset, and Baseline Models for Vietnamese Spoken-Based Machine Reading Comprehension
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;VlogQA&#65306;&#36234;&#21335;&#21475;&#35821;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#12289;&#25968;&#25454;&#38598;&#21644;&#22522;&#32447;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#20219;&#21153;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#30340;&#35265;&#35299;&#12290;VlogQA&#26159;&#19968;&#20010;&#22522;&#20110;&#26469;&#33258;YouTube&#30340;&#21095;&#26412;&#25991;&#26723;&#30340;&#38382;&#31572;&#23545;&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20102;&#39135;&#29289;&#21644;&#26053;&#34892;&#31561;&#20027;&#39064;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#27979;&#35797;&#38598;&#21462;&#24471;&#20102;75.34%&#30340;&#26368;&#39640;F1&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#36234;&#21335;&#21475;&#35821;&#35821;&#26009;&#24211;&#30340;&#24320;&#21457;&#36807;&#31243;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#26102;&#36935;&#21040;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#30340;&#35265;&#35299;&#12290;&#29616;&#26377;&#30340;&#36234;&#21335;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#35821;&#26009;&#24211;&#20027;&#35201;&#20851;&#27880;&#27491;&#24335;&#30340;&#20070;&#38754;&#25991;&#26723;&#65292;&#22914;&#32500;&#22522;&#30334;&#31185;&#25991;&#31456;&#12289;&#22312;&#32447;&#25253;&#32440;&#25110;&#25945;&#31185;&#20070;&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;VlogQA&#21253;&#21547;&#20102;10,076&#20010;&#38382;&#31572;&#23545;&#65292;&#22522;&#20110;&#20174;YouTube&#33719;&#21462;&#30340;1,230&#20221;&#21095;&#26412;&#25991;&#26723;&#65292;YouTube&#26159;&#19968;&#20010;&#21253;&#21547;&#20102;&#29992;&#25143;&#19978;&#20256;&#20869;&#23481;&#30340;&#24191;&#27867;&#36164;&#28304;&#65292;&#28085;&#30422;&#20102;&#39135;&#29289;&#21644;&#26053;&#34892;&#31561;&#20027;&#39064;&#12290;&#36890;&#36807;&#25429;&#25417;&#36234;&#21335;&#26412;&#22303;&#20154;&#22312;&#33258;&#28982;&#29615;&#22659;&#20013;&#30340;&#21475;&#35821;&#34920;&#36798;&#65292;&#36825;&#26159;&#36234;&#21335;&#30740;&#31350;&#20013;&#34987;&#24573;&#35270;&#30340;&#19968;&#20010;&#35282;&#33853;&#65292;&#35813;&#35821;&#26009;&#24211;&#20026;&#26410;&#26469;&#36234;&#21335;&#35821;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#36164;&#28304;&#12290;&#22312;&#24615;&#33021;&#35780;&#20272;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#27979;&#35797;&#38598;&#19978;&#21462;&#24471;&#20102;&#26368;&#39640;&#30340;F1&#20998;&#25968;&#20026;75.34%&#65292;&#34920;&#26126;&#20102;&#20854;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents the development process of a Vietnamese spoken language corpus for machine reading comprehension (MRC) tasks and provides insights into the challenges and opportunities associated with using real-world data for machine reading comprehension tasks. The existing MRC corpora in Vietnamese mainly focus on formal written documents such as Wikipedia articles, online newspapers, or textbooks. In contrast, the VlogQA consists of 10,076 question-answer pairs based on 1,230 transcript documents sourced from YouTube -- an extensive source of user-uploaded content, covering the topics of food and travel. By capturing the spoken language of native Vietnamese speakers in natural settings, an obscure corner overlooked in Vietnamese research, the corpus provides a valuable resource for future research in reading comprehension tasks for the Vietnamese language. Regarding performance evaluation, our deep-learning models achieved the highest F1 score of 75.34% on the test set, indicat
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#35299;&#20915;&#22312;&#32447;&#31038;&#21306;&#20013;&#25925;&#20107;&#26816;&#27979;&#22256;&#38590;&#30340;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;StorySeeker&#24037;&#20855;&#21253;&#65292;&#21253;&#25324;&#35814;&#32454;&#27880;&#37322;&#30340;Reddit&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#65292;&#31361;&#20986;&#20102;&#22312;&#32447;&#21465;&#20107;&#30340;&#25991;&#26412;&#29305;&#24449;&#65292;&#24341;&#20837;&#20102;&#21465;&#20107;&#36328;&#24230;&#26816;&#27979;&#20316;&#20026;&#19968;&#20010;&#26032;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2311.09675</link><description>&lt;p&gt;
&#20154;&#20204;&#22312;&#21738;&#37324;&#22312;&#32447;&#35762;&#25925;&#20107;&#65311;&#36328;&#22312;&#32447;&#31038;&#21306;&#30340;&#25925;&#20107;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Where Do People Tell Stories Online? Story Detection Across Online Communities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09675
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#35299;&#20915;&#22312;&#32447;&#31038;&#21306;&#20013;&#25925;&#20107;&#26816;&#27979;&#22256;&#38590;&#30340;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;StorySeeker&#24037;&#20855;&#21253;&#65292;&#21253;&#25324;&#35814;&#32454;&#27880;&#37322;&#30340;Reddit&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#65292;&#31361;&#20986;&#20102;&#22312;&#32447;&#21465;&#20107;&#30340;&#25991;&#26412;&#29305;&#24449;&#65292;&#24341;&#20837;&#20102;&#21465;&#20107;&#36328;&#24230;&#26816;&#27979;&#20316;&#20026;&#19968;&#20010;&#26032;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#31038;&#21306;&#20013;&#30340;&#25925;&#20107;&#26816;&#27979;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#25925;&#20107;&#20998;&#25955;&#22312;&#31038;&#21306;&#20013;&#65292;&#24182;&#19988;&#19982;&#21333;&#20010;&#25991;&#26412;&#20013;&#30340;&#38750;&#21465;&#20107;&#37096;&#20998;&#20132;&#32455;&#22312;&#19968;&#36215;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#21644;&#21457;&#24067;StorySeeker&#24037;&#20855;&#21253;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#21253;&#21547;502&#20010;Reddit&#24086;&#23376;&#21644;&#35780;&#35770;&#30340;&#20016;&#23500;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#19968;&#20010;&#36866;&#24212;&#31038;&#20132;&#23186;&#20307;&#32972;&#26223;&#30340;&#35814;&#32454;&#30340;&#20195;&#30721;&#20070;&#65292;&#20197;&#21450;&#29992;&#20110;&#22312;&#25991;&#26723;&#21644;&#36328;&#24230;&#32423;&#21035;&#39044;&#27979;&#21465;&#20107;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#26159;&#20174;&#25968;&#30334;&#20010;&#27969;&#34892;&#30340;&#33521;&#35821;Reddit&#31038;&#21306;&#20013;&#25277;&#26679;&#32780;&#26469;&#65292;&#28085;&#30422;&#20102;33&#20010;&#20027;&#39064;&#31867;&#21035;&#65292;&#23427;&#21253;&#21547;&#20102;&#32454;&#31890;&#24230;&#30340;&#19987;&#23478;&#27880;&#37322;&#65292;&#21253;&#25324;&#20108;&#20803;&#25925;&#20107;&#26631;&#31614;&#65292;&#25925;&#20107;&#36328;&#24230;&#21644;&#20107;&#20214;&#36328;&#24230;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#25968;&#25454;&#35780;&#20272;&#20102;&#19968;&#31995;&#21015;&#26816;&#27979;&#26041;&#27861;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#32447;&#21465;&#20107;&#30340;&#29420;&#29305;&#25991;&#26412;&#29305;&#24449;&#65292;&#37325;&#28857;&#20851;&#27880;&#21465;&#20107;&#36328;&#24230;&#26816;&#27979;&#65292;&#36825;&#26159;&#25105;&#20204;&#24341;&#20837;&#30340;&#19968;&#20010;&#26032;&#20219;&#21153;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#22823;&#35268;&#27169;&#21465;&#20107;&#30340;&#20998;&#24067;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09675v2 Announce Type: replace  Abstract: Story detection in online communities is a challenging task as stories are scattered across communities and interwoven with non-storytelling spans within a single text. We address this challenge by building and releasing the StorySeeker toolkit, including a richly annotated dataset of 502 Reddit posts and comments, a detailed codebook adapted to the social media context, and models to predict storytelling at the document and span level. Our dataset is sampled from hundreds of popular English-language Reddit communities ranging across 33 topic categories, and it contains fine-grained expert annotations, including binary story labels, story spans, and event spans. We evaluate a range of detection methods using our data, and we identify the distinctive textual features of online storytelling, focusing on storytelling span detection, which we introduce as a new task. We illuminate distributional characteristics of storytelling on a large
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Transformer&#21644;Ensemble&#26041;&#27861;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#38463;&#35821;&#24694;&#24847;&#35328;&#35770;&#30340;&#26816;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#22810;&#25968;&#34920;&#20915;&#30340;&#38598;&#25104;&#26041;&#27861;&#20855;&#26377;&#26368;&#20339;&#25928;&#26524;&#65292;&#20854;&#22312;&#27979;&#35797;&#38598;&#19978;&#30340;&#20934;&#30830;&#29575;&#20026;0.86&#65292;F1&#20998;&#25968;&#20026;0.60&#12290;</title><link>http://arxiv.org/abs/2303.09823</link><description>&lt;p&gt;
Transformers&#21644;Ensemble&#26041;&#27861;&#65306;&#38463;&#35821;&#24694;&#24847;&#35328;&#35770;&#26816;&#27979;&#30340;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Transformers and Ensemble methods: A solution for Hate Speech Detection in Arabic languages. (arXiv:2303.09823v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09823
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Transformer&#21644;Ensemble&#26041;&#27861;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#38463;&#35821;&#24694;&#24847;&#35328;&#35770;&#30340;&#26816;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#22810;&#25968;&#34920;&#20915;&#30340;&#38598;&#25104;&#26041;&#27861;&#20855;&#26377;&#26368;&#20339;&#25928;&#26524;&#65292;&#20854;&#22312;&#27979;&#35797;&#38598;&#19978;&#30340;&#20934;&#30830;&#29575;&#20026;0.86&#65292;F1&#20998;&#25968;&#20026;0.60&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#25105;&#20204;&#21442;&#21152;CERIST NLP&#25361;&#25112;&#36187;2022&#20013;&#24694;&#24847;&#35328;&#35770;&#26816;&#27979;&#20849;&#20139;&#20219;&#21153;&#30340;&#23454;&#39564;&#36807;&#31243;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;6&#20010;Transformer&#27169;&#22411;&#21450;&#20854;&#32452;&#21512;&#30340;&#24615;&#33021;&#65292;&#24182;&#20351;&#29992;&#20102;2&#31181;&#38598;&#25104;&#26041;&#27861;&#12290;&#22312;&#20116;&#25240;&#20132;&#21449;&#39564;&#35777;&#30340;&#35757;&#32451;&#38598;&#19978;&#65292;&#22522;&#20110;&#22810;&#25968;&#34920;&#20915;&#30340;&#38598;&#25104;&#26041;&#27861;&#33719;&#24471;&#20102;&#26368;&#20339;&#32467;&#26524;&#12290;&#22312;&#27979;&#35797;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#20026;F1&#20998;&#25968;&#20026;0.60&#65292;&#20934;&#30830;&#24615;&#20026;0.86&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper describes our participation in the shared task of hate speech detection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our experiments evaluate the performance of six transformer models and their combination using 2 ensemble approaches. The best results on the training set, in a five-fold cross validation scenario, were obtained by using the ensemble approach based on the majority vote. The evaluation of this approach on the test set resulted in an F1-score of 0.60 and an Accuracy of 0.86.
&lt;/p&gt;</description></item></channel></rss>