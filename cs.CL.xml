<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20013;&#65292;&#24403;&#25968;&#25454;&#38598;&#30340;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#20302;&#26102;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;PT&#65289;&#32988;&#36807;&#27169;&#22411;&#26080;&#20851;&#20803;&#23398;&#20064;&#65288;MAML&#65289;&#12290;&#24403;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#39640;&#26102;&#65292;MAML&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2306.13841</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;&#30495;&#30340;&#27604;&#20803;&#23398;&#20064;&#26356;&#22909;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Pre-training Truly Better Than Meta-Learning?. (arXiv:2306.13841v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13841
&lt;/p&gt;
&lt;p&gt;
&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20013;&#65292;&#24403;&#25968;&#25454;&#38598;&#30340;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#20302;&#26102;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;PT&#65289;&#32988;&#36807;&#27169;&#22411;&#26080;&#20851;&#20803;&#23398;&#20064;&#65288;MAML&#65289;&#12290;&#24403;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#39640;&#26102;&#65292;MAML&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#32972;&#26223;&#19979;&#65292;&#30446;&#21069;&#26222;&#36941;&#35748;&#20026;&#22266;&#23450;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;PT&#65289;&#21152;&#19978;&#22312;&#35780;&#20215;&#26102;&#24494;&#35843;&#26368;&#21518;&#19968;&#23618;&#65292;&#32988;&#36807;&#26631;&#20934;&#30340;&#20803;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#28145;&#20837;&#30340;&#23454;&#35777;&#30740;&#31350;&#21644;&#24191;&#27867;&#30340;&#25968;&#25454;&#38598;&#27604;&#36739;PT&#21644;&#27169;&#22411;&#26080;&#20851;&#20803;&#23398;&#20064;&#65288;MAML&#65289;&#36825;&#20123;&#35828;&#27861;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#24378;&#35843;&#20351;&#29992;&#30456;&#21516;&#30340;&#20307;&#31995;&#32467;&#26500;&#12289;&#30456;&#21516;&#30340;&#20248;&#21270;&#22120;&#65292;&#20197;&#21450;&#25152;&#26377;&#27169;&#22411;&#37117;&#35757;&#32451;&#21040;&#25910;&#25947;&#12290;&#20851;&#38190;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#26356;&#20005;&#26684;&#30340;&#32479;&#35745;&#24037;&#20855;&#8212;&#8212;&#25928;&#24212;&#37327;&#65288;Cohen's d&#65289;&#8212;&#8212;&#26469;&#30830;&#23450;&#20351;&#29992;PT&#19982;&#20351;&#29992;MAML&#20043;&#38388;&#30340;&#27169;&#22411;&#24046;&#24322;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;&#28982;&#21518;&#20351;&#29992;&#19968;&#20010;&#39044;&#20808;&#25552;&#20986;&#30340;&#24230;&#37327;&#8212;&#8212;&#22810;&#26679;&#24615;&#31995;&#25968;&#8212;&#8212;&#26469;&#35745;&#31639;&#25968;&#25454;&#38598;&#30340;&#24179;&#22343;&#27491;&#24335;&#22810;&#26679;&#24615;&#12290;&#20351;&#29992;&#36825;&#31181;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20197;&#19979;&#20107;&#23454;&#65306;1. &#24403;&#25968;&#25454;&#38598;&#30340;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#20302;&#26102;&#65292;PT&#22312;&#24179;&#22343;&#24847;&#20041;&#19978;&#32988;&#36807;MAML&#65307;2. &#24403;&#27491;&#24335;&#22810;&#26679;&#24615;&#36739;&#39640;&#26102;&#65292;MAML&#32988;&#36807;PT&#12290;
&lt;/p&gt;
&lt;p&gt;
In the context of few-shot learning, it is currently believed that a fixed pre-trained (PT) model, along with fine-tuning the final layer during evaluation, outperforms standard meta-learning algorithms. We re-evaluate these claims under an in-depth empirical examination of an extensive set of formally diverse datasets and compare PT to Model Agnostic Meta-Learning (MAML). Unlike previous work, we emphasize a fair comparison by using: the same architecture, the same optimizer, and all models trained to convergence. Crucially, we use a more rigorous statistical tool -- the effect size (Cohen's d) -- to determine the practical significance of the difference between a model trained with PT vs. a MAML. We then use a previously proposed metric -- the diversity coefficient -- to compute the average formal diversity of a dataset. Using this analysis, we demonstrate the following: 1. when the formal diversity of a data set is low, PT beats MAML on average and 2. when the formal diversity is hi
&lt;/p&gt;</description></item></channel></rss>