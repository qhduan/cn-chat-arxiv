<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#23581;&#35797;&#24635;&#32467;&#21644;&#35780;&#20272;&#30001;&#35813;&#39046;&#22495;&#36804;&#20170;&#36827;&#23637;&#32780;&#24418;&#25104;&#30340;NLP&#39564;&#35777;&#27969;&#31243;&#30340;&#19968;&#33324;&#32452;&#25104;&#37096;&#20998;&#65292;&#36129;&#29486;&#22312;&#20110;&#25552;&#20986;&#20102;&#23558;&#21477;&#23376;&#23884;&#20837;&#36830;&#32493;&#31354;&#38388;&#24471;&#21040;&#30340;&#21487;&#39564;&#35777;&#23376;&#31354;&#38388;&#30340;&#19968;&#33324;&#25551;&#36848;&#12290;</title><link>https://arxiv.org/abs/2403.10144</link><description>&lt;p&gt;
NLP&#39564;&#35777;&#65306;&#36208;&#21521;&#19968;&#31181;&#36890;&#29992;&#30340;&#29992;&#20110;&#35748;&#35777;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#35770;
&lt;/p&gt;
&lt;p&gt;
NLP Verification: Towards a General Methodology for Certifying Robustness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23581;&#35797;&#24635;&#32467;&#21644;&#35780;&#20272;&#30001;&#35813;&#39046;&#22495;&#36804;&#20170;&#36827;&#23637;&#32780;&#24418;&#25104;&#30340;NLP&#39564;&#35777;&#27969;&#31243;&#30340;&#19968;&#33324;&#32452;&#25104;&#37096;&#20998;&#65292;&#36129;&#29486;&#22312;&#20110;&#25552;&#20986;&#20102;&#23558;&#21477;&#23376;&#23884;&#20837;&#36830;&#32493;&#31354;&#38388;&#24471;&#21040;&#30340;&#21487;&#39564;&#35777;&#23376;&#31354;&#38388;&#30340;&#19968;&#33324;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#21151;&#65292;&#30830;&#20445;&#23427;&#20204;&#30340;&#23433;&#20840;&#24615;&#21644;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#65306;&#22312;&#23433;&#20840;&#20851;&#38190;&#30340;&#24773;&#22659;&#20013;&#65292;&#36825;&#20123;&#27169;&#22411;&#24517;&#39035;&#23545;&#21464;&#21270;&#25110;&#25915;&#20987;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#33021;&#23545;&#20854;&#36755;&#20986;&#32473;&#20986;&#20445;&#35777;&#12290;&#19982;&#35745;&#31639;&#26426;&#35270;&#35273;&#19981;&#21516;&#65292;NLP&#32570;&#20047;&#19968;&#20010;&#32479;&#19968;&#30340;&#39564;&#35777;&#26041;&#27861;&#35770;&#65292;&#23613;&#31649;&#36817;&#24180;&#26469;&#25991;&#29486;&#20013;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#23545;&#20110;NLP&#39564;&#35777;&#30340;&#23454;&#29992;&#38382;&#39064;&#24120;&#24120;&#28041;&#21450;&#19981;&#28145;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23581;&#35797;&#25552;&#28860;&#21644;&#35780;&#20272;&#19968;&#20010;NLP&#39564;&#35777;&#27969;&#31243;&#30340;&#19968;&#33324;&#32452;&#25104;&#37096;&#20998;&#65292;&#35813;&#27969;&#31243;&#26469;&#28304;&#20110;&#36804;&#20170;&#20026;&#27490;&#35813;&#39046;&#22495;&#30340;&#36827;&#23637;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26377;&#20004;&#26041;&#38754;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23558;&#21477;&#23376;&#23884;&#20837;&#36830;&#32493;&#31354;&#38388;&#24471;&#21040;&#30340;&#21487;&#39564;&#35777;&#23376;&#31354;&#38388;&#30340;&#19968;&#33324;&#25551;&#36848;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#21487;&#39564;&#35777;&#23376;&#31354;&#38388;&#30340;&#35821;&#20041;&#27867;&#21270;&#25216;&#26415;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10144v1 Announce Type: cross  Abstract: Deep neural networks have exhibited substantial success in the field of Natural Language Processing (NLP) and ensuring their safety and reliability is crucial: there are safety critical contexts where such models must be robust to variability or attack, and give guarantees over their output. Unlike Computer Vision, NLP lacks a unified verification methodology and, despite recent advancements in literature, they are often light on the pragmatical issues of NLP verification. In this paper, we make an attempt to distil and evaluate general components of an NLP verification pipeline, that emerges from the progress in the field to date. Our contributions are two-fold. Firstly, we give a general characterisation of verifiable subspaces that result from embedding sentences into continuous spaces. We identify, and give an effective method to deal with, the technical challenge of semantic generalisability of verified subspaces; and propose it a
&lt;/p&gt;</description></item><item><title>&#35843;&#26597;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#31181;&#26063;&#21644;&#24615;&#21035;&#20559;&#35265;&#65292;&#23588;&#20854;&#23545;&#19982;&#40657;&#20154;&#22899;&#24615;&#30456;&#20851;&#30340;&#21517;&#23383;&#34920;&#29616;&#26368;&#19981;&#21033;&#12290;&#23457;&#35745;&#22312;&#27169;&#22411;&#37096;&#32626;&#21644;&#23454;&#26045;&#26102;&#30340;&#37325;&#35201;&#24615;&#24471;&#21040;&#24378;&#35843;&#12290;</title><link>https://arxiv.org/abs/2402.14875</link><description>&lt;p&gt;
&#21517;&#23383;&#30340;&#21547;&#20041;&#26159;&#20160;&#20040;&#65311;&#23457;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#31181;&#26063;&#21644;&#24615;&#21035;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
What's in a Name? Auditing Large Language Models for Race and Gender Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14875
&lt;/p&gt;
&lt;p&gt;
&#35843;&#26597;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#31181;&#26063;&#21644;&#24615;&#21035;&#20559;&#35265;&#65292;&#23588;&#20854;&#23545;&#19982;&#40657;&#20154;&#22899;&#24615;&#30456;&#20851;&#30340;&#21517;&#23383;&#34920;&#29616;&#26368;&#19981;&#21033;&#12290;&#23457;&#35745;&#22312;&#27169;&#22411;&#37096;&#32626;&#21644;&#23454;&#26045;&#26102;&#30340;&#37325;&#35201;&#24615;&#24471;&#21040;&#24378;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37319;&#29992;&#23457;&#35745;&#35774;&#35745;&#26469;&#35843;&#26597;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#65292;&#21253;&#25324;GPT-4&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#21457;&#27169;&#22411;&#22312;&#21508;&#31181;&#24773;&#26223;&#19979;&#20026;&#20010;&#20154;&#25552;&#20379;&#24314;&#35758;&#65292;&#27604;&#22914;&#22312;&#36141;&#36710;&#35848;&#21028;&#25110;&#36873;&#20030;&#32467;&#26524;&#39044;&#27979;&#36807;&#31243;&#20013;&#12290;&#25105;&#20204;&#21457;&#29616;&#35813;&#24314;&#35758;&#31995;&#32479;&#24615;&#22320;&#23545;&#19982;&#31181;&#26063;&#23569;&#25968;&#32676;&#20307;&#21644;&#22899;&#24615;&#24120;&#35265;&#30456;&#20851;&#30340;&#21517;&#23383;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#19982;&#40657;&#20154;&#22899;&#24615;&#30456;&#20851;&#30340;&#21517;&#23383;&#24471;&#21040;&#30340;&#32467;&#26524;&#26368;&#19981;&#21033;&#12290;&#36825;&#20123;&#20559;&#35265;&#22312;42&#20010;&#25552;&#31034;&#27169;&#26495;&#21644;&#22810;&#20010;&#27169;&#22411;&#20013;&#37117;&#26159;&#19968;&#33268;&#30340;&#65292;&#34920;&#26126;&#36825;&#26159;&#19968;&#20010;&#31995;&#32479;&#24615;&#38382;&#39064;&#65292;&#32780;&#19981;&#26159;&#23396;&#31435;&#20107;&#20214;&#12290;&#22312;&#25552;&#31034;&#20013;&#25552;&#20379;&#25968;&#20540;&#12289;&#19982;&#20915;&#31574;&#30456;&#20851;&#30340;&#38170;&#28857;&#21487;&#20197;&#25104;&#21151;&#25269;&#28040;&#20559;&#35265;&#65292;&#32780;&#23450;&#24615;&#32454;&#33410;&#30340;&#24433;&#21709;&#24182;&#19981;&#19968;&#33268;&#65292;&#29978;&#33267;&#21487;&#33021;&#20250;&#21152;&#21095;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#24378;&#35843;&#20102;&#22312;&#35821;&#35328;&#27169;&#22411;&#37096;&#32626;&#21644;&#23454;&#26045;&#26102;&#36827;&#34892;&#23457;&#35745;&#30340;&#37325;&#35201;&#24615;&#65292;&#20197;&#20943;&#36731;&#20854;&#28508;&#22312;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14875v1 Announce Type: cross  Abstract: We employ an audit design to investigate biases in state-of-the-art large language models, including GPT-4. In our study, we elicit prompt the models for advice regarding an individual across a variety of scenarios, such as during car purchase negotiations or election outcome predictions. We find that the advice systematically disadvantages names that are commonly associated with racial minorities and women. Names associated with Black women receive the least advantageous outcomes. The biases are consistent across 42 prompt templates and several models, indicating a systemic issue rather than isolated incidents. While providing numerical, decision-relevant anchors in the prompt can successfully counteract the biases, qualitative details have inconsistent effects and may even increase disparities. Our findings underscore the importance of conducting audits at the point of LLM deployment and implementation to mitigate their potential for
&lt;/p&gt;</description></item></channel></rss>