<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#31574;&#30053;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#21160;&#35780;&#20272;&#21644;&#36873;&#25321;&#65292;&#24182;&#36890;&#36807;&#36830;&#32493;&#39044;&#35757;&#32451;&#26174;&#33879;&#25552;&#39640;&#20102;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#12290;&#20027;&#35201;&#21019;&#26032;&#21253;&#25324;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#39564;&#35777;&#22120;&#65292;&#21457;&#24067;&#20102;&#39640;&#36136;&#37327;&#30340;AutoMathText&#25968;&#25454;&#38598;&#65292;&#24182;&#23454;&#29616;&#20102;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#30340;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.07625</link><description>&lt;p&gt;
AutoMathText&#65306;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#31574;&#30053;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#21160;&#35780;&#20272;&#21644;&#36873;&#25321;&#65292;&#24182;&#36890;&#36807;&#36830;&#32493;&#39044;&#35757;&#32451;&#26174;&#33879;&#25552;&#39640;&#20102;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#12290;&#20027;&#35201;&#21019;&#26032;&#21253;&#25324;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#39564;&#35777;&#22120;&#65292;&#21457;&#24067;&#20102;&#39640;&#36136;&#37327;&#30340;AutoMathText&#25968;&#25454;&#38598;&#65292;&#24182;&#23454;&#29616;&#20102;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36890;&#36807;&#25345;&#32493;&#30340;&#39044;&#35757;&#32451;&#25913;&#21892;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#25512;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31574;&#30053;&#65292;&#21033;&#29992;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#12290;&#19982;&#20256;&#32479;&#30340;&#26377;&#20154;&#24037;&#26631;&#27880;&#25968;&#25454;&#30340;&#30417;&#30563;&#24494;&#35843;&#25110;&#35757;&#32451;&#36807;&#30340;&#20998;&#31867;&#22120;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#38646;&#26679;&#26412;&#39564;&#35777;&#22120;&#65292;&#33258;&#20027;&#35780;&#20272;&#21644;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#25968;&#23398;&#20869;&#23481;&#65292;&#24182;&#21457;&#24067;&#20102;&#32463;&#36807;&#31574;&#21010;&#30340;&#24320;&#28304;AutoMathText&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#36229;&#36807;200GB&#30340;&#25968;&#25454;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#23545;AutoMathText&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#36830;&#32493;&#39044;&#35757;&#32451;&#65292;&#20351;&#24471;7B&#21442;&#25968;&#30340;Mistral&#35821;&#35328;&#27169;&#22411;&#22312;MATH&#25968;&#25454;&#38598;&#19978;&#30340;&#19979;&#28216;&#24615;&#33021;&#22823;&#24133;&#25552;&#21319;&#65292;&#32780;&#20196;&#29260;&#25968;&#37327;&#27604;&#20043;&#21069;&#30340;&#36830;&#32493;&#39044;&#35757;&#32451;&#24037;&#20316;&#20943;&#23569;&#20102;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;&#22522;&#20934;&#30340;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#25552;&#39640;&#20102;2&#20493;&#65292;&#31361;&#26174;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#22686;&#24378;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
To improve language models' proficiency in mathematical reasoning via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional supervised fine-tuning or trained classifiers with human-annotated data, our approach utilizes meta-prompted language models as zero-shot verifiers to autonomously evaluate and select high-quality mathematical content, and we release the curated open-source AutoMathText dataset encompassing over 200GB of data. To demonstrate the efficacy of our method, we continuously pretrained a 7B-parameter Mistral language model on the AutoMathText dataset, achieving substantial improvements in downstream performance on the MATH dataset with a token amount reduced by orders of magnitude compared to previous continuous pretraining works. Our method showcases a 2 times increase in pretraining token efficiency compared to baselines, underscoring the potential of our approach in enhancing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#36801;&#31227;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32570;&#22833;&#27169;&#24577;&#19979;&#36827;&#34892;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#32763;&#35793;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#30340;&#20869;&#23481;&#20197;&#37325;&#26500;&#32570;&#22833;&#30340;&#38899;&#39057;&#27169;&#24577;&#65292;&#24182;&#21033;&#29992;&#36328;&#27169;&#24577;&#27880;&#24847;&#26426;&#21046;&#36827;&#34892;&#24773;&#24863;&#39044;&#27979;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#21644;&#19982;&#23436;&#25972;&#22810;&#27169;&#24577;&#30417;&#30563;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.10747</link><description>&lt;p&gt;
&#32570;&#22833;&#27169;&#24577;&#19979;&#30340;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;:&#19968;&#31181;&#30693;&#35782;&#36801;&#31227;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach. (arXiv:2401.10747v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10747
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#35782;&#36801;&#31227;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#32570;&#22833;&#27169;&#24577;&#19979;&#36827;&#34892;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#32763;&#35793;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#30340;&#20869;&#23481;&#20197;&#37325;&#26500;&#32570;&#22833;&#30340;&#38899;&#39057;&#27169;&#24577;&#65292;&#24182;&#21033;&#29992;&#36328;&#27169;&#24577;&#27880;&#24847;&#26426;&#21046;&#36827;&#34892;&#24773;&#24863;&#39044;&#27979;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#21644;&#19982;&#23436;&#25972;&#22810;&#27169;&#24577;&#30417;&#30563;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#26088;&#22312;&#36890;&#36807;&#35270;&#35273;&#12289;&#35821;&#35328;&#21644;&#22768;&#38899;&#32447;&#32034;&#26469;&#35782;&#21035;&#20010;&#20307;&#34920;&#36798;&#30340;&#24773;&#32490;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#22823;&#22810;&#20551;&#35774;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#36807;&#31243;&#20013;&#25152;&#26377;&#27169;&#24577;&#37117;&#26159;&#21487;&#29992;&#30340;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#30340;&#31639;&#27861;&#23481;&#26131;&#21463;&#21040;&#32570;&#22833;&#27169;&#24577;&#30340;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#30693;&#35782;&#36801;&#31227;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#19981;&#21516;&#27169;&#24577;&#20043;&#38388;&#36827;&#34892;&#32763;&#35793;&#65292;&#20197;&#37325;&#26500;&#32570;&#22833;&#30340;&#38899;&#39057;&#27169;&#24577;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#36328;&#27169;&#24577;&#27880;&#24847;&#26426;&#21046;&#65292;&#20197;&#20445;&#30041;&#37325;&#26500;&#21644;&#35266;&#23519;&#21040;&#30340;&#27169;&#24577;&#30340;&#26368;&#22823;&#20449;&#24687;&#65292;&#29992;&#20110;&#24773;&#24863;&#39044;&#27979;&#12290;&#22312;&#19977;&#20010;&#20844;&#24320;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#30456;&#23545;&#20110;&#22522;&#32447;&#31639;&#27861;&#30340;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#23454;&#29616;&#20102;&#19982;&#20855;&#26377;&#23436;&#25972;&#22810;&#27169;&#24577;&#30417;&#30563;&#30340;&#20808;&#21069;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal sentiment analysis aims to identify the emotions expressed by individuals through visual, language, and acoustic cues. However, most of the existing research efforts assume that all modalities are available during both training and testing, making their algorithms susceptible to the missing modality scenario. In this paper, we propose a novel knowledge-transfer network to translate between different modalities to reconstruct the missing audio modalities. Moreover, we develop a cross-modality attention mechanism to retain the maximal information of the reconstructed and observed modalities for sentiment prediction. Extensive experiments on three publicly available datasets demonstrate significant improvements over baselines and achieve comparable results to the previous methods with complete multi-modality supervision.
&lt;/p&gt;</description></item><item><title>&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;AI&#30340;&#33258;&#21160;&#23398;&#29983;&#21453;&#39304;&#26694;&#26550;&#21487;&#20197;&#25552;&#20379;&#20016;&#23500;&#30340;&#21453;&#39304;&#65292;&#20294;&#24341;&#20837;&#20102;&#20262;&#29702;&#38382;&#39064;&#65292;&#24182;&#38656;&#35201;&#35299;&#20915;&#8220;&#22810;&#25968;&#20154;&#30340;&#26292;&#25919;&#8221;&#21644;&#24573;&#35270;&#38271;&#23614;&#20013;&#23569;&#25968;&#32676;&#20307;&#38656;&#27714;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.15334</link><description>&lt;p&gt;
&#19968;&#31181;&#36127;&#36131;&#20219;&#24320;&#21457;&#22522;&#20110;&#29983;&#25104;AI&#30340;&#33258;&#21160;&#23398;&#29983;&#21453;&#39304;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Framework for Responsible Development of Automated Student Feedback with Generative AI. (arXiv:2308.15334v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15334
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;AI&#30340;&#33258;&#21160;&#23398;&#29983;&#21453;&#39304;&#26694;&#26550;&#21487;&#20197;&#25552;&#20379;&#20016;&#23500;&#30340;&#21453;&#39304;&#65292;&#20294;&#24341;&#20837;&#20102;&#20262;&#29702;&#38382;&#39064;&#65292;&#24182;&#38656;&#35201;&#35299;&#20915;&#8220;&#22810;&#25968;&#20154;&#30340;&#26292;&#25919;&#8221;&#21644;&#24573;&#35270;&#38271;&#23614;&#20013;&#23569;&#25968;&#32676;&#20307;&#38656;&#27714;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#20016;&#23500;&#30340;&#21453;&#39304;&#23545;&#20110;&#25903;&#25345;&#23398;&#29983;&#23398;&#20064;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#29983;&#25104;AI&#23588;&#20854;&#26159;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#36827;&#23637;&#65292;&#20026;&#21521;&#23398;&#29983;&#25552;&#20379;&#21487;&#37325;&#22797;&#12289;&#21487;&#25193;&#23637;&#21644;&#21363;&#26102;&#29983;&#25104;&#30340;&#33258;&#21160;&#21453;&#39304;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#20351;&#24471;&#20043;&#21069;&#31232;&#32570;&#19988;&#26114;&#36149;&#30340;&#23398;&#20064;&#36164;&#28304;&#21464;&#24471;&#20016;&#23500;&#36215;&#26469;&#12290;&#20174;&#25216;&#26415;&#35282;&#24230;&#32780;&#35328;&#65292;&#36825;&#31181;&#26041;&#27861;&#26159;&#21487;&#34892;&#30340;&#65292;&#24471;&#30410;&#20110;&#26368;&#36817;&#20154;&#24037;&#26234;&#33021;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#36827;&#27493;&#65307;&#28982;&#32780;&#65292;&#37319;&#29992;&#36825;&#20123;&#25216;&#26415;&#20063;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#28508;&#22312;&#30340;&#20262;&#29702;&#38382;&#39064;&#65292;&#38656;&#35201;&#35748;&#30495;&#32771;&#34385;&#12290;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#21560;&#24341;&#21147;&#22312;&#20110;&#23427;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#33258;&#21160;&#21270;&#26368;&#20047;&#21619;&#30340;&#20219;&#21153;&#65307;&#20294;&#26159;&#36825;&#20063;&#21487;&#33021;&#23548;&#33268;&#8220;&#22810;&#25968;&#20154;&#30340;&#26292;&#25919;&#8221;&#65292;&#21363;&#24573;&#35270;&#20102;&#38271;&#23614;&#20013;&#23569;&#25968;&#32676;&#20307;&#30340;&#38656;&#27714;&#65292;&#22240;&#20026;&#36825;&#20123;&#38656;&#27714;&#24456;&#38590;&#33258;&#21160;&#21270;&#12290;&#22240;&#27492;&#65292;&#24320;&#21457;&#33021;&#22815;&#20135;&#29983;&#26377;&#20215;&#20540;&#21644;&#30495;&#23454;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Providing rich feedback to students is essential for supporting student learning. Recent advances in generative AI, particularly within large language modelling (LLM), provide the opportunity to deliver repeatable, scalable and instant automatically generated feedback to students, making abundant a previously scarce and expensive learning resource. Such an approach is feasible from a technical perspective due to these recent advances in Artificial Intelligence (AI) and Natural Language Processing (NLP); while the potential upside is a strong motivator, doing so introduces a range of potential ethical issues that must be considered as we apply these technologies. The attractiveness of AI systems is that they can effectively automate the most mundane tasks; but this risks introducing a "tyranny of the majority", where the needs of minorities in the long tail are overlooked because they are difficult to automate.  Developing machine learning models that can generate valuable and authentic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#30340;&#20027;&#39064;&#21457;&#29616;&#26041;&#27861;&#65292;&#23558;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#26469;&#33258;&#36755;&#20837;&#35821;&#26009;&#24211;&#30340;&#23616;&#37096;&#35821;&#20041;&#30456;&#32467;&#21512;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#20027;&#39064;&#36830;&#36143;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.01845</link><description>&lt;p&gt;
&#24102;&#26377;&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#30340;&#20027;&#39064;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds. (arXiv:2205.01845v1 [cs.CL] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.01845
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#30340;&#20027;&#39064;&#21457;&#29616;&#26041;&#27861;&#65292;&#23558;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#26469;&#33258;&#36755;&#20837;&#35821;&#26009;&#24211;&#30340;&#23616;&#37096;&#35821;&#20041;&#30456;&#32467;&#21512;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#20027;&#39064;&#36830;&#36143;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#24180;&#26469;&#65292;&#20174;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#21457;&#29616;&#28508;&#22312;&#20027;&#39064;&#19968;&#30452;&#26159;&#30740;&#31350;&#30340;&#35838;&#39064;&#12290;&#35768;&#22810;&#29616;&#26377;&#30340;&#20027;&#39064;&#27169;&#22411;&#37319;&#29992;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#35774;&#32622;&#65292;&#30001;&#20110;&#23427;&#20204;&#26080;&#27861;&#21033;&#29992;&#29992;&#25143;&#25351;&#23548;&#65292;&#25152;&#20197;&#23427;&#20204;&#21457;&#29616;&#30340;&#20027;&#39064;&#21487;&#33021;&#19981;&#31526;&#21512;&#29992;&#25143;&#30340;&#29305;&#23450;&#20852;&#36259;&#12290;&#34429;&#28982;&#23384;&#22312;&#21033;&#29992;&#29992;&#25143;&#25552;&#20379;&#30340;&#31181;&#23376;&#35789;&#26469;&#21457;&#29616;&#20027;&#39064;&#20195;&#34920;&#35789;&#30340;&#31181;&#23376;&#24341;&#23548;&#20027;&#39064;&#21457;&#29616;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#36739;&#23569;&#20851;&#27880;&#20004;&#20010;&#22240;&#32032;&#65306;(1)&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#30340;&#23384;&#22312;&#21644;(2)&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#31181;&#23376;&#24341;&#23548;&#20027;&#39064;&#21457;&#29616;&#30340;&#20219;&#21153;&#25512;&#24191;&#21040;&#20801;&#35768;&#26410;&#30331;&#24405;&#35789;&#31181;&#23376;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;SeeTopic&#65292;&#22312;&#20854;&#20013;PLM&#30340;&#36890;&#29992;&#30693;&#35782;&#21644;&#20174;&#36755;&#20837;&#35821;&#26009;&#24211;&#20013;&#23398;&#20064;&#30340;&#23616;&#37096;&#35821;&#20041;&#21487;&#20197;&#30456;&#20114;&#21463;&#30410;&#12290;&#22312;&#26469;&#33258;&#19981;&#21516;&#39046;&#22495;&#30340;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;SeeTopic&#22312;&#20027;&#39064;&#36830;&#36143;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering latent topics from text corpora has been studied for decades. Many existing topic models adopt a fully unsupervised setting, and their discovered topics may not cater to users' particular interests due to their inability of leveraging user guidance. Although there exist seed-guided topic discovery approaches that leverage user-provided seeds to discover topic-representative terms, they are less concerned with two factors: (1) the existence of out-of-vocabulary seeds and (2) the power of pre-trained language models (PLMs). In this paper, we generalize the task of seed-guided topic discovery to allow out-of-vocabulary seeds. We propose a novel framework, named SeeTopic, wherein the general knowledge of PLMs and the local semantics learned from the input corpus can mutually benefit each other. Experiments on three real datasets from different domains demonstrate the effectiveness of SeeTopic in terms of topic coherence, accuracy, and diversity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22269;&#23478;&#26377;&#32447;&#30005;&#35270;&#26032;&#38395;&#23545;&#32654;&#22269;&#26412;&#22303;&#25253;&#32440;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24403;&#22320;&#25253;&#32440;&#30340;&#20869;&#23481;&#20250;&#22240;&#20026;&#24403;&#22320; FNC &#35266;&#20247;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#36235;&#21521;&#20110; FNC &#30340;&#20542;&#21521;&#65292;&#24182;&#19988;&#26377;&#32447;&#30005;&#35270;&#20542;&#21521;&#20250;&#26497;&#21270;&#22320;&#26041;&#26032;&#38395;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2202.07269</link><description>&lt;p&gt;
&#23186;&#20307;&#20542;&#21521;&#26159;&#20855;&#26377;&#20256;&#26579;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Media Slant is Contagious. (arXiv:2202.07269v2 [econ.GN] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.07269
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22269;&#23478;&#26377;&#32447;&#30005;&#35270;&#26032;&#38395;&#23545;&#32654;&#22269;&#26412;&#22303;&#25253;&#32440;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24403;&#22320;&#25253;&#32440;&#30340;&#20869;&#23481;&#20250;&#22240;&#20026;&#24403;&#22320; FNC &#35266;&#20247;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#36235;&#21521;&#20110; FNC &#30340;&#20542;&#21521;&#65292;&#24182;&#19988;&#26377;&#32447;&#30005;&#35270;&#20542;&#21521;&#20250;&#26497;&#21270;&#22320;&#26041;&#26032;&#38395;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#23186;&#20307;&#20542;&#21521;&#30340;&#20256;&#25773;&#65292;&#20855;&#20307;&#26469;&#35828;&#26159;&#22269;&#23478;&#26377;&#32447;&#30005;&#35270;&#26032;&#38395;&#23545;&#32654;&#22269;&#26412;&#22303;&#25253;&#32440;&#65288;2005-2008&#65289;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#22522;&#20110; Fox News Channel&#65288;FNC&#65289;&#12289;CNN &#21644; MSNBC &#20869;&#23481;&#30340;&#26377;&#32447;&#30005;&#35270;&#20542;&#21521;&#25991;&#26412;&#24230;&#37327;&#26041;&#27861;&#65292;&#20998;&#26512;&#22320;&#26041;&#25253;&#32440;&#22914;&#20309;&#37319;&#29992; FNC &#30340;&#20542;&#21521;&#32780;&#19981;&#26159; CNN/MSNBC &#30340;&#20542;&#21521;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#22320;&#26041;&#26032;&#38395;&#38543;&#30528;&#24403;&#22320; FNC &#35266;&#20247;&#20154;&#25968;&#30340;&#22806;&#37096;&#22686;&#38271;&#32780;&#21464;&#24471;&#26356;&#21152;&#31867;&#20284;&#20110; FNC &#30340;&#20869;&#23481;&#12290;&#36825;&#31181;&#36716;&#21464;&#19981;&#20165;&#38480;&#20110;&#20174;&#26377;&#32447;&#30005;&#35270;&#20511;&#37492;&#65292;&#32780;&#26159;&#22320;&#26041;&#25253;&#32440;&#33258;&#36523;&#20869;&#23481;&#30340;&#25913;&#21464;&#12290;&#27492;&#22806;&#65292;&#26377;&#32447;&#30005;&#35270;&#20542;&#21521;&#26497;&#21270;&#20102;&#22320;&#26041;&#26032;&#38395;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the diffusion of media slant, specifically how partisan content from national cable news affects local newspapers in the U.S., 2005-2008. We use a text-based measure of cable news slant trained on content from Fox News Channel (FNC), CNN, and MSNBC to analyze how local newspapers adopt FNC's slant over CNN/MSNBC's. Our findings show that local news becomes more similar to FNC content in response to an exogenous increase in local FNC viewership. This shift is not limited to borrowing from cable news, but rather, local newspapers' own content changes. Further, cable TV slant polarizes local news content.
&lt;/p&gt;</description></item></channel></rss>