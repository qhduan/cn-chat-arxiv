<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#28145;&#20837;&#35780;&#20272;&#20102;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#65292;&#25351;&#20986;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#20173;&#26377;&#24453;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.04963</link><description>&lt;p&gt;
&#22312;&#22522;&#20110;&#38169;&#35823;&#30340;&#20154;&#31867;&#35780;&#20272;&#20013;&#28145;&#20837;&#35780;&#20272;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#35780;&#20272;&#20102;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#65292;&#25351;&#20986;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#20173;&#26377;&#24453;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21477;&#23376;&#31616;&#21270;&#26159;&#19968;&#31181;&#37325;&#20889;&#21477;&#23376;&#20197;&#20415;&#26356;&#26131;&#38405;&#35835;&#21644;&#29702;&#35299;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#24110;&#21161;&#26377;&#21508;&#31181;&#38405;&#35835;&#38590;&#39064;&#30340;&#20154;&#26469;&#35828;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;&#38543;&#30528;&#20808;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20852;&#36215;&#65292;&#35780;&#20272;&#23427;&#20204;&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#21464;&#24471;&#36843;&#22312;&#30473;&#30571;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21033;&#29992;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26469;&#35780;&#20272;LLMs&#30340;&#31616;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#35780;&#20272;&#26041;&#27861;&#23545;LLMs&#22312;&#31616;&#21270;&#35780;&#20272;&#20013;&#30340;&#36866;&#29992;&#24615;&#20173;&#28982;&#23384;&#22312;&#30097;&#38382;&#12290;&#39318;&#20808;&#65292;&#29616;&#26377;&#33258;&#21160;&#25351;&#26631;&#22312;LLMs&#30340;&#31616;&#21270;&#35780;&#20272;&#20013;&#30340;&#36866;&#29992;&#24615;&#20173;&#19981;&#30830;&#23450;&#12290;&#20854;&#27425;&#65292;&#24403;&#21069;&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#36890;&#24120;&#38519;&#20837;&#20004;&#20010;&#26497;&#31471;&#65306;&#35201;&#20040;&#36807;&#20110;&#32932;&#27973;&#65292;&#26080;&#27861;&#28165;&#26224;&#29702;&#35299;&#27169;&#22411;&#30340;&#34920;&#29616;&#65292;&#35201;&#20040;&#36807;&#20110;&#35814;&#32454;&#65292;&#20351;&#27880;&#37322;&#36807;&#31243;&#22797;&#26434;&#19988;&#23481;&#26131;&#20986;&#29616;&#19981;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#24433;&#21709;&#35780;&#20272;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04963v1 Announce Type: cross  Abstract: Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs' simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models' performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation's reliabil
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;PhaseEvo&#65292;&#19968;&#20010;&#26088;&#22312;&#23454;&#29616;&#25552;&#31034;&#25351;&#20196;&#21644;&#31034;&#20363;&#30340;&#32852;&#21512;&#20248;&#21270;&#30340;&#39640;&#25928;&#33258;&#21160;&#25552;&#31034;&#20248;&#21270;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;LLMs&#30340;&#29983;&#25104;&#33021;&#21147;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#20840;&#23616;&#25628;&#32034;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.11347</link><description>&lt;p&gt;
PhaseEvo&#65306;&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#32479;&#19968;&#19978;&#19979;&#25991;&#25552;&#31034;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11347
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;PhaseEvo&#65292;&#19968;&#20010;&#26088;&#22312;&#23454;&#29616;&#25552;&#31034;&#25351;&#20196;&#21644;&#31034;&#20363;&#30340;&#32852;&#21512;&#20248;&#21270;&#30340;&#39640;&#25928;&#33258;&#21160;&#25552;&#31034;&#20248;&#21270;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;LLMs&#30340;&#29983;&#25104;&#33021;&#21147;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#20840;&#23616;&#25628;&#32034;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21046;&#23450;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#29702;&#24819;&#25552;&#31034;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#38656;&#35201;&#26174;&#33879;&#30340;&#36164;&#28304;&#21644;&#19987;&#19994;&#20154;&#21592;&#30340;&#36755;&#20837;&#12290;&#29616;&#26377;&#24037;&#20316;&#23558;&#20248;&#21270;&#25552;&#31034;&#25351;&#20196;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#31034;&#20363;&#35270;&#20026;&#19981;&#21516;&#38382;&#39064;&#65292;&#23548;&#33268;&#25552;&#31034;&#24615;&#33021;&#27425;&#20248;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#32479;&#19968;&#30340;&#19978;&#19979;&#25991;&#25552;&#31034;&#20248;&#21270;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#19968;&#23616;&#38480;&#24615;&#65292;&#26088;&#22312;&#23454;&#29616;&#25552;&#31034;&#25351;&#20196;&#21644;&#31034;&#20363;&#30340;&#32852;&#21512;&#20248;&#21270;&#12290;&#28982;&#32780;&#65292;&#22312;&#31163;&#25955;&#19988;&#39640;&#32500;&#30340;&#33258;&#28982;&#35821;&#35328;&#31354;&#38388;&#20013;&#21046;&#23450;&#36825;&#31181;&#20248;&#21270;&#24341;&#20837;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PhaseEvo&#65292;&#36825;&#26159;&#19968;&#20010;&#32467;&#21512;&#20102;LLMs&#30340;&#29983;&#25104;&#33021;&#21147;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#20840;&#23616;&#25628;&#32034;&#25928;&#29575;&#30340;&#39640;&#25928;&#33258;&#21160;&#25552;&#31034;&#20248;&#21270;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#37319;&#29992;&#22810;&#38454;&#27573;&#35774;&#35745;&#65292;&#34701;&#21512;&#20102;&#21019;&#26032;&#30340;&#22522;&#20110;LLMs&#30340;&#21464;&#24322;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11347v1 Announce Type: new  Abstract: Crafting an ideal prompt for Large Language Models (LLMs) is a challenging task that demands significant resources and expert human input. Existing work treats the optimization of prompt instruction and in-context learning examples as distinct problems, leading to sub-optimal prompt performance. This research addresses this limitation by establishing a unified in-context prompt optimization framework, which aims to achieve joint optimization of the prompt instruction and examples. However, formulating such optimization in the discrete and high-dimensional natural language space introduces challenges in terms of convergence and computational efficiency. To overcome these issues, we present PhaseEvo, an efficient automatic prompt optimization framework that combines the generative capability of LLMs with the global search proficiency of evolution algorithms. Our framework features a multi-phase design incorporating innovative LLM-based mut
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#39064;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#23545;&#25968;&#20284;&#28982;&#30340;&#35777;&#25454;&#19979;&#30028;&#21644;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#30340;&#21152;&#26435;&#32447;&#24615;&#32452;&#21512;&#65292;&#23558;&#23545;&#27604;&#20027;&#39064;&#24314;&#27169;&#20316;&#20026;&#19968;&#31181;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#33719;&#24471;&#33021;&#22815;&#25429;&#25417;&#20849;&#20139;&#35821;&#20041;&#24182;&#20811;&#26381;&#20302;&#32423;&#21035;&#20114;&#20449;&#24687;&#24178;&#25200;&#30340;&#20027;&#39064;&#21521;&#37327;&#38598;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.07577</link><description>&lt;p&gt;
&#20027;&#39064;&#24314;&#27169;&#20316;&#20026;&#22810;&#30446;&#26631;&#23545;&#27604;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Topic Modeling as Multi-Objective Contrastive Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07577
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#39064;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#23545;&#25968;&#20284;&#28982;&#30340;&#35777;&#25454;&#19979;&#30028;&#21644;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#30340;&#21152;&#26435;&#32447;&#24615;&#32452;&#21512;&#65292;&#23558;&#23545;&#27604;&#20027;&#39064;&#24314;&#27169;&#20316;&#20026;&#19968;&#31181;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#33719;&#24471;&#33021;&#22815;&#25429;&#25417;&#20849;&#20139;&#35821;&#20041;&#24182;&#20811;&#26381;&#20302;&#32423;&#21035;&#20114;&#20449;&#24687;&#24178;&#25200;&#30340;&#20027;&#39064;&#21521;&#37327;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#23545;&#25968;&#20284;&#28982;&#30340;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#21644;&#23545;&#27604;&#23398;&#20064;&#30446;&#26631;&#30340;&#21152;&#26435;&#32447;&#24615;&#32452;&#21512;&#26469;&#22686;&#24378;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#25991;&#26723;&#32423;&#23545;&#27604;&#23398;&#20064;&#21487;&#33021;&#25429;&#25417;&#21040;&#20302;&#32423;&#21035;&#30340;&#20114;&#20449;&#24687;&#65292;&#20363;&#22914;&#35789;&#27604;&#20363;&#65292;&#36825;&#20250;&#24178;&#25200;&#20027;&#39064;&#24314;&#27169;&#12290;&#27492;&#22806;&#65292;ELBO&#25439;&#22833;&#26088;&#22312;&#35760;&#24518;&#36755;&#20837;&#32454;&#33410;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#37325;&#26500;&#36136;&#37327;&#65292;&#32780;&#23545;&#27604;&#25439;&#22833;&#21017;&#35797;&#22270;&#23398;&#20064;&#22312;&#36755;&#20837;&#25991;&#26723;&#20043;&#38388;&#27867;&#21270;&#30340;&#20027;&#39064;&#34920;&#31034;&#65292;&#20108;&#32773;&#23384;&#22312;&#28508;&#22312;&#20914;&#31361;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#39318;&#20808;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38754;&#21521;&#20027;&#39064;&#21521;&#37327;&#38598;&#21512;&#30340;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#25429;&#25417;&#19968;&#32452;&#36755;&#20837;&#25991;&#26723;&#20043;&#38388;&#20849;&#20139;&#30340;&#26377;&#29992;&#35821;&#20041;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23558;&#23545;&#27604;&#20027;&#39064;&#24314;&#27169;&#26126;&#30830;&#25552;&#20986;&#20026;&#19968;&#20010;&#22522;&#20110;&#26799;&#24230;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#23454;&#29616;&#24085;&#32047;&#25176;&#24179;&#31283;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent representation learning approaches enhance neural topic models by optimizing the weighted linear combination of the evidence lower bound (ELBO) of the log-likelihood and the contrastive learning objective that contrasts pairs of input documents. However, document-level contrastive learning might capture low-level mutual information, such as word ratio, which disturbs topic modeling. Moreover, there is a potential conflict between the ELBO loss that memorizes input details for better reconstruction quality, and the contrastive loss which attempts to learn topic representations that generalize among input documents. To address these issues, we first introduce a novel contrastive learning method oriented towards sets of topic vectors to capture useful semantics that are shared among a set of input documents. Secondly, we explicitly cast contrastive topic modeling as a gradient-based multi-objective optimization problem, with the goal of achieving a Pareto stationary solution that b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#20998;&#31867;&#20013;&#21333;&#35789;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#20197;&#35780;&#20272;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;SP-Attack&#21644;SP-Defense&#26041;&#27861;&#26469;&#38024;&#23545;&#21333;&#35789;&#25200;&#21160;&#36827;&#34892;&#25915;&#20987;&#21644;&#38450;&#24481;&#65292;&#23454;&#29616;&#26356;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#21644;&#26356;&#22909;&#30340;&#21477;&#23376;&#21547;&#20041;&#20445;&#25345;&#12290;</title><link>https://arxiv.org/abs/2401.17196</link><description>&lt;p&gt;
&#19968;&#20010;&#21333;&#35789;&#30340;&#25913;&#21464;&#21363;&#21487;&#65306;&#20026;&#25991;&#26412;&#20998;&#31867;&#22120;&#35774;&#35745;&#25915;&#20987;&#19982;&#38450;&#24481;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17196
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#20998;&#31867;&#20013;&#21333;&#35789;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#20197;&#35780;&#20272;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;SP-Attack&#21644;SP-Defense&#26041;&#27861;&#26469;&#38024;&#23545;&#21333;&#35789;&#25200;&#21160;&#36827;&#34892;&#25915;&#20987;&#21644;&#38450;&#24481;&#65292;&#23454;&#29616;&#26356;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#21644;&#26356;&#22909;&#30340;&#21477;&#23376;&#21547;&#20041;&#20445;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25991;&#26412;&#20998;&#31867;&#20013;&#65292;&#21019;&#24314;&#23545;&#25239;&#26679;&#26412;&#24847;&#21619;&#30528;&#22312;&#21477;&#23376;&#20013;&#24494;&#22937;&#22320;&#25200;&#21160;&#20960;&#20010;&#21333;&#35789;&#32780;&#19981;&#25913;&#21464;&#20854;&#21547;&#20041;&#65292;&#23548;&#33268;&#20998;&#31867;&#22120;&#38169;&#35823;&#20998;&#31867;&#12290;&#20196;&#20154;&#25285;&#24551;&#30340;&#26159;&#65292;&#29616;&#26377;&#26041;&#27861;&#29983;&#25104;&#30340;&#23545;&#25239;&#26679;&#26412;&#20013;&#26377;&#30456;&#24403;&#37096;&#20998;&#21482;&#25913;&#21464;&#20102;&#19968;&#20010;&#21333;&#35789;&#12290;&#36825;&#31181;&#21333;&#35789;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#20195;&#34920;&#20102;&#20998;&#31867;&#22120;&#30340;&#19968;&#20010;&#37325;&#22823;&#24369;&#28857;&#65292;&#24694;&#24847;&#29992;&#25143;&#21487;&#20197;&#21033;&#29992;&#23427;&#39640;&#25928;&#22320;&#21019;&#24314;&#22823;&#37327;&#23545;&#25239;&#26679;&#26412;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#24182;&#20316;&#20986;&#20102;&#20197;&#19979;&#20851;&#38190;&#36129;&#29486;&#65306;(1) &#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631; \r{ho} &#26469;&#23450;&#37327;&#35780;&#20272;&#20998;&#31867;&#22120;&#23545;&#20110;&#21333;&#35789;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;(2) &#25105;&#20204;&#25552;&#20986;&#20102; SP-Attack&#65292;&#26088;&#22312;&#21033;&#29992;&#21333;&#35789;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#65292;&#23454;&#29616;&#26356;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#26356;&#22909;&#22320;&#20445;&#25345;&#21477;&#23376;&#30340;&#21547;&#20041;&#65292;&#21516;&#26102;&#38477;&#20302;&#19982;&#29616;&#26377;&#23545;&#25239;&#26041;&#27861;&#30456;&#27604;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;(3) &#25105;&#20204;&#25552;&#20986;&#20102; SP-Defense&#65292;&#26088;&#22312;&#25913;&#36827;&#20998;&#31867;&#22120;&#30340;&#25269;&#25239;&#21333;&#35789;&#25200;&#21160;&#30340;&#33021;&#21147;&#65292;&#20943;&#23567;&#25915;&#20987;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In text classification, creating an adversarial example means subtly perturbing a few words in a sentence without changing its meaning, causing it to be misclassified by a classifier. A concerning observation is that a significant portion of adversarial examples generated by existing methods change only one word. This single-word perturbation vulnerability represents a significant weakness in classifiers, which malicious users can exploit to efficiently create a multitude of adversarial examples. This paper studies this problem and makes the following key contributions: (1) We introduce a novel metric \r{ho} to quantitatively assess a classifier's robustness against single-word perturbation. (2) We present the SP-Attack, designed to exploit the single-word perturbation vulnerability, achieving a higher attack success rate, better preserving sentence meaning, while reducing computation costs compared to state-of-the-art adversarial methods. (3) We propose SP-Defense, which aims to impro
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;Cascade Speculative Drafting&#65288;CS Drafting&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#22402;&#30452;&#32423;&#32852;&#28040;&#38500;&#31070;&#32463;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#29983;&#25104;&#65292;&#36890;&#36807;&#27700;&#24179;&#32423;&#32852;&#20248;&#21270;&#33609;&#31295;&#20013;&#30340;&#26102;&#38388;&#20998;&#37197;&#65292;&#20174;&#32780;&#36827;&#19968;&#27493;&#25552;&#39640;LLM&#25512;&#29702;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2312.11462</link><description>&lt;p&gt;
&#29992;&#20110;&#26356;&#24555;&#30340;LLM&#25512;&#29702;&#30340;&#32423;&#32852;&#25512;&#27979;&#33609;&#22270;
&lt;/p&gt;
&lt;p&gt;
Cascade Speculative Drafting for Even Faster LLM Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.11462
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;Cascade Speculative Drafting&#65288;CS Drafting&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#22402;&#30452;&#32423;&#32852;&#28040;&#38500;&#31070;&#32463;&#27169;&#22411;&#30340;&#33258;&#22238;&#24402;&#29983;&#25104;&#65292;&#36890;&#36807;&#27700;&#24179;&#32423;&#32852;&#20248;&#21270;&#33609;&#31295;&#20013;&#30340;&#26102;&#38388;&#20998;&#37197;&#65292;&#20174;&#32780;&#36827;&#19968;&#27493;&#25552;&#39640;LLM&#25512;&#29702;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25512;&#29702;&#25928;&#29575;&#30340;&#32423;&#32852;&#25512;&#27979;&#33609;&#22270;&#65292;&#36890;&#36807;&#36739;&#23567;&#30340;&#27169;&#22411;&#29983;&#25104;&#33609;&#31295;&#26469;&#36816;&#20316;&#12290;&#36739;&#22823;&#30340;&#30446;&#26631;&#27169;&#22411;&#28982;&#21518;&#26597;&#30475;&#36825;&#20010;&#33609;&#31295;&#20197;&#19982;&#20854;&#36755;&#20986;&#23545;&#40784;&#65292;&#30446;&#26631;&#27169;&#22411;&#30340;&#20219;&#20309;&#25509;&#21463;&#37117;&#23558;&#20943;&#23569;&#30446;&#26631;&#27169;&#22411;&#36816;&#34892;&#30340;&#25968;&#37327;&#65292;&#20174;&#32780;&#25552;&#39640;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#22312;&#32423;&#32852;&#25512;&#27979;&#30340;&#33609;&#22270;&#36807;&#31243;&#20013;&#21253;&#25324;&#32531;&#24930;&#30340;&#33258;&#22238;&#24402;&#29983;&#25104;&#65292;&#24182;&#20026;&#29983;&#25104;&#30340;&#26631;&#35760;&#20998;&#37197;&#30456;&#21516;&#30340;&#26102;&#38388;&#65292;&#32780;&#19981;&#32771;&#34385;&#23427;&#20204;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#20123;&#20302;&#25928;&#24615;&#20849;&#21516;&#23548;&#33268;&#32423;&#32852;&#25512;&#27979;&#30340;&#24615;&#33021;&#19981;&#20339;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25913;&#21892;LLM&#25512;&#29702;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32423;&#32852;&#25512;&#27979;&#33609;&#22270;&#65288;CS Drafting&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#25972;&#21512;&#20102;&#20004;&#31181;&#32423;&#32852;&#31867;&#22411;&#30340;&#25512;&#27979;&#25191;&#34892;&#31639;&#27861;&#12290;&#22402;&#30452;&#32423;&#32852;&#20174;&#31070;&#32463;&#27169;&#22411;&#20013;&#28040;&#38500;&#33258;&#22238;&#24402;&#29983;&#25104;&#65292;&#32780;&#27700;&#24179;&#32423;&#32852;&#20248;&#21270;&#20102;&#33609;&#31295;&#20013;&#30340;&#26102;&#38388;&#20998;&#37197;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.11462v3 Announce Type: replace-cross  Abstract: Introduced to enhance the efficiency of large language model (LLM) inference, speculative decoding operates by having a smaller model generate a draft. A larger target model then reviews this draft to align with its output, and any acceptance by the target model results in a reduction of the number of the target model runs, ultimately improving efficiency. However, the drafting process in speculative decoding includes slow autoregressive generation and allocates equal time to generating tokens, irrespective of their importance. These inefficiencies collectively contribute to the suboptimal performance of speculative decoding. To further improve LLM inference, we introduce Cascade Speculative Drafting (CS Drafting), a speculative execution algorithm that incorporates two types of cascades. The Vertical Cascade eliminates autoregressive generation from neural models, while the Horizontal Cascade optimizes time allocation in draft
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24433;&#21709;&#39537;&#21160;&#30340;&#36873;&#25321;&#24615;&#27880;&#37322;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25913;&#21892;&#19978;&#19979;&#25991;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#36873;&#25321;&#20851;&#38190;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#23376;&#38598;&#36827;&#34892;&#27880;&#37322;&#65292;&#22312;&#38477;&#20302;&#27880;&#37322;&#25104;&#26412;&#30340;&#21516;&#26102;&#25552;&#39640;&#20102;&#19978;&#19979;&#25991;&#31034;&#20363;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.10873</link><description>&lt;p&gt;
IDEAL: &#24378;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#24433;&#21709;&#39537;&#21160;&#36873;&#25321;&#24615;&#27880;&#37322;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models. (arXiv:2310.10873v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10873
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24433;&#21709;&#39537;&#21160;&#30340;&#36873;&#25321;&#24615;&#27880;&#37322;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25913;&#21892;&#19978;&#19979;&#25991;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#36873;&#25321;&#20851;&#38190;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#23376;&#38598;&#36827;&#34892;&#27880;&#37322;&#65292;&#22312;&#38477;&#20302;&#27880;&#37322;&#25104;&#26412;&#30340;&#21516;&#26102;&#25552;&#39640;&#20102;&#19978;&#19979;&#25991;&#31034;&#20363;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#23398;&#20064;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#33539;&#24335;&#65292;&#23427;&#21033;&#29992;&#19978;&#19979;&#25991;&#31034;&#20363;&#20316;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39044;&#27979;&#30340;&#25552;&#31034;&#12290;&#36825;&#20123;&#25552;&#31034;&#23545;&#20110;&#33719;&#24471;&#24378;&#22823;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#20123;&#25552;&#31034;&#38656;&#35201;&#20174;&#22823;&#37327;&#27880;&#37322;&#30340;&#31034;&#20363;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#25214;&#21040;&#27491;&#30830;&#30340;&#25552;&#31034;&#21487;&#33021;&#23548;&#33268;&#39640;&#26114;&#30340;&#27880;&#37322;&#25104;&#26412;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#24433;&#21709;&#39537;&#21160;&#30340;&#36873;&#25321;&#24615;&#27880;&#37322;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#25913;&#21892;&#19978;&#19979;&#25991;&#31034;&#20363;&#36136;&#37327;&#30340;&#21516;&#26102;&#26368;&#22823;&#31243;&#24230;&#22320;&#38477;&#20302;&#27880;&#37322;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#20174;&#22823;&#35268;&#27169;&#26410;&#26631;&#35760;&#30340;&#25968;&#25454;&#27744;&#20013;&#36873;&#25321;&#19968;&#20010;&#20851;&#38190;&#23376;&#38598;&#36827;&#34892;&#27880;&#37322;&#65292;&#20197;&#29992;&#20110;&#21518;&#32493;&#30340;&#25552;&#31034;&#37319;&#26679;&#12290;&#20855;&#20307;&#22320;&#65292;&#39318;&#20808;&#26500;&#24314;&#19968;&#20010;&#26377;&#21521;&#22270;&#26469;&#34920;&#31034;&#26410;&#26631;&#35760;&#30340;&#25968;&#25454;&#65292;&#28982;&#21518;&#21033;&#29992;&#25193;&#25955;&#36807;&#31243;&#37327;&#21270;&#20505;&#36873;&#26410;&#26631;&#35760;&#23376;&#38598;&#30340;&#24433;&#21709;&#21147;&#65292;&#26368;&#21518;&#24341;&#20837;&#19968;&#20010;&#31616;&#21333;&#21448;&#26377;&#25928;&#30340;&#36138;&#24515;&#31639;&#27861;&#26469;&#36873;&#25321;&#26410;&#26631;&#35760;&#30340;&#25968;&#25454;&#12290;&#22914;&#26524;&#25968;&#25454;&#25552;&#20379;&#20102;&#26368;&#22823;&#30340;&#24433;&#21709;&#21147;&#65292;&#31639;&#27861;&#23601;&#20250;&#36845;&#20195;&#22320;&#36873;&#25321;&#36825;&#20123;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In-context learning is a promising paradigm that utilizes in-context examples as prompts for the predictions of large language models. These prompts are crucial for achieving strong performance. However, since the prompts need to be sampled from a large volume of annotated examples, finding the right prompt may result in high annotation costs. To address this challenge, this paper introduces an influence-driven selective annotation method that aims to minimize annotation costs while improving the quality of in-context examples. The essence of our method is to select a pivotal subset from a large-scale unlabeled data pool to annotate for the subsequent sampling of prompts. Specifically, a directed graph is first constructed to represent unlabeled data. Afterward, the influence of candidate unlabeled subsets is quantified with a diffusion process. A simple yet effective greedy algorithm for unlabeled data selection is lastly introduced. It iteratively selects the data if it provides a ma
&lt;/p&gt;</description></item></channel></rss>