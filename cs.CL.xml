<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;&#65292;&#36890;&#36807;&#32534;&#36753;&#27169;&#22411;&#20869;&#37096;&#28608;&#27963;&#26469;&#25913;&#21892;CodeLLMs&#22312;&#20195;&#30721;&#31867;&#22411;&#39044;&#27979;&#20013;&#23545;&#20110;&#35821;&#27861;&#24178;&#25200;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#65292;&#23558;&#31867;&#22411;&#35823;&#24046;&#29575;&#32416;&#27491;&#39640;&#36798;90%&#12290;</title><link>https://arxiv.org/abs/2404.01903</link><description>&lt;p&gt;
&#22312;CodeLLMs&#20013;&#23454;&#29616;&#31867;&#22411;&#39044;&#27979;&#30340;&#40065;&#26834;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Activation Steering for Robust Type Prediction in CodeLLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01903
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#23548;&#21521;&#25216;&#26415;&#65292;&#36890;&#36807;&#32534;&#36753;&#27169;&#22411;&#20869;&#37096;&#28608;&#27963;&#26469;&#25913;&#21892;CodeLLMs&#22312;&#20195;&#30721;&#31867;&#22411;&#39044;&#27979;&#20013;&#23545;&#20110;&#35821;&#27861;&#24178;&#25200;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#65292;&#23558;&#31867;&#22411;&#35823;&#24046;&#29575;&#32416;&#27491;&#39640;&#36798;90%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#22312;&#20195;&#30721;&#19978;&#30340;&#29616;&#20195;LLMs&#33021;&#22815;&#25104;&#21151;&#22320;&#23436;&#25104;&#21508;&#31181;&#32534;&#31243;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#23545;&#35821;&#27861;&#29305;&#24449;&#38750;&#24120;&#25935;&#24863;&#65292;&#20363;&#22914;&#21464;&#37327;&#21644;&#31867;&#22411;&#30340;&#21517;&#31216;&#12289;&#20195;&#30721;&#32467;&#26500;&#20197;&#21450;&#31867;&#22411;&#25552;&#31034;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25512;&#29702;&#26102;&#25216;&#26415;&#65292;&#20351;CodeLLMs&#26356;&#33021;&#25269;&#24481;&#35821;&#27861;&#24178;&#25200;&#22240;&#32032;&#65292;&#36825;&#20123;&#22240;&#32032;&#19982;&#35821;&#20041;&#26080;&#20851;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#28608;&#27963;&#23548;&#21521;&#65292;&#28041;&#21450;&#32534;&#36753;&#20869;&#37096;&#27169;&#22411;&#28608;&#27963;&#20197;&#23558;&#27169;&#22411;&#24341;&#23548;&#21040;&#27491;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#20174;&#31361;&#21464;&#27979;&#35797;&#20013;&#27762;&#21462;&#28789;&#24863;&#26500;&#24314;&#28608;&#27963;&#21521;&#37327;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26500;&#24314;&#26368;&#23567;&#30340;&#30772;&#22351;&#35821;&#20041;&#30340;&#20195;&#30721;&#32534;&#36753;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#20174;&#20445;&#30041;&#35821;&#20041;&#30340;&#20195;&#30721;&#32534;&#36753;&#20013;&#26500;&#24314;&#28608;&#27963;&#21521;&#37327;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#36880;&#28176;&#31867;&#22411;&#21270;&#35821;&#35328;Python&#21644;TypeScript&#30340;&#31867;&#22411;&#39044;&#27979;&#20219;&#21153;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#32416;&#27491;&#39640;&#36798;90%&#30340;&#31867;&#22411;&#38169;&#35823;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01903v1 Announce Type: new  Abstract: Contemporary LLMs pretrained on code are capable of succeeding at a wide variety of programming tasks. However, their performance is very sensitive to syntactic features, such as the names of variables and types, the structure of code, and presence of type hints. We contribute an inference-time technique to make CodeLLMs more robust to syntactic distractors that are semantically irrelevant. Our methodology relies on activation steering, which involves editing internal model activations to steer the model towards the correct prediction. We contribute a novel way to construct steering vectors by taking inspiration from mutation testing, which constructs minimal semantics-breaking code edits. In contrast, we construct steering vectors from semantics-preserving code edits. We apply our approach to the task of type prediction for the gradually typed languages Python and TypeScript. This approach corrects up to 90% of type mispredictions. Fina
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#26032;&#30340;&#22810;&#35821;&#35328;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38754;&#23545;&#21508;&#31181;&#22122;&#22768;&#36755;&#20837;&#26102;&#27604;&#20808;&#21069;&#30340;&#27169;&#22411;&#26356;&#21152;&#31283;&#20581;&#65292;&#23613;&#31649;&#23427;&#20204;&#30340;&#21442;&#25968;&#26356;&#22810;&#12289;&#35757;&#32451;&#36807;&#31243;&#26356;&#22797;&#26434;&#65292;&#24182;&#19988;&#27809;&#26377;&#37319;&#29992;&#29305;&#23450;&#35774;&#35745;&#29992;&#20110;&#22686;&#24378;&#31283;&#20581;&#24615;&#30340;&#25216;&#26415;&#12290;</title><link>https://arxiv.org/abs/2403.03923</link><description>&lt;p&gt;
&#32763;&#35793;&#27169;&#22411;&#26159;&#21542;&#22312;&#26080;&#20154;&#21457;&#35273;&#30340;&#24773;&#20917;&#19979;&#21464;&#24471;&#26356;&#21152;&#31283;&#20581;&#20102;&#65311;
&lt;/p&gt;
&lt;p&gt;
Did Translation Models Get More Robust Without Anyone Even Noticing?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03923
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#26032;&#30340;&#22810;&#35821;&#35328;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38754;&#23545;&#21508;&#31181;&#22122;&#22768;&#36755;&#20837;&#26102;&#27604;&#20808;&#21069;&#30340;&#27169;&#22411;&#26356;&#21152;&#31283;&#20581;&#65292;&#23613;&#31649;&#23427;&#20204;&#30340;&#21442;&#25968;&#26356;&#22810;&#12289;&#35757;&#32451;&#36807;&#31243;&#26356;&#22797;&#26434;&#65292;&#24182;&#19988;&#27809;&#26377;&#37319;&#29992;&#29305;&#23450;&#35774;&#35745;&#29992;&#20110;&#22686;&#24378;&#31283;&#20581;&#24615;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#65288;MT&#65289;&#27169;&#22411;&#22312;&#21508;&#31181;&#22330;&#26223;&#20013;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#32467;&#26524;&#65292;&#20294;&#26222;&#36941;&#35748;&#20026;&#23427;&#20204;&#23545;"&#22024;&#26434;"&#36755;&#20837;&#65288;&#22914;&#25340;&#20889;&#38169;&#35823;&#12289;&#32553;&#20889;&#21644;&#20854;&#20182;&#26684;&#24335;&#38382;&#39064;&#65289;&#38750;&#24120;&#25935;&#24863;&#12290;&#26412;&#25991;&#38024;&#23545;&#26368;&#36817;&#30340;&#22810;&#35821;&#35328;MT&#27169;&#22411;&#21644;&#24212;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#37325;&#26032;&#23457;&#35270;&#36825;&#19968;&#35266;&#28857;&#12290;&#26377;&#20123;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#36890;&#36807;&#21463;&#25511;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#20123;&#27169;&#22411;&#23545;&#35768;&#22810;&#31181;&#22122;&#22768;&#27604;&#20808;&#21069;&#30340;&#27169;&#22411;&#26356;&#21152;&#31283;&#20581;&#65292;&#21363;&#20351;&#22312;&#24178;&#20928;&#25968;&#25454;&#19978;&#34920;&#29616;&#31867;&#20284;&#12290;&#36825;&#24456;&#24341;&#20154;&#27880;&#30446;&#65292;&#22240;&#20026;&#23613;&#31649;LLMs&#25317;&#26377;&#27604;&#36807;&#21435;&#27169;&#22411;&#26356;&#22810;&#30340;&#21442;&#25968;&#21644;&#26356;&#22797;&#26434;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#25105;&#20204;&#32771;&#34385;&#30340;&#24320;&#28304;&#27169;&#22411;&#20013;&#27809;&#26377;&#19968;&#20010;&#20351;&#29992;&#20219;&#20309;&#19987;&#38376;&#35774;&#35745;&#30340;&#40723;&#21169;&#31283;&#20581;&#24615;&#30340;&#25216;&#26415;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#31867;&#20284;&#30340;&#36235;&#21183;&#20063;&#36866;&#29992;&#20110;&#31038;&#20132;&#23186;&#20307;&#32763;&#35793;&#23454;&#39564;&#8212;&#8212;LLMs&#23545;&#31038;&#20132;&#23186;&#20307;&#25991;&#26412;&#26356;&#21152;&#31283;&#20581;&#12290;&#25105;&#20204;&#36824;&#21253;&#25324;&#20102;&#19968;&#39033;&#20851;&#20110;......
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03923v1 Announce Type: new  Abstract: Neural machine translation (MT) models achieve strong results across a variety of settings, but it is widely believed that they are highly sensitive to "noisy" inputs, such as spelling errors, abbreviations, and other formatting issues. In this paper, we revisit this insight in light of recent multilingual MT models and large language models (LLMs) applied to machine translation. Somewhat surprisingly, we show through controlled experiments that these models are far more robust to many kinds of noise than previous models, even when they perform similarly on clean data. This is notable because, even though LLMs have more parameters and more complex training processes than past models, none of the open ones we consider use any techniques specifically designed to encourage robustness. Next, we show that similar trends hold for social media translation experiments -- LLMs are more robust to social media text. We include an analysis of the ci
&lt;/p&gt;</description></item></channel></rss>