<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#20102;&#36234;&#29425;&#25552;&#31034;&#65292;&#25104;&#21151;&#22320;&#32469;&#36807;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26377;&#23475;&#38382;&#39064;&#30340;&#26816;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#25915;&#20987;&#25104;&#21151;&#29575;&#39640;&#36798;59.42%&#12290;</title><link>https://arxiv.org/abs/2402.10601</link><description>&lt;p&gt;
&#20351;&#29992;&#21333;&#35789;&#26367;&#25442;&#23494;&#30721;&#26469;&#36234;&#29425;&#19987;&#26377;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Jailbreaking Proprietary Large Language Models using Word Substitution Cipher
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10601
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#20102;&#36234;&#29425;&#25552;&#31034;&#65292;&#25104;&#21151;&#22320;&#32469;&#36807;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26377;&#23475;&#38382;&#39064;&#30340;&#26816;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#25915;&#20987;&#25104;&#21151;&#29575;&#39640;&#36798;59.42%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36981;&#24490;&#36947;&#24503;&#21644;&#20262;&#29702;&#20934;&#21017;&#65292;&#20294;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#21517;&#20026;Jailbreak&#30340;&#21019;&#24847;&#25552;&#31034;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#25552;&#31034;&#21487;&#20197;&#32469;&#36807;&#23545;&#40784;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36234;&#29425;&#25552;&#31034;&#21253;&#21547;&#33258;&#28982;&#35821;&#35328;&#65288;&#20027;&#35201;&#26159;&#33521;&#35821;&#65289;&#20013;&#30340;&#26377;&#23475;&#38382;&#39064;&#65292;&#21487;&#20197;&#34987;LLMs&#33258;&#36523;&#26816;&#27979;&#21040;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#30340;&#36234;&#29425;&#25552;&#31034;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#26368;&#20808;&#36827;&#30340;LLM&#65292;GPT-4&#19978;&#36827;&#34892;&#20102;&#19968;&#20010;&#35797;&#28857;&#30740;&#31350;&#65292;&#35299;&#30721;&#20102;&#20351;&#29992;&#21508;&#31181;&#23494;&#30721;&#25216;&#26415;&#21152;&#23494;&#30340;&#20960;&#20010;&#23433;&#20840;&#21477;&#23376;&#65292;&#21457;&#29616;&#31616;&#21333;&#30340;&#21333;&#35789;&#26367;&#25442;&#23494;&#30721;&#21487;&#20197;&#34987;&#26368;&#26377;&#25928;&#22320;&#35299;&#30721;&#12290;&#21463;&#27492;&#32467;&#26524;&#21551;&#21457;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#32534;&#30721;&#25216;&#26415;&#26469;&#32534;&#20889;&#36234;&#29425;&#25552;&#31034;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23558;&#19981;&#23433;&#20840;&#21333;&#35789;&#26144;&#23556;&#21040;&#23433;&#20840;&#21333;&#35789;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#26144;&#23556;&#30340;&#21333;&#35789;&#25552;&#20986;&#19981;&#23433;&#20840;&#38382;&#39064;&#30340;&#26144;&#23556;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#36234;&#29425;&#25915;&#20987;&#25104;&#21151;&#29575;&#65288;&#39640;&#36798;59.42%&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10601v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are aligned to moral and ethical guidelines but remain susceptible to creative prompts called Jailbreak that can bypass the alignment process. However, most jailbreaking prompts contain harmful questions in the natural language (mainly English), which can be detected by the LLM themselves. In this paper, we present jailbreaking prompts encoded using cryptographic techniques. We first present a pilot study on the state-of-the-art LLM, GPT-4, in decoding several safe sentences that have been encrypted using various cryptographic techniques and find that a straightforward word substitution cipher can be decoded most effectively. Motivated by this result, we use this encoding technique for writing jailbreaking prompts. We present a mapping of unsafe words with safe words and ask the unsafe question using these mapped words. Experimental results show an attack success rate (up to 59.42%) of our proposed jailbrea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#29616;&#20195;&#24076;&#33098;&#26041;&#35328;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;GRDD&#65292;&#24182;&#20351;&#29992;&#35813;&#25968;&#25454;&#38598;&#36827;&#34892;&#26041;&#35328;&#35782;&#21035;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#21363;&#20351;&#26159;&#31616;&#21333;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20063;&#33021;&#22312;&#35813;&#20219;&#21153;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2308.00802</link><description>&lt;p&gt;
GRDD: &#24076;&#33098;&#26041;&#35328;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
GRDD: A Dataset for Greek Dialectal NLP. (arXiv:2308.00802v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#29616;&#20195;&#24076;&#33098;&#26041;&#35328;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;GRDD&#65292;&#24182;&#20351;&#29992;&#35813;&#25968;&#25454;&#38598;&#36827;&#34892;&#26041;&#35328;&#35782;&#21035;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#21363;&#20351;&#26159;&#31616;&#21333;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20063;&#33021;&#22312;&#35813;&#20219;&#21153;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#29616;&#20195;&#24076;&#33098;&#26041;&#35328;&#30340;&#25968;&#25454;&#38598;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#20811;&#37324;&#29305;&#12289;&#24222;&#25552;&#12289;&#21271;&#24076;&#33098;&#21644;&#22622;&#28006;&#36335;&#26031;&#24076;&#33098;&#22235;&#31181;&#26041;&#35328;&#30340;&#21407;&#22987;&#25991;&#26412;&#25968;&#25454;&#12290;&#23613;&#31649;&#23384;&#22312;&#19981;&#24179;&#34913;&#65292;&#20294;&#35813;&#25968;&#25454;&#38598;&#26159;&#30456;&#24403;&#22823;&#30340;&#65292;&#24182;&#19988;&#26159;&#21019;&#24314;&#29616;&#20195;&#24076;&#33098;&#26041;&#35328;&#31867;&#20284;&#36164;&#28304;&#30340;&#39318;&#27425;&#23581;&#35797;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#35813;&#25968;&#25454;&#38598;&#36827;&#34892;&#26041;&#35328;&#35782;&#21035;&#65292;&#24182;&#23581;&#35797;&#20102;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21644;&#31616;&#21333;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#34920;&#29616;&#38750;&#24120;&#22909;&#65292;&#36825;&#21487;&#33021;&#34920;&#26126;&#25152;&#30740;&#31350;&#30340;&#26041;&#35328;&#20855;&#26377;&#36275;&#22815;&#30340;&#29420;&#29305;&#29305;&#24449;&#65292;&#21363;&#20351;&#26159;&#31616;&#21333;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20063;&#33021;&#22312;&#35813;&#20219;&#21153;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#38024;&#23545;&#34920;&#29616;&#26368;&#20339;&#30340;&#31639;&#27861;&#36827;&#34892;&#20102;&#38169;&#35823;&#20998;&#26512;&#65292;&#32467;&#26524;&#26174;&#31034;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#38169;&#35823;&#26159;&#30001;&#20110;&#25968;&#25454;&#38598;&#28165;&#29702;&#19981;&#36275;&#36896;&#25104;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a dataset for the computational study of a number of Modern Greek dialects. It consists of raw text data from four dialects of Modern Greek, Cretan, Pontic, Northern Greek and Cypriot Greek. The dataset is of considerable size, albeit imbalanced, and presents the first attempt to create large scale dialectal resources of this type for Modern Greek dialects. We then use the dataset to perform dialect idefntification. We experiment with traditional ML algorithms, as well as simple DL architectures. The results show very good performance on the task, potentially revealing that the dialects in question have distinct enough characteristics allowing even simple ML models to perform well on the task. Error analysis is performed for the top performing algorithms showing that in a number of cases the errors are due to insufficient dataset cleaning.
&lt;/p&gt;</description></item></channel></rss>