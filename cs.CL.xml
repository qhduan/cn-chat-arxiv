<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#25805;&#20316;&#31995;&#32479;&#20013;&#30340;LLM&#20195;&#29702;&#25805;&#20316;&#31995;&#32479;&#65292;&#26088;&#22312;&#20248;&#21270;&#36164;&#28304;&#20998;&#37197;&#12289;&#20419;&#36827;&#20195;&#29702;&#38388;&#19978;&#19979;&#25991;&#20999;&#25442;&#12289;&#23454;&#29616;&#24182;&#21457;&#25191;&#34892;&#20197;&#21450;&#20026;&#20195;&#29702;&#25552;&#20379;&#24037;&#20855;&#26381;&#21153;&#12290;</title><link>https://arxiv.org/abs/2403.16971</link><description>&lt;p&gt;
LLM Agent Operating System
&lt;/p&gt;
&lt;p&gt;
LLM Agent Operating System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16971
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#25805;&#20316;&#31995;&#32479;&#20013;&#30340;LLM&#20195;&#29702;&#25805;&#20316;&#31995;&#32479;&#65292;&#26088;&#22312;&#20248;&#21270;&#36164;&#28304;&#20998;&#37197;&#12289;&#20419;&#36827;&#20195;&#29702;&#38388;&#19978;&#19979;&#25991;&#20999;&#25442;&#12289;&#23454;&#29616;&#24182;&#21457;&#25191;&#34892;&#20197;&#21450;&#20026;&#20195;&#29702;&#25552;&#20379;&#24037;&#20855;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16971v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#37096;&#32626;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26234;&#33021;&#20195;&#29702;&#23384;&#22312;&#35832;&#22810;&#25361;&#25112;&#65292;&#20250;&#25439;&#23475;&#23427;&#20204;&#30340;&#25928;&#29575;&#21644;&#21151;&#25928;&#12290;&#20854;&#20013;&#21253;&#25324;&#20195;&#29702;&#35831;&#27714;&#22312;LLM&#19978;&#30340;&#27425;&#20248;&#35843;&#24230;&#21644;&#36164;&#28304;&#20998;&#37197;&#12289;&#22312;&#20195;&#29702;&#21644;LLM&#20043;&#38388;&#20132;&#20114;&#26102;&#20445;&#25345;&#19978;&#19979;&#25991;&#30340;&#22256;&#38590;&#65292;&#20197;&#21450;&#23558;&#20855;&#26377;&#19981;&#21516;&#33021;&#21147;&#21644;&#19987;&#19994;&#21270;&#30340;&#24322;&#26500;&#20195;&#29702;&#38598;&#25104;&#22312;&#19968;&#36215;&#30340;&#22797;&#26434;&#24615;&#12290;&#20195;&#29702;&#25968;&#37327;&#21644;&#22797;&#26434;&#24615;&#30340;&#24555;&#36895;&#22686;&#21152;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#36890;&#24120;&#20250;&#23548;&#33268;&#36164;&#28304;&#29942;&#39048;&#21644;&#27425;&#20248;&#36164;&#28304;&#21033;&#29992;&#12290;&#21463;&#21040;&#36825;&#20123;&#25361;&#25112;&#30340;&#21551;&#21457;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;AIOS&#65292;&#19968;&#31181;LLM&#20195;&#29702;&#25805;&#20316;&#31995;&#32479;&#65292;&#23427;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#25805;&#20316;&#31995;&#32479;&#65288;OS&#65289;&#20013;&#12290;&#20855;&#20307;&#22320;&#65292;AIOS&#26088;&#22312;&#20248;&#21270;&#36164;&#28304;&#20998;&#37197;&#65292;&#20419;&#36827;&#20195;&#29702;&#20043;&#38388;&#30340;&#19978;&#19979;&#25991;&#20999;&#25442;&#65292;&#23454;&#29616;&#20195;&#29702;&#30340;&#24182;&#21457;&#25191;&#34892;&#65292;&#20026;&#20195;&#29702;&#25552;&#20379;&#24037;&#20855;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16971v1 Announce Type: cross  Abstract: The integration and deployment of large language model (LLM)-based intelligent agents have been fraught with challenges that compromise their efficiency and efficacy. Among these issues are sub-optimal scheduling and resource allocation of agent requests over the LLM, the difficulties in maintaining context during interactions between agent and LLM, and the complexities inherent in integrating heterogeneous agents with different capabilities and specializations. The rapid increase of agent quantity and complexity further exacerbates these issues, often leading to bottlenecks and sub-optimal utilization of resources. Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS). Specifically, AIOS is designed to optimize resource allocation, facilitate context switch across agents, enable concurrent execution of agents, provide tool service for agents
&lt;/p&gt;</description></item><item><title>Gemini&#23478;&#26063;&#26159;&#19968;&#31995;&#21015;&#22312;&#22270;&#20687;&#12289;&#38899;&#39057;&#12289;&#35270;&#39057;&#21644;&#25991;&#26412;&#29702;&#35299;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#65292;&#20854;&#20013;&#26368;&#20855;&#33021;&#21147;&#30340;Gemini Ultra&#27169;&#22411;&#22312;30&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#25512;&#36827;&#20102;&#25216;&#26415;&#21069;&#27839;&#65292;&#24182;&#25913;&#36827;&#20102;&#25152;&#26377;20&#20010;&#22810;&#27169;&#24577;&#22522;&#20934;&#27979;&#35797;&#30340;&#25216;&#26415;&#29366;&#24577;&#12290;</title><link>https://arxiv.org/abs/2312.11805</link><description>&lt;p&gt;
Gemini&#65306;&#19968;&#31995;&#21015;&#39640;&#24615;&#33021;&#22810;&#27169;&#24577;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Gemini: A Family of Highly Capable Multimodal Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.11805
&lt;/p&gt;
&lt;p&gt;
Gemini&#23478;&#26063;&#26159;&#19968;&#31995;&#21015;&#22312;&#22270;&#20687;&#12289;&#38899;&#39057;&#12289;&#35270;&#39057;&#21644;&#25991;&#26412;&#29702;&#35299;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#65292;&#20854;&#20013;&#26368;&#20855;&#33021;&#21147;&#30340;Gemini Ultra&#27169;&#22411;&#22312;30&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#25512;&#36827;&#20102;&#25216;&#26415;&#21069;&#27839;&#65292;&#24182;&#25913;&#36827;&#20102;&#25152;&#26377;20&#20010;&#22810;&#27169;&#24577;&#22522;&#20934;&#27979;&#35797;&#30340;&#25216;&#26415;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25253;&#21578;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#31995;&#21015;Gemini&#65292;&#23637;&#31034;&#20986;&#22312;&#22270;&#20687;&#12289;&#38899;&#39057;&#12289;&#35270;&#39057;&#21644;&#25991;&#26412;&#29702;&#35299;&#26041;&#38754;&#30340;&#26174;&#33879;&#33021;&#21147;&#12290;Gemini&#31995;&#21015;&#21253;&#25324;Ultra&#12289;Pro&#21644;Nano&#23610;&#23544;&#65292;&#36866;&#29992;&#20110;&#20174;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#21040;&#35774;&#22791;&#20869;&#23384;&#21463;&#38480;&#24212;&#29992;&#30340;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;&#22312;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#26368;&#20855;&#33021;&#21147;&#30340;Gemini Ultra&#27169;&#22411;&#22312;32&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;30&#20010;&#20013;&#25512;&#36827;&#20102;&#25216;&#26415;&#21069;&#27839; - &#26174;&#33879;&#22320;&#26159;&#31532;&#19968;&#20010;&#22312;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#32771;&#35797;&#22522;&#20934;&#27979;&#35797;MMLU&#19978;&#23454;&#29616;&#20154;&#31867;&#19987;&#23478;&#27700;&#24179;&#34920;&#29616;&#30340;&#27169;&#22411;&#65292;&#24182;&#22312;&#25105;&#20204;&#30740;&#31350;&#30340;&#27599;&#19968;&#20010;20&#20010;&#22810;&#27169;&#24577;&#22522;&#20934;&#27979;&#35797;&#20013;&#25913;&#36827;&#20102;&#25216;&#26415;&#21069;&#27839;&#12290;&#25105;&#20204;&#30456;&#20449;Gemini&#31995;&#21015;&#22312;&#36328;&#27169;&#24577;&#25512;&#29702;&#21644;&#35821;&#35328;&#29702;&#35299;&#26041;&#38754;&#30340;&#26032;&#33021;&#21147;&#23558;&#33021;&#22815;&#25903;&#25345;&#21508;&#31181;&#29992;&#20363;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#36127;&#36131;&#20219;&#22320;&#21521;&#29992;&#25143;&#25552;&#20379;Gemini&#27169;&#22411;&#30340;&#35757;&#32451;&#21518;&#21644;&#37096;&#32626;&#26041;&#27861;&#65292;&#21253;&#25324;&#20351;&#29992;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.11805v2 Announce Type: replace-cross  Abstract: This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services includi
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#21457;&#29616;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#25551;&#36848;&#22312;&#19981;&#21516;&#35821;&#35328;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#35821;&#20041;&#24046;&#24322;&#65292;&#22810;&#35821;&#35328;&#25968;&#25454;&#26377;&#26356;&#39640;&#30340;&#35821;&#20041;&#35206;&#30422;&#29575;&#65292;&#24182;&#19988;&#22522;&#20110;&#22810;&#35821;&#35328;&#35757;&#32451;&#30340;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.14356</link><description>&lt;p&gt;
&#25991;&#21270;&#21644;&#35821;&#35328;&#22810;&#26679;&#24615;&#25552;&#39640;&#20102;&#35270;&#35273;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Cultural and Linguistic Diversity Improves Visual Representations. (arXiv:2310.14356v1 [cs.CV] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14356
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#21457;&#29616;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#25551;&#36848;&#22312;&#19981;&#21516;&#35821;&#35328;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#35821;&#20041;&#24046;&#24322;&#65292;&#22810;&#35821;&#35328;&#25968;&#25454;&#26377;&#26356;&#39640;&#30340;&#35821;&#20041;&#35206;&#30422;&#29575;&#65292;&#24182;&#19988;&#22522;&#20110;&#22810;&#35821;&#35328;&#35757;&#32451;&#30340;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#26426;&#35270;&#35273;&#36890;&#24120;&#23558;&#24863;&#30693;&#35270;&#20026;&#23458;&#35266;&#30340;&#65292;&#24182;&#19988;&#36825;&#31181;&#20551;&#35774;&#22312;&#25968;&#25454;&#38598;&#25910;&#38598;&#21644;&#27169;&#22411;&#35757;&#32451;&#20013;&#24471;&#21040;&#21453;&#26144;&#12290;&#20363;&#22914;&#65292;&#19981;&#21516;&#35821;&#35328;&#30340;&#22270;&#20687;&#25551;&#36848;&#36890;&#24120;&#34987;&#20551;&#23450;&#20026;&#30456;&#21516;&#35821;&#20041;&#20869;&#23481;&#30340;&#32763;&#35793;&#12290;&#28982;&#32780;&#65292;&#36328;&#25991;&#21270;&#24515;&#29702;&#23398;&#21644;&#35821;&#35328;&#23398;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20010;&#20307;&#30340;&#35270;&#35273;&#24863;&#30693;&#22240;&#20854;&#25991;&#21270;&#32972;&#26223;&#21644;&#25152;&#35828;&#30340;&#35821;&#35328;&#32780;&#24322;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#29983;&#25104;&#30340;&#26631;&#39064;&#20013;&#65292;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#35821;&#20041;&#20869;&#23481;&#24046;&#24322;&#12290;&#24403;&#25968;&#25454;&#26159;&#22810;&#35821;&#35328;&#32780;&#19981;&#26159;&#21333;&#35821;&#35328;&#26102;&#65292;&#26631;&#39064;&#30340;&#35821;&#20041;&#35206;&#30422;&#29575;&#24179;&#22343;&#26356;&#39640;&#65292;&#20197;&#22330;&#26223;&#22270;&#12289;&#23884;&#20837;&#21644;&#35821;&#35328;&#22797;&#26434;&#24615;&#36827;&#34892;&#27979;&#37327;&#12290;&#20363;&#22914;&#65292;&#19982;&#19968;&#32452;&#21333;&#35821;&#26631;&#39064;&#30456;&#27604;&#65292;&#22810;&#35821;&#26631;&#39064;&#24179;&#22343;&#26377;21.8&#65285;&#26356;&#22810;&#30340;&#23545;&#35937;&#65292;24.5&#65285;&#26356;&#22810;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;27.1&#65285;&#26356;&#22810;&#30340;&#23646;&#24615;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#26469;&#33258;&#19981;&#21516;&#35821;&#35328;&#30340;&#20869;&#23481;&#35757;&#32451;&#30340;&#27169;&#22411;&#34920;&#29616;&#26368;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computer vision often treats perception as objective, and this assumption gets reflected in the way that datasets are collected and models are trained. For instance, image descriptions in different languages are typically assumed to be translations of the same semantic content. However, work in cross-cultural psychology and linguistics has shown that individuals differ in their visual perception depending on their cultural background and the language they speak. In this paper, we demonstrate significant differences in semantic content across languages in both dataset and model-produced captions. When data is multilingual as opposed to monolingual, captions have higher semantic coverage on average, as measured by scene graph, embedding, and linguistic complexity. For example, multilingual captions have on average 21.8% more objects, 24.5% more relations, and 27.1% more attributes than a set of monolingual captions. Moreover, models trained on content from different languages perform bes
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;</title><link>http://arxiv.org/abs/2310.13548</link><description>&lt;p&gt;
&#25506;&#32034;&#35821;&#35328;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13548
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#12300;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#12301;&#26159;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#19968;&#31181;&#27969;&#34892;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;RLHF&#21487;&#33021;&#20250;&#40723;&#21169;&#27169;&#22411;&#36890;&#36807;&#19982;&#29992;&#25143;&#20449;&#24565;&#30456;&#31526;&#30340;&#22238;&#31572;&#26469;&#20195;&#26367;&#30495;&#23454;&#22238;&#31572;&#65292;&#36825;&#31181;&#34892;&#20026;&#34987;&#31216;&#20026;&#35844;&#23194;&#34892;&#20026;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;RLHF&#35757;&#32451;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#26222;&#36941;&#24615;&#20197;&#21450;&#20154;&#31867;&#20559;&#22909;&#21028;&#26029;&#26159;&#21542;&#36215;&#21040;&#20102;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20116;&#20010;&#26368;&#20808;&#36827;&#30340;AI&#21161;&#25163;&#22312;&#22235;&#20010;&#19981;&#21516;&#30340;&#33258;&#30001;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#19968;&#36143;&#34920;&#29616;&#20986;&#35844;&#23194;&#34892;&#20026;&#12290;&#20026;&#20102;&#29702;&#35299;&#20154;&#31867;&#20559;&#22909;&#26159;&#21542;&#39537;&#21160;&#20102;RLHF&#27169;&#22411;&#30340;&#36825;&#31181;&#24191;&#27867;&#34892;&#20026;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24403;&#22238;&#31572;&#19982;&#29992;&#25143;&#30340;&#35266;&#28857;&#30456;&#31526;&#26102;&#65292;&#23427;&#26356;&#26377;&#21487;&#33021;&#34987;&#36873;&#20013;&#12290;&#27492;&#22806;&#65292;&#20154;&#31867;&#21644;&#20559;&#22909;&#27169;&#22411;&#65288;PMs&#65289;&#23558;&#26377;&#35828;&#26381;&#21147;&#30340;&#35844;&#23194;&#22238;&#31572;&#19982;&#27491;&#30830;&#22238;&#31572;&#30456;&#27604;&#65292;&#26377;&#26102;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#22320;&#36873;&#25321;&#20102;&#35844;&#23194;&#22238;&#31572;&#12290;&#20248;&#21270;&#27169;&#22411;&#36755;&#20986;&#20197;&#28385;&#36275;PMs&#26377;&#26102;&#20063;&#20250;&#22312;&#30495;&#23454;&#24615;&#21644;&#35844;&#23194;&#34892;&#20026;&#20043;&#38388;&#20570;&#20986;&#21462;&#33293;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Over
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;&#19978;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;LLM&#26080;&#27861;&#21462;&#24471;&#26368;&#20339;&#32467;&#26524;&#19988;&#19981;&#33021;&#20165;&#36890;&#36807;&#26631;&#39064;&#23454;&#29616;&#28385;&#24847;&#30340;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2306.09597</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Clickbait Detection via Large Language Models. (arXiv:2306.09597v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;&#19978;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;LLM&#26080;&#27861;&#21462;&#24471;&#26368;&#20339;&#32467;&#26524;&#19988;&#19981;&#33021;&#20165;&#36890;&#36807;&#26631;&#39064;&#23454;&#29616;&#28385;&#24847;&#30340;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#35825;&#39575;&#65288;Clickbait&#65289;&#20250;&#36890;&#36807;&#19968;&#20123;&#20196;&#20154;&#24778;&#35766;&#29978;&#33267;&#24341;&#20154;&#20837;&#32988;&#30340;&#26631;&#39064;&#26469;&#35825;&#23548;&#29992;&#25143;&#36827;&#34892;&#28857;&#20987;&#65292;&#20960;&#20046;&#28183;&#36879;&#21040;&#25152;&#26377;&#22312;&#32447;&#20869;&#23481;&#21457;&#24067;&#32773;&#65292;&#22914;&#26032;&#38395;&#38376;&#25143;&#21644;&#31038;&#20132;&#23186;&#20307;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLM)&#24050;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;NLP&#19979;&#28216;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;LLM&#26159;&#21542;&#21487;&#20197;&#20316;&#20026;&#39640;&#36136;&#37327;&#30340;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;&#31995;&#32479;&#36824;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;LLM&#22312;&#22810;&#20010;&#33521;&#25991;&#21644;&#20013;&#25991;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#23569;&#26679;&#26412;&#22330;&#26223;&#19979;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#21644;&#24494;&#35843;PLM&#26041;&#27861;&#30456;&#27604;&#65292;LLM&#26080;&#27861;&#36798;&#21040;&#26368;&#20339;&#32467;&#26524;&#12290;&#19982;&#20154;&#31867;&#30452;&#35273;&#19981;&#21516;&#65292;&#23454;&#39564;&#34920;&#26126;LLM&#19981;&#33021;&#20165;&#36890;&#36807;&#26631;&#39064;&#23454;&#29616;&#28385;&#24847;&#30340;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clickbait, which aims to induce users with some surprising and even thrilling headlines for increasing click-through rates, permeates almost all online content publishers, such as news portals and social media. Recently, Large Language Models (LLMs) have emerged as a powerful instrument and achieved tremendous success in a serious of NLP downstream tasks. However, it is not yet known whether LLMs can be served as a high-quality clickbait detection system. In this paper, we analyze the performance of LLMs in the few-shot scenarios on a number of English and Chinese benchmark datasets. Experimental results show that LLMs cannot achieve the best results compared to the state-of-the-art deep and fine-tuning PLMs methods. Different from the human intuition, the experiments demonstrated that LLMs cannot make satisfied clickbait detection just by the headlines.
&lt;/p&gt;</description></item></channel></rss>