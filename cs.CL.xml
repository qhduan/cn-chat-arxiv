<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>CMAT&#26694;&#26550;&#24341;&#20837;&#20102;TinyAgent&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#29615;&#22659;&#21453;&#39304;&#36827;&#34892;&#33258;&#36866;&#24212;&#26435;&#37325;&#26356;&#26032;&#65292;&#22686;&#24378;&#20102;&#35821;&#35328;&#26234;&#33021;&#20307;&#30340;&#33021;&#21147;&#21644;&#38271;&#26399;&#35760;&#24518;&#12290;</title><link>https://arxiv.org/abs/2404.01663</link><description>&lt;p&gt;
CMAT: &#29992;&#20110;&#22686;&#24378;&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#35843;&#25972;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01663
&lt;/p&gt;
&lt;p&gt;
CMAT&#26694;&#26550;&#24341;&#20837;&#20102;TinyAgent&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#29615;&#22659;&#21453;&#39304;&#36827;&#34892;&#33258;&#36866;&#24212;&#26435;&#37325;&#26356;&#26032;&#65292;&#22686;&#24378;&#20102;&#35821;&#35328;&#26234;&#33021;&#20307;&#30340;&#33021;&#21147;&#21644;&#38271;&#26399;&#35760;&#24518;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#25918;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26174;&#33879;&#25512;&#21160;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;LLMs&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#30340;&#26377;&#25928;&#25805;&#20316;&#20173;&#28982;&#20005;&#37325;&#20381;&#36182;&#20110;&#20154;&#31867;&#36755;&#20837;&#26469;&#20934;&#30830;&#24341;&#23548;&#23545;&#35805;&#27969;&#31243;&#65292;&#26234;&#33021;&#20307;&#35843;&#25972;&#26159;&#19968;&#31181;&#20851;&#38190;&#30340;&#20248;&#21270;&#25216;&#26415;&#65292;&#28041;&#21450;&#20154;&#31867;&#23545;&#27169;&#22411;&#30340;&#35843;&#25972;&#65292;&#20197;&#26356;&#22909;&#22320;&#21709;&#24212;&#36825;&#31181;&#24341;&#23548;&#12290;&#38024;&#23545;&#36825;&#19968;&#20381;&#36182;&#24615;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24341;&#20837;&#20102;TinyAgent&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#30340;&#39640;&#36136;&#37327;&#25968;&#25454;&#38598;&#35757;&#32451;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;Collaborative Multi-Agent Tuning&#65288;CMAT&#65289;&#26694;&#26550;&#65292;&#36825;&#26159;&#19968;&#20010;&#21019;&#26032;&#24615;&#31995;&#32479;&#65292;&#26088;&#22312;&#36890;&#36807;&#26681;&#25454;&#29615;&#22659;&#21453;&#39304;&#36827;&#34892;&#33258;&#36866;&#24212;&#26435;&#37325;&#26356;&#26032;&#26469;&#22686;&#24378;&#35821;&#35328;&#26234;&#33021;&#20307;&#30340;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#20419;&#36827;&#20102;&#22810;&#20010;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21327;&#20316;&#23398;&#20064;&#21644;&#23454;&#26102;&#36866;&#24212;&#65292;&#22686;&#24378;&#20102;&#23427;&#20204;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#21644;&#38271;&#26399;&#35760;&#24518;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01663v1 Announce Type: new  Abstract: Open large language models (LLMs) have significantly advanced the field of natural language processing, showcasing impressive performance across various tasks.Despite the significant advancements in LLMs, their effective operation still relies heavily on human input to accurately guide the dialogue flow, with agent tuning being a crucial optimization technique that involves human adjustments to the model for better response to such guidance.Addressing this dependency, our work introduces the TinyAgent model, trained on a meticulously curated high-quality dataset. We also present the Collaborative Multi-Agent Tuning (CMAT) framework, an innovative system designed to augment language agent capabilities through adaptive weight updates based on environmental feedback. This framework fosters collaborative learning and real-time adaptation among multiple intelligent agents, enhancing their context-awareness and long-term memory. In this resear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;AutoTRIZ&#65292;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#21270;&#21644;&#22686;&#24378;TRIZ&#26041;&#27861;&#30340;&#20154;&#24037;&#21019;&#24847;&#24037;&#20855;&#65292;&#20026;&#35774;&#35745;&#33258;&#21160;&#21270;&#21644;&#21487;&#35299;&#37322;&#21019;&#24847;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.13002</link><description>&lt;p&gt;
AutoTRIZ&#65306;&#21033;&#29992;TRIZ&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20154;&#24037;&#21019;&#24847;
&lt;/p&gt;
&lt;p&gt;
AutoTRIZ: Artificial Ideation with TRIZ and Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13002
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;AutoTRIZ&#65292;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#21270;&#21644;&#22686;&#24378;TRIZ&#26041;&#27861;&#30340;&#20154;&#24037;&#21019;&#24847;&#24037;&#20855;&#65292;&#20026;&#35774;&#35745;&#33258;&#21160;&#21270;&#21644;&#21487;&#35299;&#37322;&#21019;&#24847;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#21644;&#21019;&#26032;&#32773;&#22312;&#24320;&#21457;&#24605;&#32500;&#26041;&#27861;&#26041;&#38754;&#20570;&#20986;&#20102;&#24040;&#22823;&#21162;&#21147;&#65292;&#27604;&#22914;&#24418;&#24577;&#20998;&#26512;&#21644;&#31867;&#27604;&#35774;&#35745;&#65292;&#20197;&#36741;&#21161;&#24037;&#31243;&#35774;&#35745;&#21019;&#24847;&#65292;&#35299;&#20915;&#38382;&#39064;&#21644;&#25512;&#21160;&#21019;&#26032;&#12290;&#22312;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;TRIZ&#20316;&#20026;&#26368;&#33879;&#21517;&#30340;&#26041;&#27861;&#33073;&#39062;&#32780;&#20986;&#65292;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#31995;&#32479;&#21270;&#21019;&#26032;&#12290;&#28982;&#32780;&#65292;TRIZ&#36164;&#28304;&#21644;&#27010;&#24565;&#30340;&#22797;&#26434;&#24615;&#65292;&#20197;&#21450;&#20854;&#23545;&#29992;&#25143;&#30693;&#35782;&#12289;&#32463;&#39564;&#21644;&#25512;&#29702;&#33021;&#21147;&#30340;&#20381;&#36182;&#65292;&#38480;&#21046;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;AutoTRIZ&#65292;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33258;&#21160;&#21270;&#21644;&#22686;&#24378;TRIZ&#26041;&#27861;&#30340;&#20154;&#24037;&#21019;&#24847;&#24037;&#20855;&#12290;&#36890;&#36807;&#21033;&#29992;LLMs&#30340;&#24191;&#27867;&#30693;&#35782;&#21644;&#20808;&#36827;&#25512;&#29702;&#33021;&#21147;&#65292;AutoTRIZ&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#36827;&#34892;&#35774;&#35745;&#33258;&#21160;&#21270;&#21644;&#21487;&#35299;&#37322;&#21019;&#24847;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#30683;&#30462;&#26816;&#27979;&#21644;&#27604;&#36739;&#26041;&#38754;&#30340;&#19968;&#33268;&#24615;&#23454;&#39564;&#26469;&#35777;&#26126;&#24182;&#35780;&#20272;AutoTRIZ&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13002v1 Announce Type: cross  Abstract: Researchers and innovators have made enormous efforts in developing ideation methods, such as morphological analysis and design-by-analogy, to aid engineering design ideation for problem solving and innovation. Among these, TRIZ stands out as the most well-known approach, widely applied for systematic innovation. However, the complexity of TRIZ resources and concepts, coupled with its reliance on users' knowledge, experience, and reasoning capabilities, limits its practicability. This paper proposes AutoTRIZ, an artificial ideation tool that leverages large language models (LLMs) to automate and enhance the TRIZ methodology. By leveraging the broad knowledge and advanced reasoning capabilities of LLMs, AutoTRIZ offers a novel approach to design automation and interpretable ideation with artificial intelligence. We demonstrate and evaluate the effectiveness of AutoTRIZ through consistency experiments in contradiction detection and compa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NavCoT&#30340;&#26032;&#31574;&#30053;&#65292;&#22312;&#35270;&#35273;&#19982;&#35821;&#35328;&#23548;&#33322;&#20013;&#36890;&#36807;&#23398;&#20064;&#35299;&#32806;&#25512;&#29702;&#65292;&#23454;&#29616;&#20102;&#33258;&#20027;&#23548;&#33322;&#20915;&#31574;&#65292;&#26377;&#25928;&#20943;&#36731;&#20102;&#39046;&#22495;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.07376</link><description>&lt;p&gt;
NavCoT: &#36890;&#36807;&#23398;&#20064;&#35299;&#32806;&#25512;&#29702;&#25552;&#21319;&#22522;&#20110;LLM&#30340;&#35270;&#35273;&#19982;&#35821;&#35328;&#23548;&#33322;
&lt;/p&gt;
&lt;p&gt;
NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NavCoT&#30340;&#26032;&#31574;&#30053;&#65292;&#22312;&#35270;&#35273;&#19982;&#35821;&#35328;&#23548;&#33322;&#20013;&#36890;&#36807;&#23398;&#20064;&#35299;&#32806;&#25512;&#29702;&#65292;&#23454;&#29616;&#20102;&#33258;&#20027;&#23548;&#33322;&#20915;&#31574;&#65292;&#26377;&#25928;&#20943;&#36731;&#20102;&#39046;&#22495;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#19982;&#35821;&#35328;&#23548;&#33322;(VLN)&#20316;&#20026;&#20855;&#26377;&#37325;&#35201;&#30740;&#31350;&#20215;&#20540;&#30340;&#20855;&#36523;&#20154;&#24037;&#26234;&#33021;&#38382;&#39064;&#65292;&#38656;&#35201;&#19968;&#20010;&#20855;&#36523;&#20195;&#29702;&#26681;&#25454;&#33258;&#28982;&#35821;&#35328;&#25351;&#31034;&#31359;&#36234;&#22797;&#26434;&#30340;3D&#29615;&#22659;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#31361;&#20986;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;VLN&#20013;&#25552;&#39640;&#23548;&#33322;&#25512;&#29702;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#20027;&#35201;&#22312;&#31163;&#32447;&#26041;&#24335;&#19979;&#30340;&#20351;&#29992;&#36890;&#24120;&#22312;VLN&#20219;&#21153;&#21644;LLM&#35757;&#32451;&#35821;&#26009;&#24211;&#20043;&#38388;&#36973;&#21463;&#26174;&#33879;&#30340;&#39046;&#22495;&#24046;&#36317;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#23548;&#33322;&#24605;&#32500;&#38142;(NavCoT)&#30340;&#26032;&#22411;&#31574;&#30053;&#65292;&#25105;&#20204;&#36890;&#36807;&#23436;&#25104;&#39046;&#22495;&#20869;&#39640;&#25928;&#21442;&#25968;&#35757;&#32451;&#65292;&#23454;&#29616;&#33258;&#20027;&#23548;&#33322;&#20915;&#31574;&#65292;&#26377;&#25928;&#20943;&#36731;&#39046;&#22495;&#24046;&#36317;&#30340;&#25104;&#26412;&#12290;&#20855;&#20307;&#22320;&#65292;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#65292;LLM&#34987;&#25552;&#31034;&#36890;&#36807;&#20316;&#20026;&#19990;&#30028;&#27169;&#22411;&#26469;&#39044;&#27979;&#23548;&#33322;&#24605;&#32500;&#38142;&#65306;1)&#26681;&#25454;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07376v1 Announce Type: cross  Abstract: Vision-and-Language Navigation (VLN), as a crucial research problem of Embodied AI, requires an embodied agent to navigate through complex 3D environments following natural language instructions. Recent research has highlighted the promising capacity of large language models (LLMs) in VLN by improving navigational reasoning accuracy and interpretability. However, their predominant use in an offline manner usually suffers from substantial domain gap between the VLN task and the LLM training corpus. This paper introduces a novel strategy called Navigational Chain-of-Thought (NavCoT), where we fulfill parameter-efficient in-domain training to enable self-guided navigational decision, leading to a significant mitigation of the domain gap in a cost-effective manner. Specifically, at each timestep, the LLM is prompted to forecast the navigational chain-of-thought by: 1) acting as a world model to imagine the next observation according to the
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38646;-shot&#20998;&#31867;&#22312;&#22788;&#29702;&#22797;&#26434;&#20219;&#21153;&#22914;&#24694;&#24847;&#27169;&#22240;&#26816;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;</title><link>https://arxiv.org/abs/2402.12198</link><description>&lt;p&gt;
&#38646;-shot &#21487;&#35265;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#20167;&#24680;&#27169;&#22240;&#26816;&#27979;&#65306;&#25105;&#20204;&#24050;&#32463;&#21040;&#36798;&#30446;&#26631;&#20102;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Zero shot VLMs for hate meme detection: Are we there yet?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38646;-shot&#20998;&#31867;&#22312;&#22788;&#29702;&#22797;&#26434;&#20219;&#21153;&#22914;&#24694;&#24847;&#27169;&#22240;&#26816;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#22810;&#23186;&#20307;&#20869;&#23481;&#27491;&#22312;&#36805;&#36895;&#21457;&#23637;&#65292;&#20854;&#20013;&#27169;&#22240;&#20316;&#20026;&#19968;&#31181;&#29420;&#29305;&#24418;&#24335;&#21464;&#24471;&#26085;&#30410;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#19968;&#20123;&#24694;&#24847;&#29992;&#25143;&#21033;&#29992;&#27169;&#22240;&#38024;&#23545;&#20010;&#20154;&#25110;&#26131;&#21463;&#25915;&#20987;&#30340;&#31038;&#21306;&#65292;&#22240;&#27492;&#26377;&#24517;&#35201;&#35782;&#21035;&#21644;&#35299;&#20915;&#27492;&#31867;&#24694;&#24847;&#27169;&#22240;&#12290;&#24050;&#32463;&#36827;&#34892;&#20102;&#22823;&#37327;&#30740;&#31350;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36890;&#36807;&#24320;&#21457;&#20167;&#24680;&#27169;&#22240;&#26816;&#27979;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;/&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#19968;&#20010;&#26174;&#33879;&#23616;&#38480;&#24615;&#26159;&#38656;&#35201;&#24102;&#26631;&#31614;&#30340;&#25968;&#25454;&#38598;&#25165;&#33021;&#36827;&#34892;&#20934;&#30830;&#20998;&#31867;&#12290;&#26368;&#36817;&#65292;&#30740;&#31350;&#30028;&#35265;&#35777;&#20102;&#20960;&#31181;&#21487;&#35265;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#35843;&#26597;&#36825;&#20123;&#21487;&#35265;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#35832;&#22914;&#20167;&#24680;&#27169;&#22240;&#26816;&#27979;&#31561;&#22797;&#26434;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#35774;&#32622;&#26469;&#19987;&#27880;&#20110;&#23545;&#24694;&#24847;/&#26377;&#23475;&#27169;&#22240;&#30340;&#38646;-shot &#20998;&#31867;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;o
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12198v1 Announce Type: new  Abstract: Multimedia content on social media is rapidly evolving, with memes gaining prominence as a distinctive form. Unfortunately, some malicious users exploit memes to target individuals or vulnerable communities, making it imperative to identify and address such instances of hateful memes. Extensive research has been conducted to address this issue by developing hate meme detection models. However, a notable limitation of traditional machine/deep learning models is the requirement for labeled datasets for accurate classification. Recently, the research community has witnessed the emergence of several visual language models that have exhibited outstanding performance across various tasks. In this study, we aim to investigate the efficacy of these visual language models in handling intricate tasks such as hate meme detection. We use various prompt settings to focus on zero-shot classification of hateful/harmful memes. Through our analysis, we o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#31574;&#30053;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#21160;&#35780;&#20272;&#21644;&#36873;&#25321;&#65292;&#24182;&#36890;&#36807;&#36830;&#32493;&#39044;&#35757;&#32451;&#26174;&#33879;&#25552;&#39640;&#20102;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#12290;&#20027;&#35201;&#21019;&#26032;&#21253;&#25324;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#39564;&#35777;&#22120;&#65292;&#21457;&#24067;&#20102;&#39640;&#36136;&#37327;&#30340;AutoMathText&#25968;&#25454;&#38598;&#65292;&#24182;&#23454;&#29616;&#20102;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#30340;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.07625</link><description>&lt;p&gt;
AutoMathText&#65306;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#31574;&#30053;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25968;&#23398;&#25991;&#26412;&#30340;&#33258;&#21160;&#35780;&#20272;&#21644;&#36873;&#25321;&#65292;&#24182;&#36890;&#36807;&#36830;&#32493;&#39044;&#35757;&#32451;&#26174;&#33879;&#25552;&#39640;&#20102;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#12290;&#20027;&#35201;&#21019;&#26032;&#21253;&#25324;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#39564;&#35777;&#22120;&#65292;&#21457;&#24067;&#20102;&#39640;&#36136;&#37327;&#30340;AutoMathText&#25968;&#25454;&#38598;&#65292;&#24182;&#23454;&#29616;&#20102;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36890;&#36807;&#25345;&#32493;&#30340;&#39044;&#35757;&#32451;&#25913;&#21892;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#25512;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31574;&#30053;&#65292;&#21033;&#29992;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#33258;&#20027;&#25968;&#25454;&#36873;&#25321;&#12290;&#19982;&#20256;&#32479;&#30340;&#26377;&#20154;&#24037;&#26631;&#27880;&#25968;&#25454;&#30340;&#30417;&#30563;&#24494;&#35843;&#25110;&#35757;&#32451;&#36807;&#30340;&#20998;&#31867;&#22120;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20803;&#25552;&#31034;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#38646;&#26679;&#26412;&#39564;&#35777;&#22120;&#65292;&#33258;&#20027;&#35780;&#20272;&#21644;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#25968;&#23398;&#20869;&#23481;&#65292;&#24182;&#21457;&#24067;&#20102;&#32463;&#36807;&#31574;&#21010;&#30340;&#24320;&#28304;AutoMathText&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#36229;&#36807;200GB&#30340;&#25968;&#25454;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#23545;AutoMathText&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#36830;&#32493;&#39044;&#35757;&#32451;&#65292;&#20351;&#24471;7B&#21442;&#25968;&#30340;Mistral&#35821;&#35328;&#27169;&#22411;&#22312;MATH&#25968;&#25454;&#38598;&#19978;&#30340;&#19979;&#28216;&#24615;&#33021;&#22823;&#24133;&#25552;&#21319;&#65292;&#32780;&#20196;&#29260;&#25968;&#37327;&#27604;&#20043;&#21069;&#30340;&#36830;&#32493;&#39044;&#35757;&#32451;&#24037;&#20316;&#20943;&#23569;&#20102;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;&#22522;&#20934;&#30340;&#39044;&#35757;&#32451;&#20196;&#29260;&#25928;&#29575;&#25552;&#39640;&#20102;2&#20493;&#65292;&#31361;&#26174;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#22686;&#24378;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
To improve language models' proficiency in mathematical reasoning via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional supervised fine-tuning or trained classifiers with human-annotated data, our approach utilizes meta-prompted language models as zero-shot verifiers to autonomously evaluate and select high-quality mathematical content, and we release the curated open-source AutoMathText dataset encompassing over 200GB of data. To demonstrate the efficacy of our method, we continuously pretrained a 7B-parameter Mistral language model on the AutoMathText dataset, achieving substantial improvements in downstream performance on the MATH dataset with a token amount reduced by orders of magnitude compared to previous continuous pretraining works. Our method showcases a 2 times increase in pretraining token efficiency compared to baselines, underscoring the potential of our approach in enhancing
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21560;&#24341;&#20102;&#24456;&#22810;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#19978;&#30340;&#24378;&#22823;&#34920;&#29616;&#12290;&#35813;&#30740;&#31350;&#39046;&#22495;&#21457;&#23637;&#36805;&#36895;&#65292;&#21253;&#25324;&#20102;&#21508;&#31181;&#33879;&#21517;&#30340;LLMs&#12289;&#26500;&#24314;&#21644;&#22686;&#24378;LLMs&#30340;&#25216;&#26415;&#12289;&#20197;&#21450;&#27969;&#34892;&#30340;LLM&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#12290;</title><link>https://arxiv.org/abs/2402.06196</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Large Language Models: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06196
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21560;&#24341;&#20102;&#24456;&#22810;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#19978;&#30340;&#24378;&#22823;&#34920;&#29616;&#12290;&#35813;&#30740;&#31350;&#39046;&#22495;&#21457;&#23637;&#36805;&#36895;&#65292;&#21253;&#25324;&#20102;&#21508;&#31181;&#33879;&#21517;&#30340;LLMs&#12289;&#26500;&#24314;&#21644;&#22686;&#24378;LLMs&#30340;&#25216;&#26415;&#12289;&#20197;&#21450;&#27969;&#34892;&#30340;LLM&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30001;&#20110;&#20854;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#19978;&#30340;&#20986;&#33394;&#34920;&#29616;&#32780;&#21463;&#21040;&#20102;&#24456;&#22810;&#20851;&#27880;&#65292;&#33258;2022&#24180;11&#26376;ChatGPT&#21457;&#24067;&#20197;&#26469;&#12290;LLMs&#36890;&#36807;&#22312;&#22823;&#37327;&#25991;&#26412;&#25968;&#25454;&#19978;&#35757;&#32451;&#27169;&#22411;&#30340;&#25968;&#21313;&#20159;&#21442;&#25968;&#26469;&#33719;&#24471;&#24191;&#27867;&#30340;&#36890;&#29992;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#36825;&#31526;&#21512;&#32553;&#25918;&#23450;&#24459;&#30340;&#39044;&#27979;&#12290;LLMs&#30340;&#30740;&#31350;&#39046;&#22495;&#23613;&#31649;&#38750;&#24120;&#26032;&#65292;&#20294;&#22312;&#35768;&#22810;&#19981;&#21516;&#26041;&#38754;&#27491;&#22312;&#24555;&#36895;&#21457;&#23637;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#19968;&#20123;&#26368;&#33879;&#21517;&#30340;LLMs&#65292;&#21253;&#25324;&#19977;&#20010;&#27969;&#34892;&#30340;LLM&#31995;&#21015;&#65288;GPT&#12289;LLaMA&#12289;PaLM&#65289;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#29305;&#28857;&#12289;&#36129;&#29486;&#21644;&#38480;&#21046;&#12290;&#25105;&#20204;&#36824;&#27010;&#36848;&#20102;&#26500;&#24314;&#21644;&#22686;&#24378;LLMs&#30340;&#25216;&#26415;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#20026;LLM&#35757;&#32451;&#12289;&#24494;&#35843;&#21644;&#35780;&#20272;&#20934;&#22791;&#30340;&#27969;&#34892;&#25968;&#25454;&#38598;&#65292;&#23457;&#26597;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;LLM&#35780;&#20272;&#25351;&#26631;&#65292;&#24182;&#27604;&#36739;&#20102;&#20960;&#20010;&#27969;&#34892;LLM&#22312;&#19968;&#32452;&#20195;&#34920;&#24615;&#22522;&#20934;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have drawn a lot of attention due to their strong performance on a wide range of natural language tasks, since the release of ChatGPT in November 2022. LLMs' ability of general-purpose language understanding and generation is acquired by training billions of model's parameters on massive amounts of text data, as predicted by scaling laws \cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while very recent, is evolving rapidly in many different ways. In this paper, we review some of the most prominent LLMs, including three popular LLM families (GPT, LLaMA, PaLM), and discuss their characteristics, contributions and limitations. We also give an overview of techniques developed to build, and augment LLMs. We then survey popular datasets prepared for LLM training, fine-tuning, and evaluation, review widely used LLM evaluation metrics, and compare the performance of several popular LLMs on a set of representative benchmarks. Finally, we co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;P2P&#20511;&#36151;&#24179;&#21488;&#19978;&#20511;&#27454;&#20154;&#25552;&#20379;&#30340;&#25991;&#26412;&#25551;&#36848;&#26469;&#26500;&#24314;&#39118;&#38505;&#25351;&#26631;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#39118;&#38505;&#35780;&#20998;&#21487;&#20197;&#26126;&#26174;&#25552;&#39640;&#20449;&#29992;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16458</link><description>&lt;p&gt;
&#20449;&#29992;&#39118;&#38505;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#65306;&#20174;P2P&#20511;&#36151;&#30340;&#36151;&#27454;&#25551;&#36848;&#20013;&#26500;&#24314;&#39118;&#38505;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending. (arXiv:2401.16458v1 [q-fin.RM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16458
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;P2P&#20511;&#36151;&#24179;&#21488;&#19978;&#20511;&#27454;&#20154;&#25552;&#20379;&#30340;&#25991;&#26412;&#25551;&#36848;&#26469;&#26500;&#24314;&#39118;&#38505;&#25351;&#26631;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#39118;&#38505;&#35780;&#20998;&#21487;&#20197;&#26126;&#26174;&#25552;&#39640;&#20449;&#29992;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
P2P&#20511;&#36151;&#20316;&#20026;&#19968;&#31181;&#29420;&#29305;&#30340;&#34701;&#36164;&#26426;&#21046;&#65292;&#36890;&#36807;&#22312;&#32447;&#24179;&#21488;&#23558;&#20511;&#27454;&#20154;&#19982;&#25918;&#27454;&#20154;&#32852;&#31995;&#36215;&#26469;&#12290;&#28982;&#32780;&#65292;P2P&#20511;&#36151;&#38754;&#20020;&#20449;&#24687;&#19981;&#23545;&#31216;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#25918;&#27454;&#20154;&#24448;&#24448;&#32570;&#20047;&#36275;&#22815;&#30340;&#25968;&#25454;&#26469;&#35780;&#20272;&#20511;&#27454;&#20154;&#30340;&#20449;&#29992;&#20215;&#20540;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21363;&#21033;&#29992;&#20511;&#27454;&#20154;&#22312;&#36151;&#27454;&#30003;&#35831;&#36807;&#31243;&#20013;&#25552;&#20379;&#30340;&#25991;&#26412;&#25551;&#36848;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22788;&#29702;&#36825;&#20123;&#25991;&#26412;&#25551;&#36848;&#65292;LLM&#26159;&#19968;&#31181;&#33021;&#22815;&#35782;&#21035;&#25991;&#26412;&#20013;&#30340;&#27169;&#24335;&#21644;&#35821;&#20041;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#23558;&#36801;&#31227;&#23398;&#20064;&#24212;&#29992;&#20110;&#23558;LLM&#36866;&#24212;&#29305;&#23450;&#20219;&#21153;&#12290;&#25105;&#20204;&#20174;Lending Club&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#32467;&#26524;&#26174;&#31034;&#65292;BERT&#29983;&#25104;&#30340;&#39118;&#38505;&#35780;&#20998;&#26174;&#33879;&#25552;&#39640;&#20102;&#20449;&#29992;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;LLM&#30340;&#31995;&#32479;&#22266;&#26377;&#30340;&#19981;&#36879;&#26126;&#24615;&#65292;&#20197;&#21450;&#28508;&#22312;&#20559;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#38480;&#21046;&#20102;&#20854;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Peer-to-peer (P2P) lending has emerged as a distinctive financing mechanism, linking borrowers with lenders through online platforms. However, P2P lending faces the challenge of information asymmetry, as lenders often lack sufficient data to assess the creditworthiness of borrowers. This paper proposes a novel approach to address this issue by leveraging the textual descriptions provided by borrowers during the loan application process. Our methodology involves processing these textual descriptions using a Large Language Model (LLM), a powerful tool capable of discerning patterns and semantics within the text. Transfer learning is applied to adapt the LLM to the specific task at hand.  Our results derived from the analysis of the Lending Club dataset show that the risk score generated by BERT, a widely used LLM, significantly improves the performance of credit risk classifiers. However, the inherent opacity of LLM-based systems, coupled with uncertainties about potential biases, unders
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;BERT&#30340;&#28966;&#28857;&#29228;&#34411;ThreatCrawl&#65292;&#20351;&#29992;&#20027;&#39064;&#24314;&#27169;&#21644;&#20851;&#38190;&#35789;&#25552;&#21462;&#25216;&#26415;&#26469;&#31579;&#36873;&#20986;&#26368;&#21487;&#33021;&#21253;&#21547;&#26377;&#20215;&#20540;CTI&#20449;&#24687;&#30340;&#32593;&#39029;&#12290;</title><link>http://arxiv.org/abs/2304.11960</link><description>&lt;p&gt;
ThreatCrawl&#65306;&#22522;&#20110;BERT&#30340;&#32593;&#32476;&#23433;&#20840;&#28966;&#28857;&#29228;&#34411;
&lt;/p&gt;
&lt;p&gt;
ThreatCrawl: A BERT-based Focused Crawler for the Cybersecurity Domain. (arXiv:2304.11960v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11960
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;BERT&#30340;&#28966;&#28857;&#29228;&#34411;ThreatCrawl&#65292;&#20351;&#29992;&#20027;&#39064;&#24314;&#27169;&#21644;&#20851;&#38190;&#35789;&#25552;&#21462;&#25216;&#26415;&#26469;&#31579;&#36873;&#20986;&#26368;&#21487;&#33021;&#21253;&#21547;&#26377;&#20215;&#20540;CTI&#20449;&#24687;&#30340;&#32593;&#39029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20844;&#24320;&#33719;&#21462;&#30340;&#20449;&#24687;&#23545;&#20110;&#32593;&#32476;&#23041;&#32961;&#24773;&#25253;&#65288;CTI&#65289;&#26469;&#35828;&#21253;&#21547;&#26377;&#20215;&#20540;&#30340;&#20449;&#24687;&#12290;&#36825;&#21487;&#20197;&#29992;&#20110;&#39044;&#38450;&#24050;&#32463;&#22312;&#20854;&#20182;&#31995;&#32479;&#19978;&#21457;&#29983;&#30340;&#25915;&#20987;&#12290;&#20294;&#26159;&#65292;&#34429;&#28982;&#26377;&#19981;&#21516;&#30340;&#26631;&#20934;&#26469;&#20132;&#27969;&#36825;&#20123;&#20449;&#24687;&#65292;&#20294;&#24456;&#22810;&#20449;&#24687;&#26159;&#20197;&#38750;&#26631;&#20934;&#21270;&#30340;&#26041;&#24335;&#22312;&#25991;&#31456;&#25110;&#21338;&#23458;&#24086;&#23376;&#20013;&#20849;&#20139;&#30340;&#12290;&#25163;&#21160;&#27983;&#35272;&#22810;&#20010;&#22312;&#32447;&#38376;&#25143;&#21644;&#26032;&#38395;&#39029;&#38754;&#20197;&#21457;&#29616;&#26032;&#23041;&#32961;&#24182;&#25552;&#21462;&#23427;&#20204;&#26159;&#19968;&#39033;&#32791;&#26102;&#30340;&#20219;&#21153;&#12290;&#20026;&#20102;&#33258;&#21160;&#21270;&#36825;&#20010;&#25195;&#25551;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#65292;&#22810;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20174;&#25991;&#26723;&#20013;&#25552;&#21462;&#23041;&#32961;&#25351;&#31034;&#22120;&#65288;IOCs&#65289;&#30340;&#25552;&#21462;&#22120;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#36825;&#24050;&#32463;&#35299;&#20915;&#20102;&#20174;&#25991;&#26723;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#38382;&#39064;&#65292;&#20294;&#24456;&#23569;&#32771;&#34385;&#25628;&#32034;&#36825;&#20123;&#25991;&#26723;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28966;&#28857;&#29228;&#34411;ThreatCrawl&#65292;&#23427;&#20351;&#29992;&#21452;&#21521;&#32534;&#30721;&#22120;&#34920;&#31034;&#65288;BERT&#65289;&#25628;&#32034;&#32593;&#32476;&#23433;&#20840;&#39046;&#22495;&#20013;&#30340;&#30456;&#20851;&#25991;&#26723;&#12290;ThreatCrawl&#20351;&#29992;&#20027;&#39064;&#24314;&#27169;&#21644;&#20851;&#38190;&#35789;&#25552;&#21462;&#25216;&#26415;&#26469;&#35782;&#21035;&#30456;&#20851;&#32593;&#31449;&#21644;&#32593;&#39029;&#65292;&#28982;&#21518;&#24212;&#29992;&#22522;&#20110;BERT&#30340;&#20998;&#31867;&#22120;&#26469;&#20248;&#20808;&#32771;&#34385;&#26368;&#21487;&#33021;&#21253;&#21547;&#26377;&#20215;&#20540;CTI&#20449;&#24687;&#30340;&#32593;&#39029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Publicly available information contains valuable information for Cyber Threat Intelligence (CTI). This can be used to prevent attacks that have already taken place on other systems. Ideally, only the initial attack succeeds and all subsequent ones are detected and stopped. But while there are different standards to exchange this information, a lot of it is shared in articles or blog posts in non-standardized ways. Manually scanning through multiple online portals and news pages to discover new threats and extracting them is a time-consuming task. To automize parts of this scanning process, multiple papers propose extractors that use Natural Language Processing (NLP) to extract Indicators of Compromise (IOCs) from documents. However, while this already solves the problem of extracting the information out of documents, the search for these documents is rarely considered. In this paper, a new focused crawler is proposed called ThreatCrawl, which uses Bidirectional Encoder Representations 
&lt;/p&gt;</description></item></channel></rss>