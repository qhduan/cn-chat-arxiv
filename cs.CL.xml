<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#20174;&#35821;&#35328;&#36827;&#21270;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#26032;&#20852;&#27807;&#36890;&#25991;&#29486;&#65292;&#21457;&#29616;&#20854;&#22312;&#35774;&#35745;&#21644;&#35843;&#25972;&#27169;&#22411;&#20197;&#24674;&#22797;&#33258;&#28982;&#35821;&#35328;&#20013;&#21021;&#22987;&#32570;&#22833;&#30340;&#35821;&#35328;&#29616;&#35937;&#26041;&#38754;&#34920;&#29616;&#20248;&#31168;&#65292;&#25581;&#31034;&#20102;&#20851;&#38190;&#21387;&#21147;&#20419;&#20351;&#24674;&#22797;&#26368;&#21021;&#19981;&#26174;&#29616;&#30340;&#20154;&#31867;&#27169;&#24335;&#12290;</title><link>https://arxiv.org/abs/2403.14427</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#32039;&#24613;&#27807;&#36890;&#21644;&#23398;&#20064;&#21387;&#21147;&#65306;&#35821;&#35328;&#36827;&#21270;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Emergent communication and learning pressures in language models: a language evolution perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14427
&lt;/p&gt;
&lt;p&gt;
&#20174;&#35821;&#35328;&#36827;&#21270;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#26032;&#20852;&#27807;&#36890;&#25991;&#29486;&#65292;&#21457;&#29616;&#20854;&#22312;&#35774;&#35745;&#21644;&#35843;&#25972;&#27169;&#22411;&#20197;&#24674;&#22797;&#33258;&#28982;&#35821;&#35328;&#20013;&#21021;&#22987;&#32570;&#22833;&#30340;&#35821;&#35328;&#29616;&#35937;&#26041;&#38754;&#34920;&#29616;&#20248;&#31168;&#65292;&#25581;&#31034;&#20102;&#20851;&#38190;&#21387;&#21147;&#20419;&#20351;&#24674;&#22797;&#26368;&#21021;&#19981;&#26174;&#29616;&#30340;&#20154;&#31867;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#21644;&#20154;&#31867;&#26159;&#20004;&#31181;&#23398;&#20064;&#31995;&#32479;&#12290;&#21457;&#29616;&#25110;&#20419;&#36827;&#20108;&#32773;&#20043;&#38388;&#30340;&#20849;&#21516;&#28857;&#21487;&#33021;&#20250;&#22312;&#25105;&#20204;&#29702;&#35299;&#35821;&#35328;&#30340;&#20064;&#24471;&#21644;&#28436;&#21270;&#26041;&#38754;&#21462;&#24471;&#37325;&#22823;&#31361;&#30772;&#12290;&#35768;&#22810;&#35821;&#35328;&#36827;&#21270;&#29702;&#35770;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#23398;&#20064;&#20559;&#22909;&#21644;&#23398;&#20064;&#21387;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23398;&#20064;&#21387;&#21147;&#23384;&#22312;&#30528;&#37325;&#22823;&#24046;&#24322;&#65292;&#23545;&#20110;&#20154;&#31867;&#21644;&#26426;&#22120;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26159;&#21542;&#36275;&#20197;&#21551;&#21457;&#27934;&#35265;&#24182;&#20540;&#24471;&#19982;&#20154;&#31867;&#21442;&#19982;&#32773;&#19968;&#36215;&#36827;&#34892;&#27979;&#35797;&#26159;&#20540;&#24471;&#24576;&#30097;&#30340;&#12290;&#26412;&#25991;&#20174;&#35821;&#35328;&#36827;&#21270;&#30340;&#35282;&#24230;&#23457;&#35270;&#20102;&#26032;&#20852;&#27807;&#36890;&#25991;&#29486;&#65292;&#36825;&#26159;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#19968;&#20010;&#23376;&#39046;&#22495;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#26032;&#20852;&#27807;&#36890;&#25991;&#29486;&#22312;&#35774;&#35745;&#21644;&#35843;&#25972;&#27169;&#22411;&#20197;&#24674;&#22797;&#33258;&#28982;&#35821;&#35328;&#30340;&#26368;&#21021;&#19981;&#26174;&#29616;&#30340;&#35821;&#35328;&#29616;&#35937;&#26041;&#38754;&#26377;&#26480;&#20986;&#34920;&#29616;&#12290;&#26681;&#25454;&#23545;&#25991;&#29486;&#30340;&#31616;&#35201;&#22238;&#39038;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20123;&#22312;&#26032;&#20852;&#27807;&#36890;&#20013;&#24674;&#22797;&#26368;&#21021;&#19981;&#26174;&#29616;&#30340;&#20154;&#31867;&#27169;&#24335;&#30340;&#20851;&#38190;&#21387;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14427v1 Announce Type: new  Abstract: Language models and humans are two types of learning systems. Finding or facilitating commonalities could enable major breakthroughs in our understanding of the acquisition and evolution of language. Many theories of language evolution rely heavily on learning biases and learning pressures. Yet due to substantial differences in learning pressures, it is questionable whether the similarity between humans and machines is sufficient for insights to carry over and to be worth testing with human participants. Here, we review the emergent communication literature, a subfield of multi-agent reinforcement learning, from a language evolution perspective. We find that the emergent communication literature excels at designing and adapting models to recover initially absent linguistic phenomena of natural languages. Based on a short literature review, we identify key pressures that have recovered initially absent human patterns in emergent communica
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22823;&#35268;&#27169;&#30417;&#27979;&#21644;&#20998;&#26512;GPT&#21830;&#24215;&#65292;&#24320;&#21457;&#20102;&#33258;&#21160;&#21270;&#24037;&#20855;&#26469;&#30740;&#31350;GPT&#24212;&#29992;&#31243;&#24207;&#20013;&#30340;&#28431;&#27934;&#21644;&#25220;&#34989;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2402.15105</link><description>&lt;p&gt;
GPT&#24212;&#29992;&#30340;&#21021;&#25506;&#65306;&#26684;&#23616;&#19982;&#33030;&#24369;&#24615;
&lt;/p&gt;
&lt;p&gt;
A First Look at GPT Apps: Landscape and Vulnerability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15105
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#35268;&#27169;&#30417;&#27979;&#21644;&#20998;&#26512;GPT&#21830;&#24215;&#65292;&#24320;&#21457;&#20102;&#33258;&#21160;&#21270;&#24037;&#20855;&#26469;&#30740;&#31350;GPT&#24212;&#29992;&#31243;&#24207;&#20013;&#30340;&#28431;&#27934;&#21644;&#25220;&#34989;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36827;&#27493;&#65292;&#36234;&#26469;&#36234;&#22797;&#26434;&#21644;&#24378;&#22823;&#30340;GPT&#36827;&#20837;&#24066;&#22330;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;LLM&#29983;&#24577;&#31995;&#32479;&#20173;&#28982;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;LLMs&#23545;&#25915;&#20987;&#30340;&#25935;&#24863;&#24615;&#24341;&#21457;&#20102;&#23545;&#23433;&#20840;&#24615;&#21644;&#25220;&#34989;&#30340;&#25285;&#24551;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;GPT&#21830;&#24215;&#36827;&#34892;&#20102;&#24320;&#21019;&#24615;&#30340;&#25506;&#32034;&#65292;&#26088;&#22312;&#30740;&#31350;GPT&#24212;&#29992;&#31243;&#24207;&#20013;&#30340;&#28431;&#27934;&#21644;&#25220;&#34989;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#25454;&#25105;&#20204;&#25152;&#30693;&#30340;&#31532;&#19968;&#27425;&#22823;&#35268;&#27169;&#30417;&#27979;&#21644;&#20998;&#26512;&#65292;&#20998;&#21035;&#26159;&#19968;&#20010;&#38750;&#23448;&#26041;&#30340;GPTStore.AI&#21644;&#19968;&#20010;&#23448;&#26041;&#30340;OpenAI GPT Store&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;TriLevel GPT Reversing&#65288;T-GR&#65289;&#31574;&#30053;&#65292;&#29992;&#20110;&#25552;&#21462;GPT&#20869;&#37096;&#20449;&#24687;&#12290;&#20026;&#20102;&#26377;&#25928;&#22320;&#23436;&#25104;&#36825;&#20004;&#39033;&#20219;&#21153;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#20010;&#33258;&#21160;&#21270;&#24037;&#20855;&#65306;&#19968;&#20010;&#29992;&#20110;&#32593;&#32476;&#25235;&#21462;&#65292;&#21478;&#19968;&#20010;&#35774;&#35745;&#29992;&#20110;&#19982;GPT&#36827;&#34892;&#31243;&#24207;&#21270;&#20132;&#20114;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20102;&#29992;&#25143;&#21644;&#24320;&#21457;&#32773;&#23545;GPT&#20132;&#20114;&#21644;&#21019;&#24314;&#30340;&#24040;&#22823;&#28909;&#24773;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15105v1 Announce Type: cross  Abstract: With the advancement of Large Language Models (LLMs), increasingly sophisticated and powerful GPTs are entering the market. Despite their popularity, the LLM ecosystem still remains unexplored. Additionally, LLMs' susceptibility to attacks raises concerns over safety and plagiarism. Thus, in this work, we conduct a pioneering exploration of GPT stores, aiming to study vulnerabilities and plagiarism within GPT applications. To begin with, we conduct, to our knowledge, the first large-scale monitoring and analysis of two stores, an unofficial GPTStore.AI, and an official OpenAI GPT Store. Then, we propose a TriLevel GPT Reversing (T-GR) strategy for extracting GPT internals. To complete these two tasks efficiently, we develop two automated tools: one for web scraping and another designed for programmatically interacting with GPTs. Our findings reveal a significant enthusiasm among users and developers for GPT interaction and creation, as
&lt;/p&gt;</description></item><item><title>&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;&#21487;&#20197;&#20316;&#20026;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#23384;&#22312;&#23545;&#27969;&#34892;&#24086;&#23376;&#20559;&#35265;&#36739;&#39640;&#12289;&#24773;&#24863;&#26356;&#31215;&#26497;&#20197;&#21450;&#24573;&#35270;&#25919;&#27835;&#12289;&#33394;&#24773;&#21644;&#31895;&#20439;&#24086;&#23376;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2401.15479</link><description>&lt;p&gt;
&#24212;&#23545;&#21518;API&#22256;&#22659;&#65306;&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;&#21576;&#29616;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#20559;&#35265;&#35266;
&lt;/p&gt;
&lt;p&gt;
Navigating the Post-API Dilemma Search Engine Results Pages Present a Biased View of Social Media Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15479
&lt;/p&gt;
&lt;p&gt;
&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;&#21487;&#20197;&#20316;&#20026;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#23384;&#22312;&#23545;&#27969;&#34892;&#24086;&#23376;&#20559;&#35265;&#36739;&#39640;&#12289;&#24773;&#24863;&#26356;&#31215;&#26497;&#20197;&#21450;&#24573;&#35270;&#25919;&#27835;&#12289;&#33394;&#24773;&#21644;&#31895;&#20439;&#24086;&#23376;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20572;&#27490;&#35775;&#38382;&#31038;&#20132;&#23186;&#20307;API&#30340;&#20915;&#23450;&#23545;&#20114;&#32852;&#32593;&#30740;&#31350;&#21644;&#25972;&#20010;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#39046;&#22495;&#20135;&#29983;&#20102;&#19981;&#21033;&#24433;&#21709;&#12290;&#36825;&#31181;&#23545;&#25968;&#25454;&#30340;&#35775;&#38382;&#32570;&#20047;&#24050;&#34987;&#31216;&#20026;&#20114;&#32852;&#32593;&#30740;&#31350;&#30340;&#21518;API&#26102;&#20195;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#27969;&#34892;&#30340;&#25628;&#32034;&#24341;&#25806;&#26377;&#33021;&#21147;&#29228;&#21462;&#12289;&#25429;&#33719;&#21644;&#23637;&#31034;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#22312;&#20854;&#25628;&#32034;&#24341;&#25806;&#32467;&#26524;&#39029;&#38754;(SERP)&#19978;&#65292;&#22914;&#26524;&#25552;&#20379;&#36866;&#24403;&#30340;&#25628;&#32034;&#26597;&#35810;&#65292;&#21487;&#33021;&#20250;&#20026;&#36825;&#19968;&#22256;&#22659;&#25552;&#20379;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#24403;&#21069;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38382;&#65306;SERP&#26159;&#21542;&#25552;&#20379;&#31038;&#20132;&#23186;&#20307;&#25968;&#25454;&#30340;&#23436;&#25972;&#21644;&#26080;&#20559;&#35265;&#26679;&#26412;&#65311; SERP&#26159;&#21542;&#26159;&#30452;&#25509;API&#35775;&#38382;&#30340;&#21487;&#34892;&#26367;&#20195;&#26041;&#26696;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#23545;&#65288;Google&#65289;SERP&#32467;&#26524;&#21644;&#26469;&#33258;Reddit&#21644;Twitter/X&#30340;&#38750;&#21462;&#26679;&#25968;&#25454;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;SERP&#32467;&#26524;&#22312;&#25903;&#25345;&#27969;&#34892;&#24086;&#23376;&#26041;&#38754;&#23384;&#22312;&#39640;&#24230;&#20559;&#35265;&#65307;&#21453;&#23545;&#25919;&#27835;&#12289;&#33394;&#24773;&#21644;&#31895;&#20439;&#24086;&#23376;&#65307;&#22312;&#24773;&#24863;&#19978;&#26356;&#20026;&#31215;&#26497;&#65307;&#24182;&#26377;&#22823;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.15479v2 Announce Type: replace-cross  Abstract: Recent decisions to discontinue access to social media APIs are having detrimental effects on Internet research and the field of computational social science as a whole. This lack of access to data has been dubbed the Post-API era of Internet research. Fortunately, popular search engines have the means to crawl, capture, and surface social media data on their Search Engine Results Pages (SERP) if provided the proper search query, and may provide a solution to this dilemma. In the present work we ask: does SERP provide a complete and unbiased sample of social media data? Is SERP a viable alternative to direct API-access? To answer these questions, we perform a comparative analysis between (Google) SERP results and nonsampled data from Reddit and Twitter/X. We find that SERP results are highly biased in favor of popular posts; against political, pornographic, and vulgar posts; are more positive in their sentiment; and have large 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#35789;&#27719;&#12289;&#35821;&#20041;&#21644;&#19978;&#19979;&#25991;&#34920;&#31034;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#20107;&#20214;&#26816;&#27979;&#26041;&#27861;&#22312;&#35782;&#21035;&#26032;&#20852;&#31038;&#20132;&#20107;&#20214;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#31038;&#20132;&#25968;&#25454;&#36827;&#34892;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#21270;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.16082</link><description>&lt;p&gt;
EnrichEvent: &#20351;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#20026;&#26032;&#20986;&#29616;&#30340;&#20107;&#20214;&#25552;&#20379;&#20016;&#23500;&#30340;&#31038;&#20132;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction. (arXiv:2307.16082v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#35789;&#27719;&#12289;&#35821;&#20041;&#21644;&#19978;&#19979;&#25991;&#34920;&#31034;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#20107;&#20214;&#26816;&#27979;&#26041;&#27861;&#22312;&#35782;&#21035;&#26032;&#20852;&#31038;&#20132;&#20107;&#20214;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#31038;&#20132;&#25968;&#25454;&#36827;&#34892;&#20016;&#23500;&#30340;&#19978;&#19979;&#25991;&#21270;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#24179;&#21488;&#24050;&#25104;&#20026;&#20256;&#25773;&#21644;&#35752;&#35770;&#30495;&#23454;&#20107;&#20214;&#20449;&#24687;&#30340;&#20851;&#38190;&#24179;&#21488;&#65292;&#20026;&#21450;&#26089;&#21457;&#29616;&#26377;&#26032;&#38395;&#20215;&#20540;&#30340;&#20107;&#20214;&#25552;&#20379;&#20102;&#33391;&#22909;&#30340;&#26426;&#20250;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#20107;&#20214;&#26816;&#27979;&#26041;&#27861;&#20165;&#21033;&#29992;&#20851;&#38190;&#35789;&#31361;&#21457;&#24615;&#25110;&#32593;&#32476;&#32467;&#26500;&#26469;&#26816;&#27979;&#28909;&#28857;&#20107;&#20214;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#20107;&#20214;&#21644;&#31038;&#20132;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#32780;&#35328;&#65292;&#23427;&#20204;&#24448;&#24448;&#26080;&#27861;&#22312;&#36798;&#21040;&#36235;&#21183;&#29366;&#24577;&#20043;&#21069;&#35782;&#21035;&#20986;&#26032;&#20986;&#29616;&#30340;&#31038;&#20132;&#20107;&#20214;&#12290;&#31038;&#20132;&#25968;&#25454;&#65292;&#20363;&#22914;&#25512;&#25991;&#65292;&#20855;&#26377;&#25340;&#20889;&#38169;&#35823;&#12289;&#19981;&#23436;&#25972;&#24615;&#12289;&#27495;&#20041;&#24615;&#21644;&#35821;&#35328;&#19981;&#35268;&#33539;&#24615;&#65292;&#20197;&#21450;&#24847;&#35265;&#26041;&#38754;&#30340;&#21464;&#21270;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#26377;&#38480;&#30340;&#19978;&#19979;&#25991;&#30693;&#35782;&#26469;&#23398;&#20064;&#20107;&#20214;&#30340;&#28436;&#21464;&#29305;&#24449;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20960;&#20046;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#27969;&#24335;&#31038;&#20132;&#25968;&#25454;&#30340;&#35789;&#27719;&#12289;&#35821;&#20041;&#21644;&#19978;&#19979;&#25991;&#34920;&#31034;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Social platforms have emerged as a crucial platform for disseminating and discussing information about real-life events, which offers an excellent opportunity for early detection of newsworthy events. However, most existing approaches for event detection solely exploit keyword burstiness or network structures to detect hot events. Thus, they often fail to identify emerging social events before reaching a trending state regarding the challenging nature of events and social data. Social data, e.g., tweets, is characterized by misspellings, incompleteness, ambiguity, and irregular language, as well as variation in aspects of opinions. Moreover, learning the evolving characteristics of the events utilizing limited contextual knowledge is almost infeasible for machine learning models. To address these problems, in this paper, we propose a framework that exploits the lexical, semantic, and contextual representations of streaming social data. In particular, we leverage contextual knowledge to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CIF-Transducer&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#23558;&#36830;&#32493;&#31215;&#20998;&#21644;&#28779;&#26426;&#21046;&#19982;RNN-T&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#23545;&#40784;&#65292;&#24182;&#25918;&#24323;&#20102;RNN-T Loss&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#65292;&#24182;&#20351;&#39044;&#27979;&#32593;&#32476;&#21457;&#25381;&#26356;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;CIF-T&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.14132</link><description>&lt;p&gt;
&#21578;&#21035;RNN-T Loss&#65306;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;CIF&#30340;&#36716;&#24405;&#22120;&#26550;&#26500;&#29992;&#20110;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for Automatic Speech Recognition. (arXiv:2307.14132v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CIF-Transducer&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#23558;&#36830;&#32493;&#31215;&#20998;&#21644;&#28779;&#26426;&#21046;&#19982;RNN-T&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#23545;&#40784;&#65292;&#24182;&#25918;&#24323;&#20102;RNN-T Loss&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#65292;&#24182;&#20351;&#39044;&#27979;&#32593;&#32476;&#21457;&#25381;&#26356;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;CIF-T&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
RNN-T&#27169;&#22411;&#22312;ASR&#20013;&#24191;&#27867;&#20351;&#29992;&#65292;&#20381;&#38752;RNN-T Loss&#23454;&#29616;&#36755;&#20837;&#38899;&#39057;&#21644;&#30446;&#26631;&#24207;&#21015;&#30340;&#38271;&#24230;&#23545;&#40784;&#12290;&#28982;&#32780;&#65292;RNN-T Loss&#30340;&#23454;&#29616;&#22797;&#26434;&#24615;&#21644;&#22522;&#20110;&#23545;&#40784;&#30340;&#20248;&#21270;&#30446;&#26631;&#23548;&#33268;&#35745;&#31639;&#20887;&#20313;&#21644;&#39044;&#27979;&#32593;&#32476;&#35282;&#33394;&#30340;&#20943;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CIF-Transducer&#65288;CIF-T&#65289;&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#23427;&#23558;&#36830;&#32493;&#31215;&#20998;&#21644;&#28779;&#65288;CIF&#65289;&#26426;&#21046;&#19982;RNN-T&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#23454;&#29616;&#39640;&#25928;&#30340;&#23545;&#40784;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25918;&#24323;&#20102;RNN-T Loss&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#65292;&#24182;&#20351;&#39044;&#27979;&#32593;&#32476;&#21457;&#25381;&#26356;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;Funnel-CIF&#12289;Context Blocks&#12289;Unified Gating&#21644;Bilinear Pooling&#32852;&#21512;&#32593;&#32476;&#20197;&#21450;&#36741;&#21161;&#35757;&#32451;&#31574;&#30053;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;178&#23567;&#26102;&#30340;AISHELL-1&#21644;10000&#23567;&#26102;&#30340;WenetSpeech&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;RNN-T&#27169;&#22411;&#30456;&#27604;&#65292;CIF-T&#20197;&#26356;&#20302;&#30340;&#35745;&#31639;&#24320;&#38144;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve length alignment between input audio and target sequence. However, the implementation complexity and the alignment-based optimization target of RNN-T loss lead to computational redundancy and a reduced role for predictor network, respectively. In this paper, we propose a novel model named CIF-Transducer (CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism with the RNN-T model to achieve efficient alignment. In this way, the RNN-T loss is abandoned, thus bringing a computational reduction and allowing the predictor network a more significant role. We also introduce Funnel-CIF, Context Blocks, Unified Gating and Bilinear Pooling joint network, and auxiliary training strategy to further improve performance. Experiments on the 178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves state-of-the-art results with lower computational overhead compared to RNN-T models.
&lt;/p&gt;</description></item></channel></rss>