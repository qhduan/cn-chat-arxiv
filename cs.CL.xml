<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>GPT-4&#22312;&#26631;&#20934;&#21270;&#35821;&#31687;&#29702;&#35299;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#19982;&#20154;&#31867;&#30456;&#24403;&#30340;&#33021;&#21147;&#65292;&#23588;&#20854;&#22312;&#25512;&#26029;&#26410;&#26126;&#30830;&#38472;&#36848;&#20449;&#24687;&#26041;&#38754;&#26174;&#31034;&#20986;&#26174;&#33879;&#23454;&#21147;</title><link>https://arxiv.org/abs/2403.17196</link><description>&lt;p&gt;
GPT-4&#33267;&#23569;&#33021;&#22815;&#20687;&#20154;&#31867;&#19968;&#26679;&#29702;&#35299;&#35821;&#31687;
&lt;/p&gt;
&lt;p&gt;
GPT-4 Understands Discourse at Least as Well as Humans Do
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17196
&lt;/p&gt;
&lt;p&gt;
GPT-4&#22312;&#26631;&#20934;&#21270;&#35821;&#31687;&#29702;&#35299;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#19982;&#20154;&#31867;&#30456;&#24403;&#30340;&#33021;&#21147;&#65292;&#23588;&#20854;&#22312;&#25512;&#26029;&#26410;&#26126;&#30830;&#38472;&#36848;&#20449;&#24687;&#26041;&#38754;&#26174;&#31034;&#20986;&#26174;&#33879;&#23454;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#27979;&#35797;&#20102;&#19968;&#31181;&#39046;&#20808;&#30340;AI&#31995;&#32479;GPT-4&#26159;&#21542;&#20687;&#20154;&#31867;&#19968;&#26679;&#29702;&#35299;&#35821;&#31687;&#65292;&#20351;&#29992;&#20102;&#19968;&#39033;&#26631;&#20934;&#21270;&#30340;&#35821;&#31687;&#29702;&#35299;&#27979;&#35797;&#12290;&#21442;&#19982;&#32773;&#20250;&#34987;&#21576;&#29616;&#31616;&#30701;&#30340;&#25925;&#20107;&#65292;&#28982;&#21518;&#22238;&#31572;&#20843;&#20010;&#26159;/&#21542;&#38382;&#39064;&#65292;&#25506;&#31350;&#20182;&#20204;&#23545;&#25925;&#20107;&#30340;&#29702;&#35299;&#12290;&#36825;&#20123;&#38382;&#39064;&#30340;&#26684;&#24335;&#26088;&#22312;&#35780;&#20272;&#30452;&#25509;&#24615;&#65288;&#38472;&#36848; vs. &#26263;&#31034;&#65289;&#21644;&#26174;&#33879;&#24615;&#65288;&#20027;&#35201;&#35266;&#28857; vs. &#32454;&#33410;&#65289;&#30340;&#29420;&#31435;&#24433;&#21709;&#12290;&#37492;&#20110;&#20154;&#31867;&#34920;&#29616;&#27700;&#24179;&#38750;&#24120;&#39640;&#65292;GPT-4&#30340;&#34920;&#29616;&#30053;&#22909;&#20110;&#20154;&#31867;&#65292;&#20294;&#24182;&#26080;&#32479;&#35745;&#23398;&#26174;&#33879;&#24046;&#24322;&#12290;GPT-4&#21644;&#20154;&#31867;&#37117;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#33021;&#21147;&#65292;&#33021;&#22815;&#25512;&#26029;&#25925;&#20107;&#20013;&#26410;&#26126;&#30830;&#38472;&#36848;&#30340;&#20449;&#24687;&#65292;&#36825;&#26159;&#23545;&#29702;&#35299;&#21147;&#30340;&#37325;&#35201;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17196v1 Announce Type: new  Abstract: We test whether a leading AI system GPT-4 understands discourse as well as humans do, using a standardized test of discourse comprehension. Participants are presented with brief stories and then answer eight yes/no questions probing their comprehension of the story. The questions are formatted to assess the separate impacts of directness (stated vs. implied) and salience (main idea vs. details). GPT-4 performs slightly, but not statistically significantly, better than humans given the very high level of human performance. Both GPT-4 and humans exhibit a strong ability to make inferences about information that is not explicitly stated in a story, a critical test of understanding.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#26159;&#21542;&#23384;&#22312;&#31038;&#20250;&#32463;&#27982;&#20559;&#35265;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;SilverSpoon&#65292;&#24182;&#35780;&#20272;&#20102;&#36825;&#31181;&#20559;&#35265;&#30340;&#31243;&#24230;&#20197;&#21450;&#38543;&#30528;&#27169;&#22411;&#22823;&#23567;&#30340;&#21464;&#21270;&#12290;</title><link>https://arxiv.org/abs/2403.14633</link><description>&lt;p&gt;
&#20986;&#36523;&#23500;&#36149;&#65311;&#25506;&#35752;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#31038;&#20250;&#32463;&#27982;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Born With a Silver Spoon? Investigating Socioeconomic Bias in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14633
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#26159;&#21542;&#23384;&#22312;&#31038;&#20250;&#32463;&#27982;&#20559;&#35265;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;SilverSpoon&#65292;&#24182;&#35780;&#20272;&#20102;&#36825;&#31181;&#20559;&#35265;&#30340;&#31243;&#24230;&#20197;&#21450;&#38543;&#30528;&#27169;&#22411;&#22823;&#23567;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20250;&#32463;&#27982;&#20559;&#35265;&#22312;&#31038;&#20250;&#20013;&#21152;&#21095;&#20102;&#19981;&#20844;&#24179;&#29616;&#35937;&#65292;&#26681;&#25454;&#20010;&#20154;&#32463;&#27982;&#21644;&#31038;&#20250;&#32972;&#26223;&#24433;&#21709;&#33719;&#21462;&#26426;&#20250;&#21644;&#36164;&#28304;&#30340;&#26426;&#20250;&#12290;&#36825;&#19968;&#26222;&#36941;&#38382;&#39064;&#25345;&#32493;&#22320;&#24310;&#32493;&#20102;&#31995;&#32479;&#24615;&#30340;&#19981;&#24179;&#31561;&#65292;&#38459;&#30861;&#20102;&#20316;&#20026;&#19968;&#20010;&#31038;&#20250;&#36861;&#27714;&#21253;&#23481;&#24615;&#36827;&#27493;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#26159;&#21542;&#23384;&#22312;&#31038;&#20250;&#32463;&#27982;&#20559;&#35265;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65288;SilverSpoon&#65289;&#65292;&#21253;&#21547;3000&#20010;&#26679;&#26412;&#65292;&#23637;&#31034;&#20102;&#29301;&#28041;&#21040;&#24369;&#21183;&#32676;&#20307;&#30001;&#20110;&#20182;&#20204;&#30340;&#22788;&#22659;&#32780;&#23454;&#26045;&#36947;&#24503;&#27169;&#31946;&#34892;&#20026;&#30340;&#20551;&#35774;&#24773;&#26223;&#65292;&#24182;&#38382;&#36825;&#31181;&#34892;&#20026;&#26159;&#21542;&#22312;&#36947;&#24503;&#19978;&#25104;&#31435;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#20855;&#26377;&#21452;&#37325;&#26631;&#35760;&#26041;&#26696;&#65292;&#24182;&#30001;&#23646;&#20110;&#31038;&#20250;&#32463;&#27982;&#20004;&#31471;&#30340;&#20154;&#36827;&#34892;&#20102;&#27880;&#37322;&#12290;&#20351;&#29992;SilverSpoon&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#34920;&#29616;&#20986;&#30340;&#31038;&#20250;&#32463;&#27982;&#20559;&#35265;&#31243;&#24230;&#20197;&#21450;&#35813;&#31243;&#24230;&#22914;&#20309;&#38543;&#27169;&#22411;&#22823;&#23567;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14633v1 Announce Type: cross  Abstract: Socioeconomic bias in society exacerbates disparities, influencing access to opportunities and resources based on individuals' economic and social backgrounds. This pervasive issue perpetuates systemic inequalities, hindering the pursuit of inclusive progress as a society. In this paper, we investigate the presence of socioeconomic bias, if any, in large language models. To this end, we introduce a novel dataset (SilverSpoon), consisting of 3000 samples that illustrate hypothetical scenarios that involve underprivileged people performing ethically ambiguous actions due to their circumstances, and ask whether the action is ethically justified. Further, this dataset has a dual-labeling scheme and has been annotated by people belonging to both ends of the socioeconomic spectrum. Using SilverSpoon, we evaluate the degree of socioeconomic bias expressed in large language models and the variation of this degree as a function of model size. W
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;SLCoLM&#65292;&#19968;&#20010;&#27169;&#22411;&#21327;&#20316;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#8220;&#35757;&#32451;-&#25351;&#23548;-&#39044;&#27979;&#8221;&#31574;&#30053;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#22823;&#35821;&#35328;&#27169;&#22411;&#65292;&#25104;&#21151;&#32531;&#35299;&#20102;&#38271;&#23614;&#25968;&#25454;&#38382;&#39064;&#65292;&#20419;&#36827;&#20102;&#23454;&#20307;&#20851;&#31995;&#30340;&#25277;&#21462;&#12290;</title><link>https://arxiv.org/abs/2402.14373</link><description>&lt;p&gt;
&#23567;&#35821;&#35328;&#27169;&#22411;&#22312;&#20013;&#25991;&#23454;&#20307;&#20851;&#31995;&#25277;&#21462;&#20013;&#26159;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#33391;&#22909;&#21521;&#23548;
&lt;/p&gt;
&lt;p&gt;
Small Language Model Is a Good Guide for Large Language Model in Chinese Entity Relation Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14373
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;SLCoLM&#65292;&#19968;&#20010;&#27169;&#22411;&#21327;&#20316;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#8220;&#35757;&#32451;-&#25351;&#23548;-&#39044;&#27979;&#8221;&#31574;&#30053;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#22823;&#35821;&#35328;&#27169;&#22411;&#65292;&#25104;&#21151;&#32531;&#35299;&#20102;&#38271;&#23614;&#25968;&#25454;&#38382;&#39064;&#65292;&#20419;&#36827;&#20102;&#23454;&#20307;&#20851;&#31995;&#30340;&#25277;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20851;&#31995;&#25277;&#21462;&#65288;RE&#65289;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#23588;&#20854;&#26159;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20013;&#12290;&#20851;&#31995;&#25277;&#21462;&#39046;&#22495;&#20013;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#26159;&#38271;&#23614;&#25968;&#25454;&#65292;&#28982;&#32780;&#30446;&#21069;&#24456;&#23569;&#26377;&#20851;&#27880;&#20351;&#29992;LLM&#26041;&#27861;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SLCoLM&#65292;&#19968;&#20010;&#27169;&#22411;&#21327;&#20316;&#26694;&#26550;&#65292;&#20197;&#32531;&#35299;&#25968;&#25454;&#38271;&#23614;&#38382;&#39064;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#8220;&#35757;&#32451;-&#25351;&#23548;-&#39044;&#27979;&#8221;&#31574;&#30053;&#26469;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#21644;LLMs&#30340;&#20248;&#21183;&#65292;&#20854;&#20013;&#19968;&#20010;&#29305;&#23450;&#20110;&#20219;&#21153;&#30340;PLM&#26694;&#26550;&#20805;&#24403;&#23548;&#24072;&#65292;&#23558;&#20219;&#21153;&#30693;&#35782;&#36716;&#31227;&#21040;LLM&#65292;&#24182;&#25351;&#23548;LLM&#25191;&#34892;RE&#20219;&#21153;&#12290;&#25105;&#20204;&#23545;&#19968;&#20010;&#23500;&#21547;&#20851;&#31995;&#31867;&#22411;&#30340;RE&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#26412;&#25991;&#20013;&#30340;&#26041;&#27861;&#20419;&#36827;&#20102;&#38271;&#23614;&#20851;&#31995;&#31867;&#22411;&#30340;RE&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14373v1 Announce Type: new  Abstract: Recently, large language models (LLMs) have been successful in relational extraction (RE) tasks, especially in the few-shot learning. An important problem in the field of RE is long-tailed data, while not much attention is currently paid to this problem using LLM approaches. Therefore, in this paper, we propose SLCoLM, a model collaboration framework, to mitigate the data long-tail problem. In our framework, We use the ``\textit{Training-Guide-Predict}'' strategy to combine the strengths of pre-trained language models (PLMs) and LLMs, where a task-specific PLM framework acts as a tutor, transfers task knowledge to the LLM, and guides the LLM in performing RE tasks. Our experiments on a RE dataset rich in relation types show that the approach in this paper facilitates RE of long-tail relation types.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#20195;&#29702;&#20989;&#25968;&#22312;&#36845;&#20195;&#23631;&#34109;&#23454;&#39564;&#20013;&#35780;&#20272;&#20102;&#36716;&#25442;&#22120;&#27169;&#22411;&#25152;&#32534;&#30721;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#20854;&#20182;&#35780;&#20272;&#26041;&#27861;&#30340;&#20559;&#35265;&#20272;&#35745;&#65292;&#21457;&#29616;&#36716;&#25442;&#22120;&#27169;&#22411;&#20013;&#23384;&#22312;&#30456;&#23545;&#36739;&#39640;&#30340;&#23447;&#25945;&#21644;&#27531;&#30142;&#20559;&#35265;&#65292;&#32780;&#24615;&#21035;&#20559;&#35265;&#21017;&#30456;&#23545;&#36739;&#20302;&#12290;</title><link>https://arxiv.org/abs/2402.13954</link><description>&lt;p&gt;
&#36890;&#36807;&#39044;&#27979;&#36136;&#37327;&#38388;&#25509;&#27979;&#37327;&#25513;&#30422;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#31038;&#20250;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#20195;&#29702;&#20989;&#25968;&#22312;&#36845;&#20195;&#23631;&#34109;&#23454;&#39564;&#20013;&#35780;&#20272;&#20102;&#36716;&#25442;&#22120;&#27169;&#22411;&#25152;&#32534;&#30721;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#20854;&#20182;&#35780;&#20272;&#26041;&#27861;&#30340;&#20559;&#35265;&#20272;&#35745;&#65292;&#21457;&#29616;&#36716;&#25442;&#22120;&#27169;&#22411;&#20013;&#23384;&#22312;&#30456;&#23545;&#36739;&#39640;&#30340;&#23447;&#25945;&#21644;&#27531;&#30142;&#20559;&#35265;&#65292;&#32780;&#24615;&#21035;&#20559;&#35265;&#21017;&#30456;&#23545;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20250;&#21644;&#25919;&#27835;&#31185;&#23398;&#23478;&#32463;&#24120;&#26088;&#22312;&#20174;&#25991;&#26412;&#25968;&#25454;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#20013;&#21457;&#29616;&#21644;&#34913;&#37327;&#19981;&#21516;&#30340;&#20559;&#35265;&#12290;&#21019;&#26032;&#30340;&#22522;&#20110;&#36716;&#25442;&#22120;&#30340;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20855;&#26377;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20196;&#29260;&#23884;&#20837;&#65292;&#24182;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#24050;&#34987;&#35777;&#26126;&#22312;&#19979;&#28216;&#24212;&#29992;&#20013;&#32534;&#30721;&#20102;&#19981;&#38656;&#35201;&#30340;&#20559;&#35265;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#20195;&#29702;&#20989;&#25968;&#22312;&#36845;&#20195;&#23631;&#34109;&#23454;&#39564;&#20013;&#35780;&#20272;&#30001;&#35757;&#32451;&#26377;&#36974;&#34109;&#35821;&#35328;&#24314;&#27169;&#30446;&#26631;&#30340;&#36716;&#25442;&#22120;&#25152;&#32534;&#30721;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#20197;&#27979;&#37327;&#36716;&#25442;&#22120;&#27169;&#22411;&#39044;&#27979;&#36136;&#37327;&#65292;&#24182;&#35780;&#20272;MLM&#23545;&#19981;&#21033;&#32676;&#20307;&#21644;&#26377;&#21033;&#32676;&#20307;&#30340;&#20559;&#22909;&#12290;&#25105;&#20204;&#27604;&#36739;&#20351;&#29992;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#20559;&#35265;&#20272;&#35745;&#19982;&#20854;&#20182;&#35780;&#20272;&#26041;&#27861;&#20135;&#29983;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#32771;&#34385;&#30340;MLMs&#20013;&#23384;&#22312;&#30456;&#23545;&#36739;&#39640;&#30340;&#23447;&#25945;&#21644;&#27531;&#30142;&#20559;&#35265;&#65292;&#32780;&#30456;&#23545;&#20110;&#21478;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#19968;&#20010;&#25968;&#25454;&#38598;&#20013;&#23384;&#22312;&#36739;&#20302;&#30340;&#24615;&#21035;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13954v1 Announce Type: new  Abstract: Social and political scientists often aim to discover and measure distinct biases from text data representations (embeddings). Innovative transformer-based language models produce contextually-aware token embeddings and have achieved state-of-the-art performance for a variety of natural language tasks, but have been shown to encode unwanted biases for downstream applications. In this paper, we evaluate the social biases encoded by transformers trained with the masked language modeling objective using proposed proxy functions within an iterative masking experiment to measure the quality of transformer models' predictions, and assess the preference of MLMs towards disadvantaged and advantaged groups. We compare bias estimations with those produced by other evaluation methods using two benchmark datasets, finding relatively high religious and disability biases across considered MLMs and low gender bias in one dataset relative to the other. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;RoBERTa-CNN&#27169;&#22411;&#26469;&#22312;&#31038;&#20132;&#23186;&#20307;&#24086;&#23376;&#20013;&#26816;&#27979;&#33258;&#26432;&#24847;&#22270;&#30340;&#26032;&#26041;&#27861;&#12290;RoBERTa-CNN&#36890;&#36807;&#22312;RoBERTa&#27169;&#22411;&#20013;&#28155;&#21152;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#23618;&#65292;&#25552;&#39640;&#20102;&#23545;&#37325;&#35201;&#27169;&#24335;&#30340;&#25429;&#25417;&#33021;&#21147;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#22312;&#33258;&#26432;&#21644;&#25233;&#37057;&#26816;&#27979;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02262</link><description>&lt;p&gt;
&#25968;&#25454;&#36136;&#37327;&#24456;&#37325;&#35201;&#65306;&#20351;&#29992;RoBERTa-CNN&#27169;&#22411;&#22312;&#31038;&#20132;&#23186;&#20307;&#24086;&#23376;&#20013;&#26816;&#27979;&#33258;&#26432;&#24847;&#22270;
&lt;/p&gt;
&lt;p&gt;
Data Quality Matters: Suicide Intention Detection on Social Media Posts Using a RoBERTa-CNN Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;RoBERTa-CNN&#27169;&#22411;&#26469;&#22312;&#31038;&#20132;&#23186;&#20307;&#24086;&#23376;&#20013;&#26816;&#27979;&#33258;&#26432;&#24847;&#22270;&#30340;&#26032;&#26041;&#27861;&#12290;RoBERTa-CNN&#36890;&#36807;&#22312;RoBERTa&#27169;&#22411;&#20013;&#28155;&#21152;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#23618;&#65292;&#25552;&#39640;&#20102;&#23545;&#37325;&#35201;&#27169;&#24335;&#30340;&#25429;&#25417;&#33021;&#21147;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#22312;&#33258;&#26432;&#21644;&#25233;&#37057;&#26816;&#27979;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#26432;&#20173;&#28982;&#26159;&#20840;&#29699;&#20581;&#24247;&#39046;&#22495;&#30340;&#19968;&#20010;&#20851;&#27880;&#28966;&#28857;&#65292;&#24613;&#38656;&#21019;&#26032;&#26041;&#27861;&#36827;&#34892;&#26089;&#26399;&#26816;&#27979;&#21644;&#24178;&#39044;&#12290;&#26412;&#25991;&#30528;&#37325;&#20110;&#35782;&#21035;SuicideWatch Reddit&#24086;&#23376;&#20013;&#30340;&#33258;&#26432;&#24847;&#22270;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23574;&#31471;&#30340;RoBERTa-CNN&#27169;&#22411;&#36827;&#34892;&#33258;&#26432;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;RoBERTa-CNN&#26159;RoBERTa&#65288;&#40065;&#26834;&#24615;&#20248;&#21270;BERT&#26041;&#27861;&#65289;&#30340;&#19968;&#31181;&#21464;&#20307;&#12290;RoBERTa&#34987;&#29992;&#20110;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#65292;&#21253;&#25324;&#25991;&#26412;&#20998;&#31867;&#21644;&#24773;&#24863;&#20998;&#26512;&#12290;RoBERTa&#30340;&#26377;&#25928;&#24615;&#22312;&#20110;&#23427;&#33021;&#22815;&#25429;&#25417;&#25991;&#26412;&#20449;&#24687;&#24182;&#24418;&#25104;&#25991;&#26412;&#20043;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;&#36890;&#36807;&#22312;&#21407;&#22987;&#27169;&#22411;&#20013;&#28155;&#21152;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#23618;&#65292;RoBERTa&#22686;&#24378;&#20102;&#20174;&#24222;&#22823;&#25968;&#25454;&#38598;&#20013;&#25429;&#25417;&#37325;&#35201;&#27169;&#24335;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#33258;&#26432;&#21644;&#25233;&#37057;&#26816;&#27979;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;RoBERTa-CNN&#65292;&#24182;&#33719;&#24471;&#20102;&#21487;&#38752;&#30340;&#32467;&#26524;&#65292;&#20363;&#22914;&#65292;RoBERTa-CNN&#22312;&#24179;&#22343;&#20934;&#30830;&#29575;&#19978;&#33719;&#24471;&#20102;98&#65285;&#65292;&#26631;&#20934;&#24046;&#20026;...
&lt;/p&gt;
&lt;p&gt;
Suicide remains a global health concern for the field of health, which urgently needs innovative approaches for early detection and intervention. In this paper, we focus on identifying suicidal intentions in SuicideWatch Reddit posts and present a novel approach to suicide detection using the cutting-edge RoBERTa-CNN model, a variant of RoBERTa (Robustly optimized BERT approach). RoBERTa is used for various Natural Language Processing (NLP) tasks, including text classification and sentiment analysis. The effectiveness of the RoBERTa lies in its ability to capture textual information and form semantic relationships within texts. By adding the Convolution Neural Network (CNN) layer to the original model, the RoBERTa enhances its ability to capture important patterns from heavy datasets. To evaluate the RoBERTa-CNN, we experimented on the Suicide and Depression Detection dataset and obtained solid results. For example, RoBERTa-CNN achieves 98% mean accuracy with the standard deviation (ST
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35843;&#26597;&#20102;&#26368;&#36817;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#30740;&#31350;&#36827;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#19981;&#21516;&#31639;&#27861;&#24615;&#33021;&#30340;&#28145;&#24230;&#27604;&#36739;&#65292;&#36824;&#25506;&#35752;&#20102;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#26041;&#27861;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.10825</link><description>&lt;p&gt;
&#26368;&#26032;&#36827;&#23637;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A survey on recent advances in named entity recognition. (arXiv:2401.10825v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10825
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35843;&#26597;&#20102;&#26368;&#36817;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#30740;&#31350;&#36827;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#19981;&#21516;&#31639;&#27861;&#24615;&#33021;&#30340;&#28145;&#24230;&#27604;&#36739;&#65292;&#36824;&#25506;&#35752;&#20102;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#26041;&#27861;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#26088;&#22312;&#20174;&#25991;&#26412;&#20013;&#25552;&#21462;&#20986;&#21629;&#21517;&#30495;&#23454;&#19990;&#30028;&#23545;&#35937;&#30340;&#23376;&#23383;&#31526;&#20018;&#65292;&#24182;&#30830;&#23450;&#20854;&#31867;&#22411;&#65288;&#20363;&#22914;&#65292;&#26159;&#21542;&#25351;&#20154;&#29289;&#25110;&#32452;&#32455;&#65289;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#27010;&#36848;&#20102;&#26368;&#36817;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#20851;&#27880;&#20102;&#22522;&#20110;&#22270;&#21644;&#21464;&#25442;&#22120;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#24456;&#23569;&#22312;&#20854;&#20182;&#32508;&#36848;&#20013;&#28041;&#21450;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#38024;&#23545;&#31232;&#32570;&#27880;&#37322;&#25968;&#25454;&#38598;&#35774;&#35745;&#30340;&#26041;&#27861;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#20027;&#35201;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#23454;&#29616;&#22312;&#21508;&#31181;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#65288;&#39046;&#22495;&#12289;&#35268;&#27169;&#21644;&#31867;&#21035;&#25968;&#65289;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20174;&#26410;&#21516;&#26102;&#32771;&#34385;&#30340;&#31639;&#27861;&#30340;&#28145;&#24230;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#25968;&#25454;&#38598;&#29305;&#24449;&#22914;&#20309;&#24433;&#21709;&#25105;&#20204;&#27604;&#36739;&#30340;&#26041;&#27861;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Named Entity Recognition seeks to extract substrings within a text that name real-world objects and to determine their type (for example, whether they refer to persons or organizations). In this survey, we first present an overview of recent popular approaches, but we also look at graph- and transformer- based methods including Large Language Models (LLMs) that have not had much coverage in other surveys. Second, we focus on methods designed for datasets with scarce annotations. Third, we evaluate the performance of the main NER implementations on a variety of datasets with differing characteristics (as regards their domain, their size, and their number of classes). We thus provide a deep comparison of algorithms that are never considered together. Our experiments shed some light on how the characteristics of datasets affect the behavior of the methods that we compare.
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#25512;&#29702;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#25552;&#39640;&#25552;&#31034;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#19968;&#33268;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Hypotheses-to-Theories (HtT)&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;LLMs&#25512;&#29702;&#30340;&#35268;&#21017;&#24211;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#25552;&#31034;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.07064</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#23398;&#20064;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Large Language Models can Learn Rules. (arXiv:2310.07064v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07064
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#25512;&#29702;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#25552;&#39640;&#25552;&#31034;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#19968;&#33268;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Hypotheses-to-Theories (HtT)&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;LLMs&#25512;&#29702;&#30340;&#35268;&#21017;&#24211;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#25552;&#31034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#32473;&#20986;&#19968;&#20123;&#31034;&#20363;&#21644;&#20013;&#38388;&#27493;&#39588;&#26102;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#25512;&#29702;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20381;&#36182;LLM&#20013;&#30340;&#38544;&#24335;&#30693;&#35782;&#30340;&#25552;&#31034;&#26041;&#27861;&#22312;&#38544;&#24335;&#30693;&#35782;&#38169;&#35823;&#25110;&#19982;&#20219;&#21153;&#19981;&#19968;&#33268;&#26102;&#24448;&#24448;&#20250;&#20135;&#29983;&#38169;&#35823;&#30340;&#31572;&#26696;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;"&#20551;&#35774;&#21040;&#29702;&#35770;" (HtT) &#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;LLMs&#25512;&#29702;&#30340;&#35268;&#21017;&#24211;&#12290;HtT&#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#65292;&#24402;&#32435;&#38454;&#27573;&#21644;&#28436;&#32462;&#38454;&#27573;&#12290;&#22312;&#24402;&#32435;&#38454;&#27573;&#65292;&#39318;&#20808;&#35201;&#27714;LLM&#26681;&#25454;&#19968;&#32452;&#35757;&#32451;&#31034;&#20363;&#29983;&#25104;&#21644;&#39564;&#35777;&#35268;&#21017;&#12290;&#20986;&#29616;&#24182;&#23548;&#33268;&#27491;&#30830;&#31572;&#26696;&#30340;&#35268;&#21017;&#23558;&#34987;&#25910;&#38598;&#24418;&#25104;&#19968;&#20010;&#35268;&#21017;&#24211;&#12290;&#22312;&#28436;&#32462;&#38454;&#27573;&#65292;&#28982;&#21518;&#35201;&#27714;LLM&#20351;&#29992;&#23398;&#20064;&#30340;&#35268;&#21017;&#24211;&#36827;&#34892;&#25512;&#29702;&#20197;&#22238;&#31572;&#27979;&#35797;&#38382;&#39064;&#12290;&#22312;&#25968;&#20540;&#25512;&#29702;&#21644;&#20851;&#31995;&#25512;&#29702;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;HtT&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#25552;&#31034;&#26041;&#27861;&#65292;&#20351;&#20854;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
When prompted with a few examples and intermediate steps, large language models (LLMs) have demonstrated impressive performance in various reasoning tasks. However, prompting methods that rely on implicit knowledge in an LLM often hallucinate incorrect answers when the implicit knowledge is wrong or inconsistent with the task. To tackle this problem, we present Hypotheses-to-Theories (HtT), a framework that learns a rule library for reasoning with LLMs. HtT contains two stages, an induction stage and a deduction stage. In the induction stage, an LLM is first asked to generate and verify rules over a set of training examples. Rules that appear and lead to correct answers sufficiently often are collected to form a rule library. In the deduction stage, the LLM is then prompted to employ the learned rule library to perform reasoning to answer test questions. Experiments on both numerical reasoning and relational reasoning problems show that HtT improves existing prompting methods, with an 
&lt;/p&gt;</description></item></channel></rss>