<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#23558;&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;SLMs&#65289;&#19982;&#25552;&#31034;&#23398;&#20064;&#33539;&#24335;&#32467;&#21512;&#24212;&#29992;&#20110;&#39046;&#22495;&#29305;&#23450;&#25991;&#26412;&#20998;&#31867;&#30340;&#28508;&#21147;&#65292;&#24182;&#22312;&#38646;&#21806;&#19994;&#30340;&#23458;&#25143;&#21644;&#20195;&#29702;&#20154;&#20132;&#20114;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#19979;&#65292;SLM T5-base&#33021;&#22815;&#23454;&#29616;&#32422;75%&#30340;&#20934;&#30830;&#29575;&#65292;&#23637;&#29616;&#20102;SLMs&#19982;&#25552;&#31034;&#23398;&#20064;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.14779</link><description>&lt;p&gt;
&#20351;&#29992;&#25552;&#31034;&#23398;&#20064;&#33539;&#24335;&#25506;&#32034;&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#39640;&#25928;&#39046;&#22495;&#29305;&#23450;&#25991;&#26412;&#20998;&#31867;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification. (arXiv:2309.14779v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#23558;&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;SLMs&#65289;&#19982;&#25552;&#31034;&#23398;&#20064;&#33539;&#24335;&#32467;&#21512;&#24212;&#29992;&#20110;&#39046;&#22495;&#29305;&#23450;&#25991;&#26412;&#20998;&#31867;&#30340;&#28508;&#21147;&#65292;&#24182;&#22312;&#38646;&#21806;&#19994;&#30340;&#23458;&#25143;&#21644;&#20195;&#29702;&#20154;&#20132;&#20114;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#19979;&#65292;SLM T5-base&#33021;&#22815;&#23454;&#29616;&#32422;75%&#30340;&#20934;&#30830;&#29575;&#65292;&#23637;&#29616;&#20102;SLMs&#19982;&#25552;&#31034;&#23398;&#20064;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#23545;&#25163;&#21160;&#26631;&#35760;&#30340;&#39640;&#25104;&#26412;&#65292;&#39046;&#22495;&#29305;&#23450;&#25991;&#26412;&#20998;&#31867;&#38754;&#20020;&#31232;&#32570;&#30340;&#26631;&#35760;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;&#25552;&#31034;&#23398;&#20064;&#20316;&#20026;&#20256;&#32479;&#24494;&#35843;&#26041;&#27861;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#22312;&#23569;&#26679;&#26412;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#39640;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#24341;&#36215;&#20102;&#20851;&#27880;&#65292;&#20294;&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;SLMs&#65292;&#23567;&#20110;10&#20159;&#20010;&#21442;&#25968;&#65289;&#22312;&#39046;&#22495;&#29305;&#23450;&#20219;&#21153;&#20013;&#20855;&#26377;&#26174;&#33879;&#30340;&#23450;&#21046;&#24615;&#12289;&#36866;&#24212;&#24615;&#21644;&#25104;&#26412;&#25928;&#30410;&#65292;&#31526;&#21512;&#24037;&#19994;&#32422;&#26463;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;SLMs&#19982;&#25552;&#31034;&#23398;&#20064;&#33539;&#24335;&#32467;&#21512;&#24212;&#29992;&#20110;&#39046;&#22495;&#29305;&#23450;&#25991;&#26412;&#20998;&#31867;&#30340;&#28508;&#21147;&#65292;&#23588;&#20854;&#26159;&#22312;&#38646;&#21806;&#19994;&#30340;&#23458;&#25143;&#21644;&#20195;&#29702;&#20154;&#20132;&#20114;&#20013;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#23569;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#21487;&#20197;&#36827;&#34892;&#22522;&#20110;&#25552;&#31034;&#30340;&#27169;&#22411;&#24494;&#35843;&#26102;&#65292;&#20855;&#26377;220M&#21442;&#25968;&#30340;&#20856;&#22411;SLM T5-base&#33021;&#22815;&#22312;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#19978;&#23454;&#29616;&#32422;75%&#30340;&#20934;&#30830;&#29575;&#65288;&#36798;&#21040;&#23436;&#25972;&#25968;&#25454;&#30340;15%&#65289;&#65292;&#26174;&#31034;&#20986;SLMs&#19982;&#25552;&#31034;&#23398;&#20064;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain-specific text classification faces the challenge of scarce labeled data due to the high cost of manual labeling. Prompt-learning, known for its efficiency in few-shot scenarios, is proposed as an alternative to traditional fine-tuning methods. And besides, although large language models (LLMs) have gained prominence, small language models (SLMs, with under 1B parameters) offer significant customizability, adaptability, and cost-effectiveness for domain-specific tasks, given industry constraints. In this study, we investigate the potential of SLMs combined with prompt-learning paradigm for domain-specific text classification, specifically within customer-agent interactions in retail. Our evaluations show that, in few-shot settings when prompt-based model fine-tuning is possible, T5-base, a typical SLM with 220M parameters, achieve approximately 75% accuracy with limited labeled data (up to 15% of full data), which shows great potentials of SLMs with prompt-learning. Based on this
&lt;/p&gt;</description></item></channel></rss>