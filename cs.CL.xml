<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#21644;&#28436;&#31034;&#23398;&#20064; DFA&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#20855;&#22791;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07051</link><description>&lt;p&gt;
$L^*LM$: &#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23450;&#20041;&#31034;&#20363;&#23398;&#20064;&#33258;&#21160;&#26426;
&lt;/p&gt;
&lt;p&gt;
$L^*LM$: Learning Automata from Examples using Natural Language Oracles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07051
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#21644;&#28436;&#31034;&#23398;&#20064; DFA&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#20855;&#22791;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#23478;&#28436;&#31034;&#24050;&#34987;&#35777;&#26126;&#26159;&#31616;&#21270;&#38388;&#25509;&#25351;&#23450;&#22797;&#26434;&#20219;&#21153;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#31639;&#27861;&#29978;&#33267;&#25903;&#25345;&#20174;&#28436;&#31034;&#20013;&#25552;&#21462;&#26126;&#30830;&#30340;&#24418;&#24335;&#35268;&#33539;&#65292;&#22914;&#30830;&#23450;&#24615;&#26377;&#38480;&#33258;&#21160;&#26426;&#65288;DFA&#65289;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#25216;&#26415;&#36890;&#24120;&#19981;&#20855;&#22791;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#28436;&#31034;&#21644;&#33258;&#28982;&#35821;&#35328;&#20013;&#23398;&#20064; DFA&#12290;&#30001;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20174;&#19987;&#23478;&#28436;&#31034;&#20013;&#23398;&#20064; DFA &#30340;&#25968;&#25454;&#25928;&#29575;&#26174;&#33879;&#25552;&#39640;&#12290;&#20174;&#25216;&#26415;&#19978;&#35762;&#65292;$L^*LM$ &#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#22238;&#31572;&#20851;&#20110;&#24213;&#23618;&#20219;&#21153;&#30340;&#25104;&#21592;&#26597;&#35810;&#12290;&#28982;&#21518;&#23558;&#20854;&#19982;&#26368;&#36817;&#30340;&#28436;&#31034;&#23398;&#20064;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23558;&#23398;&#20064;&#36716;&#21270;&#20026;&#19968;&#31995;&#21015;&#24102;&#26631;&#31614;&#31034;&#20363;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#20004;&#31181;&#27169;&#24577;&#30456;&#20114;&#34917;&#20805;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Expert demonstrations have proven an easy way to indirectly specify complex tasks. Recent algorithms even support extracting unambiguous formal specifications, e.g. deterministic finite automata (DFA), from demonstrations. Unfortunately, these techniques are generally not sample efficient. In this work, we introduce $L^*LM$, an algorithm for learning DFAs from both demonstrations and natural language. Due to the expressivity of natural language, we observe a significant improvement in the data efficiency of learning DFAs from expert demonstrations. Technically, $L^*LM$ leverages large language models to answer membership queries about the underlying task. This is then combined with recent techniques for transforming learning from demonstrations into a sequence of labeled example learning problems. In our experiments, we observe the two modalities complement each other, yielding a powerful few-shot learner.
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#23545;LLM&#25351;&#23548;&#35843;&#20248;&#30340;&#25968;&#25454;&#36873;&#25321;&#36827;&#34892;&#20102;&#20840;&#38754;&#35843;&#26597;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25968;&#25454;&#38598;&#30340;&#36136;&#37327;&#22312;&#25351;&#23548;&#35843;&#20248;&#36807;&#31243;&#20013;&#27604;&#25968;&#37327;&#26356;&#20026;&#37325;&#35201;&#65292;&#22240;&#27492;&#35768;&#22810;&#30740;&#31350;&#33268;&#21147;&#20110;&#25506;&#32034;&#20174;&#25351;&#23548;&#25968;&#25454;&#38598;&#20013;&#36873;&#25321;&#39640;&#36136;&#37327;&#23376;&#38598;&#30340;&#26041;&#27861;&#12290;&#35838;&#39064;&#21576;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#20307;&#31995;&#12289;&#20171;&#32461;&#20102;&#26368;&#36817;&#30340;&#30740;&#31350;&#36827;&#23637;&#24182;&#35814;&#32454;&#35780;&#20272;&#20102;&#36825;&#20123;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.05123</link><description>&lt;p&gt;
LLM&#25351;&#23548;&#35843;&#20248;&#30340;&#25968;&#25454;&#36873;&#25321;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Data Selection for LLM Instruction Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#23545;LLM&#25351;&#23548;&#35843;&#20248;&#30340;&#25968;&#25454;&#36873;&#25321;&#36827;&#34892;&#20102;&#20840;&#38754;&#35843;&#26597;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25968;&#25454;&#38598;&#30340;&#36136;&#37327;&#22312;&#25351;&#23548;&#35843;&#20248;&#36807;&#31243;&#20013;&#27604;&#25968;&#37327;&#26356;&#20026;&#37325;&#35201;&#65292;&#22240;&#27492;&#35768;&#22810;&#30740;&#31350;&#33268;&#21147;&#20110;&#25506;&#32034;&#20174;&#25351;&#23548;&#25968;&#25454;&#38598;&#20013;&#36873;&#25321;&#39640;&#36136;&#37327;&#23376;&#38598;&#30340;&#26041;&#27861;&#12290;&#35838;&#39064;&#21576;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#20307;&#31995;&#12289;&#20171;&#32461;&#20102;&#26368;&#36817;&#30340;&#30740;&#31350;&#36827;&#23637;&#24182;&#35814;&#32454;&#35780;&#20272;&#20102;&#36825;&#20123;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#23548;&#35843;&#20248;&#26159;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#22914;&#20309;&#25552;&#39640;&#25351;&#23548;&#35843;&#20248;&#30340;&#25928;&#26524;&#24050;&#32463;&#24341;&#36215;&#20102;&#22686;&#21152;&#30340;&#20851;&#27880;&#12290;&#29616;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;LLM&#30340;&#25351;&#23548;&#35843;&#20248;&#36807;&#31243;&#20013;&#65292;&#25968;&#25454;&#38598;&#30340;&#36136;&#37327;&#27604;&#25968;&#37327;&#26356;&#20026;&#37325;&#35201;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#35768;&#22810;&#30740;&#31350;&#33268;&#21147;&#20110;&#25506;&#32034;&#20174;&#25351;&#23548;&#25968;&#25454;&#38598;&#20013;&#36873;&#25321;&#39640;&#36136;&#37327;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#24182;&#25913;&#21892;LLM&#30340;&#25351;&#23548;&#33021;&#21147;&#12290;&#26412;&#25991;&#23545;LLM&#25351;&#23548;&#35843;&#20248;&#30340;&#25968;&#25454;&#36873;&#25321;&#36827;&#34892;&#20102;&#32508;&#36848;&#12290;&#39318;&#20808;&#65292;&#20171;&#32461;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;&#25351;&#23548;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#35814;&#32454;&#20171;&#32461;&#20102;&#26368;&#36817;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#36824;&#35814;&#32454;&#38416;&#36848;&#20102;&#25968;&#25454;&#36873;&#25321;&#26041;&#27861;&#30340;&#35780;&#20272;&#31574;&#30053;&#21644;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#24378;&#35843;&#20102;&#35813;&#20219;&#21153;&#30340;&#24320;&#25918;&#25361;&#25112;&#21644;&#26032;&#30340;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Instruction tuning is a vital step of training large language models (LLM), so how to enhance the effect of instruction tuning has received increased attention. Existing works indicate that the quality of the dataset is more crucial than the quantity during instruction tuning of LLM. Therefore, recently a lot of studies focus on exploring the methods of selecting high-quality subset from instruction datasets, aiming to reduce training costs and enhance the instruction-following capabilities of LLMs. This paper presents a comprehensive survey on data selection for LLM instruction tuning. Firstly, we introduce the wildly used instruction datasets. Then, we propose a new taxonomy of the data selection methods and provide a detailed introduction of recent advances,and the evaluation strategies and results of data selection methods are also elaborated in detail. Finally, we emphasize the open challenges and present new frontiers of this task.
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.01763</link><description>&lt;p&gt;
&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36935;&#19978;&#21521;&#37327;&#25968;&#25454;&#24211;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
When Large Language Models Meet Vector Databases: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#22312;&#20154;&#31867;&#25991;&#23383;&#22788;&#29702;&#21644;&#29983;&#25104;&#26041;&#38754;&#24320;&#21551;&#20102;&#26032;&#30340;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23427;&#20204;&#30340;&#26174;&#33879;&#22686;&#38271;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30528;&#21253;&#25324;&#24187;&#35273;&#12289;&#20559;&#35265;&#12289;&#23454;&#26102;&#30693;&#35782;&#26356;&#26032;&#20197;&#21450;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#23454;&#26045;&#21644;&#32500;&#25252;&#30340;&#39640;&#25104;&#26412;&#31561;&#37325;&#35201;&#25361;&#25112;&#12290;&#32780;&#21478;&#19968;&#31181;&#26085;&#30410;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#21521;&#37327;&#25968;&#25454;&#24211;&#21017;&#20026;&#36825;&#20123;&#25361;&#25112;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20123;&#25968;&#25454;&#24211;&#25797;&#38271;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#19988;&#23545;&#20110;&#39640;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#21644;&#35821;&#20041;&#25628;&#32034;&#31561;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25972;&#21512;&#65292;&#23427;&#20204;&#26174;&#33879;&#22686;&#24378;&#20102;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#26356;&#26377;&#25928;&#22320;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#36827;&#34892;&#20102;&#28145;&#20837;&#32780;&#29420;&#29305;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent burst in Large Language Models has opened new frontiers in human-like text processing and generation. However, alongside their remarkable growth, Large Language Models have encountered critical challenges including issues of hallucination, bias, real-time knowledge updates, and the high costs of implementation and maintenance in commercial settings. Vector Databases, another increasingly popular tool, offer potential solutions to these challenges. These databases are adept at handling high-dimensional data and are crucial for tasks such as efficient information retrieval and semantic search. By integrating with Large Language Models, they significantly enhance AI systems' ability to manage and utilize diverse data more effectively. This survey paper provides an in-depth and unique analysis of the intersection between Large Language Models and Vector Databases.
&lt;/p&gt;</description></item></channel></rss>