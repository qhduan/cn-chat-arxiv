<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36923;&#36753;&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;ChatGPT&#22312;&#22768;&#26126;&#39564;&#35777;&#20013;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#22312;&#24402;&#32435;&#25512;&#29702;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10735</link><description>&lt;p&gt;
&#22312;&#22768;&#26126;&#39564;&#35777;&#30340;&#32972;&#26223;&#19979;&#35780;&#20272;ChatGPT&#30340;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10735
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36923;&#36753;&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;ChatGPT&#22312;&#22768;&#26126;&#39564;&#35777;&#20013;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#22312;&#24402;&#32435;&#25512;&#29702;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#26377;&#20851;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#30340;&#36777;&#35770;&#27491;&#22312;&#26085;&#30410;&#28608;&#28872;&#12290;&#25105;&#20204;&#20174;&#22768;&#26126;/&#35875;&#35328;&#39564;&#35777;&#30340;&#35282;&#24230;&#26469;&#23457;&#35270;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#36923;&#36753;&#25512;&#29702;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;&#20219;&#20309;&#22768;&#26126;&#25110;&#20256;&#35328;&#19982;&#35777;&#25454;&#32467;&#21512;&#65292;&#25286;&#20998;&#25104;&#39564;&#35777;&#25152;&#38656;&#30340;&#22522;&#26412;&#25512;&#29702;&#27493;&#39588;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#25972;&#29702;&#20102;&#20004;&#20010;&#27880;&#37322;&#38598;&#21512;&#65292;&#20854;&#20013;&#21253;&#25324;&#26469;&#33258;&#32500;&#22522;&#30334;&#31185;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#28304;&#33258;Twitter&#19978;&#27969;&#20256;&#30340;&#35875;&#35328;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#20351;&#29992;&#23427;&#20204;&#26469;&#35780;&#20272;GPT-3.5-Turbo&#21644;GPT-4&#65288;&#20197;&#19979;&#31616;&#31216;&#20026;ChatGPT&#65289;&#22312;&#25105;&#20204;&#26694;&#26550;&#30340;&#32972;&#26223;&#19979;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#25552;&#20379;&#20102;&#24443;&#24213;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;ChatGPT&#22312;&#24402;&#32435;&#25512;&#29702;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#23613;&#31649;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#25163;&#21160;&#30340;&#24605;&#32500;&#38142;&#36335;&#65288;Chain of Thought&#65292;CoT&#65289;&#26469;&#32531;&#35299;&#36825;&#19968;&#38382;&#39064;&#65292;&#32780;&#38750;&#38646;&#32534;&#30721;&#65288;Zero Shot&#65292;ZS&#65289;&#21644;ZS CoT&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26377;&#21161;&#20110;&#19981;&#26029;&#22686;&#38271;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#34920;&#26126;Cha
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10735v1 Announce Type: new  Abstract: The reasoning capabilities of LLMs are currently hotly debated. We examine the issue from the perspective of claim/rumour verification. We propose the first logical reasoning framework designed to break down any claim or rumor paired with evidence into the atomic reasoning steps necessary for verification. Based on our framework, we curate two annotated collections of such claim/evidence pairs: a synthetic dataset from Wikipedia and a real-world set stemming from rumours circulating on Twitter. We use them to evaluate the reasoning capabilities of GPT-3.5-Turbo and GPT-4 (hereinafter referred to as ChatGPT) within the context of our framework, providing a thorough analysis. Our results show that ChatGPT struggles in abductive reasoning, although this can be somewhat mitigated by using manual Chain of Thought (CoT) as opposed to Zero Shot (ZS) and ZS CoT approaches. Our study contributes to the growing body of research suggesting that Cha
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;NLP&#20998;&#26512;&#20102;ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65292;&#36890;&#36807;&#26500;&#24314;&#24341;&#29992;&#32593;&#32476;&#21644;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#25991;&#29486;&#32508;&#36848;&#12290;</title><link>http://arxiv.org/abs/2308.12420</link><description>&lt;p&gt;
ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65306;&#23545;&#25991;&#29486;&#36827;&#34892;NLP&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature. (arXiv:2308.12420v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;NLP&#20998;&#26512;&#20102;ESG&#20027;&#23548;&#30340;DLT&#30740;&#31350;&#30340;&#28436;&#21270;&#65292;&#36890;&#36807;&#26500;&#24314;&#24341;&#29992;&#32593;&#32476;&#21644;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#25991;&#29486;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#36134;&#26412;&#25216;&#26415;(DLT)&#36805;&#36895;&#21457;&#23637;&#65292;&#38656;&#35201;&#20840;&#38754;&#20102;&#35299;&#20854;&#21508;&#20010;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#38024;&#23545;DLT&#30340;&#29615;&#22659;&#12289;&#21487;&#25345;&#32493;&#24615;&#21644;&#27835;&#29702;(ESG)&#32452;&#25104;&#37096;&#20998;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#36824;&#19981;&#36275;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;107&#31687;&#31181;&#23376;&#25991;&#29486;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;63,083&#20010;&#21442;&#32771;&#25991;&#29486;&#30340;&#24341;&#29992;&#32593;&#32476;&#65292;&#24182;&#23558;&#20854;&#31934;&#28860;&#20026;24,539&#31687;&#25991;&#29486;&#30340;&#35821;&#26009;&#24211;&#36827;&#34892;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#19968;&#20010;&#24050;&#24314;&#31435;&#30340;&#25216;&#26415;&#20998;&#31867;&#27861;&#20174;46&#31687;&#35770;&#25991;&#20013;&#26631;&#35760;&#20102;&#21629;&#21517;&#23454;&#20307;&#65292;&#24182;&#36890;&#36807;&#25214;&#20986;DLT&#30340;ESG&#35201;&#32032;&#26469;&#23436;&#21892;&#36825;&#20010;&#20998;&#31867;&#27861;&#12290;&#21033;&#29992;&#22522;&#20110;transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#23545;&#19968;&#20010;&#39044;&#20808;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#32454;&#21270;&#35843;&#25972;&#65292;&#29992;&#20110;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#65292;&#20351;&#29992;&#25105;&#20204;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#35843;&#25972;&#21518;&#30340;&#35821;&#35328;&#27169;&#22411;&#23545;&#35821;&#26009;&#24211;&#36827;&#34892;&#20102;&#31934;&#31616;&#65292;&#24471;&#21040;&#20102;505&#31687;&#20851;&#38190;&#35770;&#25991;&#65292;&#36890;&#36807;&#21629;&#21517;&#23454;&#20307;&#21644;&#26102;&#38388;&#22270;&#20998;&#26512;&#65292;&#20419;&#36827;&#20102;&#23545;DLT&#22312;ESG&#32972;&#26223;&#19979;&#30340;&#28436;&#21270;&#30340;&#25991;&#29486;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed Ledger Technologies (DLTs) have rapidly evolved, necessitating comprehensive insights into their diverse components. However, a systematic literature review that emphasizes the Environmental, Sustainability, and Governance (ESG) components of DLT remains lacking. To bridge this gap, we selected 107 seed papers to build a citation network of 63,083 references and refined it to a corpus of 24,539 publications for analysis. Then, we labeled the named entities in 46 papers according to twelve top-level categories derived from an established technology taxonomy and enhanced the taxonomy by pinpointing DLT's ESG elements. Leveraging transformer-based language models, we fine-tuned a pre-trained language model for a Named Entity Recognition (NER) task using our labeled dataset. We used our fine-tuned language model to distill the corpus to 505 key papers, facilitating a literature review via named entities and temporal graph analysis on DLT evolution in the context of ESG. Our con
&lt;/p&gt;</description></item><item><title>FigCaps-HF&#26159;&#19968;&#20010;&#22270;&#20687;&#29983;&#25104;&#26631;&#39064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#34701;&#20837;&#39046;&#22495;&#19987;&#23478;&#30340;&#21453;&#39304;&#24847;&#35265;&#65292;&#29983;&#25104;&#31526;&#21512;&#35835;&#32773;&#20559;&#22909;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#26631;&#39064;&#12290;&#23558;&#33258;&#21160;&#35780;&#20272;&#21644;&#24378;&#21270;&#23398;&#20064;&#19982;&#20154;&#31867;&#21453;&#39304;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#30340;&#26631;&#39064;&#19982;&#35835;&#32773;&#20559;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.10867</link><description>&lt;p&gt;
FigCaps-HF:&#19968;&#20010;&#22522;&#20110;&#20154;&#31867;&#21453;&#39304;&#30340;&#22270;&#20687;&#29983;&#25104;&#26631;&#39064;&#26694;&#26550;&#21644;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback. (arXiv:2307.10867v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10867
&lt;/p&gt;
&lt;p&gt;
FigCaps-HF&#26159;&#19968;&#20010;&#22270;&#20687;&#29983;&#25104;&#26631;&#39064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#34701;&#20837;&#39046;&#22495;&#19987;&#23478;&#30340;&#21453;&#39304;&#24847;&#35265;&#65292;&#29983;&#25104;&#31526;&#21512;&#35835;&#32773;&#20559;&#22909;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#26631;&#39064;&#12290;&#23558;&#33258;&#21160;&#35780;&#20272;&#21644;&#24378;&#21270;&#23398;&#20064;&#19982;&#20154;&#31867;&#21453;&#39304;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#30340;&#26631;&#39064;&#19982;&#35835;&#32773;&#20559;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#39064;&#23545;&#20110;&#29702;&#35299;&#31185;&#23398;&#21487;&#35270;&#21270;&#21644;&#25991;&#26723;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#31185;&#23398;&#22270;&#20687;&#29983;&#25104;&#26631;&#39064;&#26041;&#27861;&#20381;&#36182;&#20110;&#20174;&#25991;&#26723;&#20013;&#25552;&#21462;&#30340;&#22270;&#20687;-&#26631;&#39064;&#37197;&#23545;&#36827;&#34892;&#35757;&#32451;&#65292;&#20294;&#20854;&#20013;&#35768;&#22810;&#37197;&#23545;&#22312;&#24110;&#21161;&#24615;&#12289;&#35299;&#37322;&#24615;&#21644;&#35270;&#35273;&#25551;&#36848;&#24615;&#31561;&#25351;&#26631;&#19978;&#23384;&#22312;&#19981;&#36275;&#65292;&#23548;&#33268;&#29983;&#25104;&#30340;&#26631;&#39064;&#19982;&#35835;&#32773;&#20559;&#22909;&#19981;&#19968;&#33268;&#12290;&#20026;&#20102;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#26631;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;FigCaps-HF&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#30340;&#22270;&#20687;&#29983;&#25104;&#26631;&#39064;&#26694;&#26550;&#65292;&#21487;&#20197;&#34701;&#20837;&#39046;&#22495;&#19987;&#23478;&#30340;&#21453;&#39304;&#24847;&#35265;&#65292;&#20197;&#29983;&#25104;&#20248;&#21270;&#20102;&#35835;&#32773;&#20559;&#22909;&#30340;&#26631;&#39064;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#21547;1&#65289;&#19968;&#31181;&#35780;&#20272;&#22270;&#20687;-&#26631;&#39064;&#37197;&#23545;&#36136;&#37327;&#30340;&#33258;&#21160;&#26041;&#27861;&#65292;2&#65289;&#19968;&#31181;&#22522;&#20110;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#29983;&#25104;&#24335;&#22270;&#20687;&#29983;&#25104;&#26631;&#39064;&#27169;&#22411;&#20197;&#31526;&#21512;&#35835;&#32773;&#20559;&#22909;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#27169;&#22411;&#19978;&#25913;&#36827;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#31616;&#21333;&#30340;&#23398;&#20064;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Captions are crucial for understanding scientific visualizations and documents. Existing captioning methods for scientific figures rely on figure-caption pairs extracted from documents for training, many of which fall short with respect to metrics like helpfulness, explainability, and visual-descriptiveness [15] leading to generated captions being misaligned with reader preferences. To enable the generation of high-quality figure captions, we introduce FigCaps-HF a new framework for figure-caption generation that can incorporate domain expert feedback in generating captions optimized for reader preferences. Our framework comprises of 1) an automatic method for evaluating quality of figure-caption pairs, 2) a novel reinforcement learning with human feedback (RLHF) method to optimize a generative figure-to-caption model for reader preferences. We demonstrate the effectiveness of our simple learning framework by improving performance over standard fine-tuning across different types of mod
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26522;&#20030;&#30340;&#21487;&#21387;&#32553;&#24615;&#23545;&#20110;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#30340;&#30456;&#23545;Kolmogorov&#22797;&#26434;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#20219;&#20309;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#37117;&#21487;&#20197;&#36827;&#34892;&#24378;&#21387;&#32553;&#21644;&#26080;&#22686;&#30410;&#24369;&#21387;&#32553;&#12290;</title><link>http://arxiv.org/abs/2304.03030</link><description>&lt;p&gt;
&#26522;&#20030;&#21387;&#32553;&#19982;&#22686;&#30410;
&lt;/p&gt;
&lt;p&gt;
Compression of enumerations and gain. (arXiv:2304.03030v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26522;&#20030;&#30340;&#21487;&#21387;&#32553;&#24615;&#23545;&#20110;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#30340;&#30456;&#23545;Kolmogorov&#22797;&#26434;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#20219;&#20309;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#37117;&#21487;&#20197;&#36827;&#34892;&#24378;&#21387;&#32553;&#21644;&#26080;&#22686;&#30410;&#24369;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26522;&#20030;&#30340;&#21487;&#21387;&#32553;&#24615;&#65292;&#20197;&#21450;&#20854;&#22312;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#30340;&#30456;&#23545;Kolmogorov&#22797;&#26434;&#24230;&#20013;&#23494;&#24230;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#20851;&#27880;&#20102;&#24378;&#21387;&#32553;&#21644;&#24369;&#21387;&#32553;&#65292;&#20197;&#21450;&#21387;&#32553;&#26522;&#20030;&#20013;&#23884;&#20837;&#30340;&#38468;&#21152;&#20449;&#24687;&#30340;&#25968;&#37327;&#65306;&#22686;&#30410;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#37117;&#21487;&#20197;&#36827;&#34892;&#24378;&#21387;&#32553;&#21644;&#26080;&#22686;&#30410;&#24369;&#21387;&#32553;&#65292;&#24182;&#30740;&#31350;&#20102;&#20301;&#32622;&#28216;&#25103;&#20197;&#29702;&#35299;&#24378;&#26080;&#22686;&#30410;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the compressibility of enumerations, and its role in the relative Kolmogorov complexity of computably enumerable sets, with respect to density. With respect to a strong and a weak form of compression, we examine the gain: the amount of auxiliary information embedded in the compressed enumeration. Strong compression and weak gainless compression is shown for any computably enumerable set, and a positional game is studied toward understanding strong gainless compression.
&lt;/p&gt;</description></item></channel></rss>