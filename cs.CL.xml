<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#35266;&#23519;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19981;&#21516;&#23618;&#23545;&#38544;&#34255;&#29366;&#24577;&#30340;&#24433;&#21709;&#31243;&#24230;&#65292;&#25552;&#20986;&#20102;LLM-Streamline&#26041;&#27861;&#65292;&#21253;&#25324;&#23618;&#21098;&#26525;&#21644;&#23618;&#26367;&#25442;&#65292;&#29992;&#20110;&#21387;&#32553;&#27169;&#22411;&#24182;&#20445;&#25345;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.19135</link><description>&lt;p&gt;
&#36890;&#36807;&#31616;&#21270;&#19981;&#37325;&#35201;&#30340;&#23618;&#21387;&#32553;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Compressing Large Language Models by Streamlining the Unimportant Layer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19135
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35266;&#23519;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19981;&#21516;&#23618;&#23545;&#38544;&#34255;&#29366;&#24577;&#30340;&#24433;&#21709;&#31243;&#24230;&#65292;&#25552;&#20986;&#20102;LLM-Streamline&#26041;&#27861;&#65292;&#21253;&#25324;&#23618;&#21098;&#26525;&#21644;&#23618;&#26367;&#25442;&#65292;&#29992;&#20110;&#21387;&#32553;&#27169;&#22411;&#24182;&#20445;&#25345;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#21644;&#39046;&#22495;&#65292;&#20294;&#20854;&#36866;&#29992;&#24615;&#21463;&#21040;&#27169;&#22411;&#21442;&#25968;&#30340;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#20851;&#27880;&#34920;&#29616;&#20986;&#39640;&#24615;&#33021;&#30340;&#32039;&#20945;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;LLM&#30340;&#19981;&#21516;&#23618;&#23545;&#38544;&#34255;&#29366;&#24577;&#26377;&#19981;&#21516;&#31243;&#24230;&#30340;&#25200;&#21160;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35782;&#21035;&#20986;&#19981;&#37027;&#20040;&#37325;&#35201;&#30340;&#23618;&#12290;&#22522;&#20110;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LLM-Streamline&#65292;&#21253;&#25324;&#20004;&#37096;&#20998;&#65306;&#23618;&#21098;&#26525;&#65292;&#26681;&#25454;&#30446;&#26631;&#31232;&#30095;&#24230;&#31227;&#38500;&#27169;&#22411;&#20013;&#19968;&#32452;&#36830;&#32493;&#30340;&#26368;&#19981;&#37325;&#35201;&#30340;&#23618;&#65307;&#23618;&#26367;&#25442;&#65292;&#35757;&#32451;&#19968;&#20010;&#36731;&#37327;&#32423;&#27169;&#22411;&#26469;&#26367;&#25442;&#34987;&#21098;&#26525;&#30340;&#23618;&#65292;&#20174;&#32780;&#32531;&#35299;&#30001;&#21098;&#26525;&#36896;&#25104;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;(MLP)&#21644;&#19968;&#20010;transformer&#23618;&#31561;&#32467;&#26500;&#20316;&#20026;&#36731;&#37327;&#32423;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19135v1 Announce Type: cross  Abstract: Large language models (LLM) have been extensively applied in various natural language tasks and domains, but their applicability is constrained by the large number of parameters of the models. Consequently, there is an increasing emphasis on compact models that exhibit high performance. In this study, we observe that different layers in LLM have varying degrees of perturbation on the hidden states, which allows us to identify less important layers. Based on this phenomenon, we propose LLM-Streamline, which consists of two parts: layer pruning, where we remove a set of consecutive layers with the lowest importance in the model according to the target sparsity; and layer replacement, where we train a lightweight model to substitute the pruned layers, thereby mitigating the performance degradation caused by pruning. In our experiments, we utilize structures such as a multi-layer perceptron (MLP) and a transformer layer as lightweight mode
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;</title><link>https://arxiv.org/abs/2403.14734</link><description>&lt;p&gt;
&#19968;&#39033;&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#30340;&#35843;&#26597;&#65306;&#33539;&#24335;&#12289;&#36827;&#23637;&#19982;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14734
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#31070;&#32463;&#20195;&#30721;&#26234;&#33021;--&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#20248;&#21270;&#20195;&#30721;--&#22312;&#25972;&#20010;&#31038;&#20250;&#19978;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#21487;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21644;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#36825;&#19968;&#39046;&#22495;&#22312;&#36807;&#21435;&#20960;&#24180;&#24341;&#36215;&#20102;&#20004;&#20010;&#30740;&#31350;&#31038;&#21306;&#30740;&#31350;&#20154;&#21592;&#30340;&#26497;&#22823;&#20851;&#27880;&#12290;&#26412;&#35843;&#26597;&#31995;&#32479;&#22320;&#21644;&#25353;&#26102;&#38388;&#39034;&#24207;&#22238;&#39038;&#20102;&#20195;&#30721;&#26234;&#33021;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#21253;&#25324;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21450;&#20854;&#21464;&#20307;&#12289;20&#22810;&#31181;&#20219;&#21153;&#31867;&#21035;&#20197;&#21450;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#12290;&#25105;&#20204;&#36981;&#24490;&#21382;&#21490;&#36827;&#23637;&#65292;&#36319;&#36394;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#36716;&#21464;&#65288;&#20363;&#22914;&#65292;&#20174;&#20351;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#20195;&#30721;&#24314;&#27169;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65289;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#19981;&#21516;&#38454;&#27573;&#28085;&#30422;&#30340;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#35780;&#20272;&#30340;&#20027;&#35201;&#25216;&#26415;&#36716;&#21464;&#12290;&#23545;&#20110;&#24212;&#29992;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 Announce Type: cross  Abstract: Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we 
&lt;/p&gt;</description></item><item><title>&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#26469;&#22312;&#35745;&#31639;&#39044;&#31639;&#20869;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;MeRino&#27169;&#22411;&#65292;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23637;&#29616;&#20986;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#31454;&#20105;&#24615;&#33021;&#30340;&#29305;&#28857;</title><link>https://arxiv.org/abs/2403.07921</link><description>&lt;p&gt;
Merino&#65306;&#22522;&#20110;&#29109;&#39537;&#21160;&#30340;IoT&#35774;&#22791;&#19978;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Merino: Entropy-driven Design for Generative Language Models on IoT Devices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07921
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#26469;&#22312;&#35745;&#31639;&#39044;&#31639;&#20869;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;MeRino&#27169;&#22411;&#65292;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23637;&#29616;&#20986;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#31454;&#20105;&#24615;&#33021;&#30340;&#29305;&#28857;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#20154;&#24037;&#26234;&#33021;&#29616;&#20195;&#26102;&#20195;&#30340;&#38761;&#21629;&#24615;&#36827;&#27493;&#65292;&#28982;&#32780;&#65292;&#30452;&#25509;&#37096;&#32626;LLMs&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#30828;&#20214;&#19978;&#65292;&#27604;&#22914;&#29289;&#32852;&#32593;&#65288;IoT&#65289;&#35774;&#22791;&#65292;&#30001;&#20110;&#20854;&#39640;&#35745;&#31639;&#25104;&#26412;&#32780;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20449;&#24687;&#29109;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#25163;&#26426;&#21451;&#22909;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35774;&#35745;&#33539;&#24335;&#26159;&#22312;&#32473;&#23450;&#30340;&#35745;&#31639;&#39044;&#31639;&#20869;&#26368;&#22823;&#21270;transformer&#35299;&#30721;&#22120;&#30340;&#29109;&#12290;&#25972;&#20010;&#35774;&#35745;&#36807;&#31243;&#28041;&#21450;&#35299;&#20915;&#19968;&#20010;&#25968;&#23398;&#35268;&#21010;&#65288;MP&#65289;&#38382;&#39064;&#65292;&#21487;&#20197;&#22312;&#20960;&#20998;&#38047;&#20869;&#22312;CPU&#19978;&#23436;&#25104;&#65292;&#20351;&#20854;&#20960;&#20046;&#26159;&#38646;&#25104;&#26412;&#30340;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#35774;&#35745;&#30340;&#27169;&#22411;MeRino&#65292;&#22312;&#20061;&#20010;NLP&#19979;&#28216;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#23545;&#25239;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#33258;&#22238;&#24402;transformer&#27169;&#22411;&#30340;&#31454;&#20105;&#24615;&#34920;&#29616;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;MeRino&#22312;&#31227;&#21160;&#35774;&#32622;&#19979;&#33719;&#24471;&#20102;&#31867;&#20284;&#25110;&#26356;&#22909;&#30340;&#38646;&#24615;&#33021;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07921v1 Announce Type: cross  Abstract: Generative Large Language Models (LLMs) stand as a revolutionary advancement in the modern era of artificial intelligence (AI). However, directly deploying LLMs in resource-constrained hardware, such as Internet-of-Things (IoT) devices, is difficult due to their high computational cost. In this paper, we propose a novel information-entropy framework for designing mobile-friendly generative language models. Our key design paradigm is to maximize the entropy of transformer decoders within the given computational budgets. The whole design procedure involves solving a mathematical programming (MP) problem, which can be done on the CPU within minutes, making it nearly zero-cost. We evaluate our designed models, termed MeRino, across nine NLP downstream tasks, showing their competitive performance against the state-of-the-art autoregressive transformer models under the mobile setting. Notably, MeRino achieves similar or better zero performan
&lt;/p&gt;</description></item><item><title>KnowAgent&#24341;&#20837;&#20102;&#26174;&#24335;&#21160;&#20316;&#30693;&#35782;&#65292;&#36890;&#36807;&#21160;&#20316;&#30693;&#35782;&#24211;&#21644;&#30693;&#35782;&#22411;&#33258;&#23398;&#20064;&#31574;&#30053;&#26469;&#22686;&#24378;LLM&#30340;&#35268;&#21010;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#21892;&#35821;&#35328;Agent&#30340;&#35268;&#21010;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2403.03101</link><description>&lt;p&gt;
KnowAgent: &#30693;&#35782;&#22686;&#24378;&#35268;&#21010;&#29992;&#20110;&#22522;&#20110;LLM&#30340;Agent
&lt;/p&gt;
&lt;p&gt;
KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03101
&lt;/p&gt;
&lt;p&gt;
KnowAgent&#24341;&#20837;&#20102;&#26174;&#24335;&#21160;&#20316;&#30693;&#35782;&#65292;&#36890;&#36807;&#21160;&#20316;&#30693;&#35782;&#24211;&#21644;&#30693;&#35782;&#22411;&#33258;&#23398;&#20064;&#31574;&#30053;&#26469;&#22686;&#24378;LLM&#30340;&#35268;&#21010;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#21892;&#35821;&#35328;Agent&#30340;&#35268;&#21010;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#24040;&#22823;&#28508;&#21147;&#65292;&#20294;&#22312;&#22788;&#29702;&#26356;&#22797;&#26434;&#30340;&#25361;&#25112;&#26102;&#20173;&#26377;&#25152;&#19981;&#36275;&#65292;&#29305;&#21035;&#26159;&#19982;&#29615;&#22659;&#20114;&#21160;&#36890;&#36807;&#29983;&#25104;&#21487;&#25191;&#34892;&#21160;&#20316;&#26102;&#12290;&#36825;&#31181;&#19981;&#36275;&#20027;&#35201;&#26469;&#33258;&#20110;&#35821;&#35328;Agent&#20013;&#32570;&#20047;&#20869;&#32622;&#21160;&#20316;&#30693;&#35782;&#65292;&#23548;&#33268;&#22312;&#20219;&#21153;&#27714;&#35299;&#36807;&#31243;&#20013;&#26080;&#27861;&#26377;&#25928;&#24341;&#23548;&#35268;&#21010;&#36712;&#36857;&#65292;&#20174;&#32780;&#23548;&#33268;&#35268;&#21010;&#24187;&#35273;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;KnowAgent&#65292;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#25972;&#21512;&#26174;&#24335;&#21160;&#20316;&#30693;&#35782;&#26469;&#22686;&#24378;LLM&#35268;&#21010;&#33021;&#21147;&#30340;&#26032;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;KnowAgent&#37319;&#29992;&#20102;&#19968;&#20010;&#21160;&#20316;&#30693;&#35782;&#24211;&#21644;&#19968;&#20010;&#30693;&#35782;&#22411;&#33258;&#23398;&#20064;&#31574;&#30053;&#26469;&#38480;&#21046;&#35268;&#21010;&#36807;&#31243;&#20013;&#30340;&#34892;&#21160;&#36335;&#24452;&#65292;&#23454;&#29616;&#26356;&#21512;&#29702;&#30340;&#36712;&#36857;&#21512;&#25104;&#65292;&#36827;&#32780;&#25552;&#39640;&#35821;&#35328;Agent&#30340;&#35745;&#21010;&#24615;&#33021;&#12290;&#22522;&#20110;HotpotQA&#21644;ALFWorld&#30340;&#23454;&#39564;&#32467;&#26524;&#22522;&#20110;&#19981;&#21516;&#30340;&#20027;&#24178;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03101v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. This inadequacy primarily stems from the lack of built-in action knowledge in language agents, which fails to effectively guide the planning trajectories during task solving and results in planning hallucination. To address this issue, we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge. Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents. Experimental results on HotpotQA and ALFWorld based on various backbone m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#35270;&#35282;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#25552;&#31034;&#20248;&#21270;&#22120;&#26469;&#25913;&#36827;&#20219;&#21153;&#25552;&#31034;&#65292;&#36890;&#36807;&#31867;&#27604;&#22522;&#20110;&#26799;&#24230;&#30340;&#27169;&#22411;&#20248;&#21270;&#22120;&#65292;&#35774;&#35745;&#20102;&#25913;&#36827;&#30340;LLM-based&#25552;&#31034;&#20248;&#21270;&#22120;&#31574;&#30053;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;&#22522;&#20110;&#26799;&#24230;&#21551;&#21457;&#30340;LLM-based&#25552;&#31034;&#20248;&#21270;&#22120;GPO&#12290;</title><link>https://arxiv.org/abs/2402.17564</link><description>&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#37322;&#25918;&#20026;&#25552;&#31034;&#20248;&#21270;&#22120;&#30340;&#28508;&#21147;&#65306;&#19982;&#22522;&#20110;&#26799;&#24230;&#30340;&#27169;&#22411;&#20248;&#21270;&#22120;&#30340;&#31867;&#27604;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Unleashing the Potential of Large Language Models as Prompt Optimizers: An Analogical Analysis with Gradient-based Model Optimizers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#35270;&#35282;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#25552;&#31034;&#20248;&#21270;&#22120;&#26469;&#25913;&#36827;&#20219;&#21153;&#25552;&#31034;&#65292;&#36890;&#36807;&#31867;&#27604;&#22522;&#20110;&#26799;&#24230;&#30340;&#27169;&#22411;&#20248;&#21270;&#22120;&#65292;&#35774;&#35745;&#20102;&#25913;&#36827;&#30340;LLM-based&#25552;&#31034;&#20248;&#21270;&#22120;&#31574;&#30053;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;&#22522;&#20110;&#26799;&#24230;&#21551;&#21457;&#30340;LLM-based&#25552;&#31034;&#20248;&#21270;&#22120;GPO&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#25552;&#31034;&#20248;&#21270;&#26159;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24615;&#33021;&#30340;&#37325;&#35201;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;LLMs&#20316;&#20026;&#25552;&#31034;&#20248;&#21270;&#22120;&#20855;&#26377;&#28508;&#21147;&#65292;&#21487;&#20197;&#36890;&#36807;&#36845;&#20195;&#25913;&#36827;&#29983;&#25104;&#25913;&#36827;&#30340;&#20219;&#21153;&#25552;&#31034;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#35270;&#35282;&#65292;&#36890;&#36807;&#19982;&#22522;&#20110;&#26799;&#24230;&#30340;&#27169;&#22411;&#20248;&#21270;&#22120;&#36827;&#34892;&#31867;&#27604;&#26469;&#30740;&#31350;&#22522;&#20110;LLM&#30340;&#25552;&#31034;&#20248;&#21270;&#22120;&#30340;&#35774;&#35745;&#12290;&#20026;&#20102;&#36830;&#25509;&#36825;&#20004;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#30830;&#23450;&#27169;&#22411;&#21442;&#25968;&#23398;&#20064;&#20013;&#30340;&#20004;&#20010;&#20851;&#38190;&#22240;&#32032;&#65306;&#26356;&#26032;&#26041;&#21521;&#21644;&#26356;&#26032;&#26041;&#27861;&#12290;&#19987;&#27880;&#20110;&#36825;&#20004;&#20010;&#26041;&#38754;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#26799;&#24230;&#20248;&#21270;&#30340;&#29702;&#35770;&#26694;&#26550;&#21644;&#23398;&#20064;&#26041;&#27861;&#65292;&#35774;&#35745;&#20102;&#25913;&#36827;&#30340;LLM-based&#25552;&#31034;&#20248;&#21270;&#22120;&#31574;&#30053;&#12290;&#36890;&#36807;&#31995;&#32479;&#20998;&#26512;&#20016;&#23500;&#30340;&#25913;&#36827;&#31574;&#30053;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#20010;&#33021;&#21147;&#24378;&#22823;&#30340;&#22522;&#20110;&#26799;&#24230;&#21551;&#21457;&#30340;LLM-based&#25552;&#31034;&#20248;&#21270;&#22120;&#65292;&#31216;&#20026;GPO&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17564v1 Announce Type: new  Abstract: Automatic prompt optimization is an important approach to improving the performance of large language models (LLMs). Recent research demonstrates the potential of using LLMs as prompt optimizers, which can generate improved task prompts via iterative refinement. In this paper, we propose a novel perspective to investigate the design of LLM-based prompt optimizers, by drawing an analogy with gradient-based model optimizers. To connect these two approaches, we identify two pivotal factors in model parameter learning: update direction and update method. Focused on the two aspects, we borrow the theoretical framework and learning methods from gradient-based optimization to design improved strategies for LLM-based prompt optimizers. By systematically analyzing a rich set of improvement strategies, we further develop a capable Gradient-inspired LLM-based Prompt Optimizer called GPO. At each step, it first retrieves relevant prompts from the op
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#38754;&#21521;&#32452;&#21512;&#26410;&#30693;&#38382;&#39064;&#30340;&#33258;&#25105;&#20998;&#32780;&#27835;&#20043;&#31639;&#27861;&#65292;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#32452;&#21512;&#26410;&#30693;&#38382;&#39064;&#38382;&#31572;&#25968;&#25454;&#38598;&#65288;CuQA&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#35843;&#29992;&#19981;&#21516;&#26041;&#27861;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.13514</link><description>&lt;p&gt;
&#33258;&#25105;&#20998;&#32780;&#27835;&#20043;&#65306;&#20309;&#26102;&#26816;&#32034;&#12289;&#20309;&#26102;&#29983;&#25104;&#65311;&#38754;&#21521;&#32452;&#21512;&#26410;&#30693;&#38382;&#39064;&#30340;&#33258;&#25105;&#20998;&#32780;&#27835;&#20043;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Self-DC: When to retrieve and When to generate? Self Divide-and-Conquer for Compositional Unknown Questions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13514
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#38754;&#21521;&#32452;&#21512;&#26410;&#30693;&#38382;&#39064;&#30340;&#33258;&#25105;&#20998;&#32780;&#27835;&#20043;&#31639;&#27861;&#65292;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#32452;&#21512;&#26410;&#30693;&#38382;&#39064;&#38382;&#31572;&#25968;&#25454;&#38598;&#65288;CuQA&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#35843;&#29992;&#19981;&#21516;&#26041;&#27861;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;-&#28982;&#21518;&#38405;&#35835;&#21644;&#29983;&#25104;-&#28982;&#21518;&#38405;&#35835;&#26159;&#22788;&#29702;&#24320;&#25918;&#22495;&#38382;&#31572;&#20013;&#26410;&#30693;&#21644;&#24050;&#30693;&#38382;&#39064;&#30340;&#20004;&#31181;&#20856;&#22411;&#35299;&#20915;&#26041;&#26696;&#65292;&#21069;&#32773;&#26816;&#32034;&#24517;&#35201;&#30340;&#22806;&#37096;&#30693;&#35782;&#65292;&#21518;&#32773;&#21017;&#20419;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#21442;&#25968;&#20013;&#32534;&#30721;&#30340;&#20869;&#37096;&#24050;&#30693;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#36807;&#21435;&#24456;&#23569;&#26377;&#20316;&#21697;&#32771;&#34385;&#21040;&#32452;&#21512;&#26410;&#30693;&#38382;&#39064;&#65292;&#36825;&#20123;&#38382;&#39064;&#30001;&#20960;&#20010;&#24050;&#30693;&#25110;&#26410;&#30693;&#30340;&#23376;&#38382;&#39064;&#32452;&#25104;&#12290;&#22240;&#27492;&#65292;&#31616;&#21333;&#30340;&#20108;&#20803;&#20998;&#31867;&#65288;&#24050;&#30693;&#25110;&#26410;&#30693;&#65289;&#21464;&#24471;&#27425;&#20248;&#21644;&#20302;&#25928;&#65292;&#22240;&#20026;&#23427;&#20250;&#23545;&#27599;&#20010;&#32452;&#21512;&#26410;&#30693;&#38382;&#39064;&#36807;&#24230;&#35843;&#29992;&#22806;&#37096;&#26816;&#32034;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#32452;&#21512;&#26410;&#30693;&#38382;&#39064;&#38382;&#31572;&#25968;&#25454;&#38598;&#65288;CuQA&#65289;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#33258;&#25105;&#20998;&#32780;&#27835;&#20043;&#65288;Self-DC&#65289;&#26694;&#26550;&#65292;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#35843;&#29992;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#25552;&#39640;&#24615;&#33021;&#21644;&#25928;&#29575;&#12290;&#23454;&#39564;&#32467;&#26524;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#65288;CuQA&#21644;FreshQA&#65289;&#19978;&#34920;&#26126;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13514v1 Announce Type: cross  Abstract: Retrieve-then-read and generate-then-read are two typical solutions to handle unknown and known questions in open-domain question-answering, while the former retrieves necessary external knowledge and the later prompt the large language models to generate internal known knowledge encoded in the parameters. However, few of previous works consider the compositional unknown questions, which consist of several known or unknown sub-questions. Thus, simple binary classification (known or unknown) becomes sub-optimal and inefficient since it will call external retrieval excessively for each compositional unknown question. To this end, we propose the first Compositional unknown Question-Answering dataset (CuQA), and introduce a Self Divide-and-Conquer (Self-DC) framework to empower LLMs to adaptively call different methods on-demand, resulting in better performance and efficiency. Experimental results on two datasets (CuQA and FreshQA) demonst
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#36890;&#29992;logit&#33976;&#39311; (ULD) &#25439;&#22833;&#65292;&#29992;&#20110;&#35299;&#20915;&#19981;&#21516;&#26550;&#26500;&#21644;&#20998;&#35789;&#22120;&#27169;&#22411;&#20043;&#38388;&#33976;&#39311;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.12030</link><description>&lt;p&gt;
&#36328;&#20998;&#35789;&#22120;&#33976;&#39311;&#65306;&#29992;&#20110;LLM&#30340;&#36890;&#29992;logit&#33976;&#39311;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Towards Cross-Tokenizer Distillation: the Universal Logit Distillation Loss for LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12030
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#36890;&#29992;logit&#33976;&#39311; (ULD) &#25439;&#22833;&#65292;&#29992;&#20110;&#35299;&#20915;&#19981;&#21516;&#26550;&#26500;&#21644;&#20998;&#35789;&#22120;&#27169;&#22411;&#20043;&#38388;&#33976;&#39311;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37096;&#32626;&#20960;&#21313;&#20159;&#21442;&#25968;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLMs) &#22312;&#22823;&#22810;&#25968;&#24037;&#19994;&#24212;&#29992;&#20013;&#21487;&#33021;&#24182;&#19981;&#20999;&#23454;&#38469;&#65292;&#21407;&#22240;&#26159;&#35832;&#22914;&#25104;&#26412;&#12289;&#24310;&#36831;&#38480;&#21046;&#21644;&#30828;&#20214;&#21487;&#35775;&#38382;&#24615;&#31561;&#32422;&#26463;&#12290;&#30693;&#35782;&#33976;&#39311; (KD) &#36890;&#36807;&#23558;&#36164;&#28304;&#23494;&#38598;&#22411;&#22823;&#27169;&#22411;&#30340;&#30693;&#35782;&#21387;&#32553;&#21040;&#36739;&#23567;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#12290;&#23384;&#22312;&#22810;&#31181;&#31574;&#30053;&#65292;&#19968;&#20123;&#20381;&#36182;&#20110;&#25945;&#24072;&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26412;&#65292;&#24182;&#21487;&#36873;&#25321;&#24615;&#22320;&#21033;&#29992;&#20854;logits&#26469;&#22686;&#24378;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;logits&#30340;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#35201;&#27714;&#25945;&#24072;&#21644;&#23398;&#29983;&#27169;&#22411;&#20849;&#20139;&#30456;&#21516;&#30340;&#20998;&#35789;&#22120;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#19981;&#21516;LLM&#31995;&#21015;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#36890;&#29992;logit&#33976;&#39311; (ULD) &#25439;&#22833;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;ULD&#25439;&#22833;&#22312;&#21551;&#29992;&#19981;&#21516;&#26550;&#26500;&#21644;&#20998;&#35789;&#22120;&#30340;&#27169;&#22411;&#20043;&#38388;&#30340;&#33976;&#39311;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#20026;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12030v1 Announce Type: new  Abstract: Deploying large language models (LLMs) of several billion parameters can be impractical in most industrial use cases due to constraints such as cost, latency limitations, and hardware accessibility. Knowledge distillation (KD) offers a solution by compressing knowledge from resource-intensive large models to smaller ones. Various strategies exist, some relying on the text generated by the teacher model and optionally utilizing his logits to enhance learning. However, these methods based on logits often require both teacher and student models to share the same tokenizer, limiting their applicability across different LLM families. In this paper, we introduce Universal Logit Distillation (ULD) loss, grounded in optimal transport, to address this limitation. Our experimental results demonstrate the effectiveness of ULD loss in enabling distillation across models with different architectures and tokenizers, paving the way to a more widespread
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#22411;&#38388;&#25509;&#25512;&#29702;&#26041;&#27861;&#65292;&#20351;&#29992;&#21453;&#35777;&#21644;&#30683;&#30462;&#30340;&#36923;&#36753;&#26469;&#22788;&#29702;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#22686;&#24378;&#25968;&#25454;&#21644;&#35268;&#21017;&#65292;&#20197;&#21450;&#35774;&#35745;&#25552;&#31034;&#27169;&#26495;&#30340;&#26041;&#24335;&#22686;&#24378;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.03667</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#38388;&#25509;&#25512;&#29702;&#22120;&#65306;&#23545;&#33258;&#21160;&#25512;&#29702;&#30340;&#21453;&#35777;&#21644;&#30683;&#30462;
&lt;/p&gt;
&lt;p&gt;
Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03667
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#22411;&#38388;&#25509;&#25512;&#29702;&#26041;&#27861;&#65292;&#20351;&#29992;&#21453;&#35777;&#21644;&#30683;&#30462;&#30340;&#36923;&#36753;&#26469;&#22788;&#29702;&#22797;&#26434;&#25512;&#29702;&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#22686;&#24378;&#25968;&#25454;&#21644;&#35268;&#21017;&#65292;&#20197;&#21450;&#35774;&#35745;&#25552;&#31034;&#27169;&#26495;&#30340;&#26041;&#24335;&#22686;&#24378;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#22797;&#26434;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20197;&#21069;&#30340;&#26041;&#27861;&#20027;&#35201;&#26159;&#36981;&#24490;&#30452;&#25509;&#25512;&#29702;&#65288;DR&#65289;&#26694;&#26550;&#65292;&#22914;&#8220;&#24605;&#32500;&#38142;&#8221;&#21644;&#8220;&#33258;&#19968;&#33268;&#24615;&#8221;&#65292;&#22240;&#27492;&#22312;&#35299;&#20915;&#24456;&#38590;&#36890;&#36807;DR&#35299;&#20915;&#30340;&#20247;&#22810;&#23454;&#38469;&#38382;&#39064;&#26102;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#22686;&#24378;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38388;&#25509;&#25512;&#29702;&#65288;IR&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21453;&#35777;&#21644;&#30683;&#30462;&#30340;&#36923;&#36753;&#26469;&#22788;&#29702;&#20107;&#23454;&#25512;&#29702;&#21644;&#25968;&#23398;&#35777;&#26126;&#31561;IR&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;&#21453;&#35777;&#30340;&#36923;&#36753;&#31561;&#20215;&#24615;&#26469;&#22686;&#24378;LLMs&#30340;&#25968;&#25454;&#21644;&#35268;&#21017;&#65292;&#20197;&#25552;&#39640;&#20854;&#21487;&#29702;&#35299;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#32452;&#25552;&#31034;&#27169;&#26495;&#65292;&#35302;&#21457;LLMs&#36827;&#34892;&#22522;&#20110;&#30683;&#30462;&#35777;&#26126;&#30340;IR&#65292;&#20854;&#36923;&#36753;&#19978;&#31561;&#20215;&#20110;&#21407;&#22987;&#30340;DR&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;IR&#26041;&#27861;&#31616;&#21333;&#32780;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, increasing attention has been focused drawn on to improve the ability of Large Language Models (LLMs) to perform complex reasoning. However, previous methods, such as Chain-of-Thought and Self-Consistency, mainly follow Direct Reasoning (DR) frameworks, so they will meet difficulty in solving numerous real-world tasks which can hardly be solved via DR. Therefore, to strengthen the reasoning power of LLMs, this paper proposes a novel Indirect Reasoning (IR) method that employs the logic of contrapositives and contradictions to tackle IR tasks such as factual reasoning and mathematic proof. Specifically, our methodology comprises two steps. Firstly, we leverage the logical equivalence of contrapositive to augment the data and rules to enhance the comprehensibility of LLMs. Secondly, we design a set of prompt templates to trigger LLMs to conduct IR based on proof by contradiction that is logically equivalent to the original DR process. Our IR method is simple yet effective and c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#25968;&#25454;&#29983;&#25104;&#30340;&#35282;&#24230;&#37325;&#26032;&#35299;&#37322;&#20102;In-Context Learning&#65288;ICL&#65289;&#30340;&#26426;&#21046;&#65292;&#24182;&#25506;&#35752;&#20102;&#27969;&#34892;&#30340;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;&#23545;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#30340;&#20248;&#21155;&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#65292;&#24378;&#35843;&#20102;&#20854;&#20013;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;</title><link>https://arxiv.org/abs/2402.02212</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#29983;&#25104;&#30340;&#35282;&#24230;&#23545;In-Context Learning&#26426;&#21046;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
A Data Generation Perspective to the Mechanism of In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02212
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#25968;&#25454;&#29983;&#25104;&#30340;&#35282;&#24230;&#37325;&#26032;&#35299;&#37322;&#20102;In-Context Learning&#65288;ICL&#65289;&#30340;&#26426;&#21046;&#65292;&#24182;&#25506;&#35752;&#20102;&#27969;&#34892;&#30340;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;&#23545;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#30340;&#20248;&#21155;&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#65292;&#24378;&#35843;&#20102;&#20854;&#20013;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
In-Context Learning&#65288;ICL&#65289;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#33021;&#22815;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#65292;&#22312;&#21482;&#26377;&#23569;&#37327;&#19978;&#19979;&#25991;&#31034;&#20363;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#19979;&#28216;&#27867;&#21270;&#65292;&#32780;&#26080;&#38656;&#26799;&#24230;&#26356;&#26032;&#12290;&#23613;&#31649;&#26377;&#40723;&#33310;&#20154;&#24515;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;ICL&#30340;&#22522;&#26412;&#26426;&#21046;&#20173;&#28982;&#19981;&#28165;&#26970;&#65292;&#29616;&#26377;&#30740;&#31350;&#25552;&#20379;&#20102;&#21508;&#31181;&#19981;&#21516;&#35266;&#28857;&#30340;&#29702;&#35299;&#12290;&#36825;&#20123;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#30452;&#35273;&#21644;&#20020;&#26102;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#26469;&#35299;&#37322;ICL&#65292;&#21576;&#29616;&#20986;&#20102;&#19968;&#26465;&#27169;&#31946;&#30340;&#36335;&#32447;&#22270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#25968;&#25454;&#29983;&#25104;&#30340;&#35270;&#35282;&#37325;&#26032;&#35299;&#37322;&#26368;&#36817;&#30340;&#30740;&#31350;&#25104;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#27969;&#34892;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#22312;&#24191;&#27867;&#24212;&#29992;&#65292;&#20174;&#32780;&#25509;&#36817;&#19968;&#20010;&#31995;&#32479;&#30340;&#35282;&#24230;&#12290;&#25105;&#20204;&#20005;&#26684;&#37319;&#29992;&#25216;&#33021;&#23398;&#20064;&#21644;&#25216;&#33021;&#35782;&#21035;&#30340;&#27010;&#24565;&#23450;&#20041;&#12290;&#23427;&#20204;&#20043;&#38388;&#30340;&#21306;&#21035;&#22312;&#20110;&#25216;&#33021;&#23398;&#20064;&#21487;&#20197;&#20174;&#19978;&#19979;&#25991;&#25968;&#25454;&#20013;&#23398;&#20064;&#26032;&#30340;&#25968;&#25454;&#29983;&#25104;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#23545;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#30340;&#20248;&#21183;&#21644;&#24369;&#28857;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#24182;&#24378;&#35843;&#20102;&#20854;&#20013;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
In-Context Learning (ICL) empowers Large Language Models (LLMs) with the capacity to learn in context, achieving downstream generalization without gradient updates but with a few in-context examples. Despite the encouraging empirical success, the underlying mechanism of ICL remains unclear, and existing research offers various viewpoints of understanding. These studies propose intuition-driven and ad-hoc technical solutions for interpreting ICL, illustrating an ambiguous road map. In this paper, we leverage a data generation perspective to reinterpret recent efforts and demonstrate the potential broader usage of popular technical solutions, approaching a systematic angle. For a conceptual definition, we rigorously adopt the terms of skill learning and skill recognition. The difference between them is skill learning can learn new data generation functions from in-context data. We also provide a comprehensive study on the merits and weaknesses of different solutions, and highlight the un
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LiPO&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#38382;&#39064;&#23450;&#20041;&#20026;&#19968;&#20010;&#21015;&#34920;&#22411;&#25490;&#24207;&#38382;&#39064;&#12290;&#36890;&#36807;&#20174;&#25490;&#21517;&#21015;&#34920;&#20013;&#23398;&#20064;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20351;&#31574;&#30053;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#21040;&#21487;&#34892;&#30340;&#21709;&#24212;&#12290;</title><link>https://arxiv.org/abs/2402.01878</link><description>&lt;p&gt;
LiPO: &#36890;&#36807;&#23398;&#20064;&#25490;&#24207;&#36827;&#34892;&#21015;&#34920;&#22411;&#20559;&#22909;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
LiPO: Listwise Preference Optimization through Learning-to-Rank
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LiPO&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#38382;&#39064;&#23450;&#20041;&#20026;&#19968;&#20010;&#21015;&#34920;&#22411;&#25490;&#24207;&#38382;&#39064;&#12290;&#36890;&#36807;&#20174;&#25490;&#21517;&#21015;&#34920;&#20013;&#23398;&#20064;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#20351;&#31574;&#30053;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#21040;&#21487;&#34892;&#30340;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#35821;&#35328;&#27169;&#22411;&#19982;&#20154;&#24037;&#21453;&#39304;&#36827;&#34892;&#23545;&#40784;&#26159;&#25511;&#21046;&#20854;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#34892;&#20026;&#30340;&#20851;&#38190;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#22914;DPO&#21644;SLiC&#65292;&#25104;&#20026;&#20256;&#32479;&#30340;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;&#22686;&#24378;&#23398;&#20064;&#26041;&#27861;&#30340;&#26377;&#24076;&#26395;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#23454;&#38469;&#19978;&#65292;&#20154;&#24037;&#21453;&#39304;&#36890;&#24120;&#20197;&#23545;&#22810;&#20010;&#21709;&#24212;&#36827;&#34892;&#25490;&#24207;&#30340;&#26684;&#24335;&#25552;&#20379;&#65292;&#20197;&#25674;&#38144;&#38405;&#35835;&#25552;&#31034;&#30340;&#25104;&#26412;&#12290;&#22810;&#20010;&#21709;&#24212;&#20063;&#21487;&#20197;&#36890;&#36807;&#22870;&#21169;&#27169;&#22411;&#25110;AI&#21453;&#39304;&#36827;&#34892;&#25490;&#24207;&#12290;&#32570;&#23569;&#20851;&#20110;&#30452;&#25509;&#36866;&#24212;&#21709;&#24212;&#21015;&#34920;&#30340;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#38382;&#39064;&#23450;&#20041;&#20026;&#19968;&#20010;&#21015;&#34920;&#22411;&#25490;&#24207;&#38382;&#39064;&#65292;&#24182;&#25551;&#36848;&#20102;&#21015;&#34920;&#22411;&#20559;&#22909;&#20248;&#21270;&#65288;LiPO&#65289;&#26694;&#26550;&#65292;&#22312;&#32473;&#23450;&#25552;&#31034;&#30340;&#24773;&#20917;&#19979;&#65292;&#31574;&#30053;&#21487;&#20197;&#20174;&#19968;&#20010;&#25490;&#21517;&#21015;&#34920;&#20013;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#21487;&#34892;&#21709;&#24212;&#12290;&#36825;&#31181;&#35266;&#28857;&#19982;&#23398;&#20064;&#25490;&#24207;&#65288;LTR&#65289;&#24418;&#25104;&#26126;&#30830;&#30340;&#32852;&#31995;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#20559;&#22909;&#20248;&#21270;&#24037;&#20316;&#21487;&#20197;&#26144;&#23556;&#21040;&#29616;&#26377;&#30340;&#25490;&#21517;&#30446;&#26631;&#65292;&#29305;&#21035;&#26159;
&lt;/p&gt;
&lt;p&gt;
Aligning language models (LMs) with curated human feedback is critical to control their behaviors in real-world applications. Several recent policy optimization methods, such as DPO and SLiC, serve as promising alternatives to the traditional Reinforcement Learning from Human Feedback (RLHF) approach. In practice, human feedback often comes in a format of a ranked list over multiple responses to amortize the cost of reading prompt. Multiple responses can also be ranked by reward models or AI feedback. There lacks such a study on directly fitting upon a list of responses. In this work, we formulate the LM alignment as a listwise ranking problem and describe the Listwise Preference Optimization (LiPO) framework, where the policy can potentially learn more effectively from a ranked list of plausible responses given the prompt. This view draws an explicit connection to Learning-to-Rank (LTR), where most existing preference optimization work can be mapped to existing ranking objectives, esp
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#38388;&#25509;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#22522;&#20934;&#27979;&#35797;BIPIA&#65292;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38754;&#23545;&#27492;&#31867;&#25915;&#20987;&#26102;&#30340;&#39118;&#38505;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#20998;&#26512;&#20102;&#25915;&#20987;&#25104;&#21151;&#30340;&#21407;&#22240;&#65292;&#20174;&#32780;&#24320;&#21457;&#20102;&#38450;&#24481;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2312.14197</link><description>&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36827;&#34892;&#38388;&#25509;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14197
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#38388;&#25509;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#22522;&#20934;&#27979;&#35797;BIPIA&#65292;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38754;&#23545;&#27492;&#31867;&#25915;&#20987;&#26102;&#30340;&#39118;&#38505;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#20998;&#26512;&#20102;&#25915;&#20987;&#25104;&#21151;&#30340;&#21407;&#22240;&#65292;&#20174;&#32780;&#24320;&#21457;&#20102;&#38450;&#24481;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#22806;&#37096;&#20869;&#23481;&#30340;&#25972;&#21512;&#24050;&#32463;&#23454;&#29616;&#20102;LLMs&#30340;&#26356;&#26032;&#21644;&#24191;&#27867;&#24212;&#29992;&#65292;&#27604;&#22914;&#24494;&#36719;Copilot&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#25972;&#21512;&#20063;&#35753;LLMs&#38754;&#20020;&#20102;&#38388;&#25509;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#39118;&#38505;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#22312;&#22806;&#37096;&#20869;&#23481;&#20013;&#23884;&#20837;&#24694;&#24847;&#25351;&#20196;&#65292;&#20174;&#32780;ompromising LLM&#36755;&#20986;&#24182;&#23548;&#33268;&#21709;&#24212;&#20559;&#31163;&#29992;&#25143;&#26399;&#26395;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#37325;&#35201;&#20294;&#26410;&#34987;&#20805;&#20998;&#25506;&#35752;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#38388;&#25509;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#22522;&#20934;&#27979;&#35797;BIPIA&#65292;&#20197;&#35780;&#20272;&#36825;&#31867;&#25915;&#20987;&#30340;&#39118;&#38505;&#12290;&#22522;&#20110;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#37325;&#28857;&#20998;&#26512;&#20102;&#35813;&#25915;&#20987;&#25104;&#21151;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#21363;LLMs&#26080;&#27861;&#21306;&#20998;&#25351;&#20196;&#21644;&#22806;&#37096;&#20869;&#23481;&#20197;&#21450;&#32570;&#20047;&#24847;&#35782;&#19981;&#25191;&#34892;&#22806;&#37096;&#20869;&#23481;&#20869;&#30340;&#25351;&#20196;&#12290;&#22522;&#20110;&#36825;&#19968;&#20998;&#26512;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#31181;&#40657;&#30418;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14197v2 Announce Type: replace-cross  Abstract: The integration of large language models (LLMs) with external content has enabled more up-to-date and wide-ranging applications of LLMs, such as Microsoft Copilot. However, this integration has also exposed LLMs to the risk of indirect prompt injection attacks, where an attacker can embed malicious instructions within external content, compromising LLM output and causing responses to deviate from user expectations. To investigate this important but underexplored issue, we introduce the first benchmark for indirect prompt injection attacks, named BIPIA, to evaluate the risk of such attacks. Based on the evaluation, our work makes a key analysis of the underlying reason for the success of the attack, namely the inability of LLMs to distinguish between instructions and external content and the absence of LLMs' awareness to not execute instructions within external content. Building upon this analysis, we develop two black-box metho
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20197;&#20302;&#35745;&#31639;&#36164;&#28304;&#28040;&#32791;&#20026;&#20013;&#24515;&#30340;&#39640;&#25928;&#30693;&#35782;&#24211;&#38382;&#31572;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#32447;&#32034;&#24341;&#23548;&#36335;&#24452;&#25506;&#32034;&#30340;&#26041;&#24335;&#65292;&#23558;&#30693;&#35782;&#24211;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39640;&#25928;&#22320;&#34701;&#21512;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#23545;&#27169;&#22411;&#33021;&#21147;&#30340;&#35201;&#27714;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.13444</link><description>&lt;p&gt;
&#20197;&#20302;&#35745;&#31639;&#36164;&#28304;&#28040;&#32791;&#20026;&#20013;&#24515;&#30340;&#39640;&#25928;&#30693;&#35782;&#24211;&#38382;&#31572;&#26694;&#26550;&#65306;&#22522;&#20110;&#32447;&#32034;&#24341;&#23548;&#36335;&#24452;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption. (arXiv:2401.13444v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13444
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20197;&#20302;&#35745;&#31639;&#36164;&#28304;&#28040;&#32791;&#20026;&#20013;&#24515;&#30340;&#39640;&#25928;&#30693;&#35782;&#24211;&#38382;&#31572;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#32447;&#32034;&#24341;&#23548;&#36335;&#24452;&#25506;&#32034;&#30340;&#26041;&#24335;&#65292;&#23558;&#30693;&#35782;&#24211;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39640;&#25928;&#22320;&#34701;&#21512;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#23545;&#27169;&#22411;&#33021;&#21147;&#30340;&#35201;&#27714;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#26356;&#26032;&#23427;&#20204;&#30340;&#30693;&#35782;&#38754;&#20250;&#24102;&#26469;&#25361;&#25112;&#65292;&#24403;&#38754;&#23545;&#19981;&#29087;&#24713;&#30340;&#26597;&#35810;&#26102;&#21487;&#33021;&#23548;&#33268;&#19981;&#20934;&#30830;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#30740;&#31350;&#20102;&#23558;&#30693;&#35782;&#22270;&#35889;&#19982;LLMs&#38598;&#25104;&#30340;&#26041;&#27861;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#23558;LLMs&#35270;&#20026;&#20027;&#35201;&#30340;&#20915;&#31574;&#32773;&#65292;&#23545;&#20854;&#33021;&#21147;&#25552;&#20986;&#20102;&#36739;&#39640;&#30340;&#35201;&#27714;&#12290;&#23545;&#20110;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#19988;&#24615;&#33021;&#30456;&#23545;&#36739;&#24046;&#30340;LLMs&#26469;&#35828;&#65292;&#36825;&#26159;&#19981;&#22826;&#21512;&#36866;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20197;&#32447;&#32034;&#24341;&#23548;&#36335;&#24452;&#25506;&#32034;&#20026;&#26680;&#24515;&#30340;&#30693;&#35782;&#24211;&#38382;&#31572;&#26694;&#26550;&#65288;CGPE&#65289;&#65292;&#23427;&#23558;&#30693;&#35782;&#24211;&#19982;LLMs&#39640;&#25928;&#22320;&#34701;&#21512;&#65292;&#23545;&#27169;&#22411;&#30340;&#33021;&#21147;&#35201;&#27714;&#36739;&#20302;&#12290;&#21463;&#20154;&#31867;&#25163;&#21160;&#26816;&#32034;&#30693;&#35782;&#30340;&#26041;&#27861;&#21551;&#21457;&#65292;CGPE&#21033;&#29992;&#38382;&#39064;&#20013;&#30340;&#20449;&#24687;&#20316;&#20026;&#32447;&#32034;&#65292;&#31995;&#32479;&#22320;&#25506;&#32034;&#30693;&#35782;&#24211;&#20013;&#25152;&#38656;&#30340;&#30693;&#35782;&#36335;&#24452;&#12290;&#24320;&#28304;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;CGPE&#20248;&#20110;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#38750;&#24120;&#36866;&#29992;&#20110;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#19988;&#24615;&#33021;&#36739;&#24046;&#30340;LLMs&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent times, large language models (LLMs) have showcased remarkable capabilities. However, updating their knowledge poses challenges, potentially leading to inaccuracies when confronted with unfamiliar queries. While integrating knowledge graphs with LLMs has been explored, existing approaches treat LLMs as primary decision-makers, imposing high demands on their capabilities. This is particularly unsuitable for LLMs with lower computational costs and relatively poorer performance. In this paper, we introduce a Clue-Guided Path Exploration framework (CGPE) that efficiently merges a knowledge base with an LLM, placing less stringent requirements on the model's capabilities. Inspired by the method humans use to manually retrieve knowledge, CGPE employs information from the question as clues to systematically explore the required knowledge path within the knowledge base. Experiments on open-source datasets reveal that CGPE outperforms previous methods and is highly applicable to LLMs w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20020;&#24202;&#25991;&#26412;&#29983;&#25104;&#30340;&#21019;&#26032;&#26041;&#27861;ClinGen&#65292;&#35813;&#26041;&#27861;&#23558;&#22806;&#37096;&#39046;&#22495;&#29305;&#23450;&#30340;&#30693;&#35782;&#21644;&#35821;&#35328;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#39640;&#20102;&#20020;&#24202;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#24182;&#20016;&#23500;&#20102;&#26679;&#26412;&#30340;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.00287</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#27880;&#20837;&#65306;&#35780;&#20272;&#21644;&#25512;&#36827;&#20020;&#24202;&#25991;&#26412;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models. (arXiv:2311.00287v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20020;&#24202;&#25991;&#26412;&#29983;&#25104;&#30340;&#21019;&#26032;&#26041;&#27861;ClinGen&#65292;&#35813;&#26041;&#27861;&#23558;&#22806;&#37096;&#39046;&#22495;&#29305;&#23450;&#30340;&#30693;&#35782;&#21644;&#35821;&#35328;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#39640;&#20102;&#20020;&#24202;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#24182;&#20016;&#23500;&#20102;&#26679;&#26412;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20020;&#24202;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#38656;&#35201;&#33021;&#22815;&#24212;&#23545;&#39046;&#22495;&#29305;&#23450;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#20363;&#22914;&#22797;&#26434;&#30340;&#21307;&#23398;&#26415;&#35821;&#21644;&#20020;&#24202;&#32972;&#26223;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#36825;&#20010;&#39046;&#22495;&#26174;&#31034;&#20986;&#20102;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#30452;&#25509;&#37096;&#32626;&#21487;&#33021;&#23548;&#33268;&#38544;&#31169;&#38382;&#39064;&#65292;&#24182;&#21463;&#21040;&#36164;&#28304;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#20102;&#20351;&#29992;LLMs&#36827;&#34892;&#20020;&#24202;NLP&#20219;&#21153;&#30340;&#21512;&#25104;&#20020;&#24202;&#25991;&#26412;&#29983;&#25104;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#12289;&#36164;&#28304;&#39640;&#25928;&#30340;&#26041;&#27861;ClinGen&#65292;&#23427;&#23558;&#30693;&#35782;&#27880;&#20837;&#21040;&#36825;&#20010;&#36807;&#31243;&#20013;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#28041;&#21450;&#20020;&#24202;&#30693;&#35782;&#25552;&#21462;&#21644;&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;LLM&#25552;&#31034;&#12290;&#20020;&#24202;&#20027;&#39064;&#21644;&#20889;&#20316;&#39118;&#26684;&#37117;&#26469;&#33258;&#22806;&#37096;&#39046;&#22495;&#29305;&#23450;&#30340;&#30693;&#35782;&#22270;&#35889;&#21644;LLMs&#65292;&#20197;&#24341;&#23548;&#25968;&#25454;&#29983;&#25104;&#12290;&#25105;&#20204;&#22312;7&#20010;&#20020;&#24202;NLP&#20219;&#21153;&#21644;16&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#32467;&#26524;&#26174;&#31034;ClinGen&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#22987;&#32456;&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#26377;&#25928;&#22320;&#20351;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#20998;&#24067;&#23545;&#40784;&#65292;&#24182;&#26174;&#33879;&#20016;&#23500;&#20102;&#26679;&#26412;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the divers
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#65292;&#36890;&#36807;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#26412;&#27604;&#36739;&#65292;&#24182;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#35780;&#20998;&#23610;&#24230;&#12290;&#35813;&#26041;&#27861;&#22312;Twitter&#19978;&#23545;&#24773;&#24863;&#35328;&#35770;&#30340;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.12049</link><description>&lt;p&gt;
Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models (&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#25552;&#31034;&#36827;&#34892;&#25991;&#26412;&#37197;&#23545;&#27604;&#36739;&#32553;&#25918;)
&lt;/p&gt;
&lt;p&gt;
Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models. (arXiv:2310.12049v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12049
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#65292;&#36890;&#36807;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#26412;&#27604;&#36739;&#65292;&#24182;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#35780;&#20998;&#23610;&#24230;&#12290;&#35813;&#26041;&#27861;&#22312;Twitter&#19978;&#23545;&#24773;&#24863;&#35328;&#35770;&#30340;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#32463;&#24120;&#38656;&#35201;&#22823;&#22411;&#35821;&#26009;&#24211;&#65292;&#38590;&#20197;&#22788;&#29702;&#30701;&#25991;&#26412;&#65292;&#25110;&#38656;&#35201;&#26377;&#26631;&#31614;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#26469;&#36827;&#34892;&#25991;&#26412;&#32553;&#25918;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#65288;CGCoT&#65289;&#65292;&#23427;&#20351;&#29992;&#35774;&#35745;&#29992;&#20110;&#24635;&#32467;&#24819;&#27861;&#24182;&#22312;&#25991;&#26412;&#20013;&#35782;&#21035;&#30446;&#26631;&#26041;&#30340;&#25552;&#31034;&#26469;&#29983;&#25104;&#27010;&#24565;&#29305;&#23450;&#30340;&#32454;&#20998;&#65292;&#31867;&#20284;&#20110;&#20154;&#31867;&#32534;&#30721;&#22120;&#20869;&#23481;&#20998;&#26512;&#30340;&#25351;&#23548;&#12290;CGCoT&#23558;&#37197;&#23545;&#25991;&#26412;&#27604;&#36739;&#20174;&#19968;&#20010;&#25512;&#29702;&#38382;&#39064;&#36716;&#21464;&#20026;&#19968;&#20010;&#27169;&#24335;&#35782;&#21035;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;LLM&#23545;&#27010;&#24565;&#29305;&#23450;&#30340;&#32454;&#20998;&#36827;&#34892;&#37197;&#23545;&#27604;&#36739;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#37197;&#23545;&#27604;&#36739;&#30340;&#32467;&#26524;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#19968;&#20010;&#35780;&#20998;&#23610;&#24230;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#23545;Twitter&#19978;&#30340;&#24773;&#24863;&#35328;&#35770;&#36827;&#34892;&#32553;&#25918;&#12290;&#25105;&#20204;&#30340;&#27979;&#37327;&#20540;&#19982;&#20154;&#31867;&#21028;&#26029;&#30340;&#30456;&#20851;&#24615;&#27604;Wordfish&#31561;&#26367;&#20195;&#26041;&#27861;&#26356;&#24378;&#12290;&#38500;&#20102;&#19968;&#23567;&#32452;&#29992;&#20110;&#24320;&#21457;CGCoT&#25552;&#31034;&#30340;&#35797;&#39564;&#25968;&#25454;&#20043;&#22806;&#65292;...
&lt;/p&gt;
&lt;p&gt;
Existing text scaling methods often require a large corpus, struggle with short texts, or require labeled data. We develop a text scaling method that leverages the pattern recognition capabilities of generative large language models (LLMs). Specifically, we propose concept-guided chain-of-thought (CGCoT), which uses prompts designed to summarize ideas and identify target parties in texts to generate concept-specific breakdowns, in many ways similar to guidance for human coder content analysis. CGCoT effectively shifts pairwise text comparisons from a reasoning problem to a pattern recognition problem. We then pairwise compare concept-specific breakdowns using an LLM. We use the results of these pairwise comparisons to estimate a scale using the Bradley-Terry model. We use this approach to scale affective speech on Twitter. Our measures correlate more strongly with human judgments than alternative approaches like Wordfish. Besides a small set of pilot data to develop the CGCoT prompts, 
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#25104;&#21151;&#22797;&#21046;&#20102;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#65292;&#20294;&#20854;&#32467;&#26524;&#34920;&#26126;&#24179;&#22343;&#35780;&#32423;&#26377;&#19978;&#21319;&#20559;&#24046;&#21644;&#36739;&#20302;&#30340;&#21464;&#24322;&#24615;&#19982;&#32467;&#26500;&#25928;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.10679</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#22797;&#21046;&#36328;&#25991;&#21270;&#20010;&#24615;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Large language models can replicate cross-cultural differences in personality. (arXiv:2310.10679v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10679
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#25104;&#21151;&#22797;&#21046;&#20102;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#65292;&#20294;&#20854;&#32467;&#26524;&#34920;&#26126;&#24179;&#22343;&#35780;&#32423;&#26377;&#19978;&#21319;&#20559;&#24046;&#21644;&#36739;&#20302;&#30340;&#21464;&#24322;&#24615;&#19982;&#32467;&#26500;&#25928;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#39564;(N=8000)&#26469;&#30830;&#23450;GPT-4&#26159;&#21542;&#21487;&#20197;&#22797;&#21046;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#12290;&#25105;&#20204;&#36873;&#25321;&#32654;&#22269;&#21644;&#38889;&#22269;&#20316;&#20026;&#25991;&#21270;&#23545;&#27604;&#65292;&#22240;&#20026;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#36825;&#20004;&#20010;&#22269;&#23478;&#30340;&#20154;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#20154;&#26684;&#24046;&#24322;&#12290;&#25105;&#20204;&#25805;&#32437;&#20102;&#27169;&#25311;&#30340;&#30446;&#26631;&#65288;&#32654;&#22269; vs. &#38889;&#22269;&#65289;&#65292;&#38382;&#21367;&#30340;&#35821;&#35328;&#65288;&#33521;&#35821; vs. &#38889;&#35821;&#65289;&#20197;&#21450;&#35821;&#35328;&#27169;&#22411;&#65288;GPT-4 vs. GPT-3.5&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4&#22797;&#21046;&#20102;&#27599;&#20010;&#22240;&#23376;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#35780;&#32423;&#20855;&#26377;&#19978;&#21319;&#20559;&#24046;&#65292;&#24182;&#19988;&#27604;&#20154;&#31867;&#26679;&#26412;&#30340;&#21464;&#24322;&#24615;&#26356;&#20302;&#65292;&#20197;&#21450;&#32467;&#26500;&#25928;&#24230;&#36739;&#20302;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21021;&#27493;&#30340;&#35777;&#25454;&#35828;&#26126;LLMs&#21487;&#20197;&#20419;&#36827;&#36328;&#25991;&#21270;&#24515;&#29702;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We use a large-scale experiment (N=8000) to determine whether GPT-4 can replicate cross-cultural differences in the Big Five, measured using the Ten-Item Personality Inventory. We used the US and South Korea as the cultural pair, given that prior research suggests substantial personality differences between people from these two countries. We manipulated the target of the simulation (US vs. Korean), the language of the inventory (English vs. Korean), and the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4 replicated the cross-cultural differences for each factor. However, mean ratings had an upward bias and exhibited lower variation than in the human samples, as well as lower structural validity. Overall, we provide preliminary evidence that LLMs can aid cross-cultural psychological research.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#20026;&#20363;&#65292;&#26816;&#26597;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#20449;&#20219;&#19982;&#23433;&#20840;&#38382;&#39064;&#20013;&#23398;&#26415;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#33073;&#33410;&#65292;&#24182;&#21457;&#29616;&#20102;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#20005;&#37325;&#19981;&#36275;&#20043;&#22788;&#65292;&#21253;&#25324;&#20219;&#21153;&#19981;&#31526;&#21512;&#22312;&#32447;&#26381;&#21153;&#38754;&#20020;&#30340;&#25361;&#25112;&#12289;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#35780;&#20272;&#19981;&#30495;&#23454;&#12289;&#35780;&#20272;&#19981;&#29420;&#31435;&#20110;&#27169;&#22411;&#35757;&#32451;&#31561;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#20449;&#20219;&#19982;&#23433;&#20840;&#38382;&#39064;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2308.12215</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#20449;&#20219;&#19982;&#23433;&#20840;&#26041;&#38754;&#30340;&#25361;&#25112;&#65306;&#19968;&#20010;&#38024;&#23545;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection. (arXiv:2308.12215v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12215
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#20026;&#20363;&#65292;&#26816;&#26597;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#20449;&#20219;&#19982;&#23433;&#20840;&#38382;&#39064;&#20013;&#23398;&#26415;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#33073;&#33410;&#65292;&#24182;&#21457;&#29616;&#20102;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#20005;&#37325;&#19981;&#36275;&#20043;&#22788;&#65292;&#21253;&#25324;&#20219;&#21153;&#19981;&#31526;&#21512;&#22312;&#32447;&#26381;&#21153;&#38754;&#20020;&#30340;&#25361;&#25112;&#12289;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#35780;&#20272;&#19981;&#30495;&#23454;&#12289;&#35780;&#20272;&#19981;&#29420;&#31435;&#20110;&#27169;&#22411;&#35757;&#32451;&#31561;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#20449;&#20219;&#19982;&#23433;&#20840;&#38382;&#39064;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#20316;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#26816;&#26597;&#20102;&#22312;&#23558;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#20449;&#20219;&#19982;&#23433;&#20840;&#38382;&#39064;&#19978;&#23398;&#26415;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#33073;&#33410;&#12290;&#25105;&#20204;&#23545;&#35813;&#39046;&#22495;&#20013;270&#31687;&#24191;&#21463;&#24341;&#29992;&#30340;&#35770;&#25991;&#36827;&#34892;&#20102;&#33258;&#21160;&#26816;&#27979;&#34394;&#20551;&#20449;&#24687;&#30340;&#25991;&#29486;&#31995;&#32479;&#21270;&#65292;&#24182;&#23545;&#23376;&#38598;&#20013;&#30340;&#35770;&#25991;&#36827;&#34892;&#20102;&#25968;&#25454;&#21644;&#20195;&#30721;&#30340;&#21487;&#29992;&#24615;&#12289;&#35774;&#35745;&#22833;&#35823;&#12289;&#21487;&#22797;&#29616;&#24615;&#21644;&#27867;&#21270;&#24615;&#31561;&#26041;&#38754;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#21457;&#29616;&#25991;&#29486;&#20013;&#23384;&#22312;&#20005;&#37325;&#30340;&#19981;&#36275;&#20043;&#22788;&#65292;&#36825;&#23545;&#25152;&#22768;&#31216;&#30340;&#24615;&#33021;&#21644;&#23454;&#29992;&#24615;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;&#26816;&#27979;&#20219;&#21153;&#36890;&#24120;&#19982;&#22312;&#32447;&#26381;&#21153;&#30495;&#27491;&#38754;&#20020;&#30340;&#25361;&#25112;&#26377;&#26412;&#36136;&#19978;&#30340;&#21306;&#21035;&#12290;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#35780;&#20272;&#36890;&#24120;&#19981;&#20195;&#34920;&#29616;&#23454;&#19990;&#30028;&#30340;&#24773;&#26223;&#65292;&#32780;&#19988;&#35780;&#20272;&#24448;&#24448;&#19981;&#29420;&#31435;&#20110;&#27169;&#22411;&#35757;&#32451;&#12290;&#25968;&#25454;&#21644;&#20195;&#30721;&#30340;&#21487;&#29992;&#24615;&#24456;&#24046;&#12290;&#27169;&#22411;&#22312;&#39046;&#22495;&#22806;&#30340;&#25968;&#25454;&#19978;&#27867;&#21270;&#33021;&#21147;&#19981;&#24378;&#12290;&#22522;&#20110;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#20449;&#20219;&#19982;&#23433;&#20840;&#38382;&#39064;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the disconnect between scholarship and practice in applying machine learning to trust and safety problems, using misinformation detection as a case study. We systematize literature on automated detection of misinformation across a corpus of 270 well-cited papers in the field. We then examine subsets of papers for data and code availability, design missteps, reproducibility, and generalizability. We find significant shortcomings in the literature that call into question claimed performance and practicality. Detection tasks are often meaningfully distinct from the challenges that online services actually face. Datasets and model evaluation are often non-representative of real-world contexts, and evaluation frequently is not independent of model training. Data and code availability is poor. Models do not generalize well to out-of-domain data. Based on these results, we offer recommendations for evaluating machine learning applications to trust and safety problems. Our aim is fo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09254</link><description>&lt;p&gt;
&#29992;&#20110;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#22686;&#24378;&#27169;&#22411;&#21487;&#20449;&#24230;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#30001;&#20110;&#23545;&#29983;&#25104;&#34394;&#26500;&#20107;&#23454;&#30340;&#25285;&#24551;&#65292;&#26368;&#36817;&#20852;&#36215;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;GLM&#65289;&#29305;&#21035;&#24378;&#35843;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31070;&#32463;&#39044;&#27979;&#38598;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;&#30340;&#26041;&#24335;&#37327;&#21270;GLM&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#39044;&#27979;&#38598;&#27169;&#22411;&#36890;&#36807;&#26631;&#37327;&#20540;&#21442;&#25968;&#21270;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#39044;&#27979;&#38598;&#65292;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#20173;&#28385;&#36275;PAC&#20445;&#35777;&#12290;&#36890;&#36807;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#20845;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
&lt;/p&gt;</description></item></channel></rss>