<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#33258;&#23450;&#20041;&#25968;&#25454;&#38598;&#19978;&#30340;&#24494;&#35843;&#21644;&#26410;&#24494;&#35843;&#65292;&#21457;&#29616;&#32463;&#36807;&#24494;&#35843;&#30340;&#27169;&#22411;&#32988;&#36807;&#29616;&#26377;&#27169;&#22411;&#65292;&#22312;&#29983;&#25104;&#25688;&#35201;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;</title><link>https://arxiv.org/abs/2403.20145</link><description>&lt;p&gt;
&#20026;&#33258;&#21160;&#35786;&#26029;&#31579;&#26597;&#24635;&#32467;&#20248;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20145
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#33258;&#23450;&#20041;&#25968;&#25454;&#38598;&#19978;&#30340;&#24494;&#35843;&#21644;&#26410;&#24494;&#35843;&#65292;&#21457;&#29616;&#32463;&#36807;&#24494;&#35843;&#30340;&#27169;&#22411;&#32988;&#36807;&#29616;&#26377;&#27169;&#22411;&#65292;&#22312;&#29983;&#25104;&#25688;&#35201;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21457;&#23637;&#20013;&#22269;&#23478;&#25913;&#21892;&#24515;&#29702;&#20581;&#24247;&#25903;&#25345;&#26159;&#19968;&#20010;&#32039;&#36843;&#30340;&#38656;&#27714;&#12290;&#19968;&#31181;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#24320;&#21457;&#21487;&#25193;&#23637;&#30340;&#33258;&#21160;&#31995;&#32479;&#36827;&#34892;&#35786;&#26029;&#31579;&#26597;&#65292;&#36825;&#26377;&#21161;&#20110;&#20943;&#36731;&#24515;&#29702;&#20581;&#24247;&#19987;&#19994;&#20154;&#21592;&#30340;&#36127;&#25285;&#12290;&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#23450;&#20041;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24494;&#35843;&#21644;&#26410;&#24494;&#35843;&#65292;&#29992;&#20110;&#20174;&#24515;&#29702;&#29366;&#24577;&#26816;&#26597;&#20013;&#29983;&#25104;&#31616;&#26126;&#25688;&#35201;&#12290;&#25105;&#20204;&#20351;&#29992;&#24050;&#24314;&#31435;&#30340;ROUGE&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#32773;&#30340;&#36755;&#20837;&#65292;&#23545;&#22235;&#31181;&#19981;&#21516;&#30340;&#25688;&#35201;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#20102;&#20005;&#26684;&#35780;&#20272;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#34920;&#29616;&#26368;&#20339;&#30340;&#32463;&#36807;&#24494;&#35843;&#30340;&#27169;&#22411;&#32988;&#36807;&#29616;&#26377;&#27169;&#22411;&#65292;&#20998;&#21035;&#23454;&#29616;&#20102;0.810&#21644;0.764&#30340;ROUGE-1&#21644;ROUGE-L&#20540;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#24494;&#35843;&#27169;&#22411;&#22312;&#20844;&#24320;&#21487;&#29992;&#30340;D4&#25968;&#25454;&#38598;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#20196;&#20154;&#40723;&#33310;&#65292;&#34920;&#26126;&#20854;&#28508;&#22312;&#36866;&#29992;&#24615;&#36229;&#20986;&#25105;&#20204;&#30340;&#33258;&#23450;&#20041;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20145v1 Announce Type: new  Abstract: Improving mental health support in developing countries is a pressing need. One potential solution is the development of scalable, automated systems to conduct diagnostic screenings, which could help alleviate the burden on mental health professionals. In this work, we evaluate several state-of-the-art Large Language Models (LLMs), with and without fine-tuning, on our custom dataset for generating concise summaries from mental state examinations. We rigorously evaluate four different models for summary generation using established ROUGE metrics and input from human evaluators. The results highlight that our top-performing fine-tuned model outperforms existing models, achieving ROUGE-1 and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessed the fine-tuned model's generalizability on a publicly available D4 dataset, and the outcomes were promising, indicating its potential applicability beyond our custom dataset.
&lt;/p&gt;</description></item></channel></rss>