<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;SOLID&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#25773;&#31181;&#21644;&#22810;&#24847;&#22270;&#33258;&#25105;&#25351;&#23548;&#26041;&#26696;&#26469;&#23454;&#29616;LLMs&#29983;&#25104;&#24847;&#22270;&#24863;&#30693;&#30340;&#20449;&#24687;&#26816;&#32034;&#23545;&#35805;&#12290;</title><link>https://arxiv.org/abs/2402.11633</link><description>&lt;p&gt;
&#21033;&#29992;&#33258;&#25105;&#25773;&#31181;&#21644;&#22810;&#24847;&#22270;&#33258;&#25105;&#25351;&#23548;&#30340;LLM&#29983;&#25104;&#24847;&#22270;&#24863;&#30693;&#30340;&#20449;&#24687;&#26816;&#32034;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking dialogs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11633
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;SOLID&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#25105;&#25773;&#31181;&#21644;&#22810;&#24847;&#22270;&#33258;&#25105;&#25351;&#23548;&#26041;&#26696;&#26469;&#23454;&#29616;LLMs&#29983;&#25104;&#24847;&#22270;&#24863;&#30693;&#30340;&#20449;&#24687;&#26816;&#32034;&#23545;&#35805;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#20449;&#24687;&#26816;&#32034;&#23545;&#35805;&#20013;&#29992;&#25143;&#24847;&#22270;&#23545;&#20110;&#31995;&#32479;&#28385;&#36275;&#29992;&#25143;&#20449;&#24687;&#38656;&#27714;&#33267;&#20851;&#37325;&#35201;&#12290;&#24847;&#22270;&#39044;&#27979;&#65288;IP&#65289;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#38656;&#35201;&#20805;&#20998;&#30340;&#19982;&#20154;&#24037;&#26631;&#27880;&#24847;&#22270;&#23545;&#35805;&#29992;&#20110;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#25163;&#21160;&#27880;&#37322;&#24847;&#22270;&#36164;&#28304;&#23494;&#38598;&#12290;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#26041;&#38754;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#23578;&#26080;&#30740;&#31350;&#20351;&#29992;LLMs&#29983;&#25104;&#24847;&#22270;&#24863;&#30693;&#30340;&#20449;&#24687;&#26816;&#32034;&#23545;&#35805;&#12290;&#26412;&#25991;&#30340;&#30740;&#31350;&#37325;&#28857;&#26159;&#21033;&#29992;LLMs&#36827;&#34892;&#38646;-shot&#29983;&#25104;&#22823;&#35268;&#27169;&#12289;&#24320;&#25918;&#39046;&#22495;&#21644;&#24847;&#22270;&#24863;&#30693;&#30340;&#20449;&#24687;&#26816;&#32034;&#23545;&#35805;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;SOLID&#65292;&#20854;&#20013;&#21253;&#25324;&#26032;&#39062;&#30340;&#33258;&#25105;&#25773;&#31181;&#21644;&#22810;&#24847;&#22270;&#33258;&#25105;&#25351;&#23548;&#26041;&#26696;&#12290;&#21069;&#32773;&#36890;&#36807;&#21033;&#29992;LLM&#33258;&#36523;&#30340;&#30693;&#35782;&#33539;&#22260;&#26469;&#21551;&#21160;&#23545;&#35805;&#29983;&#25104;&#26469;&#25552;&#39640;&#29983;&#25104;&#36136;&#37327;&#65307;&#21518;&#32773;&#20419;&#20351;LLM&#25353;&#39034;&#24207;&#29983;&#25104;&#35805;&#35821;&#65292;&#24182;&#36890;&#36807;&#35201;&#27714;LLM&#33258;&#21160;&#23436;&#25104;&#35805;&#39064;&#35774;&#35745;&#26469;&#20943;&#36731;&#25163;&#21160;&#35805;&#39064;&#35774;&#35745;&#30340;&#38656;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11633v1 Announce Type: new  Abstract: Identifying user intents in information-seeking dialogs is crucial for a system to meet user's information needs. Intent prediction (IP) is challenging and demands sufficient dialogs with human-labeled intents for training. However, manually annotating intents is resource-intensive. While large language models (LLMs) have been shown to be effective in generating synthetic data, there is no study on using LLMs to generate intent-aware information-seeking dialogs. In this paper, we focus on leveraging LLMs for zero-shot generation of large-scale, open-domain, and intent-aware information-seeking dialogs. We propose SOLID, which has novel self-seeding and multi-intent self-instructing schemes. The former improves the generation quality by using the LLM's own knowledge scope to initiate dialog generation; the latter prompts the LLM to generate utterances sequentially, and mitigates the need for manual prompt design by asking the LLM to auton
&lt;/p&gt;</description></item></channel></rss>