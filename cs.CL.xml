<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#20013;&#30340;&#25439;&#22833;&#23574;&#23792;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25214;&#20986;&#20102;&#26799;&#24230;&#29190;&#28856;&#30340;&#21407;&#22240;&#65292;&#24182;&#25552;&#20986;&#20102;&#28385;&#36275;&#35201;&#27714;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#38450;&#27490;&#23574;&#23792;&#30340;&#21457;&#29983;&#12290;</title><link>https://rss.arxiv.org/abs/2312.16903</link><description>&lt;p&gt;
&#21035;&#20877;&#20986;&#29616;&#23574;&#23792;&#20102;&#65306;&#31283;&#23450;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Spike No More: Stabilizing the Pre-training of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2312.16903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#20013;&#30340;&#25439;&#22833;&#23574;&#23792;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25214;&#20986;&#20102;&#26799;&#24230;&#29190;&#28856;&#30340;&#21407;&#22240;&#65292;&#24182;&#25552;&#20986;&#20102;&#28385;&#36275;&#35201;&#27714;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#38450;&#27490;&#23574;&#23792;&#30340;&#21457;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#32463;&#24120;&#20986;&#29616;&#25439;&#22833;&#23574;&#23792;&#12290;&#36825;&#20123;&#23574;&#23792;&#20250;&#38477;&#20302;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#26377;&#26102;&#20250;&#30772;&#22351;&#39044;&#35757;&#32451;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#38656;&#35201;&#22823;&#37327;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#25105;&#20204;&#24212;&#35813;&#36991;&#20813;&#36825;&#31181;&#23574;&#23792;&#30340;&#20986;&#29616;&#12290;&#20026;&#20102;&#30740;&#31350;&#25439;&#22833;&#23574;&#23792;&#30340;&#21407;&#22240;&#65292;&#25105;&#20204;&#20851;&#27880;&#20869;&#37096;&#23618;&#30340;&#26799;&#24230;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#26799;&#24230;&#29190;&#28856;&#30340;&#20004;&#20010;&#21407;&#22240;&#65292;&#24182;&#25552;&#20379;&#20102;&#39044;&#38450;&#26799;&#24230;&#29190;&#28856;&#30340;&#35201;&#27714;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32452;&#21512;&#21021;&#22987;&#21270;&#26041;&#27861;&#21644;&#23545;&#23884;&#20837;&#36827;&#34892;&#31616;&#21333;&#20462;&#25913;&#26469;&#28385;&#36275;&#35201;&#27714;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#21508;&#31181;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#30340;&#26377;&#25928;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#39044;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#36825;&#31181;&#32452;&#21512;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#38450;&#27490;&#23574;&#23792;&#30340;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Loss spikes often occur during pre-training of large language models. The spikes degrade the performance of large language models and sometimes ruin the pre-training. Since the pre-training needs a vast computational budget, we should avoid such spikes. To investigate the cause of loss spikes, we focus on gradients of internal layers. Through theoretical analyses, we reveal two causes of the exploding gradients, and provide requirements to prevent the explosion. In addition, we propose a method to satisfy the requirements by combining the initialization method and a simple modification to embeddings. We conduct various experiments to verify our theoretical analyses empirically. Experimental results indicate that the combination is effective in preventing spikes during pre-training.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#20851;&#31995;&#25552;&#21462;&#20219;&#21153;&#20013;&#39046;&#22495;&#29305;&#24322;&#24615;&#23545;&#20110;&#35821;&#35328;&#27169;&#22411;&#21644;&#25351;&#23548;&#24494;&#35843;&#30340;&#37325;&#35201;&#24615;&#65292;&#23545;&#27604;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#19982;&#36890;&#29992;&#39046;&#22495;&#35757;&#32451;&#30340;&#27169;&#22411;&#25928;&#26524;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#25351;&#23548;&#24494;&#35843;&#30340;&#27169;&#22411;&#22312;&#24615;&#33021;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.13470</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#21644;&#29983;&#29289;&#21307;&#23398;&#20851;&#31995;&#25552;&#21462;&#20013;&#30340;&#39046;&#22495;&#29305;&#24322;&#24615;&#26377;&#22810;&#37325;&#35201;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Important is Domain Specificity in Language Models and Instruction Finetuning for Biomedical Relation Extraction?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13470
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#20851;&#31995;&#25552;&#21462;&#20219;&#21153;&#20013;&#39046;&#22495;&#29305;&#24322;&#24615;&#23545;&#20110;&#35821;&#35328;&#27169;&#22411;&#21644;&#25351;&#23548;&#24494;&#35843;&#30340;&#37325;&#35201;&#24615;&#65292;&#23545;&#27604;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#19982;&#36890;&#29992;&#39046;&#22495;&#35757;&#32451;&#30340;&#27169;&#22411;&#25928;&#26524;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#25351;&#23548;&#24494;&#35843;&#30340;&#27169;&#22411;&#22312;&#24615;&#33021;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#20215;&#20540;&#12289;&#25968;&#25454;&#20016;&#23500;&#30340;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#24120;&#24120;&#20250;&#20351;&#29992;&#26368;&#21069;&#27839;&#30340;&#36890;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#12290;&#36807;&#21435;&#20960;&#24180;&#26469;&#65292;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#12289;&#25351;&#23548;&#24494;&#35843;&#21644;&#23569;&#26679;&#26412;&#23398;&#20064;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#30340;&#28966;&#28857;&#12290;&#22240;&#27492;&#65292;&#39044;&#35757;&#32451;&#20110;&#29983;&#29289;&#21307;&#23398;&#35821;&#26009;&#24211;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#26029;&#28044;&#29616;&#65292;&#21516;&#26102;&#20063;&#23581;&#35797;&#23545;&#29983;&#29289;&#21307;&#23398;&#25351;&#23548;&#24494;&#35843;&#65292;&#24076;&#26395;&#39046;&#22495;&#29305;&#24322;&#24615;&#21487;&#20197;&#25913;&#21892;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#37492;&#20110;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#25152;&#38656;&#30340;&#38750;&#24179;&#20961;&#21162;&#21147;&#65292;&#25105;&#20204;&#30740;&#31350;&#23427;&#20204;&#22312;&#20851;&#31995;&#25552;&#21462;&#36825;&#19968;&#20851;&#38190;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#26159;&#21542;&#23384;&#22312;&#20219;&#20309;&#30410;&#22788;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#20004;&#20010;&#38382;&#39064;&#65306;(1) &#22312;&#29983;&#29289;&#21307;&#23398;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#20248;&#20110;&#22312;&#36890;&#29992;&#39046;&#22495;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#65311;(2) &#22312;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#25351;&#23548;&#24494;&#35843;&#30340;&#27169;&#22411;&#26159;&#21542;&#20248;&#20110;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#25110;&#32773;&#20165;&#20165;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#65311;&#25105;&#20204;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13470v1 Announce Type: new  Abstract: Cutting edge techniques developed in the general NLP domain are often subsequently applied to the high-value, data-rich biomedical domain. The past few years have seen generative language models (LMs), instruction finetuning, and few-shot learning become foci of NLP research. As such, generative LMs pretrained on biomedical corpora have proliferated and biomedical instruction finetuning has been attempted as well, all with the hope that domain specificity improves performance on downstream tasks. Given the nontrivial effort in training such models, we investigate what, if any, benefits they have in the key biomedical NLP task of relation extraction. Specifically, we address two questions: (1) Do LMs trained on biomedical corpora outperform those trained on general domain corpora? (2) Do models instruction finetuned on biomedical datasets outperform those finetuned on assorted datasets or those simply pretrained? We tackle these questions
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#29992;&#20110;&#31471;&#21040;&#31471;&#20851;&#31995;&#25277;&#21462;&#30340;&#31649;&#36947;&#12289;&#24207;&#21015;&#21040;&#24207;&#21015;&#21644;GPT&#27169;&#22411;&#65292;&#21457;&#29616;&#31649;&#36947;&#27169;&#22411;&#20173;&#28982;&#26159;&#26368;&#20339;&#36873;&#25321;&#65292;&#32780;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#32039;&#38543;&#20854;&#21518;&#65307;&#21442;&#25968;&#37327;&#22686;&#21152;&#20843;&#20493;&#30340;GPT&#27169;&#22411;&#29978;&#33267;&#27604;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#26356;&#24046;&#65292;&#19988;&#27604;&#31649;&#36947;&#27169;&#22411;&#20302;10&#20010;F1&#28857;&#20197;&#19978;&#12290;</title><link>https://arxiv.org/abs/2311.13729</link><description>&lt;p&gt;
&#27604;&#36739;&#29992;&#20110;&#31471;&#21040;&#31471;&#20851;&#31995;&#25277;&#21462;&#30340;&#31649;&#36947;&#12289;&#24207;&#21015;&#21040;&#24207;&#21015;&#21644;GPT&#27169;&#22411;&#65306;&#20197;&#32597;&#35265;&#30142;&#30149;&#29992;&#20363;&#20026;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#29992;&#20110;&#31471;&#21040;&#31471;&#20851;&#31995;&#25277;&#21462;&#30340;&#31649;&#36947;&#12289;&#24207;&#21015;&#21040;&#24207;&#21015;&#21644;GPT&#27169;&#22411;&#65292;&#21457;&#29616;&#31649;&#36947;&#27169;&#22411;&#20173;&#28982;&#26159;&#26368;&#20339;&#36873;&#25321;&#65292;&#32780;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#32039;&#38543;&#20854;&#21518;&#65307;&#21442;&#25968;&#37327;&#22686;&#21152;&#20843;&#20493;&#30340;GPT&#27169;&#22411;&#29978;&#33267;&#27604;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#26356;&#24046;&#65292;&#19988;&#27604;&#31649;&#36947;&#27169;&#22411;&#20302;10&#20010;F1&#28857;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31471;&#21040;&#31471;&#20851;&#31995;&#25277;&#21462;&#65288;E2ERE&#65289;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#22312;&#29983;&#29289;&#21307;&#23398;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#32780;&#29616;&#23454;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#26088;&#22312;&#20351;&#29992;&#19968;&#20010;&#20851;&#27880;&#32597;&#35265;&#30142;&#30149;&#12289;&#28041;&#21450;&#19981;&#36830;&#32493;&#21644;&#23884;&#22871;&#23454;&#20307;&#30340;&#22797;&#26434;&#25968;&#25454;&#38598;&#65292;&#27604;&#36739;E2ERE&#30340;&#19977;&#31181;&#27969;&#34892;&#33539;&#24335;&#12290;&#25105;&#20204;&#20351;&#29992;RareDis&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;&#35780;&#20272;&#20102;&#19977;&#31181;&#31454;&#20105;&#26041;&#27861;&#65288;&#29992;&#20110;E2ERE&#65289;&#65306;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#8594;&#20851;&#31995;&#25277;&#21462;&#65288;RE&#65289;&#31649;&#36947;&#12289;&#32852;&#21512;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#21644;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#21464;&#21387;&#22120;&#65288;GPT&#65289;&#27169;&#22411;&#12290;&#25105;&#20204;&#38024;&#23545;&#27599;&#31181;&#26041;&#27861;&#20351;&#29992;&#21487;&#27604;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#21644;&#26368;&#20339;&#23454;&#36341;&#65292;&#24182;&#36827;&#34892;&#38169;&#35823;&#20998;&#26512;&#20197;&#35780;&#20272;&#23427;&#20204;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26174;&#31034;&#65292;&#31649;&#36947;&#27169;&#22411;&#20173;&#28982;&#26159;&#26368;&#20339;&#36873;&#25321;&#65292;&#32780;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#32039;&#38543;&#20854;&#21518;&#65307;&#21442;&#25968;&#37327;&#22686;&#21152;&#20843;&#20493;&#30340;GPT&#27169;&#22411;&#29978;&#33267;&#27604;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#26356;&#24046;&#65292;&#19988;&#27604;&#31649;&#36947;&#27169;&#22411;&#20302;10&#20010;F1&#28857;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13729v2 Announce Type: replace  Abstract: End-to-end relation extraction (E2ERE) is an important and realistic application of natural language processing (NLP) in biomedicine. In this paper, we aim to compare three prevailing paradigms for E2ERE using a complex dataset focused on rare diseases involving discontinuous and nested entities. We use the RareDis information extraction dataset to evaluate three competing approaches (for E2ERE): NER $\rightarrow$ RE pipelines, joint sequence to sequence models, and generative pre-trained transformer (GPT) models. We use comparable state-of-the-art models and best practices for each of these approaches and conduct error analyses to assess their failure modes. Our findings reveal that pipeline models are still the best, while sequence-to-sequence models are not far behind; GPT models with eight times as many parameters are worse than even sequence-to-sequence models and lose to pipeline models by over 10 F1 points. Partial matches and
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#20302;&#36164;&#28304;&#23433;&#20840;&#25915;&#20987;&#27169;&#24335;&#35782;&#21035;&#21305;&#37197;&#26694;&#26550;&#65292;&#36890;&#36807;&#30452;&#25509;&#35821;&#20041;&#30456;&#20284;&#24230;&#20915;&#23450;&#25991;&#26412;&#19982;&#25915;&#20987;&#27169;&#24335;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#20197;&#38477;&#20302;&#22823;&#37327;&#31867;&#21035;&#12289;&#26631;&#31614;&#20998;&#24067;&#19981;&#22343;&#21644;&#26631;&#31614;&#31354;&#38388;&#22797;&#26434;&#24615;&#24102;&#26469;&#30340;&#23398;&#20064;&#38590;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.10337</link><description>&lt;p&gt;
&#22522;&#20110;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#20302;&#36164;&#28304;&#23433;&#20840;&#25915;&#20987;&#27169;&#24335;&#35782;&#21035;&#21305;&#37197;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10337
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#30340;&#20302;&#36164;&#28304;&#23433;&#20840;&#25915;&#20987;&#27169;&#24335;&#35782;&#21035;&#21305;&#37197;&#26694;&#26550;&#65292;&#36890;&#36807;&#30452;&#25509;&#35821;&#20041;&#30456;&#20284;&#24230;&#20915;&#23450;&#25991;&#26412;&#19982;&#25915;&#20987;&#27169;&#24335;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#20197;&#38477;&#20302;&#22823;&#37327;&#31867;&#21035;&#12289;&#26631;&#31614;&#20998;&#24067;&#19981;&#22343;&#21644;&#26631;&#31614;&#31354;&#38388;&#22797;&#26434;&#24615;&#24102;&#26469;&#30340;&#23398;&#20064;&#38590;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25112;&#26415;&#12289;&#25216;&#26415;&#21644;&#31243;&#24207;&#65288;TTPs&#65289;&#26159;&#32593;&#32476;&#23433;&#20840;&#39046;&#22495;&#20013;&#22797;&#26434;&#30340;&#25915;&#20987;&#27169;&#24335;&#65292;&#22312;&#25991;&#26412;&#30693;&#35782;&#24211;&#20013;&#26377;&#35814;&#32454;&#30340;&#25551;&#36848;&#12290;&#22312;&#32593;&#32476;&#23433;&#20840;&#20889;&#20316;&#20013;&#35782;&#21035;TTPs&#65292;&#36890;&#24120;&#31216;&#20026;TTP&#26144;&#23556;&#65292;&#26159;&#19968;&#20010;&#37325;&#35201;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20256;&#32479;&#30340;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#20197;&#32463;&#20856;&#30340;&#22810;&#31867;&#25110;&#22810;&#26631;&#31614;&#20998;&#31867;&#35774;&#32622;&#20026;&#30446;&#26631;&#12290;&#30001;&#20110;&#23384;&#22312;&#22823;&#37327;&#30340;&#31867;&#21035;&#65288;&#21363;TTPs&#65289;&#65292;&#26631;&#31614;&#20998;&#24067;&#30340;&#19981;&#22343;&#34913;&#21644;&#26631;&#31614;&#31354;&#38388;&#30340;&#22797;&#26434;&#23618;&#27425;&#32467;&#26500;&#65292;&#36825;&#31181;&#35774;&#32622;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#23398;&#20064;&#33539;&#24335;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#23558;&#25991;&#26412;&#19982;TTP&#26631;&#31614;&#20043;&#38388;&#30340;&#30452;&#25509;&#35821;&#20041;&#30456;&#20284;&#24230;&#20915;&#23450;&#20026;&#25991;&#26412;&#20998;&#37197;&#32473;TTP&#26631;&#31614;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#20165;&#20165;&#22312;&#22823;&#22411;&#26631;&#31614;&#31354;&#38388;&#19978;&#31454;&#20105;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26377;&#25928;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#23398;&#20064;&#27604;&#36739;&#26426;&#21046;&#30340;&#31070;&#32463;&#21305;&#37197;&#26550;&#26500;&#65292;&#20419;&#36827;&#23398;&#20064;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tactics, Techniques and Procedures (TTPs) represent sophisticated attack patterns in the cybersecurity domain, described encyclopedically in textual knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP mapping, is an important and challenging task. Conventional learning approaches often target the problem in the classical multi-class or multilabel classification setting. This setting hinders the learning ability of the model due to a large number of classes (i.e., TTPs), the inevitable skewness of the label distribution and the complex hierarchical structure of the label space. We formulate the problem in a different learning paradigm, where the assignment of a text to a TTP label is decided by the direct semantic similarity between the two, thus reducing the complexity of competing solely over the large labeling space. To that end, we propose a neural matching architecture with an effective sampling-based learn-to-compare mechanism, facilitating the learning pr
&lt;/p&gt;</description></item></channel></rss>