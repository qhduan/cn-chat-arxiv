<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#23558;&#25277;&#35937;&#24847;&#20041;&#34920;&#31034;&#32467;&#21512;&#21040;LLMs&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#26377;&#25928;&#30340;&#26694;&#26550;&#29992;&#20110;&#25913;&#21892;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#35780;&#20272;</title><link>https://arxiv.org/abs/2404.01129</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#20449;&#24687;&#24456;&#37325;&#35201;&#65306;&#23558;&#25277;&#35937;&#24847;&#20041;&#34920;&#31034;&#24341;&#20837;LLMs&#20197;&#25913;&#21892;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Structured Information Matters: Incorporating Abstract Meaning Representation into LLMs for Improved Open-Domain Dialogue Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01129
&lt;/p&gt;
&lt;p&gt;
&#23558;&#25277;&#35937;&#24847;&#20041;&#34920;&#31034;&#32467;&#21512;&#21040;LLMs&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#26377;&#25928;&#30340;&#26694;&#26550;&#29992;&#20110;&#25913;&#21892;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01129v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#30340; &#25688;&#35201;&#65306;&#33258;&#21160;&#30340;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#35780;&#20272;&#24050;&#32463;&#24341;&#36215;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#21487;&#35757;&#32451;&#30340;&#35780;&#20272;&#25351;&#26631;&#36890;&#24120;&#26159;&#36890;&#36807;&#35757;&#32451;&#20855;&#26377;&#30495;&#27491;&#27491;&#20363;&#21644;&#38543;&#26426;&#36873;&#25321;&#30340;&#36127;&#20363;&#22238;&#22797;&#26469;&#35757;&#32451;&#30340;&#65292;&#23548;&#33268;&#23427;&#20204;&#20542;&#21521;&#20110;&#23558;&#26356;&#39640;&#20869;&#23481;&#30456;&#20284;&#24615;&#30340;&#22238;&#22797;&#20998;&#37197;&#26356;&#39640;&#30340;&#24471;&#20998;&#32473;&#23450;&#19968;&#20010;&#19978;&#19979;&#25991;&#12290;&#28982;&#32780;&#65292;&#23545;&#25239;&#24615;&#30340;&#36127;&#38754;&#22238;&#22797;&#20855;&#26377;&#19982;&#19978;&#19979;&#25991;&#39640;&#20869;&#23481;&#30456;&#20284;&#24615;&#65292;&#21516;&#26102;&#22312;&#35821;&#20041;&#19978;&#19981;&#21516;&#12290;&#22240;&#27492;&#65292;&#29616;&#26377;&#30340;&#35780;&#20272;&#25351;&#26631;&#19981;&#36275;&#20197;&#35780;&#20272;&#36825;&#31867;&#22238;&#22797;&#65292;&#23548;&#33268;&#19982;&#20154;&#31867;&#21028;&#26029;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#36739;&#20302;&#12290;&#34429;&#28982;&#26368;&#36817;&#30340;&#30740;&#31350;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#35780;&#20272;&#26041;&#38754;&#26377;&#19968;&#23450;&#25928;&#26524;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#22312;&#26377;&#25928;&#22788;&#29702;&#23545;&#25239;&#24615;&#36127;&#38754;&#31034;&#20363;&#26041;&#38754;&#36935;&#21040;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26694;&#26550;&#29992;&#20110;&#24320;&#25918;&#39046;&#22495;&#23545;&#35805;&#35780;&#20272;&#65292;&#23427;&#32467;&#21512;&#20102;&#39046;&#22495;&#29305;&#23450;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;SLMs&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01129v1 Announce Type: new  Abstract: Automatic open-domain dialogue evaluation has attracted increasing attention. Trainable evaluation metrics are commonly trained with true positive and randomly selected negative responses, resulting in a tendency for them to assign a higher score to the responses that share higher content similarity with a given context. However, adversarial negative responses possess high content similarity with the contexts whilst being semantically different. Therefore, existing evaluation metrics are not robust enough to evaluate such responses, resulting in low correlations with human judgments. While recent studies have shown some efficacy in utilizing Large Language Models (LLMs) for open-domain dialogue evaluation, they still encounter challenges in effectively handling adversarial negative examples. In this paper, we propose a simple yet effective framework for open-domain dialogue evaluation, which combines domain-specific language models (SLMs
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#20998;&#26512;&#20102;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#21508;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#38899;&#27169;&#22411;&#20013;&#30340;&#26032;&#39062;&#29616;&#35937;&#65292;&#24182;&#23637;&#31034;&#20102;&#29305;&#24449;&#20132;&#20114;&#22914;&#20309;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.13106</link><description>&lt;p&gt;
&#35748;&#35782;&#20320;&#30340;&#38750;&#32447;&#24615;&#65306;Shapley&#20114;&#21160;&#25581;&#31034;&#25968;&#25454;&#30340;&#28508;&#22312;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Knowing Your Nonlinearities: Shapley Interactions Reveal the Underlying Structure of Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#20998;&#26512;&#20102;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#21508;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#35821;&#35328;&#27169;&#22411;&#21644;&#35821;&#38899;&#27169;&#22411;&#20013;&#30340;&#26032;&#39062;&#29616;&#35937;&#65292;&#24182;&#23637;&#31034;&#20102;&#29305;&#24449;&#20132;&#20114;&#22914;&#20309;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#37327;&#38750;&#32447;&#24615;&#29305;&#24449;&#20132;&#20114;&#26159;&#29702;&#35299;&#35768;&#22810;&#27169;&#22411;&#20013;&#22797;&#26434;&#24402;&#22240;&#27169;&#24335;&#30340;&#19968;&#31181;&#24050;&#24314;&#31435;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#20351;&#29992;Shapley Taylor&#20114;&#21160;&#25351;&#25968;&#65288;STII&#65289;&#26469;&#20998;&#26512;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#22810;&#31181;&#27169;&#24577;&#12289;&#20219;&#21153;&#21644;&#26550;&#26500;&#20013;&#27169;&#22411;&#34920;&#24449;&#30340;&#24433;&#21709;&#12290;&#22312;&#32771;&#34385;&#25513;&#30721;&#21644;&#33258;&#22238;&#24402;&#35821;&#35328;&#27169;&#22411;&#65288;MLMs&#21644;ALMs&#65289;&#20013;&#30340;&#35821;&#35328;&#32467;&#26500;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;STII&#22312;&#24815;&#29992;&#34920;&#36798;&#20013;&#22686;&#21152;&#65292;MLMs&#38543;&#21477;&#27861;&#36317;&#31163;&#25193;&#23637;STII&#65292;&#26356;&#22810;&#22320;&#20381;&#36182;&#35821;&#27861;&#22312;&#20854;&#38750;&#32447;&#24615;&#32467;&#26500;&#20013;&#30456;&#27604;ALMs&#12290;&#25105;&#20204;&#30340;&#35821;&#38899;&#27169;&#22411;&#30740;&#31350;&#21453;&#26144;&#20102;&#21475;&#33108;&#24352;&#24320;&#31243;&#24230;&#20915;&#23450;&#38899;&#32032;&#26681;&#25454;&#19978;&#19979;&#25991;&#21464;&#21270;&#30340;&#25968;&#37327;&#30340;&#21407;&#21017;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#22270;&#20687;&#20998;&#31867;&#22120;&#24182;&#35828;&#26126;&#29305;&#24449;&#20132;&#20114;&#30452;&#35266;&#21453;&#26144;&#23545;&#35937;&#36793;&#30028;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#36328;&#23398;&#31185;&#24037;&#20316;&#21644;&#39046;&#22495;&#20043;&#38388;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13106v1 Announce Type: cross  Abstract: Measuring nonlinear feature interaction is an established approach to understanding complex patterns of attribution in many models. In this paper, we use Shapley Taylor interaction indices (STII) to analyze the impact of underlying data structure on model representations in a variety of modalities, tasks, and architectures. Considering linguistic structure in masked and auto-regressive language models (MLMs and ALMs), we find that STII increases within idiomatic expressions and that MLMs scale STII with syntactic distance, relying more on syntax in their nonlinear structure than ALMs do. Our speech model findings reflect the phonetic principal that the openness of the oral cavity determines how much a phoneme varies based on its context. Finally, we study image classifiers and illustrate that feature interactions intuitively reflect object boundaries. Our wide range of results illustrates the benefits of interdisciplinary work and doma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#24067;&#20102;&#19968;&#20010;&#22823;&#22411;&#26631;&#20934;&#25968;&#25454;&#38598;DREsS&#65292;&#29992;&#20110;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#33258;&#21160;&#20316;&#25991;&#35780;&#20998;&#65292;&#22312;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30772;&#22351;&#30340;&#20316;&#25991;&#22686;&#24378;&#31574;&#30053;CASE&#21518;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#30340;&#22522;&#32447;&#32467;&#26524;&#25552;&#39640;&#20102;45.44&#65285;&#12290;</title><link>https://arxiv.org/abs/2402.16733</link><description>&lt;p&gt;
DREsS: &#33521;&#35821;&#20316;&#20026;&#22806;&#35821;&#20889;&#20316;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#24067;&#20102;&#19968;&#20010;&#22823;&#22411;&#26631;&#20934;&#25968;&#25454;&#38598;DREsS&#65292;&#29992;&#20110;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#33258;&#21160;&#20316;&#25991;&#35780;&#20998;&#65292;&#22312;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30772;&#22351;&#30340;&#20316;&#25991;&#22686;&#24378;&#31574;&#30053;CASE&#21518;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#30340;&#22522;&#32447;&#32467;&#26524;&#25552;&#39640;&#20102;45.44&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#20316;&#25991;&#35780;&#20998;&#65288;AES&#65289;&#26159;&#33521;&#35821;&#20316;&#20026;&#22806;&#35821;&#20889;&#20316;&#25945;&#32946;&#20013;&#19968;&#31181;&#26377;&#29992;&#30340;&#24037;&#20855;&#65292;&#20026;&#23398;&#29983;&#21644;&#25945;&#24072;&#25552;&#20379;&#23454;&#26102;&#20316;&#25991;&#35780;&#20998;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;AES&#27169;&#22411;&#26159;&#22312;&#19982;EFL&#20889;&#20316;&#25945;&#32946;&#23454;&#38469;&#22330;&#26223;&#19981;&#30456;&#20851;&#30340;&#20316;&#25991;&#21644;&#20998;&#25968;&#19978;&#36827;&#34892;&#35757;&#32451;&#30340;&#65292;&#24182;&#19988;&#36890;&#24120;&#30001;&#20110;&#32570;&#20047;&#36866;&#24403;&#30340;&#25968;&#25454;&#38598;&#32780;&#25552;&#20379;&#21333;&#19968;&#30340;&#25972;&#20307;&#35780;&#20998;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;DREsS&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#33258;&#21160;&#20316;&#25991;&#35780;&#20998;&#30340;&#22823;&#22411;&#26631;&#20934;&#25968;&#25454;&#38598;&#12290;DREsS&#21253;&#25324;&#19977;&#20010;&#23376;&#25968;&#25454;&#38598;&#65306;DREsS_New&#65292;DREsS_Std.&#21644;DREsS_CASE&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;DREsS_New&#65292;&#36825;&#26159;&#19968;&#20010;&#30001;EFL&#26412;&#31185;&#29983;&#25776;&#20889;&#24182;&#30001;&#33521;&#35821;&#25945;&#32946;&#19987;&#23478;&#35780;&#20998;&#30340;&#30495;&#23454;&#35838;&#22530;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#36824;&#23558;&#29616;&#26377;&#30340;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#20316;&#25991;&#35780;&#20998;&#25968;&#25454;&#38598;&#26631;&#20934;&#21270;&#20026;DREsS_Std&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;CASE&#30340;&#22522;&#20110;&#30772;&#22351;&#30340;&#20316;&#25991;&#22686;&#24378;&#31574;&#30053;&#65292;&#29992;&#20110;&#29983;&#25104;20K&#20010;DREsS_CASE&#30340;&#21512;&#25104;&#26679;&#26412;&#65292;&#24182;&#23558;&#22522;&#32447;&#32467;&#26524;&#25552;&#39640;&#20102;45.44&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16733v1 Announce Type: new  Abstract: Automated essay scoring (AES) is a useful tool in English as a Foreign Language (EFL) writing education, offering real-time essay scores for students and instructors. However, previous AES models were trained on essays and scores irrelevant to the practical scenarios of EFL writing education and usually provided a single holistic score due to the lack of appropriate datasets. In this paper, we release DREsS, a large-scale, standard dataset for rubric-based automated essay scoring. DREsS comprises three sub-datasets: DREsS_New, DREsS_Std., and DREsS_CASE. We collect DREsS_New, a real-classroom dataset with 1.7K essays authored by EFL undergraduate students and scored by English education experts. We also standardize existing rubric-based essay scoring datasets as DREsS_Std. We suggest CASE, a corruption-based augmentation strategy for essays, which generates 20K synthetic samples of DREsS_CASE and improves the baseline results by 45.44%. 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#27169;&#24577;&#22768;&#38899;&#28151;&#21512;&#32534;&#36753;&#22120;&#65292;&#36890;&#36807;&#29992;&#25143;&#25552;&#20379;&#30340;&#25991;&#26412;&#25351;&#20196;&#23454;&#29616;&#23545;&#22768;&#38899;&#28304;&#30340;&#20462;&#25913;&#65292;&#23454;&#29616;&#20102;&#21516;&#26102;&#32534;&#36753;&#22810;&#20010;&#22768;&#38899;&#28304;&#30340;&#33021;&#21147;&#65292;&#26080;&#38656;&#23558;&#23427;&#20204;&#20998;&#31163;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#32534;&#36753;&#22120;&#30340;&#23454;&#29992;&#24615;&#21644;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.03710</link><description>&lt;p&gt;
&#21548;&#12289;&#32842;&#12289;&#32534;&#36753;&#65306;&#22522;&#20110;&#25991;&#26412;&#25351;&#23548;&#30340;&#22768;&#26223;&#20462;&#25913;&#20197;&#22686;&#24378;&#21548;&#35273;&#20307;&#39564;
&lt;/p&gt;
&lt;p&gt;
Listen, Chat, and Edit: Text-Guided Soundscape Modification for Enhanced Auditory Experience
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#27169;&#24577;&#22768;&#38899;&#28151;&#21512;&#32534;&#36753;&#22120;&#65292;&#36890;&#36807;&#29992;&#25143;&#25552;&#20379;&#30340;&#25991;&#26412;&#25351;&#20196;&#23454;&#29616;&#23545;&#22768;&#38899;&#28304;&#30340;&#20462;&#25913;&#65292;&#23454;&#29616;&#20102;&#21516;&#26102;&#32534;&#36753;&#22810;&#20010;&#22768;&#38899;&#28304;&#30340;&#33021;&#21147;&#65292;&#26080;&#38656;&#23558;&#23427;&#20204;&#20998;&#31163;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#32534;&#36753;&#22120;&#30340;&#23454;&#29992;&#24615;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#65292;&#25105;&#20204;&#36935;&#21040;&#21508;&#31181;&#21508;&#26679;&#30340;&#22768;&#38899;&#65292;&#26377;&#20123;&#26159;&#25105;&#20204;&#26399;&#26395;&#30340;&#65292;&#26377;&#20123;&#26159;&#25105;&#20204;&#19981;&#24076;&#26395;&#30340;&#65292;&#23545;&#23427;&#20204;&#30340;&#23384;&#22312;&#21644;&#38899;&#37327;&#30340;&#25511;&#21046;&#26377;&#38480;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#27169;&#24577;&#22768;&#38899;&#28151;&#21512;&#32534;&#36753;&#22120;"&#21548;&#12289;&#32842;&#12289;&#32534;&#36753;"(LCE)&#65292;&#35813;&#32534;&#36753;&#22120;&#26681;&#25454;&#29992;&#25143;&#25552;&#20379;&#30340;&#25991;&#26412;&#25351;&#20196;&#20462;&#25913;&#28151;&#21512;&#20013;&#30340;&#27599;&#20010;&#22768;&#38899;&#28304;&#12290;LCE&#36890;&#36807;&#29992;&#25143;&#21451;&#22909;&#30340;&#32842;&#22825;&#30028;&#38754;&#20197;&#21450;&#20854;&#22312;&#19981;&#38656;&#35201;&#23558;&#22768;&#38899;&#28304;&#20998;&#31163;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#23545;&#22810;&#20010;&#22768;&#38899;&#28304;&#36827;&#34892;&#32534;&#36753;&#30340;&#33021;&#21147;&#32780;&#19982;&#20247;&#19981;&#21516;&#12290;&#29992;&#25143;&#36755;&#20837;&#24320;&#25918;&#24615;&#30340;&#25991;&#26412;&#25552;&#31034;&#65292;&#36825;&#20123;&#25552;&#31034;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35299;&#37322;&#65292;&#29992;&#20110;&#21019;&#24314;&#32534;&#36753;&#22768;&#38899;&#28151;&#21512;&#30340;&#35821;&#20041;&#28388;&#27874;&#22120;&#12290;&#31995;&#32479;&#28982;&#21518;&#23558;&#28151;&#21512;&#35299;&#26512;&#25104;&#20854;&#32452;&#25104;&#37096;&#20998;&#65292;&#24212;&#29992;&#35821;&#20041;&#28388;&#27874;&#22120;&#65292;&#24182;&#23558;&#20854;&#37325;&#26032;&#32452;&#35013;&#25104;&#26399;&#26395;&#30340;&#36755;&#20986;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#25324;&#35821;&#38899;&#21644;&#21508;&#31181;&#38899;&#39057;&#28304;&#20197;&#21450;&#29992;&#20110;&#19981;&#21516;&#32534;&#36753;&#20219;&#21153;&#30340;&#25991;&#26412;&#25552;&#31034;&#30340;160&#23567;&#26102;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#25552;&#21462;&#12289;&#21024;&#38500;&#21644;&#38899;&#37327;&#25511;&#21046;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
In daily life, we encounter a variety of sounds, both desirable and undesirable, with limited control over their presence and volume. Our work introduces "Listen, Chat, and Edit" (LCE), a novel multimodal sound mixture editor that modifies each sound source in a mixture based on user-provided text instructions. LCE distinguishes itself with a user-friendly chat interface and its unique ability to edit multiple sound sources simultaneously within a mixture, without needing to separate them. Users input open-vocabulary text prompts, which are interpreted by a large language model to create a semantic filter for editing the sound mixture. The system then decomposes the mixture into its components, applies the semantic filter, and reassembles it into the desired output. We developed a 160-hour dataset with over 100k mixtures, including speech and various audio sources, along with text prompts for diverse editing tasks like extraction, removal, and volume control. Our experiments demonstrat
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#23646;&#24615;&#24863;&#30693;&#30340;&#22810;&#27169;&#24577;&#23454;&#20307;&#38142;&#25509;&#26041;&#27861;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;AMELI&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#23558;&#23646;&#24615;&#20449;&#24687;&#32435;&#20837;&#23454;&#20307;&#38142;&#25509;&#36807;&#31243;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14725</link><description>&lt;p&gt;
AMELI:&#32454;&#31890;&#24230;&#23646;&#24615;&#22686;&#24378;&#22810;&#27169;&#24577;&#23454;&#20307;&#38142;&#25509;
&lt;/p&gt;
&lt;p&gt;
AMELI: Enhancing Multimodal Entity Linking with Fine-Grained Attributes. (arXiv:2305.14725v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14725
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#23646;&#24615;&#24863;&#30693;&#30340;&#22810;&#27169;&#24577;&#23454;&#20307;&#38142;&#25509;&#26041;&#27861;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;AMELI&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#23558;&#23646;&#24615;&#20449;&#24687;&#32435;&#20837;&#23454;&#20307;&#38142;&#25509;&#36807;&#31243;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23646;&#24615;&#24863;&#30693;&#30340;&#22810;&#27169;&#24577;&#23454;&#20307;&#38142;&#25509;&#26041;&#27861;&#65292;&#20854;&#20013;&#36755;&#20837;&#26159;&#19968;&#20010;&#30001;&#25991;&#26412;&#21644;&#22270;&#20687;&#25551;&#36848;&#30340;&#25552;&#21450;&#65292;&#30446;&#26631;&#26159;&#20174;&#19968;&#20010;&#22810;&#27169;&#24577;&#30693;&#35782;&#24211;&#20013;&#39044;&#27979;&#30456;&#24212;&#30340;&#30446;&#26631;&#23454;&#20307;&#65292;&#20854;&#20013;&#27599;&#20010;&#23454;&#20307;&#37117;&#26159;&#29992;&#25991;&#26412;&#25551;&#36848;&#12289;&#35270;&#35273;&#22270;&#20687;&#21644;&#19968;&#32452;&#23646;&#24615;&#20540;&#25551;&#36848;&#30340;&#12290;&#20026;&#20102;&#25903;&#25345;&#36825;&#39033;&#30740;&#31350;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;AMELI&#65292;&#20854;&#20013;&#21253;&#21547;18,472&#20010;&#35780;&#35770;&#21644;35,598&#20010;&#20135;&#21697;&#12290;&#25105;&#20204;&#22312;AMELI&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#20351;&#29992;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22810;&#27169;&#24577;&#23454;&#20307;&#38142;&#25509;&#26041;&#27861;&#21644;&#25105;&#20204;&#22686;&#24378;&#30340;&#23646;&#24615;&#24863;&#30693;&#27169;&#22411;&#26469;&#24314;&#31435;&#22522;&#20934;&#24615;&#33021;&#65292;&#24182;&#23637;&#31034;&#20102;&#23558;&#23646;&#24615;&#20449;&#24687;&#32435;&#20837;&#23454;&#20307;&#38142;&#25509;&#36807;&#31243;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#26159;&#31532;&#19968;&#20010;&#20026;&#23646;&#24615;&#24863;&#30693;&#22810;&#27169;&#24577;&#23454;&#20307;&#38142;&#25509;&#20219;&#21153;&#24314;&#31435;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#35299;&#20915;&#26041;&#26696;&#30340;&#22242;&#38431;&#12290;&#25968;&#25454;&#38598;&#21644;&#20195;&#30721;&#23558;&#20844;&#24320;&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose attribute-aware multimodal entity linking, where the input is a mention described with a text and image, and the goal is to predict the corresponding target entity from a multimodal knowledge base (KB) where each entity is also described with a text description, a visual image and a set of attributes and values. To support this research, we construct AMELI, a large-scale dataset consisting of 18,472 reviews and 35,598 products. To establish baseline performance on AMELI, we experiment with the current state-of-the-art multimodal entity linking approaches and our enhanced attribute-aware model and demonstrate the importance of incorporating the attribute information into the entity linking process. To be best of our knowledge, we are the first to build benchmark dataset and solutions for the attribute-aware multimodal entity linking task. Datasets and codes will be made publicly available.
&lt;/p&gt;</description></item></channel></rss>