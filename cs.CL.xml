<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>ALTO&#26159;&#19968;&#20010;&#32593;&#32476;&#32534;&#25490;&#22120;&#65292;&#38024;&#23545;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#26426;&#20250;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.04311</link><description>&lt;p&gt;
ALTO&#65306;&#19968;&#31181;&#29992;&#20110;&#22797;&#21512;AI&#31995;&#32479;&#30340;&#39640;&#25928;&#32593;&#32476;&#32534;&#25490;&#22120;
&lt;/p&gt;
&lt;p&gt;
ALTO: An Efficient Network Orchestrator for Compound AI Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04311
&lt;/p&gt;
&lt;p&gt;
ALTO&#26159;&#19968;&#20010;&#32593;&#32476;&#32534;&#25490;&#22120;&#65292;&#38024;&#23545;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#26426;&#20250;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ALTO&#65292;&#19968;&#31181;&#29992;&#20110;&#26377;&#25928;&#20026;&#35832;&#22914;&#35821;&#35328;&#27169;&#22411;&#31649;&#36947;&#20043;&#31867;&#30340;&#22797;&#21512;AI&#31995;&#32479;&#25552;&#20379;&#26381;&#21153;&#30340;&#32593;&#32476;&#32534;&#25490;&#22120;&#12290;ALTO&#36890;&#36807;&#21033;&#29992;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#29305;&#26377;&#30340;&#20248;&#21270;&#26426;&#20250;&#65306;&#27969;&#24335;&#20013;&#38388;&#36755;&#20986;&#65292;&#23454;&#29616;&#20102;&#39640;&#21534;&#21520;&#37327;&#21644;&#20302;&#24310;&#36831;&#12290;&#30001;&#20110;&#35821;&#35328;&#27169;&#22411;&#36880;&#20010;&#29983;&#25104;token&#30340;&#36755;&#20986;&#65292;ALTO&#22312;&#21487;&#33021;&#26102;&#26292;&#38706;&#20102;&#22312;&#38454;&#27573;&#20043;&#38388;&#27969;&#24335;&#20256;&#36755;&#20013;&#38388;&#36755;&#20986;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#22312;&#36328;&#20998;&#24067;&#24335;&#31649;&#36947;&#38454;&#27573;&#23454;&#20363;&#20043;&#38388;&#27969;&#24335;&#20256;&#36755;&#20013;&#38388;&#25968;&#25454;&#26102;&#20986;&#29616;&#30340;&#20004;&#20010;&#26032;&#25361;&#25112;&#65306;&#27491;&#30830;&#24615;&#21644;&#36127;&#36733;&#24179;&#34913;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#32858;&#21512;&#24863;&#30693;&#36335;&#30001;&#25509;&#21475;&#21644;&#20998;&#24067;&#24335;&#25552;&#31034;&#24863;&#30693;&#35843;&#24230;&#20197;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#22797;&#26434;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#39564;&#35777;&#31649;&#36947;&#19978;&#23637;&#31034;&#20102;ALTO&#37096;&#20998;&#36755;&#20986;&#27969;&#24335;&#20256;&#36755;&#30340;&#24433;&#21709;&#65292;&#23558;&#21534;&#21520;&#37327;&#25552;&#39640;&#20102;&#26368;&#22810;3&#20493;&#65292;&#21516;&#26102;&#23558;&#22266;&#23450;&#24310;&#36831;&#30446;&#26631;&#35774;&#32622;&#20026;4&#31186;/&#35831;&#27714;&#65292;&#36824;&#20943;&#23569;&#20102;&#23614;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04311v1 Announce Type: new  Abstract: We present ALTO, a network orchestrator for efficiently serving compound AI systems such as pipelines of language models. ALTO achieves high throughput and low latency by taking advantage of an optimization opportunity specific to generative language models: streaming intermediate outputs. As language models produce outputs token by token, ALTO exposes opportunities to stream intermediate outputs between stages when possible. We highlight two new challenges of correctness and load balancing which emerge when streaming intermediate data across distributed pipeline stage instances. We also motivate the need for an aggregation-aware routing interface and distributed prompt-aware scheduling to address these challenges. We demonstrate the impact of ALTO's partial output streaming on a complex chatbot verification pipeline, increasing throughput by up to 3x for a fixed latency target of 4 seconds / request while also reducing tail latency by 1
&lt;/p&gt;</description></item><item><title>AQA-Bench&#26159;&#19968;&#20010;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#30740;&#31350;&#21457;&#29616;&#38381;&#28304;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26174;&#33879;&#20248;&#20110;&#24320;&#28304;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.09404</link><description>&lt;p&gt;
AQA-Bench&#65306;&#35780;&#20272;LLM&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#30340;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09404
&lt;/p&gt;
&lt;p&gt;
AQA-Bench&#26159;&#19968;&#20010;&#20132;&#20114;&#24335;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#30740;&#31350;&#21457;&#29616;&#38381;&#28304;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26174;&#33879;&#20248;&#20110;&#24320;&#28304;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;AQA-Bench&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31639;&#27861;&#19978;&#19979;&#25991;&#20013;&#65292;&#22914;&#28145;&#24230;&#20248;&#20808;&#25628;&#32034;&#65288;DFS&#65289;&#31561;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#35780;&#20272;&#22522;&#20934;&#27979;&#35797;&#30340;&#20851;&#38190;&#29305;&#28857;&#22312;&#20110;&#20854;&#20132;&#20114;&#24335;&#35780;&#20272;&#21327;&#35758;-&#20363;&#22914;&#65292;&#22312;DFS&#20013;&#65292;&#27599;&#20010;&#33410;&#28857;&#30340;&#21487;&#29992;&#36830;&#25509;&#36793;&#21462;&#20915;&#20110;&#27169;&#22411;&#23545;&#35813;&#33410;&#28857;&#30340;&#36941;&#21382;&#65292;&#22240;&#27492;&#38656;&#35201;LLM&#26377;&#25928;&#22320;&#35760;&#20303;&#24050;&#35775;&#38382;&#33410;&#28857;&#24182;&#31574;&#21010;&#21518;&#32493;&#31227;&#21160;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#20351;&#29992;&#19977;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#26500;&#24314;&#20102;AQA-Bench&#65292;&#20998;&#21035;&#26159;&#20108;&#20998;&#25628;&#32034;&#65292;&#28145;&#24230;&#20248;&#20808;&#25628;&#32034;&#21644;&#24191;&#24230;&#20248;&#20808;&#25628;&#32034;&#65292;&#24182;&#35780;&#20272;&#20102;12&#31181;&#19981;&#21516;&#30340;LLMs&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#25581;&#31034;&#20102;&#19968;&#20123;&#26377;&#36259;&#30340;&#21457;&#29616;&#65306;&#65288;1&#65289;&#31867;&#20284;GPT-4&#21644;Gemini&#31561;&#38381;&#28304;&#27169;&#22411;&#36890;&#24120;&#26174;&#31034;&#20986;&#24378;&#22823;&#30340;&#39034;&#24207;&#25512;&#29702;&#33021;&#21147;&#65292;&#26126;&#26174;&#20248;&#20110;&#24320;&#28304;LLMs&#12290;&#65288;2&#65289;&#22825;&#30495;&#22320;&#25552;&#20379;&#20114;&#25805;&#20316;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09404v1 Announce Type: cross Abstract: This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol -- for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 12 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show strong sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing inter
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#25552;&#39640;&#23398;&#26415;&#20889;&#20316;&#36136;&#37327;&#21644;&#25928;&#29575;&#30340;&#21407;&#21017;&#21644;&#26041;&#27861;&#65292;&#21253;&#25324;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#26694;&#26550;&#12289;&#26377;&#25928;&#30340;&#25552;&#31034;&#25216;&#26415;&#21644;&#20004;&#38454;&#27573;&#27169;&#22411;&#65292;&#26088;&#22312;&#23454;&#29616;&#35748;&#30693;&#21368;&#36733;&#21644;&#24819;&#35937;&#21050;&#28608;&#30340;AI&#36741;&#21161;&#20889;&#20316;&#12290;</title><link>http://arxiv.org/abs/2310.17143</link><description>&lt;p&gt;
&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#25512;&#21160;&#23398;&#26415;&#20889;&#20316;&#65306;&#26694;&#26550;&#12289;&#25216;&#26415;&#21644;&#27880;&#24847;&#20107;&#39033;
&lt;/p&gt;
&lt;p&gt;
Supercharging academic writing with generative AI: framework, techniques, and caveats. (arXiv:2310.17143v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17143
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#25552;&#39640;&#23398;&#26415;&#20889;&#20316;&#36136;&#37327;&#21644;&#25928;&#29575;&#30340;&#21407;&#21017;&#21644;&#26041;&#27861;&#65292;&#21253;&#25324;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#26694;&#26550;&#12289;&#26377;&#25928;&#30340;&#25552;&#31034;&#25216;&#26415;&#21644;&#20004;&#38454;&#27573;&#27169;&#22411;&#65292;&#26088;&#22312;&#23454;&#29616;&#35748;&#30693;&#21368;&#36733;&#21644;&#24819;&#35937;&#21050;&#28608;&#30340;AI&#36741;&#21161;&#20889;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#26415;&#20889;&#20316;&#26159;&#30740;&#31350;&#39033;&#30446;&#20013;&#19981;&#21487;&#25110;&#32570;&#20294;&#36153;&#26102;&#36153;&#21147;&#30340;&#37096;&#20998;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25552;&#39640;&#23398;&#26415;&#20889;&#20316;&#36136;&#37327;&#21644;&#25928;&#29575;&#30340;&#21407;&#21017;&#21644;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#26694;&#26550;&#65292;&#35814;&#32454;&#38416;&#36848;&#20102;AI&#22312;&#20889;&#20316;&#20013;&#30340;&#29702;&#35770;&#22522;&#30784;&#65288;&#20026;&#20160;&#20040;&#65289;&#12289;&#36807;&#31243;&#65288;&#22914;&#20309;&#65289;&#21644;&#24615;&#36136;&#65288;&#20160;&#20040;&#65289;&#12290;&#35813;&#26694;&#26550;&#25351;&#20986;&#20102;&#30701;&#26399;&#21644;&#38271;&#26399;&#21442;&#19982;AI&#20889;&#20316;&#30340;&#21407;&#22240;&#21450;&#20854;&#22522;&#26412;&#26426;&#21046;&#65288;&#22914;&#35748;&#30693;&#21368;&#36733;&#21644;&#24819;&#35937;&#21050;&#28608;&#65289;&#12290;&#23427;&#25581;&#31034;&#20102;AI&#22312;&#25972;&#20010;&#20889;&#20316;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#65292;&#36890;&#36807;&#19968;&#20010;&#20154;&#26426;&#21327;&#20316;&#20889;&#20316;&#30340;&#20004;&#38454;&#27573;&#27169;&#22411;&#21644;&#20889;&#20316;&#36741;&#21161;&#31867;&#22411;&#21644;&#32423;&#21035;&#30340;&#27169;&#22411;&#34920;&#31034;&#20102;AI&#22312;&#20889;&#20316;&#20013;&#30340;&#24110;&#21161;&#26041;&#24335;&#12290;&#22522;&#20110;&#35813;&#26694;&#26550;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#22312;&#20889;&#20316;&#24120;&#35268;&#20013;&#25972;&#21512;AI&#30340;&#26377;&#25928;&#25552;&#31034;&#25216;&#26415;&#65288;&#22823;&#32434;&#12289;&#36215;&#33609;&#21644;&#32534;&#36753;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Academic writing is an indispensable yet laborious part of the research enterprise. This Perspective maps out principles and methods for using generative artificial intelligence (AI), specifically large language models (LLMs), to elevate the quality and efficiency of academic writing. We introduce a human-AI collaborative framework that delineates the rationale (why), process (how), and nature (what) of AI engagement in writing. The framework pinpoints both short-term and long-term reasons for engagement and their underlying mechanisms (e.g., cognitive offloading and imaginative stimulation). It reveals the role of AI throughout the writing process, conceptualized through a two-stage model for human-AI collaborative writing, and the nature of AI assistance in writing, represented through a model of writing-assistance types and levels. Building on this framework, we describe effective prompting techniques for incorporating AI into the writing routine (outlining, drafting, and editing) a
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;AI&#23398;&#26415;&#30028;&#30340;78K&#30740;&#31350;&#20154;&#21592;&#30340;&#20998;&#26512;&#65292;&#30740;&#31350;&#21457;&#29616;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#20855;&#26377;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#65307;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#12290;&#25105;&#20204;&#40723;&#21169;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14597</link><description>&lt;p&gt;
&#22905;&#20204;&#30340;&#22768;&#38899;&#65306;&#20998;&#26512;&#20154;&#24037;&#26234;&#33021;&#20986;&#29256;&#39046;&#22495;&#30340;&#24615;&#21035;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Voices of Her: Analyzing Gender Differences in the AI Publication World. (arXiv:2305.14597v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14597
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;AI&#23398;&#26415;&#30028;&#30340;78K&#30740;&#31350;&#20154;&#21592;&#30340;&#20998;&#26512;&#65292;&#30740;&#31350;&#21457;&#29616;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#20855;&#26377;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#65307;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#12290;&#25105;&#20204;&#40723;&#21169;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#20998;&#26512;&#20102;&#23398;&#26415;&#30028;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#65292;&#20294;&#26159;&#25105;&#20204;&#20173;&#28982;&#32570;&#20047;&#19968;&#20010;&#20840;&#38754;&#30340;&#20154;&#24037;&#26234;&#33021;&#31038;&#21306;&#24615;&#21035;&#24046;&#24322;&#30340;&#20998;&#26512;&#65292;&#28085;&#30422;&#21508;&#31181;&#20027;&#39064;&#21644;&#19981;&#21516;&#30340;&#21457;&#23637;&#36235;&#21183;&#12290;&#25105;&#20204;&#20351;&#29992;AI Scholar&#25968;&#25454;&#38598;&#20013;&#30340;78K&#20301;AI&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#24615;&#21035;&#24046;&#24322;&#65306;&#65288;1&#65289;&#34429;&#28982;&#22899;&#24615;&#30740;&#31350;&#20154;&#21592;&#30340;&#24635;&#24341;&#29992;&#27425;&#25968;&#27604;&#30007;&#24615;&#23569;&#65292;&#20294;&#36825;&#31181;&#24341;&#29992;&#24046;&#24322;&#24182;&#19981;&#36866;&#29992;&#20110;&#25152;&#26377;&#23398;&#26415;&#24180;&#40836;&#32452;&#65307;&#65288;2&#65289;&#22312;AI&#35770;&#25991;&#30340;&#21512;&#33879;&#20013;&#23384;&#22312;&#24456;&#22823;&#30340;&#24615;&#21035;&#21516;&#36136;&#24615;&#65307;&#65288;3&#65289;&#22899;&#24615;&#31532;&#19968;&#20316;&#32773;&#30340;&#35770;&#25991;&#26174;&#31034;&#20986;&#19981;&#21516;&#30340;&#35821;&#35328;&#39118;&#26684;&#65292;&#20363;&#22914;&#26356;&#38271;&#30340;&#25991;&#26412;&#12289;&#26356;&#22810;&#30340;&#27491;&#38754;&#24773;&#24863;&#35789;&#27719;&#21644;&#26356;&#24341;&#20154;&#27880;&#30446;&#30340;&#26631;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20026;&#25105;&#20204;&#30340;AI&#31038;&#21306;&#29616;&#26377;&#30340;&#20154;&#21475;&#32479;&#35745;&#36235;&#21183;&#25552;&#20379;&#20102;&#19968;&#20010;&#31383;&#21475;&#65292;&#24182;&#40723;&#21169;&#22312;&#26410;&#26469;&#23454;&#29616;&#26356;&#22810;&#30340;&#24615;&#21035;&#24179;&#31561;&#21644;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#21487;&#22312;https://github.com/causalNLP/ai-scholar-gender&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
While several previous studies have analyzed gender bias in research, we are still missing a comprehensive analysis of gender differences in the AI community, covering diverse topics and different development trends. Using the AI Scholar dataset of 78K researchers in the field of AI, we identify several gender differences: (1) Although female researchers tend to have fewer overall citations than males, this citation difference does not hold for all academic-age groups; (2) There exist large gender homophily in co-authorship on AI papers; (3) Female first-authored papers show distinct linguistic styles, such as longer text, more positive emotion words, and more catchy titles than male first-authored papers. Our analysis provides a window into the current demographic trends in our AI community, and encourages more gender equality and diversity in the future. Our code and data are at https://github.com/causalNLP/ai-scholar-gender.
&lt;/p&gt;</description></item></channel></rss>