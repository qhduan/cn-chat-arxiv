<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#23558;&#24418;&#24577;&#32032;&#20998;&#21106;&#20219;&#21153;&#37325;&#26032;&#23450;&#20041;&#20026;&#24207;&#21015;&#21040;&#24207;&#21015;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#22810;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20986;&#20248;&#24322;&#24615;&#33021;&#65292;&#25581;&#31034;&#20102;&#39640;&#36164;&#28304;&#35821;&#35328;&#29615;&#22659;&#19979;&#30340;&#21487;&#27604;&#25928;&#21147;&#65292;&#20197;&#21450;&#20302;&#36164;&#28304;&#35821;&#35328;&#22330;&#26223;&#19979;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.15436</link><description>&lt;p&gt;
&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#36827;&#34892;&#21477;&#23376;&#32423;&#24418;&#24577;&#32032;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
Using Contextual Information for Sentence-level Morpheme Segmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15436
&lt;/p&gt;
&lt;p&gt;
&#23558;&#24418;&#24577;&#32032;&#20998;&#21106;&#20219;&#21153;&#37325;&#26032;&#23450;&#20041;&#20026;&#24207;&#21015;&#21040;&#24207;&#21015;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#22810;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20986;&#20248;&#24322;&#24615;&#33021;&#65292;&#25581;&#31034;&#20102;&#39640;&#36164;&#28304;&#35821;&#35328;&#29615;&#22659;&#19979;&#30340;&#21487;&#27604;&#25928;&#21147;&#65292;&#20197;&#21450;&#20302;&#36164;&#28304;&#35821;&#35328;&#22330;&#26223;&#19979;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#24418;&#24577;&#32032;&#20998;&#21106;&#30340;&#21457;&#23637;&#20027;&#35201;&#24378;&#35843;&#21333;&#35789;&#32423;&#21035;&#30340;&#20998;&#21106;&#65292;&#36890;&#24120;&#24573;&#35270;&#20102;&#21477;&#23376;&#20869;&#30340;&#19978;&#19979;&#25991;&#30456;&#20851;&#24615;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#24418;&#24577;&#32032;&#20998;&#21106;&#20219;&#21153;&#37325;&#26032;&#23450;&#20041;&#20026;&#19968;&#20010;&#24207;&#21015;&#21040;&#24207;&#21015;&#30340;&#38382;&#39064;&#65292;&#23558;&#25972;&#20010;&#21477;&#23376;&#20316;&#20026;&#36755;&#20837;&#65292;&#32780;&#19981;&#26159;&#23396;&#31435;&#22320;&#22788;&#29702;&#21333;&#20010;&#21333;&#35789;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22810;&#35821;&#35328;&#27169;&#22411;&#19982;&#21333;&#35821;&#27169;&#22411;&#30456;&#27604;&#22987;&#32456;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#24615;&#33021;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#27169;&#22411;&#27809;&#26377;&#36229;&#36234;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#65292;&#20294;&#22312;&#39640;&#36164;&#28304;&#35821;&#35328;&#20013;&#23637;&#29616;&#20986;&#21487;&#27604;&#36739;&#30340;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#22330;&#26223;&#20013;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15436v1 Announce Type: new  Abstract: Recent advancements in morpheme segmentation primarily emphasize word-level segmentation, often neglecting the contextual relevance within the sentence. In this study, we redefine the morpheme segmentation task as a sequence-to-sequence problem, treating the entire sentence as input rather than isolating individual words. Our findings reveal that the multilingual model consistently exhibits superior performance compared to monolingual counterparts. While our model did not surpass the performance of the current state-of-the-art, it demonstrated comparable efficacy with high-resource languages while revealing limitations in low-resource language scenarios.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#22240;&#26524;&#24341;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#21069;&#38376;&#35843;&#25972;&#26377;&#25928;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2403.02738</link><description>&lt;p&gt;
&#22240;&#26524;&#24341;&#23548;&#65306;&#22522;&#20110;&#21069;&#38376;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21551;&#21457;&#24335;&#21435;&#20559;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02738
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#22240;&#26524;&#24341;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#21069;&#38376;&#35843;&#25972;&#26377;&#25928;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#29616;&#26377;&#30340;&#35832;&#22914;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#24605;&#32500;&#38142;&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21551;&#21457;&#24335;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#23601;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#38754;&#20020;&#21508;&#31181;&#20559;&#35265;&#25361;&#25112;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#21551;&#21457;&#24335;&#26041;&#27861;&#32972;&#21518;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21069;&#38376;&#35843;&#25972;&#30340;&#26032;&#22411;&#22240;&#26524;&#24341;&#23548;&#26041;&#27861;&#65292;&#20197;&#26377;&#25928;&#20943;&#36731;LLMs&#30340;&#20559;&#35265;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#35774;&#35745;&#25552;&#31034;&#32780;&#26080;&#38656;&#35775;&#38382;LLMs&#30340;&#21442;&#25968;&#21644;logit&#26469;&#23454;&#26045;&#22240;&#26524;&#24178;&#39044;&#12290;&#30001;LLMs&#29983;&#25104;&#30340;&#24605;&#32500;&#38142;&#34987;&#29992;&#20316;&#20013;&#20171;&#21464;&#37327;&#65292;&#36890;&#36807;&#21069;&#38376;&#35745;&#31639;&#36755;&#20837;&#25552;&#31034;&#19982;&#36755;&#20986;&#31572;&#26696;&#20043;&#38388;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02738v1 Announce Type: new  Abstract: Despite the significant achievements of existing prompting methods such as in-context learning and chain-of-thought for large language models (LLMs), they still face challenges of various biases. Traditional debiasing methods primarily focus on the model training stage, including data augmentation-based and reweight-based approaches, with the limitations of addressing the complex biases of LLMs. To address such limitations, the causal relationship behind the prompting methods is uncovered using a structural causal model, and a novel causal prompting method based on front-door adjustment is proposed to effectively mitigate the bias of LLMs. In specific, causal intervention is implemented by designing the prompts without accessing the parameters and logits of LLMs.The chain-of-thoughts generated by LLMs are employed as the mediator variable and the causal effect between the input prompt and the output answers is calculated through front-do
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26816;&#32034;&#33719;&#21462;&#30340;Web&#26469;&#28304;&#20449;&#24687;&#65292;&#20026;&#26032;&#20852;&#20107;&#20214;&#29983;&#25104;&#32467;&#26500;&#21270;&#30340;&#20840;&#38271;&#32500;&#22522;&#30334;&#31185;&#25991;&#26723;&#65292;&#36991;&#20813;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#26368;&#36817;&#21457;&#29983;&#20107;&#20214;&#30456;&#20851;&#30340;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>https://arxiv.org/abs/2402.18264</link><description>&lt;p&gt;
&#22522;&#20110;&#26816;&#32034;&#30340;&#24212;&#24613;&#20107;&#20214;&#20840;&#38271;&#32500;&#22522;&#30334;&#31185;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Retrieval-based Full-length Wikipedia Generation for Emergent Events
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18264
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26816;&#32034;&#33719;&#21462;&#30340;Web&#26469;&#28304;&#20449;&#24687;&#65292;&#20026;&#26032;&#20852;&#20107;&#20214;&#29983;&#25104;&#32467;&#26500;&#21270;&#30340;&#20840;&#38271;&#32500;&#22522;&#30334;&#31185;&#25991;&#26723;&#65292;&#36991;&#20813;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19982;&#26368;&#36817;&#21457;&#29983;&#20107;&#20214;&#30456;&#20851;&#30340;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20170;&#24555;&#33410;&#22863;&#30340;&#19990;&#30028;&#20013;&#65292;&#36805;&#36895;&#29983;&#25104;&#26032;&#20852;&#20107;&#20214;&#20840;&#38754;&#20934;&#30830;&#30340;&#32500;&#22522;&#30334;&#31185;&#25991;&#26723;&#30340;&#38656;&#27714;&#26085;&#30410;&#37325;&#35201;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#32500;&#22522;&#30334;&#31185;&#29983;&#25104;&#24037;&#20316;&#24448;&#24448;&#26410;&#33021;&#28385;&#36275;&#29616;&#23454;&#38656;&#27714;&#12290;&#19968;&#20123;&#26041;&#27861;&#20165;&#19987;&#27880;&#20110;&#29983;&#25104;&#23436;&#25972;&#32500;&#22522;&#30334;&#31185;&#25991;&#26723;&#30340;&#37096;&#20998;&#20869;&#23481;&#65292;&#32780;&#21478;&#19968;&#20123;&#21017;&#24573;&#35270;&#20102;&#29983;&#25104;&#36807;&#31243;&#20013;&#24544;&#23454;&#24615;&#30340;&#37325;&#35201;&#24615;&#65292;&#25110;&#26410;&#32771;&#34385;&#39044;&#35757;&#32451;&#35821;&#26009;&#24211;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27169;&#25311;&#20102;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#65292;&#20351;&#29992;&#20174;&#32593;&#39029;&#26469;&#28304;&#26816;&#32034;&#30340;&#20869;&#23481;&#20026;&#26032;&#20852;&#20107;&#20214;&#29983;&#25104;&#32467;&#26500;&#21270;&#30340;&#20840;&#38271;&#32500;&#22522;&#30334;&#31185;&#25991;&#26723;&#12290;&#20026;&#30830;&#20445;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26410;&#32463;&#36807;&#22522;&#20110;&#26368;&#36817;&#21457;&#29983;&#20107;&#20214;&#30340;&#35821;&#26009;&#24211;&#35757;&#32451;&#65292;&#25105;&#20204;&#36873;&#25321;&#26368;&#36817;&#21457;&#29983;&#30340;&#20107;&#20214;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934; Wiki-GenBen&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;309&#20010;&#20107;&#20214;&#21450;&#20854;&#23545;&#24212;&#30340;&#26816;&#32034;&#21040;&#30340;&#32593;&#39029;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18264v1 Announce Type: new  Abstract: In today's fast-paced world, the growing demand to quickly generate comprehensive and accurate Wikipedia documents for emerging events is both crucial and challenging. However, previous efforts in Wikipedia generation have often fallen short of meeting real-world requirements. Some approaches focus solely on generating segments of a complete Wikipedia document, while others overlook the importance of faithfulness in generation or fail to consider the influence of the pre-training corpus. In this paper, we simulate a real-world scenario where structured full-length Wikipedia documents are generated for emergent events using input retrieved from web sources. To ensure that Large Language Models (LLMs) are not trained on corpora related to recently occurred events, we select events that have taken place recently and introduce a new benchmark Wiki-GenBen, which consists of 309 events paired with their corresponding retrieved web pages for ge
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LlamaIT&#30340;&#22522;&#20110;&#25552;&#31034;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#39046;&#22495;&#29305;&#23450;&#26426;&#22120;&#32763;&#35793;&#20219;&#21153;&#65292;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#39046;&#22495;&#29305;&#23450;&#26426;&#22120;&#32763;&#35793;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.15061</link><description>&lt;p&gt;
&#38024;&#23545;&#39046;&#22495;&#29305;&#23450;&#26426;&#22120;&#32763;&#35793;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning Large Language Models for Domain-specific Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15061
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LlamaIT&#30340;&#22522;&#20110;&#25552;&#31034;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#39046;&#22495;&#29305;&#23450;&#26426;&#22120;&#32763;&#35793;&#20219;&#21153;&#65292;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#39046;&#22495;&#29305;&#23450;&#26426;&#22120;&#32763;&#35793;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#26426;&#22120;&#32763;&#35793;&#65288;MT&#65289;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#39046;&#22495;&#29305;&#23450;MT&#20013;&#30340;&#28508;&#21147;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#24403;&#21069;&#22522;&#20110;LLMs&#30340;MT&#31995;&#32479;&#20173;&#28982;&#38754;&#20020;&#19968;&#20123;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LlamaIT&#30340;&#22522;&#20110;&#25552;&#31034;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#20197;&#26377;&#25928;&#39640;&#25928;&#22320;&#20026;&#39046;&#22495;&#29305;&#23450;MT&#20219;&#21153;&#24494;&#35843;&#36890;&#29992;LLM&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15061v1 Announce Type: new  Abstract: Large language models (LLMs) have made significant progress in machine translation (MT). However, their potential in domain-specific MT remains under-explored. Current LLM-based MT systems still face several challenges. First, for LLMs with in-context learning, their effectiveness is highly sensitive to input translation examples, and processing them can increase inference costs. They often require extra post-processing due to over-generation. Second, LLMs with fine-tuning on domain-specific data often require high training costs for domain adaptation, and may weaken the zero-shot MT capabilities of LLMs due to over-specialization. The aforementioned methods can struggle to translate rare words in domain transfer scenarios. To address these challenges, this paper proposes a prompt-oriented fine-tuning method, denoted as LlamaIT, to effectively and efficiently fine-tune a general-purpose LLM for domain-specific MT tasks. First, we constru
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22522;&#20110;&#35838;&#31243;&#30340;&#27491;&#26080;&#26631;&#35760;&#23398;&#20064; CuPUL &#26041;&#27861;&#65292;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#22024;&#26434;&#26631;&#31614;&#30340;&#24433;&#21709;&#65292;&#32988;&#36807;&#29616;&#26377;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.14948</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#36828;&#31243;&#30417;&#30563;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65306;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#21644;&#31616;&#21333;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Re-Examine Distantly Supervised NER: A New Benchmark and a Simple Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14948
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22522;&#20110;&#35838;&#31243;&#30340;&#27491;&#26080;&#26631;&#35760;&#23398;&#20064; CuPUL &#26041;&#27861;&#65292;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#22024;&#26434;&#26631;&#31614;&#30340;&#24433;&#21709;&#65292;&#32988;&#36807;&#29616;&#26377;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#22312;&#36828;&#31243;&#30417;&#30563;&#65288;DS-NER&#65289;&#26694;&#26550;&#19979;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#65292;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#26631;&#31614;&#36136;&#37327;&#21463;&#21040;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#22914;&#20551;&#38451;&#24615;&#12289;&#20551;&#38452;&#24615;&#21644;&#27491;&#21521;&#31867;&#22411;&#38169;&#35823;&#12290;&#25105;&#20204;&#25209;&#21028;&#24615;&#22320;&#35780;&#20272;&#20102;&#24403;&#21069;DS-NER&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#20351;&#29992;&#20102;&#19968;&#20010;&#21517;&#20026;QTL&#30340;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#25581;&#31034;&#23427;&#20204;&#30340;&#24615;&#33021;&#24448;&#24448;&#19981;&#31526;&#21512;&#39044;&#26399;&#12290;&#20026;&#20102;&#35299;&#20915;&#26631;&#31614;&#22122;&#22768;&#26222;&#36941;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#35838;&#31243;&#30340;&#27491;&#26080;&#26631;&#35760;&#23398;&#20064;&#65288;CuPUL&#65289;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#31574;&#30053;&#24615;&#22320;&#20174;&#8220;&#26131;&#8221;&#21644;&#26356;&#28165;&#27905;&#30340;&#26679;&#26412;&#24320;&#22987;&#65292;&#20197;&#22686;&#24378;&#27169;&#22411;&#23545;&#22024;&#26434;&#26679;&#26412;&#30340;&#38887;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#31361;&#20986;&#20102;CuPUL&#20943;&#23569;&#22024;&#26434;&#26631;&#31614;&#24433;&#21709;&#24182;&#32988;&#36807;&#29616;&#26377;&#26041;&#27861;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14948v1 Announce Type: new  Abstract: This paper delves into Named Entity Recognition (NER) under the framework of Distant Supervision (DS-NER), where the main challenge lies in the compromised quality of labels due to inherent errors such as false positives, false negatives, and positive type errors. We critically assess the efficacy of current DS-NER methodologies using a real-world benchmark dataset named QTL, revealing that their performance often does not meet expectations. To tackle the prevalent issue of label noise, we introduce a simple yet effective approach, Curriculum-based Positive-Unlabeled Learning CuPUL, which strategically starts on "easy" and cleaner samples during the training process to enhance model resilience to noisy samples. Our empirical results highlight the capability of CuPUL to significantly reduce the impact of noisy labels and outperform existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21518;&#38376;&#25915;&#20987;&#22330;&#26223;&#65292;&#25915;&#20987;&#32773;&#36890;&#36807;&#21033;&#29992;&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#30340;&#35821;&#27861;&#38169;&#35823;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#65292;&#20197;&#31192;&#23494;&#20256;&#25773;&#23450;&#21521;&#38169;&#35823;&#20449;&#24687;&#65292;&#22914;&#20167;&#24680;&#35328;&#35770;&#25110;&#24191;&#21578;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#25915;&#20987;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#38544;&#21311;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13532</link><description>&lt;p&gt;
&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#22120;&#29992;&#20110;&#20256;&#25773;&#20449;&#24687;&#38169;&#35823;&#30340;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21518;&#38376;&#25915;&#20987;&#22330;&#26223;&#65292;&#25915;&#20987;&#32773;&#36890;&#36807;&#21033;&#29992;&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#30340;&#35821;&#27861;&#38169;&#35823;&#35302;&#21457;&#21518;&#38376;&#25915;&#20987;&#65292;&#20197;&#31192;&#23494;&#20256;&#25773;&#23450;&#21521;&#38169;&#35823;&#20449;&#24687;&#65292;&#22914;&#20167;&#24680;&#35328;&#35770;&#25110;&#24191;&#21578;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#25915;&#20987;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#38544;&#21311;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#26816;&#32034;&#22120;&#21644;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#24050;&#24191;&#27867;&#29992;&#20110;&#21508;&#31181;NLP&#24212;&#29992;&#65292;&#23613;&#31649;&#35774;&#35745;&#29992;&#20110;&#25552;&#20379;&#21487;&#38752;&#21644;&#23433;&#20840;&#30340;&#32467;&#26524;&#65292;&#20294;&#26816;&#32034;&#22120;&#23545;&#28508;&#22312;&#25915;&#20987;&#30340;&#33030;&#24369;&#24615;&#20173;&#19981;&#28165;&#26970;&#65292;&#24341;&#21457;&#20154;&#20204;&#23545;&#20854;&#23433;&#20840;&#24615;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24773;&#26223;&#65292;&#25915;&#20987;&#32773;&#26088;&#22312;&#36890;&#36807;&#26816;&#32034;&#31995;&#32479;&#38544;&#34109;&#20256;&#25773;&#23450;&#21521;&#38169;&#35823;&#20449;&#24687;&#65292;&#22914;&#20167;&#24680;&#35328;&#35770;&#25110;&#24191;&#21578;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23494;&#38598;&#36890;&#36947;&#26816;&#32034;&#20013;&#30001;&#35821;&#27861;&#38169;&#35823;&#35302;&#21457;&#30340;&#21361;&#38505;&#21518;&#38376;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30830;&#20445;&#34987;&#25915;&#20987;&#30340;&#27169;&#22411;&#22312;&#26631;&#20934;&#26597;&#35810;&#19979;&#21487;&#20197;&#27491;&#24120;&#36816;&#34892;&#65292;&#20294;&#22312;&#29992;&#25143;&#22312;&#26597;&#35810;&#20013;&#24847;&#22806;&#22320;&#29359;&#35821;&#27861;&#38169;&#35823;&#26102;&#65292;&#34987;&#31713;&#25913;&#20197;&#36820;&#22238;&#25915;&#20987;&#32773;&#25351;&#23450;&#30340;&#27573;&#33853;&#12290;&#22823;&#37327;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#25915;&#20987;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#38544;&#34109;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13532v1 Announce Type: new  Abstract: Dense retrievers and retrieval-augmented language models have been widely used in various NLP applications. Despite being designed to deliver reliable and secure outcomes, the vulnerability of retrievers to potential attacks remains unclear, raising concerns about their security. In this paper, we introduce a novel scenario where the attackers aim to covertly disseminate targeted misinformation, such as hate speech or advertisement, through a retrieval system. To achieve this, we propose a perilous backdoor attack triggered by grammar errors in dense passage retrieval. Our approach ensures that attacked models can function normally for standard queries but are manipulated to return passages specified by the attacker when users unintentionally make grammatical mistakes in their queries. Extensive experiments demonstrate the effectiveness and stealthiness of our proposed attack method. When a user query is error-free, our model consistentl
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#22312;&#27169;&#25311;&#25919;&#27835;&#36777;&#35770;&#20013;&#23384;&#22312;&#30340;&#31995;&#32479;&#24615;&#20559;&#24046;&#65292;&#23613;&#31649;&#34987;&#25351;&#23450;&#20174;&#29305;&#23450;&#30340;&#25919;&#27835;&#35266;&#28857;&#36827;&#34892;&#36777;&#35770;&#65292;LLMs&#20195;&#29702;&#26426;&#26500;&#20542;&#21521;&#20110;&#36981;&#24490;&#27169;&#22411;&#22266;&#26377;&#30340;&#31038;&#20250;&#20559;&#35265;&#12290;&#36890;&#36807;&#33258;&#21160;&#33258;&#25105;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#23454;&#20102;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.04049</link><description>&lt;p&gt;
&#35770;&#35821;&#26009;&#24211;&#27169;&#25311;&#36777;&#35770;&#20013;&#30340;&#31995;&#32479;&#24615;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Systematic Biases in LLM Simulations of Debates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#22312;&#27169;&#25311;&#25919;&#27835;&#36777;&#35770;&#20013;&#23384;&#22312;&#30340;&#31995;&#32479;&#24615;&#20559;&#24046;&#65292;&#23613;&#31649;&#34987;&#25351;&#23450;&#20174;&#29305;&#23450;&#30340;&#25919;&#27835;&#35266;&#28857;&#36827;&#34892;&#36777;&#35770;&#65292;LLMs&#20195;&#29702;&#26426;&#26500;&#20542;&#21521;&#20110;&#36981;&#24490;&#27169;&#22411;&#22266;&#26377;&#30340;&#31038;&#20250;&#20559;&#35265;&#12290;&#36890;&#36807;&#33258;&#21160;&#33258;&#25105;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#23454;&#20102;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#36827;&#23637;&#65292;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#65292;&#20026;&#26500;&#24314;&#33021;&#22815;&#20934;&#30830;&#22797;&#21046;&#20154;&#31867;&#34892;&#20026;&#30340;&#35745;&#31639;&#26426;&#27169;&#25311;&#25552;&#20379;&#20102;&#20196;&#20154;&#20852;&#22859;&#30340;&#21487;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;LLMs&#26159;&#22797;&#26434;&#30340;&#32479;&#35745;&#23398;&#20064;&#22120;&#65292;&#27809;&#26377;&#30452;&#25509;&#30340;&#28436;&#32462;&#35268;&#21017;&#65292;&#20351;&#20854;&#23481;&#26131;&#20986;&#29616;&#24847;&#22806;&#34892;&#20026;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;LLMs&#22312;&#27169;&#25311;&#20154;&#31867;&#20114;&#21160;&#20013;&#30340;&#38480;&#21046;&#65292;&#29305;&#21035;&#20851;&#27880;LLMs&#22312;&#27169;&#25311;&#25919;&#27835;&#36777;&#35770;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#23613;&#31649;&#34987;&#25351;&#23450;&#20174;&#29305;&#23450;&#30340;&#25919;&#27835;&#35266;&#28857;&#36827;&#34892;&#36777;&#35770;&#65292;LLMs&#20195;&#29702;&#26426;&#26500;&#20542;&#21521;&#20110;&#36981;&#24490;&#27169;&#22411;&#22266;&#26377;&#30340;&#31038;&#20250;&#20559;&#35265;&#12290;&#36825;&#31181;&#20542;&#21521;&#23548;&#33268;&#20986;&#29616;&#34892;&#20026;&#27169;&#24335;&#65292;&#20284;&#20046;&#20559;&#31163;&#20102;&#20154;&#31867;&#20043;&#38388;&#24050;&#32463;&#30830;&#31435;&#30340;&#31038;&#20250;&#21160;&#24577;&#12290;&#25105;&#20204;&#20351;&#29992;&#33258;&#21160;&#33258;&#25105;&#20248;&#21270;&#26041;&#27861;&#21152;&#24378;&#20102;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;&#35813;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#25805;&#32437;LLMs&#20869;&#37096;&#30340;&#20559;&#35265;&#65292;&#24182;&#35777;&#26126;&#20195;&#29702;&#38543;&#21518;&#19982;&#36825;&#20123;&#35843;&#25972;&#20445;&#25345;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in natural language processing, especially the emergence of Large Language Models (LLMs), have opened exciting possibilities for constructing computational simulations designed to replicate human behavior accurately. However, LLMs are complex statistical learners without straightforward deductive rules, making them prone to unexpected behaviors. In this study, we highlight the limitations of LLMs in simulating human interactions, particularly focusing on LLMs' ability to simulate political debates. Our findings indicate a tendency for LLM agents to conform to the model's inherent social biases despite being directed to debate from certain political perspectives. This tendency results in behavioral patterns that seem to deviate from well-established social dynamics among humans. We reinforce these observations using an automatic self-fine-tuning method, which enables us to manipulate the biases within the LLM and demonstrate that agents subsequently align with the al
&lt;/p&gt;</description></item><item><title>SemPLeS&#26694;&#26550;&#21033;&#29992;&#35821;&#20041;&#25552;&#31034;&#23398;&#20064;&#35299;&#20915;&#24369;&#30417;&#30563;&#35821;&#20041;&#20998;&#21106;&#20013;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23398;&#20064;&#26377;&#25928;&#25552;&#31034;&#26469;&#22686;&#24378;&#20998;&#21106;&#21306;&#22495;&#19982;&#30446;&#26631;&#23545;&#35937;&#31867;&#21035;&#20043;&#38388;&#30340;&#35821;&#20041;&#23545;&#40784;&#12290;</title><link>https://arxiv.org/abs/2401.11791</link><description>&lt;p&gt;
SemPLeS: &#35821;&#20041;&#25552;&#31034;&#23398;&#20064;&#29992;&#20110;&#24369;&#30417;&#30563;&#35821;&#20041;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.11791
&lt;/p&gt;
&lt;p&gt;
SemPLeS&#26694;&#26550;&#21033;&#29992;&#35821;&#20041;&#25552;&#31034;&#23398;&#20064;&#35299;&#20915;&#24369;&#30417;&#30563;&#35821;&#20041;&#20998;&#21106;&#20013;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23398;&#20064;&#26377;&#25928;&#25552;&#31034;&#26469;&#22686;&#24378;&#20998;&#21106;&#21306;&#22495;&#19982;&#30446;&#26631;&#23545;&#35937;&#31867;&#21035;&#20043;&#38388;&#30340;&#35821;&#20041;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24369;&#30417;&#30563;&#35821;&#20041;&#20998;&#21106;&#65288;WSSS&#65289;&#26088;&#22312;&#21033;&#29992;&#20165;&#20855;&#26377;&#22270;&#20687;&#32423;&#30417;&#30563;&#30340;&#22270;&#20687;&#25968;&#25454;&#26469;&#35757;&#32451;&#20998;&#21106;&#27169;&#22411;&#12290;&#30001;&#20110;&#26080;&#27861;&#33719;&#24471;&#31934;&#30830;&#30340;&#20687;&#32032;&#32423;&#26631;&#27880;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#20391;&#37325;&#20110;&#36890;&#36807;&#20248;&#21270;CAM&#26679;&#24335;&#30340;&#28909;&#22270;&#26469;&#29983;&#25104;&#29992;&#20110;&#35757;&#32451;&#20998;&#21106;&#27169;&#22411;&#30340;&#20266;&#26631;&#35760;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#30340;&#28909;&#22270;&#21487;&#33021;&#20165;&#25429;&#33719;&#23545;&#35937;&#31867;&#21035;&#30340;&#20855;&#26377;&#21306;&#20998;&#24615;&#30340;&#22270;&#20687;&#21306;&#22495;&#25110;&#30456;&#20851;&#30340;&#20849;&#21516;&#20986;&#29616;&#30340;&#32972;&#26223;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;WSSS&#30340;&#35821;&#20041;&#25552;&#31034;&#23398;&#20064;&#65288;SemPLeS&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23398;&#20064;&#26377;&#25928;&#22320;&#25552;&#31034;CLIP&#28508;&#31354;&#38388;&#20197;&#22686;&#24378;&#20998;&#21106;&#21306;&#22495;&#19982;&#30446;&#26631;&#23545;&#35937;&#31867;&#21035;&#20043;&#38388;&#30340;&#35821;&#20041;&#23545;&#20934;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#27604;&#25552;&#31034;&#23398;&#20064;&#21644;&#25552;&#31034;&#24341;&#23548;&#30340;&#35821;&#20041;&#32454;&#21270;&#65292;&#20197;&#23398;&#20064;&#36866;&#24403;&#25551;&#36848;&#21644;&#25233;&#21046;&#19982;&#27599;&#20010;&#30446;&#26631;&#23545;&#35937;&#31867;&#21035;&#30456;&#20851;&#30340;&#20849;&#21516;&#20986;&#29616;&#30340;&#32972;&#26223;&#30340;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.11791v2 Announce Type: replace-cross  Abstract: Weakly-Supervised Semantic Segmentation (WSSS) aims to train segmentation models using image data with only image-level supervision. Since precise pixel-level annotations are not accessible, existing methods typically focus on producing pseudo masks for training segmentation models by refining CAM-like heatmaps. However, the produced heatmaps may capture only the discriminative image regions of object categories or the associated co-occurring backgrounds. To address the issues, we propose a Semantic Prompt Learning for WSSS (SemPLeS) framework, which learns to effectively prompt the CLIP latent space to enhance the semantic alignment between the segmented regions and the target object categories. More specifically, we propose Contrastive Prompt Learning and Prompt-guided Semantic Refinement to learn the prompts that adequately describe and suppress the co-occurring backgrounds associated with each target object category. In thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#25968;&#23398;&#23548;&#20986;&#65292;&#20998;&#26512;&#20102;&#24494;&#35843;&#27169;&#22411;&#23545;&#26410;&#35265;&#31526;&#21495;&#21644;&#26041;&#31243;&#32467;&#26500;&#26356;&#25913;&#30340;&#25935;&#24863;&#24615;&#65292;&#32467;&#26524;&#34920;&#26126;&#24494;&#35843;&#30340;FLAN-T5-large&#65288;MathT5&#65289;&#22312;&#21508;&#20010;&#27979;&#35797;&#38598;&#19978;&#30340;&#32477;&#23545;&#24615;&#33021;&#20248;&#20110;GPT&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2307.09998</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#25968;&#23398;&#23548;&#20986;
&lt;/p&gt;
&lt;p&gt;
Generating Mathematical Derivations with Large Language Models. (arXiv:2307.09998v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09998
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#25968;&#23398;&#23548;&#20986;&#65292;&#20998;&#26512;&#20102;&#24494;&#35843;&#27169;&#22411;&#23545;&#26410;&#35265;&#31526;&#21495;&#21644;&#26041;&#31243;&#32467;&#26500;&#26356;&#25913;&#30340;&#25935;&#24863;&#24615;&#65292;&#32467;&#26524;&#34920;&#26126;&#24494;&#35843;&#30340;FLAN-T5-large&#65288;MathT5&#65289;&#22312;&#21508;&#20010;&#27979;&#35797;&#38598;&#19978;&#30340;&#32477;&#23545;&#24615;&#33021;&#20248;&#20110;GPT&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#19987;&#19994;&#39046;&#22495;&#20013;&#29983;&#25104;&#25968;&#23398;&#32467;&#26524;&#30340;&#23548;&#20986;&#26159;&#19968;&#20010;&#26032;&#20852;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#21487;&#20197;&#24110;&#21161;&#35782;&#21035;&#27169;&#22411;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#26377;&#21487;&#33021;&#25903;&#25345;&#25968;&#23398;&#21457;&#29616;&#12290;&#26412;&#25991;&#21033;&#29992;&#31526;&#21495;&#24341;&#25806;&#22312;&#22823;&#35268;&#27169;&#19978;&#29983;&#25104;&#26041;&#31243;&#30340;&#23548;&#20986;&#65292;&#24182;&#30740;&#31350;&#20102;LLM&#22312;&#20174;&#21069;&#25552;&#20013;&#23548;&#20986;&#30446;&#26631;&#26041;&#31243;&#26102;&#30340;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37319;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#26469;&#23545;GPT&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#23545;&#19968;&#31995;&#21015;T5&#27169;&#22411;&#36827;&#34892;&#20102;&#24494;&#35843;&#65292;&#20197;&#27604;&#36739;&#39044;&#35757;&#32451;&#31574;&#30053;&#23545;&#19987;&#38376;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#32463;&#36807;&#24494;&#35843;&#30340;FLAN-T5-large&#65288;MathT5&#65289;&#22312;&#25152;&#26377;&#38745;&#24577;&#21644;&#36229;&#20986;&#20998;&#24067;&#30340;&#27979;&#35797;&#38598;&#19978;&#30340;&#32477;&#23545;&#24615;&#33021;&#20248;&#20110;GPT&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#28145;&#20837;&#20998;&#26512;&#34920;&#26126;&#65292;&#24494;&#35843;&#27169;&#22411;&#23545;&#28041;&#21450;&#26410;&#35265;&#31526;&#21495;&#30340;&#25200;&#21160;&#65288;&#20197;&#21450;&#22312;&#36739;&#23567;&#31243;&#24230;&#19978;&#30340;&#26041;&#31243;&#32467;&#26500;&#26356;&#25913;&#65289;&#26356;&#20026;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;1.7K&#20010;&#26041;&#31243;&#21644;200&#22810;&#20010;&#23548;&#20986;&#20197;&#20984;&#26174;&#20986;LLM&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The derivation of mathematical results in specialised fields using Large Language Models (LLMs) is an emerging research direction that can help identify models' limitations, and potentially support mathematical discovery. In this paper, we leverage a symbolic engine to generate derivations of equations at scale, and investigate the capabilities of LLMs when deriving goal equations from premises. Specifically, we employ in-context learning for GPT and fine-tune a range of T5 models to compare the robustness and generalisation of pre-training strategies to specialised models. Empirical results show that fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and out-of-distribution test sets in terms of absolute performance. However, an in-depth analysis reveals that the fine-tuned models are more sensitive to perturbations involving unseen symbols and (to a lesser extent) changes to equation structure. In addition, we analyse 1.7K equations and over 200 derivations to hig
&lt;/p&gt;</description></item></channel></rss>