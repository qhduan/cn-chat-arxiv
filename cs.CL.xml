<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>GINopic&#26159;&#19968;&#31181;&#20027;&#39064;&#24314;&#27169;&#26694;&#26550;&#65292;&#21033;&#29992;&#22270;&#21516;&#26500;&#32593;&#32476;&#25429;&#25417;&#21333;&#35789;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#20027;&#39064;&#27169;&#22411;&#65292;&#23637;&#31034;&#20102;&#26356;&#22909;&#30340;&#26377;&#25928;&#24615;&#21644;&#25512;&#36827;&#20027;&#39064;&#24314;&#27169;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.02115</link><description>&lt;p&gt;
GINopic&#65306;&#21033;&#29992;&#22270;&#21516;&#26500;&#32593;&#32476;&#36827;&#34892;&#20027;&#39064;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
GINopic: Topic Modeling with Graph Isomorphism Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02115
&lt;/p&gt;
&lt;p&gt;
GINopic&#26159;&#19968;&#31181;&#20027;&#39064;&#24314;&#27169;&#26694;&#26550;&#65292;&#21033;&#29992;&#22270;&#21516;&#26500;&#32593;&#32476;&#25429;&#25417;&#21333;&#35789;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#20027;&#39064;&#27169;&#22411;&#65292;&#23637;&#31034;&#20102;&#26356;&#22909;&#30340;&#26377;&#25928;&#24615;&#21644;&#25512;&#36827;&#20027;&#39064;&#24314;&#27169;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#39064;&#24314;&#27169;&#26159;&#20998;&#26512;&#21644;&#25506;&#32034;&#22823;&#22411;&#25991;&#26723;&#38598;&#21512;&#30340;&#24191;&#27867;&#20351;&#29992;&#26041;&#27861;&#12290; &#26368;&#36817;&#30340;&#30740;&#31350;&#24037;&#20316;&#23558;&#39044;&#35757;&#32451;&#30340;&#19978;&#19979;&#25991;&#21270;&#35821;&#35328;&#27169;&#22411;&#65292;&#22914;BERT&#23884;&#20837;&#65292;&#32435;&#20837;&#20027;&#39064;&#24314;&#27169;&#20013;&#12290; &#28982;&#32780;&#65292;&#23427;&#20204;&#36890;&#24120;&#24573;&#30053;&#20102;&#21333;&#35789;&#20043;&#38388;&#30456;&#20114;&#20381;&#36182;&#20256;&#36798;&#30340;&#22266;&#26377;&#20449;&#24687;&#20215;&#20540;&#12290; &#26412;&#30740;&#31350;&#20171;&#32461;&#20102;GINopic&#65292;&#19968;&#31181;&#22522;&#20110;&#22270;&#21516;&#26500;&#32593;&#32476;&#30340;&#20027;&#39064;&#24314;&#27169;&#26694;&#26550;&#65292;&#20197;&#25429;&#25417;&#21333;&#35789;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290; &#36890;&#36807;&#22312;&#19981;&#21516;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20869;&#22312;&#30340;&#65288;&#23450;&#37327;&#21644;&#23450;&#24615;&#65289;&#21644;&#22806;&#37096;&#30340;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#20027;&#39064;&#27169;&#22411;&#30456;&#27604;&#65292;GINopic&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#20854;&#25512;&#36827;&#20027;&#39064;&#24314;&#27169;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02115v1 Announce Type: new  Abstract: Topic modeling is a widely used approach for analyzing and exploring large document collections. Recent research efforts have incorporated pre-trained contextualized language models, such as BERT embeddings, into topic modeling. However, they often neglect the intrinsic informational value conveyed by mutual dependencies between words. In this study, we introduce GINopic, a topic modeling framework based on graph isomorphism networks to capture the correlation between words. By conducting intrinsic (quantitative as well as qualitative) and extrinsic evaluations on diverse benchmark datasets, we demonstrate the effectiveness of GINopic compared to existing topic models and highlight its potential for advancing topic modeling.
&lt;/p&gt;</description></item><item><title>TableLLM&#26159;&#19968;&#20010;&#25317;&#26377;130&#20159;&#21442;&#25968;&#30340;&#24378;&#22823;&#22823;&#35821;&#35328;&#27169;&#22411;&#65292;&#19987;&#38376;&#29992;&#20110;&#29087;&#32451;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#25805;&#20316;&#20219;&#21153;&#65292;&#36890;&#36807;&#36828;&#31243;&#30417;&#30563;&#26041;&#27861;&#21644;&#20132;&#21449;&#39564;&#35777;&#31574;&#30053;&#65292;TableLLM&#30456;&#23545;&#20110;&#20854;&#20182;&#29616;&#26377;&#30340;&#36890;&#29992;&#21644;&#34920;&#26684;&#25968;&#25454;&#19987;&#27880;&#30340;LLMs&#20855;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.19318</link><description>&lt;p&gt;
TableLLM&#65306;&#22312;&#23454;&#38469;&#21150;&#20844;&#20351;&#29992;&#22330;&#26223;&#20013;&#23454;&#29616;LLMs&#23545;&#34920;&#26684;&#25968;&#25454;&#36827;&#34892;&#22788;&#29702;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19318
&lt;/p&gt;
&lt;p&gt;
TableLLM&#26159;&#19968;&#20010;&#25317;&#26377;130&#20159;&#21442;&#25968;&#30340;&#24378;&#22823;&#22823;&#35821;&#35328;&#27169;&#22411;&#65292;&#19987;&#38376;&#29992;&#20110;&#29087;&#32451;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#25805;&#20316;&#20219;&#21153;&#65292;&#36890;&#36807;&#36828;&#31243;&#30417;&#30563;&#26041;&#27861;&#21644;&#20132;&#21449;&#39564;&#35777;&#31574;&#30053;&#65292;TableLLM&#30456;&#23545;&#20110;&#20854;&#20182;&#29616;&#26377;&#30340;&#36890;&#29992;&#21644;&#34920;&#26684;&#25968;&#25454;&#19987;&#27880;&#30340;LLMs&#20855;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;TableLLM&#65292;&#36825;&#26159;&#19968;&#20010;&#25317;&#26377;130&#20159;&#21442;&#25968;&#30340;&#24378;&#22823;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#19987;&#38376;&#29992;&#20110;&#29087;&#32451;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#25805;&#20316;&#20219;&#21153;&#65292;&#26080;&#35770;&#20854;&#23884;&#20837;&#22312;&#25991;&#26723;&#36824;&#26159;&#30005;&#23376;&#34920;&#26684;&#20013;&#65292;&#20197;&#28385;&#36275;&#30495;&#23454;&#21150;&#20844;&#22330;&#26223;&#38656;&#27714;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36828;&#31243;&#30417;&#30563;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#31181;&#25512;&#29702;&#36807;&#31243;&#25193;&#23637;&#31574;&#30053;&#65292;&#26377;&#21161;&#20110;&#35757;&#32451;LLMs&#26356;&#26377;&#25928;&#22320;&#29702;&#35299;&#25512;&#29702;&#27169;&#24335;&#65292;&#20197;&#21450;&#19968;&#31181;&#20132;&#21449;&#39564;&#35777;&#31574;&#30053;&#65292;&#30830;&#20445;&#33258;&#21160;&#29983;&#25104;&#25968;&#25454;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#35780;&#20272;TableLLM&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#26088;&#22312;&#35299;&#20915;&#25991;&#26723;&#21644;&#30005;&#23376;&#34920;&#26684;&#26684;&#24335;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#33021;&#22815;&#22788;&#29702;&#20004;&#31181;&#22330;&#26223;&#30340;&#32452;&#32455;&#33391;&#22909;&#30340;&#35780;&#20272;&#31649;&#32447;&#12290;&#24443;&#24213;&#30340;&#35780;&#20272;&#20984;&#26174;&#20102;TableLLM&#30456;&#23545;&#20110;&#21508;&#31181;&#29616;&#26377;&#36890;&#29992;&#21644;&#19987;&#27880;&#20110;&#34920;&#26684;&#25968;&#25454;&#30340;LLMs&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#24050;&#20844;&#24320;&#21457;&#24067;&#20102;&#35813;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19318v1 Announce Type: new  Abstract: We introduce TableLLM, a robust large language model (LLM) with 13 billion parameters, purpose-built for proficiently handling tabular data manipulation tasks, whether they are embedded within documents or spreadsheets, catering to real-world office scenarios. We propose a distant supervision method for training, which comprises a reasoning process extension strategy, aiding in training LLMs to understand reasoning patterns more effectively as well as a cross-way validation strategy, ensuring the quality of the automatically generated data. To evaluate the performance of TableLLM, we have crafted a benchmark tailored to address both document and spreadsheet formats as well as constructed a well-organized evaluation pipeline capable of handling both scenarios. Thorough evaluations underscore the advantages of TableLLM when compared to various existing general-purpose and tabular data-focused LLMs. We have publicly released the model check
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20808;&#36827;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#20027;&#39064;&#32454;&#21270;&#8221;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#25552;&#31034;&#24037;&#31243;&#21644;&#28040;&#38500;&#31163;&#39064;&#35789;&#31561;&#26041;&#24335;&#25913;&#36827;&#30701;&#25991;&#26412;&#30340;&#20027;&#39064;&#24314;&#27169;&#36136;&#37327;&#65292;&#25552;&#39640;&#20102;&#20027;&#39064;&#30340;&#35821;&#20041;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.17706</link><description>&lt;p&gt;
&#22686;&#24378;&#30701;&#25991;&#26412;&#24314;&#27169;&#65306;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20027;&#39064;&#32454;&#21270;
&lt;/p&gt;
&lt;p&gt;
Enhanced Short Text Modeling: Leveraging Large Language Models for Topic Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17706
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20808;&#36827;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#20027;&#39064;&#32454;&#21270;&#8221;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#25552;&#31034;&#24037;&#31243;&#21644;&#28040;&#38500;&#31163;&#39064;&#35789;&#31561;&#26041;&#24335;&#25913;&#36827;&#30701;&#25991;&#26412;&#30340;&#20027;&#39064;&#24314;&#27169;&#36136;&#37327;&#65292;&#25552;&#39640;&#20102;&#20027;&#39064;&#30340;&#35821;&#20041;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#22320;&#26500;&#24314;&#38024;&#23545;&#31616;&#30701;&#25991;&#26412;&#65288;&#22914;&#25512;&#25991;&#21644;&#26032;&#38395;&#26631;&#39064;&#65289;&#30340;&#20027;&#39064;&#27169;&#22411;&#23545;&#25429;&#25417;&#31038;&#20250;&#21160;&#24577;&#30340;&#36805;&#36895;&#21464;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#20027;&#39064;&#27169;&#22411;&#24448;&#24448;&#22312;&#20934;&#30830;&#34920;&#36798;&#30701;&#25991;&#26412;&#30340;&#35821;&#20041;&#32454;&#24494;&#24046;&#24322;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#36825;&#26159;&#30001;&#20110;&#23427;&#20204;&#30340;&#31616;&#27905;&#24615;&#21644;&#32570;&#20047;&#19978;&#19979;&#25991;&#25968;&#25454;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20808;&#36827;&#33021;&#21147;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#20027;&#39064;&#32454;&#21270;&#8221;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#24182;&#38750;&#30452;&#25509;&#21442;&#19982;&#20027;&#39064;&#30340;&#21021;&#27493;&#24314;&#27169;&#65292;&#32780;&#26159;&#19987;&#27880;&#20110;&#25913;&#36827;&#20027;&#39064;&#22312;&#34987;&#25366;&#25496;&#21518;&#30340;&#38454;&#27573;&#12290;&#36890;&#36807;&#24341;&#20837;&#25552;&#31034;&#24037;&#31243;&#65292;&#25105;&#20204;&#25351;&#23548;LLMs&#28040;&#38500;&#32473;&#23450;&#20027;&#39064;&#20013;&#30340;&#31163;&#39064;&#35789;&#65292;&#30830;&#20445;&#20165;&#20445;&#30041;&#19982;&#35821;&#22659;&#30456;&#20851;&#30340;&#35789;&#27719;&#25110;&#29992;&#26356;&#31526;&#21512;&#35821;&#20041;&#30340;&#35789;&#27719;&#26367;&#25442;&#12290;&#36825;&#31181;&#26041;&#27861;&#27169;&#25311;&#20102;&#20154;&#31867;&#33324;&#30340;&#23457;&#26597;&#21644;&#25913;&#36827;&#20027;&#39064;&#30340;&#26041;&#24335;&#65292;&#20174;&#32780;&#25552;&#21319;&#20102;&#21508;&#31181;&#20027;&#39064;&#29983;&#25104;&#30340;&#35821;&#20041;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17706v1 Announce Type: cross  Abstract: Crafting effective topic models for brief texts, like tweets and news headlines, is essential for capturing the swift shifts in social dynamics. Traditional topic models, however, often fall short in accurately representing the semantic intricacies of short texts due to their brevity and lack of contextual data. In our study, we harness the advanced capabilities of Large Language Models (LLMs) to introduce a novel approach termed "Topic Refinement". This approach does not directly involve itself in the initial modeling of topics but focuses on improving topics after they have been mined. By employing prompt engineering, we direct LLMs to eliminate off-topic words within a given topic, ensuring that only contextually relevant words are preserved or substituted with ones that fit better semantically. This method emulates human-like scrutiny and improvement of topics, thereby elevating the semantic quality of the topics generated by vario
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#26497;&#22823;&#24433;&#21709;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#20854;&#20808;&#36827;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#32780;&#26412;&#32508;&#36848;&#21017;&#37325;&#28857;&#35780;&#20272;&#21644;&#25913;&#36827;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#26029;&#26041;&#38754;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#25552;&#39640;&#25512;&#29702;&#33021;&#21147;&#12289;&#35299;&#20915;&#20844;&#24179;&#21644;&#23433;&#20840;&#38382;&#39064;&#12289;&#25552;&#20379;&#35299;&#37322;&#21644;&#22788;&#29702;&#22810;&#27169;&#24577;&#12290;</title><link>https://arxiv.org/abs/2403.09606</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#21327;&#20316;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#65306;&#19968;&#39033;&#32508;&#21512;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09606
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#26497;&#22823;&#24433;&#21709;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#20854;&#20808;&#36827;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#32780;&#26412;&#32508;&#36848;&#21017;&#37325;&#28857;&#35780;&#20272;&#21644;&#25913;&#36827;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#26029;&#26041;&#38754;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#25552;&#39640;&#25512;&#29702;&#33021;&#21147;&#12289;&#35299;&#20915;&#20844;&#24179;&#21644;&#23433;&#20840;&#38382;&#39064;&#12289;&#25552;&#20379;&#35299;&#37322;&#21644;&#22788;&#29702;&#22810;&#27169;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#24050;&#32463;&#26174;&#31034;&#20986;&#28508;&#21147;&#65292;&#36890;&#36807;&#25429;&#25417;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#25552;&#39640;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#31283;&#20581;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#29983;&#25104;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#26174;&#33879;&#24433;&#21709;&#20102;&#21508;&#31181;NLP&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#20854;&#20808;&#36827;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#35813;&#35843;&#26597;&#37325;&#28857;&#35780;&#20272;&#21644;&#25913;&#36827;LLMs&#30340;&#22240;&#26524;&#35270;&#35282;&#65292;&#22312;&#20197;&#19979;&#39046;&#22495;&#23637;&#24320;&#65306;&#29702;&#35299;&#21644;&#25913;&#36827;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#35299;&#20915;LLMs&#20013;&#30340;&#20844;&#24179;&#24615;&#21644;&#23433;&#20840;&#24615;&#38382;&#39064;&#65292;&#20026;LLMs&#25552;&#20379;&#35299;&#37322;&#65292;&#24182;&#22788;&#29702;&#22810;&#27169;&#24577;&#12290;&#21516;&#26102;&#65292;LLMs&#24378;&#22823;&#30340;&#25512;&#29702;&#33021;&#21147;&#21453;&#36807;&#26469;&#21487;&#20197;&#36890;&#36807;&#24110;&#21161;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#21644;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26469;&#20419;&#36827;&#22240;&#26524;&#25512;&#26029;&#39046;&#22495;&#30340;&#21457;&#23637;&#12290;&#26412;&#32508;&#36848;&#25506;&#35752;&#20102;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#19982;LLMs&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24378;&#35843;&#20102;&#23427;&#20204;&#30340;&#38598;&#20307;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09606v1 Announce Type: cross  Abstract: Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective p
&lt;/p&gt;</description></item><item><title>&#23545;&#27604;&#25552;&#31034;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#22797;&#26434;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#19981;&#20165;&#22312;&#31639;&#26415;&#12289;&#24120;&#35782;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#33391;&#65292;&#36824;&#21487;&#20197;&#19982;&#29616;&#26377;&#25552;&#31034;&#26041;&#27861;&#25972;&#21512;&#65292;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.08211</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#23545;&#27604;&#25512;&#29702;&#32773;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Contrastive Reasoners
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08211
&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#25552;&#31034;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#22797;&#26434;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#19981;&#20165;&#22312;&#31639;&#26415;&#12289;&#24120;&#35782;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#33391;&#65292;&#36824;&#21487;&#20197;&#19982;&#29616;&#26377;&#25552;&#31034;&#26041;&#27861;&#25972;&#21512;&#65292;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#31034;&#26041;&#27861;&#22312;&#22686;&#24378;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#33021;&#21147;&#26041;&#38754;&#21457;&#25381;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#23545;&#27604;&#25552;&#31034;&#65288;CP&#65289;&#22914;&#20309;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25191;&#34892;&#22797;&#26434;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#31616;&#21333;&#22320;&#22312;LLMs&#25552;&#20379;&#31572;&#26696;&#20043;&#21069;&#28155;&#21152;"&#35753;&#25105;&#20204;&#32473;&#20986;&#19968;&#20010;&#27491;&#30830;&#31572;&#26696;&#21644;&#19968;&#20010;&#38169;&#35823;&#31572;&#26696;"&#26469;&#28436;&#31034;LLMs&#26159;&#20307;&#38754;&#30340;&#23545;&#27604;&#25512;&#29702;&#32773;&#12290;&#23545;&#20004;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#38646;&#36801;&#31227;&#23545;&#27604;&#25552;&#31034;&#25552;&#21319;&#20102;&#22312;&#19968;&#31995;&#21015;&#31639;&#26415;&#12289;&#24120;&#35782;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#65292;&#32780;&#19981;&#38656;&#35201;&#25163;&#24037;&#21046;&#20316;&#30340;&#23569;&#37327;&#36801;&#31227;&#31034;&#20363;&#65292;&#27604;&#22914;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;GPT-4&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#22312;GSM8K&#19978;&#30340;&#20934;&#30830;&#29575;&#20174;35.9%&#21040;88.8%&#20197;&#21450;AQUA-RAT&#20174;41.3%&#21040;62.2%&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#22312;&#22823;&#22810;&#25968;&#31639;&#26415;&#21644;&#24120;&#35782;&#25512;&#29702;&#20219;&#21153;&#20013;&#32988;&#36807;&#38646;&#36801;&#31227;CoT&#21644;&#23569;&#37327;&#36801;&#31227;CoT&#65292;&#36824;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#25552;&#31034;&#26041;&#27861;&#26080;&#32541;&#25972;&#21512;&#65292;&#20174;&#32780;&#23454;&#29616;&#25913;&#36827;&#25110;&#32773;&#31454;&#20105;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08211v1 Announce Type: cross  Abstract: Prompting methods play a crucial role in enhancing the capabilities of pre-trained large language models (LLMs). We explore how contrastive prompting (CP) significantly improves the ability of large language models to perform complex reasoning. We demonstrate that LLMs are decent contrastive reasoners by simply adding "Let's give a correct and a wrong answer." before LLMs provide answers. Experiments on two large language models show that zero-shot contrastive prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks without any hand-crafted few-shot examples, such as increasing the accuracy on GSM8K from 35.9% to 88.8% and AQUA-RAT from 41.3% to 62.2% with the state-of-the-art GPT-4 model. Our method not only surpasses zero-shot CoT and few-shot CoT in most arithmetic and commonsense reasoning tasks but also can seamlessly integrate with existing prompting methods, resulting in improved or comp
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#22312;&#25928;&#29575;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#26631;&#20934;&#30340;&#22810;&#22836;&#27880;&#24847;&#21147;&#65292;&#25552;&#39640;&#20102;Transformer&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#26356;&#24191;&#27867;&#30340;&#37096;&#32626;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.01643</link><description>&lt;p&gt;
&#24744;&#38656;&#35201;&#26356;&#22909;&#22320;&#20851;&#27880;&#20184;&#36153;
&lt;/p&gt;
&lt;p&gt;
You Need to Pay Better Attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01643
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#22312;&#25928;&#29575;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#26631;&#20934;&#30340;&#22810;&#22836;&#27880;&#24847;&#21147;&#65292;&#25552;&#39640;&#20102;Transformer&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#26356;&#24191;&#27867;&#30340;&#37096;&#32626;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19977;&#31181;&#26032;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#36825;&#20123;&#26426;&#21046;&#22312;&#25928;&#29575;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#32988;&#36807;&#26631;&#20934;&#30340;&#22810;&#22836;&#27880;&#24847;&#21147;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;Transformer&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#26356;&#24191;&#27867;&#30340;&#37096;&#32626;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#20248;&#21270;&#27880;&#24847;&#21147;&#65292;&#20854;&#24615;&#33021;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#30456;&#20284;&#65292;&#20294;&#21442;&#25968;&#25968;&#37327;&#23569;&#20102;&#22235;&#20998;&#20043;&#19977;&#65292;&#27599;&#20010;&#22836;&#37096;&#23569;&#20102;&#19968;&#20010;&#30697;&#38453;&#20056;&#27861;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#39640;&#25928;&#27880;&#24847;&#21147;&#65292;&#20854;&#24615;&#33021;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#30456;&#24403;&#65292;&#20294;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569;&#20102;&#19968;&#21322;&#65292;&#27599;&#20010;&#22836;&#37096;&#20943;&#23569;&#20102;&#20004;&#20010;&#30697;&#38453;&#20056;&#27861;&#65292;&#24182;&#19988;&#27604;&#26631;&#20934;&#27880;&#24847;&#21147;&#24555;&#20004;&#20493;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#36229;&#32423;&#27880;&#24847;&#21147;&#65292;&#22312;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#26126;&#26174;&#36229;&#36234;&#20102;&#26631;&#20934;&#27880;&#24847;&#21147;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#23569;&#30340;&#21442;&#25968;&#21644;&#30697;&#38453;&#20056;&#27861;&#12290;&#38500;&#20102;&#25552;&#20379;&#20005;&#26684;&#30340;&#25968;&#23398;&#27604;&#36739;&#65292;&#25105;&#20204;&#22312;MN&#20013;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01643v1 Announce Type: cross  Abstract: We introduce three new attention mechanisms that outperform standard multi-head attention in terms of efficiency and learning capabilities, thereby improving the performance and broader deployability of Transformer models. Our first contribution is Optimised Attention, which performs similarly to standard attention, but has 3/4 as many parameters and one matrix multiplication fewer per head. Next, we introduce Efficient Attention, which performs on par with standard attention with only 1/2 as many parameters as many parameters and two matrix multiplications fewer per head and is up to twice as fast as standard attention. Lastly, we introduce Super Attention, which surpasses standard attention by a significant margin in both vision and natural language processing tasks while having fewer parameters and matrix multiplications. In addition to providing rigorous mathematical comparisons, we evaluate the presented attention mechanisms on MN
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#20559;&#35265;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#30740;&#31350;&#20102;"&#25216;&#24039;&#27979;&#35797;"&#19982;&#26356;&#29616;&#23454;&#19990;&#30028;&#20013;&#34920;&#29616;&#30340;RUTEd&#35780;&#20272;&#20043;&#38388;&#30340;&#20851;&#32852;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#24615;&#21035;-&#32844;&#19994;&#20559;&#35265;&#65292;&#24182;&#36827;&#34892;&#20102;&#22810;&#39033;&#35780;&#20272;&#27604;&#36739;&#12290;</title><link>https://arxiv.org/abs/2402.12649</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#65306;&#36229;&#36234;&#25216;&#24039;&#27979;&#35797;&#65292;&#36208;&#21521;RUTEd&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12649
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#20559;&#35265;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#30740;&#31350;&#20102;"&#25216;&#24039;&#27979;&#35797;"&#19982;&#26356;&#29616;&#23454;&#19990;&#30028;&#20013;&#34920;&#29616;&#30340;RUTEd&#35780;&#20272;&#20043;&#38388;&#30340;&#20851;&#32852;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#24615;&#21035;-&#32844;&#19994;&#20559;&#35265;&#65292;&#24182;&#36827;&#34892;&#20102;&#22810;&#39033;&#35780;&#20272;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bias benchmarks are a popular method for studying the negative impacts of bias in LLMs, yet there has been little empirical investigation of whether these benchmarks are actually indicative of how real world harm may manifest in the real world. In this work, we study the correspondence between such decontextualized "trick tests" and evaluations that are more grounded in Realistic Use and Tangible {Effects (i.e. RUTEd evaluations). We explore this correlation in the context of gender-occupation bias--a popular genre of bias evaluation. We compare three de-contextualized evaluations adapted from the current literature to three analogous RUTEd evaluations applied to long-form content generation. We conduct each evaluation for seven instruction-tuned LLMs. For the RUTEd evaluations, we conduct repeated trials of three text generation tasks: children's bedtime stories, user personas, and English language learning exercises. We found no corres
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12649v1 Announce Type: new  Abstract: Bias benchmarks are a popular method for studying the negative impacts of bias in LLMs, yet there has been little empirical investigation of whether these benchmarks are actually indicative of how real world harm may manifest in the real world. In this work, we study the correspondence between such decontextualized "trick tests" and evaluations that are more grounded in Realistic Use and Tangible {Effects (i.e. RUTEd evaluations). We explore this correlation in the context of gender-occupation bias--a popular genre of bias evaluation. We compare three de-contextualized evaluations adapted from the current literature to three analogous RUTEd evaluations applied to long-form content generation. We conduct each evaluation for seven instruction-tuned LLMs. For the RUTEd evaluations, we conduct repeated trials of three text generation tasks: children's bedtime stories, user personas, and English language learning exercises. We found no corres
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#21512;&#35843;&#26597;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;GPT4&#65289;&#25972;&#21512;&#21040;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#26102;&#23545;&#20803;&#25968;&#25454;&#21644;&#33258;&#28982;&#35821;&#35328;&#30340;&#21019;&#26032;&#21033;&#29992;&#65292;&#24378;&#35843;&#20102;LLMs&#22312;&#22686;&#24378;&#20256;&#32479;CD&#26041;&#27861;&#21644;&#20316;&#20026;&#19987;&#23478;&#36741;&#21161;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.11068</link><description>&lt;p&gt;
&#26550;&#36215;&#22240;&#26524;&#21457;&#29616;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#26725;&#26753;&#65306;&#25972;&#21512;&#26041;&#27861;&#21644;&#26410;&#26469;&#26041;&#21521;&#30340;&#32508;&#21512;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Bridging Causal Discovery and Large Language Models: A Comprehensive Survey of Integrative Approaches and Future Directions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11068
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#21512;&#35843;&#26597;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;GPT4&#65289;&#25972;&#21512;&#21040;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#26102;&#23545;&#20803;&#25968;&#25454;&#21644;&#33258;&#28982;&#35821;&#35328;&#30340;&#21019;&#26032;&#21033;&#29992;&#65292;&#24378;&#35843;&#20102;LLMs&#22312;&#22686;&#24378;&#20256;&#32479;CD&#26041;&#27861;&#21644;&#20316;&#20026;&#19987;&#23478;&#36741;&#21161;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#65288;CD&#65289;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20195;&#34920;&#30528;&#20004;&#20010;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#21147;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#39046;&#22495;&#12290;&#23613;&#31649;&#23427;&#20204;&#36215;&#28304;&#19981;&#21516;&#65292;CD&#20391;&#37325;&#20110;&#20174;&#25968;&#25454;&#20013;&#25581;&#31034;&#22240;&#26524;&#20851;&#31995;&#65292;LLMs&#21017;&#20391;&#37325;&#20110;&#22788;&#29702;&#21644;&#29983;&#25104;&#31867;&#20284;&#20154;&#31867;&#30340;&#25991;&#26412;&#65292;&#20294;&#36825;&#20004;&#20010;&#39046;&#22495;&#30340;&#34701;&#21512;&#20026;&#29702;&#35299;&#22797;&#26434;&#31995;&#32479;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#35265;&#35299;&#21644;&#26041;&#27861;&#35770;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;LLMs&#65288;&#22914;GPT4&#65289;&#25972;&#21512;&#21040;CD&#20219;&#21153;&#20013;&#30340;&#32508;&#21512;&#35843;&#26597;&#12290;&#25105;&#20204;&#31995;&#32479;&#22320;&#23457;&#26597;&#21644;&#27604;&#36739;&#20102;&#21033;&#29992;LLMs&#36827;&#34892;&#21508;&#31181;CD&#20219;&#21153;&#30340;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#31361;&#20986;&#20102;&#23427;&#20204;&#23545;&#20803;&#25968;&#25454;&#21644;&#33258;&#28982;&#35821;&#35328;&#30340;&#21019;&#26032;&#21033;&#29992;&#20197;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;LLMs&#22312;&#22686;&#24378;&#20256;&#32479;CD&#26041;&#27861;&#21644;&#20316;&#20026;&#19981;&#23436;&#32654;&#19987;&#23478;&#26041;&#38754;&#30340;&#20248;&#21183;&#21644;&#28508;&#21147;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#24403;&#21069;&#23454;&#36341;&#20013;&#22266;&#26377;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#25991;&#29486;&#20013;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11068v1 Announce Type: cross  Abstract: Causal discovery (CD) and Large Language Models (LLMs) represent two emerging fields of study with significant implications for artificial intelligence. Despite their distinct origins, CD focuses on uncovering cause-effect relationships from data, and LLMs on processing and generating humanlike text, the convergence of these domains offers novel insights and methodologies for understanding complex systems. This paper presents a comprehensive survey of the integration of LLMs, such as GPT4, into CD tasks. We systematically review and compare existing approaches that leverage LLMs for various CD tasks and highlight their innovative use of metadata and natural language to infer causal structures. Our analysis reveals the strengths and potential of LLMs in both enhancing traditional CD methods and as an imperfect expert, alongside the challenges and limitations inherent in current practices. Furthermore, we identify gaps in the literature 
&lt;/p&gt;</description></item><item><title>ChatGPT&#22312;LLM&#35268;&#27169;&#19978;&#36890;&#36807;&#21033;&#29992;&#35821;&#35328;&#26412;&#36523;&#30340;&#25910;&#25947;&#32422;&#26463;&#26469;&#20570;&#21040;&#36229;&#20986;&#39044;&#26399;&#30340;&#34920;&#29616;&#65292;&#20294;&#24182;&#19981;&#30495;&#27491;&#29702;&#35299;&#35821;&#20041;&#20197;&#21450;&#19982;&#24863;&#35273;&#21160;&#20316;&#30340;&#30452;&#25509;&#32852;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.02243</link><description>&lt;p&gt;
&#35821;&#35328;&#25193;&#23637;&#65306;LLMs&#65292;ChatGPT&#65292;&#25509;&#22320;&#65292;&#24847;&#20041;&#21644;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Language Writ Large: LLMs, ChatGPT, Grounding, Meaning and Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02243
&lt;/p&gt;
&lt;p&gt;
ChatGPT&#22312;LLM&#35268;&#27169;&#19978;&#36890;&#36807;&#21033;&#29992;&#35821;&#35328;&#26412;&#36523;&#30340;&#25910;&#25947;&#32422;&#26463;&#26469;&#20570;&#21040;&#36229;&#20986;&#39044;&#26399;&#30340;&#34920;&#29616;&#65292;&#20294;&#24182;&#19981;&#30495;&#27491;&#29702;&#35299;&#35821;&#20041;&#20197;&#21450;&#19982;&#24863;&#35273;&#21160;&#20316;&#30340;&#30452;&#25509;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;OpenAI&#21487;&#33021;&#23545;&#25105;&#20204;&#38544;&#30610;&#30340;&#23569;&#37327;&#20449;&#24687;&#22806;&#65292;&#25105;&#20204;&#37117;&#22823;&#33268;&#30693;&#36947;ChatGPT&#26159;&#22914;&#20309;&#24037;&#20316;&#30340;&#65288;&#23427;&#30340;&#22823;&#22411;&#25991;&#26412;&#25968;&#25454;&#24211;&#65292;&#32479;&#35745;&#25968;&#25454;&#65292;&#21521;&#37327;&#34920;&#31034;&#20197;&#21450;&#23427;&#24040;&#22823;&#30340;&#21442;&#25968;&#25968;&#37327;&#65292;&#20854;&#19979;&#19968;&#20010;&#35789;&#30340;&#35757;&#32451;&#31561;&#65289;&#12290;&#20294;&#25105;&#20204;&#35841;&#20063;&#19981;&#33021;&#35828;&#25105;&#20204;&#23545;ChatGPT&#30340;&#36825;&#20123;&#36164;&#28304;&#25152;&#33021;&#20570;&#21040;&#30340;&#20107;&#24773;&#19981;&#24863;&#21040;&#24778;&#35766;&#12290;&#36825;&#29978;&#33267;&#35753;&#25105;&#20204;&#26377;&#20154;&#24471;&#20986;&#32467;&#35770;&#65292;ChatGPT&#23454;&#38469;&#19978;&#29702;&#35299;&#20102;&#12290;&#23427;&#24182;&#19981;&#29702;&#35299;&#65292;&#20294;&#25105;&#20204;&#20063;&#19981;&#33021;&#35828;&#25105;&#20204;&#29702;&#35299;&#23427;&#26159;&#22914;&#20309;&#20570;&#21040;&#36825;&#19968;&#28857;&#30340;&#12290;&#25105;&#23558;&#25552;&#20986;&#20851;&#20110;&#33391;&#24615;&#20559;&#35265;&#30340;&#19968;&#20123;&#29468;&#24819;&#65306;&#22312;LLM&#35268;&#27169;&#19978;&#20986;&#29616;&#30340;&#25910;&#25947;&#32422;&#26463;&#21487;&#33021;&#26377;&#21161;&#20110;ChatGPT&#20570;&#24471;&#27604;&#25105;&#20204;&#39044;&#26399;&#30340;&#22909;&#24471;&#22810;&#12290;&#36825;&#20123;&#20559;&#35265;&#26159;&#35821;&#35328;&#26412;&#36523;&#22312;LLM&#35268;&#27169;&#19978;&#22266;&#26377;&#30340;&#65292;&#24182;&#19988;&#19982;ChatGPT&#32570;&#20047;&#30452;&#25509;&#30340;&#24863;&#35273;&#21160;&#20316;&#25509;&#22320;&#20197;&#23558;&#20854;&#35789;&#19982;&#20854;&#25152;&#25351;&#30340;&#23545;&#35937;&#20197;&#21450;&#20854;&#21629;&#39064;&#19982;&#20854;&#24847;&#20041;&#32852;&#31995;&#36215;&#26469;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Apart from what (little) OpenAI may be concealing from us, we all know (roughly) how ChatGPT works (its huge text database, its statistics, its vector representations, and their huge number of parameters, its next-word training, and so on). But none of us can say (hand on heart) that we are not surprised by what ChatGPT has proved to be able to do with these resources. This has even driven some of us to conclude that ChatGPT actually understands. It is not true that it understands. But it is also not true that we understand how it can do what it can do. I will suggest some hunches about benign biases: convergent constraints that emerge at LLM scale that may be helping ChatGPT do so much better than we would have expected. These biases are inherent in the nature of language itself, at LLM scale, and they are closely linked to what it is that ChatGPT lacks, which is direct sensorimotor grounding to connect its words to their referents and its propositions to their meanings. These converg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;LLM&#20195;&#29702;&#20197;&#20943;&#36731;&#22810;&#20195;&#29702;&#35774;&#32622;&#19979;&#35848;&#21028;&#20013;&#30340;&#31038;&#20132;&#35268;&#33539;&#36829;&#21453;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20215;&#20540;&#24433;&#21709;&#30340;&#29615;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20026;&#22522;&#20110;LLM&#30340;&#20462;&#27491;&#20195;&#29702;&#35782;&#21035;&#39640;&#36136;&#37327;&#30340;ICL&#31034;&#20363;&#65292;&#20854;&#20013;&#20215;&#20540;&#24433;&#21709;&#20989;&#25968;&#34913;&#37327;&#35848;&#21028;&#32467;&#26524;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#31574;&#30053;&#23398;&#20064;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#23454;&#35777;&#35777;&#25454;&#26469;&#35777;&#26126;&#20854;&#22312;&#19977;&#20010;&#19981;&#21516;&#20027;&#39064;&#30340;&#35848;&#21028;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.01737</link><description>&lt;p&gt;
&#20026;&#31038;&#20132;&#24863;&#30693;&#30340;&#35848;&#21028;&#23545;&#35805;&#24320;&#21457;&#36741;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;LLM&#20195;&#29702;&#20197;&#20943;&#36731;&#22810;&#20195;&#29702;&#35774;&#32622;&#19979;&#35848;&#21028;&#20013;&#30340;&#31038;&#20132;&#35268;&#33539;&#36829;&#21453;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20215;&#20540;&#24433;&#21709;&#30340;&#29615;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20026;&#22522;&#20110;LLM&#30340;&#20462;&#27491;&#20195;&#29702;&#35782;&#21035;&#39640;&#36136;&#37327;&#30340;ICL&#31034;&#20363;&#65292;&#20854;&#20013;&#20215;&#20540;&#24433;&#21709;&#20989;&#25968;&#34913;&#37327;&#35848;&#21028;&#32467;&#26524;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#31574;&#30053;&#23398;&#20064;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#23454;&#35777;&#35777;&#25454;&#26469;&#35777;&#26126;&#20854;&#22312;&#19977;&#20010;&#19981;&#21516;&#20027;&#39064;&#30340;&#35848;&#21028;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;LLM&#20195;&#29702;&#20197;&#20943;&#36731;&#22810;&#20195;&#29702;&#35774;&#32622;&#19979;&#35848;&#21028;&#20013;&#30340;&#31038;&#20132;&#35268;&#33539;&#36829;&#21453;&#12290;&#25105;&#20204;&#36890;&#36807;&#35753;&#20004;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25198;&#28436;&#27599;&#27425;&#23545;&#35805;&#20013;&#30340;&#20004;&#21517;&#35848;&#21028;&#32773;&#26469;&#27169;&#25311;&#29616;&#23454;&#19990;&#30028;&#35848;&#21028;&#12290;&#31532;&#19977;&#20010;LLM&#20805;&#24403;&#20462;&#27491;&#20195;&#29702;&#65292;&#37325;&#26032;&#32534;&#20889;&#36829;&#21453;&#35268;&#33539;&#30340;&#35805;&#35821;&#20197;&#25913;&#21892;&#35848;&#21028;&#32467;&#26524;&#12290;&#30001;&#20110;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#20219;&#21153;&#65292;&#19981;&#23384;&#22312;&#25163;&#21160;&#26500;&#24314;&#30340;&#25968;&#25454;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20215;&#20540;&#24433;&#21709;&#30340;&#29615;&#22659;&#23398;&#20064;&#65288;ICL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20026;&#22522;&#20110;LLM&#30340;&#20462;&#27491;&#20195;&#29702;&#35782;&#21035;&#39640;&#36136;&#37327;&#30340;ICL&#31034;&#20363;&#65292;&#20854;&#20013;&#20215;&#20540;&#24433;&#21709;&#20989;&#25968;&#34913;&#37327;&#35848;&#21028;&#32467;&#26524;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#31574;&#30053;&#23398;&#20064;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#23454;&#35777;&#35777;&#25454;&#26469;&#35777;&#26126;&#20854;&#22312;&#19977;&#20010;&#19981;&#21516;&#20027;&#39064;&#30340;&#35848;&#21028;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#21363;&#20135;&#21697;&#38144;&#21806;&#12289;&#25151;&#20215;&#21644;&#34218;&#36164;&#35848;&#21028;&#12290;&#28304;&#20195;&#30721;&#21644;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#23558;&#22312;&#25509;&#21463;&#21518;&#20844;&#24320;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we aim to develop LLM agents to mitigate social norm violations in negotiations in a multi-agent setting. We simulate real-world negotiations by letting two large Language Models (LLMs) play the roles of two negotiators in each conversation. A third LLM acts as a remediation agent to rewrite utterances violating norms for improving negotiation outcomes. As it is a novel task, no manually constructed data is available. To address this limitation, we introduce a value impact based In-Context Learning (ICL) method to identify high-quality ICL examples for the LLM-based remediation agents, where the value impact function measures the quality of negotiation outcomes. We show the connection of this method to policy learning and provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different topics: product sale, housing price, and salary negotiation. The source code and the generated dataset will be publicly available upon acceptance.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#39064;&#35789;&#23884;&#20837;&#20462;&#25913;&#26694;&#26550;&#65288;SWEA&#65289;&#65292;&#36890;&#36807;&#22312;&#25512;&#29702;&#38454;&#27573;&#20462;&#25913;&#20027;&#39064;&#30340;&#34920;&#31034;&#26469;&#32534;&#36753;&#30693;&#35782;&#65292;&#20445;&#25252;&#27169;&#22411;&#30340;&#21407;&#22987;&#26435;&#37325;&#65292;&#36991;&#20813;&#19981;&#21487;&#36870;&#30340;&#25439;&#23475;&#21644;&#39069;&#22806;&#30340;&#25512;&#29702;&#24320;&#38144;&#12290;</title><link>https://arxiv.org/abs/2401.17809</link><description>&lt;p&gt;
SWEA:&#36890;&#36807;&#20027;&#39064;&#35789;&#23884;&#20837;&#20462;&#25913;&#25913;&#21464;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20107;&#23454;&#30693;&#35782;
&lt;/p&gt;
&lt;p&gt;
SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17809
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#39064;&#35789;&#23884;&#20837;&#20462;&#25913;&#26694;&#26550;&#65288;SWEA&#65289;&#65292;&#36890;&#36807;&#22312;&#25512;&#29702;&#38454;&#27573;&#20462;&#25913;&#20027;&#39064;&#30340;&#34920;&#31034;&#26469;&#32534;&#36753;&#30693;&#35782;&#65292;&#20445;&#25252;&#27169;&#22411;&#30340;&#21407;&#22987;&#26435;&#37325;&#65292;&#36991;&#20813;&#19981;&#21487;&#36870;&#30340;&#25439;&#23475;&#21644;&#39069;&#22806;&#30340;&#25512;&#29702;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#32534;&#36753;&#36817;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#30446;&#21069;&#30340;&#27169;&#22411;&#32534;&#36753;&#26041;&#27861;&#20027;&#35201;&#28041;&#21450;&#20462;&#25913;&#27169;&#22411;&#21442;&#25968;&#25110;&#21521;&#29616;&#26377;&#27169;&#22411;&#28155;&#21152;&#38468;&#21152;&#27169;&#22359;&#12290;&#28982;&#32780;&#65292;&#21069;&#32773;&#20250;&#23545;LLM&#36896;&#25104;&#19981;&#21487;&#36870;&#30340;&#24433;&#21709;&#65292;&#32780;&#21518;&#32773;&#20250;&#20135;&#29983;&#39069;&#22806;&#30340;&#25512;&#29702;&#24320;&#38144;&#65292;&#24182;&#19988;&#27169;&#31946;&#30340;&#21521;&#37327;&#21305;&#37197;&#24182;&#19981;&#24635;&#26159;&#21487;&#38752;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#20027;&#39064;&#35789;&#23884;&#20837;&#20462;&#25913;&#65288;SWEA&#65289;&#26694;&#26550;&#65292;&#23427;&#22312;&#25512;&#29702;&#38454;&#27573;&#20462;&#25913;&#20027;&#39064;&#30340;&#34920;&#31034;&#65292;&#24182;&#23454;&#29616;&#32534;&#36753;&#30693;&#35782;&#30340;&#30446;&#26631;&#12290;SWEA&#22312;&#27169;&#22411;&#22806;&#37096;&#20351;&#29992;&#31934;&#30830;&#30340;&#20851;&#38190;&#21305;&#37197;&#65292;&#24182;&#36827;&#34892;&#21487;&#38752;&#30340;&#20027;&#39064;&#35789;&#23884;&#20837;&#20462;&#25913;&#65292;&#20174;&#32780;&#20445;&#25252;&#27169;&#22411;&#30340;&#21407;&#22987;&#26435;&#37325;&#32780;&#19981;&#22686;&#21152;&#25512;&#29702;&#24320;&#38144;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20248;&#21270;&#25233;&#21046;&#34701;&#21512;&#26041;&#27861;&#65292;&#39318;&#20808;&#20248;&#21270;&#32534;&#36753;&#30446;&#26631;&#30340;&#23884;&#20837;&#21521;&#37327;&#65292;&#28982;&#21518;&#25233;&#21046;&#30693;&#35782;&#23884;&#20837;&#32500;&#24230;&#65288;KED&#65289;&#20197;&#33719;&#24471;&#26368;&#32456;&#34701;&#21512;&#30340;&#23884;&#20837;&#12290;&#25105;&#20204;&#22240;&#27492;&#25552;&#20986;&#20102;SWEAOS&#20803;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model editing has recently gained widespread attention. Current model editing methods primarily involve modifying model parameters or adding additional modules to the existing model. However, the former causes irreversible damage to LLMs, while the latter incurs additional inference overhead and fuzzy vector matching is not always reliable. To address these issues, we propose an expandable Subject Word Embedding Altering (SWEA) framework, which modifies the representation of subjects and achieve the goal of editing knowledge during the inference stage. SWEA uses precise key matching outside the model and performs reliable subject word embedding altering, thus protecting the original weights of the model without increasing inference overhead. We then propose optimizing then suppressing fusion method, which first optimizes the embedding vector for the editing target and then suppresses the Knowledge Embedding Dimension (KED) to obtain the final fused embedding. We thus propose SWEAOS met
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#24494;&#35843;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#31574;&#30053;&#22312;&#35299;&#20915;&#36328;&#35821;&#35328;&#20219;&#21153;&#26102;&#30340;&#34920;&#29616;&#65292;&#35780;&#20272;&#20102;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#31243;&#24230;&#21644;&#36716;&#31227;&#30340;&#25104;&#21151;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.06089</link><description>&lt;p&gt;
&#22312;&#36328;&#35821;&#35328;&#36716;&#31227;&#33539;&#24335;&#20013;&#27979;&#37327;&#28798;&#38590;&#24615;&#36951;&#24536;&#65306;&#25506;&#32034;&#35843;&#20248;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Measuring Catastrophic Forgetting in Cross-Lingual Transfer Paradigms: Exploring Tuning Strategies. (arXiv:2309.06089v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06089
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#24494;&#35843;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#31574;&#30053;&#22312;&#35299;&#20915;&#36328;&#35821;&#35328;&#20219;&#21153;&#26102;&#30340;&#34920;&#29616;&#65292;&#35780;&#20272;&#20102;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#31243;&#24230;&#21644;&#36716;&#31227;&#30340;&#25104;&#21151;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36328;&#35821;&#35328;&#36716;&#31227;&#26159;&#19968;&#31181;&#35299;&#20915;&#36164;&#28304;&#21294;&#20047;&#35821;&#35328;&#20219;&#21153;&#30340;&#26377;&#24076;&#26395;&#30340;&#25216;&#26415;&#12290;&#22312;&#36825;&#20010;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20004;&#31181;&#19982;&#38646;&#23556;&#21644;&#20840;&#23556;&#23398;&#20064;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36328;&#35821;&#35328;&#35774;&#32622;&#19979;&#30340;&#24494;&#35843;&#26041;&#27861;&#12290;&#20316;&#20026;&#24494;&#35843;&#31574;&#30053;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#21442;&#25968;&#25928;&#29575;&#36866;&#37197;&#22120;&#26041;&#27861;&#19982;&#25152;&#26377;&#21442;&#25968;&#24494;&#35843;&#12290;&#20316;&#20026;&#36328;&#35821;&#35328;&#36716;&#31227;&#31574;&#30053;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20351;&#29992;&#27599;&#20010;&#35821;&#35328;&#20381;&#27425;&#30340;&#20013;&#38388;&#35757;&#32451;&#65288;IT&#65289;&#21644;&#22312;&#24494;&#35843;&#30340;&#39564;&#35777;&#38454;&#27573;&#24050;&#32463;&#20351;&#29992;&#30446;&#26631;&#35821;&#35328;&#30340;&#36328;&#35821;&#35328;&#39564;&#35777;&#65288;CLV&#65289;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#36716;&#31227;&#30340;&#25104;&#21151;&#31243;&#24230;&#20197;&#21450;&#28304;&#35821;&#35328;&#20013;&#30001;&#20110;&#36328;&#35821;&#35328;&#36716;&#31227;&#32780;&#23548;&#33268;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#31243;&#24230;&#65292;&#21363;&#22312;&#23398;&#20064;&#19981;&#21516;&#35821;&#35328;&#20013;&#30340;&#26032;&#20449;&#24687;&#26102;&#20043;&#21069;&#33719;&#24471;&#30340;&#30693;&#35782;&#25439;&#22833;&#20102;&#22810;&#23569;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#30340;&#20998;&#31867;&#38382;&#39064;&#19978;&#65292;&#21253;&#25324;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#21644;&#20135;&#21697;&#35780;&#35770;&#65292;&#20998;&#21035;&#21253;&#21547;&#20102;&#22810;&#20010;&#35821;&#31181;&#25968;&#25454;&#38598;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The cross-lingual transfer is a promising technique to solve tasks in less-resourced languages. In this empirical study, we compare two fine-tuning approaches combined with zero-shot and full-shot learning approaches for large language models in a cross-lingual setting. As fine-tuning strategies, we compare parameter-efficient adapter methods with fine-tuning of all parameters. As cross-lingual transfer strategies, we compare the intermediate-training (\textit{IT}) that uses each language sequentially and cross-lingual validation (\textit{CLV}) that uses a target language already in the validation phase of fine-tuning. We assess the success of transfer and the extent of catastrophic forgetting in a source language due to cross-lingual transfer, i.e., how much previously acquired knowledge is lost when we learn new information in a different language. The results on two different classification problems, hate speech detection and product reviews, each containing datasets in several lang
&lt;/p&gt;</description></item></channel></rss>