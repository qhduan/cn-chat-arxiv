<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#26597;&#35810;&#24615;&#33021;&#39044;&#27979;&#26694;&#26550;&#65292;&#33021;&#22815;&#35299;&#20915;&#20808;&#21069;&#26041;&#27861;&#20013;&#23545;&#19981;&#21516;IR&#35780;&#20272;&#25351;&#26631;&#20934;&#30830;&#24615;&#21644;&#35299;&#37322;&#24615;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2404.01012</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#26469;&#39044;&#27979;&#26597;&#35810;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Query Performance Prediction using Relevance Judgments Generated by Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01012
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#26597;&#35810;&#24615;&#33021;&#39044;&#27979;&#26694;&#26550;&#65292;&#33021;&#22815;&#35299;&#20915;&#20808;&#21069;&#26041;&#27861;&#20013;&#23545;&#19981;&#21516;IR&#35780;&#20272;&#25351;&#26631;&#20934;&#30830;&#24615;&#21644;&#35299;&#37322;&#24615;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#24615;&#33021;&#39044;&#27979;&#65288;QPP&#65289;&#26088;&#22312;&#20272;&#35745;&#25628;&#32034;&#31995;&#32479;&#23545;&#26597;&#35810;&#30340;&#26816;&#32034;&#36136;&#37327;&#65292;&#32780;&#26080;&#38656;&#20154;&#24037;&#30456;&#20851;&#24615;&#21028;&#26029;&#12290;&#20808;&#21069;&#30340;QPP&#26041;&#27861;&#36890;&#24120;&#36820;&#22238;&#21333;&#20010;&#26631;&#37327;&#20540;&#65292;&#24182;&#19981;&#35201;&#27714;&#39044;&#27979;&#20540;&#25509;&#36817;&#29305;&#23450;&#30340;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#35780;&#20272;&#25351;&#26631;&#65292;&#20174;&#32780;&#23548;&#33268;&#20197;&#19979;&#26576;&#20123;&#32570;&#28857;&#65306;&#65288;i&#65289;&#21333;&#20010;&#26631;&#37327;&#26080;&#27861;&#20934;&#30830;&#34920;&#31034;&#19981;&#21516;&#30340;IR&#35780;&#20272;&#25351;&#26631;&#65292;&#29305;&#21035;&#26159;&#24403;&#24230;&#37327;&#19981;&#39640;&#24230;&#30456;&#20851;&#26102;&#65292;&#65288;ii&#65289;&#21333;&#20010;&#26631;&#37327;&#38480;&#21046;&#20102;QPP&#26041;&#27861;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#22240;&#20026;&#20165;&#20351;&#29992;&#26631;&#37327;&#26080;&#27861;&#35299;&#37322;QPP&#32467;&#26524;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;QPP&#26694;&#26550;&#65288;QPP-GenRE&#65289;&#65292;&#23558;QPP&#20998;&#35299;&#20026;&#29420;&#31435;&#30340;&#23376;&#20219;&#21153;&#65292;&#21363;&#23545;&#25490;&#21517;&#21015;&#34920;&#20013;&#27599;&#20010;&#39033;&#30446;&#23545;&#32473;&#23450;&#26597;&#35810;&#30340;&#30456;&#20851;&#24615;&#36827;&#34892;&#21028;&#26029;&#12290;&#36825;&#26679;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#29983;&#25104;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#26469;&#39044;&#27979;&#20219;&#20309;IR&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01012v1 Announce Type: cross  Abstract: Query performance prediction (QPP) aims to estimate the retrieval quality of a search system for a query without human relevance judgments. Previous QPP methods typically return a single scalar value and do not require the predicted values to approximate a specific information retrieval (IR) evaluation measure, leading to certain drawbacks: (i) a single scalar is insufficient to accurately represent different IR evaluation measures, especially when metrics do not highly correlate, and (ii) a single scalar limits the interpretability of QPP methods because solely using a scalar is insufficient to explain QPP results. To address these issues, we propose a QPP framework using automatically generated relevance judgments (QPP-GenRE), which decomposes QPP into independent subtasks of judging the relevance of each item in a ranked list to a given query. This allows us to predict any IR evaluation measure using the generated relevance judgment
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;MELoRA&#65292;&#19968;&#31181;&#36855;&#20320;&#38598;&#25104;&#20302;&#31209;&#36866;&#37197;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#26356;&#23569;&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#21516;&#26102;&#20445;&#25345;&#26356;&#39640;&#30340;&#31209;&#65292;&#20174;&#32780;&#25552;&#20379;&#25913;&#36827;&#30340;&#24615;&#33021;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.17263</link><description>&lt;p&gt;
&#36855;&#20320;&#38598;&#25104;&#20302;&#31209;&#36866;&#37197;&#22120;&#29992;&#20110;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17263
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;MELoRA&#65292;&#19968;&#31181;&#36855;&#20320;&#38598;&#25104;&#20302;&#31209;&#36866;&#37197;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#26356;&#23569;&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#21516;&#26102;&#20445;&#25345;&#26356;&#39640;&#30340;&#31209;&#65292;&#20174;&#32780;&#25552;&#20379;&#25913;&#36827;&#30340;&#24615;&#33021;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#65288;PEFT&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#23450;&#21046;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27969;&#34892;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;&#27169;&#22411;&#35268;&#27169;&#21644;&#20219;&#21153;&#22810;&#26679;&#24615;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#12290;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#22522;&#20110;&#36825;&#26679;&#19968;&#20010;&#24605;&#24819;&#65292;&#21363;&#36866;&#24212;&#36807;&#31243;&#22312;&#26412;&#36136;&#19978;&#26159;&#20302;&#32500;&#30340;&#65292;&#21363;&#21487;&#20197;&#29992;&#30456;&#23545;&#36739;&#23569;&#30340;&#21442;&#25968;&#34920;&#31034;&#37325;&#35201;&#30340;&#27169;&#22411;&#21464;&#21270;&#12290;&#28982;&#32780;&#65292;&#19982;&#20840;&#21442;&#25968;&#24494;&#35843;&#30456;&#27604;&#65292;&#38477;&#20302;&#31209;&#20250;&#36935;&#21040;&#29305;&#23450;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;MELoRA&#65292;&#19968;&#31181;&#36855;&#20320;&#38598;&#25104;&#20302;&#31209;&#36866;&#37197;&#22120;&#65292;&#20351;&#29992;&#26356;&#23569;&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#21516;&#26102;&#20445;&#25345;&#26356;&#39640;&#30340;&#31209;&#65292;&#20174;&#32780;&#25552;&#20379;&#25913;&#36827;&#30340;&#24615;&#33021;&#28508;&#21147;&#12290;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#20923;&#32467;&#21407;&#22987;&#30340;&#39044;&#35757;&#32451;&#26435;&#37325;&#65292;&#24182;&#35757;&#32451;&#19968;&#32452;&#20165;&#20855;&#26377;&#23569;&#37327;&#21442;&#25968;&#30340;&#36855;&#20320;LoRA&#12290;&#36825;&#21487;&#20197;&#25429;&#25417;&#36855;&#20320;LoRA&#20043;&#38388;&#30340;&#37325;&#35201;&#22810;&#26679;&#24615;&#31243;&#24230;&#65292;&#20174;&#32780;&#20419;&#36827;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17263v1 Announce Type: new  Abstract: Parameter-efficient fine-tuning (PEFT) is a popular method for tailoring pre-trained large language models (LLMs), especially as the models' scale and the diversity of tasks increase. Low-rank adaptation (LoRA) is based on the idea that the adaptation process is intrinsically low-dimensional, i.e., significant model changes can be represented with relatively few parameters. However, decreasing the rank encounters challenges with generalization errors for specific tasks when compared to full-parameter fine-tuning. We present MELoRA, a mini-ensemble low-rank adapters that uses fewer trainable parameters while maintaining a higher rank, thereby offering improved performance potential. The core idea is to freeze original pretrained weights and train a group of mini LoRAs with only a small number of parameters. This can capture a significant degree of diversity among mini LoRAs, thus promoting better generalization ability. We conduct a theor
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Prejudice-Caprice Framework&#65288;PCF&#65289;&#26469;&#20840;&#38754;&#34913;&#37327;LLMs&#20013;&#30340;&#27495;&#35270;&#65292;&#32771;&#34385;&#20102;&#23427;&#20204;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#30340;&#19968;&#36143;&#20559;&#35265;&#20559;&#22909;&#21644;&#20559;&#22909;&#21464;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.15481</link><description>&lt;p&gt;
&#20559;&#35265;&#21644;&#21453;&#22797;&#26080;&#24120;&#65306;&#34913;&#37327;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#31038;&#20250;&#27495;&#35270;&#30340;&#32479;&#35745;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Prejudice and Caprice: A Statistical Framework for Measuring Social Discrimination in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15481
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Prejudice-Caprice Framework&#65288;PCF&#65289;&#26469;&#20840;&#38754;&#34913;&#37327;LLMs&#20013;&#30340;&#27495;&#35270;&#65292;&#32771;&#34385;&#20102;&#23427;&#20204;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#30340;&#19968;&#36143;&#20559;&#35265;&#20559;&#22909;&#21644;&#20559;&#22909;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15481v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31038;&#20250;&#36816;&#33829;&#20013;&#30340;&#26085;&#30410;&#34701;&#21512;&#21152;&#21095;&#20102;&#23427;&#20204;&#23545;&#32463;&#27982;&#12289;&#27861;&#24459;&#12289;&#25945;&#32946;&#21644;&#21307;&#30103;&#31561;&#37325;&#35201;&#39046;&#22495;&#20915;&#31574;&#30340;&#24433;&#21709;&#65292;&#24341;&#21457;&#20102;&#20844;&#20247;&#23545;&#36825;&#20123;&#27169;&#22411;&#28041;&#21450;&#27495;&#35270;&#23433;&#20840;&#21644;&#21487;&#38752;&#24615;&#30340;&#25285;&#24551;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#27495;&#35270;&#27979;&#37327;&#26694;&#26550;&#20165;&#35780;&#20272;LLMs&#30340;&#24179;&#22343;&#27495;&#35270;&#34892;&#20026;&#65292;&#24448;&#24448;&#30001;&#20110;&#24573;&#35270;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#23548;&#33268;&#27495;&#35270;&#30340;&#22240;&#32032;&#65292;&#21363;LLMs&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#30340;&#39044;&#27979;&#21464;&#21270;&#32780;&#21464;&#24471;&#19981;&#36275;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Prejudice-Caprice Framework&#65288;PCF&#65289;&#65292;&#36890;&#36807;&#32771;&#34385;LLMs&#30340;&#19968;&#36143;&#20559;&#35265;&#20559;&#22909;&#21644;&#22312;&#22810;&#26679;&#19978;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15481v1 Announce Type: new  Abstract: The growing integration of large language models (LLMs) into social operations amplifies their impact on decisions in crucial areas such as economics, law, education, and healthcare, raising public concerns about these models' discrimination-related safety and reliability. However, prior discrimination measuring frameworks solely assess the average discriminatory behavior of LLMs, often proving inadequate due to the overlook of an additional discrimination-leading factor, i.e., the LLMs' prediction variation across diverse contexts. In this work, we present the Prejudice-Caprice Framework (PCF) that comprehensively measures discrimination in LLMs by considering both their consistently biased preference and preference variation across diverse contexts. Specifically, we mathematically dissect the aggregated contextualized discrimination risk of LLMs into prejudice risk, originating from LLMs' persistent prejudice, and caprice risk, stemmin
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#32622;&#20449;&#24230;&#35780;&#20272;&#30340;&#20840;&#38754;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#19994;&#22810;&#35821;&#35328;&#38382;&#31572;&#25968;&#25454;&#38598;&#65292;&#24182;&#30740;&#31350;&#20102;&#36825;&#20123;&#32622;&#20449;&#24230;&#20998;&#25968;&#22914;&#20309;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#65292;&#26368;&#32456;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#35821;&#35328;&#32622;&#20449;&#24230;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.13606</link><description>&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#32622;&#20449;&#24230;&#35780;&#20272;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13606
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#32622;&#20449;&#24230;&#35780;&#20272;&#30340;&#20840;&#38754;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#19994;&#22810;&#35821;&#35328;&#38382;&#31572;&#25968;&#25454;&#38598;&#65292;&#24182;&#30740;&#31350;&#20102;&#36825;&#20123;&#32622;&#20449;&#24230;&#20998;&#25968;&#22914;&#20309;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#65292;&#26368;&#32456;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#35821;&#35328;&#32622;&#20449;&#24230;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#24187;&#35273;&#24182;&#22312;&#39044;&#27979;&#20013;&#34920;&#29616;&#36807;&#20110;&#33258;&#20449;&#30340;&#20542;&#21521;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#20854;&#21487;&#38752;&#24615;&#30340;&#25285;&#24551;&#12290;&#34920;&#26126;&#27169;&#22411;&#21709;&#24212;&#30340;&#21487;&#20449;&#24230;&#25110;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#23545;&#20110;&#24320;&#21457;&#21487;&#38752;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#12290;&#30446;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#33521;&#35821;&#20013;LLM&#30340;&#32622;&#20449;&#24230;&#20272;&#35745;&#19978;&#65292;&#22312;&#20854;&#20182;&#24191;&#27867;&#20351;&#29992;&#30340;&#35821;&#35328;&#26041;&#38754;&#20173;&#23384;&#22312;&#31354;&#30333;&#65292;&#38459;&#30861;&#20102;&#21487;&#38752;AI&#24212;&#29992;&#30340;&#20840;&#29699;&#21457;&#23637;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#23545;LLM&#19978;&#30340;&#22810;&#35821;&#35328;&#32622;&#20449;&#24230;&#35780;&#20272;&#65288;MlingConf&#65289;&#30340;&#20840;&#38754;&#35843;&#26597;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#32463;&#36807;&#35814;&#32454;&#26816;&#26597;&#30340;&#19987;&#19994;&#22810;&#35821;&#35328;&#38382;&#31572;&#25968;&#25454;&#38598;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#32622;&#20449;&#24230;&#20272;&#35745;&#30340;&#24615;&#33021;&#65292;&#24182;&#30740;&#31350;&#36825;&#20123;&#32622;&#20449;&#24230;&#20998;&#25968;&#22914;&#20309;&#36890;&#36807;&#36328;&#19981;&#21516;&#35821;&#35328;&#30340;&#33258;&#25105;&#23436;&#21892;&#26469;&#22686;&#24378;LLM&#30340;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#35821;&#35328;&#32622;&#20449;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13606v1 Announce Type: new  Abstract: The tendency of Large Language Models to generate hallucinations and exhibit overconfidence in predictions raises concerns regarding their reliability. Confidence or uncertainty estimations indicating the extent of trustworthiness of a model's response are essential to developing reliable AI systems. Current research primarily focuses on LLM confidence estimations in English, remaining a void for other widely used languages and impeding the global development of reliable AI applications. This paper introduces a comprehensive investigation of Multi-lingual confidence estimation (MlingConf) on LLMs. First, we introduce an elaborated and expert-checked multilingual QA dataset. Second, we delve into the performance of confidence estimations and examine how these confidence scores can enhance LLM performance through self-refinement across diverse languages. Finally, we propose a cross-lingual confidence estimation method to achieve more preci
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32479;&#19968;&#30340;&#22522;&#20110;&#20998;&#31867;&#23398;&#25351;&#23548;&#30340;&#25351;&#23548;&#35843;&#25972;&#26694;&#26550;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29616;&#26377;&#20998;&#31867;&#23398;&#36827;&#34892;&#23454;&#20307;&#20851;&#31995;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#23454;&#20307;&#38598;&#25193;&#23637;&#12289;&#20998;&#31867;&#23398;&#25193;&#23637;&#21644;&#31181;&#23376;&#24341;&#23548;&#20998;&#31867;&#23398;&#26500;&#24314;&#19977;&#20010;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.13405</link><description>&lt;p&gt;
&#19968;&#20010;&#32479;&#19968;&#30340;&#22522;&#20110;&#20998;&#31867;&#23398;&#25351;&#23548;&#30340;&#23454;&#20307;&#38598;&#25193;&#23637;&#21644;&#20998;&#31867;&#23398;&#25193;&#23637;&#30340;&#25351;&#23548;&#35843;&#25972;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unified Taxonomy-Guided Instruction Tuning Framework for Entity Set Expansion and Taxonomy Expansion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13405
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32479;&#19968;&#30340;&#22522;&#20110;&#20998;&#31867;&#23398;&#25351;&#23548;&#30340;&#25351;&#23548;&#35843;&#25972;&#26694;&#26550;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29616;&#26377;&#20998;&#31867;&#23398;&#36827;&#34892;&#23454;&#20307;&#20851;&#31995;&#24494;&#35843;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#23454;&#20307;&#38598;&#25193;&#23637;&#12289;&#20998;&#31867;&#23398;&#25193;&#23637;&#21644;&#31181;&#23376;&#24341;&#23548;&#20998;&#31867;&#23398;&#26500;&#24314;&#19977;&#20010;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#38598;&#25193;&#23637;&#12289;&#20998;&#31867;&#23398;&#25193;&#23637;&#21644;&#31181;&#23376;&#24341;&#23548;&#20998;&#31867;&#23398;&#26500;&#24314;&#26159;&#19977;&#20010;&#20195;&#34920;&#24615;&#20219;&#21153;&#65292;&#21487;&#20197;&#29992;&#26469;&#33258;&#21160;&#21521;&#29616;&#26377;&#20998;&#31867;&#23398;&#22635;&#20805;&#26032;&#23454;&#20307;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#24322;&#36136;&#25216;&#26415;&#20998;&#21035;&#35299;&#20915;&#36825;&#20123;&#20219;&#21153;&#65292;&#32570;&#20047;&#32479;&#19968;&#30340;&#35270;&#35282;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#20998;&#31867;&#23398;&#32467;&#26500;&#30340;&#35270;&#35282;&#30830;&#35748;&#20102;&#36825;&#20123;&#20219;&#21153;&#25152;&#38656;&#30340;&#20849;&#21516;&#20851;&#38190;&#25216;&#33021;&#8212;&#8212;&#25214;&#21040;&#8220;&#20804;&#24351;&#8221;&#21644;&#25214;&#21040;&#8220;&#29238;&#27597;&#8221;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#22522;&#20110;&#20998;&#31867;&#23398;&#25351;&#23548;&#30340;&#25351;&#23548;&#35843;&#25972;&#26694;&#26550;&#26469;&#20849;&#21516;&#35299;&#20915;&#36825;&#19977;&#20010;&#20219;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#26377;&#20998;&#31867;&#23398;&#20316;&#20026;&#20016;&#23500;&#30340;&#23454;&#20307;&#20851;&#31995;&#28304;&#65292;&#25105;&#20204;&#21033;&#29992;&#25351;&#23548;&#35843;&#25972;&#26469;&#24494;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#29983;&#25104;&#29238;&#27597;&#21644;&#20804;&#24351;&#23454;&#20307;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;TaxoInstruct&#30340;&#26377;&#25928;&#24615;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#39033;&#25351;&#26631;&#19978;&#22343;&#20248;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13405v1 Announce Type: new  Abstract: Entity Set Expansion, Taxonomy Expansion, and Seed-Guided Taxonomy Construction are three representative tasks that can be used to automatically populate an existing taxonomy with new entities. However, previous approaches often address these tasks separately with heterogeneous techniques, lacking a unified perspective. To tackle this issue, in this paper, we identify the common key skills needed for these tasks from the view of taxonomy structures -- finding 'siblings' and finding 'parents' -- and propose a unified taxonomy-guided instruction tuning framework to jointly solve the three tasks. To be specific, by leveraging the existing taxonomy as a rich source of entity relationships, we utilize instruction tuning to fine-tune a large language model to generate parent and sibling entities. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of TaxoInstruct, which outperforms task-specific baselines across 
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#20013;&#30340;&#34920;&#29616;&#65292;&#25581;&#31034;&#20102;&#20854;&#23384;&#22312;&#30340;&#20559;&#22909;&#24615;&#20559;&#24046;&#38382;&#39064;&#65292;&#21363;&#23545;&#29305;&#23450;&#31574;&#30053;&#30340;&#36807;&#39640;&#20559;&#22909;&#20250;&#38459;&#30861;&#26377;&#25928;&#30340;&#24773;&#24863;&#25903;&#25345;&#12290;</title><link>https://arxiv.org/abs/2402.13211</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#25104;&#20026;&#33391;&#22909;&#30340;&#24773;&#24863;&#25903;&#25345;&#32773;&#21527;&#65311;&#20943;&#36731;&#23545;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#20013;&#30340;&#20559;&#22909;&#24615;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13211
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#20013;&#30340;&#34920;&#29616;&#65292;&#25581;&#31034;&#20102;&#20854;&#23384;&#22312;&#30340;&#20559;&#22909;&#24615;&#20559;&#24046;&#38382;&#39064;&#65292;&#21363;&#23545;&#29305;&#23450;&#31574;&#30053;&#30340;&#36807;&#39640;&#20559;&#22909;&#20250;&#38459;&#30861;&#26377;&#25928;&#30340;&#24773;&#24863;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#65288;ESC&#65289;&#26159;&#19968;&#39033;&#26088;&#22312;&#36890;&#36807;&#26085;&#24120;&#23545;&#35805;&#32531;&#35299;&#20010;&#20307;&#24773;&#24863;&#22256;&#25200;&#30340;&#20219;&#21153;&#12290;&#37492;&#20110;&#20854;&#22266;&#26377;&#30340;&#22797;&#26434;&#24615;&#21644;&#38750;&#30452;&#35273;&#24615;&#36136;&#65292;ESConv&#25968;&#25454;&#38598;&#34701;&#20837;&#20102;&#25903;&#25345;&#31574;&#30053;&#65292;&#20197;&#20419;&#36827;&#29983;&#25104;&#36866;&#24403;&#30340;&#22238;&#24212;&#12290;&#26368;&#36817;&#65292;&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20855;&#26377;&#21331;&#36234;&#30340;&#23545;&#35805;&#33021;&#21147;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#23427;&#20204;&#22312;&#25552;&#20379;&#26377;&#29992;&#30340;&#24773;&#24863;&#25903;&#25345;&#26041;&#38754;&#32463;&#24120;&#36935;&#21040;&#22256;&#38590;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#39318;&#20808;&#20998;&#26512;&#20102;LLMs&#22312;ESConv&#19978;&#30340;&#32467;&#26524;&#65292;&#25581;&#31034;&#20102;&#22312;&#36873;&#25321;&#27491;&#30830;&#31574;&#30053;&#21644;&#23545;&#29305;&#23450;&#31574;&#30053;&#30340;&#26174;&#33879;&#20559;&#22909;&#26041;&#38754;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#20010;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;LLMs&#22266;&#26377;&#20559;&#22909;&#23545;&#25552;&#20379;&#24773;&#24863;&#25903;&#25345;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#23637;&#29616;&#20986;&#23545;&#29305;&#23450;&#31574;&#30053;&#30340;&#39640;&#20559;&#22909;&#20250;&#38459;&#30861;&#26377;&#25928;&#30340;&#24773;&#24863;&#25903;&#25345;&#65292;&#21152;&#21095;&#20854;&#22312;&#39044;&#27979;&#36866;&#24403;&#31574;&#30053;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13211v1 Announce Type: new  Abstract: Emotional Support Conversation (ESC) is a task aimed at alleviating individuals' emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently, despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support. Hence, this work initially analyzes the results of LLMs on ESConv, revealing challenges in selecting the correct strategy and a notable preference for a specific strategy. Motivated by these, we explore the impact of the inherent preference in LLMs on providing emotional support, and consequently, we observe that exhibiting high preference for specific strategies hinders effective emotional support, aggravating its robustness in predicting the appropriate strategy. Moreover
&lt;/p&gt;</description></item><item><title>&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#25915;&#20987;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35780;&#20272;&#65292;&#25581;&#31034;&#20102;&#19968;&#31181;&#32469;&#36807;&#23433;&#20840;&#25514;&#26045;&#30340;&#19981;&#31283;&#23450;&#28431;&#27934;&#12290;&#26412;&#30740;&#31350;&#26159;&#39318;&#27425;&#23545;&#22810;&#31181;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#36827;&#34892;&#22823;&#35268;&#27169;&#27979;&#37327;&#65292;&#23454;&#39564;&#35777;&#26126;&#20248;&#21270;&#30340;&#36234;&#29425;&#25552;&#31034;&#33021;&#22815;&#25345;&#32493;&#36798;&#21040;&#26368;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.05668</link><description>&lt;p&gt;
&#23545;LLMs&#30340;&#36234;&#29425;&#25915;&#20987;&#30340;&#32508;&#21512;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Comprehensive Assessment of Jailbreak Attacks Against LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05668
&lt;/p&gt;
&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#25915;&#20987;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35780;&#20272;&#65292;&#25581;&#31034;&#20102;&#19968;&#31181;&#32469;&#36807;&#23433;&#20840;&#25514;&#26045;&#30340;&#19981;&#31283;&#23450;&#28431;&#27934;&#12290;&#26412;&#30740;&#31350;&#26159;&#39318;&#27425;&#23545;&#22810;&#31181;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#36827;&#34892;&#22823;&#35268;&#27169;&#27979;&#37327;&#65292;&#23454;&#39564;&#35777;&#26126;&#20248;&#21270;&#30340;&#36234;&#29425;&#25552;&#31034;&#33021;&#22815;&#25345;&#32493;&#36798;&#21040;&#26368;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#28389;&#29992;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24050;&#32463;&#37319;&#21462;&#20102;&#23433;&#20840;&#25514;&#26045;&#20197;&#30830;&#20445;LLMs&#31526;&#21512;&#31038;&#20250;&#20262;&#29702;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#20102;&#19968;&#31181;&#32469;&#36807;LLMs&#23433;&#20840;&#25514;&#26045;&#30340;&#19981;&#31283;&#23450;&#28431;&#27934;&#65292;&#34987;&#31216;&#20026;&#36234;&#29425;&#25915;&#20987;&#12290;&#36890;&#36807;&#24212;&#29992;&#25216;&#26415;&#65292;&#22914;&#35282;&#33394;&#25198;&#28436;&#22330;&#26223;&#12289;&#23545;&#25239;&#24615;&#26679;&#26412;&#25110;&#23545;&#23433;&#20840;&#30446;&#26631;&#30340;&#24494;&#22937;&#30772;&#22351;&#20316;&#20026;&#25552;&#31034;&#65292;LLMs&#21487;&#20197;&#20135;&#29983;&#19981;&#36866;&#24403;&#29978;&#33267;&#26377;&#23475;&#30340;&#22238;&#24212;&#12290;&#34429;&#28982;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#30740;&#31350;&#20102;&#20960;&#31181;&#36234;&#29425;&#25915;&#20987;&#30340;&#31867;&#21035;&#65292;&#20294;&#20182;&#20204;&#37117;&#26159;&#23396;&#31435;&#22320;&#36827;&#34892;&#30340;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#21508;&#31181;&#36234;&#29425;&#25915;&#20987;&#26041;&#27861;&#30340;&#39318;&#27425;&#22823;&#35268;&#27169;&#27979;&#37327;&#12290;&#25105;&#20204;&#38598;&#20013;&#22312;&#26469;&#33258;&#22235;&#20010;&#31867;&#21035;&#30340;13&#31181;&#23574;&#31471;&#36234;&#29425;&#26041;&#27861;&#12289;16&#31181;&#36829;&#35268;&#31867;&#21035;&#30340;160&#20010;&#38382;&#39064;&#20197;&#21450;&#20845;&#31181;&#27969;&#34892;&#30340;LLMs&#19978;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20248;&#21270;&#30340;&#36234;&#29425;&#25552;&#31034;&#22987;&#32456;&#33021;&#22815;&#36798;&#21040;&#26368;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#24182;&#34920;&#29616;&#20986;...
&lt;/p&gt;
&lt;p&gt;
Misuse of the Large Language Models (LLMs) has raised widespread concern. To address this issue, safeguards have been taken to ensure that LLMs align with social ethics. However, recent findings have revealed an unsettling vulnerability bypassing the safeguards of LLMs, known as jailbreak attacks. By applying techniques, such as employing role-playing scenarios, adversarial examples, or subtle subversion of safety objectives as a prompt, LLMs can produce an inappropriate or even harmful response. While researchers have studied several categories of jailbreak attacks, they have done so in isolation. To fill this gap, we present the first large-scale measurement of various jailbreak attack methods. We concentrate on 13 cutting-edge jailbreak methods from four categories, 160 questions from 16 violation categories, and six popular LLMs. Our extensive experimental results demonstrate that the optimized jailbreak prompts consistently achieve the highest attack success rates, as well as exhi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#35282;&#33394;&#25198;&#28436;&#30340;&#31995;&#32479;&#65292;&#21487;&#20197;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#36234;&#29425;&#65292;&#29992;&#20110;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#21335;&#36981;&#24490;&#24773;&#20917;&#12290;&#31995;&#32479;&#36890;&#36807;&#25910;&#38598;&#29616;&#26377;&#36234;&#29425;&#24182;&#23558;&#20854;&#32452;&#32455;&#25104;&#30693;&#35782;&#22270;&#26469;&#29983;&#25104;&#26032;&#30340;&#36234;&#29425;&#65292;&#35777;&#26126;&#20102;&#20854;&#39640;&#25928;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03299</link><description>&lt;p&gt;
GUARD: &#36890;&#36807;&#35282;&#33394;&#25198;&#28436;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#36234;&#29425;&#26469;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36981;&#24490;&#25351;&#21335;&#30340;&#21512;&#35268;&#24615;
&lt;/p&gt;
&lt;p&gt;
GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03299
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#35282;&#33394;&#25198;&#28436;&#30340;&#31995;&#32479;&#65292;&#21487;&#20197;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#36234;&#29425;&#65292;&#29992;&#20110;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#21335;&#36981;&#24490;&#24773;&#20917;&#12290;&#31995;&#32479;&#36890;&#36807;&#25910;&#38598;&#29616;&#26377;&#36234;&#29425;&#24182;&#23558;&#20854;&#32452;&#32455;&#25104;&#30693;&#35782;&#22270;&#26469;&#29983;&#25104;&#26032;&#30340;&#36234;&#29425;&#65292;&#35777;&#26126;&#20102;&#20854;&#39640;&#25928;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21457;&#29616;&#32469;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#23433;&#20840;&#36807;&#28388;&#21644;&#26377;&#23475;&#22238;&#24212;&#30340;"&#36234;&#29425;"&#24050;&#32463;&#40723;&#21169;&#31038;&#21306;&#37319;&#21462;&#23433;&#20840;&#25514;&#26045;&#12290;&#20854;&#20013;&#19968;&#20010;&#20027;&#35201;&#30340;&#23433;&#20840;&#25514;&#26045;&#26159;&#22312;&#21457;&#24067;&#20043;&#21069;&#29992;&#36234;&#29425;&#20027;&#21160;&#27979;&#35797;LLM&#12290;&#22240;&#27492;&#65292;&#36825;&#26679;&#30340;&#27979;&#35797;&#23558;&#38656;&#35201;&#19968;&#31181;&#33021;&#22815;&#22823;&#35268;&#27169;&#19988;&#39640;&#25928;&#22320;&#29983;&#25104;&#36234;&#29425;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#22312;&#36861;&#38543;&#19968;&#31181;&#26032;&#39062;&#32780;&#30452;&#35266;&#30340;&#31574;&#30053;&#19979;&#65292;&#20197;&#20154;&#31867;&#29983;&#25104;&#30340;&#26041;&#24335;&#26469;&#29983;&#25104;&#36234;&#29425;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35282;&#33394;&#25198;&#28436;&#31995;&#32479;&#65292;&#23558;&#22235;&#31181;&#19981;&#21516;&#35282;&#33394;&#20998;&#37197;&#32473;&#29992;&#25143;LLM&#65292;&#20197;&#20415;&#21327;&#20316;&#29983;&#25104;&#26032;&#30340;&#36234;&#29425;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25910;&#38598;&#29616;&#26377;&#30340;&#36234;&#29425;&#65292;&#24182;&#36890;&#36807;&#21477;&#23376;&#36880;&#21477;&#36827;&#34892;&#32858;&#31867;&#39057;&#29575;&#21644;&#35821;&#20041;&#27169;&#24335;&#30340;&#21010;&#20998;&#65292;&#23558;&#23427;&#20204;&#20998;&#25104;&#19981;&#21516;&#30340;&#29420;&#31435;&#29305;&#24449;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#29305;&#24449;&#32452;&#32455;&#25104;&#19968;&#20010;&#30693;&#35782;&#22270;&#65292;&#20351;&#20854;&#26356;&#26131;&#20110;&#35775;&#38382;&#21644;&#26816;&#32034;&#12290;&#25105;&#20204;&#30340;&#35282;&#33394;&#31995;&#32479;&#23558;&#21033;&#29992;&#36825;&#20010;&#30693;&#35782;&#22270;&#26469;&#29983;&#25104;&#26032;&#30340;&#36234;&#29425;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The discovery of "jailbreaks" to bypass safety filters of Large Language Models (LLMs) and harmful responses have encouraged the community to implement safety measures. One major safety measure is to proactively test the LLMs with jailbreaks prior to the release. Therefore, such testing will require a method that can generate jailbreaks massively and efficiently. In this paper, we follow a novel yet intuitive strategy to generate jailbreaks in the style of the human generation. We propose a role-playing system that assigns four different roles to the user LLMs to collaborate on new jailbreaks. Furthermore, we collect existing jailbreaks and split them into different independent characteristics using clustering frequency and semantic patterns sentence by sentence. We organize these characteristics into a knowledge graph, making them more accessible and easier to retrieve. Our system of different roles will leverage this knowledge graph to generate new jailbreaks, which have proved effec
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#25910;&#38598;&#29305;&#23450;&#39046;&#22495;&#30693;&#35782;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#21517;&#20026;&#8220;Knowledge Pile&#8221;&#30340;&#25968;&#25454;&#38598;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#26174;&#33879;&#25913;&#21892;&#20102;&#29305;&#23450;&#39046;&#22495;&#30340;&#25968;&#25454;&#31232;&#32570;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.14624</link><description>&lt;p&gt;
CC&#26597;&#35810;&#65306;&#20174;&#20844;&#24320;&#25991;&#29486;&#20013;&#21457;&#29616;&#22823;&#35268;&#27169;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;
&lt;/p&gt;
&lt;p&gt;
Query of CC: Unearthing Large Scale Domain-Specific Knowledge from Public Corpora. (arXiv:2401.14624v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14624
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#25910;&#38598;&#29305;&#23450;&#39046;&#22495;&#30693;&#35782;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#21517;&#20026;&#8220;Knowledge Pile&#8221;&#30340;&#25968;&#25454;&#38598;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#26174;&#33879;&#25913;&#21892;&#20102;&#29305;&#23450;&#39046;&#22495;&#30340;&#25968;&#25454;&#31232;&#32570;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#28508;&#21147;&#65292;&#28982;&#32780;&#29305;&#23450;&#39046;&#22495;&#30340;&#24320;&#28304;&#27169;&#22411;&#21644;&#25968;&#25454;&#20173;&#28982;&#38750;&#24120;&#31232;&#32570;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#25163;&#21160;&#25351;&#23450;&#36164;&#28304;&#21644;&#25910;&#38598;&#29305;&#23450;&#39046;&#22495;&#30340;&#39640;&#36136;&#37327;&#25968;&#25454;&#65292;&#36825;&#28040;&#32791;&#20102;&#22823;&#37327;&#26102;&#38388;&#21644;&#31934;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39640;&#25928;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#8220;CC&#26597;&#35810;&#8221;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24341;&#23548;&#31181;&#23376;&#20449;&#24687;&#65292;&#24182;&#20174;&#20844;&#24320;&#25991;&#29486;&#20013;&#26816;&#32034;&#30456;&#20851;&#25968;&#25454;&#12290;&#23427;&#19981;&#20165;&#25910;&#38598;&#20102;&#29305;&#23450;&#39046;&#22495;&#30340;&#30693;&#35782;&#30456;&#20851;&#25968;&#25454;&#65292;&#36824;&#25581;&#31034;&#20102;&#28508;&#22312;&#30340;&#25512;&#29702;&#36807;&#31243;&#25968;&#25454;&#12290;&#36890;&#36807;&#24212;&#29992;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;Knowledge Pile&#8221;&#30340;&#39640;&#36136;&#37327;&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20102;&#21253;&#25324;STEM&#31185;&#23398;&#21644;&#20154;&#25991;&#31185;&#23398;&#22312;&#20869;&#30340;&#22235;&#20010;&#20027;&#35201;&#39046;&#22495;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#8220;Knowledge Pile&#8221;&#26174;&#33879;&#25913;&#21892;&#20102;
&lt;/p&gt;
&lt;p&gt;
Large language models have demonstrated remarkable potential in various tasks, however, there remains a significant scarcity of open-source models and data for specific domains. Previous works have primarily focused on manually specifying resources and collecting high-quality data on specific domains, which significantly consume time and effort. To address this limitation, we propose an efficient data collection method~\textit{Query of CC} based on large language models. This method bootstraps seed information through a large language model and retrieves related data from public corpora. It not only collects knowledge-related data for specific domains but unearths the data with potential reasoning procedures. Through the application of this method, we have curated a high-quality dataset called~\textsc{Knowledge Pile}, encompassing four major domains, including stem and humanities sciences, among others. Experimental results demonstrate that~\textsc{Knowledge Pile} significantly improve
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#37329;&#34701;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#26009;&#24211;&#22810;&#26679;&#24615;&#23545;&#20854;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#22312;&#22810;&#26679;&#21270;&#30340;&#37329;&#34701;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#26032;&#27169;&#22411;FiLM&#65292;&#21462;&#24471;&#20102;&#27604;&#29616;&#26377;&#27169;&#22411;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.13312</link><description>&lt;p&gt;
&#25506;&#32034;&#35821;&#26009;&#24211;&#22810;&#26679;&#24615;&#23545;&#37329;&#34701;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Exploring the Impact of Corpus Diversity on Financial Pretrained Language Models. (arXiv:2310.13312v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#37329;&#34701;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#26009;&#24211;&#22810;&#26679;&#24615;&#23545;&#20854;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#22312;&#22810;&#26679;&#21270;&#30340;&#37329;&#34701;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#26032;&#27169;&#22411;FiLM&#65292;&#21462;&#24471;&#20102;&#27604;&#29616;&#26377;&#27169;&#22411;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#20960;&#24180;&#37324;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#29305;&#23450;&#39046;&#22495;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#12289;&#31185;&#23398;&#21644;&#20020;&#24202;&#31561;&#19987;&#19994;&#39046;&#22495;&#34920;&#29616;&#20986;&#33394;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#37329;&#34701;&#25968;&#25454;&#20998;&#26512;&#30340;&#37325;&#22823;&#32463;&#27982;&#24433;&#21709;&#65292;&#37329;&#34701;PLM&#20063;&#24471;&#21040;&#20102;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#37329;&#34701;PLMs&#22312;&#39044;&#35757;&#32451;&#20013;&#27809;&#26377;&#20805;&#20998;&#22810;&#26679;&#21270;&#30340;&#37329;&#34701;&#25968;&#25454;&#12290;&#36825;&#31181;&#32570;&#20047;&#22810;&#26679;&#24615;&#30340;&#35757;&#32451;&#25968;&#25454;&#23548;&#33268;&#20102;&#36739;&#24046;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#22312;&#35768;&#22810;&#19979;&#28216;&#20219;&#21153;&#19978;&#65292;&#36890;&#29992;&#30340;PLMs&#65292;&#21253;&#25324;BERT&#65292;&#24448;&#24448;&#20248;&#20110;&#37329;&#34701;PLMs&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#21508;&#31181;&#24191;&#27867;&#30340;&#37329;&#34701;&#35821;&#26009;&#24211;&#65292;&#24182;&#22312;&#36825;&#20123;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#37329;&#34701;&#35821;&#35328;&#27169;&#22411;&#65288;FiLM&#65289;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#25454;&#35777;&#23454;&#65292;FiLM&#19981;&#20165;&#20248;&#20110;&#29616;&#26377;&#30340;&#37329;&#34701;PLMs&#65292;&#32780;&#19988;&#20248;&#20110;&#36890;&#29992;&#39046;&#22495;&#30340;PLMs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23454;&#35777;&#35777;&#25454;&#65292;&#21363;&#36825;&#31181;&#25913;&#36827;&#21363;&#20351;&#23545;&#20110;&#26410;&#35265;&#36807;&#30340;&#35821;&#26009;&#32452;&#20063;&#21487;&#20197;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past few years, various domain-specific pretrained language models (PLMs) have been proposed and have outperformed general-domain PLMs in specialized areas such as biomedical, scientific, and clinical domains. In addition, financial PLMs have been studied because of the high economic impact of financial data analysis. However, we found that financial PLMs were not pretrained on sufficiently diverse financial data. This lack of diverse training data leads to a subpar generalization performance, resulting in general-purpose PLMs, including BERT, often outperforming financial PLMs on many downstream tasks. To address this issue, we collected a broad range of financial corpus and trained the Financial Language Model (FiLM) on these diverse datasets. Our experimental results confirm that FiLM outperforms not only existing financial PLMs but also general domain PLMs. Furthermore, we provide empirical evidence that this improvement can be achieved even for unseen corpus groups.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#21477;&#23376;&#23884;&#20837;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#65292;&#35299;&#30721;&#20102;&#21452;&#20154;&#23545;&#35805;&#20013;&#30340;&#24773;&#24863;&#65292;&#24182;&#21457;&#29616;&#22312;&#20914;&#31361;&#23545;&#35805;&#20013;&#65292;&#22971;&#23376;&#30340;&#24773;&#24863;&#19982;&#35821;&#20041;&#30456;&#20284;&#24615;&#21576;&#27491;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2309.12646</link><description>&lt;p&gt;
&#22312;&#21452;&#20154;&#23545;&#35805;&#20013;&#35299;&#30721;&#24773;&#24863;&#65306;&#36890;&#36807;&#21477;&#23376;&#23884;&#20837;&#21033;&#29992;&#35821;&#20041;&#30456;&#20284;&#24615;
&lt;/p&gt;
&lt;p&gt;
Decoding Affect in Dyadic Conversations: Leveraging Semantic Similarity through Sentence Embedding. (arXiv:2309.12646v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#21477;&#23376;&#23884;&#20837;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#65292;&#35299;&#30721;&#20102;&#21452;&#20154;&#23545;&#35805;&#20013;&#30340;&#24773;&#24863;&#65292;&#24182;&#21457;&#29616;&#22312;&#20914;&#31361;&#23545;&#35805;&#20013;&#65292;&#22971;&#23376;&#30340;&#24773;&#24863;&#19982;&#35821;&#20041;&#30456;&#20284;&#24615;&#21576;&#27491;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#31361;&#26174;&#20102;&#21477;&#23376;&#23884;&#20837;&#22312;&#27979;&#37327;&#35821;&#20041;&#30456;&#20284;&#24615;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#20854;&#22312;&#20998;&#26512;&#29616;&#23454;&#20013;&#30340;&#21452;&#20154;&#20114;&#21160;&#24182;&#39044;&#27979;&#23545;&#35805;&#21442;&#19982;&#32773;&#24773;&#24863;&#26041;&#38754;&#30340;&#24212;&#29992;&#20173;&#28982;&#24456;&#23569;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#30740;&#31350;&#21033;&#29992;50&#23545;&#22827;&#22971;&#20043;&#38388;&#20851;&#20110;&#20914;&#31361;&#21644;&#24841;&#24555;&#27963;&#21160;&#30340;&#21475;&#22836;&#23545;&#35805;&#12290;&#37319;&#29992;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;all-MiniLM-L6-v2&#26469;&#33719;&#24471;&#27599;&#20010;&#21457;&#35328;&#32773;&#35805;&#35821;&#30340;&#23884;&#20837;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#23884;&#20837;&#30456;&#37051;&#35805;&#35821;&#20043;&#38388;&#30340;&#20313;&#24358;&#30456;&#20284;&#24615;&#30340;&#24179;&#22343;&#20540;&#23545;&#23545;&#35805;&#30340;&#25972;&#20307;&#30456;&#20284;&#24615;&#36827;&#34892;&#37327;&#21270;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#35821;&#20041;&#30456;&#20284;&#24615;&#19982;&#22971;&#23376;&#22312;&#20914;&#31361;&#23545;&#35805;&#20013;&#30340;&#24773;&#24863;&#21576;&#27491;&#30456;&#20851;&#65288;&#20294;&#22312;&#24841;&#24555;&#23545;&#35805;&#20013;&#19981;&#30456;&#20851;&#65289;&#12290;&#27492;&#22806;&#65292;&#26080;&#35770;&#23545;&#35805;&#31867;&#22411;&#22914;&#20309;&#65292;&#37117;&#26410;&#35266;&#23519;&#21040;&#36825;&#31181;&#30456;&#20851;&#24615;&#19982;&#19976;&#22827;&#30340;&#24773;&#24863;&#20043;&#38388;&#12290;&#20004;&#20010;&#39564;&#35777;&#26816;&#39564;&#36827;&#19968;&#27493;&#25903;&#25345;&#20102;t
&lt;/p&gt;
&lt;p&gt;
Recent advancements in Natural Language Processing (NLP) have highlighted the potential of sentence embeddings in measuring semantic similarity. Yet, its application in analyzing real-world dyadic interactions and predicting the affect of conversational participants remains largely uncharted. To bridge this gap, the present study utilizes verbal conversations within 50 married couples talking about conflicts and pleasant activities. Transformer-based model all-MiniLM-L6-v2 was employed to obtain the embeddings of the utterances from each speaker. The overall similarity of the conversation was then quantified by the average cosine similarity between the embeddings of adjacent utterances. Results showed that semantic similarity had a positive association with wives' affect during conflict (but not pleasant) conversations. Moreover, this association was not observed with husbands' affect regardless of conversation types. Two validation checks further provided support for the validity of t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23567;&#22411;&#25968;&#25454;&#38598;&#19978;&#25913;&#36827;ResNet-9&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24212;&#29992;&#19968;&#31995;&#21015;&#25216;&#26415;&#26469;&#25552;&#39640;&#20854;&#27867;&#21270;&#24615;&#33021;&#65292;&#22312;&#19981;&#21040;10&#20998;&#38047;&#30340;&#26102;&#38388;&#20869;&#65292;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#30340;10%&#23376;&#38598;&#19978;&#36798;&#21040;&#20102;88%&#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.03965</link><description>&lt;p&gt;
&#22312;&#23567;&#22411;&#25968;&#25454;&#38598;&#19978;&#25913;&#36827;ResNet-9&#30340;&#27867;&#21270;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Improving Resnet-9 Generalization Trained on Small Datasets. (arXiv:2309.03965v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03965
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23567;&#22411;&#25968;&#25454;&#38598;&#19978;&#25913;&#36827;ResNet-9&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24212;&#29992;&#19968;&#31995;&#21015;&#25216;&#26415;&#26469;&#25552;&#39640;&#20854;&#27867;&#21270;&#24615;&#33021;&#65292;&#22312;&#19981;&#21040;10&#20998;&#38047;&#30340;&#26102;&#38388;&#20869;&#65292;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#30340;10%&#23376;&#38598;&#19978;&#36798;&#21040;&#20102;88%&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;ICLR&#30828;&#20214;&#24863;&#30693;&#39640;&#25928;&#35757;&#32451;&#31454;&#36187;&#20013;&#33719;&#24471;&#20102;&#31532;&#19968;&#21517;&#12290;&#25361;&#25112;&#26159;&#22312;&#19981;&#21040;10&#20998;&#38047;&#30340;&#26102;&#38388;&#20869;&#65292;&#22312;&#19968;&#20010;&#23567;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#23613;&#21487;&#33021;&#39640;&#30340;&#22270;&#20687;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;&#35757;&#32451;&#20351;&#29992;&#30340;&#23567;&#25968;&#25454;&#38598;&#26159;&#20174;CIFAR-10&#25968;&#25454;&#38598;&#20013;&#38543;&#26426;&#25361;&#36873;&#30340;5000&#24133;&#22270;&#20687;&#12290;&#35780;&#20272;&#30001;&#31454;&#36187;&#32452;&#32455;&#32773;&#22312;&#19968;&#20010;&#21253;&#21547;1000&#24133;&#30456;&#21516;&#22823;&#23567;&#22270;&#20687;&#30340;&#31192;&#23494;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#24212;&#29992;&#19968;&#31995;&#21015;&#25216;&#26415;&#26469;&#25552;&#39640;ResNet-9&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#21253;&#25324;&#65306;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#12289;&#26631;&#31614;&#24179;&#28369;&#12289;&#26799;&#24230;&#23621;&#20013;&#21270;&#12289;&#36755;&#20837;&#22270;&#20687;&#34917;&#19969;&#30333;&#21270;&#20197;&#21450;&#22522;&#20110;&#20803;&#23398;&#20064;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#19981;&#21040;10&#20998;&#38047;&#30340;&#26102;&#38388;&#20869;&#65292;ResNet-9&#21487;&#20197;&#22312;&#20165;&#35757;&#32451;CIFAR-10&#25968;&#25454;&#38598;&#30340;10%&#23376;&#38598;&#19978;&#36798;&#21040;88%&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents our proposed approach that won the first prize at the ICLR competition on Hardware Aware Efficient Training. The challenge is to achieve the highest possible accuracy in an image classification task in less than 10 minutes. The training is done on a small dataset of 5000 images picked randomly from CIFAR-10 dataset. The evaluation is performed by the competition organizers on a secret dataset with 1000 images of the same size. Our approach includes applying a series of technique for improving the generalization of ResNet-9 including: sharpness aware optimization, label smoothing, gradient centralization, input patch whitening as well as metalearning based training. Our experiments show that the ResNet-9 can achieve the accuracy of 88% while trained only on a 10% subset of CIFAR-10 dataset in less than 10 minuets
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#21152;&#36895;&#20302;&#31209;&#20998;&#35299;&#27169;&#22411;&#30340;&#25216;&#26415;&#65306;&#31209;&#20248;&#21270;&#21644;&#39034;&#24207;&#20923;&#32467;&#20998;&#35299;&#23618;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#35757;&#32451;&#21534;&#21520;&#37327;&#39640;&#36798;60%&#65292;&#25512;&#29702;&#21534;&#21520;&#37327;&#39640;&#36798;37%&#65292;&#21516;&#26102;&#20445;&#25345;&#20934;&#30830;&#24615;&#25509;&#36817;&#21407;&#22987;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.03824</link><description>&lt;p&gt;
&#20302;&#31209;&#20998;&#35299;&#32593;&#32476;&#30340;&#35757;&#32451;&#21152;&#36895;&#65306;&#39034;&#24207;&#20923;&#32467;&#21644;&#31209;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Training Acceleration of Low-Rank Decomposed Networks using Sequential Freezing and Rank Quantization. (arXiv:2309.03824v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#21152;&#36895;&#20302;&#31209;&#20998;&#35299;&#27169;&#22411;&#30340;&#25216;&#26415;&#65306;&#31209;&#20248;&#21270;&#21644;&#39034;&#24207;&#20923;&#32467;&#20998;&#35299;&#23618;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#35757;&#32451;&#21534;&#21520;&#37327;&#39640;&#36798;60%&#65292;&#25512;&#29702;&#21534;&#21520;&#37327;&#39640;&#36798;37%&#65292;&#21516;&#26102;&#20445;&#25345;&#20934;&#30830;&#24615;&#25509;&#36817;&#21407;&#22987;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#20998;&#35299;&#65288;LRD&#65289;&#26159;&#19968;&#31181;&#24212;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26435;&#37325;&#24352;&#37327;&#30340;&#27169;&#22411;&#21387;&#32553;&#25216;&#26415;&#65292;&#20197;&#20943;&#23569;&#21487;&#35757;&#32451;&#21442;&#25968;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22312;&#24212;&#29992;LRD&#21518;&#22312;&#26550;&#26500;&#20013;&#28155;&#21152;&#20102;&#22823;&#37327;&#26032;&#23618;&#65292;&#22914;&#26524;&#20998;&#35299;&#31209;&#19981;&#22815;&#23567;&#65292;&#21017;&#21487;&#33021;&#23548;&#33268;&#35757;&#32451;/&#25512;&#29702;&#21152;&#36895;&#24615;&#19981;&#39640;&#12290;&#38382;&#39064;&#22312;&#20110;&#65292;&#20351;&#29992;&#36739;&#23567;&#30340;&#31209;&#20250;&#22686;&#21152;&#20998;&#35299;&#21518;&#30340;&#26174;&#33879;&#20934;&#30830;&#29575;&#19979;&#38477;&#30340;&#39118;&#38505;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#21152;&#36895;&#20302;&#31209;&#20998;&#35299;&#27169;&#22411;&#30340;&#25216;&#26415;&#65292;&#32780;&#19981;&#38656;&#35201;&#20351;&#29992;&#36739;&#23567;&#30340;&#31209;&#36827;&#34892;&#20998;&#35299;&#12290;&#36825;&#20123;&#26041;&#27861;&#21253;&#25324;&#31209;&#20248;&#21270;&#21644;&#39034;&#24207;&#20923;&#32467;&#20998;&#35299;&#23618;&#12290;&#25105;&#20204;&#22312;&#21367;&#31215;&#21644;&#22522;&#20110;transformer&#30340;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#25216;&#26415;&#22312;&#20445;&#25345;&#25509;&#36817;&#21407;&#22987;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#35757;&#32451;&#21534;&#21520;&#37327;&#39640;&#36798;60%&#65292;&#25512;&#29702;&#21534;&#21520;&#37327;&#39640;&#36798;37%&#12290;
&lt;/p&gt;
&lt;p&gt;
Low Rank Decomposition (LRD) is a model compression technique applied to the weight tensors of deep learning models in order to reduce the number of trainable parameters and computational complexity. However, due to high number of new layers added to the architecture after applying LRD, it may not lead to a high training/inference acceleration if the decomposition ranks are not small enough. The issue is that using small ranks increases the risk of significant accuracy drop after decomposition. In this paper, we propose two techniques for accelerating low rank decomposed models without requiring to use small ranks for decomposition. These methods include rank optimization and sequential freezing of decomposed layers. We perform experiments on both convolutional and transformer-based models. Experiments show that these techniques can improve the model throughput up to 60% during training and 37% during inference when combined together while preserving the accuracy close to that of the o
&lt;/p&gt;</description></item><item><title>AtteSTNet&#26159;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#23376;&#35789;&#20998;&#21106;&#30340;&#26816;&#27979;&#28151;&#21512;&#35821;&#35328;&#20167;&#24680;&#35328;&#35770;&#30340;&#26041;&#27861;&#65292;&#23427;&#19981;&#20165;&#19982;&#22797;&#26434;&#32593;&#32476;&#30456;&#24403;&#65292;&#32780;&#19988;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#24615;&#33021;&#26356;&#22909;&#65292;&#20854;&#26497;&#22823;&#30340;&#31616;&#21333;&#24615;&#21644;&#26131;&#20110;&#32500;&#25252;&#24615;&#26159;&#20854;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2112.11479</link><description>&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#23376;&#35789;&#20998;&#21106;&#30340;&#28151;&#21512;&#35821;&#35328;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
AtteSTNet -- An attention and subword tokenization based approach for code-switched text hate speech detection. (arXiv:2112.11479v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.11479
&lt;/p&gt;
&lt;p&gt;
AtteSTNet&#26159;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#23376;&#35789;&#20998;&#21106;&#30340;&#26816;&#27979;&#28151;&#21512;&#35821;&#35328;&#20167;&#24680;&#35328;&#35770;&#30340;&#26041;&#27861;&#65292;&#23427;&#19981;&#20165;&#19982;&#22797;&#26434;&#32593;&#32476;&#30456;&#24403;&#65292;&#32780;&#19988;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#24615;&#33021;&#26356;&#22909;&#65292;&#20854;&#26497;&#22823;&#30340;&#31616;&#21333;&#24615;&#21644;&#26131;&#20110;&#32500;&#25252;&#24615;&#26159;&#20854;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25216;&#26415;&#30340;&#26368;&#26032;&#36827;&#23637;&#23548;&#33268;&#31038;&#20132;&#23186;&#20307;&#30340;&#20351;&#29992;&#37327;&#22686;&#21152;&#65292;&#20063;&#23548;&#33268;&#22823;&#37327;&#29992;&#25143;&#29983;&#25104;&#30340;&#25968;&#25454;&#65292;&#20854;&#20013;&#21253;&#25324;&#20196;&#20154;&#35752;&#21388;&#21644;&#20882;&#29359;&#30340;&#35328;&#35770;&#12290;&#31038;&#20132;&#23186;&#20307;&#19978;&#20351;&#29992;&#30340;&#35821;&#35328;&#36890;&#24120;&#26159;&#33521;&#35821;&#21644;&#32946;&#22320;&#26041;&#35821;&#35328;&#30340;&#32452;&#21512;&#12290;&#22312;&#21360;&#24230;&#65292;&#21360;&#22320;&#35821;&#26159;&#20027;&#35201;&#20351;&#29992;&#30340;&#35821;&#35328;&#65292;&#24182;&#32463;&#24120;&#19982;&#33521;&#35821;&#20999;&#25442;&#65292;&#24418;&#25104;&#21360;&#22320;&#33521;&#35821;&#65288;Hinglish&#65289;&#35821;&#35328;&#12290;&#36807;&#21435;&#24050;&#32463;&#37319;&#29992;&#20102;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#26469;&#23545;&#28151;&#21512;&#26102;&#30340;&#21360;&#22320;&#33521;&#35821;&#20167;&#24680;&#35328;&#35770;&#36827;&#34892;&#20998;&#31867;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#20351;&#29992;&#30340;&#24490;&#29615;&#25110;&#21367;&#31215;&#26426;&#21046;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#20869;&#23384;&#38656;&#27714;&#22823;&#12290;&#36807;&#21435;&#30340;&#25216;&#26415;&#36824;&#20351;&#29992;&#22797;&#26434;&#30340;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#65292;&#20351;&#29616;&#26377;&#25216;&#26415;&#38750;&#24120;&#22797;&#26434;&#19988;&#38590;&#20197;&#25913;&#21464;&#25968;&#25454;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#19981;&#20165;&#19982;&#36825;&#20123;&#22797;&#26434;&#32593;&#32476;&#19968;&#26679;&#65292;&#24182;&#19988;&#22312;&#22914;HASOC&#65288;&#21360;&#27431;&#35821;&#35328;&#30340;&#20167;&#24680;&#35328;&#35770;&#21644;&#20882;&#29359;&#20869;&#23481;&#35782;&#21035;&#65289;&#27492;&#31867;&#28151;&#21512;&#21360;&#22320;&#33521;&#35821;&#25991;&#26412;&#30340;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#24615;&#33021;&#22522;&#20934;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21517;&#20026;AtteSTNet&#65292;&#23427;&#21033;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#21644;&#23376;&#35789;&#20998;&#21106;&#26469;&#35782;&#21035;&#28151;&#21512;&#35821;&#35328;&#20013;&#30340;&#20167;&#24680;&#35328;&#35770;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#20197;&#21069;&#30340;&#25216;&#26415;&#34920;&#29616;&#26356;&#22909;&#65292;&#26356;&#31616;&#21333;&#26131;&#20110;&#32500;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in technology have led to a boost in social media usage which has ultimately led to large amounts of user-generated data which also includes hateful and offensive speech. The language used in social media is often a combination of English and the native language in the region. In India, Hindi is used predominantly and is often code-switched with English, giving rise to the Hinglish (Hindi+English) language. Various approaches have been made in the past to classify the code-mixed Hinglish hate speech using different machine learning and deep learning-based techniques. However, these techniques make use of recurrence on convolution mechanisms which are computationally expensive and have high memory requirements. Past techniques also make use of complex data processing making the existing techniques very complex and non-sustainable to change in data. Proposed work gives a much simpler approach which is not only at par with these complex networks but also exceeds perfor
&lt;/p&gt;</description></item></channel></rss>