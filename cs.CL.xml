<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;&#28151;&#21512;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;HUDS&#65292;&#32467;&#21512;&#20102;&#19981;&#30830;&#23450;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#29992;&#20110;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#21477;&#23376;&#36873;&#25321;&#12290;</title><link>https://arxiv.org/abs/2403.09259</link><description>&lt;p&gt;
&#26159;&#21542;&#32473;&#25968;&#25454;&#36148;&#26631;&#31614;&#65306;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;&#28151;&#21512;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
To Label or Not to Label: Hybrid Active Learning for Neural Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09259
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;&#28151;&#21512;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;HUDS&#65292;&#32467;&#21512;&#20102;&#19981;&#30830;&#23450;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#29992;&#20110;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#21477;&#23376;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#25216;&#26415;&#36890;&#36807;&#20174;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#36873;&#25321;&#26356;&#23567;&#30340;&#20195;&#34920;&#24615;&#23376;&#38598;&#36827;&#34892;&#27880;&#37322;&#65292;&#38477;&#20302;&#20102;&#35757;&#32451;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#65288;NMT&#65289;&#27169;&#22411;&#30340;&#26631;&#35760;&#25104;&#26412;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;HUDS&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;NMT&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#28151;&#21512;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#65292;&#23558;&#19981;&#30830;&#23450;&#24615;&#21644;&#22810;&#26679;&#24615;&#30456;&#32467;&#21512;&#65292;&#20197;&#36827;&#34892;&#21477;&#23376;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09259v1 Announce Type: new  Abstract: Active learning (AL) techniques reduce labeling costs for training neural machine translation (NMT) models by selecting smaller representative subsets from unlabeled data for annotation. Diversity sampling techniques select heterogeneous instances, while uncertainty sampling methods select instances with the highest model uncertainty. Both approaches have limitations - diversity methods may extract varied but trivial examples, while uncertainty sampling can yield repetitive, uninformative instances. To bridge this gap, we propose HUDS, a hybrid AL strategy for domain adaptation in NMT that combines uncertainty and diversity for sentence selection. HUDS computes uncertainty scores for unlabeled sentences and subsequently stratifies them. It then clusters sentence embeddings within each stratum using k-MEANS and computes diversity scores by distance to the centroid. A weighted hybrid score that combines uncertainty and diversity is then us
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22312;&#35821;&#35328;&#27169;&#22411;&#32534;&#30721;&#31354;&#38388;&#20013;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;Transformer&#30340;&#35299;&#30721;&#22120;&#20197;&#21450;&#33258;&#25105;&#35843;&#33410;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#21517;&#20026;TEncDM&#30340;&#25991;&#26412;&#32534;&#30721;&#25193;&#25955;&#27169;&#22411;&#65292;&#22312;&#20004;&#20010;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;</title><link>https://arxiv.org/abs/2402.19097</link><description>&lt;p&gt;
TEncDM: &#22312;&#35821;&#35328;&#27169;&#22411;&#32534;&#30721;&#31354;&#38388;&#20013;&#29702;&#35299;&#25193;&#25955;&#27169;&#22411;&#30340;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
TEncDM: Understanding the Properties of Diffusion Model in the Space of Language Model Encodings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19097
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#35821;&#35328;&#27169;&#22411;&#32534;&#30721;&#31354;&#38388;&#20013;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;Transformer&#30340;&#35299;&#30721;&#22120;&#20197;&#21450;&#33258;&#25105;&#35843;&#33410;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#21517;&#20026;TEncDM&#30340;&#25991;&#26412;&#32534;&#30721;&#25193;&#25955;&#27169;&#22411;&#65292;&#22312;&#20004;&#20010;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#25193;&#25955;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#35768;&#22810;&#30740;&#31350;&#35770;&#25991;&#25552;&#20986;&#20102;&#23558;&#20854;&#24212;&#29992;&#20110;&#25991;&#26412;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#23613;&#31649;&#26377;&#36825;&#20123;&#21162;&#21147;&#65292;&#20294;&#27809;&#26377;&#19968;&#31181;&#26041;&#27861;&#33021;&#22815;&#36798;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#23545;&#25991;&#26412;&#25193;&#25955;&#27169;&#22411;&#30340;&#20851;&#38190;&#32452;&#20214;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Text Encoding Diffusion Model (TEncDM)&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#35821;&#35328;&#27169;&#22411;&#32534;&#30721;&#31354;&#38388;&#20013;&#35757;&#32451;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#32780;&#19981;&#26159;&#36890;&#24120;&#20351;&#29992;&#30340;&#26631;&#35760;&#23884;&#20837;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22522;&#20110;Transformer&#30340;&#35299;&#30721;&#22120;&#65292;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#36827;&#34892;&#25991;&#26412;&#37325;&#26500;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#33258;&#25105;&#35843;&#33410;&#65292;&#24182;&#21457;&#29616;&#36825;&#20250;&#22686;&#21152;&#27169;&#22411;&#36755;&#20986;&#30340;&#25968;&#37327;&#32423;&#65292;&#20174;&#32780;&#20943;&#23569;&#25512;&#29702;&#38454;&#27573;&#30340;&#21435;&#22122;&#27493;&#39588;&#25968;&#37327;&#12290;&#22312;&#20004;&#20010;&#19979;&#28216;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;QQP&#21644;XSum&#19978;&#23545;TEncDM&#30340;&#35780;&#20272;&#34920;&#26126;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19097v1 Announce Type: new  Abstract: Drawing inspiration from the success of diffusion models in various domains, numerous research papers proposed methods for adapting them to text data. Despite these efforts, none of them has managed to achieve the quality of the large language models. In this paper, we conduct a comprehensive analysis of key components of the text diffusion models and introduce a novel approach named Text Encoding Diffusion Model (TEncDM). Instead of the commonly used token embedding space, we train our model in the space of the language model encodings. Additionally, we propose to use a Transformer-based decoder that utilizes contextual information for text reconstruction. We also analyse self-conditioning and find that it increases the magnitude of the model outputs, allowing the reduction of the number of denoising steps at the inference stage. Evaluation of TEncDM on two downstream text generation tasks, QQP and XSum, demonstrates its superiority ove
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SocREval&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;GPT-4&#21644;&#33487;&#26684;&#25289;&#24213;&#26041;&#27861;&#36827;&#34892;&#26080;&#21442;&#32771;&#25512;&#29702;&#35780;&#20272;&#65292;&#20197;&#35299;&#20915;&#24403;&#21069;&#22797;&#26434;&#25512;&#29702;&#27169;&#22411;&#35780;&#20272;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.00074</link><description>&lt;p&gt;
SocREval&#65306;&#20351;&#29992;&#33487;&#26684;&#25289;&#24213;&#26041;&#27861;&#36827;&#34892;&#26080;&#21442;&#32771;&#25512;&#29702;&#35780;&#20272;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SocREval: Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation. (arXiv:2310.00074v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SocREval&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;GPT-4&#21644;&#33487;&#26684;&#25289;&#24213;&#26041;&#27861;&#36827;&#34892;&#26080;&#21442;&#32771;&#25512;&#29702;&#35780;&#20272;&#65292;&#20197;&#35299;&#20915;&#24403;&#21069;&#22797;&#26434;&#25512;&#29702;&#27169;&#22411;&#35780;&#20272;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20840;&#38754;&#35780;&#20272;&#24403;&#21069;&#27169;&#22411;&#22312;&#22797;&#26434;&#25512;&#29702;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#20197;&#21487;&#25193;&#23637;&#30340;&#26041;&#24335;&#35780;&#20272;&#23427;&#20204;&#30340;&#36880;&#27493;&#25512;&#29702;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#29616;&#26377;&#30340;&#22522;&#20110;&#21442;&#32771;&#30340;&#35780;&#20272;&#25351;&#26631;&#20381;&#36182;&#20110;&#20154;&#24037;&#27880;&#37322;&#30340;&#25512;&#29702;&#38142;&#26469;&#35780;&#20272;&#27169;&#22411;&#23548;&#20986;&#30340;&#25512;&#29702;&#38142;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#8220;&#40644;&#37329;&#26631;&#20934;&#8221;&#20154;&#24037;&#32534;&#20889;&#30340;&#25512;&#29702;&#38142;&#21487;&#33021;&#19981;&#26159;&#21807;&#19968;&#30340;&#65292;&#24182;&#19988;&#20854;&#33719;&#21462;&#36890;&#24120;&#26159;&#21171;&#21160;&#23494;&#38598;&#22411;&#30340;&#12290;&#29616;&#26377;&#30340;&#26080;&#21442;&#32771;&#25512;&#29702;&#25351;&#26631;&#28040;&#38500;&#20102;&#20154;&#24037;&#21046;&#20316;&#25512;&#29702;&#38142;&#30340;&#38656;&#27714;&#20316;&#20026;&#21442;&#32771;&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#22312;&#20855;&#26377;&#20154;&#24037;&#25512;&#29702;&#38142;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#36825;&#22797;&#26434;&#21270;&#20102;&#27969;&#31243;&#24182;&#24341;&#21457;&#20102;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#27867;&#21270;&#24615;&#30340;&#25285;&#24551;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#21033;&#29992;GPT-4&#33258;&#21160;&#35780;&#20272;&#25512;&#29702;&#38142;&#36136;&#37327;&#65292;&#28040;&#38500;&#20102;&#23545;&#20154;&#24037;&#21046;&#20316;&#21442;&#32771;&#30340;&#38656;&#27714;&#12290;&#21033;&#29992;&#33487;&#26684;&#25289;&#24213;&#26041;&#27861;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#23450;&#21046;&#21270;&#25552;&#31034;&#26469;&#22686;&#24378;&#26080;&#21442;&#32771;&#25512;&#29702;&#35780;&#20272;&#65292;&#36825;&#23601;&#26159;&#25105;&#20204;&#31216;&#20043;&#20026;SocREval&#65288;&#33487;&#26684;&#25289;&#24213;&#26041;&#27861;&#65289;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
To comprehensively assess the capacity of current models for complex reasoning, it is crucial to assess their step-by-step reasoning in a scalable manner. Established reference-based evaluation metrics rely on human-annotated reasoning chains to assess the model-derived chains. However, such ``gold-standard'' human-written reasoning chains may not be unique and their acquisition is often labor-intensive. Existing reference-free reasoning metrics eliminate the need for human-crafted reasoning chains as references, but they typically require fine-tuning on datasets with human-derived reasoning chains, which complicates the process and raises concerns regarding generalizability across diverse datasets. To address these challenges, we harness GPT-4 to automatically evaluate reasoning chain quality, obviating the need for human-crafted references. Leveraging the Socratic method, we devise tailored prompts to enhance reference-free reasoning evaluation, which we term SocREval (Socratic metho
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27979;&#37327;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#21512;&#25104;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#24182;&#20174;&#24418;&#23481;&#35789;&#20462;&#39280;&#21517;&#35789;&#30701;&#35821;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19977;&#20010;&#26032;&#30340;&#21512;&#25104;&#34892;&#20026;&#27979;&#35797;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21069;&#30340;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#21482;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#31526;&#21512;&#39044;&#26399;&#30340;&#35821;&#35328;&#29702;&#35770;&#12290;</title><link>http://arxiv.org/abs/2212.04310</link><description>&lt;p&gt;
&#33945;&#22612;&#21476;&#35821;&#20041;&#19982;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20462;&#39280;&#19968;&#33268;&#24615;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
Montague semantics and modifier consistency measurement in neural language models. (arXiv:2212.04310v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.04310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27979;&#37327;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#21512;&#25104;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#24182;&#20174;&#24418;&#23481;&#35789;&#20462;&#39280;&#21517;&#35789;&#30701;&#35821;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19977;&#20010;&#26032;&#30340;&#21512;&#25104;&#34892;&#20026;&#27979;&#35797;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21069;&#30340;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#21482;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#31526;&#21512;&#39044;&#26399;&#30340;&#35821;&#35328;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#20960;&#24180;&#20013;&#65292;&#20998;&#24067;&#24335;&#35821;&#35328;&#34920;&#31034;&#27169;&#22411;&#24050;&#32463;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#21516;&#26102;&#65292;&#21487;&#35299;&#37322;&#24615;&#30340;&#38656;&#27714;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#23427;&#20204;&#30340;&#26412;&#36136;&#23646;&#24615;&#21644;&#33021;&#21147;&#30340;&#36136;&#30097;&#12290;&#23588;&#20854;&#26159;&#65292;&#20998;&#24067;&#24335;&#27169;&#22411;&#22312;&#22788;&#29702;&#33258;&#28982;&#35821;&#35328;&#30340;&#32452;&#21512;&#29616;&#35937;&#26102;&#24448;&#24448;&#19981;&#19968;&#33268;&#65292;&#36825;&#23545;&#23427;&#20204;&#30340;&#23433;&#20840;&#24615;&#21644;&#20844;&#24179;&#24615;&#20855;&#26377;&#37325;&#35201;&#30340;&#24433;&#21709;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#30446;&#21069;&#22823;&#22810;&#25968;&#26377;&#20851;&#21512;&#25104;&#24615;&#30340;&#30740;&#31350;&#21482;&#26159;&#38024;&#23545;&#25913;&#21892;&#23427;&#20204;&#22312;&#30456;&#20284;&#24615;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#12290;&#26412;&#30740;&#31350;&#37319;&#21462;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27979;&#37327;&#24403;&#20195;&#35821;&#35328;&#27169;&#22411;&#32452;&#25104;&#24615;&#34892;&#20026;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#24418;&#23481;&#35789;&#20462;&#39280;&#21517;&#35789;&#30701;&#35821;&#20013;&#30340;&#24418;&#23481;&#35789;&#20462;&#39280;&#29616;&#35937;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19977;&#20010;&#28789;&#24863;&#26469;&#33258;&#33945;&#22612;&#21476;&#35821;&#24847;&#30340;&#21512;&#25104;&#34892;&#20026;&#27979;&#35797;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21069;&#30340;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#21482;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#31526;&#21512;&#39044;&#26399;&#30340;&#35821;&#35328;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, distributional language representation models have demonstrated great practical success. At the same time, the need for interpretability has elicited questions on their intrinsic properties and capabilities. Crucially, distributional models are often inconsistent when dealing with compositional phenomena in natural language, which has significant implications for their safety and fairness. Despite this, most current research on compositionality is directed towards improving their performance on similarity tasks only. This work takes a different approach, and proposes a methodology for measuring compositional behavior in contemporary language models. Specifically, we focus on adjectival modifier phenomena in adjective-noun phrases. We introduce three novel tests of compositional behavior inspired by Montague semantics. Our experimental results indicate that current neural language models behave according to the expected linguistic theories to a limited extent only. This
&lt;/p&gt;</description></item></channel></rss>