<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Counting-Stars&#30340;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21512;&#29702;&#31574;&#30053;&#65292;&#29992;&#20110;&#35780;&#20272;&#38271;&#19978;&#19979;&#25991;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#21457;&#29616;GPT-4 Turbo&#21644;Kimi Chat&#22312;&#27492;&#20219;&#21153;&#19978;&#21462;&#24471;&#26174;&#33879;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.11802</link><description>&lt;p&gt;
Counting-Stars&#65306;&#19968;&#31181;&#35780;&#20272;&#38271;&#19978;&#19979;&#25991;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21512;&#29702;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Counting-Stars: A Simple, Efficient, and Reasonable Strategy for Evaluating Long-Context Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11802
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Counting-Stars&#30340;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21512;&#29702;&#31574;&#30053;&#65292;&#29992;&#20110;&#35780;&#20272;&#38271;&#19978;&#19979;&#25991;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#21457;&#29616;GPT-4 Turbo&#21644;Kimi Chat&#22312;&#27492;&#20219;&#21153;&#19978;&#21462;&#24471;&#26174;&#33879;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24320;&#21457;&#20855;&#26377;&#24378;&#22823;&#38271;&#19978;&#19979;&#25991;&#33021;&#21147;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#30001;&#20110;&#32570;&#20047;&#36866;&#24403;&#30340;&#35780;&#20272;&#31574;&#30053;&#65292;&#23545;&#39046;&#20808;&#30340;LLMs&#65288;&#20363;&#22914;ChatGPT&#21644;KimiChat&#65289;&#30340;&#38271;&#19978;&#19979;&#25991;&#22788;&#29702;&#33021;&#21147;&#21644;&#24615;&#33021;&#20102;&#35299;&#29978;&#23569;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21512;&#29702;&#30340;&#38271;&#19978;&#19979;&#25991;LLMs&#35780;&#20272;&#31574;&#30053;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#65292;&#21517;&#20026;Counting-Stars&#12290;Counting-Stars&#26088;&#22312;&#35201;&#27714;LLMs&#20805;&#20998;&#29702;&#35299;&#21644;&#25429;&#25417;&#38271;&#19978;&#19979;&#25991;&#20013;&#30340;&#38271;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#33021;&#22815;&#25910;&#38598;&#36328;&#36234;&#25972;&#20010;&#19978;&#19979;&#25991;&#30340;&#22810;&#20010;&#35777;&#25454;&#20043;&#38388;&#30340;&#30456;&#20114;&#20381;&#36182;&#26469;&#23436;&#25104;&#20219;&#21153;&#12290;&#22522;&#20110;Counting-Stars&#65292;&#25105;&#20204;&#36827;&#34892;&#23454;&#39564;&#35780;&#20272;&#20102;&#20004;&#20010;&#39046;&#20808;&#30340;&#38271;&#19978;&#19979;&#25991;LLMs&#65292;&#21363;GPT-4 Turbo&#21644;Kimi Chat&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4 Turbo&#21644;Kimi Chat&#22312;Counting-Stars&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11802v1 Announce Type: new  Abstract: While recent research endeavors have concentrated on developing Large Language Models (LLMs) with robust long-context capabilities, due to the lack of appropriate evaluation strategies, relatively little is known about how well the long-context processing abilities and performance of leading LLMs (e.g., ChatGPT and KimiChat). To address this gap, we propose a simple, efficient, and reasonable strategy for evaluating long-context LLMs as a new benchmark, named Counting-Stars. The Counting-Stars is designed to require LLMs to fully understand and capture long dependencies in long contexts and be able to collect inter-dependency across multiple pieces of evidence spanning the entire context to finish the task. Based on the Counting-Stars, we conduct experiments to evaluate the two leading long-context LLMs, i.e., GPT-4 Turbo and Kimi Chat. The experimental results indicate that GPT-4 Turbo and Kimi Chat achieve significant performance in th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26032;&#30340;&#25991;&#26723;&#21521;&#37327;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#26816;&#27979;&#38035;&#40060;&#32593;&#32476;&#25915;&#20987;&#30340;&#30005;&#23376;&#37038;&#20214;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20855;&#26377;&#39640;&#25928;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08309</link><description>&lt;p&gt;
&#36890;&#36807;&#25552;&#31034;&#30340;&#19978;&#19979;&#25991;&#21521;&#37327;&#26816;&#27979;&#38035;&#40060;&#32593;&#32476;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Prompted Contextual Vectors for Spear-Phishing Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08309
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26032;&#30340;&#25991;&#26723;&#21521;&#37327;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#26816;&#27979;&#38035;&#40060;&#32593;&#32476;&#25915;&#20987;&#30340;&#30005;&#23376;&#37038;&#20214;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20855;&#26377;&#39640;&#25928;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38035;&#40060;&#32593;&#32476;&#25915;&#20987;&#26159;&#19968;&#20010;&#37325;&#22823;&#30340;&#23433;&#20840;&#25361;&#25112;&#65292;&#32780;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#29983;&#25104;&#20196;&#20154;&#20449;&#26381;&#30340;&#30005;&#23376;&#37038;&#20214;&#24182;&#26041;&#20415;&#30446;&#26631;&#20390;&#23519;&#26469;&#21319;&#32423;&#20102;&#23041;&#32961;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#39062;&#25991;&#26723;&#21521;&#37327;&#21270;&#26041;&#27861;&#30340;&#26816;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;LLMs&#30340;&#38598;&#21512;&#26469;&#21019;&#24314;&#34920;&#31034;&#21521;&#37327;&#12290;&#36890;&#36807;&#25552;&#31034;LLMs&#26469;&#25512;&#29702;&#21644;&#22238;&#31572;&#20154;&#24037;&#21046;&#23450;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#37327;&#21270;&#30005;&#23376;&#37038;&#20214;&#20869;&#23481;&#20013;&#24120;&#35265;&#35828;&#26381;&#21407;&#21017;&#30340;&#23384;&#22312;&#65292;&#20026;&#19979;&#28216;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#29983;&#25104;&#25552;&#31034;&#19978;&#19979;&#25991;&#25991;&#26723;&#21521;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#19987;&#26377;&#31995;&#32479;&#29983;&#25104;&#30340;&#29420;&#29305;&#25968;&#25454;&#38598;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#35813;&#31995;&#32479;&#33258;&#21160;&#21270;&#30446;&#26631;&#20390;&#23519;&#21644;&#38035;&#40060;&#30005;&#23376;&#37038;&#20214;&#30340;&#21019;&#24314;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20165;&#21253;&#21547;&#20256;&#32479;&#38035;&#40060;&#21644;&#33391;&#24615;&#30005;&#23376;&#37038;&#20214;&#30340;&#35757;&#32451;&#38598;&#20013;&#23454;&#29616;&#20102;91%&#30340;F1&#24471;&#20998;&#65292;&#20854;&#20013;&#20851;&#38190;&#36129;&#29486;&#21253;&#25324;&#19968;&#31181;&#21019;&#26032;&#30340;&#25991;&#26723;&#21521;&#37327;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spear-phishing attacks present a significant security challenge, with large language models (LLMs) escalating the threat by generating convincing emails and facilitating target reconnaissance. To address this, we propose a detection approach based on a novel document vectorization method that utilizes an ensemble of LLMs to create representation vectors. By prompting LLMs to reason and respond to human-crafted questions, we quantify the presence of common persuasion principles in the email's content, producing prompted contextual document vectors for a downstream supervised machine learning model. We evaluate our method using a unique dataset generated by a proprietary system that automates target reconnaissance and spear-phishing email creation. Our method achieves a 91% F1 score in identifying LLM-generated spear-phishing emails, with the training set comprising only traditional phishing and benign emails. Key contributions include an innovative document vectorization method utilizin
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#34920;&#31034;&#24037;&#31243;&#23545;LLMs&#36827;&#34892;&#36234;&#29425;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#23569;&#37327;&#26597;&#35810;&#23545;&#25552;&#21462;&#8220;&#23433;&#20840;&#27169;&#24335;&#8221;&#65292;&#25104;&#21151;&#35268;&#36991;&#30446;&#26631;&#27169;&#22411;&#30340;&#38450;&#24481;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36234;&#29425;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2401.06824</link><description>&lt;p&gt;
&#25171;&#24320;LLMs&#30340;&#28504;&#22810;&#25289;&#39764;&#30418;&#65306;&#36890;&#36807;&#34920;&#31034;&#24037;&#31243;&#23545;LLMs&#36827;&#34892;&#36234;&#29425;
&lt;/p&gt;
&lt;p&gt;
Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.06824
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#34920;&#31034;&#24037;&#31243;&#23545;LLMs&#36827;&#34892;&#36234;&#29425;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#23569;&#37327;&#26597;&#35810;&#23545;&#25552;&#21462;&#8220;&#23433;&#20840;&#27169;&#24335;&#8221;&#65292;&#25104;&#21151;&#35268;&#36991;&#30446;&#26631;&#27169;&#22411;&#30340;&#38450;&#24481;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36234;&#29425;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#29425;&#25216;&#26415;&#26088;&#22312;&#36890;&#36807;&#35825;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#23545;&#24694;&#24847;&#26597;&#35810;&#20135;&#29983;&#26377;&#27602;&#21709;&#24212;&#65292;&#26469;&#25506;&#32034;LLMs&#23433;&#20840;&#24615;&#36793;&#30028;&#65292;&#36825;&#22312;LLMs&#31038;&#21306;&#20869;&#26159;&#19968;&#20010;&#37325;&#35201;&#20851;&#27880;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;&#36890;&#36807;&#34920;&#31034;&#24037;&#31243;&#23545;LLMs&#36827;&#34892;&#36234;&#29425;&#65288;Jailbreaking LLMs through Representation Engineering&#65292;JRE&#65289;&#30340;&#26032;&#39062;&#36234;&#29425;&#26041;&#27861;&#65292;&#20854;&#20165;&#38656;&#35201;&#23569;&#37327;&#26597;&#35810;&#23545;&#20197;&#25552;&#21462;&#21487;&#29992;&#20110;&#35268;&#36991;&#30446;&#26631;&#27169;&#22411;&#38450;&#24481;&#30340;&#8220;&#23433;&#20840;&#27169;&#24335;&#8221;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36234;&#29425;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.06824v2 Announce Type: replace-cross  Abstract: Jailbreaking techniques aim to probe the boundaries of safety in large language models (LLMs) by inducing them to generate toxic responses to malicious queries, a significant concern within the LLM community. While existing jailbreaking methods primarily rely on prompt engineering, altering inputs to evade LLM safety mechanisms, they suffer from low attack success rates and significant time overheads, rendering them inflexible. To overcome these limitations, we propose a novel jailbreaking approach, named Jailbreaking LLMs through Representation Engineering (JRE). Our method requires only a small number of query pairs to extract ``safety patterns'' that can be used to circumvent the target model's defenses, achieving unprecedented jailbreaking performance. Building upon these findings, we also introduce a novel defense framework inspired by JRE principles, which demonstrates notable effectiveness. Extensive experimentation conf
&lt;/p&gt;</description></item><item><title>AgentBoard&#26159;&#19968;&#20010;&#32508;&#21512;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#35780;&#20272;&#26694;&#26550;&#65292;&#19987;&#20026;&#20998;&#26512;&#35780;&#20272;LLM&#26234;&#33021;&#20307;&#32780;&#35774;&#35745;&#65292;&#35299;&#20915;&#20102;&#22312;&#22810;&#36718;&#20132;&#20114;&#21644;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#20013;&#23545;&#26234;&#33021;&#20307;&#24615;&#33021;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#32454;&#31890;&#24230;&#30340;&#36827;&#23637;&#29575;&#25351;&#26631;&#21644;&#35780;&#20272;&#24037;&#20855;&#21253;&#12290;</title><link>http://arxiv.org/abs/2401.13178</link><description>&lt;p&gt;
AgentBoard: &#19968;&#31181;&#22810;&#36718;LLM&#26234;&#33021;&#20307;&#30340;&#20998;&#26512;&#35780;&#20272;&#26495;
&lt;/p&gt;
&lt;p&gt;
AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents. (arXiv:2401.13178v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13178
&lt;/p&gt;
&lt;p&gt;
AgentBoard&#26159;&#19968;&#20010;&#32508;&#21512;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#35780;&#20272;&#26694;&#26550;&#65292;&#19987;&#20026;&#20998;&#26512;&#35780;&#20272;LLM&#26234;&#33021;&#20307;&#32780;&#35774;&#35745;&#65292;&#35299;&#20915;&#20102;&#22312;&#22810;&#36718;&#20132;&#20114;&#21644;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#20013;&#23545;&#26234;&#33021;&#20307;&#24615;&#33021;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#32454;&#31890;&#24230;&#30340;&#36827;&#23637;&#29575;&#25351;&#26631;&#21644;&#35780;&#20272;&#24037;&#20855;&#21253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20316;&#20026;&#36890;&#29992;&#26234;&#33021;&#20307;&#23545;&#20110;&#29702;&#35299;&#20854;&#33021;&#21147;&#24182;&#20419;&#36827;&#20854;&#34701;&#20837;&#23454;&#38469;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#35780;&#20272;&#36807;&#31243;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#20027;&#35201;&#38556;&#30861;&#20043;&#19968;&#26159;&#22312;&#32479;&#19968;&#26694;&#26550;&#20869;&#23545;&#26234;&#33021;&#20307;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#24615;&#33021;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#29305;&#21035;&#26159;&#22312;&#32500;&#25252;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#21644;&#30830;&#20445;&#22810;&#36718;&#20132;&#20114;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#30340;&#35780;&#20272;&#26694;&#26550;&#20027;&#35201;&#20851;&#27880;&#26368;&#32456;&#25104;&#21151;&#29575;&#65292;&#36807;&#31243;&#20013;&#25552;&#20379;&#30340;&#35265;&#35299;&#24456;&#23569;&#65292;&#26080;&#27861;&#28145;&#20837;&#29702;&#35299;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;AgentBoard&#65292;&#36825;&#26159;&#19968;&#20010;&#21019;&#26032;&#30340;&#32508;&#21512;&#22522;&#20934;&#21644;&#20276;&#38543;&#30340;&#24320;&#28304;&#35780;&#20272;&#26694;&#26550;&#65292;&#19987;&#20026;LLM&#26234;&#33021;&#20307;&#30340;&#20998;&#26512;&#35780;&#20272;&#32780;&#35774;&#35745;&#12290;AgentBoard&#25552;&#20379;&#20102;&#19968;&#31181;&#32454;&#31890;&#24230;&#30340;&#36827;&#23637;&#29575;&#25351;&#26631;&#65292;&#25429;&#25417;&#36880;&#27493;&#30340;&#36827;&#23637;&#65292;&#20197;&#21450;&#19968;&#20010;&#32508;&#21512;&#30340;&#35780;&#20272;&#24037;&#20855;&#21253;&#65292;&#20855;&#26377;&#26131;&#20110;&#35780;&#20272;&#21644;&#20998;&#26512;&#27169;&#22411;&#33021;&#21147;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assess
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;ChatGPT&#21644;GPT-4&#30340;&#20808;&#21069;&#35780;&#20272;&#36827;&#34892;&#20102;&#32508;&#21512;&#20998;&#26512;&#65292;&#20851;&#27880;&#20854;&#35821;&#35328;&#21644;&#25512;&#29702;&#33021;&#21147;&#12289;&#31185;&#23398;&#30693;&#35782;&#21644;&#20262;&#29702;&#32771;&#34385;&#65292;&#25552;&#20986;&#20102;&#20960;&#20010;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2308.12488</link><description>&lt;p&gt;
GPTEval: &#23545;ChatGPT&#21644;GPT-4&#35780;&#20272;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
GPTEval: A Survey on Assessments of ChatGPT and GPT-4. (arXiv:2308.12488v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;ChatGPT&#21644;GPT-4&#30340;&#20808;&#21069;&#35780;&#20272;&#36827;&#34892;&#20102;&#32508;&#21512;&#20998;&#26512;&#65292;&#20851;&#27880;&#20854;&#35821;&#35328;&#21644;&#25512;&#29702;&#33021;&#21147;&#12289;&#31185;&#23398;&#30693;&#35782;&#21644;&#20262;&#29702;&#32771;&#34385;&#65292;&#25552;&#20986;&#20102;&#20960;&#20010;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#30340;&#20986;&#29616;&#24341;&#21457;&#20102;&#23186;&#20307;&#23545;&#20854;&#25200;&#20081;&#31038;&#20250;&#21644;&#32463;&#27982;&#31995;&#32479;&#28508;&#21147;&#30340;&#35768;&#22810;&#29468;&#27979;&#12290;&#20854;&#24778;&#20154;&#30340;&#35821;&#35328;&#33021;&#21147;&#28608;&#36215;&#23398;&#32773;&#20204;&#23545;&#20854;&#22312;&#19981;&#21516;&#39046;&#22495;&#34920;&#29616;&#30340;&#27987;&#21402;&#20852;&#36259;&#12290;&#24050;&#32463;&#26377;&#35768;&#22810;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#21644;GPT-4&#22312;&#19981;&#21516;&#20219;&#21153;&#21644;&#23398;&#31185;&#20013;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#19968;&#39033;&#32508;&#21512;&#24615;&#30340;&#32508;&#36848;&#24635;&#32467;&#38598;&#20307;&#35780;&#20272;&#32467;&#26524;&#12290;&#26412;&#35843;&#26597;&#30340;&#30446;&#26631;&#26159;&#23545;ChatGPT&#21644;GPT-4&#30340;&#20808;&#21069;&#35780;&#20272;&#36827;&#34892;&#28145;&#20837;&#20998;&#26512;&#65292;&#37325;&#28857;&#20851;&#27880;&#20854;&#35821;&#35328;&#21644;&#25512;&#29702;&#33021;&#21147;&#12289;&#31185;&#23398;&#30693;&#35782;&#21644;&#20262;&#29702;&#32771;&#34385;&#12290;&#27492;&#22806;&#65292;&#23545;&#29616;&#26377;&#35780;&#20272;&#26041;&#27861;&#36827;&#34892;&#20102;&#26816;&#26597;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#20010;&#26410;&#26469;&#30740;&#31350;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.
&lt;/p&gt;</description></item></channel></rss>