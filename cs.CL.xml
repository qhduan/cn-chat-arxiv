<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35843;&#26597;&#24635;&#32467;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20844;&#24179;&#24615;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21253;&#25324;&#23545;&#20559;&#35265;&#22240;&#32032;&#30340;&#20998;&#26512;&#12289;&#20844;&#24179;&#24230;&#37327;&#21644;&#29616;&#26377;&#31639;&#27861;&#20998;&#31867;&#12290;</title><link>https://arxiv.org/abs/2404.01349</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20844;&#24179;&#24615;&#65306;&#19968;&#20010;&#20998;&#31867;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Fairness in Large Language Models: A Taxonomic Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01349
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35843;&#26597;&#24635;&#32467;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20844;&#24179;&#24615;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21253;&#25324;&#23545;&#20559;&#35265;&#22240;&#32032;&#30340;&#20998;&#26512;&#12289;&#20844;&#24179;&#24230;&#37327;&#21644;&#29616;&#26377;&#31639;&#27861;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#23637;&#29616;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#23427;&#20204;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#22823;&#22810;&#25968;&#36825;&#20123;&#31639;&#27861;&#32570;&#20047;&#20844;&#24179;&#24615;&#32771;&#34385;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#21487;&#33021;&#23548;&#33268;&#38024;&#23545;&#26576;&#20123;&#31038;&#21306;&#65292;&#29305;&#21035;&#26159;&#36793;&#32536;&#21270;&#20154;&#32676;&#30340;&#27495;&#35270;&#24615;&#32467;&#26524;&#65292;&#20419;&#20351;&#23545;&#20844;&#24179;&#30340;LLMs&#36827;&#34892;&#24191;&#27867;&#30740;&#31350;&#12290;&#19982;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20844;&#24179;&#30456;&#21453;&#65292;&#22312;LLMs&#20013;&#30340;&#20844;&#24179;&#24615;&#28041;&#21450;&#29420;&#29305;&#30340;&#32972;&#26223;&#12289;&#20998;&#31867;&#27861;&#21644;&#23454;&#29616;&#25216;&#26415;&#12290;&#20026;&#27492;&#65292;&#35813;&#35843;&#26597;&#25552;&#20379;&#20102;&#20851;&#20110;&#20844;&#24179;LLMs&#30340;&#29616;&#26377;&#25991;&#29486;&#30740;&#31350;&#36827;&#23637;&#30340;&#20840;&#38754;&#27010;&#36848;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25552;&#20379;&#20102;&#26377;&#20851;LLMs&#30340;&#31616;&#35201;&#20171;&#32461;&#65292;&#25509;&#30528;&#20998;&#26512;&#20102;&#23548;&#33268;LLMs&#20559;&#35265;&#30340;&#22240;&#32032;&#12290;&#27492;&#22806;&#65292;&#20998;&#31867;&#35752;&#35770;&#20102;LLMs&#20013;&#30340;&#20844;&#24179;&#27010;&#24565;&#65292;&#24635;&#32467;&#20102;&#35780;&#20272;LLMs&#20559;&#35265;&#30340;&#25351;&#26631;&#21644;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01349v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable success across various domains. However, despite their promising performance in numerous real-world applications, most of these algorithms lack fairness considerations. Consequently, they may lead to discriminatory outcomes against certain communities, particularly marginalized populations, prompting extensive study in fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in traditional machine learning, entails exclusive backgrounds, taxonomies, and fulfillment techniques. To this end, this survey presents a comprehensive overview of recent advances in the existing literature concerning fair LLMs. Specifically, a brief introduction to LLMs is provided, followed by an analysis of factors contributing to bias in LLMs. Additionally, the concept of fairness in LLMs is discussed categorically, summarizing metrics for evaluating bias in LLMs and existing algorithms 
&lt;/p&gt;</description></item><item><title>Hands-Free VR &#26159;&#19968;&#31181;&#26080;&#38656;&#25163;&#37096;&#25805;&#20316;&#30340;&#34394;&#25311;&#29616;&#23454;&#31995;&#32479;&#65292;&#36890;&#36807;&#35821;&#38899;&#21629;&#20196;&#23454;&#29616;&#65292;&#20855;&#26377;&#33521;&#35821;&#21475;&#38899;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#23545;&#25991;&#26412;&#30340;&#36716;&#25442;&#21644;&#25191;&#34892;&#12290;</title><link>https://arxiv.org/abs/2402.15083</link><description>&lt;p&gt;
&#26080;&#38656;&#25163;&#37096;&#25805;&#20316;&#30340;&#34394;&#25311;&#29616;&#23454;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Hands-Free VR
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15083
&lt;/p&gt;
&lt;p&gt;
Hands-Free VR &#26159;&#19968;&#31181;&#26080;&#38656;&#25163;&#37096;&#25805;&#20316;&#30340;&#34394;&#25311;&#29616;&#23454;&#31995;&#32479;&#65292;&#36890;&#36807;&#35821;&#38899;&#21629;&#20196;&#23454;&#29616;&#65292;&#20855;&#26377;&#33521;&#35821;&#21475;&#38899;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#23545;&#25991;&#26412;&#30340;&#36716;&#25442;&#21644;&#25191;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Hands-Free VR&#30340;&#22522;&#20110;&#35821;&#38899;&#30340;&#33258;&#28982;&#35821;&#35328;&#34394;&#25311;&#29616;&#23454;&#30028;&#38754;&#12290;&#29992;&#25143;&#21487;&#20197;&#36890;&#36807;&#35821;&#38899;&#21457;&#20986;&#21629;&#20196;&#65292;&#20854;&#35821;&#38899;&#38899;&#39057;&#25968;&#25454;&#32463;&#36807;&#19968;&#20010;&#38024;&#23545;&#21333;&#35789;&#38899;&#32032;&#30456;&#20284;&#24615;&#21644;&#33521;&#35821;&#21475;&#38899;&#30340;&#40065;&#26834;&#24615;&#36827;&#34892;&#24494;&#35843;&#30340;&#35821;&#38899;&#35782;&#21035;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36716;&#25442;&#20026;&#25991;&#26412;&#65292;&#28982;&#21518;&#21033;&#29992;&#19968;&#20010;&#23545;&#33258;&#28982;&#35821;&#35328;&#22810;&#26679;&#24615;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#25991;&#26412;&#26144;&#23556;&#20026;&#21487;&#25191;&#34892;&#30340;&#34394;&#25311;&#29616;&#23454;&#21629;&#20196;&#12290;Hands-Free VR&#22312;&#19968;&#20010;&#21463;&#25511;&#30340;&#34987;&#35797;&#30740;&#31350;&#20013;&#65288;N = 22&#65289;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#35201;&#27714;&#21442;&#19982;&#32773;&#25214;&#21040;&#29305;&#23450;&#29289;&#20307;&#24182;&#20197;&#21508;&#31181;&#37197;&#32622;&#25918;&#32622;&#23427;&#20204;&#12290;&#22312;&#23545;&#29031;&#26465;&#20214;&#19979;&#65292;&#21442;&#19982;&#32773;&#20351;&#29992;&#20256;&#32479;&#30340;&#34394;&#25311;&#29616;&#23454;&#29992;&#25143;&#30028;&#38754;&#36890;&#36807;&#25163;&#25345;&#25511;&#21046;&#22120;&#25235;&#21462;&#12289;&#25644;&#36816;&#21644;&#23450;&#20301;&#29289;&#20307;&#12290;&#22312;&#23454;&#39564;&#26465;&#20214;&#19979;&#65292;&#21442;&#19982;&#32773;&#20351;&#29992;Hands-Free VR&#12290;&#32467;&#26524;&#34920;&#26126;&#65306;&#65288;1&#65289;Hands-Free VR&#23545;&#33521;&#35821;&#21475;&#38899;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#22240;&#20026;&#22312;&#25105;&#20204;&#30340;20&#21517;&#21442;&#19982;&#32773;&#20013;&#65292;&#33521;&#35821;&#19981;&#26159;&#20182;&#20204;&#30340;&#39318;&#36873;&#35821;&#35328;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15083v1 Announce Type: cross  Abstract: The paper introduces Hands-Free VR, a voice-based natural-language interface for VR. The user gives a command using their voice, the speech audio data is converted to text using a speech-to-text deep learning model that is fine-tuned for robustness to word phonetic similarity and to spoken English accents, and the text is mapped to an executable VR command using a large language model that is robust to natural language diversity. Hands-Free VR was evaluated in a controlled within-subjects study (N = 22) that asked participants to find specific objects and to place them in various configurations. In the control condition participants used a conventional VR user interface to grab, carry, and position the objects using the handheld controllers. In the experimental condition participants used Hands-Free VR. The results confirm that: (1) Hands-Free VR is robust to spoken English accents, as for 20 of our participants English was not their f
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;DeepSoftDebias&#31639;&#27861;&#65292;&#22312;&#19981;&#21516;&#39046;&#22495;&#25968;&#25454;&#38598;&#12289;&#20934;&#30830;&#24230;&#25351;&#26631;&#21644;NLP&#20219;&#21153;&#20013;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#20854;&#22312;&#20943;&#23569;&#24615;&#21035;&#12289;&#31181;&#26063;&#21644;&#23447;&#25945;&#20559;&#35265;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.11512</link><description>&lt;p&gt;
&#20174;&#20559;&#35265;&#21040;&#24179;&#31561;&#65306;&#21435;&#20559;&#24040;&#22411;&#35821;&#35328;&#27169;&#22411;&#35789;&#23884;&#20837;&#30340;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11512
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;DeepSoftDebias&#31639;&#27861;&#65292;&#22312;&#19981;&#21516;&#39046;&#22495;&#25968;&#25454;&#38598;&#12289;&#20934;&#30830;&#24230;&#25351;&#26631;&#21644;NLP&#20219;&#21153;&#20013;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#20854;&#22312;&#20943;&#23569;&#24615;&#21035;&#12289;&#31181;&#26063;&#21644;&#23447;&#25945;&#20559;&#35265;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23884;&#20837;&#22312;&#24040;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#12290;&#23427;&#20204;&#26159;&#36825;&#20123;&#27169;&#22411;&#25226;&#25569;&#19978;&#19979;&#25991;&#20851;&#31995;&#12289;&#20419;&#36827;&#26356;&#32454;&#33268;&#35821;&#35328;&#29702;&#35299;&#20197;&#21450;&#22312;&#35768;&#22810;&#38656;&#35201;&#23545;&#20154;&#31867;&#35821;&#35328;&#26377;&#22522;&#26412;&#29702;&#35299;&#30340;&#22797;&#26434;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#30340;&#22522;&#30707;&#12290;&#37492;&#20110;&#36825;&#20123;&#23884;&#20837;&#24448;&#24448;&#33258;&#36523;&#21453;&#26144;&#25110;&#23637;&#31034;&#20559;&#35265;&#65292;&#22240;&#27492;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#20063;&#20250;&#26080;&#24847;&#20013;&#23398;&#20064;&#36825;&#31181;&#20559;&#35265;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#22312;&#24320;&#21019;&#24615;&#21069;&#20154;&#30740;&#31350;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;DeepSoftDebias&#65292;&#36825;&#26159;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#8220;&#36719;&#21435;&#20559;&#8221;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21508;&#31867;&#26368;&#20808;&#36827;&#25968;&#25454;&#38598;&#12289;&#20934;&#30830;&#24230;&#25351;&#26631;&#21644;&#20855;&#26377;&#25361;&#25112;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#20840;&#38754;&#35780;&#20272;&#20102;&#36825;&#20010;&#31639;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;DeepSoftDebias&#22312;&#20943;&#23569;&#24615;&#21035;&#12289;&#31181;&#26063;&#21644;&#23447;&#25945;&#20559;&#35265;&#26041;&#38754;&#20248;&#20110;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11512v1 Announce Type: new  Abstract: Embeddings play a pivotal role in the efficacy of Large Language Models. They are the bedrock on which these models grasp contextual relationships and foster a more nuanced understanding of language and consequently perform remarkably on a plethora of complex tasks that require a fundamental understanding of human language. Given that these embeddings themselves often reflect or exhibit bias, it stands to reason that these models may also inadvertently learn this bias. In this work, we build on the seminal previous work and propose DeepSoftDebias, an algorithm that uses a neural network to perform `soft debiasing'. We exhaustively evaluate this algorithm across a variety of SOTA datasets, accuracy metrics, and challenging NLP tasks. We find that DeepSoftDebias outperforms the current state-of-the-art methods at reducing bias across gender, race, and religion.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;Agent-OM&#65292;&#21033;&#29992;LLM&#20195;&#29702;&#20026;&#26412;&#20307;&#21305;&#37197;&#31995;&#32479;&#24341;&#20837;&#20102;&#26032;&#30340;&#35774;&#35745;&#33539;&#24335;&#12290;</title><link>https://arxiv.org/abs/2312.00326</link><description>&lt;p&gt;
Agent-OM&#65306;&#21033;&#29992;LLM&#20195;&#29702;&#36827;&#34892;&#26412;&#20307;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Agent-OM: Leveraging LLM Agents for Ontology Matching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.00326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;Agent-OM&#65292;&#21033;&#29992;LLM&#20195;&#29702;&#20026;&#26412;&#20307;&#21305;&#37197;&#31995;&#32479;&#24341;&#20837;&#20102;&#26032;&#30340;&#35774;&#35745;&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#20307;&#21305;&#37197;&#65288;OM&#65289;&#33021;&#22815;&#23454;&#29616;&#19981;&#21516;&#26412;&#20307;&#20043;&#38388;&#30340;&#35821;&#20041;&#20114;&#25805;&#20316;&#24615;&#65292;&#36890;&#36807;&#23545;&#40784;&#30456;&#20851;&#23454;&#20307;&#26469;&#35299;&#20915;&#20854;&#27010;&#24565;&#24322;&#26500;&#24615;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#20195;&#29702;&#30340;LLM&#35774;&#35745;&#33539;&#24335;&#65292;&#21629;&#21517;&#20026;Agent-OM&#65292;&#21253;&#25324;&#20004;&#20010;&#29992;&#20110;&#26816;&#32034;&#21644;&#21305;&#37197;&#30340;&#21516;&#20307;&#20195;&#29702;&#20197;&#21450;&#19968;&#32452;&#22522;&#20110;&#25552;&#31034;&#30340;&#31616;&#21333;OM&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.00326v2 Announce Type: replace  Abstract: Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM, consisting of two Siamese agents for retrieval and matching, with a set of simple prompt-based OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAE
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;LoBaSS&#65292;&#21033;&#29992;&#25968;&#25454;&#30340;&#21487;&#23398;&#20064;&#24615;&#20316;&#20026;&#36873;&#25321;&#30417;&#30563;&#24494;&#35843;&#25968;&#25454;&#30340;&#20027;&#35201;&#26631;&#20934;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26681;&#25454;&#27169;&#22411;&#30340;&#33021;&#21147;&#23558;&#25968;&#25454;&#36873;&#25321;&#19982;&#27169;&#22411;&#23545;&#40784;&#65292;&#30830;&#20445;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.13008</link><description>&lt;p&gt;
LoBaSS&#65306;&#22312;&#30417;&#30563;&#24494;&#35843;&#25968;&#25454;&#20013;&#27979;&#37327;&#21487;&#23398;&#20064;&#24615;
&lt;/p&gt;
&lt;p&gt;
LoBaSS: Gauging Learnability in Supervised Fine-tuning Data. (arXiv:2310.13008v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;LoBaSS&#65292;&#21033;&#29992;&#25968;&#25454;&#30340;&#21487;&#23398;&#20064;&#24615;&#20316;&#20026;&#36873;&#25321;&#30417;&#30563;&#24494;&#35843;&#25968;&#25454;&#30340;&#20027;&#35201;&#26631;&#20934;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26681;&#25454;&#27169;&#22411;&#30340;&#33021;&#21147;&#23558;&#25968;&#25454;&#36873;&#25321;&#19982;&#27169;&#22411;&#23545;&#40784;&#65292;&#30830;&#20445;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#26159;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#29305;&#23450;&#20219;&#21153;&#30340;&#20808;&#20915;&#26465;&#20214;&#23545;&#40784;&#30340;&#20851;&#38190;&#38454;&#27573;&#12290;&#24494;&#35843;&#25968;&#25454;&#30340;&#36873;&#25321;&#28145;&#21051;&#24433;&#21709;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#20256;&#32479;&#19978;&#20197;&#25968;&#25454;&#36136;&#37327;&#21644;&#20998;&#24067;&#20026;&#22522;&#30784;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SFT&#25968;&#25454;&#36873;&#25321;&#30340;&#19968;&#20010;&#26032;&#32500;&#24230;&#65306;&#21487;&#23398;&#20064;&#24615;&#12290;&#36825;&#20010;&#26032;&#32500;&#24230;&#30340;&#21160;&#26426;&#26159;&#30001;LLM&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#33719;&#24471;&#30340;&#33021;&#21147;&#12290;&#37492;&#20110;&#19981;&#21516;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#20855;&#26377;&#19981;&#21516;&#30340;&#33021;&#21147;&#65292;&#36866;&#21512;&#19968;&#20010;&#27169;&#22411;&#30340;SFT&#25968;&#25454;&#21487;&#33021;&#19981;&#36866;&#21512;&#21478;&#19968;&#20010;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23398;&#20064;&#33021;&#21147;&#36825;&#20010;&#26415;&#35821;&#26469;&#23450;&#20041;&#25968;&#25454;&#23545;&#27169;&#22411;&#36827;&#34892;&#26377;&#25928;&#23398;&#20064;&#30340;&#36866;&#21512;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25439;&#22833;&#30340;SFT&#25968;&#25454;&#36873;&#25321;&#65288;LoBaSS&#65289;&#26041;&#27861;&#65292;&#21033;&#29992;&#25968;&#25454;&#30340;&#21487;&#23398;&#20064;&#24615;&#20316;&#20026;&#36873;&#25321;SFT&#25968;&#25454;&#30340;&#20027;&#35201;&#26631;&#20934;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#32454;&#33268;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#23558;&#25968;&#25454;&#36873;&#25321;&#19982;&#22266;&#26377;&#30340;&#27169;&#22411;&#33021;&#21147;&#23545;&#40784;&#65292;&#30830;&#20445;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites. The selection of fine-tuning data profoundly influences the model's performance, whose principle is traditionally grounded in data quality and distribution. In this paper, we introduce a new dimension in SFT data selection: learnability. This new dimension is motivated by the intuition that SFT unlocks capabilities acquired by a LLM during the pretraining phase. Given that different pretrained models have disparate capabilities, the SFT data appropriate for one may not suit another. Thus, we introduce the term learnability to define the suitability of data for effective learning by the model. We present the Loss Based SFT Data Selection (LoBaSS) method, utilizing data learnability as the principal criterion for the selection SFT data. This method provides a nuanced approach, allowing the alignment of data selection with inherent model capabilities, ensuring op
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;UOR&#65292;&#21487;&#20197;&#33258;&#21160;&#36873;&#25321;&#35302;&#21457;&#22120;&#24182;&#23398;&#20064;&#36890;&#29992;&#36755;&#20986;&#34920;&#31034;&#65292;&#25104;&#21151;&#29575;&#39640;&#36798;99.3&#65285;&#65292;&#33021;&#22815;&#23545;&#22810;&#31181;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#19979;&#28216;&#20219;&#21153;&#23454;&#26045;&#25915;&#20987;&#65292;&#19988;&#21487;&#31361;&#30772;&#26368;&#26032;&#30340;&#38450;&#24481;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.09574</link><description>&lt;p&gt;
UOR&#65306;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
UOR: Universal Backdoor Attacks on Pre-trained Language Models. (arXiv:2305.09574v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;UOR&#65292;&#21487;&#20197;&#33258;&#21160;&#36873;&#25321;&#35302;&#21457;&#22120;&#24182;&#23398;&#20064;&#36890;&#29992;&#36755;&#20986;&#34920;&#31034;&#65292;&#25104;&#21151;&#29575;&#39640;&#36798;99.3&#65285;&#65292;&#33021;&#22815;&#23545;&#22810;&#31181;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#19979;&#28216;&#20219;&#21153;&#23454;&#26045;&#25915;&#20987;&#65292;&#19988;&#21487;&#31361;&#30772;&#26368;&#26032;&#30340;&#38450;&#24481;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#26893;&#20837;&#21518;&#38376;&#21487;&#20197;&#20256;&#36882;&#21040;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#36825;&#23545;&#23433;&#20840;&#26500;&#25104;&#20102;&#20005;&#37325;&#23041;&#32961;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#38024;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#21518;&#38376;&#25915;&#20987;&#22823;&#37117;&#26159;&#38750;&#30446;&#26631;&#21644;&#29305;&#23450;&#20219;&#21153;&#30340;&#12290;&#24456;&#23569;&#26377;&#38024;&#23545;&#30446;&#26631;&#21644;&#20219;&#21153;&#19981;&#21487;&#30693;&#24615;&#30340;&#26041;&#27861;&#20351;&#29992;&#25163;&#21160;&#39044;&#23450;&#20041;&#30340;&#35302;&#21457;&#22120;&#21644;&#36755;&#20986;&#34920;&#31034;&#65292;&#36825;&#20351;&#24471;&#25915;&#20987;&#25928;&#26524;&#19981;&#22815;&#24378;&#22823;&#21644;&#26222;&#36866;&#12290;&#26412;&#25991;&#39318;&#20808;&#24635;&#32467;&#20102;&#19968;&#20010;&#26356;&#20855;&#23041;&#32961;&#24615;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21518;&#38376;&#25915;&#20987;&#24212;&#28385;&#36275;&#30340;&#35201;&#27714;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#38376;&#25915;&#20987;&#26041;&#27861;UOR&#65292;&#36890;&#36807;&#23558;&#25163;&#21160;&#36873;&#25321;&#21464;&#25104;&#33258;&#21160;&#20248;&#21270;&#65292;&#25171;&#30772;&#20102;&#20197;&#24448;&#26041;&#27861;&#30340;&#29942;&#39048;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#34987;&#27745;&#26579;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#65292;&#21487;&#20197;&#33258;&#21160;&#23398;&#20064;&#21508;&#31181;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#35302;&#21457;&#22120;&#30340;&#26356;&#21152;&#22343;&#21248;&#21644;&#36890;&#29992;&#36755;&#20986;&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#26799;&#24230;&#25628;&#32034;&#36873;&#21462;&#36866;&#24403;&#30340;&#35302;&#21457;&#35789;&#65292;&#21487;&#20197;&#36866;&#24212;&#19981;&#21516;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#21644;&#35789;&#27719;&#34920;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;UOR&#21487;&#20197;&#22312;&#21508;&#31181;PLMs&#21644;&#19979;&#28216;&#20219;&#21153;&#20013;&#23454;&#29616;&#39640;&#21518;&#38376;&#25104;&#21151;&#29575;&#65288;&#39640;&#36798;99.3&#65285;&#65289;&#65292;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;UOR&#36824;&#21487;&#20197;&#31361;&#30772;&#23545;&#25239;&#21518;&#38376;&#25915;&#20987;&#30340;&#26368;&#26032;&#38450;&#24481;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Backdoors implanted in pre-trained language models (PLMs) can be transferred to various downstream tasks, which exposes a severe security threat. However, most existing backdoor attacks against PLMs are un-targeted and task-specific. Few targeted and task-agnostic methods use manually pre-defined triggers and output representations, which prevent the attacks from being more effective and general. In this paper, we first summarize the requirements that a more threatening backdoor attack against PLMs should satisfy, and then propose a new backdoor attack method called UOR, which breaks the bottleneck of the previous approach by turning manual selection into automatic optimization. Specifically, we define poisoned supervised contrastive learning which can automatically learn the more uniform and universal output representations of triggers for various PLMs. Moreover, we use gradient search to select appropriate trigger words which can be adaptive to different PLMs and vocabularies. Experi
&lt;/p&gt;</description></item></channel></rss>