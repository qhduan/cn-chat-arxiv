<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#25968;&#25454;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;</title><link>https://arxiv.org/abs/2311.16466</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#35821;&#35328;&#29305;&#24449;&#23545;&#40784;&#21487;&#20197;&#22686;&#24378;&#35828;&#26381;&#21147;
&lt;/p&gt;
&lt;p&gt;
Large language models can enhance persuasion through linguistic feature alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#25968;&#25454;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLMs)&#27491;&#22312;&#37325;&#26032;&#22609;&#36896;&#20154;&#31867;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#20294;&#25105;&#20204;&#23545;&#23427;&#20204;&#30340;&#24433;&#21709;&#30340;&#29702;&#35299;&#20173;&#28982;&#26377;&#20123;&#21463;&#38480;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;LLMs&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#30340;&#25968;&#25454;&#12290;&#36890;&#36807;&#23545;&#28040;&#36153;&#32773;&#37329;&#34701;&#20445;&#25252;&#23616; (CFPB) &#25910;&#38598;&#30340;&#36229;&#36807;820,000&#20010;&#25237;&#35785;&#36827;&#34892;AI&#26816;&#27979;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;ChatGPT&#21457;&#24067;&#21518;&#19981;&#20037;&#65292;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#24615;&#24613;&#21095;&#22686;&#21152;&#12290;&#27492;&#22806;&#65292;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#24615;&#19982;&#20449;&#24687;&#35828;&#26381;&#21147;&#65288;&#21363;&#20174;&#37329;&#34701;&#20844;&#21496;&#33719;&#24471;&#25937;&#27982;&#30340;&#21487;&#33021;&#24615;&#22686;&#21152;&#65289;&#21576;&#27491;&#30456;&#20851;&#12290;&#35745;&#31639;&#35821;&#35328;&#20998;&#26512;&#34920;&#26126;&#65292;&#36825;&#31181;&#27491;&#30456;&#20851;&#21487;&#33021;&#26159;&#30001;LLMs&#22686;&#24378;&#20102;&#21508;&#31181;&#35821;&#35328;&#29305;&#24449;&#25152;&#35299;&#37322;&#30340;&#12290;&#26681;&#25454;&#36825;&#20123;&#35266;&#23519;&#30740;&#31350;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#20551;&#35774;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#23545;&#20855;&#26377;&#19981;&#21516;&#35821;&#35328;&#32972;&#26223;&#30340;&#25509;&#25910;&#32773;&#30340;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although large language models (LLMs) are reshaping various aspects of human life, our current understanding of their impacts remains somewhat constrained. Here we investigate the impact of LLMs on human communication, using data on consumer complaints in the financial industry. By employing an AI detection tool on more than 820K complaints gathered by the Consumer Financial Protection Bureau (CFPB), we find a sharp increase in the likely use of LLMs shortly after the release of ChatGPT. Moreover, the likely LLM usage was positively correlated with message persuasiveness (i.e., increased likelihood of obtaining relief from financial firms). Computational linguistic analyses suggest that the positive correlation may be explained by LLMs' enhancement of various linguistic features. Based on the results of these observational studies, we hypothesize that LLM usage may enhance a comprehensive set of linguistic features, increasing message persuasiveness to receivers with heterogeneous ling
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102; ChatGPT &#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#65292;&#32467;&#26524;&#34920;&#26126; ChatGPT &#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#65292;&#24182;&#19988;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#12290;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2304.00228</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models can rate news outlet credibility. (arXiv:2304.00228v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00228
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102; ChatGPT &#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#65292;&#32467;&#26524;&#34920;&#26126; ChatGPT &#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#65292;&#24182;&#19988;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#12290;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#20135;&#29983;&#24187;&#35937;&#12290;&#29616;&#20195;&#26368;&#20808;&#36827;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#22914;&#26032;&#30340; Bing&#65292;&#23581;&#35797;&#36890;&#36807;&#30452;&#25509;&#20174;&#20114;&#32852;&#32593;&#25910;&#38598;&#20449;&#24687;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#21306;&#20998;&#20540;&#24471;&#20449;&#36182;&#30340;&#20449;&#24687;&#28304;&#23545;&#20110;&#21521;&#29992;&#25143;&#25552;&#20379;&#36866;&#24403;&#30340;&#20934;&#30830;&#24615;&#32972;&#26223;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#30693;&#21517;&#30340;LLM ChatGPT&#26159;&#21542;&#33021;&#22815;&#35780;&#20272;&#26032;&#38395;&#26426;&#26500;&#30340;&#21487;&#20449;&#24230;&#12290;&#22312;&#36866;&#24403;&#30340;&#25351;&#23548;&#19979;&#65292;ChatGPT&#21487;&#20197;&#20026;&#19981;&#21516;&#35821;&#35328;&#21644;&#35773;&#21050;&#24615;&#36164;&#28304;&#30340;&#26032;&#38395;&#26426;&#26500;&#25552;&#20379;&#35780;&#32423;&#21450;&#20854;&#32972;&#26223;&#35828;&#26126;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#35780;&#32423;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#32423;&#30456;&#20851;&#65288;Spearmam's $\rho=0.54, p&lt;0.001$&#65289;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#65292;LLMs&#21487;&#20197;&#25104;&#20026;&#20107;&#23454;&#26816;&#26597;&#24212;&#29992;&#31243;&#24207;&#20013;&#21487;&#20449;&#24230;&#35780;&#32423;&#30340;&#32463;&#27982;&#21442;&#32771;&#12290;&#26410;&#26469;&#30340;LLMs&#24212;&#22686;&#24378;&#23427;&#20204;&#30340;&#23545;&#40784;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although large language models (LLMs) have shown exceptional performance in various natural language processing tasks, they are prone to hallucinations. State-of-the-art chatbots, such as the new Bing, attempt to mitigate this issue by gathering information directly from the internet to ground their answers. In this setting, the capacity to distinguish trustworthy sources is critical for providing appropriate accuracy contexts to users. Here we assess whether ChatGPT, a prominent LLM, can evaluate the credibility of news outlets. With appropriate instructions, ChatGPT can provide ratings for a diverse set of news outlets, including those in non-English languages and satirical sources, along with contextual explanations. Our results show that these ratings correlate with those from human experts (Spearmam's $\rho=0.54, p&lt;0.001$). These findings suggest that LLMs could be an affordable reference for credibility ratings in fact-checking applications. Future LLMs should enhance their align
&lt;/p&gt;</description></item></channel></rss>