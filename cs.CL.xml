<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>RAPT&#26159;&#19968;&#20010;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#25552;&#31034;&#35843;&#25972;&#26694;&#26550;&#65292;&#37319;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#21644;&#26032;&#39062;&#30340;&#38544;&#31169;&#21270;&#26631;&#35760;&#37325;&#24314;&#20219;&#21153;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#21644;&#33391;&#22909;&#30340;&#38544;&#31169;&#20445;&#25252;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.06212</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#38544;&#31169;&#20445;&#25252;&#25552;&#31034;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Prompt Tuning for Large Language Model Services. (arXiv:2305.06212v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06212
&lt;/p&gt;
&lt;p&gt;
RAPT&#26159;&#19968;&#20010;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#30340;&#25552;&#31034;&#35843;&#25972;&#26694;&#26550;&#65292;&#37319;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#21644;&#26032;&#39062;&#30340;&#38544;&#31169;&#21270;&#26631;&#35760;&#37325;&#24314;&#20219;&#21153;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#21644;&#33391;&#22909;&#30340;&#38544;&#31169;&#20445;&#25252;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#31034;&#35843;&#25972;&#20026;&#29992;&#25143;&#22312;&#26032;&#20852;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#26381;&#21153;&#22330;&#26223;&#19979;&#20351;&#29992;&#20854;&#31169;&#26377;&#25968;&#25454;&#33258;&#23450;&#20041;&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#26377;&#25928;&#26041;&#24335;&#12290;&#20294;&#26159;&#65292;&#31169;&#26377;&#25968;&#25454;&#30340;&#25935;&#24863;&#24615;&#38656;&#35201;&#22312;LLM&#26381;&#21153;&#23450;&#21046;&#20013;&#20445;&#25252;&#38544;&#31169;&#12290;&#22522;&#20110;&#25552;&#31034;&#35843;&#25972;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#38544;&#31169;&#20445;&#25252;&#25552;&#31034;&#35843;&#25972;(RAPT)&#30340;&#26694;&#26550;&#65292;&#20026;LLM&#26381;&#21153;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#12290;RAPT&#37319;&#29992;&#26412;&#22320;&#38544;&#31169;&#35774;&#32622;&#65292;&#20801;&#35768;&#29992;&#25143;&#20351;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#23545;&#20854;&#25968;&#25454;&#36827;&#34892;&#26412;&#22320;&#21270;&#38544;&#31169;&#22788;&#29702;&#12290;&#30001;&#20110;&#22312;&#30452;&#25509;&#35757;&#32451;&#38544;&#31169;&#21270;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#31034;&#35843;&#25972;&#34920;&#29616;&#19981;&#20339;&#65292;&#22240;&#27492;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38544;&#31169;&#21270;&#26631;&#35760;&#37325;&#24314;&#20219;&#21153;&#65292;&#19982;&#19979;&#28216;&#20219;&#21153;&#19968;&#36215;&#36827;&#34892;&#22521;&#35757;&#65292;&#20351;LLM&#23398;&#20064;&#26356;&#22909;&#30340;&#20219;&#21153;&#30456;&#20851;&#34920;&#31034;&#12290;&#23613;&#31649;&#25105;&#20204;&#30340;&#26694;&#26550;&#31616;&#21333;&#65292;&#20294;&#23454;&#39564;&#34920;&#26126;&#65292;RAPT&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#22343;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#25269;&#24481;&#23545;&#25163;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prompt tuning provides an efficient way for users to customize Large Language Models (LLMs) with their private data in the emerging LLM service scenario. However, the sensitive nature of private data brings the need for privacy preservation in LLM service customization. Based on prompt tuning, we propose Privacy-Preserving Prompt Tuning (RAPT), a framework that provides privacy guarantees for LLM services. \textsc{rapt} adopts a local privacy setting, allowing users to privatize their data locally with local differential privacy. As prompt tuning performs poorly when directly trained on privatized data, we introduce a novel privatized token reconstruction task that is trained jointly with the downstream task, allowing LLMs to learn better task-dependent representations. Despite the simplicity of our framework, experiments show that RAPT achieves competitive performance across tasks while providing privacy guarantees against adversaries.
&lt;/p&gt;</description></item></channel></rss>