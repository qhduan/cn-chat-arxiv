<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24187;&#35273;&#30340;&#26816;&#27979;&#12289;&#35299;&#37322;&#21644;&#32531;&#35299;&#30340;&#26368;&#26032;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#24187;&#35273;&#29616;&#35937;&#21644;&#35780;&#20272;&#22522;&#20934;&#30340;&#20998;&#31867;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#28508;&#22312;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2309.01219</link><description>&lt;p&gt;
AI&#28023;&#27915;&#20013;&#30340;&#22934;&#24618;&#20043;&#27468;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models. (arXiv:2309.01219v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01219
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24187;&#35273;&#30340;&#26816;&#27979;&#12289;&#35299;&#37322;&#21644;&#32531;&#35299;&#30340;&#26368;&#26032;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#24187;&#35273;&#29616;&#35937;&#21644;&#35780;&#20272;&#22522;&#20934;&#30340;&#20998;&#31867;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#28508;&#22312;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#20154;&#20204;&#23545;&#20854;&#20135;&#29983;&#24187;&#35273;&#30340;&#20542;&#21521;&#34920;&#31034;&#25285;&#24551;&#65306;LLMs&#26377;&#26102;&#20250;&#29983;&#25104;&#19982;&#29992;&#25143;&#36755;&#20837;&#19981;&#31526;&#12289;&#19982;&#20808;&#21069;&#29983;&#25104;&#30340;&#20869;&#23481;&#30456;&#30683;&#30462;&#25110;&#19982;&#24050;&#24314;&#31435;&#30340;&#19990;&#30028;&#30693;&#35782;&#19981;&#31526;&#30340;&#20869;&#23481;&#12290;&#36825;&#31181;&#29616;&#35937;&#23545;LLMs&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#21487;&#38752;&#24615;&#26500;&#25104;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#26412;&#25991;&#23545;&#20851;&#20110;&#24187;&#35273;&#26816;&#27979;&#12289;&#35299;&#37322;&#21644;&#32531;&#35299;&#30340;&#26368;&#26032;&#30740;&#31350;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#37325;&#28857;&#25506;&#35752;&#20102;LLMs&#25152;&#38754;&#20020;&#30340;&#29420;&#29305;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;LLM&#24187;&#35273;&#29616;&#35937;&#21644;&#35780;&#20272;&#22522;&#20934;&#30340;&#20998;&#31867;&#65292;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#26088;&#22312;&#32531;&#35299;LLM&#24187;&#35273;&#30340;&#26041;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#28508;&#22312;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23391;&#21152;&#25289;&#35821;&#20013;&#20551;&#26032;&#38395;&#30340;&#26816;&#27979;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#24635;&#32467;&#21644;&#25193;&#20805;&#25216;&#26415;&#65292;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22235;&#37325;&#26041;&#27861;&#26469;&#20998;&#31867;&#23391;&#21152;&#25289;&#35821;&#30340;&#20551;&#26032;&#38395;&#25991;&#31456;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#24635;&#32467;&#21644;&#25193;&#20805;&#22312;&#23391;&#21152;&#25289;&#35821;&#20551;&#26032;&#38395;&#26816;&#27979;&#20013;&#20855;&#26377;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.06979</link><description>&lt;p&gt;
&#35299;&#20915;&#23391;&#21152;&#25289;&#35821;&#20013;&#30340;&#20551;&#26032;&#38395;&#38382;&#39064;&#65306;&#25581;&#31034;&#24635;&#32467;&#19982;&#25193;&#20805;&#23545;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Tackling Fake News in Bengali: Unraveling the Impact of Summarization vs. Augmentation on Pre-trained Language Models. (arXiv:2307.06979v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06979
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#23391;&#21152;&#25289;&#35821;&#20013;&#20551;&#26032;&#38395;&#30340;&#26816;&#27979;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#24635;&#32467;&#21644;&#25193;&#20805;&#25216;&#26415;&#65292;&#32467;&#21512;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22235;&#37325;&#26041;&#27861;&#26469;&#20998;&#31867;&#23391;&#21152;&#25289;&#35821;&#30340;&#20551;&#26032;&#38395;&#25991;&#31456;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#24635;&#32467;&#21644;&#25193;&#20805;&#22312;&#23391;&#21152;&#25289;&#35821;&#20551;&#26032;&#38395;&#26816;&#27979;&#20013;&#20855;&#26377;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#21644;&#22312;&#32447;&#26032;&#38395;&#26469;&#28304;&#30340;&#20852;&#36215;&#65292;&#20551;&#26032;&#38395;&#24050;&#25104;&#20026;&#20840;&#29699;&#24615;&#30340;&#37325;&#22823;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#20687;&#23391;&#21152;&#25289;&#35821;&#36825;&#26679;&#30340;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#26816;&#27979;&#20551;&#26032;&#38395;&#22312;&#30740;&#31350;&#20013;&#21463;&#21040;&#20102;&#26377;&#38480;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21033;&#29992;&#24635;&#32467;&#21644;&#25193;&#20805;&#25216;&#26415;&#20197;&#21450;&#20116;&#31181;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#26469;&#20998;&#31867;&#23391;&#21152;&#25289;&#35821;&#30340;&#20551;&#26032;&#38395;&#25991;&#31456;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#23558;&#33521;&#35821;&#26032;&#38395;&#25991;&#31456;&#36827;&#34892;&#32763;&#35793;&#65292;&#24182;&#20351;&#29992;&#25193;&#20805;&#25216;&#26415;&#26469;&#35299;&#20915;&#20551;&#26032;&#38395;&#25991;&#31456;&#30340;&#19981;&#36275;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#36824;&#30528;&#37325;&#20110;&#36890;&#36807;&#24635;&#32467;&#26032;&#38395;&#26469;&#35299;&#20915;&#22522;&#20110;BERT&#27169;&#22411;&#30340;&#20196;&#29260;&#38271;&#24230;&#38480;&#21046;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#21644;&#20005;&#26684;&#30340;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24635;&#32467;&#21644;&#25193;&#20805;&#22312;&#23391;&#21152;&#25289;&#35821;&#20551;&#26032;&#38395;&#26816;&#27979;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#19977;&#20010;&#29420;&#31435;&#30340;&#27979;&#35797;&#25968;&#25454;&#38598;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;&#24403;&#23558;BanglaBERT&#22522;&#30784;&#27169;&#22411;&#19982;&#25193;&#20805;&#25216;&#26415;&#30456;&#32467;&#21512;&#26102;&#65292;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rise of social media and online news sources, fake news has become a significant issue globally. However, the detection of fake news in low resource languages like Bengali has received limited attention in research. In this paper, we propose a methodology consisting of four distinct approaches to classify fake news articles in Bengali using summarization and augmentation techniques with five pre-trained language models. Our approach includes translating English news articles and using augmentation techniques to curb the deficit of fake news articles. Our research also focused on summarizing the news to tackle the token length limitation of BERT based models. Through extensive experimentation and rigorous evaluation, we show the effectiveness of summarization and augmentation in the case of Bengali fake news detection. We evaluated our models using three separate test datasets. The BanglaBERT Base model, when combined with augmentation techniques, achieved an impressive accurac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20026;&#20160;&#20040;&#22312;&#39044;&#35757;&#32451;&#20043;&#21518;&#65292;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#23454;&#29616;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20551;&#35774;&#65292;&#35748;&#20026;LLMs&#22312;&#38754;&#23545;&#19978;&#19979;&#25991;&#31034;&#20363;&#26102;&#33021;&#22815;&#36890;&#36807;&#20869;&#37096;&#34920;&#31034;&#27169;&#25311;&#26680;&#22238;&#24402;&#12290;</title><link>http://arxiv.org/abs/2305.12766</link><description>&lt;p&gt;
&#23558; Emergent In-Context Learning &#35299;&#37322;&#20026;&#26680;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Explaining Emergent In-Context Learning as Kernel Regression. (arXiv:2305.12766v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20026;&#20160;&#20040;&#22312;&#39044;&#35757;&#32451;&#20043;&#21518;&#65292;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#23454;&#29616;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20551;&#35774;&#65292;&#35748;&#20026;LLMs&#22312;&#38754;&#23545;&#19978;&#19979;&#25991;&#31034;&#20363;&#26102;&#33021;&#22815;&#36890;&#36807;&#20869;&#37096;&#34920;&#31034;&#27169;&#25311;&#26680;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#24341;&#36215;&#20102;&#19968;&#22330;&#33539;&#24335;&#36716;&#21464;&#12290;&#19982;&#32463;&#20856;&#30340;&#39044;&#35757;&#32451;-&#24494;&#35843;&#36807;&#31243;&#30456;&#27604;&#65292;&#20026;&#20102;&#23558;LLMs&#29992;&#20110;&#19979;&#28216;&#39044;&#27979;&#20219;&#21153;&#65292;&#21482;&#38656;&#35201;&#25552;&#20379;&#19968;&#20123;&#31034;&#20363;&#65292;&#21363;&#19978;&#19979;&#25991;&#31034;&#20363;&#65292;&#32780;&#26080;&#38656;&#28155;&#21152;&#25110;&#26356;&#26032;&#29616;&#26377;&#30340;&#27169;&#22411;&#21442;&#25968;&#12290;LLMs&#30340;&#36825;&#31181;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#38750;&#24120;&#26377;&#24847;&#24605;&#65292;&#20294;&#30446;&#21069;&#23578;&#19981;&#23436;&#20840;&#20102;&#35299;&#39044;&#35757;&#32451;LLMs&#22914;&#20309;&#33719;&#24471;&#36825;&#31181;&#33021;&#21147;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#20551;&#35774;&#65292;&#21363;&#24403;&#38754;&#20020;&#19978;&#19979;&#25991;&#31034;&#20363;&#26102;&#65292;LLMs&#33021;&#22815;&#36890;&#36807;&#20869;&#37096;&#34920;&#31034;&#27169;&#25311;&#26680;&#22238;&#24402;&#65292;&#26469;&#30740;&#31350;&#20026;&#20309;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#22312;&#39044;&#35757;&#32451;&#36890;&#29992;&#35821;&#26009;&#24211;&#20043;&#21518;&#23454;&#29616;&#19978;&#19979;&#25991;&#23398;&#20064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#19978;&#19979;&#25991;&#25552;&#31034;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#21487;&#20197;&#34987;&#29702;&#35299;&#20026;&#26680;&#22238;&#24402; $\hat y = \sum_i y_i K(x, x_i)/\sum_i K(x, x_i)$&#65292;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have initiated a paradigm shift in transfer learning. In contrast to the classic pretraining-then-finetuning procedure, in order to use LLMs for downstream prediction tasks, one only needs to provide a few demonstrations, known as in-context examples, without adding more or updating existing model parameters. This in-context learning (ICL) capability of LLMs is intriguing, and it is not yet fully understood how pretrained LLMs acquire such capabilities. In this paper, we investigate the reason why a transformer-based language model can accomplish in-context learning after pre-training on a general language corpus by proposing one hypothesis that LLMs can simulate kernel regression with internal representations when faced with in-context examples. More concretely, we first prove that Bayesian inference on in-context prompts can be asymptotically understood as kernel regression $\hat y = \sum_i y_i K(x, x_i)/\sum_i K(x, x_i)$ as the number of in-context demon
&lt;/p&gt;</description></item></channel></rss>