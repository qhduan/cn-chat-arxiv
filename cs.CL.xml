<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>RealKIE&#25552;&#20379;&#20102;&#20116;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20225;&#19994;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;&#65292;&#20026;&#25237;&#36164;&#20998;&#26512;&#21644;&#27861;&#24459;&#25968;&#25454;&#22788;&#29702;&#31561;&#20219;&#21153;&#25552;&#20379;&#20102;&#29616;&#23454;&#30340;&#27979;&#35797;&#22522;&#22320;&#65292;&#24182;&#20026;NLP&#27169;&#22411;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2403.20101</link><description>&lt;p&gt;
RealKIE: &#20116;&#20010;&#26032;&#39062;&#30340;&#20225;&#19994;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
RealKIE: Five Novel Datasets for Enterprise Key Information Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20101
&lt;/p&gt;
&lt;p&gt;
RealKIE&#25552;&#20379;&#20102;&#20116;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20225;&#19994;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#25968;&#25454;&#38598;&#65292;&#20026;&#25237;&#36164;&#20998;&#26512;&#21644;&#27861;&#24459;&#25968;&#25454;&#22788;&#29702;&#31561;&#20219;&#21153;&#25552;&#20379;&#20102;&#29616;&#23454;&#30340;&#27979;&#35797;&#22522;&#22320;&#65292;&#24182;&#20026;NLP&#27169;&#22411;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;RealKIE&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#25512;&#21160;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#26041;&#27861;&#21457;&#23637;&#30340;&#20116;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#22522;&#20934;&#65292;&#37325;&#28857;&#26159;&#20225;&#19994;&#24212;&#29992;&#12290;&#36825;&#20123;&#25968;&#25454;&#38598;&#21253;&#25324;&#32654;&#22269;SEC S1&#25991;&#20214;&#12289;&#32654;&#22269;&#20445;&#23494;&#21327;&#35758;&#12289;&#33521;&#22269;&#24904;&#21892;&#25253;&#21578;&#12289;FCC&#21457;&#31080;&#21644;&#36164;&#28304;&#21512;&#21516;&#31561;&#21508;&#31181;&#31867;&#22411;&#30340;&#25991;&#26723;&#12290;&#27599;&#20010;&#25968;&#25454;&#38598;&#37117;&#20855;&#26377;&#29420;&#29305;&#30340;&#25361;&#25112;&#65306;&#25991;&#26412;&#24207;&#21015;&#21270;&#19981;&#20339;&#12289;&#38271;&#25991;&#26723;&#20013;&#31232;&#30095;&#30340;&#27880;&#37322;&#21644;&#22797;&#26434;&#30340;&#34920;&#26684;&#24067;&#23616;&#12290;&#36825;&#20123;&#25968;&#25454;&#38598;&#20026;&#20851;&#38190;&#20449;&#24687;&#25552;&#21462;&#20219;&#21153;&#65288;&#22914;&#25237;&#36164;&#20998;&#26512;&#21644;&#27861;&#24459;&#25968;&#25454;&#22788;&#29702;&#65289;&#25552;&#20379;&#20102;&#19968;&#20010;&#29616;&#23454;&#30340;&#27979;&#35797;&#22522;&#22320;&#12290;&#38500;&#20102;&#20171;&#32461;&#36825;&#20123;&#25968;&#25454;&#38598;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23545;&#27880;&#37322;&#36807;&#31243;&#12289;&#25991;&#26723;&#22788;&#29702;&#25216;&#26415;&#21644;&#22522;&#32447;&#24314;&#27169;&#26041;&#27861;&#30340;&#28145;&#20837;&#25551;&#36848;&#12290;&#36825;&#19968;&#36129;&#29486;&#20419;&#36827;&#20102;&#33021;&#22815;&#22788;&#29702;&#23454;&#38469;&#25361;&#25112;&#30340;NLP&#27169;&#22411;&#30340;&#21457;&#23637;&#65292;&#24182;&#25903;&#25345;&#36827;&#19968;&#27493;&#30740;&#31350;&#21487;&#24212;&#29992;&#20110;&#24037;&#19994;&#30340;&#20449;&#24687;&#25552;&#21462;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20101v1 Announce Type: new  Abstract: We introduce RealKIE, a benchmark of five challenging datasets aimed at advancing key information extraction methods, with an emphasis on enterprise applications. The datasets include a diverse range of documents including SEC S1 Filings, US Non-disclosure Agreements, UK Charity Reports, FCC Invoices, and Resource Contracts. Each presents unique challenges: poor text serialization, sparse annotations in long documents, and complex tabular layouts. These datasets provide a realistic testing ground for key information extraction tasks like investment analysis and legal data processing.   In addition to presenting these datasets, we offer an in-depth description of the annotation process, document processing techniques, and baseline modeling approaches. This contribution facilitates the development of NLP models capable of handling practical challenges and supports further research into information extraction technologies applicable to indu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;Rowen&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#26816;&#32034;&#22686;&#24378;&#36807;&#31243;&#65292;&#37319;&#29992;&#22810;&#35821;&#20041;&#24863;&#30693;&#26816;&#27979;&#27169;&#22359;&#26469;&#24179;&#34913;&#21442;&#25968;&#21270;&#30693;&#35782;&#21644;&#22806;&#37096;&#20449;&#24687;&#65292;&#20197;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.10612</link><description>&lt;p&gt;
&#20165;&#22312;&#38656;&#35201;&#26102;&#26816;&#32034;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#36866;&#24212;&#24615;&#26816;&#32034;&#22686;&#24378;&#20197;&#20943;&#36731;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;Rowen&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#26816;&#32034;&#22686;&#24378;&#36807;&#31243;&#65292;&#37319;&#29992;&#22810;&#35821;&#20041;&#24863;&#30693;&#26816;&#27979;&#27169;&#22359;&#26469;&#24179;&#34913;&#21442;&#25968;&#21270;&#30693;&#35782;&#21644;&#22806;&#37096;&#20449;&#24687;&#65292;&#20197;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24187;&#35273;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23454;&#38469;&#23454;&#26045;&#26500;&#25104;&#20102;&#26174;&#33879;&#25361;&#25112;&#12290;&#29983;&#25104;&#20107;&#23454;&#20869;&#23481;&#26102;&#21033;&#29992;&#21442;&#25968;&#21270;&#30693;&#35782;&#21463;&#21040;LLMs&#26377;&#38480;&#30693;&#35782;&#30340;&#38480;&#21046;&#65292;&#21487;&#33021;&#23548;&#33268;&#20869;&#37096;&#24187;&#35273;&#12290;&#34429;&#28982;&#25972;&#21512;&#22806;&#37096;&#20449;&#24687;&#21487;&#20197;&#22635;&#34917;&#30693;&#35782;&#31354;&#30333;&#65292;&#20294;&#20063;&#20250;&#24341;&#20837;&#26080;&#20851;&#20449;&#24687;&#30340;&#39118;&#38505;&#65292;&#20174;&#32780;&#22686;&#21152;&#22806;&#37096;&#24187;&#35273;&#30340;&#21487;&#33021;&#24615;&#12290;&#22312;LLMs&#20869;&#37096;&#24179;&#34913;&#22320;&#25972;&#21512;&#21442;&#25968;&#21270;&#30693;&#35782;&#21644;&#22806;&#37096;&#20449;&#24687;&#23545;&#32531;&#35299;&#24187;&#35273;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;Rowen&#65292;&#19968;&#31181;&#22686;&#24378;LLMs&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#31181;&#36873;&#25321;&#24615;&#26816;&#32034;&#22686;&#24378;&#36807;&#31243;&#65292;&#26088;&#22312;&#35299;&#20915;&#24187;&#35273;&#36755;&#20986;&#12290;&#35813;&#36807;&#31243;&#30001;&#19968;&#20010;&#22810;&#35821;&#20041;&#24863;&#30693;&#26816;&#27979;&#27169;&#22359;&#31649;&#29702;&#65292;&#35813;&#27169;&#22359;&#35780;&#20272;&#20102;&#23545;&#30456;&#21516;&#26597;&#35810;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#30340;&#25200;&#21160;&#21709;&#24212;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10612v1 Announce Type: new  Abstract: Hallucinations pose a significant challenge for the practical implementation of large language models (LLMs). The utilization of parametric knowledge in generating factual content is constrained by the limited knowledge of LLMs, potentially resulting in internal hallucinations. While incorporating external information can help fill knowledge gaps, it also introduces the risk of irrelevant information, thereby increasing the likelihood of external hallucinations. A careful and balanced integration of the parametric knowledge within LLMs with external information is crucial to alleviate hallucinations. In this study, we present Rowen, a novel approach that enhances LLMs with a selective retrieval augmentation process tailored to address hallucinated outputs. This process is governed by a multilingual semantic-aware detection module, which evaluates the consistency of the perturbed responses across various languages for the same queries. Up
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#20102;&#36234;&#29425;&#25552;&#31034;&#65292;&#25104;&#21151;&#22320;&#32469;&#36807;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26377;&#23475;&#38382;&#39064;&#30340;&#26816;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#25915;&#20987;&#25104;&#21151;&#29575;&#39640;&#36798;59.42%&#12290;</title><link>https://arxiv.org/abs/2402.10601</link><description>&lt;p&gt;
&#20351;&#29992;&#21333;&#35789;&#26367;&#25442;&#23494;&#30721;&#26469;&#36234;&#29425;&#19987;&#26377;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Jailbreaking Proprietary Large Language Models using Word Substitution Cipher
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10601
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#20102;&#36234;&#29425;&#25552;&#31034;&#65292;&#25104;&#21151;&#22320;&#32469;&#36807;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#26377;&#23475;&#38382;&#39064;&#30340;&#26816;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#25915;&#20987;&#25104;&#21151;&#29575;&#39640;&#36798;59.42%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36981;&#24490;&#36947;&#24503;&#21644;&#20262;&#29702;&#20934;&#21017;&#65292;&#20294;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#21517;&#20026;Jailbreak&#30340;&#21019;&#24847;&#25552;&#31034;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#25552;&#31034;&#21487;&#20197;&#32469;&#36807;&#23545;&#40784;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36234;&#29425;&#25552;&#31034;&#21253;&#21547;&#33258;&#28982;&#35821;&#35328;&#65288;&#20027;&#35201;&#26159;&#33521;&#35821;&#65289;&#20013;&#30340;&#26377;&#23475;&#38382;&#39064;&#65292;&#21487;&#20197;&#34987;LLMs&#33258;&#36523;&#26816;&#27979;&#21040;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23494;&#30721;&#25216;&#26415;&#32534;&#30721;&#30340;&#36234;&#29425;&#25552;&#31034;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#26368;&#20808;&#36827;&#30340;LLM&#65292;GPT-4&#19978;&#36827;&#34892;&#20102;&#19968;&#20010;&#35797;&#28857;&#30740;&#31350;&#65292;&#35299;&#30721;&#20102;&#20351;&#29992;&#21508;&#31181;&#23494;&#30721;&#25216;&#26415;&#21152;&#23494;&#30340;&#20960;&#20010;&#23433;&#20840;&#21477;&#23376;&#65292;&#21457;&#29616;&#31616;&#21333;&#30340;&#21333;&#35789;&#26367;&#25442;&#23494;&#30721;&#21487;&#20197;&#34987;&#26368;&#26377;&#25928;&#22320;&#35299;&#30721;&#12290;&#21463;&#27492;&#32467;&#26524;&#21551;&#21457;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#32534;&#30721;&#25216;&#26415;&#26469;&#32534;&#20889;&#36234;&#29425;&#25552;&#31034;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23558;&#19981;&#23433;&#20840;&#21333;&#35789;&#26144;&#23556;&#21040;&#23433;&#20840;&#21333;&#35789;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#26144;&#23556;&#30340;&#21333;&#35789;&#25552;&#20986;&#19981;&#23433;&#20840;&#38382;&#39064;&#30340;&#26144;&#23556;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#36234;&#29425;&#25915;&#20987;&#25104;&#21151;&#29575;&#65288;&#39640;&#36798;59.42%&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10601v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are aligned to moral and ethical guidelines but remain susceptible to creative prompts called Jailbreak that can bypass the alignment process. However, most jailbreaking prompts contain harmful questions in the natural language (mainly English), which can be detected by the LLM themselves. In this paper, we present jailbreaking prompts encoded using cryptographic techniques. We first present a pilot study on the state-of-the-art LLM, GPT-4, in decoding several safe sentences that have been encrypted using various cryptographic techniques and find that a straightforward word substitution cipher can be decoded most effectively. Motivated by this result, we use this encoding technique for writing jailbreaking prompts. We present a mapping of unsafe words with safe words and ask the unsafe question using these mapped words. Experimental results show an attack success rate (up to 59.42%) of our proposed jailbrea
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20998;&#26512;&#20102;&#38271;&#31687;&#38382;&#31572;&#20013;&#30340;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#20102;&#29983;&#25104;&#31572;&#26696;&#30340;&#23646;&#24615;&#21644;&#24402;&#22240;&#27169;&#24335;&#65292;&#24182;&#25214;&#20986;&#20102;&#24402;&#22240;&#38169;&#35823;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#30740;&#31350;&#32467;&#26524;&#23545;&#38271;&#31687;&#12289;&#30693;&#35782;&#20016;&#23500;&#30340;&#25991;&#26412;&#29983;&#25104;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.12150</link><description>&lt;p&gt;
&#29702;&#35299;&#29992;&#20110;&#38271;&#31687;&#38382;&#31572;&#30340;&#26816;&#32034;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Understanding Retrieval Augmentation for Long-Form Question Answering. (arXiv:2310.12150v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12150
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20998;&#26512;&#20102;&#38271;&#31687;&#38382;&#31572;&#20013;&#30340;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#20102;&#29983;&#25104;&#31572;&#26696;&#30340;&#23646;&#24615;&#21644;&#24402;&#22240;&#27169;&#24335;&#65292;&#24182;&#25214;&#20986;&#20102;&#24402;&#22240;&#38169;&#35823;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#30740;&#31350;&#32467;&#26524;&#23545;&#38271;&#31687;&#12289;&#30693;&#35782;&#20016;&#23500;&#30340;&#25991;&#26412;&#29983;&#25104;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38271;&#31687;&#38382;&#31572;&#20013;&#25552;&#20986;&#20102;&#19968;&#39033;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30740;&#31350;&#12290;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#20351;&#29992;&#30456;&#21516;&#35777;&#25454;&#25991;&#26723;&#30340;&#27169;&#22411;&#29983;&#25104;&#30340;&#31572;&#26696;&#65292;&#20998;&#26512;&#20102;&#26816;&#32034;&#22686;&#24378;&#23545;&#19981;&#21516;LMs&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#26816;&#32034;&#25991;&#26723;&#38598;&#36136;&#37327;&#23545;&#30456;&#21516;LMs&#29983;&#25104;&#30340;&#31572;&#26696;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29983;&#25104;&#31572;&#26696;&#30340;&#21508;&#31181;&#23646;&#24615;&#65288;&#20363;&#22914;&#65292;&#27969;&#30021;&#24230;&#12289;&#38271;&#24230;&#12289;&#21464;&#24322;&#24615;&#65289;&#65292;&#37325;&#28857;&#22312;&#20110;&#23558;&#29983;&#25104;&#30340;&#38271;&#31687;&#31572;&#26696;&#24402;&#22240;&#20110;&#25991;&#26412;&#20013;&#30340;&#35777;&#25454;&#25991;&#26723;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#31572;&#26696;&#24402;&#22240;&#30340;&#20154;&#24037;&#26631;&#27880;&#24182;&#35780;&#20272;&#20102;&#33258;&#21160;&#35780;&#21028;&#24402;&#22240;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#26816;&#32034;&#22686;&#24378;&#22914;&#20309;&#24433;&#21709;LMs&#29983;&#25104;&#38271;&#31687;&#12289;&#30693;&#35782;&#20016;&#23500;&#30340;&#25991;&#26412;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#38271;&#25991;&#26412;&#29983;&#25104;&#30340;&#24402;&#22240;&#27169;&#24335;&#24182;&#20998;&#26512;&#20102;&#24402;&#22240;&#38169;&#35823;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#32508;&#19978;&#25152;&#36848;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#26816;&#32034;&#22686;&#24378;&#23545;&#38271;&#31687;&#12289;&#30693;&#35782;&#20016;&#23500;&#30340;&#25991;&#26412;&#29983;&#25104;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a study of retrieval-augmented language models (LMs) on long-form question answering. We analyze how retrieval augmentation impacts different LMs, by comparing answers generated from models while using the same evidence documents, and how differing quality of retrieval document set impacts the answers generated from the same LM. We study various attributes of generated answers (e.g., fluency, length, variance) with an emphasis on the attribution of generated long-form answers to in-context evidence documents. We collect human annotations of answer attribution and evaluate methods for automatically judging attribution. Our study provides new insights on how retrieval augmentation impacts long, knowledge-rich text generation of LMs. We further identify attribution patterns for long text generation and analyze the main culprits of attribution errors. Together, our analysis reveals how retrieval augmentation impacts long knowledge-rich text generation and provide directions for 
&lt;/p&gt;</description></item><item><title>AgentBench&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#20316;&#20026;&#20195;&#29702;&#20154;&#30340;&#22810;&#32500;&#24230;&#22522;&#20934;&#65292;&#21457;&#29616;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#65292;&#21830;&#19994;LLMs&#22312;&#20805;&#24403;&#20195;&#29702;&#20154;&#26041;&#38754;&#34920;&#29616;&#24378;&#21170;&#65292;&#20294;&#19982;&#24320;&#28304;&#31454;&#20105;&#23545;&#25163;&#30456;&#27604;&#65292;&#23384;&#22312;&#26174;&#33879;&#24615;&#33021;&#24046;&#36317;&#12290;&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#22312;&#38271;&#26399;&#25512;&#29702;&#12289;&#20915;&#31574;&#21644;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#19978;&#30340;&#29942;&#39048;&#12290;</title><link>http://arxiv.org/abs/2308.03688</link><description>&lt;p&gt;
AgentBench: &#35780;&#20272;LLMs&#20316;&#20026;&#20195;&#29702;&#20154;
&lt;/p&gt;
&lt;p&gt;
AgentBench: Evaluating LLMs as Agents. (arXiv:2308.03688v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03688
&lt;/p&gt;
&lt;p&gt;
AgentBench&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#20316;&#20026;&#20195;&#29702;&#20154;&#30340;&#22810;&#32500;&#24230;&#22522;&#20934;&#65292;&#21457;&#29616;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#65292;&#21830;&#19994;LLMs&#22312;&#20805;&#24403;&#20195;&#29702;&#20154;&#26041;&#38754;&#34920;&#29616;&#24378;&#21170;&#65292;&#20294;&#19982;&#24320;&#28304;&#31454;&#20105;&#23545;&#25163;&#30456;&#27604;&#65292;&#23384;&#22312;&#26174;&#33879;&#24615;&#33021;&#24046;&#36317;&#12290;&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;LLMs&#22312;&#38271;&#26399;&#25512;&#29702;&#12289;&#20915;&#31574;&#21644;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#19978;&#30340;&#29942;&#39048;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#21464;&#24471;&#36234;&#26469;&#36234;&#26234;&#33021;&#21644;&#33258;&#20027;&#65292;&#38024;&#23545;&#20256;&#32479;&#30340;NLP&#20219;&#21153;&#20043;&#22806;&#30340;&#29616;&#23454;&#19990;&#30028;&#23454;&#38469;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#36843;&#20999;&#38656;&#35201;&#22312;&#20114;&#21160;&#29615;&#22659;&#20013;&#35780;&#20272;LLMs&#20316;&#20026;&#20195;&#29702;&#20154;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#19978;&#30340;&#25512;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;AgentBench&#65292;&#19968;&#20010;&#22810;&#32500;&#24230;&#28436;&#21464;&#30340;&#22522;&#20934;&#65292;&#30446;&#21069;&#21253;&#25324;8&#20010;&#19981;&#21516;&#30340;&#29615;&#22659;&#65292;&#20197;&#35780;&#20272;LLM&#20316;&#20026;&#20195;&#29702;&#20154;&#22312;&#22810;&#36718;&#24320;&#25918;&#24335;&#29983;&#25104;&#35774;&#32622;&#20013;&#30340;&#25512;&#29702;&#21644;&#20915;&#31574;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;27&#20010;&#22522;&#20110;API&#21644;&#24320;&#28304;&#30340;LLM&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;&#39030;&#32423;&#21830;&#19994;LLM&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#20195;&#29702;&#20154;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#19982;&#24320;&#28304;&#31454;&#20105;&#23545;&#25163;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#24456;&#22823;&#12290;&#25105;&#20204;&#25214;&#20986;&#20102;&#29615;&#22659;&#21644;LLM&#20013;&#22833;&#36133;&#30340;&#20856;&#22411;&#21407;&#22240;&#65292;&#34920;&#26126;&#38271;&#26399;&#25512;&#29702;&#12289;&#20915;&#31574;&#21644;&#36981;&#24490;&#25351;&#31034;&#33021;&#21147;&#19981;&#20339;&#26159;&#24320;&#21457;&#21487;&#29992;LLM&#20195;&#29702;&#20154;&#30340;&#20027;&#35201;&#38556;&#30861;&#12290;&#36890;&#36807;&#23545;&#20195;&#30721;&#21644;&#39640;&#36136;&#37327;&#36827;&#34892;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 27 API-based and open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and OSS competitors. We identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents. Training on code and high quality 
&lt;/p&gt;</description></item></channel></rss>