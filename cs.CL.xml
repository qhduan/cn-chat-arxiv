<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#24207;&#21015;&#22270;&#30340;&#23454;&#29616;&#21644;&#27495;&#20041;&#38382;&#39064;&#65292;&#36890;&#36807;&#32452;&#21512;&#21644;&#35745;&#31639;&#30340;&#26041;&#27861;&#32771;&#34385;&#20102;&#22270;&#30340;&#31383;&#21475;&#22823;&#23567;&#12289;&#26041;&#21521;&#24615;&#21644;&#26435;&#37325;&#31561;&#22240;&#32032;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#35299;&#20915;&#23454;&#29616;&#21644;&#26522;&#20030;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.08830</link><description>&lt;p&gt;
&#24207;&#21015;&#22270;&#23454;&#29616;&#19982;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#27495;&#20041;
&lt;/p&gt;
&lt;p&gt;
Sequence graphs realizations and ambiguity in language models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08830
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#24207;&#21015;&#22270;&#30340;&#23454;&#29616;&#21644;&#27495;&#20041;&#38382;&#39064;&#65292;&#36890;&#36807;&#32452;&#21512;&#21644;&#35745;&#31639;&#30340;&#26041;&#27861;&#32771;&#34385;&#20102;&#22270;&#30340;&#31383;&#21475;&#22823;&#23567;&#12289;&#26041;&#21521;&#24615;&#21644;&#26435;&#37325;&#31561;&#22240;&#32032;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#35299;&#20915;&#23454;&#29616;&#21644;&#26522;&#20030;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#31181;&#27969;&#34892;&#30340;&#35821;&#35328;&#27169;&#22411;&#23558;&#36755;&#20837;&#25991;&#26412;&#20013;&#30340;&#23616;&#37096;&#19978;&#19979;&#25991;&#34920;&#31034;&#20026;&#35789;&#34955;&#12290;&#36825;&#26679;&#30340;&#34920;&#31034;&#33258;&#28982;&#22320;&#36890;&#36807;&#19968;&#20010;&#24207;&#21015;&#22270;&#26469;&#32534;&#30721;&#65292;&#20854;&#20013;&#39030;&#28857;&#26159;&#20986;&#29616;&#22312;&#36755;&#20837;&#25991;&#26412;&#20013;&#30340;&#19981;&#21516;&#35789;&#65292;&#36793;&#34920;&#31034;&#22312;&#22823;&#23567;&#20026;w&#30340;&#28369;&#21160;&#31383;&#21475;&#20869;&#20004;&#20010;&#35789;&#30340;&#65288;&#26377;&#24207;&#65289;&#20849;&#29616;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#21387;&#32553;&#34920;&#31034;&#36890;&#24120;&#19981;&#26159;&#21452;&#23556;&#30340;&#65292;&#21487;&#33021;&#24341;&#20837;&#19968;&#23450;&#31243;&#24230;&#30340;&#27495;&#20041;&#12290;&#19968;&#20123;&#24207;&#21015;&#22270;&#21487;&#33021;&#20197;&#22810;&#31181;&#26041;&#24335;&#23454;&#29616;&#20026;&#19968;&#20010;&#24207;&#21015;&#65292;&#32780;&#20854;&#20182;&#19968;&#20123;&#21487;&#33021;&#26080;&#27861;&#23454;&#29616;&#20219;&#20309;&#24207;&#21015;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#32452;&#21512;&#21644;&#35745;&#31639;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#24207;&#21015;&#22270;&#30340;&#21487;&#23454;&#29616;&#24615;&#21644;&#27495;&#20041;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#30340;&#24207;&#21015;&#22270;&#23454;&#29616;&#30340;&#23384;&#22312;&#21644;&#26522;&#20030;&#65306;&#31383;&#21475;&#22823;&#23567;w&#12289;&#22270;&#30340;&#26041;&#21521;&#24615;&#30340;&#23384;&#22312;/&#32570;&#22833;&#21644;&#26435;&#37325;&#65288;&#37325;&#22797;&#24615;&#65289;&#30340;&#23384;&#22312;/&#32570;&#22833;&#12290;&#24403;w = 2&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#23454;&#29616;&#21644;&#26522;&#20030;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08830v1 Announce Type: cross Abstract: Several popular language models represent local contexts in an input text as bags of words. Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in x, with edges representing the (ordered) co-occurrence of two words within a sliding window of size w. However, this compressed representation is not generally bijective, and may introduce some degree of ambiguity. Some sequence graphs may admit several realizations as a sequence, while others may not admit any realization. In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and computational point of view. We consider the existence and enumeration of realizations of a sequence graph under multiple settings: window size w, presence/absence of graph orientation, and presence/absence of weights (multiplicities). When w = 2, we provide polynomial time algorithms for realizability and enumeratio
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24369;&#21040;&#24378;&#30772;&#35299;&#25915;&#20987;&#65292;&#23545;&#25163;&#21487;&#20197;&#21033;&#29992;&#36739;&#23567;&#30340;&#19981;&#23433;&#20840;/&#23545;&#40784;LLMs&#25351;&#23548;&#23545;&#26174;&#33879;&#36739;&#22823;&#30340;&#23545;&#40784;LLMs&#36827;&#34892;&#30772;&#35299;&#65292;&#19982;&#35299;&#30721;&#36739;&#22823;&#30340;LLMs&#30456;&#27604;&#65292;&#20854;&#35745;&#31639;&#21644;&#24310;&#36831;&#25104;&#26412;&#36739;&#23567;&#12290;</title><link>https://arxiv.org/abs/2401.17256</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#24369;&#21040;&#24378;&#30772;&#35299;
&lt;/p&gt;
&lt;p&gt;
Weak-to-Strong Jailbreaking on Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17256
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24369;&#21040;&#24378;&#30772;&#35299;&#25915;&#20987;&#65292;&#23545;&#25163;&#21487;&#20197;&#21033;&#29992;&#36739;&#23567;&#30340;&#19981;&#23433;&#20840;/&#23545;&#40784;LLMs&#25351;&#23548;&#23545;&#26174;&#33879;&#36739;&#22823;&#30340;&#23545;&#40784;LLMs&#36827;&#34892;&#30772;&#35299;&#65292;&#19982;&#35299;&#30721;&#36739;&#22823;&#30340;LLMs&#30456;&#27604;&#65292;&#20854;&#35745;&#31639;&#21644;&#24310;&#36831;&#25104;&#26412;&#36739;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24050;&#32463;&#20184;&#20986;&#20102;&#22823;&#37327;&#21162;&#21147;&#26469;&#23545;&#40784;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#20294;&#32418;&#38431;&#27979;&#35797;&#25253;&#21578;&#34920;&#26126;&#65292;&#36825;&#20123;&#32463;&#36807;&#31934;&#24515;&#23545;&#40784;&#30340;LLMs&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#23545;&#25239;&#24615;&#25552;&#31034;&#12289;&#35843;&#20248;&#25110;&#35299;&#30721;&#36827;&#34892;&#30772;&#35299;&#12290;&#22312;&#35843;&#26597;&#23545;&#40784;LLMs&#30340;&#30772;&#35299;&#28431;&#27934;&#26102;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#30772;&#35299;&#21644;&#23545;&#40784;&#27169;&#22411;&#30340;&#35299;&#30721;&#20998;&#24067;&#20165;&#22312;&#21021;&#22987;&#29983;&#25104;&#20013;&#23384;&#22312;&#24046;&#24322;&#12290;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#28608;&#21457;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#24369;&#21040;&#24378;&#30772;&#35299;&#25915;&#20987;&#65292;&#25932;&#23545;&#26041;&#21487;&#20197;&#21033;&#29992;&#36739;&#23567;&#30340;&#19981;&#23433;&#20840;/&#23545;&#40784;LLMs&#65288;&#20363;&#22914;7B&#65289;&#25351;&#23548;&#23545;&#26174;&#33879;&#36739;&#22823;&#30340;&#23545;&#40784;LLMs&#65288;&#20363;&#22914;70B&#65289;&#36827;&#34892;&#30772;&#35299;&#12290;&#35201;&#36827;&#34892;&#30772;&#35299;&#65292;&#21482;&#38656;&#39069;&#22806;&#35299;&#30721;&#20004;&#20010;&#36739;&#23567;&#30340;LLMs&#19968;&#27425;&#65292;&#19982;&#35299;&#30721;&#36739;&#22823;&#30340;LLMs&#30456;&#27604;&#65292;&#20854;&#35745;&#31639;&#21644;&#24310;&#36831;&#25104;&#26412;&#36739;&#23567;&#12290;&#36890;&#36807;&#22312;&#19977;&#20010;&#19981;&#21516;&#32452;&#32455;&#30340;&#20116;&#20010;&#27169;&#22411;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#19968;&#31181;&#20197;&#21069;&#26410;&#27880;&#24847;&#21040;&#20294;&#39640;&#25928;&#30340;&#30772;&#35299;&#26041;&#24335;&#65292;
&lt;/p&gt;
&lt;p&gt;
Although significant efforts have been dedicated to aligning large language models (LLMs), red-teaming reports suggest that these carefully aligned LLMs could still be jailbroken through adversarial prompts, tuning, or decoding. Upon examining the jailbreaking vulnerability of aligned LLMs, we observe that the decoding distributions of jailbroken and aligned models differ only in the initial generations. This observation motivates us to propose the weak-to-strong jailbreaking attack, where adversaries can utilize smaller unsafe/aligned LLMs (e.g., 7B) to guide jailbreaking against significantly larger aligned LLMs (e.g., 70B). To jailbreak, one only needs to additionally decode two smaller LLMs once, which involves minimal computation and latency compared to decoding the larger LLMs. The efficacy of this attack is demonstrated through experiments conducted on five models from three different organizations. Our study reveals a previously unnoticed yet efficient way of jailbreaking, expo
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#30740;&#31350;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#24212;&#29992;&#21644;&#32467;&#26524;&#36827;&#34892;&#20102;&#32508;&#21512;&#20998;&#26512;&#65292;&#21457;&#29616;&#20854;&#22312;&#35786;&#26029;&#12289;&#27835;&#30103;&#21644;&#24739;&#32773;&#21442;&#19982;&#22686;&#24378;&#31561;&#26041;&#38754;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#36824;&#35782;&#21035;&#21644;&#35752;&#35770;&#20102;&#22312;&#36825;&#20123;&#19987;&#19994;&#39046;&#22495;&#20013;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.02984</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#39033;&#32508;&#36848;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large Language Models in Mental Health Care: a Scoping Review. (arXiv:2401.02984v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#30740;&#31350;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#24212;&#29992;&#21644;&#32467;&#26524;&#36827;&#34892;&#20102;&#32508;&#21512;&#20998;&#26512;&#65292;&#21457;&#29616;&#20854;&#22312;&#35786;&#26029;&#12289;&#27835;&#30103;&#21644;&#24739;&#32773;&#21442;&#19982;&#22686;&#24378;&#31561;&#26041;&#38754;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#36824;&#35782;&#21035;&#21644;&#35752;&#35770;&#20102;&#22312;&#36825;&#20123;&#19987;&#19994;&#39046;&#22495;&#20013;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20351;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#65292;&#38656;&#35201;&#23545;&#23427;&#20204;&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#39046;&#22495;&#30340;&#24212;&#29992;&#21644;&#32467;&#26524;&#36827;&#34892;&#20840;&#38754;&#30340;&#32508;&#36848;&#12290;&#26412;&#32508;&#36848;&#30740;&#31350;&#26088;&#22312;&#23545;LLMs&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#29616;&#26377;&#21457;&#23637;&#21644;&#24212;&#29992;&#36827;&#34892;&#25209;&#21028;&#24615;&#20998;&#26512;&#65292;&#31361;&#20986;&#23427;&#20204;&#30340;&#25104;&#21151;&#65292;&#24182;&#35782;&#21035;&#36825;&#20123;&#19987;&#19994;&#39046;&#22495;&#20013;&#30340;&#25361;&#25112;&#21644;&#38480;&#21046;&#12290;&#26448;&#26009;&#21644;&#26041;&#27861;&#65306;2023&#24180;11&#26376;&#65292;&#22312;PubMed&#12289;Web of Science&#12289;Google Scholar&#12289;arXiv&#12289;medRxiv&#21644;PsyArXiv&#20845;&#20010;&#25968;&#25454;&#24211;&#20013;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25991;&#29486;&#25628;&#32034;&#65292;&#36981;&#24490;2020&#24180;&#29256;&#30340;&#8220;&#31995;&#32479;&#35780;&#20215;&#21644;Meta&#20998;&#26512;&#30340;&#39318;&#36873;&#25253;&#21578;&#39033;&#30446;&#8221;&#65288;PRISMA&#65289;&#25351;&#21335;&#12290;&#26368;&#21021;&#35782;&#21035;&#20102;313&#31687;&#20986;&#29256;&#29289;&#65292;&#25353;&#29031;&#30740;&#31350;&#32435;&#20837;&#26631;&#20934;&#65292;&#26368;&#32456;&#36873;&#25321;&#20102;34&#31687;&#20986;&#29256;&#29289;&#36827;&#34892;&#32508;&#36848;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#21457;&#29616;&#20102;LLMs&#22312;&#24515;&#29702;&#20581;&#24247;&#25252;&#29702;&#20013;&#30340;&#22810;&#31181;&#24212;&#29992;&#65292;&#21253;&#25324;&#35786;&#26029;&#12289;&#27835;&#30103;&#12289;&#24739;&#32773;&#21442;&#19982;&#22686;&#24378;&#31561;&#12290;&#20851;&#38190;&#25361;&#25112;&#21644;&#38480;&#21046;&#26041;&#38754;&#30340;&#21457;&#29616;&#23558;&#34987;&#24635;&#32467;&#21644;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Objective: The growing use of large language models (LLMs) stimulates a need for a comprehensive review of their applications and outcomes in mental health care contexts. This scoping review aims to critically analyze the existing development and applications of LLMs in mental health care, highlighting their successes and identifying their challenges and limitations in these specialized fields. Materials and Methods: A broad literature search was conducted in November 2023 using six databases (PubMed, Web of Science, Google Scholar, arXiv, medRxiv, and PsyArXiv) following the 2020 version of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A total of 313 publications were initially identified, and after applying the study inclusion criteria, 34 publications were selected for the final review. Results: We identified diverse applications of LLMs in mental health care, including diagnosis, therapy, patient engagement enhancement, etc. Key challen
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#21160;&#29983;&#25104;&#27010;&#24565;&#35868;&#39064;&#30340;&#26041;&#27861;&#65292;&#20197;&#20419;&#36827;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#23398;&#20064;&#32773;&#21442;&#19982;&#24230;&#12290;&#36890;&#36807;&#24212;&#29992;&#27010;&#24565;&#36798;&#25104;&#27169;&#22411;&#21644;&#29983;&#25104;&#35868;&#39064;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24110;&#21161;&#23398;&#20064;&#32773;&#26356;&#22909;&#22320;&#29702;&#35299;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2310.18290</link><description>&lt;p&gt;
&#19968;&#31181;&#33258;&#21160;&#29983;&#25104;&#35868;&#39064;&#20197;&#36741;&#21161;&#27010;&#24565;&#29702;&#35299;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Approach to Automatically generating Riddles aiding Concept Attainment. (arXiv:2310.18290v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18290
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#21160;&#29983;&#25104;&#27010;&#24565;&#35868;&#39064;&#30340;&#26041;&#27861;&#65292;&#20197;&#20419;&#36827;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#23398;&#20064;&#32773;&#21442;&#19982;&#24230;&#12290;&#36890;&#36807;&#24212;&#29992;&#27010;&#24565;&#36798;&#25104;&#27169;&#22411;&#21644;&#29983;&#25104;&#35868;&#39064;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24110;&#21161;&#23398;&#20064;&#32773;&#26356;&#22909;&#22320;&#29702;&#35299;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#20013;&#65292;&#20445;&#25345;&#23398;&#20064;&#32773;&#30340;&#31215;&#26497;&#21442;&#19982;&#26159;&#19968;&#20010;&#20027;&#35201;&#30340;&#25361;&#25112;&#12290;&#20026;&#22686;&#24378;&#23398;&#20064;&#32773;&#30340;&#21442;&#19982;&#24230;&#65292;&#25552;&#20986;&#20102;&#21508;&#31181;&#19981;&#21516;&#30340;&#25945;&#23398;&#31574;&#30053;&#65292;&#26080;&#35770;&#26159;&#22312;&#32447;&#36824;&#26159;&#31163;&#32447;&#29615;&#22659;&#20013;&#12290;&#27010;&#24565;&#36798;&#25104;&#27169;&#22411;&#23601;&#26159;&#19968;&#31181;&#25945;&#23398;&#31574;&#30053;&#65292;&#23427;&#30528;&#37325;&#20110;&#23398;&#20064;&#32773;&#23545;&#27010;&#24565;&#30340;&#28145;&#20837;&#29702;&#35299;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#23545;&#27010;&#24565;&#30340;&#23383;&#20856;&#23450;&#20041;&#12290;&#36890;&#36807;&#25628;&#32034;&#21644;&#21015;&#20030;&#29992;&#20110;&#21306;&#20998;&#21508;&#31181;&#27010;&#24565;&#30340;&#23454;&#20363;&#21644;&#38750;&#23454;&#20363;&#20043;&#38388;&#30340;&#23646;&#24615;&#65292;&#26469;&#36798;&#21040;&#36825;&#19968;&#30446;&#30340;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#35797;&#22270;&#23558;&#27010;&#24565;&#36798;&#25104;&#27169;&#22411;&#24212;&#29992;&#20110;&#26500;&#24314;&#27010;&#24565;&#35868;&#39064;&#65292;&#20197;&#22312;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#20013;&#20351;&#29992;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#20174;&#23398;&#20064;&#36164;&#28304;&#20013;&#21019;&#24314;&#20107;&#23454;&#19977;&#20803;&#32452;&#65292;&#26681;&#25454;&#20854;&#23545;&#27010;&#24565;&#30340;&#21807;&#19968;&#24615;&#36827;&#34892;&#20998;&#31867;&#20026;&#8220;&#20027;&#39064;&#26631;&#35760;&#8221;&#21644;&#8220;&#20849;&#21516;&#8221;&#65292;&#28982;&#21518;&#26681;&#25454;&#27010;&#24565;&#36798;&#25104;&#27169;&#22411;&#30340;&#26684;&#24335;&#29983;&#25104;&#35868;&#39064;&#65292;&#24182;&#25429;&#33719;&#36825;&#20123;&#35868;&#39064;&#30340;&#25152;&#26377;&#21487;&#33021;&#35299;&#12290;&#20174;&#20154;&#31867;&#35780;&#20272;&#20013;&#33719;&#24471;&#30340;&#32467;&#26524;&#26174;&#31034;...
&lt;/p&gt;
&lt;p&gt;
One of the primary challenges in online learning environments, is to retain learner engagement. Several different instructional strategies are proposed both in online and offline environments to enhance learner engagement. The Concept Attainment Model is one such instructional strategy that focuses on learners acquiring a deeper understanding of a concept rather than just its dictionary definition. This is done by searching and listing the properties used to distinguish examples from non-examples of various concepts. Our work attempts to apply the Concept Attainment Model to build conceptual riddles, to deploy over online learning environments. The approach involves creating factual triples from learning resources, classifying them based on their uniqueness to a concept into `Topic Markers' and `Common', followed by generating riddles based on the Concept Attainment Model's format and capturing all possible solutions to those riddles. The results obtained from the human evaluation of r
&lt;/p&gt;</description></item></channel></rss>