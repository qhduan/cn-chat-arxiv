<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>SongComposer&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27468;&#26354;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#37319;&#29992;&#31526;&#21495;&#21270;&#30340;&#27468;&#26354;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;LLM&#21487;&#20197;&#26126;&#30830;&#21019;&#20316;&#27468;&#26354;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.17645</link><description>&lt;p&gt;
SongComposer&#65306;&#19968;&#31181;&#29992;&#20110;&#27468;&#26354;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#29992;&#20110;&#27468;&#35789;&#21644;&#26059;&#24459;&#21019;&#20316;
&lt;/p&gt;
&lt;p&gt;
SongComposer: A Large Language Model for Lyric and Melody Composition in Song Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17645
&lt;/p&gt;
&lt;p&gt;
SongComposer&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27468;&#26354;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#37319;&#29992;&#31526;&#21495;&#21270;&#30340;&#27468;&#26354;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;LLM&#21487;&#20197;&#26126;&#30830;&#21019;&#20316;&#27468;&#26354;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;SongComposer&#65292;&#19968;&#20010;&#20026;&#27468;&#26354;&#21019;&#20316;&#32780;&#35774;&#35745;&#30340;&#21019;&#26032;&#22411;LLM&#12290;&#23427;&#33021;&#22815;&#29702;&#35299;&#21644;&#29983;&#25104;&#27468;&#26354;&#20013;&#30340;&#26059;&#24459;&#21644;&#27468;&#35789;&#65292;&#36890;&#36807;&#21033;&#29992;LLM&#30340;&#33021;&#21147;&#22312;&#31526;&#21495;&#21270;&#30340;&#27468;&#26354;&#34920;&#31034;&#20013;&#29983;&#25104;&#12290;&#29616;&#26377;&#30340;&#19982;&#38899;&#20048;&#30456;&#20851;&#30340;LLM&#23558;&#38899;&#20048;&#35270;&#20026;&#37327;&#21270;&#30340;&#38899;&#39057;&#20449;&#21495;&#65292;&#32780;&#36825;&#31181;&#38544;&#24335;&#32534;&#30721;&#23548;&#33268;&#20102;&#32534;&#30721;&#25928;&#29575;&#20302;&#19979;&#21644;&#28789;&#27963;&#24615;&#24046;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#31526;&#21495;&#21270;&#30340;&#27468;&#26354;&#34920;&#31034;&#65292;&#36825;&#26159;&#20154;&#31867;&#20026;&#38899;&#20048;&#35774;&#35745;&#30340;&#25104;&#29087;&#21644;&#39640;&#25928;&#30340;&#26041;&#24335;&#65292;&#24182;&#20351;LLM&#33021;&#22815;&#20687;&#20154;&#31867;&#19968;&#26679;&#26126;&#30830;&#22320;&#21019;&#20316;&#27468;&#26354;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20803;&#32452;&#35774;&#35745;&#65292;&#29992;&#20110;&#26684;&#24335;&#21270;&#27468;&#35789;&#21644;&#26059;&#24459;&#20013;&#30340;&#19977;&#20010;&#38899;&#31526;&#23646;&#24615;&#65288;&#38899;&#39640;&#12289;&#25345;&#32493;&#26102;&#38388;&#21644;&#20241;&#27490;&#26102;&#38388;&#65289;&#65292;&#20174;&#32780;&#20445;&#35777;LLM&#23545;&#38899;&#20048;&#31526;&#21495;&#30340;&#27491;&#30830;&#29702;&#35299;&#65292;&#24182;&#23454;&#29616;&#27468;&#35789;&#21644;&#26059;&#24459;&#20043;&#38388;&#30340;&#31934;&#30830;&#23545;&#40784;&#12290;&#20026;&#20102;&#21521;LLM&#28748;&#36755;&#22522;&#26412;&#30340;&#38899;&#20048;&#29702;&#35299;&#65292;&#25105;&#20204;&#31934;&#24515;&#25910;&#38598;&#20102;SongCompose-PT&#65292;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#27468;&#26354;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#27468;&#35789;&#12289;&#26059;&#24459;&#21644;&#25104;&#23545;&#30340;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17645v1 Announce Type: cross  Abstract: We present SongComposer, an innovative LLM designed for song composition. It could understand and generate melodies and lyrics in symbolic song representations, by leveraging the capability of LLM. Existing music-related LLM treated the music as quantized audio signals, while such implicit encoding leads to inefficient encoding and poor flexibility. In contrast, we resort to symbolic song representation, the mature and efficient way humans designed for music, and enable LLM to explicitly compose songs like humans. In practice, we design a novel tuple design to format lyric and three note attributes (pitch, duration, and rest duration) in the melody, which guarantees the correct LLM understanding of musical symbols and realizes precise alignment between lyrics and melody. To impart basic music understanding to LLM, we carefully collected SongCompose-PT, a large-scale song pretraining dataset that includes lyrics, melodies, and paired ly
&lt;/p&gt;</description></item><item><title>&#22810;&#35821;&#35328;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#23384;&#22312;&#24615;&#21035;&#20559;&#35265;&#65307;&#36890;&#36807;MAGBIG&#35780;&#20272;&#27169;&#22411;&#26102;&#65292;&#21457;&#29616;&#27169;&#22411;&#23545;&#19981;&#21516;&#35821;&#35328;&#20855;&#26377;&#37325;&#35201;&#24046;&#24322;&#65307;&#25105;&#20204;&#21628;&#21505;&#30740;&#31350;&#22810;&#35821;&#35328;&#27169;&#22411;&#39046;&#22495;&#28040;&#38500;&#24615;&#21035;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2401.16092</link><description>&lt;p&gt;
&#22810;&#35821;&#35328;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#25918;&#22823;&#20102;&#24615;&#21035;&#21051;&#26495;&#21360;&#35937;&#65292;&#24182;&#19988;&#20462;&#27491;&#24037;&#31243;&#21487;&#33021;&#26080;&#27861;&#24110;&#21161;&#24744;
&lt;/p&gt;
&lt;p&gt;
Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and Prompt Engineering May Not Help You
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.16092
&lt;/p&gt;
&lt;p&gt;
&#22810;&#35821;&#35328;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#23384;&#22312;&#24615;&#21035;&#20559;&#35265;&#65307;&#36890;&#36807;MAGBIG&#35780;&#20272;&#27169;&#22411;&#26102;&#65292;&#21457;&#29616;&#27169;&#22411;&#23545;&#19981;&#21516;&#35821;&#35328;&#20855;&#26377;&#37325;&#35201;&#24046;&#24322;&#65307;&#25105;&#20204;&#21628;&#21505;&#30740;&#31350;&#22810;&#35821;&#35328;&#27169;&#22411;&#39046;&#22495;&#28040;&#38500;&#24615;&#21035;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#22312;&#22270;&#20687;&#36136;&#37327;&#12289;&#28789;&#27963;&#24615;&#21644;&#25991;&#26412;&#23545;&#40784;&#26041;&#38754;&#21462;&#24471;&#20102;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#65292;&#24182;&#22240;&#27492;&#22312;&#36234;&#26469;&#36234;&#22810;&#30340;&#24212;&#29992;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;&#36890;&#36807;&#25913;&#21892;&#22810;&#35821;&#35328;&#33021;&#21147;&#65292;&#26356;&#22810;&#30340;&#31038;&#32676;&#29616;&#22312;&#21487;&#20197;&#35775;&#38382;&#36825;&#31181;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#25105;&#20204;&#23558;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#22810;&#35821;&#35328;&#27169;&#22411;&#19982;&#21333;&#35821;&#27169;&#22411;&#19968;&#26679;&#21463;&#21040;(&#24615;&#21035;)&#20559;&#35265;&#30340;&#22256;&#25200;&#12290;&#27492;&#22806;&#65292;&#20154;&#20204;&#33258;&#28982;&#26399;&#26395;&#36825;&#20123;&#27169;&#22411;&#22312;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#25552;&#20379;&#31867;&#20284;&#30340;&#32467;&#26524;&#65292;&#20294;&#20107;&#23454;&#24182;&#38750;&#22914;&#27492;&#65292;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#23384;&#22312;&#37325;&#35201;&#30340;&#24046;&#24322;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26088;&#22312;&#20419;&#36827;&#27809;&#26377;&#24615;&#21035;&#20559;&#35265;&#30340;&#22810;&#35821;&#35328;&#27169;&#22411;&#30740;&#31350;&#30340;&#26032;&#22522;&#20934;MAGBIG&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#35821;&#35328;T2I&#27169;&#22411;&#26159;&#21542;&#36890;&#36807;MAGBIG&#25918;&#22823;&#20102;&#24615;&#21035;&#20559;&#35265;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#22810;&#35821;&#35328;&#25552;&#31034;&#35831;&#27714;&#29305;&#23450;&#32844;&#19994;&#25110;&#29305;&#36136;&#30340;&#20154;&#20687;&#22270;&#20687;(&#20351;&#29992;&#24418;&#23481;&#35789;)&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#20165;&#34920;&#26126;&#27169;&#22411;&#20559;&#31163;&#20102;&#35268;&#33539;&#30340;&#20551;&#35774;&#65292;...
&lt;/p&gt;
&lt;p&gt;
Text-to-image generation models have recently achieved astonishing results in image quality, flexibility, and text alignment and are consequently employed in a fast-growing number of applications. Through improvements in multilingual abilities, a larger community now has access to this kind of technology. Yet, as we will show, multilingual models suffer similarly from (gender) biases as monolingual models. Furthermore, the natural expectation is that these models will provide similar results across languages, but this is not the case and there are important differences between languages. Thus, we propose a novel benchmark MAGBIG intending to foster research in multilingual models without gender bias. We investigate whether multilingual T2I models magnify gender bias with MAGBIG. To this end, we use multilingual prompts requesting portrait images of persons of a certain occupation or trait (using adjectives). Our results show not only that models deviate from the normative assumption th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#955;&#28436;&#31639;&#27861;&#65292;&#20351;&#29992;&#955;&#35821;&#35328;&#32534;&#31243;&#65292;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#25191;&#34892;&#25972;&#20010;&#31243;&#24207;&#30340;&#33021;&#21147;&#65292;&#26088;&#22312;&#25299;&#23637;&#31070;&#32463;&#32593;&#32476;&#22312;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.09276</link><description>&lt;p&gt;
&#19968;&#31181;&#31070;&#32463;&#955;&#28436;&#31639;&#27861;&#65306;&#31070;&#32463;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#36935;&#35265;&#35745;&#31639;&#21644;&#20989;&#25968;&#24335;&#32534;&#31243;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming. (arXiv:2304.09276v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#955;&#28436;&#31639;&#27861;&#65292;&#20351;&#29992;&#955;&#35821;&#35328;&#32534;&#31243;&#65292;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#25191;&#34892;&#25972;&#20010;&#31243;&#24207;&#30340;&#33021;&#21147;&#65292;&#26088;&#22312;&#25299;&#23637;&#31070;&#32463;&#32593;&#32476;&#22312;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#65292;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#25104;&#20026;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20027;&#23548;&#33539;&#24335;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#35748;&#20026;&#22312;&#31526;&#21495;&#23398;&#20064;&#20013;&#20351;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#26159;&#36234;&#26469;&#36234;&#30456;&#20851;&#30340;&#12290;&#20026;&#20102;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#22312;&#31526;&#21495;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#33021;&#21147;&#65292;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#25506;&#32034;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#25968;&#23398;&#26500;&#36896;&#65288;&#22914;&#21152;&#27861;&#21644;&#20056;&#27861;&#65289;&#12289;&#36923;&#36753;&#25512;&#29702;&#65288;&#22914;&#23450;&#29702;&#35777;&#26126;&#22120;&#65289;&#29978;&#33267;&#25191;&#34892;&#35745;&#31639;&#26426;&#31243;&#24207;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#21518;&#32773;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#26469;&#35828;&#26159;&#22826;&#22797;&#26434;&#30340;&#20219;&#21153;&#65292;&#32467;&#26524;&#24182;&#19981;&#24635;&#26159;&#25104;&#21151;&#30340;&#65292;&#24182;&#19988;&#24448;&#24448;&#38656;&#35201;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#24341;&#20837;&#26377;&#20559;&#35265;&#30340;&#20803;&#32032;&#65292;&#20197;&#38480;&#21046;&#21487;&#33021;&#35201;&#25191;&#34892;&#30340;&#31243;&#24207;&#30340;&#33539;&#22260;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#22914;&#20309;&#25191;&#34892;&#25972;&#20010;&#31243;&#24207;&#30340;&#33021;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#19981;&#20351;&#29992;&#21629;&#20196;&#24335;&#32534;&#31243;&#35821;&#35328;&#65292;&#32780;&#26159;&#37319;&#29992;&#955;&#35821;&#35328;&#36827;&#34892;&#32534;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the last decades, deep neural networks based-models became the dominant paradigm in machine learning. Further, the use of artificial neural networks in symbolic learning has been seen as increasingly relevant recently. To study the capabilities of neural networks in the symbolic AI domain, researchers have explored the ability of deep neural networks to learn mathematical constructions, such as addition and multiplication, logic inference, such as theorem provers, and even the execution of computer programs. The latter is known to be too complex a task for neural networks. Therefore, the results were not always successful, and often required the introduction of biased elements in the learning process, in addition to restricting the scope of possible programs to be executed. In this work, we will analyze the ability of neural networks to learn how to execute programs as a whole. To do so, we propose a different approach. Instead of using an imperative programming language, with com
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17475</link><description>&lt;p&gt;
&#36229;&#36234;&#36127;&#37319;&#26679;&#30340;&#39640;&#25928;&#20998;&#24067;&#24335;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#20063;&#31216;&#20026;&#23884;&#20837;&#65289;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#20010;&#31867;&#20284;&#20110;Word2Vec&#31639;&#27861;&#20013;&#24341;&#20837;&#24182;&#22312;&#22810;&#20010;&#24037;&#20316;&#20013;&#37319;&#29992;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#23454;&#29616;&#12290;&#20248;&#21270;&#35745;&#31639;&#30340;&#29942;&#39048;&#26159;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#35745;&#31639;&#65292;&#36825;&#38656;&#35201;&#19982;&#26679;&#26412;&#22823;&#23567;&#21576;&#20108;&#27425;&#27604;&#20363;&#30340;&#25805;&#20316;&#25968;&#12290;&#36825;&#31181;&#22797;&#26434;&#24230;&#19981;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#25152;&#20197;&#36127;&#37319;&#26679;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19982;&#26679;&#26412;&#22823;&#23567;&#32447;&#24615;&#30456;&#20851;&#30340;&#26102;&#38388;&#20869;&#33719;&#24471;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36127;&#37319;&#26679;&#20250;&#25913;&#21464;&#25439;&#22833;&#20989;&#25968;&#65292;&#22240;&#27492;&#35299;&#20915;&#30340;&#26159;&#19982;&#26368;&#21021;&#25552;&#20986;&#30340;&#19981;&#21516;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#22312;&#20110;&#23637;&#31034;&#22914;&#20309;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#20174;&#32780;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23884;&#20837;&#36136;&#37327;&#21644;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#20248;&#20110;&#36127;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our ap
&lt;/p&gt;</description></item></channel></rss>