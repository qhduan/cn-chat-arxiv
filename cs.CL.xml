<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GRAFFORD&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#27979;&#35797;&#35821;&#35328;&#21644;&#35270;&#35273;&#27169;&#22411;&#23545;&#29289;&#20307;&#21487;&#20379;&#24615;&#30693;&#35782;&#30340;&#34920;&#29616;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#24403;&#21069;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#19981;&#24120;&#35265;&#29289;&#20307;&#21487;&#20379;&#24615;&#26041;&#38754;&#23384;&#22312;&#25512;&#29702;&#33021;&#21147;&#30340;&#23616;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.12881</link><description>&lt;p&gt;
GRAFFORD: &#29992;&#20110;&#27979;&#35797;&#35821;&#35328;&#21644;&#35270;&#35273;&#27169;&#22411;&#23545;&#29289;&#20307;&#21487;&#20379;&#24615;&#30693;&#35782;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
GRAFFORD: A Benchmark Dataset for Testing the Knowledge of Object Affordances of Language and Vision Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12881
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;GRAFFORD&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#27979;&#35797;&#35821;&#35328;&#21644;&#35270;&#35273;&#27169;&#22411;&#23545;&#29289;&#20307;&#21487;&#20379;&#24615;&#30693;&#35782;&#30340;&#34920;&#29616;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#24403;&#21069;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#19981;&#24120;&#35265;&#29289;&#20307;&#21487;&#20379;&#24615;&#26041;&#38754;&#23384;&#22312;&#25512;&#29702;&#33021;&#21147;&#30340;&#23616;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35843;&#26597;&#20102;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#21644;&#39044;&#35757;&#32451;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#20013;&#20851;&#20110;&#29289;&#20307;&#21487;&#20379;&#24615;&#30340;&#30693;&#35782;&#12290;&#22522;&#20110;Transformer&#30340;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PTLM&#65289;&#20174;&#22823;&#37327;&#26410;&#26631;&#35760;&#25991;&#26412;&#20013;&#23398;&#20064;&#19978;&#19979;&#25991;&#34920;&#31034;&#65292;&#24182;&#22312;&#19979;&#28216;NLU&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#25991;&#29486;&#34920;&#26126;&#65292;PTLM&#22312;&#25512;&#29702;&#21644;&#22522;&#30784;&#26041;&#38754;&#23384;&#22312;&#19981;&#19968;&#33268;&#19988;&#19981;&#30452;&#35266;&#30340;&#22833;&#36133;&#12290;&#20026;&#20102;&#39318;&#27425;&#23450;&#37327;&#34913;&#37327;&#22522;&#30784;&#65288;&#25110;&#32570;&#20047;&#65289;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#31934;&#24515;&#31574;&#21010;&#20102;&#19968;&#20010;&#20851;&#20110;&#29289;&#20307;&#21487;&#20379;&#24615;&#30340;&#26032;&#39062;&#32780;&#20840;&#38754;&#30340;&#25968;&#25454;&#38598;-- GrAFFORD&#65292;&#21253;&#21547;15&#20010;&#21487;&#20379;&#24615;&#31867;&#21035;&#12290;&#19982;&#35270;&#35273;&#21644;&#35821;&#35328;&#39046;&#22495;&#25910;&#38598;&#30340;&#21487;&#20379;&#24615;&#25968;&#25454;&#38598;&#19981;&#21516;&#65292;&#25105;&#20204;&#29992;&#29616;&#22330;&#21477;&#23376;&#26631;&#27880;&#20102;&#23545;&#35937;&#21644;&#21487;&#20379;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#24403;&#28041;&#21450;&#19981;&#24120;&#35265;&#30340;&#29289;&#20307;&#21487;&#20379;&#24615;&#26102;&#65292;PTLM&#34920;&#29616;&#20986;&#26377;&#38480;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;PTLM&#22312;&#29702;&#35299;&#19981;&#24120;&#35265;&#29289;&#20307;&#21487;&#20379;&#24615;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12881v1 Announce Type: new  Abstract: We investigate the knowledge of object affordances in pre-trained language models (LMs) and pre-trained Vision-Language models (VLMs). Transformers-based large pre-trained language models (PTLM) learn contextual representation from massive amounts of unlabeled text and are shown to perform impressively in downstream NLU tasks. In parallel, a growing body of literature shows that PTLMs fail inconsistently and non-intuitively, showing a lack of reasoning and grounding. To take a first step toward quantifying the effect of grounding (or lack thereof), we curate a novel and comprehensive dataset of object affordances -- GrAFFORD, characterized by 15 affordance classes. Unlike affordance datasets collected in vision and language domains, we annotate in-the-wild sentences with objects and affordances. Experimental results reveal that PTLMs exhibit limited reasoning abilities when it comes to uncommon object affordances. We also observe that pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;&#37319;&#29992;&#32447;&#24615;&#21270;&#31574;&#30053;&#23558;&#36755;&#20986;&#26641;&#32467;&#26500;&#36716;&#21270;&#20026;&#31526;&#21495;&#24207;&#21015;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#20219;&#21153;&#30340;&#25928;&#26524;&#12290;&#23454;&#39564;&#32467;&#26524;&#23545;LLMs&#30340;&#24615;&#33021;&#12289;&#27867;&#21270;&#33021;&#21147;&#21644;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#20013;&#30340;&#25361;&#25112;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2310.19462</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Constituency Parsing using LLMs. (arXiv:2310.19462v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;&#37319;&#29992;&#32447;&#24615;&#21270;&#31574;&#30053;&#23558;&#36755;&#20986;&#26641;&#32467;&#26500;&#36716;&#21270;&#20026;&#31526;&#21495;&#24207;&#21015;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#20219;&#21153;&#30340;&#25928;&#26524;&#12290;&#23454;&#39564;&#32467;&#26524;&#23545;LLMs&#30340;&#24615;&#33021;&#12289;&#27867;&#21270;&#33021;&#21147;&#21644;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#20013;&#30340;&#25361;&#25112;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#26159;&#19968;&#20010;&#22522;&#30784;&#20294;&#23578;&#26410;&#35299;&#20915;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#30340;&#21331;&#36234;&#24615;&#33021;&#22312;&#35299;&#20915;&#36825;&#19968;&#20219;&#21153;&#19978;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#37319;&#29992;&#19977;&#31181;&#32447;&#24615;&#21270;&#31574;&#30053;&#23558;&#36755;&#20986;&#30340;&#26641;&#32467;&#26500;&#36716;&#21270;&#20026;&#31526;&#21495;&#24207;&#21015;&#65292;&#20351;&#24471;LLMs&#21487;&#20197;&#36890;&#36807;&#29983;&#25104;&#32447;&#24615;&#21270;&#26641;&#26469;&#35299;&#20915;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#12290;&#25105;&#20204;&#20351;&#29992;&#22810;&#31181;&#19981;&#21516;&#30340;LLMs&#36827;&#34892;&#23454;&#39564;&#65292;&#21253;&#25324;ChatGPT&#12289;GPT-4&#12289;OPT&#12289;LLaMA&#21644;Alpaca&#65292;&#24182;&#23558;&#23427;&#20204;&#30340;&#24615;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#22120;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#28085;&#30422;&#20102;&#38646;&#26679;&#26412;&#23398;&#20064;&#12289;&#23569;&#26679;&#26412;&#23398;&#20064;&#21644;&#20840;&#26679;&#26412;&#23398;&#20064;&#30340;&#19981;&#21516;&#35774;&#32622;&#65292;&#24182;&#22312;&#19968;&#20010;&#39046;&#22495;&#20869;&#21644;&#20116;&#20010;&#39046;&#22495;&#22806;&#30340;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20102;LLMs&#30340;&#24615;&#33021;&#12289;&#27867;&#21270;&#33021;&#21147;&#21644;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constituency parsing is a fundamental yet unsolved natural language processing task. In this paper, we explore the potential of recent large language models (LLMs) that have exhibited remarkable performance across various domains and tasks to tackle this task. We employ three linearization strategies to transform output trees into symbol sequences, such that LLMs can solve constituency parsing by generating linearized trees. We conduct experiments using a diverse range of LLMs, including ChatGPT, GPT-4, OPT, LLaMA, and Alpaca, comparing their performance against the state-of-the-art constituency parsers. Our experiments encompass zero-shot, few-shot, and full-training learning settings, and we evaluate the models on one in-domain and five out-of-domain test datasets. Our findings reveal insights into LLMs' performance, generalization abilities, and challenges in constituency parsing.
&lt;/p&gt;</description></item></channel></rss>