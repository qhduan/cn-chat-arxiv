<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#29983;&#25104;&#30340;&#33258;&#21160;&#21270;&#25552;&#39640;&#20102;&#23398;&#26415;&#35265;&#35299;&#30340;&#21487;&#35775;&#38382;&#24615;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#23398;&#26415;&#20986;&#29256;&#29289;&#21644;&#30456;&#24212;&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#25506;&#32034;&#33258;&#21160;&#29983;&#25104;&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17768</link><description>&lt;p&gt;
&#20174;&#23398;&#26415;&#22797;&#26434;&#24615;&#21040;&#20844;&#20247;&#21465;&#20107;&#65306;&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
SciNews: From Scholarly Complexities to Public Narratives -- A Dataset for Scientific News Report Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17768
&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#29983;&#25104;&#30340;&#33258;&#21160;&#21270;&#25552;&#39640;&#20102;&#23398;&#26415;&#35265;&#35299;&#30340;&#21487;&#35775;&#38382;&#24615;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#23398;&#26415;&#20986;&#29256;&#29289;&#21644;&#30456;&#24212;&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#25506;&#32034;&#33258;&#21160;&#29983;&#25104;&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#20316;&#20026;&#19968;&#20010;&#26725;&#26753;&#65292;&#24039;&#22937;&#22320;&#23558;&#22797;&#26434;&#30340;&#30740;&#31350;&#25991;&#31456;&#32763;&#35793;&#25104;&#19982;&#26356;&#24191;&#27867;&#30340;&#20844;&#20247; resonant &#30340;&#25253;&#36947;&#12290;&#36825;&#31181;&#21465;&#20107;&#30340;&#33258;&#21160;&#29983;&#25104;&#22686;&#24378;&#20102;&#23398;&#26415;&#35265;&#35299;&#30340;&#21487;&#35775;&#38382;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35821;&#26009;&#24211;&#26469;&#20419;&#36827;&#36825;&#31181;&#33539;&#24335;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#30340;&#35821;&#26009;&#24211;&#21253;&#25324;&#20061;&#20010;&#23398;&#31185;&#39046;&#22495;&#20013;&#23398;&#26415;&#20986;&#29256;&#29289;&#21450;&#20854;&#30456;&#24212;&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#30340;&#24179;&#34892;&#32534;&#35793;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#25968;&#25454;&#38598;&#30340;&#23454;&#29992;&#24615;&#21644;&#21487;&#38752;&#24615;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#20998;&#26512;&#65292;&#31361;&#20986;&#20102;&#31185;&#23398;&#26032;&#38395;&#21465;&#20107;&#21644;&#23398;&#26415;&#25991;&#31295;&#20043;&#38388;&#30340;&#21487;&#35835;&#24615;&#21644;&#31616;&#27905;&#24615;&#24046;&#24322;&#12290;&#25105;&#20204;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#22522;&#20934;&#27979;&#35797;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#12290;&#35780;&#20272;&#36807;&#31243;&#21253;&#25324;&#33258;&#21160;&#35780;&#20272;&#21644;&#20154;&#24037;&#35780;&#20272;&#65292;&#20026;&#26410;&#26469;&#25506;&#32034;&#33258;&#21160;&#29983;&#25104;&#31185;&#23398;&#26032;&#38395;&#25253;&#36947;&#25171;&#19979;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17768v1 Announce Type: cross  Abstract: Scientific news reports serve as a bridge, adeptly translating complex research articles into reports that resonate with the broader public. The automated generation of such narratives enhances the accessibility of scholarly insights. In this paper, we present a new corpus to facilitate this paradigm development. Our corpus comprises a parallel compilation of academic publications and their corresponding scientific news reports across nine disciplines. To demonstrate the utility and reliability of our dataset, we conduct an extensive analysis, highlighting the divergences in readability and brevity between scientific news narratives and academic manuscripts. We benchmark our dataset employing state-of-the-art text generation models. The evaluation process involves both automatic and human evaluation, which lays the groundwork for future explorations into the automated generation of scientific news reports. The dataset and code related 
&lt;/p&gt;</description></item><item><title>CHARM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20840;&#38754;&#28145;&#20837;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25991;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#30340;&#22522;&#20934;&#65292;&#30740;&#31350;&#21457;&#29616;LLM&#30340;&#35821;&#35328;&#23548;&#21521;&#24615;&#21644;&#20219;&#21153;&#39046;&#22495;&#20250;&#24433;&#21709;&#25552;&#31034;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25351;&#20986;&#19968;&#20123;LLMs&#22312;&#35760;&#24518;&#20013;&#25991;&#24120;&#35782;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#32780;&#20854;&#20182;&#19968;&#20123;LLMs&#22312;&#25512;&#29702;&#19978;&#34920;&#29616;&#23384;&#22312;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2403.14112</link><description>&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25991;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#65306;&#20174;&#20013;&#25991;&#29305;&#23450;&#21040;&#25512;&#29702;-&#35760;&#24518;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14112
&lt;/p&gt;
&lt;p&gt;
CHARM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20840;&#38754;&#28145;&#20837;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#25991;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#30340;&#22522;&#20934;&#65292;&#30740;&#31350;&#21457;&#29616;LLM&#30340;&#35821;&#35328;&#23548;&#21521;&#24615;&#21644;&#20219;&#21153;&#39046;&#22495;&#20250;&#24433;&#21709;&#25552;&#31034;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25351;&#20986;&#19968;&#20123;LLMs&#22312;&#35760;&#24518;&#20013;&#25991;&#24120;&#35782;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#32780;&#20854;&#20182;&#19968;&#20123;LLMs&#22312;&#25512;&#29702;&#19978;&#34920;&#29616;&#23384;&#22312;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;CHARM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20840;&#38754;&#28145;&#20837;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#25991;&#24120;&#35782;&#25512;&#29702;&#33021;&#21147;&#30340;&#22522;&#20934;&#65292;&#28085;&#30422;&#20102;&#20840;&#29699;&#24050;&#30693;&#21644;&#20013;&#25991;&#29305;&#26377;&#30340;&#24120;&#35782;&#12290;&#22312;CHARM&#19978;&#35780;&#20272;&#20102;7&#20010;&#33521;&#25991;&#21644;12&#20010;&#20013;&#25991;&#23450;&#21521;LLMs&#65292;&#37319;&#29992;&#20102;5&#31181;&#20195;&#34920;&#24615;&#25552;&#31034;&#31574;&#30053;&#26469;&#25552;&#39640;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#27604;&#22914;&#24605;&#32500;&#38142;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;LLM&#30340;&#35821;&#35328;&#23548;&#21521;&#24615;&#21644;&#20219;&#21153;&#39046;&#22495;&#24433;&#21709;&#20102;&#25552;&#31034;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#65292;&#36825;&#20016;&#23500;&#20102;&#20197;&#24448;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#32039;&#23494;&#20851;&#32852;&#30340;&#25512;&#29702;&#21644;&#35760;&#24518;&#20219;&#21153;&#65292;&#24182;&#21457;&#29616;&#19968;&#20123;LLMs&#22312;&#35760;&#24518;&#20013;&#25991;&#24120;&#35782;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#24433;&#21709;&#20102;&#23427;&#20204;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#32780;&#20854;&#20182;&#19968;&#20123;LLMs&#22312;&#25512;&#29702;&#19978;&#34920;&#29616;&#23384;&#22312;&#24046;&#24322;&#65292;&#23613;&#31649;&#35760;&#24518;&#34920;&#29616;&#30456;&#20284;&#12290;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;LLMs&#30340;&#19982;&#35760;&#24518;&#26080;&#20851;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#20998;&#26512;&#20102;&#20856;&#22411;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14112v1 Announce Type: new  Abstract: We introduce CHARM, the first benchmark for comprehensively and in-depth evaluating the commonsense reasoning ability of large language models (LLMs) in Chinese, which covers both globally known and Chinese-specific commonsense. We evaluated 7 English and 12 Chinese-oriented LLMs on CHARM, employing 5 representative prompt strategies for improving LLMs' reasoning ability, such as Chain-of-Thought. Our findings indicate that the LLM's language orientation and the task's domain influence the effectiveness of the prompt strategy, which enriches previous research findings. We built closely-interconnected reasoning and memorization tasks, and found that some LLMs struggle with memorizing Chinese commonsense, affecting their reasoning ability, while others show differences in reasoning despite similar memorization performance. We also evaluated the LLMs' memorization-independent reasoning abilities and analyzed the typical errors. Our study pr
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20174;&#26356;&#31616;&#21333;&#30340;&#20219;&#21153;&#23398;&#20064;&#65292;&#23454;&#29616;&#23545;&#26356;&#38590;&#25512;&#29702;&#20219;&#21153;&#30340;&#26377;&#25928;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#23545;&#40784;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.09472</link><description>&lt;p&gt;
&#26131;&#20110;&#38590;&#30340;&#27867;&#21270;&#65306;&#36229;&#36234;&#20154;&#31867;&#30417;&#30563;&#30340;&#21487;&#25193;&#23637;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09472
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20174;&#26356;&#31616;&#21333;&#30340;&#20219;&#21153;&#23398;&#20064;&#65292;&#23454;&#29616;&#23545;&#26356;&#38590;&#25512;&#29702;&#20219;&#21153;&#30340;&#26377;&#25928;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#23545;&#40784;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#26041;&#27861;&#20381;&#36182;&#20110;&#20154;&#31867;&#25552;&#20379;&#30340;&#28436;&#31034;&#25110;&#21028;&#26029;&#65292;&#30001;&#20110;&#36825;&#31181;&#26041;&#27861;&#65292;AI&#31995;&#32479;&#23398;&#20064;&#21040;&#30340;&#33021;&#21147;&#23558;&#21463;&#21040;&#20154;&#31867;&#33021;&#21147;&#30340;&#19978;&#30028;&#38480;&#21046;&#12290;&#36825;&#23601;&#24102;&#26469;&#20102;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30740;&#31350;&#38382;&#39064;&#65306;&#24403;&#31995;&#32479;&#30340;&#33021;&#21147;&#36229;&#36807;&#20154;&#31867;&#27700;&#24179;&#26102;&#65292;&#25105;&#20204;&#22914;&#20309;&#32487;&#32493;&#25913;&#36827;&#36825;&#20123;&#31995;&#32479;&#65311;&#26412;&#25991;&#22312;&#35299;&#20915;&#38590;&#24230;&#25512;&#29702;&#20219;&#21153;&#65288;&#22914;4-5&#32423;&#25968;&#23398;&#38382;&#39064;&#65289;&#30340;&#32972;&#26223;&#19979;&#22238;&#31572;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#36890;&#36807;&#20174;&#26356;&#31616;&#21333;&#30340;&#20219;&#21153;&#65288;&#22914;1-3&#32423;&#25968;&#23398;&#38382;&#39064;&#65289;&#20013;&#23398;&#20064;&#20154;&#31867;&#27880;&#37322;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#8220;&#26131;&#20110;&#38590;&#30340;&#27867;&#21270;&#8221;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35266;&#28857;&#26159;&#65292;&#19968;&#20010;&#22312;&#26356;&#31616;&#21333;&#20219;&#21153;&#30340;&#30417;&#30563;&#19979;&#35757;&#32451;&#30340;&#35780;&#20272;&#22120;&#65288;&#22870;&#21169;&#27169;&#22411;&#65289;&#21487;&#20197;&#26377;&#25928;&#22320;&#29992;&#20110;&#35780;&#20998;&#26356;&#38590;&#20219;&#21153;&#30340;&#20505;&#36873;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#20419;&#36827;&#22312;&#19981;&#21516;&#38590;&#24230;&#20219;&#21153;&#38388;&#30340;&#26131;&#20110;&#38590;&#30340;&#27867;&#21270;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#25193;&#23637;&#23545;&#40784;&#26041;&#27861;&#65292;&#39318;&#20808;&#35757;&#32451;&#22788;&#29702;&#30563;&#23548;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09472v1 Announce Type: cross  Abstract: Current AI alignment methodologies rely on human-provided demonstrations or judgments, and the learned capabilities of AI systems would be upper-bounded by human capabilities as a result. This raises a challenging research question: How can we keep improving the systems when their capabilities have surpassed the levels of humans? This paper answers this question in the context of tackling hard reasoning tasks (e.g., level 4-5 MATH problems) via learning from human annotations on easier tasks (e.g., level 1-3 MATH problems), which we term as \textit{easy-to-hard generalization}. Our key insight is that an evaluator (reward model) trained on supervisions for easier tasks can be effectively used for scoring candidate solutions of harder tasks and hence facilitating easy-to-hard generalization over different levels of tasks. Based on this insight, we propose a novel approach to scalable alignment, which firstly trains the process-supervise
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#20581;&#24247;&#20445;&#20581;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;</title><link>https://arxiv.org/abs/2403.05720</link><description>&lt;p&gt;
&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05720
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#20581;&#24247;&#20445;&#20581;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#65288;BHC&#65289;&#25688;&#35201;&#26159;&#36890;&#36807;&#24635;&#32467;&#20020;&#24202;&#35760;&#24405;&#32780;&#29983;&#25104;&#30340;&#24120;&#35265;&#20020;&#24202;&#25991;&#20214;&#12290;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#21160;&#21270;&#23454;&#38469;&#20219;&#21153;&#26041;&#38754;&#23637;&#29616;&#20986;&#26174;&#33879;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;&#21307;&#30103;&#24212;&#29992;&#65288;&#22914;BHC&#21512;&#25104;&#65289;&#20013;&#30340;&#33021;&#21147;&#23578;&#26410;&#24471;&#21040;&#23637;&#31034;&#12290;&#20026;&#20102;&#20351;LLMs&#33021;&#22815;&#36866;&#24212;BHC&#21512;&#25104;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#21547;&#20174;MIMIC-IV&#35760;&#24405;&#20013;&#25552;&#21462;&#30340;&#32463;&#36807;&#39044;&#22788;&#29702;&#30340;&#25968;&#25454;&#38598;&#65292;&#23553;&#35013;&#20102;&#20020;&#24202;&#35760;&#24405;&#21644;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#65288;BHC&#65289;&#23545;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20004;&#20010;&#36890;&#29992;LLMs&#21644;&#19977;&#20010;&#21307;&#30103;&#39046;&#22495;&#36866;&#24212;&#30340;LLMs&#30340;&#24615;&#33021;&#65292;&#20197;&#25913;&#36827;&#20174;&#20020;&#24202;&#35760;&#24405;&#29983;&#25104;BHC&#12290;&#25105;&#20204;&#20351;&#29992;&#20020;&#24202;&#35760;&#24405;&#20316;&#20026;&#36755;&#20837;&#26469;&#29983;&#25104;BHC&#65292;&#37319;&#29992;&#22522;&#20110;&#25552;&#31034;&#30340;&#65288;&#20351;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#65289;&#21644;&#22522;&#20110;&#24494;&#35843;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#26469;&#24212;&#29992;&#20110;&#19977;&#20010;&#24320;&#28304;LLMs&#65288;Clinical-T5-Large&#65292;Llama2-13B&#65292;FLAN-UL2&#65289;&#21644;&#20004;&#20010;&#19987;&#26377;LLMs&#65288;GPT-3.5&#65292;GPT-4&#65289;&#12290;&#25105;&#20204;&#23450;&#37327;&#35780;&#20272;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05720v1 Announce Type: cross  Abstract: Brief hospital course (BHC) summaries are common clinical documents generated by summarizing clinical notes. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as BHC synthesis have not been shown. To enable the adaptation of LLMs for BHC synthesis, we introduce a novel benchmark consisting of a pre-processed dataset extracted from MIMIC-IV notes, encapsulating clinical note, and brief hospital course (BHC) pairs. We assess the performance of two general-purpose LLMs and three healthcare-adapted LLMs to improve BHC synthesis from clinical notes. Using clinical notes as input for generating BHCs, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to three open-source LLMs (Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5, GPT-4). We quantitatively evaluate the performa
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#34920;&#36798;&#20154;&#31867;&#20010;&#24615;&#29305;&#24449;&#26041;&#38754;&#30340;&#21487;&#38752;&#24615;&#65292;&#30740;&#31350;&#35748;&#30693;&#19982;&#34892;&#20026;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#20197;&#21450;&#25552;&#20986;&#23545;&#35266;&#23519;&#32467;&#26524;&#30340;&#24515;&#29702;&#29702;&#35770;&#21644;&#25351;&#26631;&#20551;&#35774;</title><link>https://arxiv.org/abs/2402.14679</link><description>&lt;p&gt;
&#35748;&#30693;&#19982;&#34892;&#20026;&#19968;&#33268;&#36824;&#26159;&#19981;&#19968;&#33268;&#65306;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20010;&#24615;
&lt;/p&gt;
&lt;p&gt;
Is Cognition and Action Consistent or Not: Investigating Large Language Model's Personality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14679
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#34920;&#36798;&#20154;&#31867;&#20010;&#24615;&#29305;&#24449;&#26041;&#38754;&#30340;&#21487;&#38752;&#24615;&#65292;&#30740;&#31350;&#35748;&#30693;&#19982;&#34892;&#20026;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#20197;&#21450;&#25552;&#20986;&#23545;&#35266;&#23519;&#32467;&#26524;&#30340;&#24515;&#29702;&#29702;&#35770;&#21644;&#25351;&#26631;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22238;&#31572;&#20154;&#26684;&#38382;&#21367;&#35843;&#26597;&#26469;&#25506;&#35752;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#34920;&#36798;&#31867;&#20154;&#20010;&#24615;&#29305;&#24449;&#26041;&#38754;&#30340;&#21487;&#38752;&#24615;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35780;&#20272;LLMs&#25152;&#34920;&#36798;&#30340;&#20010;&#24615;&#20542;&#21521;&#19982;&#23427;&#20204;&#23454;&#38469;&#8220;&#34892;&#20026;&#8221;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#26816;&#39564;&#36825;&#20123;&#27169;&#22411;&#33021;&#22815;&#27169;&#25311;&#31867;&#20154;&#20010;&#24615;&#27169;&#24335;&#30340;&#31243;&#24230;&#12290;&#36890;&#36807;&#20840;&#38754;&#20998;&#26512;LLM&#36755;&#20986;&#19982;&#24050;&#24314;&#31435;&#30340;&#20154;&#31867;&#22522;&#20934;&#20043;&#38388;&#30340;&#23545;&#27604;&#65292;&#25105;&#20204;&#35797;&#22270;&#20102;&#35299;LLMs&#20013;&#35748;&#30693;&#19982;&#34892;&#20026;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#26681;&#25454;&#24515;&#29702;&#29702;&#35770;&#21644;&#25351;&#26631;&#23545;&#35266;&#23519;&#32467;&#26524;&#25552;&#20986;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14679v1 Announce Type: new  Abstract: In this study, we investigate the reliability of Large Language Models (LLMs) in professing human-like personality traits through responses to personality questionnaires. Our goal is to evaluate the consistency between LLMs' professed personality inclinations and their actual "behavior", examining the extent to which these models can emulate human-like personality patterns. Through a comprehensive analysis of LLM outputs against established human benchmarks, we seek to understand the cognition-action divergence in LLMs and propose hypotheses for the observed results based on psychological theories and metrics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26356;&#26032;&#20013;&#30340;&#36951;&#24536;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#19978;&#28216;&#23454;&#20363;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;&#26681;&#25454;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#21464;&#21270;&#19982;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#30456;&#20284;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.01865</link><description>&lt;p&gt;
&#25105;&#30340;&#27169;&#22411;&#20250;&#24536;&#35760;&#20160;&#20040;&#65311;&#35821;&#35328;&#27169;&#22411;&#25913;&#36827;&#20013;&#30340;&#34987;&#36951;&#24536;&#23454;&#20363;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26356;&#26032;&#20013;&#30340;&#36951;&#24536;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#19978;&#28216;&#23454;&#20363;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;&#26681;&#25454;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#21464;&#21270;&#19982;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#30456;&#20284;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#35821;&#35328;&#27169;&#22411;&#20250;&#20986;&#29616;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#20165;&#20165;&#36890;&#36807;&#23558;&#27169;&#22411;&#26356;&#26032;&#20026;&#32416;&#27491;&#38169;&#35823;&#23454;&#20363;&#65292;&#20250;&#23548;&#33268;&#28798;&#38590;&#24615;&#30340;&#36951;&#24536;&#65292;&#26356;&#26032;&#21518;&#30340;&#27169;&#22411;&#22312;&#25351;&#23548;&#24494;&#35843;&#25110;&#19978;&#28216;&#35757;&#32451;&#38454;&#27573;&#20013;&#23398;&#21040;&#30340;&#23454;&#20363;&#19978;&#20986;&#29616;&#38169;&#35823;&#12290;&#38543;&#26426;&#37325;&#25773;&#19978;&#28216;&#25968;&#25454;&#30340;&#25928;&#26524;&#19981;&#20196;&#20154;&#28385;&#24847;&#65292;&#24448;&#24448;&#20276;&#38543;&#30528;&#36739;&#39640;&#30340;&#26041;&#24046;&#21644;&#36739;&#24046;&#30340;&#21487;&#25511;&#24615;&#12290;&#20026;&#20102;&#25913;&#21892;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#35797;&#22270;&#39044;&#27979;&#30001;&#20110;&#27169;&#22411;&#26356;&#26032;&#32780;&#36951;&#24536;&#30340;&#19978;&#28216;&#23454;&#20363;&#12290;&#25105;&#20204;&#26681;&#25454;&#19968;&#32452;&#22312;&#32447;&#23398;&#20064;&#30340;&#23454;&#20363;&#21644;&#30456;&#24212;&#34987;&#36951;&#24536;&#30340;&#19978;&#28216;&#39044;&#35757;&#32451;&#23454;&#20363;&#35757;&#32451;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#36825;&#26679;&#30340;&#35266;&#23519;&#32467;&#26524;&#65306;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#30340;&#21464;&#21270;&#31867;&#20284;&#20110;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#21464;&#21270;&#65292;&#36825;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#19981;&#38169;&#30340;&#25928;&#26524;&#65292;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Language models deployed in the wild make errors. However, simply updating the model with the corrected error instances causes catastrophic forgetting -- the updated model makes errors on instances learned during the instruction tuning or upstream training phase. Randomly replaying upstream data yields unsatisfactory performance and often comes with high variance and poor controllability. To this end, we try to forecast upstream examples that will be forgotten due to a model update for improved controllability of the replay process and interpretability. We train forecasting models given a collection of online learned examples and corresponding forgotten upstream pre-training examples. We propose a partially interpretable forecasting model based on the observation that changes in pre-softmax logit scores of pretraining examples resemble that of online learned examples, which performs decently on BART but fails on T5 models. We further show a black-box classifier based on inner products 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25581;&#31034;&#20102;BPDec&#65288;BERT&#39044;&#35757;&#32451;&#35299;&#30721;&#22120;&#65289;&#30340;&#28508;&#21147;&#65292;&#24378;&#35843;&#22686;&#24378;&#30340;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#35299;&#30721;&#22120;&#35774;&#35745;&#21450;&#30740;&#31350;&#22312;BERT&#39044;&#35757;&#32451;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.15861</link><description>&lt;p&gt;
BPDec: &#25581;&#31034;BERT&#39044;&#35757;&#32451;&#20013;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#35299;&#30721;&#22120;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;BPDec&#65288;BERT&#39044;&#35757;&#32451;&#35299;&#30721;&#22120;&#65289;&#30340;&#28508;&#21147;&#65292;&#24378;&#35843;&#22686;&#24378;&#30340;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#35299;&#30721;&#22120;&#35774;&#35745;&#21450;&#30740;&#31350;&#22312;BERT&#39044;&#35757;&#32451;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
BERT&#65288;&#26469;&#33258;Transformer&#30340;&#21452;&#21521;&#32534;&#30721;&#34920;&#31034;&#65289;&#36890;&#36807;&#20854;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#20986;&#33394;&#30340;&#24615;&#33021;&#24443;&#24213;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#20154;&#21592;&#20027;&#35201;&#38598;&#20013;&#22312;&#19982;&#27169;&#22411;&#32467;&#26500;&#30456;&#20851;&#30340;&#22686;&#24378;&#65292;&#20363;&#22914;&#30456;&#23545;&#20301;&#32622;&#23884;&#20837;&#21644;&#26356;&#26377;&#25928;&#30340;&#27880;&#24847;&#26426;&#21046;&#12290;&#36824;&#26377;&#19968;&#20123;&#20154;&#28145;&#20837;&#30740;&#31350;&#20102;&#19982;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#30456;&#20851;&#30340;&#39044;&#35757;&#32451;&#25216;&#24039;&#65292;&#21253;&#25324;&#25972;&#35789;&#25513;&#30721;&#12290;DeBERTa&#24341;&#20837;&#20102;&#19968;&#31181;&#38024;&#23545;BERT&#32534;&#30721;&#22120;&#27169;&#22411;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#22686;&#24378;&#35299;&#30721;&#22120;&#65292;&#35777;&#26126;&#25928;&#26524;&#38750;&#24120;&#26174;&#33879;&#12290;&#25105;&#20204;&#35748;&#20026;&#22260;&#32469;&#22686;&#24378;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#35299;&#30721;&#22120;&#30340;&#35774;&#35745;&#21644;&#30740;&#31350;&#24182;&#26410;&#24471;&#21040;&#24212;&#26377;&#30340;&#37325;&#35270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#22686;&#24378;&#35299;&#30721;&#22120;&#30340;&#35774;&#35745;&#65292;&#24182;&#20171;&#32461;&#20102;BPDec&#65288;BERT&#39044;&#35757;&#32451;&#35299;&#30721;&#22120;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#24314;&#27169;&#35757;&#32451;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#24120;&#65292;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#20250;&#38024;&#23545;&#29305;&#23450;&#30340;&#33258;&#28982;&#35821;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.15861v2 Announce Type: replace-cross  Abstract: BERT (Bidirectional Encoder Representations from Transformers) has revolutionized the field of natural language processing through its exceptional performance on numerous tasks. Yet, the majority of researchers have mainly concentrated on enhancements related to the model structure, such as relative position embedding and more efficient attention mechanisms. Others have delved into pretraining tricks associated with Masked Language Modeling, including whole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's encoder model for pretraining, proving to be highly effective. We argue that the design and research around enhanced masked language modeling decoders have been underappreciated. In this paper, we propose several designs of enhanced decoders and introduce BPDec (BERT Pretraining Decoder), a novel method for modeling training. Typically, a pretrained BERT model is fine-tuned for specific Natural Language 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;SCDA&#65292;&#36890;&#36807;&#21033;&#29992;&#20122;&#25991;&#21270;&#34920;&#36798;&#29983;&#25104;&#22120;&#20026;&#27599;&#20010;&#35757;&#32451;&#25991;&#26412;&#29983;&#25104;&#20845;&#20010;&#22686;&#24378;&#25991;&#26412;&#65292;&#20197;&#35299;&#20915;&#24773;&#24863;&#20998;&#26512;&#20013;&#38754;&#20020;&#30340;&#35757;&#32451;&#25968;&#25454;&#19981;&#36275;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;SCDA&#30340;&#26377;&#25928;&#24615;&#21644;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.00178</link><description>&lt;p&gt;
&#24773;&#24863;&#20998;&#26512;&#26159;&#21542;&#38656;&#35201;&#20122;&#25991;&#21270;&#65311;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Will Sentiment Analysis Need Subculture? A New Data Augmentation Approach. (arXiv:2309.00178v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00178
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;SCDA&#65292;&#36890;&#36807;&#21033;&#29992;&#20122;&#25991;&#21270;&#34920;&#36798;&#29983;&#25104;&#22120;&#20026;&#27599;&#20010;&#35757;&#32451;&#25991;&#26412;&#29983;&#25104;&#20845;&#20010;&#22686;&#24378;&#25991;&#26412;&#65292;&#20197;&#35299;&#20915;&#24773;&#24863;&#20998;&#26512;&#20013;&#38754;&#20020;&#30340;&#35757;&#32451;&#25968;&#25454;&#19981;&#36275;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;SCDA&#30340;&#26377;&#25928;&#24615;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33879;&#21517;&#35866;&#35821;&#8220;&#31508;&#33021;&#32988;&#36807;&#21073;&#8221;&#24378;&#35843;&#20102;&#25991;&#23383;&#34920;&#36798;&#22312;&#22609;&#36896;&#24773;&#24863;&#26041;&#38754;&#25152;&#20855;&#26377;&#30340;&#24378;&#22823;&#24433;&#21709;&#21147;&#12290;&#20107;&#23454;&#19978;&#65292;&#31934;&#24515;&#25171;&#36896;&#30340;&#25991;&#23383;&#21487;&#20197;&#22312;&#25991;&#21270;&#20013;&#20135;&#29983;&#28145;&#36828;&#20849;&#40483;&#65292;&#20256;&#36798;&#28145;&#21051;&#30340;&#24773;&#24863;&#12290;&#22914;&#20170;&#65292;&#20114;&#32852;&#32593;&#30340;&#26222;&#21450;&#20419;&#25104;&#20102;&#22260;&#32469;&#24403;&#20195;&#31038;&#20250;&#29615;&#22659;&#32858;&#38598;&#30340;&#20122;&#25991;&#21270;&#12290;&#20122;&#25991;&#21270;&#36890;&#36807;&#28909;&#34935;&#36861;&#27714;&#26032;&#22855;&#26469;&#24039;&#22937;&#22320;&#34920;&#36798;&#20154;&#31867;&#24773;&#24863;&#30340;&#22797;&#26434;&#24615;&#65292;&#36825;&#22312;&#24773;&#24863;&#20998;&#26512;&#20013;&#26159;&#19981;&#21487;&#24573;&#35270;&#30340;&#20107;&#23454;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20122;&#25991;&#21270;&#30340;&#35270;&#35282;&#20016;&#23500;&#25968;&#25454;&#65292;&#20197;&#35299;&#20915;&#24773;&#24863;&#20998;&#26512;&#38754;&#20020;&#30340;&#35757;&#32451;&#25968;&#25454;&#19981;&#36275;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20122;&#25991;&#21270;&#30340;&#25968;&#25454;&#22686;&#24378;&#65288;SCDA&#65289;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#21019;&#24314;&#20845;&#31181;&#19981;&#21516;&#20122;&#25991;&#21270;&#34920;&#36798;&#29983;&#25104;&#22120;&#65292;&#20026;&#27599;&#20010;&#35757;&#32451;&#25991;&#26412;&#29983;&#25104;&#20845;&#20010;&#22686;&#24378;&#25991;&#26412;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#20102;SCDA&#30340;&#26377;&#25928;&#24615;&#21644;&#28508;&#21147;&#12290;&#32467;&#26524;&#36824;&#25581;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#25552;&#39640;&#24773;&#24863;&#20998;&#26512;&#24615;&#33021;&#30340;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
The renowned proverb that "The pen is mightier than the sword" underscores the formidable influence wielded by text expressions in shaping sentiments. Indeed, well-crafted written can deeply resonate within cultures, conveying profound sentiments. Nowadays, the omnipresence of the Internet has fostered a subculture that congregates around the contemporary milieu. The subculture artfully articulates the intricacies of human feelings by ardently pursuing the allure of novelty, a fact that cannot be disregarded in the sentiment analysis. This paper strives to enrich data through the lens of subculture, to address the insufficient training data faced by sentiment analysis. To this end, a new approach of subculture-based data augmentation (SCDA) is proposed, which engenders six enhanced texts for each training text by leveraging the creation of six diverse subculture expression generators. The extensive experiments attest to the effectiveness and potential of SCDA. The results also shed lig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#31995;&#32479;&#22320;&#26816;&#26597;ChatGPT&#22312;&#20004;&#20010;&#21487;&#25511;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#21363;ChatGPT&#33021;&#21542;&#36866;&#24212;&#19981;&#21516;&#30340;&#30446;&#26631;&#21463;&#20247;&#21644;&#20889;&#20316;&#39118;&#26684;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20154;&#31867;&#20135;&#29983;&#30340;&#25991;&#20307;&#21464;&#21270;&#27604;ChatGPT&#34920;&#29616;&#20986;&#30340;&#26356;&#22823;&#65292;&#32780;&#29983;&#25104;&#30340;&#25991;&#26412;&#22312;&#19968;&#20123;&#29305;&#24449;&#19978;&#19982;&#20154;&#31867;&#26679;&#26412;&#26377;&#25152;&#19981;&#21516;&#65292;&#26377;&#26102;&#20250;&#21253;&#21547;&#20107;&#23454;&#38169;&#35823;&#25110;&#24187;&#35273;&#12290;</title><link>http://arxiv.org/abs/2306.07799</link><description>&lt;p&gt;
ChatGPT&#19982;&#20154;&#24037;&#25776;&#20889;&#25991;&#26412;&#65306;&#21487;&#25511;&#25991;&#26412;&#25688;&#35201;&#21644;&#21477;&#23376;&#39118;&#26684;&#36716;&#31227;&#30340;&#27934;&#23519;
&lt;/p&gt;
&lt;p&gt;
ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer. (arXiv:2306.07799v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07799
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#31995;&#32479;&#22320;&#26816;&#26597;ChatGPT&#22312;&#20004;&#20010;&#21487;&#25511;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#21363;ChatGPT&#33021;&#21542;&#36866;&#24212;&#19981;&#21516;&#30340;&#30446;&#26631;&#21463;&#20247;&#21644;&#20889;&#20316;&#39118;&#26684;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20154;&#31867;&#20135;&#29983;&#30340;&#25991;&#20307;&#21464;&#21270;&#27604;ChatGPT&#34920;&#29616;&#20986;&#30340;&#26356;&#22823;&#65292;&#32780;&#29983;&#25104;&#30340;&#25991;&#26412;&#22312;&#19968;&#20123;&#29305;&#24449;&#19978;&#19982;&#20154;&#31867;&#26679;&#26412;&#26377;&#25152;&#19981;&#21516;&#65292;&#26377;&#26102;&#20250;&#21253;&#21547;&#20107;&#23454;&#38169;&#35823;&#25110;&#24187;&#35273;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;ChatGPT&#65289;&#20197;&#20854;&#20986;&#33394;&#30340;&#33021;&#21147;&#20174;&#31616;&#30701;&#30340;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#29983;&#25104;&#36830;&#36143;&#30340;&#25991;&#26412;&#24341;&#36215;&#20102;&#23186;&#20307;&#30340;&#37325;&#35270;&#12290;&#26412;&#25991;&#26088;&#22312;&#31995;&#32479;&#22320;&#26816;&#26597;ChatGPT&#22312;&#20004;&#20010;&#21487;&#25511;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#21363;ChatGPT&#33021;&#21542;&#36866;&#24212;&#19981;&#21516;&#30340;&#30446;&#26631;&#21463;&#20247;&#65288;&#19987;&#23478;&#19982;&#19968;&#33324;&#20154;&#65289;&#21644;&#20889;&#20316;&#39118;&#26684;&#65288;&#27491;&#24335;&#19982;&#38750;&#27491;&#24335;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#29983;&#25104;&#25991;&#26412;&#30340;&#24544;&#23454;&#24230;&#65292;&#24182;&#23558;&#27169;&#22411;&#30340;&#34920;&#29616;&#19982;&#20154;&#24037;&#25776;&#20889;&#30340;&#25991;&#26412;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#20154;&#31867;&#20135;&#29983;&#30340;&#25991;&#20307;&#21464;&#21270;&#27604;ChatGPT&#34920;&#29616;&#20986;&#30340;&#26356;&#22823;&#65292;&#32780;&#29983;&#25104;&#30340;&#25991;&#26412;&#22312;&#35832;&#22914;&#21333;&#35789;&#31867;&#22411;&#20998;&#24067;&#31561;&#20960;&#20010;&#29305;&#24449;&#19978;&#19982;&#20154;&#31867;&#26679;&#26412;&#26377;&#25152;&#19981;&#21516;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403; ChatGPT &#23558;&#25991;&#26412;&#36866;&#24212;&#29305;&#23450;&#39118;&#26684;&#26102;&#65292;&#26377;&#26102;&#20250;&#21253;&#21547;&#20107;&#23454;&#38169;&#35823;&#25110;&#24187;&#35273;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale language models, like ChatGPT, have garnered significant media attention and stunned the public with their remarkable capacity for generating coherent text from short natural language prompts. In this paper, we aim to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, with respect to ChatGPT's ability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal). Additionally, we evaluate the faithfulness of the generated text, and compare the model's performance with human-authored texts. Our findings indicate that the stylistic variations produced by humans are considerably larger than those demonstrated by ChatGPT, and the generated texts diverge from human samples in several characteristics, such as the distribution of word types. Moreover, we observe that ChatGPT sometimes incorporates factual errors or hallucinations when adapting the text to suit a specific style.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;'RSTformer'&#30340;&#25688;&#35201;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20840;&#38754;&#34701;&#21512;&#20102;&#35805;&#35821;&#20851;&#31995;&#31867;&#22411;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20197;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#20026;&#22522;&#30784;&#65292;&#32463;&#36807;&#20005;&#26684;&#35780;&#20272;&#65292;&#34920;&#29616;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.16784</link><description>&lt;p&gt;
&#32467;&#21512;&#35805;&#35821;&#32467;&#26500;&#20998;&#24067;&#30340;&#38271;&#25991;&#26412;&#33258;&#21160;&#25688;&#35201;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization. (arXiv:2305.16784v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;'RSTformer'&#30340;&#25688;&#35201;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20840;&#38754;&#34701;&#21512;&#20102;&#35805;&#35821;&#20851;&#31995;&#31867;&#22411;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20197;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#20026;&#22522;&#30784;&#65292;&#32463;&#36807;&#20005;&#26684;&#35780;&#20272;&#65292;&#34920;&#29616;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#25991;&#26412;&#25688;&#35201;&#65292;&#35805;&#35821;&#32467;&#26500;&#22312;&#36776;&#35782;&#25991;&#26412;&#26680;&#24515;&#20869;&#23481;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#21487;&#24796;&#30340;&#26159;&#65292;&#20043;&#21069;&#23558;&#20462;&#36766;&#32467;&#26500;&#29702;&#35770;&#65288;RST&#65289;&#24341;&#20837;&#22522;&#20110;transformer&#30340;&#33258;&#21160;&#25688;&#35201;&#27169;&#22411;&#30340;&#30740;&#31350;&#20165;&#32771;&#34385;&#20102;&#26680;&#24515;&#37096;&#20998;&#30340;&#27880;&#37322;&#65292;&#20174;&#32780;&#24573;&#30053;&#20102;&#21508;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#35805;&#35821;&#20851;&#31995;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;'RSTformer'&#30340;&#26032;&#22411;&#25688;&#35201;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20840;&#38754;&#34701;&#21512;&#20102;&#35805;&#35821;&#20851;&#31995;&#31867;&#22411;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#30340;RST-attention&#26426;&#21046;&#26159;&#22522;&#20110;&#25991;&#26723;&#32423;&#20462;&#36766;&#32467;&#26500;&#30340;Longformer&#26694;&#26550;&#30340;&#25193;&#23637;&#12290;&#32463;&#36807;&#20005;&#26684;&#35780;&#20272;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#27169;&#22411;&#34920;&#29616;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#27169;&#22411;&#65292;&#20984;&#26174;&#20986;&#20854;&#22312;&#22810;&#20010;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#24037;&#35780;&#20272;&#19978;&#30340;&#21331;&#36234;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
For text summarization, the role of discourse structure is pivotal in discerning the core content of a text. Regrettably, prior studies on incorporating Rhetorical Structure Theory (RST) into transformer-based summarization models only consider the nuclearity annotation, thereby overlooking the variety of discourse relation types. This paper introduces the 'RSTformer', a novel summarization model that comprehensively incorporates both the types and uncertainty of rhetorical relations. Our RST-attention mechanism, rooted in document-level rhetorical structure, is an extension of the recently devised Longformer framework. Through rigorous evaluation, the model proposed herein exhibits significant superiority over state-of-the-art models, as evidenced by its notable performance on several automatic metrics and human evaluation.
&lt;/p&gt;</description></item></channel></rss>