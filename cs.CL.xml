<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#22810;&#20010;&#38543;&#26426;&#25277;&#26679;&#27169;&#22411;&#29983;&#25104;&#30340;&#20998;&#24067;&#25512;&#26029;&#32622;&#20449;&#24230;&#30340;&#28508;&#21147;&#65292;&#21487;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.13904</link><description>&lt;p&gt;
&#20351;&#29992;&#26679;&#26412;&#19968;&#33268;&#24615;&#26657;&#20934;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Calibrating Large Language Models with Sample Consistency
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13904
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#20010;&#38543;&#26426;&#25277;&#26679;&#27169;&#22411;&#29983;&#25104;&#30340;&#20998;&#24067;&#25512;&#26029;&#32622;&#20449;&#24230;&#30340;&#28508;&#21147;&#65292;&#21487;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39044;&#27979;&#30340;&#32622;&#20449;&#27700;&#24179;&#23545;&#20110;&#23427;&#20204;&#30340;&#21487;&#38752;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#19987;&#26377;&#24615;&#36136;&#21644;&#22823;&#35268;&#27169;&#65292;LLMs&#36890;&#24120;&#22825;&#29983;&#19981;&#32463;&#26657;&#20934;&#65292;&#20351;&#24471;&#20256;&#32479;&#30340;&#26657;&#20934;&#25216;&#26415;&#24456;&#38590;&#36866;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36890;&#36807;&#22810;&#20010;&#38543;&#26426;&#25277;&#26679;&#30340;&#27169;&#22411;&#29983;&#25104;&#30340;&#20998;&#24067;&#26469;&#25512;&#26029;&#32622;&#20449;&#24230;&#30340;&#28508;&#21147;&#65292;&#37319;&#29992;&#20102;&#19977;&#31181;&#19968;&#33268;&#24615;&#24230;&#37327;&#12290;&#25105;&#20204;&#22312;&#20061;&#20010;&#25512;&#29702;&#25968;&#25454;&#38598;&#19978;&#23545;&#21508;&#31181;&#24320;&#28304;&#21644;&#38381;&#28304;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22522;&#20110;&#19968;&#33268;&#24615;&#30340;&#26657;&#20934;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#20107;&#21518;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#20013;&#38388;&#35299;&#37322;&#12289;&#27169;&#22411;&#25193;&#23637;&#21644;&#26356;&#22823;&#30340;&#26679;&#26412;&#22823;&#23567;&#31561;&#22240;&#32032;&#21487;&#20197;&#22686;&#24378;&#26657;&#20934;&#65292;&#32780;&#25351;&#23548;&#35843;&#25972;&#20250;&#20351;&#26657;&#20934;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#19968;&#33268;&#24615;&#33719;&#24471;&#30340;&#32622;&#20449;&#24230;&#20998;&#25968;&#26377;&#26395;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13904v1 Announce Type: new  Abstract: Accurately gauging the confidence level of Large Language Models' (LLMs) predictions is pivotal for their reliable application. However, LLMs are often uncalibrated inherently and elude conventional calibration techniques due to their proprietary nature and massive scale. In this work, we explore the potential of deriving confidence from the distribution of multiple randomly sampled model generations, via three measures of consistency. We perform an extensive evaluation across various open and closed-source models on nine reasoning datasets. Results show that consistency-based calibration methods outperform existing post-hoc approaches. Meanwhile, we find that factors such as intermediate explanations, model scaling, and larger sample sizes enhance calibration, while instruction-tuning makes calibration more difficult. Moreover, confidence scores obtained from consistency have the potential to enhance model performance. Finally, we offer
&lt;/p&gt;</description></item></channel></rss>