<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#20171;&#32461;&#20102;IR2&#65292;&#19968;&#31181;&#29992;&#20110;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#20943;&#23569;&#36807;&#25311;&#21512;&#30340;&#20449;&#24687;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#22312;&#22797;&#26434;&#26597;&#35810;&#30340;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#21516;&#26102;&#23558;&#25104;&#26412;&#38477;&#20302;&#39640;&#36798;50%&#12290;</title><link>https://arxiv.org/abs/2402.16200</link><description>&lt;p&gt;
IR2&#65306;&#20449;&#24687;&#27491;&#21017;&#21270;&#29992;&#20110;&#20449;&#24687;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
IR2: Information Regularization for Information Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16200
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;IR2&#65292;&#19968;&#31181;&#29992;&#20110;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#20943;&#23569;&#36807;&#25311;&#21512;&#30340;&#20449;&#24687;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#22312;&#22797;&#26434;&#26597;&#35810;&#30340;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#21516;&#26102;&#23558;&#25104;&#26412;&#38477;&#20302;&#39640;&#36798;50%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#22320;&#22312;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#22797;&#26434;&#26597;&#35810;&#65292;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;IR2&#65292;&#21363;&#20449;&#24687;&#26816;&#32034;&#30340;&#20449;&#24687;&#27491;&#21017;&#21270;&#65292;&#19968;&#31181;&#29992;&#20110;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#20943;&#23569;&#36807;&#25311;&#21512;&#30340;&#25216;&#26415;&#12290;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#22797;&#26434;&#26597;&#35810;&#29305;&#24449;&#30340;&#19977;&#20010;&#26368;&#36817;&#30340;IR&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65306;DORIS-MAE&#12289;ArguAna&#21644;WhatsThatBook&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#19981;&#20165;&#22312;&#25152;&#32771;&#34385;&#30340;&#20219;&#21153;&#19978;&#20248;&#20110;&#20808;&#21069;&#30340;&#21512;&#25104;&#26597;&#35810;&#29983;&#25104;&#26041;&#27861;&#65292;&#32780;&#19988;&#36824;&#33021;&#23558;&#25104;&#26412;&#38477;&#20302;&#39640;&#36798;50&#65285;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#23558;&#19981;&#21516;&#38454;&#27573;&#30340;&#19977;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#8212;&#8212;&#36755;&#20837;&#12289;&#25552;&#31034;&#21644;&#36755;&#20986;&#36827;&#34892;&#20102;&#20998;&#31867;&#21644;&#25506;&#32034;&#65292;&#27599;&#31181;&#26041;&#27861;&#30456;&#23545;&#20110;&#27809;&#26377;&#27491;&#21017;&#21270;&#30340;&#27169;&#22411;&#22343;&#25552;&#20379;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16200v1 Announce Type: cross  Abstract: Effective information retrieval (IR) in settings with limited training data, particularly for complex queries, remains a challenging task. This paper introduces IR2, Information Regularization for Information Retrieval, a technique for reducing overfitting during synthetic data generation. This approach, representing a novel application of regularization techniques in synthetic data creation for IR, is tested on three recent IR tasks characterized by complex queries: DORIS-MAE, ArguAna, and WhatsThatBook. Experimental results indicate that our regularization techniques not only outperform previous synthetic query generation methods on the tasks considered but also reduce cost by up to 50%. Furthermore, this paper categorizes and explores three regularization methods at different stages of the query synthesis pipeline-input, prompt, and output-each offering varying degrees of performance improvement compared to models where no regulariz
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#32431;&#35821;&#35328;&#25688;&#35201;&#30340;&#25351;&#26631;&#27979;&#35797;&#24179;&#21488;APPLS&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25351;&#26631;POMME&#26469;&#35780;&#20272;PLS&#20013;&#30340;&#25991;&#26412;&#31616;&#21270;&#12290;&#36890;&#36807;&#23545;&#25351;&#26631;&#30340;&#20998;&#26512;&#21457;&#29616;&#65292;&#24403;&#21069;&#30340;&#25351;&#26631;&#26410;&#33021;&#22987;&#32456;&#25429;&#25417;&#21040;&#31616;&#21270;&#24230;&#12290;</title><link>https://arxiv.org/abs/2305.14341</link><description>&lt;p&gt;
APPLS: &#35780;&#20272;&#32431;&#35821;&#35328;&#25688;&#35201;&#30340;&#35780;&#20215;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
APPLS: Evaluating Evaluation Metrics for Plain Language Summarization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2305.14341
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#32431;&#35821;&#35328;&#25688;&#35201;&#30340;&#25351;&#26631;&#27979;&#35797;&#24179;&#21488;APPLS&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25351;&#26631;POMME&#26469;&#35780;&#20272;PLS&#20013;&#30340;&#25991;&#26412;&#31616;&#21270;&#12290;&#36890;&#36807;&#23545;&#25351;&#26631;&#30340;&#20998;&#26512;&#21457;&#29616;&#65292;&#24403;&#21069;&#30340;&#25351;&#26631;&#26410;&#33021;&#22987;&#32456;&#25429;&#25417;&#21040;&#31616;&#21270;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#23545;&#20110;&#32431;&#35821;&#35328;&#25688;&#35201;&#65288;PLS&#65289;&#30340;&#27169;&#22411;&#26377;&#20102;&#24456;&#22823;&#30340;&#21457;&#23637;&#65292;&#20294;&#35780;&#20272;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;PLS&#32570;&#20047;&#19987;&#38376;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#30001;&#20110;&#28041;&#21450;&#21040;&#29420;&#29305;&#30340;&#36716;&#25442;&#65288;&#20363;&#22914;&#65292;&#28155;&#21152;&#32972;&#26223;&#35299;&#37322;&#65292;&#21024;&#38500;&#19987;&#19994;&#26415;&#35821;&#65289;&#65292;&#22240;&#27492;&#23545;&#20110;&#25991;&#26412;&#29983;&#25104;&#35780;&#20272;&#25351;&#26631;&#30340;&#36866;&#29992;&#24615;&#23578;&#19981;&#28165;&#26970;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32454;&#33268;&#30340;&#20803;&#35780;&#20272;&#27979;&#35797;&#24179;&#21488;APPLS&#65292;&#26088;&#22312;&#35780;&#20272;PLS&#30340;&#25351;&#26631;&#12290;&#25105;&#20204;&#26681;&#25454;&#20808;&#21069;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#23450;&#20041;&#20102;&#22235;&#20010;&#26631;&#20934;&#19978;&#30340;&#19968;&#32452;&#25200;&#21160;&#65292;PLS&#25351;&#26631;&#24212;&#35813;&#25429;&#25417;&#21040;&#65306;&#20449;&#24687;&#24615;&#12289;&#31616;&#21270;&#24230;&#12289;&#36830;&#36143;&#24615;&#21644;&#24544;&#23454;&#24230;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#27979;&#35797;&#24179;&#21488;&#23545;&#25351;&#26631;&#36827;&#34892;&#20998;&#26512;&#21457;&#29616;&#65292;&#24403;&#21069;&#30340;&#25351;&#26631;&#26410;&#33021;&#22987;&#32456;&#25429;&#25417;&#21040;&#31616;&#21270;&#24230;&#12290;&#20316;&#20026;&#22238;&#24212;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25351;&#26631;POMME&#65292;&#26088;&#22312;&#35780;&#20272;PLS&#20013;&#25991;&#26412;&#31616;&#21270;&#65307;&#35813;&#25351;&#26631;&#26159;&#26681;&#25454;&#22495;&#20869;&#21644;&#22495;&#22806;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#26631;&#20934;&#21270;&#22256;&#24785;&#24230;&#24046;&#35745;&#31639;&#24471;&#21040;&#30340;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;POMME&#30340;&#25928;&#26524;&#65292;&#24182;&#19982;&#20854;&#20182;&#25351;&#26631;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
While there has been significant development of models for Plain Language Summarization (PLS), evaluation remains a challenge. PLS lacks a dedicated assessment metric, and the suitability of text generation evaluation metrics is unclear due to the unique transformations involved (e.g., adding background explanations, removing specialized terminology). To address these concerns, our study presents a granular meta-evaluation testbed, APPLS, designed to evaluate metrics for PLS. We define a set of perturbations along four criteria inspired by previous work that a PLS metric should capture: informativeness, simplification, coherence, and faithfulness. An analysis of metrics using our testbed reveals that current metrics fail to capture simplification consistently. In response, we introduce POMME, a new metric designed to assess text simplification in PLS; the metric is calculated as the normalized perplexity difference between an in-domain and out-of-domain language model. We demonstrate P
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#23545;&#24615;&#21035;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#65292;&#24110;&#21161;&#20943;&#36731;&#20256;&#32479;&#31461;&#35805;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#21453;&#20107;&#23454;&#24615;&#21035;&#21051;&#26495;&#21360;&#35937;&#26469;&#20943;&#36731;&#23398;&#20064;&#21040;&#30340;&#20559;&#35265;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#23545;&#24615;&#21035;&#25200;&#21160;&#25935;&#24863;&#65292;&#20294;&#22312;&#21453;&#20107;&#23454;&#35757;&#32451;&#21518;&#23545;&#21518;&#32493;&#24341;&#20837;&#30340;&#21453;&#24615;&#21035;&#20559;&#35265;&#26356;&#19981;&#25935;&#24863;&#12290;</title><link>http://arxiv.org/abs/2310.10865</link><description>&lt;p&gt;
&#29579;&#23376;&#20250;&#24471;&#21040;&#30495;&#29233;&#20043;&#21563;&#21527;&#65311;&#20851;&#20110;&#31461;&#35805;&#25991;&#26412;&#20013;&#24615;&#21035;&#25200;&#21160;&#23545;&#27169;&#22411;&#25935;&#24863;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender Perturbation over Fairytale Texts. (arXiv:2310.10865v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10865
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#23545;&#24615;&#21035;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#65292;&#24110;&#21161;&#20943;&#36731;&#20256;&#32479;&#31461;&#35805;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#21453;&#20107;&#23454;&#24615;&#21035;&#21051;&#26495;&#21360;&#35937;&#26469;&#20943;&#36731;&#23398;&#20064;&#21040;&#30340;&#20559;&#35265;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#23545;&#24615;&#21035;&#25200;&#21160;&#25935;&#24863;&#65292;&#20294;&#22312;&#21453;&#20107;&#23454;&#35757;&#32451;&#21518;&#23545;&#21518;&#32493;&#24341;&#20837;&#30340;&#21453;&#24615;&#21035;&#20559;&#35265;&#26356;&#19981;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#26174;&#31034;&#65292;&#20256;&#32479;&#30340;&#31461;&#35805;&#25925;&#20107;&#20013;&#23384;&#22312;&#22823;&#37327;&#26377;&#23475;&#30340;&#24615;&#21035;&#20559;&#35265;&#12290;&#20026;&#20102;&#20943;&#36731;&#31461;&#35805;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#65292;&#26412;&#30740;&#31350;&#26088;&#22312;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#21040;&#30340;&#20559;&#35265;&#23545;&#24615;&#21035;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#31461;&#35805;&#25925;&#20107;&#20013;&#30340;&#38382;&#31572;&#20219;&#21153;&#12290;&#36890;&#36807;&#20351;&#29992;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;FairytaleQA&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35780;&#20272;&#27169;&#22411;&#23545;&#20132;&#25442;&#24615;&#21035;&#35282;&#33394;&#20449;&#24687;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#22312;&#35757;&#32451;&#26102;&#24341;&#20837;&#21453;&#20107;&#23454;&#24615;&#21035;&#21051;&#26495;&#21360;&#35937;&#26469;&#20943;&#36731;&#23398;&#20064;&#21040;&#30340;&#20559;&#35265;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#24222;&#22823;&#35789;&#27719;&#37327;&#26469;&#25903;&#25345;&#36229;&#36234;&#31461;&#35805;&#25925;&#20107;&#30340;&#25991;&#26412;&#31867;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#27169;&#22411;&#23545;&#24615;&#21035;&#25200;&#21160;&#25935;&#24863;&#65292;&#24615;&#33021;&#19982;&#21407;&#22987;&#27979;&#35797;&#38598;&#30456;&#27604;&#26174;&#33879;&#19979;&#38477;&#12290;&#28982;&#32780;&#65292;&#24403;&#39318;&#20808;&#22312;&#21453;&#20107;&#23454;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#21518;&#65292;&#27169;&#22411;&#23545;&#21518;&#32493;&#24341;&#20837;&#30340;&#21453;&#24615;&#21035;&#20559;&#35265;&#26356;&#19981;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies show that traditional fairytales are rife with harmful gender biases. To help mitigate these gender biases in fairytales, this work aims to assess learned biases of language models by evaluating their robustness against gender perturbations. Specifically, we focus on Question Answering (QA) tasks in fairytales. Using counterfactual data augmentation to the FairytaleQA dataset, we evaluate model robustness against swapped gender character information, and then mitigate learned biases by introducing counterfactual gender stereotypes during training time. We additionally introduce a novel approach that utilizes the massive vocabulary of language models to support text genres beyond fairytales. Our experimental results suggest that models are sensitive to gender perturbations, with significant performance drops compared to the original testing set. However, when first fine-tuned on a counterfactual training dataset, models are less sensitive to the later introduced anti-gend
&lt;/p&gt;</description></item></channel></rss>