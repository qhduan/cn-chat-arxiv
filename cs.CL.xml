<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27979;&#35797;&#26694;&#26550;&#65292;&#29992;&#20110;&#39640;&#25928;&#27979;&#37327;&#35821;&#35328;&#27169;&#22411;&#30340;&#35748;&#30693;&#33021;&#21147;&#12290;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#27979;&#35797;&#38382;&#39064;&#30340;&#29305;&#24615;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#24182;&#20351;&#29992;&#26356;&#23569;&#30340;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#35813;&#26694;&#26550;&#20351;&#24471;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#19982;&#20154;&#31867;&#36827;&#34892;&#36731;&#26494;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2306.10512</link><description>&lt;p&gt;
&#39640;&#25928;&#27979;&#37327;&#35821;&#35328;&#27169;&#22411;&#30340;&#35748;&#30693;&#33021;&#21147;&#65306;&#33258;&#36866;&#24212;&#27979;&#35797;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective. (arXiv:2306.10512v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10512
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#27979;&#35797;&#26694;&#26550;&#65292;&#29992;&#20110;&#39640;&#25928;&#27979;&#37327;&#35821;&#35328;&#27169;&#22411;&#30340;&#35748;&#30693;&#33021;&#21147;&#12290;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#27979;&#35797;&#38382;&#39064;&#30340;&#29305;&#24615;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#24182;&#20351;&#29992;&#26356;&#23569;&#30340;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#35813;&#26694;&#26550;&#20351;&#24471;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#19982;&#20154;&#31867;&#36827;&#34892;&#36731;&#26494;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#65292;&#23637;&#29616;&#20102;&#19968;&#20123;&#31867;&#20284;&#20110;&#20154;&#31867;&#30340;&#35748;&#30693;&#33021;&#21147;&#12290;&#20026;&#20102;&#27604;&#36739;&#19981;&#21516;&#27169;&#22411;&#30340;&#36825;&#20123;&#33021;&#21147;&#65292;&#36890;&#24120;&#37319;&#29992;&#26469;&#33258;&#19981;&#21516;&#39046;&#22495;&#65288;&#22914;&#25991;&#23398;&#12289;&#29983;&#29289;&#23398;&#21644;&#24515;&#29702;&#23398;&#65289;&#30340;&#22810;&#20010;&#22522;&#20934;&#65288;&#21363;&#26631;&#20934;&#27979;&#35797;&#38382;&#39064;&#38598;&#65289;&#65292;&#24182;&#25253;&#21578;&#20256;&#32479;&#24230;&#37327;&#25351;&#26631;&#65288;&#22914;&#20934;&#30830;&#29575;&#12289;&#21484;&#22238;&#29575;&#21644;F1&#65289;&#12290;&#28982;&#32780;&#65292;&#20174;&#35748;&#30693;&#31185;&#23398;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#35780;&#20272;LLMs&#30340;&#26041;&#27861;&#21487;&#33021;&#25928;&#29575;&#20302;&#19979;&#19988;&#19981;&#20934;&#30830;&#12290;&#21463;&#24515;&#29702;&#27979;&#37327;&#23398;&#20013;&#35745;&#31639;&#26426;&#33258;&#36866;&#24212;&#27979;&#35797;&#65288;CAT&#65289;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;LLM&#35780;&#20272;&#30340;&#33258;&#36866;&#24212;&#27979;&#35797;&#26694;&#26550;&#12290;&#35813;&#26041;&#27861;&#26681;&#25454;&#27169;&#22411;&#30340;&#34920;&#29616;&#21160;&#24577;&#35843;&#25972;&#27979;&#35797;&#38382;&#39064;&#30340;&#29305;&#24615;&#65288;&#22914;&#38590;&#24230;&#65289;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#26631;&#20934;&#30340;&#27979;&#35797;&#38598;&#24182;&#31616;&#21333;&#25253;&#21578;&#20934;&#30830;&#29575;&#12290;&#36825;&#20351;&#24471;&#33021;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#24182;&#20351;&#29992;&#26356;&#23569;&#30340;&#38382;&#39064;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#23427;&#20351;LLMs&#33021;&#22815;&#19982;&#20154;&#31867;&#36827;&#34892;&#36731;&#26494;&#27604;&#36739;&#65292;&#36825;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs), like ChatGPT, have shown some human-like cognitive abilities. For comparing these abilities of different models, several benchmarks (i.e. sets of standard test questions) from different fields (e.g., Literature, Biology and Psychology) are often adopted and the test results under traditional metrics such as accuracy, recall and F1, are reported. However, such way for evaluating LLMs can be inefficient and inaccurate from the cognitive science perspective. Inspired by Computerized Adaptive Testing (CAT) used in psychometrics, we propose an adaptive testing framework for LLM evaluation. Rather than using a standard test set and simply reporting accuracy, this approach dynamically adjusts the characteristics of the test questions, such as difficulty, based on the model's performance. This allows for a more accurate estimation of the model's abilities, using fewer questions. More importantly, it allows LLMs to be compared with humans easily, which is essential
&lt;/p&gt;</description></item></channel></rss>