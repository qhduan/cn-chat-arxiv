<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#37325;&#26032;&#24605;&#32771;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#20013;&#23545;Kullback-Leibler&#25955;&#24230;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#36870;Kullback-Leibler&#21644;&#27491;&#21521;Kullback-Leibler&#25955;&#24230;&#22312;&#20248;&#21270;&#30446;&#26631;&#19978;&#30456;&#20284;&#65292;&#20026;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;Kullback-Leiber&#25955;&#24230;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.02657</link><description>&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#20013;&#37325;&#26032;&#24605;&#32771;Kullback-Leibler&#25955;&#24230;
&lt;/p&gt;
&lt;p&gt;
Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#26032;&#24605;&#32771;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;&#20013;&#23545;Kullback-Leibler&#25955;&#24230;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#36870;Kullback-Leibler&#21644;&#27491;&#21521;Kullback-Leibler&#25955;&#24230;&#22312;&#20248;&#21270;&#30446;&#26631;&#19978;&#30456;&#20284;&#65292;&#20026;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;Kullback-Leiber&#25955;&#24230;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kullback-Leibler&#25955;&#24230;&#22312;&#30693;&#35782;&#33976;&#39311;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21387;&#32553;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#26412;&#30740;&#31350;&#20174;&#32463;&#39564;&#21644;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#65292;&#22312;LLMs&#30340;&#30693;&#35782;&#33976;&#39311;&#20013;&#65292;&#19982;&#20043;&#21069;&#26029;&#35328;&#30340;&#36870;Kullback-Leibler&#65288;RKL&#65289;&#25955;&#24230;&#23547;&#25214;&#27169;&#24335;&#24182;&#22240;&#27492;&#20248;&#20110;&#23547;&#25214;&#24179;&#22343;&#20540;&#30340;&#27491;&#21521;Kullback-Leibler&#65288;FKL&#65289;&#25955;&#24230;&#30456;&#21453;&#65292;&#23454;&#38469;&#19978;&#22312;&#30693;&#35782;&#33976;&#39311;&#20013;&#37117;&#27809;&#26377;&#20307;&#29616;&#20986;&#23547;&#25214;&#27169;&#24335;&#25110;&#23547;&#25214;&#24179;&#22343;&#20540;&#30340;&#29305;&#24615;&#12290;&#30456;&#21453;&#65292;&#21457;&#29616;RKL&#21644;FKL&#20855;&#26377;&#30456;&#21516;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#24182;&#22312;&#36275;&#22815;&#25968;&#37327;&#30340;&#26102;&#20195;&#20043;&#21518;&#37117;&#20250;&#25910;&#25947;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23454;&#38469;&#32422;&#26463;&#65292;LLMs&#24456;&#23569;&#34987;&#35757;&#32451;&#22914;&#27492;&#22810;&#30340;&#26102;&#20195;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#65292;RKL&#22312;&#20998;&#24067;&#30340;&#23614;&#37096;&#65292;&#32780;FKL&#22312;&#24320;&#22987;&#26102;&#20195;&#20391;&#37325;&#20110;&#20998;&#24067;&#30340;&#22836;&#37096;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#33258;&#36866;&#24212;Kullback-Leiber&#65288;AKL&#65289;&#25955;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33258;&#36866;&#24212;&#22320;&#20998;&#37197;&#26435;&#37325;&#26469;&#32452;&#21512;F
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02657v1 Announce Type: cross  Abstract: Kullback-Leiber divergence has been widely used in Knowledge Distillation (KD) to compress Large Language Models (LLMs). Contrary to prior assertions that reverse Kullback-Leibler (RKL) divergence is mode-seeking and thus preferable over the mean-seeking forward Kullback-Leibler (FKL) divergence, this study empirically and theoretically demonstrates that neither mode-seeking nor mean-seeking properties manifest in KD for LLMs. Instead, RKL and FKL are found to share the same optimization objective and both converge after a sufficient number of epochs. However, due to practical constraints, LLMs are seldom trained for such an extensive number of epochs. Meanwhile, we further find that RKL focuses on the tail part of the distributions, while FKL focuses on the head part at the beginning epochs. Consequently, we propose a simple yet effective Adaptive Kullback-Leiber (AKL) divergence method, which adaptively allocates weights to combine F
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23545;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#28145;&#20837;&#35752;&#35770;&#20102;&#20851;&#38190;&#38382;&#39064;&#65292;&#21253;&#25324;&#22810;&#35821;&#35328;&#35821;&#26009;&#24211;&#12289;&#23545;&#40784;&#21644;&#20559;&#35265;&#12290;</title><link>https://arxiv.org/abs/2404.00929</link><description>&lt;p&gt;
&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#35821;&#26009;&#24211;&#12289;&#23545;&#40784;&#21644;&#20559;&#35265;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00929
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23545;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#28145;&#20837;&#35752;&#35770;&#20102;&#20851;&#38190;&#38382;&#39064;&#65292;&#21253;&#25324;&#22810;&#35821;&#35328;&#35821;&#26009;&#24211;&#12289;&#23545;&#40784;&#21644;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#21457;&#23637;&#20102;&#22810;&#35821;&#35328;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLMs&#65289;&#26469;&#35299;&#20915;&#22810;&#35821;&#35328;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#25361;&#25112;&#65292;&#24076;&#26395;&#23454;&#29616;&#20174;&#39640;&#36164;&#28304;&#21040;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;&#30693;&#35782;&#36716;&#31227;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#37325;&#35201;&#38480;&#21046;&#21644;&#25361;&#25112;&#65292;&#27604;&#22914;&#35821;&#35328;&#19981;&#24179;&#34913;&#12289;&#22810;&#35821;&#35328;&#23545;&#40784;&#21644;&#22266;&#26377;&#20559;&#35265;&#12290;&#26412;&#25991;&#26088;&#22312;&#23545;MLLMs&#36827;&#34892;&#20840;&#38754;&#20998;&#26512;&#65292;&#28145;&#20837;&#35752;&#35770;&#22260;&#32469;&#36825;&#20123;&#20851;&#38190;&#38382;&#39064;&#30340;&#35758;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00929v1 Announce Type: cross  Abstract: Based on the foundation of Large Language Models (LLMs), Multilingual Large Language Models (MLLMs) have been developed to address the challenges of multilingual natural language processing tasks, hoping to achieve knowledge transfer from high-resource to low-resource languages. However, significant limitations and challenges still exist, such as language imbalance, multilingual alignment, and inherent bias. In this paper, we aim to provide a comprehensive analysis of MLLMs, delving deeply into discussions surrounding these critical issues. First of all, we start by presenting an overview of MLLMs, covering their evolution, key techniques, and multilingual capacities. Secondly, we explore widely utilized multilingual corpora for MLLMs' training and multilingual datasets oriented for downstream tasks that are crucial for enhancing the cross-lingual capability of MLLMs. Thirdly, we survey the existing studies on multilingual representati
&lt;/p&gt;</description></item><item><title>PRISM&#26159;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21487;&#35299;&#37322;&#19988;&#26131;&#20256;&#36882;&#30340;&#25552;&#31034;&#65292;&#20174;&#32780;&#26377;&#25928;&#29983;&#25104;&#25152;&#38656;&#27010;&#24565;&#65292;&#20165;&#20351;&#29992;&#40657;&#30418;&#35775;&#38382;T2I&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.19103</link><description>&lt;p&gt;
&#29992;&#20110;&#20010;&#24615;&#21270;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#30340;&#33258;&#21160;&#21270;&#40657;&#30418;&#25552;&#31034;&#24037;&#31243;
&lt;/p&gt;
&lt;p&gt;
Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19103
&lt;/p&gt;
&lt;p&gt;
PRISM&#26159;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21487;&#35299;&#37322;&#19988;&#26131;&#20256;&#36882;&#30340;&#25552;&#31034;&#65292;&#20174;&#32780;&#26377;&#25928;&#29983;&#25104;&#25152;&#38656;&#27010;&#24565;&#65292;&#20165;&#20351;&#29992;&#40657;&#30418;&#35775;&#38382;T2I&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#31034;&#24037;&#31243;&#23545;&#20110;&#25511;&#21046;&#25991;&#26412;&#21040;&#22270;&#20687;&#65288;T2I&#65289;&#29983;&#25104;&#27169;&#22411;&#30340;&#36755;&#20986;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#30001;&#20110;&#38656;&#35201;&#25163;&#21160;&#21046;&#20316;&#25552;&#31034;&#32780;&#23548;&#33268;&#24037;&#20316;&#32321;&#37325;&#12290;&#36825;&#19968;&#25361;&#25112;&#20419;&#20351;&#20102;&#33258;&#21160;&#25552;&#31034;&#29983;&#25104;&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#22312;T2I&#27169;&#22411;&#20043;&#38388;&#30340;&#21487;&#20256;&#36882;&#24615;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#65292;&#38656;&#35201;&#23545;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#30333;&#30418;&#35775;&#38382;&#65292;&#24182;&#20135;&#29983;&#38750;&#30452;&#35266;&#30340;&#25552;&#31034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;PRISM&#65292;&#36825;&#26159;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#20165;&#20351;&#29992;&#40657;&#30418;&#35775;&#38382;T2I&#27169;&#22411;&#23601;&#33258;&#21160;&#35782;&#21035;&#20154;&#31867;&#21487;&#35299;&#37322;&#19988;&#26131;&#20256;&#36882;&#30340;&#25552;&#31034;&#65292;&#20174;&#32780;&#26377;&#25928;&#29983;&#25104;&#25152;&#38656;&#27010;&#24565;&#12290;&#21463;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36234;&#29425;&#30340;&#21551;&#21457;&#65292;PRISM&#21033;&#29992;LLM&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#26469;&#36845;&#20195;&#22320;&#25913;&#36827;&#32473;&#23450;&#21442;&#32771;&#22270;&#20687;&#30340;&#20505;&#36873;&#25552;&#31034;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;PRISM&#22312;&#20026;&#23545;&#35937;&#12289;&#26679;&#24335;&#31561;&#29983;&#25104;&#20934;&#30830;&#25552;&#31034;&#26041;&#38754;&#30340;&#22810;&#26679;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19103v1 Announce Type: cross  Abstract: Prompt engineering is effective for controlling the output of text-to-image (T2I) generative models, but it is also laborious due to the need for manually crafted prompts. This challenge has spurred the development of algorithms for automated prompt generation. However, these methods often struggle with transferability across T2I models, require white-box access to the underlying model, and produce non-intuitive prompts. In this work, we introduce PRISM, an algorithm that automatically identifies human-interpretable and transferable prompts that can effectively generate desired concepts given only black-box access to T2I models. Inspired by large language model (LLM) jailbreaking, PRISM leverages the in-context learning ability of LLMs to iteratively refine the candidate prompts distribution for given reference images. Our experiments demonstrate the versatility and effectiveness of PRISM in generating accurate prompts for objects, sty
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#26159;&#20855;&#26377;&#19968;&#23450;&#28508;&#21147;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.16851</link><description>&lt;p&gt;
ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can ChatGPT predict article retraction based on Twitter mentions?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ChatGPT&#26159;&#21542;&#33021;&#22815;&#22522;&#20110;Twitter&#25552;&#21450;&#26469;&#39044;&#27979;&#25991;&#31456;&#30340;&#25764;&#22238;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#26159;&#20855;&#26377;&#19968;&#23450;&#28508;&#21147;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#26377;&#38382;&#39064;&#30340;&#30740;&#31350;&#25991;&#31456;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26681;&#25454;&#34987;&#25764;&#22238;&#25991;&#31456;&#22312;Twitter&#19978;&#30340;&#25552;&#21450;&#26159;&#21542;&#33021;&#22815;&#22312;&#25991;&#31456;&#34987;&#25764;&#22238;&#21069;&#21457;&#20986;&#20449;&#21495;&#65292;&#20174;&#32780;&#22312;&#39044;&#27979;&#26410;&#26469;&#34987;&#25764;&#22238;&#30340;&#26377;&#38382;&#39064;&#25991;&#31456;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;&#20998;&#26512;&#20102;&#21253;&#25324;3,505&#31687;&#24050;&#25764;&#22238;&#25991;&#31456;&#21450;&#20854;&#30456;&#20851;Twitter&#25552;&#21450;&#22312;&#20869;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#20351;&#29992;&#31895;&#31961;&#31934;&#30830;&#21305;&#37197;&#26041;&#27861;&#33719;&#21462;&#30340;&#20855;&#26377;&#31867;&#20284;&#29305;&#24449;&#30340;3,505&#31687;&#26410;&#25764;&#22238;&#25991;&#31456;&#12290;&#36890;&#36807;&#22235;&#31181;&#39044;&#27979;&#26041;&#27861;&#35780;&#20272;&#20102;Twitter&#25552;&#21450;&#22312;&#39044;&#27979;&#25991;&#31456;&#25764;&#22238;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#25163;&#21160;&#26631;&#27880;&#12289;&#20851;&#38190;&#35789;&#35782;&#21035;&#12289;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;ChatGPT&#12290;&#25163;&#21160;&#26631;&#27880;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#30340;&#30830;&#26377;&#34987;&#25764;&#22238;&#30340;&#25991;&#31456;&#65292;&#20854;Twitter&#25552;&#21450;&#21253;&#21547;&#22312;&#25764;&#22238;&#21069;&#21457;&#20986;&#20449;&#21495;&#30340;&#21487;&#35782;&#21035;&#35777;&#25454;&#65292;&#23613;&#31649;&#23427;&#20204;&#21482;&#21344;&#25152;&#26377;&#34987;&#25764;&#22238;&#25991;&#31456;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16851v1 Announce Type: cross  Abstract: Detecting problematic research articles timely is a vital task. This study explores whether Twitter mentions of retracted articles can signal potential problems with the articles prior to retraction, thereby playing a role in predicting future retraction of problematic articles. A dataset comprising 3,505 retracted articles and their associated Twitter mentions is analyzed, alongside 3,505 non-retracted articles with similar characteristics obtained using the Coarsened Exact Matching method. The effectiveness of Twitter mentions in predicting article retraction is evaluated by four prediction methods, including manual labelling, keyword identification, machine learning models, and ChatGPT. Manual labelling results indicate that there are indeed retracted articles with their Twitter mentions containing recognizable evidence signaling problems before retraction, although they represent only a limited share of all retracted articles with 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;CLIP&#30340;&#33258;&#30417;&#30563;&#26041;&#27861;QualiCLIP&#65292;&#36890;&#36807;&#36136;&#37327;&#24863;&#30693;&#30340;&#22270;&#20687;-&#25991;&#26412;&#23545;&#40784;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#19981;&#38656;&#35201;&#26631;&#35760;MOS&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.11176</link><description>&lt;p&gt;
&#38754;&#21521;&#29616;&#23454;&#19990;&#30028;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#30340;&#36136;&#37327;&#24863;&#30693;&#22270;&#20687;-&#25991;&#26412;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Quality-Aware Image-Text Alignment for Real-World Image Quality Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11176
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;CLIP&#30340;&#33258;&#30417;&#30563;&#26041;&#27861;QualiCLIP&#65292;&#36890;&#36807;&#36136;&#37327;&#24863;&#30693;&#30340;&#22270;&#20687;-&#25991;&#26412;&#23545;&#40784;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#19981;&#38656;&#35201;&#26631;&#35760;MOS&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#21442;&#32771;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#65288;NR-IQA&#65289;&#33268;&#21147;&#20110;&#35774;&#35745;&#19968;&#31181;&#22312;&#27809;&#26377;&#39640;&#36136;&#37327;&#21442;&#32771;&#22270;&#20687;&#30340;&#24773;&#20917;&#19979;&#27979;&#37327;&#22270;&#20687;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20197;&#31526;&#21512;&#20154;&#31867;&#24863;&#30693;&#65292;&#22823;&#37096;&#20998;&#26368;&#20808;&#36827;&#30340;NR-IQA&#26041;&#27861;&#20013;&#20381;&#36182;&#26631;&#27880;&#30340;&#20027;&#35266;&#35780;&#20998;&#65288;MOS&#65289;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;QualiCLIP&#65288;Quality-aware CLIP&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;CLIP&#30340;&#33258;&#30417;&#30563;&#19981;&#38656;&#35201;&#26631;&#35760;MOS&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#36136;&#37327;&#24863;&#30693;&#30340;&#22270;&#20687;-&#25991;&#26412;&#23545;&#40784;&#31574;&#30053;&#65292;&#20351;&#24471;CLIP&#29983;&#25104;&#30340;&#34920;&#31034;&#19982;&#22270;&#20687;&#22266;&#26377;&#36136;&#37327;&#30456;&#20851;&#12290;&#20174;&#21407;&#22987;&#22270;&#20687;&#24320;&#22987;&#65292;&#25105;&#20204;&#20351;&#29992;&#19981;&#26029;&#22686;&#21152;&#30340;&#24378;&#24230;&#21512;&#25104;&#22320;&#21155;&#21270;&#23427;&#20204;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35757;&#32451;CLIP&#26681;&#25454;&#20854;&#19982;&#36136;&#37327;&#30456;&#20851;&#30340;&#21453;&#20041;&#25991;&#26412;&#25552;&#31034;&#30340;&#30456;&#20284;&#24615;&#23545;&#36825;&#20123;&#38477;&#35299;&#22270;&#20687;&#36827;&#34892;&#25490;&#21517;&#65292;&#21516;&#26102;&#20445;&#35777;&#19968;&#33268;&#30340;&#34920;&#36798;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11176v1 Announce Type: cross  Abstract: No-Reference Image Quality Assessment (NR-IQA) focuses on designing methods to measure image quality in alignment with human perception when a high-quality reference image is unavailable. The reliance on annotated Mean Opinion Scores (MOS) in the majority of state-of-the-art NR-IQA approaches limits their scalability and broader applicability to real-world scenarios. To overcome this limitation, we propose QualiCLIP (Quality-aware CLIP), a CLIP-based self-supervised opinion-unaware method that does not require labeled MOS. In particular, we introduce a quality-aware image-text alignment strategy to make CLIP generate representations that correlate with the inherent quality of the images. Starting from pristine images, we synthetically degrade them with increasing levels of intensity. Then, we train CLIP to rank these degraded images based on their similarity to quality-related antonym text prompts, while guaranteeing consistent represe
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#22522;&#20934;&#65288;SRB&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#27169;&#22411;&#23545;&#21508;&#31181;&#30772;&#22351;&#30340;&#40065;&#26834;&#24615;&#65292;&#21457;&#29616;&#27169;&#22411;&#22823;&#23567;&#21644;&#26576;&#20123;&#24314;&#27169;&#36873;&#25321;&#26377;&#21161;&#20110;&#25552;&#39640;&#40065;&#26834;&#24615;&#65292;&#24182;&#35266;&#23519;&#21040;&#22312;&#19981;&#21516;&#20154;&#21475;&#20122;&#32452;&#19978;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#23384;&#22312;&#26126;&#26174;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2403.07937</link><description>&lt;p&gt;
&#35821;&#38899;&#40065;&#26834;&#22522;&#20934;&#65306;&#29992;&#20110;&#35821;&#38899;&#35782;&#21035;&#30340;&#40065;&#26834;&#24615;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Speech Robust Bench: A Robustness Benchmark For Speech Recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07937
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#22522;&#20934;&#65288;SRB&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#27169;&#22411;&#23545;&#21508;&#31181;&#30772;&#22351;&#30340;&#40065;&#26834;&#24615;&#65292;&#21457;&#29616;&#27169;&#22411;&#22823;&#23567;&#21644;&#26576;&#20123;&#24314;&#27169;&#36873;&#25321;&#26377;&#21161;&#20110;&#25552;&#39640;&#40065;&#26834;&#24615;&#65292;&#24182;&#35266;&#23519;&#21040;&#22312;&#19981;&#21516;&#20154;&#21475;&#20122;&#32452;&#19978;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#23384;&#22312;&#26126;&#26174;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#27169;&#22411;&#21464;&#24471;&#36234;&#26469;&#36234;&#26222;&#36941;&#65292;&#30830;&#20445;&#23427;&#20204;&#22312;&#29289;&#29702;&#19990;&#30028;&#21644;&#25968;&#23383;&#19990;&#30028;&#20013;&#30340;&#21508;&#31181;&#30772;&#22351;&#19979;&#36827;&#34892;&#21487;&#38752;&#39044;&#27979;&#21464;&#24471;&#24840;&#21457;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35821;&#38899;&#40065;&#26834;&#22522;&#20934;&#65288;SRB&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;ASR&#27169;&#22411;&#23545;&#21508;&#31181;&#30772;&#22351;&#30340;&#40065;&#26834;&#24615;&#30340;&#20840;&#38754;&#22522;&#20934;&#12290;SRB&#30001;69&#20010;&#36755;&#20837;&#25200;&#21160;&#32452;&#25104;&#65292;&#26088;&#22312;&#27169;&#25311;ASR&#27169;&#22411;&#21487;&#33021;&#22312;&#29289;&#29702;&#19990;&#30028;&#21644;&#25968;&#23383;&#19990;&#30028;&#20013;&#36935;&#21040;&#30340;&#21508;&#31181;&#30772;&#22351;&#12290;&#25105;&#20204;&#20351;&#29992;SRB&#26469;&#35780;&#20272;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;ASR&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#35266;&#23519;&#21040;&#27169;&#22411;&#22823;&#23567;&#21644;&#26576;&#20123;&#24314;&#27169;&#36873;&#25321;&#65288;&#22914;&#31163;&#25955;&#34920;&#31034;&#21644;&#33258;&#25105;&#35757;&#32451;&#65289;&#20284;&#20046;&#26377;&#21161;&#20110;&#25552;&#39640;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#23558;&#27492;&#20998;&#26512;&#25193;&#23637;&#21040;&#34913;&#37327;ASR&#27169;&#22411;&#22312;&#26469;&#33258;&#21508;&#31181;&#20154;&#21475;&#20122;&#32452;&#30340;&#25968;&#25454;&#19978;&#30340;&#40065;&#26834;&#24615;&#65292;&#21363;&#33521;&#35821;&#21644;&#35199;&#29677;&#29273;&#35821;&#20351;&#29992;&#32773;&#20197;&#21450;&#30007;&#24615;&#21644;&#22899;&#24615;&#65292;&#24182;&#35266;&#23519;&#21040;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#22312;&#19981;&#21516;&#20122;&#32452;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07937v1 Announce Type: cross  Abstract: As Automatic Speech Recognition (ASR) models become ever more pervasive, it is important to ensure that they make reliable predictions under corruptions present in the physical and digital world. We propose Speech Robust Bench (SRB), a comprehensive benchmark for evaluating the robustness of ASR models to diverse corruptions. SRB is composed of 69 input perturbations which are intended to simulate various corruptions that ASR models may encounter in the physical and digital world. We use SRB to evaluate the robustness of several state-of-the-art ASR models and observe that model size and certain modeling choices such as discrete representations, and self-training appear to be conducive to robustness. We extend this analysis to measure the robustness of ASR models on data from various demographic subgroups, namely English and Spanish speakers, and males and females, and observed noticeable disparities in the model's robustness across su
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#20581;&#24247;&#20445;&#20581;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;</title><link>https://arxiv.org/abs/2403.05720</link><description>&lt;p&gt;
&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05720
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#29992;&#20110;&#29983;&#25104;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#25688;&#35201;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#20581;&#24247;&#20445;&#20581;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#65288;BHC&#65289;&#25688;&#35201;&#26159;&#36890;&#36807;&#24635;&#32467;&#20020;&#24202;&#35760;&#24405;&#32780;&#29983;&#25104;&#30340;&#24120;&#35265;&#20020;&#24202;&#25991;&#20214;&#12290;&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#21160;&#21270;&#23454;&#38469;&#20219;&#21153;&#26041;&#38754;&#23637;&#29616;&#20986;&#26174;&#33879;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;&#21307;&#30103;&#24212;&#29992;&#65288;&#22914;BHC&#21512;&#25104;&#65289;&#20013;&#30340;&#33021;&#21147;&#23578;&#26410;&#24471;&#21040;&#23637;&#31034;&#12290;&#20026;&#20102;&#20351;LLMs&#33021;&#22815;&#36866;&#24212;BHC&#21512;&#25104;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#21547;&#20174;MIMIC-IV&#35760;&#24405;&#20013;&#25552;&#21462;&#30340;&#32463;&#36807;&#39044;&#22788;&#29702;&#30340;&#25968;&#25454;&#38598;&#65292;&#23553;&#35013;&#20102;&#20020;&#24202;&#35760;&#24405;&#21644;&#31616;&#35201;&#20303;&#38498;&#30149;&#31243;&#65288;BHC&#65289;&#23545;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20004;&#20010;&#36890;&#29992;LLMs&#21644;&#19977;&#20010;&#21307;&#30103;&#39046;&#22495;&#36866;&#24212;&#30340;LLMs&#30340;&#24615;&#33021;&#65292;&#20197;&#25913;&#36827;&#20174;&#20020;&#24202;&#35760;&#24405;&#29983;&#25104;BHC&#12290;&#25105;&#20204;&#20351;&#29992;&#20020;&#24202;&#35760;&#24405;&#20316;&#20026;&#36755;&#20837;&#26469;&#29983;&#25104;BHC&#65292;&#37319;&#29992;&#22522;&#20110;&#25552;&#31034;&#30340;&#65288;&#20351;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#65289;&#21644;&#22522;&#20110;&#24494;&#35843;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#26469;&#24212;&#29992;&#20110;&#19977;&#20010;&#24320;&#28304;LLMs&#65288;Clinical-T5-Large&#65292;Llama2-13B&#65292;FLAN-UL2&#65289;&#21644;&#20004;&#20010;&#19987;&#26377;LLMs&#65288;GPT-3.5&#65292;GPT-4&#65289;&#12290;&#25105;&#20204;&#23450;&#37327;&#35780;&#20272;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05720v1 Announce Type: cross  Abstract: Brief hospital course (BHC) summaries are common clinical documents generated by summarizing clinical notes. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as BHC synthesis have not been shown. To enable the adaptation of LLMs for BHC synthesis, we introduce a novel benchmark consisting of a pre-processed dataset extracted from MIMIC-IV notes, encapsulating clinical note, and brief hospital course (BHC) pairs. We assess the performance of two general-purpose LLMs and three healthcare-adapted LLMs to improve BHC synthesis from clinical notes. Using clinical notes as input for generating BHCs, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to three open-source LLMs (Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5, GPT-4). We quantitatively evaluate the performa
&lt;/p&gt;</description></item><item><title>KorMedMCQA&#26159;&#39318;&#20010;&#20174;&#38889;&#22269;&#21307;&#30103;&#19987;&#19994;&#25191;&#19994;&#32771;&#35797;&#20013;&#34893;&#29983;&#30340;&#22810;&#39033;&#36873;&#25321;&#39064;&#38382;&#31572;&#22522;&#20934;&#65292;&#25552;&#20379;&#20102;&#22810;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#32447;&#23454;&#39564;&#32467;&#26524;&#65292;&#24182;&#22312;HuggingFace&#19978;&#20844;&#24320;&#20102;&#25968;&#25454;&#65292;&#20026;&#38889;&#22269;&#21307;&#30103;&#29615;&#22659;&#20013;&#30340;&#36827;&#19968;&#27493;&#30740;&#31350;&#21644;&#21457;&#23637;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.01469</link><description>&lt;p&gt;
KorMedMCQA: &#38889;&#22269;&#21307;&#30103;&#19987;&#19994;&#25191;&#19994;&#32771;&#35797;&#30340;&#22810;&#39033;&#36873;&#25321;&#39064;&#38382;&#31572;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean Healthcare Professional Licensing Examinations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01469
&lt;/p&gt;
&lt;p&gt;
KorMedMCQA&#26159;&#39318;&#20010;&#20174;&#38889;&#22269;&#21307;&#30103;&#19987;&#19994;&#25191;&#19994;&#32771;&#35797;&#20013;&#34893;&#29983;&#30340;&#22810;&#39033;&#36873;&#25321;&#39064;&#38382;&#31572;&#22522;&#20934;&#65292;&#25552;&#20379;&#20102;&#22810;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#32447;&#23454;&#39564;&#32467;&#26524;&#65292;&#24182;&#22312;HuggingFace&#19978;&#20844;&#24320;&#20102;&#25968;&#25454;&#65292;&#20026;&#38889;&#22269;&#21307;&#30103;&#29615;&#22659;&#20013;&#30340;&#36827;&#19968;&#27493;&#30740;&#31350;&#21644;&#21457;&#23637;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;KorMedMCQA&#65292;&#36825;&#26159;&#39318;&#20010;&#28304;&#33258;&#38889;&#22269;&#21307;&#30103;&#19987;&#19994;&#25191;&#19994;&#32771;&#35797;&#30340;&#38889;&#35821;&#22810;&#39033;&#36873;&#25321;&#39064;&#38382;&#31572;&#65288;MCQA&#65289;&#22522;&#20934;&#65292;&#28085;&#30422;&#20102;&#20174;2012&#24180;&#21040;2023&#24180;&#30340;&#32771;&#35797;&#20869;&#23481;&#12290;&#35813;&#25968;&#25454;&#38598;&#21253;&#25324;&#21307;&#29983;&#12289;&#25252;&#22763;&#21644;&#33647;&#21058;&#24072;&#25191;&#29031;&#32771;&#35797;&#20013;&#30340;&#19968;&#37096;&#20998;&#38382;&#39064;&#65292;&#28085;&#30422;&#22810;&#31181;&#23398;&#31185;&#12290;&#25105;&#20204;&#23545;&#21508;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#32447;&#23454;&#39564;&#65292;&#21253;&#25324;&#19987;&#26377;/&#24320;&#28304;&#12289;&#22810;&#35821;&#35328;/&#38889;&#35821;&#38468;&#21152;&#39044;&#35757;&#32451;&#21644;&#20020;&#24202;&#32972;&#26223;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#31361;&#26174;&#20102;&#36827;&#19968;&#27493;&#22686;&#24378;&#28508;&#21147;&#12290;&#25105;&#20204;&#22312;HuggingFace&#19978;&#20844;&#24320;&#20102;&#25105;&#20204;&#30340;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;LM-Harness&#25552;&#20379;&#20102;&#19968;&#20010;&#35780;&#20272;&#33050;&#26412;&#65292;&#36992;&#35831;&#22312;&#38889;&#22269;&#21307;&#30103;&#29615;&#22659;&#20013;&#36827;&#34892;&#36827;&#19968;&#27493;&#25506;&#32034;&#21644;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01469v1 Announce Type: new  Abstract: We introduce KorMedMCQA, the first Korean multiple-choice question answering (MCQA) benchmark derived from Korean healthcare professional licensing examinations, covering from the year 2012 to year 2023. This dataset consists of a selection of questions from the license examinations for doctors, nurses, and pharmacists, featuring a diverse array of subjects. We conduct baseline experiments on various large language models, including proprietary/open-source, multilingual/Korean-additional pretrained, and clinical context pretrained models, highlighting the potential for further enhancements. We make our data publicly available on HuggingFace and provide a evaluation script via LM-Harness, inviting further exploration and advancement in Korean healthcare environments.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#30340;&#22810;&#31181;&#24212;&#29992;&#21450;&#20854;&#35282;&#33394;&#65292;&#25351;&#20986;&#20102;&#26410;&#24320;&#21457;&#39046;&#22495;&#21644;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.18659</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#28216;&#25103;&#65306;&#35843;&#30740;&#19982;&#36335;&#32447;&#22270;
&lt;/p&gt;
&lt;p&gt;
Large Language Models and Games: A Survey and Roadmap
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18659
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#30340;&#22810;&#31181;&#24212;&#29992;&#21450;&#20854;&#35282;&#33394;&#65292;&#25351;&#20986;&#20102;&#26410;&#24320;&#21457;&#39046;&#22495;&#21644;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#30740;&#31350;&#24613;&#21095;&#22686;&#21152;&#65292;&#24182;&#20276;&#38543;&#30528;&#20844;&#20247;&#23545;&#35813;&#20027;&#39064;&#30340;&#21442;&#19982;&#12290;&#23613;&#31649;&#36215;&#21021;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#19968;&#23567;&#37096;&#20998;&#65292;LLMs&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#21644;&#39046;&#22495;&#20013;&#23637;&#29616;&#20986;&#26174;&#33879;&#28508;&#21147;&#65292;&#21253;&#25324;&#28216;&#25103;&#12290;&#26412;&#25991;&#35843;&#26597;&#20102;LLMs&#22312;&#28216;&#25103;&#20013;&#21450;&#20026;&#28216;&#25103;&#25552;&#20379;&#25903;&#25345;&#30340;&#21508;&#31181;&#24212;&#29992;&#30340;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#65292;&#24182;&#26126;&#30830;&#20102;LLMs&#22312;&#28216;&#25103;&#20013;&#21487;&#20197;&#25198;&#28436;&#30340;&#19981;&#21516;&#35282;&#33394;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23578;&#26410;&#24320;&#21457;&#30340;&#39046;&#22495;&#21644;LLMs&#22312;&#28216;&#25103;&#20013;&#26410;&#26469;&#24212;&#29992;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#65292;&#20197;&#21450;&#22312;&#28216;&#25103;&#39046;&#22495;&#20013;LLMs&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#12290;&#20316;&#20026;LLMs&#21644;&#28216;&#25103;&#20132;&#21449;&#39046;&#22495;&#30340;&#31532;&#19968;&#20221;&#32508;&#21512;&#35843;&#26597;&#21644;&#36335;&#32447;&#22270;&#65292;&#25105;&#20204;&#24076;&#26395;&#26412;&#25991;&#33021;&#22815;&#25104;&#20026;&#36825;&#19968;&#28608;&#21160;&#20154;&#24515;&#30340;&#26032;&#39046;&#22495;&#30340;&#24320;&#21019;&#24615;&#30740;&#31350;&#21644;&#21019;&#26032;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18659v1 Announce Type: cross  Abstract: Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;RNNs&#21644;Transformer&#22312;&#22788;&#29702;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#29616;&#33021;&#21147;&#24046;&#36317;&#65292;&#21457;&#29616;RNNs&#23384;&#22312;&#20851;&#38190;&#29942;&#39048;&#65292;&#21363;&#26080;&#27861;&#23436;&#32654;&#22320;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#23548;&#33268;&#26080;&#27861;&#20687;Transformer&#37027;&#26679;&#36731;&#26494;&#35299;&#20915;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.18510</link><description>&lt;p&gt;
RNNs&#36824;&#19981;&#26159;Transformer&#65306;&#22312;&#19978;&#19979;&#25991;&#26816;&#32034;&#20013;&#30340;&#20851;&#38190;&#29942;&#39048;
&lt;/p&gt;
&lt;p&gt;
RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;RNNs&#21644;Transformer&#22312;&#22788;&#29702;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#29616;&#33021;&#21147;&#24046;&#36317;&#65292;&#21457;&#29616;RNNs&#23384;&#22312;&#20851;&#38190;&#29942;&#39048;&#65292;&#21363;&#26080;&#27861;&#23436;&#32654;&#22320;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#23548;&#33268;&#26080;&#27861;&#20687;Transformer&#37027;&#26679;&#36731;&#26494;&#35299;&#20915;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNNs&#65289;&#21644;Transformer&#22312;&#35299;&#20915;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#31034;&#33021;&#21147;&#24046;&#36317;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;RNNs&#26159;&#21542;&#33021;&#22312;&#22788;&#29702;&#38271;&#24207;&#21015;&#26102;&#65292;&#36890;&#36807;Chain-of-Thought (CoT)&#25552;&#31034;&#65292;&#19982;Transformer&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#26174;&#31034;CoT&#21487;&#20197;&#25913;&#36827;RNNs&#65292;&#20294;&#26080;&#27861;&#24357;&#34917;&#19982;Transformer&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20851;&#38190;&#29942;&#39048;&#22312;&#20110;RNNs&#26080;&#27861;&#23436;&#20840;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#21363;&#20351;&#32463;&#36807;CoT&#30340;&#22686;&#24378;&#65306;&#23545;&#20110;&#20960;&#20010;&#26126;&#30830;&#25110;&#38544;&#24335;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#65292;&#22914;&#32852;&#24819;&#21484;&#22238;&#21644;&#30830;&#23450;&#22270;&#26159;&#21542;&#20026;&#26641;&#65292;&#25105;&#20204;&#35777;&#26126;RNNs&#34920;&#36798;&#33021;&#21147;&#19981;&#36275;&#20197;&#35299;&#20915;&#36825;&#20123;&#20219;&#21153;&#65292;&#32780;Transformer&#21487;&#20197;&#36731;&#26494;&#35299;&#20915;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#37319;&#29992;&#22686;&#24378;RNNs&#19978;&#19979;&#25991;&#26816;&#32034;&#33021;&#21147;&#30340;&#25216;&#26415;&#65292;&#21253;&#25324;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18510v1 Announce Type: cross  Abstract: This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems. We focus on understanding whether RNNs, known for their memory efficiency in handling long sequences, can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: for several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease. Conversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, inclu
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;ToMBench&#26694;&#26550;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#36827;&#34892;&#24515;&#28789;&#29702;&#35770;&#24615;&#33021;&#35780;&#20272;&#65292;&#21457;&#29616;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#20173;&#28982;&#33853;&#21518;&#20110;&#20154;&#31867;&#34920;&#29616;&#36229;&#36807;10%&#12290;</title><link>https://arxiv.org/abs/2402.15052</link><description>&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#22522;&#20934;&#27979;&#35797;&#24515;&#28789;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
ToMBench: Benchmarking Theory of Mind in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15052
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;ToMBench&#26694;&#26550;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#36827;&#34892;&#24515;&#28789;&#29702;&#35770;&#24615;&#33021;&#35780;&#20272;&#65292;&#21457;&#29616;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#20173;&#28982;&#33853;&#21518;&#20110;&#20154;&#31867;&#34920;&#29616;&#36229;&#36807;10%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24515;&#28789;&#29702;&#35770;&#65288;ToM&#65289;&#26159;&#25351;&#24863;&#30693;&#21644;&#24402;&#22240;&#33258;&#24049;&#20197;&#21450;&#20182;&#20154;&#30340;&#24515;&#29702;&#29366;&#24577;&#30340;&#35748;&#30693;&#33021;&#21147;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#24341;&#21457;&#20102;&#20851;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#21542;&#34920;&#29616;&#20986;&#19968;&#31181;&#24418;&#24335;&#30340;&#24515;&#28789;&#29702;&#35770;&#30340;&#20105;&#35770;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24515;&#28789;&#29702;&#35770;&#35780;&#20272;&#21463;&#21040;&#35832;&#22914;&#21463;&#38480;&#33539;&#22260;&#12289;&#20027;&#35266;&#21028;&#26029;&#21644;&#24847;&#22806;&#27745;&#26579;&#31561;&#25361;&#25112;&#30340;&#21046;&#32422;&#65292;&#23548;&#33268;&#35780;&#20272;&#19981;&#36275;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ToMBench&#65292;&#20855;&#26377;&#19977;&#20010;&#20851;&#38190;&#29305;&#24449;&#65306;&#31995;&#32479;&#35780;&#20272;&#26694;&#26550;&#28085;&#30422;&#31038;&#20250;&#35748;&#30693;&#20013;&#30340;8&#39033;&#20219;&#21153;&#21644;31&#39033;&#33021;&#21147;&#65292;&#22810;&#39033;&#36873;&#25321;&#39064;&#26684;&#24335;&#20197;&#25903;&#25345;&#33258;&#21160;&#21270;&#21644;&#26080;&#20559;&#35265;&#30340;&#35780;&#20272;&#65292;&#20197;&#21450;&#22522;&#20110;&#21452;&#35821;&#28165;&#21333;&#30340;&#20174;&#22836;&#26500;&#24314;&#65292;&#20005;&#26684;&#36991;&#20813;&#25968;&#25454;&#27844;&#28431;&#12290;&#22522;&#20110;ToMBench&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#35780;&#20272;&#20102;10&#20010;&#27969;&#34892;LLMs&#22312;&#20219;&#21153;&#21644;&#33021;&#21147;&#26041;&#38754;&#30340;&#24515;&#28789;&#29702;&#35770;&#34920;&#29616;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21363;&#20351;&#20687;GPT-4&#36825;&#26679;&#30340;&#26368;&#20808;&#36827;&#30340;LLMs&#20063;&#27604;&#20154;&#31867;&#34920;&#29616;&#33853;&#21518;&#36229;&#36807;10&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15052v1 Announce Type: cross  Abstract: Theory of Mind (ToM) is the cognitive capability to perceive and ascribe mental states to oneself and others. Recent research has sparked a debate over whether large language models (LLMs) exhibit a form of ToM. However, existing ToM evaluations are hindered by challenges such as constrained scope, subjective judgment, and unintended contamination, yielding inadequate assessments. To address this gap, we introduce ToMBench with three key characteristics: a systematic evaluation framework encompassing 8 tasks and 31 abilities in social cognition, a multiple-choice question format to support automated and unbiased evaluation, and a build-from-scratch bilingual inventory to strictly avoid data leakage. Based on ToMBench, we conduct extensive experiments to evaluate the ToM performance of 10 popular LLMs across tasks and abilities. We find that even the most advanced LLMs like GPT-4 lag behind human performance by over 10% points, indicati
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26597;&#35810;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36828;&#31243;&#35821;&#35328;&#27169;&#22411;&#30340; API &#35775;&#38382;&#26500;&#36896;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#20351;&#27169;&#22411;&#20197;&#26356;&#39640;&#27010;&#29575;&#21457;&#20986;&#26377;&#23475;&#23383;&#31526;&#20018;&#65292;&#32780;&#38750;&#20165;&#20165;&#22522;&#20110;&#27169;&#22411;&#20043;&#38388;&#30340;&#36716;&#31227;&#24615;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2402.12329</link><description>&lt;p&gt;
&#22522;&#20110;&#26597;&#35810;&#30340;&#23545;&#25239;&#24615;&#25552;&#31034;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Query-Based Adversarial Prompt Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12329
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26597;&#35810;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36828;&#31243;&#35821;&#35328;&#27169;&#22411;&#30340; API &#35775;&#38382;&#26500;&#36896;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#20351;&#27169;&#22411;&#20197;&#26356;&#39640;&#27010;&#29575;&#21457;&#20986;&#26377;&#23475;&#23383;&#31526;&#20018;&#65292;&#32780;&#38750;&#20165;&#20165;&#22522;&#20110;&#27169;&#22411;&#20043;&#38388;&#30340;&#36716;&#31227;&#24615;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#20197;&#26500;&#36896;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#23548;&#33268;&#19968;&#20010;&#23545;&#20854;&#36827;&#34892;&#20102;&#35843;&#25972;&#30340;&#35821;&#35328;&#27169;&#22411;&#20135;&#29983;&#26377;&#23475;&#23383;&#31526;&#20018;&#25110;&#25191;&#34892;&#26377;&#23475;&#34892;&#20026;&#12290;&#29616;&#26377;&#30340;&#25915;&#20987;&#35201;&#20040;&#22312;&#30333;&#30418;&#35774;&#32622;&#20013;&#65288;&#23436;&#20840;&#35775;&#38382;&#27169;&#22411;&#26435;&#37325;&#65289;&#65292;&#35201;&#20040;&#36890;&#36807;&#21487;&#36716;&#31227;&#24615;&#65306;&#19968;&#31181;&#29616;&#35937;&#65292;&#21363;&#22312;&#19968;&#20010;&#27169;&#22411;&#19978;&#31934;&#24515;&#35774;&#35745;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#36890;&#24120;&#22312;&#20854;&#20182;&#27169;&#22411;&#19978;&#20173;&#28982;&#26377;&#25928;&#12290;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#26597;&#35810;&#30340;&#25915;&#20987;&#25913;&#36827;&#20197;&#21069;&#30340;&#24037;&#20316;&#65292;&#21033;&#29992; API &#35775;&#38382;&#36828;&#31243;&#35821;&#35328;&#27169;&#22411;&#26469;&#26500;&#36896;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#20351;&#27169;&#22411;&#20197;&#65288;&#26126;&#26174;&#65289;&#26356;&#39640;&#30340;&#27010;&#29575;&#21457;&#20986;&#26377;&#23475;&#23383;&#31526;&#20018;&#65292;&#32780;&#19981;&#33021;&#20165;&#20165;&#20351;&#29992;&#36716;&#31227;&#25915;&#20987;&#12290;&#25105;&#20204;&#22312; GPT-3.5 &#21644; OpenAI &#30340;&#23433;&#20840;&#20998;&#31867;&#22120;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#25915;&#20987;&#65307;&#25105;&#20204;&#33021;&#22815;&#35753; GPT-3.5 &#21457;&#20986;&#26377;&#23475;&#23383;&#31526;&#20018;&#65292;&#32780;&#30446;&#21069;&#30340;&#36716;&#31227;&#25915;&#20987;&#22833;&#36133;&#20102;&#65292;&#24182;&#19988;&#25105;&#20204;&#20960;&#20046;&#20197; 100% &#30340;&#27010;&#29575;&#35268;&#36991;&#20102;&#23433;&#20840;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12329v1 Announce Type: cross  Abstract: Recent work has shown it is possible to construct adversarial examples that cause an aligned language model to emit harmful strings or perform harmful behavior. Existing attacks work either in the white-box setting (with full access to the model weights), or through transferability: the phenomenon that adversarial examples crafted on one model often remain effective on other models. We improve on prior work with a query-based attack that leverages API access to a remote language model to construct adversarial examples that cause the model to emit harmful strings with (much) higher probability than with transfer-only attacks. We validate our attack on GPT-3.5 and OpenAI's safety classifier; we can cause GPT-3.5 to emit harmful strings that current transfer attacks fail at, and we can evade the safety classifier with nearly 100% probability.
&lt;/p&gt;</description></item><item><title>FIPO&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#30001;&#24418;&#24335;&#25351;&#23548;&#30340;&#25552;&#31034;&#20248;&#21270;&#26041;&#27861;&#65292;&#32467;&#21512;&#20559;&#22909;&#25968;&#25454;&#38598;&#21644;&#27169;&#22359;&#21270;&#24494;&#35843;&#27169;&#24335;&#65292;&#37325;&#26032;&#26500;&#24605;&#20102;&#20248;&#21270;&#36807;&#31243;&#24182;&#23454;&#29616;&#20102;&#28789;&#27963;&#30340;&#20219;&#21153;&#25552;&#31034;&#29983;&#25104;&#12290;</title><link>https://arxiv.org/abs/2402.11811</link><description>&lt;p&gt;
FIPO&#65306;&#22522;&#20110;&#33258;&#30001;&#24418;&#24335;&#25351;&#23548;&#30340;&#25552;&#31034;&#20248;&#21270;&#19982;&#20559;&#22909;&#25968;&#25454;&#38598;&#21644;&#27169;&#22359;&#21270;&#24494;&#35843;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
FIPO: Free-form Instruction-oriented Prompt Optimization with Preference Dataset and Modular Fine-tuning Schema
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11811
&lt;/p&gt;
&lt;p&gt;
FIPO&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#30001;&#24418;&#24335;&#25351;&#23548;&#30340;&#25552;&#31034;&#20248;&#21270;&#26041;&#27861;&#65292;&#32467;&#21512;&#20559;&#22909;&#25968;&#25454;&#38598;&#21644;&#27169;&#22359;&#21270;&#24494;&#35843;&#27169;&#24335;&#65292;&#37325;&#26032;&#26500;&#24605;&#20102;&#20248;&#21270;&#36807;&#31243;&#24182;&#23454;&#29616;&#20102;&#28789;&#27963;&#30340;&#20219;&#21153;&#25552;&#31034;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20419;&#36827;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#26368;&#32456;&#29992;&#25143;-&#26426;&#22120;&#20154;&#20132;&#20114;&#20013;&#30340;&#28145;&#24230;&#26234;&#33021;&#26041;&#38754;&#65292;&#25552;&#31034;&#21019;&#20316;&#30340;&#33402;&#26415;&#34987;&#35270;&#20026;&#26222;&#36890;&#29992;&#25143;&#30340;&#19968;&#39033;&#20851;&#38190;&#20294;&#22797;&#26434;&#30340;&#20219;&#21153;&#12290;&#19982;&#20043;&#21069;&#22522;&#20110;&#27169;&#22411;&#32780;&#19981;&#32771;&#34385;&#25351;&#23548;&#30340;&#33258;&#21160;&#25552;&#31034;&#20248;&#21270;&#26041;&#27861;&#24418;&#25104;&#23545;&#27604;&#65292;&#36825;&#20123;&#26041;&#27861;&#20026;&#39044;&#23450;&#20041;&#30446;&#26631;&#27169;&#22411;&#20135;&#29983;&#20102;&#20809;&#28369;&#30340;&#32467;&#26524;&#65292;&#20294;&#22312;&#20351;&#29992;&#24320;&#31665;&#21363;&#29992;&#27169;&#22411;&#26102;&#23481;&#26131;&#24555;&#36895;&#36864;&#21270;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#30001;&#24418;&#24335;&#25351;&#23548;&#30340;&#25552;&#31034;&#20248;&#21270;&#65288;FIPO&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#24471;&#21040;&#25105;&#20204;&#30340;&#22823;&#35268;&#27169;&#25552;&#31034;&#20559;&#22909;&#25968;&#25454;&#38598;&#30340;&#25903;&#25345;&#65292;&#24182;&#37319;&#29992;&#27169;&#22359;&#21270;&#24494;&#35843;&#27169;&#24335;&#12290;FIPO&#27169;&#24335;&#37325;&#26032;&#26500;&#24605;&#20102;&#20248;&#21270;&#36807;&#31243;&#65292;&#23558;&#20854;&#20998;&#35299;&#20026;&#21487;&#31649;&#29702;&#30340;&#27169;&#22359;&#65292;&#20197;&#21160;&#24577;&#35843;&#25972;&#20869;&#23481;&#30340;&#20803;&#25552;&#31034;&#20026;&#38170;&#28857;&#12290;&#36825;&#20801;&#35768;&#28789;&#27963;&#25972;&#21512;&#21407;&#22987;&#20219;&#21153;&#25351;&#23548;&#12289;&#21487;&#36873;&#25351;&#23548;&#21709;&#24212;&#21644;&#21487;&#36873;&#30495;&#23454;&#20540;&#65292;&#20197;&#29983;&#25104;&#32463;&#36807;&#31934;&#24515;&#20248;&#21270;&#30340;&#20219;&#21153;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11811v1 Announce Type: new  Abstract: In the quest to facilitate the deep intelligence of Large Language Models (LLMs) accessible in final-end user-bot interactions, the art of prompt crafting emerges as a critical yet complex task for the average user. Contrast to previous model-oriented yet instruction-agnostic Automatic Prompt Optimization methodologies, yielding polished results for predefined target models while suffering rapid degradation with out-of-box models, we present Free-form Instruction-oriented Prompt Optimization (FIPO). This approach is supported by our large-scale prompt preference dataset and employs a modular fine-tuning schema. The FIPO schema reimagines the optimization process into manageable modules, anchored by a meta prompt that dynamically adapts content. This allows for the flexible integration of the raw task instruction, the optional instruction response, and the optional ground truth to produce finely optimized task prompts. The FIPO preference
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#27604;&#36739;LLMs&#19982;&#20256;&#32479;&#27169;&#22411;&#65292;&#21457;&#29616;&#20102;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#25351;&#20986;LLMs&#22312;&#39044;&#27979;&#20855;&#26377;&#26126;&#26174;&#27169;&#24335;&#21644;&#36235;&#21183;&#30340;&#26102;&#38388;&#24207;&#21015;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#32570;&#20047;&#21608;&#26399;&#24615;&#30340;&#25968;&#25454;&#38598;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#21516;&#26102;&#25351;&#20986;&#34701;&#20837;&#22806;&#37096;&#30693;&#35782;&#21644;&#37319;&#29992;&#33258;&#28982;&#35821;&#35328;&#37322;&#20041;&#26377;&#21161;&#20110;&#25552;&#21319;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.10835</link><description>&lt;p&gt;
LLMs&#19979;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65306;&#29702;&#35299;&#21644;&#22686;&#24378;&#27169;&#22411;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#27604;&#36739;LLMs&#19982;&#20256;&#32479;&#27169;&#22411;&#65292;&#21457;&#29616;&#20102;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#25351;&#20986;LLMs&#22312;&#39044;&#27979;&#20855;&#26377;&#26126;&#26174;&#27169;&#24335;&#21644;&#36235;&#21183;&#30340;&#26102;&#38388;&#24207;&#21015;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#32570;&#20047;&#21608;&#26399;&#24615;&#30340;&#25968;&#25454;&#38598;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#21516;&#26102;&#25351;&#20986;&#34701;&#20837;&#22806;&#37096;&#30693;&#35782;&#21644;&#37319;&#29992;&#33258;&#28982;&#35821;&#35328;&#37322;&#20041;&#26377;&#21161;&#20110;&#25552;&#21319;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLMs)&#36817;&#24180;&#26469;&#22312;&#35768;&#22810;&#39046;&#22495;&#24471;&#21040;&#36805;&#36895;&#21457;&#23637;&#12290;&#20316;&#20026;&#19968;&#31181;&#32463;&#20856;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26368;&#36817;&#20174;LLMs&#20013;&#33719;&#24471;&#20102;&#25512;&#21160;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#19968;&#39046;&#22495;&#65292;LLMs&#30340;&#20559;&#22909;&#23384;&#22312;&#30740;&#31350;&#31354;&#30333;&#12290;&#36890;&#36807;&#23558;LLMs&#19982;&#20256;&#32479;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#65292;&#21457;&#29616;&#20102;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#35768;&#22810;&#29305;&#24615;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;LLMs&#22312;&#39044;&#27979;&#20855;&#26377;&#26126;&#26174;&#27169;&#24335;&#21644;&#36235;&#21183;&#30340;&#26102;&#38388;&#24207;&#21015;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#32570;&#20047;&#21608;&#26399;&#24615;&#30340;&#25968;&#25454;&#38598;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#25552;&#31034;&#35201;&#27714;LLMs&#21578;&#30693;&#25968;&#25454;&#38598;&#30340;&#21608;&#26399;&#26469;&#35299;&#37322;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#30740;&#31350;&#20102;&#36755;&#20837;&#31574;&#30053;&#65292;&#21457;&#29616;&#34701;&#20837;&#22806;&#37096;&#30693;&#35782;&#21644;&#37319;&#29992;&#33258;&#28982;&#35821;&#35328;&#37322;&#20041;&#31215;&#26497;&#24433;&#21709;&#20102;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#36825;&#39033;&#30740;&#31350;&#26377;&#21161;&#20110;&#27934;&#23519;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10835v1 Announce Type: new  Abstract: Large language models (LLMs) have been applied in many fields with rapid development in recent years. As a classic machine learning task, time series forecasting has recently received a boost from LLMs. However, there is a research gap in the LLMs' preferences in this field. In this paper, by comparing LLMs with traditional models, many properties of LLMs in time series prediction are found. For example, our study shows that LLMs excel in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. We explain our findings through designing prompts to require LLMs to tell the period of the datasets. In addition, the input strategy is investigated, and it is found that incorporating external knowledge and adopting natural language paraphrases positively affects the predictive performance of LLMs for time series. Overall, this study contributes to insight into the advantages and limitations of
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;ChatGPT&#22312;&#29983;&#25104;&#20851;&#20110;&#20044;&#20811;&#20848;&#25112;&#20105;&#30340;&#34394;&#20551;&#20449;&#24687;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#23427;&#21487;&#20197;&#20197;&#36739;&#20302;&#25104;&#26412;&#12289;&#24555;&#36895;&#19988;&#22823;&#35268;&#27169;&#22320;&#29983;&#25104;&#36924;&#30495;&#30340;&#23450;&#21046;&#34394;&#20551;&#20449;&#24687;&#65292;&#32780;&#19988;&#36825;&#20123;&#34394;&#20551;&#20449;&#24687;&#24456;&#38590;&#34987;&#20154;&#31867;&#35835;&#32773;&#21644;&#29616;&#26377;&#30340;&#33258;&#21160;&#21270;&#24037;&#20855;&#21487;&#38752;&#22320;&#21306;&#20998;&#20986;&#26469;&#12290;</title><link>https://arxiv.org/abs/2402.08467</link><description>&lt;p&gt;
&#32993;&#20081;&#36896;&#35875;&#65306;&#32469;&#36807;ChatGPT&#30340;&#38450;&#25252;&#25514;&#26045;&#65292;&#22823;&#35268;&#27169;&#29983;&#25104;&#38590;&#20197;&#26816;&#27979;&#30340;&#34394;&#20551;&#20449;&#24687;&#22768;&#26126;
&lt;/p&gt;
&lt;p&gt;
Lying Blindly: Bypassing ChatGPT's Safeguards to Generate Hard-to-Detect Disinformation Claims at Scale
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;ChatGPT&#22312;&#29983;&#25104;&#20851;&#20110;&#20044;&#20811;&#20848;&#25112;&#20105;&#30340;&#34394;&#20551;&#20449;&#24687;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#23427;&#21487;&#20197;&#20197;&#36739;&#20302;&#25104;&#26412;&#12289;&#24555;&#36895;&#19988;&#22823;&#35268;&#27169;&#22320;&#29983;&#25104;&#36924;&#30495;&#30340;&#23450;&#21046;&#34394;&#20551;&#20449;&#24687;&#65292;&#32780;&#19988;&#36825;&#20123;&#34394;&#20551;&#20449;&#24687;&#24456;&#38590;&#34987;&#20154;&#31867;&#35835;&#32773;&#21644;&#29616;&#26377;&#30340;&#33258;&#21160;&#21270;&#24037;&#20855;&#21487;&#38752;&#22320;&#21306;&#20998;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21464;&#24471;&#36234;&#26469;&#36234;&#29087;&#32451;&#65292;&#23427;&#20204;&#22312;&#22823;&#35268;&#27169;&#30149;&#27602;&#24335;&#34394;&#20551;&#20449;&#24687;&#27963;&#21160;&#20013;&#30340;&#28389;&#29992;&#25104;&#20026;&#19968;&#20010;&#36234;&#26469;&#36234;&#20005;&#37325;&#30340;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ChatGPT&#29983;&#25104;&#20851;&#20110;&#20044;&#20811;&#20848;&#25112;&#20105;&#30340;&#26080;&#26465;&#20214;&#22768;&#26126;&#30340;&#33021;&#21147;&#65292;&#36825;&#26159;&#19968;&#20010;&#36229;&#20986;&#20854;&#30693;&#35782;&#30028;&#38480;&#30340;&#20107;&#20214;&#65292;&#24182;&#35780;&#20272;&#36825;&#20123;&#22768;&#26126;&#26159;&#21542;&#21487;&#20197;&#34987;&#20154;&#31867;&#35835;&#32773;&#21644;&#33258;&#21160;&#21270;&#24037;&#20855;&#19982;&#20154;&#31867;&#32534;&#20889;&#30340;&#22768;&#26126;&#21306;&#20998;&#20986;&#26469;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;ClaimReview&#20013;&#20851;&#20110;&#25112;&#20105;&#30340;&#22768;&#26126;&#65292;&#36825;&#20123;&#22768;&#26126;&#26159;&#30001;IFCN&#27880;&#20876;&#30340;&#20107;&#23454;&#26680;&#26597;&#21592;&#25776;&#20889;&#30340;&#65292;&#20197;&#21450;ChatGPT&#29983;&#25104;&#30340;&#31867;&#20284;&#30340;&#30701;&#31687;&#20869;&#23481;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;ChatGPT&#21487;&#20197;&#24555;&#36895;&#12289;&#24265;&#20215;&#19988;&#35268;&#27169;&#21270;&#22320;&#29983;&#25104;&#36924;&#30495;&#19988;&#38024;&#23545;&#29305;&#23450;&#30446;&#26631;&#30340;&#34394;&#20551;&#20449;&#24687;&#65292;&#32780;&#19988;&#36825;&#20123;&#22768;&#26126;&#20154;&#31867;&#21644;&#29616;&#26377;&#30340;&#33258;&#21160;&#21270;&#24037;&#20855;&#26080;&#27861;&#21487;&#38752;&#22320;&#21306;&#20998;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
As Large Language Models (LLMs) become more proficient, their misuse in large-scale viral disinformation campaigns is a growing concern. This study explores the capability of ChatGPT to generate unconditioned claims about the war in Ukraine, an event beyond its knowledge cutoff, and evaluates whether such claims can be differentiated by human readers and automated tools from human-written ones. We compare war-related claims from ClaimReview, authored by IFCN-registered fact-checkers, and similar short-form content generated by ChatGPT. We demonstrate that ChatGPT can produce realistic, target-specific disinformation cheaply, fast, and at scale, and that these claims cannot be reliably distinguished by humans or existing automated tools.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;EntGPT&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;Entity Disambiguation&#65288;ED&#65289;&#20219;&#21153;&#65292;&#36830;&#25509;&#20102;&#29983;&#25104;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#24211;&#12290;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#21644;&#25351;&#20196;&#35843;&#25972;&#65292;&#35813;&#27169;&#22411;&#22312;&#27809;&#26377;&#26377;&#30417;&#30563;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;LLMs&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#23454;&#20307;&#28040;&#27495;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06738</link><description>&lt;p&gt;
EntGPT: &#23558;&#29983;&#25104;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#24211;&#30456;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
EntGPT: Linking Generative Large Language Models with Knowledge Bases
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;EntGPT&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;Entity Disambiguation&#65288;ED&#65289;&#20219;&#21153;&#65292;&#36830;&#25509;&#20102;&#29983;&#25104;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#30693;&#35782;&#24211;&#12290;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#21644;&#25351;&#20196;&#35843;&#25972;&#65292;&#35813;&#27169;&#22411;&#22312;&#27809;&#26377;&#26377;&#30417;&#30563;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;LLMs&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#23454;&#20307;&#28040;&#27495;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#35757;&#32451;&#21644;&#25512;&#29702;&#36807;&#31243;&#20013;&#32570;&#20047;&#20107;&#23454;&#26680;&#23454;&#21644;&#30693;&#35782;&#22522;&#30784;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#29983;&#25104;&#30340;&#20107;&#23454;&#27491;&#30830;&#36755;&#20986;&#30340;&#33021;&#21147;&#30456;&#23545;&#36739;&#23569;&#34987;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;Entity Disambiguation&#65288;ED&#65289;&#20219;&#21153;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;&#25552;&#31034;&#24037;&#31243;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#19977;&#27493;&#30828;&#25552;&#31034;&#26041;&#27861;&#65292;&#20197;&#22312;&#27809;&#26377;&#26377;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#30340;&#24773;&#20917;&#19979;&#25506;&#27979;LLM&#30340;ED&#24615;&#33021;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#35813;&#25552;&#31034;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#21407;&#22987;&#22522;&#20934;&#27169;&#22411;&#30340;&#24494;F_1&#24471;&#20998;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;36%&#29978;&#33267;&#26356;&#39640;&#65292;&#24182;&#22312;10&#20010;&#25968;&#25454;&#38598;&#19978;&#19982;&#29616;&#26377;&#30340;SFT&#26041;&#27861;&#30456;&#27604;&#65292;&#33719;&#24471;&#20102;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#31867;&#20284;&#30340;&#25552;&#31034;&#21644;&#21709;&#24212;&#36827;&#34892;&#25351;&#20196;&#35843;&#25972;&#65288;IT&#65289;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#30693;&#35782;&#22522;&#30784;&#12290;&#25351;&#20196;&#35843;&#25972;&#30340;&#27169;&#22411;&#22312;&#21463;&#30417;&#30563;&#23454;&#20307;&#28040;&#27495;&#20219;&#21153;&#19978;&#19981;&#20165;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#24494;F1&#24471;&#20998;&#24615;&#33021;&#65292;&#32780;&#19988;&#24179;&#22343;&#24494;F_1&#25552;&#39640;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability of Large Language Models (LLMs) to generate factually correct output remains relatively unexplored due to the lack of fact-checking and knowledge grounding during training and inference. In this work, we aim to address this challenge through the Entity Disambiguation (ED) task. We first consider prompt engineering, and design a three-step hard-prompting method to probe LLMs' ED performance without supervised fine-tuning (SFT). Overall, the prompting method improves the micro-F_1 score of the original vanilla models by a large margin, on some cases up to 36% and higher, and obtains comparable performance across 10 datasets when compared to existing methods with SFT. We further improve the knowledge grounding ability through instruction tuning (IT) with similar prompts and responses. The instruction-tuned model not only achieves higher micro-F1 score performance as compared to several baseline methods on supervised entity disambiguation tasks with an average micro-F_1 improve
&lt;/p&gt;</description></item><item><title>CIC&#26159;&#19968;&#31181;&#38754;&#21521;&#25991;&#21270;&#24863;&#30693;&#22270;&#20687;&#23383;&#24149;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#35270;&#35273;&#38382;&#31572;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#29983;&#25104;&#33021;&#25551;&#36848;&#22270;&#20687;&#20013;&#25991;&#21270;&#20803;&#32032;&#30340;&#35814;&#32454;&#23383;&#24149;&#12290;</title><link>https://arxiv.org/abs/2402.05374</link><description>&lt;p&gt;
CIC&#65306;&#19968;&#31181;&#38754;&#21521;&#25991;&#21270;&#24863;&#30693;&#22270;&#20687;&#23383;&#24149;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
CIC: A framework for Culturally-aware Image Captioning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05374
&lt;/p&gt;
&lt;p&gt;
CIC&#26159;&#19968;&#31181;&#38754;&#21521;&#25991;&#21270;&#24863;&#30693;&#22270;&#20687;&#23383;&#24149;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#35270;&#35273;&#38382;&#31572;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#29983;&#25104;&#33021;&#25551;&#36848;&#22270;&#20687;&#20013;&#25991;&#21270;&#20803;&#32032;&#30340;&#35814;&#32454;&#23383;&#24149;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#20687;&#23383;&#24149;&#36890;&#36807;&#20351;&#29992;&#35270;&#35273;-&#35821;&#35328;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;VLPs&#65289;&#22914;BLIP&#20174;&#22270;&#20687;&#29983;&#25104;&#25551;&#36848;&#24615;&#21477;&#23376;&#65292;&#36825;&#31181;&#26041;&#27861;&#24050;&#32463;&#21462;&#24471;&#20102;&#24456;&#22823;&#30340;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#32570;&#20047;&#23545;&#22270;&#20687;&#20013;&#25152;&#25551;&#32472;&#30340;&#25991;&#21270;&#20803;&#32032;&#65288;&#20363;&#22914;&#20122;&#27954;&#25991;&#21270;&#32676;&#20307;&#30340;&#20256;&#32479;&#26381;&#35013;&#65289;&#29983;&#25104;&#35814;&#32454;&#25551;&#36848;&#24615;&#23383;&#24149;&#30340;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;\textbf{&#38754;&#21521;&#25991;&#21270;&#24863;&#30693;&#22270;&#20687;&#23383;&#24149;&#65288;CIC&#65289;}&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#20174;&#20195;&#34920;&#19981;&#21516;&#25991;&#21270;&#30340;&#22270;&#20687;&#20013;&#29983;&#25104;&#23383;&#24149;&#24182;&#25551;&#36848;&#25991;&#21270;&#20803;&#32032;&#12290;&#21463;&#21040;&#23558;&#35270;&#35273;&#27169;&#24577;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#36866;&#24403;&#30340;&#25552;&#31034;&#36827;&#34892;&#32452;&#21512;&#30340;&#26041;&#27861;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#65288;1&#65289;&#26681;&#25454;&#22270;&#20687;&#20013;&#30340;&#25991;&#21270;&#31867;&#21035;&#29983;&#25104;&#38382;&#39064;&#65292;&#65288;2&#65289;&#21033;&#29992;&#29983;&#25104;&#30340;&#38382;&#39064;&#20174;&#35270;&#35273;&#38382;&#31572;&#65288;VQA&#65289;&#20013;&#25552;&#21462;&#25991;&#21270;&#35270;&#35273;&#20803;&#32032;&#65292;&#65288;3&#65289;&#20351;&#29992;&#24102;&#26377;&#25552;&#31034;&#30340;LLMs&#29983;&#25104;&#25991;&#21270;&#24863;&#30693;&#23383;&#24149;&#12290;&#25105;&#20204;&#22312;4&#20010;&#19981;&#21516;&#22823;&#23398;&#30340;45&#21517;&#21442;&#19982;&#32773;&#19978;&#36827;&#34892;&#20102;&#20154;&#24037;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Image Captioning generates descriptive sentences from images using Vision-Language Pre-trained models (VLPs) such as BLIP, which has improved greatly. However, current methods lack the generation of detailed descriptive captions for the cultural elements depicted in the images, such as the traditional clothing worn by people from Asian cultural groups. In this paper, we propose a new framework, \textbf{Culturally-aware Image Captioning (CIC)}, that generates captions and describes cultural elements extracted from cultural visual elements in images representing cultures. Inspired by methods combining visual modality and Large Language Models (LLMs) through appropriate prompts, our framework (1) generates questions based on cultural categories from images, (2) extracts cultural visual elements from Visual Question Answering (VQA) using generated questions, and (3) generates culturally-aware captions using LLMs with the prompts. Our human evaluation conducted on 45 participants from 4 dif
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20110;&#29992;&#25143;&#30340;&#21453;&#39304;&#25968;&#25454;&#20013;&#24341;&#20837;&#20010;&#24615;&#21270;&#29305;&#24449;&#26469;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#22312;&#22810;&#26679;&#21270;&#29992;&#25143;&#20559;&#22909;&#19979;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.05133</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#35821;&#35328;&#27169;&#22411;&#22522;&#20110;&#20010;&#24615;&#21270;&#20154;&#31867;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Personalized Language Modeling from Personalized Human Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05133
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20010;&#24615;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20110;&#29992;&#25143;&#30340;&#21453;&#39304;&#25968;&#25454;&#20013;&#24341;&#20837;&#20010;&#24615;&#21270;&#29305;&#24449;&#26469;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#22312;&#22810;&#26679;&#21270;&#29992;&#25143;&#20559;&#22909;&#19979;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#20010;&#24615;&#21270;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26159;&#30446;&#21069;&#20027;&#27969;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#26356;&#22909;&#22320;&#31526;&#21512;&#20154;&#31867;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#24320;&#21457;&#30340;&#31639;&#27861;&#30340;&#22522;&#26412;&#21069;&#25552;&#22312;&#29992;&#25143;&#20559;&#22909;&#22810;&#26679;&#21270;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#20986;&#29616;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#24320;&#21457;&#20010;&#24615;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#27491;&#24335;&#20171;&#32461;&#20102;&#20174;&#20010;&#24615;&#21270;&#20154;&#31867;&#21453;&#39304;&#20013;&#23398;&#20064;&#30340;&#20219;&#21153;&#65292;&#24182;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26222;&#36890;&#30340;RLHF&#21487;&#33021;&#20250;&#23384;&#22312;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20010;&#24615;&#21270;-RLHF&#65288;P-RLHF&#65289;&#26694;&#26550;&#65292;&#38656;&#35201;&#21516;&#26102;&#23398;&#20064;&#29992;&#25143;&#27169;&#22411;&#21644;&#35821;&#35328;&#65288;&#25110;&#22870;&#21169;&#65289;&#27169;&#22411;&#12290;&#29992;&#25143;&#27169;&#22411;&#25509;&#25910;&#29992;&#25143;&#20449;&#24687;&#24182;&#36755;&#20986;&#29992;&#25143;&#34920;&#31034;&#12290;&#20854;&#32467;&#26500;&#32534;&#30721;&#20102;&#25105;&#20204;&#23545;&#21453;&#39304;&#25968;&#25454;&#20013;&#29992;&#25143;&#20559;&#22909;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#20026;&#20010;&#24615;&#21270;&#22870;&#21169;&#24314;&#27169;&#21644;&#20010;&#24615;&#21270;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#24320;&#21457;&#20102;&#26032;&#30340;&#23398;&#20064;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback (RLHF) is the current dominating framework to fine-tune large language models to better align with human preferences. However, the underlying premise of algorithms developed under this framework can be problematic when user preferences encoded in human feedback are diverse. In this work, we aim to address this problem by developing methods for building personalized language models. We first formally introduce the task of learning from personalized human feedback and explain why vanilla RLHF can be problematic in this context. We then propose a general Personalized-RLHF (P-RLHF) framework, which requires one to jointly learn a user model and a language (or reward) model. The user model takes in user information and outputs user representations. Its structure encodes our assumptions about user preferences underlying the feedback data. We develop new learning objectives for personalized reward modeling and personalized Direct Preference Optimizat
&lt;/p&gt;</description></item><item><title>&#20247;&#21253;&#33258;&#36866;&#24212;&#35843;&#26597;&#26041;&#27861;&#65288;CSAS&#65289;&#32467;&#21512;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#33021;&#22815;&#26681;&#25454;&#29992;&#25143;&#36755;&#20837;&#28436;&#21464;&#38382;&#39064;&#24211;&#65292;&#24182;&#22312;&#35843;&#26597;&#20013;&#36866;&#24212;&#26032;&#30340;&#38382;&#39064;&#65292;&#24212;&#29992;&#22312;&#25289;&#19969;&#35028;&#20449;&#24687;&#29615;&#22659;&#21644;&#35758;&#39064;&#37325;&#35201;&#24615;&#39046;&#22495;&#65292;&#33021;&#22815;&#35782;&#21035;&#38590;&#20197;&#36890;&#36807;&#20256;&#32479;&#26041;&#27861;&#36319;&#36394;&#30340;&#20027;&#24352;&#25110;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.12986</link><description>&lt;p&gt;
&#20247;&#21253;&#33258;&#36866;&#24212;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Crowdsourced Adaptive Surveys. (arXiv:2401.12986v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12986
&lt;/p&gt;
&lt;p&gt;
&#20247;&#21253;&#33258;&#36866;&#24212;&#35843;&#26597;&#26041;&#27861;&#65288;CSAS&#65289;&#32467;&#21512;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#33021;&#22815;&#26681;&#25454;&#29992;&#25143;&#36755;&#20837;&#28436;&#21464;&#38382;&#39064;&#24211;&#65292;&#24182;&#22312;&#35843;&#26597;&#20013;&#36866;&#24212;&#26032;&#30340;&#38382;&#39064;&#65292;&#24212;&#29992;&#22312;&#25289;&#19969;&#35028;&#20449;&#24687;&#29615;&#22659;&#21644;&#35758;&#39064;&#37325;&#35201;&#24615;&#39046;&#22495;&#65292;&#33021;&#22815;&#35782;&#21035;&#38590;&#20197;&#36890;&#36807;&#20256;&#32479;&#26041;&#27861;&#36319;&#36394;&#30340;&#20027;&#24352;&#25110;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#20247;&#33286;&#35770;&#35843;&#26597;&#23545;&#20110;&#27665;&#20027;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#23545;&#20110;&#20256;&#32479;&#35843;&#26597;&#26041;&#27861;&#26469;&#35828;&#65292;&#24555;&#36895;&#21464;&#21270;&#30340;&#20449;&#24687;&#29615;&#22659;&#21644;&#22312;&#23567;&#20247;&#31038;&#21306;&#20013;&#34913;&#37327;&#35266;&#28857;&#21487;&#33021;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20247;&#21253;&#33258;&#36866;&#24212;&#35843;&#26597;&#26041;&#27861;&#65288;CSAS&#65289;&#65292;&#23427;&#23558;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#33258;&#36866;&#24212;&#31639;&#27861;&#30340;&#36827;&#23637;&#32467;&#21512;&#36215;&#26469;&#65292;&#29983;&#25104;&#38543;&#30528;&#29992;&#25143;&#36755;&#20837;&#19981;&#26029;&#28436;&#21464;&#30340;&#38382;&#39064;&#24211;&#12290;CSAS&#26041;&#27861;&#23558;&#21442;&#19982;&#32773;&#25552;&#20379;&#30340;&#24320;&#25918;&#24335;&#25991;&#26412;&#36716;&#25442;&#20026;Likert&#24335;&#39033;&#30446;&#65292;&#24182;&#24212;&#29992;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#26469;&#30830;&#23450;&#24212;&#20248;&#20808;&#32771;&#34385;&#22312;&#35843;&#26597;&#20013;&#30340;&#29992;&#25143;&#25552;&#20379;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#30340;&#33258;&#36866;&#24212;&#24615;&#20801;&#35768;&#25506;&#32034;&#26032;&#30340;&#35843;&#26597;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#35843;&#26597;&#38271;&#24230;&#19978;&#26045;&#21152;&#26368;&#23567;&#30340;&#25104;&#26412;&#12290;&#22312;&#25289;&#19969;&#35028;&#20449;&#24687;&#29615;&#22659;&#21644;&#35758;&#39064;&#37325;&#35201;&#24615;&#39046;&#22495;&#30340;&#24212;&#29992;&#23637;&#31034;&#20102;CSAS&#35782;&#21035;&#21487;&#33021;&#38590;&#20197;&#36890;&#36807;&#26631;&#20934;&#26041;&#27861;&#36319;&#36394;&#30340;&#20027;&#24352;&#25110;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#25552;&#20986; Conclusion by di&#30340;&#32467;&#26463;&#35821;&#12290;
&lt;/p&gt;
&lt;p&gt;
Public opinion surveys are vital for informing democratic decision-making, but responding to rapidly changing information environments and measuring beliefs within niche communities can be challenging for traditional survey methods. This paper introduces a crowdsourced adaptive survey methodology (CSAS) that unites advances in natural language processing and adaptive algorithms to generate question banks that evolve with user input. The CSAS method converts open-ended text provided by participants into Likert-style items and applies a multi-armed bandit algorithm to determine user-provided questions that should be prioritized in the survey. The method's adaptive nature allows for the exploration of new survey questions, while imposing minimal costs in survey length. Applications in the domains of Latino information environments and issue importance showcase CSAS's ability to identify claims or issues that might otherwise be difficult to track using standard approaches. I conclude by di
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#38024;&#23545;&#26041;&#35328;&#30340;&#26041;&#27861;&#21644;&#38382;&#39064;&#65292;&#24378;&#35843;&#20102;&#26041;&#35328;&#23545;&#20110;NLP&#27169;&#22411;&#24615;&#33021;&#21644;&#35821;&#35328;&#25216;&#26415;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#26041;&#35328;&#30456;&#20851;&#20219;&#21153;&#21644;&#35821;&#35328;&#30340;&#20840;&#38754;&#32508;&#36848;&#12290;</title><link>http://arxiv.org/abs/2401.05632</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#35821;&#35328;&#26041;&#35328;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#27861;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Natural Language Processing for Dialects of a Language: A Survey. (arXiv:2401.05632v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05632
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#30740;&#31350;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#38024;&#23545;&#26041;&#35328;&#30340;&#26041;&#27861;&#21644;&#38382;&#39064;&#65292;&#24378;&#35843;&#20102;&#26041;&#35328;&#23545;&#20110;NLP&#27169;&#22411;&#24615;&#33021;&#21644;&#35821;&#35328;&#25216;&#26415;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#26041;&#35328;&#30456;&#20851;&#20219;&#21153;&#21644;&#35821;&#35328;&#30340;&#20840;&#38754;&#32508;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#27169;&#22411;&#26159;&#22312;&#22823;&#35268;&#27169;&#35757;&#32451;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#65292;&#24182;&#22312;&#35780;&#20272;&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#26412;&#35843;&#26597;&#25506;&#35752;&#20102;&#36825;&#20123;&#25968;&#25454;&#38598;&#30340;&#19968;&#20010;&#37325;&#35201;&#23646;&#24615;&#65306;&#35821;&#35328;&#26041;&#35328;&#12290;&#32771;&#34385;&#21040;&#38024;&#23545;&#26041;&#35328;&#25968;&#25454;&#38598;&#30340;NLP&#27169;&#22411;&#24615;&#33021;&#19979;&#38477;&#21450;&#20854;&#23545;&#35821;&#35328;&#25216;&#26415;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#26377;&#20851;&#26041;&#35328;NLP&#30340;&#36807;&#21435;&#30740;&#31350;&#65292;&#21253;&#25324;&#25968;&#25454;&#38598;&#21644;&#26041;&#27861;&#12290;&#25105;&#20204;&#20174;&#20004;&#20010;&#31867;&#21035;&#30340;&#35270;&#35282;&#25551;&#36848;&#20102;&#21508;&#31181;NLP&#20219;&#21153;&#65306;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#65288;NLU&#65289;&#65288;&#22914;&#26041;&#35328;&#20998;&#31867;&#12289;&#24773;&#24863;&#20998;&#26512;&#12289;&#35299;&#26512;&#21644;NLU&#22522;&#20934;&#27979;&#35797;&#65289;&#21644;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#65288;NLG&#65289;&#65288;&#22914;&#25688;&#35201;&#12289;&#26426;&#22120;&#32763;&#35793;&#21644;&#23545;&#35805;&#31995;&#32479;&#65289;&#12290;&#36825;&#39033;&#35843;&#26597;&#36824;&#24191;&#27867;&#28085;&#30422;&#20102;&#33521;&#35821;&#12289;&#38463;&#25289;&#20271;&#35821;&#12289;&#24503;&#35821;&#31561;&#22810;&#31181;&#35821;&#35328;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#26377;&#20851;&#26041;&#35328;&#30340;&#36807;&#21435;NLP&#24037;&#20316;&#19981;&#27490;&#20110;&#26041;&#35328;&#20998;&#31867;&#65292;&#32780;&#26159;...
&lt;/p&gt;
&lt;p&gt;
State-of-the-art natural language processing (NLP) models are trained on massive training corpora, and report a superlative performance on evaluation datasets. This survey delves into an important attribute of these datasets: the dialect of a language. Motivated by the performance degradation of NLP models for dialectic datasets and its implications for the equity of language technologies, we survey past research in NLP for dialects in terms of datasets, and approaches. We describe a wide range of NLP tasks in terms of two categories: natural language understanding (NLU) (for tasks such as dialect classification, sentiment analysis, parsing, and NLU benchmarks) and natural language generation (NLG) (for summarisation, machine translation, and dialogue systems). The survey is also broad in its coverage of languages which include English, Arabic, German among others. We observe that past work in NLP concerning dialects goes deeper than mere dialect classification, and . This includes ear
&lt;/p&gt;</description></item><item><title>PORTIA&#26159;&#19968;&#20010;&#26088;&#22312;&#26657;&#20934;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#22120;&#30340;&#20301;&#32622;&#20559;&#24046;&#30340;&#23545;&#40784;&#31995;&#32479;&#65292;&#36890;&#36807;&#23558;&#31572;&#26696;&#20998;&#21106;&#25104;&#22810;&#20010;&#29255;&#27573;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#23545;&#40784;&#65292;&#28982;&#21518;&#23558;&#20854;&#21512;&#24182;&#22238;&#19968;&#20010;&#21333;&#19968;&#30340;&#25552;&#31034;&#65292;&#20197;&#25552;&#39640;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#21644;&#20844;&#27491;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.01432</link><description>&lt;p&gt;
&#20998;&#21106;&#19982;&#21512;&#24182;&#65306;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20301;&#32622;&#20559;&#24046;&#36827;&#34892;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Split and Merge: Aligning Position Biases in Large Language Model based Evaluators. (arXiv:2310.01432v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01432
&lt;/p&gt;
&lt;p&gt;
PORTIA&#26159;&#19968;&#20010;&#26088;&#22312;&#26657;&#20934;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#22120;&#30340;&#20301;&#32622;&#20559;&#24046;&#30340;&#23545;&#40784;&#31995;&#32479;&#65292;&#36890;&#36807;&#23558;&#31572;&#26696;&#20998;&#21106;&#25104;&#22810;&#20010;&#29255;&#27573;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#23545;&#40784;&#65292;&#28982;&#21518;&#23558;&#20854;&#21512;&#24182;&#22238;&#19968;&#20010;&#21333;&#19968;&#30340;&#25552;&#31034;&#65292;&#20197;&#25552;&#39640;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#21644;&#20844;&#27491;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#20316;&#20026;&#33258;&#21160;&#21270;&#35780;&#20272;&#22120;&#65292;&#29992;&#20110;&#35780;&#20272;AI&#31995;&#32479;&#29983;&#25104;&#30340;&#31572;&#26696;&#30340;&#36136;&#37327;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22522;&#20110;LLM&#30340;&#35780;&#20272;&#22120;&#22312;&#20351;&#29992;&#23545;&#27604;&#35780;&#20272;&#20505;&#36873;&#31572;&#26696;&#26102;&#23384;&#22312;&#20301;&#32622;&#20559;&#24046;&#25110;&#19981;&#19968;&#33268;&#24615;&#65292;&#26080;&#35270;&#20869;&#23481;&#32780;&#20559;&#21521;&#20110;&#31532;&#19968;&#20010;&#25110;&#31532;&#20108;&#20010;&#31572;&#26696;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PORTIA&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#23545;&#40784;&#30340;&#31995;&#32479;&#65292;&#26088;&#22312;&#27169;&#25311;&#20154;&#31867;&#30340;&#27604;&#36739;&#31574;&#30053;&#65292;&#20197;&#36731;&#37327;&#32423;&#20294;&#26377;&#25928;&#30340;&#26041;&#24335;&#26657;&#20934;&#20301;&#32622;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;PORTIA&#23558;&#31572;&#26696;&#20998;&#21106;&#25104;&#22810;&#20010;&#29255;&#27573;&#65292;&#23545;&#27604;&#20505;&#36873;&#31572;&#26696;&#20013;&#30340;&#30456;&#20284;&#20869;&#23481;&#36827;&#34892;&#23545;&#40784;&#65292;&#24182;&#23558;&#23427;&#20204;&#21512;&#24182;&#22238;&#19968;&#20010;&#21333;&#19968;&#30340;&#25552;&#31034;&#65292;&#20197;&#20379;LLMs&#35780;&#20272;&#12290;&#25105;&#20204;&#20351;&#29992;&#20845;&#31181;&#19981;&#21516;&#30340;LLM&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#35780;&#20272;&#20102;11,520&#20010;&#31572;&#26696;&#23545;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;PORTIA&#26174;&#33879;&#25552;&#39640;&#20102;&#25152;&#26377;&#27169;&#22411;&#21644;&#23545;&#27604;&#24418;&#24335;&#30340;&#19968;&#33268;&#24615;&#29575;&#65292;&#24179;&#22343;&#30456;&#23545;&#25913;&#36827;&#29575;&#36798;&#21040;47.46%&#12290;&#24341;&#20154;&#27880;&#30446;&#30340;&#26159;&#65292;PORTIA&#20351;&#24471;LLMs&#33021;&#22815;&#35780;&#20272;&#20013;&#23545;&#20301;&#32622;&#20559;&#24046;&#36827;&#34892;&#26657;&#20934;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#21644;&#20844;&#27491;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have shown promise as automated evaluators for assessing the quality of answers generated by AI systems. However, these LLM-based evaluators exhibit position bias, or inconsistency, when used to evaluate candidate answers in pairwise comparisons, favoring either the first or second answer regardless of content. To address this limitation, we propose PORTIA, an alignment-based system designed to mimic human comparison strategies to calibrate position bias in a lightweight yet effective manner. Specifically, PORTIA splits the answers into multiple segments, aligns similar content across candidate answers, and then merges them back into a single prompt for evaluation by LLMs. We conducted extensive experiments with six diverse LLMs to evaluate 11,520 answer pairs. Our results show that PORTIA markedly enhances the consistency rates for all the models and comparison forms tested, achieving an average relative improvement of 47.46%. Remarkably, PORTIA enables le
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#38376;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#37329;&#34701;&#39046;&#22495;&#30693;&#35782;&#19978;&#30340;&#22522;&#20934;FinEval&#12290;&#36890;&#36807;&#22312;FinEval&#19978;&#35780;&#20272;&#20013;&#33521;&#25991;LLMs&#65292;&#32467;&#26524;&#26174;&#31034;&#21482;&#26377;GPT-4&#22312;&#19981;&#21516;&#25552;&#31034;&#35774;&#32622;&#19979;&#23454;&#29616;&#20102;&#25509;&#36817;70%&#30340;&#20934;&#30830;&#29575;&#65292;&#23637;&#31034;&#20102;LLMs&#22312;&#37329;&#34701;&#39046;&#22495;&#30693;&#35782;&#20013;&#30340;&#26174;&#33879;&#22686;&#38271;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.09975</link><description>&lt;p&gt;
FinEval&#65306;&#19968;&#20010;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20013;&#25991;&#37329;&#34701;&#39046;&#22495;&#30693;&#35782;&#35780;&#20272;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models. (arXiv:2308.09975v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19987;&#38376;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#37329;&#34701;&#39046;&#22495;&#30693;&#35782;&#19978;&#30340;&#22522;&#20934;FinEval&#12290;&#36890;&#36807;&#22312;FinEval&#19978;&#35780;&#20272;&#20013;&#33521;&#25991;LLMs&#65292;&#32467;&#26524;&#26174;&#31034;&#21482;&#26377;GPT-4&#22312;&#19981;&#21516;&#25552;&#31034;&#35774;&#32622;&#19979;&#23454;&#29616;&#20102;&#25509;&#36817;70%&#30340;&#20934;&#30830;&#29575;&#65292;&#23637;&#31034;&#20102;LLMs&#22312;&#37329;&#34701;&#39046;&#22495;&#30693;&#35782;&#20013;&#30340;&#26174;&#33879;&#22686;&#38271;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20294;&#26159;&#23427;&#20204;&#22312;&#26356;&#20855;&#25361;&#25112;&#24615;&#21644;&#19987;&#19994;&#39046;&#22495;&#30340;&#20219;&#21153;&#20013;&#30340;&#25928;&#26524;&#23578;&#26410;&#24471;&#21040;&#28145;&#20837;&#30740;&#31350;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;FinEval&#65292;&#36825;&#26159;&#19968;&#20010;&#19987;&#38376;&#20026;LLMs&#20013;&#30340;&#37329;&#34701;&#39046;&#22495;&#30693;&#35782;&#35774;&#35745;&#30340;&#35780;&#20272;&#22522;&#20934;&#12290;FinEval&#26159;&#19968;&#20010;&#21253;&#21547;&#20102;&#37329;&#34701;&#12289;&#32463;&#27982;&#12289;&#20250;&#35745;&#21644;&#35777;&#20070;&#31561;34&#20010;&#23398;&#26415;&#31185;&#30446;&#30340;&#39640;&#36136;&#37327;&#22810;&#39033;&#36873;&#25321;&#39064;&#30340;&#38598;&#21512;&#65292;&#24635;&#35745;&#21253;&#21547;&#20102;4,661&#36947;&#39064;&#30446;&#12290;&#20026;&#20102;&#30830;&#20445;&#23545;&#27169;&#22411;&#24615;&#33021;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#65292;FinEval&#20351;&#29992;&#20102;&#22810;&#31181;&#25552;&#31034;&#31867;&#22411;&#65292;&#21253;&#25324;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#25552;&#31034;&#65292;&#20197;&#21450;&#20165;&#31572;&#26696;&#25552;&#31034;&#21644;&#24605;&#36335;&#38142;&#24335;&#25552;&#31034;&#12290;&#36890;&#36807;&#22312;FinEval&#19978;&#35780;&#20272;&#26368;&#20808;&#36827;&#30340;&#20013;&#25991;&#21644;&#33521;&#25991;LLMs&#65292;&#32467;&#26524;&#26174;&#31034;&#21482;&#26377;GPT-4&#22312;&#19981;&#21516;&#30340;&#25552;&#31034;&#35774;&#32622;&#19979;&#23454;&#29616;&#20102;&#25509;&#36817;70%&#30340;&#20934;&#30830;&#29575;&#65292;&#34920;&#26126;LLMs&#22312;&#37329;&#34701;&#39046;&#22495;&#30693;&#35782;&#20013;&#20855;&#26377;&#26174;&#33879;&#30340;&#22686;&#38271;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#37329;&#34701;&#39046;&#22495;&#30340;&#30693;&#35782;&#35780;&#20272;&#25552;&#20379;&#20102;&#26356;&#20840;&#38754;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have demonstrated exceptional performance in various natural language processing tasks, yet their efficacy in more challenging and domain-specific tasks remains largely unexplored. This paper presents FinEval, a benchmark specifically designed for the financial domain knowledge in the LLMs. FinEval is a collection of high-quality multiple-choice questions covering Finance, Economy, Accounting, and Certificate. It includes 4,661 questions spanning 34 different academic subjects. To ensure a comprehensive model performance evaluation, FinEval employs a range of prompt types, including zero-shot and few-shot prompts, as well as answer-only and chain-of-thought prompts. Evaluating state-of-the-art Chinese and English LLMs on FinEval, the results show that only GPT-4 achieved an accuracy close to 70% in different prompt settings, indicating significant growth potential for LLMs in the financial domain knowledge. Our work offers a more comprehensive financial kno
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#24314;&#31435;&#30340;&#20840;&#32654;&#31038;&#21306;&#35843;&#26597;&#65288;ACS&#65289;&#35780;&#20272;&#20102;&#21313;&#20960;&#20010;&#19981;&#21516;&#22823;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#21457;&#29616;&#23567;&#22411;&#27169;&#22411;&#20855;&#26377;&#26174;&#33879;&#30340;&#20301;&#32622;&#21644;&#26631;&#31614;&#20559;&#24046;&#65292;&#32780;&#27169;&#22411;&#22823;&#23567;&#30340;&#22686;&#21152;&#33021;&#20943;&#36731;&#36825;&#31181;&#20559;&#24046;&#65292;&#20294;&#26080;&#27861;&#26681;&#25454;US&#32676;&#20307;&#25110;&#20219;&#20309;&#21487;&#35782;&#21035;&#30340;&#32676;&#20307;&#36235;&#21183;&#36827;&#34892;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2306.07951</link><description>&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35843;&#26597;&#21709;&#24212;&#30340;&#36136;&#30097;
&lt;/p&gt;
&lt;p&gt;
Questioning the Survey Responses of Large Language Models. (arXiv:2306.07951v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07951
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#24314;&#31435;&#30340;&#20840;&#32654;&#31038;&#21306;&#35843;&#26597;&#65288;ACS&#65289;&#35780;&#20272;&#20102;&#21313;&#20960;&#20010;&#19981;&#21516;&#22823;&#23567;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#21457;&#29616;&#23567;&#22411;&#27169;&#22411;&#20855;&#26377;&#26174;&#33879;&#30340;&#20301;&#32622;&#21644;&#26631;&#31614;&#20559;&#24046;&#65292;&#32780;&#27169;&#22411;&#22823;&#23567;&#30340;&#22686;&#21152;&#33021;&#20943;&#36731;&#36825;&#31181;&#20559;&#24046;&#65292;&#20294;&#26080;&#27861;&#26681;&#25454;US&#32676;&#20307;&#25110;&#20219;&#20309;&#21487;&#35782;&#21035;&#30340;&#32676;&#20307;&#36235;&#21183;&#36827;&#34892;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#22686;&#24378;&#65292;&#30740;&#31350;&#20154;&#21592;&#24320;&#22987;&#20197;&#21508;&#31181;&#31185;&#23398;&#21160;&#26426;&#23545;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#35843;&#26597;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#24050;&#32463;&#24314;&#31435;&#30340;&#20840;&#32654;&#31038;&#21306;&#35843;&#26597;&#65288;ACS&#65289;&#65292;&#23601;&#27169;&#22411;&#30340;&#35843;&#26597;&#21709;&#24212;&#32467;&#26524;&#25506;&#31350;&#25152;&#33021;&#20102;&#35299;&#30340;&#20869;&#23481;&#12290;&#25105;&#20204;&#23545;&#21313;&#20960;&#20010;&#19981;&#21516;&#22823;&#23567;&#30340;&#27169;&#22411;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#21442;&#25968;&#33539;&#22260;&#20174;&#20960;&#20159;&#21040;&#19968;&#19975;&#20159;&#19981;&#31561;&#65292;&#20351;&#29992;ACS&#30340;&#38382;&#39064;&#36827;&#34892;&#20102;&#25968;&#21313;&#19975;&#27425;&#30340;&#27979;&#35797;&#65292;&#31995;&#32479;&#22320;&#24471;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#27169;&#24335;&#12290;&#39318;&#20808;&#65292;&#23567;&#22411;&#27169;&#22411;&#23384;&#22312;&#26126;&#26174;&#30340;&#20301;&#32622;&#21644;&#26631;&#31614;&#20559;&#24046;&#65292;&#20363;&#22914;&#20559;&#21521;&#20110;&#37319;&#29992;&#26631;&#35760;&#20026;&#8220;A&#8221;&#30340;&#35843;&#26597;&#21709;&#24212;&#12290;&#38543;&#30528;&#27169;&#22411;&#23610;&#23544;&#30340;&#22686;&#21152;&#65292;A-&#20559;&#24046;&#34429;&#28982;&#26377;&#25152;&#20943;&#23569;&#65292;&#20294;&#20063;&#36827;&#23637;&#32531;&#24930;&#12290;&#20854;&#27425;&#65292;&#21363;&#20351;&#36890;&#36807;&#38543;&#26426;&#31572;&#26696;&#39034;&#24207;&#26469;&#35843;&#25972;&#36825;&#31181;&#26631;&#35760;&#20559;&#24046;&#65292;&#27169;&#22411;&#20173;&#28982;&#19981;&#20250;&#36235;&#21521;&#20110;&#32654;&#22269;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#25110;&#20219;&#20309;&#21487;&#35782;&#21035;&#30340;&#20154;&#21475;&#25490;&#24207;&#12290;&#30456;&#21453;&#65292;&#21508;&#31181;&#27169;&#22411;&#36235;&#21521;&#20110;&#22343;&#21248;&#38543;&#26426;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
As large language models increase in capability, researchers have started to conduct surveys of all kinds on these models with varying scientific motivations. In this work, we examine what we can learn from a model's survey responses on the basis of the well-established American Community Survey (ACS) by the U.S. Census Bureau. Evaluating more than a dozen different models, varying in size from a few hundred million to ten billion parameters, hundreds of thousands of times each on questions from the ACS, we systematically establish two dominant patterns. First, smaller models have a significant position and labeling bias, for example, towards survey responses labeled with the letter "A". This A-bias diminishes, albeit slowly, as model size increases. Second, when adjusting for this labeling bias through randomized answer ordering, models still do not trend toward US population statistics or those of any cognizable population. Rather, models across the board trend toward uniformly rando
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#33258;&#21160;&#26631;&#27880;&#25991;&#26412;&#30340;&#28508;&#21147;&#65292;&#37325;&#28857;&#32771;&#23519;&#20102;&#20174;&#26412;&#22320;&#35821;&#27861;&#35282;&#24230;&#35266;&#23519;&#36947;&#27465;&#35328;&#35821;&#34892;&#20026;&#26500;&#25104;&#30340;&#21151;&#33021;&#20803;&#32032;&#30340;&#31243;&#24230;&#65292;&#24182;&#27604;&#36739;&#20102;&#19981;&#21516;&#27169;&#22411;&#22312;&#27880;&#37322;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#32467;&#26524;&#34920;&#26126;Bing&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;ChatGPT&#21644;&#20154;&#31867;&#26631;&#27880;&#21592;&#12290;</title><link>http://arxiv.org/abs/2305.08339</link><description>&lt;p&gt;
&#20351;&#29992;LLM&#36741;&#21161;&#27880;&#37322;&#36827;&#34892;&#35821;&#26009;&#24211;&#35821;&#35328;&#23398;&#30740;&#31350;&#65306;&#26412;&#22320;&#35821;&#27861;&#20998;&#26512;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Using LLM-assisted Annotation for Corpus Linguistics: A Case Study of Local Grammar Analysis. (arXiv:2305.08339v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#33258;&#21160;&#26631;&#27880;&#25991;&#26412;&#30340;&#28508;&#21147;&#65292;&#37325;&#28857;&#32771;&#23519;&#20102;&#20174;&#26412;&#22320;&#35821;&#27861;&#35282;&#24230;&#35266;&#23519;&#36947;&#27465;&#35328;&#35821;&#34892;&#20026;&#26500;&#25104;&#30340;&#21151;&#33021;&#20803;&#32032;&#30340;&#31243;&#24230;&#65292;&#24182;&#27604;&#36739;&#20102;&#19981;&#21516;&#27169;&#22411;&#22312;&#27880;&#37322;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#65292;&#32467;&#26524;&#34920;&#26126;Bing&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;ChatGPT&#21644;&#20154;&#31867;&#26631;&#27880;&#21592;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#35821;&#35328;&#29702;&#35299;&#26041;&#38754;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;LLMs&#22312;&#21327;&#21161;&#22522;&#20110;&#35821;&#26009;&#24211;&#30340;&#35821;&#35328;&#23398;&#30740;&#31350;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#36890;&#36807;&#23558;&#25991;&#26412;&#33258;&#21160;&#26631;&#27880;&#20026;&#29305;&#23450;&#35821;&#35328;&#20449;&#24687;&#31867;&#21035;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#26412;&#22320;&#35821;&#27861;&#30340;&#35282;&#24230;&#35266;&#23519;&#36947;&#27465;&#35328;&#35821;&#34892;&#20026;&#26500;&#25104;&#30340;&#21151;&#33021;&#20803;&#32032;&#30340;&#31243;&#24230;&#65292;&#36890;&#36807;&#27604;&#36739;&#22522;&#20110;GPT-3.5&#30340;ChatGPT&#12289;&#22522;&#20110;GPT-4&#30340;Bing&#32842;&#22825;&#26426;&#22120;&#20154;&#21644;&#20154;&#31867;&#32534;&#30721;&#22120;&#22312;&#27880;&#37322;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;Bing&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#20219;&#21153;&#20013;&#34920;&#29616;&#26174;&#30528;&#20248;&#20110;ChatGPT&#12290;&#19982;&#20154;&#31867;&#26631;&#27880;&#21592;&#30456;&#27604;&#65292;Bing&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#25972;&#20307;&#34920;&#29616;&#30053;&#20302;&#20110;&#20154;&#31867;&#26631;&#27880;&#21592;&#30340;&#34920;&#29616;&#65292;&#20294;&#24050;&#32463;&#21462;&#24471;&#20102;&#36739;&#39640;&#30340;F1&#24471;&#20998;:&#36947;&#27465;&#26631;&#35760;99.95&#65285;&#65292;&#21407;&#22240;&#26631;&#35760;91.91&#65285;&#65292;&#36947;&#27465;&#32773;&#26631;&#35760;95.35&#65285;&#65292;&#34987;&#36947;&#27465;&#32773;&#26631;&#35760;89.74&#65285;&#21644;&#21152;&#24378;&#26631;&#35760;96.47&#65285;&#12290;&#36825;&#34920;&#26126;&#65292;&#22312;&#35821;&#35328;&#31867;&#21035;&#28165;&#26224;&#19988;&#21487;&#20197;&#36731;&#26494;&#35782;&#21035;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;LLM&#36741;&#21161;&#27880;&#37322;&#36827;&#34892;&#35821;&#26009;&#24211;&#35821;&#35328;&#23398;&#30740;&#31350;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Chatbots based on Large Language Models (LLMs) have shown strong capabilities in language understanding. In this study, we explore the potential of LLMs in assisting corpus-based linguistic studies through automatic annotation of texts with specific categories of linguistic information. Specifically, we examined to what extent LLMs understand the functional elements constituting the speech act of apology from a local grammar perspective, by comparing the performance of ChatGPT (powered by GPT-3.5), the Bing chatbot (powered by GPT-4), and a human coder in the annotation task. The results demonstrate that the Bing chatbot significantly outperformed ChatGPT in the task. Compared to human annotator, the overall performance of the Bing chatbot was slightly less satisfactory. However, it already achieved high F1 scores: 99.95% for the tag of APOLOGISING, 91.91% for REASON, 95.35% for APOLOGISER, 89.74% for APOLOGISEE, and 96.47% for INTENSIFIER. This suggests that it is feasible to use LLM-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#35821;&#35328;&#25511;&#21046;&#25193;&#25955;&#27169;&#22411;&#30340;&#20998;&#23618;&#35268;&#21010;&#22120;&#65292;&#26377;&#25928;&#32780;&#39640;&#25928;&#22320;&#25193;&#23637;&#25193;&#25955;&#27169;&#22411;&#65292;&#35299;&#20915;&#38271;&#26102;&#38388;&#36328;&#24230;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#19979;&#30340;&#25511;&#21046;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#21333;&#20219;&#21153;&#21644;&#22810;&#20219;&#21153;&#25104;&#21151;&#29575;&#65292;&#24182;&#26497;&#22823;&#22320;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2210.15629</link><description>&lt;p&gt;
&#35821;&#35328;&#25511;&#21046;&#25193;&#25955;&#65306;&#36890;&#36807;&#31354;&#38388;&#12289;&#26102;&#38388;&#21644;&#20219;&#21153;&#39640;&#25928;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks. (arXiv:2210.15629v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15629
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#35821;&#35328;&#25511;&#21046;&#25193;&#25955;&#27169;&#22411;&#30340;&#20998;&#23618;&#35268;&#21010;&#22120;&#65292;&#26377;&#25928;&#32780;&#39640;&#25928;&#22320;&#25193;&#23637;&#25193;&#25955;&#27169;&#22411;&#65292;&#35299;&#20915;&#38271;&#26102;&#38388;&#36328;&#24230;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#19979;&#30340;&#25511;&#21046;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#36739;&#39640;&#30340;&#21333;&#20219;&#21153;&#21644;&#22810;&#20219;&#21153;&#25104;&#21151;&#29575;&#65292;&#24182;&#26497;&#22823;&#22320;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#36890;&#29992;&#22411;&#26234;&#33021;&#20307;&#22312;&#21508;&#20010;&#26041;&#38754;&#37117;&#24456;&#22256;&#38590;&#65292;&#38656;&#35201;&#22788;&#29702;&#39640;&#32500;&#36755;&#20837;&#65288;&#31354;&#38388;&#65289;&#12289;&#38271;&#26102;&#38388;&#36328;&#24230;&#65288;&#26102;&#38388;&#65289;&#21644;&#22810;&#20010;&#26032;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#32467;&#26500;&#26041;&#38754;&#30340;&#36827;&#23637;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#27839;&#30528;&#20854;&#20013;&#19968;&#20010;&#25110;&#20004;&#20010;&#32500;&#24230;&#25552;&#39640;&#25193;&#23637;&#24615;&#33021;&#21147;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#20173;&#28982;&#24456;&#39640;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#35821;&#35328;&#25511;&#21046;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#26465;&#20214;&#30340;&#20998;&#23618;&#35268;&#21010;&#22120;&#65288;LCD&#65289;&#26469;&#24212;&#23545;&#36825;&#19977;&#20010;&#26041;&#38754;&#12290;&#25105;&#20204;&#26377;&#25928;&#32780;&#39640;&#25928;&#22320;&#25193;&#23637;&#25193;&#25955;&#27169;&#22411;&#65292;&#20197;&#24212;&#23545;&#26102;&#38388;&#12289;&#29366;&#24577;&#21644;&#20219;&#21153;&#31354;&#38388;&#32500;&#24230;&#30340;&#38271;&#26102;&#38388;&#36328;&#24230;&#25511;&#21046;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;CALVIN&#35821;&#35328;&#26426;&#22120;&#20154;&#22522;&#20934;&#27979;&#35797;&#20013;&#23558;LCD&#19982;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#65292;&#21457;&#29616;LCD&#22312;&#22810;&#20219;&#21153;&#25104;&#21151;&#29575;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#32780;&#21333;&#20219;&#21153;&#25104;&#21151;&#29575;&#65288;SR&#65289;&#20026;88.7%&#65292;&#36828;&#39640;&#20110;&#20197;&#21069;&#30340;&#26368;&#20339;&#25104;&#32489;82.6%&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training generalist agents is difficult across several axes, requiring us to deal with high-dimensional inputs (space), long horizons (time), and multiple and new tasks. Recent advances with architectures have allowed for improved scaling along one or two of these dimensions, but are still prohibitive computationally. In this paper, we propose to address all three axes by leveraging Language to Control Diffusion models as a hierarchical planner conditioned on language (LCD). We effectively and efficiently scale diffusion models for planning in extended temporal, state, and task dimensions to tackle long horizon control problems conditioned on natural language instructions. We compare LCD with other state-of-the-art models on the CALVIN language robotics benchmark and find that LCD outperforms other SOTA methods in multi task success rates while dramatically improving computational efficiency with a single task success rate (SR) of 88.7% against the previous best of 82.6%. We show that 
&lt;/p&gt;</description></item></channel></rss>