<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36923;&#36753;&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;ChatGPT&#22312;&#22768;&#26126;&#39564;&#35777;&#20013;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#22312;&#24402;&#32435;&#25512;&#29702;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10735</link><description>&lt;p&gt;
&#22312;&#22768;&#26126;&#39564;&#35777;&#30340;&#32972;&#26223;&#19979;&#35780;&#20272;ChatGPT&#30340;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10735
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36923;&#36753;&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;ChatGPT&#22312;&#22768;&#26126;&#39564;&#35777;&#20013;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#22312;&#24402;&#32435;&#25512;&#29702;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32531;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#26377;&#20851;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#30340;&#36777;&#35770;&#27491;&#22312;&#26085;&#30410;&#28608;&#28872;&#12290;&#25105;&#20204;&#20174;&#22768;&#26126;/&#35875;&#35328;&#39564;&#35777;&#30340;&#35282;&#24230;&#26469;&#23457;&#35270;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#36923;&#36753;&#25512;&#29702;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;&#20219;&#20309;&#22768;&#26126;&#25110;&#20256;&#35328;&#19982;&#35777;&#25454;&#32467;&#21512;&#65292;&#25286;&#20998;&#25104;&#39564;&#35777;&#25152;&#38656;&#30340;&#22522;&#26412;&#25512;&#29702;&#27493;&#39588;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#25972;&#29702;&#20102;&#20004;&#20010;&#27880;&#37322;&#38598;&#21512;&#65292;&#20854;&#20013;&#21253;&#25324;&#26469;&#33258;&#32500;&#22522;&#30334;&#31185;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#28304;&#33258;Twitter&#19978;&#27969;&#20256;&#30340;&#35875;&#35328;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#20351;&#29992;&#23427;&#20204;&#26469;&#35780;&#20272;GPT-3.5-Turbo&#21644;GPT-4&#65288;&#20197;&#19979;&#31616;&#31216;&#20026;ChatGPT&#65289;&#22312;&#25105;&#20204;&#26694;&#26550;&#30340;&#32972;&#26223;&#19979;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#25552;&#20379;&#20102;&#24443;&#24213;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;ChatGPT&#22312;&#24402;&#32435;&#25512;&#29702;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#23613;&#31649;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#25163;&#21160;&#30340;&#24605;&#32500;&#38142;&#36335;&#65288;Chain of Thought&#65292;CoT&#65289;&#26469;&#32531;&#35299;&#36825;&#19968;&#38382;&#39064;&#65292;&#32780;&#38750;&#38646;&#32534;&#30721;&#65288;Zero Shot&#65292;ZS&#65289;&#21644;ZS CoT&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26377;&#21161;&#20110;&#19981;&#26029;&#22686;&#38271;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#34920;&#26126;Cha
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10735v1 Announce Type: new  Abstract: The reasoning capabilities of LLMs are currently hotly debated. We examine the issue from the perspective of claim/rumour verification. We propose the first logical reasoning framework designed to break down any claim or rumor paired with evidence into the atomic reasoning steps necessary for verification. Based on our framework, we curate two annotated collections of such claim/evidence pairs: a synthetic dataset from Wikipedia and a real-world set stemming from rumours circulating on Twitter. We use them to evaluate the reasoning capabilities of GPT-3.5-Turbo and GPT-4 (hereinafter referred to as ChatGPT) within the context of our framework, providing a thorough analysis. Our results show that ChatGPT struggles in abductive reasoning, although this can be somewhat mitigated by using manual Chain of Thought (CoT) as opposed to Zero Shot (ZS) and ZS CoT approaches. Our study contributes to the growing body of research suggesting that Cha
&lt;/p&gt;</description></item></channel></rss>