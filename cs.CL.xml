<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22312;&#25688;&#35201;&#19968;&#33268;&#24615;&#35780;&#20272;&#26041;&#38754;&#65292;&#35813;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#20020;&#24202;&#25991;&#26412;&#25688;&#35201;&#30340;&#25968;&#25454;&#38598;TreatFact&#24182;&#23545;11&#20010;&#22823;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35780;&#20272;&#65292;&#22635;&#34917;&#20102;&#20851;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#25688;&#35201;&#20107;&#23454;&#19968;&#33268;&#24615;&#35780;&#20272;&#26041;&#38754;&#30340;&#32570;&#21475;&#12290;</title><link>https://arxiv.org/abs/2402.13758</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#20013;&#25688;&#35201;&#30340;&#20107;&#23454;&#19968;&#33268;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Factual Consistency Evaluation of Summarisation in the Era of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13758
&lt;/p&gt;
&lt;p&gt;
&#22312;&#25688;&#35201;&#19968;&#33268;&#24615;&#35780;&#20272;&#26041;&#38754;&#65292;&#35813;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#20020;&#24202;&#25991;&#26412;&#25688;&#35201;&#30340;&#25968;&#25454;&#38598;TreatFact&#24182;&#23545;11&#20010;&#22823;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35780;&#20272;&#65292;&#22635;&#34917;&#20102;&#20851;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#25688;&#35201;&#20107;&#23454;&#19968;&#33268;&#24615;&#35780;&#20272;&#26041;&#38754;&#30340;&#32570;&#21475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#29983;&#25104;&#25688;&#35201;&#20013;&#19982;&#28304;&#25991;&#20214;&#30340;&#20107;&#23454;&#19981;&#19968;&#33268;&#21487;&#33021;&#23548;&#33268;&#38169;&#35823;&#20449;&#24687;&#25110;&#24102;&#26469;&#39118;&#38505;&#12290;&#29616;&#26377;&#30340;&#20107;&#23454;&#19968;&#33268;&#24615;&#65288;FC&#65289;&#24230;&#37327;&#21463;&#21040;&#20854;&#24615;&#33021;&#12289;&#25928;&#29575;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#38480;&#21046;&#12290;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#22312;&#25991;&#26412;&#35780;&#20272;&#26041;&#38754;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#28508;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;&#35780;&#20272;&#25688;&#35201;&#20013;&#30340;FC&#26041;&#38754;&#30340;&#25928;&#26524;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#19987;&#26377;LLMs&#19978;&#65292;&#26410;&#25506;&#35752;&#24433;&#21709;&#23427;&#20204;&#35780;&#20272;&#33021;&#21147;&#30340;&#37325;&#35201;&#22240;&#32032;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#30340;FC&#35780;&#20272;&#22522;&#20934;&#20165;&#38480;&#20110;&#26032;&#38395;&#25991;&#31456;&#65292;&#23545;&#22312;&#20854;&#19978;&#27979;&#35797;&#30340;FC&#26041;&#27861;&#30340;&#26222;&#36941;&#24615;&#20135;&#29983;&#24576;&#30097;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#24341;&#20837;TreatFact&#25968;&#25454;&#38598;&#35299;&#20915;&#36825;&#19968;&#24046;&#36317;&#65292;&#35813;&#25968;&#25454;&#38598;&#21253;&#21547;&#30001;&#39046;&#22495;&#19987;&#23478;&#27880;&#37322;&#30340;&#20020;&#24202;&#25991;&#26412;&#30340;LLM&#29983;&#25104;&#25688;&#35201;&#30340;FC&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#26032;&#38395;&#21644;&#20020;&#24202;&#39046;&#22495;&#20013;&#20026;FC&#35780;&#20272;&#23545;&#27604;&#20102;11&#20010;LLMs&#65292;&#24182;&#20998;&#26512;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13758v1 Announce Type: new  Abstract: Factual inconsistency with source documents in automatically generated summaries can lead to misinformation or pose risks. Existing factual consistency(FC) metrics are constrained by their performance, efficiency, and explainability. Recent advances in Large language models (LLMs) have demonstrated remarkable potential in text evaluation but their effectiveness in assessing FC in summarisation remains underexplored. Prior research has mostly focused on proprietary LLMs, leaving essential factors that affect their assessment capabilities unexplored. Additionally, current FC evaluation benchmarks are restricted to news articles, casting doubt on the generality of the FC methods tested on them. In this paper, we first address the gap by introducing TreatFact a dataset of LLM-generated summaries of clinical texts, annotated for FC by domain experts. Moreover, we benchmark 11 LLMs for FC evaluation across news and clinical domains and analyse
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#35874;&#33778;&#23572;&#24503;&#22823;&#23398;&#30340;&#26426;&#22120;&#32763;&#35793;&#26041;&#27861;&#65292;&#25104;&#21151;&#22312;AmericasNLP&#26426;&#22120;&#32763;&#35793;&#22303;&#33879;&#35821;&#35328;&#20998;&#20139;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#39640;&#30340;&#24179;&#22343;chrF&#65292;&#20854;&#20013;&#22312;Aymara&#65292;Guarani&#21644;Quechua&#26041;&#38754;&#26377;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2306.09830</link><description>&lt;p&gt;
&#35874;&#33778;&#23572;&#24503;&#22823;&#23398;&#25552;&#20132;&#32473;AmericasNLP&#26426;&#22120;&#32763;&#35793;&#22303;&#33879;&#35821;&#35328;&#20998;&#20139;&#20219;&#21153;&#30340;&#35770;&#25991;&#65288;arXiv: 2306.09830v1 [cs.CL]&#65289;
&lt;/p&gt;
&lt;p&gt;
Sheffield's Submission to the AmericasNLP Shared Task on Machine Translation into Indigenous Languages. (arXiv:2306.09830v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09830
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#35874;&#33778;&#23572;&#24503;&#22823;&#23398;&#30340;&#26426;&#22120;&#32763;&#35793;&#26041;&#27861;&#65292;&#25104;&#21151;&#22312;AmericasNLP&#26426;&#22120;&#32763;&#35793;&#22303;&#33879;&#35821;&#35328;&#20998;&#20139;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#39640;&#30340;&#24179;&#22343;chrF&#65292;&#20854;&#20013;&#22312;Aymara&#65292;Guarani&#21644;Quechua&#26041;&#38754;&#26377;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#35874;&#33778;&#23572;&#24503;&#22823;&#23398;&#25552;&#20132;&#32473;AmericasNLP 2023&#26426;&#22120;&#32763;&#35793;&#22303;&#33879;&#35821;&#35328;&#20998;&#20139;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#35813;&#20219;&#21153;&#21253;&#25324;&#23558;&#35199;&#29677;&#29273;&#35821;&#32763;&#35793;&#25104;&#21313;&#19968;&#31181;&#22303;&#33879;&#35821;&#35328;&#12290; &#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#25193;&#23637;&#65292;&#35757;&#32451;&#21644;&#19982;&#19981;&#21516;&#31181;&#31867;&#30340;NLLB-200&#32452;&#21512;&#12290; &#25105;&#20204;&#20351;&#29992;&#32452;&#32455;&#32773;&#25552;&#20379;&#30340;&#25968;&#25454;&#20197;&#21450;&#23466;&#27861;&#65292;&#25163;&#20876;&#65292;&#26032;&#38395;&#25991;&#31456;&#21644;&#20174;&#21333;&#35821;&#25968;&#25454;&#29983;&#25104;&#30340;&#22238;&#35793;&#31561;&#21508;&#31181;&#20854;&#20182;&#26469;&#28304;&#30340;&#25968;&#25454;&#12290; &#22312;&#24320;&#21457;&#38598;&#19978;&#65292;&#25105;&#20204;&#30340;&#26368;&#20339;&#25104;&#32489;&#22312;&#25152;&#26377;&#35821;&#35328;&#30340;&#24179;&#22343;chrF&#19978;&#27604;&#22522;&#32447;&#25552;&#39640;&#20102;11&#65285;&#65292;&#23588;&#20854;&#26159;&#22312;Aymara&#65292;Guarani&#21644;Quechua&#26041;&#38754;&#26377;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290; &#22312;&#27979;&#35797;&#38598;&#19978;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#25152;&#26377;&#25552;&#20132;&#20013;&#26368;&#39640;&#30340;&#24179;&#22343;chrF&#65292;&#25105;&#20204;&#22312;11&#31181;&#35821;&#35328;&#20013;&#25490;&#21517;&#21069;&#22235;&#20301;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#33267;&#23569;&#19968;&#20010;&#25552;&#20132;&#22312;&#25152;&#26377;&#35821;&#35328;&#20013;&#25490;&#21517;&#21069;&#19977;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we describe the University of Sheffield's submission to the AmericasNLP 2023 Shared Task on Machine Translation into Indigenous Languages which comprises the translation from Spanish to eleven indigenous languages. Our approach consists of extending, training, and ensembling different variations of NLLB-200. We use data provided by the organizers and data from various other sources such as constitutions, handbooks, news articles, and backtranslations generated from monolingual data. On the dev set, our best submission outperforms the baseline by 11% average chrF across all languages, with substantial improvements particularly for Aymara, Guarani and Quechua. On the test set, we achieve the highest average chrF of all the submissions, we rank first in four of the eleven languages, and at least one of our submissions ranks in the top 3 for all languages.
&lt;/p&gt;</description></item></channel></rss>