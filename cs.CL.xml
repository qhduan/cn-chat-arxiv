<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#20013;&#23545;&#19981;&#21512;&#29702;&#24615;&#30340;&#21453;&#24212;&#65292;&#35774;&#35745;&#20102;&#19981;&#21512;&#29702;&#25968;&#23398;&#38382;&#39064;&#22522;&#20934;&#20197;&#21450;&#20851;&#38190;&#35745;&#31639;&#21644;&#32467;&#35770;&#25552;&#31034;&#27169;&#26495;&#65292;&#25552;&#21319;&#20102;&#23427;&#20204;&#22312;&#38169;&#35823;&#26816;&#27979;&#21644;&#20462;&#27491;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.19346</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#38382;&#39064;&#20013;&#23545;&#19981;&#21512;&#29702;&#24615;&#27627;&#26080;&#24847;&#35782;
&lt;/p&gt;
&lt;p&gt;
Large Language Models Are Unconscious of Unreasonability in Math Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19346
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#20013;&#23545;&#19981;&#21512;&#29702;&#24615;&#30340;&#21453;&#24212;&#65292;&#35774;&#35745;&#20102;&#19981;&#21512;&#29702;&#25968;&#23398;&#38382;&#39064;&#22522;&#20934;&#20197;&#21450;&#20851;&#38190;&#35745;&#31639;&#21644;&#32467;&#35770;&#25552;&#31034;&#27169;&#26495;&#65292;&#25552;&#21319;&#20102;&#23427;&#20204;&#22312;&#38169;&#35823;&#26816;&#27979;&#21644;&#20462;&#27491;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23637;&#31034;&#20102;&#22312;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26041;&#38754;&#30340;&#24040;&#22823;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#32473;&#20986;&#21253;&#21547;&#19981;&#21512;&#29702;&#38169;&#35823;&#30340;&#38382;&#39064;&#26102;&#65292;&#23427;&#20204;&#20542;&#21521;&#20110;&#20135;&#29983;&#24187;&#35273;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#22312;&#38754;&#23545;&#19981;&#21512;&#29702;&#25968;&#23398;&#38382;&#39064;&#26102;&#30340;&#34892;&#20026;&#65292;&#24182;&#36827;&#19968;&#27493;&#25506;&#35752;&#20102;&#23427;&#20204;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19981;&#21512;&#29702;&#25968;&#23398;&#38382;&#39064;(UMP)&#22522;&#20934;&#26469;&#26816;&#26597;LLMs&#30340;&#38169;&#35823;&#26816;&#27979;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;LLMs&#33021;&#22815;&#26816;&#27979;&#21040;&#19981;&#21512;&#29702;&#38169;&#35823;&#65292;&#20294;&#20173;&#28982;&#22312;&#29983;&#25104;&#38750;&#24187;&#35273;&#20869;&#23481;&#26041;&#38754;&#22833;&#36133;&#12290;&#20026;&#20102;&#25913;&#21892;&#23427;&#20204;&#30340;&#38169;&#35823;&#26816;&#27979;&#21644;&#20462;&#27491;&#33021;&#21147;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35774;&#35745;&#20102;&#19968;&#31181;&#31216;&#20026;&#20851;&#38190;&#35745;&#31639;&#21644;&#32467;&#35770;(CCC)&#30340;&#25112;&#30053;&#25552;&#31034;&#27169;&#26495;&#12290;&#36890;&#36807;CCC&#65292;LLMs&#21487;&#20197;&#26356;&#22909;&#22320;&#33258;&#25105;&#35780;&#20272;&#24182;&#26816;&#27979;&#25968;&#23398;&#38382;&#39064;&#20013;&#30340;&#19981;&#21512;&#29702;&#38169;&#35823;&#65292;&#20351;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013;&#26356;&#21487;&#38752;&#21644;&#23433;&#20840;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19346v1 Announce Type: new  Abstract: Large language models (LLMs) demonstrate substantial capabilities in solving math problems. However, they tend to produce hallucinations when given questions containing unreasonable errors. In this paper, we study the behavior of LLMs when faced with unreasonable math problems and further explore their potential to address these problems. First, we construct the Unreasonable Math Problem (UMP) benchmark to examine the error detection ability of LLMs. Experiments show that LLMs are able to detect unreasonable errors, but still fail in generating non-hallucinatory content. In order to improve their ability of error detection and correction, we further design a strategic prompt template called Critical Calculation and Conclusion(CCC). With CCC, LLMs can better self-evaluate and detect unreasonable errors in math questions, making them more reliable and safe in practical application scenarios.
&lt;/p&gt;</description></item><item><title>&#36882;&#24402;&#24635;&#32467;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#38271;&#26399;&#23545;&#35805;&#35760;&#24518;&#65292;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#31995;&#32479;&#22312;&#38271;&#23545;&#35805;&#20013;&#35760;&#24518;&#37325;&#35201;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.15022</link><description>&lt;p&gt;
&#36882;&#24402;&#24635;&#32467;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#38271;&#26399;&#23545;&#35805;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models. (arXiv:2308.15022v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15022
&lt;/p&gt;
&lt;p&gt;
&#36882;&#24402;&#24635;&#32467;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#38271;&#26399;&#23545;&#35805;&#35760;&#24518;&#65292;&#21487;&#20197;&#25552;&#39640;&#23545;&#35805;&#31995;&#32479;&#22312;&#38271;&#23545;&#35805;&#20013;&#35760;&#24518;&#37325;&#35201;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24320;&#25918;&#39046;&#22495;&#30340;&#23545;&#35805;&#31995;&#32479;&#22312;&#38271;&#26399;&#23545;&#35805;&#20013;&#23481;&#26131;&#36951;&#24536;&#37325;&#35201;&#20449;&#24687;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#35757;&#32451;&#29305;&#23450;&#30340;&#26816;&#32034;&#22120;&#25110;&#24635;&#32467;&#22120;&#20174;&#36807;&#21435;&#33719;&#21462;&#20851;&#38190;&#20449;&#24687;&#65292;&#36825;&#38656;&#35201;&#32791;&#36153;&#26102;&#38388;&#19988;&#39640;&#24230;&#20381;&#36182;&#26631;&#35760;&#25968;&#25454;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36882;&#24402;&#29983;&#25104;&#24635;&#32467;/&#35760;&#24518;&#65292;&#20197;&#22686;&#24378;&#38271;&#26399;&#35760;&#24518;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#21050;&#28608;LLMs&#35760;&#20303;&#23567;&#23545;&#35805;&#19978;&#19979;&#25991;&#65292;&#28982;&#21518;&#36882;&#24402;&#22320;&#20351;&#29992;&#20043;&#21069;&#30340;&#35760;&#24518;&#21644;&#38543;&#21518;&#30340;&#23545;&#35805;&#20869;&#23481;&#20135;&#29983;&#26032;&#30340;&#35760;&#24518;&#12290;&#26368;&#21518;&#65292;LLM&#21487;&#20197;&#22312;&#26368;&#26032;&#35760;&#24518;&#30340;&#24110;&#21161;&#19979;&#36731;&#26494;&#29983;&#25104;&#39640;&#24230;&#19968;&#33268;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#20351;&#29992;ChatGPT&#21644;text-davinci-003&#36827;&#34892;&#35780;&#20272;&#65292;&#23545;&#24191;&#27867;&#20351;&#29992;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#38271;&#23545;&#35805;&#20013;&#21487;&#20197;&#29983;&#25104;&#26356;&#19968;&#33268;&#30340;&#21709;&#24212;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#23454;&#29616;LLM&#24314;&#27169;&#30340;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most open-domain dialogue systems suffer from forgetting important information, especially in a long-term conversation. Existing works usually train the specific retriever or summarizer to obtain key information from the past, which is time-consuming and highly depends on the quality of labeled data. To alleviate this problem, we propose to recursively generate summaries/ memory using large language models (LLMs) to enhance long-term memory ability. Specifically, our method first stimulates LLMs to memorize small dialogue contexts and then recursively produce new memory using previous memory and following contexts. Finally, the LLM can easily generate a highly consistent response with the help of the latest memory. We evaluate our method using ChatGPT and text-davinci-003, and the experiments on the widely-used public dataset show that our method can generate more consistent responses in a long-context conversation. Notably, our method is a potential solution to enable the LLM to model
&lt;/p&gt;</description></item></channel></rss>