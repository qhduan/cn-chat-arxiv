<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>DE$^3$-BERT&#26159;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#32593;&#32476;&#21644;&#36317;&#31163;&#24230;&#37327;&#30340;&#22686;&#24378;&#36317;&#31163;&#26089;&#26399;&#20572;&#27490;&#26694;&#26550;&#65292;&#29992;&#20110;&#25552;&#39640;BERT&#31561;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#26029;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05948</link><description>&lt;p&gt;
DE$^3$-BERT: &#22522;&#20110;&#21407;&#22411;&#32593;&#32476;&#30340;&#22686;&#24378;&#36317;&#31163;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#65292;&#29992;&#20110;BERT
&lt;/p&gt;
&lt;p&gt;
DE$^3$-BERT: Distance-Enhanced Early Exiting for BERT based on Prototypical Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05948
&lt;/p&gt;
&lt;p&gt;
DE$^3$-BERT&#26159;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#32593;&#32476;&#21644;&#36317;&#31163;&#24230;&#37327;&#30340;&#22686;&#24378;&#36317;&#31163;&#26089;&#26399;&#20572;&#27490;&#26694;&#26550;&#65292;&#29992;&#20110;&#25552;&#39640;BERT&#31561;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#26029;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#25191;&#34892;&#30340;&#23618;&#25968;&#65292;&#25552;&#39640;&#20102;&#20687;BERT&#36825;&#26679;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#26029;&#36895;&#24230;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#20165;&#32771;&#34385;&#20102;&#26469;&#33258;&#21333;&#20010;&#27979;&#35797;&#26679;&#26412;&#30340;&#23616;&#37096;&#20449;&#24687;&#26469;&#30830;&#23450;&#26089;&#26399;&#20572;&#27490;&#30340;&#25351;&#26631;&#65292;&#32780;&#26410;&#21033;&#29992;&#26679;&#26412;&#32676;&#20307;&#25552;&#20379;&#30340;&#20840;&#23616;&#20449;&#24687;&#12290;&#36825;&#23548;&#33268;&#23545;&#39044;&#27979;&#27491;&#30830;&#24615;&#30340;&#20272;&#35745;&#19981;&#22815;&#20934;&#30830;&#65292;&#20174;&#32780;&#20135;&#29983;&#38169;&#35823;&#30340;&#26089;&#26399;&#20572;&#27490;&#20915;&#31574;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#26377;&#25928;&#32467;&#21512;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#20197;&#30830;&#20445;&#21487;&#38752;&#30340;&#26089;&#26399;&#20572;&#27490;&#30340;&#24517;&#35201;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#21033;&#29992;&#21407;&#22411;&#32593;&#32476;&#23398;&#20064;&#31867;&#21035;&#21407;&#22411;&#65292;&#24182;&#35774;&#35745;&#20102;&#26679;&#26412;&#21644;&#31867;&#21035;&#21407;&#22411;&#20043;&#38388;&#30340;&#36317;&#31163;&#24230;&#37327;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#20840;&#23616;&#20449;&#24687;&#26469;&#20272;&#35745;&#26089;&#26399;&#39044;&#27979;&#30340;&#27491;&#30830;&#24615;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;DE$^3$-BERT&#22686;&#24378;&#36317;&#31163;&#26089;&#26399;&#20572;&#27490;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Early exiting has demonstrated its effectiveness in accelerating the inference of pre-trained language models like BERT by dynamically adjusting the number of layers executed. However, most existing early exiting methods only consider local information from an individual test sample to determine their exiting indicators, failing to leverage the global information offered by sample population. This leads to suboptimal estimation of prediction correctness, resulting in erroneous exiting decisions. To bridge the gap, we explore the necessity of effectively combining both local and global information to ensure reliable early exiting during inference. Purposefully, we leverage prototypical networks to learn class prototypes and devise a distance metric between samples and class prototypes. This enables us to utilize global information for estimating the correctness of early predictions. On this basis, we propose a novel Distance-Enhanced Early Exiting framework for BERT (DE$^3$-BERT). DE$^3
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#22797;&#26434;&#24615;&#21644;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#25216;&#26415;HouYi&#65292;&#24182;&#25581;&#31034;&#20102;&#24212;&#29992;&#31243;&#24207;&#25552;&#31034;&#26426;&#21046;&#20013;&#20197;&#21069;&#26410;&#30693;&#21644;&#20005;&#37325;&#20302;&#20272;&#30340;&#28431;&#27934;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21628;&#21505;&#36827;&#19968;&#27493;&#24320;&#21457;&#20840;&#38754;&#30340;&#38450;&#24481;&#25514;&#26045;&#65292;&#20197;&#25269;&#24481;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;</title><link>http://arxiv.org/abs/2306.05499</link><description>&lt;p&gt;
LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Prompt Injection attack against LLM-integrated Applications. (arXiv:2306.05499v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#22797;&#26434;&#24615;&#21644;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#25216;&#26415;HouYi&#65292;&#24182;&#25581;&#31034;&#20102;&#24212;&#29992;&#31243;&#24207;&#25552;&#31034;&#26426;&#21046;&#20013;&#20197;&#21069;&#26410;&#30693;&#21644;&#20005;&#37325;&#20302;&#20272;&#30340;&#28431;&#27934;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21628;&#21505;&#36827;&#19968;&#27493;&#24320;&#21457;&#20840;&#38754;&#30340;&#38450;&#24481;&#25514;&#26045;&#65292;&#20197;&#25269;&#24481;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#22240;&#20854;&#21331;&#36234;&#30340;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#32780;&#22312;&#23427;&#20204;&#21608;&#22260;&#21050;&#28608;&#20102;&#19968;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#24212;&#29992;&#29983;&#24577;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#21508;&#31181;&#26381;&#21153;&#20013;&#30340;&#24191;&#27867;&#34701;&#21512;&#24102;&#26469;&#20102;&#37325;&#22823;&#30340;&#23433;&#20840;&#39118;&#38505;&#12290;&#26412;&#30740;&#31350;&#23558;&#35299;&#26500;&#23454;&#38469;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#22797;&#26434;&#24615;&#21644;&#24433;&#21709;&#12290;&#26368;&#21021;&#65292;&#25105;&#20204;&#23545;&#21313;&#20010;&#21830;&#19994;&#24212;&#29992;&#31243;&#24207;&#36827;&#34892;&#20102;&#25506;&#32034;&#24615;&#20998;&#26512;&#65292;&#31361;&#20986;&#20102;&#30446;&#21069;&#25915;&#20987;&#31574;&#30053;&#22312;&#23454;&#36341;&#20013;&#30340;&#32422;&#26463;&#26465;&#20214;&#12290;&#21463;&#36825;&#20123;&#38480;&#21046;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#38543;&#21518;&#21046;&#23450;&#20102;HouYi&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#40657;&#30418;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#25216;&#26415;&#65292;&#23427;&#20511;&#37492;&#20102;&#20256;&#32479;&#30340;Web&#27880;&#20837;&#25915;&#20987;&#12290;HouYi&#20998;&#20026;&#19977;&#20010;&#20851;&#38190;&#20803;&#32032;: &#19968;&#20010;&#26080;&#32541;&#38598;&#25104;&#30340;&#39044;&#26500;&#24314;&#25552;&#31034;&#12289;&#19968;&#20010;&#27880;&#20837;&#25552;&#31034;&#35825;&#23548;&#19978;&#19979;&#25991;&#20998;&#21306;&#20197;&#21450;&#19968;&#20010;&#24694;&#24847;&#36733;&#33655;&#65292;&#26088;&#22312;&#23454;&#29616;&#25915;&#20987;&#30446;&#26631;&#12290;&#21033;&#29992;HouYi&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#24212;&#29992;&#31243;&#24207;&#25552;&#31034;&#26426;&#21046;&#20013;&#20197;&#21069;&#26410;&#30693;&#21644;&#20005;&#37325;&#20302;&#20272;&#30340;&#28431;&#27934;&#65292;&#24182;&#28436;&#31034;&#20102;&#32469;&#36807;&#26368;&#20808;&#36827;&#30340;&#26816;&#27979;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21628;&#21505;&#36827;&#19968;&#27493;&#30740;&#31350;&#24320;&#21457;&#20840;&#38754;&#30340;&#38450;&#24481;&#25514;&#26045;&#65292;&#20197;&#25269;&#24481;LLM&#38598;&#25104;&#24212;&#29992;&#20013;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and sev
&lt;/p&gt;</description></item></channel></rss>