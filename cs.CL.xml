<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#36328;&#27169;&#24577;&#30693;&#35782;&#33976;&#39311;&#21644;LLMs&#23545;&#40784;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#38745;&#24577;&#21644;&#21160;&#24577;&#30693;&#35782;&#65292;&#20805;&#20998;&#37322;&#25918;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#28508;&#21147;</title><link>https://arxiv.org/abs/2403.07300</link><description>&lt;p&gt;
&#36890;&#36807;&#36328;&#27169;&#24577;&#30693;&#35782;&#33976;&#39311;&#25511;&#21046;&#39044;&#35757;&#32451;LLMs&#36827;&#34892;&#24191;&#20041;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Taming Pre-trained LLMs for Generalised Time Series Forecasting via Cross-modal Knowledge Distillation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07300
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36328;&#27169;&#24577;&#30693;&#35782;&#33976;&#39311;&#21644;LLMs&#23545;&#40784;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#38745;&#24577;&#21644;&#21160;&#24577;&#30693;&#35782;&#65292;&#20805;&#20998;&#37322;&#25918;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26368;&#36817;&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#24555;&#36895;&#22686;&#38271;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#26377;&#38480;&#30340;&#26102;&#38388;&#25968;&#25454;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#27169;&#22411;&#65292;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#27867;&#21270;&#12290;&#26368;&#36817;&#65292;&#38543;&#30528;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#28608;&#22686;&#65292;&#19968;&#20123;&#24037;&#20316;&#23581;&#35797;&#23558;LLMs&#24341;&#20837;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#30452;&#25509;&#23558;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;LLMs&#30340;&#36755;&#20837;&#65292;&#24573;&#30053;&#20102;&#26102;&#38388;&#21644;&#25991;&#26412;&#25968;&#25454;&#20043;&#38388;&#22266;&#26377;&#30340;&#27169;&#24577;&#24046;&#36317;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#26102;&#38388;&#24207;&#21015;&#23545;&#40784;&#26694;&#26550;&#65292;&#31216;&#20026;LLaTA&#65292;&#20197;&#20805;&#20998;&#21457;&#25381;LLMs&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#25361;&#25112;&#20013;&#30340;&#28508;&#21147;&#12290;&#22522;&#20110;&#36328;&#27169;&#24577;&#30693;&#35782;&#33976;&#39311;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#39044;&#35757;&#32451;LLMs&#20013;&#30340;&#36755;&#20837;&#26080;&#20851;&#38745;&#24577;&#30693;&#35782;&#21644;&#36755;&#20837;&#30456;&#20851;&#21160;&#24577;&#30693;&#35782;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#35813;&#26041;&#27861;&#20026;&#39044;&#27979;&#27169;&#22411;&#36171;&#33021;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07300v1 Announce Type: cross  Abstract: Multivariate time series forecasting has recently gained great success with the rapid growth of deep learning models. However, existing approaches usually train models from scratch using limited temporal data, preventing their generalization. Recently, with the surge of the Large Language Models (LLMs), several works have attempted to introduce LLMs into time series forecasting. Despite promising results, these methods directly take time series as the input to LLMs, ignoring the inherent modality gap between temporal and text data. In this work, we propose a novel Large Language Models and time series alignment framework, dubbed LLaTA, to fully unleash the potentials of LLMs in the time series forecasting challenge. Based on cross-modal knowledge distillation, the proposed method exploits both input-agnostic static knowledge and input-dependent dynamic knowledge in pre-trained LLMs. In this way, it empowers the forecasting model with f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#35780;&#20272;&#20102;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#65292;&#25351;&#20986;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#20173;&#26377;&#24453;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.04963</link><description>&lt;p&gt;
&#22312;&#22522;&#20110;&#38169;&#35823;&#30340;&#20154;&#31867;&#35780;&#20272;&#20013;&#28145;&#20837;&#35780;&#20272;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#35780;&#20272;&#20102;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#65292;&#25351;&#20986;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#20173;&#26377;&#24453;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21477;&#23376;&#31616;&#21270;&#26159;&#19968;&#31181;&#37325;&#20889;&#21477;&#23376;&#20197;&#20415;&#26356;&#26131;&#38405;&#35835;&#21644;&#29702;&#35299;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#24110;&#21161;&#26377;&#21508;&#31181;&#38405;&#35835;&#38590;&#39064;&#30340;&#20154;&#26469;&#35828;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;&#38543;&#30528;&#20808;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20852;&#36215;&#65292;&#35780;&#20272;&#23427;&#20204;&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#21464;&#24471;&#36843;&#22312;&#30473;&#30571;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21033;&#29992;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26469;&#35780;&#20272;LLMs&#30340;&#31616;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#35780;&#20272;&#26041;&#27861;&#23545;LLMs&#22312;&#31616;&#21270;&#35780;&#20272;&#20013;&#30340;&#36866;&#29992;&#24615;&#20173;&#28982;&#23384;&#22312;&#30097;&#38382;&#12290;&#39318;&#20808;&#65292;&#29616;&#26377;&#33258;&#21160;&#25351;&#26631;&#22312;LLMs&#30340;&#31616;&#21270;&#35780;&#20272;&#20013;&#30340;&#36866;&#29992;&#24615;&#20173;&#19981;&#30830;&#23450;&#12290;&#20854;&#27425;&#65292;&#24403;&#21069;&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#36890;&#24120;&#38519;&#20837;&#20004;&#20010;&#26497;&#31471;&#65306;&#35201;&#20040;&#36807;&#20110;&#32932;&#27973;&#65292;&#26080;&#27861;&#28165;&#26224;&#29702;&#35299;&#27169;&#22411;&#30340;&#34920;&#29616;&#65292;&#35201;&#20040;&#36807;&#20110;&#35814;&#32454;&#65292;&#20351;&#27880;&#37322;&#36807;&#31243;&#22797;&#26434;&#19988;&#23481;&#26131;&#20986;&#29616;&#19981;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#24433;&#21709;&#35780;&#20272;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04963v1 Announce Type: cross  Abstract: Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs' simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models' performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation's reliabil
&lt;/p&gt;</description></item></channel></rss>