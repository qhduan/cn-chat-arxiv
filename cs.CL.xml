<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>DeAL&#26159;&#19968;&#20010;&#20801;&#35768;&#29992;&#25143;&#33258;&#23450;&#20041;&#22870;&#21169;&#20989;&#25968;&#24182;&#23454;&#29616;&#35299;&#30721;&#26102;&#23545;&#40784;LLMs&#30340;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2402.06147</link><description>&lt;p&gt;
DeAL&#65306;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35299;&#30721;&#26102;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
DeAL: Decoding-time Alignment for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06147
&lt;/p&gt;
&lt;p&gt;
DeAL&#26159;&#19968;&#20010;&#20801;&#35768;&#29992;&#25143;&#33258;&#23450;&#20041;&#22870;&#21169;&#20989;&#25968;&#24182;&#23454;&#29616;&#35299;&#30721;&#26102;&#23545;&#40784;LLMs&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29616;&#22312;&#26399;&#26395;&#29983;&#25104;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#30340;&#20869;&#23481;&#12290;&#30446;&#21069;&#30340;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#27169;&#22411;&#35757;&#32451;&#26102;&#38388;&#23545;&#40784;&#19978;&#65292;&#36890;&#36807;&#35832;&#22914;&#24378;&#21270;&#23398;&#20064;&#19982;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#31561;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#19981;&#28165;&#26970;&#36825;&#20123;&#26041;&#27861;&#26159;&#21542;&#26377;&#25928;&#22320;&#25945;&#23548;&#27169;&#22411;&#23545;&#40784;&#30446;&#26631;&#12290;&#39318;&#20808;&#65292;&#26080;&#27861;&#25972;&#21512;&#22810;&#20010;&#33258;&#23450;&#20041;&#22870;&#21169;&#21644;&#20381;&#36182;&#27169;&#22411;&#24320;&#21457;&#32773;&#23545;&#36890;&#29992;&#21644;&#38745;&#24577;&#21407;&#21017;&#30340;&#29702;&#35299;&#26159;&#20027;&#35201;&#23616;&#38480;&#12290;&#20854;&#27425;&#65292;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#27531;&#30041;&#24046;&#36317;&#20197;&#21450;&#36825;&#20123;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#20063;&#20540;&#24471;&#36136;&#30097;&#65288;&#20363;&#22914;&#65292;&#21363;&#20351;&#22312;&#23433;&#20840;&#35757;&#32451;&#21518;&#20173;&#28982;&#23481;&#26131;&#34987;&#36234;&#29425;&#65289;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DeAL&#65292;&#19968;&#20010;&#20801;&#35768;&#29992;&#25143;&#33258;&#23450;&#20041;&#22870;&#21169;&#20989;&#25968;&#24182;&#23454;&#29616;&#35299;&#30721;&#26102;&#23545;&#40784;LLMs&#65288;DeAL&#65289;&#30340;&#26694;&#26550;&#12290;&#26680;&#24515;&#24605;&#24819;&#22312;&#20110;&#23558;&#35299;&#30721;&#35270;&#20026;&#19968;&#20010;&#21551;&#21457;&#24335;&#24341;&#23548;&#30340;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#20419;&#20351;&#20351;&#29992;&#21508;&#31181;&#23545;&#40784;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20197;&#32534;&#31243;&#32422;&#26463;&#20026;&#20363;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are nowadays expected to generate content aligned with human preferences. Current work focuses on alignment at model training time, through techniques such as Reinforcement Learning with Human Feedback (RLHF). However, it is unclear if such methods are an effective choice to teach alignment objectives to the model. First, the inability to incorporate multiple, custom rewards and reliance on a model developer's view of universal and static principles are key limitations. Second, the residual gaps in model training and the reliability of such approaches are also questionable (e.g. susceptibility to jail-breaking even after safety training). To address these, we propose DeAL, a framework that allows the user to customize reward functions and enables Decoding-time Alignment of LLMs (DeAL). At its core, we view decoding as a heuristic-guided search process and facilitate the use of a wide variety of alignment objectives. Our experiments with programmatic constra
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35843;&#26597;&#20102;&#25945;&#32946;&#39046;&#22495;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#24635;&#32467;&#20102;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2401.07518</link><description>&lt;p&gt;
&#25945;&#32946;&#39046;&#22495;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#35843;&#26597;&#65306;&#20998;&#31867;&#20307;&#31995;&#12289;&#31995;&#32479;&#32508;&#36848;&#21644;&#26410;&#26469;&#36235;&#21183;
&lt;/p&gt;
&lt;p&gt;
Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.07518
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35843;&#26597;&#20102;&#25945;&#32946;&#39046;&#22495;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#24635;&#32467;&#20102;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#26088;&#22312;&#36890;&#36807;&#35745;&#31639;&#26426;&#31185;&#23398;&#39046;&#22495;&#30340;&#25216;&#26415;&#20998;&#26512;&#25991;&#26412;&#65292;&#24212;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#12289;&#21830;&#19994;&#21644;&#25945;&#32946;&#39046;&#22495;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#25945;&#32946;&#39046;&#22495;&#65292;NLP&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#25945;&#23398;&#21644;&#23398;&#20064;&#26041;&#38754;&#30340;&#24110;&#21161;&#12290;&#26412;&#35843;&#26597;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#35299;&#20915;&#19982;&#25945;&#32946;&#39046;&#22495;&#30456;&#20851;&#30340;&#38382;&#39064;&#65292;&#24182;&#22238;&#39038;&#20102;NLP&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20174;&#20171;&#32461;&#30456;&#20851;&#32972;&#26223;&#24320;&#22987;&#65292;&#28982;&#21518;&#25552;&#20986;&#25945;&#32946;&#39046;&#22495;NLP&#30340;&#20998;&#31867;&#31995;&#32479;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#26681;&#25454;&#19978;&#36848;&#20998;&#31867;&#31995;&#32479;&#35828;&#26126;&#20219;&#21153;&#23450;&#20041;&#12289;&#25361;&#25112;&#21644;&#30456;&#24212;&#30340;&#25216;&#26415;&#12290;&#20043;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#39046;&#22495;&#20013;&#30340;&#19968;&#20123;&#29616;&#26377;&#28436;&#31034;&#65292;&#24182;&#24635;&#32467;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural Language Processing (NLP) aims to analyze the text via techniques in the computer science field. It serves the applications in healthcare, commerce, and education domains. Particularly, NLP has been applied to the education domain to help teaching and learning. In this survey, we review recent advances in NLP with a focus on solving problems related to the education domain. In detail, we begin with introducing the relevant background. Then, we present the taxonomy of NLP in the education domain. Next, we illustrate the task definition, challenges, and corresponding techniques based on the above taxonomy. After that, we showcase some off-the-shelf demonstrations in this domain and conclude with future directions.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#39318;&#27425;&#23558;&#27597;&#35821;&#35782;&#21035;&#24212;&#29992;&#20110;&#22303;&#32819;&#20854;&#35821;,&#36890;&#36807;&#20998;&#26512;&#20316;&#32773;&#19981;&#21516;&#35821;&#35328;&#30340;&#20889;&#20316;&#26469;&#39044;&#27979;&#20316;&#32773;&#30340;&#27597;&#35821;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#22303;&#32819;&#20854;&#23398;&#20064;&#32773;&#35821;&#26009;&#24211;&#21644;&#19977;&#20010;&#21477;&#27861;&#29305;&#24449;&#26469;&#23637;&#31034;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.14850</link><description>&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#39318;&#27425;&#23558;&#27597;&#35821;&#35782;&#21035;&#65288;Native Language Identification&#65292;NLI&#65289;&#24212;&#29992;&#20110;&#22303;&#32819;&#20854;&#35821;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Turkish Native Language Identification. (arXiv:2307.14850v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14850
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#39318;&#27425;&#23558;&#27597;&#35821;&#35782;&#21035;&#24212;&#29992;&#20110;&#22303;&#32819;&#20854;&#35821;,&#36890;&#36807;&#20998;&#26512;&#20316;&#32773;&#19981;&#21516;&#35821;&#35328;&#30340;&#20889;&#20316;&#26469;&#39044;&#27979;&#20316;&#32773;&#30340;&#27597;&#35821;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#22303;&#32819;&#20854;&#23398;&#20064;&#32773;&#35821;&#26009;&#24211;&#21644;&#19977;&#20010;&#21477;&#27861;&#29305;&#24449;&#26469;&#23637;&#31034;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23558;&#27597;&#35821;&#35782;&#21035;&#65288;NLI&#65289;&#24212;&#29992;&#20110;&#22303;&#32819;&#20854;&#35821;&#12290;NLI &#26159;&#36890;&#36807;&#20998;&#26512;&#20316;&#32773;&#19981;&#21516;&#35821;&#35328;&#30340;&#20889;&#20316;&#26469;&#39044;&#27979;&#20316;&#32773;&#30340;&#27597;&#35821;&#12290;&#23613;&#31649;&#22823;&#22810;&#25968;NLI&#30740;&#31350;&#37117;&#20391;&#37325;&#20110;&#33521;&#35821;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#23558;&#20854;&#33539;&#22260;&#25193;&#23637;&#21040;&#22303;&#32819;&#20854;&#35821;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#26368;&#36817;&#26500;&#24314;&#30340;&#22303;&#32819;&#20854;&#23398;&#20064;&#32773;&#35821;&#26009;&#24211;&#65292;&#24182;&#32467;&#21512;&#20102;&#19977;&#20010;&#21477;&#27861;&#29305;&#24449;&#65288;CFG &#20135;&#29983;&#35268;&#21017;&#65292;&#35789;&#24615;n-gram&#21644;&#20989;&#25968;&#35789;&#65289;&#19982;L2&#25991;&#26412;&#65292;&#20197;&#23637;&#31034;&#23427;&#20204;&#22312;&#35813;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present the first application of Native Language Identification (NLI) for the Turkish language. NLI involves predicting the writer's first language by analysing their writing in different languages. While most NLI research has focused on English, our study extends its scope to Turkish. We used the recently constructed Turkish Learner Corpus and employed a combination of three syntactic features (CFG production rules, part-of-speech n-grams and function words) with L2 texts to demonstrate their effectiveness in this task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;Distantly-Supervised Named Entity Recognition&#20013;&#38169;&#35823;&#21644;&#19981;&#23436;&#25972;&#26631;&#27880;&#22122;&#22768;&#30340;&#20998;&#31163;&#31574;&#30053;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22411;&#26500;&#24314;&#26469;&#24212;&#23545;&#20004;&#31181;&#31867;&#22411;&#30340;&#22122;&#22768;&#12290;</title><link>http://arxiv.org/abs/2305.04076</link><description>&lt;p&gt;
SANTA&#65306;Distantly-Supervised Named Entity Recognition&#20013;&#22788;&#29702;&#38169;&#35823;&#21644;&#19981;&#23436;&#25972;&#26631;&#27880;&#22122;&#22768;&#30340;&#20998;&#31163;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition. (arXiv:2305.04076v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;Distantly-Supervised Named Entity Recognition&#20013;&#38169;&#35823;&#21644;&#19981;&#23436;&#25972;&#26631;&#27880;&#22122;&#22768;&#30340;&#20998;&#31163;&#31574;&#30053;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22411;&#26500;&#24314;&#26469;&#24212;&#23545;&#20004;&#31181;&#31867;&#22411;&#30340;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36828;&#31243;&#30417;&#30563;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#26377;&#25928;&#22320;&#20943;&#36731;&#20102;&#30417;&#30563;&#35774;&#32622;&#20013;&#32791;&#26102;&#19988;&#26114;&#36149;&#30340;&#27880;&#37322;&#36127;&#25285;&#65292;&#20294;&#26159;&#26080;&#19978;&#19979;&#25991;&#30340;&#21305;&#37197;&#36807;&#31243;&#21644;&#30693;&#35782;&#24211;&#30340;&#26377;&#38480;&#35206;&#30422;&#24341;&#20837;&#20102;&#19981;&#20934;&#30830;&#21644;&#19981;&#23436;&#25972;&#30340;&#26631;&#27880;&#22122;&#38899;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#19981;&#21516;&#30340;&#31574;&#30053;&#26469;&#22788;&#29702;&#20004;&#31181;&#31867;&#22411;&#30340;&#22122;&#22768;&#30340;SANTA&#65292;&#20197;&#35299;&#20915;&#30001;&#19981;&#20934;&#30830;&#21644;&#19981;&#23436;&#25972;&#26631;&#27880;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distantly-Supervised Named Entity Recognition effectively alleviates the burden of time-consuming and expensive annotation in the supervised setting. But the context-free matching process and the limited coverage of knowledge bases introduce inaccurate and incomplete annotation noise respectively. Previous studies either considered only incomplete annotation noise or indiscriminately handle two types of noise with the same strategy. In this paper, we argue that the different causes of two types of noise bring up the requirement of different strategies in model architecture. Therefore, we propose the SANTA to handle these two types of noise separately with (1) Memory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity problem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate decision boundary shifting problem caused by incomplete annotation and a noise-tolerant loss to improve the robustness. Benefiting from our separate tailored strategies, we co
&lt;/p&gt;</description></item></channel></rss>