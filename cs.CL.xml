<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21046;&#31070;&#32463;&#25512;&#29702;&#22120;&#32500;&#25252;&#25191;&#34892;&#36712;&#36857;&#20316;&#20026;&#26377;&#38480;&#39044;&#23450;&#20041;&#29366;&#24577;&#32452;&#21512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#31639;&#27861;&#29366;&#24577;&#36716;&#25442;&#30340;&#30417;&#30563;&#35757;&#32451;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#19982;&#21407;&#22987;&#31639;&#27861;&#23436;&#32654;&#23545;&#40784;&#65292;&#24182;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#23436;&#32654;&#30340;&#27979;&#35797;&#25104;&#32489;&#12290;</title><link>https://arxiv.org/abs/2402.11628</link><description>&lt;p&gt;
&#31163;&#25955;&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Discrete Neural Algorithmic Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11628
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21046;&#31070;&#32463;&#25512;&#29702;&#22120;&#32500;&#25252;&#25191;&#34892;&#36712;&#36857;&#20316;&#20026;&#26377;&#38480;&#39044;&#23450;&#20041;&#29366;&#24577;&#32452;&#21512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#31639;&#27861;&#29366;&#24577;&#36716;&#25442;&#30340;&#30417;&#30563;&#35757;&#32451;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#19982;&#21407;&#22987;&#31639;&#27861;&#23436;&#32654;&#23545;&#40784;&#65292;&#24182;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#23436;&#32654;&#30340;&#27979;&#35797;&#25104;&#32489;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#26088;&#22312;&#36890;&#36807;&#23398;&#20064;&#27169;&#20223;&#32463;&#20856;&#31639;&#27861;&#30340;&#25191;&#34892;&#26469;&#25429;&#25417;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#35745;&#31639;&#12290;&#23613;&#31649;&#24120;&#35265;&#30340;&#26550;&#26500;&#36275;&#22815;&#34920;&#36798;&#27491;&#30830;&#30340;&#27169;&#22411;&#22312;&#26435;&#37325;&#31354;&#38388;&#20013;&#65292;&#20294;&#24403;&#21069;&#30340;&#31070;&#32463;&#25512;&#29702;&#22120;&#22312;&#22788;&#29702;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#26102;&#38754;&#20020;&#27867;&#21270;&#22256;&#38590;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#32463;&#20856;&#35745;&#31639;&#19981;&#21463;&#20998;&#24067;&#21464;&#21270;&#30340;&#24433;&#21709;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#25551;&#36848;&#20026;&#31163;&#25955;&#35745;&#31639;&#29366;&#24577;&#20043;&#38388;&#30340;&#36716;&#25442;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24378;&#21046;&#31070;&#32463;&#25512;&#29702;&#22120;&#23558;&#25191;&#34892;&#36712;&#36857;&#20316;&#20026;&#26377;&#38480;&#39044;&#23450;&#20041;&#29366;&#24577;&#30340;&#32452;&#21512;&#36827;&#34892;&#32500;&#25252;&#12290;&#36890;&#36807;&#23545;&#31639;&#27861;&#29366;&#24577;&#36716;&#25442;&#30340;&#30417;&#30563;&#35757;&#32451;&#65292;&#36825;&#31181;&#27169;&#22411;&#33021;&#22815;&#19982;&#21407;&#22987;&#31639;&#27861;&#23436;&#32654;&#23545;&#40784;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#22312;SALSA-CLRS&#22522;&#20934;&#27979;&#35797;&#19978;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#22312;&#37027;&#37324;&#25105;&#20204;&#20026;&#25152;&#26377;&#20219;&#21153;&#33719;&#24471;&#20102;&#23436;&#32654;&#30340;&#27979;&#35797;&#25104;&#32489;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#26550;&#26500;&#36873;&#25321;&#20351;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11628v1 Announce Type: new  Abstract: Neural algorithmic reasoning aims to capture computations with neural networks via learning the models to imitate the execution of classical algorithms. While common architectures are expressive enough to contain the correct model in the weights space, current neural reasoners are struggling to generalize well on out-of-distribution data. On the other hand, classical computations are not affected by distribution shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. Trained with supervision on the algorithm's state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on the SALSA-CLRS benchmark, where we get perfect test scores for all tasks. Moreover, the proposed architectural choice allows us to prove the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25991;&#26723;&#32423;&#31471;&#21040;&#31471;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#26143;&#32423;&#35780;&#20998;&#26631;&#31614;&#65292;&#23454;&#29616;&#26041;&#38754;&#26816;&#27979;&#12289;&#24773;&#24863;&#20998;&#26512;&#21644;&#35780;&#20998;&#39044;&#27979;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.01710</link><description>&lt;p&gt;
&#26143;&#36784;&#21363;&#20320;&#25152;&#38656;&#65306;&#29992;&#36828;&#31243;&#30417;&#30563;&#37329;&#23383;&#22612;&#32593;&#32476;&#36827;&#34892;&#25991;&#26723;&#32423;&#31471;&#21040;&#31471;&#24773;&#24863;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Stars Are All You Need: A Distantly Supervised Pyramid Network for Document-Level End-to-End Sentiment Analysis. (arXiv:2305.01710v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25991;&#26723;&#32423;&#31471;&#21040;&#31471;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#26143;&#32423;&#35780;&#20998;&#26631;&#31614;&#65292;&#23454;&#29616;&#26041;&#38754;&#26816;&#27979;&#12289;&#24773;&#24863;&#20998;&#26512;&#21644;&#35780;&#20998;&#39044;&#27979;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25991;&#26723;&#32423;&#31471;&#21040;&#31471;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26143;&#32423;&#35780;&#20998;&#26631;&#31614;&#23545;&#22312;&#32447;&#35780;&#35770;&#20013;&#34920;&#36798;&#30340;&#26041;&#38754;&#21644;&#35780;&#35770;&#24773;&#24863;&#36827;&#34892;&#26377;&#25928;&#30340;&#32479;&#19968;&#20998;&#26512;&#12290;&#25105;&#20204;&#20551;&#35774;&#26143;&#32423;&#35780;&#20998;&#26631;&#31614;&#26159;&#35780;&#35770;&#20013;&#21508;&#26041;&#38754;&#35780;&#20998;&#30340;&#8220;&#31895;&#31890;&#24230;&#32508;&#21512;&#8221;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36828;&#31243;&#30417;&#30563;&#30340;&#37329;&#23383;&#22612;&#32593;&#32476;&#65288;DSPN&#65289;&#65292;&#21482;&#29992;&#25991;&#26723;&#26143;&#32423;&#35780;&#20998;&#26631;&#31614;&#36827;&#34892;&#35757;&#32451;&#65292;&#21363;&#21487;&#26377;&#25928;&#22320;&#25191;&#34892;&#26041;&#38754;-&#31867;&#21035;&#26816;&#27979;&#12289;&#26041;&#38754;-&#31867;&#21035;&#24773;&#24863;&#20998;&#26512;&#21644;&#35780;&#20998;&#39044;&#27979;&#12290;&#36890;&#36807;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#25191;&#34892;&#36825;&#19977;&#20010;&#30456;&#20851;&#30340;&#24773;&#24863;&#23376;&#20219;&#21153;&#65292;DSPN&#21487;&#20197;&#25552;&#21462;&#35780;&#35770;&#20013;&#25552;&#21040;&#30340;&#26041;&#38754;&#65292;&#30830;&#23450;&#30456;&#24212;&#30340;&#24773;&#24863;&#65292;&#24182;&#39044;&#27979;&#26143;&#32423;&#35780;&#20998;&#26631;&#31614;&#12290;&#25105;&#20204;&#22312;&#33521;&#25991;&#21644;&#27721;&#35821;&#22810;&#26041;&#38754;&#35780;&#35770;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;DSPN&#65292;&#21457;&#29616;&#20165;&#20351;&#29992;&#26143;&#32423;&#35780;&#20998;&#26631;&#31614;&#36827;&#34892;&#30417;&#30563;&#65292;DSPN&#30340;&#24615;&#33021;&#19982;&#21508;&#31181;&#22522;&#20934;&#27169;&#22411;&#30456;&#24403;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;DSPN&#22312;&#35780;&#35770;&#19978;&#30340;&#21487;&#35299;&#37322;&#24615;&#36755;&#20986;&#65292;&#20197;&#35828;&#26126;&#37329;&#23383;&#22612;&#32593;&#32476;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose document-level end-to-end sentiment analysis to efficiently understand aspect and review sentiment expressed in online reviews in a unified manner. In particular, we assume that star rating labels are a "coarse-grained synthesis" of aspect ratings across in the review. We propose a Distantly Supervised Pyramid Network (DSPN) to efficiently perform Aspect-Category Detection, Aspect-Category Sentiment Analysis, and Rating Prediction using only document star rating labels for training. By performing these three related sentiment subtasks in an end-to-end manner, DSPN can extract aspects mentioned in the review, identify the corresponding sentiments, and predict the star rating labels. We evaluate DSPN on multi-aspect review datasets in English and Chinese and find that with only star rating labels for supervision, DSPN can perform comparably well to a variety of benchmark models. We also demonstrate the interpretability of DSPN's outputs on reviews to show the py
&lt;/p&gt;</description></item></channel></rss>