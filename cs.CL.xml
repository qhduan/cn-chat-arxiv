<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#21010;-&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#34920;&#26684;&#19978;&#30340;&#21477;&#23376;&#32972;&#26223;&#20013;&#22238;&#31572;&#29992;&#25143;&#26597;&#35810;&#65292;&#36890;&#36807;&#23545;Llama-2-7B&#36827;&#34892;&#24494;&#35843;&#65292;&#26500;&#24314;&#20102;ProTrix&#27169;&#22411;&#65292;&#24191;&#27867;&#36866;&#29992;&#20110;&#19981;&#21516;&#34920;&#26684;&#20219;&#21153;&#65292;&#24182;&#34920;&#29616;&#20986;&#19982;GPT-3.5-turbo&#30456;&#24403;&#30340;&#24615;&#33021;&#27700;&#24179;&#65292;&#21487;&#29983;&#25104;&#20934;&#30830;&#19988;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2403.02177</link><description>&lt;p&gt;
ProTrix: &#20351;&#29992;&#21477;&#23376;&#32972;&#26223;&#26500;&#24314;&#29992;&#20110;&#35268;&#21010;&#21644;&#25512;&#29702;&#34920;&#26684;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02177
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#21010;-&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#34920;&#26684;&#19978;&#30340;&#21477;&#23376;&#32972;&#26223;&#20013;&#22238;&#31572;&#29992;&#25143;&#26597;&#35810;&#65292;&#36890;&#36807;&#23545;Llama-2-7B&#36827;&#34892;&#24494;&#35843;&#65292;&#26500;&#24314;&#20102;ProTrix&#27169;&#22411;&#65292;&#24191;&#27867;&#36866;&#29992;&#20110;&#19981;&#21516;&#34920;&#26684;&#20219;&#21153;&#65292;&#24182;&#34920;&#29616;&#20986;&#19982;GPT-3.5-turbo&#30456;&#24403;&#30340;&#24615;&#33021;&#27700;&#24179;&#65292;&#21487;&#29983;&#25104;&#20934;&#30830;&#19988;&#24544;&#23454;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#65292;&#34920;&#26684;&#22312;&#20256;&#36798;&#20449;&#24687;&#26041;&#38754;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#26159;&#32452;&#32455;&#21644;&#21576;&#29616;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#19981;&#21487;&#25110;&#32570;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#21010;-&#25512;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#22238;&#31572;&#24102;&#26377;&#21477;&#23376;&#32972;&#26223;&#30340;&#34920;&#26684;&#19978;&#30340;&#19981;&#21516;&#31867;&#22411;&#30340;&#29992;&#25143;&#26597;&#35810;&#12290;&#35813;&#26694;&#26550;&#39318;&#20808;&#35268;&#21010;&#19978;&#19979;&#25991;&#20013;&#30340;&#25512;&#29702;&#36335;&#24452;&#65292;&#28982;&#21518;&#23558;&#27599;&#20010;&#27493;&#39588;&#20998;&#37197;&#32473;&#22522;&#20110;&#31243;&#24207;&#25110;&#25991;&#26412;&#30340;&#25512;&#29702;&#65292;&#20197;&#36798;&#21040;&#26368;&#32456;&#31572;&#26696;&#12290;&#25105;&#20204;&#26681;&#25454;&#35813;&#26694;&#26550;&#26500;&#24314;&#20102;&#19968;&#20010;&#25351;&#20196;&#35843;&#25972;&#38598;TrixtInstruct&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#28085;&#30422;&#20102;&#37027;&#20123;&#38656;&#35201;&#32467;&#21512;&#34920;&#26684;&#21644;&#21477;&#23376;&#20449;&#24687;&#26469;&#33719;&#24471;&#35268;&#21010;&#21644;&#25512;&#29702;&#33021;&#21147;&#30340;&#31243;&#24207;&#26080;&#27861;&#35299;&#20915;&#30340;&#26597;&#35810;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;TrixInstruct&#19978;&#30340;Llama-2-7B&#36827;&#34892;&#24494;&#35843;&#65292;&#25552;&#20986;&#20102;ProTrix&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;ProTrix&#23545;&#21508;&#31181;&#34920;&#26684;&#20219;&#21153;&#20855;&#26377;&#26222;&#36941;&#24615;&#65292;&#24182;&#19988;&#36798;&#21040;&#20102;&#19982;GPT-3.5-turbo&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;ProTrix&#21487;&#20197;&#29983;&#25104;&#20934;&#30830;&#21644;&#24544;&#23454;&#30340;&#35299;&#37322;&#26469;&#22238;&#31572;&#22797;&#26434;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02177v1 Announce Type: new  Abstract: Tables play a crucial role in conveying information in various domains, serving as indispensable tools for organizing and presenting data in a structured manner. We propose a Plan-then-Reason framework to answer different types of user queries over tables with sentence context. The framework first plans the reasoning paths over the context, then assigns each step to program-based or textual reasoning to reach the final answer. We construct an instruction tuning set TrixInstruct following the framework. Our dataset cover queries that are program-unsolvable or need combining information from tables and sentences to obtain planning and reasoning abilities. We present ProTrix by finetuning Llama-2-7B on TrixInstruct. Our experiments show that ProTrix generalizes to diverse tabular tasks and achieves comparable performance to GPT-3.5-turbo. We further demonstrate that ProTrix can generate accurate and faithful explanations to answer complex f
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;LLsM&#65292;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#38544;&#20889;&#26415;&#12290;&#36890;&#36807;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#36827;&#34892;&#24494;&#35843;&#65292;LLM&#33021;&#22815;&#20197;&#21487;&#25511;&#30340;&#26041;&#24335;&#29983;&#25104;&#20855;&#26377;&#29305;&#23450;&#35805;&#35821;&#29305;&#24449;&#30340;&#38544;&#20889;&#25991;&#26412;&#65292;&#25552;&#39640;&#20102;&#38544;&#34109;&#36890;&#20449;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2401.15656</link><description>&lt;p&gt;
LLsM: &#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#38544;&#20889;&#26415;
&lt;/p&gt;
&lt;p&gt;
LLsM: Generative Linguistic Steganography with Large Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.15656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;LLsM&#65292;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#38544;&#20889;&#26415;&#12290;&#36890;&#36807;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#36827;&#34892;&#24494;&#35843;&#65292;LLM&#33021;&#22815;&#20197;&#21487;&#25511;&#30340;&#26041;&#24335;&#29983;&#25104;&#20855;&#26377;&#29305;&#23450;&#35805;&#35821;&#29305;&#24449;&#30340;&#38544;&#20889;&#25991;&#26412;&#65292;&#25552;&#39640;&#20102;&#38544;&#34109;&#36890;&#20449;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#38544;&#20889;&#26415;&#65288;LS&#65289;&#26088;&#22312;&#26681;&#25454;&#31192;&#23494;&#20449;&#24687;&#29983;&#25104;&#38544;&#20889;&#25991;&#26412;&#65288;stego&#65289;&#12290;&#21482;&#26377;&#25480;&#26435;&#25509;&#25910;&#32773;&#25165;&#33021;&#23519;&#35273;&#25991;&#26412;&#20013;&#31192;&#23494;&#30340;&#23384;&#22312;&#24182;&#25552;&#21462;&#20986;&#26469;&#65292;&#20174;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#26696;&#29983;&#25104;&#30340;&#38544;&#20889;&#25991;&#26412;&#21487;&#25511;&#24615;&#36739;&#24046;&#65292;&#24456;&#38590;&#21253;&#21547;&#29305;&#23450;&#30340;&#35805;&#35821;&#29305;&#24449;&#65292;&#22914;&#39118;&#26684;&#12290;&#32467;&#26524;&#65292;&#38544;&#20889;&#25991;&#26412;&#23481;&#26131;&#34987;&#26816;&#27979;&#20986;&#26469;&#65292;&#21361;&#21450;&#38544;&#34109;&#36890;&#20449;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;LLsM&#65292;&#31532;&#19968;&#20010;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;LS&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21253;&#21547;&#20016;&#23500;&#35805;&#35821;&#29305;&#24449;&#30340;&#22823;&#35268;&#27169;&#26500;&#24314;&#25968;&#25454;&#38598;&#23545;LLaMA2&#36827;&#34892;&#24494;&#35843;&#65292;&#20351;&#24471;&#24494;&#35843;&#21518;&#30340;LLM&#33021;&#22815;&#20197;&#21487;&#25511;&#30340;&#26041;&#24335;&#29983;&#25104;&#20855;&#26377;&#29305;&#23450;&#35805;&#35821;&#29305;&#24449;&#30340;&#25991;&#26412;&#12290;&#28982;&#21518;&#23558;&#35805;&#35821;&#20316;&#20026;&#24341;&#23548;&#20449;&#24687;&#21644;&#31192;&#23494;&#19968;&#36215;&#36755;&#20837;&#32473;&#24494;&#35843;&#21518;&#30340;LLM&#65292;&#24418;&#24335;&#20026;&#8220;Prompt&#8221;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#26500;&#24314;&#30340;&#20505;&#36873;&#27744;&#23558;&#36827;&#34892;&#33539;&#22260;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linguistic Steganography (LS) tasks aim to generate steganographic text (stego) based on secret information. Only authorized recipients can perceive the existence of secrets in the texts and extract them, thereby preserving privacy. However, the controllability of the stego generated by existing schemes is poor, and the stego is difficult to contain specific discourse characteristics such as style. As a result, the stego is easily detectable, compromising covert communication. To address these problems, this paper proposes LLsM, the first LS with the Large Language Model (LLM). We fine-tuned the LLaMA2 with a large-scale constructed dataset encompassing rich discourse characteristics, which enables the fine-tuned LLM to generate texts with specific discourse in a controllable manner. Then the discourse is used as guiding information and inputted into the fine-tuned LLM in the form of the Prompt together with secret. On this basis, the constructed candidate pool will be range encoded an
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#22870;&#21169;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;LLM&#20316;&#20026;&#35780;&#21028;&#32773;&#65292;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#33258;&#24049;&#25552;&#20379;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#22870;&#21169;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#19981;&#20165;&#21487;&#20197;&#25552;&#39640;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#65292;&#36824;&#21487;&#20197;&#20026;&#33258;&#24049;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#22870;&#21169;&#12290;&#36890;&#36807;&#23545;Llama 2 70B&#27169;&#22411;&#30340;&#19977;&#27425;&#36845;&#20195;&#24494;&#35843;&#65292;&#32467;&#26524;&#22312;AlpacaEval 2.0&#25490;&#34892;&#27036;&#19978;&#36229;&#36807;&#20102;&#20854;&#20182;&#29616;&#26377;&#31995;&#32479;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#23454;&#29616;&#33021;&#22815;&#19981;&#26029;&#33258;&#25105;&#25913;&#36827;&#30340;&#27169;&#22411;&#24320;&#36767;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.10020</link><description>&lt;p&gt;
&#33258;&#22870;&#21169;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Self-Rewarding Language Models. (arXiv:2401.10020v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10020
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#22870;&#21169;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;LLM&#20316;&#20026;&#35780;&#21028;&#32773;&#65292;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#33258;&#24049;&#25552;&#20379;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#22870;&#21169;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#19981;&#20165;&#21487;&#20197;&#25552;&#39640;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#65292;&#36824;&#21487;&#20197;&#20026;&#33258;&#24049;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#22870;&#21169;&#12290;&#36890;&#36807;&#23545;Llama 2 70B&#27169;&#22411;&#30340;&#19977;&#27425;&#36845;&#20195;&#24494;&#35843;&#65292;&#32467;&#26524;&#22312;AlpacaEval 2.0&#25490;&#34892;&#27036;&#19978;&#36229;&#36807;&#20102;&#20854;&#20182;&#29616;&#26377;&#31995;&#32479;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#23454;&#29616;&#33021;&#22815;&#19981;&#26029;&#33258;&#25105;&#25913;&#36827;&#30340;&#27169;&#22411;&#24320;&#36767;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20551;&#35774;&#35201;&#23454;&#29616;&#36229;&#20154;&#32423;&#30340;&#26234;&#33021;&#20307;&#65292;&#26410;&#26469;&#30340;&#27169;&#22411;&#38656;&#35201;&#36229;&#20154;&#32423;&#30340;&#21453;&#39304;&#65292;&#20197;&#25552;&#20379;&#36275;&#22815;&#30340;&#35757;&#32451;&#20449;&#21495;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#26159;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#35757;&#32451;&#22870;&#21169;&#27169;&#22411;&#65292;&#36825;&#21487;&#33021;&#20250;&#21463;&#21040;&#20154;&#31867;&#34920;&#29616;&#27700;&#24179;&#30340;&#38480;&#21046;&#65292;&#32780;&#19988;&#36825;&#20123;&#29420;&#31435;&#30340;&#20923;&#32467;&#22870;&#21169;&#27169;&#22411;&#22312;LLM&#35757;&#32451;&#36807;&#31243;&#20013;&#26080;&#27861;&#23398;&#20064;&#25913;&#36827;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#22870;&#21169;&#35821;&#35328;&#27169;&#22411;&#65292;&#20854;&#20013;&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#36890;&#36807;LLM&#20316;&#20026;&#35780;&#21028;&#32773;&#30340;&#25552;&#31034;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#33258;&#24049;&#30340;&#22870;&#21169;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#36845;&#20195;DPO&#35757;&#32451;&#20013;&#65292;&#19981;&#20165;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#24471;&#21040;&#20102;&#25552;&#39640;&#65292;&#32780;&#19988;&#33021;&#22815;&#20026;&#33258;&#24049;&#25552;&#20379;&#39640;&#36136;&#37327;&#30340;&#22870;&#21169;&#12290;&#36890;&#36807;&#23545;Llama 2 70B&#36827;&#34892;&#25105;&#20204;&#26041;&#27861;&#30340;&#19977;&#27425;&#36845;&#20195;&#30340;&#24494;&#35843;&#65292;&#24471;&#21040;&#30340;&#27169;&#22411;&#22312;AlpacaEval 2.0&#25490;&#34892;&#27036;&#19978;&#32988;&#36807;&#35768;&#22810;&#29616;&#26377;&#31995;&#32479;&#65292;&#21253;&#25324;Claude 2&#12289;Gemini Pro&#21644;GPT-4 0613&#12290;&#34429;&#28982;&#36825;&#21482;&#26159;&#19968;&#39033;&#21021;&#27493;&#30740;&#31350;&#65292;&#20294;&#36825;&#39033;&#24037;&#20316;&#20026;&#21487;&#33021;&#23454;&#29616;&#33021;&#22815;&#19981;&#26029;&#33258;&#25105;&#25913;&#36827;&#30340;&#27169;&#22411;&#25171;&#24320;&#20102;&#22823;&#38376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We posit that to achieve superhuman agents, future models require superhuman feedback in order to provide an adequate training signal. Current approaches commonly train reward models from human preferences, which may then be bottlenecked by human performance level, and secondly these separate frozen reward models cannot then learn to improve during LLM training. In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during training. We show that during Iterative DPO training that not only does instruction following ability improve, but also the ability to provide high-quality rewards to itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard, including Claude 2, Gemini Pro, and GPT-4 0613. While only a preliminary study, this work opens the door to the possibility of models that can continuall
&lt;/p&gt;</description></item></channel></rss>