<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35770;&#25991;&#25581;&#31034;&#20102;&#22312;&#26576;&#20123;&#20219;&#21153;&#31867;&#21035;&#20013;&#65292;&#25945;&#24072;&#24378;&#21046;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#22312;&#31532;&#19968;&#26102;&#38388;&#23398;&#20064;&#21040;&#20934;&#30830;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#65292;&#36827;&#32780;&#23548;&#33268;&#27169;&#22411;&#22833;&#36133;&#30340;&#19968;&#33324;&#26426;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.06963</link><description>&lt;p&gt;
&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30340;&#38519;&#38449;
&lt;/p&gt;
&lt;p&gt;
The pitfalls of next-token prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06963
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25581;&#31034;&#20102;&#22312;&#26576;&#20123;&#20219;&#21153;&#31867;&#21035;&#20013;&#65292;&#25945;&#24072;&#24378;&#21046;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#22312;&#31532;&#19968;&#26102;&#38388;&#23398;&#20064;&#21040;&#20934;&#30830;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#22120;&#65292;&#36827;&#32780;&#23548;&#33268;&#27169;&#22411;&#22833;&#36133;&#30340;&#19968;&#33324;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#31687;&#20851;&#20110;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30340;&#35770;&#25991;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#30452;&#35266;&#30340;&#25285;&#24551;&#65306;&#19968;&#20010;&#20165;&#20165;&#22522;&#20110;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30340;&#27169;&#22411;&#26159;&#21542;&#33021;&#24544;&#23454;&#22320;&#27169;&#25311;&#20154;&#31867;&#26234;&#33021;&#12290;&#25105;&#20204;&#35748;&#20026;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#20013;&#32463;&#24120;&#28151;&#28102;&#30340;&#20004;&#20010;&#38454;&#27573; -- &#33258;&#22238;&#24402;&#25512;&#26029;&#21644;&#25945;&#24072;&#24378;&#21046;&#35757;&#32451; -- &#24517;&#39035;&#34987;&#21306;&#21035;&#23545;&#24453;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#19968;&#33324;&#26426;&#21046;&#65292;&#23637;&#31034;&#20102;&#25945;&#24072;&#24378;&#21046;&#22914;&#20309;&#22833;&#36133;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#35745;&#21010;&#20219;&#21153;&#65292;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;Transformer&#21644;Mamba&#26550;&#26500;&#22312;&#23454;&#36341;&#20013;&#20197;&#36825;&#31181;&#26041;&#24335;&#22833;&#36133; -- &#23613;&#31649;&#20219;&#21153;&#26412;&#36523;&#24456;&#23481;&#26131;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06963v1 Announce Type: cross  Abstract: Can a mere next-token predictor faithfully model human intelligence? We crystallize this intuitive concern, which is fragmented in the literature. As a starting point, we argue that the two often-conflated phases of next-token prediction -- autoregressive inference and teacher-forced training -- must be treated distinctly. The popular criticism that errors can compound during autoregressive inference, crucially assumes that teacher-forcing has learned an accurate next-token predictor. This assumption sidesteps a more deep-rooted problem we expose: in certain classes of tasks, teacher-forcing can simply fail to learn an accurate next-token predictor in the first place. We describe a general mechanism of how teacher-forcing can fail, and design a minimal planning task where both the Transformer and the Mamba architecture empirically fail in that manner -- remarkably, despite the task being straightforward to learn. We provide preliminary
&lt;/p&gt;</description></item></channel></rss>