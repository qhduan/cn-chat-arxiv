<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26816;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20851;&#38190;&#32479;&#35745;&#37327;&#21644;&#31192;&#23494;&#23494;&#38053;&#25511;&#21046;&#35823;&#25253;&#29575;&#65292;&#21516;&#26102;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.01245</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#26694;&#26550;: &#26530;&#36724;&#12289;&#26816;&#27979;&#25928;&#29575;&#21644;&#26368;&#20248;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01245
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26816;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20851;&#38190;&#32479;&#35745;&#37327;&#21644;&#31192;&#23494;&#23494;&#38053;&#25511;&#21046;&#35823;&#25253;&#29575;&#65292;&#21516;&#26102;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;ChatGPT&#20110;2022&#24180;11&#26376;&#25512;&#20986;&#20197;&#26469;&#65292;&#23558;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#30340;&#32479;&#35745;&#20449;&#21495;&#23884;&#20837;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#65292;&#20063;&#34987;&#31216;&#20026;&#27700;&#21360;&#65292;&#24050;&#34987;&#29992;&#20316;&#20174;&#20854;&#20154;&#31867;&#25776;&#20889;&#23545;&#24212;&#29289;&#19978;&#21487;&#35777;&#26816;&#27979;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290; &#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#29702;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#24182;&#35774;&#35745;&#24378;&#22823;&#30340;&#26816;&#27979;&#35268;&#21017;&#12290;&#21463;&#27700;&#21360;&#26816;&#27979;&#30340;&#20551;&#35774;&#26816;&#39564;&#20844;&#24335;&#21551;&#21457;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#39318;&#20808;&#36873;&#25321;&#25991;&#26412;&#30340;&#26530;&#36724;&#32479;&#35745;&#37327;&#21644;&#30001;LLM&#25552;&#20379;&#32473;&#39564;&#35777;&#22120;&#30340;&#31192;&#23494;&#23494;&#38053;&#65292;&#20197;&#23454;&#29616;&#25511;&#21046;&#35823;&#25253;&#29575;&#65288;&#23558;&#20154;&#31867;&#25776;&#20889;&#30340;&#25991;&#26412;&#38169;&#35823;&#22320;&#26816;&#27979;&#20026;LLM&#29983;&#25104;&#30340;&#38169;&#35823;&#65289;&#12290; &#25509;&#19979;&#26469;&#65292;&#35813;&#26694;&#26550;&#20801;&#35768;&#36890;&#36807;&#33719;&#21462;&#28176;&#36817;&#38169;&#35823;&#36127;&#29575;&#65288;&#23558;LLM&#29983;&#25104;&#25991;&#26412;&#38169;&#35823;&#22320;&#26816;&#27979;&#20026;&#20154;&#31867;&#25776;&#20889;&#30340;&#38169;&#35823;&#65289;&#30340;&#23553;&#38381;&#24418;&#24335;&#34920;&#36798;&#24335;&#26469;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01245v1 Announce Type: cross  Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#26088;&#22312;&#35780;&#20272;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#30340;&#21160;&#24577;&#22522;&#20934;NPHardEval4V&#65292;&#21457;&#29616;&#22312;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#19981;&#21516;&#27169;&#22411;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#24182;&#25581;&#31034;&#20102;&#30456;&#23545;&#20110;LLMs&#65292;MLLMs&#30340;&#25512;&#29702;&#24615;&#33021;&#36739;&#24369;&#12290;</title><link>https://arxiv.org/abs/2403.01777</link><description>&lt;p&gt;
NPHardEval4V: &#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21160;&#24577;&#25512;&#29702;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01777
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#26088;&#22312;&#35780;&#20272;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#33021;&#21147;&#30340;&#21160;&#24577;&#22522;&#20934;NPHardEval4V&#65292;&#21457;&#29616;&#22312;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#19981;&#21516;&#27169;&#22411;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#24182;&#25581;&#31034;&#20102;&#30456;&#23545;&#20110;LLMs&#65292;MLLMs&#30340;&#25512;&#29702;&#24615;&#33021;&#36739;&#24369;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLMs&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21160;&#24577;&#22522;&#20934;&#65292;NPHardEval4V&#65292;&#26088;&#22312;&#35299;&#20915;&#35780;&#20272;MLLM&#32431;&#31929;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#29616;&#26377;&#24046;&#36317;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#26088;&#22312;&#25552;&#20379;&#19968;&#20010;&#24179;&#21488;&#65292;&#20197;&#35299;&#24320;&#35832;&#22810;&#22240;&#32032;&#65288;&#22914;&#22270;&#20687;&#35782;&#21035;&#21644;&#25351;&#20196;&#36981;&#24490;&#65289;&#23545;&#27169;&#22411;&#25972;&#20307;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#19987;&#27880;&#20110;&#35780;&#20272;&#23427;&#20204;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#19981;&#21516;&#27169;&#22411;&#22312;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#24182;&#31361;&#20986;&#20102;&#30456;&#36739;&#20110;LLMs&#65292;MLLMs&#22312;&#25512;&#29702;&#26041;&#38754;&#34920;&#29616;&#30456;&#23545;&#36739;&#24369;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19981;&#21516;&#25552;&#31034;&#26679;&#24335;&#65288;&#21253;&#25324;&#35270;&#35273;&#12289;&#25991;&#26412;&#21644;&#32467;&#21512;&#35270;&#35273;&#19982;&#25991;&#26412;&#25552;&#31034;&#65289;&#23545;MLLM&#25512;&#29702;&#33021;&#21147;&#30340;&#24433;&#21709;&#65292;&#23637;&#31034;&#20102;&#22810;&#27169;&#24577;&#36755;&#20837;&#22312;&#27169;&#22411;&#24615;&#33021;&#20013;&#30340;&#19981;&#21516;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01777v1 Announce Type: new  Abstract: Understanding the reasoning capabilities of Multimodal Large Language Models (MLLMs) is an important area of research. In this study, we introduce a dynamic benchmark, NPHardEval4V, aimed at addressing the existing gaps in evaluating the pure reasoning abilities of MLLMs. Our benchmark aims to provide a venue to disentangle the effect of various factors such as image recognition and instruction following, from the overall performance of the models, allowing us to focus solely on evaluating their reasoning abilities. Our findings reveal significant discrepancies in reasoning abilities across different models and highlight the relatively weak performance of MLLMs compared to LLMs in terms of reasoning. We also investigate the impact of different prompting styles, including visual, text, and combined vision and text prompts, on the reasoning abilities of MLLMs, demonstrating the different impacts of multimodal inputs in model performance. U
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#23545;&#31038;&#20132;&#23186;&#20307;&#20013;&#36328;&#35821;&#35328;&#20882;&#29359;&#24615;&#35821;&#35328;&#26816;&#27979;&#30340;&#25216;&#26415;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#65292;&#20998;&#26512;&#20102;67&#31687;&#30456;&#20851;&#35770;&#25991;&#65292;&#24182;&#24635;&#32467;&#20102;&#36328;&#35821;&#35328;&#36716;&#31227;&#23398;&#20064;&#30340;&#19977;&#31181;&#20027;&#35201;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#36824;&#25506;&#35752;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2401.09244</link><description>&lt;p&gt;
&#36328;&#35821;&#35328;&#20882;&#29359;&#24615;&#35821;&#35328;&#26816;&#27979;&#65306;&#25968;&#25454;&#38598;&#12289;&#36716;&#31227;&#26041;&#27861;&#21644;&#25361;&#25112;&#30340;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Cross-lingual Offensive Language Detection: A Systematic Review of Datasets, Transfer Approaches and Challenges. (arXiv:2401.09244v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09244
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#23545;&#31038;&#20132;&#23186;&#20307;&#20013;&#36328;&#35821;&#35328;&#20882;&#29359;&#24615;&#35821;&#35328;&#26816;&#27979;&#30340;&#25216;&#26415;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#65292;&#20998;&#26512;&#20102;67&#31687;&#30456;&#20851;&#35770;&#25991;&#65292;&#24182;&#24635;&#32467;&#20102;&#36328;&#35821;&#35328;&#36716;&#31227;&#23398;&#20064;&#30340;&#19977;&#31181;&#20027;&#35201;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#36824;&#25506;&#35752;&#20102;&#35813;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#19978;&#20882;&#29359;&#24615;&#35821;&#35328;&#30340;&#26222;&#21450;&#21644;&#36805;&#36895;&#21457;&#23637;&#22686;&#21152;&#20102;&#26816;&#27979;&#30340;&#22797;&#26434;&#24615;&#65292;&#23588;&#20854;&#31361;&#26174;&#20102;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#35782;&#21035;&#27492;&#31867;&#20869;&#23481;&#30340;&#25361;&#25112;&#12290;&#26412;&#32508;&#36848;&#31995;&#32479;&#24615;&#12289;&#20840;&#38754;&#22320;&#25506;&#35752;&#20102;&#31038;&#20132;&#23186;&#20307;&#20013;&#36328;&#35821;&#35328;&#36716;&#31227;&#23398;&#20064;&#65288;CLTL&#65289;&#25216;&#26415;&#22312;&#20882;&#29359;&#24615;&#35821;&#35328;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26159;&#35813;&#39046;&#22495;&#39318;&#20010;&#19987;&#27880;&#20110;&#36328;&#35821;&#35328;&#24773;&#26223;&#30340;&#20840;&#38754;&#27010;&#36848;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;67&#31687;&#30456;&#20851;&#35770;&#25991;&#65292;&#24182;&#23545;&#36825;&#20123;&#30740;&#31350;&#36827;&#34892;&#20102;&#21508;&#20010;&#32500;&#24230;&#30340;&#20998;&#31867;&#65292;&#21253;&#25324;&#20351;&#29992;&#30340;&#22810;&#35821;&#31181;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#12289;&#20351;&#29992;&#30340;&#36328;&#35821;&#35328;&#36164;&#28304;&#20197;&#21450;&#23454;&#26045;&#30340;&#20855;&#20307;CLTL&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#26681;&#25454;&#8220;&#20309;&#31181;&#36716;&#31227;&#8221;&#65292;&#25105;&#20204;&#36824;&#24635;&#32467;&#20102;&#19977;&#31181;&#20027;&#35201;&#30340;CLTL&#36716;&#31227;&#26041;&#27861;&#65306;&#23454;&#20363;&#12289;&#29305;&#24449;&#21644;&#21442;&#25968;&#36716;&#31227;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#35813;&#39046;&#22495;&#24403;&#21069;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;
The growing prevalence and rapid evolution of offensive language in social media amplify the complexities of detection, particularly highlighting the challenges in identifying such content across diverse languages. This survey presents a systematic and comprehensive exploration of Cross-Lingual Transfer Learning (CLTL) techniques in offensive language detection in social media. Our study stands as the first holistic overview to focus exclusively on the cross-lingual scenario in this domain. We analyse 67 relevant papers and categorise these studies across various dimensions, including the characteristics of multilingual datasets used, the cross-lingual resources employed, and the specific CLTL strategies implemented. According to "what to transfer", we also summarise three main CLTL transfer approaches: instance, feature, and parameter transfer. Additionally, we shed light on the current challenges and future research opportunities in this field. Furthermore, we have made our survey re
&lt;/p&gt;</description></item></channel></rss>