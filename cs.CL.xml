<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#20998;&#31867;&#20013;&#21333;&#35789;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#20197;&#35780;&#20272;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;SP-Attack&#21644;SP-Defense&#26041;&#27861;&#26469;&#38024;&#23545;&#21333;&#35789;&#25200;&#21160;&#36827;&#34892;&#25915;&#20987;&#21644;&#38450;&#24481;&#65292;&#23454;&#29616;&#26356;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#21644;&#26356;&#22909;&#30340;&#21477;&#23376;&#21547;&#20041;&#20445;&#25345;&#12290;</title><link>https://arxiv.org/abs/2401.17196</link><description>&lt;p&gt;
&#19968;&#20010;&#21333;&#35789;&#30340;&#25913;&#21464;&#21363;&#21487;&#65306;&#20026;&#25991;&#26412;&#20998;&#31867;&#22120;&#35774;&#35745;&#25915;&#20987;&#19982;&#38450;&#24481;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17196
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#20998;&#31867;&#20013;&#21333;&#35789;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#20197;&#35780;&#20272;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;SP-Attack&#21644;SP-Defense&#26041;&#27861;&#26469;&#38024;&#23545;&#21333;&#35789;&#25200;&#21160;&#36827;&#34892;&#25915;&#20987;&#21644;&#38450;&#24481;&#65292;&#23454;&#29616;&#26356;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#21644;&#26356;&#22909;&#30340;&#21477;&#23376;&#21547;&#20041;&#20445;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25991;&#26412;&#20998;&#31867;&#20013;&#65292;&#21019;&#24314;&#23545;&#25239;&#26679;&#26412;&#24847;&#21619;&#30528;&#22312;&#21477;&#23376;&#20013;&#24494;&#22937;&#22320;&#25200;&#21160;&#20960;&#20010;&#21333;&#35789;&#32780;&#19981;&#25913;&#21464;&#20854;&#21547;&#20041;&#65292;&#23548;&#33268;&#20998;&#31867;&#22120;&#38169;&#35823;&#20998;&#31867;&#12290;&#20196;&#20154;&#25285;&#24551;&#30340;&#26159;&#65292;&#29616;&#26377;&#26041;&#27861;&#29983;&#25104;&#30340;&#23545;&#25239;&#26679;&#26412;&#20013;&#26377;&#30456;&#24403;&#37096;&#20998;&#21482;&#25913;&#21464;&#20102;&#19968;&#20010;&#21333;&#35789;&#12290;&#36825;&#31181;&#21333;&#35789;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#20195;&#34920;&#20102;&#20998;&#31867;&#22120;&#30340;&#19968;&#20010;&#37325;&#22823;&#24369;&#28857;&#65292;&#24694;&#24847;&#29992;&#25143;&#21487;&#20197;&#21033;&#29992;&#23427;&#39640;&#25928;&#22320;&#21019;&#24314;&#22823;&#37327;&#23545;&#25239;&#26679;&#26412;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#24182;&#20316;&#20986;&#20102;&#20197;&#19979;&#20851;&#38190;&#36129;&#29486;&#65306;(1) &#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631; \r{ho} &#26469;&#23450;&#37327;&#35780;&#20272;&#20998;&#31867;&#22120;&#23545;&#20110;&#21333;&#35789;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;(2) &#25105;&#20204;&#25552;&#20986;&#20102; SP-Attack&#65292;&#26088;&#22312;&#21033;&#29992;&#21333;&#35789;&#25200;&#21160;&#30340;&#33030;&#24369;&#24615;&#65292;&#23454;&#29616;&#26356;&#39640;&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#26356;&#22909;&#22320;&#20445;&#25345;&#21477;&#23376;&#30340;&#21547;&#20041;&#65292;&#21516;&#26102;&#38477;&#20302;&#19982;&#29616;&#26377;&#23545;&#25239;&#26041;&#27861;&#30456;&#27604;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;(3) &#25105;&#20204;&#25552;&#20986;&#20102; SP-Defense&#65292;&#26088;&#22312;&#25913;&#36827;&#20998;&#31867;&#22120;&#30340;&#25269;&#25239;&#21333;&#35789;&#25200;&#21160;&#30340;&#33021;&#21147;&#65292;&#20943;&#23567;&#25915;&#20987;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In text classification, creating an adversarial example means subtly perturbing a few words in a sentence without changing its meaning, causing it to be misclassified by a classifier. A concerning observation is that a significant portion of adversarial examples generated by existing methods change only one word. This single-word perturbation vulnerability represents a significant weakness in classifiers, which malicious users can exploit to efficiently create a multitude of adversarial examples. This paper studies this problem and makes the following key contributions: (1) We introduce a novel metric \r{ho} to quantitatively assess a classifier's robustness against single-word perturbation. (2) We present the SP-Attack, designed to exploit the single-word perturbation vulnerability, achieving a higher attack success rate, better preserving sentence meaning, while reducing computation costs compared to state-of-the-art adversarial methods. (3) We propose SP-Defense, which aims to impro
&lt;/p&gt;</description></item></channel></rss>