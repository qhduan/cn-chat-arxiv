<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#21644;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#21644;&#20943;&#36731;&#36807;&#24230;&#25311;&#21512;&#12290;</title><link>https://arxiv.org/abs/2403.10056</link><description>&lt;p&gt;
&#19981;&#35201;&#21322;&#24515;&#21322;&#24847;&#65306;&#25429;&#25417;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#20013;&#30340;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10056
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#21644;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#21644;&#20943;&#36731;&#36807;&#24230;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10056v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25351;&#23548;&#35843;&#25972;&#21487;&#20197;&#39537;&#20351;&#23427;&#20204;&#22312;&#29305;&#23450;&#19979;&#28216;&#20219;&#21153;&#20013;&#20135;&#29983;&#31526;&#21512;&#20154;&#31867;&#30446;&#26631;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;LLMs&#30340;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#65288;CIT&#65289;&#36807;&#31243;&#21487;&#33021;&#20250;&#24102;&#26469;&#28798;&#38590;&#24615;&#36951;&#24536;&#65288;CF&#65289;&#38382;&#39064;&#65292;&#23548;&#33268;&#20808;&#21069;&#23398;&#21040;&#30340;&#33021;&#21147;&#36864;&#21270;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#23581;&#35797;&#36890;&#36807;&#20462;&#25913;&#27169;&#22411;&#25110;&#37325;&#25918;&#25968;&#25454;&#26469;&#32531;&#35299;CF&#38382;&#39064;&#65292;&#20294;&#36825;&#21487;&#33021;&#21482;&#35760;&#20303;&#25351;&#20196;&#30340;&#34920;&#38754;&#27169;&#24335;&#24182;&#22312;&#30041;&#23384;&#20219;&#21153;&#19978;&#24863;&#21040;&#22256;&#24785;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#37096;&#20998;&#20449;&#24687;&#22686;&#30410;&#65288;KPIG&#65289;&#30340;&#26032;&#22411;&#36830;&#32493;&#25351;&#23548;&#35843;&#25972;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35745;&#31639;&#25513;&#30422;&#37096;&#20998;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#21160;&#24577;&#37325;&#25918;&#25968;&#25454;&#24182;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#65292;&#20174;&#32780;&#20351;LLMs&#33021;&#22815;&#25429;&#25417;&#19982;&#27491;&#30830;&#21709;&#24212;&#30456;&#20851;&#30340;&#20219;&#21153;&#24863;&#30693;&#20449;&#24687;&#65292;&#24182;&#20943;&#36731;&#23545;&#25351;&#23548;&#20013;&#36890;&#29992;&#25551;&#36848;&#30340;&#36807;&#24230;&#25311;&#21512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#25351;&#26631;&#65292;P&#20998;&#21644;V&#20998;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10056v1 Announce Type: cross  Abstract: Instruction tuning for large language models (LLMs) can drive them to produce results consistent with human goals in specific downstream tasks. However, the process of continual instruction tuning (CIT) for LLMs may bring about the catastrophic forgetting (CF) problem, where previously learned abilities are degraded. Recent methods try to alleviate the CF problem by modifying models or replaying data, which may only remember the surface-level pattern of instructions and get confused on held-out tasks. In this paper, we propose a novel continual instruction tuning method based on Key-part Information Gain (KPIG). Our method computes the information gain on masked parts to dynamically replay data and refine the training objective, which enables LLMs to capture task-aware information relevant to the correct response and alleviate overfitting to general descriptions in instructions. In addition, we propose two metrics, P-score and V-score,
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20559;&#24046;&#22686;&#24378;&#30340;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;BCT&#65289;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#38142;&#24335;&#24605;&#32500;&#20013;&#30340;&#20559;&#35265;&#25512;&#29702;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#36890;&#36807;&#35757;&#32451;&#27169;&#22411;&#22312;&#24102;&#26377;&#21644;&#19981;&#24102;&#26377;&#20559;&#32622;&#29305;&#24449;&#30340;&#25552;&#31034;&#19979;&#36827;&#34892;&#19968;&#33268;&#30340;&#25512;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.05518</link><description>&lt;p&gt;
&#36890;&#36807;&#20559;&#24046;&#22686;&#24378;&#19968;&#33268;&#24615;&#35757;&#32451;&#20943;&#23569;&#38142;&#24335;&#24605;&#32500;&#20013;&#30340;&#20559;&#35265;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05518
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20559;&#24046;&#22686;&#24378;&#30340;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;BCT&#65289;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#38142;&#24335;&#24605;&#32500;&#20013;&#30340;&#20559;&#35265;&#25512;&#29702;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#36890;&#36807;&#35757;&#32451;&#27169;&#22411;&#22312;&#24102;&#26377;&#21644;&#19981;&#24102;&#26377;&#20559;&#32622;&#29305;&#24449;&#30340;&#25552;&#31034;&#19979;&#36827;&#34892;&#19968;&#33268;&#30340;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#38142;&#24335;&#24605;&#32500;&#25552;&#31034;&#65288;CoT&#65289;&#26377;&#28508;&#21147;&#25913;&#21892;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20294;&#23427;&#21487;&#33021;&#20250;&#31995;&#32479;&#24615;&#22320;&#27498;&#26354;&#24433;&#21709;&#27169;&#22411;&#34892;&#20026;&#30340;&#22240;&#32032;--&#27604;&#22914;&#65292;&#21512;&#29702;&#21270;&#31572;&#26696;&#20197;&#31526;&#21512;&#29992;&#25143;&#24847;&#35265;&#32780;&#19981;&#25552;&#21450;&#27492;&#20559;&#35265;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#19968;&#20559;&#35265;&#25512;&#29702;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20559;&#24046;&#22686;&#24378;&#30340;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;BCT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#24494;&#35843;&#26041;&#26696;&#65292;&#26088;&#22312;&#35757;&#32451;&#27169;&#22411;&#22312;&#24102;&#26377;&#21644;&#19981;&#24102;&#26377;&#20559;&#32622;&#29305;&#24449;&#30340;&#25552;&#31034;&#19979;&#36827;&#34892;&#19968;&#33268;&#30340;&#25512;&#29702;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#27979;&#35797;&#21333;&#20803;&#65292;&#38024;&#23545;&#19971;&#20010;&#38382;&#31572;&#20219;&#21153;&#27979;&#35797;&#20102;&#20061;&#31181;&#24418;&#24335;&#30340;&#26377;&#20559;&#25512;&#29702;&#65292;&#21457;&#29616;&#23558;BCT&#24212;&#29992;&#20110;&#24102;&#26377;&#19968;&#31181;&#20559;&#35265;&#30340;GPT-3.5-Turbo&#21487;&#20197;&#23558;&#26377;&#20559;&#25512;&#29702;&#30340;&#27604;&#20363;&#22312;&#26410;&#30693;&#20219;&#21153;&#19978;&#38477;&#20302;86%&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#27169;&#22411;&#25512;&#24191;&#21040;&#20854;&#20182;&#24418;&#24335;&#30340;&#20559;&#35265;&#65292;&#24179;&#22343;&#23558;&#26410;&#30693;&#20559;&#35265;&#19978;&#30340;&#26377;&#20559;&#25512;&#29702;&#20943;&#23569;&#20102;37%&#12290;&#30001;&#20110;BCT&#23558;&#26410;&#30693;&#20559;&#35265;&#27867;&#21270;&#24182;&#19988;&#19981;&#38656;&#35201;&#37329;&#26631;&#31614;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#20250;&#26377;&#21161;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05518v1 Announce Type: cross  Abstract: While chain-of-thought prompting (CoT) has the potential to improve the explainability of language model reasoning, it can systematically misrepresent the factors influencing models' behavior--for example, rationalizing answers in line with a user's opinion without mentioning this bias. To mitigate this biased reasoning problem, we introduce bias-augmented consistency training (BCT), an unsupervised fine-tuning scheme that trains models to give consistent reasoning across prompts with and without biasing features. We construct a suite testing nine forms of biased reasoning on seven question-answering tasks, and find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of biased reasoning by 86% on held-out tasks. Moreover, this model generalizes to other forms of bias, reducing biased reasoning on held-out biases by an average of 37%. As BCT generalizes to held-out biases and does not require gold labels, this method may h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#35780;&#20272;&#20102;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#65292;&#25351;&#20986;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#20173;&#26377;&#24453;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.04963</link><description>&lt;p&gt;
&#22312;&#22522;&#20110;&#38169;&#35823;&#30340;&#20154;&#31867;&#35780;&#20272;&#20013;&#28145;&#20837;&#35780;&#20272;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#35780;&#20272;&#20102;GPT-4&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#65292;&#25351;&#20986;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#20173;&#26377;&#24453;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21477;&#23376;&#31616;&#21270;&#26159;&#19968;&#31181;&#37325;&#20889;&#21477;&#23376;&#20197;&#20415;&#26356;&#26131;&#38405;&#35835;&#21644;&#29702;&#35299;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#24110;&#21161;&#26377;&#21508;&#31181;&#38405;&#35835;&#38590;&#39064;&#30340;&#20154;&#26469;&#35828;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;&#38543;&#30528;&#20808;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20852;&#36215;&#65292;&#35780;&#20272;&#23427;&#20204;&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#34920;&#29616;&#21464;&#24471;&#36843;&#22312;&#30473;&#30571;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21033;&#29992;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#21644;&#20154;&#31867;&#35780;&#20272;&#26469;&#35780;&#20272;LLMs&#30340;&#31616;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#35780;&#20272;&#26041;&#27861;&#23545;LLMs&#22312;&#31616;&#21270;&#35780;&#20272;&#20013;&#30340;&#36866;&#29992;&#24615;&#20173;&#28982;&#23384;&#22312;&#30097;&#38382;&#12290;&#39318;&#20808;&#65292;&#29616;&#26377;&#33258;&#21160;&#25351;&#26631;&#22312;LLMs&#30340;&#31616;&#21270;&#35780;&#20272;&#20013;&#30340;&#36866;&#29992;&#24615;&#20173;&#19981;&#30830;&#23450;&#12290;&#20854;&#27425;&#65292;&#24403;&#21069;&#22312;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#20154;&#31867;&#35780;&#20272;&#26041;&#27861;&#36890;&#24120;&#38519;&#20837;&#20004;&#20010;&#26497;&#31471;&#65306;&#35201;&#20040;&#36807;&#20110;&#32932;&#27973;&#65292;&#26080;&#27861;&#28165;&#26224;&#29702;&#35299;&#27169;&#22411;&#30340;&#34920;&#29616;&#65292;&#35201;&#20040;&#36807;&#20110;&#35814;&#32454;&#65292;&#20351;&#27880;&#37322;&#36807;&#31243;&#22797;&#26434;&#19988;&#23481;&#26131;&#20986;&#29616;&#19981;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#24433;&#21709;&#35780;&#20272;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04963v1 Announce Type: cross  Abstract: Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs' simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models' performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation's reliabil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#24037;&#19994;&#32972;&#26223;&#19979;&#21033;&#29992;LLMs&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#21069;&#26223;&#65292;&#24182;&#36890;&#36807;&#23545;&#34892;&#19994;&#20174;&#19994;&#32773;&#35843;&#26597;&#20197;&#21450;&#23457;&#26597;&#22823;&#37327;&#34892;&#19994;&#35770;&#25991;&#24471;&#20986;&#26377;&#24847;&#20041;&#30340;&#32467;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.14558</link><description>&lt;p&gt;
&#20855;&#26377;&#24037;&#19994;&#35270;&#35282;&#30340;LLMs&#65306;&#25581;&#31034;&#25361;&#25112;&#19982;&#21069;&#26223;--&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
LLMs with Industrial Lens: Deciphering the Challenges and Prospects -- A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14558
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22312;&#24037;&#19994;&#32972;&#26223;&#19979;&#21033;&#29992;LLMs&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21644;&#21069;&#26223;&#65292;&#24182;&#36890;&#36807;&#23545;&#34892;&#19994;&#20174;&#19994;&#32773;&#35843;&#26597;&#20197;&#21450;&#23457;&#26597;&#22823;&#37327;&#34892;&#19994;&#35770;&#25991;&#24471;&#20986;&#26377;&#24847;&#20041;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#25104;&#20026;&#25512;&#21160;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#30340;&#31192;&#23494;&#27494;&#22120;&#65292;&#23637;&#31034;&#20986;&#23427;&#20204;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#30340;&#21331;&#36234;&#36866;&#24212;&#24615;&#12290;&#20174;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#24773;&#24863;&#20998;&#26512;&#21040;&#20869;&#23481;&#29983;&#25104;&#21644;&#20010;&#24615;&#21270;&#25512;&#33616;&#65292;&#23427;&#20204;&#26080;&#19982;&#20262;&#27604;&#30340;&#36866;&#24212;&#24615;&#20419;&#36827;&#20102;&#22312;&#21508;&#20010;&#34892;&#19994;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;LLMs&#24102;&#26469;&#30340;&#36825;&#31181;&#36716;&#21464;&#24378;&#35843;&#20102;&#25506;&#32034;&#19982;&#21033;&#29992;&#20013;&#30340;&#22256;&#38590;&#21644;&#22686;&#24378;&#26426;&#20250;&#30340;&#24517;&#35201;&#24615;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#25581;&#31034;&#21644;&#35780;&#20272;&#22312;&#24037;&#19994;&#32972;&#26223;&#19979;&#21033;&#29992;LLMs&#25152;&#38754;&#20020;&#30340;&#38556;&#30861;&#21644;&#26426;&#20250;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#28041;&#21450;&#19968;&#32452;&#34892;&#19994;&#20174;&#19994;&#32773;&#30340;&#35843;&#26597;&#65292;&#25552;&#20986;&#20102;&#22235;&#20010;&#30740;&#31350;&#38382;&#39064;&#65292;&#24182;&#26681;&#25454;&#25910;&#38598;&#21040;&#30340;&#35265;&#35299;&#23457;&#26597;&#20102;68&#31687;&#34892;&#19994;&#35770;&#25991;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#24182;&#24471;&#20986;&#26377;&#24847;&#20041;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14558v1 Announce Type: new  Abstract: Large language models (LLMs) have become the secret ingredient driving numerous industrial applications, showcasing their remarkable versatility across a diverse spectrum of tasks. From natural language processing and sentiment analysis to content generation and personalized recommendations, their unparalleled adaptability has facilitated widespread adoption across industries. This transformative shift driven by LLMs underscores the need to explore the underlying associated challenges and avenues for enhancement in their utilization. In this paper, our objective is to unravel and evaluate the obstacles and opportunities inherent in leveraging LLMs within an industrial context. To this end, we conduct a survey involving a group of industry practitioners, develop four research questions derived from the insights gathered, and examine 68 industry papers to address these questions and derive meaningful conclusions.
&lt;/p&gt;</description></item><item><title>&#26816;&#32034;&#20197;&#35299;&#37322;&#65288;R2E&#65289;&#26159;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;Shapley&#20540;&#30830;&#23450;&#35777;&#25454;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#65292;&#20174;&#32780;&#22312;&#40657;&#30418;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#24212;&#29992;&#20110;&#33647;&#29289;&#38774;&#28857;&#37492;&#23450;&#20219;&#21153;&#20013;&#65292;R2E&#27169;&#22411;&#22312;&#39044;&#27979;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#22522;&#22240;&#23398;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.04068</link><description>&lt;p&gt;
&#26816;&#32034;&#20197;&#35299;&#37322;&#65306;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#35777;&#25454;&#39537;&#21160;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Retrieve to Explain: Evidence-driven Predictions with Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04068
&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#20197;&#35299;&#37322;&#65288;R2E&#65289;&#26159;&#19968;&#31181;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#26816;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;Shapley&#20540;&#30830;&#23450;&#35777;&#25454;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#65292;&#20174;&#32780;&#22312;&#40657;&#30418;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#24212;&#29992;&#20110;&#33647;&#29289;&#38774;&#28857;&#37492;&#23450;&#20219;&#21153;&#20013;&#65292;R2E&#27169;&#22411;&#22312;&#39044;&#27979;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#22522;&#22240;&#23398;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#23588;&#20854;&#26159;&#35821;&#35328;&#27169;&#22411;&#65292;&#24448;&#24448;&#38590;&#20197;&#28145;&#20837;&#20998;&#26512;&#12290;&#40657;&#30418;&#27169;&#22411;&#21487;&#33021;&#25513;&#30422;&#20102;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#38382;&#39064;&#21644;&#26377;&#23475;&#20559;&#24046;&#12290;&#23545;&#20110;&#20154;&#26426;&#21327;&#20316;&#36807;&#31243;&#26469;&#35828;&#65292;&#19981;&#36879;&#26126;&#30340;&#39044;&#27979;&#21487;&#33021;&#23548;&#33268;&#32570;&#20047;&#20449;&#20219;&#65292;&#38480;&#21046;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#21363;&#20351;&#27169;&#22411;&#30340;&#24615;&#33021;&#24456;&#22909;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26816;&#32034;&#20197;&#35299;&#37322;&#65288;Retrieve to Explain&#65292;&#31616;&#31216;R2E&#65289;&#12290;R2E&#26159;&#19968;&#31181;&#22522;&#20110;&#26816;&#32034;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#26681;&#25454;&#25991;&#26723;&#35821;&#26009;&#24211;&#20013;&#30340;&#35777;&#25454;&#65292;&#20351;&#29992;Shapley&#20540;&#26469;&#30830;&#23450;&#35777;&#25454;&#23545;&#26368;&#32456;&#39044;&#27979;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#65292;&#24182;&#26681;&#25454;&#33258;&#28982;&#35821;&#35328;&#27169;&#26495;&#23558;&#32467;&#26500;&#21270;&#25968;&#25454;&#32435;&#20837;&#20854;&#20013;&#12290;R2E&#33021;&#22815;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#36866;&#24212;&#26032;&#30340;&#35777;&#25454;&#65292;&#24182;&#19988;&#33021;&#22815;&#36890;&#36807;&#27169;&#26495;&#21270;&#23558;&#32467;&#26500;&#21270;&#25968;&#25454;&#32435;&#20837;&#21040;&#33258;&#28982;&#35821;&#35328;&#20013;&#12290;&#25105;&#20204;&#22312;&#36890;&#36807;&#20998;&#26512;&#24050;&#21457;&#34920;&#30340;&#31185;&#23398;&#25991;&#29486;&#36827;&#34892;&#33647;&#29289;&#38774;&#28857;&#37492;&#23450;&#30340;&#23454;&#38469;&#26696;&#20363;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#27169;&#22411;&#22312;&#39044;&#27979;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#26041;&#38754;&#20248;&#20110;&#34892;&#19994;&#26631;&#20934;&#30340;&#22522;&#22240;&#23398;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models, particularly language models, are notoriously difficult to introspect. Black-box models can mask both issues in model training and harmful biases. For human-in-the-loop processes, opaque predictions can drive lack of trust, limiting a model's impact even when it performs effectively. To address these issues, we introduce Retrieve to Explain (R2E). R2E is a retrieval-based language model that prioritizes amongst a pre-defined set of possible answers to a research question based on the evidence in a document corpus, using Shapley values to identify the relative importance of pieces of evidence to the final prediction. R2E can adapt to new evidence without retraining, and incorporate structured data through templating into natural language. We assess on the use case of drug target identification from published scientific literature, where we show that the model outperforms an industry-standard genetics-based approach on predicting clinical trial outcomes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#22686;&#21152;&#23545;&#40784;&#24230;&#21644;&#20943;&#23569;&#26377;&#29992;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#25552;&#20379;&#36825;&#20004;&#20010;&#25968;&#37327;&#30340;&#36793;&#30028;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.16332</link><description>&lt;p&gt;
&#23545;&#40784;&#21644;&#26377;&#29992;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65306;&#35821;&#35328;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Tradeoffs Between Alignment and Helpfulness in Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.16332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#22686;&#21152;&#23545;&#40784;&#24230;&#21644;&#20943;&#23569;&#26377;&#29992;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#25552;&#20379;&#36825;&#20004;&#20010;&#25968;&#37327;&#30340;&#36793;&#30028;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#24050;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#23433;&#20840;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#36890;&#36807;&#22686;&#24378;&#26399;&#26395;&#34892;&#20026;&#21644;&#25233;&#21046;&#38750;&#26399;&#26395;&#34892;&#20026;&#65292;&#23454;&#29616;&#20154;&#31867;&#19982;&#35821;&#35328;&#27169;&#22411;&#20043;&#38388;&#30340;&#23433;&#20840;&#20132;&#20114;&#12290;&#36890;&#24120;&#36890;&#36807;&#35843;&#25972;&#27169;&#22411;&#25110;&#25554;&#20837;&#39044;&#35774;&#30340;&#23545;&#40784;&#25552;&#31034;&#26469;&#23454;&#29616;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#25913;&#21464;&#35757;&#32451;&#21518;&#30340;&#34920;&#31034;&#26469;&#25913;&#21464;&#27169;&#22411;&#34892;&#20026;&#30340;&#34920;&#31034;&#24037;&#31243;&#26041;&#27861;&#22312;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#26377;&#25928;&#24615;&#12290;&#34920;&#31034;&#24037;&#31243;&#22312;&#38754;&#23545;&#23545;&#25239;&#25915;&#20987;&#21644;&#38477;&#20302;&#31038;&#20250;&#20559;&#35265;&#31561;&#23545;&#40784;&#23548;&#21521;&#20219;&#21153;&#26041;&#38754;&#21462;&#24471;&#20102;&#22686;&#30410;&#65292;&#20294;&#20063;&#23548;&#33268;&#20102;&#27169;&#22411;&#25191;&#34892;&#22522;&#26412;&#20219;&#21153;&#33021;&#21147;&#30340;&#38477;&#20302;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22686;&#21152;&#23545;&#40784;&#24230;&#21644;&#20943;&#23569;&#27169;&#22411;&#26377;&#29992;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#25552;&#20379;&#36825;&#20004;&#20010;&#25968;&#37327;&#30340;&#36793;&#30028;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#27169;&#22411;&#30340;&#26377;&#29992;&#24615;&#36890;&#24120;&#20250;&#20943;&#23569;
&lt;/p&gt;
&lt;p&gt;
Language model alignment has become an important component of AI safety, allowing safe interactions between humans and language models, by enhancing desired behaviors and inhibiting undesired ones. It is often done by tuning the model or inserting preset aligning prompts. Recently, representation engineering, a method which alters the model's behavior via changing its representations post-training, was shown to be effective in aligning LLMs (Zou et al., 2023a). Representation engineering yields gains in alignment oriented tasks such as resistance to adversarial attacks and reduction of social biases, but was also shown to cause a decrease in the ability of the model to perform basic tasks. In this paper we study the tradeoff between the increase in alignment and decrease in helpfulness of the model. We propose a theoretical framework which provides bounds for these two quantities, and demonstrate their relevance empirically. Interestingly, we find that while the helpfulness generally d
&lt;/p&gt;</description></item><item><title>CLEVRER-Humans&#26159;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21028;&#26029;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20154;&#24037;&#26631;&#27880;&#26469;&#35299;&#20915;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#35821;&#35328;&#25551;&#36848;&#30340;&#32570;&#20047;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#21644;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.03635</link><description>&lt;p&gt;
CLEVRER-Humans: &#29992;&#20154;&#31867;&#30340;&#26041;&#24335;&#25551;&#36848;&#29289;&#29702;&#21644;&#22240;&#26524;&#20107;&#20214;
&lt;/p&gt;
&lt;p&gt;
CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03635
&lt;/p&gt;
&lt;p&gt;
CLEVRER-Humans&#26159;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21028;&#26029;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20154;&#24037;&#26631;&#27880;&#26469;&#35299;&#20915;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#35821;&#35328;&#25551;&#36848;&#30340;&#32570;&#20047;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#21644;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#33021;&#22815;&#25512;&#29702;&#29289;&#29702;&#20107;&#20214;&#21450;&#20854;&#22240;&#26524;&#20851;&#31995;&#30340;&#26426;&#22120;&#23545;&#20110;&#19982;&#29289;&#29702;&#19990;&#30028;&#36827;&#34892;&#28789;&#27963;&#20114;&#21160;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#29289;&#29702;&#21644;&#22240;&#26524;&#25512;&#29702;&#22522;&#20934;&#37117;&#20165;&#22522;&#20110;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#36825;&#31181;&#35774;&#35745;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#65306;&#19968;&#26159;&#20107;&#20214;&#31867;&#22411;&#21644;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#32570;&#20047;&#22810;&#26679;&#24615;&#65307;&#20108;&#26159;&#22522;&#20110;&#25163;&#21160;&#23450;&#20041;&#30340;&#21551;&#21457;&#24335;&#35268;&#21017;&#30340;&#22240;&#26524;&#20851;&#31995;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CLEVRER-Humans&#22522;&#20934;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20154;&#24037;&#26631;&#27880;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#23545;&#29289;&#29702;&#20107;&#20214;&#30340;&#22240;&#26524;&#21028;&#26029;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#31181;&#25216;&#26415;&#26469;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#65306;&#39318;&#20808;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#20219;&#21153;&#65292;&#20197; eliciting &#35270;&#39057;&#20013;&#20107;&#20214;&#30340;&#26032;&#34920;&#31034;&#26041;&#24335;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#22240;&#26524;&#20107;&#20214;&#22270; (CEGs)&#65307;&#20854;&#27425;&#65292;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Building machines that can reason about physical events and their causal relationships is crucial for flexible interaction with the physical world. However, most existing physical and causal reasoning benchmarks are exclusively based on synthetically generated events and synthetic natural language descriptions of causal relationships. This design brings up two issues. First, there is a lack of diversity in both event types and natural language descriptions; second, causal relationships based on manually-defined heuristics are different from human judgments. To address both shortcomings, we present the CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of physical events with human labels. We employ two techniques to improve data collection efficiency: first, a novel iterative event cloze task to elicit a new representation of events in videos, which we term Causal Event Graphs (CEGs); second, a data augmentation technique based on neural language generative models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992; Evol-Instruct &#26041;&#27861;&#21019;&#24314;&#20102;&#22823;&#37327;&#19981;&#21516;&#22797;&#26434;&#24230;&#30340;&#25351;&#20196;&#25968;&#25454;&#29992;&#20110;&#24494;&#35843; LLaMA &#27169;&#22411;&#65292;&#24471;&#21040;&#20102;&#26032;&#27169;&#22411; WizardLM&#12290;&#20154;&#31867;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126; Evol-Instruct &#29983;&#25104;&#30340;&#25351;&#20196;&#20248;&#20110;&#20154;&#24037;&#21019;&#24314;&#30340;&#65292;&#32780; WizardLM &#36755;&#20986;&#30340;&#32467;&#26524;&#20063;&#27604; OpenAI ChatGPT &#26356;&#21463;&#27426;&#36814;&#12290;</title><link>http://arxiv.org/abs/2304.12244</link><description>&lt;p&gt;
WizardLM: &#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36981;&#24490;&#22797;&#26434;&#25351;&#20196;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
WizardLM: Empowering Large Language Models to Follow Complex Instructions. (arXiv:2304.12244v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992; Evol-Instruct &#26041;&#27861;&#21019;&#24314;&#20102;&#22823;&#37327;&#19981;&#21516;&#22797;&#26434;&#24230;&#30340;&#25351;&#20196;&#25968;&#25454;&#29992;&#20110;&#24494;&#35843; LLaMA &#27169;&#22411;&#65292;&#24471;&#21040;&#20102;&#26032;&#27169;&#22411; WizardLM&#12290;&#20154;&#31867;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126; Evol-Instruct &#29983;&#25104;&#30340;&#25351;&#20196;&#20248;&#20110;&#20154;&#24037;&#21019;&#24314;&#30340;&#65292;&#32780; WizardLM &#36755;&#20986;&#30340;&#32467;&#26524;&#20063;&#27604; OpenAI ChatGPT &#26356;&#21463;&#27426;&#36814;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#24320;&#25918;&#22495;&#25351;&#20196;&#36861;&#36394;&#25968;&#25454;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#25163;&#21160;&#21019;&#24314;&#36825;&#26679;&#30340;&#25351;&#20196;&#25968;&#25454;&#38750;&#24120;&#32791;&#26102;&#21644;&#21171;&#21160;&#23494;&#38598;&#65292;&#19988;&#20154;&#31867;&#21487;&#33021;&#38590;&#20197;&#29983;&#25104;&#39640;&#22797;&#26434;&#24230;&#25351;&#20196;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;LLM&#32780;&#19981;&#26159;&#20154;&#31867;&#21019;&#24314;&#22823;&#37327;&#19981;&#21516;&#22797;&#26434;&#24230;&#25351;&#20196;&#25968;&#25454;&#30340;&#36884;&#24452;&#12290;&#25105;&#20204;&#20174;&#19968;&#32452;&#21021;&#22987;&#25351;&#20196;&#24320;&#22987;&#65292;&#20351;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;Evol-Instruct&#36880;&#27493;&#23558;&#20854;&#37325;&#26032;&#32534;&#20889;&#20026;&#26356;&#22797;&#26434;&#30340;&#25351;&#20196;&#12290;&#28982;&#21518;&#65292;&#23558;&#25152;&#26377;&#29983;&#25104;&#30340;&#25351;&#20196;&#25968;&#25454;&#28151;&#21512;&#20197;&#24494;&#35843;LLaMA&#12290;&#25105;&#20204;&#31216;&#32467;&#26524;&#27169;&#22411;&#20026;WizardLM&#12290;&#38024;&#23545;&#19968;&#20010;&#22797;&#26434;&#24230;&#24179;&#34913;&#30340;&#27979;&#35797;&#38598;&#21644;Vicuna&#30340;&#27979;&#35797;&#38598;&#36827;&#34892;&#30340;&#20154;&#31867;&#35780;&#20272;&#34920;&#26126;&#65292;Evol-Instruct&#29983;&#25104;&#30340;&#25351;&#20196;&#20248;&#20110;&#20154;&#24037;&#21019;&#24314;&#30340;&#25351;&#20196;&#12290;&#36890;&#36807;&#20998;&#26512;&#39640;&#22797;&#26434;&#24615;&#37096;&#20998;&#30340;&#20154;&#31867;&#35780;&#20272;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20174;&#25105;&#20204;&#30340;WizardLM&#29983;&#25104;&#30340;&#36755;&#20986;&#27604;&#20174;OpenAI ChatGPT&#29983;&#25104;&#30340;&#36755;&#20986;&#26356;&#21463;&#27426;&#36814;&#12290;&#22312;GPT-4&#33258;&#21160;&#35780;&#20272;&#20013;&#65292;WizardLM&#20135;&#29983;&#20102;&#26368;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation
&lt;/p&gt;</description></item></channel></rss>