<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#34913;&#37327;&#25991;&#26412;&#22810;&#26679;&#24615;&#30340;&#26631;&#20934;&#20998;&#25968;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#21387;&#32553;&#31639;&#27861;&#21487;&#20197;&#25429;&#25417;&#31867;&#20284;&#20110;$n$-gram&#37325;&#21472;&#21516;&#36136;&#24615;&#24471;&#20998;&#30340;&#20449;&#24687;&#65292;&#24182;&#32467;&#21512;&#22810;&#31181;&#24230;&#37327;&#26041;&#27861;&#26469;&#25253;&#21578;&#20998;&#25968;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#31867;&#22411;&#30340;&#25991;&#26412;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2403.00553</link><description>&lt;p&gt;
&#35268;&#33539;&#25991;&#26412;&#22810;&#26679;&#24615;&#30340;&#27979;&#37327;&#65306;&#19968;&#20010;&#24037;&#20855;&#21644;&#23545;&#20998;&#25968;&#30340;&#27604;&#36739;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Standardizing the Measurement of Text Diversity: A Tool and a Comparative Analysis of Scores
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#34913;&#37327;&#25991;&#26412;&#22810;&#26679;&#24615;&#30340;&#26631;&#20934;&#20998;&#25968;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#21387;&#32553;&#31639;&#27861;&#21487;&#20197;&#25429;&#25417;&#31867;&#20284;&#20110;$n$-gram&#37325;&#21472;&#21516;&#36136;&#24615;&#24471;&#20998;&#30340;&#20449;&#24687;&#65292;&#24182;&#32467;&#21512;&#22810;&#31181;&#24230;&#37327;&#26041;&#27861;&#26469;&#25253;&#21578;&#20998;&#25968;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#31867;&#22411;&#30340;&#25991;&#26412;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#36755;&#20986;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#22609;&#36896;&#20102;&#20154;&#20204;&#23545;&#20854;&#36136;&#37327;&#21644;&#23454;&#29992;&#24615;&#30340;&#30475;&#27861;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#33521;&#35821;&#25991;&#26412;&#30340;&#22810;&#26679;&#24615;&#24471;&#20998;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#21387;&#32553;&#31639;&#27861;&#25429;&#25417;&#21040;&#19982;$n$-gram&#30340;&#37325;&#21472;&#21516;&#36136;&#24615;&#24471;&#20998;&#25152;&#34913;&#37327;&#30340;&#20449;&#24687;&#30456;&#20284;&#12290;&#27492;&#22806;&#65292;&#32467;&#21512;&#22810;&#31181;&#24230;&#37327;&#26041;&#27861;&#8212;&#8212;&#21387;&#32553;&#27604;&#12289;&#38271;$n$-gram&#30340;&#33258;&#37325;&#22797;&#12289;Self-BLEU&#21644;BERTScore&#8212;&#8212;&#36275;&#20197;&#25253;&#21578;&#65292;&#22240;&#20026;&#23427;&#20204;&#24444;&#27492;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#32852;&#36739;&#20302;&#12290;&#36825;&#20123;&#20998;&#25968;&#30340;&#36866;&#29992;&#24615;&#36229;&#20986;&#20102;&#29983;&#25104;&#27169;&#22411;&#30340;&#20998;&#26512;&#65307;&#20363;&#22914;&#65292;&#25105;&#20204;&#31361;&#20986;&#20102;&#22312;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#38598;&#21644;&#20154;&#31867;&#29983;&#25104;&#30340;&#25991;&#26412;&#19978;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#19968;&#20010;&#22810;&#26679;&#24615;&#31243;&#24230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00553v1 Announce Type: new  Abstract: The diversity across outputs generated by large language models shapes the perception of their quality and utility. Prompt leaks, templated answer structure, and canned responses across different interactions are readily noticed by people, but there is no standard score to measure this aspect of model behavior. In this work we empirically investigate diversity scores on English texts. We find that computationally efficient compression algorithms capture information similar to what is measured by slow to compute $n$-gram overlap homogeneity scores. Further, a combination of measures -- compression ratios, self-repetition of long $n$-grams and Self-BLEU and BERTScore -- are sufficient to report, as they have low mutual correlation with each other. The applicability of scores extends beyond analysis of generative models; for example, we highlight applications on instruction-tuning datasets and human-produced texts. We release a diversity sc
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35848;&#21028;&#28216;&#25103;&#30340;&#35270;&#35282;&#65292;&#25552;&#20986;&#20849;&#21516;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#30340;&#24615;&#33021;&#21644;&#23545;&#40784;&#65292;&#20197;&#26356;&#22909;&#22320;&#21453;&#26144;&#30495;&#23454;&#19990;&#30028;&#30340;&#37096;&#32626;&#26465;&#20214;&#65292;&#24182;&#36991;&#20813;&#25968;&#25454;&#27844;&#28431;&#12290;&#36890;&#36807;&#35780;&#20272;&#22810;&#36718;&#27425;&#21644;&#36328;&#27169;&#22411;&#20132;&#20114;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;LM&#30340;&#33258;&#25105;&#23545;&#24328;&#21644;&#20132;&#21449;&#23545;&#24328;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.04536</link><description>&lt;p&gt;
&#36890;&#36807;&#35848;&#21028;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#30340;&#20195;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Evaluating Language Model Agency through Negotiations. (arXiv:2401.04536v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04536
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35848;&#21028;&#28216;&#25103;&#30340;&#35270;&#35282;&#65292;&#25552;&#20986;&#20849;&#21516;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#30340;&#24615;&#33021;&#21644;&#23545;&#40784;&#65292;&#20197;&#26356;&#22909;&#22320;&#21453;&#26144;&#30495;&#23454;&#19990;&#30028;&#30340;&#37096;&#32626;&#26465;&#20214;&#65292;&#24182;&#36991;&#20813;&#25968;&#25454;&#27844;&#28431;&#12290;&#36890;&#36807;&#35780;&#20272;&#22810;&#36718;&#27425;&#21644;&#36328;&#27169;&#22411;&#20132;&#20114;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;LM&#30340;&#33258;&#25105;&#23545;&#24328;&#21644;&#20132;&#21449;&#23545;&#24328;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#21496;&#12289;&#32452;&#32455;&#21644;&#25919;&#24220;&#36234;&#26469;&#36234;&#22810;&#22320;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#23637;&#31034;&#31867;&#20284;&#20195;&#29702;&#34892;&#20026;&#30340;&#20986;&#33394;&#33021;&#21147;&#12290;&#38543;&#30528;LM&#34987;&#37319;&#29992;&#26469;&#25191;&#34892;&#36234;&#26469;&#36234;&#20855;&#26377;&#33258;&#20027;&#24615;&#30340;&#20219;&#21153;&#65292;&#36843;&#20999;&#38656;&#35201;&#21487;&#38752;&#19988;&#21487;&#25193;&#23637;&#30340;&#35780;&#20272;&#22522;&#20934;&#12290;&#24403;&#21069;&#20027;&#35201;&#26159;&#38745;&#24577;&#30340;LM&#22522;&#20934;&#26080;&#27861;&#24456;&#22909;&#22320;&#35780;&#20272;&#27492;&#31867;&#21160;&#24577;&#24212;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#35758;&#36890;&#36807;&#35848;&#21028;&#28216;&#25103;&#30340;&#35270;&#35282;&#26469;&#20849;&#21516;&#35780;&#20272;LM&#30340;&#24615;&#33021;&#21644;&#23545;&#40784;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#20010;&#20849;&#21516;&#20219;&#21153;&#26356;&#22909;&#22320;&#21453;&#26144;&#20102;&#30495;&#23454;&#19990;&#30028;&#30340;&#37096;&#32626;&#26465;&#20214;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;LM&#20915;&#31574;&#36807;&#31243;&#30340;&#35265;&#35299;&#12290;&#33267;&#20851;&#37325;&#35201;&#30340;&#26159;&#65292;&#35848;&#21028;&#28216;&#25103;&#20351;&#25105;&#20204;&#33021;&#22815;&#30740;&#31350;&#22810;&#36718;&#27425;&#21644;&#36328;&#27169;&#22411;&#20132;&#20114;&#65292;&#35843;&#25972;&#22797;&#26434;&#24615;&#65292;&#24182;&#36991;&#20813;&#35780;&#20272;&#20013;&#30340;&#24847;&#22806;&#25968;&#25454;&#27844;&#28431;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#26469;&#33258;&#20960;&#20010;&#20027;&#35201;&#20379;&#24212;&#21830;&#30340;&#20845;&#20010;&#20844;&#24320;&#21487;&#35775;&#38382;&#30340;LM&#22312;&#21508;&#31181;&#35848;&#21028;&#28216;&#25103;&#19978;&#30340;&#32467;&#26524;&#65292;&#35780;&#20272;&#20102;&#33258;&#25105;&#23545;&#24328;&#21644;&#20132;&#21449;&#23545;&#24328;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#21457;&#29616;&#21253;&#25324;&#65306;&#65288;i&#65289;&#24320;&#28304;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
Companies, organizations, and governments increasingly exploit Language Models' (LM) remarkable capability to display agent-like behavior. As LMs are adopted to perform tasks with growing autonomy, there exists an urgent need for reliable and scalable evaluation benchmarks. Current, predominantly static LM benchmarks are ill-suited to evaluate such dynamic applications. Thus, we propose jointly evaluating LM performance and alignment through the lenses of negotiation games. We argue that this common task better reflects real-world deployment conditions while offering insights into LMs' decision-making processes. Crucially, negotiation games allow us to study multi-turn, and cross-model interactions, modulate complexity, and side-step accidental data leakage in evaluation. We report results for six publicly accessible LMs from several major providers on a variety of negotiation games, evaluating both self-play and cross-play performance. Noteworthy findings include: (i) open-source mode
&lt;/p&gt;</description></item></channel></rss>