<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#65292;&#36890;&#36807;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#26412;&#27604;&#36739;&#65292;&#24182;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#35780;&#20998;&#23610;&#24230;&#12290;&#35813;&#26041;&#27861;&#22312;Twitter&#19978;&#23545;&#24773;&#24863;&#35328;&#35770;&#30340;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.12049</link><description>&lt;p&gt;
Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models (&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#25552;&#31034;&#36827;&#34892;&#25991;&#26412;&#37197;&#23545;&#27604;&#36739;&#32553;&#25918;)
&lt;/p&gt;
&lt;p&gt;
Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models. (arXiv:2310.12049v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12049
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#65292;&#36890;&#36807;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#26412;&#27604;&#36739;&#65292;&#24182;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#35780;&#20998;&#23610;&#24230;&#12290;&#35813;&#26041;&#27861;&#22312;Twitter&#19978;&#23545;&#24773;&#24863;&#35328;&#35770;&#30340;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#25991;&#26412;&#32553;&#25918;&#26041;&#27861;&#32463;&#24120;&#38656;&#35201;&#22823;&#22411;&#35821;&#26009;&#24211;&#65292;&#38590;&#20197;&#22788;&#29702;&#30701;&#25991;&#26412;&#65292;&#25110;&#38656;&#35201;&#26377;&#26631;&#31614;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#27169;&#24335;&#35782;&#21035;&#33021;&#21147;&#26469;&#36827;&#34892;&#25991;&#26412;&#32553;&#25918;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27010;&#24565;&#23548;&#21521;&#24605;&#32500;&#38142;&#22270;&#65288;CGCoT&#65289;&#65292;&#23427;&#20351;&#29992;&#35774;&#35745;&#29992;&#20110;&#24635;&#32467;&#24819;&#27861;&#24182;&#22312;&#25991;&#26412;&#20013;&#35782;&#21035;&#30446;&#26631;&#26041;&#30340;&#25552;&#31034;&#26469;&#29983;&#25104;&#27010;&#24565;&#29305;&#23450;&#30340;&#32454;&#20998;&#65292;&#31867;&#20284;&#20110;&#20154;&#31867;&#32534;&#30721;&#22120;&#20869;&#23481;&#20998;&#26512;&#30340;&#25351;&#23548;&#12290;CGCoT&#23558;&#37197;&#23545;&#25991;&#26412;&#27604;&#36739;&#20174;&#19968;&#20010;&#25512;&#29702;&#38382;&#39064;&#36716;&#21464;&#20026;&#19968;&#20010;&#27169;&#24335;&#35782;&#21035;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;LLM&#23545;&#27010;&#24565;&#29305;&#23450;&#30340;&#32454;&#20998;&#36827;&#34892;&#37197;&#23545;&#27604;&#36739;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#37197;&#23545;&#27604;&#36739;&#30340;&#32467;&#26524;&#20351;&#29992;Bradley-Terry&#27169;&#22411;&#26469;&#20272;&#35745;&#19968;&#20010;&#35780;&#20998;&#23610;&#24230;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#23545;Twitter&#19978;&#30340;&#24773;&#24863;&#35328;&#35770;&#36827;&#34892;&#32553;&#25918;&#12290;&#25105;&#20204;&#30340;&#27979;&#37327;&#20540;&#19982;&#20154;&#31867;&#21028;&#26029;&#30340;&#30456;&#20851;&#24615;&#27604;Wordfish&#31561;&#26367;&#20195;&#26041;&#27861;&#26356;&#24378;&#12290;&#38500;&#20102;&#19968;&#23567;&#32452;&#29992;&#20110;&#24320;&#21457;CGCoT&#25552;&#31034;&#30340;&#35797;&#39564;&#25968;&#25454;&#20043;&#22806;&#65292;...
&lt;/p&gt;
&lt;p&gt;
Existing text scaling methods often require a large corpus, struggle with short texts, or require labeled data. We develop a text scaling method that leverages the pattern recognition capabilities of generative large language models (LLMs). Specifically, we propose concept-guided chain-of-thought (CGCoT), which uses prompts designed to summarize ideas and identify target parties in texts to generate concept-specific breakdowns, in many ways similar to guidance for human coder content analysis. CGCoT effectively shifts pairwise text comparisons from a reasoning problem to a pattern recognition problem. We then pairwise compare concept-specific breakdowns using an LLM. We use the results of these pairwise comparisons to estimate a scale using the Bradley-Terry model. We use this approach to scale affective speech on Twitter. Our measures correlate more strongly with human judgments than alternative approaches like Wordfish. Besides a small set of pilot data to develop the CGCoT prompts, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;Transformer&#22312;&#35821;&#38899;&#30456;&#20851;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#20026;&#30740;&#31350;&#32773;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36164;&#28304;&#12290;&#21516;&#26102;&#65292;&#25351;&#20986;&#20102;&#22312;&#35821;&#38899;&#22788;&#29702;&#39046;&#22495;&#20013;Transformer&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21450;&#21487;&#33021;&#30340;&#35299;&#20915;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2303.11607</link><description>&lt;p&gt;
&#35770;&#25991;&#32763;&#35793;&#65306;&#35821;&#38899;&#22788;&#29702;&#20013;&#30340;Transformer&#65306;&#32508;&#36848;&#65288;arXiv:2303.11607v1 [cs.CL]&#65289;
&lt;/p&gt;
&lt;p&gt;
Transformers in Speech Processing: A Survey. (arXiv:2303.11607v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11607
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;Transformer&#22312;&#35821;&#38899;&#30456;&#20851;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#20026;&#30740;&#31350;&#32773;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36164;&#28304;&#12290;&#21516;&#26102;&#65292;&#25351;&#20986;&#20102;&#22312;&#35821;&#38899;&#22788;&#29702;&#39046;&#22495;&#20013;Transformer&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#21450;&#21487;&#33021;&#30340;&#35299;&#20915;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer &#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#30340;&#26174;&#33879;&#25104;&#21151;&#24341;&#36215;&#20102;&#35821;&#38899;&#22788;&#29702;&#31038;&#21306;&#30340;&#20852;&#36259;&#65292;&#36827;&#32780;&#25506;&#32034;&#20102;&#20854;&#27169;&#25311;&#35821;&#38899;&#24207;&#21015;&#20013;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#30340;&#28508;&#21147;&#12290;&#26368;&#36817;&#65292;Transformer &#22312;&#21508;&#31181;&#28041;&#21450;&#35821;&#38899;&#30340;&#39046;&#22495;&#20013;&#21517;&#22768;&#40522;&#36215;&#65292;&#21253;&#25324;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#12289;&#35821;&#38899;&#21512;&#25104;&#12289;&#35821;&#38899;&#32763;&#35793;&#12289;&#35821;&#38899;&#22768;&#35843;&#23398;&#12289;&#35821;&#38899;&#22686;&#24378;&#12289;&#21475;&#35821;&#23545;&#35805;&#31995;&#32479;&#65292;&#20197;&#21450;&#35768;&#22810;&#22810;&#27169;&#24577;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20379;&#19968;&#20221;&#32508;&#21512;&#24615;&#35843;&#26597;&#25253;&#21578;&#65292;&#26088;&#22312;&#26725;&#25509;&#35821;&#38899;&#25216;&#26415;&#21508;&#23376;&#39046;&#22495;&#30340;&#30740;&#31350;&#12290;&#36890;&#36807;&#25972;&#21512;&#26469;&#33258;&#35821;&#38899;&#25216;&#26415;&#39046;&#22495;&#30340;&#30740;&#31350;&#32467;&#26524;&#65292;&#25105;&#20204;&#20026;&#24076;&#26395;&#21033;&#29992;Transformer&#25512;&#36827;&#39046;&#22495;&#21457;&#23637;&#30340;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36164;&#28304;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#20063;&#25351;&#20986;&#20102;Transformer&#22312;&#35821;&#38899;&#22788;&#29702;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#28508;&#22312;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable success of transformers in the field of natural language processing has sparked the interest of the speech-processing community, leading to an exploration of their potential for modeling long-range dependencies within speech sequences. Recently, transformers have gained prominence across various speech-related domains, including automatic speech recognition, speech synthesis, speech translation, speech para-linguistics, speech enhancement, spoken dialogue systems, and numerous multimodal applications. In this paper, we present a comprehensive survey that aims to bridge research studies from diverse subfields within speech technology. By consolidating findings from across the speech technology landscape, we provide a valuable resource for researchers interested in harnessing the power of transformers to advance the field. We identify the challenges encountered by transformers in speech processing while also offering insights into potential solutions to address these issue
&lt;/p&gt;</description></item></channel></rss>