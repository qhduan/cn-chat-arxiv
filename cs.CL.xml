<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36890;&#36807;&#28151;&#21512;&#32467;&#26500;&#21270;&#25688;&#35201;&#21644;&#22522;&#20110;LLM&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#20027;&#39064;&#30456;&#20851;&#24615;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#26356;&#22909;&#22320;&#23398;&#20064;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24230;&#12290;</title><link>https://arxiv.org/abs/2404.02616</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#32467;&#26500;&#21270;&#25688;&#35201;&#21644;&#22522;&#20110;LLM&#30340;&#25968;&#25454;&#22686;&#24378;&#26469;&#25913;&#36827;&#20027;&#39064;&#30456;&#20851;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Improving Topic Relevance Model by Mix-structured Summarization and LLM-based Data Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02616
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#32467;&#26500;&#21270;&#25688;&#35201;&#21644;&#22522;&#20110;LLM&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#20027;&#39064;&#30456;&#20851;&#24615;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#26356;&#22909;&#22320;&#23398;&#20064;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26597;&#35810;&#21644;&#25991;&#26723;&#20043;&#38388;&#30340;&#20027;&#39064;&#30456;&#20851;&#24615;&#26159;&#31038;&#20132;&#25628;&#32034;&#30340;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#37096;&#20998;&#65292;&#21487;&#20197;&#35780;&#20272;&#25991;&#26723;&#19982;&#29992;&#25143;&#38656;&#27714;&#20043;&#38388;&#30340;&#21305;&#37197;&#31243;&#24230;&#12290;&#22312;&#22823;&#22810;&#25968;&#31038;&#20132;&#25628;&#32034;&#22330;&#26223;&#20013;&#65292;&#22914;&#22823;&#20247;&#28857;&#35780;&#65292;&#24314;&#27169;&#25628;&#32034;&#30456;&#20851;&#24615;&#24635;&#26159;&#38754;&#20020;&#20004;&#20010;&#25361;&#25112;&#12290;&#19968;&#20010;&#26159;&#35768;&#22810;&#31038;&#20132;&#25628;&#32034;&#20013;&#30340;&#25991;&#26723;&#38750;&#24120;&#38271;&#19988;&#21253;&#21547;&#22823;&#37327;&#20887;&#20313;&#20449;&#24687;&#12290;&#21478;&#19968;&#20010;&#38382;&#39064;&#26159;&#25628;&#32034;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#24456;&#38590;&#33719;&#24471;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#22810;&#20998;&#31867;&#30456;&#20851;&#24615;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#20197;&#19978;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#26597;&#35810;&#19982;&#22522;&#20110;&#26597;&#35810;&#30340;&#25688;&#35201;&#20197;&#21450;&#19981;&#24102;&#26597;&#35810;&#30340;&#25991;&#26723;&#25688;&#35201;&#21512;&#24182;&#65292;&#20316;&#20026;&#20027;&#39064;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#36755;&#20837;&#65292;&#36825;&#26377;&#21161;&#20110;&#27169;&#22411;&#23398;&#20064;&#26597;&#35810;&#21644;&#25991;&#26723;&#26680;&#24515;&#20027;&#39064;&#20043;&#38388;&#30340;&#30456;&#20851;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#20174;&#29616;&#26377;&#35757;&#32451;&#25968;&#25454;&#20013;&#37325;&#26032;&#32534;&#20889;&#21644;&#29983;&#25104;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02616v1 Announce Type: cross  Abstract: Topic relevance between query and document is a very important part of social search, which can evaluate the degree of matching between document and user's requirement. In most social search scenarios such as Dianping, modeling search relevance always faces two challenges. One is that many documents in social search are very long and have much redundant information. The other is that the training data for search relevance model is difficult to get, especially for multi-classification relevance model. To tackle above two problems, we first take query concatenated with the query-based summary and the document summary without query as the input of topic relevance model, which can help model learn the relevance degree between query and the core topic of document. Then, we utilize the language understanding and generation abilities of large language model (LLM) to rewrite and generate query from queries and documents in existing training da
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#21521;&#37327;&#25509;&#22320;&#38382;&#39064;&#65292;&#36890;&#36807;&#21306;&#20998;&#20869;&#37096;&#34920;&#31034;&#25509;&#22320;&#30340;&#19981;&#21516;&#26041;&#24335;&#65292;&#24635;&#32467;&#20986;&#20116;&#20010;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2304.01481</link><description>&lt;p&gt;
&#21521;&#37327;&#25509;&#22320;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
The Vector Grounding Problem. (arXiv:2304.01481v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#21521;&#37327;&#25509;&#22320;&#38382;&#39064;&#65292;&#36890;&#36807;&#21306;&#20998;&#20869;&#37096;&#34920;&#31034;&#25509;&#22320;&#30340;&#19981;&#21516;&#26041;&#24335;&#65292;&#24635;&#32467;&#20986;&#20116;&#20010;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22788;&#29702;&#22797;&#26434;&#30340;&#35821;&#35328;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#24341;&#21457;&#20102;&#23545;&#23427;&#20204;&#33021;&#21147;&#26412;&#36136;&#30340;&#28608;&#28872;&#36777;&#35770;&#12290;&#19981;&#21516;&#20110;&#20154;&#31867;&#65292;&#36825;&#20123;&#27169;&#22411;&#21482;&#33021;&#20174;&#25991;&#26412;&#25968;&#25454;&#20013;&#23398;&#20064;&#35821;&#35328;&#65292;&#27809;&#26377;&#19982;&#30495;&#23454;&#19990;&#30028;&#30340;&#30452;&#25509;&#20132;&#20114;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#23427;&#20204;&#33021;&#22815;&#29983;&#25104;&#20851;&#20110;&#21508;&#31181;&#35805;&#39064;&#20284;&#20046;&#26377;&#24847;&#20041;&#30340;&#25991;&#26412;&#12290;&#36825;&#19968;&#21360;&#35937;&#28145;&#21051;&#30340;&#25104;&#23601;&#37325;&#26032;&#24341;&#36215;&#20102;&#23545;&#32463;&#20856;&#8220;&#31526;&#21495;&#25509;&#22320;&#38382;&#39064;&#8221;&#30340;&#20851;&#27880;&#65292;&#36825;&#20010;&#38382;&#39064;&#36136;&#30097;&#20102;&#32463;&#20856;&#31526;&#21495;AI&#31995;&#32479;&#30340;&#20869;&#37096;&#34920;&#31034;&#21644;&#36755;&#20986;&#33021;&#21542;&#20855;&#26377;&#20869;&#22312;&#24847;&#20041;&#12290;&#19982;&#36825;&#20123;&#31995;&#32479;&#19981;&#21516;&#65292;&#29616;&#20195;LLMs&#26159;&#35745;&#31639;&#21521;&#37327;&#32780;&#19981;&#26159;&#31526;&#21495;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#31995;&#32479;&#20063;&#26377;&#31867;&#20284;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#21521;&#37327;&#25509;&#22320;&#38382;&#39064;&#12290;&#26412;&#25991;&#26377;&#20004;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21306;&#20998;&#20102;&#29983;&#29289;&#25110;&#20154;&#24037;&#31995;&#32479;&#20013;&#20869;&#37096;&#34920;&#31034;&#21487;&#20197;&#25509;&#22320;&#30340;&#21508;&#31181;&#26041;&#24335;&#65292;&#30830;&#23450;&#20102;&#20116;&#20010;&#19981;&#21516;&#30340;&#27010;&#24565;
&lt;/p&gt;
&lt;p&gt;
The remarkable performance of large language models (LLMs) on complex linguistic tasks has sparked a lively debate on the nature of their capabilities. Unlike humans, these models learn language exclusively from textual data, without direct interaction with the real world. Nevertheless, they can generate seemingly meaningful text about a wide range of topics. This impressive accomplishment has rekindled interest in the classical 'Symbol Grounding Problem,' which questioned whether the internal representations and outputs of classical symbolic AI systems could possess intrinsic meaning. Unlike these systems, modern LLMs are artificial neural networks that compute over vectors rather than symbols. However, an analogous problem arises for such systems, which we dub the Vector Grounding Problem. This paper has two primary objectives. First, we differentiate various ways in which internal representations can be grounded in biological or artificial systems, identifying five distinct notions 
&lt;/p&gt;</description></item></channel></rss>