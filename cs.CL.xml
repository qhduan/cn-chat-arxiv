<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;EBBS&#65292;&#37197;&#21512;&#26032;&#39062;&#30340;&#21452;&#23618;&#26463;&#25628;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#20248;&#20110;&#30452;&#25509;&#21644;&#36890;&#36807;&#31532;&#19977;&#35821;&#35328;&#36827;&#34892;&#30340;&#32763;&#35793;&#65292;&#24182;&#23454;&#29616;&#30693;&#35782;&#33976;&#39311;&#26469;&#25552;&#39640;&#25512;&#29702;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.00144</link><description>&lt;p&gt;
EBBS: &#19968;&#20010;&#20855;&#26377;&#21452;&#23618;&#26463;&#25628;&#32034;&#30340;&#38598;&#25104;&#26041;&#27861;&#29992;&#20110;&#38646;&#32763;&#35793;&#26426;&#22120;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00144
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;EBBS&#65292;&#37197;&#21512;&#26032;&#39062;&#30340;&#21452;&#23618;&#26463;&#25628;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#20248;&#20110;&#30452;&#25509;&#21644;&#36890;&#36807;&#31532;&#19977;&#35821;&#35328;&#36827;&#34892;&#30340;&#32763;&#35793;&#65292;&#24182;&#23454;&#29616;&#30693;&#35782;&#33976;&#39311;&#26469;&#25552;&#39640;&#25512;&#29702;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#25105;&#20204;&#29992;&#29305;&#23450;&#30340;&#32763;&#35793;&#26041;&#21521;&#35757;&#32451;&#22810;&#35821;&#35328;&#27169;&#22411;&#26102;&#65292;&#38646;&#32763;&#35793;&#30340;&#33021;&#21147;&#23601;&#20250;&#20986;&#29616;&#65307;&#27169;&#22411;&#21487;&#20197;&#30452;&#25509;&#22312;&#26410;&#35265;&#36807;&#30340;&#26041;&#21521;&#36827;&#34892;&#32763;&#35793;&#12290;&#21478;&#22806;&#65292;&#38646;&#32763;&#35793;&#20063;&#21487;&#20197;&#36890;&#36807;&#31532;&#19977;&#31181;&#35821;&#35328;&#65288;&#20363;&#22914;&#33521;&#35821;&#65289;&#26469;&#23454;&#29616;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#30452;&#25509;&#21644;&#36890;&#36807;&#31532;&#19977;&#31181;&#35821;&#35328;&#36827;&#34892;&#30340;&#32763;&#35793;&#37117;&#23384;&#22312;&#22122;&#38899;&#65292;&#24182;&#19988;&#34920;&#29616;&#19981;&#23613;&#22914;&#20154;&#24847;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;EBBS&#65292;&#19968;&#20010;&#20855;&#26377;&#26032;&#39062;&#30340;&#21452;&#23618;&#26463;&#25628;&#32034;&#31639;&#27861;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#20854;&#20013;&#27599;&#20010;&#38598;&#25104;&#32452;&#20214;&#22312;&#19979;&#23618;&#36880;&#27493;&#25506;&#32034;&#33258;&#24049;&#30340;&#39044;&#27979;&#65292;&#20294;&#23427;&#20204;&#36890;&#36807;&#19978;&#23618;&#30340;&#8220;&#36719;&#25237;&#31080;&#8221;&#26426;&#21046;&#36827;&#34892;&#21516;&#27493;&#12290;&#22312;&#20004;&#20010;&#27969;&#34892;&#30340;&#22810;&#35821;&#35328;&#32763;&#35793;&#25968;&#25454;&#38598;&#19978;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;EBBS&#22987;&#32456;&#20248;&#20110;&#30452;&#25509;&#21644;&#36890;&#36807;&#31532;&#19977;&#31181;&#35821;&#35328;&#36827;&#34892;&#30340;&#32763;&#35793;&#65292;&#20197;&#21450;&#29616;&#26377;&#30340;&#38598;&#25104;&#25216;&#26415;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#38598;&#25104;&#30340;&#30693;&#35782;&#20256;&#22238;&#21040;&#22810;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20197;&#25552;&#39640;&#25512;&#29702;&#25928;&#29575;&#65307;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;E
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00144v1 Announce Type: cross  Abstract: The ability of zero-shot translation emerges when we train a multilingual model with certain translation directions; the model can then directly translate in unseen directions. Alternatively, zero-shot translation can be accomplished by pivoting through a third language (e.g., English). In our work, we observe that both direct and pivot translations are noisy and achieve less satisfactory performance. We propose EBBS, an ensemble method with a novel bi-level beam search algorithm, where each ensemble component explores its own prediction step by step at the lower level but they are synchronized by a "soft voting" mechanism at the upper level. Results on two popular multilingual translation datasets show that EBBS consistently outperforms direct and pivot translations as well as existing ensemble techniques. Further, we can distill the ensemble's knowledge back to the multilingual model to improve inference efficiency; profoundly, our E
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#20195;&#29702;&#20989;&#25968;&#22312;&#36845;&#20195;&#23631;&#34109;&#23454;&#39564;&#20013;&#35780;&#20272;&#20102;&#36716;&#25442;&#22120;&#27169;&#22411;&#25152;&#32534;&#30721;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#20854;&#20182;&#35780;&#20272;&#26041;&#27861;&#30340;&#20559;&#35265;&#20272;&#35745;&#65292;&#21457;&#29616;&#36716;&#25442;&#22120;&#27169;&#22411;&#20013;&#23384;&#22312;&#30456;&#23545;&#36739;&#39640;&#30340;&#23447;&#25945;&#21644;&#27531;&#30142;&#20559;&#35265;&#65292;&#32780;&#24615;&#21035;&#20559;&#35265;&#21017;&#30456;&#23545;&#36739;&#20302;&#12290;</title><link>https://arxiv.org/abs/2402.13954</link><description>&lt;p&gt;
&#36890;&#36807;&#39044;&#27979;&#36136;&#37327;&#38388;&#25509;&#27979;&#37327;&#25513;&#30422;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#31038;&#20250;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#20195;&#29702;&#20989;&#25968;&#22312;&#36845;&#20195;&#23631;&#34109;&#23454;&#39564;&#20013;&#35780;&#20272;&#20102;&#36716;&#25442;&#22120;&#27169;&#22411;&#25152;&#32534;&#30721;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#20854;&#20182;&#35780;&#20272;&#26041;&#27861;&#30340;&#20559;&#35265;&#20272;&#35745;&#65292;&#21457;&#29616;&#36716;&#25442;&#22120;&#27169;&#22411;&#20013;&#23384;&#22312;&#30456;&#23545;&#36739;&#39640;&#30340;&#23447;&#25945;&#21644;&#27531;&#30142;&#20559;&#35265;&#65292;&#32780;&#24615;&#21035;&#20559;&#35265;&#21017;&#30456;&#23545;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20250;&#21644;&#25919;&#27835;&#31185;&#23398;&#23478;&#32463;&#24120;&#26088;&#22312;&#20174;&#25991;&#26412;&#25968;&#25454;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#20013;&#21457;&#29616;&#21644;&#34913;&#37327;&#19981;&#21516;&#30340;&#20559;&#35265;&#12290;&#21019;&#26032;&#30340;&#22522;&#20110;&#36716;&#25442;&#22120;&#30340;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20855;&#26377;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20196;&#29260;&#23884;&#20837;&#65292;&#24182;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#24050;&#34987;&#35777;&#26126;&#22312;&#19979;&#28216;&#24212;&#29992;&#20013;&#32534;&#30721;&#20102;&#19981;&#38656;&#35201;&#30340;&#20559;&#35265;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#20195;&#29702;&#20989;&#25968;&#22312;&#36845;&#20195;&#23631;&#34109;&#23454;&#39564;&#20013;&#35780;&#20272;&#30001;&#35757;&#32451;&#26377;&#36974;&#34109;&#35821;&#35328;&#24314;&#27169;&#30446;&#26631;&#30340;&#36716;&#25442;&#22120;&#25152;&#32534;&#30721;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#20197;&#27979;&#37327;&#36716;&#25442;&#22120;&#27169;&#22411;&#39044;&#27979;&#36136;&#37327;&#65292;&#24182;&#35780;&#20272;MLM&#23545;&#19981;&#21033;&#32676;&#20307;&#21644;&#26377;&#21033;&#32676;&#20307;&#30340;&#20559;&#22909;&#12290;&#25105;&#20204;&#27604;&#36739;&#20351;&#29992;&#20004;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#20559;&#35265;&#20272;&#35745;&#19982;&#20854;&#20182;&#35780;&#20272;&#26041;&#27861;&#20135;&#29983;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#32771;&#34385;&#30340;MLMs&#20013;&#23384;&#22312;&#30456;&#23545;&#36739;&#39640;&#30340;&#23447;&#25945;&#21644;&#27531;&#30142;&#20559;&#35265;&#65292;&#32780;&#30456;&#23545;&#20110;&#21478;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#19968;&#20010;&#25968;&#25454;&#38598;&#20013;&#23384;&#22312;&#36739;&#20302;&#30340;&#24615;&#21035;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13954v1 Announce Type: new  Abstract: Social and political scientists often aim to discover and measure distinct biases from text data representations (embeddings). Innovative transformer-based language models produce contextually-aware token embeddings and have achieved state-of-the-art performance for a variety of natural language tasks, but have been shown to encode unwanted biases for downstream applications. In this paper, we evaluate the social biases encoded by transformers trained with the masked language modeling objective using proposed proxy functions within an iterative masking experiment to measure the quality of transformer models' predictions, and assess the preference of MLMs towards disadvantaged and advantaged groups. We compare bias estimations with those produced by other evaluation methods using two benchmark datasets, finding relatively high religious and disability biases across considered MLMs and low gender bias in one dataset relative to the other. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23450;&#37327;&#30693;&#35782;&#26816;&#32034;&#30340;&#21487;&#34892;&#24615;&#65292;&#20197;&#36741;&#21161;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#24037;&#31243;&#26694;&#26550;&#65292;&#23558;LLMs&#20316;&#20026;&#31185;&#23398;&#25991;&#29486;&#28508;&#22312;&#31354;&#38388;&#30340;&#25509;&#21475;&#12290;&#35752;&#35770;&#20102;&#20351;&#29992;LLMs&#20316;&#20026;&#8220;&#19987;&#23478;&#8221;&#30340;&#24433;&#21709;&#21644;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.07770</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#23450;&#37327;&#30693;&#35782;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Quantitative knowledge retrieval from large language models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23450;&#37327;&#30693;&#35782;&#26816;&#32034;&#30340;&#21487;&#34892;&#24615;&#65292;&#20197;&#36741;&#21161;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#24037;&#31243;&#26694;&#26550;&#65292;&#23558;LLMs&#20316;&#20026;&#31185;&#23398;&#25991;&#29486;&#28508;&#22312;&#31354;&#38388;&#30340;&#25509;&#21475;&#12290;&#35752;&#35770;&#20102;&#20351;&#29992;LLMs&#20316;&#20026;&#8220;&#19987;&#23478;&#8221;&#30340;&#24433;&#21709;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22240;&#20854;&#29983;&#25104;&#20855;&#26377;&#35828;&#26381;&#21147;&#30340;&#33258;&#28982;&#35821;&#35328;&#24207;&#21015;&#30340;&#33021;&#21147;&#32780;&#34987;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#20854;&#20316;&#20026;&#23450;&#37327;&#20449;&#24687;&#26816;&#32034;&#30340;&#23454;&#29992;&#24615;&#23578;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;LLMs&#20316;&#20026;&#23450;&#37327;&#30693;&#35782;&#26816;&#32034;&#26426;&#21046;&#30340;&#21487;&#34892;&#24615;&#65292;&#20197;&#24110;&#21161;&#25968;&#25454;&#20998;&#26512;&#20219;&#21153;&#65292;&#22914;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#20808;&#39564;&#20998;&#24067;&#24341;&#23548;&#21644;&#32570;&#22833;&#25968;&#25454;&#30340;&#22635;&#34917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#24037;&#31243;&#26694;&#26550;&#65292;&#23558;LLMs&#35270;&#20026;&#31185;&#23398;&#25991;&#29486;&#28508;&#22312;&#31354;&#38388;&#30340;&#25509;&#21475;&#65292;&#22312;&#19981;&#21516;&#19978;&#19979;&#25991;&#21644;&#39046;&#22495;&#20013;&#27604;&#36739;&#21709;&#24212;&#19982;&#26356;&#25104;&#29087;&#30340;&#26041;&#27861;&#12290;&#35752;&#35770;&#20102;&#20351;&#29992;LLMs&#20316;&#20026;&#8220;&#19987;&#23478;&#8221;&#30340;&#24433;&#21709;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have been extensively studied for their abilities to generate convincing natural language sequences, however their utility for quantitative information retrieval is less well understood. In this paper we explore the feasibility of LLMs as a mechanism for quantitative knowledge retrieval to aid data analysis tasks such as elicitation of prior distributions for Bayesian models and imputation of missing data. We present a prompt engineering framework, treating an LLM as an interface to a latent space of scientific literature, comparing responses in different contexts and domains against more established approaches. Implications and challenges of using LLMs as 'experts' are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#27169;&#25311;&#35780;&#20272;&#24320;&#25918;&#24335;&#20449;&#24687;&#25552;&#21462;&#27169;&#22411;&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#36890;&#36807;&#21028;&#26029;&#27169;&#22411;&#22312;&#25972;&#20010;&#22242;&#20307;&#19978;&#30340;&#34920;&#29616;&#26159;&#21542;&#22987;&#32456;&#20934;&#30830;&#26469;&#35780;&#20272;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.13981</link><description>&lt;p&gt;
&#20445;&#25345;&#30693;&#35782;&#19981;&#21464;&#24615;&#65306;&#37325;&#26032;&#24605;&#32771;&#24320;&#25918;&#20449;&#24687;&#25277;&#21462;&#30340;&#40065;&#26834;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction. (arXiv:2305.13981v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#27169;&#25311;&#35780;&#20272;&#24320;&#25918;&#24335;&#20449;&#24687;&#25552;&#21462;&#27169;&#22411;&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#36890;&#36807;&#21028;&#26029;&#27169;&#22411;&#22312;&#25972;&#20010;&#22242;&#20307;&#19978;&#30340;&#34920;&#29616;&#26159;&#21542;&#22987;&#32456;&#20934;&#30830;&#26469;&#35780;&#20272;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40065;&#26834;&#24615;&#26159;&#30830;&#20445;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#33021;&#22815;&#25104;&#21151;&#24212;&#29992;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20449;&#24687;&#25277;&#21462;&#20219;&#21153;&#32780;&#35328;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#35780;&#20272;&#22522;&#20934;&#37117;&#19987;&#27880;&#20110;&#39564;&#35777;&#37197;&#23545;&#21305;&#37197;&#30340;&#27491;&#30830;&#24615;&#65292;&#24573;&#30053;&#20102;&#20851;&#38190;&#30340;&#40065;&#26834;&#24615;&#27979;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#65292;&#27169;&#25311;&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#35780;&#20272;&#24320;&#25918;&#24335;&#20449;&#24687;&#25552;&#21462;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21516;&#19968;&#30693;&#35782;&#21547;&#20041;&#30340;&#21477;&#27861;&#21644;&#34920;&#36798;&#20998;&#24067;&#20250;&#21508;&#19981;&#30456;&#21516;&#12290;&#25105;&#20204;&#35774;&#35745;&#21644;&#27880;&#37322;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#27979;&#35797;&#24179;&#21488;&#65292;&#20854;&#20013;&#27599;&#20010;&#31034;&#20363;&#37117;&#26159;&#19968;&#20010;&#30693;&#35782;&#19981;&#21464;&#30340;&#22242;&#20307;&#65292;&#30001;&#20855;&#26377;&#30456;&#21516;&#21547;&#20041;&#20294;&#32467;&#26500;&#19981;&#21516;&#30340;&#21477;&#23376;&#32452;&#25104;&#12290;&#36890;&#36807;&#36827;&#19968;&#27493;&#38416;&#36848;&#40065;&#26834;&#24615;&#25351;&#26631;&#65292;&#24403;&#27169;&#22411;&#22312;&#25972;&#20010;&#22242;&#20307;&#19978;&#30340;&#34920;&#29616;&#22987;&#32456;&#20934;&#30830;&#26102;&#65292;&#34987;&#21028;&#23450;&#20026;&#40065;&#26834;&#24615;&#24378;&#12290;&#25105;&#20204;&#23545;&#36807;&#21435;&#21313;&#24180;&#20013;&#21457;&#34920;&#30340;&#20960;&#31181;&#20856;&#22411;&#27169;&#22411;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
The robustness to distribution changes ensures that NLP models can be successfully applied in the realistic world, especially for information extraction tasks. However, most prior evaluation benchmarks have been devoted to validating pairwise matching correctness, ignoring the crucial measurement of robustness. In this paper, we present the first benchmark that simulates the evaluation of open information extraction models in the real world, where the syntactic and expressive distributions under the same knowledge meaning may drift variously. We design and annotate a large-scale testbed in which each example is a knowledge-invariant clique that consists of sentences with structured knowledge of the same meaning but with different syntactic and expressive forms. By further elaborating the robustness metric, a model is judged to be robust if its performance is consistently accurate on the overall cliques. We perform experiments on typical models published in the last decade as well as a 
&lt;/p&gt;</description></item></channel></rss>