<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#19988;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#21363;Unsolvable Problem Detection&#65288;UPD&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#22312;&#35270;&#35273;&#38382;&#31572;&#20219;&#21153;&#20013;&#33021;&#21542;&#22312;&#38754;&#23545;&#19981;&#21487;&#35299;&#38382;&#39064;&#26102;&#20445;&#25345;&#31572;&#26696;&#30340;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#24191;&#27867;&#23454;&#39564;&#21457;&#29616;&#22823;&#22810;&#25968;&#27169;&#22411;&#23384;&#22312;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;</title><link>https://arxiv.org/abs/2403.20331</link><description>&lt;p&gt;
&#19981;&#21487;&#35299;&#38382;&#39064;&#26816;&#27979;&#65306;&#35780;&#20272;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;
&lt;/p&gt;
&lt;p&gt;
Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#19988;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#21363;Unsolvable Problem Detection&#65288;UPD&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#22312;&#35270;&#35273;&#38382;&#31572;&#20219;&#21153;&#20013;&#33021;&#21542;&#22312;&#38754;&#23545;&#19981;&#21487;&#35299;&#38382;&#39064;&#26102;&#20445;&#25345;&#31572;&#26696;&#30340;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#24191;&#27867;&#23454;&#39564;&#21457;&#29616;&#22823;&#22810;&#25968;&#27169;&#22411;&#23384;&#22312;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#39062;&#32780;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#21363;Unsolvable Problem Detection&#65288;UPD&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#22312;&#35270;&#35273;&#38382;&#31572;&#65288;VQA&#65289;&#20219;&#21153;&#20013;&#38754;&#23545;&#19981;&#21487;&#35299;&#38382;&#39064;&#26102;&#20445;&#25345;&#31572;&#26696;&#30340;&#33021;&#21147;&#12290;UPD&#21253;&#25324;&#19977;&#20010;&#19981;&#21516;&#30340;&#35774;&#32622;&#65306;&#32570;&#22833;&#31572;&#26696;&#26816;&#27979;&#65288;AAD&#65289;&#12289;&#19981;&#20860;&#23481;&#31572;&#26696;&#38598;&#26816;&#27979;&#65288;IASD&#65289;&#21644;&#19981;&#20860;&#23481;&#35270;&#35273;&#38382;&#39064;&#26816;&#27979;&#65288;IVQD&#65289;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#28145;&#20837;&#30740;&#31350;UPD&#38382;&#39064;&#34920;&#26126;&#65292;&#22823;&#22810;&#25968;VLMs&#65292;&#21253;&#25324;GPT-4V&#21644;LLaVA-Next-34B&#65292;&#22312;&#21508;&#31181;&#31243;&#24230;&#19978;&#37117;&#24456;&#38590;&#24212;&#23545;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#31361;&#26174;&#20102;&#25913;&#36827;&#30340;&#37325;&#35201;&#31354;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;UPD&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#26080;&#38656;&#35757;&#32451;&#21644;&#22522;&#20110;&#35757;&#32451;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#25552;&#20379;&#20102;&#23545;&#20854;&#26377;&#25928;&#24615;&#21644;&#23616;&#38480;&#24615;&#30340;&#26032;&#35265;&#35299;&#12290;&#25105;&#20204;&#24076;&#26395;&#25105;&#20204;&#30340;&#35265;&#35299;&#65292;&#20197;&#21450;&#22312;&#25552;&#35758;&#30340;UPD&#35774;&#32622;&#20869;&#30340;&#26410;&#26469;&#21162;&#21147;&#65292;&#23558;&#22686;&#24378;&#23545;VLMs&#30340;&#26356;&#24191;&#27867;&#29702;&#35299;&#21644;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20331v1 Announce Type: cross  Abstract: This paper introduces a novel and significant challenge for Vision Language Models (VLMs), termed Unsolvable Problem Detection (UPD). UPD examines the VLM's ability to withhold answers when faced with unsolvable problems in the context of Visual Question Answering (VQA) tasks. UPD encompasses three distinct settings: Absent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and Incompatible Visual Question Detection (IVQD). To deeply investigate the UPD problem, extensive experiments indicate that most VLMs, including GPT-4V and LLaVA-Next-34B, struggle with our benchmarks to varying extents, highlighting significant room for the improvements. To address UPD, we explore both training-free and training-based solutions, offering new insights into their effectiveness and limitations. We hope our insights, together with future efforts within the proposed UPD settings, will enhance the broader understanding and development of
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#24341;&#23548;&#27169;&#22411;&#21305;&#37197;&#65288;IMM&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#23436;&#25972;&#27169;&#22411;&#30340;&#24615;&#33021;&#19982;&#21463;&#38480;&#27169;&#22411;&#23545;&#40784;&#65292;&#23558;&#21463;&#38480;&#27169;&#22411;&#30340;&#30693;&#35782;&#20256;&#36882;&#32473;&#23436;&#25972;&#27169;&#22411;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12513</link><description>&lt;p&gt;
&#24341;&#23548;&#27169;&#22411;&#21305;&#37197;&#65306;&#21463;&#38480;&#27169;&#22411;&#22914;&#20309;&#24110;&#21161;&#26356;&#22823;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Induced Model Matching: How Restricted Models Can Help Larger Ones
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12513
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#24341;&#23548;&#27169;&#22411;&#21305;&#37197;&#65288;IMM&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#23436;&#25972;&#27169;&#22411;&#30340;&#24615;&#33021;&#19982;&#21463;&#38480;&#27169;&#22411;&#23545;&#40784;&#65292;&#23558;&#21463;&#38480;&#27169;&#22411;&#30340;&#30693;&#35782;&#20256;&#36882;&#32473;&#23436;&#25972;&#27169;&#22411;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#35757;&#32451;&#26356;&#22823;&#12289;&#20855;&#26377;&#23436;&#25972;&#29305;&#24449;&#30340;&#27169;&#22411;&#26102;&#65292;&#26159;&#21542;&#21487;&#20197;&#21033;&#29992;&#21463;&#38480;&#29305;&#24449;&#30340;&#38750;&#24120;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#36825;&#20010;&#21463;&#38480;&#27169;&#22411;&#21487;&#20197;&#34987;&#35270;&#20026;&#8220;&#36741;&#21161;&#20449;&#24687;&#8221;&#65292;&#21487;&#20197;&#36890;&#36807;&#26469;&#33258;&#36741;&#21161;&#28304;&#25968;&#25454;&#38598;&#30340;&#35814;&#23613;&#25968;&#25454;&#25110;&#22312;&#30456;&#21516;&#25968;&#25454;&#38598;&#19978;&#36890;&#36807;&#26045;&#21152;&#38480;&#21046;&#26469;&#33719;&#24471;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#23558;&#21463;&#38480;&#27169;&#22411;&#30340;&#30693;&#35782;&#20256;&#36882;&#32473;&#23436;&#25972;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#23436;&#25972;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#21463;&#38480;&#24615;&#33021;&#19982;&#21463;&#38480;&#27169;&#22411;&#30340;&#24615;&#33021;&#23545;&#40784;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#31216;&#20026;&#24341;&#23548;&#27169;&#22411;&#21305;&#37197;&#65288;IMM&#65289;&#65292;&#39318;&#20808;&#36890;&#36807;&#20197;&#36923;&#36753;&#22238;&#24402;&#20026;&#29609;&#20855;&#31034;&#20363;&#26469;&#35828;&#26126;&#20854;&#26222;&#36866;&#24615;&#12290;&#28982;&#21518;&#25105;&#20204;&#25506;&#35752;&#20102;IMM&#22312;&#35821;&#35328;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#65292;&#36825;&#20063;&#26159;&#26368;&#21021;&#30340;&#28789;&#24863;&#26469;&#28304;&#65292;IMM&#22312;&#36825;&#37324;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#22522;&#30784;&#65292;&#19982;&#22312;&#25216;&#26415;&#20013;&#38544;&#24335;&#20351;&#29992;&#21463;&#38480;&#27169;&#22411;&#30340;&#26041;&#27861;&#30456;&#23545;&#24212;&#65292;&#20363;&#22914;&#28155;&#21152;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12513v1 Announce Type: new  Abstract: We consider scenarios where a very accurate predictive model using restricted features is available at the time of training of a larger, full-featured, model. This restricted model may be thought of as "side-information", derived either from an auxiliary exhaustive dataset or on the same dataset, by forcing the restriction. How can the restricted model be useful to the full model? We propose an approach for transferring the knowledge of the restricted model to the full model, by aligning the full model's context-restricted performance with that of the restricted model's. We call this methodology Induced Model Matching (IMM) and first illustrate its general applicability by using logistic regression as a toy example. We then explore IMM's use in language modeling, the application that initially inspired it, and where it offers an explicit foundation in contrast to the implicit use of restricted models in techniques such as noising. We dem
&lt;/p&gt;</description></item><item><title>CroissantLLM&#26159;&#19968;&#20010;1.3B&#30340;&#21452;&#35821;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;1:1&#30340;&#33521;&#35821;-&#27861;&#35821;&#39044;&#35757;&#32451;&#25968;&#25454;&#27604;&#20363;&#12289;&#33258;&#23450;&#20041;&#30340;&#20998;&#35789;&#22120;&#21644;&#21452;&#35821;&#35843;&#20248;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#39640;&#24615;&#33021;&#21644;&#24320;&#28304;&#12290;&#27169;&#22411;&#36824;&#21457;&#24067;&#20102;&#35757;&#32451;&#25968;&#25454;&#38598;&#21644;&#22810;&#20010;&#26816;&#26597;&#28857;&#65292;&#20197;&#21450;&#19968;&#20010;&#27861;&#35821;&#22522;&#20934;&#27979;&#35797; FrenchBench&#12290;</title><link>https://arxiv.org/abs/2402.00786</link><description>&lt;p&gt;
CroissantLLM: &#19968;&#20010;&#30495;&#27491;&#30340;&#21452;&#35821;&#27861;&#35821;-&#33521;&#35821;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
CroissantLLM: A Truly Bilingual French-English Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00786
&lt;/p&gt;
&lt;p&gt;
CroissantLLM&#26159;&#19968;&#20010;1.3B&#30340;&#21452;&#35821;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;1:1&#30340;&#33521;&#35821;-&#27861;&#35821;&#39044;&#35757;&#32451;&#25968;&#25454;&#27604;&#20363;&#12289;&#33258;&#23450;&#20041;&#30340;&#20998;&#35789;&#22120;&#21644;&#21452;&#35821;&#35843;&#20248;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#39640;&#24615;&#33021;&#21644;&#24320;&#28304;&#12290;&#27169;&#22411;&#36824;&#21457;&#24067;&#20102;&#35757;&#32451;&#25968;&#25454;&#38598;&#21644;&#22810;&#20010;&#26816;&#26597;&#28857;&#65292;&#20197;&#21450;&#19968;&#20010;&#27861;&#35821;&#22522;&#20934;&#27979;&#35797; FrenchBench&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;CroissantLLM&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;3T&#20010;&#33521;&#35821;&#21644;&#27861;&#35821;&#26631;&#35760;&#19978;&#39044;&#35757;&#32451;&#30340;13&#20159;&#35821;&#35328;&#27169;&#22411;&#65292;&#20026;&#30740;&#31350;&#21644;&#24037;&#19994;&#31038;&#21306;&#24102;&#26469;&#20102;&#19968;&#31181;&#39640;&#24615;&#33021;&#30340;&#12289;&#23436;&#20840;&#24320;&#28304;&#30340;&#21452;&#35821;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#28040;&#36153;&#32423;&#26412;&#22320;&#30828;&#20214;&#19978;&#24555;&#36895;&#36816;&#34892;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#27425;&#23581;&#35797;&#20351;&#29992;1:1&#30340;&#33521;&#35821;-&#27861;&#35821;&#39044;&#35757;&#32451;&#25968;&#25454;&#27604;&#20363;&#12289;&#33258;&#23450;&#20041;&#30340;&#20998;&#35789;&#22120;&#21644;&#21452;&#35821;&#35843;&#20248;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;&#19968;&#31181;&#20869;&#22312;&#21452;&#35821;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19968;&#20010;&#27861;&#35821;&#20998;&#21106;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#25163;&#24037;&#31574;&#21010;&#12289;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#28304;&#12290;&#20026;&#20102;&#35780;&#20272;&#22312;&#33521;&#35821;&#20197;&#22806;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797; FrenchBench&#65292;&#21253;&#25324;&#19968;&#31995;&#21015;&#20998;&#31867;&#21644;&#29983;&#25104;&#20219;&#21153;&#65292;&#28085;&#30422;&#20102;&#27169;&#22411;&#22312;&#27861;&#35821;&#35821;&#35328;&#20013;&#24615;&#33021;&#30340;&#21508;&#20010;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20445;&#25345;&#36879;&#26126;&#24230;&#24182;&#20419;&#36827;&#36827;&#19968;&#27493;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;&#20195;&#30721;&#24211;&#21644;&#21508;&#31181;&#27169;&#22411;&#35268;&#27169;&#12289;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#20960;&#21313;&#20010;&#26816;&#26597;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-to-French pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, 
&lt;/p&gt;</description></item></channel></rss>