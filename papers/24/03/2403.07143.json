{
    "title": "New Perspectives in Online Contract Design: Heterogeneous, Homogeneous, Non-myopic Agents and Team Production",
    "abstract": "arXiv:2403.07143v1 Announce Type: cross  Abstract: This work studies the repeated principal-agent problem from an online learning perspective. The principal's goal is to learn the optimal contract that maximizes her utility through repeated interactions, without prior knowledge of the agent's type (i.e., the agent's cost and production functions).   I study three different settings when the principal contracts with a $\\textit{single}$ agent each round: 1. The agents are heterogeneous; 2. the agents are homogenous; 3. the principal interacts with the same agent and the agent is non-myopic. I present different approaches and techniques for designing learning algorithms in each setting. For heterogeneous agent types, I identify a condition that allows the problem to be reduced to Lipschitz bandits directly. For identical agents, I give a polynomial sample complexity scheme to learn the optimal contract based on inverse game theory. For strategic non-myopic agents, I design a low strategic",
    "link": "https://arxiv.org/abs/2403.07143",
    "context": "Title: New Perspectives in Online Contract Design: Heterogeneous, Homogeneous, Non-myopic Agents and Team Production\nAbstract: arXiv:2403.07143v1 Announce Type: cross  Abstract: This work studies the repeated principal-agent problem from an online learning perspective. The principal's goal is to learn the optimal contract that maximizes her utility through repeated interactions, without prior knowledge of the agent's type (i.e., the agent's cost and production functions).   I study three different settings when the principal contracts with a $\\textit{single}$ agent each round: 1. The agents are heterogeneous; 2. the agents are homogenous; 3. the principal interacts with the same agent and the agent is non-myopic. I present different approaches and techniques for designing learning algorithms in each setting. For heterogeneous agent types, I identify a condition that allows the problem to be reduced to Lipschitz bandits directly. For identical agents, I give a polynomial sample complexity scheme to learn the optimal contract based on inverse game theory. For strategic non-myopic agents, I design a low strategic",
    "path": "papers/24/03/2403.07143.json",
    "total_tokens": 932,
    "translated_title": "在线合同设计的新视角：异质、同质、非单纯视角代理和团队生产",
    "translated_abstract": "这项工作从在线学习的视角研究了重复的委托-代理问题。 委托方的目标是通过重复互动学习最大化其效用的最佳合同，而没有关于代理方类型（即代理方的成本和生产函数）的先验知识。 我研究了三种不同的情境，委托方在每一轮与$\\textit{单个}$代理方签订合同时：1. 代理方是异质的；2. 代理方是同质的；3. 委托方与相同的代理方互动且该代理方是非单纯的。 我提出不同的方法和技术来设计每种情况下的学习算法。 对于异质代理类型，我确定了一个条件，允许将问题直接简化为Lipschitz老虎机问题。 对于相同代理方，我提出了一个基于逆博弈论的多项式样本复杂度方案来学习最佳合同。 对于战略性非单纯代理，我设计了一个低战略性",
    "tldr": "本研究从在线学习的视角研究了重复的委托-代理问题，针对不同情形提出了设计学习算法的不同方法和技术，包括异质代理、同质代理和非单纯视角代理。",
    "en_tdlr": "This work explores the repeated principal-agent problem from an online learning perspective, proposing various methods and techniques for designing learning algorithms in different scenarios, including heterogeneous agents, homogeneous agents, and non-myopic agents."
}