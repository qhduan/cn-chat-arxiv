{
    "title": "SoK: Challenges and Opportunities in Federated Unlearning",
    "abstract": "arXiv:2403.02437v1 Announce Type: cross  Abstract: Federated learning (FL), introduced in 2017, facilitates collaborative learning between non-trusting parties with no need for the parties to explicitly share their data among themselves. This allows training models on user data while respecting privacy regulations such as GDPR and CPRA. However, emerging privacy requirements may mandate model owners to be able to \\emph{forget} some learned data, e.g., when requested by data owners or law enforcement. This has given birth to an active field of research called \\emph{machine unlearning}. In the context of FL, many techniques developed for unlearning in centralized settings are not trivially applicable! This is due to the unique differences between centralized and distributed learning, in particular, interactivity, stochasticity, heterogeneity, and limited accessibility in FL. In response, a recent line of work has focused on developing unlearning mechanisms tailored to FL.   This SoK pape",
    "link": "https://arxiv.org/abs/2403.02437",
    "context": "Title: SoK: Challenges and Opportunities in Federated Unlearning\nAbstract: arXiv:2403.02437v1 Announce Type: cross  Abstract: Federated learning (FL), introduced in 2017, facilitates collaborative learning between non-trusting parties with no need for the parties to explicitly share their data among themselves. This allows training models on user data while respecting privacy regulations such as GDPR and CPRA. However, emerging privacy requirements may mandate model owners to be able to \\emph{forget} some learned data, e.g., when requested by data owners or law enforcement. This has given birth to an active field of research called \\emph{machine unlearning}. In the context of FL, many techniques developed for unlearning in centralized settings are not trivially applicable! This is due to the unique differences between centralized and distributed learning, in particular, interactivity, stochasticity, heterogeneity, and limited accessibility in FL. In response, a recent line of work has focused on developing unlearning mechanisms tailored to FL.   This SoK pape",
    "path": "papers/24/03/2403.02437.json",
    "total_tokens": 832,
    "translated_title": "SoK: 联邦反学习中的挑战与机遇",
    "translated_abstract": "引入于2017年的联邦学习（FL）促进了不信任方之间的合作学习，无需各方明确共享其数据。这允许在尊重GDPR和CPRA等隐私规定的同时，在用户数据上训练模型。然而，新兴的隐私要求可能要求模型所有者能够“遗忘”一些已学习的数据，例如当数据所有者或执法机构要求时。这催生了一个名为“机器反学习”的活跃研究领域。在FL的背景下，许多为集中式环境开发的反学习技术并不容易应用！这是由于FL中集中式和分布式学习之间的独特差异，特别是互动性、随机性、异构性和有限可访问性。为应对这一挑战，最近的一系列研究工作聚焦于开发适用于FL的反学习机制。",
    "tldr": "联邦学习引入了新的隐私要求，促使研究开始关注适用于联邦学习环境的反学习机制。",
    "en_tdlr": "Federated learning introduces new privacy requirements, prompting research to focus on unlearning mechanisms tailored for federated learning environments."
}