{
    "title": "Genetic Programming for Explainable Manifold Learning",
    "abstract": "arXiv:2403.14139v1 Announce Type: cross  Abstract: Manifold learning techniques play a pivotal role in machine learning by revealing lower-dimensional embeddings within high-dimensional data, thus enhancing both the efficiency and interpretability of data analysis by transforming the data into a lower-dimensional representation. However, a notable challenge with current manifold learning methods is their lack of explicit functional mappings, crucial for explainability in many real-world applications. Genetic programming, known for its interpretable functional tree-based models, has emerged as a promising approach to address this challenge. Previous research leveraged multi-objective GP to balance manifold quality against embedding dimensionality, producing functional mappings across a range of embedding sizes. Yet, these mapping trees often became complex, hindering explainability. In response, in this paper, we introduce Genetic Programming for Explainable Manifold Learning (GP-EMaL),",
    "link": "https://arxiv.org/abs/2403.14139",
    "context": "Title: Genetic Programming for Explainable Manifold Learning\nAbstract: arXiv:2403.14139v1 Announce Type: cross  Abstract: Manifold learning techniques play a pivotal role in machine learning by revealing lower-dimensional embeddings within high-dimensional data, thus enhancing both the efficiency and interpretability of data analysis by transforming the data into a lower-dimensional representation. However, a notable challenge with current manifold learning methods is their lack of explicit functional mappings, crucial for explainability in many real-world applications. Genetic programming, known for its interpretable functional tree-based models, has emerged as a promising approach to address this challenge. Previous research leveraged multi-objective GP to balance manifold quality against embedding dimensionality, producing functional mappings across a range of embedding sizes. Yet, these mapping trees often became complex, hindering explainability. In response, in this paper, we introduce Genetic Programming for Explainable Manifold Learning (GP-EMaL),",
    "path": "papers/24/03/2403.14139.json",
    "total_tokens": 818,
    "translated_title": "用于可解释流形学习的遗传规划",
    "translated_abstract": "流形学习技术在机器学习中发挥着关键作用，通过揭示高维数据中的低维嵌入，从而将数据转换为更低维的表示形式，提高了数据分析的效率和可解释性。然而，当前流形学习方法的一个显著挑战是它们缺乏明确的功能映射，在许多现实世界应用中解释性至关重要。遗传规划以其可解释的基于功能树的模型而闻名，已成为解决这一挑战的一种有希望的方法。先前的研究利用多目标遗传规划来平衡流形质量与嵌入维度，产生了一系列嵌入大小下的功能映射。然而，这些映射树经常变得复杂，阻碍了解释性。作为回应，在本文中，我们提出了用于可解释流形学习的遗传规划（GP-EMaL）。",
    "tldr": "遗传规划方法提出了用于可解释流形学习的新方法，帮助解决当前流形学习中功能映射不明确的挑战。"
}