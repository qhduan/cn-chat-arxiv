{
    "title": "ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs",
    "abstract": "arXiv:2403.09724v1 Announce Type: new  Abstract: In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they often lack appropriate explainability or granularity to be useful in various contexts. A text validation method that is easy to use, accessible, and can perform fine-grained evidence attribution has become crucial. More importantly, building user trust in such a method requires presenting the rationale behind each prediction, as research shows this significantly influences people's belief in automated systems. It is also paramount to localize and bring users' attention to the specific problematic content, instead of providing simple blanket labels. In this paper, we present $\\textit{ClaimVer, a human-centric framework}$ tailored to meet users' info",
    "link": "https://arxiv.org/abs/2403.09724",
    "context": "Title: ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs\nAbstract: arXiv:2403.09724v1 Announce Type: new  Abstract: In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they often lack appropriate explainability or granularity to be useful in various contexts. A text validation method that is easy to use, accessible, and can perform fine-grained evidence attribution has become crucial. More importantly, building user trust in such a method requires presenting the rationale behind each prediction, as research shows this significantly influences people's belief in automated systems. It is also paramount to localize and bring users' attention to the specific problematic content, instead of providing simple blanket labels. In this paper, we present $\\textit{ClaimVer, a human-centric framework}$ tailored to meet users' info",
    "path": "papers/24/03/2403.09724.json",
    "total_tokens": 858,
    "translated_title": "ClaimVer：通过知识图谱实现可解释的声明级验证和证据归因",
    "translated_abstract": "在广泛传播的信息误导和社交媒体以及人工智能生成的文本的激增中，验证和信任所遇到的信息变得日益困难。许多事实核查方法和工具已被开发，但它们往往缺乏适当的可解释性或细粒度，无法在各种情境中发挥作用。一种易于使用、可访问且能够执行细粒度证据归因的文本验证方法变得至关重要。更重要的是，建立用户对这种方法的信任需要呈现每个预测背后的理由，因为研究表明这显著影响人们对自动化系统的信任。将用户关注重点放在具体的问题内容上，而不是提供简单的笼统标签也非常重要。在本文中，我们提出了$\\textit{ClaimVer，一个以人为中心的框架}$，旨在满足用户的信息需求。",
    "tldr": "ClaimVer是一个人为中心的框架，通过知识图谱实现可解释的声明级验证和证据归因，致力于提高用户对文本验证方法的信任并强调细粒度证据的重要性。",
    "en_tdlr": "ClaimVer is a human-centric framework that achieves explainable claim-level verification and evidence attribution through knowledge graphs, aiming to enhance user trust in text validation methods and highlight the importance of fine-grained evidence attribution."
}