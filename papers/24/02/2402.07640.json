{
    "title": "Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image Data",
    "abstract": "The ability to generate sentiment-controlled feedback in response to multimodal inputs, comprising both text and images, addresses a critical gap in human-computer interaction by enabling systems to provide empathetic, accurate, and engaging responses. This capability has profound applications in healthcare, marketing, and education. To this end, we construct a large-scale Controllable Multimodal Feedback Synthesis (CMFeed) dataset and propose a controllable feedback synthesis system. The proposed system includes an encoder, decoder, and controllability block for textual and visual inputs. It extracts textual and visual features using a transformer and Faster R-CNN networks and combines them to generate feedback. The CMFeed dataset encompasses images, text, reactions to the post, human comments with relevance scores, and reactions to the comments. The reactions to the post and comments are utilized to train the proposed model to produce feedback with a particular (positive or negative)",
    "link": "https://arxiv.org/abs/2402.07640",
    "context": "Title: Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image Data\nAbstract: The ability to generate sentiment-controlled feedback in response to multimodal inputs, comprising both text and images, addresses a critical gap in human-computer interaction by enabling systems to provide empathetic, accurate, and engaging responses. This capability has profound applications in healthcare, marketing, and education. To this end, we construct a large-scale Controllable Multimodal Feedback Synthesis (CMFeed) dataset and propose a controllable feedback synthesis system. The proposed system includes an encoder, decoder, and controllability block for textual and visual inputs. It extracts textual and visual features using a transformer and Faster R-CNN networks and combines them to generate feedback. The CMFeed dataset encompasses images, text, reactions to the post, human comments with relevance scores, and reactions to the comments. The reactions to the post and comments are utilized to train the proposed model to produce feedback with a particular (positive or negative)",
    "path": "papers/24/02/2402.07640.json",
    "total_tokens": 826,
    "translated_title": "合成对多模态文本和图片数据的情感控制反馈",
    "translated_abstract": "生成对多模态输入（包括文本和图片）的情感控制反馈能够弥补人机交互领域的一个关键差距，使系统能够提供具有同理心、准确性和引人入胜的回应。这种能力在医疗、营销和教育等领域有着深远的应用。为此，我们构建了一个大规模的可控多模态反馈合成（CMFeed）数据集，并提出了一个可控的反馈合成系统。所提出的系统包括一个编码器、解码器和控制性模块，用于处理文本和视觉输入。它使用Transformer和Faster R-CNN网络提取文本和视觉特征，并将它们结合起来生成反馈。CMFeed数据集包含图片、文本、对帖子的反应、带有相关性评分的人类评论以及对评论的反应。对帖子和评论的反应被用来训练提出的模型以产生具有特定（积极或消极）情感的反馈。",
    "tldr": "该论文提出了一个可控的多模态反馈合成系统，能够根据文本和图像输入生成具有特定情感（积极或消极）的反馈，有着广泛的应用价值。"
}