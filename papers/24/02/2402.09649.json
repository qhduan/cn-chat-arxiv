{
    "title": "ProtChatGPT: Towards Understanding Proteins with Large Language Models",
    "abstract": "arXiv:2402.09649v1 Announce Type: cross  Abstract: Protein research is crucial in various fundamental disciplines, but understanding their intricate structure-function relationships remains challenging. Recent Large Language Models (LLMs) have made significant strides in comprehending task-specific knowledge, suggesting the potential for ChatGPT-like systems specialized in protein to facilitate basic research. In this work, we introduce ProtChatGPT, which aims at learning and understanding protein structures via natural languages. ProtChatGPT enables users to upload proteins, ask questions, and engage in interactive conversations to produce comprehensive answers. The system comprises protein encoders, a Protein-Language Pertaining Transformer (PLP-former), a projection adapter, and an LLM. The protein first undergoes protein encoders and PLP-former to produce protein embeddings, which are then projected by the adapter to conform with the LLM. The LLM finally combines user questions wit",
    "link": "https://arxiv.org/abs/2402.09649",
    "context": "Title: ProtChatGPT: Towards Understanding Proteins with Large Language Models\nAbstract: arXiv:2402.09649v1 Announce Type: cross  Abstract: Protein research is crucial in various fundamental disciplines, but understanding their intricate structure-function relationships remains challenging. Recent Large Language Models (LLMs) have made significant strides in comprehending task-specific knowledge, suggesting the potential for ChatGPT-like systems specialized in protein to facilitate basic research. In this work, we introduce ProtChatGPT, which aims at learning and understanding protein structures via natural languages. ProtChatGPT enables users to upload proteins, ask questions, and engage in interactive conversations to produce comprehensive answers. The system comprises protein encoders, a Protein-Language Pertaining Transformer (PLP-former), a projection adapter, and an LLM. The protein first undergoes protein encoders and PLP-former to produce protein embeddings, which are then projected by the adapter to conform with the LLM. The LLM finally combines user questions wit",
    "path": "papers/24/02/2402.09649.json",
    "total_tokens": 928,
    "translated_title": "ProtChatGPT：用于理解大规模语言模型的蛋白质",
    "translated_abstract": "蛋白质研究在各个基础学科中至关重要，但理解其复杂的结构与功能关系仍然具有挑战性。最近的大型语言模型（LLMs）在理解特定任务的知识方面取得了重大进展，这表明了用于蛋白质的ChatGPT-like系统在促进基础研究方面的潜力。在这项工作中，我们介绍了ProtChatGPT，旨在通过自然语言学习和理解蛋白质结构。ProtChatGPT使用户可以上传蛋白质、提问并进行交互式对话以产生全面的回答。该系统包括蛋白编码器、蛋白语言相关转换器（PLP-former）、投影适配器和LLM。蛋白质首先通过蛋白编码器和PLP-former进行编码以产生蛋白质嵌入，然后通过适配器将其投射到与LLM相符合。最后，LLM将用户的问题与蛋白质嵌入进行综合处理。",
    "tldr": "ProtChatGPT是一个基于大型语言模型的系统，通过自然语言学习和理解蛋白质结构，为用户提供上传蛋白质、提问和交互式对话等功能，有助于进一步理解蛋白质的结构与功能关系。"
}