{
    "title": "Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects",
    "abstract": "arXiv:2402.12907v1 Announce Type: new  Abstract: The burgeoning integration of artificial intelligence (AI) into human society brings forth significant implications for societal governance and safety. While considerable strides have been made in addressing AI alignment challenges, existing methodologies primarily focus on technical facets, often neglecting the intricate sociotechnical nature of AI systems, which can lead to a misalignment between the development and deployment contexts. To this end, we posit a new problem worth exploring: Incentive Compatibility Sociotechnical Alignment Problem (ICSAP). We hope this can call for more researchers to explore how to leverage the principles of Incentive Compatibility (IC) from game theory to bridge the gap between technical and societal components to maintain AI consensus with human societies in different contexts. We further discuss three classical game problems for achieving IC: mechanism design, contract theory, and Bayesian persuasion,",
    "link": "https://arxiv.org/abs/2402.12907",
    "context": "Title: Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects\nAbstract: arXiv:2402.12907v1 Announce Type: new  Abstract: The burgeoning integration of artificial intelligence (AI) into human society brings forth significant implications for societal governance and safety. While considerable strides have been made in addressing AI alignment challenges, existing methodologies primarily focus on technical facets, often neglecting the intricate sociotechnical nature of AI systems, which can lead to a misalignment between the development and deployment contexts. To this end, we posit a new problem worth exploring: Incentive Compatibility Sociotechnical Alignment Problem (ICSAP). We hope this can call for more researchers to explore how to leverage the principles of Incentive Compatibility (IC) from game theory to bridge the gap between technical and societal components to maintain AI consensus with human societies in different contexts. We further discuss three classical game problems for achieving IC: mechanism design, contract theory, and Bayesian persuasion,",
    "path": "papers/24/02/2402.12907.json",
    "total_tokens": 867,
    "translated_title": "AI对齐在社会技术系统中的激励兼容性：立场与前景",
    "translated_abstract": "人工智能（AI）日益融入人类社会，对社会治理和安全带来重要影响。尽管在解决AI对齐挑战方面取得了重大进展，但现有方法主要集中在技术方面，往往忽视了AI系统复杂的社会技术性质，这可能导致开发和部署背景之间的不一致。因此，我们提出一个值得探索的新问题：激励兼容性社会技术对齐问题（ICSAP）。我们希望这能呼吁更多研究人员探讨如何利用博弈论中的激励兼容性原则来弥合技术和社会组成部分之间的鸿沟，以在不同背景下维持AI与人类社会的共识。我们进一步讨论了实现IC的三个经典博弈问题：机制设计、契约理论和贝叶斯说服。",
    "tldr": "该论文提出了激励兼容性社会技术对齐问题（ICSAP），旨在探讨如何利用博弈论中的激励兼容性原则来维持AI与人类社会的共识。",
    "en_tdlr": "This paper introduces the Incentive Compatibility Sociotechnical Alignment Problem (ICSAP) to explore leveraging the principles of Incentive Compatibility from game theory to maintain AI consensus with human societies."
}