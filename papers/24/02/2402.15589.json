{
    "title": "Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives of Scholarly Manuscripts",
    "abstract": "arXiv:2402.15589v1 Announce Type: cross  Abstract: One of the most important yet onerous tasks in the academic peer-reviewing process is composing meta-reviews, which involves understanding the core contributions, strengths, and weaknesses of a scholarly manuscript based on peer-review narratives from multiple experts and then summarizing those multiple experts' perspectives into a concise holistic overview. Given the latest major developments in generative AI, especially Large Language Models (LLMs), it is very compelling to rigorously study the utility of LLMs in generating such meta-reviews in an academic peer-review setting. In this paper, we perform a case study with three popular LLMs, i.e., GPT-3.5, LLaMA2, and PaLM2, to automatically generate meta-reviews by prompting them with different types/levels of prompts based on the recently proposed TELeR taxonomy. Finally, we perform a detailed qualitative study of the meta-reviews generated by the LLMs and summarize our findings and ",
    "link": "https://arxiv.org/abs/2402.15589",
    "context": "Title: Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives of Scholarly Manuscripts\nAbstract: arXiv:2402.15589v1 Announce Type: cross  Abstract: One of the most important yet onerous tasks in the academic peer-reviewing process is composing meta-reviews, which involves understanding the core contributions, strengths, and weaknesses of a scholarly manuscript based on peer-review narratives from multiple experts and then summarizing those multiple experts' perspectives into a concise holistic overview. Given the latest major developments in generative AI, especially Large Language Models (LLMs), it is very compelling to rigorously study the utility of LLMs in generating such meta-reviews in an academic peer-review setting. In this paper, we perform a case study with three popular LLMs, i.e., GPT-3.5, LLaMA2, and PaLM2, to automatically generate meta-reviews by prompting them with different types/levels of prompts based on the recently proposed TELeR taxonomy. Finally, we perform a detailed qualitative study of the meta-reviews generated by the LLMs and summarize our findings and ",
    "path": "papers/24/02/2402.15589.json",
    "total_tokens": 903,
    "translated_title": "从学术手稿的同行评审叙事中要求LLMs撰写元评论草案",
    "translated_abstract": "学术同行评审过程中最重要但也最繁重的任务之一是撰写元评论，这涉及根据多位专家的同行评审叙事理解学术手稿的核心贡献、优点和缺点，然后将这些专家多视角的看法总结为简洁的整体概述。鉴于生成型AI，尤其是大型语言模型（LLMs）的最新重大发展，我们有充分的理由深入研究LLMs在学术同行评审环境中生成这种元评论的实用性。本文通过使用三种流行的LLM，即GPT-3.5、LLaMA2和PaLM2，执行案例研究，通过基于最近提出的TELeR分类法以不同类型/级别的提示促使它们自动生成元评论。最后，我们对LLM生成的元评论进行了详细的定性研究，并总结了我们的发现。",
    "tldr": "本文研究了使用不同类型/级别的提示来激发三种流行LLM，GPT-3.5、LLaMA2和PaLM2，在学术同行评审过程中自动生成元评论，并进行了详细的定性研究。",
    "en_tdlr": "This paper investigates the use of prompts of varying types/levels to prompt three popular LLMs, GPT-3.5, LLaMA2, and PaLM2, to automatically generate meta-reviews in an academic peer-review setting, followed by a detailed qualitative study."
}