{
    "title": "ForestColl: Efficient Collective Communications on Heterogeneous Network Fabrics",
    "abstract": "As modern DNN models grow ever larger, collective communications between the accelerators (allreduce, etc.) emerge as a significant performance bottleneck. Designing efficient communication schedules is challenging given today's highly diverse and heterogeneous network fabrics. In this paper, we present ForestColl, a tool that generates efficient schedules for any network topology. ForestColl constructs broadcast/aggregation spanning trees as the communication schedule, achieving theoretically minimum network congestion. Its schedule generation runs in strongly polynomial time and is highly scalable. ForestColl supports any network fabrics, including both switching fabrics and direct connections, as well as any network graph structure. We evaluated ForestColl on multi-cluster AMD MI250 and NVIDIA A100 platforms. ForestColl's schedules achieved up to 52\\% higher performance compared to the vendors' own optimized communication libraries, RCCL and NCCL. ForestColl also outperforms other s",
    "link": "https://arxiv.org/abs/2402.06787",
    "context": "Title: ForestColl: Efficient Collective Communications on Heterogeneous Network Fabrics\nAbstract: As modern DNN models grow ever larger, collective communications between the accelerators (allreduce, etc.) emerge as a significant performance bottleneck. Designing efficient communication schedules is challenging given today's highly diverse and heterogeneous network fabrics. In this paper, we present ForestColl, a tool that generates efficient schedules for any network topology. ForestColl constructs broadcast/aggregation spanning trees as the communication schedule, achieving theoretically minimum network congestion. Its schedule generation runs in strongly polynomial time and is highly scalable. ForestColl supports any network fabrics, including both switching fabrics and direct connections, as well as any network graph structure. We evaluated ForestColl on multi-cluster AMD MI250 and NVIDIA A100 platforms. ForestColl's schedules achieved up to 52\\% higher performance compared to the vendors' own optimized communication libraries, RCCL and NCCL. ForestColl also outperforms other s",
    "path": "papers/24/02/2402.06787.json",
    "total_tokens": 852,
    "translated_title": "ForestColl: 异构网络结构上高效的集合通信",
    "translated_abstract": "随着现代深度神经网络模型越来越大，加速器之间的集合通信（如allreduce等）成为一个重要的性能瓶颈。在当今高度多样化和异构的网络结构下设计高效的通信调度是一项具有挑战性的任务。本文提出了一种名为ForestColl的工具，它能够为任意网络拓扑生成高效的调度。ForestColl使用广播/聚合生成跨越树作为通信调度，实现了理论上的最小网络拥塞。其调度生成运行在强多项式时间内，且具有高扩展性。ForestColl支持包括交换网络和直接连接在内的任何网络结构，以及任何网络图结构。我们在多集群的AMD MI250和NVIDIA A100平台上评估了ForestColl。与供应商自己优化的通信库RCCL和NCCL相比，ForestColl的调度性能提高了高达52％。ForestColl还优于其他...",
    "tldr": "ForestColl是一种针对任意网络拓扑生成高效调度的工具，通过构建广播/聚合生成跨越树的通信调度，实现了理论上的最小网络拥塞，并在实验中表现出高于供应商自带通信库的性能。",
    "en_tdlr": "ForestColl is a tool that generates efficient schedules for any network topology by constructing broadcast/aggregation spanning trees as the communication schedule, achieving theoretically minimum network congestion. It outperforms vendor-optimized communication libraries in experimental evaluations."
}