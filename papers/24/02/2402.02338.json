{
    "title": "Large Language Model Adaptation for Networking",
    "abstract": "Many networking tasks now employ deep learning (DL) to solve complex prediction and system optimization problems. However, current design philosophy of DL-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (DNNs) for different networking tasks. Besides, DNNs tend to achieve poor generalization performance on unseen data distributions/environments.   Motivated by the recent success of large language models (LLMs), for the first time, this work studies the LLM adaptation for networking to explore a more sustainable design philosophy. With the massive pre-trained knowledge and powerful inference ability, LLM can serve as the foundation model, and is expected to achieve \"one model for all\" with even better performance and stronger generalization for various tasks. In this paper, we present NetLLM, the first LLM adaptation framework that efficiently adapts LLMs to solve networking problems. NetLLM addresses many practical challenges in L",
    "link": "https://arxiv.org/abs/2402.02338",
    "context": "Title: Large Language Model Adaptation for Networking\nAbstract: Many networking tasks now employ deep learning (DL) to solve complex prediction and system optimization problems. However, current design philosophy of DL-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (DNNs) for different networking tasks. Besides, DNNs tend to achieve poor generalization performance on unseen data distributions/environments.   Motivated by the recent success of large language models (LLMs), for the first time, this work studies the LLM adaptation for networking to explore a more sustainable design philosophy. With the massive pre-trained knowledge and powerful inference ability, LLM can serve as the foundation model, and is expected to achieve \"one model for all\" with even better performance and stronger generalization for various tasks. In this paper, we present NetLLM, the first LLM adaptation framework that efficiently adapts LLMs to solve networking problems. NetLLM addresses many practical challenges in L",
    "path": "papers/24/02/2402.02338.json",
    "total_tokens": 887,
    "translated_title": "大型语言模型用于网络的适应性",
    "translated_abstract": "现在许多网络任务都使用深度学习（DL）来解决复杂的预测和系统优化问题。然而，目前基于DL的算法的设计哲学需要进行大量的工程开销，因为需要为不同的网络任务手动设计深度神经网络（DNN）。此外，DNN在未见过的数据分布/环境上的泛化性能较差。在大型语言模型（LLM）的最新成功的推动下，本文首次研究了LLM用于网络的适应性，以探索更可持续的设计哲学。凭借海量的预训练知识和强大的推理能力，LLM可以作为基础模型，并且有望在各种任务中实现“一模型适用于所有”，并具有更好的性能和更强的泛化能力。在本文中，我们提出了NetLLM，这是第一个有效地将LLM应用于解决网络问题的适应性框架。NetLLM解决了许多实际挑战。",
    "tldr": "本文首次研究了使用大型语言模型（LLM）适应网络问题的方法，通过利用LLM的预训练知识和强大推理能力，实现了“一模型适用于所有”的目标，并取得了更好的性能和更强的泛化能力。",
    "en_tdlr": "This work studies the adaptation of large language models (LLMs) for networking, aiming to achieve \"one model for all\" with the utilization of pre-trained knowledge and powerful inference ability of LLMs, leading to better performance and stronger generalization."
}