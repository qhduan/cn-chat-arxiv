{
    "title": "Fairness Risks for Group-conditionally Missing Demographics",
    "abstract": "arXiv:2402.13393v1 Announce Type: new  Abstract: Fairness-aware classification models have gained increasing attention in recent years as concerns grow on discrimination against some demographic groups. Most existing models require full knowledge of the sensitive features, which can be impractical due to privacy, legal issues, and an individual's fear of discrimination. The key challenge we will address is the group dependency of the unavailability, e.g., people of some age range may be more reluctant to reveal their age. Our solution augments general fairness risks with probabilistic imputations of the sensitive features, while jointly learning the group-conditionally missing probabilities in a variational auto-encoder. Our model is demonstrated effective on both image and tabular datasets, achieving an improved balance between accuracy and fairness.",
    "link": "https://arxiv.org/abs/2402.13393",
    "context": "Title: Fairness Risks for Group-conditionally Missing Demographics\nAbstract: arXiv:2402.13393v1 Announce Type: new  Abstract: Fairness-aware classification models have gained increasing attention in recent years as concerns grow on discrimination against some demographic groups. Most existing models require full knowledge of the sensitive features, which can be impractical due to privacy, legal issues, and an individual's fear of discrimination. The key challenge we will address is the group dependency of the unavailability, e.g., people of some age range may be more reluctant to reveal their age. Our solution augments general fairness risks with probabilistic imputations of the sensitive features, while jointly learning the group-conditionally missing probabilities in a variational auto-encoder. Our model is demonstrated effective on both image and tabular datasets, achieving an improved balance between accuracy and fairness.",
    "path": "papers/24/02/2402.13393.json",
    "total_tokens": 803,
    "translated_title": "针对群体条件性缺失人口统计数据的公平风险",
    "translated_abstract": "具有公平意识的分类模型近年来越来越受到关注，因为对某些人口统计群体的歧视问题日益引起担忧。大多数现有模型要求完全了解敏感特征，这可能由于隐私、法律问题和个人对歧视的恐惧而不切实际。我们将解决的关键挑战是不可用性的群体依赖性，例如，某些年龄范围的人可能更不愿透露他们的年龄。我们的解决方案通过对敏感特征进行概率填充，同时在变分自动编码器中联合学习群体条件性缺失的概率，将一般公平风险与之增强。我们的模型在图像和表格数据集上表现出了有效性，实现了准确性和公平性之间的改进平衡。",
    "tldr": "通过概率填充敏感特征，联合学习群体条件性缺失概率，增强一般公平风险，实现准确性和公平性之间的改进平衡",
    "en_tdlr": "Augmenting fairness risks with probabilistic imputations of sensitive features and joint learning of group-conditionally missing probabilities in a variational auto-encoder to achieve an improved balance between accuracy and fairness."
}