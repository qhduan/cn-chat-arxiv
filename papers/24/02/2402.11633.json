{
    "title": "Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking dialogs",
    "abstract": "arXiv:2402.11633v1 Announce Type: new  Abstract: Identifying user intents in information-seeking dialogs is crucial for a system to meet user's information needs. Intent prediction (IP) is challenging and demands sufficient dialogs with human-labeled intents for training. However, manually annotating intents is resource-intensive. While large language models (LLMs) have been shown to be effective in generating synthetic data, there is no study on using LLMs to generate intent-aware information-seeking dialogs. In this paper, we focus on leveraging LLMs for zero-shot generation of large-scale, open-domain, and intent-aware information-seeking dialogs. We propose SOLID, which has novel self-seeding and multi-intent self-instructing schemes. The former improves the generation quality by using the LLM's own knowledge scope to initiate dialog generation; the latter prompts the LLM to generate utterances sequentially, and mitigates the need for manual prompt design by asking the LLM to auton",
    "link": "https://arxiv.org/abs/2402.11633",
    "context": "Title: Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking dialogs\nAbstract: arXiv:2402.11633v1 Announce Type: new  Abstract: Identifying user intents in information-seeking dialogs is crucial for a system to meet user's information needs. Intent prediction (IP) is challenging and demands sufficient dialogs with human-labeled intents for training. However, manually annotating intents is resource-intensive. While large language models (LLMs) have been shown to be effective in generating synthetic data, there is no study on using LLMs to generate intent-aware information-seeking dialogs. In this paper, we focus on leveraging LLMs for zero-shot generation of large-scale, open-domain, and intent-aware information-seeking dialogs. We propose SOLID, which has novel self-seeding and multi-intent self-instructing schemes. The former improves the generation quality by using the LLM's own knowledge scope to initiate dialog generation; the latter prompts the LLM to generate utterances sequentially, and mitigates the need for manual prompt design by asking the LLM to auton",
    "path": "papers/24/02/2402.11633.json",
    "total_tokens": 843,
    "translated_title": "利用自我播种和多意图自我指导的LLM生成意图感知的信息检索对话",
    "translated_abstract": "识别信息检索对话中用户意图对于系统满足用户信息需求至关重要。意图预测（IP）具有挑战性，并需要充分的与人工标注意图对话用于训练。然而，手动注释意图资源密集。虽然大型语言模型（LLMs）已被证明在生成合成数据方面非常有效，但尚无研究使用LLMs生成意图感知的信息检索对话。本文的研究重点是利用LLMs进行零-shot生成大规模、开放领域和意图感知的信息检索对话。我们提出了SOLID，其中包括新颖的自我播种和多意图自我指导方案。前者通过利用LLM自身的知识范围来启动对话生成来提高生成质量；后者促使LLM按顺序生成话语，并通过要求LLM自动完成话题设计来减轻手动话题设计的需要。",
    "tldr": "本论文提出了SOLID模型，利用自我播种和多意图自我指导方案来实现LLMs生成意图感知的信息检索对话。",
    "en_tdlr": "This paper introduces the SOLID model, which leverages self-seeding and multi-intent self-instructing schemes to enable LLMs to generate intent-aware information-seeking dialogs."
}