{
    "title": "On Minimal Depth in Neural Networks",
    "abstract": "arXiv:2402.15315v1 Announce Type: new  Abstract: A characterization of the representability of neural networks is relevant to comprehend their success in artificial intelligence. This study investigate two topics on ReLU neural network expressivity and their connection with a conjecture related to the minimum depth required for representing any continuous piecewise linear function (CPWL). The topics are the minimal depth representation of the sum and max operations, as well as the exploration of polytope neural networks. For the sum operation, we establish a sufficient condition on the minimal depth of the operands to find the minimal depth of the operation. In contrast, regarding the max operation, a comprehensive set of examples is presented, demonstrating that no sufficient conditions, depending solely on the depth of the operands, would imply a minimal depth for the operation. The study also examine the minimal depth relationship between convex CPWL functions. On polytope neural ne",
    "link": "https://arxiv.org/abs/2402.15315",
    "context": "Title: On Minimal Depth in Neural Networks\nAbstract: arXiv:2402.15315v1 Announce Type: new  Abstract: A characterization of the representability of neural networks is relevant to comprehend their success in artificial intelligence. This study investigate two topics on ReLU neural network expressivity and their connection with a conjecture related to the minimum depth required for representing any continuous piecewise linear function (CPWL). The topics are the minimal depth representation of the sum and max operations, as well as the exploration of polytope neural networks. For the sum operation, we establish a sufficient condition on the minimal depth of the operands to find the minimal depth of the operation. In contrast, regarding the max operation, a comprehensive set of examples is presented, demonstrating that no sufficient conditions, depending solely on the depth of the operands, would imply a minimal depth for the operation. The study also examine the minimal depth relationship between convex CPWL functions. On polytope neural ne",
    "path": "papers/24/02/2402.15315.json",
    "total_tokens": 769,
    "translated_title": "关于神经网络中的最小深度",
    "translated_abstract": "通过对ReLU神经网络表达能力以及与表示任何连续分段线性函数（CPWL）所需的最小深度相关的猜想的关系进行研究，本研究探讨了神经网络的表达能力特性。研究重点包括对求和和最大运算的最小深度表示，以及对多面体神经网络的探索。实验结果表明，对于求和运算，我们建立了关于操作数最小深度的充分条件以找到运算的最小深度。相反，关于最大运算，我们提供了全面的例子，证明仅依赖于操作数深度的充分条件，并不会暗示运算的最小深度。研究还考察了凸CPWL函数之间的最小深度关系。",
    "tldr": "本研究研究了神经网络中关于最小深度的问题，特别关注了ReLU神经网络的表达能力和最小深度与CPWL函数的关系。",
    "en_tdlr": "This study investigates the minimal depth in neural networks, focusing on the expressivity of ReLU neural networks and the relationship between minimal depth and CPWL functions."
}