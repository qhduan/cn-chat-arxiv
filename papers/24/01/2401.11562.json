{
    "title": "Enhancing selectivity using Wasserstein distance based reweighing. (arXiv:2401.11562v1 [stat.ML])",
    "abstract": "Given two labeled data-sets $\\mathcal{S}$ and $\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\mathcal{T}$.  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1",
    "link": "http://arxiv.org/abs/2401.11562",
    "context": "Title: Enhancing selectivity using Wasserstein distance based reweighing. (arXiv:2401.11562v1 [stat.ML])\nAbstract: Given two labeled data-sets $\\mathcal{S}$ and $\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\mathcal{T}$.  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1",
    "path": "papers/24/01/2401.11562.json",
    "total_tokens": 986,
    "translated_title": "ä½¿ç”¨Wassersteinè·ç¦»è¿›è¡ŒåŠ æƒä»¥å¢å¼ºé€‰æ‹©æ€§",
    "translated_abstract": "ç»™å®šä¸¤ä¸ªæ ‡è®°æ•°æ®é›†ğ’®å’Œğ’¯ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç®€å•é«˜æ•ˆçš„è´ªå©ªç®—æ³•æ¥å¯¹æŸå¤±å‡½æ•°è¿›è¡ŒåŠ æƒï¼Œä½¿å¾—åœ¨ğ’®ä¸Šè®­ç»ƒå¾—åˆ°çš„ç¥ç»ç½‘ç»œæƒé‡çš„æé™åˆ†å¸ƒé€¼è¿‘åœ¨ğ’¯ä¸Šè®­ç»ƒå¾—åˆ°çš„æé™åˆ†å¸ƒã€‚åœ¨ç†è®ºæ–¹é¢ï¼Œæˆ‘ä»¬è¯æ˜äº†å½“è¾“å…¥æ•°æ®é›†çš„åº¦é‡ç†µæœ‰ç•Œæ—¶ï¼Œæˆ‘ä»¬çš„è´ªå©ªç®—æ³•è¾“å‡ºæ¥è¿‘æœ€ä¼˜çš„åŠ æƒï¼Œå³ç½‘ç»œæƒé‡çš„ä¸¤ä¸ªä¸å˜åˆ†å¸ƒåœ¨æ€»å˜å·®è·ç¦»ä¸Šå¯ä»¥è¯æ˜æ¥è¿‘ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•ç®€å•å¯æ‰©å±•ï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜è¯æ˜äº†ç®—æ³•çš„æ•ˆç‡ä¸Šç•Œã€‚æˆ‘ä»¬çš„ç®—æ³•å¯ä»¥æœ‰æ„åœ°å¼•å…¥åˆ†å¸ƒåç§»ä»¥è¿›è¡Œï¼ˆè½¯ï¼‰å¤šç›®æ ‡ä¼˜åŒ–ã€‚ä½œä¸ºä¸€ä¸ªåŠ¨æœºåº”ç”¨ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è¯†åˆ«å¯¹MNK2ï¼ˆä¸€ç§ç»†èƒä¿¡å·ä¼ å¯¼çš„MAPæ¿€é…¶ï¼‰å…·æœ‰éç»“åˆæ€§çš„å°åˆ†å­ç»“åˆç‰©ã€‚",
    "tldr": "æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä½¿ç”¨Wassersteinè·ç¦»è¿›è¡ŒåŠ æƒçš„ç®—æ³•ï¼Œåœ¨æ ‡è®°çš„æ•°æ®é›†ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œå¯ä»¥é€¼è¿‘åœ¨å…¶ä»–æ•°æ®é›†ä¸Šè®­ç»ƒå¾—åˆ°çš„ç»“æœã€‚æˆ‘ä»¬è¯æ˜äº†ç®—æ³•å¯ä»¥è¾“å‡ºæ¥è¿‘æœ€ä¼˜çš„åŠ æƒï¼Œä¸”ç®—æ³•ç®€å•å¯æ‰©å±•ã€‚æˆ‘ä»¬çš„ç®—æ³•å¯ä»¥æœ‰æ„åœ°å¼•å…¥åˆ†å¸ƒåç§»è¿›è¡Œå¤šç›®æ ‡ä¼˜åŒ–ã€‚ä½œä¸ºåº”ç”¨å®ä¾‹ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è¯†åˆ«å¯¹ç»†èƒä¿¡å·ä¼ å¯¼çš„MAPæ¿€é…¶å…·æœ‰éç»“åˆæ€§çš„å°åˆ†å­ç»“åˆç‰©ã€‚",
    "en_tdlr": "We propose a methodology that uses Wasserstein distance based reweighing to improve selectivity in training neural networks on labeled datasets. Our algorithm outputs close to optimal reweighing, is simple and scalable, and can introduce intentional distribution shifts for multi-criteria optimization. As an application, we train a neural network to recognize small molecule binders to a specific protein."
}