{
    "title": "CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion. (arXiv:2401.14066v1 [cs.CV])",
    "abstract": "Large-scale text-to-image generative models have made impressive strides, showcasing their ability to synthesize a vast array of high-quality images. However, adapting these models for artistic image editing presents two significant challenges. Firstly, users struggle to craft textual prompts that meticulously detail visual elements of the input image. Secondly, prevalent models, when effecting modifications in specific zones, frequently disrupt the overall artistic style, complicating the attainment of cohesive and aesthetically unified artworks. To surmount these obstacles, we build the innovative unified framework CreativeSynth, which is based on a diffusion model with the ability to coordinate multimodal inputs and multitask in the field of artistic image generation. By integrating multimodal features with customized attention mechanisms, CreativeSynth facilitates the importation of real-world semantic content into the domain of art through inversion and real-time style transfer. T",
    "link": "http://arxiv.org/abs/2401.14066",
    "context": "Title: CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion. (arXiv:2401.14066v1 [cs.CV])\nAbstract: Large-scale text-to-image generative models have made impressive strides, showcasing their ability to synthesize a vast array of high-quality images. However, adapting these models for artistic image editing presents two significant challenges. Firstly, users struggle to craft textual prompts that meticulously detail visual elements of the input image. Secondly, prevalent models, when effecting modifications in specific zones, frequently disrupt the overall artistic style, complicating the attainment of cohesive and aesthetically unified artworks. To surmount these obstacles, we build the innovative unified framework CreativeSynth, which is based on a diffusion model with the ability to coordinate multimodal inputs and multitask in the field of artistic image generation. By integrating multimodal features with customized attention mechanisms, CreativeSynth facilitates the importation of real-world semantic content into the domain of art through inversion and real-time style transfer. T",
    "path": "papers/24/01/2401.14066.json",
    "total_tokens": 924,
    "translated_title": "CreativeSynth：基于多模态扩散的视觉艺术创意融合与合成",
    "translated_abstract": "大规模的文本到图像生成模型取得了巨大的进步，展示了其合成各种高质量图像的能力。然而，将这些模型应用于艺术图像编辑面临两个重要挑战。首先，用户往往难以构建详细描述输入图像视觉元素的文本提示。其次，现有模型在特定区域进行修改时常常会破坏整体艺术风格，使得实现一致且具有审美统一的作品变得更加复杂。为了克服这些障碍，我们构建了一种创新的统一框架CreativeSynth，该框架基于具有协调多模态输入和多任务能力的扩散模型，通过整合多模态特征和定制的注意力机制，CreativeSynth实现了将现实世界的语义内容导入到艺术领域中，实现了反转和实时风格转移。",
    "tldr": "CreativeSynth是一种基于多模态扩散的创新统一框架，通过整合多模态特征和定制的注意力机制，实现了将现实世界的语义内容导入到艺术领域中，能够协调多模态输入和多任务，在艺术图像生成方面具有重要意义。",
    "en_tdlr": "CreativeSynth is an innovative unified framework based on multimodal diffusion, which integrates multimodal features and customized attention mechanisms to import real-world semantic content into the domain of art, coordinating multimodal inputs and multitasking in the field of artistic image generation. Its significance lies in overcoming the challenges of crafting detailed textual prompts and maintaining artistic style during image editing."
}