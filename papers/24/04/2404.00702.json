{
    "title": "Tired of Plugins? Large Language Models Can Be End-To-End Recommenders",
    "abstract": "arXiv:2404.00702v1 Announce Type: new  Abstract: Recommender systems aim to predict user interest based on historical behavioral data. They are mainly designed in sequential pipelines, requiring lots of data to train different sub-systems, and are hard to scale to new domains. Recently, Large Language Models (LLMs) have demonstrated remarkable generalized capabilities, enabling a singular model to tackle diverse recommendation tasks across various scenarios. Nonetheless, existing LLM-based recommendation systems utilize LLM purely for a single task of the recommendation pipeline. Besides, these systems face challenges in presenting large-scale item sets to LLMs in natural language format, due to the constraint of input length. To address these challenges, we introduce an LLM-based end-to-end recommendation framework: UniLLMRec. Specifically, UniLLMRec integrates multi-stage tasks (e.g. recall, ranking, re-ranking) via chain-of-recommendations. To deal with large-scale items, we propose",
    "link": "https://arxiv.org/abs/2404.00702",
    "context": "Title: Tired of Plugins? Large Language Models Can Be End-To-End Recommenders\nAbstract: arXiv:2404.00702v1 Announce Type: new  Abstract: Recommender systems aim to predict user interest based on historical behavioral data. They are mainly designed in sequential pipelines, requiring lots of data to train different sub-systems, and are hard to scale to new domains. Recently, Large Language Models (LLMs) have demonstrated remarkable generalized capabilities, enabling a singular model to tackle diverse recommendation tasks across various scenarios. Nonetheless, existing LLM-based recommendation systems utilize LLM purely for a single task of the recommendation pipeline. Besides, these systems face challenges in presenting large-scale item sets to LLMs in natural language format, due to the constraint of input length. To address these challenges, we introduce an LLM-based end-to-end recommendation framework: UniLLMRec. Specifically, UniLLMRec integrates multi-stage tasks (e.g. recall, ranking, re-ranking) via chain-of-recommendations. To deal with large-scale items, we propose",
    "path": "papers/24/04/2404.00702.json",
    "total_tokens": 838,
    "translated_title": "厌倦了插件？大型语言模型可以成为端到端推荐系统",
    "translated_abstract": "推荐系统旨在基于历史行为数据预测用户兴趣。它们主要设计为顺序流水线，需要大量数据来训练不同子系统，并且难以扩展到新域。最近，大型语言模型（LLMs）展示了出色的通用能力，使一个模型能够处理各种场景中的多样化推荐任务。然而，现有基于LLM的推荐系统纯粹利用LLM来处理推荐流水线的单个任务。此外，这些系统面临着以自然语言格式向LLM呈现大规模物品集合的挑战，由于输入长度的限制。为解决这些挑战，我们引入了一种基于LLM的端到端推荐框架：UniLLMRec。具体而言，UniLLMRec通过推荐链集成多阶段任务（例如召回、排序、重新排序）。为了处理大规模物品，我们提出",
    "tldr": "大型语言模型UniLLMRec将多阶段任务整合为端到端推荐框架，以解决推荐系统中对大规模物品集合的挑战",
    "en_tdlr": "UniLLMRec, a large language model, integrates multi-stage tasks into an end-to-end recommendation framework to address the challenge of presenting large-scale item sets in recommender systems."
}