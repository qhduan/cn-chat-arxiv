{
    "title": "Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies. (arXiv:2309.16025v1 [cs.LG])",
    "abstract": "Current methods of imitation learning (IL), primarily based on deep neural networks, offer efficient means for obtaining driving policies from real-world data but suffer from significant limitations in interpretability and generalizability. These shortcomings are particularly concerning in safety-critical applications like autonomous driving. In this paper, we address these limitations by introducing Symbolic Imitation Learning (SIL), a groundbreaking method that employs Inductive Logic Programming (ILP) to learn driving policies which are transparent, explainable and generalisable from available datasets. Utilizing the real-world highD dataset, we subject our method to a rigorous comparative analysis against prevailing neural-network-based IL methods. Our results demonstrate that SIL not only enhances the interpretability of driving policies but also significantly improves their applicability across varied driving situations. Hence, this work offers a novel pathway to more reliable an",
    "link": "http://arxiv.org/abs/2309.16025",
    "context": "Title: Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies. (arXiv:2309.16025v1 [cs.LG])\nAbstract: Current methods of imitation learning (IL), primarily based on deep neural networks, offer efficient means for obtaining driving policies from real-world data but suffer from significant limitations in interpretability and generalizability. These shortcomings are particularly concerning in safety-critical applications like autonomous driving. In this paper, we address these limitations by introducing Symbolic Imitation Learning (SIL), a groundbreaking method that employs Inductive Logic Programming (ILP) to learn driving policies which are transparent, explainable and generalisable from available datasets. Utilizing the real-world highD dataset, we subject our method to a rigorous comparative analysis against prevailing neural-network-based IL methods. Our results demonstrate that SIL not only enhances the interpretability of driving policies but also significantly improves their applicability across varied driving situations. Hence, this work offers a novel pathway to more reliable an",
    "path": "papers/23/09/2309.16025.json",
    "total_tokens": 1015,
    "translated_title": "符号化模仿学习：从黑盒到可解释的驾驶策略",
    "translated_abstract": "当前的模仿学习方法主要基于深度神经网络，提供了从现实世界数据中获取驾驶策略的有效手段，但在可解释性和泛化性方面存在显著局限性。这些缺点在自动驾驶等安全关键应用中尤为令人担忧。本文通过引入符号化模仿学习（SIL），一种使用归纳逻辑编程（ILP）学习从可用数据集中获取透明、可解释和泛化的驾驶策略的创新方法，来解决这些局限性。利用真实世界的highD数据集，我们对我们的方法进行了严格的比较分析，与当前的基于神经网络的模仿学习方法进行了对比。我们的结果表明，SIL不仅提高了驾驶策略的可解释性，还显著提高了它们在各种驾驶情况下的适用性。因此，这项工作为实现更可靠和可解释的驾驶策略打开了一条新的途径。",
    "tldr": "本文介绍了一种名为符号化模仿学习（SIL）的方法，通过引入归纳逻辑编程（ILP）来学习从现有数据集中获取透明、可解释和泛化的驾驶策略。与传统的基于深度神经网络的模仿学习方法相比，SIL不仅提高了驾驶策略的可解释性，还显著改进了它们在各种驾驶情况下的适用性。"
}