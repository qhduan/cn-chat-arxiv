{
    "title": "Optimal Learning via Moderate Deviations Theory. (arXiv:2305.14496v1 [stat.ML])",
    "abstract": "This paper proposes a statistically optimal approach for learning a function value using a confidence interval in a wide range of models, including general non-parametric estimation of an expected loss described as a stochastic programming problem or various SDE models. More precisely, we develop a systematic construction of highly accurate confidence intervals by using a moderate deviation principle-based approach. It is shown that the proposed confidence intervals are statistically optimal in the sense that they satisfy criteria regarding exponential accuracy, minimality, consistency, mischaracterization probability, and eventual uniformly most accurate (UMA) property. The confidence intervals suggested by this approach are expressed as solutions to robust optimization problems, where the uncertainty is expressed via the underlying moderate deviation rate function induced by the data-generating process. We demonstrate that for many models these optimization problems admit tractable r",
    "link": "http://arxiv.org/abs/2305.14496",
    "context": "Title: Optimal Learning via Moderate Deviations Theory. (arXiv:2305.14496v1 [stat.ML])\nAbstract: This paper proposes a statistically optimal approach for learning a function value using a confidence interval in a wide range of models, including general non-parametric estimation of an expected loss described as a stochastic programming problem or various SDE models. More precisely, we develop a systematic construction of highly accurate confidence intervals by using a moderate deviation principle-based approach. It is shown that the proposed confidence intervals are statistically optimal in the sense that they satisfy criteria regarding exponential accuracy, minimality, consistency, mischaracterization probability, and eventual uniformly most accurate (UMA) property. The confidence intervals suggested by this approach are expressed as solutions to robust optimization problems, where the uncertainty is expressed via the underlying moderate deviation rate function induced by the data-generating process. We demonstrate that for many models these optimization problems admit tractable r",
    "path": "papers/23/05/2305.14496.json",
    "total_tokens": 849,
    "translated_title": "通过中度偏差理论进行最优学习",
    "translated_abstract": "本文提出了一种在广泛模型中使用置信区间学习函数值的统计最优方法，包括描述为随机规划问题或各种SDE模型的期望损失的一般非参数估计。更准确地说，我们通过采用基于中度偏差原理的方法系统地构建高度准确的置信区间。研究表明，所提出的置信区间在统计意义上是最优的，因为它们满足以指数精度、最小性、一致性、误判概率以及最终的一致最大精度为标准的要求。该方法提出的置信区间是通过强化优化问题的解来表达的，其中不确定性通过数据生成过程引发的中度偏差率函数来表示。我们演示了对于许多模型，这些优化问题具有易于解的结果。",
    "tldr": "本文提出了一种能够在广泛模型中进行最优学习的方法，利用中度偏差原理构建高度准确的置信区间，满足指数精度、一致性和最大精度等标准，为该方法提供了理论依据。",
    "en_tdlr": "This paper proposes a statistically optimal approach to learning a function value using a confidence interval in a wide range of models, and develops highly accurate confidence intervals using a moderate deviation principle-based approach. The proposed confidence intervals satisfy criteria regarding exponential accuracy, consistency, and eventually, the uniformly most accurate property, providing a theoretical basis for the method."
}