{
    "title": "Large Language Models as Data Preprocessors. (arXiv:2308.16361v1 [cs.AI])",
    "abstract": "Large Language Models (LLMs), typified by OpenAI's GPT series and Meta's LLaMA variants, have marked a significant advancement in artificial intelligence. Trained on vast amounts of text data, LLMs are capable of understanding and generating human-like text across a diverse range of topics. This study expands on the applications of LLMs, exploring their potential in data preprocessing, a critical stage in data mining and analytics applications. We delve into the applicability of state-of-the-art LLMs such as GPT-3.5, GPT-4, and Vicuna-13B for error detection, data imputation, schema matching, and entity matching tasks. Alongside showcasing the inherent capabilities of LLMs, we highlight their limitations, particularly in terms of computational expense and inefficiency. We propose an LLM-based framework for data preprocessing, which integrates cutting-edge prompt engineering techniques, coupled with traditional methods like contextualization and feature selection, to improve the perform",
    "link": "http://arxiv.org/abs/2308.16361",
    "context": "Title: Large Language Models as Data Preprocessors. (arXiv:2308.16361v1 [cs.AI])\nAbstract: Large Language Models (LLMs), typified by OpenAI's GPT series and Meta's LLaMA variants, have marked a significant advancement in artificial intelligence. Trained on vast amounts of text data, LLMs are capable of understanding and generating human-like text across a diverse range of topics. This study expands on the applications of LLMs, exploring their potential in data preprocessing, a critical stage in data mining and analytics applications. We delve into the applicability of state-of-the-art LLMs such as GPT-3.5, GPT-4, and Vicuna-13B for error detection, data imputation, schema matching, and entity matching tasks. Alongside showcasing the inherent capabilities of LLMs, we highlight their limitations, particularly in terms of computational expense and inefficiency. We propose an LLM-based framework for data preprocessing, which integrates cutting-edge prompt engineering techniques, coupled with traditional methods like contextualization and feature selection, to improve the perform",
    "path": "papers/23/08/2308.16361.json",
    "total_tokens": 835,
    "translated_title": "大型语言模型作为数据预处理器",
    "translated_abstract": "大型语言模型（LLMs），如OpenAI的GPT系列和Meta的LLaMA变体，标志着人工智能的重大进展。经过大量文本数据的训练，LLMs能够理解和生成各种主题上人类化的文本。本研究扩展了LLMs的应用范围，探讨了它们在数据预处理中的潜力，这是数据挖掘和分析应用中的关键阶段。我们深入研究了最先进的LLMs（如GPT-3.5、GPT-4和Vicuna-13B）在错误检测、数据插补、模式匹配和实体匹配任务中的适用性。除了展示LLMs的内在能力外，我们还强调了它们的局限性，特别是在计算开销和效率方面。我们提出了一种基于LLMs的数据预处理框架，该框架整合了前沿的提示工程技术，结合了上下文化和特征选择等传统方法，以提高性能。",
    "tldr": "大型语言模型可以作为数据预处理器的应用，通过使用开发工程技术和传统方法来提高性能。",
    "en_tdlr": "Large Language Models can be used as data preprocessors to enhance performance by utilizing cutting-edge engineering techniques and traditional methods."
}