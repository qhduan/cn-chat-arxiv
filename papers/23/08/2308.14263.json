{
    "title": "Cross-Modal Retrieval: A Systematic Review of Methods and Future Directions. (arXiv:2308.14263v2 [cs.IR] UPDATED)",
    "abstract": "With the exponential surge in diverse multi-modal data, traditional uni-modal retrieval methods struggle to meet the needs of users demanding access to data from various modalities. To address this, cross-modal retrieval has emerged, enabling interaction across modalities, facilitating semantic matching, and leveraging complementarity and consistency between different modal data. Although prior literature undertook a review of the cross-modal retrieval field, it exhibits numerous deficiencies pertaining to timeliness, taxonomy, and comprehensiveness. This paper conducts a comprehensive review of cross-modal retrieval's evolution, spanning from shallow statistical analysis techniques to vision-language pre-training models. Commencing with a comprehensive taxonomy grounded in machine learning paradigms, mechanisms, and models, the paper then delves deeply into the principles and architectures underpinning existing cross-modal retrieval methods. Furthermore, it offers an overview of widel",
    "link": "http://arxiv.org/abs/2308.14263",
    "context": "Title: Cross-Modal Retrieval: A Systematic Review of Methods and Future Directions. (arXiv:2308.14263v2 [cs.IR] UPDATED)\nAbstract: With the exponential surge in diverse multi-modal data, traditional uni-modal retrieval methods struggle to meet the needs of users demanding access to data from various modalities. To address this, cross-modal retrieval has emerged, enabling interaction across modalities, facilitating semantic matching, and leveraging complementarity and consistency between different modal data. Although prior literature undertook a review of the cross-modal retrieval field, it exhibits numerous deficiencies pertaining to timeliness, taxonomy, and comprehensiveness. This paper conducts a comprehensive review of cross-modal retrieval's evolution, spanning from shallow statistical analysis techniques to vision-language pre-training models. Commencing with a comprehensive taxonomy grounded in machine learning paradigms, mechanisms, and models, the paper then delves deeply into the principles and architectures underpinning existing cross-modal retrieval methods. Furthermore, it offers an overview of widel",
    "path": "papers/23/08/2308.14263.json",
    "total_tokens": 893,
    "translated_title": "跨模态检索：方法和未来方向的系统综述",
    "translated_abstract": "随着多样化多模态数据的爆炸性增长，传统的单模态检索方法难以满足用户对不同模态数据访问的需求。为解决这个问题，跨模态检索应运而生，它能够实现跨模态交互，促进语义匹配，并利用不同模态数据之间的互补性和一致性。尽管以往的文献对跨模态检索领域进行了综述，但存在着关于及时性、分类体系和全面性等方面的缺陷。本文对跨模态检索的发展进行了全面的综述，涵盖了从浅层统计分析技术到视觉-语言预训练模型的演进。文章首先从机器学习范式、机制和模型的角度构建了一个全面的分类体系，然后深入探讨了现有跨模态检索方法的原理和架构。此外，文章还概述了当前广泛使用的评估数据集、性能评价指标和常见问题。",
    "tldr": "本文提供了一篇关于跨模态检索的方法和未来方向的系统综述，从浅层统计分析到视觉-语言预训练模型，深入探讨了现有跨模态检索方法的原理和架构。",
    "en_tdlr": "This paper presents a systematic review of methods and future directions in cross-modal retrieval, covering the evolution from shallow statistical analysis to vision-language pre-training models, and delving into the principles and architectures of existing cross-modal retrieval methods."
}