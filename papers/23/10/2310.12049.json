{
    "title": "Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models. (arXiv:2310.12049v1 [cs.CL])",
    "abstract": "Existing text scaling methods often require a large corpus, struggle with short texts, or require labeled data. We develop a text scaling method that leverages the pattern recognition capabilities of generative large language models (LLMs). Specifically, we propose concept-guided chain-of-thought (CGCoT), which uses prompts designed to summarize ideas and identify target parties in texts to generate concept-specific breakdowns, in many ways similar to guidance for human coder content analysis. CGCoT effectively shifts pairwise text comparisons from a reasoning problem to a pattern recognition problem. We then pairwise compare concept-specific breakdowns using an LLM. We use the results of these pairwise comparisons to estimate a scale using the Bradley-Terry model. We use this approach to scale affective speech on Twitter. Our measures correlate more strongly with human judgments than alternative approaches like Wordfish. Besides a small set of pilot data to develop the CGCoT prompts, ",
    "link": "http://arxiv.org/abs/2310.12049",
    "context": "Title: Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models. (arXiv:2310.12049v1 [cs.CL])\nAbstract: Existing text scaling methods often require a large corpus, struggle with short texts, or require labeled data. We develop a text scaling method that leverages the pattern recognition capabilities of generative large language models (LLMs). Specifically, we propose concept-guided chain-of-thought (CGCoT), which uses prompts designed to summarize ideas and identify target parties in texts to generate concept-specific breakdowns, in many ways similar to guidance for human coder content analysis. CGCoT effectively shifts pairwise text comparisons from a reasoning problem to a pattern recognition problem. We then pairwise compare concept-specific breakdowns using an LLM. We use the results of these pairwise comparisons to estimate a scale using the Bradley-Terry model. We use this approach to scale affective speech on Twitter. Our measures correlate more strongly with human judgments than alternative approaches like Wordfish. Besides a small set of pilot data to develop the CGCoT prompts, ",
    "path": "papers/23/10/2310.12049.json",
    "total_tokens": 971,
    "translated_title": "Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models (使用大型语言模型的概念导向思维链图提示进行文本配对比较缩放)",
    "translated_abstract": "现有的文本缩放方法经常需要大型语料库，难以处理短文本，或需要有标签的数据。我们开发了一种利用生成性大型语言模型（LLM）的模式识别能力来进行文本缩放的方法。具体而言，我们提出了概念导向思维链图（CGCoT），它使用设计用于总结想法并在文本中识别目标方的提示来生成概念特定的细分，类似于人类编码器内容分析的指导。CGCoT将配对文本比较从一个推理问题转变为一个模式识别问题。然后，我们使用LLM对概念特定的细分进行配对比较。我们利用这些配对比较的结果使用Bradley-Terry模型来估计一个评分尺度。我们利用这种方法对Twitter上的情感言论进行缩放。我们的测量值与人类判断的相关性比Wordfish等替代方法更强。除了一小组用于开发CGCoT提示的试验数据之外，...",
    "tldr": "这项研究开发了一种文本缩放方法，利用生成性大型语言模型的模式识别能力，通过概念导向思维链图和大型语言模型进行文本比较，并使用Bradley-Terry模型来估计评分尺度。该方法在Twitter上对情感言论的缩放效果更好。"
}