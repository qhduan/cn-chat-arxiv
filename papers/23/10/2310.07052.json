{
    "title": "Uses of Sub-sample Estimates to Reduce Errors in Stochastic Optimization Models. (arXiv:2310.07052v1 [math.OC])",
    "abstract": "Optimization software enables the solution of problems with millions of variables and associated parameters. These parameters are, however, often uncertain and represented with an analytical description of the parameter's distribution or with some form of sample. With large numbers of such parameters, optimization of the resulting model is often driven by mis-specifications or extreme sample characteristics, resulting in solutions that are far from a true optimum. This paper describes how asymptotic convergence results may not be useful in large-scale problems and how the optimization of problems based on sub-sample estimates may achieve improved results over models using full-sample solution estimates. A motivating example and numerical results from a portfolio optimization problem demonstrate the potential improvement. A theoretical analysis also provides insight into the structure of problems where sub-sample optimization may be most beneficial.",
    "link": "http://arxiv.org/abs/2310.07052",
    "context": "Title: Uses of Sub-sample Estimates to Reduce Errors in Stochastic Optimization Models. (arXiv:2310.07052v1 [math.OC])\nAbstract: Optimization software enables the solution of problems with millions of variables and associated parameters. These parameters are, however, often uncertain and represented with an analytical description of the parameter's distribution or with some form of sample. With large numbers of such parameters, optimization of the resulting model is often driven by mis-specifications or extreme sample characteristics, resulting in solutions that are far from a true optimum. This paper describes how asymptotic convergence results may not be useful in large-scale problems and how the optimization of problems based on sub-sample estimates may achieve improved results over models using full-sample solution estimates. A motivating example and numerical results from a portfolio optimization problem demonstrate the potential improvement. A theoretical analysis also provides insight into the structure of problems where sub-sample optimization may be most beneficial.",
    "path": "papers/23/10/2310.07052.json",
    "total_tokens": 774,
    "translated_title": "使用子样本估计减少随机优化模型中的误差",
    "translated_abstract": "优化软件能够解决具有数百万个变量和相关参数的问题。然而，这些参数往往是不确定的，并用参数分布的解析描述或某种形式的样本表示。在具有大量此类参数的情况下，由于规范错误或极端样本特征驱动的模型优化通常导致离真正最优解很远的解。本文描述了渐近收敛结果在大规模问题中可能无用的情况，以及基于子样本估计的问题优化可能实现比使用全样本解估计更好的结果。一个激励性示例和一个投资组合优化问题的数值结果展示了潜在的改进。理论分析还揭示了子样本优化在哪些问题结构中可能最有益的一些见解。",
    "tldr": "本文研究了使用子样本估计来减少大规模随机优化模型中的误差，通过对比全样本解估计的结果，证明了子样本优化可能获得更好的结果。"
}