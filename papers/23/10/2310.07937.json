{
    "title": "Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using Large Language Models. (arXiv:2310.07937v1 [cs.RO])",
    "abstract": "In advanced human-robot interaction tasks, visual target navigation is crucial for autonomous robots navigating unknown environments. While numerous approaches have been developed in the past, most are designed for single-robot operations, which often suffer from reduced efficiency and robustness due to environmental complexities. Furthermore, learning policies for multi-robot collaboration are resource-intensive. To address these challenges, we propose Co-NavGPT, an innovative framework that integrates Large Language Models (LLMs) as a global planner for multi-robot cooperative visual target navigation. Co-NavGPT encodes the explored environment data into prompts, enhancing LLMs' scene comprehension. It then assigns exploration frontiers to each robot for efficient target search. Experimental results on Habitat-Matterport 3D (HM3D) demonstrate that Co-NavGPT surpasses existing models in success rates and efficiency without any learning process, demonstrating the vast potential of LLMs",
    "link": "http://arxiv.org/abs/2310.07937",
    "context": "Title: Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using Large Language Models. (arXiv:2310.07937v1 [cs.RO])\nAbstract: In advanced human-robot interaction tasks, visual target navigation is crucial for autonomous robots navigating unknown environments. While numerous approaches have been developed in the past, most are designed for single-robot operations, which often suffer from reduced efficiency and robustness due to environmental complexities. Furthermore, learning policies for multi-robot collaboration are resource-intensive. To address these challenges, we propose Co-NavGPT, an innovative framework that integrates Large Language Models (LLMs) as a global planner for multi-robot cooperative visual target navigation. Co-NavGPT encodes the explored environment data into prompts, enhancing LLMs' scene comprehension. It then assigns exploration frontiers to each robot for efficient target search. Experimental results on Habitat-Matterport 3D (HM3D) demonstrate that Co-NavGPT surpasses existing models in success rates and efficiency without any learning process, demonstrating the vast potential of LLMs",
    "path": "papers/23/10/2310.07937.json",
    "total_tokens": 941,
    "translated_title": "Co-NavGPT: 使用大型语言模型的多机器人合作视觉语义导航",
    "translated_abstract": "在高级人机交互任务中，对于自主机器人在未知环境中进行视觉目标导航至关重要。尽管过去已经开发了许多方法，但大多数都是设计用于单一机器人操作，这往往由于环境复杂性而导致效率和鲁棒性降低。此外，学习多机器人协作的策略需要资源密集型。为了解决这些挑战，我们提出了Co-NavGPT，这是一个创新的框架，将大型语言模型(LLMs)作为多机器人合作视觉目标导航的全局规划器。Co-NavGPT将探索的环境数据编码为提示，增强LLMs对场景的理解。然后，它为每个机器人分配探索前沿以实现高效的目标搜索。在Habitat-Matterport 3D (HM3D)上的实验结果表明，Co-NavGPT在成功率和效率方面超过了现有模型，而无需任何学习过程，展示了LLMs的巨大潜力。",
    "tldr": "Co-NavGPT是一个创新的框架，使用大型语言模型作为全局规划器，实现多机器人合作的视觉目标导航。在实验中表现出了超越现有模型的成功率和效率，展示了大型语言模型的巨大潜力。",
    "en_tdlr": "Co-NavGPT is an innovative framework that uses large language models as a global planner to achieve multi-robot cooperative visual target navigation. It demonstrates superior success rates and efficiency compared to existing models, showcasing the great potential of large language models."
}