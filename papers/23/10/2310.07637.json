{
    "title": "OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models. (arXiv:2310.07637v2 [cs.AI] UPDATED)",
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in NLP-related tasks such as translation, summarizing, and generation. The application of LLMs in specific areas, notably AIOps (Artificial Intelligence for IT Operations), holds great potential due to their advanced abilities in information summarizing, report analyzing, and ability of API calling. Nevertheless, the performance of current LLMs in AIOps tasks is yet to be determined. Furthermore, a comprehensive benchmark is required to steer the optimization of LLMs tailored for AIOps. Compared with existing benchmarks that focus on evaluating specific fields like network configuration, in this paper, we present \\textbf{OpsEval}, a comprehensive task-oriented AIOps benchmark designed for LLMs. For the first time, OpsEval assesses LLMs' proficiency in three crucial scenarios (Wired Network Operation, 5G Communication Operation, and Database Operation) at various ability levels (knowledge recall, analytical thinking, an",
    "link": "http://arxiv.org/abs/2310.07637",
    "context": "Title: OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models. (arXiv:2310.07637v2 [cs.AI] UPDATED)\nAbstract: Large language models (LLMs) have exhibited remarkable capabilities in NLP-related tasks such as translation, summarizing, and generation. The application of LLMs in specific areas, notably AIOps (Artificial Intelligence for IT Operations), holds great potential due to their advanced abilities in information summarizing, report analyzing, and ability of API calling. Nevertheless, the performance of current LLMs in AIOps tasks is yet to be determined. Furthermore, a comprehensive benchmark is required to steer the optimization of LLMs tailored for AIOps. Compared with existing benchmarks that focus on evaluating specific fields like network configuration, in this paper, we present \\textbf{OpsEval}, a comprehensive task-oriented AIOps benchmark designed for LLMs. For the first time, OpsEval assesses LLMs' proficiency in three crucial scenarios (Wired Network Operation, 5G Communication Operation, and Database Operation) at various ability levels (knowledge recall, analytical thinking, an",
    "path": "papers/23/10/2310.07637.json",
    "total_tokens": 895,
    "translated_title": "OpsEval: 用于大型语言模型的全面任务导向的AIOps基准测试",
    "translated_abstract": "大型语言模型(Large Language Models, LLMs)在翻译、总结和生成等NLP相关任务中表现出了显著的能力。LLMs在特定领域中应用，特别是在AIOps（面向IT运维的人工智能）中，由于其先进的信息汇总、报告分析和API调用能力而具有巨大的潜力。然而，当前LLMs在AIOps任务中的性能尚未确定。此外，需要一个全面的基准测试来引导针对AIOps定制的LLMs的优化。与现有的专注于评估网络配置等特定领域的基准测试不同，本文提出了OpsEval，这是一个专为LLMs设计的全面任务导向的AIOps基准测试。OpsEval首次对LLMs在三个关键场景（有线网络操作、5G通信操作和数据库操作）以及不同的能力水平（知识回忆、分析思考）进行评估。",
    "tldr": "OpsEval是一个全面任务导向的AIOps基准测试，评估了大型语言模型在有线网络操作、5G通信操作和数据库操作等关键场景下的能力水平，为提供针对AIOps定制的LLMs的优化方向。"
}