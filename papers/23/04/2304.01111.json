{
    "title": "Theoretical guarantees for neural control variates in MCMC. (arXiv:2304.01111v1 [math.ST])",
    "abstract": "In this paper, we propose a variance reduction approach for Markov chains based on additive control variates and the minimization of an appropriate estimate for the asymptotic variance. We focus on the particular case when control variates are represented as deep neural networks. We derive the optimal convergence rate of the asymptotic variance under various ergodicity assumptions on the underlying Markov chain. The proposed approach relies upon recent results on the stochastic errors of variance reduction algorithms and function approximation theory.",
    "link": "http://arxiv.org/abs/2304.01111",
    "context": "Title: Theoretical guarantees for neural control variates in MCMC. (arXiv:2304.01111v1 [math.ST])\nAbstract: In this paper, we propose a variance reduction approach for Markov chains based on additive control variates and the minimization of an appropriate estimate for the asymptotic variance. We focus on the particular case when control variates are represented as deep neural networks. We derive the optimal convergence rate of the asymptotic variance under various ergodicity assumptions on the underlying Markov chain. The proposed approach relies upon recent results on the stochastic errors of variance reduction algorithms and function approximation theory.",
    "path": "papers/23/04/2304.01111.json",
    "total_tokens": 620,
    "translated_title": "神经控制变量在MCMC中的理论保证",
    "translated_abstract": "本文提出了一种基于加性控制变量和最小化渐近方差的马尔可夫链方差缩减方法。我们专注于控制变量表示为深度神经网络的特定情况。在基础马尔可夫链的各种遍历性假设下，推导了渐近方差的最优收敛速率。该方法依赖于方差缩减算法和函数逼近理论的随机误差的最新成果。",
    "tldr": "本文提出了一种利用神经控制变量的方差缩减方法，推导并得出了在各种遍历性假设下渐近方差的最优收敛速率。",
    "en_tdlr": "This paper proposes a variance reduction approach using neural control variates and derives the optimal convergence rate of asymptotic variance under various ergodicity assumptions on the underlying Markov chain."
}