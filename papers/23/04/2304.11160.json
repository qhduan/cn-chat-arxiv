{
    "title": "The Isotonic Mechanism for Exponential Family Estimation. (arXiv:2304.11160v1 [math.ST])",
    "abstract": "In 2023, the International Conference on Machine Learning (ICML) required authors with multiple submissions to rank their submissions based on perceived quality. In this paper, we aim to employ these author-specified rankings to enhance peer review in machine learning and artificial intelligence conferences by extending the Isotonic Mechanism (Su, 2021, 2022) to exponential family distributions. This mechanism generates adjusted scores closely align with the original scores while adhering to author-specified rankings. Despite its applicability to a broad spectrum of exponential family distributions, this mechanism's implementation does not necessitate knowledge of the specific distribution form. We demonstrate that an author is incentivized to provide accurate rankings when her utility takes the form of a convex additive function of the adjusted review scores. For a certain subclass of exponential family distributions, we prove that the author reports truthfully only if the question in",
    "link": "http://arxiv.org/abs/2304.11160",
    "context": "Title: The Isotonic Mechanism for Exponential Family Estimation. (arXiv:2304.11160v1 [math.ST])\nAbstract: In 2023, the International Conference on Machine Learning (ICML) required authors with multiple submissions to rank their submissions based on perceived quality. In this paper, we aim to employ these author-specified rankings to enhance peer review in machine learning and artificial intelligence conferences by extending the Isotonic Mechanism (Su, 2021, 2022) to exponential family distributions. This mechanism generates adjusted scores closely align with the original scores while adhering to author-specified rankings. Despite its applicability to a broad spectrum of exponential family distributions, this mechanism's implementation does not necessitate knowledge of the specific distribution form. We demonstrate that an author is incentivized to provide accurate rankings when her utility takes the form of a convex additive function of the adjusted review scores. For a certain subclass of exponential family distributions, we prove that the author reports truthfully only if the question in",
    "path": "papers/23/04/2304.11160.json",
    "total_tokens": 748,
    "translated_title": "利用保序机制提高机器学习和人工智能会议的同行评审",
    "translated_abstract": "本文致力于扩展保序机制，将其应用于指数族分布以提高同行评审的质量。该机制可生成与原始评分接近的调整分数，并符合作者指定的排名要求，得到广泛的指数族分布应用，而且不需要知道具体的分布形式。研究表明，在一定的指数族分布下，如果作者的效用函数采用简单的凸可加函数，则激励作者提供准确的排名建议。",
    "tldr": "本文利用扩展的保序机制，将其应用于指数族分布以提高同行评审的质量，并发现作者的同行评分可以较准确地在不需要知道具体分布情况下进行调整。",
    "en_tdlr": "This paper extends the Isotonic Mechanism to exponential family distributions to enhance peer review in machine learning and artificial intelligence conferences, generating adjusted scores closely align with the original scores while adhering to author-specified rankings. The author's utility takes the form of a convex additive function of the adjusted review scores, incentivizing accurate rankings."
}