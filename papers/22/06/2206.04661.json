{
    "title": "Distillation Decision Tree. (arXiv:2206.04661v2 [stat.ME] UPDATED)",
    "abstract": "Machine learning models, particularly the black-box models, are widely favored for their outstanding predictive capabilities. However, they often face scrutiny and criticism due to the lack of interpretability. Paradoxically, their strong predictive capabilities suggest a deep understanding about the underlying data, implying significant potential for interpretation. Leveraging the emerging concept of knowledge distillation, we introduced the method of distillation decision tree (DDT). This method enables the distillation of knowledge about the data from a black-box model into a decision tree, thereby facilitating the interpretation of the black-box model. Constructed through the knowledge distillation process, the interpretability of DDT relies significantly on the stability of its structure. We establish the theoretical foundations for the structural stability of DDT, demonstrating that its structure can achieve stability under mild assumptions. Furthermore, we develop algorithms for",
    "link": "http://arxiv.org/abs/2206.04661",
    "context": "Title: Distillation Decision Tree. (arXiv:2206.04661v2 [stat.ME] UPDATED)\nAbstract: Machine learning models, particularly the black-box models, are widely favored for their outstanding predictive capabilities. However, they often face scrutiny and criticism due to the lack of interpretability. Paradoxically, their strong predictive capabilities suggest a deep understanding about the underlying data, implying significant potential for interpretation. Leveraging the emerging concept of knowledge distillation, we introduced the method of distillation decision tree (DDT). This method enables the distillation of knowledge about the data from a black-box model into a decision tree, thereby facilitating the interpretation of the black-box model. Constructed through the knowledge distillation process, the interpretability of DDT relies significantly on the stability of its structure. We establish the theoretical foundations for the structural stability of DDT, demonstrating that its structure can achieve stability under mild assumptions. Furthermore, we develop algorithms for",
    "path": "papers/22/06/2206.04661.json",
    "total_tokens": 819,
    "translated_title": "精馏决策树",
    "translated_abstract": "机器学习模型，特别是黑盒模型，因其出色的预测能力而受到广泛青睐。然而，由于缺乏可解释性，它们经常面临批评和挑战。矛盾的是，它们强大的预测能力表明对底层数据有深入的理解，从而意味着重要的解释潜力。借助知识精馏的新概念，我们引入了精馏决策树（DDT）的方法。该方法将关于数据的知识从黑盒模型精馏到决策树中，从而促进了对黑盒模型的解释。通过知识精馏过程构建的DDT的可解释性在很大程度上依赖于其结构的稳定性。我们为DDT的结构稳定性建立了理论基础，证明其在一些假设下可以实现结构稳定性。此外，我们还开发了算法用于...",
    "tldr": "精馏决策树（DDT）是一种通过将黑盒模型中的知识精馏到决策树中来促进解释性的方法。该方法建立在知识精馏的理论基础上，并且在结构稳定性的条件下可以有效实现。"
}