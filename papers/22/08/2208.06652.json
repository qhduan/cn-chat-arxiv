{
    "title": "Differentiable Inductive Logic Programming in High-Dimensional Space. (arXiv:2208.06652v2 [cs.AI] UPDATED)",
    "abstract": "Synthesizing large logic programs through symbolic Inductive Logic Programming (ILP) typically requires intermediate definitions. However, cluttering the hypothesis space with intensional predicates typically degrades performance. In contrast, gradient descent provides an efficient way to find solutions within such high- dimensional spaces. Neuro-symbolic ILP approaches have not fully exploited this so far. We propose extending the {\\delta}ILP approach to inductive synthesis with large-scale predicate invention, thus allowing us to exploit the efficacy of high-dimensional gradient descent. We show that large-scale predicate invention benefits differentiable inductive synthesis through gradient descent and allows one to learn solutions for tasks beyond the capabilities of existing neuro-symbolic ILP systems. Furthermore, we achieve these results without specifying the precise structure of the solution within the language bias.",
    "link": "http://arxiv.org/abs/2208.06652",
    "context": "Title: Differentiable Inductive Logic Programming in High-Dimensional Space. (arXiv:2208.06652v2 [cs.AI] UPDATED)\nAbstract: Synthesizing large logic programs through symbolic Inductive Logic Programming (ILP) typically requires intermediate definitions. However, cluttering the hypothesis space with intensional predicates typically degrades performance. In contrast, gradient descent provides an efficient way to find solutions within such high- dimensional spaces. Neuro-symbolic ILP approaches have not fully exploited this so far. We propose extending the {\\delta}ILP approach to inductive synthesis with large-scale predicate invention, thus allowing us to exploit the efficacy of high-dimensional gradient descent. We show that large-scale predicate invention benefits differentiable inductive synthesis through gradient descent and allows one to learn solutions for tasks beyond the capabilities of existing neuro-symbolic ILP systems. Furthermore, we achieve these results without specifying the precise structure of the solution within the language bias.",
    "path": "papers/22/08/2208.06652.json",
    "total_tokens": 882,
    "translated_title": "高维空间中可微归纳逻辑编程",
    "translated_abstract": "通过符号归纳逻辑编程（ILP）合成大型逻辑程序通常需要中间定义。然而，使用内涵谓词杂乱地占据假设空间通常会降低性能。相反，梯度下降提供了在这些高维空间中寻找解决方案的有效方法。到目前为止，神经符号ILP方法并没有充分利用这一点。我们提出扩展{\\delta}ILP方法，以进行大规模谓词发明的归纳合成，从而允许我们利用高维梯度下降的效能。我们展示了大规模谓词发明通过梯度下降受益于可微归纳合成，并允许我们学习超出现有神经符号ILP系统能力的任务的解决方案。此外，我们在不指定解决方案的精确结构的语言偏差的情况下实现了这些结果。",
    "tldr": "本研究提出了一种在高维空间中进行可微归纳逻辑编程的扩展方法，通过大规模谓词发明来充分利用高维梯度下降的效能，以学习超出现有神经符号ILP系统能力的任务的解决方案。"
}