# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Establishing trust in automated reasoning.](http://arxiv.org/abs/2309.12351) | 本研究探讨了自动推理系统的可审查性和可信度问题，并提出了通过技术和社会措施相结合的方式来增加信任的可能步骤。 |

# 详细

[^1]: 在自动推理中建立信任

    Establishing trust in automated reasoning. (arXiv:2309.12351v1 [cs.CY])

    [http://arxiv.org/abs/2309.12351](http://arxiv.org/abs/2309.12351)

    本研究探讨了自动推理系统的可审查性和可信度问题，并提出了通过技术和社会措施相结合的方式来增加信任的可能步骤。

    

    自从上世纪40年代开始，计算机的自动推理已经成为科学研究中日益重要的工具。迄今为止，自动推理的规则主要由人类以程序源代码的形式制定。通过机器学习技术从大量数据中得出的规则是一种互补的方法，目前正在积极发展中。为什么我们应该信任这些系统以及与其帮助下获得的结果的问题，已经被科学哲学家们讨论过，但从实践者那里收到的关注还很少。本研究重点关注独立审查，这是科学中的一个重要信任来源，并确定影响其可审查性的自动推理系统的特性。它还讨论了通过技术和社会措施相结合来增加可审查性和可信度的可能步骤。

    Since its beginnings in the 1940s, automated reasoning by computers has become a tool of ever growing importance in scientific research. So far, the rules underlying automated reasoning have mainly been formulated by humans, in the form of program source code. Rules derived from large amounts of data, via machine learning techniques, are a complementary approach currently under intense development. The question of why we should trust these systems, and the results obtained with their help, has been discussed by philosophers of science but has so far received little attention by practitioners. The present work focuses on independent reviewing, an important source of trust in science, and identifies the characteristics of automated reasoning systems that affect their reviewability. It also discusses possible steps towards increasing reviewability and trustworthiness via a combination of technical and social measures.
    

