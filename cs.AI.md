# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Query Performance Prediction using Relevance Judgments Generated by Large Language Models](https://arxiv.org/abs/2404.01012) | 提出了一种使用自动生成的相关性判断的查询性能预测框架，能够解决先前方法中对不同IR评估指标准确性和解释性的限制。 |
| [^2] | [TG-NAS: Leveraging Zero-Cost Proxies with Transformer and Graph Convolution Networks for Efficient Neural Architecture Search](https://arxiv.org/abs/2404.00271) | TG-NAS提出了一种新型模型通用代理，利用Transformer的运算符嵌入生成器和图卷积网络来预测架构性能，指导神经结构搜索。 |
| [^3] | [SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly Network](https://arxiv.org/abs/2403.18195) | 介绍了单步组装错误校正任务和LEGO错误校正组装数据集（LEGO-ECA），提出了用于这一任务的自校正组装网络（SCANet）。 |
| [^4] | [Enabling Uncertainty Estimation in Iterative Neural Networks](https://arxiv.org/abs/2403.16732) | 迭代神经网络中的新方法利用连续输出的收敛速率作为不确定性的有用代理，提供了比集成方法更低计算成本的先进不确定性估计。 |
| [^5] | [Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy](https://arxiv.org/abs/2403.16591) | 论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。 |
| [^6] | [Abstracting Sparse DNN Acceleration via Structured Sparse Tensor Decomposition](https://arxiv.org/abs/2403.07953) | 本文提出了通过结构化分解张量进一步抽象稀疏DNN加速的方法，实现了将稀疏张量转换成一系列结构化稀疏张量，从而弥合了稀疏DNN模型和硬件之间的差距。 |
| [^7] | [QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations](https://arxiv.org/abs/2402.17516) | QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。 |
| [^8] | [Comprehensive Assessment of Jailbreak Attacks Against LLMs](https://arxiv.org/abs/2402.05668) | 对大型语言模型（LLMs）的越狱攻击进行了全面的评估，揭示了一种绕过安全措施的不稳定漏洞。本研究是首次对多种越狱攻击方法进行大规模测量，实验证明优化的越狱提示能够持续达到最高的攻击成功率。 |
| [^9] | [Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways](https://arxiv.org/abs/2402.04420) | 通过调查研究和实验研究，本文研究了机器学习错误对人们的影响，发现强化刻板印象的错误引起更多主观上的伤害体验，而违反刻板印象的错误对男性产生更大的主观上的伤害，有助于我们理解机器学习在引发刻板印象和伤害方面的作用。 |
| [^10] | [FERGI: Automatic Annotation of User Preferences for Text-to-Image Generation from Spontaneous Facial Expression Reaction](https://arxiv.org/abs/2312.03187) | 开发了一种从用户自发面部表情反应中自动注释用户对生成图像偏好的方法，发现多个面部动作单元与用户对生成图像的评估高度相关，可用于通过这些面部动作单元区分图像对并自动标注用户偏好。 |
| [^11] | [Distributional Reinforcement Learning with Dual Expectile-Quantile Regression](https://arxiv.org/abs/2305.16877) | 提出了一种用双期望分位回归的分布式强化学习方法，能够更高效地学习任意回报分布 |
| [^12] | [Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model.](http://arxiv.org/abs/2401.15210) | Roq是一个基于风险感知学习方法的综合框架，用于实现鲁棒的查询优化。 |
| [^13] | [Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice.](http://arxiv.org/abs/2311.07745) | 本研究在解决具有高维度和连续观测的部分可观测马尔可夫决策过程中，提出了一种基于统计总变差距离的新型概率界限，能够简化观测模型并保证解决方案的质量。 |
| [^14] | [On Continuity of Robust and Accurate Classifiers.](http://arxiv.org/abs/2309.17048) | 本文研究了稳健和准确分类器的连续性，提出了当假设连续时，其稳健性和准确性是不兼容的观点。 |
| [^15] | [Joint Communication and Computation Framework for Goal-Oriented Semantic Communication with Distortion Rate Resilience.](http://arxiv.org/abs/2309.14587) | 本论文提出了一个创新的联合通信和计算框架，利用率畸变理论来分析通信和语义压缩引起的畸变，从而评估其对目标导向语义通信中人工智能模型性能的影响，使目标导向语义通信问题成为可能。 |
| [^16] | [Natural revision is contingently-conditionalized revision.](http://arxiv.org/abs/2309.12655) | 自然修正是一种有条件的修正方式，它尽可能少地改变信念来融入新信息，并将修正限制在当前条件下。 |
| [^17] | [A Comprehensive Survey of Artificial Intelligence Techniques for Talent Analytics.](http://arxiv.org/abs/2307.03195) | 这篇论文综述了人工智能技术在人才分析中的应用。通过使用大数据和人工智能技术，组织可以从数据科学的角度理解组织行为并实时做出决策，为有效的人才管理提供智能支持。 |
| [^18] | [Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems.](http://arxiv.org/abs/2305.02251) | 本文调研了自动化科学发现，介绍了各种方法和最近的话题，并概述了闭环科学发现系统和自主发现系统，其中最大级别不需要任何人类干预。该研究旨在发展能够产生诺贝尔级成果的AI科学家。 |

# 详细

[^1]: 使用大型语言模型生成的相关性判断来预测查询性能

    Query Performance Prediction using Relevance Judgments Generated by Large Language Models

    [https://arxiv.org/abs/2404.01012](https://arxiv.org/abs/2404.01012)

    提出了一种使用自动生成的相关性判断的查询性能预测框架，能够解决先前方法中对不同IR评估指标准确性和解释性的限制。

    

    查询性能预测（QPP）旨在估计搜索系统对查询的检索质量，而无需人工相关性判断。先前的QPP方法通常返回单个标量值，并不要求预测值接近特定的信息检索（IR）评估指标，从而导致以下某些缺点：（i）单个标量无法准确表示不同的IR评估指标，特别是当度量不高度相关时，（ii）单个标量限制了QPP方法的可解释性，因为仅使用标量无法解释QPP结果。为解决这些问题，我们提出了一个使用自动生成的相关性判断的QPP框架（QPP-GenRE），将QPP分解为独立的子任务，即对排名列表中每个项目对给定查询的相关性进行判断。这样我们可以使用生成的相关性判断来预测任何IR评估指标。

    arXiv:2404.01012v1 Announce Type: cross  Abstract: Query performance prediction (QPP) aims to estimate the retrieval quality of a search system for a query without human relevance judgments. Previous QPP methods typically return a single scalar value and do not require the predicted values to approximate a specific information retrieval (IR) evaluation measure, leading to certain drawbacks: (i) a single scalar is insufficient to accurately represent different IR evaluation measures, especially when metrics do not highly correlate, and (ii) a single scalar limits the interpretability of QPP methods because solely using a scalar is insufficient to explain QPP results. To address these issues, we propose a QPP framework using automatically generated relevance judgments (QPP-GenRE), which decomposes QPP into independent subtasks of judging the relevance of each item in a ranked list to a given query. This allows us to predict any IR evaluation measure using the generated relevance judgment
    
[^2]: TG-NAS：利用Transformer和图卷积网络与零成本代理进行高效神经结构搜索

    TG-NAS: Leveraging Zero-Cost Proxies with Transformer and Graph Convolution Networks for Efficient Neural Architecture Search

    [https://arxiv.org/abs/2404.00271](https://arxiv.org/abs/2404.00271)

    TG-NAS提出了一种新型模型通用代理，利用Transformer的运算符嵌入生成器和图卷积网络来预测架构性能，指导神经结构搜索。

    

    神经结构搜索(NAS)是一种发现新的卷积神经网络(CNN)架构的有效方法。然而，现有方法通常需要耗时的训练或密集的采样和评估。零成本NAS旨在为架构性能预测创建免训练代理。然而，现有代理性能亚优，并且常常被模型参数数量或浮点运算次数等简单指标所超越。此外，现有基于模型的代理无法将泛化到新的搜索空间，其中具有未见新类型运算符且不带有黄金准确度。一个普遍最优的代理仍然难以找到。我们引入了TG-NAS，一种利用基于Transformer的运算符嵌入生成器和图卷积网络(GCN)来预测架构性能的新型模型通用代理。这种方法指导着在任何给定搜索空间内进行神经结构搜索。

    arXiv:2404.00271v1 Announce Type: cross  Abstract: Neural architecture search (NAS) is an effective method for discovering new convolutional neural network (CNN) architectures. However, existing approaches often require time-consuming training or intensive sampling and evaluations. Zero-shot NAS aims to create training-free proxies for architecture performance prediction. However, existing proxies have suboptimal performance, and are often outperformed by simple metrics such as model parameter counts or the number of floating-point operations. Besides, existing model-based proxies cannot be generalized to new search spaces with unseen new types of operators without golden accuracy truth. A universally optimal proxy remains elusive. We introduce TG-NAS, a novel model-based universal proxy that leverages a transformer-based operator embedding generator and a graph convolution network (GCN) to predict architecture performance. This approach guides neural architecture search across any giv
    
[^3]: 用自校正组装网络纠正LEGO组装错误

    SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly Network

    [https://arxiv.org/abs/2403.18195](https://arxiv.org/abs/2403.18195)

    介绍了单步组装错误校正任务和LEGO错误校正组装数据集（LEGO-ECA），提出了用于这一任务的自校正组装网络（SCANet）。

    

    在机器人学和3D视觉中，自主组装面临着重大挑战，尤其是确保组装正确性。主流方法如MEPNet目前专注于基于手动提供的图像进行组件组装。然而，这些方法在需要长期规划的任务中往往难以取得满意的结果。在同一时间，我们观察到整合自校正模块可以在一定程度上缓解这些问题。受此问题启发，我们引入了单步组装错误校正任务，其中涉及识别和纠正组件组装错误。为支持这一领域的研究，我们提出了LEGO错误校正组装数据集（LEGO-ECA），包括用于组装步骤和组装失败实例的手动图像。此外，我们提出了自校正组装网络（SCANet），这是一种新颖的方法来解决这一任务。SCANet将组装的部件视为查询，

    arXiv:2403.18195v1 Announce Type: cross  Abstract: Autonomous assembly in robotics and 3D vision presents significant challenges, particularly in ensuring assembly correctness. Presently, predominant methods such as MEPNet focus on assembling components based on manually provided images. However, these approaches often fall short in achieving satisfactory results for tasks requiring long-term planning. Concurrently, we observe that integrating a self-correction module can partially alleviate such issues. Motivated by this concern, we introduce the single-step assembly error correction task, which involves identifying and rectifying misassembled components. To support research in this area, we present the LEGO Error Correction Assembly Dataset (LEGO-ECA), comprising manual images for assembly steps and instances of assembly failures. Additionally, we propose the Self-Correct Assembly Network (SCANet), a novel method to address this task. SCANet treats assembled components as queries, de
    
[^4]: 在迭代神经网络中实现不确定性估计

    Enabling Uncertainty Estimation in Iterative Neural Networks

    [https://arxiv.org/abs/2403.16732](https://arxiv.org/abs/2403.16732)

    迭代神经网络中的新方法利用连续输出的收敛速率作为不确定性的有用代理，提供了比集成方法更低计算成本的先进不确定性估计。

    

    将传递网络架构转变为迭代网络架构，迭代网络使用自身的输出作为输入，这是一种提升性能的众所周知的方法。本文认为这种架构还提供了额外的好处：连续输出的收敛速率与其收敛值的准确性高度相关。因此，我们可以将收敛速率用作不确定性的有用代理。这导致了一种不确定性估计方法，以比诸如集成方法更低的计算成本提供了最先进的估计，而且不需要对原始迭代模型进行任何修改。我们通过将其嵌入到两个应用领域中来展示其实用价值：航空图像中的道路检测和二维和三维形状的空气动力特性估计。

    arXiv:2403.16732v1 Announce Type: new  Abstract: Turning pass-through network architectures into iterative ones, which use their own output as input, is a well-known approach for boosting performance. In this paper, we argue that such architectures offer an additional benefit: The convergence rate of their successive outputs is highly correlated with the accuracy of the value to which they converge. Thus, we can use the convergence rate as a useful proxy for uncertainty. This results in an approach to uncertainty estimation that provides state-of-the-art estimates at a much lower computational cost than techniques like Ensembles, and without requiring any modifications to the original iterative model. We demonstrate its practical value by embedding it in two application domains: road detection in aerial images and the estimation of aerodynamic properties of 2D and 3D shapes.
    
[^5]: 揭示本地差分隐私、平均贝叶斯隐私和最大贝叶斯隐私之间的相互作用

    Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy

    [https://arxiv.org/abs/2403.16591](https://arxiv.org/abs/2403.16591)

    论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。

    

    机器学习的迅速发展导致了隐私定义的多样化，由于对隐私构成的威胁，包括本地差分隐私（LDP）的概念。虽然被广泛接受并在许多领域中被利用，但这种传统的隐私测量方法仍然存在一定限制，从无法防止推断披露到缺乏对对手背景知识的考虑。在这项全面研究中，我们引入贝叶斯隐私并深入探讨本地差分隐私和其贝叶斯对应物之间错综复杂的关系，揭示了关于效用-隐私权衡的新见解。我们引入了一个框架，概括了攻击和防御策略，突出它们之间的相互作用和效果。我们的理论贡献基于平均贝叶斯隐私（ABP）和最大贝叶斯隐私之间的严格定义和关系。

    arXiv:2403.16591v1 Announce Type: cross  Abstract: The swift evolution of machine learning has led to emergence of various definitions of privacy due to the threats it poses to privacy, including the concept of local differential privacy (LDP). Although widely embraced and utilized across numerous domains, this conventional approach to measure privacy still exhibits certain limitations, spanning from failure to prevent inferential disclosure to lack of consideration for the adversary's background knowledge. In this comprehensive study, we introduce Bayesian privacy and delve into the intricate relationship between local differential privacy and its Bayesian counterparts, unveiling novel insights into utility-privacy trade-offs. We introduce a framework that encapsulates both attack and defense strategies, highlighting their interplay and effectiveness. Our theoretical contributions are anchored in the rigorous definitions and relationships between Average Bayesian Privacy (ABP) and Max
    
[^6]: 通过结构化稀疏张量分解对稀疏DNN加速进行抽象化

    Abstracting Sparse DNN Acceleration via Structured Sparse Tensor Decomposition

    [https://arxiv.org/abs/2403.07953](https://arxiv.org/abs/2403.07953)

    本文提出了通过结构化分解张量进一步抽象稀疏DNN加速的方法，实现了将稀疏张量转换成一系列结构化稀疏张量，从而弥合了稀疏DNN模型和硬件之间的差距。

    

    在深度神经网络（DNNs）中利用稀疏性已成为满足现代DNN日益增长的计算需求的一种具有前景的领域。然而，在实践中，稀疏DNN加速仍然面临一个关键挑战。为了最小化稀疏加速的开销，硬件设计师最近提出了结构化稀疏硬件支持，这提供了有限的灵活性并需要额外的模型微调。此外，为某些结构化稀疏硬件微调的任何稀疏模型无法被其他结构化硬件加速。为了弥合稀疏DNN模型和硬件之间的差距，本文提出了通过结构分解的张量近似（TASD），利用了线性代数中的分配性质将任何稀疏张量转化为一系列结构化稀疏张量。接下来，我们开发了一个软件框架TASDER，通过搜索逐层高质量的结构化分解来加速DNNs的权重和...

    arXiv:2403.07953v1 Announce Type: cross  Abstract: Exploiting sparsity in deep neural networks (DNNs) has been a promising area to meet the growing computation need of modern DNNs. However, in practice, sparse DNN acceleration still faces a key challenge. To minimize the overhead of sparse acceleration, hardware designers have proposed structured sparse hardware support recently, which provides limited flexibility and requires extra model fine-tuning. Moreover, any sparse model fine-tuned for certain structured sparse hardware cannot be accelerated by other structured hardware. To bridge the gap between sparse DNN models and hardware, this paper proposes tensor approximation via structured decomposition (TASD), which leverages the distributive property in linear algebra to turn any sparse tensor into a series of structured sparse tensors. Next, we develop a software framework, TASDER, to accelerate DNNs by searching layer-wise, high-quality structured decomposition for both weight and 
    
[^7]: QUCE: 减少和量化基于路径的不确定性以生成对抗性反事实解释

    QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations

    [https://arxiv.org/abs/2402.17516](https://arxiv.org/abs/2402.17516)

    QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。

    

    arXiv:2402.17516v1 公告类型：跨学科 深度神经网络（DNNs）作为机器学习领域最突出的方法之一。DNNs的有效性随着最近计算能力的增加而激增，使得这些方法能够扩展到处理大数据中的重要复杂性以应对预测挑战。然而，随着DNN模型复杂性的提高，可解释性降低。针对这一挑战，诸如对抗梯度整合（AGI）这样的可解释模型利用DNN提供的基于路径的梯度来阐明它们的决策。然而，当梯度在越界路径遍历期间表现出不规则性时，基于路径的解释器的性能可能会受到损害。在这种情况下，我们介绍了Quantified Uncertainty Counterfactual Explanations（QUCE），这是一种旨在减少路径不确定性的方法，以缓解越界遍历。 QUCE不仅在提出解释时量化不确定性

    arXiv:2402.17516v1 Announce Type: cross  Abstract: Deep Neural Networks (DNNs) stand out as one of the most prominent approaches within the Machine Learning (ML) domain. The efficacy of DNNs has surged alongside recent increases in computational capacity, allowing these approaches to scale to significant complexities for addressing predictive challenges in big data. However, as the complexity of DNN models rises, interpretability diminishes. In response to this challenge, explainable models such as Adversarial Gradient Integration (AGI) leverage path-based gradients provided by DNNs to elucidate their decisions. Yet the performance of path-based explainers can be compromised when gradients exhibit irregularities during out-of-distribution path traversal. In this context, we introduce Quantified Uncertainty Counterfactual Explanations (QUCE), a method designed to mitigate out-of-distribution traversal by minimizing path uncertainty. QUCE not only quantifies uncertainty when presenting e
    
[^8]: 对LLMs的越狱攻击的综合评估

    Comprehensive Assessment of Jailbreak Attacks Against LLMs

    [https://arxiv.org/abs/2402.05668](https://arxiv.org/abs/2402.05668)

    对大型语言模型（LLMs）的越狱攻击进行了全面的评估，揭示了一种绕过安全措施的不稳定漏洞。本研究是首次对多种越狱攻击方法进行大规模测量，实验证明优化的越狱提示能够持续达到最高的攻击成功率。

    

    对大型语言模型（LLMs）的滥用引起了广泛关注。为了解决这个问题，已经采取了安全措施以确保LLMs符合社会伦理。然而，最近的研究发现了一种绕过LLMs安全措施的不稳定漏洞，被称为越狱攻击。通过应用技术，如角色扮演场景、对抗性样本或对安全目标的微妙破坏作为提示，LLMs可以产生不适当甚至有害的回应。虽然研究人员已经研究了几种越狱攻击的类别，但他们都是孤立地进行的。为了填补这个空白，我们提出了对各种越狱攻击方法的首次大规模测量。我们集中在来自四个类别的13种尖端越狱方法、16种违规类别的160个问题以及六种流行的LLMs上。我们广泛的实验结果表明，优化的越狱提示始终能够达到最高的攻击成功率，并表现出...

    Misuse of the Large Language Models (LLMs) has raised widespread concern. To address this issue, safeguards have been taken to ensure that LLMs align with social ethics. However, recent findings have revealed an unsettling vulnerability bypassing the safeguards of LLMs, known as jailbreak attacks. By applying techniques, such as employing role-playing scenarios, adversarial examples, or subtle subversion of safety objectives as a prompt, LLMs can produce an inappropriate or even harmful response. While researchers have studied several categories of jailbreak attacks, they have done so in isolation. To fill this gap, we present the first large-scale measurement of various jailbreak attack methods. We concentrate on 13 cutting-edge jailbreak methods from four categories, 160 questions from 16 violation categories, and six popular LLMs. Our extensive experimental results demonstrate that the optimized jailbreak prompts consistently achieve the highest attack success rates, as well as exhi
    
[^9]: 测量机器学习中的刻板印象伤害：需要了解谁正在受到哪些错误以及以何种方式受到伤害

    Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways

    [https://arxiv.org/abs/2402.04420](https://arxiv.org/abs/2402.04420)

    通过调查研究和实验研究，本文研究了机器学习错误对人们的影响，发现强化刻板印象的错误引起更多主观上的伤害体验，而违反刻板印象的错误对男性产生更大的主观上的伤害，有助于我们理解机器学习在引发刻板印象和伤害方面的作用。

    

    随着机器学习应用的普及，我们需要了解它们可能造成的伤害。然而，当前的公平性指标很少基于人类对伤害的心理体验。借鉴刻板印象的社会心理学，我们以图像搜索中的性别刻板印象为案例研究，研究了人们对机器学习错误的反应。首先，我们使用调查研究表明，并非所有的机器学习错误都反映了刻板印象，也没有同样的伤害程度。然后，在实验研究中，我们随机使参与者接触到强化、违反和中性的机器学习错误。我们发现，强化刻板印象的错误引起更多主观上的伤害体验，但对认知信念、态度或行为的改变很小。这种体验上的伤害对女性影响更大。然而，某些违反刻板印象的错误对男性产生更大的主观上的伤害，可能是由于对男性阳刚性的威胁感知。

    As machine learning applications proliferate, we need an understanding of their potential for harm. However, current fairness metrics are rarely grounded in human psychological experiences of harm. Drawing on the social psychology of stereotypes, we use a case study of gender stereotypes in image search to examine how people react to machine learning errors. First, we use survey studies to show that not all machine learning errors reflect stereotypes nor are equally harmful. Then, in experimental studies we randomly expose participants to stereotype-reinforcing, -violating, and -neutral machine learning errors. We find stereotype-reinforcing errors induce more experientially (i.e., subjectively) harmful experiences, while having minimal changes to cognitive beliefs, attitudes, or behaviors. This experiential harm impacts women more than men. However, certain stereotype-violating errors are more experientially harmful for men, potentially due to perceived threats to masculinity. We conc
    
[^10]: FERGI：来自自发面部表情反应的文本到图像生成用户偏好的自动注释

    FERGI: Automatic Annotation of User Preferences for Text-to-Image Generation from Spontaneous Facial Expression Reaction

    [https://arxiv.org/abs/2312.03187](https://arxiv.org/abs/2312.03187)

    开发了一种从用户自发面部表情反应中自动注释用户对生成图像偏好的方法，发现多个面部动作单元与用户对生成图像的评估高度相关，可用于通过这些面部动作单元区分图像对并自动标注用户偏好。

    

    研究人员提出使用人类偏好反馈数据来微调文本到图像生成模型。然而，由于其依赖于手动注释，人类反馈收集的可扩展性受到限制。因此，我们开发并测试了一种方法，从用户的自发面部表情反应中自动注释其对生成图像的偏好。我们收集了一个面部表情反应到生成图像（FERGI）的数据集，并展示了多个面部运动单元（AUs）的激活与用户对生成图像的评估高度相关。具体来说，AU4（眉毛下垂者）反映了对生成图像的负面评价，而AU12（嘴角拉动者）反映了正面评价。这两者在两个方面都很有用。首先，我们可以准确地使用这些AU响应存在实质差异的图像对之间自动注释用户偏好。

    arXiv:2312.03187v2 Announce Type: replace-cross  Abstract: Researchers have proposed to use data of human preference feedback to fine-tune text-to-image generative models. However, the scalability of human feedback collection has been limited by its reliance on manual annotation. Therefore, we develop and test a method to automatically annotate user preferences from their spontaneous facial expression reaction to the generated images. We collect a dataset of Facial Expression Reaction to Generated Images (FERGI) and show that the activations of multiple facial action units (AUs) are highly correlated with user evaluations of the generated images. Specifically, AU4 (brow lowerer) is reflective of negative evaluations of the generated image whereas AU12 (lip corner puller) is reflective of positive evaluations. These can be useful in two ways. Firstly, we can automatically annotate user preferences between image pairs with substantial difference in these AU responses with an accuracy sig
    
[^11]: 用双期望分位回归的分布式强化学习

    Distributional Reinforcement Learning with Dual Expectile-Quantile Regression

    [https://arxiv.org/abs/2305.16877](https://arxiv.org/abs/2305.16877)

    提出了一种用双期望分位回归的分布式强化学习方法，能够更高效地学习任意回报分布

    

    分布式强化学习（RL）已经在多个基准测试中证明其有效性，因为它可以近似整个回报分布，并更好地利用环境样本。常用的基于不对称$L_1$损失的分布式RL的分位回归方法提供了一种灵活而有效的学习任意回报分布的方式。在实践中，通过使用更高效的混合不对称$L_1$-$L_2$ Huber损失来改进往往会提高性能。然而，通过这样做，分布估计保证消失了，我们实证观察到估计的分布会迅速收敛到其均值。事实上，与期望回归相对应的不对称$L_2$损失不能直接用于分布式时序差异学习。受到$L_2$为基础学习效率的启发，我们提出了联合学习回报分布的期望值和分位数的方法。

    arXiv:2305.16877v2 Announce Type: replace-cross  Abstract: Distributional reinforcement learning (RL) has proven useful in multiple benchmarks as it enables approximating the full distribution of returns and makes a better use of environment samples. The commonly used quantile regression approach to distributional RL -- based on asymmetric $L_1$ losses -- provides a flexible and effective way of learning arbitrary return distributions. In practice, it is often improved by using a more efficient, hybrid asymmetric $L_1$-$L_2$ Huber loss for quantile regression. However, by doing so, distributional estimation guarantees vanish, and we empirically observe that the estimated distribution rapidly collapses to its mean. Indeed, asymmetric $L_2$ losses, corresponding to expectile regression, cannot be readily used for distributional temporal difference learning. Motivated by the efficiency of $L_2$-based learning, we propose to jointly learn expectiles and quantiles of the return distribution
    
[^12]: Roq：基于风险感知学习成本模型的鲁棒查询优化

    Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model. (arXiv:2401.15210v1 [cs.DB])

    [http://arxiv.org/abs/2401.15210](http://arxiv.org/abs/2401.15210)

    Roq是一个基于风险感知学习方法的综合框架，用于实现鲁棒的查询优化。

    

    关系数据库管理系统(RDBMS)中的查询优化器搜索预期对于给定查询最优的执行计划。它们使用参数估计，通常是不准确的，并且做出的假设在实践中可能不成立。因此，在这些估计和假设无效时，它们可能选择在运行时是次优的执行计划，这可能导致查询性能不佳。因此，查询优化器不足以支持鲁棒的查询优化。近年来，使用机器学习(ML)来提高数据系统的效率并减少其维护开销的兴趣日益高涨，在查询优化领域取得了有希望的结果。在本文中，受到这些进展的启发，并基于IBM Db2多年的经验，我们提出了Roq: 一种基于风险感知学习方法的综合框架，它实现了鲁棒的查询优化。

    Query optimizers in relational database management systems (RDBMSs) search for execution plans expected to be optimal for a given queries. They use parameter estimates, often inaccurate, and make assumptions that may not hold in practice. Consequently, they may select execution plans that are suboptimal at runtime, when these estimates and assumptions are not valid, which may result in poor query performance. Therefore, query optimizers do not sufficiently support robust query optimization. Recent years have seen a surge of interest in using machine learning (ML) to improve efficiency of data systems and reduce their maintenance overheads, with promising results obtained in the area of query optimization in particular. In this paper, inspired by these advancements, and based on several years of experience of IBM Db2 in this journey, we propose Robust Optimization of Queries, (Roq), a holistic framework that enables robust query optimization based on a risk-aware learning approach. Roq 
    
[^13]: 在具有概率保证和实践的连续POMDP规划中简化复杂的观测模型

    Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice. (arXiv:2311.07745v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.07745](http://arxiv.org/abs/2311.07745)

    本研究在解决具有高维度和连续观测的部分可观测马尔可夫决策过程中，提出了一种基于统计总变差距离的新型概率界限，能够简化观测模型并保证解决方案的质量。

    

    解决具有高维度和连续观测（如相机图像）的部分可观测马尔可夫决策过程(POMDP)对于许多实际机器人和规划问题是必需的。最近的研究建议使用机器学习的概率模型作为观测模型，但它们目前在线部署时计算成本过高。我们探讨了在规划中使用简化观测模型的影响，同时保持对解决方案质量的形式化保证。我们的主要贡献是一种基于简化模型的统计总变差距离的新型概率界限。我们证明，通过推广最近的粒子置信度MDP集中界限的结果，它将理论POMDP值与简化模型下的实际规划值进行了约束。我们的计算可以分为离线和在线部分，并且我们可以得到形式化的保证，而无需

    Solving partially observable Markov decision processes (POMDPs) with high dimensional and continuous observations, such as camera images, is required for many real life robotics and planning problems. Recent researches suggested machine learned probabilistic models as observation models, but their use is currently too computationally expensive for online deployment. We deal with the question of what would be the implication of using simplified observation models for planning, while retaining formal guarantees on the quality of the solution. Our main contribution is a novel probabilistic bound based on a statistical total variation distance of the simplified model. We show that it bounds the theoretical POMDP value w.r.t. original model, from the empirical planned value with the simplified model, by generalizing recent results of particle-belief MDP concentration bounds. Our calculations can be separated into offline and online parts, and we arrive at formal guarantees without having to
    
[^14]: 关于稳健和准确分类器连续性的研究

    On Continuity of Robust and Accurate Classifiers. (arXiv:2309.17048v1 [cs.LG])

    [http://arxiv.org/abs/2309.17048](http://arxiv.org/abs/2309.17048)

    本文研究了稳健和准确分类器的连续性，提出了当假设连续时，其稳健性和准确性是不兼容的观点。

    

    学习模型的可靠性是成功应用机器学习于各种领域的关键。创建一个稳健的模型，特别是一个不受对抗攻击影响的模型，需要全面理解对抗样本现象。然而，由于机器学习中问题的复杂性，很难描述这一现象。在文献中已经证明了对抗性训练可以提高假设的稳健性，但这种改进是以自然样本性能下降为代价的。因此，有人提出假设的稳健性和准确性是相互矛盾的。本文提出了另一种观点，假设的连续性与其稳健性和准确性是不兼容的。换句话说，连续函数不能有效地学习最佳稳健假设。为此，我们将引入一个系统研究谐波和ho的框架。

    The reliability of a learning model is key to the successful deployment of machine learning in various applications. Creating a robust model, particularly one unaffected by adversarial attacks, requires a comprehensive understanding of the adversarial examples phenomenon. However, it is difficult to describe the phenomenon due to the complicated nature of the problems in machine learning. It has been shown that adversarial training can improve the robustness of the hypothesis. However, this improvement comes at the cost of decreased performance on natural samples. Hence, it has been suggested that robustness and accuracy of a hypothesis are at odds with each other. In this paper, we put forth the alternative proposal that it is the continuity of a hypothesis that is incompatible with its robustness and accuracy. In other words, a continuous function cannot effectively learn the optimal robust hypothesis. To this end, we will introduce a framework for a rigorous study of harmonic and ho
    
[^15]: 目标导向语义通信的联合通信和计算框架，具有畸变率鲁棒性

    Joint Communication and Computation Framework for Goal-Oriented Semantic Communication with Distortion Rate Resilience. (arXiv:2309.14587v1 [cs.LG])

    [http://arxiv.org/abs/2309.14587](http://arxiv.org/abs/2309.14587)

    本论文提出了一个创新的联合通信和计算框架，利用率畸变理论来分析通信和语义压缩引起的畸变，从而评估其对目标导向语义通信中人工智能模型性能的影响，使目标导向语义通信问题成为可能。

    

    最近关于语义通信的研究主要考虑准确性作为优化目标导向通信系统的主要问题。然而，这些方法引入了一个悖论：人工智能任务的准确性应该通过训练自然地出现，而不是由网络约束所决定。鉴于这个困境，本文引入了一种创新的方法，利用率畸变理论来分析由通信和语义压缩引起的畸变，并分析学习过程。具体来说，我们研究了原始数据和畸变数据之间的分布偏移，从而评估其对人工智能模型性能的影响。基于这个分析，我们可以预先估计人工智能任务的实际准确性，使目标导向语义通信问题变得可行。为了实现这个目标，我们提出了我们方法的理论基础，并进行了模拟和实验。

    Recent research efforts on semantic communication have mostly considered accuracy as a main problem for optimizing goal-oriented communication systems. However, these approaches introduce a paradox: the accuracy of artificial intelligence (AI) tasks should naturally emerge through training rather than being dictated by network constraints. Acknowledging this dilemma, this work introduces an innovative approach that leverages the rate-distortion theory to analyze distortions induced by communication and semantic compression, thereby analyzing the learning process. Specifically, we examine the distribution shift between the original data and the distorted data, thus assessing its impact on the AI model's performance. Founding upon this analysis, we can preemptively estimate the empirical accuracy of AI tasks, making the goal-oriented semantic communication problem feasible. To achieve this objective, we present the theoretical foundation of our approach, accompanied by simulations and ex
    
[^16]: 自然修正是一种有条件的修正方式。

    Natural revision is contingently-conditionalized revision. (arXiv:2309.12655v1 [cs.AI])

    [http://arxiv.org/abs/2309.12655](http://arxiv.org/abs/2309.12655)

    自然修正是一种有条件的修正方式，它尽可能少地改变信念来融入新信息，并将修正限制在当前条件下。

    

    自然修正看起来很自然：它尽可能少地改变信念来融入新信息。然而，一些反例显示这是错误的。它非常保守，从不完全相信。它只在当前条件下相信。这在某些情况下是正确的，在其他情况下是错误的。哪种情况是哪种情况？回答这个问题需要将自然修正从表达普遍真理的简单公式（某物成立）扩展到表达条件真理的条件语句（某种情况下成立）。这种扩展基于自然修正遵循的基本原则，被确定为最小改变、漠不关心和天真：尽可能少地改变信念；默认情况下将场景的可能性视为相等；对所有情况持有信念，直到有矛盾发生。扩展表明自然修正将修正限制在当前条件下。与不受限制的修正进行比较可以确定当前条件。它不是当前被认为是真的，如果与新信息相矛盾的话。

    Natural revision seems so natural: it changes beliefs as little as possible to incorporate new information. Yet, some counterexamples show it wrong. It is so conservative that it never fully believes. It only believes in the current conditions. This is right in some cases and wrong in others. Which is which? The answer requires extending natural revision from simple formulae expressing universal truths (something holds) to conditionals expressing conditional truth (something holds in certain conditions). The extension is based on the basic principles natural revision follows, identified as minimal change, indifference and naivety: change beliefs as little as possible; equate the likeliness of scenarios by default; believe all until contradicted. The extension says that natural revision restricts changes to the current conditions. A comparison with an unrestricting revision shows what exactly the current conditions are. It is not what currently considered true if it contradicts the new 
    
[^17]: 人才分析的人工智能技术综述

    A Comprehensive Survey of Artificial Intelligence Techniques for Talent Analytics. (arXiv:2307.03195v1 [cs.CY])

    [http://arxiv.org/abs/2307.03195](http://arxiv.org/abs/2307.03195)

    这篇论文综述了人工智能技术在人才分析中的应用。通过使用大数据和人工智能技术，组织可以从数据科学的角度理解组织行为并实时做出决策，为有效的人才管理提供智能支持。

    

    在当今竞争激烈且快速发展的商业环境下，组织需要重新思考以量化方式做出人才相关决策的重要性。事实上，大数据和人工智能技术的最新发展已经彻底改变了人力资源管理。大规模人才和管理相关数据的可用性为企业领导者提供了从数据科学角度理解组织行为和获取实际知识的无与伦比机会，进而为实时决策和有效的人才管理提供智能支持。在过去的十年中，人才分析已经成为应用数据科学在人力资源管理方面的有希望的领域，引起了人工智能社区的广泛关注并激发了许多研究工作。为此，我们提供了一个最新、全面的关于人工智能技术在人才分析中的应用的综述。

    In today's competitive and fast-evolving business environment, it is a critical time for organizations to rethink how to make talent-related decisions in a quantitative manner. Indeed, the recent development of Big Data and Artificial Intelligence (AI) techniques have revolutionized human resource management. The availability of large-scale talent and management-related data provides unparalleled opportunities for business leaders to comprehend organizational behaviors and gain tangible knowledge from a data science perspective, which in turn delivers intelligence for real-time decision-making and effective talent management at work for their organizations. In the last decade, talent analytics has emerged as a promising field in applied data science for human resource management, garnering significant attention from AI communities and inspiring numerous research efforts. To this end, we present an up-to-date and comprehensive survey on AI technologies used for talent analytics in the f
    
[^18]: 自动化科学发现：从方程式探索到自主发现系统

    Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems. (arXiv:2305.02251v1 [cs.AI])

    [http://arxiv.org/abs/2305.02251](http://arxiv.org/abs/2305.02251)

    本文调研了自动化科学发现，介绍了各种方法和最近的话题，并概述了闭环科学发现系统和自主发现系统，其中最大级别不需要任何人类干预。该研究旨在发展能够产生诺贝尔级成果的AI科学家。

    

    本文调研了自动化科学发现，从方程式探索和符号回归到自主发现系统和代理。从“宏观”和上下文角度讨论了各种方法，但也讨论了开放问题和最近的话题，如深度神经网络在这个领域中的各种角色，帮助发现人类可解释的知识。此外，我们将介绍闭环科学发现系统，从Adam系统的开创性工作到当前在材料科学和天文学等领域的努力。最后，我们将从机器学习的角度详细阐述自主性，并以自动驾驶的自主级别为类比。最大级别，第五级，定义为在生产科学知识时不需要任何人类干预。实现这一点是迈向解决Nobel Turing Grand Challenge的一步：开发能够产生诺贝尔级科学成果的AI科学家 - 能力的一步。

    The paper surveys automated scientific discovery, from equation discovery and symbolic regression to autonomous discovery systems and agents. It discusses the individual approaches from a "big picture" perspective and in context, but also discusses open issues and recent topics like the various roles of deep neural networks in this area, aiding in the discovery of human-interpretable knowledge. Further, we will present closed-loop scientific discovery systems, starting with the pioneering work on the Adam system up to current efforts in fields from material science to astronomy. Finally, we will elaborate on autonomy from a machine learning perspective, but also in analogy to the autonomy levels in autonomous driving. The maximal level, level five, is defined to require no human intervention at all in the production of scientific knowledge. Achieving this is one step towards solving the Nobel Turing Grand Challenge to develop AI Scientists: AI systems capable of making Nobel-quality sc
    

