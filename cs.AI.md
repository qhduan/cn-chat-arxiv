# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generation and Detection of Sign Language Deepfakes - A Linguistic and Visual Analysis](https://arxiv.org/abs/2404.01438) | 通过在上半身生成手语深度伪造视频，并由手语专家审核，本研究探讨了在深度伪造技术中的积极应用，为聋哑和听障社区带来潜在的健康和教育益处。 |
| [^2] | [Enhanced Short Text Modeling: Leveraging Large Language Models for Topic Refinement](https://arxiv.org/abs/2403.17706) | 利用大型语言模型的先进能力，提出了一种名为“主题细化”的新方法，通过引入提示工程和消除离题词等方式改进短文本的主题建模质量，提高了主题的语义质量。 |
| [^3] | [Reasoning-Enhanced Object-Centric Learning for Videos](https://arxiv.org/abs/2403.15245) | 设计了一种新颖的推理模块STATM，利用记忆缓冲区增强模型在复杂场景中的感知能力。 |
| [^4] | [Threats, Attacks, and Defenses in Machine Unlearning: A Survey](https://arxiv.org/abs/2403.13682) | 机器遗忘（MU）通过知识去除过程来解决训练数据相关的人工智能治理问题，提高了AI系统的安全和负责任使用。 |
| [^5] | [Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey](https://arxiv.org/abs/2403.09606) | 大型语言模型的出现极大影响了自然语言处理领域，特别是通过其先进的推理能力。而本综述则重点评估和改进了大型语言模型在因果推断方面的应用，包括提高推理能力、解决公平和安全问题、提供解释和处理多模态。 |
| [^6] | [Large Language Models are Contrastive Reasoners](https://arxiv.org/abs/2403.08211) | 对比提示方法显著提高大型语言模型进行复杂推理的能力，不仅在算术、常识和符号推理任务上表现优良，还可以与现有提示方法整合，实现更好的性能。 |
| [^7] | [Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations](https://arxiv.org/abs/2403.07887) | 提出了神经槽解释器（NSI），通过槽表示学习接地和生成物体语义，实现了将现实世界的物体语义结合到抽象中。 |
| [^8] | [You Need to Pay Better Attention](https://arxiv.org/abs/2403.01643) | 提出了三种新的注意力机制，在效率和学习能力方面优于标准的多头注意力，提高了Transformer模型的性能和更广泛的部署能力。 |
| [^9] | [Bridging Causal Discovery and Large Language Models: A Comprehensive Survey of Integrative Approaches and Future Directions](https://arxiv.org/abs/2402.11068) | 本文综合调查了将大型语言模型（如GPT4）整合到因果发现任务中的方法，揭示了它们在推断因果结构时对元数据和自然语言的创新利用，强调了LLMs在增强传统CD方法和作为专家辅助方面的潜力和挑战。 |
| [^10] | [Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues](https://arxiv.org/abs/2402.01737) | 本文旨在开发LLM代理以减轻多代理设置下谈判中的社交规范违反。我们引入了基于价值影响的环境学习（ICL）方法，用于为基于LLM的修正代理识别高质量的ICL示例，其中价值影响函数衡量谈判结果的质量。我们展示了这种方法与策略学习的联系，并提供了丰富的实证证据来证明其在三个不同主题的谈判中的有效性。 |
| [^11] | [SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering](https://arxiv.org/abs/2401.17809) | 提出了一种主题词嵌入修改框架（SWEA），通过在推理阶段修改主题的表示来编辑知识，保护模型的原始权重，避免不可逆的损害和额外的推理开销。 |
| [^12] | [A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia](https://arxiv.org/abs/2312.02073) | 通过Fakepedia数据集研究语言模型的基础能力和进行因果中介分析，以解决上下文信息与存储知识相矛盾的问题。 |
| [^13] | [Stochastic Population Update Can Provably Be Helpful in Multi-Objective Evolutionary Algorithms](https://arxiv.org/abs/2306.02611) | 本研究通过理论分析证明，在多目标进化算法中采用随机种群更新机制可以显著降低算法的运行时间，从而提高问题的求解效率。 |
| [^14] | [ShaRP: Explaining Rankings with Shapley Values.](http://arxiv.org/abs/2401.16744) | ShaRP是一个基于Shapley值的框架，用于解释排名结果中各个特征的贡献。即使使用线性评分函数，特征的权重也不一定对应其Shapley值的贡献，而是取决于特征分布和评分特征之间的局部相互作用。 |
| [^15] | [SWBT: Similarity Weighted Behavior Transformer with the Imperfect Demonstration for Robotic Manipulation.](http://arxiv.org/abs/2401.08957) | 本论文提出了一种新型框架SWBT，能够在机器人操作任务中有效地从专家演示和不完美演示中学习，而无需与环境进行交互。这是第一个将不完美演示整合到离线模仿学习设置中的机器人操作任务的研究。 |
| [^16] | [Sum-of-Parts Models: Faithful Attributions for Groups of Features.](http://arxiv.org/abs/2310.16316) | Sum-of-Parts模型通过构造保证特征组归因的忠实性，将预测分解为可解释的分数之和，帮助天体物理学家发现了关于星系形成的新知识。 |
| [^17] | [Unbiased Pain Assessment through Wearables and EHR Data: Multi-attribute Fairness Loss-based CNN Approach.](http://arxiv.org/abs/2307.05333) | 本文提出了一种基于多属性公平损失的CNN模型，通过考虑患者数据中的敏感属性，公平预测疼痛状态，致力于减少差异。 |
| [^18] | [Novelty Accommodating Multi-Agent Planning in High Fidelity Simulated Open World.](http://arxiv.org/abs/2306.12654) | 本文介绍了一个能够检测、描述和适应现实环境中创新的领域独立AI代理在高保真模拟开放世界中成功应用的研究。在处理新颖环境干扰的多智能体规划任务中，该代理性能明显优于现有的基线。 |
| [^19] | [Probabilistic Learning of Multivariate Time Series with Temporal Irregularity.](http://arxiv.org/abs/2306.09147) | 本文提出了一种针对具有时间不规则性的多元时间序列的概率学习方法，通过允许观察到达时间在模型构建中发挥核心作用，使用新颖的非参数先验模型明确融入时间不规则性。 |
| [^20] | [Learning to Learn from APIs: Black-Box Data-Free Meta-Learning.](http://arxiv.org/abs/2305.18413) | 该论文提出了一个BiDf-MKD框架，可以从一组API库中无需访问训练数据，直接进行元学习；能够在更广泛的黑盒API上进行元学习，提高了元模型的泛化性能和应用范围。 |
| [^21] | [GPT-NAS: Neural Architecture Search with the Generative Pre-Trained Model.](http://arxiv.org/abs/2305.05351) | GPT-NAS使用生成式预训练模型优化神经架构搜索，通过提出近似的架构组件减小搜索空间，并明显优于其他NAS方法。 |
| [^22] | [A Review on Longitudinal Car-Following Model.](http://arxiv.org/abs/2304.07143) | 这篇论文综述了逐车跟驰模型的不同原则和分类，以及面临的挑战和局限性。 |
| [^23] | [Architecture, Dataset and Model-Scale Agnostic Data-free Meta-Learning.](http://arxiv.org/abs/2303.11183) | 不受体系结构、数据集和模型规模限制的无数据元学习框架PURER，通过ECI执行伪周期训练以适应新的任务，通过ICFIL对反演梯度进行校准来优化反演过程，并在各种任务中显著优于现有方法。 |
| [^24] | [Topology optimization with physics-informed neural networks: application to noninvasive detection of hidden geometries.](http://arxiv.org/abs/2303.09280) | 该论文介绍了一种基于物理知识神经网络的拓扑优化方法，应用于无先验知识的几何结构检测，通过材料密度场表示任意解决方案拓扑，并通过Eikonal正则化实现。该方法可用于医疗和工业应用中的非侵入式成像技术。 |
| [^25] | [Human alignment of neural network representations.](http://arxiv.org/abs/2211.01201) | 本文研究神经网络表示与人类心理表示之间的对齐问题，发现模型规模和体系结构对对齐几乎没有影响，而训练数据集和目标函数都对对齐有很大的影响。从一个数据集中学习的神经网络表示的线性变换能显著提高对另外两个数据集中人类相似性判断的对齐性。 |

# 详细

[^1]: 深度伪造手语的生成与检测-语言和视觉分析

    Generation and Detection of Sign Language Deepfakes - A Linguistic and Visual Analysis

    [https://arxiv.org/abs/2404.01438](https://arxiv.org/abs/2404.01438)

    通过在上半身生成手语深度伪造视频，并由手语专家审核，本研究探讨了在深度伪造技术中的积极应用，为聋哑和听障社区带来潜在的健康和教育益处。

    

    深度伪造领域中一个逐渐出现的问题是我们是否可以超越面部深度伪造，以及这对社会是否有益。因此，这项研究提出了在上半身生成中深度伪造技术的积极应用，同时为聋哑和听障（DHoH）社区执行手语。随后，通过一位手语专家对生成的视频进行审核。鉴于手语的复杂性、手语专家的匮乏以及对健康和教育的潜在益处，这种做法尤为有益。本研究的目标包括构建可靠的深度伪造数据集，通过计算机视觉和自然语言处理模型评估其技术和视觉可信度，以及评估生成内容的可信度。使用1200多个视频，模型包含以前见过和未见过的个体，借助一位手语专家的帮助进行生成。

    arXiv:2404.01438v1 Announce Type: cross  Abstract: A question in the realm of deepfakes is slowly emerging pertaining to whether we can go beyond facial deepfakes and whether it would be beneficial to society. Therefore, this research presents a positive application of deepfake technology in upper body generation, while performing sign-language for the Deaf and Hard of Hearing (DHoH) community. The resulting videos are later vetted with a sign language expert. This is particularly helpful, given the intricate nature of sign language, a scarcity of sign language experts, and potential benefits for health and education. The objectives of this work encompass constructing a reliable deepfake dataset, evaluating its technical and visual credibility through computer vision and natural language processing models, and assessing the plausibility of the generated content. With over 1200 videos, featuring both previously seen and unseen individuals for the generation model, using the help of a si
    
[^2]: 增强短文本建模：利用大型语言模型进行主题细化

    Enhanced Short Text Modeling: Leveraging Large Language Models for Topic Refinement

    [https://arxiv.org/abs/2403.17706](https://arxiv.org/abs/2403.17706)

    利用大型语言模型的先进能力，提出了一种名为“主题细化”的新方法，通过引入提示工程和消除离题词等方式改进短文本的主题建模质量，提高了主题的语义质量。

    

    有效地构建针对简短文本（如推文和新闻标题）的主题模型对捕捉社会动态的迅速变化至关重要。然而，传统主题模型往往在准确表达短文本的语义细微差异方面存在不足，这是由于它们的简洁性和缺乏上下文数据。在我们的研究中，我们利用大型语言模型（LLMs）的先进能力，引入了一种称为“主题细化”的新方法。该方法并非直接参与主题的初步建模，而是专注于改进主题在被挖掘后的阶段。通过引入提示工程，我们指导LLMs消除给定主题中的离题词，确保仅保留与语境相关的词汇或用更符合语义的词汇替换。这种方法模拟了人类般的审查和改进主题的方式，从而提升了各种主题生成的语义质量。

    arXiv:2403.17706v1 Announce Type: cross  Abstract: Crafting effective topic models for brief texts, like tweets and news headlines, is essential for capturing the swift shifts in social dynamics. Traditional topic models, however, often fall short in accurately representing the semantic intricacies of short texts due to their brevity and lack of contextual data. In our study, we harness the advanced capabilities of Large Language Models (LLMs) to introduce a novel approach termed "Topic Refinement". This approach does not directly involve itself in the initial modeling of topics but focuses on improving topics after they have been mined. By employing prompt engineering, we direct LLMs to eliminate off-topic words within a given topic, ensuring that only contextually relevant words are preserved or substituted with ones that fit better semantically. This method emulates human-like scrutiny and improvement of topics, thereby elevating the semantic quality of the topics generated by vario
    
[^3]: 视频的增强推理对象中心学习

    Reasoning-Enhanced Object-Centric Learning for Videos

    [https://arxiv.org/abs/2403.15245](https://arxiv.org/abs/2403.15245)

    设计了一种新颖的推理模块STATM，利用记忆缓冲区增强模型在复杂场景中的感知能力。

    

    物体中心学习旨在将复杂的视觉场景分解为更易处理的物体表示，提升机器学习系统对物理世界的理解和推理能力。最近，基于槽位的视频模型展现出在分割和跟踪物体方面出色的能力，但忽视了有效推理模块的重要性。为了增强模型在复杂场景中的感知能力，我们设计了一种名为具有记忆缓冲区的基于槽位的时空变换器（STATM）的新型推理模块。记忆缓冲区主要用于存储来自上游模块的槽位信息，基于槽位的时空变换器通过槽位为基础进行预测。

    arXiv:2403.15245v1 Announce Type: cross  Abstract: Object-centric learning aims to break down complex visual scenes into more manageable object representations, enhancing the understanding and reasoning abilities of machine learning systems toward the physical world. Recently, slot-based video models have demonstrated remarkable proficiency in segmenting and tracking objects, but they overlook the importance of the effective reasoning module. In the real world, reasoning and predictive abilities play a crucial role in human perception and object tracking; in particular, these abilities are closely related to human intuitive physics. Inspired by this, we designed a novel reasoning module called the Slot-based Time-Space Transformer with Memory buffer (STATM) to enhance the model's perception ability in complex scenes. The memory buffer primarily serves as storage for slot information from upstream modules, the Slot-based Time-Space Transformer makes predictions through slot-based spatio
    
[^4]: 机器学习中的威胁、攻击和防御：一项调查

    Threats, Attacks, and Defenses in Machine Unlearning: A Survey

    [https://arxiv.org/abs/2403.13682](https://arxiv.org/abs/2403.13682)

    机器遗忘（MU）通过知识去除过程来解决训练数据相关的人工智能治理问题，提高了AI系统的安全和负责任使用。

    

    机器遗忘（MU）最近引起了相当大的关注，因为它有潜力通过从训练的机器学习模型中消除特定数据的影响来实现安全人工智能。这个被称为知识去除的过程解决了与训练数据相关的人工智能治理问题，如数据质量、敏感性、版权限制和过时性。这种能力对于确保遵守诸如被遗忘权等隐私法规也至关重要。此外，有效的知识去除有助于减轻有害结果的风险，防范偏见、误导和未经授权的数据利用，从而增强了AI系统的安全和负责任使用。已经开展了设计高效的遗忘方法的工作，通过研究MU服务以与现有的机器学习作为服务集成，使用户能够提交请求从训练语料库中删除特定数据。

    arXiv:2403.13682v2 Announce Type: replace-cross  Abstract: Machine Unlearning (MU) has gained considerable attention recently for its potential to achieve Safe AI by removing the influence of specific data from trained machine learning models. This process, known as knowledge removal, addresses AI governance concerns of training data such as quality, sensitivity, copyright restrictions, and obsolescence. This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten. Furthermore, effective knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the safe and responsible use of AI systems. Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service, allowing users to submit requests to remove specific data from the training corpus. However, 
    
[^5]: 大型语言模型与协作中的因果推断：一项综合调查

    Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey

    [https://arxiv.org/abs/2403.09606](https://arxiv.org/abs/2403.09606)

    大型语言模型的出现极大影响了自然语言处理领域，特别是通过其先进的推理能力。而本综述则重点评估和改进了大型语言模型在因果推断方面的应用，包括提高推理能力、解决公平和安全问题、提供解释和处理多模态。

    

    因果推断已经显示出潜力，通过捕捉变量之间的因果关系，提高自然语言处理（NLP）模型的预测准确性、公平性、稳健性和可解释性。生成型大型语言模型（LLMs）的出现显著影响了各种NLP领域，特别是通过其先进的推理能力。该调查重点评估和改进LLMs的因果视角，在以下领域展开：理解和改进LLMs的推理能力，解决LLMs中的公平性和安全性问题，为LLMs提供解释，并处理多模态。同时，LLMs强大的推理能力反过来可以通过帮助因果关系发现和因果效应估计来促进因果推断领域的发展。本综述探讨了因果推断框架与LLMs之间的相互作用，强调了它们的集体作用。

    arXiv:2403.09606v1 Announce Type: cross  Abstract: Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective p
    
[^6]: 大型语言模型是对比推理者

    Large Language Models are Contrastive Reasoners

    [https://arxiv.org/abs/2403.08211](https://arxiv.org/abs/2403.08211)

    对比提示方法显著提高大型语言模型进行复杂推理的能力，不仅在算术、常识和符号推理任务上表现优良，还可以与现有提示方法整合，实现更好的性能。

    

    提示方法在增强预训练大型语言模型（LLMs）的能力方面发挥着至关重要的作用。我们探讨了对比提示（CP）如何显著提高大型语言模型执行复杂推理的能力。我们通过简单地在LLMs提供答案之前添加"让我们给出一个正确答案和一个错误答案"来演示LLMs是体面的对比推理者。对两个大型语言模型的实验表明，零迁移对比提示提升了在一系列算术、常识和符号推理任务上的表现，而不需要手工制作的少量迁移示例，比如使用最先进的GPT-4模型，提高了在GSM8K上的准确率从35.9%到88.8%以及AQUA-RAT从41.3%到62.2%。我们的方法不仅在大多数算术和常识推理任务中胜过零迁移CoT和少量迁移CoT，还可以与现有的提示方法无缝整合，从而实现改进或者竞争

    arXiv:2403.08211v1 Announce Type: cross  Abstract: Prompting methods play a crucial role in enhancing the capabilities of pre-trained large language models (LLMs). We explore how contrastive prompting (CP) significantly improves the ability of large language models to perform complex reasoning. We demonstrate that LLMs are decent contrastive reasoners by simply adding "Let's give a correct and a wrong answer." before LLMs provide answers. Experiments on two large language models show that zero-shot contrastive prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks without any hand-crafted few-shot examples, such as increasing the accuracy on GSM8K from 35.9% to 88.8% and AQUA-RAT from 41.3% to 62.2% with the state-of-the-art GPT-4 model. Our method not only surpasses zero-shot CoT and few-shot CoT in most arithmetic and commonsense reasoning tasks but also can seamlessly integrate with existing prompting methods, resulting in improved or comp
    
[^7]: 神经槽解释器：在新兴的槽表示中接地对象语义

    Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations

    [https://arxiv.org/abs/2403.07887](https://arxiv.org/abs/2403.07887)

    提出了神经槽解释器（NSI），通过槽表示学习接地和生成物体语义，实现了将现实世界的物体语义结合到抽象中。

    

    物体中心方法在将原始感知无监督分解为丰富的类似物体的抽象方面取得了重大进展。然而，将现实世界的物体语义接地到学到的抽象中的能力有限，这阻碍了它们在下游理解应用中的采用。我们提出神经槽解释器（NSI），它通过槽表示学习接地和生成物体语义。NSI的核心是一种类似XML的编程语言，它使用简单的语法规则将场景的物体语义组织成以物体为中心的程序原语。然后，一个对齐模型学习通过共享嵌入空间上的双层对比学习目标将程序原语接地到槽。最后，我们构建NSI程序生成模型，利用对齐模型推断的密集关联从槽生成以物体为中心的程序。在双模式检索实验中，

    arXiv:2403.07887v1 Announce Type: cross  Abstract: Object-centric methods have seen significant progress in unsupervised decomposition of raw perception into rich object-like abstractions. However, limited ability to ground object semantics of the real world into the learned abstractions has hindered their adoption in downstream understanding applications. We present the Neural Slot Interpreter (NSI) that learns to ground and generate object semantics via slot representations. At the core of NSI is an XML-like programming language that uses simple syntax rules to organize the object semantics of a scene into object-centric program primitives. Then, an alignment model learns to ground program primitives into slots through a bi-level contrastive learning objective over a shared embedding space. Finally, we formulate the NSI program generator model to use the dense associations inferred from the alignment model to generate object-centric programs from slots. Experiments on bi-modal retrie
    
[^8]: 您需要更好地关注付费

    You Need to Pay Better Attention

    [https://arxiv.org/abs/2403.01643](https://arxiv.org/abs/2403.01643)

    提出了三种新的注意力机制，在效率和学习能力方面优于标准的多头注意力，提高了Transformer模型的性能和更广泛的部署能力。

    

    我们引入了三种新的注意力机制，这些机制在效率和学习能力方面胜过标准的多头注意力，从而提高了Transformer模型的性能和更广泛的部署能力。我们的第一个贡献是优化注意力，其性能与标准注意力相似，但参数数量少了四分之三，每个头部少了一个矩阵乘法。接下来，我们引入了高效注意力，其性能与标准注意力相当，但参数数量减少了一半，每个头部减少了两个矩阵乘法，并且比标准注意力快两倍。最后，我们介绍了超级注意力，在视觉和自然语言处理任务中明显超越了标准注意力，同时具有更少的参数和矩阵乘法。除了提供严格的数学比较，我们在MN中评估了所提出的注意力机制

    arXiv:2403.01643v1 Announce Type: cross  Abstract: We introduce three new attention mechanisms that outperform standard multi-head attention in terms of efficiency and learning capabilities, thereby improving the performance and broader deployability of Transformer models. Our first contribution is Optimised Attention, which performs similarly to standard attention, but has 3/4 as many parameters and one matrix multiplication fewer per head. Next, we introduce Efficient Attention, which performs on par with standard attention with only 1/2 as many parameters as many parameters and two matrix multiplications fewer per head and is up to twice as fast as standard attention. Lastly, we introduce Super Attention, which surpasses standard attention by a significant margin in both vision and natural language processing tasks while having fewer parameters and matrix multiplications. In addition to providing rigorous mathematical comparisons, we evaluate the presented attention mechanisms on MN
    
[^9]: 架起因果发现与大型语言模型之间的桥梁：整合方法和未来方向的综合调查

    Bridging Causal Discovery and Large Language Models: A Comprehensive Survey of Integrative Approaches and Future Directions

    [https://arxiv.org/abs/2402.11068](https://arxiv.org/abs/2402.11068)

    本文综合调查了将大型语言模型（如GPT4）整合到因果发现任务中的方法，揭示了它们在推断因果结构时对元数据和自然语言的创新利用，强调了LLMs在增强传统CD方法和作为专家辅助方面的潜力和挑战。

    

    因果发现（CD）和大型语言模型（LLMs）代表着两个具有重要影响力的人工智能研究领域。尽管它们起源不同，CD侧重于从数据中揭示因果关系，LLMs则侧重于处理和生成类似人类的文本，但这两个领域的融合为理解复杂系统提供了新颖的见解和方法论。本文介绍了将LLMs（如GPT4）整合到CD任务中的综合调查。我们系统地审查和比较了利用LLMs进行各种CD任务的现有方法，并突出了它们对元数据和自然语言的创新利用以推断因果结构。我们的分析揭示了LLMs在增强传统CD方法和作为不完美专家方面的优势和潜力，同时也揭示了当前实践中固有的挑战和限制。此外，我们确定了文献中的空白。

    arXiv:2402.11068v1 Announce Type: cross  Abstract: Causal discovery (CD) and Large Language Models (LLMs) represent two emerging fields of study with significant implications for artificial intelligence. Despite their distinct origins, CD focuses on uncovering cause-effect relationships from data, and LLMs on processing and generating humanlike text, the convergence of these domains offers novel insights and methodologies for understanding complex systems. This paper presents a comprehensive survey of the integration of LLMs, such as GPT4, into CD tasks. We systematically review and compare existing approaches that leverage LLMs for various CD tasks and highlight their innovative use of metadata and natural language to infer causal structures. Our analysis reveals the strengths and potential of LLMs in both enhancing traditional CD methods and as an imperfect expert, alongside the challenges and limitations inherent in current practices. Furthermore, we identify gaps in the literature 
    
[^10]: 为社交感知的谈判对话开发辅助大型语言模型代理

    Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues

    [https://arxiv.org/abs/2402.01737](https://arxiv.org/abs/2402.01737)

    本文旨在开发LLM代理以减轻多代理设置下谈判中的社交规范违反。我们引入了基于价值影响的环境学习（ICL）方法，用于为基于LLM的修正代理识别高质量的ICL示例，其中价值影响函数衡量谈判结果的质量。我们展示了这种方法与策略学习的联系，并提供了丰富的实证证据来证明其在三个不同主题的谈判中的有效性。

    

    本文旨在开发LLM代理以减轻多代理设置下谈判中的社交规范违反。我们通过让两个大型语言模型（LLM）扮演每次对话中的两名谈判者来模拟现实世界谈判。第三个LLM充当修正代理，重新编写违反规范的话语以改善谈判结果。由于这是一个新颖的任务，不存在手动构建的数据。为解决这个限制，我们引入了基于价值影响的环境学习（ICL）方法，用于为基于LLM的修正代理识别高质量的ICL示例，其中价值影响函数衡量谈判结果的质量。我们展示了这种方法与策略学习的联系，并提供了丰富的实证证据来证明其在三个不同主题的谈判中的有效性，即产品销售、房价和薪资谈判。源代码和生成的数据集将在接受后公开。

    In this work, we aim to develop LLM agents to mitigate social norm violations in negotiations in a multi-agent setting. We simulate real-world negotiations by letting two large Language Models (LLMs) play the roles of two negotiators in each conversation. A third LLM acts as a remediation agent to rewrite utterances violating norms for improving negotiation outcomes. As it is a novel task, no manually constructed data is available. To address this limitation, we introduce a value impact based In-Context Learning (ICL) method to identify high-quality ICL examples for the LLM-based remediation agents, where the value impact function measures the quality of negotiation outcomes. We show the connection of this method to policy learning and provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different topics: product sale, housing price, and salary negotiation. The source code and the generated dataset will be publicly available upon acceptance.
    
[^11]: SWEA:通过主题词嵌入修改改变大型语言模型中的事实知识

    SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering

    [https://arxiv.org/abs/2401.17809](https://arxiv.org/abs/2401.17809)

    提出了一种主题词嵌入修改框架（SWEA），通过在推理阶段修改主题的表示来编辑知识，保护模型的原始权重，避免不可逆的损害和额外的推理开销。

    

    模型编辑近来引起了广泛关注。目前的模型编辑方法主要涉及修改模型参数或向现有模型添加附加模块。然而，前者会对LLM造成不可逆的影响，而后者会产生额外的推理开销，并且模糊的向量匹配并不总是可靠的。为了解决这些问题，我们提出了一种可扩展的主题词嵌入修改（SWEA）框架，它在推理阶段修改主题的表示，并实现编辑知识的目标。SWEA在模型外部使用精确的关键匹配，并进行可靠的主题词嵌入修改，从而保护模型的原始权重而不增加推理开销。然后，我们提出优化抑制融合方法，首先优化编辑目标的嵌入向量，然后抑制知识嵌入维度（KED）以获得最终融合的嵌入。我们因此提出了SWEAOS元方法。

    Model editing has recently gained widespread attention. Current model editing methods primarily involve modifying model parameters or adding additional modules to the existing model. However, the former causes irreversible damage to LLMs, while the latter incurs additional inference overhead and fuzzy vector matching is not always reliable. To address these issues, we propose an expandable Subject Word Embedding Altering (SWEA) framework, which modifies the representation of subjects and achieve the goal of editing knowledge during the inference stage. SWEA uses precise key matching outside the model and performs reliable subject word embedding altering, thus protecting the original weights of the model without increasing inference overhead. We then propose optimizing then suppressing fusion method, which first optimizes the embedding vector for the editing target and then suppresses the Knowledge Embedding Dimension (KED) to obtain the final fused embedding. We thus propose SWEAOS met
    
[^12]: 一剂病毒？使用Fakepedia定位和检测语言模型的潜在问题

    A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia

    [https://arxiv.org/abs/2312.02073](https://arxiv.org/abs/2312.02073)

    通过Fakepedia数据集研究语言模型的基础能力和进行因果中介分析，以解决上下文信息与存储知识相矛盾的问题。

    

    大型语言模型（LLMs）具有从其上下文中提供的新颖信息中获得的出色能力。然而，尚不清楚在上下文信息与参数中存储的事实知识相矛盾的情况下，支撑这种上下文基础的机制，LLMs在回忆方面也表现出色。偏好上下文信息对于检索增强生成方法至关重要，这些方法通过将上下文与最新信息丰富，希望基础可以纠正过时或有噪声的存储知识。我们提出了一种使用Fakepedia的新颖方法来研究基础能力，这是一个用于与模型内部参数知识冲突的反事实文本数据集。我们使用Fakepedia对各种LLMs进行基准测试，然后我们进行因果中介分析，基于我们的遮蔽分组因果追踪（MGCT），对回答Fakepedia查询时的LLM组件进行分析。在这个分析中，我们鉴别出d

    arXiv:2312.02073v2 Announce Type: replace  Abstract: Large language models (LLMs) have an impressive ability to draw on novel information supplied in their context. Yet the mechanisms underlying this contextual grounding remain unknown, especially in situations where contextual information contradicts factual knowledge stored in the parameters, which LLMs also excel at recalling. Favoring the contextual information is critical for retrieval-augmented generation methods, which enrich the context with up-to-date information, hoping that grounding can rectify outdated or noisy stored knowledge. We present a novel method to study grounding abilities using Fakepedia, a dataset of counterfactual texts constructed to clash with a model's internal parametric knowledge. We benchmark various LLMs with Fakepedia and then we conduct a causal mediation analysis, based on our Masked Grouped Causal Tracing (MGCT), on LLM components when answering Fakepedia queries. Within this analysis, we identify d
    
[^13]: 随机种群更新在多目标进化算法中可以被证明是有帮助的

    Stochastic Population Update Can Provably Be Helpful in Multi-Objective Evolutionary Algorithms

    [https://arxiv.org/abs/2306.02611](https://arxiv.org/abs/2306.02611)

    本研究通过理论分析证明，在多目标进化算法中采用随机种群更新机制可以显著降低算法的运行时间，从而提高问题的求解效率。

    

    进化算法（EAs）因其基于种群的搜索特性，已被广泛且成功地应用于解决多目标优化问题。种群更新是多目标进化算法（MOEAs）中的关键组成部分，通常以贪婪、确定性的方式进行。也就是说，下一代种群是通过从当前种群和新生成的解中选择最优解形成的（无论使用的选择标准是Pareto支配、拥挤度还是指标等）。本文对这种做法提出了质疑。我们从理论上证明了随机种群更新对于MOEAs的搜索是有益的。具体地，我们证明了将确定性种群更新机制替换为随机机制，可以指数级减少两个已经被广泛接受的MOEAs（SMS-EMOA和NSGA-II）在解决两个双目标问题（OneJumpZeroJump和双目标RealRoyalRoad）上的预计运行时间。此外，还进行了实证研究。

    Evolutionary algorithms (EAs) have been widely and successfully applied to solve multi-objective optimization problems, due to their nature of population-based search. Population update, a key component in multi-objective EAs (MOEAs), is usually performed in a greedy, deterministic manner. That is, the next-generation population is formed by selecting the best solutions from the current population and newly-generated solutions (irrespective of the selection criteria used such as Pareto dominance, crowdedness and indicators). In this paper, we question this practice. We analytically present that stochastic population update can be beneficial for the search of MOEAs. Specifically, we prove that the expected running time of two well-established MOEAs, SMS-EMOA and NSGA-II, for solving two bi-objective problems, OneJumpZeroJump and bi-objective RealRoyalRoad, can be exponentially decreased if replacing its deterministic population update mechanism by a stochastic one. Empirical studies als
    
[^14]: ShaRP：用Shapley值解释排名

    ShaRP: Explaining Rankings with Shapley Values. (arXiv:2401.16744v1 [cs.AI])

    [http://arxiv.org/abs/2401.16744](http://arxiv.org/abs/2401.16744)

    ShaRP是一个基于Shapley值的框架，用于解释排名结果中各个特征的贡献。即使使用线性评分函数，特征的权重也不一定对应其Shapley值的贡献，而是取决于特征分布和评分特征之间的局部相互作用。

    

    在招聘、大学招生和贷款等重要领域的算法决策常常是基于排名的。由于这些决策对个人、组织和人群的影响，有必要了解它们：了解决策是否遵守法律，帮助个人提高他们的排名，并设计更好的排名程序。本文提出了ShaRP（Shapley for Rankings and Preferences），这是一个基于Shapley值的框架，用于解释特征对排名结果不同方面的贡献。使用ShaRP，我们展示了即使算法排名器使用的评分函数是已知的且是线性的，每个特征的权重也不一定对应其Shapley值的贡献。贡献取决于特征的分布以及评分特征之间微妙的局部相互作用。ShaRP基于量化输入影响框架，并可以计算贡献。

    Algorithmic decisions in critical domains such as hiring, college admissions, and lending are often based on rankings. Because of the impact these decisions have on individuals, organizations, and population groups, there is a need to understand them: to know whether the decisions are abiding by the law, to help individuals improve their rankings, and to design better ranking procedures.  In this paper, we present ShaRP (Shapley for Rankings and Preferences), a framework that explains the contributions of features to different aspects of a ranked outcome, and is based on Shapley values. Using ShaRP, we show that even when the scoring function used by an algorithmic ranker is known and linear, the weight of each feature does not correspond to its Shapley value contribution. The contributions instead depend on the feature distributions, and on the subtle local interactions between the scoring features. ShaRP builds on the Quantitative Input Influence framework, and can compute the contri
    
[^15]: SWBT：具有不完美演示的相似性加权行为转换器用于机器人操作

    SWBT: Similarity Weighted Behavior Transformer with the Imperfect Demonstration for Robotic Manipulation. (arXiv:2401.08957v1 [cs.RO])

    [http://arxiv.org/abs/2401.08957](http://arxiv.org/abs/2401.08957)

    本论文提出了一种新型框架SWBT，能够在机器人操作任务中有效地从专家演示和不完美演示中学习，而无需与环境进行交互。这是第一个将不完美演示整合到离线模仿学习设置中的机器人操作任务的研究。

    

    模仿学习旨在从专家演示中学习最佳控制策略，已成为机器人操作任务的有效方法。然而，先前的模仿学习方法要么仅使用昂贵的专家演示并忽略不完美的演示，要么依赖于与环境的交互和从在线经验中学习。在机器人操作的背景下，我们旨在克服上述两个挑战，并提出了一种名为Similarity Weighted Behavior Transformer（SWBT）的新型框架。SWBT能够有效地从专家演示和不完美演示中学习，而无需与环境进行交互。我们揭示了易获取的不完美演示，如正向和反向动力学，通过学习有益信息显著增强了网络。据我们所知，我们是第一个尝试将不完美演示整合到离线模仿学习设置中的机器人操作任务中的研究。在ManiSkill2 bench上进行了大量实验。

    Imitation learning (IL), aiming to learn optimal control policies from expert demonstrations, has been an effective method for robot manipulation tasks. However, previous IL methods either only use expensive expert demonstrations and omit imperfect demonstrations or rely on interacting with the environment and learning from online experiences. In the context of robotic manipulation, we aim to conquer the above two challenges and propose a novel framework named Similarity Weighted Behavior Transformer (SWBT). SWBT effectively learn from both expert and imperfect demonstrations without interaction with environments. We reveal that the easy-to-get imperfect demonstrations, such as forward and inverse dynamics, significantly enhance the network by learning fruitful information. To the best of our knowledge, we are the first to attempt to integrate imperfect demonstrations into the offline imitation learning setting for robot manipulation tasks. Extensive experiments on the ManiSkill2 bench
    
[^16]: Sum-of-Parts模型：对特征组的忠实归因

    Sum-of-Parts Models: Faithful Attributions for Groups of Features. (arXiv:2310.16316v1 [cs.LG])

    [http://arxiv.org/abs/2310.16316](http://arxiv.org/abs/2310.16316)

    Sum-of-Parts模型通过构造保证特征组归因的忠实性，将预测分解为可解释的分数之和，帮助天体物理学家发现了关于星系形成的新知识。

    

    如果机器学习模型的解释准确反映了其决策过程，则被认为是“忠实”的解释。然而，例如深度学习的特征归因等解释并不能保证忠实，有可能产生具有误导性的解释。在这项工作中，我们开发了Sum-of-Parts（SOP）模型，它是一类模型，其预测具有通过构造保证忠实的特征组归因。该模型将预测分解为可解释的分数之和，每个分数直接归因于一组稀疏特征。我们使用标准可解释性指标对SOP进行评估，并在一个案例研究中，利用SOP提供的忠实解释帮助天体物理学家发现了关于星系形成的新知识。

    An explanation of a machine learning model is considered "faithful" if it accurately reflects the model's decision-making process. However, explanations such as feature attributions for deep learning are not guaranteed to be faithful, and can produce potentially misleading interpretations. In this work, we develop Sum-of-Parts (SOP), a class of models whose predictions come with grouped feature attributions that are faithful-by-construction. This model decomposes a prediction into an interpretable sum of scores, each of which is directly attributable to a sparse group of features. We evaluate SOP on benchmarks with standard interpretability metrics, and in a case study, we use the faithful explanations from SOP to help astrophysicists discover new knowledge about galaxy formation.
    
[^17]: 通过可穿戴设备和电子健康记录数据进行无偏见的疼痛评估：基于多属性公平损失的CNN方法

    Unbiased Pain Assessment through Wearables and EHR Data: Multi-attribute Fairness Loss-based CNN Approach. (arXiv:2307.05333v1 [eess.SP])

    [http://arxiv.org/abs/2307.05333](http://arxiv.org/abs/2307.05333)

    本文提出了一种基于多属性公平损失的CNN模型，通过考虑患者数据中的敏感属性，公平预测疼痛状态，致力于减少差异。

    

    多样化的健康数据（物联网、电子健康记录和临床调查）与可扩展的适应性人工智能相结合，已经实现了对疼痛状态的身体、行为和心理社交指标的发现。尽管以技术进步改变医疗系统的热情和承诺，但临床疼痛评估中的人工智能应用受到了问题本身的多样性和个性化以及公平性等其他挑战的阻碍。研究表明，许多人工智能（如机器学习或深度学习）模型显示出偏见，并歧视特定人群（如基于性别或种族），这引起了医疗专业人员对人工智能适应性的怀疑。在本文中，我们提出了一种基于多属性公平损失的CNN模型，旨在考虑数据中包含的任何敏感属性，并公平预测患者的疼痛状态，同时尽量减少差异。

    The combination of diverse health data (IoT, EHR, and clinical surveys) and scalable-adaptable Artificial Intelligence (AI), has enabled the discovery of physical, behavioral, and psycho-social indicators of pain status. Despite the hype and promise to fundamentally alter the healthcare system with technological advancements, much AI adoption in clinical pain evaluation has been hampered by the heterogeneity of the problem itself and other challenges, such as personalization and fairness. Studies have revealed that many AI (i.e., machine learning or deep learning) models display biases and discriminate against specific population segments (such as those based on gender or ethnicity), which breeds skepticism among medical professionals about AI adaptability. In this paper, we propose a Multi-attribute Fairness Loss (MAFL) based CNN model that aims to account for any sensitive attributes included in the data and fairly predict patients' pain status while attempting to minimize the discre
    
[^18]: 在高保真模拟开放世界中考虑创新的多智能体规划

    Novelty Accommodating Multi-Agent Planning in High Fidelity Simulated Open World. (arXiv:2306.12654v1 [cs.AI])

    [http://arxiv.org/abs/2306.12654](http://arxiv.org/abs/2306.12654)

    本文介绍了一个能够检测、描述和适应现实环境中创新的领域独立AI代理在高保真模拟开放世界中成功应用的研究。在处理新颖环境干扰的多智能体规划任务中，该代理性能明显优于现有的基线。

    

    自主智能体在现实环境中行动时经常需要处理未知的创新干扰其计划执行。创新是一种意外的现象，可以改变环境的核心特征、组成和动态。创新在任何足够复杂的环境中的任何时间都可能发生，而没有任何事先通知或解释。先前的研究表明，创新对智能体的性能产生灾难性影响。智能体通过世界的内在模型进行推理，以理解其环境的复杂性，并成功执行其计划。创新通常使得他们的内部模型不准确并且生成的计划不再适用。创新特别普遍在现实世界中，在其中领域特定甚至是预测的创新特定方法被用于减轻创新的影响。在这项工作中，我们展示了一个设计用于在现实环境中检测，描绘和适应创新的领域独立AI代理可以成功地将其技能转移到高保真的模拟开放世界中。我们的代理在涉及处理新颖环境干扰的多智能体规划任务中显示出了显着的改进，而且比现有的基线表现得更好。

    Autonomous agents acting in real-world environments often need to reason with unknown novelties interfering with their plan execution. Novelty is an unexpected phenomenon that can alter the core characteristics, composition, and dynamics of the environment. Novelty can occur at any time in any sufficiently complex environment without any prior notice or explanation. Previous studies show that novelty has catastrophic impact on agent performance. Intelligent agents reason with an internal model of the world to understand the intricacies of their environment and to successfully execute their plans. The introduction of novelty into the environment usually renders their internal model inaccurate and the generated plans no longer applicable. Novelty is particularly prevalent in the real world where domain-specific and even predicted novelty-specific approaches are used to mitigate the novelty's impact. In this work, we demonstrate that a domain-independent AI agent designed to detect, chara
    
[^19]: 具有时间不规则性的多元时间序列的概率学习

    Probabilistic Learning of Multivariate Time Series with Temporal Irregularity. (arXiv:2306.09147v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09147](http://arxiv.org/abs/2306.09147)

    本文提出了一种针对具有时间不规则性的多元时间序列的概率学习方法，通过允许观察到达时间在模型构建中发挥核心作用，使用新颖的非参数先验模型明确融入时间不规则性。

    

    在实践中收集的多元序列数据经常表现出时间的不规则性，包括非均匀时间间隔和组件错位。然而，如果不均匀的间距和异步是数据内生特征而不是不足观察的结果，则这些不规则性的信息内容在表征多元依赖结构时发挥决定性作用。现有的概率预测方法要么忽略了由此产生的统计异质性，要么易受到插补偏差的影响，要么将参数假设强加于数据分布上。本文提出了一种端到端解决方案，通过允许观察到达时间在模型构建中发挥核心作用来克服这些限制，这是时间不规则性的核心。为了认识到时间的不规则性，我们首先为组件启用唯一的隐藏状态，以便到达时间可以指导何时、如何和哪个隐藏状态应该更新。然后，我们通过一种新颖的非参数先验模型明确地融入了时间不规则性，该模型联合建模观测和隐藏状态，并自适应地捕获了跨组件的时间异质性和条件依赖性。我们使用合成数据和实际数据集展示了我们方法的优越性。

    Multivariate sequential data collected in practice often exhibit temporal irregularities, including nonuniform time intervals and component misalignment. However, if uneven spacing and asynchrony are endogenous characteristics of the data rather than a result of insufficient observation, the information content of these irregularities plays a defining role in characterizing the multivariate dependence structure. Existing approaches for probabilistic forecasting either overlook the resulting statistical heterogeneities, are susceptible to imputation biases, or impose parametric assumptions on the data distribution. This paper proposes an end-to-end solution that overcomes these limitations by allowing the observation arrival times to play the central role of model construction, which is at the core of temporal irregularities. To acknowledge temporal irregularities, we first enable unique hidden states for components so that the arrival times can dictate when, how, and which hidden state
    
[^20]: 从API学习学习：黑盒数据无关元学习

    Learning to Learn from APIs: Black-Box Data-Free Meta-Learning. (arXiv:2305.18413v1 [cs.LG])

    [http://arxiv.org/abs/2305.18413](http://arxiv.org/abs/2305.18413)

    该论文提出了一个BiDf-MKD框架，可以从一组API库中无需访问训练数据，直接进行元学习；能够在更广泛的黑盒API上进行元学习，提高了元模型的泛化性能和应用范围。

    

    无数据元学习（DFML）旨在通过从一组预训练模型进行元学习而无需访问训练数据，从而实现高效学习新任务。现有的DFML工作仅能从（i）白盒和（ii）小规模预训练模型（iii）相同的架构中元学习，忽略了更实际的设置，即用户仅能通过任意模型架构和规模的API进行推断。为解决这个问题，我们提出了一个双层数据无关元知识蒸馏（BiDf-MKD）框架，将更通用的元知识从一组黑盒API转移到一个单一的元模型中。

    Data-free meta-learning (DFML) aims to enable efficient learning of new tasks by meta-learning from a collection of pre-trained models without access to the training data. Existing DFML work can only meta-learn from (i) white-box and (ii) small-scale pre-trained models (iii) with the same architecture, neglecting the more practical setting where the users only have inference access to the APIs with arbitrary model architectures and model scale inside. To solve this issue, we propose a Bi-level Data-free Meta Knowledge Distillation (BiDf-MKD) framework to transfer more general meta knowledge from a collection of black-box APIs to one single meta model. Specifically, by just querying APIs, we inverse each API to recover its training data via a zero-order gradient estimator and then perform meta-learning via a novel bi-level meta knowledge distillation structure, in which we design a boundary query set recovery technique to recover a more informative query set near the decision boundary. 
    
[^21]: GPT-NAS: 以生成式预训练模型为基础的神经架构搜索

    GPT-NAS: Neural Architecture Search with the Generative Pre-Trained Model. (arXiv:2305.05351v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2305.05351](http://arxiv.org/abs/2305.05351)

    GPT-NAS使用生成式预训练模型优化神经架构搜索，通过提出近似的架构组件减小搜索空间，并明显优于其他NAS方法。

    

    神经架构搜索(NAS)已经成为了一种自动设计最优神经网络架构的有效方法之一。虽然一些人工设计的神经网络已经在多项任务中取得了人类水平的表现，但在NAS方法中很少出现这类成果，主要原因在于神经架构的搜索空间太大了，导致NAS算法效率低下。这项工作提出了一种新的架构搜索算法，称为GPT-NAS，通过生成式预训练模型来优化神经架构。在GPT-NAS中，我们假设一个在大规模语料库上预训练的生成模型能够学习构建神经架构的基本规律。因此，GPT-NAS利用生成式预训练模型来提出合理的架构组件，从而大大减少了搜索空间，引入了搜索过程中的先验知识。广泛的实验结果表明，我们的GPT-NAS方法明显优于其他NAS方法。

    Neural Architecture Search (NAS) has emerged as one of the effective methods to design the optimal neural network architecture automatically. Although neural architectures have achieved human-level performances in several tasks, few of them are obtained from the NAS method. The main reason is the huge search space of neural architectures, making NAS algorithms inefficient. This work presents a novel architecture search algorithm, called GPT-NAS, that optimizes neural architectures by Generative Pre-Trained (GPT) model. In GPT-NAS, we assume that a generative model pre-trained on a large-scale corpus could learn the fundamental law of building neural architectures. Therefore, GPT-NAS leverages the generative pre-trained (GPT) model to propose reasonable architecture components given the basic one. Such an approach can largely reduce the search space by introducing prior knowledge in the search process. Extensive experimental results show that our GPT-NAS method significantly outperforms
    
[^22]: 逐车跟驰模型综述

    A Review on Longitudinal Car-Following Model. (arXiv:2304.07143v1 [eess.SY])

    [http://arxiv.org/abs/2304.07143](http://arxiv.org/abs/2304.07143)

    这篇论文综述了逐车跟驰模型的不同原则和分类，以及面临的挑战和局限性。

    

    车跟车模型是交通仿真的核心组成部分，已经内置于许多配备ADAS的汽车中。对车跟车行为的研究使我们能够确定由基本的车辆交互过程引起的不同宏观现象的根源。本文提供了一份详尽的调查，重点介绍了各种车跟车模型之间的区别、互补性和重叠之处。该审查将在不同原则中概念化的车跟车模型进行分类。

    The car-following (CF) model is the core component for traffic simulations and has been built-in in many production vehicles with Advanced Driving Assistance Systems (ADAS). Research of CF behavior allows us to identify the sources of different macro phenomena induced by the basic process of pairwise vehicle interaction. The CF behavior and control model encompasses various fields, such as traffic engineering, physics, cognitive science, machine learning, and reinforcement learning. This paper provides a comprehensive survey highlighting differences, complementarities, and overlaps among various CF models according to their underlying logic and principles. We reviewed representative algorithms, ranging from the theory-based kinematic models, stimulus-response models, and cruise control models to data-driven Behavior Cloning (BC) and Imitation Learning (IL) and outlined their strengths and limitations. This review categorizes CF models that are conceptualized in varying principles and s
    
[^23]: 不受体系结构、数据集和模型规模限制的无数据元学习

    Architecture, Dataset and Model-Scale Agnostic Data-free Meta-Learning. (arXiv:2303.11183v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.11183](http://arxiv.org/abs/2303.11183)

    不受体系结构、数据集和模型规模限制的无数据元学习框架PURER，通过ECI执行伪周期训练以适应新的任务，通过ICFIL对反演梯度进行校准来优化反演过程，并在各种任务中显著优于现有方法。

    

    无数据元学习的目的是从一组经过预训练的模型中学习有用的先验知识，而无需访问其训练数据。然而，现有的研究仅在参数空间中解决了该问题，忽略了预训练模型中蕴含的丰富数据知识，无法扩展到大规模预训练模型，只能元学习具有相同网络架构的预训练模型。为了解决这些问题，我们提出了一个统一的框架——PURER，其中包含：（1）数据无关的元训练期间的节目课程反转（ECI）；（2）元测试期间内部循环后的反演校准（ICFIL）。在元训练期间，我们提出了ECI来执行伪周期训练，以便快速适应新的看不见的任务。在元测试期间，我们提出了ICFIL来校准反演梯度，以减少基于反演的优化的负面影响。广泛的实验结果表明，所提出的PURER可以有效地元学习来自具有不同网络架构、数据集域甚至不同大小的预训练模型，并在各种任务中显著优于现有方法。

    The goal of data-free meta-learning is to learn useful prior knowledge from a collection of pre-trained models without accessing their training data. However, existing works only solve the problem in parameter space, which (i) ignore the fruitful data knowledge contained in the pre-trained models; (ii) can not scale to large-scale pre-trained models; (iii) can only meta-learn pre-trained models with the same network architecture. To address those issues, we propose a unified framework, dubbed PURER, which contains: (1) ePisode cUrriculum inveRsion (ECI) during data-free meta training; and (2) invErsion calibRation following inner loop (ICFIL) during meta testing. During meta training, we propose ECI to perform pseudo episode training for learning to adapt fast to new unseen tasks. Specifically, we progressively synthesize a sequence of pseudo episodes by distilling the training data from each pre-trained model. The ECI adaptively increases the difficulty level of pseudo episodes accord
    
[^24]: 物理知识神经网络拓扑优化：应用于隐藏几何结构的非侵入式探测。

    Topology optimization with physics-informed neural networks: application to noninvasive detection of hidden geometries. (arXiv:2303.09280v1 [cs.LG])

    [http://arxiv.org/abs/2303.09280](http://arxiv.org/abs/2303.09280)

    该论文介绍了一种基于物理知识神经网络的拓扑优化方法，应用于无先验知识的几何结构检测，通过材料密度场表示任意解决方案拓扑，并通过Eikonal正则化实现。该方法可用于医疗和工业应用中的非侵入式成像技术。

    

    在医疗和工业应用中，通过电磁、声学或机械负载从表面测量中检测隐藏的几何结构是非侵入成像技术的目标。由于未知的拓扑和几何形状、数据的稀疏性以及物理规律的复杂性，解决逆问题是具有挑战性的。物理知识神经网络已经表现出许多优点，是一个简单而强大的问题反演工具，但它们尚未应用于具有先验未知拓扑的一般问题。在这里，我们介绍了一个基于PINNs的拓扑优化框架，它可以解决没有形状数量或类型先验知识的几何检测问题。我们允许任意的解决方案拓扑，通过使用材料密度场来表示几何形状，并通过新的Eikonal正则化接近二进制值。我们通过检测隐含虚空和包含物的数量、位置和形状来验证我们的框架。

    Detecting hidden geometrical structures from surface measurements under electromagnetic, acoustic, or mechanical loading is the goal of noninvasive imaging techniques in medical and industrial applications. Solving the inverse problem can be challenging due to the unknown topology and geometry, the sparsity of the data, and the complexity of the physical laws. Physics-informed neural networks (PINNs) have shown promise as a simple-yet-powerful tool for problem inversion, but they have yet to be applied to general problems with a priori unknown topology. Here, we introduce a topology optimization framework based on PINNs that solves geometry detection problems without prior knowledge of the number or types of shapes. We allow for arbitrary solution topology by representing the geometry using a material density field that approaches binary values thanks to a novel eikonal regularization. We validate our framework by detecting the number, locations, and shapes of hidden voids and inclusio
    
[^25]: 人类对神经网络表示的对齐

    Human alignment of neural network representations. (arXiv:2211.01201v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.01201](http://arxiv.org/abs/2211.01201)

    本文研究神经网络表示与人类心理表示之间的对齐问题，发现模型规模和体系结构对对齐几乎没有影响，而训练数据集和目标函数都对对齐有很大的影响。从一个数据集中学习的神经网络表示的线性变换能显著提高对另外两个数据集中人类相似性判断的对齐性。

    

    当今的计算机视觉模型在各种视觉任务上实现了人类或接近人类水平的性能。然而，它们的体系结构、数据和学习算法与导致人类视觉的方式存在许多不同之处。本文研究影响神经网络所学习的表示与通过行为反应推断出的人类心理表示之间对齐的因素。我们发现，模型的规模和体系结构对与人类行为反应的对齐基本上没有影响，而训练数据集和目标函数则具有更大的影响。这些发现在使用两种不同任务收集的三个人类相似度判断数据集中保持一致。从一个数据集中学习的神经网络表示的线性变换显著提高了对另外两个数据集中的人类相似度判断的对齐性。此外，我们发现，一些人类概念...

    Today's computer vision models achieve human or near-human level performance across a wide variety of vision tasks. However, their architectures, data, and learning algorithms differ in numerous ways from those that give rise to human vision. In this paper, we investigate the factors that affect the alignment between the representations learned by neural networks and human mental representations inferred from behavioral responses. We find that model scale and architecture have essentially no effect on the alignment with human behavioral responses, whereas the training dataset and objective function both have a much larger impact. These findings are consistent across three datasets of human similarity judgments collected using two different tasks. Linear transformations of neural network representations learned from behavioral responses from one dataset substantially improve alignment with human similarity judgments on the other two datasets. In addition, we find that some human concept
    

