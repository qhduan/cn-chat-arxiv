# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech](https://arxiv.org/abs/2403.15449) | 研究研究了对抗在线仇恨言论的最佳方法，通过分析对话中的理由、情感和信誉等说服方式，对比封闭和开放交互中的不同行为和话题层面，发现了在对抗言论中的微妙差异。 |
| [^2] | [Machine Learning and Vision Transformers for Thyroid Carcinoma Diagnosis: A review](https://arxiv.org/abs/2403.13843) | 该论文总结了使用机器学习和大数据分析结合transformer评估甲状腺癌预后的方法，介绍了新的分类系统，并强调了人工智能在辅助甲状腺癌诊断和治疗中的重要性。 |
| [^3] | [PhD: A Prompted Visual Hallucination Evaluation Dataset](https://arxiv.org/abs/2403.11116) | 本研究针对Intrinsic Vision-Language Hallucination（IVL-Hallu）问题进行了深入分析，提出了几种新颖的IVL-Hallu任务，并将其分为四种类型，有助于揭示其产生的原因和反映。 |
| [^4] | [Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses](https://arxiv.org/abs/2402.17097) | 提出了一种名为Re-Ex的方法，通过引入事实错误说明步骤来修正LLM生成文本中的事实错误，并提出了新的提示技术来减少所需的标记数量和挂钟时间 |
| [^5] | [COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling](https://arxiv.org/abs/2402.14701) | 本文提出了一种名为COMPASS的新框架，通过分析心理治疗会话中的自然语言，直接推断治疗工作联盟，为临床精神病学提供了可解释性，并在识别与正在治疗的疾病相关的新兴模式方面发挥作用。 |
| [^6] | [LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation](https://arxiv.org/abs/2402.13840) | 该研究提出了LLM4SBR框架，是第一个适合在基于会话的推荐中集成大型语言模型的轻量且有效框架。 |
| [^7] | [Adaptive Skeleton Graph Decoding](https://arxiv.org/abs/2402.12280) | 提出了骨架图解码（SGD）方法，利用子问题之间的依赖关系进行信息转发，改善响应质量且提高性能。 |
| [^8] | [Secret Collusion Among Generative AI Agents](https://arxiv.org/abs/2402.07510) | 本文汇集了人工智能和安全领域的相关概念，系统地形式化了生成式AI代理系统中的秘密勾结问题，并提出了缓解措施。通过测试各种形式的秘密勾结所需的能力，我们发现当前模型的隐写能力有限，但 GPT-4 展示了能力的飞跃。 |
| [^9] | [Embedding Ontologies via Incoprorating Extensional and Intensional Knowledge](https://arxiv.org/abs/2402.01677) | 本文提出了一种新型本体嵌入方法EIKE，通过整合外延知识和内涵知识，在外延空间和内涵空间中表示本体，并采用基于几何的方法和预训练的语言模型对实例、概念和关系进行嵌入建模。 |
| [^10] | [Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm.](http://arxiv.org/abs/2310.13019) | 本文提出了一种增强版DeepFool算法，名为Targeted DeepFool，可以针对特定类别进行错误分类，并引入了最小置信度分数要求超参数来提高灵活性。 |
| [^11] | [Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping.](http://arxiv.org/abs/2309.06038) | 本文提出了一个名为“人类助力灵巧抓取”的新型任务，通过使用Grasping Gradient Field和基于历史条件的残差策略，训练控制机器人手指以适应不同用户意图和物体几何形状的灵巧抓取操作。 |
| [^12] | [Loss Functions and Metrics in Deep Learning. A Review.](http://arxiv.org/abs/2307.02694) | 本文回顾了深度学习中最常见的损失函数和性能测量方法，旨在帮助从业者选择最适合其特定任务的方法。 |

# 详细

[^1]: 憎恨源于无知！对抗会话性仇恨言论中说服方式的提炼

    Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech

    [https://arxiv.org/abs/2403.15449](https://arxiv.org/abs/2403.15449)

    研究研究了对抗在线仇恨言论的最佳方法，通过分析对话中的理由、情感和信誉等说服方式，对比封闭和开放交互中的不同行为和话题层面，发现了在对抗言论中的微妙差异。

    

    研究对抗言论使用的因素是理解在线对抗仇恨言论的最佳方法的核心。各种研究评估对抗言论中使用的情感基础因素，如情感共鸣、冒犯程度和敌意程度。为了更好地理解会话交互中使用的对抗言论，本研究将说服方式分解为理由、情感和信誉，然后评估它们在涉及种族主义、性别歧视和宗教问题的两种对话交互类型中的使用。评估涵盖了人类与生成对抗言论的不同行为。我们还评估了回复的立场与每种对抗言论中的说服方式之间的相互作用。值得注意的是，我们观察到了在开放和封闭交互的对抗言论说服方式上的微妙差异 -- 尤其是在话题层面上。

    arXiv:2403.15449v1 Announce Type: cross  Abstract: Examining the factors that the counter-speech uses is at the core of understanding the optimal methods for confronting hate speech online. Various studies assess the emotional base factor used in counter speech, such as emotion-empathy, offensiveness, and level of hostility. To better understand the counter-speech used in conversational interactions, this study distills persuasion modes into reason, emotion, and credibility and then evaluates their use in two types of conversation interactions: closed (multi-turn) and open (single-turn) conversation interactions concerning racism, sexism, and religion. The evaluation covers the distinct behaviors of human versus generated counter-speech. We also assess the interplay between the replies' stance and each mode of persuasion in the counter-speech. Notably, we observe nuanced differences in the counter-speech persuasion modes for open and closed interactions -- especially on the topic level
    
[^2]: 机器学习和视觉Transformer在甲状腺癌诊断中的应用：综述

    Machine Learning and Vision Transformers for Thyroid Carcinoma Diagnosis: A review

    [https://arxiv.org/abs/2403.13843](https://arxiv.org/abs/2403.13843)

    该论文总结了使用机器学习和大数据分析结合transformer评估甲状腺癌预后的方法，介绍了新的分类系统，并强调了人工智能在辅助甲状腺癌诊断和治疗中的重要性。

    

    与发展智能诊断系统以帮助医学专家处理大量数据以治疗不可治愈疾病的兴趣不断增长。特别是，在识别甲状腺癌（TC）的挑战方面，使用机器学习（ML）和大数据分析取得了进展，结合transformer评估TC预后，并确定个体的恶性风险。本综述文章总结了各种关于以人工智能（AI）算法为基础的方法的研究，特别是那些采用transformer进行甲状腺癌诊断的方法。它引入了一个新的基于AI算法、框架目标和使用的计算环境对这些方法进行分类的系统。此外，它通过其特征审查和对比了可用的TC数据集。该论文强调了AI工具在通过监督、无监督或混合方式协助诊断和治疗TC方面的重要性。

    arXiv:2403.13843v1 Announce Type: cross  Abstract: The growing interest in developing smart diagnostic systems to help medical experts process extensive data for treating incurable diseases has been notable. In particular, the challenge of identifying thyroid cancer (TC) has seen progress with the use of machine learning (ML) and big data analysis, incorporating transformers to evaluate TC prognosis and determine the risk of malignancy in individuals. This review article presents a summary of various studies on AIbased approaches, especially those employing transformers, for diagnosing TC. It introduces a new categorization system for these methods based on artifcial intelligence (AI) algorithms, the goals of the framework, and the computing environments used. Additionally, it scrutinizes and contrasts the available TC datasets by their features. The paper highlights the importance of AI instruments in aiding the diagnosis and treatment of TC through supervised, unsupervised, or mixed 
    
[^3]: 博士论文：一个提示的视觉幻觉评估数据集

    PhD: A Prompted Visual Hallucination Evaluation Dataset

    [https://arxiv.org/abs/2403.11116](https://arxiv.org/abs/2403.11116)

    本研究针对Intrinsic Vision-Language Hallucination（IVL-Hallu）问题进行了深入分析，提出了几种新颖的IVL-Hallu任务，并将其分为四种类型，有助于揭示其产生的原因和反映。

    

    大型语言模型（LLMs）的快速增长推动了大型视觉语言模型（LVLMs）的发展。在LLMs中普遍存在的幻觉挑战也出现在LVLMs中。然而，大部分现有研究主要集中在LVLM中的对象幻觉上，忽略了LVLM幻觉的多样化类型。本研究深入探讨了固有视觉语言幻觉（IVL-Hallu）问题，对导致幻觉的不同类型的IVL-Hallu进行了彻底分析。具体来说，我们提出了几个新颖的IVL-Hallu任务，并将它们分为四种类型：（a）对象幻觉，由于对象的误识别而产生，（b）属性幻觉，由于属性的误识别而引起，（c）多模态冲突幻觉，源自文本和视觉信息之间的矛盾，以及（d）反常识幻觉，由于对立之间的矛盾。

    arXiv:2403.11116v1 Announce Type: cross  Abstract: The rapid growth of Large Language Models (LLMs) has driven the development of Large Vision-Language Models (LVLMs). The challenge of hallucination, prevalent in LLMs, also emerges in LVLMs. However, most existing efforts mainly focus on object hallucination in LVLM, ignoring diverse types of LVLM hallucinations. In this study, we delve into the Intrinsic Vision-Language Hallucination (IVL-Hallu) issue, thoroughly analyzing different types of IVL-Hallu on their causes and reflections. Specifically, we propose several novel IVL-Hallu tasks and categorize them into four types: (a) object hallucination, which arises from the misidentification of objects, (b) attribute hallucination, which is caused by the misidentification of attributes, (c) multi-modal conflicting hallucination, which derives from the contradictions between textual and visual information, and (d) counter-common-sense hallucination, which owes to the contradictions betwee
    
[^4]: 修复: 在说明后修正LLM响应中的事实错误

    Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses

    [https://arxiv.org/abs/2402.17097](https://arxiv.org/abs/2402.17097)

    提出了一种名为Re-Ex的方法，通过引入事实错误说明步骤来修正LLM生成文本中的事实错误，并提出了新的提示技术来减少所需的标记数量和挂钟时间

    

    缓解幻觉问题是LLM的主要挑战之一，我们需要克服这一挑战，以便可靠地在现实场景中使用它们。最近，提出了各种方法来检查LLM生成的文本中的事实错误，并相应地进行修订，以减少幻觉问题。在本文中，我们提出了Re-Ex，一种修订LLM生成文本的方法，它引入了一个称为事实错误说明步骤的新步骤。 Re-Ex使用3个步骤对LLM的初始响应进行修订：首先，使用外部工具获取响应中事实错误的证据；第二，要求LLM根据第一步中收集的证据解释响应中的问题部分；最后，LLM使用在第二步中获得的解释对响应进行修订。除了说明步骤，我们还提出了新的提示技术，以减少所需的标记数量和挂钟时间。

    arXiv:2402.17097v1 Announce Type: cross  Abstract: Mitigating hallucination issues is one of the main challenges of LLMs we need to overcome, in order to reliably use them in real-world scenarios. Recently, various methods are proposed to check the factual errors in the LLM-generated texts and revise them accordingly, to reduce the hallucination issue. In this paper, we propose Re-Ex, a method of revising LLM-generated texts, which introduces a novel step dubbed as the factual error explanation step. Re-Ex revises the initial response of LLMs using 3-steps: first, external tools are used to get the evidences on the factual errors in the response; second, LLMs are instructed to explain the problematic parts of the response based on the evidences gathered in the first step; finally, LLMs revise the response using the explanation obtained in the second step. In addition to the explanation step, we propose new prompting techniques to reduce the amount of tokens and wall-clock time required
    
[^5]: COMPASS：利用语言建模对患者-治疗师联盟策略进行计算映射

    COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling

    [https://arxiv.org/abs/2402.14701](https://arxiv.org/abs/2402.14701)

    本文提出了一种名为COMPASS的新框架，通过分析心理治疗会话中的自然语言，直接推断治疗工作联盟，为临床精神病学提供了可解释性，并在识别与正在治疗的疾病相关的新兴模式方面发挥作用。

    

    治疗工作联盟是预测心理治疗治疗成功的关键因素。传统上，工作联盟评估依赖于治疗师和患者填写的问卷。本文提出了COMPASS，一个新颖的框架，可直接从心理治疗课程中使用的自然语言中推断治疗工作联盟。我们的方法利用先进的大型语言模型分析心理治疗会话的转录，并将其与工作联盟清单中陈述的分布式表示进行比较。通过分析涵盖多种精神疾病的超过950个会话的数据集，我们展示了我们的方法在显微地映射患者-治疗师对齐轨迹方面的有效性，并为临床精神病学提供解释性，并在识别与正在治疗的疾病相关的新兴模式方面提供可解释性。通过使用各种神经主题模式

    arXiv:2402.14701v1 Announce Type: cross  Abstract: The therapeutic working alliance is a critical factor in predicting the success of psychotherapy treatment. Traditionally, working alliance assessment relies on questionnaires completed by both therapists and patients. In this paper, we present COMPASS, a novel framework to directly infer the therapeutic working alliance from the natural language used in psychotherapy sessions. Our approach utilizes advanced large language models to analyze transcripts of psychotherapy sessions and compare them with distributed representations of statements in the working alliance inventory. Analyzing a dataset of over 950 sessions covering diverse psychiatric conditions, we demonstrate the effectiveness of our method in microscopically mapping patient-therapist alignment trajectories and providing interpretability for clinical psychiatry and in identifying emerging patterns related to the condition being treated. By employing various neural topic mode
    
[^6]: LLM4SBR: 一个轻量且有效的框架，用于在基于会话的推荐中集成大型语言模型

    LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation

    [https://arxiv.org/abs/2402.13840](https://arxiv.org/abs/2402.13840)

    该研究提出了LLM4SBR框架，是第一个适合在基于会话的推荐中集成大型语言模型的轻量且有效框架。

    

    传统的基于会话的推荐(SBR)利用来自匿名用户的会话行为序列进行推荐。虽然这种策略非常高效，但牺牲了商品的固有语义信息，使模型难以理解会话的真正意图，导致推荐结果缺乏可解释性。近年来，大型语言模型(LLMs)在各个领域蓬勃发展，为解决上述挑战带来了一线希望。受LLMs影响，探讨LLMs与推荐系统(RS)集成的研究如雨后春笋般涌现。然而，受限于高时间和空间成本，以及会话数据短暂且匿名的特性，第一个适合工业部署的LLM推荐框架在SBR领域尚未出现。为了解决上述挑战，我们...

    arXiv:2402.13840v1 Announce Type: cross  Abstract: Traditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation. Although this strategy is highly efficient, it sacrifices the inherent semantic information of the items, making it difficult for the model to understand the true intent of the session and resulting in a lack of interpretability in the recommended results. Recently, large language models (LLMs) have flourished across various domains, offering a glimpse of hope in addressing the aforementioned challenges. Inspired by the impact of LLMs, research exploring the integration of LLMs with the Recommender system (RS) has surged like mushrooms after rain. However, constrained by high time and space costs, as well as the brief and anonymous nature of session data, the first LLM recommendation framework suitable for industrial deployment has yet to emerge in the field of SBR. To address the aforementioned challenges, we hav
    
[^7]: 自适应骨架图解码

    Adaptive Skeleton Graph Decoding

    [https://arxiv.org/abs/2402.12280](https://arxiv.org/abs/2402.12280)

    提出了骨架图解码（SGD）方法，利用子问题之间的依赖关系进行信息转发，改善响应质量且提高性能。

    

    大型语言模型（LLMs）已经在自然语言任务中得到广泛应用，其成功归因于大量的模型参数（例如，70亿+）；然而，LLM推断会产生巨大的计算和内存成本。最近的方法提出了并行解码策略，例如“思想骨架”（SoT），通过将提示分解为可以并行解码的子问题来改善性能；但是，它们往往在响应质量上遭受损失。我们的关键见解是，在生成子问题时，我们可以请求额外信息，特别是依赖关系和难度，以提高响应质量和性能。在本文中，我们提出了骨架图解码（SGD），利用子问题之间暴露的依赖关系，支持依赖子问题之间的信息转发，以提高质量，同时暴露独立子问题解码的并行化机会。

    arXiv:2402.12280v1 Announce Type: cross  Abstract: Large language models (LLMs) have seen significant adoption for natural language tasks, owing their success to massive numbers of model parameters (e.g., 70B+); however, LLM inference incurs significant computation and memory costs. Recent approaches propose parallel decoding strategies, such as Skeleton-of-Thought (SoT), to improve performance by breaking prompts down into sub-problems that can be decoded in parallel; however, they often suffer from reduced response quality. Our key insight is that we can request additional information, specifically dependencies and difficulty, when generating the sub-problems to improve both response quality and performance. In this paper, we propose Skeleton Graph Decoding (SGD), which uses dependencies exposed between sub-problems to support information forwarding between dependent sub-problems for improved quality while exposing parallelization opportunities for decoding independent sub-problems. 
    
[^8]: 生成式AI代理之间的秘密勾结

    Secret Collusion Among Generative AI Agents

    [https://arxiv.org/abs/2402.07510](https://arxiv.org/abs/2402.07510)

    本文汇集了人工智能和安全领域的相关概念，系统地形式化了生成式AI代理系统中的秘密勾结问题，并提出了缓解措施。通过测试各种形式的秘密勾结所需的能力，我们发现当前模型的隐写能力有限，但 GPT-4 展示了能力的飞跃。

    

    最近大型语言模型在能力上的增强为通信的生成式AI代理团队解决联合任务的应用打开了可能性。这引发了关于未经授权分享信息或其他不必要的代理协调形式的隐私和安全挑战。现代隐写术技术可能使这种动态难以检测。本文通过汲取人工智能和安全领域相关概念，全面系统地形式化了生成式AI代理系统中的秘密勾结问题。我们研究了使用隐写术的动机，并提出了各种缓解措施。我们的研究结果是一个模型评估框架，系统地测试了各种形式的秘密勾结所需的能力。我们在各种当代大型语言模型上提供了广泛的实证结果。虽然当前模型的隐写能力仍然有限，但 GPT-4 显示出能力的飞跃，这表明有必要进行进一步的研究。

    Recent capability increases in large language models (LLMs) open up applications in which teams of communicating generative AI agents solve joint tasks. This poses privacy and security challenges concerning the unauthorised sharing of information, or other unwanted forms of agent coordination. Modern steganographic techniques could render such dynamics hard to detect. In this paper, we comprehensively formalise the problem of secret collusion in systems of generative AI agents by drawing on relevant concepts from both the AI and security literature. We study incentives for the use of steganography, and propose a variety of mitigation measures. Our investigations result in a model evaluation framework that systematically tests capabilities required for various forms of secret collusion. We provide extensive empirical results across a range of contemporary LLMs. While the steganographic capabilities of current models remain limited, GPT-4 displays a capability jump suggesting the need fo
    
[^9]: 通过整合外延知识和内涵知识嵌入本体

    Embedding Ontologies via Incoprorating Extensional and Intensional Knowledge

    [https://arxiv.org/abs/2402.01677](https://arxiv.org/abs/2402.01677)

    本文提出了一种新型本体嵌入方法EIKE，通过整合外延知识和内涵知识，在外延空间和内涵空间中表示本体，并采用基于几何的方法和预训练的语言模型对实例、概念和关系进行嵌入建模。

    

    本体包含领域内丰富的知识，可以分为两个类别，即外延知识和内涵知识。外延知识提供关于本体中特定概念所属的具体实例的信息，而内涵知识详细描述了概念之间的内在属性、特征和语义关联。然而，现有的本体嵌入方法未能同时充分考虑外延知识和内涵知识。在本文中，我们提出了一种名为EIKE（Extensional and Intensional Knowledge Embedding）的新型本体嵌入方法，通过在外延空间和内涵空间中表示本体。EIKE提出了一个统一的框架，用于将实例、概念及其关系嵌入到本体中，采用基于几何的方法对外延知识进行建模，并使用预训练的语言模型对内涵知识进行建模。

    Ontologies contain rich knowledge within domain, which can be divided into two categories, namely extensional knowledge and intensional knowledge. Extensional knowledge provides information about the concrete instances that belong to specific concepts in the ontology, while intensional knowledge details inherent properties, characteristics, and semantic associations among concepts. However, existing ontology embedding approaches fail to take both extensional knowledge and intensional knowledge into fine consideration simultaneously. In this paper, we propose a novel ontology embedding approach named EIKE (Extensional and Intensional Knowledge Embedding) by representing ontologies in two spaces, called extensional space and intensional space. EIKE presents a unified framework for embedding instances, concepts and their relations in an ontology, applying a geometry-based method to model extensional knowledge and a pretrained language model to model intensional knowledge, which can captur
    
[^10]: 通过DeepFool算法对深度神经网络进行有针对性的类别操纵的对抗攻击定制

    Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm. (arXiv:2310.13019v1 [cs.CV])

    [http://arxiv.org/abs/2310.13019](http://arxiv.org/abs/2310.13019)

    本文提出了一种增强版DeepFool算法，名为Targeted DeepFool，可以针对特定类别进行错误分类，并引入了最小置信度分数要求超参数来提高灵活性。

    

    深度神经网络（DNNs）在各个领域都取得了显著的进展，但对抗攻击的易受攻击性引起了严重关注。了解这些易受攻击性并开发有效的防御机制至关重要。DeepFool是Moosavi-Dezfooli等人（2016年）提出的一种算法，用于找到将输入图像错误分类的最小扰动。然而，DeepFool缺乏有针对性的方法，使其在特定攻击场景中的有效性较低。此外，在先前的相关工作中，研究人员主要关注的是成功率，而没有考虑图像被扭曲的程度、图像质量的完整性以及错误分类的置信度水平。因此，在本文中，我们提出了Targeted DeepFool，这是DeepFool的增强版，可以针对特定类别进行错误分类。我们还引入了一个最小置信度分数要求超参数来增强灵活性。我们的实验证明了所提方法在不同情况下的有效性和效率。

    Deep neural networks (DNNs) have significantly advanced various domains, but their vulnerability to adversarial attacks poses serious concerns. Understanding these vulnerabilities and developing effective defense mechanisms is crucial. DeepFool, an algorithm proposed by Moosavi-Dezfooli et al. (2016), finds minimal perturbations to misclassify input images. However, DeepFool lacks a targeted approach, making it less effective in specific attack scenarios. Also, in previous related works, researchers primarily focus on success, not considering how much an image is getting distorted; the integrity of the image quality, and the confidence level to misclassifying. So, in this paper, we propose Targeted DeepFool, an augmented version of DeepFool that allows targeting specific classes for misclassification. We also introduce a minimum confidence score requirement hyperparameter to enhance flexibility. Our experiments demonstrate the effectiveness and efficiency of the proposed method across 
    
[^11]: 为人类助力灵巧抓取学习基于得分的抓取原语

    Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping. (arXiv:2309.06038v1 [cs.RO])

    [http://arxiv.org/abs/2309.06038](http://arxiv.org/abs/2309.06038)

    本文提出了一个名为“人类助力灵巧抓取”的新型任务，通过使用Grasping Gradient Field和基于历史条件的残差策略，训练控制机器人手指以适应不同用户意图和物体几何形状的灵巧抓取操作。

    

    在本文中，我们提出了一种名为“人类助力灵巧抓取”的新型任务，旨在训练控制机器人手指以帮助用户抓取物体的策略。与传统的灵巧抓取不同，这个任务面临着更复杂的挑战，因为策略需要适应不同的用户意图和物体的几何形状。我们通过提出一个由两个子模块组成的方法来解决这个挑战：一种手-物体条件抓取原语称为Grasping Gradient Field（GraspGF），以及一种基于历史条件的残差策略。GraspGF通过估计来自成功抓取示例集的梯度来学习“如何”抓取，而残差策略根据轨迹历史确定“何时”和以何种速度执行抓取动作。实验结果证明了我们方法的有效性。

    The use of anthropomorphic robotic hands for assisting individuals in situations where human hands may be unavailable or unsuitable has gained significant importance. In this paper, we propose a novel task called human-assisting dexterous grasping that aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task presents a more complex challenge as the policy needs to adapt to diverse user intentions, in addition to the object's geometry. We address this challenge by proposing an approach consisting of two sub-modules: a hand-object-conditional grasping primitive called Grasping Gradient Field~(GraspGF), and a history-conditional residual policy. GraspGF learns `how' to grasp by estimating the gradient from a success grasping example set, while the residual policy determines `when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results demons
    
[^12]: 深度学习中的损失函数和度量方法：一项评论

    Loss Functions and Metrics in Deep Learning. A Review. (arXiv:2307.02694v1 [cs.LG])

    [http://arxiv.org/abs/2307.02694](http://arxiv.org/abs/2307.02694)

    本文回顾了深度学习中最常见的损失函数和性能测量方法，旨在帮助从业者选择最适合其特定任务的方法。

    

    深度学习的一个重要组成部分是选择用于训练和评估模型的损失函数和性能度量。本文回顾了深度学习中最常见的损失函数和性能测量方法。我们探讨了每种技术的优势和局限性，并举例说明它们在各种深度学习问题上的应用。我们的评论旨在全面了解最常见的深度学习任务中使用的不同损失函数和性能指标，并帮助从业者选择最适合其特定任务的方法。

    One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models. This paper reviews the most prevalent loss functions and performance measurements in deep learning. We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems. Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task.
    

