# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Towards the new XAI: A Hypothesis-Driven Approach to Decision Support Using Evidence](https://rss.arxiv.org/abs/2402.01292) | 本文介绍并评估了一种基于证据权重框架的假设驱动可解释人工智能方法，通过提供支持或驳斥假设的证据来增加决策准确性和减少依赖程度。 |

# 详细

[^1]: 迈向新的可解释人工智能：通过证据支持的假设驱动方法的决策支持

    Towards the new XAI: A Hypothesis-Driven Approach to Decision Support Using Evidence

    [https://rss.arxiv.org/abs/2402.01292](https://rss.arxiv.org/abs/2402.01292)

    本文介绍并评估了一种基于证据权重框架的假设驱动可解释人工智能方法，通过提供支持或驳斥假设的证据来增加决策准确性和减少依赖程度。

    

    之前关于AI辅助人类决策的研究探索了几种不同的可解释人工智能（XAI）方法。最近的一篇论文提出了一种范式转变，呼吁通过一个称为评价型AI的概念框架来进行假设驱动的XAI，该框架为人们提供支持或驳斥假设的证据，而不一定给出决策辅助推荐。在本文中，我们描述并评估了一种基于证据权重（WoE）框架的假设驱动XAI方法，该方法为给定的假设生成正面和负面证据。通过人类行为实验，我们展示了我们的假设驱动方法提高了决策准确性，与推荐驱动方法和仅AI解释基线相比减少了依赖程度，但相对于推荐驱动方法，在依赖程度下降方面略微增加。此外，我们还展示了参与者在使用我们的假设驱动方法时与两个基线的方式存在实质性的差异。

    Prior research on AI-assisted human decision-making has explored several different explainable AI (XAI) approaches. A recent paper has proposed a paradigm shift calling for hypothesis-driven XAI through a conceptual framework called evaluative AI that gives people evidence that supports or refutes hypotheses without necessarily giving a decision-aid recommendation. In this paper we describe and evaluate an approach for hypothesis-driven XAI based on the Weight of Evidence (WoE) framework, which generates both positive and negative evidence for a given hypothesis. Through human behavioural experiments, we show that our hypothesis-driven approach increases decision accuracy, reduces reliance compared to a recommendation-driven approach and an AI-explanation-only baseline, but with a small increase in under-reliance compared to the recommendation-driven approach. Further, we show that participants used our hypothesis-driven approach in a materially different way to the two baselines.
    

