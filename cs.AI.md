# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Are Colors Quanta of Light for Human Vision? A Quantum Cognition Study of Visual Perception](https://arxiv.org/abs/2403.18850) | 该研究揭示了量子测量过程中范畴感知现象的机制，认为颜色在人类视觉中可以被视为光子，为视觉感知提供了新的量子认知视角。 |
| [^2] | [Evaluating Fairness Metrics Across Borders from Human Perceptions](https://arxiv.org/abs/2403.16101) | 该研究通过国际调查评估了不同国家对其决策情景中各种公平度量标准的适用性。 |
| [^3] | [FreDF: Learning to Forecast in Frequency Domain](https://arxiv.org/abs/2402.02399) | FreDF是一种在频域中学习预测的方法，解决了时间序列建模中标签序列的自相关问题，相比现有方法有更好的性能表现，并且与各种预测模型兼容。 |
| [^4] | [Incoherent Probability Judgments in Large Language Models.](http://arxiv.org/abs/2401.16646) | 在本论文中，研究人员通过对大型语言模型(LLMs)进行实验证明，这些模型产生的概率判断经常是不连贯的，显示出类似于人类一样的非理性偏差。他们还提出了将自回归LLMs与隐性贝叶斯推断联系起来的解释。 |
| [^5] | [A backdoor attack against link prediction tasks with graph neural networks.](http://arxiv.org/abs/2401.02663) | 本文研究了一种针对图神经网络链接预测任务的后门攻击方法，发现GNN模型容易受到后门攻击，提出了针对该任务的后门攻击方式。 |
| [^6] | [Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using Large Language Models.](http://arxiv.org/abs/2310.07937) | Co-NavGPT是一个创新的框架，使用大型语言模型作为全局规划器，实现多机器人合作的视觉目标导航。在实验中表现出了超越现有模型的成功率和效率，展示了大型语言模型的巨大潜力。 |
| [^7] | [ParFam -- Symbolic Regression Based on Continuous Global Optimization.](http://arxiv.org/abs/2310.05537) | ParFam是一种新的符号回归方法，利用参数化的符号函数族将离散问题转化为连续问题，并结合全局优化器，能够有效解决符号回归问题。 |
| [^8] | [Towards A Robust Group-level Emotion Recognition via Uncertainty-Aware Learning.](http://arxiv.org/abs/2310.04306) | 本文提出了一种考虑不确定性的学习方法用于群体级情绪识别。通过模型化每个个体的不确定性，利用随机嵌入来代替确定性的点嵌入。这种表示能够捕捉概率和在推断阶段产生多样的预测。 |
| [^9] | [q-Learning in Continuous Time.](http://arxiv.org/abs/2207.00713) | 本文研究了连续时间下的q-Learning，通过引入小q函数作为一阶近似，研究了q-learning理论，应用于设计不同的演员-评论家算法。 |

# 详细

[^1]: 人类视觉中颜色是否是光子？视觉知觉的量子认知研究

    Are Colors Quanta of Light for Human Vision? A Quantum Cognition Study of Visual Perception

    [https://arxiv.org/abs/2403.18850](https://arxiv.org/abs/2403.18850)

    该研究揭示了量子测量过程中范畴感知现象的机制，认为颜色在人类视觉中可以被视为光子，为视觉感知提供了新的量子认知视角。

    

    我们研究了量子测量过程中范畴感知的现象。该现象的机制在于被感知的扩散刺激被认为属于不同类别，而被感知的收缩刺激被认为属于相同类别。我们展示了，由于纯态之间的距离与密度态之间的距离的确定方式自然不同，因此范畴感知现象根植于量子测量过程的结构中。我们将研究结果应用于颜色的视觉感知情况，并认为可以将颜色视为人类视觉感知中的光子，类似于光频物理测量中的光子。在我们的方法中，我们将知觉看作是现有物理现实、刺激以及被感知者所期望的现实之间的复杂相遇。

    arXiv:2403.18850v1 Announce Type: cross  Abstract: We study the phenomenon of categorical perception within the quantum measurement process. The mechanism underlying this phenomenon consists in dilating stimuli being perceived to belong to different categories and contracting stimuli being perceived to belong to the same category. We show that, due to the naturally different way in determining the distance between pure states compared to the distance between density states, the phenomenon of categorical perception is rooted in the structure of the quantum measurement process itself. We apply our findings to the situation of visual perception of colors and argue that it is possible to consider colors as light quanta for human visual perception in a similar way as photons are light quanta for physical measurements of light frequencies. In our approach we see perception as a complex encounter between the existing physical reality, the stimuli, and the reality expected by the perciever, re
    
[^2]: 跨国界评估公平度量标准：来自人类感知的视角

    Evaluating Fairness Metrics Across Borders from Human Perceptions

    [https://arxiv.org/abs/2403.16101](https://arxiv.org/abs/2403.16101)

    该研究通过国际调查评估了不同国家对其决策情景中各种公平度量标准的适用性。

    

    哪些公平度量标准适用于您的场景？即使结果符合已建立的公平度量标准，也可能存在关于公平感知的不一致情况。已进行了多项调查，评估了公平度量标准与人们对公平的感知。然而，这些调查范围有限，仅包括单个国家中数百名参与者。在这项研究中，我们进行了一项国际调查，以评估各种公平度量标准在决策场景中的适用性。我们分别从中国、法国、日本和美国的每个国家收集了1,000名参与者的回应，总计得到了4,000个回应，以分析公平度量标准的偏好。我们的调查包括三个不同场景，配备了四种公平度量标准，每个参与者在每种情况下选择其喜好的公平度量标准。该研究探讨了

    arXiv:2403.16101v1 Announce Type: new  Abstract: Which fairness metrics are appropriately applicable in your contexts? There may be instances of discordance regarding the perception of fairness, even when the outcomes comply with established fairness metrics. Several surveys have been conducted to evaluate fairness metrics with human perceptions of fairness. However, these surveys were limited in scope, including only a few hundred participants within a single country. In this study, we conduct an international survey to evaluate the appropriateness of various fairness metrics in decision-making scenarios. We collected responses from 1,000 participants in each of China, France, Japan, and the United States, amassing a total of 4,000 responses, to analyze the preferences of fairness metrics. Our survey consists of three distinct scenarios paired with four fairness metrics, and each participant answers their preference for the fairness metric in each case. This investigation explores the
    
[^3]: FreDF: 在频域中学习预测

    FreDF: Learning to Forecast in Frequency Domain

    [https://arxiv.org/abs/2402.02399](https://arxiv.org/abs/2402.02399)

    FreDF是一种在频域中学习预测的方法，解决了时间序列建模中标签序列的自相关问题，相比现有方法有更好的性能表现，并且与各种预测模型兼容。

    

    时间序列建模在历史序列和标签序列中都面临自相关的挑战。当前的研究主要集中在处理历史序列中的自相关问题，但往往忽视了标签序列中的自相关存在。具体来说，新兴的预测模型主要遵循直接预测（DF）范式，在标签序列中假设条件独立性下生成多步预测。这种假设忽视了标签序列中固有的自相关性，从而限制了基于DF的模型的性能。针对这一问题，我们引入了频域增强直接预测（FreDF），通过在频域中学习预测来避免标签自相关的复杂性。我们的实验证明，FreDF在性能上大大超过了包括iTransformer在内的现有最先进方法，并且与各种预测模型兼容。

    Time series modeling is uniquely challenged by the presence of autocorrelation in both historical and label sequences. Current research predominantly focuses on handling autocorrelation within the historical sequence but often neglects its presence in the label sequence. Specifically, emerging forecast models mainly conform to the direct forecast (DF) paradigm, generating multi-step forecasts under the assumption of conditional independence within the label sequence. This assumption disregards the inherent autocorrelation in the label sequence, thereby limiting the performance of DF-based models. In response to this gap, we introduce the Frequency-enhanced Direct Forecast (FreDF), which bypasses the complexity of label autocorrelation by learning to forecast in the frequency domain. Our experiments demonstrate that FreDF substantially outperforms existing state-of-the-art methods including iTransformer and is compatible with a variety of forecast models.
    
[^4]: 大型语言模型中的不连贯概率判断

    Incoherent Probability Judgments in Large Language Models. (arXiv:2401.16646v1 [cs.CL])

    [http://arxiv.org/abs/2401.16646](http://arxiv.org/abs/2401.16646)

    在本论文中，研究人员通过对大型语言模型(LLMs)进行实验证明，这些模型产生的概率判断经常是不连贯的，显示出类似于人类一样的非理性偏差。他们还提出了将自回归LLMs与隐性贝叶斯推断联系起来的解释。

    

    针对下一个词预测训练的自回归大型语言模型(LLMs)展示出出色的连贯文本生成能力。但它们是否同样擅长形成连贯的概率判断？我们使用概率身份和重复判断来评估LLMs生成的概率判断的连贯性。我们的结果显示，这些模型产生的判断经常是不连贯的，显示出人类一样的概率理论规则偏离。此外，当要求对同一事件进行判断时，LLMs产生的概率判断的均值-方差关系呈现出人类所见到的倒U形状。我们提出这些非理性的偏离可以通过将自回归LLMs与隐性贝叶斯推断联系起来，并与人类概率判断的贝叶斯抽样器模型进行类比来解释。

    Autoregressive Large Language Models (LLMs) trained for next-word prediction have demonstrated remarkable proficiency at producing coherent text. But are they equally adept at forming coherent probability judgments? We use probabilistic identities and repeated judgments to assess the coherence of probability judgments made by LLMs. Our results show that the judgments produced by these models are often incoherent, displaying human-like systematic deviations from the rules of probability theory. Moreover, when prompted to judge the same event, the mean-variance relationship of probability judgments produced by LLMs shows an inverted-U-shaped like that seen in humans. We propose that these deviations from rationality can be explained by linking autoregressive LLMs to implicit Bayesian inference and drawing parallels with the Bayesian Sampler model of human probability judgments.
    
[^5]: 用于图神经网络链接预测任务的后门攻击

    A backdoor attack against link prediction tasks with graph neural networks. (arXiv:2401.02663v1 [cs.LG])

    [http://arxiv.org/abs/2401.02663](http://arxiv.org/abs/2401.02663)

    本文研究了一种针对图神经网络链接预测任务的后门攻击方法，发现GNN模型容易受到后门攻击，提出了针对该任务的后门攻击方式。

    

    图神经网络（GNN）是一类能够处理图结构数据的深度学习模型，在各种实际应用中表现出显著的性能。最近的研究发现，GNN模型容易受到后门攻击。当具体的模式（称为后门触发器，例如子图、节点等）出现在输入数据中时，嵌入在GNN模型中的后门会被激活，将输入数据误分类为攻击者指定的目标类标签，而当输入中没有后门触发器时，嵌入在GNN模型中的后门不会被激活，模型正常工作。后门攻击具有极高的隐蔽性，给GNN模型带来严重的安全风险。目前，对GNN的后门攻击研究主要集中在图分类和节点分类等任务上，对链接预测任务的后门攻击研究较少。在本文中，我们提出一种后门攻击方法。

    Graph Neural Networks (GNNs) are a class of deep learning models capable of processing graph-structured data, and they have demonstrated significant performance in a variety of real-world applications. Recent studies have found that GNN models are vulnerable to backdoor attacks. When specific patterns (called backdoor triggers, e.g., subgraphs, nodes, etc.) appear in the input data, the backdoor embedded in the GNN models is activated, which misclassifies the input data into the target class label specified by the attacker, whereas when there are no backdoor triggers in the input, the backdoor embedded in the GNN models is not activated, and the models work normally. Backdoor attacks are highly stealthy and expose GNN models to serious security risks. Currently, research on backdoor attacks against GNNs mainly focus on tasks such as graph classification and node classification, and backdoor attacks against link prediction tasks are rarely studied. In this paper, we propose a backdoor a
    
[^6]: Co-NavGPT: 使用大型语言模型的多机器人合作视觉语义导航

    Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using Large Language Models. (arXiv:2310.07937v1 [cs.RO])

    [http://arxiv.org/abs/2310.07937](http://arxiv.org/abs/2310.07937)

    Co-NavGPT是一个创新的框架，使用大型语言模型作为全局规划器，实现多机器人合作的视觉目标导航。在实验中表现出了超越现有模型的成功率和效率，展示了大型语言模型的巨大潜力。

    

    在高级人机交互任务中，对于自主机器人在未知环境中进行视觉目标导航至关重要。尽管过去已经开发了许多方法，但大多数都是设计用于单一机器人操作，这往往由于环境复杂性而导致效率和鲁棒性降低。此外，学习多机器人协作的策略需要资源密集型。为了解决这些挑战，我们提出了Co-NavGPT，这是一个创新的框架，将大型语言模型(LLMs)作为多机器人合作视觉目标导航的全局规划器。Co-NavGPT将探索的环境数据编码为提示，增强LLMs对场景的理解。然后，它为每个机器人分配探索前沿以实现高效的目标搜索。在Habitat-Matterport 3D (HM3D)上的实验结果表明，Co-NavGPT在成功率和效率方面超过了现有模型，而无需任何学习过程，展示了LLMs的巨大潜力。

    In advanced human-robot interaction tasks, visual target navigation is crucial for autonomous robots navigating unknown environments. While numerous approaches have been developed in the past, most are designed for single-robot operations, which often suffer from reduced efficiency and robustness due to environmental complexities. Furthermore, learning policies for multi-robot collaboration are resource-intensive. To address these challenges, we propose Co-NavGPT, an innovative framework that integrates Large Language Models (LLMs) as a global planner for multi-robot cooperative visual target navigation. Co-NavGPT encodes the explored environment data into prompts, enhancing LLMs' scene comprehension. It then assigns exploration frontiers to each robot for efficient target search. Experimental results on Habitat-Matterport 3D (HM3D) demonstrate that Co-NavGPT surpasses existing models in success rates and efficiency without any learning process, demonstrating the vast potential of LLMs
    
[^7]: ParFam - 基于连续全局优化的符号回归

    ParFam -- Symbolic Regression Based on Continuous Global Optimization. (arXiv:2310.05537v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.05537](http://arxiv.org/abs/2310.05537)

    ParFam是一种新的符号回归方法，利用参数化的符号函数族将离散问题转化为连续问题，并结合全局优化器，能够有效解决符号回归问题。

    

    符号回归（SR）问题在许多不同的应用中出现，比如从给定数据中识别物理定律或推导描述金融市场行为的数学方程。目前存在多种解决SR问题的方法，通常基于遗传编程。然而，这些方法通常非常复杂，需要大量超参数调整和计算资源。本文介绍了我们提出的新方法ParFam，它利用适合的符号函数的参数化族将离散的符号回归问题转化为连续问题，相比当前最先进的方法，这种方法的设置更加直观。结合强大的全局优化器，这种方法可以有效地解决SR问题。此外，它可以轻松扩展到更高级的算法，例如添加深度神经网络以找到适合的参数化族。我们证明了这种方法的性能。

    The problem of symbolic regression (SR) arises in many different applications, such as identifying physical laws or deriving mathematical equations describing the behavior of financial markets from given data. Various methods exist to address the problem of SR, often based on genetic programming. However, these methods are usually quite complicated and require a lot of hyperparameter tuning and computational resources. In this paper, we present our new method ParFam that utilizes parametric families of suitable symbolic functions to translate the discrete symbolic regression problem into a continuous one, resulting in a more straightforward setup compared to current state-of-the-art methods. In combination with a powerful global optimizer, this approach results in an effective method to tackle the problem of SR. Furthermore, it can be easily extended to more advanced algorithms, e.g., by adding a deep neural network to find good-fitting parametric families. We prove the performance of 
    
[^8]: 通过考虑不确定性的学习方法实现鲁棒的群体级情绪识别

    Towards A Robust Group-level Emotion Recognition via Uncertainty-Aware Learning. (arXiv:2310.04306v1 [cs.CV])

    [http://arxiv.org/abs/2310.04306](http://arxiv.org/abs/2310.04306)

    本文提出了一种考虑不确定性的学习方法用于群体级情绪识别。通过模型化每个个体的不确定性，利用随机嵌入来代替确定性的点嵌入。这种表示能够捕捉概率和在推断阶段产生多样的预测。

    

    群体级情绪识别是人类行为分析中不可分割的一部分，旨在识别多人场景中的整体情绪。然而，现有方法致力于整合不同的情绪线索，而忽视了在无约束环境下存在的团体内拥挤和遮挡等固有不确定性。此外，由于仅有群体级标签可用，在一个群体中个体之间的不一致情绪预测会混淆网络。在本文中，我们提出了一种考虑不确定性的学习方法，为群体级情绪识别提取更加鲁棒的表示。通过明确地建模每个个体的不确定性，我们利用高斯分布中的随机嵌入来代替确定性的点嵌入。这种表示捕捉了不同情绪的概率，并通过这种随机性在推断阶段产生多样的预测。

    Group-level emotion recognition (GER) is an inseparable part of human behavior analysis, aiming to recognize an overall emotion in a multi-person scene. However, the existing methods are devoted to combing diverse emotion cues while ignoring the inherent uncertainties under unconstrained environments, such as congestion and occlusion occurring within a group. Additionally, since only group-level labels are available, inconsistent emotion predictions among individuals in one group can confuse the network. In this paper, we propose an uncertainty-aware learning (UAL) method to extract more robust representations for GER. By explicitly modeling the uncertainty of each individual, we utilize stochastic embedding drawn from a Gaussian distribution instead of deterministic point embedding. This representation captures the probabilities of different emotions and generates diverse predictions through this stochasticity during the inference stage. Furthermore, uncertainty-sensitive scores are a
    
[^9]: 连续时间下的q-Learning

    q-Learning in Continuous Time. (arXiv:2207.00713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.00713](http://arxiv.org/abs/2207.00713)

    本文研究了连续时间下的q-Learning，通过引入小q函数作为一阶近似，研究了q-learning理论，应用于设计不同的演员-评论家算法。

    

    我们研究了基于熵正则化的探索性扩散过程的Q-learning在连续时间下的应用。我们引入了“小q函数”作为大Q函数的一阶近似，研究了q函数的q-learning理论，并应用于设计不同的演员-评论家算法。

    We study the continuous-time counterpart of Q-learning for reinforcement learning (RL) under the entropy-regularized, exploratory diffusion process formulation introduced by Wang et al. (2020). As the conventional (big) Q-function collapses in continuous time, we consider its first-order approximation and coin the term ``(little) q-function". This function is related to the instantaneous advantage rate function as well as the Hamiltonian. We develop a ``q-learning" theory around the q-function that is independent of time discretization. Given a stochastic policy, we jointly characterize the associated q-function and value function by martingale conditions of certain stochastic processes, in both on-policy and off-policy settings. We then apply the theory to devise different actor-critic algorithms for solving underlying RL problems, depending on whether or not the density function of the Gibbs measure generated from the q-function can be computed explicitly. One of our algorithms inter
    

