# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Compressing Large Language Models by Streamlining the Unimportant Layer](https://arxiv.org/abs/2403.19135) | 通过观察大型语言模型中不同层对隐藏状态的影响程度，提出了LLM-Streamline方法，包括层剪枝和层替换，用于压缩模型并保持性能。 |
| [^2] | [Understanding the Functional Roles of Modelling Components in Spiking Neural Networks](https://arxiv.org/abs/2403.16674) | 系统研究揭示了尖峰神经网络中滤泄、重置和循环等建模组件在平衡记忆保留、时间处理和动态建模方面的功能角色。 |
| [^3] | [MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis](https://arxiv.org/abs/2403.15585) | MedPromptX是第一个将多模态大型语言模型、少样本提示和视觉基础相结合，用于胸部X线诊断的模型，通过补充缺失的EHR信息，有效解决了幻觉问题，但选择最佳少样本示例和高质量候选者仍有待解决。 |
| [^4] | [A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond](https://arxiv.org/abs/2403.14734) | 神经代码智能领域的调查系统回顾了50多种代表性模型和超过680项相关作品，突出了不同研究阶段的范式和技术转变。 |
| [^5] | [Merino: Entropy-driven Design for Generative Language Models on IoT Devices](https://arxiv.org/abs/2403.07921) | 在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型，通过最大化transformer解码器的熵来在计算预算内，成功设计了MeRino模型，在移动设置下展现出与当前最先进的自回归transformer模型竞争性能的特点 |
| [^6] | [KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](https://arxiv.org/abs/2403.03101) | KnowAgent引入了显式动作知识，通过动作知识库和知识型自学习策略来增强LLM的规划能力，从而改善语言Agent的规划表现。 |
| [^7] | [Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning](https://arxiv.org/abs/2402.17217) | 提出了时间逻辑规范条件化决策转换器（SDT）框架，结合信号时间逻辑（STL）和决策转换器（DT）的能力，比现有方法在离线安全强化学习中学习出更好的安全高奖励策略。 |
| [^8] | [Studying the Impact of Stochasticity on the Evaluation of Deep Neural Networks for Forest-Fire Prediction](https://arxiv.org/abs/2402.15163) | 该论文首次系统研究了在随机假设下评估深度神经网络用于森林火灾预测的影响，发现评估对统计的忠实度是在高度随机场景下的可靠替代方法。 |
| [^9] | [Self-DC: When to retrieve and When to generate? Self Divide-and-Conquer for Compositional Unknown Questions](https://arxiv.org/abs/2402.13514) | 提出了面向组合未知问题的自我分而治之算法，引入了第一个组合未知问题问答数据集（CuQA），通过自适应调用不同方法实现更好的性能和效率。 |
| [^10] | [Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning](https://arxiv.org/abs/2402.03667) | 本文提出了一种大型语言模型的新型间接推理方法，使用反证和矛盾的逻辑来处理复杂推理任务，并通过增强数据和规则，以及设计提示模板的方式增强模型的推理能力。 |
| [^11] | [Large Language Model Distilling Medication Recommendation Model](https://arxiv.org/abs/2402.02803) | 本研究旨在利用大型语言模型改进药物推荐方法，以解决传统模型在医学数据语义理解和新患者处方推荐方面的挑战。 |
| [^12] | [Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models](https://arxiv.org/abs/2312.14197) | 该研究引入了第一个间接提示注入攻击基准测试BIPIA，对大型语言模型在面对此类攻击时的风险进行评估，并分析了攻击成功的原因，从而开发了防御方法。 |
| [^13] | [Compelling ReLU Network Initialization and Training to Leverage Exponential Scaling with Depth](https://arxiv.org/abs/2311.18022) | 该论文提出了一种新的训练策略，通过重新参数化网络权重，使得神经网络的指数数量的激活模式得以展现，从而得到远远超过随机初始化的结果。 |
| [^14] | [Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption.](http://arxiv.org/abs/2401.13444) | 该论文介绍了一种以低计算资源消耗为中心的高效知识库问答框架，通过引入线索引导路径探索的方式，将知识库与大型语言模型高效地融合，从而降低了对模型能力的要求，并在实验证明了其优越性能。 |
| [^15] | [CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks.](http://arxiv.org/abs/2401.05043) | CreINNs是一种用于分类任务的Credal-Set Interval Neural Networks，通过保留传统的区间神经网络结构，捕捉权重不确定性，并使用概率区间的数学框架预测可信区间。实验结果表明，CreINNs在不确定性估计方面优于变分贝叶斯神经网络和深度集成，并且具有较低的计算复杂度和模型大小。 |
| [^16] | [Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series.](http://arxiv.org/abs/2401.04979) | 我们提出了一种可逆解决非规则采样时间序列的神经微分方程分析方法，通过引入神经流的概念，我们的方法既保证了可逆性又降低了计算负担，并且在分类和插值任务中表现出了优异的性能。 |
| [^17] | [Turbulence: Systematically and Automatically Testing Instruction-Tuned Large Language Models for Code.](http://arxiv.org/abs/2312.14856) | 这项研究提出了一种通过新的基准测试Turbulence来系统评估针对代码生成的指令调整大型语言模型（LLMs）的正确性和鲁棒性的方法。通过构建一组问题模板，可以评估LLMs在解决相似编程问题时的准确性，并发现其代码生成能力的缺陷和异常情况。这项研究在五个LLMs上进行了实验。 |
| [^18] | [Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching.](http://arxiv.org/abs/2311.01248) | 本研究利用视觉触觉传感器和模仿学习相结合，通过配对优化触觉力量曲线和简化传感器应用，对接触丰富的操作任务进行了研究。 |
| [^19] | [Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models.](http://arxiv.org/abs/2311.00287) | 本文提出了一种通过大型语言模型进行临床文本生成的创新方法ClinGen，该方法将外部领域特定的知识和语言模型结合起来，提高了临床自然语言处理任务的性能，并丰富了样本的多样性。 |
| [^20] | [Causal Understanding of Why Users Share Hate Speech on Social Media.](http://arxiv.org/abs/2310.15772) | 本文研究了用户为何分享社交媒体上的仇恨言论，提出了一个因果分析框架，通过消除数据偏差和模拟用户脆弱性来揭示影响用户分享行为的因素。 |
| [^21] | [Large language models can replicate cross-cultural differences in personality.](http://arxiv.org/abs/2310.10679) | 大型语言模型GPT-4成功复制了使用十项人格问卷测量的大五人格的跨文化差异，但其结果表明平均评级有上升偏差和较低的变异性与结构效度。 |
| [^22] | [GenDOM: Generalizable One-shot Deformable Object Manipulation with Parameter-Aware Policy.](http://arxiv.org/abs/2309.09051) | GenDOM是一个框架，通过条件化操作策略和多样化模拟训练，使操作策略能够仅通过一个真实世界演示来处理不同的可变形物体，并通过最小化真实世界演示和模拟之间的点云格密度差异来估计新物体的可变形物体参数。 |
| [^23] | [SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption.](http://arxiv.org/abs/2307.00677) | 本文提出了一种基于密度的聚类算法，能够检测到高密度区域中的结构，具有先前算法所不具备的能力。 |
| [^24] | [Generalizable One-shot Rope Manipulation with Parameter-Aware Policy.](http://arxiv.org/abs/2306.09872) | GenORM通过增加可变形绳索参数和使用各种可变形绳索的模拟训练操作策略，实现利用一次真实演示处理不同可形变绳索，从而节省演示时间和提高适用性。 |
| [^25] | [Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep Learning Models.](http://arxiv.org/abs/2306.05497) | 本文研究了使用噪声鲁棒损失函数增强深度学习模型对标签噪声的鲁棒性，并提出了一种无需超参数调整的新技术：包括输出偏置。 |
| [^26] | [Collective Intelligence for 2D Push Manipulation with Mobile Robots.](http://arxiv.org/abs/2211.15136) | 本研究利用基于软体物理模拟器的规划器和基于注意力的神经网络，实现了移动机器人2D协作推动操作中的集体智能，比传统方法具有更好的性能并具备环境自适应能力。 |

# 详细

[^1]: 通过简化不重要的层压缩大型语言模型

    Compressing Large Language Models by Streamlining the Unimportant Layer

    [https://arxiv.org/abs/2403.19135](https://arxiv.org/abs/2403.19135)

    通过观察大型语言模型中不同层对隐藏状态的影响程度，提出了LLM-Streamline方法，包括层剪枝和层替换，用于压缩模型并保持性能。

    

    大型语言模型(LLM)已广泛应用于各种自然语言任务和领域，但其适用性受到模型参数的限制。因此，越来越多的人关注表现出高性能的紧凑模型。在这项研究中，我们观察到LLM的不同层对隐藏状态有不同程度的扰动，这使我们能够识别出不那么重要的层。基于这一现象，我们提出了LLM-Streamline，包括两部分：层剪枝，根据目标稀疏度移除模型中一组连续的最不重要的层；层替换，训练一个轻量级模型来替换被剪枝的层，从而缓解由剪枝造成的性能下降。在实验中，我们利用了多层感知器(MLP)和一个transformer层等结构作为轻量级模型。

    arXiv:2403.19135v1 Announce Type: cross  Abstract: Large language models (LLM) have been extensively applied in various natural language tasks and domains, but their applicability is constrained by the large number of parameters of the models. Consequently, there is an increasing emphasis on compact models that exhibit high performance. In this study, we observe that different layers in LLM have varying degrees of perturbation on the hidden states, which allows us to identify less important layers. Based on this phenomenon, we propose LLM-Streamline, which consists of two parts: layer pruning, where we remove a set of consecutive layers with the lowest importance in the model according to the target sparsity; and layer replacement, where we train a lightweight model to substitute the pruned layers, thereby mitigating the performance degradation caused by pruning. In our experiments, we utilize structures such as a multi-layer perceptron (MLP) and a transformer layer as lightweight mode
    
[^2]: 理解尖峰神经网络中建模组件的功能角色

    Understanding the Functional Roles of Modelling Components in Spiking Neural Networks

    [https://arxiv.org/abs/2403.16674](https://arxiv.org/abs/2403.16674)

    系统研究揭示了尖峰神经网络中滤泄、重置和循环等建模组件在平衡记忆保留、时间处理和动态建模方面的功能角色。

    

    受大脑神经回路启发，尖峰神经网络（SNNs）在实现高计算效率和生物保真度方面很有前景。然而，优化SNNs相当困难，因为其建模组件的功能角色仍不清楚。通过设计和评估经典模型的几个变体，我们系统研究了滤泄、重置和循环这些关键建模组件在基于漏积分放电（LIF）的SNNs中的功能角色。通过大量实验，我们演示了这些组件如何影响SNNs的准确性、泛化性和稳健性。具体来说，我们发现滤泄在平衡记忆保留和稳健性方面起着至关重要的作用，重置机制对于不间断的时间处理和计算效率至关重要，而循环则丰富了模型复杂动态的能力，但会损害稳健性。

    arXiv:2403.16674v1 Announce Type: cross  Abstract: Spiking neural networks (SNNs), inspired by the neural circuits of the brain, are promising in achieving high computational efficiency with biological fidelity. Nevertheless, it is quite difficult to optimize SNNs because the functional roles of their modelling components remain unclear. By designing and evaluating several variants of the classic model, we systematically investigate the functional roles of key modelling components, leakage, reset, and recurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive experiments, we demonstrate how these components influence the accuracy, generalization, and robustness of SNNs. Specifically, we find that the leakage plays a crucial role in balancing memory retention and robustness, the reset mechanism is essential for uninterrupted temporal processing and computational efficiency, and the recurrence enriches the capability to model complex dynamics at a cost of robustness degr
    
[^3]: MedPromptX：基于现实的多模态提示用于胸部X线诊断

    MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis

    [https://arxiv.org/abs/2403.15585](https://arxiv.org/abs/2403.15585)

    MedPromptX是第一个将多模态大型语言模型、少样本提示和视觉基础相结合，用于胸部X线诊断的模型，通过补充缺失的EHR信息，有效解决了幻觉问题，但选择最佳少样本示例和高质量候选者仍有待解决。

    

    胸部X线图像通常用于预测急性和慢性心肺疾病，但是将它们与结构化临床数据整合的努力面临着因电子健康记录（EHR）不完整而带来的挑战。本文引入了MedPromptX，这是第一个将多模态大型语言模型（MLLMs）、少样本提示（FP）和视觉基础（VG）相结合，将图像与EHR数据用于胸部X线诊断的模型。预训练的MLLM被用来补充缺失的EHR信息，提供对患者病史的全面理解。此外，少样本提示减少了对MLLM的大量训练的必要性，同时有效解决了幻觉问题。然而，确定最佳少样本示例的过程和选择高质量候选者可能过于繁琐，但它对模型性能产生着深远影响。因此，我们提出了一种新技术来动态地...

    arXiv:2403.15585v1 Announce Type: cross  Abstract: Chest X-ray images are commonly used for predicting acute and chronic cardiopulmonary conditions, but efforts to integrate them with structured clinical data face challenges due to incomplete electronic health records (EHR). This paper introduces \textbf{MedPromptX}, the first model to integrate multimodal large language models (MLLMs), few-shot prompting (FP) and visual grounding (VG) to combine imagery with EHR data for chest X-ray diagnosis. A pre-trained MLLM is utilized to complement the missing EHR information, providing a comprehensive understanding of patients' medical history. Additionally, FP reduces the necessity for extensive training of MLLMs while effectively tackling the issue of hallucination. Nevertheless, the process of determining the optimal number of few-shot examples and selecting high-quality candidates can be burdensome, yet it profoundly influences model performance. Hence, we propose a new technique that dynam
    
[^4]: 一项神经代码智能的调查：范式、进展与未来

    A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond

    [https://arxiv.org/abs/2403.14734](https://arxiv.org/abs/2403.14734)

    神经代码智能领域的调查系统回顾了50多种代表性模型和超过680项相关作品，突出了不同研究阶段的范式和技术转变。

    

    arXiv:2403.14734v1 公告类型: 跨领域 摘要: 神经代码智能--利用深度学习理解、生成和优化代码--在整个社会上具有巨大的潜力，可产生深远影响。作为自然语言和编程语言之间的桥梁，这一领域在过去几年引起了两个研究社区研究人员的极大关注。本调查系统地和按时间顺序回顾了代码智能方面的进展，包括50多种代表性模型及其变体、20多种任务类别以及超过680项相关作品。我们遵循历史进展，跟踪不同研究阶段的范式转变（例如，从使用循环神经网络对代码建模到大型语言模型时代）。同时，我们重点介绍了不同阶段涵盖的模型、任务和评估的主要技术转变。对于应用，我们

    arXiv:2403.14734v1 Announce Type: cross  Abstract: Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we 
    
[^5]: Merino：基于熵驱动的IoT设备上生成式语言模型设计

    Merino: Entropy-driven Design for Generative Language Models on IoT Devices

    [https://arxiv.org/abs/2403.07921](https://arxiv.org/abs/2403.07921)

    在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型，通过最大化transformer解码器的熵来在计算预算内，成功设计了MeRino模型，在移动设置下展现出与当前最先进的自回归transformer模型竞争性能的特点

    

    大规模生成式语言模型（LLMs）作为人工智能现代时代的革命性进步，然而，直接部署LLMs在资源受限的硬件上，比如物联网（IoT）设备，由于其高计算成本而变得困难。在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型。我们的主要设计范式是在给定的计算预算内最大化transformer解码器的熵。整个设计过程涉及解决一个数学规划（MP）问题，可以在几分钟内在CPU上完成，使其几乎是零成本的。我们评估了我们设计的模型MeRino，在九个NLP下游任务上展示了它们在移动设置下对抗当前最先进的自回归transformer模型的竞争性表现。值得注意的是，MeRino在移动设置下获得了类似或更好的零性能表现

    arXiv:2403.07921v1 Announce Type: cross  Abstract: Generative Large Language Models (LLMs) stand as a revolutionary advancement in the modern era of artificial intelligence (AI). However, directly deploying LLMs in resource-constrained hardware, such as Internet-of-Things (IoT) devices, is difficult due to their high computational cost. In this paper, we propose a novel information-entropy framework for designing mobile-friendly generative language models. Our key design paradigm is to maximize the entropy of transformer decoders within the given computational budgets. The whole design procedure involves solving a mathematical programming (MP) problem, which can be done on the CPU within minutes, making it nearly zero-cost. We evaluate our designed models, termed MeRino, across nine NLP downstream tasks, showing their competitive performance against the state-of-the-art autoregressive transformer models under the mobile setting. Notably, MeRino achieves similar or better zero performan
    
[^6]: KnowAgent: 知识增强规划用于基于LLM的Agent

    KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents

    [https://arxiv.org/abs/2403.03101](https://arxiv.org/abs/2403.03101)

    KnowAgent引入了显式动作知识，通过动作知识库和知识型自学习策略来增强LLM的规划能力，从而改善语言Agent的规划表现。

    

    大型语言模型(LLMs)在复杂推理任务中表现出巨大潜力，但在处理更复杂的挑战时仍有所不足，特别是与环境互动通过生成可执行动作时。这种不足主要来自于语言Agent中缺乏内置动作知识，导致在任务求解过程中无法有效引导规划轨迹，从而导致规划幻觉。为了解决这个问题，我们引入了KnowAgent，一种旨在通过整合显式动作知识来增强LLM规划能力的新方法。具体而言，KnowAgent采用了一个动作知识库和一个知识型自学习策略来限制规划过程中的行动路径，实现更合理的轨迹合成，进而提高语言Agent的计划性能。基于HotpotQA和ALFWorld的实验结果基于不同的主干模型。

    arXiv:2403.03101v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. This inadequacy primarily stems from the lack of built-in action knowledge in language agents, which fails to effectively guide the planning trajectories during task solving and results in planning hallucination. To address this issue, we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge. Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents. Experimental results on HotpotQA and ALFWorld based on various backbone m
    
[^7]: 离线安全强化学习中的时间逻辑规范条件化决策转换器

    Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning

    [https://arxiv.org/abs/2402.17217](https://arxiv.org/abs/2402.17217)

    提出了时间逻辑规范条件化决策转换器（SDT）框架，结合信号时间逻辑（STL）和决策转换器（DT）的能力，比现有方法在离线安全强化学习中学习出更好的安全高奖励策略。

    

    离线安全强化学习旨在从固定数据集训练一个满足约束的策略。本文提出了一种新颖的框架，即时间逻辑规范条件化决策转换器（SDT），它利用信号时间逻辑（STL）的表达能力来指定代理应该遵循的复杂时间规则，以及决策转换器（DT）的顺序建模能力。对DSRL基准测试的实证评估表明，与现有方法相比，SDT在学习安全高奖励策略方面具有更好的能力。

    arXiv:2402.17217v1 Announce Type: cross  Abstract: Offline safe reinforcement learning (RL) aims to train a constraint satisfaction policy from a fixed dataset. Current state-of-the-art approaches are based on supervised learning with a conditioned policy. However, these approaches fall short in real-world applications that involve complex tasks with rich temporal and logical structures. In this paper, we propose temporal logic Specification-conditioned Decision Transformer (SDT), a novel framework that harnesses the expressive power of signal temporal logic (STL) to specify complex temporal rules that an agent should follow and the sequential modeling capability of Decision Transformer (DT). Empirical evaluations on the DSRL benchmarks demonstrate the better capacity of SDT in learning safe and high-reward policies compared with existing approaches. In addition, SDT shows good alignment with respect to different desired degrees of satisfaction of the STL specification that it is condi
    
[^8]: 研究随机性对深度神经网络在森林火灾预测中评估的影响

    Studying the Impact of Stochasticity on the Evaluation of Deep Neural Networks for Forest-Fire Prediction

    [https://arxiv.org/abs/2402.15163](https://arxiv.org/abs/2402.15163)

    该论文首次系统研究了在随机假设下评估深度神经网络用于森林火灾预测的影响，发现评估对统计的忠实度是在高度随机场景下的可靠替代方法。

    

    本文首次系统研究了在随机假设下评估深度神经网络（DNNs）用于离散动力系统，重点关注野火预测。我们开发了一个框架来研究随机性对两类评估指标的影响：基于分类的指标，评估对观察地面真相（GT）的忠实度，以及适当的得分规则，测试对统计的忠实度。我们的研究结果表明，在高度随机的情况下，评估对统计的忠实度是一个可靠的替代方案。我们将我们的分析扩展到现实世界的森林火灾数据，突显了传统森林火灾预测评估方法中的局限性，并建议可解释的适用于随机性的替代方法。

    arXiv:2402.15163v1 Announce Type: cross  Abstract: This paper presents the first systematic study of the evaluation of Deep Neural Networks (DNNs) for discrete dynamical systems under stochastic assumptions, with a focus on wildfire prediction. We develop a framework to study the impact of stochasticity on two classes of evaluation metrics: classification-based metrics, which assess fidelity to observed ground truth (GT), and proper scoring rules, which test fidelity-to-statistic. Our findings reveal that evaluating for fidelity-to-statistic is a reliable alternative in highly stochastic scenarios. We extend our analysis to real-world wildfire data, highlighting limitations in traditional wildfire prediction evaluation methods, and suggest interpretable stochasticity-compatible alternatives.
    
[^9]: 自我分而治之：何时检索、何时生成？面向组合未知问题的自我分而治之算法

    Self-DC: When to retrieve and When to generate? Self Divide-and-Conquer for Compositional Unknown Questions

    [https://arxiv.org/abs/2402.13514](https://arxiv.org/abs/2402.13514)

    提出了面向组合未知问题的自我分而治之算法，引入了第一个组合未知问题问答数据集（CuQA），通过自适应调用不同方法实现更好的性能和效率。

    

    检索-然后阅读和生成-然后阅读是处理开放域问答中未知和已知问题的两种典型解决方案，前者检索必要的外部知识，后者则促使大型语言模型生成参数中编码的内部已知知识。然而，过去很少有作品考虑到组合未知问题，这些问题由几个已知或未知的子问题组成。因此，简单的二元分类（已知或未知）变得次优和低效，因为它会对每个组合未知问题过度调用外部检索。为此，我们提出了第一个组合未知问题问答数据集（CuQA），并引入了一个自我分而治之（Self-DC）框架，使大型语言模型能够自适应地调用不同的方法，从而提高性能和效率。实验结果在两个数据集（CuQA和FreshQA）上表明……

    arXiv:2402.13514v1 Announce Type: cross  Abstract: Retrieve-then-read and generate-then-read are two typical solutions to handle unknown and known questions in open-domain question-answering, while the former retrieves necessary external knowledge and the later prompt the large language models to generate internal known knowledge encoded in the parameters. However, few of previous works consider the compositional unknown questions, which consist of several known or unknown sub-questions. Thus, simple binary classification (known or unknown) becomes sub-optimal and inefficient since it will call external retrieval excessively for each compositional unknown question. To this end, we propose the first Compositional unknown Question-Answering dataset (CuQA), and introduce a Self Divide-and-Conquer (Self-DC) framework to empower LLMs to adaptively call different methods on-demand, resulting in better performance and efficiency. Experimental results on two datasets (CuQA and FreshQA) demonst
    
[^10]: 大型语言模型作为间接推理器：对自动推理的反证和矛盾

    Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning

    [https://arxiv.org/abs/2402.03667](https://arxiv.org/abs/2402.03667)

    本文提出了一种大型语言模型的新型间接推理方法，使用反证和矛盾的逻辑来处理复杂推理任务，并通过增强数据和规则，以及设计提示模板的方式增强模型的推理能力。

    

    最近，人们越来越关注提高大型语言模型（LLMs）进行复杂推理的能力。然而，以前的方法主要是遵循直接推理（DR）框架，如“思维链”和“自一致性”，因此在解决很难通过DR解决的众多实际问题时会遇到困难。因此，为了增强LLMs的推理能力，本文提出了一种新颖的间接推理（IR）方法，该方法利用反证和矛盾的逻辑来处理事实推理和数学证明等IR任务。具体而言，我们的方法包括两个步骤。首先，我们利用反证的逻辑等价性来增强LLMs的数据和规则，以提高其可理解性。其次，我们设计了一组提示模板，触发LLMs进行基于矛盾证明的IR，其逻辑上等价于原始的DR过程。我们的IR方法简单而有效。

    Recently, increasing attention has been focused drawn on to improve the ability of Large Language Models (LLMs) to perform complex reasoning. However, previous methods, such as Chain-of-Thought and Self-Consistency, mainly follow Direct Reasoning (DR) frameworks, so they will meet difficulty in solving numerous real-world tasks which can hardly be solved via DR. Therefore, to strengthen the reasoning power of LLMs, this paper proposes a novel Indirect Reasoning (IR) method that employs the logic of contrapositives and contradictions to tackle IR tasks such as factual reasoning and mathematic proof. Specifically, our methodology comprises two steps. Firstly, we leverage the logical equivalence of contrapositive to augment the data and rules to enhance the comprehensibility of LLMs. Secondly, we design a set of prompt templates to trigger LLMs to conduct IR based on proof by contradiction that is logically equivalent to the original DR process. Our IR method is simple yet effective and c
    
[^11]: 大型语言模型蒸馏药物推荐模型

    Large Language Model Distilling Medication Recommendation Model

    [https://arxiv.org/abs/2402.02803](https://arxiv.org/abs/2402.02803)

    本研究旨在利用大型语言模型改进药物推荐方法，以解决传统模型在医学数据语义理解和新患者处方推荐方面的挑战。

    

    药物推荐是智能医疗系统中的重要方面，它根据患者特定的健康需求来推荐最合适的药物。然而，目前使用的许多复杂模型往往忽视医学数据的细微语义，而只是过度依赖标识。此外，这些模型在处理首次访问医院的患者的情况时面临重大挑战，因为它们缺乏之前的处方历史可以参考。为了解决这些问题，我们利用大型语言模型（LLMs）强大的语义理解和输入不可知的特性。我们的研究旨在利用LLMs改进现有的药物推荐方法。在本文中，我们介绍了一种新颖的方法，称为大型语言模型蒸馏药物推荐（LEADER）。我们首先创建合适的提示模板，使LLMs能够有效地推荐药物。

    The recommendation of medication is a vital aspect of intelligent healthcare systems, as it involves prescribing the most suitable drugs based on a patient's specific health needs. Unfortunately, many sophisticated models currently in use tend to overlook the nuanced semantics of medical data, while only relying heavily on identities. Furthermore, these models face significant challenges in handling cases involving patients who are visiting the hospital for the first time, as they lack prior prescription histories to draw upon. To tackle these issues, we harness the powerful semantic comprehension and input-agnostic characteristics of Large Language Models (LLMs). Our research aims to transform existing medication recommendation methodologies using LLMs. In this paper, we introduce a novel approach called Large Language Model Distilling Medication Recommendation (LEADER). We begin by creating appropriate prompt templates that enable LLMs to suggest medications effectively. However, the
    
[^12]: 在大型语言模型上进行间接提示注入攻击的基准测试和防御

    Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models

    [https://arxiv.org/abs/2312.14197](https://arxiv.org/abs/2312.14197)

    该研究引入了第一个间接提示注入攻击基准测试BIPIA，对大型语言模型在面对此类攻击时的风险进行评估，并分析了攻击成功的原因，从而开发了防御方法。

    

    大型语言模型（LLMs）与外部内容的整合已经实现了LLMs的更新和广泛应用，比如微软Copilot。然而，这种整合也让LLMs面临了间接提示注入攻击的风险，攻击者可以在外部内容中嵌入恶意指令，从而ompromising LLM输出并导致响应偏离用户期望。为了研究这个重要但未被充分探讨的问题，我们引入了第一个间接提示注入攻击基准测试BIPIA，以评估这类攻击的风险。基于评估，我们的工作重点分析了该攻击成功的潜在原因，即LLMs无法区分指令和外部内容以及缺乏意识不执行外部内容内的指令。基于这一分析，我们开发了两种黑盒方法。

    arXiv:2312.14197v2 Announce Type: replace-cross  Abstract: The integration of large language models (LLMs) with external content has enabled more up-to-date and wide-ranging applications of LLMs, such as Microsoft Copilot. However, this integration has also exposed LLMs to the risk of indirect prompt injection attacks, where an attacker can embed malicious instructions within external content, compromising LLM output and causing responses to deviate from user expectations. To investigate this important but underexplored issue, we introduce the first benchmark for indirect prompt injection attacks, named BIPIA, to evaluate the risk of such attacks. Based on the evaluation, our work makes a key analysis of the underlying reason for the success of the attack, namely the inability of LLMs to distinguish between instructions and external content and the absence of LLMs' awareness to not execute instructions within external content. Building upon this analysis, we develop two black-box metho
    
[^13]: 利用指数尺度的深度强化ReLU网络初始化和训练

    Compelling ReLU Network Initialization and Training to Leverage Exponential Scaling with Depth

    [https://arxiv.org/abs/2311.18022](https://arxiv.org/abs/2311.18022)

    该论文提出了一种新的训练策略，通过重新参数化网络权重，使得神经网络的指数数量的激活模式得以展现，从而得到远远超过随机初始化的结果。

    

    ReLU激活的神经网络可以看作是分段线性函数的组合。对于这样的网络，随着深度的增加，表达在输入域上的不同线性区域的数量有可能以指数级增长，但当初始参数选择随机时，不太可能出现这种情况。这种不良的尺度能够导致即使是简单函数也需要使用过大的模型来近似。为了解决这个问题，我们引入了一种新的训练策略：首先以一种方式重新参数化网络权重，使得指数数量的激活模式得以展现。在这些新参数上进行训练可以得到一个初始解，稍后通过更新底层模型权重来改进。这种方法使我们能够产生比随机初始化对应的函数逼近好几个数量级的结果。

    A neural network with ReLU activations may be viewed as a composition of piecewise linear functions. For such networks, the number of distinct linear regions expressed over the input domain has the potential to scale exponentially with depth, but it is not expected to do so when the initial parameters are chosen randomly. This poor scaling can necessitate the use of overly large models to approximate even simple functions. To address this issue, we introduce a novel training strategy: we first reparameterize the network weights in a manner that forces an exponential number of activation patterns to manifest. Training first on these new parameters provides an initial solution that can later be refined by updating the underlying model weights. This approach allows us to produce function approximations that are several orders of magnitude better than their randomly initialized counterparts.
    
[^14]: 以低计算资源消耗为中心的高效知识库问答框架：基于线索引导路径探索

    Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption. (arXiv:2401.13444v1 [cs.CL])

    [http://arxiv.org/abs/2401.13444](http://arxiv.org/abs/2401.13444)

    该论文介绍了一种以低计算资源消耗为中心的高效知识库问答框架，通过引入线索引导路径探索的方式，将知识库与大型语言模型高效地融合，从而降低了对模型能力的要求，并在实验证明了其优越性能。

    

    在最近的研究中，大型语言模型（LLMs）展示了出色的能力。然而，更新它们的知识面会带来挑战，当面对不熟悉的查询时可能导致不准确性。虽然已经研究了将知识图谱与LLMs集成的方法，但现有方法将LLMs视为主要的决策者，对其能力提出了较高的要求。对于计算成本较低且性能相对较差的LLMs来说，这是不太合适的。本文介绍了一种以线索引导路径探索为核心的知识库问答框架（CGPE），它将知识库与LLMs高效地融合，对模型的能力要求较低。受人类手动检索知识的方法启发，CGPE利用问题中的信息作为线索，系统地探索知识库中所需的知识路径。开源数据集上的实验证明，CGPE优于先前的方法，并且非常适用于计算成本较低且性能较差的LLMs。

    In recent times, large language models (LLMs) have showcased remarkable capabilities. However, updating their knowledge poses challenges, potentially leading to inaccuracies when confronted with unfamiliar queries. While integrating knowledge graphs with LLMs has been explored, existing approaches treat LLMs as primary decision-makers, imposing high demands on their capabilities. This is particularly unsuitable for LLMs with lower computational costs and relatively poorer performance. In this paper, we introduce a Clue-Guided Path Exploration framework (CGPE) that efficiently merges a knowledge base with an LLM, placing less stringent requirements on the model's capabilities. Inspired by the method humans use to manually retrieve knowledge, CGPE employs information from the question as clues to systematically explore the required knowledge path within the knowledge base. Experiments on open-source datasets reveal that CGPE outperforms previous methods and is highly applicable to LLMs w
    
[^15]: CreINNs: Credal-Set Interval Neural Networks用于分类任务中的不确定性估计

    CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks. (arXiv:2401.05043v1 [cs.LG])

    [http://arxiv.org/abs/2401.05043](http://arxiv.org/abs/2401.05043)

    CreINNs是一种用于分类任务的Credal-Set Interval Neural Networks，通过保留传统的区间神经网络结构，捕捉权重不确定性，并使用概率区间的数学框架预测可信区间。实验结果表明，CreINNs在不确定性估计方面优于变分贝叶斯神经网络和深度集成，并且具有较低的计算复杂度和模型大小。

    

    不确定性估计对于提高神经网络的可靠性越来越有吸引力。在这项工作中，我们提出了新颖的Credal-Set Interval Neural Networks（CreINNs），用于分类任务。CreINNs保留了传统的区间神经网络结构，通过确定性区间捕捉权重的不确定性，同时使用概率区间的数学框架预测可信区间。在一个超出分发检测基准（CIFAR10 vs SVHN）上的实验验证中，CreINNs相比于变分贝叶斯神经网络（BNNs）和深度集成（DEs），在认知不确定性估计方面表现出色。此外，与变分BNNs相比，CreINNs的计算复杂度显著降低，并且比DEs具有较小的模型大小。

    Uncertainty estimation is increasingly attractive for improving the reliability of neural networks. In this work, we present novel credal-set interval neural networks (CreINNs) designed for classification tasks. CreINNs preserve the traditional interval neural network structure, capturing weight uncertainty through deterministic intervals, while forecasting credal sets using the mathematical framework of probability intervals. Experimental validations on an out-of-distribution detection benchmark (CIFAR10 vs SVHN) showcase that CreINNs outperform epistemic uncertainty estimation when compared to variational Bayesian neural networks (BNNs) and deep ensembles (DEs). Furthermore, CreINNs exhibit a notable reduction in computational complexity compared to variational BNNs and demonstrate smaller model sizes than DEs.
    
[^16]: 可逆解决非规则采样时间序列的神经微分方程分析方法

    Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series. (arXiv:2401.04979v1 [cs.LG])

    [http://arxiv.org/abs/2401.04979](http://arxiv.org/abs/2401.04979)

    我们提出了一种可逆解决非规则采样时间序列的神经微分方程分析方法，通过引入神经流的概念，我们的方法既保证了可逆性又降低了计算负担，并且在分类和插值任务中表现出了优异的性能。

    

    为了处理非规则和不完整的时间序列数据的复杂性，我们提出了一种基于神经微分方程（NDE）的可逆解决方案。虽然基于NDE的方法是分析非规则采样时间序列的一种强大方法，但它们通常不能保证在其标准形式下进行可逆变换。我们的方法建议使用具有神经流的神经控制微分方程（Neural CDEs）的变种，该方法在保持较低的计算负担的同时确保了可逆性。此外，它还可以训练双重潜在空间，增强了对动态时间动力学的建模能力。我们的研究提出了一个先进的框架，在分类和插值任务中都表现出色。我们方法的核心是一个经过精心设计的增强型双重潜在状态架构，用于在各种时间序列任务中提高精度。实证分析表明，我们的方法明显优于现有模型。

    To handle the complexities of irregular and incomplete time series data, we propose an invertible solution of Neural Differential Equations (NDE)-based method. While NDE-based methods are a powerful method for analyzing irregularly-sampled time series, they typically do not guarantee reversible transformations in their standard form. Our method suggests the variation of Neural Controlled Differential Equations (Neural CDEs) with Neural Flow, which ensures invertibility while maintaining a lower computational burden. Additionally, it enables the training of a dual latent space, enhancing the modeling of dynamic temporal dynamics. Our research presents an advanced framework that excels in both classification and interpolation tasks. At the core of our approach is an enhanced dual latent states architecture, carefully designed for high precision across various time series tasks. Empirical analysis demonstrates that our method significantly outperforms existing models. This work significan
    
[^17]: 系统化和自动化测试针对代码的指令调整大型语言模型的涡流方法

    Turbulence: Systematically and Automatically Testing Instruction-Tuned Large Language Models for Code. (arXiv:2312.14856v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2312.14856](http://arxiv.org/abs/2312.14856)

    这项研究提出了一种通过新的基准测试Turbulence来系统评估针对代码生成的指令调整大型语言模型（LLMs）的正确性和鲁棒性的方法。通过构建一组问题模板，可以评估LLMs在解决相似编程问题时的准确性，并发现其代码生成能力的缺陷和异常情况。这项研究在五个LLMs上进行了实验。

    

    我们提出了一种通过一个新的基准测试Turbulence，系统评估针对代码生成的指令调整大型语言模型（LLM）的正确性和鲁棒性的方法。Turbulence包含一组大量的自然语言“问题模板”，每个模板都是一个编程问题，参数化使得可以以多种不同形式提问。每个问题模板都有一个相关的“测试预测器”，用来判断LLM返回的代码解决方案是否正确。因此，通过一个问题模板，可以向LLM提问一个非常相似的编程问题“邻域”，并评估每个问题返回的结果的正确性。这允许识别LLM代码生成能力的差距，包括LLM在邻域中解决“几乎所有”问题但对特定参数实例化失败的“异常”。我们针对OpenAI、Co等五个LLM进行了实验。

    We present a method for systematically evaluating the correctness and robustness of instruction-tuned large language models (LLMs) for code generation via a new benchmark, Turbulence. Turbulence consists of a large set of natural language $\textit{question templates}$, each of which is a programming problem, parameterised so that it can be asked in many different forms. Each question template has an associated $\textit{test oracle}$ that judges whether a code solution returned by an LLM is correct. Thus, from a single question template, it is possible to ask an LLM a $\textit{neighbourhood}$ of very similar programming questions, and assess the correctness of the result returned for each question. This allows gaps in an LLM's code generation abilities to be identified, including $\textit{anomalies}$ where the LLM correctly solves $\textit{almost all}$ questions in a neighbourhood but fails for particular parameter instantiations. We present experiments against five LLMs from OpenAI, Co
    
[^18]: 将其推向展示极限：多模态视觉触觉模仿学习与力匹配

    Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching. (arXiv:2311.01248v1 [cs.RO])

    [http://arxiv.org/abs/2311.01248](http://arxiv.org/abs/2311.01248)

    本研究利用视觉触觉传感器和模仿学习相结合，通过配对优化触觉力量曲线和简化传感器应用，对接触丰富的操作任务进行了研究。

    

    光学触觉传感器已经成为机器人操作过程中获取密集接触信息的有效手段。最近引入的“透视你的皮肤”（STS）型传感器具有视觉和触觉模式，通过利用半透明表面和可控照明实现。本文研究了视觉触觉传感与模仿学习在富有接触的操作任务中的好处。首先，我们使用触觉力测量和一种新的算法，在运动示范中产生更好匹配人体示范者的力曲线。其次，我们添加了视觉/触觉STS模式切换作为控制策略输出，简化传感器的应用。最后，我们研究了多种观察配置，比较和对比了视觉/触觉数据（包括模式切换和不切换）与手腕挂载的眼在手摄像机的视觉数据的价值。我们在一个广泛的实验系列上进行实验。

    Optical tactile sensors have emerged as an effective means to acquire dense contact information during robotic manipulation. A recently-introduced `see-through-your-skin' (STS) variant of this type of sensor has both visual and tactile modes, enabled by leveraging a semi-transparent surface and controllable lighting. In this work, we investigate the benefits of pairing visuotactile sensing with imitation learning for contact-rich manipulation tasks. First, we use tactile force measurements and a novel algorithm during kinesthetic teaching to yield a force profile that better matches that of the human demonstrator. Second, we add visual/tactile STS mode switching as a control policy output, simplifying the application of the sensor. Finally, we study multiple observation configurations to compare and contrast the value of visual/tactile data (both with and without mode switching) with visual data from a wrist-mounted eye-in-hand camera. We perform an extensive series of experiments on a
    
[^19]: 通过大型语言模型的知识注入：评估和推进临床文本数据生成

    Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models. (arXiv:2311.00287v1 [cs.CL])

    [http://arxiv.org/abs/2311.00287](http://arxiv.org/abs/2311.00287)

    本文提出了一种通过大型语言模型进行临床文本生成的创新方法ClinGen，该方法将外部领域特定的知识和语言模型结合起来，提高了临床自然语言处理任务的性能，并丰富了样本的多样性。

    

    临床自然语言处理需要能够应对领域特定挑战的方法，例如复杂的医学术语和临床背景。最近，大型语言模型（LLMs）在这个领域显示出了潜力。然而，它们的直接部署可能导致隐私问题，并受到资源限制。为了解决这个挑战，我们深入研究了使用LLMs进行临床NLP任务的合成临床文本生成。我们提出了一种创新的、资源高效的方法ClinGen，它将知识注入到这个过程中。我们的模型涉及临床知识提取和基于上下文的LLM提示。临床主题和写作风格都来自外部领域特定的知识图谱和LLMs，以引导数据生成。我们在7个临床NLP任务和16个数据集上进行了广泛的实证研究，结果显示ClinGen在各种任务中始终提高了性能，有效地使真实数据集的分布对齐，并显著丰富了样本的多样性。

    Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the divers
    
[^20]: 用户在社交媒体上分享仇恨言论的因果理解

    Causal Understanding of Why Users Share Hate Speech on Social Media. (arXiv:2310.15772v1 [cs.SI])

    [http://arxiv.org/abs/2310.15772](http://arxiv.org/abs/2310.15772)

    本文研究了用户为何分享社交媒体上的仇恨言论，提出了一个因果分析框架，通过消除数据偏差和模拟用户脆弱性来揭示影响用户分享行为的因素。

    

    社交媒体上的仇恨言论威胁到个人的心理和身体健康，并且进一步导致现实中的暴力事件。仇恨言论传播背后的重要驱动因素是转发，但是人们很少了解为什么用户会转发仇恨言论。本文提供了一个全面、因果分析的用户属性框架，研究用户为何分享仇恨言论。然而，在从社交媒体数据中进行因果推断时存在一些挑战，因为这类数据很可能存在选择偏差，并且用户对仇恨言论的脆弱性存在混淆。我们开发了一个新颖的三步因果框架：（1）我们通过逆向倾向评分来消除观察性社交媒体数据的偏差。（2）我们使用消除偏差的倾向评分来模拟用户对仇恨言论的潜在脆弱性作为潜在嵌入。（3）我们建立了用户属性对用户分享仇恨言论概率的因果效应模型。

    Hate speech on social media threatens the mental and physical well-being of individuals and is further responsible for real-world violence. An important driver behind the spread of hate speech and thus why hateful posts can go viral are reshares, yet little is known about why users reshare hate speech. In this paper, we present a comprehensive, causal analysis of the user attributes that make users reshare hate speech. However, causal inference from observational social media data is challenging, because such data likely suffer from selection bias, and there is further confounding due to differences in the vulnerability of users to hate speech. We develop a novel, three-step causal framework: (1) We debias the observational social media data by applying inverse propensity scoring. (2) We use the debiased propensity scores to model the latent vulnerability of users to hate speech as a latent embedding. (3) We model the causal effects of user attributes on users' probability of sharing h
    
[^21]: 大型语言模型可以复制跨文化个性差异

    Large language models can replicate cross-cultural differences in personality. (arXiv:2310.10679v1 [cs.CL])

    [http://arxiv.org/abs/2310.10679](http://arxiv.org/abs/2310.10679)

    大型语言模型GPT-4成功复制了使用十项人格问卷测量的大五人格的跨文化差异，但其结果表明平均评级有上升偏差和较低的变异性与结构效度。

    

    我们使用一项大规模实验(N=8000)来确定GPT-4是否可以复制使用十项人格问卷测量的大五人格的跨文化差异。我们选择美国和韩国作为文化对比，因为先前的研究表明这两个国家的人之间存在显著的人格差异。我们操纵了模拟的目标（美国 vs. 韩国），问卷的语言（英语 vs. 韩语）以及语言模型（GPT-4 vs. GPT-3.5）。我们的结果表明，GPT-4复制了每个因子的跨文化差异。然而，平均评级具有上升偏差，并且比人类样本的变异性更低，以及结构效度较低。总的来说，我们提供了初步的证据说明LLMs可以促进跨文化心理研究。

    We use a large-scale experiment (N=8000) to determine whether GPT-4 can replicate cross-cultural differences in the Big Five, measured using the Ten-Item Personality Inventory. We used the US and South Korea as the cultural pair, given that prior research suggests substantial personality differences between people from these two countries. We manipulated the target of the simulation (US vs. Korean), the language of the inventory (English vs. Korean), and the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4 replicated the cross-cultural differences for each factor. However, mean ratings had an upward bias and exhibited lower variation than in the human samples, as well as lower structural validity. Overall, we provide preliminary evidence that LLMs can aid cross-cultural psychological research.
    
[^22]: GenDOM：具有参数感知的泛化性一次变形物体操作

    GenDOM: Generalizable One-shot Deformable Object Manipulation with Parameter-Aware Policy. (arXiv:2309.09051v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2309.09051](http://arxiv.org/abs/2309.09051)

    GenDOM是一个框架，通过条件化操作策略和多样化模拟训练，使操作策略能够仅通过一个真实世界演示来处理不同的可变形物体，并通过最小化真实世界演示和模拟之间的点云格密度差异来估计新物体的可变形物体参数。

    

    由于在运动中存在固有的变形不确定性，以往的可变形物体操作方法（如绳子和布料）通常需要数百个真实世界演示来训练每个物体的操作策略，这限制了它们在不断变化的世界中的应用。为了解决这个问题，我们引入了GenDOM，这是一个框架，允许操作策略只需一个真实世界演示来处理不同的可变形物体。为了实现这一点，我们通过将操作策略与可变形物体参数联系起来，并使用多样化的模拟可变形物体对其进行训练，使策略能够根据不同的物体参数调整动作。在推理时，给定一个新的物体，GenDOM可以通过最小化真实世界演示和模拟之间点云的格密度差异来估计可变形物体参数，而只需一个真实世界演示。

    Due to the inherent uncertainty in their deformability during motion, previous methods in deformable object manipulation, such as rope and cloth, often required hundreds of real-world demonstrations to train a manipulation policy for each object, which hinders their applications in our ever-changing world. To address this issue, we introduce GenDOM, a framework that allows the manipulation policy to handle different deformable objects with only a single real-world demonstration. To achieve this, we augment the policy by conditioning it on deformable object parameters and training it with a diverse range of simulated deformable objects so that the policy can adjust actions based on different object parameters. At the time of inference, given a new object, GenDOM can estimate the deformable object parameters with only a single real-world demonstration by minimizing the disparity between the grid density of point clouds of real-world demonstrations and simulations in a differentiable phys
    
[^23]: SDC-HSDD-NDSA: 使用层次次级导向差异和归一化密度自适应的结构检测聚类算法

    SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption. (arXiv:2307.00677v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.00677](http://arxiv.org/abs/2307.00677)

    本文提出了一种基于密度的聚类算法，能够检测到高密度区域中的结构，具有先前算法所不具备的能力。

    

    基于密度的聚类算法是最受欢迎的聚类算法之一，因为它能够识别任意形状的聚类，只要不同的高密度聚类之间有低密度区域分隔。然而，通过低密度区域将聚类分隔开的要求并不是微不足道的，因为高密度区域可能具有不同的结构，应该被聚类到不同的组中。这种情况说明了我们已知的所有先前基于密度的聚类算法的主要缺陷--无法检测高密度聚类中的结构。因此，本文旨在提供一种基于密度的聚类方案，既具有先前方法的能力，又能够检测到高密度区域中未被低密度区分开的结构。该算法采用层次次级导向差异、层次化、归一化密度以及自适应系数，因此被称为结构检测聚类算法。

    Density-based clustering could be the most popular clustering algorithm since it can identify clusters of arbitrary shape as long as different (high-density) clusters are separated by low-density regions. However, the requirement of the separateness of clusters by low-density regions is not trivial since a high-density region might have different structures which should be clustered into different groups. Such a situation demonstrates the main flaw of all previous density-based clustering algorithms we have known--structures in a high-density cluster could not be detected. Therefore, this paper aims to provide a density-based clustering scheme that not only has the ability previous ones have but could also detect structures in a high-density region not separated by low-density ones. The algorithm employs secondary directed differential, hierarchy, normalized density, as well as the self-adaption coefficient, and thus is called Structure Detecting Cluster by Hierarchical Secondary Direc
    
[^24]: 可泛化的一次性绳索操作策略及其参数感知性。

    Generalizable One-shot Rope Manipulation with Parameter-Aware Policy. (arXiv:2306.09872v1 [cs.LG])

    [http://arxiv.org/abs/2306.09872](http://arxiv.org/abs/2306.09872)

    GenORM通过增加可变形绳索参数和使用各种可变形绳索的模拟训练操作策略，实现利用一次真实演示处理不同可形变绳索，从而节省演示时间和提高适用性。

    

    以绳索在运动过程中的固有不确定性为因素，以往绳索操作方法往往需要数百次真实演示来为每个绳索训练操作策略，即使是简单的“到达目标”任务，这限制了它们在我们不断变化的世界中的应用。为了解决这个问题，我们介绍了GenORM，一个框架，它可以让操作策略通过一次真实演示就可以处理不同可形变的绳索。我们通过在策略上增加可变形绳索参数并使用各种模拟可变形绳索来训练它，使策略能够根据不同的绳索参数调整行动。在推断时，GenORM通过最小化真实演示和模拟点云的网格密度差异来估计可变形绳索参数。通过可微分物理模拟器的帮助，我们仅需要一次演示数据就可以处理不同的绳索。

    Due to the inherent uncertainty in their deformability during motion, previous methods in rope manipulation often require hundreds of real-world demonstrations to train a manipulation policy for each rope, even for simple tasks such as rope goal reaching, which hinder their applications in our ever-changing world. To address this issue, we introduce GenORM, a framework that allows the manipulation policy to handle different deformable ropes with a single real-world demonstration. To achieve this, we augment the policy by conditioning it on deformable rope parameters and training it with a diverse range of simulated deformable ropes so that the policy can adjust actions based on different rope parameters. At the time of inference, given a new rope, GenORM estimates the deformable rope parameters by minimizing the disparity between the grid density of point clouds of real-world demonstrations and simulations. With the help of a differentiable physics simulator, we require only a single r
    
[^25]: 重新评估损失函数：增强深度学习模型对标签噪声的鲁棒性

    Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep Learning Models. (arXiv:2306.05497v1 [cs.LG])

    [http://arxiv.org/abs/2306.05497](http://arxiv.org/abs/2306.05497)

    本文研究了使用噪声鲁棒损失函数增强深度学习模型对标签噪声的鲁棒性，并提出了一种无需超参数调整的新技术：包括输出偏置。

    

    大规模标注的数据集中难免会出现错误的标签，这给深度神经网络的训练带来了极大的挑战，因为它们很容易适应这些错误的标签。只有使用不受噪声干扰的鲁棒模型进行训练，才能获得良好的泛化性能。创建噪声鲁棒模型的一种简单而有效的方式是使用噪声鲁棒损失函数。然而，提出的损失函数数量众多，它们通常伴随着超参数，而且可能学习速度比广泛使用但对噪声敏感的交叉熵损失要慢。通过启发式考虑和广泛的数值实验，我们研究了在哪些情况下提出的损失函数适用，并提出了如何选择合适的损失的建议。此外，我们提出了一种新的技术来增强带有有界损失函数的学习：包括输出偏置，即略微增加与正确标签相对应的神经元预激活。令人惊讶的是，我们发现这种技术在无需超参数调整的情况下表现与最先进的方法类似。

    Large annotated datasets inevitably contain incorrect labels, which poses a major challenge for the training of deep neural networks as they easily fit the labels. Only when training with a robust model that is not easily distracted by the noise, a good generalization performance can be achieved. A simple yet effective way to create a noise robust model is to use a noise robust loss function. However, the number of proposed loss functions is large, they often come with hyperparameters, and may learn slower than the widely used but noise sensitive Cross Entropy loss. By heuristic considerations and extensive numerical experiments, we study in which situations the proposed loss functions are applicable and give suggestions on how to choose an appropriate loss. Additionally, we propose a novel technique to enhance learning with bounded loss functions: the inclusion of an output bias, i.e. a slight increase in the neuron pre-activation corresponding to the correct label. Surprisingly, we f
    
[^26]: 移动机器人的2D推动操作中的集体智能

    Collective Intelligence for 2D Push Manipulation with Mobile Robots. (arXiv:2211.15136v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.15136](http://arxiv.org/abs/2211.15136)

    本研究利用基于软体物理模拟器的规划器和基于注意力的神经网络，实现了移动机器人2D协作推动操作中的集体智能，比传统方法具有更好的性能并具备环境自适应能力。

    

    自然系统通常表现出能够自我组织和适应变化的集体智能，但大多数人工系统缺乏这种等效性。本文探讨使用移动机器人进行2D协作推动操作的集体智能系统的可能性。我们展示了将从软体物理模拟派生的规划器提炼为基于注意力的神经网络后，我们的多机器人推动操作系统相对于基线系统具有更好的性能，并可适应外部扰动和环境变化完成任务。

    While natural systems often present collective intelligence that allows them to self-organize and adapt to changes, the equivalent is missing in most artificial systems. We explore the possibility of such a system in the context of cooperative 2D push manipulations using mobile robots. Although conventional works demonstrate potential solutions for the problem in restricted settings, they have computational and learning difficulties. More importantly, these systems do not possess the ability to adapt when facing environmental changes. In this work, we show that by distilling a planner derived from a differentiable soft-body physics simulator into an attention-based neural network, our multi-robot push manipulation system achieves better performance than baselines. In addition, our system also generalizes to configurations not seen during training and is able to adapt toward task completions when external turbulence and environmental changes are applied. Supplementary videos can be foun
    

