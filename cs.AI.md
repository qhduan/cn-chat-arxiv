# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Recurrent Transformers with Dynamic Halt](https://rss.arxiv.org/abs/2402.00976) | 本文研究了增强Transformer与循环机制的两种方法，并提出了新的扩展和组合方法。在多个诊断任务中进行比较，探索它们的归纳偏好。 |
| [^2] | [Using Quantum Computing to Infer Dynamic Behaviors of Biological and Artificial Neural Networks](https://arxiv.org/abs/2403.18963) | 本研究展示了如何利用Grover和Deutsch-Josza等基础量子算法，通过一组精心构建的条件，推断生物和人工神经网络在一段时间内是否具有继续维持动态活动的潜力。 |
| [^3] | [The Blind Normalized Stein Variational Gradient Descent-Based Detection for Intelligent Massive Random Access](https://arxiv.org/abs/2403.18846) | 提出了一种基于盲归一化斯坦变分梯度下降的检测器，用于解决智能大规模随机接入中的前导碰撞问题，并通过开发改进Hadamard变换和设计块MHT层来提高检测性能。 |
| [^4] | [S+t-SNE - Bringing dimensionality reduction to data streams](https://arxiv.org/abs/2403.17643) | S+t-SNE是t-SNE算法的改进版本，在处理数据流时具有增量更新和盲目漂移管理的特点，能够实现高效的降维和信息可视化。 |
| [^5] | [Yi: Open Foundation Models by 01.AI](https://arxiv.org/abs/2403.04652) | Yi模型系列基于强大的多维能力，通过基于6B和34B预训练模型的扩展，包括聊天模型、长上下文模型、深度放大模型和视觉语言模型，取得了优异的性能。 |
| [^6] | [Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation](https://arxiv.org/abs/2403.02302) | 本研究评估了多模态大型语言模型（MLLMs）在年龄和性别估计中的能力，对不同模型进行了比较，揭示了它们在特定任务上的优势和劣势。 |
| [^7] | [Q-FOX Learning: Breaking Tradition in Reinforcement Learning](https://arxiv.org/abs/2402.16562) | Q-FOX学习是一种新颖的自动超参数调整方法，结合了FOX优化器和Q-learning算法，提出了使用新的目标函数来解决强化学习中超参数调整的问题。 |
| [^8] | [DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel Generation](https://arxiv.org/abs/2401.08095) | DurFlex-EVC通过引入风格自编码器和交叉注意力，解决了传统情绪语音转换模型中对语言和语音信息的同步问题。 |
| [^9] | [AutoMix: Automatically Mixing Language Models](https://arxiv.org/abs/2310.12963) | AutoMix提出了一种自动选择更大语言模型处理查询的方法，通过少量样本自我验证和元验证器提高了输出的可靠性，可显著提高计算成本和性能的优化，实验证明性能优于基线最多86%. |
| [^10] | [Selective Uncertainty Propagation in Offline RL](https://arxiv.org/abs/2302.00284) | 本论文提出了一种名为选择性不确定性传播的方法，用于解决离线强化学习中的分布偏移问题。该方法通过自适应的方式建立置信区间，有效地处理了实际问题中策略学习的挑战。 |
| [^11] | [Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification.](http://arxiv.org/abs/2401.03158) | 四步推理（QLFR）框架是一种通过引入句法和语义丰富的CoT来提升短文本分类任务中大型语言模型（LLMs）性能的方法。 |
| [^12] | [Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation.](http://arxiv.org/abs/2310.02842) | 本论文提出了一种使用智能多任务适应混合提示的方法来解决LLM在处理异质任务和数据分布时的问题。研究者设计了智能门控功能，用于识别嵌入在不同提示组中的相关技能，并根据目标任务的需求动态分配组合专家。该方法对任何模型压缩技术都不受限制，提高了任务处理的效率。 |
| [^13] | [Exploiting Uncertainty for Querying Inconsistent Description Logics Knowledge Bases.](http://arxiv.org/abs/2306.09138) | 本论文研究了如何利用概率语义来查询不一致的描述逻辑知识库，并通过实验证明了该方法的有效性。 |
| [^14] | [Transformer-based model for monocular visual odometry: a video understanding approach.](http://arxiv.org/abs/2305.06121) | 本文提出了一种基于Transformer模型的TSformer-VO方法，将单目视觉里程计作为一项视频理解任务并通过时空自注意机制从视频片段中提取特征，以实现端到端的运动估计，达到了最新成果。 |
| [^15] | [Experts' cognition-driven safe noisy labels learning for precise segmentation of residual tumor in breast cancer.](http://arxiv.org/abs/2304.07295) | 本文提出了一种基于专家认知驱动的安全噪声标签学习方法，用于乳腺癌残余肿瘤的精确分割，该方法将病理专家的认知和人工智能专家的数据建模认知相结合，以缓解乳腺癌组织和肿瘤细胞形态学改变的挑战。 |
| [^16] | [Method for the semantic indexing of concept hierarchies, uniform representation, use of relational database systems and generic and case-based reasoning.](http://arxiv.org/abs/1910.01539) | 本文提出了一种语义索引方法，通过概念层次结构表示知识并将键分配给节点，使得概念与所有更具体的概念部分可统一，并且只允许添加语义正确的概念。此方法可以使用基于案例的推理和通用问题解决方法进行推理。 |

# 详细

[^1]: 具有动态停止的循环Transformer

    Recurrent Transformers with Dynamic Halt

    [https://rss.arxiv.org/abs/2402.00976](https://rss.arxiv.org/abs/2402.00976)

    本文研究了增强Transformer与循环机制的两种方法，并提出了新的扩展和组合方法。在多个诊断任务中进行比较，探索它们的归纳偏好。

    

    本文研究了两种主要方法在增强Transformer与循环机制方面的归纳偏好——（1）类似于Universal Transformers的深度逐层循环方法；和（2）类似于Temporal Latent Bottleneck的分块时态循环方法。此外，我们提出并研究了扩展和组合上述方法的新方式，例如，我们提出了一种基于全局均值的Universal Transformer动态停止机制，并将Universal Transformer的元素融入到Temporal Latent Bottleneck中。我们通过多个诊断任务（如Long Range Arena（LRA），翻转-翻转语言建模，ListOps和逻辑推理）比较了模型并探索了它们的归纳偏好。

    In this paper, we study the inductive biases of two major approaches to augmenting Transformers with a recurrent mechanism - (1) the approach of incorporating a depth-wise recurrence similar to Universal Transformers; and (2) the approach of incorporating a chunk-wise temporal recurrence like Temporal Latent Bottleneck. Furthermore, we propose and investigate novel ways to extend and combine the above methods - for example, we propose a global mean-based dynamic halting mechanism for Universal Transformer and an augmentation of Temporal Latent Bottleneck with elements from Universal Transformer. We compare the models and probe their inductive biases in several diagnostic tasks such as Long Range Arena (LRA), flip-flop language modeling, ListOps, and Logical Inference.
    
[^2]: 使用量子计算推断生物和人工神经网络的动态行为

    Using Quantum Computing to Infer Dynamic Behaviors of Biological and Artificial Neural Networks

    [https://arxiv.org/abs/2403.18963](https://arxiv.org/abs/2403.18963)

    本研究展示了如何利用Grover和Deutsch-Josza等基础量子算法，通过一组精心构建的条件，推断生物和人工神经网络在一段时间内是否具有继续维持动态活动的潜力。

    

    新问题类别的探索是量子计算研究的一个活跃领域。一个基本上完全未被探讨的主题是使用量子算法和计算来探索和询问神经网络的功能动态。这是将量子计算应用于生物和人工神经网络建模和仿真的尚未成熟的主题的一个组成部分。在本研究中，我们展示了如何通过精心构建的一组条件来使用两个基础量子算法，Grover和Deutsch-Josza，以使输出测量具有一种解释，保证我们能够推断一个简单的神经网络表示（适用于生物和人工网络）在一段时间后是否有可能继续维持动态活动。或者这些动态保证会停止，要么是通过'癫痫'动态，要么是静止状态。

    arXiv:2403.18963v1 Announce Type: cross  Abstract: The exploration of new problem classes for quantum computation is an active area of research. An essentially completely unexplored topic is the use of quantum algorithms and computing to explore and ask questions \textit{about} the functional dynamics of neural networks. This is a component of the still-nascent topic of applying quantum computing to the modeling and simulations of biological and artificial neural networks. In this work, we show how a carefully constructed set of conditions can use two foundational quantum algorithms, Grover and Deutsch-Josza, in such a way that the output measurements admit an interpretation that guarantees we can infer if a simple representation of a neural network (which applies to both biological and artificial networks) after some period of time has the potential to continue sustaining dynamic activity. Or whether the dynamics are guaranteed to stop either through 'epileptic' dynamics or quiescence
    
[^3]: 基于盲归一化斯坦变分梯度下降的智能大规模随机接入检测

    The Blind Normalized Stein Variational Gradient Descent-Based Detection for Intelligent Massive Random Access

    [https://arxiv.org/abs/2403.18846](https://arxiv.org/abs/2403.18846)

    提出了一种基于盲归一化斯坦变分梯度下降的检测器，用于解决智能大规模随机接入中的前导碰撞问题，并通过开发改进Hadamard变换和设计块MHT层来提高检测性能。

    

    缺乏高效的前导检测算法仍然是解决实际通信场景中智能大规模随机接入(RA)中前导碰撞问题的挑战。为解决这一问题，我们提出了一种新颖的基于最大似然估计(MLE)模型的早期前导检测方案，在授予式RA流程的第一步。提出了一种新颖的基于盲归一化斯坦变分梯度下降(SVGD)的检测器，以获得MLE模型的近似解。首先，通过探索Hadamard变换和小波变换之间的关系，开发了一种新的改进Hadamard变换(MHT)，使用二阶导数滤波器将高频分离出重要部分。接下来，为了消除SVGD检测器中的噪声并减轻梯度消失问题，设计了基于MHT的块MHT层，该层基于MHT、缩放层、软阈值层构建。

    arXiv:2403.18846v1 Announce Type: cross  Abstract: The lack of an efficient preamble detection algorithm remains a challenge for solving preamble collision problems in intelligent massive random access (RA) in practical communication scenarios. To solve this problem, we present a novel early preamble detection scheme based on a maximum likelihood estimation (MLE) model at the first step of the grant-based RA procedure. A novel blind normalized Stein variational gradient descent (SVGD)-based detector is proposed to obtain an approximate solution to the MLE model. First, by exploring the relationship between the Hadamard transform and wavelet transform, a new modified Hadamard transform (MHT) is developed to separate high-frequencies from important components using the second-order derivative filter. Next, to eliminate noise and mitigate the vanishing gradients problem in the SVGD-based detectors, the block MHT layer is designed based on the MHT, scaling layer, soft-thresholding layer, i
    
[^4]: S+t-SNE - 将降维引入数据流

    S+t-SNE - Bringing dimensionality reduction to data streams

    [https://arxiv.org/abs/2403.17643](https://arxiv.org/abs/2403.17643)

    S+t-SNE是t-SNE算法的改进版本，在处理数据流时具有增量更新和盲目漂移管理的特点，能够实现高效的降维和信息可视化。

    

    我们提出了S+t-SNE，这是t-SNE算法的一种改进，旨在处理无限数据流。S+t-SNE的核心思想是随着新数据的到来逐步更新t-SNE嵌入，确保可扩展性和适应性，以处理流式场景。通过在每一步选择最重要的点，该算法确保可扩展性同时保持信息可视化。采用盲目方法进行漂移管理调整嵌入空间，促进不断可视化不断发展的数据动态。我们的实验评估证明了S+t-SNE的有效性和效率。结果突显了其在流式场景中捕捉模式的能力。我们希望我们的方法为研究人员和从业者提供一个实时工具，用于理解和解释高维数据。

    arXiv:2403.17643v1 Announce Type: new  Abstract: We present S+t-SNE, an adaptation of the t-SNE algorithm designed to handle infinite data streams. The core idea behind S+t-SNE is to update the t-SNE embedding incrementally as new data arrives, ensuring scalability and adaptability to handle streaming scenarios. By selecting the most important points at each step, the algorithm ensures scalability while keeping informative visualisations. Employing a blind method for drift management adjusts the embedding space, facilitating continuous visualisation of evolving data dynamics. Our experimental evaluations demonstrate the effectiveness and efficiency of S+t-SNE. The results highlight its ability to capture patterns in a streaming scenario. We hope our approach offers researchers and practitioners a real-time tool for understanding and interpreting high-dimensional data.
    
[^5]: Yi: 由 01.AI 推出的开放基础模型

    Yi: Open Foundation Models by 01.AI

    [https://arxiv.org/abs/2403.04652](https://arxiv.org/abs/2403.04652)

    Yi模型系列基于强大的多维能力，通过基于6B和34B预训练模型的扩展，包括聊天模型、长上下文模型、深度放大模型和视觉语言模型，取得了优异的性能。

    

    我们介绍了Yi模型系列，这是一系列具有强大多维能力的语言和多模态模型。Yi模型系列基于6B和34B的预训练语言模型，然后我们将它们扩展为聊天模型、200K长上下文模型、深度放大模型和视觉语言模型。我们的基础模型在诸如MMLU之类的各种基准测试中表现出色，而我们微调过的聊天模型在AlpacaEval和Chatbot Arena等主要评估平台上具有较高的人类偏好率。通过依赖于我们的可扩展超级计算基础设施和经典的Transformer架构，我们认为Yi模型的性能主要归因于其数据质量，这是由我们的数据工程工作所带来的。对于预训练，我们使用级联的数据去重和质量过滤流水线构建了3100亿个英文和中文语料库的标记。对于微调，我们对小规模模型进行了改进

    arXiv:2403.04652v1 Announce Type: cross  Abstract: We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities. The Yi model family is based on 6B and 34B pretrained language models, then we extend them to chat models, 200K long context models, depth-upscaled models, and vision-language models. Our base models achieve strong performance on a wide range of benchmarks like MMLU, and our finetuned chat models deliver strong human preference rate on major evaluation platforms like AlpacaEval and Chatbot Arena. Building upon our scalable super-computing infrastructure and the classical transformer architecture, we attribute the performance of Yi models primarily to its data quality resulting from our data-engineering efforts. For pretraining, we construct 3.1 trillion tokens of English and Chinese corpora using a cascaded data deduplication and quality filtering pipeline. For finetuning, we polish a small scale (less th
    
[^6]: 超越专业化：评估MLLMs在年龄和性别估计中的能力

    Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation

    [https://arxiv.org/abs/2403.02302](https://arxiv.org/abs/2403.02302)

    本研究评估了多模态大型语言模型（MLLMs）在年龄和性别估计中的能力，对不同模型进行了比较，揭示了它们在特定任务上的优势和劣势。

    

    最近，多模态大型语言模型（MLLMs）变得异常流行。像ChatGPT-4V和Gemini这样功能强大的商用模型，以及像LLaVA这样的开源模型，本质上都是通用模型，应用于解决各种各样的任务，包括计算机视觉中的任务。这些神经网络具有如此强大的通用知识和推理能力，以至于它们已被证明能够处理甚至未经专门训练的任务。我们将迄今为止最强大的MLLMs的能力进行了比较：ShareGPT4V、ChatGPT、LLaVA-Next 进行了专门任务的年龄和性别估计，与我们的最新专业化模型MiVOLO进行了比较。我们还更新了MiVOLO，并在本文中提供了详细信息和新的指标。这种比较产生了一些有趣的结果和关于参与模型的优点和缺点的见解。此外，我们尝试了各种微调方法

    arXiv:2403.02302v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) have recently gained immense popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as open-source ones such as LLaVA, are essentially general-purpose models and are applied to solve a wide variety of tasks, including those in computer vision. These neural networks possess such strong general knowledge and reasoning abilities that they have proven capable of working even on tasks for which they were not specifically trained. We compared the capabilities of the most powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task of age and gender estimation with our state-of-the-art specialized model, MiVOLO. We also updated MiVOLO and provide details and new metrics in this article. This comparison has yielded some interesting results and insights about the strengths and weaknesses of the participating models. Furthermore, we attempted various ways to fine-tune 
    
[^7]: Q-FOX学习：颠覆传统的强化学习

    Q-FOX Learning: Breaking Tradition in Reinforcement Learning

    [https://arxiv.org/abs/2402.16562](https://arxiv.org/abs/2402.16562)

    Q-FOX学习是一种新颖的自动超参数调整方法，结合了FOX优化器和Q-learning算法，提出了使用新的目标函数来解决强化学习中超参数调整的问题。

    

    强化学习（RL）是人工智能（AI）的一个子集，代理通过与环境的交互来学习最佳动作，因此适用于不需要标记数据或直接监督的任务。 本文提出了一种名为Q-FOX的新颖自动调参方法，该方法使用了FOX优化器和常用的易于实现的RL Q-learning算法解决了调参的问题。此外，还提出了一个新的目标函数，该函数将奖励放在均方误差（MSE）和学习时间之上。

    arXiv:2402.16562v2 Announce Type: replace-cross  Abstract: Reinforcement learning (RL) is a subset of artificial intelligence (AI) where agents learn the best action by interacting with the environment, making it suitable for tasks that do not require labeled data or direct supervision. Hyperparameters (HP) tuning refers to choosing the best parameter that leads to optimal solutions in RL algorithms. Manual or random tuning of the HP may be a crucial process because variations in this parameter lead to changes in the overall learning aspects and different rewards. In this paper, a novel and automatic HP-tuning method called Q-FOX is proposed. This uses both the FOX optimizer, a new optimization method inspired by nature that mimics red foxes' hunting behavior, and the commonly used, easy-to-implement RL Q-learning algorithm to solve the problem of HP tuning. Moreover, a new objective function is proposed which prioritizes the reward over the mean squared error (MSE) and learning time (
    
[^8]: DurFlex-EVC: 具有并行生成的持续灵活情绪语音转换

    DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel Generation

    [https://arxiv.org/abs/2401.08095](https://arxiv.org/abs/2401.08095)

    DurFlex-EVC通过引入风格自编码器和交叉注意力，解决了传统情绪语音转换模型中对语言和语音信息的同步问题。

    

    情绪语音转换（EVC）旨在修改说话者声音的情绪色彩，同时保留原始的语言内容和说话者独特的声音特征。最近EVC的进展涉及同时建模音高和持续时间，利用序列到序列（seq2seq）模型的潜力。为了增强转换的可靠性和效率，本研究将重点转向并行语音生成。我们介绍了DurFlex-EVC，它集成了风格自编码器和单元对齐器。传统模型虽然融入了包含语言和语音信息的自监督学习（SSL）表示，但却忽视了这种双重性质，导致了可控性的降低。为了解决这个问题，我们实现了交叉注意力以将这些表示与不同情绪进行同步。此外，我们还开发了一个风格自编码器。

    arXiv:2401.08095v2 Announce Type: replace-cross  Abstract: Emotional voice conversion (EVC) seeks to modify the emotional tone of a speaker's voice while preserving the original linguistic content and the speaker's unique vocal characteristics. Recent advancements in EVC have involved the simultaneous modeling of pitch and duration, utilizing the potential of sequence-to-sequence (seq2seq) models. To enhance reliability and efficiency in conversion, this study shifts focus towards parallel speech generation. We introduce Duration-Flexible EVC (DurFlex-EVC), which integrates a style autoencoder and unit aligner. Traditional models, while incorporating self-supervised learning (SSL) representations that contain both linguistic and paralinguistic information, have neglected this dual nature, leading to reduced controllability. Addressing this issue, we implement cross-attention to synchronize these representations with various emotions. Additionally, a style autoencoder is developed for t
    
[^9]: AutoMix: 自动混合语言模型

    AutoMix: Automatically Mixing Language Models

    [https://arxiv.org/abs/2310.12963](https://arxiv.org/abs/2310.12963)

    AutoMix提出了一种自动选择更大语言模型处理查询的方法，通过少量样本自我验证和元验证器提高了输出的可靠性，可显著提高计算成本和性能的优化，实验证明性能优于基线最多86%.

    

    大型语言模型(LLMs)现在可以通过各种尺寸和配置的云API提供商获得。虽然这种多样性提供了广泛的选择，但有效利用这些选项以优化计算成本和性能仍然具有挑战性。在这项工作中，我们提出了AutoMix，一种根据较小LM的输出的近似正确性来策略性地将查询路由到更大LM的方法。AutoMix的核心是一种少量样本的自我验证机制，它可以估计输出的可靠性而无需训练。鉴于验证可能存在噪声，我们在AutoMix中使用了元验证器来提高这些评估的准确性。我们在五个基于上下文的推理数据集上使用LLAMA2-13B和GPT-4进行实验，结果表明AutoMix超越了已建立的基线，每单位成本的增量效益提高了最多86%。我们的代码和数据可在https://github.c找到

    arXiv:2310.12963v3 Announce Type: replace  Abstract: Large language models (LLMs) are now available from cloud API providers in various sizes and configurations. While this diversity offers a broad spectrum of choices, effectively leveraging the options to optimize computational cost and performance remains challenging. In this work, we present AutoMix, an approach that strategically routes queries to larger LMs, based on the approximate correctness of outputs from a smaller LM. Central to AutoMix is a few-shot self-verification mechanism, which estimates the reliability of its own outputs without requiring training. Given that verifications can be noisy, we employ a meta-verifier in AutoMix to refine the accuracy of these assessments. Our experiments using LLAMA2-13B and GPT-4, on five context-grounded reasoning datasets demonstrate that AutoMix surpasses established baselines, improving the incremental benefit per cost by up to 86%. Our code and data are available at https://github.c
    
[^10]: 选择性不确定性传播在离线强化学习中的应用

    Selective Uncertainty Propagation in Offline RL

    [https://arxiv.org/abs/2302.00284](https://arxiv.org/abs/2302.00284)

    本论文提出了一种名为选择性不确定性传播的方法，用于解决离线强化学习中的分布偏移问题。该方法通过自适应的方式建立置信区间，有效地处理了实际问题中策略学习的挑战。

    

    本研究考虑有限时间段离线强化学习的情景，目标在于应对动态规划算法中每一步策略学习的挑战。通过评估离开行为策略在第h步时的处理效果，就可以学习到这一步的策略。由于每一步策略都会影响下一状态的分布，相关的分布偏移问题使得这一问题在统计学上比随机情境挑战下的处理效果估计更加困难。然而，许多现实强化学习问题的难度介于这两种情境之间。我们开发了一种灵活且通用的方法，名为选择性不确定性传播，用于建立置信区间，并根据相关分布偏移问题的难度进行自适应。在玩具环境中展示了我们方法的优势，并证明了这些技术在离线策略学习中的好处。

    We consider the finite-horizon offline reinforcement learning (RL) setting, and are motivated by the challenge of learning the policy at any step h in dynamic programming (DP) algorithms. To learn this, it is sufficient to evaluate the treatment effect of deviating from the behavioral policy at step h after having optimized the policy for all future steps. Since the policy at any step can affect next-state distributions, the related distributional shift challenges can make this problem far more statistically hard than estimating such treatment effects in the stochastic contextual bandit setting. However, the hardness of many real-world RL instances lies between the two regimes. We develop a flexible and general method called selective uncertainty propagation for confidence interval construction that adapts to the hardness of the associated distribution shift challenges. We show benefits of our approach on toy environments and demonstrate the benefits of these techniques for offline pol
    
[^11]: 四步推理（QLFR）框架：推进短文本分类的四步推理

    Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification. (arXiv:2401.03158v1 [cs.CL])

    [http://arxiv.org/abs/2401.03158](http://arxiv.org/abs/2401.03158)

    四步推理（QLFR）框架是一种通过引入句法和语义丰富的CoT来提升短文本分类任务中大型语言模型（LLMs）性能的方法。

    

    短文本分类（STC）对于处理和理解当代数字平台上流行的简洁而重要的内容至关重要。STC在抓住语义和句法复杂性方面遇到困难，这个问题在传统的预训练语言模型中很明显。尽管图卷积网络通过整合外部知识库提高了性能，但这些方法受到应用知识质量和范围的限制。最近，大型语言模型（LLMs）和思维链（CoT）的出现显著提高了复杂推理任务的性能。然而，一些研究指出了它们在基础NLP任务中的应用限制。因此，本研究旨在运用CoT来研究LLMs在STC任务中的能力。本研究引入了四步推理（QLFR）框架。这个框架主要包括句法和语义丰富的CoT，有效利用了LLMs的能力。

    Short Text Classification (STC) is crucial for processing and comprehending the brief but substantial content prevalent on contemporary digital platforms. The STC encounters difficulties in grasping semantic and syntactic intricacies, an issue that is apparent in traditional pre-trained language models. Although Graph Convolutional Networks enhance performance by integrating external knowledge bases, these methods are limited by the quality and extent of the knowledge applied. Recently, the emergence of Large Language Models (LLMs) and Chain-of-Thought (CoT) has significantly improved the performance of complex reasoning tasks. However, some studies have highlighted the limitations of their application in fundamental NLP tasks. Consequently, this study sought to employ CoT to investigate the capabilities of LLMs in STC tasks. This study introduces Quartet Logic: A Four-Step Reasoning (QLFR) framework. This framework primarily incorporates Syntactic and Semantic Enrichment CoT, effectiv
    
[^12]: 用智能多任务适应混合提示扫描异质性

    Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation. (arXiv:2310.02842v1 [cs.CL])

    [http://arxiv.org/abs/2310.02842](http://arxiv.org/abs/2310.02842)

    本论文提出了一种使用智能多任务适应混合提示的方法来解决LLM在处理异质任务和数据分布时的问题。研究者设计了智能门控功能，用于识别嵌入在不同提示组中的相关技能，并根据目标任务的需求动态分配组合专家。该方法对任何模型压缩技术都不受限制，提高了任务处理的效率。

    

    大型语言模型(LLM)有能力解决各种任务，如文本摘要和数学问题，但通常是针对单一任务进行训练。由于高计算成本，当前趋势是使用提示指导调节预先训练的LLM以适应新的下游任务。因此，如何扩展提示调节以同时处理异质任务和数据分布是一个广泛开放的问题。为了解决这一问题，我们建议使用"混合提示"或MoPs，并结合智能门控功能：后者的设计是本文的贡献之一，它可以识别嵌入在不同提示组中的相关技能，并根据目标任务动态分配组合专家(即一组提示)。此外，MoPs在应用任何模型压缩技术时都不受影响——以提高效率。

    Large Language Models (LLMs) have the ability to solve a variety of tasks, such as text summarization and mathematical questions, just out of the box, but they are often trained with a single task in mind. Due to high computational costs, the current trend is to use prompt instruction tuning to better adjust monolithic, pretrained LLMs for new -- but often individual -- downstream tasks. Thus, how one would expand prompt tuning to handle -- concomitantly -heterogeneous tasks and data distributions is a widely open question. To address this gap, we suggest the use of \emph{Mixture of Prompts}, or MoPs, associated with smart gating functionality: the latter -- whose design is one of the contributions of this paper -- can identify relevant skills embedded in different groups of prompts and dynamically assign combined experts (i.e., collection of prompts), based on the target task. Additionally, MoPs are empirically agnostic to any model compression technique applied -- for efficiency re
    
[^13]: 利用不确定性查询不一致的描述逻辑知识库

    Exploiting Uncertainty for Querying Inconsistent Description Logics Knowledge Bases. (arXiv:2306.09138v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.09138](http://arxiv.org/abs/2306.09138)

    本论文研究了如何利用概率语义来查询不一致的描述逻辑知识库，并通过实验证明了该方法的有效性。

    

    随着语义Web的重要性日益增加，管理描述逻辑知识库（KBs）中的不一致性变得越来越必要。这些知识库包含来自不同来源的信息，其内容经常发生变化，并且在单独考虑或综合考虑时可能包含相互矛盾的描述。传统的推理算法无法处理不一致的知识库，需要通过调试知识库来消除不一致性。本文利用一种称为DISPONTE的现有概率语义来解决这个问题，并允许在不一致的知识库中进行查询。我们在TRILL和BUNDLE推理器中实现了我们的方法，并通过实验证明了我们的提案的有效性。此外，我们还将所提出的方法与修复语义进行了正式比较，后者是在考虑DL推理任务时最为成熟的语义之一。

    The necessity to manage inconsistency in Description Logics Knowledge Bases~(KBs) has come to the fore with the increasing importance gained by the Semantic Web, where information comes from different sources that constantly change their content and may contain contradictory descriptions when considered either alone or together. Classical reasoning algorithms do not handle inconsistent KBs, forcing the debugging of the KB in order to remove the inconsistency. In this paper, we exploit an existing probabilistic semantics called DISPONTE to overcome this problem and allow queries also in case of inconsistent KBs. We implemented our approach in the reasoners TRILL and BUNDLE and empirically tested the validity of our proposal. Moreover, we formally compare the presented approach to that of the repair semantics, one of the most established semantics when considering DL reasoning tasks.
    
[^14]: 基于Transformer模型的单目视觉里程计：一种视频理解方法

    Transformer-based model for monocular visual odometry: a video understanding approach. (arXiv:2305.06121v1 [cs.CV])

    [http://arxiv.org/abs/2305.06121](http://arxiv.org/abs/2305.06121)

    本文提出了一种基于Transformer模型的TSformer-VO方法，将单目视觉里程计作为一项视频理解任务并通过时空自注意机制从视频片段中提取特征，以实现端到端的运动估计，达到了最新成果。

    

    在移动机器人和自主车辆中，给定单个摄像机图像估计摄像机姿势是一项传统任务。这个问题称为单目视觉里程计，通常依赖于需要针对特定场景进行工程化的几何方法。经过适当训练和足够的数据可用性，深度学习方法已被证明是具有普适性的。Transformer架构已统治了自然语言处理和计算机视觉任务的最前沿，例如图像和视频理解。本文将单目视觉里程计作为一项视频理解任务进行处理，以估计6-DoF摄像机的姿势，提出了基于时空自注意机制的TSformer-VO模型，以端到端的方式从视频片段中提取特征并估计运动，与几何和深度学习方法相比，我们的方法在KITTI数据集上取得了有竞争力的最新成果。

    Estimating the camera pose given images of a single camera is a traditional task in mobile robots and autonomous vehicles. This problem is called monocular visual odometry and it often relies on geometric approaches that require engineering effort for a specific scenario. Deep learning methods have shown to be generalizable after proper training and a considerable amount of available data. Transformer-based architectures have dominated the state-of-the-art in natural language processing and computer vision tasks, such as image and video understanding. In this work, we deal with the monocular visual odometry as a video understanding task to estimate the 6-DoF camera's pose. We contribute by presenting the TSformer-VO model based on spatio-temporal self-attention mechanisms to extract features from clips and estimate the motions in an end-to-end manner. Our approach achieved competitive state-of-the-art performance compared with geometry-based and deep learning-based methods on the KITTI
    
[^15]: 基于专家认知驱动的安全噪声标签学习用于乳腺癌残余肿瘤的精确分割

    Experts' cognition-driven safe noisy labels learning for precise segmentation of residual tumor in breast cancer. (arXiv:2304.07295v1 [q-bio.QM])

    [http://arxiv.org/abs/2304.07295](http://arxiv.org/abs/2304.07295)

    本文提出了一种基于专家认知驱动的安全噪声标签学习方法，用于乳腺癌残余肿瘤的精确分割，该方法将病理专家的认知和人工智能专家的数据建模认知相结合，以缓解乳腺癌组织和肿瘤细胞形态学改变的挑战。

    

    新辅助化疗后准确分割乳腺癌残余肿瘤 (PSRTBC) 是乳腺癌治疗过程中的一个基本关键技术。然而，由于乳腺癌组织和肿瘤细胞在新辅助化疗后常常具有复杂和多种多样的形态学改变，因此产生一个具有良好泛化性能的预测模型仍然是一个挑战。为了缓解这种情况，本文提出了一种基于专家认知驱动的安全噪声标签学习 (ECDSNLL) 方法。ECDSNLL是在安全噪声标签学习的概念下构建的，后者是一种典型的安全弱监督学习方法，它将病理专家对乳腺癌残余肿瘤识别的认知与提供的数据基础上的人工智能专家的数据建模认知相结合。我们展示了所提出的ECDSNLL方法的优势和潜力。

    Precise segmentation of residual tumor in breast cancer (PSRTBC) after neoadjuvant chemotherapy is a fundamental key technique in the treatment process of breast cancer. However, achieving PSRTBC is still a challenge, since the breast cancer tissue and tumor cells commonly have complex and varied morphological changes after neoadjuvant chemotherapy, which inevitably increases the difficulty to produce a predictive model that has good generalization with machine learning. To alleviate this situation, in this paper, we propose an experts' cognition-driven safe noisy labels learning (ECDSNLL) approach. In the concept of safe noisy labels learning, which is a typical type of safe weakly supervised learning, ECDSNLL is constructed by integrating the pathology experts' cognition about identifying residual tumor in breast cancer and the artificial intelligence experts' cognition about data modeling with provided data basis. We show the advantages of the proposed ECDSNLL approach and its promi
    
[^16]: 概念层次结构的语义索引方法，统一表示，关系数据库系统和通用与基于案例的推理方法

    Method for the semantic indexing of concept hierarchies, uniform representation, use of relational database systems and generic and case-based reasoning. (arXiv:1910.01539v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1910.01539](http://arxiv.org/abs/1910.01539)

    本文提出了一种语义索引方法，通过概念层次结构表示知识并将键分配给节点，使得概念与所有更具体的概念部分可统一，并且只允许添加语义正确的概念。此方法可以使用基于案例的推理和通用问题解决方法进行推理。

    

    本文提出了一种语义索引方法，并描述了其在知识表示领域的应用。语义索引的起点是通过概念层次结构表示的知识。其目标是将键分配给节点（概念），这些节点按层次顺序排列且语法和语义正确。使用索引算法，计算键，使得概念与所有更具体的概念部分可统一，并且只允许添加语义正确的概念。键表示术语关系。所述索引算法的正确性和完备性已被证明。描述了将经典关系数据库用于实例存储的方法。由于统一表示，可以使用基于案例的推理和通用问题解决方法进行推理。

    This paper presents a method for semantic indexing and describes its application in the field of knowledge representation. Starting point of the semantic indexing is the knowledge represented by concept hierarchies. The goal is to assign keys to nodes (concepts) that are hierarchically ordered and syntactically and semantically correct. With the indexing algorithm, keys are computed such that concepts are partially unifiable with all more specific concepts and only semantically correct concepts are allowed to be added. The keys represent terminological relationships. Correctness and completeness of the underlying indexing algorithm are proven. The use of classical relational databases for the storage of instances is described. Because of the uniform representation, inference can be done using case-based reasoning and generic problem solving methods.
    

