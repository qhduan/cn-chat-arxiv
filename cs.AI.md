# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Sparse multimodal fusion with modal channel attention](https://arxiv.org/abs/2403.20280) | 研究了蒙特卡罗多模态变换器架构在模态样本稀疏对齐时学习稳健嵌入空间的能力，并提出了模态通道注意力（MCA）机制，可以改善生成的嵌入空间质量和下游任务性能。 |
| [^2] | [Artificial consciousness. Some logical and conceptual preliminaries](https://arxiv.org/abs/2403.20177) | 需要在人工系统中平衡讨论意识的可能实现，提出了使用意识的维度和特征来进行讨论的必要性。 |
| [^3] | [Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking](https://arxiv.org/abs/2403.17234) | 本文提出了一种将强化学习与蒙特卡洛树搜索集成的方法，用于自动停车任务中的在线路径规划，旨在加速路径规划过程，提高效率。 |
| [^4] | [EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union](https://arxiv.org/abs/2403.15474) | 通过EC-IoU度量，本文引入了一种定向安全性物体检测方法，可以在安全关键领域中提高物体检测器的性能，并在KITTI数据集上取得了比IoU更好的结果。 |
| [^5] | [Verifix: Post-Training Correction to Improve Label Noise Robustness with Verified Samples](https://arxiv.org/abs/2403.08618) | 提出了后训练校正的新范式，通过奇异值分解算法Verifix在初始训练后校正模型权重以减轻标签噪声，避免了重新训练的需求 |
| [^6] | [Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging](https://arxiv.org/abs/2402.18205) | Lemur提出了一种先进的日志解析框架，采用熵抽样和思维链合并，解决了日志解析中存在的人工规则依赖和语义信息忽略等问题。 |
| [^7] | [Text2Data: Low-Resource Data Generation with Textual Control](https://arxiv.org/abs/2402.10941) | Text2Data提出了一种利用未标记数据通过无监督扩散模型来理解基础数据分布的新方法，以解决低资源环境下缺乏文本标签的文本到数据任务中的挑战。 |
| [^8] | [A Competition Winning Deep Reinforcement Learning Agent in microRTS](https://arxiv.org/abs/2402.08112) | 在IEEE microRTS竞赛中，RAISocketAI成为第一个获胜的深度强化学习代理，它通过逐步优化基本策略和迁移学习来击败了前两位竞赛获胜者，在未来的竞赛中可以作为基准参考，并为DRL研究提供起点。 |
| [^9] | [Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web](https://arxiv.org/abs/2311.18751) | 本文介绍了语言模型代理 (LMA) 在多步决策任务上的有希望的范例，在基本任务上具有出色的性能，但在组合任务上表现不佳。通过平衡数据分布，我们训练了一个新模型 HTML-T5++，在现实应用中取得了超越人类的性能，并在新基准测试中实现了最佳零-shot性能。 |
| [^10] | [Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations.](http://arxiv.org/abs/2401.14142) | 基于能量的概念瓶颈模型统一了预测、概念干预和条件解释的功能，解决了现有方法在高阶非线性相互作用和复杂条件依赖关系上的限制。 |
| [^11] | [Multi-Agent Quantum Reinforcement Learning using Evolutionary Optimization.](http://arxiv.org/abs/2311.05546) | 本研究提出了三种基于变分量子线路的进化优化多智能体强化学习变体，并在Coin Game环境中证明了这些方法相比于经典方法表现显著更好。 |
| [^12] | [Preserving the knowledge of long clinical texts using aggregated ensembles of large language models.](http://arxiv.org/abs/2311.01571) | 本文提出了一种使用聚合集成模型的方法来保留长篇临床文本的知识。与以往方法不同，我们将集成学习与文本聚合相结合，并在两个临床预测任务上训练多个大型语言模型。实验证明，我们的方法可以在处理长输入和多样性数据集时提升大型语言模型的性能。 |
| [^13] | [Detecting stealthy cyberattacks on adaptive cruise control vehicles: A machine learning approach.](http://arxiv.org/abs/2310.17091) | 本研究针对自适应巡航控制车辆可能遭受的网络攻击问题，提出了一个交通模型框架和基于GAN的异常检测模型，能够实时识别恶意操纵、虚假注入和拒绝服务攻击。 |
| [^14] | [Connecting NTK and NNGP: A Unified Theoretical Framework for Neural Network Learning Dynamics in the Kernel Regime.](http://arxiv.org/abs/2309.04522) | 本文提出了一个马尔可夫近似学习模型，统一了神经切向核（NTK）和神经网络高斯过程（NNGP）核，用于描述无限宽度深层网络的学习动力学。 |
| [^15] | [Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models.](http://arxiv.org/abs/2308.04399) | 本文提出了一个模型，探讨了通用模型的微调过程中的利润分享问题，为一般类的成本和收入函数描述了解决方案的条件。 |
| [^16] | [PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations.](http://arxiv.org/abs/2307.02762) | 本研究提出了PRD算法，利用同行评级和讨论改善了基于大型语言模型的评估方法，解决了自我提升和位置偏见等问题。 |
| [^17] | [MADiff: Offline Multi-agent Learning with Diffusion Models.](http://arxiv.org/abs/2305.17330) | 本论文提出了基于注意力的扩散模型MADiff，解决了多智能体问题，是第一个扩散模型应用于多智能体离线RL的框架。 |
| [^18] | [Biophysical Cybernetics of Directed Evolution and Eco-evolutionary Dynamics.](http://arxiv.org/abs/2305.03340) | 本论文提出了一种新的方法，以部分可观察的马尔可夫过程模型为基础，分析生态演化动力学中生态和个体基因型/表型类型复杂性的不确定性。 |
| [^19] | [InceptionNeXt: When Inception Meets ConvNeXt.](http://arxiv.org/abs/2303.16900) | 本论文提出了一种名为InceptionNeXt的新型神经网络，通过将大内核卷积沿通道维度分解为四个平行分支来提高模型效率，解决了保持性能的同时加快基于大内核的CNN模型的问题。 |
| [^20] | [Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution.](http://arxiv.org/abs/2208.04957) | 本研究首次研究了异构零样本协同问题，并提出了一种基于协同进化的通用方法，通过配对、更新和选择的过程，实现了多智能体零样本协同。实验结果表明，考虑异构情况的必要性，并证明了该方法对于异构零样本协同任务的有前景的解决方案。 |

# 详细

[^1]: 带有模态通道注意力的稀疏多模态融合

    Sparse multimodal fusion with modal channel attention

    [https://arxiv.org/abs/2403.20280](https://arxiv.org/abs/2403.20280)

    研究了蒙特卡罗多模态变换器架构在模态样本稀疏对齐时学习稳健嵌入空间的能力，并提出了模态通道注意力（MCA）机制，可以改善生成的嵌入空间质量和下游任务性能。

    

    通过测量生成的嵌入空间质量作为模态稀疏度函数的能力，研究了蒙特卡罗多模态变换器架构在模态样本稀疏对齐时学习稳健嵌入空间的能力。提出了一种扩展的蒙特卡罗多模态变压器模型，该模型在多头注意机制中引入了模态不完全通道，称为模态通道注意力（MCA）。使用了包含4种模态的两个数据集，CMU-MOSEI用于多模态情感识别，TCGA用于多组学。模型显示在大多数样本中只用了四种模态中的两种就学习出统一且对齐的嵌入空间。发现，即使没有模态稀疏，所提出的MCA机制也能提高生成的嵌入空间质量，召回指标，并提高下游任务的性能。

    arXiv:2403.20280v1 Announce Type: cross  Abstract: The ability of masked multimodal transformer architectures to learn a robust embedding space when modality samples are sparsely aligned is studied by measuring the quality of generated embedding spaces as a function of modal sparsity. An extension to the masked multimodal transformer model is proposed which incorporates modal-incomplete channels in the multihead attention mechanism called modal channel attention (MCA). Two datasets with 4 modalities are used, CMU-MOSEI for multimodal sentiment recognition and TCGA for multiomics. Models are shown to learn uniform and aligned embedding spaces with only two out of four modalities in most samples. It was found that, even with no modal sparsity, the proposed MCA mechanism improves the quality of generated embedding spaces, recall metrics, and subsequent performance on downstream tasks.
    
[^2]: 人工意识。一些逻辑和概念初步

    Artificial consciousness. Some logical and conceptual preliminaries

    [https://arxiv.org/abs/2403.20177](https://arxiv.org/abs/2403.20177)

    需要在人工系统中平衡讨论意识的可能实现，提出了使用意识的维度和特征来进行讨论的必要性。

    

    arXiv:2403.20177v1 公告类型: 新的 摘要: 人工意识在理论上是否可能？是否合乎情理？如果是，那么技术上可行吗？要解决这些问题，有必要奠定一些基础，阐明人工意识产生的逻辑和经验条件以及涉及的相关术语的含义。意识是一个多义词：来自不同领域的研究人员，包括神经科学、人工智能、机器人技术和哲学等，有时会使用不同术语来指称相同现象，或者使用相同术语来指称不同现象。事实上，如果我们想探讨人工意识，就需要恰当界定关键概念。在此，经过一些逻辑和概念初步工作后，我们认为有必要使用意识的维度和特征进行平衡讨论，探讨它们在人工系统中的可能实例化或实现。我们在这项工作的主要目标是...

    arXiv:2403.20177v1 Announce Type: new  Abstract: Is artificial consciousness theoretically possible? Is it plausible? If so, is it technically feasible? To make progress on these questions, it is necessary to lay some groundwork clarifying the logical and empirical conditions for artificial consciousness to arise and the meaning of relevant terms involved. Consciousness is a polysemic word: researchers from different fields, including neuroscience, Artificial Intelligence, robotics, and philosophy, among others, sometimes use different terms in order to refer to the same phenomena or the same terms to refer to different phenomena. In fact, if we want to pursue artificial consciousness, a proper definition of the key concepts is required. Here, after some logical and conceptual preliminaries, we argue for the necessity of using dimensions and profiles of consciousness for a balanced discussion about their possible instantiation or realisation in artificial systems. Our primary goal in t
    
[^3]: 在自动停车中通过强化学习在MCTS中加速路径规划

    Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking

    [https://arxiv.org/abs/2403.17234](https://arxiv.org/abs/2403.17234)

    本文提出了一种将强化学习与蒙特卡洛树搜索集成的方法，用于自动停车任务中的在线路径规划，旨在加速路径规划过程，提高效率。

    

    本文针对一种方法进行了讨论，该方法将强化学习整合到蒙特卡洛树搜索中，以提升在全可观测环境下进行自动停车任务的在线路径规划。在高维空间下基于采样的规划方法可能具有计算开销大、耗时长的特点。状态评估方法通过将先验知识应用于搜索步骤中，使实时系统中的过程更快速。鉴于自动停车任务通常在复杂环境中执行，传统分析方式难以构建坚实但轻量级的启发式指导。为了克服这一局限性，我们提出了在路径规划框架下具有蒙特卡洛树搜索的强化学习流水线。通过迭代地学习状态的价值以及最佳动作，在前一个周期结果的样本中选择最佳动作，我们能够建模一个值估计器以及一个...

    arXiv:2403.17234v1 Announce Type: new  Abstract: In this paper, we address a method that integrates reinforcement learning into the Monte Carlo tree search to boost online path planning under fully observable environments for automated parking tasks. Sampling-based planning methods under high-dimensional space can be computationally expensive and time-consuming. State evaluation methods are useful by leveraging the prior knowledge into the search steps, making the process faster in a real-time system. Given the fact that automated parking tasks are often executed under complex environments, a solid but lightweight heuristic guidance is challenging to compose in a traditional analytical way. To overcome this limitation, we propose a reinforcement learning pipeline with a Monte Carlo tree search under the path planning framework. By iteratively learning the value of a state and the best action among samples from its previous cycle's outcomes, we are able to model a value estimator and a 
    
[^4]: EC-IoU: 通过自我中心交并联调整物体检测器的安全性

    EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union

    [https://arxiv.org/abs/2403.15474](https://arxiv.org/abs/2403.15474)

    通过EC-IoU度量，本文引入了一种定向安全性物体检测方法，可以在安全关键领域中提高物体检测器的性能，并在KITTI数据集上取得了比IoU更好的结果。

    

    本文介绍了通过一种新颖的自我中心交并联（EC-IoU）度量来定向安全性物体检测，解决了在自动驾驶等安全关键领域应用最先进的基于学习的感知模型时面临的实际问题。具体来说，我们提出了一种加权机制来优化广泛使用的IoU度量，使其能够根据自我代理人的视角覆盖更近的地面真实对象点的预测分配更高的分数。所提出的EC-IoU度量可以用于典型的评估过程，选择有更高安全性表现的物体检测器用于下游任务。它还可以集成到常见损失函数中进行模型微调。尽管面向安全性，但我们在KITTI数据集上的实验表明，使用EC-IoU训练的模型在均值平均精度方面的性能可能会优于使用IoU训练的变体。

    arXiv:2403.15474v1 Announce Type: cross  Abstract: This paper presents safety-oriented object detection via a novel Ego-Centric Intersection-over-Union (EC-IoU) measure, addressing practical concerns when applying state-of-the-art learning-based perception models in safety-critical domains such as autonomous driving. Concretely, we propose a weighting mechanism to refine the widely used IoU measure, allowing it to assign a higher score to a prediction that covers closer points of a ground-truth object from the ego agent's perspective. The proposed EC-IoU measure can be used in typical evaluation processes to select object detectors with higher safety-related performance for downstream tasks. It can also be integrated into common loss functions for model fine-tuning. While geared towards safety, our experiment with the KITTI dataset demonstrates the performance of a model trained on EC-IoU can be better than that of a variant trained on IoU in terms of mean Average Precision as well.
    
[^5]: Verifix: 后训练校正以改善具有经过验证样本的标签噪声鲁棒性

    Verifix: Post-Training Correction to Improve Label Noise Robustness with Verified Samples

    [https://arxiv.org/abs/2403.08618](https://arxiv.org/abs/2403.08618)

    提出了后训练校正的新范式，通过奇异值分解算法Verifix在初始训练后校正模型权重以减轻标签噪声，避免了重新训练的需求

    

    标签错误，即训练样本具有不正确的标签，可能严重损害机器学习模型的性能。这种错误往往来自非专家标注或敌对攻击。获取大型、完全标记的数据集成本高，当有干净的数据集可用时，重新训练大型模型就变得计算昂贵。为了解决这一挑战，我们提出了后训练校正，这是一种在初始训练后调整模型参数以减轻标签噪声的新范式，消除了重新训练的需要。我们引入了Verifix，这是一种基于奇异值分解（SVD）的新算法，利用一个小的、经过验证的数据集，通过单个更新校正模型权重。Verifix使用SVD估计干净激活空间，然后将模型的权重投影到这个空间上，以抑制对应于损坏数据的激活。我们展示了Verifix的有效性。

    arXiv:2403.08618v1 Announce Type: cross  Abstract: Label corruption, where training samples have incorrect labels, can significantly degrade the performance of machine learning models. This corruption often arises from non-expert labeling or adversarial attacks. Acquiring large, perfectly labeled datasets is costly, and retraining large models from scratch when a clean dataset becomes available is computationally expensive. To address this challenge, we propose Post-Training Correction, a new paradigm that adjusts model parameters after initial training to mitigate label noise, eliminating the need for retraining. We introduce Verifix, a novel Singular Value Decomposition (SVD) based algorithm that leverages a small, verified dataset to correct the model weights using a single update. Verifix uses SVD to estimate a Clean Activation Space and then projects the model's weights onto this space to suppress activations corresponding to corrupted data. We demonstrate Verifix's effectiveness 
    
[^6]: Lemur: 使用熵抽样和思维链合并进行日志解析

    Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging

    [https://arxiv.org/abs/2402.18205](https://arxiv.org/abs/2402.18205)

    Lemur提出了一种先进的日志解析框架，采用熵抽样和思维链合并，解决了日志解析中存在的人工规则依赖和语义信息忽略等问题。

    

    大型软件系统产生的日志对监视系统行为至关重要。先进的日志分析有助于检测、报警和诊断系统故障。日志解析是日志分析自动化的关键阶段，它涉及将原始日志消息转换为结构化模板。现有的日志解析器由于依赖于人工制定的规则而无法识别正确的模板。此外，这些方法侧重于统计特征，而忽略了日志消息中的语义信息。为了解决这些挑战，我们提出了一种先进的日志解析框架，采用熵抽样和思维链合并（Lemur）。具体而言，为了摆脱繁琐的手动规则，我们提出了一种受信息熵启发的新型抽样方法，能够有效地对典型日志进行聚类。此外，为了增强日志模板的合并，我们设计了一种思维链方法。

    arXiv:2402.18205v1 Announce Type: cross  Abstract: Logs produced by extensive software systems are integral to monitoring system behaviors. Advanced log analysis facilitates the detection, alerting, and diagnosis of system faults. Log parsing, which entails transforming raw log messages into structured templates, constitutes a critical phase in the automation of log analytics. Existing log parsers fail to identify the correct templates due to reliance on human-made rules. Besides, These methods focus on statistical features while ignoring semantic information in log messages. To address these challenges, we introduce a cutting-edge \textbf{L}og parsing framework with \textbf{E}ntropy sampling and Chain-of-Thought \textbf{M}erging (Lemur). Specifically, to discard the tedious manual rules. We propose a novel sampling method inspired by information entropy, which efficiently clusters typical logs. Furthermore, to enhance the merging of log templates, we design a chain-of-thought method f
    
[^7]: Text2Data：使用文本控制的低资源数据生成

    Text2Data: Low-Resource Data Generation with Textual Control

    [https://arxiv.org/abs/2402.10941](https://arxiv.org/abs/2402.10941)

    Text2Data提出了一种利用未标记数据通过无监督扩散模型来理解基础数据分布的新方法，以解决低资源环境下缺乏文本标签的文本到数据任务中的挑战。

    

    自然语言作为人类与机器无缝交互的一种常见直接控制信号。意识到这一接口的重要性，机器学习社区正在投入大量精力生成与文本指令在语义上一致的数据。虽然在涵盖图像编辑、音频合成、视频生成等领域取得了进展，但低资源领域由于昂贵注释或复杂数据结构（如分子、运动动态和时序）等特点，往往缺乏文本标签。这种不足阻碍了监督学习，从而限制了将先进生成模型应用于文本到数据任务的可能性。为了应对低资源场景中的这些挑战，我们提出了Text2Data，这是一种利用未标记数据通过无监督扩散模型来理解基础数据分布的新方法。

    arXiv:2402.10941v1 Announce Type: cross  Abstract: Natural language serves as a common and straightforward control signal for humans to interact seamlessly with machines. Recognizing the importance of this interface, the machine learning community is investing considerable effort in generating data that is semantically coherent with textual instructions. While strides have been made in text-to-data generation spanning image editing, audio synthesis, video creation, and beyond, low-resource areas characterized by expensive annotations or complex data structures, such as molecules, motion dynamics, and time series, often lack textual labels. This deficiency impedes supervised learning, thereby constraining the application of advanced generative models for text-to-data tasks. In response to these challenges in the low-resource scenario, we propose Text2Data, a novel approach that utilizes unlabeled data to understand the underlying data distribution through an unsupervised diffusion model
    
[^8]: 一种在microRTS中获奖的深度强化学习代理

    A Competition Winning Deep Reinforcement Learning Agent in microRTS

    [https://arxiv.org/abs/2402.08112](https://arxiv.org/abs/2402.08112)

    在IEEE microRTS竞赛中，RAISocketAI成为第一个获胜的深度强化学习代理，它通过逐步优化基本策略和迁移学习来击败了前两位竞赛获胜者，在未来的竞赛中可以作为基准参考，并为DRL研究提供起点。

    

    在CIG和CoG举办的IEEE microRTS（$\mu$RTS）竞赛的五届中，脚本代理主导了比赛。尽管深度强化学习（DRL）算法在实时策略（RTS）游戏中取得了重大进展，但由于需要大量的培训资源以及创建和调试此类代理所固有的复杂性，它们在这个主要是学术竞赛中的采用仍然有限。RAISocketAI是第一个在IEEE microRTS竞赛中获胜的DRL代理。在一个没有性能限制的基准测试中，RAISocketAI经常击败前两位竞赛获胜者。这个第一个获胜的DRL提交可以成为未来microRTS竞赛的基准，并成为未来DRL研究的起点。逐步优化基本策略和对特定地图进行迁移学习对RAISocketAI的获胜表现至关重要。这些策略可以用于经济训练未来的DRL代理。在模仿学习方面的进一步工作可以进一步提高DRL代理的性能。

    Scripted agents have predominantly won the five previous iterations of the IEEE microRTS ($\mu$RTS) competitions hosted at CIG and CoG. Despite Deep Reinforcement Learning (DRL) algorithms making significant strides in real-time strategy (RTS) games, their adoption in this primarily academic competition has been limited due to the considerable training resources required and the complexity inherent in creating and debugging such agents. RAISocketAI is the first DRL agent to win the IEEE microRTS competition. In a benchmark without performance constraints, RAISocketAI regularly defeated the two prior competition winners. This first competition-winning DRL submission can be a benchmark for future microRTS competitions and a starting point for future DRL research. Iteratively fine-tuning the base policy and transfer learning to specific maps were critical to RAISocketAI's winning performance. These strategies can be used to economically train future DRL agents. Further work in Imitation L
    
[^9]: 在Web上揭示语言模型代理在顺序任务组合中的局限性

    Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web

    [https://arxiv.org/abs/2311.18751](https://arxiv.org/abs/2311.18751)

    本文介绍了语言模型代理 (LMA) 在多步决策任务上的有希望的范例，在基本任务上具有出色的性能，但在组合任务上表现不佳。通过平衡数据分布，我们训练了一个新模型 HTML-T5++，在现实应用中取得了超越人类的性能，并在新基准测试中实现了最佳零-shot性能。

    

    最近，语言模型代理(LMA)作为一种在多步决策任务上的有希望的范例出现，通常表现优于人类和其他强化学习代理。尽管有这种希望，但它们在通常涉及任务组合的现实应用中的性能仍未得到充分探索。在这项工作中，我们引入了一个新的基准，叫做CompWoB-反映更现实假设的50个组合性网站自动化任务。我们发现，虽然现有的提示型LMA（gpt-3.5-turbo或gpt-4）在基本任务上实现了94.0％的平均成功率，但在组合任务上降至24.9％的成功率。另一方面，只在基本任务上进行微调的转移性LMA表现出更小的泛化性差距，从85.4％下降到54.8％。通过平衡任务之间的数据分布，我们训练了一个新模型HTML-T5++，在MiniWoB上超过了人类水平的性能（95.2％），并在CompWoB上实现了最佳的零-shot性能（61.5%）。

    Language model agents (LMA) recently emerged as a promising paradigm on muti-step decision making tasks, often outperforming humans and other reinforcement learning agents. Despite the promise, their performance on real-world applications that often involve combinations of tasks is still underexplored. In this work, we introduce a new benchmark, called CompWoB -- 50 new compositional web automation tasks reflecting more realistic assumptions. We show that while existing prompted LMAs (gpt-3.5-turbo or gpt-4) achieve 94.0% average success rate on base tasks, their performance degrades to 24.9% success rate on compositional tasks. On the other hand, transferred LMAs (finetuned only on base tasks) show less generalization gap, dropping from 85.4% to 54.8%. By balancing data distribution across tasks, we train a new model, HTML-T5++, that surpasses human-level performance (95.2%) on MiniWoB, and achieves the best zero-shot performance on CompWoB (61.5%). While these highlight the promise o
    
[^10]: 基于能量的概念瓶颈模型：统一预测、概念干预和条件解释

    Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations. (arXiv:2401.14142v1 [cs.CV])

    [http://arxiv.org/abs/2401.14142](http://arxiv.org/abs/2401.14142)

    基于能量的概念瓶颈模型统一了预测、概念干预和条件解释的功能，解决了现有方法在高阶非线性相互作用和复杂条件依赖关系上的限制。

    

    现有方法，如概念瓶颈模型 (CBM)，在为黑盒深度学习模型提供基于概念的解释方面取得了成功。它们通常通过在给定输入的情况下预测概念，然后在给定预测的概念的情况下预测最终的类别标签。然而，它们经常无法捕捉到概念之间的高阶非线性相互作用，例如纠正一个预测的概念（例如“黄色胸部”）无法帮助纠正高度相关的概念（例如“黄色腹部”），导致最终准确率不理想；它们无法自然地量化不同概念和类别标签之间的复杂条件依赖关系（例如对于一个带有类别标签“Kentucky Warbler”和概念“黑色嘴巴”的图像，模型能够正确预测另一个概念“黑色冠”的概率是多少），因此无法提供关于黑盒模型工作原理更深层次的洞察。针对这些限制，我们提出了基于能量的概念瓶颈模型（Energy-based Concept Bottleneck Models）。

    Existing methods, such as concept bottleneck models (CBMs), have been successful in providing concept-based interpretations for black-box deep learning models. They typically work by predicting concepts given the input and then predicting the final class label given the predicted concepts. However, (1) they often fail to capture the high-order, nonlinear interaction between concepts, e.g., correcting a predicted concept (e.g., "yellow breast") does not help correct highly correlated concepts (e.g., "yellow belly"), leading to suboptimal final accuracy; (2) they cannot naturally quantify the complex conditional dependencies between different concepts and class labels (e.g., for an image with the class label "Kentucky Warbler" and a concept "black bill", what is the probability that the model correctly predicts another concept "black crown"), therefore failing to provide deeper insight into how a black-box model works. In response to these limitations, we propose Energy-based Concept Bot
    
[^11]: 多智能体量子强化学习使用进化优化

    Multi-Agent Quantum Reinforcement Learning using Evolutionary Optimization. (arXiv:2311.05546v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2311.05546](http://arxiv.org/abs/2311.05546)

    本研究提出了三种基于变分量子线路的进化优化多智能体强化学习变体，并在Coin Game环境中证明了这些方法相比于经典方法表现显著更好。

    

    多智能体强化学习在自动驾驶和其他智能产业应用方面变得越来越重要。与此同时，利用量子力学的固有属性，采用新的有希望的强化学习方法，显著减少模型的可训练参数。然而，基于梯度的多智能体量子强化学习方法常常面临贫瘠平台问题，阻碍了它们与经典方法性能的匹配。我们在现有的无梯度量子强化学习方法基础上构建，并提出了三种基于变分量子线路的进化优化多智能体强化学习变体。我们在Coin Game环境中评估了我们的遗传变种，并与经典方法进行了比较。我们证明了我们的变分量子线路方法相比于具有类似参数数量的神经网络表现显著更好。

    Multi-Agent Reinforcement Learning is becoming increasingly more important in times of autonomous driving and other smart industrial applications. Simultaneously a promising new approach to Reinforcement Learning arises using the inherent properties of quantum mechanics, reducing the trainable parameters of a model significantly. However, gradient-based Multi-Agent Quantum Reinforcement Learning methods often have to struggle with barren plateaus, holding them back from matching the performance of classical approaches. We build upon an existing approach for gradient free Quantum Reinforcement Learning and propose three genetic variations with Variational Quantum Circuits for Multi-Agent Reinforcement Learning using evolutionary optimization. We evaluate our genetic variations in the Coin Game environment and also compare them to classical approaches. We showed that our Variational Quantum Circuit approaches perform significantly better compared to a neural network with a similar amount
    
[^12]: 使用聚合集成模型保留长篇临床文本的知识

    Preserving the knowledge of long clinical texts using aggregated ensembles of large language models. (arXiv:2311.01571v1 [cs.CL])

    [http://arxiv.org/abs/2311.01571](http://arxiv.org/abs/2311.01571)

    本文提出了一种使用聚合集成模型的方法来保留长篇临床文本的知识。与以往方法不同，我们将集成学习与文本聚合相结合，并在两个临床预测任务上训练多个大型语言模型。实验证明，我们的方法可以在处理长输入和多样性数据集时提升大型语言模型的性能。

    

    临床文本，如入院记录、出院小结和进展记录，包含丰富而宝贵的信息，可用于各种临床结果预测任务。然而，将基于BERT的大型语言模型应用于临床文本面临两个主要挑战：输入长度的限制和数据来源的多样性。本文提出了一种新颖的方法，使用聚合集成的大型语言模型来保留长篇临床文本的知识。与以往研究单独使用模型集成或文本聚合方法不同，我们将集成学习与文本聚合相结合，在两个临床结果预测任务（死亡预测和住院天数预测）上训练多个大型语言模型。我们展示了我们的方法可以比基线、独立的集成和聚合效果更好，并且可以在处理长输入和多样性数据集时提高大型语言模型的性能。

    Clinical texts, such as admission notes, discharge summaries, and progress notes, contain rich and valuable information that can be used for various clinical outcome prediction tasks. However, applying large language models, such as BERT-based models, to clinical texts poses two major challenges: the limitation of input length and the diversity of data sources. This paper proposes a novel method to preserve the knowledge of long clinical texts using aggregated ensembles of large language models. Unlike previous studies which use model ensembling or text aggregation methods separately, we combine ensemble learning with text aggregation and train multiple large language models on two clinical outcome tasks: mortality prediction and length of stay prediction. We show that our method can achieve better results than baselines, ensembling, and aggregation individually, and can improve the performance of large language models while handling long inputs and diverse datasets. We conduct extensi
    
[^13]: 对自适应巡航控制车辆的隐蔽网络攻击的检测：一种机器学习方法

    Detecting stealthy cyberattacks on adaptive cruise control vehicles: A machine learning approach. (arXiv:2310.17091v1 [cs.MA])

    [http://arxiv.org/abs/2310.17091](http://arxiv.org/abs/2310.17091)

    本研究针对自适应巡航控制车辆可能遭受的网络攻击问题，提出了一个交通模型框架和基于GAN的异常检测模型，能够实时识别恶意操纵、虚假注入和拒绝服务攻击。

    

    随着配备了自适应巡航控制（ACC）和其他自动驾驶功能的先进驾驶辅助系统的出现，针对这些自动驾驶车辆（AVs）的网络攻击潜在风险也出现了。虽然强制车辆发生碰撞的明显攻击容易被识别，但更隐蔽的攻击，只略微改变行驶行为，可能会导致网络范围内拥堵、燃油消耗增加，甚至增加碰撞风险，但很难被检测到。为了解决这种攻击的检测问题，我们首先提出了一个交通模型框架，用于描述可能的三种网络攻击类型：恶意操纵车辆控制命令、对传感器测量数据进行虚假注入攻击和拒绝服务（DoS）攻击。然后，我们研究了这些攻击对个体车辆（微观）和交通流（宏观）水平的影响。我们提出了一种基于生成对抗网络（GAN）的异常检测模型，用于实时识别。

    With the advent of vehicles equipped with advanced driver-assistance systems, such as adaptive cruise control (ACC) and other automated driving features, the potential for cyberattacks on these automated vehicles (AVs) has emerged. While overt attacks that force vehicles to collide may be easily identified, more insidious attacks, which only slightly alter driving behavior, can result in network-wide increases in congestion, fuel consumption, and even crash risk without being easily detected. To address the detection of such attacks, we first present a traffic model framework for three types of potential cyberattacks: malicious manipulation of vehicle control commands, false data injection attacks on sensor measurements, and denial-of-service (DoS) attacks. We then investigate the impacts of these attacks at both the individual vehicle (micro) and traffic flow (macro) levels. A novel generative adversarial network (GAN)-based anomaly detection model is proposed for real-time identifica
    
[^14]: 连接NTK和NNGP：神经网络学习动力学在核区域的统一理论框架

    Connecting NTK and NNGP: A Unified Theoretical Framework for Neural Network Learning Dynamics in the Kernel Regime. (arXiv:2309.04522v1 [cs.LG])

    [http://arxiv.org/abs/2309.04522](http://arxiv.org/abs/2309.04522)

    本文提出了一个马尔可夫近似学习模型，统一了神经切向核（NTK）和神经网络高斯过程（NNGP）核，用于描述无限宽度深层网络的学习动力学。

    

    人工神经网络近年来在机器学习领域取得了革命性的进展，但其学习过程缺乏一个完整的理论框架。对于无限宽度网络，已经取得了重大进展。在这个范式中，使用了两种不同的理论框架来描述网络的输出：一种基于神经切向核（NTK）的框架，假设了线性化的梯度下降动力学；另一种是基于神经网络高斯过程（NNGP）核的贝叶斯框架。然而，这两种框架之间的关系一直不明确。本文通过一个马尔可夫近似学习模型，统一了这两种不同的理论，用于描述随机初始化的无限宽度深层网络的学习动力学。我们推导出了在学习过程中和学习后的网络输入-输出函数的精确分析表达式，并引入了一个新的时间相关的神经动态核（NDK），这个核可以同时产生NTK和NNGP。

    Artificial neural networks have revolutionized machine learning in recent years, but a complete theoretical framework for their learning process is still lacking. Substantial progress has been made for infinitely wide networks. In this regime, two disparate theoretical frameworks have been used, in which the network's output is described using kernels: one framework is based on the Neural Tangent Kernel (NTK) which assumes linearized gradient descent dynamics, while the Neural Network Gaussian Process (NNGP) kernel assumes a Bayesian framework. However, the relation between these two frameworks has remained elusive. This work unifies these two distinct theories using a Markov proximal learning model for learning dynamics in an ensemble of randomly initialized infinitely wide deep networks. We derive an exact analytical expression for the network input-output function during and after learning, and introduce a new time-dependent Neural Dynamical Kernel (NDK) from which both NTK and NNGP
    
[^15]: Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models

    Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models. (arXiv:2308.04399v1 [cs.GT])

    [http://arxiv.org/abs/2308.04399](http://arxiv.org/abs/2308.04399)

    本文提出了一个模型，探讨了通用模型的微调过程中的利润分享问题，为一般类的成本和收入函数描述了解决方案的条件。

    

    机器学习（ML）和人工智能（AI）方面的重大进展越来越多地采用开发和发布通用模型的形式。这些模型旨在由其他企业和机构进行适应，以执行特定的领域专用功能。这个过程被称为适应或微调。本文提供了一个微调过程的模型，其中一位通用专家将技术产品（即ML模型）提升到一定的性能水平，并且一位或多位领域专家将其调整适用于特定领域。这两个实体都是追求利润的，当他们投资于技术时会产生成本，在技术进入市场前，他们必须就如何分享收入达成谈判协议。对于相对一般的成本和收入函数类，我们刻画了微调博弈产生利润分享解决方案的条件。我们观察到，任何潜在的领域专业化都会产生...

    Major advances in Machine Learning (ML) and Artificial Intelligence (AI) increasingly take the form of developing and releasing general-purpose models. These models are designed to be adapted by other businesses and agencies to perform a particular, domain-specific function. This process has become known as adaptation or fine-tuning. This paper offers a model of the fine-tuning process where a Generalist brings the technological product (here an ML model) to a certain level of performance, and one or more Domain-specialist(s) adapts it for use in a particular domain. Both entities are profit-seeking and incur costs when they invest in the technology, and they must reach a bargaining agreement on how to share the revenue for the technology to reach the market. For a relatively general class of cost and revenue functions, we characterize the conditions under which the fine-tuning game yields a profit-sharing solution. We observe that any potential domain-specialization will either contri
    
[^16]: PRD: 同行评级和讨论改善基于大型语言模型的评估

    PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations. (arXiv:2307.02762v1 [cs.CL])

    [http://arxiv.org/abs/2307.02762](http://arxiv.org/abs/2307.02762)

    本研究提出了PRD算法，利用同行评级和讨论改善了基于大型语言模型的评估方法，解决了自我提升和位置偏见等问题。

    

    如今，评估和比较不同现代大型语言模型（LLMs）生成的回答质量在自动化方面很难。最近的研究建议并主要使用LLMs作为无参考度量衡开放式问题回答的参考指标。更具体地说，他们以被认为是“最强”的LLM作为评估器，对候选模型的答案进行两两比较并提供排名分数。然而，这种直观的方法存在多个问题，例如带来自我提升（青睐自己的答案）和位置偏见。我们从教育领域（Cho and MacArthur, 2011；Walsh, 2014）中汲取见解和教训，改进了基于LLM的评估。具体而言，我们提出了（1）同行评级（PR）算法，该算法考虑每个同行LLM对所有答案对的两两偏好，并输出模型的最终排名；以及（2）同行讨论（PD），在其中我们促使两个LLMs进行讨论并尝试就两个偏好达成共识。

    Nowadays, the quality of responses generated by different modern large language models (LLMs) are hard to evaluate and compare automatically. Recent studies suggest and predominantly use LLMs as a reference-free metric for open-ended question answering. More specifically, they use the recognized "strongest" LLM as the evaluator, which conducts pairwise comparisons of candidate models' answers and provides a ranking score. However, this intuitive method has multiple problems, such as bringing in self-enhancement (favoring its own answers) and positional bias. We draw insights and lessons from the educational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based evaluations. Specifically, we propose the (1) peer rank (PR) algorithm that takes into account each peer LLM's pairwise preferences of all answer pairs, and outputs a final ranking of models; and (2) peer discussion (PD), where we prompt two LLMs to discuss and try to reach a mutual agreement on preferences of two an
    
[^17]: MADiff：离线多智能体学习与扩散模型

    MADiff: Offline Multi-agent Learning with Diffusion Models. (arXiv:2305.17330v1 [cs.AI])

    [http://arxiv.org/abs/2305.17330](http://arxiv.org/abs/2305.17330)

    本论文提出了基于注意力的扩散模型MADiff，解决了多智能体问题，是第一个扩散模型应用于多智能体离线RL的框架。

    

    扩散模型（DM）是一种强大的生成模型，最近在包括离线强化学习在内的各种场景中取得了巨大成功，其中策略通过在在线评估中产生轨迹来进行规划学习。然而，尽管单智能体学习显示了其有效性，但仍不清楚DM如何在多智能体问题中操作，其中代理商很难在独立建模每个代理商轨迹的情况下完成团队合作。在本文中，我们提出MADiff，一种新的生成式多智能体学习框架，以解决这个问题。MADiff是通过基于注意力的扩散模型来实现对多个扩散智能体行为的复杂协调建模。据我们所知，MADiff是第一个基于扩散的多智能体离线RL框架，它既可以行为为分散的政策，又可以为集中控制器，其中包括对手建模，并可用于多智能体轨迹预测。

    Diffusion model (DM), as a powerful generative model, recently achieved huge success in various scenarios including offline reinforcement learning, where the policy learns to conduct planning by generating trajectory in the online evaluation. However, despite the effectiveness shown for single-agent learning, it remains unclear how DMs can operate in multi-agent problems, where agents can hardly complete teamwork without good coordination by independently modeling each agent's trajectories. In this paper, we propose MADiff, a novel generative multi-agent learning framework to tackle this problem. MADiff is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple diffusion agents. To the best of our knowledge, MADiff is the first diffusion-based multi-agent offline RL framework, which behaves as both a decentralized policy and a centralized controller, which includes opponent modeling and can be used for multi-agent trajectory predic
    
[^18]: 定向演化和生态进化动力学的生物物理控制

    Biophysical Cybernetics of Directed Evolution and Eco-evolutionary Dynamics. (arXiv:2305.03340v1 [q-bio.PE])

    [http://arxiv.org/abs/2305.03340](http://arxiv.org/abs/2305.03340)

    本论文提出了一种新的方法，以部分可观察的马尔可夫过程模型为基础，分析生态演化动力学中生态和个体基因型/表型类型复杂性的不确定性。

    

    进化动力学中的许多重要问题可以在博弈理论背景下以随机轨迹分析的方式有意义地映射到分析中。通常的方法是分析少量不同的群体和/或假设动力学发生在人口规模大到足以使确定性轨迹成为现实的区域。被称为“生态演化动力学”的生态因素的添加进一步复杂化了动力学，并导致许多问题难以处理或当前的理论方法难以实际应用。但是，一种类似但未被充分探讨的方法是将重点放在模型本身的不确定性上，依据强化学习领域和相邻领域的研究人员的语言，而被称为“部分可观察马尔可夫过程”。在这里，我们介绍了一种对偶性，将同时考虑生态和个体基因型/表型类型的复杂性映射到一个新的马尔可夫过程模型上。

    Many major questions in the theory of evolutionary dynamics can in a meaningful sense be mapped to analyses of stochastic trajectories in game theoretic contexts. Often the approach is to analyze small numbers of distinct populations and/or to assume dynamics occur within a regime of population sizes large enough that deterministic trajectories are an excellent approximation of reality. The addition of ecological factors, termed "eco-evolutionary dynamics", further complicates the dynamics and results in many problems which are intractable or impractically messy for current theoretical methods. However, an analogous but underexplored approach is to analyze these systems with an eye primarily towards uncertainty in the models themselves. In the language of researchers in Reinforcement Learning and adjacent fields, a Partially Observable Markov Process. Here we introduce a duality which maps the complexity of accounting for both ecology and individual genotypic/phenotypic types onto a pr
    
[^19]: InceptionNeXt：当Inception遇到ConvNeXt

    InceptionNeXt: When Inception Meets ConvNeXt. (arXiv:2303.16900v1 [cs.CV])

    [http://arxiv.org/abs/2303.16900](http://arxiv.org/abs/2303.16900)

    本论文提出了一种名为InceptionNeXt的新型神经网络，通过将大内核卷积沿通道维度分解为四个平行分支来提高模型效率，解决了保持性能的同时加快基于大内核的CNN模型的问题。

    

    受ViTs长程建模能力的启发，近期广泛研究和采用了大内核卷积来扩大感受野和提高模型性能，例如ConvNeXt采用了7x7深度卷积。虽然这种深度操作仅消耗少量FLOPs，但由于高内存访问成本，这在功能强大的计算设备上大大损害了模型效率。尽管缩小ConvNeXt的内核大小能提高速度，但会导致性能显着下降。如何在保持性能的同时加快基于大内核的CNN模型仍不清楚。为了解决这个问题，受Inceptions的启发，我们提出将大内核深度卷积沿通道维度分解为四个平行分支，即小方内核、两个正交带内核和一个互补内核。

    Inspired by the long-range modeling ability of ViTs, large-kernel convolutions are widely studied and adopted recently to enlarge the receptive field and improve model performance, like the remarkable work ConvNeXt which employs 7x7 depthwise convolution. Although such depthwise operator only consumes a few FLOPs, it largely harms the model efficiency on powerful computing devices due to the high memory access costs. For example, ConvNeXt-T has similar FLOPs with ResNet-50 but only achieves 60% throughputs when trained on A100 GPUs with full precision. Although reducing the kernel size of ConvNeXt can improve speed, it results in significant performance degradation. It is still unclear how to speed up large-kernel-based CNN models while preserving their performance. To tackle this issue, inspired by Inceptions, we propose to decompose large-kernel depthwise convolution into four parallel branches along channel dimension, i.e. small square kernel, two orthogonal band kernels, and an ide
    
[^20]: 异构多智能体零样本协同进化研究

    Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution. (arXiv:2208.04957v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2208.04957](http://arxiv.org/abs/2208.04957)

    本研究首次研究了异构零样本协同问题，并提出了一种基于协同进化的通用方法，通过配对、更新和选择的过程，实现了多智能体零样本协同。实验结果表明，考虑异构情况的必要性，并证明了该方法对于异构零样本协同任务的有前景的解决方案。

    

    在合作多智能体强化学习领域，生成能够与未知合作伙伴零样本协同的智能体是一个新的挑战。最近的一些研究在零样本协同方面取得了进展，通过训练过程中向智能体暴露多样化的合作伙伴。然而，这些方法通常在训练伙伴时涉及自我对弈，隐式地假设任务是同质的。然而，许多真实世界的任务是异构的，因此先前的方法可能效率低下。本文首次研究了异构零样本协同的问题，并提出了一种基于协同进化的通用方法，通过三个子过程：配对、更新和选择，对两个智能体和合作伙伴进行协同进化。对不同异构任务的实验结果突出了考虑异构情况的必要性，并证明我们提出的方法是解决异构零样本协同任务的一种有前景的解决方案。

    Generating agents that can achieve zero-shot coordination (ZSC) with unseen partners is a new challenge in cooperative multi-agent reinforcement learning (MARL). Recently, some studies have made progress in ZSC by exposing the agents to diverse partners during the training process. They usually involve self-play when training the partners, implicitly assuming that the tasks are homogeneous. However, many real-world tasks are heterogeneous, and hence previous methods may be inefficient. In this paper, we study the heterogeneous ZSC problem for the first time and propose a general method based on coevolution, which coevolves two populations of agents and partners through three sub-processes: pairing, updating and selection. Experimental results on various heterogeneous tasks highlight the necessity of considering the heterogeneous setting and demonstrate that our proposed method is a promising solution for heterogeneous ZSC tasks.
    

