# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Molecular Generative Adversarial Network with Multi-Property Optimization](https://arxiv.org/abs/2404.00081) | 该研究引入了一种新型的基于演员-评论家强化学习的GAN，即InstGAN，以在令牌级别上生成具有多属性优化的分子，并利用最大化信息熵来缓解模式崩溃。 |
| [^2] | [Diffusion on language model embeddings for protein sequence generation](https://arxiv.org/abs/2403.03726) | 使用DiMA模型，在蛋白语言模型嵌入进行扩散来生成氨基酸序列，比传统解决方案表现更好，并通过设计选择的影响来量化其优越性能。 |
| [^3] | [Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models](https://arxiv.org/abs/2403.01489) | 提出了一种基于重建的无需训练的方法，用于将由文本到图像生成模型生成的假图像归因于其来源模型，从而让模型所有者对模型的任何滥用负责。 |
| [^4] | [Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data](https://arxiv.org/abs/2402.12391) | 引入了一个名为AI科学家团队（TAIS）的框架，旨在简化科学发现流程，由模拟角色协作，特别关注于识别具有疾病预测价值的基因 |
| [^5] | [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/abs/2402.12226) | AnyGPT是一个统一的多模态语言模型，通过离散表示实现各种模态的统一处理，能够在不改变大型语言模型架构或训练方式的情况下稳定训练，为新模态的无缝整合提供了可能。 |
| [^6] | [Deep Learning-driven Community Resilience Rating based on Intertwined Socio-Technical Systems Features.](http://arxiv.org/abs/2311.01661) | 这项研究提出了一个基于三层深度学习模型的社区韧性评估方法，通过捕捉社区社会技术系统的异质特征和非线性相互作用，实现对社区韧性的全面评估。 |
| [^7] | [GameGPT: Multi-agent Collaborative Framework for Game Development.](http://arxiv.org/abs/2310.08067) | GameGPT是一个多智能体协作框架，用于自动化游戏开发。它通过使用双重协作和分层方法，结合多个内部词库和解耦方法，解决了大型语言模型在游戏开发中的幻觉和冗余问题。 |
| [^8] | [A Review of Machine Learning Techniques in Imbalanced Data and Future Trends.](http://arxiv.org/abs/2310.07917) | 该论文综述了在非平衡数据中使用的各种机器学习方法，并提供了一个通用指南，旨在帮助研究人员在大规模非平衡数据中进行机器学习。 |
| [^9] | [Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation.](http://arxiv.org/abs/2309.14394) | 本文提出了一种多噪声扩散模型（MDD）用于半监督多域翻译，通过引入噪声级别来对缺失的域进行建模，实现了任意域之间的翻译而不需要训练单独的模型。 |
| [^10] | [Exploring the Influence of Information Entropy Change in Learning Systems.](http://arxiv.org/abs/2309.10625) | 本研究探索了在深度学习系统中引入噪声对性能的影响，证明了特定噪声可以在降低任务复杂性的条件下提升深度架构的性能，通过实验证明了在大规模图像数据集中的显著性能提升。 |

# 详细

[^1]: 具有多属性优化的分子生成对抗网络

    Molecular Generative Adversarial Network with Multi-Property Optimization

    [https://arxiv.org/abs/2404.00081](https://arxiv.org/abs/2404.00081)

    该研究引入了一种新型的基于演员-评论家强化学习的GAN，即InstGAN，以在令牌级别上生成具有多属性优化的分子，并利用最大化信息熵来缓解模式崩溃。

    

    深度生成模型，如生成对抗网络（GANs），已被应用于药物发现中$de~novo$分子生成。大多数先前的研究使用强化学习（RL）算法，特别是蒙特卡罗树搜索（MCTS），来处理GANs中分子表示的离散特性。然而，由于GANs和RL模型的固有训练不稳定性，以及与MCTS采样相关的高计算成本，MCTS RL-based GANs难以扩展到大型化学数据库。为了解决这些挑战，本研究提出了一种基于带即时和全局奖励的演员-评论家RL的新型GAN，称为InstGAN，以在令牌级别上生成具有多属性优化的分子。此外，最大化信息熵被利用来缓解模式崩溃。实验结果表明，InstGAN优于其他基线，达到了可比较的性能。

    arXiv:2404.00081v1 Announce Type: cross  Abstract: Deep generative models, such as generative adversarial networks (GANs), have been employed for $de~novo$ molecular generation in drug discovery. Most prior studies have utilized reinforcement learning (RL) algorithms, particularly Monte Carlo tree search (MCTS), to handle the discrete nature of molecular representations in GANs. However, due to the inherent instability in training GANs and RL models, along with the high computational cost associated with MCTS sampling, MCTS RL-based GANs struggle to scale to large chemical databases. To tackle these challenges, this study introduces a novel GAN based on actor-critic RL with instant and global rewards, called InstGAN, to generate molecules at the token-level with multi-property optimization. Furthermore, maximized information entropy is leveraged to alleviate the mode collapse. The experimental results demonstrate that InstGAN outperforms other baselines, achieves comparable performance
    
[^2]: 蛋白质序列生成的语言模型嵌入扩散

    Diffusion on language model embeddings for protein sequence generation

    [https://arxiv.org/abs/2403.03726](https://arxiv.org/abs/2403.03726)

    使用DiMA模型，在蛋白语言模型嵌入进行扩散来生成氨基酸序列，比传统解决方案表现更好，并通过设计选择的影响来量化其优越性能。

    

    蛋白设计需要对蛋白质宇宙固有复杂性的深入了解。尽管许多工作倾向于有条件的生成或专注于特定蛋白质家族，但无条件生成的基础任务仍未得到充分探索和重视。在这里，我们探索这个关键领域，引入了DiMA，这是一个利用从蛋白语言模型ESM-2衍生的嵌入进行连续扩散以生成氨基酸序列的模型。DiMA超越了包括自回归变换器和离散扩散模型在内的主要解决方案，我们定量地说明了导致其卓越性能的设计选择所带来的影响。我们使用各种指标跨多种形式广泛评估生成序列的质量、多样性、分布相似性和生物相关性。我们的方法始终产生新颖、多样化的蛋白质序列，精准

    arXiv:2403.03726v1 Announce Type: cross  Abstract: Protein design requires a deep understanding of the inherent complexities of the protein universe. While many efforts lean towards conditional generation or focus on specific families of proteins, the foundational task of unconditional generation remains underexplored and undervalued. Here, we explore this pivotal domain, introducing DiMA, a model that leverages continuous diffusion on embeddings derived from the protein language model, ESM-2, to generate amino acid sequences. DiMA surpasses leading solutions, including autoregressive transformer-based and discrete diffusion models, and we quantitatively illustrate the impact of the design choices that lead to its superior performance. We extensively evaluate the quality, diversity, distribution similarity, and biological relevance of the generated sequences using multiple metrics across various modalities. Our approach consistently produces novel, diverse protein sequences that accura
    
[^3]: 基于重建的无需训练的文本到图像生成模型生成的假图像溯源方法

    Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models

    [https://arxiv.org/abs/2403.01489](https://arxiv.org/abs/2403.01489)

    提出了一种基于重建的无需训练的方法，用于将由文本到图像生成模型生成的假图像归因于其来源模型，从而让模型所有者对模型的任何滥用负责。

    

    文本到图像生成模型最近引起了人们的广泛关注，因为它们能够基于描述生成图像。虽然这些模型表现出色，但人们对生成的假图像可能被滥用提出了担忧。为了应对这一问题，我们提出了一种简单而有效的无需训练的方法，用于将由文本到图像模型生成的假图像归因于其来源模型。给定一个待归因的测试图像，首先我们反向重建图像的文本提示，然后将重建的提示放入不同的候选模型中以再现候选假图像。通过计算和排名测试图像与候选图像之间的相似性，我们可以确定图像的来源。这种溯源方法可以让模型所有者对其模型的任何滥用负责。需要注意的是，我们的方法不限制候选文本到图像生成模型的数量。

    arXiv:2403.01489v1 Announce Type: cross  Abstract: Text-to-image generative models have recently garnered significant attention due to their ability to generate images based on prompt descriptions. While these models have shown promising performance, concerns have been raised regarding the potential misuse of the generated fake images. In response to this, we have presented a simple yet effective training-free method to attribute fake images generated by text-to-image models to their source models. Given a test image to be attributed, we first inverse the textual prompt of the image, and then put the reconstructed prompt into different candidate models to regenerate candidate fake images. By calculating and ranking the similarity of the test image and the candidate images, we can determine the source of the image. This attribution allows model owners to be held accountable for any misuse of their models. Note that our approach does not limit the number of candidate text-to-image genera
    
[^4]: 实现基因表达数据科学发现的AI科学家团队

    Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data

    [https://arxiv.org/abs/2402.12391](https://arxiv.org/abs/2402.12391)

    引入了一个名为AI科学家团队（TAIS）的框架，旨在简化科学发现流程，由模拟角色协作，特别关注于识别具有疾病预测价值的基因

    

    机器学习已成为科学发现的强大工具，使研究人员能够从复杂数据集中提取有意义的见解。我们引入了一个新颖的框架，名为AI科学家团队（TAIS），旨在简化科学发现流程。TAIS包括模拟角色，包括项目经理、数据工程师和领域专家，每个角色由大型语言模型（LLM）代表。这些角色协作以复制数据科学家通常执行的任务，特别关注于识别具有疾病预测价值的基因。

    arXiv:2402.12391v1 Announce Type: cross  Abstract: Machine learning has emerged as a powerful tool for scientific discovery, enabling researchers to extract meaningful insights from complex datasets. For instance, it has facilitated the identification of disease-predictive genes from gene expression data, significantly advancing healthcare. However, the traditional process for analyzing such datasets demands substantial human effort and expertise for the data selection, processing, and analysis. To address this challenge, we introduce a novel framework, a Team of AI-made Scientists (TAIS), designed to streamline the scientific discovery pipeline. TAIS comprises simulated roles, including a project manager, data engineer, and domain expert, each represented by a Large Language Model (LLM). These roles collaborate to replicate the tasks typically performed by data scientists, with a specific focus on identifying disease-predictive genes. Furthermore, we have curated a benchmark dataset t
    
[^5]: AnyGPT：统一的多模式离散序列建模语言模型

    AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling

    [https://arxiv.org/abs/2402.12226](https://arxiv.org/abs/2402.12226)

    AnyGPT是一个统一的多模态语言模型，通过离散表示实现各种模态的统一处理，能够在不改变大型语言模型架构或训练方式的情况下稳定训练，为新模态的无缝整合提供了可能。

    

    我们介绍了 AnyGPT，这是一个任意多模式语言模型，利用离散表示统一处理各种模态，包括语音、文本、图像和音乐。AnyGPT 可以稳定训练，无需对当前大型语言模型（LLM）架构或训练范式进行任何改动。相反，它仅依赖于数据级预处理，促进了新模态的无缝集成到LLM中，类似于新语言的整合。我们构建了一个多模式文本中心的数据集，用于多模式对齐预训练。利用生成模型，我们合成了第一个大规模任意多模式指令数据集。它包括108k个多轮对话示例，精细地交织各种模态，从而使模型能够处理多模态输入和输出的任意组合。实验结果表明，AnyGPT能够促进...

    arXiv:2402.12226v1 Announce Type: cross  Abstract: We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music. AnyGPT can be trained stably without any alterations to the current large language model (LLM) architecture or training paradigms. Instead, it relies exclusively on data-level preprocessing, facilitating the seamless integration of new modalities into LLMs, akin to the incorporation of new languages. We build a multimodal text-centric dataset for multimodal alignment pre-training. Utilizing generative models, we synthesize the first large-scale any-to-any multimodal instruction dataset. It consists of 108k samples of multi-turn conversations that intricately interweave various modalities, thus equipping the model to handle arbitrary combinations of multimodal inputs and outputs. Experimental results demonstrate that AnyGPT is capable of facilitat
    
[^6]: 基于深度学习的社区韧性评估：基于相互关联的社会技术系统特征

    Deep Learning-driven Community Resilience Rating based on Intertwined Socio-Technical Systems Features. (arXiv:2311.01661v1 [cs.SI])

    [http://arxiv.org/abs/2311.01661](http://arxiv.org/abs/2311.01661)

    这项研究提出了一个基于三层深度学习模型的社区韧性评估方法，通过捕捉社区社会技术系统的异质特征和非线性相互作用，实现对社区韧性的全面评估。

    

    社区韧性是一个复杂且多维的现象，其源于不同社会技术系统之间的复杂非线性相互作用和其韧性特性。然而，目前关于社区韧性的研究主要集中在脆弱性评估，并采用基于指标的方法，其对于捕捉社区社会技术系统内部的异质特征及其非线性相互作用以塑造韧性的稳健性、冗余性和资源性等组成部分的能力有限。为了弥补这一差距，本文提出了一个基于三层深度学习模型的社区韧性评估方法（称为Resili-Net）。在社区社会技术系统（即设施、基础设施和社会）中，确定和计算了具体的12个可测量的韧性特征，与韧性的稳健性、冗余性和资源性三个组成部分相关。通过使用多个美国大都市统计区的公开可访问数据进行实证研究，证明了该方法的有效性。

    Community resilience is a complex and muti-faceted phenomenon that emerges from complex and nonlinear interactions among different socio-technical systems and their resilience properties. However, present studies on community resilience focus primarily on vulnerability assessment and utilize index-based approaches, with limited ability to capture heterogeneous features within community socio-technical systems and their nonlinear interactions in shaping robustness, redundancy, and resourcefulness components of resilience. To address this gap, this paper presents an integrated three-layer deep learning model for community resilience rating (called Resili-Net). Twelve measurable resilience features are specified and computed within community socio-technical systems (i.e., facilities, infrastructures, and society) related to three resilience components of robustness, redundancy, and resourcefulness. Using publicly accessible data from multiple metropolitan statistical areas in the United S
    
[^7]: GameGPT: 游戏开发的多智能体协作框架

    GameGPT: Multi-agent Collaborative Framework for Game Development. (arXiv:2310.08067v1 [cs.AI])

    [http://arxiv.org/abs/2310.08067](http://arxiv.org/abs/2310.08067)

    GameGPT是一个多智能体协作框架，用于自动化游戏开发。它通过使用双重协作和分层方法，结合多个内部词库和解耦方法，解决了大型语言模型在游戏开发中的幻觉和冗余问题。

    

    基于大型语言模型(LLM)的智能体展示了它们自动化和加速软件开发过程的能力。本文针对游戏开发，提出了一个名为GameGPT的多智能体协作框架，用于自动化游戏开发。尽管许多研究已经指出幻觉是部署LLM在生产中的主要障碍，但我们认为还存在另一个问题：冗余。我们的框架提出了一系列方法来缓解这两个问题。这些方法包括双重协作和分层方法，结合多个内部词库，以降低规划、任务识别和实施阶段的幻觉和冗余。此外，我们还引入了一种解耦方法，以更好地实现代码生成的精度。

    The large language model (LLM) based agents have demonstrated their capacity to automate and expedite software development processes. In this paper, we focus on game development and propose a multi-agent collaborative framework, dubbed GameGPT, to automate game development. While many studies have pinpointed hallucination as a primary roadblock for deploying LLMs in production, we identify another concern: redundancy. Our framework presents a series of methods to mitigate both concerns. These methods include dual collaboration and layered approaches with several in-house lexicons, to mitigate the hallucination and redundancy in the planning, task identification, and implementation phases. Furthermore, a decoupling approach is also introduced to achieve code generation with better precision.
    
[^8]: 在非平衡数据和未来趋势中的机器学习技术综述

    A Review of Machine Learning Techniques in Imbalanced Data and Future Trends. (arXiv:2310.07917v1 [cs.LG])

    [http://arxiv.org/abs/2310.07917](http://arxiv.org/abs/2310.07917)

    该论文综述了在非平衡数据中使用的各种机器学习方法，并提供了一个通用指南，旨在帮助研究人员在大规模非平衡数据中进行机器学习。

    

    在过去的二十年里，检测罕见事件一直是数据挖掘和机器学习领域的一个挑战性任务。现实生活中的问题激发了研究人员进一步改进数据处理和算法方法，以实现有效和计算效率高的非平衡学习方法。本论文收集和审查了258篇来自期刊和会议论文的同行评审论文，旨在从技术和应用角度深入审查非平衡学习中的各种方法。该工作旨在为在学术界或工业界希望深入学习大规模非平衡数据下的机器学习领域的研究人员提供一个结构化的方法综述，并为他们提供一个通用指南。

    For over two decades, detecting rare events has been a challenging task among researchers in the data mining and machine learning domain. Real-life problems inspire researchers to navigate and further improve data processing and algorithmic approaches to achieve effective and computationally efficient methods for imbalanced learning. In this paper, we have collected and reviewed 258 peer-reviewed papers from archival journals and conference papers in an attempt to provide an in-depth review of various approaches in imbalanced learning from technical and application perspectives. This work aims to provide a structured review of methods used to address the problem of imbalanced data in various domains and create a general guideline for researchers in academia or industry who want to dive into the broad field of machine learning using large-scale imbalanced data.
    
[^9]: 多噪声扩散模型用于半监督多域翻译

    Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation. (arXiv:2309.14394v1 [cs.CL])

    [http://arxiv.org/abs/2309.14394](http://arxiv.org/abs/2309.14394)

    本文提出了一种多噪声扩散模型（MDD）用于半监督多域翻译，通过引入噪声级别来对缺失的域进行建模，实现了任意域之间的翻译而不需要训练单独的模型。

    

    域间翻译涉及在给定源域条件下生成目标域样本。大多数现有方法都集中在固定的输入和输出域上，即它们仅适用于特定的配置（例如对于两个域，要么$D_1\rightarrow{}D_2$，要么$D_2\rightarrow{}D_1$）。本文提出了Multi-Domain Diffusion（MDD）方法，这是一种用于半监督多域翻译的条件扩散框架。与以往的方法不同，MDD不需要定义输入和输出域，允许在一组域的任何分区之间进行翻译（例如$(D_1, D_2)\rightarrow{}D_3$，$D_2\rightarrow{}(D_1, D_3)$，$D_3\rightarrow{}D_1$等），而无需为每个域配置训练单独的模型。MDD的关键思想是利用扩散模型的噪声形式，通过为每个域引入一个噪声级别，以自然的方式对缺失的域进行建模。这将传统的翻译问题转化为一个通过噪声建模来解决的问题。

    Domain-to-domain translation involves generating a target domain sample given a condition in the source domain. Most existing methods focus on fixed input and output domains, i.e. they only work for specific configurations (i.e. for two domains, either $D_1\rightarrow{}D_2$ or $D_2\rightarrow{}D_1$). This paper proposes Multi-Domain Diffusion (MDD), a conditional diffusion framework for multi-domain translation in a semi-supervised context. Unlike previous methods, MDD does not require defining input and output domains, allowing translation between any partition of domains within a set (such as $(D_1, D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$, etc. for 3 domains), without the need to train separate models for each domain configuration. The key idea behind MDD is to leverage the noise formulation of diffusion models by incorporating one noise level per domain, which allows missing domains to be modeled with noise in a natural way. This transforms the tra
    
[^10]: 探索学习系统中信息熵变化的影响

    Exploring the Influence of Information Entropy Change in Learning Systems. (arXiv:2309.10625v1 [cs.AI])

    [http://arxiv.org/abs/2309.10625](http://arxiv.org/abs/2309.10625)

    本研究探索了在深度学习系统中引入噪声对性能的影响，证明了特定噪声可以在降低任务复杂性的条件下提升深度架构的性能，通过实验证明了在大规模图像数据集中的显著性能提升。

    

    在本研究中，我们通过向输入/隐含特征添加噪声来探索深度学习系统中熵变化的影响。本文的应用重点是计算机视觉中的深度学习任务，但所提出的理论可以进一步应用于其他领域。噪声通常被视为各种深度学习架构（如卷积神经网络和视觉变换器）以及图像分类和迁移学习等不同学习任务中的有害扰动。然而，本文旨在重新思考传统命题是否总是成立。我们证明了在特定条件下，特定噪声可以提升各种深度架构的性能。我们在信息熵定义的任务复杂性减少方面从理论上证明了正噪声的增强效果，并在大规模图像数据集（如ImageNet）中实验证明了显著的性能提升。

    In this work, we explore the influence of entropy change in deep learning systems by adding noise to the inputs/latent features. The applications in this paper focus on deep learning tasks within computer vision, but the proposed theory can be further applied to other fields. Noise is conventionally viewed as a harmful perturbation in various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers (ViTs), as well as different learning tasks like image classification and transfer learning. However, this paper aims to rethink whether the conventional proposition always holds. We demonstrate that specific noise can boost the performance of various deep architectures under certain conditions. We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy and experimentally show the significant performance gain in large image datasets, such as the ImageNet. Herein, we use the informat
    

