# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Developing and Evaluating a Design Method for Positive Artificial Intelligence](https://rss.arxiv.org/abs/2402.01499) | 这项研究提出并评估了一种正向人工智能设计方法，用于确保人工智能系统对社会产生积极影响。该方法通过以人为中心的流程，将幸福愿景转化为具体实践，并通过持续的测量和反馈循环进行支持。 |
| [^2] | [Fairness in Large Language Models: A Taxonomic Survey](https://arxiv.org/abs/2404.01349) | 该调查总结了大型语言模型中公平性的最新进展，包括对偏见因素的分析、公平度量和现有算法分类。 |
| [^3] | [A Survey on Consumer IoT Traffic: Security and Privacy](https://arxiv.org/abs/2403.16149) | 本调查针对消费者物联网（CIoT）流量分析从安全和隐私的角度出发，总结了CIoT流量分析的新特征、最新进展和挑战，认为通过流量分析可以揭示CIoT领域中的安全和隐私问题。 |
| [^4] | [Spectral Motion Alignment for Video Motion Transfer using Diffusion Models](https://arxiv.org/abs/2403.15249) | 提出了一种名为Spectral Motion Alignment（SMA）的新框架，通过傅立叶和小波变换来优化和对齐运动向量，学习整帧全局运动动态，减轻空间伪影，有效改善运动转移。 |
| [^5] | [Hands-Free VR](https://arxiv.org/abs/2402.15083) | Hands-Free VR 是一种无需手部操作的虚拟现实系统，通过语音命令实现，具有英语口音鲁棒性，通过深度学习模型和大型语言模型实现对文本的转换和执行。 |
| [^6] | [XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event Prediction](https://arxiv.org/abs/2402.02258) | XTSFormer是一个用于不规则时间事件预测的跨时空尺度的Transformer模型，通过新颖的循环感知时间位置编码和分层的多尺度时间注意机制来解决不规则时间间隔、循环、周期性和多尺度事件交互等挑战。 |
| [^7] | [EASRec: Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems](https://arxiv.org/abs/2402.00390) | EASRec是一个针对顺序推荐系统的弹性架构搜索方法，通过自动剪枝技术和先进模型架构结合，以及资源受限神经架构搜索技术，实现了降低计算成本和资源消耗的同时保持或增强准确性。 |
| [^8] | [Enhancing Multimodal Large Language Models with Vision Detection Models: An Empirical Study](https://arxiv.org/abs/2401.17981) | 本文通过实证研究，将最先进的目标检测和光学字符识别模型与多模态大型语言模型相结合，在提高图像理解和减少回答错误插入方面取得了显著改进。 |
| [^9] | [Agent-OM: Leveraging LLM Agents for Ontology Matching](https://arxiv.org/abs/2312.00326) | 本研究提出了Agent-OM，利用LLM代理为本体匹配系统引入了新的设计范式。 |
| [^10] | [Selective Uncertainty Propagation in Offline RL](https://arxiv.org/abs/2302.00284) | 本论文提出了一种名为选择性不确定性传播的方法，用于解决离线强化学习中的分布偏移问题。该方法通过自适应的方式建立置信区间，有效地处理了实际问题中策略学习的挑战。 |
| [^11] | [Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series.](http://arxiv.org/abs/2401.04979) | 我们提出了一种可逆解决非规则采样时间序列的神经微分方程分析方法，通过引入神经流的概念，我们的方法既保证了可逆性又降低了计算负担，并且在分类和插值任务中表现出了优异的性能。 |
| [^12] | [LoBaSS: Gauging Learnability in Supervised Fine-tuning Data.](http://arxiv.org/abs/2310.13008) | 本文介绍了一种新的方法LoBaSS，利用数据的可学习性作为选择监督微调数据的主要标准。这种方法可以根据模型的能力将数据选择与模型对齐，确保高效的学习。 |
| [^13] | [Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis.](http://arxiv.org/abs/2309.07675) | 本文提出了一种基于集合的可达性分析方法，通过 emergent representation 实现目标空间抽象，在分层强化学习中自主发现符号目标表示，并引入封建HRL算法来同时学习目标表示和分层策略。 |
| [^14] | [DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend.](http://arxiv.org/abs/2309.03579) | 提出了一种名为DTW+S的新型测量方法，它通过创建局部趋势的矩阵表示，并应用动态时间规整来计算距离，解决了现有方法无法捕捉局部趋势相似性的问题。 |
| [^15] | [Scaling Laws for Imitation Learning in NetHack.](http://arxiv.org/abs/2307.09423) | 本文研究了在NetHack游戏中的模仿学习，发现通过扩大模型和数据规模可以改进模仿学习的效果，并建立了训练计算最优IL代理人的幂律。 |
| [^16] | [UOR: Universal Backdoor Attacks on Pre-trained Language Models.](http://arxiv.org/abs/2305.09574) | 本文介绍了一种新的后门攻击方法UOR，可以自动选择触发器并学习通用输出表示，成功率高达99.3％，能够对多种预训练语言模型和下游任务实施攻击，且可突破最新的防御方法。 |

# 详细

[^1]: 开发和评估正向人工智能设计方法

    Developing and Evaluating a Design Method for Positive Artificial Intelligence

    [https://rss.arxiv.org/abs/2402.01499](https://rss.arxiv.org/abs/2402.01499)

    这项研究提出并评估了一种正向人工智能设计方法，用于确保人工智能系统对社会产生积极影响。该方法通过以人为中心的流程，将幸福愿景转化为具体实践，并通过持续的测量和反馈循环进行支持。

    

    随着人工智能的不断发展，确保人工智能系统对社会产生积极影响变得至关重要，尤其是在人工智能系统在各个方面日益普及的情况下。然而，开发“AI for good”在与复杂人类价值观保持一致方面存在巨大挑战。目前，我们缺乏成熟的方法来解决这些挑战。本文介绍和评估了正向人工智能设计方法，旨在填补这一空白。该方法提供了一个以人为中心的流程，将幸福愿景转化为具体实践。首先，我们解释了该方法的四个关键步骤：情境化、操作化、优化化和实现福祉，同时支持持续测量和反馈循环。然后，我们提出了一个多个案例研究，其中初学者设计师应用了该方法，揭示了与效力和可用性相关的优点和缺点。接下来，一项专家评估研究评估了所得概念的质量，将其评为中等水平。

    As artificial intelligence (AI) continues advancing, ensuring positive societal impacts becomes critical, especially as AI systems become increasingly ubiquitous in various aspects of life. However, developing "AI for good" poses substantial challenges around aligning systems with complex human values. Presently, we lack mature methods for addressing these challenges. This article presents and evaluates the Positive AI design method aimed at addressing this gap. The method provides a human-centered process to translate wellbeing aspirations into concrete practices. First, we explain the method's four key steps: contextualizing, operationalizing, optimizing, and implementing wellbeing supported by continuous measurement for feedback cycles. We then present a multiple case study where novice designers applied the method, revealing strengths and weaknesses related to efficacy and usability. Next, an expert evaluation study assessed the quality of the resulting concepts, rating them modera
    
[^2]: 大型语言模型中的公平性：一个分类调查

    Fairness in Large Language Models: A Taxonomic Survey

    [https://arxiv.org/abs/2404.01349](https://arxiv.org/abs/2404.01349)

    该调查总结了大型语言模型中公平性的最新进展，包括对偏见因素的分析、公平度量和现有算法分类。

    

    大型语言模型（LLMs）在各个领域展现了显著的成功。然而，尽管它们在许多实际应用中表现出色，大多数这些算法缺乏公平性考虑。因此，它们可能导致针对某些社区，特别是边缘化人群的歧视性结果，促使对公平的LLMs进行广泛研究。与传统机器学习中的公平相反，在LLMs中的公平性涉及独特的背景、分类法和实现技术。为此，该调查提供了关于公平LLMs的现有文献研究进展的全面概述。具体来说，提供了有关LLMs的简要介绍，接着分析了导致LLMs偏见的因素。此外，分类讨论了LLMs中的公平概念，总结了评估LLMs偏见的指标和现有算法。

    arXiv:2404.01349v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable success across various domains. However, despite their promising performance in numerous real-world applications, most of these algorithms lack fairness considerations. Consequently, they may lead to discriminatory outcomes against certain communities, particularly marginalized populations, prompting extensive study in fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in traditional machine learning, entails exclusive backgrounds, taxonomies, and fulfillment techniques. To this end, this survey presents a comprehensive overview of recent advances in the existing literature concerning fair LLMs. Specifically, a brief introduction to LLMs is provided, followed by an analysis of factors contributing to bias in LLMs. Additionally, the concept of fairness in LLMs is discussed categorically, summarizing metrics for evaluating bias in LLMs and existing algorithms 
    
[^3]: 消费者物联网流量的调查：安全与隐私

    A Survey on Consumer IoT Traffic: Security and Privacy

    [https://arxiv.org/abs/2403.16149](https://arxiv.org/abs/2403.16149)

    本调查针对消费者物联网（CIoT）流量分析从安全和隐私的角度出发，总结了CIoT流量分析的新特征、最新进展和挑战，认为通过流量分析可以揭示CIoT领域中的安全和隐私问题。

    

    在过去几年里，消费者物联网（CIoT）已经进入了公众生活。尽管CIoT提高了人们日常生活的便利性，但也带来了新的安全和隐私问题。我们尝试通过流量分析这一安全领域中的流行方法，找出研究人员可以从流量分析中了解CIoT安全和隐私方面的内容。本调查从安全和隐私角度探讨了CIoT流量分析中的新特征、CIoT流量分析的最新进展以及尚未解决的挑战。我们从2018年1月至2023年12月收集了310篇与CIoT流量分析有关的安全和隐私角度的论文，总结了识别了CIoT新特征的CIoT流量分析过程。然后，我们根据五个应用目标详细介绍了现有的研究工作：设备指纹识别、用户活动推断、恶意行为检测、隐私泄露以及通信模式识别。

    arXiv:2403.16149v1 Announce Type: cross  Abstract: For the past few years, the Consumer Internet of Things (CIoT) has entered public lives. While CIoT has improved the convenience of people's daily lives, it has also brought new security and privacy concerns. In this survey, we try to figure out what researchers can learn about the security and privacy of CIoT by traffic analysis, a popular method in the security community. From the security and privacy perspective, this survey seeks out the new characteristics in CIoT traffic analysis, the state-of-the-art progress in CIoT traffic analysis, and the challenges yet to be solved. We collected 310 papers from January 2018 to December 2023 related to CIoT traffic analysis from the security and privacy perspective and summarized the process of CIoT traffic analysis in which the new characteristics of CIoT are identified. Then, we detail existing works based on five application goals: device fingerprinting, user activity inference, malicious
    
[^4]: 使用扩散模型进行视频运动转移的光谱运动对齐

    Spectral Motion Alignment for Video Motion Transfer using Diffusion Models

    [https://arxiv.org/abs/2403.15249](https://arxiv.org/abs/2403.15249)

    提出了一种名为Spectral Motion Alignment（SMA）的新框架，通过傅立叶和小波变换来优化和对齐运动向量，学习整帧全局运动动态，减轻空间伪影，有效改善运动转移。

    

    扩散模型的发展在视频生成和理解方面产生了巨大影响。特别是，文本到视频扩散模型（VDMs）显著促进了将输入视频定制为目标外观、运动等。尽管取得了这些进展，但准确提取视频帧的运动信息仍然存在挑战。现有作品利用连续帧残差作为目标运动向量，但它们固有地缺乏全局运动背景，并容易受到逐帧失真的影响。为了解决这个问题，我们提出了光谱运动对齐（SMA），这是一个通过傅立叶和小波变换来优化和对齐运动向量的新框架。SMA通过整合频域正则化来学习运动模式，促进整帧全局运动动态的学习，并减轻空间伪影。大量实验证明了SMA在改善运动转移方面的有效性。

    arXiv:2403.15249v1 Announce Type: cross  Abstract: The evolution of diffusion models has greatly impacted video generation and understanding. Particularly, text-to-video diffusion models (VDMs) have significantly facilitated the customization of input video with target appearance, motion, etc. Despite these advances, challenges persist in accurately distilling motion information from video frames. While existing works leverage the consecutive frame residual as the target motion vector, they inherently lack global motion context and are vulnerable to frame-wise distortions. To address this, we present Spectral Motion Alignment (SMA), a novel framework that refines and aligns motion vectors using Fourier and wavelet transforms. SMA learns motion patterns by incorporating frequency-domain regularization, facilitating the learning of whole-frame global motion dynamics, and mitigating spatial artifacts. Extensive experiments demonstrate SMA's efficacy in improving motion transfer while main
    
[^5]: 无需手部操作的虚拟现实系统

    Hands-Free VR

    [https://arxiv.org/abs/2402.15083](https://arxiv.org/abs/2402.15083)

    Hands-Free VR 是一种无需手部操作的虚拟现实系统，通过语音命令实现，具有英语口音鲁棒性，通过深度学习模型和大型语言模型实现对文本的转换和执行。

    

    本文介绍了一种名为Hands-Free VR的基于语音的自然语言虚拟现实界面。用户可以通过语音发出命令，其语音音频数据经过一个针对单词音素相似性和英语口音的鲁棒性进行微调的语音识别深度学习模型转换为文本，然后利用一个对自然语言多样性具有鲁棒性的大型语言模型将文本映射为可执行的虚拟现实命令。Hands-Free VR在一个受控的被试研究中（N = 22）进行了评估，要求参与者找到特定物体并以各种配置放置它们。在对照条件下，参与者使用传统的虚拟现实用户界面通过手持控制器抓取、搬运和定位物体。在实验条件下，参与者使用Hands-Free VR。结果表明：（1）Hands-Free VR对英语口音具有鲁棒性，因为在我们的20名参与者中，英语不是他们的首选语言。

    arXiv:2402.15083v1 Announce Type: cross  Abstract: The paper introduces Hands-Free VR, a voice-based natural-language interface for VR. The user gives a command using their voice, the speech audio data is converted to text using a speech-to-text deep learning model that is fine-tuned for robustness to word phonetic similarity and to spoken English accents, and the text is mapped to an executable VR command using a large language model that is robust to natural language diversity. Hands-Free VR was evaluated in a controlled within-subjects study (N = 22) that asked participants to find specific objects and to place them in various configurations. In the control condition participants used a conventional VR user interface to grab, carry, and position the objects using the handheld controllers. In the experimental condition participants used Hands-Free VR. The results confirm that: (1) Hands-Free VR is robust to spoken English accents, as for 20 of our participants English was not their f
    
[^6]: XTSFormer: 跨时空尺度的Transformer用于不规则时间事件预测

    XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event Prediction

    [https://arxiv.org/abs/2402.02258](https://arxiv.org/abs/2402.02258)

    XTSFormer是一个用于不规则时间事件预测的跨时空尺度的Transformer模型，通过新颖的循环感知时间位置编码和分层的多尺度时间注意机制来解决不规则时间间隔、循环、周期性和多尺度事件交互等挑战。

    

    事件预测旨在基于历史事件序列预测未来事件的时间和类型。尽管其重要性，但存在几个挑战，包括连续事件之间时间间隔的不规则性、循环、周期性和多尺度事件交互，以及长事件序列的高计算成本。现有的神经时间点过程（TPP）方法不能捕捉事件交互的多尺度特性，而这在许多实际应用中（如临床事件数据）很常见。为了解决这些问题，我们提出了跨时空尺度的Transformer（XTSFormer），特别适用于不规则时间事件数据。我们的模型包含两个关键组成部分：一种新颖的基于特征的循环感知时间位置编码（FCPE），能够灵活捕捉时间的循环性质，以及一个分层的多尺度时间注意机制。这些尺度由自底向上的聚类算法确定。

    Event prediction aims to forecast the time and type of a future event based on a historical event sequence. Despite its significance, several challenges exist, including the irregularity of time intervals between consecutive events, the existence of cycles, periodicity, and multi-scale event interactions, as well as the high computational costs for long event sequences. Existing neural temporal point processes (TPPs) methods do not capture the multi-scale nature of event interactions, which is common in many real-world applications such as clinical event data. To address these issues, we propose the cross-temporal-scale transformer (XTSFormer), designed specifically for irregularly timed event data. Our model comprises two vital components: a novel Feature-based Cycle-aware Time Positional Encoding (FCPE) that adeptly captures the cyclical nature of time, and a hierarchical multi-scale temporal attention mechanism. These scales are determined by a bottom-up clustering algorithm. Extens
    
[^7]: EASRec：用于高效长期顺序推荐系统的弹性架构搜索

    EASRec: Elastic Architecture Search for Efficient Long-term Sequential Recommender Systems

    [https://arxiv.org/abs/2402.00390](https://arxiv.org/abs/2402.00390)

    EASRec是一个针对顺序推荐系统的弹性架构搜索方法，通过自动剪枝技术和先进模型架构结合，以及资源受限神经架构搜索技术，实现了降低计算成本和资源消耗的同时保持或增强准确性。

    

    在数据丰富的时代，从海量信息中提取有意义的见解的能力至关重要。我们的研究解决了当前顺序推荐系统（SRSs）在计算和资源效率方面存在的问题，特别是那些采用了基于注意力模型（如SASRec）的系统。这些系统旨在为各种应用提供下一个项目的推荐，从电子商务到社交网络。然而，这些系统在推理阶段会产生相当大的计算成本和资源消耗。为了解决这些问题，我们的研究提出了一种结合自动剪枝技术和先进模型架构的新方法。我们还探索了在推荐系统领域中流行的资源受限神经架构搜索（NAS）技术的潜力，以调整模型以减少FLOPs、延迟和能量使用，同时保持或增强准确性。我们的工作的主要贡献是开发了一种

    In this age where data is abundant, the ability to distill meaningful insights from the sea of information is essential. Our research addresses the computational and resource inefficiencies that current Sequential Recommender Systems (SRSs) suffer from. especially those employing attention-based models like SASRec, These systems are designed for next-item recommendations in various applications, from e-commerce to social networks. However, such systems suffer from substantial computational costs and resource consumption during the inference stage. To tackle these issues, our research proposes a novel method that combines automatic pruning techniques with advanced model architectures. We also explore the potential of resource-constrained Neural Architecture Search (NAS), a technique prevalent in the realm of recommendation systems, to fine-tune models for reduced FLOPs, latency, and energy usage while retaining or even enhancing accuracy. The main contribution of our work is developing 
    
[^8]: 通过视觉检测模型增强多模态大型语言模型：一项实证研究

    Enhancing Multimodal Large Language Models with Vision Detection Models: An Empirical Study

    [https://arxiv.org/abs/2401.17981](https://arxiv.org/abs/2401.17981)

    本文通过实证研究，将最先进的目标检测和光学字符识别模型与多模态大型语言模型相结合，在提高图像理解和减少回答错误插入方面取得了显著改进。

    

    尽管多模态大型语言模型（MLLMs）在集成文本和图像模态方面具有令人印象深刻的能力，但在准确解释细节视觉元素方面仍存在挑战。本文通过将最先进的目标检测和光学字符识别模型与MLLMs结合，进行实证研究，旨在提高对细粒度图像理解，并减少回答中的错误插入。我们的研究探讨了基于嵌入的检测信息的融合，这种融合对MLLMs的原始能力的影响，以及检测模型的可互换性。我们对LLaVA-1.5、DINO和PaddleOCRv2等模型进行了系统实验，发现我们的方法不仅改善了MLLMs在特定视觉任务中的性能，而且保持了它们的原始优势。通过在10个基准测试中，增强的MLLMs在9个测试中超越了最先进模型，标准化平均得分提升高达12.99%，取得了显著的改进。

    Despite the impressive capabilities of Multimodal Large Language Models (MLLMs) in integrating text and image modalities, challenges remain in accurately interpreting detailed visual elements. This paper presents an empirical study on enhancing MLLMs with state-of-the-art (SOTA) object detection and Optical Character Recognition models to improve fine-grained image understanding and reduce hallucination in responses. Our research investigates the embedding-based infusion of detection information, the impact of such infusion on the MLLMs' original abilities, and the interchangeability of detection models. We conduct systematic experiments with models such as LLaVA-1.5, DINO, and PaddleOCRv2, revealing that our approach not only refines MLLMs' performance in specific visual tasks but also maintains their original strengths. The resulting enhanced MLLMs outperform SOTA models on 9 out of 10 benchmarks, achieving an improvement of up to 12.99% on the normalized average score, marking a not
    
[^9]: Agent-OM：利用LLM代理进行本体匹配

    Agent-OM: Leveraging LLM Agents for Ontology Matching

    [https://arxiv.org/abs/2312.00326](https://arxiv.org/abs/2312.00326)

    本研究提出了Agent-OM，利用LLM代理为本体匹配系统引入了新的设计范式。

    

    本体匹配（OM）能够实现不同本体之间的语义互操作性，通过对齐相关实体来解决其概念异构性。本研究引入了一种新颖的基于代理的LLM设计范式，命名为Agent-OM，包括两个用于检索和匹配的同体代理以及一组基于提示的简单OM工具。

    arXiv:2312.00326v2 Announce Type: replace  Abstract: Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM, consisting of two Siamese agents for retrieval and matching, with a set of simple prompt-based OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAE
    
[^10]: 选择性不确定性传播在离线强化学习中的应用

    Selective Uncertainty Propagation in Offline RL

    [https://arxiv.org/abs/2302.00284](https://arxiv.org/abs/2302.00284)

    本论文提出了一种名为选择性不确定性传播的方法，用于解决离线强化学习中的分布偏移问题。该方法通过自适应的方式建立置信区间，有效地处理了实际问题中策略学习的挑战。

    

    本研究考虑有限时间段离线强化学习的情景，目标在于应对动态规划算法中每一步策略学习的挑战。通过评估离开行为策略在第h步时的处理效果，就可以学习到这一步的策略。由于每一步策略都会影响下一状态的分布，相关的分布偏移问题使得这一问题在统计学上比随机情境挑战下的处理效果估计更加困难。然而，许多现实强化学习问题的难度介于这两种情境之间。我们开发了一种灵活且通用的方法，名为选择性不确定性传播，用于建立置信区间，并根据相关分布偏移问题的难度进行自适应。在玩具环境中展示了我们方法的优势，并证明了这些技术在离线策略学习中的好处。

    We consider the finite-horizon offline reinforcement learning (RL) setting, and are motivated by the challenge of learning the policy at any step h in dynamic programming (DP) algorithms. To learn this, it is sufficient to evaluate the treatment effect of deviating from the behavioral policy at step h after having optimized the policy for all future steps. Since the policy at any step can affect next-state distributions, the related distributional shift challenges can make this problem far more statistically hard than estimating such treatment effects in the stochastic contextual bandit setting. However, the hardness of many real-world RL instances lies between the two regimes. We develop a flexible and general method called selective uncertainty propagation for confidence interval construction that adapts to the hardness of the associated distribution shift challenges. We show benefits of our approach on toy environments and demonstrate the benefits of these techniques for offline pol
    
[^11]: 可逆解决非规则采样时间序列的神经微分方程分析方法

    Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series. (arXiv:2401.04979v1 [cs.LG])

    [http://arxiv.org/abs/2401.04979](http://arxiv.org/abs/2401.04979)

    我们提出了一种可逆解决非规则采样时间序列的神经微分方程分析方法，通过引入神经流的概念，我们的方法既保证了可逆性又降低了计算负担，并且在分类和插值任务中表现出了优异的性能。

    

    为了处理非规则和不完整的时间序列数据的复杂性，我们提出了一种基于神经微分方程（NDE）的可逆解决方案。虽然基于NDE的方法是分析非规则采样时间序列的一种强大方法，但它们通常不能保证在其标准形式下进行可逆变换。我们的方法建议使用具有神经流的神经控制微分方程（Neural CDEs）的变种，该方法在保持较低的计算负担的同时确保了可逆性。此外，它还可以训练双重潜在空间，增强了对动态时间动力学的建模能力。我们的研究提出了一个先进的框架，在分类和插值任务中都表现出色。我们方法的核心是一个经过精心设计的增强型双重潜在状态架构，用于在各种时间序列任务中提高精度。实证分析表明，我们的方法明显优于现有模型。

    To handle the complexities of irregular and incomplete time series data, we propose an invertible solution of Neural Differential Equations (NDE)-based method. While NDE-based methods are a powerful method for analyzing irregularly-sampled time series, they typically do not guarantee reversible transformations in their standard form. Our method suggests the variation of Neural Controlled Differential Equations (Neural CDEs) with Neural Flow, which ensures invertibility while maintaining a lower computational burden. Additionally, it enables the training of a dual latent space, enhancing the modeling of dynamic temporal dynamics. Our research presents an advanced framework that excels in both classification and interpolation tasks. At the core of our approach is an enhanced dual latent states architecture, carefully designed for high precision across various time series tasks. Empirical analysis demonstrates that our method significantly outperforms existing models. This work significan
    
[^12]: LoBaSS：在监督微调数据中测量可学习性

    LoBaSS: Gauging Learnability in Supervised Fine-tuning Data. (arXiv:2310.13008v1 [cs.LG])

    [http://arxiv.org/abs/2310.13008](http://arxiv.org/abs/2310.13008)

    本文介绍了一种新的方法LoBaSS，利用数据的可学习性作为选择监督微调数据的主要标准。这种方法可以根据模型的能力将数据选择与模型对齐，确保高效的学习。

    

    监督微调（SFT）是将大型语言模型（LLM）与特定任务的先决条件对齐的关键阶段。微调数据的选择深刻影响模型的性能，传统上以数据质量和分布为基础。在本文中，我们引入了SFT数据选择的一个新维度：可学习性。这个新维度的动机是由LLM在预训练阶段获得的能力。鉴于不同的预训练模型具有不同的能力，适合一个模型的SFT数据可能不适合另一个模型。因此，我们引入了学习能力这个术语来定义数据对模型进行有效学习的适合性。我们提出了基于损失的SFT数据选择（LoBaSS）方法，利用数据的可学习性作为选择SFT数据的主要标准。这种方法提供了一种细致的方法，允许将数据选择与固有的模型能力对齐，确保高效的学习。

    Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites. The selection of fine-tuning data profoundly influences the model's performance, whose principle is traditionally grounded in data quality and distribution. In this paper, we introduce a new dimension in SFT data selection: learnability. This new dimension is motivated by the intuition that SFT unlocks capabilities acquired by a LLM during the pretraining phase. Given that different pretrained models have disparate capabilities, the SFT data appropriate for one may not suit another. Thus, we introduce the term learnability to define the suitability of data for effective learning by the model. We present the Loss Based SFT Data Selection (LoBaSS) method, utilizing data learnability as the principal criterion for the selection SFT data. This method provides a nuanced approach, allowing the alignment of data selection with inherent model capabilities, ensuring op
    
[^13]: 通过基于集合的可达性分析，在分层强化学习中实现目标空间抽象

    Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis. (arXiv:2309.07675v1 [cs.LG])

    [http://arxiv.org/abs/2309.07675](http://arxiv.org/abs/2309.07675)

    本文提出了一种基于集合的可达性分析方法，通过 emergent representation 实现目标空间抽象，在分层强化学习中自主发现符号目标表示，并引入封建HRL算法来同时学习目标表示和分层策略。

    

    开放式学习通过使用符号方法进行目标表示而获益良多，因为它们提供了一种结构化知识以进行高效和可传递的学习。然而，现有的依赖符号推理的分层强化学习(HRL)方法通常受限于需要手动设置目标表示。自主发现符号目标表示的挑战在于它必须保留关键信息，例如环境动力学。在本文中，我们提出了一种通过新出现的表示来实现目标发现的发展机制，该表示将具有类似任务中的角色的环境状态集合进行抽象（即分组）。我们引入了一个同时学习目标表示和分层策略的封建HRL算法。该算法使用神经网络的符号可达性分析来近似状态集合之间的过渡关系，并改进目标表示。

    Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this paper, we propose a developmental mechanism for goal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We introduce a Feudal HRL algorithm that concurrently learns both the goal representation and a hierarchical policy. The algorithm uses symbolic reachability analysis for neural networks to approximate the transition relation among sets of states and to refine the goal representation. We eval
    
[^14]: DTW+S: 使用有序局部趋势进行基于形状的时间序列比较

    DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend. (arXiv:2309.03579v1 [cs.LG])

    [http://arxiv.org/abs/2309.03579](http://arxiv.org/abs/2309.03579)

    提出了一种名为DTW+S的新型测量方法，它通过创建局部趋势的矩阵表示，并应用动态时间规整来计算距离，解决了现有方法无法捕捉局部趋势相似性的问题。

    

    时间序列数据的距离或相似度的测量是许多应用包括分类和聚类的基本方面。现有的测量方法可能由于局部趋势（形状）而无法捕捉到相似之处，甚至可能产生误导性的结果。我们的目标是开发一种能够寻找在相似时间周围发生的相似趋势的测量方法，并且对应用领域的研究人员易于解释的方法。这对于时间序列具有有序的有意义的局部趋势序列的应用特别有用，例如在流行病中（从增长到峰值再到减少）。我们提出了一种新的测量方法，DTW+S，它创建了一个可解释的“保持接近性”的矩阵表示时间序列，其中每一列代表局部趋势，然后应用动态时间规整来计算这些矩阵之间的距离。我们提供了支持这种表示的理论分析。我们展示了DTW+S的实用性。

    Measuring distance or similarity between time-series data is a fundamental aspect of many applications including classification and clustering. Existing measures may fail to capture similarities due to local trends (shapes) and may even produce misleading results. Our goal is to develop a measure that looks for similar trends occurring around similar times and is easily interpretable for researchers in applied domains. This is particularly useful for applications where time-series have a sequence of meaningful local trends that are ordered, such as in epidemics (a surge to an increase to a peak to a decrease). We propose a novel measure, DTW+S, which creates an interpretable "closeness-preserving" matrix representation of the time-series, where each column represents local trends, and then it applies Dynamic Time Warping to compute distances between these matrices. We present a theoretical analysis that supports the choice of this representation. We demonstrate the utility of DTW+S in 
    
[^15]: 在NetHack中的模仿学习的规模律

    Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])

    [http://arxiv.org/abs/2307.09423](http://arxiv.org/abs/2307.09423)

    本文研究了在NetHack游戏中的模仿学习，发现通过扩大模型和数据规模可以改进模仿学习的效果，并建立了训练计算最优IL代理人的幂律。

    

    模仿学习 (IL) 是机器学习中最常用的方法之一。然而，虽然强大，但许多研究发现它往往不能完全恢复出潜在的专家行为。然而，这些研究没有深入探究模型和数据规模的扩大在其中的作用。受最近在自然语言处理 (NLP) 领域的工作的启发，在那里“扩大规模”已经导致了越来越有能力的领域特定语言模型 (LLMs)，我们研究了仔细扩大模型和数据规模是否可以在模仿学习的设置中带来类似的改进。为了展示我们的发现，我们将重点放在 NetHack 游戏上，这是一个具有程序生成、随机性、长期依赖性和部分可观测性的具有挑战性的环境。我们发现 IL 的损失和平均回报随着计算预算的变化而平滑变化且强相关，从而在模型大小和样本数量方面为训练计算最优的 IL 代理人的计算预算建立了幂律。我们预测并训练了几个具有 IL 的NetHack代理。

    Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where "scaling up" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL an
    
[^16]: UOR：预训练语言模型的通用后门攻击

    UOR: Universal Backdoor Attacks on Pre-trained Language Models. (arXiv:2305.09574v1 [cs.CL])

    [http://arxiv.org/abs/2305.09574](http://arxiv.org/abs/2305.09574)

    本文介绍了一种新的后门攻击方法UOR，可以自动选择触发器并学习通用输出表示，成功率高达99.3％，能够对多种预训练语言模型和下游任务实施攻击，且可突破最新的防御方法。

    

    在预训练语言模型中植入后门可以传递到各种下游任务，这对安全构成了严重威胁。然而，现有的针对预训练语言模型的后门攻击大都是非目标和特定任务的。很少有针对目标和任务不可知性的方法使用手动预定义的触发器和输出表示，这使得攻击效果不够强大和普适。本文首先总结了一个更具威胁性的预训练语言模型后门攻击应满足的要求，然后提出了一种新的后门攻击方法UOR，通过将手动选择变成自动优化，打破了以往方法的瓶颈。具体来说，我们定义了被污染的监督对比学习，可以自动学习各种预训练语言模型触发器的更加均匀和通用输出表示。此外，我们使用梯度搜索选取适当的触发词，可以适应不同的预训练语言模型和词汇表。实验证明，UOR可以在各种PLMs和下游任务中实现高后门成功率（高达99.3％），优于现有方法。此外，UOR还可以突破对抗后门攻击的最新防御方法。

    Backdoors implanted in pre-trained language models (PLMs) can be transferred to various downstream tasks, which exposes a severe security threat. However, most existing backdoor attacks against PLMs are un-targeted and task-specific. Few targeted and task-agnostic methods use manually pre-defined triggers and output representations, which prevent the attacks from being more effective and general. In this paper, we first summarize the requirements that a more threatening backdoor attack against PLMs should satisfy, and then propose a new backdoor attack method called UOR, which breaks the bottleneck of the previous approach by turning manual selection into automatic optimization. Specifically, we define poisoned supervised contrastive learning which can automatically learn the more uniform and universal output representations of triggers for various PLMs. Moreover, we use gradient search to select appropriate trigger words which can be adaptive to different PLMs and vocabularies. Experi
    

