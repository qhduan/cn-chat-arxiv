# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Multi-Generative Agent Collective Decision-Making in Urban Planning: A Case Study for Kendall Square Renovation](https://arxiv.org/abs/2402.11314) | 多生成代理系统在城市规划中模拟社区决策，发现沟通有助于集体推理，而包含人口统计数据和生活价值导致意见分歧。这为城市规划和社区参与提供了有价值的见解。 |
| [^2] | [An Evaluation on Large Language Model Outputs: Discourse and Memorization.](http://arxiv.org/abs/2304.08637) | 评估了九个大语言模型的输出，发现其中80％包含记忆数据，但包含最多记忆内容的输出更可能是高质量的。提出了缓解策略以降低记忆文本率。 |

# 详细

[^1]: 多生成代理集体决策在城市规划中的应用：Kendall Square改造案例研究

    Multi-Generative Agent Collective Decision-Making in Urban Planning: A Case Study for Kendall Square Renovation

    [https://arxiv.org/abs/2402.11314](https://arxiv.org/abs/2402.11314)

    多生成代理系统在城市规划中模拟社区决策，发现沟通有助于集体推理，而包含人口统计数据和生活价值导致意见分歧。这为城市规划和社区参与提供了有价值的见解。

    

    在这项研究中，我们开发了一个多生成代理系统，用于模拟 Kendall Square Volpe 大厦改造的社区决策过程。通过与当地利益相关者的访谈，我们的模拟结合了不同程度的沟通、人口统计数据和生活价值在代理提示中的应用。结果显示，代理之间的沟通改善了集体推理，而包含人口统计数据和生活价值导致了更明显的意见分歧。这些发现凸显了人工智能在理解复杂社会互动和决策过程中的潜在应用，为城市规划和 Kendall Square 等多样化环境中的社区参与提供了宝贵的见解。

    arXiv:2402.11314v1 Announce Type: cross  Abstract: In this study, we develop a multiple-generative agent system to simulate community decision-making for the redevelopment of Kendall Square's Volpe building. Drawing on interviews with local stakeholders, our simulations incorporated varying degrees of communication, demographic data, and life values in the agent prompts. The results revealed that communication among agents improved collective reasoning, while the inclusion of demographic and life values led to more distinct opinions. These findings highlight the potential application of AI in understanding complex social interactions and decision-making processes, offering valuable insights for urban planning and community engagement in diverse settings like Kendall Square.
    
[^2]: 大型语言模型输出的评估：话语和记忆

    An Evaluation on Large Language Model Outputs: Discourse and Memorization. (arXiv:2304.08637v1 [cs.CL])

    [http://arxiv.org/abs/2304.08637](http://arxiv.org/abs/2304.08637)

    评估了九个大语言模型的输出，发现其中80％包含记忆数据，但包含最多记忆内容的输出更可能是高质量的。提出了缓解策略以降低记忆文本率。

    

    我们对九个最广泛可用的大型语言模型（LLMs）生成的各种输出进行了经验性评估。我们使用现成的工具进行分析，发现在与输出病态（例如，反事实和逻辑上的错误陈述）以及不保持主题等方面的关系中，记忆文本百分比、独特文本百分比和整体输出质量之间存在相关性。总体而言，80.0％的输出包含记忆数据，但包含最多记忆内容的输出也更有可能被认为具有高质量。我们讨论和评估了缓解策略，并显示，在评估的模型中，输出的记忆文本率有所降低。最后，我们就学习、记忆和评估优质文本的潜在影响进行了讨论。

    We present an empirical evaluation of various outputs generated by nine of the most widely-available large language models (LLMs). Our analysis is done with off-the-shelf, readily-available tools. We find a correlation between percentage of memorized text, percentage of unique text, and overall output quality, when measured with respect to output pathologies such as counterfactual and logically-flawed statements, and general failures like not staying on topic. Overall, 80.0% of the outputs evaluated contained memorized data, but outputs containing the most memorized content were also more likely to be considered of high quality. We discuss and evaluate mitigation strategies, showing that, in the models evaluated, the rate of memorized text being output is reduced. We conclude with a discussion on potential implications around what it means to learn, to memorize, and to evaluate quality text.
    

