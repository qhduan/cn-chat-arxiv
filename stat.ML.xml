<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01454</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#19968;&#31181;&#32479;&#35745;&#22240;&#26524;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#30340;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#65288;SCD&#65289;&#20013;&#65292;&#23558;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#20316;&#20026;&#32422;&#26463;&#23884;&#20837;&#21040;&#31639;&#27861;&#20013;&#34987;&#24191;&#27867;&#25509;&#21463;&#65292;&#22240;&#20026;&#36825;&#23545;&#20110;&#21019;&#24314;&#19968;&#33268;&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#27169;&#22411;&#26159;&#37325;&#35201;&#30340;&#65292;&#23613;&#31649;&#35782;&#21035;&#32972;&#26223;&#30693;&#35782;&#30340;&#25361;&#25112;&#34987;&#35748;&#21487;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#23558;LLM&#30340;&#8220;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#65288;SCP&#65289;&#8221;&#19982;SCD&#26041;&#27861;&#21644;&#22522;&#20110;&#30693;&#35782;&#30340;&#22240;&#26524;&#25512;&#26029;&#65288;KBCI&#65289;&#30456;&#32467;&#21512;&#65292;&#23545;SCD&#36827;&#34892;&#20808;&#39564;&#30693;&#35782;&#22686;&#24378;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4&#21487;&#20197;&#20351;LLM-KBCI&#30340;&#36755;&#20986;&#19982;&#24102;&#26377;LLM-KBCI&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;SCD&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#65292;&#22914;&#26524;GPT-4&#32463;&#21382;&#20102;SCP&#65292;&#37027;&#20040;SCD&#30340;&#32467;&#26524;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#21892;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;LLM&#19981;&#21547;&#26377;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;LLM&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#20854;&#32972;&#26223;&#30693;&#35782;&#26469;&#25913;&#36827;SCD&#12290;
&lt;/p&gt;
&lt;p&gt;
In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through "statistical causal prompting (SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31639;&#27861;&#22797;&#26434;&#24230;&#65292;&#36827;&#32780;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#26032;&#30340;&#21516;&#27493;&#31639;&#27861;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.12338</link><description>&lt;p&gt;
&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;&#24212;&#29992;&#21450;&#20854;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic Halpern iteration in normed spaces and applications to reinforcement learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12338
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31639;&#27861;&#22797;&#26434;&#24230;&#65292;&#36827;&#32780;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#26032;&#30340;&#21516;&#27493;&#31639;&#27861;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#20855;&#26377;&#26041;&#24046;&#20943;&#23569;&#30340;&#38543;&#26426;Halpern&#36845;&#20195;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#26088;&#22312;&#36817;&#20284;&#26377;&#30028;&#21644;&#25910;&#32553;&#31639;&#23376;&#30340;&#19981;&#21160;&#28857;&#22312;&#19968;&#20010;&#26377;&#38480;&#32500;&#36171;&#33539;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;&#24213;&#23618;&#30340;&#38543;&#26426;Oracle&#20855;&#26377;&#19968;&#33268;&#26377;&#30028;&#30340;&#26041;&#24046;&#65292;&#21017;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#29616;&#20986;&#24635;&#30340;Oracle&#22797;&#26434;&#24230;&#20026;$ \tilde{O} (\varepsilon^{-5})$&#65292;&#25913;&#36827;&#20102;&#26368;&#36817;&#20026;&#38543;&#26426;Krasnoselskii-Mann&#36845;&#20195;&#24314;&#31435;&#30340;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102; $\Omega (\varepsilon^{-3})$&#30340;&#19979;&#30028;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#33539;&#22260;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#25152;&#26377;&#24102;&#26377;&#23567;&#25209;&#22788;&#29702;&#30340;&#24179;&#22343;&#36845;&#20195;&#12290;&#36890;&#36807;&#36866;&#24403;&#20462;&#25913;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#31639;&#23376;&#20026; $\gamma$-&#25910;&#32553;&#30340;&#24773;&#20917;&#19979;&#19968;&#20010; $O(\varepsilon^{-2}(1-\gamma)^{-3})$&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#29992;&#20110;&#24179;&#22343;&#22870;&#21169;&#21644;&#25240;&#25187;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#21516;&#27493;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12338v1 Announce Type: cross  Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, f
&lt;/p&gt;</description></item><item><title>&#22312;&#37325;&#23614;&#25200;&#21160;&#19979;&#65292;&#22122;&#22768;SGD&#23454;&#29616;&#20102;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#31867;&#65292;&#29305;&#21035;&#26159;&#38750;&#20984;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.02051</link><description>&lt;p&gt;
&#22312;&#37325;&#23614;&#25200;&#21160;&#19979;&#22122;&#22768;(S)GD&#30340;&#24046;&#20998;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy of Noisy (S)GD under Heavy-Tailed Perturbations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02051
&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#23614;&#25200;&#21160;&#19979;&#65292;&#22122;&#22768;SGD&#23454;&#29616;&#20102;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#31867;&#65292;&#29305;&#21035;&#26159;&#38750;&#20984;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#37325;&#23614;&#22122;&#22768;&#27880;&#20837;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#36845;&#20195;&#20013;&#24050;&#32463;&#24341;&#36215;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#23613;&#31649;&#23545;&#23548;&#33268;&#30340;&#31639;&#27861;&#30340;&#21508;&#31181;&#29702;&#35770;&#24615;&#36136;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#20027;&#35201;&#26469;&#33258;&#23398;&#20064;&#29702;&#35770;&#21644;&#20248;&#21270;&#35270;&#35282;&#65292;&#20294;&#23427;&#20204;&#30340;&#38544;&#31169;&#20445;&#25252;&#24615;&#36136;&#23578;&#26410;&#24314;&#31435;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#32570;&#21475;&#65292;&#25105;&#20204;&#20026;&#22122;&#22768;SGD&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;(DP)&#20445;&#35777;&#65292;&#24403;&#27880;&#20837;&#30340;&#22122;&#22768;&#36981;&#24490;$\alpha$-&#31283;&#23450;&#20998;&#24067;&#26102;&#65292;&#35813;&#20998;&#24067;&#21253;&#25324;&#19968;&#31995;&#21015;&#37325;&#23614;&#20998;&#24067;(&#20855;&#26377;&#26080;&#38480;&#26041;&#24046;)&#20197;&#21450;&#39640;&#26031;&#20998;&#24067;&#12290;&#32771;&#34385;$(\epsilon,\delta)$-DP&#26694;&#26550;&#65292;&#25105;&#20204;&#34920;&#26126;&#24102;&#26377;&#37325;&#23614;&#25200;&#21160;&#30340;SGD&#23454;&#29616;&#20102;$(0,\tilde{\mathcal{O}}(1/n))$-DP&#30340;&#24191;&#27867;&#25439;&#22833;&#20989;&#25968;&#31867;&#65292;&#36825;&#20123;&#20989;&#25968;&#21487;&#20197;&#26159;&#38750;&#20984;&#30340;&#65292;&#36825;&#37324;$n$&#26159;&#25968;&#25454;&#28857;&#30340;&#25968;&#37327;&#12290;&#20316;&#20026;&#19968;&#39033;&#26174;&#30528;&#30340;&#21103;&#20135;&#21697;&#65292;&#19982;&#20197;&#24448;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#35813;&#24037;&#20316;&#35201;&#27714;&#26377;&#30028;se
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02051v1 Announce Type: cross  Abstract: Injecting heavy-tailed noise to the iterates of stochastic gradient descent (SGD) has received increasing attention over the past few years. While various theoretical properties of the resulting algorithm have been analyzed mainly from learning theory and optimization perspectives, their privacy preservation properties have not yet been established. Aiming to bridge this gap, we provide differential privacy (DP) guarantees for noisy SGD, when the injected noise follows an $\alpha$-stable distribution, which includes a spectrum of heavy-tailed distributions (with infinite variance) as well as the Gaussian distribution. Considering the $(\epsilon, \delta)$-DP framework, we show that SGD with heavy-tailed perturbations achieves $(0, \tilde{\mathcal{O}}(1/n))$-DP for a broad class of loss functions which can be non-convex, where $n$ is the number of data points. As a remarkable byproduct, contrary to prior work that necessitates bounded se
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28508;&#22312;&#37096;&#20998;&#22240;&#26524;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#22312;&#35782;&#21035;&#28508;&#22312;&#32806;&#21512;&#21464;&#37327;&#26041;&#38754;&#30340;&#20248;&#31168;&#33021;&#21147;&#65292;&#24182;&#25581;&#31034;&#20102;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#36890;&#36807;&#32447;&#24615;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#23398;&#20064;&#20998;&#31163;&#34920;&#31034;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.06223</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#37096;&#20998;&#22240;&#26524;&#27169;&#22411;&#25581;&#31034;&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06223
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#37096;&#20998;&#22240;&#26524;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#22312;&#35782;&#21035;&#28508;&#22312;&#32806;&#21512;&#21464;&#37327;&#26041;&#38754;&#30340;&#20248;&#31168;&#33021;&#21147;&#65292;&#24182;&#25581;&#31034;&#20102;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#36890;&#36807;&#32447;&#24615;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#23398;&#20064;&#20998;&#31163;&#34920;&#31034;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#30001;&#20110;&#23427;&#20204;&#33021;&#22815;&#29983;&#25104;&#22797;&#26434;&#29616;&#35937;&#30340;&#26377;&#24847;&#20041;&#30340;&#20849;&#20139;&#34920;&#31034;&#12290;&#20026;&#20102;&#22686;&#24378;&#23545;&#36825;&#20123;&#33719;&#24471;&#30340;&#34920;&#31034;&#30340;&#28145;&#24230;&#20998;&#26512;&#21644;&#29702;&#35299;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#21035;&#38024;&#23545;&#22810;&#27169;&#24577;&#25968;&#25454;&#35774;&#35745;&#30340;&#32479;&#19968;&#22240;&#26524;&#27169;&#22411;&#12290;&#36890;&#36807;&#30740;&#31350;&#36825;&#20010;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#22312;&#35782;&#21035;&#22312;&#25552;&#20986;&#30340;&#32479;&#19968;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#32806;&#21512;&#21464;&#37327;&#26041;&#38754;&#30340;&#20248;&#31168;&#33021;&#21147;&#65292;&#21363;&#20351;&#22312;&#19981;&#21516;&#20551;&#35774;&#19979;&#23548;&#33268;&#30340;&#32447;&#24615;&#25110;&#32622;&#25442;&#21464;&#25442;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20102;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;&#22914;CLIP&#65289;&#36890;&#36807;&#32447;&#24615;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#36825;&#19968;&#20196;&#20154;&#24778;&#35766;&#30340;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#24037;&#20855;&#23398;&#20064;&#20998;&#31163;&#34920;&#31034;&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#21457;&#29616;&#30340;&#40065;&#26834;&#24615;&#65292;&#21363;&#20351;&#22312;&#34987;&#36829;&#21453;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#22312;&#23398;&#20064;&#30142;&#30149;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal contrastive representation learning methods have proven successful across a range of domains, partly due to their ability to generate meaningful shared representations of complex phenomena. To enhance the depth of analysis and understanding of these acquired representations, we introduce a unified causal model specifically designed for multimodal data. By examining this model, we show that multimodal contrastive representation learning excels at identifying latent coupled variables within the proposed unified model, up to linear or permutation transformations resulting from different assumptions. Our findings illuminate the potential of pre-trained multimodal models, eg, CLIP, in learning disentangled representations through a surprisingly simple yet highly effective tool: linear independent component analysis. Experiments demonstrate the robustness of our findings, even when the assumptions are violated, and validate the effectiveness of the proposed method in learning dise
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24179;&#28369;&#26680;&#31215;&#20998;&#21464;&#25442;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#65292;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.02890</link><description>&lt;p&gt;
&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Nonlinear functional regression by functional deep neural network with kernel embedding. (arXiv:2401.02890v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24179;&#28369;&#26680;&#31215;&#20998;&#21464;&#25442;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#65292;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#22312;&#35821;&#38899;&#35782;&#21035;&#12289;&#22270;&#20687;&#20998;&#31867;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#39046;&#22495;&#30340;&#36805;&#36895;&#21457;&#23637;&#65292;&#23427;&#20063;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26080;&#38480;&#32500;&#30340;&#36755;&#20837;&#65292;&#25105;&#20204;&#38656;&#35201;&#19968;&#20010;&#24378;&#22823;&#30340;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#26469;&#22788;&#29702;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#22522;&#20110;&#24179;&#28369;&#26680;&#31215;&#20998;&#21464;&#25442;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#39640;&#25928;&#19988;&#23436;&#20840;&#25968;&#25454;&#20381;&#36182;&#30340;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#30340;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20989;&#25968;&#32593;&#32476;&#30001;&#20197;&#19979;&#27493;&#39588;&#32452;&#25104;&#65306;&#26680;&#23884;&#20837;&#27493;&#39588;&#65306;&#21033;&#29992;&#25968;&#25454;&#30456;&#20851;&#30340;&#24179;&#28369;&#26680;&#36827;&#34892;&#31215;&#20998;&#21464;&#25442;&#65307;&#25237;&#24433;&#27493;&#39588;&#65306;&#36890;&#36807;&#22522;&#20110;&#23884;&#20837;&#26680;&#30340;&#29305;&#24449;&#20989;&#25968;&#22522;&#24213;&#36827;&#34892;&#32500;&#24230;&#32553;&#20943;&#65307;&#26368;&#21518;&#26159;&#19968;&#20010;&#34920;&#36798;&#20016;&#23500;&#30340;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rapid development of deep learning in various fields of science and technology, such as speech recognition, image classification, and natural language processing, recently it is also widely applied in the functional data analysis (FDA) with some empirical success. However, due to the infinite dimensional input, we need a powerful dimension reduction method for functional learning tasks, especially for the nonlinear functional regression. In this paper, based on the idea of smooth kernel integral transformation, we propose a functional deep neural network with an efficient and fully data-dependent dimension reduction method. The architecture of our functional net consists of a kernel embedding step: an integral transformation with a data-dependent smooth kernel; a projection step: a dimension reduction by projection with eigenfunction basis based on the embedding kernel; and finally an expressive deep ReLU neural network for the prediction. The utilization of smooth kernel embe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.13786</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fundamental Limits of Membership Inference Attacks on Machine Learning Models. (arXiv:2310.13786v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIA&#65289;&#21487;&#20197;&#25581;&#31034;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#26159;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#19968;&#37096;&#20998;&#65292;&#21487;&#33021;&#26292;&#38706;&#20010;&#20154;&#30340;&#25935;&#24863;&#20449;&#24687;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;MIA&#30340;&#22522;&#26412;&#32479;&#35745;&#38480;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20102;&#32479;&#35745;&#37327;&#65292;&#35813;&#32479;&#35745;&#37327;&#20915;&#23450;&#20102;&#36825;&#31181;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#21644;&#25104;&#21151;&#29575;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20960;&#31181;&#24773;&#20917;&#65292;&#24182;&#23545;&#36825;&#20010;&#24863;&#20852;&#36259;&#30340;&#32479;&#35745;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#23398;&#20064;&#27169;&#22411;&#30340;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#30452;&#25509;&#20174;&#25968;&#25454;&#38598;&#20013;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Membership inference attacks (MIA) can reveal whether a particular data point was part of the training dataset, potentially exposing sensitive information about individuals. This article explores the fundamental statistical limitations associated with MIAs on machine learning models. More precisely, we first derive the statistical quantity that governs the effectiveness and success of such attacks. Then, we investigate several situations for which we provide bounds on this quantity of interest. This allows us to infer the accuracy of potential attacks as a function of the number of samples and other structural parameters of learning models, which in some cases can be directly estimated from the dataset.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;</title><link>http://arxiv.org/abs/2310.13548</link><description>&lt;p&gt;
&#25506;&#32034;&#35821;&#35328;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13548
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#12300;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#12301;&#26159;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#19968;&#31181;&#27969;&#34892;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;RLHF&#21487;&#33021;&#20250;&#40723;&#21169;&#27169;&#22411;&#36890;&#36807;&#19982;&#29992;&#25143;&#20449;&#24565;&#30456;&#31526;&#30340;&#22238;&#31572;&#26469;&#20195;&#26367;&#30495;&#23454;&#22238;&#31572;&#65292;&#36825;&#31181;&#34892;&#20026;&#34987;&#31216;&#20026;&#35844;&#23194;&#34892;&#20026;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;RLHF&#35757;&#32451;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#26222;&#36941;&#24615;&#20197;&#21450;&#20154;&#31867;&#20559;&#22909;&#21028;&#26029;&#26159;&#21542;&#36215;&#21040;&#20102;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20116;&#20010;&#26368;&#20808;&#36827;&#30340;AI&#21161;&#25163;&#22312;&#22235;&#20010;&#19981;&#21516;&#30340;&#33258;&#30001;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#19968;&#36143;&#34920;&#29616;&#20986;&#35844;&#23194;&#34892;&#20026;&#12290;&#20026;&#20102;&#29702;&#35299;&#20154;&#31867;&#20559;&#22909;&#26159;&#21542;&#39537;&#21160;&#20102;RLHF&#27169;&#22411;&#30340;&#36825;&#31181;&#24191;&#27867;&#34892;&#20026;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24403;&#22238;&#31572;&#19982;&#29992;&#25143;&#30340;&#35266;&#28857;&#30456;&#31526;&#26102;&#65292;&#23427;&#26356;&#26377;&#21487;&#33021;&#34987;&#36873;&#20013;&#12290;&#27492;&#22806;&#65292;&#20154;&#31867;&#21644;&#20559;&#22909;&#27169;&#22411;&#65288;PMs&#65289;&#23558;&#26377;&#35828;&#26381;&#21147;&#30340;&#35844;&#23194;&#22238;&#31572;&#19982;&#27491;&#30830;&#22238;&#31572;&#30456;&#27604;&#65292;&#26377;&#26102;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#22320;&#36873;&#25321;&#20102;&#35844;&#23194;&#22238;&#31572;&#12290;&#20248;&#21270;&#27169;&#22411;&#36755;&#20986;&#20197;&#28385;&#36275;PMs&#26377;&#26102;&#20063;&#20250;&#22312;&#30495;&#23454;&#24615;&#21644;&#35844;&#23194;&#34892;&#20026;&#20043;&#38388;&#20570;&#20986;&#21462;&#33293;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Over
&lt;/p&gt;</description></item></channel></rss>