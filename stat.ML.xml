<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#35299;&#20915;&#20102;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2104.10751</link><description>&lt;p&gt;
&#20998;&#31867;&#35268;&#21017;&#29983;&#25104;&#65306;&#21487;&#25193;&#23637;&#24615;&#65292;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rule Generation for Classification: Scalability, Interpretability, and Fairness. (arXiv:2104.10751v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.10751
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#35299;&#20915;&#20102;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#20855;&#26377;&#32422;&#26463;&#26465;&#20214;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#65292;&#22240;&#27492;&#21487;&#25193;&#23637;&#21040;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#25152;&#24471;&#23450;&#20215;&#23376;&#38382;&#39064;&#34987;&#35777;&#26126;&#26159;NP&#38590;&#38382;&#39064;&#12290;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#20915;&#31574;&#26641;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#19968;&#20010;&#20195;&#29702;&#23450;&#20215;&#23376;&#38382;&#39064;&#20197;&#21152;&#36895;&#12290;&#35813;&#26041;&#27861;&#36820;&#22238;&#19968;&#32452;&#35268;&#21017;&#20197;&#21450;&#23427;&#20204;&#30340;&#26368;&#20248;&#26435;&#37325;&#65292;&#25351;&#31034;&#27599;&#20010;&#35268;&#21017;&#23545;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#35268;&#21017;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#26469;&#35299;&#20915;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#23616;&#37096;&#35299;&#37322;&#24615;&#65292;&#24182;&#23558;&#20844;&#24179;&#24615;&#30340;&#19968;&#33324;&#20998;&#31163;&#20934;&#21017;&#25512;&#24191;&#21040;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#21644;&#31867;&#21035;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#26469;&#35814;&#32454;&#38416;&#36848;&#20854;&#19981;&#21516;&#26041;&#38754;&#12290;&#25152;&#25552;&#20986;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#23398;&#20064;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#36798;&#21040;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new rule-based optimization method for classification with constraints. The proposed method leverages column generation for linear programming, and hence, is scalable to large datasets. The resulting pricing subproblem is shown to be NP-Hard. We recourse to a decision tree-based heuristic and solve a proxy pricing subproblem for acceleration. The method returns a set of rules along with their optimal weights indicating the importance of each rule for learning. We address interpretability and fairness by assigning cost coefficients to the rules and introducing additional constraints. In particular, we focus on local interpretability and generalize separation criterion in fairness to multiple sensitive attributes and classes. We test the performance of the proposed methodology on a collection of datasets and present a case study to elaborate on its different aspects. The proposed rule-based learning method exhibits a good compromise between local interpretability and fairn
&lt;/p&gt;</description></item></channel></rss>