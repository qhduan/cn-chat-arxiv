<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20855;&#26377;&#26032;&#39062;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#39318;&#27425;&#22312;&#27969;&#24335;&#35774;&#32622;&#20013;&#20026;&#40065;&#26834;ReLU&#22238;&#24402;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.01204</link><description>&lt;p&gt;
&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#27969;&#24335;&#32447;&#24615;&#21644;&#20462;&#27491;&#32447;&#24615;&#31995;&#32479;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient descent for streaming linear and rectified linear systems with Massart noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01204
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;Massart&#22122;&#22768;&#30340;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#38382;&#39064;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20855;&#26377;&#26032;&#39062;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#39318;&#27425;&#22312;&#27969;&#24335;&#35774;&#32622;&#20013;&#20026;&#40065;&#26834;ReLU&#22238;&#24402;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;SGD-exp&#65292;&#19968;&#31181;&#29992;&#20110;&#32447;&#24615;&#21644;ReLU&#22238;&#24402;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#22312;Massart&#22122;&#22768;&#65288;&#23545;&#25239;&#24615;&#21322;&#38543;&#26426;&#30772;&#22351;&#27169;&#22411;&#65289;&#19979;&#65292;&#23436;&#20840;&#27969;&#24335;&#35774;&#32622;&#19979;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;SGD-exp&#23545;&#30495;&#23454;&#21442;&#25968;&#30340;&#36817;&#20046;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#65292;&#26368;&#39640;&#21487;&#36798;50%&#30340;Massart&#30772;&#22351;&#29575;&#65292;&#22312;&#23545;&#31216;&#26080;&#24551;&#30772;&#22351;&#24773;&#20917;&#19979;&#65292;&#20219;&#24847;&#30772;&#22351;&#29575;&#20063;&#26377;&#20445;&#35777;&#12290;&#36825;&#26159;&#27969;&#24335;&#35774;&#32622;&#20013;&#40065;&#26834;ReLU&#22238;&#24402;&#30340;&#31532;&#19968;&#20010;&#25910;&#25947;&#20445;&#35777;&#32467;&#26524;&#65292;&#23427;&#26174;&#31034;&#20102;&#30456;&#27604;&#20110;&#20197;&#21069;&#30340;&#40065;&#26834;&#26041;&#27861;&#23545;&#20110;L1&#32447;&#24615;&#22238;&#24402;&#20855;&#26377;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#36825;&#26159;&#30001;&#20110;&#36873;&#25321;&#20102;&#25351;&#25968;&#34928;&#20943;&#27493;&#38271;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#30340;&#28418;&#31227;&#20998;&#26512;&#65292;&#36825;&#26412;&#36523;&#20063;&#21487;&#33021;&#26159;&#26377;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01204v1 Announce Type: new  Abstract: We propose SGD-exp, a stochastic gradient descent approach for linear and ReLU regressions under Massart noise (adversarial semi-random corruption model) for the fully streaming setting. We show novel nearly linear convergence guarantees of SGD-exp to the true parameter with up to $50\%$ Massart corruption rate, and with any corruption rate in the case of symmetric oblivious corruptions. This is the first convergence guarantee result for robust ReLU regression in the streaming setting, and it shows the improved convergence rate over previous robust methods for $L_1$ linear regression due to a choice of an exponentially decaying step size, known for its efficiency in practice. Our analysis is based on the drift analysis of a discrete stochastic process, which could also be interesting on its own.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#22686;&#24191;&#36870;&#27010;&#29575;&#21152;&#26435;&#65288;AIPW&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#35266;&#27979;&#32593;&#32476;&#25968;&#25454;&#20272;&#35745;&#21644;&#25512;&#26029;&#20855;&#26377;&#28322;&#20986;&#25928;&#24212;&#30340;&#27835;&#30103;&#30340;&#30452;&#25509;&#25928;&#24212;&#12290;&#26041;&#27861;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#26679;&#26412;&#20998;&#21106;&#65292;&#24471;&#21040;&#25910;&#25947;&#36895;&#24230;&#36739;&#24555;&#19988;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#30340;&#21322;&#21442;&#25968;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#22120;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#32771;&#34385;&#23398;&#29983;&#31038;&#20132;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#26102;&#38388;&#23545;&#32771;&#35797;&#25104;&#32489;&#26377;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2206.14591</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#22788;&#29702;&#35266;&#27979;&#32593;&#32476;&#25968;&#25454;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Treatment Effect Estimation with Observational Network Data using Machine Learning. (arXiv:2206.14591v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14591
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#22686;&#24191;&#36870;&#27010;&#29575;&#21152;&#26435;&#65288;AIPW&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#35266;&#27979;&#32593;&#32476;&#25968;&#25454;&#20272;&#35745;&#21644;&#25512;&#26029;&#20855;&#26377;&#28322;&#20986;&#25928;&#24212;&#30340;&#27835;&#30103;&#30340;&#30452;&#25509;&#25928;&#24212;&#12290;&#26041;&#27861;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#26679;&#26412;&#20998;&#21106;&#65292;&#24471;&#21040;&#25910;&#25947;&#36895;&#24230;&#36739;&#24555;&#19988;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#30340;&#21322;&#21442;&#25968;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#22120;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#32771;&#34385;&#23398;&#29983;&#31038;&#20132;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#26102;&#38388;&#23545;&#32771;&#35797;&#25104;&#32489;&#26377;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#29420;&#31435;&#21333;&#20803;&#26469;&#36827;&#34892;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20551;&#35774;&#32463;&#24120;&#26159;&#26377;&#38382;&#39064;&#30340;&#65292;&#22240;&#20026;&#21333;&#20803;&#20043;&#38388;&#21487;&#33021;&#20250;&#30456;&#20114;&#20316;&#29992;&#65292;&#23548;&#33268;&#21333;&#20803;&#20043;&#38388;&#30340;&#28322;&#20986;&#25928;&#24212;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#22686;&#24191;&#36870;&#27010;&#29575;&#21152;&#26435;&#65288;AIPW&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#20855;&#26377;&#28322;&#20986;&#25928;&#24212;&#30340;&#21333;&#20010;&#65288;&#31038;&#20132;&#65289;&#32593;&#32476;&#30340;&#35266;&#27979;&#25968;&#25454;&#23545;&#27835;&#30103;&#30340;&#30452;&#25509;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;&#21644;&#25512;&#26029;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#25554;&#20214;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#26679;&#26412;&#20998;&#21106;&#26041;&#27861;&#65292;&#24471;&#21040;&#19968;&#20010;&#21322;&#21442;&#25968;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#22120;&#65292;&#20854;&#28176;&#36817;&#25910;&#25947;&#20110;&#21442;&#25968;&#36895;&#29575;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#12290;&#25105;&#20204;&#23558;AIPW&#26041;&#27861;&#24212;&#29992;&#20110;&#29790;&#22763;&#23398;&#29983;&#20154;&#29983;&#30740;&#31350;&#25968;&#25454;&#65292;&#20197;&#30740;&#31350;&#23398;&#20064;&#26102;&#38388;&#23545;&#32771;&#35797;&#25104;&#32489;&#30340;&#24433;&#21709;&#65292;&#32771;&#34385;&#21040;&#23398;&#29983;&#30340;&#31038;&#20132;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference methods for treatment effect estimation usually assume independent units. However, this assumption is often questionable because units may interact, resulting in spillover effects between units. We develop augmented inverse probability weighting (AIPW) for estimation and inference of the direct effect of the treatment with observational data from a single (social) network with spillover effects. We use plugin machine learning and sample splitting to obtain a semiparametric treatment effect estimator that converges at the parametric rate and asymptotically follows a Gaussian distribution. We apply our AIPW method to the Swiss StudentLife Study data to investigate the effect of hours spent studying on exam performance accounting for the students' social network.
&lt;/p&gt;</description></item></channel></rss>