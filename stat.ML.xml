<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#36895;&#38750;&#32447;&#24615;&#32422;&#26463;&#19979;&#30340;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#20854;&#20248;&#28857;&#26159;&#36991;&#20813;&#20102;&#22312;&#25972;&#20010;&#21487;&#34892;&#38598;&#19978;&#36827;&#34892;&#20248;&#21270;&#65292;&#32780;&#19988;&#21033;&#29992;&#36895;&#24230;&#26469;&#34920;&#36798;&#32422;&#26463;&#65292;&#20351;&#24471;&#31639;&#27861;&#22312;&#20915;&#31574;&#21464;&#37327;&#25968;&#37327;&#21644;&#32422;&#26463;&#25968;&#37327;&#19978;&#30340;&#22797;&#26434;&#24230;&#22686;&#38271;&#36866;&#24230;&#65292;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2302.00316</link><description>&lt;p&gt;
&#21152;&#36895;&#38750;&#32447;&#24615;&#32422;&#26463;&#19979;&#30340;&#19968;&#38454;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Accelerated First-Order Optimization under Nonlinear Constraints. (arXiv:2302.00316v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00316
&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#36895;&#38750;&#32447;&#24615;&#32422;&#26463;&#19979;&#30340;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#20854;&#20248;&#28857;&#26159;&#36991;&#20813;&#20102;&#22312;&#25972;&#20010;&#21487;&#34892;&#38598;&#19978;&#36827;&#34892;&#20248;&#21270;&#65292;&#32780;&#19988;&#21033;&#29992;&#36895;&#24230;&#26469;&#34920;&#36798;&#32422;&#26463;&#65292;&#20351;&#24471;&#31639;&#27861;&#22312;&#20915;&#31574;&#21464;&#37327;&#25968;&#37327;&#21644;&#32422;&#26463;&#25968;&#37327;&#19978;&#30340;&#22797;&#26434;&#24230;&#22686;&#38271;&#36866;&#24230;&#65292;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#32422;&#26463;&#20248;&#21270;&#21644;&#38750;&#20809;&#28369;&#21160;&#21147;&#31995;&#32479;&#20043;&#38388;&#30340;&#31867;&#27604;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#36895;&#38750;&#32447;&#24615;&#32422;&#26463;&#19979;&#30340;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861;&#12290;&#19982;Frank-Wolfe&#25110;&#25237;&#24433;&#26799;&#24230;&#19981;&#21516;&#65292;&#36825;&#20123;&#31639;&#27861;&#36991;&#20813;&#20102;&#27599;&#27425;&#36845;&#20195;&#22312;&#25972;&#20010;&#21487;&#34892;&#38598;&#19978;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25512;&#23548;&#20102;&#22312;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20013;&#30340;&#20984;&#35774;&#32622;&#30340;&#21152;&#36895;&#29575;&#12290;&#36825;&#20123;&#31639;&#27861;&#30340;&#19968;&#20010;&#37325;&#35201;&#29305;&#24615;&#26159;&#20351;&#29992;&#36895;&#24230;&#32780;&#19981;&#26159;&#20301;&#32622;&#26469;&#34920;&#36798;&#32422;&#26463;&#65292;&#36825;&#33258;&#28982;&#22320;&#23548;&#33268;&#21487;&#34892;&#38598;&#30340;&#31232;&#30095;&#12289;&#23616;&#37096;&#21644;&#20984;&#36817;&#20284;&#65288;&#21363;&#20351;&#21487;&#34892;&#38598;&#26159;&#38750;&#20984;&#30340;&#65289;&#12290;&#22240;&#27492;&#65292;&#22797;&#26434;&#24230;&#22312;&#20915;&#31574;&#21464;&#37327;&#25968;&#37327;&#21644;&#32422;&#26463;&#25968;&#37327;&#19978;&#36866;&#24230;&#22686;&#38271;&#65292;&#20351;&#24471;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#12290;&#25105;&#20204;&#23558;&#31639;&#27861;&#24212;&#29992;&#20110;&#21387;&#32553;&#24863;&#30693;&#21644;&#31232;&#30095;&#183;&#183;&#183;
&lt;/p&gt;
&lt;p&gt;
We exploit analogies between first-order algorithms for constrained optimization and non-smooth dynamical systems to design a new class of accelerated first-order algorithms for constrained optimization. Unlike Frank-Wolfe or projected gradients, these algorithms avoid optimization over the entire feasible set at each iteration. We prove convergence to stationary points even in a nonconvex setting and we derive accelerated rates for the convex setting both in continuous time, as well as in discrete time. An important property of these algorithms is that constraints are expressed in terms of velocities instead of positions, which naturally leads to sparse, local and convex approximations of the feasible set (even if the feasible set is nonconvex). Thus, the complexity tends to grow mildly in the number of decision variables and in the number of constraints, which makes the algorithms suitable for machine learning applications. We apply our algorithms to a compressed sensing and a sparse
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2211.09619</link><description>&lt;p&gt;
&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#31616;&#20171;
&lt;/p&gt;
&lt;p&gt;
Introduction to Online Nonstochastic Control. (arXiv:2211.09619v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09619
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#21160;&#24577;&#31995;&#32479;&#25511;&#21046;&#19982;&#21487;&#24494;&#24378;&#21270;&#23398;&#20064;&#33539;&#24335;&#8212;&#8212;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#65292;&#24182;&#24212;&#29992;&#22312;&#32447;&#20984;&#20248;&#21270;&#21644;&#20984;&#26494;&#24347;&#25216;&#26415;&#24471;&#21040;&#20102;&#20855;&#26377;&#21487;&#35777;&#26126;&#20445;&#35777;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#26368;&#20339;&#21644;&#40065;&#26834;&#25511;&#21046;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#12290;&#19982;&#20854;&#20182;&#26694;&#26550;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#30340;&#30446;&#26631;&#26159;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#22312;&#26080;&#27861;&#39044;&#27979;&#25200;&#21160;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
This text presents an introduction to an emerging paradigm in control of dynamical systems and differentiable reinforcement learning called online nonstochastic control. The new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies.  This objective suggests the use of the decision making frame
&lt;/p&gt;</description></item></channel></rss>