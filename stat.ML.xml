<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; tamed interactive particle Langevin algorithms&#65288;tIPLA&#65289;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#22686;&#38271;&#24773;&#20917;&#19979;&#33719;&#24471;&#31283;&#23450;&#19988;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.19587</link><description>&lt;p&gt;
&#39535;&#26381;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861; -- &#36229;&#32447;&#24615;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Taming the Interactive Particle Langevin Algorithm -- the superlinear case
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19587
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; tamed interactive particle Langevin algorithms&#65288;tIPLA&#65289;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#22686;&#38271;&#24773;&#20917;&#19979;&#33719;&#24471;&#31283;&#23450;&#19988;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#38543;&#26426;&#20248;&#21270;&#26041;&#38754;&#30340;&#36827;&#23637;&#20135;&#29983;&#20102;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861;&#65288;IPLA&#65289;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20132;&#20114;&#31890;&#23376;&#31995;&#32479;&#65288;IPS&#65289;&#30340;&#27010;&#24565;&#26469;&#39640;&#25928;&#22320;&#20174;&#36817;&#20284;&#21518;&#39564;&#23494;&#24230;&#20013;&#25277;&#26679;&#12290;&#36825;&#22312;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#26694;&#26550;&#20013;&#21464;&#24471;&#23588;&#20026;&#20851;&#38190;&#65292;&#20854;&#20013; E &#27493;&#39588;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#29978;&#33267;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#23613;&#31649;&#20808;&#21069;&#30340;&#30740;&#31350;&#20391;&#37325;&#20110;&#26799;&#24230;&#26368;&#22810;&#32447;&#24615;&#22686;&#38271;&#30340;&#20984;&#24773;&#20917;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#27492;&#26694;&#26550;&#25193;&#23637;&#21040;&#21253;&#25324;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#37319;&#29992;&#39535;&#26381;&#25216;&#26415;&#29983;&#25104;&#26126;&#30830;&#30340;&#31163;&#25955;&#21270;&#26041;&#26696;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#31867;&#31283;&#23450;&#30340;&#12289;&#22312;&#36825;&#31181;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#31216;&#20026;&#39535;&#26381;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861;&#65288;tIPLA&#65289;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#26032;&#31867;&#22312; Wasserstein-2 &#36317;&#31163;&#19979;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#65292;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19587v1 Announce Type: cross  Abstract: Recent advances in stochastic optimization have yielded the interactive particle Langevin algorithm (IPLA), which leverages the notion of interacting particle systems (IPS) to efficiently sample from approximate posterior densities. This becomes particularly crucial within the framework of Expectation-Maximization (EM), where the E-step is computationally challenging or even intractable. Although prior research has focused on scenarios involving convex cases with gradients of log densities that grow at most linearly, our work extends this framework to include polynomial growth. Taming techniques are employed to produce an explicit discretization scheme that yields a new class of stable, under such non-linearities, algorithms which are called tamed interactive particle Langevin algorithms (tIPLA). We obtain non-asymptotic convergence error estimates in Wasserstein-2 distance for the new class under an optimal rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.19516</link><description>&lt;p&gt;
&#38024;&#23545;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation on Stochastic Blockmodels for Directed Graph Clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19516
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#23398;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#26377;&#21521;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#23558;&#32858;&#31867;&#38382;&#39064;&#24314;&#27169;&#20026;&#26377;&#21521;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;DSBM&#65289;&#20013;&#28508;&#22312;&#31038;&#21306;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#23545;DSBM&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#65292;&#20174;&#32780;&#30830;&#23450;&#32473;&#23450;&#35266;&#23519;&#21040;&#30340;&#22270;&#32467;&#26500;&#26102;&#26368;&#21487;&#33021;&#30340;&#31038;&#21306;&#20998;&#37197;&#12290;&#38500;&#20102;&#32479;&#35745;&#35266;&#28857;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24314;&#31435;&#20102;&#36825;&#31181;MLE&#20844;&#24335;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#27969;&#20248;&#21270;&#21551;&#21457;&#24335;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#35813;&#21551;&#21457;&#24335;&#21516;&#26102;&#32771;&#34385;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#26377;&#21521;&#22270;&#32479;&#35745;&#37327;&#65306;&#36793;&#23494;&#24230;&#21644;&#36793;&#26041;&#21521;&#12290;&#22522;&#20110;&#36825;&#31181;&#26377;&#21521;&#32858;&#31867;&#30340;&#26032;&#20844;&#24335;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#21521;&#32858;&#31867;&#31639;&#27861;&#65292;&#20998;&#21035;&#26159;&#35889;&#32858;&#31867;&#31639;&#27861;&#21644;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#25105;&#20204;&#20026;&#35889;&#32858;&#31867;&#31639;&#27861;&#30340;&#38169;&#35823;&#32858;&#31867;&#39030;&#28857;&#25968;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19516v1 Announce Type: cross  Abstract: This paper studies the directed graph clustering problem through the lens of statistics, where we formulate clustering as estimating underlying communities in the directed stochastic block model (DSBM). We conduct the maximum likelihood estimation (MLE) on the DSBM and thereby ascertain the most probable community assignment given the observed graph structure. In addition to the statistical point of view, we further establish the equivalence between this MLE formulation and a novel flow optimization heuristic, which jointly considers two important directed graph statistics: edge density and edge orientation. Building on this new formulation of directed clustering, we introduce two efficient and interpretable directed clustering algorithms, a spectral clustering algorithm and a semidefinite programming based clustering algorithm. We provide a theoretical upper bound on the number of misclustered vertices of the spectral clustering algor
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#22312;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#21160;&#21147;&#31995;&#32479;&#20013;&#23398;&#20064;&#39044;&#27979;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#26469;&#37327;&#21270;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.06614</link><description>&lt;p&gt;
&#21160;&#21147;&#31995;&#32479;&#20013;&#39034;&#24207;&#39044;&#27979;&#30340;&#22797;&#26434;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Complexity of Sequential Prediction in Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06614
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#22312;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#21160;&#21147;&#31995;&#32479;&#20013;&#23398;&#20064;&#39044;&#27979;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#26469;&#37327;&#21270;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#39044;&#27979;&#21160;&#21147;&#31995;&#32479;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#23545;&#21160;&#21147;&#31995;&#32479;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#65292;&#24182;&#20174;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#35813;&#38382;&#39064;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning to predict the next state of a dynamical system when the underlying evolution function is unknown. Unlike previous work, we place no parametric assumptions on the dynamical system, and study the problem from a learning theory perspective. We define new combinatorial measures and dimensions and show that they quantify the optimal mistake and regret bounds in the realizable and agnostic setting respectively.
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#21487;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#65306;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#36805;&#36895;&#20943;&#23567;&#65307;&#31532;&#20108;&#38454;&#27573;&#20013;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#32531;&#24930;&#20943;&#23567;&#12290;&#36825;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.08247</link><description>&lt;p&gt;
&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#20004;&#20010;&#38454;&#27573;&#30340;&#32553;&#25918;&#24459;
&lt;/p&gt;
&lt;p&gt;
Two Phases of Scaling Laws for Nearest Neighbor Classifiers. (arXiv:2308.08247v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08247
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#21487;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#65306;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#36805;&#36895;&#20943;&#23567;&#65307;&#31532;&#20108;&#38454;&#27573;&#20013;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#32531;&#24930;&#20943;&#23567;&#12290;&#36825;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32553;&#25918;&#24459;&#26159;&#25351;&#24403;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;&#27169;&#22411;&#30340;&#27979;&#35797;&#24615;&#33021;&#20250;&#25552;&#39640;&#30340;&#35266;&#23519;&#32467;&#26524;&#12290;&#24555;&#36895;&#30340;&#32553;&#25918;&#24459;&#24847;&#21619;&#30528;&#36890;&#36807;&#22686;&#21152;&#25968;&#25454;&#21644;&#27169;&#22411;&#22823;&#23567;&#23601;&#33021;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#22686;&#21152;&#26356;&#22810;&#25968;&#25454;&#30340;&#22909;&#22788;&#21487;&#33021;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#12290;&#25105;&#20204;&#21457;&#29616;&#32553;&#25918;&#24459;&#21487;&#33021;&#26377;&#20004;&#20010;&#38454;&#27573;&#65306;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#19988;&#24555;&#36895;&#20943;&#23567;&#65307;&#32780;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#19988;&#20943;&#23567;&#24471;&#24930;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#31361;&#26174;&#20102;&#25968;&#25454;&#20998;&#24067;&#22312;&#20915;&#23450;&#27867;&#21270;&#35823;&#24046;&#20013;&#30340;&#22797;&#26434;&#24615;&#12290;&#24403;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
A scaling law refers to the observation that the test performance of a model improves as the number of training data increases. A fast scaling law implies that one can solve machine learning problems by simply boosting the data and the model sizes. Yet, in many cases, the benefit of adding more data can be negligible. In this work, we study the rate of scaling laws of nearest neighbor classifiers. We show that a scaling law can have two phases: in the first phase, the generalization error depends polynomially on the data dimension and decreases fast; whereas in the second phase, the error depends exponentially on the data dimension and decreases slowly. Our analysis highlights the complexity of the data distribution in determining the generalization error. When the data distributes benignly, our result suggests that nearest neighbor classifier can achieve a generalization error that depends polynomially, instead of exponentially, on the data dimension.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#25506;&#35752;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#37325;&#28857;&#26159;&#36890;&#36807;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#30340;&#35889;&#20998;&#26512;&#26469;&#29702;&#35299;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2306.17301</link><description>&lt;p&gt;
&#27973;&#23618;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65306;&#19968;&#20010;&#25968;&#20540;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Why Shallow Networks Struggle with Approximating and Learning High Frequency: A Numerical Study. (arXiv:2306.17301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#25506;&#35752;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#37325;&#28857;&#26159;&#36890;&#36807;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#30340;&#35889;&#20998;&#26512;&#26469;&#29702;&#35299;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#20998;&#26512;&#21644;&#23454;&#39564;&#30340;&#32508;&#21512;&#25968;&#20540;&#30740;&#31350;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#26426;&#22120;&#31934;&#24230;&#21644;&#35745;&#31639;&#25104;&#26412;&#31561;&#23454;&#38469;&#22240;&#32032;&#20013;&#65292;&#22788;&#29702;&#39640;&#39057;&#29575;&#30340;&#36924;&#36817;&#21644;&#23398;&#20064;&#23384;&#22312;&#22256;&#38590;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30740;&#31350;&#20102;&#20197;&#19979;&#22522;&#26412;&#35745;&#31639;&#38382;&#39064;&#65306;&#65288;1&#65289;&#22312;&#26377;&#38480;&#30340;&#26426;&#22120;&#31934;&#24230;&#19979;&#21487;&#20197;&#36798;&#21040;&#30340;&#26368;&#20339;&#31934;&#24230;&#65292;&#65288;2&#65289;&#23454;&#29616;&#32473;&#23450;&#31934;&#24230;&#25152;&#38656;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#20197;&#21450;&#65288;3&#65289;&#23545;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#30740;&#31350;&#30340;&#20851;&#38190;&#26159;&#30456;&#24212;&#28608;&#27963;&#20989;&#25968;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#30340;&#35889;&#20998;&#26512;&#65292;&#35813;&#20998;&#26512;&#36824;&#26174;&#31034;&#20102;&#28608;&#27963;&#20989;&#25968;&#23646;&#24615;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, a comprehensive numerical study involving analysis and experiments shows why a two-layer neural network has difficulties handling high frequencies in approximation and learning when machine precision and computation cost are important factors in real practice. In particular, the following fundamental computational issues are investigated: (1) the best accuracy one can achieve given a finite machine precision, (2) the computation cost to achieve a given accuracy, and (3) stability with respect to perturbations. The key to the study is the spectral analysis of the corresponding Gram matrix of the activation functions which also shows how the properties of the activation function play a role in the picture.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#20195;&#26367;&#23494;&#24230;&#27604;&#26469;&#20272;&#35745;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20004;&#32452;&#25968;&#25454;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#36991;&#20813;&#20102;&#20998;&#31867;&#22120;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15612</link><description>&lt;p&gt;
&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning. (arXiv:2305.15612v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15612
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#20195;&#26367;&#23494;&#24230;&#27604;&#26469;&#20272;&#35745;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20004;&#32452;&#25968;&#25454;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#36991;&#20813;&#20102;&#20998;&#31867;&#22120;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#31185;&#23398;&#19982;&#24037;&#31243;&#30340;&#22810;&#20010;&#39046;&#22495;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#33021;&#39640;&#25928;&#22320;&#25214;&#21040;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#36890;&#24120;&#65292;&#19968;&#20010;&#27010;&#29575;&#22238;&#24402;&#27169;&#22411;&#65292;&#22914;&#39640;&#26031;&#36807;&#31243;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#34987;&#24191;&#27867;&#29992;&#20316;&#26367;&#20195;&#20989;&#25968;&#65292;&#29992;&#20110;&#27169;&#25311;&#22312;&#32473;&#23450;&#36755;&#20837;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#20989;&#25968;&#35780;&#20272;&#30340;&#26174;&#24335;&#20998;&#24067;&#12290;&#38500;&#20102;&#22522;&#20110;&#27010;&#29575;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#24050;&#34987;&#25552;&#20986;&#26469;&#20272;&#35745;&#30456;&#23545;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#30456;&#23545;&#25509;&#36817;&#21644;&#30456;&#23545;&#36828;&#31163;&#30340;&#20004;&#32452;&#23494;&#24230;&#27604;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#21457;&#23637;&#36825;&#19968;&#30740;&#31350;&#65292;&#21487;&#20197;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#26469;&#20272;&#35745;&#36825;&#20004;&#32452;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#32780;&#19981;&#26159;&#23494;&#24230;&#27604;&#12290;&#28982;&#32780;&#65292;&#27492;&#31574;&#30053;&#20013;&#20351;&#29992;&#30340;&#30417;&#30563;&#20998;&#31867;&#22120;&#20542;&#21521;&#20110;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization has attracted huge attention from diverse research areas in science and engineering, since it is capable of finding a global optimum of an expensive-to-evaluate black-box function efficiently. In general, a probabilistic regression model, e.g., Gaussian processes, random forests, and Bayesian neural networks, is widely used as a surrogate function to model an explicit distribution over function evaluations given an input to estimate and a training dataset. Beyond the probabilistic regression-based Bayesian optimization, density ratio estimation-based Bayesian optimization has been suggested in order to estimate a density ratio of the groups relatively close and relatively far to a global optimum. Developing this line of research further, a supervised classifier can be employed to estimate a class probability for the two groups instead of a density ratio. However, the supervised classifiers used in this strategy tend to be overconfident for a global solution candid
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#22312;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#20256;&#36882;&#26377;&#29992;&#20449;&#24687;&#30340;&#36807;&#31243;&#20013;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#65292;&#20855;&#26377;&#39640;&#25928;&#21644;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#31561;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.05529</link><description>&lt;p&gt;
&#21033;&#29992;Birth-Death &#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#21152;&#36895;Langevin&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Accelerate Langevin Sampling with Birth-Death process and Exploration Component. (arXiv:2305.05529v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05529
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#22312;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#20256;&#36882;&#26377;&#29992;&#20449;&#24687;&#30340;&#36807;&#31243;&#20013;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#65292;&#20855;&#26377;&#39640;&#25928;&#21644;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#65292;&#37319;&#26679;&#24050;&#30693;&#27010;&#29575;&#20998;&#24067;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#38024;&#23545;&#22810;&#23792;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#12290;&#35813;&#26041;&#27861;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#8220;&#19977;&#24605;&#32780;&#21518;&#34892;&#8221;&#12290;&#25105;&#20204;&#20445;&#30041;&#20004;&#32452;&#37319;&#26679;&#22120;&#65292;&#19968;&#32452;&#22312;&#36739;&#39640;&#28201;&#24230;&#19979;&#65292;&#19968;&#32452;&#22312;&#21407;&#22987;&#28201;&#24230;&#19979;&#12290;&#21069;&#32773;&#20316;&#20026;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#23558;&#26377;&#29992;&#20449;&#24687;&#20256;&#36882;&#32473;&#21518;&#32773;&#30340;&#20808;&#39537;&#65292;&#21518;&#32773;&#22312;&#25509;&#25910;&#20449;&#24687;&#21518;&#23545;&#30446;&#26631;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22343;&#22330;&#26497;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#25506;&#32034;&#36807;&#31243;&#22914;&#20309;&#20915;&#23450;&#37319;&#26679;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23545;&#20197;&#21069;&#25991;&#29486;&#20013;&#30340;&#23454;&#39564;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#24182;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling a probability distribution with known likelihood is a fundamental task in computational science and engineering. Aiming at multimodality, we propose a new sampling method that takes advantage of both birth-death process and exploration component. The main idea of this method is \textit{look before you leap}. We keep two sets of samplers, one at warmer temperature and one at original temperature. The former one serves as pioneer in exploring new modes and passing useful information to the other, while the latter one samples the target distribution after receiving the information. We derive a mean-field limit and show how the exploration process determines sampling efficiency. Moreover, we prove exponential asymptotic convergence under mild assumption. Finally, we test on experiments from previous literature and compared our methodology to previous ones.
&lt;/p&gt;</description></item></channel></rss>