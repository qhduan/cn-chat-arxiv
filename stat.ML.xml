<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#65292;&#20272;&#35745;&#20102;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#30340;&#19979;&#38480;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.10504</link><description>&lt;p&gt;
&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#24377;&#24615;
&lt;/p&gt;
&lt;p&gt;
Resilience of the quadratic Littlewood-Offord problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10504
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#65292;&#20272;&#35745;&#20102;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#30340;&#19979;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#25968;&#25454;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;$\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi}$&#21453;&#38598;&#20013;&#29305;&#24615;&#30340;&#24433;&#21709;&#30340;&#20272;&#35745;&#65292;&#20854;&#20013;$M$&#26159;&#19968;&#20010;&#22266;&#23450;&#30340;&#65288;&#39640;&#32500;&#65289;&#30697;&#38453;&#65292;$\boldsymbol{\xi}$&#26159;&#19968;&#20010;&#20849;&#24418;Rademacher&#21521;&#37327;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;$\boldsymbol{\xi}$&#33021;&#22815;&#25215;&#21463;&#22810;&#23569;&#23545;&#25239;&#24615;&#31526;&#21495;&#32763;&#36716;&#32780;&#19981;&#8220;&#33192;&#32960;&#8221;$\sup_{x\in \mathbb{R}} \mathbb{P} \left\{\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi} = x\right\}$&#65292;&#20174;&#32780;&#8220;&#21435;&#38500;&#8221;&#21407;&#22987;&#20998;&#24067;&#23548;&#33268;&#26356;&#8220;&#26377;&#31890;&#24230;&#8221;&#21644;&#23545;&#25239;&#24615;&#20559;&#20506;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#19979;&#38480;&#20272;&#35745;&#65307;&#36825;&#20123;&#32467;&#26524;&#22312;&#20851;&#38190;&#21306;&#22495;&#34987;&#35777;&#26126;&#26159;&#28176;&#36817;&#32039;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10504v1 Announce Type: cross  Abstract: We study the statistical resilience of high-dimensional data. Our results provide estimates as to the effects of adversarial noise over the anti-concentration properties of the quadratic Radamecher chaos $\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi}$, where $M$ is a fixed (high-dimensional) matrix and $\boldsymbol{\xi}$ is a conformal Rademacher vector. Specifically, we pursue the question of how many adversarial sign-flips can $\boldsymbol{\xi}$ sustain without "inflating" $\sup_{x\in \mathbb{R}} \mathbb{P} \left\{\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi} = x\right\}$ and thus "de-smooth" the original distribution resulting in a more "grainy" and adversarially biased distribution. Our results provide lower bound estimations for the statistical resilience of the quadratic and bilinear Rademacher chaos; these are shown to be asymptotically tight across key regimes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;logistic-beta&#36807;&#31243;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;beta&#36793;&#38469;&#20998;&#24067;&#30340;&#30456;&#20851;&#38543;&#26426;&#27010;&#29575;&#12290;&#35813;&#36807;&#31243;&#20855;&#26377;&#28789;&#27963;&#30340;&#30456;&#20851;&#32467;&#26500;&#21644;&#35745;&#31639;&#20248;&#21183;&#65292;&#24182;&#36890;&#36807;&#38750;&#21442;&#25968;&#20108;&#20998;&#31867;&#22238;&#24402;&#27169;&#25311;&#30740;&#31350;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07048</link><description>&lt;p&gt;
&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;beta&#36793;&#38469;&#20998;&#24067;&#30340;&#30456;&#20851;&#38543;&#26426;&#27010;&#29575;&#30340;logistic-beta&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Logistic-beta processes for modeling dependent random probabilities with beta marginals
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;logistic-beta&#36807;&#31243;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;beta&#36793;&#38469;&#20998;&#24067;&#30340;&#30456;&#20851;&#38543;&#26426;&#27010;&#29575;&#12290;&#35813;&#36807;&#31243;&#20855;&#26377;&#28789;&#27963;&#30340;&#30456;&#20851;&#32467;&#26500;&#21644;&#35745;&#31639;&#20248;&#21183;&#65292;&#24182;&#36890;&#36807;&#38750;&#21442;&#25968;&#20108;&#20998;&#31867;&#22238;&#24402;&#27169;&#25311;&#30740;&#31350;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
beta&#20998;&#24067;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#27010;&#29575;&#24314;&#27169;&#65292;&#24182;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#23588;&#20854;&#22312;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#39046;&#22495;&#12290;&#23613;&#31649;&#20854;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#22312;&#24314;&#27169;&#30456;&#20851;&#38543;&#26426;&#27010;&#29575;&#30340;&#28789;&#27963;&#21644;&#35745;&#31639;&#26041;&#20415;&#30340;&#38543;&#26426;&#36807;&#31243;&#25193;&#23637;&#26041;&#38754;&#65292;&#30456;&#20851;&#24037;&#20316;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#31216;&#20026;logistic-beta&#36807;&#31243;&#65292;&#20854;logistic&#21464;&#25442;&#29983;&#25104;&#20855;&#26377;&#24120;&#35265;beta&#36793;&#38469;&#20998;&#24067;&#30340;&#38543;&#26426;&#36807;&#31243;&#12290;&#31867;&#20284;&#20110;&#39640;&#26031;&#36807;&#31243;&#65292;logistic-beta&#36807;&#31243;&#21487;&#20197;&#24314;&#27169;&#31163;&#25955;&#21644;&#36830;&#32493;&#22495;&#65288;&#20363;&#22914;&#31354;&#38388;&#25110;&#26102;&#38388;&#65289;&#19978;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#36890;&#36807;&#30456;&#20851;&#26680;&#20989;&#25968;&#20855;&#26377;&#39640;&#24230;&#28789;&#27963;&#30340;&#30456;&#20851;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#23427;&#30340;&#27491;&#24577;&#26041;&#24046;-&#22343;&#20540;&#28151;&#21512;&#34920;&#31034;&#23548;&#33268;&#20102;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#29702;&#31639;&#27861;&#12290;&#36890;&#36807;&#38750;&#21442;&#25968;&#20108;&#20998;&#31867;&#22238;&#24402;&#27169;&#25311;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;logistic-beta&#36807;&#31243;&#30340;&#28789;&#27963;&#24615;&#21644;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
The beta distribution serves as a canonical tool for modeling probabilities and is extensively used in statistics and machine learning, especially in the field of Bayesian nonparametrics. Despite its widespread use, there is limited work on flexible and computationally convenient stochastic process extensions for modeling dependent random probabilities. We propose a novel stochastic process called the logistic-beta process, whose logistic transformation yields a stochastic process with common beta marginals. Similar to the Gaussian process, the logistic-beta process can model dependence on both discrete and continuous domains, such as space or time, and has a highly flexible dependence structure through correlation kernels. Moreover, its normal variance-mean mixture representation leads to highly effective posterior inference algorithms. The flexibility and computational benefits of logistic-beta processes are demonstrated through nonparametric binary regression simulation studies. Fur
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#19979;&#22788;&#29702;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#30452;&#25509;&#20272;&#35745;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#24182;&#35757;&#32451;&#20986;&#22122;&#22768;&#23481;&#24525;&#20998;&#31867;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#19979;&#37117;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04398</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#26102;&#38388;&#24207;&#21015;&#19979;&#22788;&#29702;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;
&lt;/p&gt;
&lt;p&gt;
Learning from Time Series under Temporal Label Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04398
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#19979;&#22788;&#29702;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#30452;&#25509;&#20272;&#35745;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#24182;&#35757;&#32451;&#20986;&#22122;&#22768;&#23481;&#24525;&#20998;&#31867;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#19979;&#37117;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#39034;&#24207;&#20998;&#31867;&#20219;&#21153;&#21463;&#21040;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#26631;&#31614;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#36825;&#31181;&#22122;&#22768;&#21487;&#33021;&#20250;&#23548;&#33268;&#26631;&#31614;&#36136;&#37327;&#38543;&#26102;&#38388;&#25913;&#21892;&#12289;&#24694;&#21270;&#25110;&#21608;&#26399;&#24615;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#21644;&#31995;&#32479;&#21270;&#20102;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#20851;&#20110;&#26102;&#38388;&#24207;&#21015;&#39034;&#24207;&#20998;&#31867;&#30340;&#19968;&#20010;&#26410;&#32463;&#30740;&#31350;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#22810;&#20010;&#26631;&#31614;&#36830;&#32493;&#35760;&#24405;&#65292;&#21516;&#26102;&#21463;&#21040;&#19968;&#20010;&#19982;&#26102;&#38388;&#30456;&#20851;&#30340;&#22122;&#22768;&#20989;&#25968;&#30340;&#24178;&#25200;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#24314;&#27169;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#20197;&#21450;&#29616;&#26377;&#26041;&#27861;&#30340;&#25345;&#32493;&#20302;&#25928;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#35757;&#32451;&#20986;&#23545;&#22122;&#22768;&#20855;&#26377;&#23481;&#24525;&#24615;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#21508;&#26679;&#30340;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#19979;&#65292;&#20351;&#29992;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#22312;&#24615;&#33021;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many sequential classification tasks are affected by label noise that varies over time. Such noise can cause label quality to improve, worsen, or periodically change over time. We first propose and formalize temporal label noise, an unstudied problem for sequential classification of time series. In this setting, multiple labels are recorded in sequence while being corrupted by a time-dependent noise function. We first demonstrate the importance of modelling the temporal nature of the label noise function and how existing methods will consistently underperform. We then propose methods that can train noise-tolerant classifiers by estimating the temporal label noise function directly from data. We show that our methods lead to state-of-the-art performance in the presence of diverse temporal label noise functions using real and synthetic data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#65292;&#36890;&#36807;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#26679;&#26412;&#35201;&#27714;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02041</link><description>&lt;p&gt;
&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
$\alpha$-Divergence Loss Function for Neural Density Ratio Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#31070;&#32463;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#65292;&#36890;&#36807;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#30740;&#31350;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#26679;&#26412;&#35201;&#27714;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22522;&#30784;&#25216;&#26415;&#23494;&#24230;&#27604;&#20272;&#35745;(DRE)&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22240;DRE&#30340;&#25439;&#22833;&#20989;&#25968;&#32780;&#20986;&#29616;&#20102;&#20248;&#21270;&#38382;&#39064;&#65306;KL&#25955;&#24230;&#38656;&#35201;&#22823;&#26679;&#26412;&#65292;&#35757;&#32451;&#25439;&#22833;&#26799;&#24230;&#28040;&#22833;&#65292;&#25439;&#22833;&#20989;&#25968;&#26799;&#24230;&#26377;&#20559;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#20379;&#31616;&#27905;&#23454;&#29616;&#21644;&#31283;&#23450;&#20248;&#21270;&#30340;$\alpha$-&#25955;&#24230;&#25439;&#22833;&#20989;&#25968;($\alpha$-Div)&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#23545;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#25216;&#26415;&#39564;&#35777;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;DRE&#20219;&#21153;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;DRE&#30340;&#26679;&#26412;&#35201;&#27714;&#65292;&#20197;$L_1$&#35823;&#24046;&#30340;&#19978;&#30028;&#32852;&#31995;&#36215;&#26469;&#65292;&#35813;&#19978;&#30028;&#23558;&#39640;&#32500;&#24230;DRE&#20219;&#21153;&#20013;&#30340;&#32500;&#24230;&#35781;&#21650;&#20316;&#20026;&#19968;&#20010;&#20849;&#21516;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, neural networks have produced state-of-the-art results for density-ratio estimation (DRE), a fundamental technique in machine learning. However, existing methods bear optimization issues that arise from the loss functions of DRE: a large sample requirement of Kullback--Leibler (KL)-divergence, vanishing of train loss gradients, and biased gradients of the loss functions. Thus, an $\alpha$-divergence loss function ($\alpha$-Div) that offers concise implementation and stable optimization is proposed in this paper. Furthermore, technical justifications for the proposed loss function are presented. The stability of the proposed loss function is empirically demonstrated and the estimation accuracy of DRE tasks is investigated. Additionally, this study presents a sample requirement for DRE using the proposed loss function in terms of the upper bound of $L_1$ error, which connects a curse of dimensionality as a common problem in high-dimensional DRE tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#19979;&#30340;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20173;&#28982;&#21463;&#30410;&#12290;</title><link>https://arxiv.org/abs/2311.17539</link><description>&lt;p&gt;
&#22312;&#36807;&#21442;&#25968;&#21270;&#19979;&#20998;&#26512;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Analyzing Sharpness-aware Minimization under Overparameterization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#19979;&#30340;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20173;&#28982;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#23613;&#31649;&#35757;&#32451;&#25439;&#22833;&#30456;&#21516;&#65292;&#20294;&#21487;&#20197;&#24471;&#21040;&#20855;&#26377;&#19981;&#21516;&#27867;&#21270;&#33021;&#21147;&#30340;&#26497;&#23567;&#20540;&#12290;&#26377;&#35777;&#25454;&#34920;&#26126;&#65292;&#26497;&#23567;&#20540;&#30340;&#38160;&#24230;&#19982;&#20854;&#27867;&#21270;&#35823;&#24046;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#22240;&#27492;&#24050;&#32463;&#20570;&#20986;&#20102;&#26356;&#22810;&#21162;&#21147;&#24320;&#21457;&#19968;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#20197;&#26174;&#24335;&#22320;&#25214;&#21040;&#25153;&#24179;&#26497;&#23567;&#20540;&#20316;&#20026;&#26356;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#30340;&#35299;&#12290;&#28982;&#32780;&#65292;&#33267;&#20170;&#20026;&#27490;&#65292;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#31574;&#30053;&#30340;&#24433;&#21709;&#30340;&#30740;&#31350;&#36824;&#19981;&#22810;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#19981;&#21516;&#31243;&#24230;&#30340;&#36807;&#21442;&#25968;&#21270;&#19979;&#30340;SAM&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#34920;&#26126;&#36807;&#21442;&#25968;&#21270;&#23545;SAM&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#28085;&#30422;&#20102;&#21508;&#20010;&#39046;&#22495;&#65292;&#24182;&#34920;&#26126;&#23384;&#22312;&#19968;&#31181;&#19968;&#33268;&#30340;&#36235;&#21183;&#65292;&#21363;SAM&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#21463;&#30410;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#19968;&#20123;&#20196;&#20154;&#20449;&#26381;&#30340;&#26696;&#20363;&#65292;&#35828;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training an overparameterized neural network can yield minimizers of different generalization capabilities despite the same level of training loss. With evidence that suggests a correlation between sharpness of minima and their generalization errors, increasing efforts have been made to develop an optimization method to explicitly find flat minima as more generalizable solutions. However, this sharpness-aware minimization (SAM) strategy has not been studied much yet as to whether and how it is affected by overparameterization.   In this work, we analyze SAM under overparameterization of varying degrees and present both empirical and theoretical results that indicate a critical influence of overparameterization on SAM. Specifically, we conduct extensive numerical experiments across various domains, and show that there exists a consistent trend that SAM continues to benefit from increasing overparameterization. We also discover compelling cases where the effect of overparameterization is
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#26681;&#25454;&#23567;&#26679;&#26412;&#25968;&#25454;&#30340;&#21407;&#22987;&#31181;&#32676;&#23558;&#25968;&#25454;&#20998;&#20026;&#20004;&#32452;&#65292;&#36866;&#29992;&#20110;&#31181;&#32676;&#20043;&#38388;&#24046;&#24322;&#36739;&#23567;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.10927</link><description>&lt;p&gt;
&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#30340;&#21435;&#20559;&#21644;&#23616;&#37096;&#20998;&#26512;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Debiasing and a local analysis for population clustering using semidefinite programming. (arXiv:2401.10927v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#26681;&#25454;&#23567;&#26679;&#26412;&#25968;&#25454;&#30340;&#21407;&#22987;&#31181;&#32676;&#23558;&#25968;&#25454;&#20998;&#20026;&#20004;&#32452;&#65292;&#36866;&#29992;&#20110;&#31181;&#32676;&#20043;&#38388;&#24046;&#24322;&#36739;&#23567;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20174;&#28151;&#21512;&#30340;2&#20010;&#27425;&#39640;&#26031;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#23567;&#25968;&#25454;&#26679;&#26412;&#30340;&#20998;&#21306;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21516;&#19968;&#20316;&#32773;&#25552;&#20986;&#30340;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#23558;&#25968;&#25454;&#26681;&#25454;&#20854;&#21407;&#22987;&#31181;&#32676;&#22823;&#33268;&#20998;&#20026;&#20004;&#32452;&#65292;&#32473;&#23450;&#19968;&#20010;&#23567;&#26679;&#26412;&#12290;&#26412;&#25991;&#30340;&#30740;&#31350;&#21160;&#26426;&#26159;&#23558;&#20010;&#20307;&#26681;&#25454;&#20854;&#21407;&#22987;&#31181;&#32676;&#20351;&#29992;p&#20010;&#26631;&#35760;&#36827;&#34892;&#32858;&#31867;&#65292;&#24403;&#20219;&#24847;&#20004;&#20010;&#31181;&#32676;&#20043;&#38388;&#30340;&#24046;&#24322;&#24456;&#23567;&#26102;&#12290;&#25105;&#20204;&#22522;&#20110;&#25972;&#25968;&#20108;&#27425;&#35268;&#21010;&#30340;&#21322;&#27491;&#23450;&#26494;&#24347;&#24418;&#24335;&#26500;&#24314;&#65292;&#35813;&#35268;&#21010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#22312;&#19968;&#20010;&#22270;&#19978;&#25214;&#21040;&#26368;&#22823;&#21106;&#65292;&#20854;&#20013;&#21106;&#20013;&#30340;&#36793;&#26435;&#37325;&#34920;&#31034;&#22522;&#20110;&#23427;&#20204;&#30340;p&#20010;&#29305;&#24449;&#30340;&#20004;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#19981;&#30456;&#20284;&#24230;&#24471;&#20998;&#12290;&#25105;&#20204;&#29992;&#916;^2:=p&#947;&#26469;&#34920;&#31034;&#20004;&#20010;&#20013;&#24515;&#65288;&#22343;&#20540;&#21521;&#37327;&#65289;&#20043;&#38388;&#30340;&#8467;_2^2&#36317;&#31163;&#65292;&#21363;&#956;^(1), &#956;^(2)&#8712;&#8477;^p&#12290;&#30446;&#26631;&#26159;&#22312;&#20132;&#25442;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#20043;&#38388;&#25552;&#20379;&#20840;&#38754;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of partitioning a small data sample of size $n$ drawn from a mixture of $2$ sub-gaussian distributions. In particular, we analyze computational efficient algorithms proposed by the same author, to partition data into two groups approximately according to their population of origin given a small sample. This work is motivated by the application of clustering individuals according to their population of origin using $p$ markers, when the divergence between any two of the populations is small. We build upon the semidefinite relaxation of an integer quadratic program that is formulated essentially as finding the maximum cut on a graph, where edge weights in the cut represent dissimilarity scores between two nodes based on their $p$ features. Here we use $\Delta^2 :=p \gamma$ to denote the $\ell_2^2$ distance between two centers (mean vectors), namely, $\mu^{(1)}$, $\mu^{(2)}$ $\in$ $\mathbb{R}^p$. The goal is to allow a full range of tradeoffs between
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#29109;&#21305;&#37197;&#26694;&#26550;&#30340;&#26032;&#30340;&#21487;&#22788;&#29702;&#30340;&#25512;&#26029;&#26041;&#26696;&#65292;&#21487;&#20197;&#23884;&#20837;&#21040;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#20013;&#65292;&#23545;&#20110;&#25551;&#36848;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#36807;&#31243;&#30340;Markov&#36339;&#36291;&#36807;&#31243;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#31867;&#36817;&#20284;&#20998;&#24067;&#30340;&#38381;&#24335;&#32467;&#26524;&#20197;&#21450;&#24212;&#29992;&#20110;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#30340;&#19968;&#33324;&#31867;&#21035;&#26469;&#21152;&#20197;&#35770;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#36817;&#20284;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31243;&#24207;&#23548;&#20986;&#20102;&#28508;&#22312;&#21442;&#25968;&#30340;&#28857;&#20272;&#35745;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#22312;&#21508;&#31181;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#31034;&#20363;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;&#26410;&#26469;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.15604</link><description>&lt;p&gt;
Entropic Matching&#29992;&#20110;Markov&#36339;&#36291;&#36807;&#31243;&#30340;&#26399;&#26395;&#20256;&#25773;&#30340;&#29109;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Entropic Matching for Expectation Propagation of Markov Jump Processes. (arXiv:2309.15604v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15604
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#29109;&#21305;&#37197;&#26694;&#26550;&#30340;&#26032;&#30340;&#21487;&#22788;&#29702;&#30340;&#25512;&#26029;&#26041;&#26696;&#65292;&#21487;&#20197;&#23884;&#20837;&#21040;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#20013;&#65292;&#23545;&#20110;&#25551;&#36848;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#36807;&#31243;&#30340;Markov&#36339;&#36291;&#36807;&#31243;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#31867;&#36817;&#20284;&#20998;&#24067;&#30340;&#38381;&#24335;&#32467;&#26524;&#20197;&#21450;&#24212;&#29992;&#20110;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#30340;&#19968;&#33324;&#31867;&#21035;&#26469;&#21152;&#20197;&#35770;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#36817;&#20284;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31243;&#24207;&#23548;&#20986;&#20102;&#28508;&#22312;&#21442;&#25968;&#30340;&#28857;&#20272;&#35745;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#22312;&#21508;&#31181;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#31034;&#20363;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;&#26410;&#26469;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#28508;&#22312;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#36807;&#31243;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#30001;Markov&#36339;&#36291;&#36807;&#31243;&#25551;&#36848;&#30340;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#36807;&#31243;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#22788;&#29702;&#30340;&#25512;&#26029;&#26041;&#26696;&#65292;&#22522;&#20110;&#29109;&#21305;&#37197;&#26694;&#26550;&#65292;&#21487;&#20197;&#23884;&#20837;&#21040;&#20247;&#25152;&#21608;&#30693;&#30340;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#19968;&#31867;&#31616;&#21333;&#30340;&#36817;&#20284;&#20998;&#24067;&#25552;&#20379;&#38381;&#24335;&#32467;&#26524;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#30340;&#19968;&#33324;&#31867;&#21035;&#65292;&#35813;&#31867;&#21035;&#26159;&#31995;&#32479;&#29983;&#29289;&#23398;&#24314;&#27169;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#26469;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#36817;&#20284;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31243;&#24207;&#23548;&#20986;&#20102;&#28508;&#22312;&#21442;&#25968;&#30340;&#28857;&#20272;&#35745;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#21508;&#31181;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#31034;&#20363;&#20013;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#38543;&#26426;&#30340;Lotka-Voltera&#31034;&#20363;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#30340;&#23616;&#38480;&#24615;&#21644;&#26410;&#26469;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the problem of statistical inference for latent continuous-time stochastic processes, which is often intractable, particularly for discrete state space processes described by Markov jump processes. To overcome this issue, we propose a new tractable inference scheme based on an entropic matching framework that can be embedded into the well-known expectation propagation algorithm. We demonstrate the effectiveness of our method by providing closed-form results for a simple family of approximate distributions and apply it to the general class of chemical reaction networks, which are a crucial tool for modeling in systems biology. Moreover, we derive closed form expressions for point estimation of the underlying parameters using an approximate expectation maximization procedure. We evaluate the performance of our method on various chemical reaction network instantiations, including a stochastic Lotka-Voltera example, and discuss its limitations and potential for future 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.07261</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21516;&#26102;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#30740;&#31350;&#20013;&#65292;&#24120;&#24120;&#36827;&#34892;&#25104;&#21315;&#19978;&#19975;&#20010;&#21516;&#26102;&#20551;&#35774;&#26816;&#39564;&#65292;&#20197;&#30830;&#23450;&#24046;&#24322;&#34920;&#36798;&#30340;&#22522;&#22240;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#22312;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#65292;&#35768;&#22810;&#26631;&#20934;&#32479;&#35745;&#26041;&#27861;&#21487;&#33021;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#22810;&#20803;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#12290;&#22312;&#20219;&#24847;&#28151;&#28102;&#26426;&#21046;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#24182;&#23558;&#32447;&#24615;&#25237;&#24433;&#25972;&#21512;&#21040;&#19977;&#20010;&#20851;&#38190;&#38454;&#27573;&#20013;&#12290;&#39318;&#20808;&#65292;&#21033;&#29992;&#22810;&#20803;&#21709;&#24212;&#21464;&#37327;&#20998;&#31163;&#36793;&#38469;&#21644;&#19981;&#30456;&#20851;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#24674;&#22797;&#28151;&#28102;&#31995;&#25968;&#30340;&#21015;&#31354;&#38388;&#12290;&#38543;&#21518;&#65292;&#21033;&#29992;$\ell_1$&#27491;&#21017;&#21270;&#36827;&#34892;&#31232;&#30095;&#24615;&#20272;&#35745;&#65292;&#24182;&#24378;&#21152;&#27491;&#20132;&#24615;&#38480;&#21046;&#20110;&#28151;&#28102;&#31995;&#25968;&#65292;&#32852;&#21512;&#20272;&#35745;&#28508;&#22312;&#22240;&#23376;&#21644;&#20027;&#35201;&#25928;&#24212;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32467;&#21512;&#25237;&#24433;&#21644;&#21152;&#26435;&#20559;&#24046;&#26657;&#27491;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;Nystr\"om $M$-Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;&#65292;&#38024;&#23545;&#22823;&#35268;&#27169;&#24212;&#29992;&#30340;&#20108;&#27425;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#36827;&#34892;&#20102;&#35299;&#20915;&#65292;&#24182;&#20860;&#39038;&#20102;&#22810;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#25512;&#24191;&#24773;&#20917;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2302.09930</link><description>&lt;p&gt;
Nystr\"om $M$-Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Nystr\"om $M$-Hilbert-Schmidt Independence Criterion. (arXiv:2302.09930v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09930
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;Nystr\"om $M$-Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;&#65292;&#38024;&#23545;&#22823;&#35268;&#27169;&#24212;&#29992;&#30340;&#20108;&#27425;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#36827;&#34892;&#20102;&#35299;&#20915;&#65292;&#24182;&#20860;&#39038;&#20102;&#22810;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#25512;&#24191;&#24773;&#20917;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#25216;&#26415;&#26159;&#25968;&#25454;&#31185;&#23398;&#20013;&#26368;&#21463;&#27426;&#36814;&#21644;&#24378;&#22823;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#26680;&#30340;&#24191;&#27867;&#24212;&#29992;&#30340;&#20851;&#38190;&#29305;&#24615;&#21253;&#25324;&#65306;(i) &#23427;&#20204;&#38024;&#23545;&#30340;&#39046;&#22495;&#25968;&#37327;&#22810;&#65292;(ii) &#19982;&#26680;&#30456;&#20851;&#30340;&#20989;&#25968;&#31867;&#20855;&#26377;Hilbert&#32467;&#26500;&#65292;&#20415;&#20110;&#32479;&#35745;&#20998;&#26512;&#65292;&#20197;&#21450;(iii) &#23427;&#20204;&#33021;&#22815;&#20197;&#19981;&#20002;&#22833;&#20449;&#24687;&#30340;&#26041;&#24335;&#34920;&#31034;&#27010;&#29575;&#20998;&#24067;&#12290;&#36825;&#20123;&#29305;&#24615;&#23548;&#33268;&#20102;Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;(HSIC)&#30340;&#24040;&#22823;&#25104;&#21151;&#65292;&#35813;&#20934;&#21017;&#33021;&#22815;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#25429;&#25417;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#29420;&#31435;&#24615;&#65292;&#24182;&#20801;&#35768;&#20855;&#26377;&#20108;&#27425;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#38381;&#24335;&#20272;&#35745;&#22120;(&#30456;&#23545;&#20110;&#26679;&#26412;&#22823;&#23567;)&#12290;&#20026;&#20102;&#35299;&#20915;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#30340;&#20108;&#27425;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#22810;&#20010;HSIC&#36817;&#20284;&#20272;&#35745;&#22120;&#65292;&#28982;&#32780;&#36825;&#20123;&#20272;&#35745;&#22120;&#38480;&#21046;&#20110;$M=2$&#20010;&#38543;&#26426;&#21464;&#37327;&#65292;&#19981;&#33021;&#33258;&#28982;&#22320;&#25512;&#24191;&#21040;$M \geq 2$&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;Nystr\"om $M$-Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel techniques are among the most popular and powerful approaches of data science. Among the key features that make kernels ubiquitous are (i) the number of domains they have been designed for, (ii) the Hilbert structure of the function class associated to kernels facilitating their statistical analysis, and (iii) their ability to represent probability distributions without loss of information. These properties give rise to the immense success of Hilbert-Schmidt independence criterion (HSIC) which is able to capture joint independence of random variables under mild conditions, and permits closed-form estimators with quadratic computational complexity (w.r.t. the sample size). In order to alleviate the quadratic computational bottleneck in large-scale applications, multiple HSIC approximations have been proposed, however these estimators are restricted to $M=2$ random variables, do not extend naturally to the $M\ge 2$ case, and lack theoretical guarantees. In this work, we propose an
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#25968;&#25454;&#22686;&#24378;&#22914;&#20309;&#24433;&#21709;&#20272;&#35745;&#30340;&#26041;&#24046;&#21644;&#26497;&#38480;&#20998;&#24067;&#30340;&#30830;&#20999;&#37327;&#21270;&#32467;&#26524;&#65292;&#21457;&#29616;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#22686;&#21152;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#20854;&#25928;&#26524;&#21462;&#20915;&#20110;&#22810;&#20010;&#22240;&#32032;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#36824;&#36890;&#36807;&#38543;&#26426;&#36716;&#25442;&#30340;&#39640;&#32500;&#38543;&#26426;&#21521;&#37327;&#30340;&#20989;&#25968;&#30340;&#26497;&#38480;&#23450;&#29702;&#36827;&#34892;&#20102;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2202.09134</link><description>&lt;p&gt;
&#22312;&#27424;&#21442;&#25968;&#21270;&#21644;&#36807;&#21442;&#25968;&#21270;&#30340;&#27169;&#24335;&#20013;&#30340;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Data Augmentation in the Underparameterized and Overparameterized Regimes. (arXiv:2202.09134v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.09134
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#25968;&#25454;&#22686;&#24378;&#22914;&#20309;&#24433;&#21709;&#20272;&#35745;&#30340;&#26041;&#24046;&#21644;&#26497;&#38480;&#20998;&#24067;&#30340;&#30830;&#20999;&#37327;&#21270;&#32467;&#26524;&#65292;&#21457;&#29616;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#22686;&#21152;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#20854;&#25928;&#26524;&#21462;&#20915;&#20110;&#22810;&#20010;&#22240;&#32032;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#36824;&#36890;&#36807;&#38543;&#26426;&#36716;&#25442;&#30340;&#39640;&#32500;&#38543;&#26426;&#21521;&#37327;&#30340;&#20989;&#25968;&#30340;&#26497;&#38480;&#23450;&#29702;&#36827;&#34892;&#20102;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#30830;&#20999;&#37327;&#21270;&#25968;&#25454;&#22686;&#24378;&#22914;&#20309;&#24433;&#21709;&#20272;&#35745;&#30340;&#26041;&#24046;&#21644;&#26497;&#38480;&#20998;&#24067;&#30340;&#32467;&#26524;&#65292;&#24182;&#35814;&#32454;&#20998;&#26512;&#20102;&#20960;&#20010;&#20855;&#20307;&#27169;&#22411;&#12290;&#32467;&#26524;&#35777;&#23454;&#20102;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#30340;&#19968;&#20123;&#35266;&#23519;&#65292;&#20294;&#20063;&#24471;&#20986;&#20102;&#24847;&#22806;&#30340;&#21457;&#29616;&#65306;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#22686;&#21152;&#32780;&#19981;&#26159;&#20943;&#23569;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#27604;&#22914;&#32463;&#39564;&#39044;&#27979;&#39118;&#38505;&#12290;&#23427;&#21487;&#20197;&#20805;&#24403;&#27491;&#21017;&#21270;&#22120;&#65292;&#20294;&#22312;&#26576;&#20123;&#39640;&#32500;&#38382;&#39064;&#20013;&#21364;&#26080;&#27861;&#23454;&#29616;&#65292;&#24182;&#19988;&#21487;&#33021;&#20250;&#25913;&#21464;&#32463;&#39564;&#39118;&#38505;&#30340;&#21452;&#37325;&#19979;&#38477;&#23792;&#20540;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#20998;&#26512;&#34920;&#26126;&#25968;&#25454;&#22686;&#24378;&#34987;&#36171;&#20104;&#30340;&#20960;&#20010;&#23646;&#24615;&#35201;&#20040;&#26159;&#30495;&#30340;&#65292;&#35201;&#20040;&#26159;&#20551;&#30340;&#65292;&#32780;&#26159;&#21462;&#20915;&#20110;&#22810;&#20010;&#22240;&#32032;&#30340;&#32452;&#21512;-&#29305;&#21035;&#26159;&#25968;&#25454;&#20998;&#24067;&#65292;&#20272;&#35745;&#22120;&#30340;&#23646;&#24615;&#20197;&#21450;&#26679;&#26412;&#22823;&#23567;&#65292;&#22686;&#24378;&#25968;&#37327;&#21644;&#32500;&#25968;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#29702;&#35770;&#24037;&#20855;&#26159;&#38543;&#26426;&#36716;&#25442;&#30340;&#39640;&#32500;&#38543;&#26426;&#21521;&#37327;&#30340;&#20989;&#25968;&#30340;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide results that exactly quantify how data augmentation affects the variance and limiting distribution of estimates, and analyze several specific models in detail. The results confirm some observations made in machine learning practice, but also lead to unexpected findings: Data augmentation may increase rather than decrease the uncertainty of estimates, such as the empirical prediction risk. It can act as a regularizer, but fails to do so in certain high-dimensional problems, and it may shift the double-descent peak of an empirical risk. Overall, the analysis shows that several properties data augmentation has been attributed with are not either true or false, but rather depend on a combination of factors -- notably the data distribution, the properties of the estimator, and the interplay of sample size, number of augmentations, and dimension. Our main theoretical tool is a limit theorem for functions of randomly transformed, high-dimensional random vectors. The proof draws on 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#31616;&#21333;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;&#12290;&#36890;&#36807;&#24341;&#20837;&#24207;&#36143;&#26680;&#23884;&#20837;&#25216;&#26415;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#23545;&#22797;&#26434;&#22240;&#26524;&#20272;&#35745;&#30340;&#31616;&#21270;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#20272;&#35745;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#24378;&#22823;&#24615;&#33021;&#21644;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.03950</link><description>&lt;p&gt;
&#24207;&#36143;&#26680;&#23884;&#20837;&#29992;&#20110;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Sequential Kernel Embedding for Mediated and Time-Varying Dose Response Curves. (arXiv:2111.03950v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.03950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#31616;&#21333;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;&#12290;&#36890;&#36807;&#24341;&#20837;&#24207;&#36143;&#26680;&#23884;&#20837;&#25216;&#26415;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#23545;&#22797;&#26434;&#22240;&#26524;&#20272;&#35745;&#30340;&#31616;&#21270;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#20272;&#35745;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#24378;&#22823;&#24615;&#33021;&#21644;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;&#30340;&#31616;&#21333;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#12290;&#36890;&#36807;&#23884;&#20837;Pearl&#30340;&#20171;&#23548;&#20844;&#24335;&#21644;Robins&#30340;g&#20844;&#24335;&#19982;&#26680;&#20989;&#25968;&#65292;&#25105;&#20204;&#20801;&#35768;&#22788;&#29702;&#12289;&#20171;&#23548;&#32773;&#21644;&#21327;&#21464;&#37327;&#22312;&#19968;&#33324;&#31354;&#38388;&#20013;&#36830;&#32493;&#21464;&#21270;&#65292;&#20063;&#20801;&#35768;&#38750;&#32447;&#24615;&#30340;&#22788;&#29702;-&#28151;&#28102;&#22240;&#32032;&#21453;&#39304;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#21019;&#26032;&#26159;&#19968;&#31181;&#31216;&#20026;&#24207;&#36143;&#26680;&#23884;&#20837;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#25216;&#26415;&#65292;&#25105;&#20204;&#20351;&#29992;&#23427;&#26469;&#26500;&#24314;&#22797;&#26434;&#22240;&#26524;&#20272;&#35745;&#30340;&#31616;&#21333;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20445;&#30041;&#20102;&#32463;&#20856;&#35782;&#21035;&#30340;&#26222;&#36866;&#24615;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#38750;&#28176;&#36827;&#22343;&#21248;&#25910;&#25947;&#36895;&#24230;&#12290;&#22312;&#20855;&#26377;&#35768;&#22810;&#21327;&#21464;&#37327;&#30340;&#38750;&#32447;&#24615;&#27169;&#25311;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20272;&#35745;&#20102;&#32654;&#22269;&#32844;&#19994;&#35757;&#32451;&#22242;&#30340;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;&#65292;&#24182;&#28165;&#27905;&#21487;&#33021;&#25104;&#20026;&#26410;&#26469;&#24037;&#20316;&#22522;&#20934;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#20171;&#23548;&#21644;&#26102;&#21464;&#22788;&#29702;&#25928;&#24212;&#20197;&#21450;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#39564;&#35777;&#20102;&#21322;&#21442;&#25968;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose simple nonparametric estimators for mediated and time-varying dose response curves based on kernel ridge regression. By embedding Pearl's mediation formula and Robins' g-formula with kernels, we allow treatments, mediators, and covariates to be continuous in general spaces, and also allow for nonlinear treatment-confounder feedback. Our key innovation is a reproducing kernel Hilbert space technique called sequential kernel embedding, which we use to construct simple estimators for complex causal estimands. Our estimators preserve the generality of classic identification while also achieving nonasymptotic uniform rates. In nonlinear simulations with many covariates, we demonstrate strong performance. We estimate mediated and time-varying dose response curves of the US Job Corps, and clean data that may serve as a benchmark in future work. We extend our results to mediated and time-varying treatment effects and counterfactual distributions, verifying semiparametric efficiency 
&lt;/p&gt;</description></item></channel></rss>