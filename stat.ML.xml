<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#20102;&#22522;&#20110;Fisher&#20449;&#24687;&#30697;&#38453;&#30340;&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#22312;&#32447;&#24615;&#35268;&#21010;&#20013;&#30340;&#24212;&#29992;&#65292;&#23637;&#31034;&#20102;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#29616;&#26377;&#32467;&#26524;&#30340;&#29109;&#27491;&#21017;&#21270;&#35823;&#24046;&#20272;&#35745;&#65292;&#24182;&#23545;&#25200;&#21160;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#21644;&#33258;&#28982;&#26799;&#24230;&#27969;&#30340;&#27425;&#32447;&#24615;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.19448</link><description>&lt;p&gt;
Fisher-Rao&#32447;&#24615;&#35268;&#21010;&#21644;&#29366;&#24577;-&#21160;&#20316;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#26799;&#24230;&#27969;
&lt;/p&gt;
&lt;p&gt;
Fisher-Rao Gradient Flows of Linear Programs and State-Action Natural Policy Gradients
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19448
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22522;&#20110;Fisher&#20449;&#24687;&#30697;&#38453;&#30340;&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#22312;&#32447;&#24615;&#35268;&#21010;&#20013;&#30340;&#24212;&#29992;&#65292;&#23637;&#31034;&#20102;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#29616;&#26377;&#32467;&#26524;&#30340;&#29109;&#27491;&#21017;&#21270;&#35823;&#24046;&#20272;&#35745;&#65292;&#24182;&#23545;&#25200;&#21160;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#21644;&#33258;&#28982;&#26799;&#24230;&#27969;&#30340;&#27425;&#32447;&#24615;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kakade&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#36817;&#24180;&#26469;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#34920;&#26126;&#22312;&#26377;&#25110;&#26080;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21478;&#19968;&#31181;&#22522;&#20110;&#29366;&#24577;-&#21160;&#20316;&#20998;&#24067;&#30340;Fisher&#20449;&#24687;&#30697;&#38453;&#30340;&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#65292;&#20294;&#22312;&#29702;&#35770;&#26041;&#38754;&#25509;&#21463;&#24230;&#36739;&#20302;&#12290;&#22312;&#36825;&#37324;&#65292;&#29366;&#24577;-&#21160;&#20316;&#20998;&#24067;&#22312;&#29366;&#24577;-&#21160;&#20316;&#22810;&#38754;&#20307;&#20869;&#36981;&#24490;Fisher-Rao&#26799;&#24230;&#27969;&#65292;&#30456;&#23545;&#20110;&#32447;&#24615;&#21183;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26356;&#20840;&#38754;&#22320;&#30740;&#31350;&#32447;&#24615;&#35268;&#21010;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#65292;&#24182;&#26174;&#31034;&#20102;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#20854;&#36895;&#29575;&#21462;&#20915;&#20110;&#32447;&#24615;&#35268;&#21010;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#36825;&#25552;&#20379;&#20102;&#32447;&#24615;&#35268;&#21010;&#30340;&#29109;&#27491;&#21017;&#21270;&#24341;&#36215;&#30340;&#35823;&#24046;&#20272;&#35745;&#65292;&#36825;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#12290;&#25105;&#20204;&#25299;&#23637;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#23545;&#25200;&#21160;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#21644;&#33258;&#28982;&#26799;&#24230;&#27969;&#30340;&#27425;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#30452;&#21040;&#36924;&#36817;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19448v1 Announce Type: cross  Abstract: Kakade's natural policy gradient method has been studied extensively in the last years showing linear convergence with and without regularization. We study another natural gradient method which is based on the Fisher information matrix of the state-action distributions and has received little attention from the theoretical side. Here, the state-action distributions follow the Fisher-Rao gradient flow inside the state-action polytope with respect to a linear potential. Therefore, we study Fisher-Rao gradient flows of linear programs more generally and show linear convergence with a rate that depends on the geometry of the linear program. Equivalently, this yields an estimate on the error induced by entropic regularization of the linear program which improves existing results. We extend these results and show sublinear convergence for perturbed Fisher-Rao gradient flows and natural gradient flows up to an approximation error. In particul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#30740;&#31350;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#33021;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#25910;&#25947;&#24615;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.09766</link><description>&lt;p&gt;
&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Bayesian Optimization. (arXiv:2310.09766v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#30740;&#31350;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#33021;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#25910;&#25947;&#24615;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20248;&#21270;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#20854;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#19968;&#20010;&#26367;&#20195;&#27169;&#22411;&#26469;&#36817;&#20284;&#30446;&#26631;&#65292;&#24182;&#19988;&#37325;&#35201;&#30340;&#26159;&#37327;&#21270;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#25506;&#32034;&#21644;&#24320;&#21457;&#20043;&#38388;&#30340;&#24179;&#34913;&#30340;&#39034;&#24207;&#25628;&#32034;&#12290;&#39640;&#26031;&#36807;&#31243;(GP)&#19968;&#30452;&#26159;&#26367;&#20195;&#27169;&#22411;&#30340;&#39318;&#36873;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#36125;&#21494;&#26031;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#21644;&#24314;&#27169;&#28789;&#27963;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#25361;&#25112;&#20063;&#24341;&#21457;&#20102;&#19968;&#31995;&#21015;&#25910;&#25947;&#24615;&#26356;&#26174;&#24471;&#19981;&#26126;&#26174;&#30340;&#22791;&#36873;&#26041;&#26696;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#24341;&#20986;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#26469;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#30340;&#25910;&#25947;&#24615;&#65292;&#20197;&#24212;&#29992;&#20110;&#38500;&#20102;GP&#30456;&#20851;&#26041;&#27861;&#20043;&#22806;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#30340;&#35774;&#35745;&#33258;&#30001;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#26469;&#26500;&#24314;&#32463;&#39564;&#19978;&#26356;&#20248;&#30340;&#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#31616;&#21333;&#30340;&#23616;&#37096;&#22238;&#24402;&#21644;&#19968;&#20010;&#36866;&#24212;&#38382;&#39064;&#29305;&#24615;&#30340;&#20195;&#29702;&#27169;&#22411;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-related methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a sui
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22343;&#21248;&#30340;$k$-dag&#24191;&#25773;&#27169;&#22411;&#65292;&#30830;&#23450;&#20102;&#19982;$p$&#21644;$k$&#26377;&#20851;&#30340;&#38408;&#20540;&#65292;&#24182;&#35752;&#35770;&#20102;&#22823;&#22810;&#25968;&#35268;&#21017;&#30340;&#35823;&#24046;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.01727</link><description>&lt;p&gt;
&#22312;&#38543;&#26426;&#36882;&#24402;&#26377;&#21521;&#26080;&#29615;&#22270;&#20013;&#30340;&#24191;&#25773;
&lt;/p&gt;
&lt;p&gt;
Broadcasting in random recursive dags. (arXiv:2306.01727v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01727
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22343;&#21248;&#30340;$k$-dag&#24191;&#25773;&#27169;&#22411;&#65292;&#30830;&#23450;&#20102;&#19982;$p$&#21644;$k$&#26377;&#20851;&#30340;&#38408;&#20540;&#65292;&#24182;&#35752;&#35770;&#20102;&#22823;&#22810;&#25968;&#35268;&#21017;&#30340;&#35823;&#24046;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#22343;&#21248;&#30340;$k$-dag&#36890;&#36807;&#20174;&#29616;&#26377;&#33410;&#28857;&#20013;&#22343;&#21248;&#38543;&#26426;&#36873;&#25321;$k$&#20010;&#29238;&#33410;&#28857;&#26469;&#25512;&#24191;&#22343;&#21248;&#30340;&#38543;&#26426;&#36882;&#24402;&#26641;&#12290;&#23427;&#20197;$k$&#20010;&#8220;&#26681;&#8221;&#24320;&#22987;&#12290;&#27599;&#20010;$k$&#20010;&#26681;&#33410;&#28857;&#37117;&#34987;&#20998;&#37197;&#19968;&#20010;&#20301;&#12290;&#36825;&#20123;&#20301;&#36890;&#36807;&#19968;&#20010;&#22024;&#26434;&#30340;&#20449;&#36947;&#20256;&#25773;&#12290;&#27599;&#20010;&#29238;&#33410;&#28857;&#30340;&#20301;&#37117;&#20197;&#27010;&#29575;$p$&#21457;&#29983;&#21464;&#21270;&#65292;&#24182;&#36827;&#34892;&#22823;&#22810;&#25968;&#34920;&#20915;&#12290;&#24403;&#25152;&#26377;&#33410;&#28857;&#37117;&#25509;&#25910;&#21040;&#23427;&#20204;&#30340;&#20301;&#21518;&#65292;$k$-dag&#34987;&#26174;&#31034;&#65292;&#19981;&#35782;&#21035;&#26681;&#33410;&#28857;&#12290;&#30446;&#26631;&#26159;&#20272;&#35745;&#25152;&#26377;&#26681;&#33410;&#28857;&#20013;&#30340;&#22823;&#22810;&#25968;&#20301;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;$p$&#30340;&#38408;&#20540;&#65292;&#20316;&#20026;&#19968;&#20010;&#20851;&#20110;$k$&#30340;&#20989;&#25968;&#65292;&#20351;&#24471;&#25152;&#26377;&#33410;&#28857;&#30340;&#22823;&#22810;&#25968;&#35268;&#21017;&#20135;&#29983;&#38169;&#35823;$c+o(1)$&#30340;&#27010;&#29575;&#23567;&#20110;$1/2$&#12290;&#22312;&#38408;&#20540;&#20197;&#19978;&#65292;&#22823;&#22810;&#25968;&#35268;&#21017;&#30340;&#38169;&#35823;&#27010;&#29575;&#20026;$1/2+o(1)$&#12290;
&lt;/p&gt;
&lt;p&gt;
A uniform $k$-{\sc dag} generalizes the uniform random recursive tree by picking $k$ parents uniformly at random from the existing nodes. It starts with $k$ ''roots''. Each of the $k$ roots is assigned a bit. These bits are propagated by a noisy channel. The parents' bits are flipped with probability $p$, and a majority vote is taken. When all nodes have received their bits, the $k$-{\sc dag} is shown without identifying the roots. The goal is to estimate the majority bit among the roots. We identify the threshold for $p$ as a function of $k$ below which the majority rule among all nodes yields an error $c+o(1)$ with $c&lt;1/2$. Above the threshold the majority rule errs with probability $1/2+o(1)$.
&lt;/p&gt;</description></item></channel></rss>