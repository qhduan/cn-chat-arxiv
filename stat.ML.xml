<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;</title><link>https://arxiv.org/abs/2403.07728</link><description>&lt;p&gt;
CAS: &#19968;&#31181;&#20855;&#26377;FCR&#25511;&#21046;&#30340;&#22312;&#32447;&#36873;&#25321;&#24615;&#31526;&#21512;&#39044;&#27979;&#30340;&#36890;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
CAS: A General Algorithm for Online Selective Conformal Prediction with FCR Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07728
&lt;/p&gt;
&lt;p&gt;
CAS&#26694;&#26550;&#20801;&#35768;&#22312;&#22312;&#32447;&#36873;&#25321;&#24615;&#39044;&#27979;&#20013;&#25511;&#21046;FCR&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#21644;&#26657;&#20934;&#38598;&#26500;&#36896;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#26041;&#24335;&#19979;&#21518;&#36873;&#25321;&#39044;&#27979;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#23558;&#36164;&#28304;&#32791;&#36153;&#22312;&#19981;&#37325;&#35201;&#30340;&#21333;&#20301;&#19978;&#65292;&#22312;&#25253;&#21578;&#20854;&#39044;&#27979;&#21306;&#38388;&#20043;&#21069;&#23545;&#24403;&#21069;&#20010;&#20307;&#36827;&#34892;&#21021;&#27493;&#36873;&#25321;&#22312;&#22312;&#32447;&#39044;&#27979;&#20219;&#21153;&#20013;&#26159;&#24120;&#35265;&#19988;&#26377;&#24847;&#20041;&#30340;&#12290;&#30001;&#20110;&#22312;&#32447;&#36873;&#25321;&#23548;&#33268;&#25152;&#36873;&#39044;&#27979;&#21306;&#38388;&#20013;&#23384;&#22312;&#26102;&#38388;&#22810;&#37325;&#24615;&#65292;&#22240;&#27492;&#25511;&#21046;&#23454;&#26102;&#35823;&#35206;&#30422;&#38472;&#36848;&#29575;&#65288;FCR&#65289;&#26469;&#27979;&#37327;&#24179;&#22343;&#35823;&#35206;&#30422;&#35823;&#24046;&#26159;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21517;&#20026;CAS&#65288;&#36866;&#24212;&#24615;&#36873;&#25321;&#21518;&#26657;&#20934;&#65289;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#21253;&#35065;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#21644;&#22312;&#32447;&#36873;&#25321;&#35268;&#21017;&#65292;&#20197;&#36755;&#20986;&#21518;&#36873;&#25321;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#22914;&#26524;&#36873;&#25321;&#20102;&#24403;&#21069;&#20010;&#20307;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#21382;&#21490;&#25968;&#25454;&#36827;&#34892;&#33258;&#36866;&#24212;&#36873;&#25321;&#26469;&#26500;&#24314;&#26657;&#20934;&#38598;&#65292;&#28982;&#21518;&#20026;&#26410;&#35266;&#23519;&#21040;&#30340;&#26631;&#31614;&#36755;&#20986;&#31526;&#21512;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#20026;&#26657;&#20934;&#38598;&#25552;&#20379;&#20102;&#21487;&#34892;&#30340;&#26500;&#36896;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07728v1 Announce Type: cross  Abstract: We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) to measure the averaged miscoverage error. We develop a general framework named CAS (Calibration after Adaptive Selection) that can wrap around any prediction model and online selection rule to output post-selection prediction intervals. If the current individual is selected, we first perform an adaptive selection on historical data to construct a calibration set, then output a conformal prediction interval for the unobserved label. We provide tractable constructions for the calibration set for 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;NetHack&#28216;&#25103;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#65292;&#21457;&#29616;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#21487;&#20197;&#25913;&#36827;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#24182;&#24314;&#31435;&#20102;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;IL&#20195;&#29702;&#20154;&#30340;&#24130;&#24459;&#12290;</title><link>http://arxiv.org/abs/2307.09423</link><description>&lt;p&gt;
&#22312;NetHack&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#30340;&#35268;&#27169;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;NetHack&#28216;&#25103;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#65292;&#21457;&#29616;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#21487;&#20197;&#25913;&#36827;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#24182;&#24314;&#31435;&#20102;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;IL&#20195;&#29702;&#20154;&#30340;&#24130;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#20223;&#23398;&#20064; (IL) &#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#24378;&#22823;&#65292;&#20294;&#35768;&#22810;&#30740;&#31350;&#21457;&#29616;&#23427;&#24448;&#24448;&#19981;&#33021;&#23436;&#20840;&#24674;&#22797;&#20986;&#28508;&#22312;&#30340;&#19987;&#23478;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#27809;&#26377;&#28145;&#20837;&#25506;&#31350;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#30340;&#25193;&#22823;&#22312;&#20854;&#20013;&#30340;&#20316;&#29992;&#12290;&#21463;&#26368;&#36817;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702; (NLP) &#39046;&#22495;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#22312;&#37027;&#37324;&#8220;&#25193;&#22823;&#35268;&#27169;&#8221;&#24050;&#32463;&#23548;&#33268;&#20102;&#36234;&#26469;&#36234;&#26377;&#33021;&#21147;&#30340;&#39046;&#22495;&#29305;&#23450;&#35821;&#35328;&#27169;&#22411; (LLMs)&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20180;&#32454;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#26159;&#21542;&#21487;&#20197;&#22312;&#27169;&#20223;&#23398;&#20064;&#30340;&#35774;&#32622;&#20013;&#24102;&#26469;&#31867;&#20284;&#30340;&#25913;&#36827;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312; NetHack &#28216;&#25103;&#19978;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#31243;&#24207;&#29983;&#25104;&#12289;&#38543;&#26426;&#24615;&#12289;&#38271;&#26399;&#20381;&#36182;&#24615;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29615;&#22659;&#12290;&#25105;&#20204;&#21457;&#29616; IL &#30340;&#25439;&#22833;&#21644;&#24179;&#22343;&#22238;&#25253;&#38543;&#30528;&#35745;&#31639;&#39044;&#31639;&#30340;&#21464;&#21270;&#32780;&#24179;&#28369;&#21464;&#21270;&#19988;&#24378;&#30456;&#20851;&#65292;&#20174;&#32780;&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#26679;&#26412;&#25968;&#37327;&#26041;&#38754;&#20026;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;&#30340; IL &#20195;&#29702;&#20154;&#30340;&#35745;&#31639;&#39044;&#31639;&#24314;&#31435;&#20102;&#24130;&#24459;&#12290;&#25105;&#20204;&#39044;&#27979;&#24182;&#35757;&#32451;&#20102;&#20960;&#20010;&#20855;&#26377; IL &#30340;NetHack&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where "scaling up" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL an
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#24182;&#19988;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#32473;&#20986;&#20272;&#35745;&#26631;&#31614;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#12290;&#24182;&#19988;&#65292;&#21333;&#27493;&#35889;&#31639;&#27861;&#21487;&#20197;&#22312;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#30340;&#26631;&#31614;&#12290;</title><link>http://arxiv.org/abs/2306.06845</link><description>&lt;p&gt;
&#23545;&#31216;&#20108;&#20803;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#19982;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Strong consistency and optimality of spectral clustering in symmetric binary non-uniform Hypergraph Stochastic Block Model. (arXiv:2306.06845v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06845
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#35889;&#32858;&#31867;&#30340;&#24378;&#19968;&#33268;&#24615;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#24182;&#19988;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#32473;&#20986;&#20272;&#35745;&#26631;&#31614;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#12290;&#24182;&#19988;&#65292;&#21333;&#27493;&#35889;&#31639;&#27861;&#21487;&#20197;&#22312;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#30340;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32771;&#34385;&#20102;&#22312;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#65292;&#20004;&#20010;&#31561;&#22823;&#23567;&#30340;&#31038;&#21306;&#65288;n/2&#65289;&#20013;&#30340;&#38543;&#26426;&#36229;&#22270;&#19978;&#30340;&#26080;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#36793;&#21482;&#20381;&#36182;&#20110;&#20854;&#39030;&#28857;&#30340;&#26631;&#31614;&#65292;&#36793;&#20197;&#19968;&#23450;&#27010;&#29575;&#29420;&#31435;&#20986;&#29616;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#24314;&#31435;&#20102;&#24378;&#19968;&#33268;&#24615;&#30340;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#65292;&#22312;&#35813;&#38408;&#20540;&#20197;&#19979;&#65292;&#20219;&#20309;&#31639;&#27861;&#37117;&#26377;&#24456;&#39640;&#27010;&#29575;&#20250;&#35823;&#20998;&#31867;&#33267;&#23569;&#20004;&#20010;&#39030;&#28857;&#65292;&#32780;&#29305;&#24449;&#21521;&#37327;&#20272;&#35745;&#37327;&#30340;&#26399;&#26395;&#8220;&#19981;&#21305;&#37197;&#29575;&#8221;&#19978;&#30028;&#20026;$n$&#30340;&#38408;&#20540;&#30340;&#36127;&#25351;&#25968;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#24403;&#36229;&#36807;&#35813;&#38408;&#20540;&#26102;&#65292;&#23613;&#31649;&#24352;&#37327;&#25910;&#32553;&#24341;&#36215;&#20102;&#20449;&#24687;&#25439;&#22833;&#65292;&#20294;&#21333;&#27493;&#35889;&#31639;&#27861;&#20165;&#22312;&#32473;&#23450;&#25910;&#32553;&#30340;&#37051;&#25509;&#30697;&#38453;&#26102;&#65292;&#21363;&#20351;SDP&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22833;&#36133;&#65292;&#20063;&#21487;&#20197;&#38750;&#24120;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#22320;&#32473;&#23450;&#27599;&#20010;&#39030;&#28857;&#20998;&#37197;&#26631;&#31614;&#12290;&#27492;&#22806;&#65292;&#24378;&#19968;&#33268;&#24615;&#21487;&#20197;&#36890;&#36807;&#23545;&#25152;&#26377;&#27425;&#20248;&#32858;&#21512;&#20449;&#24687;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the unsupervised classification problem in random hypergraphs under the non-uniform \emph{Hypergraph Stochastic Block Model} (HSBM) with two equal-sized communities ($n/2$), where each edge appears independently with some probability depending only on the labels of its vertices. In this paper, an \emph{information-theoretical} threshold for strong consistency is established. Below the threshold, every algorithm would misclassify at least two vertices with high probability, and the expected \emph{mismatch ratio} of the eigenvector estimator is upper bounded by $n$ to the power of minus the threshold. On the other hand, when above the threshold, despite the information loss induced by tensor contraction, one-stage spectral algorithms assign every vertex correctly with high probability when only given the contracted adjacency matrix, even if \emph{semidefinite programming} (SDP) fails in some scenarios. Moreover, strong consistency is achievable by aggregating information from al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#22522;&#32447;&#30340;&#26032;&#22411;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#39564;&#35777;&#22240;&#26524;&#22270;&#30340;&#27491;&#30830;&#24615;&#24182;&#25351;&#23548;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.09565</link><description>&lt;p&gt;
&#22522;&#20110;&#32622;&#25442;&#26816;&#39564;&#30340;&#22240;&#26524;&#22270;&#20551;&#35774;&#39564;&#35777;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Toward Falsifying Causal Graphs Using a Permutation-Based Test. (arXiv:2305.09565v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#22522;&#32447;&#30340;&#26032;&#22411;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#39564;&#35777;&#22240;&#26524;&#22270;&#30340;&#27491;&#30830;&#24615;&#24182;&#25351;&#23548;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31995;&#32479;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#23545;&#20110;&#35299;&#37322;&#21644;&#25511;&#21046;&#20854;&#34892;&#20026;&#33267;&#20851;&#37325;&#35201;&#12290;&#20294;&#26159;&#65292;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#22270;&#38656;&#35201;&#24456;&#22810;&#19981;&#24635;&#26159;&#29616;&#23454;&#30340;&#24378;&#20551;&#35774;&#12290;&#23545;&#20110;&#39046;&#22495;&#19987;&#23478;&#26469;&#35828;&#65292;&#24456;&#38590;&#34920;&#36798;&#22240;&#26524;&#22270;&#12290;&#22240;&#27492;&#65292;&#22312;&#23558;&#22240;&#26524;&#22270;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#20043;&#21069;&#65292;&#23450;&#37327;&#35780;&#20272;&#22240;&#26524;&#22270;&#30340;&#20248;&#21155;&#30340;&#24230;&#37327;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#26816;&#26597;&#12290;&#29616;&#26377;&#30340;&#24230;&#37327;&#25552;&#20379;&#20102;&#19968;&#20010;&#32477;&#23545;&#25968;&#37327;&#30340;&#22240;&#26524;&#22270;&#19982;&#35266;&#23519;&#25968;&#25454;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#32780;&#27809;&#26377;&#22522;&#30784;&#32447;&#65292;&#20174;&#19994;&#20154;&#21592;&#38656;&#35201;&#22238;&#31572;&#26377;&#22810;&#23569;&#36825;&#26679;&#30340;&#19981;&#19968;&#33268;&#24615;&#26159;&#21487;&#25509;&#21463;&#25110;&#39044;&#26399;&#30340;&#36825;&#19968;&#38590;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#30340;&#26367;&#20195;&#22522;&#32447;&#12290;&#36890;&#36807;&#23558;&#19981;&#19968;&#33268;&#24615;&#30340;&#25968;&#37327;&#19982;&#26367;&#20195;&#22522;&#32447;&#19978;&#30340;&#25968;&#37327;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#35299;&#37322;&#30340;&#24230;&#37327;&#65292;&#25429;&#25417;&#26377;&#21521;&#26080;&#29615;&#22270;&#26159;&#21542;&#26174;&#33879;&#36866;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the causal relationships among the variables of a system is paramount to explain and control its behaviour. Inferring the causal graph from observational data without interventions, however, requires a lot of strong assumptions that are not always realistic. Even for domain experts it can be challenging to express the causal graph. Therefore, metrics that quantitatively assess the goodness of a causal graph provide helpful checks before using it in downstream tasks. Existing metrics provide an absolute number of inconsistencies between the graph and the observed data, and without a baseline, practitioners are left to answer the hard question of how many such inconsistencies are acceptable or expected. Here, we propose a novel consistency metric by constructing a surrogate baseline through node permutations. By comparing the number of inconsistencies with those on the surrogate baseline, we derive an interpretable metric that captures whether the DAG fits significantly bet
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#25345;&#32493;&#21516;&#35843;&#25216;&#26415;&#22312;&#25429;&#25417;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#38271;&#31243;&#22270;&#24615;&#36136;&#26041;&#38754;&#34920;&#29616;&#20986;&#30340;&#39640;&#34920;&#36798;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.09826</link><description>&lt;p&gt;
&#25345;&#32493;&#21516;&#35843;&#22312;&#22270;&#23398;&#20064;&#20013;&#30340;&#34920;&#36798;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Expressivity of Persistent Homology in Graph Learning. (arXiv:2302.09826v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#25345;&#32493;&#21516;&#35843;&#25216;&#26415;&#22312;&#25429;&#25417;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#38271;&#31243;&#22270;&#24615;&#36136;&#26041;&#38754;&#34920;&#29616;&#20986;&#30340;&#39640;&#34920;&#36798;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#35745;&#31639;&#25299;&#25169;&#23398;&#20013;&#30340;&#19968;&#39033;&#25216;&#26415;&#65292;&#25345;&#32493;&#21516;&#35843;&#23637;&#29616;&#20986;&#22312;&#22270;&#20998;&#31867;&#26041;&#38754;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#23427;&#33021;&#22815;&#36890;&#36807;&#39640;&#38454;&#25299;&#25169;&#29305;&#24449;&#8212;&#8212;&#22914;&#20219;&#24847;&#38271;&#24230;&#30340;&#29615;&#8212;&#8212;&#20197;&#21450;&#22810;&#23610;&#24230;&#25299;&#25169;&#25551;&#36848;&#31526;&#25429;&#25417;&#38271;&#31243;&#22270;&#24615;&#36136;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#8212;&#8212;&#22914;&#20998;&#23376;&#8212;&#8212;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25345;&#32493;&#21516;&#35843;&#30340;&#29702;&#35770;&#24615;&#36136;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#23578;&#26410;&#24471;&#21040;&#27491;&#24335;&#35780;&#20272;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#25552;&#20379;&#25345;&#32493;&#21516;&#35843;&#22312;&#22270;&#20013;&#30340;&#31616;&#35201;&#20171;&#32461;&#20197;&#21450;&#23545;&#20854;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34920;&#36798;&#24615;&#36827;&#34892;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#24357;&#21512;&#35745;&#31639;&#25299;&#25169;&#23398;&#21644;&#22270;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology, a technique from computational topology, has recently shown strong empirical performance in the context of graph classification. Being able to capture long range graph properties via higher-order topological features, such as cycles of arbitrary length, in combination with multi-scale topological descriptors, has improved predictive performance for data sets with prominent topological structures, such as molecules. At the same time, the theoretical properties of persistent homology have not been formally assessed in this context. This paper intends to bridge the gap between computational topology and graph machine learning by providing a brief introduction to persistent homology in the context of graphs, as well as a theoretical discussion and empirical analysis of its expressivity for graph learning tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#22914;&#20309;&#26356;&#26032;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#26469;&#25351;&#23548;&#24178;&#39044;&#12290;&#20316;&#32773;&#25552;&#20986;&#20351;&#29992;&#30041;&#32622;&#38598;&#30340;&#26041;&#24335;&#36827;&#34892;&#26356;&#26032;&#65292;&#36890;&#36807;&#25214;&#21040;&#30041;&#32622;&#38598;&#30340;&#21512;&#36866;&#22823;&#23567;&#21487;&#20197;&#20445;&#35777;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#25968;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#24635;&#25104;&#26412;&#22686;&#38271;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2202.06374</link><description>&lt;p&gt;
&#38024;&#23545;&#39044;&#27979;&#27169;&#22411;&#26356;&#26032;&#30340;&#30041;&#32622;&#38598;
&lt;/p&gt;
&lt;p&gt;
Holdouts set for predictive model updating. (arXiv:2202.06374v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06374
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22797;&#26434;&#29615;&#22659;&#20013;&#22914;&#20309;&#26356;&#26032;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#26469;&#25351;&#23548;&#24178;&#39044;&#12290;&#20316;&#32773;&#25552;&#20986;&#20351;&#29992;&#30041;&#32622;&#38598;&#30340;&#26041;&#24335;&#36827;&#34892;&#26356;&#26032;&#65292;&#36890;&#36807;&#25214;&#21040;&#30041;&#32622;&#38598;&#30340;&#21512;&#36866;&#22823;&#23567;&#21487;&#20197;&#20445;&#35777;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#25968;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#24635;&#25104;&#26412;&#22686;&#38271;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22797;&#26434;&#30340;&#29615;&#22659;&#20013;&#65292;&#22914;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#65292;&#39044;&#27979;&#39118;&#38505;&#35780;&#20998;&#22312;&#25351;&#23548;&#24178;&#39044;&#26041;&#38754;&#36215;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#26356;&#26032;&#29992;&#20110;&#25351;&#23548;&#24178;&#39044;&#30340;&#39118;&#38505;&#35780;&#20998;&#21487;&#33021;&#23548;&#33268;&#20559;&#24046;&#39118;&#38505;&#20272;&#35745;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#8220;&#30041;&#32622;&#38598;&#8221;&#26469;&#36827;&#34892;&#26356;&#26032;-&#30041;&#32622;&#38598;&#26159;&#19968;&#20010;&#19981;&#25509;&#21463;&#39118;&#38505;&#35780;&#20998;&#25351;&#23548;&#24178;&#39044;&#30340;&#20154;&#32676;&#30340;&#23376;&#38598;&#12290;&#22312;&#30041;&#32622;&#38598;&#30340;&#22823;&#23567;&#19978;&#21462;&#24471;&#24179;&#34913;&#26159;&#20851;&#38190;&#65292;&#20197;&#30830;&#20445;&#26356;&#26032;&#21518;&#30340;&#39118;&#38505;&#35780;&#20998;&#24615;&#33021;&#33391;&#22909;&#65292;&#21516;&#26102;&#26368;&#22823;&#38480;&#24230;&#22320;&#20943;&#23569;&#30041;&#32622;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#20351;&#24471;&#24635;&#25104;&#26412;&#21487;&#20197;&#20197;$O\left(N^{2/3}\right)$&#30340;&#36895;&#24230;&#22686;&#38271;&#65292;&#20854;&#20013;$N$&#26159;&#20154;&#21475;&#35268;&#27169;&#65292;&#24182;&#19988;&#35748;&#20026;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#27809;&#26377;&#31454;&#20105;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#36890;&#36807;&#23450;&#20041;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20123;&#26465;&#20214;&#65292;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#30830;&#23450;&#26368;&#20339;&#30041;&#32622;&#38598;&#22823;&#23567;&#65288;OHS&#65289;&#65292;&#24182;&#24341;&#20837;&#21442;&#25968;&#21270;&#21644;&#21322;&#21442;&#25968;&#21270;&#31639;&#27861;&#26469;&#20272;&#35745;OHS&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#26368;&#26032;&#39118;&#38505;&#35780;&#20998;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In complex settings, such as healthcare, predictive risk scores play an increasingly crucial role in guiding interventions. However, directly updating risk scores used to guide intervention can lead to biased risk estimates. To address this, we propose updating using a `holdout set' - a subset of the population that does not receive interventions guided by the risk score. Striking a balance in the size of the holdout set is essential, to ensure good performance of the updated risk score whilst minimising the number of held out samples. We prove that this approach enables total costs to grow at a rate $O\left(N^{2/3}\right)$ for a population of size $N$, and argue that in general circumstances there is no competitive alternative. By defining an appropriate loss function, we describe conditions under which an optimal holdout size (OHS) can be readily identified, and introduce parametric and semi-parametric algorithms for OHS estimation, demonstrating their use on a recent risk score for 
&lt;/p&gt;</description></item></channel></rss>