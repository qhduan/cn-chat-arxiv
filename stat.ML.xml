<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01632</link><description>&lt;p&gt;
&#36229;&#36234;&#23610;&#24230;&#65306;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#26080;&#36951;&#25022;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01632
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#38656;&#35201;&#25311;&#21512;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#32780;&#25311;&#21512;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#38656;&#35201;&#25351;&#23450;&#36229;&#21442;&#25968; - &#22823;&#37096;&#20998;&#29702;&#35770;&#25991;&#29486;&#20551;&#35774;&#36825;&#20123;&#36229;&#21442;&#25968;&#26159;&#24050;&#30693;&#30340;&#12290;&#20043;&#21069;&#30340;&#29702;&#35770;&#30740;&#31350;&#36890;&#24120;&#20551;&#35774;&#25968;&#25454;&#22312;&#31354;&#38388;&#20013;&#22343;&#21248;&#22635;&#20805;&#65292;&#32780;&#24120;&#29992;&#30340;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#21482;&#26377;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25165;&#26159;&#19968;&#33268;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#25968;&#25454;&#19981;&#19968;&#23450;&#28385;&#36275;&#36825;&#31181;&#22343;&#21248;&#22635;&#20805;&#30340;&#26465;&#20214;&#12290;&#30001;&#20110;&#26080;&#27861;&#20445;&#35777;&#36229;&#21442;&#25968;&#20272;&#35745;&#30340;&#27491;&#30830;&#24615;&#65292;&#24182;&#19988;&#36825;&#20123;&#36229;&#21442;&#25968;&#21487;&#20197;&#26174;&#33879;&#24433;&#21709;&#39640;&#26031;&#36807;&#31243;&#25311;&#21512;&#65292;&#22240;&#27492;&#23545;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20043;&#21069;&#25552;&#20986;&#30340;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#30340;&#31639;&#27861;&#20165;&#33021;&#22788;&#29702;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#26410;&#30693;&#38271;&#24230;&#23610;&#24230;&#12289;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#33539;&#25968;&#65292;&#24182;&#19988;&#20165;&#36866;&#29992;&#20110;&#39057;&#29575;&#27966;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;HE-GP-UCB&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#30340;&#31639;&#27861;&#65292;&#22312;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimisation requires fitting a Gaussian process model, which in turn requires specifying hyperparameters - most of the theoretical literature assumes those hyperparameters are known. The commonly used maximum likelihood estimator for hyperparameters of the Gaussian process is consistent only if the data fills the space uniformly, which does not have to be the case in Bayesian optimisation. Since no guarantees exist regarding the correctness of hyperparameter estimation, and those hyperparameters can significantly affect the Gaussian process fit, theoretical analysis of Bayesian optimisation with unknown hyperparameters is very challenging. Previously proposed algorithms with the no-regret property were only able to handle the special case of unknown lengthscales, reproducing kernel Hilbert space norm and applied only to the frequentist case. We propose a novel algorithm, HE-GP-UCB, which is the first algorithm enjoying the no-regret property in the case of unknown hyperparame
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32570;&#22833;&#25968;&#25454;&#39044;&#27979;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#36866;&#24212;&#35266;&#27979;&#29305;&#24449;&#38598;&#65292;&#24182;&#23558;&#22635;&#20805;&#35268;&#21017;&#21644;&#22238;&#24402;&#27169;&#22411;&#21516;&#26102;&#23398;&#20064;&#65292;&#30456;&#27604;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#38750;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#24773;&#20917;&#19979;&#65292;&#26041;&#27861;&#23454;&#29616;&#20102;2-10%&#30340;&#20934;&#30830;&#24615;&#25913;&#36827;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01543</link><description>&lt;p&gt;
&#38024;&#23545;&#32570;&#22833;&#25968;&#25454;&#39044;&#27979;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Optimization for Prediction with Missing Data
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32570;&#22833;&#25968;&#25454;&#39044;&#27979;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#36866;&#24212;&#35266;&#27979;&#29305;&#24449;&#38598;&#65292;&#24182;&#23558;&#22635;&#20805;&#35268;&#21017;&#21644;&#22238;&#24402;&#27169;&#22411;&#21516;&#26102;&#23398;&#20064;&#65292;&#30456;&#27604;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#38750;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#24773;&#20917;&#19979;&#65292;&#26041;&#27861;&#23454;&#29616;&#20102;2-10%&#30340;&#20934;&#30830;&#24615;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#20855;&#26377;&#32570;&#22833;&#26465;&#30446;&#30340;&#39044;&#27979;&#27169;&#22411;&#26102;&#65292;&#26368;&#24120;&#29992;&#21644;&#22810;&#21151;&#33021;&#30340;&#26041;&#27861;&#26159;&#19968;&#31181;&#27969;&#27700;&#32447;&#25216;&#26415;&#65292;&#39318;&#20808;&#22635;&#20805;&#32570;&#22833;&#26465;&#30446;&#65292;&#28982;&#21518;&#35745;&#31639;&#39044;&#27979;&#32467;&#26524;&#12290;&#26412;&#25991;&#23558;&#32570;&#22833;&#25968;&#25454;&#39044;&#27979;&#35270;&#20026;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#31867;&#21035;&#65292;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#22238;&#24402;&#31995;&#25968;&#33021;&#22815;&#36866;&#24212;&#35266;&#27979;&#29305;&#24449;&#38598;&#12290;&#25105;&#20204;&#34920;&#26126;&#19968;&#20123;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#31561;&#21516;&#20110;&#21516;&#26102;&#23398;&#20064;&#22635;&#20805;&#35268;&#21017;&#21644;&#19979;&#28216;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#32780;&#19981;&#26159;&#39034;&#24207;&#23398;&#20064;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#32852;&#21512;&#22635;&#20805;-&#22238;&#24402;&#30340;&#35299;&#37322;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#27169;&#22411;&#12290;&#22312;&#25968;&#25454;&#38750;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26679;&#22806;&#20934;&#30830;&#24615;&#26041;&#38754;&#23454;&#29616;&#20102;2-10%&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
When training predictive models on data with missing entries, the most widely used and versatile approach is a pipeline technique where we first impute missing entries and then compute predictions. In this paper, we view prediction with missing data as a two-stage adaptive optimization problem and propose a new class of models, adaptive linear regression models, where the regression coefficients adapt to the set of observed features. We show that some adaptive linear regression models are equivalent to learning an imputation rule and a downstream linear regression model simultaneously instead of sequentially. We leverage this joint-impute-then-regress interpretation to generalize our framework to non-linear models. In settings where data is strongly not missing at random, our methods achieve a 2-10% improvement in out-of-sample accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23485;&#26494;&#20551;&#35774;&#19979;&#30340;&#38543;&#26426;&#20248;&#21270;&#20013;Adam&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20010;&#27169;&#22411;&#19979;&#65292;Adam&#31639;&#27861;&#21487;&#20197;&#20197;&#36739;&#39640;&#30340;&#27010;&#29575;&#39640;&#25928;&#22320;&#23547;&#25214;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;&#19982;&#20854;&#20182;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#30456;&#27604;&#65292;Adam&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#33258;&#36866;&#24212;&#24615;&#33021;&#65292;&#26080;&#38656;&#35843;&#25972;&#27493;&#38271;&#21644;&#38382;&#39064;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.03982</link><description>&lt;p&gt;
&#22312;&#23485;&#26494;&#20551;&#35774;&#19979;&#20851;&#20110;&#38543;&#26426;&#20248;&#21270;&#20013;Adam&#25910;&#25947;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Convergence of Adam for Stochastic Optimization under Relaxed Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23485;&#26494;&#20551;&#35774;&#19979;&#30340;&#38543;&#26426;&#20248;&#21270;&#20013;Adam&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20010;&#27169;&#22411;&#19979;&#65292;Adam&#31639;&#27861;&#21487;&#20197;&#20197;&#36739;&#39640;&#30340;&#27010;&#29575;&#39640;&#25928;&#22320;&#23547;&#25214;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;&#19982;&#20854;&#20182;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#30456;&#27604;&#65292;Adam&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#33258;&#36866;&#24212;&#24615;&#33021;&#65292;&#26080;&#38656;&#35843;&#25972;&#27493;&#38271;&#21644;&#38382;&#39064;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36866;&#24212;&#24615;&#21160;&#37327;&#35780;&#20272;&#65288;Adam&#65289;&#31639;&#27861;&#22312;&#35757;&#32451;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#22312;&#38750;&#20984;&#20809;&#28369;&#22330;&#26223;&#19979;&#65292;&#29305;&#21035;&#26159;&#22312;&#21487;&#33021;&#23384;&#22312;&#26080;&#30028;&#26799;&#24230;&#21644;&#20223;&#23556;&#26041;&#24046;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;Adam&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36825;&#20123;&#20855;&#26377;&#25361;&#25112;&#24615;&#26465;&#20214;&#19979;&#30340;&#26222;&#36890;Adam&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#25511;&#21046;&#30528;&#20223;&#23556;&#26041;&#24046;&#22122;&#22768;&#12289;&#26377;&#30028;&#22122;&#22768;&#21644;&#27425;&#39640;&#26031;&#22122;&#22768;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36825;&#20010;&#36890;&#29992;&#22122;&#22768;&#27169;&#22411;&#19979;&#65292;Adam&#31639;&#27861;&#21487;&#20197;&#20197;$\mathcal{O}(\text{poly}(\log T)/\sqrt{T})$&#30340;&#27010;&#29575;&#39640;&#25928;&#22320;&#23547;&#25214;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#65292;&#20854;&#20013;$T$&#34920;&#31034;&#24635;&#36845;&#20195;&#27425;&#25968;&#65292;&#19982;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#30340;&#26356;&#24213;&#25928;&#29575;&#30456;&#21305;&#37197;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#22312;&#30456;&#21516;&#26465;&#20214;&#19979;&#65292;Adam&#31639;&#27861;&#26080;&#38656;&#35843;&#25972;&#27493;&#38271;&#21644;&#20219;&#20309;&#38382;&#39064;&#21442;&#25968;&#65292;&#20855;&#26377;&#27604;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26356;&#22909;&#30340;&#33258;&#36866;&#24212;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Adaptive Momentum Estimation (Adam) algorithm is highly effective in training various deep learning tasks. Despite this, there's limited theoretical understanding for Adam, especially when focusing on its vanilla form in non-convex smooth scenarios with potential unbounded gradients and affine variance noise. In this paper, we study vanilla Adam under these challenging conditions. We introduce a comprehensive noise model which governs affine variance noise, bounded noise and sub-Gaussian noise. We show that Adam can find a stationary point with a $\mathcal{O}(\text{poly}(\log T)/\sqrt{T})$ rate in high probability under this general noise model where $T$ denotes total number iterations, matching the lower rate of stochastic first-order algorithms up to logarithm factors. More importantly, we reveal that Adam is free of tuning step-sizes with any problem-parameters, yielding a better adaptation property than the Stochastic Gradient Descent under the same conditions. We also provide 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#12290;&#23427;&#37319;&#29992;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#26469;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#20197;&#38477;&#20302;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#24341;&#36215;&#30340;&#20559;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.02306</link><description>&lt;p&gt;
&#24377;&#24615;&#36125;&#21494;&#26031;g&#24418;&#24335;&#22312;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A flexible Bayesian g-formula for causal survival analyses with time-dependent confounding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#12290;&#23427;&#37319;&#29992;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#26469;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#20197;&#38477;&#20302;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#24341;&#36215;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#26102;&#38388;&#33267;&#20107;&#20214;&#32467;&#26524;&#30340;&#32437;&#21521;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#65292;&#22240;&#26524;&#20998;&#26512;&#30340;&#24120;&#35265;&#30446;&#26631;&#26159;&#22312;&#30740;&#31350;&#32676;&#20307;&#20013;&#20272;&#35745;&#22312;&#20551;&#35774;&#24178;&#39044;&#24773;&#26223;&#19979;&#30340;&#22240;&#26524;&#29983;&#23384;&#26354;&#32447;&#12290;g&#24418;&#24335;&#26159;&#36825;&#31181;&#20998;&#26512;&#30340;&#19968;&#20010;&#29305;&#21035;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#20026;&#20102;&#22686;&#24378;&#20256;&#32479;&#30340;&#21442;&#25968;&#21270;g&#24418;&#24335;&#26041;&#27861;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#21516;&#26102;&#25903;&#25345;&#32437;&#21521;&#39044;&#27979;&#21644;&#22240;&#26524;&#25512;&#26029;&#12290;&#23427;&#22312;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#30340;&#24314;&#27169;&#20013;&#24341;&#20837;&#20102;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#65292;&#26088;&#22312;&#20943;&#36731;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#36896;&#25104;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#26356;&#36890;&#29992;&#30340;&#31163;&#25955;&#29983;&#23384;&#25968;&#25454;g&#24418;&#24335;&#12290;&#36825;&#20123;&#20844;&#24335;&#21487;&#20197;&#24341;&#20837;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#65292;&#36825;&#22312;&#22788;&#29702;&#36234;&#26469;&#36234;&#22810;&#30340;&#26102;&#21464;&#28151;&#26434;&#22240;&#32032;&#26102;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#38477;&#32500;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In longitudinal observational studies with a time-to-event outcome, a common objective in causal analysis is to estimate the causal survival curve under hypothetical intervention scenarios within the study cohort. The g-formula is a particularly useful tool for this analysis. To enhance the traditional parametric g-formula approach, we developed a more adaptable Bayesian g-formula estimator. This estimator facilitates both longitudinal predictive and causal inference. It incorporates Bayesian additive regression trees in the modeling of the time-evolving generative components, aiming to mitigate bias due to model misspecification. Specifically, we introduce a more general class of g-formulas for discrete survival data. These formulas can incorporate the longitudinal balancing scores, which serve as an effective method for dimension reduction and are vital when dealing with an expanding array of time-varying confounders. The minimum sufficient formulation of these longitudinal balancing
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#30340;&#31639;&#27861;&#31867;&#65292;&#29992;&#20110;&#24178;&#39044;&#33539;&#22260;&#20869;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#28085;&#30422;&#20102;&#32447;&#24615;&#21644;&#19968;&#33324;&#36716;&#21270;&#12290;&#31639;&#27861;&#20445;&#35777;&#20102;&#21487;&#35782;&#21035;&#24615;&#21644;&#23454;&#29616;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#21019;&#36896;&#24615;&#22320;&#23558;&#24471;&#20998;&#20989;&#25968;&#19982;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30456;&#32467;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.00849</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65306;&#32447;&#24615;&#21644;&#19968;&#33324;&#30340;&#36716;&#21270;
&lt;/p&gt;
&lt;p&gt;
Score-based Causal Representation Learning: Linear and General Transformations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00849
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#30340;&#31639;&#27861;&#31867;&#65292;&#29992;&#20110;&#24178;&#39044;&#33539;&#22260;&#20869;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#28085;&#30422;&#20102;&#32447;&#24615;&#21644;&#19968;&#33324;&#36716;&#21270;&#12290;&#31639;&#27861;&#20445;&#35777;&#20102;&#21487;&#35782;&#21035;&#24615;&#21644;&#23454;&#29616;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#21019;&#36896;&#24615;&#22320;&#23558;&#24471;&#20998;&#20989;&#25968;&#19982;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#38024;&#23545;&#19968;&#33324;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#21644;&#23558;&#28508;&#22312;&#21464;&#37327;&#26144;&#23556;&#21040;&#35266;&#27979;&#21464;&#37327;&#30340;&#26410;&#30693;&#36716;&#21270;&#65292;&#30740;&#31350;&#20102;&#22522;&#20110;&#24178;&#39044;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65288;CRL&#65289;&#12290;&#30740;&#31350;&#20102;&#32447;&#24615;&#21644;&#19968;&#33324;&#30340;&#36716;&#21270;&#12290;&#36825;&#31687;&#35770;&#25991;&#21516;&#26102;&#35752;&#35770;&#20102;&#21487;&#35782;&#21035;&#24615;&#21644;&#23454;&#29616;&#24615;&#20004;&#20010;&#26041;&#38754;&#12290;&#21487;&#35782;&#21035;&#24615;&#26159;&#25351;&#30830;&#23450;&#31639;&#27861;&#19981;&#30456;&#20851;&#30340;&#26465;&#20214;&#65292;&#20197;&#30830;&#20445;&#24674;&#22797;&#30495;&#23454;&#30340;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#21644;&#28508;&#22312;&#22240;&#26524;&#22270;&#12290;&#23454;&#29616;&#24615;&#26159;&#25351;&#31639;&#27861;&#26041;&#38754;&#65292;&#35299;&#20915;&#35774;&#35745;&#31639;&#27861;&#26469;&#23454;&#29616;&#21487;&#35782;&#21035;&#20445;&#35777;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#24471;&#20998;&#20989;&#25968;&#65288;&#21363;&#23494;&#24230;&#20989;&#25968;&#23545;&#25968;&#30340;&#26799;&#24230;&#65289;&#19982;CRL&#20043;&#38388;&#24314;&#31435;&#26032;&#32852;&#31995;&#65292;&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#24471;&#20998;&#20026;&#22522;&#30784;&#30340;&#31639;&#27861;&#31867;&#65292;&#30830;&#20445;&#20102;&#21487;&#35782;&#21035;&#24615;&#21644;&#23454;&#29616;&#24615;&#12290;&#39318;&#20808;&#65292;&#26412;&#25991;&#19987;&#27880;&#20110;&#32447;&#24615;&#36716;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#27599;&#20010;n&#20010;&#38543;&#26426;&#30828;&#24178;&#39044;&#19979;&#35813;&#36716;&#21270;&#30340;&#22240;&#26524;&#34920;&#31034;&#21487;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the \emph{identifiability} and \emph{achievability} aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between \emph{score functions} (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a \emph{score-based class of algorithms} that ensures both identifiability and achievability. First, the paper focuses on \emph{linear} transformations and shows that one stochastic hard intervention per n
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#65292;&#25105;&#20204;&#21487;&#20197;&#21033;&#29992;&#21152;&#26435;&#22240;&#26524;&#35268;&#21017;&#26469;&#20272;&#35745;&#21644;&#21152;&#24378;&#23545;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#30340;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.06746</link><description>&lt;p&gt;
&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#65306;&#36890;&#36807;&#21152;&#26435;&#22240;&#26524;&#35268;&#21017;&#22686;&#24378;&#23545;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Causal Rule Learning: Enhancing the Understanding of Heterogeneous Treatment Effect via Weighted Causal Rules. (arXiv:2310.06746v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06746
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#65292;&#25105;&#20204;&#21487;&#20197;&#21033;&#29992;&#21152;&#26435;&#22240;&#26524;&#35268;&#21017;&#26469;&#20272;&#35745;&#21644;&#21152;&#24378;&#23545;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#24615;&#26159;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#26102;&#30340;&#20851;&#38190;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21307;&#30103;&#24212;&#29992;&#26469;&#35828;&#65292;&#24120;&#24120;&#38656;&#35201;&#20570;&#20986;&#39640;&#39118;&#38505;&#20915;&#31574;&#12290;&#21463;&#21040;&#35299;&#37322;&#24615;&#30340;&#39044;&#27979;&#24615;&#12289;&#25551;&#36848;&#24615;&#12289;&#30456;&#20851;&#24615;&#26694;&#26550;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#25214;&#21040;&#25551;&#36848;&#28508;&#22312;&#23376;&#32676;&#30340;&#31934;&#32454;&#22240;&#26524;&#35268;&#21017;&#38598;&#26469;&#20272;&#35745;&#21644;&#22686;&#24378;&#25105;&#20204;&#23545;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#30340;&#29702;&#35299;&#12290;&#22240;&#26524;&#35268;&#21017;&#23398;&#20064;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65306;&#35268;&#21017;&#21457;&#29616;&#12289;&#35268;&#21017;&#36873;&#25321;&#21644;&#35268;&#21017;&#20998;&#26512;&#12290;&#22312;&#35268;&#21017;&#21457;&#29616;&#38454;&#27573;&#65292;&#25105;&#20204;&#21033;&#29992;&#22240;&#26524;&#26862;&#26519;&#29983;&#25104;&#19968;&#32452;&#20855;&#26377;&#30456;&#24212;&#23376;&#32676;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#22240;&#26524;&#35268;&#21017;&#27744;&#12290;&#36873;&#25321;&#38454;&#27573;&#20351;&#29992;D-&#23398;&#20064;&#26041;&#27861;&#20174;&#36825;&#20123;&#35268;&#21017;&#20013;&#36873;&#25321;&#23376;&#38598;&#65292;&#23558;&#20010;&#20307;&#27700;&#24179;&#30340;&#27835;&#30103;&#25928;&#24212;&#20316;&#20026;&#23376;&#32676;&#27700;&#24179;&#25928;&#24212;&#30340;&#32447;&#24615;&#32452;&#21512;&#36827;&#34892;&#35299;&#26500;&#12290;&#36825;&#26377;&#21161;&#20110;&#22238;&#31572;&#20043;&#21069;&#25991;&#29486;&#24573;&#35270;&#30340;&#38382;&#39064;&#65306;&#22914;&#26524;&#19968;&#20010;&#20010;&#20307;&#21516;&#26102;&#23646;&#20110;&#22810;&#20010;&#19981;&#21516;&#30340;&#27835;&#30103;&#23376;&#32676;&#65292;&#20250;&#24590;&#20040;&#26679;&#21602;&#65311;
&lt;/p&gt;
&lt;p&gt;
Interpretability is a key concern in estimating heterogeneous treatment effects using machine learning methods, especially for healthcare applications where high-stake decisions are often made. Inspired by the Predictive, Descriptive, Relevant framework of interpretability, we propose causal rule learning which finds a refined set of causal rules characterizing potential subgroups to estimate and enhance our understanding of heterogeneous treatment effects. Causal rule learning involves three phases: rule discovery, rule selection, and rule analysis. In the rule discovery phase, we utilize a causal forest to generate a pool of causal rules with corresponding subgroup average treatment effects. The selection phase then employs a D-learning method to select a subset of these rules to deconstruct individual-level treatment effects as a linear combination of the subgroup-level effects. This helps to answer an ignored question by previous literature: what if an individual simultaneously bel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;</title><link>http://arxiv.org/abs/2306.07566</link><description>&lt;p&gt;
&#23398;&#20064;&#36873;&#25321;&#26631;&#31614;&#19979;&#30340;&#24322;&#36136;&#20915;&#31574;&#32773;&#65306;&#19968;&#31181;&#24037;&#20855;&#21464;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning under Selective Labels with Heterogeneous Decision-makers: An Instrumental Variable Approach. (arXiv:2306.07566v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#36825;&#31181;&#38382;&#39064;&#22312;&#21382;&#21490;&#20915;&#31574;&#23548;&#33268;&#32467;&#26524;&#20165;&#37096;&#20998;&#26631;&#35760;&#26102;&#20986;&#29616;&#12290;&#26631;&#35760;&#25968;&#25454;&#20998;&#24067;&#21487;&#33021;&#19982;&#25972;&#20307;&#20154;&#32676;&#26377;&#26174;&#33879;&#24046;&#24322;&#65292;&#29305;&#21035;&#26159;&#24403;&#21382;&#21490;&#20915;&#31574;&#21644;&#30446;&#26631;&#32467;&#26524;&#21487;&#20197;&#21516;&#26102;&#21463;&#26576;&#20123;&#26410;&#35266;&#23519;&#21040;&#30340;&#22240;&#32032;&#24433;&#21709;&#26102;&#12290;&#22240;&#27492;&#65292;&#20165;&#22522;&#20110;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#21487;&#33021;&#20250;&#23548;&#33268;&#22312;&#25972;&#20307;&#20154;&#32676;&#20013;&#30340;&#20005;&#37325;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#35768;&#22810;&#24212;&#29992;&#20013;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#26469;&#35299;&#20915;&#27492;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#19979;&#20998;&#26512;&#20102;&#36825;&#31181;&#35774;&#32622;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#28385;&#36275;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#26102;&#20219;&#20309;&#32473;&#23450;&#39044;&#27979;&#35268;&#21017;&#30340;&#20840;&#20307;&#39118;&#38505;&#30340;&#28857;&#35782;&#21035;&#26465;&#20214;&#65292;&#24182;&#22312;&#28857;&#35782;&#21035;&#22833;&#36133;&#26102;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#39118;&#38505;&#30028;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning with selectively labeled data, which arises when outcomes are only partially labeled due to historical decision-making. The labeled data distribution may substantially differ from the full population, especially when the historical decisions and the target outcome can be simultaneously affected by some unobserved factors. Consequently, learning with only the labeled data may lead to severely biased results when deployed to the full population. Our paper tackles this challenge by exploiting the fact that in many applications the historical decisions were made by a set of heterogeneous decision-makers. In particular, we analyze this setup in a principled instrumental variable (IV) framework. We establish conditions for the full-population risk of any given prediction rule to be point-identified from the observed data and provide sharp risk bounds when the point identification fails. We further propose a weighted learning approach that learns prediction ru
&lt;/p&gt;</description></item></channel></rss>