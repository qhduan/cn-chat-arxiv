<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#23618;&#21098;&#26525;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#22823;&#37096;&#20998;&#23618;&#30340;&#31227;&#38500;&#32780;&#20445;&#25345;&#24615;&#33021;&#65292;&#21516;&#26102;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#21487;&#20197;&#36827;&#19968;&#27493;&#20943;&#23569;&#35745;&#31639;&#36164;&#28304;&#65292;&#25552;&#39640;&#25512;&#26029;&#30340;&#20869;&#23384;&#21644;&#24310;&#36831;&#12290;</title><link>https://arxiv.org/abs/2403.17887</link><description>&lt;p&gt;
&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#23618;&#21098;&#26525;&#30340;&#19981;&#21512;&#29702;&#26080;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Unreasonable Ineffectiveness of the Deeper Layers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17887
&lt;/p&gt;
&lt;p&gt;
&#23618;&#21098;&#26525;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#29616;&#22823;&#37096;&#20998;&#23618;&#30340;&#31227;&#38500;&#32780;&#20445;&#25345;&#24615;&#33021;&#65292;&#21516;&#26102;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#21487;&#20197;&#36827;&#19968;&#27493;&#20943;&#23569;&#35745;&#31639;&#36164;&#28304;&#65292;&#25552;&#39640;&#25512;&#26029;&#30340;&#20869;&#23384;&#21644;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#27969;&#34892;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#31616;&#21333;&#30340;&#23618;&#21098;&#26525;&#31574;&#30053;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#21457;&#29616;&#22312;&#31227;&#38500;&#22823;&#37096;&#20998;&#23618;&#65288;&#26368;&#39640;&#36798;&#19968;&#21322;&#65289;&#20043;&#21069;&#65292;&#19981;&#21516;&#38382;&#31572;&#22522;&#20934;&#27979;&#35797;&#30340;&#24615;&#33021;&#20960;&#20046;&#27809;&#26377;&#21463;&#21040;&#24433;&#21709;&#12290;&#20026;&#20102;&#21098;&#26525;&#36825;&#20123;&#27169;&#22411;&#65292;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#23618;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#30830;&#23450;&#26368;&#20339;&#30340;&#21098;&#26525;&#23618;&#22359;&#65307;&#28982;&#21518;&#65292;&#20026;&#20102;&#8220;&#20462;&#22797;&#8221;&#25439;&#23475;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23569;&#37327;&#24494;&#35843;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#65288;PEFT&#65289;&#26041;&#27861;&#65292;&#20855;&#20307;&#21253;&#25324;&#37327;&#21270;&#21644;&#20302;&#31209;&#36866;&#37197;&#22120;&#65288;QLoRA&#65289;&#65292;&#36825;&#26679;&#25105;&#20204;&#30340;&#27599;&#20010;&#23454;&#39564;&#37117;&#21487;&#20197;&#22312;&#21333;&#20010;A100 GPU&#19978;&#25191;&#34892;&#12290;&#20174;&#23454;&#38469;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#23618;&#21098;&#26525;&#26041;&#27861;&#21487;&#20197;&#34917;&#20805;&#20854;&#20182;PEFT&#31574;&#30053;&#65292;&#20174;&#32780;&#36827;&#19968;&#27493;&#20943;&#23569;&#24494;&#35843;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#21478;&#19968;&#26041;&#38754;&#21487;&#20197;&#25552;&#39640;&#25512;&#26029;&#30340;&#20869;&#23384;&#21644;&#24310;&#36831;&#12290;&#20174;&#31185;&#23398;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#35813;&#30740;&#31350;&#34920;&#26126;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#27169;&#22411;&#30340;&#21098;&#26525;&#27809;&#26377;&#22826;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17887v1 Announce Type: new  Abstract: We empirically study a simple layer-pruning strategy for popular families of open-weight pretrained LLMs, finding minimal degradation of performance on different question-answering benchmarks until after a large fraction (up to half) of the layers are removed. To prune these models, we identify the optimal block of layers to prune by considering similarity across layers; then, to "heal" the damage, we perform a small amount of finetuning. In particular, we use parameter-efficient finetuning (PEFT) methods, specifically quantization and Low Rank Adapters (QLoRA), such that each of our experiments can be performed on a single A100 GPU. From a practical perspective, these results suggest that layer pruning methods can complement other PEFT strategies to further reduce computational resources of finetuning on the one hand, and can improve the memory and latency of inference on the other hand. From a scientific perspective, the robustness of 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#19968;&#20010;&#29305;&#23450;&#30340;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#31361;&#20986;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#65292;&#21516;&#26102;&#20855;&#26377;&#24378;&#22823;&#29983;&#25104;&#22120;&#30340;&#29420;&#29305;&#35270;&#35282;&#12290;</title><link>https://arxiv.org/abs/2403.02957</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#28176;&#36817;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Asymptotic Mean Square Error Optimality of Diffusion Probabilistic Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#19968;&#20010;&#29305;&#23450;&#30340;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#31361;&#20986;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#65292;&#21516;&#26102;&#20855;&#26377;&#24378;&#22823;&#29983;&#25104;&#22120;&#30340;&#29420;&#29305;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPMs&#65289;&#22312;&#21435;&#22122;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;&#23613;&#31649;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24456;&#26377;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#29702;&#35299;&#23384;&#22312;&#26126;&#26174;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#29305;&#23450;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65288;CME&#65289;&#65292;&#20026;&#35813;&#39046;&#22495;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#35265;&#35299;&#12290;&#30740;&#31350;&#30340;&#22522;&#20110;DPM&#30340;&#21435;&#22122;&#22120;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#19982;DPMs&#20849;&#20139;&#65292;&#20294;&#22312;&#35757;&#32451;&#21518;&#30340;&#36870;&#25512;&#29702;&#36807;&#31243;&#20013;&#20165;&#20256;&#36882;&#26465;&#20214;&#22343;&#20540;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#30340;&#29420;&#29305;&#35270;&#35282;&#65292;&#21516;&#26102;&#36890;&#36807;&#22312;&#36870;&#36807;&#31243;&#20013;&#20999;&#25442;&#37325;&#26032;&#37319;&#26679;&#30340;&#26041;&#24335;&#32487;&#25215;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#29983;&#25104;&#22120;&#12290;&#36890;&#36807;&#25968;&#20540;&#32467;&#26524;&#39564;&#35777;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02957v1 Announce Type: new  Abstract: Diffusion probabilistic models (DPMs) have recently shown great potential for denoising tasks. Despite their practical utility, there is a notable gap in their theoretical understanding. This paper contributes novel theoretical insights by rigorously proving the asymptotic convergence of a specific DPM denoising strategy to the mean square error (MSE)-optimal conditional mean estimator (CME) over a large number of diffusion steps. The studied DPM-based denoiser shares the training procedure of DPMs but distinguishes itself by forwarding only the conditional mean during the reverse inference process after training. We highlight the unique perspective that DPMs are composed of an asymptotically optimal denoiser while simultaneously inheriting a powerful generator by switching re-sampling in the reverse process on and off. The theoretical findings are validated by numerical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;Koopman&#31639;&#23376;&#26694;&#26550;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;Nystro&#776;m&#36924;&#36817;&#23454;&#29616;&#20102;&#23545;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#26377;&#25928;&#25511;&#21046;&#65292;&#20854;&#29702;&#35770;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.02811</link><description>&lt;p&gt;
&#20855;&#26377;Koopman&#31639;&#23376;&#23398;&#20064;&#21644;Nystro&#776;m&#26041;&#27861;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#32447;&#24615;&#20108;&#27425;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Linear quadratic control of nonlinear systems with Koopman operator learning and the Nystr\"om method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;Koopman&#31639;&#23376;&#26694;&#26550;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;Nystro&#776;m&#36924;&#36817;&#23454;&#29616;&#20102;&#23545;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#26377;&#25928;&#25511;&#21046;&#65292;&#20854;&#29702;&#35770;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Koopman&#31639;&#23376;&#26694;&#26550;&#22914;&#20309;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#20197;&#26377;&#25928;&#25511;&#21046;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#12290;&#34429;&#28982;&#26680;&#26041;&#27861;&#36890;&#24120;&#20855;&#26377;&#24456;&#22823;&#30340;&#35745;&#31639;&#38656;&#27714;&#65292;&#20294;&#25105;&#20204;&#23637;&#31034;&#20102;&#38543;&#26426;&#23376;&#31354;&#38388;&#65288;Nystro&#776;m&#36924;&#36817;&#65289;&#22914;&#20309;&#23454;&#29616;&#24040;&#22823;&#30340;&#35745;&#31639;&#33410;&#32422;&#65292;&#21516;&#26102;&#20445;&#25345;&#31934;&#24230;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;&#20851;&#20110;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#30456;&#20851;&#35299;&#30340;&#36817;&#20284;Riccati&#31639;&#23376;&#21644;&#35843;&#33410;&#22120;&#30446;&#26631;&#37117;&#20197;$ m^{-1/2} $&#30340;&#36895;&#29575;&#25910;&#25947;&#65292;&#20854;&#20013;$ m $&#26159;&#38543;&#26426;&#23376;&#31354;&#38388;&#22823;&#23567;&#12290;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#25968;&#20540;&#23454;&#39564;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02811v1 Announce Type: cross  Abstract: In this paper, we study how the Koopman operator framework can be combined with kernel methods to effectively control nonlinear dynamical systems. While kernel methods have typically large computational requirements, we show how random subspaces (Nystr\"om approximation) can be used to achieve huge computational savings while preserving accuracy. Our main technical contribution is deriving theoretical guarantees on the effect of the Nystr\"om approximation. More precisely, we study the linear quadratic regulator problem, showing that both the approximated Riccati operator and the regulator objective, for the associated solution of the optimal control problem, converge at the rate $m^{-1/2}$, where $m$ is the random subspace size. Theoretical findings are complemented by numerical experiments corroborating our results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#38543;&#26426;&#36807;&#31243;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#26680;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#23454;&#29616;&#20102;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#65292;&#20197;&#21450;&#24320;&#21457;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#29992;&#20110;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;</title><link>https://arxiv.org/abs/2402.18477</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#31614;&#21517;&#26680;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#29992;&#20110;&#38543;&#26426;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18477
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#38543;&#26426;&#36807;&#31243;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#26680;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#23454;&#29616;&#20102;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#65292;&#20197;&#21450;&#24320;&#21457;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#29992;&#20110;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25512;&#26029;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#22312;&#31185;&#23398;&#12289;&#20581;&#24247;&#21644;&#37329;&#34701;&#31561;&#39046;&#22495;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#12290;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#31614;&#21517;&#26680;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#8220;&#36335;&#24452;&#31354;&#38388;&#8221;&#19978;&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;CI&#65289;&#27979;&#35797;&#65292;&#29992;&#20110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#36739;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#36335;&#24452;&#31354;&#38388;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;CI&#27979;&#35797;&#34920;&#29616;&#20986;&#20005;&#26684;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;&#38750;&#24490;&#29615;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#24320;&#21457;&#20102;&#22522;&#20110;&#32422;&#26463;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#65292;&#21033;&#29992;&#26102;&#38388;&#20449;&#24687;&#26469;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;&#22312;&#20551;&#35774;&#24544;&#23454;&#24615;&#21644;CI&#39044;&#35328;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23436;&#22791;&#19988;&#27491;&#30830;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18477v1 Announce Type: cross  Abstract: Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via "which variables enter the differential of which other variables". In this paper, we develop a kernel-based test of conditional independence (CI) on "path-space" -- solutions to SDEs -- by leveraging recent advances in signature kernels. We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space. Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph. Assuming faithfulness and a CI oracle, our algorithm is sound and complete. We empirical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CP-E2LSH&#21644;TT-E2LSH&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;LSH&#65292;&#22312;&#22788;&#29702;&#24352;&#37327;&#25968;&#25454;&#30340;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#21644;&#20313;&#24358;&#30456;&#20284;&#24230;&#26102;&#33021;&#22815;&#25552;&#20379;&#26356;&#24555;&#21644;&#26356;&#31354;&#38388;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.07189</link><description>&lt;p&gt;
&#36890;&#36807;&#24352;&#37327;&#21270;&#38543;&#26426;&#25237;&#24433;&#25913;&#36827;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;LSH
&lt;/p&gt;
&lt;p&gt;
Improving LSH via Tensorized Random Projection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CP-E2LSH&#21644;TT-E2LSH&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#31639;&#27861;LSH&#65292;&#22312;&#22788;&#29702;&#24352;&#37327;&#25968;&#25454;&#30340;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#21644;&#20313;&#24358;&#30456;&#20284;&#24230;&#26102;&#33021;&#22815;&#25552;&#20379;&#26356;&#24555;&#21644;&#26356;&#31354;&#38388;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;(LSH)&#26159;&#25968;&#25454;&#31185;&#23398;&#23478;&#29992;&#20110;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#38382;&#39064;&#30340;&#22522;&#26412;&#31639;&#27861;&#24037;&#20855;&#65292;&#24050;&#22312;&#35768;&#22810;&#22823;&#35268;&#27169;&#25968;&#25454;&#22788;&#29702;&#24212;&#29992;&#20013;&#24191;&#27867;&#20351;&#29992;&#65292;&#22914;&#36817;&#20284;&#37325;&#22797;&#26816;&#27979;&#12289;&#26368;&#36817;&#37051;&#25628;&#32034;&#12289;&#32858;&#31867;&#31561;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25552;&#20986;&#26356;&#24555;&#21644;&#31354;&#38388;&#26356;&#26377;&#25928;&#30340;&#23616;&#37096;&#25935;&#24863;&#21704;&#24076;&#20989;&#25968;&#65292;&#29992;&#20110;&#24352;&#37327;&#25968;&#25454;&#30340;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#21644;&#20313;&#24358;&#30456;&#20284;&#24230;&#12290;&#36890;&#24120;&#65292;&#23545;&#20110;&#24352;&#37327;&#25968;&#25454;&#33719;&#24471;LSH&#30340;&#26420;&#32032;&#26041;&#27861;&#28041;&#21450;&#23558;&#24352;&#37327;&#37325;&#22609;&#20026;&#21521;&#37327;&#65292;&#28982;&#21518;&#24212;&#29992;&#29616;&#26377;&#30340;&#21521;&#37327;&#25968;&#25454;LSH&#26041;&#27861;(E2LSH&#21644;SRP)&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#38454;&#24352;&#37327;&#65292;&#36825;&#31181;&#26041;&#27861;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#65292;&#22240;&#20026;&#37325;&#22609;&#21521;&#37327;&#30340;&#22823;&#23567;&#22312;&#24352;&#37327;&#30340;&#38454;&#25968;&#20013;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#22240;&#27492;&#65292;LSH&#21442;&#25968;&#30340;&#22823;&#23567;&#21576;&#25351;&#25968;&#22686;&#21152;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#21644;&#20313;&#24358;&#30456;&#20284;&#24230;&#30340;LSH&#26041;&#27861;&#65292;&#20998;&#21035;&#26159;CP-E2LSH&#21644;TT-E2LSH&#12290;
&lt;/p&gt;
&lt;p&gt;
Locality sensitive hashing (LSH) is a fundamental algorithmic toolkit used by data scientists for approximate nearest neighbour search problems that have been used extensively in many large scale data processing applications such as near duplicate detection, nearest neighbour search, clustering, etc. In this work, we aim to propose faster and space efficient locality sensitive hash functions for Euclidean distance and cosine similarity for tensor data. Typically, the naive approach for obtaining LSH for tensor data involves first reshaping the tensor into vectors, followed by applying existing LSH methods for vector data $E2LSH$ and $SRP$. However, this approach becomes impractical for higher order tensors because the size of the reshaped vector becomes exponential in the order of the tensor. Consequently, the size of LSH parameters increases exponentially. To address this problem, we suggest two methods for LSH for Euclidean distance and cosine similarity, namely $CP-E2LSH$, $TT-E2LSH
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(WCE-GNN)&#23454;&#29616;&#20102;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;WCE-GNN&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.05569</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Hypergraph Node Classification With Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(WCE-GNN)&#23454;&#29616;&#20102;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;WCE-GNN&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#26159;&#29992;&#26469;&#27169;&#25311;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#20851;&#38190;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#25104;&#21151;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#20855;&#26377;&#25104;&#23545;&#20132;&#20114;&#30340;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#36825;&#28608;&#21457;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#20855;&#26377;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#25968;&#25454;&#30340;&#24819;&#27861;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;HyperGNNs&#65289;&#30340;&#21457;&#23637;&#12290;GNNs&#21644;HyperGNNs&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19981;&#21516;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#34987;&#35774;&#35745;&#29992;&#20110;&#22788;&#29702;&#19981;&#21516;&#20960;&#20309;&#25299;&#25169;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#22312;&#33410;&#28857;&#20998;&#31867;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#22823;&#22810;&#25968;HyperGNNs&#21487;&#20197;&#20351;&#29992;&#24102;&#26377;&#36229;&#22270;&#30340;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;GNN&#26469;&#36817;&#20284;&#12290;&#36825;&#23548;&#33268;&#20102;WCE-GNN&#65292;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#19968;&#20010;GNN&#21644;&#19968;&#20010;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#65288;WCE&#65289;&#65292;&#29992;&#20110;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23545;&#20110;&#20061;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;WCE-GNN&#19981;&#20165;&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#65292;&#32780;&#19988;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs, with hyperedges connecting more than two nodes, are key for modelling higher-order interactions in real-world data. The success of graph neural networks (GNNs) reveals the capability of neural networks to process data with pairwise interactions. This inspires the usage of neural networks for data with higher-order interactions, thereby leading to the development of hypergraph neural networks (HyperGNNs). GNNs and HyperGNNs are typically considered distinct since they are designed for data on different geometric topologies. However, in this paper, we theoretically demonstrate that, in the context of node classification, most HyperGNNs can be approximated using a GNN with a weighted clique expansion of the hypergraph. This leads to WCE-GNN, a simple and efficient framework comprising a GNN and a weighted clique expansion (WCE), for hypergraph node classification. Experiments on nine real-world hypergraph node classification benchmarks showcase that WCE-GNN demonstrates not o
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#23454;&#29616;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#12290;</title><link>https://arxiv.org/abs/2311.15487</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15487
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#23454;&#29616;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#29992;&#20110;&#26368;&#23567;&#21270;$\mathcal{L}^2$&#20195;&#20215;&#20989;&#25968;&#30340;&#26799;&#24230;&#19979;&#38477;&#27969;&#65292;&#24182;&#24341;&#20837;&#20004;&#20010;&#25913;&#36827;&#29256;&#26412;&#65307;&#19968;&#20010;&#36866;&#29992;&#20110;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#65292;&#21478;&#19968;&#20010;&#36866;&#29992;&#20110;&#27424;&#21442;&#25968;&#21270;&#35774;&#32622;&#12290;&#36825;&#20004;&#20010;&#29256;&#26412;&#37117;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#65292;&#32771;&#34385;&#21040;&#22312;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#30340;&#25289;&#22238;&#21521;&#37327;&#19995;&#32467;&#26500;&#21644;&#22312;&#27424;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#30340;&#25512;&#21069;&#21521;&#37327;&#19995;&#32467;&#26500;&#12290;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#28385;&#36275;&#31209;&#26465;&#20214;&#65292;&#25913;&#36827;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#25152;&#26377;&#36712;&#36947;&#23558;&#20197;&#22343;&#21248;&#25351;&#25968;&#25910;&#25947;&#36895;&#29575;&#23558;$\mathcal{L}^2$&#20195;&#20215;&#39537;&#21160;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#65307;&#22240;&#27492;&#65292;&#23545;&#20110;&#20219;&#20309;&#39044;&#20808;&#25351;&#23450;&#30340;&#25509;&#36817;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#36817;&#20284;&#65292;&#25105;&#20204;&#21487;&#20197;&#24471;&#21040;&#20808;&#39564;&#20572;&#27490;&#26102;&#38388;&#12290;&#25105;&#20204;&#25351;&#20986;&#21518;&#32773;&#19982;&#27425;Riemann&#20960;&#20309;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.15487v3 Announce Type: replace-cross  Abstract: We consider the gradient descent flow widely used for the minimization of the $\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two modified versions; one adapted for the overparametrized setting, and the other for the underparametrized setting. Both have a clear and natural invariant geometric meaning, taking into account the pullback vector bundle structure in the overparametrized, and the pushforward vector bundle structure in the underparametrized setting. In the overparametrized case, we prove that, provided that a rank condition holds, all orbits of the modified gradient descent drive the $\mathcal{L}^2$ cost to its global minimum at a uniform exponential convergence rate; one thereby obtains an a priori stopping time for any prescribed proximity to the global minimum. We point out relations of the latter to sub-Riemannian geometry.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#35777;&#26126;&#24403;&#30495;&#23454;&#21442;&#25968;&#20026;0&#26102;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#22312;&#35813;&#25200;&#21160;&#19979;&#30340;&#26497;&#38480;&#20998;&#24067;&#21487;&#33021;&#22312;0&#22788;&#26377;&#19968;&#20010;&#27491;&#27010;&#29575;&#36136;&#37327;&#65292;&#25552;&#20379;&#20102;&#31232;&#30095;&#24615;&#24674;&#22797;&#33021;&#21147;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#36807;&#31243;&#8212;&#8212;&#33258;&#36866;&#24212;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.15262</link><description>&lt;p&gt;
&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Behavior of Adversarial Training Estimator under $\ell_\infty$-Perturbation. (arXiv:2401.15262v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#35777;&#26126;&#24403;&#30495;&#23454;&#21442;&#25968;&#20026;0&#26102;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#22312;&#35813;&#25200;&#21160;&#19979;&#30340;&#26497;&#38480;&#20998;&#24067;&#21487;&#33021;&#22312;0&#22788;&#26377;&#19968;&#20010;&#27491;&#27010;&#29575;&#36136;&#37327;&#65292;&#25552;&#20379;&#20102;&#31232;&#30095;&#24615;&#24674;&#22797;&#33021;&#21147;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#36807;&#31243;&#8212;&#8212;&#33258;&#36866;&#24212;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#35757;&#32451;&#34987;&#25552;&#20986;&#26469;&#25269;&#24481;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#36825;&#20010;&#38382;&#39064;&#26368;&#36817;&#24341;&#36215;&#20102;&#24456;&#22810;&#30740;&#31350;&#30340;&#20851;&#27880;&#12290;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#34892;&#20026;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#30495;&#23454;&#21442;&#25968;&#20026;0&#26102;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#26497;&#38480;&#20998;&#24067;&#21487;&#33021;&#22312;0&#22788;&#26377;&#19968;&#20010;&#27491;&#27010;&#29575;&#36136;&#37327;&#65292;&#20026;&#30456;&#20851;&#30340;&#31232;&#30095;&#24615;&#24674;&#22797;&#33021;&#21147;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#36807;&#31243;&#8212;&#8212;&#33258;&#36866;&#24212;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25152;&#25552;&#20986;&#30340;&#36807;&#31243;&#21487;&#20197;&#23454;&#29616;&#28176;&#36817;&#26080;&#20559;&#24615;&#21644;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#31232;&#30095;&#24615;&#24674;&#22797;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under $\ell_\infty$-perturbation, which has recently attracted much research attention. The asymptotic behavior of the adversarial training estimator is investigated in the generalized linear model. The results imply that the limiting distribution of the adversarial training estimator under $\ell_\infty$-perturbation could put a positive probability mass at $0$ when the true parameter is $0$, providing a theoretical guarantee of the associated sparsity-recovery ability. Alternatively, a two-step procedure is proposed -adaptive adversarial training, which could further improve the performance of adversarial training under $\ell_\infty$-perturbation. Specifically, the proposed procedure could achieve asymptotic unbiasedness and variable-selection consistency. Numerical experiments are conducted to show the sparsity-recovery a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#26694;&#26550;&#65288;ScoreAG&#65289;&#65292;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#24182;&#36890;&#36807;&#22270;&#20687;&#36716;&#25442;&#25110;&#26032;&#22270;&#20687;&#21512;&#25104;&#30340;&#26041;&#27861;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.04285</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#22270;&#20687;&#29983;&#25104;&#35780;&#20272;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing Robustness via Score-Based Adversarial Image Generation. (arXiv:2310.04285v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#26694;&#26550;&#65288;ScoreAG&#65289;&#65292;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#24182;&#36890;&#36807;&#22270;&#20687;&#36716;&#25442;&#25110;&#26032;&#22270;&#20687;&#21512;&#25104;&#30340;&#26041;&#27861;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#23545;&#25239;&#25915;&#20987;&#21644;&#38450;&#24481;&#37117;&#38598;&#20013;&#22312;&#23567;&#30340;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#20869;&#30340;&#25200;&#21160;&#19978;&#12290;&#28982;&#32780;&#65292;$\ell_p$&#23041;&#32961;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#21040;&#25152;&#26377;&#30456;&#20851;&#30340;&#20445;&#30041;&#35821;&#20041;&#30340;&#25200;&#21160;&#65292;&#22240;&#27492;&#65292;&#40065;&#26834;&#24615;&#35780;&#20272;&#30340;&#33539;&#22260;&#26159;&#26377;&#38480;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#65288;ScoreAG&#65289;&#65292;&#19968;&#31181;&#21033;&#29992;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#36827;&#23637;&#26469;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#26080;&#38480;&#21046;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#20811;&#26381;&#20102;&#23427;&#20204;&#30340;&#23616;&#38480;&#24615;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;ScoreAG&#22312;&#29983;&#25104;&#36924;&#30495;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#26102;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#21487;&#20197;&#36890;&#36807;&#36716;&#25442;&#29616;&#26377;&#22270;&#20687;&#25110;&#23436;&#20840;&#20174;&#38646;&#24320;&#22987;&#21512;&#25104;&#26032;&#22270;&#20687;&#30340;&#26041;&#24335;&#23454;&#29616;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21033;&#29992;ScoreAG&#30340;&#29983;&#25104;&#33021;&#21147;&#26469;&#20928;&#21270;&#22270;&#20687;&#65292;&#20174;&#32463;&#39564;&#19978;&#22686;&#24378;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;ScoreAG&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#30340;&#24615;&#33021;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most adversarial attacks and defenses focus on perturbations within small $\ell_p$-norm constraints. However, $\ell_p$ threat models cannot capture all relevant semantic-preserving perturbations, and hence, the scope of robustness evaluations is limited. In this work, we introduce Score-Based Adversarial Generation (ScoreAG), a novel framework that leverages the advancements in score-based generative models to generate adversarial examples beyond $\ell_p$-norm constraints, so-called unrestricted adversarial examples, overcoming their limitations. Unlike traditional methods, ScoreAG maintains the core semantics of images while generating realistic adversarial examples, either by transforming existing images or synthesizing new ones entirely from scratch. We further exploit the generative capability of ScoreAG to purify images, empirically enhancing the robustness of classifiers. Our extensive empirical evaluation demonstrates that ScoreAG matches the performance of state-of-the-art atta
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#40065;&#26834;&#31574;&#30053;&#35780;&#20272;&#30340;&#22312;&#32447;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#35299;&#20915;&#24322;&#24120;&#20540;&#27745;&#26579;&#21644;&#37325;&#23614;&#22870;&#21169;&#30340;&#38382;&#39064;&#26041;&#38754;&#24341;&#20837;&#20102;&#40065;&#26834;&#32479;&#35745;&#23398;&#30340;&#27010;&#24565;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#22312;&#32447;&#30340;&#32479;&#35745;&#25512;&#26029;&#36807;&#31243;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#37327;&#30340;&#26497;&#38480;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2310.02581</link><description>&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#40065;&#26834;&#31574;&#30053;&#35780;&#20272;&#30340;&#22312;&#32447;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Online Estimation and Inference for Robust Policy Evaluation in Reinforcement Learning. (arXiv:2310.02581v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02581
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#40065;&#26834;&#31574;&#30053;&#35780;&#20272;&#30340;&#22312;&#32447;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#35299;&#20915;&#24322;&#24120;&#20540;&#27745;&#26579;&#21644;&#37325;&#23614;&#22870;&#21169;&#30340;&#38382;&#39064;&#26041;&#38754;&#24341;&#20837;&#20102;&#40065;&#26834;&#32479;&#35745;&#23398;&#30340;&#27010;&#24565;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#22312;&#32447;&#30340;&#32479;&#35745;&#25512;&#26029;&#36807;&#31243;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#37327;&#30340;&#26497;&#38480;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#24378;&#21270;&#23398;&#20064;&#22312;&#29616;&#20195;&#32479;&#35745;&#23398;&#20013;&#22791;&#21463;&#20851;&#27880;&#65292;&#31574;&#30053;&#35780;&#20272;&#26159;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#19982;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#19978;&#23545;&#35813;&#20027;&#39064;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#35745;&#31639;&#30340;&#21442;&#25968;&#20272;&#35745;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#23613;&#31649;&#22823;&#22810;&#25968;&#29616;&#26377;&#20998;&#26512;&#20551;&#35774;&#38543;&#26426;&#22870;&#21169;&#36981;&#24490;&#26631;&#20934;&#20998;&#24067;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#65292;&#20294;&#25105;&#20204;&#22312;&#32479;&#19968;&#26694;&#26550;&#20013;&#21516;&#26102;&#35299;&#20915;&#20102;&#24322;&#24120;&#20540;&#27745;&#26579;&#21644;&#37325;&#23614;&#22870;&#21169;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#25317;&#25265;&#20102;&#40065;&#26834;&#32479;&#35745;&#23398;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27010;&#24565;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#40065;&#26834;&#31574;&#30053;&#35780;&#20272;&#36807;&#31243;&#65292;&#24182;&#26681;&#25454;&#20854;Bahadur&#34920;&#31034;&#24314;&#31435;&#20102;&#25105;&#20204;&#20272;&#35745;&#37327;&#30340;&#26497;&#38480;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#23436;&#20840;&#22312;&#32447;&#30340;&#36807;&#31243;&#65292;&#20197;&#39640;&#25928;&#22320;&#36827;&#34892;&#22522;&#20110;&#28176;&#36817;&#20998;&#24067;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#36825;&#31687;&#35770;&#25991;&#22635;&#34917;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#40065;&#26834;&#32479;&#35745;&#23398;&#21644;&#32479;&#35745;&#25512;&#26029;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, reinforcement learning has gained prominence in modern statistics, with policy evaluation being a key component. Unlike traditional machine learning literature on this topic, our work places emphasis on statistical inference for the parameter estimates computed using reinforcement learning algorithms. While most existing analyses assume random rewards to follow standard distributions, limiting their applicability, we embrace the concept of robust statistics in reinforcement learning by simultaneously addressing issues of outlier contamination and heavy-tailed rewards within a unified framework. In this paper, we develop an online robust policy evaluation procedure, and establish the limiting distribution of our estimator, based on its Bahadur representation. Furthermore, we develop a fully-online procedure to efficiently conduct statistical inference based on the asymptotic distribution. This paper bridges the gap between robust statistics and statistical inference in reinfor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.14872</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#24179;&#34913;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#20960;&#20309;&#24863;&#30693;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14872
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21463;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#34920;&#29616;&#33391;&#22909;&#30340;&#23454;&#35777;&#24615;&#33021;&#19982;&#24754;&#35266;&#29702;&#35770;&#21518;&#24724;&#30028;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#21551;&#21457;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#21253;&#25324;&#36138;&#24515;&#12289;OFUL&#21644;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#22312;&#20869;&#30340;&#24191;&#27867;&#31639;&#27861;&#31867;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#22312;&#20445;&#30041;&#22522;&#26412;&#31639;&#27861;&#22823;&#37096;&#20998;&#20248;&#33391;&#29305;&#24615;&#30340;&#21516;&#26102;&#8220;&#26657;&#27491;&#8221;&#22522;&#26412;&#31639;&#27861;&#22312;&#26576;&#20123;&#23454;&#20363;&#20013;&#34920;&#29616;&#24046;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#28176;&#36817;&#26368;&#20248;&#21518;&#24724;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26641;&#29983;&#38271;&#35268;&#21017;&#65292;&#20351;&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#22312;&#26080;&#26799;&#24230;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#22823;&#22823;&#33410;&#30465;&#20102;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2306.11908</link><description>&lt;p&gt;
&#22522;&#20110;&#23450;&#28857;&#26641;&#30340;&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Accelerating Generalized Random Forests with Fixed-Point Trees. (arXiv:2306.11908v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11908
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26641;&#29983;&#38271;&#35268;&#21017;&#65292;&#20351;&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#22312;&#26080;&#26799;&#24230;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#22823;&#22823;&#33410;&#30465;&#20102;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#24314;&#31435;&#22312;&#20256;&#32479;&#38543;&#26426;&#26862;&#26519;&#30340;&#22522;&#30784;&#19978;&#65292;&#36890;&#36807;&#23558;&#20854;&#20316;&#20026;&#33258;&#36866;&#24212;&#26680;&#21152;&#26435;&#31639;&#27861;&#26469;&#26500;&#24314;&#20272;&#31639;&#22120;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#26799;&#24230;&#30340;&#26641;&#29983;&#38271;&#36807;&#31243;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#29983;&#38271;&#35268;&#21017;&#65292;&#22522;&#20110;&#23450;&#28857;&#36845;&#20195;&#36817;&#20284;&#34920;&#31034;&#26799;&#24230;&#36817;&#20284;&#65292;&#23454;&#29616;&#20102;&#26080;&#26799;&#24230;&#20248;&#21270;&#65292;&#24182;&#20026;&#27492;&#24320;&#21457;&#20102;&#28176;&#36817;&#29702;&#35770;&#12290;&#36825;&#26377;&#25928;&#22320;&#33410;&#30465;&#20102;&#26102;&#38388;&#65292;&#23588;&#20854;&#26159;&#22312;&#30446;&#26631;&#37327;&#30340;&#32500;&#24230;&#36866;&#20013;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized random forests arXiv:1610.01271 build upon the well-established success of conventional forests (Breiman, 2001) to offer a flexible and powerful non-parametric method for estimating local solutions of heterogeneous estimating equations. Estimators are constructed by leveraging random forests as an adaptive kernel weighting algorithm and implemented through a gradient-based tree-growing procedure. By expressing this gradient-based approximation as being induced from a single Newton-Raphson root-finding iteration, and drawing upon the connection between estimating equations and fixed-point problems arXiv:2110.11074, we propose a new tree-growing rule for generalized random forests induced from a fixed-point iteration type of approximation, enabling gradient-free optimization, and yielding substantial time savings for tasks involving even modest dimensionality of the target quantity (e.g. multiple/multi-level treatment effects). We develop an asymptotic theory for estimators o
&lt;/p&gt;</description></item></channel></rss>