<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#19987;&#23478;&#31574;&#30053;&#36827;&#34892;&#20915;&#31574;&#25351;&#23548;&#30340;&#32534;&#25490;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23545;&#25239;&#24615;&#35774;&#32622;&#20013;&#30340;&#21518;&#24724;&#36793;&#30028;&#32467;&#26524;&#36716;&#31227;&#21040;&#34920;&#26684;&#35774;&#32622;&#19979;&#30340;&#32534;&#25490;&#20013;&#65292;&#25512;&#24191;&#20102;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#27934;&#23519;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#20851;&#38190;&#28857;&#22312;&#20110;&#20854;&#36879;&#26126;&#30340;&#35777;&#26126;&#12290;&#22312;&#38543;&#26426;&#21305;&#37197;&#29609;&#20855;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#27169;&#25311;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2310.16473</link><description>&lt;p&gt;
&#19987;&#23478;&#30340;&#20132;&#21709;&#26354;&#65306;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#36816;&#29992;&#23545;&#25239;&#24615;&#27934;&#23519;&#21147;&#30340;&#32534;&#25490;
&lt;/p&gt;
&lt;p&gt;
Symphony of experts: orchestration with adversarial insights in reinforcement learning. (arXiv:2310.16473v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16473
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#19987;&#23478;&#31574;&#30053;&#36827;&#34892;&#20915;&#31574;&#25351;&#23548;&#30340;&#32534;&#25490;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23545;&#25239;&#24615;&#35774;&#32622;&#20013;&#30340;&#21518;&#24724;&#36793;&#30028;&#32467;&#26524;&#36716;&#31227;&#21040;&#34920;&#26684;&#35774;&#32622;&#19979;&#30340;&#32534;&#25490;&#20013;&#65292;&#25512;&#24191;&#20102;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#27934;&#23519;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#20851;&#38190;&#28857;&#22312;&#20110;&#20854;&#36879;&#26126;&#30340;&#35777;&#26126;&#12290;&#22312;&#38543;&#26426;&#21305;&#37197;&#29609;&#20855;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#27169;&#25311;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#21270;&#24378;&#21270;&#23398;&#20064;&#21033;&#29992;&#20855;&#26377;&#20248;&#21183;&#29305;&#24615;&#30340;&#31574;&#30053;&#20197;&#36798;&#21040;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#25506;&#32034;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#32534;&#25490;&#30340;&#27010;&#24565;&#26469;&#25506;&#32034;&#36825;&#19968;&#39046;&#22495;&#65292;&#20854;&#20013;&#19968;&#32452;&#65288;&#23569;&#37327;&#65289;&#19987;&#23478;&#31574;&#30053;&#25351;&#23548;&#20915;&#31574;&#65307;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#24314;&#31435;&#20102;&#27492;&#24314;&#27169;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20174;&#23545;&#25239;&#24615;&#35774;&#32622;&#20013;&#36716;&#31227;&#21518;&#24724;&#36793;&#30028;&#32467;&#26524;&#65292;&#22312;&#34920;&#26684;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#32534;&#25490;&#30340;&#20215;&#20540;&#20989;&#25968;&#21518;&#24724;&#36793;&#30028;&#12290;&#25105;&#20204;&#23558;&#23545; Agarwal &#31561;&#20154; [2021, &#31532;5.3&#33410;] &#20013;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#20998;&#26512;&#25512;&#24191;&#24182;&#25193;&#23637;&#21040;&#20219;&#24847;&#23545;&#25239;&#24615;&#32858;&#21512;&#31574;&#30053;&#12290;&#25105;&#20204;&#36824;&#23558;&#20854;&#25193;&#23637;&#21040;&#20272;&#35745;&#20248;&#21183;&#20989;&#25968;&#30340;&#24773;&#20917;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#26399;&#26395;&#20540;&#21644;&#39640;&#27010;&#29575;&#19979;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#27934;&#23519;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#28857;&#22312;&#20110;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#32780;&#35328;&#35777;&#26126;&#36739;&#20026;&#36879;&#26126;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#38024;&#23545;&#38543;&#26426;&#21305;&#37197;&#29609;&#20855;&#27169;&#22411;&#36827;&#34892;&#20102;&#27169;&#25311;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structured reinforcement learning leverages policies with advantageous properties to reach better performance, particularly in scenarios where exploration poses challenges. We explore this field through the concept of orchestration, where a (small) set of expert policies guides decision-making; the modeling thereof constitutes our first contribution. We then establish value-functions regret bounds for orchestration in the tabular setting by transferring regret-bound results from adversarial settings. We generalize and extend the analysis of natural policy gradient in Agarwal et al. [2021, Section 5.3] to arbitrary adversarial aggregation strategies. We also extend it to the case of estimated advantage functions, providing insights into sample complexity both in expectation and high probability. A key point of our approach lies in its arguably more transparent proofs compared to existing methods. Finally, we present simulations for a stochastic matching toy model.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65292;&#36890;&#36807;&#19981;&#23545;&#20854;&#20182;&#21464;&#37327;&#20570;&#22826;&#22810;&#20551;&#35774;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#21644;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.16048</link><description>&lt;p&gt;
&#23616;&#37096;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#32467;&#26500;&#38480;&#21046;: &#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
Structural restrictions in local causal discovery: identifying direct causes of a target variable. (arXiv:2307.16048v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16048
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65292;&#36890;&#36807;&#19981;&#23545;&#20854;&#20182;&#21464;&#37327;&#20570;&#22826;&#22810;&#20551;&#35774;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#21644;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#35266;&#23519;&#32852;&#21512;&#20998;&#24067;&#20013;&#23398;&#20064;&#30446;&#26631;&#21464;&#37327;&#30340;&#19968;&#32452;&#30452;&#25509;&#21407;&#22240;&#30340;&#38382;&#39064;&#12290;&#23398;&#20064;&#34920;&#31034;&#22240;&#26524;&#32467;&#26500;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#26159;&#31185;&#23398;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#24403;&#23436;&#25972;&#30340;DAG&#20174;&#20998;&#24067;&#20013;&#21487;&#35782;&#21035;&#26102;&#65292;&#24050;&#30693;&#26377;&#19968;&#20123;&#32467;&#26524;&#65292;&#20363;&#22914;&#20551;&#35774;&#38750;&#32447;&#24615;&#39640;&#26031;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#12290;&#36890;&#24120;&#65292;&#25105;&#20204;&#21482;&#23545;&#35782;&#21035;&#19968;&#20010;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65288;&#23616;&#37096;&#22240;&#26524;&#32467;&#26500;&#65289;&#65292;&#32780;&#19981;&#26159;&#23436;&#25972;&#30340;DAG&#24863;&#20852;&#36259;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23545;&#30446;&#26631;&#21464;&#37327;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#19981;&#21516;&#20551;&#35774;&#65292;&#35813;&#20551;&#35774;&#19979;&#30452;&#25509;&#21407;&#22240;&#38598;&#21512;&#21487;&#20197;&#20174;&#20998;&#24067;&#20013;&#35782;&#21035;&#20986;&#26469;&#12290;&#22312;&#36825;&#26679;&#20570;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23545;&#38500;&#30446;&#26631;&#21464;&#37327;&#20043;&#22806;&#30340;&#21464;&#37327;&#22522;&#26412;&#19978;&#27809;&#26377;&#20219;&#20309;&#20551;&#35774;&#12290;&#38500;&#20102;&#26032;&#30340;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20004;&#31181;&#20174;&#26377;&#38480;&#38543;&#26426;&#26679;&#26412;&#20272;&#35745;&#30452;&#25509;&#21407;&#22240;&#30340;&#23454;&#29992;&#31639;&#27861;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning a set of direct causes of a target variable from an observational joint distribution. Learning directed acyclic graphs (DAGs) that represent the causal structure is a fundamental problem in science. Several results are known when the full DAG is identifiable from the distribution, such as assuming a nonlinear Gaussian data-generating process. Often, we are only interested in identifying the direct causes of one target variable (local causal structure), not the full DAG. In this paper, we discuss different assumptions for the data-generating process of the target variable under which the set of direct causes is identifiable from the distribution. While doing so, we put essentially no assumptions on the variables other than the target variable. In addition to the novel identifiability results, we provide two practical algorithms for estimating the direct causes from a finite random sample and demonstrate their effectiveness on several benchmark dataset
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.14872</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#24179;&#34913;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#20960;&#20309;&#24863;&#30693;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14872
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21463;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#34920;&#29616;&#33391;&#22909;&#30340;&#23454;&#35777;&#24615;&#33021;&#19982;&#24754;&#35266;&#29702;&#35770;&#21518;&#24724;&#30028;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#21551;&#21457;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#21253;&#25324;&#36138;&#24515;&#12289;OFUL&#21644;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#22312;&#20869;&#30340;&#24191;&#27867;&#31639;&#27861;&#31867;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#22312;&#20445;&#30041;&#22522;&#26412;&#31639;&#27861;&#22823;&#37096;&#20998;&#20248;&#33391;&#29305;&#24615;&#30340;&#21516;&#26102;&#8220;&#26657;&#27491;&#8221;&#22522;&#26412;&#31639;&#27861;&#22312;&#26576;&#20123;&#23454;&#20363;&#20013;&#34920;&#29616;&#24046;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#28176;&#36817;&#26368;&#20248;&#21518;&#24724;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#20998;&#31867;&#22120;&#21644;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#27169;&#22411;&#22312;&#25910;&#25947;&#26102;&#20250;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23637;&#31034;&#20102;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#22312;&#25910;&#25947;&#26102;&#20063;&#33021;&#36798;&#21040;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.12494</link><description>&lt;p&gt;
&#20851;&#20110;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#21644;&#19968;&#31867;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
On the Generalized Likelihood Ratio Test and One-Class Classifiers. (arXiv:2210.12494v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#20998;&#31867;&#22120;&#21644;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#27169;&#22411;&#22312;&#25910;&#25947;&#26102;&#20250;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23637;&#31034;&#20102;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#22312;&#25910;&#25947;&#26102;&#20063;&#33021;&#36798;&#21040;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#31867;&#20998;&#31867;&#65288;OCC&#65289;&#26159;&#20915;&#23450;&#35266;&#23519;&#26679;&#26412;&#26159;&#21542;&#23646;&#20110;&#30446;&#26631;&#31867;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#21253;&#21547;&#30446;&#26631;&#31867;&#26679;&#26412;&#30340;&#25968;&#25454;&#38598;&#19978;&#23398;&#20064;&#19968;&#20010;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#65288;GLRT&#65289;&#30340;OCC&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#24403;&#30446;&#26631;&#31867;&#30340;&#32479;&#35745;&#20449;&#24687;&#21487;&#29992;&#26102;&#65292;GLRT&#35299;&#20915;&#20102;&#30456;&#21516;&#30340;&#38382;&#39064;&#12290;GLRT&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#19988;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#26368;&#20339;&#30340;&#20998;&#31867;&#22120;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#27169;&#22411;&#12290;&#23427;&#20204;&#20351;&#29992;&#20154;&#24037;&#25968;&#25454;&#38598;&#35757;&#32451;&#20026;&#20004;&#31867;&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#26367;&#20195;&#31867;&#20351;&#29992;&#22312;&#30446;&#26631;&#31867;&#25968;&#25454;&#38598;&#30340;&#23450;&#20041;&#22495;&#19978;&#22343;&#21248;&#29983;&#25104;&#30340;&#38543;&#26426;&#26679;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#27169;&#22411;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#25910;&#25947;&#21040;&#20102;GLRT&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#20855;&#26377;&#36866;&#24403;&#26680;&#20989;&#25968;&#30340;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#65288;OCLSSVM&#65289;&#22312;&#25910;&#25947;&#26102;&#34920;&#29616;&#20026;GLRT&#12290;
&lt;/p&gt;
&lt;p&gt;
One-class classification (OCC) is the problem of deciding whether an observed sample belongs to a target class. We consider the problem of learning an OCC model that performs as the generalized likelihood ratio test (GLRT), given a dataset containing samples of the target class. The GLRT solves the same problem when the statistics of the target class are available. The GLRT is a well-known and provably optimal (under specific assumptions) classifier. To this end, we consider both the multilayer perceptron neural network (NN) and the support vector machine (SVM) models. They are trained as two-class classifiers using an artificial dataset for the alternative class, obtained by generating random samples, uniformly over the domain of the target-class dataset. We prove that, under suitable assumptions, the models converge (with a large dataset) to the GLRT. Moreover, we show that the one-class least squares SVM (OCLSSVM) with suitable kernels at convergence performs as the GLRT. Lastly, we
&lt;/p&gt;</description></item></channel></rss>