<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>PIP-Net&#26159;&#19968;&#20010;&#26032;&#22411;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#21160;&#24577;&#23398;&#25968;&#25454;&#21644;&#22330;&#26223;&#31354;&#38388;&#29305;&#24449;&#65292;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#25104;&#21151;&#39044;&#27979;&#34892;&#20154;&#36890;&#36807;&#39532;&#36335;&#30340;&#24847;&#22270;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>https://arxiv.org/abs/2402.12810</link><description>&lt;p&gt;
PIP-Net&#65306;&#22478;&#24066;&#20013;&#34892;&#20154;&#24847;&#22270;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
PIP-Net: Pedestrian Intention Prediction in the Wild
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12810
&lt;/p&gt;
&lt;p&gt;
PIP-Net&#26159;&#19968;&#20010;&#26032;&#22411;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#21160;&#24577;&#23398;&#25968;&#25454;&#21644;&#22330;&#26223;&#31354;&#38388;&#29305;&#24449;&#65292;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#25104;&#21151;&#39044;&#27979;&#34892;&#20154;&#36890;&#36807;&#39532;&#36335;&#30340;&#24847;&#22270;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#20934;&#30340;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#65288;AVs&#65289;&#23545;&#34892;&#20154;&#24847;&#22270;&#30340;&#39044;&#27979;&#26159;&#24403;&#21069;&#35813;&#39046;&#22495;&#30340;&#19968;&#39033;&#30740;&#31350;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;PIP-Net&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#39044;&#27979;AVs&#22312;&#29616;&#23454;&#19990;&#30028;&#22478;&#24066;&#22330;&#26223;&#20013;&#30340;&#34892;&#20154;&#36807;&#39532;&#36335;&#24847;&#22270;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#31181;&#38024;&#23545;&#19981;&#21516;&#25668;&#20687;&#22836;&#23433;&#35013;&#21644;&#35774;&#32622;&#35774;&#35745;&#30340;PIP-Net&#21464;&#31181;&#12290;&#21033;&#29992;&#26469;&#33258;&#34892;&#39542;&#22330;&#26223;&#30340;&#21160;&#21147;&#23398;&#25968;&#25454;&#21644;&#31354;&#38388;&#29305;&#24449;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;&#20026;&#20102;&#22686;&#24378;&#36947;&#36335;&#29992;&#25143;&#30340;&#35270;&#35273;&#34920;&#31034;&#21450;&#20854;&#19982;&#33258;&#36710;&#30340;&#30456;&#20851;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20998;&#31867;&#28145;&#24230;&#29305;&#24449;&#22270;&#65292;&#32467;&#21512;&#23616;&#37096;&#36816;&#21160;&#27969;&#29305;&#24449;&#65292;&#20026;&#22330;&#26223;&#21160;&#24577;&#25552;&#20379;&#20016;&#23500;&#30340;&#27934;&#23519;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#23558;&#25668;&#20687;&#22836;&#30340;&#35270;&#37326;&#20174;&#19968;&#20010;&#25193;&#23637;&#21040;&#22260;&#32469;&#33258;&#36710;&#30340;&#19977;&#20010;&#25668;&#20687;&#22836;&#30340;&#24433;&#21709;&#65292;&#20197;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12810v1 Announce Type: cross  Abstract: Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to enhancement in the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#25506;&#35752;&#20102;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#21442;&#25968;&#25928;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;&#36890;&#20449;&#22270;&#35774;&#35745;&#21644;&#22823;&#23567;&#23545;&#21518;&#39564;&#25910;&#32553;&#29575;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2311.08214</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#39057;&#29575;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Frequentist Guarantees of Distributed (Non)-Bayesian Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#25506;&#35752;&#20102;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#21442;&#25968;&#25928;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;&#36890;&#20449;&#22270;&#35774;&#35745;&#21644;&#22823;&#23567;&#23545;&#21518;&#39564;&#25910;&#32553;&#29575;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#20998;&#26512;&#22823;&#22411;&#20998;&#25955;&#25968;&#25454;&#38598;&#30340;&#38656;&#27714;&#25512;&#21160;&#65292;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#24050;&#25104;&#20026;&#36328;&#22810;&#20010;&#39046;&#22495;&#65288;&#21253;&#25324;&#32479;&#35745;&#23398;&#12289;&#30005;&#27668;&#24037;&#31243;&#21644;&#32463;&#27982;&#23398;&#65289;&#30340;&#20851;&#38190;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#22914;&#21518;&#39564;&#19968;&#33268;&#24615;&#12289;&#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#21518;&#39564;&#25910;&#32553;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36890;&#20449;&#22270;&#19978;&#30340;&#36866;&#24403;&#20551;&#35774;&#19979;&#65292;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#20445;&#30041;&#20102;&#21442;&#25968;&#25928;&#29575;&#65292;&#21516;&#26102;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#22686;&#24378;&#20102;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#30740;&#31350;&#35774;&#35745;&#21644;&#36890;&#20449;&#22270;&#30340;&#22823;&#23567;&#22914;&#20309;&#24433;&#21709;&#21518;&#39564;&#25910;&#32553;&#29575;&#26469;&#25506;&#35752;&#20102;&#32479;&#35745;&#25928;&#29575;&#21644;&#36890;&#20449;&#25928;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#26102;&#21464;&#22270;&#65292;&#24182;&#23558;&#32467;&#26524;&#24212;&#29992;&#20110;&#25351;&#25968;f
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08214v2 Announce Type: replace-cross  Abstract: Motivated by the need to analyze large, decentralized datasets, distributed Bayesian inference has become a critical research area across multiple fields, including statistics, electrical engineering, and economics. This paper establishes Frequentist properties, such as posterior consistency, asymptotic normality, and posterior contraction rates, for the distributed (non-)Bayes Inference problem among agents connected via a communication network. Our results show that, under appropriate assumptions on the communication graph, distributed Bayesian inference retains parametric efficiency while enhancing robustness in uncertainty quantification. We also explore the trade-off between statistical efficiency and communication efficiency by examining how the design and size of the communication graph impact the posterior contraction rate. Furthermore, We extend our analysis to time-varying graphs and apply our results to exponential f
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#26469;&#35774;&#35745;&#21487;&#38752;&#22320;&#25490;&#21517;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;SHAP&#21644;LIME&#31561;&#24120;&#29992;&#26041;&#27861;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#23548;&#33268;&#30340;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.15800</link><description>&lt;p&gt;
&#20351;&#29992;SHAP&#21644;LIME&#36827;&#34892;&#21487;&#35777;&#26126;&#31283;&#23450;&#30340;&#29305;&#24449;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Provably Stable Feature Rankings with SHAP and LIME. (arXiv:2401.15800v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15800
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#26469;&#35774;&#35745;&#21487;&#38752;&#22320;&#25490;&#21517;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;SHAP&#21644;LIME&#31561;&#24120;&#29992;&#26041;&#27861;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#23548;&#33268;&#30340;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#24402;&#22240;&#26159;&#20102;&#35299;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#30340;&#26222;&#36941;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#35780;&#20998;&#36755;&#20837;&#21464;&#37327;&#30340;&#24120;&#29992;&#26041;&#27861;&#65292;&#22914;SHAP&#21644;LIME&#65292;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#32780;&#20855;&#26377;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#12290;&#20511;&#37492;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#27491;&#30830;&#25490;&#21517;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#24402;&#22240;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;RankSHAP&#20445;&#35777;$K$&#20010;&#26368;&#39640;Shapley&#20540;&#20855;&#26377;&#36229;&#36807;$1-\alpha$&#30340;&#27491;&#30830;&#25490;&#24207;&#27010;&#29575;&#12290;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#36824;&#22312;&#20043;&#21069;&#30340;&#24037;&#20316;&#22522;&#30784;&#19978;&#20026;LIME&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#65292;&#30830;&#20445;&#20197;&#27491;&#30830;&#39034;&#24207;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature attributions are ubiquitous tools for understanding the predictions of machine learning models. However, popular methods for scoring input variables such as SHAP and LIME suffer from high instability due to random sampling. Leveraging ideas from multiple hypothesis testing, we devise attribution methods that correctly rank the most important features with high probability. Our algorithm RankSHAP guarantees that the $K$ highest Shapley values have the proper ordering with probability exceeding $1-\alpha$. Empirical results demonstrate its validity and impressive computational efficiency. We also build on previous work to yield similar results for LIME, ensuring the most important features are selected in the right order.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#65292;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#65292;&#24182;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;</title><link>http://arxiv.org/abs/2401.14483</link><description>&lt;p&gt;
&#39044;&#27979;&#30340;&#22235;&#20010;&#26041;&#38754;&#65306;&#26657;&#20934;&#12289;&#39044;&#27979;&#24615;&#12289;&#38543;&#26426;&#24615;&#21644;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Four Facets of Forecast Felicity: Calibration, Predictiveness, Randomness and Regret. (arXiv:2401.14483v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#65292;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#65292;&#24182;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26159;&#20851;&#20110;&#39044;&#27979;&#30340;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#21482;&#26377;&#32463;&#36807;&#35780;&#20272;&#21518;&#25165;&#20855;&#26377;&#20854;&#26377;&#29992;&#24615;&#12290;&#26426;&#22120;&#23398;&#20064;&#20256;&#32479;&#19978;&#20851;&#27880;&#25439;&#22833;&#31867;&#22411;&#21450;&#20854;&#30456;&#24212;&#30340;&#36951;&#25022;&#12290;&#30446;&#21069;&#65292;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#37325;&#26032;&#23545;&#26657;&#20934;&#20135;&#29983;&#20102;&#20852;&#36259;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26657;&#20934;&#21644;&#36951;&#25022;&#22312;&#35780;&#20272;&#39044;&#27979;&#20013;&#30340;&#27010;&#24565;&#31561;&#20215;&#24615;&#12290;&#25105;&#20204;&#23558;&#35780;&#20272;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39044;&#27979;&#32773;&#12289;&#19968;&#20010;&#36172;&#24466;&#21644;&#33258;&#28982;&#20043;&#38388;&#30340;&#21338;&#24328;&#12290;&#36890;&#36807;&#23545;&#36172;&#24466;&#21644;&#39044;&#27979;&#32773;&#26045;&#21152;&#30452;&#35266;&#30340;&#38480;&#21046;&#65292;&#26657;&#20934;&#21644;&#36951;&#25022;&#33258;&#28982;&#22320;&#25104;&#20026;&#20102;&#36825;&#20010;&#26694;&#26550;&#30340;&#19968;&#37096;&#20998;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#21338;&#24328;&#23558;&#39044;&#27979;&#30340;&#35780;&#20272;&#19982;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;&#30456;&#23545;&#20110;&#39044;&#27979;&#32780;&#35328;&#65292;&#32467;&#26524;&#30340;&#38543;&#26426;&#24615;&#31561;&#21516;&#20110;&#20851;&#20110;&#32467;&#26524;&#30340;&#22909;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#31216;&#36825;&#20004;&#20010;&#26041;&#38754;&#20026;&#26657;&#20934;&#21644;&#36951;&#25022;&#12289;&#39044;&#27979;&#24615;&#21644;&#38543;&#26426;&#24615;&#65292;&#21363;&#39044;&#27979;&#30340;&#22235;&#20010;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning is about forecasting. Forecasts, however, obtain their usefulness only through their evaluation. Machine learning has traditionally focused on types of losses and their corresponding regret. Currently, the machine learning community regained interest in calibration. In this work, we show the conceptual equivalence of calibration and regret in evaluating forecasts. We frame the evaluation problem as a game between a forecaster, a gambler and nature. Putting intuitive restrictions on gambler and forecaster, calibration and regret naturally fall out of the framework. In addition, this game links evaluation of forecasts to randomness of outcomes. Random outcomes with respect to forecasts are equivalent to good forecasts with respect to outcomes. We call those dual aspects, calibration and regret, predictiveness and randomness, the four facets of forecast felicity.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;&#30340;&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#20855;&#26377;&#22312;&#25968;&#23398;&#37329;&#34701;&#39046;&#22495;&#20013;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19603</link><description>&lt;p&gt;
&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21487;&#20197;&#36827;&#34892;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
Deep Kalman Filters Can Filter. (arXiv:2310.19603v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;&#30340;&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#20855;&#26377;&#22312;&#25968;&#23398;&#37329;&#34701;&#39046;&#22495;&#20013;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#26159;&#19968;&#31867;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#24207;&#21015;&#25968;&#25454;&#20013;&#29983;&#25104;&#39640;&#26031;&#27010;&#29575;&#27979;&#24230;&#12290;&#34429;&#28982;DKFs&#21463;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#21551;&#21457;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#19982;&#38543;&#26426;&#28388;&#27874;&#38382;&#39064;&#30340;&#20855;&#20307;&#29702;&#35770;&#20851;&#32852;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#20538;&#21048;&#21644;&#26399;&#26435;&#23450;&#20215;&#27169;&#22411;&#26657;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;DKFs&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#25968;&#23398;&#22522;&#30784;&#20013;&#30340;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36817;&#20284;&#32467;&#26524;&#22312;&#36335;&#24452;&#30340;&#36275;&#22815;&#35268;&#21017;&#30340;&#32039;&#33268;&#23376;&#38598;&#19978;&#19968;&#33268;&#25104;&#31435;&#65292;&#20854;&#20013;&#36817;&#20284;&#35823;&#24046;&#30001;&#22312;&#32473;&#23450;&#32039;&#33268;&#36335;&#24452;&#38598;&#19978;&#22343;&#19968;&#22320;&#35745;&#31639;&#30340;&#26368;&#22351;&#24773;&#20917;2-Wasserstein&#36317;&#31163;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Kalman filters (DKFs) are a class of neural network models that generate Gaussian probability measures from sequential data. Though DKFs are inspired by the Kalman filter, they lack concrete theoretical ties to the stochastic filtering problem, thus limiting their applicability to areas where traditional model-based filters have been used, e.g.\ model calibration for bond and option prices in mathematical finance. We address this issue in the mathematical foundations of deep learning by exhibiting a class of continuous-time DKFs which can approximately implement the conditional law of a broad class of non-Markovian and conditionally Gaussian signal processes given noisy continuous-times measurements. Our approximation results hold uniformly over sufficiently regular compact subsets of paths, where the approximation error is quantified by the worst-case 2-Wasserstein distance computed uniformly over the given compact set of paths.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38543;&#26426;&#21270;&#26080;&#27169;&#22411;&#31639;&#27861;RandQL&#65292;&#29992;&#20110;&#20943;&#23567;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#36951;&#25022;&#12290;RandQL&#36890;&#36807;&#23398;&#20064;&#29575;&#38543;&#26426;&#21270;&#23454;&#29616;&#20048;&#35266;&#25506;&#32034;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2310.18186</link><description>&lt;p&gt;
&#26080;&#27169;&#22411;&#21518;&#39564;&#37319;&#26679;&#30340;&#27169;&#22411;&#33258;&#30001;&#38543;&#26426;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model-free Posterior Sampling via Learning Rate Randomization. (arXiv:2310.18186v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38543;&#26426;&#21270;&#26080;&#27169;&#22411;&#31639;&#27861;RandQL&#65292;&#29992;&#20110;&#20943;&#23567;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#36951;&#25022;&#12290;RandQL&#36890;&#36807;&#23398;&#20064;&#29575;&#38543;&#26426;&#21270;&#23454;&#29616;&#20048;&#35266;&#25506;&#32034;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#21270;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;Randomized Q-learning&#65288;&#31616;&#31216;RandQL&#65289;&#65292;&#29992;&#20110;&#20943;&#23567;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#20013;&#30340;&#36951;&#25022;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;RandQL&#26159;&#31532;&#19968;&#20010;&#21487;&#34892;&#30340;&#27169;&#22411;&#33258;&#30001;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;RandQL&#22312;&#34920;&#26684;&#21644;&#38750;&#34920;&#26684;&#24230;&#37327;&#31354;&#38388;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#12290;&#22312;&#34920;&#26684;MDPs&#20013;&#65292;RandQL&#23454;&#29616;&#20102;&#19968;&#20010;&#36951;&#25022;&#30028;&#30340;&#39034;&#24207;&#20026;$\widetilde{\mathcal{O}}(\sqrt{H^{5}SAT})$&#65292;&#20854;&#20013;$H$&#26159;&#35745;&#21010;&#30340;&#26102;&#38388;&#38271;&#24230;&#65292;$S$&#26159;&#29366;&#24577;&#25968;&#65292;$A$&#26159;&#21160;&#20316;&#25968;&#65292;$T$&#26159;&#22238;&#21512;&#25968;&#12290;&#23545;&#20110;&#24230;&#37327;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#65292;RandQL&#23454;&#29616;&#20102;&#19968;&#20010;&#36951;&#25022;&#30028;&#30340;&#39034;&#24207;&#20026;$\widetilde{\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$&#65292;&#20854;&#20013;$d_z$&#34920;&#31034;&#32553;&#25918;&#32500;&#24230;&#12290;&#38656;&#35201;&#27880;&#24847;&#30340;&#26159;&#65292;RandQL&#23454;&#29616;&#20102;&#20048;&#35266;&#25506;&#32034;&#65292;&#32780;&#19981;&#20351;&#29992;&#22870;&#21169;&#65292;&#32780;&#26159;&#20381;&#36182;&#20110;&#23398;&#20064;&#29575;&#38543;&#26426;&#21270;&#30340;&#26032;&#24605;&#24819;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;RandQL&#22312;&#22522;&#32447;&#25506;&#32034;&#19978;&#32988;&#36807;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce Randomized Q-learning (RandQL), a novel randomized model-free algorithm for regret minimization in episodic Markov Decision Processes (MDPs). To the best of our knowledge, RandQL is the first tractable model-free posterior sampling-based algorithm. We analyze the performance of RandQL in both tabular and non-tabular metric space settings. In tabular MDPs, RandQL achieves a regret bound of order $\widetilde{\mathcal{O}}(\sqrt{H^{5}SAT})$, where $H$ is the planning horizon, $S$ is the number of states, $A$ is the number of actions, and $T$ is the number of episodes. For a metric state-action space, RandQL enjoys a regret bound of order $\widetilde{\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$, where $d_z$ denotes the zooming dimension. Notably, RandQL achieves optimistic exploration without using bonuses, relying instead on a novel idea of learning rate randomization. Our empirical study shows that RandQL outperforms existing approaches on baseline exploration en
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;</title><link>http://arxiv.org/abs/2310.12140</link><description>&lt;p&gt;
&#22312;&#32447;&#20272;&#35745;&#19982;&#28378;&#21160;&#39564;&#35777;&#65306;&#36866;&#24212;&#24615;&#38750;&#21442;&#25968;&#20272;&#35745;&#19982;&#25968;&#25454;&#27969;
&lt;/p&gt;
&lt;p&gt;
Online Estimation with Rolling Validation: Adaptive Nonparametric Estimation with Stream Data. (arXiv:2310.12140v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#39640;&#25928;&#35745;&#31639;&#21644;&#31454;&#20105;&#24615;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#32447;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#20363;&#23376;&#26159;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21464;&#20307;&#12290;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#19968;&#27425;&#21482;&#21462;&#19968;&#20010;&#26679;&#26412;&#28857;&#65292;&#24182;&#31435;&#21363;&#26356;&#26032;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20123;&#22312;&#32447;&#31639;&#27861;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#65292;&#19968;&#31181;&#22312;&#32447;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#21464;&#20307;&#65292;&#23545;&#20110;&#35768;&#22810;&#20856;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#22120;&#26469;&#35828;&#65292;&#39069;&#22806;&#30340;&#35745;&#31639;&#25104;&#26412;&#26368;&#23567;&#12290;&#31867;&#20284;&#20110;&#25209;&#37327;&#20132;&#21449;&#39564;&#35777;&#65292;&#23427;&#21487;&#20197;&#25552;&#21319;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#24456;&#31616;&#21333;&#65292;&#20027;&#35201;&#20381;&#36182;&#20110;&#19968;&#20123;&#19968;&#33324;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#20551;&#35774;&#12290;&#27169;&#25311;&#30740;&#31350;&#24378;&#35843;&#20102;&#28378;&#21160;&#39564;&#35777;&#20013;&#21457;&#25955;&#26435;&#37325;&#22312;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#21363;&#20351;&#21482;&#26377;&#19968;&#20010;&#24456;&#23567;&#30340;&#20559;&#24046;&#65292;&#23427;&#30340;&#25935;&#24863;&#24615;&#20063;&#24456;&#39640;
&lt;/p&gt;
&lt;p&gt;
Online nonparametric estimators are gaining popularity due to their efficient computation and competitive generalization abilities. An important example includes variants of stochastic gradient descent. These algorithms often take one sample point at a time and instantly update the parameter estimate of interest. In this work we consider model selection and hyperparameter tuning for such online algorithms. We propose a weighted rolling-validation procedure, an online variant of leave-one-out cross-validation, that costs minimal extra computation for many typical stochastic gradient descent estimators. Similar to batch cross-validation, it can boost base estimators to achieve a better, adaptive convergence rate. Our theoretical analysis is straightforward, relying mainly on some general statistical stability assumptions. The simulation study underscores the significance of diverging weights in rolling validation in practice and demonstrates its sensitivity even when there is only a slim
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#38543;&#26426;Metropolis-Hastings&#31639;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#36890;&#36807;&#24341;&#20837;&#31616;&#21333;&#30340;&#20462;&#27491;&#39033;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36991;&#20813;&#35745;&#31639;&#25104;&#26412;&#19978;&#30340;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#38750;&#21442;&#25968;&#22238;&#24402;&#24773;&#26223;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#30340;&#25968;&#20540;&#23454;&#20363;&#26469;&#35777;&#26126;&#20102;&#20854;&#22312;&#37319;&#26679;&#21644;&#21487;&#20449;&#21306;&#38388;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.09335</link><description>&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;Metropolis-Hastings&#31639;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical guarantees for stochastic Metropolis-Hastings. (arXiv:2310.09335v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09335
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#38543;&#26426;Metropolis-Hastings&#31639;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#36890;&#36807;&#24341;&#20837;&#31616;&#21333;&#30340;&#20462;&#27491;&#39033;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36991;&#20813;&#35745;&#31639;&#25104;&#26412;&#19978;&#30340;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#38750;&#21442;&#25968;&#22238;&#24402;&#24773;&#26223;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#30340;&#25968;&#20540;&#23454;&#20363;&#26469;&#35777;&#26126;&#20102;&#20854;&#22312;&#37319;&#26679;&#21644;&#21487;&#20449;&#21306;&#38388;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Metropolis-Hastings&#27493;&#39588;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22522;&#20110;&#26799;&#24230;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#12290;&#36890;&#36807;&#23545;&#25209;&#27425;&#35745;&#31639;&#25509;&#21463;&#27010;&#29575;&#65292;&#38543;&#26426;Metropolis-Hastings&#27493;&#39588;&#33410;&#30465;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#20294;&#38477;&#20302;&#20102;&#26377;&#25928;&#26679;&#26412;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#31616;&#21333;&#30340;&#20462;&#27491;&#39033;&#21487;&#20197;&#36991;&#20813;&#36825;&#20010;&#38556;&#30861;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#26524;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#35774;&#32622;&#20013;&#24212;&#29992;&#25913;&#36827;&#30340;&#38543;&#26426;Metropolis-Hastings&#26041;&#27861;&#20174;Gibbs&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#21017;&#38142;&#30340;&#32467;&#26524;&#31283;&#24577;&#20998;&#24067;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;&#38024;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PAC-Bayes&#39044;&#35328;&#19981;&#31561;&#24335;&#65292;&#23427;&#25552;&#20379;&#20102;&#26368;&#20248;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#20998;&#26512;&#20102;&#32467;&#26524;&#21487;&#20449;&#21306;&#38388;&#30340;&#30452;&#24452;&#21644;&#39640;&#32622;&#20449;&#27010;&#29575;&#12290;&#36890;&#36807;&#22312;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#25968;&#20540;&#23454;&#20363;&#65292;&#25105;&#20204;&#35828;&#26126;&#20102;&#38543;&#26426;Metropolis-Hastings&#31639;&#27861;&#30340;&#21487;&#20449;&#21306;&#38388;&#21644;&#25910;&#32553;&#36895;&#29575;&#30830;&#23454;&#34920;&#29616;&#20986;&#31867;&#20284;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Metropolis-Hastings step is widely used for gradient-based Markov chain Monte Carlo methods in uncertainty quantification. By calculating acceptance probabilities on batches, a stochastic Metropolis-Hastings step saves computational costs, but reduces the effective sample size. We show that this obstacle can be avoided by a simple correction term. We study statistical properties of the resulting stationary distribution of the chain if the corrected stochastic Metropolis-Hastings approach is applied to sample from a Gibbs posterior distribution in a nonparametric regression setting. Focusing on deep neural network regression, we prove a PAC-Bayes oracle inequality which yields optimal contraction rates and we analyze the diameter and show high coverage probability of the resulting credible sets. With a numerical example in a high-dimensional parameter space, we illustrate that credible sets and contraction rates of the stochastic Metropolis-Hastings algorithm indeed behave similar to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#32500;&#24230;&#36739;&#39640;&#19988;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38598;&#30340;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#65292;&#32780;&#23545;&#20110;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.05657</link><description>&lt;p&gt;
&#20851;&#20110;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
On the quality of randomized approximations of Tukey's depth. (arXiv:2309.05657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#32500;&#24230;&#36739;&#39640;&#19988;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38598;&#30340;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#65292;&#32780;&#23545;&#20110;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Tukey&#28145;&#24230;&#65288;&#25110;&#21322;&#31354;&#38388;&#28145;&#24230;&#65289;&#26159;&#29992;&#20110;&#22810;&#20803;&#25968;&#25454;&#20013;&#24515;&#24230;&#37327;&#30340;&#24191;&#27867;&#24212;&#29992;&#30340;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#24230;&#19979;&#65292;Tukey&#28145;&#24230;&#30340;&#31934;&#30830;&#35745;&#31639;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20154;&#20204;&#25552;&#20986;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#26679;&#30340;&#38543;&#26426;&#31639;&#27861;&#20309;&#26102;&#33021;&#22815;&#36820;&#22238;&#19968;&#20010;&#33391;&#22909;&#30340;Tukey&#28145;&#24230;&#36817;&#20284;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38519;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#35201;&#27714;&#31639;&#27861;&#22312;&#32500;&#24230;&#19978;&#20197;&#22810;&#39033;&#24335;&#26102;&#38388;&#36816;&#34892;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#22320;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;1/2&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#23545;&#20110;&#20219;&#20309;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tukey's depth (or halfspace depth) is a widely used measure of centrality for multivariate data. However, exact computation of Tukey's depth is known to be a hard problem in high dimensions. As a remedy, randomized approximations of Tukey's depth have been proposed. In this paper we explore when such randomized algorithms return a good approximation of Tukey's depth. We study the case when the data are sampled from a log-concave isotropic distribution. We prove that, if one requires that the algorithm runs in polynomial time in the dimension, the randomized algorithm correctly approximates the maximal depth $1/2$ and depths close to zero. On the other hand, for any point of intermediate depth, any good approximation requires exponential complexity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;Wasserstein&#32858;&#31867;&#65292;&#29992;&#20110;&#22788;&#29702;&#37329;&#34701;&#26426;&#26500;&#30340;&#22797;&#26434;&#25968;&#25454;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#32570;&#22833;&#20540;&#21644;&#22522;&#20110;&#29305;&#23450;&#29305;&#24449;&#35782;&#21035;&#32858;&#31867;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#30417;&#31649;&#32773;&#30340;&#30417;&#31649;&#24037;&#20316;&#65292;&#24182;&#22312;&#20854;&#39046;&#22495;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.03565</link><description>&lt;p&gt;
&#37329;&#34701;&#26426;&#26500;&#30340;&#20960;&#20309;&#24418;&#24577;--&#37329;&#34701;&#25968;&#25454;&#30340;Wasserstein&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
The geometry of financial institutions -- Wasserstein clustering of financial data. (arXiv:2305.03565v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;Wasserstein&#32858;&#31867;&#65292;&#29992;&#20110;&#22788;&#29702;&#37329;&#34701;&#26426;&#26500;&#30340;&#22797;&#26434;&#25968;&#25454;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#32570;&#22833;&#20540;&#21644;&#22522;&#20110;&#29305;&#23450;&#29305;&#24449;&#35782;&#21035;&#32858;&#31867;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#30417;&#31649;&#32773;&#30340;&#30417;&#31649;&#24037;&#20316;&#65292;&#24182;&#22312;&#20854;&#39046;&#22495;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#26029;&#22686;&#21152;&#30340;&#21508;&#31181;&#26377;&#36259;&#23545;&#35937;&#30340;&#32454;&#33410;&#21644;&#22823;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#20351;&#24471;&#26377;&#24517;&#35201;&#24320;&#21457;&#23558;&#36825;&#20123;&#20449;&#24687;&#21387;&#32553;&#25104;&#20195;&#34920;&#24615;&#21644;&#21487;&#29702;&#35299;&#30340;&#22320;&#22270;&#30340;&#26041;&#27861;&#12290;&#37329;&#34701;&#30417;&#31649;&#26159;&#19968;&#20010;&#23637;&#31034;&#36825;&#31181;&#38656;&#27714;&#30340;&#39046;&#22495;&#65292;&#22240;&#20026;&#30417;&#31649;&#26426;&#26500;&#38656;&#35201;&#20174;&#37329;&#34701;&#26426;&#26500;&#33719;&#21462;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#65292;&#26377;&#26102;&#26159;&#39640;&#24230;&#32454;&#31890;&#24230;&#30340;&#65292;&#20197;&#30417;&#30563;&#21644;&#35780;&#20272;&#20182;&#20204;&#30340;&#27963;&#21160;&#12290;&#28982;&#32780;&#65292;&#22788;&#29702;&#21644;&#20998;&#26512;&#36825;&#26679;&#30340;&#25968;&#25454;&#21487;&#33021;&#26159;&#19968;&#39033;&#33392;&#24040;&#30340;&#20219;&#21153;&#65292;&#23588;&#20854;&#26159;&#32771;&#34385;&#21040;&#22788;&#29702;&#32570;&#22833;&#20540;&#21644;&#22522;&#20110;&#29305;&#23450;&#29305;&#24449;&#35782;&#21035;&#32858;&#31867;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#27010;&#29575;&#20998;&#24067;&#30340;Lloyd&#31639;&#27861;&#21464;&#20307;&#65292;&#24182;&#20351;&#29992;&#24191;&#20041;Wasserstein&#37325;&#24515;&#26500;&#24314;&#34920;&#31034;&#19981;&#21516;&#23545;&#35937;&#19978;&#30340;&#32473;&#23450;&#25968;&#25454;&#30340;&#24230;&#37327;&#31354;&#38388;&#65292;&#20174;&#32780;&#24212;&#23545;&#37329;&#34701;&#30417;&#31649;&#32972;&#26223;&#19979;&#30417;&#31649;&#32773;&#38754;&#20020;&#30340;&#20855;&#20307;&#25361;&#25112;&#12290;&#25105;&#20204;&#30456;&#20449;&#36825;&#31181;&#26041;&#27861;&#22312;&#37329;&#34701;&#30417;&#31649;&#39046;&#22495;&#20855;&#26377;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing availability of granular and big data on various objects of interest has made it necessary to develop methods for condensing this information into a representative and intelligible map. Financial regulation is a field that exemplifies this need, as regulators require diverse and often highly granular data from financial institutions to monitor and assess their activities. However, processing and analyzing such data can be a daunting task, especially given the challenges of dealing with missing values and identifying clusters based on specific features.  To address these challenges, we propose a variant of Lloyd's algorithm that applies to probability distributions and uses generalized Wasserstein barycenters to construct a metric space which represents given data on various objects in condensed form. By applying our method to the financial regulation context, we demonstrate its usefulness in dealing with the specific challenges faced by regulators in this domain. We beli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2303.17765</link><description>&lt;p&gt;
&#23398;&#20064;&#30456;&#20284;&#30340;&#32447;&#24615;&#34920;&#31034;&#65306;&#36866;&#24212;&#24615;&#12289;&#26497;&#23567;&#21270;&#12289;&#20197;&#21450;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness. (arXiv:2303.17765v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#28982;&#32780;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#27424;&#32570;&#12290;&#26412;&#25991;&#26088;&#22312;&#29702;&#35299;&#20174;&#20855;&#26377;&#30456;&#20284;&#20294;&#24182;&#38750;&#23436;&#20840;&#30456;&#21516;&#30340;&#32447;&#24615;&#34920;&#31034;&#30340;&#20219;&#21153;&#20013;&#23398;&#20064;&#65292;&#21516;&#26102;&#22788;&#29702;&#24322;&#24120;&#20540;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21333;&#20219;&#21153;&#25110;&#20165;&#30446;&#26631;&#23398;&#20064;&#26102;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \textit{adaptive} to the similarity structure and \textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when
&lt;/p&gt;</description></item></channel></rss>