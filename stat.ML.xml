<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>GLAD&#26159;&#19968;&#20010;&#22312;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36866;&#24212;&#25193;&#25955;&#26725;&#32467;&#26500;&#23398;&#20064;&#20854;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#20110;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#30340;&#20998;&#35299;&#65292;&#22312;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.16883</link><description>&lt;p&gt;
&#24102;&#25193;&#25955;&#26725;&#30340;&#31163;&#25955;&#28508;&#22312;&#22270;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Discrete Latent Graph Generative Modeling with Diffusion Bridges
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16883
&lt;/p&gt;
&lt;p&gt;
GLAD&#26159;&#19968;&#20010;&#22312;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36866;&#24212;&#25193;&#25955;&#26725;&#32467;&#26500;&#23398;&#20064;&#20854;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#20110;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#30340;&#20998;&#35299;&#65292;&#22312;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#30456;&#27604;&#20110;&#22312;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#27169;&#22411;&#21463;&#21040;&#36739;&#23569;&#20851;&#27880;&#65292;&#36804;&#20170;&#34920;&#29616;&#20986;&#30340;&#24615;&#33021;&#20047;&#21892;&#21487;&#38472;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GLAD&#65292;&#19968;&#20010;&#28508;&#22312;&#31354;&#38388;&#22270;&#29983;&#25104;&#27169;&#22411;&#12290;&#19982;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#28508;&#22312;&#31354;&#38388;&#22270;&#29983;&#25104;&#27169;&#22411;&#19981;&#21516;&#65292;GLAD&#22312;&#20445;&#30041;&#22270;&#32467;&#26500;&#30340;&#31163;&#25955;&#24615;&#36136;&#26041;&#38754;&#36816;&#34892;&#65292;&#26080;&#38656;&#36827;&#34892;&#35832;&#22914;&#28508;&#22312;&#31354;&#38388;&#36830;&#32493;&#24615;&#31561;&#19981;&#33258;&#28982;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25193;&#25955;&#26725;&#35843;&#25972;&#21040;&#20854;&#32467;&#26500;&#65292;&#26469;&#23398;&#20064;&#25105;&#20204;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#12290;&#36890;&#36807;&#22312;&#36866;&#24403;&#26500;&#24314;&#30340;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#65292;&#25105;&#20204;&#36991;&#20813;&#20381;&#36182;&#20110;&#24120;&#29992;&#20110;&#22312;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#25805;&#20316;&#30340;&#27169;&#22411;&#20013;&#30340;&#20998;&#35299;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#22270;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#26126;&#26174;&#23637;&#31034;&#20102;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20248;&#36234;&#24615;&#65292;&#24182;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#22270;&#29983;&#25104;&#24615;&#33021;&#65292;&#20351;GLA
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16883v1 Announce Type: new  Abstract: Learning graph generative models over latent spaces has received less attention compared to models that operate on the original data space and has so far demonstrated lacklustre performance. We present GLAD a latent space graph generative model. Unlike most previous latent space graph generative models, GLAD operates on a discrete latent space that preserves to a significant extent the discrete nature of the graph structures making no unnatural assumptions such as latent space continuity. We learn the prior of our discrete latent space by adapting diffusion bridges to its structure. By operating over an appropriately constructed latent space we avoid relying on decompositions that are often used in models that operate in the original data space. We present experiments on a series of graph benchmark datasets which clearly show the superiority of the discrete latent space and obtain state of the art graph generative performance, making GLA
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#19968;&#20010;&#29305;&#23450;&#30340;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#31361;&#20986;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#65292;&#21516;&#26102;&#20855;&#26377;&#24378;&#22823;&#29983;&#25104;&#22120;&#30340;&#29420;&#29305;&#35270;&#35282;&#12290;</title><link>https://arxiv.org/abs/2403.02957</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#28176;&#36817;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Asymptotic Mean Square Error Optimality of Diffusion Probabilistic Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#19968;&#20010;&#29305;&#23450;&#30340;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#31361;&#20986;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#65292;&#21516;&#26102;&#20855;&#26377;&#24378;&#22823;&#29983;&#25104;&#22120;&#30340;&#29420;&#29305;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPMs&#65289;&#22312;&#21435;&#22122;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;&#23613;&#31649;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24456;&#26377;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#29702;&#35299;&#23384;&#22312;&#26126;&#26174;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#36890;&#36807;&#20005;&#26684;&#35777;&#26126;&#29305;&#23450;DPM&#21435;&#22122;&#31574;&#30053;&#22312;&#22823;&#37327;&#25193;&#25955;&#27493;&#25968;&#19979;&#25910;&#25947;&#21040;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#26368;&#20248;&#26465;&#20214;&#22343;&#20540;&#20272;&#35745;&#22120;&#65288;CME&#65289;&#65292;&#20026;&#35813;&#39046;&#22495;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#35265;&#35299;&#12290;&#30740;&#31350;&#30340;&#22522;&#20110;DPM&#30340;&#21435;&#22122;&#22120;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#19982;DPMs&#20849;&#20139;&#65292;&#20294;&#22312;&#35757;&#32451;&#21518;&#30340;&#36870;&#25512;&#29702;&#36807;&#31243;&#20013;&#20165;&#20256;&#36882;&#26465;&#20214;&#22343;&#20540;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;DPM&#30001;&#28176;&#36817;&#26368;&#20248;&#30340;&#21435;&#22122;&#22120;&#32452;&#25104;&#30340;&#29420;&#29305;&#35270;&#35282;&#65292;&#21516;&#26102;&#36890;&#36807;&#22312;&#36870;&#36807;&#31243;&#20013;&#20999;&#25442;&#37325;&#26032;&#37319;&#26679;&#30340;&#26041;&#24335;&#32487;&#25215;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#29983;&#25104;&#22120;&#12290;&#36890;&#36807;&#25968;&#20540;&#32467;&#26524;&#39564;&#35777;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02957v1 Announce Type: new  Abstract: Diffusion probabilistic models (DPMs) have recently shown great potential for denoising tasks. Despite their practical utility, there is a notable gap in their theoretical understanding. This paper contributes novel theoretical insights by rigorously proving the asymptotic convergence of a specific DPM denoising strategy to the mean square error (MSE)-optimal conditional mean estimator (CME) over a large number of diffusion steps. The studied DPM-based denoiser shares the training procedure of DPMs but distinguishes itself by forwarding only the conditional mean during the reverse inference process after training. We highlight the unique perspective that DPMs are composed of an asymptotically optimal denoiser while simultaneously inheriting a powerful generator by switching re-sampling in the reverse process on and off. The theoretical findings are validated by numerical results.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#34892;&#38598;&#30340;&#26354;&#29575;&#65292;&#22312;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.12868</link><description>&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#21487;&#34892;&#38598;&#30340;&#26354;&#29575;&#65292;&#22312;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#23454;&#29616;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Fast Rates in Online Convex Optimization by Exploiting the Curvature of Feasible Sets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12868
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#34892;&#38598;&#30340;&#26354;&#29575;&#65292;&#22312;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#65288;OCO&#65289;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#21487;&#34892;&#38598;&#30340;&#26354;&#29575;&#25552;&#20379;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#30340;&#26032;&#20998;&#26512;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#65292;&#22914;&#26524;&#26368;&#20248;&#20915;&#31574;&#20301;&#20110;&#21487;&#34892;&#38598;&#30340;&#36793;&#30028;&#19978;&#19988;&#22522;&#30784;&#25439;&#22833;&#20989;&#25968;&#30340;&#26799;&#24230;&#38750;&#38646;&#65292;&#21017;&#31639;&#27861;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#21487;&#20197;&#36798;&#21040;$O(\rho \log T)$&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#20854;&#20013;&#65292;$\rho &gt; 0$&#26159;&#21253;&#21547;&#26368;&#20248;&#20915;&#31574;&#24182;&#22260;&#32469;&#21487;&#34892;&#38598;&#30340;&#26368;&#23567;&#29699;&#20307;&#30340;&#21322;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12868v1 Announce Type: new  Abstract: In this paper, we explore online convex optimization (OCO) and introduce a new analysis that provides fast rates by exploiting the curvature of feasible sets. In online linear optimization, it is known that if the average gradient of loss functions is larger than a certain value, the curvature of feasible sets can be exploited by the follow-the-leader (FTL) algorithm to achieve a logarithmic regret. This paper reveals that algorithms adaptive to the curvature of loss functions can also leverage the curvature of feasible sets. We first prove that if an optimal decision is on the boundary of a feasible set and the gradient of an underlying loss function is non-zero, then the algorithm achieves a regret upper bound of $O(\rho \log T)$ in stochastic environments. Here, $\rho &gt; 0$ is the radius of the smallest sphere that includes the optimal decision and encloses the feasible set. Our approach, unlike existing ones, can work directly with co
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39118;&#38505;&#20998;&#35299;&#21644;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#21516;&#26469;&#28304;&#65292;&#24182;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.10727</link><description>&lt;p&gt;
&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#23454;&#29616;&#20005;&#26684;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Predictive Uncertainty Quantification via Risk Decompositions for Strictly Proper Scoring Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10727
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39118;&#38505;&#20998;&#35299;&#21644;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#21516;&#26469;&#28304;&#65292;&#24182;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#39044;&#27979;&#27169;&#22411;&#24212;&#29992;&#20013;&#65292;&#21306;&#20998;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#25552;&#20986;&#20102;&#35768;&#22810;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#20294;&#24182;&#27809;&#26377;&#20005;&#26684;&#30340;&#23450;&#20041;&#26469;&#35299;&#24320;&#23427;&#20204;&#12290;&#27492;&#22806;&#65292;&#19981;&#21516;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25514;&#26045;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#28982;&#26377;&#20123;&#19981;&#28165;&#26224;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26681;&#26893;&#20110;&#32479;&#35745;&#25512;&#29702;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#19981;&#20165;&#20801;&#35768;&#21019;&#24314;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#36824;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#32479;&#35745;&#39118;&#38505;&#26469;&#21306;&#20998;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#25104;&#20998;&#65292;&#24182;&#21033;&#29992;&#36866;&#24403;&#30340;&#35780;&#20998;&#35268;&#21017;&#23545;&#20854;&#36827;&#34892;&#37327;&#21270;&#12290;&#20026;&#20102;&#20351;&#20854;&#22312;&#23454;&#36341;&#20013;&#26131;&#20110;&#22788;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#36825;&#19968;&#26694;&#26550;&#20013;&#25972;&#21512;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#24819;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#25152;&#25552;&#36817;&#20284;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10727v1 Announce Type: cross  Abstract: Distinguishing sources of predictive uncertainty is of crucial importance in the application of forecasting models across various domains. Despite the presence of a great variety of proposed uncertainty measures, there are no strict definitions to disentangle them. Furthermore, the relationship between different measures of uncertainty quantification remains somewhat unclear. In this work, we introduce a general framework, rooted in statistical reasoning, which not only allows the creation of new uncertainty measures but also clarifies their interrelations. Our approach leverages statistical risk to distinguish aleatoric and epistemic uncertainty components and utilizes proper scoring rules to quantify them. To make it practically tractable, we propose an idea to incorporate Bayesian reasoning into this framework and discuss the properties of the proposed approximation.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21512;&#24182;&#20351;&#29992;&#19981;&#21516;&#36807;&#28388;&#22120;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#39034;&#24207;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09698</link><description>&lt;p&gt;
&#21512;&#24182;&#19981;&#21516;&#36807;&#28388;&#22120;&#20013;&#30340;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
Combining Evidence Across Filtrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09698
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21512;&#24182;&#20351;&#29992;&#19981;&#21516;&#36807;&#28388;&#22120;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#39034;&#24207;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20219;&#20309;&#26102;&#21051;&#26377;&#25928;&#30340;&#39034;&#24207;&#25512;&#29702;&#20013;&#65292;&#24050;&#30693;&#20219;&#20309;&#21487;&#25509;&#21463;&#30340;&#25512;&#29702;&#26041;&#27861;&#24517;&#39035;&#22522;&#20110;&#27979;&#35797;&#38789;&#21644;&#23427;&#20204;&#30340;&#32452;&#21512;&#24191;&#20041;&#21270;&#65292;&#31216;&#20026;e&#36827;&#31243;&#65292;&#23427;&#20204;&#26159;&#38750;&#36127;&#36827;&#31243;&#65292;&#20854;&#22312;&#20219;&#20309;&#20219;&#24847;&#20572;&#26102;&#30340;&#26399;&#26395;&#19978;&#30028;&#19981;&#36229;&#36807;&#19968;&#12290;e&#36827;&#31243;&#37327;&#21270;&#20102;&#38024;&#23545;&#22797;&#21512;&#38646;&#20551;&#35774;&#30340;&#19968;&#31995;&#21015;&#32467;&#26524;&#30340;&#32047;&#31215;&#35777;&#25454;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#19981;&#21516;&#20449;&#24687;&#38598;&#65288;&#21363;&#36807;&#28388;&#22120;&#65289;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#21512;&#24182;&#26041;&#27861;&#65292;&#38024;&#23545;&#19968;&#20010;&#38646;&#20551;&#35774;&#12290;&#23613;&#31649;&#22312;&#30456;&#21516;&#36807;&#28388;&#22120;&#19978;&#26500;&#24314;&#30340;e&#36827;&#31243;&#21487;&#20197;&#36731;&#26494;&#22320;&#21512;&#24182;&#65288;&#20363;&#22914;&#65292;&#36890;&#36807;&#24179;&#22343;&#65289;&#65292;&#20294;&#22312;&#19981;&#21516;&#36807;&#28388;&#22120;&#19978;&#26500;&#24314;&#30340;e&#36827;&#31243;&#19981;&#33021;&#37027;&#20040;&#23481;&#26131;&#22320;&#21512;&#24182;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#36739;&#31895;&#30340;&#36807;&#28388;&#22120;&#20013;&#30340;&#26377;&#25928;&#24615;&#19981;&#33021;&#36716;&#25442;&#20026;&#22312;&#26356;&#32454;&#30340;&#36807;&#28388;&#22120;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#25991;&#29486;&#20013;&#19977;&#20010;&#20855;&#20307;&#20363;&#23376;&#65306;&#21487;&#20132;&#25442;&#24615;&#27979;&#35797;&#65292;&#29420;&#31435;&#24615;&#27979;&#35797;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09698v1 Announce Type: cross  Abstract: In anytime-valid sequential inference, it is known that any admissible inference procedure must be based on test martingales and their composite generalization, called e-processes, which are nonnegative processes whose expectation at any arbitrary stopping time is upper-bounded by one. An e-process quantifies the accumulated evidence against a composite null hypothesis over a sequence of outcomes. This paper studies methods for combining e-processes that are computed using different information sets, i.e., filtrations, for a null hypothesis. Even though e-processes constructed on the same filtration can be combined effortlessly (e.g., by averaging), e-processes constructed on different filtrations cannot be combined as easily because their validity in a coarser filtration does not translate to validity in a finer filtration. We discuss three concrete examples of such e-processes in the literature: exchangeability tests, independence te
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#37096;&#20998;&#30417;&#27979;&#38382;&#39064;&#20013;&#25506;&#32034;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#27491;&#21017;&#21270;&#22120;&#21487;&#20197;&#25552;&#39640;&#22312;&#38543;&#26426;&#21644;&#23545;&#25239;&#29615;&#22659;&#20013;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.08321</link><description>&lt;p&gt;
&#20351;&#29992;&#28151;&#21512;&#27491;&#21017;&#21270;&#22120;&#30340;&#20248;&#21270;&#25506;&#32034;&#65306;&#22312;&#37096;&#20998;&#30417;&#27979;&#20013;&#20855;&#26377;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#23545;&#25968;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Exploration by Optimization with Hybrid Regularizers: Logarithmic Regret with Adversarial Robustness in Partial Monitoring
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08321
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#37096;&#20998;&#30417;&#27979;&#38382;&#39064;&#20013;&#25506;&#32034;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#27491;&#21017;&#21270;&#22120;&#21487;&#20197;&#25552;&#39640;&#22312;&#38543;&#26426;&#21644;&#23545;&#25239;&#29615;&#22659;&#20013;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37096;&#20998;&#30417;&#27979;&#26159;&#19968;&#31181;&#20855;&#26377;&#26377;&#38480;&#35266;&#27979;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#20026;&#20102;&#20174;&#36825;&#31181;&#26377;&#38480;&#35266;&#27979;&#20013;&#20570;&#20986;&#20915;&#31574;&#65292;&#38656;&#35201;&#25214;&#21040;&#19968;&#20010;&#36866;&#24403;&#30340;&#25506;&#32034;&#20998;&#24067;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27492;&#30446;&#30340;&#30340;&#24378;&#22823;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#20248;&#21270;&#36827;&#34892;&#25506;&#32034;&#65288;ExO&#65289;&#65292;&#23427;&#21033;&#29992;&#36861;&#36394;&#27491;&#21017;&#21270;&#26368;&#20248;&#26041;&#27861;&#65292;&#22312;&#24191;&#27867;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#20013;&#23454;&#29616;&#23545;&#25239;&#29615;&#22659;&#19979;&#30340;&#26368;&#20248;&#30028;&#38480;&#12290;&#28982;&#32780;&#65292;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#32431;&#31929;&#24212;&#29992;ExO&#20250;&#26174;&#33879;&#38477;&#20302;&#36951;&#25022;&#30028;&#38480;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#23616;&#37096;&#21487;&#35266;&#27979;&#28216;&#25103;&#20013;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;ExO&#19982;&#28151;&#21512;&#27491;&#21017;&#21270;&#22120;&#30340;&#26694;&#26550;&#21644;&#20998;&#26512;&#12290;&#36825;&#20010;&#21457;&#23637;&#20351;&#25105;&#20204;&#33021;&#22815;&#26174;&#33879;&#25913;&#36827;&#26368;&#20339;&#21452;&#36194;&#31639;&#27861;&#65288;BOBW&#65289;&#30340;&#29616;&#26377;&#36951;&#25022;&#30028;&#38480;&#65292;&#22312;&#38543;&#26426;&#21644;&#23545;&#25239;&#29615;&#22659;&#20013;&#37117;&#23454;&#29616;&#20102;&#20960;&#20046;&#26368;&#20248;&#30340;&#30028;&#38480;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#38543;&#26426;&#36951;&#25022;&#30028;&#38480;&#20026;$O(\sum_{a \neq a^*} k^2 m^2$
&lt;/p&gt;
&lt;p&gt;
Partial monitoring is a generic framework of online decision-making problems with limited observations. To make decisions from such limited observations, it is necessary to find an appropriate distribution for exploration. Recently, a powerful approach for this purpose, exploration by optimization (ExO), was proposed, which achieves the optimal bounds in adversarial environments with follow-the-regularized-leader for a wide range of online decision-making problems. However, a naive application of ExO in stochastic environments significantly degrades regret bounds. To resolve this problem in locally observable games, we first establish a novel framework and analysis for ExO with a hybrid regularizer. This development allows us to significantly improve the existing regret bounds of best-of-both-worlds (BOBW) algorithms, which achieves nearly optimal bounds both in stochastic and adversarial environments. In particular, we derive a stochastic regret bound of $O(\sum_{a \neq a^*} k^2 m^2 \
&lt;/p&gt;</description></item><item><title>&#22312;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#21487;&#20197;&#20135;&#29983;&#38750;&#22343;&#21248;&#20559;&#24046;&#65292;&#22240;&#27492;&#36890;&#24120;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20250;&#19982;&#31364;&#25945;&#24072;NN&#19968;&#26679;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.06323</link><description>&lt;p&gt;
&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#22914;&#20309;&#24341;&#36215;&#19981;&#22343;&#21248;&#20559;&#24046;&#65306;&#20856;&#22411;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#19982;&#31364;&#25945;&#24072;&#30340;&#26222;&#36941;&#24615;
&lt;/p&gt;
&lt;p&gt;
How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06323
&lt;/p&gt;
&lt;p&gt;
&#22312;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#21487;&#20197;&#20135;&#29983;&#38750;&#22343;&#21248;&#20559;&#24046;&#65292;&#22240;&#27492;&#36890;&#24120;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20250;&#19982;&#31364;&#25945;&#24072;NN&#19968;&#26679;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#12290;&#19968;&#20010;&#20027;&#35201;&#30340;&#29702;&#35770;&#38590;&#39064;&#26159;&#24403;&#31070;&#32463;&#32593;&#32476;&#34987;&#35757;&#32451;&#21040;&#38646;&#35823;&#24046;&#65288;&#21363;&#25554;&#20540;&#25968;&#25454;&#65289;&#26102;&#65292;&#20026;&#20160;&#20040;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#36890;&#24120;&#65292;NN&#26159;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25110;&#20854;&#21464;&#31181;&#20043;&#19968;&#35757;&#32451;&#30340;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#23454;&#35777;&#30740;&#31350;&#26816;&#39564;&#20102;&#20174;&#30475;&#20284;&#22343;&#21248;&#30340;&#21442;&#25968;&#20808;&#39564;&#20013;&#37319;&#26679;&#30340;&#38543;&#26426;NN&#23545;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#65306;&#35813;NN&#23545;&#35757;&#32451;&#38598;&#36827;&#34892;&#20102;&#23436;&#32654;&#20998;&#31867;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#26679;&#30340;NN&#26679;&#26412;&#36890;&#24120;&#20687;SGD&#35757;&#32451;&#30340;NN&#19968;&#26679;&#27867;&#21270;&#33391;&#22909;&#12290;&#36129;&#29486;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22914;&#26524;&#23384;&#22312;&#19982;&#26631;&#31614;&#19968;&#33268;&#30340;&#31364;&#8220;&#25945;&#24072;NN&#8221;&#65292;&#37027;&#20040;&#36825;&#26679;&#30340;&#38543;&#26426;NN&#25554;&#20540;&#22120;&#36890;&#24120;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;NN&#21442;&#25968;&#21270;&#20013;&#30340;&#8220;&#24179;&#22374;&#8221;&#20808;&#39564;&#36890;&#36807;NN&#32467;&#26500;&#20013;&#30340;&#20887;&#20313;&#24341;&#20837;&#20102;&#20016;&#23500;&#30340;NN&#20989;&#25968;&#20808;&#39564;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20250;&#23545;&#36739;&#31616;&#21333;&#30340;&#20989;&#25968;&#20135;&#29983;&#20559;&#21521;&#65292;&#36825;&#20123;&#20989;&#25968;&#38656;&#35201;&#36739;&#23569;&#30340;&#30456;&#20851;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background. A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with Stochastic Gradient Descent (SGD) or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as SGD-trained NNs.   Contributions. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant pa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.05806</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#26657;&#20934;&#21644;&#31526;&#21512;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Calibration and Conformal Prediction of Deep Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20998;&#31867;&#24212;&#29992;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22522;&#20110;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#38656;&#35201;&#20276;&#38543;&#19968;&#20123;&#32622;&#20449;&#24230;&#25351;&#31034;&#12290;&#38024;&#23545;&#36825;&#20010;&#30446;&#26631;&#65292;&#26377;&#20004;&#31181;&#27969;&#34892;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#65306;1&#65289;&#26657;&#20934;&#65306;&#20462;&#25913;&#20998;&#31867;&#22120;&#30340;softmax&#20540;&#65292;&#20351;&#20854;&#26368;&#22823;&#20540;&#65288;&#19982;&#39044;&#27979;&#30456;&#20851;&#65289;&#26356;&#22909;&#22320;&#20272;&#35745;&#27491;&#30830;&#27010;&#29575;&#65307;&#21644;2&#65289;&#31526;&#21512;&#39044;&#27979;&#65288;CP&#65289;&#65306;&#35774;&#35745;&#19968;&#20010;&#22522;&#20110;softmax&#20540;&#30340;&#20998;&#25968;&#65292;&#20174;&#20013;&#20135;&#29983;&#19968;&#32452;&#39044;&#27979;&#65292;&#20855;&#26377;&#29702;&#35770;&#19978;&#20445;&#35777;&#27491;&#30830;&#31867;&#21035;&#36793;&#38469;&#35206;&#30422;&#30340;&#29305;&#24615;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#20004;&#31181;&#25351;&#31034;&#37117;&#21487;&#33021;&#26159;&#38656;&#35201;&#30340;&#65292;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#23578;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#65292;&#36825;&#26159;&#26368;&#24120;&#35265;&#30340;&#26657;&#20934;&#25216;&#26415;&#65292;&#23545;&#37325;&#35201;&#30340;CP&#26041;&#27861;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#20102;&#19968;&#39033;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#20854;&#20013;&#26174;&#31034;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#27934;&#23519;&#65292;&#20854;&#20013;&#21253;&#25324;&#20196;&#20154;&#24778;&#35766;&#30340;&#21457;&#29616;&#65292;&#21363;&#26657;&#20934;&#23545;&#27969;&#34892;&#30340;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many classification applications, the prediction of a deep neural network (DNN) based classifier needs to be accompanied with some confidence indication. Two popular post-processing approaches for that aim are: 1) calibration: modifying the classifier's softmax values such that their maximum (associated with the prediction) better estimates the correctness probability; and 2) conformal prediction (CP): devising a score (based on the softmax values) from which a set of predictions with theoretically guaranteed marginal coverage of the correct class is produced. While in practice both types of indications can be desired, so far the interplay between them has not been investigated. Toward filling this gap, in this paper we study the effect of temperature scaling, arguably the most common calibration technique, on prominent CP methods. We start with an extensive empirical study that among other insights shows that, surprisingly, calibration has a detrimental effect on popular adaptive C
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#22312;2-Wasserstein&#36317;&#31163;&#20013;&#30340;&#19968;&#33324;&#31867;&#27010;&#29575;&#27969;ODE&#25277;&#26679;&#22120;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#20551;&#35774;&#24471;&#20998;&#20272;&#35745;&#20934;&#30830;&#12290;</title><link>https://arxiv.org/abs/2401.17958</link><description>&lt;p&gt;
&#22312;Wasserstein&#36317;&#31163;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#19968;&#33324;&#27010;&#29575;&#27969;ODE&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis for General Probability Flow ODEs of Diffusion Models in Wasserstein Distances
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#22312;2-Wasserstein&#36317;&#31163;&#20013;&#30340;&#19968;&#33324;&#31867;&#27010;&#29575;&#27969;ODE&#25277;&#26679;&#22120;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#20551;&#35774;&#24471;&#20998;&#20272;&#35745;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27010;&#29575;&#27969;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#34429;&#28982;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#21508;&#31181;&#24555;&#36895;&#30340;&#22522;&#20110;ODE&#30340;&#25277;&#26679;&#22120;&#24182;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#65292;&#20294;&#23545;&#27010;&#29575;&#27969;ODE&#30340;&#25910;&#25947;&#24615;&#23646;&#24615;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#38750;&#24120;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#36866;&#29992;&#20110;2-Wasserstein&#36317;&#31163;&#20013;&#30340;&#19968;&#33324;&#31867;&#27010;&#29575;&#27969;ODE&#25277;&#26679;&#22120;&#30340;&#39318;&#20010;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#20998;&#26512;&#32467;&#26524;&#65292;&#20551;&#35774;&#20934;&#30830;&#30340;&#24471;&#20998;&#20272;&#35745;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#21508;&#31181;&#31034;&#20363;&#65292;&#24182;&#30830;&#23450;&#20102;&#30456;&#24212;&#22522;&#20110;ODE&#30340;&#25277;&#26679;&#22120;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative modeling with probability flow ordinary differential equations (ODEs) has achieved remarkable success in a variety of applications. While various fast ODE-based samplers have been proposed in the literature and employed in practice, the theoretical understandings about convergence properties of the probability flow ODE are still quite limited. In this paper, we provide the first non-asymptotic convergence analysis for a general class of probability flow ODE samplers in 2-Wasserstein distance, assuming accurate score estimates. We then consider various examples and establish results on the iteration complexity of the corresponding ODE-based samplers.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#23436;&#25972;&#25910;&#25947;&#29702;&#35770;&#20445;&#35777;&#65292;&#33719;&#24471;&#20102;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#20248;&#19978;&#38480;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2311.13584</link><description>&lt;p&gt;
&#20851;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#21450;&#20854;&#35823;&#24046;&#30028;&#38480;&#65306;&#23436;&#20840;&#25910;&#25947;&#20272;&#35745;&#19979;&#30340;&#23545;&#25968;&#20985;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13584
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#23436;&#25972;&#25910;&#25947;&#29702;&#35770;&#20445;&#35777;&#65292;&#33719;&#24471;&#20102;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#20248;&#19978;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#20026;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#34892;&#20026;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#32780;&#25105;&#20204;&#29992;&#20110;&#24471;&#20998;&#20272;&#35745;&#30340;&#36924;&#36817;&#20989;&#25968;&#31867;&#30001;Lipschitz&#36830;&#32493;&#20989;&#25968;&#32452;&#25104;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#28608;&#21169;&#24615;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24378;&#22823;&#20043;&#22788;&#65292;&#21363;&#20174;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#30340;&#39640;&#26031;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#30456;&#20851;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#24471;&#20998;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#23558;&#20854;&#19982;&#30456;&#24212;&#30340;&#37319;&#26679;&#20272;&#35745;&#32467;&#21512;&#36215;&#26469;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26368;&#22909;&#30340;&#24050;&#30693;&#19978;&#38480;&#20272;&#35745;&#65292;&#28041;&#21450;&#20851;&#38190;&#24863;&#20852;&#36259;&#30340;&#25968;&#37327;&#65292;&#22914;&#25968;&#25454;&#20998;&#24067;&#65288;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#30340;&#39640;&#26031;&#20998;&#24067;&#65289;&#19982;&#25105;&#20204;&#30340;&#37319;&#26679;&#31639;&#27861;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#32500;&#24230;&#21644;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13584v2 Announce Type: replace  Abstract: We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm.   Beyond the motivating example and in order to allow for the use of a diverse range o
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;Thompson&#37319;&#26679;&#20174;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#26032;&#30340;&#20505;&#36873;&#32773;&#65292;&#36991;&#20813;&#20102;&#32321;&#26434;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#12290;</title><link>http://arxiv.org/abs/2310.15788</link><description>&lt;p&gt;
qPOTS: &#39640;&#25928;&#30340;&#25209;&#37327;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
qPOTS: Efficient batch multiobjective Bayesian optimization via Pareto optimal Thompson sampling. (arXiv:2310.15788v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15788
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;Thompson&#37319;&#26679;&#20174;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#26032;&#30340;&#20505;&#36873;&#32773;&#65292;&#36991;&#20813;&#20102;&#32321;&#26434;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#36827;&#21270;&#26041;&#27861;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#23545;&#30446;&#26631;&#36827;&#34892;&#22823;&#37327;&#26597;&#35810;&#21487;&#33021;&#19981;&#21033;&#20110;&#30446;&#26631;&#33457;&#36153;&#24456;&#22810;&#25110;&#32773;&#35745;&#31639;&#37327;&#24456;&#22823;&#30340;&#26102;&#20505;&#12290;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#26367;&#20195;&#29289;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#26469;&#35299;&#20915;&#22810;&#30446;&#26631;&#20248;&#21270;&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;(MOBO)&#28041;&#21450;&#26500;&#24314;&#19968;&#20010;&#34987;&#20248;&#21270;&#29992;&#26469;&#33719;&#24471;&#26032;&#35266;&#23519;&#20505;&#36873;&#30340;&#33719;&#21462;&#20989;&#25968;&#12290;&#36825;&#20010;&#8220;&#20869;&#37096;&#8221;&#20248;&#21270;&#21487;&#33021;&#24456;&#22256;&#38590;&#65292;&#22240;&#20026;&#33719;&#21462;&#20989;&#25968;&#26159;&#38750;&#20984;&#30340;&#65292;&#19981;&#21487;&#24494;&#30340;&#21644;/&#25110;&#32773;&#19981;&#20986;&#27874;&#65292;MOBO&#30340;&#25104;&#21151;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#36825;&#20010;&#20869;&#37096;&#20248;&#21270;&#12290;&#25105;&#20204;&#25682;&#24323;&#36825;&#20010;&#22256;&#38590;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#65292;&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22522;&#20110;Thompson&#37319;&#26679;&#30340;&#26041;&#27861;($q\texttt{POTS}$)&#65292;&#20854;&#20013;&#26032;&#30340;&#20505;&#36873;&#32773;&#26159;&#20174;&#36890;&#36807;&#27714;&#35299;&#19968;&#20010;&#26356;&#20415;&#23452;&#30340;&#22810;&#20010;&#21518;&#39564;&#26679;&#26412;&#36335;&#24452;&#30340;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical evolutionary approaches for multiobjective optimization are quite effective but incur a lot of queries to the objectives; this can be prohibitive when objectives are expensive oracles. A sample-efficient approach to solving multiobjective optimization is via Gaussian process (GP) surrogates and Bayesian optimization (BO). Multiobjective Bayesian optimization (MOBO) involves the construction of an acquisition function which is optimized to acquire new observation candidates. This ``inner'' optimization can be hard due to various reasons: acquisition functions being nonconvex, nondifferentiable and/or unavailable in analytical form; the success of MOBO heavily relies on this inner optimization. We do away with this hard acquisition function optimization step and propose a simple, but effective, Thompson sampling based approach ($q\texttt{POTS}$) where new candidate(s) are chosen from the Pareto frontier of random GP posterior sample paths obtained by solving a much cheaper mult
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#27969;&#24418;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#31232;&#30095;&#33258;&#36866;&#24212;&#30340;&#20146;&#21644;&#30697;&#38453;&#65292;&#24182;&#22312;&#36830;&#32493;&#26497;&#38480;&#19979;&#19982;&#25289;&#26222;&#25289;&#26031;&#22411;&#31639;&#23376;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2307.09816</link><description>&lt;p&gt;
&#29992;&#31232;&#30095;&#27491;&#21017;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#27969;&#24418;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Manifold Learning with Sparse Regularised Optimal Transport. (arXiv:2307.09816v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09816
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#27969;&#24418;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#31232;&#30095;&#33258;&#36866;&#24212;&#30340;&#20146;&#21644;&#30697;&#38453;&#65292;&#24182;&#22312;&#36830;&#32493;&#26497;&#38480;&#19979;&#19982;&#25289;&#26222;&#25289;&#26031;&#22411;&#31639;&#23376;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#26159;&#29616;&#20195;&#32479;&#35745;&#23398;&#21644;&#25968;&#25454;&#31185;&#23398;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#20219;&#21153;&#12290;&#35768;&#22810;&#25968;&#25454;&#38598;&#65288;&#32454;&#32990;&#12289;&#25991;&#26723;&#12289;&#22270;&#20687;&#12289;&#20998;&#23376;&#65289;&#21487;&#20197;&#34987;&#34920;&#31034;&#20026;&#23884;&#20837;&#22312;&#39640;&#32500;&#29615;&#22659;&#31354;&#38388;&#20013;&#30340;&#28857;&#20113;&#65292;&#28982;&#32780;&#25968;&#25454;&#22266;&#26377;&#30340;&#33258;&#30001;&#24230;&#36890;&#24120;&#36828;&#36828;&#23569;&#20110;&#29615;&#22659;&#32500;&#24230;&#30340;&#25968;&#37327;&#12290;&#26816;&#27979;&#25968;&#25454;&#23884;&#20837;&#30340;&#28508;&#22312;&#27969;&#24418;&#26159;&#35768;&#22810;&#19979;&#28216;&#20998;&#26512;&#30340;&#20808;&#20915;&#26465;&#20214;&#12290;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#32463;&#24120;&#21463;&#21040;&#22122;&#22768;&#35266;&#27979;&#21644;&#25277;&#26679;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#25552;&#21462;&#20851;&#20110;&#28508;&#22312;&#27969;&#24418;&#30340;&#20449;&#24687;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#23545;&#31216;&#29256;&#26412;&#30340;&#26368;&#20248;&#20256;&#36755;&#21644;&#20108;&#27425;&#27491;&#21017;&#21270;&#30340;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#26500;&#24314;&#20102;&#19968;&#20010;&#31232;&#30095;&#33258;&#36866;&#24212;&#30340;&#20146;&#21644;&#30697;&#38453;&#65292;&#21487;&#20197;&#35299;&#37322;&#20026;&#21452;&#38543;&#26426;&#26680;&#24402;&#19968;&#21270;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36830;&#32493;&#26497;&#38480;&#19979;&#20135;&#29983;&#30340;&#26680;&#19982;&#25289;&#26222;&#25289;&#26031;&#22411;&#31639;&#23376;&#19968;&#33268;&#65292;&#24182;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#20581;&#22766;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manifold learning is a central task in modern statistics and data science. Many datasets (cells, documents, images, molecules) can be represented as point clouds embedded in a high dimensional ambient space, however the degrees of freedom intrinsic to the data are usually far fewer than the number of ambient dimensions. The task of detecting a latent manifold along which the data are embedded is a prerequisite for a wide family of downstream analyses. Real-world datasets are subject to noisy observations and sampling, so that distilling information about the underlying manifold is a major challenge. We propose a method for manifold learning that utilises a symmetric version of optimal transport with a quadratic regularisation that constructs a sparse and adaptive affinity matrix, that can be interpreted as a generalisation of the bistochastic kernel normalisation. We prove that the resulting kernel is consistent with a Laplace-type operator in the continuous limit, establish robustness
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#20998;&#31867;&#65292;&#36890;&#36807;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20197;&#34920;&#31034;&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#21644;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20272;&#35745;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05772</link><description>&lt;p&gt;
&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning. (arXiv:2307.05772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05772
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#20998;&#31867;&#65292;&#36890;&#36807;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20197;&#34920;&#31034;&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#21644;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20272;&#35745;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#65292;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#38169;&#35823;&#30340;&#39044;&#27979;&#21487;&#33021;&#23548;&#33268;&#28508;&#22312;&#30340;&#28798;&#38590;&#24615;&#21518;&#26524;&#12290;&#36825;&#31361;&#20986;&#20102;&#23398;&#20064;&#31995;&#32479;&#38656;&#35201;&#33021;&#22815;&#30830;&#23450;&#27169;&#22411;&#23545;&#20854;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#20197;&#21450;&#19982;&#20043;&#30456;&#20851;&#32852;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#30340;&#25163;&#27573;&#65292;&#8220;&#30693;&#36947;&#19968;&#20010;&#27169;&#22411;&#19981;&#30693;&#36947;&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#20998;&#31867;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#65292;&#20854;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20351;&#29992;&#38543;&#26426;&#38598;&#21512;&#30340;&#25968;&#23398;&#65292;&#21363;&#23545;&#26679;&#26412;&#31354;&#38388;&#30340;&#24130;&#38598;&#30340;&#20998;&#24067;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#38543;&#26426;&#38598;&#27169;&#22411;&#33021;&#22815;&#34920;&#31034;&#26426;&#22120;&#23398;&#20064;&#20013;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#8220;&#35748;&#35782;&#24615;&#8221;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#36817;&#20284;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#30456;&#20851;&#32852;&#30340;&#32622;&#20449;&#38598;&#30340;&#22823;&#23567;&#26469;&#20272;&#35745;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning is increasingly deployed in safety-critical domains where robustness against adversarial attacks is crucial and erroneous predictions could lead to potentially catastrophic consequences. This highlights the need for learning systems to be equipped with the means to determine a model's confidence in its prediction and the epistemic uncertainty associated with it, 'to know when a model does not know'. In this paper, we propose a novel Random-Set Convolutional Neural Network (RS-CNN) for classification which predicts belief functions rather than probability vectors over the set of classes, using the mathematics of random sets, i.e., distributions over the power set of the sample space. Based on the epistemic deep learning approach, random-set models are capable of representing the 'epistemic' uncertainty induced in machine learning by limited training sets. We estimate epistemic uncertainty by approximating the size of credal sets associated with the predicted belief func
&lt;/p&gt;</description></item></channel></rss>