<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24369;&#26465;&#20214;&#19979;&#33719;&#24471;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23454;&#29616;&#26041;&#24046;&#20943;&#23569;&#30340;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2402.08992</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#26041;&#24046;&#20943;&#23569;&#21644;&#20302;&#26679;&#26412;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Variance Reduction and Low Sample Complexity in Stochastic Optimization via Proximal Point Method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24369;&#26465;&#20214;&#19979;&#33719;&#24471;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23454;&#29616;&#26041;&#24046;&#20943;&#23569;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#36817;&#31471;&#28857;&#27861;&#26469;&#35299;&#20915;&#38543;&#26426;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#39640;&#27010;&#29575;&#32467;&#26524;&#36890;&#24120;&#20381;&#36182;&#20110;&#23545;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#20363;&#22914;&#23376;&#39640;&#26031;&#20998;&#24067;&#12290;&#26412;&#25991;&#21482;&#20551;&#35774;&#20102;&#38543;&#26426;&#26799;&#24230;&#30340;&#26377;&#30028;&#26041;&#24046;&#31561;&#24369;&#26465;&#20214;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#20197;&#33719;&#24471;&#20851;&#20110;&#25152;&#25552;&#26041;&#27861;&#25910;&#25947;&#30340;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#26412;&#24037;&#20316;&#30340;&#19968;&#20010;&#26174;&#33879;&#26041;&#38754;&#26159;&#21457;&#23637;&#20102;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#36817;&#31471;&#23376;&#38382;&#39064;&#30340;&#23376;&#31243;&#24207;&#65292;&#23427;&#21516;&#26102;&#20063;&#26159;&#19968;&#31181;&#29992;&#20110;&#20943;&#23569;&#26041;&#24046;&#30340;&#26032;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08992v1 Announce Type: cross Abstract: This paper proposes a stochastic proximal point method to solve a stochastic convex composite optimization problem. High probability results in stochastic optimization typically hinge on restrictive assumptions on the stochastic gradient noise, for example, sub-Gaussian distributions. Assuming only weak conditions such as bounded variance of the stochastic gradient, this paper establishes a low sample complexity to obtain a high probability guarantee on the convergence of the proposed method. Additionally, a notable aspect of this work is the development of a subroutine to solve the proximal subproblem, which also serves as a novel technique for variance reduction.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2212.04382</link><description>&lt;p&gt;
&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#65306;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.04382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#35770;&#22522;&#20110;&#27169;&#22411;&#12289;&#35757;&#32451;&#25968;&#25454;&#36824;&#26159;&#20108;&#32773;&#32452;&#21512;&#65292;&#20998;&#31867;&#22120;&#23558;&#65288;&#21487;&#33021;&#22797;&#26434;&#30340;&#65289;&#36755;&#20837;&#25968;&#25454;&#24402;&#20837;&#30456;&#23545;&#36739;&#23569;&#30340;&#36755;&#20986;&#31867;&#21035;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#22312;&#36755;&#20837;&#31354;&#38388;&#20026;&#22270;&#30340;&#24773;&#20917;&#19979;&#65292;&#36793;&#30028;&#30340;&#32467;&#26500;&#8212;&#8212;&#37027;&#20123;&#34987;&#20998;&#31867;&#20026;&#19981;&#21516;&#31867;&#21035;&#30340;&#37051;&#36817;&#28857;&#8212;&#8212;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#30340;&#31185;&#23398;&#32972;&#26223;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#30001;&#19979;&#19968;&#20195;&#27979;&#24207;&#20202;&#29983;&#25104;&#30340;DNA&#35835;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36793;&#30028;&#26082;&#26159;&#24040;&#22823;&#30340;&#65292;&#21448;&#20855;&#26377;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#23427;&#23558;&#19968;&#20010;&#28857;&#30340;&#32467;&#26524;&#19982;&#20854;&#37051;&#23621;&#30340;&#32467;&#26524;&#20998;&#24067;&#36827;&#34892;&#27604;&#36739;&#12290;&#36825;&#20010;&#24230;&#37327;&#19981;&#20165;&#36861;&#36394;&#20102;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#20004;&#20010;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#36824;&#21487;&#20197;&#22312;&#27809;&#26377;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#30340;&#20998;&#31867;&#22120;&#19978;&#23454;&#29616;&#65292;&#20294;&#38656;&#35201;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether based on models, training data or a combination, classifiers place (possibly complex) input data into one of a relatively small number of output categories. In this paper, we study the structure of the boundary--those points for which a neighbor is classified differently--in the context of an input space that is a graph, so that there is a concept of neighboring inputs, The scientific setting is a model-based naive Bayes classifier for DNA reads produced by Next Generation Sequencers. We show that the boundary is both large and complicated in structure. We create a new measure of uncertainty, called Neighbor Similarity, that compares the result for a point to the distribution of results for its neighbors. This measure not only tracks two inherent uncertainty measures for the Bayes classifier, but also can be implemented, at a computational cost, for classifiers without inherent measures of uncertainty.
&lt;/p&gt;</description></item><item><title>&#26631;&#20934;&#21270;&#24402;&#19968;&#20114;&#20449;&#24687;&#26159;&#19968;&#31181;&#20559;&#20506;&#24230;&#37327;&#65292;&#22240;&#20026;&#23427;&#24573;&#30053;&#20102;&#26465;&#20214;&#34920;&#30340;&#20449;&#24687;&#20869;&#23481;&#24182;&#19988;&#23545;&#31639;&#27861;&#36755;&#20986;&#26377;&#22122;&#22768;&#20381;&#36182;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#29256;&#26412;&#30340;&#20114;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#23545;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#30340;&#27979;&#35797;&#35777;&#26126;&#20102;&#20351;&#29992;&#26080;&#20559;&#24230;&#37327;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.01282</link><description>&lt;p&gt;
&#26631;&#20934;&#21270;&#24402;&#19968;&#20114;&#20449;&#24687;&#26159;&#20998;&#31867;&#21644;&#31038;&#21306;&#26816;&#27979;&#30340;&#19968;&#31181;&#20559;&#20506;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Normalized mutual information is a biased measure for classification and community detection. (arXiv:2307.01282v1 [cs.SI] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01282
&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#21270;&#24402;&#19968;&#20114;&#20449;&#24687;&#26159;&#19968;&#31181;&#20559;&#20506;&#24230;&#37327;&#65292;&#22240;&#20026;&#23427;&#24573;&#30053;&#20102;&#26465;&#20214;&#34920;&#30340;&#20449;&#24687;&#20869;&#23481;&#24182;&#19988;&#23545;&#31639;&#27861;&#36755;&#20986;&#26377;&#22122;&#22768;&#20381;&#36182;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#29256;&#26412;&#30340;&#20114;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#23545;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#31639;&#27861;&#30340;&#27979;&#35797;&#35777;&#26126;&#20102;&#20351;&#29992;&#26080;&#20559;&#24230;&#37327;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#24402;&#19968;&#20114;&#20449;&#24687;&#34987;&#24191;&#27867;&#29992;&#20316;&#35780;&#20272;&#32858;&#31867;&#21644;&#20998;&#31867;&#31639;&#27861;&#24615;&#33021;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#12290;&#26412;&#25991;&#34920;&#26126;&#26631;&#20934;&#21270;&#24402;&#19968;&#20114;&#20449;&#24687;&#30340;&#32467;&#26524;&#26377;&#20004;&#20010;&#20559;&#20506;&#22240;&#32032;&#65306;&#39318;&#20808;&#65292;&#22240;&#20026;&#23427;&#20204;&#24573;&#30053;&#20102;&#26465;&#20214;&#34920;&#30340;&#20449;&#24687;&#20869;&#23481;&#65307;&#20854;&#27425;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#23545;&#31216;&#24402;&#19968;&#21270;&#24341;&#20837;&#20102;&#23545;&#31639;&#27861;&#36755;&#20986;&#30340;&#22122;&#22768;&#20381;&#36182;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#29256;&#26412;&#30340;&#20114;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#32570;&#38519;&#12290;&#36890;&#36807;&#23545;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#20013;&#19968;&#31726;&#23376;&#27969;&#34892;&#31639;&#27861;&#36827;&#34892;&#22823;&#37327;&#25968;&#20540;&#27979;&#35797;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#26080;&#20559;&#24230;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#19988;&#26174;&#31034;&#20256;&#32479;&#20114;&#20449;&#24687;&#20013;&#30340;&#20559;&#20506;&#23545;&#36873;&#25321;&#26368;&#20339;&#31639;&#27861;&#30340;&#32467;&#35770;&#20135;&#29983;&#20102;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalized mutual information is widely used as a similarity measure for evaluating the performance of clustering and classification algorithms. In this paper, we show that results returned by the normalized mutual information are biased for two reasons: first, because they ignore the information content of the contingency table and, second, because their symmetric normalization introduces spurious dependence on algorithm output. We introduce a modified version of the mutual information that remedies both of these shortcomings. As a practical demonstration of the importance of using an unbiased measure, we perform extensive numerical tests on a basket of popular algorithms for network community detection and show that one's conclusions about which algorithm is best are significantly affected by the biases in the traditional mutual information.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#20989;&#25968;&#37325;&#26500;&#38543;&#26426;&#21464;&#37327;X&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#25968;&#25454;&#31232;&#21270;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#65292;&#24182;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.12931</link><description>&lt;p&gt;
&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#24191;&#20041;&#25968;&#25454;&#31232;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalized Data Thinning Using Sufficient Statistics. (arXiv:2303.12931v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#23637;&#20102;&#19968;&#31181;&#22522;&#20110;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#20989;&#25968;&#37325;&#26500;&#38543;&#26426;&#21464;&#37327;X&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#25968;&#25454;&#31232;&#21270;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#65292;&#24182;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;&#19968;&#31181;&#23558;&#38543;&#26426;&#21464;&#37327;X&#20998;&#35299;&#20026;&#22810;&#20010;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#32780;&#19981;&#20250;&#20002;&#22833;&#20219;&#20309;&#26377;&#20851;&#26410;&#30693;&#21442;&#25968;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#36890;&#36807;&#26494;&#24347;&#27714;&#21644;&#35201;&#27714;&#24182;&#20165;&#35201;&#27714;&#19968;&#20123;&#24050;&#30693;&#30340;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#30340;&#20989;&#25968;&#23436;&#20840;&#37325;&#26500;X&#26469;&#25512;&#24191;&#20102;&#26368;&#36817;&#19968;&#31687;&#35770;&#25991;&#30340;&#36807;&#31243;&#12290;&#35813;&#36807;&#31243;&#30340;&#25512;&#24191;&#26377;&#20004;&#20010;&#30446;&#30340;&#12290;&#39318;&#20808;&#65292;&#23427;&#26497;&#22823;&#22320;&#25193;&#23637;&#20102;&#21487;&#36827;&#34892;&#31232;&#21270;&#30340;&#20998;&#24067;&#26063;&#12290;&#20854;&#27425;&#65292;&#23427;&#32479;&#19968;&#20102;&#26679;&#26412;&#20998;&#35010;&#21644;&#25968;&#25454;&#31232;&#21270;&#65292;&#23427;&#20204;&#22312;&#34920;&#38754;&#19978;&#20284;&#20046;&#38750;&#24120;&#19981;&#21516;&#65292;&#20294;&#24212;&#29992;&#20102;&#21516;&#26679;&#30340;&#21407;&#29702;&#12290;&#36825;&#20010;&#20849;&#21516;&#30340;&#21407;&#29702;&#26159;&#20805;&#20998;&#24615;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#35748;&#35782;&#23545;&#21508;&#31181;&#19981;&#21516;&#30340;&#23478;&#26063;&#36827;&#34892;&#24191;&#20041;&#31232;&#30095;&#21270;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our goal is to develop a general strategy to decompose a random variable $X$ into multiple independent random variables, without sacrificing any information about unknown parameters. A recent paper showed that for some well-known natural exponential families, $X$ can be "thinned" into independent random variables $X^{(1)}, \ldots, X^{(K)}$, such that $X = \sum_{k=1}^K X^{(k)}$. In this paper, we generalize their procedure by relaxing this summation requirement and simply asking that some known function of the independent random variables exactly reconstruct $X$. This generalization of the procedure serves two purposes. First, it greatly expands the families of distributions for which thinning can be performed. Second, it unifies sample splitting and data thinning, which on the surface seem to be very different, as applications of the same principle. This shared principle is sufficiency. We use this insight to perform generalized thinning operations for a diverse set of families.
&lt;/p&gt;</description></item></channel></rss>