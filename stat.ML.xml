<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20026;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#24102;&#26469;&#26032;&#39062;&#35270;&#35282;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#26631;&#20934;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#20989;&#25968;&#36924;&#36817;&#30340;&#21306;&#21035;&#12290;</title><link>https://arxiv.org/abs/2403.09621</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#20998;&#24067;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09621
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20026;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#24102;&#26469;&#26032;&#39062;&#35270;&#35282;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#26631;&#20934;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#20989;&#25968;&#36924;&#36817;&#30340;&#21306;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#23547;&#27714;&#38024;&#23545;&#29615;&#22659;&#25200;&#21160;&#30340;&#40065;&#26834;&#31574;&#30053;&#35757;&#32451;&#65292;&#36890;&#36807;&#24314;&#27169;&#21160;&#24577;&#19981;&#30830;&#23450;&#24615;&#26469;&#35843;&#29992;&#20989;&#25968;&#36924;&#36817;&#65292;&#24403;&#38754;&#23545;&#24222;&#22823;&#30340;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#26102;&#65292;&#36825;&#31181;RL&#38656;&#35201;&#32771;&#34385;&#21040;&#21160;&#24577;&#19981;&#30830;&#23450;&#24615;&#65292;&#24341;&#20837;&#20102;&#22522;&#26412;&#30340;&#38750;&#32447;&#24615;&#21644;&#35745;&#31639;&#36127;&#25285;&#65292;&#36825;&#32473;&#20998;&#26512;&#21644;&#23454;&#38469;&#24212;&#29992;&#20989;&#25968;&#36924;&#36817;&#25552;&#20986;&#20102;&#29420;&#29305;&#25361;&#25112;&#12290;&#22312;&#22522;&#26412;&#35774;&#32622;&#19979;&#65292;&#25552;&#35758;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20989;&#25968;&#36924;&#36817;&#65292;&#24182;&#22312;&#40065;&#26834;&#31163;&#32447;RL&#30340;&#32972;&#26223;&#19979;&#21551;&#21160;&#23545;&#23454;&#20363;&#30456;&#20851;&#27425;&#20248;&#24615;&#20998;&#26512;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#40065;&#26834;&#31163;&#32447;RL&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#26412;&#36136;&#19978;&#19982;&#26631;&#20934;&#31163;&#32447;RL&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#26377;&#26126;&#26174;&#21306;&#21035;&#65292;&#21487;&#33021;&#26356;&#21152;&#22256;&#38590;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#29702;&#35770;&#32467;&#26524;&#33267;&#20851;&#37325;&#35201;&#22320;&#20381;&#36182;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09621v1 Announce Type: cross  Abstract: Distributionally robust offline reinforcement learning (RL), which seeks robust policy training against environment perturbation by modeling dynamics uncertainty, calls for function approximations when facing large state-action spaces. However, the consideration of dynamics uncertainty introduces essential nonlinearity and computational burden, posing unique challenges for analyzing and practically employing function approximation. Focusing on a basic setting where the nominal model and perturbed models are linearly parameterized, we propose minimax optimal and computationally efficient algorithms realizing function approximation and initiate the study on instance-dependent suboptimality analysis in the context of robust offline RL. Our results uncover that function approximation in robust offline RL is essentially distinct from and probably harder than that in standard offline RL. Our algorithms and theoretical results crucially depen
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#38382;&#39064;&#65292;&#22312;&#28176;&#36817;&#21644;&#38750;&#28176;&#36817;&#35774;&#32622;&#20013;&#25552;&#20986;&#20102;Tri-BBAI&#21644;Opt-BBAI&#31639;&#27861;&#65292;&#20998;&#21035;&#23454;&#29616;&#20102;&#26368;&#20248;&#21644;&#20960;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.14129</link><description>&lt;p&gt;
&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#30340;&#26368;&#20339;&#25209;&#22788;&#29702;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Batched Best Arm Identification. (arXiv:2310.14129v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#38382;&#39064;&#65292;&#22312;&#28176;&#36817;&#21644;&#38750;&#28176;&#36817;&#35774;&#32622;&#20013;&#25552;&#20986;&#20102;Tri-BBAI&#21644;Opt-BBAI&#31639;&#27861;&#65292;&#20998;&#21035;&#23454;&#29616;&#20102;&#26368;&#20248;&#21644;&#20960;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#20339;&#25209;&#22788;&#29702;&#27494;&#22120;&#35782;&#21035;&#65288;BBAI&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#22312;&#23613;&#37327;&#23569;&#22320;&#26356;&#25442;&#31574;&#30053;&#30340;&#21516;&#26102;&#35782;&#21035;&#20986;&#26368;&#20339;&#27494;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20197;&#27010;&#29575;$1-\delta$&#25214;&#21040;&#26368;&#20339;&#27494;&#22120;&#65292;&#20854;&#20013;$\delta&gt;0$&#26159;&#19968;&#20010;&#23567;&#24120;&#25968;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#26679;&#26412;&#22797;&#26434;&#24230;&#65288;&#27494;&#22120;&#25289;&#21462;&#30340;&#24635;&#25968;&#65289;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#65288;&#25209;&#22788;&#29702;&#30340;&#24635;&#25968;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#25209;&#27425;&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#65288;Tri-BBAI&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#28176;&#36817;&#35774;&#32622;&#65288;&#21363;$\delta\rightarrow0$&#65289;&#20013;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#19988;&#20165;&#22312;&#26368;&#22810;&#19977;&#20010;&#25209;&#27425;&#20013;&#36816;&#34892;&#30340;&#25209;&#22788;&#29702;&#31639;&#27861;&#12290;&#22522;&#20110;Tri-BBAI&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#20960;&#20046;&#26368;&#20248;&#30340;&#25209;&#22788;&#29702;&#26368;&#20339;&#27494;&#22120;&#35782;&#21035;&#65288;Opt-BBAI&#65289;&#31639;&#27861;&#65292;&#22312;&#38750;&#28176;&#36817;&#35774;&#32622;&#65288;&#21363;$\delta&gt;0$&#26159;&#20219;&#24847;&#22266;&#23450;&#30340;&#65289;&#20013;&#23454;&#29616;&#36817;&#20284;&#26368;&#20248;&#30340;&#26679;&#26412;&#21644;&#25209;&#22788;&#29702;&#22797;&#26434;&#24230;&#65292;&#21516;&#26102;&#22312;$\delta$&#36235;&#20110;&#38646;&#26102;&#20139;&#21463;&#19982;Tri-BBAI&#30456;&#21516;&#30340;&#25209;&#22788;&#29702;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the batched best arm identification (BBAI) problem, where the learner's goal is to identify the best arm while switching the policy as less as possible. In particular, we aim to find the best arm with probability $1-\delta$ for some small constant $\delta&gt;0$ while minimizing both the sample complexity (total number of arm pulls) and the batch complexity (total number of batches). We propose the three-batch best arm identification (Tri-BBAI) algorithm, which is the first batched algorithm that achieves the optimal sample complexity in the asymptotic setting (i.e., $\delta\rightarrow 0$) and runs only in at most $3$ batches. Based on Tri-BBAI, we further propose the almost optimal batched best arm identification (Opt-BBAI) algorithm, which is the first algorithm that achieves the near-optimal sample and batch complexity in the non-asymptotic setting (i.e., $\delta&gt;0$ is arbitrarily fixed), while enjoying the same batch and sample complexity as Tri-BBAI when $\delta$ tends to zer
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#26694;&#26550;&#65288;ScoreAG&#65289;&#65292;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#24182;&#36890;&#36807;&#22270;&#20687;&#36716;&#25442;&#25110;&#26032;&#22270;&#20687;&#21512;&#25104;&#30340;&#26041;&#27861;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.04285</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#22270;&#20687;&#29983;&#25104;&#35780;&#20272;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing Robustness via Score-Based Adversarial Image Generation. (arXiv:2310.04285v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#26694;&#26550;&#65288;ScoreAG&#65289;&#65292;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#24182;&#36890;&#36807;&#22270;&#20687;&#36716;&#25442;&#25110;&#26032;&#22270;&#20687;&#21512;&#25104;&#30340;&#26041;&#27861;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#23545;&#25239;&#25915;&#20987;&#21644;&#38450;&#24481;&#37117;&#38598;&#20013;&#22312;&#23567;&#30340;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#20869;&#30340;&#25200;&#21160;&#19978;&#12290;&#28982;&#32780;&#65292;$\ell_p$&#23041;&#32961;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#21040;&#25152;&#26377;&#30456;&#20851;&#30340;&#20445;&#30041;&#35821;&#20041;&#30340;&#25200;&#21160;&#65292;&#22240;&#27492;&#65292;&#40065;&#26834;&#24615;&#35780;&#20272;&#30340;&#33539;&#22260;&#26159;&#26377;&#38480;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#65288;ScoreAG&#65289;&#65292;&#19968;&#31181;&#21033;&#29992;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#36827;&#23637;&#26469;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#26080;&#38480;&#21046;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#20811;&#26381;&#20102;&#23427;&#20204;&#30340;&#23616;&#38480;&#24615;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;ScoreAG&#22312;&#29983;&#25104;&#36924;&#30495;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#26102;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#21487;&#20197;&#36890;&#36807;&#36716;&#25442;&#29616;&#26377;&#22270;&#20687;&#25110;&#23436;&#20840;&#20174;&#38646;&#24320;&#22987;&#21512;&#25104;&#26032;&#22270;&#20687;&#30340;&#26041;&#24335;&#23454;&#29616;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21033;&#29992;ScoreAG&#30340;&#29983;&#25104;&#33021;&#21147;&#26469;&#20928;&#21270;&#22270;&#20687;&#65292;&#20174;&#32463;&#39564;&#19978;&#22686;&#24378;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;ScoreAG&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#30340;&#24615;&#33021;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most adversarial attacks and defenses focus on perturbations within small $\ell_p$-norm constraints. However, $\ell_p$ threat models cannot capture all relevant semantic-preserving perturbations, and hence, the scope of robustness evaluations is limited. In this work, we introduce Score-Based Adversarial Generation (ScoreAG), a novel framework that leverages the advancements in score-based generative models to generate adversarial examples beyond $\ell_p$-norm constraints, so-called unrestricted adversarial examples, overcoming their limitations. Unlike traditional methods, ScoreAG maintains the core semantics of images while generating realistic adversarial examples, either by transforming existing images or synthesizing new ones entirely from scratch. We further exploit the generative capability of ScoreAG to purify images, empirically enhancing the robustness of classifiers. Our extensive empirical evaluation demonstrates that ScoreAG matches the performance of state-of-the-art atta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376; Langevin &#31639;&#27861;&#65292;&#29992;&#20110;&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#12290;&#20351;&#29992;&#27492;&#31639;&#27861;&#65292;&#20272;&#35745;&#22120;&#30340;&#20248;&#21270;&#35823;&#24046;&#20855;&#26377;&#38750;&#28176;&#36817;&#27987;&#24230;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.13429</link><description>&lt;p&gt;
&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376; Langevin &#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Interacting Particle Langevin Algorithm for Maximum Marginal Likelihood Estimation. (arXiv:2303.13429v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376; Langevin &#31639;&#27861;&#65292;&#29992;&#20110;&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#12290;&#20351;&#29992;&#27492;&#31639;&#27861;&#65292;&#20272;&#35745;&#22120;&#30340;&#20248;&#21270;&#35823;&#24046;&#20855;&#26377;&#38750;&#28176;&#36817;&#27987;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#29992;&#20110;&#23454;&#29616;&#28508;&#21464;&#37327;&#27169;&#22411;&#21442;&#25968;&#30340;&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#36807;&#31243;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#23427;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#22312;&#25193;&#23637;&#30340;&#29366;&#24577;&#31354;&#38388;&#19978;&#30340; Langevin&#28418;&#31227;&#65292;&#20854;&#20013;&#22312;&#32463;&#20856;&#30340;&#20248;&#21270;&#20013;&#65292;&#31890;&#23376;&#25968;&#37327;&#20316;&#20026;&#30456;&#21453;&#28201;&#24230;&#21442;&#25968;&#12290;&#20351;&#29992;Langevin&#28418;&#31227;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26368;&#22823;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#20248;&#21270;&#35823;&#24046;&#30340;&#38750;&#28176;&#36817;&#27987;&#24230;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19982;&#31890;&#23376;&#31995;&#32479;&#20013;&#30340;&#31890;&#23376;&#25968;&#37327;&#65292;&#31639;&#27861;&#30340;&#36845;&#20195;&#27425;&#25968;&#20197;&#21450;&#26102;&#38388;&#31163;&#25955;&#21270;&#20998;&#26512;&#30340;&#27493;&#38271;&#21442;&#25968;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a class of interacting particle systems for implementing a marginal maximum likelihood estimation (MLE) procedure to optimize over the parameters of a latent variable model. To do so, we propose a continuous-time interacting particle system which can be seen as a Langevin diffusion over an extended state space, where the number of particles acts as the inverse temperature parameter in classical settings for optimisation. Using Langevin diffusions, we prove nonasymptotic concentration bounds for the optimisation error of the maximum marginal likelihood estimator in terms of the number of particles in the particle system, the number of iterations of the algorithm, and the step-size parameter for the time discretisation analysis.
&lt;/p&gt;</description></item></channel></rss>