<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32447;&#24615;&#35889;&#32479;&#35745;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#38750;&#24120;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#25152;&#26377;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#27979;&#35797;&#20013;&#65292;&#23454;&#29616;&#20102;&#31867;&#22411; I &#21644;&#31867;&#22411; II &#38169;&#35823;&#29575;&#20043;&#38388;&#30340;&#26368;&#20339;&#26435;&#34913;&#26354;&#32447;&#12290;</title><link>http://arxiv.org/abs/2311.00289</link><description>&lt;p&gt;
&#39640;&#25928;&#27979;&#35797;&#30340;&#31934;&#30830;&#38169;&#35823;&#29575;
&lt;/p&gt;
&lt;p&gt;
Precise Error Rates for Computationally Efficient Testing. (arXiv:2311.00289v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00289
&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32447;&#24615;&#35889;&#32479;&#35745;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#38750;&#24120;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#25152;&#26377;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#27979;&#35797;&#20013;&#65292;&#23454;&#29616;&#20102;&#31867;&#22411; I &#21644;&#31867;&#22411; II &#38169;&#35823;&#29575;&#20043;&#38388;&#30340;&#26368;&#20339;&#26435;&#34913;&#26354;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#31616;&#21333;&#19982;&#31616;&#21333;&#20551;&#35774;&#26816;&#39564;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#22240;&#20026;&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#65292;&#32479;&#35745;&#19978;&#26368;&#20248;&#30340;&#20284;&#28982;&#27604;&#26816;&#39564;&#36890;&#24120;&#26159;&#35745;&#31639;&#19978;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#22312;&#32463;&#20856;&#30340;&#23574;&#23792;&#32500;&#26684;&#32435;&#27169;&#22411;&#65288;&#20855;&#26377;&#19968;&#33324;&#24615; i.i.d. &#23574;&#23792;&#20808;&#39564;&#65289;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#22522;&#20110;&#32447;&#24615;&#35889;&#32479;&#35745;&#30340;&#29616;&#26377;&#27979;&#35797;&#23454;&#29616;&#20102;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#27979;&#35797;&#20043;&#38388;&#30340;&#26368;&#20339;&#26435;&#34913;&#26354;&#32447;&#65292;&#21363;&#20351;&#23384;&#22312;&#26356;&#22909;&#30340;&#25351;&#25968;&#26102;&#38388;&#27979;&#35797;&#12290;&#36825;&#20010;&#32467;&#26524;&#26159;&#22312;&#19968;&#20010;&#36866;&#24403;&#22797;&#26434;&#24615;&#29702;&#35770;&#30340;&#29468;&#24819;&#26465;&#20214;&#19979;&#24471;&#21040;&#30340;&#65292;&#21363;&#19968;&#20010;&#33258;&#28982;&#21152;&#24378;&#24050;&#32463;&#24314;&#31435;&#30340;&#20302;&#27425;&#25968;&#29468;&#24819;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#35889;&#26159;&#35745;&#31639;&#21463;&#38480;&#30340;&#27979;&#35797;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65288;&#20294;&#19981;&#26159;&#25152;&#26377;&#27979;&#35797;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65289;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#39318;&#20010;&#29992;&#20110;&#25512;&#29702;&#20851;&#20110;&#26377;&#25928;&#35745;&#31639;&#25152;&#33021;&#23454;&#29616;&#30340;&#31934;&#30830;&#28176;&#36817;&#27979;&#35797;&#35823;&#24046;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit the fundamental question of simple-versus-simple hypothesis testing with an eye towards computational complexity, as the statistically optimal likelihood ratio test is often computationally intractable in high-dimensional settings. In the classical spiked Wigner model (with a general i.i.d. spike prior) we show that an existing test based on linear spectral statistics achieves the best possible tradeoff curve between type I and type II error rates among all computationally efficient tests, even though there are exponential-time tests that do better. This result is conditional on an appropriate complexity-theoretic conjecture, namely a natural strengthening of the well-established low-degree conjecture. Our result shows that the spectrum is a sufficient statistic for computationally bounded tests (but not for all tests).  To our knowledge, our approach gives the first tool for reasoning about the precise asymptotic testing error achievable with efficient computation. The main
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;</title><link>http://arxiv.org/abs/2310.16705</link><description>&lt;p&gt;
&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#27969;&#22312;&#21464;&#20998;&#25512;&#26029;&#30340;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gradient Flow over Variational Parameter Space for Variational Inference. (arXiv:2310.16705v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#21464;&#20998;&#21442;&#25968;&#34987;&#35843;&#25972;&#20197;&#20351;&#21464;&#20998;&#20998;&#24067;&#19982;&#30495;&#23454;&#21518;&#39564;&#23613;&#21487;&#33021;&#25509;&#36817;&#12290;&#21487;&#20197;&#36890;&#36807;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#26222;&#36890;&#26799;&#24230;&#19979;&#38477;&#25110;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#26469;&#35299;&#20915;&#20248;&#21270;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#19968;&#20010;&#8220;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#8221;&#20013;&#23450;&#20041;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#20248;&#21270;&#25216;&#26415;&#65292;&#21363;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#21644;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#65292;&#21487;&#20197;&#37325;&#26032;&#35299;&#37322;&#20026;&#25152;&#25552;&#20986;&#30340;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#30340;&#29305;&#23450;&#23454;&#20363;&#12290;&#20026;&#20102;&#25552;&#39640;&#20248;&#21270;&#25928;&#29575;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#23454;&#29992;&#30340;&#26041;&#27861;&#26469;&#25968;&#20540;&#27714;&#35299;&#31163;&#25955;&#26799;&#24230;&#27969;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference (VI) can be cast as an optimization problem in which the variational parameters are tuned to closely align a variational distribution with the true posterior. The optimization task can be approached through vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient VI. In this work, we reframe VI as the optimization of an objective that concerns probability distributions defined over a \textit{variational parameter space}. Subsequently, we propose Wasserstein gradient descent for tackling this optimization problem. Notably, the optimization techniques, namely black-box VI and natural-gradient VI, can be reinterpreted as specific instances of the proposed Wasserstein gradient descent. To enhance the efficiency of optimization, we develop practical methods for numerically solving the discrete gradient flows. We validate the effectiveness of the proposed methods through empirical experiments on a synthetic dataset, supplemented by theore
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#22312;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2307.14530</link><description>&lt;p&gt;
&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimation in Mixed-Membership Stochastic Block Models. (arXiv:2307.14530v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#22312;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#29616;&#20195;&#32593;&#32476;&#31185;&#23398;&#20013;&#26368;&#20851;&#38190;&#30340;&#38382;&#39064;&#20043;&#19968;&#12290;&#20854;&#24212;&#29992;&#21487;&#20197;&#22312;&#21508;&#20010;&#39046;&#22495;&#25214;&#21040;&#65292;&#20174;&#34507;&#30333;&#36136;&#24314;&#27169;&#21040;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#12290;&#26368;&#36817;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#35770;&#25991;&#30740;&#31350;&#37325;&#21472;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#21363;&#32593;&#32476;&#20013;&#30340;&#27599;&#20010;&#33410;&#28857;&#21487;&#33021;&#23646;&#20110;&#22810;&#20010;&#31038;&#21306;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#30001;Airoldi&#31561;&#20154;&#65288;2008&#65289;&#39318;&#27425;&#25552;&#20986;&#30340;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;MMSB&#65289;&#12290;MMSB&#22312;&#22270;&#20013;&#23545;&#37325;&#21472;&#31038;&#21306;&#32467;&#26500;&#25552;&#20379;&#20102;&#30456;&#24403;&#19968;&#33324;&#30340;&#35774;&#32622;&#12290;&#26412;&#25991;&#30340;&#26680;&#24515;&#38382;&#39064;&#26159;&#22312;&#35266;&#23519;&#21040;&#30340;&#32593;&#32476;&#20013;&#37325;&#24314;&#31038;&#21306;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#36825;&#20010;&#19979;&#30028;&#21305;&#37197;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#32467;&#26524;&#22312;&#23545;&#25152;&#32771;&#34385;&#30340;&#27169;&#22411;&#30340;&#30456;&#24403;&#26222;&#36941;&#26465;&#20214;&#19979;&#24471;&#21040;&#35777;&#26126;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#26469;&#35828;&#26126;&#36825;&#20010;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community detection is one of the most critical problems in modern network science. Its applications can be found in various fields, from protein modeling to social network analysis. Recently, many papers appeared studying the problem of overlapping community detection, where each node of a network may belong to several communities. In this work, we consider Mixed-Membership Stochastic Block Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite a general setting for modeling overlapping community structure in graphs. The central question of this paper is to reconstruct relations between communities given an observed network. We compare different approaches and establish the minimax lower bound on the estimation error. Then, we propose a new estimator that matches this lower bound. Theoretical results are proved under fairly general conditions on the considered model. Finally, we illustrate the theory in a series of experiments.
&lt;/p&gt;</description></item></channel></rss>