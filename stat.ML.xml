<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#36890;&#29992;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#26102;&#30340;&#35745;&#31639;&#38590;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.03007</link><description>&lt;p&gt;
&#36890;&#29992;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Scalable Bayesian inference for the generalized linear mixed model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03007
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#36890;&#29992;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#26102;&#30340;&#35745;&#31639;&#38590;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#29992;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#65288;GLMM&#65289;&#26159;&#22788;&#29702;&#30456;&#20851;&#25968;&#25454;&#30340;&#19968;&#31181;&#27969;&#34892;&#32479;&#35745;&#26041;&#27861;&#65292;&#22312;&#21253;&#25324;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#31561;&#22823;&#25968;&#25454;&#24120;&#35265;&#30340;&#24212;&#29992;&#39046;&#22495;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#26412;&#25991;&#30340;&#37325;&#28857;&#26159;&#38024;&#23545;GLMM&#30340;&#21487;&#25193;&#23637;&#32479;&#35745;&#25512;&#26029;&#65292;&#25105;&#20204;&#23558;&#32479;&#35745;&#25512;&#26029;&#23450;&#20041;&#20026;&#65306;&#65288;i&#65289;&#23545;&#24635;&#20307;&#21442;&#25968;&#30340;&#20272;&#35745;&#20197;&#21450;&#65288;ii&#65289;&#22312;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#31185;&#23398;&#20551;&#35774;&#12290;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#23398;&#20064;&#31639;&#27861;&#25797;&#38271;&#21487;&#25193;&#23637;&#30340;&#32479;&#35745;&#20272;&#35745;&#65292;&#20294;&#24456;&#23569;&#21253;&#25324;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#25552;&#20379;&#23436;&#25972;&#30340;&#32479;&#35745;&#25512;&#26029;&#65292;&#22240;&#20026;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33258;&#21160;&#26469;&#33258;&#21518;&#39564;&#20998;&#24067;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#21253;&#25324;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#22312;&#20869;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#22312;&#22823;&#25968;&#25454;&#29615;&#22659;&#20013;&#21464;&#24471;&#38590;&#20197;&#35745;&#31639;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#35745;&#25512;&#26029;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03007v1 Announce Type: cross  Abstract: The generalized linear mixed model (GLMM) is a popular statistical approach for handling correlated data, and is used extensively in applications areas where big data is common, including biomedical data settings. The focus of this paper is scalable statistical inference for the GLMM, where we define statistical inference as: (i) estimation of population parameters, and (ii) evaluation of scientific hypotheses in the presence of uncertainty. Artificial intelligence (AI) learning algorithms excel at scalable statistical estimation, but rarely include uncertainty quantification. In contrast, Bayesian inference provides full statistical inference, since uncertainty quantification results automatically from the posterior distribution. Unfortunately, Bayesian inference algorithms, including Markov Chain Monte Carlo (MCMC), become computationally intractable in big data settings. In this paper, we introduce a statistical inference algorithm 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#19978;&#19979;&#30028;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#32622;&#29305;&#23450;&#30340;&#20989;&#25968;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#19978;&#19979;&#30028;&#38480;&#65292;&#24182;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#32852;&#31995;</title><link>https://arxiv.org/abs/2402.13662</link><description>&lt;p&gt;
&#19968;&#31181;&#30028;&#23450;&#23614;&#37096;&#27010;&#29575;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Method For Bounding Tail Probabilities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13662
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#19978;&#19979;&#30028;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#32622;&#29305;&#23450;&#30340;&#20989;&#25968;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#19978;&#19979;&#30028;&#38480;&#65292;&#24182;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#19978;&#19979;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#65288;RVs&#65289;&#30340;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#12290;&#23545;&#20110;&#20855;&#26377;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;$f_X(x)$&#30340;RV $X$&#30340;&#21491;&#23614;&#27010;&#29575;&#65292;&#35813;&#26041;&#27861;&#39318;&#20808;&#35201;&#27714;&#35774;&#32622;&#19968;&#20010;&#36830;&#32493;&#30340;&#12289;&#27491;&#30340;&#12289;&#20005;&#26684;&#36882;&#20943;&#30340;&#20989;&#25968;$g_X(x)$&#65292;&#20351;&#24471;$-f_X(x)/g'_X(x)$&#26159;&#19968;&#20010;&#36882;&#20943;&#19988;&#36882;&#22686;&#30340;&#20989;&#25968;&#65292;$\forall x&gt;x_0$&#65292;&#20998;&#21035;&#32473;&#20986;&#24418;&#24335;&#20026;$-f_X(x) g_X(x)/g'_X(x)$&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;$\forall x&gt;x_0$&#65292;&#20854;&#20013;$x_0$&#26159;&#26576;&#20010;&#28857;&#12290;&#31867;&#20284;&#22320;&#65292;&#23545;&#20110;$X$&#30340;&#24038;&#23614;&#27010;&#29575;&#30340;&#19978;&#19979;&#30028;&#65292;&#35813;&#26041;&#27861;&#39318;&#20808;&#35201;&#27714;&#35774;&#32622;&#19968;&#20010;&#36830;&#32493;&#30340;&#12289;&#27491;&#30340;&#12289;&#20005;&#26684;&#36882;&#22686;&#30340;&#20989;&#25968;$g_X(x)$&#65292;&#20351;&#24471;$f_X(x)/g'_X(x)$&#26159;&#19968;&#20010;&#22686;&#21152;&#19988;&#36882;&#20943;&#30340;&#20989;&#25968;&#65292;$\forall x&lt;x_0$&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#20989;&#25968;$g_X(x)$&#30340;&#33391;&#22909;&#20505;&#36873;&#31034;&#20363;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#26032;&#30028;&#38480;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13662v1 Announce Type: cross  Abstract: We present a method for upper and lower bounding the right and the left tail probabilities of continuous random variables (RVs). For the right tail probability of RV $X$ with probability density function $f_X(x)$, this method requires first setting a continuous, positive, and strictly decreasing function $g_X(x)$ such that $-f_X(x)/g'_X(x)$ is a decreasing and increasing function, $\forall x&gt;x_0$, which results in upper and lower bounds, respectively, given in the form $-f_X(x) g_X(x)/g'_X(x)$, $\forall x&gt;x_0$, where $x_0$ is some point. Similarly, for the upper and lower bounds on the left tail probability of $X$, this method requires first setting a continuous, positive, and strictly increasing function $g_X(x)$ such that $f_X(x)/g'_X(x)$ is an increasing and decreasing function, $\forall x&lt;x_0$. We provide some examples of good candidates for the function $g_X(x)$. We also establish connections between the new bounds and Markov's in
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#24120;&#24120;&#23548;&#33268;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25214;&#21040;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.05187</link><description>&lt;p&gt;
&#22312;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#20013;&#20803;&#23398;&#20064;&#38236;&#20687;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Meta-learning the mirror map in policy mirror descent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#24120;&#24120;&#23548;&#33268;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25214;&#21040;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#65288;PMD&#65289;&#26159;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#27969;&#34892;&#26694;&#26550;&#65292;&#20316;&#20026;&#19968;&#31181;&#32479;&#19968;&#35270;&#35282;&#65292;&#23427;&#21253;&#21547;&#20102;&#35768;&#22810;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#26159;&#36890;&#36807;&#36873;&#25321;&#19968;&#20010;&#38236;&#20687;&#26144;&#23556;&#32780;&#23548;&#20986;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26102;&#38388;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#23613;&#31649;&#23427;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#23545;PMD&#30340;&#20840;&#38754;&#28508;&#21147;&#30340;&#25506;&#32034;&#26159;&#26377;&#38480;&#30340;&#65292;&#22823;&#37096;&#20998;&#30740;&#31350;&#38598;&#20013;&#22312;&#19968;&#20010;&#29305;&#23450;&#30340;&#38236;&#20687;&#26144;&#23556;&#19978;&#65292;&#21363;&#36127;&#29109;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#33879;&#21517;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65288;NPG&#65289;&#26041;&#27861;&#12290;&#30446;&#21069;&#30340;&#29702;&#35770;&#30740;&#31350;&#36824;&#19981;&#30830;&#23450;&#38236;&#20687;&#26144;&#23556;&#30340;&#36873;&#25321;&#26159;&#21542;&#20250;&#23545;PMD&#30340;&#26377;&#25928;&#24615;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#20960;&#20010;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#32463;&#24120;&#20135;&#29983;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#24212;&#29992;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#24179;&#22343;&#24615;&#33021;&#36824;&#26159;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map -- namely, the negative entropy -- which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. By applying a meta-learning approach, we identify more efficient mirror maps that enhance performance, both on average and in terms of best performance achieved along th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.11143</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#30340;&#24503;&#22269;&#39640;&#20998;&#36776;&#29575;&#23460;&#20869;&#27681;&#27668;&#22320;&#22270;
&lt;/p&gt;
&lt;p&gt;
A new high-resolution indoor radon map for Germany using a machine learning based probabilistic exposure model. (arXiv:2310.11143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23460;&#20869;&#27681;&#27668;&#26159;&#19968;&#31181;&#33268;&#30284;&#30340;&#25918;&#23556;&#24615;&#27668;&#20307;&#65292;&#21487;&#20197;&#22312;&#23460;&#20869;&#31215;&#32047;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#20840;&#22269;&#33539;&#22260;&#20869;&#30340;&#23460;&#20869;&#27681;&#26292;&#38706;&#26159;&#22522;&#20110;&#24191;&#27867;&#30340;&#27979;&#37327;&#27963;&#21160;&#20272;&#35745;&#24471;&#26469;&#30340;&#12290;&#28982;&#32780;&#65292;&#26679;&#26412;&#30340;&#29305;&#24449;&#24448;&#24448;&#19982;&#20154;&#21475;&#29305;&#24449;&#19981;&#21516;&#65292;&#36825;&#26159;&#30001;&#20110;&#35768;&#22810;&#30456;&#20851;&#22240;&#32032;&#65292;&#22914;&#22320;&#36136;&#28304;&#27681;&#27668;&#30340;&#21487;&#29992;&#24615;&#25110;&#27004;&#23618;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#26679;&#26412;&#22823;&#23567;&#36890;&#24120;&#19981;&#20801;&#35768;&#20197;&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#36827;&#34892;&#26292;&#38706;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#27604;&#32431;&#25968;&#25454;&#26041;&#27861;&#26356;&#21152;&#29616;&#23454;&#22320;&#20272;&#35745;&#23460;&#20869;&#27681;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#38454;&#27573;&#24314;&#27169;&#26041;&#27861;&#65306;1&#65289;&#24212;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#65292;&#20351;&#29992;&#29615;&#22659;&#21644;&#24314;&#31569;&#25968;&#25454;&#20316;&#20026;&#39044;&#27979;&#22240;&#23376;&#65292;&#20272;&#35745;&#20102;&#24503;&#22269;&#27599;&#20010;&#20303;&#23429;&#27004;&#30340;&#27599;&#20010;&#27004;&#23618;&#30340;&#23460;&#20869;&#27681;&#27010;&#29575;&#20998;&#24067;&#20989;&#25968;&#65307;2&#65289;&#20351;&#29992;&#27010;&#29575;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#25216;&#26415;&#20351;&#23427;&#20204;&#32452;&#21512;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor radon exposure at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sample often differ from the characteristics of the population due to the large number of relevant factors such as the availability of geogenic radon or floor level. Furthermore, the sample size usually does not allow exposure estimation with high spatial resolution. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. We applied a two-stage modelling approach: 1) a quantile regression forest using environmental and building data as predictors was applied to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany; (2) a probabilistic Monte Carlo sampling technique enabled the combination and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20943;&#23567;&#20559;&#24046;&#21644;&#20135;&#29983;&#26356;&#20934;&#30830;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#36817;&#20284;&#21518;&#39564;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#21518;&#39564;&#30340;&#21464;&#25442;&#26469;&#26368;&#22823;&#21270;&#24471;&#20998;&#35268;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21482;&#38656;&#35201;&#36827;&#34892;&#23569;&#37327;&#22797;&#26434;&#27169;&#22411;&#27169;&#25311;&#65292;&#19988;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.05357</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#36817;&#20284;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#24471;&#20998;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Bayesian score calibration for approximate models. (arXiv:2211.05357v4 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20943;&#23567;&#20559;&#24046;&#21644;&#20135;&#29983;&#26356;&#20934;&#30830;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#36817;&#20284;&#21518;&#39564;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#21518;&#39564;&#30340;&#21464;&#25442;&#26469;&#26368;&#22823;&#21270;&#24471;&#20998;&#35268;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21482;&#38656;&#35201;&#36827;&#34892;&#23569;&#37327;&#22797;&#26434;&#27169;&#22411;&#27169;&#25311;&#65292;&#19988;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#23478;&#20204;&#19981;&#26029;&#21457;&#23637;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#26426;&#26800;&#27169;&#22411;&#65292;&#20197;&#26356;&#30495;&#23454;&#22320;&#21453;&#26144;&#20182;&#20204;&#30340;&#30693;&#35782;&#12290;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#30456;&#24212;&#30340;&#20284;&#28982;&#20989;&#25968;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#65292;&#24182;&#19988;&#27169;&#22411;&#27169;&#25311;&#21487;&#33021;&#24102;&#26469;&#35745;&#31639;&#36127;&#25285;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#37319;&#29992;&#26367;&#20195;&#27169;&#22411;&#25110;&#36817;&#20284;&#20284;&#28982;&#20989;&#25968;&#12290;&#30452;&#25509;&#20351;&#29992;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#21487;&#33021;&#24456;&#26041;&#20415;&#65292;&#20294;&#21487;&#33021;&#23548;&#33268;&#20559;&#24046;&#21644;&#19981;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#21518;&#39564;&#30340;&#21464;&#25442;&#26469;&#26368;&#22823;&#21270;&#24471;&#20998;&#35268;&#21017;&#65292;&#20174;&#32780;&#20943;&#23567;&#20559;&#24046;&#24182;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21482;&#38656;&#35201;&#36827;&#34892;&#65288;&#22266;&#23450;&#30340;&#65289;&#23569;&#37327;&#22797;&#26434;&#27169;&#22411;&#27169;&#25311;&#65292;&#19988;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#19981;&#26029;&#22686;&#21152;&#30340;&#31034;&#20363;&#19978;&#23637;&#31034;&#20102;&#26032;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scientists continue to develop increasingly complex mechanistic models to reflect their knowledge more realistically. Statistical inference using these models can be challenging since the corresponding likelihood function is often intractable and model simulation may be computationally burdensome. Fortunately, in many of these situations, it is possible to adopt a surrogate model or approximate likelihood function. It may be convenient to conduct Bayesian inference directly with the surrogate, but this can result in bias and poor uncertainty quantification. In this paper we propose a new method for adjusting approximate posterior samples to reduce bias and produce more accurate uncertainty quantification. We do this by optimizing a transform of the approximate posterior that maximizes a scoring rule. Our approach requires only a (fixed) small number of complex model simulations and is numerically stable. We demonstrate good performance of the new method on several examples of increasin
&lt;/p&gt;</description></item></channel></rss>