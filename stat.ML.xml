<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#65292;&#20197;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#22312;&#34920;&#31034;&#21160;&#21147;&#24179;&#34913;&#21644;&#36866;&#29992;&#20110;&#25968;&#25454;&#21516;&#21270;&#23454;&#39564;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.03702</link><description>&lt;p&gt;
&#22312;&#32447;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#19982;&#31070;&#32463;&#32593;&#32476;: &#24212;&#29992;&#20110;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Online model error correction with neural networks: application to the Integrated Forecasting System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03702
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#65292;&#20197;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#22312;&#34920;&#31034;&#21160;&#21147;&#24179;&#34913;&#21644;&#36866;&#29992;&#20110;&#25968;&#25454;&#21516;&#21270;&#23454;&#39564;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#22312;&#20840;&#29699;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#30340;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#24320;&#21457;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#36825;&#20123;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#20855;&#26377;&#20854;&#20248;&#21183;&#65292;&#23588;&#20854;&#26159;&#20934;&#30830;&#24615;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#38656;&#27714;&#65292;&#20294;&#20063;&#23384;&#22312;&#20854;&#24369;&#28857;&#65306;&#23427;&#20204;&#38590;&#20197;&#34920;&#31034;&#22522;&#26412;&#21160;&#21147;&#24179;&#34913;&#65292;&#24182;&#19988;&#36828;&#26410;&#36866;&#29992;&#20110;&#36164;&#26009;&#21516;&#21270;&#23454;&#39564;&#12290;&#28151;&#21512;&#24314;&#27169;&#20986;&#29616;&#20026;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#30340;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;&#28151;&#21512;&#27169;&#22411;&#23558;&#22522;&#20110;&#29289;&#29702;&#30340;&#26680;&#24515;&#32452;&#20214;&#19982;&#32479;&#35745;&#32452;&#20214;&#65288;&#36890;&#24120;&#26159;&#31070;&#32463;&#32593;&#32476;&#65289;&#38598;&#25104;&#22312;&#19968;&#36215;&#65292;&#20197;&#22686;&#24378;&#39044;&#27979;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#36816;&#34892;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#65288;IFS&#65289;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#12290;&#31070;&#32463;&#32593;&#32476;&#26368;&#21021;&#20250;&#31163;&#32447;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#20351;&#29992;&#22823;&#37327;&#36816;&#34892;&#20998;&#26512;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03702v1 Announce Type: cross  Abstract: In recent years, there has been significant progress in the development of fully data-driven global numerical weather prediction models. These machine learning weather prediction models have their strength, notably accuracy and low computational requirements, but also their weakness: they struggle to represent fundamental dynamical balances, and they are far from being suitable for data assimilation experiments. Hybrid modelling emerges as a promising approach to address these limitations. Hybrid models integrate a physics-based core component with a statistical component, typically a neural network, to enhance prediction capabilities. In this article, we propose to develop a model error correction for the operational Integrated Forecasting System (IFS) of the European Centre for Medium-Range Weather Forecasts using a neural network. The neural network is initially pre-trained offline using a large dataset of operational analyses and a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;</title><link>https://arxiv.org/abs/2402.17732</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;
&lt;/p&gt;
&lt;p&gt;
Batched Nonparametric Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17732
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#21160;&#20316;&#30340;&#26399;&#26395;&#22870;&#21169;&#34987;&#24314;&#27169;&#20026;&#21327;&#21464;&#37327;&#30340;&#24179;&#28369;&#20989;&#25968;&#65292;&#24182;&#19988;&#31574;&#30053;&#26356;&#26032;&#26159;&#22312;&#27599;&#20010;Observations&#25209;&#27425;&#32467;&#26463;&#26102;&#36827;&#34892;&#30340;&#12290;&#25105;&#20204;&#20026;&#36825;&#31181;&#35774;&#32622;&#24314;&#31435;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Batched Successive Elimination with Dynamic Binning&#65288;BaSEDB&#65289;&#30340;&#26041;&#26696;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21518;&#24724;&#65288;&#36798;&#21040;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#23454;&#36136;&#19978;&#65292;BaSEDB&#21160;&#24577;&#22320;&#23558;&#21327;&#21464;&#37327;&#31354;&#38388;&#20998;&#21106;&#25104;&#26356;&#23567;&#30340;&#31665;&#23376;&#65292;&#24182;&#20180;&#32454;&#35843;&#25972;&#23427;&#20204;&#30340;&#23485;&#24230;&#20197;&#31526;&#21512;&#25209;&#27425;&#22823;&#23567;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#38745;&#24577;&#20998;&#31665;&#30340;&#38750;&#26368;&#20248;&#24615;&#65292;&#31361;&#20986;&#20102;&#21160;&#24577;&#20998;&#31665;&#30340;&#24517;&#35201;&#24615;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23436;&#20840;&#22312;&#32447;&#35774;&#32622;&#20013;&#65292;&#20960;&#20046;&#24658;&#23450;&#25968;&#37327;&#30340;&#31574;&#30053;&#26356;&#26032;&#21487;&#20197;&#36798;&#21040;&#26368;&#20339;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17732v1 Announce Type: cross  Abstract: We study nonparametric contextual bandits under batch constraints, where the expected reward for each action is modeled as a smooth function of covariates, and the policy updates are made at the end of each batch of observations. We establish a minimax regret lower bound for this setting and propose Batched Successive Elimination with Dynamic Binning (BaSEDB) that achieves optimal regret (up to logarithmic factors). In essence, BaSEDB dynamically splits the covariate space into smaller bins, carefully aligning their widths with the batch size. We also show the suboptimality of static binning under batch constraints, highlighting the necessity of dynamic binning. Additionally, our results suggest that a nearly constant number of policy updates can attain optimal regret in the fully online setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21033;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#26679;&#26412;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#31574;&#30053;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#65292;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#65292;&#24182;&#35777;&#26126;&#20854;&#25910;&#25947;&#36895;&#24230;&#20248;&#20110;&#38543;&#26426;&#36873;&#25321;&#12290;&#21516;&#26102;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#30340;SIFT&#26041;&#27861;&#65292;&#24182;&#22312;&#35757;&#32451;BERT&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.07052</link><description>&lt;p&gt;
&#29702;&#35299;&#36890;&#36807;&#20351;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Understanding the Training Speedup from Sampling with Approximate Losses
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21033;&#29992;&#36817;&#20284;&#25439;&#22833;&#36827;&#34892;&#26679;&#26412;&#37319;&#26679;&#30340;&#35757;&#32451;&#21152;&#36895;&#26041;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#31574;&#30053;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#65292;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#65292;&#24182;&#35777;&#26126;&#20854;&#25910;&#25947;&#36895;&#24230;&#20248;&#20110;&#38543;&#26426;&#36873;&#25321;&#12290;&#21516;&#26102;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#30340;SIFT&#26041;&#27861;&#65292;&#24182;&#22312;&#35757;&#32451;BERT&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#36873;&#25321;&#20855;&#26377;&#36739;&#22823;&#25439;&#22833;/&#26799;&#24230;&#30340;&#26679;&#26412;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#35757;&#32451;&#27493;&#39588;&#30340;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#30340;&#24320;&#38144;&#24448;&#24448;&#36807;&#39640;&#65292;&#26080;&#27861;&#22312;&#24635;&#20307;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#33719;&#24471;&#26377;&#24847;&#20041;&#30340;&#25552;&#21319;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#36873;&#25321;&#20855;&#26377;&#22823;&#32422;&#25439;&#22833;&#30340;&#26679;&#26412;&#30340;&#36138;&#23146;&#26041;&#27861;&#65292;&#32780;&#19981;&#26159;&#20934;&#30830;&#25439;&#22833;&#65292;&#20197;&#20943;&#23569;&#36873;&#25321;&#30340;&#24320;&#38144;&#12290;&#23545;&#20110;&#24179;&#28369;&#20984;&#25439;&#22833;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#36138;&#23146;&#31574;&#30053;&#21487;&#20197;&#22312;&#27604;&#38543;&#26426;&#36873;&#25321;&#26356;&#23569;&#30340;&#36845;&#20195;&#27425;&#25968;&#20869;&#25910;&#25947;&#21040;&#24179;&#22343;&#25439;&#22833;&#30340;&#26368;&#23567;&#20540;&#30340;&#24120;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#36824;&#29702;&#35770;&#19978;&#37327;&#21270;&#20102;&#36817;&#20284;&#27700;&#24179;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20351;&#29992;&#20013;&#38388;&#23618;&#34920;&#31034;&#33719;&#21462;&#36817;&#20284;&#25439;&#22833;&#20197;&#36827;&#34892;&#26679;&#26412;&#36873;&#25321;&#30340;SIFT&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;SIFT&#22312;&#35757;&#32451;&#19968;&#20010;&#20855;&#26377;1.1&#20159;&#21442;&#25968;&#30340;12&#23618;BERT&#22522;&#30784;&#27169;&#22411;&#19978;&#30340;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#65288;&#20197;&#35757;&#32451;&#26102;&#38388;&#21644;&#21453;&#21521;&#20256;&#25773;&#27493;&#39588;&#30340;&#25968;&#37327;&#34913;&#37327;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that selecting samples with large losses/gradients can significantly reduce the number of training steps. However, the selection overhead is often too high to yield any meaningful gains in terms of overall training time. In this work, we focus on the greedy approach of selecting samples with large \textit{approximate losses} instead of exact losses in order to reduce the selection overhead. For smooth convex losses, we show that such a greedy strategy can converge to a constant factor of the minimum value of the average loss in fewer iterations than the standard approach of random selection. We also theoretically quantify the effect of the approximation level. We then develop SIFT which uses early exiting to obtain approximate losses with an intermediate layer's representations for sample selection. We evaluate SIFT on the task of training a 110M parameter 12-layer BERT base model and show significant gains (in terms of training hours and number of backpropagation step
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.18270</link><description>&lt;p&gt;
&#23398;&#20064;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#27425;(&#24040;&#22823;)&#30340;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning Two-Layer Neural Networks, One (Giant) Step at a Time. (arXiv:2305.18270v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18270
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#30740;&#31350;&#20102;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26377;&#21161;&#20110;&#22312;&#26680;&#24515;&#33539;&#22260;&#20043;&#22806;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#25209;&#37327;&#22823;&#23567;&#21644;&#22810;&#20010;(&#20294;&#26377;&#38480;&#30340;)&#27493;&#39588;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#27493;&#39588;&#36807;&#31243;&#65292;&#21457;&#29616;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#21487;&#20197;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#20294;&#21482;&#36866;&#21512;&#23398;&#20064;&#21333;&#19968;&#26041;&#21521;&#25110;&#21333;&#32034;&#24341;&#27169;&#22411;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;$n=O(d^2)$&#23545;&#20110;&#23398;&#20064;&#22810;&#20010;&#26041;&#21521;&#21644;&#19987;&#19994;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#8220;&#30828;&#8221;&#26041;&#21521;&#32570;&#20047;&#21069;$\ell$&#20010;Hermite&#31995;&#25968;&#65292;&#20173;&#26410;&#34987;&#21457;&#29616;&#65292;&#24182;&#19988;&#38656;&#35201;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d^\ell)$&#25165;&#33021;&#34987;&#26799;&#24230;&#19979;&#38477;&#25429;&#33719;&#12290;&#32463;&#36807;&#20960;&#27425;&#36845;&#20195;&#65292;&#24773;&#20917;&#21457;&#29983;&#21464;&#21270;&#65306;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#36275;&#20197;&#23398;&#20064;&#26032;&#30340;&#30446;&#26631;&#26041;&#21521;&#65292;&#36825;&#20123;&#26041;&#21521;&#22312;Hermite&#22522;&#30784;&#19978;&#32447;&#24615;&#36830;&#25509;&#21040;&#20043;&#21069;&#23398;&#20064;&#30340;&#26041;&#21521;&#25152;&#28085;&#30422;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the training dynamics of shallow neural networks, investigating the conditions under which a limited number of large batch gradient descent steps can facilitate feature learning beyond the kernel regime. We compare the influence of batch size and that of multiple (but finitely many) steps. Our analysis of a single-step process reveals that while a batch size of $n = O(d)$ enables feature learning, it is only adequate for learning a single direction, or a single-index model. In contrast, $n = O(d^2)$ is essential for learning multiple directions and specialization. Moreover, we demonstrate that ``hard'' directions, which lack the first $\ell$ Hermite coefficients, remain unobserved and require a batch size of $n = O(d^\ell)$ for being captured by gradient descent. Upon iterating a few steps, the scenario changes: a batch-size of $n = O(d)$ is enough to learn new target directions spanning the subspace linearly connected in the Hermite basis to the previously learned directions,
&lt;/p&gt;</description></item></channel></rss>