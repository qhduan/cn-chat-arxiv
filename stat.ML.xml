<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#32771;&#34385;&#20102;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12472</link><description>&lt;p&gt;
&#26080;&#27169;&#22411;&#24191;&#20041;&#22522;&#20934;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Model-free generalized fiducial inference. (arXiv:2307.12472v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#32771;&#34385;&#20102;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#30340;&#23433;&#20840;&#21487;&#38752;&#24615;&#30340;&#38656;&#27714;&#65292;&#26412;&#25991;&#25552;&#20986;&#24182;&#21457;&#23637;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#19981;&#20934;&#30830;&#27010;&#29575;&#39044;&#27979;&#25512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#25552;&#20379;&#39044;&#27979;&#38598;&#30340;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#23545;&#31532;&#19968;&#31867;&#38169;&#35823;&#30340;&#26377;&#38480;&#26679;&#26412;&#25511;&#21046;&#65292;&#36825;&#19982;&#19968;&#33268;&#24615;&#39044;&#27979;&#38598;&#20855;&#26377;&#30456;&#21516;&#30340;&#23646;&#24615;&#65292;&#20294;&#36825;&#31181;&#26032;&#26041;&#27861;&#36824;&#25552;&#20379;&#20102;&#26356;&#28789;&#27963;&#30340;&#19981;&#20934;&#30830;&#27010;&#29575;&#25512;&#29702;&#24037;&#20855;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#24182;&#32771;&#34385;&#20102;&#19968;&#31181;&#31934;&#30830;&#27010;&#29575;&#36817;&#20284;&#27169;&#22411;&#26080;&#20851;&#30340;&#19981;&#20934;&#30830;&#25512;&#29702;&#26694;&#26550;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#29305;&#24615;&#12290;&#36890;&#36807;&#23558;&#20449;&#24565;/&#21487;&#20449;&#24230;&#24230;&#37327;&#23545;&#36817;&#20284;&#20026;&#22312;&#21487;&#20449;&#21306;&#38388;&#20013;&#30340;[&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#26368;&#20248;]&#27010;&#29575;&#24230;&#37327;&#65292;&#26159;&#25193;&#22823;&#22312;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#25512;&#24191;&#19981;&#20934;&#30830;&#27010;&#29575;&#25512;&#29702;&#26041;&#27861;&#25152;&#38656;&#30340;&#20851;&#38190;&#35299;&#20915;&#26041;&#26696;&#65292;&#30446;&#21069;&#22312;&#32479;&#35745;&#21644;
&lt;/p&gt;
&lt;p&gt;
Motivated by the need for the development of safe and reliable methods for uncertainty quantification in machine learning, I propose and develop ideas for a model-free statistical framework for imprecise probabilistic prediction inference. This framework facilitates uncertainty quantification in the form of prediction sets that offer finite sample control of type 1 errors, a property shared with conformal prediction sets, but this new approach also offers more versatile tools for imprecise probabilistic reasoning. Furthermore, I propose and consider the theoretical and empirical properties of a precise probabilistic approximation to the model-free imprecise framework. Approximating a belief/plausibility measure pair by an [optimal in some sense] probability measure in the credal set is a critical resolution needed for the broader adoption of imprecise probabilistic approaches to inference in statistical and machine learning communities. It is largely undetermined in the statistical and
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#38024;&#23545;&#38750;&#20809;&#28369;&#21644;&#20809;&#28369;&#30446;&#26631;&#30340;&#26080;&#35270;&#35273;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.17470</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#29305;&#24449;&#20540;&#20248;&#21270;&#38382;&#39064;&#30340;&#26080;&#35270;&#35273;&#38543;&#26426;&#22797;&#21512;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Oblivious Stochastic Composite Optimization Algorithm for Eigenvalue Optimization Problems. (arXiv:2306.17470v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#38024;&#23545;&#38750;&#20809;&#28369;&#21644;&#20809;&#28369;&#30446;&#26631;&#30340;&#26080;&#35270;&#35273;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20351;&#29992;&#38543;&#26426;&#21270;&#19968;&#38454;&#26041;&#27861;&#21644;&#38543;&#26426;&#24179;&#28369;&#35299;&#20915;&#22823;&#35268;&#27169;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#22522;&#20110;&#20114;&#34917;&#22797;&#21512;&#35774;&#32622;&#30340;&#26080;&#35270;&#35273;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#12290;&#19968;&#31181;&#31639;&#27861;&#35774;&#35745;&#29992;&#20110;&#38750;&#20809;&#28369;&#30446;&#26631;&#65292;&#32780;&#21152;&#36895;&#29256;&#26412;&#21017;&#36866;&#29992;&#20110;&#20809;&#28369;&#30446;&#26631;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#37117;&#19981;&#38656;&#35201;&#23545;&#30446;&#26631;&#20989;&#25968;&#30340;Lipschitz&#24120;&#25968;&#25110;&#20809;&#28369;&#24230;&#26377;&#20808;&#39564;&#30693;&#35782;&#12290;&#23545;&#20110;&#20855;&#26377;$\mathcal{M}-$&#26377;&#30028;&#39044;&#35328;&#30340;&#38750;&#20809;&#28369;&#24773;&#20917;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#20026;$ O( {\mathcal{M}}/{\sqrt{T}} ) $&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#23545;&#20110;&#20855;&#26377;&#30001;$D$&#38480;&#21046;&#30340;&#21487;&#34892;&#38598;&#30340;$L$-&#20809;&#28369;&#24773;&#20917;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#20026;$ O( {L^2 D^2}/{(T^{2}\sqrt{T})} + {(D_0^2+\sigma^2)}/{\sqrt{T}} )$&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$D_0$&#26159;&#21040;&#26368;&#20248;&#35299;&#30340;&#36215;&#22987;&#36317;&#31163;&#65292;$ \sigma^2$&#26159;&#38543;&#26426;&#39044;&#35328;&#26041;&#24046;&#12290;&#30446;&#21069;&#21482;&#26377;&#22312;&#20551;&#35774;&#20808;&#39564;&#30693;&#35782;&#30340;Lipschitz&#24120;&#25968;&#25110;t&#24773;&#20917;&#19979;&#25165;&#33021;&#24471;&#21040;&#36825;&#20123;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we revisit the problem of solving large-scale semidefinite programs using randomized first-order methods and stochastic smoothing. We introduce two oblivious stochastic mirror descent algorithms based on a complementary composite setting. One algorithm is designed for non-smooth objectives, while an accelerated version is tailored for smooth objectives. Remarkably, both algorithms work without prior knowledge of the Lipschitz constant or smoothness of the objective function. For the non-smooth case with $\mathcal{M}-$bounded oracles, we prove a convergence rate of $ O( {\mathcal{M}}/{\sqrt{T}} ) $. For the $L$-smooth case with a feasible set bounded by $D$, we derive a convergence rate of $ O( {L^2 D^2}/{(T^{2}\sqrt{T})} + {(D_0^2+\sigma^2)}/{\sqrt{T}} )$, where $D_0$ is the starting distance to an optimal solution, and $ \sigma^2$ is the stochastic oracle variance. These rates had only been obtained so far by either assuming prior knowledge of the Lipschitz constant or t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.16822</link><description>&lt;p&gt;
&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#20284;&#36817;&#31471;&#31639;&#27861;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
An inexact linearized proximal algorithm for a class of DC composite optimization problems and applications. (arXiv:2303.16822v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;DC&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#31867;&#38382;&#39064;&#36890;&#24120;&#30001;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#30340;&#40065;&#26834;&#20998;&#35299;&#27169;&#22411;&#25512;&#23548;&#32780;&#26469;&#65292;&#26159;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#21644;&#20855;&#26377;&#38750;&#20809;&#28369;&#20998;&#37327;&#30340;DC&#35268;&#21010;&#30340;&#25193;&#23637;&#12290;&#38024;&#23545;&#36825;&#31867;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#31934;&#30830;&#32447;&#24615;&#21270;&#36817;&#31471;&#31639;&#27861;&#65288;iLPA&#65289;&#12290;&#31639;&#27861;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#30446;&#26631;&#20989;&#25968;&#30340;&#37096;&#20998;&#32447;&#24615;&#21270;&#65292;&#35745;&#31639;&#24378;&#20984;&#20027;&#23548;&#30340;&#38750;&#31934;&#30830;&#26368;&#23567;&#21270;&#20540;&#12290;&#36845;&#20195;&#24207;&#21015;&#30340;&#29983;&#25104;&#25910;&#25947;&#20110;&#28508;&#22312;&#20989;&#25968;&#30340;Kurdyka-{\L}ojasiewicz&#65288;KL&#65289;&#24615;&#36136;&#65292;&#22914;&#26524;&#28508;&#22312;&#20989;&#25968;&#22312;&#26497;&#38480;&#28857;&#22788;&#20855;&#26377;KL&#25351;&#25968;$1/2$&#30340;KL&#24615;&#36136;&#65292;&#21017;&#25910;&#25947;&#20855;&#26377;&#23616;&#37096;R&#32447;&#24615;&#36895;&#29575;&#12290;&#23545;&#20110;&#21518;&#19968;&#31181;&#20551;&#35774;&#65292;&#25105;&#20204;&#21033;&#29992;&#22797;&#21512;&#32467;&#26500;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#39564;&#35777;&#30340;&#26465;&#20214;&#65292;&#24182;&#38416;&#26126;&#20102;&#19982;&#20984;&#22797;&#21512;&#20248;&#21270;&#25152;&#20351;&#29992;&#30340;&#27491;&#21017;&#24615;&#30340;&#20851;&#31995;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#38750;&#31934;&#30830;&#32447;&#24615;&#36817;&#31471;&#31639;&#27861;&#24212;&#29992;&#20110;&#35299;&#20915;&#40065;&#26834;&#20998;&#35299;&#20013;&#30340;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#24352;&#37327;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;TRPCA&#65289;&#21644;&#24352;&#37327;&#40065;&#26834;&#20302;&#31209;&#24352;&#37327;&#23436;&#25104;&#65288;TRLRTC&#65289;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#26032;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with a class of DC composite optimization problems which, as an extension of the convex composite optimization problem and the DC program with nonsmooth components, often arises from robust factorization models of low-rank matrix recovery. For this class of nonconvex and nonsmooth problems, we propose an inexact linearized proximal algorithm (iLPA) which in each step computes an inexact minimizer of a strongly convex majorization constructed by the partial linearization of their objective functions. The generated iterate sequence is shown to be convergent under the Kurdyka-{\L}ojasiewicz (KL) property of a potential function, and the convergence admits a local R-linear rate if the potential function has the KL property of exponent $1/2$ at the limit point. For the latter assumption, we provide a verifiable condition by leveraging the composite structure, and clarify its relation with the regularity used for the convex composite optimization. Finally, the propose
&lt;/p&gt;</description></item></channel></rss>