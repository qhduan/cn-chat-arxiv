<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#22312;&#24037;&#19994;&#38646;&#37096;&#20214;&#20998;&#31867;&#20013;&#25506;&#35752;&#20102;&#21033;&#29992;&#26356;&#20415;&#23452;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#23454;&#29616;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2403.10182</link><description>&lt;p&gt;
&#29992;&#26356;&#20415;&#23452;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#23454;&#29616;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#24037;&#19994;&#38646;&#37096;&#20214;&#20998;&#31867;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Reliable uncertainty with cheaper neural network ensembles: a case study in industrial parts classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10182
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#22312;&#24037;&#19994;&#38646;&#37096;&#20214;&#20998;&#31867;&#20013;&#25506;&#35752;&#20102;&#21033;&#29992;&#26356;&#20415;&#23452;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#23454;&#29616;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36816;&#31609;&#23398;(OR)&#20013;&#65292;&#39044;&#27979;&#27169;&#22411;&#32463;&#24120;&#20250;&#36935;&#21040;&#25968;&#25454;&#20998;&#24067;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#30340;&#22330;&#26223;&#12290;&#36817;&#24180;&#26469;&#65292;&#31070;&#32463;&#32593;&#32476;(NNs)&#22312;&#22270;&#20687;&#20998;&#31867;&#31561;&#39046;&#22495;&#30340;&#20986;&#33394;&#24615;&#33021;&#20351;&#20854;&#22312;OR&#20013;&#22791;&#21463;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;OOD&#25968;&#25454;&#26102;&#65292;NNs&#24448;&#24448;&#20250;&#20570;&#20986;&#33258;&#20449;&#20294;&#19981;&#27491;&#30830;&#30340;&#39044;&#27979;&#12290;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20026;&#33258;&#20449;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#24403;&#36755;&#20986;&#24212;(&#19981;&#24212;)&#34987;&#20449;&#20219;&#26102;&#36827;&#34892;&#36890;&#20449;&#12290;&#22240;&#27492;&#65292;&#22312;OR&#39046;&#22495;&#20013;&#65292;NNs&#20013;&#30340;&#21487;&#38752;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#22810;&#20010;&#29420;&#31435;NNs&#32452;&#25104;&#30340;&#28145;&#24230;&#38598;&#21512;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#65292;&#19981;&#20165;&#25552;&#20379;&#24378;&#22823;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#36824;&#33021;&#21487;&#38752;&#22320;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#37096;&#32626;&#30001;&#20110;&#36739;&#22823;&#30340;&#35745;&#31639;&#38656;&#27714;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26368;&#36817;&#30340;&#22522;&#30784;&#30740;&#31350;&#25552;&#20986;&#20102;&#26356;&#39640;&#25928;&#30340;NN&#38598;&#25104;&#65292;&#21363;sna
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10182v1 Announce Type: new  Abstract: In operations research (OR), predictive models often encounter out-of-distribution (OOD) scenarios where the data distribution differs from the training data distribution. In recent years, neural networks (NNs) are gaining traction in OR for their exceptional performance in fields such as image classification. However, NNs tend to make confident yet incorrect predictions when confronted with OOD data. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Hence, reliable uncertainty quantification in NNs is crucial in the OR domain. Deep ensembles, composed of multiple independent NNs, have emerged as a promising approach, offering not only strong predictive accuracy but also reliable uncertainty estimation. However, their deployment is challenging due to substantial computational demands. Recent fundamental research has proposed more efficient NN ensembles, namely the sna
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#34913;&#37327;&#20154;&#31867;&#19982;&#27169;&#22411;&#20559;&#22909;&#20043;&#38388;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#36827;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#27979;&#25490;&#21517;&#12290;</title><link>https://arxiv.org/abs/2402.17826</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#27979;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Prediction-Powered Ranking of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17826
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#34913;&#37327;&#20154;&#31867;&#19982;&#27169;&#22411;&#20559;&#22909;&#20043;&#38388;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#36827;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#27979;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#24120;&#26681;&#25454;&#20854;&#19982;&#20154;&#31867;&#20559;&#22909;&#30340;&#19968;&#33268;&#24615;&#27700;&#24179;&#36827;&#34892;&#25490;&#21517;--&#22914;&#26524;&#19968;&#20010;&#27169;&#22411;&#30340;&#36755;&#20986;&#26356;&#21463;&#20154;&#31867;&#20559;&#22909;&#65292;&#37027;&#20040;&#23427;&#23601;&#27604;&#20854;&#20182;&#27169;&#22411;&#26356;&#22909;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26694;&#26550;&#26469;&#24357;&#21512;&#20154;&#31867;&#19982;&#27169;&#22411;&#20559;&#22909;&#20043;&#38388;&#21487;&#33021;&#24341;&#20837;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17826v1 Announce Type: cross  Abstract: Large language models are often ranked according to their level of alignment with human preferences -- a model is better than other models if its outputs are more frequently preferred by humans. One of the most popular ways to elicit human preferences utilizes pairwise comparisons between the outputs provided by different models to the same inputs. However, since gathering pairwise comparisons by humans is costly and time-consuming, it has become a very common practice to gather pairwise comparisons by a strong large language model -- a model strongly aligned with human preferences. Surprisingly, practitioners cannot currently measure the uncertainty that any mismatch between human and model preferences may introduce in the constructed rankings. In this work, we develop a statistical framework to bridge this gap. Given a small set of pairwise comparisons by humans and a large set of pairwise comparisons by a model, our framework provid
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#26367;&#20195;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#25972;&#21512;&#20197;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#21457;&#29616;&#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#28151;&#21512;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;</title><link>https://arxiv.org/abs/2402.04376</link><description>&lt;p&gt;
&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#26367;&#20195;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#30340;&#25193;&#23637;&#35268;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling laws for learning with real and surrogate data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#26367;&#20195;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#25972;&#21512;&#20197;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#21457;&#29616;&#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#28151;&#21512;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25910;&#38598;&#22823;&#37327;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#36890;&#24120;&#34987;&#38480;&#21046;&#22312;&#25104;&#26412;&#26114;&#36149;&#25110;&#19981;&#20999;&#23454;&#38469;&#30340;&#33539;&#22260;&#20869;, &#36825;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29942;&#39048;&#12290;&#30456;&#21453;&#22320;, &#21487;&#20197;&#23558;&#26469;&#33258;&#30446;&#26631;&#20998;&#24067;&#30340;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19982;&#26469;&#33258;&#20844;&#20849;&#25968;&#25454;&#38598;&#12289;&#19981;&#21516;&#24773;&#20917;&#19979;&#25910;&#38598;&#30340;&#25968;&#25454;&#25110;&#30001;&#29983;&#25104;&#27169;&#22411;&#21512;&#25104;&#30340;&#25968;&#25454;&#30456;&#32467;&#21512;, &#20316;&#20026;&#26367;&#20195;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#26696;&#26469;&#23558;&#26367;&#20195;&#25968;&#25454;&#25972;&#21512;&#21040;&#35757;&#32451;&#20013;, &#24182;&#20351;&#29992;&#29702;&#35770;&#27169;&#22411;&#21644;&#23454;&#35777;&#30740;&#31350;&#25506;&#32034;&#20854;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21457;&#29616;&#26159;&#65306;(i) &#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#21407;&#22987;&#20998;&#24067;&#30340;&#27979;&#35797;&#35823;&#24046;&#65307;(ii) &#20026;&#20102;&#33719;&#24471;&#36825;&#31181;&#25928;&#30410;, &#20351;&#29992;&#26368;&#20248;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38750;&#24120;&#20851;&#38190;&#65307;(iii) &#22312;&#28151;&#21512;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#26367;&#20195;&#25968;&#25454;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#21487;&#20197;&#24456;&#22909;&#22320;&#29992;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#12290;&#36825;&#21487;&#20197;&#29992;&#26469;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collecting large quantities of high-quality data is often prohibitively expensive or impractical, and a crucial bottleneck in machine learning. One may instead augment a small set of $n$ data points from the target distribution with data from more accessible sources like public datasets, data collected under different circumstances, or synthesized by generative models. Blurring distinctions, we refer to such data as `surrogate data'.   We define a simple scheme for integrating surrogate data into training and use both theoretical models and empirical studies to explore its behavior. Our main findings are: $(i)$ Integrating surrogate data can significantly reduce the test error on the original distribution; $(ii)$ In order to reap this benefit, it is crucial to use optimally weighted empirical risk minimization; $(iii)$ The test error of models trained on mixtures of real and surrogate data is well described by a scaling law. This can be used to predict the optimal weighting and the gai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65292;&#21487;&#20197;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#24674;&#22797;&#25110;&#36229;&#36234;&#20102;&#24050;&#30693;&#30340;&#36335;&#24452;&#33539;&#25968;&#30028;&#38480;&#65292;&#24182;&#25361;&#25112;&#20102;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#19968;&#20123;&#20855;&#20307;&#25215;&#35834;&#12290;</title><link>http://arxiv.org/abs/2310.01225</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#29616;&#20195;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65306;&#24433;&#21709;&#12289;&#21069;&#26223;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A path-norm toolkit for modern networks: consequences, promises and challenges. (arXiv:2310.01225v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65292;&#21487;&#20197;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#24674;&#22797;&#25110;&#36229;&#36234;&#20102;&#24050;&#30693;&#30340;&#36335;&#24452;&#33539;&#25968;&#30028;&#38480;&#65292;&#24182;&#25361;&#25112;&#20102;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#19968;&#20123;&#20855;&#20307;&#25215;&#35834;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#23436;&#20840;&#33021;&#22815;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#19981;&#20165;&#36866;&#29992;&#20110;&#26368;&#24191;&#27867;&#30340;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#21487;&#20197;&#24674;&#22797;&#25110;&#36229;&#36234;&#24050;&#30693;&#30340;&#27492;&#31867;&#33539;&#25968;&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#36335;&#24452;&#33539;&#25968;&#36824;&#20139;&#26377;&#36335;&#24452;&#33539;&#25968;&#30340;&#24120;&#35268;&#20248;&#28857;&#65306;&#35745;&#31639;&#31616;&#20415;&#12289;&#23545;&#32593;&#32476;&#30340;&#23545;&#31216;&#24615;&#20855;&#26377;&#19981;&#21464;&#24615;&#65292;&#22312;&#21069;&#39304;&#32593;&#32476;&#19978;&#27604;&#25805;&#20316;&#31526;&#33539;&#25968;&#30340;&#20056;&#31215;&#65288;&#21478;&#19968;&#31181;&#24120;&#29992;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65289;&#20855;&#26377;&#26356;&#22909;&#30340;&#38160;&#24230;&#12290;&#24037;&#20855;&#21253;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#26131;&#20110;&#23454;&#26045;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#25968;&#20540;&#35780;&#20272;&#22312;ImageNet&#19978;&#23545;ResNet&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#26469;&#25361;&#25112;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#20855;&#20307;&#25215;&#35834;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces the first toolkit around path-norms that is fully able to encompass general DAG ReLU networks with biases, skip connections and max pooling. This toolkit notably allows us to establish generalization bounds for real modern neural networks that are not only the most widely applicable path-norm based ones, but also recover or beat the sharpest known bounds of this type. These extended path-norms further enjoy the usual benefits of path-norms: ease of computation, invariance under the symmetries of the network, and improved sharpness on feedforward networks compared to the product of operators' norms, another complexity measure most commonly used.  The versatility of the toolkit and its ease of implementation allow us to challenge the concrete promises of path-norm-based generalization bounds, by numerically evaluating the sharpest known bounds for ResNets on ImageNet.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#22312;&#19968;&#31867;DeepONets&#20013;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#30028;&#38480;&#19981;&#20250;&#38543;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#32780;&#26126;&#30830;&#21464;&#21270;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#23637;&#31034;&#20102;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#26469;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2205.11359</link><description>&lt;p&gt;
&#38754;&#21521;&#23610;&#24230;&#26080;&#20851;&#30340;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Towards Size-Independent Generalization Bounds for Deep Operator Nets. (arXiv:2205.11359v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11359
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#22312;&#19968;&#31867;DeepONets&#20013;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#30028;&#38480;&#19981;&#20250;&#38543;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#32780;&#26126;&#30830;&#21464;&#21270;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#23637;&#31034;&#20102;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#26469;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#26102;&#26399;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#20998;&#26512;&#29289;&#29702;&#31995;&#32479;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#22312;&#36825;&#20010;&#20027;&#39064;&#20013;&#29305;&#21035;&#27963;&#36291;&#30340;&#39046;&#22495;&#26159;"&#29289;&#29702;&#20449;&#24687;&#26426;&#22120;&#23398;&#20064;"&#65292;&#23427;&#19987;&#27880;&#20110;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#25968;&#20540;&#27714;&#35299;&#24494;&#20998;&#26041;&#31243;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25512;&#36827;&#22312;&#35757;&#32451;DeepONets&#26102;&#27979;&#37327;&#26679;&#26412;&#22806;&#35823;&#24046;&#30340;&#29702;&#35770; - &#36825;&#26159;&#35299;&#20915;PDE&#31995;&#32479;&#26368;&#36890;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#39318;&#20808;&#65292;&#38024;&#23545;&#19968;&#31867;DeepONets&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#26377;&#19968;&#20010;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#19981;&#20250;&#26126;&#30830;&#22320;&#38543;&#30528;&#28041;&#21450;&#30340;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#26469;&#23637;&#31034;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#65292;&#20351;&#24471;&#23545;&#20110;&#36825;&#20123;DeepONet&#31867;&#65292;&#33021;&#22815;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36866;&#29992;&#20110;&#20219;&#20309;&#30446;&#26631;&#26159;&#30001;DeepONets&#27714;&#35299;&#30340;PDE&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent times machine learning methods have made significant advances in becoming a useful tool for analyzing physical systems. A particularly active area in this theme has been "physics-informed machine learning" which focuses on using neural nets for numerically solving differential equations. In this work, we aim to advance the theory of measuring out-of-sample error while training DeepONets -- which is among the most versatile ways to solve PDE systems in one-shot.  Firstly, for a class of DeepONets, we prove a bound on their Rademacher complexity which does not explicitly scale with the width of the nets involved. Secondly, we use this to show how the Huber loss can be chosen so that for these DeepONet classes generalization error bounds can be obtained that have no explicit dependence on the size of the nets. We note that our theoretical results apply to any PDE being targeted to be solved by DeepONets.
&lt;/p&gt;</description></item></channel></rss>