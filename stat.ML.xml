<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#26080;&#38656;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#23454;&#29616;&#26368;&#20248;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#26469;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.11017</link><description>&lt;p&gt;
&#26080;&#31232;&#30095;&#24615;&#30340;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Contextual Bandit Problem without Sparsity. (arXiv:2306.11017v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11017
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#26080;&#38656;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#23454;&#29616;&#26368;&#20248;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#26469;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#39640;&#32500;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#29305;&#24449;&#25968; $p$ &#22823;&#20110;&#39044;&#31639; $T$ &#25110;&#29978;&#33267;&#26080;&#38480;&#21046;&#12290;&#19982;&#27492;&#39046;&#22495;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#19981;&#23545;&#22238;&#24402;&#31995;&#25968;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20381;&#38752;&#26368;&#36817;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#30740;&#31350;&#25104;&#26524;&#65292;&#20174;&#32780;&#33021;&#22815;&#22312;&#25968;&#25454;&#20998;&#24067;&#20855;&#26377;&#36739;&#23567;&#26377;&#25928;&#31209;&#26102;&#20998;&#26512;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25506;&#32034;-&#24320;&#21457; (EtC) &#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#26816;&#39564;&#20102;&#23427;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#20197; $T$ &#20026;&#21464;&#37327;&#65292;&#23548;&#20986;&#20102;ETC&#31639;&#27861;&#30340;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#34920;&#26126;&#36825;&#20010;&#36895;&#29575;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#26469;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457; (AEtC)&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#33258;&#36866;&#24212;&#22320;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#27169;&#25311;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this research, we investigate the high-dimensional linear contextual bandit problem where the number of features $p$ is greater than the budget $T$, or it may even be infinite. Differing from the majority of previous works in this field, we do not impose sparsity on the regression coefficients. Instead, we rely on recent findings on overparameterized models, which enables us to analyze the performance the minimum-norm interpolating estimator when data distributions have small effective ranks. We propose an explore-then-commit (EtC) algorithm to address this problem and examine its performance. Through our analysis, we derive the optimal rate of the ETC algorithm in terms of $T$ and show that this rate can be achieved by balancing exploration and exploitation. Moreover, we introduce an adaptive explore-then-commit (AEtC) algorithm that adaptively finds the optimal balance. We assess the performance of the proposed algorithms through a series of simulations.
&lt;/p&gt;</description></item></channel></rss>