<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26469;&#35299;&#20915;&#26377;&#38480;&#29366;&#24577;&#22343;&#22330;&#21338;&#24328;&#30340;&#20027;&#26041;&#31243;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04975</link><description>&lt;p&gt;
&#28145;&#24230;&#21453;&#21521;&#21644;Galerkin&#26041;&#27861;&#29992;&#20110;&#26377;&#38480;&#29366;&#24577;&#20027;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep Backward and Galerkin Methods for the Finite State Master Equation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04975
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26469;&#35299;&#20915;&#26377;&#38480;&#29366;&#24577;&#22343;&#22330;&#21338;&#24328;&#30340;&#20027;&#26041;&#31243;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#26377;&#38480;&#29366;&#24577;&#22343;&#22330;&#21338;&#24328;&#30340;&#20027;&#26041;&#31243;&#12290;&#35299;&#20915;MFGs&#20026;&#20855;&#26377;&#26377;&#38480;&#20294;&#22823;&#37327;&#20195;&#29702;&#20154;&#32676;&#30340;&#38543;&#26426;&#12289;&#24494;&#20998;&#21338;&#24328;&#25552;&#20379;&#36817;&#20284;&#32435;&#20160;&#22343;&#34913;&#12290;&#20027;&#26041;&#31243;&#26159;&#19968;&#20010;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#65292;&#20854;&#35299;&#34920;&#24449;&#20219;&#20309;&#21487;&#33021;&#30340;&#21021;&#22987;&#20998;&#24067;&#19979;&#30340;MFG&#22343;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31532;&#19968;&#31181;&#26041;&#27861;&#20381;&#36182;&#20110;&#22312;&#26102;&#38388;&#20998;&#37327;&#19978;&#30340;&#21453;&#21521;&#24402;&#32435;&#65292;&#32780;&#31532;&#20108;&#31181;&#26041;&#27861;&#30452;&#25509;&#35299;&#20915;&#20102;PDE&#65292;&#32780;&#26080;&#38656;&#31163;&#25955;&#21270;&#26102;&#38388;&#12290;&#23545;&#20110;&#20004;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#32467;&#26524;&#65306;&#23384;&#22312;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#20351;&#31639;&#27861;&#30340;&#25439;&#22833;&#20989;&#25968;&#20219;&#24847;&#23567;&#65292;&#24182;&#19988;&#21453;&#20043;&#65292;&#22914;&#26524;&#25439;&#22833;&#24456;&#23567;&#65292;&#21017;&#31070;&#32463;&#32593;&#32476;&#26159;&#20027;&#26041;&#31243;&#35299;&#30340;&#33391;&#22909;&#36817;&#20284;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#25991;&#29486;&#20013;&#30340;&#22522;&#20934;&#38382;&#39064;&#36827;&#34892;&#20102;&#32500;&#24230;&#20026;15&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#24182;&#20570;&#20986;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04975v1 Announce Type: cross  Abstract: This paper proposes and analyzes two neural network methods to solve the master equation for finite-state mean field games (MFGs). Solving MFGs provides approximate Nash equilibria for stochastic, differential games with finite but large populations of agents. The master equation is a partial differential equation (PDE) whose solution characterizes MFG equilibria for any possible initial distribution. The first method we propose relies on backward induction in a time component while the second method directly tackles the PDE without discretizing time. For both approaches, we prove two types of results: there exist neural networks that make the algorithms' loss functions arbitrarily small, and conversely, if the losses are small, then the neural networks are good approximations of the master equation's solution. We conclude the paper with numerical experiments on benchmark problems from the literature up to dimension 15, and a compariso
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.05639</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Instrumental Variable Regression through Stochastic Approximate Gradients
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;SAGD-IV&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26469;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#65288;NPIV&#65289;&#22238;&#24402;&#26694;&#26550;&#12290;&#20202;&#22120;&#21464;&#37327;&#65288;IV&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#65292;&#20197;&#35299;&#20915;&#22312;&#23384;&#22312;&#19981;&#21487;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#19988;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#33268;&#21147;&#20110;&#25913;&#36827;&#29616;&#26377;&#26041;&#27861;&#24182;&#22312;NPIV&#35774;&#32622;&#19979;&#35774;&#35745;&#26032;&#26041;&#27861;&#65292;&#35813;&#35774;&#32622;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#19981;&#36866;&#23450;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#25105;&#20204;&#31639;&#27861;&#30340;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#23454;&#39564;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#24182;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#32780;&#35813;&#24773;&#20917;&#22312;&#31038;&#21306;&#20013;&#27809;&#26377;&#24471;&#21040;&#19982;&#20854;&#36830;&#32493;&#23545;&#24212;&#29289;&#30340;&#21516;&#26679;&#20851;&#27880;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes SAGD-IV, a novel framework for conducting nonparametric instrumental variable (NPIV) regression by employing stochastic approximate gradients to minimize the projected populational risk. Instrumental Variables (IVs) are widely used in econometrics to address estimation problems in the presence of unobservable confounders, and the Machine Learning community has devoted significant effort to improving existing methods and devising new ones in the NPIV setting, which is known to be an ill-posed linear inverse problem. We provide theoretical support for our algorithm and further exemplify its competitive performance through empirical experiments. Furthermore, we address, with promising results, the case of binary outcomes, which has not received as much attention from the community as its continuous counterpart.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#31561;&#22810;&#31181;&#26550;&#26500;&#65292;&#25506;&#32034;&#20102;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#35748;&#20026;&#23545;&#20110;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#19981;&#21516;&#26550;&#26500;&#38656;&#35201;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#12290;</title><link>https://arxiv.org/abs/2402.04875</link><description>&lt;p&gt;
&#20851;&#20110;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Provable Length and Compositional Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#31561;&#22810;&#31181;&#26550;&#26500;&#65292;&#25506;&#32034;&#20102;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#35748;&#20026;&#23545;&#20110;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#19981;&#21516;&#26550;&#26500;&#38656;&#35201;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#24230;&#27867;&#21270;&#8212;&#8212;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#21040;&#30340;&#26356;&#38271;&#24207;&#21015;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#21450;&#32452;&#21512;&#27867;&#21270;&#8212;&#8212;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#21040;&#30340;&#20196;&#29260;&#32452;&#21512;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#20013;&#26159;&#37325;&#35201;&#30340;&#38750;&#20998;&#24067;&#21270;&#27867;&#21270;&#24418;&#24335;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#19968;&#31995;&#21015;&#26550;&#26500;&#20013;&#65292;&#26397;&#30528;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;&#26681;&#25454;&#26550;&#26500;&#30340;&#19981;&#21516;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#30340;&#24517;&#35201;&#24615;&#65292;&#20363;&#22914;&#19982;&#30495;&#23454;&#34920;&#31034;&#20855;&#26377;&#32447;&#24615;&#25110;&#25490;&#21015;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Length generalization -- the ability to generalize to longer sequences than ones seen during training, and compositional generalization -- the ability to generalize to token combinations not seen during training, are crucial forms of out-of-distribution generalization in sequence-to-sequence models. In this work, we take the first steps towards provable length and compositional generalization for a range of architectures, including deep sets, transformers, state space models, and simple recurrent neural nets. Depending on the architecture, we prove different degrees of representation identification, e.g., a linear or a permutation relation with ground truth representation, is necessary for length and compositional generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2402.02322</link><description>&lt;p&gt;
&#21160;&#24577;&#22686;&#37327;&#20248;&#21270;&#29992;&#20110;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Dynamic Incremental Optimization for Best Subset Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#34987;&#35748;&#20026;&#26159;&#31232;&#30095;&#23398;&#20064;&#38382;&#39064;&#30340;&#8220;&#40644;&#37329;&#26631;&#20934;&#8221;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#20248;&#21270;&#25216;&#26415;&#26469;&#25915;&#20987;&#36825;&#20010;&#38750;&#20809;&#28369;&#38750;&#20984;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#12290;&#22522;&#20110;&#21407;&#22987;&#38382;&#39064;&#21644;&#23545;&#20598;&#38382;&#39064;&#30340;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#12290;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#28508;&#22312;&#22320;&#20943;&#23569;&#20102;&#20887;&#20313;&#35745;&#31639;&#24182;&#25913;&#36827;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Best subset selection is considered the `gold standard' for many sparse learning problems. A variety of optimization techniques have been proposed to attack this non-smooth non-convex problem. In this paper, we investigate the dual forms of a family of $\ell_0$-regularized problems. An efficient primal-dual algorithm is developed based on the primal and dual problem structures. By leveraging the dual range estimation along with the incremental strategy, our algorithm potentially reduces redundant computation and improves the solutions of best subset selection. Theoretical analysis and experiments on synthetic and real-world datasets validate the efficiency and statistical properties of the proposed solutions.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#35777;&#38750;&#20984;&#20998;&#35299;&#26041;&#27861;&#29992;&#20110;&#24352;&#37327;&#21015;&#36710;&#24674;&#22797;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#24038;&#27491;&#20132;TT&#26684;&#24335;&#26469;&#23454;&#29616;&#27491;&#20132;&#32467;&#26500;&#65292;&#24182;&#20351;&#29992;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#20248;&#21270;&#22240;&#23376;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#24182;&#19988;&#22312;&#28385;&#36275;&#21463;&#38480;&#31561;&#35889;&#24615;&#36136;&#30340;&#26465;&#20214;&#19979;&#33021;&#22815;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#12290;</title><link>http://arxiv.org/abs/2401.02592</link><description>&lt;p&gt;
&#20445;&#35777;&#38750;&#20984;&#20998;&#35299;&#26041;&#27861;&#29992;&#20110;&#24352;&#37327;&#21015;&#36710;&#24674;&#22797;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Guaranteed Nonconvex Factorization Approach for Tensor Train Recovery. (arXiv:2401.02592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#35777;&#38750;&#20984;&#20998;&#35299;&#26041;&#27861;&#29992;&#20110;&#24352;&#37327;&#21015;&#36710;&#24674;&#22797;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#24038;&#27491;&#20132;TT&#26684;&#24335;&#26469;&#23454;&#29616;&#27491;&#20132;&#32467;&#26500;&#65292;&#24182;&#20351;&#29992;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#20248;&#21270;&#22240;&#23376;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#24182;&#19988;&#22312;&#28385;&#36275;&#21463;&#38480;&#31561;&#35889;&#24615;&#36136;&#30340;&#26465;&#20214;&#19979;&#33021;&#22815;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;&#23545;&#20110;&#20998;&#35299;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#36991;&#20813;&#23610;&#24230;&#27495;&#20041;&#24182;&#20415;&#20110;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#20248;&#21270;&#25152;&#35859;&#30340;&#24038;&#27491;&#20132;TT&#26684;&#24335;&#65292;&#24378;&#21046;&#20351;&#22823;&#37096;&#20998;&#22240;&#23376;&#24444;&#27492;&#27491;&#20132;&#12290;&#20026;&#20102;&#30830;&#20445;&#27491;&#20132;&#32467;&#26500;&#65292;&#25105;&#20204;&#21033;&#29992;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#65288;RGD&#65289;&#26469;&#20248;&#21270;Stiefel&#27969;&#24418;&#19978;&#30340;&#36825;&#20123;&#22240;&#23376;&#12290;&#25105;&#20204;&#39318;&#20808;&#28145;&#20837;&#30740;&#31350;TT&#20998;&#35299;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;RGD&#30340;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#38543;&#30528;&#24352;&#37327;&#38454;&#25968;&#30340;&#22686;&#21152;&#65292;&#25910;&#25947;&#36895;&#29575;&#20165;&#32463;&#21382;&#32447;&#24615;&#19979;&#38477;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24863;&#30693;&#38382;&#39064;&#65292;&#21363;&#20174;&#32447;&#24615;&#27979;&#37327;&#20013;&#24674;&#22797;TT&#26684;&#24335;&#24352;&#37327;&#12290;&#20551;&#35774;&#24863;&#30693;&#31639;&#23376;&#28385;&#36275;&#21463;&#38480;&#31561;&#35889;&#24615;&#36136;&#65288;RIP&#65289;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#36890;&#36807;&#35889;&#21021;&#22987;&#21270;&#33719;&#24471;&#65292;RGD&#20063;&#20250;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide the first convergence guarantee for the factorization approach. Specifically, to avoid the scaling ambiguity and to facilitate theoretical analysis, we optimize over the so-called left-orthogonal TT format which enforces orthonormality among most of the factors. To ensure the orthonormal structure, we utilize the Riemannian gradient descent (RGD) for optimizing those factors over the Stiefel manifold. We first delve into the TT factorization problem and establish the local linear convergence of RGD. Notably, the rate of convergence only experiences a linear decline as the tensor order increases. We then study the sensing problem that aims to recover a TT format tensor from linear measurements. Assuming the sensing operator satisfies the restricted isometry property (RIP), we show that with a proper initialization, which could be obtained through spectral initialization, RGD also converges to the ground-truth tensor at a linear rate. Furthermore, we expand our 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#26377;&#25928;&#20943;&#36731;&#20102;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.19653</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#30340;&#26080;&#38480;&#25968;&#25454;&#35745;&#21010;&#21319;&#32423;VAE&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion Models. (arXiv:2310.19653v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19653
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#26377;&#25928;&#20943;&#36731;&#20102;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#34920;&#31034;&#23398;&#20064;&#27169;&#22411;&#65292;&#20294;&#20854;&#32534;&#30721;&#22120;&#23481;&#26131;&#36807;&#25311;&#21512;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;&#19981;&#26159;&#30495;&#23454;&#65288;&#36830;&#32493;&#65289;&#25968;&#25454;&#20998;&#24067;$p_{\mathrm{data}}(\mathbf{x})$&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#22266;&#23450;&#32534;&#30721;&#22120;&#36991;&#20813;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#36825;&#20351;&#24471;&#23427;&#20204;&#30340;&#34920;&#31034;&#19981;&#22826;&#21487;&#35299;&#37322;&#65292;&#20294;&#31616;&#21270;&#20102;&#35757;&#32451;&#65292;&#21487;&#20197;&#31934;&#30830;&#21644;&#36830;&#32493;&#22320;&#36924;&#36817;$p_{\mathrm{data}}(\mathbf{x})$&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#35757;&#32451;&#65292;&#21487;&#20197;&#26377;&#25928;&#20943;&#36731;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#36825;&#20123;&#32467;&#26524;&#26377;&#20123;&#20986;&#20154;&#24847;&#26009;&#65292;&#22240;&#20026;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#20351;&#29992;&#21478;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#26102;&#65292;&#29983;&#25104;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#35757;&#32451;&#30340;VAE&#30340;&#27867;&#21270;&#24615;&#33021;&#12289;&#20998;&#25674;&#24046;&#36317;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) are popular models for representation learning but their encoders are susceptible to overfitting (Cremer et al., 2018) because they are trained on a finite training set instead of the true (continuous) data distribution $p_{\mathrm{data}}(\mathbf{x})$. Diffusion models, on the other hand, avoid this issue by keeping the encoder fixed. This makes their representations less interpretable, but it simplifies training, enabling accurate and continuous approximations of $p_{\mathrm{data}}(\mathbf{x})$. In this paper, we show that overfitting encoders in VAEs can be effectively mitigated by training on samples from a pre-trained diffusion model. These results are somewhat unexpected as recent findings (Alemohammad et al., 2023; Shumailov et al., 2023) observe a decay in generative performance when models are trained on data generated by another generative model. We analyze generalization performance, amortization gap, and robustness of VAEs trained with our pro
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#19982;&#20998;&#24067;&#27010;&#25324;&#30340;&#26032;&#36830;&#25509;&#65292;&#35299;&#20915;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05805</link><description>&lt;p&gt;
&#25552;&#21319;&#25511;&#21046;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Boosted Control Functions. (arXiv:2310.05805v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#19982;&#20998;&#24067;&#27010;&#25324;&#30340;&#26032;&#36830;&#25509;&#65292;&#35299;&#20915;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#20026;&#20174;&#22823;&#37327;&#30340;&#21327;&#21464;&#37327;&#20013;&#20934;&#30830;&#39044;&#27979;&#30446;&#26631;&#25968;&#37327;&#25171;&#24320;&#20102;&#22823;&#38376;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#27979;&#26041;&#27861;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#19981;&#20339;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#38544;&#34255;&#28151;&#28102;&#30340;&#24773;&#20917;&#19979;&#12290;&#34429;&#28982;&#23545;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65288;&#20363;&#22914;&#20202;&#22120;&#21464;&#37327;&#65289;&#24050;&#32463;&#23545;&#38544;&#34255;&#28151;&#28102;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#39044;&#27979;&#20219;&#21153;&#26469;&#35828;&#24182;&#38750;&#22914;&#27492;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#35299;&#20915;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#30340;&#24773;&#20917;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#20998;&#24067;&#27010;&#25324;&#39046;&#22495;&#65292;&#20197;&#21450;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#30340;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#21644;&#25511;&#21046;&#20989;&#25968;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#30340;&#26680;&#24515;&#26159;&#25551;&#36848;&#22312;&#19968;&#32452;&#20998;&#24067;&#36716;&#21464;&#19979;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#20998;&#24067;&#27010;&#25324;&#21516;&#26102;&#26041;&#31243;&#27169;&#22411;&#65288;SIMDGs&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning methods and the availability of large-scale data opened the door to accurately predict target quantities from large sets of covariates. However, existing prediction methods can perform poorly when the training and testing data are different, especially in the presence of hidden confounding. While hidden confounding is well studied for causal effect estimation (e.g., instrumental variables), this is not the case for prediction tasks. This work aims to bridge this gap by addressing predictions under different training and testing distributions in the presence of unobserved confounding. In particular, we establish a novel connection between the field of distribution generalization from machine learning, and simultaneous equation models and control function from econometrics. Central to our contribution are simultaneous equation models for distribution generalization (SIMDGs) which describe the data-generating process under a set of distributional shifts. Within thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.02211</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Machine Learning with Multi-source Data. (arXiv:2309.02211v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#30446;&#26631;&#20998;&#24067;&#19982;&#28304;&#25968;&#25454;&#38598;&#19981;&#21516;&#26102;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#36739;&#24046;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26412;&#25991;&#21033;&#29992;&#22810;&#20010;&#25968;&#25454;&#28304;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#20248;&#21270;&#20851;&#20110;&#30446;&#26631;&#20998;&#24067;&#31867;&#30340;&#21487;&#35299;&#37322;&#26041;&#24046;&#30340;&#23545;&#25239;&#24615;&#22870;&#21169;&#12290;&#19982;&#20256;&#32479;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#25913;&#21892;&#20102;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26159;&#28304;&#25968;&#25454;&#38598;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340;&#21152;&#26435;&#24179;&#22343;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#20851;&#38190;&#37492;&#21035;&#32467;&#26524;&#26469;&#25552;&#39640;&#20219;&#24847;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#21644;&#31070;&#32463;&#32593;&#32476;&#31561;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#22120;&#26469;&#20272;&#35745;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;c&#26041;&#38754;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal aggregation weight for general machine-learning algorithms and demonstrate its improvement in the c
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20998;&#24067;&#23545;&#31216;&#24615;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#38598;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#27979;&#35797;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#12290;</title><link>http://arxiv.org/abs/2307.15834</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#23545;&#20998;&#37197;&#32676;&#23545;&#31216;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Non-parametric Hypothesis Tests for Distributional Group Symmetry. (arXiv:2307.15834v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15834
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20998;&#24067;&#23545;&#31216;&#24615;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#38598;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#27979;&#35797;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#24615;&#22312;&#31185;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#36215;&#30528;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#23545;&#20110;&#24050;&#30693;&#36981;&#24490;&#23545;&#31216;&#24615;&#30340;&#25968;&#25454;&#65292;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#35768;&#22810;&#21033;&#29992;&#23545;&#31216;&#24615;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26222;&#36941;&#32676;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#25110;&#19981;&#23384;&#22312;&#30340;&#32479;&#35745;&#26816;&#39564;&#20960;&#20046;&#19981;&#23384;&#22312;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#22522;&#20110;&#21333;&#20010;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#65292;&#29992;&#20110;&#38024;&#23545;&#29305;&#23450;&#32676;&#30340;&#20998;&#24067;&#23545;&#31216;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36866;&#29992;&#20110;&#20004;&#31181;&#24191;&#27867;&#24773;&#20917;&#30340;&#23545;&#31216;&#24615;&#26816;&#39564;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#31532;&#19968;&#31181;&#24773;&#20917;&#26159;&#27979;&#35797;&#22312;&#32039;&#33268;&#32676;&#20316;&#29992;&#19979;&#30340;&#36793;&#38469;&#25110;&#32852;&#21512;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#19968;&#20010;&#28176;&#36817;&#26080;&#20559;&#30340;&#26816;&#39564;&#21482;&#38656;&#35201;&#19968;&#20010;&#21487;&#35745;&#31639;&#30340;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#19978;&#30340;&#24230;&#37327;&#21644;&#33021;&#22815;&#22343;&#21248;&#38543;&#26426;&#37319;&#26679;&#32676;&#20803;&#32032;&#30340;&#33021;&#21147;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;&#26465;&#20214;&#33945;&#29305;&#21345;&#32599;&#26816;&#39564;&#65292;&#24182;&#35777;&#26126;&#23427;&#21487;&#20197;&#23454;&#29616;&#31934;&#30830;&#30340;p&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symmetry plays a central role in the sciences, machine learning, and statistics. For situations in which data are known to obey a symmetry, a multitude of methods that exploit symmetry have been developed. Statistical tests for the presence or absence of general group symmetry, however, are largely non-existent. This work formulates non-parametric hypothesis tests, based on a single independent and identically distributed sample, for distributional symmetry under a specified group. We provide a general formulation of tests for symmetry that apply to two broad settings. The first setting tests for the invariance of a marginal or joint distribution under the action of a compact group. Here, an asymptotically unbiased test only requires a computable metric on the space of probability distributions and the ability to sample uniformly random group elements. Building on this, we propose an easy-to-implement conditional Monte Carlo test and prove that it achieves exact $p$-values with finitel
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#27714;&#35299;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;OED&#38382;&#39064;&#65292;&#32467;&#26524;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#26356;&#23569;&#30340;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.10430</link><description>&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Variational Sequential Optimal Experimental Design using Reinforcement Learning. (arXiv:2306.10430v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10430
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#27714;&#35299;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;OED&#38382;&#39064;&#65292;&#32467;&#26524;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#26356;&#23569;&#30340;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745; (vsOED) &#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#26469;&#26368;&#20248;&#22320;&#35774;&#35745;&#26377;&#38480;&#24207;&#21015;&#30340;&#23454;&#39564;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#21464;&#20998;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#19979;&#30028;&#20272;&#35745;&#26399;&#26395;&#25928;&#29992;&#12290;&#36890;&#36807;&#21516;&#26102;&#26368;&#22823;&#21270;&#21464;&#20998;&#19979;&#30028;&#21644;&#25191;&#34892;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#26469;&#25968;&#20540;&#35299;&#20915;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#31995;&#21015;&#38754;&#21521;&#21442;&#25968;&#25512;&#26029;&#12289;&#27169;&#22411;&#21306;&#20998;&#21644;&#30446;&#26631;&#23548;&#21521;&#39044;&#27979;&#30340;OED&#38382;&#39064;&#12290;&#36825;&#20123;&#26696;&#20363;&#28085;&#30422;&#20102;&#26174;&#24335;&#21644;&#38544;&#24335;&#20284;&#28982;&#20989;&#25968;&#12289;&#40635;&#28902;&#21442;&#25968;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;vsOED&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20197;&#21069;&#30340;&#39034;&#24207;&#35774;&#35745;&#31639;&#27861;&#30456;&#27604;&#65292;&#26679;&#26412;&#25928;&#29575;&#22823;&#22823;&#25552;&#39640;&#65292;&#25152;&#38656;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#20943;&#23569;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce variational sequential Optimal Experimental Design (vsOED), a new method for optimally designing a finite sequence of experiments under a Bayesian framework and with information-gain utilities. Specifically, we adopt a lower bound estimator for the expected utility through variational approximation to the Bayesian posteriors. The optimal design policy is solved numerically by simultaneously maximizing the variational lower bound and performing policy gradient updates. We demonstrate this general methodology for a range of OED problems targeting parameter inference, model discrimination, and goal-oriented prediction. These cases encompass explicit and implicit likelihoods, nuisance parameters, and physics-based partial differential equation models. Our vsOED results indicate substantially improved sample efficiency and reduced number of forward model simulations compared to previous sequential design algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#22312;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;ODE&#31995;&#32479;&#65292;&#21487;&#20197;&#35299;&#20915;&#26174;&#24335;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#25968;&#25454;&#21644;&#22270;&#20687;&#25968;&#25454;&#20013;&#37117;&#20855;&#26377;&#36890;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.10189</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#23398;&#20064;&#39640;&#32500;&#38750;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning High-Dimensional Nonparametric Differential Equations via Multivariate Occupation Kernel Functions. (arXiv:2306.10189v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#22312;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;ODE&#31995;&#32479;&#65292;&#21487;&#20197;&#35299;&#20915;&#26174;&#24335;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#25968;&#25454;&#21644;&#22270;&#20687;&#25968;&#25454;&#20013;&#37117;&#20855;&#26377;&#36890;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;$d$&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;$n$&#20010;&#36712;&#36857;&#24555;&#29031;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#31995;&#32479;&#38656;&#35201;&#23398;&#20064;$d$&#20010;&#20989;&#25968;&#12290;&#38500;&#38750;&#20855;&#26377;&#39069;&#22806;&#30340;&#31995;&#32479;&#23646;&#24615;&#30693;&#35782;&#65292;&#20363;&#22914;&#31232;&#30095;&#24615;&#21644;&#23545;&#31216;&#24615;&#65292;&#21542;&#21017;&#26174;&#24335;&#30340;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21521;&#37327;&#20540;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#25552;&#20379;&#30340;&#38544;&#24335;&#20844;&#24335;&#23398;&#20064;&#30340;&#32447;&#24615;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;ODE&#37325;&#20889;&#20026;&#26356;&#24369;&#30340;&#31215;&#20998;&#24418;&#24335;&#65292;&#25105;&#20204;&#38543;&#21518;&#36827;&#34892;&#26368;&#23567;&#21270;&#24182;&#25512;&#23548;&#20986;&#25105;&#20204;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#35299;&#21521;&#37327;&#22330;&#20381;&#36182;&#20110;&#19982;&#35299;&#36712;&#36857;&#30456;&#20851;&#30340;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;$d$&#21487;&#33021;&#36229;&#36807;100&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#20174;&#22270;&#20687;&#25968;&#25454;&#23398;&#20064;&#38750;&#21442;&#25968;&#19968;&#38454;&#25311;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning a nonparametric system of ordinary differential equations (ODEs) from $n$ trajectory snapshots in a $d$-dimensional state space requires learning $d$ functions of $d$ variables. Explicit formulations scale quadratically in $d$ unless additional knowledge about system properties, such as sparsity and symmetries, is available. In this work, we propose a linear approach to learning using the implicit formulation provided by vector-valued Reproducing Kernel Hilbert Spaces. By rewriting the ODEs in a weaker integral form, which we subsequently minimize, we derive our learning algorithm. The minimization problem's solution for the vector field relies on multivariate occupation kernel functions associated with the solution trajectories. We validate our approach through experiments on highly nonlinear simulated and real data, where $d$ may exceed 100. We further demonstrate the versatility of the proposed method by learning a nonparametric first order quasilinear partial differential 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#33021;&#22815;&#23558;&#25968;&#23383;&#29305;&#24449;&#32534;&#30721;&#20026;&#22522;&#20989;&#25968;&#21521;&#37327;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22240;&#23376;&#26426;&#20013;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#22240;&#23376;&#26426;&#20013;&#65292;&#21487;&#20197;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14528</link><description>&lt;p&gt;
&#22522;&#20989;&#25968;&#32534;&#30721;&#25913;&#21892;&#22240;&#23376;&#26426;&#20013;&#25968;&#23383;&#29305;&#24449;&#30340;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Basis Function Encoding of Numerical Features in Factorization Machines for Improved Accuracy. (arXiv:2305.14528v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14528
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#33021;&#22815;&#23558;&#25968;&#23383;&#29305;&#24449;&#32534;&#30721;&#20026;&#22522;&#20989;&#25968;&#21521;&#37327;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22240;&#23376;&#26426;&#20013;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#22240;&#23376;&#26426;&#20013;&#65292;&#21487;&#20197;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#23376;&#26426;(FM)&#21464;&#20307;&#34987;&#24191;&#27867;&#29992;&#20110;&#22823;&#35268;&#27169;&#23454;&#26102;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#27169;&#22411;&#20934;&#30830;&#24615;&#21644;&#35757;&#32451;&#25512;&#29702;&#30340;&#20302;&#35745;&#31639;&#25104;&#26412;&#20043;&#38388;&#25552;&#20379;&#20102;&#20986;&#33394;&#30340;&#24179;&#34913;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#12289;&#29702;&#35770;&#19978;&#21512;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25968;&#20540;&#29305;&#24449;&#32534;&#30721;&#20026;&#25152;&#36873;&#20989;&#25968;&#38598;&#30340;&#20989;&#25968;&#20540;&#21521;&#37327;&#23558;&#25968;&#20540;&#29305;&#24449;&#32435;&#20837;FM&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Factorization machine (FM) variants are widely used for large scale real-time content recommendation systems, since they offer an excellent balance between model accuracy and low computational costs for training and inference. These systems are trained on tabular data with both numerical and categorical columns. Incorporating numerical columns poses a challenge, and they are typically incorporated using a scalar transformation or binning, which can be either learned or chosen a-priori. In this work, we provide a systematic and theoretically-justified way to incorporate numerical features into FM variants by encoding them into a vector of function values for a set of functions of one's choice.  We view factorization machines as approximators of segmentized functions, namely, functions from a field's value to the real numbers, assuming the remaining fields are assigned some given constants, which we refer to as the segment. From this perspective, we show that our technique yields a model
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#36275;&#22815;&#24179;&#28369;&#20984;&#30340;&#28608;&#27963;&#20989;&#25968;&#26102;&#65292;SGD&#21487;&#20197;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#35777;&#26126;&#36807;&#31243;&#20013;&#24341;&#20837;Frobenius&#33539;&#25968;&#27491;&#21017;&#21270;&#19982;&#24688;&#24403;&#20998;&#24067;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#65292;&#21516;&#26102;&#25299;&#23637;&#20102;&#36830;&#32493;&#26102;&#38388;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.11452</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;SGD&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Global Convergence of SGD On Two Layer Neural Nets. (arXiv:2210.11452v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11452
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#36275;&#22815;&#24179;&#28369;&#20984;&#30340;&#28608;&#27963;&#20989;&#25968;&#26102;&#65292;SGD&#21487;&#20197;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#35777;&#26126;&#36807;&#31243;&#20013;&#24341;&#20837;Frobenius&#33539;&#25968;&#27491;&#21017;&#21270;&#19982;&#24688;&#24403;&#20998;&#24067;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#65292;&#21516;&#26102;&#25299;&#23637;&#20102;&#36830;&#32493;&#26102;&#38388;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#28145;&#24230;&#20026;2&#30340;&#32593;&#32476;&#37319;&#29992;&#36275;&#22815;&#24179;&#28369;&#19988;&#26377;&#36793;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#65288;&#27604;&#22914;sigmoid&#21644;tanh&#65289;&#26102;&#65292;SGD&#21487;&#20197;&#35777;&#26126;&#24615;&#22320;&#25910;&#25947;&#21040;&#36866;&#24403;&#27491;&#21017;&#21270;&#30340;$\ell_2-$&#32463;&#39564;&#39118;&#38505;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;--&#23545;&#20110;&#20219;&#24847;&#25968;&#25454;&#21644;&#20219;&#24847;&#25968;&#37327;&#30340;&#38376;&#12290;&#25105;&#20204;&#22312;[1]&#30340;&#30740;&#31350;&#25104;&#26524;&#19978;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#24182;&#22312;&#26435;&#37325;&#19978;&#28155;&#21152;&#20102;&#24658;&#23450;&#37327;&#30340;Frobenius&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#21516;&#26102;&#36873;&#21462;&#20102;&#24688;&#24403;&#30340;&#20998;&#24067;&#23545;&#21021;&#22987;&#26435;&#37325;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#30340;SGD&#25910;&#25947;&#32467;&#26524;&#65292;&#21516;&#26679;&#36866;&#29992;&#20110;&#22914;SoftPlus&#36825;&#26679;&#30340;&#24179;&#28369;&#26080;&#36793;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24819;&#27861;&#26159;&#23637;&#31034;&#20102;&#23384;&#22312;&#20110;&#22266;&#23450;&#22823;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23427;&#20204;&#26159;&#8220;Villani&#20989;&#25968;&#8221;[1] Bin Shi, Weijie J. Su, and Michael I. Jordan. On learning rates and schr\"odinger operators, 2020. arXiv:2004.06977
&lt;/p&gt;
&lt;p&gt;
In this note we demonstrate provable convergence of SGD to the global minima of appropriately regularized $\ell_2-$empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates, if they are using adequately smooth and bounded activations like sigmoid and tanh. We build on the results in [1] and leverage a constant amount of Frobenius norm regularization on the weights, along with sampling of the initial weights from an appropriate distribution. We also give a continuous time SGD convergence result that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence loss functions on constant sized neural nets which are "Villani Functions". [1] Bin Shi, Weijie J. Su, and Michael I. Jordan. On learning rates and schr\"odinger operators, 2020. arXiv:2004.06977
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#65292;&#26469;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2205.14568</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#30340;&#39044;&#27979;&#20998;&#24067;&#65306;&#22312;&#38134;&#27827;&#32418;&#31227;&#20272;&#35745;&#21644;&#27010;&#29575;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Conditionally Calibrated Predictive Distributions by Probability-Probability Map: Application to Galaxy Redshift Estimation and Probabilistic Forecasting. (arXiv:2205.14568v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#65292;&#26469;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#35780;&#20272;AI&#31639;&#27861;&#30340;&#39044;&#27979;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#33268;&#21147;&#20110;&#25551;&#36848;&#30446;&#26631;&#21464;&#37327;$y \in \mathbb{R}$&#22312;&#32473;&#23450;&#22797;&#26434;&#36755;&#20837;&#29305;&#24449;$\mathbf{x} \in \mathcal{X}$&#30340;&#26465;&#20214;&#19979;&#30340;&#39044;&#27979;&#20998;&#24067;$F(y|\mathbf{x})$&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#27979;&#20998;&#24067;&#65288;&#20363;&#22914;&#65292;&#24402;&#19968;&#21270;&#27969;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65289;&#24448;&#24448;&#32570;&#20047;&#26465;&#20214;&#26657;&#20934;&#65292;&#21363;&#32473;&#23450;&#36755;&#20837;$\mathbf{x}$&#30340;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#19982;&#39044;&#27979;&#27010;&#29575;&#26174;&#33879;&#19981;&#21516;&#12290;&#24403;&#21069;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#33021;&#23436;&#20840;&#35780;&#20272;&#21644;&#23454;&#26045;&#26377;&#26465;&#20214;&#26657;&#20934;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20174;&#26657;&#20934;&#25968;&#25454;&#20013;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#26469;&#21516;&#26102;&#35299;&#20915;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23545;&#27010;&#29575;&#31215;&#20998;&#21464;&#25442;&#20998;&#25968;&#36827;&#34892;$\mathbf{x}$&#30340;&#22238;&#24402;&#12290;&#20272;&#35745;&#30340;&#22238;&#24402;&#25552;&#20379;&#20102;&#23545;&#29305;&#24449;&#31354;&#38388;&#20013;&#26465;&#20214;&#35206;&#30422;&#30340;&#21487;&#35299;&#37322;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification is crucial for assessing the predictive ability of AI algorithms. Much research has been devoted to describing the predictive distribution (PD) $F(y|\mathbf{x})$ of a target variable $y \in \mathbb{R}$ given complex input features $\mathbf{x} \in \mathcal{X}$. However, off-the-shelf PDs (from, e.g., normalizing flows and Bayesian neural networks) often lack conditional calibration with the probability of occurrence of an event given input $\mathbf{x}$ being significantly different from the predicted probability. Current calibration methods do not fully assess and enforce conditionally calibrated PDs. Here we propose \texttt{Cal-PIT}, a method that addresses both PD diagnostics and recalibration by learning a single probability-probability map from calibration data. The key idea is to regress probability integral transform scores against $\mathbf{x}$. The estimated regression provides interpretable diagnostics of conditional coverage across the feature space. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#30340;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#36827;&#30340;&#20505;&#36873;&#29238;&#33410;&#28857;&#38598;&#21512;&#30340;&#30830;&#23450;&#21644;&#20998;&#35299;&#65292;&#20197;&#21450;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#30340;&#35299;&#20915;&#65292;&#33021;&#22815;&#22312;&#27604;&#29305;&#23481;&#37327;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#35299;&#20915;&#22522;&#20110;&#35780;&#20998;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2006.06926</link><description>&lt;p&gt;
&#29992;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#23398;&#20064;&#36125;&#21494;&#26031;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Bayesian Networks with Annealing Machine. (arXiv:2006.06926v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.06926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#30340;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#36827;&#30340;&#20505;&#36873;&#29238;&#33410;&#28857;&#38598;&#21512;&#30340;&#30830;&#23450;&#21644;&#20998;&#35299;&#65292;&#20197;&#21450;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#30340;&#35299;&#20915;&#65292;&#33021;&#22815;&#22312;&#27604;&#29305;&#23481;&#37327;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#35299;&#20915;&#22522;&#20110;&#35780;&#20998;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#33021;&#22815;&#39640;&#31934;&#24230;&#22320;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#26377;&#28508;&#21147;&#29992;&#20110;&#22522;&#20110;&#35780;&#20998;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#30340;&#27604;&#29305;&#23481;&#37327;&#30446;&#21069;&#26377;&#38480;&#12290;&#20026;&#20102;&#21033;&#29992;&#27169;&#25311;&#36864;&#28779;&#25216;&#26415;&#65292;&#38656;&#35201;&#23558;&#22522;&#20110;&#35780;&#20998;&#30340;&#23398;&#20064;&#38382;&#39064;&#36716;&#21270;&#20026;&#22312;&#27604;&#29305;&#23481;&#37327;&#20869;&#30340;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20803;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#36716;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#36827;&#30340;&#20505;&#36873;&#29238;&#33410;&#28857;&#38598;&#21512;&#30340;&#30830;&#23450;&#21644;&#20854;&#20998;&#35299;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#65292;&#20197;&#25214;&#21040;&#26368;&#23567;&#21270;&#25152;&#38656;&#27604;&#29305;&#25968;&#30340;&#20998;&#35299;&#12290;&#22312;&#21253;&#21547;&#21464;&#37327;&#20174;75&#21040;223&#30340;7&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25152;&#38656;&#30340;&#27604;&#29305;&#25968;&#27604;&#22235;&#20195;&#23500;&#22763;&#36890;&#25968;&#23383;&#36864;&#28779;&#22120;&#65288;&#19968;&#31181;&#37319;&#29992;&#21322;&#23548;&#20307;&#25216;&#26415;&#24320;&#21457;&#30340;&#20840;&#32806;&#21512;&#27169;&#25311;&#36864;&#28779;&#26426;&#22120;&#65289;&#30340;100K&#27604;&#29305;&#23481;&#37327;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have reported that annealing machines are capable of solving combinatorial optimization problems with high accuracy. Annealing machines can potentially be applied to score-based Bayesian network structure learning. However, the bit capacity of an annealing machine is currently limited. To utilize the annealing technology, converting score-based learning problems into quadratic unconstrained binary optimizations within the bit capacity is necessary. In this paper, we propose an efficient conversion method with the advanced identification of candidate parent sets and their decomposition. We also provide an integer programming problem to find the decomposition that minimizes the number of required bits. Experimental results on $7$ benchmark datasets with variables from $75$ to $223$ show that our approach requires less bits than the $100$K bit capacity of the fourth-generation Fujitsu Digital Annealer, a fully coupled annealing machine developed with semiconductor technolog
&lt;/p&gt;</description></item></channel></rss>