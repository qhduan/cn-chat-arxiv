<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.03819</link><description>&lt;p&gt;
SMOTE&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#30740;&#31350;&#65306;&#20851;&#20110;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#30340;&#38480;&#21046;&#21644;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03819
&lt;/p&gt;
&lt;p&gt;
SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
SMOTE&#65288;Synthetic Minority Oversampling Technique&#65289;&#26159;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#24120;&#29992;&#30340;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;SMOTE&#65288;&#40664;&#35748;&#21442;&#25968;&#65289;&#36890;&#36807;&#31616;&#21333;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#25903;&#25345;&#36793;&#30028;&#38468;&#36817;&#65292;SMOTE&#30340;&#23494;&#24230;&#20250;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;&#24120;&#35265;&#30340;BorderLine SMOTE&#31574;&#30053;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#29616;&#26377;&#30340;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21482;&#26377;&#24403;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#26102;&#25165;&#38656;&#35201;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#23545;&#20110;&#36825;&#31181;&#25968;&#25454;&#38598;&#65292;SMOTE&#12289;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced data sets. Asymptotically, we prove that SMOTE (with default parameter) regenerates the original distribution by simply copying the original minority samples. We also prove that SMOTE density vanishes near the boundary of the support of the minority distribution, therefore justifying the common BorderLine SMOTE strategy. Then we introduce two new SMOTE-related strategies, and compare them with state-of-the-art rebalancing procedures. We show that rebalancing strategies are only required when the data set is highly imbalanced. For such data sets, SMOTE, our proposals, or undersampling procedures are the best strategies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#20854;&#33021;&#22815;&#19982;&#21508;&#31181;MCMC&#26041;&#27861;&#32467;&#21512;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#32452;&#21512;&#21644;&#36827;&#34892;&#26356;&#22909;&#30340;&#37319;&#26679;&#12290;</title><link>http://arxiv.org/abs/2307.14012</link><description>&lt;p&gt;
MCMC-&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#29992;&#20110;&#27169;&#22411;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
MCMC-Correction of Score-Based Diffusion Models for Model Composition. (arXiv:2307.14012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#20854;&#33021;&#22815;&#19982;&#21508;&#31181;MCMC&#26041;&#27861;&#32467;&#21512;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#32452;&#21512;&#21644;&#36827;&#34892;&#26356;&#22909;&#30340;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#29992;&#24471;&#20998;&#25110;&#33021;&#37327;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#12290;&#33021;&#37327;&#21442;&#25968;&#21270;&#20855;&#26377;&#26356;&#22909;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#20027;&#35201;&#26159;&#23427;&#21487;&#20197;&#36890;&#36807;&#22312;&#25552;&#35758;&#26679;&#26412;&#20013;&#24635;&#33021;&#37327;&#30340;&#21464;&#21270;&#22522;&#20110;Metropolis-Hastings&#20462;&#27491;&#27493;&#39588;&#26469;&#36827;&#34892;&#25193;&#23637;&#37319;&#26679;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#23427;&#20284;&#20046;&#20135;&#29983;&#20102;&#31245;&#24494;&#36739;&#24046;&#30340;&#24615;&#33021;&#65292;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#30001;&#20110;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26222;&#36941;&#27969;&#34892;&#65292;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#33021;&#37327;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#21487;&#29992;&#24615;&#21463;&#21040;&#38480;&#21046;&#12290;&#36825;&#31181;&#38480;&#21046;&#21066;&#24369;&#20102;&#27169;&#22411;&#32452;&#21512;&#30340;&#30446;&#30340;&#65292;&#21363;&#23558;&#39044;&#35757;&#32451;&#27169;&#22411;&#32452;&#21512;&#36215;&#26469;&#20174;&#26032;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#25552;&#35758;&#24314;&#35758;&#20445;&#30041;&#24471;&#20998;&#21442;&#25968;&#21270;&#65292;&#32780;&#26159;&#36890;&#36807;&#23545;&#24471;&#20998;&#20989;&#25968;&#36827;&#34892;&#32447;&#31215;&#20998;&#26469;&#35745;&#31639;&#22522;&#20110;&#33021;&#37327;&#30340;&#25509;&#21463;&#27010;&#29575;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#37325;&#29992;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#23558;&#21453;&#21521;&#36807;&#31243;&#19982;&#21508;&#31181;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#26041;&#27861;&#32452;&#21512;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models can be parameterised in terms of either a score or an energy function. The energy parameterisation has better theoretical properties, mainly that it enables an extended sampling procedure with a Metropolis--Hastings correction step, based on the change in total energy in the proposed samples. However, it seems to yield slightly worse performance, and more importantly, due to the widespread popularity of score-based diffusion, there are limited availability of off-the-shelf pre-trained energy-based ones. This limitation undermines the purpose of model composition, which aims to combine pre-trained models to sample from new distributions. Our proposal, however, suggests retaining the score parameterization and instead computing the energy-based acceptance probability through line integration of the score function. This allows us to re-use existing diffusion models and still combine the reverse process with various Markov-Chain Monte Carlo (MCMC) methods. We evaluate our 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#30452;&#25509;&#21046;&#23450;&#25193;&#25955;&#22522;&#20110;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#20808;&#31163;&#25955;&#21270;&#20877;&#24212;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#36991;&#20813;&#21442;&#25968;&#32454;&#21270;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#65292;&#20026;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#25552;&#20379;&#20102;&#20934;&#21017;&#12290;</title><link>http://arxiv.org/abs/2302.10130</link><description>&lt;p&gt;
&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Infinite-Dimensional Diffusion Models. (arXiv:2302.10130v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10130
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#30452;&#25509;&#21046;&#23450;&#25193;&#25955;&#22522;&#20110;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#20808;&#31163;&#25955;&#21270;&#20877;&#24212;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#36991;&#20813;&#21442;&#25968;&#32454;&#21270;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#65292;&#20026;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#25552;&#20379;&#20102;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#37117;&#20135;&#29983;&#20102;&#28145;&#36828;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#37027;&#20123;&#25968;&#25454;&#26412;&#36136;&#19978;&#26159;&#26080;&#38480;&#32500;&#30340;&#39046;&#22495;&#65292;&#22914;&#22270;&#20687;&#25110;&#26102;&#38388;&#24207;&#21015;&#12290;&#26631;&#20934;&#26041;&#27861;&#26159;&#39318;&#20808;&#31163;&#25955;&#21270;&#25968;&#25454;&#65292;&#28982;&#21518;&#23558;&#25193;&#25955;&#27169;&#22411;&#24212;&#29992;&#20110;&#31163;&#25955;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#32454;&#21270;&#31163;&#25955;&#21270;&#21442;&#25968;&#26102;&#36890;&#24120;&#20250;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30452;&#25509;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#21046;&#23450;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#20989;&#25968;&#30340;&#29983;&#25104;&#24314;&#27169;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20844;&#24335;&#22312;&#26080;&#38480;&#32500;&#24230;&#29615;&#22659;&#20013;&#26159;&#33391;&#22909;&#23450;&#20041;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;&#20174;&#26679;&#26412;&#21040;&#30446;&#26631;&#27979;&#24230;&#30340;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#36824;&#21046;&#23450;&#20102;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#30340;&#20934;&#21017;&#12290;&#23545;&#20110;&#22270;&#20687;&#20998;&#24067;&#65292;&#36825;&#20123;&#20934;&#21017;&#19982;&#24403;&#21069;&#29992;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#32463;&#20856;&#36873;&#25321;&#19968;&#33268;&#12290;&#23545;&#20110;&#20854;&#20182;&#20998;&#24067;...
&lt;/p&gt;
&lt;p&gt;
Diffusion models have had a profound impact on many application areas, including those where data are intrinsically infinite-dimensional, such as images or time series. The standard approach is first to discretize and then to apply diffusion models to the discretized data. While such approaches are practically appealing, the performance of the resulting algorithms typically deteriorates as discretization parameters are refined. In this paper, we instead directly formulate diffusion-based generative models in infinite dimensions and apply them to the generative modeling of functions. We prove that our formulations are well posed in the infinite-dimensional setting and provide dimension-independent distance bounds from the sample to the target measure. Using our theory, we also develop guidelines for the design of infinite-dimensional diffusion models. For image distributions, these guidelines are in line with the canonical choices currently made for diffusion models. For other distribut
&lt;/p&gt;</description></item></channel></rss>