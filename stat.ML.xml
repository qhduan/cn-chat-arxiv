<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;&#65292;&#21487;&#20197;&#21450;&#26102;&#24536;&#35760;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01401</link><description>&lt;p&gt;
&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#22312;&#35268;&#27169;&#19978;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Machine Unlearning at Scale via Lipschitz Regularization
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01401
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;&#65292;&#21487;&#20197;&#21450;&#26102;&#24536;&#35760;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36981;&#23432;&#20154;&#24037;&#26234;&#33021;&#21644;&#25968;&#25454;&#35268;&#23450;&#65292;&#20174;&#35757;&#32451;&#24471;&#21040;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#36951;&#24536;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#30340;&#38656;&#27714;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#36951;&#24536;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#21450;&#26102;&#24536;&#35760;&#24517;&#35201;&#30340;&#25968;&#25454;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#38646;&#26679;&#26412;&#36951;&#24536;&#30340;&#22330;&#26223;&#65292;&#21363;&#21482;&#26377;&#19968;&#20010;&#32463;&#36807;&#35757;&#32451;&#30340;&#27169;&#22411;&#21644;&#35201;&#36951;&#24536;&#30340;&#25968;&#25454;&#65292;&#36951;&#24536;&#31639;&#27861;&#24517;&#39035;&#33021;&#22815;&#31227;&#38500;&#25968;&#25454;&#12290;&#26681;&#25454;&#36825;&#26679;&#23450;&#20041;&#65292;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26159;&#19981;&#22815;&#30340;&#12290;&#22522;&#20110;Lipschitz&#36830;&#32493;&#24615;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26679;&#26412;&#25200;&#21160;&#30340;&#36755;&#20986;&#36827;&#34892;&#24179;&#28369;&#22788;&#29702;&#26469;&#35825;&#23548;&#36951;&#24536;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#24179;&#28369;&#24615;&#25104;&#21151;&#22320;&#23454;&#29616;&#20102;&#36951;&#24536;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#24635;&#20307;&#27169;&#22411;&#24615;&#33021;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#21253;&#25324;&#19968;&#31995;&#21015;&#24403;&#20195;&#22522;&#20934;&#27979;&#35797;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20005;&#26684;&#30340;&#38646;&#26679;&#26412;&#32422;&#26463;&#19979;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
To comply with AI and data regulations, the need to forget private or copyrighted information from trained machine learning models is increasingly important. The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance. In this work, we address the zero-shot unlearning scenario, whereby an unlearning algorithm must be able to remove data given only a trained model and the data to be forgotten. Under such a definition, existing state-of-the-art methods are insufficient. Building on the concepts of Lipschitz continuity, we present a method that induces smoothing of the forget sample's output, with respect to perturbations of that sample. We show this smoothing successfully results in forgetting while preserving general model performance. We perform extensive empirical evaluation of our method over a range of contemporary benchmarks, verifying that our method achieves state-of-the-art performance under the strict constraints of ze
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26816;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20851;&#38190;&#32479;&#35745;&#37327;&#21644;&#31192;&#23494;&#23494;&#38053;&#25511;&#21046;&#35823;&#25253;&#29575;&#65292;&#21516;&#26102;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.01245</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#26694;&#26550;: &#26530;&#36724;&#12289;&#26816;&#27979;&#25928;&#29575;&#21644;&#26368;&#20248;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01245
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26816;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20851;&#38190;&#32479;&#35745;&#37327;&#21644;&#31192;&#23494;&#23494;&#38053;&#25511;&#21046;&#35823;&#25253;&#29575;&#65292;&#21516;&#26102;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;ChatGPT&#20110;2022&#24180;11&#26376;&#25512;&#20986;&#20197;&#26469;&#65292;&#23558;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#30340;&#32479;&#35745;&#20449;&#21495;&#23884;&#20837;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#65292;&#20063;&#34987;&#31216;&#20026;&#27700;&#21360;&#65292;&#24050;&#34987;&#29992;&#20316;&#20174;&#20854;&#20154;&#31867;&#25776;&#20889;&#23545;&#24212;&#29289;&#19978;&#21487;&#35777;&#26816;&#27979;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290; &#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#29702;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#24182;&#35774;&#35745;&#24378;&#22823;&#30340;&#26816;&#27979;&#35268;&#21017;&#12290;&#21463;&#27700;&#21360;&#26816;&#27979;&#30340;&#20551;&#35774;&#26816;&#39564;&#20844;&#24335;&#21551;&#21457;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#39318;&#20808;&#36873;&#25321;&#25991;&#26412;&#30340;&#26530;&#36724;&#32479;&#35745;&#37327;&#21644;&#30001;LLM&#25552;&#20379;&#32473;&#39564;&#35777;&#22120;&#30340;&#31192;&#23494;&#23494;&#38053;&#65292;&#20197;&#23454;&#29616;&#25511;&#21046;&#35823;&#25253;&#29575;&#65288;&#23558;&#20154;&#31867;&#25776;&#20889;&#30340;&#25991;&#26412;&#38169;&#35823;&#22320;&#26816;&#27979;&#20026;LLM&#29983;&#25104;&#30340;&#38169;&#35823;&#65289;&#12290; &#25509;&#19979;&#26469;&#65292;&#35813;&#26694;&#26550;&#20801;&#35768;&#36890;&#36807;&#33719;&#21462;&#28176;&#36817;&#38169;&#35823;&#36127;&#29575;&#65288;&#23558;LLM&#29983;&#25104;&#25991;&#26412;&#38169;&#35823;&#22320;&#26816;&#27979;&#20026;&#20154;&#31867;&#25776;&#20889;&#30340;&#38169;&#35823;&#65289;&#30340;&#23553;&#38381;&#24418;&#24335;&#34920;&#36798;&#24335;&#26469;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01245v1 Announce Type: cross  Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#26159;&#24378;&#20984;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.11858</link><description>&lt;p&gt;
&#22312;&#26446;&#32676;&#19978;&#30340;&#38543;&#26426;Hessian&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Stochastic Hessian Fitting on Lie Group
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#26159;&#24378;&#20984;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;Hessian-&#21521;&#37327;&#20056;&#31215;&#19978;&#25311;&#21512;Hessian&#25110;&#20854;&#36870;&#12290;&#20351;&#29992;&#20102;&#19968;&#20010;Hessian&#25311;&#21512;&#20934;&#21017;&#65292;&#21487;&#29992;&#20110;&#25512;&#23548;&#22823;&#37096;&#20998;&#24120;&#29992;&#26041;&#27861;&#65292;&#22914;BFGS&#12289;&#39640;&#26031;&#29275;&#39039;&#12289;AdaGrad&#31561;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#19981;&#21516;Hessian&#25311;&#21512;&#26041;&#27861;&#30340;&#19981;&#21516;&#25910;&#25947;&#36895;&#29575;&#65292;&#20363;&#22914;&#65292;&#22312;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#27425;&#32447;&#24615;&#36895;&#29575;&#21644;&#23545;&#31216;&#27491;&#23450;&#65288;SPL&#65289;&#30697;&#38453;&#21644;&#26576;&#20123;&#26446;&#32676;&#19978;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#32447;&#24615;&#36895;&#29575;&#12290;&#22312;&#29305;&#23450;&#19988;&#36275;&#22815;&#19968;&#33324;&#30340;&#26446;&#32676;&#19978;&#30340;Hessian&#25311;&#21512;&#38382;&#39064;&#22312;&#36731;&#24494;&#26465;&#20214;&#19979;&#34987;&#35777;&#26126;&#26159;&#24378;&#20984;&#30340;&#12290;&#20026;&#20102;&#30830;&#35748;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#35774;&#32622;&#19979;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#22914;&#26377;&#22122;&#22768;&#30340;Hessian-&#21521;&#37327;&#20056;&#31215;&#12289;&#26102;&#21464;&#30340;Hessians&#21644;&#20302;&#31934;&#24230;&#31639;&#26415;&#12290;&#36825;&#20123;&#21457;&#29616;&#23545;&#20381;&#36182;&#20110;&#38543;&#26426;&#20108;&#38454;&#20248;&#21270;&#30340;&#26041;&#27861;&#26159;&#26377;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11858v1 Announce Type: cross  Abstract: This paper studies the fitting of Hessian or its inverse with stochastic Hessian-vector products. A Hessian fitting criterion, which can be used to derive most of the commonly used methods, e.g., BFGS, Gaussian-Newton, AdaGrad, etc., is used for the analysis. Our studies reveal different convergence rates for different Hessian fitting methods, e.g., sublinear rates for gradient descent in the Euclidean space and a commonly used closed-form solution, linear rates for gradient descent on the manifold of symmetric positive definite (SPL) matrices and certain Lie groups. The Hessian fitting problem is further shown to be strongly convex under mild conditions on a specific yet general enough Lie group. To confirm our analysis, these methods are tested under different settings like noisy Hessian-vector products, time varying Hessians, and low precision arithmetic. These findings are useful for stochastic second order optimizations that rely 
&lt;/p&gt;</description></item><item><title>&#20462;&#27491;&#20102;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38169;&#35823;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20998;&#26512;&#25968;&#20540;&#31163;&#25955;&#36941;&#21382;SDE&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#35299;&#20915;&#20102;&#23454;&#36341;&#20013;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.08711</link><description>&lt;p&gt;
&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Correction to "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations"
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08711
&lt;/p&gt;
&lt;p&gt;
&#20462;&#27491;&#20102;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38169;&#35823;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20998;&#26512;&#25968;&#20540;&#31163;&#25955;&#36941;&#21382;SDE&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#35299;&#20915;&#20102;&#23454;&#36341;&#20013;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;San-Serna&#21644;Zygalakis&#30340;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#25968;&#20540;&#31163;&#25955;&#20998;&#26512;&#26041;&#27861;&#36827;&#34892;&#20102;&#20462;&#27491;&#12290;&#20182;&#20204;&#20998;&#26512;&#20102;UBU&#31215;&#20998;&#22120;&#65292;&#35813;&#31215;&#20998;&#22120;&#26159;&#20108;&#38454;&#24378;&#22411;&#30340;&#65292;&#24182;&#19988;&#27599;&#20010;&#27493;&#39588;&#21482;&#38656;&#35201;&#19968;&#27425;&#26799;&#24230;&#35780;&#20272;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#29702;&#24819;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#29305;&#21035;&#26159;&#22312;Wasserstein-2&#36317;&#31163;&#20013;&#21040;&#36798;&#31163;&#30446;&#26631;&#20998;&#24067; $\epsilon &gt; 0$ &#30340;&#36317;&#31163;&#20165;&#38656; $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ &#27493;&#12290;&#28982;&#32780;&#65292;Sanz-Serna&#21644;Zygalakis (2021)&#20013;&#30340;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#23384;&#22312;&#38169;&#35823;&#65292;&#22312;&#23454;&#36341;&#20013;&#38656;&#35201;&#26356;&#24378;&#30340;&#20551;&#35774;&#25165;&#33021;&#23454;&#29616;&#36825;&#20123;&#22797;&#26434;&#24230;&#20272;&#35745;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#29702;&#35770;&#19982;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#30340;&#35768;&#22810;&#24212;&#29992;&#22330;&#26223;&#20013;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08711v1 Announce Type: cross Abstract: A method for analyzing non-asymptotic guarantees of numerical discretizations of ergodic SDEs in Wasserstein-2 distance is presented by Sanz-Serna and Zygalakis in ``Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations". They analyze the UBU integrator which is strong order two and only requires one gradient evaluation per step, resulting in desirable non-asymptotic guarantees, in particular $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ steps to reach a distance of $\epsilon &gt; 0$ in Wasserstein-2 distance away from the target distribution. However, there is a mistake in the local error estimates in Sanz-Serna and Zygalakis (2021), in particular, a stronger assumption is needed to achieve these complexity estimates. This note reconciles the theory with the dimension dependence observed in practice in many applications of interest.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#23618;&#30340;&#24490;&#29615;&#20999;&#25442;&#29366;&#24577;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#26080;&#30417;&#30563;&#22320;&#21516;&#26102;&#35299;&#37322;&#31995;&#32479;&#32423;&#21644;&#20010;&#20307;&#32423;&#30340;&#21160;&#24577;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#24314;&#27169;&#21516;&#27493;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32676;&#20307;&#21160;&#24577;&#12290;</title><link>http://arxiv.org/abs/2401.14973</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#23618;&#24490;&#29615;&#20999;&#25442;&#29366;&#24577;&#27169;&#22411;&#21457;&#29616;&#21516;&#27493;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32676;&#20307;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Discovering group dynamics in synchronous time series via hierarchical recurrent switching-state models. (arXiv:2401.14973v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14973
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#23618;&#30340;&#24490;&#29615;&#20999;&#25442;&#29366;&#24577;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#26080;&#30417;&#30563;&#22320;&#21516;&#26102;&#35299;&#37322;&#31995;&#32479;&#32423;&#21644;&#20010;&#20307;&#32423;&#30340;&#21160;&#24577;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#24314;&#27169;&#21516;&#27493;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32676;&#20307;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#33268;&#21147;&#20110;&#23545;&#21516;&#19968;&#26102;&#38388;&#27573;&#20869;&#22810;&#20010;&#23454;&#20307;&#30456;&#20114;&#20316;&#29992;&#32780;&#20135;&#29983;&#30340;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#36827;&#34892;&#24314;&#27169;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#24314;&#27169;&#20010;&#20307;&#26102;&#38388;&#24207;&#21015;&#26041;&#38754;&#23545;&#25105;&#20204;&#30340;&#39044;&#26399;&#24212;&#29992;&#26159;&#19981;&#36275;&#22815;&#30340;&#65292;&#20854;&#20013;&#38598;&#20307;&#31995;&#32479;&#32423;&#34892;&#20026;&#24433;&#21709;&#30528;&#20010;&#20307;&#23454;&#20307;&#30340;&#36712;&#36857;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#23618;&#20999;&#25442;&#29366;&#24577;&#27169;&#22411;&#65292;&#21487;&#20197;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#35757;&#32451;&#65292;&#21516;&#26102;&#35299;&#37322;&#31995;&#32479;&#32423;&#21644;&#20010;&#20307;&#32423;&#30340;&#21160;&#24577;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#38544;&#21547;&#30340;&#31995;&#32479;&#32423;&#31163;&#25955;&#29366;&#24577;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#39537;&#21160;&#30528;&#38544;&#21547;&#30340;&#23454;&#20307;&#32423;&#38142;&#65292;&#36827;&#32780;&#25511;&#21046;&#27599;&#20010;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;&#21160;&#24577;&#12290;&#35266;&#27979;&#32467;&#26524;&#22312;&#23454;&#20307;&#21644;&#31995;&#32479;&#32423;&#30340;&#38142;&#20043;&#38388;&#36827;&#34892;&#21453;&#39304;&#65292;&#36890;&#36807;&#20381;&#36182;&#20110;&#19978;&#19979;&#25991;&#30340;&#29366;&#24577;&#36716;&#25442;&#26469;&#25552;&#39640;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#23618;&#20999;&#25442;&#24490;&#29615;&#21160;&#21147;&#23398;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#23553;&#38381;&#24418;&#24335;&#30340;&#21464;&#20998;&#22352;&#26631;&#19978;&#21319;&#26356;&#26032;&#26469;&#23398;&#20064;&#65292;&#20854;&#22312;&#20010;&#20307;&#25968;&#37327;&#19978;&#21576;&#32447;&#24615;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
We seek to model a collection of time series arising from multiple entities interacting over the same time period. Recent work focused on modeling individual time series is inadequate for our intended applications, where collective system-level behavior influences the trajectories of individual entities. To address such problems, we present a new hierarchical switching-state model that can be trained in an unsupervised fashion to simultaneously explain both system-level and individual-level dynamics. We employ a latent system-level discrete state Markov chain that drives latent entity-level chains which in turn govern the dynamics of each observed time series. Feedback from the observations to the chains at both the entity and system levels improves flexibility via context-dependent state transitions. Our hierarchical switching recurrent dynamical models can be learned via closed-form variational coordinate ascent updates to all latent chains that scale linearly in the number of indivi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#21487;&#20197;&#22312;&#36845;&#20195;&#22797;&#26434;&#24615;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2401.10989</link><description>&lt;p&gt;
&#20855;&#26377;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#30340;&#21487;&#35777;&#20280;&#32553;&#24615;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Provably Scalable Black-Box Variational Inference with Structured Variational Families. (arXiv:2401.10989v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#21487;&#20197;&#22312;&#36845;&#20195;&#22797;&#26434;&#24615;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#30693;&#20855;&#26377;&#28385;&#31209;&#21327;&#26041;&#24046;&#36924;&#36817;&#30340;&#21464;&#20998;&#26063;&#22312;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#20013;&#34920;&#29616;&#19981;&#20339;&#65292;&#26080;&#35770;&#26159;&#20174;&#23454;&#35777;&#19978;&#36824;&#26159;&#29702;&#35770;&#19978;&#12290;&#20107;&#23454;&#19978;&#65292;&#26368;&#36817;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#30456;&#27604;&#65292;&#28385;&#31209;&#21464;&#20998;&#26063;&#22312;&#38382;&#39064;&#30340;&#32500;&#24230;&#19978;&#25193;&#23637;&#24471;&#24456;&#24046;&#12290;&#36825;&#23545;&#20855;&#26377;&#26412;&#22320;&#21464;&#37327;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#23588;&#20026;&#20851;&#38190;&#65292;&#23427;&#20204;&#30340;&#32500;&#24230;&#38543;&#30528;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#32780;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#36845;&#20195;&#22797;&#26434;&#24615;&#23545;&#25968;&#25454;&#38598;&#22823;&#23567;N&#23384;&#22312;&#26126;&#30830;&#30340;O(N^2)&#20381;&#36182;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#12290;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126;&#20102;&#26576;&#20123;&#23610;&#24230;&#30697;&#38453;&#32467;&#26500;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#36845;&#20195;&#22797;&#26434;&#24615;O(N)&#65292;&#20174;&#32780;&#19982;N&#30340;&#32553;&#25918;&#26356;&#22909;&#22320;&#21305;&#37197;&#12290;&#25105;&#20204;&#22312;&#29616;&#23454;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Variational families with full-rank covariance approximations are known not to work well in black-box variational inference (BBVI), both empirically and theoretically. In fact, recent computational complexity results for BBVI have established that full-rank variational families scale poorly with the dimensionality of the problem compared to e.g. mean field families. This is particularly critical to hierarchical Bayesian models with local variables; their dimensionality increases with the size of the datasets. Consequently, one gets an iteration complexity with an explicit $\mathcal{O}(N^2)$ dependence on the dataset size $N$. In this paper, we explore a theoretical middle ground between mean-field variational families and full-rank families: structured variational families. We rigorously prove that certain scale matrix structures can achieve a better iteration complexity of $\mathcal{O}(N)$, implying better scaling with respect to $N$. We empirically verify our theoretical results on l
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#24494;&#22937;&#24046;&#24322;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.03482</link><description>&lt;p&gt;
&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification on Clinical Trial Outcome Prediction. (arXiv:2401.03482v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#24494;&#22937;&#24046;&#24322;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#37325;&#35201;&#24615;&#26085;&#30410;&#34987;&#35748;&#35782;&#21040;&#12290;&#20934;&#30830;&#35780;&#20272;&#27169;&#22411;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#20154;&#21592;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#21644;&#22686;&#21152;&#20449;&#24515;&#12290;&#36825;&#22312;&#21307;&#23398;&#35786;&#26029;&#21644;&#33647;&#29289;&#21457;&#29616;&#39046;&#22495;&#23588;&#20026;&#37325;&#35201;&#65292;&#22240;&#20026;&#21487;&#38752;&#30340;&#39044;&#27979;&#30452;&#25509;&#24433;&#21709;&#30740;&#31350;&#36136;&#37327;&#21644;&#24739;&#32773;&#20581;&#24247;&#12290;&#26412;&#25991;&#25552;&#20986;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#32435;&#20837;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#20013;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#25552;&#39640;&#27169;&#22411;&#36776;&#21035;&#24494;&#22937;&#24046;&#24322;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#26174;&#33879;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#36873;&#25321;&#24615;&#20998;&#31867;&#26041;&#27861;&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#30446;&#26631;&#65292;&#24182;&#23558;&#20854;&#19982;&#23618;&#27425;&#20132;&#20114;&#32593;&#32476;(HINT)&#26080;&#32541;&#38598;&#25104;&#65292;HINT&#26159;&#20020;&#24202;&#35797;&#39564;&#39044;&#27979;&#24314;&#27169;&#30340;&#26368;&#21069;&#27839;&#12290;&#36873;&#25321;&#24615;&#20998;&#31867;&#28085;&#30422;&#20102;&#19968;&#31995;&#21015;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#20445;&#30041;&#20449;&#24687;&#20197;&#20379;&#36827;&#19968;&#27493;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The importance of uncertainty quantification is increasingly recognized in the diverse field of machine learning. Accurately assessing model prediction uncertainty can help provide deeper understanding and confidence for researchers and practitioners. This is especially critical in medical diagnosis and drug discovery areas, where reliable predictions directly impact research quality and patient health.  In this paper, we proposed incorporating uncertainty quantification into clinical trial outcome predictions. Our main goal is to enhance the model's ability to discern nuanced differences, thereby significantly improving its overall performance.  We have adopted a selective classification approach to fulfill our objective, integrating it seamlessly with the Hierarchical Interaction Network (HINT), which is at the forefront of clinical trial prediction modeling. Selective classification, encompassing a spectrum of methods for uncertainty quantification, empowers the model to withhold de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;FLANDERS&#65292;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#33258;&#22238;&#24402;&#30340;&#32852;&#37030;&#23398;&#20064;&#32858;&#21512;&#26041;&#26696;&#65292;&#21487;&#20197;&#35782;&#21035;&#24694;&#24847;&#23458;&#25143;&#31471;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#25308;&#21344;&#24237;&#25915;&#20987;&#38450;&#24481;&#12290;</title><link>http://arxiv.org/abs/2303.16668</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#33258;&#22238;&#24402;&#30340;&#32852;&#37030;&#23398;&#20064;&#25308;&#21344;&#24237;&#23481;&#38169;&#32858;&#21512;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
A Byzantine-Resilient Aggregation Scheme for Federated Learning via Matrix Autoregression on Client Updates. (arXiv:2303.16668v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16668
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;FLANDERS&#65292;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#33258;&#22238;&#24402;&#30340;&#32852;&#37030;&#23398;&#20064;&#32858;&#21512;&#26041;&#26696;&#65292;&#21487;&#20197;&#35782;&#21035;&#24694;&#24847;&#23458;&#25143;&#31471;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#25308;&#21344;&#24237;&#25915;&#20987;&#38450;&#24481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;FLANDERS&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#32858;&#21512;&#26041;&#26696;&#65292;&#21487;&#20197;&#25269;&#24481;&#25308;&#21344;&#24237;&#25915;&#20987;&#12290;FLANDERS&#23558;&#27599;&#20010;FL&#36718;&#27425;&#20013;&#30001;&#23458;&#25143;&#31471;&#21457;&#36865;&#30340;&#26412;&#22320;&#27169;&#22411;&#26356;&#26032;&#35270;&#20026;&#30697;&#38453;&#20540;&#26102;&#38388;&#24207;&#21015;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#23558;&#23454;&#38469;&#35266;&#27979;&#19982;&#30001;&#30697;&#38453;&#33258;&#22238;&#24402;&#39044;&#27979;&#27169;&#22411;&#20272;&#35745;&#30340;&#35266;&#27979;&#36827;&#34892;&#27604;&#36739;&#65292;&#35782;&#21035;&#24694;&#24847;&#23458;&#25143;&#31471;&#20316;&#20026;&#36825;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#24322;&#24120;&#20540;&#12290;&#22312;&#19981;&#21516;FL&#35774;&#32622;&#19979;&#23545;&#22810;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;FLANDERS&#22312;&#25269;&#24481;&#25308;&#21344;&#24237;&#25915;&#20987;&#26041;&#38754;&#19982;&#26368;&#24378;&#22823;&#30340;&#22522;&#32447;&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#19982;&#29616;&#26377;&#30340;&#38450;&#24481;&#31574;&#30053;&#30456;&#27604;&#65292; FLANDERS&#21363;&#20351;&#22312;&#26497;&#20854;&#20005;&#37325;&#30340;&#25915;&#20987;&#22330;&#26223;&#19979;&#20173;&#28982;&#38750;&#24120;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose FLANDERS, a novel federated learning (FL) aggregation scheme robust to Byzantine attacks. FLANDERS considers the local model updates sent by clients at each FL round as a matrix-valued time series. Then, it identifies malicious clients as outliers of this time series by comparing actual observations with those estimated by a matrix autoregressive forecasting model. Experiments conducted on several datasets under different FL settings demonstrate that FLANDERS matches the robustness of the most powerful baselines against Byzantine clients. Furthermore, FLANDERS remains highly effective even under extremely severe attack scenarios, as opposed to existing defense strategies.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20351;&#29992;&#30340;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968; $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2302.08766</link><description>&lt;p&gt;
&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#30340;&#19979;&#30028;&#21644;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08766
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20351;&#29992;&#30340;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968; $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#26368;&#20248;&#21270;&#38382;&#39064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#19978;&#23618;&#21644;&#19979;&#23618;&#30446;&#26631;&#23545;&#24212;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#22240;&#27492;&#20855;&#26377;&#24635;&#21644;&#32467;&#26500;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33879;&#21517;&#30340;SARAH&#31639;&#27861;&#30340;&#21452;&#23618;&#25193;&#23637;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#38656;&#35201;$\mathcal {O}((n+m)^{\frac{1}{2}}\varepsilon ^{-1})$&#27425;&#26799;&#24230;&#35745;&#31639;&#25165;&#33021;&#23454;&#29616;$\varepsilon$&#31283;&#23450;&#24615;&#65292;&#20854;&#20013;$n+m$&#26159;&#26679;&#26412;&#24635;&#25968;&#65292;&#36825;&#27604;&#20808;&#21069;&#25152;&#26377;&#30340;&#21452;&#23618;&#31639;&#27861;&#37117;&#35201;&#22909;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#29992;&#20110;&#24471;&#21040;&#21452;&#23618;&#38382;&#39064;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#25152;&#38656;&#30340;oracle&#35843;&#29992;&#27425;&#25968;&#12290;&#36825;&#20010;&#19979;&#30028;&#27491;&#26159;&#25105;&#20204;&#30340;&#31639;&#27861;&#25152;&#36798;&#21040;&#30340;&#65292;&#22240;&#27492;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\mathcal{O}((n+m)^{\frac12}\varepsilon^{-1})$ gradient computations to achieve $\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.
&lt;/p&gt;</description></item></channel></rss>