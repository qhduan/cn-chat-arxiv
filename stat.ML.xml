<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#26088;&#22312;&#31995;&#32479;&#27604;&#36739;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#20197;&#29983;&#25104;&#27010;&#29575;&#24615;&#22825;&#27668;&#39044;&#27979;&#65292;&#36229;&#36234;&#20256;&#32479;&#22522;&#20110;&#29289;&#29702;&#30340;&#22825;&#27668;&#39044;&#27979;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.13458</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#22825;&#27668;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification for data-driven weather models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13458
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#26088;&#22312;&#31995;&#32479;&#27604;&#36739;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#20197;&#29983;&#25104;&#27010;&#29575;&#24615;&#22825;&#27668;&#39044;&#27979;&#65292;&#36229;&#36234;&#20256;&#32479;&#22522;&#20110;&#29289;&#29702;&#30340;&#22825;&#27668;&#39044;&#27979;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#39537;&#21160;&#30340;&#25968;&#25454;&#39537;&#21160;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#22312;&#36807;&#21435;&#20960;&#24180;&#21462;&#24471;&#20102;&#24555;&#36895;&#36827;&#23637;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20351;&#29992;&#20877;&#20998;&#26512;&#25968;&#25454;&#35757;&#32451;&#30340;&#27169;&#22411;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#21464;&#37327;&#21644;&#35780;&#20272;&#25351;&#26631;&#19978;&#23637;&#31034;&#20102;&#26126;&#26174;&#25913;&#36827;&#65292;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#22522;&#20110;&#29289;&#29702;&#30340;&#25968;&#20540;&#22825;&#27668;&#39044;&#27979;&#27169;&#22411;&#12290;&#38500;&#20102;&#25913;&#36827;&#30340;&#39044;&#27979;&#22806;&#65292;&#25968;&#25454;&#39537;&#21160;&#22825;&#27668;&#27169;&#22411;&#30340;&#20027;&#35201;&#20248;&#21183;&#26159;&#23427;&#20204;&#26174;&#33879;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#21644;&#19968;&#26086;&#27169;&#22411;&#34987;&#35757;&#32451;&#23601;&#33021;&#26356;&#24555;&#22320;&#29983;&#25104;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#25968;&#25454;&#39537;&#21160;&#22825;&#27668;&#39044;&#27979;&#30340;&#21162;&#21147;&#37117;&#23616;&#38480;&#20110;&#30830;&#23450;&#24615;&#30340;&#12289;&#28857;&#20540;&#39044;&#27979;&#65292;&#20351;&#24471;&#26080;&#27861;&#37327;&#21270;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#23545;&#20110;&#30740;&#31350;&#21644;&#24212;&#29992;&#20013;&#30340;&#26368;&#20339;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#25972;&#20307;&#30446;&#26631;&#26159;&#31995;&#32479;&#22320;&#30740;&#31350;&#21644;&#27604;&#36739;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#20197;&#29983;&#25104;&#27010;&#29575;&#24615;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13458v1 Announce Type: cross  Abstract: Artificial intelligence (AI)-based data-driven weather forecasting models have experienced rapid progress over the last years. Recent studies, with models trained on reanalysis data, achieve impressive results and demonstrate substantial improvements over state-of-the-art physics-based numerical weather prediction models across a range of variables and evaluation metrics. Beyond improved predictions, the main advantages of data-driven weather models are their substantially lower computational costs and the faster generation of forecasts, once a model has been trained. However, most efforts in data-driven weather forecasting have been limited to deterministic, point-valued predictions, making it impossible to quantify forecast uncertainties, which is crucial in research and for optimal decision making in applications. Our overarching aim is to systematically study and compare uncertainty quantification methods to generate probabilistic 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;</title><link>https://arxiv.org/abs/2402.05928</link><description>&lt;p&gt;
&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65306;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#30340;&#24179;&#26041;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#24615;&#65288;&#946;-&#28151;&#21512;&#65289;&#25968;&#25454;&#21644;&#24179;&#26041;&#25439;&#22833;&#30340;&#32479;&#35745;&#23398;&#20064;&#65292;&#22312;&#19968;&#20010;&#20551;&#35774;&#31867;&#21035;&#934;_p&#30340;&#23376;&#38598;F&#20013;&#65292;&#20854;&#20013;&#934;_p&#26159;&#33539;&#25968;&#8741;f&#8741;_&#934;_p&#8801;sup_m&#8805;1 m^{-1/p}&#8741;f&#8741;_L^m&#65292;&#20854;&#20013;p&#8712;[2&#65292;&#8734;]&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21160;&#26426;&#26159;&#22312;&#20855;&#26377;&#20381;&#36182;&#24615;&#25968;&#25454;&#30340;&#23398;&#20064;&#20013;&#23547;&#25214;&#23574;&#38160;&#30340;&#22122;&#22768;&#20132;&#20114;&#39033;&#25110;&#26041;&#24046;&#20195;&#29702;&#12290;&#22312;&#27809;&#26377;&#20219;&#20309;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20856;&#22411;&#30340;&#38750;&#28176;&#36817;&#32467;&#26524;&#26174;&#31034;&#20986;&#26041;&#24046;&#20195;&#29702;&#36890;&#36807;&#24213;&#23618;&#21327;&#21464;&#37327;&#36807;&#31243;&#30340;&#28151;&#21512;&#26102;&#38388;&#36827;&#34892;&#20102;&#20056;&#31215;&#32553;&#20943;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#22312;&#25105;&#20204;&#30340;&#20551;&#35774;&#31867;&#21035;F&#19978;&#65292;L^2&#21644;&#934;_p&#30340;&#25299;&#25169;&#26159;&#21487;&#27604;&#36739;&#30340;&#65292;&#21363;&#934;_p&#26159;&#19968;&#20010;&#24369;&#20122;&#39640;&#26031;&#31867;&#21035;&#65306;&#8741;f&#8741;_&#934;_p&#8818;&#8741;f&#8741;_L^2^&#951;&#65292;&#20854;&#20013;&#951;&#8712;(0&#65292;1]&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#22312;&#20854;&#20027;&#23548;&#39033;&#20013;&#21482;&#23454;&#29616;&#20102;&#19968;&#31181;&#21482;&#20381;&#36182;&#20110;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#35768;&#22810;&#20381;&#36182;&#24615;&#25968;&#25454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study statistical learning with dependent ($\beta$-mixing) data and square loss in a hypothesis class $\mathscr{F}\subset L_{\Psi_p}$ where $\Psi_p$ is the norm $\|f\|_{\Psi_p} \triangleq \sup_{m\geq 1} m^{-1/p} \|f\|_{L^m} $ for some $p\in [2,\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data. Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \emph{multiplicatively} by the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\Psi_p$ are comparable on our hypothesis class $\mathscr{F}$ -- that is, $\mathscr{F}$ is a weakly sub-Gaussian class: $\|f\|_{\Psi_p} \lesssim \|f\|_{L^2}^\eta$ for some $\eta\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. Our result holds whether t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;CDVAE&#65289;&#26469;&#35299;&#20915;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#21644;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#26469;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;</title><link>http://arxiv.org/abs/2310.10559</link><description>&lt;p&gt;
&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Causal Dynamic Variational Autoencoder for Counterfactual Regression in Longitudinal Data. (arXiv:2310.10559v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10559
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;CDVAE&#65289;&#26469;&#35299;&#20915;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#21644;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#26469;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24456;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#22914;&#31934;&#20934;&#21307;&#23398;&#12289;&#27969;&#34892;&#30149;&#23398;&#12289;&#32463;&#27982;&#21644;&#24066;&#22330;&#33829;&#38144;&#20013;&#65292;&#20272;&#35745;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#26159;&#30456;&#20851;&#30340;&#12290;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#35201;&#20040;&#20551;&#35774;&#20102;&#25152;&#26377;&#28151;&#26434;&#21464;&#37327;&#30340;&#35266;&#27979;&#32467;&#26524;&#65292;&#35201;&#20040;&#35797;&#22270;&#25512;&#26029;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21464;&#37327;&#12290;&#25105;&#20204;&#37319;&#21462;&#20102;&#19981;&#21516;&#30340;&#35266;&#28857;&#65292;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#21363;&#20165;&#24433;&#21709;&#32467;&#26524;&#24207;&#21015;&#30340;&#35843;&#25972;&#21464;&#37327;&#12290;&#22312;&#26080;&#28151;&#26434;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20197;&#26410;&#35266;&#27979;&#21040;&#30340;&#39118;&#38505;&#22240;&#32032;&#23548;&#33268;&#30340;&#27835;&#30103;&#21453;&#24212;&#20013;&#30340;&#26410;&#30693;&#24322;&#36136;&#24615;&#20026;&#30446;&#26631;&#65292;&#20272;&#35745;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE&#65289;&#12290;&#25105;&#20204;&#24212;&#23545;&#20102;&#26102;&#21464;&#25928;&#24212;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;&#22312;&#23398;&#20064;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#30340;&#26377;&#25928;&#24615;&#21644;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33324;&#21270;&#30028;&#38480;&#30340;&#29702;&#35770;&#32467;&#26524;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22240;&#26524;DVAE&#65288;CDVAE&#65289;&#12290;&#35813;&#27169;&#22411;&#23558;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#19982;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating treatment effects over time is relevant in many real-world applications, such as precision medicine, epidemiology, economy, and marketing. Many state-of-the-art methods either assume the observations of all confounders or seek to infer the unobserved ones. We take a different perspective by assuming unobserved risk factors, i.e., adjustment variables that affect only the sequence of outcomes. Under unconfoundedness, we target the Individual Treatment Effect (ITE) estimation with unobserved heterogeneity in the treatment response due to missing risk factors. We address the challenges posed by time-varying effects and unobserved adjustment variables. Led by theoretical results over the validity of the learned adjustment variables and generalization bounds over the treatment effect, we devise Causal DVAE (CDVAE). This model combines a Dynamic Variational Autoencoder (DVAE) framework with a weighting strategy using propensity scores to estimate counterfactual responses. The CDVA
&lt;/p&gt;</description></item></channel></rss>