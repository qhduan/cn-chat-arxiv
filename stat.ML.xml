<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;Brenier&#30340;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#31070;&#32463;&#23454;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#28508;&#22312;&#20989;&#25968;$u$&#65292;&#20174;&#26368;&#26032;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#36827;&#23637;&#20013;&#27762;&#21462;&#28789;&#24863;&#12290;</title><link>https://arxiv.org/abs/2403.03071</link><description>&lt;p&gt;
&#35770;Brenier&#30340;&#26497;&#20998;&#35299;&#30340;&#31070;&#32463;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
On a Neural Implementation of Brenier's Polar Factorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03071
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Brenier&#30340;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#31070;&#32463;&#23454;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#28508;&#22312;&#20989;&#25968;$u$&#65292;&#20174;&#26368;&#26032;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#36827;&#23637;&#20013;&#27762;&#21462;&#28789;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1991&#24180;&#65292;Brenier&#35777;&#26126;&#20102;&#19968;&#20010;&#23450;&#29702;&#65292;&#23558;$QR$&#20998;&#35299;&#65288;&#20998;&#20026;&#21322;&#27491;&#23450;&#30697;&#38453;$\times$&#37193;&#30697;&#38453;&#65289;&#25512;&#24191;&#21040;&#20219;&#24847;&#30690;&#37327;&#22330;$F:\mathbb{R}^d\rightarrow \mathbb{R}^d$&#12290;&#36825;&#20010;&#34987;&#31216;&#20026;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#20219;&#24847;&#22330;$F$&#37117;&#21487;&#20197;&#34920;&#31034;&#20026;&#20984;&#20989;&#25968;$u$&#30340;&#26799;&#24230;&#19982;&#20445;&#27979;&#24230;&#26144;&#23556;$M$&#30340;&#22797;&#21512;&#65292;&#21363;$F=\nabla u \circ M$&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#19968;&#20855;&#26377;&#28145;&#36828;&#29702;&#35770;&#24847;&#20041;&#30340;&#32467;&#26524;&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21487;&#33021;&#30340;&#24212;&#29992;&#12290;&#35813;&#23450;&#29702;&#19982;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#29702;&#35770;&#23494;&#20999;&#30456;&#20851;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23558;&#28508;&#22312;&#20989;&#25968;$u$&#21442;&#25968;&#21270;&#20026;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#12290;&#26144;&#23556;$M$&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;$u^*$&#65292;&#21363;$u$&#30340;&#20984;&#20849;&#36717;&#65292;&#36880;&#28857;&#35745;&#31639;&#24471;&#21040;&#65292;&#21363;$M=\nabla u^* \circ F$&#65292;&#25110;&#32773;&#20316;&#20026;&#36741;&#21161;&#32593;&#32476;&#23398;&#20064;&#24471;&#21040;&#12290;&#22240;&#20026;$M$&#22312;&#22522;&#22240;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03071v1 Announce Type: cross  Abstract: In 1991, Brenier proved a theorem that generalizes the $QR$ decomposition for square matrices -- factored as PSD $\times$ unitary -- to any vector field $F:\mathbb{R}^d\rightarrow \mathbb{R}^d$. The theorem, known as the polar factorization theorem, states that any field $F$ can be recovered as the composition of the gradient of a convex function $u$ with a measure-preserving map $M$, namely $F=\nabla u \circ M$. We propose a practical implementation of this far-reaching theoretical result, and explore possible uses within machine learning. The theorem is closely related to optimal transport (OT) theory, and we borrow from recent advances in the field of neural optimal transport to parameterize the potential $u$ as an input convex neural network. The map $M$ can be either evaluated pointwise using $u^*$, the convex conjugate of $u$, through the identity $M=\nabla u^* \circ F$, or learned as an auxiliary network. Because $M$ is, in gene
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65292;&#33021;&#22815;&#36991;&#20813;&#32452;&#21512;&#32467;&#26500;&#30340;&#22797;&#26434;&#24615;&#65292;&#23454;&#29616;&#39640;&#25928;&#32431;&#25506;&#32034;&#65292;&#20174;&#32780;&#20934;&#30830;&#22238;&#31572;&#26597;&#35810;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.19319</link><description>&lt;p&gt;
&#39640;&#25928;&#32431;&#25506;&#32034;&#30340;&#21452;&#21521;&#31639;&#27861;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Dual-Directed Algorithm Design for Efficient Pure Exploration. (arXiv:2310.19319v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19319
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65292;&#33021;&#22815;&#36991;&#20813;&#32452;&#21512;&#32467;&#26500;&#30340;&#22797;&#26434;&#24615;&#65292;&#23454;&#29616;&#39640;&#25928;&#32431;&#25506;&#32034;&#65292;&#20174;&#32780;&#20934;&#30830;&#22238;&#31572;&#26597;&#35810;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#26377;&#38480;&#30340;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#38543;&#26426;&#39034;&#24207;&#33258;&#36866;&#24212;&#23454;&#39564;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#20915;&#31574;&#32773;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#26368;&#23567;&#30340;&#27979;&#37327;&#24037;&#20316;&#20197;&#39640;&#32622;&#20449;&#24230;&#20934;&#30830;&#22238;&#31572;&#19982;&#22791;&#36873;&#26041;&#26696;&#30456;&#20851;&#30340;&#26597;&#35810;&#38382;&#39064;&#12290;&#19968;&#20010;&#20856;&#22411;&#30340;&#26597;&#35810;&#38382;&#39064;&#26159;&#30830;&#23450;&#34920;&#29616;&#26368;&#20339;&#30340;&#22791;&#36873;&#26041;&#26696;&#65292;&#36825;&#22312;&#25490;&#21517;&#21644;&#36873;&#25321;&#38382;&#39064;&#20197;&#21450;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#31216;&#20026;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#22266;&#23450;&#31934;&#24230;&#30340;&#35774;&#23450;&#65292;&#24182;&#23548;&#20986;&#20102;&#19968;&#20010;&#19982;&#26679;&#26412;&#26368;&#20248;&#20998;&#37197;&#26377;&#24378;&#25910;&#25947;&#24615;&#27010;&#24565;&#30456;&#20851;&#30340;&#20248;&#21270;&#26465;&#20214;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25105;&#20204;&#21051;&#30011;&#20102;&#19968;&#20010;&#20998;&#37197;&#26159;&#21542;&#26368;&#20248;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#23545;&#20598;&#21464;&#37327;&#30340;&#20351;&#29992;&#20351;&#25105;&#20204;&#33021;&#22815;&#32469;&#36807;&#23436;&#20840;&#20381;&#36182;&#20110;&#21407;&#22987;&#21464;&#37327;&#30340;&#26368;&#20248;&#26465;&#20214;&#30340;&#32452;&#21512;&#32467;&#26500;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#26368;&#20248;&#26465;&#20214;&#20351;&#24471;&#21452;&#21521;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#30340;&#25193;&#23637;&#25104;&#20026;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider pure-exploration problems in the context of stochastic sequential adaptive experiments with a finite set of alternative options. The goal of the decision-maker is to accurately answer a query question regarding the alternatives with high confidence with minimal measurement efforts. A typical query question is to identify the alternative with the best performance, leading to ranking and selection problems, or best-arm identification in the machine learning literature. We focus on the fixed-precision setting and derive a sufficient condition for optimality in terms of a notion of strong convergence to the optimal allocation of samples. Using dual variables, we characterize the necessary and sufficient conditions for an allocation to be optimal. The use of dual variables allow us to bypass the combinatorial structure of the optimality conditions that relies solely on primal variables. Remarkably, these optimality conditions enable an extension of top-two algorithm design princ
&lt;/p&gt;</description></item><item><title>CLEVRER-Humans&#26159;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21028;&#26029;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20154;&#24037;&#26631;&#27880;&#26469;&#35299;&#20915;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#35821;&#35328;&#25551;&#36848;&#30340;&#32570;&#20047;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#21644;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.03635</link><description>&lt;p&gt;
CLEVRER-Humans: &#29992;&#20154;&#31867;&#30340;&#26041;&#24335;&#25551;&#36848;&#29289;&#29702;&#21644;&#22240;&#26524;&#20107;&#20214;
&lt;/p&gt;
&lt;p&gt;
CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03635
&lt;/p&gt;
&lt;p&gt;
CLEVRER-Humans&#26159;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21028;&#26029;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20154;&#24037;&#26631;&#27880;&#26469;&#35299;&#20915;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#35821;&#35328;&#25551;&#36848;&#30340;&#32570;&#20047;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#21644;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#33021;&#22815;&#25512;&#29702;&#29289;&#29702;&#20107;&#20214;&#21450;&#20854;&#22240;&#26524;&#20851;&#31995;&#30340;&#26426;&#22120;&#23545;&#20110;&#19982;&#29289;&#29702;&#19990;&#30028;&#36827;&#34892;&#28789;&#27963;&#20114;&#21160;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#29289;&#29702;&#21644;&#22240;&#26524;&#25512;&#29702;&#22522;&#20934;&#37117;&#20165;&#22522;&#20110;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#36825;&#31181;&#35774;&#35745;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#65306;&#19968;&#26159;&#20107;&#20214;&#31867;&#22411;&#21644;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#32570;&#20047;&#22810;&#26679;&#24615;&#65307;&#20108;&#26159;&#22522;&#20110;&#25163;&#21160;&#23450;&#20041;&#30340;&#21551;&#21457;&#24335;&#35268;&#21017;&#30340;&#22240;&#26524;&#20851;&#31995;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CLEVRER-Humans&#22522;&#20934;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20154;&#24037;&#26631;&#27880;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#23545;&#29289;&#29702;&#20107;&#20214;&#30340;&#22240;&#26524;&#21028;&#26029;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#31181;&#25216;&#26415;&#26469;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#65306;&#39318;&#20808;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#20219;&#21153;&#65292;&#20197; eliciting &#35270;&#39057;&#20013;&#20107;&#20214;&#30340;&#26032;&#34920;&#31034;&#26041;&#24335;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#22240;&#26524;&#20107;&#20214;&#22270; (CEGs)&#65307;&#20854;&#27425;&#65292;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Building machines that can reason about physical events and their causal relationships is crucial for flexible interaction with the physical world. However, most existing physical and causal reasoning benchmarks are exclusively based on synthetically generated events and synthetic natural language descriptions of causal relationships. This design brings up two issues. First, there is a lack of diversity in both event types and natural language descriptions; second, causal relationships based on manually-defined heuristics are different from human judgments. To address both shortcomings, we present the CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of physical events with human labels. We employ two techniques to improve data collection efficiency: first, a novel iterative event cloze task to elicit a new representation of events in videos, which we term Causal Event Graphs (CEGs); second, a data augmentation technique based on neural language generative models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#21644;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#12290;&#21516;&#26102;&#65292;&#22312;&#25554;&#20540;&#20998;&#31867;&#22120;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2309.12238</link><description>&lt;p&gt;
&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Model-based Clustering using Non-parametric Hidden Markov Models. (arXiv:2309.12238v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12238
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#21644;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#12290;&#21516;&#26102;&#65292;&#22312;&#25554;&#20540;&#20998;&#31867;&#22120;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#30001;&#20110;&#20854;&#20381;&#36182;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#19981;&#25351;&#23450;&#32676;&#32452;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20351;&#29992;HMM&#36827;&#34892;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23558;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#19982;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#32852;&#31995;&#36215;&#26469;&#30340;&#32467;&#26524;&#65292;&#29992;&#20197;&#30830;&#23450;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#30340;&#20851;&#38190;&#25968;&#37327;&#12290;&#25105;&#20204;&#36824;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26694;&#26550;&#19979;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#25554;&#20540;&#20998;&#31867;&#22120;&#30340;&#36807;&#24230;&#39118;&#38505;&#12290;&#25152;&#26377;&#36825;&#20123;&#32467;&#26524;&#37117;&#34987;&#35777;&#26126;&#22312;&#22312;&#32447;&#35774;&#32622;&#20013;&#20173;&#28982;&#26377;&#25928;&#65292;&#22312;&#35813;&#35774;&#32622;&#19979;&#65292;&#35266;&#27979;&#32467;&#26524;&#34987;&#39034;&#24207;&#32858;&#31867;&#12290;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thanks to their dependency structure, non-parametric Hidden Markov Models (HMMs) are able to handle model-based clustering without specifying group distributions. The aim of this work is to study the Bayes risk of clustering when using HMMs and to propose associated clustering procedures. We first give a result linking the Bayes risk of classification and the Bayes risk of clustering, which we use to identify the key quantity determining the difficulty of the clustering task. We also give a proof of this result in the i.i.d. framework, which might be of independent interest. Then we study the excess risk of the plugin classifier. All these results are shown to remain valid in the online setting where observations are clustered sequentially. Simulations illustrate our findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#29305;&#24449;&#26469;&#24674;&#22797;&#22270;&#30340;&#25299;&#25169;&#23646;&#24615;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#20248;&#31168;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20063;&#23637;&#29616;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.09924</link><description>&lt;p&gt;
&#22522;&#20110;&#28909;&#21644;&#27874;&#21160;&#21160;&#21147;&#23398;&#29305;&#24449;&#30340;&#22270;&#25299;&#25169;&#23646;&#24615;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Graph topological property recovery with heat and wave dynamics-based features on graphsD. (arXiv:2309.09924v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#29305;&#24449;&#26469;&#24674;&#22797;&#22270;&#30340;&#25299;&#25169;&#23646;&#24615;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#20248;&#31168;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20063;&#23637;&#29616;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#19978;&#30340;PDE&#35299;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20026;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#33719;&#24471;&#36830;&#32493;&#30340;&#33410;&#28857;&#21644;&#22270;&#32423;&#34920;&#31034;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#19982;&#22270;&#30340;&#35889;&#29305;&#24615;&#20197;&#21450;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#28216;&#36208;&#22312;&#22270;&#19978;&#34892;&#20026;&#20043;&#38388;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#36890;&#36807;&#24674;&#22797;&#38543;&#26426;&#22270;&#29983;&#25104;&#21442;&#25968;&#12289;Ricci&#26354;&#29575;&#21644;&#25345;&#20037;&#21516;&#35843;&#31561;&#26041;&#24335;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#21160;&#21147;&#23398;&#33021;&#22815;&#25429;&#25417;&#21040;&#22270;&#24418;&#20960;&#20309;&#21644;&#25299;&#25169;&#30340;&#26174;&#33879;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;GDeNet&#22312;&#21253;&#25324;&#24341;&#29992;&#22270;&#12289;&#33647;&#29289;&#20998;&#23376;&#21644;&#34507;&#30333;&#36136;&#22312;&#20869;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21327;&#20316;&#26469;&#21152;&#36895;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#36951;&#25022;&#26368;&#23567;&#21270;&#21644;&#32858;&#31867;&#36136;&#37327;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08710</link><description>&lt;p&gt;
&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Clustered Multi-Agent Linear Bandits. (arXiv:2309.08710v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21327;&#20316;&#26469;&#21152;&#36895;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#36951;&#25022;&#26368;&#23567;&#21270;&#21644;&#32858;&#31867;&#36136;&#37327;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#38382;&#39064;&#30340;&#19968;&#20010;&#29305;&#23450;&#23454;&#20363;&#65292;&#21363;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#26377;&#25928;&#21327;&#20316;&#26469;&#21152;&#36895;&#25972;&#20307;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#36825;&#19968;&#36129;&#29486;&#20013;&#65292;&#32593;&#32476;&#25511;&#21046;&#22120;&#36127;&#36131;&#20272;&#35745;&#32593;&#32476;&#30340;&#22522;&#26412;&#38598;&#32676;&#32467;&#26500;&#24182;&#20248;&#21270;&#21516;&#19968;&#32452;&#20013;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#32463;&#39564;&#20998;&#20139;&#12290;&#25105;&#20204;&#23545;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#21644;&#32858;&#31867;&#36136;&#37327;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#19982;&#26368;&#20808;&#36827;&#31639;&#27861;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#25105;&#20204;&#30340;&#31639;&#27861;&#26174;&#33879;&#25913;&#21892;&#20102;&#36951;&#25022;&#26368;&#23567;&#21270;&#65292;&#24182;&#25104;&#21151;&#24674;&#22797;&#20102;&#30495;&#23454;&#30340;&#22522;&#26412;&#38598;&#32676;&#21010;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address in this paper a particular instance of the multi-agent linear stochastic bandit problem, called clustered multi-agent linear bandits. In this setting, we propose a novel algorithm leveraging an efficient collaboration between the agents in order to accelerate the overall optimization problem. In this contribution, a network controller is responsible for estimating the underlying cluster structure of the network and optimizing the experiences sharing among agents within the same groups. We provide a theoretical analysis for both the regret minimization problem and the clustering quality. Through empirical evaluation against state-of-the-art algorithms on both synthetic and real data, we demonstrate the effectiveness of our approach: our algorithm significantly improves regret minimization while managing to recover the true underlying cluster partitioning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;</title><link>http://arxiv.org/abs/2306.07566</link><description>&lt;p&gt;
&#23398;&#20064;&#36873;&#25321;&#26631;&#31614;&#19979;&#30340;&#24322;&#36136;&#20915;&#31574;&#32773;&#65306;&#19968;&#31181;&#24037;&#20855;&#21464;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning under Selective Labels with Heterogeneous Decision-makers: An Instrumental Variable Approach. (arXiv:2306.07566v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#36825;&#31181;&#38382;&#39064;&#22312;&#21382;&#21490;&#20915;&#31574;&#23548;&#33268;&#32467;&#26524;&#20165;&#37096;&#20998;&#26631;&#35760;&#26102;&#20986;&#29616;&#12290;&#26631;&#35760;&#25968;&#25454;&#20998;&#24067;&#21487;&#33021;&#19982;&#25972;&#20307;&#20154;&#32676;&#26377;&#26174;&#33879;&#24046;&#24322;&#65292;&#29305;&#21035;&#26159;&#24403;&#21382;&#21490;&#20915;&#31574;&#21644;&#30446;&#26631;&#32467;&#26524;&#21487;&#20197;&#21516;&#26102;&#21463;&#26576;&#20123;&#26410;&#35266;&#23519;&#21040;&#30340;&#22240;&#32032;&#24433;&#21709;&#26102;&#12290;&#22240;&#27492;&#65292;&#20165;&#22522;&#20110;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#21487;&#33021;&#20250;&#23548;&#33268;&#22312;&#25972;&#20307;&#20154;&#32676;&#20013;&#30340;&#20005;&#37325;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#35768;&#22810;&#24212;&#29992;&#20013;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#26469;&#35299;&#20915;&#27492;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#19979;&#20998;&#26512;&#20102;&#36825;&#31181;&#35774;&#32622;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#28385;&#36275;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#26102;&#20219;&#20309;&#32473;&#23450;&#39044;&#27979;&#35268;&#21017;&#30340;&#20840;&#20307;&#39118;&#38505;&#30340;&#28857;&#35782;&#21035;&#26465;&#20214;&#65292;&#24182;&#22312;&#28857;&#35782;&#21035;&#22833;&#36133;&#26102;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#39118;&#38505;&#30028;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning with selectively labeled data, which arises when outcomes are only partially labeled due to historical decision-making. The labeled data distribution may substantially differ from the full population, especially when the historical decisions and the target outcome can be simultaneously affected by some unobserved factors. Consequently, learning with only the labeled data may lead to severely biased results when deployed to the full population. Our paper tackles this challenge by exploiting the fact that in many applications the historical decisions were made by a set of heterogeneous decision-makers. In particular, we analyze this setup in a principled instrumental variable (IV) framework. We establish conditions for the full-population risk of any given prediction rule to be point-identified from the observed data and provide sharp risk bounds when the point identification fails. We further propose a weighted learning approach that learns prediction ru
&lt;/p&gt;</description></item></channel></rss>