<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;</title><link>https://arxiv.org/abs/2403.13748</link><description>&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#20013;&#22240;&#23376;&#21270;&#39640;&#26031;&#36817;&#20284;&#30340;&#24046;&#24322;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13748
&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#20013;&#65292;&#32473;&#23450;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#20998;&#24067;$p$&#65292;&#38382;&#39064;&#26159;&#20174;&#19968;&#20123;&#26356;&#26131;&#22788;&#29702;&#30340;&#26063;$\mathcal{Q}$&#20013;&#35745;&#31639;&#26368;&#20339;&#36817;&#20284;$q$&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#36817;&#20284;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;Kullback-Leibler (KL)&#25955;&#24230;&#26469;&#25214;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23384;&#22312;&#20854;&#20182;&#26377;&#25928;&#30340;&#25955;&#24230;&#36873;&#25321;&#65292;&#24403;$\mathcal{Q}$&#19981;&#21253;&#21547;$p$&#26102;&#65292;&#27599;&#20010;&#25955;&#24230;&#37117;&#25903;&#25345;&#19981;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#39640;&#26031;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#34987;&#23545;&#35282;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#36817;&#20284;&#25152;&#24433;&#21709;&#30340;VI&#32467;&#26524;&#20013;&#65292;&#25955;&#24230;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;VI&#32467;&#26524;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#30340;&#25955;&#24230;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#22914;&#26041;&#24046;&#12289;&#31934;&#24230;&#21644;&#29109;&#65292;&#36827;&#34892;\textit{&#25490;&#24207;}&#12290;&#25105;&#20204;&#36824;&#24471;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#23450;&#29702;&#65292;&#34920;&#26126;&#26080;&#27861;&#36890;&#36807;&#22240;&#23376;&#21270;&#36817;&#20284;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;&#65307;&#22240;&#27492;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13748v1 Announce Type: cross  Abstract: Given an intractable distribution $p$, the problem of variational inference (VI) is to compute the best approximation $q$ from some more tractable family $\mathcal{Q}$. Most commonly the approximation is found by minimizing a Kullback-Leibler (KL) divergence. However, there exist other valid choices of divergences, and when $\mathcal{Q}$ does not contain~$p$, each divergence champions a different solution. We analyze how the choice of divergence affects the outcome of VI when a Gaussian with a dense covariance matrix is approximated by a Gaussian with a diagonal covariance matrix. In this setting we show that different divergences can be \textit{ordered} by the amount that their variational approximations misestimate various measures of uncertainty, such as the variance, precision, and entropy. We also derive an impossibility theorem showing that no two of these measures can be simultaneously matched by a factorized approximation; henc
&lt;/p&gt;</description></item><item><title>FreDF&#26159;&#19968;&#31181;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#26631;&#31614;&#24207;&#21015;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;</title><link>https://arxiv.org/abs/2402.02399</link><description>&lt;p&gt;
FreDF: &#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
FreDF: Learning to Forecast in Frequency Domain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02399
&lt;/p&gt;
&lt;p&gt;
FreDF&#26159;&#19968;&#31181;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#26631;&#31614;&#24207;&#21015;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#22312;&#21382;&#21490;&#24207;&#21015;&#21644;&#26631;&#31614;&#24207;&#21015;&#20013;&#37117;&#38754;&#20020;&#33258;&#30456;&#20851;&#30340;&#25361;&#25112;&#12290;&#24403;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#22788;&#29702;&#21382;&#21490;&#24207;&#21015;&#20013;&#30340;&#33258;&#30456;&#20851;&#38382;&#39064;&#65292;&#20294;&#24448;&#24448;&#24573;&#35270;&#20102;&#26631;&#31614;&#24207;&#21015;&#20013;&#30340;&#33258;&#30456;&#20851;&#23384;&#22312;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#26032;&#20852;&#30340;&#39044;&#27979;&#27169;&#22411;&#20027;&#35201;&#36981;&#24490;&#30452;&#25509;&#39044;&#27979;&#65288;DF&#65289;&#33539;&#24335;&#65292;&#22312;&#26631;&#31614;&#24207;&#21015;&#20013;&#20551;&#35774;&#26465;&#20214;&#29420;&#31435;&#24615;&#19979;&#29983;&#25104;&#22810;&#27493;&#39044;&#27979;&#12290;&#36825;&#31181;&#20551;&#35774;&#24573;&#35270;&#20102;&#26631;&#31614;&#24207;&#21015;&#20013;&#22266;&#26377;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#22522;&#20110;DF&#30340;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#38024;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#39057;&#22495;&#22686;&#24378;&#30452;&#25509;&#39044;&#27979;&#65288;FreDF&#65289;&#65292;&#36890;&#36807;&#22312;&#39057;&#22495;&#20013;&#23398;&#20064;&#39044;&#27979;&#26469;&#36991;&#20813;&#26631;&#31614;&#33258;&#30456;&#20851;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;FreDF&#22312;&#24615;&#33021;&#19978;&#22823;&#22823;&#36229;&#36807;&#20102;&#21253;&#25324;iTransformer&#22312;&#20869;&#30340;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#24182;&#19988;&#19982;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series modeling is uniquely challenged by the presence of autocorrelation in both historical and label sequences. Current research predominantly focuses on handling autocorrelation within the historical sequence but often neglects its presence in the label sequence. Specifically, emerging forecast models mainly conform to the direct forecast (DF) paradigm, generating multi-step forecasts under the assumption of conditional independence within the label sequence. This assumption disregards the inherent autocorrelation in the label sequence, thereby limiting the performance of DF-based models. In response to this gap, we introduce the Frequency-enhanced Direct Forecast (FreDF), which bypasses the complexity of label autocorrelation by learning to forecast in the frequency domain. Our experiments demonstrate that FreDF substantially outperforms existing state-of-the-art methods including iTransformer and is compatible with a variety of forecast models.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#20989;&#25968;&#26469;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#26080;&#38656;&#35757;&#32451;&#65292;&#19988;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#33021;&#22815;&#23454;&#29616;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.12395</link><description>&lt;p&gt;
&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Closed-Form Diffusion Models. (arXiv:2310.12395v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#24335;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#20989;&#25968;&#26469;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#26080;&#38656;&#35757;&#32451;&#65292;&#19988;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#33021;&#22815;&#23454;&#29616;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;(SGMs)&#36890;&#36807;&#36845;&#20195;&#22320;&#20351;&#29992;&#25200;&#21160;&#30446;&#26631;&#20989;&#25968;&#30340;&#24471;&#20998;&#20989;&#25968;&#26469;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#23545;&#20110;&#20219;&#20309;&#26377;&#38480;&#30340;&#35757;&#32451;&#38598;&#65292;&#21487;&#20197;&#38381;&#24335;&#22320;&#35780;&#20272;&#36825;&#20010;&#24471;&#20998;&#20989;&#25968;&#65292;&#20294;&#30001;&#27492;&#24471;&#21040;&#30340;SGMs&#20250;&#35760;&#24518;&#20854;&#35757;&#32451;&#25968;&#25454;&#65292;&#19981;&#33021;&#29983;&#25104;&#26032;&#26679;&#26412;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#24471;&#20998;&#20989;&#25968;&#65292;&#20294;&#36825;&#31181;&#36817;&#20284;&#30340;&#35823;&#24046;&#26377;&#21161;&#20110;&#25512;&#24191;&#65292;&#28982;&#32780;&#31070;&#32463;SGMs&#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#20195;&#20215;&#39640;&#65292;&#32780;&#19988;&#23545;&#20110;&#36825;&#31181;&#35823;&#24046;&#25552;&#20379;&#30340;&#26377;&#25928;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#23578;&#19981;&#28165;&#26970;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#26174;&#24335;&#24179;&#28369;&#30340;&#38381;&#24335;&#24471;&#20998;&#26469;&#33719;&#24471;&#19968;&#20010;&#29983;&#25104;&#26032;&#26679;&#26412;&#30340;SGMs&#65292;&#32780;&#26080;&#38656;&#35757;&#32451;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#39640;&#25928;&#24471;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#12290;&#21033;&#29992;&#36825;&#20010;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#28040;&#36153;&#32423;CPU&#19978;&#36816;&#34892;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#31070;&#32463;SGMs&#30456;&#31454;&#20105;&#30340;&#37319;&#26679;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models (SGMs) sample from a target distribution by iteratively transforming noise using the score function of the perturbed target. For any finite training set, this score function can be evaluated in closed form, but the resulting SGM memorizes its training data and does not generate novel samples. In practice, one approximates the score by training a neural network via score-matching. The error in this approximation promotes generalization, but neural SGMs are costly to train and sample, and the effective regularization this error provides is not well-understood theoretically. In this work, we instead explicitly smooth the closed-form score to obtain an SGM that generates novel samples without training. We analyze our model and propose an efficient nearest-neighbor-based estimator of its score function. Using this estimator, our method achieves sampling times competitive with neural SGMs while running on consumer-grade CPUs.
&lt;/p&gt;</description></item></channel></rss>