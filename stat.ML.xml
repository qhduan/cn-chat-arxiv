<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#23398;&#20064;&#22823;&#38388;&#36317;&#21322;&#31354;&#38388;&#38382;&#39064;&#30340;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#31639;&#27861;&#65292;&#22312;&#32500;&#24230;&#26080;&#20851;&#12289;&#26102;&#38388;&#22797;&#26434;&#24230;&#20248;&#21270;&#12289;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#31561;&#22810;&#20010;&#20851;&#38190;&#21442;&#25968;&#19978;&#22343;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.13857</link><description>&lt;p&gt;
&#21487;&#22797;&#21046;&#23398;&#20064;&#22823;&#38388;&#36317;&#21322;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Replicable Learning of Large-Margin Halfspaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13857
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#23398;&#20064;&#22823;&#38388;&#36317;&#21322;&#31354;&#38388;&#38382;&#39064;&#30340;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#31639;&#27861;&#65292;&#22312;&#32500;&#24230;&#26080;&#20851;&#12289;&#26102;&#38388;&#22797;&#26434;&#24230;&#20248;&#21270;&#12289;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#31561;&#22810;&#20010;&#20851;&#38190;&#21442;&#25968;&#19978;&#22343;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#21487;&#22797;&#21046;&#31639;&#27861;&#26469;&#35299;&#20915;&#23398;&#20064;&#22823;&#38388;&#36317;&#21322;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25913;&#36827;&#20102;Impagliazzo, Lei, Pitassi&#21644;Sorrell&#22312;STOC, 2022&#20013;&#25552;&#20379;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#36825;&#20010;&#20219;&#21153;&#30340;&#39318;&#20010;&#19982;&#32500;&#24230;&#26080;&#20851;&#30340;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#20854;&#36816;&#34892;&#26102;&#38388;&#20026;&#22810;&#39033;&#24335;&#65292;&#26159;&#27491;&#30830;&#30340;&#65292;&#24182;&#19988;&#22312;&#25152;&#26377;&#30456;&#20851;&#21442;&#25968;&#26041;&#38754;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#37117;&#20005;&#26684;&#27604;Impagliazzo&#31561;&#20154;&#22312;2022&#24180;&#23454;&#29616;&#30340;&#31639;&#27861;&#35201;&#22909;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;&#22312;&#31934;&#24230;&#21442;&#25968;$\epsilon$&#26041;&#38754;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;SGD&#30340;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#22312;&#26576;&#20123;&#21442;&#25968;&#33539;&#22260;&#20869;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20248;&#20110;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13857v1 Announce Type: new  Abstract: We provide efficient replicable algorithms for the problem of learning large-margin halfspaces. Our results improve upon the algorithms provided by Impagliazzo, Lei, Pitassi, and Sorrell [STOC, 2022]. We design the first dimension-independent replicable algorithms for this task which runs in polynomial time, is proper, and has strictly improved sample complexity compared to the one achieved by Impagliazzo et al. [2022] with respect to all the relevant parameters. Moreover, our first algorithm has sample complexity that is optimal with respect to the accuracy parameter $\epsilon$. We also design an SGD-based replicable algorithm that, in some parameters' regimes, achieves better sample and time complexity than our first algorithm.   Departing from the requirement of polynomial time algorithms, using the DP-to-Replicability reduction of Bun, Gaboardi, Hopkins, Impagliazzo, Lei, Pitassi, Sorrell, and Sivakumar [STOC, 2023], we show how to o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#38024;&#23545;&#32479;&#35745;&#32858;&#31867;&#30340;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#21487;&#22797;&#21046;&#32858;&#31867;&#30340;&#27010;&#24565;&#65292;&#20854;&#20013;&#21253;&#25324;&#21033;&#29992;&#36817;&#20284;&#31639;&#27861;&#32452;&#21512;&#38382;&#39064;&#30340;&#40657;&#30418;&#26041;&#24335;&#35299;&#20915;&#32479;&#35745;$k$-medians&#12289;&#32479;&#35745;$k$-means&#21644;&#32479;&#35745;$k$-centers&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#34920;&#31034;&#31639;&#27861;&#22797;&#26434;&#24230;&#30340;&#20989;&#25968;&#21644;&#35823;&#24046;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2302.10359</link><description>&lt;p&gt;
&#21487;&#22797;&#21046;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Replicable Clustering. (arXiv:2302.10359v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10359
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#38024;&#23545;&#32479;&#35745;&#32858;&#31867;&#30340;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#21487;&#22797;&#21046;&#32858;&#31867;&#30340;&#27010;&#24565;&#65292;&#20854;&#20013;&#21253;&#25324;&#21033;&#29992;&#36817;&#20284;&#31639;&#27861;&#32452;&#21512;&#38382;&#39064;&#30340;&#40657;&#30418;&#26041;&#24335;&#35299;&#20915;&#32479;&#35745;$k$-medians&#12289;&#32479;&#35745;$k$-means&#21644;&#32479;&#35745;$k$-centers&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#34920;&#31034;&#31639;&#27861;&#22797;&#26434;&#24230;&#30340;&#20989;&#25968;&#21644;&#35823;&#24046;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#26368;&#36817;&#30001;Impagliazzo&#31561;&#20154;[2022]&#24341;&#20837;&#30340;&#21487;&#22797;&#21046;&#24615;&#27010;&#24565;&#19979;&#35774;&#35745;&#20102;&#22312;&#32479;&#35745;&#32858;&#31867;&#20013;&#21487;&#22797;&#21046;&#30340;&#31639;&#27861;&#12290;&#26681;&#25454;&#36825;&#20010;&#23450;&#20041;&#65292;&#22914;&#26524;&#19968;&#20010;&#32858;&#31867;&#31639;&#27861;&#26159;&#21487;&#22797;&#21046;&#30340;&#65292;&#37027;&#20040;&#22312;&#21516;&#19968;&#20998;&#24067;&#30340;&#20004;&#20010;&#19981;&#21516;&#36755;&#20837;&#19978;&#25191;&#34892;&#26102;&#65292;&#21482;&#35201;&#20854;&#20869;&#37096;&#38543;&#26426;&#24615;&#22312;&#25191;&#34892;&#20013;&#24471;&#21040;&#20849;&#20139;&#65292;&#23601;&#33021;&#39640;&#27010;&#29575;&#22320;&#20135;&#29983;&#23436;&#20840;&#30456;&#21516;&#30340;&#26679;&#26412;&#31354;&#38388;&#20998;&#21306;&#12290;&#25105;&#20204;&#36890;&#36807;&#40657;&#30418;&#30340;&#26041;&#24335;&#21033;&#29992;&#32452;&#21512;&#23545;&#24212;&#38382;&#39064;&#30340;&#36817;&#20284;&#31639;&#27861;&#65292;&#20026;&#32479;&#35745;$k$-medians&#12289;&#32479;&#35745;$k$-means&#21644;&#32479;&#35745;$k$-centers&#38382;&#39064;&#25552;&#20986;&#20102;&#36825;&#26679;&#30340;&#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#21487;&#22797;&#21046;&#30340;$O(1)$-&#36924;&#36817;&#31639;&#27861;&#65292;&#20854;&#36866;&#29992;&#20110;&#32479;&#35745;&#27431;&#20960;&#37324;&#24471;$k$-medians ($k$-means)&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\operatorname{poly}(d)$&#12290;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#19968;&#20010;$O(1)$-&#36924;&#36817;&#31639;&#27861;&#65292;&#20854;&#22312;&#32479;&#35745;&#27431;&#20960;&#37324;&#24471;$k$-centers$&#26102;&#20855;&#26377;&#39069;&#22806;&#30340;$O(1)$-&#21152;&#24615;&#35823;&#24046;&#65292;&#23613;&#31649;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\exp(d)$&#12290;
&lt;/p&gt;
&lt;p&gt;
We design replicable algorithms in the context of statistical clustering under the recently introduced notion of replicability from Impagliazzo et al. [2022]. According to this definition, a clustering algorithm is replicable if, with high probability, its output induces the exact same partition of the sample space after two executions on different inputs drawn from the same distribution, when its internal randomness is shared across the executions. We propose such algorithms for the statistical $k$-medians, statistical $k$-means, and statistical $k$-centers problems by utilizing approximation routines for their combinatorial counterparts in a black-box manner. In particular, we demonstrate a replicable $O(1)$-approximation algorithm for statistical Euclidean $k$-medians ($k$-means) with $\operatorname{poly}(d)$ sample complexity. We also describe an $O(1)$-approximation algorithm with an additional $O(1)$-additive error for statistical Euclidean $k$-centers, albeit with $\exp(d)$ samp
&lt;/p&gt;</description></item></channel></rss>