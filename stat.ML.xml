<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#27604;&#36739;&#20102;&#20256;&#32479;&#30340;&#22810;&#37325;&#25554;&#34917;&#19982;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#22312;&#22810;&#23618;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;MICE&#22312;&#20934;&#30830;&#30340;&#25298;&#32477;&#29575;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#32780;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#22312;&#20943;&#23569;&#20559;&#24046;&#26041;&#38754;&#34920;&#29616;&#36739;&#22909;&#12290;</title><link>http://arxiv.org/abs/2401.14161</link><description>&lt;p&gt;
&#36866;&#24212;&#22810;&#23618;&#25968;&#25454;&#30340;&#22522;&#20110;&#26641;&#30340;&#22810;&#37325;&#25554;&#34917;&#26041;&#27861;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adapting tree-based multiple imputation methods for multi-level data? A simulation study. (arXiv:2401.14161v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14161
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#27604;&#36739;&#20102;&#20256;&#32479;&#30340;&#22810;&#37325;&#25554;&#34917;&#19982;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#22312;&#22810;&#23618;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;MICE&#22312;&#20934;&#30830;&#30340;&#25298;&#32477;&#29575;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#32780;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#22312;&#20943;&#23569;&#20559;&#24046;&#26041;&#38754;&#34920;&#29616;&#36739;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;&#38024;&#23545;&#22810;&#23618;&#25968;&#25454;&#30340;&#22810;&#37325;&#25554;&#34917;(MI)&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#12290;&#23427;&#27604;&#36739;&#20102;&#20256;&#32479;&#30340;&#20197;&#38142;&#24335;&#26041;&#31243;&#20026;&#22522;&#30784;&#30340;&#22810;&#37325;&#25554;&#34917;(MICE)&#19982;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65288;&#22914;&#38142;&#24335;&#38543;&#26426;&#26862;&#26519;&#19982;&#39044;&#27979;&#22343;&#20540;&#21305;&#37197;&#21644;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#65289;&#30340;&#24615;&#33021;&#12290;&#36824;&#23545;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#21253;&#25324;&#20102;&#21253;&#25324;&#38598;&#32676;&#25104;&#21592;&#30340;&#34394;&#25311;&#21464;&#37327;&#30340;&#25913;&#36827;&#29256;&#26412;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#35813;&#30740;&#31350;&#20351;&#29992;&#20855;&#26377;&#19981;&#21516;&#38598;&#32676;&#22823;&#23567;(25&#21644;50)&#21644;&#19981;&#23436;&#25972;&#31243;&#24230;(10\%&#21644;50\%)&#30340;&#27169;&#25311;&#20998;&#23618;&#25968;&#25454;&#23545;&#31995;&#25968;&#20272;&#35745;&#20559;&#24046;&#12289;&#32479;&#35745;&#21151;&#25928;&#21644;&#31867;&#22411;I&#38169;&#35823;&#29575;&#36827;&#34892;&#35780;&#20272;&#12290;&#31995;&#25968;&#26159;&#20351;&#29992;&#38543;&#26426;&#25130;&#36317;&#21644;&#38543;&#26426;&#26012;&#29575;&#27169;&#22411;&#36827;&#34892;&#20272;&#35745;&#30340;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;MICE&#26356;&#36866;&#21512;&#20934;&#30830;&#30340;&#25298;&#32477;&#29575;&#65292;&#20294;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#26377;&#21161;&#20110;&#20943;&#23569;&#20559;&#24046;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#21457;&#29616;&#65292;&#19981;&#21516;&#38598;&#32676;&#22823;&#23567;&#30340;&#20559;&#24046;&#27700;&#24179;&#30456;&#20284;&#65292;&#20294;&#25298;&#32477;&#29575;&#22312;&#23569;&#25968;&#32570;&#22833;&#24773;&#20917;&#19979;&#36739;&#19981;&#29702;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
This simulation study evaluates the effectiveness of multiple imputation (MI) techniques for multilevel data. It compares the performance of traditional Multiple Imputation by Chained Equations (MICE) with tree-based methods such as Chained Random Forests with Predictive Mean Matching and Extreme Gradient Boosting. Adapted versions that include dummy variables for cluster membership are also included for the tree-based methods. Methods are evaluated for coefficient estimation bias, statistical power, and type I error rates on simulated hierarchical data with different cluster sizes (25 and 50) and levels of missingness (10\% and 50\%). Coefficients are estimated using random intercept and random slope models. The results show that while MICE is preferred for accurate rejection rates, Extreme Gradient Boosting is advantageous for reducing bias. Furthermore, the study finds that bias levels are similar across different cluster sizes, but rejection rates tend to be less favorable with few
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.02211</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Machine Learning with Multi-source Data. (arXiv:2309.02211v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#30446;&#26631;&#20998;&#24067;&#19982;&#28304;&#25968;&#25454;&#38598;&#19981;&#21516;&#26102;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#36739;&#24046;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26412;&#25991;&#21033;&#29992;&#22810;&#20010;&#25968;&#25454;&#28304;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#20248;&#21270;&#20851;&#20110;&#30446;&#26631;&#20998;&#24067;&#31867;&#30340;&#21487;&#35299;&#37322;&#26041;&#24046;&#30340;&#23545;&#25239;&#24615;&#22870;&#21169;&#12290;&#19982;&#20256;&#32479;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#25913;&#21892;&#20102;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26159;&#28304;&#25968;&#25454;&#38598;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340;&#21152;&#26435;&#24179;&#22343;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#20851;&#38190;&#37492;&#21035;&#32467;&#26524;&#26469;&#25552;&#39640;&#20219;&#24847;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#21644;&#31070;&#32463;&#32593;&#32476;&#31561;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#22120;&#26469;&#20272;&#35745;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;c&#26041;&#38754;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal aggregation weight for general machine-learning algorithms and demonstrate its improvement in the c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23545;&#25237;&#24433;&#31995;&#25968;&#36827;&#34892;&#26816;&#27979;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2110.01729</link><description>&lt;p&gt;
&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#21450;&#20854;&#22312;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic coordinate transformations with applications to robust machine learning. (arXiv:2110.01729v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.01729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23545;&#25237;&#24433;&#31995;&#25968;&#36827;&#34892;&#26816;&#27979;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#32452;&#26032;&#30340;&#29305;&#24449;&#65292;&#21033;&#29992;Karhunen-Loeve&#23637;&#24320;&#27861;&#26469;&#35782;&#21035;&#36755;&#20837;&#25968;&#25454;&#30340;&#28508;&#22312;&#38543;&#26426;&#34892;&#20026;&#12290;&#36825;&#20123;&#26032;&#29305;&#24449;&#26159;&#36890;&#36807;&#22522;&#20110;&#26368;&#36817;&#30340;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#29702;&#35770;&#36827;&#34892;&#30340;&#22352;&#26631;&#21464;&#25442;&#26500;&#24314;&#30340;&#65292;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#30456;&#20851;&#30340;&#20449;&#21495;&#20998;&#35299;&#26159;&#29992;&#24050;&#30693;&#20248;&#21270;&#23646;&#24615;&#30340;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#20855;&#26377;&#26377;&#38480;&#21151;&#33021;&#31354;&#38388;&#30340;&#38543;&#26426;&#36807;&#31243;&#65288;&#38543;&#26426;&#22330;&#65289;&#12290;&#21407;&#21017;&#19978;&#65292;&#36825;&#20123;&#20302;&#32500;&#31354;&#38388;&#21487;&#20197;&#25429;&#25417;&#32473;&#23450;&#21517;&#20041;&#31867;&#21035;&#30340;'&#24213;&#23618;&#20449;&#21495;'&#30340;&#22823;&#37096;&#20998;&#38543;&#26426;&#21464;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#23558;&#26469;&#33258;&#20854;&#23427;&#31867;&#21035;&#30340;&#20449;&#21495;&#25298;&#32477;&#20026;&#38543;&#26426;&#24322;&#24120;&#12290;&#36890;&#36807;&#21517;&#20041;&#31867;&#21035;&#30340;&#23618;&#32423;&#26377;&#38480;&#32500;&#23637;&#24320;&#65292;&#26500;&#24314;&#20102;&#19968;&#31995;&#21015;&#29992;&#20110;&#26816;&#27979;&#24322;&#24120;&#20449;&#21495;&#32452;&#20214;&#30340;&#27491;&#20132;&#23884;&#22871;&#23376;&#31354;&#38388;&#12290;&#28982;&#21518;&#20351;&#29992;&#36825;&#20123;&#23376;&#31354;&#38388;&#20013;&#30340;&#25237;&#24433;&#31995;&#25968;&#26469;&#35757;&#32451;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#32467;&#26524;&#34920;&#26126;&#20854;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we introduce a set of novel features for identifying underlying stochastic behavior of input data using the Karhunen-Loeve expansion. These novel features are constructed by applying a coordinate transformation based on the recent Functional Data Analysis theory for anomaly detection. The associated signal decomposition is an exact hierarchical tensor product expansion with known optimality properties for approximating stochastic processes (random fields) with finite dimensional function spaces. In principle these low dimensional spaces can capture most of the stochastic behavior of `underlying signals' in a given nominal class, and can reject signals in alternative classes as stochastic anomalies. Using a hierarchical finite dimensional expansion of the nominal class, a series of orthogonal nested subspaces is constructed for detecting anomalous signal components. Projection coefficients of input data in these subspaces are then used to train a Machine Learning (ML) clas
&lt;/p&gt;</description></item></channel></rss>