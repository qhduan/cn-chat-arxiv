<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;RMSProp&#21644;Adam&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#32039;&#33268;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#23637;&#31034;&#20102;&#22312;&#26368;&#23485;&#26494;&#30340;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RMSProp&#21644;Adam&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;</title><link>https://arxiv.org/abs/2404.01436</link><description>&lt;p&gt;
RMSProp&#21644;Adam&#22312;&#20855;&#26377;&#20223;&#23556;&#22122;&#22768;&#26041;&#24046;&#30340;&#24191;&#20041;&#20809;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;RMSProp&#21644;Adam&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#32039;&#33268;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#23637;&#31034;&#20102;&#22312;&#26368;&#23485;&#26494;&#30340;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RMSProp&#21644;Adam&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22352;&#26631;&#32423;&#21035;&#24191;&#20041;&#20809;&#28369;&#24615;&#21644;&#20223;&#23556;&#22122;&#22768;&#26041;&#24046;&#30340;&#26368;&#23485;&#26494;&#20551;&#35774;&#19979;&#65292;&#20026;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;RMSProp&#21644;Adam&#25552;&#20379;&#20102;&#39318;&#20010;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#39318;&#20808;&#20998;&#26512;&#20102;RMSProp&#65292;&#23427;&#26159;&#19968;&#31181;&#20855;&#26377;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#20294;&#27809;&#26377;&#19968;&#38454;&#21160;&#37327;&#30340;Adam&#30340;&#29305;&#20363;&#12290;&#20855;&#20307;&#22320;&#65292;&#20026;&#20102;&#35299;&#20915;&#33258;&#36866;&#24212;&#26356;&#26032;&#12289;&#26080;&#30028;&#26799;&#24230;&#20272;&#35745;&#21644;Lipschitz&#24120;&#25968;&#20043;&#38388;&#30340;&#20381;&#36182;&#25361;&#25112;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19979;&#38477;&#24341;&#29702;&#20013;&#30340;&#19968;&#38454;&#39033;&#25910;&#25947;&#65292;&#24182;&#19988;&#20854;&#20998;&#27597;&#30001;&#26799;&#24230;&#33539;&#25968;&#30340;&#20989;&#25968;&#19978;&#30028;&#38480;&#21046;&#12290;&#22522;&#20110;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#36866;&#24403;&#30340;&#36229;&#21442;&#25968;&#30340;RMSProp&#25910;&#25947;&#21040;&#19968;&#20010;$\epsilon$-&#31283;&#23450;&#28857;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;&#28982;&#21518;&#65292;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25512;&#24191;&#21040;Adam&#65292;&#39069;&#22806;&#30340;&#25361;&#25112;&#26159;&#30001;&#20110;&#26799;&#24230;&#19982;&#19968;&#38454;&#21160;&#37327;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01436v1 Announce Type: cross  Abstract: This paper provides the first tight convergence analyses for RMSProp and Adam in non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. We first analyze RMSProp, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and first-order momentum. We develop a new upper bound on
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#26088;&#22312;&#20840;&#38754;&#27010;&#36848;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#22914;&#20309;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#26469;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644; GNN &#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#35266;&#28857;&#12290;</title><link>https://arxiv.org/abs/2403.07185</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Uncertainty in Graph Neural Networks: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#26088;&#22312;&#20840;&#38754;&#27010;&#36848;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#22914;&#20309;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#26469;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644; GNN &#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#12290;&#28982;&#32780;&#65292;GNNs&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#28304;&#33258;&#25968;&#25454;&#20013;&#30340;&#22266;&#26377;&#38543;&#26426;&#24615;&#21644;&#27169;&#22411;&#35757;&#32451;&#35823;&#24046;&#31561;&#22810;&#31181;&#22240;&#32032;&#65292;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#21644;&#38169;&#35823;&#30340;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#35782;&#21035;&#12289;&#37327;&#21270;&#21644;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#21644;GNN&#39044;&#27979;&#30340;&#21487;&#38752;&#24615;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#26412;&#35843;&#26597;&#26088;&#22312;&#20174;&#19981;&#30830;&#23450;&#24615;&#30340;&#35282;&#24230;&#20840;&#38754;&#27010;&#36848;GNNs&#65292;&#24182;&#24378;&#35843;&#20854;&#22312;&#22270;&#23398;&#20064;&#20013;&#30340;&#25972;&#21512;&#12290;&#25105;&#20204;&#27604;&#36739;&#21644;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#22270;&#19981;&#30830;&#23450;&#24615;&#29702;&#35770;&#21644;&#26041;&#27861;&#65292;&#20197;&#21450;&#30456;&#24212;&#30340;&#19979;&#28216;&#20219;&#21153;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#24357;&#21512;&#20102;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#21516;&#26102;&#36830;&#25509;&#19981;&#21516;&#30340;GNN&#31038;&#21306;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#36825;&#19968;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07185v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have been extensively used in various real-world applications. However, the predictive uncertainty of GNNs stemming from diverse sources such as inherent randomness in data and model training errors can lead to unstable and erroneous predictions. Therefore, identifying, quantifying, and utilizing uncertainty are essential to enhance the performance of the model for the downstream tasks as well as the reliability of the GNN predictions. This survey aims to provide a comprehensive overview of the GNNs from the perspective of uncertainty with an emphasis on its integration in graph learning. We compare and summarize existing graph uncertainty theory and methods, alongside the corresponding downstream tasks. Thereby, we bridge the gap between theory and practice, meanwhile connecting different GNN communities. Moreover, our work provides valuable insights into promising directions in this field.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#23558;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#35270;&#20026;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#25104;&#21151;&#35843;&#25972; EI &#24182;&#23637;&#31034;&#20854;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11345</link><description>&lt;p&gt;
&#21464;&#20998;&#29109;&#25628;&#32034;&#29992;&#20110;&#35843;&#25972;&#26399;&#26395;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Variational Entropy Search for Adjusting Expected Improvement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#23558;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#35270;&#20026;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#25104;&#21151;&#35843;&#25972; EI &#24182;&#23637;&#31034;&#20854;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bayesian optimization &#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#30340;&#25216;&#26415;&#65292;&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#26159;&#35813;&#39046;&#22495;&#20013;&#26368;&#24120;&#29992;&#30340;&#33719;&#21462;&#20989;&#25968;&#12290;&#34429;&#28982; EI &#36890;&#24120;&#34987;&#35270;&#20026;&#19982;&#20854;&#20182;&#20449;&#24687;&#29702;&#35770;&#33719;&#21462;&#20989;&#25968;&#65288;&#22914;&#29109;&#25628;&#32034;&#65288;ES&#65289;&#21644;&#26368;&#22823;&#20540;&#29109;&#25628;&#32034;&#65288;MES&#65289;&#65289;&#19981;&#21516;&#65292;&#20294;&#25105;&#20204;&#30340;&#24037;&#20316;&#25581;&#31034;&#20102;&#65292;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#26041;&#27861;&#65292;EI &#21487;&#20197;&#34987;&#35270;&#20026; MES &#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#22312;&#36825;&#19968;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#21464;&#20998;&#29109;&#25628;&#32034;&#65288;VES&#65289;&#26041;&#27861;&#21644; VES-Gamma &#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#20449;&#24687;&#29702;&#35770;&#27010;&#24565;&#30340;&#21407;&#21017;&#25972;&#21512;&#21040; EI &#20013;&#26469;&#35843;&#25972; EI&#12290;VES-Gamma &#30340;&#26377;&#25928;&#24615;&#22312;&#21508;&#31181;&#27979;&#35797;&#20989;&#25968;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;&#31361;&#20986;&#20102;&#23427;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#22330;&#26223;&#20013;&#30340;&#29702;&#35770;&#21644;&#23454;&#38469;&#29992;&#36884;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11345v1 Announce Type: cross  Abstract: Bayesian optimization is a widely used technique for optimizing black-box functions, with Expected Improvement (EI) being the most commonly utilized acquisition function in this domain. While EI is often viewed as distinct from other information-theoretic acquisition functions, such as entropy search (ES) and max-value entropy search (MES), our work reveals that EI can be considered a special case of MES when approached through variational inference (VI). In this context, we have developed the Variational Entropy Search (VES) methodology and the VES-Gamma algorithm, which adapts EI by incorporating principles from information-theoretic concepts. The efficacy of VES-Gamma is demonstrated across a variety of test functions and read datasets, highlighting its theoretical and practical utilities in Bayesian optimization scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.09469</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20613;&#31435;&#21494;&#30005;&#36335;&#65306;&#35299;&#38145;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Fourier Circuits in Neural Networks: Unlocking the Potential of Large Language Models in Mathematical Reasoning and Modular Arithmetic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#19981;&#26029;&#21457;&#23637;&#30340;&#32972;&#26223;&#19979;&#65292;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#25152;&#21033;&#29992;&#30340;&#20869;&#37096;&#34920;&#31034;&#26159;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#22312;&#36817;&#26399;&#30340;&#30740;&#31350;&#22522;&#30784;&#19978;&#65292;&#23545;&#32593;&#32476;&#37319;&#29992;&#29305;&#23450;&#35745;&#31639;&#31574;&#30053;&#32972;&#21518;&#30340;&#21407;&#22240;&#36827;&#34892;&#20102;&#25506;&#32034;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#28041;&#21450;k&#20010;&#36755;&#20837;&#30340;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#65292;&#21363;&#27169;&#36816;&#31639;&#30340;&#21152;&#27861;&#12290;&#25105;&#20204;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#36825;&#19968;&#20219;&#21153;&#20013;&#23398;&#21040;&#30340;&#29305;&#24449;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#29702;&#35770;&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#26159;&#38416;&#26126;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#30340;&#29305;&#24449;&#30340;&#24433;&#21709;&#12290;&#20854;&#20013;&#65292;p&#34920;&#31034;&#27169;&#25968;&#65292;Dp&#34920;&#31034;k&#20010;&#36755;&#20837;&#30340;&#27169;&#36816;&#31639;&#25968;&#25454;&#38598;&#65292;m&#34920;&#31034;&#32593;&#32476;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09469v1 Announce Type: new  Abstract: In the evolving landscape of machine learning, a pivotal challenge lies in deciphering the internal representations harnessed by neural networks and Transformers. Building on recent progress toward comprehending how networks execute distinct target functions, our study embarks on an exploration of the underlying reasons behind networks adopting specific computational strategies. We direct our focus to the complex algebraic learning task of modular addition involving $k$ inputs. Our research presents a thorough analytical characterization of the features learned by stylized one-hidden layer neural networks and one-layer Transformers in addressing this task.   A cornerstone of our theoretical framework is the elucidation of how the principle of margin maximization shapes the features adopted by one-hidden layer neural networks. Let $p$ denote the modulus, $D_p$ denote the dataset of modular arithmetic with $k$ inputs and $m$ denote the net
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21457;&#29616;&#65292;&#22312;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#26410;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#21462;&#20915;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36951;&#20256;&#31639;&#27861;&#65292;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.05835</link><description>&lt;p&gt;
&#19981;&#21487;&#35265;&#25968;&#25454;&#21462;&#20915;&#20110;&#24050;&#30693;&#20449;&#24687;&#30340;&#22810;&#23569;
&lt;/p&gt;
&lt;p&gt;
How Much is Unseen Depends Chiefly on Information About the Seen
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05835
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21457;&#29616;&#65292;&#22312;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#26410;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#21462;&#20915;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36951;&#20256;&#31639;&#27861;&#65292;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20045;&#19968;&#30475;&#21487;&#33021;&#26377;&#20123;&#36829;&#21453;&#30452;&#35273;&#65306;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#39044;&#26399;&#20013;&#65292;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#27809;&#26377;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#30001;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;$f_k$&#30830;&#23450;&#12290;&#34429;&#28982;&#22312;&#29702;&#35770;&#19978;&#25105;&#20204;&#35777;&#26126;&#20102;&#30001;&#35813;&#20272;&#35745;&#37327;&#24341;&#36215;&#30340;&#20559;&#24046;&#22312;&#26679;&#26412;&#22823;&#23567;&#25351;&#25968;&#32423;&#34928;&#20943;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#39640;&#26041;&#24046;&#38459;&#27490;&#25105;&#20204;&#30452;&#25509;&#20351;&#29992;&#23427;&#20316;&#20026;&#26679;&#26412;&#35206;&#30422;&#20272;&#35745;&#37327;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#23545;$f_k$&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#36827;&#34892;&#20102;&#31934;&#30830;&#30340;&#25551;&#36848;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#22810;&#20010;&#19981;&#21516;&#26399;&#26395;&#20540;&#34920;&#31034;&#30340;&#25628;&#32034;&#31354;&#38388;&#65292;&#21487;&#20197;&#30830;&#23450;&#22320;&#23454;&#20363;&#21270;&#20026;&#20272;&#35745;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36716;&#21521;&#20248;&#21270;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#36951;&#20256;&#31639;&#27861;&#65292;&#20165;&#26681;&#25454;&#26679;&#26412;&#25628;&#32034;&#24179;&#22343;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#26368;&#23567;&#30340;&#20272;&#35745;&#37327;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#36951;&#20256;&#31639;&#27861;&#21457;&#29616;&#20102;&#20855;&#26377;&#26126;&#26174;&#36739;&#23567;&#26041;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
It might seem counter-intuitive at first: We find that, in expectation, the proportion of data points in an unknown population-that belong to classes that do not appear in the training data-is almost entirely determined by the number $f_k$ of classes that do appear in the training data the same number of times. While in theory we show that the difference of the induced estimator decays exponentially in the size of the sample, in practice the high variance prevents us from using it directly for an estimator of the sample coverage. However, our precise characterization of the dependency between $f_k$'s induces a large search space of different representations of the expected value, which can be deterministically instantiated as estimators. Hence, we turn to optimization and develop a genetic algorithm that, given only the sample, searches for an estimator with minimal mean-squared error (MSE). In our experiments, our genetic algorithm discovers estimators that have a substantially smalle
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;Hessian&#30697;&#38453;&#36870;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;Robbins-Monro&#36807;&#31243;&#65292;&#33021;&#22815; drastical reducescomputational complexity,&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#65292;&#30740;&#31350;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36827;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.10923</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#36890;&#29992;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#24212;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;Hessian&#30697;&#38453;&#30340;&#36870;&#30340;&#22312;&#32447;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Online estimation of the inverse of the Hessian for stochastic optimization with application to universal stochastic Newton algorithms. (arXiv:2401.10923v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10923
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;Hessian&#30697;&#38453;&#36870;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;Robbins-Monro&#36807;&#31243;&#65292;&#33021;&#22815; drastical reducescomputational complexity,&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#65292;&#30740;&#31350;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36827;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20197;&#26399;&#26395;&#24418;&#24335;&#34920;&#31034;&#30340;&#20984;&#20989;&#25968;&#30340;&#27425;&#20248;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#36882;&#24402;&#20272;&#35745;&#36870;Hessian&#30697;&#38453;&#30340;&#25216;&#26415;&#65292;&#37319;&#29992;&#20102;Robbins-Monro&#36807;&#31243;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22823;&#24133;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#20801;&#35768;&#24320;&#21457;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36817;&#25928;&#29575;&#12290;&#36825;&#39033;&#24037;&#20316;&#25193;&#23637;&#20102;&#22312;&#38543;&#26426;&#20248;&#21270;&#20013;&#20108;&#38454;&#31639;&#27861;&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses second-order stochastic optimization for estimating the minimizer of a convex function written as an expectation. A direct recursive estimation technique for the inverse Hessian matrix using a Robbins-Monro procedure is introduced. This approach enables to drastically reduces computational complexity. Above all, it allows to develop universal stochastic Newton methods and investigate the asymptotic efficiency of the proposed approach. This work so expands the application scope of secondorder algorithms in stochastic optimization.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#65292;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#39564;&#35777;&#65292;&#37327;&#21270;&#20102;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#32467;&#26524;&#34920;&#26126;PnP-ULA&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#12290;</title><link>http://arxiv.org/abs/2310.03546</link><description>&lt;p&gt;
&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#22312;&#19981;&#21305;&#37197;&#27979;&#37327;&#21644;&#20808;&#39564;&#27169;&#22411;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03546
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#65292;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#39564;&#35777;&#65292;&#37327;&#21270;&#20102;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#32467;&#26524;&#34920;&#26126;PnP-ULA&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#24050;&#34987;&#35777;&#26126;&#26159;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#24378;&#22823;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#26368;&#36817;&#21457;&#23637;&#36215;&#26469;&#30340;&#25554;&#25300;&#24335;&#26410;&#35843;&#25972;&#26391;&#20043;&#19975;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#20351;&#29992;&#22270;&#20687;&#21435;&#22122;&#22120;&#25351;&#23450;&#30340;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#65288;MMSE&#65289;&#20272;&#35745;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;PnP-ULA&#30340;&#37319;&#26679;&#20998;&#24067;&#19982;&#19981;&#21305;&#37197;&#30340;&#25968;&#25454;&#20445;&#30495;&#24230;&#21644;&#21435;&#22122;&#22120;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#23578;&#26410;&#32463;&#36807;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#21518;&#39564;-L2&#25311;&#24230;&#37327;&#24182;&#21033;&#29992;&#23427;&#26469;&#37327;&#21270;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#30340;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#36870;&#38382;&#39064;&#19978;&#23545;&#25105;&#20204;&#30340;&#29702;&#35770;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#65292;&#22914;&#20174;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#22270;&#20687;&#21435;&#27169;&#31946;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;PnP-ULA&#30340;&#37319;&#26679;&#20998;&#24067;&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#65292;&#24182;&#21487;&#20197;&#31934;&#30830;&#22320;&#25551;&#36848;&#20854;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Posterior sampling has been shown to be a powerful Bayesian approach for solving imaging inverse problems. The recent plug-and-play unadjusted Langevin algorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling and minimum mean squared error (MMSE) estimation by combining physical measurement models with deep-learning priors specified using image denoisers. However, the intricate relationship between the sampling distribution of PnP-ULA and the mismatched data-fidelity and denoiser has not been theoretically analyzed. We address this gap by proposing a posterior-L2 pseudometric and using it to quantify an explicit error bound for PnP-ULA under mismatched posterior distribution. We numerically validate our theory on several inverse problems such as sampling from Gaussian mixture models and image deblurring. Our results suggest that the sensitivity of the sampling distribution of PnP-ULA to a mismatch in the measurement model and the denoiser can be precisely characte
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;</title><link>http://arxiv.org/abs/2305.05792</link><description>&lt;p&gt;
&#36807;&#25311;&#21512;&#30340;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Testing for Overfitting. (arXiv:2305.05792v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05792
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#39640;&#22797;&#26434;&#24230;&#30340;&#27169;&#22411;&#24120;&#35265;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#21363;&#27169;&#22411;&#33021;&#22815;&#24456;&#22909;&#22320;&#20195;&#34920;&#25968;&#25454;&#65292;&#20294;&#26080;&#27861;&#25512;&#24191;&#21040;&#22522;&#30784;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#12290;&#35299;&#20915;&#36807;&#25311;&#21512;&#30340;&#20856;&#22411;&#26041;&#27861;&#26159;&#22312;&#30041;&#32622;&#38598;&#19978;&#35745;&#31639;&#32463;&#39564;&#39118;&#38505;&#65292;&#19968;&#26086;&#39118;&#38505;&#24320;&#22987;&#22686;&#21152;&#65292;&#23601;&#20572;&#27490;&#65288;&#25110;&#26631;&#35760;&#20309;&#26102;&#20572;&#27490;&#65289;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#36755;&#20986;&#20102;&#33391;&#22909;&#27867;&#21270;&#30340;&#27169;&#22411;&#65292;&#20294;&#20854;&#23454;&#29616;&#21407;&#29702;&#20027;&#35201;&#26159;&#21551;&#21457;&#24335;&#30340;&#12290;&#26412;&#25991;&#35752;&#35770;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;&#26631;&#20934;&#28176;&#36817;&#21644;&#27987;&#24230;&#32467;&#26524;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20986;&#24182;&#38416;&#36848;&#20102;&#19968;&#20010;&#20551;&#35774;&#26816;&#39564;&#65292;&#36890;&#36807;&#35813;&#26816;&#39564;&#21487;&#20197;&#23545;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#37327;&#21270;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;&#25105;&#20204;&#20381;&#38752;&#30830;&#20445;&#32463;&#39564;&#22343;&#20540;&#24212;&#35813;&#39640;&#27010;&#29575;&#22320;&#36817;&#20284;&#20854;&#30495;&#23454;&#22343;&#20540;&#30340;&#27987;&#24230;&#30028;&#38480;&#65292;&#20197;&#24471;&#20986;&#20182;&#20204;&#24212;&#35813;&#30456;&#20114;&#25509;&#36817;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
High complexity models are notorious in machine learning for overfitting, a phenomenon in which models well represent data but fail to generalize an underlying data generating process. A typical procedure for circumventing overfitting computes empirical risk on a holdout set and halts once (or flags that/when) it begins to increase. Such practice often helps in outputting a well-generalizing model, but justification for why it works is primarily heuristic.  We discuss the overfitting problem and explain why standard asymptotic and concentration results do not hold for evaluation with training data. We then proceed to introduce and argue for a hypothesis test by means of which both model performance may be evaluated using training data, and overfitting quantitatively defined and detected. We rely on said concentration bounds which guarantee that empirical means should, with high probability, approximate their true mean to conclude that they should approximate each other. We stipulate co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#21457;&#29616;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#22312;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2303.00055</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#26102;&#38388;&#23610;&#24230;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Learning time-scales in two-layers neural networks. (arXiv:2303.00055v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#21457;&#29616;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#22312;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20855;&#26377;&#22810;&#20010;&#24341;&#20154;&#27880;&#24847;&#30340;&#29305;&#28857;&#12290;&#23588;&#20854;&#26159;&#65292;&#22312;&#22823;&#25209;&#37327;&#25968;&#25454;&#24179;&#22343;&#21518;&#65292;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#20960;&#20046;&#27809;&#26377;&#36827;&#23637;&#30340;&#38271;&#21608;&#26399;&#21644;&#24555;&#36895;&#19979;&#38477;&#30340;&#38388;&#38548;&#20132;&#26367;&#20986;&#29616;&#12290;&#36825;&#20123;&#36830;&#32493;&#30340;&#23398;&#20064;&#38454;&#27573;&#24448;&#24448;&#22312;&#38750;&#24120;&#19981;&#21516;&#30340;&#26102;&#38388;&#23610;&#24230;&#19978;&#36827;&#34892;&#12290;&#26368;&#21518;&#65292;&#22312;&#26089;&#26399;&#38454;&#27573;&#23398;&#20064;&#30340;&#27169;&#22411;&#36890;&#24120;&#26159;&#8220;&#31616;&#21333;&#30340;&#8221;&#25110;&#8220;&#26131;&#20110;&#23398;&#20064;&#30340;&#8221;&#65292;&#23613;&#31649;&#20197;&#38590;&#20197;&#24418;&#24335;&#21270;&#30340;&#26041;&#24335;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#65292;&#22312;&#19968;&#31995;&#21015;&#26032;&#30340;&#20005;&#23494;&#32467;&#26524;&#12289;&#38750;&#20005;&#23494;&#25968;&#23398;&#25512;&#23548;&#21644;&#25968;&#20540;&#23454;&#39564;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#29305;&#21035;&#25351;&#20986;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#19982;&#38271;&#21608;&#26399;&#30340;&#20986;&#29616;&#21644;&#28040;&#22833;&#26377;&#20851;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#21487;&#20197;&#29992;&#20110;&#35268;&#33539;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-based learning in multi-layer neural networks displays a number of striking features. In particular, the decrease rate of empirical risk is non-monotone even after averaging over large batches. Long plateaus in which one observes barely any progress alternate with intervals of rapid decrease. These successive phases of learning often take place on very different time scales. Finally, models learnt in an early phase are typically `simpler' or `easier to learn' although in a way that is difficult to formalize.  Although theoretical explanations of these phenomena have been put forward, each of them captures at best certain specific regimes. In this paper, we study the gradient flow dynamics of a wide two-layer neural network in high-dimension, when data are distributed according to a single-index model (i.e., the target function depends on a one-dimensional projection of the covariates). Based on a mixture of new rigorous results, non-rigorous mathematical derivations, and numer
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22810;&#31181;&#24120;&#29992;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#23427;&#20204;&#20351;&#29992;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#31574;&#30053;&#24322;&#21516;&#65292;&#24182;&#30740;&#31350;&#20102;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2204.10969</link><description>&lt;p&gt;
&#24403;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#36935;&#21040;&#26426;&#22120;&#23398;&#20064;&#65306;&#29992;&#20110;&#20174;&#23454;&#38469;&#25968;&#25454;&#20013;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
When Doubly Robust Methods Meet Machine Learning for Estimating Treatment Effects from Real-World Data: A Comparative Study. (arXiv:2204.10969v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22810;&#31181;&#24120;&#29992;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#23427;&#20204;&#20351;&#29992;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#31574;&#30053;&#24322;&#21516;&#65292;&#24182;&#30740;&#31350;&#20102;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35266;&#23519;&#24615;&#38431;&#21015;&#30740;&#31350;&#36234;&#26469;&#36234;&#24120;&#29992;&#20110;&#27604;&#36739;&#25928;&#26524;&#30740;&#31350;&#65292;&#20197;&#35780;&#20272;&#27835;&#30103;&#26041;&#27861;&#30340;&#23433;&#20840;&#24615;&#12290;&#26368;&#36817;&#65292;&#21508;&#31181;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#24050;&#34987;&#25552;&#20986;&#65292;&#36890;&#36807;&#21305;&#37197;&#12289;&#21152;&#26435;&#21644;&#22238;&#24402;&#31561;&#19981;&#21516;&#26041;&#24335;&#65292;&#36890;&#36807;&#32452;&#21512;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#26469;&#20272;&#35745;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#12290;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#30340;&#20851;&#38190;&#20248;&#21183;&#22312;&#20110;&#65292;&#23427;&#20204;&#35201;&#27714;&#27835;&#30103;&#27169;&#22411;&#25110;&#32467;&#26524;&#27169;&#22411;&#20043;&#19968;&#34987;&#27491;&#30830;&#35268;&#23450;&#65292;&#20197;&#33719;&#24471;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33268;&#20272;&#35745;&#20540;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#20934;&#30830;&#12289;&#36890;&#24120;&#26356;&#31934;&#30830;&#30340;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#24037;&#20316;&#21435;&#29702;&#35299;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#30001;&#20110;&#20351;&#29992;&#27835;&#30103;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#29420;&#29305;&#31574;&#30053;&#22914;&#20309;&#19981;&#21516;&#20197;&#21450;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#26816;&#26597;&#20102;&#22810;&#20010;&#21463;&#27426;&#36814;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#19981;&#21516;&#30340;&#27835;&#30103;&#21644;&#32467;&#26524;&#27169;&#22411;&#27604;&#36739;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Observational cohort studies are increasingly being used for comparative effectiveness research to assess the safety of therapeutics. Recently, various doubly robust methods have been proposed for average treatment effect estimation by combining the treatment model and the outcome model via different vehicles, such as matching, weighting, and regression. The key advantage of doubly robust estimators is that they require either the treatment model or the outcome model to be correctly specified to obtain a consistent estimator of average treatment effects, and therefore lead to a more accurate and often more precise inference. However, little work has been done to understand how doubly robust estimators differ due to their unique strategies of using the treatment and outcome models and how machine learning techniques can be combined to boost their performance. Here we examine multiple popular doubly robust methods and compare their performance using different treatment and outcome modeli
&lt;/p&gt;</description></item></channel></rss>