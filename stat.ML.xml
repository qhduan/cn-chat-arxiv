<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#36890;&#36807;&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#65292;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#21644;&#29420;&#31435;&#27714;&#35299;&#33021;&#21147;&#12290;</title><link>https://rss.arxiv.org/abs/2212.00133</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#21021;&#22987;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Learning of Sinkhorn Algorithm Initializations
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2212.00133
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#65292;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#21644;&#29420;&#31435;&#27714;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sinkhorn&#31639;&#27861;&#26159;&#36817;&#20284;&#27714;&#35299;&#31163;&#25955;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#29109;&#27491;&#21017;&#36755;&#36816;&#65288;OT&#65289;&#36317;&#31163;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;&#31639;&#27861;&#21021;&#22987;&#21270;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;Sinkhorn&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#24335;&#20351;&#29992;&#31532;&#20108;&#20010;&#29983;&#25104;&#32593;&#32476;&#21644;&#33258;&#30417;&#30563;&#24341;&#23548;&#25439;&#22833;&#26469;&#35757;&#32451;&#25105;&#20204;&#30340;&#39044;&#27979;&#32593;&#32476;&#12290;&#39044;&#27979;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#33021;&#22815;&#25512;&#24191;&#21040;&#20219;&#24847;&#22266;&#23450;&#32500;&#24230;&#21644;&#25104;&#26412;&#30340;&#27010;&#29575;&#20998;&#24067;&#23545;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#29983;&#25104;&#32593;&#32476;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20135;&#29983;&#20219;&#24847;&#27010;&#29575;&#20998;&#24067;&#23545;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32593;&#32476;&#21487;&#20197;&#20316;&#20026;&#29420;&#31435;&#30340;OT&#27714;&#35299;&#22120;&#26469;&#36817;&#20284;&#27491;&#21017;&#21270;&#36755;&#36816;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sinkhorn algorithm is the state-of-the-art to approximate solutions of entropic optimal transport (OT) distances between discrete probability distributions. We show that meticulously training a neural network to learn initializations to the algorithm via the entropic OT dual problem can significantly speed up convergence, while maintaining desirable properties of the Sinkhorn algorithm, such as differentiability and parallelizability. We train our predictive network in an adversarial fashion using a second, generating network and a self-supervised bootstrapping loss. The predictive network is universal in the sense that it is able to generalize to any pair of distributions of fixed dimension and cost at inference, and we prove that we can make the generating network universal in the sense that it is capable of producing any pair of distributions during training. Furthermore, we show that our network can even be used as a standalone OT solver to approximate regularized transport dis
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.10763</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#26356;&#24555;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#30340;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Primal-Dual Algorithm for Faster Distributionally Robust Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10763
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24102;&#26377;&#38381;&#21512;&#12289;&#20984;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#24809;&#32602;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#65292;&#36825;&#20010;&#35774;&#32622;&#21253;&#25324;&#20102;&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;$f$-DRO&#12289;Wasserstein-DRO&#21644;&#35889;/$L$-&#39118;&#38505;&#20844;&#24335;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Drago&#65292;&#19968;&#31181;&#38543;&#26426;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#65292;&#22312;&#24378;&#20984;-&#24378;&#20985;DRO&#38382;&#39064;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;&#35813;&#26041;&#27861;&#23558;&#38543;&#26426;&#21270;&#21644;&#24490;&#29615;&#32452;&#20214;&#19982;&#23567;&#25209;&#37327;&#32467;&#21512;&#65292;&#26377;&#25928;&#22788;&#29702;&#20102;DRO&#20013;&#21407;&#22987;&#21644;&#23545;&#20598;&#38382;&#39064;&#30340;&#29420;&#29305;&#19981;&#23545;&#31216;&#24615;&#36136;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#31867;&#21644;&#22238;&#24402;&#20013;&#30340;&#25968;&#20540;&#22522;&#20934;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10763v1 Announce Type: cross  Abstract: We consider the penalized distributionally robust optimization (DRO) problem with a closed, convex uncertainty set, a setting that encompasses the $f$-DRO, Wasserstein-DRO, and spectral/$L$-risk formulations used in practice. We present Drago, a stochastic primal-dual algorithm that achieves a state-of-the-art linear convergence rate on strongly convex-strongly concave DRO problems. The method combines both randomized and cyclic components with mini-batching, which effectively handles the unique asymmetric nature of the primal and dual problems in DRO. We support our theoretical results with numerical benchmarks in classification and regression.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#20013;&#20943;&#23569;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#20195;&#20215;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09401</link><description>&lt;p&gt;
&#20351;&#29992;&#20027;&#21160;&#26597;&#35810;&#30340;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback with Active Queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#20013;&#20943;&#23569;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#20195;&#20215;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#23545;&#40784;&#65292;&#22312;&#26500;&#24314;&#29616;&#20195;&#29983;&#25104;&#27169;&#22411;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#24403;&#21069;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#20294;&#24448;&#24448;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#65292;&#32780;&#36825;&#31181;&#25968;&#25454;&#25910;&#38598;&#36153;&#26102;&#36153;&#21147;&#12290;&#26412;&#25991;&#21463;&#21040;&#20027;&#21160;&#23398;&#20064;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#36890;&#36807;&#25552;&#20986;&#26597;&#35810;&#25928;&#29575;&#39640;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#23545;&#40784;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#19978;&#19979;&#25991;&#31454;&#20105;&#20108;&#33218;&#24378;&#30423;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;APPO&#65289;&#31639;&#27861;&#65292;&#20855;&#26377;$\tilde{O}(d^2/\Delta)$&#30340;&#36951;&#25022;&#30028;&#21644;$\tilde{O}(d^2/\Delta^2)$&#30340;&#26597;&#35810;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;$d$&#26159;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#24230;&#65292;$\Delta$&#26159;&#25152;&#26377;&#19978;&#19979;&#25991;&#20013;&#30340;&#27425;&#20248;&#24046;&#36317;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ADPO&#65292;&#36825;&#26159;&#25105;&#20204;&#31639;&#27861;&#30340;&#23454;&#38469;&#29256;&#26412;&#65292;&#22522;&#20110;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09401v1 Announce Type: cross Abstract: Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32467;&#21512;&#20102;PAC-Bayes&#24037;&#20855;&#31665;&#21644;Poincar&#233;&#19982;Log-Sobolev&#19981;&#31561;&#24335;&#65292;&#25552;&#20379;&#20102;&#26032;&#30340;&#26799;&#24230;&#39033;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#31361;&#20986;&#20102;&#24179;&#22374;&#26368;&#23567;&#20540;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.08508</link><description>&lt;p&gt;
&#24191;&#20041;&#21644;&#24179;&#22343;&#23481;&#37327;&#20043;&#38388;&#30340;PAC-Bayes&#32852;&#32467;
&lt;/p&gt;
&lt;p&gt;
A PAC-Bayesian Link Between Generalisation and Flat Minima
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32467;&#21512;&#20102;PAC-Bayes&#24037;&#20855;&#31665;&#21644;Poincar&#233;&#19982;Log-Sobolev&#19981;&#31561;&#24335;&#65292;&#25552;&#20379;&#20102;&#26032;&#30340;&#26799;&#24230;&#39033;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#31361;&#20986;&#20102;&#24179;&#22374;&#26368;&#23567;&#20540;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#36890;&#24120;&#20351;&#29992;&#36229;&#21442;&#25968;&#35774;&#32622;&#65288;&#35757;&#32451;&#21442;&#25968;&#25968;&#37327;&#22823;&#20110;&#25968;&#25454;&#38598;&#22823;&#23567;&#65289;&#20013;&#30340;&#39044;&#27979;&#22120;&#65292;&#23427;&#20204;&#30340;&#35757;&#32451;&#19981;&#20165;&#20135;&#29983;&#33391;&#22909;&#30340;&#35757;&#32451;&#25968;&#25454;&#24615;&#33021;&#65292;&#32780;&#19988;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#36825;&#19968;&#29616;&#35937;&#25361;&#25112;&#20102;&#35768;&#22810;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#19988;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#28041;&#21450;&#26799;&#24230;&#39033;&#30340;&#26032;&#22411;&#27867;&#21270;&#30028;&#38480;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;PAC-Bayes&#24037;&#20855;&#31665;&#19982;Poincar&#233;&#21644;Log-Sobolev&#19981;&#31561;&#24335;&#30456;&#32467;&#21512;&#65292;&#36991;&#20813;&#20102;&#23545;&#39044;&#27979;&#22120;&#31354;&#38388;&#32500;&#25968;&#30340;&#26174;&#24335;&#20381;&#36182;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31361;&#20986;&#20102;&#8220;&#24179;&#22374;&#26368;&#23567;&#20540;&#8221;&#65288;&#20960;&#20046;&#33021;&#22815;&#26368;&#23567;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37051;&#36817;&#26368;&#23567;&#20540;&#65289;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#65292;&#30452;&#25509;&#28041;&#21450;&#21040;&#20248;&#21270;&#38454;&#27573;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning usually involves predictors in the overparametrised setting (number of trained parameters greater than dataset size), and their training yield not only good performances on training data, but also good generalisation capacity. This phenomenon challenges many theoretical results, and remains an open problem. To reach a better understanding, we provide novel generalisation bounds involving gradient terms. To do so, we combine the PAC-Bayes toolbox with Poincar\'e and Log-Sobolev inequalities, avoiding an explicit dependency on dimension of the predictor space. Our results highlight the positive influence of \emph{flat minima} (being minima with a neighbourhood nearly minimising the learning problem as well) on generalisation performances, involving directly the benefits of the optimisation phase.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.05642</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A duality framework for generalization analysis of random feature models and two-layer neural networks. (arXiv:2305.05642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#39640;&#32500;&#20998;&#26512;&#20013;&#20986;&#29616;&#30340;&#33258;&#28982;&#20989;&#25968;&#31354;&#38388; $\mathcal{F}_{p,\pi}$ &#21644; Barron &#31354;&#38388;&#20013;&#23398;&#20064;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23545;&#20598;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20123;&#31354;&#38388;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#21487;&#20197;&#22312;&#26576;&#31181;&#24847;&#20041;&#19979;&#34987;&#35270;&#20026;&#31561;&#20215;&#30340;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#22312;&#30740;&#31350;&#36825;&#20004;&#31181;&#27169;&#22411;&#30340;&#27867;&#21270;&#26102;&#26356;&#19987;&#27880;&#20110;&#26356;&#23481;&#26131;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#30340;&#22797;&#26434;&#24230;&#26469;&#26377;&#25928;&#22320;&#25511;&#21046;&#20272;&#35745;&#35823;&#24046;&#65292;&#24314;&#31435;&#20102;&#23545;&#20598;&#31561;&#20215;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#20004;&#20010;&#20855;&#20307;&#24212;&#29992;&#36827;&#34892;&#32508;&#21512;&#20998;&#26512;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#12290;&#31532;&#19968;&#20010;&#24212;&#29992;&#26159;&#30740;&#31350;&#20351;&#29992; RFMs &#23398;&#20064; $\mathcal{F}_{p,\pi}$ &#20013;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#21482;&#35201; $p&gt;1$&#65292;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#36825;&#24847;&#21619;&#30528; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning functions in the $\mathcal{F}_{p,\pi}$ and Barron spaces, which are natural function spaces that arise in the high-dimensional analysis of random feature models (RFMs) and two-layer neural networks. Through a duality analysis, we reveal that the approximation and estimation of these spaces can be considered equivalent in a certain sense. This enables us to focus on the easier problem of approximation and estimation when studying the generalization of both models. The dual equivalence is established by defining an information-based complexity that can effectively control estimation errors. Additionally, we demonstrate the flexibility of our duality framework through comprehensive analyses of two concrete applications.  The first application is to study learning functions in $\mathcal{F}_{p,\pi}$ with RFMs. We prove that the learning does not suffer from the curse of dimensionality as long as $p&gt;1$, implying RFMs can work beyond the kernel regime. Our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#19988;&#26080;&#38656;&#38543;&#26426;&#21270;&#12290;</title><link>http://arxiv.org/abs/2209.02525</link><description>&lt;p&gt;
&#22522;&#20110;&#30830;&#23450;&#24615;PAC-Bayes&#30340;&#26799;&#24230;&#19979;&#38477;&#19979;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalisation under gradient descent via deterministic PAC-Bayes. (arXiv:2209.02525v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02525
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#19988;&#26080;&#38656;&#38543;&#26426;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#24314;&#31435;&#20102;&#32454;&#20998;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#12290;&#19982;PAC-Bayes&#35774;&#23450;&#20013;&#30340;&#26631;&#20934;&#20570;&#27861;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#30830;&#23450;&#24615;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#21435;&#38543;&#26426;&#21270;&#30340;&#27493;&#39588;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#23436;&#20840;&#21487;&#35745;&#31639;&#30340;&#65292;&#21462;&#20915;&#20110;&#21021;&#22987;&#20998;&#24067;&#30340;&#23494;&#24230;&#21644;&#36712;&#36857;&#19978;&#35757;&#32451;&#30446;&#26631;&#30340;&#28023;&#26862;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#12289;&#21160;&#37327;&#31639;&#27861;&#21644;&#38459;&#23612;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish disintegrated PAC-Bayesian generalisation bounds for models trained with gradient descent methods or continuous gradient flows. Contrary to standard practice in the PAC-Bayesian setting, our result applies to optimisation algorithms that are deterministic, without requiring any de-randomisation step. Our bounds are fully computable, depending on the density of the initial distribution and the Hessian of the training objective over the trajectory. We show that our framework can be applied to a variety of iterative optimisation algorithms, including stochastic gradient descent (SGD), momentum-based schemes, and damped Hamiltonian dynamics.
&lt;/p&gt;</description></item></channel></rss>