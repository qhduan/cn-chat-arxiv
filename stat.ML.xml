<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32852;&#21512;&#19978;&#28216;&#21644;&#19979;&#28216;&#27169;&#22411;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#19968;&#27493;&#31574;&#30053;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#20559;&#35823;&#65292;&#22312;CEO&#26102;&#38388;&#21033;&#29992;&#25968;&#25454;&#30340;&#24212;&#29992;&#20013;&#20135;&#29983;&#20102;&#37325;&#35201;&#25928;&#26524;&#65292;&#36866;&#21512;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#12290;</title><link>https://arxiv.org/abs/2402.15585</link><description>&lt;p&gt;
&#20351;&#29992;&#26469;&#33258;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#29983;&#25104;&#30340;&#21464;&#37327;&#36827;&#34892;&#22238;&#24402;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference for Regression with Variables Generated from Unstructured Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15585
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32852;&#21512;&#19978;&#28216;&#21644;&#19979;&#28216;&#27169;&#22411;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#19968;&#27493;&#31574;&#30053;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#20559;&#35823;&#65292;&#22312;CEO&#26102;&#38388;&#21033;&#29992;&#25968;&#25454;&#30340;&#24212;&#29992;&#20013;&#20135;&#29983;&#20102;&#37325;&#35201;&#25928;&#26524;&#65292;&#36866;&#21512;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#20027;&#35201;&#31574;&#30053;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;&#19978;&#28216;&#20449;&#24687;&#26816;&#32034;&#27169;&#22411;&#20272;&#35745;&#24863;&#20852;&#36259;&#30340;&#28508;&#22312;&#32463;&#27982;&#21464;&#37327;&#12290;&#20854;&#27425;&#65292;&#23558;&#20272;&#35745;&#20540;&#35270;&#20026;&#19979;&#28216;&#35745;&#37327;&#32463;&#27982;&#27169;&#22411;&#20013;&#30340;&#8220;&#25968;&#25454;&#8221;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#29702;&#35770;&#35770;&#28857;&#65292;&#35299;&#37322;&#20026;&#20160;&#20040;&#22312;&#23454;&#35777;&#21512;&#29702;&#30340;&#35774;&#32622;&#20013;&#65292;&#36825;&#31181;&#20004;&#27493;&#31574;&#30053;&#20250;&#23548;&#33268;&#20559;&#35823;&#30340;&#25512;&#26029;&#12290;&#26356;&#20855;&#24314;&#35774;&#24615;&#30340;&#26159;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#25512;&#26029;&#30340;&#19968;&#27493;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21516;&#26102;&#20351;&#29992;&#19978;&#28216;&#21644;&#19979;&#28216;&#27169;&#22411;&#12290;&#22312;&#27169;&#25311;&#20013;&#65292;&#36825;&#19968;&#27493;&#31574;&#30053;(i) &#26174;&#33879;&#20943;&#23569;&#20102;&#20559;&#35823;&#65307;(ii) &#22312;&#20351;&#29992;CEO&#26102;&#38388;&#21033;&#29992;&#25968;&#25454;&#30340;&#20027;&#35201;&#24212;&#29992;&#20013;&#20135;&#29983;&#20102;&#23450;&#37327;&#37325;&#35201;&#30340;&#25928;&#26524;&#65307;(iii) &#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#34987;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#37319;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15585v1 Announce Type: new  Abstract: The leading strategy for analyzing unstructured data uses two steps. First, latent variables of economic interest are estimated with an upstream information retrieval model. Second, the estimates are treated as "data" in a downstream econometric model. We establish theoretical arguments for why this two-step strategy leads to biased inference in empirically plausible settings. More constructively, we propose a one-step strategy for valid inference that uses the upstream and downstream models jointly. The one-step strategy (i) substantially reduces bias in simulations; (ii) has quantitatively important effects in a leading application using CEO time-use data; and (iii) can be readily adapted by applied researchers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26356;&#26032;&#20013;&#30340;&#36951;&#24536;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#19978;&#28216;&#23454;&#20363;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;&#26681;&#25454;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#21464;&#21270;&#19982;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#30456;&#20284;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.01865</link><description>&lt;p&gt;
&#25105;&#30340;&#27169;&#22411;&#20250;&#24536;&#35760;&#20160;&#20040;&#65311;&#35821;&#35328;&#27169;&#22411;&#25913;&#36827;&#20013;&#30340;&#34987;&#36951;&#24536;&#23454;&#20363;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26356;&#26032;&#20013;&#30340;&#36951;&#24536;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#19978;&#28216;&#23454;&#20363;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;&#26681;&#25454;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#21464;&#21270;&#19982;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#30456;&#20284;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#35821;&#35328;&#27169;&#22411;&#20250;&#20986;&#29616;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#20165;&#20165;&#36890;&#36807;&#23558;&#27169;&#22411;&#26356;&#26032;&#20026;&#32416;&#27491;&#38169;&#35823;&#23454;&#20363;&#65292;&#20250;&#23548;&#33268;&#28798;&#38590;&#24615;&#30340;&#36951;&#24536;&#65292;&#26356;&#26032;&#21518;&#30340;&#27169;&#22411;&#22312;&#25351;&#23548;&#24494;&#35843;&#25110;&#19978;&#28216;&#35757;&#32451;&#38454;&#27573;&#20013;&#23398;&#21040;&#30340;&#23454;&#20363;&#19978;&#20986;&#29616;&#38169;&#35823;&#12290;&#38543;&#26426;&#37325;&#25773;&#19978;&#28216;&#25968;&#25454;&#30340;&#25928;&#26524;&#19981;&#20196;&#20154;&#28385;&#24847;&#65292;&#24448;&#24448;&#20276;&#38543;&#30528;&#36739;&#39640;&#30340;&#26041;&#24046;&#21644;&#36739;&#24046;&#30340;&#21487;&#25511;&#24615;&#12290;&#20026;&#20102;&#25913;&#21892;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#35797;&#22270;&#39044;&#27979;&#30001;&#20110;&#27169;&#22411;&#26356;&#26032;&#32780;&#36951;&#24536;&#30340;&#19978;&#28216;&#23454;&#20363;&#12290;&#25105;&#20204;&#26681;&#25454;&#19968;&#32452;&#22312;&#32447;&#23398;&#20064;&#30340;&#23454;&#20363;&#21644;&#30456;&#24212;&#34987;&#36951;&#24536;&#30340;&#19978;&#28216;&#39044;&#35757;&#32451;&#23454;&#20363;&#35757;&#32451;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#36825;&#26679;&#30340;&#35266;&#23519;&#32467;&#26524;&#65306;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#30340;&#21464;&#21270;&#31867;&#20284;&#20110;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#21464;&#21270;&#65292;&#36825;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#19981;&#38169;&#30340;&#25928;&#26524;&#65292;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Language models deployed in the wild make errors. However, simply updating the model with the corrected error instances causes catastrophic forgetting -- the updated model makes errors on instances learned during the instruction tuning or upstream training phase. Randomly replaying upstream data yields unsatisfactory performance and often comes with high variance and poor controllability. To this end, we try to forecast upstream examples that will be forgotten due to a model update for improved controllability of the replay process and interpretability. We train forecasting models given a collection of online learned examples and corresponding forgotten upstream pre-training examples. We propose a partially interpretable forecasting model based on the observation that changes in pre-softmax logit scores of pretraining examples resemble that of online learned examples, which performs decently on BART but fails on T5 models. We further show a black-box classifier based on inner products 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31867;&#20284;ResNet&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#36817;&#20284;Langevin Monte Carlo&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#26469;&#33258;&#31616;&#21333;&#21442;&#32771;&#20998;&#24067;&#30340;&#26679;&#26412;&#26144;&#23556;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#26679;&#26412;&#20013;&#26469;&#36827;&#34892;&#37319;&#26679;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#36924;&#36817;&#36895;&#24230;&#21644;&#34920;&#36798;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.03242</link><description>&lt;p&gt;
&#20351;&#29992;&#31867;&#20284;ResNet&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#36817;&#20284;Langevin Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures. (arXiv:2311.03242v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.03242
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31867;&#20284;ResNet&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#36817;&#20284;Langevin Monte Carlo&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#26469;&#33258;&#31616;&#21333;&#21442;&#32771;&#20998;&#24067;&#30340;&#26679;&#26412;&#26144;&#23556;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#26679;&#26412;&#20013;&#26469;&#36827;&#34892;&#37319;&#26679;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#36924;&#36817;&#36895;&#24230;&#21644;&#34920;&#36798;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#23558;&#26469;&#33258;&#31616;&#21333;&#21442;&#32771;&#20998;&#24067;&#65288;&#22914;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#65289;&#30340;&#26679;&#26412;&#26144;&#23556;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#26679;&#26412;&#20013;&#65292;&#20174;&#32780;&#20174;&#32473;&#23450;&#30340;&#30446;&#26631;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21463;Langevin Monte Carlo (LMC)&#31639;&#27861;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;&#22522;&#20110;LMC&#25200;&#21160;&#32467;&#26524;&#65292;&#22312;Wasserstein-2&#36317;&#31163;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26550;&#26500;&#23545;&#20110;&#24179;&#28369;&#30340;&#23545;&#25968;&#20985;&#30446;&#26631;&#20998;&#24067;&#30340;&#36924;&#36817;&#36895;&#24230;&#12290;&#20998;&#26512;&#20005;&#37325;&#20381;&#36182;&#20110;&#25200;&#21160;LMC&#36807;&#31243;&#30340;&#20013;&#38388;&#24230;&#37327;&#30340;&#20122;&#39640;&#26031;&#24615;&#27010;&#24565;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26681;&#25454;&#19981;&#21516;&#25200;&#21160;&#20551;&#35774;&#25512;&#23548;&#20986;&#20102;&#20013;&#38388;&#26041;&#24046;&#20195;&#29702;&#30340;&#22686;&#38271;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#28145;&#24230;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#36817;&#20284;&#26679;&#26412;&#19982;&#30446;&#26631;&#20998;&#24067;&#26144;&#23556;&#30340;&#34920;&#36798;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We sample from a given target distribution by constructing a neural network which maps samples from a simple reference, e.g. the standard normal distribution, to samples from the target. To that end, we propose using a neural network architecture inspired by the Langevin Monte Carlo (LMC) algorithm. Based on LMC perturbation results, we show approximation rates of the proposed architecture for smooth, log-concave target distributions measured in the Wasserstein-$2$ distance. The analysis heavily relies on the notion of sub-Gaussianity of the intermediate measures of the perturbed LMC process. In particular, we derive bounds on the growth of the intermediate variance proxies under different assumptions on the perturbations. Moreover, we propose an architecture similar to deep residual neural networks and derive expressivity results for approximating the sample to target distribution map.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#25193;&#25955;&#27169;&#22411;&#20013;&#28418;&#31227;&#39033;&#30340;&#25968;&#23398;&#20998;&#26512;&#12290;&#36890;&#36807;&#27425;&#27969;&#24418;&#20551;&#35774;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21487;&#22788;&#29702;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#22855;&#24322;&#25968;&#25454;&#20998;&#24067;&#65292;&#35299;&#20915;&#20102;&#22343;&#20540;&#28418;&#31227;&#20989;&#25968;&#21644;&#24471;&#20998;&#20989;&#25968;&#28176;&#36817;&#21457;&#25955;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.07882</link><description>&lt;p&gt;
&#22522;&#20110;&#27425;&#27969;&#24418;&#20551;&#35774;&#19979;&#25193;&#25955;&#27169;&#22411;&#22855;&#24322;&#24615;&#30340;&#25968;&#23398;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Mathematical analysis of singularities in the diffusion model under the submanifold assumption. (arXiv:2301.07882v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07882
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#25193;&#25955;&#27169;&#22411;&#20013;&#28418;&#31227;&#39033;&#30340;&#25968;&#23398;&#20998;&#26512;&#12290;&#36890;&#36807;&#27425;&#27969;&#24418;&#20551;&#35774;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21487;&#22788;&#29702;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#22855;&#24322;&#25968;&#25454;&#20998;&#24067;&#65292;&#35299;&#20915;&#20102;&#22343;&#20540;&#28418;&#31227;&#20989;&#25968;&#21644;&#24471;&#20998;&#20989;&#25968;&#28176;&#36817;&#21457;&#25955;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#25193;&#25955;&#27169;&#22411;&#30340;&#25968;&#23398;&#20998;&#26512;&#12290;&#20197;&#26465;&#20214;&#26399;&#26395;&#34920;&#31034;&#21453;&#21521;&#37319;&#26679;&#27969;&#31243;&#30340;&#28418;&#31227;&#39033;&#65292;&#20854;&#20013;&#28041;&#21450;&#25968;&#25454;&#20998;&#24067;&#21644;&#21069;&#21521;&#25193;&#25955;&#12290;&#35757;&#32451;&#36807;&#31243;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#19982;&#26465;&#20214;&#26399;&#26395;&#30456;&#20851;&#30340;&#22343;&#26041;&#27531;&#24046;&#26469;&#23547;&#25214;&#27492;&#31867;&#28418;&#31227;&#20989;&#25968;&#12290;&#20351;&#29992;&#21069;&#21521;&#25193;&#25955;&#30340;Green&#20989;&#25968;&#30340;&#23567;&#26102;&#38388;&#36817;&#20284;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;DDPM&#20013;&#30340;&#35299;&#26512;&#22343;&#20540;&#28418;&#31227;&#20989;&#25968;&#21644;SGM&#20013;&#30340;&#24471;&#20998;&#20989;&#25968;&#22312;&#37319;&#26679;&#36807;&#31243;&#30340;&#26368;&#21518;&#38454;&#27573;&#65292;&#23545;&#20110;&#20687;&#37027;&#20123;&#38598;&#20013;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#22855;&#24322;&#25968;&#25454;&#20998;&#24067;&#32780;&#35328;&#65292;&#28176;&#36817;&#22320;&#21457;&#25955;&#65292;&#22240;&#27492;&#38590;&#20197;&#36890;&#36807;&#32593;&#32476;&#36827;&#34892;&#36924;&#36817;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#22256;&#38590;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22312;&#22788;&#29702;&#22855;&#24322;&#25968;&#25454;&#20998;&#24067;&#26102;&#20173;&#28982;&#20445;&#25345;&#26377;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#26469;&#35828;&#26126;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper provide several mathematical analyses of the diffusion model in machine learning. The drift term of the backwards sampling process is represented as a conditional expectation involving the data distribution and the forward diffusion. The training process aims to find such a drift function by minimizing the mean-squared residue related to the conditional expectation. Using small-time approximations of the Green's function of the forward diffusion, we show that the analytical mean drift function in DDPM and the score function in SGM asymptotically blow up in the final stages of the sampling process for singular data distributions such as those concentrated on lower-dimensional manifolds, and is therefore difficult to approximate by a network. To overcome this difficulty, we derive a new target function and associated loss, which remains bounded even for singular data distributions. We illustrate the theoretical findings with several numerical examples.
&lt;/p&gt;</description></item></channel></rss>