<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#20917;&#19979;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20808;&#39564;&#20551;&#35774;&#36827;&#34892;&#31616;&#21333;&#30340;&#32553;&#25918;&#65292;&#20351;&#26222;&#36890;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#39640;&#32500;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>https://arxiv.org/abs/2402.02229</link><description>&lt;p&gt;
&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#26222;&#36890;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#34920;&#29616;&#20986;&#33394;
&lt;/p&gt;
&lt;p&gt;
Vanilla Bayesian Optimization Performs Great in High Dimension
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#20917;&#19979;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20808;&#39564;&#20551;&#35774;&#36827;&#34892;&#31616;&#21333;&#30340;&#32553;&#25918;&#65292;&#20351;&#26222;&#36890;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#39640;&#32500;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#20197;&#26469;&#65292;&#39640;&#32500;&#38382;&#39064;&#19968;&#30452;&#34987;&#35748;&#20026;&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#30340;&#36719;&#32907;&#12290;&#21463;&#21040;&#32500;&#24230;&#22122;&#38899;&#30340;&#21050;&#28608;&#65292;&#35768;&#22810;&#31639;&#27861;&#26088;&#22312;&#36890;&#36807;&#23545;&#30446;&#26631;&#24212;&#29992;&#21508;&#31181;&#31616;&#21270;&#20551;&#35774;&#26469;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;&#26412;&#25991;&#36890;&#36807;&#35782;&#21035;&#23548;&#33268;&#26222;&#36890;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#39640;&#32500;&#20219;&#21153;&#20013;&#19981;&#36866;&#29992;&#30340;&#36864;&#21270;&#29616;&#35937;&#65292;&#24182;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#29616;&#26377;&#31639;&#27861;&#22914;&#20309;&#36890;&#36807;&#38477;&#20302;&#27169;&#22411;&#22797;&#26434;&#24230;&#26469;&#24212;&#23545;&#36825;&#20123;&#36864;&#21270;&#29616;&#35937;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#26222;&#36890;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#20013;&#20856;&#22411;&#20808;&#39564;&#20551;&#35774;&#30340;&#25913;&#36827;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#19981;&#23545;&#30446;&#26631;&#26045;&#21152;&#32467;&#26500;&#24615;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#23558;&#22797;&#26434;&#24615;&#38477;&#20302;&#21040;&#21487;&#31649;&#29702;&#30340;&#27700;&#24179;&#12290;&#25105;&#20204;&#30340;&#20462;&#25913;&#26041;&#27861;&#8212;&#8212;&#36890;&#36807;&#32500;&#24230;&#23545;&#39640;&#26031;&#36807;&#31243;&#38271;&#24230;&#20808;&#39564;&#36827;&#34892;&#31616;&#21333;&#30340;&#32553;&#25918;&#8212;&#8212;&#25581;&#31034;&#20102;&#26631;&#20934;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#26174;&#33879;&#25913;&#36827;&#65292;&#26126;&#30830;&#34920;&#26126;&#20854;&#25928;&#26524;&#36828;&#36828;&#36229;&#20986;&#20197;&#24448;&#30340;&#39044;&#26399;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional problems have long been considered the Achilles' heel of Bayesian optimization algorithms. Spurred by the curse of dimensionality, a large collection of algorithms aim to make it more performant in this setting, commonly by imposing various simplifying assumptions on the objective. In this paper, we identify the degeneracies that make vanilla Bayesian optimization poorly suited to high-dimensional tasks, and further show how existing algorithms address these degeneracies through the lens of lowering the model complexity. Moreover, we propose an enhancement to the prior assumptions that are typical to vanilla Bayesian optimization algorithms, which reduces the complexity to manageable levels without imposing structural restrictions on the objective. Our modification - a simple scaling of the Gaussian process lengthscale prior with the dimensionality - reveals that standard Bayesian optimization works drastically better than previously thought in high dimensions, clearly
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#24102;&#26377;Bandit&#21453;&#39304;&#30340;&#26497;&#23567;&#26497;&#22823;&#27425;&#27169;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#26368;&#23567;&#26368;&#22823;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#19982;&#19979;&#38480;&#36951;&#25022;&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.18465</link><description>&lt;p&gt;
&#24102;&#26377;Bandit&#21453;&#39304;&#30340;&#26497;&#23567;&#26497;&#22823;&#27425;&#27169;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal Submodular Optimization with Bandit Feedback. (arXiv:2310.18465v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18465
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#24102;&#26377;Bandit&#21453;&#39304;&#30340;&#26497;&#23567;&#26497;&#22823;&#27425;&#27169;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#26368;&#23567;&#26368;&#22823;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#19982;&#19979;&#38480;&#36951;&#25022;&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#38543;&#26426;Bandit&#21453;&#39304;&#19979;&#65292;&#26368;&#22823;&#21270;&#19968;&#20010;&#21333;&#35843;&#27425;&#27169;&#38598;&#20989;&#25968;$f&#65306;2 ^ {[n]} \rightarrow [0,1]$&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;$f$&#23545;&#20110;&#23398;&#20064;&#32773;&#26159;&#26410;&#30693;&#30340;&#65292;&#20294;&#26159;&#22312;&#27599;&#20010;&#26102;&#38388;$t=1,\dots,T$&#65292;&#23398;&#20064;&#32773;&#36873;&#25321;&#19968;&#20010;&#38598;&#21512;$S_t \subset [n]$&#65292;&#20854;&#20013;$|S_t|\leq k$&#65292;&#24182;&#25509;&#25910;&#22870;&#21169;$f(S_t)+\eta_t$&#65292;&#20854;&#20013;$\eta_t$&#26159;&#22343;&#20540;&#20026;&#38646;&#30340;&#27425;&#39640;&#26031;&#22122;&#22768;&#12290;&#30446;&#26631;&#26159;&#22312;$T$&#27425;&#20013;&#20351;&#24471;&#23398;&#20064;&#32773;&#23545;&#20110;&#24102;&#26377;$|S_*|=k$&#30340;&#26368;&#22823;$f(S_*)$&#30340;($1-e^{-1}$)&#36817;&#20284;&#30340;&#26368;&#23567;&#36951;&#25022;&#65292;&#36890;&#36807;&#23545;$f$&#30340;&#36138;&#23146;&#26368;&#22823;&#21270;&#26469;&#36798;&#21040;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#25991;&#29486;&#20013;&#26368;&#22909;&#30340;&#36951;&#25022;&#36793;&#30028;&#25353;&#29031;$k n^{1/3} T^{2/3}$&#30340;&#27604;&#20363;&#32553;&#25918;&#12290;&#36890;&#36807;&#23558;&#27599;&#20010;&#38598;&#21512;&#31616;&#21333;&#22320;&#35270;&#20026;&#19968;&#20010;&#21807;&#19968;&#30340;arm&#65292;&#21487;&#20197;&#25512;&#26029;&#20986;$\sqrt{{n \choose k} T}$&#20063;&#26159;&#21487;&#23454;&#29616;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#31532;&#19968;&#20010;&#26497;&#23567;&#26497;&#22823;&#19979;&#38480;&#65292;&#20854;&#25353;&#29031;$\mathcal{O}(\min_{i \le k}(in^{1/3}T^{2/3} + \sqrt{n^{k-i}T}))$&#30340;&#27604;&#20363;&#32553;&#25918;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#19982;&#19979;&#38480;&#36951;&#25022;&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider maximizing a monotonic, submodular set function $f: 2^{[n]} \rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is unknown to the learner but at each time $t=1,\dots,T$ the learner chooses a set $S_t \subset [n]$ with $|S_t| \leq k$ and receives reward $f(S_t) + \eta_t$ where $\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize the learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation of maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of $f$. To date, the best regret bound in the literature scales as $k n^{1/3} T^{2/3}$. And by trivially treating every set as a unique arm one deduces that $\sqrt{ {n \choose k} T }$ is also achievable. In this work, we establish the first minimax lower bound for this setting that scales like $\mathcal{O}(\min_{i \le k}(in^{1/3}T^{2/3} + \sqrt{n^{k-i}T}))$. Moreover, we propose an algorithm that is capable of matching the lower bound regret.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#21452;&#37325;&#40065;&#26834;&#30340;&#20272;&#35745;&#22120;TNDDR&#65292;&#29992;&#20110;&#22312;&#38452;&#24615;&#27979;&#35797;&#35774;&#35745;&#19979;&#20272;&#35745;COVID-19&#30123;&#33495;&#30340;&#26377;&#25928;&#24615;&#65292;&#21487;&#26377;&#25928;&#35299;&#20915;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#36827;&#34892;&#36741;&#21161;&#20989;&#25968;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2310.04578</link><description>&lt;p&gt;
TNDDR: &#39640;&#25928;&#19988;&#21452;&#37325;&#40065;&#26834;&#30340;COVID-19&#30123;&#33495;&#26377;&#25928;&#24615;&#20272;&#35745;&#22312;&#38452;&#24615;&#27979;&#35797;&#35774;&#35745;&#19979;
&lt;/p&gt;
&lt;p&gt;
TNDDR: Efficient and doubly robust estimation of COVID-19 vaccine effectiveness under the test-negative design. (arXiv:2310.04578v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04578
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#19988;&#21452;&#37325;&#40065;&#26834;&#30340;&#20272;&#35745;&#22120;TNDDR&#65292;&#29992;&#20110;&#22312;&#38452;&#24615;&#27979;&#35797;&#35774;&#35745;&#19979;&#20272;&#35745;COVID-19&#30123;&#33495;&#30340;&#26377;&#25928;&#24615;&#65292;&#21487;&#26377;&#25928;&#35299;&#20915;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#36827;&#34892;&#36741;&#21161;&#20989;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#38452;&#24615;&#27979;&#35797;&#35774;&#35745;&#65288;TND&#65289;&#24120;&#29992;&#20110;&#30417;&#27979;&#23395;&#33410;&#24615;&#27969;&#24863;&#30123;&#33495;&#26377;&#25928;&#24615;&#65288;VE&#65289;&#65292;&#20294;&#26368;&#36817;&#24050;&#25104;&#20026;COVID-19&#30123;&#33495;&#30417;&#27979;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#20294;&#30001;&#20110;&#32467;&#26524;&#30456;&#20851;&#25277;&#26679;&#65292;&#23427;&#23481;&#26131;&#21463;&#21040;&#36873;&#25321;&#20559;&#24046;&#30340;&#24433;&#21709;&#12290;&#19968;&#20123;&#30740;&#31350;&#24050;&#32463;&#35299;&#20915;&#20102;TND&#19979;&#22240;&#26524;&#21442;&#25968;&#30340;&#21487;&#37492;&#21035;&#24615;&#21644;&#20272;&#35745;&#38382;&#39064;&#65292;&#20294;&#23578;&#26410;&#30740;&#31350;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#22312;&#26080;&#28151;&#26434;&#24615;&#20551;&#35774;&#19979;&#30340;&#25928;&#29575;&#36793;&#30028;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;TNDDR&#65288;TND&#21452;&#37325;&#40065;&#26834;&#65289;&#30340;&#19968;&#27493;&#21452;&#37325;&#40065;&#26834;&#21644;&#23616;&#37096;&#39640;&#25928;&#20272;&#35745;&#22120;,&#23427;&#21033;&#29992;&#26679;&#26412;&#20998;&#21106;&#65292;&#24182;&#21487;&#20197;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20272;&#35745;&#36741;&#21161;&#20989;&#25968;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#32467;&#26524;&#36793;&#38469;&#26399;&#26395;&#30340;&#39640;&#25928;&#24433;&#21709;&#20989;&#25968;&#65288;EIF&#65289;&#65292;&#25506;&#32034;&#20102;von Mises&#23637;&#24320;&#65292;&#24182;&#24314;&#31435;&#20102;TNDDR&#30340;n&#30340;&#24179;&#26041;&#26681;&#19968;&#33268;&#24615;&#12289;&#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#21452;&#37325;&#40065;&#26834;&#24615;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
While the test-negative design (TND), which is routinely used for monitoring seasonal flu vaccine effectiveness (VE), has recently become integral to COVID-19 vaccine surveillance, it is susceptible to selection bias due to outcome-dependent sampling. Some studies have addressed the identifiability and estimation of causal parameters under the TND, but efficiency bounds for nonparametric estimators of the target parameter under the unconfoundedness assumption have not yet been investigated. We propose a one-step doubly robust and locally efficient estimator called TNDDR (TND doubly robust), which utilizes sample splitting and can incorporate machine learning techniques to estimate the nuisance functions. We derive the efficient influence function (EIF) for the marginal expectation of the outcome under a vaccination intervention, explore the von Mises expansion, and establish the conditions for $\sqrt{n}-$consistency, asymptotic normality and double robustness of TNDDR. The proposed TND
&lt;/p&gt;</description></item><item><title>AdaStop&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#35299;&#20915;&#23454;&#39564;&#32467;&#26524;&#21487;&#22797;&#21046;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.10882</link><description>&lt;p&gt;
AdaStop&#65306;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#27604;&#36739;&#30340;&#39640;&#25928;&#21487;&#38752;&#24207;&#21015;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
AdaStop: sequential testing for efficient and reliable comparisons of Deep RL Agents. (arXiv:2306.10882v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10882
&lt;/p&gt;
&lt;p&gt;
AdaStop&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#35299;&#20915;&#23454;&#39564;&#32467;&#26524;&#21487;&#22797;&#21046;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#23454;&#39564;&#32467;&#26524;&#30340;&#21487;&#22797;&#29616;&#24615;&#21463;&#21040;&#36136;&#30097;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#21487;&#22797;&#29616;&#24615;&#21361;&#26426;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#19978;&#21487;&#38752;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#30001;&#20110;&#19968;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#19968;&#27425;&#25191;&#34892;&#24615;&#33021;&#26159;&#38543;&#26426;&#30340;&#65292;&#25152;&#20197;&#38656;&#35201;&#36827;&#34892;&#29420;&#31435;&#30340;&#22810;&#27425;&#25191;&#34892;&#26469;&#31934;&#30830;&#35780;&#20272;&#23427;&#12290;&#24403;&#27604;&#36739;&#22810;&#20010;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26102;&#65292;&#19968;&#20010;&#20027;&#35201;&#38382;&#39064;&#26159;&#38656;&#35201;&#36827;&#34892;&#22810;&#23569;&#27425;&#25191;&#34892;&#65292;&#24182;&#19988;&#22914;&#20309;&#30830;&#20445;&#36825;&#26679;&#27604;&#36739;&#30340;&#32467;&#26524;&#22312;&#29702;&#35770;&#19978;&#26159;&#21487;&#38752;&#30340;&#12290;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#30740;&#31350;&#20154;&#21592;&#36890;&#24120;&#20351;&#29992;&#23569;&#20110;5&#20010;&#29420;&#31435;&#25191;&#34892;&#26469;&#27604;&#36739;&#31639;&#27861;&#65306;&#25105;&#20204;&#35748;&#20026;&#36825;&#36890;&#24120;&#26159;&#19981;&#22815;&#30340;&#12290;&#32780;&#19988;&#65292;&#24403;&#21516;&#26102;&#27604;&#36739;&#20960;&#20010;&#31639;&#27861;&#26102;&#65292;&#27599;&#20010;&#27604;&#36739;&#30340;&#35823;&#24046;&#37117;&#20250;&#32047;&#31215;&#65292;&#24517;&#39035;&#37319;&#29992;&#22810;&#37325;&#27979;&#35797;&#31243;&#24207;&#26469;&#32771;&#34385;&#36825;&#20123;&#35823;&#24046;&#65292;&#20197;&#32500;&#25345;&#20302;&#35823;&#24046;&#20445;&#35777;&#12290;&#20026;&#20102;&#20197;&#32479;&#35745;&#23398;&#19978;&#30340;&#21487;&#38752;&#26041;&#24335;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;AdaStop&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reproducibility of many experimental results in Deep Reinforcement Learning (RL) is under question. To solve this reproducibility crisis, we propose a theoretically sound methodology to compare multiple Deep RL algorithms. The performance of one execution of a Deep RL algorithm is random so that independent executions are needed to assess it precisely. When comparing several RL algorithms, a major question is how many executions must be made and how can we assure that the results of such a comparison is theoretically sound. Researchers in Deep RL often use less than 5 independent executions to compare algorithms: we claim that this is not enough in general. Moreover, when comparing several algorithms at once, the error of each comparison accumulates and must be taken into account with a multiple tests procedure to preserve low error guarantees. To address this problem in a statistically sound way, we introduce AdaStop, a new statistical test based on multiple group sequential tests
&lt;/p&gt;</description></item></channel></rss>