<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20174;&#32780;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;</title><link>https://arxiv.org/abs/2403.04082</link><description>&lt;p&gt;
&#36890;&#36807;&#25554;&#20540;&#36827;&#34892;&#25512;&#26029;&#65306;&#23545;&#27604;&#34920;&#31034;&#21487;&#35777;&#26126;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04082
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20174;&#32780;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#25105;&#20204;&#22914;&#20309;&#22238;&#31572;&#35832;&#22914;&#8220;&#26410;&#26469;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#8221;&#21644;&#8220;&#25105;&#20204;&#26159;&#22914;&#20309;&#21040;&#36798;&#36825;&#37324;&#30340;&#65311;&#8221;&#36825;&#31867;&#27010;&#29575;&#25512;&#26029;&#38382;&#39064;&#22312;&#35266;&#27979;&#20540;&#20026;&#39640;&#32500;&#26102;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#38382;&#39064;&#22914;&#20309;&#36890;&#36807;&#23398;&#20064;&#34920;&#31034;&#30340;&#32039;&#20945;&#38381;&#24335;&#35299;&#20915;&#26041;&#26696;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#23545;&#27604;&#23398;&#20064;&#30340;&#21464;&#20307;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#34920;&#26126;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#34920;&#31034;&#32534;&#30721;&#20102;&#27010;&#29575;&#27604;&#12290;&#36890;&#36807;&#23558;&#20043;&#21069;&#30340;&#24037;&#20316;&#25193;&#23637;&#20197;&#34920;&#26126;&#34920;&#31034;&#30340;&#36793;&#38469;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#65292;&#25105;&#20204;&#38543;&#21518;&#35777;&#26126;&#34920;&#31034;&#30340;&#32852;&#21512;&#20998;&#24067;&#20063;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#36825;&#20123;&#32467;&#26524;&#20849;&#21516;&#34920;&#26126;&#65292;&#36890;&#36807;&#26102;&#38388;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#19968;&#31181;&#22270;&#24418;&#27169;&#22411;&#65292;&#20854;&#20013;&#23545;&#34920;&#31034;&#36827;&#34892;&#30340;&#25512;&#26029;&#65288;&#20363;&#22914;&#39044;&#27979;&#12289;&#35268;&#21010;&#65289;&#23545;&#24212;&#20110;&#21453;&#28436;&#20302;&#32500;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04082v1 Announce Type: new  Abstract: Given time series data, how can we answer questions like "what will happen in the future?" and "how did we get here?" These sorts of probabilistic inference questions are challenging when observations are high-dimensional. In this paper, we show how these questions can have compact, closed form solutions in terms of learned representations. The key idea is to apply a variant of contrastive learning to time series data. Prior work already shows that the representations learned by contrastive learning encode a probability ratio. By extending prior work to show that the marginal distribution over representations is Gaussian, we can then prove that joint distribution of representations is also Gaussian. Taken together, these results show that representations learned via temporal contrastive learning follow a Gauss-Markov chain, a graphical model where inference (e.g., prediction, planning) over representations corresponds to inverting a low-
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#19981;&#21516;&#25968;&#25454;&#22495;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#65292;&#25512;&#27979;&#20102;&#27169;&#22411;&#23545;&#29305;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2402.12264</link><description>&lt;p&gt;
&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification in fine-tuned LLMs using LoRA ensembles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12264
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;LoRA&#38598;&#25104;&#22312;&#31934;&#35843;LLMs&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#19981;&#21516;&#25968;&#25454;&#22495;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#65292;&#25512;&#27979;&#20102;&#27169;&#22411;&#23545;&#29305;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#29305;&#23450;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#23613;&#31649;&#23545;&#20110;&#31934;&#35843;&#27169;&#22411;&#23398;&#21040;&#20102;&#20160;&#20040;&#12289;&#36951;&#24536;&#20102;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#20449;&#20219;&#20854;&#39044;&#27979;&#20173;&#28982;&#32570;&#20047;&#19968;&#20010;&#19968;&#33324;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#23545;&#31934;&#35843;LLMs&#36827;&#34892;&#22522;&#20110;&#21518;&#39564;&#36924;&#36817;&#30340;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;Mistral-7b&#30340;&#20302;&#31209;&#36866;&#24212;&#38598;&#25104;&#20998;&#26512;&#20102;&#19977;&#20010;&#24120;&#35265;&#30340;&#22810;&#39033;&#36873;&#25321;&#25968;&#25454;&#38598;&#65292;&#24182;&#23545;&#20854;&#22312;&#31934;&#35843;&#36807;&#31243;&#20013;&#21644;&#20043;&#21518;&#23545;&#19981;&#21516;&#30446;&#26631;&#39046;&#22495;&#30340;&#24863;&#30693;&#22797;&#26434;&#24615;&#21644;&#27169;&#22411;&#25928;&#33021;&#36827;&#34892;&#20102;&#23450;&#37327;&#21644;&#23450;&#24615;&#30340;&#32467;&#35770;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22522;&#20110;&#25968;&#20540;&#23454;&#39564;&#25903;&#25345;&#65292;&#25105;&#20204;&#23545;&#37027;&#20123;&#23545;&#20110;&#32473;&#23450;&#26550;&#26500;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#39046;&#22495;&#30340;&#29109;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#25552;&#20986;&#20102;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12264v1 Announce Type: cross  Abstract: Fine-tuning large language models can improve task specific performance, although a general understanding of what the fine-tuned model has learned, forgotten and how to trust its predictions is still missing. We derive principled uncertainty quantification for fine-tuned LLMs with posterior approximations using computationally efficient low-rank adaptation ensembles. We analyze three common multiple-choice datasets using low-rank adaptation ensembles based on Mistral-7b, and draw quantitative and qualitative conclusions on their perceived complexity and model efficacy on the different target domains during and after fine-tuning. In particular, backed by the numerical experiments, we hypothesise about signals from entropic uncertainty measures for data domains that are inherently difficult for a given architecture to learn.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#35760;&#24518;&#26680;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#24182;&#22312;Sobolev&#33539;&#25968;Loss&#20989;&#25968;&#21644;RKHS&#27491;&#21017;&#21270;&#19979;&#23454;&#29616;&#22238;&#24402;&#65292;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#25913;&#36827;&#24615;&#33021;&#65292;&#23545;&#27604;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11705</link><description>&lt;p&gt;
&#22312;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#23398;&#20064;&#35760;&#24518;&#26680;
&lt;/p&gt;
&lt;p&gt;
Learning Memory Kernels in Generalized Langevin Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11705
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#35760;&#24518;&#26680;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#24182;&#22312;Sobolev&#33539;&#25968;Loss&#20989;&#25968;&#21644;RKHS&#27491;&#21017;&#21270;&#19979;&#23454;&#29616;&#22238;&#24402;&#65292;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#25913;&#36827;&#24615;&#33021;&#65292;&#23545;&#27604;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#30340;&#35760;&#24518;&#26680;&#12290;&#35813;&#26041;&#27861;&#26368;&#21021;&#21033;&#29992;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20174;&#36712;&#36857;&#25968;&#25454;&#20013;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#65292;&#28982;&#21518;&#36890;&#36807;&#22522;&#20110;Sobolev&#33539;&#25968;&#30340;&#22238;&#24402;&#21644;RKHS&#27491;&#21017;&#21270;&#26469;&#36827;&#34892;&#22238;&#24402;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20445;&#35777;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#20102;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#26680;&#20272;&#35745;&#35823;&#24046;&#21463;&#25511;&#20110;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#31034;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30456;&#23545;&#20110;&#20381;&#36182;&#20110;$L^2$&#25439;&#22833;&#20989;&#25968;&#30340;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#20197;&#21450;&#20174;&#36870;&#25289;&#26222;&#25289;&#26031;&#21464;&#25442;&#25512;&#23548;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#65292;&#36825;&#20123;&#31034;&#20363;&#31361;&#26174;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#21508;&#31181;&#26435;&#37325;&#21442;&#25968;&#36873;&#25321;&#19978;&#30340;&#25345;&#32493;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21253;&#25324;&#21147;&#21644;&#28418;&#31227;&#39033;&#22312;&#26041;&#31243;&#20013;&#30340;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11705v1 Announce Type: cross  Abstract: We introduce a novel approach for learning memory kernels in Generalized Langevin Equations. This approach initially utilizes a regularized Prony method to estimate correlation functions from trajectory data, followed by regression over a Sobolev norm-based loss function with RKHS regularization. Our approach guarantees improved performance within an exponentially weighted $L^2$ space, with the kernel estimation error controlled by the error in estimated correlation functions. We demonstrate the superiority of our estimator compared to other regression estimators that rely on $L^2$ loss functions and also an estimator derived from the inverse Laplace transform, using numerical examples that highlight its consistent advantage across various weight parameter selections. Additionally, we provide examples that include the application of force and drift terms in the equation.
&lt;/p&gt;</description></item></channel></rss>