<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20805;&#28385;&#22242;&#22270;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#31616;&#21333;&#22270;&#20013;&#65292;&#20805;&#28385;&#22242;&#22270;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#36890;&#36807;&#20855;&#20307;&#35745;&#31639;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#26368;&#22823;&#22242;&#25968;&#37327;&#30340;&#22270;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2307.14120</link><description>&lt;p&gt;
&#20316;&#20026;&#35745;&#31639;&#31616;&#21333;&#22270;&#30340;&#26368;&#22823;&#22242;&#30340;&#26368;&#22823;&#25968;&#37327;&#30340;&#25163;&#27573;&#30340;&#20805;&#28385;&#22242;&#22270;
&lt;/p&gt;
&lt;p&gt;
Cliqueful graphs as a means of calculating the maximal number of maximum cliques of simple graphs. (arXiv:2307.14120v1 [math.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20805;&#28385;&#22242;&#22270;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#31616;&#21333;&#22270;&#20013;&#65292;&#20805;&#28385;&#22242;&#22270;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#36890;&#36807;&#20855;&#20307;&#35745;&#31639;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#26368;&#22823;&#22242;&#25968;&#37327;&#30340;&#22270;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#31616;&#21333;&#22270;&#22312;n&#20010;&#39030;&#28857;&#19978;&#21487;&#33021;&#21253;&#21547;&#35768;&#22810;&#26368;&#22823;&#22242;&#12290;&#20294;&#23427;&#21487;&#33021;&#21253;&#21547;&#22810;&#23569;&#20010;&#21602;&#65311;&#25105;&#20204;&#23558;&#23637;&#31034;&#26368;&#22823;&#22242;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#25152;&#35859;&#30340;&#20805;&#28385;&#22242;&#22270;&#65292;&#20855;&#20307;&#22320;&#35828;&#65292;&#22914;&#26524;n&#8805;15&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#23427;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#21033;&#29992;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#21253;&#21547;3^{&#8970;n/3&#8971;}c&#20010;&#26368;&#22823;&#22242;&#30340;&#22270;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#30340;&#26368;&#22823;&#22242;&#25968;&#37327;&#65292;&#20854;&#20013;c&#8712;{1,4/3,2}&#65292;&#21462;&#20915;&#20110;n&#27169;3&#30340;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
A simple graph on $n$ vertices may contain a lot of maximum cliques. But how many can it potentially contain? We will show that the maximum number of maximum cliques is taken over so-called cliqueful graphs, more specifically, later we will show that it is taken over saturated composite cliqueful graphs, if $n \ge 15$. Using this we will show that the graph that contains $3^{\lfloor n/3 \rfloor}c$ maxcliques has the most number of maxcliques on $n$ vertices, where $c\in\{1,\frac{4}{3},2\}$, depending on $n \text{ mod } 3$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#19979;&#30340;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#36817;&#20284;&#36807;&#31243;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#31639;&#27861;&#34920;&#29616;&#20248;&#31168;&#12290;</title><link>http://arxiv.org/abs/2307.03034</link><description>&lt;p&gt;
&#24102;&#26377;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#30340;&#19981;&#23433;&#23450;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;
&lt;/p&gt;
&lt;p&gt;
PCL-Indexability and Whittle Index for Restless Bandits with General Observation Models. (arXiv:2307.03034v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#19979;&#30340;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#36817;&#20284;&#36807;&#31243;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#31639;&#27861;&#34920;&#29616;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#65292;&#29992;&#20110;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#30001;&#20110;&#36164;&#28304;&#32422;&#26463;&#25110;&#29615;&#22659;&#25110;&#22266;&#26377;&#22122;&#22768;&#65292;&#29609;&#23478;&#25805;&#20316;&#38656;&#35201;&#22522;&#20110;&#26576;&#31181;&#26377;&#35823;&#24046;&#30340;&#21453;&#39304;&#26426;&#21046;&#12290;&#36890;&#36807;&#24314;&#31435;&#21453;&#39304;/&#35266;&#27979;&#21160;&#21147;&#23398;&#30340;&#19968;&#33324;&#27010;&#29575;&#27169;&#22411;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#34920;&#36848;&#20026;&#19968;&#20010;&#20174;&#20219;&#24847;&#21021;&#22987;&#20449;&#24565;&#65288;&#20808;&#39564;&#20449;&#24687;&#65289;&#24320;&#22987;&#30340;&#20855;&#26377;&#21487;&#25968;&#20449;&#24565;&#29366;&#24577;&#31354;&#38388;&#30340;&#19981;&#23433;&#23450;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#21033;&#29992;&#20855;&#26377;&#37096;&#20998;&#23432;&#24658;&#23450;&#24459;&#65288;PCL&#65289;&#30340;&#21487;&#23454;&#29616;&#21306;&#22495;&#26041;&#27861;&#65292;&#20998;&#26512;&#20102;&#26080;&#38480;&#29366;&#24577;&#38382;&#39064;&#30340;&#21487;&#32034;&#24341;&#24615;&#21644;&#20248;&#20808;&#32423;&#32034;&#24341;&#65288;Whittle&#32034;&#24341;&#65289;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#36807;&#31243;&#65292;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#20197;&#24212;&#29992;Ni&#241;o-Mora&#21644;Bertsimas&#38024;&#23545;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#30340;AG&#31639;&#27861;&#30340;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider a general observation model for restless multi-armed bandit problems. The operation of the player needs to be based on certain feedback mechanism that is error-prone due to resource constraints or environmental or intrinsic noises. By establishing a general probabilistic model for dynamics of feedback/observation, we formulate the problem as a restless bandit with a countable belief state space starting from an arbitrary initial belief (a priori information). We apply the achievable region method with partial conservation law (PCL) to the infinite-state problem and analyze its indexability and priority index (Whittle index). Finally, we propose an approximation process to transform the problem into which the AG algorithm of Ni\~no-Mora and Bertsimas for finite-state problems can be applied to. Numerical experiments show that our algorithm has an excellent performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2305.15786</link><description>&lt;p&gt;
&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#30340;&#29702;&#35770;&#20445;&#35777;&#21450;&#20854;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting. (arXiv:2305.15786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#21512;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#24037;&#20855;&#20043;&#19968;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#26377;&#25928;&#22320;&#20943;&#23569;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#38024;&#23545;&#40657;&#30418;&#22522;&#23398;&#20064;&#22120;&#30340;&#22823;&#22810;&#25968;&#38598;&#21512;&#26041;&#27861;&#37117;&#23646;&#20110;&#8220;&#21472;&#21152;&#27867;&#21270;&#8221;&#33539;&#30068;&#65292;&#21363;&#35757;&#32451;&#19968;&#20010;&#25509;&#21463;&#22522;&#23398;&#20064;&#22120;&#25512;&#29702;&#20316;&#20026;&#36755;&#20837;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#34429;&#28982;&#21472;&#21152;&#27867;&#21270;&#22312;&#23454;&#36341;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#20173;&#28982;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#8220;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#8221;&#21472;&#21152;&#27867;&#21270;&#20013;&#30340;&#26368;&#20339;&#21472;&#21152;&#27867;&#21270;&#24182;&#19981;&#27604;&#26368;&#20248;&#35299;&#34920;&#29616;&#8220;&#24046;&#24471;&#22810;&#8221;&#12290;&#36825;&#19968;&#32467;&#26524;&#21152;&#24378;&#21644;&#22823;&#22823;&#25193;&#23637;&#20102;Van der Laan&#31561;&#20154;&#65288;2007&#24180;&#65289;&#30340;&#32467;&#26524;&#12290;&#21463;&#21040;&#29702;&#35770;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#27010;&#29575;&#39044;&#27979;&#30340;&#32972;&#26223;&#19979;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#19981;&#21516;&#25935;&#24863;&#24615;&#30340;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling is among the most popular tools in machine learning (ML) due to its effectiveness in minimizing variance and thus improving generalization. Most ensembling methods for black-box base learners fall under the umbrella of "stacked generalization," namely training an ML algorithm that takes the inferences from the base learners as input. While stacking has been widely applied in practice, its theoretical properties are poorly understood. In this paper, we prove a novel result, showing that choosing the best stacked generalization from a (finite or finite-dimensional) family of stacked generalizations based on cross-validated performance does not perform "much worse" than the oracle best. Our result strengthens and significantly extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis, we further propose a particular family of stacked generalizations in the context of probabilistic forecasting, each one with a different sensitivity for how much the 
&lt;/p&gt;</description></item></channel></rss>