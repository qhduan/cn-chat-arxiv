<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#26469;&#38477;&#20302;&#35745;&#31639;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.20285</link><description>&lt;p&gt;
&#36890;&#36807;&#20197;&#35745;&#31639;&#20026;&#20195;&#20215;&#21152;&#36895;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Accelerating Generalized Linear Models by Trading off Computation for Uncertainty. (arXiv:2310.20285v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#26469;&#38477;&#20302;&#35745;&#31639;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLMs&#65289;&#23450;&#20041;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#27169;&#20998;&#31867;&#12289;&#26377;&#24207;&#21644;&#36830;&#32493;&#25968;&#25454;&#65292;&#24182;&#19988;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;GLMs&#30340;&#31934;&#30830;&#25512;&#26029;&#20195;&#20215;&#22826;&#39640;&#65292;&#22240;&#27492;&#38656;&#35201;&#22312;&#23454;&#36341;&#20013;&#36827;&#34892;&#36817;&#20284;&#12290;&#36896;&#25104;&#30340;&#36817;&#20284;&#35823;&#24046;&#23545;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#65292;&#24182;&#19988;&#27809;&#26377;&#34987;&#32771;&#34385;&#22312;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20013;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#36845;&#20195;&#26041;&#27861;&#65292;&#26126;&#30830;&#22320;&#23545;&#36825;&#20010;&#35823;&#24046;&#24314;&#27169;&#12290;&#23427;&#20204;&#38750;&#24120;&#36866;&#21512;&#24182;&#34892;&#35745;&#31639;&#30828;&#20214;&#65292;&#26377;&#25928;&#22320;&#22238;&#25910;&#35745;&#31639;&#24182;&#21387;&#32553;&#20449;&#24687;&#65292;&#20197;&#20943;&#23569;GLMs&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#19968;&#20010;&#23454;&#38469;&#30340;&#22823;&#22411;&#20998;&#31867;&#38382;&#39064;&#19978;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#26126;&#30830;&#22320;&#23558;&#20943;&#23569;&#35745;&#31639;&#19982;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#26435;&#34913;&#26469;&#26174;&#33879;&#21152;&#36895;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in GLMs is prohibitively expensive for large datasets, thus requiring approximations in practice. The resulting approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. In this work, we introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for GLMs. As we demonstrate on a realistically large classification problem, our method significantly accelerates training by explicitly trading off reduced computation for increased uncertainty.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2303.17765</link><description>&lt;p&gt;
&#23398;&#20064;&#30456;&#20284;&#30340;&#32447;&#24615;&#34920;&#31034;&#65306;&#36866;&#24212;&#24615;&#12289;&#26497;&#23567;&#21270;&#12289;&#20197;&#21450;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness. (arXiv:2303.17765v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#28982;&#32780;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#27424;&#32570;&#12290;&#26412;&#25991;&#26088;&#22312;&#29702;&#35299;&#20174;&#20855;&#26377;&#30456;&#20284;&#20294;&#24182;&#38750;&#23436;&#20840;&#30456;&#21516;&#30340;&#32447;&#24615;&#34920;&#31034;&#30340;&#20219;&#21153;&#20013;&#23398;&#20064;&#65292;&#21516;&#26102;&#22788;&#29702;&#24322;&#24120;&#20540;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21333;&#20219;&#21153;&#25110;&#20165;&#30446;&#26631;&#23398;&#20064;&#26102;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \textit{adaptive} to the similarity structure and \textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;</title><link>http://arxiv.org/abs/2002.08907</link><description>&lt;p&gt;
&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;
&lt;/p&gt;
&lt;p&gt;
Second-order Conditional Gradient Sliding. (arXiv:2002.08907v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.08907
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#38656;&#35201;&#39640;&#31934;&#24230;&#35299;&#20915;&#38382;&#39064;&#26102;&#65292;&#32422;&#26463;&#20108;&#38454;&#20984;&#20248;&#21270;&#31639;&#27861;&#26159;&#39318;&#36873;&#65292;&#22240;&#20026;&#23427;&#20204;&#20855;&#26377;&#23616;&#37096;&#20108;&#27425;&#25910;&#25947;&#24615;&#12290;&#36825;&#20123;&#31639;&#27861;&#22312;&#27599;&#27425;&#36845;&#20195;&#26102;&#38656;&#35201;&#35299;&#20915;&#19968;&#20010;&#32422;&#26463;&#20108;&#27425;&#23376;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;\emph{&#20108;&#38454;&#26465;&#20214;&#26799;&#24230;&#28369;&#21160;}&#65288;SOCGS&#65289;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#19968;&#31181;&#26080;&#25237;&#24433;&#31639;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;&#32422;&#26463;&#20108;&#27425;&#23376;&#38382;&#39064;&#12290;&#24403;&#21487;&#34892;&#22495;&#26159;&#19968;&#20010;&#22810;&#38754;&#20307;&#26102;&#65292;&#35813;&#31639;&#27861;&#22312;&#26377;&#38480;&#27425;&#32447;&#24615;&#25910;&#25947;&#36845;&#20195;&#21518;&#20108;&#27425;&#25910;&#25947;&#20110;&#21407;&#22987;&#38388;&#38553;&#12290;&#36827;&#20837;&#20108;&#27425;&#25910;&#25947;&#38454;&#27573;&#21518;&#65292;SOCGS&#31639;&#27861;&#38656;&#36890;&#36807;$\mathcal{O}(\log(\log 1/\varepsilon))$&#27425;&#19968;&#38454;&#21644;Hessian&#27491;&#20132;&#35843;&#29992;&#20197;&#21450;$\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$&#27425;&#32447;&#24615;&#26368;&#23567;&#21270;&#27491;&#20132;&#35843;&#29992;&#26469;&#23454;&#29616;$\varepsilon$-&#26368;&#20248;&#35299;&#12290;&#24403;&#21487;&#34892;&#22495;&#21482;&#33021;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#27491;&#20132;&#35843;&#29992;&#39640;&#25928;&#35775;&#38382;&#26102;&#65292;&#27492;&#31639;&#27861;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constrained second-order convex optimization algorithms are the method of choice when a high accuracy solution to a problem is needed, due to their local quadratic convergence. These algorithms require the solution of a constrained quadratic subproblem at every iteration. We present the \emph{Second-Order Conditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free algorithm to solve the constrained quadratic subproblems inexactly. When the feasible region is a polytope the algorithm converges quadratically in primal gap after a finite number of linearly convergent iterations. Once in the quadratic regime the SOCGS algorithm requires $\mathcal{O}(\log(\log 1/\varepsilon))$ first-order and Hessian oracle calls and $\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$ linear minimization oracle calls to achieve an $\varepsilon$-optimal solution. This algorithm is useful when the feasible region can only be accessed efficiently through a linear optimization oracle, 
&lt;/p&gt;</description></item></channel></rss>