<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#35813;&#31574;&#30053;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#19968;&#33324;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.00539</link><description>&lt;p&gt;
&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#19979;&#30340;Thompson&#25506;&#32034;&#22312;&#26368;&#20339;&#33218;&#35782;&#21035;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Thompson Exploration with Best Challenger Rule in Best Arm Identification. (arXiv:2310.00539v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#35813;&#31574;&#30053;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#22312;&#19968;&#33324;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32463;&#20856;&#21333;&#21442;&#25968;&#25351;&#25968;&#27169;&#22411;&#19979;&#65292;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#30446;&#21069;&#24050;&#26377;&#24456;&#22810;&#31574;&#30053;&#34987;&#25552;&#20986;&#65292;&#20294;&#22823;&#22810;&#25968;&#38656;&#35201;&#22312;&#27599;&#19968;&#36718;&#35299;&#20915;&#19968;&#20010;&#26368;&#20248;&#21270;&#38382;&#39064;&#21644;/&#25110;&#32773;&#38656;&#35201;&#25506;&#32034;&#19968;&#20010;&#33218;&#33267;&#23569;&#19968;&#23450;&#27425;&#25968;&#65292;&#38500;&#38750;&#26159;&#38024;&#23545;&#39640;&#26031;&#27169;&#22411;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#23558;Thompson&#37319;&#26679;&#19982;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#8212;&#8212;&#26368;&#20339;&#20505;&#36873;&#35268;&#21017;&#30456;&#32467;&#21512;&#12290;&#34429;&#28982;Thompson&#37319;&#26679;&#26368;&#21021;&#34987;&#32771;&#34385;&#29992;&#20110;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#23427;&#20063;&#21487;&#20197;&#33258;&#28982;&#22320;&#29992;&#20110;&#22312;BAI&#20013;&#25506;&#32034;&#33218;&#32780;&#19981;&#24378;&#36843;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31574;&#30053;&#22312;&#20219;&#24847;&#20004;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#26159;&#28176;&#36817;&#26368;&#20248;&#30340;&#65292;&#24182;&#19988;&#22312;&#19968;&#33324;&#30340;$K$&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19978;&#65288;$K\geq 3$&#65289;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31574;&#30053;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#34920;&#29616;&#20986;&#20102;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the fixed-confidence best arm identification (BAI) problem in the bandit framework in the canonical single-parameter exponential models. For this problem, many policies have been proposed, but most of them require solving an optimization problem at every round and/or are forced to explore an arm at least a certain number of times except those restricted to the Gaussian model. To address these limitations, we propose a novel policy that combines Thompson sampling with a computationally efficient approach known as the best challenger rule. While Thompson sampling was originally considered for maximizing the cumulative reward, we demonstrate that it can be used to naturally explore arms in BAI without forcing it. We show that our policy is asymptotically optimal for any two-armed bandit problems and achieves near optimality for general $K$-armed bandit problems for $K\geq 3$. Nevertheless, in numerical experiments, our policy shows competitive performance compared to as
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20102;&#21508;&#31181;&#38459;&#30861;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20960;&#20309;&#38556;&#30861;&#21644;&#30001;&#20110;&#23545;&#31216;&#24615;&#23548;&#33268;&#30340;&#20016;&#23500;&#30340;&#20020;&#30028;&#28857;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2306.07886</link><description>&lt;p&gt;
&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#38382;&#39064;&#30340;&#23545;&#31216;&#24615;&#19982;&#20020;&#30028;&#28857;
&lt;/p&gt;
&lt;p&gt;
Symmetry &amp; Critical Points for Symmetric Tensor Decompositions Problems. (arXiv:2306.07886v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20102;&#21508;&#31181;&#38459;&#30861;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20960;&#20309;&#38556;&#30861;&#21644;&#30001;&#20110;&#23545;&#31216;&#24615;&#23548;&#33268;&#30340;&#20016;&#23500;&#30340;&#20020;&#30028;&#28857;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#21033;&#29992;&#20854;&#20016;&#23500;&#30340;&#23545;&#31216;&#32467;&#26500;&#65292;&#23548;&#20986;Puiseux&#32423;&#25968;&#34920;&#31034;&#30340;&#19968;&#31995;&#21015;&#20020;&#30028;&#28857;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20020;&#30028;&#20540;&#21644;Hessian&#35889;&#30340;&#31934;&#30830;&#20998;&#26512;&#20272;&#35745;&#12290;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#21508;&#31181;&#20960;&#20309;&#38556;&#30861;&#65292;&#38459;&#30861;&#20102;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20351;&#29992;&#65292;&#26368;&#21518;&#65292;&#21033;&#29992;&#19968;&#20010;&#29275;&#39039;&#22810;&#38754;&#20307;&#35770;&#35777;&#20102;&#22266;&#23450;&#23545;&#31216;&#24615;&#30340;&#25152;&#26377;&#20020;&#30028;&#28857;&#30340;&#23436;&#20840;&#26522;&#20030;&#65292;&#24182;&#35777;&#26126;&#20102;&#19982;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#38598;&#21512;&#30456;&#27604;&#65292;&#30001;&#20110;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#65292;&#20020;&#30028;&#28857;&#30340;&#38598;&#21512;&#21487;&#33021;&#20250;&#26174;&#31034;&#20986;&#32452;&#21512;&#30340;&#20016;&#23500;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the non-convex optimization problem associated with the decomposition of a real symmetric tensor into a sum of rank one terms. Use is made of the rich symmetry structure to derive Puiseux series representations of families of critical points, and so obtain precise analytic estimates on the critical values and the Hessian spectrum. The sharp results make possible an analytic characterization of various geometric obstructions to local optimization methods, revealing in particular a complex array of saddles and local minima which differ by their symmetry, structure and analytic properties. A desirable phenomenon, occurring for all critical points considered, concerns the index of a point, i.e., the number of negative Hessian eigenvalues, increasing with the value of the objective function. Lastly, a Newton polytope argument is used to give a complete enumeration of all critical points of fixed symmetry, and it is shown that contrarily to the set of global minima which remains 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#28385;&#36275;&#25351;&#25968;&#31934;&#24230;&#12289;&#19968;&#33268;&#24615;&#21644;&#26368;&#22823;&#31934;&#24230;&#31561;&#26631;&#20934;&#65292;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.14496</link><description>&lt;p&gt;
&#36890;&#36807;&#20013;&#24230;&#20559;&#24046;&#29702;&#35770;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learning via Moderate Deviations Theory. (arXiv:2305.14496v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#28385;&#36275;&#25351;&#25968;&#31934;&#24230;&#12289;&#19968;&#33268;&#24615;&#21644;&#26368;&#22823;&#31934;&#24230;&#31561;&#26631;&#20934;&#65292;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#20351;&#29992;&#32622;&#20449;&#21306;&#38388;&#23398;&#20064;&#20989;&#25968;&#20540;&#30340;&#32479;&#35745;&#26368;&#20248;&#26041;&#27861;&#65292;&#21253;&#25324;&#25551;&#36848;&#20026;&#38543;&#26426;&#35268;&#21010;&#38382;&#39064;&#25110;&#21508;&#31181;SDE&#27169;&#22411;&#30340;&#26399;&#26395;&#25439;&#22833;&#30340;&#19968;&#33324;&#38750;&#21442;&#25968;&#20272;&#35745;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#22522;&#20110;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#30340;&#26041;&#27861;&#31995;&#32479;&#22320;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#22312;&#32479;&#35745;&#24847;&#20041;&#19978;&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#28385;&#36275;&#20197;&#25351;&#25968;&#31934;&#24230;&#12289;&#26368;&#23567;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#35823;&#21028;&#27010;&#29575;&#20197;&#21450;&#26368;&#32456;&#30340;&#19968;&#33268;&#26368;&#22823;&#31934;&#24230;&#20026;&#26631;&#20934;&#30340;&#35201;&#27714;&#12290;&#35813;&#26041;&#27861;&#25552;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#26159;&#36890;&#36807;&#24378;&#21270;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#26469;&#34920;&#36798;&#30340;&#65292;&#20854;&#20013;&#19981;&#30830;&#23450;&#24615;&#36890;&#36807;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#24341;&#21457;&#30340;&#20013;&#24230;&#20559;&#24046;&#29575;&#20989;&#25968;&#26469;&#34920;&#31034;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#23545;&#20110;&#35768;&#22810;&#27169;&#22411;&#65292;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#20855;&#26377;&#26131;&#20110;&#35299;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a statistically optimal approach for learning a function value using a confidence interval in a wide range of models, including general non-parametric estimation of an expected loss described as a stochastic programming problem or various SDE models. More precisely, we develop a systematic construction of highly accurate confidence intervals by using a moderate deviation principle-based approach. It is shown that the proposed confidence intervals are statistically optimal in the sense that they satisfy criteria regarding exponential accuracy, minimality, consistency, mischaracterization probability, and eventual uniformly most accurate (UMA) property. The confidence intervals suggested by this approach are expressed as solutions to robust optimization problems, where the uncertainty is expressed via the underlying moderate deviation rate function induced by the data-generating process. We demonstrate that for many models these optimization problems admit tractable r
&lt;/p&gt;</description></item></channel></rss>