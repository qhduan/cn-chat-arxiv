<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#29992;&#20110;&#27714;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#21644;O(&#949;^(-4))&#12290;</title><link>https://arxiv.org/abs/2402.03352</link><description>&lt;p&gt;
&#38754;&#21521;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#21407;&#22987;&#23545;&#20598;&#20132;&#26367;&#25237;&#24433;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Zeroth-Order primal-dual Alternating Projection Gradient Algorithms for Nonconvex Minimax Problems with Coupled linear Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#29992;&#20110;&#27714;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#21644;O(&#949;^(-4))&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#35774;&#32622;&#19979;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#36825;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#21644;&#20854;&#20182;&#39046;&#22495;&#20013;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20363;&#22914;&#36164;&#28304;&#20998;&#37197;&#38382;&#39064;&#21644;&#32593;&#32476;&#27969;&#38382;&#39064;&#20013;&#30340;&#23545;&#25239;&#25915;&#20987;&#31561;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#20998;&#21035;&#26159;&#38646;&#38454;&#21407;&#22987;&#23545;&#20598;&#20132;&#26367;&#25237;&#24433;&#26799;&#24230;&#65288;ZO-PDAPG&#65289;&#31639;&#27861;&#21644;&#38646;&#38454;&#27491;&#21017;&#21160;&#37327;&#21407;&#22987;&#23545;&#20598;&#25237;&#24433;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-RMPDPG&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#38750;&#20984;-(&#24378;)&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;&#31639;&#27861;&#33719;&#24471;&#19968;&#20010;&#949;-&#31283;&#23450;&#28857;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;O(&#949;^(-2))&#65288;&#23545;&#20110;&#27714;&#35299;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65289;&#21644;O(&#949;^(-4))&#65288;&#23545;&#20110;&#27714;&#35299;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study zeroth-order algorithms for nonconvex minimax problems with coupled linear constraints under the deterministic and stochastic settings, which have attracted wide attention in machine learning, signal processing and many other fields in recent years, e.g., adversarial attacks in resource allocation problems and network flow problems etc. We propose two single-loop algorithms, namely the zero-order primal-dual alternating projected gradient (ZO-PDAPG) algorithm and the zero-order regularized momentum primal-dual projected gradient algorithm (ZO-RMPDPG), for solving deterministic and stochastic nonconvex-(strongly) concave minimax problems with coupled linear constraints. The iteration complexity of the two proposed algorithms to obtain an $\varepsilon$-stationary point are proved to be $\mathcal{O}(\varepsilon ^{-2})$ (resp. $\mathcal{O}(\varepsilon ^{-4})$) for solving nonconvex-strongly concave (resp. nonconvex-concave) minimax problems with coupled linear const
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#20999;&#32447;&#31354;&#38388;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#26469;&#25511;&#21046;&#20998;&#24067;&#20559;&#31227;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#25311;&#32467;&#26524;&#30340;&#31934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.09259</link><description>&lt;p&gt;
&#32531;&#35299;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;
&lt;/p&gt;
&lt;p&gt;
Mitigating distribution shift in machine learning-augmented hybrid simulation. (arXiv:2401.09259v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#20999;&#32447;&#31354;&#38388;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#26469;&#25511;&#21046;&#20998;&#24067;&#20559;&#31227;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#25311;&#32467;&#26524;&#30340;&#31934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#20854;&#20013;&#27169;&#25311;&#31639;&#27861;&#30340;&#37096;&#20998;&#34987;&#25968;&#25454;&#39537;&#21160;&#30340;&#26367;&#20195;&#27169;&#22411;&#21462;&#20195;&#12290;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#26469;&#29702;&#35299;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#38382;&#39064;&#30340;&#32467;&#26500;&#65292;&#20197;&#21450;&#30456;&#20851;&#30340;&#20998;&#24067;&#20559;&#31227;&#30340;&#21407;&#22240;&#21644;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#25968;&#20540;&#21644;&#29702;&#35770;&#19978;&#23637;&#31034;&#20102;&#20998;&#24067;&#20559;&#31227;&#19982;&#27169;&#25311;&#35823;&#24046;&#30340;&#30456;&#20851;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20999;&#32447;&#31354;&#38388;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#30340;&#31616;&#21333;&#26041;&#27861;&#26469;&#25511;&#21046;&#20998;&#24067;&#20559;&#31227;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#25311;&#32467;&#26524;&#30340;&#38271;&#26399;&#31934;&#30830;&#24615;&#12290;&#22312;&#32447;&#24615;&#21160;&#21147;&#23398;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35814;&#23613;&#30340;&#29702;&#35770;&#20998;&#26512;&#26469;&#37327;&#21270;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#21253;&#25324;&#27169;&#25311;&#37096;&#20998;&#24050;&#30693;&#30340;&#21453;&#24212;&#25193;&#25955;&#26041;&#31243;&#20197;&#21450;&#20351;&#29992;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#25237;&#24433;&#26041;&#27861;&#27714;&#35299;Navier-Stokes&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of distribution shift generally arising in machine-learning augmented hybrid simulation, where parts of simulation algorithms are replaced by data-driven surrogates. We first establish a mathematical framework to understand the structure of machine-learning augmented hybrid simulation problems, and the cause and effect of the associated distribution shift. We show correlations between distribution shift and simulation error both numerically and theoretically. Then, we propose a simple methodology based on tangent-space regularized estimator to control the distribution shift, thereby improving the long-term accuracy of the simulation results. In the linear dynamics case, we provide a thorough theoretical analysis to quantify the effectiveness of the proposed method. Moreover, we conduct several numerical experiments, including simulating a partially known reaction-diffusion equation and solving Navier-Stokes equations using the projection method with a data-driven p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.05857</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#21487;&#20197;&#34987;&#21098;&#26525;&#21040;&#22810;&#20040;&#31232;&#30095;&#65306;&#20960;&#20309;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Sparse Can We Prune A Deep Network: A Geometric Viewpoint. (arXiv:2306.05857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#20043;&#19968;&#12290;&#34429;&#28982;&#23427;&#21487;&#20197;&#25552;&#20379;&#20986;&#33394;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20294;&#21516;&#26102;&#20063;&#24378;&#21152;&#20102;&#37325;&#22823;&#30340;&#23384;&#20648;&#36127;&#25285;&#65292;&#22240;&#27492;&#26377;&#24517;&#35201;&#30740;&#31350;&#32593;&#32476;&#21098;&#26525;&#12290;&#19968;&#20010;&#33258;&#28982;&#32780;&#22522;&#26412;&#30340;&#38382;&#39064;&#26159;&#65306;&#25105;&#20204;&#33021;&#21098;&#26525;&#19968;&#20010;&#28145;&#24230;&#32593;&#32476;&#21040;&#22810;&#20040;&#31232;&#30095;&#65288;&#20960;&#20046;&#19981;&#24433;&#21709;&#24615;&#33021;&#65289;&#65311;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#37319;&#29992;&#20102;&#31532;&#19968;&#21407;&#29702;&#26041;&#27861;&#65292;&#20855;&#20307;&#22320;&#65292;&#21482;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25105;&#20204;&#33021;&#22815;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#25551;&#36848;&#21098;&#26525;&#27604;&#29575;&#30340;&#23574;&#38160;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#23545;&#24212;&#20110;&#21487;&#34892;&#21644;&#19981;&#21487;&#34892;&#20043;&#38388;&#30340;&#36793;&#30028;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#65292;&#36825;&#20123;&#20984;&#20307;&#26159;&#30001;$l_1$-&#35268;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#24471;&#20986;&#30340;&#65292;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21098;&#26525;&#36807;&#31243;&#20013;&#21442;&#25968;&#30340;&#20998;&#24067;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparameterization constitutes one of the most significant hallmarks of deep neural networks. Though it can offer the advantage of outstanding generalization performance, it meanwhile imposes substantial storage burden, thus necessitating the study of network pruning. A natural and fundamental question is: How sparse can we prune a deep network (with almost no hurt on the performance)? To address this problem, in this work we take a first principles approach, specifically, by merely enforcing the sparsity constraint on the original loss function, we're able to characterize the sharp phase transition point of pruning ratio, which corresponds to the boundary between the feasible and the infeasible, from the perspective of high-dimensional geometry. It turns out that the phase transition point of pruning ratio equals the squared Gaussian width of some convex body resulting from the $l_1$-regularized loss function, normalized by the original dimension of parameters. As a byproduct, we pr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#65292;&#31034;&#20363;&#35777;&#26126;&#20854;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20855;&#26377;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2208.02814</link><description>&lt;p&gt;
&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal Risk Control. (arXiv:2208.02814v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.02814
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#65292;&#31034;&#20363;&#35777;&#26126;&#20854;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20855;&#26377;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#25512;&#24191;&#33267;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;&#35813;&#31639;&#27861;&#23558;&#20998;&#35010;&#31526;&#21512;&#24615;&#39044;&#27979;&#21450;&#20854;&#35206;&#30422;&#20445;&#35777;&#36827;&#34892;&#20102;&#27867;&#21270;&#12290;&#31867;&#20284;&#20110;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#22312;$\mathcal{O}(1/n)$&#22240;&#23376;&#20869;&#20445;&#25345;&#32039;&#23494;&#24615;&#12290;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#31034;&#20363;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#22312;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\mathcal{O}(1/n)$ factor. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.
&lt;/p&gt;</description></item></channel></rss>