<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#20013;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38544;&#24615;&#20559;&#24046;&#20197;&#21450;&#20854;&#25910;&#25947;&#36895;&#29575;&#65292;&#36890;&#36807;&#35777;&#26126;&#22312;&#29305;&#23450;&#25968;&#25454;&#35774;&#32622;&#19979;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.05738</link><description>&lt;p&gt;
&#38544;&#24615;&#20559;&#24046;&#19982;&#33258;&#27880;&#24847;&#21147;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias and Fast Convergence Rates for Self-attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05738
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#20013;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38544;&#24615;&#20559;&#24046;&#20197;&#21450;&#20854;&#25910;&#25947;&#36895;&#29575;&#65292;&#36890;&#36807;&#35777;&#26126;&#22312;&#29305;&#23450;&#25968;&#25454;&#35774;&#32622;&#19979;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#26159;transformer&#30340;&#26680;&#24515;&#26426;&#21046;&#65292;&#23427;&#20351;&#20854;&#19982;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#26377;&#25152;&#21306;&#21035;&#65292;&#24182;&#39537;&#21160;&#20854;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#24320;&#21457;&#33258;&#27880;&#24847;&#21147;&#30340;&#22522;&#26412;&#20248;&#21270;&#21407;&#21017;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#35757;&#32451;&#20855;&#26377;&#22266;&#23450;&#32447;&#24615;&#35299;&#30721;&#22120;&#30340;&#33258;&#27880;&#24847;&#21147;&#23618;&#22312;&#20108;&#20803;&#20998;&#31867;&#20013;&#30340;&#38544;&#24615;&#20559;&#24046;&#12290;&#21463;&#21040;&#22312;&#21487;&#20998;&#31163;&#25968;&#25454;&#19978;&#32447;&#24615;&#36923;&#36753;&#22238;&#24402;&#20013;GD&#30340;&#30740;&#31350;&#21551;&#21457;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#38543;&#30528;&#36845;&#20195;&#27425;&#25968;t&#26080;&#38480;&#25509;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38190;-&#26597;&#35810;&#30697;&#38453;W_t&#22312;&#23616;&#37096;&#19978;&#65288;&#30456;&#23545;&#20110;&#21021;&#22987;&#21270;&#26041;&#21521;&#65289;&#25910;&#25947;&#21040;&#19968;&#20010;&#30828;&#36793;&#30028;&#25903;&#25345;&#21521;&#37327;&#26426;&#35299;W_mm&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#22235;&#20010;&#26041;&#38754;&#22686;&#24378;&#20102;&#36825;&#20010;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#38750;&#24179;&#20961;&#30340;&#25968;&#25454;&#35774;&#32622;&#65292;&#23545;&#20110;&#36825;&#20123;&#35774;&#32622;&#65292;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25581;&#31034;&#20102;&#20248;&#21270;&#31354;&#38388;&#30340;&#29305;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#65292;&#24182;&#37327;&#21270;&#20102;&#31232;&#30095;&#21270;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-attention, the core mechanism of transformers, distinguishes them from traditional neural networks and drives their outstanding performance. Towards developing the fundamental optimization principles of self-attention, we investigate the implicit bias of gradient descent (GD) in training a self-attention layer with fixed linear decoder in binary classification. Drawing inspiration from the study of GD in linear logistic regression over separable data, recent work demonstrates that as the number of iterations $t$ approaches infinity, the key-query matrix $W_t$ converges locally (with respect to the initialization direction) to a hard-margin SVM solution $W_{mm}$. Our work enhances this result in four aspects. Firstly, we identify non-trivial data settings for which convergence is provably global, thus shedding light on the optimization landscape. Secondly, we provide the first finite-time convergence rate for $W_t$ to $W_{mm}$, along with quantifying the rate of sparsification in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;&#31639;&#27861;&#65288;D-SOBA&#65289;&#65292;&#39318;&#27425;&#38416;&#26126;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#22312;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2402.03167</link><description>&lt;p&gt;
&#22270;&#19978;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;: &#26080;&#29615;&#31639;&#27861;&#26356;&#26032;&#21644;&#30636;&#24577;&#36845;&#20195;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Decentralized Bilevel Optimization over Graphs: Loopless Algorithmic Update and Transient Iteration Complexity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03167
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#20248;&#21270;&#31639;&#27861;&#65288;D-SOBA&#65289;&#65292;&#39318;&#27425;&#38416;&#26126;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#22312;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21452;&#32423;&#20248;&#21270;&#65288;SBO&#65289;&#22312;&#22788;&#29702;&#23884;&#22871;&#32467;&#26500;&#26041;&#38754;&#30340;&#22810;&#26679;&#24615;&#20351;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#20026;&#20102;&#35299;&#20915;&#22823;&#35268;&#27169;SBO&#65292;&#21435;&#20013;&#24515;&#21270;&#26041;&#27861;&#20316;&#20026;&#26377;&#25928;&#30340;&#33539;&#20363;&#20986;&#29616;&#65292;&#20854;&#20013;&#33410;&#28857;&#19982;&#30452;&#25509;&#30456;&#37051;&#33410;&#28857;&#36827;&#34892;&#36890;&#20449;&#65292;&#26080;&#38656;&#20013;&#22830;&#26381;&#21153;&#22120;&#65292;&#20174;&#32780;&#25552;&#39640;&#36890;&#20449;&#25928;&#29575;&#21644;&#22686;&#24378;&#31639;&#27861;&#30340;&#31283;&#20581;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#21435;&#20013;&#24515;&#21270;SBO&#31639;&#27861;&#38754;&#20020;&#25361;&#25112;&#65292;&#21253;&#25324;&#26114;&#36149;&#30340;&#20869;&#37096;&#24490;&#29615;&#26356;&#26032;&#21644;&#23545;&#32593;&#32476;&#25299;&#25169;&#12289;&#25968;&#25454;&#24322;&#26500;&#24615;&#21644;&#23884;&#22871;&#21452;&#32423;&#31639;&#27861;&#32467;&#26500;&#30340;&#24433;&#21709;&#19981;&#26126;&#30830;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#30340;&#21435;&#20013;&#24515;&#21270;SBO&#65288;D-SOBA&#65289;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#20854;&#30636;&#24577;&#36845;&#20195;&#22797;&#26434;&#24615;&#65292;&#39318;&#27425;&#28548;&#28165;&#20102;&#32593;&#32476;&#25299;&#25169;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#23545;&#21435;&#20013;&#24515;&#21270;&#21452;&#32423;&#31639;&#27861;&#30340;&#20849;&#21516;&#24433;&#21709;&#12290;D-SOBA&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#28176;&#36817;&#36895;&#29575;&#12289;&#28176;&#36817;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#21644;&#30636;&#24577;&#26799;&#24230;/&#28023;&#26862;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic bilevel optimization (SBO) is becoming increasingly essential in machine learning due to its versatility in handling nested structures. To address large-scale SBO, decentralized approaches have emerged as effective paradigms in which nodes communicate with immediate neighbors without a central server, thereby improving communication efficiency and enhancing algorithmic robustness. However, current decentralized SBO algorithms face challenges, including expensive inner-loop updates and unclear understanding of the influence of network topology, data heterogeneity, and the nested bilevel algorithmic structures. In this paper, we introduce a single-loop decentralized SBO (D-SOBA) algorithm and establish its transient iteration complexity, which, for the first time, clarifies the joint influence of network topology and data heterogeneity on decentralized bilevel algorithms. D-SOBA achieves the state-of-the-art asymptotic rate, asymptotic gradient/Hessian complexity, and transien
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22240;&#26524;&#21457;&#29616;&#26694;&#26550;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#39044;&#35757;&#32451;&#19982;&#32463;&#20856;&#21457;&#29616;&#31639;&#27861;&#30340;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#12289;&#20934;&#30830;&#22320;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#26356;&#22909;&#30340;&#34920;&#29616;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.01929</link><description>&lt;p&gt;
&#26679;&#26412;&#12289;&#20272;&#35745;&#12289;&#32858;&#21512;&#65306;&#22240;&#26524;&#21457;&#29616;&#22522;&#30784;&#27169;&#22411;&#30340;&#19968;&#31181;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample, estimate, aggregate: A recipe for causal discovery foundation models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22240;&#26524;&#21457;&#29616;&#26694;&#26550;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#39044;&#35757;&#32451;&#19982;&#32463;&#20856;&#21457;&#29616;&#31639;&#27861;&#30340;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#12289;&#20934;&#30830;&#22320;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#26356;&#22909;&#30340;&#34920;&#29616;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#26159;&#20174;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#30340;&#20219;&#21153;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;&#31185;&#23398;&#30740;&#31350;&#12289;&#25351;&#23548;&#20915;&#31574;&#31561;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#30340;&#27599;&#20010;&#25968;&#25454;&#38598;&#30340;&#29305;&#24615;&#20351;&#23427;&#20204;&#21464;&#24471;&#32531;&#24930;&#12289;&#38656;&#35201;&#22823;&#37327;&#25968;&#25454;&#24182;&#19988;&#33030;&#24369;&#12290;&#21463;&#22522;&#30784;&#27169;&#22411;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21457;&#29616;&#26694;&#26550;&#65292;&#20854;&#20013;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#39044;&#35757;&#32451;&#29992;&#20110;&#22788;&#29702;&#22312;&#36739;&#23567;&#30340;&#21464;&#37327;&#23376;&#38598;&#19978;&#36816;&#34892;&#30340;&#32463;&#20856;&#21457;&#29616;&#31639;&#27861;&#30340;&#39044;&#27979;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#21033;&#29992;&#20197;&#19979;&#35266;&#23519;&#32467;&#26524;&#65306;&#32463;&#20856;&#31639;&#27861;&#30340;&#36755;&#20986;&#22312;&#23567;&#38382;&#39064;&#19978;&#35745;&#31639;&#36895;&#24230;&#24555;&#65292;&#23545;&#65288;&#36793;&#38469;&#65289;&#25968;&#25454;&#32467;&#26500;&#20855;&#26377;&#20449;&#24687;&#37327;&#65292;&#19988;&#23427;&#20204;&#30340;&#36755;&#20986;&#32467;&#26500;&#20316;&#20026;&#23545;&#35937;&#22312;&#25968;&#25454;&#38598;&#20043;&#38388;&#21487;&#20197;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21487;&#20197;&#25512;&#24191;&#21040;&#35757;&#32451;&#26399;&#38388;&#26410;&#35265;&#36807;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#65292;&#24182;&#19988;&#25552;&#20379;&#27604;&#29616;&#26377;&#27169;&#22411;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#25512;&#29702;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery, the task of inferring causal structure from data, promises to accelerate scientific research, inform policy making, and more. However, the per-dataset nature of existing causal discovery algorithms renders them slow, data hungry, and brittle. Inspired by foundation models, we propose a causal discovery framework where a deep learning model is pretrained to resolve predictions from classical discovery algorithms run over smaller subsets of variables. This method is enabled by the observations that the outputs from classical algorithms are fast to compute for small problems, informative of (marginal) data structure, and their structure outputs as objects remain comparable across datasets. Our method achieves state-of-the-art performance on synthetic and realistic datasets, generalizes to data generating mechanisms not seen during training, and offers inference speeds that are orders of magnitude faster than existing models.
&lt;/p&gt;</description></item><item><title>&#36825;&#20221;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#19979;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;&#20197;&#21450;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65292;&#24182;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#21644;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#26469;&#31163;&#25955;&#21270;&#31215;&#20998;&#36816;&#31639;&#31526;&#12290;</title><link>http://arxiv.org/abs/2401.06740</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#26399;&#26435;&#23450;&#20215;&#30340;&#28145;&#24230;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models. (arXiv:2401.06740v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06740
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#19979;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;&#20197;&#21450;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65292;&#24182;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#21644;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#26469;&#31163;&#25955;&#21270;&#31215;&#20998;&#36816;&#31639;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#21160;&#24577;&#19979;&#30340;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#12290;&#23558;&#26399;&#26435;&#23450;&#20215;&#38382;&#39064;&#34920;&#36848;&#20026;&#19968;&#20010;&#20559;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26102;&#38388;&#27493;&#27861;&#36827;&#34892;&#36817;&#20284;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#28145;&#24230;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#36880;&#27493;&#36924;&#36817;&#12290;&#31215;&#20998;&#36816;&#31639;&#31526;&#36890;&#36807;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#31163;&#25955;&#21270;&#65306;a&#65289;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#65292;&#37319;&#29992;&#22855;&#24322;&#20540;&#20998;&#35299;&#20135;&#29983;&#30340;&#23616;&#37096;&#22352;&#26631;&#36724;&#65292;&#24182;&#19988;b&#65289;&#36890;&#36807;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#12290;&#20851;&#38190;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;ANN&#30340;&#26500;&#36896;&#30830;&#20445;&#20102;&#35299;&#20915;&#26041;&#26696;&#22312;&#26631;&#30340;&#36164;&#20135;&#36739;&#22823;&#20540;&#26102;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#19988;&#19982;&#35299;&#20915;&#26041;&#26696;&#20808;&#39564;&#24050;&#30693;&#30340;&#23450;&#24615;&#29305;&#24615;&#30456;&#19968;&#33268;&#36755;&#20986;&#12290;&#23545;&#26041;&#27861;&#32500;&#24230;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assesse
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12781</link><description>&lt;p&gt;
&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#20195;&#32479;&#35745;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#38656;&#35201;&#22312;&#25935;&#24863;&#29992;&#25143;&#25968;&#25454;&#19978;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#12290;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#19968;&#31181;&#27491;&#24335;&#30340;&#20445;&#35777;&#65292;&#21363;&#20010;&#20307;&#29992;&#25143;&#20449;&#24687;&#19981;&#20250;&#27844;&#38706;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21521;&#20445;&#23494;&#25968;&#25454;&#27880;&#20837;&#26657;&#20934;&#30340;&#22122;&#22768;&#65292;&#20174;&#32780;&#20135;&#29983;&#38544;&#31169;&#20445;&#25252;&#30340;&#25968;&#25454;&#38598;&#25110;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#20250;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#65292;&#38590;&#20197;&#23545;&#22522;&#30784;&#26426;&#23494;&#25968;&#25454;&#30340;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#30340;&#25512;&#29702;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#38598;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#20316;&#20026;&#19968;&#32452;&#28789;&#27963;&#30340;&#20998;&#24067;&#26469;&#36817;&#20284;&#32473;&#23450;&#35266;&#27979;&#21040;&#30340;&#31169;&#26377;&#26597;&#35810;&#32467;&#26524;&#30340;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#20256;&#26579;&#30149;&#27169;&#22411;&#19979;&#30340;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20197;&#21450;&#26222;&#36890;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#19978;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many modern statistical analysis and machine learning applications require training models on sensitive user data. Differential privacy provides a formal guarantee that individual-level information about users does not leak. In this framework, randomized algorithms inject calibrated noise into the confidential data, resulting in privacy-protected datasets or queries. However, restricting access to only the privatized data during statistical analysis makes it computationally challenging to perform valid inferences on parameters underlying the confidential data. In this work, we propose simulation-based inference methods from privacy-protected datasets. Specifically, we use neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and on ordinary linear regression models. Illustra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10545</link><description>&lt;p&gt;
&#20248;&#21270;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#19982;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;
&lt;/p&gt;
&lt;p&gt;
Optimal vintage factor analysis with deflation varimax. (arXiv:2310.10545v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#26088;&#22312;&#39318;&#20808;&#25214;&#21040;&#21407;&#22987;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#23547;&#27714;&#26059;&#36716;&#65292;&#20351;&#26059;&#36716;&#21518;&#30340;&#20302;&#32500;&#34920;&#31034;&#20855;&#26377;&#31185;&#23398;&#24847;&#20041;&#12290;&#23613;&#31649;Principal Component Analysis (PCA) followed by the varimax rotation&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#65292;&#20294;&#30001;&#20110;varimax rotation&#38656;&#35201;&#22312;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#19978;&#35299;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22240;&#27492;&#24456;&#38590;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#34892;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#30340;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#36807;&#31243;&#12290;&#38500;&#20102;&#22312;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#21644;&#28789;&#27963;&#24615;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#33021;&#22312;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#23545;&#25152;&#25552;&#20986;&#30340;&#36807;&#31243;&#36827;&#34892;&#23436;&#20840;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;PCA&#20043;&#21518;&#37319;&#29992;&#36825;&#31181;&#26032;&#30340;varimax&#26041;&#27861;&#20316;&#20026;&#31532;&#20108;&#27493;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#36825;&#20010;&#20004;&#27493;&#36807;&#31243;&#22312;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#22240;&#23376;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vintage factor analysis is one important type of factor analysis that aims to first find a low-dimensional representation of the original data, and then to seek a rotation such that the rotated low-dimensional representation is scientifically meaningful. Perhaps the most widely used vintage factor analysis is the Principal Component Analysis (PCA) followed by the varimax rotation. Despite its popularity, little theoretical guarantee can be provided mainly because varimax rotation requires to solve a non-convex optimization over the set of orthogonal matrices.  In this paper, we propose a deflation varimax procedure that solves each row of an orthogonal matrix sequentially. In addition to its net computational gain and flexibility, we are able to fully establish theoretical guarantees for the proposed procedure in a broad context.  Adopting this new varimax approach as the second step after PCA, we further analyze this two step procedure under a general class of factor models. Our resul
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;ARMOR_D&#26469;&#21152;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#36827;&#34892;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;ARMOR_D&#26041;&#27861;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#20013;&#33021;&#22815;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.03791</link><description>&lt;p&gt;
&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#26469;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences. (arXiv:2309.03791v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;ARMOR_D&#26469;&#21152;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#36827;&#34892;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;ARMOR_D&#26041;&#27861;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#20013;&#33021;&#22815;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;ARMOR_D&#26041;&#27861;&#20316;&#20026;&#22686;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#31867;&#65292;&#36890;&#36807;&#20449;&#24687;&#24046;&#24322;&#21644;&#26368;&#20248;&#20256;&#36755;&#25104;&#26412;&#20043;&#38388;&#30340;infimal&#21367;&#31215;&#26500;&#24314;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#22686;&#24378;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#65292;&#36825;&#34987;&#31216;&#20026;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#12290;&#20316;&#20026;&#26500;&#24314;&#23545;&#25239;&#26679;&#26412;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#26679;&#26412;&#26681;&#25454;&#26368;&#20248;&#20256;&#36755;&#25104;&#26412;&#36827;&#34892;&#20256;&#36755;&#65292;&#24182;&#26681;&#25454;&#20449;&#24687;&#24046;&#24322;&#36827;&#34892;&#37325;&#26032;&#21152;&#26435;&#12290;&#25105;&#20204;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#21457;&#29616;&#22312;&#22686;&#24378;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#26041;&#38754;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;ARMOR_D&#22312;FGSM&#25915;&#20987;&#19979;&#30340;robustified&#20934;&#30830;&#29575;&#36798;&#21040;98.29%&#65292;&#22312;&#20854;&#20182;&#25915;&#20987;&#19979;&#36798;&#21040;98.18%&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\%$ against $FGSM$ and $98.18\%$ aga
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24182;&#19988;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24314;&#27169;&#20102;&#38543;&#26426;&#23545;&#35937;&#65292;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#24180;&#40836;&#20998;&#24067;&#21644;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2207.05442</link><description>&lt;p&gt;
Wasserstein&#22810;&#20803;&#33258;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#24314;&#27169;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#21450;&#20854;&#22312;&#22270;&#24418;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning. (arXiv:2207.05442v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.05442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24182;&#19988;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24314;&#27169;&#20102;&#38543;&#26426;&#23545;&#35937;&#65292;&#25552;&#20379;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#24180;&#40836;&#20998;&#24067;&#21644;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#32479;&#35745;&#20998;&#26512;&#22810;&#20803;&#20998;&#24067;&#26102;&#38388;&#24207;&#21015;&#12290;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#21253;&#25324;&#19968;&#32452;&#22312;&#23454;&#32447;&#26377;&#30028;&#38388;&#38548;&#19978;&#25903;&#25345;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#22810;&#20010;&#31995;&#21015;&#65292;&#24182;&#19988;&#34987;&#19981;&#21516;&#26102;&#38388;&#30636;&#38388;&#25152;&#32034;&#24341;&#12290;&#27010;&#29575;&#27979;&#24230;&#34987;&#24314;&#27169;&#20026;Wasserstein&#31354;&#38388;&#20013;&#30340;&#38543;&#26426;&#23545;&#35937;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;Lebesgue&#27979;&#24230;&#30340;&#20999;&#31354;&#38388;&#20013;&#24314;&#31435;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#39318;&#20808;&#23545;&#25152;&#26377;&#21407;&#22987;&#27979;&#24230;&#36827;&#34892;&#23621;&#20013;&#22788;&#29702;&#65292;&#20197;&#20415;&#23427;&#20204;&#30340;Fr&#233;chet&#24179;&#22343;&#20540;&#25104;&#20026;Lebesgue&#27979;&#24230;&#12290;&#21033;&#29992;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#31995;&#32479;&#30340;&#29702;&#35770;&#65292;&#25552;&#20379;&#20102;&#36825;&#26679;&#19968;&#20010;&#27169;&#22411;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#24179;&#31283;&#24615;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#27169;&#22411;&#31995;&#25968;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#38500;&#20102;&#23545;&#27169;&#25311;&#25968;&#25454;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#36824;&#20351;&#29992;&#20004;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#27169;&#22411;&#28436;&#31034;&#65306;&#19968;&#20010;&#26159;&#19981;&#21516;&#22269;&#23478;&#24180;&#40836;&#20998;&#24067;&#30340;&#35266;&#23519;&#25968;&#25454;&#38598;&#65292;&#21478;&#19968;&#20010;&#26159;&#24052;&#40654;&#33258;&#34892;&#36710;&#20849;&#20139;&#32593;&#32476;&#30340;&#35266;&#23519;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new auto-regressive model for the statistical analysis of multivariate distributional time series. The data of interest consist of a collection of multiple series of probability measures supported over a bounded interval of the real line, and that are indexed by distinct time instants. The probability measures are modelled as random objects in the Wasserstein space. We establish the auto-regressive model in the tangent space at the Lebesgue measure by first centering all the raw measures so that their Fr\'echet means turn to be the Lebesgue measure. Using the theory of iterated random function systems, results on the existence, uniqueness and stationarity of the solution of such a model are provided. We also propose a consistent estimator for the model coefficient. In addition to the analysis of simulated data, the proposed model is illustrated with two real data sets made of observations from age distribution in different countries and bike sharing network in Paris. Final
&lt;/p&gt;</description></item></channel></rss>