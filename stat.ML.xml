<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20855;&#26377;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#25216;&#26415;&#12289;&#22810;&#31181;&#36866;&#24212;&#27169;&#22411;&#21644;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#31561;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2112.14249</link><description>&lt;p&gt;
&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65306;&#38271;&#26399;&#12289;&#20013;&#20171;&#21644;&#26102;&#21464;&#27835;&#30103;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Nested Nonparametric Instrumental Variable Regression: Long Term, Mediated, and Time Varying Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2112.14249
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20855;&#26377;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#25216;&#26415;&#12289;&#22810;&#31181;&#36866;&#24212;&#27169;&#22411;&#21644;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#31561;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#20013;&#30340;&#20960;&#20010;&#22240;&#26524;&#21442;&#25968;&#26159;&#31216;&#20026;&#23884;&#22871;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;&#65288;nested NPIV&#65289;&#30340;&#20989;&#25968;&#30340;&#26631;&#37327;&#24635;&#32467;&#12290;&#20363;&#22914;&#65292;&#20351;&#29992;&#20195;&#29702;&#21464;&#37327;&#35782;&#21035;&#20986;&#38271;&#26399;&#12289;&#20013;&#20171;&#21644;&#26102;&#21464;&#27835;&#30103;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#20284;&#20046;&#19981;&#23384;&#22312;&#20851;&#20110;&#23884;&#22871;NPIV&#30340;&#20808;&#21069;&#20272;&#35745;&#37327;&#25110;&#20445;&#35777;&#65292;&#36825;&#26679;&#23601;&#26080;&#27861;&#28789;&#27963;&#22320;&#20272;&#35745;&#21644;&#25512;&#26029;&#36825;&#20123;&#22240;&#26524;&#21442;&#25968;&#12290;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#30001;&#20110;&#23884;&#22871;&#36870;&#38382;&#39064;&#32780;&#23548;&#33268;&#30340;&#22797;&#21512;&#30149;&#24577;&#24615;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#23884;&#22871;NPIV&#30340;&#23545;&#25239;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#22240;&#26524;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#20855;&#26377;&#19977;&#20010;&#26174;&#33879;&#29305;&#24449;&#65306;&#65288;i&#65289;&#24341;&#20837;&#38480;&#21046;&#30149;&#24577;&#24615;&#22797;&#21512;&#30340;&#25216;&#26415;&#65307;&#65288;ii&#65289;&#36866;&#24212;&#31070;&#32463;&#32593;&#32476;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65307;&#65288;iii&#65289;&#25193;&#23637;&#21040;&#22240;&#26524;&#20989;&#25968;&#65292;&#20363;&#22914;&#38271;&#26399;&#24322;&#36136;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2112.14249v3 Announce Type: replace-cross  Abstract: Several causal parameters in short panel data models are scalar summaries of a function called a nested nonparametric instrumental variable regression (nested NPIV). Examples include long term, mediated, and time varying treatment effects identified using proxy variables. However, it appears that no prior estimators or guarantees for nested NPIV exist, preventing flexible estimation and inference for these causal parameters. A major challenge is compounding ill posedness due to the nested inverse problems. We analyze adversarial estimators of nested NPIV, and provide sufficient conditions for efficient inference on the causal parameter. Our nonasymptotic analysis has three salient features: (i) introducing techniques that limit how ill posedness compounds; (ii) accommodating neural networks, random forests, and reproducing kernel Hilbert spaces; and (iii) extending to causal functions, e.g. long term heterogeneous treatment eff
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2401.14283</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#39044;&#27979;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;
&lt;/p&gt;
&lt;p&gt;
Information Leakage Detection through Approximate Bayes-optimal Prediction. (arXiv:2401.14283v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20170;&#22825;&#30340;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#19990;&#30028;&#20013;&#65292;&#20844;&#24320;&#21487;&#33719;&#24471;&#30340;&#20449;&#24687;&#30340;&#22686;&#21152;&#21152;&#21095;&#20102;&#20449;&#24687;&#27844;&#28431;&#65288;IL&#65289;&#30340;&#25361;&#25112;&#65292;&#24341;&#21457;&#20102;&#23433;&#20840;&#38382;&#39064;&#12290;IL&#28041;&#21450;&#36890;&#36807;&#31995;&#32479;&#30340;&#21487;&#35266;&#23519;&#20449;&#24687;&#26080;&#24847;&#22320;&#23558;&#31192;&#23494;&#65288;&#25935;&#24863;&#65289;&#20449;&#24687;&#26292;&#38706;&#32473;&#26410;&#32463;&#25480;&#26435;&#30340;&#26041;&#65292;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;&#21487;&#35266;&#23519;&#20449;&#24687;&#21644;&#31192;&#23494;&#20449;&#24687;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#26469;&#26816;&#27979;IL&#65292;&#38754;&#20020;&#32500;&#24230;&#28798;&#38590;&#12289;&#25910;&#25947;&#12289;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;MI&#20272;&#35745;&#38169;&#35823;&#31561;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#26032;&#20852;&#30340;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#22312;&#20108;&#36827;&#21046;&#31995;&#32479;&#25935;&#24863;&#20449;&#24687;&#30340;&#26816;&#27979;&#19978;&#26377;&#25928;&#65292;&#20294;&#32570;&#20047;&#19968;&#20010;&#20840;&#38754;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#24314;&#31435;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;IL&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;MI&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's data-driven world, the proliferation of publicly available information intensifies the challenge of information leakage (IL), raising security concerns. IL involves unintentionally exposing secret (sensitive) information to unauthorized parties via systems' observable information. Conventional statistical approaches, which estimate mutual information (MI) between observable and secret information for detecting IL, face challenges such as the curse of dimensionality, convergence, computational complexity, and MI misestimation. Furthermore, emerging supervised machine learning (ML) methods, though effective, are limited to binary system-sensitive information and lack a comprehensive theoretical framework. To address these limitations, we establish a theoretical framework using statistical learning theory and information theory to accurately quantify and detect IL. We demonstrate that MI can be accurately estimated by approximating the log-loss and accuracy of the Bayes predict
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#12289;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#35758;&#20102;&#19968;&#31181;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#25910;&#25947;&#36895;&#24230;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06738</link><description>&lt;p&gt;
&#22122;&#22768;&#33258;&#36866;&#24212;&#65288;&#21152;&#36895;&#65289;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;
&lt;/p&gt;
&lt;p&gt;
Noise-adaptive (Accelerated) Stochastic Heavy-Ball Momentum. (arXiv:2401.06738v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#12289;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#35758;&#20102;&#19968;&#31181;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#25910;&#25947;&#36895;&#24230;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#65292;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#65288;SHB&#65289;&#30340;&#25910;&#25947;&#24615;&#12290;Kidambi&#31561;&#20154;&#65288;2018&#65289;&#34920;&#26126;&#65292;&#23545;&#20110;&#20108;&#27425;&#20989;&#25968;&#65292;SHB&#65288;&#24102;&#26377;&#23567;&#25209;&#37327;&#65289;&#26080;&#27861;&#36798;&#21040;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#29468;&#24819;SHB&#30340;&#23454;&#38469;&#25910;&#30410;&#26159;&#23567;&#25209;&#37327;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#19968;&#23450;&#38408;&#20540;&#26102;&#65292;SHB&#21487;&#20197;&#33719;&#24471;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35777;&#23454;&#36825;&#19968;&#35266;&#28857;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#26465;&#20214;&#25968;&#20026;$\kappa$&#30340;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#26631;&#20934;&#27493;&#38271;&#21644;&#21160;&#37327;&#21442;&#25968;&#30340;SHB&#20855;&#26377;$O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$T$&#20026;&#36845;&#20195;&#27425;&#25968;&#65292;$\sigma^2$&#20026;&#38543;&#26426;&#26799;&#24230;&#30340;&#26041;&#24046;&#12290;&#20026;&#30830;&#20445;&#25910;&#25947;&#21040;&#26497;&#23567;&#20540;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#32467;&#26524;&#26159;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;$O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$&#36895;&#24230;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#24378;&#20984;&#20989;&#25968;&#65292;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the convergence of stochastic heavy ball (SHB) momentum in the smooth, strongly-convex setting. Kidambi et al. (2018) show that SHB (with small mini-batches) cannot attain an accelerated rate of convergence even for quadratics, and conjecture that the practical gain of SHB is a by-product of mini-batching. We substantiate this claim by showing that SHB can obtain an accelerated rate when the mini-batch size is larger than some threshold. In particular, for strongly-convex quadratics with condition number $\kappa$, we prove that SHB with the standard step-size and momentum parameters results in an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence rate, where $T$ is the number of iterations and $\sigma^2$ is the variance in the stochastic gradients. To ensure convergence to the minimizer, we propose a multi-stage approach that results in a noise-adaptive $O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$ rate. For general strongly-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.00098</link><description>&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#23398;&#20064;&#36827;&#34892;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Federated Learning with Differential Privacy for End-to-End Speech Recognition. (arXiv:2310.00098v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#31471;&#21040;&#31471;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#32447;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20294;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#39046;&#22495;&#20165;&#38480;&#20110;&#21021;&#27493;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#32852;&#37030;&#23398;&#20064;&#19981;&#33021;&#26412;&#36136;&#19978;&#20445;&#35777;&#29992;&#25143;&#38544;&#31169;&#65292;&#24182;&#38656;&#35201;&#24046;&#20998;&#38544;&#31169;&#26469;&#25552;&#20379;&#31283;&#20581;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36824;&#19981;&#28165;&#26970;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#20808;&#21069;&#24037;&#20316;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20026;&#32852;&#37030;&#23398;&#20064;&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;&#30340;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#22522;&#20934;&#65292;&#24182;&#24314;&#31435;&#31532;&#19968;&#20010;&#22522;&#32447;&#26469;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#32852;&#37030;&#23398;&#20064;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#30740;&#31350;&#65292;&#25506;&#32034;&#20102;&#26368;&#26032;&#30340;&#22823;&#22411;&#31471;&#21040;&#31471;Transformer&#27169;&#22411;&#30340;&#19981;&#21516;&#26041;&#38754;&#65306;&#26550;&#26500;&#35774;&#35745;&#65292;&#31181;&#23376;&#27169;&#22411;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#65292;&#39046;&#22495;&#36716;&#31227;&#65292;&#20197;&#21450;cohort&#22823;&#23567;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#21512;&#29702;&#30340;&#20013;&#22830;&#32858;&#21512;&#25968;&#37327;&#65292;&#25105;&#20204;&#33021;&#22815;&#35757;&#32451;&#20986;&#21363;&#20351;&#22312;&#24322;&#26500;&#25968;&#25454;&#12289;&#26469;&#33258;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#31181;&#23376;&#27169;&#22411;&#25110;&#26080;&#39044;&#20808;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#25509;&#36817;&#26368;&#20248;&#30340;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
While federated learning (FL) has recently emerged as a promising approach to train machine learning models, it is limited to only preliminary explorations in the domain of automatic speech recognition (ASR). Moreover, FL does not inherently guarantee user privacy and requires the use of differential privacy (DP) for robust privacy guarantees. However, we are not aware of prior work on applying DP to FL for ASR. In this paper, we aim to bridge this research gap by formulating an ASR benchmark for FL with DP and establishing the first baselines. First, we extend the existing research on FL for ASR by exploring different aspects of recent $\textit{large end-to-end transformer models}$: architecture design, seed models, data heterogeneity, domain shift, and impact of cohort size. With a $\textit{practical}$ number of central aggregations we are able to train $\textbf{FL models}$ that are \textbf{nearly optimal} even with heterogeneous data, a seed model from another domain, or no pre-trai
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#65292;&#24182;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#32447;&#24615;&#20551;&#35774;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#20379;&#36739;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13135</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#21487;&#21152;&#20540;&#20989;&#25968;&#65306;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#21450;&#20854;&#22312;&#22806;&#31185;&#25163;&#26415;&#24674;&#22797;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Additive Value Functions: Interpretable Reinforcement Learning with an Application to Surgical Recovery. (arXiv:2308.13135v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13135
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#65292;&#24182;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#32447;&#24615;&#20551;&#35774;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#20379;&#36739;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#12290;&#23398;&#20064;&#20381;&#38752;&#25968;&#23383;&#34920;&#22411;&#29305;&#24449;&#30340;&#26377;&#25928;&#33258;&#36866;&#24212;&#20020;&#24202;&#24178;&#39044;&#26159;&#21307;&#21153;&#20154;&#21592;&#37325;&#35270;&#30340;&#38382;&#39064;&#12290;&#22312;&#33034;&#26609;&#25163;&#26415;&#26041;&#38754;&#65292;&#20851;&#20110;&#24739;&#32773;&#36816;&#21160;&#33021;&#21147;&#24674;&#22797;&#30340;&#19981;&#21516;&#26415;&#21518;&#24674;&#22797;&#24314;&#35758;&#21487;&#33021;&#20250;&#23548;&#33268;&#24739;&#32773;&#24674;&#22797;&#31243;&#24230;&#30340;&#26174;&#33879;&#21464;&#21270;&#12290;&#34429;&#28982;&#24378;&#21270;&#23398;&#20064;&#22312;&#28216;&#25103;&#31561;&#39046;&#22495;&#21462;&#24471;&#20102;&#24191;&#27867;&#25104;&#21151;&#65292;&#20294;&#26368;&#36817;&#30340;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#40657;&#30418;&#26041;&#27861;&#65292;&#22914;&#31070;&#32463;&#32593;&#32476;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#38459;&#30861;&#20102;&#32771;&#23519;&#27599;&#20010;&#29305;&#24449;&#23545;&#20110;&#20135;&#29983;&#26368;&#32456;&#24314;&#35758;&#20915;&#31574;&#30340;&#36129;&#29486;&#12290;&#34429;&#28982;&#22312;&#32463;&#20856;&#31639;&#27861;&#65288;&#22914;&#26368;&#23567;&#20108;&#20056;&#31574;&#30053;&#36845;&#20195;&#65289;&#20013;&#21487;&#20197;&#36731;&#26494;&#25552;&#20379;&#36825;&#26679;&#30340;&#35299;&#37322;&#65292;&#20294;&#22522;&#26412;&#30340;&#32447;&#24615;&#20551;&#35774;&#38459;&#27490;&#20102;&#23398;&#20064;&#29305;&#24449;&#20043;&#38388;&#30340;&#39640;&#38454;&#28789;&#27963;&#20132;&#20114;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#25216;&#26415;&#26469;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#24182;&#33021;&#22815;&#24471;&#21040;&#35299;&#37322;&#24615;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a nonparametric additive model for estimating interpretable value functions in reinforcement learning. Learning effective adaptive clinical interventions that rely on digital phenotyping features is a major for concern medical practitioners. With respect to spine surgery, different post-operative recovery recommendations concerning patient mobilization can lead to significant variation in patient recovery. While reinforcement learning has achieved widespread success in domains such as games, recent methods heavily rely on black-box methods, such neural networks. Unfortunately, these methods hinder the ability of examining the contribution each feature makes in producing the final suggested decision. While such interpretations are easily provided in classical algorithms such as Least Squares Policy Iteration, basic linearity assumptions prevent learning higher-order flexible interactions between features. In this paper, we present a novel method that offers a flexible techniq
&lt;/p&gt;</description></item></channel></rss>