<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.04355</link><description>&lt;p&gt;
PQMass: &#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#30340;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#27010;&#29575;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04355
&lt;/p&gt;
&lt;p&gt;
PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#22522;&#20110;&#26679;&#26412;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#20272;&#35745;&#20004;&#20010;&#26679;&#26412;&#38598;&#21512;&#26469;&#33258;&#21516;&#19968;&#20998;&#24067;&#30340;&#27010;&#29575;&#65292;&#20026;&#35780;&#20272;&#21333;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#25110;&#27604;&#36739;&#22312;&#21516;&#19968;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#22810;&#20010;&#31454;&#20105;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#35745;&#19978;&#20005;&#26684;&#30340;&#26041;&#27861;&#12290;&#35813;&#27604;&#36739;&#21487;&#20197;&#36890;&#36807;&#23558;&#31354;&#38388;&#21010;&#20998;&#20026;&#38750;&#37325;&#21472;&#30340;&#21306;&#22495;&#24182;&#27604;&#36739;&#27599;&#20010;&#21306;&#22495;&#20013;&#30340;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#26469;&#36827;&#34892;&#12290;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#29983;&#25104;&#27169;&#22411;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#26679;&#26412;&#12290;&#23427;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#26080;&#38656;&#38477;&#32500;&#12290;&#26174;&#33879;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#20851;&#20110;&#30495;&#23454;&#20998;&#24067;&#23494;&#24230;&#30340;&#20551;&#35774;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#35757;&#32451;&#25110;&#25311;&#21512;&#20219;&#20309;&#36741;&#21161;&#27169;&#22411;&#12290;&#30456;&#21453;&#65292;&#23427;&#30528;&#37325;&#20110;&#36817;&#20284;&#35745;&#31639;&#23494;&#24230;&#30340;&#31215;&#20998;&#65288;&#27010;&#29575;&#36136;&#37327;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a comprehensive sample-based method for assessing the quality of generative models. The proposed approach enables the estimation of the probability that two sets of samples are drawn from the same distribution, providing a statistically rigorous method for assessing the performance of a single generative model or the comparison of multiple competing models trained on the same dataset. This comparison can be conducted by dividing the space into non-overlapping regions and comparing the number of data samples in each region. The method only requires samples from the generative model and the test data. It is capable of functioning directly on high-dimensional data, obviating the need for dimensionality reduction. Significantly, the proposed method does not depend on assumptions regarding the density of the true distribution, and it does not rely on training or fitting any auxiliary models. Instead, it focuses on approximating the integral of the density (probability mass) acros
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Sparse Gaussian Process attention (SGPA)&#26469;&#26657;&#20934;Transformer&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;SGPA-based Transformers&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.02444</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#26657;&#20934;Transformer
&lt;/p&gt;
&lt;p&gt;
Calibrating Transformers via Sparse Gaussian Processes. (arXiv:2303.02444v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02444
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Sparse Gaussian Process attention (SGPA)&#26469;&#26657;&#20934;Transformer&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;SGPA-based Transformers&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#27169;&#22411;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#35821;&#38899;&#35782;&#21035;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#24191;&#27867;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#23558;Transformer&#30340;&#25104;&#21151;&#25193;&#23637;&#21040;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#38656;&#35201;&#20934;&#30830;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#36739;&#23569;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#27880;&#24847;&#21147;&#65288;SGPA&#65289;&#65292;&#23427;&#30452;&#25509;&#22312;Transformer&#30340;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#22359;&#65288;MHA&#65289;&#30340;&#36755;&#20986;&#31354;&#38388;&#20013;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20197;&#26657;&#20934;&#20854;&#19981;&#30830;&#23450;&#24615;&#12290;&#23427;&#29992;&#19968;&#20010;&#26377;&#25928;&#30340;&#23545;&#31216;&#26680;&#26367;&#20195;&#20102;&#32553;&#25918;&#28857;&#31215;&#25805;&#20316;&#65292;&#24182;&#20351;&#29992;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#65288;SGP&#65289;&#25216;&#26415;&#26469;&#36817;&#20284;MHA&#36755;&#20986;&#30340;&#21518;&#39564;&#36807;&#31243;&#12290;&#32463;&#39564;&#19978;&#65292;&#22312;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#30340;&#19968;&#31995;&#21015;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#22522;&#20110;SGPA&#30340;Transformer&#27169;&#22411;&#23454;&#29616;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#26174;&#33879;&#25913;&#21892;&#20102;&#20869;&#20998;&#24067;&#26657;&#20934;&#21644;&#22806;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#21644;&#26816;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer models have achieved profound success in prediction tasks in a wide range of applications in natural language processing, speech recognition and computer vision. Extending Transformer's success to safety-critical domains requires calibrated uncertainty estimation which remains under-explored. To address this, we propose Sparse Gaussian Process attention (SGPA), which performs Bayesian inference directly in the output space of multi-head attention blocks (MHAs) in transformer to calibrate its uncertainty. It replaces the scaled dot-product operation with a valid symmetric kernel and uses sparse Gaussian processes (SGP) techniques to approximate the posterior processes of MHA outputs. Empirically, on a suite of prediction tasks on text, images and graphs, SGPA-based Transformers achieve competitive predictive accuracy, while noticeably improving both in-distribution calibration and out-of-distribution robustness and detection.
&lt;/p&gt;</description></item></channel></rss>