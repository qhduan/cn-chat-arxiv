<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;</title><link>http://arxiv.org/abs/2310.16945</link><description>&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection&#65288;CATE&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#22240;&#26524;Q&#38598;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16945
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#26159;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#29992;&#20110;CATE&#20272;&#35745;&#30340;&#27169;&#22411;&#65292;&#20294;&#30001;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#39033;&#38750;&#24120;&#26840;&#25163;&#30340;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#23454;&#35777;&#24037;&#20316;&#25552;&#20379;&#20102;&#26377;&#21033;&#20110;&#20855;&#26377;&#21452;&#37325;&#40065;&#26834;&#24615;&#36136;&#30340;&#20195;&#29702;&#25439;&#22833;&#24230;&#37327;&#21644;&#27169;&#22411;&#38598;&#25104;&#30340;&#35777;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#29702;&#35299;&#36824;&#19981;&#22815;&#12290;&#30452;&#25509;&#24212;&#29992;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20250;&#30001;&#20110;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#30340;&#38750;&#20984;&#24615;&#32780;&#23548;&#33268;&#27425;&#20248;&#30340;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#26377;&#20027;&#35201;CATE&#38598;&#25104;&#26041;&#27861;&#30340;&#36951;&#25022;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#30340;Q&#38598;&#25104;&#30340;&#26032;&#30340;CATE&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22240;&#26524;Q&#38598;&#25104;&#22312;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#30340;&#36951;&#25022;&#29575;&#19978;&#36798;&#21040;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#20540;&#20026;$\frac{\log(M)}{n}$&#65288;&#20854;&#20013;$M$&#20026;&#27169;&#22411;&#25968;&#65292;$n$&#20026;&#26679;&#26412;&#25968;&#65289;&#65292;&#21152;&#19978;&#39640;&#38454;&#20272;&#35745;&#35823;&#24046;&#39033;
&lt;/p&gt;
&lt;p&gt;
Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#26469;&#33719;&#21462;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#36341;&#24314;&#35758;&#21644;&#31034;&#20363;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2206.02340</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#20135;&#29983;&#20102;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;
&lt;/p&gt;
&lt;p&gt;
Minimising the Expected Posterior Entropy Yields Optimal Summary Statistics. (arXiv:2206.02340v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02340
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#26469;&#33719;&#21462;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#36341;&#24314;&#35758;&#21644;&#31034;&#20363;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#23545;&#20110;&#39640;&#25928;&#65288;&#26080;&#20284;&#28982;&#65289;&#25512;&#26029;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#31867;&#21035;&#30340;&#25688;&#35201;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#23545;&#20110;&#27491;&#30830;&#20998;&#26512;&#38477;&#32500;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#22312;&#27169;&#22411;&#30340;&#20808;&#39564;&#39044;&#27979;&#20998;&#24067;&#19979;&#26368;&#23567;&#21270;&#26399;&#26395;&#21518;&#39564;&#29109;&#65288;EPE&#65289;&#26469;&#33719;&#21462;&#25688;&#35201;&#12290;&#35768;&#22810;&#29616;&#26377;&#26041;&#27861;&#31561;&#25928;&#20110;&#25110;&#26159;&#26368;&#23567;&#21270;EPE&#30340;&#29305;&#27530;&#25110;&#26497;&#38480;&#24773;&#20917;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#33719;&#21462;&#26368;&#23567;&#21270;EPE&#30340;&#39640;&#20445;&#30495;&#25688;&#35201;&#65307;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#22522;&#20934;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#31034;&#20363;&#12290;&#25105;&#20204;&#26082;&#25552;&#20379;&#20102;&#33719;&#21462;&#26377;&#25928;&#25688;&#35201;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#21448;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#20855;&#20307;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extracting low-dimensional summary statistics from large datasets is essential for efficient (likelihood-free) inference. We characterise different classes of summaries and demonstrate their importance for correctly analysing dimensionality reduction algorithms. We propose obtaining summaries by minimising the expected posterior entropy (EPE) under the prior predictive distribution of the model. Many existing methods are equivalent to or are special or limiting cases of minimising the EPE. We develop a method to obtain high-fidelity summaries that minimise the EPE; we apply it to benchmark and real-world examples. We both offer a unifying perspective for obtaining informative summaries and provide concrete recommendations for practitioners.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#23545;&#20110;&#20855;&#26377;&#20004;&#20010;&#20219;&#21153;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#24120;&#29992;&#20272;&#35745;&#37327;&#30340;&#36229;&#39069;&#39118;&#38505;&#36827;&#34892;&#20102;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2010.11750</link><description>&lt;p&gt;
&#37327;&#21270;&#24322;&#26500;&#36716;&#31227;&#30340;&#31934;&#30830;&#39640;&#32500;&#28176;&#36817;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers. (arXiv:2010.11750v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.11750
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#23545;&#20110;&#20855;&#26377;&#20004;&#20010;&#20219;&#21153;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#24120;&#29992;&#20272;&#35745;&#37327;&#30340;&#36229;&#39069;&#39118;&#38505;&#36827;&#34892;&#20102;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23398;&#20064;&#19968;&#20010;&#20219;&#21153;&#26102;&#20351;&#29992;&#26469;&#33258;&#21478;&#19968;&#20010;&#20219;&#21153;&#30340;&#26679;&#26412;&#30340;&#38382;&#39064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;&#20160;&#20040;&#26102;&#20505;&#23558;&#26469;&#33258;&#20004;&#20010;&#20219;&#21153;&#30340;&#25968;&#25454;&#21512;&#24182;&#27604;&#21333;&#29420;&#23398;&#20064;&#19968;&#20010;&#20219;&#21153;&#26356;&#22909;&#65311;&#30452;&#35266;&#19978;&#65292;&#20174;&#19968;&#20010;&#20219;&#21153;&#21040;&#21478;&#19968;&#20010;&#20219;&#21153;&#30340;&#36716;&#31227;&#25928;&#24212;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#30340;&#36716;&#31227;&#65292;&#22914;&#26679;&#26412;&#22823;&#23567;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#28982;&#32780;&#65292;&#37327;&#21270;&#36825;&#31181;&#36716;&#31227;&#25928;&#24212;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#38656;&#35201;&#27604;&#36739;&#32852;&#21512;&#23398;&#20064;&#21644;&#21333;&#20219;&#21153;&#23398;&#20064;&#20043;&#38388;&#30340;&#39118;&#38505;&#65292;&#24182;&#19988;&#19968;&#20010;&#20219;&#21153;&#26159;&#21542;&#27604;&#21478;&#19968;&#20010;&#20219;&#21153;&#20855;&#26377;&#27604;&#36739;&#20248;&#21183;&#21462;&#20915;&#20110;&#20004;&#20010;&#20219;&#21153;&#20043;&#38388;&#30830;&#20999;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#31867;&#22411;&#12290;&#26412;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#22312;&#20855;&#26377;&#20004;&#20010;&#20219;&#21153;&#30340;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#35299;&#20915;&#20102;&#36825;&#19968;&#25361;&#25112;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#19968;&#20123;&#24120;&#29992;&#20272;&#35745;&#37327;&#30340;&#36229;&#39069;&#39118;&#38505;&#30340;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#65292;&#24403;&#26679;&#26412;&#22823;&#23567;&#19982;&#29305;&#24449;&#32500;&#24230;&#25104;&#27604;&#20363;&#22686;&#21152;&#26102;&#65292;&#22266;&#23450;&#27604;&#20363;&#12290;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#20197;&#26679;&#26412;&#22823;&#23567;&#30340;&#20989;&#25968;&#24418;&#24335;&#32473;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of learning one task with samples from another task has received much interest recently. In this paper, we ask a fundamental question: when is combining data from two tasks better than learning one task alone? Intuitively, the transfer effect from one task to another task depends on dataset shifts such as sample sizes and covariance matrices. However, quantifying such a transfer effect is challenging since we need to compare the risks between joint learning and single-task learning, and the comparative advantage of one over the other depends on the exact kind of dataset shift between both tasks. This paper uses random matrix theory to tackle this challenge in a linear regression setting with two tasks. We give precise asymptotics about the excess risks of some commonly used estimators in the high-dimensional regime, when the sample sizes increase proportionally with the feature dimension at fixed ratios. The precise asymptotics is provided as a function of the sample sizes 
&lt;/p&gt;</description></item></channel></rss>