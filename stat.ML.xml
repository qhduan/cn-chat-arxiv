<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#23567;&#30340;&#31867;&#20869;&#21464;&#21270;&#19982;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#26377;&#20851;</title><link>https://arxiv.org/abs/2402.03991</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#31867;&#20869;&#21464;&#21270;&#23567;&#20250;&#23548;&#33268;&#20302;&#31209;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Neural Rank Collapse: Weight Decay and Small Within-Class Variability Yield Low-Rank Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03991
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#34928;&#20943;&#21644;&#23567;&#30340;&#31867;&#20869;&#21464;&#21270;&#19982;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#26377;&#20851;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22312;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#30340;&#30740;&#31350;&#26174;&#31034;&#20102;&#19968;&#20010;&#38544;&#21547;&#30340;&#20302;&#31209;&#20559;&#24046;&#29616;&#35937;&#65306;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#30697;&#38453;&#24448;&#24448;&#36817;&#20284;&#20026;&#20302;&#31209;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25110;&#20174;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#20013;&#21435;&#38500;&#30456;&#23545;&#36739;&#23567;&#30340;&#22855;&#24322;&#20540;&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#27169;&#22411;&#22823;&#23567;&#65292;&#21516;&#26102;&#20445;&#25345;&#29978;&#33267;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20302;&#31209;&#20559;&#24046;&#30340;&#29702;&#35770;&#30740;&#31350;&#37117;&#28041;&#21450;&#21040;&#31616;&#21270;&#30340;&#32447;&#24615;&#28145;&#24230;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24102;&#26377;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#21644;&#26435;&#37325;&#34928;&#20943;&#21442;&#25968;&#30340;&#36890;&#29992;&#32593;&#32476;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#31070;&#32463;&#31209;&#23849;&#28291;&#29616;&#35937;&#65292;&#23427;&#23558;&#35757;&#32451;&#22909;&#30340;&#32593;&#32476;&#30340;&#20302;&#31209;&#20559;&#24046;&#19982;&#32593;&#32476;&#30340;&#31070;&#32463;&#23849;&#28291;&#29305;&#24615;&#32852;&#31995;&#36215;&#26469;&#65306;&#38543;&#30528;&#26435;&#37325;&#34928;&#20943;&#21442;&#25968;&#30340;&#22686;&#21152;&#65292;&#32593;&#32476;&#20013;&#27599;&#19968;&#23618;&#30340;&#31209;&#21576;&#27604;&#20363;&#36882;&#20943;&#65292;&#19982;&#21069;&#38754;&#23618;&#30340;&#38544;&#34255;&#31354;&#38388;&#23884;&#20837;&#30340;&#31867;&#20869;&#21464;&#21270;&#25104;&#21453;&#27604;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work in deep learning has shown strong empirical and theoretical evidence of an implicit low-rank bias: weight matrices in deep networks tend to be approximately low-rank and removing relatively small singular values during training or from available trained models may significantly reduce model size while maintaining or even improving model performance. However, the majority of the theoretical investigations around low-rank bias in neural networks deal with oversimplified deep linear networks. In this work, we consider general networks with nonlinear activations and the weight decay parameter, and we show the presence of an intriguing neural rank collapse phenomenon, connecting the low-rank bias of trained networks with networks' neural collapse properties: as the weight decay parameter grows, the rank of each layer in the network decreases proportionally to the within-class variability of the hidden-space embeddings of the previous layers. Our theoretical findings are supporte
&lt;/p&gt;</description></item><item><title>&#24120;&#29992;&#30340;&#20855;&#26377;&#26080;&#33618;&#21407;&#35777;&#26126;&#30340;&#27169;&#22411;&#20063;&#21487;&#20197;&#22312;&#36827;&#34892;&#21021;&#22987;&#25968;&#25454;&#37319;&#38598;&#38454;&#27573;&#20174;&#37327;&#23376;&#35774;&#22791;&#20013;&#25910;&#38598;&#19968;&#20123;&#32463;&#20856;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#32463;&#20856;&#27169;&#25311;</title><link>https://arxiv.org/abs/2312.09121</link><description>&lt;p&gt;
&#35777;&#23454;&#26080;&#33618;&#21407;&#23384;&#22312;&#26159;&#21542;&#24847;&#21619;&#30528;&#32463;&#20856;&#27169;&#25311;&#65311;&#25110;&#32773;&#65292;&#20026;&#20160;&#20040;&#25105;&#20204;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#21464;&#20998;&#37327;&#23376;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Does provable absence of barren plateaus imply classical simulability? Or, why we need to rethink variational quantum computing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.09121
&lt;/p&gt;
&lt;p&gt;
&#24120;&#29992;&#30340;&#20855;&#26377;&#26080;&#33618;&#21407;&#35777;&#26126;&#30340;&#27169;&#22411;&#20063;&#21487;&#20197;&#22312;&#36827;&#34892;&#21021;&#22987;&#25968;&#25454;&#37319;&#38598;&#38454;&#27573;&#20174;&#37327;&#23376;&#35774;&#22791;&#20013;&#25910;&#38598;&#19968;&#20123;&#32463;&#20856;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#32463;&#20856;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20154;&#20204;&#23545;&#33618;&#21407;&#29616;&#35937;&#36827;&#34892;&#20102;&#22823;&#37327;&#30740;&#31350;&#12290; &#22312;&#36825;&#31687;&#35266;&#28857;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#38754;&#23545;&#20102;&#36234;&#26469;&#36234;&#26126;&#26174;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35768;&#22810;&#20154;&#26263;&#31034;&#20294;&#23578;&#26410;&#26126;&#30830;&#35299;&#20915;&#30340;&#38382;&#39064;&#65306;&#20801;&#35768;&#36991;&#20813;&#33618;&#21407;&#30340;&#32467;&#26500;&#26159;&#21542;&#20063;&#21487;&#20197;&#34987;&#21033;&#29992;&#26469;&#26377;&#25928;&#22320;&#32463;&#20856;&#27169;&#25311;&#25439;&#22833;&#65311; &#25105;&#20204;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#35777;&#25454;&#65292;&#34920;&#26126;&#24120;&#29992;&#30340;&#20855;&#26377;&#26080;&#33618;&#21407;&#35777;&#26126;&#30340;&#27169;&#22411;&#20063;&#21487;&#20197;&#22312;&#36827;&#34892;&#21021;&#22987;&#25968;&#25454;&#37319;&#38598;&#38454;&#27573;&#20174;&#37327;&#23376;&#35774;&#22791;&#20013;&#25910;&#38598;&#19968;&#20123;&#32463;&#20856;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#32463;&#20856;&#27169;&#25311;&#12290; &#36825;&#26159;&#22240;&#20026;&#33618;&#21407;&#29616;&#35937;&#26159;&#30001;&#32500;&#24230;&#30340;&#35781;&#21650;&#23548;&#33268;&#30340;&#65292;&#32780;&#30446;&#21069;&#35299;&#20915;&#38382;&#39064;&#30340;&#26041;&#27861;&#26368;&#32456;&#23558;&#38382;&#39064;&#32534;&#30721;&#21040;&#19968;&#20123;&#23567;&#30340;&#12289;&#32463;&#20856;&#21487;&#27169;&#25311;&#30340;&#23376;&#31354;&#38388;&#20013;&#12290; &#22240;&#27492;&#65292;&#23613;&#31649;&#24378;&#35843;&#37327;&#23376;&#35745;&#31639;&#21487;&#20197;&#26159;&#25910;&#38598;&#25968;&#25454;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#24341;&#36215;&#20102;&#20005;&#37325;&#30340;&#24605;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.09121v2 Announce Type: replace-cross  Abstract: A large amount of effort has recently been put into understanding the barren plateau phenomenon. In this perspective article, we face the increasingly loud elephant in the room and ask a question that has been hinted at by many but not explicitly addressed: Can the structure that allows one to avoid barren plateaus also be leveraged to efficiently simulate the loss classically? We present strong evidence that commonly used models with provable absence of barren plateaus are also classically simulable, provided that one can collect some classical data from quantum devices during an initial data acquisition phase. This follows from the observation that barren plateaus result from a curse of dimensionality, and that current approaches for solving them end up encoding the problem into some small, classically simulable, subspaces. Thus, while stressing quantum computers can be essential for collecting data, our analysis sheds seriou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#20316;&#20026;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20165;&#38656;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#26469;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2401.10811</link><description>&lt;p&gt;
&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simulation Based Bayesian Optimization. (arXiv:2401.10811v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#20316;&#20026;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20165;&#38656;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#26469;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#23558;&#20808;&#39564;&#30693;&#35782;&#19982;&#25345;&#32493;&#20989;&#25968;&#35780;&#20272;&#30456;&#32467;&#21512;&#30340;&#24378;&#22823;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#26500;&#24314;&#19982;&#21327;&#21464;&#37327;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#27010;&#29575;&#20195;&#29702;&#27169;&#22411;&#26469;&#25351;&#23548;&#26410;&#26469;&#35780;&#20272;&#28857;&#30340;&#36873;&#25321;&#12290;&#23545;&#20110;&#24179;&#28369;&#36830;&#32493;&#30340;&#25628;&#32034;&#31354;&#38388;&#65292;&#39640;&#26031;&#36807;&#31243;&#32463;&#24120;&#34987;&#29992;&#20316;&#20195;&#29702;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20204;&#25552;&#20379;&#23545;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#30340;&#35299;&#26512;&#35775;&#38382;&#65292;&#20174;&#32780;&#20415;&#20110;&#35745;&#31639;&#21644;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#28041;&#21450;&#23545;&#20998;&#31867;&#25110;&#28151;&#21512;&#21327;&#21464;&#37327;&#31354;&#38388;&#36827;&#34892;&#20248;&#21270;&#30340;&#22797;&#26434;&#24773;&#20917;&#19979;&#65292;&#39640;&#26031;&#36807;&#31243;&#21487;&#33021;&#19981;&#26159;&#29702;&#24819;&#30340;&#36873;&#25321;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#23545;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#36827;&#34892;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#65292;&#20197;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) is a powerful method for optimizing black-box functions by combining prior knowledge with ongoing function evaluations. BO constructs a probabilistic surrogate model of the objective function given the covariates, which is in turn used to inform the selection of future evaluation points through an acquisition function. For smooth continuous search spaces, Gaussian Processes (GPs) are commonly used as the surrogate model as they offer analytical access to posterior predictive distributions, thus facilitating the computation and optimization of acquisition functions. However, in complex scenarios involving optimizations over categorical or mixed covariate spaces, GPs may not be ideal.  This paper introduces Simulation Based Bayesian Optimization (SBBO) as a novel approach to optimizing acquisition functions that only requires \emph{sampling-based} access to posterior predictive distributions. SBBO allows the use of surrogate probabilistic models tailored for co
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#36890;&#36807;&#19968;&#20010;&#32508;&#21512;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#20915;&#31574;&#32773;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#21644;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.09018</link><description>&lt;p&gt;
&#20851;&#20110;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
On the Foundation of Distributionally Robust Reinforcement Learning. (arXiv:2311.09018v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.09018
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#36890;&#36807;&#19968;&#20010;&#32508;&#21512;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#20915;&#31574;&#32773;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#21644;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20986;&#20110;&#23545;&#22312;&#35757;&#32451;&#21644;&#37096;&#32626;&#20043;&#38388;&#29615;&#22659;&#21464;&#21270;&#26102;&#40065;&#26834;&#31574;&#30053;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#36890;&#36807;&#19968;&#20010;&#20197;&#20998;&#24067;&#40065;&#26834;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;DRMDPs&#65289;&#20026;&#20013;&#24515;&#30340;&#32508;&#21512;&#24314;&#27169;&#26694;&#26550;&#65292;&#25105;&#20204;&#20351;&#20915;&#31574;&#32773;&#22312;&#19968;&#20010;&#30001;&#23545;&#25163;&#25805;&#32437;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#12290;&#36890;&#36807;&#32479;&#19968;&#21644;&#25193;&#23637;&#29616;&#26377;&#30340;&#34920;&#36848;&#65292;&#25105;&#20204;&#20005;&#26684;&#26500;&#24314;&#20102;&#36866;&#29992;&#20110;&#20915;&#31574;&#32773;&#21644;&#23545;&#25163;&#30340;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#30340;DRMDPs&#65292;&#21253;&#25324;&#36866;&#24212;&#24615;&#31890;&#24230;&#12289;&#25506;&#32034;&#21382;&#21490;&#20381;&#36182;&#24615;&#12289;&#39532;&#23572;&#31185;&#22827;&#21644;&#39532;&#23572;&#31185;&#22827;&#26102;&#38388;&#40784;&#27425;&#30340;&#20915;&#31574;&#32773;&#21644;&#23545;&#25163;&#21160;&#24577;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#20102;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#65292;&#30740;&#31350;&#20102;SA&#21644;S-&#30697;&#24418;&#24615;&#12290;&#22312;&#36825;&#20010;DRMDP&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23454;&#29616;&#40065;&#26834;&#24615;&#25152;&#38656;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the need for a robust policy in the face of environment shifts between training and the deployment, we contribute to the theoretical foundation of distributionally robust reinforcement learning (DRRL). This is accomplished through a comprehensive modeling framework centered around distributionally robust Markov decision processes (DRMDPs). This framework obliges the decision maker to choose an optimal policy under the worst-case distributional shift orchestrated by an adversary. By unifying and extending existing formulations, we rigorously construct DRMDPs that embraces various modeling attributes for both the decision maker and the adversary. These attributes include adaptability granularity, exploring history-dependent, Markov, and Markov time-homogeneous decision maker and adversary dynamics. Additionally, we delve into the flexibility of shifts induced by the adversary, examining SA and S-rectangularity. Within this DRMDP framework, we investigate conditions for the e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#20165;&#38656;&#35201;&#36739;&#23569;&#30340;&#26679;&#26412;&#21363;&#21487;&#22312;&#36817;&#32447;&#24615;&#26102;&#38388;&#20869;&#20272;&#35745;&#31232;&#30095;&#22343;&#20540;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15276</link><description>&lt;p&gt;
&#22686;&#37327;&#23398;&#20064;&#19979;&#30340;&#31232;&#30095;&#22343;&#20540;&#40065;&#26834;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Robust Sparse Mean Estimation via Incremental Learning. (arXiv:2305.15276v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#20165;&#38656;&#35201;&#36739;&#23569;&#30340;&#26679;&#26412;&#21363;&#21487;&#22312;&#36817;&#32447;&#24615;&#26102;&#38388;&#20869;&#20272;&#35745;&#31232;&#30095;&#22343;&#20540;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#22343;&#20540;&#30340;&#40065;&#26834;&#24615;&#20272;&#35745;&#38382;&#39064;&#65292;&#26088;&#22312;&#20272;&#35745;&#20174;&#37325;&#23614;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#37096;&#20998;&#25439;&#22351;&#26679;&#26412;&#30340;$k$-&#31232;&#30095;&#22343;&#20540;&#12290;&#29616;&#26377;&#20272;&#35745;&#22120;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#38754;&#20020;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#65306;&#39318;&#20808;&#65292;&#23427;&#20204;&#21463;&#21040;&#19968;&#20010;&#34987;&#25512;&#27979;&#30340;&#35745;&#31639;&#32479;&#35745;&#26435;&#34913;&#30340;&#38480;&#21046;&#65292;&#36825;&#24847;&#21619;&#30528;&#20219;&#20309;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#38656;&#35201;$\tilde\Omega(k^2)$&#20010;&#26679;&#26412;&#65292;&#32780;&#20854;&#22312;&#32479;&#35745;&#19978;&#26368;&#20248;&#30340;&#23545;&#24212;&#29289;&#21482;&#38656;&#35201;$\tilde O(k)$&#20010;&#26679;&#26412;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#30340;&#20272;&#35745;&#22120;&#35268;&#27169;&#38543;&#30528;&#29615;&#22659;&#30340;&#32500;&#24230;&#22686;&#21152;&#32780;&#24613;&#21095;&#19978;&#21319;&#65292;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#22312;&#36866;&#24230;&#30340;&#26465;&#20214;&#19979;&#20811;&#26381;&#20102;&#36825;&#20004;&#20010;&#25361;&#25112;&#65306;&#23427;&#22312;&#20960;&#20046;&#32447;&#24615;&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#20013;&#36816;&#34892;&#65288;&#30456;&#23545;&#20110;&#29615;&#22659;&#32500;&#24230;&#65289;&#65292;&#21516;&#26102;&#21482;&#38656;&#35201;$\tilde O(k)$&#20010;&#26679;&#26412;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#22343;&#20540;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#22686;&#37327;&#23398;&#20064;&#29616;&#35937;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#38750;&#20984;&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#23558;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#36716;&#21270;&#20026;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#22522;&#20110;&#22686;&#37327;&#23398;&#20064;&#30340;&#31639;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of robust sparse mean estimation, where the goal is to estimate a $k$-sparse mean from a collection of partially corrupted samples drawn from a heavy-tailed distribution. Existing estimators face two critical challenges in this setting. First, they are limited by a conjectured computational-statistical tradeoff, implying that any computationally efficient algorithm needs $\tilde\Omega(k^2)$ samples, while its statistically-optimal counterpart only requires $\tilde O(k)$ samples. Second, the existing estimators fall short of practical use as they scale poorly with the ambient dimension. This paper presents a simple mean estimator that overcomes both challenges under moderate conditions: it runs in near-linear time and memory (both with respect to the ambient dimension) while requiring only $\tilde O(k)$ samples to recover the true mean. At the core of our method lies an incremental learning phenomenon: we introduce a simple nonconvex framework that ca
&lt;/p&gt;</description></item></channel></rss>