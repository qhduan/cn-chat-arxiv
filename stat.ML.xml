<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21512;&#24182;&#20351;&#29992;&#19981;&#21516;&#36807;&#28388;&#22120;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#39034;&#24207;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09698</link><description>&lt;p&gt;
&#21512;&#24182;&#19981;&#21516;&#36807;&#28388;&#22120;&#20013;&#30340;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
Combining Evidence Across Filtrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09698
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21512;&#24182;&#20351;&#29992;&#19981;&#21516;&#36807;&#28388;&#22120;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#39034;&#24207;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20219;&#20309;&#26102;&#21051;&#26377;&#25928;&#30340;&#39034;&#24207;&#25512;&#29702;&#20013;&#65292;&#24050;&#30693;&#20219;&#20309;&#21487;&#25509;&#21463;&#30340;&#25512;&#29702;&#26041;&#27861;&#24517;&#39035;&#22522;&#20110;&#27979;&#35797;&#38789;&#21644;&#23427;&#20204;&#30340;&#32452;&#21512;&#24191;&#20041;&#21270;&#65292;&#31216;&#20026;e&#36827;&#31243;&#65292;&#23427;&#20204;&#26159;&#38750;&#36127;&#36827;&#31243;&#65292;&#20854;&#22312;&#20219;&#20309;&#20219;&#24847;&#20572;&#26102;&#30340;&#26399;&#26395;&#19978;&#30028;&#19981;&#36229;&#36807;&#19968;&#12290;e&#36827;&#31243;&#37327;&#21270;&#20102;&#38024;&#23545;&#22797;&#21512;&#38646;&#20551;&#35774;&#30340;&#19968;&#31995;&#21015;&#32467;&#26524;&#30340;&#32047;&#31215;&#35777;&#25454;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#19981;&#21516;&#20449;&#24687;&#38598;&#65288;&#21363;&#36807;&#28388;&#22120;&#65289;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#21512;&#24182;&#26041;&#27861;&#65292;&#38024;&#23545;&#19968;&#20010;&#38646;&#20551;&#35774;&#12290;&#23613;&#31649;&#22312;&#30456;&#21516;&#36807;&#28388;&#22120;&#19978;&#26500;&#24314;&#30340;e&#36827;&#31243;&#21487;&#20197;&#36731;&#26494;&#22320;&#21512;&#24182;&#65288;&#20363;&#22914;&#65292;&#36890;&#36807;&#24179;&#22343;&#65289;&#65292;&#20294;&#22312;&#19981;&#21516;&#36807;&#28388;&#22120;&#19978;&#26500;&#24314;&#30340;e&#36827;&#31243;&#19981;&#33021;&#37027;&#20040;&#23481;&#26131;&#22320;&#21512;&#24182;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#36739;&#31895;&#30340;&#36807;&#28388;&#22120;&#20013;&#30340;&#26377;&#25928;&#24615;&#19981;&#33021;&#36716;&#25442;&#20026;&#22312;&#26356;&#32454;&#30340;&#36807;&#28388;&#22120;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#25991;&#29486;&#20013;&#19977;&#20010;&#20855;&#20307;&#20363;&#23376;&#65306;&#21487;&#20132;&#25442;&#24615;&#27979;&#35797;&#65292;&#29420;&#31435;&#24615;&#27979;&#35797;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09698v1 Announce Type: cross  Abstract: In anytime-valid sequential inference, it is known that any admissible inference procedure must be based on test martingales and their composite generalization, called e-processes, which are nonnegative processes whose expectation at any arbitrary stopping time is upper-bounded by one. An e-process quantifies the accumulated evidence against a composite null hypothesis over a sequence of outcomes. This paper studies methods for combining e-processes that are computed using different information sets, i.e., filtrations, for a null hypothesis. Even though e-processes constructed on the same filtration can be combined effortlessly (e.g., by averaging), e-processes constructed on different filtrations cannot be combined as easily because their validity in a coarser filtration does not translate to validity in a finer filtration. We discuss three concrete examples of such e-processes in the literature: exchangeability tests, independence te
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#36873;&#25321;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#30340;&#20154;&#30340;&#38382;&#39064;&#65292;&#22312;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#21644;&#30830;&#23450;&#25130;&#26029;&#20540;&#26102;&#38754;&#20020;&#22810;&#37325;&#27979;&#35797;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#32622;&#20449;&#24102;&#26041;&#27861;&#26469;&#35780;&#20272;&#36825;&#20123;&#20010;&#20307;&#30340;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.07973</link><description>&lt;p&gt;
&#23545;&#20110;&#36873;&#25321;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#30340;&#20154;&#30340;&#32479;&#35745;&#24615;&#33021;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical Performance Guarantee for Selecting Those Predicted to Benefit Most from Treatment. (arXiv:2310.07973v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07973
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#36873;&#25321;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#30340;&#20154;&#30340;&#38382;&#39064;&#65292;&#22312;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#21644;&#30830;&#23450;&#25130;&#26029;&#20540;&#26102;&#38754;&#20020;&#22810;&#37325;&#27979;&#35797;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#32622;&#20449;&#24102;&#26041;&#27861;&#26469;&#35780;&#20272;&#36825;&#20123;&#20010;&#20307;&#30340;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#30340;&#23398;&#31185;&#39046;&#22495;&#20013;&#65292;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26469;&#35782;&#21035;&#19968;&#32452;&#34987;&#31216;&#20026;&#20363;&#22806;&#21453;&#24212;&#32773;&#30340;&#20010;&#20307;&#65292;&#20182;&#20204;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#12290;&#19968;&#20010;&#24120;&#35265;&#30340;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#12290;&#39318;&#20808;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#25110;&#20854;&#20195;&#29702;&#12290;&#28982;&#21518;&#30830;&#23450;&#25152;&#24471;&#27835;&#30103;&#20248;&#20808;&#39034;&#24207;&#20998;&#25968;&#30340;&#25130;&#26029;&#20540;&#65292;&#20197;&#36873;&#25321;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#20174;&#27835;&#30103;&#20013;&#33719;&#30410;&#30340;&#20154;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#20272;&#35745;&#30340;&#27835;&#30103;&#20248;&#20808;&#39034;&#24207;&#20998;&#25968;&#24448;&#24448;&#23384;&#22312;&#20559;&#24046;&#21644;&#22122;&#22768;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#30456;&#21516;&#30340;&#25968;&#25454;&#26082;&#36873;&#25321;&#25130;&#26029;&#20540;&#21448;&#20272;&#35745;&#25152;&#36873;&#20010;&#20307;&#30340;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#20250;&#36935;&#21040;&#22810;&#37325;&#27979;&#35797;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32622;&#20449;&#24102;&#26469;&#23454;&#39564;&#24615;&#22320;&#35780;&#20272;&#37027;&#20123;&#27835;&#30103;&#20248;&#20808;&#39034;&#24207;&#20998;&#25968;&#33267;&#23569;&#19982;&#20219;&#20309;&#32473;&#23450;&#37327;&#21270;&#20540;&#30456;&#31561;&#30340;&#20010;&#20307;&#30340;&#25490;&#24207;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#65288;GATES&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Across a wide array of disciplines, many researchers use machine learning (ML) algorithms to identify a subgroup of individuals, called exceptional responders, who are likely to be helped by a treatment the most. A common approach consists of two steps. One first estimates the conditional average treatment effect or its proxy using an ML algorithm. They then determine the cutoff of the resulting treatment prioritization score to select those predicted to benefit most from the treatment. Unfortunately, these estimated treatment prioritization scores are often biased and noisy. Furthermore, utilizing the same data to both choose a cutoff value and estimate the average treatment effect among the selected individuals suffer from a multiple testing problem. To address these challenges, we develop a uniform confidence band for experimentally evaluating the sorted average treatment effect (GATES) among the individuals whose treatment prioritization score is at least as high as any given quant
&lt;/p&gt;</description></item><item><title>Sinkhorn&#31639;&#27861;&#21644;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#31243;&#24207;&#21487;&#20197;&#25910;&#25947;&#21040;&#19968;&#20010;Wasserstein&#38236;&#20687;&#26799;&#24230;&#27969;&#65292;&#20854;&#20013;&#36895;&#24230;&#22330;&#30340;&#33539;&#25968;&#20195;&#34920;&#32447;&#24615;&#21270;&#26368;&#20339;&#36755;&#36816;&#36317;&#31163;&#30340;&#24230;&#37327;&#23548;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.16421</link><description>&lt;p&gt;
Wasserstein&#38236;&#20687;&#26799;&#24230;&#27969;&#20316;&#20026;Sinkhorn&#31639;&#27861;&#30340;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Mirror Gradient Flow as the limit of the Sinkhorn Algorithm. (arXiv:2307.16421v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16421
&lt;/p&gt;
&lt;p&gt;
Sinkhorn&#31639;&#27861;&#21644;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#31243;&#24207;&#21487;&#20197;&#25910;&#25947;&#21040;&#19968;&#20010;Wasserstein&#38236;&#20687;&#26799;&#24230;&#27969;&#65292;&#20854;&#20013;&#36895;&#24230;&#22330;&#30340;&#33539;&#25968;&#20195;&#34920;&#32447;&#24615;&#21270;&#26368;&#20339;&#36755;&#36816;&#36317;&#31163;&#30340;&#24230;&#37327;&#23548;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;Sinkhorn&#31639;&#27861;&#25110;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#31243;&#24207;&#65288;IPFP&#65289;&#24471;&#21040;&#30340;&#24207;&#21015;&#36793;&#32536;&#22312;$\varepsilon$&#36235;&#21521;&#20110;&#38646;&#19988;&#36845;&#20195;&#27425;&#25968;&#25353;$1/\varepsilon$&#32553;&#25918;&#26102;&#65292;&#20250;&#25910;&#25947;&#21040;$2$-Wasserstein&#31354;&#38388;&#19978;&#30340;&#19968;&#20010;&#32477;&#23545;&#36830;&#32493;&#26354;&#32447;&#65288;&#22312;&#28385;&#36275;&#20854;&#20182;&#25216;&#26415;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65289;&#12290;&#25105;&#20204;&#31216;&#36825;&#20010;&#26497;&#38480;&#20026;Sinkhorn&#27969;&#65292;&#23427;&#26159;Wasserstein&#38236;&#20687;&#26799;&#24230;&#27969;&#30340;&#19968;&#20010;&#20363;&#23376;&#65292;&#36825;&#20010;&#27010;&#24565;&#26159;&#25105;&#20204;&#22312;&#36825;&#37324;&#24341;&#20837;&#30340;&#65292;&#21463;&#21040;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;&#27431;&#20960;&#37324;&#24471;&#38236;&#20687;&#26799;&#24230;&#27969;&#30340;&#21551;&#21457;&#12290;&#22312;Sinkhorn&#30340;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#26159;&#30456;&#23545;&#29109;&#27867;&#20989;&#30456;&#23545;&#20110;&#20854;&#20013;&#19968;&#20010;&#36793;&#32536;&#30340;&#26799;&#24230;&#65292;&#32780;&#38236;&#20687;&#21017;&#26159;&#30456;&#23545;&#20110;&#21478;&#19968;&#20010;&#36793;&#32536;&#30340;&#24179;&#26041;Wasserstein&#36317;&#31163;&#27867;&#20989;&#30340;&#19968;&#21322;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#20010;&#27969;&#30340;&#36895;&#24230;&#22330;&#30340;&#33539;&#25968;&#21487;&#20197;&#35299;&#37322;&#20026;&#30456;&#23545;&#20110;&#32447;&#24615;&#21270;&#26368;&#20339;&#36755;&#36816;&#65288;LOT&#65289;&#36317;&#31163;&#30340;&#24230;&#37327;&#23548;&#25968;&#12290;&#23545;&#36825;&#20010;&#27969;&#30340;&#31561;&#20215;&#25551;&#36848;&#26159;...
&lt;/p&gt;
&lt;p&gt;
We prove that the sequence of marginals obtained from the iterations of the Sinkhorn algorithm or the iterative proportional fitting procedure (IPFP) on joint densities, converges to an absolutely continuous curve on the $2$-Wasserstein space, as the regularization parameter $\varepsilon$ goes to zero and the number of iterations is scaled as $1/\varepsilon$ (and other technical assumptions). This limit, which we call the Sinkhorn flow, is an example of a Wasserstein mirror gradient flow, a concept we introduce here inspired by the well-known Euclidean mirror gradient flows. In the case of Sinkhorn, the gradient is that of the relative entropy functional with respect to one of the marginals and the mirror is half of the squared Wasserstein distance functional from the other marginal. Interestingly, the norm of the velocity field of this flow can be interpreted as the metric derivative with respect to the linearized optimal transport (LOT) distance. An equivalent description of this flo
&lt;/p&gt;</description></item><item><title>ODTlearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#12290;&#23427;&#25552;&#20379;&#20102;&#22810;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#38382;&#39064;&#21644;&#31639;&#27861;&#30340;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2307.15691</link><description>&lt;p&gt;
ODTlearn: &#19968;&#20010;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#30340;&#21253;
&lt;/p&gt;
&lt;p&gt;
ODTlearn: A Package for Learning Optimal Decision Trees for Prediction and Prescription. (arXiv:2307.15691v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15691
&lt;/p&gt;
&lt;p&gt;
ODTlearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#12290;&#23427;&#25552;&#20379;&#20102;&#22810;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#38382;&#39064;&#21644;&#31639;&#27861;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ODTLearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;(MIO)&#26694;&#26550;&#30340;&#39640;&#39118;&#38505;&#39044;&#27979;&#21644;&#22788;&#26041;&#20219;&#21153;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#23398;&#20064;&#26041;&#27861;&#12290;&#35813;&#21253;&#30340;&#24403;&#21069;&#29256;&#26412;&#25552;&#20379;&#20102;&#23398;&#20064;&#26368;&#20248;&#20998;&#31867;&#26641;&#12289;&#20844;&#24179;&#26368;&#20248;&#20998;&#31867;&#26641;&#12289;&#40065;&#26834;&#26368;&#20248;&#20998;&#31867;&#26641;&#21644;&#20174;&#35266;&#27979;&#25968;&#25454;&#23398;&#20064;&#26368;&#20248;&#22788;&#26041;&#26641;&#30340;&#23454;&#29616;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#35813;&#21253;&#20197;&#20415;&#20110;&#32500;&#25252;&#21644;&#25193;&#23637;&#65292;&#24403;&#24341;&#20837;&#26032;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#38382;&#39064;&#31867;&#12289;&#37325;&#26500;&#31574;&#30053;&#21644;&#35299;&#20915;&#31639;&#27861;&#26102;&#65292;&#21487;&#20197;&#36731;&#26494;&#26356;&#26032;&#12290;&#20026;&#27492;&#65292;&#35813;&#21253;&#36981;&#24490;&#38754;&#21521;&#23545;&#35937;&#30340;&#35774;&#35745;&#21407;&#21017;&#65292;&#24182;&#25903;&#25345;&#21830;&#19994;(Gurobi)&#21644;&#24320;&#28304;(COIN-OR branch and cut)&#27714;&#35299;&#22120;&#12290;&#21253;&#30340;&#25991;&#26723;&#21644;&#35814;&#32454;&#29992;&#25143;&#25351;&#21335;&#21487;&#20197;&#22312;https://d3m-research-group.github.io/odtlearn/&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
ODTLearn is an open-source Python package that provides methods for learning optimal decision trees for high-stakes predictive and prescriptive tasks based on the mixed-integer optimization (MIO) framework proposed in Aghaei et al. (2019) and several of its extensions. The current version of the package provides implementations for learning optimal classification trees, optimal fair classification trees, optimal classification trees robust to distribution shifts, and optimal prescriptive trees from observational data. We have designed the package to be easy to maintain and extend as new optimal decision tree problem classes, reformulation strategies, and solution algorithms are introduced. To this end, the package follows object-oriented design principles and supports both commercial (Gurobi) and open source (COIN-OR branch and cut) solvers. The package documentation and an extensive user guide can be found at https://d3m-research-group.github.io/odtlearn/. Additionally, users can view
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#28508;&#22312;&#25928;&#29992;Q&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#23558;&#24739;&#32773;&#20559;&#22909;&#32435;&#20837;&#22797;&#21512;&#32467;&#26524;&#30340;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#20013;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#23545;&#26102;&#38388;&#28857;&#21644;&#32467;&#26524;&#25968;&#37327;&#30340;&#38480;&#21046;&#65292;&#33021;&#22815;&#23454;&#29616;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.12022</link><description>&lt;p&gt;
&#23558;&#24739;&#32773;&#20559;&#22909;&#32435;&#20837;Q&#23398;&#20064;&#30340;&#28789;&#27963;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Flexible Framework for Incorporating Patient Preferences Into Q-Learning. (arXiv:2307.12022v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12022
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#28508;&#22312;&#25928;&#29992;Q&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#23558;&#24739;&#32773;&#20559;&#22909;&#32435;&#20837;&#22797;&#21512;&#32467;&#26524;&#30340;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#20013;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#23545;&#26102;&#38388;&#28857;&#21644;&#32467;&#26524;&#25968;&#37327;&#30340;&#38480;&#21046;&#65292;&#33021;&#22815;&#23454;&#29616;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#21307;&#30103;&#38382;&#39064;&#20013;&#65292;&#36890;&#24120;&#23384;&#22312;&#22810;&#20010;&#31454;&#20105;&#24615;&#30340;&#20851;&#27880;&#28857;&#65292;&#22914;&#27835;&#30103;&#30103;&#25928;&#21644;&#21103;&#20316;&#29992;&#20005;&#37325;&#31243;&#24230;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#20272;&#35745;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696; (DTRs) &#30340;&#32479;&#35745;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#21482;&#26377;&#19968;&#20010;&#20851;&#27880;&#28857;&#65292;&#32780;&#22788;&#29702;&#22797;&#21512;&#32467;&#26524;&#30340;&#26041;&#27861;&#24456;&#23569;&#65292;&#23384;&#22312;&#37325;&#35201;&#38480;&#21046;&#65292;&#21253;&#25324;&#23545;&#21333;&#20010;&#26102;&#38388;&#28857;&#21644;&#20004;&#20010;&#32467;&#26524;&#30340;&#38480;&#21046;&#12289;&#26080;&#27861;&#32435;&#20837;&#24739;&#32773;&#30340;&#33258;&#36848;&#20559;&#22909;&#20197;&#21450;&#26377;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#28508;&#22312;&#25928;&#29992;Q&#23398;&#20064;(LUQ-Learning)&#12290;LUQ-Learning&#37319;&#29992;&#28508;&#22312;&#27169;&#22411;&#26041;&#27861;&#65292;&#33258;&#28982;&#22320;&#23558;Q&#23398;&#20064;&#25193;&#23637;&#21040;&#22797;&#21512;&#32467;&#26524;&#35774;&#32622;&#65292;&#24182;&#20026;&#27599;&#20010;&#24739;&#32773;&#36873;&#25321;&#29702;&#24819;&#30340;&#32467;&#26524;&#26435;&#34913;&#12290;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#20219;&#24847;&#25968;&#37327;&#30340;&#26102;&#38388;&#28857;&#21644;&#32467;&#26524;&#65292;&#32435;&#20837;&#38472;&#36848;&#30340;&#20559;&#22909;&#65292;&#24182;&#23454;&#29616;&#24378;&#22823;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world healthcare problems, there are often multiple competing outcomes of interest, such as treatment efficacy and side effect severity. However, statistical methods for estimating dynamic treatment regimes (DTRs) usually assume a single outcome of interest, and the few methods that deal with composite outcomes suffer from important limitations. This includes restrictions to a single time point and two outcomes, the inability to incorporate self-reported patient preferences and limited theoretical guarantees. To this end, we propose a new method to address these limitations, which we dub Latent Utility Q-Learning (LUQ-Learning). LUQ-Learning uses a latent model approach to naturally extend Q-learning to the composite outcome setting and adopt the ideal trade-off between outcomes to each patient. Unlike previous approaches, our framework allows for an arbitrary number of time points and outcomes, incorporates stated preferences and achieves strong asymptotic performance with rea
&lt;/p&gt;</description></item></channel></rss>