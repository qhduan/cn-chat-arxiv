<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2309.14073</link><description>&lt;p&gt;
&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65306;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35745;&#31639;&#36825;&#20010;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;&#19968;&#20010;&#29305;&#23450;&#20844;&#24335;&#25152;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.07779</link><description>&lt;p&gt;
&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#30340;&#22312;&#32447;&#31639;&#27861;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence analysis of online algorithms for vector-valued kernel regression. (arXiv:2309.07779v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;&#19968;&#20010;&#29305;&#23450;&#20844;&#24335;&#25152;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#36866;&#24403;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20316;&#20026;&#20808;&#39564;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20174;&#22122;&#22768;&#21521;&#37327;&#20540;&#25968;&#25454;&#20013;&#36924;&#36817;&#22238;&#24402;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#22312;&#22312;&#32447;&#31639;&#27861;&#20013;&#65292;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26679;&#26412;&#36890;&#36807;&#38543;&#26426;&#36807;&#31243;&#36880;&#20010;&#21487;&#29992;&#65292;&#24182;&#20381;&#27425;&#22788;&#29702;&#20197;&#26500;&#24314;&#23545;&#22238;&#24402;&#20989;&#25968;&#30340;&#36817;&#20284;&#12290;&#25105;&#20204;&#20851;&#27880;&#36825;&#31181;&#22312;&#32447;&#36924;&#36817;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;$C^2(m+1)^{-s/(2+s)}$&#32465;&#23450;&#65292;&#20854;&#20013;$m$&#20026;&#24403;&#19979;&#22788;&#29702;&#30340;&#25968;&#25454;&#25968;&#37327;&#65292;&#21442;&#25968;$0&lt;s\leq 1$&#34920;&#31034;&#23545;&#22238;&#24402;&#20989;&#25968;&#30340;&#39069;&#22806;&#20809;&#28369;&#24615;&#20551;&#35774;&#65292;&#24120;&#25968;$C$&#21462;&#20915;&#20110;&#36755;&#20837;&#22122;&#22768;&#30340;&#26041;&#24046;&#12289;&#22238;&#24402;&#20989;&#25968;&#30340;&#20809;&#28369;&#24615;&#20197;&#21450;&#31639;&#27861;&#30340;&#20854;&#20182;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of approximating the regression function from noisy vector-valued data by an online learning algorithm using an appropriate reproducing kernel Hilbert space (RKHS) as prior. In an online algorithm, i.i.d. samples become available one by one by a random process and are successively processed to build approximations to the regression function. We are interested in the asymptotic performance of such online approximation algorithms and show that the expected squared error in the RKHS norm can be bounded by $C^2 (m+1)^{-s/(2+s)}$, where $m$ is the current number of processed data, the parameter $0&lt;s\leq 1$ expresses an additional smoothness assumption on the regression function and the constant $C$ depends on the variance of the input noise, the smoothness of the regression function and further parameters of the algorithm.
&lt;/p&gt;</description></item><item><title>BOF-UCB&#26159;&#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;&#65292;&#20854;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#65292;&#25552;&#39640;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#23427;&#21033;&#29992;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#20197;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#26159;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#39034;&#24207;&#20915;&#31574;&#30340;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.03587</link><description>&lt;p&gt;
BOF-UCB: &#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#19978;&#19979;&#30028;&#20449;&#24515;&#31639;&#27861;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
BOF-UCB: A Bayesian-Optimistic Frequentist Algorithm for Non-Stationary Contextual Bandits. (arXiv:2307.03587v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03587
&lt;/p&gt;
&lt;p&gt;
BOF-UCB&#26159;&#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;&#65292;&#20854;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#65292;&#25552;&#39640;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#23427;&#21033;&#29992;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#20197;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#26159;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#39034;&#24207;&#20915;&#31574;&#30340;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#19978;&#19979;&#30028;&#20449;&#24515;&#31639;&#27861;&#65288;BOF-UCB&#65289;&#65292;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#38543;&#26426;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#12290;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#30340;&#29420;&#29305;&#32467;&#21512;&#22686;&#24378;&#20102;&#31639;&#27861;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#36866;&#24212;&#24615;&#21644;&#24615;&#33021;&#12290;BOF-UCB&#31639;&#27861;&#21033;&#29992;&#39034;&#24207;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#26410;&#30693;&#22238;&#24402;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#38543;&#21518;&#37319;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#36890;&#36807;&#26368;&#22823;&#21270;&#21518;&#39564;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#25910;&#30410;&#26469;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#65288;UCB&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;BOF-UCB&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel Bayesian-Optimistic Frequentist Upper Confidence Bound (BOF-UCB) algorithm for stochastic contextual linear bandits in non-stationary environments. This unique combination of Bayesian and frequentist principles enhances adaptability and performance in dynamic settings. The BOF-UCB algorithm utilizes sequential Bayesian updates to infer the posterior distribution of the unknown regression parameter, and subsequently employs a frequentist approach to compute the Upper Confidence Bound (UCB) by maximizing the expected reward over the posterior distribution. We provide theoretical guarantees of BOF-UCB's performance and demonstrate its effectiveness in balancing exploration and exploitation on synthetic datasets and classical control tasks in a reinforcement learning setting. Our results show that BOF-UCB outperforms existing methods, making it a promising solution for sequential decision-making in non-stationary environments.
&lt;/p&gt;</description></item></channel></rss>