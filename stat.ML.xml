<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#23567;&#26377;&#25928;&#35270;&#22270;&#65288;MSVs&#65289;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#31867;&#20284;&#20110;&#22810;&#35270;&#22270;&#65292;&#20294;&#36866;&#29992;&#20110;&#23454;&#38469;&#22270;&#20687;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;MSV&#30340;&#25968;&#37327;&#19982;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01095</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#20351;&#29992;&#22810;&#23569;&#20010;&#35270;&#22270;&#65311;
&lt;/p&gt;
&lt;p&gt;
How many views does your deep neural network use for prediction?
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#23567;&#26377;&#25928;&#35270;&#22270;&#65288;MSVs&#65289;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#31867;&#20284;&#20110;&#22810;&#35270;&#22270;&#65292;&#20294;&#36866;&#29992;&#20110;&#23454;&#38469;&#22270;&#20687;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;MSV&#30340;&#25968;&#37327;&#19982;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36827;&#34892;&#20102;&#35768;&#22810;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#20294;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#27867;&#21270;&#33021;&#21147;&#20173;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#26368;&#36817;&#65292;Allen-Zhu&#21644;Li&#65288;2023&#65289;&#24341;&#20837;&#20102;&#22810;&#35270;&#22270;&#30340;&#27010;&#24565;&#26469;&#35299;&#37322;DNN&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20294;&#20182;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#38598;&#25104;&#25110;&#33976;&#39311;&#27169;&#22411;&#65292;&#24182;&#26410;&#35752;&#35770;&#29992;&#20110;&#29305;&#23450;&#36755;&#20837;&#39044;&#27979;&#30340;&#22810;&#35270;&#22270;&#20272;&#35745;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26368;&#23567;&#26377;&#25928;&#35270;&#22270;&#65288;MSVs&#65289;&#65292;&#23427;&#31867;&#20284;&#20110;&#22810;&#35270;&#22270;&#65292;&#20294;&#21487;&#20197;&#39640;&#25928;&#22320;&#35745;&#31639;&#30495;&#23454;&#22270;&#20687;&#12290;MSVs&#26159;&#36755;&#20837;&#20013;&#30340;&#19968;&#32452;&#26368;&#23567;&#19988;&#19981;&#21516;&#30340;&#29305;&#24449;&#65292;&#27599;&#20010;&#29305;&#24449;&#20445;&#30041;&#20102;&#27169;&#22411;&#23545;&#35813;&#36755;&#20837;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#19981;&#21516;&#27169;&#22411;&#65288;&#21253;&#25324;&#21367;&#31215;&#21644;&#36716;&#25442;&#27169;&#22411;&#65289;&#30340;MSV&#25968;&#37327;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#23384;&#22312;&#26126;&#30830;&#30340;&#20851;&#31995;&#65292;&#36825;&#34920;&#26126;&#22810;&#35270;&#22270;&#30340;&#35282;&#24230;&#23545;&#20110;&#29702;&#35299;&#65288;&#38750;&#38598;&#25104;&#25110;&#38750;&#33976;&#39311;&#65289;DNN&#30340;&#27867;&#21270;&#33021;&#21147;&#20063;&#24456;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generalization ability of Deep Neural Networks (DNNs) is still not fully understood, despite numerous theoretical and empirical analyses. Recently, Allen-Zhu &amp; Li (2023) introduced the concept of multi-views to explain the generalization ability of DNNs, but their main target is ensemble or distilled models, and no method for estimating multi-views used in a prediction of a specific input is discussed. In this paper, we propose Minimal Sufficient Views (MSVs), which is similar to multi-views but can be efficiently computed for real images. MSVs is a set of minimal and distinct features in an input, each of which preserves a model's prediction for the input. We empirically show that there is a clear relationship between the number of MSVs and prediction accuracy across models, including convolutional and transformer models, suggesting that a multi-view like perspective is also important for understanding the generalization ability of (non-ensemble or non-distilled) DNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24448;&#36820;&#35774;&#35745;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#20026;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#26356;&#26377;&#25928;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#39057;&#29575;&#21487;&#20197;&#38477;&#20302;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.17285</link><description>&lt;p&gt;
&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24448;&#36820;&#35774;&#35745;&#36827;&#34892;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Analysis of Switchback Designs in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24448;&#36820;&#35774;&#35745;&#23545;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#20026;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#26356;&#26377;&#25928;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#39057;&#29575;&#21487;&#20197;&#38477;&#20302;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;A/B&#27979;&#35797;&#20013;&#24448;&#36820;&#35774;&#35745;&#30340;&#35814;&#32454;&#30740;&#31350;&#65292;&#36825;&#20123;&#35774;&#35745;&#38543;&#26102;&#38388;&#22312;&#22522;&#20934;&#21644;&#26032;&#31574;&#30053;&#20043;&#38388;&#20132;&#26367;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20840;&#38754;&#35780;&#20272;&#36825;&#20123;&#35774;&#35745;&#23545;&#20854;&#20135;&#29983;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#20272;&#35745;&#22120;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#8220;&#24369;&#20449;&#21495;&#20998;&#26512;&#8221;&#26694;&#26550;&#65292;&#22823;&#22823;&#31616;&#21270;&#20102;&#36825;&#20123;ATE&#30340;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#22312;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#29615;&#22659;&#20013;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65306;(i) &#24403;&#22823;&#37096;&#20998;&#22870;&#21169;&#35823;&#24046;&#21576;&#27491;&#30456;&#20851;&#26102;&#65292;&#24448;&#36820;&#35774;&#35745;&#27604;&#27599;&#26085;&#20999;&#25442;&#31574;&#30053;&#30340;&#20132;&#26367;&#35774;&#35745;&#26356;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#22686;&#21152;&#25919;&#31574;&#20999;&#25442;&#30340;&#39057;&#29575;&#24448;&#24448;&#20250;&#38477;&#20302;ATE&#20272;&#35745;&#22120;&#30340;MSE&#12290;(ii) &#28982;&#32780;&#65292;&#24403;&#35823;&#24046;&#19981;&#30456;&#20851;&#26102;&#65292;&#25152;&#26377;&#36825;&#20123;&#35774;&#35745;&#21464;&#24471;&#28176;&#36817;&#31561;&#25928;&#12290;(iii) &#22312;&#22823;&#22810;&#25968;&#35823;&#24046;&#20026;&#36127;&#30456;&#20851;&#26102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17285v1 Announce Type: cross  Abstract: This paper offers a detailed investigation of switchback designs in A/B testing, which alternate between baseline and new policies over time. Our aim is to thoroughly evaluate the effects of these designs on the accuracy of their resulting average treatment effect (ATE) estimators. We propose a novel "weak signal analysis" framework, which substantially simplifies the calculations of the mean squared errors (MSEs) of these ATEs in Markov decision process environments. Our findings suggest that (i) when the majority of reward errors are positively correlated, the switchback design is more efficient than the alternating-day design which switches policies in a daily basis. Additionally, increasing the frequency of policy switches tends to reduce the MSE of the ATE estimator. (ii) When the errors are uncorrelated, however, all these designs become asymptotically equivalent. (iii) In cases where the majority of errors are negative correlate
&lt;/p&gt;</description></item></channel></rss>