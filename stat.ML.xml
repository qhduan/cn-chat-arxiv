<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>PyTorch Frame&#26159;&#19968;&#20010;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#30340;PyTorch&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#25968;&#25454;&#32467;&#26500;&#12289;&#27169;&#22411;&#25277;&#35937;&#21644;&#22806;&#37096;&#22522;&#30784;&#27169;&#22411;&#25972;&#21512;&#31561;&#21151;&#33021;&#65292;&#23454;&#29616;&#20102;&#27169;&#22359;&#21270;&#30340;&#34920;&#26684;&#27169;&#22411;&#23454;&#29616;&#65292;&#24182;&#25104;&#21151;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2404.00776</link><description>&lt;p&gt;
PyTorch Frame: &#19968;&#20010;&#29992;&#20110;&#22810;&#27169;&#24577;&#34920;&#26684;&#23398;&#20064;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
PyTorch Frame: A Modular Framework for Multi-Modal Tabular Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00776
&lt;/p&gt;
&lt;p&gt;
PyTorch Frame&#26159;&#19968;&#20010;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#30340;PyTorch&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#25968;&#25454;&#32467;&#26500;&#12289;&#27169;&#22411;&#25277;&#35937;&#21644;&#22806;&#37096;&#22522;&#30784;&#27169;&#22411;&#25972;&#21512;&#31561;&#21151;&#33021;&#65292;&#23454;&#29616;&#20102;&#27169;&#22359;&#21270;&#30340;&#34920;&#26684;&#27169;&#22411;&#23454;&#29616;&#65292;&#24182;&#25104;&#21151;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;PyTorch Frame&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;PyTorch&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#30340;&#28145;&#24230;&#23398;&#20064;&#12290;PyTorch Frame&#36890;&#36807;&#25552;&#20379;&#22522;&#20110;PyTorch&#30340;&#25968;&#25454;&#32467;&#26500;&#26469;&#22788;&#29702;&#22797;&#26434;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#24341;&#20837;&#27169;&#22411;&#25277;&#35937;&#20197;&#23454;&#29616;&#34920;&#26684;&#27169;&#22411;&#30340;&#27169;&#22359;&#21270;&#23454;&#29616;&#65292;&#24182;&#20801;&#35768;&#25972;&#21512;&#22806;&#37096;&#22522;&#30784;&#27169;&#22411;&#26469;&#22788;&#29702;&#22797;&#26434;&#21015;&#65288;&#20363;&#22914;&#65292;&#29992;&#20110;&#25991;&#26412;&#21015;&#30340;LLMs&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#20197;&#27169;&#22359;&#21270;&#26041;&#24335;&#23454;&#29616;&#22810;&#26679;&#30340;&#34920;&#26684;&#27169;&#22411;&#65292;&#25104;&#21151;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#65292;&#24182;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#19982;PyTorch Geometric&#38598;&#25104;&#65292;PyTorch Geometric&#26159;&#19968;&#20010;&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;PyTorch&#24211;&#65292;&#20197;&#23454;&#29616;&#23545;&#20851;&#31995;&#25968;&#25454;&#24211;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00776v1 Announce Type: new  Abstract: We present PyTorch Frame, a PyTorch-based framework for deep learning over multi-modal tabular data. PyTorch Frame makes tabular deep learning easy by providing a PyTorch-based data structure to handle complex tabular data, introducing a model abstraction to enable modular implementation of tabular models, and allowing external foundation models to be incorporated to handle complex columns (e.g., LLMs for text columns). We demonstrate the usefulness of PyTorch Frame by implementing diverse tabular models in a modular way, successfully applying these models to complex multi-modal tabular data, and integrating our framework with PyTorch Geometric, a PyTorch library for Graph Neural Networks (GNNs), to perform end-to-end learning over relational databases.
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2404.00221</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#24378;&#20581;&#23398;&#20064;&#20197;&#33719;&#24471;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00221
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#30103;&#24178;&#39044;&#28041;&#21450;&#20854;&#27835;&#30103;&#20998;&#37197;&#20013;&#30340;&#21160;&#24577;&#24615;&#65292;&#27835;&#30103;&#36890;&#24120;&#20381;&#25454;&#20808;&#21069;&#27835;&#30103;&#30340;&#21382;&#21490;&#21644;&#30456;&#20851;&#29305;&#24449;&#23545;&#27599;&#20010;&#38454;&#27573;&#30340;&#25928;&#26524;&#20855;&#26377;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#32479;&#35745;&#23398;&#20064;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;(DTR)&#65292;&#26681;&#25454;&#20010;&#20307;&#30340;&#21382;&#21490;&#25351;&#23548;&#27599;&#20010;&#38454;&#27573;&#30340;&#26368;&#20339;&#27835;&#30103;&#20998;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#30340;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#22312;&#39034;&#24207;&#21487;&#24573;&#30053;&#24615;&#20551;&#35774;&#19979;&#23398;&#20064;&#26368;&#20339;DTR&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#39034;&#24207;&#27835;&#30103;&#20998;&#37197;&#38382;&#39064;&#65292;&#22312;&#27599;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#32467;&#21512;&#20542;&#21521;&#35780;&#20998;&#21644;&#34892;&#21160;&#20540;&#20989;&#25968;(Q&#20989;&#25968;)&#30340;&#20272;&#35745;&#37327;&#65292;&#26500;&#24314;&#20102;&#25919;&#31574;&#20215;&#20540;&#30340;&#22686;&#24378;&#21453;&#21521;&#27010;&#29575;&#21152;&#26435;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00221v1 Announce Type: cross  Abstract: Many public policies and medical interventions involve dynamics in their treatment assignments, where treatments are sequentially assigned to the same individuals across multiple stages, and the effect of treatment at each stage is usually heterogeneous with respect to the history of prior treatments and associated characteristics. We study statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's history. We propose a step-wise doubly-robust approach to learn the optimal DTR using observational data under the assumption of sequential ignorability. The approach solves the sequential treatment assignment problem through backward induction, where, at each step, we combine estimators of propensity scores and action-value functions (Q-functions) to construct augmented inverse probability weighting estimators of values of policies 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#38543;&#26426;&#36882;&#24402;&#26641;&#20013;&#39030;&#28857;&#21040;&#36798;&#39034;&#24207;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;Jordan&#20013;&#24515;&#24615;&#24230;&#37327;&#30340;&#39034;&#24207;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20854;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.09755</link><description>&lt;p&gt;
&#20272;&#35745;&#38543;&#26426;&#36882;&#24402;&#26641;&#30340;&#21382;&#21490;
&lt;/p&gt;
&lt;p&gt;
Estimating the history of a random recursive tree
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09755
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#38543;&#26426;&#36882;&#24402;&#26641;&#20013;&#39030;&#28857;&#21040;&#36798;&#39034;&#24207;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;Jordan&#20013;&#24515;&#24615;&#24230;&#37327;&#30340;&#39034;&#24207;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20854;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#38543;&#26426;&#36882;&#24402;&#26641;&#20013;&#39030;&#28857;&#21040;&#36798;&#39034;&#24207;&#30340;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#22522;&#26412;&#27169;&#22411;&#65306;&#22343;&#21248;&#36830;&#25509;&#27169;&#22411;&#21644;&#32447;&#24615;&#20248;&#20808;&#36830;&#25509;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Jordan&#20013;&#24515;&#24615;&#24230;&#37327;&#30340;&#39034;&#24207;&#20272;&#35745;&#22120;&#65292;&#24182;&#23450;&#20041;&#20102;&#19968;&#26063;&#39118;&#38505;&#24230;&#37327;&#26469;&#37327;&#21270;&#25490;&#24207;&#36807;&#31243;&#30340;&#36136;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#36825;&#20010;&#38382;&#39064;&#24314;&#31435;&#20102;&#26497;&#23567;-&#26368;&#22823;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#20248;&#20110;&#22522;&#20110;&#24230;&#25968;&#21644;&#35889;&#25490;&#24207;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09755v1 Announce Type: cross  Abstract: This paper studies the problem of estimating the order of arrival of the vertices in a random recursive tree. Specifically, we study two fundamental models: the uniform attachment model and the linear preferential attachment model. We propose an order estimator based on the Jordan centrality measure and define a family of risk measures to quantify the quality of the ordering procedure. Moreover, we establish a minimax lower bound for this problem, and prove that the proposed estimator is nearly optimal. Finally, we numerically demonstrate that the proposed estimator outperforms degree-based and spectral ordering procedures.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25361;&#25112;&#30340;&#26368;&#20248;Top-Two&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.09123</link><description>&lt;p&gt;
&#26368;&#20339;&#33218;&#35782;&#21035;&#21644;&#27969;&#20307;&#20998;&#26512;&#30340;&#26368;&#20248;Top-Two&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Top-Two Method for Best Arm Identification and Fluid Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09123
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25361;&#25112;&#30340;&#26368;&#20248;Top-Two&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Top-2&#26041;&#27861;&#22312;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#20013;&#21464;&#24471;&#27969;&#34892;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#19968;&#20010;&#31639;&#27861;&#35782;&#21035;&#26368;&#20339;&#33218;&#65292;&#21363;&#22312;&#26377;&#38480;&#25968;&#37327;&#33218;&#20013;&#20855;&#26377;&#26368;&#22823;&#22343;&#20540;&#30340;&#33218;&#65292;&#35813;&#31639;&#27861;&#22312;&#20219;&#20309;&#39034;&#24207;&#27493;&#39588;&#20013;&#29420;&#31435;&#22320;&#20197;&#22266;&#23450;&#27010;&#29575; &#946; &#25289;&#21160;&#32463;&#39564;&#26368;&#20339;&#33218;&#65292;&#24182;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#25289;&#21160;&#26368;&#20339;&#25361;&#25112;&#32773;&#33218;&#12290;&#36873;&#25321;&#38169;&#35823;&#30340;&#27010;&#29575;&#20445;&#35777;&#22312;&#25351;&#23450;&#30340;&#948; &gt;0&#20197;&#19979;&#12290;&#23545;&#20110;BAI&#38382;&#39064;&#65292;&#24050;&#30693;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#948; &#8594; 0&#26102;&#19982;&#35745;&#31639;&#35201;&#27714;&#39640;&#30340;&#25554;&#20214;&#26041;&#27861;&#28176;&#36817;&#21305;&#37197;&#12290; &#23545;&#20110;&#20219;&#20309; &#946; &#8712;&#65288;0,1&#65289;&#30340;&#19978;&#36848;Top 2&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#22987;&#32456;&#20445;&#25345;&#22312;&#19979;&#30028;&#30340;&#24120;&#25968;&#33539;&#22260;&#20869;&#12290;&#28982;&#32780;&#65292;&#30830;&#23450;&#19982;&#19979;&#30028;&#21305;&#37197;&#30340;&#26368;&#20339; &#946; &#24050;&#34987;&#35777;&#26126;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#20248;&#30340;Top-2&#31867;&#22411;&#31639;&#27861;&#12290;&#25105;&#20204;&#32771;&#34385;&#20998;&#37197;&#38170;&#28857;&#30340;&#19968;&#20010;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09123v1 Announce Type: new  Abstract: Top-$2$ methods have become popular in solving the best arm identification (BAI) problem. The best arm, or the arm with the largest mean amongst finitely many, is identified through an algorithm that at any sequential step independently pulls the empirical best arm, with a fixed probability $\beta$, and pulls the best challenger arm otherwise. The probability of incorrect selection is guaranteed to lie below a specified $\delta &gt;0$. Information theoretic lower bounds on sample complexity are well known for BAI problem and are matched asymptotically as $\delta \rightarrow 0$ by computationally demanding plug-in methods. The above top 2 algorithm for any $\beta \in (0,1)$ has sample complexity within a constant of the lower bound. However, determining the optimal $\beta$ that matches the lower bound has proven difficult. In this paper, we address this and propose an optimal top-2 type algorithm. We consider a function of allocations anchor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#20316;&#20026;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20165;&#38656;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#26469;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2401.10811</link><description>&lt;p&gt;
&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simulation Based Bayesian Optimization. (arXiv:2401.10811v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#20316;&#20026;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20165;&#38656;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#26469;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#23558;&#20808;&#39564;&#30693;&#35782;&#19982;&#25345;&#32493;&#20989;&#25968;&#35780;&#20272;&#30456;&#32467;&#21512;&#30340;&#24378;&#22823;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#26500;&#24314;&#19982;&#21327;&#21464;&#37327;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#27010;&#29575;&#20195;&#29702;&#27169;&#22411;&#26469;&#25351;&#23548;&#26410;&#26469;&#35780;&#20272;&#28857;&#30340;&#36873;&#25321;&#12290;&#23545;&#20110;&#24179;&#28369;&#36830;&#32493;&#30340;&#25628;&#32034;&#31354;&#38388;&#65292;&#39640;&#26031;&#36807;&#31243;&#32463;&#24120;&#34987;&#29992;&#20316;&#20195;&#29702;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20204;&#25552;&#20379;&#23545;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#30340;&#35299;&#26512;&#35775;&#38382;&#65292;&#20174;&#32780;&#20415;&#20110;&#35745;&#31639;&#21644;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#28041;&#21450;&#23545;&#20998;&#31867;&#25110;&#28151;&#21512;&#21327;&#21464;&#37327;&#31354;&#38388;&#36827;&#34892;&#20248;&#21270;&#30340;&#22797;&#26434;&#24773;&#20917;&#19979;&#65292;&#39640;&#26031;&#36807;&#31243;&#21487;&#33021;&#19981;&#26159;&#29702;&#24819;&#30340;&#36873;&#25321;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#23545;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#36827;&#34892;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#65292;&#20197;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) is a powerful method for optimizing black-box functions by combining prior knowledge with ongoing function evaluations. BO constructs a probabilistic surrogate model of the objective function given the covariates, which is in turn used to inform the selection of future evaluation points through an acquisition function. For smooth continuous search spaces, Gaussian Processes (GPs) are commonly used as the surrogate model as they offer analytical access to posterior predictive distributions, thus facilitating the computation and optimization of acquisition functions. However, in complex scenarios involving optimizations over categorical or mixed covariate spaces, GPs may not be ideal.  This paper introduces Simulation Based Bayesian Optimization (SBBO) as a novel approach to optimizing acquisition functions that only requires \emph{sampling-based} access to posterior predictive distributions. SBBO allows the use of surrogate probabilistic models tailored for co
&lt;/p&gt;</description></item><item><title>xVal&#26159;&#19968;&#31181;&#36830;&#32493;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#20010;&#26631;&#35760;&#26469;&#34920;&#31034;&#20219;&#20309;&#23454;&#25968;&#12290;&#19982;&#29616;&#26377;&#30340;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#30456;&#27604;&#65292;xVal&#26356;&#21152;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.02989</link><description>&lt;p&gt;
xVal: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36830;&#32493;&#25968;&#23383;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
xVal: A Continuous Number Encoding for Large Language Models. (arXiv:2310.02989v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02989
&lt;/p&gt;
&lt;p&gt;
xVal&#26159;&#19968;&#31181;&#36830;&#32493;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#20010;&#26631;&#35760;&#26469;&#34920;&#31034;&#20219;&#20309;&#23454;&#25968;&#12290;&#19982;&#29616;&#26377;&#30340;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#30456;&#27604;&#65292;xVal&#26356;&#21152;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#25968;&#23383;&#20196;&#29260;&#21270;&#30340;&#29420;&#29305;&#22256;&#38590;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23578;&#26410;&#24191;&#27867;&#29992;&#20110;&#31185;&#23398;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;xVal&#65292;&#19968;&#31181;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#65292;&#21487;&#20197;&#20351;&#29992;&#21333;&#20010;&#26631;&#35760;&#26469;&#34920;&#31034;&#20219;&#20309;&#23454;&#25968;&#12290;xVal&#36890;&#36807;&#23558;&#19987;&#29992;&#23884;&#20837;&#21521;&#37327;&#25353;&#25968;&#23383;&#20540;&#36827;&#34892;&#32553;&#25918;&#26469;&#34920;&#31034;&#32473;&#23450;&#30340;&#23454;&#25968;&#12290;&#32467;&#21512;&#20462;&#25913;&#21518;&#30340;&#25968;&#23383;&#25512;&#26029;&#26041;&#27861;&#65292;&#35813;&#31574;&#30053;&#20351;&#27169;&#22411;&#22312;&#32771;&#34385;&#20316;&#20026;&#20174;&#36755;&#20837;&#23383;&#31526;&#20018;&#30340;&#25968;&#23383;&#21040;&#36755;&#20986;&#23383;&#31526;&#20018;&#30340;&#25968;&#23383;&#30340;&#26144;&#23556;&#26102;&#25104;&#20026;&#31471;&#21040;&#31471;&#36830;&#32493;&#30340;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#26356;&#36866;&#29992;&#20110;&#31185;&#23398;&#39046;&#22495;&#24212;&#29992;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#25105;&#20204;&#22312;&#35768;&#22810;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#19982;&#29616;&#26377;&#30340;&#25968;&#23383;&#32534;&#30721;&#26041;&#26696;&#30456;&#27604;&#65292;&#25105;&#20204;&#21457;&#29616;xVal&#22312;&#20196;&#29260;&#25928;&#29575;&#21644;&#27867;&#21270;&#24615;&#33021;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models have not yet been broadly adapted for the analysis of scientific datasets due in part to the unique difficulties of tokenizing numbers. We propose xVal, a numerical encoding scheme that represents any real number using just a single token. xVal represents a given real number by scaling a dedicated embedding vector by the number value. Combined with a modified number-inference approach, this strategy renders the model end-to-end continuous when considered as a map from the numbers of the input string to those of the output string. This leads to an inductive bias that is generally more suitable for applications in scientific domains. We empirically evaluate our proposal on a number of synthetic and real-world datasets. Compared with existing number encoding schemes, we find that xVal is more token-efficient and demonstrates improved generalization.
&lt;/p&gt;</description></item></channel></rss>