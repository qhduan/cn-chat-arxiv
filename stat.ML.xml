<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#26377;&#38480;&#25968;&#25454;&#37327;&#22238;&#31572;&#31639;&#27861;&#24615;&#33021;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#40657;&#30418;&#27979;&#35797;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#22238;&#31572;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;&#38598;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#21644;&#29305;&#23450;&#27169;&#22411;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.07388</link><description>&lt;p&gt;
&#26080;&#20551;&#35774;&#27979;&#35797;&#31639;&#27861;&#24615;&#33021;&#30340;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
The Limits of Assumption-free Tests for Algorithm Performance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07388
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#26377;&#38480;&#25968;&#25454;&#37327;&#22238;&#31572;&#31639;&#27861;&#24615;&#33021;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#40657;&#30418;&#27979;&#35797;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#22238;&#31572;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;&#38598;&#19978;&#30340;&#25972;&#20307;&#24615;&#33021;&#21644;&#29305;&#23450;&#27169;&#22411;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#35780;&#20215;&#21644;&#27604;&#36739;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#22522;&#26412;&#30340;&#38382;&#39064;&#65292;&#19968;&#20010;&#31639;&#27861;&#22312;&#32473;&#23450;&#30340;&#24314;&#27169;&#20219;&#21153;&#20013;&#34920;&#29616;&#22914;&#20309;&#65292;&#21738;&#20010;&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#65311;&#35768;&#22810;&#26041;&#27861;&#24050;&#32463;&#24320;&#21457;&#20986;&#26469;&#35780;&#20272;&#31639;&#27861;&#24615;&#33021;&#65292;&#36890;&#24120;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#31574;&#30053;&#65292;&#23558;&#24863;&#20852;&#36259;&#30340;&#31639;&#27861;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#23376;&#38598;&#19978;&#37325;&#26032;&#35757;&#32451;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#30041;&#20986;&#25968;&#25454;&#28857;&#19978;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#24191;&#27867;&#20351;&#29992;&#36825;&#20123;&#31243;&#24207;&#65292;&#20294;&#23545;&#20110;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#26377;&#38480;&#30340;&#25968;&#25454;&#37327;&#19979;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#30340;&#19968;&#20123;&#22522;&#26412;&#38480;&#21046;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21306;&#20998;&#20102;&#20004;&#20010;&#38382;&#39064;: &#31639;&#27861;$A$&#22312;&#22823;&#23567;&#20026;$n$&#30340;&#35757;&#32451;&#38598;&#19978;&#23398;&#20064;&#38382;&#39064;&#26377;&#22810;&#22909;&#65292;&#20197;&#21450;&#22312;&#29305;&#23450;&#22823;&#23567;&#20026;$n$&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;$A$&#25152;&#20135;&#29983;&#30340;&#29305;&#23450;&#25311;&#21512;&#27169;&#22411;&#26377;&#22810;&#22909;&#65311;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#35777;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#23558;&#31639;&#27861;&#35270;&#20026;&#40657;&#30418;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#26080;&#27861;&#20934;&#30830;&#22320;&#22238;&#31572;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithm evaluation and comparison are fundamental questions in machine learning and statistics -- how well does an algorithm perform at a given modeling task, and which algorithm performs best? Many methods have been developed to assess algorithm performance, often based around cross-validation type strategies, retraining the algorithm of interest on different subsets of the data and assessing its performance on the held-out data points. Despite the broad use of such procedures, the theoretical properties of these methods are not yet fully understood. In this work, we explore some fundamental limits for answering these questions with limited amounts of data. In particular, we make a distinction between two questions: how good is an algorithm $A$ at the problem of learning from a training set of size $n$, versus, how good is a particular fitted model produced by running $A$ on a particular training data set of size $n$?   Our main results prove that, for any test that treats the algor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#20197;&#21450;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#30340;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#39044;&#27979;&#21644;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2307.08038</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind Fields. (arXiv:2307.08038v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08038
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#20197;&#21450;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#30340;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#39118;&#22330;&#30340;&#39044;&#27979;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#39118;&#22330;&#25968;&#25454;&#23545;&#20110;&#27668;&#20505;&#12289;&#28023;&#27915;&#21644;&#27668;&#35937;&#30740;&#31350;&#20013;&#30340;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#20110;&#39118;&#25968;&#25454;&#24448;&#24448;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#39640;&#31354;&#38388;&#21464;&#24322;&#24615;&#21644;&#24322;&#36136;&#24615;&#65292;&#22240;&#27492;&#23545;&#20855;&#26377;&#20004;&#20010;&#32500;&#24230;&#36895;&#24230;&#30340;&#21452;&#21464;&#37327;&#39118;&#22330;&#36827;&#34892;&#22823;&#35268;&#27169;&#31354;&#38388;&#25554;&#20540;&#25110;&#19979;&#32553;&#25918;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#31354;&#38388;&#32479;&#35745;&#23398;&#20013;&#65292;&#24120;&#29992;cokriging&#26469;&#39044;&#27979;&#21452;&#21464;&#37327;&#31354;&#38388;&#22330;&#12290;&#28982;&#32780;&#65292;cokriging&#39044;&#27979;&#22120;&#38500;&#20102;&#23545;&#39640;&#26031;&#36807;&#31243;&#26377;&#25928;&#22806;&#65292;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;cokriging&#35745;&#31639;&#37327;&#24040;&#22823;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21452;&#21464;&#37327;&#28145;&#24230;&#20811;&#37324;&#37329;&#30340;&#26041;&#27861;&#65292;&#23427;&#26159;&#19968;&#20010;&#30001;&#31354;&#38388;&#24452;&#21521;&#22522;&#20989;&#25968;&#26500;&#24314;&#30340;&#31354;&#38388;&#30456;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#21644;&#23884;&#20837;&#23618;&#65292;&#29992;&#20110;&#21452;&#21464;&#37327;&#31354;&#38388;&#25968;&#25454;&#39044;&#27979;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#33258;&#21161;&#27861;&#21644;&#38598;&#25104;DNN&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#30340;cokriging&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
High spatial resolution wind data are essential for a wide range of applications in climate, oceanographic and meteorological studies. Large-scale spatial interpolation or downscaling of bivariate wind fields having velocity in two dimensions is a challenging task because wind data tend to be non-Gaussian with high spatial variability and heterogeneity. In spatial statistics, cokriging is commonly used for predicting bivariate spatial fields. However, the cokriging predictor is not optimal except for Gaussian processes. Additionally, cokriging is computationally prohibitive for large datasets. In this paper, we propose a method, called bivariate DeepKriging, which is a spatially dependent deep neural network (DNN) with an embedding layer constructed by spatial radial basis functions for bivariate spatial data prediction. We then develop a distribution-free uncertainty quantification method based on bootstrap and ensemble DNN. Our proposed approach outperforms the traditional cokriging 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20102;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#36845;&#20195;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.11497</link><description>&lt;p&gt;
&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#24120;&#27493;&#38271;SGD&#30340;&#25910;&#25947;&#21644;&#38598;&#20013;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Convergence and concentration properties of constant step-size SGD through Markov chains. (arXiv:2306.11497v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20102;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#36845;&#20195;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20248;&#21270;&#24179;&#28369;&#19988;&#24378;&#20984;&#30340;&#30446;&#26631;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20854;&#24615;&#36136;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#36731;&#24494;&#21463;&#25511;&#26041;&#24046;&#30340;&#26080;&#20559;&#26799;&#24230;&#20272;&#35745;&#65292;&#36845;&#20195;&#20197;&#24635;&#21464;&#24046;&#36317;&#31163;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#22312;&#19982;&#20197;&#21069;&#24037;&#20316;&#30456;&#27604;&#26799;&#24230;&#22122;&#22768;&#20998;&#24067;&#30340;&#25918;&#23485;&#20551;&#35774;&#19979;&#65292;&#22312;Wasserstein-2&#36317;&#31163;&#19979;&#24314;&#31435;&#20102;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;&#30001;&#20110;&#26497;&#38480;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#36136;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#36825;&#20123;&#23545;&#20110;&#26799;&#24230;&#25104;&#31435;&#26102;&#65292;&#21518;&#32773;&#32487;&#25215;&#20102;&#20122;&#39640;&#26031;&#25110;&#20122;&#25351;&#25968;&#27987;&#24230;&#29305;&#24615;&#12290;&#36825;&#20801;&#35768;&#25512;&#23548;&#20986;&#23545;&#20110;&#26368;&#32456;&#20272;&#35745;&#30340;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;&#26368;&#21518;&#65292;&#22312;&#36825;&#31181;&#26465;&#20214;&#19979;&#65292;&#22312;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;Polyak-Ruppert&#24207;&#21015;&#30340;&#23614;&#37096;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#26080;&#32500;&#24230;&#20559;&#24046;&#38480;&#21046;&#12290;&#25152;&#26377;&#32467;&#26524;&#22343;&#20026;&#38750;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#21518;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the optimization of a smooth and strongly convex objective using constant step-size stochastic gradient descent (SGD) and study its properties through the prism of Markov chains. We show that, for unbiased gradient estimates with mildly controlled variance, the iteration converges to an invariant distribution in total variation distance. We also establish this convergence in Wasserstein-2 distance under a relaxed assumption on the gradient noise distribution compared to previous work. Thanks to the invariance property of the limit distribution, our analysis shows that the latter inherits sub-Gaussian or sub-exponential concentration properties when these hold true for the gradient. This allows the derivation of high-confidence bounds for the final estimate. Finally, under such conditions in the linear case, we obtain a dimension-free deviation bound for the Polyak-Ruppert average of a tail sequence. All our results are non-asymptotic and their consequences are discussed thr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.00833</link><description>&lt;p&gt;
&#33258;&#19979;&#32780;&#19978;&#20309;&#26102;&#20987;&#36133;&#33258;&#19978;&#32780;&#19979;&#36827;&#34892;&#20998;&#23618;&#31038;&#21306;&#26816;&#27979;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Bottom-up Beat Top-down in Hierarchical Community Detection?. (arXiv:2306.00833v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#30340;&#20998;&#23618;&#32858;&#31867;&#26159;&#25351;&#26597;&#25214;&#19968;&#32452;&#31038;&#21306;&#30340;&#26641;&#24418;&#32467;&#26500;&#65292;&#20854;&#20013;&#23618;&#27425;&#32467;&#26500;&#30340;&#36739;&#20302;&#32423;&#21035;&#26174;&#31034;&#26356;&#32454;&#31890;&#24230;&#30340;&#31038;&#21306;&#32467;&#26500;&#12290;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#31639;&#27861;&#26377;&#20004;&#20010;&#20027;&#35201;&#31867;&#21035;&#65306;&#33258;&#19978;&#32780;&#19979;&#30340;&#31639;&#27861;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#31639;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;&#20998;&#23618;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#36825;&#31181;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#22312;&#23618;&#27425;&#32467;&#26500;&#30340;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#24674;&#22797;&#26465;&#20214;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#33258;&#19978;&#32780;&#19979;&#31639;&#27861;&#30340;&#26465;&#20214;&#26469;&#35828;&#65292;&#38480;&#21046;&#26356;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hierarchical clustering of networks consists in finding a tree of communities, such that lower levels of the hierarchy reveal finer-grained community structures. There are two main classes of algorithms tackling this problem. Divisive ($\textit{top-down}$) algorithms recursively partition the nodes into two communities, until a stopping rule indicates that no further split is needed. In contrast, agglomerative ($\textit{bottom-up}$) algorithms first identify the smallest community structure and then repeatedly merge the communities using a $\textit{linkage}$ method. In this article, we establish theoretical guarantees for the recovery of the hierarchical tree and community structure of a Hierarchical Stochastic Block Model by a bottom-up algorithm. We also establish that this bottom-up algorithm attains the information-theoretic threshold for exact recovery at intermediate levels of the hierarchy. Notably, these recovery conditions are less restrictive compared to those existing for to
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#26469;&#33719;&#21462;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#36341;&#24314;&#35758;&#21644;&#31034;&#20363;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2206.02340</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#20135;&#29983;&#20102;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;
&lt;/p&gt;
&lt;p&gt;
Minimising the Expected Posterior Entropy Yields Optimal Summary Statistics. (arXiv:2206.02340v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02340
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#37325;&#35201;&#24615;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26368;&#23567;&#21270;&#21518;&#39564;&#29109;&#26469;&#33719;&#21462;&#26368;&#20248;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#36341;&#24314;&#35758;&#21644;&#31034;&#20363;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20302;&#32500;&#25688;&#35201;&#32479;&#35745;&#37327;&#23545;&#20110;&#39640;&#25928;&#65288;&#26080;&#20284;&#28982;&#65289;&#25512;&#26029;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#23545;&#19981;&#21516;&#31867;&#21035;&#30340;&#25688;&#35201;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#23545;&#20110;&#27491;&#30830;&#20998;&#26512;&#38477;&#32500;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#22312;&#27169;&#22411;&#30340;&#20808;&#39564;&#39044;&#27979;&#20998;&#24067;&#19979;&#26368;&#23567;&#21270;&#26399;&#26395;&#21518;&#39564;&#29109;&#65288;EPE&#65289;&#26469;&#33719;&#21462;&#25688;&#35201;&#12290;&#35768;&#22810;&#29616;&#26377;&#26041;&#27861;&#31561;&#25928;&#20110;&#25110;&#26159;&#26368;&#23567;&#21270;EPE&#30340;&#29305;&#27530;&#25110;&#26497;&#38480;&#24773;&#20917;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#33719;&#21462;&#26368;&#23567;&#21270;EPE&#30340;&#39640;&#20445;&#30495;&#25688;&#35201;&#65307;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#22522;&#20934;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#31034;&#20363;&#12290;&#25105;&#20204;&#26082;&#25552;&#20379;&#20102;&#33719;&#21462;&#26377;&#25928;&#25688;&#35201;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#21448;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#20855;&#20307;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extracting low-dimensional summary statistics from large datasets is essential for efficient (likelihood-free) inference. We characterise different classes of summaries and demonstrate their importance for correctly analysing dimensionality reduction algorithms. We propose obtaining summaries by minimising the expected posterior entropy (EPE) under the prior predictive distribution of the model. Many existing methods are equivalent to or are special or limiting cases of minimising the EPE. We develop a method to obtain high-fidelity summaries that minimise the EPE; we apply it to benchmark and real-world examples. We both offer a unifying perspective for obtaining informative summaries and provide concrete recommendations for practitioners.
&lt;/p&gt;</description></item></channel></rss>