<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;</title><link>https://arxiv.org/abs/2403.13748</link><description>&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#20013;&#22240;&#23376;&#21270;&#39640;&#26031;&#36817;&#20284;&#30340;&#24046;&#24322;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13748
&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#25955;&#24230;&#25490;&#24207;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#24182;&#19988;&#22240;&#23376;&#21270;&#36817;&#20284;&#26080;&#27861;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#20013;&#65292;&#32473;&#23450;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#20998;&#24067;$p$&#65292;&#38382;&#39064;&#26159;&#20174;&#19968;&#20123;&#26356;&#26131;&#22788;&#29702;&#30340;&#26063;$\mathcal{Q}$&#20013;&#35745;&#31639;&#26368;&#20339;&#36817;&#20284;$q$&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#36817;&#20284;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;Kullback-Leibler (KL)&#25955;&#24230;&#26469;&#25214;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23384;&#22312;&#20854;&#20182;&#26377;&#25928;&#30340;&#25955;&#24230;&#36873;&#25321;&#65292;&#24403;$\mathcal{Q}$&#19981;&#21253;&#21547;$p$&#26102;&#65292;&#27599;&#20010;&#25955;&#24230;&#37117;&#25903;&#25345;&#19981;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#39640;&#26031;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#34987;&#23545;&#35282;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#36817;&#20284;&#25152;&#24433;&#21709;&#30340;VI&#32467;&#26524;&#20013;&#65292;&#25955;&#24230;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;VI&#32467;&#26524;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#30340;&#25955;&#24230;&#21487;&#20197;&#36890;&#36807;&#23427;&#20204;&#30340;&#21464;&#20998;&#36817;&#20284;&#35823;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#21508;&#31181;&#24230;&#37327;&#65292;&#22914;&#26041;&#24046;&#12289;&#31934;&#24230;&#21644;&#29109;&#65292;&#36827;&#34892;\textit{&#25490;&#24207;}&#12290;&#25105;&#20204;&#36824;&#24471;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#23450;&#29702;&#65292;&#34920;&#26126;&#26080;&#27861;&#36890;&#36807;&#22240;&#23376;&#21270;&#36817;&#20284;&#21516;&#26102;&#21305;&#37197;&#36825;&#20123;&#24230;&#37327;&#20013;&#30340;&#20219;&#24847;&#20004;&#20010;&#65307;&#22240;&#27492;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13748v1 Announce Type: cross  Abstract: Given an intractable distribution $p$, the problem of variational inference (VI) is to compute the best approximation $q$ from some more tractable family $\mathcal{Q}$. Most commonly the approximation is found by minimizing a Kullback-Leibler (KL) divergence. However, there exist other valid choices of divergences, and when $\mathcal{Q}$ does not contain~$p$, each divergence champions a different solution. We analyze how the choice of divergence affects the outcome of VI when a Gaussian with a dense covariance matrix is approximated by a Gaussian with a diagonal covariance matrix. In this setting we show that different divergences can be \textit{ordered} by the amount that their variational approximations misestimate various measures of uncertainty, such as the variance, precision, and entropy. We also derive an impossibility theorem showing that no two of these measures can be simultaneously matched by a factorized approximation; henc
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#21464;&#20998;Shapley&#32593;&#32476;&#65292;&#36890;&#36807;&#27010;&#29575;&#21270;&#30340;&#26041;&#27861;&#31616;&#21270;&#20102;&#35745;&#31639;Shapley&#20540;&#30340;&#36807;&#31243;&#65292;&#24182;&#35299;&#20915;&#20102;&#20272;&#35745;&#27169;&#22411;&#36793;&#38469;&#20540;&#21644;&#22788;&#29702;&#35299;&#37322;&#21487;&#21464;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.04211</link><description>&lt;p&gt;
&#21464;&#20998;Shapley&#32593;&#32476;&#65306;&#19968;&#31181;&#27010;&#29575;&#21270;&#30340;&#26041;&#27861;&#29992;&#20110;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#33258;&#35299;&#37322;Shapley&#20540;
&lt;/p&gt;
&lt;p&gt;
Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#21464;&#20998;Shapley&#32593;&#32476;&#65292;&#36890;&#36807;&#27010;&#29575;&#21270;&#30340;&#26041;&#27861;&#31616;&#21270;&#20102;&#35745;&#31639;Shapley&#20540;&#30340;&#36807;&#31243;&#65292;&#24182;&#35299;&#20915;&#20102;&#20272;&#35745;&#27169;&#22411;&#36793;&#38469;&#20540;&#21644;&#22788;&#29702;&#35299;&#37322;&#21487;&#21464;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley&#20540;&#24050;&#32463;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#38416;&#26126;&#27169;&#22411;&#20915;&#31574;&#36807;&#31243;&#30340;&#22522;&#30784;&#24037;&#20855;&#12290;&#23613;&#31649;&#23427;&#20204;&#34987;&#24191;&#27867;&#37319;&#29992;&#24182;&#20855;&#26377;&#28385;&#36275;&#37325;&#35201;&#21487;&#35299;&#37322;&#24615;&#20844;&#29702;&#30340;&#29420;&#29305;&#33021;&#21147;&#65292;&#20294;&#22312;&#20272;&#35745;&#36807;&#31243;&#20013;&#20173;&#28982;&#23384;&#22312;&#35745;&#31639;&#25361;&#25112;&#65292;&#21253;&#25324;&#65288;i&#65289;&#23545;&#27169;&#22411;&#22312;&#25152;&#26377;&#21487;&#33021;&#30340;&#36755;&#20837;&#29305;&#24449;&#32452;&#21512;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#65288;ii&#65289;&#20272;&#35745;&#27169;&#22411;&#30340;&#36793;&#38469;&#20540;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#22788;&#29702;&#35299;&#37322;&#30340;&#21487;&#21464;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#35299;&#37322;&#26041;&#27861;&#65292;&#26174;&#33879;&#31616;&#21270;&#20102;Shapley&#20540;&#30340;&#35745;&#31639;&#65292;&#21482;&#38656;&#35201;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#12290;&#37492;&#20110;Shapley&#20540;&#30340;&#30830;&#23450;&#24615;&#22788;&#29702;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#38480;&#21046;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#23558;&#27010;&#29575;&#26694;&#26550;&#32435;&#20837;&#20854;&#20013;&#20197;&#25429;&#25417;&#35299;&#37322;&#20013;&#22266;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#20854;&#20182;&#26367;&#20195;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#19981;&#30452;&#25509;&#20381;&#36182;&#20110;&#35266;&#27979;&#25968;&#25454;&#31354;&#38388;&#26469;&#20272;&#35745;&#36793;&#38469;&#20540;&#65307;&#30456;&#21453;&#65292;&#23427;&#20351;&#29992;&#20174;&#28508;&#22312;&#30340;&#12289;&#29305;&#23450;&#20110;&#29305;&#24449;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#27966;&#29983;&#20986;&#30340;&#21487;&#36866;&#24212;&#30340;&#22522;&#32447;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Shapley values have emerged as a foundational tool in machine learning (ML) for elucidating model decision-making processes. Despite their widespread adoption and unique ability to satisfy essential explainability axioms, computational challenges persist in their estimation when ($i$) evaluating a model over all possible subset of input feature combinations, ($ii$) estimating model marginals, and ($iii$) addressing variability in explanations. We introduce a novel, self-explaining method that simplifies the computation of Shapley values significantly, requiring only a single forward pass. Recognizing the deterministic treatment of Shapley values as a limitation, we explore incorporating a probabilistic framework to capture the inherent uncertainty in explanations. Unlike alternatives, our technique does not rely directly on the observed data space to estimate marginals; instead, it uses adaptable baseline values derived from a latent, feature-specific embedding space, generated by a no
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#20998;&#21306;&#20998;&#31867;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20986;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#26032;&#29305;&#24615;&#65292;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;</title><link>https://arxiv.org/abs/2312.14889</link><description>&lt;p&gt;
&#35770;&#20174;&#21487;&#35266;&#27979;&#21644;&#31169;&#23494;&#25968;&#25454;&#20013;&#23454;&#29616;&#36895;&#29575;&#26368;&#20248;&#20998;&#21306;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
On Rate-Optimal Partitioning Classification from Observable and from Privatised Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14889
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#20998;&#21306;&#20998;&#31867;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20986;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#26032;&#29305;&#24615;&#65292;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20998;&#21306;&#20998;&#31867;&#30340;&#32463;&#20856;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#21253;&#25324;&#21487;&#35266;&#27979;&#65288;&#38750;&#31169;&#23494;&#65289;&#21644;&#31169;&#23494;&#25968;&#25454;&#12290;&#25105;&#20204;&#20551;&#35774;&#29305;&#24449;&#21521;&#37327;$X$&#21462;&#20540;&#20110;$\mathbb{R}^d$&#65292;&#20854;&#26631;&#31614;&#20026;$Y$&#12290;&#20043;&#21069;&#20851;&#20110;&#20998;&#21306;&#20998;&#31867;&#22120;&#30340;&#32467;&#26524;&#22522;&#20110;&#24378;&#23494;&#24230;&#20551;&#35774;&#65292;&#36825;&#31181;&#20551;&#35774;&#38480;&#21046;&#36739;&#22823;&#65292;&#25105;&#20204;&#36890;&#36807;&#31616;&#21333;&#30340;&#20363;&#23376;&#21152;&#20197;&#35777;&#26126;&#12290;&#25105;&#20204;&#20551;&#35774;$X$&#30340;&#20998;&#24067;&#26159;&#32477;&#23545;&#36830;&#32493;&#20998;&#24067;&#21644;&#31163;&#25955;&#20998;&#24067;&#30340;&#28151;&#21512;&#20307;&#65292;&#20854;&#20013;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#38598;&#20013;&#20110;&#19968;&#20010;$d_a$&#32500;&#23376;&#31354;&#38388;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#22312;&#26356;&#23485;&#26494;&#30340;&#26465;&#20214;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65306;&#38500;&#20102;&#26631;&#20934;&#30340;Lipschitz&#21644;&#36793;&#38469;&#26465;&#20214;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#19968;&#20010;&#26032;&#29305;&#24615;&#65292;&#36890;&#36807;&#35813;&#29305;&#24615;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;&#65292;&#23545;&#20110;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14889v2 Announce Type: replace-cross  Abstract: In this paper we revisit the classical method of partitioning classification and study its convergence rate under relaxed conditions, both for observable (non-privatised) and for privatised data. Let the feature vector $X$ take values in $\mathbb{R}^d$ and denote its label by $Y$. Previous results on the partitioning classifier worked with the strong density assumption, which is restrictive, as we demonstrate through simple examples. We assume that the distribution of $X$ is a mixture of an absolutely continuous and a discrete distribution, such that the absolutely continuous component is concentrated to a $d_a$ dimensional subspace. Here, we study the problem under much milder assumptions: in addition to the standard Lipschitz and margin conditions, a novel characteristic of the absolutely continuous component is introduced, by which the exact convergence rate of the classification error probability is calculated, both for the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24207;&#21015;&#25193;&#23637;&#30340;Gibbs&#20808;&#39564;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20271;&#24681;&#26031;&#22374;-&#20911;&#183;&#23494;&#26031;&#23450;&#29702;&#22312;&#27969;&#24418;&#19978;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.12882</link><description>&lt;p&gt;
&#24102;&#26377;&#24207;&#21015;Gibbs&#20808;&#39564;&#30340;&#36129;&#29486;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sequential Gibbs Posteriors with Applications to Principal Component Analysis. (arXiv:2310.12882v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12882
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24207;&#21015;&#25193;&#23637;&#30340;Gibbs&#20808;&#39564;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20271;&#24681;&#26031;&#22374;-&#20911;&#183;&#23494;&#26031;&#23450;&#29702;&#22312;&#27969;&#24418;&#19978;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gibbs&#20808;&#39564;&#19982;&#20808;&#39564;&#20998;&#24067;&#20056;&#20197;&#25351;&#25968;&#25439;&#22833;&#20989;&#25968;&#25104;&#27604;&#20363;&#65292;&#20854;&#20013;&#20851;&#38190;&#35843;&#25972;&#21442;&#25968;&#22312;&#25439;&#22833;&#19982;&#20808;&#39564;&#20013;&#26435;&#37325;&#20449;&#24687;&#65292;&#24182;&#25552;&#20379;&#25511;&#21046;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#30340;&#33021;&#21147;&#12290;Gibbs&#20808;&#39564;&#20026;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#25512;&#29702;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21407;&#21017;&#30340;&#26694;&#26550;&#65292;&#20294;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#21333;&#19968;&#35843;&#25972;&#21442;&#25968;&#20250;&#23548;&#33268;&#36739;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24207;&#21015;&#25193;&#23637;&#30340;Gibbs&#20808;&#39564;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#24207;&#21015;&#21518;&#39564;&#23637;&#31034;&#20102;&#38598;&#20013;&#24615;&#21644;&#19968;&#20010;&#20271;&#24681;&#26031;&#22374;-&#20911;&#183;&#23494;&#26031;&#23450;&#29702;&#65292;&#35813;&#23450;&#29702;&#22312;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#21644;&#27969;&#24418;&#19978;&#26131;&#20110;&#39564;&#35777;&#30340;&#26465;&#20214;&#19979;&#25104;&#31435;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20256;&#32479;&#22522;&#20110;&#20284;&#28982;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#22312;&#27969;&#24418;&#19978;&#30340;&#31532;&#19968;&#20010;&#20271;&#24681;&#26031;&#22374;-&#20911;&#183;&#23494;&#26031;&#23450;&#29702;&#12290;&#25152;&#26377;&#26041;&#27861;&#37117;&#26377;&#31034;&#20363;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gibbs posteriors are proportional to a prior distribution multiplied by an exponentiated loss function, with a key tuning parameter weighting information in the loss relative to the prior and providing a control of posterior uncertainty. Gibbs posteriors provide a principled framework for likelihood-free Bayesian inference, but in many situations, including a single tuning parameter inevitably leads to poor uncertainty quantification. In particular, regardless of the value of the parameter, credible regions have far from the nominal frequentist coverage even in large samples. We propose a sequential extension to Gibbs posteriors to address this problem. We prove the proposed sequential posterior exhibits concentration and a Bernstein-von Mises theorem, which holds under easy to verify conditions in Euclidean space and on manifolds. As a byproduct, we obtain the first Bernstein-von Mises theorem for traditional likelihood-based Bayesian posteriors on manifolds. All methods are illustrat
&lt;/p&gt;</description></item></channel></rss>