<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#30340;&#20840;&#23616;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#39044;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#26469;&#20943;&#23569;&#39069;&#22806;&#30340;&#35745;&#31639;&#36127;&#36733;&#12290;</title><link>https://arxiv.org/abs/2402.14402</link><description>&lt;p&gt;
&#20840;&#23616;&#23433;&#20840;&#39034;&#24207;&#23398;&#20064;&#36890;&#36807;&#39640;&#25928;&#30693;&#35782;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Global Safe Sequential Learning via Efficient Knowledge Transfer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14402
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#30340;&#20840;&#23616;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#39044;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#26469;&#20943;&#23569;&#39069;&#22806;&#30340;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14402v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#25688;&#35201;: &#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#20363;&#22914;&#20027;&#21160;&#23398;&#20064;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#26469;&#23398;&#20064;&#19968;&#20010;&#20219;&#21153;&#12290;&#22312;&#35768;&#22810;&#21307;&#23398;&#25110;&#24037;&#31243;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#36873;&#25321;&#21463;&#20808;&#39564;&#26410;&#30693;&#30340;&#23433;&#20840;&#26465;&#20214;&#38480;&#21046;&#12290;&#19968;&#26465;&#26377;&#21069;&#36884;&#30340;&#23433;&#20840;&#23398;&#20064;&#26041;&#27861;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26469;&#24314;&#27169;&#23433;&#20840;&#27010;&#29575;&#65292;&#24182;&#22312;&#20855;&#26377;&#36739;&#39640;&#23433;&#20840;&#32622;&#20449;&#24230;&#30340;&#21306;&#22495;&#20013;&#36827;&#34892;&#25968;&#25454;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#20934;&#30830;&#30340;&#23433;&#20840;&#24314;&#27169;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#25110;&#28040;&#32791;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#23433;&#20840;&#32622;&#20449;&#24230;&#38598;&#20013;&#22312;&#32473;&#23450;&#30340;&#35266;&#27979;&#20540;&#21608;&#22260;&#65292;&#23548;&#33268;&#23616;&#37096;&#25506;&#32034;&#12290;&#30001;&#20110;&#22312;&#23433;&#20840;&#20851;&#38190;&#23454;&#39564;&#20013;&#36890;&#24120;&#23384;&#22312;&#21487;&#36716;&#31227;&#30340;&#28304;&#30693;&#35782;&#65292;&#25105;&#20204;&#25552;&#20986;&#32771;&#34385;&#36716;&#31227;&#23433;&#20840;&#39034;&#24207;&#23398;&#20064;&#26469;&#21152;&#36895;&#23433;&#20840;&#23398;&#20064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#32771;&#34385;&#20808;&#35745;&#31639;&#28304;&#32452;&#20214;&#65292;&#20197;&#20943;&#23569;&#24341;&#20837;&#28304;&#25968;&#25454;&#24102;&#26469;&#30340;&#39069;&#22806;&#35745;&#31639;&#36127;&#36733;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14402v1 Announce Type: new  Abstract: Sequential learning methods such as active learning and Bayesian optimization select the most informative data to learn about a task. In many medical or engineering applications, the data selection is constrained by a priori unknown safety conditions. A promissing line of safe learning methods utilize Gaussian processes (GPs) to model the safety probability and perform data selection in areas with high safety confidence. However, accurate safety modeling requires prior knowledge or consumes data. In addition, the safety confidence centers around the given observations which leads to local exploration. As transferable source knowledge is often available in safety critical experiments, we propose to consider transfer safe sequential learning to accelerate the learning of safety. We further consider a pre-computation of source components to reduce the additional computational load that is introduced by incorporating source data. In this pap
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#20013;&#25506;&#32034;&#39033;&#30340;&#26032;&#20998;&#26512;&#26041;&#27861;&#65292;&#21306;&#20998;&#20102;&#20854;&#24179;&#28369;&#23398;&#20064;&#30446;&#26631;&#21644;&#22686;&#21152;&#26799;&#24230;&#20272;&#35745;&#30340;&#20004;&#31181;&#19981;&#21516;&#20316;&#29992;&#12290;&#21516;&#26102;&#65292;&#35814;&#32454;&#35752;&#35770;&#21644;&#23454;&#35777;&#20102;&#22522;&#20110;&#29109;&#22870;&#21169;&#30340;&#25506;&#32034;&#31574;&#30053;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#24320;&#36767;&#20102;&#26410;&#26469;&#23545;&#36825;&#20123;&#31574;&#30053;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2402.00162</link><description>&lt;p&gt;
&#25919;&#31574;&#26799;&#24230;&#25506;&#32034;&#32972;&#21518;&#30340;&#31070;&#35805;
&lt;/p&gt;
&lt;p&gt;
Behind the Myth of Exploration in Policy Gradients
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#20013;&#25506;&#32034;&#39033;&#30340;&#26032;&#20998;&#26512;&#26041;&#27861;&#65292;&#21306;&#20998;&#20102;&#20854;&#24179;&#28369;&#23398;&#20064;&#30446;&#26631;&#21644;&#22686;&#21152;&#26799;&#24230;&#20272;&#35745;&#30340;&#20004;&#31181;&#19981;&#21516;&#20316;&#29992;&#12290;&#21516;&#26102;&#65292;&#35814;&#32454;&#35752;&#35770;&#21644;&#23454;&#35777;&#20102;&#22522;&#20110;&#29109;&#22870;&#21169;&#30340;&#25506;&#32034;&#31574;&#30053;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#24320;&#36767;&#20102;&#26410;&#26469;&#23545;&#36825;&#20123;&#31574;&#30053;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#26159;&#35299;&#20915;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#30340;&#25511;&#21046;&#38382;&#39064;&#30340;&#26377;&#25928;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;&#20026;&#20102;&#35745;&#31639;&#25509;&#36817;&#26368;&#20248;&#30340;&#31574;&#30053;&#65292;&#22312;&#23454;&#36341;&#20013;&#24517;&#39035;&#22312;&#23398;&#20064;&#30446;&#26631;&#20013;&#21253;&#21547;&#25506;&#32034;&#39033;&#12290;&#23613;&#31649;&#36825;&#20123;&#39033;&#30340;&#26377;&#25928;&#24615;&#36890;&#24120;&#36890;&#36807;&#23545;&#25506;&#32034;&#29615;&#22659;&#30340;&#20869;&#22312;&#38656;&#27714;&#36827;&#34892;&#35777;&#26126;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#21306;&#20998;&#20102;&#36825;&#20123;&#25216;&#26415;&#30340;&#20004;&#31181;&#19981;&#21516;&#21547;&#20041;&#12290;&#39318;&#20808;&#65292;&#23427;&#20204;&#20351;&#24471;&#24179;&#28369;&#23398;&#20064;&#30446;&#26631;&#25104;&#20026;&#21487;&#33021;&#65292;&#24182;&#22312;&#20445;&#25345;&#20840;&#23616;&#26368;&#22823;&#20540;&#30340;&#21516;&#26102;&#28040;&#38500;&#20102;&#23616;&#37096;&#26368;&#20248;&#35299;&#12290;&#20854;&#27425;&#65292;&#23427;&#20204;&#20462;&#25913;&#20102;&#26799;&#24230;&#20272;&#35745;&#65292;&#22686;&#21152;&#20102;&#38543;&#26426;&#21442;&#25968;&#26356;&#26032;&#26368;&#32456;&#25552;&#20379;&#26368;&#20248;&#31574;&#30053;&#30340;&#27010;&#29575;&#12290;&#22522;&#20110;&#36825;&#20123;&#25928;&#24212;&#65292;&#25105;&#20204;&#35752;&#35770;&#24182;&#23454;&#35777;&#20102;&#22522;&#20110;&#29109;&#22870;&#21169;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#31361;&#20986;&#20102;&#20854;&#23616;&#38480;&#24615;&#65292;&#24182;&#20026;&#35774;&#35745;&#21644;&#20998;&#26512;&#36825;&#20123;&#31574;&#30053;&#30340;&#26410;&#26469;&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy-gradient algorithms are effective reinforcement learning methods for solving control problems with continuous state and action spaces. To compute near-optimal policies, it is essential in practice to include exploration terms in the learning objective. Although the effectiveness of these terms is usually justified by an intrinsic need to explore environments, we propose a novel analysis and distinguish two different implications of these techniques. First, they make it possible to smooth the learning objective and to eliminate local optima while preserving the global maximum. Second, they modify the gradient estimates, increasing the probability that the stochastic parameter update eventually provides an optimal policy. In light of these effects, we discuss and illustrate empirically exploration strategies based on entropy bonuses, highlighting their limitations and opening avenues for future works in the design and analysis of such strategies.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#20998;&#26512;&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#30340;&#28526;&#27969;&#65292;&#25581;&#31034;&#20102;&#20854;&#22797;&#26434;&#30340;&#28023;&#27915;&#20122;&#20013;&#23610;&#24230;&#29305;&#24449;&#20197;&#21450;&#29289;&#29702;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#27861;&#26469;&#22686;&#24378;&#20998;&#26512;&#30340;&#31283;&#20581;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01377</link><description>&lt;p&gt;
&#21033;&#29992;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#20998;&#26512;&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#30340;&#28526;&#27969;
&lt;/p&gt;
&lt;p&gt;
Analysis of tidal flows through the Strait of Gibraltar using Dynamic Mode Decomposition. (arXiv:2311.01377v1 [math.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01377
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#20998;&#26512;&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#30340;&#28526;&#27969;&#65292;&#25581;&#31034;&#20102;&#20854;&#22797;&#26434;&#30340;&#28023;&#27915;&#20122;&#20013;&#23610;&#24230;&#29305;&#24449;&#20197;&#21450;&#29289;&#29702;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#27861;&#26469;&#22686;&#24378;&#20998;&#26512;&#30340;&#31283;&#20581;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#26159;&#19968;&#20010;&#30001;&#22320;&#24418;&#12289;&#28526;&#27728;&#21147;&#12289;&#19981;&#31283;&#23450;&#24615;&#21644;&#38750;&#32447;&#24615;&#27700;&#21147;&#36807;&#31243;&#24433;&#21709;&#30340;&#22797;&#26434;&#28023;&#27915;&#20122;&#20013;&#23610;&#24230;&#29305;&#24449;&#21306;&#22495;&#65292;&#25152;&#26377;&#36825;&#20123;&#37117;&#21463;&#38750;&#32447;&#24615;&#27969;&#20307;&#36816;&#21160;&#26041;&#31243;&#31649;&#25511;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;3D MIT&#36890;&#29992;&#29615;&#27969;&#27169;&#22411;&#27169;&#25311;&#65292;&#21253;&#25324;&#27874;&#28010;&#12289;&#28065;&#26059;&#21644;&#26059;&#22238;&#65292;&#25581;&#31034;&#36825;&#20123;&#29616;&#35937;&#32972;&#21518;&#30340;&#29289;&#29702;&#26426;&#21046;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#37319;&#29992;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;DMD&#65289;&#23558;&#27169;&#25311;&#24555;&#29031;&#20998;&#35299;&#25104;Koopman&#27169;&#24577;&#65292;&#20855;&#26377;&#19981;&#21516;&#30340;&#25351;&#25968;&#22686;&#38271;/&#34928;&#20943;&#29575;&#21644;&#25391;&#33633;&#39057;&#29575;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#21253;&#25324;&#35780;&#20272;DMD&#22312;&#25429;&#25417;&#24050;&#30693;&#29305;&#24449;&#12289;&#25581;&#31034;&#26032;&#20803;&#32032;&#12289;&#25490;&#21517;&#27169;&#24577;&#21644;&#25506;&#32034;&#38477;&#38454;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#20123;&#20462;&#25913;&#26469;&#22686;&#24378;DMD&#30340;&#31283;&#20581;&#24615;&#12289;&#25968;&#20540;&#31934;&#24230;&#21644;&#29305;&#24449;&#20540;&#30340;&#31283;&#20581;&#24615;&#12290;DMD&#20998;&#26512;&#20135;&#29983;&#20102;&#23545;&#27969;&#21160;&#27169;&#24335;&#12289;&#20869;&#27874;&#24418;&#25104;&#21644;&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#21160;&#21147;&#23398;&#30340;&#20840;&#38754;&#20102;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Strait of Gibraltar is a region characterized by intricate oceanic sub-mesoscale features, influenced by topography, tidal forces, instabilities, and nonlinear hydraulic processes, all governed by the nonlinear equations of fluid motion. In this study, we aim to uncover the underlying physics of these phenomena within 3D MIT general circulation model simulations, including waves, eddies, and gyres. To achieve this, we employ Dynamic Mode Decomposition (DMD) to break down simulation snapshots into Koopman modes, with distinct exponential growth/decay rates and oscillation frequencies. Our objectives encompass evaluating DMD's efficacy in capturing known features, unveiling new elements, ranking modes, and exploring order reduction. We also introduce modifications to enhance DMD's robustness, numerical accuracy, and robustness of eigenvalues. DMD analysis yields a comprehensive understanding of flow patterns, internal wave formation, and the dynamics of the Strait of Gibraltar, its m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09254</link><description>&lt;p&gt;
&#29992;&#20110;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#22686;&#24378;&#27169;&#22411;&#21487;&#20449;&#24230;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#30001;&#20110;&#23545;&#29983;&#25104;&#34394;&#26500;&#20107;&#23454;&#30340;&#25285;&#24551;&#65292;&#26368;&#36817;&#20852;&#36215;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;GLM&#65289;&#29305;&#21035;&#24378;&#35843;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31070;&#32463;&#39044;&#27979;&#38598;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;&#30340;&#26041;&#24335;&#37327;&#21270;GLM&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#39044;&#27979;&#38598;&#27169;&#22411;&#36890;&#36807;&#26631;&#37327;&#20540;&#21442;&#25968;&#21270;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#39044;&#27979;&#38598;&#65292;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#20173;&#28385;&#36275;PAC&#20445;&#35777;&#12290;&#36890;&#36807;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#20845;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.17583</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#26080;&#38480;&#26641;&#29366;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Neural Networks as Infinite Tree-Structured Probabilistic Graphical Models. (arXiv:2305.17583v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17583
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;&#27010;&#29575;&#22270;&#27169;&#22411;(PGMs)&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26399;&#38388;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#26366;&#32463;&#30340;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#26680;&#26426;&#22120;&#25110;&#26080;&#38480;&#22823;&#23567;&#30340;&#39640;&#26031;&#36807;&#31243;&#30340;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#12290;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) lack the precise semantics and definitive probabilistic interpretation of probabilistic graphical models (PGMs). In this paper, we propose an innovative solution by constructing infinite tree-structured PGMs that correspond exactly to neural networks. Our research reveals that DNNs, during forward propagation, indeed perform approximations of PGM inference that are precise in this alternative PGM structure. Not only does our research complement existing studies that describe neural networks as kernel machines or infinite-sized Gaussian processes, it also elucidates a more direct approximation that DNNs make to exact inference in PGMs. Potential benefits include improved pedagogy and interpretation of DNNs, and algorithms that can merge the strengths of PGMs and DNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#22120;&#20197;&#21382;&#21490;&#35266;&#23519;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#39640;&#25928;&#12289;&#28789;&#27963;&#21644;&#34920;&#31034;&#33021;&#21147;&#31561;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.12569</link><description>&lt;p&gt;
&#26377;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#26159;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#30340;&#24517;&#22791;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional Generative Modeling is All You Need for Marked Temporal Point Processes. (arXiv:2305.12569v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#22120;&#20197;&#21382;&#21490;&#35266;&#23519;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#39640;&#25928;&#12289;&#28789;&#27963;&#21644;&#34920;&#31034;&#33021;&#21147;&#31561;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29983;&#25104;&#24314;&#27169;&#30340;&#36827;&#27493;&#20351;&#24471;&#20174;&#19978;&#19979;&#25991;&#20449;&#24687;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#20869;&#23481;&#25104;&#20026;&#21487;&#33021;&#65292;&#20294;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#22914;&#20309;&#25945;&#27169;&#22411;&#30693;&#36947;&#20309;&#26102;&#29983;&#25104;&#20869;&#23481;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#24178;&#20928;&#12289;&#28789;&#27963;&#21644;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#28041;&#21450;&#22810;&#32500;&#26631;&#35760;&#30340;&#21508;&#31181;&#24212;&#29992;&#12290;&#25105;&#20204;&#26088;&#22312;&#25429;&#25417;&#28857;&#36807;&#31243;&#30340;&#20998;&#24067;&#32780;&#19981;&#38656;&#26126;&#30830;&#25351;&#23450;&#26465;&#20214;&#24378;&#24230;&#25110;&#27010;&#29575;&#23494;&#24230;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#26465;&#20214;&#29983;&#25104;&#22120;&#65292;&#20197;&#20107;&#20214;&#21382;&#21490;&#20026;&#36755;&#20837;&#24182;&#29983;&#25104;&#22312;&#20808;&#21069;&#35266;&#23519;&#21040;&#30340;&#20107;&#20214;&#19979;&#65292;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#21033;&#30410;&#65292;&#21253;&#25324;&#22312;&#23398;&#20064;&#27169;&#22411;&#21644;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#30340;&#24322;&#24120;&#25928;&#29575;&#20197;&#21450;&#30456;&#24403;&#22823;&#30340;&#34920;&#31034;&#33021;&#21147;&#26469;&#25429;&#25417;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in generative modeling have made it possible to generate high-quality content from context information, but a key question remains: how to teach models to know when to generate content? To answer this question, this study proposes a novel event generative model that draws its statistical intuition from marked temporal point processes, and offers a clean, flexible, and computationally efficient solution for a wide range of applications involving multi-dimensional marks. We aim to capture the distribution of the point process without explicitly specifying the conditional intensity or probability density. Instead, we use a conditional generator that takes the history of events as input and generates the high-quality subsequent event that is likely to occur given the prior observations. The proposed framework offers a host of benefits, including exceptional efficiency in learning the model and generating samples, as well as considerable representational power to capture
&lt;/p&gt;</description></item><item><title>XPER&#26041;&#27861;&#33021;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#65292;&#24182;&#21487;&#29992;&#20110;&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#26500;&#24314;&#21516;&#36136;&#21270;&#20010;&#20307;&#32676;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2212.05866</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#24615;&#33021;&#65306;&#34913;&#37327;&#39044;&#27979;&#24615;&#33021;&#30340;&#39537;&#21160;&#21147;
&lt;/p&gt;
&lt;p&gt;
Explainable Performance: Measuring the Driving Forces of Predictive Performance. (arXiv:2212.05866v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05866
&lt;/p&gt;
&lt;p&gt;
XPER&#26041;&#27861;&#33021;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#65292;&#24182;&#21487;&#29992;&#20110;&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#26500;&#24314;&#21516;&#36136;&#21270;&#20010;&#20307;&#32676;&#20307;&#65292;&#20174;&#32780;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;XPER&#65288;eXplainable PERformance&#65289;&#26041;&#27861;&#26469;&#34913;&#37327;&#36755;&#20837;&#29305;&#24449;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#20855;&#20307;&#36129;&#29486;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#22522;&#20110;Shapley&#20540;&#65292;&#26082;&#19981;&#20381;&#36182;&#20110;&#27169;&#22411;&#65292;&#20063;&#19981;&#20381;&#36182;&#20110;&#24615;&#33021;&#24230;&#37327;&#12290;&#27492;&#22806;&#65292;XPER&#21487;&#22312;&#27169;&#22411;&#32423;&#21035;&#25110;&#20010;&#20307;&#32423;&#21035;&#23454;&#29616;&#12290;&#25105;&#20204;&#35777;&#26126;XPER&#20855;&#26377;&#26631;&#20934;&#35299;&#37322;&#24615;&#26041;&#27861;&#65288;SHAP&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;&#22312;&#36151;&#27454;&#36829;&#32422;&#39044;&#27979;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;XPER&#22788;&#29702;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#22806;&#24615;&#33021;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#20010;&#20307;XPER&#20540;&#23545;&#20182;&#20204;&#36827;&#34892;&#32858;&#31867;&#26469;&#26500;&#24314;&#21516;&#36136;&#21270;&#30340;&#20010;&#20307;&#32676;&#20307;&#12290;&#25105;&#20204;&#21457;&#29616;&#20272;&#35745;&#32676;&#20307;&#29305;&#23450;&#30340;&#27169;&#22411;&#27604;&#19968;&#20010;&#27169;&#22411;&#36866;&#29992;&#20110;&#25152;&#26377;&#20010;&#20307;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the XPER (eXplainable PERformance) methodology to measure the specific contribution of the input features to the predictive performance of a model. Our methodology is theoretically grounded on Shapley values and is both model-agnostic and performance metric-agnostic. Furthermore, XPER can be implemented either at the model level or at the individual level. We demonstrate that XPER has as a special case the standard explainability method in machine learning (SHAP). In a loan default forecasting application, we show how XPER can be used to deal with heterogeneity issues and significantly boost out-of-sample performance. To do so, we build homogeneous groups of individuals by clustering them based on their individual XPER values. We find that estimating group-specific models yields a much higher predictive accuracy than with a one-fits-all model.
&lt;/p&gt;</description></item></channel></rss>