<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#26367;&#20195;&#26041;&#27861;&#20013;&#65292;&#20851;&#20110;&#20302;&#32500;&#36817;&#20284;&#31209;&#30340;&#19968;&#20010;&#19979;&#30028;&#65292;&#20174;&#32780;&#20445;&#35777;&#21487;&#38752;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#24182;&#23558;&#26377;&#25928;&#32500;&#24230;&#19982;&#26368;&#22823;&#32479;&#35745;&#26464;&#26438;&#24471;&#20998;&#32852;&#31995;&#36215;&#26469;&#12290;</title><link>https://arxiv.org/abs/2402.12885</link><description>&lt;p&gt;
&#23545;&#26368;&#22823;&#36793;&#38469;&#33258;&#30001;&#24230;&#30340;&#19968;&#20010;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
A Bound on the Maximal Marginal Degrees of Freedom
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12885
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#26367;&#20195;&#26041;&#27861;&#20013;&#65292;&#20851;&#20110;&#20302;&#32500;&#36817;&#20284;&#31209;&#30340;&#19968;&#20010;&#19979;&#30028;&#65292;&#20174;&#32780;&#20445;&#35777;&#21487;&#38752;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#24182;&#23558;&#26377;&#25928;&#32500;&#24230;&#19982;&#26368;&#22823;&#32479;&#35745;&#26464;&#26438;&#24471;&#20998;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12885v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449;&#25688;&#35201;: &#36890;&#29992;&#26680;&#23725;&#22238;&#24402;&#22312;&#20869;&#23384;&#20998;&#37197;&#21644;&#35745;&#31639;&#26102;&#38388;&#19978;&#25104;&#26412;&#39640;&#26114;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#26367;&#20195;&#26041;&#27861;&#65292;&#20197;&#24212;&#23545;&#36825;&#20123;&#22256;&#38590;&#12290;&#26412;&#25991;&#30340;&#22522;&#26412;&#36129;&#29486;&#22312;&#20110;&#23545;&#20302;&#32500;&#36817;&#20284;&#30340;&#31209;&#25552;&#20986;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#35201;&#27714;&#20854;&#20445;&#25345;&#21487;&#38752;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#35813;&#30028;&#38480;&#23558;&#26377;&#25928;&#32500;&#24230;&#19982;&#26368;&#22823;&#32479;&#35745;&#26464;&#26438;&#24471;&#20998;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#36890;&#36807;&#28041;&#21450;&#26680;&#30340;&#27491;&#21017;&#24615;&#26469;&#34920;&#24449;&#26377;&#25928;&#32500;&#24230;&#21450;&#20854;&#38543;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#22686;&#38271;&#34892;&#20026;&#12290;&#23545;&#20110;&#36866;&#24403;&#36873;&#25321;&#30340;&#26680;&#65292;&#36825;&#31181;&#22686;&#38271;&#34987;&#35777;&#26126;&#26159;&#23545;&#25968;&#28176;&#36817;&#30340;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;&#20302;&#31209;&#36817;&#20284;&#20316;&#20026;Nystro&#776;m&#26041;&#27861;&#30340;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12885v1 Announce Type: cross  Abstract: Common kernel ridge regression is expensive in memory allocation and computation time. This paper addresses low rank approximations and surrogates for kernel ridge regression, which bridge these difficulties. The fundamental contribution of the paper is a lower bound on the rank of the low dimensional approximation, which is required such that the prediction power remains reliable. The bound relates the effective dimension with the largest statistical leverage score. We characterize the effective dimension and its growth behavior with respect to the regularization parameter by involving the regularity of the kernel. This growth is demonstrated to be asymptotically logarithmic for suitably chosen kernels, justifying low-rank approximations as the Nystr\"om method.
&lt;/p&gt;</description></item><item><title>&#24320;&#21457;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#31574;&#30053;&#20248;&#21270;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#27979;&#35797;&#26368;&#20248;Q&#20989;&#25968;&#30340;&#38750;&#24179;&#31283;&#24615;&#24182;&#24320;&#21457;&#24207;&#36143;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#26469;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2203.01707</link><description>&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#27979;&#35797;&#24179;&#31283;&#24615;&#21644;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Testing Stationarity and Change Point Detection in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.01707
&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#31574;&#30053;&#20248;&#21270;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#27979;&#35797;&#26368;&#20248;Q&#20989;&#25968;&#30340;&#38750;&#24179;&#31283;&#24615;&#24182;&#24320;&#21457;&#24207;&#36143;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#21487;&#33021;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26041;&#27861;&#12290;&#35768;&#22810;&#25991;&#29486;&#20013;&#29616;&#26377;&#30340;RL&#31639;&#27861;&#20381;&#36182;&#20110;&#38656;&#35201;&#31995;&#32479;&#36716;&#25442;&#21644;&#22870;&#21169;&#20989;&#25968;&#38543;&#26102;&#38388;&#20445;&#25345;&#24658;&#23450;&#30340;&#24179;&#31283;&#24615;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#23454;&#36341;&#20013;&#24179;&#31283;&#24615;&#20551;&#35774;&#26159;&#26377;&#38480;&#21046;&#30340;&#65292;&#24182;&#19988;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24456;&#21487;&#33021;&#34987;&#36829;&#21453;&#65292;&#21253;&#25324;&#20132;&#36890;&#20449;&#21495;&#25511;&#21046;&#12289;&#26426;&#22120;&#20154;&#25216;&#26415;&#21644;&#31227;&#21160;&#20581;&#24247;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#19968;&#33268;&#30340;&#31243;&#24207;&#65292;&#22522;&#20110;&#39044;&#20808;&#25910;&#38598;&#30340;&#21382;&#21490;&#25968;&#25454;&#27979;&#35797;&#26368;&#20248;Q&#20989;&#25968;&#30340;&#38750;&#24179;&#31283;&#24615;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#22312;&#32447;&#25968;&#25454;&#25910;&#38598;&#12290;&#22522;&#20110;&#25152;&#25552;&#20986;&#30340;&#26816;&#39564;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#31181;&#39034;&#24207;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#28982;&#22320;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;RL&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#29702;&#35770;&#32467;&#26524;&#12289;&#20223;&#30495;&#30740;&#31350;&#21644;&#23454;&#36341;&#20013;&#30340;&#26696;&#20363;&#24471;&#21040;&#20102;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2203.01707v3 Announce Type: replace-cross  Abstract: We consider offline reinforcement learning (RL) methods in possibly nonstationary environments. Many existing RL algorithms in the literature rely on the stationarity assumption that requires the system transition and the reward function to be constant over time. However, the stationarity assumption is restrictive in practice and is likely to be violated in a number of applications, including traffic signal control, robotics and mobile health. In this paper, we develop a consistent procedure to test the nonstationarity of the optimal Q-function based on pre-collected historical data, without additional online data collection. Based on the proposed test, we further develop a sequential change point detection method that can be naturally coupled with existing state-of-the-art RL methods for policy optimization in nonstationary environments. The usefulness of our method is illustrated by theoretical results, simulation studies, an
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#20381;&#36182;&#36328;&#22495;&#22240;&#26524;&#26426;&#21046;&#30340;&#26368;&#23567;&#25913;&#21464;&#23646;&#24615;&#65292;&#22312;&#20445;&#25345;&#29305;&#23450;&#32452;&#20998;&#36328;&#22495;&#19981;&#21464;&#30340;&#21069;&#25552;&#19979;&#26368;&#23567;&#21270;&#20998;&#24067;&#36716;&#31227;&#30340;&#19981;&#24517;&#35201;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.06510</link><description>&lt;p&gt;
&#38024;&#23545;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Partial Identifiability for Domain Adaptation. (arXiv:2306.06510v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#20381;&#36182;&#36328;&#22495;&#22240;&#26524;&#26426;&#21046;&#30340;&#26368;&#23567;&#25913;&#21464;&#23646;&#24615;&#65292;&#22312;&#20445;&#25345;&#29305;&#23450;&#32452;&#20998;&#36328;&#22495;&#19981;&#21464;&#30340;&#21069;&#25552;&#19979;&#26368;&#23567;&#21270;&#20998;&#24067;&#36716;&#31227;&#30340;&#19981;&#24517;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#23545;&#20110;&#35768;&#22810;&#27809;&#26377;&#30446;&#26631;&#22495;&#26631;&#31614;&#20449;&#24687;&#30340;&#23454;&#38469;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#22914;&#26524;&#27809;&#26377;&#36827;&#19968;&#27493;&#30340;&#20551;&#35774;&#65292;&#29305;&#24449;&#21644;&#26631;&#31614;&#30340;&#32852;&#21512;&#20998;&#24067;&#22312;&#30446;&#26631;&#22495;&#20013;&#26159;&#19981;&#21487;&#35782;&#21035;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20381;&#36182;&#36328;&#22495;&#22240;&#26524;&#26426;&#21046;&#30340;&#26368;&#23567;&#25913;&#21464;&#23646;&#24615;&#65292;&#20197;&#26368;&#23567;&#21270;&#20998;&#24067;&#36716;&#31227;&#30340;&#19981;&#24517;&#35201;&#24433;&#21709;&#12290;&#20026;&#20102;&#32534;&#30721;&#36825;&#20010;&#23646;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#19968;&#20010;&#24102;&#26377;&#20004;&#20010;&#20998;&#21306;&#28508;&#21464;&#37327;&#23376;&#31354;&#38388;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26469;&#21046;&#23450;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65306;&#19981;&#21464;&#37096;&#20998;&#30340;&#20998;&#24067;&#22312;&#36328;&#22495;&#26102;&#20445;&#25345;&#19981;&#21464;&#65292;&#32780;&#31232;&#30095;&#30340;&#21487;&#21464;&#37096;&#20998;&#20250;&#22312;&#19981;&#21516;&#30340;&#22495;&#20013;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#38480;&#21046;&#20102;&#22495;&#31227;&#20301;&#23545;&#21487;&#21464;&#37096;&#20998;&#30340;&#24433;&#21709;&#12290;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#37096;&#20998;&#21487;&#35782;&#21035;&#30340;&#28508;&#21464;&#37327;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;&#30446;&#26631;&#22495;&#20013;&#25968;&#25454;&#21644;&#26631;&#31614;&#30340;&#32852;&#21512;&#20998;&#24067;&#20063;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain adaptation is critical to many real-world applications where label information is unavailable in the target domain. In general, without further assumptions, the joint distribution of the features and the label is not identifiable in the target domain. To address this issue, we rely on the property of minimal changes of causal mechanisms across domains to minimize unnecessary influences of distribution shifts. To encode this property, we first formulate the data-generating process using a latent variable model with two partitioned latent subspaces: invariant components whose distributions stay the same across domains and sparse changing components that vary across domains. We further constrain the domain shift to have a restrictive influence on the changing components. Under mild conditions, we show that the latent variables are partially identifiable, from which it follows that the joint distribution of data and labels in the target domain is also identifiable. Give
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#26641;&#29366;&#24352;&#37327;&#32593;&#32476;&#30340;CP&#31209;&#32422;&#26463;&#21644;&#24352;&#37327;&#20002;&#24323;&#65292;&#26469;&#26500;&#24314;&#20302;&#31209;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#26102;&#23578;-MNIST&#22270;&#20687;&#20998;&#31867;&#20013;&#23637;&#31034;&#20986;&#20102;&#20248;&#24322;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.19440</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#24352;&#37327;&#32593;&#32476;&#12289;CP&#31209;&#32422;&#26463;&#21644;&#24352;&#37327;&#20002;&#24323;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning with tree tensor networks, CP rank constraints, and tensor dropout. (arXiv:2305.19440v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19440
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#26641;&#29366;&#24352;&#37327;&#32593;&#32476;&#30340;CP&#31209;&#32422;&#26463;&#21644;&#24352;&#37327;&#20002;&#24323;&#65292;&#26469;&#26500;&#24314;&#20302;&#31209;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#26102;&#23578;-MNIST&#22270;&#20687;&#20998;&#31867;&#20013;&#23637;&#31034;&#20986;&#20102;&#20248;&#24322;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#38477;&#20302;&#33258;&#30001;&#24230;&#26469;&#36817;&#20284;&#34920;&#31034;$N$&#38454;&#24352;&#37327;&#65292;&#24182;&#26500;&#25104;&#19968;&#31995;&#21015;&#21387;&#32553;&#30340;&#23567;&#24352;&#37327;&#32593;&#32476;&#12290;&#22312;[arXiv:2205.15296]&#25991;&#31456;&#20013;&#65292;&#20316;&#32773;&#25552;&#20986;&#21487;&#20197;&#36890;&#36807;&#23545;&#24352;&#37327;&#32593;&#32476;&#20013;&#30340;&#24352;&#37327;&#30340;CP&#31209;&#38468;&#21152;&#32422;&#26463;&#65292;&#36827;&#19968;&#27493;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#26412;&#25991;&#26088;&#22312;&#23637;&#31034;&#22914;&#20309;&#21033;&#29992;&#22522;&#20110;&#26641;&#29366;&#24352;&#37327;&#32593;&#32476;(TTN)&#30340;CP&#31209;&#32422;&#26463;&#21644;&#24352;&#37327;&#20002;&#24323;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#26426;&#22120;&#23398;&#20064;&#65292;&#24182;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#26102;&#23578;-MNIST&#22270;&#20687;&#20998;&#31867;&#20013;&#20248;&#20110;&#20854;&#20182;&#22522;&#20110;&#24352;&#37327;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#24403;&#20998;&#25903;&#31995;&#25968;$b=4$&#26102;&#65292;&#20302;&#31209;TTN&#20998;&#31867;&#22120;&#36798;&#21040;&#20102;&#27979;&#35797;&#38598;&#20934;&#30830;&#29575;90.3\%&#65292;&#21516;&#26102;&#25317;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22522;&#20110;&#32447;&#24615;&#20803;&#32032;&#26500;&#25104;&#30340;&#24352;&#37327;&#32593;&#32476;&#20998;&#31867;&#22120;&#36991;&#20813;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#12290;CP&#31209;&#32422;&#26463;&#36824;&#26377;&#20854;&#20182;&#20248;&#28857;&#65306;&#21487;&#20197;&#20943;&#23569;&#21644;&#35843;&#25972;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor networks approximate order-$N$ tensors with a reduced number of degrees of freedom that is only polynomial in $N$ and arranged as a network of partially contracted smaller tensors. As suggested in [arXiv:2205.15296] in the context of quantum many-body physics, computation costs can be further substantially reduced by imposing constraints on the canonical polyadic (CP) rank of the tensors in such networks. Here we demonstrate how tree tensor networks (TTN) with CP rank constraints and tensor dropout can be used in machine learning. The approach is found to outperform other tensor-network based methods in Fashion-MNIST image classification. A low-rank TTN classifier with branching ratio $b=4$ reaches test set accuracy 90.3\% with low computation costs. Consisting of mostly linear elements, tensor network classifiers avoid the vanishing gradient problem of deep neural networks. The CP rank constraints have additional advantages: The number of parameters can be decreased and tuned m
&lt;/p&gt;</description></item></channel></rss>