<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>CATS&#36890;&#36807;&#26500;&#24314;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#22806;&#29983;&#21464;&#37327;&#65292;&#26377;&#25928;&#22320;&#34920;&#31034;&#21644;&#25972;&#21512;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25552;&#39640;&#20102;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#30456;&#36739;&#20110;&#20043;&#21069;&#30340;&#27169;&#22411;&#22823;&#24133;&#20943;&#23569;&#20102;&#22797;&#26434;&#24615;&#21644;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.01673</link><description>&lt;p&gt;
CATS&#65306;&#36890;&#36807;&#26500;&#24314;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#22806;&#29983;&#21464;&#37327;&#22686;&#24378;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01673
&lt;/p&gt;
&lt;p&gt;
CATS&#36890;&#36807;&#26500;&#24314;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#22806;&#29983;&#21464;&#37327;&#65292;&#26377;&#25928;&#22320;&#34920;&#31034;&#21644;&#25972;&#21512;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25552;&#39640;&#20102;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#30456;&#36739;&#20110;&#20043;&#21069;&#30340;&#27169;&#22411;&#22823;&#24133;&#20943;&#23569;&#20102;&#22797;&#26434;&#24615;&#21644;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;MTSF&#65289;&#65292;&#26368;&#36817;&#30340;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#26174;&#31034;&#65292;&#21333;&#21464;&#37327;&#27169;&#22411;&#32463;&#24120;&#20248;&#20110;&#22810;&#20803;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#22810;&#20803;&#27169;&#22411;&#30340;&#19981;&#36275;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21363;&#26500;&#24314;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#65288;CATS&#65289;&#65292;&#23427;&#31867;&#20284;&#20110;2D&#26102;&#38388;&#19978;&#19979;&#25991;&#20851;&#27880;&#26426;&#21046;&#65292;&#20174;&#21407;&#22987;&#26102;&#38388;&#24207;&#21015;&#65288;OTS&#65289;&#29983;&#25104;&#36741;&#21161;&#26102;&#38388;&#24207;&#21015;&#65288;ATS&#65289;&#65292;&#20197;&#26377;&#25928;&#34920;&#31034;&#21644;&#25972;&#21512;&#31995;&#21015;&#38388;&#20851;&#31995;&#29992;&#20110;&#39044;&#27979;&#12290;ATS&#30340;&#20851;&#38190;&#21407;&#21017;-&#36830;&#32493;&#24615;&#65292;&#31232;&#30095;&#24615;&#21644;&#21464;&#24322;&#24615;-&#36890;&#36807;&#19981;&#21516;&#27169;&#22359;&#36827;&#34892;&#35782;&#21035;&#21644;&#23454;&#29616;&#12290;&#21363;&#20351;&#26159;&#22522;&#26412;&#30340;2&#23618;MLP&#20316;&#20026;&#26680;&#24515;&#39044;&#27979;&#22120;&#65292;CATS&#20063;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#25104;&#26524;&#65292;&#30456;&#23545;&#20110;&#20808;&#21069;&#30340;&#22810;&#20803;&#27169;&#22411;&#65292;&#23427;&#26174;&#33879;&#20943;&#23569;&#20102;&#22797;&#26434;&#24615;&#21644;&#21442;&#25968;&#65292;&#20351;&#20854;&#25104;&#20026;&#39640;&#25928;&#19988;&#21487;&#36716;&#31227;&#30340;MTSF&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01673v1 Announce Type: cross  Abstract: For Multivariate Time Series Forecasting (MTSF), recent deep learning applications show that univariate models frequently outperform multivariate ones. To address the difficiency in multivariate models, we introduce a method to Construct Auxiliary Time Series (CATS) that functions like a 2D temporal-contextual attention mechanism, which generates Auxiliary Time Series (ATS) from Original Time Series (OTS) to effectively represent and incorporate inter-series relationships for forecasting. Key principles of ATS - continuity, sparsity, and variability - are identified and implemented through different modules. Even with a basic 2-layer MLP as core predictor, CATS achieves state-of-the-art, significantly reducing complexity and parameters compared to previous multivariate models, marking it an efficient and transferable MTSF solution.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;ARM&#65292;&#19968;&#31181;&#22810;&#21464;&#37327;&#30340;&#26102;&#38388;-&#19978;&#19979;&#25991;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;ARM&#36890;&#36807;&#37319;&#29992;&#33258;&#36866;&#24212;&#21333;&#21464;&#37327;&#25928;&#24212;&#23398;&#20064;&#12289;&#38543;&#26426;&#20002;&#24323;&#35757;&#32451;&#31574;&#30053;&#21644;&#22810;&#26680;&#23616;&#37096;&#24179;&#28369;&#65292;&#33021;&#26356;&#22909;&#22320;&#22788;&#29702;&#26102;&#38388;&#27169;&#24335;&#21644;&#23398;&#20064;&#31995;&#21015;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;ARM&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#32780;&#35745;&#31639;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2310.09488</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#26102;&#38388;-&#19978;&#19979;&#25991;&#23398;&#20064;&#20248;&#21270;&#22810;&#21464;&#37327;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning. (arXiv:2310.09488v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;ARM&#65292;&#19968;&#31181;&#22810;&#21464;&#37327;&#30340;&#26102;&#38388;-&#19978;&#19979;&#25991;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;ARM&#36890;&#36807;&#37319;&#29992;&#33258;&#36866;&#24212;&#21333;&#21464;&#37327;&#25928;&#24212;&#23398;&#20064;&#12289;&#38543;&#26426;&#20002;&#24323;&#35757;&#32451;&#31574;&#30053;&#21644;&#22810;&#26680;&#23616;&#37096;&#24179;&#28369;&#65292;&#33021;&#26356;&#22909;&#22320;&#22788;&#29702;&#26102;&#38388;&#27169;&#24335;&#21644;&#23398;&#20064;&#31995;&#21015;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;ARM&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#32780;&#35745;&#31639;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;LTSF&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#37117;&#24456;&#37325;&#35201;&#65292;&#20294;&#22312;&#22788;&#29702;&#22797;&#26434;&#30340;&#26102;&#38388;-&#19978;&#19979;&#25991;&#20851;&#31995;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#30001;&#20110;&#22810;&#21464;&#37327;&#36755;&#20837;&#27169;&#22411;&#34920;&#29616;&#19981;&#22914;&#26368;&#36817;&#30340;&#19968;&#20123;&#21333;&#21464;&#37327;&#27169;&#22411;&#65292;&#25105;&#20204;&#35748;&#20026;&#38382;&#39064;&#22312;&#20110;&#29616;&#26377;&#30340;&#22810;&#21464;&#37327;LTSF&#21464;&#21387;&#22120;&#27169;&#22411;&#26080;&#27861;&#39640;&#25928;&#22320;&#24314;&#27169;&#31995;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#65306;&#24448;&#24448;&#19981;&#33021;&#27491;&#30830;&#22320;&#25429;&#25417;&#21040;&#31995;&#21015;&#20043;&#38388;&#30340;&#29305;&#24449;&#24046;&#24322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ARM&#65306;&#19968;&#31181;&#22810;&#21464;&#37327;&#30340;&#26102;&#38388;-&#19978;&#19979;&#25991;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#26159;&#19987;&#38376;&#20026;&#22810;&#21464;&#37327;LTSF&#24314;&#27169;&#32780;&#35774;&#35745;&#30340;&#22686;&#24378;&#22411;&#26550;&#26500;&#12290;ARM&#37319;&#29992;&#33258;&#36866;&#24212;&#21333;&#21464;&#37327;&#25928;&#24212;&#23398;&#20064;&#65288;AUEL&#65289;&#12289;&#38543;&#26426;&#20002;&#24323;&#65288;RD&#65289;&#35757;&#32451;&#31574;&#30053;&#21644;&#22810;&#26680;&#23616;&#37096;&#24179;&#28369;&#65288;MKLS&#65289;&#26469;&#26356;&#22909;&#22320;&#22788;&#29702;&#21333;&#20010;&#31995;&#21015;&#30340;&#26102;&#38388;&#27169;&#24335;&#24182;&#27491;&#30830;&#23398;&#20064;&#31995;&#21015;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;ARM&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#32780;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#24182;&#27809;&#26377;&#26174;&#33879;&#22686;&#21152;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Long-term time series forecasting (LTSF) is important for various domains but is confronted by challenges in handling the complex temporal-contextual relationships. As multivariate input models underperforming some recent univariate counterparts, we posit that the issue lies in the inefficiency of existing multivariate LTSF Transformers to model series-wise relationships: the characteristic differences between series are often captured incorrectly. To address this, we introduce ARM: a multivariate temporal-contextual adaptive learning method, which is an enhanced architecture specifically designed for multivariate LTSF modelling. ARM employs Adaptive Univariate Effect Learning (AUEL), Random Dropping (RD) training strategy, and Multi-kernel Local Smoothing (MKLS), to better handle individual series temporal patterns and correctly learn inter-series dependencies. ARM demonstrates superior performance on multiple benchmarks without significantly increasing computational costs compared to
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#21033;&#29992;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#26500;&#24314;&#20102;TLRC&#65292;&#24182;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.16858</link><description>&lt;p&gt;
Transductive Learning&#30340;&#23574;&#38160;&#27867;&#21270;&#65306;&#19968;&#31181;Transductive Local Rademacher Complexity&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sharp Generalization of Transductive Learning: A Transductive Local Rademacher Complexity Approach. (arXiv:2309.16858v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16858
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#21033;&#29992;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#26500;&#24314;&#20102;TLRC&#65292;&#24182;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24037;&#20855;&#65292;Transductive Local Rademacher Complexity (TLRC)&#65292;&#29992;&#20110;&#20998;&#26512;transductive learning&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24182;&#25512;&#21160;&#26032;&#30340;transductive learning&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#20256;&#32479;&#30340;local rademacher complexity (LRC)&#30340;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;transductive&#35774;&#32622;&#20013;&#65292;&#30456;&#23545;&#20110;&#20856;&#22411;&#30340;LRC&#26041;&#27861;&#22312;&#24402;&#32435;&#35774;&#32622;&#20013;&#30340;&#20998;&#26512;&#26377;&#20102;&#30456;&#24403;&#22823;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Rademacher complex&#30340;&#23616;&#37096;&#21270;&#24037;&#20855;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;transductive learning&#38382;&#39064;&#65292;&#24182;&#22312;&#36866;&#24403;&#26465;&#20214;&#19979;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#30028;&#38480;&#12290;&#19982;LRC&#30340;&#21457;&#23637;&#31867;&#20284;&#65292;&#25105;&#20204;&#36890;&#36807;&#20174;&#29420;&#31435;&#21464;&#37327;&#30340;&#26041;&#24046;&#20449;&#24687;&#24320;&#22987;&#26500;&#24314;TLRC&#65292;&#23558;transductive learning&#27169;&#22411;&#30340;&#39044;&#27979;&#20989;&#25968;&#31867;&#20998;&#20026;&#22810;&#20010;&#37096;&#20998;&#65292;&#27599;&#20010;&#37096;&#20998;&#30340;Rademacher complexity&#19978;&#30028;&#30001;&#19968;&#20010;&#23376;&#26681;&#20989;&#25968;&#32473;&#20986;&#65292;&#24182;&#38480;&#21046;&#20102;&#27599;&#20010;&#37096;&#20998;&#20013;&#25152;&#26377;&#20989;&#25968;&#30340;&#26041;&#24046;&#12290;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We introduce a new tool, Transductive Local Rademacher Complexity (TLRC), to analyze the generalization performance of transductive learning methods and motivate new transductive learning algorithms. Our work extends the idea of the popular Local Rademacher Complexity (LRC) to the transductive setting with considerable changes compared to the analysis of typical LRC methods in the inductive setting. We present a localized version of Rademacher complexity based tool wihch can be applied to various transductive learning problems and gain sharp bounds under proper conditions. Similar to the development of LRC, we build TLRC by starting from a sharp concentration inequality for independent variables with variance information. The prediction function class of a transductive learning model is then divided into pieces with a sub-root function being the upper bound for the Rademacher complexity of each piece, and the variance of all the functions in each piece is limited. A carefully designed 
&lt;/p&gt;</description></item></channel></rss>