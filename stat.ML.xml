<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#24182;&#25913;&#21892;&#27169;&#22411;&#30340;&#22806;&#22495;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.15734</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#23454;&#29616;&#39640;&#25928;&#30340;&#36816;&#31639;&#31526;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15734
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#24182;&#25913;&#21892;&#27169;&#22411;&#30340;&#22806;&#22495;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#35265;&#35777;&#20102;&#23558;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#19982;&#29289;&#29702;&#39046;&#22495;&#29305;&#23450;&#27934;&#23519;&#21147;&#30456;&#32467;&#21512;&#65292;&#20197;&#35299;&#20915;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#31185;&#23398;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#23494;&#38598;&#65292;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#38656;&#35201;&#22823;&#37327;PDE&#25968;&#25454;&#12290; &#36825;&#37325;&#26032;&#24341;&#20837;&#20102;&#23545;&#26114;&#36149;&#30340;&#25968;&#20540;PDE&#35299;&#20915;&#26041;&#26696;&#30340;&#38656;&#27714;&#65292;&#37096;&#20998;&#21066;&#24369;&#20102;&#36991;&#20813;&#36825;&#20123;&#26114;&#36149;&#27169;&#25311;&#30340;&#21407;&#22987;&#30446;&#26631;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#20026;&#20102;&#23547;&#27714;&#25968;&#25454;&#25928;&#29575;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#29992;&#20110;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#12290; &#20026;&#20102;&#20943;&#23569;&#23545;&#24102;&#26377;&#27169;&#25311;&#35299;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#37325;&#26500;&#30340;&#20195;&#29702;&#20219;&#21153;&#22312;&#26410;&#26631;&#35760;&#30340;PDE&#25968;&#25454;&#19978;&#39044;&#35757;&#32451;&#31070;&#32463;&#36816;&#31639;&#31526;&#12290; &#20026;&#20102;&#25552;&#39640;&#36229;&#20986;&#20998;&#24067;&#24615;&#33021;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24110;&#21161;&#31070;&#32463;&#36816;&#31639;&#31526;&#28789;&#27963;&#22320;&#21033;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#25104;&#26412;&#25110;&#35774;&#35745;&#12290; &#22312;&#21508;&#31181;PD&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15734v1 Announce Type: new  Abstract: Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insight for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining and in-context learning methods for PDE operator learning. To reduce the need for training data with simulated solutions, we pretrain neural operators on unlabeled PDE data using reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging in-context learning methods, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PD
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#29978;&#33267;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65307;&#21516;&#26102;&#65292;&#22312;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.10252</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#30028;&#21644;&#36864;&#21270;&#22122;&#22768;&#30340;&#32447;&#24615;&#31995;&#32479;&#22312;&#32447;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Online Control of Linear Systems with Unbounded and Degenerate Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10252
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#29978;&#33267;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65307;&#21516;&#26102;&#65292;&#22312;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21487;&#33021;&#23384;&#22312;&#26080;&#30028;&#21644;&#36864;&#21270;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#32447;&#24615;&#31995;&#32479;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#25104;&#26412;&#20989;&#25968;&#26410;&#30693;&#65292;&#34987;&#31216;&#20026;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#12290;&#19982;&#29616;&#26377;&#30340;&#20165;&#20551;&#35774;&#22122;&#22768;&#26377;&#30028;&#24615;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013; $ T $ &#34920;&#31034;&#26102;&#38388;&#36328;&#24230;&#12290;&#27492;&#22806;&#65292;&#24403;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#32780;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#20551;&#35774;&#65292;&#36825;&#22312;&#25991;&#29486;&#20013;&#26159;&#24517;&#38656;&#30340;&#12290;&#28040;&#38500;&#22122;&#22768;&#31209;&#30340;&#20851;&#38190;&#26159;&#19982;&#22122;&#22768;&#21327;&#26041;&#24046;&#30456;&#20851;&#32852;&#30340;&#31995;&#32479;&#36716;&#21270;&#12290;&#36825;&#21516;&#26102;&#23454;&#29616;&#20102;&#22312;&#32447;&#25511;&#21046;&#31639;&#27861;&#30340;&#21442;&#25968;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10252v1 Announce Type: cross  Abstract: This paper investigates the problem of controlling a linear system under possibly unbounded and degenerate noise with unknown cost functions, known as an online control problem. In contrast to the existing work, which assumes the boundedness of noise, we reveal that for convex costs, an $ \widetilde{O}(\sqrt{T}) $ regret bound can be achieved even for unbounded noise, where $ T $ denotes the time horizon. Moreover, when the costs are strongly convex, we establish an $ O({\rm poly} (\log T)) $ regret bound without the assumption that noise covariance is non-degenerate, which has been required in the literature. The key ingredient in removing the rank assumption on noise is a system transformation associated with the noise covariance. This simultaneously enables the parameter reduction of an online control algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#65292;&#30028;&#38480;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;</title><link>https://arxiv.org/abs/2402.07723</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#37325;&#23614;SDEs&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds for Heavy-Tailed SDEs through the Fractional Fokker-Planck Equation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07723
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#65292;&#30028;&#38480;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#26469;&#65292;&#29702;&#35299;&#37325;&#23614;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#21033;&#29992;&#37325;&#23614;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20316;&#20026;&#20195;&#29702;&#26469;&#38416;&#26126;&#38543;&#26426;&#20248;&#21270;&#22120;&#30340;&#26377;&#36259;&#26041;&#38754;&#26102;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#25552;&#20379;&#39044;&#26399;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#35201;&#20040;&#24341;&#20837;&#20102;&#19981;&#21487;&#35745;&#31639;&#30340;&#20449;&#24687;&#35770;&#26415;&#35821;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#32570;&#28857;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19981;&#21547;&#20219;&#20309;&#38750;&#24179;&#20961;&#30340;&#20449;&#24687;&#35770;&#26415;&#35821;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22522;&#20110;&#20272;&#35745;&#19982;&#25152;&#35859;&#30340;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#30456;&#20851;&#32852;&#30340;&#29109;&#27969;&#65292;&#24320;&#21457;&#20102;&#26032;&#30340;&#35777;&#26126;&#25216;&#26415;&#65288;&#36825;&#26159;&#19968;&#31181;&#25511;&#21046;&#30456;&#24212;&#37325;&#23614;SDE&#20998;&#24067;&#28436;&#21270;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65289;&#12290;&#38500;&#20102;&#33719;&#24471;&#39640;&#27010;&#29575;&#30028;&#38480;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the generalization properties of heavy-tailed stochastic optimization algorithms has attracted increasing attention over the past years. While illuminating interesting aspects of stochastic optimizers by using heavy-tailed stochastic differential equations as proxies, prior works either provided expected generalization bounds, or introduced non-computable information theoretic terms. Addressing these drawbacks, in this work, we prove high-probability generalization bounds for heavy-tailed SDEs which do not contain any nontrivial information theoretic terms. To achieve this goal, we develop new proof techniques based on estimating the entropy flows associated with the so-called fractional Fokker-Planck equation (a partial differential equation that governs the evolution of the distribution of the corresponding heavy-tailed SDE). In addition to obtaining high-probability bounds, we show that our bounds have a better dependence on the dimension of parameters as compared to p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.05806</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#26657;&#20934;&#21644;&#31526;&#21512;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Calibration and Conformal Prediction of Deep Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20998;&#31867;&#24212;&#29992;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22522;&#20110;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#38656;&#35201;&#20276;&#38543;&#19968;&#20123;&#32622;&#20449;&#24230;&#25351;&#31034;&#12290;&#38024;&#23545;&#36825;&#20010;&#30446;&#26631;&#65292;&#26377;&#20004;&#31181;&#27969;&#34892;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#65306;1&#65289;&#26657;&#20934;&#65306;&#20462;&#25913;&#20998;&#31867;&#22120;&#30340;softmax&#20540;&#65292;&#20351;&#20854;&#26368;&#22823;&#20540;&#65288;&#19982;&#39044;&#27979;&#30456;&#20851;&#65289;&#26356;&#22909;&#22320;&#20272;&#35745;&#27491;&#30830;&#27010;&#29575;&#65307;&#21644;2&#65289;&#31526;&#21512;&#39044;&#27979;&#65288;CP&#65289;&#65306;&#35774;&#35745;&#19968;&#20010;&#22522;&#20110;softmax&#20540;&#30340;&#20998;&#25968;&#65292;&#20174;&#20013;&#20135;&#29983;&#19968;&#32452;&#39044;&#27979;&#65292;&#20855;&#26377;&#29702;&#35770;&#19978;&#20445;&#35777;&#27491;&#30830;&#31867;&#21035;&#36793;&#38469;&#35206;&#30422;&#30340;&#29305;&#24615;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#20004;&#31181;&#25351;&#31034;&#37117;&#21487;&#33021;&#26159;&#38656;&#35201;&#30340;&#65292;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#23578;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#65292;&#36825;&#26159;&#26368;&#24120;&#35265;&#30340;&#26657;&#20934;&#25216;&#26415;&#65292;&#23545;&#37325;&#35201;&#30340;CP&#26041;&#27861;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#20102;&#19968;&#39033;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#20854;&#20013;&#26174;&#31034;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#27934;&#23519;&#65292;&#20854;&#20013;&#21253;&#25324;&#20196;&#20154;&#24778;&#35766;&#30340;&#21457;&#29616;&#65292;&#21363;&#26657;&#20934;&#23545;&#27969;&#34892;&#30340;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many classification applications, the prediction of a deep neural network (DNN) based classifier needs to be accompanied with some confidence indication. Two popular post-processing approaches for that aim are: 1) calibration: modifying the classifier's softmax values such that their maximum (associated with the prediction) better estimates the correctness probability; and 2) conformal prediction (CP): devising a score (based on the softmax values) from which a set of predictions with theoretically guaranteed marginal coverage of the correct class is produced. While in practice both types of indications can be desired, so far the interplay between them has not been investigated. Toward filling this gap, in this paper we study the effect of temperature scaling, arguably the most common calibration technique, on prominent CP methods. We start with an extensive empirical study that among other insights shows that, surprisingly, calibration has a detrimental effect on popular adaptive C
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#27861;&#26469;&#25512;&#26029;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#36890;&#36807;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#65292;&#30456;&#20851;&#31639;&#27861;&#32463;&#36807;&#39564;&#35777;&#20855;&#26377;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.01835</link><description>&lt;p&gt;
&#20998;&#24067;&#26080;&#20851;&#25512;&#26029;&#20108;&#20803;&#20998;&#31867;&#30340;&#22238;&#24402;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Inference for the Regression Function of Binary Classification. (arXiv:2308.01835v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#27861;&#26469;&#25512;&#26029;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#36890;&#36807;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#65292;&#30456;&#20851;&#31639;&#27861;&#32463;&#36807;&#39564;&#35777;&#20855;&#26377;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#20803;&#20998;&#31867;&#30340;&#19968;&#20010;&#20851;&#38190;&#23545;&#35937;&#26159;&#22238;&#24402;&#20989;&#25968;&#65292;&#21363;&#32473;&#23450;&#36755;&#20837;&#30340;&#31867;&#21035;&#26631;&#31614;&#30340;&#26465;&#20214;&#26399;&#26395;&#12290;&#36890;&#36807;&#22238;&#24402;&#20989;&#25968;&#65292;&#19981;&#20165;&#21487;&#20197;&#23450;&#20041;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#65292;&#36824;&#21487;&#20197;&#32534;&#30721;&#23545;&#24212;&#30340;&#38169;&#35823;&#20998;&#31867;&#27010;&#29575;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#37319;&#26679;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#31934;&#30830;&#12289;&#20998;&#24067;&#26080;&#20851;&#19988;&#38750;&#28176;&#36817;&#20445;&#35777;&#30340;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#26681;&#25454;&#29992;&#25143;&#36873;&#25321;&#30340;&#32622;&#20449;&#27700;&#24179;&#12290;&#28982;&#21518;&#65292;&#25552;&#20986;&#20102;&#29305;&#23450;&#30340;&#31639;&#27861;&#26469;&#28436;&#31034;&#35813;&#26694;&#26550;&#12290;&#35777;&#26126;&#20102;&#26500;&#24314;&#30340;&#32622;&#20449;&#21306;&#38388;&#26159;&#24378;&#19968;&#33268;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#20219;&#20309;&#38169;&#35823;&#30340;&#27169;&#22411;&#26368;&#32456;&#34987;&#25490;&#38500;&#30340;&#27010;&#29575;&#20026;1&#12290;&#25490;&#38500;&#30340;&#31243;&#24230;&#20063;&#36890;&#36807;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#31867;&#22411;&#30340;&#30028;&#38480;&#36827;&#34892;&#20102;&#37327;&#21270;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#31639;&#27861;&#65292;&#24182;&#23558;&#26041;&#27861;&#19982;&#36817;&#20284;&#28176;&#36817;&#32622;&#20449;&#26925;&#22278;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the key objects of binary classification is the regression function, i.e., the conditional expectation of the class labels given the inputs. With the regression function not only a Bayes optimal classifier can be defined, but it also encodes the corresponding misclassification probabilities. The paper presents a resampling framework to construct exact, distribution-free and non-asymptotically guaranteed confidence regions for the true regression function for any user-chosen confidence level. Then, specific algorithms are suggested to demonstrate the framework. It is proved that the constructed confidence regions are strongly consistent, that is, any false model is excluded in the long run with probability one. The exclusion is quantified with probably approximately correct type bounds, as well. Finally, the algorithms are validated via numerical experiments, and the methods are compared to approximate asymptotic confidence ellipsoids.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#24212;&#29992;&#20110;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#23454;&#29616;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#20381;&#36182;&#20110;RKHS&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.17329</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#22312;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Kernel $\epsilon$-Greedy for Contextual Bandits. (arXiv:2306.17329v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17329
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#24212;&#29992;&#20110;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#23454;&#29616;&#23545;&#22870;&#21169;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#19968;&#33268;&#24615;&#21644;&#20381;&#36182;&#20110;RKHS&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#24773;&#22659;&#33033;&#20914;&#20013;&#30340;&#22522;&#20110;&#26680;&#30340;$\epsilon$-&#36138;&#24515;&#31574;&#30053;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#33218;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35748;&#20026;&#24179;&#22343;&#22870;&#21169;&#20989;&#25968;&#20301;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22870;&#21169;&#20989;&#25968;&#30340;&#22312;&#32447;&#21152;&#26435;&#26680;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#12290;&#22312;&#23545;&#25506;&#32034;&#27010;&#29575;&#24207;&#21015;$\{\epsilon_t\}_t$&#21644;&#27491;&#21017;&#21270;&#21442;&#25968;$\{\lambda_t\}_t$&#30340;&#19968;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#23545;&#20110;&#20219;&#20309;&#26680;&#21644;&#30456;&#24212;&#30340;RKHS&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#20381;&#36182;&#20110;RKHS&#20869;&#22312;&#32500;&#24230;&#30340;&#27425;&#32447;&#24615;&#21518;&#24724;&#29575;&#12290;&#27492;&#22806;&#65292;&#22312;&#26377;&#38480;&#32500;RKHS&#30340;&#36793;&#38469;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;$\sqrt{T}$&#30340;&#26368;&#20248;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a kernelized version of the $\epsilon$-greedy strategy for contextual bandits. More precisely, in a setting with finitely many arms, we consider that the mean reward functions lie in a reproducing kernel Hilbert space (RKHS). We propose an online weighted kernel ridge regression estimator for the reward functions. Under some conditions on the exploration probability sequence, $\{\epsilon_t\}_t$, and choice of the regularization parameter, $\{\lambda_t\}_t$, we show that the proposed estimator is consistent. We also show that for any choice of kernel and the corresponding RKHS, we achieve a sub-linear regret rate depending on the intrinsic dimensionality of the RKHS. Furthermore, we achieve the optimal regret rate of $\sqrt{T}$ under a margin condition for finite-dimensional RKHS.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#65292;&#20197;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#30446;&#21069;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36827;&#34892;&#29305;&#24449;&#26500;&#24314;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23384;&#22312;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.16297</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#26102;&#21464;&#35843;&#33410;&#22240;&#32032;&#30340;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#20272;&#35745;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Meta-Learning Method for Estimation of Causal Excursion Effects to Assess Time-Varying Moderation. (arXiv:2306.16297v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16297
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#65292;&#20197;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#30446;&#21069;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36827;&#34892;&#29305;&#24449;&#26500;&#24314;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23384;&#22312;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#31359;&#25140;&#25216;&#26415;&#21644;&#26234;&#33021;&#25163;&#26426;&#25552;&#20379;&#30340;&#25968;&#23383;&#21270;&#20581;&#24247;&#24178;&#39044;&#30340;&#21452;&#37325;&#38761;&#21629;&#26174;&#33879;&#22686;&#21152;&#20102;&#31227;&#21160;&#20581;&#24247;&#65288;mHealth&#65289;&#24178;&#39044;&#22312;&#21508;&#20010;&#20581;&#24247;&#31185;&#23398;&#39046;&#22495;&#30340;&#21487;&#21450;&#24615;&#21644;&#37319;&#32435;&#29575;&#12290;&#39034;&#24207;&#38543;&#26426;&#23454;&#39564;&#31216;&#20026;&#24494;&#38543;&#26426;&#35797;&#39564;&#65288;MRTs&#65289;&#24050;&#32463;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#29992;&#20110;&#23454;&#35777;&#35780;&#20272;&#36825;&#20123;mHealth&#24178;&#39044;&#32452;&#25104;&#37096;&#20998;&#30340;&#26377;&#25928;&#24615;&#12290;MRTs&#20135;&#29983;&#20102;&#19968;&#31867;&#26032;&#30340;&#22240;&#26524;&#20272;&#35745;&#37327;&#65292;&#31216;&#20026;&#8220;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#8221;&#65292;&#20351;&#20581;&#24247;&#31185;&#23398;&#23478;&#33021;&#22815;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#29992;&#20110;&#20272;&#35745;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#12290;&#34429;&#28982;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#33258;&#21160;&#29305;&#24449;&#26500;&#24314;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23548;&#33268;&#20102;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Twin revolutions in wearable technologies and smartphone-delivered digital health interventions have significantly expanded the accessibility and uptake of mobile health (mHealth) interventions across various health science domains. Sequentially randomized experiments called micro-randomized trials (MRTs) have grown in popularity to empirically evaluate the effectiveness of these mHealth intervention components. MRTs have given rise to a new class of causal estimands known as "causal excursion effects", which enable health scientists to assess how intervention effectiveness changes over time or is moderated by individual characteristics, context, or responses in the past. However, current data analysis methods for estimating causal excursion effects require pre-specified features of the observed high-dimensional history to construct a working model of an important nuisance parameter. While machine learning algorithms are ideal for automatic feature construction, their naive application
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17475</link><description>&lt;p&gt;
&#36229;&#36234;&#36127;&#37319;&#26679;&#30340;&#39640;&#25928;&#20998;&#24067;&#24335;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#20063;&#31216;&#20026;&#23884;&#20837;&#65289;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#20010;&#31867;&#20284;&#20110;Word2Vec&#31639;&#27861;&#20013;&#24341;&#20837;&#24182;&#22312;&#22810;&#20010;&#24037;&#20316;&#20013;&#37319;&#29992;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#23454;&#29616;&#12290;&#20248;&#21270;&#35745;&#31639;&#30340;&#29942;&#39048;&#26159;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#35745;&#31639;&#65292;&#36825;&#38656;&#35201;&#19982;&#26679;&#26412;&#22823;&#23567;&#21576;&#20108;&#27425;&#27604;&#20363;&#30340;&#25805;&#20316;&#25968;&#12290;&#36825;&#31181;&#22797;&#26434;&#24230;&#19981;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#25152;&#20197;&#36127;&#37319;&#26679;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19982;&#26679;&#26412;&#22823;&#23567;&#32447;&#24615;&#30456;&#20851;&#30340;&#26102;&#38388;&#20869;&#33719;&#24471;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36127;&#37319;&#26679;&#20250;&#25913;&#21464;&#25439;&#22833;&#20989;&#25968;&#65292;&#22240;&#27492;&#35299;&#20915;&#30340;&#26159;&#19982;&#26368;&#21021;&#25552;&#20986;&#30340;&#19981;&#21516;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#22312;&#20110;&#23637;&#31034;&#22914;&#20309;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#20174;&#32780;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23884;&#20837;&#36136;&#37327;&#21644;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#20248;&#20110;&#36127;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our ap
&lt;/p&gt;</description></item></channel></rss>