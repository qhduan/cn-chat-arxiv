<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22312;&#35813;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#36895;&#29575;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#20114;&#20449;&#24687;&#20250;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;</title><link>https://arxiv.org/abs/2402.17067</link><description>&lt;p&gt;
&#20851;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#29420;&#31435;&#26679;&#26412;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Independent Samples Along the Langevin Diffusion and the Unadjusted Langevin Algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17067
&lt;/p&gt;
&lt;p&gt;
&#22312;&#35813;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#20013;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#36895;&#29575;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#20114;&#20449;&#24687;&#20250;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#21021;&#22987;&#21644;&#24403;&#21069;&#38543;&#26426;&#21464;&#37327;&#29420;&#31435;&#21270;&#30340;&#36895;&#29575;&#65292;&#37325;&#28857;&#20851;&#27880;&#36830;&#32493;&#26102;&#38388;&#20013;&#30340;&#26391;&#20043;&#20961;&#25193;&#25955;&#21644;&#31163;&#25955;&#26102;&#38388;&#20013;&#30340;&#26410;&#35843;&#25972;&#26391;&#20043;&#20961;&#31639;&#27861;&#65288;ULA&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#23427;&#20204;&#30340;&#20114;&#20449;&#24687;&#24230;&#37327;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23545;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#26102;&#65292;&#20114;&#20449;&#24687;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#24369;&#23545;&#25968;&#20985;&#26102;&#65292;&#20197;&#22810;&#39033;&#24335;&#36895;&#29575;&#25910;&#25947;&#12290;&#36825;&#20123;&#36895;&#29575;&#31867;&#20284;&#20110;&#22312;&#31867;&#20284;&#26465;&#20214;&#19979;&#26391;&#20043;&#20961;&#25193;&#25955;&#30340;&#28151;&#21512;&#26102;&#38388;&#12290;&#23545;&#20110;ULA&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#30446;&#26631;&#20989;&#25968;&#24378;&#23545;&#25968;&#20985;&#19988;&#20809;&#28369;&#26102;&#65292;&#20114;&#20449;&#24687;&#20197;&#25351;&#25968;&#36895;&#29575;&#25910;&#25947;&#20110;$0$&#12290;&#25105;&#20204;&#36890;&#36807;&#21457;&#23637;&#36825;&#20123;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#20114;&#20449;&#24687;&#29256;&#26412;&#30340;&#28151;&#21512;&#26102;&#38388;&#20998;&#26512;&#26469;&#35777;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22522;&#20110;&#26391;&#20043;&#20961;&#25193;&#25955;&#30340;&#24378;&#25968;&#25454;&#22788;&#29702;&#19981;&#31561;&#24335;&#30340;&#26367;&#20195;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17067v1 Announce Type: cross  Abstract: We study the rate at which the initial and current random variables become independent along a Markov chain, focusing on the Langevin diffusion in continuous time and the Unadjusted Langevin Algorithm (ULA) in discrete time. We measure the dependence between random variables via their mutual information. For the Langevin diffusion, we show the mutual information converges to $0$ exponentially fast when the target is strongly log-concave, and at a polynomial rate when the target is weakly log-concave. These rates are analogous to the mixing time of the Langevin diffusion under similar assumptions. For the ULA, we show the mutual information converges to $0$ exponentially fast when the target is strongly log-concave and smooth. We prove our results by developing the mutual version of the mixing time analyses of these Markov chains. We also provide alternative proofs based on strong data processing inequalities for the Langevin diffusion 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#32422;&#31616;&#26041;&#27861;&#65292;&#21033;&#29992;&#26684;&#32599;&#33707;&#22827;-&#29926;&#29791;&#26031;&#22374;&#25237;&#24433;&#32479;&#19968;&#20102;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#21516;&#26102;&#35299;&#20915;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#39046;&#22495;&#34920;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.02239</link><description>&lt;p&gt;
&#20998;&#24067;&#32422;&#31616;&#65306;&#29992;&#26684;&#32599;&#33707;&#22827;-&#29926;&#29791;&#26031;&#22374;&#25237;&#24433;&#32479;&#19968;&#38477;&#32500;&#21644;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Distributional Reduction: Unifying Dimensionality Reduction and Clustering with Gromov-Wasserstein Projection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#32422;&#31616;&#26041;&#27861;&#65292;&#21033;&#29992;&#26684;&#32599;&#33707;&#22827;-&#29926;&#29791;&#26031;&#22374;&#25237;&#24433;&#32479;&#19968;&#20102;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#20248;&#21270;&#38382;&#39064;&#21516;&#26102;&#35299;&#20915;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#39046;&#22495;&#34920;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#23398;&#20064;&#26088;&#22312;&#25429;&#25417;&#28508;&#22312;&#30340;&#22823;&#35268;&#27169;&#21644;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#32467;&#26500;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#28041;&#21450;&#20351;&#29992;&#38477;&#32500;&#26041;&#27861;&#23558;&#25968;&#25454;&#25237;&#24433;&#21040;&#21487;&#35299;&#37322;&#30340;&#31354;&#38388;&#19978;&#65292;&#25110;&#23558;&#25968;&#25454;&#28857;&#32452;&#32455;&#25104;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#26159;&#25353;&#39034;&#24207;&#20351;&#29992;&#30340;&#65292;&#32780;&#19981;&#33021;&#20445;&#35777;&#32858;&#31867;&#19982;&#38477;&#32500;&#30456;&#19968;&#33268;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35266;&#28857;&#65306;&#20351;&#29992;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#30340;&#24037;&#20855;&#65292;&#29305;&#21035;&#26159;&#26684;&#32599;&#33707;&#22827;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#65292;&#25105;&#20204;&#23558;&#32858;&#31867;&#21644;&#38477;&#32500;&#32479;&#19968;&#20026;&#19968;&#20010;&#31216;&#20026;&#20998;&#24067;&#32422;&#31616;&#30340;&#21333;&#19968;&#26694;&#26550;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#21333;&#20010;&#20248;&#21270;&#38382;&#39064;&#21516;&#26102;&#35299;&#20915;&#32858;&#31867;&#21644;&#38477;&#32500;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#35299;&#37322;&#24615;&#65292;&#24182;&#34920;&#26126;&#23427;&#22312;&#21508;&#31181;&#22270;&#20687;&#21644;&#22522;&#22240;&#32452;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised learning aims to capture the underlying structure of potentially large and high-dimensional datasets. Traditionally, this involves using dimensionality reduction methods to project data onto interpretable spaces or organizing points into meaningful clusters. In practice, these methods are used sequentially, without guaranteeing that the clustering aligns well with the conducted dimensionality reduction. In this work, we offer a fresh perspective: that of distributions. Leveraging tools from optimal transport, particularly the Gromov-Wasserstein distance, we unify clustering and dimensionality reduction into a single framework called distributional reduction. This allows us to jointly address clustering and dimensionality reduction with a single optimization problem. Through comprehensive experiments, we highlight the versatility and interpretability of our method and show that it outperforms existing approaches across a variety of image and genomics datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ROME&#30340;&#40065;&#26834;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#20272;&#35745;&#25972;&#20307;&#20998;&#24067;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#20272;&#35745;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.10566</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Robust Multi-Modal Density Estimation. (arXiv:2401.10566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ROME&#30340;&#40065;&#26834;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#20272;&#35745;&#25972;&#20307;&#20998;&#24067;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#20272;&#35745;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#27010;&#29575;&#39044;&#27979;&#27169;&#22411;&#30340;&#21457;&#23637;&#24341;&#21457;&#20102;&#23545;&#32508;&#21512;&#35780;&#20272;&#25351;&#26631;&#30340;&#38656;&#27714;&#12290;&#34429;&#28982;&#26377;&#20960;&#20010;&#25351;&#26631;&#21487;&#20197;&#34920;&#24449;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65288;&#20363;&#22914;&#65292;&#36127;&#23545;&#25968;&#20284;&#28982;&#12289;Jensen-Shannon&#25955;&#24230;&#65289;&#65292;&#20294;&#36825;&#20123;&#25351;&#26631;&#36890;&#24120;&#20316;&#29992;&#20110;&#27010;&#29575;&#23494;&#24230;&#19978;&#12290;&#22240;&#27492;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#32431;&#31929;&#22522;&#20110;&#26679;&#26412;&#30340;&#39044;&#27979;&#27169;&#22411;&#38656;&#35201;&#20272;&#35745;&#24213;&#23618;&#23494;&#24230;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#24120;&#35265;&#30340;&#26041;&#27861;&#22914;&#26680;&#23494;&#24230;&#20272;&#35745;&#65288;KDE&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#40065;&#26834;&#24615;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#32780;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#22312;&#22810;&#27169;&#24577;&#20272;&#35745;&#38382;&#39064;&#20013;&#23578;&#26410;&#24471;&#21040;&#35780;&#20272;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#30340;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;ROME&#65288;RObust Multi-modal density Estimator&#65289;&#65292;&#23427;&#35299;&#20915;&#20102;&#20272;&#35745;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#30340;&#25361;&#25112;&#12290;ROME&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#28982;&#21518;&#32467;&#21512;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#24471;&#21040;&#24635;&#20307;&#30340;&#20272;&#35745;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Development of multi-modal, probabilistic prediction models has lead to a need for comprehensive evaluation metrics. While several metrics can characterize the accuracy of machine-learned models (e.g., negative log-likelihood, Jensen-Shannon divergence), these metrics typically operate on probability densities. Applying them to purely sample-based prediction models thus requires that the underlying density function is estimated. However, common methods such as kernel density estimation (KDE) have been demonstrated to lack robustness, while more complex methods have not been evaluated in multi-modal estimation problems. In this paper, we present ROME (RObust Multi-modal density Estimator), a non-parametric approach for density estimation which addresses the challenge of estimating multi-modal, non-normal, and highly correlated distributions. ROME utilizes clustering to segment a multi-modal set of samples into multiple uni-modal ones and then combines simple KDE estimates obtained for i
&lt;/p&gt;</description></item></channel></rss>