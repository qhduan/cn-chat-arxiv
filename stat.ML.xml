<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#20854;&#26799;&#24230;&#65292;&#21363;&#20351;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#12290;&#36825;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#21487;&#35777;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.04535</link><description>&lt;p&gt;
&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;: &#20272;&#35745;&#12289;&#21464;&#37327;&#36873;&#25321;&#21450;&#20854;&#20182;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Deep Sobolev Regression: Estimation, Variable Selection and Beyond. (arXiv:2401.04535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04535
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#20854;&#26799;&#24230;&#65292;&#21363;&#20351;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#12290;&#36825;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#21487;&#35777;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;SDORE&#65292;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#20272;&#35745;&#28508;&#22312;&#30340;&#22238;&#24402;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#12290;SDORE&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#65292;&#24182;&#37319;&#29992;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#20801;&#35768;&#23545;&#26080;&#26631;&#31614;&#25968;&#25454;&#35745;&#31639;&#26799;&#24230;&#33539;&#25968;&#12290;&#25105;&#20204;&#23545;SDORE&#30340;&#25910;&#25947;&#36895;&#24230;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#24314;&#31435;&#20102;&#22238;&#24402;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#26368;&#20248;&#36895;&#29575;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#22312;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#20851;&#32852;&#30340;&#25554;&#20540;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#20026;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#21644;&#30830;&#23450;&#31070;&#32463;&#32593;&#32476;&#30340;&#22823;&#23567;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#20808;&#39564;&#25351;&#23548;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#21487;&#35777;&#20248;&#21183;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;SDORE&#26159;&#31532;&#19968;&#20010;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#30340;&#21487;&#35777;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose SDORE, a semi-supervised deep Sobolev regressor, for the nonparametric estimation of the underlying regression function and its gradient. SDORE employs deep neural networks to minimize empirical risk with gradient norm regularization, allowing computation of the gradient norm on unlabeled data. We conduct a comprehensive analysis of the convergence rates of SDORE and establish a minimax optimal rate for the regression function. Crucially, we also derive a convergence rate for the associated plug-in gradient estimator, even in the presence of significant domain shift. These theoretical findings offer valuable prior guidance for selecting regularization parameters and determining the size of the neural network, while showcasing the provable advantage of leveraging unlabeled data in semi-supervised learning. To the best of our knowledge, SDORE is the first provable neural network-based approach that simultaneously estimates the regression function and its gradient, with diverse
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#26680;&#23398;&#20064;&#30340;&#20302;&#31209;&#35299;&#30340;&#24615;&#36136;&#12290;&#22312;&#21482;&#26377;&#20302;&#32500;&#23376;&#31354;&#38388;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#35299;&#37322;&#33021;&#21147;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#21160;&#24471;&#21040;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.11736</link><description>&lt;p&gt;
&#22312;Ridge&#22238;&#24402;&#20013;&#65292;&#26680;&#23398;&#20064;&#8220;&#33258;&#21160;&#8221;&#32473;&#20986;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;
&lt;/p&gt;
&lt;p&gt;
Kernel Learning in Ridge Regression "Automatically" Yields Exact Low Rank Solution. (arXiv:2310.11736v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11736
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#26680;&#23398;&#20064;&#30340;&#20302;&#31209;&#35299;&#30340;&#24615;&#36136;&#12290;&#22312;&#21482;&#26377;&#20302;&#32500;&#23376;&#31354;&#38388;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#35299;&#37322;&#33021;&#21147;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#33258;&#21160;&#24471;&#21040;&#31934;&#30830;&#30340;&#20302;&#31209;&#35299;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24418;&#24335;&#20026;$(x,x') \mapsto \phi(\|x-x'\|^2_\Sigma)$&#19988;&#30001;&#21442;&#25968;$\Sigma$&#21442;&#25968;&#21270;&#30340;&#26680;&#20989;&#25968;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#26680;&#20989;&#25968;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#23427;&#21516;&#26102;&#20248;&#21270;&#20102;&#39044;&#27979;&#20989;&#25968;&#21644;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#21442;&#25968;$\Sigma$&#12290;&#20174;&#36825;&#20010;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#20013;&#23398;&#21040;&#30340;$\Sigma$&#30340;&#29305;&#24449;&#31354;&#38388;&#21487;&#20197;&#21578;&#35785;&#25105;&#20204;&#21327;&#21464;&#37327;&#31354;&#38388;&#20013;&#21738;&#20123;&#26041;&#21521;&#23545;&#39044;&#27979;&#26159;&#37325;&#35201;&#30340;&#12290;&#20551;&#35774;&#21327;&#21464;&#37327;&#21482;&#36890;&#36807;&#20302;&#32500;&#23376;&#31354;&#38388;&#65288;&#20013;&#24515;&#22343;&#20540;&#23376;&#31354;&#38388;&#65289;&#23545;&#21709;&#24212;&#21464;&#37327;&#26377;&#38750;&#38646;&#30340;&#35299;&#37322;&#33021;&#21147;&#65292;&#25105;&#20204;&#21457;&#29616;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#19979;&#26377;&#38480;&#26679;&#26412;&#26680;&#23398;&#20064;&#30446;&#26631;&#30340;&#20840;&#23616;&#26368;&#23567;&#21270;&#32773;&#20063;&#26159;&#20302;&#31209;&#30340;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#26368;&#23567;&#21270;$\Sigma$&#30340;&#31209;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#34987;&#20013;&#24515;&#22343;&#20540;&#23376;&#31354;&#38388;&#30340;&#32500;&#24230;&#25152;&#38480;&#21046;&#12290;&#36825;&#20010;&#29616;&#35937;&#24456;&#26377;&#36259;&#65292;&#22240;&#20026;&#20302;&#31209;&#29305;&#24615;&#26159;&#22312;&#27809;&#26377;&#20351;&#29992;&#20219;&#20309;&#23545;$\Sigma$&#30340;&#26174;&#24335;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#30340;&#65292;&#20363;&#22914;&#26680;&#33539;&#25968;&#27491;&#21017;&#21270;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider kernels of the form $(x,x') \mapsto \phi(\|x-x'\|^2_\Sigma)$ parametrized by $\Sigma$. For such kernels, we study a variant of the kernel ridge regression problem which simultaneously optimizes the prediction function and the parameter $\Sigma$ of the reproducing kernel Hilbert space. The eigenspace of the $\Sigma$ learned from this kernel ridge regression problem can inform us which directions in covariate space are important for prediction.  Assuming that the covariates have nonzero explanatory power for the response only through a low dimensional subspace (central mean subspace), we find that the global minimizer of the finite sample kernel learning objective is also low rank with high probability. More precisely, the rank of the minimizing $\Sigma$ is with high probability bounded by the dimension of the central mean subspace. This phenomenon is interesting because the low rankness property is achieved without using any explicit regularization of $\Sigma$, e.g., nuclear
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#27599;&#36718;&#25237;&#24433;&#30340;&#25968;&#37327;&#26469;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08911</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Methods for Non-stationary Online Learning. (arXiv:2309.08911v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08911
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#27599;&#36718;&#25237;&#24433;&#30340;&#25968;&#37327;&#26469;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#29305;&#21035;&#26159;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#65292;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#34987;&#25552;&#20986;&#20316;&#20026;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#20004;&#20010;&#21407;&#21017;&#24615;&#24615;&#33021;&#24230;&#37327;&#12290;&#20026;&#20102;&#20248;&#21270;&#23427;&#20204;&#65292;&#36890;&#24120;&#37319;&#29992;&#20004;&#23618;&#22312;&#32447;&#38598;&#25104;&#65292;&#30001;&#20110;&#38750;&#24179;&#31283;&#24615;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#65292;&#20854;&#20013;&#32500;&#25252;&#19968;&#32452;&#22522;&#23398;&#20064;&#22120;&#65292;&#24182;&#37319;&#29992;&#20803;&#31639;&#27861;&#22312;&#36816;&#34892;&#36807;&#31243;&#20013;&#36319;&#36394;&#26368;&#20339;&#23398;&#20064;&#22120;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20004;&#23618;&#32467;&#26500;&#24341;&#21457;&#20102;&#20851;&#20110;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#25285;&#24551; -&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#21516;&#26102;&#32500;&#25252;$\mathcal{O}(\log T)$&#20010;&#22522;&#23398;&#20064;&#22120;&#65292;&#23545;&#20110;&#19968;&#20010;$T$&#36718;&#22312;&#32447;&#28216;&#25103;&#65292;&#22240;&#27492;&#27599;&#36718;&#25191;&#34892;&#22810;&#27425;&#25237;&#24433;&#21040;&#21487;&#34892;&#22495;&#19978;&#65292;&#24403;&#22495;&#24456;&#22797;&#26434;&#26102;&#65292;&#36825;&#25104;&#20026;&#35745;&#31639;&#29942;&#39048;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#23558;&#27599;&#36718;&#30340;&#25237;&#24433;&#27425;&#25968;&#20174;$\mathcal{O}(\log T)$&#38477;&#20302;&#21040;...
&lt;/p&gt;
&lt;p&gt;
Non-stationary online learning has drawn much attention in recent years. In particular, dynamic regret and adaptive regret are proposed as two principled performance measures for online convex optimization in non-stationary environments. To optimize them, a two-layer online ensemble is usually deployed due to the inherent uncertainty of the non-stationarity, in which a group of base-learners are maintained and a meta-algorithm is employed to track the best one on the fly. However, the two-layer structure raises the concern about the computational complexity -- those methods typically maintain $\mathcal{O}(\log T)$ base-learners simultaneously for a $T$-round online game and thus perform multiple projections onto the feasible domain per round, which becomes the computational bottleneck when the domain is complicated. In this paper, we present efficient methods for optimizing dynamic regret and adaptive regret, which reduce the number of projections per round from $\mathcal{O}(\log T)$ t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.10656</link><description>&lt;p&gt;
&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65306;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20154;&#31867;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21307;&#30103;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#21892;&#36523;&#20307;&#21644;&#31934;&#31070;&#29366;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65288;VHGM&#65289;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#26377;&#20851;&#21307;&#30103;&#20445;&#20581;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20010;&#24615;&#30340;&#23646;&#24615;&#12290;VHGM&#26159;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20351;&#29992;&#25513;&#30721;&#24314;&#27169;&#35757;&#32451;&#65292;&#22312;&#24050;&#30693;&#23646;&#24615;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#23646;&#24615;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#21033;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#39640;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#25968;&#20540;&#35780;&#20272;&#20102;VHGM&#21450;&#20854;&#35757;&#32451;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20316;&#20026;VHGM&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#24212;&#29992;&#31243;&#24207;&#65292;&#28436;&#31034;&#20102;&#29992;&#25143;&#24773;&#22659;&#65292;&#20363;&#22914;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#65292;&#25552;&#39640;&#20102;&#22312;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#20272;&#35745;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.06818</link><description>&lt;p&gt;
&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#65306;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Dynamic treatment effects: high-dimensional inference under model misspecification. (arXiv:2111.06818v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.06818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#65292;&#25552;&#39640;&#20102;&#22312;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#20272;&#35745;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#22312;&#21508;&#20010;&#23398;&#31185;&#20013;&#37117;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#21487;&#20197;&#25552;&#20379;&#26377;&#20851;&#24178;&#39044;&#30340;&#26102;&#21464;&#22240;&#26524;&#24433;&#21709;&#30340;&#24494;&#22937;&#35265;&#35299;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#8220;&#32500;&#25968;&#28798;&#38590;&#8221;&#21644;&#26102;&#21464;&#28151;&#26434;&#30340;&#23384;&#22312;&#65292;&#36825;&#31181;&#20272;&#35745;&#23384;&#22312;&#30528;&#25361;&#25112;&#65292;&#21487;&#33021;&#23548;&#33268;&#20272;&#35745;&#20559;&#35823;&#12290;&#27492;&#22806;&#65292;&#27491;&#30830;&#22320;&#35268;&#23450;&#26085;&#30410;&#22686;&#22810;&#30340;&#27835;&#30103;&#20998;&#37197;&#21644;&#22810;&#37325;&#26292;&#38706;&#30340;&#32467;&#26524;&#27169;&#22411;&#20284;&#20046;&#36807;&#20110;&#22797;&#26434;&#12290;&#37492;&#20110;&#36825;&#20123;&#25361;&#25112;&#65292;&#21452;&#37325;&#40065;&#26834;&#24615;&#30340;&#27010;&#24565;&#65292;&#22312;&#20801;&#35768;&#27169;&#22411;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#65292;&#26159;&#38750;&#24120;&#26377;&#20215;&#20540;&#30340;&#65292;&#28982;&#32780;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24182;&#27809;&#26377;&#23454;&#29616;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21516;&#26102;&#23545;&#27835;&#30103;&#20998;&#37197;&#21644;&#32467;&#26524;&#27169;&#22411;&#36827;&#34892;&#40065;&#26834;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#24207;&#21015;&#27169;&#22411;&#21452;&#37325;&#40065;&#26834;&#24615;&#8221;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#24403;&#27599;&#20010;&#26102;&#38388;&#26292;&#38706;&#37117;&#26159;&#21452;&#37325;&#40065;&#26834;&#24615;&#30340;&#26102;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#26102;&#38388;&#28857;&#19978;&#23454;&#29616;&#21452;&#37325;&#40065;&#26834;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#39640;&#20102;&#39640;&#32500;&#29615;&#22659;&#19979;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating dynamic treatment effects is essential across various disciplines, offering nuanced insights into the time-dependent causal impact of interventions. However, this estimation presents challenges due to the "curse of dimensionality" and time-varying confounding, which can lead to biased estimates. Additionally, correctly specifying the growing number of treatment assignments and outcome models with multiple exposures seems overly complex. Given these challenges, the concept of double robustness, where model misspecification is permitted, is extremely valuable, yet unachieved in practical applications. This paper introduces a new approach by proposing novel, robust estimators for both treatment assignments and outcome models. We present a "sequential model double robust" solution, demonstrating that double robustness over multiple time points can be achieved when each time exposure is doubly robust. This approach improves the robustness and reliability of dynamic treatment effe
&lt;/p&gt;</description></item></channel></rss>